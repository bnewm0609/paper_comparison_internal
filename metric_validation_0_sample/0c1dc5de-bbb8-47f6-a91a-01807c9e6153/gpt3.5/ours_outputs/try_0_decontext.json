[{"id": 590, "tabid": "0c1dc5de-bbb8-47f6-a91a-01807c9e6153", "schema": ["Invariance to scaling, translation, and rotation", "Efficient feature detection and matching"], "table": {"Invariance to scaling, translation, and rotation": {"paper_1": ["The features are invariant to image scaling, translation, and rotation."], "paper_2": ["The spin-images provide invariance to rigid transformations."], "paper_3": ["Integration of Convolutional Neural Network trained to predict 3D poses in the form of 2D projections provides robustness to scaling, translation, and rotation."]}, "Efficient feature detection and matching": {"paper_1": ["Features are efficiently detected through a staged filtering approach."], "paper_2": ["The method describes a dense collection of oriented points, and their accumulation results in images that allow for efficient feature matching."], "paper_3": ["The method relies on a 'holistic' approach and utilizes a Convolutional Neural Network for efficient feature detection and matching."]}}, "caption": "Object recognition from local features", "gold_col": 2, "predicted_col_num": 2, "type": "gpt3.5_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}, "decontext_schema": {"Invariance to scaling, translation, and rotation": "In the context of the table, Invariance to scaling, translation, and rotation refers to the ability of the features or methods to remain unchanged or consistent despite changes in image size, position, or orientation.", "Efficient feature detection and matching": "In the context of the table, Efficient feature detection and matching refers to the ability of the features to be quickly and effectively identified and matched between different images, despite variations in scaling, translation, and rotation."}}, {"id": 590, "tabid": "0c1dc5de-bbb8-47f6-a91a-01807c9e6153", "schema": ["Surface representation using oriented points and spin-images", "Robustness to clutter, occlusion, and sensor noise"], "table": {"Surface representation using oriented points and spin-images": {"paper_1": ["N/A"], "paper_2": ["Our representation uses oriented points and spin-images to describe the surface shape. The spin-images provide a localized description of the global shape of the surface and are robust to partial views and clutter."], "paper_3": ["N/A"]}, "Robustness to clutter, occlusion, and sensor noise": {"paper_1": ["Robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."], "paper_2": ["Spin-image matching is robust to scene clutter by recognizing objects in 100 scenes containing clutter and occlusion."], "paper_3": ["We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background.", "We improve the state-of-the-art from 73.7% to 89.3% of correctly registered RGB frames.", "The full approach is also scalable, as a single network can be trained for multiple objects simultaneously."]}}, "caption": "3D surface matching", "gold_col": 2, "predicted_col_num": 2, "type": "gpt3.5_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}, "decontext_schema": {"Surface representation using oriented points and spin-images": "In paper_2, Surface representation using oriented points and spin-images refers to a method for describing the surface shape using oriented points and localized descriptions of global shape called spin-images, which are robust to partial views and clutter.", "Robustness to clutter, occlusion, and sensor noise": "In the given context, Robustness to clutter, occlusion, and sensor noise refers to the ability of the surface representation or object recognition method to accurately identify and distinguish objects in complex environments with partial occlusions, cluttered backgrounds, and sensor noise."}}, {"id": 590, "tabid": "0c1dc5de-bbb8-47f6-a91a-01807c9e6153", "schema": ["3D pose prediction using color images only", "Handling of partially occluded and cluttered objects"], "table": {"3D pose prediction using color images only": {"paper_1": ["N/A"], "paper_2": ["N/A"], "paper_3": ["We introduce a novel method for 3D object detection and pose estimation from color images only. We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background. By contrast with recent patch-based methods, we rely on a 'holistic' approach: We apply to the detected objects a Convolutional Neural Network (CNN) trained to predict their 3D poses in the form of 2D projections of the corners of their 3D bounding boxes."]}, "Handling of partially occluded and cluttered objects": {"paper_1": ["Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."], "paper_2": ["We also verify experimentally that spin-image matching is robust to scene clutter by recognizing objects in 100 scenes containing clutter and occlusion."], "paper_3": ["We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background."]}}, "caption": "3D object detection and pose estimation from color images", "gold_col": 2, "predicted_col_num": 2, "type": "gpt3.5_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}, "decontext_schema": {"3D pose prediction using color images only": "The term \"3D pose prediction using color images only\" in the context of the table refers to the use of color images as input to predict the three-dimensional poses of objects, even in the presence of partial occlusions and cluttered background, by relying on a holistic approach such as segmentation and Convolutional Neural Networks (CNNs).", "Handling of partially occluded and cluttered objects": "Handling of partially occluded and cluttered objects refers to the ability of the method or algorithm to accurately detect and recognize objects in images that are partially occluded or surrounded by clutter."}}]