[{"id": 590, "tabid": "0c1dc5de-bbb8-47f6-a91a-01807c9e6153", "schema": ["Invariance to scaling, translation, and rotation", "Efficient feature detection and matching"], "table": {"Invariance to scaling, translation, and rotation": {"paper_1": ["The features are invariant to image scaling, translation, and rotation."], "paper_2": ["The spin-images provide invariance to rigid transformations."], "paper_3": ["Integration of Convolutional Neural Network trained to predict 3D poses in the form of 2D projections provides robustness to scaling, translation, and rotation."]}, "Efficient feature detection and matching": {"paper_1": ["Features are efficiently detected through a staged filtering approach."], "paper_2": ["The method describes a dense collection of oriented points, and their accumulation results in images that allow for efficient feature matching."], "paper_3": ["The method relies on a 'holistic' approach and utilizes a Convolutional Neural Network for efficient feature detection and matching."]}}, "caption": "Object recognition from local features", "gold_col": 2, "predicted_col_num": 2, "type": "gpt3.5_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}}, {"id": 590, "tabid": "0c1dc5de-bbb8-47f6-a91a-01807c9e6153", "schema": ["Surface representation using oriented points and spin-images", "Robustness to clutter, occlusion, and sensor noise"], "table": {"Surface representation using oriented points and spin-images": {"paper_1": ["N/A"], "paper_2": ["Our representation uses oriented points and spin-images to describe the surface shape. The spin-images provide a localized description of the global shape of the surface and are robust to partial views and clutter."], "paper_3": ["N/A"]}, "Robustness to clutter, occlusion, and sensor noise": {"paper_1": ["Robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."], "paper_2": ["Spin-image matching is robust to scene clutter by recognizing objects in 100 scenes containing clutter and occlusion."], "paper_3": ["We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background.", "We improve the state-of-the-art from 73.7% to 89.3% of correctly registered RGB frames.", "The full approach is also scalable, as a single network can be trained for multiple objects simultaneously."]}}, "caption": "3D surface matching", "gold_col": 2, "predicted_col_num": 2, "type": "gpt3.5_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}}, {"id": 590, "tabid": "0c1dc5de-bbb8-47f6-a91a-01807c9e6153", "schema": ["3D pose prediction using color images only", "Handling of partially occluded and cluttered objects"], "table": {"3D pose prediction using color images only": {"paper_1": ["N/A"], "paper_2": ["N/A"], "paper_3": ["We introduce a novel method for 3D object detection and pose estimation from color images only. We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background. By contrast with recent patch-based methods, we rely on a 'holistic' approach: We apply to the detected objects a Convolutional Neural Network (CNN) trained to predict their 3D poses in the form of 2D projections of the corners of their 3D bounding boxes."]}, "Handling of partially occluded and cluttered objects": {"paper_1": ["Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds."], "paper_2": ["We also verify experimentally that spin-image matching is robust to scene clutter by recognizing objects in 100 scenes containing clutter and occlusion."], "paper_3": ["We first use segmentation to detect the objects of interest in 2D even in presence of partial occlusions and cluttered background."]}}, "caption": "3D object detection and pose estimation from color images", "gold_col": 2, "predicted_col_num": 2, "type": "gpt3.5_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}}]