[{"id": 755, "tabid": "0c10c02d-6c29-45a1-9594-828ed6de8a73", "schema": ["Types of voice or speech signals used", "Methods for acquiring or collecting voice or speech signals", "Preprocessing techniques applied to voice or speech signals"], "table": {"Types of voice or speech signals used": {"paper_1": ["voice signals"], "paper_2": ["voice signals"], "paper_3": ["voice signals"], "paper_4": ["voice signals"], "paper_5": ["voice signals"], "paper_6": ["sustained vowels"], "paper_7": ["signal of vowels production"], "paper_8": ["voice signals"], "paper_9": ["patient recordings"]}, "Methods for acquiring or collecting voice or speech signals": {"paper_1": ["using a publicly available database"], "paper_2": ["N/A"], "paper_3": ["N/A"], "paper_4": ["N/A"], "paper_5": ["using existing databases"], "paper_6": ["recording voices"], "paper_7": ["using Saarbruecken Voice Database"], "paper_8": ["N/A"], "paper_9": ["patient recordings"]}, "Preprocessing techniques applied to voice or speech signals": {"paper_1": ["co-occurrence matrices, spectrograms"], "paper_2": ["multitaper Mel Frequency Cepstral Coefficients (MFCC)"], "paper_3": ["MPEG-7 low-level audio, interlaced derivative pattern"], "paper_4": ["Linear Discriminant Analysis, Support Vector Machine"], "paper_5": ["autocorrelation, entropy"], "paper_6": ["acoustical measurements, neural networks"], "paper_7": ["Mel Frequency Cepstral Coefficient, jitter, shimmer, fundamental frequency"], "paper_8": ["short-term cepstral parameters, Linear Discriminant Analysis"], "paper_9": ["35 parameters"]}}, "caption": "Use of voice signals and speech signals for analysis", "gold_col": 3, "predicted_col_num": 3, "type": "mixtral_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}}, {"id": 755, "tabid": "0c10c02d-6c29-45a1-9594-828ed6de8a73", "schema": ["Types of machine learning algorithms used", "Features used for training the machine learning algorithms", "Performance metrics used for evaluating the machine learning algorithms"], "table": {"Types of machine learning algorithms used": {"Paper 1": ["Gaussian mixture model-based classifier"], "Paper 2": ["N/A"], "Paper 3": ["Support vector machine", "Extreme learning machine", "Gaussian mixture model"], "Paper 4": ["Support Vector Machine"], "Paper 5": ["Support vector machine"], "Paper 6": ["N/A"], "Paper 7": ["Na\u00efve Bayes Network"], "Paper 8": ["Artificial Neural Networks"], "Paper 9": ["Autoassociative neural networks"]}, "Features used for training the machine learning algorithms": {"Paper 1": ["Co-occurrence matrices", "Energy", "Entropy", "Contrast", "Homogeneity"], "Paper 2": ["Multitaper Mel Frequency Cepstral Coefficients (MFCCs)"], "Paper 3": ["MPEG-7 low-level audio", "Interlaced derivative pattern"], "Paper 4": ["Mel Frequency Cepstral Coefficients (MFCC)", "Linear Discriminant Analysis (LDA)"], "Paper 5": ["Autocorrelation features", "Entropy"], "Paper 6": ["Pitch", "Jitter", "Shimmer", "Harmonic-to-noise ratio"], "Paper 7": ["Mel Frequency Cepstral Coefficients (MFCC)", "Jitter", "Shimmer", "Fundamental frequency"], "Paper 8": ["Mel Frequency Cepstral Coefficients (MFCC)", "First and second derivatives"], "Paper 9": ["35 parameters describing the vocal tract"]}, "Performance metrics used for evaluating the machine learning algorithms": {"Paper 1": ["Accuracy", "Speed"], "Paper 2": ["Distinguishing between normal voice and disordered voice"], "Paper 3": ["Accuracy", "Time requirement"], "Paper 4": ["Accuracy", "Sensitivity", "Specificity", "Precision", "Area Under Curve (AUC)"], "Paper 5": ["Accuracy"], "Paper 6": ["Accuracy", "Sensitivity", "Specificity"], "Paper 7": ["Classification rate"], "Paper 8": ["Accuracy", "Sensitivity", "Specificity", "Precision", "Area Under Curve (AUC)"], "Paper 9": ["Accuracy"]}}, "caption": "Use of machine learning techniques for voice pathology assessment", "gold_col": 3, "predicted_col_num": 3, "type": "mixtral_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}}, {"id": 755, "tabid": "0c10c02d-6c29-45a1-9594-828ed6de8a73", "schema": ["Datasets used for comparison", "Results or outcomes of the comparison", "Conclusions drawn from the comparison"], "table": {"Datasets used for comparison": {"Paper 1": ["Saarbrucken voice database"], "Paper 2": ["N/A"], "Paper 3": ["N/A"], "Paper 4": ["N/A"], "Paper 5": ["Massachusetts eye and ear infirmary (MEEI)", "Saarbr\u00fccken voice database (SVD)", "Arabic voice pathology database (AVPD)"], "Paper 6": ["German database of voice disorders"], "Paper 7": ["Saarbruecken Voice Database (SVD)"], "Paper 8": ["N/A"], "Paper 9": ["Recordings of patients suffering from hyperfunctional dysphonia, recurrent laryngeal nerve paralysis, laryngitis and healthy control group"]}, "Results or outcomes of the comparison": {"Paper 1": ["The proposed system demonstrates high accuracy and speed in assessing voice pathology"], "Paper 2": ["Adapted weighted Thomson multitaper method could distinguish between normal voice and disordered voice better than the results done by the conventional single-taper technique"], "Paper 3": ["The proposed VPA system shows its efficiency in terms of accuracy and time requirement"], "Paper 4": ["The system performance is evaluated in terms of accuracy, sensitivity, specificity, precision and Area Under Curve (AUC)"], "Paper 5": ["The best achieved accuracies in both detection and classification varied depending on the used band, method, and database"], "Paper 6": ["The performance of the proposed algorithm is evaluated in a term of the accuracy (97.9%), sensitivity (1.6%), and specificity (95.1%)"], "Paper 7": ["The classification rate of the developed detection system is 90%"], "Paper 8": ["The optimized combination of the original MFCC features with their first and second derivatives provides the best performances"], "Paper 9": ["Effectiveness of auto-associative neural networks seems to be promising in the application of pathological voice distinction"]}, "Conclusions drawn from the comparison": {"Paper 1": ["The proposed system can be extended to assess other disabilities in an ELE"], "Paper 2": ["Multitaper MFCC features may be helpful in identifying voices at risk for a real pathology"], "Paper 3": ["A framework is required that facilitates collection, extraction, storage, classification, processing, and modeling of healthcare big data"], "Paper 4": ["The detection of voice disorders can be efficient using only the original Mel Frequency Cepstral Coefficients (MFCC) ignoring their first and second derivative"], "Paper 5": ["The most contributive bands in both detection and classification were between 1000 and 8000 Hz"], "Paper 6": ["The degree of severity is estimated to evaluate how the parameters are far from the standard values based on the percent of normal and pathological values"], "Paper 7": ["N/A"], "Paper 8": ["Short-term cepstral parameters could be useful to conclude an efficient system for detecting voice impairments"], "Paper 9": ["This system ensures non-invasive and fully automated analysis of voice characteristics and decision system based on neural networks"]}}, "caption": "Comparison of different methods or techniques for voice pathology assessment", "gold_col": 3, "predicted_col_num": 3, "type": "mixtral_5_single_call_multiple", "error_counts": {"length_error": 2, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": true}}]