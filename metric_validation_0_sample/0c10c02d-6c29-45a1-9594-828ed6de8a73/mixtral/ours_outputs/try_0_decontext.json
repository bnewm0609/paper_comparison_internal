[{"id": 755, "tabid": "0c10c02d-6c29-45a1-9594-828ed6de8a73", "schema": ["Types of voice or speech signals used", "Methods for acquiring or collecting voice or speech signals", "Preprocessing techniques applied to voice or speech signals"], "table": {"Types of voice or speech signals used": {"paper_1": ["voice signals"], "paper_2": ["voice signals"], "paper_3": ["voice signals"], "paper_4": ["voice signals"], "paper_5": ["voice signals"], "paper_6": ["sustained vowels"], "paper_7": ["signal of vowels production"], "paper_8": ["voice signals"], "paper_9": ["patient recordings"]}, "Methods for acquiring or collecting voice or speech signals": {"paper_1": ["using a publicly available database"], "paper_2": ["N/A"], "paper_3": ["N/A"], "paper_4": ["N/A"], "paper_5": ["using existing databases"], "paper_6": ["recording voices"], "paper_7": ["using Saarbruecken Voice Database"], "paper_8": ["N/A"], "paper_9": ["patient recordings"]}, "Preprocessing techniques applied to voice or speech signals": {"paper_1": ["co-occurrence matrices, spectrograms"], "paper_2": ["multitaper Mel Frequency Cepstral Coefficients (MFCC)"], "paper_3": ["MPEG-7 low-level audio, interlaced derivative pattern"], "paper_4": ["Linear Discriminant Analysis, Support Vector Machine"], "paper_5": ["autocorrelation, entropy"], "paper_6": ["acoustical measurements, neural networks"], "paper_7": ["Mel Frequency Cepstral Coefficient, jitter, shimmer, fundamental frequency"], "paper_8": ["short-term cepstral parameters, Linear Discriminant Analysis"], "paper_9": ["35 parameters"]}}, "caption": "Use of voice signals and speech signals for analysis", "gold_col": 3, "predicted_col_num": 3, "type": "mixtral_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}, "decontext_schema": {"Types of voice or speech signals used": "The column \"Types of voice or speech signals used\" in the table refers to the specific type of voice or speech signals that were used as data in each scientific paper.", "Methods for acquiring or collecting voice or speech signals": "The Methods for acquiring or collecting voice or speech signals refer to the ways in which the researchers obtained the voice or speech signals used in their studies, such as using existing databases or recording voices directly.", "Preprocessing techniques applied to voice or speech signals": "Preprocessing techniques applied to voice or speech signals refer to various methods used to transform or prepare the raw voice or speech data for further analysis, such as extracting features or improving signal quality, as indicated by techniques like spectrograms, Mel Frequency Cepstral Coefficients (MFCC), interlaced derivative pattern, autocorrelation, entropy, short-term cepstral parameters, and neural networks."}}, {"id": 755, "tabid": "0c10c02d-6c29-45a1-9594-828ed6de8a73", "schema": ["Types of machine learning algorithms used", "Features used for training the machine learning algorithms", "Performance metrics used for evaluating the machine learning algorithms"], "table": {"Types of machine learning algorithms used": {"Paper 1": ["Gaussian mixture model-based classifier"], "Paper 2": ["N/A"], "Paper 3": ["Support vector machine", "Extreme learning machine", "Gaussian mixture model"], "Paper 4": ["Support Vector Machine"], "Paper 5": ["Support vector machine"], "Paper 6": ["N/A"], "Paper 7": ["Na\u00efve Bayes Network"], "Paper 8": ["Artificial Neural Networks"], "Paper 9": ["Autoassociative neural networks"]}, "Features used for training the machine learning algorithms": {"Paper 1": ["Co-occurrence matrices", "Energy", "Entropy", "Contrast", "Homogeneity"], "Paper 2": ["Multitaper Mel Frequency Cepstral Coefficients (MFCCs)"], "Paper 3": ["MPEG-7 low-level audio", "Interlaced derivative pattern"], "Paper 4": ["Mel Frequency Cepstral Coefficients (MFCC)", "Linear Discriminant Analysis (LDA)"], "Paper 5": ["Autocorrelation features", "Entropy"], "Paper 6": ["Pitch", "Jitter", "Shimmer", "Harmonic-to-noise ratio"], "Paper 7": ["Mel Frequency Cepstral Coefficients (MFCC)", "Jitter", "Shimmer", "Fundamental frequency"], "Paper 8": ["Mel Frequency Cepstral Coefficients (MFCC)", "First and second derivatives"], "Paper 9": ["35 parameters describing the vocal tract"]}, "Performance metrics used for evaluating the machine learning algorithms": {"Paper 1": ["Accuracy", "Speed"], "Paper 2": ["Distinguishing between normal voice and disordered voice"], "Paper 3": ["Accuracy", "Time requirement"], "Paper 4": ["Accuracy", "Sensitivity", "Specificity", "Precision", "Area Under Curve (AUC)"], "Paper 5": ["Accuracy"], "Paper 6": ["Accuracy", "Sensitivity", "Specificity"], "Paper 7": ["Classification rate"], "Paper 8": ["Accuracy", "Sensitivity", "Specificity", "Precision", "Area Under Curve (AUC)"], "Paper 9": ["Accuracy"]}}, "caption": "Use of machine learning techniques for voice pathology assessment", "gold_col": 3, "predicted_col_num": 3, "type": "mixtral_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}, "decontext_schema": {"Types of machine learning algorithms used": "The column \"Types of machine learning algorithms used\" in the table refers to the specific machine learning algorithms that were employed in each research paper for analyzing their respective datasets.", "Features used for training the machine learning algorithms": "In the context of the table from the scientific papers, \"Features used for training the machine learning algorithms\" refer to the specific input data or characteristics used to train each type of machine learning algorithm mentioned in the paper.", "Performance metrics used for evaluating the machine learning algorithms": "In the context of the table, Performance metrics used for evaluating the machine learning algorithms refer to the specific measures used to assess the accuracy and efficiency of the algorithms in the given studies."}}, {"id": 755, "tabid": "0c10c02d-6c29-45a1-9594-828ed6de8a73", "schema": ["Datasets used for comparison", "Results or outcomes of the comparison", "Conclusions drawn from the comparison"], "table": {"Datasets used for comparison": {"Paper 1": ["Saarbrucken voice database"], "Paper 2": ["N/A"], "Paper 3": ["N/A"], "Paper 4": ["N/A"], "Paper 5": ["Massachusetts eye and ear infirmary (MEEI)", "Saarbr\u00fccken voice database (SVD)", "Arabic voice pathology database (AVPD)"], "Paper 6": ["German database of voice disorders"], "Paper 7": ["Saarbruecken Voice Database (SVD)"], "Paper 8": ["N/A"], "Paper 9": ["Recordings of patients suffering from hyperfunctional dysphonia, recurrent laryngeal nerve paralysis, laryngitis and healthy control group"]}, "Results or outcomes of the comparison": {"Paper 1": ["The proposed system demonstrates high accuracy and speed in assessing voice pathology"], "Paper 2": ["Adapted weighted Thomson multitaper method could distinguish between normal voice and disordered voice better than the results done by the conventional single-taper technique"], "Paper 3": ["The proposed VPA system shows its efficiency in terms of accuracy and time requirement"], "Paper 4": ["The system performance is evaluated in terms of accuracy, sensitivity, specificity, precision and Area Under Curve (AUC)"], "Paper 5": ["The best achieved accuracies in both detection and classification varied depending on the used band, method, and database"], "Paper 6": ["The performance of the proposed algorithm is evaluated in a term of the accuracy (97.9%), sensitivity (1.6%), and specificity (95.1%)"], "Paper 7": ["The classification rate of the developed detection system is 90%"], "Paper 8": ["The optimized combination of the original MFCC features with their first and second derivatives provides the best performances"], "Paper 9": ["Effectiveness of auto-associative neural networks seems to be promising in the application of pathological voice distinction"]}, "Conclusions drawn from the comparison": {"Paper 1": ["The proposed system can be extended to assess other disabilities in an ELE"], "Paper 2": ["Multitaper MFCC features may be helpful in identifying voices at risk for a real pathology"], "Paper 3": ["A framework is required that facilitates collection, extraction, storage, classification, processing, and modeling of healthcare big data"], "Paper 4": ["The detection of voice disorders can be efficient using only the original Mel Frequency Cepstral Coefficients (MFCC) ignoring their first and second derivative"], "Paper 5": ["The most contributive bands in both detection and classification were between 1000 and 8000 Hz"], "Paper 6": ["The degree of severity is estimated to evaluate how the parameters are far from the standard values based on the percent of normal and pathological values"], "Paper 7": ["N/A"], "Paper 8": ["Short-term cepstral parameters could be useful to conclude an efficient system for detecting voice impairments"], "Paper 9": ["This system ensures non-invasive and fully automated analysis of voice characteristics and decision system based on neural networks"]}}, "caption": "Comparison of different methods or techniques for voice pathology assessment", "gold_col": 3, "predicted_col_num": 3, "type": "mixtral_5_single_call_multiple", "error_counts": {"length_error": 2, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": true}, "decontext_schema": {"Datasets used for comparison": "In the context of the table, Datasets used for comparison refers to the specific datasets that were utilized for comparing the results or outcomes of various studies or methods.", "Results or outcomes of the comparison": "In the context of the given table from the scientific papers, the Results or outcomes of the comparison refer to the specific findings or achievements reported by each paper in relation to their comparison or evaluation of various methods, techniques, or datasets for assessing voice pathology or other related healthcare issues. These results may include accuracy rates, efficiency improvements, or identification of contributing factors, among others.", "Conclusions drawn from the comparison": "In the context of the given table, Conclusions drawn from the comparison refer to the inferences or findings made based on the results or outcomes of the comparison between different studies or methods mentioned in each paper. These conclusions often provide suggestions for future research or applications."}}]