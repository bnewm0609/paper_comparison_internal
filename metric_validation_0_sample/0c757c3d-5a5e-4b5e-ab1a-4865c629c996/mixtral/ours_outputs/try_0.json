[{"id": 788, "tabid": "0c757c3d-5a5e-4b5e-ab1a-4865c629c996", "schema": ["Type of sensor used", "Type of data used", "Method of real-world estimation", "Applications of real-world estimation"], "table": {"Type of sensor used": {"Paper 1": ["Multispectral camera and a standard wide-aperture lens"], "Paper 2": ["IR image and point cloud from a TOF camera"]}, "Type of data used": {"Paper 1": ["Multispectral images"], "Paper 2": ["2D image data and 3D point cloud data"]}, "Method of real-world estimation": {"Paper 1": ["Chromatic aberration and defocus blur for depth map recovery"], "Paper 2": ["Joint 2D-3D network incorporating image-based and point-based features for 3D human pose estimation"]}, "Applications of real-world estimation": {"Paper 1": ["Real-world depth estimation in various scenes"], "Paper 2": ["3D driver pose estimation in computer-human interaction scenarios"]}}, "caption": "Use of sensors and images for real-world estimation", "gold_col": 4, "predicted_col_num": 4, "type": "mixtral_5_single_call_multiple", "error_counts": {"length_error": 0, "json_error": 0, "paper_num_error": 0, "column_num_error": 0, "scheme_length_error": 0, "scheme_json_error": 0, "scheme_unknown_error": 0, "over_max_length_error": false, "have_length_error": false}}]