ID: 35de49f8-d513-458d-9cd7-86fb8e9f910b

GOLD TABLE:
|           | Year     | LiDARs                                                     | Cameras                                                         | Annotated LiDAR Frames   | Traffic Scenario             | Diversity              |
|----------:|:---------|:-----------------------------------------------------------|:----------------------------------------------------------------|:-------------------------|:-----------------------------|:-----------------------|
|   6724907 | ['2012'] | ['1 Velodyne HDL-64E']                                     | ['2 color, 2 grayscale cameras']                                | ['15k']                  | ['Urban, Suburban, Highway'] | ['-']                  |
| 209140225 | ['2019'] | ['5 LiDARs']                                               | ['5 high-resolution pinhole cameras']                           | ['230k']                 | ['Urban, Suburban']          | ['Locations']          |
|  85517967 | ['2019'] | ['1 Spinning 32-beams LiDAR']                              | ['6 RGB cameras']                                               | ['40k']                  | ['Urban, Suburban']          | ['Locations, Weather'] |
|   3943983 | ['2018'] | ['2 VUX-1HA laser scanners']                               | ['2 front cameras']                                             | ['144k']                 | ['Urban, Suburban, Highway'] | ['Weather, Locations'] |
| 239929154 | ['2021'] | ['1 Mechanical spinning LiDAR and 1 Forward-facing LiDAR'] | ['5 wide-angle cameras and 1 forward-facing long-focus camera'] | ['6k']                   | ['Urban']                    | ['Locations']          |
| 202540994 | ['2020'] | ['2 Velodyne HDL-32E LiDARs and 1 ibeo LUX 4L LiDARs']     | ['2 stereo cameras and 2 Pixelink PL-B742F industrial cameras'] | ['-']                    | ['Urban, Suburban']          | ['Season']             |
| 202577706 | ['2020'] | ['2 Velodyne HDL-32e LiDARs']                              | ['4 RGB cameras']                                               | ['-']                    | ['Urban, Highway']           | ['Weather']            |
| 202583249 | ['2020'] | ['1 Velodyne HDL-64ES3 3D-LiDAR']                          | ['2 color cameras']                                             | ['39k']                  | ['Urban']                    | ['Weather']            |
| 227162402 | ['2021'] | ['1 Ouster OS1 LiDAR and 1 Velodyne Ultra Puck']           | ['1 3D stereo camera and 1 RGB camera']                         | ['13k']                  | ['Suburban']                 | ['-']                  |
| 227344672 | ['2021'] | ['2 Luminar Model H2 LiDARs']                              | ['1 RGB camera']                                                | ['6k']                   | ['Urban']                    | ['-']                  |
| 235490450 | ['2021'] | ['1 40-beam LiDAR']                                        | ['8 high-resolution cameras']                                   | ['16k']                  | ['Urban, Suburban']          | ['Weather, Locations'] |

GOLD SCHEMA:
0: Year
1: LiDARs
2: Cameras
3: Annotated LiDAR Frames
4: Traffic Scenario
5: Diversity

PREDICTION PATH:../../metric_validation_0/35de49f8-d513-458d-9cd7-86fb8e9f910b/gpt3.5/ours_outputs/try_0.json

PREDICTED TABLE:
|          | Number and type of sensors                                                               | Data collection setup                                                                                                                                                               | Calibration quality                                                                                                                                                                                      | Data annotation approach                                                                                                                                                                                                  | Scene capture duration                                                                | Data availability                                                                                                                    |
|:---------|:-----------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|
| paper_1  | ['6 cameras, 5 radars, 1 lidar']                                                         | ['nuScenes: The first dataset to carry the full autonomous vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree field of view']                          | ['Careful dataset analysis as well as baselines for lidar and image-based detection and tracking']                                                                                                       | ['Fully annotated with 3D bounding boxes for 23 classes and 8 attributes using the autonomous vehicle sensor suite.']                                                                                                     | ['Each scene is 20 seconds long.']                                                    | ['Data, development kit, and more information are available online.']                                                                |
| paper_2  | ['LiDAR, camera']                                                                        | ['Data is well synchronized and calibrated, captured across a range of urban and suburban geographies']                                                                             | ['We exhaustively annotated this data with 2D (camera image) and 3D (LiDAR) bounding boxes, with consistent identifiers across frames']                                                                  | ['Exhaustively annotated with 2D and 3D bounding boxes with consistent identifiers across frames.']                                                                                                                       | ['Each scene spans 20 seconds.']                                                      | ['Find data, code, and more up-to-date information at http://www.waymo.com/open.']                                                   |
| paper_3  | ['1 million LiDAR scenes, 7 million corresponding camera images']                        | ['Data is selected from 144 driving hours, collected across a range of different areas, periods, and weather conditions']                                                           | ['We additionally provide a benchmark in which we reproduce and evaluate a variety of self-supervised and semi-supervised methods on the ONCE dataset']                                                  | ['Provides a benchmark for self-supervised and semi-supervised methods using 1 million LiDAR scenes and 7 million corresponding camera images.']                                                                          | ['Selected from 144 driving hours.']                                                  | ['Data, code, and more information are available at https://once-for-auto-driving.github.io/index.html.']                            |
| paper_4  | ['Four high resolution video cameras, Velodyne laser scanner']                           | ['Recorded in cluttered scenarios, equipped with four high resolution video cameras, a Velodyne laser scanner, and a state-of-the-art localization system']                         | ['Results from state-of-the-art algorithms reveal that methods ranking high on established datasets such as Middlebury perform below average when being moved outside the laboratory to the real world'] | ['Comprises 389 stereo and optical flow image pairs and more than 200k 3D object annotations captured in cluttered scenarios.']                                                                                           | ['Stereo visual odometry sequences of 39.2 km length.']                               | ['Benchmarks are available online at: www.cvlibs.net/datasets/kitti.']                                                               |
| paper_5  | ['RGB videos, dense 3D point clouds']                                                    | ['The data consists of RGB videos and corresponding dense 3D point clouds captured in various traffic conditions']                                                                  | ['High-accuracy pose information at cm accuracy and the static background point cloud has mm relative accuracy']                                                                                         | ['Contains RGB videos and corresponding dense 3D point clouds, each with its per-pixel semantic mask, and different lane markings based on the lane colors and styles.']                                                  | ['Initial release contains over 140K images, each with its per-pixel semantic mask.'] | ['The dataset is available for public use.']                                                                                         |
| paper_6  | ['Two LiDARs, six cameras']                                                              | ['Dataset collected using one 360° mechanical spinning LiDAR, one forward-facing, long-range LiDAR, and 6 cameras']                                                                 | ['We provide baselines for LiDAR-only 3D object detection, LiDAR-camera fusion 3D object detection and LiDAR point cloud segmentation']                                                                  | ['Provides 28 types of labels for object classification and 37 types of labels for semantic segmentation using a complete, high-precision autonomous vehicle sensor kit.']                                                | ['Each scene is 8 seconds long.']                                                     | ['For more details about PandaSet and the development kit, see https://scale.com/open-datasets/pandaset.']                           |
| paper_7  | ['Eleven sensors including various cameras and lidars, a radar, an IMU, and a GPS-RTK']  | ['Integration of eleven heterogeneous sensors, captured many new research challenges (e.g. highly dynamic environment)']                                                            | ['Exploits a ROS (Robot Operating System) based software to process the sensory data']                                                                                                                   | ['Introduces a new dataset collected with an instrumented vehicle integrating eleven heterogeneous sensors and publicly available to the community.']                                                                     | ['Collected recordings of more than 350 km of rides.']                                | ['The dataset is publicly available to the community.']                                                                              |
| paper_8  | ['Four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera']        | ['Recorded in Brno - Czech Republic, offers data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver'] | ['All the data are precisely timestamped with submillisecond precision to allow a wider range of applications']                                                                                          | ['Offers data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera, and differential RTK GNSS receiver with centimetre accuracy, and precisely timestamped with submillisecond precision.'] | ['Recordings of more than 350 km of rides in varying environment.']                   | ['Recordings of more than 350 km of rides in varying environment are shared at: https://github.com/RoboticsBUT/Brno-Urban-Dataset.'] |
| paper_9  | ['RGB images and LiDAR data']                                                            | ['The data was collected on the Rellis Campus of Texas A&M University']                                                                                                             | ['The data was collected on the Rellis Campus of Texas A&M University']                                                                                                                                  | ['Consists of RGB images and LiDAR data with a significant diversity of scene, time, and weather and contains annotations for 230K 3D object annotations, addressing the gaps in the existing datasets.']                 | ['The dataset contains 39K frames.']                                                  | ['The dataset RELLIS-3D is available at https://github.com/unmannedlab/RELLIS-3D.']                                                  |
| paper_10 | ['LiDAR scans, images']                                                                  | ['Data collected on the Rellis Campus of Texas A&M University']                                                                                                                     | ['Experimental results show that RELLIS-3D presents challenges for algorithms designed for segmentation in urban environments']                                                                          | ['Offers annotations for 13,556 LiDAR scans and 6,235 images in an off-road environment, presenting challenges to existing algorithms related to class imbalance and environmental topography.']                          | ['Collected on the Rellis Campus of Texas A&M University.']                           | ['RELLIS-3D is available at https://github.com/unmannedlab/RELLIS-3D.']                                                              |
| paper_11 | ['High-resolution video camera, pair of LiDAR sensors with a 250-meter effective range'] | ['Recorded with a pair of LiDAR sensors with a 250-meter effective range, using both Gaussian and uniform scanning patterns']                                                       | ['To illustrate the kind of studies supported by this new dataset, we introduce LiDAR model adaptation across different ranges, scanning patterns, and sensor devices']                                  | ['Provides paired point clouds simultaneously using both Gaussian and uniform scanning patterns, exhaustively annotated in the LiDAR point clouds for the entire effective range.']                                       | ['LiDAR sensors with a 250-meter effective range.']                                   | ['The dataset is publicly available for autonomous driving tasks.']                                                                  |

MATCHES:
Number and type of sensors: 
Data collection setup: 
Calibration quality: 
Data annotation approach: 
Scene capture duration: 
Data availability: 