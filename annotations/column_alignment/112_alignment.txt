ID: ea633ba2-44f4-4a74-b096-dd319318ca97

GOLD TABLE:
|           | Language       | Pretrained from                | Corpora                                                     | Publicly Available   | Evaluation                                                                                     |
|----------:|:---------------|:-------------------------------|:------------------------------------------------------------|:---------------------|:-----------------------------------------------------------------------------------------------|
| 211678011 | ['Japanese']   | ['Scratch']                    | ['Japanese Clinical Text + Japanese Wikipedia']             | ['No']               | ['Text Classification']                                                                        |
| 226283634 | ['Portuguese'] | ['Multilingual BERT']          | ['Brazilian Clinical Text + Biomedical Text']               | ['Yes']              | ['Clinical Concept Extraction']                                                                |
| 215416118 | ['Russian']    | ['Multilingual BERT']          | ['Russian and English Health Reviews']                      | ['Yes']              | ['ADR Tweets Classification']                                                                  |
| 225452639 | ['German']     | ['General German BERT']        | ['Private Radiology Reports']                               | ['No']               | ['Radiology Reports Classification']                                                           |
| 218564040 | ['Spanish']    | ['Scratch']                    | ['Spanish Biomedical Text']                                 | ['No']               | ['Biomedical NER']                                                                             |
| 232283435 | ['Arabic']     | ['AraBERT']                    | ['General Arabic Text+ Arabic Biomedical Text']             | ['No']               | ['Biomedical NER']                                                                             |
| 219956480 | ['French']     | ['CamemBERT {{cite:a40b78e}}'] | ['French Biomedical Corpus']                                | ['No']               | ['Biomedical NER']                                                                             |
| 221293343 | ['Chinese']    | ['General Chinese BERT']       | ['Chinese Biomedical Text, Encyclopedia , Medical records'] | ['Yes']              | ['ChineseBLUE']                                                                                |
| 220409271 | ['Japanese']   | ['Scratch']                    | ['Japanese Clinical Text']                                  | ['Yes']              | ['Text Classification']                                                                        |
| 233240721 | ['Persian']    | ['ParsBERT {{cite:d02ce8d}}']  | ['Persian Medical Corpus']                                  | ['No']               | ['Medical Question Classification, Medical Question Retrieval and Medical Sentiment Analysis'] |
| 235077408 | ['Spanish']    | ['XLM-R {{cite:e715160}}']     | ['Spanish Clinical Text corpus']                            | ['Yes']              | ['Medical Coding']                                                                             |

GOLD SCHEMA:
0: Language
1: Pretrained from
2: Corpora
3: Publicly Available
4: Evaluation

PREDICTION PATH:../../metric_validation_0/ea633ba2-44f4-4a74-b096-dd319318ca97/mixtral/ours_outputs/try_0.json

PREDICTED TABLE:
|          | Pre-training data sources and techniques                                                                                                                                                      | Fine-tuning data sources and strategies                                                                              | Comparison of pre-trained vs fine-tuned models                                                         | Fine-tuning data sizes and domains                                                                    | Impact of pre-training on model performance                                                                                                                                    |
|:---------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| paper_1  | ['3.8 million text reports', 'unlabelled data, deep bidirectional transformers, BERT']                                                                                                        | ['Intensive care chest x-ray reports', 'BERT to identify the most important findings']                               | ['Pre-trained model has higher AUC than previous approaches for chest x-ray report classification']    | ['N/A']                                                                                               | ['Outperformed the multilingual BERT from Google and other state-of-the-art approaches']                                                                                       |
| paper_2  | ['Large corpus of clinical narratives and biomedical-scientific papers in Brazilian Portuguese', 'transfer learning from a multilingual-BERT model']                                          | ['Two annotated corpora containing clinical narratives', 'BERT models']                                              | ['In-domain model outperformed the baseline in F1-score by 2.72%']                                     | ['N/A']                                                                                               | ['Outperformed the baseline model by 2.72%, achieving higher performance in 11 out of 13 assessed entities']                                                                   |
| paper_3  | ['Large corpus of clinical narratives and biomedical-scientific papers in Brazilian Portuguese', 'transfer learning from a multilingual-BERT model']                                          | ['Two annotated corpora containing clinical narratives', 'BERT models']                                              | ['In-domain model outperformed the baseline in F1-score by 2.72%']                                     | ['N/A']                                                                                               | ['Outperformed the baseline model by 2.72%, achieving higher performance in 11 out of 13 assessed entities']                                                                   |
| paper_4  | ['Large corpus of clinical narratives and biomedical-scientific papers in Brazilian Portuguese', 'transfer learning from a multilingual-BERT model']                                          | ['Two annotated corpora containing clinical narratives', 'BERT models']                                              | ['In-domain model outperformed the baseline in F1-score by 2.72%']                                     | ['N/A']                                                                                               | ['Outperformed the baseline model by 2.72%, achieving higher performance in 11 out of 13 assessed entities']                                                                   |
| paper_5  | ['1.4 million health-related user-generated texts collected from various Internet sources, including social media', 'N/A']                                                                    | ['RuDReC corpus', 'baseline model for named entity recognition (NER) and multi-label sentence classification tasks'] | ['RuDR-BERT model achieved 74.85% in NER task macro F1 score']                                         | ['1.4 million health-related user-generated texts', 'Consumer reviews about pharmaceutical products'] | ['Achieved a macro F1 score of 74.85% for the NER task, and 68.82% for the sentence classification task']                                                                      |
| paper_6  | ['1.4 million health-related user-generated texts collected from various Internet sources, including social media', 'N/A']                                                                    | ['RuDReC corpus', 'baseline model for named entity recognition (NER) and multi-label sentence classification tasks'] | ['RuDR-BERT model achieved 74.85% in NER task macro F1 score']                                         | ['1.4 million health-related user-generated texts', 'Consumer reviews about pharmaceutical products'] | ['Achieved a macro F1 score of 74.85% for the NER task, and 68.82% for the sentence classification task']                                                                      |
| paper_7  | ['3.8 million text reports', 'deep bidirectional transformers, BERT']                                                                                                                         | ['Intensive care chest x-ray reports', 'BERT to identify the most important findings']                               | ['BERT achieved higher AUC than previous approaches for chest x-ray report classification']            | ['3.8 million text reports']                                                                          | ['Achieved areas under the ROC curve of 0.98 for congestion, 0.97 for effusion, 0.97 for consolidation and 0.99 for pneumothorax']                                             |
| paper_8  | ['3.8 million text reports', 'deep bidirectional transformers, BERT']                                                                                                                         | ['Intensive care chest x-ray reports', 'BERT to identify the most important findings']                               | ['BERT achieved higher AUC than previous approaches for chest x-ray report classification']            | ['3.8 million text reports']                                                                          | ['Achieved areas under the ROC curve of 0.98 for congestion, 0.97 for effusion, 0.97 for consolidation and 0.99 for pneumothorax']                                             |
| paper_9  | [' Spanish Clinical Case Corpus (SPACCC)', 'BERT language representation model']                                                                                                              | ['Dataset obtained from the SPACCC', 'BERT language representation model']                                           | ['BERT-based model achieved better NER results than model with standard word embeddings']              | ['Spanish Clinical Case Corpus (SPACCC)']                                                             | ['Showed better results than the NER model trained over the standard word embeddings']                                                                                         |
| paper_10 | ['A small-scale biomedical dataset in Arabic', 'BERT-based model']                                                                                                                            | ['Arabic biomedical text data', 'BERT-based model']                                                                  | ['BERT-based model achieved 85% F1-score in identifying disease and treatment named entities']         | ['Small-scale biomedical dataset']                                                                    | ['Outperformed both models with 85% F1-score']                                                                                                                                 |
| paper_11 | ['N/A', 'contextualized language models']                                                                                                                                                     | ['French biomedical text', 'contextualized language models']                                                         | ['Contextualized language models achieved up to 28% F1-measure improvement in NER task']               | ['Défi Fouille de Textes challenge dataset']                                                          | ['Achieved an F1 -measure of 66% for symptoms and signs, and pathology categories, and 75% for anatomy, dose, exam, mode, moment, substance, treatment, and value categories'] |
| paper_12 | ['Chinese biomedical corpora', 'conceptualized representation learning']                                                                                                                      | ['Chinese biomedical corpora', 'conceptualized representation learning']                                             | ['Conceptualized representation learning approach achieved significant gain on ChineseBLUE benchmark'] | ['Chinese Biomedical Language Understanding Evaluation benchmark']                                    | ['Our approach could bring significant gain']                                                                                                                                  |
| paper_13 | ['Approximately 120 millions of clinical text stored at the University of Tokyo Hospital', 'BERT-base']                                                                                       | ['NTCIR-13 MedWeb', 'BERT']                                                                                          | ['No significant differences found between the developed BERT and other nonspecific BERTs']            | ['120 millions of clinical text from the University of Tokyo Hospital']                               | ['Tends to show higher performances on the MedWeb task than the other nonspecific BERTs']                                                                                      |
| paper_14 | ['A large-scale corpus of medical contents including formal and informal texts collected from a variety of online resources in the Persian language', 'pre-training on a large-scale corpus'] | ['Medical contents in Persian', 'pre-training on a large-scale corpus']                                              | ['SINA-BERT outperforms BERT-based models previously made available in the Persian language']          | ['Large-scale corpus of medical contents']                                                            | ['Outperforms BERT-based models that were previously made available in the Persian language']                                                                                  |
| paper_15 | ['A corpus of real-world oncology clinical cases', 'transfer-learning-based approach, mBERT, BETO, XLM-R']                                                                                    | ['Real-world oncology clinical cases', 'transfer-learning-based approach, mBERT, BETO, XLM-R']                       | ['Domain-specific versions outperformed original general domain models across clinical coding tasks']  | ['Corpus of real-world oncology clinical cases']                                                      | ['Domain-specific version outperformed the original general domain model across the tasks']                                                                                    |
| paper_16 | ['A corpus of real-world oncology clinical cases', 'transfer-learning-based approach, mBERT, BETO, XLM-R']                                                                                    | ['Real-world oncology clinical cases', 'transfer-learning-based approach, mBERT, BETO, XLM-R']                       | ['Domain-specific versions outperformed original general domain models across clinical coding tasks']  | ['Corpus of real-world oncology clinical cases']                                                      | ['Domain-specific version outperformed the original general domain model across the tasks']                                                                                    |
| paper_17 | ['A corpus of real-world oncology clinical cases', 'transfer-learning-based approach, mBERT, BETO, XLM-R']                                                                                    | ['Real-world oncology clinical cases', 'transfer-learning-based approach, mBERT, BETO, XLM-R']                       | ['Domain-specific versions outperformed original general domain models across clinical coding tasks']  | ['Corpus of real-world oncology clinical cases']                                                      | ['Domain-specific version outperformed the original general domain model across the tasks']                                                                                    |

MATCHES:
Pre-training data sources and techniques: 
Fine-tuning data sources and strategies: 
Comparison of pre-trained vs fine-tuned models: 
Fine-tuning data sizes and domains: 
Impact of pre-training on model performance: 