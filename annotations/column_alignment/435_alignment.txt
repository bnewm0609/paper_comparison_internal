ID: e4459d7e-c1db-435a-8fdf-728317419ebd

GOLD TABLE:
|           | Optimizer                      | Batch Size   | Epoch    |
|----------:|:-------------------------------|:-------------|:---------|
| 235771540 | ['Adam']                       | ['NA']       | ['NA']   |
|  52284436 | ['Adam']                       | ['NA']       | ['15']   |
| 216465778 | ['Adam']                       | ['NA']       | ['15']   |
| 212646385 | ['Adam']                       | ['NA']       | ['NA']   |
|  53108672 | ['Adam']                       | ['NA']       | ['NA']   |
| 235771211 | ['Adam']                       | ['64']       | ['NA']   |
|  40762981 | ['SGD with Nesterov momentum'] | ['NA']       | ['100']  |
| 146058215 | ['NA']                         | ['NA']       | ['NA']   |
|   4531539 | ['Adam']                       | ['NA']       | ['NA']   |
| 234082789 | ['Adam']                       | ['5']        | ['NA']   |
| 231979425 | ['Adam']                       | ['NA']       | ['NA']   |
| 209458171 | ['Adam']                       | ['NA']       | ['NA']   |
| 208209257 | ['NA']                         | ['NA']       | ['NA']   |
|  35019434 | ['SGD with momentum']          | ['NA']       | ['20']   |
|  14688745 | ['RMSprop']                    | ['NA']       | ['NA']   |
|  52153773 | ['Adam']                       | ['4']        | ['25']   |
| 221136012 | ['Adam']                       | ['NA']       | ['70']   |
|  18004775 | ['SGD with momentum']          | ['30']       | ['1000'] |
|  13749489 | ['Adam']                       | ['NA']       | ['NA']   |
| 146082119 | ['SGD']                        | ['NA']       | ['NA']   |
|  53872628 | ['Adam']                       | ['NA']       | ['NA']   |
|  18642708 | ['RMSprop']                    | ['NA']       | ['1000'] |

GOLD SCHEMA:
0: Optimizer
1: Batch Size
2: Epoch

PREDICTION PATH:../../metric_validation_0/e4459d7e-c1db-435a-8fdf-728317419ebd/gpt3.5/ours_outputs/try_0.json

PREDICTED TABLE:
|          | Vocal Source Extraction                                                                                                                                                                                                                                           | Accompaniment Removal                                                                                                                                                                                                                                                                    | Harmonic Masking                                                                                                                                                                                                                                                                                                                                                                   |
|:---------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| paper_1  | ['Spectral correlation module (SCM) explicitly models the relationships among all frequency bands in a time-frequency representation, allowing the encoding of global spectral information into a conventional CNN.']                                             | ['Focuses on the learning of local features and relationships among spectral components, neglecting relationships among spectral components locating far apart. Proposes the modeling of spectral correlation explicitly for melody extraction.']                                        | ['We propose to integrate center frequencies with the input feature map of SCM to improve the performance. This approach could be considered a form of harmonic masking for singing melody extraction.']                                                                                                                                                                           |
| paper_2  | ['Hybrid neural network imitates human pitch perception by combining spectral and temporal models, achieving improved performance in singing melody extraction.']                                                                                                 | ['Imitates human pitch perception by simulating the duplex model that complements the pitch perception from unresolved harmonics of the spectral model using the temporal model, achieving improved performance in singing melody extraction.']                                          | ['The spectral model and the temporal model, in accordance with whether harmonics are resolved or not, simulate the duplex model, which complements the pitch perception from unresolved harmonics of the spectral model using the temporal model. The discussion of complex pitch perception models implies the manipulation of harmonic information, akin to harmonic masking.'] |
| paper_3  | ['Proposes a neural network involving spectro-temporal multi-resolution decomposition of the log-spectrogram of the sound for singing melody extraction.']                                                                                                        | ['Emphasizes bottom-up and top-down processes by proposing a network for singing melody extraction that includes spectro-temporal multi-resolution decomposition and a semantic segmentation model.']                                                                                    | ['The neural network includes spectro-temporal multi-resolution decomposition of the log-spectrogram of the sound and a semantic segmentation model. This process may involve techniques related to harmonic masking for feature decomposition in melody extraction.']                                                                                                             |
| paper_4  | ['Built a fully convolutional network (FCN) for melody extraction from polyphonic music. Achieves state-of-the-art performance with less computation and fewer parameters.']                                                                                      | ['Presents a fully convolutional network (FCN) with combined frequency and periodicity representation for melody extraction, achieving state-of-the-art performance with less computation and fewer parameters.']                                                                        | ['The combined frequency and periodicity (CFP) representation, which contains spectral and cepstral information, was adopted as the input feature of the proposed model. The use of combined frequency and periodicity in the model implies the consideration of harmonics, potentially related to harmonic masking.']                                                             |
| paper_5  | ['Proposes a novel streamlined encoder/decoder network and a way to use the bottleneck layer of the network to estimate the existence of a melody line for each time frame, achieving effective melody extraction.']                                              | ['Proposes a novel streamlined encoder/decoder network with a method to use the bottleneck layer of the network to estimate the existence of a melody line for each time frame and achieve simpler convolution modules for accompaniment removal.']                                      | ['The use of the bottleneck layer of the network to estimate the existence of a melody line for each time frame may involve the suppression or manipulation of harmonic frequencies, resembling harmonic masking techniques.']                                                                                                                                                     |
| paper_6  | ['Uses a pitch refinement method to refine the semitone-level pitch sequences and a high-resolution network (HRNet) for melody extraction, outperforming state-of-the-art algorithms.']                                                                           | ['Proposes a pitch refinement method to refine the semitone-level pitch sequences and a bidirectional long short-term memory (BLSTM) layer in a multi-stage training model for accompaniment removal.']                                                                                  | ['The pitch refinement method refines the semitone-level pitch sequences decoded from massive melody MIDI files to generate F0 values for model training, potentially involving harmonic masking techniques in the refinement process.']                                                                                                                                           |
| paper_7  | ['Presents a classification-based singing melody extraction model using deep convolutional neural networks, achieving continuous curve prediction and competitive performance.']                                                                                  | ['Presents a classification-based singing melody extraction model using deep convolutional neural networks; the model consists of singing pitch extractor (SPE) and singing voice activity detector (SVAD) for accompaniment removal.']                                                  | ['The proposed model consists of a singing pitch extractor (SPE) and a singing voice activity detector (SVAD). The model is trained to predict a high-resolution pitch label of singing voice, which may involve the suppression or manipulation of harmonic frequencies, representing aspects of harmonic masking.']                                                              |
| paper_8  | ['Proposes a two-stage multi-resolution end-to-end model for singing melody extraction based on human hearing perception and multi-resolution representations']                                                                                                   | ['Proposes a two-stage multi-resolution end-to-end model for accompaniment removal based on multi-resolution representations and 1-D and 2-D multi-resolution analysis on waveform and spectrogram-like graph for accompaniment suppression.']                                           | ['The convolutional neural network (CNN) is the core of the proposed model to generate multi-resolution representations. The multi-resolution analysis on waveform and spectrogram-like graph may involve techniques related to harmonic masking in the context of singing melody extraction.']                                                                                    |
| paper_9  | ['Describes a fully convolutional neural network for learning salience representations for estimating fundamental frequencies, achieving state-of-the-art performance.']                                                                                          | ['Describes a fully convolutional neural network for learning salience representations for both multi-f0 and melody tracking in polyphonic audio, achieving state-of-the-art performance on several multi-f0 and melody datasets.']                                                      | ['We describe a fully convolutional neural network for learning salience representations for estimating fundamental frequencies, trained using a large, semi-automatically generated F0 dataset. This process may involve techniques related to the manipulation or suppression of harmonic frequencies akin to harmonic masking.']                                                |
| paper_10 | ['Uses a high-resolution network (HRNet) to separate vocals from polyphonic music and an encoder-decoder network to estimate vocal F0 values, demonstrating effectiveness in melody extraction.']                                                                 | ['Uses a high-resolution network (HRNet) to separate vocals from polyphonic music, reducing the interference of accompaniment on the extraction of vocal melody.']                                                                                                                       | ['The vocal F0 values are estimated using an encoder-decoder network, which involves the suppression or manipulation of harmonic frequencies in reducing the interference of accompaniment during pitch estimation, likely employing aspects related to harmonic masking.']                                                                                                        |
| paper_11 | ['Proposes a hierarchical attention network for singing melody extraction to extract attention-aware features and achieve superior performance compared to other state-of-the-art methods.']                                                                      | ['Proposes a hierarchical attention network for singing melody extraction to extract discriminative attention-aware features for accompaniment removal and alleviate the workload of the convolutional recurrent neural network (CRNN).']                                                | ['A hierarchical attention network for singing melody extraction (HANME) to extract the discriminative attention-aware features might involve the suppression or manipulation of harmonic frequencies, resembling aspects related to harmonic masking.']                                                                                                                           |
| paper_12 | ['Describes a multi-task learning approach to joint extraction of vocal F0 and separation of singing voices from music signals, achieving competitive accuracy in melody transcription.']                                                                         | ['Proposes a multi-task learning approach to joint vocal F0 extraction and singing voice separation, demonstrating its effectiveness for singing voice melody transcription.']                                                                                                           | ['We propose a unified network that consists of a deep convolutional neural network for vocal F0 saliency estimation and a U-Net with an encoder shared by two decoders. The differentiable layer that converts an F0 saliency spectrogram into harmonic masks indicates the locations of harmonic partials of a singing voice, reflecting aspects of harmonic masking.']          |
| paper_13 | ['Presents several approaches for jointly separating vocals and estimating fundamental frequency, showing that joint learning is advantageous and outperforms other configurations.']                                                                             | ['Proposes a joint approach for vocal source separation and fundamental frequency estimation, demonstrating that the first task, vocal separation, outperforms the other configurations considered.']                                                                                    | ['We propose several different approaches for jointly separating vocals and estimating fundamental frequency, which may involve the suppression or manipulation of harmonic frequencies akin to harmonic masking techniques in the context of melody extraction.']                                                                                                                 |
| paper_14 | ['Proposes a LSTM-RNN for extracting melody and detecting regions of melody from polyphonic audio using harmonic sum loss.']                                                                                                                                      | ['Proposes a LSTM-RNN for extracting melody and simultaneously detecting regions of melody in polyphonic audio using harmonic sum loss for accompaniment removal.']                                                                                                                      | ['This paper proposes a LSTM-RNN for extracting melody and simultaneously detecting regions of melody from polyphonic audio using the proposed harmonic sum loss, reflecting an aspect related to the manipulation of harmonic frequencies in melody extraction, similar to harmonic masking techniques.']                                                                         |
| paper_15 | ['Presents a classiﬁcation-based approach for melody extraction on vocal segments using multi-column deep neural networks, showing incremental improvements in melody prediction.']                                                                               | ['Presents a classiﬁcation-based approach for melody extraction and uses several neural networks for accompaniment removal. The final melody contour is inferred by combining the outputs of the networks and post-processing with a hidden Markov model.']                              | ['We present a classification-based approach for melody extraction on vocal segments using multi-column deep neural networks, likely involving aspects related to the manipulation or suppression of harmonic frequencies, resembling harmonic masking techniques.']                                                                                                               |
| paper_16 | ['Introduces a multitask deep learning architecture that jointly estimates outputs for various tasks including multiple-f0, melody, vocal, and bass line estimation, showing improved performance over single-task counterparts.']                                | ['Introduces a multitask deep learning architecture that jointly estimates outputs for various tasks including melody, achieving improved performance over single-task counterparts.']                                                                                                   | ['We present a multitask deep learning architecture that jointly estimates outputs for various tasks including multiple-F0, melody, vocal, and bass line estimation, involving harmonic information and reflecting aspects of harmonic masking.']                                                                                                                                  |
| paper_17 | ['Employs a semi-supervised learning method using teacher-student models for vocal melody extraction, demonstrating significantly increased performance compared to supervised learning only.']                                                                   | ['Employs a semi-supervised learning method using teacher-student models for vocal melody extraction and demonstrates that the SSL method significantly increases the performance against supervised learning only.']                                                                    | ['A semi-supervised learning (SSL) method using teacher-student models for vocal melody extraction, involving the supervision of labeled data to guide model predictions, may apply techniques related to the suppression or manipulation of harmonic frequencies, resembling harmonic masking.']                                                                                  |
| paper_18 | ['Presents a system for the transcription of singing voice melodies based on DNN models and demonstrates highest accuracy through better generalization on different music databases.']                                                                           | ['Presents a system for the transcription of singing voice melodies in polyphonic music based on DNN models, achieving highest accuracy through a better generalization and performance of the melody transcription system for accompaniment removal.']                                  | ['The paper presents a system for the transcription of singing voice melodies in polyphonic music signals based on Deep Neural Network (DNN) models, reflecting an aspect related to the manipulation or suppression of harmonic frequencies, akin to harmonic masking.']                                                                                                          |
| paper_19 | ['Introduces a patch-based CNN model for vocal melody extraction, achieving excellent speed and competitive accuracy compared to other deep learning approaches.']                                                                                                | ['Introduces a patch-based CNN model for vocal melody extraction, which enables an efficient training process with limited labeled data and demonstrates competitive accuracy comparing to other deep learning approaches for accompaniment removal.']                                   | ['A patch-based convolutional neural network (CNN) model is presented in this paper for vocal melody extraction in polyphonic music, likely involving aspects related to the suppression or manipulation of harmonic frequencies in melody extraction, similar to harmonic masking techniques.']                                                                                   |
| paper_20 | ['Proposes a DNN-based pitch estimation method for melody extraction, utilizing melody MIDI files as sources of labels and a salience-based method for pitch refinement to achieve outperformance of state-of-the-art methods.']                                  | ['Uses melody MIDI files to train a deep neural network (DNN) model for melody extraction and further proposes a salience-based method to refine the pitch estimate for accompaniment removal.']                                                                                         | ['We propose to use melody MIDI files as the sources of labels to train a deep neural network (DNN) model for melody extraction, reflecting aspects related to the manipulation or suppression of harmonic frequencies akin to harmonic masking techniques.']                                                                                                                      |
| paper_21 | ['Proposes a melody extraction system using DCNN with dilated convolution as the semantic segmentation tool and an adaptive progressive neural network to transfer the semantic segmentation model, showing competitive accuracy.']                               | ['Proposes a deep convolutional neural network (DCNN) with dilated convolution as the semantic segmentation tool for melody extraction and employs an adaptive progressive neural network for the audio domain transfer, demonstrating competitive accuracy for accompaniment removal.'] | ['We propose a novel melody extraction system, using a deep convolutional neural network (DCNN) with dilated convolution as the semantic segmentation tool. The discussion of enhancing candidate pitch contours on the time-frequency image may involve the manipulation or suppression of harmonic frequencies, resembling harmonic masking techniques.']                        |
| paper_22 | ['Proposes a two-stage approach to singing pitch extraction, involving singing voice separation and pitch tracking for monaural polyphonic audio music, demonstrating significant outperformance of a previous state-of-the-art approach in raw-pitch accuracy.'] | ['Proposes a two-stage approach to singing pitch extraction, with the first stage focused on singing voice separation, effectively removing accompaniment and achieving superior raw-pitch accuracy.']                                                                                   | ['The proposed approach involves singing voice separation and pitch tracking for monaural polyphonic audio music, indicating aspects related to the manipulation or suppression of harmonic frequencies in melody extraction, similar to harmonic masking techniques.']                                                                                                            |

MATCHES:
Vocal Source Extraction: 
Accompaniment Removal: 
Harmonic Masking: 