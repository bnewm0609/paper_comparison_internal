ID: 35de49f8-d513-458d-9cd7-86fb8e9f910b

GOLD TABLE:
|           | Year     | LiDARs                                                     | Cameras                                                         | Annotated LiDAR Frames   | Traffic Scenario             | Diversity              |
|----------:|:---------|:-----------------------------------------------------------|:----------------------------------------------------------------|:-------------------------|:-----------------------------|:-----------------------|
|   6724907 | ['2012'] | ['1 Velodyne HDL-64E']                                     | ['2 color, 2 grayscale cameras']                                | ['15k']                  | ['Urban, Suburban, Highway'] | ['-']                  |
| 209140225 | ['2019'] | ['5 LiDARs']                                               | ['5 high-resolution pinhole cameras']                           | ['230k']                 | ['Urban, Suburban']          | ['Locations']          |
|  85517967 | ['2019'] | ['1 Spinning 32-beams LiDAR']                              | ['6 RGB cameras']                                               | ['40k']                  | ['Urban, Suburban']          | ['Locations, Weather'] |
|   3943983 | ['2018'] | ['2 VUX-1HA laser scanners']                               | ['2 front cameras']                                             | ['144k']                 | ['Urban, Suburban, Highway'] | ['Weather, Locations'] |
| 239929154 | ['2021'] | ['1 Mechanical spinning LiDAR and 1 Forward-facing LiDAR'] | ['5 wide-angle cameras and 1 forward-facing long-focus camera'] | ['6k']                   | ['Urban']                    | ['Locations']          |
| 202540994 | ['2020'] | ['2 Velodyne HDL-32E LiDARs and 1 ibeo LUX 4L LiDARs']     | ['2 stereo cameras and 2 Pixelink PL-B742F industrial cameras'] | ['-']                    | ['Urban, Suburban']          | ['Season']             |
| 202577706 | ['2020'] | ['2 Velodyne HDL-32e LiDARs']                              | ['4 RGB cameras']                                               | ['-']                    | ['Urban, Highway']           | ['Weather']            |
| 202583249 | ['2020'] | ['1 Velodyne HDL-64ES3 3D-LiDAR']                          | ['2 color cameras']                                             | ['39k']                  | ['Urban']                    | ['Weather']            |
| 227162402 | ['2021'] | ['1 Ouster OS1 LiDAR and 1 Velodyne Ultra Puck']           | ['1 3D stereo camera and 1 RGB camera']                         | ['13k']                  | ['Suburban']                 | ['-']                  |
| 227344672 | ['2021'] | ['2 Luminar Model H2 LiDARs']                              | ['1 RGB camera']                                                | ['6k']                   | ['Urban']                    | ['-']                  |
| 235490450 | ['2021'] | ['1 40-beam LiDAR']                                        | ['8 high-resolution cameras']                                   | ['16k']                  | ['Urban, Suburban']          | ['Weather, Locations'] |

GOLD SCHEMA:
0: Year
1: LiDARs
2: Cameras
3: Annotated LiDAR Frames
4: Traffic Scenario
5: Diversity

PREDICTION PATH:../../metric_validation_0/35de49f8-d513-458d-9cd7-86fb8e9f910b/mixtral/baseline_outputs/try_0.json

PREDICTED TABLE:
|          | Size and Diversity of Data                                                                                                                                                                                                                                                                                | Sensors and Equipment                                                                                                                                                           | Use Cases and Applications                                                                                                                                            | Sensor Suite                                                                                      | Data Size                                                                                                                                                          | Scenario and Purpose                                                                                                                 |
|:---------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|
| Paper 1  | ['1000 scenes, each 20s long and fully annotated with 3D bounding boxes for 23 classes and 8 attributes, 7x as many annotations and 100x as many images as KITTI dataset']                                                                                                                                | ['6 cameras, 5 radars and 1 lidar, all with full 360 degree field of view']                                                                                                     | ['Training and evaluation of machine learning based methods for detection and tracking on datasets containing range sensor data along with images']                   | ['6 cameras, 5 radars, 1 lidar']                                                                  | ['1000 scenes, 20s each, 3D bounding boxes for 23 classes and 8 attributes']                                                                                       | ['Autonomous vehicle technology']                                                                                                    |
| Paper 2  | ['1150 scenes that each span 20 seconds, consisting of well synchronized and calibrated high quality LiDAR and camera data captured across a range of urban and suburban geographies, 15x more diverse opacity-based geographical and weather variation than the largest camera+LiDAR dataset available'] | ['High quality LiDAR and camera data']                                                                                                                                          | ['Autonomous driving research, generalization within and between operating regions']                                                                                  | ['1 LiDAR, cameras']                                                                              | ['1150 scenes, 20s each, 2D (camera image) and 3D (LiDAR) bounding boxes']                                                                                         | ['Autonomous driving research']                                                                                                      |
| Paper 3  | ['1 million LiDAR scenes and 7 million corresponding camera images, selected from 144 driving hours, collected across a range of different areas, periods and weather conditions']                                                                                                                        | ['1 million LiDAR scenes and 7 million corresponding camera images']                                                                                                            | ['Fully/semi/self-supervised methods for 3D perception in autonomous driving']                                                                                        | ['1 LiDAR']                                                                                       | ['1 million LiDAR scenes and 7 million corresponding camera images']                                                                                               | ['Learning from unlabeled large-scale collected data and incrementally self-training powerful recognition models for 3D perception'] |
| Paper 4  | ['389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3D object annotations captured in cluttered scenarios']                                                                                                                                 | ['4 high resolution video cameras, a Velodyne laser scanner and a state-of-the-art localization system']                                                                        | ['Stereo, optical flow, visual odometry/SLAM and 3D object detection in autonomous driving']                                                                          | ['4 cameras, 1 Velodyne laser scanner']                                                           | ['389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3D object annotations']                          | ['Stereo, optical flow, visual odometry/SLAM and 3D object detection tasks in autonomous driving']                                   |
| Paper 5  | ['Over 140K images - each with its per-pixel semantic mask, up to 1M is scheduled, captured in various traffic conditions, the number of moving objects averages from tens to over one hundred']                                                                                                          | ['RGB videos and corresponding dense 3D point clouds']                                                                                                                          | ['Pixel-accurate environmental perception for autonomous driving, scene parsing, 2D/3D scene understanding, localization, transfer learning, and driving simulation'] | ['RGB videos, 3D point clouds']                                                                   | ['Over 140K images, each with its per-pixel semantic mask, up to 1M scheduled']                                                                                    | ['Outdoor scene parsing for autonomous driving']                                                                                     |
| Paper 6  | ['Over 100 scenes, each of which is 8 seconds long, with 28 types of labels for object classification and 37 types of labels for semantic segmentation']                                                                                                                                                  | ['One 360° mechanical spinning LiDAR, one forward-facing, long-range LiDAR, and 6 cameras']                                                                                     | ['LiDAR-only 3D object detection, LiDAR-camera fusion 3D object detection and LiDAR point cloud segmentation in autonomous driving']                                  | ['1 360° mechanical spinning LiDAR, 1 forward-facing, long-range LiDAR, 6 cameras']               | ['Over 100 scenes, 8 seconds long, 28 types of labels for object classification and 37 types of labels for semantic segmentation']                                 | ['Training deep learning networks for autonomous driving perception algorithms']                                                     |
| Paper 7  | ['11 heterogeneous sensors including various cameras and lidars, a radar, an IMU (Inertial Measurement Unit), and a GPS-RTK (Global Positioning System / Real-Time Kinematic)']                                                                                                                           | ['11 heterogeneous sensors including various cameras and lidars, a radar, an IMU (Inertial Measurement Unit), and a GPS-RTK (Global Positioning System / Real-Time Kinematic)'] | ['Vehicle perception, localization and mapping in autonomous driving']                                                                                                | ['Various cameras and lidars, a radar, an IMU, and a GPS-RTK']                                    | ['Recordings of more than 350 km of rides in varying environment']                                                                                                 | ['Autonomous driving, resulting challenges in long-term autonomy, and map creation and maintenance']                                 |
| Paper 8  | ['Data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver with centimetre accuracy']                                                                                                                                        | ['Data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver with centimetre accuracy']              | ['Environment perception, learning and reasoning, and interacting with the environment in autonomous driving']                                                        | ['4 WUXGA cameras, 2 3D LiDARs, inertial measurement unit, infrared camera, and a GNSS receiver'] | ['Data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver with centimetre accuracy'] | ['Autonomous driving in a varying environment']                                                                                      |
| Paper 9  | ['39K frames, 7 classes, and 230K 3D object annotations, high-density images and heavy occlusions, a large number of nighttime frames addressing the gaps in the existing datasets']                                                                                                                      | ['RGB images and LiDAR data']                                                                                                                                                   | ['Training and testing 3D object detection in real-world setting in autonomous driving']                                                                              | ['RGB images and LiDAR data']                                                                     | ['39K frames, 7 classes, and 230K 3D object annotations']                                                                                                          | ['3D object detection in diverse and challenging environments']                                                                      |
| Paper 10 | ['13,556 LiDAR scans and 6,235 images, collected in an off-road environment, presents challenges to existing algorithms related to class imbalance and environmental topography']                                                                                                                         | ['LiDAR scans and images']                                                                                                                                                      | ['Semantic scene understanding for robust and safe autonomous navigation, particularly so in off-road environments in autonomous driving']                            | ['LiDAR scans and images']                                                                        | ['Annotations for 13,556 LiDAR scans and 6,235 images']                                                                                                            | ['Semantic scene understanding for autonomous navigation in off-road environments']                                                  |
| Paper 11 | ['Over 250,000 frames, 14 object categories, and point cloud data of 250-meter effective range, 90 degree horizontal field of view, and 25 degree vertical field of view, point density varies significantly across such a long range']                                                                   | ['Bi-pattern LiDAR sensors with a 250-meter effective range and a high-resolution video camera']                                                                                | ['3D object detection, critical to highway driving and timely decision making in autonomous driving']                                                                 | ['High-resolution video camera and a pair of LiDAR sensors']                                      | ['Paired point clouds simultaneously using both Gaussian and uniform scanning patterns, within a 250-meter effective range']                                       | ['3D object detection in long-range, highway driving scenarios']                                                                     |

MATCHES:
Size and Diversity of Data: 
Sensors and Equipment: 
Use Cases and Applications: 
Sensor Suite: 
Data Size: 
Scenario and Purpose: 