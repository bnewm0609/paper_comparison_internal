ID: ea633ba2-44f4-4a74-b096-dd319318ca97

GOLD TABLE:
|           | Language       | Pretrained from                | Corpora                                                     | Publicly Available   | Evaluation                                                                                     |
|----------:|:---------------|:-------------------------------|:------------------------------------------------------------|:---------------------|:-----------------------------------------------------------------------------------------------|
| 211678011 | ['Japanese']   | ['Scratch']                    | ['Japanese Clinical Text + Japanese Wikipedia']             | ['No']               | ['Text Classification']                                                                        |
| 226283634 | ['Portuguese'] | ['Multilingual BERT']          | ['Brazilian Clinical Text + Biomedical Text']               | ['Yes']              | ['Clinical Concept Extraction']                                                                |
| 215416118 | ['Russian']    | ['Multilingual BERT']          | ['Russian and English Health Reviews']                      | ['Yes']              | ['ADR Tweets Classification']                                                                  |
| 225452639 | ['German']     | ['General German BERT']        | ['Private Radiology Reports']                               | ['No']               | ['Radiology Reports Classification']                                                           |
| 218564040 | ['Spanish']    | ['Scratch']                    | ['Spanish Biomedical Text']                                 | ['No']               | ['Biomedical NER']                                                                             |
| 232283435 | ['Arabic']     | ['AraBERT']                    | ['General Arabic Text+ Arabic Biomedical Text']             | ['No']               | ['Biomedical NER']                                                                             |
| 219956480 | ['French']     | ['CamemBERT {{cite:a40b78e}}'] | ['French Biomedical Corpus']                                | ['No']               | ['Biomedical NER']                                                                             |
| 221293343 | ['Chinese']    | ['General Chinese BERT']       | ['Chinese Biomedical Text, Encyclopedia , Medical records'] | ['Yes']              | ['ChineseBLUE']                                                                                |
| 220409271 | ['Japanese']   | ['Scratch']                    | ['Japanese Clinical Text']                                  | ['Yes']              | ['Text Classification']                                                                        |
| 233240721 | ['Persian']    | ['ParsBERT {{cite:d02ce8d}}']  | ['Persian Medical Corpus']                                  | ['No']               | ['Medical Question Classification, Medical Question Retrieval and Medical Sentiment Analysis'] |
| 235077408 | ['Spanish']    | ['XLM-R {{cite:e715160}}']     | ['Spanish Clinical Text corpus']                            | ['Yes']              | ['Medical Coding']                                                                             |

GOLD SCHEMA:
0: Language
1: Pretrained from
2: Corpora
3: Publicly Available
4: Evaluation

PREDICTION PATH:../../metric_validation_0/ea633ba2-44f4-4a74-b096-dd319318ca97/mixtral/ours_outputs/try_0.json

PREDICTED TABLE:
|          | Type of language model                                                            | Evaluation metrics and results                                                                                                                                                | Comparison to other language models                                                                                                                                                                                                 | Domains and tasks for evaluation                                                                                                                             | Dataset and corpus sizes                                                                                |
|:---------|:----------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------|
| Paper 1  | ['Transformer-based model for Arabic language understanding', 'BERT-based model'] | ['Macro F1 score of 74.85% in NER task', 'Macro F1 score of 68.82% in sentence classification task']                                                                          | ['Compared to multilingual BERT from Google and other state-of-the-art approaches']                                                                                                                                                 | ['Arabic language understanding', 'Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA)']                                    | ['Not specified']                                                                                       |
| Paper 2  | ['BERT-based model for Portuguese clinical NLP']                                  | ['Outperformed the baseline model in F1-score by 2.72%, achieving higher performance in 11 out of 13 assessed entities']                                                      | ['Compared to existing BERT models']                                                                                                                                                                                                | ['Clinical Named Entity Recognition (NER) in Portuguese']                                                                                                    | ['Two annotated corpora containing clinical narratives']                                                |
| Paper 3  | ['BERT-based model for Portuguese clinical NLP']                                  | ['Outperformed the baseline model in F1-score by 2.72%, achieving higher performance in 11 out of 13 assessed entities']                                                      | ['Compared to existing BERT models']                                                                                                                                                                                                | ['Clinical Named Entity Recognition (NER) in Portuguese']                                                                                                    | ['Two annotated corpora containing clinical narratives']                                                |
| Paper 4  | ['BERT-based model for Portuguese clinical NLP']                                  | ['Outperformed the baseline model in F1-score by 2.72%, achieving higher performance in 11 out of 13 assessed entities']                                                      | ['Compared to existing BERT models']                                                                                                                                                                                                | ['Clinical Named Entity Recognition (NER) in Portuguese']                                                                                                    | ['Two annotated corpora containing clinical narratives']                                                |
| Paper 5  | ['BERT-based model for Russian NER and sentence classification']                  | ['Macro F1 score of 74.85% in NER task', 'Macro F1 score of 68.82% in sentence classification task']                                                                          | ['N/A']                                                                                                                                                                                                                             | ['Named Entity Recognition (NER) and sentence classification in Russian for health-related named entities and the effectiveness of pharmaceutical products'] | ['1.4 million health-related user-generated texts in Russian, 500 consumer reviews about drug therapy'] |
| Paper 6  | ['BERT-based model for Russian NER and sentence classification']                  | ['Macro F1 score of 74.85% in NER task', 'Macro F1 score of 68.82% in sentence classification task']                                                                          | ['N/A']                                                                                                                                                                                                                             | ['Named Entity Recognition (NER) and sentence classification in Russian for health-related named entities and the effectiveness of pharmaceutical products'] | ['1.4 million health-related user-generated texts in Russian, 500 consumer reviews about drug therapy'] |
| Paper 7  | ['BERT-based model for chest radiographic report classification']                 | ['Areas under the receiver operation characteristics curve of 0.98 for congestion, 0.97 for effusion, 0.97 for consolidation, and 0.99 for pneumothorax']                     | ['N/A']                                                                                                                                                                                                                             | ['Chest radiographic report classification']                                                                                                                 | ['3.8 million text reports']                                                                            |
| Paper 8  | ['BERT-based model for chest radiographic report classification']                 | ['Areas under the receiver operation characteristics curve of 0.98 for congestion, 0.97 for effusion, 0.97 for consolidation, and 0.99 for pneumothorax']                     | ['N/A']                                                                                                                                                                                                                             | ['Chest radiographic report classification']                                                                                                                 | ['3.8 million text reports']                                                                            |
| Paper 9  | ['BERT-based model for Spanish biomedical NER']                                   | ['F1-score not provided']                                                                                                                                                     | ['N/A']                                                                                                                                                                                                                             | ['Named Entity Recognition (NER) in Spanish biomedical literature']                                                                                          | ['Spanish Clinical Case Corpus (SPACCC)']                                                               |
| Paper 10 | ['BERT-based model for Arabic biomedical NER']                                    | ['85% F1-score']                                                                                                                                                              | ['Outperformed AraBERT and multilingual BERT cased models']                                                                                                                                                                         | ['Biomedical Named-Entity Recognition in Arabic text data']                                                                                                  | ['Small-scale biomedical dataset']                                                                      |
| Paper 11 | ['Contextualized French language models for biomedical NER']                      | ['F1-measure of 66% for symptoms and signs, and pathology categories', 'F1-measure of 75% for anatomy, dose, exam, mode, moment, substance, treatment, and value categories'] | ['Ensemble of neural language models improved over a CRF baseline and a single specialized language model']                                                                                                                         | ['Named Entity Recognition in French biomedical text']                                                                                                       | ['Not specified']                                                                                       |
| Paper 12 | ['BERT-based model for Chinese biomedical text mining']                           | ['F1-measure not provided']                                                                                                                                                   | ['Examined the effectiveness of Chinese pre-trained models: BERT, BERT-wwm, RoBERTa, and their approach']                                                                                                                           | ['Biomedical text mining in Chinese']                                                                                                                        | ['Not specified']                                                                                       |
| Paper 13 | ['Clinical specific BERT for Japanese clinical texts']                            | ['Accuracies of Masked LM and Next Sentence Prediction of 0.773 and 0.975, respectively']                                                                                     | ['Compared the performances on the MedWeb task with the other nonspecific BERTs, but no significant differences were found']                                                                                                        | ['Clinical coding in Japanese']                                                                                                                              | ['Approximately 120 millions of clinical text from the University of Tokyo Hospital']                   |
| Paper 14 | ['BERT-based model for Persian medical texts']                                    | ['Outperforms BERT-based models in medical question categorization, sentiment analysis, and question retrieval']                                                              | ['Outperforms BERT-based models previously made available in the Persian language']                                                                                                                                                 | ['Medical text analysis in Persian']                                                                                                                         | ['Large-scale corpus of medical contents in Persian']                                                   |
| Paper 15 | ['Transformer-based models for clinical coding in Spanish']                       | ['MAP scores of 0.662, 0.544, and 0.884 on CodiEsp-D, CodiEsp-P, and Cantemist-Coding shared tasks, respectively']                                                            | ['Domain-specific versions outperformed original general domain models across clinical coding tasks', 'Ensemble approach leveraging the predictive capacities of the three distinct transformers resulted in the best performance'] | ['Clinical coding in Spanish']                                                                                                                               | ['Corpus of real-world oncology clinical cases in Spanish']                                             |
| Paper 16 | ['Transformer-based models for clinical coding in Spanish']                       | ['MAP scores of 0.662, 0.544, and 0.884 on CodiEsp-D, CodiEsp-P, and Cantemist-Coding shared tasks, respectively']                                                            | ['Domain-specific versions outperformed original general domain models across clinical coding tasks', 'Ensemble approach leveraging the predictive capacities of the three distinct transformers resulted in the best performance'] | ['Clinical coding in Spanish']                                                                                                                               | ['Corpus of real-world oncology clinical cases in Spanish']                                             |
| Paper 17 | ['Transformer-based models for clinical coding in Spanish']                       | ['MAP scores of 0.662, 0.544, and 0.884 on CodiEsp-D, CodiEsp-P, and Cantemist-Coding shared tasks, respectively']                                                            | ['Domain-specific versions outperformed original general domain models across clinical coding tasks', 'Ensemble approach leveraging the predictive capacities of the three distinct transformers resulted in the best performance'] | ['Clinical coding in Spanish']                                                                                                                               | ['Corpus of real-world oncology clinical cases in Spanish']                                             |

MATCHES:
Type of language model: 
Evaluation metrics and results: 
Comparison to other language models: 
Domains and tasks for evaluation: 
Dataset and corpus sizes: 