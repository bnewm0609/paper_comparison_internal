ID: 35de49f8-d513-458d-9cd7-86fb8e9f910b

GOLD TABLE:
|           | Year     | LiDARs                                                     | Cameras                                                         | Annotated LiDAR Frames   | Traffic Scenario             | Diversity              |
|----------:|:---------|:-----------------------------------------------------------|:----------------------------------------------------------------|:-------------------------|:-----------------------------|:-----------------------|
|   6724907 | ['2012'] | ['1 Velodyne HDL-64E']                                     | ['2 color, 2 grayscale cameras']                                | ['15k']                  | ['Urban, Suburban, Highway'] | ['-']                  |
| 209140225 | ['2019'] | ['5 LiDARs']                                               | ['5 high-resolution pinhole cameras']                           | ['230k']                 | ['Urban, Suburban']          | ['Locations']          |
|  85517967 | ['2019'] | ['1 Spinning 32-beams LiDAR']                              | ['6 RGB cameras']                                               | ['40k']                  | ['Urban, Suburban']          | ['Locations, Weather'] |
|   3943983 | ['2018'] | ['2 VUX-1HA laser scanners']                               | ['2 front cameras']                                             | ['144k']                 | ['Urban, Suburban, Highway'] | ['Weather, Locations'] |
| 239929154 | ['2021'] | ['1 Mechanical spinning LiDAR and 1 Forward-facing LiDAR'] | ['5 wide-angle cameras and 1 forward-facing long-focus camera'] | ['6k']                   | ['Urban']                    | ['Locations']          |
| 202540994 | ['2020'] | ['2 Velodyne HDL-32E LiDARs and 1 ibeo LUX 4L LiDARs']     | ['2 stereo cameras and 2 Pixelink PL-B742F industrial cameras'] | ['-']                    | ['Urban, Suburban']          | ['Season']             |
| 202577706 | ['2020'] | ['2 Velodyne HDL-32e LiDARs']                              | ['4 RGB cameras']                                               | ['-']                    | ['Urban, Highway']           | ['Weather']            |
| 202583249 | ['2020'] | ['1 Velodyne HDL-64ES3 3D-LiDAR']                          | ['2 color cameras']                                             | ['39k']                  | ['Urban']                    | ['Weather']            |
| 227162402 | ['2021'] | ['1 Ouster OS1 LiDAR and 1 Velodyne Ultra Puck']           | ['1 3D stereo camera and 1 RGB camera']                         | ['13k']                  | ['Suburban']                 | ['-']                  |
| 227344672 | ['2021'] | ['2 Luminar Model H2 LiDARs']                              | ['1 RGB camera']                                                | ['6k']                   | ['Urban']                    | ['-']                  |
| 235490450 | ['2021'] | ['1 40-beam LiDAR']                                        | ['8 high-resolution cameras']                                   | ['16k']                  | ['Urban, Suburban']          | ['Weather, Locations'] |

GOLD SCHEMA:
0: Year
1: LiDARs
2: Cameras
3: Annotated LiDAR Frames
4: Traffic Scenario
5: Diversity

PREDICTION PATH:../../metric_validation_0/35de49f8-d513-458d-9cd7-86fb8e9f910b/mixtral/ours_outputs/try_0.json

PREDICTED TABLE:
|          | Purpose of the dataset                                                                                                                                                                                                                                                                                                                                                  | Number and type of sensors used                                                                                                                                                     | Range and field of view of the sensors                                                                                                                               | Number of annotated scenes and length of each scene                                             | Number and types of objects and attributes annotated                                                                                                                                        | Metrics defined for evaluation                                                          |
|:---------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------|
| paper_1  | ['To train and evaluate machine learning based methods on datasets containing range sensor data along with images, for robust detection and tracking of objects in autonomous driving.']                                                                                                                                                                                | ['6 cameras, 5 radars, and 1 lidar']                                                                                                                                                | ['6 cameras, 5 radars and 1 lidar, all with full 360 degree field of view, 1 lidar with 360 degree field of view, 5 radars with 360 degree field of view']           | ['1000 scenes']                                                                                 | ['3D bounding boxes for 23 classes and 8 attributes']                                                                                                                                       | ['NuScenes detection score, NuScenes tracking score, and Mean Average Precision (mAP)'] |
| paper_2  | ['To help align the research community’s contributions with real-world self-driving problems, by providing a large scale, high quality, diverse dataset with 1150 scenes and well synchronized and calibrated high quality LiDAR and camera data captured across a range of urban and suburban geographies.']                                                           | ['well synchronized and calibrated high quality LiDAR and camera data']                                                                                                             | ['high quality LiDAR and camera data captured across a range of urban and suburban geographies']                                                                     | ['1150 scenes']                                                                                 | ['2D bounding boxes in camera images and 3D bounding boxes in LiDAR point clouds for 3D detection']                                                                                         | ['KITTI detection and tracking metrics']                                                |
| paper_3  | ['To facilitate future research on exploiting unlabeled data for 3D detection, by introducing the ONCE (One millioN sCenEs) dataset for 3D object detection in the autonomous driving scenario. The ONCE dataset consists of 1 million LiDAR scenes and 7 million corresponding camera images.']                                                                        | ['1 million LiDAR scenes and 7 million corresponding camera images']                                                                                                                | ['1 million LiDAR scenes with range information']                                                                                                                    | ['1 million scenes']                                                                            | ['Annotations for 3D object detection']                                                                                                                                                     | ['Evaluation metrics for 3D object detection']                                          |
| paper_4  | ['To develop novel challenging benchmarks for the tasks of stereo, optical flow, visual odometry/SLAM and 3D object detection, for reducing the bias of moving visual recognition systems outside the laboratory to the real world.']                                                                                                                                   | ['four high resolution video cameras, a Velodyne laser scanner']                                                                                                                    | ['four high resolution video cameras, a Velodyne laser scanner with range information']                                                                              | ['389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length'] | ['3D object annotations (up to 15 cars and 30 pedestrians per image) for stereo, optical flow, visual odometry/SLAM, and 3D object detection']                                              | ['Mean Average Precision (mAP)']                                                        |
| paper_5  | ['To provide a large scale dataset for the design and evaluation of scene parsing algorithms, in particular for outdoor scenes, by presenting a large-scale open dataset, ApolloScape, that consists of RGB videos and corresponding dense 3D point clouds.']                                                                                                           | ['RGB videos and corresponding dense 3D point clouds']                                                                                                                              | ['RGB videos and corresponding dense 3D point clouds with range information']                                                                                        | ['Over 140K images']                                                                            | ['Per-pixel semantic mask for each image']                                                                                                                                                  | ['Intersection over Union (IoU) and pixel accuracy']                                    |
| paper_6  | ['To provide a dataset produced by a complete, high-precision autonomous vehicle sensor kit with a no-cost commercial license for training deep learning networks for improving self-driving perception algorithms.']                                                                                                                                                   | ['one 360° mechanical spinning LiDAR, one forward-facing, long-range LiDAR, and 6 cameras']                                                                                         | ['one 360° mechanical spinning LiDAR with 360 degree field of view, one forward-facing, long-range LiDAR with longer range than the 360° mechanical spinning LiDAR'] | ['More than 100 scenes']                                                                        | ['28 types of labels for object classification and 37 types of labels for semantic segmentation']                                                                                           | ['Evaluation metrics for semantic segmentation and object detection']                   |
| paper_7  | ['To present a new dataset, publicly available to the community, for autonomous driving captured with a multisensor platform allowing vehicle to perceive its surroundings and locate itself in a more efficient and accurate way.']                                                                                                                                    | ['eleven heterogeneous sensors including various cameras and lidars, a radar, an IMU (Inertial Measurement Unit), and a GPS-RTK (Global Positioning System / Real-Time Kinematic)'] | ['various cameras and lidars with range information']                                                                                                                | ['Not specified']                                                                               | ['Not specified']                                                                                                                                                                           | ['Not specified']                                                                       |
| paper_8  | ['To offer data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera, and especially differential RTK GNSS receiver with centimeter accuracy, for autonomous driving tasks such as 3D object detection and mapping.']                                                                                                                     | ['four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera, differential RTK GNSS receiver']                                                                   | ['four WUXGA cameras, two 3D LiDARs with range information']                                                                                                         | ['Recordings of more than 350 km of rides']                                                     | ['Data from four TE Connectivity WUXGA cameras, two 3D Velodyne LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver with centimetre accuracy'] | ['Not applicable (dataset provides annotated point clouds, not scenes)']                |
| paper_9  | ['To introduce a new challenging A*3D dataset which consists of RGB images and LiDAR data with a significant diversity of scene, time, and weather, addressing the gaps in the existing datasets for pushing the boundaries of tasks in autonomous driving research.']                                                                                                  | ['RGB images and LiDAR data']                                                                                                                                                       | ['RGB images and LiDAR data with range information']                                                                                                                 | ['39K frames']                                                                                  | ['7 classes and 230K 3D object annotations']                                                                                                                                                | ['Mean Average Precision (mAP) and nuScenes detection score']                           |
| paper_10 | ['To fill the gap of existing datasets that either represent urban environments or lack multimodal off-road data, by providing a multimodal dataset collected in an off-road environment, which contains annotations for 13,556 LiDAR scans and 6,235 images, and evaluating the current state of the art deep learning semantic segmentation models on this dataset.'] | ['13,556 LiDAR scans and 6,235 images']                                                                                                                                             | ['13,556 LiDAR scans and 6,235 images']                                                                                                                              | ['Annotations for 13,556 LiDAR scans and 6,235 images']                                         | ['Annotations for 13,556 LiDAR scans and 6,235 images']                                                                                                                                     | ['Accuracy, completeness, and consistency']                                             |
| paper_11 | ['To introduce Cirrus, a new long-range bi-pattern LiDAR public dataset for autonomous driving tasks such as 3D object detection, critical to highway driving and timely decision making, equipped with a high-resolution video camera and a pair of LiDAR sensors with a 250-meter effective range, which is significantly longer than existing public datasets.']     | ['one high-resolution video camera and a pair of LiDAR sensors']                                                                                                                    | ['a pair of LiDAR sensors with a 250-meter effective range, which is significantly longer than existing public datasets']                                            | ['Not applicable (dataset provides annotated point clouds, not scenes)']                        | ['8 categories of objects exhaustively annotated in the LiDAR point clouds for the entire effective range']                                                                                 | ['Intersection over Union (IoU) for 3D object detection']                               |

MATCHES:
Purpose of the dataset: 
Number and type of sensors used: 
Range and field of view of the sensors: 
Number of annotated scenes and length of each scene: 
Number and types of objects and attributes annotated: 
Metrics defined for evaluation: 