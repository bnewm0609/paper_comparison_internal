{"id": 258297964, "updated": "2023-12-13 22:37:05.831", "metadata": {"title": "Fed-BioMed: Open, Transparent and Trusted Federated Learning for Real-world Healthcare Applications", "authors": "[{\"first\":\"Francesco\",\"last\":\"Cremonesi\",\"middle\":[]},{\"first\":\"Marc\",\"last\":\"Vesin\",\"middle\":[]},{\"first\":\"Sergen\",\"last\":\"Cansiz\",\"middle\":[]},{\"first\":\"Yannick\",\"last\":\"Bouillard\",\"middle\":[]},{\"first\":\"Irene\",\"last\":\"Balelli\",\"middle\":[]},{\"first\":\"Lucia\",\"last\":\"Innocenti\",\"middle\":[]},{\"first\":\"Santiago\",\"last\":\"Silva\",\"middle\":[]},{\"first\":\"Samy-Safwan\",\"last\":\"Ayed\",\"middle\":[]},{\"first\":\"Riccardo\",\"last\":\"Taiello\",\"middle\":[]},{\"first\":\"Laetita\",\"last\":\"Kameni\",\"middle\":[]},{\"first\":\"Richard\",\"last\":\"Vidal\",\"middle\":[]},{\"first\":\"Fanny\",\"last\":\"Orlhac\",\"middle\":[]},{\"first\":\"Christophe\",\"last\":\"Nioche\",\"middle\":[]},{\"first\":\"Nathan\",\"last\":\"Lapel\",\"middle\":[]},{\"first\":\"Bastien\",\"last\":\"Houis\",\"middle\":[]},{\"first\":\"Romain\",\"last\":\"Modzelewski\",\"middle\":[]},{\"first\":\"Olivier\",\"last\":\"Humbert\",\"middle\":[]},{\"first\":\"Melek\",\"last\":\"Onen\",\"middle\":[]},{\"first\":\"Marco\",\"last\":\"Lorenzi\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "The real-world implementation of federated learning is complex and requires research and development actions at the crossroad between different domains ranging from data science, to software programming, networking, and security. While today several FL libraries are proposed to data scientists and users, most of these frameworks are not designed to find seamless application in medical use-cases, due to the specific challenges and requirements of working with medical data and hospital infrastructures. Moreover, governance, design principles, and security assumptions of these frameworks are generally not clearly illustrated, thus preventing the adoption in sensitive applications. Motivated by the current technological landscape of FL in healthcare, in this document we present Fed-BioMed: a research and development initiative aiming at translating federated learning (FL) into real-world medical research applications. We describe our design space, targeted users, domain constraints, and how these factors affect our current and future software architecture.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2304-12012", "doi": "10.48550/arxiv.2304.12012"}}, "content": {"source": {"pdf_hash": "51fff8dc8af70c8d45c6df93a4b5b3444f27c23c", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2304.12012v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "5a90f9a741f393b873a8c7eab0017e8e3e403b2f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/51fff8dc8af70c8d45c6df93a4b5b3444f27c23c.txt", "contents": "\nFed-BioMed: Open, Transparent and Trusted Federated Learning for Real-world Healthcare Applications\n\n\nFrancesco Cremonesi \nEpione Research Group\nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nFrance\n\nMarc Vesin \nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nSED Group\nFrance\n\nSergen Cansiz \nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nSED Group\nFrance\n\nYannick Bouillard \nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nSED Group\nFrance\n\nIrene Balelli \nEpione Research Group\nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nFrance\n\nLucia Innocenti \nEpione Research Group\nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nFrance\n\nSantiago Silva \nEpione Research Group\nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nFrance\n\nSamy-Safwan Ayed \nEpione Research Group\nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nFrance\n\nRiccardo Taiello \nEpione Research Group\nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nFrance\n\nLaetita Kameni \nAccenture Labs\nFrance\n\nRichard Vidal \nAccenture Labs\nFrance\n\nFanny Orlhac \nCentre de Recherche de l'Institut Curie\nLaboratoire d'Imagerie Translationnelle en Oncologie (LITO)\nUniversit\u00e9 Paris-Saclay\nU1288 InsermOrsayFrance\n\nChristophe Nioche \nCentre de Recherche de l'Institut Curie\nLaboratoire d'Imagerie Translationnelle en Oncologie (LITO)\nUniversit\u00e9 Paris-Saclay\nU1288 InsermOrsayFrance\n\nNathan Lapel \nNuclear Medicine Department\nHenri Becquerel Center\nRouenFrance\n\nBastien Houis \nNuclear Medicine Department\nHenri Becquerel Center\nRouenFrance\n\nRomain Modzelewski \nNuclear Medicine Department\nHenri Becquerel Center\nRouenFrance\n\nOlivier Humbert \nUCA\nUniversit\u00e9 C\u00f4te d'Azur\nFrance\n\nMelek Onen \nEURECOM\nFrance\n\nMarco Lorenzi \nEpione Research Group\nUniversit\u00e9 C\u00f4te d'Azur\nInria Sophia Antipolis\nFrance\n\nFed-BioMed: Open, Transparent and Trusted Federated Learning for Real-world Healthcare Applications\n\nThe real-world implementation of federated learning is complex and requires research and development actions at the crossroad between different domains ranging from data science, to software programming, networking, and security. While today several FL libraries are proposed to data scientists and users, most of these frameworks are not designed to find seamless application in medical use-cases, due to the specific challenges and requirements of working with medical data and hospital infrastructures. Moreover, governance, design principles, and security assumptions of these frameworks are generally not clearly illustrated, thus preventing the adoption in sensitive applications. Motivated by the current technological landscape of FL in healthcare, in this document we present arXiv:2304.12012v1 [cs.LG] 24 Apr 2023Fed-BioMed: a research and development initiative aiming at translating federated learning (FL) into real-world medical research applications. We describe our design space, targeted users, domain constraints, and how these factors affect our current and future software architecture.\n\nIntroduction\n\nThe need for large amounts of data to develop Artificial Intelligence (AI) in healthcare has motivated a number of national and international initiatives aimed at creating medical data lakes accessible to researchers, such as the French Health Data Hub [10], the UK BioBank [59], the US ADNI [26] and TCGA [60], among the many [58,40,7]. In spite of these initiatives, there are still major bottlenecks preventing the widespread availability of large centralized repositories of healthcare information [63].\n\nTo overcome these limitations, Federated Learning (FL) has been proposed as a working paradigm to enable the training of ML models on large datasets from diverse sources while guaranteeing the respect of data privacy and governance. The basic paradigm of FL consists of iterating the following steps: i) model training is performed locally in the hospitals starting from a common initialization, ii) the resulting model parameters are subsequently shared (instead of the data) and aggregated, to define a global model iii) transmitted back to the hospitals to initiate a new local training step. Under certain conditions [39], this procedure is guaranteed to converge to a final global model representing an optimal consensus among the hospitals participating in the experiment. FL is particularly suited for applications in sensitive domains, such as healthcare and biomedical research [48,9,13]. The current societal and economical interest in FL for healthcare is paramount [56,52], as demonstrated by the several largescale medical research projects based on FL at the national and international level, focusing for example on rare hematological diseases 1 , drug development 2 , blood cancer 3 , among the many [15,53,19].\n\nIn spite of the current popularity, the real-world implementation of FL is complex and requires research and development actions at the crossroad between different domains spanning data science, software programming, networking, and security. Today, several FL software frameworks are currently being proposed to data scientists and users, based on different design spaces, goals, and with varying degrees of software maturity. Nevertheless, most of these frameworks are not designed to find seamless application in medical use-cases, due to the specific challenges and requirements of working with medical data and hospital infrastructures. Furthermore, several widely-used FL libraries oftentimes devote little attention to describe the design space and guiding principles, while the spotlight is often placed on describing implementation details without justifying particular design choices.\n\nIn this document we present Fed-BioMed: a research and development initiative aiming at translating FL into real-world medical research applications, motivated by the current technological landscape of FL for healthcare. We describe our design space, targeted users, domain constraints, and how these factors affect our current and future software architecture. While implementation details may change with the evolution of new technologies and contributions from a growing pool of developers, we believe that a description of Fed-BioMed's philosophy and guiding principles, along with the relevant architectural details, provides a faithful and transparent representation of our goal and ambitions.\n\n\nContribution\n\nWhile several FL frameworks are currently available, none of them have documented a clear set of design principles and guiding concepts inspired by the application domain, nor a demonstration of how their architecture and implementation satisfy the specific requirements of FL in clinical applications. In what follows, we identify the requirements arising from the needs of medical data owners and biomedical data scientists, and show how Fed-BioMed addresses the specific challenges of this domain.\n\nTo meet the strict security requirements typical of medical environments, Fed-BioMed focuses on empowering the user with a tight control of data management and model training process. This is based on a deployment workflow enabling easy setup of its main components, on prototypes of a data and model governance system with a graphical interface for non-technical users such as clinical data managers and physicians, on a Jupyter notebook interface for researchers and data scientists, and on extensive documentation and tutorials targeting biomedical data scientists as well as health data providers 4 . Overall, the straightforward design of Fed-BioMed aims at simplifying the development and deployment of federated learning analysis in real-world healthcare research.\n\n\nFederated Learning for biomedical research applications: design considerations\n\nThe application of ML methods, and in particular of FL, in the context of medical data analysis presents unique challenges requiring a targeted approach. First and foremost, is the conflict between the need for large datasets to train ML models and data sharing regulations, such as the European General Data Protection Regulation (GDPR) 5 and the US Health Insurance Portability and Accountability Act (HIPAA) 6 . Additionally, ethical, economical, and technical barriers hinder the sharing of medical information [63,61]. The entities that provide medical records for FL experiments are therefore compelled to enforce 4 https://fedbiomed.gitlabpages.inria.fr/ 5 https://gdpr-info.eu/ 6 https://www.cdc.gov/phlp/publications/topic/hipaa.html strict data governance policies on their data, requiring strong security and privacy guarantees as well as retaining the ability to exert fine-grained control over data processing and flow. Medical data are generally not directly amenable to FL analysis: they are often stored in unstructured, potentially proprietary formats inside independent silos, leading to large degrees of heterogeneity making data potentially biased and difficult to compare [24,61]. For example, the lack of standardized coded definitions may lead to noisy labels, with a detrimental effect on training performance, especially for medical data where missingness is a common problem [21]. Big data in medicine is characterized by relatively low volumes with high information density [24], and often requires integration of multiple data acquisition methods, bringing all the challenges associated with the analysis of multimodal data [30]. Furthermore, hospital IT infrastructure has been designed to support clinical and billing operations, but is not optimized for data analytics [24]. The procedures for installing and operating FL software may vary wildly across different hospitals, leading to difficulties during the deployment process and inconsistencies in the execution.\n\nIn a biomedical research setting, the prototypical FL experiment consists of a dynamic and highly interactive series of training rounds interspersed with sessions of model and hyperparameter tuning, interpretation of partial results with domain experts, and general debugging. This process requires a large degree of interactivity that can be in contrast with the design of FL systems for other applications that are more focused on batch execution of training rounds, model stability, and high availability of the infrastructure.\n\nAny software being operated in the context of biomedical research must satisfy strict security rules arising not only from data privacy concerns but also from intellectual property and compliance to guidelines [12]. The FL process itself exposes multiples vulnerabilities such as model inversion, membership inference, and model poisoning attacks [6,57], which must be mitigated through a combination of classical cybersecurity approaches -such as e.g. encryption, firewalls, malware protection, and network segmentation-as well as FL-specific techniques such as secure aggregation [36].\n\n\nPrimary Requirements\n\nFrom the challenges described above we derive a set of requirements that Fed-BioMed aims at satisfying, categorized in four primary (i.e. must-have), four secondary (i.e. nice-to-have) and three minor (i.e. could-have) requirements. We summarize the challenges and requirements in Table 1.\n\n\nData and model governance\n\nWe define these as the granting the following rights to clinical data nodes: i) the ability to review, add or revoke at any time the availability of any given dataset for federated training; ii) the ability to approve, audit and monitor the execution of specific FL workflows; iii) the ability to review, audit and customize the deployment of the software infrastructure. Furthermore, as the time of data managers and clinical experts is often a scarce resource, the ability to exercise such fine-grained control on data governance and processing should be provided in a simple user interface requiring only minimal learning efforts.\n\n\nIntegration with biomedical data sources\n\nAn FL framework targeting interoperability should at the very least be aware of existing interoperability efforts in medical data management and analysis, and ideally should offer direct and seamless integration for the management of data in such formats.\n\n\nResearcher interactivity\n\nFL frameworks suited for research purposes should provide the ability to launch, stop and generally manipulate the training process, modify model and training parameters on the fly, resume training from checkpoints, and monitor convergence, while respecting the FL paradigm, the data providers' privacy, and node's governance requirements.\n\n\nSecurity\n\nAn FL framework for the biomedical research domain should provide a secure environment for the FL technical infrastructure, minimizing the surface of attacks on the data providers' systems through the framework itself, implementing network segmentation, securing network communication, and insulating the execution from external attackers. Furthermore, the framework should support and allow for easy activation of gradient protection, against model-targeted attacks such as model poisoning, membership inference, and model inversion.\n\n\nSecondary and Minor Requirements\n\nFederated pre/post-processing, i.e. the framework's ability to support data or model pre/post-processing in a federated approach.\n\nSupported ML libraries/frameworks, meaning the framework's capability to seamlessly integrate with a variety of state-of-the-art ML libraries and providing state-of-the-art FL algorithms.\n\nPortability, intended as reproducibility of the development environment as obtained e.g. by the use of containers and virtual environments.\n\nDrop-out tolerance, as in the framework's resilience to node drop-outs, other unexpected failure events, or the framework's ability to provide finegrained node selection during training. Note that in a controlled cross-silo setting unexpected drop-outs are usually considered less relevant than in a crossdevice FL deployment.\n\nFinally, we note that some other requirements are often cited in the broader context of FL applications but are of relatively minor importance to the domain of biomedical research, such as e.g. high availability of servers, scalability in terms of number of clients, and lightweight software implementation.\n\n\nBackground: FL Frameworks Landscape\n\nThe number of FL frameworks has dramatically surged in recent years, witnessing the growing interest in the applications of this technology [31,56,44]. We are aware of well-established products whose focus is not related to biomedical applications, but whose implementation does not exclude future deployments in this domain, such as e.g. Tensorflow Federated (TFF) [5], FedML [23], IBM-FL [34], FATE [33], PaddleFL [35], and PySyft [51]. Henceforth, we restrict our analysis to SubstraFL [46], OpenFL [17], Flare [50], and Flower [4], which are frameworks that have already been applied in medical use-cases, in accordance with the focus of this paper. Table 2 summarizes our frameworks review in light of the requirements identified in section 2.1. LabeliaLab's SubstraFL framework is a Python library based on the Substra software developed by the company Owkin [46,20]. It is currently being used in healthcare applications for drug discovery in the context of the Mellody project [8], as well as oncology, anatomopathology and fertility in the context of the Healthchain project [45,43]. SubstraFL's architecture is based on a fully-decentralized distributed ledger, and is designed upon the three core principles of collaboration, privacy, and traceability. Data governance is implemented through operations on the distributed ledger, which also guarantees traceability of all ML operations within the consortium. Operational roles are well-defined, and a permissions regime inspired by the Role-Based Access Control paradigm (RBAC) can be used to enable additional governance measures for handling remote assets (algorithms and data). Furthermore, a Graphical User Interface (GUI) is provided to simplify the management of assets on nodes. While SubstraFL has been deployed in healthcare settings, to our knowledge no tools specifically dedicated to the management of healthcare or biomedical assets are provided with the library, nor are there any tutorials or deployment examples focused on this domain. SubstraFL's target use-case is the execution of FL experiments at scale, and therefore the library is intended to be mainly used in production environments. For this reason, it may not be an ideal choice for exploratory workflows requiring a high degree of interactivity during model development and training. The distributed ledger at the core of SubstraFL's architecture also acts as a security feature by providing a strong guarantee against the alteration of training and inference metadata, and potentially against model poisoning attacks. No explicit description of encrypted secured communications, such as TLS, is currently provided in the framework, while differential privacy and secure aggregation approaches are not integrated in the library. Finally, governance and roadmap of SubstraFL are centralised, preventing the development of an open-source community around the project.\n\nOpenFL is another Python-based FL library, originally designed for a healthcare application but later expanded to be use case-agnostic [17]. It has been  Table 2: Comparison of FL frameworks with respect to the requirements identified in Section 2.1. The label \"Only demonstrators\" signifies that a feature is not built in the framework, but that a demonstrator has been provided in the form of a reference implementation, a tutorial, or documentation.\n\nused in the context of medical applications for a global FL deployment aimed at detecting glioblastoma sub-compartment boundaries [47]. OpenFL has been designed to support multi-institutional collaborations with a strong focus on cybersecurity. The system architecture is based on the star topology paradigm with the aggregator as the central node and collaborators as edge nodes, authenticated through PKI certificates and communicating via encrypted TLS connections. Governance is implemented mainly through API operations or code snippets written by data owners. For example, the code implementing a ShardDescriptor needs to be present on each node. In some setups, data scientists may query centralized datasets and experiment registries holding metadata describing the whole federation. We could not find any core functionalities in the library that are specific to the integration with biomedical data sources. However, tutorials with a medical focus are provided in the examples section and can serve as a rough template for simple biomedical applications. From the point of view of interactivity, OpenFL's documentation and experiment API seems to implicitly emphasize batch execution of training experiments rather than model exploration, even though some features, such as e.g. the simple porting of model descriptions from the serial to the federated approach, do enable some degree of interactivity. OpenFL has a strong declared focus on cybersecurity. The usage of hardware-level features such as Trusted Execution Environments (TEE), as well as more conventional network-level measures such as TLS-encrypted communication and PKI certificates guarantee high degree of protection against attacks. Nevertheless, fully exploiting the capabilities of OpenFL is bound to the adoption of proprietary hardware. This condition is not necessarily compatible with practical deployment of FL in hospitals, and may critically prevent the adoption of the software in typical real-world scenarios.\n\nFlare is yet another Python FL library, developed by Nvidia [50], which has been recently used in a world-wide federation of clinical sites to develop a new model for triaging patients affected by COVID-19 [14], as well as other healthcare-related demonstrations for e.g. classification and segmentation tasks on medical images [49,54]. Flare has been designed on the principles of scalability, flexibility and lightweight, and is targeted towards cross-silo FL, not limited to healthcare, supporting both production settings as well as simulated FL for researchers. Flare's architecture is built on the paradigm of one Controller distributing tasks to several workers, thus leading to a more generic framework with respect to the other libraries analysed here. Governance is handled through configuration files and a Python code managed manually by node administrators. Specifications for a specific training experiment are provided partially by the data scientist (e.g. the model) and partially by the clients (e.g. the learners). To our knowledge, no special tools are provided to node administrators for the management of data nor for fine-grained control over algorithm execution. Moreover, while Flare's utility has been showcased in healthcare settings, it still aims to be a generic framework, and as such we could not identify features of the library aimed specifically at the integration with biomedical data sources. Similarly as with OpenFL, the capabilities of Flare are oriented towards the adoption of specialized hardware, as demonstrated by the focus of the project on GPU usage, scalability, and high availability, which in our experience does not correspond to a prototypical hospital deployment scenario. Flare's reliance on configuration files leads to a somewhat complex ecosystem that could potentially lead to a more rigid structure, lacking some of the flexibility that medical researchers may wish for during an exploratory model development phase. From a cybersecurity point of view, Flare offers protection against man in the middle and impersonation attacks, through the use of encrypted communication, SSL authentication, and a robust provisioning workflow. Furthermore, the concept of local filters enables the implementation of secure aggregation, homomorphic encryption, and differential privacy, which are however not available as part of the standard features of the framework.\n\nRecently, the widely-used Flower framework [4] has announced a collaboration with the Swedish decentralized AI project in order to improve the national healthcare ecosystem 7 . The design principles at the basis of Flower's architecture are scalability, flexibility, and generality w.r.t ML, communication and privacy frameworks. Given the general focus, Flower does not come pre-equipped with any data governance tools, nor does it provide any specific tools for the integration with biomedical data formats. On the other hand, Flower's flexible structure makes it highly amenable to highly interactive workflows, which are also further customizable thanks to the extensible Strategy class. Flower offers native support for encrypted communication through its use of gRPC [18]. Their Secure Aggregation implementation, named Salvia, remains to our knowledge a proof of concept that is not yet built into the library.\n\n\nMethods\n\n\nDesign space and goals of Fed-BioMed\n\nThe main purpose of Fed-BioMed is to enable seamless collaboration between medical investigators, data providers, and data scientists in a high trust, highly interactive research environment. First and foremost, we aim at providing secure tools for the governance of personal biomedical data and the federated training of models on such data. Additionally, we strive to make all our interfaces, especially those facing the medical researchers and data providers, easy to use even for non-technical users. Our second goal is to make the interface for the data scientist as interactive and flexible as possible to allow fast turnaround during the development of new ML models and strategies, while respecting the privacy needs of the data providers.\n\nIn the context of the life cycle of a FL experiment, we make a clear-cut distinction between research applications and model deployment in production. Both begin with a data generation and preparation step, which is typically within the scope of a specific clinical investigation. In the case of secondary use of data, this step includes extracting data from an already existing hospital database, cleaning and wrangling the data, and applying the necessary anonymization or pseudonymization procedures. This step is followed by a model development phase, comprising federated data preprocessing, training, validation, and hyperparameter tuning. Sometimes the model development phase is split in two sub-phases: an initial exploration where a subset of the data is centralized, followed by the actual federated training phase. In the development phase, emphasis is put on the scientific process of hypothesis formulation, experiment and model design, architecture and hyperparameter search, and training. Finally, once a stable version has been reached, the model can be deployed in production mode, where emphasis is placed more on inference, reliability, robustness and high availability. The main scope of Fed-BioMed is to support the deployment and translation of AI to biomedical research and healthcare during the model development phase, but we also support deployments in production mode. To this end, we are actively working and collaborating with experts in medical data analysis, optimization, security, databases, and visualization. Figure 1 shows the typical workflow of a FL experiment, with the main design space of Fed-BioMed highlighted in the shaded area and the supported deployment modes highlighted in the dashed area.\n\nOur current design goals include using Fed-BioMed in a high-trust environment, where all parties are honest and have an open, secure channel of communication outside of it. We target mainly research consortia composed of a relatively small number of data providers (e.g. university hospitals or medical research centers) and data consumers (e.g. data scientists and researchers with an expertise on biomedical data). In the future, we aim to extend our paradigm to account for less-trusted environments, such as e.g. in the presence of malicious clients.\n\nFederated learning requires the availability of computing infrastructure at the edge nodes: rather than focusing on high performance computing, we target the more common scenario of clinical sites with varying computing capabilities. We do not make the assumption that the edge nodes' computing infrastructure is able to sustain a high availability cycle; instead we consider that the research work will be organized in periods of active testing and model training, alternating with periods of independent work where the computing infrastructure at the edge nodes may be disconnected.\n\nDuring periods of research activity and model training, we assume that all actors involved will be available and able to communicate with low response latency. Our researcher and medical data provider interfaces are designed with this underlying assumption, thus enabling us to provide what we deem to be a good balance between automatizing some governance processes while keeping a human-in-the-loop approach to maximize security.\n\nThe data scientists using Fed-BioMed, called researchers in our notation, are assumed to be knowledgeable users of at least one of the supported ML frameworks, and to be able to read API documentation and code basic Python functions complying with it. We also assume that they are able to discuss with biomedical researchers and data providers about technical aspects involving both the preparation of data (e.g. developing a common data model and format) and the development or interpretation of ML models for biomedical data. Coherently with the FL paradigm, we make the assumption that the edge nodes wish to protect their data from arbitrary access of the researchers while preventing data leakages, from either a malicious source or a manipulation mistake.\n\n\nDesign and functional architecture\n\nThe functional architecture of Fed-BioMed, as shown in Figure 2, is based on the design space described in Section 4.1 and the requirements identified in Section 2. The Fed-BioMed ecosystem comprises three architectural components: the network, the researcher, and one or more nodes. The network is responsible for brokering the communication between all Fed-BioMed components, the researcher is responsible for configuring and driving the federated learning experiment, as well as aggregating the trained models, while the nodes are responsible for local data governance and actually performing the training.\n\nA standard training experiment is described in Figure 3, where nodes are first required to make their data available for training by inserting an appropriate metadata entry in a locally-stored database, and assigning unique identifying tags to those data. This process is simplified by the web-GUI built-in to our framework, but a CLI is also available for programmatic approaches. Optionally, node-specific customizations to the data loading process may be specified here through a plugin system called DataLoadingPlan, with the intention of reducing the data formatting burden by providing a logical layer between the researcher and the actual data format as stored locally. Then researchers define Figure 2: High-level architecture and design pillars of Fed-BioMed: node-side governance and control, interoperability with medical data standards and infrastructure, researcher interactivity, and data privacy and security. Fed-BioMed is composed of three components: the researcher, a data scientist responsible for designing and steering the training of the ML model; the nodes, i.e. the clinical data providers; and the network, responsible for brokering all communication between the researcher and nodes. Each component has been designed following the Fed-BioMed requirements (Section 2), and the figure highlights which requirement affects the architectural subcomponents.\n\na TrainingPlan, i.e. an object containing the description of the ML model and aggregation parameters, the code for the training and validation routines, a data loading and preprocessing routine, and other training-specific information such as e.g. the description of the optimizer. The TrainingPlan is packaged in an Experiment object along with the aggregator, training arguments, and data identifier tags.\n\nThe researcher then issues a train command through the network's message broker, which is broadcasted to all the nodes. Nodes that identify the requested data tags within their metadata database may begin training: first the TrainingPlan object is recreated on the node, then data are loaded, preprocessed using both node-specific customizations as well as researcher-specified functions, and finally the training routine of the training plan is executed. For convenience, Fed-BioMed comes with pre-packaged TrainingPlans for widelyused frameworks, thus requiring minimal configuration from researchers.\n\n\nNode-side governance\n\nFed-BioMed empowers nodes by maximising the amount of control they have over the execution of a FL experiment. In Fed-BioMed, there is no notion of a trusted third party to which nodes must delegate full trust. For training, we make the assumption that datasets have already been treated to comply to existing data privacy regulations (e.g. pseudonymisation), and that they have been at least partially harmonised, both semantically and syntactically, to a pre-defined format common to all the nodes participating in the experiment. First the nodes mark their dataset as available for federated training, while the researcher defines and obtains approval for a TrainingPlan. Then the researcher may launch multiple experiments, and within each experiment interactively launch multiple rounds of training. In each round, data are loaded locally on the nodes and the researcher-defined training routine is executed. Communication of model parameters and metadata always happens through the Network component.\n\nWhen an experiment is launched, the datasets corresponding to the requested tags are loaded in the node's worker instance and prepared for training. A researcher-defined training data function is then used to load the data and apply local pre-processing. Although this is not yet strictly enforced, this function is expected to use one of the dataset classes defined by Fed-BioMed providing controlled access to filesystem resources and best compatibility with the rest of the Fed-BioMed workflow. It is also possible to emulate a federated data pre-processing pipeline by assembling multiple experiments, thanks to Fed-BioMed's interactive approach.\n\nFed-BioMed's answer to the obvious tradeoff between allowing researchers to execute custom code snippets on the worker nodes and the associated security issues, is to provide a mechanism called training plan approval. When enabled, this feature prevents the execution of code contained in TrainingPlans that has not yet been inspected and approved by the node. A hash of the code is computed and checked at every training execution to prevent substitution attacks, and while this feature is not a definitive fail-safe measure against malicious users, it provides an additional layer of protection, as it empowers nodes and fosters researcher-node collaboration through shared responsibility. Furthermore, nodes are granted the right to override certain training parameters, regardless of the researcher's original request, for matters concerning security and resource usage.\n\n\nIntegration with biomedical data sources\n\nLike most FL frameworks, Fed-BioMed does not offer a direct connection with raw data sources such as hospital EHR, PACS, and other clinical IT systems. Instead, clinical data managers are requested to perform a one-time data preparation task to extract and wrangle the data. Contrary to other frameworks, Fed-BioMed tries to minimize this effort by implementing dedicated mechanisms and offering built-in integration with widely-used data standards, at the cost of losing some generality by restricting its focus on biomedical data.\n\nFed-BioMed introduces the notion of a DataLoadingPlan, meaning a set of customizations configured by the node which allow changing the way data is presented to the researcher. Built-in DataLoadingPlans are already integrated in Fed-BioMed's GUI, thus providing a mechanism for data harmonization that does not require extensive effort on the node side.\n\nFed-BioMed also provides a built-in suite of dataset classes that provide an interface to common standards. For example, our MedicalFolderDataset class is inspired by the BIDS standard 8 as well as PyTorch's ImageFolder. Furthermore, our generic TabularDataset class supports any standard that may be reduced to csv format. As part of our continuous development effort, we plan to significantly expand this suite to include several other healthcare interoperability standards, depending on the needs of our collaborators.\n\nHospitals participating in the same FL experiment may have different com-puting infrastructures. Fed-BioMed supports execution on containers, virtual machines, bare-metal CPUs and GPUs in the same experiment, allowing for the reconciliation of an heterogeneous computing infrastructure across nodes.\n\n\nResearcher interactivity\n\nThe researcher-facing side of Fed-BioMed is a Python SDK for configuring and managing FL experiments, preferably via jupyter notebooks. To create an experiment, researchers first instantiate a class called TrainingPlan containing the definition of the federated data and the training routine. The code written by data scientists in the TrainingPlan is designed to be as similar as possible to the serial local version of the training loop. This interface is intentionally generic to support a wide variety of use cases, from workflows allowing to compute federated summary statistics to general distributed optimization based for example on Stochastic Gradient Descent (SGD), Expectation Maximization (EM), and Variational Inference (VI). For convenience, we offer specialized TrainingPlans for specific optimization strategies such as SGD, and for the ML framework being used.\n\nOur approach promotes researcher interactivity via the Experiment class, which allows to easily set the participating nodes, the FL strategy, and includes the TrainingPlan itself. The Experiment is provided with a logging functionality and integration with tensorboard [38]. The modular design of the Fed-BioMed training loop allows researchers to dynamically adjust hyperparameters on the fly. Furthermore, a checkpointing system allows saving and loading the state of an experiment in persistent memory.\n\nIn a highly secure environment where training plans must be approved by each node, minor changes in a training plan may lead to insufferable delays for obtaining multiple approvals. Therefore, we make a distinction between the TrainingPlan source code and a set of training and model arguments. The former must be approved by the node, but it may leverage the latter as a way to dynamically configure details about the experiment that lie within the node's acceptable ranges. For example, a TrainingPlan may include a dropout layer but the dropout rate would be specified as a model argument, thus providing security guarantees to the node while allowing flexibility for the researcher.\n\n\nCybersecurity\n\nFed-BioMed 's current threat model assumes that nodes and server are honestbut-curious, nodes are independent actors and do not collude, and researchers may be malicious. This set of assumptions corresponds to our current application scenarios in hospital networks, where clients are trusted and strong protection is required with respect to researcher's manipulations. Thus, the first measure that we put in place is deploying the whole Fed-BioMed ecosystem inside a VPN, to effectively isolate the execution and protect it against external attacks. In the honest-but-curious model, an entity that gains access to the model weights may still attempt to re-identify individual samples through model inversion attacks. Fed-BioMed implements both differential privacy as well as secure aggregation based on additively homomorphic encryption [27,36], with currently some limitations concerning the supported ML frameworks and aggregation methods.\n\nFed-BioMed's architecture offers one final layer of protection, by insulating the researcher from the nodes through the existence of a middle component, the network, that brokers all communication between them. Furthermore, our TrainingPlan approval mechanism can also be viewed as a security feature, by allowing nodes to review any code intended to be executed within their systems.\n\nIn our short-term roadmap we plan to strengthen our security features by adopting a tighter threat model. The first measure that we intend to introduce is encrypted communication inside the VPN, preventing potentially malicious actors who have gained internal access from being able to listen-in on the communication exchanges. Secondly, we intend to introduce trusted digital certificates to improve our protection against impersonation attacks.\n\n\nStatus report\n\n\nCurrent state of the implementation and future plans\n\nFed-BioMed is a constantly evolving project, with an active group of core maintainers striving to issue monthly releases. The current maturity of our library has been acknowledged to allow a first real-world deployment and validation within a federation of some members from the UniCancer consortium, as described in Section 5.2, thus characterizing its Technology Readiness Level as TLR 5 9 . However, we strive to constantly improve several aspects of the implementation in future releases, following a development roadmap inspired by the design pillars described in this paper and actively driven by the needs of our growing community of users. Building on our functional description in Section 4.2, we provide in the Supplementary Information 8.2 a fine-grained description of the core library, interface and cybersecurity functionalities currently implemented in Fed-BioMed.\n\n\nDemonstration on real-world federated hospitals networks\n\nTo illustrate the capabilities of Fed-BioMed for real world applications of federated learning in hospitals networks, in this section we report the results obtained from the end-to-end deployment and training of a federated prostate segmentation model, based on the data hosted by three different medical institutes from the Unicancer consortium 10 .\n\nThe French hospitals involved are the Centre Henri Becquerel, Rouen, the Institut Curie, Orsay, and the Centre Antoine Lacassagne, Nice. Each hospital loaded into the Fed-BioMed client the respective dataset composed by prostate magnetic resonance images (MRIs), and associated prostate segmentation masks. The dataset considered for this test were the following:\n\n\u2022 Medical Segmentation Decathlon -Prostate [1], composed by 32 prostate MRIs for training, with respective masks of peripheral and transition zone, merged into a single mask for the whole prostate. This dataset was hosted at Institut Curie (CURIE).\n\n\u2022 Promise12 [32], consisting of 50 training cases obtained with different scanners. Of those, 27 cases were acquired without using an endorectal coil. This dataset was hosted at Centre Henri Becquerel (CHB).\n\n\u2022 ProstateX [2], containing prostate MRIs acquired by using two different scanners, providing prostate segmentation masks for 189 cases [11]. This dataset was hosted at Centre Antoine Lacassagne (CAL).\n\nEach of the three hospitals was assigned a single dataset from the ones listed above, which was subsequently loaded into the Fed-BioMed node client. At each site, the data was further divided in a training subset (90% of samples) and a holdout subset (10% of samples). The resulting federated learning setup reflects a realistic scenario presenting the typical data heterogeneity of multicentric medical imaging applications (see Figure 4a and Appendix 8.1 for more details). The use of publicly available data is in the scope of this experiment, and is aimed at demonstrating the FL task on a reproducible benchmark, allowing the comparison of the results with respect to the centralized scenario. Moreover, this setup facilitated the ethical approval of this experiment by each clinical center, avoiding the cumbersome process related to the use of hospital data.\n\n\nExperimental details\n\nWithin this setup, training hyperparameters were previously identified via a simulated FL scenario on the same data. The chosen aggregation method used was FedAvg [39], and the TrainingPlanApproval security feature was enabled. On the hospitals node side, the Fed-BioMed nodes were running on GPU-enabled machines, even though the existence of specific hardware is not a requirement for running Fed-BioMed. The central aggregator and the network component were hosted on a separate server provided by Inria. The training experiment consisted of 40 rounds with 25 local gradient updates each. Additional details are provided in the Supplementary Material 8.1.\n\n\nFL does not affect final model's performance\n\nAfter training, the model obtained a Dice score of 0.868. To assess the generalizability of this result, we performed a 5-fold cross-validation with similar 90-10 splits in both a centralized and a simulated federated setting. The crossvalidation Dice score for the simulated FL model was 0.854\u00b10.028, while for the centralized (CL) model it was 0.850 \u00b1 0.035. The difference in cross-validation scores between the simulated FL and CL models is not statistically significant (p = 0.63). Furthermore, the original model trained in the real-world setting has a realistic performance that falls within 0.5\u03c3 of the average of the simulated FL cross-validation scores. The distribution of Dice scores for all cross-validation folds combined, shown in Figure 4c, are qualitatively similar between the CL and FL models. The final segmentations are also visually indistinguishable, as shown in the bottom row of Figure 4d.\n\n\nFL runtime overhead\n\nEach round required on average just over 60 seconds of wallclock time for completion. Federated Learning was found to induce a significant overhead on training time, ranging from 39% to 56% of the overall experiment wallclock time, as shown in Figure 4b. This is in contrast with other studies that report negligible overhead [62,53], and can be explained by the smaller dataset sizes in our experiment, associated with a smaller number of samples used for training within each round. We believe that our experiment represents a realistic common scenario for most real-world hospital deployments where data may be scarce and high performance computing not applicable. Some Fed-BioMed implementation details, such as an hard-coded delay at round initialization, may also impact this measure and we are investigating whether useful runtime gains could be made through software improvements.\n\n\nLessons learned\n\nAnswering to the specific needs of biomedical research applications The field of biomedical research is characterized by specific needs that do not necessarily generalize to other fields of application of FL, such as tighter regulations for data protection, very large degrees of heterogeneity, and others identified in Section 2.1. FL frameworks, on the other hand, are often developed with a generic approach in mind, striving for generality in terms of application domains. While this approach ensures that such frameworks can be more widely used, this may lead to a sub-optimal experience for users who are interested only in a specific application domain. We believe that some communities, and in particular the biomedical research field, may greatly benefit from personalized framework development approaches able to cater to specific requirements such as providing the necessary governance tools, ensuring their usability by members of the application domain's community, and providing a software architecture tailored to the privacy or performance needs. phase where data are examined, data preprocessing pipelines are designed, the model architecture is refined, and finally hyperparameters are tuned. Most of the strategies for such operations usually involve some data manipulation and observation, for example it may be insightful to examine the data samples with the highest losses for a given model. In a federated setting, all of this is not possible because data are not allowed to travel outside of the source institution. This leads to a mismatch between who has the right to examine the datai.e. the clinical data sources -, and who has the knowledge to interpret iti.e. the data scientists -. Fed-BioMed is designed to operate in high-trust environments where the communication between these two entities is encouraged, therefore we may imagine a scenario where the data scientist instructs an operator on the clinical side to look at specific images and try to identify abnormal patterns. Furthermore, our modular TrainingPlan design can support advanced explainable techniques, while still guaranteeing node's data privacy through our TrainingPlan approval process. Despite these mitigation efforts, the issue of remotely debugging ML models in a privacy-preserving way remains a difficult problem to solve.\n\nData preparation prior to federated training Data in clinical databases are typically stored in proprietary formats that are not generally readily usable for ML analysis. However, all FL frameworks, including Fed-BioMed, make the assumption that the input data is provided in a format ready for ingestion by an ML model, or maybe a preprocessing pipeline. This gap has been, in our experience, a major source of frustration and delays, with the burden of data export and conversion falling usually on clinical data managers lacking the budget and training for such operations. Fed-BioMed tries to mitigate this by providing Dataset classes that can be populated with data that has been exported but not highly transformed, for example our MedicalFolderDataset class that can handle data in a simplified BIDS structure. In the future, we also plan to extend list of supported formats with some that are closer to the raw data exported by hospital IT systems, such as DICOM for imaging, OMOP or FHIR for clinical data, VCF files for genomics, and others. An ideal scenario would include a direct integration with the hospital PACS or EHR systems, however the proprietary nature of most of this software and the strict security rules unfortunately make this an unlikely scenario. Regardless of the feasibility, we believe that FL frameworks targeted at biomedical research applications must simplify the process of data preparation and be able to interoperate with standard data formats in their raw form, to ease the burden on clinical data managers and improve data reusability.\n\nData privacy and regulation for real-world deployment Contrary to controlled academic environments, real-world deployment scenarios are characterized by strict privacy and security measures. Some notable examples include: avoiding training if a client's dataset has too few samples, requiring secure aggregation and differential privacy measures, restricting the data flow in the net-work, and ensuring compliance with hospitals firewall policies. The integration in Fed-BioMed of such security measures to meet the requirements asked by Data Protection Officers of hospitals has been a long, iterative process consisting of multiple rounds of discussion needed to achieve a common understanding and a shared vocabulary. Ultimately, this dialectic process is what allowed us to carry out our first deployment in a collaborative clinical project.\n\n\nConclusion\n\nWe have presented version v4.1 of Fed-BioMed, a Python-based FL framework aimed at supporting real-world deployments for biomedical and healthcare research applications. This document focuses on Fed-BioMed's philosophy, guiding principles, and relevant details of the current architecture. Fed-BioMed is an open-source project available in our public repository 11 under an Apache license, and we welcome contributions from the community. We also provide extensive user documentation and tutorials, in addition to an API reference for developers 12 . The development of Fed-BioMed is an ongoing effort currently brought forward by a group of vetted collaborators coordinated by a small number of core developers. In the future, we plan to grow our community of users and developers, and integrate open-source contributions through a consortium. Our short-term implementation roadmap includes finalizing our implementation of Secure Aggregation, securing client-server communications, and improving even further the usability for clinical data providers. The domain of healthcare and clinical research is characterized by specific challenges and requirements that are difficult or impossible to satisfy with the currently available frameworks. We hope that Fed-BioMed will lower the threshold to apply FL in this domain, enabling clinical data scientists to perform experiments and train ML models within a federated consortium of data providers in a secure, practical, and privacy-preserving way.   \n\n\nTechnical implementation details\n\nBuilding on our functional description in Section 4.2, we provide here a more detailed explanation of Fed-BioMed's implementation details, as shown in Figure 2, trying to make a clear distinction between those that, as of today, have already reached a satisfactory level of maturity and those that are expected to improve in the near future, or may change at some point due to the dynamic nature of our project.\n\n\nCore library functionalities\n\nOn the node side we have implemented: a database of dataset metadata based on the TinyDB 13 package; a task manager based on persist-queue 14 ; a suite of Dataset classes to represent tabular, medical imaging (BIDS [22]), and other data formats; and a Round class handling all the logic for the execution of one federated training round. In the future, we plan to vastly extend our library of supported data formats to include other imaging formats such as e.g. DI-COM, add support for NLP formats, and integrate interoperability standards and data models such as i2b2 and OMOP [42,41,55]. Furthermore, we may consider moving to more complex database solutions if dataset management becomes too cumbersome, and similarly we may consider more advanced task management systems should the need arise among clinical data providers for better resource handling and improved performance. On the researcher side, an Experiment class represents the entry-point for the configuration and steering of a FL experiment, while the TrainingPlan class contains all the logic and code to be shipped to nodes for remote execution. The highly interactive design of the researcher-facing classes represents one of the highlights of Fed-BioMed, and in the future we plan to improve this feature by moving towards an ever more modular design with clearer separation of responsibilities, a hierarchical approach, and improved user documentation. Communication between the researcher and the nodes happens through an intermediate component called the Network. This component is based on two technologies: MQTT for the brokering of short messages (e.g. train, search datasets, and others) [3], and an HTTP API based on Django REST 15 for exchanging larger files such as model parameters. MQTT was chosen because of its natural mapping to a star topology and good support of broadcast operations, which we use for discovering datasets and clients. However, in the future we plan to evaluate other approaches, more commonly used in the literature, such as relying on gRPC or other remote execution protocols. In the current implementation, nodes are pure slaves that execute commands issued by the researcher. In the future, we plan to evaluate endowing nodes with a more active role, for example inverting the direction of communication such that the nodes would request tasks instead of passively receiving them, which would entail se-curity benefits (reduced attack surface on the nodes), while shifting some of the complexity from the node implementation to the network component.\n\n\nUser interfaces\n\nIn terms of user interfaces, on the node side we have implemented both a Command Line Interface (CLI) and a Graphical User Interface (GUI). Our GUI implementation is composed of a web client based on React, and a Flask backend server that manages the interactions with the Fed-BioMed library, in particular with the dataset database. This simplifies the process of managing datasets (CRUD operations [37]), training plan approval by data science experts on the node side, and has the general goal of facilitating governance operations on data and models. Currently, the GUI is limited to executing on the same machine as the node process, but in the future we plan to decouple the two through a micro-services approach, as well as improve the RBAC with better security and account management. Another feature that we plan to implement in the future is adding experiment monitoring functionalities for the node, as well as allowing basic experiment steering functionalities such as stopping an experiment through the GUI. The researcher's interface is a Python SDK, mainly designed to be executed by interpreter such as Jython and within notebooks. The researcher may monitor the training via Tensorboard, which plots common metrics such as training loss as well as custom ones defined via a plugin system. Defining the best interface for the researcher in terms of tradeoff between interactivity, security, and simplicity is one of our main goals, and we constantly strive to improve the API for the Experiment and TrainingPlan classes.\n\n\nCybersecurity and model security\n\nCybersecurity is one of the main design pillars of Fed-BioMed. As described above, we have implemented a VPN deployment mode based on the Wireguard framework to isolate the execution of Fed-BioMed from external parties [16]. The VPN deployment mode is shipped with the software, and designed to be easily configurable and deployable. One of our short-term goals is to implement TLS-encrypted communication within the VPN, by exploring suitable MQTT and Django-REST extensions. To protect nodes from the execution of arbitrary code, a training plan approval mode can be enabled. This process is handled by the GUI on the Node side, making it easy and immediate for clinical data providers to conduct their reviews. In this configuration, when a researcher sends a train request to the node, the hash of the training plan is compared to the hashes of a set of training plans that have been previously reviewed and approved by the node, and is executed only in the case of a match. Differential Privacy can also be enabled in Fed-BioMed, when using PyTorch as the training backend, by leveraging the Opacus library and Tensorflow's accountant 16 . Secure aggregation is being implemented based on additively homomor-phic encryption [27,36], with the computation of keys based on a multi-party computation (MPC) approach inspired by the MP-SPDZ benchmark suite [28].\n\nFigure 1 :\n1Workflow of an FL experiment from the point of view of a clinical data provider. The shaded area represents Fed-BioMed's design space in terms of functionalities and targeted usage.\n\nFigure 3 :\n3Prototypical FL training workflow in Fed-BioMed. Icons indicate the steps where the design was influenced by a particular requirement.\n\nFigure 4 :\n4Model development and debugging in a federated setting The development of a new ML model almost always requires an initial exploratory a) Pixel intensity distribution grouped by clinical site. Prostate images exhibit significant differences between sites, especially in the case of Site 2. b) Breakdown of FL experiment wallclock runtime. FL introduces a significant overhead in our case, likely attributable to the relatively small number of samples seen by the model in each FL round. c) Distribution of Dice scores for centralized (CL) and federated (FL) models, combining all cross-validation folds. The performance of the two models has a statistically significant difference, but with a small effect size. The figure shows boxplots inside the violin plots. The top bottom of each boxplot depict the 3rd and 1st quartile of each measure. The white line and the red x indicate the median and mean values, respectively. The whiskers depict the extremal observations still within 1.5 times the interquartile range. d) Clockwise from top left: an example raw image, the ground truth segmentation, the FL model prediction and the CL model prediction.\n\nTable 3 :\n3Distribution of data among clinical sites during the FL experiment, including the number of samples in each cross-validation fold.Data \n\nTransformation Center cropping and padding \nCommon shape 320, 320, 16 \nTransformation Intensity normalization \n\nUNet \n\nchannels \n16, 32, 64, 128, 256 \nstrides \n2, 2, 2, 2 \nresidual units \n3 \nnormalization \nBatch normalization \ndropout \n0.3 \n\nLocal \n\nOptimizer \nSGD \nLearning rate \n0.1 \nMomentum \n0.9 \nBatch size \n8 \nLocal updates \n25 \nLoss \nDice loss \n\nFederated \nAggregation \nFedAVG \nRounds \n40 \n\n\n\nTable 4 :\n4FL experimental setup details.\nhttps://genomed4all.eu/ 2 https://www.melloddy.eu/ 3 https://www.harmony-alliance.eu/\nhttps://flower.dev/conf/flower-summit-2022/\nhttps://bids.neuroimaging.io/\nhttps://ec.europa.eu/research/participants/data/ref/h2020/wp/2014_2015/ annexes/h2020-wp1415-annex-g-trl_en.pdf 10 https://www.unicancer.fr/en/\nSupplementary Information8.1 Real-world use case scenario: prostate segmentation Data were gathered following the process described in[25] from three public datasets[1,32,2]. Each clinical site received data corresponding to a single source, to reflect the more realistic scenario of high heterogeneity of data among clinical sites. Details of the data distribution are given inTable 3, while details of the experiment setup are given inTable 4. We used Fed-BioMed v4.1.2 relied on MONAI's (v1.0.1) implementation of UNet[29] and data transformations, and on Pytorch's SGD implementation, for definition of the model and optimizer in each site's local training. 11 https://gitlab.inria.fr/fedbiomed/fedbiomed 12 https://fedbiomed.gitlabpages.inria.fr/v4.1/getting-started/ what-is-fedbiomed/\nhttps://pypi.org/project/tinydb/ 14 https://github.com/peter-wangxu/persist-queue 15 https://www.django-rest-framework.org/\nhttps://raw.githubusercontent.com/tensorflow/privacy/ 7eea74a6a1cf15e2d2bd890722400edd0e470db8/research/hyperparameters_2022/rdp_\n\nThe medical segmentation decathlon. Michela Antonelli, Nature communications. 134128Michela Antonelli et al. \"The medical segmentation decathlon\". In: Nature communications 13.1 (2022), p. 4128.\n\nPROSTATEx Challenges for computerized classification of prostate lesions from multiparametric magnetic resonance images. Samuel G Armato, Iii, Journal of Medical Imaging. 5Samuel G Armato III et al. \"PROSTATEx Challenges for computerized classification of prostate lesions from multiparametric magnetic resonance images\". In: Journal of Medical Imaging 5.4 (2018), pp. 044501-044501.\n\nMQTT Version 5.0. Tech. rep. Andrew Banks, Andrew Banks et al. MQTT Version 5.0. Tech. rep. 2019.\n\nFlower: A friendly federated learning research framework. J Daniel, Beutel, arXiv:2007.14390arXiv preprintDaniel J Beutel et al. \"Flower: A friendly federated learning research framework\". In: arXiv preprint arXiv:2007.14390 (2020).\n\nTowards federated learning at scale: System design. Keith Bonawitz, Proceedings of Machine Learning and Systems. Machine Learning and Systems1Keith Bonawitz et al. \"Towards federated learning at scale: System de- sign\". In: Proceedings of Machine Learning and Systems 1 (2019), pp. 374- 388.\n\nVulnerabilities in federated learning. Nader Bouacida, Prasant Mohapatra, IEEE Access. 9Nader Bouacida and Prasant Mohapatra. \"Vulnerabilities in federated learning\". In: IEEE Access 9 (2021), pp. 63229-63249.\n\nThe Cancer Imaging Archive (TCIA): maintaining and operating a public information repository. Kenneth Clark, Journal of digital imaging. 26Kenneth Clark et al. \"The Cancer Imaging Archive (TCIA): maintain- ing and operating a public information repository\". In: Journal of digital imaging 26.6 (2013), pp. 1045-1057.\n\n. Mellody consortium. Mellody. Tech. rep. Accessed on. Mellody consortium. Mellody. Tech. rep. Accessed on 28th November 2022. 2019. url: https://www.melloddy.eu/.\n\nA systematic review of federated learning applications for biomedical data. Matthew G Crowson, PLOS Digital Health. 133Matthew G Crowson et al. \"A systematic review of federated learning applications for biomedical data\". In: PLOS Digital Health 1.5 (2022), e0000033.\n\nThe French Health Data Hub and the German Medical Informatics Initiatives: two national projects to promote data sharing in healthcare. Marc Cuggia, St\u00e9phanie Combes, Yearbook of medical informatics. 28Marc Cuggia and St\u00e9phanie Combes. \"The French Health Data Hub and the German Medical Informatics Initiatives: two national projects to pro- mote data sharing in healthcare\". In: Yearbook of medical informatics 28.01 (2019), pp. 195-202.\n\nQuality control and whole-gland, zonal and lesion annotations for the PROSTATEx challenge public dataset. Renato Cuocolo, European Journal of Radiology. 138109647Renato Cuocolo et al. \"Quality control and whole-gland, zonal and lesion annotations for the PROSTATEx challenge public dataset\". In: European Journal of Radiology 138 (2021), p. 109647.\n\nICT Security Certification Opportunities in the Healthcare Sector. European Union Agency for Cybersecurity (ENISA)European Union Agency for Cybersecurity (ENISA). ICT Security Certi- fication Opportunities in the Healthcare Sector. 2018.\n\nFederated Learning in Medical Imaging: Part I: Toward Multicentral Health Care Ecosystems. Erfan Darzidehkalani, Mohammad Ghasemi-Rad, Pma Van Ooijen, Journal of the American College of Radiology. Erfan Darzidehkalani, Mohammad Ghasemi-Rad, and Pma van Ooijen. \"Federated Learning in Medical Imaging: Part I: Toward Multicentral Health Care Ecosystems\". In: Journal of the American College of Ra- diology (2022).\n\nFederated learning for predicting clinical outcomes in patients with COVID-19. Ittai Dayan, Nature medicine. 27Ittai Dayan et al. \"Federated learning for predicting clinical outcomes in patients with COVID-19\". In: Nature medicine 27.10 (2021), pp. 1735- 1743.\n\nDistributed learning on 20 000+ lung cancer patients -The Personal Health Train\". en. M Timo, Deist, 10.1016/j.radonc.2019.11.019Radiotherapy and Oncology. 144Timo M. Deist et al. \"Distributed learning on 20 000+ lung cancer patients -The Personal Health Train\". en. In: Radiotherapy and Oncology 144 (2020), pp. 189-200. doi: 10.1016/j.radonc.2019.11.019. url: https: //linkinghub.elsevier.com/retrieve/pii/S0167814019334899.\n\nWireguard: next generation kernel network tunnel. A Jason, Donenfeld, Jason A Donenfeld. \"Wireguard: next generation kernel network tunnel\". In: NDSS. 2017, pp. 1-12.\n\nOpenFL: the open federated learning library. Patrick Foley, http:/iopscience.iop.org/article/10.1088/1361-6560/ac97d9Physics in Medicine & Biology. Patrick Foley et al. \"OpenFL: the open federated learning library\". In: Physics in Medicine & Biology (2022). doi: 10.1088/1361-6560/ac97d9. url: http : / / iopscience . iop . org / article / 10 . 1088 / 1361 -6560 / ac97d9.\n\nCloud Native Computing Foundation. high performance, open-source universal RPC framework. Cloud Native Computing Foundation. high performance, open-source uni- versal RPC framework. Accessed on 16 December 2022. 2018. url: %5Curl% 7Bhttps://grpc.io/%7D.\n\nTruly privacy-preserving federated analytics for precision medicine with multiparty homomorphic encryption\". en. David Froelicher, 10.1038/s41467-021-25972-yNature Communications. 1215910David Froelicher et al. \"Truly privacy-preserving federated analytics for precision medicine with multiparty homomorphic encryption\". en. In: Na- ture Communications 12.1 (Oct. 2021), p. 5910. doi: 10.1038/s41467- 021-25972-y. url: https://www.nature.com/articles/s41467-021- 25972-y.\n\nSubstra: a framework for privacypreserving, traceable and collaborative machine learning. N Mathieu, Camille Galtier, Marini, arXiv:1910.11567arXiv preprintMathieu N Galtier and Camille Marini. \"Substra: a framework for privacy- preserving, traceable and collaborative machine learning\". In: arXiv preprint arXiv:1910.11567 (2019).\n\nA Review of Challenges and Opportunities in Machine Learning for Health. Marzyeh Ghassemi, AMIA Summits on Translational Science Proceedings. 2020Marzyeh Ghassemi et al. \"A Review of Challenges and Opportunities in Machine Learning for Health\". In: AMIA Summits on Translational Sci- ence Proceedings 2020 (May 2020), pp. 191-200. url: https : / / www . ncbi.nlm.nih.gov/pmc/articles/PMC7233077/.\n\nThe brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. J Krzysztof, Gorgolewski, Scientific data. 3Krzysztof J Gorgolewski et al. \"The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments\". In: Scientific data 3.1 (2016), pp. 1-9.\n\nFedml: A research library and benchmark for federated machine learning. Chaoyang He, arXiv:2007.13518arXiv preprintChaoyang He et al. \"Fedml: A research library and benchmark for feder- ated machine learning\". In: arXiv preprint arXiv:2007.13518 (2020).\n\nFrom big data to precision medicine. Tim Hulsen, Frontiers in medicine. 34Tim Hulsen et al. \"From big data to precision medicine\". In: Frontiers in medicine (2019), p. 34.\n\nLucia , Consensus-Based Methods as a Cost-Effective Alternative to Federated Learning: Benchmark on Prostate MRI Segmentation\". In: (2023). under review. Lucia et al. Innocenti. \"Consensus-Based Methods as a Cost-Effective Al- ternative to Federated Learning: Benchmark on Prostate MRI Segmenta- tion\". In: (2023). under review.\n\nThe Alzheimer's disease neuroimaging initiative (ADNI): MRI methods. Clifford R Jack Jr, Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine. 27Clifford R Jack Jr et al. \"The Alzheimer's disease neuroimaging initiative (ADNI): MRI methods\". In: Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine 27.4 (2008), pp. 685-691.\n\nA scalable scheme for privacy-preserving aggregation of time-series data. Marc Joye, Beno\u00eet Libert, International Conference on Financial Cryptography and Data Security. SpringerMarc Joye and Beno\u00eet Libert. \"A scalable scheme for privacy-preserving aggregation of time-series data\". In: International Conference on Finan- cial Cryptography and Data Security. Springer. 2013, pp. 111-125.\n\nMP-SPDZ: A Versatile Framework for Multi-Party Computation. Marcel Keller, 10.1145/3372297.3417872Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security. 2020. the 2020 ACM SIGSAC Conference on Computer and Communications Security. 2020Marcel Keller. \"MP-SPDZ: A Versatile Framework for Multi-Party Com- putation\". In: Proceedings of the 2020 ACM SIGSAC Conference on Com- puter and Communications Security. 2020. doi: 10.1145/3372297.3417872. url: https://doi.org/10.1145/3372297.3417872.\n\nLeft-ventricle quantification using residual U-Net. Eric Kerfoot, Statistical Atlases and Computational Models of the Heart. Atrial Segmentation and LV Quantification Challenges: 9th International Workshop, STACOM 2018, Held in Conjunction with MICCAI 2018. Granada, SpainSpringerRevised Selected Papers 9Eric Kerfoot et al. \"Left-ventricle quantification using residual U-Net\". In: Statistical Atlases and Computational Models of the Heart. Atrial Seg- mentation and LV Quantification Challenges: 9th International Workshop, STACOM 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Revised Selected Papers 9. Springer. 2019, pp. 371- 380.\n\nMultimodal machine learning in precision health: A scoping review. Adrienne Kline, In: npj Digital Medicine. 5Adrienne Kline et al. \"Multimodal machine learning in precision health: A scoping review\". In: npj Digital Medicine 5.1 (2022), pp. 1-14.\n\nA Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection. Qinbin Li, 10.1109/TKDE.2021.3124599IEEE Transactions on Knowledge and Data Engineering. Qinbin Li et al. \"A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection\". In: IEEE Transactions on Knowledge and Data Engineering (2021), pp. 1-1. doi: 10.1109/TKDE. 2021.3124599.\n\nEvaluation of prostate segmentation algorithms for MRI: the PROMISE12 challenge. Geert Litjens, Medical image analysis. 18Geert Litjens et al. \"Evaluation of prostate segmentation algorithms for MRI: the PROMISE12 challenge\". In: Medical image analysis 18.2 (2014), pp. 359-373.\n\nFATE: An Industrial Grade Platform for Collaborative Learning With Data Protection. Yang Liu, In: J. Mach. Learn. Res. 22Yang Liu et al. \"FATE: An Industrial Grade Platform for Collaborative Learning With Data Protection.\" In: J. Mach. Learn. Res. 22.226 (2021), pp. 1-6.\n\nIbm federated learning: an enterprise framework white paper v0. 1. Heiko Ludwig, arXiv:2007.10987arXiv preprintHeiko Ludwig et al. \"Ibm federated learning: an enterprise framework white paper v0. 1\". In: arXiv preprint arXiv:2007.10987 (2020).\n\nPaddlePaddle: An open-source deep learning platform from industrial practice. Yanjun Ma, Frontiers of Data and Domputing. 11Yanjun Ma et al. \"PaddlePaddle: An open-source deep learning platform from industrial practice\". In: Frontiers of Data and Domputing 1.1 (2019), pp. 105-115.\n\nThis is the author&#039;s version of the work. It is posted here by permission of ACM for your personal use. Not for redistribution. The definitive version was published in ACSAC 2022. Mohamad Mansouri, Melek\u00f6nen , Wafa Ben Jaballah, 10.1145/3564625.3568135.AustinACSAC 2022. ACM. \u00a9 ACMAustin, Texas, USA; Austin, Texas, USAAnnual Computer Security Applications ConferenceMohamad Mansouri, Melek\u00d6nen, and Wafa Ben Jaballah. \"Learning from failures: Secure and fault-tolerant aggregation for federated learn- ing\". In: ACSAC 2022, Annual Computer Security Applications Confer- ence, 5-9 December 2022, Austin, Texas, USA. Ed. by ACM. \u00a9 ACM, 2022. This is the author&#039;s version of the work. It is posted here by permission of ACM for your personal use. Not for redistribution. The definitive version was published in ACSAC 2022, Annual Computer Se- curity Applications Conference, 5-9 December 2022, Austin, Texas, USA https://doi.org/10.1145/3564625.3568135. Austin, 2022.\n\nManaging the data base environment. James Martin, Prentice Hall PTRJames Martin. Managing the data base environment. Prentice Hall PTR, 1983.\n\nTensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. Mart\u00edn Abadi, Software available from tensorflow.org. Mart\u00edn Abadi et al. \"TensorFlow: Large-Scale Machine Learning on Het- erogeneous Systems\". In: (2015). Software available from tensorflow.org. url: https://www.tensorflow.org/.\n\nCommunication-efficient learning of deep networks from decentralized data. H Mcmahan, PMLRArtificial intelligence and statistics. H McMahan et al. \"Communication-efficient learning of deep networks from decentralized data. arXiv e-prints\". In: Artificial intelligence and statistics. PMLR. (2017).\n\nThe multimodal brain tumor image segmentation benchmark (BRATS). H Bjoern, Menze, IEEE transactions on medical imaging. 34Bjoern H Menze et al. \"The multimodal brain tumor image segmentation benchmark (BRATS)\". In: IEEE transactions on medical imaging 34.10 (2014), pp. 1993-2024.\n\nServing the enterprise and beyond with informatics for integrating biology and the bedside (i2b2). N Shawn, Murphy, Journal of the American Medical Informatics Association. 17Shawn N Murphy et al. \"Serving the enterprise and beyond with infor- matics for integrating biology and the bedside (i2b2)\". In: Journal of the American Medical Informatics Association 17.2 (2010), pp. 124-130.\n\nOverview of the DI-COM standard. Mario Mustra, Kresimir Delac, Mislav Grgic, 50th International Symposium ELMAR. IEEE1Mario Mustra, Kresimir Delac, and Mislav Grgic. \"Overview of the DI- COM standard\". In: 2008 50th International Symposium ELMAR. Vol. 1. IEEE. 2008, pp. 39-44.\n\nFederated learning for predicting histological response to neoadjuvant chemotherapy in triple-negative breast cancer. Jean Ogier, Nature Medicine (2023). Jean Ogier du Terrail et al. \"Federated learning for predicting histological response to neoadjuvant chemotherapy in triple-negative breast cancer\". In: Nature Medicine (2023), pp. 1-12.\n\n. Roseline Oluwaseun Ogundokun, 10.3390/info13050263doi: 10 . 3390 / info13050263A Review on Federated Learning and Machine Learning Approaches: Categorization, Application Areas, and Blockchain Technology\". en. In: Information. 135263Roseline Oluwaseun Ogundokun et al. \"A Review on Federated Learning and Machine Learning Approaches: Categorization, Application Areas, and Blockchain Technology\". en. In: Information 13.5 (May 2022), p. 263. doi: 10 . 3390 / info13050263. url: https : / / www . mdpi . com / 2078 - 2489/13/5/263.\n\n. Owkin. Healthchain. Tech. rep. Accessed on. Owkin. Healthchain. Tech. rep. Accessed on 28th November 2022. 2019. url: https://www.labelia.org/fr/healthchain-project.\n\n. Owkin. Substrafl overview. Tech. rep. Accessed on. Revision b152eecf. 2022. urlOwkin. Substrafl overview. Tech. rep. Accessed on: 28th November 2022, Revision b152eecf. 2022. url: https://docs.substra.org/en/stable/ substrafl_doc/substrafl_overview.html#.\n\nFederated Learning Enables Big Data for Rare Cancer Boundary Detection. Sarthak Pati, Nature Communication. Sarthak Pati et al. \"Federated Learning Enables Big Data for Rare Cancer Boundary Detection\". In: Nature Communication (2022).\n\nThe future of digital health with federated learning. Nicola Rieke, NPJ digital medicine. 31Nicola Rieke et al. \"The future of digital health with federated learning\". In: NPJ digital medicine 3.1 (2020), pp. 1-7.\n\nFederated learning for breast density classification: A real-world implementation. R Holger, Roth, Domain adaptation and representation transfer, and distributed and collaborative learning. SpringerHolger R Roth et al. \"Federated learning for breast density classifica- tion: A real-world implementation\". In: Domain adaptation and represen- tation transfer, and distributed and collaborative learning. Springer, 2020, pp. 181-191.\n\nFLARE: Federated Learning from Simulation to Real-World. R Holger, Roth, Workshop on Federated Learning: Recent Advances and New Challenges. in Conjunction with NeurIPS 2022Holger R Roth et al. \"FLARE: Federated Learning from Simulation to Real-World\". In: Workshop on Federated Learning: Recent Advances and New Challenges (in Conjunction with NeurIPS 2022).\n\nA generic framework for privacy preserving deep learning. Theo Ryffel, arXiv:1811.04017arXiv preprintTheo Ryffel et al. \"A generic framework for privacy preserving deep learn- ing\". In: arXiv preprint arXiv:1811.04017 (2018).\n\nPrivacy-first health research with federated learning. Adam Sadilek, NPJ digital medicine. 4Adam Sadilek et al. \"Privacy-first health research with federated learn- ing\". In: NPJ digital medicine 4.1 (2021), pp. 1-8.\n\nSwarm learning for decentralized artificial intelligence in cancer histopathology\". en. Oliver Lester Saldanha, 10.1038/s41591-022-01768-5Nature Medicine. 286Oliver Lester Saldanha et al. \"Swarm learning for decentralized artificial intelligence in cancer histopathology\". en. In: Nature Medicine 28.6 (June 2022), pp. 1232-1239. doi: 10.1038/s41591-022-01768-5. url: https: //www.nature.com/articles/s41591-022-01768-5.\n\nFederated learning improves site performance in multicenter deep learning without data sharing. V Karthik, Sarma, Journal of the American Medical Informatics Association. 28Karthik V Sarma et al. \"Federated learning improves site performance in multicenter deep learning without data sharing\". In: Journal of the American Medical Informatics Association 28.6 (2021), pp. 1259-1264.\n\nObservational Health Data Sciences and Informatics. The Book of OHDSI. Independently published. \\url{10.5281/zenodo.4265255}Observational Health Data Sciences and Informatics. The Book of OHDSI. Independently published, 2019. doi: \\url{https://doi.org/10.5281/ zenodo.4265255}.\n\nApplications of federated learning. Momina Shaheen, Momina Shaheen et al. \"Applications of federated learning;\n\n. Challenges Taxonomy, Research Trends, 670In: Electronics 11.4 (2022Taxonomy, challenges, and research trends\". In: Electronics 11.4 (2022), p. 670.\n\nA systematic review of federated learning in the healthcare area: From the perspective of data properties and applications. Chi-Ren Shyu, In: Applied Sciences. 112311191Chi-Ren Shyu et al. \"A systematic review of federated learning in the healthcare area: From the perspective of data properties and applications\". In: Applied Sciences 11.23 (2021), p. 11191.\n\nThe human connectome: a structural description of the human brain. Olaf Sporns, Giulio Tononi, Rolf K\u00f6tter, PLoS computational biology. 142Olaf Sporns, Giulio Tononi, and Rolf K\u00f6tter. \"The human connectome: a structural description of the human brain\". In: PLoS computational biology 1.4 (2005), e42.\n\nUK biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age. Cathie Sudlow, PLoS medicine. 121001779Cathie Sudlow et al. \"UK biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age\". In: PLoS medicine 12.3 (2015), e1001779.\n\nThe cancer genome atlas (tcga): an immeasurable source of knowledge. K Tomczak, P Czerwi\u0144ska, M Wiznerowicz, Contemporary Oncology. 19K. Tomczak, P. Czerwi\u0144ska, and M. Wiznerowicz. \"The cancer genome atlas (tcga): an immeasurable source of knowledge.\" In: Contemporary Oncology 19 (2015).\n\nHigh-performance medicine: the convergence of human and artificial intelligence. J Eric, Topol, Nature medicine. 25Eric J Topol. \"High-performance medicine: the convergence of human and artificial intelligence\". In: Nature medicine 25.1 (2019), pp. 44-56.\n\nEncrypted federated learning for secure decentralized collaboration in cancer image analysis\". en. Daniel Truhn, https:/www.medrxiv.org/content/10.1101/2022.07.28.22277288v1doi: 10.1101/ 2022.07.28.22277288Daniel Truhn et al. \"Encrypted federated learning for secure decentralized collaboration in cancer image analysis\". en. In: (July 2022). doi: 10.1101/ 2022.07.28.22277288. url: https://www.medrxiv.org/content/10. 1101/2022.07.28.22277288v1.\n\nA systematic review of barriers to data sharing in public health. Willem G Van Panhuis, BMC public health. 14Willem G Van Panhuis et al. \"A systematic review of barriers to data sharing in public health\". In: BMC public health 14.1 (2014), pp. 1-9.\n", "annotations": {"author": "[{\"end\":199,\"start\":103},{\"end\":275,\"start\":200},{\"end\":354,\"start\":276},{\"end\":437,\"start\":355},{\"end\":528,\"start\":438},{\"end\":621,\"start\":529},{\"end\":713,\"start\":622},{\"end\":807,\"start\":714},{\"end\":901,\"start\":808},{\"end\":940,\"start\":902},{\"end\":978,\"start\":941},{\"end\":1141,\"start\":979},{\"end\":1309,\"start\":1142},{\"end\":1387,\"start\":1310},{\"end\":1466,\"start\":1388},{\"end\":1550,\"start\":1467},{\"end\":1602,\"start\":1551},{\"end\":1630,\"start\":1603},{\"end\":1721,\"start\":1631}]", "publisher": null, "author_last_name": "[{\"end\":122,\"start\":113},{\"end\":210,\"start\":205},{\"end\":289,\"start\":283},{\"end\":372,\"start\":363},{\"end\":451,\"start\":444},{\"end\":544,\"start\":535},{\"end\":636,\"start\":631},{\"end\":730,\"start\":726},{\"end\":824,\"start\":817},{\"end\":916,\"start\":910},{\"end\":954,\"start\":949},{\"end\":991,\"start\":985},{\"end\":1159,\"start\":1153},{\"end\":1322,\"start\":1317},{\"end\":1401,\"start\":1396},{\"end\":1485,\"start\":1474},{\"end\":1566,\"start\":1559},{\"end\":1613,\"start\":1609},{\"end\":1644,\"start\":1637}]", "author_first_name": "[{\"end\":112,\"start\":103},{\"end\":204,\"start\":200},{\"end\":282,\"start\":276},{\"end\":362,\"start\":355},{\"end\":443,\"start\":438},{\"end\":534,\"start\":529},{\"end\":630,\"start\":622},{\"end\":725,\"start\":714},{\"end\":816,\"start\":808},{\"end\":909,\"start\":902},{\"end\":948,\"start\":941},{\"end\":984,\"start\":979},{\"end\":1152,\"start\":1142},{\"end\":1316,\"start\":1310},{\"end\":1395,\"start\":1388},{\"end\":1473,\"start\":1467},{\"end\":1558,\"start\":1551},{\"end\":1608,\"start\":1603},{\"end\":1636,\"start\":1631}]", "author_affiliation": "[{\"end\":198,\"start\":124},{\"end\":274,\"start\":212},{\"end\":353,\"start\":291},{\"end\":436,\"start\":374},{\"end\":527,\"start\":453},{\"end\":620,\"start\":546},{\"end\":712,\"start\":638},{\"end\":806,\"start\":732},{\"end\":900,\"start\":826},{\"end\":939,\"start\":918},{\"end\":977,\"start\":956},{\"end\":1140,\"start\":993},{\"end\":1308,\"start\":1161},{\"end\":1386,\"start\":1324},{\"end\":1465,\"start\":1403},{\"end\":1549,\"start\":1487},{\"end\":1601,\"start\":1568},{\"end\":1629,\"start\":1615},{\"end\":1720,\"start\":1646}]", "title": "[{\"end\":100,\"start\":1},{\"end\":1821,\"start\":1722}]", "venue": null, "abstract": "[{\"end\":2929,\"start\":1823}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3202,\"start\":3198},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":3223,\"start\":3219},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3241,\"start\":3237},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":3255,\"start\":3251},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":3276,\"start\":3272},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3279,\"start\":3276},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3281,\"start\":3279},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":3451,\"start\":3447},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":4079,\"start\":4075},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":4345,\"start\":4341},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4347,\"start\":4345},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4350,\"start\":4347},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4435,\"start\":4431},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":4438,\"start\":4435},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4674,\"start\":4670},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":4677,\"start\":4674},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4680,\"start\":4677},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8063,\"start\":8062},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":8170,\"start\":8166},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":8173,\"start\":8170},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8848,\"start\":8844},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":8851,\"start\":8848},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9056,\"start\":9052},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9156,\"start\":9152},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9307,\"start\":9303},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9455,\"start\":9451},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10396,\"start\":10392},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10532,\"start\":10529},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":10535,\"start\":10532},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10768,\"start\":10764},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":14278,\"start\":14274},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":14281,\"start\":14278},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":14284,\"start\":14281},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14503,\"start\":14500},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14515,\"start\":14511},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14528,\"start\":14524},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14539,\"start\":14535},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":14554,\"start\":14550},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":14571,\"start\":14567},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":14627,\"start\":14623},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14640,\"start\":14636},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":14652,\"start\":14648},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14668,\"start\":14665},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":15003,\"start\":14999},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15006,\"start\":15003},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15122,\"start\":15119},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":15222,\"start\":15218},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":15225,\"start\":15222},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":17179,\"start\":17175},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":17628,\"start\":17624},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":19557,\"start\":19553},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":19703,\"start\":19699},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":19825,\"start\":19821},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":19828,\"start\":19825},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21953,\"start\":21950},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22684,\"start\":22680},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":36239,\"start\":36235},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":38020,\"start\":38016},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":38023,\"start\":38020},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":40730,\"start\":40727},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":40746,\"start\":40744},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":40950,\"start\":40946},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":41158,\"start\":41155},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41283,\"start\":41279},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":42403,\"start\":42399},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":44211,\"start\":44207},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":44214,\"start\":44211},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":51758,\"start\":51754},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":52121,\"start\":52117},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":52124,\"start\":52121},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":52127,\"start\":52124},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":53207,\"start\":53204},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":54521,\"start\":54517},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":55913,\"start\":55909},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":56832,\"start\":56830},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":56923,\"start\":56919},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":56926,\"start\":56923},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":57051,\"start\":57047},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":59593,\"start\":59589},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":59623,\"start\":59620},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":59626,\"start\":59623},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":59628,\"start\":59626},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":59980,\"start\":59976}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":57247,\"start\":57053},{\"attributes\":{\"id\":\"fig_1\"},\"end\":57395,\"start\":57248},{\"attributes\":{\"id\":\"fig_2\"},\"end\":58559,\"start\":57396},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":59107,\"start\":58560},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":59150,\"start\":59108}]", "paragraph": "[{\"end\":3452,\"start\":2945},{\"end\":4681,\"start\":3454},{\"end\":5577,\"start\":4683},{\"end\":6278,\"start\":5579},{\"end\":6795,\"start\":6295},{\"end\":7568,\"start\":6797},{\"end\":9648,\"start\":7651},{\"end\":10180,\"start\":9650},{\"end\":10769,\"start\":10182},{\"end\":11083,\"start\":10794},{\"end\":11746,\"start\":11113},{\"end\":12046,\"start\":11791},{\"end\":12414,\"start\":12075},{\"end\":12961,\"start\":12427},{\"end\":13127,\"start\":12998},{\"end\":13316,\"start\":13129},{\"end\":13457,\"start\":13318},{\"end\":13785,\"start\":13459},{\"end\":14094,\"start\":13787},{\"end\":17038,\"start\":14134},{\"end\":17492,\"start\":17040},{\"end\":19491,\"start\":17494},{\"end\":21905,\"start\":19493},{\"end\":22824,\"start\":21907},{\"end\":23622,\"start\":22875},{\"end\":25363,\"start\":23624},{\"end\":25919,\"start\":25365},{\"end\":26505,\"start\":25921},{\"end\":26938,\"start\":26507},{\"end\":27701,\"start\":26940},{\"end\":28349,\"start\":27740},{\"end\":29730,\"start\":28351},{\"end\":30139,\"start\":29732},{\"end\":30744,\"start\":30141},{\"end\":31775,\"start\":30769},{\"end\":32427,\"start\":31777},{\"end\":33303,\"start\":32429},{\"end\":33880,\"start\":33348},{\"end\":34234,\"start\":33882},{\"end\":34757,\"start\":34236},{\"end\":35058,\"start\":34759},{\"end\":35964,\"start\":35087},{\"end\":36471,\"start\":35966},{\"end\":37159,\"start\":36473},{\"end\":38120,\"start\":37177},{\"end\":38506,\"start\":38122},{\"end\":38954,\"start\":38508},{\"end\":39906,\"start\":39027},{\"end\":40317,\"start\":39967},{\"end\":40682,\"start\":40319},{\"end\":40932,\"start\":40684},{\"end\":41141,\"start\":40934},{\"end\":41344,\"start\":41143},{\"end\":42211,\"start\":41346},{\"end\":42894,\"start\":42236},{\"end\":43857,\"start\":42943},{\"end\":44769,\"start\":43881},{\"end\":47118,\"start\":44789},{\"end\":48697,\"start\":47120},{\"end\":49544,\"start\":48699},{\"end\":51058,\"start\":49559},{\"end\":51506,\"start\":51095},{\"end\":54097,\"start\":51539},{\"end\":55653,\"start\":54117},{\"end\":57052,\"start\":55690}]", "formula": null, "table_ref": "[{\"end\":11082,\"start\":11075},{\"end\":14795,\"start\":14788},{\"end\":17201,\"start\":17194}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2943,\"start\":2931},{\"attributes\":{\"n\":\"1.1\"},\"end\":6293,\"start\":6281},{\"attributes\":{\"n\":\"2\"},\"end\":7649,\"start\":7571},{\"attributes\":{\"n\":\"2.1\"},\"end\":10792,\"start\":10772},{\"end\":11111,\"start\":11086},{\"end\":11789,\"start\":11749},{\"end\":12073,\"start\":12049},{\"end\":12425,\"start\":12417},{\"attributes\":{\"n\":\"2.2\"},\"end\":12996,\"start\":12964},{\"attributes\":{\"n\":\"3\"},\"end\":14132,\"start\":14097},{\"attributes\":{\"n\":\"4\"},\"end\":22834,\"start\":22827},{\"attributes\":{\"n\":\"4.1\"},\"end\":22873,\"start\":22837},{\"attributes\":{\"n\":\"4.2\"},\"end\":27738,\"start\":27704},{\"end\":30767,\"start\":30747},{\"end\":33346,\"start\":33306},{\"end\":35085,\"start\":35061},{\"end\":37175,\"start\":37162},{\"attributes\":{\"n\":\"5\"},\"end\":38970,\"start\":38957},{\"attributes\":{\"n\":\"5.1\"},\"end\":39025,\"start\":38973},{\"attributes\":{\"n\":\"5.2\"},\"end\":39965,\"start\":39909},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":42234,\"start\":42214},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":42941,\"start\":42897},{\"attributes\":{\"n\":\"5.2.3\"},\"end\":43879,\"start\":43860},{\"attributes\":{\"n\":\"6\"},\"end\":44787,\"start\":44772},{\"attributes\":{\"n\":\"7\"},\"end\":49557,\"start\":49547},{\"attributes\":{\"n\":\"8.2\"},\"end\":51093,\"start\":51061},{\"attributes\":{\"n\":\"8.2.1\"},\"end\":51537,\"start\":51509},{\"attributes\":{\"n\":\"8.2.2\"},\"end\":54115,\"start\":54100},{\"attributes\":{\"n\":\"8.2.3\"},\"end\":55688,\"start\":55656},{\"end\":57064,\"start\":57054},{\"end\":57259,\"start\":57249},{\"end\":57407,\"start\":57397},{\"end\":58570,\"start\":58561},{\"end\":59118,\"start\":59109}]", "table": "[{\"end\":59107,\"start\":58702}]", "figure_caption": "[{\"end\":57247,\"start\":57066},{\"end\":57395,\"start\":57261},{\"end\":58559,\"start\":57409},{\"end\":58702,\"start\":58572},{\"end\":59150,\"start\":59120}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":25177,\"start\":25169},{\"end\":27803,\"start\":27795},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":28406,\"start\":28398},{\"end\":29060,\"start\":29052},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":41785,\"start\":41776},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":43698,\"start\":43689},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":43856,\"start\":43847},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":44134,\"start\":44125},{\"end\":51254,\"start\":51246}]", "bib_author_first_name": "[{\"end\":60545,\"start\":60538},{\"end\":61118,\"start\":61112},{\"end\":61241,\"start\":61240},{\"end\":61473,\"start\":61468},{\"end\":61753,\"start\":61748},{\"end\":61771,\"start\":61764},{\"end\":62021,\"start\":62014},{\"end\":62812,\"start\":62808},{\"end\":62830,\"start\":62821},{\"end\":63224,\"start\":63218},{\"end\":63797,\"start\":63792},{\"end\":63822,\"start\":63814},{\"end\":63839,\"start\":63836},{\"end\":64199,\"start\":64194},{\"end\":64464,\"start\":64463},{\"end\":64856,\"start\":64855},{\"end\":65025,\"start\":65018},{\"end\":65720,\"start\":65715},{\"end\":66166,\"start\":66165},{\"end\":66183,\"start\":66176},{\"end\":66488,\"start\":66481},{\"end\":66917,\"start\":66916},{\"end\":67225,\"start\":67217},{\"end\":67440,\"start\":67437},{\"end\":67578,\"start\":67573},{\"end\":67987,\"start\":67972},{\"end\":68447,\"start\":68443},{\"end\":68460,\"start\":68454},{\"end\":68824,\"start\":68818},{\"end\":69336,\"start\":69332},{\"end\":70026,\"start\":70018},{\"end\":70304,\"start\":70298},{\"end\":70697,\"start\":70692},{\"end\":70979,\"start\":70975},{\"end\":71236,\"start\":71231},{\"end\":71493,\"start\":71487},{\"end\":71884,\"start\":71877},{\"end\":71904,\"start\":71895},{\"end\":71911,\"start\":71907},{\"end\":72710,\"start\":72705},{\"end\":72885,\"start\":72879},{\"end\":73187,\"start\":73186},{\"end\":73476,\"start\":73475},{\"end\":73792,\"start\":73791},{\"end\":74117,\"start\":74112},{\"end\":74134,\"start\":74126},{\"end\":74148,\"start\":74142},{\"end\":74480,\"start\":74476},{\"end\":74710,\"start\":74702},{\"end\":75741,\"start\":75734},{\"end\":75958,\"start\":75952},{\"end\":76197,\"start\":76196},{\"end\":76604,\"start\":76603},{\"end\":76969,\"start\":76965},{\"end\":77193,\"start\":77189},{\"end\":77446,\"start\":77440},{\"end\":77871,\"start\":77870},{\"end\":78478,\"start\":78472},{\"end\":78560,\"start\":78550},{\"end\":78830,\"start\":78823},{\"end\":79131,\"start\":79127},{\"end\":79146,\"start\":79140},{\"end\":79159,\"start\":79155},{\"end\":79490,\"start\":79484},{\"end\":79780,\"start\":79779},{\"end\":79791,\"start\":79790},{\"end\":79805,\"start\":79804},{\"end\":80082,\"start\":80081},{\"end\":80362,\"start\":80356},{\"end\":80783,\"start\":80771}]", "bib_author_last_name": "[{\"end\":60555,\"start\":60546},{\"end\":60834,\"start\":60819},{\"end\":60839,\"start\":60836},{\"end\":61124,\"start\":61119},{\"end\":61248,\"start\":61242},{\"end\":61256,\"start\":61250},{\"end\":61482,\"start\":61474},{\"end\":61762,\"start\":61754},{\"end\":61781,\"start\":61772},{\"end\":62027,\"start\":62022},{\"end\":62496,\"start\":62479},{\"end\":62819,\"start\":62813},{\"end\":62837,\"start\":62831},{\"end\":63232,\"start\":63225},{\"end\":63812,\"start\":63798},{\"end\":63834,\"start\":63823},{\"end\":63850,\"start\":63840},{\"end\":64205,\"start\":64200},{\"end\":64469,\"start\":64465},{\"end\":64476,\"start\":64471},{\"end\":64862,\"start\":64857},{\"end\":64873,\"start\":64864},{\"end\":65031,\"start\":65026},{\"end\":65731,\"start\":65721},{\"end\":66174,\"start\":66167},{\"end\":66191,\"start\":66184},{\"end\":66199,\"start\":66193},{\"end\":66497,\"start\":66489},{\"end\":66927,\"start\":66918},{\"end\":66940,\"start\":66929},{\"end\":67228,\"start\":67226},{\"end\":67447,\"start\":67441},{\"end\":67990,\"start\":67988},{\"end\":68452,\"start\":68448},{\"end\":68467,\"start\":68461},{\"end\":68831,\"start\":68825},{\"end\":69344,\"start\":69337},{\"end\":70032,\"start\":70027},{\"end\":70307,\"start\":70305},{\"end\":70705,\"start\":70698},{\"end\":70983,\"start\":70980},{\"end\":71243,\"start\":71237},{\"end\":71496,\"start\":71494},{\"end\":71893,\"start\":71885},{\"end\":71924,\"start\":71912},{\"end\":72717,\"start\":72711},{\"end\":72891,\"start\":72886},{\"end\":73195,\"start\":73188},{\"end\":73483,\"start\":73477},{\"end\":73490,\"start\":73485},{\"end\":73798,\"start\":73793},{\"end\":73806,\"start\":73800},{\"end\":74124,\"start\":74118},{\"end\":74140,\"start\":74135},{\"end\":74154,\"start\":74149},{\"end\":74486,\"start\":74481},{\"end\":74730,\"start\":74711},{\"end\":75746,\"start\":75742},{\"end\":75964,\"start\":75959},{\"end\":76204,\"start\":76198},{\"end\":76210,\"start\":76206},{\"end\":76611,\"start\":76605},{\"end\":76617,\"start\":76613},{\"end\":76976,\"start\":76970},{\"end\":77201,\"start\":77194},{\"end\":77462,\"start\":77447},{\"end\":77879,\"start\":77872},{\"end\":77886,\"start\":77881},{\"end\":78486,\"start\":78479},{\"end\":78569,\"start\":78561},{\"end\":78586,\"start\":78571},{\"end\":78835,\"start\":78831},{\"end\":79138,\"start\":79132},{\"end\":79153,\"start\":79147},{\"end\":79166,\"start\":79160},{\"end\":79497,\"start\":79491},{\"end\":79788,\"start\":79781},{\"end\":79802,\"start\":79792},{\"end\":79817,\"start\":79806},{\"end\":80087,\"start\":80083},{\"end\":80094,\"start\":80089},{\"end\":80368,\"start\":80363},{\"end\":80791,\"start\":80784}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":235390655},\"end\":60696,\"start\":60502},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":59240336},\"end\":61081,\"start\":60698},{\"attributes\":{\"id\":\"b2\"},\"end\":61180,\"start\":61083},{\"attributes\":{\"doi\":\"arXiv:2007.14390\",\"id\":\"b3\"},\"end\":61414,\"start\":61182},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":59599820},\"end\":61707,\"start\":61416},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":233465558},\"end\":61918,\"start\":61709},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":7523372},\"end\":62236,\"start\":61920},{\"attributes\":{\"id\":\"b7\"},\"end\":62401,\"start\":62238},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":248936288},\"end\":62670,\"start\":62403},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":201042330},\"end\":63110,\"start\":62672},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":232244330},\"end\":63460,\"start\":63112},{\"attributes\":{\"id\":\"b11\"},\"end\":63699,\"start\":63462},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":248430370},\"end\":64113,\"start\":63701},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":237536154},\"end\":64375,\"start\":64115},{\"attributes\":{\"doi\":\"10.1016/j.radonc.2019.11.019\",\"id\":\"b14\",\"matched_paper_id\":210085618},\"end\":64803,\"start\":64377},{\"attributes\":{\"id\":\"b15\"},\"end\":64971,\"start\":64805},{\"attributes\":{\"doi\":\"http:/iopscience.iop.org/article/10.1088/1361-6560/ac97d9\",\"id\":\"b16\",\"matched_paper_id\":252737153},\"end\":65345,\"start\":64973},{\"attributes\":{\"id\":\"b17\"},\"end\":65600,\"start\":65347},{\"attributes\":{\"doi\":\"10.1038/s41467-021-25972-y\",\"id\":\"b18\",\"matched_paper_id\":232081916},\"end\":66073,\"start\":65602},{\"attributes\":{\"doi\":\"arXiv:1910.11567\",\"id\":\"b19\"},\"end\":66406,\"start\":66075},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":208857467},\"end\":66804,\"start\":66408},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":795781},\"end\":67143,\"start\":66806},{\"attributes\":{\"doi\":\"arXiv:2007.13518\",\"id\":\"b22\"},\"end\":67398,\"start\":67145},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":67870270},\"end\":67571,\"start\":67400},{\"attributes\":{\"id\":\"b24\"},\"end\":67901,\"start\":67573},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":3272607},\"end\":68367,\"start\":67903},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":14157956},\"end\":68756,\"start\":68369},{\"attributes\":{\"doi\":\"10.1145/3372297.3417872\",\"id\":\"b27\",\"matched_paper_id\":218550885},\"end\":69278,\"start\":68758},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":68245372},\"end\":69949,\"start\":69280},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":253386833},\"end\":70198,\"start\":69951},{\"attributes\":{\"doi\":\"10.1109/TKDE.2021.3124599\",\"id\":\"b30\",\"matched_paper_id\":198179889},\"end\":70609,\"start\":70200},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":10331142},\"end\":70889,\"start\":70611},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":246432494},\"end\":71162,\"start\":70891},{\"attributes\":{\"doi\":\"arXiv:2007.10987\",\"id\":\"b33\"},\"end\":71407,\"start\":71164},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":216566716},\"end\":71690,\"start\":71409},{\"attributes\":{\"doi\":\"10.1145/3564625.3568135.Austin\",\"id\":\"b35\"},\"end\":72667,\"start\":71692},{\"attributes\":{\"id\":\"b36\"},\"end\":72810,\"start\":72669},{\"attributes\":{\"id\":\"b37\"},\"end\":73109,\"start\":72812},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b38\",\"matched_paper_id\":14955348},\"end\":73408,\"start\":73111},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":1739295},\"end\":73690,\"start\":73410},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":28711},\"end\":74077,\"start\":73692},{\"attributes\":{\"id\":\"b41\"},\"end\":74356,\"start\":74079},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":256032647},\"end\":74698,\"start\":74358},{\"attributes\":{\"doi\":\"10.3390/info13050263\",\"id\":\"b43\"},\"end\":75232,\"start\":74700},{\"attributes\":{\"id\":\"b44\"},\"end\":75401,\"start\":75234},{\"attributes\":{\"id\":\"b45\"},\"end\":75660,\"start\":75403},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":248366603},\"end\":75896,\"start\":75662},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":212747909},\"end\":76111,\"start\":75898},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":221507926},\"end\":76544,\"start\":76113},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":253098004},\"end\":76905,\"start\":76546},{\"attributes\":{\"id\":\"b50\"},\"end\":77132,\"start\":76907},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":229371053},\"end\":77350,\"start\":77134},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":244469110},\"end\":77772,\"start\":77352},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":231803993},\"end\":78155,\"start\":77774},{\"attributes\":{\"id\":\"b54\"},\"end\":78434,\"start\":78157},{\"attributes\":{\"id\":\"b55\"},\"end\":78546,\"start\":78436},{\"attributes\":{\"id\":\"b56\"},\"end\":78697,\"start\":78548},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":244743394},\"end\":79058,\"start\":78699},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":10156739},\"end\":79360,\"start\":79060},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":16996204},\"end\":79708,\"start\":79362},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":12829250},\"end\":79998,\"start\":79710},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":57574615},\"end\":80255,\"start\":80000},{\"attributes\":{\"id\":\"b62\"},\"end\":80703,\"start\":80257},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":9649600},\"end\":80953,\"start\":80705}]", "bib_title": "[{\"end\":60536,\"start\":60502},{\"end\":60817,\"start\":60698},{\"end\":61466,\"start\":61416},{\"end\":61746,\"start\":61709},{\"end\":62012,\"start\":61920},{\"end\":62477,\"start\":62403},{\"end\":62806,\"start\":62672},{\"end\":63216,\"start\":63112},{\"end\":63790,\"start\":63701},{\"end\":64192,\"start\":64115},{\"end\":64461,\"start\":64377},{\"end\":65016,\"start\":64973},{\"end\":65713,\"start\":65602},{\"end\":66479,\"start\":66408},{\"end\":66914,\"start\":66806},{\"end\":67435,\"start\":67400},{\"end\":67970,\"start\":67903},{\"end\":68441,\"start\":68369},{\"end\":68816,\"start\":68758},{\"end\":69330,\"start\":69280},{\"end\":70016,\"start\":69951},{\"end\":70296,\"start\":70200},{\"end\":70690,\"start\":70611},{\"end\":70973,\"start\":70891},{\"end\":71485,\"start\":71409},{\"end\":71875,\"start\":71692},{\"end\":72877,\"start\":72812},{\"end\":73184,\"start\":73111},{\"end\":73473,\"start\":73410},{\"end\":73789,\"start\":73692},{\"end\":74110,\"start\":74079},{\"end\":74474,\"start\":74358},{\"end\":75732,\"start\":75662},{\"end\":75950,\"start\":75898},{\"end\":76194,\"start\":76113},{\"end\":76601,\"start\":76546},{\"end\":77187,\"start\":77134},{\"end\":77438,\"start\":77352},{\"end\":77868,\"start\":77774},{\"end\":78821,\"start\":78699},{\"end\":79125,\"start\":79060},{\"end\":79482,\"start\":79362},{\"end\":79777,\"start\":79710},{\"end\":80079,\"start\":80000},{\"end\":80769,\"start\":80705}]", "bib_author": "[{\"end\":60557,\"start\":60538},{\"end\":60836,\"start\":60819},{\"end\":60841,\"start\":60836},{\"end\":61126,\"start\":61112},{\"end\":61250,\"start\":61240},{\"end\":61258,\"start\":61250},{\"end\":61484,\"start\":61468},{\"end\":61764,\"start\":61748},{\"end\":61783,\"start\":61764},{\"end\":62029,\"start\":62014},{\"end\":62498,\"start\":62479},{\"end\":62821,\"start\":62808},{\"end\":62839,\"start\":62821},{\"end\":63234,\"start\":63218},{\"end\":63814,\"start\":63792},{\"end\":63836,\"start\":63814},{\"end\":63852,\"start\":63836},{\"end\":64207,\"start\":64194},{\"end\":64471,\"start\":64463},{\"end\":64478,\"start\":64471},{\"end\":64864,\"start\":64855},{\"end\":64875,\"start\":64864},{\"end\":65033,\"start\":65018},{\"end\":65733,\"start\":65715},{\"end\":66176,\"start\":66165},{\"end\":66193,\"start\":66176},{\"end\":66201,\"start\":66193},{\"end\":66499,\"start\":66481},{\"end\":66929,\"start\":66916},{\"end\":66942,\"start\":66929},{\"end\":67230,\"start\":67217},{\"end\":67449,\"start\":67437},{\"end\":67581,\"start\":67573},{\"end\":67992,\"start\":67972},{\"end\":68454,\"start\":68443},{\"end\":68469,\"start\":68454},{\"end\":68833,\"start\":68818},{\"end\":69346,\"start\":69332},{\"end\":70034,\"start\":70018},{\"end\":70309,\"start\":70298},{\"end\":70707,\"start\":70692},{\"end\":70985,\"start\":70975},{\"end\":71245,\"start\":71231},{\"end\":71498,\"start\":71487},{\"end\":71895,\"start\":71877},{\"end\":71907,\"start\":71895},{\"end\":71926,\"start\":71907},{\"end\":72719,\"start\":72705},{\"end\":72893,\"start\":72879},{\"end\":73197,\"start\":73186},{\"end\":73485,\"start\":73475},{\"end\":73492,\"start\":73485},{\"end\":73800,\"start\":73791},{\"end\":73808,\"start\":73800},{\"end\":74126,\"start\":74112},{\"end\":74142,\"start\":74126},{\"end\":74156,\"start\":74142},{\"end\":74488,\"start\":74476},{\"end\":74732,\"start\":74702},{\"end\":75748,\"start\":75734},{\"end\":75966,\"start\":75952},{\"end\":76206,\"start\":76196},{\"end\":76212,\"start\":76206},{\"end\":76613,\"start\":76603},{\"end\":76619,\"start\":76613},{\"end\":76978,\"start\":76965},{\"end\":77203,\"start\":77189},{\"end\":77464,\"start\":77440},{\"end\":77881,\"start\":77870},{\"end\":77888,\"start\":77881},{\"end\":78488,\"start\":78472},{\"end\":78571,\"start\":78550},{\"end\":78588,\"start\":78571},{\"end\":78837,\"start\":78823},{\"end\":79140,\"start\":79127},{\"end\":79155,\"start\":79140},{\"end\":79168,\"start\":79155},{\"end\":79499,\"start\":79484},{\"end\":79790,\"start\":79779},{\"end\":79804,\"start\":79790},{\"end\":79819,\"start\":79804},{\"end\":80089,\"start\":80081},{\"end\":80096,\"start\":80089},{\"end\":80370,\"start\":80356},{\"end\":80793,\"start\":80771}]", "bib_venue": "[{\"end\":60578,\"start\":60557},{\"end\":60867,\"start\":60841},{\"end\":61110,\"start\":61083},{\"end\":61238,\"start\":61182},{\"end\":61527,\"start\":61484},{\"end\":61794,\"start\":61783},{\"end\":62055,\"start\":62029},{\"end\":62291,\"start\":62240},{\"end\":62517,\"start\":62498},{\"end\":62870,\"start\":62839},{\"end\":63263,\"start\":63234},{\"end\":63527,\"start\":63462},{\"end\":63896,\"start\":63852},{\"end\":64222,\"start\":64207},{\"end\":64531,\"start\":64506},{\"end\":64853,\"start\":64805},{\"end\":65119,\"start\":65090},{\"end\":65435,\"start\":65347},{\"end\":65780,\"start\":65759},{\"end\":66163,\"start\":66075},{\"end\":66548,\"start\":66499},{\"end\":66957,\"start\":66942},{\"end\":67215,\"start\":67145},{\"end\":67470,\"start\":67449},{\"end\":67725,\"start\":67581},{\"end\":68114,\"start\":67992},{\"end\":68537,\"start\":68469},{\"end\":68947,\"start\":68856},{\"end\":69536,\"start\":69346},{\"end\":70058,\"start\":70034},{\"end\":70385,\"start\":70334},{\"end\":70729,\"start\":70707},{\"end\":71008,\"start\":70985},{\"end\":71229,\"start\":71164},{\"end\":71529,\"start\":71498},{\"end\":71966,\"start\":71956},{\"end\":72703,\"start\":72669},{\"end\":72931,\"start\":72893},{\"end\":73239,\"start\":73201},{\"end\":73528,\"start\":73492},{\"end\":73863,\"start\":73808},{\"end\":74190,\"start\":74156},{\"end\":74510,\"start\":74488},{\"end\":74927,\"start\":74781},{\"end\":75278,\"start\":75236},{\"end\":75454,\"start\":75405},{\"end\":75768,\"start\":75748},{\"end\":75986,\"start\":75966},{\"end\":76301,\"start\":76212},{\"end\":76685,\"start\":76619},{\"end\":76963,\"start\":76907},{\"end\":77223,\"start\":77203},{\"end\":77505,\"start\":77490},{\"end\":77943,\"start\":77888},{\"end\":78251,\"start\":78157},{\"end\":78470,\"start\":78436},{\"end\":78857,\"start\":78837},{\"end\":79194,\"start\":79168},{\"end\":79512,\"start\":79499},{\"end\":79840,\"start\":79819},{\"end\":80111,\"start\":80096},{\"end\":80354,\"start\":80257},{\"end\":80810,\"start\":80793},{\"end\":61557,\"start\":61529},{\"end\":69025,\"start\":68949},{\"end\":69552,\"start\":69538},{\"end\":72016,\"start\":71978}]"}}}, "year": 2023, "month": 12, "day": 17}