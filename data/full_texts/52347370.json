{"id": 52347370, "updated": "2023-10-01 15:33:27.341", "metadata": {"title": "Efficient Formal Safety Analysis of Neural Networks", "authors": "[{\"first\":\"Shiqi\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Kexin\",\"last\":\"Pei\",\"middle\":[]},{\"first\":\"Justin\",\"last\":\"Whitehouse\",\"middle\":[]},{\"first\":\"Junfeng\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Suman\",\"last\":\"Jana\",\"middle\":[]}]", "venue": "NeurIPS", "journal": "6369-6379", "publication_date": {"year": 2018, "month": 9, "day": 19}, "abstract": "Neural networks are increasingly deployed in real-world safety-critical domains such as autonomous driving, aircraft collision avoidance, and malware detection. However, these networks have been shown to often mispredict on inputs with minor adversarial or even accidental perturbations. Consequences of such errors can be disastrous and even potentially fatal as shown by the recent Tesla autopilot crash. Thus, there is an urgent need for formal analysis systems that can rigorously check neural networks for violations of different safety properties such as robustness against adversarial perturbations within a certain $L$-norm of a given image. An effective safety analysis system for a neural network must be able to either ensure that a safety property is satisfied by the network or find a counterexample, i.e., an input for which the network will violate the property. Unfortunately, most existing techniques for performing such analysis struggle to scale beyond very small networks and the ones that can scale to larger networks suffer from high false positives and cannot produce concrete counterexamples in case of a property violation. In this paper, we present a new efficient approach for rigorously checking different safety properties of neural networks that significantly outperforms existing approaches by multiple orders of magnitude. Our approach can check different safety properties and find concrete counterexamples for networks that are 10$\\times$ larger than the ones supported by existing analysis techniques. We believe that our approach to estimating tight output bounds of a network for a given input range can also help improve the explainability of neural networks and guide the training process of more robust neural networks.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1809.08098", "mag": "2950029838", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/WangPWYJ18", "doi": null}}, "content": {"source": {"pdf_hash": "04fd3f7c348b808bd66c28889505e04447c1ede6", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1809.08098v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "3bb512be37bf4526ee30383af5aae1cb6e73c678", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/04fd3f7c348b808bd66c28889505e04447c1ede6.txt", "contents": "\nEfficient Formal Safety Analysis of Neural Networks\n\n\nShiqi Wang tcwangshiqi@cs.columbia.edu \nColumbia University\n10027NYCNYUSA\n\nKexin Pei kpei@cs.columbia.edu \nColumbia University\n10027NYCNYUSA\n\nJustin Whitehouse \nColumbia University\n10027NYCNYUSA\n\nJunfeng Yang junfeng@cs.columbia.edu \nColumbia University\n10027NYCNYUSA\n\nSuman Jana \nColumbia University\n10027NYCNYUSA\n\nEfficient Formal Safety Analysis of Neural Networks\n\nNeural networks are increasingly deployed in real-world safety-critical domains such as autonomous driving, aircraft collision avoidance, and malware detection. However, these networks have been shown to often mispredict on inputs with minor adversarial or even accidental perturbations. Consequences of such errors can be disastrous and even potentially fatal as shown by the recent Tesla autopilot crashes. Thus, there is an urgent need for formal analysis systems that can rigorously check neural networks for violations of different safety properties such as robustness against adversarial perturbations within a certain L-norm of a given image. An effective safety analysis system for a neural network must be able to either ensure that a safety property is satisfied by the network or find a counterexample, i.e., an input for which the network will violate the property. Unfortunately, most existing techniques for performing such analysis struggle to scale beyond very small networks and the ones that can scale to larger networks suffer from high false positives and cannot produce concrete counterexamples in case of a property violation. In this paper, we present a new efficient approach for rigorously checking different safety properties of neural networks that significantly outperforms existing approaches by multiple orders of magnitude. Our approach can check different safety properties and find concrete counterexamples for networks that are 10\u00d7 larger than the ones supported by existing analysis techniques. We believe that our approach to estimating tight output bounds of a network for a given input range can also help improve the explainability of neural networks and guide the training process of more robust neural networks.\n\nIntroduction\n\nOver the last few years, significant advances in neural networks have resulted in their increasing deployments in critical domains including healthcare, autonomous vehicles, and security. However, recent work has shown that neural networks, despite their tremendous success, often make dangerous mistakes, especially for rare corner case inputs. For example, most state-of-the-art neural networks have been shown to produce incorrect outputs for adversarial inputs specifically crafted by adding minor human-imperceptible perturbations to regular inputs [36,14]. Similarly, seemingly minor changes in lighting or orientation of an input image have been shown to cause drastic mispredictions by the state-of-the-art neural networks [29,30,37]. Such mistakes can have disastrous and even potentially fatal consequences. For example, a Tesla car in autopilot mode recently caused a fatal crash as it failed to detect a white truck against a bright sky with white clouds [3].\n\nA principled way of minimizing such mistakes is to ensure that neural networks satisfy simple safety/security properties such as the absence of adversarial inputs within a certain L-norm of a given image or the invariance of the network's predictions on the images of the same object under different lighting conditions. Ideally, given a neural network and a safety property, an automated checker should either guarantee that the property is satisfied by the network or find concrete counterexamples demonstrating violations of the safety property. The effectiveness of such automated checkers hinges on how accurately they can estimate the decision boundary of the network.\n\nHowever, strict estimation of the decision boundary of a neural network with piecewise linear activation functions such as ReLU is a hard problem. While the linear pieces of each ReLU node can be partitioned into two linear constraints and efficiently check separately, the total number of linear pieces grow exponentially with the number of nodes in the network [25,27]. Therefore, exhaustive enumeration of all combinations of these pieces for any modern network is prohibitively expensive. Similarly, sampling-based inference techniques like blackbox Monte Carlo sampling may need an enormous amount of data to generate tight accurate bounds on the decision boundary [11].\n\nIn this paper, we propose a new efficient approach for rigorously checking different safety properties of neural networks that significantly outperform existing approaches by multiple orders of magnitude. Specifically, we introduce two key techniques. First, we use symbolic linear relaxation that combines symbolic interval analysis and linear relaxation to compute tighter bounds on the network outputs by keeping track of relaxed dependencies across inputs during interval propagation when the actual dependencies become too complex to track. Second, we introduce a novel technique called directed constraint refinement to iteratively minimize the errors introduced during the relaxation process until either a safety property is satisfied or a counterexample is found. To make the refinement process efficient, we identify the potentially overestimated nodes, i.e., the nodes where inaccuracies introduced during relaxation can potentially affect the checking of a given safety property, and use off-the-shelf solvers to focus only on those nodes to further tighten their output ranges.\n\nWe implement our techniques as part of Neurify, a system for rigorously checking a diverse set of safety properties of neural networks 10\u00d7 larger than the ones that can be handled by existing techniques. We used Neurify to check six different types of safety properties of nine different networks trained on five different datasets. Our experimental results show that on average Neurify is 5, 000\u00d7 faster than Reluplex [17] and 20\u00d7 than ReluVal [39].\n\nBesides formal analysis of safety properties, we believe our method for efficiently estimating tight and rigorous output ranges of a network will also be useful for guiding the training process of robust networks [42,32] and improving explainability of the decisions made by neural networks [34,20,23].\n\nRelated work. Several researchers have tried to extend and customize Satisfiability Modulo Theory (SMT) solvers for estimating decision boundaries with strong guarantees [17,18,15,10,31]. Another line of research has used Mixed Integer Linear Programming (MILP) solvers for such analysis [38,12,7]. Unfortunately, the efficiency of both of these approaches is severely limited by the high nonlinearity of the resulting formulas.\n\nDifferent convex or linear relaxation techniques have also been used to strictly approximate the decision boundary of neural networks. While these techniques tend to scale significantly better than solver-based approaches, they suffer from high false positive rates and struggle to find concrete counterexamples demonstrating violations of safety properties [42,32,13,9]. Similarly, existing works on finding lower bounds of adversarial perturbations to fool a neural network also suffer from the same limitations [28,41]. Note that concurrent work of Weng et al. [40] uses similar linear relaxation method as ours but it alone struggles to solve such problems as shown in Table  6. Also, their follow-up work [44] that provides a generic relaxation method for general activation functions does not address this issue either. In contrast, we mainly use our relaxation technique to identify crucial nodes and iteratively refine output approximations over these nodes with the help of linear solver. Another line of research has focused on strengthening network robustness either by incorporating these relaxation methods into training process [43,8,24] or by leveraging techniques like differential privacy [22]. Our method, essentially providing a more accurate formal analysis of a network, can potentially be incorporated into training process to further improve network robustness.\n\nRecently, ReluVal, by Wang et al. [39], has used interval arithmetic [33] for rigorously estimating a neural network's decision boundary by computing tight bounds on the outputs of a network for a given input range. While ReluVal achieved significant performance gain over the state-of-the-art solver-based methods [17] on networks with a small number of inputs, it struggled to scale to larger networks (see detailed discussions in Section 2).\n\n\nBackground\n\nWe build upon two prior works [10,39] on using interval analysis and linear relaxations for analyzing neural networks. We briefly describe them and refer interested readers to [10,39] for more details.\n\nSymbolic interval analysis. Interval arithmetic [33] is a flexible and efficient way of rigorously estimating the output ranges of a function given an input range by computing and propagating the output intervals for each operation in the function. However, naive interval analysis suffers from large overestimation errors as it ignores the input dependencies during interval propagation. To minimize such errors, Wang et al. [39] used symbolic intervals to keep track of dependencies by maintaining linear equations for upper and lower bounds for each ReLU and concretizing only for those ReLUs that demonstrate non-linear behavior for the given input intervals. Specifically, consider an intermediate ReLU node z = Relu(Eq), (l, u) = (Eq, Eq), where Eq denotes the symbolic representation (i.e., a closed-form equation) of the ReLU's input in terms of network inputs X and (l, u) denote the concrete lower and upper bounds of Eq, respectively. There are three possible output intervals that the ReLU node can produce depending on the bounds of Eq: (1) z = [Eq, Eq] when l \u2265 0, (2) z = [0, 0] when u \u2264 0, or (3) z = [l, u] when l < 0 < u. Wang et al. will concretize the output intervals for this node only if the third case is feasible as the output in this case cannot be represented using a single linear equation.\n\nBisection of input features. To further minimize overestimation, [39] also proposed an iterative refinement strategy involving repeated input bisection and output reunion. Consider a network F taking d-dimensional input, and the i-th input feature interval is X i and network output interval is F (X) where X = {X 1 , ..., X d }. A single bisection on X i will create two children:\nX = {X 1 , ..., [X i , Xi+Xi 2 ], ..., X d } and X = {X 1 , ..., [ Xi+Xi 2 , X i ], ..., X d }.\nThe reunion of the corresponding output intervals F (X ) F (X ), will be tighter than the original output interval, i.e., F (X ) F (X ) \u2286 F (X), as the Lipschitz continuity of the network ensures that the overestimation error decreases as the width of input interval becomes smaller. However, the efficiency of input bisection decreases drastically as the number of input dimensions increases. Linear relaxation. Ehlers et al. [10] used linear relaxation of ReLU nodes to strictly overapproximate the non-linear constraints introduced by each ReLU. The generated linear constraints can then be efficiently solved using a linear solver to get bounds on the output of a neural network for a given input range. Consider the simple ReLU node taking input z with an upper and lower bound u and l respectively and producing output z as shown in Figure 1. Linear relaxation of such a node will use the following three linear constraints: (1) z \u2265 0, (2) z \u2265 z , and (3) z \u2264 u(z \u2212l) u\u2212l to expand the feasible region to the green triangle from the two original piecewise linear components. The effectiveness of this approach heavily depends on how accurately u and l can be estimated. Unfortunately, Ehlers et al. [10] used naive interval propagation to estimate u and l leading to large overestimation errors. Furthermore, their approach cannot efficiently refine the estimated bounds and thus cannot benefit from increasing computing power.\nz \u2032 z l u W 3 W 1 x 3 x 1 W 2 x 2 z \u2032 z z \u2265 0 z \u2265 z \u2032 z \u2264 ( z \u2032 \u2212 l ) u u \u2212 l\n\nApproach\n\nIn this paper, we make two major contributions to scale formal safety analysis to networks significantly larger than those evaluated in prior works [17,10,42,39]. First, we combine symbolic interval analysis and linear relaxation (described in Section 2) in a novel way to create a significantly more efficient propagation method-symbolic linear relaxation-that can achieve substantially tighter estimations (evaluated in Section 4). Second, we present a technique for identifying the overestimated intermediate nodes, i.e., the nodes whose outputs are overestimated, during symbolic linear relaxation and propose directed constraint refinement to iteratively refine the output ranges of these nodes. In Section 4, we also show that this method mitigates the limitations of input bisection [39] and scales to larger networks. Figure 2 illustrates the high-level workflow of Neurify. Neurify takes in a range of inputs X and then determines using linear solver whether the output estimation generated by symbolic linear relaxation satisfies the safety proprieties. A property is proven to be safe if the solver find the relaxed constraints unsatisfiable. Otherwise, the solver returns potential counterexamples. Note that the returned counterexamples found by the solver might be false positives due to the inaccuracies introduced by the relaxation process. Thus Neurify will check whether a counterexample is a false positive. If so, Neurify will use directed constraint refinement guided by symbolic linear relaxation to obtain a tighter output bound and recheck the property with the solver.  The symbolic linear relaxation of the output of each ReLU z = Relu(z ) leverages the bounds on z , Eq low and Eq up (Eq low \u2264 Eq * (x) \u2264 Eq up ). Here Eq * denotes the closed-form representation of z .\n\n\nSymbolic Linear Relaxation\n\nSpecifically, Equation 1 shows the symbolic linear relaxation where \u2192 denotes \"relax to\". In addition, [l low , u low ] and [l up , u up ] denote the concrete lower and upper bounds for Eq low and Eq up , respectively. In supplementary material Section 1.2, we give a detailed proof showing that this relaxation is the tightest achievable due to its least maximum distance from Eq * . In the following discussion, we simplify Eq low and Eq up as Eq and the corresponding lower and upper bounds as [l, u]. Figure 3 shows the difference between our symbolic relaxation process and the naive concretizations used by Wang et al. [39]. More detailed discussions can be found in supplementary material Section 2.  In practice, symbolic linear relaxation can cut (on average) 59.64% more overestimation error than symbolic interval analysis (cf. Section 2) and saves the time needed to prove a property by several orders of magnitude (cf. Section 4). There are three key reasons behind such significant performance improvement. First, the maximum possible error after introducing relaxations is \u2212lup * uup uup\u2212lup for upper bound and \u2212l low * u low u low \u2212l low for lower bound in Figure 3(b) (the proof is in supplementary material Section 1.2). These relaxations are considerably tighter than naive concretizations shown in Figure 3(a), which introduces a larger error u up . Second, symbolic linear relaxation, unlike naive concretization, partially keeps the input dependencies during interval propagation ([ u u\u2212l Eq, u u\u2212l (Eq \u2212 l)] by maintaining symbolic equations. Third, as the final output error is exponential to the error introduced at each node (proved in supplementary 1.2), tighter bounds on earlier nodes produced by symbolic relaxation significantly reduce the final output error.\nRelu(Eq low ) \u2192 u low u low \u2212 l low (Eq low ) Relu(Eq up ) \u2192 u up u up \u2212 l up (Eq up \u2212 l up )(1)\n\nDirected Constraint Refinement\n\nBesides symbolic linear relaxation, we also develop another generic approach, directed constraint refinement, to further improve the overall performance of property checking. Our empirical results in Section 4 shows the substantial improvement from using this approach combined with symbolic linear relaxation. In the following, we first define overestimated nodes before describing the directed constraint refinement process in detail.\n\nOverestimated nodes. We note that, for most networks, only a small proportion of intermediate ReLU nodes operate in the non-linear region for a given input range X. These are the only nodes that need to be relaxed (cf. Section 2). We call these nodes overestimated as they introduce overestimation error during relaxation. We include other useful properties and proofs regarding overestimated nodes in supplementary material Section 1.1.\n\nBased on the definition of overestimated nodes, we define one step of directed constraint refinement as computing the refined output range F (X):\nF (X) = F (x \u2208 X|Eq(x) \u2264 0) \u222a F (x \u2208 X|Eq(x) > 0)(2)\nwhere X denotes the input intervals to the network, F is the corresponding network, and Eq is the input equation of an overestimated node. Note that here we are showing the input of a node as a single equation for simplicity instead of the upper and lower bounds shown in Section 3.1.\n\nWe iteratively refine the bounds by invoking a linear solver, allowing us to make Neurify more scalable for difficult safety properties. The convergence analysis is given in supplementary material Section 1.3.\n\nThe refinement includes the following three steps:\n\nLocating overestimated nodes. From symbolic linear relaxations, we can get the set of overestimated nodes within the network. We then prioritize the overestimated nodes with larger output gradient and refine these influential overestimated nodes first. We borrow the idea from [39] of computing the gradient of network output with respect to the input interval of the overestimated node. A larger gradient value of a node signifies that the input of that node has a greater influence towards changing the output than than the inputs of other nodes.\n\nSplitting. After locating the target overestimated node, we split its input ranges into two independent cases, Eq t > 0 and Eq t \u2264 0 where Eq t denotes the input of the target overestimated node. Now,\nunlike symbolic linear relaxation where Relu([Eq t , Eq t ]) \u2192 [ u u\u2212l Eq t , u u\u2212l (Eq t \u2212 l)]\n, neither of the two split cases requires any relaxation (Section 2) as the input interval no longer includes 0. Therefore, splitting creates two tighter approximations of the output F (x \u2208 X|Eq t (x) > 0) and\nF (x \u2208 X|Eq t (x) \u2264 0).\nSolving. We solve the resulting linear constraints, along with the constraints defined in safety properties, by instantiating an underlying linear solver. In particular, we define safety properties that check that the confidence value of a target output class F t is always greater than the outputs of other classes F o (e.g., outputs other than 7 for an image of a hand-written 7). We thus define the constraints for safety properties as Eq t low \u2212 Eq o up < 0. Here, Eq t low and Eq o up are the lower bound equations for F t and the upper bound equations for F o derived using symbolic linear relaxation. Each step of directed constraint refinement of an overestimated node results in two independent problems as shown in Equation 3 that can be checked with a linear solver.\nCheck Satifiability: Eq t low1 \u2212 Eq o up1 < 0; Eq t \u2264 0; x i \u2212 \u2264 x i \u2264 x i + (i = 1 . . . d) Check Satifiability: Eq t low2 \u2212 Eq o up2 < 0; Eq t > 0; x i \u2212 \u2264 x i \u2264 x i + (i = 1 . . . d)(3)\nIn this process, we invoke the solver in two ways. (1) If the solver tells that both cases are unsatisfiable, then the property is formally proved to be safe. Otherwise, further iterative refinement steps can be applied.\n\n(2) If either case is satisfiable, we treat the solutions returned by the linear solver as potential counterexamples violating the safety properties. Note that these solutions might be false positives due to the inaccuracies introduced during the relaxation process. We thus resort to directly executing the target network with the solutions returned from the solver as input. If the solution does not violate the property, we repeat the above process for another overestimated node (cf. Figure 2).\n\n\nSafety Properties\n\nIn this work, we support checking diverse safety properties of networks including five different classes of properties based on the input constraints. Particularly, we specify the safety properties of neural network based on defining constraints on its input-output. For example, as briefly mentioned in Section 3.1, we specify that the output of the network on input x should not change (i.e., remain invariant) when x is allowed to vary within a certain range X. For output constraints, taking an arbitrary classifier as an example, we define the output invariance by specifying the difference greater than 0 between lower and upper bound of confidence value of the original class of the input and other classes. For specifying input constraints, we consider three popular bounds, i.e., L \u221e , L 1 , and L 2 , which are widely used in the literature of adversarial machine learning [14]. These three bounds allow for arbitrary perturbations of the input features as long as the corresponding norms of the overall perturbation are within a certain threshold. In addition to these arbitrary perturbations, we consider two specific perturbations that change brightness and contrast of the input images as discussed in [30]. Properties specified using L \u221e naturally fit into our symbolic linear relaxation process where each input features are bounded by an interval. For properties specified in L 1 \u2264 or L 2 \u2264 , we need to add more constraints, i.e.,\nd i=1 |x i | \u2264 for L 1 , or d i=1 x i 2 \u2264 for L 2 ,\nwhich are no longer linear. We handle such cases by using solvers that support quadratic constraints (see details in Section 4). The safety properties involving changes in brightness and contrast can be efficiently checked by iteratively bisecting the input nodes simultaneously as\nmin x\u2208[x\u2212 ,x+ ] (F (x)) = min(min x\u2208[x,x+ ] (F (x)), min x\u2208[x\u2212 ,x] (F (x)))\nwhere F represents the computation performed by the target network .\n\n\nExperiments\n\nImplementation. We implement Neurify with about 26,000 lines of C code. We use the highly optimized OpenBLAS 1 library for matrix multiplications and lp_solve 5.5 2 for solving the linear constraints generated during the directed constraint refinement process. We further use Gurobi 8.0.0 solver for L 2 -bounded safety properties. All our evaluations were performed on a Linux server running Ubuntu 16.04 with 8 CPU cores and 256GB memory. Besides, Neurify uses optimization like thread rebalancing for parallelization and outward rounding to avoid incorrect results due to floating point imprecision. Details of such techniques can be found in Section 3 of the supplementary material. \n\n\nProperties Checked by Neurify for Each Model\n\nSummary. To evaluate the performance of Neurify, we test it on nine models trained over five datasets for different tasks where each type of model includes multiple architectures. Specifically, we evaluate on fully connected ACAS Xu models [16], three fully connected Drebin models [5], three fully connected MNIST models [21], one convolutional MNIST model [42], and one convolutional self-driving car model [2]. Table 1 summarizes the detailed structures of these models. We include more detailed descriptions in supplementary material Section 4. All the networks closely follow the publicly-known settings and are either pre-trained or trained offline to achieve comparable performance to the real-world models on these datasets.\n\nWe also summarize the safety properties checked by Neurify in Table 1 with timeout threshold set to 3,600 seconds. Here we report the result of the self-driving care model (DAVE) to illustrate how we define the safety properties and the numbers of safe and violated properties found by Neurify. We report the other results in supplementary material Section 5.  Dave. We show that Neurify is the first formal analysis tool that can systematically check different safety properties for a large (over 10,000 ReLUs) convolutional self-driving car network, Dave [2,6]. We use the dataset from Udacity self-driving car challenge containing 101,396 training and 5,614 testing samples [4]. Our model's architecture is similar to the DAVE-2 self-driving car architecture from NVIDIA [6,2] and it achieves similar 1-MSE as models used in [29]. We formally analyze the network with inputs bounded by L \u221e , L 1 , brightness, and contrast as described in Section 3.3. We define the safe range of deviation of the output steering direction from the original steering angle to be less than 30 degrees. The total number of cases Neurify can verify are shown in Table 2. DREBIN. We also evaluate Neurify on three different Drebin models containing 545,334 input features. The safety property we check is that simply adding app permissions without changing any functionality will not cause the models to misclassify malware apps as benign. Here we show in Table 3 that Neurify can formally verify safe and unsafe cases for most of the apps within 3,600 seconds.\n\n\nComparisons with Other Formal Checkers\n\nACAS Xu. Unmanned aircraft alert systems (ACAS Xu) [19] are networks advising steering decisions for aircrafts, which is on schedule to be installed in over 30,000 passengers and cargo aircraft worldwide [26] and US Navy's fleets [1]. It is comparably small and only has five input features so that ReluVal [39] can efficiently check different safety properties. However, its performance still suffers from the over-approximation of output ranges due to the concretizations introduced during symbolic interval analysis. Neurify leverages symbolic linear relaxation and achieves on average 20\u00d7 better performance than ReluVal [39] and up to 5,000\u00d7 better performance than Reluplex [17].\n\nIn Table 4, we summarize the time and speedup of Neurify compared to ReluVal and Reluplex for all the properties tested in [17,39].   MNIST_FC. The MNIST networks have significantly more inputs than ACAS Xu. It has 784 input features and ReluVal always times out when the analyzed input ranges become larger (L \u221e \u2265 5). We measure the performance of Neurify on fully connected MNIST models MNIST_FC1, MNIST_FC2 and MNIST_FC3 and compare the cases that can be verified to be safe or a counterexample can be found by ReluVal and Reluplex in Figure 4. The results show that Neurify constantly outperforms the other two. Especially when increasing the L \u221e bound, the percentages of properties that the other two can verify quickly decrease. Note that the increase in Figure 4b is caused by the more unsafe cases detected by Neurify. Initially, when the bounds are small, Neurify can easily check the properties to be safe. But as the bounds get larger, the number of verified safe cases drop drastically because (i) the underlying model tends to have real violations and (ii) Neurify suffers from relatively higher overestimation errors. However, as the bounds increase further, the counterexamples become frequent enough to be easily found by Neurify. Therefore, such phenomenon indicates that Neurify can find counterexamples more effectively than ReluVal and Reluplex due to its tighter approximation. Symbolic Linear Relaxation (SLR). We compare the widths of estimated output ranges computed by naive interval arithmetic [39] and symbolic linear relaxation on MNIST_FC1, MNIST_FC2, MNIST_FC3. We summarize the average output widths in Table 5. The experiments are based on 100 images each bounded by L \u221e \u2264 ( = 1, ..., 25). The results indicate that SLR in Neurify can tighten the output intervals by at least 100% over naive interval arithmetic, which significantly speeds up its performance. Directed Constraint Refinement (DCR). To illustrate how DCR can improve the overall performance when combined with SLR, we evaluate Neurify on MNIST_CN and measure the number of timeout cases out of 100 randomly selected input images when using symbolic linear relaxation alone and combining it with directed constraint refinement. Table 6 shows that SLR combined with DCR can verify 18.88% more cases on average than those using SLR alone.\n\n\nBenefits of Each Technique\n\nImprovements Evaluated on MNIST. We evaluate how symbolic linear relaxation and directed constraint refinement each can improve the performance compared with Relu-Val on three fully connected MNIST models, MNIST_FC1, MNIST_FC2, and MNIST_FC3. For measuring the improvement made by symbolic linear relaxation, we integrate it into Relu-Val denoted as ReluVal+SLR (input bisection + symbolic linear relaxation) and we compare with the number of original ReluVal (input bisection + symbolic interval analysis). As for the performance of directed constraint refinement, we make comparisons between ReluVal+SLR (input bisection + symbolic linear relaxation) and Neurify (directed constraint refinement + symbolic linear relaxation). We summarize the total cases that can be verified by Neurify, original ReluVal, and ReluVal+SLR out of 100 random MNIST images within 600 seconds in Figure 5. The safety properties are defined as whether the models will misclassify the images within allowable perturbed input ranges bounded by L \u221e \u2264 ( = 1, ..., 10). The experimental results demonstrate that our symbolic linear approximation can help ReluVal find 15% more cases on average. However, the input bisection used by ReluVal+SLR still suffers from larger number of input features and thus usually times out when is large. Neurify's DCR approach mitigated that problem and additionally verify up to 65% more cases on average compared to ReluVal.\n\n\nConclusion\n\nWe designed and implemented Neurify, an efficient and scalable platform for verifying safety properties of real-world neural networks and providing concrete counterexamples. We propose symbolic linear relaxation to compute a tight over-approximation of a network's output for a given input range and use directed constraint refinement to further refine the bounds using linear solvers. Our extensive empirical results demonstrate that Neurify outperforms state-of-the-art formal analysis systems by several orders of magnitude and can easily scale to networks with more than 10,000 ReLU nodes.\n\n\nAcknowledgements\n\n\nA Proofs\n\n\nA.1 Properties of Overestimated Nodes\n\nBelow we describe and prove some useful properties that overestimated nodes satisfy. Throughout this section, X denotes an input interval range, z = Relu(Eq) denotes an overestimated node, and W denotes a set of overestimated nodes. Furthermore, [l, u] and [Eq low , Equp] represent the concrete and symbolic intervals for each node before ReLU function, respectively. Lastly, we let Eq * be its ground-true equation.\n\nproperty A.1. Given input range X, an overestimated node's (z = Relu(Eq)) concrete upper and lower bounds satisfy u = maxx\u2208X Eq(x) > 0 and l = minx\u2208X Eq(x) < 0.\n\nproof: It suffices to show that \u2203x1, x2 \u2208 X such that Eq(x1) > 0 and Eq(x2) < 0. If Eq are strictly nonnegative on X, then, for any x1 \u2208 X, we have Relu(Eq(x1)) = Eq(x1) and we do not perform any relaxations. Likewise, if Eq are strictly non-positive, then for any x2 \u2208 X, we have Relu(Eq(x2)) = 0, so we also do not need to apply any relaxations. But, we assumed that the node was overestimated, so that there must be \u2203x1 \u2208 X such that Eq(x1) > 0, and \u2203x2 \u2208 X such that Eq(x2) < 0. Therefore, since u = maxx\u2208X Eq(x) \u2265 Eq(x1), and l = minx\u2208X Eq(x) \u2264 Eq(x2), we have l < 0 and u > 0, which is the desired result.\n\nproperty A.2. The symbolic input interval [Eq low , Equp] to a node of the i-th layer satisfies Eq low = Equp = Eq * if there are no overestimated node in the earlier layers.\n\nproof: We prove this inductively over the number of layers in a network. For the base case, we consider the first layer, which is the input layer. The assumption that there is no overestimated node in all previous layers, in this case, is always true, as we define overestimated nodes to occur only when we apply the activation function ReLU. Thus, we have Eq low = Eq * = Equp in this case. Now, suppose that the property holds for inputs up to the i-th layer. We show it consequently holds for inputs to the (i + 1)-th layer. We know, for the j-th node in the i-th layer, that its input is [Eq * j , Eq * j ]. Since we now assume that no nodes in the i-th layer are overestimated nodes, we know that Relu(Eq * j ) = Eq * j or 0. Let yj denote its output and let y denote the vector of outputs in this layer. Then, the output of the j-th node is [yj, yj]. Considering the weights W , one can see that the input for the k-th node of the (i + 1)-th layer is [Eq low , Equp] = [(W y) k , (W y) k ]. Thus, we have Eq low = Equp = Eq * which is exactly the same as the claim. corollary A.1. In a neural network that contains no overestimated node, there is no error in the output layer.\n\nproof: This follows from Property A.2, as it tells us that, for each node, say node j, in the output layer, Eq low = Eq * = Equp. Since this holds for all nodes, there is zero error.\n\nA.2 Symbolic Linear Relaxation lemma A.1. The maximum distances between the approximation given in symbolic linear relaxation as Equation 4 are \u2212uuplup uup\u2212lup for upper bound and \u2212u low l low u low \u2212l low for lower bound.\nRelu(Eq low ) \u2192 u low u low \u2212 l low (Eq low ) Relu(Equp) \u2192 uup uup \u2212 lup (Equp \u2212 lup)(4)\nproof: The distance for upper bound in Equation 4 is:\ndup = uup uup \u2212 lup (Equp \u2212 lup) \u2212 Relu(Equp) = uup uup\u2212lup (Equp \u2212 lup) \u2212 Equp (if 0 \u2264 Equp \u2264 uup) uup uup\u2212lup (Equp \u2212 lup) (if lup \u2264 Equp < 0) \u2264 \u2212uuplup uup \u2212 lup (when Equp = 0)(5)\nThe distance for lower bound in Equation 4 is:\nd low = Relu(Eq low ) \u2212 u low u low \u2212 l low (Eq low ) = Eq low \u2212 u low u low \u2212l low (Eq low ) (if 0 \u2264 Eq low \u2264 u low ) \u2212 u low u low \u2212l low (Eq low ) (if l low \u2264 Eq low < 0)\n\u2264 \u2212 u low l low u low \u2212 l low (when Eq low = l low /Eq low = u low )\n\nproperty A.3. The approximation produced by symbolic linear relaxation Equp and Eq low as Equation 4 has the least maximum distance from the actual output Eq * .\n\nproof: We give the proof for upper and lower symbolic linear relaxation respectively.\n\n(1) Upper symbolic linear relaxation: The maximum distance for upper bound in Equation 4 is m = \u2212ul u\u2212l when Eq(x) = 0 shown in Lemma A.1. If another symbolic linear relaxation that has maximum distance m < m, then it can be written as Relu(Equp) \u2192 k(Equp(x)) + m due to its linearity. To overestimate two points Relu(u) \u2192 k \u00b7 u + m \u2265 u and Relu(l) \u2192 k \u00b7 l \u2265 0, we arrive at the inequality u\u2212m u \u2264 k \u2264 \u2212m l . Consequently, we get m \u2265 \u2212ul u\u2212l , which conflicts with assumption m < m. (2) Lower symbolic linear relaxation: Also shown in Lemma A.1, the maximum distance m = \u2212ul u\u2212l for lower bound equation can be achieved when Eq = l or Eq = u. Assume there is another lower symbolic linear relaxation has the maximum distance m < m, it can be similarly written as Relu(Eq(x)) \u2192\nu+m 1 \u2212m 2 u\u2212l x \u2212 ul+um 1 \u2212lm 2 u\u2212l ,\nwhere Relu(l) \u2192 m 1 < m and Relu(u) \u2192 m 2 < m. To ensure\nRelu(0) \u2192 \u2212 ul+um 1 \u2212lm 2 u\u2212l\n\u2264 0, we see ul + um 1 \u2212 lm 2 \u2265 0, which conflicts with m 1 < m and m 2 < m.\n\nThus, we have shown the claim.\n\nA.3 Directed Constraint Refinement lemma A.2. If there are n overestimated nodes in a neural network, then after applying directed constraint refinement to each of the n nodes, that is, considering 2 n cases after splitting, we achieve a function F satisfying F = F * , where F * is the actual function.\n\nproof: After splitting all the n overestimated nodes, for each split cases, all the nodes are constrained to be linear and thus there is no overestimated node. According to Corollary A.1, we can see there is no error in the output layer for each case. The output union F of these 2 n cases is an approximation of the network without any overestimation error, which is exactly the same as the actual function F * .\n\n\nB Detailed Study of Symbolic Linear Relaxation\n\nAs we have shown before in Section 3 of the paper, the insight of symbolic linear relaxation is in finding the tightest possible linear bounds of the ReLU function and therefore minimizing the overestimation error while approximating network outputs. Note that overestimated nodes in different layers will have different approximation errors depending on the symbolic intervals that they were given as input. For layers before n0-th layer, the one in which the first overestimated nodes occur, symbolic lower and upper bounds will be the same for all nodes. This is shown in Property A.2, and makes the approximations in earlier layers a straightforward computation. However, the expressions of lower and upper symbolic bounds can be much more complicated in deeper layers where the presence of overestimated nodes becomes more frequent. To address this problem, we discuss and illustrate how symbolic linear relaxation works in detail below.\n\nWe consider an arbitrary overestimated node A, with equation given by z = Relu(Eq), where its input Eq is kept as a symbolic interval [Eq low , Equp]. Furthermore, we let n0 denote the first layer in which overestimated nodes occur, let nA denote the layer overestimated node A appears in, and let (l low , u low ) and (lup, uup) denote the concrete lower and upper bound of A's symbolic bounds Eq low and Equp. We consider several cases for the symbolic linear relaxations on A, depending on where it appears in relation to n0.\n\na. nA = n0 : If A is an overestimated node in n0, then, according to Property A.2, we see that A's input equation Eq satisfies Eq low = Equp = Eq. Furthermore, due to Property A.1, u = maxx\u2208X Eq(x) > 0 and l = minx\u2208X Eq(x) < 0, A s output can be easily approximated by:\nRelu([Eq, Eq]) \u2192 [ u u \u2212 l Eq, u u \u2212 l (Eq \u2212 l)](7)\nb. nA > n0 : If A is an overestimated node after n0-th layer, possibly its symbolic lower bound equation Eq low is no longer the same as its upper bound equation Equp before relaxation. Though we can still approximate the it as Relu([Eq low , Equp]) \u2192 [ uup uup\u2212l low Eq low , uup uup\u2212l low (Equp \u2212 l low )], this is not the tightest possible bound. Therefore, we consider bounds on Eq low and Equp independently to achieve tighter approximations.\n\nIn details, this process can be divided into following four scenarios shown in Equation 8, each dependent on different value taken by Eq low and Equp.\nRelu([Eq low , Equp]) \u2192 \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f3 [0, uup uup\u2212lup (Equp \u2212 lup)] (l low \u2264 0, lup \u2264 0, u low \u2264 0, uup > 0) [0, Equp] (l low \u2264 0, lup \u2264 0, u low > 0, uup > 0) [ u low u low \u2212l low Eq low , uup uup\u2212lup (Equp \u2212 lup)] (l low \u2264 0, lup > 0, u low \u2264 0, uup > 0) [ u low u low \u2212l low Eq low , Equp] (l low \u2264 0, lup \u2264 0, u low > 0, uup > 0)(8)\nFor instance, consider an overestimated node satisfying the third case that both of Eq low and Equp can take concrete value spanning 0. The maximum error introduced by relaxation according to Equation 7 is \n\n\nC Different Optimization and Implementation Details\n\nIn our initial experiments, we found out that the performance of matrix multiplications is a major determining factor for the overall performance of the symbolic relaxation and interval propagation process. We use the highly optimized OpenBLAS 3 library for matrix multiplications. For solving the linear constraints generated during the directed constraint refinement process, we use lp_solve 5.5 4 . For formally checking non-existence of adversarial images that can be generated by an L-2 norm bounded attacker, it requires us to solve an optimization problem where the constraints are linear but the objective is quadratic. Since lp_solve does not support quadratic objectives yet, Gurobi 8.0.0 5 solver can be further used to handle these attacks..\n\n\nParallelization.\n\nOur directed constraint refinement process is highly parallelizable as it creates an independent set of linear programs that can be solved in parallel. For facilitating this process, Neurify creates a thread pool where each thread solves one set of linear constraints with its own lp_solve instances. However, as the refinement process might be highly uneven for different overestimated nodes, we periodically rebalance the queues of different threads to minimize idle CPU time.\n\nOutward Rounding. One of the side effects of floating point computations is that even minor precision drops on one hidden node can be amplified significantly during propagations. To avoid such issues, we perform outward rounding after every floating point computation, i.e., we always round [x, x] to [ x , x ]. Our current prototype uses 32-bit float arithmetic that can support all of our current safety properties with outward rounding. If needed, the analysis can be easily switched to 64-bit double.  Figure 6: Element-wise matrix multiplications to allow symbolic intervals to propagate through convolutional kernels.\n\nSupporting Convolutional Layers. Models with convolutional layers are often used in computer vision applications. They usually perform matrix multiplications with a convolution kernel as shown in the dash boxes of Figure 6. To allow a symbolic interval to propagate through various convolutional layers, we simply multiply the symbolic interval inputs with the concrete kernels as shown in Figure 6.\n\n\nD Experimental Setup\n\nTo evaluate the performance of Neurify, we tested it with 9 different models, including fully connected ACAS Xu models, three fully connected Drebin models, three fully connected MNIST models, one convolutional MNIST model and one convolutional self-driving car model. The detailed structures of all these models are summarized in Manuscript Table 1 and here we provide the detailed descriptions of each type of model.\n\nACAS Xu. ACAS is crucial aircraft alert systems used for alerting and preventing aircraft collisions. Its unmanned system ACAS Xu [19] are networks advising decisions for aircraft based on the conditions of intruders and ownships. Due to its powerful abilities, it is on schedule to be installed in over 30,000 passenger and cargo aircraft worldwide [26] and US Navy's fleets [1]. ACAS Xu is made up of 45 different models, each has five inputs, five outputs, six fully connected layers, fifty ReLU nodes in each layer. All the ACAS Xu models and self-defined safety properties we tested are given in [17,16,39].\n\nMNIST_FC. MNIST [21] is a handwritten digit dataset containing 28x28 pixel images with class labels from 0 to 9. The dataset includes 60,000 training samples and 10,000 testing samples. Here we use three different architectures of fully connected MNIST models with accuracies of 96.59%, 97.43%, and 98.27%. The more ReLU nodes the model has, the higher its accuracy is.\n\nDrebin_FC. Drebin [5] is a dataset with 129,013 Android applications among which 123,453 are benign and 5,560 are malicious. Currently, there is a total of 784,544 binary features extracted from each application according to 8 predefined categories [35]. The accuracy for Drebin_FC1, Drebin_FC2 and Drebin_FC3 are 97.61%, 98.53% and 99.01%. We show that compared to input bisection and refinement, directed constraint refinement can be applied on more generalized networks, such as Drebin model with such large amount of input features.\n\nConvNet. ConvNet is a comparably large convolutional MNIST models with about 5000 ReLU nodes used in [42] trained on 60,000 MNIST dataset. Due to its large amounts of ReLU nodes, its safety property can never be supported by the traditional solver-based formal analysis systems such as Reluplex [17].\n\nSelf-driving Car. Finally, we use a large-scale (with over 10,000 ReLU nodes) convolutional autonomous vehicle model, on which no formal proof has been given before. The self-driving car dataset comes from Udacity self-driving car challenge containing 101,396 training and 5,614 testing samples [4]. And we use similar DAVE-2 self-driving car architecture from NVIDIA [6,2] with 3 \u00d7 100 \u00d7 100 inputs and 1 regression output for advisory direction. The detailed structure is shown in Manuscript Table 1. On such model, we have already shown that Neurify can formally prove four different types of safety properties: L\u221e, L1, Brightness and contrast on DAVE in Table 2.\n\n\nE Additional Results\n\nNeurify has either formally verified or provided counterexamples for thousands of safety properties, and we summarize the additional primary properties Neurify can provide on different models in the first subsection in details. Note that the results of DAVE can be found in Manuscript Section 4.\n\n\nE.1 Cases verified by Neurify for Each Model\n\nConvNet. We evaluate Neurify on ConvNet, a large convolutional MNIST model. To the best of our knowledge, none of traditional solver-based formal analysis systems can give formal guarantee for such large convolutional MNIST network. However, Neurify is able to verify most of the properties within L\u221e \u2264 5. We define the safety property as whether the model will misclassify MNIST images within allowable input ranges bounded by L\u221e \u2264 ( = 1, ..., 25). The results are shown in Table 7. The timeout setting here is 3600 seconds. MNIST_FC. We also evaluate Neurify on three different fully connected MNIST models. The property is defined as whether the image will be misclassified with allowable perturbed input ranges bounded by L\u221e \u2264 ( = 1, ..., 15). In Table 8, we show the cases that Neurify can formally verify to be safe or find concrete counterexamples on out of 100 random images from MNIST dataset within 3600 seconds.  \n\n\nE.2 Benefits of Each Technique\n\nWe have described the benefits of our two main techniques, symbolic linear relaxation (SLR) and directed constraint refinement (DCR) in Section 4 of the paper. Here, we describe additional experimental results for illustrating the benefits of each technique used in Neurify.\n\nBenefits of Depths in Refinement. The process of directed constraint refinement is a DFS search tree and each iteration of refinement will generate two subtrees and thus increase one depth of whole DFS tree. We summarize the formal analysis time on 37 ACAS Xu cases and 60 MNIST cases in terms of average and maximal depth of the directed constraint refinement search tree in Figure 7. The results indicate that formal analysis time is exponential to maximum and average depth. Therefore, in practice, we can leverage depths to estimate the whole formal analysis progress.  Figure 8: Neurify's ability to locate concrete counterexamples compared to CW attacks with 5, 10, 20 random input seeds. We evaluate on MNIST_FC1, MNIST_FC2, MNIST_FC3, with 60 different safety properties that have been verified to be violated by Neurify.\n\n\nCounterexamples\n\nBenefits of Adversarial Searching Ability. We show that Neurify has stronger ability to find counterexamples compared with current state-of-the-art gradient-based attack CW. Out of 60 violated cases found by Neurify on MNIST_FC1, MNIST_FC2, MNIST_FC3, CW attacks can only locate 47%, 46% and 43% with 20, 10 and 5 random input seeds, shown in Figure 8.\n\nFigure 1 :\n1Linear relaxation of a ReLU node.\n\nFigure 2 :\n2Workflow of Neurify to formally analyze safety properties of neural networks.\n\nFigure 3 :\n3An illustration of symbolic linear relaxation for an intermediate node. (a) Original symbolic interval analysis [39] used naive concretization. (b) Symbolic linear relaxation leverages the knowledge of concrete bounds for z and computes relaxed symbolic interval. Eq is the symbolic representation of z .\n\n\nContrast: X \u2264 X \u2264 X or X \u2264 X \u2264 X\n\nFigure 4 :\n4As we increase the L \u221e bounds of the safety properties, the number of cases ReluVal and Reluplex can verify quickly decreases while Neurify clearly outperforms both of them. We use 50 randomly selected imaged for each property and set the timeout to 1,200 seconds.\n\nFigure 5 :\n5Showing the cases out of 100 randomly selected images that can be verified by Neurify, new ReluVal+SLR and original ReluVal. Here ReluVal+SLR denotes the new ReluVal improved with our symbolic linear relaxation for showing the performance of DCR. The timeout setting is 600 seconds.\n\n\nl low , while the relaxation by Equation 8 has smaller maximum error max( \u2212uuplup uup\u2212lup , \u2212u low l low u low \u2212l low ). Thus, we can see such case work allows us to have tighter the approximations.\n\nFigure 7 :\n7The relationship between formal analysis time and the corresponding average and maximal refinement depth for 37 ACAS Xu and 60 MNIST safety properties formally verified to be safe by Neurify.\n\nTable 1 :\n1Details of the evaluated networks and corresponding safety properties. The last three columns summarize the number of safety properties that are satisfied, violated, and timed out, respectively as found by Neurify with a timeout threshold of 1 hour.Dataset \nModels \n# of \nReLUs \nArchitecture \nSafety \nProperty \nSafe Violated Timeout \n\nACAS \nXu [16] \nACAS Xu \n300 \n<5, 50, 50, 50, \n50, 50, 50, 5> # \n\nC.P.  *  \nin [39] \n141 \n37 \n0 \n\nMNIST [21] \n\nMNIST_FC1 \n48 \n<784, 24, 24, 10> # \nL\u221e \n267 \n233 \n0 \nMNIST_FC2 100 \n<784, 50, 50, 10> # \nL\u221e \n271 \n194 \n35 \nMNIST_FC3 1024 \n<784, 512, 512, 10> # \nL\u221e \n322 \n41 \n137 \n\nMNIST_CN 4804 \n<784, k:16*4*4 s:2, \nk:32*4*4 s:2, 100, 10> + \nL\u221e \n91 \n476 \n233 \n\nDrebin [5] \n\nDrebin_FC1 \n100 \n<545334, 50, 50, 2> # \nC.P.  *  \nin [29] \n\n458 \n21 \n21 \nDrebin_FC2 \n210 \n<545334, 200, 10, 2> # \n437 \n22 \n41 \nDrebin_FC3 \n400 \n<545334, 200, 200, 2> # \n297 \n27 \n176 \n\nCar [2] \nDAVE \n10276 \n<30000, k:24*5*5 s:5, \nk:36*5*5 s:5, 100, 10> + \n\nL\u221e,L1, \nBrightness, \nContrast \n\n80 \n82 \n58 \n\n* Custom properties. \n# <x, y, ...> denotes hidden layers with x neurons in first layer, y neurons in second layer, etc. \n+ k:c*w*h s:stride denotes the output channel (c), kernel width (w), height (h) and stride (stride). \n\n\n\nTable 2 :\n2Different safety properties checked by Neurify out of 10 random images on Dave within 3600 seconds.\n\nTable 3 :\n3Total cases that can be verified by Neurify on three Drebin models out of 100 random malware apps. The timeout setting here is 3600 seconds.Models \nCases(%) 10 \n50 100 150 200 \n\nDrebin_FC1 \n\nSafe \n0 \n1 \n3 \n5 \n12 \nViolated 100 98 \n97 \n86 \n77 \nTotal \n100 99 100 91 \n89 \n\nDrebin_FC2 \n\nSafe \n0 \n4 \n4 \n6 \n8 \nViolated 100 96 \n90 \n81 \n70 \nTotal \n100 100 94 \n87 \n78 \n\nDrebin_FC3 \n\nSafe \n0 \n4 \n4 \n4 \n15 \nViolated 100 89 \n74 \n23 \n11 \nTotal \n100 93 \n78 \n33 \n26 \n\n\n\nTable 4 :\n4Performance comparisons of Neurify, Reluplex, and ReluVal while checking different safety properties of ACAS Xu. \u03c6 1 to \u03c6 10 are the properties tested in[17]. \u03c6 11 to \u03c6 15 are the additional properties tested in[39]. Reluplex uses different timeout thresholds for different properties.** Reluplex returns spurious counterexamples on two safe networks due to a rounding bug and ends prematurely.Source \nProps Reluplex (sec) ReluVal (sec) Neurify (sec) Reluplex \nN eurif y (\u00d7) \n\nReluV al \n\nN eurif y (\u00d7) \n\nSecurity \nProperties \nfrom [17] \n\n\u03c61 \n>443,560.73* 14,603.27 \n458.75 \n> 967\u00d7 \n31.83\u00d7 \n\u03c6  *  *  \n\n2 \n\n123,420.40 \n117,243.26 \n16491.83 \n>8\u00d7 \n7.11\u00d7 \n\u03c63 \n35,040.28 \n19,018.90 \n600.64 \n58.33\u00d7 \n31.66\u00d7 \n\u03c64 \n13,919.51 \n441.97 \n54.56 \n255\u00d7 \n8.10\u00d7 \n\u03c65 \n23,212.52 \n216.88 \n21.378 \n1086\u00d7 \n10.15\u00d7 \n\u03c66 \n220,330.82 \n46.59 \n1.48 \n148872\u00d7 \n31.48\u00d7 \n\u03c67 \n>86400.00* 9,240.29 \n563.55 \n>154\u00d7 \n16.40\u00d7 \n\u03c68 \n43,200.01 \n40.41 \n33.17 \n1302\u00d7 \n1.22\u00d7 \n\u03c69 \n116,441.97 \n15,639.52 \n921.06 \n126.42\u00d7 \n16.98\u00d7 \n\u03c610 \n23,683.07 \n10.94 \n1.16 \n20416.38\u00d7 \n9.43\u00d7 \n\nAdditional \nSecurity \nProperties \n\n\u03c611 \n4,394.91 \n27.89 \n0.62 \n7089\u00d7 \n44.98\u00d7 \n\u03c612 \n2,556.28 \n0.104 \n0.13 \n19664\u00d7 \n0.80\u00d7 \n\u03c613 >172,800.00* 148.21 \n38.11 \n>4534\u00d7 \n3.89\u00d7 \n\u03c614 >172,810.86* 288.98 \n22.87 \n>7556\u00d7 \n12.64\u00d7 \n\u03c615 \n31,328.26 \n876.8 \n91.71 \n342\u00d7 \n9.56\u00d7 \n* \n\nTable 5 :\n5The average widths of output ranges \nof three MNIST models for 100 random im-\nages where each has five different L \u221e \u2264 \n{1, 5, 10, 15, 25}. \n\nNIA  *  SLR  *  *  Improve(%) \nMNIST_FC1 111.87 52.22 \n114.23 \nMNIST_FC2 230.27 101.72 \n126.38 \nMNIST_FC3 1271.19 624.27 \n103.63 \n* Naive Interval Arithmetic \n** Symbolic Linear Relaxation \n\n\n\nTable 6 :\n6The timeout cases out of 100 random \nimages generated while using symbolic linear re-\nlaxation alone and together with directed con-\nstraint refinement. These results are computed for \nMNIST_CN model with L \u221e \u2264 ( = 1, ..., 25). \nThe last column shows the number of additional \ncases checked while using directed constraint re-\nfinement. \n\nProperties SLR SLR + DCR Improve \n= 1 \n0 \n0 \n0 \n= 2 \n2 \n1 \n1 \n= 3 \n6 \n0 \n6 \n= 4 \n18 \n5 \n13 \n= 5 \n58 \n12 \n46 \n= 10 100 \n90 \n10 \n= 15 100 \n80 \n20 \n= 25 100 \n45 \n55 \n\n\n\n\n[5x,2x] [0,3x] [5x,2x] [0,3x]1 \n0 \n\n0 \n1 \n\n0 \n1 \n\n0 \n1 \n\n[x,x] [2x,x] [x,2x] \n\n[x,x] \n\n[0,x] \n[x,2x] \n\n[4x,0] [3x,0] \n\n[x,2x] [2x,x] \n\n[x,3x] [3x,x] \n\n[2x,x] \n\n\n\nTable 7 :\n7Showing the percentage of images formally verified (safe and violated out of 100 randomly selected images) by Neurify with different safety properties (L \u221e \u2264 ( = 1, ..., 25)) on MNISTConvNet. \nSafe(%) Violated(%) Total(%) \n1 \n100 \n0 \n100 \n2 \n98 \n1 \n99 \n3 \n98 \n2 \n100 \n4 \n93 \n2 \n95 \n5 \n86 \n2 \n88 \n10 \n1 \n9 \n10 \n15 \n0 \n20 \n20 \n25 \n0 \n55 \n55 \n\n\n\nTable 8 :\n8Total cases that can be verified by Neurify on three fully connected MNIST models out of 100 hand-written digits. The timeout setting here is 3600 seconds.Models \nCases \n(%) \n1 \n2 \n5 \n10 \n15 \n\nMNIST_FC1 \n\nViolated 15 \n27 \n29 \n66 \n96 \nSafe \n85 \n73 \n71 \n34 \n4 \nTotal \n100 100 100 100 100 \n\nMNIST_FC2 \n\nViolated \n0 \n11 \n26 \n74 \n83 \nSafe \n100 89 \n68 \n9 \n5 \nTotal \n100 100 94 \n83 \n88 \n\nMNIST_FC3 \n\nViolated \n0 \n4 \n8 \n6 \n23 \nSafe \n96 \n87 \n79 \n33 \n27 \nTotal \n96 \n91 \n87 \n39 \n50 \n\n\nhttps://www.openblas.net/ 2 http://lpsolve.sourceforge.net/5.5/\nhttps://www.openblas.net/ 4 http://lpsolve.sourceforge.net/5.5/ 5 http://www.gurobi.com/\nWe thank the anonymous reviewers for their constructive and valuable feedback. This work is sponsored in part by NSF grants CNS-16-17670, CNS-15-63843, and CNS-15-64055; ONR grants N00014-17-1-2010, N00014-16-1-2263, and N00014-17-1-2788; and a Google Faculty Fellowship. Any opinions, findings, conclusions, or recommendations expressed herein are those of the authors, and do not necessarily reflect those of the US Government, ONR, or NSF.\nNAVAIR plans to install ACAS Xu on MQ-4C fleet. NAVAIR plans to install ACAS Xu on MQ-4C fleet. https://www.flightglobal.com/news/ articles/navair-plans-to-install-acas-xu-on-mq-4c-fleet-444989/.\n\n. Nvidia-Autopilot-Keras, Nvidia-Autopilot-Keras. https://github.com/0bserver07/Nvidia-Autopilot-Keras.\n\nTesla's autopilot was involved in another deadly car crash. Tesla's autopilot was involved in another deadly car crash. https://www.wired.com/story/tesla- autopilot-self-driving-crash-california/.\n\nUsing Deep Learning to Predict Steering Angles. Using Deep Learning to Predict Steering Angles. https://github.com/udacity/self-driving-car.\n\nDrebin: Effective and explainable detection of android malware in your pocket. D Arp, M Spreitzenbarth, M Hubner, H Gascon, K Rieck, C Siemens, Proceedings of the Network and Distributed System Security Symposium. the Network and Distributed System Security Symposium14D. Arp, M. Spreitzenbarth, M. Hubner, H. Gascon, K. Rieck, and C. Siemens. Drebin: Effective and explainable detection of android malware in your pocket. In Proceedings of the Network and Distributed System Security Symposium, volume 14, pages 23-26, 2014.\n\nEnd to end learning for self-driving cars. M Bojarski, D Testa, D Dworakowski, B Firner, B Flepp, P Goyal, L D Jackel, M Monfort, U Muller, J Zhang, IEEE Intelligent Vehicles Symposium. M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp, P. Goyal, L. D. Jackel, M. Monfort, U. Muller, J. Zhang, et al. End to end learning for self-driving cars. IEEE Intelligent Vehicles Symposium, 2017.\n\nOutput range analysis for deep feedforward neural networks. S Dutta, S Jha, S Sankaranarayanan, A Tiwari, NASA Formal Methods Symposium. SpringerS. Dutta, S. Jha, S. Sankaranarayanan, and A. Tiwari. Output range analysis for deep feedforward neural networks. In NASA Formal Methods Symposium, pages 121-138. Springer, 2018.\n\nTraining verified learners with learned verifiers. K Dvijotham, S Gowal, R Stanforth, R Arandjelovic, B O&apos;donoghue, J Uesato, P Kohli, arXiv:1805.10265arXiv preprintK. Dvijotham, S. Gowal, R. Stanforth, R. Arandjelovic, B. O'Donoghue, J. Uesato, and P. Kohli. Training verified learners with learned verifiers. arXiv preprint arXiv:1805.10265, 2018.\n\nA dual approach to scalable verification of deep networks. K Dvijotham, R Stanforth, S Gowal, T Mann, P Kohli, The Conference on Uncertainty in Artificial Intelligence. K. Dvijotham, R. Stanforth, S. Gowal, T. Mann, and P. Kohli. A dual approach to scalable verification of deep networks. The Conference on Uncertainty in Artificial Intelligence, 2018.\n\nFormal verification of piece-wise linear feed-forward neural networks. R Ehlers, 15th International Symposium on Automated Technology for Verification and Analysis. R. Ehlers. Formal verification of piece-wise linear feed-forward neural networks. 15th International Symposium on Automated Technology for Verification and Analysis, 2017.\n\nA polynomial number of random points does not determine the volume of a convex body. R Eldan, Discrete & Computational Geometry. 461R. Eldan. A polynomial number of random points does not determine the volume of a convex body. Discrete & Computational Geometry, 46(1):29-47, 2011.\n\nM Fischetti, J Jo, arXiv:1712.06174Deep neural networks as 0-1 mixed integer linear programs: A feasibility study. arXiv preprintM. Fischetti and J. Jo. Deep neural networks as 0-1 mixed integer linear programs: A feasibility study. arXiv preprint arXiv:1712.06174, 2017.\n\nAi 2: Safety and robustness certification of neural networks with abstract interpretation. T Gehr, M Mirman, D Drachsler-Cohen, P Tsankov, S Chaudhuri, M Vechev, IEEE Symposium on Security and Privacy. T. Gehr, M. Mirman, D. Drachsler-Cohen, P. Tsankov, S. Chaudhuri, and M. Vechev. Ai 2: Safety and robustness certification of neural networks with abstract interpretation. In IEEE Symposium on Security and Privacy, 2018.\n\nExplaining and harnessing adversarial examples. I J Goodfellow, J Shlens, C Szegedy, International Conference on Learning Representations. I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. International Conference on Learning Representations, 2015.\n\nSafety verification of deep neural networks. X Huang, M Kwiatkowska, S Wang, M Wu, International Conference on Computer Aided Verification. SpringerX. Huang, M. Kwiatkowska, S. Wang, and M. Wu. Safety verification of deep neural networks. In International Conference on Computer Aided Verification, pages 3-29. Springer, 2017.\n\nPolicy compression for aircraft collision avoidance systems. K D Julian, J Lopez, J S Brush, M P Owen, M J Kochenderfer, 35th Digital Avionics Systems Conference. IEEEK. D. Julian, J. Lopez, J. S. Brush, M. P. Owen, and M. J. Kochenderfer. Policy compression for aircraft collision avoidance systems. In 35th Digital Avionics Systems Conference, pages 1-10. IEEE, 2016.\n\nReluplex: An efficient smt solver for verifying deep neural networks. G Katz, C Barrett, D Dill, K Julian, M Kochenderfer, International Conference on Computer Aided Verification. G. Katz, C. Barrett, D. Dill, K. Julian, and M. Kochenderfer. Reluplex: An efficient smt solver for verifying deep neural networks. International Conference on Computer Aided Verification, 2017.\n\nG Katz, C Barrett, D L Dill, K Julian, M J Kochenderfer, Towards proving the adversarial robustness of deep neural networks. 1st Workshop on Formal Verification of Autonomous Vehicles. G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J. Kochenderfer. Towards proving the adversarial robustness of deep neural networks. 1st Workshop on Formal Verification of Autonomous Vehicles, 2017.\n\nNext-generation airborne collision avoidance system. M J Kochenderfer, J E Holland, J P Chryssanthacopoulos, Massachusetts Institute of Technology-Lincoln Laboratory Lexington United StatesTechnical reportM. J. Kochenderfer, J. E. Holland, and J. P. Chryssanthacopoulos. Next-generation airborne collision avoidance system. Technical report, Massachusetts Institute of Technology-Lincoln Laboratory Lexington United States, 2012.\n\nUnderstanding black-box predictions via influence functions. P W Koh, P Liang, International Conference on Machine Learning. P. W. Koh and P. Liang. Understanding black-box predictions via influence functions. International Conference on Machine Learning, 2017.\n\nThe mnist database of handwritten digits. Y Lecun, Y. LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/, 1998.\n\nCertified robustness to adversarial examples with differential privacy. M Lecuyer, V Atlidakis, R Geambasu, H Daniel, S Jana, arXiv:1802.03471arXiv preprintM. Lecuyer, V. Atlidakis, R. Geambasu, H. Daniel, and S. Jana. Certified robustness to adversarial examples with differential privacy. arXiv preprint arXiv:1802.03471, 2018.\n\nUnderstanding neural networks through representation erasure. J Li, W Monroe, D Jurafsky, arXiv:1612.08220arXiv preprintJ. Li, W. Monroe, and D. Jurafsky. Understanding neural networks through representation erasure. arXiv preprint arXiv:1612.08220, 2016.\n\nDifferentiable abstract interpretation for provably robust neural networks. M Mirman, T Gehr, M Vechev, International Conference on Machine Learning. M. Mirman, T. Gehr, and M. Vechev. Differentiable abstract interpretation for provably robust neural networks. In International Conference on Machine Learning, pages 3575-3583, 2018.\n\nOn the number of linear regions of deep neural networks. G F Montufar, R Pascanu, K Cho, Y Bengio, Advances in neural information processing systems. G. F. Montufar, R. Pascanu, K. Cho, and Y. Bengio. On the number of linear regions of deep neural networks. In Advances in neural information processing systems, pages 2924-2932, 2014.\n\nAirborne collision avoidance system x. M T Notes, MIT Lincoln LaboratoryM. T. Notes. Airborne collision avoidance system x. MIT Lincoln Laboratory, 2015.\n\nOn the number of response regions of deep feed forward networks with piece-wise linear activations. R Pascanu, G Montufar, Y Bengio, Advances in neural information processing systems. R. Pascanu, G. Montufar, and Y. Bengio. On the number of response regions of deep feed forward networks with piece-wise linear activations. Advances in neural information processing systems, 2013.\n\nLower bounds on the robustness to adversarial perturbations. J Peck, J Roels, B Goossens, Y Saeys, Advances in Neural Information Processing Systems. J. Peck, J. Roels, B. Goossens, and Y. Saeys. Lower bounds on the robustness to adversarial perturbations. In Advances in Neural Information Processing Systems, pages 804-813, 2017.\n\nDeepxplore: Automated whitebox testing of deep learning systems. K Pei, Y Cao, J Yang, S Jana, 26th Symposium on Operating Systems Principles. ACMK. Pei, Y. Cao, J. Yang, and S. Jana. Deepxplore: Automated whitebox testing of deep learning systems. In 26th Symposium on Operating Systems Principles, pages 1-18. ACM, 2017.\n\nTowards practical verification of machine learning: The case of computer vision systems. K Pei, Y Cao, J Yang, S Jana, arXiv:1712.01785arXiv preprintK. Pei, Y. Cao, J. Yang, and S. Jana. Towards practical verification of machine learning: The case of computer vision systems. arXiv preprint arXiv:1712.01785, 2017.\n\nAn abstraction-refinement approach to verification of artificial neural networks. L Pulina, A Tacchella, International Conference on Computer Aided Verification. SpringerL. Pulina and A. Tacchella. An abstraction-refinement approach to verification of artificial neural networks. In International Conference on Computer Aided Verification, pages 243-257. Springer, 2010.\n\nA Raghunathan, J Steinhardt, P Liang, Certified defenses against adversarial examples. International Conference on Learning Representations. A. Raghunathan, J. Steinhardt, and P. Liang. Certified defenses against adversarial examples. International Conference on Learning Representations, 2018.\n\n. M J C E Ramon, R Moore, Baker, Kearfott, Introduction to Interval Analysis. SIAMM. J. C. Ramon E. Moore, R. Baker Kearfott. Introduction to Interval Analysis. SIAM, 2009.\n\nLearning important features through propagating activation differences. A Shrikumar, P Greenside, A Kundaje, International Conference on Machine Learning. A. Shrikumar, P. Greenside, and A. Kundaje. Learning important features through propagating activation differences. International Conference on Machine Learning, 2017.\n\nMobile-sandbox: having a deeper look into android applications. M Spreitzenbarth, F Freiling, F Echtler, T Schreck, J Hoffmann, 28th Annual ACM Symposium on Applied Computing. ACMM. Spreitzenbarth, F. Freiling, F. Echtler, T. Schreck, and J. Hoffmann. Mobile-sandbox: having a deeper look into android applications. In 28th Annual ACM Symposium on Applied Computing, pages 1808-1815. ACM, 2013.\n\nC Szegedy, W Zaremba, I Sutskever, J Bruna, D Erhan, I Goodfellow, R Fergus, Intriguing properties of neural networks. International Conference on Learning Representations. C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing properties of neural networks. International Conference on Learning Representations, 2013.\n\nDeepTest: Automated testing of deep-neural-network-driven autonomous cars. Y Tian, K Pei, S Jana, B Ray, 40th International Conference on Software Engineering. Y. Tian, K. Pei, S. Jana, and B. Ray. DeepTest: Automated testing of deep-neural-network-driven autonomous cars. In 40th International Conference on Software Engineering, 2018.\n\nEvaluating robustness of neural networks with mixed integer programming. V Tjeng, K Xiao, R Tedrake, arXiv:1711.07356arXiv preprintV. Tjeng, K. Xiao, and R. Tedrake. Evaluating robustness of neural networks with mixed integer program- ming. arXiv preprint arXiv:1711.07356, 2017.\n\nFormal security analysis of neural networks using symbolic intervals. S Wang, K Pei, W Justin, J Yang, S Jana, 27th USENIX Security Symposium. S. Wang, K. Pei, W. Justin, J. Yang, and S. Jana. Formal security analysis of neural networks using symbolic intervals. 27th USENIX Security Symposium, 2018.\n\nT.-W Weng, H Zhang, H Chen, Z Song, C.-J Hsieh, D Boning, I S Dhillon, L Daniel, arXiv:1804.09699Towards fast computation of certified robustness for relu networks. arXiv preprintT.-W. Weng, H. Zhang, H. Chen, Z. Song, C.-J. Hsieh, D. Boning, I. S. Dhillon, and L. Daniel. Towards fast computation of certified robustness for relu networks. arXiv preprint arXiv:1804.09699, 2018.\n\nEvaluating the robustness of neural networks: An extreme value theory approach. T.-W Weng, H Zhang, P.-Y Chen, J Yi, D Su, Y Gao, C.-J Hsieh, L Daniel, International Conference on Learning Representations. T.-W. Weng, H. Zhang, P.-Y. Chen, J. Yi, D. Su, Y. Gao, C.-J. Hsieh, and L. Daniel. Evaluating the robustness of neural networks: An extreme value theory approach. International Conference on Learning Representations, 2018.\n\nE Wong, J Z Kolter, Provable defenses against adversarial examples via the convex outer adversarial polytope. International Conference on Machine Learning. E. Wong and J. Z. Kolter. Provable defenses against adversarial examples via the convex outer adversarial polytope. International Conference on Machine Learning, 2018.\n\nScaling provable adversarial defenses. E Wong, F Schmidt, J H Metzen, J Z Kolter, Advances in Neural Information Processing Systems. E. Wong, F. Schmidt, J. H. Metzen, and J. Z. Kolter. Scaling provable adversarial defenses. Advances in Neural Information Processing Systems, 2018.\n\nEfficient neural network robustness certification with general activation functions. H Zhang, T.-W Weng, P.-Y Chen, C.-J Hsieh, L Daniel, Advances in Neural Information Processing Systems. H. Zhang, T.-W. Weng, P.-Y. Chen, C.-J. Hsieh, and L. Daniel. Efficient neural network robustness certification with general activation functions. Advances in Neural Information Processing Systems, 2018.\n", "annotations": {"author": "[{\"end\":129,\"start\":55},{\"end\":196,\"start\":130},{\"end\":250,\"start\":197},{\"end\":323,\"start\":251},{\"end\":370,\"start\":324}]", "publisher": null, "author_last_name": "[{\"end\":65,\"start\":61},{\"end\":139,\"start\":136},{\"end\":214,\"start\":204},{\"end\":263,\"start\":259},{\"end\":334,\"start\":330}]", "author_first_name": "[{\"end\":60,\"start\":55},{\"end\":135,\"start\":130},{\"end\":203,\"start\":197},{\"end\":258,\"start\":251},{\"end\":329,\"start\":324}]", "author_affiliation": "[{\"end\":128,\"start\":95},{\"end\":195,\"start\":162},{\"end\":249,\"start\":216},{\"end\":322,\"start\":289},{\"end\":369,\"start\":336}]", "title": "[{\"end\":52,\"start\":1},{\"end\":422,\"start\":371}]", "venue": null, "abstract": "[{\"end\":2176,\"start\":424}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2750,\"start\":2746},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2753,\"start\":2750},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2927,\"start\":2923},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2930,\"start\":2927},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":2933,\"start\":2930},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3162,\"start\":3159},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4208,\"start\":4204},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4211,\"start\":4208},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4515,\"start\":4511},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6033,\"start\":6029},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6059,\"start\":6055},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6279,\"start\":6275},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6282,\"start\":6279},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6357,\"start\":6353},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6360,\"start\":6357},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6363,\"start\":6360},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6540,\"start\":6536},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6543,\"start\":6540},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6546,\"start\":6543},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6549,\"start\":6546},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6552,\"start\":6549},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6658,\"start\":6654},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6661,\"start\":6658},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6663,\"start\":6661},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":7158,\"start\":7154},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7161,\"start\":7158},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7164,\"start\":7161},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7166,\"start\":7164},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7314,\"start\":7310},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7317,\"start\":7314},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7364,\"start\":7360},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7510,\"start\":7506},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7942,\"start\":7938},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7944,\"start\":7942},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7947,\"start\":7944},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8006,\"start\":8002},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8220,\"start\":8216},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8255,\"start\":8251},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8501,\"start\":8497},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8675,\"start\":8671},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8678,\"start\":8675},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8821,\"start\":8817},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8824,\"start\":8821},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8896,\"start\":8892},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":9274,\"start\":9270},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10233,\"start\":10229},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11073,\"start\":11069},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11851,\"start\":11847},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12317,\"start\":12313},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12320,\"start\":12317},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":12323,\"start\":12320},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12326,\"start\":12323},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12959,\"start\":12955},{\"end\":14495,\"start\":14489},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14621,\"start\":14617},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":17820,\"start\":17816},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21216,\"start\":21212},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21549,\"start\":21545},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23252,\"start\":23248},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23293,\"start\":23290},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23334,\"start\":23330},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":23370,\"start\":23366},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":23420,\"start\":23417},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":24302,\"start\":24299},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":24304,\"start\":24302},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":24422,\"start\":24419},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":24519,\"start\":24516},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":24521,\"start\":24519},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24574,\"start\":24570},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":25383,\"start\":25379},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25536,\"start\":25532},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":25561,\"start\":25558},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":25639,\"start\":25635},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":25957,\"start\":25953},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26012,\"start\":26008},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26142,\"start\":26138},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":26145,\"start\":26142},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27540,\"start\":27536},{\"end\":38437,\"start\":38427},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":41959,\"start\":41955},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":42179,\"start\":42175},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":42204,\"start\":42201},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":42430,\"start\":42426},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":42433,\"start\":42430},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":42436,\"start\":42433},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":42459,\"start\":42455},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":42831,\"start\":42828},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":43063,\"start\":43059},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":43453,\"start\":43449},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":43647,\"start\":43643},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":43948,\"start\":43945},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":44021,\"start\":44018},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":44023,\"start\":44021},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":45133,\"start\":45130},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":50582,\"start\":50578},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":50640,\"start\":50636}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":47168,\"start\":47122},{\"attributes\":{\"id\":\"fig_1\"},\"end\":47259,\"start\":47169},{\"attributes\":{\"id\":\"fig_3\"},\"end\":47577,\"start\":47260},{\"attributes\":{\"id\":\"fig_4\"},\"end\":47612,\"start\":47578},{\"attributes\":{\"id\":\"fig_6\"},\"end\":47890,\"start\":47613},{\"attributes\":{\"id\":\"fig_7\"},\"end\":48186,\"start\":47891},{\"attributes\":{\"id\":\"fig_8\"},\"end\":48387,\"start\":48187},{\"attributes\":{\"id\":\"fig_9\"},\"end\":48592,\"start\":48388},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":49835,\"start\":48593},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":49947,\"start\":49836},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":50412,\"start\":49948},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":51713,\"start\":50413},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":52059,\"start\":51714},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":52575,\"start\":52060},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":52738,\"start\":52576},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":53092,\"start\":52739},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":53578,\"start\":53093}]", "paragraph": "[{\"end\":3163,\"start\":2192},{\"end\":3839,\"start\":3165},{\"end\":4516,\"start\":3841},{\"end\":5608,\"start\":4518},{\"end\":6060,\"start\":5610},{\"end\":6364,\"start\":6062},{\"end\":6794,\"start\":6366},{\"end\":8180,\"start\":6796},{\"end\":8626,\"start\":8182},{\"end\":8842,\"start\":8641},{\"end\":10162,\"start\":8844},{\"end\":10545,\"start\":10164},{\"end\":12075,\"start\":10642},{\"end\":13961,\"start\":12165},{\"end\":15783,\"start\":13992},{\"end\":16350,\"start\":15914},{\"end\":16789,\"start\":16352},{\"end\":16936,\"start\":16791},{\"end\":17274,\"start\":16990},{\"end\":17485,\"start\":17276},{\"end\":17537,\"start\":17487},{\"end\":18087,\"start\":17539},{\"end\":18289,\"start\":18089},{\"end\":18595,\"start\":18386},{\"end\":19397,\"start\":18620},{\"end\":19807,\"start\":19587},{\"end\":20307,\"start\":19809},{\"end\":21777,\"start\":20329},{\"end\":22111,\"start\":21830},{\"end\":22256,\"start\":22188},{\"end\":22959,\"start\":22272},{\"end\":23740,\"start\":23008},{\"end\":25285,\"start\":23742},{\"end\":26013,\"start\":25328},{\"end\":28348,\"start\":26015},{\"end\":29813,\"start\":28379},{\"end\":30421,\"start\":29828},{\"end\":30910,\"start\":30493},{\"end\":31072,\"start\":30912},{\"end\":31685,\"start\":31074},{\"end\":31861,\"start\":31687},{\"end\":33045,\"start\":31863},{\"end\":33229,\"start\":33047},{\"end\":33453,\"start\":33231},{\"end\":33596,\"start\":33543},{\"end\":33827,\"start\":33781},{\"end\":34070,\"start\":34002},{\"end\":34233,\"start\":34072},{\"end\":34320,\"start\":34235},{\"end\":35098,\"start\":34322},{\"end\":35194,\"start\":35138},{\"end\":35300,\"start\":35225},{\"end\":35332,\"start\":35302},{\"end\":35637,\"start\":35334},{\"end\":36052,\"start\":35639},{\"end\":37045,\"start\":36103},{\"end\":37575,\"start\":37047},{\"end\":37846,\"start\":37577},{\"end\":38346,\"start\":37899},{\"end\":38498,\"start\":38348},{\"end\":39046,\"start\":38840},{\"end\":39855,\"start\":39102},{\"end\":40354,\"start\":39876},{\"end\":40979,\"start\":40356},{\"end\":41380,\"start\":40981},{\"end\":41823,\"start\":41405},{\"end\":42437,\"start\":41825},{\"end\":42808,\"start\":42439},{\"end\":43346,\"start\":42810},{\"end\":43648,\"start\":43348},{\"end\":44316,\"start\":43650},{\"end\":44636,\"start\":44341},{\"end\":45609,\"start\":44685},{\"end\":45918,\"start\":45644},{\"end\":46749,\"start\":45920},{\"end\":47121,\"start\":46769}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10641,\"start\":10546},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12153,\"start\":12076},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15880,\"start\":15784},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16989,\"start\":16937},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18385,\"start\":18290},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18619,\"start\":18596},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19586,\"start\":19398},{\"attributes\":{\"id\":\"formula_7\"},\"end\":21829,\"start\":21778},{\"attributes\":{\"id\":\"formula_8\"},\"end\":22187,\"start\":22112},{\"attributes\":{\"id\":\"formula_9\"},\"end\":33542,\"start\":33454},{\"attributes\":{\"id\":\"formula_10\"},\"end\":33780,\"start\":33597},{\"attributes\":{\"id\":\"formula_11\"},\"end\":34001,\"start\":33828},{\"attributes\":{\"id\":\"formula_13\"},\"end\":35137,\"start\":35099},{\"attributes\":{\"id\":\"formula_14\"},\"end\":35224,\"start\":35195},{\"attributes\":{\"id\":\"formula_15\"},\"end\":37898,\"start\":37847},{\"attributes\":{\"id\":\"formula_16\"},\"end\":38839,\"start\":38499}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":7477,\"start\":7469},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":23429,\"start\":23422},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":23811,\"start\":23804},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24894,\"start\":24887},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":25187,\"start\":25180},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26025,\"start\":26018},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":27657,\"start\":27650},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":28247,\"start\":28240},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":41754,\"start\":41747},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":44151,\"start\":44144},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":44315,\"start\":44308},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":45167,\"start\":45160},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":45443,\"start\":45436}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2190,\"start\":2178},{\"attributes\":{\"n\":\"2\"},\"end\":8639,\"start\":8629},{\"attributes\":{\"n\":\"3\"},\"end\":12163,\"start\":12155},{\"attributes\":{\"n\":\"3.1\"},\"end\":13990,\"start\":13964},{\"attributes\":{\"n\":\"3.2\"},\"end\":15912,\"start\":15882},{\"attributes\":{\"n\":\"3.3\"},\"end\":20327,\"start\":20310},{\"attributes\":{\"n\":\"4\"},\"end\":22270,\"start\":22259},{\"attributes\":{\"n\":\"4.1\"},\"end\":23006,\"start\":22962},{\"attributes\":{\"n\":\"4.2\"},\"end\":25326,\"start\":25288},{\"attributes\":{\"n\":\"4.3\"},\"end\":28377,\"start\":28351},{\"attributes\":{\"n\":\"5\"},\"end\":29826,\"start\":29816},{\"attributes\":{\"n\":\"6\"},\"end\":30440,\"start\":30424},{\"end\":30451,\"start\":30443},{\"end\":30491,\"start\":30454},{\"end\":36101,\"start\":36055},{\"end\":39100,\"start\":39049},{\"end\":39874,\"start\":39858},{\"end\":41403,\"start\":41383},{\"end\":44339,\"start\":44319},{\"end\":44683,\"start\":44639},{\"end\":45642,\"start\":45612},{\"end\":46767,\"start\":46752},{\"end\":47133,\"start\":47123},{\"end\":47180,\"start\":47170},{\"end\":47271,\"start\":47261},{\"end\":47624,\"start\":47614},{\"end\":47902,\"start\":47892},{\"end\":48399,\"start\":48389},{\"end\":48603,\"start\":48594},{\"end\":49846,\"start\":49837},{\"end\":49958,\"start\":49949},{\"end\":50423,\"start\":50414},{\"end\":51724,\"start\":51715},{\"end\":52070,\"start\":52061},{\"end\":52749,\"start\":52740},{\"end\":53103,\"start\":53094}]", "table": "[{\"end\":49835,\"start\":48854},{\"end\":50412,\"start\":50100},{\"end\":51713,\"start\":50819},{\"end\":52059,\"start\":51726},{\"end\":52575,\"start\":52072},{\"end\":52738,\"start\":52607},{\"end\":53092,\"start\":52934},{\"end\":53578,\"start\":53260}]", "figure_caption": "[{\"end\":47168,\"start\":47135},{\"end\":47259,\"start\":47182},{\"end\":47577,\"start\":47273},{\"end\":47612,\"start\":47580},{\"end\":47890,\"start\":47626},{\"end\":48186,\"start\":47904},{\"end\":48387,\"start\":48189},{\"end\":48592,\"start\":48401},{\"end\":48854,\"start\":48605},{\"end\":49947,\"start\":49848},{\"end\":50100,\"start\":49960},{\"end\":50819,\"start\":50425},{\"end\":52607,\"start\":52578},{\"end\":52934,\"start\":52751},{\"end\":53260,\"start\":53105}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11489,\"start\":11481},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12999,\"start\":12991},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14016,\"start\":14006},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14505,\"start\":14497},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15174,\"start\":15166},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15319,\"start\":15311},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20305,\"start\":20297},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26561,\"start\":26553},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26786,\"start\":26777},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":27736,\"start\":27719},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":29264,\"start\":29256},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":29422,\"start\":29405},{\"end\":40870,\"start\":40862},{\"end\":41203,\"start\":41195},{\"end\":41379,\"start\":41371},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":46304,\"start\":46296},{\"end\":46502,\"start\":46494},{\"end\":47120,\"start\":47112}]", "bib_author_first_name": "[{\"end\":54897,\"start\":54896},{\"end\":54904,\"start\":54903},{\"end\":54922,\"start\":54921},{\"end\":54932,\"start\":54931},{\"end\":54942,\"start\":54941},{\"end\":54951,\"start\":54950},{\"end\":55388,\"start\":55387},{\"end\":55400,\"start\":55399},{\"end\":55409,\"start\":55408},{\"end\":55424,\"start\":55423},{\"end\":55434,\"start\":55433},{\"end\":55443,\"start\":55442},{\"end\":55452,\"start\":55451},{\"end\":55454,\"start\":55453},{\"end\":55464,\"start\":55463},{\"end\":55475,\"start\":55474},{\"end\":55485,\"start\":55484},{\"end\":55806,\"start\":55805},{\"end\":55815,\"start\":55814},{\"end\":55822,\"start\":55821},{\"end\":55842,\"start\":55841},{\"end\":56122,\"start\":56121},{\"end\":56135,\"start\":56134},{\"end\":56144,\"start\":56143},{\"end\":56157,\"start\":56156},{\"end\":56173,\"start\":56172},{\"end\":56192,\"start\":56191},{\"end\":56202,\"start\":56201},{\"end\":56486,\"start\":56485},{\"end\":56499,\"start\":56498},{\"end\":56512,\"start\":56511},{\"end\":56521,\"start\":56520},{\"end\":56529,\"start\":56528},{\"end\":56852,\"start\":56851},{\"end\":57204,\"start\":57203},{\"end\":57401,\"start\":57400},{\"end\":57414,\"start\":57413},{\"end\":57765,\"start\":57764},{\"end\":57773,\"start\":57772},{\"end\":57783,\"start\":57782},{\"end\":57802,\"start\":57801},{\"end\":57813,\"start\":57812},{\"end\":57826,\"start\":57825},{\"end\":58146,\"start\":58145},{\"end\":58148,\"start\":58147},{\"end\":58162,\"start\":58161},{\"end\":58172,\"start\":58171},{\"end\":58436,\"start\":58435},{\"end\":58445,\"start\":58444},{\"end\":58460,\"start\":58459},{\"end\":58468,\"start\":58467},{\"end\":58780,\"start\":58779},{\"end\":58782,\"start\":58781},{\"end\":58792,\"start\":58791},{\"end\":58801,\"start\":58800},{\"end\":58803,\"start\":58802},{\"end\":58812,\"start\":58811},{\"end\":58814,\"start\":58813},{\"end\":58822,\"start\":58821},{\"end\":58824,\"start\":58823},{\"end\":59160,\"start\":59159},{\"end\":59168,\"start\":59167},{\"end\":59179,\"start\":59178},{\"end\":59187,\"start\":59186},{\"end\":59197,\"start\":59196},{\"end\":59466,\"start\":59465},{\"end\":59474,\"start\":59473},{\"end\":59485,\"start\":59484},{\"end\":59487,\"start\":59486},{\"end\":59495,\"start\":59494},{\"end\":59505,\"start\":59504},{\"end\":59507,\"start\":59506},{\"end\":59907,\"start\":59906},{\"end\":59909,\"start\":59908},{\"end\":59925,\"start\":59924},{\"end\":59927,\"start\":59926},{\"end\":59938,\"start\":59937},{\"end\":59940,\"start\":59939},{\"end\":60346,\"start\":60345},{\"end\":60348,\"start\":60347},{\"end\":60355,\"start\":60354},{\"end\":60590,\"start\":60589},{\"end\":60767,\"start\":60766},{\"end\":60778,\"start\":60777},{\"end\":60791,\"start\":60790},{\"end\":60803,\"start\":60802},{\"end\":60813,\"start\":60812},{\"end\":61088,\"start\":61087},{\"end\":61094,\"start\":61093},{\"end\":61104,\"start\":61103},{\"end\":61359,\"start\":61358},{\"end\":61369,\"start\":61368},{\"end\":61377,\"start\":61376},{\"end\":61674,\"start\":61673},{\"end\":61676,\"start\":61675},{\"end\":61688,\"start\":61687},{\"end\":61699,\"start\":61698},{\"end\":61706,\"start\":61705},{\"end\":61992,\"start\":61991},{\"end\":61994,\"start\":61993},{\"end\":62208,\"start\":62207},{\"end\":62219,\"start\":62218},{\"end\":62231,\"start\":62230},{\"end\":62551,\"start\":62550},{\"end\":62559,\"start\":62558},{\"end\":62568,\"start\":62567},{\"end\":62580,\"start\":62579},{\"end\":62888,\"start\":62887},{\"end\":62895,\"start\":62894},{\"end\":62902,\"start\":62901},{\"end\":62910,\"start\":62909},{\"end\":63236,\"start\":63235},{\"end\":63243,\"start\":63242},{\"end\":63250,\"start\":63249},{\"end\":63258,\"start\":63257},{\"end\":63545,\"start\":63544},{\"end\":63555,\"start\":63554},{\"end\":63835,\"start\":63834},{\"end\":63850,\"start\":63849},{\"end\":63864,\"start\":63863},{\"end\":64133,\"start\":64132},{\"end\":64139,\"start\":64134},{\"end\":64148,\"start\":64147},{\"end\":64377,\"start\":64376},{\"end\":64390,\"start\":64389},{\"end\":64403,\"start\":64402},{\"end\":64693,\"start\":64692},{\"end\":64711,\"start\":64710},{\"end\":64723,\"start\":64722},{\"end\":64734,\"start\":64733},{\"end\":64745,\"start\":64744},{\"end\":65025,\"start\":65024},{\"end\":65036,\"start\":65035},{\"end\":65047,\"start\":65046},{\"end\":65060,\"start\":65059},{\"end\":65069,\"start\":65068},{\"end\":65078,\"start\":65077},{\"end\":65092,\"start\":65091},{\"end\":65464,\"start\":65463},{\"end\":65472,\"start\":65471},{\"end\":65479,\"start\":65478},{\"end\":65487,\"start\":65486},{\"end\":65800,\"start\":65799},{\"end\":65809,\"start\":65808},{\"end\":65817,\"start\":65816},{\"end\":66078,\"start\":66077},{\"end\":66086,\"start\":66085},{\"end\":66093,\"start\":66092},{\"end\":66103,\"start\":66102},{\"end\":66111,\"start\":66110},{\"end\":66313,\"start\":66309},{\"end\":66321,\"start\":66320},{\"end\":66330,\"start\":66329},{\"end\":66338,\"start\":66337},{\"end\":66349,\"start\":66345},{\"end\":66358,\"start\":66357},{\"end\":66368,\"start\":66367},{\"end\":66370,\"start\":66369},{\"end\":66381,\"start\":66380},{\"end\":66774,\"start\":66770},{\"end\":66782,\"start\":66781},{\"end\":66794,\"start\":66790},{\"end\":66802,\"start\":66801},{\"end\":66808,\"start\":66807},{\"end\":66814,\"start\":66813},{\"end\":66824,\"start\":66820},{\"end\":66833,\"start\":66832},{\"end\":67122,\"start\":67121},{\"end\":67130,\"start\":67129},{\"end\":67132,\"start\":67131},{\"end\":67486,\"start\":67485},{\"end\":67494,\"start\":67493},{\"end\":67505,\"start\":67504},{\"end\":67507,\"start\":67506},{\"end\":67517,\"start\":67516},{\"end\":67519,\"start\":67518},{\"end\":67815,\"start\":67814},{\"end\":67827,\"start\":67823},{\"end\":67838,\"start\":67834},{\"end\":67849,\"start\":67845},{\"end\":67858,\"start\":67857}]", "bib_author_last_name": "[{\"end\":54396,\"start\":54374},{\"end\":54901,\"start\":54898},{\"end\":54919,\"start\":54905},{\"end\":54929,\"start\":54923},{\"end\":54939,\"start\":54933},{\"end\":54948,\"start\":54943},{\"end\":54959,\"start\":54952},{\"end\":55397,\"start\":55389},{\"end\":55406,\"start\":55401},{\"end\":55421,\"start\":55410},{\"end\":55431,\"start\":55425},{\"end\":55440,\"start\":55435},{\"end\":55449,\"start\":55444},{\"end\":55461,\"start\":55455},{\"end\":55472,\"start\":55465},{\"end\":55482,\"start\":55476},{\"end\":55491,\"start\":55486},{\"end\":55812,\"start\":55807},{\"end\":55819,\"start\":55816},{\"end\":55839,\"start\":55823},{\"end\":55849,\"start\":55843},{\"end\":56132,\"start\":56123},{\"end\":56141,\"start\":56136},{\"end\":56154,\"start\":56145},{\"end\":56170,\"start\":56158},{\"end\":56189,\"start\":56174},{\"end\":56199,\"start\":56193},{\"end\":56208,\"start\":56203},{\"end\":56496,\"start\":56487},{\"end\":56509,\"start\":56500},{\"end\":56518,\"start\":56513},{\"end\":56526,\"start\":56522},{\"end\":56535,\"start\":56530},{\"end\":56859,\"start\":56853},{\"end\":57210,\"start\":57205},{\"end\":57411,\"start\":57402},{\"end\":57417,\"start\":57415},{\"end\":57770,\"start\":57766},{\"end\":57780,\"start\":57774},{\"end\":57799,\"start\":57784},{\"end\":57810,\"start\":57803},{\"end\":57823,\"start\":57814},{\"end\":57833,\"start\":57827},{\"end\":58159,\"start\":58149},{\"end\":58169,\"start\":58163},{\"end\":58180,\"start\":58173},{\"end\":58442,\"start\":58437},{\"end\":58457,\"start\":58446},{\"end\":58465,\"start\":58461},{\"end\":58471,\"start\":58469},{\"end\":58789,\"start\":58783},{\"end\":58798,\"start\":58793},{\"end\":58809,\"start\":58804},{\"end\":58819,\"start\":58815},{\"end\":58837,\"start\":58825},{\"end\":59165,\"start\":59161},{\"end\":59176,\"start\":59169},{\"end\":59184,\"start\":59180},{\"end\":59194,\"start\":59188},{\"end\":59210,\"start\":59198},{\"end\":59471,\"start\":59467},{\"end\":59482,\"start\":59475},{\"end\":59492,\"start\":59488},{\"end\":59502,\"start\":59496},{\"end\":59520,\"start\":59508},{\"end\":59922,\"start\":59910},{\"end\":59935,\"start\":59928},{\"end\":59960,\"start\":59941},{\"end\":60352,\"start\":60349},{\"end\":60361,\"start\":60356},{\"end\":60596,\"start\":60591},{\"end\":60775,\"start\":60768},{\"end\":60788,\"start\":60779},{\"end\":60800,\"start\":60792},{\"end\":60810,\"start\":60804},{\"end\":60818,\"start\":60814},{\"end\":61091,\"start\":61089},{\"end\":61101,\"start\":61095},{\"end\":61113,\"start\":61105},{\"end\":61366,\"start\":61360},{\"end\":61374,\"start\":61370},{\"end\":61384,\"start\":61378},{\"end\":61685,\"start\":61677},{\"end\":61696,\"start\":61689},{\"end\":61703,\"start\":61700},{\"end\":61713,\"start\":61707},{\"end\":62000,\"start\":61995},{\"end\":62216,\"start\":62209},{\"end\":62228,\"start\":62220},{\"end\":62238,\"start\":62232},{\"end\":62556,\"start\":62552},{\"end\":62565,\"start\":62560},{\"end\":62577,\"start\":62569},{\"end\":62586,\"start\":62581},{\"end\":62892,\"start\":62889},{\"end\":62899,\"start\":62896},{\"end\":62907,\"start\":62903},{\"end\":62915,\"start\":62911},{\"end\":63240,\"start\":63237},{\"end\":63247,\"start\":63244},{\"end\":63255,\"start\":63251},{\"end\":63263,\"start\":63259},{\"end\":63552,\"start\":63546},{\"end\":63565,\"start\":63556},{\"end\":63847,\"start\":63836},{\"end\":63861,\"start\":63851},{\"end\":63870,\"start\":63865},{\"end\":64145,\"start\":64140},{\"end\":64154,\"start\":64149},{\"end\":64161,\"start\":64156},{\"end\":64171,\"start\":64163},{\"end\":64387,\"start\":64378},{\"end\":64400,\"start\":64391},{\"end\":64411,\"start\":64404},{\"end\":64708,\"start\":64694},{\"end\":64720,\"start\":64712},{\"end\":64731,\"start\":64724},{\"end\":64742,\"start\":64735},{\"end\":64754,\"start\":64746},{\"end\":65033,\"start\":65026},{\"end\":65044,\"start\":65037},{\"end\":65057,\"start\":65048},{\"end\":65066,\"start\":65061},{\"end\":65075,\"start\":65070},{\"end\":65089,\"start\":65079},{\"end\":65099,\"start\":65093},{\"end\":65469,\"start\":65465},{\"end\":65476,\"start\":65473},{\"end\":65484,\"start\":65480},{\"end\":65491,\"start\":65488},{\"end\":65806,\"start\":65801},{\"end\":65814,\"start\":65810},{\"end\":65825,\"start\":65818},{\"end\":66083,\"start\":66079},{\"end\":66090,\"start\":66087},{\"end\":66100,\"start\":66094},{\"end\":66108,\"start\":66104},{\"end\":66116,\"start\":66112},{\"end\":66318,\"start\":66314},{\"end\":66327,\"start\":66322},{\"end\":66335,\"start\":66331},{\"end\":66343,\"start\":66339},{\"end\":66355,\"start\":66350},{\"end\":66365,\"start\":66359},{\"end\":66378,\"start\":66371},{\"end\":66388,\"start\":66382},{\"end\":66779,\"start\":66775},{\"end\":66788,\"start\":66783},{\"end\":66799,\"start\":66795},{\"end\":66805,\"start\":66803},{\"end\":66811,\"start\":66809},{\"end\":66818,\"start\":66815},{\"end\":66830,\"start\":66825},{\"end\":66840,\"start\":66834},{\"end\":67127,\"start\":67123},{\"end\":67139,\"start\":67133},{\"end\":67491,\"start\":67487},{\"end\":67502,\"start\":67495},{\"end\":67514,\"start\":67508},{\"end\":67526,\"start\":67520},{\"end\":67821,\"start\":67816},{\"end\":67832,\"start\":67828},{\"end\":67843,\"start\":67839},{\"end\":67855,\"start\":67850},{\"end\":67865,\"start\":67859}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":54370,\"start\":54175},{\"attributes\":{\"id\":\"b1\"},\"end\":54475,\"start\":54372},{\"attributes\":{\"id\":\"b2\"},\"end\":54673,\"start\":54477},{\"attributes\":{\"id\":\"b3\"},\"end\":54815,\"start\":54675},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14242198},\"end\":55342,\"start\":54817},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15780954},\"end\":55743,\"start\":55344},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3332132},\"end\":56068,\"start\":55745},{\"attributes\":{\"doi\":\"arXiv:1805.10265\",\"id\":\"b7\"},\"end\":56424,\"start\":56070},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":3972365},\"end\":56778,\"start\":56426},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1931807},\"end\":57116,\"start\":56780},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":16096886},\"end\":57398,\"start\":57118},{\"attributes\":{\"doi\":\"arXiv:1712.06174\",\"id\":\"b11\"},\"end\":57671,\"start\":57400},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":206579396},\"end\":58095,\"start\":57673},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":6706414},\"end\":58388,\"start\":58097},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":11626373},\"end\":58716,\"start\":58390},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":3123038},\"end\":59087,\"start\":58718},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":516928},\"end\":59463,\"start\":59089},{\"attributes\":{\"id\":\"b17\"},\"end\":59851,\"start\":59465},{\"attributes\":{\"id\":\"b18\"},\"end\":60282,\"start\":59853},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":13193974},\"end\":60545,\"start\":60284},{\"attributes\":{\"id\":\"b20\"},\"end\":60692,\"start\":60547},{\"attributes\":{\"doi\":\"arXiv:1802.03471\",\"id\":\"b21\"},\"end\":61023,\"start\":60694},{\"attributes\":{\"doi\":\"arXiv:1612.08220\",\"id\":\"b22\"},\"end\":61280,\"start\":61025},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":51872670},\"end\":61614,\"start\":61282},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":5941770},\"end\":61950,\"start\":61616},{\"attributes\":{\"id\":\"b25\"},\"end\":62105,\"start\":61952},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":9254343},\"end\":62487,\"start\":62107},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":19508971},\"end\":62820,\"start\":62489},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":793610},\"end\":63144,\"start\":62822},{\"attributes\":{\"doi\":\"arXiv:1712.01785\",\"id\":\"b29\"},\"end\":63460,\"start\":63146},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":1679726},\"end\":63832,\"start\":63462},{\"attributes\":{\"id\":\"b31\"},\"end\":64128,\"start\":63834},{\"attributes\":{\"id\":\"b32\"},\"end\":64302,\"start\":64130},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":3385018},\"end\":64626,\"start\":64304},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":207203942},\"end\":65022,\"start\":64628},{\"attributes\":{\"id\":\"b35\"},\"end\":65386,\"start\":65024},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":4055261},\"end\":65724,\"start\":65388},{\"attributes\":{\"doi\":\"arXiv:1711.07356\",\"id\":\"b37\"},\"end\":66005,\"start\":65726},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":13745458},\"end\":66307,\"start\":66007},{\"attributes\":{\"doi\":\"arXiv:1804.09699\",\"id\":\"b39\"},\"end\":66688,\"start\":66309},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":27716347},\"end\":67119,\"start\":66690},{\"attributes\":{\"id\":\"b41\"},\"end\":67444,\"start\":67121},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":44124705},\"end\":67727,\"start\":67446},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":53297058},\"end\":68121,\"start\":67729}]", "bib_title": "[{\"end\":54894,\"start\":54817},{\"end\":55385,\"start\":55344},{\"end\":55803,\"start\":55745},{\"end\":56483,\"start\":56426},{\"end\":56849,\"start\":56780},{\"end\":57201,\"start\":57118},{\"end\":57762,\"start\":57673},{\"end\":58143,\"start\":58097},{\"end\":58433,\"start\":58390},{\"end\":58777,\"start\":58718},{\"end\":59157,\"start\":59089},{\"end\":60343,\"start\":60284},{\"end\":61356,\"start\":61282},{\"end\":61671,\"start\":61616},{\"end\":62205,\"start\":62107},{\"end\":62548,\"start\":62489},{\"end\":62885,\"start\":62822},{\"end\":63542,\"start\":63462},{\"end\":64374,\"start\":64304},{\"end\":64690,\"start\":64628},{\"end\":65461,\"start\":65388},{\"end\":66075,\"start\":66007},{\"end\":66768,\"start\":66690},{\"end\":67483,\"start\":67446},{\"end\":67812,\"start\":67729}]", "bib_author": "[{\"end\":54398,\"start\":54374},{\"end\":54903,\"start\":54896},{\"end\":54921,\"start\":54903},{\"end\":54931,\"start\":54921},{\"end\":54941,\"start\":54931},{\"end\":54950,\"start\":54941},{\"end\":54961,\"start\":54950},{\"end\":55399,\"start\":55387},{\"end\":55408,\"start\":55399},{\"end\":55423,\"start\":55408},{\"end\":55433,\"start\":55423},{\"end\":55442,\"start\":55433},{\"end\":55451,\"start\":55442},{\"end\":55463,\"start\":55451},{\"end\":55474,\"start\":55463},{\"end\":55484,\"start\":55474},{\"end\":55493,\"start\":55484},{\"end\":55814,\"start\":55805},{\"end\":55821,\"start\":55814},{\"end\":55841,\"start\":55821},{\"end\":55851,\"start\":55841},{\"end\":56134,\"start\":56121},{\"end\":56143,\"start\":56134},{\"end\":56156,\"start\":56143},{\"end\":56172,\"start\":56156},{\"end\":56191,\"start\":56172},{\"end\":56201,\"start\":56191},{\"end\":56210,\"start\":56201},{\"end\":56498,\"start\":56485},{\"end\":56511,\"start\":56498},{\"end\":56520,\"start\":56511},{\"end\":56528,\"start\":56520},{\"end\":56537,\"start\":56528},{\"end\":56861,\"start\":56851},{\"end\":57212,\"start\":57203},{\"end\":57413,\"start\":57400},{\"end\":57419,\"start\":57413},{\"end\":57772,\"start\":57764},{\"end\":57782,\"start\":57772},{\"end\":57801,\"start\":57782},{\"end\":57812,\"start\":57801},{\"end\":57825,\"start\":57812},{\"end\":57835,\"start\":57825},{\"end\":58161,\"start\":58145},{\"end\":58171,\"start\":58161},{\"end\":58182,\"start\":58171},{\"end\":58444,\"start\":58435},{\"end\":58459,\"start\":58444},{\"end\":58467,\"start\":58459},{\"end\":58473,\"start\":58467},{\"end\":58791,\"start\":58779},{\"end\":58800,\"start\":58791},{\"end\":58811,\"start\":58800},{\"end\":58821,\"start\":58811},{\"end\":58839,\"start\":58821},{\"end\":59167,\"start\":59159},{\"end\":59178,\"start\":59167},{\"end\":59186,\"start\":59178},{\"end\":59196,\"start\":59186},{\"end\":59212,\"start\":59196},{\"end\":59473,\"start\":59465},{\"end\":59484,\"start\":59473},{\"end\":59494,\"start\":59484},{\"end\":59504,\"start\":59494},{\"end\":59522,\"start\":59504},{\"end\":59924,\"start\":59906},{\"end\":59937,\"start\":59924},{\"end\":59962,\"start\":59937},{\"end\":60354,\"start\":60345},{\"end\":60363,\"start\":60354},{\"end\":60598,\"start\":60589},{\"end\":60777,\"start\":60766},{\"end\":60790,\"start\":60777},{\"end\":60802,\"start\":60790},{\"end\":60812,\"start\":60802},{\"end\":60820,\"start\":60812},{\"end\":61093,\"start\":61087},{\"end\":61103,\"start\":61093},{\"end\":61115,\"start\":61103},{\"end\":61368,\"start\":61358},{\"end\":61376,\"start\":61368},{\"end\":61386,\"start\":61376},{\"end\":61687,\"start\":61673},{\"end\":61698,\"start\":61687},{\"end\":61705,\"start\":61698},{\"end\":61715,\"start\":61705},{\"end\":62002,\"start\":61991},{\"end\":62218,\"start\":62207},{\"end\":62230,\"start\":62218},{\"end\":62240,\"start\":62230},{\"end\":62558,\"start\":62550},{\"end\":62567,\"start\":62558},{\"end\":62579,\"start\":62567},{\"end\":62588,\"start\":62579},{\"end\":62894,\"start\":62887},{\"end\":62901,\"start\":62894},{\"end\":62909,\"start\":62901},{\"end\":62917,\"start\":62909},{\"end\":63242,\"start\":63235},{\"end\":63249,\"start\":63242},{\"end\":63257,\"start\":63249},{\"end\":63265,\"start\":63257},{\"end\":63554,\"start\":63544},{\"end\":63567,\"start\":63554},{\"end\":63849,\"start\":63834},{\"end\":63863,\"start\":63849},{\"end\":63872,\"start\":63863},{\"end\":64147,\"start\":64132},{\"end\":64156,\"start\":64147},{\"end\":64163,\"start\":64156},{\"end\":64173,\"start\":64163},{\"end\":64389,\"start\":64376},{\"end\":64402,\"start\":64389},{\"end\":64413,\"start\":64402},{\"end\":64710,\"start\":64692},{\"end\":64722,\"start\":64710},{\"end\":64733,\"start\":64722},{\"end\":64744,\"start\":64733},{\"end\":64756,\"start\":64744},{\"end\":65035,\"start\":65024},{\"end\":65046,\"start\":65035},{\"end\":65059,\"start\":65046},{\"end\":65068,\"start\":65059},{\"end\":65077,\"start\":65068},{\"end\":65091,\"start\":65077},{\"end\":65101,\"start\":65091},{\"end\":65471,\"start\":65463},{\"end\":65478,\"start\":65471},{\"end\":65486,\"start\":65478},{\"end\":65493,\"start\":65486},{\"end\":65808,\"start\":65799},{\"end\":65816,\"start\":65808},{\"end\":65827,\"start\":65816},{\"end\":66085,\"start\":66077},{\"end\":66092,\"start\":66085},{\"end\":66102,\"start\":66092},{\"end\":66110,\"start\":66102},{\"end\":66118,\"start\":66110},{\"end\":66320,\"start\":66309},{\"end\":66329,\"start\":66320},{\"end\":66337,\"start\":66329},{\"end\":66345,\"start\":66337},{\"end\":66357,\"start\":66345},{\"end\":66367,\"start\":66357},{\"end\":66380,\"start\":66367},{\"end\":66390,\"start\":66380},{\"end\":66781,\"start\":66770},{\"end\":66790,\"start\":66781},{\"end\":66801,\"start\":66790},{\"end\":66807,\"start\":66801},{\"end\":66813,\"start\":66807},{\"end\":66820,\"start\":66813},{\"end\":66832,\"start\":66820},{\"end\":66842,\"start\":66832},{\"end\":67129,\"start\":67121},{\"end\":67141,\"start\":67129},{\"end\":67493,\"start\":67485},{\"end\":67504,\"start\":67493},{\"end\":67516,\"start\":67504},{\"end\":67528,\"start\":67516},{\"end\":67823,\"start\":67814},{\"end\":67834,\"start\":67823},{\"end\":67845,\"start\":67834},{\"end\":67857,\"start\":67845},{\"end\":67867,\"start\":67857}]", "bib_venue": "[{\"end\":54221,\"start\":54175},{\"end\":54535,\"start\":54477},{\"end\":54721,\"start\":54675},{\"end\":55029,\"start\":54961},{\"end\":55528,\"start\":55493},{\"end\":55880,\"start\":55851},{\"end\":56119,\"start\":56070},{\"end\":56593,\"start\":56537},{\"end\":56943,\"start\":56861},{\"end\":57245,\"start\":57212},{\"end\":57513,\"start\":57435},{\"end\":57873,\"start\":57835},{\"end\":58234,\"start\":58182},{\"end\":58528,\"start\":58473},{\"end\":58879,\"start\":58839},{\"end\":59267,\"start\":59212},{\"end\":59648,\"start\":59522},{\"end\":59904,\"start\":59853},{\"end\":60407,\"start\":60363},{\"end\":60587,\"start\":60547},{\"end\":60764,\"start\":60694},{\"end\":61085,\"start\":61025},{\"end\":61430,\"start\":61386},{\"end\":61764,\"start\":61715},{\"end\":61989,\"start\":61952},{\"end\":62289,\"start\":62240},{\"end\":62637,\"start\":62588},{\"end\":62963,\"start\":62917},{\"end\":63233,\"start\":63146},{\"end\":63622,\"start\":63567},{\"end\":63973,\"start\":63872},{\"end\":64457,\"start\":64413},{\"end\":64802,\"start\":64756},{\"end\":65195,\"start\":65101},{\"end\":65546,\"start\":65493},{\"end\":65797,\"start\":65726},{\"end\":66148,\"start\":66118},{\"end\":66472,\"start\":66406},{\"end\":66894,\"start\":66842},{\"end\":67275,\"start\":67141},{\"end\":67577,\"start\":67528},{\"end\":67916,\"start\":67867},{\"end\":55084,\"start\":55031}]"}}}, "year": 2023, "month": 12, "day": 17}