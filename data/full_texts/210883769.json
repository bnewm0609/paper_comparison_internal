{"id": 210883769, "updated": "2023-06-27 18:33:19.408", "metadata": {"title": "Hierarchical User Profiling for E-commerce Recommender Systems", "authors": "[{\"first\":\"Yulong\",\"last\":\"Gu\",\"middle\":[]},{\"first\":\"Zhuoye\",\"last\":\"Ding\",\"middle\":[]},{\"first\":\"Shuaiqiang\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Dawei\",\"last\":\"Yin\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 13th International Conference on Web Search and Data Mining", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Hierarchical user profiling that aims to model users' real-time interests in different granularity is an essential issue for personalized recommendations in E-commerce. On one hand, items (i.e. products) are usually organized hierarchically in categories, and correspondingly users' interests are naturally hierarchical on different granularity of items and categories. On the other hand, multiple granularity oriented recommendations become very popular in E-commerce sites, which require hierarchical user profiling in different granularity as well. In this paper, we propose HUP, a Hierarchical User Profiling framework to solve the hierarchical user profiling problem in E-commerce recommender systems. In HUP, we provide a Pyramid Recurrent Neural Networks, equipped with Behavior-LSTM to formulate users' hierarchical real-time interests at multiple scales. Furthermore, instead of simply utilizing users' item-level behaviors (e.g., ratings or clicks) in conventional methods, HUP harvests the sequential information of users' temporal finely-granular interactions (micro-behaviors, e.g., clicks on components of items like pictures or comments, browses with navigation of the search engines or recommendations) for modeling. Extensive experiments on two real-world E-commerce datasets demonstrate the significant performance gains of the HUP against state-of-the-art methods for the hierarchical user profiling and recommendation problems. We release the codes and datasets at https://github.com/guyulongcs/WSDM2020_HUP.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2997014384", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/wsdm/GuDWY20", "doi": "10.1145/3336191.3371827"}}, "content": {"source": {"pdf_hash": "c152f6ee10de4d78512a46d96641cec9a65481bf", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4bc31e27cfb02e187957e099c7e8f3d7c0058bbe", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c152f6ee10de4d78512a46d96641cec9a65481bf.txt", "contents": "\nHierarchi-cal User Profiling for E-commerce Recommender Systems\nFebruary 3-7, 2020. February 3-7, 2020\n\nYulong Gu guyulongcs@gmail.com \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nZhuoye Ding dingzhuoye@jd.com \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nShuaiqiang Wang wangshuaiqiang1@jd.com \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nDawei Yin yindawei@acm.org \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nYulong Gu \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nZhuoye Ding \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nShuaiqiang Wang \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nDawei Yin \nData Science Lab\nData Science Lab\nData Science Lab\nData Science Lab\n\n\nHierarchi-cal User Profiling for E-commerce Recommender Systems\n\nThe Thirteenth ACM International Conference on Web Search and Data Mining (WSDM '20)\nHouston, TX, USA 2020; Houston, TX, USAFebruary 3-7, 2020. February 3-7, 202010.1145/3336191.3371827ACM ISBN 978-1-4503-6822-3/20/02. . . $15.00. ACM, New York, NY, USA, 9 pages.CCS CONCEPTS \u2022 Information systems \u2192 PersonalizationRecommender sys- tems KEYWORDS User profilingRecommender systemsHierarchical user profilingPyramid Recurrent Neural NetworksE-commerce\nHierarchical user profiling that aims to model users' real-time interests in different granularity is an essential issue for personalized recommendations in E-commerce. On one hand, items (i.e. products) are usually organized hierarchically in categories, and correspondingly users' interests are naturally hierarchical on different granularity of items and categories. On the other hand, multiple granularity oriented recommendations become very popular in E-commerce sites, which require hierarchical user profiling in different granularity as well. In this paper, we propose HUP, a Hierarchical User Profiling framework to solve the hierarchical user profiling problem in E-commerce recommender systems. In HUP, we provide a Pyramid Recurrent Neural Networks, equipped with Behavior-LSTM to formulate users' hierarchical real-time interests at multiple scales. Furthermore, instead of simply utilizing users' item-level behaviors (e.g., ratings or clicks) in conventional methods, HUP harvests the sequential information of users' temporal finely-granular interactions (micro-behaviors, e.g., clicks on components of items like pictures or comments, browses with navigation of the search engines or recommendations) for modeling. Extensive experiments on two real-world E-commerce datasets demonstrate the significant performance gains of the HUP against state-of-the-art methods for the hierarchical user profiling and recommendation problems. We release the codes and datasets at https://github.com/guyulongcs/WSDM2020_HUP.\n\nINTRODUCTION Figure 1: Hierarchical recommendations in Amazon\n\nIn the era of Internet, recommender systems are playing crucial roles in various applications such as E-commerce portals (e.g. Amazon, JD.com, Alibaba), social networking websites like Facebook, video-sharing sites like Youtube, visual discovery sites like Pinterest and so on. In practice, User Profiling [5,11,18,24,33,38] is one of the most important phases in recommender systems. It yields profile vectors, which formally represent users' interests by deeply understanding their historical interactions, can be used for candidate generation [31,42], click-through rate prediction [4,39,40], conversion rate prediction [3,16] and long-term user engagement optimization [34][35][36][37][44][45][46].\n\nRecently, modeling users' hierarchical real-time interests is emerging to be a crucial issue in E-commerce recommender systems. Firstly, items (i.e. products) in E-commerce sites are typically organized in hierarchical catalogue. Correspondingly, users' interests naturally lie hierarchically on multiple granularity of items and categories. Secondly, different granularity of recommendations (e.g. item, topic and category) become very popular in E-commerce sites, and such scenarios require hierarchical user profiling in different  Figure 2: Hierarchical views of Micro behaviors of a user in JD.com granularity as well. For instance, Figure 1 illustrates a real example of hierarchical recommendations in Amazon. The left side of the figure recommends some items (mobile phones) to a user, while the right side shows a list of recommendations on the categories of \"phone accessories\", \"chargers\" and so on. Category recommendation can help the recommender systems quickly figure out the main interest of the user and make better recommendations.\n\nExisting user profiling methods mainly focus on item recommendations, usually based on users' item-level responses like ratings [20] or clicks [14]. Among existing methods, latent factor modeling is a popular branch, including matrix factorization [13,20,38], neural embedding [8,10], etc. Generally they learn a unified embedding for the target user to represent her interests on the items based on her historical behaviors. Recently, recurrent neural networks (RNN) have achieved state-of-the-art performance in session-based recommendations [14,29].\n\nExisting methods have the following limitations. First, when facing different granularity of recommendation tasks, most of them usually need to run a similar algorithm multiple times on different granularity of item organizations, where each run builds users' certain level profile vectors for the corresponding recommendation task, i.e., item-level profiles for item recommendations and categorylevel profiles for category recommendations. Correspondingly, the training process of each level's profile vectors is completely independent from the others. However, users' multiple-level interests are closely correlated. Figure 2 illustrates a user's hierarchical interests, including an item level and two category levels, with her historical behaviors. Resulting from the correlations between items and categories, improvement on one recommendation task might benefit others. However, to the best of our knowledge, such privilege has not been explored in existing methods.\n\nSecond, only harvesting the signals of users' item-level interactions like ratings and clicks is insufficient. In most of the Ecommerce portals, users provide finely-granular responses such as clicking and browsing different modules (e.g., comments and pictures) of items, adding to shopping carts and purchases, which are referred to as \"micro-behaviors\" [30,41]. For example, the bottom layer of Figure 2 presents a user's historical micro-behaviors in JD.com (one of the largest e-commerce site in the world), including browsing a pair of Nike shoes from the homepage, searching and reading specifications of iPhone 8, browsing Google Pixels 2 from the promoting page, searching iPhone X, reading comments and adding it into the shopping cart for purchasing, etc. Obviously, in comparison with users' item-level responses, micro-behaviors provide more detailed information, and preliminary studies [30,41] have demonstrated the advantage of modeling such detailed behaviors. However, to our best knowledge, none of existing methods has leveraged such advantages to improve the performance of multiplelevel user profiling.\n\nThird, generally users' interests are dynamic and continuously shifting. Some state-of-the-art methods like Time-LSTM [43] usually incorporate time intervals to track the interests shifting. However, we argue that besides the time intervals, the types of behaviors and their dwell time are also extremely important. As shown in Figure 2, we know that iPhone X is preferable to others, since various micro-behaviors are performed on iPhone X with long dwell time. We also observe that triggered by making an order on iPhone X, the user's interests on mobile phones drop sharply. Neglecting to model behavior types and dwell times, Time-LSTM would be in trouble to capture users' detailed preferences and interests shifting.\n\nTo cope with these challenges, we present HUP, a hierarchical user profiling framework to precisely formulate users' real-time interests on multiple organizations of items, targeting significant performance gains in recommendation accuracy. In particular, it models users' multiple-level interests with a Pyramid Recurrent Neural Networks, which typically consist of a micro layer, an item layer, and multiple category recurrent neural network layers. The micro layer harvests the detailed behavioral information and passes it to the higher layers, which could abstract users' hierarchical interests on the corresponding levels of the item organizations simultaneously. Furthermore, to sensitively track users' real-time interests, we introduce Behavior-LSTM in each layer, where a behavior gate is designed to model the types and dwell time of behaviors. Extensive experiments for item recommendation and category recommendation tasks have been conducted on two large-scale real e-commerce datasets to demonstrate the effectiveness of our proposed approach.\n\nTo sum up, our major contributions are listed as follows:\n\n\u2022 We formulate a novel hierarchical user profiling problem, which aims to precisely model users' multiple level interests simultaneously in E-commerce recommender systems. \u2022 We present HUP, which exploits a Pyramid Recurrent Neural Networks for hierarchical user profiling based on users' historical micro-behaviors. \u2022 We propose Behavior-LSTM, which utilizes a behavior gate to model the types and dwell time of behaviors for effectively formulating users' real-time interests. \u2022 We conduct extensive experiments and prove that our method outperforms state-of-the-art baselines greatly on both item recommendation and category recommendation tasks.\n\n\nRELATED WORK 2.1 User Profiling for Recommendations\n\nRecommender systems [1] can recommend potentially interested items to users for tackling the information overload problem. Existing works mainly fall into either content-based technology [26] or collaborative filtering [23]. In both of them, user profiling plays a critical role in formulating users' interests or characteristics [5] based on their behaviors in the past [18,24,33,35,38]. Classic collaborative filtering techniques like matrix factorization [20] learn users' static profiles from their rating preferences for estimation of users' interests in the future [38]. Furthermore, the evolutionary user profiling can learn users' dynamic profiles along time based on the time changing factor model [19], vector autoregression [24], dynamic sparse topic model [8], etc. However, these methods mainly focus on the item recommendation problem, where neither the sequential information of users' behaviors nor the hierarchy of the user profiles could be considered.\n\n\nRNN-based User Profiling\n\nIn recommender systems, recurrent neural networks (RNN) have shown impressive advantages by modeling user's sequential behaviors [14,15,17,29]. For example, Hidasi et al. [14] introduced the concept of session-based recommendations, and firstly proposed an RNN-based framework to process user's click sequences on items in a session. Tan et al. [29] further improved its performance by considering the data augmentation and temporal shift issues. Hidasi et al. [15] integrated some content features extracted from images and text into parallel RNN architectures, which demonstrated their significant performance improvements over baselines. Li et al. [22] proposed a neural attentive recommendation machine that can identify users' main purpose of their current session targeting the performance gains. Beyond behaviors within a session, Quadrana et al. [27] leveraged an additional GRU layer to model users' cross-session activities for session-based recommendations.\n\nRecently, it has been found that the temporal information and users' finely-granular interactions are significantly helpful for recommendations. Wu et al. [32] leveraged timestamps of behaviors with a long short-term memory (LSTM) autoregressive method. Zhu et al. [43] proposed Time-LSTM, which used the time gates to model the time intervals between behaviors. Wan and McAuley [30] exploited the effectiveness of the relations among users' different types of behaviors in recommendations. Zhou et al. [41] trained a single layer RNN model with the micro-behaviors for product recommendation. However, this method only models user's interests in items and just exploits micro behaviors information as additional input, which might lead to inferior performance. Our method uses multi-layer Behavior-LSTM cells and attentions to explicitly model the micro-behaviors information, which can solve both the item recommendation and the hierarchical categories recommendation problems.\n\nIn a word, most existing RNN-based methods fail to address the hierarchical user profiling problem. In addition, to the best of our knowledge, there are no explorations that could leverage the types, dwell time and time intervals of the behaviors simultaneously in an RNN framework for user profiling.\n\n\nPROBLEM FORMULATION\n\nIn this section, we firstly introduce the background, notations and definitions in this paper, and then formulate our problem formally.\n\n\nBackground\n\nHierarchical categories organize products of the E-commerce sites in different granularity. The hierarchy is generally a tree structure, where each lower level category is an element of a higher level one, and products are usually hung onto the finest categories as the leaf nodes of the tree. For example, the first level category \"Electronics\" might include some second level categories like \"Telephone\" and \"Accessory\", and \"Mobile Phone\" is a category in the third and finest level belonging to \"Telephone\".\n\nMicro-behaviors are detailed unit interactions (e.g. reading the detail comments, carting) of users with recommender systems. They can provide rich information for indicating users' timely interests, including the type of behavior that a user conducts on an item, how long a user dwells on an item and move to the next one [30,41]. In this paper, we consider 10 types of micro behaviors, which are shown in Table 1.\n\n\nMicro behaviors Description\n\n\nHome2Product\n\nBrowse the product from the homepage ShopList2Product\n\nBrowse the product from the category page Sale2Product\n\nBrowse the product from the sale page Cart2Product\n\nBrowse the product from the carted page SearchList2Product Browse the product from the searched results\n\n\nDetail_comments\n\nRead the comments of the product Detail_specification Read the specification of the product Detail_bottom\n\nRead the bottom of page of the product Cart Add the product to the shopping cart Order\n\nMake an order  c u } respectively based on her micro-behaviors, which represent each target user u's interests in corresponding granularity.\n\n\nDefinition 3.2 (Hierarchical Recommendations).\n\nLet U be a set of users, V be a set of items, and C (1) , C (2) , . . . , C (K ) be the K levels hierarchy of the categories. The hierarchical recommendations task aims to recommend a set of itemsV u and K set of categorie\u015d C\n(1) u , . . . ,\u0108 (K )\nu to each target user u by maximizing the relevance between u and her recommendations in different granularity.\n\n\nHUP: A HIERARCHICAL USER PROFILING FRAMEWORK\n\nIn this section, we introduce HUP, a hierarchical user profiling framework for hierarchical recommendations. As illustrated in Figure 3, HUP utilizes a Pyramid Recurrent Neural Networks to extract users' hierarchical interests from micro-behaviors at multiple scales.\n\n\nThe Input and Embedding Layers\n\nGiven a target user u, the input of our model is a sequence of her micro-behaviors\nX = \u27e8x 1 , x 2 , . . . , x N \u27e9. The ith element x i = (t i , v i , c i , b i , d i , \u0434 i ) indicates that u performs a micro-behavior of type b i on the item v i at the time t i , where v i belongs to multiple- level categories c i = {c (1) i , c (2) i , ..., c (K )\ni }, the dwell time is d i , and the time interval between x i and x i+1 is \u0434 i . Here both dwell time and time interval are real numbers. As previous work did [41], we discretize them into several buckets respectively for embedding. For each micro-behavior x i , the embedding layer firstly uses embedding tables of items, categories, behavior types, dwell time buckets and time intervals to\ntransform v i , c i , b i , d i , \u0434 i into low- dimensional dense vectors (i.e., e v i ,e c i ,e b i ,e d i ,e \u0434 i )\nrespectively and then concatenates these vectors into a single embedding vector e i . The embedding tables are initialized as random numbers.\n\n\nPyramid Recurrent Neural Networks\n\nMost of previously recurrent neural networks (RNN)-based recommendation methods [5,14,15,29,41] use a single-layer RNN to generate user profile vectors, which might not be capable of capturing user's hierarchical interests in different levels. To solve this problem, inspired by the Spatial Pyramid Pooling-net (SPP-net) [12], we propose a Pyramid Recurrent Neural Networks, which contains a micro-level, an item-level and several category-level RNN layers to abstract users' hierarchical interests at multiple scales simultaneously.\n\nThe micro-level RNN layer aims to model users' finest level interests. The input at the time stamp i of this layer x M i comes from the embedding layer, and the output of this layer Y M is forwarded to the item-level RNN layer for further calculations. The hidden state is updated after taking each micro-behavior as input. The formulations of the Micro-level RNN layer are defined in Equation 1.\nX M = [x M i ] = [e i ], i = 1, 2, ..., N Y M = [y M i ] = RN N M (X M ), i = 1, 2, ..., N(1)\nThe item-level RNN layer models users' item-level interests. The input at the time stamp i of this layer x I i is the concatenation of the item embedding e v i and the output of the micro-level layer. The hidden state is only updated after a user have transferred her focuses from one item to another. Its output Y I is forwarded to the category-level RNN layers. The formulations of the Item-level RNN layer are defined in Equation 2.\nX I = [x I i ] = [e v i ; y M i ] Y I = [y I i ] = RN N I (X I )(2)\nThe category-level RNN layers formulate users' category-level interests. In the Kth category layer (the finest granularity of categories), the input at the time stamp i is x\n(K ) C i\n, which is the concatenation of the category embedding e c i in this layer and the output of the (k \u2212 1)th level category layer. In each layer, the hidden state is only updated after a user has moved her focuses from one category to another in this layer. The formulations of the category-level RNN layers are defined in Equation 3.\nX (k ) C = [x (k ) C i ] = [e (k ) c i ; y I i ], k = K [e (k ) c i ; y (k \u22121) C i ], k = 1, ..., K \u2212 1 Y (k ) C = [y (k ) C i ] = RN N (k) C X (k ) C , k = 1, ..., K(3)\n\nBehavior-LSTM Cell\n\nGenerally users' interests are dynamic and continuously shifting. Time-LSTM [43] is a state-of-the-art method that incorporates time intervals between users' sequential purchases to address the interest shifting problem. However, it cannot model the behavior type and the dwell time information, which may lead to inferior performance. We here propose Behavior-LSTM, a novel RNN layer that provides an additional behavior gate to process the types and dwell time of the behaviors, enabling HUP to track users' real-time interests more precisely. In particular, it is described in Figure 4 and formulated in Equation 4\n\n:\nI t = \u03c3 (W I [h t \u22121 , x t ] + b I ) F t = \u03c3 (W F [h t \u22121 , x t ] + b F ) T t = \u03c3 (W T [x t , \u2206 t ] + b T ) A t = \u03c3 (W A [x t , a t ] + b A ) C t = tanh(W C [h t \u22121 , x t ] + b C ) C t = F t \u2299 C t \u22121 + I t \u2299 T t \u2299 A t \u2299C t O t = \u03c3 (W O [h t \u22121 , x t ] + b O ) h t = O t \u2299 tanh(C t )(4)\nwhere I, F , T , A and O are the input, forget, time, behavior and output gates, C and h are the cell state and hidden state vectors,\nW I ,W F ,W T ,W A ,W C andW O are weight matrices, b I , b F , b T , b A , b C and b O are the biases, respectively. The input of the Behavior- LSTM is a tuple (x t , a t , \u2206 t )\n, where x t is the embedding vector of the input at the time stamp t, a t is the embedding vector of the behavior type or dwell time information, and \u2206 t is the embedding vector of time interval between current behavior and the next one.\n\nIn Behavior-LSTM, the time gate T estimates how much information that should maintain or pass to the next state, and the behavior gate A calculates the importance of current behavior with the meta information of the behavior. In particular, such meta information of the behaviors involves two aspects: their types and users' dwell time. In particular, the behavior gate actually only processes the types of micro-behaviors in the micro level RNN layer. It is because \n\n\nThe Attention Layers\n\nThe attention mechanism [2] is a common technique in deep learning. Usually, it is able to mitigate long-term dependency issues as well as provide interpretations, which is extremely important in real-world recommender systems. In particular, an attention layer takes the output sequence Y = [y 1 , y 2 , ..., y T ] of an RNN as input and return a context vector s. Let y i be a user's interests at time stamp i. The context vector s of each attention layer is calculated as a weighted sum of the interests vectors among all the time stamps, which is formulated formally in Equation 5.\ns = T i=1 \u03b1 i y i ; \u03b1 i = exp(e i ) T k =1 exp(e k )\n;\ne i = f (y i , y T , a i )(5)\nHUP has multiple attention layers, where each is directly followed by its corresponding RNN layer and therefore referred to as micro, item and category level attention layers respectively. The context vectors from these attention layers are denoted as s m , s i and s c = {s (1) c , s (2) c , ..., s (K ) c } respectively. The attention signal a i represents the type of micro-behaviors in micro-level attention layer, and the dwell time in both the item and the category level attention layers. f is an alignment model, which scores the importance of y i based on the hidden state y i , last hidden state y T and attention signal a i . In order to achieve abundant expressive ability, we design the alignment model f as two-layers feedforward neural networks, which is jointly trained in the model.\n\n\nThe Fully Connected Layers\n\nThe fully connected neural network layers transform users' context vectors from the attention layers into hierarchical user profiles. Specifically, they transform users' micro-level, item-level and category-level context vectors s m , s i and s c = {s (1) c , s \n\n\nLoss Function\n\nDeep learning models like convolutional neural networks [21] and recurrent neural networks [9] usually use softmax as the last layer for prediction. However, in real-world recommendation scenarios, the possible items can be millions or billions, and thus such calculations on all items is prohibitively expensive. Given a user u and her sequential activities X u , we try to maximize the cosine similarity between the user's real-time profile vectors (i.e. p m , p i and\np c = {p (1) c , ..., p (K )\nc }) and the embedding of the ground-truths, on which the target user will act in the next time stamp N + 1(i.e., the next item v N +1 for micro and item level layers or the next hierarchical categories c N +1 = {c\n(1) N +1 , ..., c (K )\nN +1 } for category-level layers). Similar strategy has achieved success in recommendation systems [14,29,41]. Let L M u , L I u and\nL C u = {L (1) C u . . . L (K ) C u\n} be the losses of the micro-level, item-level and category-level layers for the target user u. The loss of the micro-level layers L M u can be calculated as Equation 6, where e v N +1 is the embedding of the ground-truth item v N +1 . The losses of the item and category levels can be calculated similarly.\nL M u = cosine_proximity(p m , e v N +1 ) = \u2212 p m \u00b7 e v N +1 \u2225p m \u2225 \u2225e v N +1 \u2225 (6)\nThe total loss L is the weighted sum of losses in micro-level, itemlevel and category-level layers of all users. Formally it is defined as follows:\nL = \u03bb l M u \u2208U L M u + \u03bb l I u \u2208U L I u + \u03bb l C u \u2208U K k =1 L (k ) C u(7)\nwhere \u03bb l M , \u03bb l I and \u03bb l C are the coefficients of the losses in the microlevel, item-level and multiple category-level layers respectively.\n\n\nEXPERIMENTAL SETTINGS 5.1 Hierarchical Recommendations\n\nWe evaluate our proposed HUP method on two tasks: item recommendations and category recommendations. Given a target user u and a sequence of her micro-behaviors, HUP generates a hierarchical profile vectors for u, which represent the user's interests in items and hierarchical categories respectively. At the same time, the embedding vectors of the items and multiple-level categories can be learned from HUP as well during the training stage. The item recommendation process is as follows. At each recommendation stage, as previous work did [41], we first retrieve a set of candidate items, which are similar to at least one of users' browsed items in terms of cosine similarity on embeddings. We then calculate the cosine similarity between each candidate item embedding and the user's item-level profile vector p i as ranking score. Finally, we rank the candidate items and select top items for recommendations. The category recommendations are performed in a similar manner.\n\n\nDataset\n\nTo evaluate the effectiveness of HUP, we utilize the benchmark \"JD Micro Behaviors Datasets\" [41], which are collected from a large e-commerce site JD.com. The datasets contain users' microbehaviors in two product categories \"Appliances\" and \"Computers\", where each line is a sequence of a user's micro behaviors in a session.\n\nThe statistics of the datasets are shown in Table 2. In each dataset, we sort all the sessions in chronological order, and use 70%, 10%, 20% sessions as the training, validation and testing set respectively. As previous work did [41] , the last item and the corresponding finest category in each session are used as ground truth.\n\nDataset JD-Applicances JD-Computers  \n\n\nBaseline Methods\n\nWe make a comparative study of our approach HUP with the following methods, where the last three are state-of-the-art RNN-based methods that have demonstrated excellent performance recently.\n\n\u2022 POP recommends the most popular items to each user. This simple method is a common mechanism in recommender systems. This simple method has been proven to be comparable to some sophisticated recommender algorithms [6]. \u2022 BPR-MF implements matrix factorization with the Bayesian personal ranking loss. It is one the most popular methods for recommendations [13,20,28]. \u2022 Item-KNN is a popular item-based recommender algorithm that uses similarities between items for recommendations [7]. In particular, the similarity is calculated with sim(i, j) = F r eq(i j) F r eq(i)\u00d7F r eq(j) , where Freq(i) is the number of sequences that an item i shows up [7]. \u2022 Word2vec makes recommendations based on embedding of the last item in the sequence [10] by Word2vec [25]. It has been proved to be effective in recommendation [10]. \u2022 Word2vec-avg makes recommendations based on the average embedding of all items in the sequence [41]. \u2022 RIB [41] is a state-of-the-art method that uses RNN and the attention mechanism to model user's micro-behaviors for recommendation . \n\n\nEvaluation Metrics\n\nWe use two widely used metrics Recall@K and MRR@K [14,27,29,41] Table 3: Performance of different methods for category recommendation and item recommendation on two datasets. \" * \" indicates the statistically significant improvements (i.e., two-sided t -test with p < 0.01) over both the best baseline and all variants.\n\n6 EXPERIMENTAL RESULTS Table 3 shows the experimental results of different methods for the item and category recommendation tasks on the Applicances and Computers datasets. We conducted significance testing (t-test) on the improvements of our approaches over all baselines. \" * \" denotes strong significant divergence with p-value<0.01. From the table we can find that:\n\n\nComparison with Baselines\n\n\u2022 HUP significantly outperforms state-of-the-art methods for the two tasks on both datasets. Specifically, for item recommendation, HUP outperforms state-of-the-art method by 3.4%, 6.1% in Recall@20 and 6.7%, 9.1% in MRR@20 for the \"Appliances\" and \"Computers\" datasets respectively. For category recommendation, our performance gains are relatively subtle, as this problem is easier than item recommendation resulting from the denser dataset. \u2022 The POP and BPR-MF methods perform the worst.\n\n\u2022 Three RNN-based methods including RIB, Time-LSTM and S-HRNN significantly overcome conventional baselines. \u2022 By modeling the temporal information, Time-LSTM achieves better performance than RIB.\n\n\nEffectiveness of Components in HUP\n\nTo systematically validate the effectiveness of each component in HUP, we implement the following variants of HUP, each eliminating a specific model component.  Table 3. From the table, we can see that the full version of HUP outperforms all of the variants and find that:\n\n(1) Pyramid Recurrent Neural Networks. Comparing with the HUP-Single method, the performance improvement demonstrate the effectiveness of PRNN.\n\n(2) Micro-behaviors. The comparison with HUP-NoMicro demonstrates the importance of micro-behaviors in HUP. We also notice that HUP-NoMicro obtains the worst performance in all metrics.\n\n(3) Temporal mechanisms. Evidenced by the performance loss of HUP-LSTM against HUP-TLSTM, and HUP, temporal information is necessary in modeling user interests. Furthermore, sophisticated temporal mechanisms could receive improved performance. For example, equipped with time gates, HUP-TLSTM can achieve better performance than HUP-LSTM; HUP outperforms HUP-TLSTM by further using Behavior gates and time-mechanisms in the attention layers.\n\n(4) Attention layers. As demonstrated in our experiments, attention layers can significantly improve the performance of HUP against the HUP-NoAtt variant. Meanwhile, attention mechanisms also help interpret and visualize the recommendation results as well. We will show that in the later case study section.\n\n\nTrade-off in Loss Function\n\nAs formulated in Equation (7), the loss function is composed of three components. According to our experiments, HUP achieves  Figure 6: Performance of HUP with \u03bb l I which is the weight of the losses of item-level RNN layer.\n\nthe best performance when \u03bb l M = 0. Because the micro-level RNN layer is useful for predicting the next micro-behaviors based on the historical ones, but does not directly affect the predictions of the items and categories. However, this layer can be used to interpret the real-time effectiveness of the historical micro-behaviors for each user. Without loss of generality, we set \u03bb l C = 1 \u2212 \u03bb l I and 0 \u2264 \u03bb l I \u2264 1. Therefore we only need to tune \u03bb l I in the loss function for a trade-off between item and category recommendation tasks. Figure 6 shows the performance of HUP with respect to different values of \u03bb l I on the \"Applicances\" dataset. The curves on the \"Computers\" dataset are similar and thus absent from this paper for satisfying the requirement of the page limit. From the figure we can see that the metrics for item recommendation decline when \u03bb l I is getting lower while the trends are completely opposite for category recommendation. To balance the performance of the user profiles in different levels, we set \u03bb l I and \u03bb l C both to 0.5 in the experiments. Figure 5 demonstrates a real case from the \"Appliances\" dataset to explain how HUP works. The last 12 micro-behaviors on 7 items from 6 categories are listed in the figure. The last item is the groundtruth, which spans 2 micro-behaviors. The right side of the figure visualizes the attention weights of these micro-behaviors from our proposed HUP, HUP-TLSTM (a variant of HUP) and RIB (a state-ofthe-art baseline). From the figure we can see that:\n\n\nCase Study\n\n(1) The attention weights of the micro behaviors \"Cart\" and \"Search2Product\" are higher than others for all methods, which means these two micro behaviors are important for modeling user interests.\n\n(2) The time interval between the browsing behaviors on the item \"Bear Electric Kettle\" and the next one is 36 seconds. As the attention weights shown, HUP-TLSTM and HUP pay much less attentions to the first 4 items than RIB resulting from the time gates. It illustrates their ability of forgetting history behaviors happened long time ago by modeling the time interval information.\n\n(3) Time interval between the browsing behaviors on \"Yogurt Maker and Ice Cream Machine\" and \"Bear Egg Cooker\" is merely 2 seconds. This number between \"Bear Egg Cooker\" and the next item (ground-truth) is also 2 seconds. Both are very short. HUP-TLSTM retains such history information and still pays much attention to these two items resulting from the short time interval. However, HUP can notice the fact that the user has already added these two items to cart. It thus reduces the importance on these two items and their categories, and then chooses an item from a related category (Yogurt Maker and Toaster Bundle) for return.\n\n\nCONCLUSIONS\n\nIn this paper, we investigate the hierarchical user profiling problem, aiming to model users' real-time interests in different granularity. It is crucial for multiple-level recommendation tasks, such as item, category, topic, theme recommendations and so on. We hence propose HUP, a hierarchical user profiling framework, which leverages a Pyramid Recurrent Neural Networks to abstract users' interests in different granularity simultaneously from users' micro-behaviors. To better model users' real-time interests, we design Behavior-LSTM cells to integrate the meta information of behaviors (e.g. the type, dwell time and time interval information) into HUP. Extensive experiments on two real-world E-commerce datasets verify the effectiveness of our method for both item and category recommendation tasks.\n\nResulting from its effectiveness and flexibility, our framework can be widely used to recommend items (e.g. movies, music, news) and corresponding categories (e.g. science fiction films, rock music, breaking news) in various web services (e.g. videos or music sharing sites, social networks).\n\nDefinition 3. 1 (\n1Hierarchical User Profiling). Hierarchical user profiling aims to generate the micro-level, item-level and hierarchical category-level profile vectors p m u , p i u and p c u = {p (1) c u , . . . , p (K )\n\n\nand the output of the item-level RNN layer calculated on items under this category. For other higher-level category layers, the input at the time stamp i of the kth level category layer is X (k ) C , which is the concatenation of the category embedding e (k )\n\nc\n, ..., s (K ) c } into real-time user profile vectors p m , p i and p c = {p (1) c , p (2) c , ..., p (K ) c } in corresponding levels.\n\n\u2022\nTime-LSTM [43] integrates the time interval information between user's item-level behaviors into LSTM. \u2022 S-HRNN [27] utilizes a hierarchical GRUs to model users' interactions across sessions.\n\n\n\u2022 HUP-NoMicro. This variant does not use micro behaviors for modeling. It only uses the item-level and category-level RNN layers based on users' interactions with items and categories.\u2022 HUP-LSTM. This variant uses LSTM in the PRNN layers.The time-related mechanism and type of micro-behaviors are absent in the method.\u2022 HUP-TLSTM. This variant uses Time-LSTM [43] in the PRNN layers, where only the time gates are used in the RNN layer to model the time interval among behaviors. \u2022 HUP-NoAtt. This variant removes the attention layers from HUP. \u2022 HUP-Single. This variant solves each recommendation task independently, which includes a single Behavior-LSTM layer and an attention layer in the framework. The performance of different variants are shown in the bottom part of\n\nTable 1 :\n1List of micro-behaviors \n\n3.2 Hierarchical User Profiling \n\n\n\n\nThe architecture of the HUP. It uses a Pyramid Recurrent Neural Networks, which is consisted of a micro layer, an item layer, and hierarchical category recurrent neural networks layers, to extract users' hierarchical profile at multiple scales. The profiles represent users' real-time interests in items and hierarchical categories, based on which the most relevant categories and items can be recommended to users.Figure 4: The architecture of the Behavior-LSTM. It has a behavior gate A and a time gate T , where A models users' behavior information in micro behaviors, and T captures the time intervals between users' micro behaviors.Technical Presentation \nWSDM '20, February 3-7, 2020, Houston, TX, USA \nInput Layer \n\nEmbedding Layer \n\nMicro Level RNN Layer \n\nItem Level RNN Layer \n\nKth level Category RNN Layer \n\nV1 \nV1 \nV2 \n\nV1 \nV2 \nV3 \n\nCK1 \nCK2 \n\n+ \n\nAttention Layers \nModel Prediction \n\n+ \n\nFully Connetcted Layers \n\ntop Kth level categories \n\ntop items \n\n+ \n\nPyramid Recurrent Neural Networks \n\ne1 \n\nx1 \n\nV3 \nV3 \n\nx2 \nx3 \nxn-1 \nxn \n\nHierarchical \nUser Profiles \n\nHierarchical \nRecommendations \n\n\u2026 \n\ne2 \ne3 \nen-1 \nen \n\n1st level Category RNN Layer \nC12 \n\n+ \n\ntop 1st level categories \n\n\u2026 \n\nC11 \n\nFigure 3: + \nX \n\nt-1 \n\nInput Gate \nForget Gate \nOutput Gate \nBehavior Gate \n\ntanh \n\n\u03c3 \n\u03c3 \n\u03c3 \n\u03c3 \n\nX \n\ntanh \n\u03c3 \n\nX \n\nt-1 \n\nt \n\nt \nt \n\nxt \nat \n\nt \n\nTime Gate \n\nt \n\nt \n\nmost of micro-behaviors are instant responses and we could not \nget their dwell time, but their types are extremely important for \nusers' interest modeling. In the item-level and hierarchical category-\nlevel RNN layers, this gate models the dwell time on the items or \ncategories. That is because the dwell time varies significantly in \nitems and categories and is very informative in presenting users' \ninterests. \n\n\n\nTable 2 :\n2Statistics of the Datasets\n\nToward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Gediminas Adomavicius, Alexander Tuzhilin, IEEE Transactions on Knowledge & Data Engineering. 6Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next gen- eration of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Transactions on Knowledge & Data Engineering 6 (2005), 734-749.\n\nDzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, arXiv:1409.0473Neural Machine Translation by Jointly Learning to Align and Translate. arXiv. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural Ma- chine Translation by Jointly Learning to Align and Translate. arXiv (2014). arXiv:1409.0473\n\nCTRec: A Long-Short Demands Evolution Model for Continuous-Time Recommendation. Ting Bai, Lixin Zou, Wayne Xin Zhao, Pan Du, Weidong Liu, Jian-Yun Nie, Ji-Rong Wen, SIGIR. Ting Bai, Lixin Zou, Wayne Xin Zhao, Pan Du, Weidong Liu, Jian-Yun Nie, and Ji-Rong Wen. 2019. CTRec: A Long-Short Demands Evolution Model for Continuous-Time Recommendation. In SIGIR. 675-684.\n\nStreaming recommender systems. Shiyu Chang, Yang Zhang, Jiliang Tang, Dawei Yin, Yi Chang, A Mark, Thomas S Hasegawa-Johnson, Huang, Shiyu Chang, Yang Zhang, Jiliang Tang, Dawei Yin, Yi Chang, Mark A Hasegawa- Johnson, and Thomas S Huang. 2017. Streaming recommender systems. In WWW. 381-389.\n\nSemi-supervised user profiling with heterogeneous graph attention networks. Weijian Chen, Yulong Gu, Zhaochun Ren, Xiangnan He, Hongtao Xie, Tong Guo, Dawei Yin, Yongdong Zhang, Weijian Chen, Yulong Gu, Zhaochun Ren, Xiangnan He, Hongtao Xie, Tong Guo, Dawei Yin, and Yongdong Zhang. 2019. Semi-supervised user profiling with heterogeneous graph attention networks. In IJCAI. 2116-2122.\n\nPerformance of Recommender Algorithms on Top-N Recommendation Tasks. Paolo Cremonesi, Yehuda Koren, Roberto Turrin, RecSys. Paolo Cremonesi, Yehuda Koren, and Roberto Turrin. 2010. Performance of Recommender Algorithms on Top-N Recommendation Tasks. In RecSys. 39-46.\n\nItem-based Top-N Recommendation Algorithms. Mukund Deshpande, George Karypis, ACM Transactions on Information Systems. 22Mukund Deshpande and George Karypis. 2004. Item-based Top-N Recommenda- tion Algorithms. ACM Transactions on Information Systems 22, 1 (2004), 143-177.\n\nCollaborative Dynamic Sparse Topic Regression with User Profile Evolution for Item Recommendation. Li Gao, Jia Wu, Chuan Zhou, Yue Hu, AAAI. Li Gao, Jia Wu, Chuan Zhou, and Yue Hu. 2017. Collaborative Dynamic Sparse Topic Regression with User Profile Evolution for Item Recommendation. In AAAI. 1316-1322.\n\nSpeech Recognition with Deep Recurrent Neural Networks. Alex Graves, Mohamed Abdel-Rahman, Geoffrey Hinton, ICASSP. Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. 2013. Speech Recognition with Deep Recurrent Neural Networks. In ICASSP. 6645-6649.\n\nMihajlo Grbovic, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp. 2015. E-commerce in Your Inbox: Product Recommendations at Scale. In KDD. Mihajlo Grbovic, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp. 2015. E-commerce in Your Inbox: Product Recommendations at Scale. In KDD. 1809-1818.\n\nHLGPS: A Home Location Global Positioning System in Location-Based Social Networks. Yulong Gu, Jiaxing Song, Weidong Liu, Lixin Zou, ICDM. Yulong Gu, Jiaxing Song, Weidong Liu, and Lixin Zou. 2016. HLGPS: A Home Location Global Positioning System in Location-Based Social Networks. In ICDM. 901-906.\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE transactions on pattern analysis and machine intelligence. 37Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Spatial pyramid pooling in deep convolutional networks for visual recognition. IEEE transactions on pattern analysis and machine intelligence 37, 9 (2015), 1904-1916.\n\nFast Matrix Factorization for Online Recommendation with Implicit Feedback. Xiangnan He, Hanwang Zhang, Min-Yen Kan, Tat-Seng Chua, SIGIR. Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast Matrix Factorization for Online Recommendation with Implicit Feedback. In SIGIR. 549-558.\n\nBal\u00e1zs Hidasi, Alexandros Karatzoglou, arXiv:1511.06939Linas Baltrunas, and Domonkos Tikk. 2015. Session-based Recommendations with Recurrent Neural Networks. arXiv. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based Recommendations with Recurrent Neural Networks. arXiv (2015). arXiv:1511.06939\n\nBal\u00e1zs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. 2016. Parallel Recurrent Neural Network Architectures for Feature-rich Sessionbased Recommendations. In RecSys. Bal\u00e1zs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. 2016. Parallel Recurrent Neural Network Architectures for Feature-rich Session- based Recommendations. In RecSys. 241-248.\n\nOnline Purchase Prediction via Multi-Scale Modeling of Behavior Dynamics. Chao Huang, Xian Wu, Xuchao Zhang, Chuxu Zhang, Jiashu Zhao, Dawei Yin, Nitesh V Chawla, Chao Huang, Xian Wu, Xuchao Zhang, Chuxu Zhang, Jiashu Zhao, Dawei Yin, and Nitesh V Chawla. 2019. Online Purchase Prediction via Multi-Scale Modeling of Behavior Dynamics. In KDD. 2613-2622.\n\nTaxonomy-aware multi-hop reasoning networks for sequential recommendation. Jin Huang, Zhaochun Ren, Wayne Xin Zhao, Gaole He, Ji-Rong Wen, Daxiang Dong, WSDM. Jin Huang, Zhaochun Ren, Wayne Xin Zhao, Gaole He, Ji-Rong Wen, and Daxiang Dong. 2019. Taxonomy-aware multi-hop reasoning networks for sequential recommendation. In WSDM. 573-581.\n\nPersonalised News and Blog Recommendations based on User Location, Facebook and Twitter User Profiling. Gabriella Kazai, Iskander Yusof, Daoud Clarke, SIGIR. Gabriella Kazai, Iskander Yusof, and Daoud Clarke. 2016. Personalised News and Blog Recommendations based on User Location, Facebook and Twitter User Profiling. In SIGIR. 1129-1132.\n\nCollaborative Filtering with Temporal Dynamics. Yehuda Koren, KDD. Yehuda Koren. 2009. Collaborative Filtering with Temporal Dynamics. In KDD. 447-456.\n\nMatrix Factorization Techniques for Recommender Systems. Yehuda Koren, Robert Bell, Chris Volinsky, Computer. 42Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Tech- niques for Recommender Systems. Computer 42, 8 (2009), 30-37.\n\nImagenet Classification with Deep Convolutional Neural Networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, NIPS. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet Classifi- cation with Deep Convolutional Neural Networks. In NIPS. 1097-1105.\n\nNeural Attentive Session-based Recommendation. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, Jun Ma, CIKM. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural Attentive Session-based Recommendation. In CIKM. 1419-1428.\n\nAmazon.Com Recommendations: Item-to-Item Collaborative Filtering. Greg Linden, Brent Smith, Jeremy York, IEEE Internet Computing. 7Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon.Com Recommenda- tions: Item-to-Item Collaborative Filtering. IEEE Internet Computing 7, 1 (2003), 76-80.\n\nCollaborative Evolution for User Profiling in Recommender Systems. Zhongqi Lu, Yong Sinno Jialin Pan, Jie Li, Qiang Jiang, Yang, IJCAI. Zhongqi Lu, Sinno Jialin Pan, Yong Li, Jie Jiang, and Qiang Yang. 2016. Collabora- tive Evolution for User Profiling in Recommender Systems. In IJCAI. 3804-3810.\n\nDistributed Representations of Words and Phrases and Their Compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, NIPS. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed Representations of Words and Phrases and Their Compositionality. In NIPS. 3111-3119.\n\nThe Adaptive Web. J Michael, Daniel Pazzani, Billsus, Chapter Content-based Recommendation Systems. Berlin, HeidelbergSpringer-VerlagMichael J. Pazzani and Daniel Billsus. 2007. The Adaptive Web. Springer-Verlag, Berlin, Heidelberg, Chapter Content-based Recommendation Systems, 325-341.\n\nPersonalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks. Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, Paolo Cremonesi, RecSys. Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, and Paolo Cremonesi. 2017. Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks. In RecSys. 130-137.\n\nBPR: Bayesian Personalized Ranking from Implicit Feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, UAI. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In UAI. 452- 461.\n\nImproved Recurrent Neural Networks for Session-based Recommendations. Xinxing Yong Kiam Tan, Yong Xu, Liu, RecSys. Yong Kiam Tan, Xinxing Xu, and Yong Liu. 2016. Improved Recurrent Neural Networks for Session-based Recommendations. In RecSys. 17-22.\n\nItem Recommendation on Monotonic Behavior Chains. Mengting Wan, Julian Mcauley, RecSys. ACM. Mengting Wan and Julian McAuley. 2018. Item Recommendation on Monotonic Behavior Chains. In RecSys. ACM, 86-94.\n\nA path-constrained framework for discriminating substitutable and complementary products in e-commerce. Zihan Wang, Ziheng Jiang, Zhaochun Ren, Jiliang Tang, Dawei Yin, WSDM. Zihan Wang, Ziheng Jiang, Zhaochun Ren, Jiliang Tang, and Dawei Yin. 2018. A path-constrained framework for discriminating substitutable and complementary products in e-commerce. In WSDM. 619-627.\n\nRecurrent Recommender Networks. Chao-Yuan, Amr Wu, Alex Ahmed, Alexander J Beutel, How Smola, Jing, WSDM. Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017. Recurrent Recommender Networks. In WSDM. 495-503.\n\nUser Profiling Approaches for Demographic Recommender Systems. Knowledge-Based Systems. Mohammad Yahya, H Al-Shamri, 100Mohammad Yahya H. and Al-Shamri. 2016. User Profiling Approaches for Demo- graphic Recommender Systems. Knowledge-Based Systems 100 (2016), 175-187.\n\nDeep reinforcement learning for search, recommendation, and online advertising: a survey by Xiangyu Zhao, Long Xia, Jiliang Tang, and Dawei Yin with Martin Vesely as coordinator. Xiangyu Zhao, Long Xia, Jiliang Tang, Dawei Yin, ACM SIGWEB Newsletter Spring. 4Xiangyu Zhao, Long Xia, Jiliang Tang, and Dawei Yin. 2019. Deep reinforcement learning for search, recommendation, and online advertising: a survey by Xiangyu Zhao, Long Xia, Jiliang Tang, and Dawei Yin with Martin Vesely as coordinator. ACM SIGWEB Newsletter Spring (2019), 4.\n\nDeep reinforcement learning for page-wise recommendations. Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, Jiliang Tang, RecSys. Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, and Jiliang Tang. 2018. Deep reinforcement learning for page-wise recommendations. In RecSys. 95-103.\n\nDeep reinforcement learning for page-wise recommendations. Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, Jiliang Tang, RecSys. Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, and Jiliang Tang. 2018. Deep reinforcement learning for page-wise recommendations. In RecSys. 95-103.\n\nXiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, Dawei Yin, Recommendations with Negative Feedback via Pairwise Deep Reinforcement Learning. In KDD. Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin. 2018. Recommendations with Negative Feedback via Pairwise Deep Rein- forcement Learning. In KDD. 1040-1048.\n\nImproving User Topic Interest Profiles by Behavior Factorization. Zhe Zhao, Zhiyuan Cheng, Lichan Hong, Ed H Chi, Zhe Zhao, Zhiyuan Cheng, Lichan Hong, and Ed H. Chi. 2015. Improving User Topic Interest Profiles by Behavior Factorization. In WWW. 1406-1416.\n\nDeep interest evolution network for click-through rate prediction. Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, Kun Gai, AAAI. Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In AAAI. 5941-5948.\n\nDeep interest network for click-through rate prediction. Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, Kun Gai, Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In KDD. 1059-1068.\n\nMicro Behaviors: A New Perspective in E-commerce Recommender Systems. Mei-Zi Zhou, Zhuoye Ding, Dawei Yin, WSDM. 727-735Mei-zi Zhou, Zhuoye Ding, and Dawei Yin. 2018. Micro Behaviors: A New Perspective in E-commerce Recommender Systems. In WSDM. 727-735.\n\nLearning Tree-based Deep Model for Recommender Systems. Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, Kun Gai, Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai. 2018. Learning Tree-based Deep Model for Recommender Systems. In KDD. 1079-1088.\n\nYu Zhu, Hao Li, Yikang Liao, Beidou Wang, Ziyu Guan, Haifeng Liu, Deng Cai, What to Do Next: Modeling User Behaviors by Time-LSTM. In IJCAI. Yu Zhu, Hao Li, Yikang Liao, Beidou Wang, Ziyu Guan, Haifeng Liu, and Deng Cai. 2017. What to Do Next: Modeling User Behaviors by Time-LSTM. In IJCAI. 3602-3608.\n\nReinforcement Learning to Optimize Long-term User Engagement in Recommender Systems. Lixin Zou, Long Xia, Zhuoye Ding, Jiaxing Song, Weidong Liu, Dawei Yin, Lixin Zou, Long Xia, Zhuoye Ding, Jiaxing Song, Weidong Liu, and Dawei Yin. 2019. Reinforcement Learning to Optimize Long-term User Engagement in Recommender Systems. In KDD. 2810-2818.\n\nReinforcement Learning to Diversify Top-N Recommendation. Lixin Zou, Long Xia, Zhuoye Ding, Dawei Yin, Jiaxing Song, Weidong Liu, DASFAA. 104-120Lixin Zou, Long Xia, Zhuoye Ding, Dawei Yin, Jiaxing Song, and Weidong Liu. 2019. Reinforcement Learning to Diversify Top-N Recommendation. In DASFAA. 104-120.\n\nPseudo Dyna-Q: A Reinforcement Learning Framework for Interactive Recommendation. Lixin Zou, Long Xia, Pan Du, Zhuo Zhang, Ting Bai, Weidong Liu, Jian-Yun Nie, Dawei Yin, WSDM. Lixin Zou, Long Xia, Pan Du, Zhuo Zhang, Ting Bai, Weidong Liu, Jian-Yun Nie, and Dawei Yin. 2020. Pseudo Dyna-Q: A Reinforcement Learning Framework for Interactive Recommendation. In WSDM.\n", "annotations": {"author": "[{\"end\":206,\"start\":105},{\"end\":307,\"start\":207},{\"end\":417,\"start\":308},{\"end\":515,\"start\":418},{\"end\":596,\"start\":516},{\"end\":679,\"start\":597},{\"end\":766,\"start\":680},{\"end\":847,\"start\":767}]", "publisher": null, "author_last_name": "[{\"end\":114,\"start\":112},{\"end\":218,\"start\":214},{\"end\":323,\"start\":319},{\"end\":427,\"start\":424},{\"end\":525,\"start\":523},{\"end\":608,\"start\":604},{\"end\":695,\"start\":691},{\"end\":776,\"start\":773}]", "author_first_name": "[{\"end\":111,\"start\":105},{\"end\":213,\"start\":207},{\"end\":318,\"start\":308},{\"end\":423,\"start\":418},{\"end\":522,\"start\":516},{\"end\":603,\"start\":597},{\"end\":690,\"start\":680},{\"end\":772,\"start\":767}]", "author_affiliation": "[{\"end\":205,\"start\":137},{\"end\":306,\"start\":238},{\"end\":416,\"start\":348},{\"end\":514,\"start\":446},{\"end\":595,\"start\":527},{\"end\":678,\"start\":610},{\"end\":765,\"start\":697},{\"end\":846,\"start\":778}]", "title": "[{\"end\":64,\"start\":1},{\"end\":911,\"start\":848}]", "venue": "[{\"end\":997,\"start\":913}]", "abstract": "[{\"end\":2891,\"start\":1363}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3265,\"start\":3262},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3268,\"start\":3265},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3271,\"start\":3268},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3274,\"start\":3271},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3277,\"start\":3274},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3280,\"start\":3277},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3506,\"start\":3502},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3509,\"start\":3506},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3544,\"start\":3541},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3547,\"start\":3544},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3550,\"start\":3547},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3582,\"start\":3579},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3585,\"start\":3582},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3633,\"start\":3629},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3637,\"start\":3633},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3641,\"start\":3637},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3645,\"start\":3641},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3649,\"start\":3645},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3653,\"start\":3649},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3657,\"start\":3653},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4843,\"start\":4839},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4858,\"start\":4854},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4963,\"start\":4959},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4966,\"start\":4963},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4969,\"start\":4966},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4991,\"start\":4988},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4994,\"start\":4991},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5259,\"start\":5255},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5262,\"start\":5259},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6599,\"start\":6595},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6602,\"start\":6599},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7144,\"start\":7140},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7147,\"start\":7144},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7487,\"start\":7483},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9936,\"start\":9933},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10104,\"start\":10100},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10136,\"start\":10132},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10246,\"start\":10243},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10288,\"start\":10284},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10291,\"start\":10288},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10294,\"start\":10291},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10297,\"start\":10294},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10300,\"start\":10297},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10375,\"start\":10371},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10488,\"start\":10484},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10624,\"start\":10620},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10652,\"start\":10648},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10684,\"start\":10681},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11045,\"start\":11041},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11048,\"start\":11045},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11051,\"start\":11048},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11054,\"start\":11051},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11087,\"start\":11083},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11261,\"start\":11257},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11377,\"start\":11373},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11567,\"start\":11563},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11770,\"start\":11766},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12041,\"start\":12037},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":12151,\"start\":12147},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12265,\"start\":12261},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12389,\"start\":12385},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14178,\"start\":14174},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":14181,\"start\":14178},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":16209,\"start\":16205},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16817,\"start\":16814},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16820,\"start\":16817},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16823,\"start\":16820},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":16826,\"start\":16823},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":16828,\"start\":16826},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17059,\"start\":17055},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17664,\"start\":17663},{\"end\":18194,\"start\":18184},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18778,\"start\":18777},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":19051,\"start\":19047},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20950,\"start\":20947},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21507,\"start\":21506},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21872,\"start\":21869},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21882,\"start\":21879},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22679,\"start\":22676},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":22764,\"start\":22760},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22798,\"start\":22795},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":23545,\"start\":23541},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":23548,\"start\":23545},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":23551,\"start\":23548},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":23779,\"start\":23778},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24973,\"start\":24969},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":25514,\"start\":25510},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":25978,\"start\":25974},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":26545,\"start\":26542},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":26688,\"start\":26684},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26691,\"start\":26688},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":26694,\"start\":26691},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":26813,\"start\":26810},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":26978,\"start\":26975},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27069,\"start\":27065},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":27086,\"start\":27082},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27145,\"start\":27141},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":27248,\"start\":27244},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":27260,\"start\":27256},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27462,\"start\":27458},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":27465,\"start\":27462},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":27468,\"start\":27465},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":27471,\"start\":27468}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":34569,\"start\":34345},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34831,\"start\":34570},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34970,\"start\":34832},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35165,\"start\":34971},{\"attributes\":{\"id\":\"fig_4\"},\"end\":35941,\"start\":35166},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":36014,\"start\":35942},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":37805,\"start\":36015},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":37844,\"start\":37806}]", "paragraph": "[{\"end\":3658,\"start\":2956},{\"end\":4709,\"start\":3660},{\"end\":5263,\"start\":4711},{\"end\":6237,\"start\":5265},{\"end\":7363,\"start\":6239},{\"end\":8087,\"start\":7365},{\"end\":9147,\"start\":8089},{\"end\":9206,\"start\":9149},{\"end\":9857,\"start\":9208},{\"end\":10883,\"start\":9913},{\"end\":11880,\"start\":10912},{\"end\":12861,\"start\":11882},{\"end\":13164,\"start\":12863},{\"end\":13323,\"start\":13188},{\"end\":13849,\"start\":13338},{\"end\":14266,\"start\":13851},{\"end\":14366,\"start\":14313},{\"end\":14422,\"start\":14368},{\"end\":14474,\"start\":14424},{\"end\":14579,\"start\":14476},{\"end\":14704,\"start\":14599},{\"end\":14792,\"start\":14706},{\"end\":14934,\"start\":14794},{\"end\":15210,\"start\":14985},{\"end\":15344,\"start\":15233},{\"end\":15660,\"start\":15393},{\"end\":15777,\"start\":15695},{\"end\":16437,\"start\":16045},{\"end\":16696,\"start\":16555},{\"end\":17267,\"start\":16734},{\"end\":17665,\"start\":17269},{\"end\":18195,\"start\":17760},{\"end\":18437,\"start\":18264},{\"end\":18779,\"start\":18447},{\"end\":19588,\"start\":18971},{\"end\":19591,\"start\":19590},{\"end\":20011,\"start\":19878},{\"end\":20429,\"start\":20192},{\"end\":20898,\"start\":20431},{\"end\":21508,\"start\":20923},{\"end\":21563,\"start\":21562},{\"end\":22393,\"start\":21594},{\"end\":22686,\"start\":22424},{\"end\":23174,\"start\":22704},{\"end\":23418,\"start\":23204},{\"end\":23574,\"start\":23442},{\"end\":23918,\"start\":23611},{\"end\":24150,\"start\":24003},{\"end\":24368,\"start\":24225},{\"end\":25405,\"start\":24427},{\"end\":25743,\"start\":25417},{\"end\":26074,\"start\":25745},{\"end\":26113,\"start\":26076},{\"end\":26324,\"start\":26134},{\"end\":27385,\"start\":26326},{\"end\":27727,\"start\":27408},{\"end\":28098,\"start\":27729},{\"end\":28619,\"start\":28128},{\"end\":28817,\"start\":28621},{\"end\":29128,\"start\":28856},{\"end\":29273,\"start\":29130},{\"end\":29460,\"start\":29275},{\"end\":29903,\"start\":29462},{\"end\":30212,\"start\":29905},{\"end\":30467,\"start\":30243},{\"end\":31997,\"start\":30469},{\"end\":32209,\"start\":32012},{\"end\":32593,\"start\":32211},{\"end\":33226,\"start\":32595},{\"end\":34050,\"start\":33242},{\"end\":34344,\"start\":34052}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15232,\"start\":15211},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16044,\"start\":15778},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16554,\"start\":16438},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17759,\"start\":17666},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18263,\"start\":18196},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18446,\"start\":18438},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18949,\"start\":18780},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19877,\"start\":19592},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20191,\"start\":20012},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21561,\"start\":21509},{\"attributes\":{\"id\":\"formula_10\"},\"end\":21593,\"start\":21564},{\"attributes\":{\"id\":\"formula_11\"},\"end\":23203,\"start\":23175},{\"attributes\":{\"id\":\"formula_12\"},\"end\":23441,\"start\":23419},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23610,\"start\":23575},{\"attributes\":{\"id\":\"formula_14\"},\"end\":24002,\"start\":23919},{\"attributes\":{\"id\":\"formula_15\"},\"end\":24224,\"start\":24151}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":14265,\"start\":14258},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":25796,\"start\":25789},{\"end\":27479,\"start\":27472},{\"end\":27759,\"start\":27752},{\"end\":29024,\"start\":29017}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2954,\"start\":2893},{\"attributes\":{\"n\":\"2\"},\"end\":9911,\"start\":9860},{\"attributes\":{\"n\":\"2.2\"},\"end\":10910,\"start\":10886},{\"attributes\":{\"n\":\"3\"},\"end\":13186,\"start\":13167},{\"attributes\":{\"n\":\"3.1\"},\"end\":13336,\"start\":13326},{\"end\":14296,\"start\":14269},{\"end\":14311,\"start\":14299},{\"end\":14597,\"start\":14582},{\"end\":14983,\"start\":14937},{\"attributes\":{\"n\":\"4\"},\"end\":15391,\"start\":15347},{\"attributes\":{\"n\":\"4.1\"},\"end\":15693,\"start\":15663},{\"attributes\":{\"n\":\"4.2\"},\"end\":16732,\"start\":16699},{\"attributes\":{\"n\":\"4.3\"},\"end\":18969,\"start\":18951},{\"attributes\":{\"n\":\"4.4\"},\"end\":20921,\"start\":20901},{\"attributes\":{\"n\":\"4.5\"},\"end\":22422,\"start\":22396},{\"attributes\":{\"n\":\"4.6\"},\"end\":22702,\"start\":22689},{\"attributes\":{\"n\":\"5\"},\"end\":24425,\"start\":24371},{\"attributes\":{\"n\":\"5.2\"},\"end\":25415,\"start\":25408},{\"attributes\":{\"n\":\"5.3\"},\"end\":26132,\"start\":26116},{\"attributes\":{\"n\":\"5.4\"},\"end\":27406,\"start\":27388},{\"attributes\":{\"n\":\"6.1\"},\"end\":28126,\"start\":28101},{\"attributes\":{\"n\":\"6.2\"},\"end\":28854,\"start\":28820},{\"attributes\":{\"n\":\"6.3\"},\"end\":30241,\"start\":30215},{\"attributes\":{\"n\":\"6.4\"},\"end\":32010,\"start\":32000},{\"attributes\":{\"n\":\"7\"},\"end\":33240,\"start\":33229},{\"end\":34363,\"start\":34346},{\"end\":34834,\"start\":34833},{\"end\":34973,\"start\":34972},{\"end\":35952,\"start\":35943},{\"end\":37816,\"start\":37807}]", "table": "[{\"end\":36014,\"start\":35954},{\"end\":37805,\"start\":36654}]", "figure_caption": "[{\"end\":34569,\"start\":34365},{\"end\":34831,\"start\":34572},{\"end\":34970,\"start\":34835},{\"end\":35165,\"start\":34974},{\"end\":35941,\"start\":35168},{\"end\":36654,\"start\":36017},{\"end\":37844,\"start\":37818}]", "figure_ref": "[{\"end\":4203,\"start\":4195},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4306,\"start\":4298},{\"end\":5892,\"start\":5884},{\"end\":6645,\"start\":6637},{\"end\":7701,\"start\":7693},{\"end\":15528,\"start\":15520},{\"end\":19559,\"start\":19551},{\"end\":30377,\"start\":30369},{\"end\":31018,\"start\":31010},{\"end\":31558,\"start\":31550}]", "bib_author_first_name": "[{\"end\":37964,\"start\":37955},{\"end\":37987,\"start\":37978},{\"end\":38290,\"start\":38283},{\"end\":38310,\"start\":38301},{\"end\":38322,\"start\":38316},{\"end\":38670,\"start\":38666},{\"end\":38681,\"start\":38676},{\"end\":38692,\"start\":38687},{\"end\":38696,\"start\":38693},{\"end\":38706,\"start\":38703},{\"end\":38718,\"start\":38711},{\"end\":38732,\"start\":38724},{\"end\":38745,\"start\":38738},{\"end\":38989,\"start\":38984},{\"end\":39001,\"start\":38997},{\"end\":39016,\"start\":39009},{\"end\":39028,\"start\":39023},{\"end\":39036,\"start\":39034},{\"end\":39045,\"start\":39044},{\"end\":39060,\"start\":39052},{\"end\":39330,\"start\":39323},{\"end\":39343,\"start\":39337},{\"end\":39356,\"start\":39348},{\"end\":39370,\"start\":39362},{\"end\":39382,\"start\":39375},{\"end\":39392,\"start\":39388},{\"end\":39403,\"start\":39398},{\"end\":39417,\"start\":39409},{\"end\":39709,\"start\":39704},{\"end\":39727,\"start\":39721},{\"end\":39742,\"start\":39735},{\"end\":39954,\"start\":39948},{\"end\":39972,\"start\":39966},{\"end\":40279,\"start\":40277},{\"end\":40288,\"start\":40285},{\"end\":40298,\"start\":40293},{\"end\":40308,\"start\":40305},{\"end\":40545,\"start\":40541},{\"end\":40561,\"start\":40554},{\"end\":40584,\"start\":40576},{\"end\":40749,\"start\":40742},{\"end\":40765,\"start\":40759},{\"end\":40788,\"start\":40781},{\"end\":40804,\"start\":40797},{\"end\":41234,\"start\":41228},{\"end\":41246,\"start\":41239},{\"end\":41260,\"start\":41253},{\"end\":41271,\"start\":41266},{\"end\":41452,\"start\":41445},{\"end\":41464,\"start\":41457},{\"end\":41480,\"start\":41472},{\"end\":41490,\"start\":41486},{\"end\":41954,\"start\":41946},{\"end\":41966,\"start\":41959},{\"end\":41981,\"start\":41974},{\"end\":41995,\"start\":41987},{\"end\":42177,\"start\":42171},{\"end\":42196,\"start\":42186},{\"end\":42518,\"start\":42512},{\"end\":42534,\"start\":42527},{\"end\":42978,\"start\":42974},{\"end\":42990,\"start\":42986},{\"end\":43001,\"start\":42995},{\"end\":43014,\"start\":43009},{\"end\":43028,\"start\":43022},{\"end\":43040,\"start\":43035},{\"end\":43054,\"start\":43046},{\"end\":43334,\"start\":43331},{\"end\":43350,\"start\":43342},{\"end\":43361,\"start\":43356},{\"end\":43365,\"start\":43362},{\"end\":43377,\"start\":43372},{\"end\":43389,\"start\":43382},{\"end\":43402,\"start\":43395},{\"end\":43710,\"start\":43701},{\"end\":43726,\"start\":43718},{\"end\":43739,\"start\":43734},{\"end\":43992,\"start\":43986},{\"end\":44154,\"start\":44148},{\"end\":44168,\"start\":44162},{\"end\":44180,\"start\":44175},{\"end\":44415,\"start\":44411},{\"end\":44432,\"start\":44428},{\"end\":44452,\"start\":44444},{\"end\":44454,\"start\":44453},{\"end\":44670,\"start\":44666},{\"end\":44682,\"start\":44675},{\"end\":44694,\"start\":44688},{\"end\":44709,\"start\":44701},{\"end\":44718,\"start\":44715},{\"end\":44728,\"start\":44725},{\"end\":44954,\"start\":44950},{\"end\":44968,\"start\":44963},{\"end\":44982,\"start\":44976},{\"end\":45251,\"start\":45244},{\"end\":45260,\"start\":45256},{\"end\":45282,\"start\":45279},{\"end\":45292,\"start\":45287},{\"end\":45558,\"start\":45553},{\"end\":45572,\"start\":45568},{\"end\":45587,\"start\":45584},{\"end\":45598,\"start\":45594},{\"end\":45600,\"start\":45599},{\"end\":45614,\"start\":45610},{\"end\":45822,\"start\":45821},{\"end\":45838,\"start\":45832},{\"end\":46188,\"start\":46181},{\"end\":46209,\"start\":46199},{\"end\":46229,\"start\":46223},{\"end\":46243,\"start\":46238},{\"end\":46523,\"start\":46516},{\"end\":46541,\"start\":46532},{\"end\":46561,\"start\":46557},{\"end\":46575,\"start\":46571},{\"end\":46838,\"start\":46831},{\"end\":46858,\"start\":46854},{\"end\":47070,\"start\":47062},{\"end\":47082,\"start\":47076},{\"end\":47327,\"start\":47322},{\"end\":47340,\"start\":47334},{\"end\":47356,\"start\":47348},{\"end\":47369,\"start\":47362},{\"end\":47381,\"start\":47376},{\"end\":47637,\"start\":47634},{\"end\":47646,\"start\":47642},{\"end\":47663,\"start\":47654},{\"end\":47665,\"start\":47664},{\"end\":47677,\"start\":47674},{\"end\":47921,\"start\":47913},{\"end\":47930,\"start\":47929},{\"end\":48281,\"start\":48274},{\"end\":48292,\"start\":48288},{\"end\":48305,\"start\":48298},{\"end\":48317,\"start\":48312},{\"end\":48699,\"start\":48692},{\"end\":48710,\"start\":48706},{\"end\":48721,\"start\":48716},{\"end\":48735,\"start\":48729},{\"end\":48747,\"start\":48742},{\"end\":48760,\"start\":48753},{\"end\":49005,\"start\":48998},{\"end\":49016,\"start\":49012},{\"end\":49027,\"start\":49022},{\"end\":49041,\"start\":49035},{\"end\":49053,\"start\":49048},{\"end\":49066,\"start\":49059},{\"end\":49252,\"start\":49245},{\"end\":49264,\"start\":49259},{\"end\":49278,\"start\":49272},{\"end\":49289,\"start\":49285},{\"end\":49302,\"start\":49295},{\"end\":49314,\"start\":49309},{\"end\":49666,\"start\":49663},{\"end\":49680,\"start\":49673},{\"end\":49694,\"start\":49688},{\"end\":49703,\"start\":49701},{\"end\":49705,\"start\":49704},{\"end\":49929,\"start\":49923},{\"end\":49938,\"start\":49936},{\"end\":49948,\"start\":49944},{\"end\":49956,\"start\":49954},{\"end\":49967,\"start\":49961},{\"end\":49979,\"start\":49974},{\"end\":49995,\"start\":49986},{\"end\":50004,\"start\":50001},{\"end\":50264,\"start\":50258},{\"end\":50280,\"start\":50271},{\"end\":50292,\"start\":50286},{\"end\":50303,\"start\":50299},{\"end\":50312,\"start\":50309},{\"end\":50322,\"start\":50318},{\"end\":50334,\"start\":50327},{\"end\":50345,\"start\":50340},{\"end\":50354,\"start\":50351},{\"end\":50362,\"start\":50359},{\"end\":50641,\"start\":50635},{\"end\":50654,\"start\":50648},{\"end\":50666,\"start\":50661},{\"end\":50880,\"start\":50877},{\"end\":50891,\"start\":50886},{\"end\":50902,\"start\":50896},{\"end\":50918,\"start\":50910},{\"end\":50926,\"start\":50923},{\"end\":50934,\"start\":50931},{\"end\":50942,\"start\":50939},{\"end\":51107,\"start\":51105},{\"end\":51116,\"start\":51113},{\"end\":51127,\"start\":51121},{\"end\":51140,\"start\":51134},{\"end\":51151,\"start\":51147},{\"end\":51165,\"start\":51158},{\"end\":51175,\"start\":51171},{\"end\":51499,\"start\":51494},{\"end\":51509,\"start\":51505},{\"end\":51521,\"start\":51515},{\"end\":51535,\"start\":51528},{\"end\":51549,\"start\":51542},{\"end\":51560,\"start\":51555},{\"end\":51816,\"start\":51811},{\"end\":51826,\"start\":51822},{\"end\":51838,\"start\":51832},{\"end\":51850,\"start\":51845},{\"end\":51863,\"start\":51856},{\"end\":51877,\"start\":51870},{\"end\":52146,\"start\":52141},{\"end\":52156,\"start\":52152},{\"end\":52165,\"start\":52162},{\"end\":52174,\"start\":52170},{\"end\":52186,\"start\":52182},{\"end\":52199,\"start\":52192},{\"end\":52213,\"start\":52205},{\"end\":52224,\"start\":52219}]", "bib_author_last_name": "[{\"end\":37976,\"start\":37965},{\"end\":37996,\"start\":37988},{\"end\":38299,\"start\":38291},{\"end\":38314,\"start\":38311},{\"end\":38329,\"start\":38323},{\"end\":38674,\"start\":38671},{\"end\":38685,\"start\":38682},{\"end\":38701,\"start\":38697},{\"end\":38709,\"start\":38707},{\"end\":38722,\"start\":38719},{\"end\":38736,\"start\":38733},{\"end\":38749,\"start\":38746},{\"end\":38995,\"start\":38990},{\"end\":39007,\"start\":39002},{\"end\":39021,\"start\":39017},{\"end\":39032,\"start\":39029},{\"end\":39042,\"start\":39037},{\"end\":39050,\"start\":39046},{\"end\":39077,\"start\":39061},{\"end\":39084,\"start\":39079},{\"end\":39335,\"start\":39331},{\"end\":39346,\"start\":39344},{\"end\":39360,\"start\":39357},{\"end\":39373,\"start\":39371},{\"end\":39386,\"start\":39383},{\"end\":39396,\"start\":39393},{\"end\":39407,\"start\":39404},{\"end\":39423,\"start\":39418},{\"end\":39719,\"start\":39710},{\"end\":39733,\"start\":39728},{\"end\":39749,\"start\":39743},{\"end\":39964,\"start\":39955},{\"end\":39980,\"start\":39973},{\"end\":40283,\"start\":40280},{\"end\":40291,\"start\":40289},{\"end\":40303,\"start\":40299},{\"end\":40311,\"start\":40309},{\"end\":40552,\"start\":40546},{\"end\":40574,\"start\":40562},{\"end\":40591,\"start\":40585},{\"end\":40757,\"start\":40750},{\"end\":40779,\"start\":40766},{\"end\":40795,\"start\":40789},{\"end\":40816,\"start\":40805},{\"end\":41237,\"start\":41235},{\"end\":41251,\"start\":41247},{\"end\":41264,\"start\":41261},{\"end\":41275,\"start\":41272},{\"end\":41455,\"start\":41453},{\"end\":41470,\"start\":41465},{\"end\":41484,\"start\":41481},{\"end\":41494,\"start\":41491},{\"end\":41957,\"start\":41955},{\"end\":41972,\"start\":41967},{\"end\":41985,\"start\":41982},{\"end\":42000,\"start\":41996},{\"end\":42184,\"start\":42178},{\"end\":42208,\"start\":42197},{\"end\":42525,\"start\":42519},{\"end\":42543,\"start\":42535},{\"end\":42984,\"start\":42979},{\"end\":42993,\"start\":42991},{\"end\":43007,\"start\":43002},{\"end\":43020,\"start\":43015},{\"end\":43033,\"start\":43029},{\"end\":43044,\"start\":43041},{\"end\":43061,\"start\":43055},{\"end\":43340,\"start\":43335},{\"end\":43354,\"start\":43351},{\"end\":43370,\"start\":43366},{\"end\":43380,\"start\":43378},{\"end\":43393,\"start\":43390},{\"end\":43407,\"start\":43403},{\"end\":43716,\"start\":43711},{\"end\":43732,\"start\":43727},{\"end\":43746,\"start\":43740},{\"end\":43998,\"start\":43993},{\"end\":44160,\"start\":44155},{\"end\":44173,\"start\":44169},{\"end\":44189,\"start\":44181},{\"end\":44426,\"start\":44416},{\"end\":44442,\"start\":44433},{\"end\":44461,\"start\":44455},{\"end\":44673,\"start\":44671},{\"end\":44686,\"start\":44683},{\"end\":44699,\"start\":44695},{\"end\":44713,\"start\":44710},{\"end\":44723,\"start\":44719},{\"end\":44731,\"start\":44729},{\"end\":44961,\"start\":44955},{\"end\":44974,\"start\":44969},{\"end\":44987,\"start\":44983},{\"end\":45254,\"start\":45252},{\"end\":45277,\"start\":45261},{\"end\":45285,\"start\":45283},{\"end\":45298,\"start\":45293},{\"end\":45304,\"start\":45300},{\"end\":45566,\"start\":45559},{\"end\":45582,\"start\":45573},{\"end\":45592,\"start\":45588},{\"end\":45608,\"start\":45601},{\"end\":45619,\"start\":45615},{\"end\":45830,\"start\":45823},{\"end\":45846,\"start\":45839},{\"end\":45855,\"start\":45848},{\"end\":46197,\"start\":46189},{\"end\":46221,\"start\":46210},{\"end\":46236,\"start\":46230},{\"end\":46253,\"start\":46244},{\"end\":46530,\"start\":46524},{\"end\":46555,\"start\":46542},{\"end\":46569,\"start\":46562},{\"end\":46590,\"start\":46576},{\"end\":46852,\"start\":46839},{\"end\":46861,\"start\":46859},{\"end\":46866,\"start\":46863},{\"end\":47074,\"start\":47071},{\"end\":47090,\"start\":47083},{\"end\":47332,\"start\":47328},{\"end\":47346,\"start\":47341},{\"end\":47360,\"start\":47357},{\"end\":47374,\"start\":47370},{\"end\":47385,\"start\":47382},{\"end\":47632,\"start\":47623},{\"end\":47640,\"start\":47638},{\"end\":47652,\"start\":47647},{\"end\":47672,\"start\":47666},{\"end\":47683,\"start\":47678},{\"end\":47689,\"start\":47685},{\"end\":47927,\"start\":47922},{\"end\":47940,\"start\":47931},{\"end\":48286,\"start\":48282},{\"end\":48296,\"start\":48293},{\"end\":48310,\"start\":48306},{\"end\":48321,\"start\":48318},{\"end\":48704,\"start\":48700},{\"end\":48714,\"start\":48711},{\"end\":48727,\"start\":48722},{\"end\":48740,\"start\":48736},{\"end\":48751,\"start\":48748},{\"end\":48765,\"start\":48761},{\"end\":49010,\"start\":49006},{\"end\":49020,\"start\":49017},{\"end\":49033,\"start\":49028},{\"end\":49046,\"start\":49042},{\"end\":49057,\"start\":49054},{\"end\":49071,\"start\":49067},{\"end\":49257,\"start\":49253},{\"end\":49270,\"start\":49265},{\"end\":49283,\"start\":49279},{\"end\":49293,\"start\":49290},{\"end\":49307,\"start\":49303},{\"end\":49318,\"start\":49315},{\"end\":49671,\"start\":49667},{\"end\":49686,\"start\":49681},{\"end\":49699,\"start\":49695},{\"end\":49709,\"start\":49706},{\"end\":49934,\"start\":49930},{\"end\":49942,\"start\":49939},{\"end\":49952,\"start\":49949},{\"end\":49959,\"start\":49957},{\"end\":49972,\"start\":49968},{\"end\":49984,\"start\":49980},{\"end\":49999,\"start\":49996},{\"end\":50008,\"start\":50005},{\"end\":50269,\"start\":50265},{\"end\":50284,\"start\":50281},{\"end\":50297,\"start\":50293},{\"end\":50307,\"start\":50304},{\"end\":50316,\"start\":50313},{\"end\":50325,\"start\":50323},{\"end\":50338,\"start\":50335},{\"end\":50349,\"start\":50346},{\"end\":50357,\"start\":50355},{\"end\":50366,\"start\":50363},{\"end\":50646,\"start\":50642},{\"end\":50659,\"start\":50655},{\"end\":50670,\"start\":50667},{\"end\":50884,\"start\":50881},{\"end\":50894,\"start\":50892},{\"end\":50908,\"start\":50903},{\"end\":50921,\"start\":50919},{\"end\":50929,\"start\":50927},{\"end\":50937,\"start\":50935},{\"end\":50946,\"start\":50943},{\"end\":51111,\"start\":51108},{\"end\":51119,\"start\":51117},{\"end\":51132,\"start\":51128},{\"end\":51145,\"start\":51141},{\"end\":51156,\"start\":51152},{\"end\":51169,\"start\":51166},{\"end\":51179,\"start\":51176},{\"end\":51503,\"start\":51500},{\"end\":51513,\"start\":51510},{\"end\":51526,\"start\":51522},{\"end\":51540,\"start\":51536},{\"end\":51553,\"start\":51550},{\"end\":51564,\"start\":51561},{\"end\":51820,\"start\":51817},{\"end\":51830,\"start\":51827},{\"end\":51843,\"start\":51839},{\"end\":51854,\"start\":51851},{\"end\":51868,\"start\":51864},{\"end\":51881,\"start\":51878},{\"end\":52150,\"start\":52147},{\"end\":52160,\"start\":52157},{\"end\":52168,\"start\":52166},{\"end\":52180,\"start\":52175},{\"end\":52190,\"start\":52187},{\"end\":52203,\"start\":52200},{\"end\":52217,\"start\":52214},{\"end\":52228,\"start\":52225}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":206742345},\"end\":38281,\"start\":37846},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b1\"},\"end\":38584,\"start\":38283},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":197928508},\"end\":38951,\"start\":38586},{\"attributes\":{\"id\":\"b3\"},\"end\":39245,\"start\":38953},{\"attributes\":{\"id\":\"b4\"},\"end\":39633,\"start\":39247},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":17638609},\"end\":39902,\"start\":39635},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207650042},\"end\":40176,\"start\":39904},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":29156271},\"end\":40483,\"start\":40178},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":206741496},\"end\":40740,\"start\":40485},{\"attributes\":{\"id\":\"b9\"},\"end\":41142,\"start\":40742},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":16008444},\"end\":41443,\"start\":41144},{\"attributes\":{\"id\":\"b11\"},\"end\":41868,\"start\":41445},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2896685},\"end\":42169,\"start\":41870},{\"attributes\":{\"doi\":\"arXiv:1511.06939\",\"id\":\"b13\"},\"end\":42510,\"start\":42171},{\"attributes\":{\"id\":\"b14\"},\"end\":42898,\"start\":42512},{\"attributes\":{\"id\":\"b15\"},\"end\":43254,\"start\":42900},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":59528258},\"end\":43595,\"start\":43256},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":16612354},\"end\":43936,\"start\":43597},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":3022077},\"end\":44089,\"start\":43938},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":58370896},\"end\":44344,\"start\":44091},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":195908774},\"end\":44617,\"start\":44346},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":21066930},\"end\":44882,\"start\":44619},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":14604122},\"end\":45175,\"start\":44884},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":16461906},\"end\":45474,\"start\":45177},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":16447573},\"end\":45801,\"start\":45476},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":8205478},\"end\":46090,\"start\":45803},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":10174110},\"end\":46455,\"start\":46092},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":10795036},\"end\":46759,\"start\":46457},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":2552056},\"end\":47010,\"start\":46761},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":52084596},\"end\":47216,\"start\":47012},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":24931235},\"end\":47589,\"start\":47218},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":5362246},\"end\":47823,\"start\":47591},{\"attributes\":{\"id\":\"b32\"},\"end\":48093,\"start\":47825},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":198986427},\"end\":48631,\"start\":48095},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":24131880},\"end\":48937,\"start\":48633},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":24131880},\"end\":49243,\"start\":48939},{\"attributes\":{\"id\":\"b36\"},\"end\":49595,\"start\":49245},{\"attributes\":{\"id\":\"b37\"},\"end\":49854,\"start\":49597},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":52188056},\"end\":50199,\"start\":49856},{\"attributes\":{\"id\":\"b39\"},\"end\":50563,\"start\":50201},{\"attributes\":{\"doi\":\"WSDM. 727-735\",\"id\":\"b40\"},\"end\":50819,\"start\":50565},{\"attributes\":{\"id\":\"b41\"},\"end\":51103,\"start\":50821},{\"attributes\":{\"id\":\"b42\"},\"end\":51407,\"start\":51105},{\"attributes\":{\"id\":\"b43\"},\"end\":51751,\"start\":51409},{\"attributes\":{\"doi\":\"DASFAA. 104-120\",\"id\":\"b44\"},\"end\":52057,\"start\":51753},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":210884039},\"end\":52425,\"start\":52059}]", "bib_title": "[{\"end\":37953,\"start\":37846},{\"end\":38664,\"start\":38586},{\"end\":39702,\"start\":39635},{\"end\":39946,\"start\":39904},{\"end\":40275,\"start\":40178},{\"end\":40539,\"start\":40485},{\"end\":41226,\"start\":41144},{\"end\":41944,\"start\":41870},{\"end\":43329,\"start\":43256},{\"end\":43699,\"start\":43597},{\"end\":43984,\"start\":43938},{\"end\":44146,\"start\":44091},{\"end\":44409,\"start\":44346},{\"end\":44664,\"start\":44619},{\"end\":44948,\"start\":44884},{\"end\":45242,\"start\":45177},{\"end\":45551,\"start\":45476},{\"end\":45819,\"start\":45803},{\"end\":46179,\"start\":46092},{\"end\":46514,\"start\":46457},{\"end\":46829,\"start\":46761},{\"end\":47060,\"start\":47012},{\"end\":47320,\"start\":47218},{\"end\":47621,\"start\":47591},{\"end\":48272,\"start\":48095},{\"end\":48690,\"start\":48633},{\"end\":48996,\"start\":48939},{\"end\":49921,\"start\":49856},{\"end\":52139,\"start\":52059}]", "bib_author": "[{\"end\":37978,\"start\":37955},{\"end\":37998,\"start\":37978},{\"end\":38301,\"start\":38283},{\"end\":38316,\"start\":38301},{\"end\":38331,\"start\":38316},{\"end\":38676,\"start\":38666},{\"end\":38687,\"start\":38676},{\"end\":38703,\"start\":38687},{\"end\":38711,\"start\":38703},{\"end\":38724,\"start\":38711},{\"end\":38738,\"start\":38724},{\"end\":38751,\"start\":38738},{\"end\":38997,\"start\":38984},{\"end\":39009,\"start\":38997},{\"end\":39023,\"start\":39009},{\"end\":39034,\"start\":39023},{\"end\":39044,\"start\":39034},{\"end\":39052,\"start\":39044},{\"end\":39079,\"start\":39052},{\"end\":39086,\"start\":39079},{\"end\":39337,\"start\":39323},{\"end\":39348,\"start\":39337},{\"end\":39362,\"start\":39348},{\"end\":39375,\"start\":39362},{\"end\":39388,\"start\":39375},{\"end\":39398,\"start\":39388},{\"end\":39409,\"start\":39398},{\"end\":39425,\"start\":39409},{\"end\":39721,\"start\":39704},{\"end\":39735,\"start\":39721},{\"end\":39751,\"start\":39735},{\"end\":39966,\"start\":39948},{\"end\":39982,\"start\":39966},{\"end\":40285,\"start\":40277},{\"end\":40293,\"start\":40285},{\"end\":40305,\"start\":40293},{\"end\":40313,\"start\":40305},{\"end\":40554,\"start\":40541},{\"end\":40576,\"start\":40554},{\"end\":40593,\"start\":40576},{\"end\":40759,\"start\":40742},{\"end\":40781,\"start\":40759},{\"end\":40797,\"start\":40781},{\"end\":40818,\"start\":40797},{\"end\":41239,\"start\":41228},{\"end\":41253,\"start\":41239},{\"end\":41266,\"start\":41253},{\"end\":41277,\"start\":41266},{\"end\":41457,\"start\":41445},{\"end\":41472,\"start\":41457},{\"end\":41486,\"start\":41472},{\"end\":41496,\"start\":41486},{\"end\":41959,\"start\":41946},{\"end\":41974,\"start\":41959},{\"end\":41987,\"start\":41974},{\"end\":42002,\"start\":41987},{\"end\":42186,\"start\":42171},{\"end\":42210,\"start\":42186},{\"end\":42527,\"start\":42512},{\"end\":42545,\"start\":42527},{\"end\":42986,\"start\":42974},{\"end\":42995,\"start\":42986},{\"end\":43009,\"start\":42995},{\"end\":43022,\"start\":43009},{\"end\":43035,\"start\":43022},{\"end\":43046,\"start\":43035},{\"end\":43063,\"start\":43046},{\"end\":43342,\"start\":43331},{\"end\":43356,\"start\":43342},{\"end\":43372,\"start\":43356},{\"end\":43382,\"start\":43372},{\"end\":43395,\"start\":43382},{\"end\":43409,\"start\":43395},{\"end\":43718,\"start\":43701},{\"end\":43734,\"start\":43718},{\"end\":43748,\"start\":43734},{\"end\":44000,\"start\":43986},{\"end\":44162,\"start\":44148},{\"end\":44175,\"start\":44162},{\"end\":44191,\"start\":44175},{\"end\":44428,\"start\":44411},{\"end\":44444,\"start\":44428},{\"end\":44463,\"start\":44444},{\"end\":44675,\"start\":44666},{\"end\":44688,\"start\":44675},{\"end\":44701,\"start\":44688},{\"end\":44715,\"start\":44701},{\"end\":44725,\"start\":44715},{\"end\":44733,\"start\":44725},{\"end\":44963,\"start\":44950},{\"end\":44976,\"start\":44963},{\"end\":44989,\"start\":44976},{\"end\":45256,\"start\":45244},{\"end\":45279,\"start\":45256},{\"end\":45287,\"start\":45279},{\"end\":45300,\"start\":45287},{\"end\":45306,\"start\":45300},{\"end\":45568,\"start\":45553},{\"end\":45584,\"start\":45568},{\"end\":45594,\"start\":45584},{\"end\":45610,\"start\":45594},{\"end\":45621,\"start\":45610},{\"end\":45832,\"start\":45821},{\"end\":45848,\"start\":45832},{\"end\":45857,\"start\":45848},{\"end\":46199,\"start\":46181},{\"end\":46223,\"start\":46199},{\"end\":46238,\"start\":46223},{\"end\":46255,\"start\":46238},{\"end\":46532,\"start\":46516},{\"end\":46557,\"start\":46532},{\"end\":46571,\"start\":46557},{\"end\":46592,\"start\":46571},{\"end\":46854,\"start\":46831},{\"end\":46863,\"start\":46854},{\"end\":46868,\"start\":46863},{\"end\":47076,\"start\":47062},{\"end\":47092,\"start\":47076},{\"end\":47334,\"start\":47322},{\"end\":47348,\"start\":47334},{\"end\":47362,\"start\":47348},{\"end\":47376,\"start\":47362},{\"end\":47387,\"start\":47376},{\"end\":47634,\"start\":47623},{\"end\":47642,\"start\":47634},{\"end\":47654,\"start\":47642},{\"end\":47674,\"start\":47654},{\"end\":47685,\"start\":47674},{\"end\":47691,\"start\":47685},{\"end\":47929,\"start\":47913},{\"end\":47942,\"start\":47929},{\"end\":48288,\"start\":48274},{\"end\":48298,\"start\":48288},{\"end\":48312,\"start\":48298},{\"end\":48323,\"start\":48312},{\"end\":48706,\"start\":48692},{\"end\":48716,\"start\":48706},{\"end\":48729,\"start\":48716},{\"end\":48742,\"start\":48729},{\"end\":48753,\"start\":48742},{\"end\":48767,\"start\":48753},{\"end\":49012,\"start\":48998},{\"end\":49022,\"start\":49012},{\"end\":49035,\"start\":49022},{\"end\":49048,\"start\":49035},{\"end\":49059,\"start\":49048},{\"end\":49073,\"start\":49059},{\"end\":49259,\"start\":49245},{\"end\":49272,\"start\":49259},{\"end\":49285,\"start\":49272},{\"end\":49295,\"start\":49285},{\"end\":49309,\"start\":49295},{\"end\":49320,\"start\":49309},{\"end\":49673,\"start\":49663},{\"end\":49688,\"start\":49673},{\"end\":49701,\"start\":49688},{\"end\":49711,\"start\":49701},{\"end\":49936,\"start\":49923},{\"end\":49944,\"start\":49936},{\"end\":49954,\"start\":49944},{\"end\":49961,\"start\":49954},{\"end\":49974,\"start\":49961},{\"end\":49986,\"start\":49974},{\"end\":50001,\"start\":49986},{\"end\":50010,\"start\":50001},{\"end\":50271,\"start\":50258},{\"end\":50286,\"start\":50271},{\"end\":50299,\"start\":50286},{\"end\":50309,\"start\":50299},{\"end\":50318,\"start\":50309},{\"end\":50327,\"start\":50318},{\"end\":50340,\"start\":50327},{\"end\":50351,\"start\":50340},{\"end\":50359,\"start\":50351},{\"end\":50368,\"start\":50359},{\"end\":50648,\"start\":50635},{\"end\":50661,\"start\":50648},{\"end\":50672,\"start\":50661},{\"end\":50886,\"start\":50877},{\"end\":50896,\"start\":50886},{\"end\":50910,\"start\":50896},{\"end\":50923,\"start\":50910},{\"end\":50931,\"start\":50923},{\"end\":50939,\"start\":50931},{\"end\":50948,\"start\":50939},{\"end\":51113,\"start\":51105},{\"end\":51121,\"start\":51113},{\"end\":51134,\"start\":51121},{\"end\":51147,\"start\":51134},{\"end\":51158,\"start\":51147},{\"end\":51171,\"start\":51158},{\"end\":51181,\"start\":51171},{\"end\":51505,\"start\":51494},{\"end\":51515,\"start\":51505},{\"end\":51528,\"start\":51515},{\"end\":51542,\"start\":51528},{\"end\":51555,\"start\":51542},{\"end\":51566,\"start\":51555},{\"end\":51822,\"start\":51811},{\"end\":51832,\"start\":51822},{\"end\":51845,\"start\":51832},{\"end\":51856,\"start\":51845},{\"end\":51870,\"start\":51856},{\"end\":51883,\"start\":51870},{\"end\":52152,\"start\":52141},{\"end\":52162,\"start\":52152},{\"end\":52170,\"start\":52162},{\"end\":52182,\"start\":52170},{\"end\":52192,\"start\":52182},{\"end\":52205,\"start\":52192},{\"end\":52219,\"start\":52205},{\"end\":52230,\"start\":52219}]", "bib_venue": "[{\"end\":38047,\"start\":37998},{\"end\":38422,\"start\":38346},{\"end\":38756,\"start\":38751},{\"end\":38982,\"start\":38953},{\"end\":39321,\"start\":39247},{\"end\":39757,\"start\":39751},{\"end\":40021,\"start\":39982},{\"end\":40317,\"start\":40313},{\"end\":40599,\"start\":40593},{\"end\":40935,\"start\":40818},{\"end\":41281,\"start\":41277},{\"end\":41637,\"start\":41496},{\"end\":42007,\"start\":42002},{\"end\":42335,\"start\":42226},{\"end\":42698,\"start\":42545},{\"end\":42972,\"start\":42900},{\"end\":43413,\"start\":43409},{\"end\":43753,\"start\":43748},{\"end\":44003,\"start\":44000},{\"end\":44199,\"start\":44191},{\"end\":44467,\"start\":44463},{\"end\":44737,\"start\":44733},{\"end\":45012,\"start\":44989},{\"end\":45311,\"start\":45306},{\"end\":45625,\"start\":45621},{\"end\":45901,\"start\":45857},{\"end\":46261,\"start\":46255},{\"end\":46595,\"start\":46592},{\"end\":46874,\"start\":46868},{\"end\":47103,\"start\":47092},{\"end\":47391,\"start\":47387},{\"end\":47695,\"start\":47691},{\"end\":47911,\"start\":47825},{\"end\":48351,\"start\":48323},{\"end\":48773,\"start\":48767},{\"end\":49079,\"start\":49073},{\"end\":49407,\"start\":49320},{\"end\":49661,\"start\":49597},{\"end\":50014,\"start\":50010},{\"end\":50256,\"start\":50201},{\"end\":50633,\"start\":50565},{\"end\":50875,\"start\":50821},{\"end\":51244,\"start\":51181},{\"end\":51492,\"start\":51409},{\"end\":51809,\"start\":51753},{\"end\":52234,\"start\":52230},{\"end\":45921,\"start\":45903}]"}}}, "year": 2023, "month": 12, "day": 17}