{"id": 232307927, "updated": "2023-10-06 05:25:25.517", "metadata": {"title": "Project-Level Encoding for Neural Source Code Summarization of Subroutines", "authors": "[{\"first\":\"Aakash\",\"last\":\"Bansal\",\"middle\":[]},{\"first\":\"Sakib\",\"last\":\"Haque\",\"middle\":[]},{\"first\":\"Collin\",\"last\":\"McMillan\",\"middle\":[]}]", "venue": "2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC)", "journal": "2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC)", "publication_date": {"year": 2021, "month": 3, "day": 22}, "abstract": "Source code summarization of a subroutine is the task of writing a short, natural language description of that subroutine. The description usually serves in documentation aimed at programmers, where even brief phrase (e.g.\"compresses data to a zip file\") can help readers rapidly comprehend what a subroutine does without resorting to reading the code itself. Techniques based on neural networks (and encoder-decoder model designs in particular) have established themselves as the state-of-the-art. Yet a problem widely recognized with these models is that they assume the information needed to create a summary is present within the code being summarized itself - an assumption which is at odds with program comprehension literature. Thus a current research frontier lies in the question of encoding source code context into neural models of summarization. In this paper, we present a project-level encoder to improve models of code summarization. By project-level, we mean that we create a vectorized representation of selected code files in a software project, and use that representation to augment the encoder of state-of-the-art neural code summarization techniques. We demonstrate how our encoder improves several existing models, and provide guidelines for maximizing improvement while controlling time and resource costs in model size.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2103.11599", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iwpc/BansalHM21", "doi": "10.1109/icpc52881.2021.00032"}}, "content": {"source": {"pdf_hash": "3a02d68164b249a2ecabbb6e0d9ba6bf8e493d78", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2103.11599v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2103.11599", "status": "GREEN"}}, "grobid": {"id": "a47011ff54a5d53970ed3b1dac7fb86d9ac56f56", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3a02d68164b249a2ecabbb6e0d9ba6bf8e493d78.txt", "contents": "\nProject-Level Encoding for Neural Source Code Summarization of Subroutines\n\n\nAakash Bansal abansal1@nd.edu \nDept. of Computer Science and Engineering\nUniversity of Notre Dame Notre Dame\nINUSA\n\nSakib Haque shaque@nd.edu \nDept. of Computer Science and Engineering\nUniversity of Notre Dame Notre Dame\nINUSA\n\nCollin Mcmillan \nDept. of Computer Science and Engineering\nUniversity of Notre Dame Notre Dame\nINUSA\n\nProject-Level Encoding for Neural Source Code Summarization of Subroutines\nIndex Terms-source code summarizationautomatic docu- mentation generationneural networks\nSource code summarization of a subroutine is the task of writing a short, natural language description of that subroutine. The description usually serves in documentation aimed at programmers, where even brief phrase (e.g. \"compresses data to a zip file\") can help readers rapidly comprehend what a subroutine does without resorting to reading the code itself. Techniques based on neural networks (and encoder-decoder model designs in particular) have established themselves as the state-of-the-art. Yet a problem widely recognized with these models is that they assume the information needed to create a summary is present within the code being summarized itself -an assumption which is at odds with program comprehension literature. Thus a current research frontier lies in the question of encoding source code context into neural models of summarization. In this paper, we present a project-level encoder to improve models of code summarization. By project-level, we mean that we create a vectorized representation of selected code files in a software project, and use that representation to augment the encoder of state-of-the-art neural code summarization techniques. We demonstrate how our encoder improves several existing models, and provide guidelines for maximizing improvement while controlling time and resource costs in model size.\n\nI. INTRODUCTION\n\nSource code summarization is the task of writing short, natural language descriptions of that code [1], [2]. Typical targets of summarization are the subroutines of a software project. The purpose of the descriptions is to provide human readers with a big picture view of what each subroutine does. Even a single phrase e.g. \"compresses data to a zip file\" can help a person understand code without having to read every detail of that code [3]. Summaries of subroutines form the foundation of much documentation aimed at programmers such as JavaDocs [4], and the literature is replete with studies demonstrating how programmers often rely on these summaries, only turning to reading the code itself as a last resort [5]. And while a majority of documentation is still written manually, recent research has made inroads towards automatic code summarization [6].\n\nThe backbone of almost all state-of-the-art approaches to automatic source code summarization is the neural encoderdecoder model architecture [7]- [9]. This architecture has its This work is supported in part by NSF CCF-1452959 and CCF-1717607 grants.\n\nroots in machine translation [10], in which the encoder creates a vectorized representation of a sentence in one language (e.g. English), while the decoder creates a representation of that same sentence in a different language (e.g. French). When trained with enough data (on the order of millions of examples [11]), these models can learn to associate patterns in the encoder representation to patterns in the decoder representation. After training, the encoder can be given an input example, and the model can generate a likely decoder representation and therefore a likely output example -and translate French sentences to English. For source code, the encoder's job is to represent the source code, while the decoder represents the source code summary -give the encoder source code, and the decoder generates a summary.\n\nThe obvious problem with these approaches is that they can only generate a summary based on whatever source code is passed to the encoder. Thus these approaches make a tacit assumption that all of the information necessary to generate that summary is present in that source code. This assumption is at odds with decades of program comprehension literature [12]- [14]. This literature is quite clear that high-level descriptions such as summaries very often contain concepts that can only be understood in the context of the other code in the same software project. To paraphrase a classic example, a subroutine called book() can only be fully understood if it is also known that it exists in a class called Seats in a project called AircraftTravel [15].\n\nIn this paper, we present a project-level encoder to augment existing encoder-decoder neural models of source code summarization. Our approach is \"project level\" in that it creates a vectorized representation of a subset of code files in a software project. Our approach augments existing models in that the output of our approach may be combined with encoder portion of most existing code summarization models: most models contain an encoder for the source code itself that produces some vectorized representation of that code, and our encoder extends that representation. The advantage to our encoder is that it provides context to the model about the software project in which a subroutine exists, so that the model does not rely only on the information in that subroutine.\n\nWe evaluate our project encoder in three ways. First, we implement our project encoder as an addition to four existing neural source code summarization techniques. We demonstrate that our encoder boosts the performance of these techniques by between 4 and 8% in terms of BLEU scores in a large Java dataset, and between 9% and 17.5% in ensemble models in that dataset. Second, we compare our whole-project encoder with a competitive approach that attempts to summarize the context surrounding code, and found between 1.5% and 7% improvement in terms of BLEU score in the Java dataset. Third, we study the time and resource costs of our project encoder, to determine the costs associated with the increased performance of our approach.\n\nWe provide all data and implementations via our online appendix (see Section VII).\n\n\nII. BACKGROUND & RELATED WORK\n\nThis section describes related work and supporting technologies, namely the neural encoder-decoder architecture.\n\nA. Source Code Summarization Figure 1 shows key papers related to source code summarization in the last four years. The list is not exhaustive and only includes peer-reviewed work. Papers are broadly categorized as based on the encoder-decoder architecture (column E), and whether their novelty (and primary means of improvement over baselines) is based on structural information about the source code itself (column S), or contextual information about surrounding source code (column C). Two observations are apparent. First, recent approaches are based on some variant of an encoder-decoder architecture. Prior to 2017, code summarization research focused on templates or information retrieval, but these have recently given way to neural encoder-decoder designs [2], [6], [32], [33].\n\nA second observation is that the strong trend has been to squeeze ever more information out of the source code being E S C *Loyola et al. (2017) [16] x * Lu et al. (2017) [17] x *Jiang et al. (2017) [18] x *Hu et al. (2018) [19] x *Hu et al. (2018) [9] x x *   [20] x x *Wan et al. (2018) [21] x x *Liang et al. (2018) [22] x x *Alon et al. (2019) [23], [24] x x *Gao et al. (2019) [25] x *LeClair et al. (2019) [7] x x *Mesbah et al. (2019) [26] x x *Nie et al. (2019) [27] x x *Haldar et al. (2020) [28] x x *Ahmad et al. (2020) [29] x *Haque et al. (2020) [30] x x *Z\u00fcgner et al. (2021) [8] x x *Liu et al. (2021) [31] x x *<this paper> x x Fig. 1. Key peer-reviewed related work from the last four years. Column E means the approach is an encoder-decoder architecture. S means that the improvement of the model relies primarily on structural information about the source code being summarized, such as a subroutine's AST. C means the improvement is primarily due to contextual information.\n\nsummarized itself, in the form of structural information. The trend began around the time Hu et al. [9] used the abstract syntax tree to mark up the source code tokens in the encoder's input sequence, and was followed up by Allamanis et al. [20], LeClair et al. [7], among others noted in the table, with different AST-based code representations. Advancement continued as AST path-based encoders [24], [34] were followed by AST graph neural network-based encoders [35]. While some research has been dedicated to novel representations of the text in code (e.g. via Transformer models [29]), the tendency has been towards more and more complex representations of the code structure. Very recently, multi-edge and hybrid GNN structures have been devised [8], [31]. Much more rare is work that attempts to improve performance by integrating contextual information. Code context may be broadly defined as the source code in the methods, files, and packages surrounding a particular snippet of code [36]. Program comprehension literature is quite clear that the context surrounding source code is critical to understanding that code, with work ranging from psychological/physiological studies [12]- [14] to empirical/technical solutions [37]- [40] verifying this conclusion. The use of code context for summarization was mainstream among older template-and IR-based techniques [2], [32], [41], though it is currently overlooked among neural network-based solutions. Haque et al. [30] are a notable exception. They use text from each function in the same file as part of the encoder portion of their model, and show improvement over different baselines.\n\nThis paper focuses on contextual information. Specifically, we focus on project context, which is the context provided by every source code file in the same project as the subroutine we are summarizing. This context is more broad than the filelevel context proposed by Haque et al. [30], but like that work, our approach is complementary to most encoder-decoder approaches rather than competitive. Our approach augments the solutions based on the structure of the code itself, it does not replace them.\n\n\nB. Neural Encoder-Decoder Architecture\n\nThe neural encoder-decoder architecture revolves around two independent vectorized representations of parallel data. The parallel data may be a sentence in one language and its translation in another language, an image and a caption of that image, or a subroutine and a natural language summary of that subroutine. Since each \"side\" of the parallel data may be quite different, the means of generating the vectorized representation will also be different. Usually the purpose of an encoder-decoder model is to create one \"side\" of the data out of the other (e.g. create a summary out of a subroutine). The input side is referred to as the encoder, and the output side is referred to as the decoder. Thus to train a model to e.g. translate from French to English, the encoder receives French sentences and the decoder receives the parallel English sentences. The encoder-decoder architecture has its roots in work by Sutskever et al. [42] published 2014. Since then the architecture has blossomed and found an extremely wide variety of uses, as several survey papers testify [43]- [45].\n\nThe vast majority of encoder-decoder architectures work because of a similarity calculation that links the encoder and decoder representation, called an attention mechanism. Essentially what the attention mechanism does is compute the similarity between the encoder and decoder representations, which helps the model learn to associate features in those representations. For example, a single word in a French sentence would be associated with its counterpart in the English sentence. Attention was proposed by Bahdanau et al. [10] and has become an integral part of most encoder-decoder models.\n\nThis paper follows in the tradition of most encoder-decoder models, though with a small twist to the attention mechanism. As the next section will show, we maintain an independent attention mechanism for our whole-project encoder, so the model can learn to attend to both the encoder for that subroutine and our whole-project encoder. In effect, the model will learn from both a local context of the subroutine itself and a global context of the whole software project. When defined in these terms, our work is related to \"cascade attention\" from image processing [46]- [49]. For example, work by Wang et al. [50] detects human emotion with a closeup of a person's face and also a zoomed out image of the entire room. The \"cascade\" is that the model attends to both the closeup and the zoomed out image. The idea is that it may detect crying in a face, but then understand it as either sadness or happiness depending on the context. Likewise, our approach is to learn from the subroutine's source code (via any number of existing encoders), then form a better understanding of it with our whole-project encoder.\n\n\nIII. OUR APPROACH\n\nOur approach, in a nutshell, is to create an encoder of a selection of the files in the same project as a subroutine, then combine this encoder with an arbitrary encoder of the subroutine itself. This section starts with our definition of project context. We then provide an overview of the encoder and guidelines for combining with existing models.\n\n\nA. Project Context\n\nWe define \"project context\" as all source code files of the same language in the whole software project in which a subroutine resides. For example, for a Java method, the project context would be all other Java files in the same project. The advantage of this broad definition of project context is that it allows the model to learn from the high level concepts that are described in many areas of the project (we illustrate this advantage with examples in Section VI). A potential disadvantage is that the project context will often be very large. A risk is that the model size could become so large that it is not feasible due to time or resource constraints -at the time of writing, not every user may be expected to have a GPU with 16gb VRAM, for instance. While we study this risk in RQ 4 , controlling these potential costs is a key factor in our model design. Therefore, even though project context is defined as all source code files, not all information from all files will be included in the model.\n\n\nB. Model Overview\n\nOur model centers around four vector spaces: the word, subroutine, file, and project embeddings. The input to these is regulated by five hyperparameters, noted in the figures below:\n\nWord Embedding The word embedding is identical to that presented in many papers on neural NLP topics, including code summarization. Essentially, each word is represented as an elength vector. To control model size, a maximum of the first v most-common words is included in the embedding space, others are marked with a default out-of-vocab token, also in the embedding space. A \"word\" in source code is defined by the preprocessing procedure. We use the preprocessor recommended for code summarization by LeClair et al. [11].\n\nSubroutine Embedding The subroutine embedding results in a vectorized representation of each subroutine. The input to the subroutine embedding is the word embedding vector for the first w words in the subroutine. Then we pass these words as a sequence through a recurrent neural network. The final state of that RNN is the vectorized representation of the subroutine. We chose to use the first w words (as opposed to w random words, words ranked via tf/idf, etc.) because these words will include the signature of the method, which has been shown to be the most important component for summarization [51].\n\nFile Embedding The file embedding results in a vectorized representation of each file. The input is the embedding for the first s subroutines in a file -an s x e matrix because each subroutine is represented with an e-length vector. We then use each row in the matrix as a position in a sequence, which we send to an RNN. The final state of the RNN is the file embedding vector. An RNN is a reasonable choice to combine subroutine vectors because the subroutines occur in the file in an order defined by the author of that file. The meaning of this order may be disputed, however, so future work may consider aggregating these vectors by some other means such as averaging.\n\nProject Embedding The project embedding output is the final output of the project encoder, prior to applying attention.\n\nThe input is the file embedding for f files in the project. We chose these files from the project with an operation SELECT. In our implementation, the SELECT operation randomly chooses f files from the project for each subroutine -each subroutine has a new f random selections. The output of the project embedding is an f x e matrix in which each row is a file embedding and each column is an index in the vector representation of those files. Note that we do not aggregate this matrix into a single vector. The reason is that we use an attention mechanism (not shown in the figure above) to attend each position in the decoder to each position in this project embedding. The design of our attention mechanism is identical to Luong et al. [52], though in principle another may be used. The result is that the model will learn to attend to the most important files in the project embedding. We present an example of how attention to the project embedding helps the model in Section VI.\n\n\nC. Implementation Guidelines\n\nOur implementation guidelines fall into two categories: hyperparameter/setup recommendations, and suggestions for integration with other encoder-decoder models.\n\n1) Hyperparameters: While a grid search for every parameter is not feasible due to high computation costs, we chose the following based on both related literature and pilot tests: The values of 100 for e and 10,000 for v are based on successful results and recommendations by LeClair et al. [11] for neural source code summarization. The value for w is based on findings that the signature of a subroutine typically contains the most valuable textual information about that subroutine (since it neatly condenses the return type, name, and parameter types in a few words) -we chose 25 because that value covers the entire signature in a majority of subroutines and because several RNN designs have been shown to lose the ability to preserve dependencies when the sequence becomes too long. We chose a GRU as the RNN as a balance between ability to preserve dependencies and time cost of computation.\n\nThe values for s and f are more subjective. On the one hand, maximizing these numbers means the model can consider much more of the project context. But on the other hand, computation and memory cost will rapidly become prohibitive. Consider that one file is 100kb of memory in the model (s x w x e x 4 bytes = 10 x 25 x 100 x 4 bytes). Each project context matrix is then 1mb (f = 10 files). The costs add up because the datasets may involve millions of subroutines.\n\n2) Integration: Recall that our intent for our whole-project encoder is to be integrated with the encoder portion of an existing encoder-decoder model. The simplest means of integration is to treat the whole-project encoder as independent of all other parts of the model, and connect its output to the existing encoder's output after attention is applied. Consider a \"vanilla\" seq2seq-like model like those used in the first neural code summarization papers [9], [33], that has a single RNN as an encoder of the words in the subroutines and a single RNN as the decoder for the words in the summary. This model would typically have an attention mechanism between the encoder and decoder which would adjust the emphasis of the information in the encoder based on the decoder. Then the attended encoder output would be combined to the decoder output and connected to a fully-connected output, as below:\n\nIntegrating this model with our whole-project encoder would involve rewiring the output of the decoder to an attention mechanism for the whole-project encoder (in addition to the pre-existing encoder), as mentioned under the Project Embedding heading in the previous section. Then the output of the existing encoder, the whole-project encoder, and the decoder would be combined and connected to the fullyconnected output layer:\n\nThree key details stand out as questions for this implementation (for maximum clarity, readers may elect to follow along in our implementation in file models/attendgru_pc.py in our online appendix (Section VII)). First, we combine the output of the encoders and the decoder by concatenating the matrices, which triples the vector length. We then use a fully-connected layer to squash these long vectors back to the specified vector size e (lines 80-85 in the implementation). The effect is that the model learns how to combine the vectors during training.\n\nSecond, we share the word embedding space between the code/text encoder and the whole-project encoder (around line 64 in the implementation). This is possible because both models use the same vocabulary, and saves both memory space and computation time. Separate word embeddings would be necessary for different vocabularies, or if it is desirable to use a pretrained embedding, etc.\n\nThird, the project context input is separate from the other encoder/decoder input, and must be extracted from the dataset prior to training. This requirement is not likely to be a problem for models that already use the source code of the subroutines to generate summaries, but there may exist application domains where this data is not available.\n\n\nIV. EVALUATION\n\nIn this section, we describe our evaluation, including research questions, methodology, datasets, and baselines.\n\n\nA. Research Questions\n\nOur research objective is to determine the degree of difference in performance that our whole-project encoder imbues on other recent neural code summarization techniques. We explore this difference from several angles by asking the following Research Questions (RQs): RQ 1 What is the difference in performance of recent baselines when augmented with our encoder, according to standard quality metrics over a large dataset? RQ 2 What is the difference in performance when measuring only the action word prediction quality? RQ 3 What is the difference in performance compared to a baseline code context encoder? RQ 4 What is the cost of the performance increase in terms of model time to train? The rationale behind RQ 1 is that the vast majority of neural code summarization research uses a set of established metrics (namely, BLEU) to evaluate the quality of the predicted summaries to a gold set. We follow this practice to compare the baselines to our augmented versions of those baselines. Evaluations in many papers stop here. Yet, complaints are rising that the accepted evaluation practice may not capture quality to the extent desired [53], so we ask several more RQs to give a more complete picture.\n\nWe ask RQ 2 in light of new recommendations by Haque et al. [54] on evaluating code summarization techniques. They observe that an overwhelming majority of code summaries start with an action word, in keeping with style guide recommendations (e.g. \"connects to game server\" or \"adds row to sql table\"). They find that this action word is a critical piece of the prediction quality, and recommend that the quality of the prediction of these words should be assessed independently from the assessment of the entire summary output.\n\nThe purpose of RQ 3 is to evaluate our approach against a baseline for contextual information. Recall that most code summarization techniques focus on the code within a subroutine (or other code snippet) itself. Our approach augments these techniques. However, at least one other code context encoder has been proposed, so we evaluate against it.\n\nThe rationale behind RQ 4 is that adding our whole-project encoder will impose some time cost over the baselines, and recent work from industry reports that training time due to added model complexity creates engineering difficulties in practice [55]. We study this cost to guide cost-benefit analysis to using our approach.\n\n\nB. Methodology\n\nOur methodology for answering RQ 1 closely follows the procedures of almost all neural source code summarization papers to date. We obtain two datasets of subroutines and summaries of those subroutines, and divide them into training/validation/test subsets (our dataset preparation procedures described in the next section). Then we train each of our baselines (also described below) with these datasets to a maximum of 10 epochs. We use the teacher forcing training procedure, as do most recent code summarization papers [34], [35]. We chose the trained model from the epoch that achieved the highest validation accuracy, so each baseline has the opportunity to find an optimum within a reasonable training time ceiling (each epoch for most models takes 2-3 hours, so ten epochs is approximately 24 hours). Then we use each baseline's trained model to predict a code summary for the subroutines in the test set. Finally, we report the BLEU [56] and ROUGE-LCS [57] scores for each baseline. We repeat the entire procedure for our versions of the baselines that we augment with the whole-project encoder. Note that this procedure for RQ 1 is not novel -our intent is to adhere to community standards.\n\nWe elected to focus on an in-depth metrics-driven evaluation rather than a human study. While human studies are often considered a gold standard for evaluation, Chatzikoumi et al. [58] point out that reality is more nuanced. Human studies are very valuable, but have two key problems. First, they are not reproducible because people are subject to biases, fatigue, mistakes, and other factors, so people may give very different results. Second, humans can only be expected to evaluate a few dozen or hundred samples. In this paper, we have 24 model configurations to test, and a test set with tens of thousands of samples. Therefore, we decided to focus on an in-depth analysis of metrics-driven evaluation.\n\nTo answer RQ 2 , we follow the recommendations of Haque et al. [54]. The training process is almost identical to RQ 1 . The difference is that a filter based on the Stanford NLP package [59] is used to extract the action word from the gold set summary (in practice, this is usually the first word), and the model is trained to predict just that word. Then during testing, the model is asked to predict the action word for the subroutines in the test set. Precision and Recall [60] are used to assess the quality of the predictions for each action word: precision is the percent of predictions of that action word which were correct, recall is the percent of instances of that action word in the gold set that are predicted. The macro average of these precision and recall values across all action words is reported. For clarity, we also produce confusion matrices to the extent possible within page limits.\n\nFor brevity, we select only a subset of the best-performing approaches from RQ 1 and RQ 2 as representative examples for the remaining RQs. However, we provide further results and details in our online appendix.\n\nOur methodology for RQ 3 is to follow the same procedures as in RQ 1 and RQ 2 , except to compare models augmented with our whole-project encoder to models augmented with a file context encoder proposed by Haque et al. [30].\n\nFor RQ 4 , we measure the size and training time for each of the models during training for RQ 1 . We report these resource costs alongside performance improvements for those models.\n\n\nC. Datasets\n\nWe use a Java dataset of 2.1m Java methods from 28k projects created by LeClair et al. [11] under strict quality guidelines. These guidelines were tested for their effect on code summarization results, namely that the training and test sets are split by project, so that data from the test set does not leak into the test set by virtue of being in the same project. We do not use datasets from other papers because they tend to be drawn from the same set of projects on online, opensource repositories (namely, Github), they tend to be smaller, and they are not vetted to the degree as this Java dataset.\n\nWe made one key change to the dataset in this paper when compared to previous papers: we improved the filter for code clones among the subroutines. The original configuration in the datasets filtered code clones only by exact duplicates. Since then, a study by Microsoft Research determined that this filter was insufficient for some ML tasks related to code, and recommended a new filtration procedure [61]. We applied that filter to the dataset in this study. The results we report for baselines in our experiments may have different values (usually lower values) than reported in the original papers for those baselines even for the same datasets. The reason for this difference is our stricter removal of code clones. It was necessary to rerun all experiments rather than rely on results reported in earlier papers, though the only difference in data or configuration was the code clone filtration procedure.\n\n\nD. Baselines\n\nWe use four baseline neural code summarization techniques. We then augment each with our whole-project encoder. At a technical level, we build our implementations in a framework provided by Haque et al. [30] in their reproducibility package for their paper on file context encoding. attendgru is a typical seq2seq-like design like those used in early neural code summarization papers (and mentioned in Section III-C2). The only input to the encoder is the text from the source code of the subroutine itself.\n\nast-attendgru was proposed by LeClair et al. [7] and built on attendgru as well as work by Hu et al. [9]. It uses a flattened AST to represent subroutines. graph2seq is a representative example in a recent class of graph neural network (GNN)-based techniques. These techniques use information extracted from the AST and other relationships in code [8], [31], [35].\n\ncode2seq is a representative of AST path-based representations of code. This baseline is a faithful reimplementation of a model proposed by Alon et al. [34], though with several hyperparameter changed to match those in other baselines.\n\nWe denote the versions of these baselines augmented with our whole-project encoder with the suffix -pc for \"project context.\" For example, attendgru-pc and code2seq-pc.\n\nFor RQ 3 , we use the file context encoder from Haque et al. [30] as a baseline. Models augmented with the file context encoder are denoted with the suffix -fc.\n\n\nE. Software / Hardware Details\n\nOur hardware platform consisted of an HP Z-640 workstation with a Xeon E-1650v4 CPU, 128GB system memory, and two Nvidia Quadro P5000 GPUs with 16GB VRAM each. Key software included CUDA 10.0 and Tensorflow 2.4.\n\n\nF. Threats to Validity\n\nThe key threats to validity to this study include the datasets and the implementation details. We chose a vetted dataset with millions of examples, but it is possible that results may not generalize to all datasets or other languages. Likewise, results may vary given the plethora of implementation decisions, such as the means of combining the whole-project encoder output with other encoder output. Caution is advised in drawing conclusions from these results beyond the scope of large opensource dataset in Java, or when implementation details differ significantly from those presented.\n\n\nV. EVALUATION RESULTS\n\nIn this section, we discuss our evaluation results, including answers to our research questions and supporting analysis.\n\n\nA. RQ 1 : Effect of Augmenting Baselines\n\nWe found improved levels of BLEU and ROUGE scores across several baselines and configurations, when comparing default versions of the baselines to versions augmented with our project encoder. Figure 2 summarizes these results. We report results under two key conditions: solo and ensemble. A solo model is a single trained model -it includes the model weights of the epoch which achieved the highest validation accuracy, under the training procedure described in Section IV-B. An ensemble model combines two trained models. For example, the models for attendgru and attendgru-pc would be combined to form an ensemble model denoted \"nc+fc\" (no context plus file context, see first column of Ensemble Models table in Figure 2). The combination procedure is to calculate the element-wise mean of the output predictions from each model, as recommended by Garmash et al. [62]. We use this procedure in light of experimental findings for ensemble neural code summarization models by LeClair et al. [7].\n\nTwo observations stand out for the solo models. First, for the three baselines attendgru, ast-attendgru, and graph2seq, aggregate BLEU score improves between 4 and 8% when our project encoder is added to the model. The greatest improvement occurred for attendgru, which rose from 15.87 to 17.19 BLEU. Note that this version is the one described in our Integration example in Section III-C2. It shows that even a relatively simple baseline can achieve competitive BLEU scores by adding project context (attendgru is just a vanilla seq2seq-like model with a single unidirectional GRU in the encoder and decoder).\n\nHigher performance is observed for ast-attendgru and graph2seq, which is expected based on previous studies [30]. The higher performance is because both model designs use information from the AST of the subroutine. The graph2seq model uses a GNN, while ast-attendgru flattens the tree Chart depicts relative improvement of our augmented version according to aggregated BLEU score. Column \"mix\" indicates which models were ensembled: nc for default/no-context, fc for file context, and pc for project context. and uses it as input to an RNN. Note that while both models see an improvement with project context, it is lower in relative terms than for attendgru. We attribute this lower relative improvement to the increased amount of information that the model must learn in the same size vector space close to the output layer of the model. Recall from Section III-C2 paragraph 3 that two vectors of size e are generated: one for the original encoder and one for the project context encoder. Concatenating them results in a vector of length 2xe. To control model complexity, it is necessary to squash these vectors back to size e with a dense network. It is likely that information is lost. This effect probably also explains the drop in performance for code2seq. That baseline is extremely complex, and the vector size of e may be too confining.\n\nThe ensemble results are, in general, much higher. The chart at the lower-right of Figure 2 shows the default solo configuration to the \"fc+pc\" ensemble test condition. All models demonstrate considerable improvement, between 9 and 17.5% The reason for this improvement proffered by Garmash et al. [62] is that different models contribute more to some predictions than others. Mathematically, it means that the value of the argmax in the output vector of some models will be higher than others, because that model recognized a pattern closely-associated with that prediction. Haque et al. [30] pointed out that file context-based models contribute more to some subroutines than others. Project context helps overall, but there are still subroutines for which other models are more useful. The best performance is achieved by combining them.\n\nConsider Figure 3. The improvement of different models is not necessarily distributed equally over all subroutines. The chart on the left shows that of 73k subroutines in the test set, attendgru earned the highest score for about 27.5k, compared to about 30k for attendgru-pc. This means that the reason attendgru-pc improved is because it created better predictions for only a portion of the results. In that light, consider the chart on the right. That chart compares solo attendgru to the \"nc+pc\" ensemble. It shows that there is a substantial subset of subroutines for which attendgru earns a higher BLEU score, even compared to the \"nc+pc\" ensemble of attendgru and attendgru-pc. What changes is that there is a much higher number of ties. The ensemble sometimes creates predictions more like attendgru, and likewise more like attendgru-pc for other subroutines. What is happening is that the output vector from attendgru has higher values for the predictions where it finds patterns closely associated with those predictions -when it does not find those patterns, the values are lower and attendgru-pc is often higher. The result is a better overall BLEU score.   return 6160 32  2365 10  72 14  6  6  262 1 2093   set 11  10388 13  40  9  15  2  2  1  0 558   get 4491 22  3210 7  13 14  2  2  30 0 907   add 4  46  1  2950 14 1  10  3  1  0 293   create 62  21  25  43  980 16  16  0  2  0 538   initialize 23  14  3  2  22 1632 0  0  0  0 201   test 35  2  2  1  2  1  1232 0  61 0 170   remove 6  1  0  1  0  1  3  1186 0  0 303   check 244 9  3  2  3  0  66  3  526 3 \n\n\nB. RQ 2 : Action Word Prediction\n\nWe found broadly similar performance in terms of precision and recall for action word prediction. Recall that Haque et al. [54] recently recommended focusing on the prediction of the action word in source code summaries, given that word's importance in the summary. Following these recommendations, we report the top-40, top-10, top-10n (which is the top 2-12, skipping get/set), and get/set. The model should be able to distinguish get from set with very high accuracy, the top-10 and top-10n results being a more difficult problem, and the top-40 with even more difficulty. The idea is that if the model cannot even predict the correct action word, then it may have little hope of predicting the rest of the summary.\n\nWe do not observe a large difference attributable to file or project context. Our interpretation of this result is that the subroutine itself tends to provide most of the information needed to predict the action word -many times the correct action word is in the name of the function e.g. \"book\" for book() in the class Seat in project AircraftTravel. The higher BLEU and ROUGE scores for project context must therefore be due to improvements in the prediction of other parts of the code summary. For example, if the summary is \"book seat on airplane\", the subroutine name will provide the action word \"book\", but code context will help find \"seat\" and \"airplane.\" We explore an example like this in Section VI.\n\n\nC. RQ 3 : Comparison to File Context\n\nWe observe improvement over the baselines that are enhanced with file context. Figure 5 depicts the change in aggregate BLEU score across key model configurations. Figure 5a shows the default baseline model, followed by the file context and project context versions of those models. Figure 5b shows the default baseline model, followed by the nc+fc and nc+pc ensembles. Recall that the \"file context\" versions are those provided by Haque et al. [30] and form the nearest competition for models that include code context (see Section II-A).\n\nOverall, the project context versions of the baselines achieve higher aggregate BLEU scores than the file context versions. However, the gains are not uniform. For example, note in Figure 5a that graph2seq-fc is the lowest performing file context model, while graph2seq-pc is nearly tied for the top position of solo models. This finding seems to be at odds with scores reported by Haque et al. [30] for graph2seq-fc. We attribute the difference to the enhanced removal of code clones we performed for experiments in this paper (see Section IV-C). The file context contains many subroutines that are considered clones by the recommend clone removal technique [61], because these subroutines may be overloaded or only slightly modified. Future researchers using file context may consider leaving clones in the file context, and only remove them from the list of subroutines in the test set to ensure fairness.\n\nThe ensemble models also show that project context helps achieve higher BLEU scores than file context. Figure 5b shows marked improvement from nc+fc ensembles (no context combined with file context) to nc+pc ensembles, then again from nc+pc to fc+pc ensembles. The exception is code2seq, which we believe is due to the same vector size restriction described in Section V-A. The gain of fc+pc over other ensembles implies that file context and project context contributes to model predictions in orthogonal ways, in the same vein as the ensemble results for RQ 1 , above. \n\n\nD. RQ 4 : Effects on Model Size\n\nAdding project context to a baseline increases the complexity of the model, and this complexity comes at a cost in terms of time to train. While it may be tempting to write off training time as a \"one time sunk cost\", in fact this added time imposes engineering challenges that affect cost-benefit decisions [55]. We report training time per epoch as a proxy for this complexity cost. All data points were collected on the hardware platform described in Section IV-E. We observe about a 3x time cost for attendgru and ast-attendgru, and about a 2x cost for graph2seq and code2seq, when comapring default configurations to the versions with project context. While the number of minutes is subject to hardware and software settings, we report these numbers to assist practitioners in deciding how to deploy these technologies. For instance, time required for ast-attendgru-pc is roughly equal to code2seq-fc even though ast-attendgru-pc achieves a higher BLEU score. At that time limit ast-attendgru-pc may be the best choice even if code2seq is a better baseline than ast-attendgru.\n\nAn implication of this finding is that the costs of including project context can be very high. We find improvement in terms of overall BLEU score, especially for ensemble models, the training difficulty is 2x to 3x even for a modest setting of f =10. Future researchers may note the potential of even a portion of project context for improving prediction performance, and may consider guiding effort into reducing the costs so that more context may be considered.\n\n\nVI. DISCUSSION & CONCLUSION\n\nThis paper advances the state of the art in two ways: 1) We propose an encoder that creates a vectorized representation of project context for use in neural models of software source code. 2) We demonstrate the benefit of this encoder for the specific problem of source code summarization. The first advancement is important because of its potential impact on many areas of software engineering research. Allamanis et al. [63] present a survey of neural models for various software engineering tasks, and separate these tasks into two categories: code generational and code representational. A code generational task is like code completion or automatic repair, in which the model is expected to create new source code. A code representation task is like code summarization or bug localization, in which the model must create some internal representation of the program, and use it to predict something about the software, such as a code summary or if a subroutine contains a particular kind of bug.\n\nThe project context encoder we propose has potential in many code representational tasks. Essentially what the encoder does is create a vectorized representation of the files surrounding a particular area of code in a project. This representation could be used in many ways. For example, a neural model for predicting bugs based on the code in a subroutine could append our project context encoder. It may help the model learn that a particular pattern in the code may be associated with bugs for some types of projects, but not others. This benefit is only a hypothetical discussion -the point is that this paper may have benefits beyond the specific problem of code summarization.\n\nThe implementation and experiment in this paper focus on code summarization, and demonstrate how project context improves predictions in terms of BLEU and ROUGE scores for several baselines (RQ 1 ). We show that our model seems to be providing orthogonal information by improving predictions for a subset of subroutines, and that by using an ensemble procedure, the benefits of project context can be combined with file context and default models. We also show that these improvements seem to be focused on areas outside the action word (RQ 2 ), and that project context tends to result in overall better scores that file context alone (RQ 3 ), even if an ensemble has the highest observed performance (fc+pc ensemble models, RQ 1 ). Our project context encoder leads to an advancement of the state of the art for code summarization.\n\nThe reason that project context helps is that many methods are very difficult to understand from only the source code of a single subroutine. Code summarization techniques that consider only the subroutine itself make the tacit assumption that that subroutine contains all the information necessary to summarize it. Consider Example 1 (method #29987000 in the dataset [11], we list ID numbers for reproducibility). This method is from a GUI program for managing config files. Its purpose is to stop and cleanup a plugin. However, this purpose is hard to ascertain without seeing the project context.\n\nCompare the predicted summary for Example 1 by attendgru versus attendgru-pc. The model attendgru predicts \"stops the bundle\", which seems a reasonable guess considering that it has access only to the source code of that subroutine. The method is called stop(), which begs the question \"stops what?\" The word \"plugin\" is in the source code, but so is the word \"translator\", \"messages\", \"bundle\", etc. Many methods in the training set have a pattern in which the action word is followed by a word from the parameter list [54], and a simple seq2seq-like model such as attendgru can learn this pattern effectively [7], [9]. So attendgru guesses \"stops the bundle.\"\n\nThe project context helps the model learn what the method really means. The method in Example 1 appears in the file ConfexPlugin.java, which is in the project with five other files. While there is far too much data in these files to reprint here, one may note the similarity between these files and the files in Example 2 (method ID numbers may be used to recover these files in the dataset). Example 2 is from the training set. The content of the method itself is quite different from Example 1 (aside from the method signature), so attendgru has difficulty seeing the two methods as similar -there are many methods named stop() that have nothing to do with plugins. But attendgru-pc has access to the project context and can identify the similarity of the files in this context. As a result, attendgru-pc predicts the summary that it has learned during training, which is correct. We caution that we selected these examples as a demonstration of what project context can offer, and may not be representative of how the model always behaves. The model can make incorrect predictions -recall from Section V-A that there is a subset of methods for which project context outperforms the baseline, and a subset where it does not. However, when the project context models go astray, it tends to be because they are recognizing patterns in the context, and we found that ensemble models can generate better summaries.\n\nOur intent in this paper is to propose a technique for encoding the project context of source code. While project context is quite expansive, our technique can capture enough of this context to be useful for the task of source code summarization. Essentially what have shown is that even a small amount of this project context -just f =10 in this paper -can lead to significant improvements in the aggregate BLEU scores of several baselines. In ensemble models, the benefit increases further. However, as we observe in RQ 5 , the costs of including even limited project context mushroom rapidly. Future work aims to capture more of this context and interactions among the code components such as dependency relationships, and to demonstrate the benefit of context to other areas using neural models of source code.\n\n\nVII. REPRODUCIBILITY\n\nWe strongly encourage reproducibility. We provide the following online appendix to facilitate reuse of this technology by practitioners and other researchers. Our code, dataset scripts, and operating instructions may be found at:\n\nhttps://github.com/aakashba/projcon ACKNOWLEDGMENT This work is supported in part by the NSF CCF-1452959 and CCF-1717607 grants. Any opinions, findings, and conclusions expressed herein are the authors' and do not necessarily reflect those of the sponsors.\n\nFig. 3 .\n3(left) Number of subroutines in the test set for which attendgru and attendgru-pc each had a higher BLEU score, and the number of ties. (right) Comparison of solo attendgru to ensemble attendgru nc+pc.\n\nFig. 4 .\n4(top) Confusion matrix showing results for top-10 action words for ast-attendgru-pc, the best performer in terms of f-measure. (bottom) Overall results under standard conditions in the Java dataset.\n\nFig. 5 .\n5Comparison of aggregate BLEU scores for -fc and -pc models. This figure is a depiction of values inFigure 2.\n\nFig. 6 .\n6Training time in minutes per epoch.\n\n\nFig. 2. Results summary for RQ 1 and RQ 3 . The table shows the BLEU and ROUGE-LCS scores for baselines and our augmented versions of those baselines.BLEU \n\nROUGE-LCS \nA \n1 \n2 \n3 \n4 \nP \nR \nF \n\nSolo Models \n\nattendgru \n15.87 36.22 18.89 11.55 08.03 55.22 46.98 48.94 \nattendgru-fc \n16.67 36.53 19.59 12.31 08.76 56.54 47.44 49.78 \nattendgru-pc \n17.19 37.34 20.20 12.71 09.10 56.12 47.81 49.88 \nast-attendgru \n16.72 37.18 19.84 12.30 08.62 56.16 47.83 49.84 \nast-attendgru-fc \n17.18 37.64 20.21 12.69 09.03 55.86 48.11 49.94 \nast-attendgru-pc \n17.45 37.34 20.47 13.02 09.32 57.08 48.05 50.37 \ngraph2seq \n16.44 36.14 19.54 12.18 08.49 57.43 47.32 50.01 \ngraph2seq-fc \n16.26 35.95 19.19 11.95 08.48 56.56 46.95 49.50 \ngraph2seq-pc \n17.37 37.61 20.37 12.89 09.21 55.70 47.87 49.74 \ncode2seq \n16.78 37.88 20.14 12.30 08.45 55.45 48.32 49.80 \ncode2seq-fc \n16.45 36.34 19.43 12.09 08.58 56.66 47.29 49.79 \ncode2seq-pc \n16.7 \n35.92 19.53 12.44 08.91 57.75 47.08 50.01 \n\nBLEU \nROUGE-LCS \nmix \nA \n1 \n2 \n3 \n4 \nP \nR \nF \n\nEnsemble Models \n\nattendgru \nnc+fc \n17.96 37.83 20.92 13.49 09.74 58.26 48.79 51.29 \nattendgru \nnc+pc 18.18 38.26 21.14 13.64 09.91 57.80 48.98 51.18 \nattendgru \nfc+pc \n18.67 38.63 21.62 14.10 10.32 58.49 49.29 51.71 \nast-attendgru nc+fc \n18.47 38.68 21.53 13.88 10.07 58.15 49.33 51.57 \nast-attendgru nc+pc 18.84 38.80 21.88 14.26 10.41 58.71 49.50 51.91 \nast-attendgru fc+pc \n19.06 39.09 22.07 14.43 10.60 58.50 49.63 51.93 \ngraph2seq \nnc+fc \n17.77 37.32 20.79 13.37 09.62 59.16 48.58 51.50 \ngraph2seq \nnc+pc 18.59 38.85 21.56 14.06 10.28 58.54 49.07 51.58 \ngraph2seq \nfc+pc \n18.80 38.62 21.72 14.23 10.48 58.56 49.20 51.70 \ncode2seq \nnc+fc \n18.16 38.35 21.24 13.60 09.81 58.14 49.14 51.47 \ncode2seq \nnc+pc 18.56 38.50 21.55 13.99 10.21 58.49 49.23 51.63 \ncode2seq \nfc+pc \n18.29 37.67 21.12 13.82 10.18 59.15 48.72 51.64 \n\n\n\n\nMethod #29987000: (from test set) reference this method is called when the plug in is stopped attendgru stops the bundle attendgru-pc this method is called when the plug in is stopped public void stop(BundleContext context) throws Exception { super.stop(context); plugin = null; Translator.removeAllMessages(); Translator.removeAllTranslatables(); } files in net.confex.application: ApplicationWorkbenchAdvisor.java ApplicationWorkbenchWindowAdvisor.java ConfexApplication.java \u2192 ConfexPlugin.java Perspective.java ToolbarLayout.java Example 1. A method from the test set for which attendgru-pc wrote the correct summary, while attendgru did not. Method is in the project net.confex.application, which contains the six listed files. Method #805539: (from training set) reference this method is called when the plug in is stopped public void stop(BundleContext context) throws Exception { super.stop(context); if (this.logManager != null) { this.logManager.shutdown(); this.logManager = null; } if (searchProviderManager != null) { searchProviderManager.dispose(); searchProviderManager = null; } plugin = null; } files in net.bioclipse: ApplicationWorkbenchAdvisor.java ApplicationWorkbenchWindowAdvisor.java ApplicationWorkbenchActionBarAdvisor.java BioclipsePerspective.java \u2192 BioclipsePlugin.java PerspectiveOpenPreferencePage.java Example 2. Method in the training set seen by both approaches. Note list of files is similar to Example 1 because both are built with the same GUI platform. Project context helps attendgru-pc detect this similarity.\n\nOn the use of automated text summarization techniques for summarizing source code. S Haiduc, J Aponte, L Moreno, A Marcus, 2010 17th Working Conference on Reverse Engineering. IEEES. Haiduc, J. Aponte, L. Moreno, and A. Marcus, \"On the use of automated text summarization techniques for summarizing source code,\" in 2010 17th Working Conference on Reverse Engineering. IEEE, 2010, pp. 35-44.\n\nTowards automatically generating summary comments for java methods. G Sridhara, E Hill, D Muppaneni, L Pollock, K Vijay-Shanker, Proceedings of the IEEE/ACM international conference on Automated software engineering. the IEEE/ACM international conference on Automated software engineeringACMG. Sridhara, E. Hill, D. Muppaneni, L. Pollock, and K. Vijay-Shanker, \"Towards automatically generating summary comments for java meth- ods,\" in Proceedings of the IEEE/ACM international conference on Automated software engineering. ACM, 2010, pp. 43-52.\n\nThe relevance of software documentation, tools and technologies: a survey. A Forward, T C Lethbridge, Proceedings of the 2002 ACM symposium on Document engineering. the 2002 ACM symposium on Document engineeringACMA. Forward and T. C. Lethbridge, \"The relevance of software documen- tation, tools and technologies: a survey,\" in Proceedings of the 2002 ACM symposium on Document engineering. ACM, 2002, pp. 26-33.\n\nApi documentation from source code comments: a case study of javadoc. D Kramer, Proceedings of the 17th annual international conference on Computer documentation. the 17th annual international conference on Computer documentationACMD. Kramer, \"Api documentation from source code comments: a case study of javadoc,\" in Proceedings of the 17th annual international conference on Computer documentation. ACM, 1999, pp. 147-153.\n\nMeasuring program comprehension: A large-scale field study with professionals. X Xia, L Bao, D Lo, Z Xing, A E Hassan, S Li, IEEE Transactions on Software Engineering. 4410X. Xia, L. Bao, D. Lo, Z. Xing, A. E. Hassan, and S. Li, \"Measuring program comprehension: A large-scale field study with professionals,\" IEEE Transactions on Software Engineering, vol. 44, no. 10, pp. 951- 976, 2017.\n\nA survey of automatic generation of code comments. F Zhao, J Zhao, Y Bai, Proceedings of the 2020 4th International Conference on Management Engineering. the 2020 4th International Conference on Management EngineeringF. Zhao, J. Zhao, and Y. Bai, \"A survey of automatic generation of code comments,\" in Proceedings of the 2020 4th International Conference on Management Engineering, Software Engineering and Service Sciences, 2020, pp. 21-25.\n\nA neural model for generating natural language summaries of program subroutines. A Leclair, S Jiang, C Mcmillan, Proceedings of the 41st International Conference on Software Engineering. the 41st International Conference on Software EngineeringIEEE PressA. LeClair, S. Jiang, and C. McMillan, \"A neural model for generating natural language summaries of program subroutines,\" in Proceedings of the 41st International Conference on Software Engineering. IEEE Press, 2019, pp. 795-806.\n\nLanguage-agnostic representation learning of source code from structure and context. D Z\u00fcgner, T Kirschstein, M Catasta, J Leskovec, S G\u00fcnnemann, International Conference on Learning Representations. D. Z\u00fcgner, T. Kirschstein, M. Catasta, J. Leskovec, and S. G\u00fcnnemann, \"Language-agnostic representation learning of source code from structure and context,\" in International Conference on Learning Representations, 2021. [Online]. Available: https://openreview.net/ forum?id=Xh5eMZVONGF\n\nDeep code comment generation. X Hu, G Li, X Xia, D Lo, Z Jin, Proceedings of the 26th Conference on Program Comprehension. the 26th Conference on Program ComprehensionACMX. Hu, G. Li, X. Xia, D. Lo, and Z. Jin, \"Deep code comment generation,\" in Proceedings of the 26th Conference on Program Com- prehension. ACM, 2018, pp. 200-210.\n\nNeural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, arXiv:1409.0473arXiv preprintD. Bahdanau, K. Cho, and Y. Bengio, \"Neural machine translation by jointly learning to align and translate,\" arXiv preprint arXiv:1409.0473, 2014.\n\nRecommendations for datasets for source code summarization. A Leclair, C Mcmillan, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1A. LeClair and C. McMillan, \"Recommendations for datasets for source code summarization,\" in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguis- tics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019, pp. 3931-3937.\n\nUnderstanding understanding source code with functional magnetic resonance imaging. J Siegmund, C K\u00e4stner, S Apel, C Parnin, A Bethmann, T Leich, G Saake, A Brechmann, Proceedings of the 36th International Conference on Software Engineering, ser. ICSE. the 36th International Conference on Software Engineering, ser. ICSENew York, NY, USAACMJ. Siegmund, C. K\u00e4stner, S. Apel, C. Parnin, A. Bethmann, T. Leich, G. Saake, and A. Brechmann, \"Understanding understanding source code with functional magnetic resonance imaging,\" in Proceedings of the 36th International Conference on Software Engineering, ser. ICSE 2014. New York, NY, USA: ACM, 2014, pp. 378-389. [Online].\n\n. http:/doi.acm.org/10.1145/2568225.2568252Available: http://doi.acm.org/10.1145/2568225.2568252\n\nCognitive processes in program comprehension. S Letovsky, Journal of Systems and software. 74S. Letovsky, \"Cognitive processes in program comprehension,\" Journal of Systems and software, vol. 7, no. 4, pp. 325-339, 1987.\n\nProgram comprehension during software maintenance and evolution. A , Von Mayrhauser, A M Vans, Computer. 288A. Von Mayrhauser and A. M. Vans, \"Program comprehension during software maintenance and evolution,\" Computer, vol. 28, no. 8, pp. 44- 55, 1995.\n\nThe concept assignment problem in program understanding. T J Biggerstaff, B G Mitbander, D Webster, Proceedings of the 15th international conference on Software Engineering. the 15th international conference on Software EngineeringIEEE Computer Society PressT. J. Biggerstaff, B. G. Mitbander, and D. Webster, \"The concept assign- ment problem in program understanding,\" in Proceedings of the 15th international conference on Software Engineering. IEEE Computer Society Press, 1993, pp. 482-498.\n\nA neural architecture for generating natural language descriptions from source code changes. P Loyola, E Marrese-Taylor, Y Matsuo, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsShort Papers2P. Loyola, E. Marrese-Taylor, and Y. Matsuo, \"A neural architecture for generating natural language descriptions from source code changes,\" in Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), 2017, pp. 287- 292.\n\nLearning to generate comments for api-based code snippets. Y Lu, Z Zhao, G Li, Z Jin, Software Engineering and Methodology for Emerging Domains. SpringerY. Lu, Z. Zhao, G. Li, and Z. Jin, \"Learning to generate comments for api-based code snippets,\" in Software Engineering and Methodology for Emerging Domains. Springer, 2017, pp. 3-14.\n\nAutomatically generating commit messages from diffs using neural machine translation. S Jiang, A Armaly, C Mcmillan, Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. the 32nd IEEE/ACM International Conference on Automated Software EngineeringIEEE PressS. Jiang, A. Armaly, and C. McMillan, \"Automatically generating commit messages from diffs using neural machine translation,\" in Pro- ceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. IEEE Press, 2017, pp. 135-146.\n\nSummarizing source code with transferred api knowledge. X Hu, G Li, X Xia, D Lo, S Lu, Z Jin, Proceedings of the 27th International Joint Conference on Artificial Intelligence. the 27th International Joint Conference on Artificial IntelligenceAAAI PressX. Hu, G. Li, X. Xia, D. Lo, S. Lu, and Z. Jin, \"Summarizing source code with transferred api knowledge,\" in Proceedings of the 27th International Joint Conference on Artificial Intelligence. AAAI Press, 2018, pp. 2269-2275.\n\nLearning to represent programs with graphs. M Allamanis, M Brockschmidt, M Khademi, International Conference on Learning Representations. M. Allamanis, M. Brockschmidt, and M. Khademi, \"Learning to rep- resent programs with graphs,\" International Conference on Learning Representations, 2018.\n\nImproving automatic source code summarization via deep reinforcement learning. Y Wan, Z Zhao, M Yang, G Xu, H Ying, J Wu, P S Yu, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. the 33rd ACM/IEEE International Conference on Automated Software EngineeringACMY. Wan, Z. Zhao, M. Yang, G. Xu, H. Ying, J. Wu, and P. S. Yu, \"Improving automatic source code summarization via deep reinforce- ment learning,\" in Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. ACM, 2018, pp. 397- 407.\n\nAutomatic generation of text descriptive comments for code blocks. Y Liang, K Q Zhu, Thirty-Second AAAI Conference on Artificial Intelligence. Y. Liang and K. Q. Zhu, \"Automatic generation of text descriptive comments for code blocks,\" in Thirty-Second AAAI Conference on Artificial Intelligence, 2018.\n\ncode2seq: Generating sequences from structured representations of code. U Alon, S Brody, O Levy, E Yahav, International Conference on Learning Representations. U. Alon, S. Brody, O. Levy, and E. Yahav, \"code2seq: Generating sequences from structured representations of code,\" International Con- ference on Learning Representations, 2019.\n\ncode2vec: Learning distributed representations of code. U Alon, M Zilberstein, O Levy, E Yahav, POPL. 3U. Alon, M. Zilberstein, O. Levy, and E. Yahav, \"code2vec: Learning distributed representations of code,\" Proceedings of the ACM on Pro- gramming Languages, vol. 3, no. POPL, pp. 1-29, 2019.\n\nA neural model for method name generation from functional description. S Gao, C Chen, Z Xing, Y Ma, W Song, S.-W Lin, 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEES. Gao, C. Chen, Z. Xing, Y. Ma, W. Song, and S.-W. Lin, \"A neural model for method name generation from functional description,\" in 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, 2019, pp. 414-421.\n\nDeepdelta: learning to repair compilation errors. A Mesbah, A Rice, E Johnston, N Glorioso, E Aftandilian, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringACMA. Mesbah, A. Rice, E. Johnston, N. Glorioso, and E. Aftandilian, \"Deepdelta: learning to repair compilation errors,\" in Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, 2019, pp. 925-936.\n\nA framework for writing trigger-action todo comments in executable format. P Nie, R Rai, J J Li, S Khurshid, R J Mooney, M Gligoric, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringACMP. Nie, R. Rai, J. J. Li, S. Khurshid, R. J. Mooney, and M. Gligoric, \"A framework for writing trigger-action todo comments in executable format,\" in Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. ACM, 2019, pp. 385-396.\n\nA multi-perspective architecture for semantic code search. R Haldar, L Wu, J Xiong, J Hockenmaier, arXiv:2005.06980arXiv preprintR. Haldar, L. Wu, J. Xiong, and J. Hockenmaier, \"A multi-perspective architecture for semantic code search,\" arXiv preprint arXiv:2005.06980, 2020.\n\nA transformer-based approach for source code summarization. W U Ahmad, S Chakraborty, B Ray, K.-W Chang, arXiv:2005.00653arXiv preprintW. U. Ahmad, S. Chakraborty, B. Ray, and K.-W. Chang, \"A transformer-based approach for source code summarization,\" arXiv preprint arXiv:2005.00653, 2020.\n\nImproved automatic summarization of subroutines via attention to file context. S Haque, A Leclair, L Wu, C Mcmillan, International Conference on Mining Software Repositories. S. Haque, A. LeClair, L. Wu, and C. McMillan, \"Improved automatic summarization of subroutines via attention to file context,\" International Conference on Mining Software Repositories, 2020.\n\nRetrieval-augmented generation for code summarization via hybrid {gnn}. S Liu, Y Chen, X Xie, J K Siow, Y Liu, International Conference on Learning Representations. S. Liu, Y. Chen, X. Xie, J. K. Siow, and Y. Liu, \"Retrieval-augmented generation for code summarization via hybrid {gnn},\" in International Conference on Learning Representations, 2021. [Online]. Available: https://openreview.net/forum?id=zv-typ1gPxA\n\nAutomatic documentation generation via source code summarization of method context. P W Mcburney, C Mcmillan, Proceedings of the 22nd International Conference on Program Comprehension. the 22nd International Conference on Program ComprehensionACMP. W. McBurney and C. McMillan, \"Automatic documentation genera- tion via source code summarization of method context,\" in Proceedings of the 22nd International Conference on Program Comprehension. ACM, 2014, pp. 279-290.\n\nSummarizing source code using a neural attention model. S Iyer, I Konstas, A Cheung, L Zettlemoyer, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsLong Papers1S. Iyer, I. Konstas, A. Cheung, and L. Zettlemoyer, \"Summarizing source code using a neural attention model,\" in Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2016, pp. 2073-2083.\n\ncode2seq: Generating sequences from structured representations of code. U Alon, S Brody, O Levy, E Yahav, International Conference on Learning Representations. U. Alon, S. Brody, O. Levy, and E. Yahav, \"code2seq: Generating sequences from structured representations of code,\" International Con- ference on Learning Representations, 2019.\n\nImproved code summarization via a graph neural network. A Leclair, S Haque, L Wu, C Mcmillan, 28th ACM/IEEE International Conference on Program Comprehension (ICPC'20). 2020A. LeClair, S. Haque, L. Wu, and C. McMillan, \"Improved code summa- rization via a graph neural network,\" in 28th ACM/IEEE International Conference on Program Comprehension (ICPC'20), 2020.\n\nEffects of context on program slicing. J Krinke, Journal of Systems and Software. 799J. Krinke, \"Effects of context on program slicing,\" Journal of Systems and Software, vol. 79, no. 9, pp. 1249-1260, 2006.\n\nOn the comprehension of program comprehension. W Maalej, R Tiarks, T Roehm, R Koschke, ACM Transactions on Software Engineering and Methodology (TOSEM). 234W. Maalej, R. Tiarks, T. Roehm, and R. Koschke, \"On the compre- hension of program comprehension,\" ACM Transactions on Software Engineering and Methodology (TOSEM), vol. 23, no. 4, pp. 1-37, 2014.\n\nThe role of concepts in program comprehension. V Rajlich, N Wilde, Proceedings 10th International Workshop on Program Comprehension. 10th International Workshop on Program ComprehensionIEEEV. Rajlich and N. Wilde, \"The role of concepts in program com- prehension,\" in Proceedings 10th International Workshop on Program Comprehension. IEEE, 2002, pp. 271-278.\n\nHow do professional developers comprehend software. T Roehm, R Tiarks, R Koschke, W Maalej, Proceedings of the 34th International Conference on Software Engineering. the 34th International Conference on Software EngineeringIEEE PressT. Roehm, R. Tiarks, R. Koschke, and W. Maalej, \"How do professional developers comprehend software?\" in Proceedings of the 34th Interna- tional Conference on Software Engineering. IEEE Press, 2012, pp. 255-265.\n\nSupporting program comprehension using semantic and structural information. J I Maletic, A Marcus, Proceedings of the 23rd International Conference on Software Engineering. ICSE. the 23rd International Conference on Software Engineering. ICSEIEEEJ. I. Maletic and A. Marcus, \"Supporting program comprehension using semantic and structural information,\" in Proceedings of the 23rd International Conference on Software Engineering. ICSE 2001. IEEE, 2001, pp. 103-112.\n\nSurvey of methods to generate natural language from source code. G Neubig, G. Neubig, \"Survey of methods to generate natural language from source code.\"\n\nSequence to sequence learning with neural networks. I Sutskever, O Vinyals, Q V Le, Advances in neural information processing systems. 27I. Sutskever, O. Vinyals, and Q. V. Le, \"Sequence to sequence learning with neural networks,\" Advances in neural information processing systems, vol. 27, pp. 3104-3112, 2014.\n\nRecent trends in deep learning based natural language processing. T Young, D Hazarika, S Poria, E Cambria, ieee Computational intelligenCe magazine. 133T. Young, D. Hazarika, S. Poria, and E. Cambria, \"Recent trends in deep learning based natural language processing,\" ieee Computational intelligenCe magazine, vol. 13, no. 3, pp. 55-75, 2018.\n\nA survey on deep learning: Algorithms, techniques, and applications. S Pouyanfar, S Sadiq, Y Yan, H Tian, Y Tao, M P Reyes, M.-L Shyu, S.-C Chen, S Iyengar, ACM Computing Surveys (CSUR). 51592S. Pouyanfar, S. Sadiq, Y. Yan, H. Tian, Y. Tao, M. P. Reyes, M.-L. Shyu, S.-C. Chen, and S. Iyengar, \"A survey on deep learning: Algorithms, techniques, and applications,\" ACM Computing Surveys (CSUR), vol. 51, no. 5, p. 92, 2018.\n\nReview of deep learning algorithms and architectures. A Shrestha, A Mahmood, IEEE Access. 7A. Shrestha and A. Mahmood, \"Review of deep learning algorithms and architectures,\" IEEE Access, vol. 7, pp. 53 040-53 065, 2019.\n\nLearning cascade attention for finegrained image classification. Y Zhu, R Li, Y Yang, N Ye, Neural Networks. 122Y. Zhu, R. Li, Y. Yang, and N. Ye, \"Learning cascade attention for fine- grained image classification,\" Neural Networks, vol. 122, pp. 174-182, 2020.\n\nCascade dynamics modeling with attention-based recurrent neural network. Y Wang, H Shen, S Liu, J Gao, X Cheng, IJCAI. Y. Wang, H. Shen, S. Liu, J. Gao, and X. Cheng, \"Cascade dynamics modeling with attention-based recurrent neural network.\" in IJCAI, 2017, pp. 2985-2991.\n\nContext-aware cascade attention-based rnn for video emotion recognition. M.-C Sun, S.-H Hsu, M.-C Yang, J.-H Chien, 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia. IEEEM.-C. Sun, S.-H. Hsu, M.-C. Yang, and J.-H. Chien, \"Context-aware cascade attention-based rnn for video emotion recognition,\" in 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia). IEEE, 2018, pp. 1-6.\n\nEnsemble model with cascade attention mechanism for high-resolution remote sensing image scene classification. F Li, R Feng, W Han, L Wang, Optics Express. 2815F. Li, R. Feng, W. Han, and L. Wang, \"Ensemble model with cascade attention mechanism for high-resolution remote sensing image scene classification,\" Optics Express, vol. 28, no. 15, pp. 22 358-22 387, 2020.\n\nCascade attention networks for group emotion recognition with face, body and image cues. K Wang, X Zeng, J Yang, D Meng, K Zhang, X Peng, Y Qiao, Proceedings of the 20th ACM International Conference on Multimodal Interaction. the 20th ACM International Conference on Multimodal InteractionK. Wang, X. Zeng, J. Yang, D. Meng, K. Zhang, X. Peng, and Y. Qiao, \"Cascade attention networks for group emotion recognition with face, body and image cues,\" in Proceedings of the 20th ACM International Conference on Multimodal Interaction, 2018, pp. 640-645.\n\nImproving automated source code summarization via an eye-tracking study of programmers. P Rodeghero, C Mcmillan, P W Mcburney, N Bosch, S D&apos;mello, Proceedings of the 36th international conference on Software engineering. the 36th international conference on Software engineeringACMP. Rodeghero, C. McMillan, P. W. McBurney, N. Bosch, and S. D'Mello, \"Improving automated source code summarization via an eye-tracking study of programmers,\" in Proceedings of the 36th international con- ference on Software engineering. ACM, 2014, pp. 390-401.\n\nEffective approaches to attention-based neural machine translation. M.-T Luong, H Pham, C D Manning, arXiv:1508.04025arXiv preprintM.-T. Luong, H. Pham, and C. D. Manning, \"Effective ap- proaches to attention-based neural machine translation,\" arXiv preprint arXiv:1508.04025, 2015.\n\nA human study of comprehension and code summarization. S Stapleton, Y Gambhir, A Leclair, Z Eberhart, W Weimer, K Leach, Y Huang, Proceedings of the 28th International Conference on Program Comprehension. the 28th International Conference on Program ComprehensionS. Stapleton, Y. Gambhir, A. LeClair, Z. Eberhart, W. Weimer, K. Leach, and Y. Huang, \"A human study of comprehension and code summariza- tion,\" in Proceedings of the 28th International Conference on Program Comprehension, 2020, pp. 2-13.\n\nAction word prediction for neural source code summarization. S Haque, A Bansal, L Wu, C Mcmillan, 28th IEEE International Conference on Software Analysis, Evolution and Reengineering. S. Haque, A. Bansal, L. Wu, and C. McMillan, \"Action word predic- tion for neural source code summarization,\" 28th IEEE International Conference on Software Analysis, Evolution and Reengineering, 2021.\n\nApplied machine learning at facebook: A datacenter infrastructure perspective. K Hazelwood, S Bird, D Brooks, S Chintala, U Diril, D Dzhulgakov, M Fawzy, B Jia, Y Jia, A Kalro, 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEEK. Hazelwood, S. Bird, D. Brooks, S. Chintala, U. Diril, D. Dzhulgakov, M. Fawzy, B. Jia, Y. Jia, A. Kalro et al., \"Applied machine learning at facebook: A datacenter infrastructure perspective,\" in 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEE, 2018, pp. 620-629.\n\nBleu: A method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W.-J Zhu, 10.3115/1073083.1073135Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL '02. the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL '02Stroudsburg, PA, USAAssociation for Computational LinguisticsK. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, \"Bleu: A method for automatic evaluation of machine translation,\" in Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL '02. Stroudsburg, PA, USA: Association for Computational Linguistics, 2002, pp. 311-318. [Online]. Available: http://dx.doi.org/10.3115/1073083.1073135\n\nRouge: A package for automatic evaluation of summaries. C.-Y. Lin, Text Summarization Branches Out. C.-Y. Lin, \"Rouge: A package for automatic evaluation of summaries,\" Text Summarization Branches Out, 2004.\n\nHow to evaluate machine translation: A review of automated and human metrics. E Chatzikoumi, Natural Language Engineering. 262E. Chatzikoumi, \"How to evaluate machine translation: A review of automated and human metrics,\" Natural Language Engineering, vol. 26, no. 2, pp. 137-161, 2020.\n\nThe stanford corenlp natural language processing toolkit. C D Manning, M Surdeanu, J Bauer, J R Finkel, S Bethard, D Mcclosky, ACL (System Demonstrations). C. D. Manning, M. Surdeanu, J. Bauer, J. R. Finkel, S. Bethard, and D. McClosky, \"The stanford corenlp natural language processing toolkit.\" in ACL (System Demonstrations), 2014, pp. 55-60.\n\nClassification assessment methods. A Tharwat, Applied Computing and Informatics. A. Tharwat, \"Classification assessment methods,\" Applied Computing and Informatics, 2020.\n\nThe adverse effects of code duplication in machine learning models of code. M Allamanis, Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software. the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and SoftwareM. Allamanis, \"The adverse effects of code duplication in machine learning models of code,\" in Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, 2019, pp. 143-153.\n\nEnsemble learning for multi-source neural machine translation. E Garmash, C Monz, Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. COLING 2016, the 26th International Conference on Computational Linguistics: Technical PapersE. Garmash and C. Monz, \"Ensemble learning for multi-source neural machine translation,\" in Proceedings of COLING 2016, the 26th Inter- national Conference on Computational Linguistics: Technical Papers, 2016, pp. 1409-1418.\n\nA survey of machine learning for big code and naturalness. M Allamanis, E T Barr, P Devanbu, C Sutton, ACM Computing Surveys (CSUR). 514M. Allamanis, E. T. Barr, P. Devanbu, and C. Sutton, \"A survey of machine learning for big code and naturalness,\" ACM Computing Surveys (CSUR), vol. 51, no. 4, pp. 1-37, 2018.\n", "annotations": {"author": "[{\"end\":193,\"start\":78},{\"end\":305,\"start\":194},{\"end\":407,\"start\":306}]", "publisher": null, "author_last_name": "[{\"end\":91,\"start\":85},{\"end\":205,\"start\":200},{\"end\":321,\"start\":313}]", "author_first_name": "[{\"end\":84,\"start\":78},{\"end\":199,\"start\":194},{\"end\":312,\"start\":306}]", "author_affiliation": "[{\"end\":192,\"start\":109},{\"end\":304,\"start\":221},{\"end\":406,\"start\":323}]", "title": "[{\"end\":75,\"start\":1},{\"end\":482,\"start\":408}]", "venue": null, "abstract": "[{\"end\":1916,\"start\":572}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2037,\"start\":2034},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2042,\"start\":2039},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2378,\"start\":2375},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2488,\"start\":2485},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2654,\"start\":2651},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2794,\"start\":2791},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2942,\"start\":2939},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2947,\"start\":2944},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3083,\"start\":3079},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3364,\"start\":3360},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4235,\"start\":4231},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4241,\"start\":4237},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4627,\"start\":4623},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7142,\"start\":7139},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7147,\"start\":7144},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":7153,\"start\":7149},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7159,\"start\":7155},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7311,\"start\":7307},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7332,\"start\":7316},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7337,\"start\":7333},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7365,\"start\":7361},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7390,\"start\":7386},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7414,\"start\":7411},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7427,\"start\":7423},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7455,\"start\":7451},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7485,\"start\":7481},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7514,\"start\":7510},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7520,\"start\":7516},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7548,\"start\":7544},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7577,\"start\":7574},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7608,\"start\":7604},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7636,\"start\":7632},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7667,\"start\":7663},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7697,\"start\":7693},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7725,\"start\":7721},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7755,\"start\":7752},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7783,\"start\":7779},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8260,\"start\":8257},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8402,\"start\":8398},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8422,\"start\":8419},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8557,\"start\":8553},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8563,\"start\":8559},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":8625,\"start\":8621},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8744,\"start\":8740},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8911,\"start\":8908},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8917,\"start\":8913},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9154,\"start\":9150},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9348,\"start\":9344},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9354,\"start\":9350},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9392,\"start\":9388},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9398,\"start\":9394},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9531,\"start\":9528},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9537,\"start\":9533},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":9543,\"start\":9539},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9634,\"start\":9630},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10091,\"start\":10087},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11287,\"start\":11283},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":11428,\"start\":11424},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":11434,\"start\":11430},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11968,\"start\":11964},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":12602,\"start\":12598},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":12608,\"start\":12604},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":12647,\"start\":12643},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15276,\"start\":15272},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":15883,\"start\":15879},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":17425,\"start\":17421},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18156,\"start\":18152},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19691,\"start\":19688},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":19697,\"start\":19693},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":23153,\"start\":23149},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":23280,\"start\":23276},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":24344,\"start\":24340},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":24963,\"start\":24959},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":24969,\"start\":24965},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":25382,\"start\":25378},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":25401,\"start\":25397},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":25822,\"start\":25818},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":26414,\"start\":26410},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":26537,\"start\":26533},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":26827,\"start\":26823},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":27691,\"start\":27687},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27983,\"start\":27979},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":28905,\"start\":28901},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":29634,\"start\":29630},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":29984,\"start\":29981},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30040,\"start\":30037},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":30287,\"start\":30284},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":30293,\"start\":30289},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":30299,\"start\":30295},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30458,\"start\":30454},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":30774,\"start\":30770},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":32792,\"start\":32788},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":32917,\"start\":32914},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":33644,\"start\":33640},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":35181,\"start\":35177},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":35472,\"start\":35468},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":37464,\"start\":37460},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":39258,\"start\":39254},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":39749,\"start\":39745},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":40013,\"start\":40009},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":41179,\"start\":41175},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":42872,\"start\":42868},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":45338,\"start\":45334},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":46091,\"start\":46087},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":46181,\"start\":46178},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":46186,\"start\":46183}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":49183,\"start\":48971},{\"attributes\":{\"id\":\"fig_3\"},\"end\":49393,\"start\":49184},{\"attributes\":{\"id\":\"fig_4\"},\"end\":49513,\"start\":49394},{\"attributes\":{\"id\":\"fig_5\"},\"end\":49560,\"start\":49514},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":51396,\"start\":49561},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":52949,\"start\":51397}]", "paragraph": "[{\"end\":2795,\"start\":1935},{\"end\":3048,\"start\":2797},{\"end\":3873,\"start\":3050},{\"end\":4628,\"start\":3875},{\"end\":5406,\"start\":4630},{\"end\":6142,\"start\":5408},{\"end\":6226,\"start\":6144},{\"end\":6372,\"start\":6260},{\"end\":7160,\"start\":6374},{\"end\":8155,\"start\":7162},{\"end\":9803,\"start\":8157},{\"end\":10307,\"start\":9805},{\"end\":11435,\"start\":10350},{\"end\":12032,\"start\":11437},{\"end\":13145,\"start\":12034},{\"end\":13516,\"start\":13167},{\"end\":14547,\"start\":13539},{\"end\":14750,\"start\":14569},{\"end\":15277,\"start\":14752},{\"end\":15884,\"start\":15279},{\"end\":16559,\"start\":15886},{\"end\":16680,\"start\":16561},{\"end\":17666,\"start\":16682},{\"end\":17859,\"start\":17699},{\"end\":18759,\"start\":17861},{\"end\":19228,\"start\":18761},{\"end\":20129,\"start\":19230},{\"end\":20558,\"start\":20131},{\"end\":21115,\"start\":20560},{\"end\":21500,\"start\":21117},{\"end\":21849,\"start\":21502},{\"end\":21980,\"start\":21868},{\"end\":23214,\"start\":22006},{\"end\":23744,\"start\":23216},{\"end\":24092,\"start\":23746},{\"end\":24418,\"start\":24094},{\"end\":25636,\"start\":24437},{\"end\":26345,\"start\":25638},{\"end\":27253,\"start\":26347},{\"end\":27466,\"start\":27255},{\"end\":27692,\"start\":27468},{\"end\":27876,\"start\":27694},{\"end\":28496,\"start\":27892},{\"end\":29410,\"start\":28498},{\"end\":29934,\"start\":29427},{\"end\":30300,\"start\":29936},{\"end\":30537,\"start\":30302},{\"end\":30707,\"start\":30539},{\"end\":30869,\"start\":30709},{\"end\":31115,\"start\":30904},{\"end\":31731,\"start\":31142},{\"end\":31877,\"start\":31757},{\"end\":32918,\"start\":31922},{\"end\":33530,\"start\":32920},{\"end\":34877,\"start\":33532},{\"end\":35719,\"start\":34879},{\"end\":37300,\"start\":35721},{\"end\":38055,\"start\":37337},{\"end\":38768,\"start\":38057},{\"end\":39348,\"start\":38809},{\"end\":40258,\"start\":39350},{\"end\":40831,\"start\":40260},{\"end\":41948,\"start\":40867},{\"end\":42414,\"start\":41950},{\"end\":43445,\"start\":42446},{\"end\":44129,\"start\":43447},{\"end\":44964,\"start\":44131},{\"end\":45565,\"start\":44966},{\"end\":46228,\"start\":45567},{\"end\":47642,\"start\":46230},{\"end\":48458,\"start\":47644},{\"end\":48712,\"start\":48483},{\"end\":48970,\"start\":48714}]", "formula": null, "table_ref": "[{\"end\":37299,\"start\":36891}]", "section_header": "[{\"end\":1933,\"start\":1918},{\"end\":6258,\"start\":6229},{\"end\":10348,\"start\":10310},{\"end\":13165,\"start\":13148},{\"end\":13537,\"start\":13519},{\"end\":14567,\"start\":14550},{\"end\":17697,\"start\":17669},{\"end\":21866,\"start\":21852},{\"end\":22004,\"start\":21983},{\"end\":24435,\"start\":24421},{\"end\":27890,\"start\":27879},{\"end\":29425,\"start\":29413},{\"end\":30902,\"start\":30872},{\"end\":31140,\"start\":31118},{\"end\":31755,\"start\":31734},{\"end\":31920,\"start\":31880},{\"end\":37335,\"start\":37303},{\"end\":38807,\"start\":38771},{\"end\":40865,\"start\":40834},{\"end\":42444,\"start\":42417},{\"end\":48481,\"start\":48461},{\"end\":48980,\"start\":48972},{\"end\":49193,\"start\":49185},{\"end\":49403,\"start\":49395},{\"end\":49523,\"start\":49515}]", "table": "[{\"end\":51396,\"start\":49713}]", "figure_caption": "[{\"end\":49183,\"start\":48982},{\"end\":49393,\"start\":49195},{\"end\":49513,\"start\":49405},{\"end\":49560,\"start\":49525},{\"end\":49713,\"start\":49563},{\"end\":52949,\"start\":51399}]", "figure_ref": "[{\"end\":6411,\"start\":6403},{\"end\":7812,\"start\":7806},{\"end\":32122,\"start\":32114},{\"end\":32645,\"start\":32637},{\"end\":34970,\"start\":34962},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":35738,\"start\":35730},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":38896,\"start\":38888},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":38982,\"start\":38973},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":39101,\"start\":39092},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":39540,\"start\":39531},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":40372,\"start\":40363}]", "bib_author_first_name": "[{\"end\":53035,\"start\":53034},{\"end\":53045,\"start\":53044},{\"end\":53055,\"start\":53054},{\"end\":53065,\"start\":53064},{\"end\":53413,\"start\":53412},{\"end\":53425,\"start\":53424},{\"end\":53433,\"start\":53432},{\"end\":53446,\"start\":53445},{\"end\":53457,\"start\":53456},{\"end\":53967,\"start\":53966},{\"end\":53978,\"start\":53977},{\"end\":53980,\"start\":53979},{\"end\":54377,\"start\":54376},{\"end\":54812,\"start\":54811},{\"end\":54819,\"start\":54818},{\"end\":54826,\"start\":54825},{\"end\":54832,\"start\":54831},{\"end\":54840,\"start\":54839},{\"end\":54842,\"start\":54841},{\"end\":54852,\"start\":54851},{\"end\":55175,\"start\":55174},{\"end\":55183,\"start\":55182},{\"end\":55191,\"start\":55190},{\"end\":55649,\"start\":55648},{\"end\":55660,\"start\":55659},{\"end\":55669,\"start\":55668},{\"end\":56138,\"start\":56137},{\"end\":56148,\"start\":56147},{\"end\":56163,\"start\":56162},{\"end\":56174,\"start\":56173},{\"end\":56186,\"start\":56185},{\"end\":56570,\"start\":56569},{\"end\":56576,\"start\":56575},{\"end\":56582,\"start\":56581},{\"end\":56589,\"start\":56588},{\"end\":56595,\"start\":56594},{\"end\":56945,\"start\":56944},{\"end\":56957,\"start\":56956},{\"end\":56964,\"start\":56963},{\"end\":57211,\"start\":57210},{\"end\":57222,\"start\":57221},{\"end\":57885,\"start\":57884},{\"end\":57897,\"start\":57896},{\"end\":57908,\"start\":57907},{\"end\":57916,\"start\":57915},{\"end\":57926,\"start\":57925},{\"end\":57938,\"start\":57937},{\"end\":57947,\"start\":57946},{\"end\":57956,\"start\":57955},{\"end\":58615,\"start\":58614},{\"end\":58856,\"start\":58855},{\"end\":58862,\"start\":58859},{\"end\":58876,\"start\":58875},{\"end\":58878,\"start\":58877},{\"end\":59102,\"start\":59101},{\"end\":59104,\"start\":59103},{\"end\":59119,\"start\":59118},{\"end\":59121,\"start\":59120},{\"end\":59134,\"start\":59133},{\"end\":59635,\"start\":59634},{\"end\":59645,\"start\":59644},{\"end\":59663,\"start\":59662},{\"end\":60184,\"start\":60183},{\"end\":60190,\"start\":60189},{\"end\":60198,\"start\":60197},{\"end\":60204,\"start\":60203},{\"end\":60549,\"start\":60548},{\"end\":60558,\"start\":60557},{\"end\":60568,\"start\":60567},{\"end\":61071,\"start\":61070},{\"end\":61077,\"start\":61076},{\"end\":61083,\"start\":61082},{\"end\":61090,\"start\":61089},{\"end\":61096,\"start\":61095},{\"end\":61102,\"start\":61101},{\"end\":61538,\"start\":61537},{\"end\":61551,\"start\":61550},{\"end\":61567,\"start\":61566},{\"end\":61867,\"start\":61866},{\"end\":61874,\"start\":61873},{\"end\":61882,\"start\":61881},{\"end\":61890,\"start\":61889},{\"end\":61896,\"start\":61895},{\"end\":61904,\"start\":61903},{\"end\":61910,\"start\":61909},{\"end\":61912,\"start\":61911},{\"end\":62425,\"start\":62424},{\"end\":62434,\"start\":62433},{\"end\":62436,\"start\":62435},{\"end\":62734,\"start\":62733},{\"end\":62742,\"start\":62741},{\"end\":62751,\"start\":62750},{\"end\":62759,\"start\":62758},{\"end\":63057,\"start\":63056},{\"end\":63065,\"start\":63064},{\"end\":63080,\"start\":63079},{\"end\":63088,\"start\":63087},{\"end\":63367,\"start\":63366},{\"end\":63374,\"start\":63373},{\"end\":63382,\"start\":63381},{\"end\":63390,\"start\":63389},{\"end\":63396,\"start\":63395},{\"end\":63407,\"start\":63403},{\"end\":63825,\"start\":63824},{\"end\":63835,\"start\":63834},{\"end\":63843,\"start\":63842},{\"end\":63855,\"start\":63854},{\"end\":63867,\"start\":63866},{\"end\":64536,\"start\":64535},{\"end\":64543,\"start\":64542},{\"end\":64550,\"start\":64549},{\"end\":64552,\"start\":64551},{\"end\":64558,\"start\":64557},{\"end\":64570,\"start\":64569},{\"end\":64572,\"start\":64571},{\"end\":64582,\"start\":64581},{\"end\":65261,\"start\":65260},{\"end\":65271,\"start\":65270},{\"end\":65277,\"start\":65276},{\"end\":65286,\"start\":65285},{\"end\":65540,\"start\":65539},{\"end\":65542,\"start\":65541},{\"end\":65551,\"start\":65550},{\"end\":65566,\"start\":65565},{\"end\":65576,\"start\":65572},{\"end\":65850,\"start\":65849},{\"end\":65859,\"start\":65858},{\"end\":65870,\"start\":65869},{\"end\":65876,\"start\":65875},{\"end\":66210,\"start\":66209},{\"end\":66217,\"start\":66216},{\"end\":66225,\"start\":66224},{\"end\":66232,\"start\":66231},{\"end\":66234,\"start\":66233},{\"end\":66242,\"start\":66241},{\"end\":66639,\"start\":66638},{\"end\":66641,\"start\":66640},{\"end\":66653,\"start\":66652},{\"end\":67080,\"start\":67079},{\"end\":67088,\"start\":67087},{\"end\":67099,\"start\":67098},{\"end\":67109,\"start\":67108},{\"end\":67617,\"start\":67616},{\"end\":67625,\"start\":67624},{\"end\":67634,\"start\":67633},{\"end\":67642,\"start\":67641},{\"end\":67940,\"start\":67939},{\"end\":67951,\"start\":67950},{\"end\":67960,\"start\":67959},{\"end\":67966,\"start\":67965},{\"end\":68287,\"start\":68286},{\"end\":68503,\"start\":68502},{\"end\":68513,\"start\":68512},{\"end\":68523,\"start\":68522},{\"end\":68532,\"start\":68531},{\"end\":68857,\"start\":68856},{\"end\":68868,\"start\":68867},{\"end\":69222,\"start\":69221},{\"end\":69231,\"start\":69230},{\"end\":69241,\"start\":69240},{\"end\":69252,\"start\":69251},{\"end\":69692,\"start\":69691},{\"end\":69694,\"start\":69693},{\"end\":69705,\"start\":69704},{\"end\":70148,\"start\":70147},{\"end\":70289,\"start\":70288},{\"end\":70302,\"start\":70301},{\"end\":70313,\"start\":70312},{\"end\":70315,\"start\":70314},{\"end\":70616,\"start\":70615},{\"end\":70625,\"start\":70624},{\"end\":70637,\"start\":70636},{\"end\":70646,\"start\":70645},{\"end\":70964,\"start\":70963},{\"end\":70977,\"start\":70976},{\"end\":70986,\"start\":70985},{\"end\":70993,\"start\":70992},{\"end\":71001,\"start\":71000},{\"end\":71008,\"start\":71007},{\"end\":71010,\"start\":71009},{\"end\":71022,\"start\":71018},{\"end\":71033,\"start\":71029},{\"end\":71041,\"start\":71040},{\"end\":71374,\"start\":71373},{\"end\":71386,\"start\":71385},{\"end\":71607,\"start\":71606},{\"end\":71614,\"start\":71613},{\"end\":71620,\"start\":71619},{\"end\":71628,\"start\":71627},{\"end\":71878,\"start\":71877},{\"end\":71886,\"start\":71885},{\"end\":71894,\"start\":71893},{\"end\":71901,\"start\":71900},{\"end\":71908,\"start\":71907},{\"end\":72155,\"start\":72151},{\"end\":72165,\"start\":72161},{\"end\":72175,\"start\":72171},{\"end\":72186,\"start\":72182},{\"end\":72644,\"start\":72643},{\"end\":72650,\"start\":72649},{\"end\":72658,\"start\":72657},{\"end\":72665,\"start\":72664},{\"end\":72991,\"start\":72990},{\"end\":72999,\"start\":72998},{\"end\":73007,\"start\":73006},{\"end\":73015,\"start\":73014},{\"end\":73023,\"start\":73022},{\"end\":73032,\"start\":73031},{\"end\":73040,\"start\":73039},{\"end\":73541,\"start\":73540},{\"end\":73554,\"start\":73553},{\"end\":73566,\"start\":73565},{\"end\":73568,\"start\":73567},{\"end\":73580,\"start\":73579},{\"end\":73589,\"start\":73588},{\"end\":74073,\"start\":74069},{\"end\":74082,\"start\":74081},{\"end\":74090,\"start\":74089},{\"end\":74092,\"start\":74091},{\"end\":74341,\"start\":74340},{\"end\":74354,\"start\":74353},{\"end\":74365,\"start\":74364},{\"end\":74376,\"start\":74375},{\"end\":74388,\"start\":74387},{\"end\":74398,\"start\":74397},{\"end\":74407,\"start\":74406},{\"end\":74850,\"start\":74849},{\"end\":74859,\"start\":74858},{\"end\":74869,\"start\":74868},{\"end\":74875,\"start\":74874},{\"end\":75255,\"start\":75254},{\"end\":75268,\"start\":75267},{\"end\":75276,\"start\":75275},{\"end\":75286,\"start\":75285},{\"end\":75298,\"start\":75297},{\"end\":75307,\"start\":75306},{\"end\":75321,\"start\":75320},{\"end\":75330,\"start\":75329},{\"end\":75337,\"start\":75336},{\"end\":75344,\"start\":75343},{\"end\":75814,\"start\":75813},{\"end\":75826,\"start\":75825},{\"end\":75836,\"start\":75835},{\"end\":75847,\"start\":75843},{\"end\":76543,\"start\":76538},{\"end\":76770,\"start\":76769},{\"end\":77038,\"start\":77037},{\"end\":77040,\"start\":77039},{\"end\":77051,\"start\":77050},{\"end\":77063,\"start\":77062},{\"end\":77072,\"start\":77071},{\"end\":77074,\"start\":77073},{\"end\":77084,\"start\":77083},{\"end\":77095,\"start\":77094},{\"end\":77362,\"start\":77361},{\"end\":77575,\"start\":77574},{\"end\":78151,\"start\":78150},{\"end\":78162,\"start\":78161},{\"end\":78658,\"start\":78657},{\"end\":78671,\"start\":78670},{\"end\":78673,\"start\":78672},{\"end\":78681,\"start\":78680},{\"end\":78692,\"start\":78691}]", "bib_author_last_name": "[{\"end\":53042,\"start\":53036},{\"end\":53052,\"start\":53046},{\"end\":53062,\"start\":53056},{\"end\":53072,\"start\":53066},{\"end\":53422,\"start\":53414},{\"end\":53430,\"start\":53426},{\"end\":53443,\"start\":53434},{\"end\":53454,\"start\":53447},{\"end\":53471,\"start\":53458},{\"end\":53975,\"start\":53968},{\"end\":53991,\"start\":53981},{\"end\":54384,\"start\":54378},{\"end\":54816,\"start\":54813},{\"end\":54823,\"start\":54820},{\"end\":54829,\"start\":54827},{\"end\":54837,\"start\":54833},{\"end\":54849,\"start\":54843},{\"end\":54855,\"start\":54853},{\"end\":55180,\"start\":55176},{\"end\":55188,\"start\":55184},{\"end\":55195,\"start\":55192},{\"end\":55657,\"start\":55650},{\"end\":55666,\"start\":55661},{\"end\":55678,\"start\":55670},{\"end\":56145,\"start\":56139},{\"end\":56160,\"start\":56149},{\"end\":56171,\"start\":56164},{\"end\":56183,\"start\":56175},{\"end\":56196,\"start\":56187},{\"end\":56573,\"start\":56571},{\"end\":56579,\"start\":56577},{\"end\":56586,\"start\":56583},{\"end\":56592,\"start\":56590},{\"end\":56599,\"start\":56596},{\"end\":56954,\"start\":56946},{\"end\":56961,\"start\":56958},{\"end\":56971,\"start\":56965},{\"end\":57219,\"start\":57212},{\"end\":57231,\"start\":57223},{\"end\":57894,\"start\":57886},{\"end\":57905,\"start\":57898},{\"end\":57913,\"start\":57909},{\"end\":57923,\"start\":57917},{\"end\":57935,\"start\":57927},{\"end\":57944,\"start\":57939},{\"end\":57953,\"start\":57948},{\"end\":57966,\"start\":57957},{\"end\":58624,\"start\":58616},{\"end\":58873,\"start\":58863},{\"end\":58883,\"start\":58879},{\"end\":59116,\"start\":59105},{\"end\":59131,\"start\":59122},{\"end\":59142,\"start\":59135},{\"end\":59642,\"start\":59636},{\"end\":59660,\"start\":59646},{\"end\":59670,\"start\":59664},{\"end\":60187,\"start\":60185},{\"end\":60195,\"start\":60191},{\"end\":60201,\"start\":60199},{\"end\":60208,\"start\":60205},{\"end\":60555,\"start\":60550},{\"end\":60565,\"start\":60559},{\"end\":60577,\"start\":60569},{\"end\":61074,\"start\":61072},{\"end\":61080,\"start\":61078},{\"end\":61087,\"start\":61084},{\"end\":61093,\"start\":61091},{\"end\":61099,\"start\":61097},{\"end\":61106,\"start\":61103},{\"end\":61548,\"start\":61539},{\"end\":61564,\"start\":61552},{\"end\":61575,\"start\":61568},{\"end\":61871,\"start\":61868},{\"end\":61879,\"start\":61875},{\"end\":61887,\"start\":61883},{\"end\":61893,\"start\":61891},{\"end\":61901,\"start\":61897},{\"end\":61907,\"start\":61905},{\"end\":61915,\"start\":61913},{\"end\":62431,\"start\":62426},{\"end\":62440,\"start\":62437},{\"end\":62739,\"start\":62735},{\"end\":62748,\"start\":62743},{\"end\":62756,\"start\":62752},{\"end\":62765,\"start\":62760},{\"end\":63062,\"start\":63058},{\"end\":63077,\"start\":63066},{\"end\":63085,\"start\":63081},{\"end\":63094,\"start\":63089},{\"end\":63371,\"start\":63368},{\"end\":63379,\"start\":63375},{\"end\":63387,\"start\":63383},{\"end\":63393,\"start\":63391},{\"end\":63401,\"start\":63397},{\"end\":63411,\"start\":63408},{\"end\":63832,\"start\":63826},{\"end\":63840,\"start\":63836},{\"end\":63852,\"start\":63844},{\"end\":63864,\"start\":63856},{\"end\":63879,\"start\":63868},{\"end\":64540,\"start\":64537},{\"end\":64547,\"start\":64544},{\"end\":64555,\"start\":64553},{\"end\":64567,\"start\":64559},{\"end\":64579,\"start\":64573},{\"end\":64591,\"start\":64583},{\"end\":65268,\"start\":65262},{\"end\":65274,\"start\":65272},{\"end\":65283,\"start\":65278},{\"end\":65298,\"start\":65287},{\"end\":65548,\"start\":65543},{\"end\":65563,\"start\":65552},{\"end\":65570,\"start\":65567},{\"end\":65582,\"start\":65577},{\"end\":65856,\"start\":65851},{\"end\":65867,\"start\":65860},{\"end\":65873,\"start\":65871},{\"end\":65885,\"start\":65877},{\"end\":66214,\"start\":66211},{\"end\":66222,\"start\":66218},{\"end\":66229,\"start\":66226},{\"end\":66239,\"start\":66235},{\"end\":66246,\"start\":66243},{\"end\":66650,\"start\":66642},{\"end\":66662,\"start\":66654},{\"end\":67085,\"start\":67081},{\"end\":67096,\"start\":67089},{\"end\":67106,\"start\":67100},{\"end\":67121,\"start\":67110},{\"end\":67622,\"start\":67618},{\"end\":67631,\"start\":67626},{\"end\":67639,\"start\":67635},{\"end\":67648,\"start\":67643},{\"end\":67948,\"start\":67941},{\"end\":67957,\"start\":67952},{\"end\":67963,\"start\":67961},{\"end\":67975,\"start\":67967},{\"end\":68294,\"start\":68288},{\"end\":68510,\"start\":68504},{\"end\":68520,\"start\":68514},{\"end\":68529,\"start\":68524},{\"end\":68540,\"start\":68533},{\"end\":68865,\"start\":68858},{\"end\":68874,\"start\":68869},{\"end\":69228,\"start\":69223},{\"end\":69238,\"start\":69232},{\"end\":69249,\"start\":69242},{\"end\":69259,\"start\":69253},{\"end\":69702,\"start\":69695},{\"end\":69712,\"start\":69706},{\"end\":70155,\"start\":70149},{\"end\":70299,\"start\":70290},{\"end\":70310,\"start\":70303},{\"end\":70318,\"start\":70316},{\"end\":70622,\"start\":70617},{\"end\":70634,\"start\":70626},{\"end\":70643,\"start\":70638},{\"end\":70654,\"start\":70647},{\"end\":70974,\"start\":70965},{\"end\":70983,\"start\":70978},{\"end\":70990,\"start\":70987},{\"end\":70998,\"start\":70994},{\"end\":71005,\"start\":71002},{\"end\":71016,\"start\":71011},{\"end\":71027,\"start\":71023},{\"end\":71038,\"start\":71034},{\"end\":71049,\"start\":71042},{\"end\":71383,\"start\":71375},{\"end\":71394,\"start\":71387},{\"end\":71611,\"start\":71608},{\"end\":71617,\"start\":71615},{\"end\":71625,\"start\":71621},{\"end\":71631,\"start\":71629},{\"end\":71883,\"start\":71879},{\"end\":71891,\"start\":71887},{\"end\":71898,\"start\":71895},{\"end\":71905,\"start\":71902},{\"end\":71914,\"start\":71909},{\"end\":72159,\"start\":72156},{\"end\":72169,\"start\":72166},{\"end\":72180,\"start\":72176},{\"end\":72192,\"start\":72187},{\"end\":72647,\"start\":72645},{\"end\":72655,\"start\":72651},{\"end\":72662,\"start\":72659},{\"end\":72670,\"start\":72666},{\"end\":72996,\"start\":72992},{\"end\":73004,\"start\":73000},{\"end\":73012,\"start\":73008},{\"end\":73020,\"start\":73016},{\"end\":73029,\"start\":73024},{\"end\":73037,\"start\":73033},{\"end\":73045,\"start\":73041},{\"end\":73551,\"start\":73542},{\"end\":73563,\"start\":73555},{\"end\":73577,\"start\":73569},{\"end\":73586,\"start\":73581},{\"end\":73602,\"start\":73590},{\"end\":74079,\"start\":74074},{\"end\":74087,\"start\":74083},{\"end\":74100,\"start\":74093},{\"end\":74351,\"start\":74342},{\"end\":74362,\"start\":74355},{\"end\":74373,\"start\":74366},{\"end\":74385,\"start\":74377},{\"end\":74395,\"start\":74389},{\"end\":74404,\"start\":74399},{\"end\":74413,\"start\":74408},{\"end\":74856,\"start\":74851},{\"end\":74866,\"start\":74860},{\"end\":74872,\"start\":74870},{\"end\":74884,\"start\":74876},{\"end\":75265,\"start\":75256},{\"end\":75273,\"start\":75269},{\"end\":75283,\"start\":75277},{\"end\":75295,\"start\":75287},{\"end\":75304,\"start\":75299},{\"end\":75318,\"start\":75308},{\"end\":75327,\"start\":75322},{\"end\":75334,\"start\":75331},{\"end\":75341,\"start\":75338},{\"end\":75350,\"start\":75345},{\"end\":75823,\"start\":75815},{\"end\":75833,\"start\":75827},{\"end\":75841,\"start\":75837},{\"end\":75851,\"start\":75848},{\"end\":76547,\"start\":76544},{\"end\":76782,\"start\":76771},{\"end\":77048,\"start\":77041},{\"end\":77060,\"start\":77052},{\"end\":77069,\"start\":77064},{\"end\":77081,\"start\":77075},{\"end\":77092,\"start\":77085},{\"end\":77104,\"start\":77096},{\"end\":77370,\"start\":77363},{\"end\":77585,\"start\":77576},{\"end\":78159,\"start\":78152},{\"end\":78167,\"start\":78163},{\"end\":78668,\"start\":78659},{\"end\":78678,\"start\":78674},{\"end\":78689,\"start\":78682},{\"end\":78699,\"start\":78693}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":7843537},\"end\":53342,\"start\":52951},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":9790585},\"end\":53889,\"start\":53344},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":8033761},\"end\":54304,\"start\":53891},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":30353027},\"end\":54730,\"start\":54306},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":52988209},\"end\":55121,\"start\":54732},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":218871925},\"end\":55565,\"start\":55123},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":59606259},\"end\":56050,\"start\":55567},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":232307359},\"end\":56537,\"start\":56052},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":49584534},\"end\":56871,\"start\":56539},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b9\"},\"end\":57148,\"start\":56873},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":102354583},\"end\":57798,\"start\":57150},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":2407216},\"end\":58468,\"start\":57800},{\"attributes\":{\"doi\":\"http:/doi.acm.org/10.1145/2568225.2568252\",\"id\":\"b12\"},\"end\":58566,\"start\":58470},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":40027275},\"end\":58788,\"start\":58568},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1682648},\"end\":59042,\"start\":58790},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":15188956},\"end\":59539,\"start\":59044},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":17355},\"end\":60122,\"start\":59541},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":203186110},\"end\":60460,\"start\":60124},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":9237290},\"end\":61012,\"start\":60462},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":49584957},\"end\":61491,\"start\":61014},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":3495200},\"end\":61785,\"start\":61493},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":52069701},\"end\":62355,\"start\":61787},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":19194935},\"end\":62659,\"start\":62357},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":51926976},\"end\":62998,\"start\":62661},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":4710028},\"end\":63293,\"start\":63000},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":84183346},\"end\":63772,\"start\":63295},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":199501739},\"end\":64458,\"start\":63774},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":198231417},\"end\":65199,\"start\":64460},{\"attributes\":{\"doi\":\"arXiv:2005.06980\",\"id\":\"b28\"},\"end\":65477,\"start\":65201},{\"attributes\":{\"doi\":\"arXiv:2005.00653\",\"id\":\"b29\"},\"end\":65768,\"start\":65479},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":215737269},\"end\":66135,\"start\":65770},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":234487049},\"end\":66552,\"start\":66137},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":8649673},\"end\":67021,\"start\":66554},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":8820379},\"end\":67542,\"start\":67023},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":51926976},\"end\":67881,\"start\":67544},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":214802082},\"end\":68245,\"start\":67883},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":10872452},\"end\":68453,\"start\":68247},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":596382},\"end\":68807,\"start\":68455},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":2757467},\"end\":69167,\"start\":68809},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":9956794},\"end\":69613,\"start\":69169},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":5860900},\"end\":70080,\"start\":69615},{\"attributes\":{\"id\":\"b41\"},\"end\":70234,\"start\":70082},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":7961699},\"end\":70547,\"start\":70236},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":3397190},\"end\":70892,\"start\":70549},{\"attributes\":{\"id\":\"b44\"},\"end\":71317,\"start\":70894},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":139164978},\"end\":71539,\"start\":71319},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":207898487},\"end\":71802,\"start\":71541},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":9720288},\"end\":72076,\"start\":71804},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":44143094},\"end\":72530,\"start\":72078},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":220979510},\"end\":72899,\"start\":72532},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":52896865},\"end\":73450,\"start\":72901},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":1654208},\"end\":73999,\"start\":73452},{\"attributes\":{\"doi\":\"arXiv:1508.04025\",\"id\":\"b52\"},\"end\":74283,\"start\":74001},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":220825019},\"end\":74786,\"start\":74285},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":231419103},\"end\":75173,\"start\":74788},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":3541031},\"end\":75747,\"start\":75175},{\"attributes\":{\"doi\":\"10.3115/1073083.1073135\",\"id\":\"b56\",\"matched_paper_id\":11080756},\"end\":76480,\"start\":75749},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":964287},\"end\":76689,\"start\":76482},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":203142176},\"end\":76977,\"start\":76691},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":14068874},\"end\":77324,\"start\":76979},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":59212480},\"end\":77496,\"start\":77326},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":56482376},\"end\":78085,\"start\":77498},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":165188},\"end\":78596,\"start\":78087},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":207591052},\"end\":78909,\"start\":78598}]", "bib_title": "[{\"end\":53032,\"start\":52951},{\"end\":53410,\"start\":53344},{\"end\":53964,\"start\":53891},{\"end\":54374,\"start\":54306},{\"end\":54809,\"start\":54732},{\"end\":55172,\"start\":55123},{\"end\":55646,\"start\":55567},{\"end\":56135,\"start\":56052},{\"end\":56567,\"start\":56539},{\"end\":57208,\"start\":57150},{\"end\":57882,\"start\":57800},{\"end\":58612,\"start\":58568},{\"end\":58853,\"start\":58790},{\"end\":59099,\"start\":59044},{\"end\":59632,\"start\":59541},{\"end\":60181,\"start\":60124},{\"end\":60546,\"start\":60462},{\"end\":61068,\"start\":61014},{\"end\":61535,\"start\":61493},{\"end\":61864,\"start\":61787},{\"end\":62422,\"start\":62357},{\"end\":62731,\"start\":62661},{\"end\":63054,\"start\":63000},{\"end\":63364,\"start\":63295},{\"end\":63822,\"start\":63774},{\"end\":64533,\"start\":64460},{\"end\":65847,\"start\":65770},{\"end\":66207,\"start\":66137},{\"end\":66636,\"start\":66554},{\"end\":67077,\"start\":67023},{\"end\":67614,\"start\":67544},{\"end\":67937,\"start\":67883},{\"end\":68284,\"start\":68247},{\"end\":68500,\"start\":68455},{\"end\":68854,\"start\":68809},{\"end\":69219,\"start\":69169},{\"end\":69689,\"start\":69615},{\"end\":70286,\"start\":70236},{\"end\":70613,\"start\":70549},{\"end\":70961,\"start\":70894},{\"end\":71371,\"start\":71319},{\"end\":71604,\"start\":71541},{\"end\":71875,\"start\":71804},{\"end\":72149,\"start\":72078},{\"end\":72641,\"start\":72532},{\"end\":72988,\"start\":72901},{\"end\":73538,\"start\":73452},{\"end\":74338,\"start\":74285},{\"end\":74847,\"start\":74788},{\"end\":75252,\"start\":75175},{\"end\":75811,\"start\":75749},{\"end\":76536,\"start\":76482},{\"end\":76767,\"start\":76691},{\"end\":77035,\"start\":76979},{\"end\":77359,\"start\":77326},{\"end\":77572,\"start\":77498},{\"end\":78148,\"start\":78087},{\"end\":78655,\"start\":78598}]", "bib_author": "[{\"end\":53044,\"start\":53034},{\"end\":53054,\"start\":53044},{\"end\":53064,\"start\":53054},{\"end\":53074,\"start\":53064},{\"end\":53424,\"start\":53412},{\"end\":53432,\"start\":53424},{\"end\":53445,\"start\":53432},{\"end\":53456,\"start\":53445},{\"end\":53473,\"start\":53456},{\"end\":53977,\"start\":53966},{\"end\":53993,\"start\":53977},{\"end\":54386,\"start\":54376},{\"end\":54818,\"start\":54811},{\"end\":54825,\"start\":54818},{\"end\":54831,\"start\":54825},{\"end\":54839,\"start\":54831},{\"end\":54851,\"start\":54839},{\"end\":54857,\"start\":54851},{\"end\":55182,\"start\":55174},{\"end\":55190,\"start\":55182},{\"end\":55197,\"start\":55190},{\"end\":55659,\"start\":55648},{\"end\":55668,\"start\":55659},{\"end\":55680,\"start\":55668},{\"end\":56147,\"start\":56137},{\"end\":56162,\"start\":56147},{\"end\":56173,\"start\":56162},{\"end\":56185,\"start\":56173},{\"end\":56198,\"start\":56185},{\"end\":56575,\"start\":56569},{\"end\":56581,\"start\":56575},{\"end\":56588,\"start\":56581},{\"end\":56594,\"start\":56588},{\"end\":56601,\"start\":56594},{\"end\":56956,\"start\":56944},{\"end\":56963,\"start\":56956},{\"end\":56973,\"start\":56963},{\"end\":57221,\"start\":57210},{\"end\":57233,\"start\":57221},{\"end\":57896,\"start\":57884},{\"end\":57907,\"start\":57896},{\"end\":57915,\"start\":57907},{\"end\":57925,\"start\":57915},{\"end\":57937,\"start\":57925},{\"end\":57946,\"start\":57937},{\"end\":57955,\"start\":57946},{\"end\":57968,\"start\":57955},{\"end\":58626,\"start\":58614},{\"end\":58859,\"start\":58855},{\"end\":58875,\"start\":58859},{\"end\":58885,\"start\":58875},{\"end\":59118,\"start\":59101},{\"end\":59133,\"start\":59118},{\"end\":59144,\"start\":59133},{\"end\":59644,\"start\":59634},{\"end\":59662,\"start\":59644},{\"end\":59672,\"start\":59662},{\"end\":60189,\"start\":60183},{\"end\":60197,\"start\":60189},{\"end\":60203,\"start\":60197},{\"end\":60210,\"start\":60203},{\"end\":60557,\"start\":60548},{\"end\":60567,\"start\":60557},{\"end\":60579,\"start\":60567},{\"end\":61076,\"start\":61070},{\"end\":61082,\"start\":61076},{\"end\":61089,\"start\":61082},{\"end\":61095,\"start\":61089},{\"end\":61101,\"start\":61095},{\"end\":61108,\"start\":61101},{\"end\":61550,\"start\":61537},{\"end\":61566,\"start\":61550},{\"end\":61577,\"start\":61566},{\"end\":61873,\"start\":61866},{\"end\":61881,\"start\":61873},{\"end\":61889,\"start\":61881},{\"end\":61895,\"start\":61889},{\"end\":61903,\"start\":61895},{\"end\":61909,\"start\":61903},{\"end\":61917,\"start\":61909},{\"end\":62433,\"start\":62424},{\"end\":62442,\"start\":62433},{\"end\":62741,\"start\":62733},{\"end\":62750,\"start\":62741},{\"end\":62758,\"start\":62750},{\"end\":62767,\"start\":62758},{\"end\":63064,\"start\":63056},{\"end\":63079,\"start\":63064},{\"end\":63087,\"start\":63079},{\"end\":63096,\"start\":63087},{\"end\":63373,\"start\":63366},{\"end\":63381,\"start\":63373},{\"end\":63389,\"start\":63381},{\"end\":63395,\"start\":63389},{\"end\":63403,\"start\":63395},{\"end\":63413,\"start\":63403},{\"end\":63834,\"start\":63824},{\"end\":63842,\"start\":63834},{\"end\":63854,\"start\":63842},{\"end\":63866,\"start\":63854},{\"end\":63881,\"start\":63866},{\"end\":64542,\"start\":64535},{\"end\":64549,\"start\":64542},{\"end\":64557,\"start\":64549},{\"end\":64569,\"start\":64557},{\"end\":64581,\"start\":64569},{\"end\":64593,\"start\":64581},{\"end\":65270,\"start\":65260},{\"end\":65276,\"start\":65270},{\"end\":65285,\"start\":65276},{\"end\":65300,\"start\":65285},{\"end\":65550,\"start\":65539},{\"end\":65565,\"start\":65550},{\"end\":65572,\"start\":65565},{\"end\":65584,\"start\":65572},{\"end\":65858,\"start\":65849},{\"end\":65869,\"start\":65858},{\"end\":65875,\"start\":65869},{\"end\":65887,\"start\":65875},{\"end\":66216,\"start\":66209},{\"end\":66224,\"start\":66216},{\"end\":66231,\"start\":66224},{\"end\":66241,\"start\":66231},{\"end\":66248,\"start\":66241},{\"end\":66652,\"start\":66638},{\"end\":66664,\"start\":66652},{\"end\":67087,\"start\":67079},{\"end\":67098,\"start\":67087},{\"end\":67108,\"start\":67098},{\"end\":67123,\"start\":67108},{\"end\":67624,\"start\":67616},{\"end\":67633,\"start\":67624},{\"end\":67641,\"start\":67633},{\"end\":67650,\"start\":67641},{\"end\":67950,\"start\":67939},{\"end\":67959,\"start\":67950},{\"end\":67965,\"start\":67959},{\"end\":67977,\"start\":67965},{\"end\":68296,\"start\":68286},{\"end\":68512,\"start\":68502},{\"end\":68522,\"start\":68512},{\"end\":68531,\"start\":68522},{\"end\":68542,\"start\":68531},{\"end\":68867,\"start\":68856},{\"end\":68876,\"start\":68867},{\"end\":69230,\"start\":69221},{\"end\":69240,\"start\":69230},{\"end\":69251,\"start\":69240},{\"end\":69261,\"start\":69251},{\"end\":69704,\"start\":69691},{\"end\":69714,\"start\":69704},{\"end\":70157,\"start\":70147},{\"end\":70301,\"start\":70288},{\"end\":70312,\"start\":70301},{\"end\":70320,\"start\":70312},{\"end\":70624,\"start\":70615},{\"end\":70636,\"start\":70624},{\"end\":70645,\"start\":70636},{\"end\":70656,\"start\":70645},{\"end\":70976,\"start\":70963},{\"end\":70985,\"start\":70976},{\"end\":70992,\"start\":70985},{\"end\":71000,\"start\":70992},{\"end\":71007,\"start\":71000},{\"end\":71018,\"start\":71007},{\"end\":71029,\"start\":71018},{\"end\":71040,\"start\":71029},{\"end\":71051,\"start\":71040},{\"end\":71385,\"start\":71373},{\"end\":71396,\"start\":71385},{\"end\":71613,\"start\":71606},{\"end\":71619,\"start\":71613},{\"end\":71627,\"start\":71619},{\"end\":71633,\"start\":71627},{\"end\":71885,\"start\":71877},{\"end\":71893,\"start\":71885},{\"end\":71900,\"start\":71893},{\"end\":71907,\"start\":71900},{\"end\":71916,\"start\":71907},{\"end\":72161,\"start\":72151},{\"end\":72171,\"start\":72161},{\"end\":72182,\"start\":72171},{\"end\":72194,\"start\":72182},{\"end\":72649,\"start\":72643},{\"end\":72657,\"start\":72649},{\"end\":72664,\"start\":72657},{\"end\":72672,\"start\":72664},{\"end\":72998,\"start\":72990},{\"end\":73006,\"start\":72998},{\"end\":73014,\"start\":73006},{\"end\":73022,\"start\":73014},{\"end\":73031,\"start\":73022},{\"end\":73039,\"start\":73031},{\"end\":73047,\"start\":73039},{\"end\":73553,\"start\":73540},{\"end\":73565,\"start\":73553},{\"end\":73579,\"start\":73565},{\"end\":73588,\"start\":73579},{\"end\":73604,\"start\":73588},{\"end\":74081,\"start\":74069},{\"end\":74089,\"start\":74081},{\"end\":74102,\"start\":74089},{\"end\":74353,\"start\":74340},{\"end\":74364,\"start\":74353},{\"end\":74375,\"start\":74364},{\"end\":74387,\"start\":74375},{\"end\":74397,\"start\":74387},{\"end\":74406,\"start\":74397},{\"end\":74415,\"start\":74406},{\"end\":74858,\"start\":74849},{\"end\":74868,\"start\":74858},{\"end\":74874,\"start\":74868},{\"end\":74886,\"start\":74874},{\"end\":75267,\"start\":75254},{\"end\":75275,\"start\":75267},{\"end\":75285,\"start\":75275},{\"end\":75297,\"start\":75285},{\"end\":75306,\"start\":75297},{\"end\":75320,\"start\":75306},{\"end\":75329,\"start\":75320},{\"end\":75336,\"start\":75329},{\"end\":75343,\"start\":75336},{\"end\":75352,\"start\":75343},{\"end\":75825,\"start\":75813},{\"end\":75835,\"start\":75825},{\"end\":75843,\"start\":75835},{\"end\":75853,\"start\":75843},{\"end\":76549,\"start\":76538},{\"end\":76784,\"start\":76769},{\"end\":77050,\"start\":77037},{\"end\":77062,\"start\":77050},{\"end\":77071,\"start\":77062},{\"end\":77083,\"start\":77071},{\"end\":77094,\"start\":77083},{\"end\":77106,\"start\":77094},{\"end\":77372,\"start\":77361},{\"end\":77587,\"start\":77574},{\"end\":78161,\"start\":78150},{\"end\":78169,\"start\":78161},{\"end\":78670,\"start\":78657},{\"end\":78680,\"start\":78670},{\"end\":78691,\"start\":78680},{\"end\":78701,\"start\":78691}]", "bib_venue": "[{\"end\":53125,\"start\":53074},{\"end\":53559,\"start\":53473},{\"end\":54054,\"start\":53993},{\"end\":54467,\"start\":54386},{\"end\":54898,\"start\":54857},{\"end\":55275,\"start\":55197},{\"end\":55752,\"start\":55680},{\"end\":56250,\"start\":56198},{\"end\":56660,\"start\":56601},{\"end\":56942,\"start\":56873},{\"end\":57375,\"start\":57233},{\"end\":58051,\"start\":57968},{\"end\":58657,\"start\":58626},{\"end\":58893,\"start\":58885},{\"end\":59216,\"start\":59144},{\"end\":59759,\"start\":59672},{\"end\":60267,\"start\":60210},{\"end\":60670,\"start\":60579},{\"end\":61189,\"start\":61108},{\"end\":61629,\"start\":61577},{\"end\":62008,\"start\":61917},{\"end\":62498,\"start\":62442},{\"end\":62819,\"start\":62767},{\"end\":63100,\"start\":63096},{\"end\":63510,\"start\":63413},{\"end\":64028,\"start\":63881},{\"end\":64740,\"start\":64593},{\"end\":65258,\"start\":65201},{\"end\":65537,\"start\":65479},{\"end\":65943,\"start\":65887},{\"end\":66300,\"start\":66248},{\"end\":66737,\"start\":66664},{\"end\":67210,\"start\":67123},{\"end\":67702,\"start\":67650},{\"end\":68050,\"start\":67977},{\"end\":68327,\"start\":68296},{\"end\":68606,\"start\":68542},{\"end\":68940,\"start\":68876},{\"end\":69333,\"start\":69261},{\"end\":69792,\"start\":69714},{\"end\":70145,\"start\":70082},{\"end\":70369,\"start\":70320},{\"end\":70696,\"start\":70656},{\"end\":71079,\"start\":71051},{\"end\":71407,\"start\":71396},{\"end\":71648,\"start\":71633},{\"end\":71921,\"start\":71916},{\"end\":72283,\"start\":72194},{\"end\":72686,\"start\":72672},{\"end\":73125,\"start\":73047},{\"end\":73676,\"start\":73604},{\"end\":74067,\"start\":74001},{\"end\":74488,\"start\":74415},{\"end\":74970,\"start\":74886},{\"end\":75434,\"start\":75352},{\"end\":75973,\"start\":75876},{\"end\":76580,\"start\":76549},{\"end\":76812,\"start\":76784},{\"end\":77133,\"start\":77106},{\"end\":77405,\"start\":77372},{\"end\":77719,\"start\":77587},{\"end\":78277,\"start\":78169},{\"end\":78729,\"start\":78701},{\"end\":53632,\"start\":53561},{\"end\":54102,\"start\":54056},{\"end\":54535,\"start\":54469},{\"end\":55340,\"start\":55277},{\"end\":55811,\"start\":55754},{\"end\":56706,\"start\":56662},{\"end\":57504,\"start\":57377},{\"end\":58138,\"start\":58053},{\"end\":59275,\"start\":59218},{\"end\":59833,\"start\":59761},{\"end\":60748,\"start\":60672},{\"end\":61257,\"start\":61191},{\"end\":62086,\"start\":62010},{\"end\":64162,\"start\":64030},{\"end\":64874,\"start\":64742},{\"end\":66797,\"start\":66739},{\"end\":67284,\"start\":67212},{\"end\":68994,\"start\":68942},{\"end\":69392,\"start\":69335},{\"end\":69857,\"start\":69794},{\"end\":73190,\"start\":73127},{\"end\":73735,\"start\":73678},{\"end\":74548,\"start\":74490},{\"end\":76077,\"start\":75975},{\"end\":77838,\"start\":77721},{\"end\":78372,\"start\":78279}]"}}}, "year": 2023, "month": 12, "day": 17}