{"id": 254685588, "updated": "2023-10-05 07:02:52.919", "metadata": {"title": "Objaverse: A Universe of Annotated 3D Objects", "authors": "[{\"first\":\"Matt\",\"last\":\"Deitke\",\"middle\":[]},{\"first\":\"Dustin\",\"last\":\"Schwenk\",\"middle\":[]},{\"first\":\"Jordi\",\"last\":\"Salvador\",\"middle\":[]},{\"first\":\"Luca\",\"last\":\"Weihs\",\"middle\":[]},{\"first\":\"Oscar\",\"last\":\"Michel\",\"middle\":[]},{\"first\":\"Eli\",\"last\":\"VanderBilt\",\"middle\":[]},{\"first\":\"Ludwig\",\"last\":\"Schmidt\",\"middle\":[]},{\"first\":\"Kiana\",\"last\":\"Ehsani\",\"middle\":[]},{\"first\":\"Aniruddha\",\"last\":\"Kembhavi\",\"middle\":[]},{\"first\":\"Ali\",\"last\":\"Farhadi\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Massive data corpora like WebText, Wikipedia, Conceptual Captions, WebImageText, and LAION have propelled recent dramatic progress in AI. Large neural models trained on such datasets produce impressive results and top many of today's benchmarks. A notable omission within this family of large-scale datasets is 3D data. Despite considerable interest and potential applications in 3D vision, datasets of high-fidelity 3D models continue to be mid-sized with limited diversity of object categories. Addressing this gap, we present Objaverse 1.0, a large dataset of objects with 800K+ (and growing) 3D models with descriptive captions, tags, and animations. Objaverse improves upon present day 3D repositories in terms of scale, number of categories, and in the visual diversity of instances within a category. We demonstrate the large potential of Objaverse via four diverse applications: training generative 3D models, improving tail category segmentation on the LVIS benchmark, training open-vocabulary object-navigation models for Embodied AI, and creating a new benchmark for robustness analysis of vision models. Objaverse can open new directions for research and enable new applications across the field of AI.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2212.08051", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/DeitkeSSWMVSEKF23", "doi": "10.1109/cvpr52729.2023.01263"}}, "content": {"source": {"pdf_hash": "1b31dbf44e68b698120552366df03e6e35a1e428", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2212.08051v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "7c6b6fc87d0a0b2001ec33c430706b7ed6d210f5", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1b31dbf44e68b698120552366df03e6e35a1e428.txt", "contents": "\nObjaverse: A Universe of Annotated 3D Objects\n\n\nMatt Deitke \nPRIOR\nAllen Institute for AI\n\n\nUniversity of Washington\nSeattle\n\nDustin Schwenk \nPRIOR\nAllen Institute for AI\n\n\nJordi Salvador \nPRIOR\nAllen Institute for AI\n\n\nLuca Weihs \nPRIOR\nAllen Institute for AI\n\n\nOscar Michel \nPRIOR\nAllen Institute for AI\n\n\nEli Vanderbilt \nPRIOR\nAllen Institute for AI\n\n\nLudwig Schmidt \nUniversity of Washington\nSeattle\n\nKiana Ehsani \nPRIOR\nAllen Institute for AI\n\n\nAniruddha Kembhavi \nPRIOR\nAllen Institute for AI\n\n\nUniversity of Washington\nSeattle\n\nAli Farhadi \nUniversity of Washington\nSeattle\n\nObjaverse: A Universe of Annotated 3D Objects\n\nFigure 1. Example instances from our large-scale 3D asset dataset OBJAVERSE. OBJAVERSE 3D assets are semantically diverse, highquality, and paired with natural-language descriptions.AbstractMassive data corpora like WebText, Wikipedia, Conceptual Captions, WebImageText, and LAION have propelled recent dramatic progress in AI. Large neural models trained on such datasets produce impressive results and top many of today's benchmarks. A notable omission within this family of large-scale datasets is 3D data. Despite considerable interest and potential applications in 3D vision, datasets of high-fidelity 3D models continue to be mid-sized with limited diversity of object categories. Addressing this gap, we present Objaverse 1.0, a large dataset of objects with 800K+ (and growing) 3D models with descriptive captions, tags, and animations. Objaverse improves upon present day 3D repositories in terms of scale, number of categories, and in the visual diversity of instances within a category. We demonstrate the large potential of Objaverse via four diverse applications: training generative 3D models, im-Correspondence to <mattd@allenai.org>.proving tail category segmentation on the LVIS benchmark, training open-vocabulary object-navigation models for Embodied AI, and creating a new benchmark for robustness analysis of vision models. Objaverse can open new directions for research and enable new applications across the field of AI.\n\nIntroduction\n\nMassive datasets have enabled and driven rapid progress in AI. Language corpora on the web led to large language models like GPT-3 [4]; paired image and text datasets like Conceptual Captions [68] led to vision-and-language pretrained models like VilBERT [45]; YouTube video datasets led to video capable models like Merlot-Reserve [87]; and massive multimodal datasets like WebImageText [70] and LAION [66,67] led to models like CLIP [60] and StableDiffusion [64]. These leaps in dataset scale and diversity were triggered by moving from manually curated datasets to harnessing the power of the web and its creative content.\n\nIn contrast to the datasets described above, the size of the datasets we are feeding to our, data-hungry, deep learning models in many other areas of research is simply not comparable. For instance, the number of 3D assets used in training generative 3D models is, maximally, on the order of thousands [24] and the simulators used to train embodied AI models typically have only between a few dozen to a thousand unique scenes [39,42,63,72]. The startling advances brought about by developing large-scale datasets for images, videos, and natural language, demand that an equivalent dataset be built for 3D assets. We present OBJAVERSE 1.0, a large scale corpus of highquality, richly annotated, 3D objects; see Fig. 1. Objects in our dataset are free to use 1 and sourced from Sketchfab, a leading online platform for managing, viewing, and distributing 3D models. In total, OBJAVERSE contains over 800K 3D assets designed by over 100K artists which makes this data large and diversely sourced. Assets not only belong to varied categories like animals, humans, and vehicles, but also include interiors and exteriors of large spaces that can be used, e.g., to train embodied agents. OBJAVERSE is a universe of rich 3D data with detailed metadata that can support many different annotations to enable new applications. With this remarkable increase in scale, we see an incredible opportunity for OBJAVERSE to impact research progress across domains. In this work, we provide promising results to answer three questions.\n\nCan 3D vision benefit from a large-scale dataset? First, as a 3D asset resource, OBJAVERSE can support the exciting field of 3D generative modeling. We use data extracted from OBJAVERSE to train generative models for single and multiple categories using GET3D [24] and find that we are able to generate high-quality objects and, moreover, that our generated objects are found by human annotators to be more diverse than those generated by a model trained on ShapeNet objects in 91% of cases.\n\nCan the diversity of 3D models help improve classical 2D vision task performance? To answer this question, we use the diversity of OBJAVERSE to improve the performance of long tail instance segmentation models. Instance segmentation data can be expensive to obtain owing to the cost of annotating contours around objects. The recent LVIS dataset contains annotations for 1,230 categories but the task remains very challenging for present day models, particularly on tail categories that have few examples. We show that increasing the volume of data by leveraging a simple Copy+Paste augmentation method with OBJAVERSE assets can improve the performance of state-of-the-art segmentation methods.\n\nWe also use OBJAVERSE to build a benchmark for evaluating the robustness of state-of-the-art visual classification models to perspective shifts. We render objects in OBJAVERSE from random orientations, which is how one 1 Creative Commons license might expect to see them in the real world and test the ability of CLIP-style visual backbones to correctly classify these images. Our experiments show that current stateof-the-art models' performance degrades dramatically in this setting when viewing objects from arbitrary views. OBJAVERSE allows us to build benchmarks to test (and potentially train) for orientation robustness for a long tail distribution of asset categories. Building such benchmarks is made uniquely possible by the scale and diversity of 3D assets in OBJAVERSE. This would simply not be feasible to create in the real world nor can they be generated from existing 2D images.\n\nCan a large-scale 3D dataset help us train embodied agents performant embodied agents? We use assets in OBJAVERSE to populate procedurally generated simulated environments in ProcTHOR [17] that are used to train Embodied AI agents. This results in an orders of magnitude increase in the number of unique assets available for use in ProcTHOR scenes (previously limited to AI2-THOR's [39] asset library of a few thousand unique instances each assigned to one of 108 object categories). Using OBJAVERSE populated scenes enables open vocabulary object navigation from any text description. In this paper, we provide quantitative results for navigating to 1.1K semantic object categories, roughly a 50x increase.\n\nThese findings represent just a small fraction of what can be accomplished using OBJAVERSE. We are excited to see how the research community will leverage OBJAVERSE to enable fast and exciting progress in 2D and 3D computer vision applications and beyond.\n\n\nRelated Work\n\nLarge scale datasets. Scaling the size and scope of training datasets has widely been demonstrated to be an effective avenue of improvement for model performance. In computer vision, the adoption of early large scale datasets such as Imagenet [18,65] and MS-COCO [44] has dramatically accelerated progress on a variety of tasks including classification, object detection, captioning, and more. Ever since, the diversity and scale of datasets have continued to grow. YFCC100M is a dataset of 99.2M images and 800K videos [77]. OpenImages [40] is a large scale dataset of 9M images that contains labeled subsets bounding boxes, visual relationships, segmentation masks, localized narratives, and categorical annotations. Massive web-scraped datasets containing image-text pairs such as Conceptual Captions [68], WIT [70], and LAION [66,67] have seen increased popularity recently as they have been used to train impressive models for vision-language representation learning [29,32,60], text-to-image generation [32,61,62,64], and vision-language multitasking [9,10,73,79].\n\n3D datasets. Current large-scale 2D image datasets offer three crucial components that benefit learning: scale, diversity, and realism. Ideally, models that reason about 3D objects should have access to datasets that meet these same criteria. However, of the numerous 3D object datasets that currently exist, none are able to excel in all three categories to the same degree as their 2D counterparts. Datasets such as KIT [35], YCB [5], BigBIRD [69], IKEA [43], and Pix3D [71] provide image-calibrated models over a diverse set of household objects, but severely lack in scale with only a few hundred objects at most. EGAD [51] procedurally generates 2K objects for grasping, but produces objects that are not that realistic or diverse. Slightly larger datasets of photo-realistic objects include GSO [19], PhotoShape [53], ABO [12] and 3D-Future [22], and ShapeNet [7] with object counts in the tens of thousands, see Fig. 2 for comparisons between OBJAVERSE and these datasets. Datasets for CAD models, such as ModelNet [83] and DeepCAD [82], and ABC [38] do not include textures or materials, which limits their ability to represent objects that could plausibly be found in the real world. Datasets of scanned 3D objects and environments are valuable for real-world understanding [11,14,15,41], but are quite small and limited. In addition to containing numerous artist designed objects, OBJAVERSE contains many scanned assets, making it a useful source of data for learning from real-world distributions.\n\nWhile rapid progress has been made in developing datasets that combine image and text, in contrast, only a few datasets that pair language and 3D data exist. Text2Shape [8] released a dataset of 15,038 chairs and tables from ShapeNet each with around 5 text captions, giving 75,344 total text-shape pairs. ShapeGlot [1] released the CiC (Chairs in Context) dataset which contains 4,511 chairs from ShapeNet along with 78,789 descriptive utterances generated from a referential game. Due to the small scale and limited diversity of these datasets, current SoTA text-to-3D models [31,47,57] forgo the use of 3D datasets entirely and instead rely on 2D image-text supervision.\n\n\nObjaverse\n\nOBJAVERSE is a massive annotated 3D dataset that can be used to enable research in a wide range of areas across computer vision. The objects are sourced from Sketchfab, an online 3D marketplace where users can upload and share models for both free and commercial use. Objects selected for OBJAVERSE have a distributable Creative Commons license and were obtained using Sketchfab's public API. Aside from licensing consideration, models marked as restricted due to objectionable or adult thematic content were excluded from the dataset.\n\nModel metadata. OBJAVERSE objects inherit a set of foundational annotations supplied by their creator when uploaded to Sketchfab. Figure 4 shows an example of the metadata available for each model. The metadata includes a name, assignments to a set of fixed categories, a set of unrestricted tags, and a natural language description.\n\nOBJAVERSE-LVIS. While OBJAVERSE metadata contains a great deal of information about objects, Sketchfab's existing categorization scheme covers only 18 categories, too coarse for most applications. Object names, categories, and tags provide multiple potential categorizations at varying levels of specificity and with some inherent noise. However, for many existing computer vision tasks, it is useful to assign objects to a single category drawn from a predetermined set of the right size and level of semantic granularity.\n\nWe choose the categories from the LVIS dataset [26] for categorizing a long-tail subset of objects in OBJAVERSE. We construct a 47K LVIS categorized object subset, called OBJAVERSE-LVIS, comprised of objects uniquely assigned to one of 1156 LVIS categories. We perform these assignments by first selecting 500 candidate objects per category using a combination of predictions from a CLIP classifi-    . Tags from the low-occurrence side of the distribution correspond to unique objects that, taken individually, are rarely seen in the world. Frequently used tags like \"furniture\" and \"car\" reflect their real-world normalcy, but the high frequency of assets like \"sword\" diverge from their real-world counterparts.\n\ncation model and candidates suggested by terms in their metadata. This combined pool contains objects visually resembling the target category (from the CLIP features of their thumbnail images) that might have missing metadata, as well as visually unusual instances of a category that are accurately named or tagged. These 250k candidate objects were then manually filtered and their assigned categories verified by crowdworkers. Since we only presented 500 object candidates per class, many popular categories, such as chair or car, have substantially more objects that could be included in OBJAVERSE-LVIS with future annotations. Animated objects and rigged characters. OBJAVERSE includes 44K animated objects and over 63K objects selfcategorized as characters. Examples of animations include fridge doors opening, animals running, and the hands on a clock moving. Rigged characters can be set up for animation and rendering, and may often come annotated with bone mappings. The vast scale of animations available in OBJAVERSE can support a wide range of research in temporal 3D learning, such as building text-based animation generative models [76], representing object changes over time with NERFs [54,59], and temporal self-supervised learning via. future frame prediction [30,87].\n\nArticulated objects. Decomposing 3D objects into parts has led to a flurry of research in the past few years, including work in learning robotic grasping policies [84,86], 3D semantic segmentation [50], and shape generation [49]. Since many objects in OBJAVERSE were uploaded by artists, the objects often come separated into parts. Figure 5 shows an example, where a chair is separated by its backrest, wheels, and legs, among many smaller parts.\n\nExteriors. Photogrammetry and NERF advances have enabled the commercialization of capturing high-quality 3D objects of large exteriors by taking pictures [75,85]. In OBJAVERSE, there are a large number of scanned buildings, cities, and stadiums. Figure 5 shows an example of a 3D object of NYC's skyline captured through a scan.\n\nOBJAVERSE-Interiors. There are 16K+ interior scenes in OBJAVERSE, including houses, classrooms, and offices. The scenes often have multiple floors, many types of rooms, and are densely populated with objects from human input. Objects in the scenes are separable into parts, which allows Figure 4. An example of metadata available for each object in OBJAVERSE. Each uploaded object has a 3D model, user-selected rendered thumbnail image, name, description, tags, category, and stats, among additional metadata. them to be usable for interactive robotics, embodied AI, and scene synthesis. To put the scale of OBJAVERSE-Interiors in perspective, the number of scenes in OBJAVERSE-Interiors is significantly larger than the 400 or so existing hand-built interactive embodied AI scenes [23,39,42,72].\n\nVisual styles. Objects in the world can be constructed in many styles and often differ in style based on the timeperiod, geographic location, and artist's style. OBJAVERSE objects cover a vast set of visual styles, including 3D scans, 3D modeled objects from virtually any platform, point clouds, and photo-realism via physically based rendering (PBR) [56]. Moreover, instances of objects often appear with many styles, which is critical for training and evaluating robust computer vision models [60]. Figure 5 shows examples of chairs in OBJAVERSE in many different styles, including Gothic, modern, Victorian, cartoon, and abstract.\n\nStatistics. OBJAVERSE 1.0 includes 818K 3D objects, designed by 160K artists. There are >2.35M tags on the objects, with >170K of them being unique. We estimate that the objects have coverage for nearly 21K WordNet entities [48] (see appendix for details). Objects were uploaded between 2012 and 2022, with over 200K objects uploaded uploaded just in 2021. Figure 3 visualizes several statistics of the dataset, including the breakdown of objects into their self-assigned Sketchfab categories, a word cloud over the tags, a frequency plot of the tags, and the number of objects in OBJAVERSE-LVIS categories.\n\n\nApplications\n\nIn this section, we present 4 initial distinct applications of OBJAVERSE, including 3D generative modeling, instance segmentation with CP3D, open-vocabulary ObjectNav, and analyze robustness in computer vision models.\n\n\n3D Generative Modeling\n\n3D generative modeling has shown much improvement recently with models such as GET3D [24] delivering impressive high quality results with rich geometric details. GET3D is trained to generate 3D textured meshes for a category and produces impressive 3D objects for categories like Car, Chair, and Motorcycle using data from ShapeNet [7]. OBJAVERSE contains 3D models for many diverse categories including tail categories which are not represented in other datasets. It also contains diverse and realistic object instances per category. This scale and diversity can be used to train large vocabulary and high quality 3D generative models. In this work, we showcase the potential of this data as follows. We choose three categories of ob- Figure 5. Highlights of the visual diversity of objects that appear in OBJAVERSE, including animated objects, rigged (body-part annotated) characters, models separatable into parts, exterior environments, interior environments, and a wide range visual styles.  jects, Shoe, Bag, and Fruit&Veg, and subsample objects from OBJAVERSE to create three separate datasets containing, respectively, 143 shoes, 816 bags, and 571 fruits & vegetables (116 apples, 112 gourds, 92 mushrooms, 68 bananas, 52 oranges, 52 pears, 31 potatoes 24 lemons, and 24 pineapples). For comparison, we also train a GET3D model on the set of 83 bags from the ShapeNet dataset. Fig. 6 shows a collection of 3D objects generated by our trained GET3D models. Qualitatively, the 3D-meshes generated by the OBJAVERSE-trained models are high-quality and diverse, especially when compared to the generations from the ShapeNet-trained model. To quantify this observation, we asked crowdworkers to rate the diversity of Bag generations produced by the OBJAVERSE and ShapeNet trained models. When shown collections of nine randomly sampled Figure 7. An illustration of 3DCP (3D copy-paste) for segmentation augmentation. We render 3D objects from multiple views and paste them over LVIS training images.\n\ngenerations from both models, workers rated the collection generated from the OBJAVERSE trained model as more diverse in appearance 91% of the time.\n\nOur fruits and vegetables, composed of 9 varieties produces perhaps the highest quality output, a promising signal that can inspire future work in text-to-3D generation.\n\n\nInstance Segmentation with CP3D\n\nA key advantage of using simulated data for computer vision is that it is much cheaper to obtain expert annotations. Annotated OBJAVERSE objects can be rendered into images, allowing them to serve as a rich source of additional data that can be used to enhance model performance on 2D computer vision tasks. As a proof-of-concept demonstrating the effectiveness of this approach, we use segmented data from OBJAVERSE objects as auxiliary labels for training models on the LVIS dataset for Large Scale Instance Segmentation [26]. The LVIS dataset contains instance segmentation masks for 1200 object categories that occur throughout a set of 164k images. Recognition is especially challenging in this task due to the long tail of the object category distribution in this dataset. LVIS categories only con- tain an average 9 instances across the dataset, so training on simulated data is a promising approach for overcoming the challenges of learning in this low-sample regime.\n\nUsing the LVIS-annotated subset of OBJAVERSE, we introduce 3DCP: an enhancement to the simple, but effective, copy-and-paste technique of [25]. Figure 7 shows an example of the setup for 3DCP. Here, we render different views of 3D objects and paste them on-top of existing LVIS images. We render 5 distinct views of each object and cache them for use throughout training. During training, an image is selected for the copy-paste augmentation with 0.5 probability, and once selected, 1-3 images of randomly chosen LVISannotated OBJAVERSE objects are pasted onto the selected training image. The segmentation masks of the selected objects are added to the training image's annotation as well. Object images and masks are randomly scaled and translated before being pasted. We use this strategy to finetune the pretrained ResNet-50 Mask-RCNN [27,28] of [3]. As shown in Tab.1, simply finetuning this model for 24 epochs yields performance gains across several metrics.\n\n\nOpen-Vocabulary ObjectNav\n\nIn this section, we introduce open-vocabulary Object-Nav, a new task propelled by the vast diversity of objects that appear in OBJAVERSE. Here, an agent is placed at a random starting location inside of a home and tasked to navigate to a target object provided from a text description (e.g. \"Raspberry Pi Pico\"). To facilitate this task, we procedurally generate 10K new homes in ProcTHOR [17] fully populated with objects from OBJAVERSE-LVIS. Until now, ObjectNav tasks have focused on training agents to navigate to 20 or so target objects provided their category label [16,17,63], and existing interactive embodied AI simulations, including ProcTHOR, only include around 2K total objects across around 100 object types [17,42,72]. In this work, we take a large step to massively scale the number of target objects used in ObjectNav (20 \u2192 OpenVocab), the number of objects available in simulation (2K \u2192 36K), and the number of object types of the objects (100 \u2192 1.1K).\n\nObject placement. To make the placement of objects in the houses more natural, we use the OBJAVERSE-LVIS subset and annotate placement constraints for each object category. Specifically, we annotate if objects of a given category typically appears on the floor, on-top of a surface, or on a wall. If instances of the object category may appear on the floor, we also annotate whether it may appear in the middle of the scene (e.g. a clutter object like a basketball) or on the edge of the scene (e.g. a toilet or a fridge). For objects placed on the floor, we also to automatically detect flat regions on top of the object's mesh to place surface object types. The annotations are used by ProcTHOR for sampling objects to place in a scene. We also filter out OBJAVERSE-LVIS objects that do not appear inside of homes, such as a jet plane. Structural objects, like doors and windows, are inherited from ProcTHOR as they would require additional cleanup.\n\nObject size correction. Objects in Sketchfab may be uploaded at unnatural scales (e.g. a plant being as large as a tower). We therefore scale the objects to be of a reasonable size for them to look natural in a house. Here, for each object category, we annotate the maximum bounding box dimension length that every instance of the object category should be scaled to. For example, we annotate the maximum bounding box dimension for bookcase to be 2 meters and fork to be 0.18 meters. If a 3D modeled bookcase then has a bounding box of 20m\u00d76m\u00d73m, we shrink each side by a factor of max(20, 6, 3)/2 = 5.\n\nPreprocessing for AI2-THOR. We add support to AI2-THOR for loading objects on the fly at runtime. Previously, all objects had to be stored in a Unity build, but such an approach is impractical when working with orders of magnitude more object data. For each object, we compress it with Blender [13] by joining all of its meshes together, decimate the joined mesh such that it has at most 5K vertices, and bake all the UV texture maps into a single texture map. We then generate colliders using V-HACD [46] to support rigid-body interactions.\n\nApproach. Given procedural houses populated with OBJAVERSE-LVIS, the task is to navigate to the proximity of a chosen target object and invoke a task-completion action when the target object is in sight, given an open-vocabulary description formed with the template \"a {name} {category}\". The name is the object name given by its creator, which is often descriptive. We filter Figure 9. Examples of objects rendered from random orientations and their 0-shot classification categories with the CLIP ViT-B/32. each by whether it is detected as being written in English by a language detector [33,34], and fall back to a class-only description for non-English name. Examples of the possible expressions include \"a victorian-monobike motorcycle\", \"a unicorn pony\", or \"a dino ghost lizard\". The agent, similar to the ones in [36], observes an RGB egocentric view of the environment, pre-processed by the visual branch of a frozen ResNet-50 CLIP model [60] -the target description is preprocessed by the corresponding text branch. We train the agent with DD-PPO [81] and evaluate on houses with floor plans, objects, and descriptions unseen in training. We use the AllenAct [80] framework to train our agent. Our trained agent achieves a success rate of 19.9%, for a random policy success of 5.1%. For more details about the experiment refer to the appendix.\n\n\nAnalyzing Robustness\n\nA persistent bias present in many image datasets, e.g. ImageNet [65], is that the subjects of interest are generally photographed from a forward-facing, canonical, orientation. When, for example, taking a photograph of a television, few would choose to take this photograph crouched on the floor behind the television. This impact of this bias was studied by Alcorn et al. [2] who find that modern computer vision systems are highly susceptible to deviations from canonical poses. This is more than a theoretical problem: computer vision systems deployed in the real world will frequently encounter objects in non-canonical orientations and in many applications, e.g. autonomous driving, it will be safety critical that they behave well.\n\nGiven the above, we adopt the experimental design of Alcorn et al. and design, using OBJAVERSE assets, a benchmark for evaluating the robustness of state-of-the-art computer vision classification models to orientation shifts. In particular, for each object in our OBJAVERSE-LVIS subset, we render 12 images of the object from random orientations rendered upon a background with RGB values equalling the mean RGB values from ImageNet; see Fig. 9 for examples. This ability to, at scale, render objects from random view-  points is a practical impossibility in the real world but is made trivial when using 3D assets. We then evaluate several modern open-domain image-classification networks (constrained to the \u22481,200 LVIS categories) on these images and report 4 metrics for each model. These metrics include:\n\n\u2022 Top-1 Random Rotation -the frequency with which a model correctly classifies an image as belonging to the respective LVIS category.\n\n\u2022 Top-1 Any Rotation -the frequency with which a model classifies an image correctly from at least one of the 12 random orientations. This second metric is diagnostic and serves to represent a model's performance when shown an object from a canonical pose. We also have Top-5 variants of the above metric where the correct category need only be in the top 5 predictions from the model. We report our results in Tab. 2 in which we evaluate a variety of performant pretrained models. Comparing the gap in performance between the Top-k Random Rotation and Top-k Any Rotation metrics we find that model performance dramatically degrades when viewing objects from unusual orientations.\n\n\nConclusion\n\nWe present OBJAVERSE, a next-generation 3D asset library containing 818K high-quality, diverse, 3D models with paired text descriptions, titles, and tags. As a small glimpse of the potential uses of OBJAVERSE, we present four experimental studies showing how OBJAVERSE can be used to power (1) generative 3D models with clear future applications to text-to-3D generation, (2) improvements to classical computer vision tasks such as instance segmentation, (3) the creation of novel embodied AI tasks like Open Vocabulary Object Navigation, and (4) quantifying the rotational robustness of vision models on renderings of objects. We hope to see OBJAVERSE enable a new universe of new applications for computer vision.\n\n\nA. Instance Segmentation with CP3D\n\nModel. We use the Mask-RCNN [27] model of [3] with a ResNet-50 backbone [28]; no additional changes to their model are made. Instead of a softmax activation, the model uses a Gumbel activation, given by the formula \u03b7(q) = exp(\u2212 exp(\u2212q)), to transform logits into probabilities. More details about the model and activation can be found in [3].\n\nTraining. We take the pretrained ResNet-50 Mask-RCNN checkpoint of [3] and finetune the model for 24 epochs with the CP3D augmentation integrated into the training pipeline. We use a batch size of 64 and a learning rate of 0.002.\n\n\nAdditional Results\n\nHere we report detection metrics in addition to the segmentation results reported in the paper in Table 1. Notably, we see an impressive gain of two points on AP for rare categories.  Table 3. Detection results for bounding box AP category metrics. APr, APc, and APf measure AP for categories that are rare (appear in 1-10 images), common (appear in 11-100 images), and frequent (appear in >100 images), respectively.\n\n\nB. Open-Vocabulary ObjectNav\n\nModel. The agent's embodiment is a simulated LoCoBot [6]. The action space consists of six actions: MOVEA-HEAD, ROTATELEFT, ROTATERIGHT, END, LOOKUP, and LOOKDOWN. Given the excellent exploration capabilities of EmbCLIP [17,36], we opt to keep the same overall architecture, just replacing the learned embedding for target types in prior work by a linear projection of the text branch output of CLIP for the target description, as shown in Fig. 10. Additionally, in order to provide more information about the target and the current visual input, we increase the respective internal representations for each modality from the original 32-D to 256-D. Note that our model does not employ the alternative zero-shot design described in [36], where the target description is not observed by the agent's RNN. Given the scale of OBJAVERSE-LVIS, we can train agents with good generalization following a more standard design.\n\nTraining. For training, we use ProcTHOR to procedurally generate 10,080 houses. Each house has up to three rooms, entirely populated with OBJAVERSE-LVIS assets except for  structural components like doors and windows, which are inherited from ProcTHOR [17]. We sample targets corresponding to LVIS categories for which a single instance is present in the scene, resulting in a total of 9,421 unique assets corresponding to 262 categories targeted during training. Training uses DD-PPO [81] and is distributed across 28 GPUs on 7 AWS g4dn.12xlarge machines, with each GPU hosting 360 houses and the subset of OBJAVERSE-LVIS assets populating them. The training hyperparameters, identical to the ones in [17], and the 262 training target categories are listed in Table 4 and  30 testing target categories are listed in Table 6. For the results provided in the main paper, the agent is trained for just 18 million simulation steps, but the resulting policy already shows reasonable performance given the variety of targets and scenes. Improved performance can be achieved with extended training (e.g., after approx. 460 million steps, the success rate is 33.0%).\n\n\nC. Composition\n\nHuman subjects data. A portion of the data included in OBJAVERSE is generated by human subjects (i.e. crowdworkers recruited through Amazon's Mechanical Turk platform) as outlined in Section 3 and detailed below. The collection process has been reviewed and approved for release by an Institutional Review Board.\n\nData collection interfaces. Human annotators were used to provide the category labels for OBJAVERSE-LVIS as described in Section 3. This task was accomplished by first creating sets of 500 candidate objects for each LVIS category. These candidate sets included objects visually resembling the target category (as ranked by the CLIP features of their thumbnail images), as well as instances whose metadata contained terms with a high similarity to the target category (as ranked by their GloVe vector similarity [55]). Candidate objects were shown to crowdworkers nine at a time, and they were asked to mark objects that were members of the category, as shown in Figure 11 a. In addition to the visual reference for each object, annotators also had access to the object's name and were encouraged to use this when helpful. Human annotators were also used to rate the relative diversity of of 3D objects generated by models trained using OBJAVERSE and ShapeNet. The user interface and instructions for this task are shown in Figure 11 b. Two sets of nine objects generated by each model were shown with random left-right orientations, and workers were asked to choose the set exhibiting the greater variety in appearance.\n\n\nD. Estimating Coverage\n\nWe use OpenAI's CLIP ViT-B/32 model to estimate the categorical coverage of the objects in OBJAVERSE. Specifically, for each object, we compute the CLIP image embedding from the thumbnail and the cosine similarity between an text embedding of each WordNet entity [20]. The entity Christmas tree, bed, bench, blackberry, chair, chicken (animal), dog, easel, elk, fireplug, forklift, garbage, gargoyle, guitar, mascot, motor, penguin, pony, pool table, radiator, rifle, scarf, sock, speaker (stero equipment), sportswear, sweat pants, trash can, trunk, wet suit, and wheel.   with the maximum cosine similarity is then assigned as the object's entity. The WordNet entities are textually encoded in the form, \"a {entity} is a {definition}\", which is loosely inspired by CuPL [58]. For instance, we might have \"a bat is a nocturnal mouselike mammal with forelimbs modified to form membranous wings and anatomical adaptations for echolocation by which they navigate\" or \"a bat is a club used for hitting a ball in various games\". Computing the nearest WordNet entity for each object gave us an estimated coverage of 20.8K entities.\n\n\nWord cloud of OBJAVERSE metadata tags.\n\nFigure 3 .\n3OBJAVERSE statistics. (a) All 18 high-level categories present in OBJAVERSE's metadata with their corresponding number of occurrences. The relative share of most popular categories are evenly split, with a small number of less frequently categories. (b) A sample of several thousand popular object tags found in OBJAVERSE log-scaled by their frequency. (c) A histogram of fine-grained OBJAVERSE-LVIS categories with representative members from several bins highlighted. (d) A histogram of OBJAVERSE tags with representative members from several bins highlighted (note y-axis log scale)\n\n\nof Bags generated with OBJAVERSE and ShapeNet. (b) Shoe and Fruit&Veg. generations. (c) Fruit&Veg. interpolation.\n\nFigure 6 .\n6(a) Example GET3D Bag object generations using OBJAVERSE and ShapeNet models for training. (b) Additional Shoe and Fruit&Veg generations from OBJAVERSE models. (c) models generated when interpolating between two, randomly sampled, latent encodings with our trained Fruit&Veg. model; what appears to be a pumpkin smoothly transforms into a mushroom.\n\nFigure 10 .\n10Open-Vocabulary ObjNav Model overview. The Ob-jectNav model (employing an RNN) uses the high-level architecture illustrated here, where it receives features from the visual and target object description encoders, besides previous hidden units and actions as input, and outputs the next action.\n\n\nof OBJAVERSE-LVIS categorization task.(b) Screenshot of relative diversity rating task.\n\nFigure 11 .\n11Data collection interfaces.\n\n\nTable 1. Comparison of our approach (GOL+3DCP) against SoTA Mask-RCNN ResNet-50 models on LVIS. We report results for APr, APc, and APf which measure AP for categories that are rare (appear in 1-10 images), common (appear in 11-100 images), and frequent (appear in >100 images), respectivelyFigure 8. An existing ProcTHOR scene (left) and a semantically similar ProcTHOR generatable scene with OBJAVERSE objects (right).Method \nAP \nAPr APc APf \n\nRFS [26] \n23.7 13.3 23.0 29.0 \nEQLv2 [74] \n25.5 17.7 24.3 30.2 \nLOCE [21] \n26.6 18.5 26.2 30.7 \nNorCal with RFS [52] 25.2 19.3 24.2 29.0 \nSeesaw [78] \n26.4 19.5 26.1 29.7 \nGOL [3] \n27.7 21.4 27.7 30.4 \nGOL + 3DCP \n28.3 21.8 28.3 31.1 \n\n\n\nTable 2 .\n2Evaluating 0-shot CLIP classification models on our rotational robustness benchmark. \u2206Top-1 denotes the difference between Top-1 Any Rotation and Top-1 Random Rotation. Models are strongly overfit to standard views of objects.\n\n\nGOL + 3DCP 28.9 21.8 28.7 32.2Method \nAP \nAPr APc APf \n\nGOL [3] \n27.5 19.8 27.2 31.2 \n\n\n\nTable 4. Training hyperparameters for Open-Vocabulary Ob-jectNav.Hyperparameter \nValue \n\nDiscount factor (\u03b3) \n0.99 \nGAE parameter (\u03bb) \n0.95 \nValue loss coefficient \n0.5 \nEntropy loss coefficient \n0.01 \nClip parameter ( ) \n0.1 \nRollout horizons \n32, 64, 128 \nRollout timesteps \n20 \nRollouts per minibatch \n1 \nLearning rate \n3 \u00b7 10 \u22124 \nOptimizer \nAdam [37] \nGradient clip norm \n0.5 \n\n\n\nTable 5 , respectively.\n5Testing. For testing, we sample 150 episodes for each of 30 target categories, which are a subset of the training target categories. The resulting 4,500 episodes are sampled from 151 procedural houses not seen during training. The Bible, Christmas tree, Rollerblade, alligator, ambulance, amplifier, arctic (type of shoe), armor, banner, barbell, barrel, barrow, baseball bat, basketball, bat (animal), bath mat, beachball, bear, bed, beetle, bench, beret, bicycle, binder, binoculars, bird, blackberry, bookcase, boot, bottle, bowling ball, bullhorn, bunk bed, bus (vehicle), butterfly, cab (taxi), cabinet, canoe, cape, car (automobile), card, cardigan, carnation, cart, cassette, cat, chair, chaise longue, chicken (animal), clothes hamper, coatrack, coffee table, cone, convertible (automobile), cornice, cow, cowboy hat, crab (animal), crate, crossbar, cube, cylinder, deck chair, deer, desk, dinghy, dirt bike, dog, dollhouse, doormat, dove, drawer, dresser, duckling, dumbbell, dumpster, easel, elephant, elk, fan, ferret, file cabinet, fireplace, fireplug, fishing rod, flag, flagpole, flamingo, flip-flop (sandal), flipper (footwear), foal, football (American), footstool, forklift, frog, futon, garbage, gargoyle, giant panda, giraffe, golf club, golfcart, gondola (boat), goose, gorilla, gravestone, grill, grizzly, grocery bag, guitar, handcart, hat, heater, hockey stick, hog, horse, horse carriage, jeep, kayak, keg, kennel, kitchen table, kitten, knee pad, ladder, ladybug, lamb (animal), lamp, lamppost, lawn mower, legging (clothing), lion, lizard, locker, log, loveseat, machine gun, mailbox (at home), manhole, mascot, mast, milk can, minivan, monkey, mop, motor, motor scooter, motor vehicle, motorcycle, mushroom, music stool, nut, ostrich, owl, pajamas, parasail (sports), parka, penguin, person, pet, pew (church bench), piano, pickup truck, pinecone, ping-pong ball, playpen, pole, polo shirt, pony, pool table, power shovel, propeller, pug-dog, pumpkin, rabbit, radiator, raincoat, ram (animal), rat, recliner, refrigerator, rhinoceros, rifle, road map, rocking chair, router (computer equipment), runner (carpet), saddle (on an animal), saddle blanket, saddlebag, sandal (type of shoe), scarecrow, scarf, sculpture, seabird, shark, shepherd dog, shield, shirt, shoe, sink, skateboard, ski parka, skullcap, snake, snowmobile, soccer ball, sock, sofa, sofa bed, solar array, sparkler (fireworks), speaker (stero equipment), spear, spider, sportswear, statue (sculpture), step stool, stepladder, stool, subwoofer, sugarcane (plant), suit (clothing), suitcase, sunhat, surfboard, sweat pants, sweater, swimsuit, table, tape measure, tarp, telephone pole, television camera, tennis ball, tennis racket, tights (clothing), toolbox, tote bag, towel, trailer truck, trampoline, trash can, tricycle, trousers, truck, trunk, turtle, tux, underdrawers, vacuum cleaner, vending machine, vest, wagon wheel, water ski, watering can, wet suit, wheel, window box (for plants), wok, wolf, and wooden leg.\n\nTable 5 .\n5Training target types for Open-Vocabulary ObjectNav.\n\nTable 6 .\n6Testing target types for Open-Vocabulary ObjectNav.\n\nShapeglot: Learning language for shape differentiation. Panos Achlioptas, Judy Fan, Robert Hawkins, Noah Goodman, Leonidas J Guibas, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionPanos Achlioptas, Judy Fan, Robert Hawkins, Noah Good- man, and Leonidas J Guibas. Shapeglot: Learning language for shape differentiation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8938- 8947, 2019. 3\n\nStrike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects. Michael A Alcorn, Qi Li, Zhitao Gong, Chengfei Wang, Long Mai, Wei-Shinn Ku, Anh Nguyen, IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019. Long Beach, CA, USAComputer Vision Foundation / IEEEMichael A. Alcorn, Qi Li, Zhitao Gong, Chengfei Wang, Long Mai, Wei-Shinn Ku, and Anh Nguyen. Strike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects. In IEEE Conference on Computer Vi- sion and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019, pages 4845-4854. Computer Vision Foundation / IEEE, 2019. 8\n\nLong-tailed instance segmentation using gumbel optimized loss. Jiankang Konstantinos Panagiotis Alexandridis, Anh Deng, Shan Nguyen, Luo, arXiv:2207.10936713arXiv preprintKonstantinos Panagiotis Alexandridis, Jiankang Deng, Anh Nguyen, and Shan Luo. Long-tailed instance segmen- tation using gumbel optimized loss. arXiv preprint arXiv:2207.10936, 2022. 6, 7, 13\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 33Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub- biah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakan- tan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Lan- guage models are few-shot learners. Advances in neural in- formation processing systems, 33:1877-1901, 2020. 1\n\nBerk Calli, Aaron Walsman, Arjun Singh, Siddhartha Srinivasa, Pieter Abbeel, Aaron M Dollar, arXiv:1502.03143Benchmarking in manipulation research: The ycb object and model set and benchmarking protocols. arXiv preprintBerk Calli, Aaron Walsman, Arjun Singh, Siddhartha Srini- vasa, Pieter Abbeel, and Aaron M Dollar. Benchmarking in manipulation research: The ycb object and model set and benchmarking protocols. arXiv preprint arXiv:1502.03143, 2015. 3\n\nLocobot: an open source low cost robot. Carnegie Mellon UniversityCarnegie Mellon University. Locobot: an open source low cost robot. http://www.locobot.org/. 13\n\nX Angel, Thomas Chang, Leonidas Funkhouser, Pat Guibas, Qixing Hanrahan, Zimo Huang, Silvio Li, Manolis Savarese, Shuran Savva, Hao Song, Su, arXiv:1512.03012An information-rich 3d model repository. 35arXiv preprintAngel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.03012, 2015. 3, 5\n\nText2shape: Generating shapes from natural language by learning joint embeddings. Kevin Chen, B Christopher, Manolis Choy, Savva, X Angel, Thomas Chang, Silvio Funkhouser, Savarese, Asian conference on computer vision. SpringerKevin Chen, Christopher B Choy, Manolis Savva, An- gel X Chang, Thomas Funkhouser, and Silvio Savarese. Text2shape: Generating shapes from natural language by learning joint embeddings. In Asian conference on computer vision, pages 100-116. Springer, 2018. 3\n\nXi Chen, Xiao Wang, Soravit Changpinyo, Piotr Piergiovanni, Daniel Padlewski, Sebastian Salz, Adam Goodman, Basil Grycner, Lucas Mustafa, Beyer, arXiv:2209.06794A jointlyscaled multilingual language-image model. arXiv preprintXi Chen, Xiao Wang, Soravit Changpinyo, AJ Piergiovanni, Piotr Padlewski, Daniel Salz, Sebastian Goodman, Adam Grycner, Basil Mustafa, Lucas Beyer, et al. Pali: A jointly- scaled multilingual language-image model. arXiv preprint arXiv:2209.06794, 2022. 2\n\nUnifying vision-and-language tasks via text generation. Jaemin Cho, Jie Lei, Hao Tan, Mohit Bansal, PMLR, 2021. 2International Conference on Machine Learning. Jaemin Cho, Jie Lei, Hao Tan, and Mohit Bansal. Unifying vision-and-language tasks via text generation. In Interna- tional Conference on Machine Learning, pages 1931-1942. PMLR, 2021. 2\n\nSungjoon Choi, Qian-Yi Zhou, Stephen Miller, Vladlen Koltun, arXiv:1602.02481A large dataset of object scans. arXiv preprintSungjoon Choi, Qian-Yi Zhou, Stephen Miller, and Vladlen Koltun. A large dataset of object scans. arXiv preprint arXiv:1602.02481, 2016. 3\n\nDataset and benchmarks for real-world 3d object understanding. Jasmine Collins, Shubham Goel, Kenan Deng, Achleshwar Luthra, Leon Xu, Erhan Gundogdu, Xi Zhang, Tomas F Yago Vicente, Thomas Dideriksen, Himanshu Arora, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022Jasmine Collins, Shubham Goel, Kenan Deng, Achlesh- war Luthra, Leon Xu, Erhan Gundogdu, Xi Zhang, Tomas F Yago Vicente, Thomas Dideriksen, Himanshu Arora, et al. Abo: Dataset and benchmarks for real-world 3d object un- derstanding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 21126- 21136, 2022. 3\n\nBlender -a 3d modelling and rendering package. Blender Online Community, Blender Online Community. Blender -a 3d modelling and rendering package. http://www.blender.org, 2018. 7\n\nIndoor semantic segmentation using depth information. Camille Couprie, Cl\u00e9ment Farabet, Laurent Najman, Yann Lecun, arXiv:1301.3572arXiv preprintCamille Couprie, Cl\u00e9ment Farabet, Laurent Najman, and Yann LeCun. Indoor semantic segmentation using depth in- formation. arXiv preprint arXiv:1301.3572, 2013. 3\n\nScannet: Richly-annotated 3d reconstructions of indoor scenes. Angela Dai, X Angel, Manolis Chang, Maciej Savva, Thomas Halber, Matthias Funkhouser, Nie\u00dfner, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionAngela Dai, Angel X Chang, Manolis Savva, Maciej Hal- ber, Thomas Funkhouser, and Matthias Nie\u00dfner. Scannet: Richly-annotated 3d reconstructions of indoor scenes. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5828-5839, 2017. 3\n\nMatt Deitke, Dhruv Batra, Yonatan Bisk, Tommaso Campari, X Angel, Devendra Chang, Changan Singh Chaplot, Claudia Chen, Kiana P\u00e9rez D&apos;arpino, Ali Ehsani, Farhadi, arXiv:2210.06849Retrospectives on the embodied ai workshop. arXiv preprintMatt Deitke, Dhruv Batra, Yonatan Bisk, Tommaso Campari, Angel X Chang, Devendra Singh Chaplot, Changan Chen, Claudia P\u00e9rez D'Arpino, Kiana Ehsani, Ali Farhadi, et al. Retrospectives on the embodied ai workshop. arXiv preprint arXiv:2210.06849, 2022. 7\n\nProcthor: Large-scale embodied ai using procedural generation. Matt Deitke, Eli Vanderbilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana Ehsani, Winson Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, Conference on Neural Information Processing Systems. 713Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs, Jordi Salvador, Kiana Ehsani, Winson Han, Eric Kolve, Ali Farhadi, Aniruddha Kembhavi, et al. Procthor: Large-scale embodied ai using procedural generation. Conference on Neural Information Processing Systems, 2022. 2, 7, 13\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. IeeeJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248-255. Ieee, 2009. 2\n\nGoogle scanned objects: A highquality dataset of 3d scanned household items. Laura Downs, Anthony Francis, Nate Koenig, Brandon Kinman, Ryan Hickman, Krista Reymann, B Thomas, Vincent Mchugh, Vanhoucke, arXiv:2204.119182022arXiv preprintLaura Downs, Anthony Francis, Nate Koenig, Brandon Kin- man, Ryan Hickman, Krista Reymann, Thomas B McHugh, and Vincent Vanhoucke. Google scanned objects: A high- quality dataset of 3d scanned household items. arXiv preprint arXiv:2204.11918, 2022. 3\n\nChristiane Fellbaum, Wordnet, Theory and applications of ontology: computer applications. Springer14Christiane Fellbaum. Wordnet. In Theory and applications of ontology: computer applications, pages 231-243. Springer, 2010. 14\n\nExploring classification equilibrium in long-tailed object detection. Chengjian Feng, Yujie Zhong, Weilin Huang, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionChengjian Feng, Yujie Zhong, and Weilin Huang. Exploring classification equilibrium in long-tailed object detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3417-3426, 2021. 6\n\n3d-future: 3d furniture shape with texture. Huan Fu, Rongfei Jia, Lin Gao, Mingming Gong, Binqiang Zhao, Steve Maybank, Dacheng Tao, International Journal of Computer Vision. 12912Huan Fu, Rongfei Jia, Lin Gao, Mingming Gong, Binqiang Zhao, Steve Maybank, and Dacheng Tao. 3d-future: 3d fur- niture shape with texture. International Journal of Computer Vision, 129(12):3313-3337, 2021. 3\n\nThreedworld: A platform for interactive multi-modal physical simulation. Chuang Gan, Jeremy Schwartz, Seth Alter, Martin Schrimpf, James Traer, Julian De Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi Sano, arXiv:2007.04954arXiv preprintChuang Gan, Jeremy Schwartz, Seth Alter, Martin Schrimpf, James Traer, Julian De Freitas, Jonas Kubilius, Abhishek Bhandwaldar, Nick Haber, Megumi Sano, et al. Threed- world: A platform for interactive multi-modal physical sim- ulation. arXiv preprint arXiv:2007.04954, 2020. 5\n\nGet3d: A generative model of high quality 3d textured shapes learned from images. Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue Yin, Daiqing Li, Or Litany, Zan Gojcic, Sanja Fidler, Advances In Neural Information Processing Systems. 25Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue Yin, Daiqing Li, Or Litany, Zan Gojcic, and Sanja Fidler. Get3d: A generative model of high quality 3d tex- tured shapes learned from images. In Advances In Neural Information Processing Systems, 2022. 2, 5\n\nSimple copy-paste is a strong data augmentation method for instance segmentation. Golnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, Tsung-Yi Lin, D Ekin, Cubuk, V Quoc, Barret Le, Zoph, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionGolnaz Ghiasi, Yin Cui, Aravind Srinivas, Rui Qian, Tsung- Yi Lin, Ekin D Cubuk, Quoc V Le, and Barret Zoph. Simple copy-paste is a strong data augmentation method for instance segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2918- 2928, 2021. 7\n\nLvis: A dataset for large vocabulary instance segmentation. Agrim Gupta, Piotr Dollar, Ross Girshick, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition36Agrim Gupta, Piotr Dollar, and Ross Girshick. Lvis: A dataset for large vocabulary instance segmentation. In Pro- ceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 5356-5364, 2019. 3, 6\n\nPiotr Doll\u00e1r, and Ross Girshick. Mask r-cnn. Kaiming He, Georgia Gkioxari, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision713Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Gir- shick. Mask r-cnn. In Proceedings of the IEEE international conference on computer vision, pages 2961-2969, 2017. 7, 13\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition713Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016. 7, 13\n\n. Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon, Nicholas Carlini, Rohan Taori, Achal Dave, Vaishaal Shankar, Hongseok Namkoong, John Miller, Hannaneh Hajishirzi, Ali Farhadi, Ludwig Schmidt, Open-CLIP. Gabriel Ilharco, Mitchell Wortsman, Ross Wightman, Cade Gordon, Nicholas Carlini, Rohan Taori, Achal Dave, Vaishaal Shankar, Hongseok Namkoong, John Miller, Han- naneh Hajishirzi, Ali Farhadi, and Ludwig Schmidt. Open- CLIP, July 2021. 2\n\nSpace-time correspondence as a contrastive random walk. Allan Jabri, Andrew Owens, Alexei Efros, Advances in neural information processing systems. 33Allan Jabri, Andrew Owens, and Alexei Efros. Space-time correspondence as a contrastive random walk. Advances in neural information processing systems, 33:19545-19560, 2020. 4\n\nZero-shot text-guided object generation with dream fields. Ajay Jain, Ben Mildenhall, Jonathan T Barron, Pieter Abbeel, Ben Poole, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022Ajay Jain, Ben Mildenhall, Jonathan T Barron, Pieter Abbeel, and Ben Poole. Zero-shot text-guided object genera- tion with dream fields. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition, pages 867-876, 2022. 3\n\nScaling up visual and vision-language representation learning with noisy text supervision. Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, Tom Duerig, PMLRInternational Conference on Machine Learning. Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig. Scaling up visual and vision-language representa- tion learning with noisy text supervision. In International Conference on Machine Learning, pages 4904-4916. PMLR, 2021. 2\n\nArmand Joulin, Edouard Grave, Piotr Bojanowski, arXiv:1612.03651Matthijs Douze, H\u00e9rve J\u00e9gou, and Tomas Mikolov. Fasttext.zip: Compressing text classification models. arXiv preprintArmand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, H\u00e9rve J\u00e9gou, and Tomas Mikolov. Fasttext.zip: Compressing text classification models. arXiv preprint arXiv:1612.03651, 2016. 8\n\nBag of tricks for efficient text classification. Armand Joulin, Edouard Grave, Piotr Bojanowski, Tomas Mikolov, arXiv:1607.01759arXiv preprintArmand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. Bag of tricks for efficient text classification. arXiv preprint arXiv:1607.01759, 2016. 8\n\nThe kit object models database: An object model database for object recognition, localization and manipulation in service robotics. Alexander Kasper, Zhixing Xue, R\u00fcdiger Dillmann, The International Journal of Robotics Research. 318Alexander Kasper, Zhixing Xue, and R\u00fcdiger Dillmann. The kit object models database: An object model database for object recognition, localization and manipulation in service robotics. The International Journal of Robotics Research, 31(8):927-934, 2012. 3\n\nSimple but effective: Clip embeddings for embodied ai. Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, Aniruddha Kembhavi, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 813Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, and Aniruddha Kembhavi. Simple but effective: Clip embed- dings for embodied ai. 2022 IEEE/CVF Conference on Com- puter Vision and Pattern Recognition (CVPR), pages 14809- 14818, 2022. 8, 13\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXivDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv, 2014. 13\n\nAbc: A big cad model dataset for geometric deep learning. Sebastian Koch, Albert Matveev, Zhongshi Jiang, Francis Williams, Alexey Artemov, Evgeny Burnaev, Marc Alexa, Denis Zorin, Daniele Panozzo, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionSebastian Koch, Albert Matveev, Zhongshi Jiang, Francis Williams, Alexey Artemov, Evgeny Burnaev, Marc Alexa, Denis Zorin, and Daniele Panozzo. Abc: A big cad model dataset for geometric deep learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9601-9611, 2019. 3\n\nAi2-thor: An interactive 3d environment for visual ai. Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli Vanderbilt, Luca Weihs, Alvaro Herrasti, Matt Deitke, Kiana Ehsani, Daniel Gordon, Yuke Zhu, Aniruddha Kembhavi, Abhinav Kumar Gupta, Ali Farhadi, 25arXiv e-printsEric Kolve, Roozbeh Mottaghi, Winson Han, Eli VanderBilt, Luca Weihs, Alvaro Herrasti, Matt Deitke, Kiana Ehsani, Daniel Gordon, Yuke Zhu, Aniruddha Kembhavi, Abhi- nav Kumar Gupta, and Ali Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv e-prints, pages arXiv- 1712, 2017. 2, 5\n\nThe open images dataset v4. Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Uijlings, Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander Kolesnikov, International Journal of Computer Vision. 1287Alina Kuznetsova, Hassan Rom, Neil Alldrin, Jasper Ui- jlings, Ivan Krasin, Jordi Pont-Tuset, Shahab Kamali, Stefan Popov, Matteo Malloci, Alexander Kolesnikov, et al. The open images dataset v4. International Journal of Computer Vision, 128(7):1956-1981, 2020. 2\n\nThe digital michelangelo project: 3d scanning of large statues. Marc Levoy, Kari Pulli, Brian Curless, Szymon Rusinkiewicz, David Koller, Lucas Pereira, Matt Ginzton, Sean Anderson, James Davis, Jeremy Ginsberg, Proceedings of the 27th annual conference on Computer graphics and interactive techniques. the 27th annual conference on Computer graphics and interactive techniquesMarc Levoy, Kari Pulli, Brian Curless, Szymon Rusinkiewicz, David Koller, Lucas Pereira, Matt Ginz- ton, Sean Anderson, James Davis, Jeremy Ginsberg, et al. The digital michelangelo project: 3d scanning of large statues. In Proceedings of the 27th annual conference on Computer graphics and interactive techniques, pages 131-144, 2000. 3\n\nigibson 2.0: Object-centric simulation for robot learning of everyday household tasks. Chengshu Li, Fei Xia, Roberto Mart\u00edn-Mart\u00edn, Michael Lingelbach, Sanjana Srivastava, Bokui Shen, Kent Vainio, Cem Gokmen, Gokul Dharan, Tanish Jain, arXiv:2108.0327257arXiv preprintChengshu Li, Fei Xia, Roberto Mart\u00edn-Mart\u00edn, Michael Lin- gelbach, Sanjana Srivastava, Bokui Shen, Kent Vainio, Cem Gokmen, Gokul Dharan, Tanish Jain, et al. igibson 2.0: Object-centric simulation for robot learning of everyday household tasks. arXiv preprint arXiv:2108.03272, 2021. 2, 5, 7\n\nParsing ikea objects: Fine pose estimation. J Joseph, Hamed Lim, Antonio Pirsiavash, Torralba, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer visionJoseph J Lim, Hamed Pirsiavash, and Antonio Torralba. Parsing ikea objects: Fine pose estimation. In Proceedings of the IEEE international conference on computer vision, pages 2992-2999, 2013. 3\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, European conference on computer vision. SpringerTsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740-755. Springer, 2014. 2\n\nVilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee, Advances in neural information processing systems. 32Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. Advances in neural information processing systems, 32, 2019. 1\n\nVolumetric hierarchical approximate convex decomposition. Khaled Mamou, A Lengyel, Peters, Game Engine Gems. AK Peters3Khaled Mamou, E Lengyel, and A Peters. Volumetric hierar- chical approximate convex decomposition. In Game Engine Gems 3, pages 141-158. AK Peters, 2016. 7\n\nText2mesh: Text-driven neural stylization for meshes. Oscar Michel, Roi Bar-On, Richard Liu, Sagie Benaim, Rana Hanocka, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022Oscar Michel, Roi Bar-On, Richard Liu, Sagie Benaim, and Rana Hanocka. Text2mesh: Text-driven neural stylization for meshes. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13492- 13502, 2022. 3\n\nWordnet: a lexical database for english. A George, Miller, Communications of the ACM. 3811George A Miller. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39-41, 1995. 5\n\nStructurenet: Hierarchical graph networks for 3d shape generation. Kaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy Mitra, Leonidas J Guibas, arXiv:1908.00575arXiv preprintKaichun Mo, Paul Guerrero, Li Yi, Hao Su, Peter Wonka, Niloy Mitra, and Leonidas J Guibas. Structurenet: Hierarchi- cal graph networks for 3d shape generation. arXiv preprint arXiv:1908.00575, 2019. 4\n\nPartnet: A largescale benchmark for fine-grained and hierarchical part-level 3d object understanding. Kaichun Mo, Shilin Zhu, X Angel, Li Chang, Subarna Yi, Leonidas J Tripathi, Hao Guibas, Su, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognitionKaichun Mo, Shilin Zhu, Angel X Chang, Li Yi, Subarna Tripathi, Leonidas J Guibas, and Hao Su. Partnet: A large- scale benchmark for fine-grained and hierarchical part-level 3d object understanding. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 909-918, 2019. 4\n\nEgad! an evolved grasping analysis dataset for diversity and reproducibility in robotic manipulation. D Morrison, P Corke, J Leitner, IEEE Robotics and Automation Letters. 53D. Morrison, P. Corke, and J. Leitner. Egad! an evolved grasping analysis dataset for diversity and reproducibility in robotic manipulation. IEEE Robotics and Automation Let- ters, 5(3):4368-4375, 2020. 3\n\nOn model calibration for long-tailed object detection and instance segmentation. Tai-Yu Pan, Cheng Zhang, Yandong Li, Hexiang Hu, Dong Xuan, Soravit Changpinyo, Boqing Gong, Wei-Lun Chao, Advances in Neural Information Processing Systems. 346Tai-Yu Pan, Cheng Zhang, Yandong Li, Hexiang Hu, Dong Xuan, Soravit Changpinyo, Boqing Gong, and Wei-Lun Chao. On model calibration for long-tailed object detection and instance segmentation. Advances in Neural Information Processing Systems, 34:2529-2542, 2021. 6\n\nPhotoshape: Photorealistic materials for large-scale shape collections. Keunhong Park, Konstantinos Rematas, Ali Farhadi, Steven M Seitz, arXiv:1809.09761arXiv preprintKeunhong Park, Konstantinos Rematas, Ali Farhadi, and Steven M Seitz. Photoshape: Photorealistic materi- als for large-scale shape collections. arXiv preprint arXiv:1809.09761, 2018. 3\n\nNerfies: Deformable neural radiance fields. Keunhong Park, Utkarsh Sinha, Jonathan T Barron, Sofien Bouaziz, Dan B Goldman, M Steven, Ricardo Seitz, Martin-Brualla, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionKeunhong Park, Utkarsh Sinha, Jonathan T Barron, Sofien Bouaziz, Dan B Goldman, Steven M Seitz, and Ricardo Martin-Brualla. Nerfies: Deformable neural radiance fields. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 5865-5874, 2021. 4\n\nGlove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). the 2014 conference on empirical methods in natural language processing (EMNLP)14Jeffrey Pennington, Richard Socher, and Christopher D Man- ning. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532-1543, 2014. 14\n\nPhysically based rendering: From theory to implementation. Matt Pharr, Jakob Wenzel, Greg Humphreys, Morgan KaufmannMatt Pharr, Wenzel Jakob, and Greg Humphreys. Physically based rendering: From theory to implementation. Morgan Kaufmann, 2016. 5\n\nBen Poole, Ajay Jain, Jonathan T Barron, Ben Mildenhall, arXiv:2209.14988Dreamfusion: Text-to-3d using 2d diffusion. 2022arXiv preprintBen Poole, Ajay Jain, Jonathan T Barron, and Ben Milden- hall. Dreamfusion: Text-to-3d using 2d diffusion. arXiv preprint arXiv:2209.14988, 2022. 3\n\nWhat does a platypus look like? generating customized prompts for zeroshot image classification. Sarah Pratt, Rosanne Liu, Ali Farhadi, arXiv:2209.033202022. 15arXiv preprintSarah Pratt, Rosanne Liu, and Ali Farhadi. What does a platypus look like? generating customized prompts for zero- shot image classification. arXiv preprint arXiv:2209.03320, 2022. 15\n\nD-nerf: Neural radiance fields for dynamic scenes. Albert Pumarola, Enric Corona, Gerard Pons-Moll, Francesc Moreno-Noguer, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionAlbert Pumarola, Enric Corona, Gerard Pons-Moll, and Francesc Moreno-Noguer. D-nerf: Neural radiance fields for dynamic scenes. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition, pages 10318-10327, 2021. 4\n\nLearning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, International Conference on Machine Learning. PMLR, 2021. 1, 2, 5, 8Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learn- ing transferable visual models from natural language super- vision. In International Conference on Machine Learning, pages 8748-8763. PMLR, 2021. 1, 2, 5, 8\n\nHierarchical text-conditional image generation with clip latents. Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen, arXiv:2204.061252022arXiv preprintAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image gen- eration with clip latents. arXiv preprint arXiv:2204.06125, 2022. 2\n\nZero-shot text-to-image generation. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever, PMLR, 2021. 2International Conference on Machine Learning. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International Confer- ence on Machine Learning, pages 8821-8831. PMLR, 2021. 2\n\nHabitat-web: Learning embodied object-search strategies from human demonstrations at scale. Ram Ramrakhya, Eric Undersander, Dhruv Batra, Abhishek Das, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition27Ram Ramrakhya, Eric Undersander, Dhruv Batra, and Ab- hishek Das. Habitat-web: Learning embodied object-search strategies from human demonstrations at scale. In Proceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5173-5183, 2022. 2, 7\n\nHigh-resolution image synthesis with latent diffusion models. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition1Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10684-10695, 2022. 1, 2\n\nImagenet large scale visual recognition challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, International journal of computer vision. 1153Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San- jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115(3):211-252, 2015. 2, 8\n\nLaion-5b: An open large-scale dataset for training next generation image-text models. Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, arXiv:2210.08402arXiv preprintChristoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Worts- man, et al. Laion-5b: An open large-scale dataset for training next generation image-text models. arXiv preprint arXiv:2210.08402, 2022. 1, 2, 8\n\nLaion-400m: Open dataset of clip-filtered 400 million image-text pairs. Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, Aran Komatsuzaki, arXiv:2111.02114arXiv preprintChristoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. Laion-400m: Open dataset of clip-filtered 400 million image-text pairs. arXiv preprint arXiv:2111.02114, 2021. 1, 2, 8\n\nConceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning. Piyush Sharma, Nan Ding, Sebastian Goodman, Radu Soricut, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsLong Papers1Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. Conceptual captions: A cleaned, hypernymed, im- age alt-text dataset for automatic image captioning. In Pro- ceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2556-2565, 2018. 1, 2\n\nBigbird: A large-scale 3d database of object instances. Arjun Singh, James Sha, Karthik S Narayan, Tudor Achim, P Abbeel, IEEE International Conference on Robotics and Automation (ICRA). Arjun Singh, James Sha, Karthik S. Narayan, Tudor Achim, and P. Abbeel. Bigbird: A large-scale 3d database of object instances. 2014 IEEE International Conference on Robotics and Automation (ICRA), pages 509-516, 2014. 3\n\nWit: Wikipedia-based image text dataset for multimodal multilingual machine learning. Krishna Srinivasan, Karthik Raman, Jiecao Chen, Michael Bendersky, Marc Najork, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval1Krishna Srinivasan, Karthik Raman, Jiecao Chen, Michael Bendersky, and Marc Najork. Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning. In Proceedings of the 44th International ACM SIGIR Confer- ence on Research and Development in Information Retrieval, pages 2443-2449, 2021. 1, 2\n\nPix3d: Dataset and methods for single-image 3d shape modeling. Xingyuan Sun, Jiajun Wu, Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, Tianfan Xue, Joshua B Tenenbaum, William T Freeman, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionXingyuan Sun, Jiajun Wu, Xiuming Zhang, Zhoutong Zhang, Chengkai Zhang, Tianfan Xue, Joshua B Tenenbaum, and William T Freeman. Pix3d: Dataset and methods for single-image 3d shape modeling. In Proceedings of the IEEE conference on computer vision and pattern recogni- tion, pages 2974-2983, 2018. 3\n\nHabitat 2.0: Training home assistants to rearrange their habitat. Andrew Szot, Alexander Clegg, Eric Undersander, Erik Wijmans, Yili Zhao, John Turner, Noah Maestre, Mustafa Mukadam, Devendra Singh Chaplot, Oleksandr Maksymets, Advances in Neural Information Processing Systems. 347Andrew Szot, Alexander Clegg, Eric Undersander, Erik Wi- jmans, Yili Zhao, John Turner, Noah Maestre, Mustafa Mukadam, Devendra Singh Chaplot, Oleksandr Maksymets, et al. Habitat 2.0: Training home assistants to rearrange their habitat. Advances in Neural Information Processing Systems, 34:251-266, 2021. 2, 5, 7\n\nLxmert: Learning crossmodality encoder representations from transformers. Hao Tan, Mohit Bansal, arXiv:1908.07490arXiv preprintHao Tan and Mohit Bansal. Lxmert: Learning cross- modality encoder representations from transformers. arXiv preprint arXiv:1908.07490, 2019. 2\n\nEqualization loss v2: A new gradient balance approach for long-tailed object detection. Jingru Tan, Xin Lu, Gang Zhang, Changqing Yin, Quanquan Li, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognitionJingru Tan, Xin Lu, Gang Zhang, Changqing Yin, and Quan- quan Li. Equalization loss v2: A new gradient balance ap- proach for long-tailed object detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1685-1694, 2021. 6\n\nBlock-nerf: Scalable large scene neural view synthesis. Matthew Tancik, Vincent Casser, Xinchen Yan, Sabeek Pradhan, Ben Mildenhall, P Pratul, Jonathan T Srinivasan, Henrik Barron, Kretzschmar, 2022. 4Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionMatthew Tancik, Vincent Casser, Xinchen Yan, Sabeek Prad- han, Ben Mildenhall, Pratul P Srinivasan, Jonathan T Barron, and Henrik Kretzschmar. Block-nerf: Scalable large scene neural view synthesis. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition, pages 8248-8258, 2022. 4\n\nHuman motion diffusion model. Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, H Amit, Daniel Bermano, Cohen-Or, arXiv:2209.149162022. 4arXiv preprintGuy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir, Amit H Bermano, and Daniel Cohen-Or. Human motion dif- fusion model. arXiv preprint arXiv:2209.14916, 2022. 4\n\nYfcc100m: The new data in multimedia research. Bart Thomee, A David, Gerald Shamma, Benjamin Friedland, Karl Elizalde, Douglas Ni, Damian Poland, Li-Jia Borth, Li, Communications of the ACM. 592Bart Thomee, David A Shamma, Gerald Friedland, Ben- jamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64-73, 2016. 2\n\nSeesaw loss for long-tailed instance segmentation. Jiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong, Kai Chen, Ziwei Liu, Chen Change Loy, Dahua Lin, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognitionJiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong, Kai Chen, Ziwei Liu, Chen Change Loy, and Dahua Lin. Seesaw loss for long-tailed instance segmentation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9695-9704, 2021. 6\n\nImage as a foreign language: Beit pretraining for all vision and visionlanguage tasks. Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Saksham Owais Khan Mohammed, Subhojit Singhal, Som, arXiv:2208.10442arXiv preprintWenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhil- iang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mo- hammed, Saksham Singhal, Subhojit Som, et al. Image as a foreign language: Beit pretraining for all vision and vision- language tasks. arXiv preprint arXiv:2208.10442, 2022. 2\n\nLuca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, Kuo-Hao Zeng, arXiv:2008.12760Roozbeh Mottaghi, and Aniruddha Kembhavi. Allenact: A framework for embodied ai research. arXiv preprintLuca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, Kuo- Hao Zeng, Roozbeh Mottaghi, and Aniruddha Kembhavi. Allenact: A framework for embodied ai research. arXiv preprint arXiv:2008.12760, 2020. 8\n\nDd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames. Erik Wijmans, Abhishek Kadian, Ari S Morcos, Stefan Lee, Irfan Essa, Devi Parikh, Manolis Savva, Dhruv Batra, ICLR, 2020. 813Erik Wijmans, Abhishek Kadian, Ari S. Morcos, Stefan Lee, Irfan Essa, Devi Parikh, Manolis Savva, and Dhruv Batra. Dd-ppo: Learning near-perfect pointgoal navigators from 2.5 billion frames. In ICLR, 2020. 8, 13\n\nDeepcad: A deep generative network for computer-aided design models. Rundi Wu, Chang Xiao, Changxi Zheng, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionRundi Wu, Chang Xiao, and Changxi Zheng. Deepcad: A deep generative network for computer-aided design models. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 6772-6782, 2021. 3\n\n3d shapenets: A deep representation for volumetric shapes. Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, Jianxiong Xiao, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionZhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Lin- guang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1912-1920, 2015. 3\n\nSapien: A simulated part-based interactive environment. Fanbo Xiang, Yuzhe Qin, Kaichun Mo, Yikuan Xia, Hao Zhu, Fangchen Liu, Minghua Liu, Hanxiao Jiang, Yifu Yuan, He Wang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionFanbo Xiang, Yuzhe Qin, Kaichun Mo, Yikuan Xia, Hao Zhu, Fangchen Liu, Minghua Liu, Hanxiao Jiang, Yifu Yuan, He Wang, et al. Sapien: A simulated part-based interactive environment. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11097- 11107, 2020. 4\n\nBungeenerf: Progressive neural radiance field for extreme multi-scale scene rendering. Yuanbo Xiangli, Linning Xu, Xingang Pan, Nanxuan Zhao, Anyi Rao, Christian Theobalt, Bo Dai, Dahua Lin, 2022. 4The European Conference on Computer Vision (ECCV). Yuanbo Xiangli, Linning Xu, Xingang Pan, Nanxuan Zhao, Anyi Rao, Christian Theobalt, Bo Dai, and Dahua Lin. Bungeenerf: Progressive neural radiance field for extreme multi-scale scene rendering. In The European Conference on Computer Vision (ECCV), 2022. 4\n\nAdagrasp: Learning an adaptive gripper-aware grasping policy. Zhenjia Xu, Beichun Qi, Shubham Agrawal, Shuran Song, 2021 IEEE International Conference on Robotics and Automation (ICRA). IEEEZhenjia Xu, Beichun Qi, Shubham Agrawal, and Shuran Song. Adagrasp: Learning an adaptive gripper-aware grasp- ing policy. In 2021 IEEE International Conference on Robotics and Automation (ICRA), pages 4620-4626. IEEE, 2021. 4\n\nMerlot reserve: Neural script knowledge through vision and language and sound. Rowan Zellers, Jiasen Lu, Ximing Lu, Youngjae Yu, Yanpeng Zhao, Mohammadreza Salehi, Aditya Kusupati, Jack Hessel, Ali Farhadi, Yejin Choi, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition14Rowan Zellers, Jiasen Lu, Ximing Lu, Youngjae Yu, Yan- peng Zhao, Mohammadreza Salehi, Aditya Kusupati, Jack Hessel, Ali Farhadi, and Yejin Choi. Merlot reserve: Neural script knowledge through vision and language and sound. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition, pages 16375-16387, 2022. 1, 4\n", "annotations": {"author": "[{\"end\":126,\"start\":49},{\"end\":173,\"start\":127},{\"end\":220,\"start\":174},{\"end\":263,\"start\":221},{\"end\":308,\"start\":264},{\"end\":355,\"start\":309},{\"end\":405,\"start\":356},{\"end\":450,\"start\":406},{\"end\":535,\"start\":451},{\"end\":582,\"start\":536}]", "publisher": null, "author_last_name": "[{\"end\":60,\"start\":54},{\"end\":141,\"start\":134},{\"end\":188,\"start\":180},{\"end\":231,\"start\":226},{\"end\":276,\"start\":270},{\"end\":323,\"start\":313},{\"end\":370,\"start\":363},{\"end\":418,\"start\":412},{\"end\":469,\"start\":461},{\"end\":547,\"start\":540}]", "author_first_name": "[{\"end\":53,\"start\":49},{\"end\":133,\"start\":127},{\"end\":179,\"start\":174},{\"end\":225,\"start\":221},{\"end\":269,\"start\":264},{\"end\":312,\"start\":309},{\"end\":362,\"start\":356},{\"end\":411,\"start\":406},{\"end\":460,\"start\":451},{\"end\":539,\"start\":536}]", "author_affiliation": "[{\"end\":91,\"start\":62},{\"end\":125,\"start\":93},{\"end\":172,\"start\":143},{\"end\":219,\"start\":190},{\"end\":262,\"start\":233},{\"end\":307,\"start\":278},{\"end\":354,\"start\":325},{\"end\":404,\"start\":372},{\"end\":449,\"start\":420},{\"end\":500,\"start\":471},{\"end\":534,\"start\":502},{\"end\":581,\"start\":549}]", "title": "[{\"end\":46,\"start\":1},{\"end\":628,\"start\":583}]", "venue": null, "abstract": "[{\"end\":2073,\"start\":630}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2223,\"start\":2220},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":2285,\"start\":2281},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2348,\"start\":2344},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":2425,\"start\":2421},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":2481,\"start\":2477},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":2496,\"start\":2492},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":2499,\"start\":2496},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":2528,\"start\":2524},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":2553,\"start\":2549},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3022,\"start\":3018},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3147,\"start\":3143},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3150,\"start\":3147},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":3153,\"start\":3150},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":3156,\"start\":3153},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4499,\"start\":4495},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5644,\"start\":5643},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6508,\"start\":6504},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6706,\"start\":6702},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7548,\"start\":7544},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":7551,\"start\":7548},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7568,\"start\":7564},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":7825,\"start\":7821},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7842,\"start\":7838},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":8109,\"start\":8105},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":8119,\"start\":8115},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":8135,\"start\":8131},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":8138,\"start\":8135},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8277,\"start\":8273},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8280,\"start\":8277},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":8283,\"start\":8280},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8314,\"start\":8310},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":8317,\"start\":8314},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":8320,\"start\":8317},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":8323,\"start\":8320},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8361,\"start\":8358},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8364,\"start\":8361},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":8367,\"start\":8364},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":8370,\"start\":8367},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8799,\"start\":8795},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8808,\"start\":8805},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":8822,\"start\":8818},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8833,\"start\":8829},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":8849,\"start\":8845},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":9000,\"start\":8996},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9178,\"start\":9174},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9195,\"start\":9191},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9205,\"start\":9201},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9224,\"start\":9220},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9242,\"start\":9239},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":9399,\"start\":9395},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":9416,\"start\":9412},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9430,\"start\":9426},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9660,\"start\":9656},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9663,\"start\":9660},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9666,\"start\":9663},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9669,\"start\":9666},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10055,\"start\":10052},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10202,\"start\":10199},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10465,\"start\":10461},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10468,\"start\":10465},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":10471,\"start\":10468},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12018,\"start\":12014},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":13833,\"start\":13829},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":13888,\"start\":13884},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":13891,\"start\":13888},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":13964,\"start\":13960},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":13967,\"start\":13964},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":14137,\"start\":14133},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":14140,\"start\":14137},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":14171,\"start\":14167},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":14198,\"start\":14194},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":14577,\"start\":14573},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":14580,\"start\":14577},{\"end\":15044,\"start\":15036},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":15535,\"start\":15531},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":15538,\"start\":15535},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":15541,\"start\":15538},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":15544,\"start\":15541},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":15903,\"start\":15899},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":16047,\"start\":16043},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":16411,\"start\":16407},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":17140,\"start\":17136},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17386,\"start\":17383},{\"end\":18897,\"start\":18889},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19936,\"start\":19932},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":20528,\"start\":20524},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21229,\"start\":21225},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":21232,\"start\":21229},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":21239,\"start\":21236},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21774,\"start\":21770},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":21957,\"start\":21953},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21960,\"start\":21957},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":21963,\"start\":21960},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22107,\"start\":22103},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":22110,\"start\":22107},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":22113,\"start\":22110},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":24208,\"start\":24204},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24415,\"start\":24411},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25047,\"start\":25043},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25050,\"start\":25047},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":25278,\"start\":25274},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":25404,\"start\":25400},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":25514,\"start\":25510},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":25626,\"start\":25622},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":25899,\"start\":25895},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26207,\"start\":26204},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28997,\"start\":28993},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29010,\"start\":29007},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":29041,\"start\":29037},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29306,\"start\":29303},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29379,\"start\":29376},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30067,\"start\":30064},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":30235,\"start\":30231},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":30238,\"start\":30235},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":30747,\"start\":30743},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":31185,\"start\":31181},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":31418,\"start\":31414},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":31635,\"start\":31631},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":32936,\"start\":32932},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33934,\"start\":33930},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":34443,\"start\":34439}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":34834,\"start\":34794},{\"attributes\":{\"id\":\"fig_1\"},\"end\":35433,\"start\":34835},{\"attributes\":{\"id\":\"fig_2\"},\"end\":35549,\"start\":35434},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35911,\"start\":35550},{\"attributes\":{\"id\":\"fig_4\"},\"end\":36220,\"start\":35912},{\"attributes\":{\"id\":\"fig_5\"},\"end\":36310,\"start\":36221},{\"attributes\":{\"id\":\"fig_6\"},\"end\":36353,\"start\":36311},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":37038,\"start\":36354},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":37277,\"start\":37039},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":37366,\"start\":37278},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":37751,\"start\":37367},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":40791,\"start\":37752},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":40856,\"start\":40792},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":40920,\"start\":40857}]", "paragraph": "[{\"end\":2714,\"start\":2089},{\"end\":4233,\"start\":2716},{\"end\":4726,\"start\":4235},{\"end\":5422,\"start\":4728},{\"end\":6318,\"start\":5424},{\"end\":7027,\"start\":6320},{\"end\":7284,\"start\":7029},{\"end\":8371,\"start\":7301},{\"end\":9881,\"start\":8373},{\"end\":10556,\"start\":9883},{\"end\":11105,\"start\":10570},{\"end\":11440,\"start\":11107},{\"end\":11965,\"start\":11442},{\"end\":12681,\"start\":11967},{\"end\":13968,\"start\":12683},{\"end\":14417,\"start\":13970},{\"end\":14747,\"start\":14419},{\"end\":15545,\"start\":14749},{\"end\":16181,\"start\":15547},{\"end\":16790,\"start\":16183},{\"end\":17024,\"start\":16807},{\"end\":19052,\"start\":17051},{\"end\":19202,\"start\":19054},{\"end\":19373,\"start\":19204},{\"end\":20384,\"start\":19409},{\"end\":21351,\"start\":20386},{\"end\":22351,\"start\":21381},{\"end\":23304,\"start\":22353},{\"end\":23908,\"start\":23306},{\"end\":24451,\"start\":23910},{\"end\":25806,\"start\":24453},{\"end\":26568,\"start\":25831},{\"end\":27379,\"start\":26570},{\"end\":27514,\"start\":27381},{\"end\":28196,\"start\":27516},{\"end\":28926,\"start\":28211},{\"end\":29307,\"start\":28965},{\"end\":29538,\"start\":29309},{\"end\":29978,\"start\":29561},{\"end\":30927,\"start\":30011},{\"end\":32088,\"start\":30929},{\"end\":32419,\"start\":32107},{\"end\":33640,\"start\":32421},{\"end\":34793,\"start\":33667}]", "formula": null, "table_ref": "[{\"end\":29666,\"start\":29659},{\"end\":29752,\"start\":29745},{\"end\":31697,\"start\":31690},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":31753,\"start\":31746}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2087,\"start\":2075},{\"attributes\":{\"n\":\"2.\"},\"end\":7299,\"start\":7287},{\"attributes\":{\"n\":\"3.\"},\"end\":10568,\"start\":10559},{\"attributes\":{\"n\":\"4.\"},\"end\":16805,\"start\":16793},{\"attributes\":{\"n\":\"4.1.\"},\"end\":17049,\"start\":17027},{\"attributes\":{\"n\":\"4.2.\"},\"end\":19407,\"start\":19376},{\"attributes\":{\"n\":\"4.3.\"},\"end\":21379,\"start\":21354},{\"attributes\":{\"n\":\"4.4.\"},\"end\":25829,\"start\":25809},{\"attributes\":{\"n\":\"5.\"},\"end\":28209,\"start\":28199},{\"end\":28963,\"start\":28929},{\"end\":29559,\"start\":29541},{\"end\":30009,\"start\":29981},{\"end\":32105,\"start\":32091},{\"end\":33665,\"start\":33643},{\"end\":34846,\"start\":34836},{\"end\":35561,\"start\":35551},{\"end\":35924,\"start\":35913},{\"end\":36323,\"start\":36312},{\"end\":37049,\"start\":37040},{\"end\":37776,\"start\":37753},{\"end\":40802,\"start\":40793},{\"end\":40867,\"start\":40858}]", "table": "[{\"end\":37038,\"start\":36776},{\"end\":37366,\"start\":37310},{\"end\":37751,\"start\":37434}]", "figure_caption": "[{\"end\":34834,\"start\":34796},{\"end\":35433,\"start\":34848},{\"end\":35549,\"start\":35436},{\"end\":35911,\"start\":35563},{\"end\":36220,\"start\":35927},{\"end\":36310,\"start\":36223},{\"end\":36353,\"start\":36326},{\"end\":36776,\"start\":36356},{\"end\":37277,\"start\":37051},{\"end\":37310,\"start\":37280},{\"end\":37434,\"start\":37369},{\"end\":40791,\"start\":37778},{\"end\":40856,\"start\":40804},{\"end\":40920,\"start\":40869}]", "figure_ref": "[{\"end\":3433,\"start\":3427},{\"end\":9298,\"start\":9292},{\"end\":11245,\"start\":11237},{\"end\":14311,\"start\":14303},{\"end\":14673,\"start\":14665},{\"end\":16057,\"start\":16049},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16548,\"start\":16540},{\"end\":17795,\"start\":17787},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18442,\"start\":18436},{\"end\":20538,\"start\":20530},{\"end\":24838,\"start\":24830},{\"end\":27014,\"start\":27008},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30458,\"start\":30451},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":33092,\"start\":33083},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":33453,\"start\":33444}]", "bib_author_first_name": "[{\"end\":40983,\"start\":40978},{\"end\":41000,\"start\":40996},{\"end\":41012,\"start\":41006},{\"end\":41026,\"start\":41022},{\"end\":41044,\"start\":41036},{\"end\":41046,\"start\":41045},{\"end\":41527,\"start\":41520},{\"end\":41529,\"start\":41528},{\"end\":41540,\"start\":41538},{\"end\":41551,\"start\":41545},{\"end\":41566,\"start\":41558},{\"end\":41577,\"start\":41573},{\"end\":41592,\"start\":41583},{\"end\":41600,\"start\":41597},{\"end\":42167,\"start\":42159},{\"end\":42209,\"start\":42206},{\"end\":42220,\"start\":42216},{\"end\":42502,\"start\":42499},{\"end\":42518,\"start\":42510},{\"end\":42529,\"start\":42525},{\"end\":42544,\"start\":42537},{\"end\":42559,\"start\":42554},{\"end\":42561,\"start\":42560},{\"end\":42578,\"start\":42570},{\"end\":42595,\"start\":42589},{\"end\":42615,\"start\":42609},{\"end\":42629,\"start\":42623},{\"end\":42644,\"start\":42638},{\"end\":42992,\"start\":42988},{\"end\":43005,\"start\":43000},{\"end\":43020,\"start\":43015},{\"end\":43038,\"start\":43028},{\"end\":43056,\"start\":43050},{\"end\":43072,\"start\":43065},{\"end\":43608,\"start\":43607},{\"end\":43622,\"start\":43616},{\"end\":43638,\"start\":43630},{\"end\":43654,\"start\":43651},{\"end\":43669,\"start\":43663},{\"end\":43684,\"start\":43680},{\"end\":43698,\"start\":43692},{\"end\":43710,\"start\":43703},{\"end\":43727,\"start\":43721},{\"end\":43738,\"start\":43735},{\"end\":44153,\"start\":44148},{\"end\":44161,\"start\":44160},{\"end\":44182,\"start\":44175},{\"end\":44197,\"start\":44196},{\"end\":44211,\"start\":44205},{\"end\":44225,\"start\":44219},{\"end\":44555,\"start\":44553},{\"end\":44566,\"start\":44562},{\"end\":44580,\"start\":44573},{\"end\":44598,\"start\":44593},{\"end\":44619,\"start\":44613},{\"end\":44640,\"start\":44631},{\"end\":44651,\"start\":44647},{\"end\":44666,\"start\":44661},{\"end\":44681,\"start\":44676},{\"end\":45097,\"start\":45091},{\"end\":45106,\"start\":45103},{\"end\":45115,\"start\":45112},{\"end\":45126,\"start\":45121},{\"end\":45389,\"start\":45381},{\"end\":45403,\"start\":45396},{\"end\":45417,\"start\":45410},{\"end\":45433,\"start\":45426},{\"end\":45715,\"start\":45708},{\"end\":45732,\"start\":45725},{\"end\":45744,\"start\":45739},{\"end\":45761,\"start\":45751},{\"end\":45774,\"start\":45770},{\"end\":45784,\"start\":45779},{\"end\":45797,\"start\":45795},{\"end\":45817,\"start\":45805},{\"end\":45833,\"start\":45827},{\"end\":45854,\"start\":45846},{\"end\":46603,\"start\":46596},{\"end\":46620,\"start\":46613},{\"end\":46637,\"start\":46630},{\"end\":46650,\"start\":46646},{\"end\":46919,\"start\":46913},{\"end\":46926,\"start\":46925},{\"end\":46941,\"start\":46934},{\"end\":46955,\"start\":46949},{\"end\":46969,\"start\":46963},{\"end\":46986,\"start\":46978},{\"end\":47424,\"start\":47420},{\"end\":47438,\"start\":47433},{\"end\":47453,\"start\":47446},{\"end\":47467,\"start\":47460},{\"end\":47478,\"start\":47477},{\"end\":47494,\"start\":47486},{\"end\":47509,\"start\":47502},{\"end\":47532,\"start\":47525},{\"end\":47544,\"start\":47539},{\"end\":47569,\"start\":47566},{\"end\":47982,\"start\":47978},{\"end\":47994,\"start\":47991},{\"end\":48013,\"start\":48007},{\"end\":48028,\"start\":48024},{\"end\":48041,\"start\":48036},{\"end\":48057,\"start\":48052},{\"end\":48072,\"start\":48066},{\"end\":48082,\"start\":48078},{\"end\":48093,\"start\":48090},{\"end\":48112,\"start\":48103},{\"end\":48519,\"start\":48516},{\"end\":48529,\"start\":48526},{\"end\":48543,\"start\":48536},{\"end\":48558,\"start\":48552},{\"end\":48566,\"start\":48563},{\"end\":48573,\"start\":48571},{\"end\":48956,\"start\":48951},{\"end\":48971,\"start\":48964},{\"end\":48985,\"start\":48981},{\"end\":49001,\"start\":48994},{\"end\":49014,\"start\":49010},{\"end\":49030,\"start\":49024},{\"end\":49041,\"start\":49040},{\"end\":49057,\"start\":49050},{\"end\":49373,\"start\":49363},{\"end\":49670,\"start\":49661},{\"end\":49682,\"start\":49677},{\"end\":49696,\"start\":49690},{\"end\":50100,\"start\":50096},{\"end\":50112,\"start\":50105},{\"end\":50121,\"start\":50118},{\"end\":50135,\"start\":50127},{\"end\":50150,\"start\":50142},{\"end\":50162,\"start\":50157},{\"end\":50179,\"start\":50172},{\"end\":50520,\"start\":50514},{\"end\":50532,\"start\":50526},{\"end\":50547,\"start\":50543},{\"end\":50561,\"start\":50555},{\"end\":50577,\"start\":50572},{\"end\":50591,\"start\":50585},{\"end\":50594,\"start\":50592},{\"end\":50609,\"start\":50604},{\"end\":50628,\"start\":50620},{\"end\":50646,\"start\":50642},{\"end\":50660,\"start\":50654},{\"end\":51061,\"start\":51058},{\"end\":51076,\"start\":51067},{\"end\":51087,\"start\":51083},{\"end\":51102,\"start\":51094},{\"end\":51116,\"start\":51109},{\"end\":51129,\"start\":51122},{\"end\":51136,\"start\":51134},{\"end\":51148,\"start\":51145},{\"end\":51162,\"start\":51157},{\"end\":51579,\"start\":51573},{\"end\":51591,\"start\":51588},{\"end\":51604,\"start\":51597},{\"end\":51618,\"start\":51615},{\"end\":51633,\"start\":51625},{\"end\":51640,\"start\":51639},{\"end\":51655,\"start\":51654},{\"end\":51668,\"start\":51662},{\"end\":52197,\"start\":52192},{\"end\":52210,\"start\":52205},{\"end\":52223,\"start\":52219},{\"end\":52660,\"start\":52653},{\"end\":52672,\"start\":52665},{\"end\":53039,\"start\":53032},{\"end\":53051,\"start\":53044},{\"end\":53067,\"start\":53059},{\"end\":53077,\"start\":53073},{\"end\":53449,\"start\":53442},{\"end\":53467,\"start\":53459},{\"end\":53482,\"start\":53478},{\"end\":53497,\"start\":53493},{\"end\":53514,\"start\":53506},{\"end\":53529,\"start\":53524},{\"end\":53542,\"start\":53537},{\"end\":53557,\"start\":53549},{\"end\":53575,\"start\":53567},{\"end\":53590,\"start\":53586},{\"end\":53607,\"start\":53599},{\"end\":53623,\"start\":53620},{\"end\":53639,\"start\":53633},{\"end\":53960,\"start\":53955},{\"end\":53974,\"start\":53968},{\"end\":53988,\"start\":53982},{\"end\":54289,\"start\":54285},{\"end\":54299,\"start\":54296},{\"end\":54320,\"start\":54312},{\"end\":54322,\"start\":54321},{\"end\":54337,\"start\":54331},{\"end\":54349,\"start\":54346},{\"end\":54854,\"start\":54850},{\"end\":54866,\"start\":54860},{\"end\":54875,\"start\":54873},{\"end\":54888,\"start\":54881},{\"end\":54901,\"start\":54895},{\"end\":54914,\"start\":54910},{\"end\":54925,\"start\":54921},{\"end\":54939,\"start\":54930},{\"end\":54950,\"start\":54946},{\"end\":54958,\"start\":54955},{\"end\":55318,\"start\":55312},{\"end\":55334,\"start\":55327},{\"end\":55347,\"start\":55342},{\"end\":55739,\"start\":55733},{\"end\":55755,\"start\":55748},{\"end\":55768,\"start\":55763},{\"end\":55786,\"start\":55781},{\"end\":56125,\"start\":56116},{\"end\":56141,\"start\":56134},{\"end\":56154,\"start\":56147},{\"end\":56534,\"start\":56528},{\"end\":56551,\"start\":56547},{\"end\":56566,\"start\":56559},{\"end\":56586,\"start\":56577},{\"end\":56957,\"start\":56956},{\"end\":56973,\"start\":56968},{\"end\":57151,\"start\":57142},{\"end\":57164,\"start\":57158},{\"end\":57182,\"start\":57174},{\"end\":57197,\"start\":57190},{\"end\":57214,\"start\":57208},{\"end\":57230,\"start\":57224},{\"end\":57244,\"start\":57240},{\"end\":57257,\"start\":57252},{\"end\":57272,\"start\":57265},{\"end\":57804,\"start\":57800},{\"end\":57819,\"start\":57812},{\"end\":57836,\"start\":57830},{\"end\":57845,\"start\":57842},{\"end\":57862,\"start\":57858},{\"end\":57876,\"start\":57870},{\"end\":57891,\"start\":57887},{\"end\":57905,\"start\":57900},{\"end\":57920,\"start\":57914},{\"end\":57933,\"start\":57929},{\"end\":57948,\"start\":57939},{\"end\":57966,\"start\":57959},{\"end\":57983,\"start\":57980},{\"end\":58343,\"start\":58338},{\"end\":58362,\"start\":58356},{\"end\":58372,\"start\":58368},{\"end\":58388,\"start\":58382},{\"end\":58403,\"start\":58399},{\"end\":58417,\"start\":58412},{\"end\":58436,\"start\":58430},{\"end\":58451,\"start\":58445},{\"end\":58465,\"start\":58459},{\"end\":58484,\"start\":58475},{\"end\":58876,\"start\":58872},{\"end\":58888,\"start\":58884},{\"end\":58901,\"start\":58896},{\"end\":58917,\"start\":58911},{\"end\":58937,\"start\":58932},{\"end\":58951,\"start\":58946},{\"end\":58965,\"start\":58961},{\"end\":58979,\"start\":58975},{\"end\":58995,\"start\":58990},{\"end\":59009,\"start\":59003},{\"end\":59619,\"start\":59611},{\"end\":59627,\"start\":59624},{\"end\":59640,\"start\":59633},{\"end\":59663,\"start\":59656},{\"end\":59683,\"start\":59676},{\"end\":59701,\"start\":59696},{\"end\":59712,\"start\":59708},{\"end\":59724,\"start\":59721},{\"end\":59738,\"start\":59733},{\"end\":59753,\"start\":59747},{\"end\":60130,\"start\":60129},{\"end\":60144,\"start\":60139},{\"end\":60157,\"start\":60150},{\"end\":60548,\"start\":60540},{\"end\":60561,\"start\":60554},{\"end\":60574,\"start\":60569},{\"end\":60590,\"start\":60585},{\"end\":60603,\"start\":60597},{\"end\":60616,\"start\":60612},{\"end\":60631,\"start\":60626},{\"end\":60650,\"start\":60640},{\"end\":61056,\"start\":61050},{\"end\":61066,\"start\":61061},{\"end\":61078,\"start\":61074},{\"end\":61093,\"start\":61087},{\"end\":61431,\"start\":61425},{\"end\":61440,\"start\":61439},{\"end\":61702,\"start\":61697},{\"end\":61714,\"start\":61711},{\"end\":61730,\"start\":61723},{\"end\":61741,\"start\":61736},{\"end\":61754,\"start\":61750},{\"end\":62199,\"start\":62198},{\"end\":62429,\"start\":62422},{\"end\":62438,\"start\":62434},{\"end\":62451,\"start\":62449},{\"end\":62459,\"start\":62456},{\"end\":62469,\"start\":62464},{\"end\":62482,\"start\":62477},{\"end\":62498,\"start\":62490},{\"end\":62500,\"start\":62499},{\"end\":62850,\"start\":62843},{\"end\":62861,\"start\":62855},{\"end\":62868,\"start\":62867},{\"end\":62878,\"start\":62876},{\"end\":62893,\"start\":62886},{\"end\":62906,\"start\":62898},{\"end\":62908,\"start\":62907},{\"end\":62922,\"start\":62919},{\"end\":63496,\"start\":63495},{\"end\":63508,\"start\":63507},{\"end\":63517,\"start\":63516},{\"end\":63860,\"start\":63854},{\"end\":63871,\"start\":63866},{\"end\":63886,\"start\":63879},{\"end\":63898,\"start\":63891},{\"end\":63907,\"start\":63903},{\"end\":63921,\"start\":63914},{\"end\":63940,\"start\":63934},{\"end\":63954,\"start\":63947},{\"end\":64361,\"start\":64353},{\"end\":64380,\"start\":64368},{\"end\":64393,\"start\":64390},{\"end\":64411,\"start\":64403},{\"end\":64687,\"start\":64679},{\"end\":64701,\"start\":64694},{\"end\":64717,\"start\":64709},{\"end\":64719,\"start\":64718},{\"end\":64734,\"start\":64728},{\"end\":64747,\"start\":64744},{\"end\":64749,\"start\":64748},{\"end\":64760,\"start\":64759},{\"end\":64776,\"start\":64769},{\"end\":65253,\"start\":65246},{\"end\":65273,\"start\":65266},{\"end\":65295,\"start\":65282},{\"end\":65783,\"start\":65779},{\"end\":65796,\"start\":65791},{\"end\":65809,\"start\":65805},{\"end\":65970,\"start\":65967},{\"end\":65982,\"start\":65978},{\"end\":65997,\"start\":65989},{\"end\":65999,\"start\":65998},{\"end\":66011,\"start\":66008},{\"end\":66353,\"start\":66348},{\"end\":66368,\"start\":66361},{\"end\":66377,\"start\":66374},{\"end\":66667,\"start\":66661},{\"end\":66683,\"start\":66678},{\"end\":66698,\"start\":66692},{\"end\":66718,\"start\":66710},{\"end\":67202,\"start\":67198},{\"end\":67216,\"start\":67212},{\"end\":67221,\"start\":67217},{\"end\":67232,\"start\":67227},{\"end\":67248,\"start\":67242},{\"end\":67264,\"start\":67257},{\"end\":67278,\"start\":67270},{\"end\":67294,\"start\":67288},{\"end\":67309,\"start\":67303},{\"end\":67324,\"start\":67318},{\"end\":67338,\"start\":67334},{\"end\":67806,\"start\":67800},{\"end\":67823,\"start\":67815},{\"end\":67838,\"start\":67834},{\"end\":67852,\"start\":67847},{\"end\":67862,\"start\":67858},{\"end\":68128,\"start\":68122},{\"end\":68144,\"start\":68137},{\"end\":68160,\"start\":68153},{\"end\":68171,\"start\":68166},{\"end\":68185,\"start\":68178},{\"end\":68196,\"start\":68192},{\"end\":68210,\"start\":68206},{\"end\":68221,\"start\":68217},{\"end\":68621,\"start\":68618},{\"end\":68637,\"start\":68633},{\"end\":68656,\"start\":68651},{\"end\":68672,\"start\":68664},{\"end\":69171,\"start\":69166},{\"end\":69188,\"start\":69181},{\"end\":69207,\"start\":69200},{\"end\":69223,\"start\":69216},{\"end\":69236,\"start\":69231},{\"end\":69710,\"start\":69706},{\"end\":69727,\"start\":69724},{\"end\":69737,\"start\":69734},{\"end\":69750,\"start\":69742},{\"end\":69766,\"start\":69759},{\"end\":69781,\"start\":69777},{\"end\":69793,\"start\":69786},{\"end\":69807,\"start\":69801},{\"end\":69824,\"start\":69818},{\"end\":69840,\"start\":69833},{\"end\":70269,\"start\":70260},{\"end\":70287,\"start\":70281},{\"end\":70305,\"start\":70298},{\"end\":70317,\"start\":70313},{\"end\":70330,\"start\":70326},{\"end\":70346,\"start\":70341},{\"end\":70359,\"start\":70355},{\"end\":70375,\"start\":70369},{\"end\":70390,\"start\":70383},{\"end\":70407,\"start\":70399},{\"end\":70830,\"start\":70821},{\"end\":70849,\"start\":70842},{\"end\":70863,\"start\":70857},{\"end\":70880,\"start\":70874},{\"end\":70901,\"start\":70894},{\"end\":70916,\"start\":70910},{\"end\":70928,\"start\":70924},{\"end\":70943,\"start\":70938},{\"end\":70956,\"start\":70952},{\"end\":71378,\"start\":71372},{\"end\":71390,\"start\":71387},{\"end\":71406,\"start\":71397},{\"end\":71420,\"start\":71416},{\"end\":71974,\"start\":71969},{\"end\":71987,\"start\":71982},{\"end\":72000,\"start\":71993},{\"end\":72002,\"start\":72001},{\"end\":72017,\"start\":72012},{\"end\":72026,\"start\":72025},{\"end\":72415,\"start\":72408},{\"end\":72435,\"start\":72428},{\"end\":72449,\"start\":72443},{\"end\":72463,\"start\":72456},{\"end\":72479,\"start\":72475},{\"end\":73086,\"start\":73078},{\"end\":73098,\"start\":73092},{\"end\":73110,\"start\":73103},{\"end\":73126,\"start\":73118},{\"end\":73142,\"start\":73134},{\"end\":73157,\"start\":73150},{\"end\":73169,\"start\":73163},{\"end\":73171,\"start\":73170},{\"end\":73192,\"start\":73183},{\"end\":73716,\"start\":73710},{\"end\":73732,\"start\":73723},{\"end\":73744,\"start\":73740},{\"end\":73762,\"start\":73758},{\"end\":73776,\"start\":73772},{\"end\":73787,\"start\":73783},{\"end\":73800,\"start\":73796},{\"end\":73817,\"start\":73810},{\"end\":73835,\"start\":73827},{\"end\":73860,\"start\":73851},{\"end\":74318,\"start\":74315},{\"end\":74329,\"start\":74324},{\"end\":74606,\"start\":74600},{\"end\":74615,\"start\":74612},{\"end\":74624,\"start\":74620},{\"end\":74641,\"start\":74632},{\"end\":74655,\"start\":74647},{\"end\":75140,\"start\":75133},{\"end\":75156,\"start\":75149},{\"end\":75172,\"start\":75165},{\"end\":75184,\"start\":75178},{\"end\":75197,\"start\":75194},{\"end\":75211,\"start\":75210},{\"end\":75228,\"start\":75220},{\"end\":75230,\"start\":75229},{\"end\":75249,\"start\":75243},{\"end\":75773,\"start\":75770},{\"end\":75786,\"start\":75781},{\"end\":75798,\"start\":75793},{\"end\":75814,\"start\":75807},{\"end\":75824,\"start\":75823},{\"end\":75837,\"start\":75831},{\"end\":76109,\"start\":76105},{\"end\":76119,\"start\":76118},{\"end\":76133,\"start\":76127},{\"end\":76150,\"start\":76142},{\"end\":76166,\"start\":76162},{\"end\":76184,\"start\":76177},{\"end\":76195,\"start\":76189},{\"end\":76210,\"start\":76204},{\"end\":76526,\"start\":76521},{\"end\":76539,\"start\":76533},{\"end\":76553,\"start\":76547},{\"end\":76566,\"start\":76560},{\"end\":76581,\"start\":76572},{\"end\":76591,\"start\":76588},{\"end\":76601,\"start\":76598},{\"end\":76613,\"start\":76608},{\"end\":76623,\"start\":76619},{\"end\":76630,\"start\":76624},{\"end\":76641,\"start\":76636},{\"end\":77182,\"start\":77176},{\"end\":77195,\"start\":77189},{\"end\":77203,\"start\":77201},{\"end\":77215,\"start\":77210},{\"end\":77232,\"start\":77224},{\"end\":77244,\"start\":77239},{\"end\":77255,\"start\":77250},{\"end\":77273,\"start\":77266},{\"end\":77303,\"start\":77295},{\"end\":77636,\"start\":77632},{\"end\":77649,\"start\":77644},{\"end\":77666,\"start\":77660},{\"end\":77679,\"start\":77674},{\"end\":77693,\"start\":77686},{\"end\":78101,\"start\":78097},{\"end\":78119,\"start\":78111},{\"end\":78131,\"start\":78128},{\"end\":78133,\"start\":78132},{\"end\":78148,\"start\":78142},{\"end\":78159,\"start\":78154},{\"end\":78170,\"start\":78166},{\"end\":78186,\"start\":78179},{\"end\":78199,\"start\":78194},{\"end\":78509,\"start\":78504},{\"end\":78519,\"start\":78514},{\"end\":78533,\"start\":78526},{\"end\":78948,\"start\":78941},{\"end\":78959,\"start\":78953},{\"end\":78972,\"start\":78966},{\"end\":78987,\"start\":78981},{\"end\":79000,\"start\":78992},{\"end\":79014,\"start\":79008},{\"end\":79030,\"start\":79021},{\"end\":79508,\"start\":79503},{\"end\":79521,\"start\":79516},{\"end\":79534,\"start\":79527},{\"end\":79545,\"start\":79539},{\"end\":79554,\"start\":79551},{\"end\":79568,\"start\":79560},{\"end\":79581,\"start\":79574},{\"end\":79594,\"start\":79587},{\"end\":79606,\"start\":79602},{\"end\":79615,\"start\":79613},{\"end\":80161,\"start\":80155},{\"end\":80178,\"start\":80171},{\"end\":80190,\"start\":80183},{\"end\":80203,\"start\":80196},{\"end\":80214,\"start\":80210},{\"end\":80229,\"start\":80220},{\"end\":80242,\"start\":80240},{\"end\":80253,\"start\":80248},{\"end\":80644,\"start\":80637},{\"end\":80656,\"start\":80649},{\"end\":80668,\"start\":80661},{\"end\":80684,\"start\":80678},{\"end\":81076,\"start\":81071},{\"end\":81092,\"start\":81086},{\"end\":81103,\"start\":81097},{\"end\":81116,\"start\":81108},{\"end\":81128,\"start\":81121},{\"end\":81147,\"start\":81135},{\"end\":81162,\"start\":81156},{\"end\":81177,\"start\":81173},{\"end\":81189,\"start\":81186},{\"end\":81204,\"start\":81199}]", "bib_author_last_name": "[{\"end\":40994,\"start\":40984},{\"end\":41004,\"start\":41001},{\"end\":41020,\"start\":41013},{\"end\":41034,\"start\":41027},{\"end\":41053,\"start\":41047},{\"end\":41536,\"start\":41530},{\"end\":41543,\"start\":41541},{\"end\":41556,\"start\":41552},{\"end\":41571,\"start\":41567},{\"end\":41581,\"start\":41578},{\"end\":41595,\"start\":41593},{\"end\":41607,\"start\":41601},{\"end\":42204,\"start\":42168},{\"end\":42214,\"start\":42210},{\"end\":42227,\"start\":42221},{\"end\":42232,\"start\":42229},{\"end\":42508,\"start\":42503},{\"end\":42523,\"start\":42519},{\"end\":42535,\"start\":42530},{\"end\":42552,\"start\":42545},{\"end\":42568,\"start\":42562},{\"end\":42587,\"start\":42579},{\"end\":42607,\"start\":42596},{\"end\":42621,\"start\":42616},{\"end\":42636,\"start\":42630},{\"end\":42651,\"start\":42645},{\"end\":42998,\"start\":42993},{\"end\":43013,\"start\":43006},{\"end\":43026,\"start\":43021},{\"end\":43048,\"start\":43039},{\"end\":43063,\"start\":43057},{\"end\":43079,\"start\":43073},{\"end\":43614,\"start\":43609},{\"end\":43628,\"start\":43623},{\"end\":43649,\"start\":43639},{\"end\":43661,\"start\":43655},{\"end\":43678,\"start\":43670},{\"end\":43690,\"start\":43685},{\"end\":43701,\"start\":43699},{\"end\":43719,\"start\":43711},{\"end\":43733,\"start\":43728},{\"end\":43743,\"start\":43739},{\"end\":43747,\"start\":43745},{\"end\":44158,\"start\":44154},{\"end\":44173,\"start\":44162},{\"end\":44187,\"start\":44183},{\"end\":44194,\"start\":44189},{\"end\":44203,\"start\":44198},{\"end\":44217,\"start\":44212},{\"end\":44236,\"start\":44226},{\"end\":44246,\"start\":44238},{\"end\":44560,\"start\":44556},{\"end\":44571,\"start\":44567},{\"end\":44591,\"start\":44581},{\"end\":44611,\"start\":44599},{\"end\":44629,\"start\":44620},{\"end\":44645,\"start\":44641},{\"end\":44659,\"start\":44652},{\"end\":44674,\"start\":44667},{\"end\":44689,\"start\":44682},{\"end\":44696,\"start\":44691},{\"end\":45101,\"start\":45098},{\"end\":45110,\"start\":45107},{\"end\":45119,\"start\":45116},{\"end\":45133,\"start\":45127},{\"end\":45394,\"start\":45390},{\"end\":45408,\"start\":45404},{\"end\":45424,\"start\":45418},{\"end\":45440,\"start\":45434},{\"end\":45723,\"start\":45716},{\"end\":45737,\"start\":45733},{\"end\":45749,\"start\":45745},{\"end\":45768,\"start\":45762},{\"end\":45777,\"start\":45775},{\"end\":45793,\"start\":45785},{\"end\":45803,\"start\":45798},{\"end\":45825,\"start\":45818},{\"end\":45844,\"start\":45834},{\"end\":45860,\"start\":45855},{\"end\":46434,\"start\":46410},{\"end\":46611,\"start\":46604},{\"end\":46628,\"start\":46621},{\"end\":46644,\"start\":46638},{\"end\":46656,\"start\":46651},{\"end\":46923,\"start\":46920},{\"end\":46932,\"start\":46927},{\"end\":46947,\"start\":46942},{\"end\":46961,\"start\":46956},{\"end\":46976,\"start\":46970},{\"end\":46997,\"start\":46987},{\"end\":47006,\"start\":46999},{\"end\":47431,\"start\":47425},{\"end\":47444,\"start\":47439},{\"end\":47458,\"start\":47454},{\"end\":47475,\"start\":47468},{\"end\":47484,\"start\":47479},{\"end\":47500,\"start\":47495},{\"end\":47523,\"start\":47510},{\"end\":47537,\"start\":47533},{\"end\":47564,\"start\":47545},{\"end\":47576,\"start\":47570},{\"end\":47585,\"start\":47578},{\"end\":47989,\"start\":47983},{\"end\":48005,\"start\":47995},{\"end\":48022,\"start\":48014},{\"end\":48034,\"start\":48029},{\"end\":48050,\"start\":48042},{\"end\":48064,\"start\":48058},{\"end\":48076,\"start\":48073},{\"end\":48088,\"start\":48083},{\"end\":48101,\"start\":48094},{\"end\":48121,\"start\":48113},{\"end\":48524,\"start\":48520},{\"end\":48534,\"start\":48530},{\"end\":48550,\"start\":48544},{\"end\":48561,\"start\":48559},{\"end\":48569,\"start\":48567},{\"end\":48581,\"start\":48574},{\"end\":48962,\"start\":48957},{\"end\":48979,\"start\":48972},{\"end\":48992,\"start\":48986},{\"end\":49008,\"start\":49002},{\"end\":49022,\"start\":49015},{\"end\":49038,\"start\":49031},{\"end\":49048,\"start\":49042},{\"end\":49064,\"start\":49058},{\"end\":49075,\"start\":49066},{\"end\":49382,\"start\":49374},{\"end\":49391,\"start\":49384},{\"end\":49675,\"start\":49671},{\"end\":49688,\"start\":49683},{\"end\":49702,\"start\":49697},{\"end\":50103,\"start\":50101},{\"end\":50116,\"start\":50113},{\"end\":50125,\"start\":50122},{\"end\":50140,\"start\":50136},{\"end\":50155,\"start\":50151},{\"end\":50170,\"start\":50163},{\"end\":50183,\"start\":50180},{\"end\":50524,\"start\":50521},{\"end\":50541,\"start\":50533},{\"end\":50553,\"start\":50548},{\"end\":50570,\"start\":50562},{\"end\":50583,\"start\":50578},{\"end\":50602,\"start\":50595},{\"end\":50618,\"start\":50610},{\"end\":50640,\"start\":50629},{\"end\":50652,\"start\":50647},{\"end\":50665,\"start\":50661},{\"end\":51065,\"start\":51062},{\"end\":51081,\"start\":51077},{\"end\":51092,\"start\":51088},{\"end\":51107,\"start\":51103},{\"end\":51120,\"start\":51117},{\"end\":51132,\"start\":51130},{\"end\":51143,\"start\":51137},{\"end\":51155,\"start\":51149},{\"end\":51169,\"start\":51163},{\"end\":51586,\"start\":51580},{\"end\":51595,\"start\":51592},{\"end\":51613,\"start\":51605},{\"end\":51623,\"start\":51619},{\"end\":51637,\"start\":51634},{\"end\":51645,\"start\":51641},{\"end\":51652,\"start\":51647},{\"end\":51660,\"start\":51656},{\"end\":51671,\"start\":51669},{\"end\":51677,\"start\":51673},{\"end\":52203,\"start\":52198},{\"end\":52217,\"start\":52211},{\"end\":52232,\"start\":52224},{\"end\":52663,\"start\":52661},{\"end\":52681,\"start\":52673},{\"end\":53042,\"start\":53040},{\"end\":53057,\"start\":53052},{\"end\":53071,\"start\":53068},{\"end\":53081,\"start\":53078},{\"end\":53457,\"start\":53450},{\"end\":53476,\"start\":53468},{\"end\":53491,\"start\":53483},{\"end\":53504,\"start\":53498},{\"end\":53522,\"start\":53515},{\"end\":53535,\"start\":53530},{\"end\":53547,\"start\":53543},{\"end\":53565,\"start\":53558},{\"end\":53584,\"start\":53576},{\"end\":53597,\"start\":53591},{\"end\":53618,\"start\":53608},{\"end\":53631,\"start\":53624},{\"end\":53647,\"start\":53640},{\"end\":53966,\"start\":53961},{\"end\":53980,\"start\":53975},{\"end\":53994,\"start\":53989},{\"end\":54294,\"start\":54290},{\"end\":54310,\"start\":54300},{\"end\":54329,\"start\":54323},{\"end\":54344,\"start\":54338},{\"end\":54355,\"start\":54350},{\"end\":54858,\"start\":54855},{\"end\":54871,\"start\":54867},{\"end\":54879,\"start\":54876},{\"end\":54893,\"start\":54889},{\"end\":54908,\"start\":54902},{\"end\":54919,\"start\":54915},{\"end\":54928,\"start\":54926},{\"end\":54944,\"start\":54940},{\"end\":54953,\"start\":54951},{\"end\":54965,\"start\":54959},{\"end\":55325,\"start\":55319},{\"end\":55340,\"start\":55335},{\"end\":55358,\"start\":55348},{\"end\":55746,\"start\":55740},{\"end\":55761,\"start\":55756},{\"end\":55779,\"start\":55769},{\"end\":55794,\"start\":55787},{\"end\":56132,\"start\":56126},{\"end\":56145,\"start\":56142},{\"end\":56163,\"start\":56155},{\"end\":56545,\"start\":56535},{\"end\":56557,\"start\":56552},{\"end\":56575,\"start\":56567},{\"end\":56595,\"start\":56587},{\"end\":56966,\"start\":56958},{\"end\":56980,\"start\":56974},{\"end\":56984,\"start\":56982},{\"end\":57156,\"start\":57152},{\"end\":57172,\"start\":57165},{\"end\":57188,\"start\":57183},{\"end\":57206,\"start\":57198},{\"end\":57222,\"start\":57215},{\"end\":57238,\"start\":57231},{\"end\":57250,\"start\":57245},{\"end\":57263,\"start\":57258},{\"end\":57280,\"start\":57273},{\"end\":57810,\"start\":57805},{\"end\":57828,\"start\":57820},{\"end\":57840,\"start\":57837},{\"end\":57856,\"start\":57846},{\"end\":57868,\"start\":57863},{\"end\":57885,\"start\":57877},{\"end\":57898,\"start\":57892},{\"end\":57912,\"start\":57906},{\"end\":57927,\"start\":57921},{\"end\":57937,\"start\":57934},{\"end\":57957,\"start\":57949},{\"end\":57978,\"start\":57967},{\"end\":57991,\"start\":57984},{\"end\":58354,\"start\":58344},{\"end\":58366,\"start\":58363},{\"end\":58380,\"start\":58373},{\"end\":58397,\"start\":58389},{\"end\":58410,\"start\":58404},{\"end\":58428,\"start\":58418},{\"end\":58443,\"start\":58437},{\"end\":58457,\"start\":58452},{\"end\":58473,\"start\":58466},{\"end\":58495,\"start\":58485},{\"end\":58882,\"start\":58877},{\"end\":58894,\"start\":58889},{\"end\":58909,\"start\":58902},{\"end\":58930,\"start\":58918},{\"end\":58944,\"start\":58938},{\"end\":58959,\"start\":58952},{\"end\":58973,\"start\":58966},{\"end\":58988,\"start\":58980},{\"end\":59001,\"start\":58996},{\"end\":59018,\"start\":59010},{\"end\":59622,\"start\":59620},{\"end\":59631,\"start\":59628},{\"end\":59654,\"start\":59641},{\"end\":59674,\"start\":59664},{\"end\":59694,\"start\":59684},{\"end\":59706,\"start\":59702},{\"end\":59719,\"start\":59713},{\"end\":59731,\"start\":59725},{\"end\":59745,\"start\":59739},{\"end\":59758,\"start\":59754},{\"end\":60137,\"start\":60131},{\"end\":60148,\"start\":60145},{\"end\":60168,\"start\":60158},{\"end\":60178,\"start\":60170},{\"end\":60552,\"start\":60549},{\"end\":60567,\"start\":60562},{\"end\":60583,\"start\":60575},{\"end\":60595,\"start\":60591},{\"end\":60610,\"start\":60604},{\"end\":60624,\"start\":60617},{\"end\":60638,\"start\":60632},{\"end\":60658,\"start\":60651},{\"end\":61059,\"start\":61057},{\"end\":61072,\"start\":61067},{\"end\":61085,\"start\":61079},{\"end\":61097,\"start\":61094},{\"end\":61437,\"start\":61432},{\"end\":61448,\"start\":61441},{\"end\":61456,\"start\":61450},{\"end\":61709,\"start\":61703},{\"end\":61721,\"start\":61715},{\"end\":61734,\"start\":61731},{\"end\":61748,\"start\":61742},{\"end\":61762,\"start\":61755},{\"end\":62206,\"start\":62200},{\"end\":62214,\"start\":62208},{\"end\":62432,\"start\":62430},{\"end\":62447,\"start\":62439},{\"end\":62454,\"start\":62452},{\"end\":62462,\"start\":62460},{\"end\":62475,\"start\":62470},{\"end\":62488,\"start\":62483},{\"end\":62507,\"start\":62501},{\"end\":62853,\"start\":62851},{\"end\":62865,\"start\":62862},{\"end\":62874,\"start\":62869},{\"end\":62884,\"start\":62879},{\"end\":62896,\"start\":62894},{\"end\":62917,\"start\":62909},{\"end\":62929,\"start\":62923},{\"end\":62933,\"start\":62931},{\"end\":63505,\"start\":63497},{\"end\":63514,\"start\":63509},{\"end\":63525,\"start\":63518},{\"end\":63864,\"start\":63861},{\"end\":63877,\"start\":63872},{\"end\":63889,\"start\":63887},{\"end\":63901,\"start\":63899},{\"end\":63912,\"start\":63908},{\"end\":63932,\"start\":63922},{\"end\":63945,\"start\":63941},{\"end\":63959,\"start\":63955},{\"end\":64366,\"start\":64362},{\"end\":64388,\"start\":64381},{\"end\":64401,\"start\":64394},{\"end\":64417,\"start\":64412},{\"end\":64692,\"start\":64688},{\"end\":64707,\"start\":64702},{\"end\":64726,\"start\":64720},{\"end\":64742,\"start\":64735},{\"end\":64757,\"start\":64750},{\"end\":64767,\"start\":64761},{\"end\":64782,\"start\":64777},{\"end\":64798,\"start\":64784},{\"end\":65264,\"start\":65254},{\"end\":65280,\"start\":65274},{\"end\":65303,\"start\":65296},{\"end\":65789,\"start\":65784},{\"end\":65803,\"start\":65797},{\"end\":65819,\"start\":65810},{\"end\":65976,\"start\":65971},{\"end\":65987,\"start\":65983},{\"end\":66006,\"start\":66000},{\"end\":66022,\"start\":66012},{\"end\":66359,\"start\":66354},{\"end\":66372,\"start\":66369},{\"end\":66385,\"start\":66378},{\"end\":66676,\"start\":66668},{\"end\":66690,\"start\":66684},{\"end\":66708,\"start\":66699},{\"end\":66732,\"start\":66719},{\"end\":67210,\"start\":67203},{\"end\":67225,\"start\":67222},{\"end\":67240,\"start\":67233},{\"end\":67255,\"start\":67249},{\"end\":67268,\"start\":67265},{\"end\":67286,\"start\":67279},{\"end\":67301,\"start\":67295},{\"end\":67316,\"start\":67310},{\"end\":67332,\"start\":67325},{\"end\":67344,\"start\":67339},{\"end\":67813,\"start\":67807},{\"end\":67832,\"start\":67824},{\"end\":67845,\"start\":67839},{\"end\":67856,\"start\":67853},{\"end\":67867,\"start\":67863},{\"end\":68135,\"start\":68129},{\"end\":68151,\"start\":68145},{\"end\":68164,\"start\":68161},{\"end\":68176,\"start\":68172},{\"end\":68190,\"start\":68186},{\"end\":68204,\"start\":68197},{\"end\":68215,\"start\":68211},{\"end\":68231,\"start\":68222},{\"end\":68631,\"start\":68622},{\"end\":68649,\"start\":68638},{\"end\":68662,\"start\":68657},{\"end\":68676,\"start\":68673},{\"end\":69179,\"start\":69172},{\"end\":69198,\"start\":69189},{\"end\":69214,\"start\":69208},{\"end\":69229,\"start\":69224},{\"end\":69242,\"start\":69237},{\"end\":69722,\"start\":69711},{\"end\":69732,\"start\":69728},{\"end\":69740,\"start\":69738},{\"end\":69757,\"start\":69751},{\"end\":69775,\"start\":69767},{\"end\":69784,\"start\":69782},{\"end\":69799,\"start\":69794},{\"end\":69816,\"start\":69808},{\"end\":69831,\"start\":69825},{\"end\":69850,\"start\":69841},{\"end\":70279,\"start\":70270},{\"end\":70296,\"start\":70288},{\"end\":70311,\"start\":70306},{\"end\":70324,\"start\":70318},{\"end\":70339,\"start\":70331},{\"end\":70353,\"start\":70347},{\"end\":70367,\"start\":70360},{\"end\":70381,\"start\":70376},{\"end\":70397,\"start\":70391},{\"end\":70416,\"start\":70408},{\"end\":70840,\"start\":70831},{\"end\":70855,\"start\":70850},{\"end\":70872,\"start\":70864},{\"end\":70892,\"start\":70881},{\"end\":70908,\"start\":70902},{\"end\":70922,\"start\":70917},{\"end\":70936,\"start\":70929},{\"end\":70950,\"start\":70944},{\"end\":70968,\"start\":70957},{\"end\":71385,\"start\":71379},{\"end\":71395,\"start\":71391},{\"end\":71414,\"start\":71407},{\"end\":71428,\"start\":71421},{\"end\":71980,\"start\":71975},{\"end\":71991,\"start\":71988},{\"end\":72010,\"start\":72003},{\"end\":72023,\"start\":72018},{\"end\":72033,\"start\":72027},{\"end\":72426,\"start\":72416},{\"end\":72441,\"start\":72436},{\"end\":72454,\"start\":72450},{\"end\":72473,\"start\":72464},{\"end\":72486,\"start\":72480},{\"end\":73090,\"start\":73087},{\"end\":73101,\"start\":73099},{\"end\":73116,\"start\":73111},{\"end\":73132,\"start\":73127},{\"end\":73148,\"start\":73143},{\"end\":73161,\"start\":73158},{\"end\":73181,\"start\":73172},{\"end\":73200,\"start\":73193},{\"end\":73721,\"start\":73717},{\"end\":73738,\"start\":73733},{\"end\":73756,\"start\":73745},{\"end\":73770,\"start\":73763},{\"end\":73781,\"start\":73777},{\"end\":73794,\"start\":73788},{\"end\":73808,\"start\":73801},{\"end\":73825,\"start\":73818},{\"end\":73849,\"start\":73836},{\"end\":73870,\"start\":73861},{\"end\":74322,\"start\":74319},{\"end\":74336,\"start\":74330},{\"end\":74610,\"start\":74607},{\"end\":74618,\"start\":74616},{\"end\":74630,\"start\":74625},{\"end\":74645,\"start\":74642},{\"end\":74658,\"start\":74656},{\"end\":75147,\"start\":75141},{\"end\":75163,\"start\":75157},{\"end\":75176,\"start\":75173},{\"end\":75192,\"start\":75185},{\"end\":75208,\"start\":75198},{\"end\":75218,\"start\":75212},{\"end\":75241,\"start\":75231},{\"end\":75256,\"start\":75250},{\"end\":75269,\"start\":75258},{\"end\":75779,\"start\":75774},{\"end\":75791,\"start\":75787},{\"end\":75805,\"start\":75799},{\"end\":75821,\"start\":75815},{\"end\":75829,\"start\":75825},{\"end\":75845,\"start\":75838},{\"end\":75855,\"start\":75847},{\"end\":76116,\"start\":76110},{\"end\":76125,\"start\":76120},{\"end\":76140,\"start\":76134},{\"end\":76160,\"start\":76151},{\"end\":76175,\"start\":76167},{\"end\":76187,\"start\":76185},{\"end\":76202,\"start\":76196},{\"end\":76216,\"start\":76211},{\"end\":76220,\"start\":76218},{\"end\":76531,\"start\":76527},{\"end\":76545,\"start\":76540},{\"end\":76558,\"start\":76554},{\"end\":76570,\"start\":76567},{\"end\":76586,\"start\":76582},{\"end\":76596,\"start\":76592},{\"end\":76606,\"start\":76602},{\"end\":76617,\"start\":76614},{\"end\":76634,\"start\":76631},{\"end\":76645,\"start\":76642},{\"end\":77187,\"start\":77183},{\"end\":77199,\"start\":77196},{\"end\":77208,\"start\":77204},{\"end\":77222,\"start\":77216},{\"end\":77237,\"start\":77233},{\"end\":77248,\"start\":77245},{\"end\":77264,\"start\":77256},{\"end\":77293,\"start\":77274},{\"end\":77311,\"start\":77304},{\"end\":77316,\"start\":77313},{\"end\":77642,\"start\":77637},{\"end\":77658,\"start\":77650},{\"end\":77672,\"start\":77667},{\"end\":77684,\"start\":77680},{\"end\":77698,\"start\":77694},{\"end\":78109,\"start\":78102},{\"end\":78126,\"start\":78120},{\"end\":78140,\"start\":78134},{\"end\":78152,\"start\":78149},{\"end\":78164,\"start\":78160},{\"end\":78177,\"start\":78171},{\"end\":78192,\"start\":78187},{\"end\":78205,\"start\":78200},{\"end\":78512,\"start\":78510},{\"end\":78524,\"start\":78520},{\"end\":78539,\"start\":78534},{\"end\":78951,\"start\":78949},{\"end\":78964,\"start\":78960},{\"end\":78979,\"start\":78973},{\"end\":78990,\"start\":78988},{\"end\":79006,\"start\":79001},{\"end\":79019,\"start\":79015},{\"end\":79035,\"start\":79031},{\"end\":79514,\"start\":79509},{\"end\":79525,\"start\":79522},{\"end\":79537,\"start\":79535},{\"end\":79549,\"start\":79546},{\"end\":79558,\"start\":79555},{\"end\":79572,\"start\":79569},{\"end\":79585,\"start\":79582},{\"end\":79600,\"start\":79595},{\"end\":79611,\"start\":79607},{\"end\":79620,\"start\":79616},{\"end\":80169,\"start\":80162},{\"end\":80181,\"start\":80179},{\"end\":80194,\"start\":80191},{\"end\":80208,\"start\":80204},{\"end\":80218,\"start\":80215},{\"end\":80238,\"start\":80230},{\"end\":80246,\"start\":80243},{\"end\":80257,\"start\":80254},{\"end\":80647,\"start\":80645},{\"end\":80659,\"start\":80657},{\"end\":80676,\"start\":80669},{\"end\":80689,\"start\":80685},{\"end\":81084,\"start\":81077},{\"end\":81095,\"start\":81093},{\"end\":81106,\"start\":81104},{\"end\":81119,\"start\":81117},{\"end\":81133,\"start\":81129},{\"end\":81154,\"start\":81148},{\"end\":81171,\"start\":81163},{\"end\":81184,\"start\":81178},{\"end\":81197,\"start\":81190},{\"end\":81209,\"start\":81205}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":147704191},\"end\":41424,\"start\":40922},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":53825219},\"end\":42094,\"start\":41426},{\"attributes\":{\"doi\":\"arXiv:2207.10936\",\"id\":\"b2\"},\"end\":42458,\"start\":42096},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":218971783},\"end\":42986,\"start\":42460},{\"attributes\":{\"doi\":\"arXiv:1502.03143\",\"id\":\"b4\"},\"end\":43442,\"start\":42988},{\"attributes\":{\"id\":\"b5\"},\"end\":43605,\"start\":43444},{\"attributes\":{\"doi\":\"arXiv:1512.03012\",\"id\":\"b6\"},\"end\":44064,\"start\":43607},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4707877},\"end\":44551,\"start\":44066},{\"attributes\":{\"doi\":\"arXiv:2209.06794\",\"id\":\"b8\"},\"end\":45033,\"start\":44553},{\"attributes\":{\"doi\":\"PMLR, 2021. 2\",\"id\":\"b9\",\"matched_paper_id\":231802355},\"end\":45379,\"start\":45035},{\"attributes\":{\"doi\":\"arXiv:1602.02481\",\"id\":\"b10\"},\"end\":45643,\"start\":45381},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":238634701},\"end\":46361,\"start\":45645},{\"attributes\":{\"id\":\"b12\"},\"end\":46540,\"start\":46363},{\"attributes\":{\"doi\":\"arXiv:1301.3572\",\"id\":\"b13\"},\"end\":46848,\"start\":46542},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":7684883},\"end\":47418,\"start\":46850},{\"attributes\":{\"doi\":\"arXiv:2210.06849\",\"id\":\"b15\"},\"end\":47913,\"start\":47420},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":249642405},\"end\":48461,\"start\":47915},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":57246310},\"end\":48872,\"start\":48463},{\"attributes\":{\"doi\":\"arXiv:2204.11918\",\"id\":\"b18\"},\"end\":49361,\"start\":48874},{\"attributes\":{\"id\":\"b19\"},\"end\":49589,\"start\":49363},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":237142601},\"end\":50050,\"start\":49591},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":221819358},\"end\":50439,\"start\":50052},{\"attributes\":{\"doi\":\"arXiv:2007.04954\",\"id\":\"b22\"},\"end\":50974,\"start\":50441},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":252438648},\"end\":51489,\"start\":50976},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":229152875},\"end\":52130,\"start\":51491},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":195441339},\"end\":52606,\"start\":52132},{\"attributes\":{\"id\":\"b26\"},\"end\":52984,\"start\":52608},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":206594692},\"end\":53438,\"start\":52986},{\"attributes\":{\"id\":\"b28\"},\"end\":53897,\"start\":53440},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":220056011},\"end\":54224,\"start\":53899},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":244799255},\"end\":54757,\"start\":54226},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b31\",\"matched_paper_id\":231879586},\"end\":55310,\"start\":54759},{\"attributes\":{\"doi\":\"arXiv:1612.03651\",\"id\":\"b32\"},\"end\":55682,\"start\":55312},{\"attributes\":{\"doi\":\"arXiv:1607.01759\",\"id\":\"b33\"},\"end\":55982,\"start\":55684},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":14844861},\"end\":56471,\"start\":55984},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":244346010},\"end\":56910,\"start\":56473},{\"attributes\":{\"id\":\"b36\"},\"end\":57082,\"start\":56912},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":56482409},\"end\":57743,\"start\":57084},{\"attributes\":{\"id\":\"b38\"},\"end\":58308,\"start\":57745},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":53296866},\"end\":58806,\"start\":58310},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":1546062},\"end\":59522,\"start\":58808},{\"attributes\":{\"doi\":\"arXiv:2108.03272\",\"id\":\"b41\"},\"end\":60083,\"start\":59524},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":152322},\"end\":60495,\"start\":60085},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":14113767},\"end\":60950,\"start\":60497},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":199453025},\"end\":61365,\"start\":60952},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":220447505},\"end\":61641,\"start\":61367},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":244908764},\"end\":62155,\"start\":61643},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":1671874},\"end\":62353,\"start\":62157},{\"attributes\":{\"doi\":\"arXiv:1908.00575\",\"id\":\"b48\"},\"end\":62739,\"start\":62355},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":54447604},\"end\":63391,\"start\":62741},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":211818000},\"end\":63771,\"start\":63393},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":235732243},\"end\":64279,\"start\":63773},{\"attributes\":{\"doi\":\"arXiv:1809.09761\",\"id\":\"b52\"},\"end\":64633,\"start\":64281},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":234364556},\"end\":65197,\"start\":64635},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":1957433},\"end\":65718,\"start\":65199},{\"attributes\":{\"id\":\"b55\"},\"end\":65965,\"start\":65720},{\"attributes\":{\"doi\":\"arXiv:2209.14988\",\"id\":\"b56\"},\"end\":66249,\"start\":65967},{\"attributes\":{\"doi\":\"arXiv:2209.03320\",\"id\":\"b57\"},\"end\":66608,\"start\":66251},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":227227965},\"end\":67125,\"start\":66610},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":231591445},\"end\":67732,\"start\":67127},{\"attributes\":{\"id\":\"b60\"},\"end\":68084,\"start\":67734},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":232035663},\"end\":68524,\"start\":68086},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":248006501},\"end\":69102,\"start\":68526},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":245335280},\"end\":69653,\"start\":69104},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":2930547},\"end\":70172,\"start\":69655},{\"attributes\":{\"id\":\"b65\"},\"end\":70747,\"start\":70174},{\"attributes\":{\"id\":\"b66\"},\"end\":71271,\"start\":70749},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":51876975},\"end\":71911,\"start\":71273},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":16619984},\"end\":72320,\"start\":71913},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":232092726},\"end\":73013,\"start\":72322},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":4794860},\"end\":73642,\"start\":73015},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":235658123},\"end\":74239,\"start\":73644},{\"attributes\":{\"id\":\"b72\"},\"end\":74510,\"start\":74241},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":229219948},\"end\":75075,\"start\":74512},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":246706356},\"end\":75738,\"start\":75077},{\"attributes\":{\"id\":\"b75\"},\"end\":76056,\"start\":75740},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":207230134},\"end\":76468,\"start\":76058},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":221266194},\"end\":77087,\"start\":76470},{\"attributes\":{\"id\":\"b78\"},\"end\":77630,\"start\":77089},{\"attributes\":{\"id\":\"b79\"},\"end\":78019,\"start\":77632},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":210839350},\"end\":78433,\"start\":78021},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":234789948},\"end\":78880,\"start\":78435},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":206592833},\"end\":79445,\"start\":78882},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":213175506},\"end\":80066,\"start\":79447},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":251040899},\"end\":80573,\"start\":80068},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":227227755},\"end\":80990,\"start\":80575},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":245837609},\"end\":81704,\"start\":80992}]", "bib_title": "[{\"end\":40976,\"start\":40922},{\"end\":41518,\"start\":41426},{\"end\":42497,\"start\":42460},{\"end\":44146,\"start\":44066},{\"end\":45089,\"start\":45035},{\"end\":45706,\"start\":45645},{\"end\":46911,\"start\":46850},{\"end\":47976,\"start\":47915},{\"end\":48514,\"start\":48463},{\"end\":49659,\"start\":49591},{\"end\":50094,\"start\":50052},{\"end\":51056,\"start\":50976},{\"end\":51571,\"start\":51491},{\"end\":52190,\"start\":52132},{\"end\":52651,\"start\":52608},{\"end\":53030,\"start\":52986},{\"end\":53953,\"start\":53899},{\"end\":54283,\"start\":54226},{\"end\":54848,\"start\":54759},{\"end\":56114,\"start\":55984},{\"end\":56526,\"start\":56473},{\"end\":57140,\"start\":57084},{\"end\":58336,\"start\":58310},{\"end\":58870,\"start\":58808},{\"end\":60127,\"start\":60085},{\"end\":60538,\"start\":60497},{\"end\":61048,\"start\":60952},{\"end\":61423,\"start\":61367},{\"end\":61695,\"start\":61643},{\"end\":62196,\"start\":62157},{\"end\":62841,\"start\":62741},{\"end\":63493,\"start\":63393},{\"end\":63852,\"start\":63773},{\"end\":64677,\"start\":64635},{\"end\":65244,\"start\":65199},{\"end\":66659,\"start\":66610},{\"end\":67196,\"start\":67127},{\"end\":68120,\"start\":68086},{\"end\":68616,\"start\":68526},{\"end\":69164,\"start\":69104},{\"end\":69704,\"start\":69655},{\"end\":71370,\"start\":71273},{\"end\":71967,\"start\":71913},{\"end\":72406,\"start\":72322},{\"end\":73076,\"start\":73015},{\"end\":73708,\"start\":73644},{\"end\":74598,\"start\":74512},{\"end\":75131,\"start\":75077},{\"end\":76103,\"start\":76058},{\"end\":76519,\"start\":76470},{\"end\":78095,\"start\":78021},{\"end\":78502,\"start\":78435},{\"end\":78939,\"start\":78882},{\"end\":79501,\"start\":79447},{\"end\":80153,\"start\":80068},{\"end\":80635,\"start\":80575},{\"end\":81069,\"start\":80992}]", "bib_author": "[{\"end\":40996,\"start\":40978},{\"end\":41006,\"start\":40996},{\"end\":41022,\"start\":41006},{\"end\":41036,\"start\":41022},{\"end\":41055,\"start\":41036},{\"end\":41538,\"start\":41520},{\"end\":41545,\"start\":41538},{\"end\":41558,\"start\":41545},{\"end\":41573,\"start\":41558},{\"end\":41583,\"start\":41573},{\"end\":41597,\"start\":41583},{\"end\":41609,\"start\":41597},{\"end\":42206,\"start\":42159},{\"end\":42216,\"start\":42206},{\"end\":42229,\"start\":42216},{\"end\":42234,\"start\":42229},{\"end\":42510,\"start\":42499},{\"end\":42525,\"start\":42510},{\"end\":42537,\"start\":42525},{\"end\":42554,\"start\":42537},{\"end\":42570,\"start\":42554},{\"end\":42589,\"start\":42570},{\"end\":42609,\"start\":42589},{\"end\":42623,\"start\":42609},{\"end\":42638,\"start\":42623},{\"end\":42653,\"start\":42638},{\"end\":43000,\"start\":42988},{\"end\":43015,\"start\":43000},{\"end\":43028,\"start\":43015},{\"end\":43050,\"start\":43028},{\"end\":43065,\"start\":43050},{\"end\":43081,\"start\":43065},{\"end\":43616,\"start\":43607},{\"end\":43630,\"start\":43616},{\"end\":43651,\"start\":43630},{\"end\":43663,\"start\":43651},{\"end\":43680,\"start\":43663},{\"end\":43692,\"start\":43680},{\"end\":43703,\"start\":43692},{\"end\":43721,\"start\":43703},{\"end\":43735,\"start\":43721},{\"end\":43745,\"start\":43735},{\"end\":43749,\"start\":43745},{\"end\":44160,\"start\":44148},{\"end\":44175,\"start\":44160},{\"end\":44189,\"start\":44175},{\"end\":44196,\"start\":44189},{\"end\":44205,\"start\":44196},{\"end\":44219,\"start\":44205},{\"end\":44238,\"start\":44219},{\"end\":44248,\"start\":44238},{\"end\":44562,\"start\":44553},{\"end\":44573,\"start\":44562},{\"end\":44593,\"start\":44573},{\"end\":44613,\"start\":44593},{\"end\":44631,\"start\":44613},{\"end\":44647,\"start\":44631},{\"end\":44661,\"start\":44647},{\"end\":44676,\"start\":44661},{\"end\":44691,\"start\":44676},{\"end\":44698,\"start\":44691},{\"end\":45103,\"start\":45091},{\"end\":45112,\"start\":45103},{\"end\":45121,\"start\":45112},{\"end\":45135,\"start\":45121},{\"end\":45396,\"start\":45381},{\"end\":45410,\"start\":45396},{\"end\":45426,\"start\":45410},{\"end\":45442,\"start\":45426},{\"end\":45725,\"start\":45708},{\"end\":45739,\"start\":45725},{\"end\":45751,\"start\":45739},{\"end\":45770,\"start\":45751},{\"end\":45779,\"start\":45770},{\"end\":45795,\"start\":45779},{\"end\":45805,\"start\":45795},{\"end\":45827,\"start\":45805},{\"end\":45846,\"start\":45827},{\"end\":45862,\"start\":45846},{\"end\":46436,\"start\":46410},{\"end\":46613,\"start\":46596},{\"end\":46630,\"start\":46613},{\"end\":46646,\"start\":46630},{\"end\":46658,\"start\":46646},{\"end\":46925,\"start\":46913},{\"end\":46934,\"start\":46925},{\"end\":46949,\"start\":46934},{\"end\":46963,\"start\":46949},{\"end\":46978,\"start\":46963},{\"end\":46999,\"start\":46978},{\"end\":47008,\"start\":46999},{\"end\":47433,\"start\":47420},{\"end\":47446,\"start\":47433},{\"end\":47460,\"start\":47446},{\"end\":47477,\"start\":47460},{\"end\":47486,\"start\":47477},{\"end\":47502,\"start\":47486},{\"end\":47525,\"start\":47502},{\"end\":47539,\"start\":47525},{\"end\":47566,\"start\":47539},{\"end\":47578,\"start\":47566},{\"end\":47587,\"start\":47578},{\"end\":47991,\"start\":47978},{\"end\":48007,\"start\":47991},{\"end\":48024,\"start\":48007},{\"end\":48036,\"start\":48024},{\"end\":48052,\"start\":48036},{\"end\":48066,\"start\":48052},{\"end\":48078,\"start\":48066},{\"end\":48090,\"start\":48078},{\"end\":48103,\"start\":48090},{\"end\":48123,\"start\":48103},{\"end\":48526,\"start\":48516},{\"end\":48536,\"start\":48526},{\"end\":48552,\"start\":48536},{\"end\":48563,\"start\":48552},{\"end\":48571,\"start\":48563},{\"end\":48583,\"start\":48571},{\"end\":48964,\"start\":48951},{\"end\":48981,\"start\":48964},{\"end\":48994,\"start\":48981},{\"end\":49010,\"start\":48994},{\"end\":49024,\"start\":49010},{\"end\":49040,\"start\":49024},{\"end\":49050,\"start\":49040},{\"end\":49066,\"start\":49050},{\"end\":49077,\"start\":49066},{\"end\":49384,\"start\":49363},{\"end\":49393,\"start\":49384},{\"end\":49677,\"start\":49661},{\"end\":49690,\"start\":49677},{\"end\":49704,\"start\":49690},{\"end\":50105,\"start\":50096},{\"end\":50118,\"start\":50105},{\"end\":50127,\"start\":50118},{\"end\":50142,\"start\":50127},{\"end\":50157,\"start\":50142},{\"end\":50172,\"start\":50157},{\"end\":50185,\"start\":50172},{\"end\":50526,\"start\":50514},{\"end\":50543,\"start\":50526},{\"end\":50555,\"start\":50543},{\"end\":50572,\"start\":50555},{\"end\":50585,\"start\":50572},{\"end\":50604,\"start\":50585},{\"end\":50620,\"start\":50604},{\"end\":50642,\"start\":50620},{\"end\":50654,\"start\":50642},{\"end\":50667,\"start\":50654},{\"end\":51067,\"start\":51058},{\"end\":51083,\"start\":51067},{\"end\":51094,\"start\":51083},{\"end\":51109,\"start\":51094},{\"end\":51122,\"start\":51109},{\"end\":51134,\"start\":51122},{\"end\":51145,\"start\":51134},{\"end\":51157,\"start\":51145},{\"end\":51171,\"start\":51157},{\"end\":51588,\"start\":51573},{\"end\":51597,\"start\":51588},{\"end\":51615,\"start\":51597},{\"end\":51625,\"start\":51615},{\"end\":51639,\"start\":51625},{\"end\":51647,\"start\":51639},{\"end\":51654,\"start\":51647},{\"end\":51662,\"start\":51654},{\"end\":51673,\"start\":51662},{\"end\":51679,\"start\":51673},{\"end\":52205,\"start\":52192},{\"end\":52219,\"start\":52205},{\"end\":52234,\"start\":52219},{\"end\":52665,\"start\":52653},{\"end\":52683,\"start\":52665},{\"end\":53044,\"start\":53032},{\"end\":53059,\"start\":53044},{\"end\":53073,\"start\":53059},{\"end\":53083,\"start\":53073},{\"end\":53459,\"start\":53442},{\"end\":53478,\"start\":53459},{\"end\":53493,\"start\":53478},{\"end\":53506,\"start\":53493},{\"end\":53524,\"start\":53506},{\"end\":53537,\"start\":53524},{\"end\":53549,\"start\":53537},{\"end\":53567,\"start\":53549},{\"end\":53586,\"start\":53567},{\"end\":53599,\"start\":53586},{\"end\":53620,\"start\":53599},{\"end\":53633,\"start\":53620},{\"end\":53649,\"start\":53633},{\"end\":53968,\"start\":53955},{\"end\":53982,\"start\":53968},{\"end\":53996,\"start\":53982},{\"end\":54296,\"start\":54285},{\"end\":54312,\"start\":54296},{\"end\":54331,\"start\":54312},{\"end\":54346,\"start\":54331},{\"end\":54357,\"start\":54346},{\"end\":54860,\"start\":54850},{\"end\":54873,\"start\":54860},{\"end\":54881,\"start\":54873},{\"end\":54895,\"start\":54881},{\"end\":54910,\"start\":54895},{\"end\":54921,\"start\":54910},{\"end\":54930,\"start\":54921},{\"end\":54946,\"start\":54930},{\"end\":54955,\"start\":54946},{\"end\":54967,\"start\":54955},{\"end\":55327,\"start\":55312},{\"end\":55342,\"start\":55327},{\"end\":55360,\"start\":55342},{\"end\":55748,\"start\":55733},{\"end\":55763,\"start\":55748},{\"end\":55781,\"start\":55763},{\"end\":55796,\"start\":55781},{\"end\":56134,\"start\":56116},{\"end\":56147,\"start\":56134},{\"end\":56165,\"start\":56147},{\"end\":56547,\"start\":56528},{\"end\":56559,\"start\":56547},{\"end\":56577,\"start\":56559},{\"end\":56597,\"start\":56577},{\"end\":56968,\"start\":56956},{\"end\":56982,\"start\":56968},{\"end\":56986,\"start\":56982},{\"end\":57158,\"start\":57142},{\"end\":57174,\"start\":57158},{\"end\":57190,\"start\":57174},{\"end\":57208,\"start\":57190},{\"end\":57224,\"start\":57208},{\"end\":57240,\"start\":57224},{\"end\":57252,\"start\":57240},{\"end\":57265,\"start\":57252},{\"end\":57282,\"start\":57265},{\"end\":57812,\"start\":57800},{\"end\":57830,\"start\":57812},{\"end\":57842,\"start\":57830},{\"end\":57858,\"start\":57842},{\"end\":57870,\"start\":57858},{\"end\":57887,\"start\":57870},{\"end\":57900,\"start\":57887},{\"end\":57914,\"start\":57900},{\"end\":57929,\"start\":57914},{\"end\":57939,\"start\":57929},{\"end\":57959,\"start\":57939},{\"end\":57980,\"start\":57959},{\"end\":57993,\"start\":57980},{\"end\":58356,\"start\":58338},{\"end\":58368,\"start\":58356},{\"end\":58382,\"start\":58368},{\"end\":58399,\"start\":58382},{\"end\":58412,\"start\":58399},{\"end\":58430,\"start\":58412},{\"end\":58445,\"start\":58430},{\"end\":58459,\"start\":58445},{\"end\":58475,\"start\":58459},{\"end\":58497,\"start\":58475},{\"end\":58884,\"start\":58872},{\"end\":58896,\"start\":58884},{\"end\":58911,\"start\":58896},{\"end\":58932,\"start\":58911},{\"end\":58946,\"start\":58932},{\"end\":58961,\"start\":58946},{\"end\":58975,\"start\":58961},{\"end\":58990,\"start\":58975},{\"end\":59003,\"start\":58990},{\"end\":59020,\"start\":59003},{\"end\":59624,\"start\":59611},{\"end\":59633,\"start\":59624},{\"end\":59656,\"start\":59633},{\"end\":59676,\"start\":59656},{\"end\":59696,\"start\":59676},{\"end\":59708,\"start\":59696},{\"end\":59721,\"start\":59708},{\"end\":59733,\"start\":59721},{\"end\":59747,\"start\":59733},{\"end\":59760,\"start\":59747},{\"end\":60139,\"start\":60129},{\"end\":60150,\"start\":60139},{\"end\":60170,\"start\":60150},{\"end\":60180,\"start\":60170},{\"end\":60554,\"start\":60540},{\"end\":60569,\"start\":60554},{\"end\":60585,\"start\":60569},{\"end\":60597,\"start\":60585},{\"end\":60612,\"start\":60597},{\"end\":60626,\"start\":60612},{\"end\":60640,\"start\":60626},{\"end\":60660,\"start\":60640},{\"end\":61061,\"start\":61050},{\"end\":61074,\"start\":61061},{\"end\":61087,\"start\":61074},{\"end\":61099,\"start\":61087},{\"end\":61439,\"start\":61425},{\"end\":61450,\"start\":61439},{\"end\":61458,\"start\":61450},{\"end\":61711,\"start\":61697},{\"end\":61723,\"start\":61711},{\"end\":61736,\"start\":61723},{\"end\":61750,\"start\":61736},{\"end\":61764,\"start\":61750},{\"end\":62208,\"start\":62198},{\"end\":62216,\"start\":62208},{\"end\":62434,\"start\":62422},{\"end\":62449,\"start\":62434},{\"end\":62456,\"start\":62449},{\"end\":62464,\"start\":62456},{\"end\":62477,\"start\":62464},{\"end\":62490,\"start\":62477},{\"end\":62509,\"start\":62490},{\"end\":62855,\"start\":62843},{\"end\":62867,\"start\":62855},{\"end\":62876,\"start\":62867},{\"end\":62886,\"start\":62876},{\"end\":62898,\"start\":62886},{\"end\":62919,\"start\":62898},{\"end\":62931,\"start\":62919},{\"end\":62935,\"start\":62931},{\"end\":63507,\"start\":63495},{\"end\":63516,\"start\":63507},{\"end\":63527,\"start\":63516},{\"end\":63866,\"start\":63854},{\"end\":63879,\"start\":63866},{\"end\":63891,\"start\":63879},{\"end\":63903,\"start\":63891},{\"end\":63914,\"start\":63903},{\"end\":63934,\"start\":63914},{\"end\":63947,\"start\":63934},{\"end\":63961,\"start\":63947},{\"end\":64368,\"start\":64353},{\"end\":64390,\"start\":64368},{\"end\":64403,\"start\":64390},{\"end\":64419,\"start\":64403},{\"end\":64694,\"start\":64679},{\"end\":64709,\"start\":64694},{\"end\":64728,\"start\":64709},{\"end\":64744,\"start\":64728},{\"end\":64759,\"start\":64744},{\"end\":64769,\"start\":64759},{\"end\":64784,\"start\":64769},{\"end\":64800,\"start\":64784},{\"end\":65266,\"start\":65246},{\"end\":65282,\"start\":65266},{\"end\":65305,\"start\":65282},{\"end\":65791,\"start\":65779},{\"end\":65805,\"start\":65791},{\"end\":65821,\"start\":65805},{\"end\":65978,\"start\":65967},{\"end\":65989,\"start\":65978},{\"end\":66008,\"start\":65989},{\"end\":66024,\"start\":66008},{\"end\":66361,\"start\":66348},{\"end\":66374,\"start\":66361},{\"end\":66387,\"start\":66374},{\"end\":66678,\"start\":66661},{\"end\":66692,\"start\":66678},{\"end\":66710,\"start\":66692},{\"end\":66734,\"start\":66710},{\"end\":67212,\"start\":67198},{\"end\":67227,\"start\":67212},{\"end\":67242,\"start\":67227},{\"end\":67257,\"start\":67242},{\"end\":67270,\"start\":67257},{\"end\":67288,\"start\":67270},{\"end\":67303,\"start\":67288},{\"end\":67318,\"start\":67303},{\"end\":67334,\"start\":67318},{\"end\":67346,\"start\":67334},{\"end\":67815,\"start\":67800},{\"end\":67834,\"start\":67815},{\"end\":67847,\"start\":67834},{\"end\":67858,\"start\":67847},{\"end\":67869,\"start\":67858},{\"end\":68137,\"start\":68122},{\"end\":68153,\"start\":68137},{\"end\":68166,\"start\":68153},{\"end\":68178,\"start\":68166},{\"end\":68192,\"start\":68178},{\"end\":68206,\"start\":68192},{\"end\":68217,\"start\":68206},{\"end\":68233,\"start\":68217},{\"end\":68633,\"start\":68618},{\"end\":68651,\"start\":68633},{\"end\":68664,\"start\":68651},{\"end\":68678,\"start\":68664},{\"end\":69181,\"start\":69166},{\"end\":69200,\"start\":69181},{\"end\":69216,\"start\":69200},{\"end\":69231,\"start\":69216},{\"end\":69244,\"start\":69231},{\"end\":69724,\"start\":69706},{\"end\":69734,\"start\":69724},{\"end\":69742,\"start\":69734},{\"end\":69759,\"start\":69742},{\"end\":69777,\"start\":69759},{\"end\":69786,\"start\":69777},{\"end\":69801,\"start\":69786},{\"end\":69818,\"start\":69801},{\"end\":69833,\"start\":69818},{\"end\":69852,\"start\":69833},{\"end\":70281,\"start\":70260},{\"end\":70298,\"start\":70281},{\"end\":70313,\"start\":70298},{\"end\":70326,\"start\":70313},{\"end\":70341,\"start\":70326},{\"end\":70355,\"start\":70341},{\"end\":70369,\"start\":70355},{\"end\":70383,\"start\":70369},{\"end\":70399,\"start\":70383},{\"end\":70418,\"start\":70399},{\"end\":70842,\"start\":70821},{\"end\":70857,\"start\":70842},{\"end\":70874,\"start\":70857},{\"end\":70894,\"start\":70874},{\"end\":70910,\"start\":70894},{\"end\":70924,\"start\":70910},{\"end\":70938,\"start\":70924},{\"end\":70952,\"start\":70938},{\"end\":70970,\"start\":70952},{\"end\":71387,\"start\":71372},{\"end\":71397,\"start\":71387},{\"end\":71416,\"start\":71397},{\"end\":71430,\"start\":71416},{\"end\":71982,\"start\":71969},{\"end\":71993,\"start\":71982},{\"end\":72012,\"start\":71993},{\"end\":72025,\"start\":72012},{\"end\":72035,\"start\":72025},{\"end\":72428,\"start\":72408},{\"end\":72443,\"start\":72428},{\"end\":72456,\"start\":72443},{\"end\":72475,\"start\":72456},{\"end\":72488,\"start\":72475},{\"end\":73092,\"start\":73078},{\"end\":73103,\"start\":73092},{\"end\":73118,\"start\":73103},{\"end\":73134,\"start\":73118},{\"end\":73150,\"start\":73134},{\"end\":73163,\"start\":73150},{\"end\":73183,\"start\":73163},{\"end\":73202,\"start\":73183},{\"end\":73723,\"start\":73710},{\"end\":73740,\"start\":73723},{\"end\":73758,\"start\":73740},{\"end\":73772,\"start\":73758},{\"end\":73783,\"start\":73772},{\"end\":73796,\"start\":73783},{\"end\":73810,\"start\":73796},{\"end\":73827,\"start\":73810},{\"end\":73851,\"start\":73827},{\"end\":73872,\"start\":73851},{\"end\":74324,\"start\":74315},{\"end\":74338,\"start\":74324},{\"end\":74612,\"start\":74600},{\"end\":74620,\"start\":74612},{\"end\":74632,\"start\":74620},{\"end\":74647,\"start\":74632},{\"end\":74660,\"start\":74647},{\"end\":75149,\"start\":75133},{\"end\":75165,\"start\":75149},{\"end\":75178,\"start\":75165},{\"end\":75194,\"start\":75178},{\"end\":75210,\"start\":75194},{\"end\":75220,\"start\":75210},{\"end\":75243,\"start\":75220},{\"end\":75258,\"start\":75243},{\"end\":75271,\"start\":75258},{\"end\":75781,\"start\":75770},{\"end\":75793,\"start\":75781},{\"end\":75807,\"start\":75793},{\"end\":75823,\"start\":75807},{\"end\":75831,\"start\":75823},{\"end\":75847,\"start\":75831},{\"end\":75857,\"start\":75847},{\"end\":76118,\"start\":76105},{\"end\":76127,\"start\":76118},{\"end\":76142,\"start\":76127},{\"end\":76162,\"start\":76142},{\"end\":76177,\"start\":76162},{\"end\":76189,\"start\":76177},{\"end\":76204,\"start\":76189},{\"end\":76218,\"start\":76204},{\"end\":76222,\"start\":76218},{\"end\":76533,\"start\":76521},{\"end\":76547,\"start\":76533},{\"end\":76560,\"start\":76547},{\"end\":76572,\"start\":76560},{\"end\":76588,\"start\":76572},{\"end\":76598,\"start\":76588},{\"end\":76608,\"start\":76598},{\"end\":76619,\"start\":76608},{\"end\":76636,\"start\":76619},{\"end\":76647,\"start\":76636},{\"end\":77189,\"start\":77176},{\"end\":77201,\"start\":77189},{\"end\":77210,\"start\":77201},{\"end\":77224,\"start\":77210},{\"end\":77239,\"start\":77224},{\"end\":77250,\"start\":77239},{\"end\":77266,\"start\":77250},{\"end\":77295,\"start\":77266},{\"end\":77313,\"start\":77295},{\"end\":77318,\"start\":77313},{\"end\":77644,\"start\":77632},{\"end\":77660,\"start\":77644},{\"end\":77674,\"start\":77660},{\"end\":77686,\"start\":77674},{\"end\":77700,\"start\":77686},{\"end\":78111,\"start\":78097},{\"end\":78128,\"start\":78111},{\"end\":78142,\"start\":78128},{\"end\":78154,\"start\":78142},{\"end\":78166,\"start\":78154},{\"end\":78179,\"start\":78166},{\"end\":78194,\"start\":78179},{\"end\":78207,\"start\":78194},{\"end\":78514,\"start\":78504},{\"end\":78526,\"start\":78514},{\"end\":78541,\"start\":78526},{\"end\":78953,\"start\":78941},{\"end\":78966,\"start\":78953},{\"end\":78981,\"start\":78966},{\"end\":78992,\"start\":78981},{\"end\":79008,\"start\":78992},{\"end\":79021,\"start\":79008},{\"end\":79037,\"start\":79021},{\"end\":79516,\"start\":79503},{\"end\":79527,\"start\":79516},{\"end\":79539,\"start\":79527},{\"end\":79551,\"start\":79539},{\"end\":79560,\"start\":79551},{\"end\":79574,\"start\":79560},{\"end\":79587,\"start\":79574},{\"end\":79602,\"start\":79587},{\"end\":79613,\"start\":79602},{\"end\":79622,\"start\":79613},{\"end\":80171,\"start\":80155},{\"end\":80183,\"start\":80171},{\"end\":80196,\"start\":80183},{\"end\":80210,\"start\":80196},{\"end\":80220,\"start\":80210},{\"end\":80240,\"start\":80220},{\"end\":80248,\"start\":80240},{\"end\":80259,\"start\":80248},{\"end\":80649,\"start\":80637},{\"end\":80661,\"start\":80649},{\"end\":80678,\"start\":80661},{\"end\":80691,\"start\":80678},{\"end\":81086,\"start\":81071},{\"end\":81097,\"start\":81086},{\"end\":81108,\"start\":81097},{\"end\":81121,\"start\":81108},{\"end\":81135,\"start\":81121},{\"end\":81156,\"start\":81135},{\"end\":81173,\"start\":81156},{\"end\":81186,\"start\":81173},{\"end\":81199,\"start\":81186},{\"end\":81211,\"start\":81199}]", "bib_venue": "[{\"end\":41126,\"start\":41055},{\"end\":41678,\"start\":41609},{\"end\":42157,\"start\":42096},{\"end\":42702,\"start\":42653},{\"end\":43191,\"start\":43097},{\"end\":43482,\"start\":43444},{\"end\":43804,\"start\":43765},{\"end\":44283,\"start\":44248},{\"end\":44763,\"start\":44714},{\"end\":45192,\"start\":45148},{\"end\":45489,\"start\":45458},{\"end\":45943,\"start\":45862},{\"end\":46408,\"start\":46363},{\"end\":46594,\"start\":46542},{\"end\":47085,\"start\":47008},{\"end\":47645,\"start\":47603},{\"end\":48174,\"start\":48123},{\"end\":48646,\"start\":48583},{\"end\":48949,\"start\":48874},{\"end\":49451,\"start\":49393},{\"end\":49775,\"start\":49704},{\"end\":50225,\"start\":50185},{\"end\":50512,\"start\":50441},{\"end\":51220,\"start\":51171},{\"end\":51760,\"start\":51679},{\"end\":52315,\"start\":52234},{\"end\":52750,\"start\":52683},{\"end\":53160,\"start\":53083},{\"end\":53658,\"start\":53649},{\"end\":54045,\"start\":53996},{\"end\":54438,\"start\":54357},{\"end\":55015,\"start\":54971},{\"end\":55476,\"start\":55376},{\"end\":55731,\"start\":55684},{\"end\":56211,\"start\":56165},{\"end\":56666,\"start\":56597},{\"end\":56954,\"start\":56912},{\"end\":57363,\"start\":57282},{\"end\":57798,\"start\":57745},{\"end\":58537,\"start\":58497},{\"end\":59109,\"start\":59020},{\"end\":59609,\"start\":59524},{\"end\":60247,\"start\":60180},{\"end\":60698,\"start\":60660},{\"end\":61148,\"start\":61099},{\"end\":61474,\"start\":61458},{\"end\":61845,\"start\":61764},{\"end\":62241,\"start\":62216},{\"end\":62420,\"start\":62355},{\"end\":63016,\"start\":62935},{\"end\":63563,\"start\":63527},{\"end\":64010,\"start\":63961},{\"end\":64351,\"start\":64281},{\"end\":64871,\"start\":64800},{\"end\":65399,\"start\":65305},{\"end\":65777,\"start\":65720},{\"end\":66082,\"start\":66040},{\"end\":66346,\"start\":66251},{\"end\":66815,\"start\":66734},{\"end\":67390,\"start\":67346},{\"end\":67798,\"start\":67734},{\"end\":68290,\"start\":68246},{\"end\":68759,\"start\":68678},{\"end\":69325,\"start\":69244},{\"end\":69892,\"start\":69852},{\"end\":70258,\"start\":70174},{\"end\":70819,\"start\":70749},{\"end\":71517,\"start\":71430},{\"end\":72098,\"start\":72035},{\"end\":72599,\"start\":72488},{\"end\":73279,\"start\":73202},{\"end\":73921,\"start\":73872},{\"end\":74313,\"start\":74241},{\"end\":74741,\"start\":74660},{\"end\":75359,\"start\":75278},{\"end\":75768,\"start\":75740},{\"end\":76247,\"start\":76222},{\"end\":76728,\"start\":76647},{\"end\":77174,\"start\":77089},{\"end\":77804,\"start\":77716},{\"end\":78217,\"start\":78207},{\"end\":78612,\"start\":78541},{\"end\":79114,\"start\":79037},{\"end\":79703,\"start\":79622},{\"end\":80315,\"start\":80266},{\"end\":80759,\"start\":80691},{\"end\":81292,\"start\":81211},{\"end\":41184,\"start\":41128},{\"end\":41699,\"start\":41680},{\"end\":46011,\"start\":45945},{\"end\":47149,\"start\":47087},{\"end\":49833,\"start\":49777},{\"end\":51828,\"start\":51762},{\"end\":52383,\"start\":52317},{\"end\":52804,\"start\":52752},{\"end\":53224,\"start\":53162},{\"end\":54506,\"start\":54440},{\"end\":57431,\"start\":57365},{\"end\":59185,\"start\":59111},{\"end\":60301,\"start\":60249},{\"end\":61913,\"start\":61847},{\"end\":63084,\"start\":63018},{\"end\":64929,\"start\":64873},{\"end\":65480,\"start\":65401},{\"end\":66883,\"start\":66817},{\"end\":68827,\"start\":68761},{\"end\":69393,\"start\":69327},{\"end\":71591,\"start\":71519},{\"end\":72697,\"start\":72601},{\"end\":73343,\"start\":73281},{\"end\":74809,\"start\":74743},{\"end\":75427,\"start\":75361},{\"end\":76796,\"start\":76730},{\"end\":78670,\"start\":78614},{\"end\":79178,\"start\":79116},{\"end\":79771,\"start\":79705},{\"end\":81360,\"start\":81294}]"}}}, "year": 2023, "month": 12, "day": 17}