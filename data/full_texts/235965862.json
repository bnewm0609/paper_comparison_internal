{"id": 235965862, "updated": "2022-09-30 00:12:53.733", "metadata": {"title": "Interpretable Pneumonia Detection by Combining Deep Learning and Explainable Models With Multisource Data", "authors": "[{\"first\":\"Hao\",\"last\":\"Ren\",\"middle\":[]},{\"first\":\"Aslan\",\"last\":\"Wong\",\"middle\":[\"B.\"]},{\"first\":\"Wanmin\",\"last\":\"Lian\",\"middle\":[]},{\"first\":\"Weibin\",\"last\":\"Cheng\",\"middle\":[]},{\"first\":\"Ying\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Jianwei\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Qingfeng\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Jiasheng\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Chen\",\"last\":\"Zhang\",\"middle\":[\"Jason\"]},{\"first\":\"Kaishun\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Haodi\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": "IEEE Access", "journal": "IEEE Access", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "With the rapid development of AI techniques, Computer-aided Diagnosis has attracted much attention and has been successfully deployed in many applications of health care and medical diagnosis. For some specific tasks, the learning-based system can compare with or even outperform human experts\u2019 performance. The impressive performance owes to the excellent expressiveness and scalability of the neural networks, although the models\u2019 intuition usually cannot be represented explicitly. Interpretability is, however, very important, even the same as the diagnosis precision, for computer-aided diagnosis. To fill this gap, our approach is intuitive to detect pneumonia interpretably. We first build a large dataset of community-acquired pneumonia consisting of 35389 cases (distinguished from nosocomial pneumonia) based on actual medical records. Second, we train a prediction model with the chest X-ray images in our dataset, capable of precisely detecting pneumonia. Third, we propose an intuitive approach to combine neural networks with an explainable model such as the Bayesian Network. The experiment result shows that our proposal further improves the performance by using multi-source data and provides intuitive explanations for the diagnosis results.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/access/RenWLCZHLYZWZ21", "doi": "10.1109/access.2021.3090215"}}, "content": {"source": {"pdf_hash": "d015e85ff08c12d6970a970d14316e548cb4ec70", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://ieeexplore.ieee.org/ielx7/6287639/9312710/09458276.pdf", "status": "GOLD"}}, "grobid": {"id": "05e13369acf880de1bc1ea6d5cb0506bb8beff1b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d015e85ff08c12d6970a970d14316e548cb4ec70.txt", "contents": "\nInterpretable Pneumonia Detection by Combining Deep Learning and Explainable Models With Multisource Data\n\n\nHao Ren \nCollege of Computer Science and Software Engineering\nShenzhen University\n518061ShenzhenChina\n\nInstitute for Healthcare Artificial Intelligence Application\nGuangdong Second Provincial General Hospital\n510317GuangzhouChina\n\nAslan B Wong \nCollege of Computer Science and Software Engineering\nShenzhen University\n518061ShenzhenChina\n\nMember, IEEEWanmin Lian \nInformation Department\nGuangdong Second Provincial General Hospital\n510317GuangzhouChina\n\nWeibin Cheng \nInstitute for Healthcare Artificial Intelligence Application\nGuangdong Second Provincial General Hospital\n510317GuangzhouChina\n\nYing Zhang \nCollege of Computer Science and Software Engineering\nShenzhen University\n518061ShenzhenChina\n\nJianwei He \nQingfeng Liu \nCollege of Computer Science and Software Engineering\nShenzhen University\n518061ShenzhenChina\n\nDepartment of Respiratory Medicine\nGuangdong Second Provincial General Hospital\n510317GuangzhouChina\n\nJiasheng Yang \nDepartment of Respiratory Medicine\nGuangdong Second Provincial General Hospital\n510317GuangzhouChina\n\nChen Jason Zhang \nDepartment of Computer Science and Engineering\nThe Hong Kong University of Science and Technology\nHong Kong\n\nMember, IEEEKaishun Wu \nCollege of Computer Science and Software Engineering\nShenzhen University\n518061ShenzhenChina\n\nANDHaodi Zhang hdzhang@szu.edu.cn \nCollege of Computer Science and Software Engineering\nShenzhen University\n518061ShenzhenChina\n\nHaodi Zhang \nInterpretable Pneumonia Detection by Combining Deep Learning and Explainable Models With Multisource Data\n10.1109/ACCESS.2021.3090215Received June 9, 2021, accepted June 10, 2021, date of publication June 17, 2021, date of current version July 13, 2021.Corresponding author:\nWith the rapid development of AI techniques, Computer-aided Diagnosis has attracted much attention and has been successfully deployed in many applications of health care and medical diagnosis. For some specific tasks, the learning-based system can compare with or even outperform human experts' performance. The impressive performance owes to the excellent expressiveness and scalability of the neural networks, although the models' intuition usually cannot be represented explicitly. Interpretability is, however, very important, even the same as the diagnosis precision, for computer-aided diagnosis. To fill this gap, our approach is intuitive to detect pneumonia interpretably. We first build a large dataset of community-acquired pneumonia consisting of 35389 cases (distinguished from nosocomial pneumonia) based on actual medical records. Second, we train a prediction model with the chest X-ray images in our dataset, capable of precisely detecting pneumonia. Third, we propose an intuitive approach to combine neural networks with an explainable model such as the Bayesian Network. The experiment result shows that our proposal further improves the performance by using multi-source data and provides intuitive explanations for the diagnosis results.INDEX TERMSPneumonia, computer-aided diagnosis, medical image analysis, interpretive medical-assisted diagnosis, large-scale annotated X-ray image dataset. This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 9, 2021 YING ZHANG received the B.E. degree from Shenzhen University, China, in 2020, where she is currently pursuing the M.S. degree. Her research interests include machine learning, deep learning, and particularly medical image analysis. JIANWEI HE is currently pursuing the B.Eng. degree with Shenzhen University, China. His research interests include deep learning and medical image analysis.\n\nI. INTRODUCTION\n\nPneumonia is a respiratory infection caused by bacteria, viruses, or fungi, and it has been known as a quite common and potentially fatal disease in the past two centuries. The incidence rate of Pneumonia is quite high in the extreme-age group. Around 450 million people (or about 7% of the world's population) were diagnosed with pneumonia each year; and about 4 million deaths were reported [1]. The diagnoses of The associate editor coordinating the review of this manuscript and approving it for publication was Yizhang Jiang . pneumonia usually start with examinations of chest X-ray images by well-trained specialists [2]. Preliminary results are then written into examination reports and submitted to clinicians. The final conclusions are given by the clinicians according to the analysis on the reports and some clinical symptoms. This process is usually cumbersome and sometimes leads to disagreements between clinicians [3]. Moreover, the signs and symptoms of pneumonia vary on different causes, patients and other factors, and the conditions of the disease usually change rapidly, which makes the pneumonia detection complicated. Existing computer-aided diagnosis systems for pneumonia usually take chest X-ray images, Computed Tomographies (CT), or Magnetic Resonance Images (MRI) as input [4]. But practically, in a real diagnosis procedure, a human physician uses not merely these images, but also some observable clinical features as criteria. Symptoms such as fever, cough, and chest pain are also very crucial to detect the disease. Motivated by the diagnosis process of human experts, we combine the clinical observation with the medical images. We propose a model named MulNet in this paper, which uses 7 typical symptoms and the chest X-ray images as input for pneumonia detection, as shown in Figure 1. The results show that, the combination of deep learning and Bayesian Network can improve the performance, as well as the interpretability of the system. Bayesian Network structure construction methods are divided into a scoring-based method and a constraint-based method [5]. The score-based method selects the structure with the highest score as the best Bayesian Network structure from the sampled structure according to the scoring criteria (such as K2 [6], BIC [7]). However, this method ignores the relationship between the result node and the factor nodes. So we propose a constraint-based algorithm that combines medical knowledge to build a reasonable Bayesian Network structure.\n\nTo be specific, we first build a large dataset of community-acquired pneumonia (distinguished from nosocomial pneumonia) based on real medical records consisting of 35389 cases. Second, we train a prediction model with chest X-ray images and reports, which is capable of precisely detect pneumonia. Third, we propose an intuitive approach to combine neural networks with Bayesian Network, which provides intuitive explanations for the diagnosis results. The experiment result shows that our proposal not only further improves the performance by using multi-source data, but also provides intuitive explanations for the diagnosis results.\n\nTo summarize, the main contributions of this work are as follows:\n\n1) We establish a large data set for pneumonia detection, which contains 35389 cases (section III). 2) We propose an intuitive method to integrate multisource data such as chest X-ray images and clinical reports in natural language to predict pneumonia (section V). 3) We propose an approach to combine medical knowledge with a Bayesian Network, which constructs a reasonable Bayesian Network structure and improves pneumonia detection's interpretability (section V).\n\nWe believe that our proposal is general enough to be used in other prediction models by fine-tuning, and is straightforward to be extended by using other explainable models such as Situation Calculus, Nonmonotonic Logics, Latent Trees, etc.\n\n\nII. RELATED WORK A. THE DATASETS OF PNEUMONIA\n\nInitially, [8]- [10] proposed the non-large-scale labeled datasets (under 2000 samples). It is challenging to train a meaningful model with deep learning by the initial dataset. In recent works, [2] build a hospital-scale chest X-Ray database called ChestX-ray8, which contains 32717 cases with eight common thoracic diseases. Later in 2017, [11] used DenseNet Image Encoder to classify pneumonia with VOLUME 9, 2021 AUC of 0.713. [12] developed CheXnet with 121 convolutional layers and yielded AUC 0.7680 in pneumonia prediction. Significantly, CheXpert [13] is a large dataset with 224316 samples chest radiographs from 65240 patients. However, the number of pneumonia cases in CheXpert is insufficient because its pneumonia cases are lower than 5000. Mendeley Dataset [14] with 5232 chest X-ray images (3883 pneumonia and 1349 normal) was collected from a Children's medical center in Guangzhou, China. Chest X-Ray Images Pneumonia [15] is a part of Mendeley and Cohen JP Dataset [15], authority prepared the dataset by checking and screening raw images to ensure quality. Our dataset contains a total of 44327 chest X-ray images, far more than other datasets. All other pneumonia datasets are from physical examination records, and our dataset is from the actual medical records in outpatient and inpatient. Therefore, there are two types of chest X-ray images in other datasets: pneumonia and normal, but our dataset includes pneumonia and other diseases. The classification of pneumonia and other diseases is more practical and more challenging clinically.\n\n\nB. THE PNEUMONIA DIAGNOSIS MODELS\n\nFew studies used multimodal medical datasets influenced by [16]. Most models are based on a CNN-RNN framework to achieve transforming image information into semantic information. Obviously, [17]- [19] are dedicated to generating medical reports through medical imaging. As a result, the transformed semantic information is a co-attention model with image information [20]. On the other hand, integrating reports with medical images is used to improve the ability of disease diagnosis [21], [22]. Likewise, [23] trained a small-scale image dataset to diagnose diseases. Still, its results compared using only reports and using only images with increased accuracy of 4% and 7%. Nevertheless, it is not efficient enough on large-scale datasets. Recently, a method was proposed to screen features using CNN and machine learning, which worked well for feature extraction but did not use features to diagnose pneumonia [24]. [25] automatic binary classification of pneumonia images based on fined-tuned versions of CNN. [26] and [27] proposed using CNN and transfer learning to diagnose pneumonia, but Ima-geNet [28] is generally used to train pre-trained models. However, these pneumonia classification models only use chest X-ray images to diagnose pneumonia, ignoring the impact of clinical symptoms.\n\n\nC. THE EXPLAINABLE MODELS\n\nDue to the successful application of deep learning on images such as face recognition [29], the 3D face-alignment method [30], which can run on a CPU in real-time, is used in human life. CAD uses deep learning to improve the accuracy of diagnosis. An effective CAD system for all cell identity from microscopic blood images was recently proposed [31], which first extracts all categories of cells and then extracts each cell's characteristics. But the current CAD system lacks interpretability.\n\nGradient-weighted Class Activation Mappings (Grad CAMs) is widely practiced in current medical interpretations [32]. To achieve an explanatory model for disease diagnosis, [2], [33] implemented Grad CAMs through images that can display the concerning location. Besides, the latent tree has obtained excellent results in the interpretability of Chinese medicine, which deployed data-driven methods and provided a theoretical foundation for the disease classification [34]- [36]. The two explainable approaches mentioned above differ from the explanatory nature of our proposal. The formers utilized only images as a competent diagnosis of multiple diseases, and the latter only classified the division of diseases.\n\n\nIII. DATA PREPARATION\n\nWe propose a systematic method to create the pneumonia dataset: first, pneumonia can be categorized into CAP (community-acquired pneumonia) and HAP (nosocomial pneumonia). In this work, we mainly focus on CAP, which is acquired in the community; therefore, we merely selected pneumonia cases from the respiratory medicine department and pediatric department. Then, we select pneumonia cases based on the ICD-10 [37] code in the records. In the electronic medical records collection process, the coding staff codes the diseases according to the doctor's reports and diagnosis results. Pneumonia is a broad concept. For example, the ICD-10 code of Haemophilus influenzae pneumonia is J14, and the ICD-10 code of streptococcal pneumonia is J13. Finally, we select the codes J12 to J18 (including J12 and J18) as the pneumonia codes. 35389 cases in the dataset were performed both inpatient and outpatient between October 2017 and January 2020. Some cases of pneumonia also have other diseases; similarly, most cases without pneumonia have other diseases. To build a model that can be applied to more patients, the dataset is created from patients with many age groups, including cases of the elderly and children. Considering the difference in the diagnosis of patients with long-term pneumonia, we only use the first record.\n\nCommunity-acquired pneumonia (CAP) is a common disease with potential life risk, especially in the elderly and patients with comorbidities [38]. The clinical diagnosis of CAP includes three phases: 1) community onset; 2) Clinical manifestations of pneumonia; 3) chest imaging examination. Clinical diagnosis can be established after meeting only 1), 2) or 3) excluding other diseases, such as tuberculosis and lung tumor. Therefore, in the process of diagnosing CAP, clinical manifestations are significant. The potential relationship between various clinical manifestations can provide a more reliable basis for Computer-Aided Diagnosis. The 7 indicators, 1) cough, 2) hemoptysis, 3) chest pain, 4) fever, 5) dyspnea, 6) wet rales, and 7) dry rales, are described by the pneumonia diagnosis through the Internal Medicine as Figure 2.\n\nWe extracted the required clinical manifestations from the reports and made valid tags of each report resulting in Training-BN, as shown in Figure 2. According to pneumonia  diagnosis, it is acknowledged that cough, hemoptysis, chest pain, fever, dyspnea, wet rales, and dry rales are essential criteria. So, we extract clinical manifestations related to cough, hemoptysis, chest pain, fever, dyspnea from the chief complaint, and wet rales and dry rales from the physical examination. We set the corresponding binary bit to ''1'' if the patient developed any one of the symptoms. For example, tag ''1001001'' identified that the patient developed a cough, fever, dry rales, and no other symptoms. We designed some basic textual processing to extract clinical manifestations from the chief complaint and physical examination. Taking ''fever'' as an example: first, we observed that the doctors generally use the words either ''fever'' or ''no fever'' to record whether the patient catches a fever. Then, we split the chief complaint by each Chinese punctuations like '', '' and '';.'' Then, we extracted the sentences containing ''heat.'' If the keyword in a sentence is ''heat,''; the bit is marked as ''1'' (the word ''heat'' is also means ''fever'' in Chinese.) Moreover, considering that some doctors might have their expression style, we manually reviewed each sentence containing ''heat'' and corrected the tag if ''heat'' was found.\n\n\nIV. DATA SPLITTING\n\nWe divide the dataset with X-ray images and electronic medical records into three parts: 1) CNN training set (Training-CNN), 2) Bayesian Network training set (Training-BN), and 3) test sets. Examples of chest X-ray images are shown in Figure 3, the left side of the figure is a chest X-ray image of a patient suffering from pneumonia, with patchy shadows in the red box, and the right side of the figure is a normal person's chest X-ray image.\n\nSimilar to CheXpert, the CNN Training set consists of chest X-ray images and their corresponding tags. In CheXpert, an image owns not only the tag of pneumonia, but also the tags of other 13 lung diseases, otherwise than, the images in CNN Training Set correspond to tags merely of pneumonia. The CNN training set is further divided into three for multiple training rounds. After training, the CNN model takes X-ray images as input and gives diagnosis result, which is either positive or negative. The result can be further associated with the data as a label for Bayesian Network training. Here are two types of test sets: 1) Test-CNN and 2) Test-BN. Test-CNN and Test-BN had the same chest X-ray images, but Test-BN contained not only the chest X-ray images but also the corresponding reports adding each chest X-ray image. Inevitably, Training-CNN and Training-BN have non-overlapping data. See Table 1 for the description details of Training-CNN, Training-BN, Test-CNN, and Test-BN.\n\nOur test set are annotated by two respiratory specialists, in order to accurately label data within a limited time, 200 cases are randomly selected as the test set, and the proportion of pneumonia in the test set is 50%. We created a website showing the chest X-ray images and the admission record of each case to assist physicians in annotating. In each case may have frontal or lateral radiographs or both. We took the notes from two physicians and the final diagnosis corresponding to each case as the ground truth. If two physicians annotated a case positive, it would be marked as positive; otherwise, it would be negative.  \n\n\nV. THE PROPOSED APPROACH A. IMAGE MODEL WITH CNN\n\nThe training process is divided into two steps. Firstly using CheXpert dataset to train DenseNet121 as a pre-training model, and secondly continue to train the pre-training model on Train-CNN dataset, converting the probability into 0 or 1 as the output. The details are as follows:\n\nCheXpert is a large chest X-ray image dataset, which also contains pneumonia data. By CheXpert, we have trained a well-performed pre-training model. We implemented DenseNet121 [39] as our model. DenseNet proposes a more radical dense connection mechanism than traditional networks. All layers are connected; specifically, each layer accepts all the layers ahead as its additional input. This connection enhances the reuse of features and allows the final classifier to make decisions based on all the characteristics of the entire network, see Figure 4. The model input x 0 is the chest X-ray image owned by the case, and the model has a total of l layers. H l () is the non-linear transformation. [x 0 , x 1 ,.., x l\u22121 ] indicates the concatenation of the feature-maps produced in each layer. x l represents the output of the model, and Equation 1 shows the reuse of features for calculation x l .\nx l = H l ([x 0 , x 1 , . . . , x l\u22121 ])(1)\nChest X-ray images of pneumonia were fed into the network with the size of 320 \u00d7 320 pixels. The \u03b2-parameters of Adam optimizer were set to default at \u03b2 1 = 0.9, \u03b2 2 = 0.999, and the learning rate was 1 \u00d7 10 4 .\n\nWe trained a new model of pneumonia diagnosis from the CheXpert data and our dataset. The AUC score on the CheXpert's validation set was 0.74. Then, we trained our three batches to get the best CNN model.\n\nWe built a Training-CNN dataset to train the pre-training model. In addition, we have adopted some data augmentation technologies, in which each example was rotated randomly between \u221225 and 25 degrees, shifted randomly between \u221225 and 25 pixels, and flipped horizontally with 50% probability while in training. To took the CNN output as the input of the Bayesian Network, we calculated the Youden's index [40] as the threshold to convert the probability value of the CNN model output into 0 or 1.\n\n\nB. MULNET\n\nA pure connectionist approach can provide diagnostic results, but it lacks interpretability and transparency. Therefore, the model needs to be able to diagnose pneumonia and have interpretability. We trained a Bayesian Network to diagnose pneumonia, which was called MulNet. As shown in Figure 6, the training dataset we used is Training-BN, in which the chest X-ray image is the input from the trained CNN model, and the output of the model is 0 or 1. The clinical manifestations in the reports in Training-BN were extracted into a 7-dimensional vector through the specific textual processing. As a final input of MulNet, the 7-dimensional vector and the CNN model's binary output were contacted into an 8-dimensional vector.\n\nIn the construction of the Bayesian Network, we hope to be able to combine medical knowledge. Cough, hemoptysis, chest pain, fever, dyspnea, wet rales, and dry rales are essential factors in the diagnosis of pneumonia, and chest X-ray image is also an essential part of the diagnosis of pneumonia, so the classification model should be able to combine all features to diagnose pneumonia.\n\nSo the Bayesian Network should be able to take into account the following requirements: 1) a total of 9 nodes ''cough'', ''hemoptysis'', ''chest_pain'', ''fever'', ''dyspnea'', ''wet_rales'', ''dry_rales'', ''pictures'' and ''pneumonia_or_not''; 2) automatically extract the dependencies between from the factor nodes ''cough'', ''hemoptysis'', ''chest_pain'', ''fever'', ''dyspnea'', ''wet_rales'', ''dry_rales'', ''pictures'' from data; 3) the factor nodes are in the same Markov blanket as the result node ''pneumonia_or_not'', which means that the factor nodes and the result node are not independent; 4) the factor nodes all point to the result node.\n\nWe propose an algorithm called MGS to construct the Bayesian Network structure by improving the constraintbased GS algorithm [5] shown in Algorithm 1. for each S \u2286 B do 7: if CONDINDEP(X,Y,S) then remove link X-Y from G; 8: break 9: end if 10: end for 11: end for /* Orient edges */ 12: for each X \u2208 {V } and Y \u2208 Bd(X ) do 13: for each Z \u2208 Bd(X ) \\ Bd(Y ) \\ {Y } do 14: orient Y \u2192 X /* to be corrected if a test yields independence */ 15: 16: for each S \u2286 B do 17: if CONDINDEP(Y,Z,B) and X ! = V 0 then remove orientation Y \u2192 Z; 18: break 19: end if 20: end for 21: if Y \u2192 X then break 22: end if 23: end for 24: end for 25: return G In this code, V 0 stands for the result node, Mb(X ) stands for the boundary of X , we note a conditional independence test with a subroutine call CONDINDEP(X , Y , Z ): ideally, this function returns true when (X \u22a5Y | Z ) holds, and false otherwise. The algorithm first computes the Markov blanket for each factor nodes from data and then defines the Markov blanket for the result node as all factor nodes (''cough'', ''hemoptysis'', ''chest_pain'', ''fever'', ''dyspnea'', ''wet_rales'', ''dry_rales'', ''pictures''). This solves the problem that the result node and the factor nodes are not in the same Markov blanket.\nB \u2190 smallest set of {Mb(Y ) \\ {Z } , Mb(Z ) \\ {Y }}\nStep 2 selects the smallest base search set for each phase and performs further conditional-independence tests around each variable to infer the structure locally.\n\nStep 3 of the algorithm orients the arcs whenever it finds that conditioning on a middle node creates a dependency without V 0 (''pneumonia_or_not'') and all nodes connected to V 0 point to V 0 . According to this algorithm, the Bayesian Network is constructed as shown in Figure 5.\n\n\nVI. IMPLEMENTATION & EVALUATION A. MATRIC\n\nIn order to test the effectiveness and robustness of the binary classification pneumonia model, the commonly medical standards are used to measure the performance of the model, that is, recall, precision, F1-score and AUC (Area Under the ROC Curve) [41].\n\nThe recall is defined as (2):\nrecall = TP TP + FN (2)\nThe precision is defined as (3):\nprecision = TP TP + FP(3)\nThe higher the recall, the lower the accuracy and vice versa in most cases. F1-score is defined to take both recall and precision into consideration (4):\nF1 = 2 * precision * recall precision + recall(4)\nAUC is defined as the area under the ROC curve. Obviously, the value of this area will not be greater than 1. Because the ROC curve is usually above the y = x line, the value ranges of AUC are from 0.5 to 1. If the AUC is larger, the classifier is better.\n\nTwo types of 95% confidence intervals are generally constructed around proportions: exact 95% confidence interval and asymptotic. Because the sample proportion is a good approximation of normal distribution, asymptotic confidence VOLUME 9, 2021 interval is used to calculated by assuming a normal approximation of the sampling distribution.\n\n\nB. TRAINING\n\nThe experimental environment was an Ubuntu Linux server with Kaby Lake GT2 GPU. The CNN model was implemented with PyTorch [42] (GPU and Ubuntu versions) framework, and BN and DT had been implemented with Scikit-learn [43] framework. The entire experimental process was divided into six steps.\n\nStep One: we trained a pre-trained model on CheXpert with DenseNet, and the AUC of CheXpert's validation was 0.74.\n\nStep Two: we continued to train the pre-training model with our X-ray image dataset, i.e., Training-CNN. To improve the reliability of the experiment and to reduce the accidental error, we trained three times to obtain 3 CNN models, which had an average AUC of 0.90. It increased by 0.16 percent comparing to the previous test on the validation set of CheXpert.\n\nStep Three: we predicted our chest X-ray dataset of Training-BN and Test-BN. We transformed the output of trained CNN models from probability values to 0 or 1.\n\nStep Four: a 7-dimensional vector is extracted from the report dataset corresponding to the chest X-ray dataset, i.e., the clinical manifestations in each report of the Training-BN and Test-BN.\n\nStep Five: label outputs from CNN was contacted with each 7-dimensional vector extracted from the report. As a result, there were 8-dimensional vectors.\n\nStep Six: construct a Bayesian Network structure called MulNet, then train and test MulNet. See Figure 6 for the complete training process.\n\nWhen training Bayesian Network, a 10-fold crossvalidation method is used to select the best parameters and avoid over-fitting with the partitioning. First, the training set is divided into ten parts, nine parts are used as the training set, and the rest is used as the validation set. Then the training was repeated ten times, and the AUC average was used as the evaluation criterion to select the best model.\n\n\nC. COMPARISON AND DISCUSSION OF STATISTICAL MANIFESTATIONS\n\nThe Figure 7 shows the calibration curve of MulNet and the estimated probabilities obtained with MulNet by both Isotonic calibration [44] and Sigmoid calibration [45]. The calibration performance is evaluated with Brier score [46], reported in the legend (the smaller the better). Isotonic calibration and Sigmoid calibration also improves the Brier score slightly.\n\nWe selected three models for comparison, and they were Support Vector Machine (SVM) with linear kernel, Random Forest, Decision Tree (DT) respectively. Then use the 10-fold cross-validation to select the best parameters and calculate the average AUC value for ten training sessions [47]. The average AUC of MulNet is 0.86, the average of AUC of DT is 0.87, the average of AUC of Random Forest is 0.86, and the average of SVM is 0.77(we calculate the functional distance from the sample point to the segmented hyperplane and then convert the distance into a probability value).\n\nAs shown in Table 2, except that the precision of MulNet is slightly lower than DT, the other are the highest. MulNet achieves an AUC of 0.87(95% CI 0.82, 0.92), a precision of 0.73(95% CI 0.65, 0.80), a recall of 0.94(95% CI 0.85, 0.98), and an F1-score of 0.82(95% CI 0.74, 0.88). Since the features extracted from reports and chest X-ray images are low-dimensional vectors, the AUC value of SVM can also reach 0.79(95% CI 0.74, 0.84). Meanwhile, to evaluate the statistical significance of the clinical information, we implement the paired t-tests (95% significance level) on regression performances of our model and the competing models. In terms of classification capabilities, the performance gap between Random Forest, DT, and MulNet is not obvious, but MulNet has a greater advantage in interpretability.\n\n\nD. INTERPRETATIVE VARIABLES OF MULNET\n\nIn addition to the ability to classify pneumonia accurately, MulNet is more importantly explainable. Compared with SVM, Random Forest and DT, MulNet shows the relationship between different factor nodes. For any result of diagnosis, the probability from root (result node) to leaf (factor nodes) can be analyzed.\n\nAs shown in Figure 8, when fever symptoms occur, that is, the probability of fever is 1, the Bayesian Network can be used to predict the probability of ''cough'', ''hemoptysis'', ''chest_pain'', ''fever'', ''dyspnea'', ''wet_rales'', ''dry_rales'', ''pictures'', and ''pneumonia_or_not'' is 0.79, 0.01, 0.02, 0.01, 0.10, 0.15, 0.68, 0.55. By analyzing this probability value, a fever patient is usually accompanied by   cough, and there is a high probability of abnormalities in the chest X-ray images. More than half of the probability will be pneumonia infection.\n\nThe Bayesian Network assigns a conditional probability table (CPT) to each variable, and CPT is used to explain the causality between nodes. We will display and analyze the conditional probability table of some nodes. Table 3 shows the conditional probability table of the node ''pictures''. When fever symptoms occur, the possibility of abnormalities in the chest X-ray images is the greatest, with a probability of 0.69. However, the occurrence of chest pain, on the contrary, reduces the possibility of abnormalities in the chest X-ray images. When chest pain occurs, regardless of whether fever symptoms occur, the possibility of abnormalities in the chest X-ray images is below 0.35, and the probability that both symptoms do not occur similar. Medically speaking, patients with pneumonia may be accompanied by chest pain, but chest pain is more common in other diseases, and fever is a common symptom in patients with pneumonia. The conditional probability table explains this phenomenon. Table 4 shows part of the conditional probability table of the ''pneumonia_or_not'' node. When the patient has a fever, the probability of suffering from pneumonia is 0.15. The probability of pneumonia when the patient has a fever and abnormalities in the chest X-ray images is 0.60. When the patient not only has fever and abnormalities in the chest X-ray images but also has chest pain, the probability of pneumonia is 0.92. According to the conditional probability table, it can VOLUME 9, 2021  be inferred that when the patient has fever and abnormalities in the chest X-ray images, there is more than half of the probability of suffering from pneumonia. When the patient has a fever, abnormalities in the chest X-ray images, and wet rales, it is almost certain that the patient suffered pneumonia.\n\n\nVII. DISCUSSION\n\n\nA. PERFORMANCE COMPARISON OF CNN MODELS\n\nIn MulNet, the CNN model is an essential part used to learn and analyze chest X-ray images. The CNN model chosen in this paper is DenseNet121. Before choosing this model, a variety of models were trained and tested on Test-CNN. The comparison models we select are Inception-V4, ResNet, Xception, and AlexNet. As shown in Figure 9, using AUC and F1-score as indicators to evaluate the performance of the model, DenseNet's AUC and F1-score values are 0.829 and 0.759, respectively, which are the best in both indicators. The experimental results demonstrate that the feature reuse  technique, DenseNet121, is more suitable for learning chest X-ray images.\n\n\nB. THE IMPACT ON THE DIFFERENT TYPES OF DATA INPUT\n\nWe trained DenseNet model to estimate the ''pictures'' node values of the Bayesian Network by creating Training-BN and Testing-BN. We respectively compared the AUC values of the three different input models as shown in Figure 10: 1) The AUC was 0.865 when MulNet integrates chest X-ray images and the clinical the reports; 2) The AUC was 0.829 when we took only chest X-ray images to diagnose via DenseNet; 3) When we took only the reports to diagnose pneumonia by MulNet, the AUC is 0.801. It confirms that combining the two different types of information to diagnose pneumonia has the most substantial AUC value. Furthermore, the AUC of chest X-ray images result is better than the report.\n\n\nC. THE WEIGHTS OF DIFFERENT NODES IN THE DECISION TREE\n\nAfter the DT training, we could calculate the weight distribution of the different nodes in the DT. The results are presented in Figure 11, which indicates that the ''pictures'' node takes up the highest weight, exceeding 0.6. ''cough,'' ''fever,'' ''wet_rales,'' and ''dry_rales'' also had a large proportion of weight, but the weight of ''hemoptysis,'' ''chest_pain,'' and ''dyspnea'' were low. The medical manifestation and the X-rays image are the most important for clinical diagnosis. Similarly, analyzing the condition from the chest X-ray images or CT and then looking at essential symptoms such as cough, fever, wet rales, and dry rales. Note that hemoptysis, chest pain, and dyspnea are not typical symptoms in pneumonia patients.\n\n\nVIII. CONCLUSION\n\nIn this paper, we propose a multi-data and interpretive medical-assisted diagnosis model for pneumonia, and we have created a large-scale dataset of pneumonia diagnosis annotated by respiratory specialists. Our model consists of CNN and the Bayesian Network (BN) combined with two types of data: 1) chest X-ray images and 2) medical reports. Moreover, the model provides diagnostic explanatory information giving that physicians can have a better understanding of the diagnosis result. The results showed that our model was better than just using only images or only reports. The model works best when compared to a variety of baselines. Next, we are working on to classify pneumonia deeper, such as to determine whether it is bacteria, viruses, or fungi. In the future, we may add a knowledge map as the input of the model. We are constructing a large-scale knowledge graph related to pneumonia, so that the classification ability of the model will be further improved.  \n\nFIGURE 1 .\n1An overview of the framework.\n\nFIGURE 2 .\n2The output of some basic textual processing when run on a report sampled from our dataset. In this case, the labeler correctly extracts all of the clinical manifestations in the report (bold) and classifies the positive ones and negative ones.\n\nFIGURE 3 .\n3Examples of chest X-ray images.\n\nFIGURE 4 .\n4DenseNet with 3 layers.\n\n\nInput: D: the training set. Output: G: partially oriented DAG /* Compute Markov Blankets */ 1: For all X \u2208 {V \u2212 V 0 }, compute the Markov blanket Mb(X ) 2: Mb(V 0 ) = {V \u2212 V 0 } /* Compute graph structure */ 3: G \u2190 moral graph according to Mb(\u00b7) 4: for each X \u2208 V and Y \u2208 Mb(X ) do 5: B \u2190 smallest set of {Bd(X ) \\ {Y } , Bd(Y ) \\ {X }} 6:\n\nFIGURE 5 .\n5Bayesian network structure.\n\nFIGURE 6 .\n6Training process.\n\nFIGURE 7 .\n7Calibrate MulNet by isotonic and sigmoid, the value in brackets is brier score.\n\nFIGURE 8 .\n8The model predicts the probability value of other nodes when fever occurs.\n\nFIGURE 9 .\n9Performance comparison of CNN models.\n\nFIGURE 10 .\n10The AUC on the different types of data input.\n\nFIGURE 11 .\n11Weight of each node in the DT.\n\nACKNOWLEDGMENT(\nHao Ren, Aslan B. Wong, and Wanmin Lian contributed equally to this work.) QINGFENG LIU received the degree from the University of South China. He is the Deputy Chief Physician and concurrently a member of the Interventional Therapy Group of the Guangdong Medical Doctor Association, the Guangdong Sleep Respiratory Society, and the Lung Cancer Professional Committee of the Guangdong Association of Thoracic Diseases. He specializes in the diagnosis and treatment of respiratory diseases, such as bronchiectasis, pneumonia, lung cancer, sleep apnea syndrome, and asthma. He has published many related academic articles. JIASHENG YANG received the master's degree in medicine from Guangzhou Medical University. Since 2015, he has been engaged in clinical work with the Department of Respiratory Medicine, Guangdong Second Provincial General Hospital. He is the Deputy Chief Physician. CHEN JASON ZHANG (Member, IEEE) received the Ph.D. degree from the Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, in 2015. He is currently a Postdoctoral Research Fellow with The Hong Kong University of Science and Technology and an Associate Professor at the Shandong University of Finance and Economics. His research interests include crowdsourcing and data integration. KAISHUN WU (Member, IEEE) received the Ph.D. degree in computer science and engineering from HKUST, in 2011. He was a Research Assistant Professor with HKUST. In 2013, he joined Shenzhen University as a Distinguished Professor. He has coauthored two books and published over 90 high-quality research articles in international leading journals and primer conferences, such as the IEEE TRANSACTIONS ON MOBILE COMPUTING, the IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS, ACM MobiCom, and IEEE INFOCOM. He has invented six U.S. and over 80 Chinese pending patents. He was a recipient of the 2012 Hong Kong Young Scientist Award and the 2014 Hong Kong ICT Awards: Best Innovation and the 2014 IEEE ComSoc Asia-Pacific Outstanding Young Researcher Award. He is an IET Fellow. HAODI ZHANG received the Ph.D. degree from the Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, in 2016. He is currently an Assistant Professor with the Guangdong Laboratory of Artificial Intelligence and Digital Economy, College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China. His current research interests include deep reinforcement learning, knowledge representation and reasoning, explainable artificial intelligence, artificial intelligence in communication, buffer-aided relaying, and wireless information.\n\nTABLE 1 .\n1Summary statistics of training and test datasets.\n\nTABLE 2 .\n2Classification performance of various methods, boldface denotes best performance.\n\nTABLE 3 .\n3The conditional probability table of the node ''pictures'', t stands for true, f stands for false.\n\nTABLE 4 .\n4Part of the conditional probability table of the node ''pneumonia_or _not ''.\n\nViral pneumonia. O Ruuskanen, E Lahti, L C Jennings, D R Murdoch, Lancet. 3779773O. Ruuskanen, E. Lahti, L. C. Jennings, and D. R. Murdoch, ''Viral pneumonia,'' Lancet, vol. 377, no. 9773, pp. 1264-1275, 2011.\n\nChestX-ray8: Hospital-scale chest X-ray database and benchmarks on weaklysupervised classification and localization of common thorax diseases. X Wang, Y Peng, L Lu, Z Lu, M Bagheri, R M Summers, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers, ''ChestX- ray8: Hospital-scale chest X-ray database and benchmarks on weakly- supervised classification and localization of common thorax diseases,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 2097-2106.\n\nVariability in the interpretation of chest radiographs for the diagnosis of pneumonia in children. M I Neuman, E Y Lee, S Bixby, S Diperna, J Hellinger, R Markowitz, S Servaes, M C Monuteaux, S S Shah, J. Hospital Med. 74M. I. Neuman, E. Y. Lee, S. Bixby, S. Diperna, J. Hellinger, R. Markowitz, S. Servaes, M. C. Monuteaux, and S. S. Shah, ''Variability in the interpre- tation of chest radiographs for the diagnosis of pneumonia in children,'' J. Hospital Med., vol. 7, no. 4, pp. 294-298, Apr. 2012.\n\nA transfer learning method with deep residual network for pediatric pneumonia diagnosis. G Liang, L Zheng, Comput. Methods Programs Biomed. 187Art. no. 104964G. Liang and L. Zheng, ''A transfer learning method with deep residual network for pediatric pneumonia diagnosis,'' Comput. Methods Programs Biomed., vol. 187, Apr. 2020, Art. no. 104964.\n\nLearning Bayesian network model structure from data. D Margaritis, School Comput. Sci. Carnegie Mellon Univ.Tech. Rep.D. Margaritis, ''Learning Bayesian network model structure from data,'' School Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA, Tech. Rep., 2003.\n\nImproving Bayesian network structure learning with mutual information-based node ordering in the K2 algorithm. X.-W Chen, G Anantha, X Lin, IEEE Trans. Knowl. Data Eng. 205X.-W. Chen, G. Anantha, and X. Lin, ''Improving Bayesian network structure learning with mutual information-based node ordering in the K2 algorithm,'' IEEE Trans. Knowl. Data Eng., vol. 20, no. 5, pp. 628-640, May 2008.\n\nA widely applicable Bayesian information criterion. S Watanabe, J. Mach. Learn. Res. 14S. Watanabe, ''A widely applicable Bayesian information criterion,'' J. Mach. Learn. Res., vol. 14, pp. 867-897, Mar. 2013.\n\nA multi-center milestone study of clinical vertebral CT segmentation. J Yao, J E Burns, D Forsberg, A Seitel, A Rasoulian, P Abolmaesumi, K Hammernik, M Urschler, B Ibragimov, R Korez, T Vrtovec, I Castro-Mateos, J M Pozo, A F Frangi, R M Summers, S Li, Comput. Med. Imag. Graph. 49J. Yao, J. E. Burns, D. Forsberg, A. Seitel, A. Rasoulian, P. Abolmaesumi, K. Hammernik, M. Urschler, B. Ibragimov, R. Korez, T. Vrtovec, I. Castro-Mateos, J. M. Pozo, A. F. Frangi, R. M. Summers, and S. Li, ''A multi-center milestone study of clinical vertebral CT segmentation,'' Comput. Med. Imag. Graph., vol. 49, pp. 16-28, Apr. 2016.\n\nA new 2.5 D representation for lymph node detection using random sets of deep convolutional neural network observations. H R Roth, L Lu, A Seff, K M Cherry, J Hoffman, S Wang, J Liu, E Turkbey, R M Summers, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent. Int. Conf. Med. Image Comput. Comput.-Assist. InterventSpringerH. R. Roth, L. Lu, A. Seff, K. M. Cherry, J. Hoffman, S. Wang, J. Liu, E. Turkbey, and R. M. Summers, ''A new 2.5 D representation for lymph node detection using random sets of deep convolutional neural network observations,'' in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent. Springer, 2014, pp. 520-527.\n\nDeepOrgan: Multi-level deep convolutional networks for automated pancreas segmentation. H R Roth, L Lu, A Farag, H.-C Shin, J Liu, E B Turkbey, R M Summers, Proc. Int. Conf. Med. Image Comput. Int. Conf. Med. Image ComputSpringerH. R. Roth, L. Lu, A. Farag, H.-C. Shin, J. Liu, E. B. Turkbey, and R. M. Summers, ''DeepOrgan: Multi-level deep convolutional networks for automated pancreas segmentation,'' in Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent. Springer, 2015, pp. 556-564.\n\nLearning to diagnose from scratch by exploiting dependencies among labels. L Yao, E Poblenz, D Dagunts, B Covington, D Bernard, K Lyman, abs/1710.10501L. Yao, E. Poblenz, D. Dagunts, B. Covington, D. Bernard, and K. Lyman, ''Learning to diagnose from scratch by exploiting dependencies among labels,'' CoRR, vol. abs/1710.10501, pp. 1-12, Oct. 2017. [Online]. Avail- able: http://arxiv.org/abs/1710.10501\n\nLearning to diagnose from scratch by exploiting dependencies among labels. L Yao, E Poblenz, D Dagunts, B Covington, D Bernard, K Lyman, arXiv:1710.10501L. Yao, E. Poblenz, D. Dagunts, B. Covington, D. Bernard, and K. Lyman, ''Learning to diagnose from scratch by exploiting dependen- cies among labels,'' 2017, arXiv:1710.10501. [Online]. Available: http:// arxiv.org/abs/1710.10501\n\nJ Irvin, P Rajpurkar, M Ko, Y Yu, S Ciurea-Ilcus, C Chute, H Marklund, B Haghgoo, R Ball, K Shpanskaya, J Seekins, D A Mong, S S Halabi, J K Sandberg, R Jones, D B Larson, C P Langlotz, B N Patel, M P Lungren, A Y Ng, CheXpert: A large chest radiograph dataset with uncertainty labels and expert comparison,'' in Proc. AAAI Conf. 33J. Irvin, P. Rajpurkar, M. Ko, Y. Yu, S. Ciurea-Ilcus, C. Chute, H. Marklund, B. Haghgoo, R. Ball, K. Shpanskaya, J. Seekins, D. A. Mong, S. S. Halabi, J. K. Sandberg, R. Jones, D. B. Larson, C. P. Langlotz, B. N. Patel, M. P. Lungren, and A. Y. Ng, ''CheXpert: A large chest radiograph dataset with uncertainty labels and expert comparison,'' in Proc. AAAI Conf. Artif. Intell., vol. 33, 2019, pp. 590-597.\n\nIdentifying medical diagnoses and treatable diseases by imagebased deep learning. D S Kermany, M Goldbaum, W Cai, C C S Valentim, H Liang, S L Baxter, A Mckeown, G Yang, X Wu, F Yan, J Dong, Cell. 1725D. S. Kermany, M. Goldbaum, W. Cai, C. C. S. Valentim, H. Liang, S. L. Baxter, A. McKeown, G. Yang, X. Wu, F. Yan, and J. Dong, ''Identifying medical diagnoses and treatable diseases by image- based deep learning,'' Cell, vol. 172, no. 5, pp. 1122-1131, 2018.\n\nSo you need datasets for your COVID-19 detection research using machine learning?. M F Sohan, arXiv:2008.05906'' 2020. M. F. Sohan, ''So you need datasets for your COVID-19 detection research using machine learning?'' 2020, arXiv:2008.05906. [Online]. Available: http://arxiv.org/abs/2008.05906\n\nDeep visual-semantic alignments for generating image descriptions. A Karpathy, L Fei-Fei, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)A. Karpathy and L. Fei-Fei, ''Deep visual-semantic alignments for gen- erating image descriptions,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2015, pp. 3128-3137.\n\nA hierarchical approach for generating descriptive image paragraphs. J Krause, J Johnson, R Krishna, L Fei-Fei, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)J. Krause, J. Johnson, R. Krishna, and L. Fei-Fei, ''A hierarchical approach for generating descriptive image paragraphs,'' in Proc. IEEE Conf. Com- put. Vis. Pattern Recognit. (CVPR), Jul. 2017, pp. 317-325.\n\nImage captioning with semantic attention. Q You, H Jin, Z Wang, C Fang, J Luo, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)Q. You, H. Jin, Z. Wang, C. Fang, and J. Luo, ''Image captioning with semantic attention,'' in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 4651-4659.\n\nShow, attend and tell: Neural image caption generation with visual attention. K Xu, J Ba, R Kiros, K Cho, A Courville, R Salakhudinov, R Zemel, Y Bengio, Proc. Int. Conf. Mach. Learn. Int. Conf. Mach. LearnK. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel, and Y. Bengio, ''Show, attend and tell: Neural image caption gener- ation with visual attention,'' in Proc. Int. Conf. Mach. Learn., 2015, pp. 2048-2057.\n\nOn the automatic generation of medical imaging reports. B Jing, P Xie, E Xing, arXiv:1711.08195B. Jing, P. Xie, and E. Xing, ''On the automatic generation of med- ical imaging reports,'' 2017, arXiv:1711.08195. [Online]. Available: http://arxiv.org/abs/1711.08195\n\nA survey on deep learning in medical image analysis. G Litjens, T Kooi, B E Bejnordi, A A A Setio, F Ciompi, M Ghafoorian, J A W M Van Der Laak, B Van Ginneken, C I S\u00e1nchez, Image Anal. 42G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian, J. A. W. M. van der Laak, B. van Ginneken, and C. I. S\u00e1nchez, ''A survey on deep learning in medical image analysis,'' Med. Image Anal., vol. 42, pp. 60-88, Dec. 2017.\n\nPredicting semantic descriptions from medical images with convolutional neural networks. T Schlegl, S M Waldstein, W.-D Vogl, U Schmidt-Erfurth, G Langs, Proc. Int. Conf. Inf. Process. Med. Imag. Int. Conf. Inf. ess. Med. ImagSpringerT. Schlegl, S. M. Waldstein, W.-D. Vogl, U. Schmidt-Erfurth, and G. Langs, ''Predicting semantic descriptions from medical images with convolutional neural networks,'' in Proc. Int. Conf. Inf. Process. Med. Imag. Springer, 2015, pp. 437-448.\n\nCombining LSTM and DenseNet for automatic annotation and classification of chest X-ray images. F Yan, X Huang, Y Yao, M Lu, M Li, IEEE Access. 7F. Yan, X. Huang, Y. Yao, M. Lu, and M. Li, ''Combining LSTM and DenseNet for automatic annotation and classification of chest X-ray images,'' IEEE Access, vol. 7, pp. 74181-74189, 2019.\n\nA deep feature learning model for pneumonia detection applying a combination of mRMR feature selection and machine learning models. M To\u011fa\u00e7ar, B Ergen, Z C\u00f6mert, F \u00d6zyurt, 41IRBMM. To\u011fa\u00e7ar, B. Ergen, Z. C\u00f6mert, and F. \u00d6zyurt, ''A deep feature learn- ing model for pneumonia detection applying a combination of mRMR feature selection and machine learning models,'' IRBM, vol. 41, no. 4, pp. 212-222, Aug. 2020.\n\nAutomated methods for detection and classification pneumonia based on X-ray images using deep learning. K El Asnaoui, Y Chawki, A Idri, arXiv:2003.143632020K. El Asnaoui, Y. Chawki, and A. Idri, ''Automated methods for detection and classification pneumonia based on X-ray images using deep learning,'' 2020, arXiv:2003.14363. [Online]. Available: http://arxiv. org/abs/2003.14363\n\nPneumonia detection in chest X-ray images using convolutional neural networks and transfer learning. R Jain, P Nagrath, G Kataria, V S Kaushik, D J Hemanth, 165Art. no. 108046R. Jain, P. Nagrath, G. Kataria, V. S. Kaushik, and D. J. Hemanth, ''Pneumonia detection in chest X-ray images using convolutional neu- ral networks and transfer learning,'' Measurement, vol. 165, Dec. 2020, Art. no. 108046.\n\nA novel transfer learning based approach for pneumonia detection in chest X-ray images. V Chouhan, S K Singh, A Khamparia, D Gupta, P Tiwari, C Moreira, R Dama\u0161evi\u010dius, V H C De Albuquerque, Appl. Sci. 102559V. Chouhan, S. K. Singh, A. Khamparia, D. Gupta, P. Tiwari, C. Moreira, R. Dama\u0161evi\u010dius, and V. H. C. de Albuquerque, ''A novel transfer learning based approach for pneumonia detection in chest X-ray images,'' Appl. Sci., vol. 10, no. 2, p. 559, Jan. 2020.\n\nImageNet classification with deep convolutional neural networks,'' in Proc. A Krizhevsky, I Sutskever, G E Hinton, Adv. Neural Inf. Process. Syst. (NIPS). 25A. Krizhevsky, I. Sutskever, and G. E. Hinton, ''ImageNet classification with deep convolutional neural networks,'' in Proc. Adv. Neural Inf. Pro- cess. Syst. (NIPS), vol. 25, Dec. 2012, pp. 1097-1105.\n\nBULDP: Biomimetic uncorrelated locality discriminant projection for feature extraction in face recognition. X Ning, W Li, B Tang, H He, IEEE Trans. Image Process. 275X. Ning, W. Li, B. Tang, and H. He, ''BULDP: Biomimetic uncorre- lated locality discriminant projection for feature extraction in face recog- nition,'' IEEE Trans. Image Process., vol. 27, no. 5, pp. 2575-2586, May 2018.\n\nReal-time 3D face alignment using an encoder-decoder network with an efficient deconvolution layer. X Ning, P Duan, W Li, S Zhang, IEEE Signal Process. Lett. 27X. Ning, P. Duan, W. Li, and S. Zhang, ''Real-time 3D face align- ment using an encoder-decoder network with an efficient deconvo- lution layer,'' IEEE Signal Process. Lett., vol. 27, pp. 1944-1948, 2020.\n\nAn efficient CAD system for ALL cell identification from microscopic blood images. Z F Mohammed, A A Abdulla, Multimedia Tools Appl. 804Z. F. Mohammed and A. A. Abdulla, ''An efficient CAD system for ALL cell identification from microscopic blood images,'' Multimedia Tools Appl., vol. 80, no. 4, pp. 6355-6368, Feb. 2021.\n\nR Selvaraju, A Das, R Vedantam, M Cogswell, D Parikh, D Batra, &apos;&apos;grad-Cam , arXiv:1611.07450Why did you say that?'' 2016. R. R Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, and D. Batra, ''Grad-CAM: Why did you say that?'' 2016, arXiv:1611.07450. [Online]. Available: http://arxiv.org/abs/1611.07450\n\nDeep-learningassisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet. N Bien, P Rajpurkar, R L Ball, J Irvin, A Park, E Jones, M Bereket, B N Patel, K W Yeom, K Shpanskaya, S Halabi, PLOS Med. 1511Art. no. e1002699N. Bien, P. Rajpurkar, R. L. Ball, J. Irvin, A. Park, E. Jones, M. Bereket, B. N. Patel, K. W. Yeom, K. Shpanskaya, and S. Halabi, ''Deep-learning- assisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet,'' PLOS Med., vol. 15, no. 11, Nov. 2018, Art. no. e1002699.\n\nA data-driven method for syndrome type identification and classification in traditional chinese medicine. N L Zhang, C Fu, T F Liu, B.-X Chen, K M Poon, P X Chen, Y.-L Zhang, J. Integrative Med. 152N. L. Zhang, C. Fu, T. F. Liu, B.-X. Chen, K. M. Poon, P. X. Chen, and Y.-L. Zhang, ''A data-driven method for syndrome type identification and classification in traditional chinese medicine,'' J. Integrative Med., vol. 15, no. 2, pp. 110-123, Mar. 2017.\n\nIdentification and classification of traditional Chinese medicine syndrome types among senior patients with vascular mild cognitive impairment using latent tree analysis. C Fu, N L Zhang, B.-X Chen, Z R Chen, X L Jin, R.-J Guo, Z.-G Chen, Y.-L Zhang, J. Integrative Med. 153C. Fu, N. L. Zhang, B.-X. Chen, Z. R. Chen, X. L. Jin, R.-J. Guo, Z.-G. Chen, and Y.-L. Zhang, ''Identification and classification of tradi- tional Chinese medicine syndrome types among senior patients with vas- cular mild cognitive impairment using latent tree analysis,'' J. Integrative Med., vol. 15, no. 3, pp. 186-200, May 2017.\n\nLatent tree models for rounding in spectral clustering. A H Liu, L K M Poon, T.-F Liu, N L Zhang, Neurocomputing. 144A. H. Liu, L. K. M. Poon, T.-F. Liu, and N. L. Zhang, ''Latent tree models for rounding in spectral clustering,'' Neurocomputing, vol. 144, pp. 448-462, Nov. 2014.\n\nThe ICD-10 Classification of Mental and Behavioural Disorders: Clinical Descriptions and Diagnostic Guidelines. W H Organization, Geneva, SwitzerlandW. H. Organization, The ICD-10 Classification of Mental and Behavioural Disorders: Clinical Descriptions and Diagnostic Guidelines. Geneva, Switzerland: World Health Organization, 1992.\n\nCommunity-acquired pneumonia. T M FileJr, Lancet. 3629400T. M. File, Jr., ''Community-acquired pneumonia,'' Lancet, vol. 362, no. 9400, pp. 1991-2001, 2003.\n\nDenseNet: Implementing efficient ConvNet descriptor pyramids. F Iandola, M Moskewicz, S Karayev, R Girshick, T Darrell, K Keutzer, arXiv:1404.1869F. Iandola, M. Moskewicz, S. Karayev, R. Girshick, T. Darrell, and K. Keutzer, ''DenseNet: Implementing efficient ConvNet descriptor pyra- mids,'' 2014, arXiv:1404.1869. [Online]. Available: http://arxiv.org/ abs/1404.1869\n\nRegret graphs, diagnostic uncertainty and Youden's Index. J Hilden, P Glasziou, Statist. Med. 1510J. Hilden and P. Glasziou, ''Regret graphs, diagnostic uncertainty and Youden's Index,'' Statist. Med., vol. 15, no. 10, pp. 969-986, May 1996.\n\nCluster-based under-sampling approaches for imbalanced data distributions. S.-J Yen, Y.-S Lee, Expert Syst. Appl. 363S.-J. Yen and Y.-S. Lee, ''Cluster-based under-sampling approaches for imbalanced data distributions,'' Expert Syst. Appl., vol. 36, no. 3, pp. 5718-5727, Apr. 2009.\n\nIntroduction to pytorch,'' in Deep Learning With Python. N Ketkar, SpringerN. Ketkar, ''Introduction to pytorch,'' in Deep Learning With Python. Springer, 2017, pp. 195-208.\n\nScikit-learn: Machine learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, J Vanderplas, J. Mach. Learn. Res. 12F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, and J. Vanderplas, ''Scikit-learn: Machine learning in Python,'' J. Mach. Learn. Res., vol. 12, pp. 2825-2830, Oct. 2011.\n\nTransforming classifier scores into accurate multiclass probability estimates. B Zadrozny, C Elkan, Proc. 8th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining. 8th ACM SIGKDD Int. Conf. Knowl. Discovery Data MiningB. Zadrozny and C. Elkan, ''Transforming classifier scores into accurate multiclass probability estimates,'' in Proc. 8th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining (KDD), 2002, pp. 694-699.\n\nEnsemble of exemplar-SVMs for object detection and beyond. T Malisiewicz, A Gupta, A A Efros, Proc. Int. Conf. Comput. Vis. Int. Conf. Comput. VisT. Malisiewicz, A. Gupta, and A. A. Efros, ''Ensemble of exemplar- SVMs for object detection and beyond,'' in Proc. Int. Conf. Comput. Vis., Nov. 2011, pp. 89-96.\n\nVerification of forecasts expressed in terms of probability. G W Brier, Monthly Weather Rev. 781G. W. Brier, ''Verification of forecasts expressed in terms of probability,'' Monthly Weather Rev., vol. 78, no. 1, pp. 1-3, Jan. 1950.\n\nRegression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis. F E Harrell, Jr , SpringerF. E. Harrell, Jr., Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis. Springer, 2015.\n\nHe is currently pursuing the master's degree with the Guangdong Laboratory of Artificial Intelligence and Digital Economy. Shenzhen University (SZ), China. His current research interest includes AI in medicine. HAO REN received the bachelor's degree from Jiangxi Agricultural UniversityHAO REN received the bachelor's degree from Jiangxi Agricultural University, in 2017. He is currently pursuing the master's degree with the Guangdong Laboratory of Artificial Intelligence and Digital Economy, College of Computer Sci- ence and Software Engineering, Shenzhen Uni- versity (SZ), China. His current research interest includes AI in medicine.\n\nHe is supervised by the Distinguished Professor Kaishun Wu. His research interests include human-computer interaction and cognitive science. Aslan B Wong, Member, IEEE) is currently pursuing the Ph.D. degree with the College of Computer Science and Software Engineering. Shenzhen UniversityACM, the Society of Petroleum Engineersand the Engineer AustraliaASLAN B. WONG (Member, IEEE) is cur- rently pursuing the Ph.D. degree with the College of Computer Science and Software Engineering, Shenzhen University. He is supervised by the Dis- tinguished Professor Kaishun Wu. His research interests include human-computer interaction and cognitive science. He is a member of ACM, the Society of Petroleum Engineers, and the Engi- neer Australia.\n\nWANMIN LIAN received the master's degree in software engineering from the South China University of Technology. Since 2003, he has been engaged in the application and research of information technology in the medical field with Guangdong Second Provincial General Hospital. He is a Senior Engineer at the South China University of TechnologyWANMIN LIAN received the master's degree in software engineering from the South China University of Technology. Since 2003, he has been engaged in the application and research of information technology in the medical field with Guangdong Second Provincial General Hospital. He is a Senior Engineer at the South China Uni- versity of Technology.\n\nWEIBIN CHENG received the master's degree in medicine from Guangdong Pharmaceutical University. He is currently working with the Institute for Healthcare Artificial Intelligence Application, Guangdong Second Provincial General Hospital. His research interests include artificial intelligence in health care and data science. WEIBIN CHENG received the master's degree in medicine from Guangdong Pharmaceutical Uni- versity. He is currently working with the Institute for Healthcare Artificial Intelligence Application, Guangdong Second Provincial General Hospital. His research interests include artificial intelligence in health care and data science.\n", "annotations": {"author": "[{\"end\":339,\"start\":109},{\"end\":447,\"start\":340},{\"end\":562,\"start\":448},{\"end\":704,\"start\":563},{\"end\":810,\"start\":705},{\"end\":822,\"start\":811},{\"end\":1032,\"start\":823},{\"end\":1149,\"start\":1033},{\"end\":1276,\"start\":1150},{\"end\":1394,\"start\":1277},{\"end\":1523,\"start\":1395},{\"end\":1536,\"start\":1524}]", "publisher": null, "author_last_name": "[{\"end\":116,\"start\":113},{\"end\":352,\"start\":348},{\"end\":471,\"start\":467},{\"end\":575,\"start\":570},{\"end\":715,\"start\":710},{\"end\":821,\"start\":819},{\"end\":835,\"start\":832},{\"end\":1046,\"start\":1042},{\"end\":1166,\"start\":1161},{\"end\":1299,\"start\":1297},{\"end\":1409,\"start\":1404},{\"end\":1535,\"start\":1530}]", "author_first_name": "[{\"end\":112,\"start\":109},{\"end\":345,\"start\":340},{\"end\":347,\"start\":346},{\"end\":466,\"start\":460},{\"end\":569,\"start\":563},{\"end\":709,\"start\":705},{\"end\":818,\"start\":811},{\"end\":831,\"start\":823},{\"end\":1041,\"start\":1033},{\"end\":1154,\"start\":1150},{\"end\":1160,\"start\":1155},{\"end\":1296,\"start\":1289},{\"end\":1403,\"start\":1398},{\"end\":1529,\"start\":1524}]", "author_affiliation": "[{\"end\":210,\"start\":118},{\"end\":338,\"start\":212},{\"end\":446,\"start\":354},{\"end\":561,\"start\":473},{\"end\":703,\"start\":577},{\"end\":809,\"start\":717},{\"end\":929,\"start\":837},{\"end\":1031,\"start\":931},{\"end\":1148,\"start\":1048},{\"end\":1275,\"start\":1168},{\"end\":1393,\"start\":1301},{\"end\":1522,\"start\":1430}]", "title": "[{\"end\":106,\"start\":1},{\"end\":1642,\"start\":1537}]", "venue": null, "abstract": "[{\"end\":3773,\"start\":1812}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4188,\"start\":4185},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4419,\"start\":4416},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4725,\"start\":4722},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5098,\"start\":5095},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5891,\"start\":5888},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6076,\"start\":6073},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6085,\"start\":6082},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7785,\"start\":7782},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7791,\"start\":7787},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7969,\"start\":7966},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8117,\"start\":8113},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8206,\"start\":8202},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8331,\"start\":8327},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8547,\"start\":8543},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8711,\"start\":8707},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8759,\"start\":8755},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9435,\"start\":9431},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9566,\"start\":9562},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9572,\"start\":9568},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9743,\"start\":9739},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9860,\"start\":9856},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9866,\"start\":9862},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9882,\"start\":9878},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10289,\"start\":10285},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10295,\"start\":10291},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10390,\"start\":10386},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10399,\"start\":10395},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10482,\"start\":10478},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10789,\"start\":10785},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10824,\"start\":10820},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":11049,\"start\":11045},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":11310,\"start\":11306},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11370,\"start\":11367},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":11376,\"start\":11372},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11665,\"start\":11661},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11671,\"start\":11667},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12349,\"start\":12345},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13401,\"start\":13397},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":18136,\"start\":18132},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":19727,\"start\":19723},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21730,\"start\":21727},{\"end\":21773,\"start\":21771},{\"end\":21825,\"start\":21823},{\"end\":21834,\"start\":21832},{\"end\":21845,\"start\":21842},{\"end\":21928,\"start\":21925},{\"end\":21971,\"start\":21968},{\"end\":22044,\"start\":22041},{\"end\":22066,\"start\":22063},{\"end\":22135,\"start\":22132},{\"end\":22145,\"start\":22142},{\"end\":22156,\"start\":22153},{\"end\":22168,\"start\":22165},{\"end\":22192,\"start\":22189},{\"end\":22203,\"start\":22200},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":23657,\"start\":23653},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":24717,\"start\":24713},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24812,\"start\":24808},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":26624,\"start\":26620},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":26653,\"start\":26649},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":26717,\"start\":26713},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":27140,\"start\":27136}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":34260,\"start\":34218},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34517,\"start\":34261},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34562,\"start\":34518},{\"attributes\":{\"id\":\"fig_4\"},\"end\":34599,\"start\":34563},{\"attributes\":{\"id\":\"fig_5\"},\"end\":34941,\"start\":34600},{\"attributes\":{\"id\":\"fig_6\"},\"end\":34982,\"start\":34942},{\"attributes\":{\"id\":\"fig_7\"},\"end\":35013,\"start\":34983},{\"attributes\":{\"id\":\"fig_8\"},\"end\":35106,\"start\":35014},{\"attributes\":{\"id\":\"fig_9\"},\"end\":35194,\"start\":35107},{\"attributes\":{\"id\":\"fig_10\"},\"end\":35245,\"start\":35195},{\"attributes\":{\"id\":\"fig_11\"},\"end\":35306,\"start\":35246},{\"attributes\":{\"id\":\"fig_12\"},\"end\":35352,\"start\":35307},{\"attributes\":{\"id\":\"fig_13\"},\"end\":38060,\"start\":35353},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38122,\"start\":38061},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":38216,\"start\":38123},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":38327,\"start\":38217},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38417,\"start\":38328}]", "paragraph": "[{\"end\":6304,\"start\":3792},{\"end\":6943,\"start\":6306},{\"end\":7010,\"start\":6945},{\"end\":7479,\"start\":7012},{\"end\":7721,\"start\":7481},{\"end\":9334,\"start\":7771},{\"end\":10669,\"start\":9372},{\"end\":11193,\"start\":10699},{\"end\":11908,\"start\":11195},{\"end\":13256,\"start\":11934},{\"end\":14092,\"start\":13258},{\"end\":15533,\"start\":14094},{\"end\":15999,\"start\":15556},{\"end\":16987,\"start\":16001},{\"end\":17619,\"start\":16989},{\"end\":17954,\"start\":17672},{\"end\":18854,\"start\":17956},{\"end\":19110,\"start\":18899},{\"end\":19316,\"start\":19112},{\"end\":19814,\"start\":19318},{\"end\":20554,\"start\":19828},{\"end\":20943,\"start\":20556},{\"end\":21600,\"start\":20945},{\"end\":22858,\"start\":21602},{\"end\":23074,\"start\":22911},{\"end\":23358,\"start\":23076},{\"end\":23658,\"start\":23404},{\"end\":23689,\"start\":23660},{\"end\":23746,\"start\":23714},{\"end\":23926,\"start\":23773},{\"end\":24232,\"start\":23977},{\"end\":24574,\"start\":24234},{\"end\":24883,\"start\":24590},{\"end\":24999,\"start\":24885},{\"end\":25362,\"start\":25001},{\"end\":25523,\"start\":25364},{\"end\":25718,\"start\":25525},{\"end\":25872,\"start\":25720},{\"end\":26013,\"start\":25874},{\"end\":26424,\"start\":26015},{\"end\":26852,\"start\":26487},{\"end\":27430,\"start\":26854},{\"end\":28244,\"start\":27432},{\"end\":28598,\"start\":28286},{\"end\":29165,\"start\":28600},{\"end\":30964,\"start\":29167},{\"end\":31679,\"start\":31026},{\"end\":32425,\"start\":31734},{\"end\":33224,\"start\":32484},{\"end\":34217,\"start\":33245}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18898,\"start\":18855},{\"attributes\":{\"id\":\"formula_1\"},\"end\":22910,\"start\":22859},{\"attributes\":{\"id\":\"formula_2\"},\"end\":23713,\"start\":23690},{\"attributes\":{\"id\":\"formula_3\"},\"end\":23772,\"start\":23747},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23976,\"start\":23927}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":16906,\"start\":16899},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":27451,\"start\":27444},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":29392,\"start\":29385},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":30169,\"start\":30162}]", "section_header": "[{\"end\":3790,\"start\":3775},{\"end\":7769,\"start\":7724},{\"end\":9370,\"start\":9337},{\"end\":10697,\"start\":10672},{\"end\":11932,\"start\":11911},{\"end\":15554,\"start\":15536},{\"end\":17670,\"start\":17622},{\"end\":19826,\"start\":19817},{\"end\":23402,\"start\":23361},{\"end\":24588,\"start\":24577},{\"end\":26485,\"start\":26427},{\"end\":28284,\"start\":28247},{\"end\":30982,\"start\":30967},{\"end\":31024,\"start\":30985},{\"end\":31732,\"start\":31682},{\"end\":32482,\"start\":32428},{\"end\":33243,\"start\":33227},{\"end\":34229,\"start\":34219},{\"end\":34272,\"start\":34262},{\"end\":34529,\"start\":34519},{\"end\":34574,\"start\":34564},{\"end\":34953,\"start\":34943},{\"end\":34994,\"start\":34984},{\"end\":35025,\"start\":35015},{\"end\":35118,\"start\":35108},{\"end\":35206,\"start\":35196},{\"end\":35258,\"start\":35247},{\"end\":35319,\"start\":35308},{\"end\":35369,\"start\":35354},{\"end\":38071,\"start\":38062},{\"end\":38133,\"start\":38124},{\"end\":38227,\"start\":38218},{\"end\":38338,\"start\":38329}]", "table": null, "figure_caption": "[{\"end\":34260,\"start\":34231},{\"end\":34517,\"start\":34274},{\"end\":34562,\"start\":34531},{\"end\":34599,\"start\":34576},{\"end\":34941,\"start\":34602},{\"end\":34982,\"start\":34955},{\"end\":35013,\"start\":34996},{\"end\":35106,\"start\":35027},{\"end\":35194,\"start\":35120},{\"end\":35245,\"start\":35208},{\"end\":35306,\"start\":35261},{\"end\":35352,\"start\":35322},{\"end\":38060,\"start\":35370},{\"end\":38122,\"start\":38073},{\"end\":38216,\"start\":38135},{\"end\":38327,\"start\":38229},{\"end\":38417,\"start\":38340}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5615,\"start\":5607},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14091,\"start\":14083},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14242,\"start\":14234},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15799,\"start\":15791},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18508,\"start\":18500},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":20123,\"start\":20115},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":23357,\"start\":23349},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":25978,\"start\":25970},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":26499,\"start\":26491},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":28620,\"start\":28612},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":31355,\"start\":31347},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31962,\"start\":31953},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32622,\"start\":32613}]", "bib_author_first_name": "[{\"end\":38437,\"start\":38436},{\"end\":38450,\"start\":38449},{\"end\":38459,\"start\":38458},{\"end\":38461,\"start\":38460},{\"end\":38473,\"start\":38472},{\"end\":38475,\"start\":38474},{\"end\":38774,\"start\":38773},{\"end\":38782,\"start\":38781},{\"end\":38790,\"start\":38789},{\"end\":38796,\"start\":38795},{\"end\":38802,\"start\":38801},{\"end\":38813,\"start\":38812},{\"end\":38815,\"start\":38814},{\"end\":39328,\"start\":39327},{\"end\":39330,\"start\":39329},{\"end\":39340,\"start\":39339},{\"end\":39342,\"start\":39341},{\"end\":39349,\"start\":39348},{\"end\":39358,\"start\":39357},{\"end\":39369,\"start\":39368},{\"end\":39382,\"start\":39381},{\"end\":39395,\"start\":39394},{\"end\":39406,\"start\":39405},{\"end\":39408,\"start\":39407},{\"end\":39421,\"start\":39420},{\"end\":39423,\"start\":39422},{\"end\":39822,\"start\":39821},{\"end\":39831,\"start\":39830},{\"end\":40133,\"start\":40132},{\"end\":40468,\"start\":40464},{\"end\":40476,\"start\":40475},{\"end\":40487,\"start\":40486},{\"end\":40799,\"start\":40798},{\"end\":41029,\"start\":41028},{\"end\":41036,\"start\":41035},{\"end\":41038,\"start\":41037},{\"end\":41047,\"start\":41046},{\"end\":41059,\"start\":41058},{\"end\":41069,\"start\":41068},{\"end\":41082,\"start\":41081},{\"end\":41097,\"start\":41096},{\"end\":41110,\"start\":41109},{\"end\":41122,\"start\":41121},{\"end\":41135,\"start\":41134},{\"end\":41144,\"start\":41143},{\"end\":41155,\"start\":41154},{\"end\":41172,\"start\":41171},{\"end\":41174,\"start\":41173},{\"end\":41182,\"start\":41181},{\"end\":41184,\"start\":41183},{\"end\":41194,\"start\":41193},{\"end\":41196,\"start\":41195},{\"end\":41207,\"start\":41206},{\"end\":41703,\"start\":41702},{\"end\":41705,\"start\":41704},{\"end\":41713,\"start\":41712},{\"end\":41719,\"start\":41718},{\"end\":41727,\"start\":41726},{\"end\":41729,\"start\":41728},{\"end\":41739,\"start\":41738},{\"end\":41750,\"start\":41749},{\"end\":41758,\"start\":41757},{\"end\":41765,\"start\":41764},{\"end\":41776,\"start\":41775},{\"end\":41778,\"start\":41777},{\"end\":42326,\"start\":42325},{\"end\":42328,\"start\":42327},{\"end\":42336,\"start\":42335},{\"end\":42342,\"start\":42341},{\"end\":42354,\"start\":42350},{\"end\":42362,\"start\":42361},{\"end\":42369,\"start\":42368},{\"end\":42371,\"start\":42370},{\"end\":42382,\"start\":42381},{\"end\":42384,\"start\":42383},{\"end\":42813,\"start\":42812},{\"end\":42820,\"start\":42819},{\"end\":42831,\"start\":42830},{\"end\":42842,\"start\":42841},{\"end\":42855,\"start\":42854},{\"end\":42866,\"start\":42865},{\"end\":43219,\"start\":43218},{\"end\":43226,\"start\":43225},{\"end\":43237,\"start\":43236},{\"end\":43248,\"start\":43247},{\"end\":43261,\"start\":43260},{\"end\":43272,\"start\":43271},{\"end\":43529,\"start\":43528},{\"end\":43538,\"start\":43537},{\"end\":43551,\"start\":43550},{\"end\":43557,\"start\":43556},{\"end\":43563,\"start\":43562},{\"end\":43579,\"start\":43578},{\"end\":43588,\"start\":43587},{\"end\":43600,\"start\":43599},{\"end\":43611,\"start\":43610},{\"end\":43619,\"start\":43618},{\"end\":43633,\"start\":43632},{\"end\":43644,\"start\":43643},{\"end\":43646,\"start\":43645},{\"end\":43654,\"start\":43653},{\"end\":43656,\"start\":43655},{\"end\":43666,\"start\":43665},{\"end\":43668,\"start\":43667},{\"end\":43680,\"start\":43679},{\"end\":43689,\"start\":43688},{\"end\":43691,\"start\":43690},{\"end\":43701,\"start\":43700},{\"end\":43703,\"start\":43702},{\"end\":43715,\"start\":43714},{\"end\":43717,\"start\":43716},{\"end\":43726,\"start\":43725},{\"end\":43728,\"start\":43727},{\"end\":43739,\"start\":43738},{\"end\":43741,\"start\":43740},{\"end\":44352,\"start\":44351},{\"end\":44354,\"start\":44353},{\"end\":44365,\"start\":44364},{\"end\":44377,\"start\":44376},{\"end\":44384,\"start\":44383},{\"end\":44388,\"start\":44385},{\"end\":44400,\"start\":44399},{\"end\":44409,\"start\":44408},{\"end\":44411,\"start\":44410},{\"end\":44421,\"start\":44420},{\"end\":44432,\"start\":44431},{\"end\":44440,\"start\":44439},{\"end\":44446,\"start\":44445},{\"end\":44453,\"start\":44452},{\"end\":44815,\"start\":44814},{\"end\":44817,\"start\":44816},{\"end\":45095,\"start\":45094},{\"end\":45107,\"start\":45106},{\"end\":45478,\"start\":45477},{\"end\":45488,\"start\":45487},{\"end\":45499,\"start\":45498},{\"end\":45510,\"start\":45509},{\"end\":45877,\"start\":45876},{\"end\":45884,\"start\":45883},{\"end\":45891,\"start\":45890},{\"end\":45899,\"start\":45898},{\"end\":45907,\"start\":45906},{\"end\":46274,\"start\":46273},{\"end\":46280,\"start\":46279},{\"end\":46286,\"start\":46285},{\"end\":46295,\"start\":46294},{\"end\":46302,\"start\":46301},{\"end\":46315,\"start\":46314},{\"end\":46331,\"start\":46330},{\"end\":46340,\"start\":46339},{\"end\":46686,\"start\":46685},{\"end\":46694,\"start\":46693},{\"end\":46701,\"start\":46700},{\"end\":46948,\"start\":46947},{\"end\":46959,\"start\":46958},{\"end\":46967,\"start\":46966},{\"end\":46969,\"start\":46968},{\"end\":46981,\"start\":46980},{\"end\":46985,\"start\":46982},{\"end\":46994,\"start\":46993},{\"end\":47004,\"start\":47003},{\"end\":47018,\"start\":47017},{\"end\":47024,\"start\":47019},{\"end\":47040,\"start\":47039},{\"end\":47056,\"start\":47055},{\"end\":47058,\"start\":47057},{\"end\":47420,\"start\":47419},{\"end\":47431,\"start\":47430},{\"end\":47433,\"start\":47432},{\"end\":47449,\"start\":47445},{\"end\":47457,\"start\":47456},{\"end\":47476,\"start\":47475},{\"end\":47903,\"start\":47902},{\"end\":47910,\"start\":47909},{\"end\":47919,\"start\":47918},{\"end\":47926,\"start\":47925},{\"end\":47932,\"start\":47931},{\"end\":48272,\"start\":48271},{\"end\":48283,\"start\":48282},{\"end\":48292,\"start\":48291},{\"end\":48302,\"start\":48301},{\"end\":48655,\"start\":48654},{\"end\":48658,\"start\":48656},{\"end\":48669,\"start\":48668},{\"end\":48679,\"start\":48678},{\"end\":49034,\"start\":49033},{\"end\":49042,\"start\":49041},{\"end\":49053,\"start\":49052},{\"end\":49064,\"start\":49063},{\"end\":49066,\"start\":49065},{\"end\":49077,\"start\":49076},{\"end\":49079,\"start\":49078},{\"end\":49422,\"start\":49421},{\"end\":49433,\"start\":49432},{\"end\":49435,\"start\":49434},{\"end\":49444,\"start\":49443},{\"end\":49457,\"start\":49456},{\"end\":49466,\"start\":49465},{\"end\":49476,\"start\":49475},{\"end\":49487,\"start\":49486},{\"end\":49503,\"start\":49502},{\"end\":49507,\"start\":49504},{\"end\":49876,\"start\":49875},{\"end\":49890,\"start\":49889},{\"end\":49903,\"start\":49902},{\"end\":49905,\"start\":49904},{\"end\":50268,\"start\":50267},{\"end\":50276,\"start\":50275},{\"end\":50282,\"start\":50281},{\"end\":50290,\"start\":50289},{\"end\":50648,\"start\":50647},{\"end\":50656,\"start\":50655},{\"end\":50664,\"start\":50663},{\"end\":50670,\"start\":50669},{\"end\":50997,\"start\":50996},{\"end\":50999,\"start\":50998},{\"end\":51011,\"start\":51010},{\"end\":51013,\"start\":51012},{\"end\":51238,\"start\":51237},{\"end\":51251,\"start\":51250},{\"end\":51258,\"start\":51257},{\"end\":51270,\"start\":51269},{\"end\":51282,\"start\":51281},{\"end\":51292,\"start\":51291},{\"end\":51320,\"start\":51300},{\"end\":51679,\"start\":51678},{\"end\":51687,\"start\":51686},{\"end\":51700,\"start\":51699},{\"end\":51702,\"start\":51701},{\"end\":51710,\"start\":51709},{\"end\":51719,\"start\":51718},{\"end\":51727,\"start\":51726},{\"end\":51736,\"start\":51735},{\"end\":51747,\"start\":51746},{\"end\":51749,\"start\":51748},{\"end\":51758,\"start\":51757},{\"end\":51760,\"start\":51759},{\"end\":51768,\"start\":51767},{\"end\":51782,\"start\":51781},{\"end\":52245,\"start\":52244},{\"end\":52247,\"start\":52246},{\"end\":52256,\"start\":52255},{\"end\":52262,\"start\":52261},{\"end\":52264,\"start\":52263},{\"end\":52274,\"start\":52270},{\"end\":52282,\"start\":52281},{\"end\":52284,\"start\":52283},{\"end\":52292,\"start\":52291},{\"end\":52294,\"start\":52293},{\"end\":52305,\"start\":52301},{\"end\":52764,\"start\":52763},{\"end\":52770,\"start\":52769},{\"end\":52772,\"start\":52771},{\"end\":52784,\"start\":52780},{\"end\":52792,\"start\":52791},{\"end\":52794,\"start\":52793},{\"end\":52802,\"start\":52801},{\"end\":52804,\"start\":52803},{\"end\":52814,\"start\":52810},{\"end\":52824,\"start\":52820},{\"end\":52835,\"start\":52831},{\"end\":53258,\"start\":53257},{\"end\":53260,\"start\":53259},{\"end\":53267,\"start\":53266},{\"end\":53271,\"start\":53268},{\"end\":53282,\"start\":53278},{\"end\":53289,\"start\":53288},{\"end\":53291,\"start\":53290},{\"end\":53596,\"start\":53595},{\"end\":53598,\"start\":53597},{\"end\":53850,\"start\":53849},{\"end\":53852,\"start\":53851},{\"end\":54040,\"start\":54039},{\"end\":54051,\"start\":54050},{\"end\":54064,\"start\":54063},{\"end\":54075,\"start\":54074},{\"end\":54087,\"start\":54086},{\"end\":54098,\"start\":54097},{\"end\":54406,\"start\":54405},{\"end\":54416,\"start\":54415},{\"end\":54669,\"start\":54665},{\"end\":54679,\"start\":54675},{\"end\":54932,\"start\":54931},{\"end\":55092,\"start\":55091},{\"end\":55105,\"start\":55104},{\"end\":55118,\"start\":55117},{\"end\":55130,\"start\":55129},{\"end\":55140,\"start\":55139},{\"end\":55151,\"start\":55150},{\"end\":55161,\"start\":55160},{\"end\":55172,\"start\":55171},{\"end\":55188,\"start\":55187},{\"end\":55197,\"start\":55196},{\"end\":55208,\"start\":55207},{\"end\":55573,\"start\":55572},{\"end\":55585,\"start\":55584},{\"end\":55969,\"start\":55968},{\"end\":55984,\"start\":55983},{\"end\":55993,\"start\":55992},{\"end\":55995,\"start\":55994},{\"end\":56281,\"start\":56280},{\"end\":56283,\"start\":56282},{\"end\":56577,\"start\":56576},{\"end\":56579,\"start\":56578},{\"end\":56591,\"start\":56589},{\"end\":57551,\"start\":57546},{\"end\":57553,\"start\":57552}]", "bib_author_last_name": "[{\"end\":38447,\"start\":38438},{\"end\":38456,\"start\":38451},{\"end\":38470,\"start\":38462},{\"end\":38483,\"start\":38476},{\"end\":38779,\"start\":38775},{\"end\":38787,\"start\":38783},{\"end\":38793,\"start\":38791},{\"end\":38799,\"start\":38797},{\"end\":38810,\"start\":38803},{\"end\":38823,\"start\":38816},{\"end\":39337,\"start\":39331},{\"end\":39346,\"start\":39343},{\"end\":39355,\"start\":39350},{\"end\":39366,\"start\":39359},{\"end\":39379,\"start\":39370},{\"end\":39392,\"start\":39383},{\"end\":39403,\"start\":39396},{\"end\":39418,\"start\":39409},{\"end\":39428,\"start\":39424},{\"end\":39828,\"start\":39823},{\"end\":39837,\"start\":39832},{\"end\":40144,\"start\":40134},{\"end\":40473,\"start\":40469},{\"end\":40484,\"start\":40477},{\"end\":40491,\"start\":40488},{\"end\":40808,\"start\":40800},{\"end\":41033,\"start\":41030},{\"end\":41044,\"start\":41039},{\"end\":41056,\"start\":41048},{\"end\":41066,\"start\":41060},{\"end\":41079,\"start\":41070},{\"end\":41094,\"start\":41083},{\"end\":41107,\"start\":41098},{\"end\":41119,\"start\":41111},{\"end\":41132,\"start\":41123},{\"end\":41141,\"start\":41136},{\"end\":41152,\"start\":41145},{\"end\":41169,\"start\":41156},{\"end\":41179,\"start\":41175},{\"end\":41191,\"start\":41185},{\"end\":41204,\"start\":41197},{\"end\":41210,\"start\":41208},{\"end\":41710,\"start\":41706},{\"end\":41716,\"start\":41714},{\"end\":41724,\"start\":41720},{\"end\":41736,\"start\":41730},{\"end\":41747,\"start\":41740},{\"end\":41755,\"start\":41751},{\"end\":41762,\"start\":41759},{\"end\":41773,\"start\":41766},{\"end\":41786,\"start\":41779},{\"end\":42333,\"start\":42329},{\"end\":42339,\"start\":42337},{\"end\":42348,\"start\":42343},{\"end\":42359,\"start\":42355},{\"end\":42366,\"start\":42363},{\"end\":42379,\"start\":42372},{\"end\":42392,\"start\":42385},{\"end\":42817,\"start\":42814},{\"end\":42828,\"start\":42821},{\"end\":42839,\"start\":42832},{\"end\":42852,\"start\":42843},{\"end\":42863,\"start\":42856},{\"end\":42872,\"start\":42867},{\"end\":43223,\"start\":43220},{\"end\":43234,\"start\":43227},{\"end\":43245,\"start\":43238},{\"end\":43258,\"start\":43249},{\"end\":43269,\"start\":43262},{\"end\":43278,\"start\":43273},{\"end\":43535,\"start\":43530},{\"end\":43548,\"start\":43539},{\"end\":43554,\"start\":43552},{\"end\":43560,\"start\":43558},{\"end\":43576,\"start\":43564},{\"end\":43585,\"start\":43580},{\"end\":43597,\"start\":43589},{\"end\":43608,\"start\":43601},{\"end\":43616,\"start\":43612},{\"end\":43630,\"start\":43620},{\"end\":43641,\"start\":43634},{\"end\":43651,\"start\":43647},{\"end\":43663,\"start\":43657},{\"end\":43677,\"start\":43669},{\"end\":43686,\"start\":43681},{\"end\":43698,\"start\":43692},{\"end\":43712,\"start\":43704},{\"end\":43723,\"start\":43718},{\"end\":43736,\"start\":43729},{\"end\":43744,\"start\":43742},{\"end\":44362,\"start\":44355},{\"end\":44374,\"start\":44366},{\"end\":44381,\"start\":44378},{\"end\":44397,\"start\":44389},{\"end\":44406,\"start\":44401},{\"end\":44418,\"start\":44412},{\"end\":44429,\"start\":44422},{\"end\":44437,\"start\":44433},{\"end\":44443,\"start\":44441},{\"end\":44450,\"start\":44447},{\"end\":44458,\"start\":44454},{\"end\":44823,\"start\":44818},{\"end\":45104,\"start\":45096},{\"end\":45115,\"start\":45108},{\"end\":45485,\"start\":45479},{\"end\":45496,\"start\":45489},{\"end\":45507,\"start\":45500},{\"end\":45518,\"start\":45511},{\"end\":45881,\"start\":45878},{\"end\":45888,\"start\":45885},{\"end\":45896,\"start\":45892},{\"end\":45904,\"start\":45900},{\"end\":45911,\"start\":45908},{\"end\":46277,\"start\":46275},{\"end\":46283,\"start\":46281},{\"end\":46292,\"start\":46287},{\"end\":46299,\"start\":46296},{\"end\":46312,\"start\":46303},{\"end\":46328,\"start\":46316},{\"end\":46337,\"start\":46332},{\"end\":46347,\"start\":46341},{\"end\":46691,\"start\":46687},{\"end\":46698,\"start\":46695},{\"end\":46706,\"start\":46702},{\"end\":46956,\"start\":46949},{\"end\":46964,\"start\":46960},{\"end\":46978,\"start\":46970},{\"end\":46991,\"start\":46986},{\"end\":47001,\"start\":46995},{\"end\":47015,\"start\":47005},{\"end\":47037,\"start\":47025},{\"end\":47053,\"start\":47041},{\"end\":47066,\"start\":47059},{\"end\":47428,\"start\":47421},{\"end\":47443,\"start\":47434},{\"end\":47454,\"start\":47450},{\"end\":47473,\"start\":47458},{\"end\":47482,\"start\":47477},{\"end\":47907,\"start\":47904},{\"end\":47916,\"start\":47911},{\"end\":47923,\"start\":47920},{\"end\":47929,\"start\":47927},{\"end\":47935,\"start\":47933},{\"end\":48280,\"start\":48273},{\"end\":48289,\"start\":48284},{\"end\":48299,\"start\":48293},{\"end\":48309,\"start\":48303},{\"end\":48666,\"start\":48659},{\"end\":48676,\"start\":48670},{\"end\":48684,\"start\":48680},{\"end\":49039,\"start\":49035},{\"end\":49050,\"start\":49043},{\"end\":49061,\"start\":49054},{\"end\":49074,\"start\":49067},{\"end\":49087,\"start\":49080},{\"end\":49430,\"start\":49423},{\"end\":49441,\"start\":49436},{\"end\":49454,\"start\":49445},{\"end\":49463,\"start\":49458},{\"end\":49473,\"start\":49467},{\"end\":49484,\"start\":49477},{\"end\":49500,\"start\":49488},{\"end\":49522,\"start\":49508},{\"end\":49887,\"start\":49877},{\"end\":49900,\"start\":49891},{\"end\":49912,\"start\":49906},{\"end\":50273,\"start\":50269},{\"end\":50279,\"start\":50277},{\"end\":50287,\"start\":50283},{\"end\":50293,\"start\":50291},{\"end\":50653,\"start\":50649},{\"end\":50661,\"start\":50657},{\"end\":50667,\"start\":50665},{\"end\":50676,\"start\":50671},{\"end\":51008,\"start\":51000},{\"end\":51021,\"start\":51014},{\"end\":51248,\"start\":51239},{\"end\":51255,\"start\":51252},{\"end\":51267,\"start\":51259},{\"end\":51279,\"start\":51271},{\"end\":51289,\"start\":51283},{\"end\":51298,\"start\":51293},{\"end\":51684,\"start\":51680},{\"end\":51697,\"start\":51688},{\"end\":51707,\"start\":51703},{\"end\":51716,\"start\":51711},{\"end\":51724,\"start\":51720},{\"end\":51733,\"start\":51728},{\"end\":51744,\"start\":51737},{\"end\":51755,\"start\":51750},{\"end\":51765,\"start\":51761},{\"end\":51779,\"start\":51769},{\"end\":51789,\"start\":51783},{\"end\":52253,\"start\":52248},{\"end\":52259,\"start\":52257},{\"end\":52268,\"start\":52265},{\"end\":52279,\"start\":52275},{\"end\":52289,\"start\":52285},{\"end\":52299,\"start\":52295},{\"end\":52311,\"start\":52306},{\"end\":52767,\"start\":52765},{\"end\":52778,\"start\":52773},{\"end\":52789,\"start\":52785},{\"end\":52799,\"start\":52795},{\"end\":52808,\"start\":52805},{\"end\":52818,\"start\":52815},{\"end\":52829,\"start\":52825},{\"end\":52841,\"start\":52836},{\"end\":53264,\"start\":53261},{\"end\":53276,\"start\":53272},{\"end\":53286,\"start\":53283},{\"end\":53297,\"start\":53292},{\"end\":53611,\"start\":53599},{\"end\":53857,\"start\":53853},{\"end\":54048,\"start\":54041},{\"end\":54061,\"start\":54052},{\"end\":54072,\"start\":54065},{\"end\":54084,\"start\":54076},{\"end\":54095,\"start\":54088},{\"end\":54106,\"start\":54099},{\"end\":54413,\"start\":54407},{\"end\":54425,\"start\":54417},{\"end\":54673,\"start\":54670},{\"end\":54683,\"start\":54680},{\"end\":54939,\"start\":54933},{\"end\":55102,\"start\":55093},{\"end\":55115,\"start\":55106},{\"end\":55127,\"start\":55119},{\"end\":55137,\"start\":55131},{\"end\":55148,\"start\":55141},{\"end\":55158,\"start\":55152},{\"end\":55169,\"start\":55162},{\"end\":55185,\"start\":55173},{\"end\":55194,\"start\":55189},{\"end\":55205,\"start\":55198},{\"end\":55219,\"start\":55209},{\"end\":55582,\"start\":55574},{\"end\":55591,\"start\":55586},{\"end\":55981,\"start\":55970},{\"end\":55990,\"start\":55985},{\"end\":56001,\"start\":55996},{\"end\":56289,\"start\":56284},{\"end\":56587,\"start\":56580},{\"end\":57558,\"start\":57554}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2077330},\"end\":38628,\"start\":38419},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":8945673},\"end\":39226,\"start\":38630},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":4975155},\"end\":39730,\"start\":39228},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":195772367},\"end\":40077,\"start\":39732},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":122677662},\"end\":40351,\"start\":40079},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":9020702},\"end\":40744,\"start\":40353},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":595637},\"end\":40956,\"start\":40746},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":53531567},\"end\":41579,\"start\":40958},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":4236914},\"end\":42235,\"start\":41581},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":5776545},\"end\":42735,\"start\":42237},{\"attributes\":{\"doi\":\"abs/1710.10501\",\"id\":\"b10\"},\"end\":43141,\"start\":42737},{\"attributes\":{\"doi\":\"arXiv:1710.10501\",\"id\":\"b11\"},\"end\":43526,\"start\":43143},{\"attributes\":{\"id\":\"b12\"},\"end\":44267,\"start\":43528},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":3516426},\"end\":44729,\"start\":44269},{\"attributes\":{\"doi\":\"arXiv:2008.05906\",\"id\":\"b14\",\"matched_paper_id\":221112369},\"end\":45025,\"start\":44731},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":8517067},\"end\":45406,\"start\":45027},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":14464447},\"end\":45832,\"start\":45408},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3120635},\"end\":46193,\"start\":45834},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":1055111},\"end\":46627,\"start\":46195},{\"attributes\":{\"doi\":\"arXiv:1711.08195\",\"id\":\"b19\"},\"end\":46892,\"start\":46629},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":2088679},\"end\":47328,\"start\":46894},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":7412277},\"end\":47805,\"start\":47330},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":195221666},\"end\":48137,\"start\":47807},{\"attributes\":{\"id\":\"b23\"},\"end\":48548,\"start\":48139},{\"attributes\":{\"doi\":\"arXiv:2003.14363\",\"id\":\"b24\"},\"end\":48930,\"start\":48550},{\"attributes\":{\"id\":\"b25\"},\"end\":49331,\"start\":48932},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":213146444},\"end\":49797,\"start\":49333},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":195908774},\"end\":50157,\"start\":49799},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":3774834},\"end\":50545,\"start\":50159},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":226637725},\"end\":50911,\"start\":50547},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":225137808},\"end\":51235,\"start\":50913},{\"attributes\":{\"doi\":\"arXiv:1611.07450\",\"id\":\"b31\"},\"end\":51556,\"start\":51237},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":53737155},\"end\":52136,\"start\":51558},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":5278642},\"end\":52590,\"start\":52138},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":24741792},\"end\":53199,\"start\":52592},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":31942455},\"end\":53481,\"start\":53201},{\"attributes\":{\"id\":\"b36\"},\"end\":53817,\"start\":53483},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":2208017},\"end\":53975,\"start\":53819},{\"attributes\":{\"doi\":\"arXiv:1404.1869\",\"id\":\"b38\"},\"end\":54345,\"start\":53977},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":42859690},\"end\":54588,\"start\":54347},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":26663602},\"end\":54872,\"start\":54590},{\"attributes\":{\"id\":\"b41\"},\"end\":55047,\"start\":54874},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":10659969},\"end\":55491,\"start\":55049},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":3349576},\"end\":55907,\"start\":55493},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":14448882},\"end\":56217,\"start\":55909},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":122906757},\"end\":56450,\"start\":56219},{\"attributes\":{\"id\":\"b46\"},\"end\":56761,\"start\":56452},{\"attributes\":{\"id\":\"b47\"},\"end\":57403,\"start\":56763},{\"attributes\":{\"id\":\"b48\"},\"end\":58145,\"start\":57405},{\"attributes\":{\"id\":\"b49\"},\"end\":58832,\"start\":58147},{\"attributes\":{\"id\":\"b50\"},\"end\":59485,\"start\":58834}]", "bib_title": "[{\"end\":38434,\"start\":38419},{\"end\":38771,\"start\":38630},{\"end\":39325,\"start\":39228},{\"end\":39819,\"start\":39732},{\"end\":40130,\"start\":40079},{\"end\":40462,\"start\":40353},{\"end\":40796,\"start\":40746},{\"end\":41026,\"start\":40958},{\"end\":41700,\"start\":41581},{\"end\":42323,\"start\":42237},{\"end\":44349,\"start\":44269},{\"end\":44812,\"start\":44731},{\"end\":45092,\"start\":45027},{\"end\":45475,\"start\":45408},{\"end\":45874,\"start\":45834},{\"end\":46271,\"start\":46195},{\"end\":46945,\"start\":46894},{\"end\":47417,\"start\":47330},{\"end\":47900,\"start\":47807},{\"end\":49419,\"start\":49333},{\"end\":49873,\"start\":49799},{\"end\":50265,\"start\":50159},{\"end\":50645,\"start\":50547},{\"end\":50994,\"start\":50913},{\"end\":51676,\"start\":51558},{\"end\":52242,\"start\":52138},{\"end\":52761,\"start\":52592},{\"end\":53255,\"start\":53201},{\"end\":53847,\"start\":53819},{\"end\":54403,\"start\":54347},{\"end\":54663,\"start\":54590},{\"end\":55089,\"start\":55049},{\"end\":55570,\"start\":55493},{\"end\":55966,\"start\":55909},{\"end\":56278,\"start\":56219},{\"end\":56884,\"start\":56763},{\"end\":57544,\"start\":57405}]", "bib_author": "[{\"end\":38449,\"start\":38436},{\"end\":38458,\"start\":38449},{\"end\":38472,\"start\":38458},{\"end\":38485,\"start\":38472},{\"end\":38781,\"start\":38773},{\"end\":38789,\"start\":38781},{\"end\":38795,\"start\":38789},{\"end\":38801,\"start\":38795},{\"end\":38812,\"start\":38801},{\"end\":38825,\"start\":38812},{\"end\":39339,\"start\":39327},{\"end\":39348,\"start\":39339},{\"end\":39357,\"start\":39348},{\"end\":39368,\"start\":39357},{\"end\":39381,\"start\":39368},{\"end\":39394,\"start\":39381},{\"end\":39405,\"start\":39394},{\"end\":39420,\"start\":39405},{\"end\":39430,\"start\":39420},{\"end\":39830,\"start\":39821},{\"end\":39839,\"start\":39830},{\"end\":40146,\"start\":40132},{\"end\":40475,\"start\":40464},{\"end\":40486,\"start\":40475},{\"end\":40493,\"start\":40486},{\"end\":40810,\"start\":40798},{\"end\":41035,\"start\":41028},{\"end\":41046,\"start\":41035},{\"end\":41058,\"start\":41046},{\"end\":41068,\"start\":41058},{\"end\":41081,\"start\":41068},{\"end\":41096,\"start\":41081},{\"end\":41109,\"start\":41096},{\"end\":41121,\"start\":41109},{\"end\":41134,\"start\":41121},{\"end\":41143,\"start\":41134},{\"end\":41154,\"start\":41143},{\"end\":41171,\"start\":41154},{\"end\":41181,\"start\":41171},{\"end\":41193,\"start\":41181},{\"end\":41206,\"start\":41193},{\"end\":41212,\"start\":41206},{\"end\":41712,\"start\":41702},{\"end\":41718,\"start\":41712},{\"end\":41726,\"start\":41718},{\"end\":41738,\"start\":41726},{\"end\":41749,\"start\":41738},{\"end\":41757,\"start\":41749},{\"end\":41764,\"start\":41757},{\"end\":41775,\"start\":41764},{\"end\":41788,\"start\":41775},{\"end\":42335,\"start\":42325},{\"end\":42341,\"start\":42335},{\"end\":42350,\"start\":42341},{\"end\":42361,\"start\":42350},{\"end\":42368,\"start\":42361},{\"end\":42381,\"start\":42368},{\"end\":42394,\"start\":42381},{\"end\":42819,\"start\":42812},{\"end\":42830,\"start\":42819},{\"end\":42841,\"start\":42830},{\"end\":42854,\"start\":42841},{\"end\":42865,\"start\":42854},{\"end\":42874,\"start\":42865},{\"end\":43225,\"start\":43218},{\"end\":43236,\"start\":43225},{\"end\":43247,\"start\":43236},{\"end\":43260,\"start\":43247},{\"end\":43271,\"start\":43260},{\"end\":43280,\"start\":43271},{\"end\":43537,\"start\":43528},{\"end\":43550,\"start\":43537},{\"end\":43556,\"start\":43550},{\"end\":43562,\"start\":43556},{\"end\":43578,\"start\":43562},{\"end\":43587,\"start\":43578},{\"end\":43599,\"start\":43587},{\"end\":43610,\"start\":43599},{\"end\":43618,\"start\":43610},{\"end\":43632,\"start\":43618},{\"end\":43643,\"start\":43632},{\"end\":43653,\"start\":43643},{\"end\":43665,\"start\":43653},{\"end\":43679,\"start\":43665},{\"end\":43688,\"start\":43679},{\"end\":43700,\"start\":43688},{\"end\":43714,\"start\":43700},{\"end\":43725,\"start\":43714},{\"end\":43738,\"start\":43725},{\"end\":43746,\"start\":43738},{\"end\":44364,\"start\":44351},{\"end\":44376,\"start\":44364},{\"end\":44383,\"start\":44376},{\"end\":44399,\"start\":44383},{\"end\":44408,\"start\":44399},{\"end\":44420,\"start\":44408},{\"end\":44431,\"start\":44420},{\"end\":44439,\"start\":44431},{\"end\":44445,\"start\":44439},{\"end\":44452,\"start\":44445},{\"end\":44460,\"start\":44452},{\"end\":44825,\"start\":44814},{\"end\":45106,\"start\":45094},{\"end\":45117,\"start\":45106},{\"end\":45487,\"start\":45477},{\"end\":45498,\"start\":45487},{\"end\":45509,\"start\":45498},{\"end\":45520,\"start\":45509},{\"end\":45883,\"start\":45876},{\"end\":45890,\"start\":45883},{\"end\":45898,\"start\":45890},{\"end\":45906,\"start\":45898},{\"end\":45913,\"start\":45906},{\"end\":46279,\"start\":46273},{\"end\":46285,\"start\":46279},{\"end\":46294,\"start\":46285},{\"end\":46301,\"start\":46294},{\"end\":46314,\"start\":46301},{\"end\":46330,\"start\":46314},{\"end\":46339,\"start\":46330},{\"end\":46349,\"start\":46339},{\"end\":46693,\"start\":46685},{\"end\":46700,\"start\":46693},{\"end\":46708,\"start\":46700},{\"end\":46958,\"start\":46947},{\"end\":46966,\"start\":46958},{\"end\":46980,\"start\":46966},{\"end\":46993,\"start\":46980},{\"end\":47003,\"start\":46993},{\"end\":47017,\"start\":47003},{\"end\":47039,\"start\":47017},{\"end\":47055,\"start\":47039},{\"end\":47068,\"start\":47055},{\"end\":47430,\"start\":47419},{\"end\":47445,\"start\":47430},{\"end\":47456,\"start\":47445},{\"end\":47475,\"start\":47456},{\"end\":47484,\"start\":47475},{\"end\":47909,\"start\":47902},{\"end\":47918,\"start\":47909},{\"end\":47925,\"start\":47918},{\"end\":47931,\"start\":47925},{\"end\":47937,\"start\":47931},{\"end\":48282,\"start\":48271},{\"end\":48291,\"start\":48282},{\"end\":48301,\"start\":48291},{\"end\":48311,\"start\":48301},{\"end\":48668,\"start\":48654},{\"end\":48678,\"start\":48668},{\"end\":48686,\"start\":48678},{\"end\":49041,\"start\":49033},{\"end\":49052,\"start\":49041},{\"end\":49063,\"start\":49052},{\"end\":49076,\"start\":49063},{\"end\":49089,\"start\":49076},{\"end\":49432,\"start\":49421},{\"end\":49443,\"start\":49432},{\"end\":49456,\"start\":49443},{\"end\":49465,\"start\":49456},{\"end\":49475,\"start\":49465},{\"end\":49486,\"start\":49475},{\"end\":49502,\"start\":49486},{\"end\":49524,\"start\":49502},{\"end\":49889,\"start\":49875},{\"end\":49902,\"start\":49889},{\"end\":49914,\"start\":49902},{\"end\":50275,\"start\":50267},{\"end\":50281,\"start\":50275},{\"end\":50289,\"start\":50281},{\"end\":50295,\"start\":50289},{\"end\":50655,\"start\":50647},{\"end\":50663,\"start\":50655},{\"end\":50669,\"start\":50663},{\"end\":50678,\"start\":50669},{\"end\":51010,\"start\":50996},{\"end\":51023,\"start\":51010},{\"end\":51250,\"start\":51237},{\"end\":51257,\"start\":51250},{\"end\":51269,\"start\":51257},{\"end\":51281,\"start\":51269},{\"end\":51291,\"start\":51281},{\"end\":51300,\"start\":51291},{\"end\":51323,\"start\":51300},{\"end\":51686,\"start\":51678},{\"end\":51699,\"start\":51686},{\"end\":51709,\"start\":51699},{\"end\":51718,\"start\":51709},{\"end\":51726,\"start\":51718},{\"end\":51735,\"start\":51726},{\"end\":51746,\"start\":51735},{\"end\":51757,\"start\":51746},{\"end\":51767,\"start\":51757},{\"end\":51781,\"start\":51767},{\"end\":51791,\"start\":51781},{\"end\":52255,\"start\":52244},{\"end\":52261,\"start\":52255},{\"end\":52270,\"start\":52261},{\"end\":52281,\"start\":52270},{\"end\":52291,\"start\":52281},{\"end\":52301,\"start\":52291},{\"end\":52313,\"start\":52301},{\"end\":52769,\"start\":52763},{\"end\":52780,\"start\":52769},{\"end\":52791,\"start\":52780},{\"end\":52801,\"start\":52791},{\"end\":52810,\"start\":52801},{\"end\":52820,\"start\":52810},{\"end\":52831,\"start\":52820},{\"end\":52843,\"start\":52831},{\"end\":53266,\"start\":53257},{\"end\":53278,\"start\":53266},{\"end\":53288,\"start\":53278},{\"end\":53299,\"start\":53288},{\"end\":53613,\"start\":53595},{\"end\":53861,\"start\":53849},{\"end\":54050,\"start\":54039},{\"end\":54063,\"start\":54050},{\"end\":54074,\"start\":54063},{\"end\":54086,\"start\":54074},{\"end\":54097,\"start\":54086},{\"end\":54108,\"start\":54097},{\"end\":54415,\"start\":54405},{\"end\":54427,\"start\":54415},{\"end\":54675,\"start\":54665},{\"end\":54685,\"start\":54675},{\"end\":54941,\"start\":54931},{\"end\":55104,\"start\":55091},{\"end\":55117,\"start\":55104},{\"end\":55129,\"start\":55117},{\"end\":55139,\"start\":55129},{\"end\":55150,\"start\":55139},{\"end\":55160,\"start\":55150},{\"end\":55171,\"start\":55160},{\"end\":55187,\"start\":55171},{\"end\":55196,\"start\":55187},{\"end\":55207,\"start\":55196},{\"end\":55221,\"start\":55207},{\"end\":55584,\"start\":55572},{\"end\":55593,\"start\":55584},{\"end\":55983,\"start\":55968},{\"end\":55992,\"start\":55983},{\"end\":56003,\"start\":55992},{\"end\":56291,\"start\":56280},{\"end\":56589,\"start\":56576},{\"end\":56594,\"start\":56589},{\"end\":57560,\"start\":57546}]", "bib_venue": "[{\"end\":38929,\"start\":38881},{\"end\":41906,\"start\":41851},{\"end\":42458,\"start\":42430},{\"end\":45221,\"start\":45173},{\"end\":45624,\"start\":45576},{\"end\":46017,\"start\":45969},{\"end\":46401,\"start\":46379},{\"end\":47556,\"start\":47526},{\"end\":55709,\"start\":55655},{\"end\":56055,\"start\":56033},{\"end\":57695,\"start\":57676},{\"end\":38491,\"start\":38485},{\"end\":38879,\"start\":38825},{\"end\":39445,\"start\":39430},{\"end\":39870,\"start\":39839},{\"end\":40164,\"start\":40146},{\"end\":40520,\"start\":40493},{\"end\":40829,\"start\":40810},{\"end\":41236,\"start\":41212},{\"end\":41849,\"start\":41788},{\"end\":42428,\"start\":42394},{\"end\":42810,\"start\":42737},{\"end\":43216,\"start\":43143},{\"end\":43856,\"start\":43746},{\"end\":44464,\"start\":44460},{\"end\":44848,\"start\":44841},{\"end\":45171,\"start\":45117},{\"end\":45574,\"start\":45520},{\"end\":45967,\"start\":45913},{\"end\":46377,\"start\":46349},{\"end\":46683,\"start\":46629},{\"end\":47078,\"start\":47068},{\"end\":47524,\"start\":47484},{\"end\":47948,\"start\":47937},{\"end\":48269,\"start\":48139},{\"end\":48652,\"start\":48550},{\"end\":49031,\"start\":48932},{\"end\":49533,\"start\":49524},{\"end\":49952,\"start\":49914},{\"end\":50320,\"start\":50295},{\"end\":50703,\"start\":50678},{\"end\":51044,\"start\":51023},{\"end\":51367,\"start\":51339},{\"end\":51799,\"start\":51791},{\"end\":52331,\"start\":52313},{\"end\":52861,\"start\":52843},{\"end\":53313,\"start\":53299},{\"end\":53593,\"start\":53483},{\"end\":53867,\"start\":53861},{\"end\":54037,\"start\":53977},{\"end\":54439,\"start\":54427},{\"end\":54702,\"start\":54685},{\"end\":54929,\"start\":54874},{\"end\":55240,\"start\":55221},{\"end\":55653,\"start\":55593},{\"end\":56031,\"start\":56003},{\"end\":56310,\"start\":56291},{\"end\":56574,\"start\":56452},{\"end\":56972,\"start\":56886},{\"end\":57674,\"start\":57560},{\"end\":58419,\"start\":58147},{\"end\":59157,\"start\":58834}]"}}}, "year": 2023, "month": 12, "day": 17}