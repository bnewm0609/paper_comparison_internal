{"id": 235306149, "updated": "2023-10-06 01:59:31.435", "metadata": {"title": "Knowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation", "authors": "[{\"first\":\"Lianghao\",\"last\":\"Xia\",\"middle\":[]},{\"first\":\"Chao\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Yong\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Peng\",\"last\":\"Dai\",\"middle\":[]},{\"first\":\"Xiyue\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Hongsheng\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Jian\",\"last\":\"Pei\",\"middle\":[]},{\"first\":\"Liefeng\",\"last\":\"Bo\",\"middle\":[]}]", "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "publication_date": {"year": 2021, "month": 10, "day": 8}, "abstract": "Accurate user and item embedding learning is crucial for modern recommender systems. However, most existing recommendation techniques have thus far focused on modeling users' preferences over singular type of user-item interactions. Many practical recommendation scenarios involve multi-typed user interactive behaviors (e.g., page view, add-to-favorite and purchase), which presents unique challenges that cannot be handled by current recommendation solutions. In particular: i) complex inter-dependencies across different types of user behaviors; ii) the incorporation of knowledge-aware item relations into the multi-behavior recommendation framework; iii) dynamic characteristics of multi-typed user-item interactions. To tackle these challenges, this work proposes a Knowledge-Enhanced Hierarchical Graph Transformer Network (KHGT), to investigate multi-typed interactive patterns between users and items in recommender systems. Specifically, KHGT is built upon a graph-structured neural architecture to i) capture type-specific behavior characteristics; ii) explicitly discriminate which types of user-item interactions are more important in assisting the forecasting task on the target behavior. Additionally, we further integrate the graph attention layer with the temporal encoding strategy, to empower the learned embeddings be reflective of both dedicated multiplex user-item and item-item relations, as well as the underlying interaction dynamics. Extensive experiments conducted on three real-world datasets show that KHGT consistently outperforms many state-of-the-art recommendation methods across various evaluation settings. Our implementation code is available at https://github.com/akaxlh/KHGT.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2110.04000", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2110-04000", "doi": "10.1609/aaai.v35i5.16576"}}, "content": {"source": {"pdf_hash": "a67085bc88589e01891f60d3ba942d73e48d3812", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2110.04000v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "03f0f2708425f26b07d5e7420c4941e41bc39b93", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a67085bc88589e01891f60d3ba942d73e48d3812.txt", "contents": "\nKnowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation\n\n\nLianghao Xia \nSouth China University of Technology\nChina\n\nChao Huang chaohuang75@gmail.com \nJD Finance America Corporation\nUSA\n\nYong Xu \nSouth China University of Technology\nChina\n\nCommunication and Computer\nNetwork Laboratory of Guangdong\nChina\n\nPeng Cheng Laboratory\nShenzhenChina\n\nPeng Dai \nJD Finance America Corporation\nUSA\n\nXiyue Zhang zhang.xiyue@mail.scut.edu.cn \nSouth China University of Technology\nChina\n\nHongsheng Yang \nJD Finance America Corporation\nUSA\n\nJian Pei jpei@cs.sfu.ca \nSimon Fraser University\nCanada\n\nLiefeng Bo liefeng.bo@jd.com \nJD Finance America Corporation\nUSA\n\nKnowledge-Enhanced Hierarchical Graph Transformer Network for Multi-Behavior Recommendation\n\nAccurate user and item embedding learning is crucial for modern recommender systems. However, most existing recommendation techniques have thus far focused on modeling users' preferences over singular type of user-item interactions. Many practical recommendation scenarios involve multi-typed user interactive behaviors (e.g., page view, addto-favorite and purchase), which presents unique challenges that cannot be handled by current recommendation solutions. In particular: i) complex inter-dependencies across different types of user behaviors; ii) the incorporation of knowledgeaware item relations into the multi-behavior recommendation framework; iii) dynamic characteristics of multityped user-item interactions. To tackle these challenges, this work proposes a Knowledge-Enhanced Hierarchical Graph Transformer Network (KHGT), to investigate multi-typed interactive patterns between users and items in recommender systems. Specifically, KHGT is built upon a graph-structured neural architecture to i) capture type-specific behavior characteristics; ii) explicitly discriminate which types of user-item interactions are more important in assisting the forecasting task on the target behavior. Additionally, we further integrate the graph attention layer with the temporal encoding strategy, to empower the learned embeddings be reflective of both dedicated multiplex user-item and item-item relations, as well as the underlying interaction dynamics. Extensive experiments conducted on three real-world datasets show that KHGT consistently outperforms many state-of-the-art recommendation methods across various evaluation settings. Our implementation code is available in https://github.com/akaxlh/KHGT.\n\nIntroduction\n\nRecommender systems have been widely deployed in many Internet services (e.g., e-commerce, online review and advertising systems) to alleviate information overload and deliver the most relevant items to users Huang et al. 2019a). In the recommendation scenario with the focus on implicit feedback, Collaborative Filtering (CF) becomes one of most popular paradigm which factorizes user-item interactions into latent representations and predicts user's preference based on the projected low-dimensional embeddings (Chen et al. 2020).\n\nMany deep neural network techniques have been developed to enhance collaborative filtering architecture for nonlinear feature interactions. Specifically, early studies, like NCF (He et al. 2017) and DMF (Xue et al. 2017) utilize the Multi-layer Perceptron to handle the non-linear interactions. Furthermore, autoencoder-based methods are designed for mapping high-dimensional sparse user-item interactions into low-dimensional dense representations (Sedhain et al. 2015;Wu, DuBois et al. 2016). Later works investigate the use of graph neural network to exploit the high-order user-item relations, and perform neighborhood-based feature aggregations Wang et al. 2019c).\n\nAlthough these methods have shown promising results, a deficiency is that they only model singular type of useritem interactions, which makes them insufficient to distill the complex collaborative signals from the multi-typed behaviors of users (Jin et al. 2020). In particular, there typically exist multiple relations between user and item that exhibit various behavior characteristics in many real-world recommendation scenarios, which are particularly helpful in learning users' preferences on the target type of behavior (Guo et al. 2019). For example, in online retail platforms, users' page view and add-to-favorite activities over different items, can serve as the auxiliary knowledge for assisting the forecasting task of customer purchase (target behavior). Therefore, it is crucial to take such inter-type behavioral influences into consideration to more accurately infer user preferences.\n\nThere are several key technical challenges that remain to be solved to realize the multi-behavior recommendation. First, how to distill the user-specific collaborative signals from the multiplex user-item interaction behaviors, is a significant challenge to tackle. In practice, type-specific behavioral patterns interweave with each other in a complex manner (Gao et al. 2019b), like the complementary correlations between the add-to-cart and purchase behaviors, or users' negative reviews are mutually exclusive with their positive feedback over the same item. Without the explicitly encoding of such heterogeneous relationships between user and item, models may suffer from the inability of capturing the complicated inherent cross-type behavior dependencies in a hierarchical way. Second, another core challenge lies in the incorporation of knowledge-aware item semantic relatedness into the encoding function of multi-behavioral patterns. The knowledge-aware side information often contains much fruitful facts and contextual connections about items (Wang et al. 2019a). It is desirable to rigorously design a joint embedding paradigm over the user-item and item-item relations in our multi-behavior recommendation. Third, a time-aware model is needed to better handle the temporal information of user-item interactions.\n\nThere are a handful of recent models that attempt to integrate multi-behavioral interactive patterns for making recommendations (Jin et al. 2020;Gao et al. 2019b). However, these works intend to consider multi-typed interactions in a relatively independent and local manner (e.g., singular dimensional cascading correlations), and can hardly capture the high-order multiplex relationships across users and items. Additionally, how to account for the side knowledge from items as well as user-item interaction dynamics, is less explored in those multi-behavior recommender systems.\n\nIn light of these differences and challenges, we present a general framework-Knowledge-Enhanced Hierarchical Graph Transformer Network (KHGT), for multi-behavior recommendation. Particularly, at the first stage, we develop a multi-behavior graph transformer network which performs recursive embedding propagation, to capture behavior heterogeneity across users and items in an attentive aggregation schema. As a result, user-item and item-item relationships of different types are enabled to maintain their specific representation space. To handle behavior dynamics, we inject the time-aware context into the graph transformer framework through a temporal encoding strategy. In addition, to encode the inter-dependencies between type-specific behavior representations, a multi-behavior mutual attention encoder is proposed to learn dependent structures of different types of behaviors in a pairwise manner. Finally, a gated aggregation layer is introduced to discriminate the contribution of typespecific relation embeddings for making recommendations.\n\nThe contributions of this paper are highlighted as follows:\n\n\u2022 We propose a framework KHGT, which explicitly achieves high-order relation learning in the knowledgeaware multi-behavior collaborative graph under the hierarchically structured graph transformer network.\n\n\u2022 To jointly integrate user-and item-wise collaborative similarities under the multi-behavior modeling paradigm of KHGT: i) the first-stage graph-structured transformer module captures the type-specific user-item interactive patterns in a time-aware environment; ii) the second-stage attentive fusion network encodes the cross-type behavior hierarchical dependencies and discriminates the typespecific contribution, in forecasting the target behaviors.\n\n\u2022 We apply the proposed KHGT method to three real-world datasets of movie, venue and product recommendations. Experiments show that our model achieves significant gains over many state-of-the-art baselines from various lines. Furthermore, model interpretation ability is also investigated with case studies of qualitative examples.\n\n\nPreliminaries\n\nWe begin with the introduction of key notations and consider a typical recommendation scenario with I users ( U = {u 1 , ..., u i , ..., u I }) and J items (V = {v 1 , ..., v j , ..., v J }).\n\nWe further define the relevant graph-structured data as: User-Item Multi-Behavior Interaction Graph. G u . With the awareness of different types of user-item interactions, a multi-behavior interaction graph is defined as: G u = (U, V, E u ), in which the edge set E u represents K types of relations (e.g., browse, add-to-favorite, purchase) between user and item. In E u , each edge e k i,j denotes that user u i interacts with item v j under the behavior type of k. Knowledge-aware Item-Item Relation Graph. G v . To incorporate the side information of items, we define graph G v = (V, E v ) to characterize multiplex dependencies across items with the consideration of their external knowledge. In G v , edge e r j,j linked between item v j and v j with their meta relations, which is denoted as {(v j , r, v j )|v j , v j \u2208 V, r \u2208 R}. Here, R indicates the set of relations which can be generated from different aspects, such as v j and v j belong to the same category, from the same location, or interacted with the same user under the same behavior type. Task Formulation. Based on above definitions, we formulate the knowledge-aware multi-behavior recommendation:\n\nInput: the user-item multi-behavior interaction graph G u and the knowledge-aware item-item relation graph G v .\n\nOutput: a predictive model which effectively infers the probability y i,j of unseen interaction between user u i and item v j under the target behavior type of k.\n\n\nMethodology\n\nWe elaborate the details of KHGT, which investigates the multiplex user-item relations in an end-to-end manner.\n\n\nAttentive Heterogeneous Message Aggregation\n\nIn this component, we aim to collectively capture the multibehavior user-item interactive patterns and item-item dependencies in a unified graph-structured neural network. The overall architecture is shown in Figure 2. Multi-Behavior Interactive Pattern Encoding. This module aims to aggregate the heterogeneous signals from multi-behavioral patterns between the user and his/her interacted items. Towards this end, we develop an adaptive multi-behavior self-attention network under a message passing paradigm with the enhancement of global behavior context, which consists of three key modules: temporal context encoding scheme, information propagation and aggregation. Temporal Information Encoding. To capture the influences between different types of user-item interactions in a time-aware scenario, we develop a temporal context encoding scheme, to incorporate the behavior dynamics in our heterogeneous message aggregation architecture. In particular, given the connection E k i,j between user u i and item v j under the behavior of k, we map their corresponding interaction timestamp t k i,j into the time slot as \u03c4 (t k i,j ), and utilize  the sinusoidal functions for embedding T k i,j \u2208 R 2d generation, which is motivated by the positional embedding framework in Transformer (Vaswani et al. 2017;Hu et al. 2020;Wu et al. 2020).\nT k,(2l) (i,j) = sin( \u03c4 (t k i,j ) 10000 2l d ), T k,(2l+1) (i,j) = cos( \u03c4 (t k i,j ) 10000 2l+1 d ) (1)\nwhere the element indexs (even and odd position index) in the temporal information embedding are represented as (2l) and (2l + 1), respectively. d is the latent dimensionality. To augment the tunable ability of our temporal context encoding, we further apply a projection layer over T k i,j as:\nT k i,j = T k i,j \u00b7 W k , W k \u2208 R 2d\u00d7d\n. W k is the transformation weights corresponding to k-th type of interactions. Information Propagation Phase. We perform the timeaware information propagation between the source and target node, over the multi-behavior user-item interaction graph G u , with the following graph attentive mechanism:\nm k i\u2190j = H h=1 \u03c9 h i,j,k \u00b7 V h k p j ; m k j\u2190i = H h=1 \u03c9 h j,i,k \u00b7 V h k p i (2)\nwhere m k i\u2190j and m k j\u2190i denote the propagated message from item v j to user u i , and from u i to v j , respectively. p j is the element-wise addition between initialized item embedding e j and the corresponding temporal context representation T k i,j . i.e., p j = e j \u2295T k i,j . Similar operation is applied for the message from user side:\np i = e i \u2295T k i,j . V h k \u2208 R d H \u00d7d\nis the h-head projection matrix with respect to the k-th behavior type. In addition, \u03c9 h i,j,k , \u03c9 h j,i,k represent the learned attentive propagation weights over the constructed message p j and p i , respectively. Formally, they are calculated as:\n\u03c9 h i,j,k = (Q h k p i ) (K h k p j ) d/H ; \u03c9 h i,j,k = exp(\u03c9 h i,j,k ) \u03a3 e k i,j \u2208Eu exp(\u03c9 h i,j ,k ) where Q h k , K h k \u2208 R d\nH \u00d7d are the head-specific query and key transformation with respect to the k-th behavior type. To incorporate the global context across different behavior types in the message passing process, we learn the attention-based transformation matrices Q h k , K h k , V h k in a multi-channel parameter learning framework. To be specific, we design a base transformation paradigm which consists of M channels of parameters, i.e.,Q\nh m ,K h m ,V h m (m = 1...M ).\nThey correspond to M latent projection subspaces, which reflect different aspects of the common behavior context across different types. Formally, the type-specific transformation procedure is performed with the gating mechanism:\nQ h k = M m=1 \u03b1 k mQ h m , K h k = M m=1 \u03b2 k mK h m , V h k = M m=1 \u03b3 k mV h m(3)\nwhere \u03b1 k m , \u03b2 k m , \u03b3 k m are quantitative gated weights for the m-th channel transformation with respect to behavior type of k. Typically, the number of channels M is smaller than the number of behavior types K in practice, which enables the parameter-efficient heterogeneous message aggregation. Information Aggregation Phase. Based on the constructed propagated message m k i\u2190j and m k j\u2190i , we aggregate the neighboring information with the summation operation:\nq k i = f ( v j \u2208N i m k i\u2190j ); q k j = f ( v i \u2208N j m k j\u2190i )(4)\nwhere N i and N j denote the neighborhood of u i and v j in the user-item interaction graph G u . q k i , q k j are the aggregated information of u i and v j under the behavior type of k. f (\u00b7) is an activation function like LeakyReLU.\n\nInformation Aggregation for Item-side Relations. We fuse the heterogeneous signals from the item-item interdependencies with the attentive aggregation:\nq r j = f ( v j \u2208N j m r j\u2190j ) = v j \u2208N j H h=1 \u03c9 h j,j ,r V h r p j(5)\nwhere r is the index of R different item-item relations and N j indicates the neighboring nodes of v j over the graph G v .\n\n\nBehavior Hierarchical Dependency Modeling\n\nIn our multi-behavior recommendation scenarios, user behaviors with different types interact with each other in a complex and hierarchical way. To address this challenge, two questions arise: i) how do we effectively preserve mutual relations between different types of behavior; ii) how to promote the collaboration across different type-specific behavior representations in assisting the final recommendation. Our mutual relation encoder is developed based on the scaled dot-product attention via learning the pairwise type-wise relevance scores \u03bb i,h k,k , which is formally represented:\nq k i = MH-Att(q k i ) = H h=1 K k =1 \u03bb i,h k,k \u00b7\u1e7c h \u00b7 q k i (6) \u03bb i,h k,k = exp\u03bb i,h k,k K k =1 exp\u03bb i,h k,k ;\u03bb i,h k,k = (Q h \u00b7 q k i ) (K h \u00b7 q k i ) d/H whereQ h ,K h ,\u1e7c h\nare learnable projection matrices of the h-th learning subspace. Similar operations are applied for updating the item embeddingq k j . Next, we propose to fuse the learned type-specific behavior representations, by investigating the individual importance in forecasting the target type of user interactions. We present our gated fusion mechanism for conclusive representation \u03a6 j as:\n\u03a6 j = K k=1 \u03b7 k jq k j \u2295 R r=1 \u03be r jq r j ; \u03b7 k j = \u03c3(\u03b7 k j ); \u03be r j = \u03c3(\u03be r j ) (7)\n\u03c3(\u00b7) is the softmax function. \u03b7 k j and \u03be r j are the learned importance score of k-th type of user-item interaction representationq k i , and r-th type of item-item relation representatio\u00f1 q r j , respectively. They are formally calculated as:\n\u03b7 k j = a 0 f (q k j ) + c u 0 ;\u03b7 r j = b 0 f (q r j ) + c v 0 (8) f (\u00b7) denotes the multi-layer network as: f (q k j ) = B u 1q k j + B u 2 K k =1q k j + c u 1 . Parameters in our gated fusion layer are denoted as a 0 , b 0 , B * 1 , B * 2 (transformations)\n, c * 0 and c * 1 (bias terms). This gating mechanism is also utilized for obtaining user representation \u03a6 i over type-specific embeddingsq k i . High-order Multi-Behavior Pattern Propagation. Based on the defined information propagation and aggregation functions, we capture high-order collaborative relations under the multi-behavior context (user-item interaction graph G u ) in our graph neural network. The update procedure from the (l)-th layer to the (l + 1)-th layer is (\u03a6\n(l) j \u2208 R d ): \u03a6 (l+1) j \u2190 Aggregate i\u2208Nu(j);j \u2208Nv(j) Propagate(\u03a6 l i , \u03a6 l j , G) (9)\nPropagate(\u00b7) is the information propagation function which extracts useful features from both the user-item interactions (over E u ) and item-item dependencies (over E v ). Aggregate(\u00b7) denotes the information fusion function. The final embeddings are summarized cross different orderspecific representations as:\n\u03a6 j = \u03a6 (1) j \u2295 ... \u2295 \u03a6 (L) j .\n\nThe Learning Phase of KHGT\n\nAfter generating the conclusive representations \u03a6 i and \u03a6 j for users and items, the likelihood of u i interacting with v j under the target behavior can be inferred as Pr i,j = z \u00b7 (\u03a6 i \u03a6 j ). To perform the model optimization, we aim to minimize the following marginal pair-wise loss function:  where I denotes the number of trained users, and S denotes the number of positive-negative pairs for each user. In practice, we randomly sample S positive items v p1 , v p2 , ..., v ps and S negative items v n1 , v n2 , ..., v ns for each user. In addition, \u0398 represents the set of all trainable parameters, and \u03bb is the weight for the regularization term. Sub-graph Sampling for Large-Scale Data. One key challenge of graph neural architecture lies in the information aggregation over the entire graph in a full-batch mode, which consumes tremendous memory and computation cost. To endow KHGT with the ability of handling large-scale data, we develop a random-walk-based sub-graph sampling algorithm over the graph G u and G v , and maintain a weight vector during the sampling process based on node relatedness extracted from the adjacent matrix of the graph.\nL = I i=1 S s=1 max(0, 1 \u2212 Pr i,ps + Pr i,ns ) + \u03bb \u0398 2 F(10)\nModel Complexity Analysis. Our KHGT spends O(K \u00d7 (I + J) \u00d7 d 2 ) to calculate the Q, K, V transformations, and O(|E| \u00d7 d) for information aggregation. For type-wise relation modeling, the most prominent computation comes from the O(K \u00d7 (I + J) \u00d7 d 2 ) transformations. Overall, our KHGT could achieve comparable time complexity with the GNN-based multi-behavior recommendation methods. Also, KHGT costs moderate extra memory for the intermediate results, compared to the most existing GNN models.\n\n\nEvaluation\n\nThis section answers the following research questions: Online Retail Data. We also investigate our KHGT in a real-world online retail scenario with explicit multi-typed user-item interactions, i.e., page view, add-to-cart, add-tofavorite and purchase. For this application, the target behavior is set as purchases and the other three types of user behaviors are considered as auxiliary behavioral signals. For the above applications, the knowledge-aware itemitem relation graph G v is generated with item meta-relations from two dimensions: i) v j -u i -v j under the behavior type of k; ii) the categorical relations between item v j and v j .\n\nEvaluation Protocols. We adopt two metrics: Normalized Discounted Cumulative Gain (NDCG@N ) and Hit Ratio (HR@N ) which have been widely used in recommendation tasks (Wang et al. 2019c;Chen et al. 2018). Note that higher HR and NDCG scores signal better performance. Following the same settings in (Yu et al. 2019;Zhao et al. 2020), we employ the time-aware leave-one-out evaluation to split the training/test sets. The test set contains the last interactive item of users and the rest of data is used for training. For fair and efficient evaluation, each positive instance is paired with randomly selected 99 non-interactive items, which is consistent with the experimental settings in (Sun et al. 2019;Huang et al. 2019b).\n\n\nMethods for Comparison. Baselines are presented as: Conventional Matrix Factorization Approach:\n\n\u2022 BiasMF (Koren, Bell, and Volinsky 2009): it enhances the matrix factorization paradigm by incorporating user and item bias with the corresponding implicit feedback.\n\nAutoencoder-based Collaborative Filtering:\n\n\u2022 AutoRec (Sedhain et al. 2015): it is a stacked autoencoder architecture to project user-item interactions into hidden representation unit with the data reconstruction loss.\n\n\u2022 CDAE (Wu, DuBois et al. 2016): it designs a denoising Autoencoder for user-item interaction modeling.\n\nNeural Network-enhanced Collaborative Filtering:\n\n\u2022 DMF (Xue et al. 2017): it enhances the MF with a multilayer perceptron to encode the interaction vector of users.\n\n\u2022 NCF (He et al. 2017): Three variants of NCF with different interaction encoders: i.e., Multilayer perceptron (NCF-M), concatenated element-wise-product branch (NCF-N) and the fixed element-wise product (NCF-G).\n\nNeural Auto-regressive Recommendation Methods:\n\n\u2022 NADE (Zheng et al. 2016): it incorporates the parameter sharing mechanism into the autoregressive CF model.\n\n\u2022 CF-UIcA (Du et al. 2018): it is a neural CF framework with auto-regression on user-item correlations.\n\nGraph Neural Networks Collaborative Filtering:\n\n\u2022 ST-GCN : it is a graph-structured encoder-decoder framework to learn latent embeddings of users and items under data scarcity, via GCNs.\n\n\u2022 NGCF (Wang et al. 2019c): it is a message passing architecture to exploit high-order connection relationships.\n\nRecommendation with Multi-Behavioral Patterns.\n\n\u2022 NMTR (Gao et al. 2019a): it is a multi-task recommendation framework which explores the cascaded correlations between multiple types of user-item interactive behavior.\n\n\u2022 DIPN (Guo et al. 2019): this approach jointly considers the behavior patterns of browsing and buying with the bidirectional recurrent network based attention mechanism.\n\n\u2022 NGCF M (Wang et al. 2019c): we integrate the multibehavioral relation learning with the neural graph collaborative filtering model under a joint graph neural network.\n\n\u2022 MATN (Xia et al. 2020): it learns the type-wise interaction dependencies with a memory attention network.\n\n\u2022 MBGCN (Jin et al. 2020): it models the multi-behavior of users and uses graph convolutional network to perform behavior-aware embedding propagation.\n\nKnowledge-aware Recommendation Method.\n\n\u2022 KGAT (Wang et al. 2019b): it investigates the high-order connectivity of the semantic item relations over the collaborative knowledge graph, with GAT framework.\n\nParameter Settings. We implement KHGT with Tensor-Flow and infer the model parameters with Adam optimizer. Our multi-head self-attention module is configured with the 2 heads for embedding learning. The channels of base transformations in our graph attention module is set as 2. The model training process is performed with the learning rate of 1e \u22123 (with decay rate of 0.96) and batch size of 32. The regularization strategy with the weight decay, which is chosen from the set of {0.1, 0.05, 0.01, 0.005, 0.001}. This is applied in the training phase to alleviate the overfitting issue.\n\n\nPerformance Validation (RQ1)\n\nWe first present the performance of all methods in forecasting the target type of user-item interactions on three datasets in Table 2. From the results, we observe that remarkable performance improvement can be achieved by KHGT on different types of datasets. Such performance gap can be attributed to the joint exploration of multi-type behavior interdependencies and the underlying knowledge-aware item collaborative signals. Among various competitive methods, the recommender systems (e.g., NMTR, NGCF M , MBGCN) which consider multi-typed interactions, improve the performance as compared to other baselines. This points to the positive effect of aggregating multiplex behavioral patterns in the designed interaction encoding function. Furthermore, GNN-based neural approaches perform better than autoencoder and autoregressive CF models, suggesting the rationality of exploring high-order collaborative signals over user-item relations. We investigate the ranking quality of top-k items recommended by different methods ranging from 1 to 9. Table 3 lists the results of Yelp data. We can observe that the best performance is always achieved by KHGT under different top-N settings.    \n\n\nModel Ablation Study (RQ2)\n\nWe consider different model variants of KHGT from five perspectives and analyze their effects (as shown in Figure 3): Type-specific Behavioral Pattern Modeling. KHGT-GA. We first evaluate the effect of our type-specific behavior semantic learning by replacing our attentive heterogeneous information aggregation with graph convolutional network. Behavior Mutual Dependency Modeling. KHGT-MR. We remove the transformer-based mutual relation encoder to capture inter-dependencies of different types of behaviors. Cross-Type Behavioral Pattern Fusion. KHGT-BF. This simplified variant directly applies the mean pooling operation over the type-specific behavior representations, instead of using the designed gated fusion layer. Temporal Context Encoding. KHGT-Ti. This variant does not include the temporal context embedding when performing information propagation in our graph transformers. Incorporation of Item-Item Relations. KHGT-KG. It does not integrate the item-item relations in the framework.\n\nWe can observe that the full version of our developed KHGT achieves the best performance in all cases. We further summarize the conclusions: (1) Modeling the type-specific user-item interactive patterns in an explicit attentive way, is better than performing graph-structured convolutions. (2) The efficacy of augmenting the multi-behavior recommendation with the underlying mutual relation learning. (3) The necessity of explicit discrimination for the contributions of type-specific behavior patterns. (4) The positive effect of temporal context information in capturing the behavior dynamics. (5) The incorporation of item external knowledge in our graph neural network is helpful for more accurately encoding user's multi-dimensional preference.\n\nPerformance v.s. Multi-Behavior Integration (RQ3)\n\nWe conduct the ablation experiments to validate whether the incorporation of more diverse behavior types could boost the performance. The model variants are generated with rubric as follows: (1) \"+\"behavior type indicates only using the target behavior itself to make predictions (e.g., +like, +buy).\n\n(2) \"-\"behavior type means removing this specific type of interactions (e.g., -pv: page-view, -cart: add-to-cart) in forecasting the user's target behavior. From the results in Figure 4, KHGT using all types of interaction behaviors consistently achieves the best performance compared to other variants, which suggests that more diverse behavior incorporation could improve the recommendation results with more comprehensive multi-behavior knowledge.\n\n\nInfluences of Interaction Sparsity Degrees (RQ4)\n\nwe further perform experiments to evaluate the model performance with respect to different sparsity levels of useritem interaction data. In particular, each user is grouped in one of five different data sparsity degrees in terms of his/her interaction density over items. The bars in the background of Figure 5 show the number of users which belong to the corresponding sparsity levels in x-axis. We keep the total number of interaction summation of each sparsity level as the same. The y-axis shows the recommendation accuracy of KHGT and several representative baselines. We can notice that the performance gap between our approach and other competitors become more significant as data becomes more sparse, which also ascertains the reasonableness of KHGT in enhancing recommender systems with the capability of learning complex interactive patterns, by modeling interdependencies among various types of user behaviors.\n\n\nHyperparameter Effect Investigation (RQ5)\n\nWe show the parameter study results of KHGT in Figure 6.\n\n\u2022 Embedding Dimensionality: d. The model achieves better performance when we increase d from 4 to 16, since a larger hidden dimension representation might be beneficial to capture more latent factors for user-item interac- tions. Due to the overfitting phenomenon, the performance degrades with the further increase of d.\n\n\u2022 Time Resolution of Temporal Encoding: \u03c4 (\u00b7). The best performance is achieved with the projected time slot of week resolution, which indicates that the weekly interactive patterns is a good trade-off between the modeling of user-specific behavior dynamics and interweave correlations with others. \u2022 Depth of Graph Neural Network: L. By stacking more graph neural layers to jointly capture the high-order useritem and item-item collaborative relations, the recommendation performance is improved. KHGT with two recursive message propagation layers achieves the best results. \u2022 Sub-graph Sampling Scale N . Table 4 shows the performance when varying the sampled sub-graph size (measured by # of nodes). We observe that training with smaller sub-graph size (training with dropout regularization to alleviate overfitting), and relatively larger sample scale for test (more graph context is provided for prediction), results in better recommendations accuracy.\n\n\nCase Studies of KHGT's Explainability (RQ6)\n\nWe visualize the learned explicit relevance scores of our KHGT model for predicting purchases on retail data in Figure 7. We observe that different types of user-item interactions (4 types) and item-item relations (5 types) are correlated in a hierarchical and explainable manner (Brighter colors signal higher behavior relevance). In particular, Squares and circles represent the learned cross-type behavior dependencies in our type-wise behavior mutual relation encoder and cross-type behavioral pattern fusion, respectively. Both first-and second-order attentive weights are presented.\n\n\nRelated Work\n\nRecommendation with Multi-Relation Modeling. There exist many recommender systems which are developed to characterize user representations, with the consideration of different-typed relations from either user or item side (Yu Training    For example, to alleviate the data sparsity issue, a lot of social recommender systems have been proposed to boost the prediction performance via integrating the useruser social influential dependencies with the user-item interactive relations (Huang et al. 2021b;Fan et al. 2019). Furthermore, another paradigm of multi-relation recommendation models leverage external knowledge graph information to construct different structural relations between a set of entities or items (Wang et al. 2019a,b). Different from them, this work generalizes the joint modeling of multiplex collaborative relations and knowledge-aware item dependency in the multi-behavior recommendation. Graph Neural Network Recommender Systems. With the recent success of graph neural network in aggregating information from various relational data, many graph neural techniques have been proposed to learn user's preference over the graph-structured data for various recommendation tasks, such as GraphSAGE (Hamilton, Ying et al. 2017) and NGCF (Wang et al. 2019c) for encoding high-order useritem interactions, and GNNs for users' sequential behavior modeling (Huang et al. 2021a). Inspired by the above research work, we propose a new method KHGT within the broader graph neural paradigm for multi-behavior recommendation, to solve its unique challenges resulting from relation heterogeneity between users and items.\n\n\nConclusion\n\nThis paper explicitly models type-specific user behavioral pattern in enhancing recommender systems. We devise a novel hierarchical graph transformer network, termed as KHGT, to perform the joint information aggregation over the user-item and item-item collaborative relations in multiple knowledge-aware behavior modalities. This refines type-specific behavior representations and encode their finegrained interactive preference over items. Evaluation results on three datasets well validate our framework. Our future work is to fully deploy KHGT in an online working system to handing the streaming data in a recursive mode.\n\nFigure 1 :\n1The model architecture of KHGT framework.\n\nFigure 2 :\n2The framework of global context enhanced parameter learning and behavior dynamics encoding in KHGT.\n\nFigure 3 :Figure 4 :\n34Ablation studies of sub-modules in KHGT. Impact study of different behavior types on Yelp and Online Retail data, in terms of HR@k and NDCG@k.\n\nFigure 5 :Figure 6 :\n56Model performance on the online Retail data w.r.t. different data sparsity, in terms of HR@10 and NDCG@10. Hyper-parameter study for the like/purchase prediction in terms of HR@10 and NDCG@10.\n\nFigure 7 :\n7Visualized explicit relevance learned by KHGT. et al. 2018).\n\n\n\u00d7 10 7 {Page View, Favorite, Cart, Purchase}Dataset \nUser # Item # Interaction # \nInteractive Behavior Type \n\nYelp \n19800 22734 1.4 \u00d7 10 6 \n{Tip, Dislike, Neutral, Like} \nML10M \n67788 8704 9.9 \u00d7 10 6 \n{Dislike, Neutral, Like} \nOnline Retail 805506 584050 6.4 \n\nTable 1 :\n1Statistics of the experimented datasets\n\n\n\u2022 RQ1: How does KHGT perform compared with the various state-of-the-art recommender systems? \u2022 RQ2: How do different designed modules and captured relational structures contribute to the model performance? \u2022 RQ3: How does KHGT work with the integration of different types of behavior in our heterogeneous aggregator? \u2022 RQ4: How does KHGT perform w.r.t different interaction sparsity levels as compared to representative competitors? \u2022 RQ5: How does KHGT perform with different parameter settings (e.g., latent dimensionality and GNN depth)? \u2022 RQ6: How is the interpretation ability of our KHGT in capturing behavior inter-dependencies?Experimental Settings \n\nData Description. We show the data statistics in Table 1. \nMovieLens Data. We differentiate explicit user's rating \nscores r (i.e., [1, ..., 5]) into multiple behavior types: (1) \nr \u2264 2: dislike behavior. (2) 2< r <4. neutral behavior. (3) \nr \u2265 4: like behavior. In this data, the target and auxiliary be-\nhaviors are set as (like) and (neutral, dislike), respectively. \nYelp Data. User's feedbacck interactions over items in this \ndata, are projected into three behavior types by following \nthe same partition rubric of MovieLens. We regard the like \n\nbehavior as the target type and (dislike, neutral, tip) as aux-\niliary sources, where tip behavior indicates that users gave \ntips on their visited venues. \n\n\n\nData Metric BiasMF DMF NCF-M NCF-G NCF-N AutoRec CDAE NADE CF-UIcA ST-GCN NGCF NMTR DIPN NGCF M MBGCN MATN KGAT KHGTYelp \nHR \n0.755 \n0.756 \n0.714 \n0.755 \n0.771 \n0.765 \n0.750 \n0.792 \n0.750 \n0.775 \n0.789 0.790 0.791 \n0.793 \n0.796 \n0.826 0.835 0.880 \nNDCG 0.481 \n0.485 \n0.429 \n0.487 \n0.500 \n0.472 \n0.462 \n0.499 \n0.469 \n0.465 \n0.500 0.478 0.500 \n0.492 \n0.502 \n0.530 0.543 0.603 \n\nMovieLens \nHR \n0.767 \n0.779 \n0.757 \n0.787 \n0.801 \n0.658 \n0.659 \n0.761 \n0.778 \n0.738 \n0.790 0.808 0.811 \n0.825 \n0.826 \n0.847 0.817 0.861 \nNDCG 0.490 \n0.485 \n0.471 \n0.502 \n0.518 \n0.392 \n0.392 \n0.486 \n0.491 \n0.444 \n0.508 0.531 0.540 \n0.546 \n0.553 \n0.569 0.514 0.597 \n\nRetail \nHR \n0.262 \n0.305 \n0.319 \n0.290 \n0.325 \n0.313 \n0.329 \n0.317 \n0.332 \n0.347 \n0.302 0.332 0.317 \n0.374 \n0.369 \n0.354 0.377 0.464 \nNDCG 0.153 \n0.189 \n0.191 \n0.167 \n0.201 \n0.190 \n0.196 \n0.191 \n0.198 \n0.206 \n0.185 0.179 0.178 \n0.221 \n0.222 \n0.209 0.214 0.278 \n\n\n\nTable 2 :\n2Performance comparison on Yelp, MovieLens, Online Retail data, in terms of HR@k and NDCG@k (k = 10).Model \n@1 \n@3 \n@5 \n@7 \n@9 \nHR NDCG HR NDCG HR NDCG HR NDCG HR NDCG \n\n\n\nTable 3 :\n3Ranking performance evaluation on Yelp dataset with varying Top-K value in terms of HR@K and NDCG@K\n\n\nN Metric Number of Sub-graph Size N When Testing 20,000 30,000 50,000 70,000 90,000 110,000 130,00030,000 \nHR \n0.379 0.413 0.452 0.466 0.470 0.473 \n0.478 \n50,000 \nHR \n0.357 0.388 0.433 0.463 0.470 0.476 \n0.479 \n70,000 \nHR \n0.338 0.384 0.429 0.461 0.469 0.478 \n0.481 \n\nTesting Time (s) \n70.3 \n94.1 148.8 207.8 261.6 309.3 \n351.7 \n\n\n\nTable 4 :\n4Influence of the sub-graph sampling scale.User-Item Correlations% & \u2190 ! \" User-Item Correlations ! \" \u2190 % & ! \" \u2190 ! \"$User-Item Correlations \nUser-Item Correlations \n\n! \" \u2190 ! \"$ \n% & \u2190 ! \" \n\n1 st order \n\n2 nd order \n\n! \" \u2190 % & \n\nItem-Item Relations \n\nItem-Item Relations \n\n\nAcknowledgmentsWe thank the anonymous reviewers for their constructive feedback and comments. This work is supported by National Nature Science Foundation of China (62072188, 61672241), Natural Science Foundation of Guangdong Province (2016A030308013), Science and Technology Program of Guangdong Province (2019A050510010).\nEfficient Heterogeneous Collaborative Filtering without Negative Sampling for Recommendation. C Chen, M Zhang, Y Zhang, W Ma, Y Liu, S Ma, AAAI. 34Chen, C.; Zhang, M.; Zhang, Y.; Ma, W.; Liu, Y.; and Ma, S. 2020. Efficient Heterogeneous Collaborative Filtering with- out Negative Sampling for Recommendation. In AAAI, vol- ume 34, 19-26.\n\nSequential recommendation with user memory networks. X Chen, H Xu, Y Zhang, J Tang, Y Cao, Z Qin, WSDM. ACMChen, X.; Xu, H.; Zhang, Y.; Tang, J.; Cao, Y.; Qin, Z.; et al. 2018. Sequential recommendation with user memory net- works. In WSDM, 108-116. ACM.\n\nCollaborative filtering with user-item co-autoregressive models. C Du, C Li, Y Zheng, J Zhu, B Zhang, AAAI. Du, C.; Li, C.; Zheng, Y.; Zhu, J.; and Zhang, B. 2018. Col- laborative filtering with user-item co-autoregressive models. In AAAI.\n\nGraph neural networks for social recommendation. W Fan, Y Ma, Q Li, Y He, E Zhao, J Tang, D Yin, WWW. Fan, W.; Ma, Y.; Li, Q.; He, Y.; Zhao, E.; Tang, J.; and Yin, D. 2019. Graph neural networks for social recommendation. In WWW, 417-426.\n\nNeural multi-task recommendation from multi-behavior data. C Gao, X He, D Gan, X Chen, F Feng, Y Li, T.-S Chua, Jin , D , ICDE. IEEEGao, C.; He, X.; Gan, D.; Chen, X.; Feng, F.; Li, Y.; Chua, T.-S.; and Jin, D. 2019a. Neural multi-task recommendation from multi-behavior data. In ICDE, 1554-1557. IEEE.\n\n. C Gao, X He, D Gan, X Chen, F Feng, Y Li, T.-S Chua, L Yao, et al. 2019b. Learning to Recommend with Multiple Cascading Behaviors. TKDEGao, C.; He, X.; Gan, D.; Chen, X.; Feng, F.; Li, Y.; Chua, T.-S.; Yao, L.; et al. 2019b. Learning to Recommend with Multiple Cascading Behaviors. TKDE .\n\nBuying or Browsing?: Predicting Real-time Purchasing Intent using Attention-based Deep Network with Multiple Behavior. L Guo, L Hua, R Jia, B Zhao, KDD. Guo, L.; Hua, L.; Jia, R.; Zhao, B.; et al. 2019. Buying or Browsing?: Predicting Real-time Purchasing Intent using Attention-based Deep Network with Multiple Behavior. In KDD, 1984-1992.\n\nInductive representation learning on large graphs. W Hamilton, Z Ying, NIPS. Hamilton, W.; Ying, Z.; et al. 2017. Inductive representation learning on large graphs. In NIPS, 1024-1034.\n\n. X He, L Liao, H Zhang, Neural collaborative filtering. In WWW. He, X.; Liao, L.; Zhang, H.; et al. 2017. Neural collaborative filtering. In WWW, 173-182.\n\nHeterogeneous graph transformer. Z Hu, Y Dong, K Wang, WWW. Hu, Z.; Dong, Y.; Wang, K.; et al. 2020. Heterogeneous graph transformer. In WWW, 2704-2710.\n\nGraph-Enhanced Multi-Task Learning of Multi-Level Transition Dynamics for Session-based Recommendation. C Huang, J Chen, L Xia, Y Xu, P Dai, Y Chen, L Bo, J Zhao, J Huang, AAAI. Huang, C.; Chen, J.; Xia, L.; Xu, Y.; Dai, P.; Chen, Y.; Bo, L.; Zhao, J.; and Huang, J. 2021a. Graph-Enhanced Multi-Task Learning of Multi-Level Transition Dynamics for Session-based Recommendation. In AAAI.\n\nOnline Purchase Prediction via Multi-Scale Modeling of Behavior Dynamics. C Huang, X Wu, X Zhang, C Zhang, KDD. Huang, C.; Wu, X.; Zhang, X.; Zhang, C.; et al. 2019a. On- line Purchase Prediction via Multi-Scale Modeling of Be- havior Dynamics. In KDD, 2613-2622.\n\nKnowledge-aware Coupled Graph Neural Network for Social Recommendation. C Huang, H Xu, Y Xu, P Dai, M Lu, L Bo, AAAI. Huang, C.; Xu, H.; Xu, Y.; Dai, P.; Lu, M.; Bo, L.; et al. 2021b. Knowledge-aware Coupled Graph Neural Network for Social Recommendation. In AAAI.\n\nTaxonomy-aware multi-hop reasoning networks for sequential recommendation. J Huang, Z Ren, W X Zhao, G He, J.-R Wen, D Dong, WSDM. Huang, J.; Ren, Z.; Zhao, W. X.; He, G.; Wen, J.-R.; and Dong, D. 2019b. Taxonomy-aware multi-hop reasoning net- works for sequential recommendation. In WSDM, 573-581.\n\nMultibehavior recommendation with graph convolutional networks. B Jin, C Gao, X He, D Jin, Y Li, SIGIR. Jin, B.; Gao, C.; He, X.; Jin, D.; and Li, Y. 2020. Multi- behavior recommendation with graph convolutional net- works. In SIGIR.\n\nMatrix factorization techniques for recommender systems. Y Koren, R Bell, C Volinsky, Computer. 8Koren, Y.; Bell, R.; and Volinsky, C. 2009. Matrix factoriza- tion techniques for recommender systems. Computer (8): 30-37.\n\nDiversified Interactive Recommendation with Implicit Feedback. Y Liu, Y Xiao, Q Wu, C Miao, J Zhang, B Zhao, AAAI. Liu, Y.; Xiao, Y.; Wu, Q.; Miao, C.; Zhang, J.; Zhao, B.; et al. 2020. Diversified Interactive Recommendation with Implicit Feedback. In AAAI, 4932-4939.\n\nAutorec: Autoencoders meet collaborative filtering. S Sedhain, A K Menon, S Sanner, L Xie, WWW. Sedhain, S.; Menon, A. K.; Sanner, S.; and Xie, L. 2015. Au- torec: Autoencoders meet collaborative filtering. In WWW, 111-112.\n\nBERT4Rec: Sequential recommendation with bidirectional encoder representations from transformer. F Sun, J Liu, J Wu, C Pei, X Lin, W Ou, P Jiang, CIKM. Sun, F.; Liu, J.; Wu, J.; Pei, C.; Lin, X.; Ou, W.; and Jiang, P. 2019. BERT4Rec: Sequential recommendation with bidirec- tional encoder representations from transformer. In CIKM, 1441-1450.\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, \u0141 Kaiser, NIPS. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, \u0141.; et al. 2017. Attention is all you need. In NIPS, 5998-6008.\n\nKnowledge-aware graph neural networks with label smoothness regularization for recommender systems. H Wang, F Zhang, M Zhang, J Leskovec, M Zhao, W Li, KDD. Wang, H.; Zhang, F.; Zhang, M.; Leskovec, J.; Zhao, M.; Li, W.; et al. 2019a. Knowledge-aware graph neural networks with label smoothness regularization for recommender sys- tems. In KDD, 968-977.\n\nKgat: Knowledge graph attention network for recommendation. X Wang, X He, Y Cao, M Liu, T.-S Chua, KDD. Wang, X.; He, X.; Cao, Y.; Liu, M.; and Chua, T.-S. 2019b. Kgat: Knowledge graph attention network for recommenda- tion. In KDD, 950-958.\n\nX Wang, X He, M Wang, F Feng, Neural Graph Collaborative Filtering. SIGIR. Wang, X.; He, X.; Wang, M.; Feng, F.; et al. 2019c. Neural Graph Collaborative Filtering. SIGIR .\n\nHierarchically Structured Transformer Networks for Fine-Grained Spatial Event Forecasting. X Wu, C Huang, C Zhang, WWW. Wu, X.; Huang, C.; Zhang, C.; et al. 2020. Hierarchically Structured Transformer Networks for Fine-Grained Spatial Event Forecasting. In WWW, 2320-2330.\n\nCollaborative denoising auto-encoders for top-n recommender systems. Y Wu, C Dubois, WSDM. ACMWu, Y.; DuBois, C.; et al. 2016. Collaborative denoising auto-encoders for top-n recommender systems. In WSDM, 153-162. ACM.\n\nMultiplex Behavioral Relation Learning for Recommendation via Memory Augmented Transformer Network. L Xia, C Huang, Y Xu, P Dai, B Zhang, L Bo, SIGIR. Xia, L.; Huang, C.; Xu, Y.; Dai, P.; Zhang, B.; and Bo, L. 2020. Multiplex Behavioral Relation Learning for Recom- mendation via Memory Augmented Transformer Network. In SIGIR, 2397-2406.\n\nDeep Matrix Factorization Models for Recommender Systems. H.-J Xue, X Dai, J Zhang, S Huang, IJCAI. Xue, H.-J.; Dai, X.; Zhang, J.; Huang, S.; et al. 2017. Deep Matrix Factorization Models for Recommender Systems. In IJCAI, 3203-3209.\n\nMultiorder attentive ranking model for sequential recommendation. L Yu, C Zhang, S Liang, X Zhang, AAAI. 33Yu, L.; Zhang, C.; Liang, S.; and Zhang, X. 2019. Multi- order attentive ranking model for sequential recommenda- tion. In AAAI, volume 33, 5709-5716.\n\nWalkranker: A unified pairwise ranking model with multiple relations for item recommendation. L Yu, C Zhang, S Pei, AAAI. Yu, L.; Zhang, C.; Pei, S.; et al. 2018. Walkranker: A uni- fied pairwise ranking model with multiple relations for item recommendation. In AAAI.\n\nStar-gcn: Stacked and reconstructed graph convolutional networks for recommender systems. J Zhang, X Shi, S Zhao, I King, IJCAI. Zhang, J.; Shi, X.; Zhao, S.; and King, I. 2019. Star-gcn: Stacked and reconstructed graph convolutional networks for recommender systems. In IJCAI.\n\nAdversarial Oracular Seq2seq Learning for Sequential Recommendation. P Zhao, T Shui, Y Zhang, K Xiao, K Bian, IJCAI. Zhao, P.; Shui, T.; Zhang, Y.; Xiao, K.; and Bian, K. 2020. Adversarial Oracular Seq2seq Learning for Sequential Rec- ommendation. In IJCAI, 1905-1911.\n\nA neural autoregressive approach to collaborative filtering. Y Zheng, B Tang, W Ding, H Zhou, ICML. Zheng, Y.; Tang, B.; Ding, W.; and Zhou, H. 2016. A neural autoregressive approach to collaborative filtering. In ICML.\n", "annotations": {"author": "[{\"end\":152,\"start\":95},{\"end\":222,\"start\":153},{\"end\":378,\"start\":223},{\"end\":424,\"start\":379},{\"end\":510,\"start\":425},{\"end\":562,\"start\":511},{\"end\":619,\"start\":563},{\"end\":685,\"start\":620}]", "publisher": null, "author_last_name": "[{\"end\":107,\"start\":104},{\"end\":163,\"start\":158},{\"end\":230,\"start\":228},{\"end\":387,\"start\":384},{\"end\":436,\"start\":431},{\"end\":525,\"start\":521},{\"end\":571,\"start\":568},{\"end\":630,\"start\":628}]", "author_first_name": "[{\"end\":103,\"start\":95},{\"end\":157,\"start\":153},{\"end\":227,\"start\":223},{\"end\":383,\"start\":379},{\"end\":430,\"start\":425},{\"end\":520,\"start\":511},{\"end\":567,\"start\":563},{\"end\":627,\"start\":620}]", "author_affiliation": "[{\"end\":151,\"start\":109},{\"end\":221,\"start\":187},{\"end\":274,\"start\":232},{\"end\":340,\"start\":276},{\"end\":377,\"start\":342},{\"end\":423,\"start\":389},{\"end\":509,\"start\":467},{\"end\":561,\"start\":527},{\"end\":618,\"start\":588},{\"end\":684,\"start\":650}]", "title": "[{\"end\":92,\"start\":1},{\"end\":777,\"start\":686}]", "venue": null, "abstract": "[{\"end\":2489,\"start\":779}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2732,\"start\":2714},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3036,\"start\":3018},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3232,\"start\":3217},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3258,\"start\":3242},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3509,\"start\":3488},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3532,\"start\":3509},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3707,\"start\":3689},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3972,\"start\":3955},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4253,\"start\":4236},{\"end\":4990,\"start\":4972},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5686,\"start\":5667},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6084,\"start\":6067},{\"end\":6100,\"start\":6084},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11769,\"start\":11748},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11784,\"start\":11769},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11799,\"start\":11784},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20561,\"start\":20542},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20578,\"start\":20561},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":20690,\"start\":20674},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":20707,\"start\":20690},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":21080,\"start\":21063},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21099,\"start\":21080},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":21443,\"start\":21422},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":21619,\"start\":21595},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21766,\"start\":21749},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21882,\"start\":21866},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22148,\"start\":22129},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":22259,\"start\":22243},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22552,\"start\":22533},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":22713,\"start\":22695},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22883,\"start\":22866},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":23058,\"start\":23040},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23225,\"start\":23208},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23335,\"start\":23318},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23528,\"start\":23509},{\"end\":31307,\"start\":31295},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":31575,\"start\":31555},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":31590,\"start\":31575},{\"end\":31809,\"start\":31788},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32316,\"start\":32289},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32345,\"start\":32327},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":32463,\"start\":32443}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33396,\"start\":33342},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33509,\"start\":33397},{\"attributes\":{\"id\":\"fig_3\"},\"end\":33676,\"start\":33510},{\"attributes\":{\"id\":\"fig_4\"},\"end\":33893,\"start\":33677},{\"attributes\":{\"id\":\"fig_5\"},\"end\":33967,\"start\":33894},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":34229,\"start\":33968},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":34281,\"start\":34230},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":35653,\"start\":34282},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":36559,\"start\":35654},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":36741,\"start\":36560},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":36853,\"start\":36742},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":37186,\"start\":36854},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":37471,\"start\":37187}]", "paragraph": "[{\"end\":3037,\"start\":2505},{\"end\":3708,\"start\":3039},{\"end\":4610,\"start\":3710},{\"end\":5937,\"start\":4612},{\"end\":6519,\"start\":5939},{\"end\":7573,\"start\":6521},{\"end\":7634,\"start\":7575},{\"end\":7841,\"start\":7636},{\"end\":8295,\"start\":7843},{\"end\":8628,\"start\":8297},{\"end\":8837,\"start\":8646},{\"end\":10009,\"start\":8839},{\"end\":10123,\"start\":10011},{\"end\":10287,\"start\":10125},{\"end\":10414,\"start\":10303},{\"end\":11800,\"start\":10462},{\"end\":12200,\"start\":11906},{\"end\":12539,\"start\":12240},{\"end\":12965,\"start\":12622},{\"end\":13253,\"start\":13004},{\"end\":13808,\"start\":13383},{\"end\":14070,\"start\":13841},{\"end\":14620,\"start\":14153},{\"end\":14922,\"start\":14687},{\"end\":15075,\"start\":14924},{\"end\":15271,\"start\":15148},{\"end\":15907,\"start\":15317},{\"end\":16467,\"start\":16084},{\"end\":16797,\"start\":16553},{\"end\":17537,\"start\":17057},{\"end\":17937,\"start\":17625},{\"end\":19157,\"start\":17999},{\"end\":19715,\"start\":19219},{\"end\":20374,\"start\":19730},{\"end\":21100,\"start\":20376},{\"end\":21366,\"start\":21200},{\"end\":21410,\"start\":21368},{\"end\":21586,\"start\":21412},{\"end\":21691,\"start\":21588},{\"end\":21741,\"start\":21693},{\"end\":21858,\"start\":21743},{\"end\":22072,\"start\":21860},{\"end\":22120,\"start\":22074},{\"end\":22231,\"start\":22122},{\"end\":22336,\"start\":22233},{\"end\":22384,\"start\":22338},{\"end\":22524,\"start\":22386},{\"end\":22638,\"start\":22526},{\"end\":22686,\"start\":22640},{\"end\":22857,\"start\":22688},{\"end\":23029,\"start\":22859},{\"end\":23199,\"start\":23031},{\"end\":23308,\"start\":23201},{\"end\":23460,\"start\":23310},{\"end\":23500,\"start\":23462},{\"end\":23664,\"start\":23502},{\"end\":24254,\"start\":23666},{\"end\":25476,\"start\":24287},{\"end\":26506,\"start\":25507},{\"end\":27257,\"start\":26508},{\"end\":27308,\"start\":27259},{\"end\":27610,\"start\":27310},{\"end\":28062,\"start\":27612},{\"end\":29036,\"start\":28115},{\"end\":29138,\"start\":29082},{\"end\":29461,\"start\":29140},{\"end\":30420,\"start\":29463},{\"end\":31056,\"start\":30468},{\"end\":32700,\"start\":31073},{\"end\":33341,\"start\":32715}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11905,\"start\":11801},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12239,\"start\":12201},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12621,\"start\":12540},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13003,\"start\":12966},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13382,\"start\":13254},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13840,\"start\":13809},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14152,\"start\":14071},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14686,\"start\":14621},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15147,\"start\":15076},{\"attributes\":{\"id\":\"formula_9\"},\"end\":16083,\"start\":15908},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16552,\"start\":16468},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17056,\"start\":16798},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17624,\"start\":17538},{\"attributes\":{\"id\":\"formula_13\"},\"end\":17969,\"start\":17938},{\"attributes\":{\"id\":\"formula_14\"},\"end\":19218,\"start\":19158}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":24420,\"start\":24413},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":25340,\"start\":25333},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":30077,\"start\":30070}]", "section_header": "[{\"end\":2503,\"start\":2491},{\"end\":8644,\"start\":8631},{\"end\":10301,\"start\":10290},{\"end\":10460,\"start\":10417},{\"end\":15315,\"start\":15274},{\"end\":17997,\"start\":17971},{\"end\":19728,\"start\":19718},{\"end\":21198,\"start\":21103},{\"end\":24285,\"start\":24257},{\"end\":25505,\"start\":25479},{\"end\":28113,\"start\":28065},{\"end\":29080,\"start\":29039},{\"end\":30466,\"start\":30423},{\"end\":31071,\"start\":31059},{\"end\":32713,\"start\":32703},{\"end\":33353,\"start\":33343},{\"end\":33408,\"start\":33398},{\"end\":33531,\"start\":33511},{\"end\":33698,\"start\":33678},{\"end\":33905,\"start\":33895},{\"end\":34240,\"start\":34231},{\"end\":36570,\"start\":36561},{\"end\":36752,\"start\":36743},{\"end\":37197,\"start\":37188}]", "table": "[{\"end\":34229,\"start\":34014},{\"end\":35653,\"start\":34919},{\"end\":36559,\"start\":35772},{\"end\":36741,\"start\":36672},{\"end\":37186,\"start\":36955},{\"end\":37471,\"start\":37316}]", "figure_caption": "[{\"end\":33396,\"start\":33355},{\"end\":33509,\"start\":33410},{\"end\":33676,\"start\":33534},{\"end\":33893,\"start\":33701},{\"end\":33967,\"start\":33907},{\"end\":34014,\"start\":33970},{\"end\":34281,\"start\":34242},{\"end\":34919,\"start\":34284},{\"end\":35772,\"start\":35656},{\"end\":36672,\"start\":36572},{\"end\":36853,\"start\":36754},{\"end\":36955,\"start\":36856},{\"end\":37316,\"start\":37199}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10679,\"start\":10671},{\"end\":25622,\"start\":25614},{\"end\":27797,\"start\":27789},{\"end\":28425,\"start\":28417},{\"end\":29137,\"start\":29129},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":30588,\"start\":30580}]", "bib_author_first_name": "[{\"end\":37891,\"start\":37890},{\"end\":37899,\"start\":37898},{\"end\":37908,\"start\":37907},{\"end\":37917,\"start\":37916},{\"end\":37923,\"start\":37922},{\"end\":37930,\"start\":37929},{\"end\":38189,\"start\":38188},{\"end\":38197,\"start\":38196},{\"end\":38203,\"start\":38202},{\"end\":38212,\"start\":38211},{\"end\":38220,\"start\":38219},{\"end\":38227,\"start\":38226},{\"end\":38457,\"start\":38456},{\"end\":38463,\"start\":38462},{\"end\":38469,\"start\":38468},{\"end\":38478,\"start\":38477},{\"end\":38485,\"start\":38484},{\"end\":38682,\"start\":38681},{\"end\":38689,\"start\":38688},{\"end\":38695,\"start\":38694},{\"end\":38701,\"start\":38700},{\"end\":38707,\"start\":38706},{\"end\":38715,\"start\":38714},{\"end\":38723,\"start\":38722},{\"end\":38932,\"start\":38931},{\"end\":38939,\"start\":38938},{\"end\":38945,\"start\":38944},{\"end\":38952,\"start\":38951},{\"end\":38960,\"start\":38959},{\"end\":38968,\"start\":38967},{\"end\":38977,\"start\":38973},{\"end\":38987,\"start\":38984},{\"end\":38991,\"start\":38990},{\"end\":39179,\"start\":39178},{\"end\":39186,\"start\":39185},{\"end\":39192,\"start\":39191},{\"end\":39199,\"start\":39198},{\"end\":39207,\"start\":39206},{\"end\":39215,\"start\":39214},{\"end\":39224,\"start\":39220},{\"end\":39232,\"start\":39231},{\"end\":39588,\"start\":39587},{\"end\":39595,\"start\":39594},{\"end\":39602,\"start\":39601},{\"end\":39609,\"start\":39608},{\"end\":39862,\"start\":39861},{\"end\":39874,\"start\":39873},{\"end\":39999,\"start\":39998},{\"end\":40005,\"start\":40004},{\"end\":40013,\"start\":40012},{\"end\":40187,\"start\":40186},{\"end\":40193,\"start\":40192},{\"end\":40201,\"start\":40200},{\"end\":40412,\"start\":40411},{\"end\":40421,\"start\":40420},{\"end\":40429,\"start\":40428},{\"end\":40436,\"start\":40435},{\"end\":40442,\"start\":40441},{\"end\":40449,\"start\":40448},{\"end\":40457,\"start\":40456},{\"end\":40463,\"start\":40462},{\"end\":40471,\"start\":40470},{\"end\":40770,\"start\":40769},{\"end\":40779,\"start\":40778},{\"end\":40785,\"start\":40784},{\"end\":40794,\"start\":40793},{\"end\":41033,\"start\":41032},{\"end\":41042,\"start\":41041},{\"end\":41048,\"start\":41047},{\"end\":41054,\"start\":41053},{\"end\":41061,\"start\":41060},{\"end\":41067,\"start\":41066},{\"end\":41302,\"start\":41301},{\"end\":41311,\"start\":41310},{\"end\":41318,\"start\":41317},{\"end\":41320,\"start\":41319},{\"end\":41328,\"start\":41327},{\"end\":41337,\"start\":41333},{\"end\":41344,\"start\":41343},{\"end\":41591,\"start\":41590},{\"end\":41598,\"start\":41597},{\"end\":41605,\"start\":41604},{\"end\":41611,\"start\":41610},{\"end\":41618,\"start\":41617},{\"end\":41819,\"start\":41818},{\"end\":41828,\"start\":41827},{\"end\":41836,\"start\":41835},{\"end\":42047,\"start\":42046},{\"end\":42054,\"start\":42053},{\"end\":42062,\"start\":42061},{\"end\":42068,\"start\":42067},{\"end\":42076,\"start\":42075},{\"end\":42085,\"start\":42084},{\"end\":42306,\"start\":42305},{\"end\":42317,\"start\":42316},{\"end\":42319,\"start\":42318},{\"end\":42328,\"start\":42327},{\"end\":42338,\"start\":42337},{\"end\":42576,\"start\":42575},{\"end\":42583,\"start\":42582},{\"end\":42590,\"start\":42589},{\"end\":42596,\"start\":42595},{\"end\":42603,\"start\":42602},{\"end\":42610,\"start\":42609},{\"end\":42616,\"start\":42615},{\"end\":42850,\"start\":42849},{\"end\":42861,\"start\":42860},{\"end\":42872,\"start\":42871},{\"end\":42882,\"start\":42881},{\"end\":42895,\"start\":42894},{\"end\":42904,\"start\":42903},{\"end\":42906,\"start\":42905},{\"end\":42915,\"start\":42914},{\"end\":43182,\"start\":43181},{\"end\":43190,\"start\":43189},{\"end\":43199,\"start\":43198},{\"end\":43208,\"start\":43207},{\"end\":43220,\"start\":43219},{\"end\":43228,\"start\":43227},{\"end\":43497,\"start\":43496},{\"end\":43505,\"start\":43504},{\"end\":43511,\"start\":43510},{\"end\":43518,\"start\":43517},{\"end\":43528,\"start\":43524},{\"end\":43680,\"start\":43679},{\"end\":43688,\"start\":43687},{\"end\":43694,\"start\":43693},{\"end\":43702,\"start\":43701},{\"end\":43945,\"start\":43944},{\"end\":43951,\"start\":43950},{\"end\":43960,\"start\":43959},{\"end\":44197,\"start\":44196},{\"end\":44203,\"start\":44202},{\"end\":44448,\"start\":44447},{\"end\":44455,\"start\":44454},{\"end\":44464,\"start\":44463},{\"end\":44470,\"start\":44469},{\"end\":44477,\"start\":44476},{\"end\":44486,\"start\":44485},{\"end\":44749,\"start\":44745},{\"end\":44756,\"start\":44755},{\"end\":44763,\"start\":44762},{\"end\":44772,\"start\":44771},{\"end\":44990,\"start\":44989},{\"end\":44996,\"start\":44995},{\"end\":45005,\"start\":45004},{\"end\":45014,\"start\":45013},{\"end\":45277,\"start\":45276},{\"end\":45283,\"start\":45282},{\"end\":45292,\"start\":45291},{\"end\":45542,\"start\":45541},{\"end\":45551,\"start\":45550},{\"end\":45558,\"start\":45557},{\"end\":45566,\"start\":45565},{\"end\":45800,\"start\":45799},{\"end\":45808,\"start\":45807},{\"end\":45816,\"start\":45815},{\"end\":45825,\"start\":45824},{\"end\":45833,\"start\":45832},{\"end\":46062,\"start\":46061},{\"end\":46071,\"start\":46070},{\"end\":46079,\"start\":46078},{\"end\":46087,\"start\":46086}]", "bib_author_last_name": "[{\"end\":37896,\"start\":37892},{\"end\":37905,\"start\":37900},{\"end\":37914,\"start\":37909},{\"end\":37920,\"start\":37918},{\"end\":37927,\"start\":37924},{\"end\":37933,\"start\":37931},{\"end\":38194,\"start\":38190},{\"end\":38200,\"start\":38198},{\"end\":38209,\"start\":38204},{\"end\":38217,\"start\":38213},{\"end\":38224,\"start\":38221},{\"end\":38231,\"start\":38228},{\"end\":38460,\"start\":38458},{\"end\":38466,\"start\":38464},{\"end\":38475,\"start\":38470},{\"end\":38482,\"start\":38479},{\"end\":38491,\"start\":38486},{\"end\":38686,\"start\":38683},{\"end\":38692,\"start\":38690},{\"end\":38698,\"start\":38696},{\"end\":38704,\"start\":38702},{\"end\":38712,\"start\":38708},{\"end\":38720,\"start\":38716},{\"end\":38727,\"start\":38724},{\"end\":38936,\"start\":38933},{\"end\":38942,\"start\":38940},{\"end\":38949,\"start\":38946},{\"end\":38957,\"start\":38953},{\"end\":38965,\"start\":38961},{\"end\":38971,\"start\":38969},{\"end\":38982,\"start\":38978},{\"end\":39183,\"start\":39180},{\"end\":39189,\"start\":39187},{\"end\":39196,\"start\":39193},{\"end\":39204,\"start\":39200},{\"end\":39212,\"start\":39208},{\"end\":39218,\"start\":39216},{\"end\":39229,\"start\":39225},{\"end\":39236,\"start\":39233},{\"end\":39592,\"start\":39589},{\"end\":39599,\"start\":39596},{\"end\":39606,\"start\":39603},{\"end\":39614,\"start\":39610},{\"end\":39871,\"start\":39863},{\"end\":39879,\"start\":39875},{\"end\":40002,\"start\":40000},{\"end\":40010,\"start\":40006},{\"end\":40019,\"start\":40014},{\"end\":40190,\"start\":40188},{\"end\":40198,\"start\":40194},{\"end\":40206,\"start\":40202},{\"end\":40418,\"start\":40413},{\"end\":40426,\"start\":40422},{\"end\":40433,\"start\":40430},{\"end\":40439,\"start\":40437},{\"end\":40446,\"start\":40443},{\"end\":40454,\"start\":40450},{\"end\":40460,\"start\":40458},{\"end\":40468,\"start\":40464},{\"end\":40477,\"start\":40472},{\"end\":40776,\"start\":40771},{\"end\":40782,\"start\":40780},{\"end\":40791,\"start\":40786},{\"end\":40800,\"start\":40795},{\"end\":41039,\"start\":41034},{\"end\":41045,\"start\":41043},{\"end\":41051,\"start\":41049},{\"end\":41058,\"start\":41055},{\"end\":41064,\"start\":41062},{\"end\":41070,\"start\":41068},{\"end\":41308,\"start\":41303},{\"end\":41315,\"start\":41312},{\"end\":41325,\"start\":41321},{\"end\":41331,\"start\":41329},{\"end\":41341,\"start\":41338},{\"end\":41349,\"start\":41345},{\"end\":41595,\"start\":41592},{\"end\":41602,\"start\":41599},{\"end\":41608,\"start\":41606},{\"end\":41615,\"start\":41612},{\"end\":41621,\"start\":41619},{\"end\":41825,\"start\":41820},{\"end\":41833,\"start\":41829},{\"end\":41845,\"start\":41837},{\"end\":42051,\"start\":42048},{\"end\":42059,\"start\":42055},{\"end\":42065,\"start\":42063},{\"end\":42073,\"start\":42069},{\"end\":42082,\"start\":42077},{\"end\":42090,\"start\":42086},{\"end\":42314,\"start\":42307},{\"end\":42325,\"start\":42320},{\"end\":42335,\"start\":42329},{\"end\":42342,\"start\":42339},{\"end\":42580,\"start\":42577},{\"end\":42587,\"start\":42584},{\"end\":42593,\"start\":42591},{\"end\":42600,\"start\":42597},{\"end\":42607,\"start\":42604},{\"end\":42613,\"start\":42611},{\"end\":42622,\"start\":42617},{\"end\":42858,\"start\":42851},{\"end\":42869,\"start\":42862},{\"end\":42879,\"start\":42873},{\"end\":42892,\"start\":42883},{\"end\":42901,\"start\":42896},{\"end\":42912,\"start\":42907},{\"end\":42922,\"start\":42916},{\"end\":43187,\"start\":43183},{\"end\":43196,\"start\":43191},{\"end\":43205,\"start\":43200},{\"end\":43217,\"start\":43209},{\"end\":43225,\"start\":43221},{\"end\":43231,\"start\":43229},{\"end\":43502,\"start\":43498},{\"end\":43508,\"start\":43506},{\"end\":43515,\"start\":43512},{\"end\":43522,\"start\":43519},{\"end\":43533,\"start\":43529},{\"end\":43685,\"start\":43681},{\"end\":43691,\"start\":43689},{\"end\":43699,\"start\":43695},{\"end\":43707,\"start\":43703},{\"end\":43948,\"start\":43946},{\"end\":43957,\"start\":43952},{\"end\":43966,\"start\":43961},{\"end\":44200,\"start\":44198},{\"end\":44210,\"start\":44204},{\"end\":44452,\"start\":44449},{\"end\":44461,\"start\":44456},{\"end\":44467,\"start\":44465},{\"end\":44474,\"start\":44471},{\"end\":44483,\"start\":44478},{\"end\":44489,\"start\":44487},{\"end\":44753,\"start\":44750},{\"end\":44760,\"start\":44757},{\"end\":44769,\"start\":44764},{\"end\":44778,\"start\":44773},{\"end\":44993,\"start\":44991},{\"end\":45002,\"start\":44997},{\"end\":45011,\"start\":45006},{\"end\":45020,\"start\":45015},{\"end\":45280,\"start\":45278},{\"end\":45289,\"start\":45284},{\"end\":45296,\"start\":45293},{\"end\":45548,\"start\":45543},{\"end\":45555,\"start\":45552},{\"end\":45563,\"start\":45559},{\"end\":45571,\"start\":45567},{\"end\":45805,\"start\":45801},{\"end\":45813,\"start\":45809},{\"end\":45822,\"start\":45817},{\"end\":45830,\"start\":45826},{\"end\":45838,\"start\":45834},{\"end\":46068,\"start\":46063},{\"end\":46076,\"start\":46072},{\"end\":46084,\"start\":46080},{\"end\":46092,\"start\":46088}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":208284469},\"end\":38133,\"start\":37796},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":207562781},\"end\":38389,\"start\":38135},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2420928},\"end\":38630,\"start\":38391},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":67769538},\"end\":38870,\"start\":38632},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":160030052},\"end\":39174,\"start\":38872},{\"attributes\":{\"id\":\"b5\"},\"end\":39466,\"start\":39176},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":196171043},\"end\":39808,\"start\":39468},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4755450},\"end\":39994,\"start\":39810},{\"attributes\":{\"id\":\"b8\"},\"end\":40151,\"start\":39996},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":211818229},\"end\":40305,\"start\":40153},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":235306079},\"end\":40693,\"start\":40307},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":196185598},\"end\":40958,\"start\":40695},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":235306136},\"end\":41224,\"start\":40960},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":59528258},\"end\":41524,\"start\":41226},{\"attributes\":{\"id\":\"b14\"},\"end\":41759,\"start\":41526},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":58370896},\"end\":41981,\"start\":41761},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":212643929},\"end\":42251,\"start\":41983},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":16274986},\"end\":42476,\"start\":42253},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":119181611},\"end\":42820,\"start\":42478},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":13756489},\"end\":43079,\"start\":42822},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":189761996},\"end\":43434,\"start\":43081},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":159042183},\"end\":43677,\"start\":43436},{\"attributes\":{\"id\":\"b22\"},\"end\":43851,\"start\":43679},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":215835115},\"end\":44125,\"start\":43853},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":6392154},\"end\":44345,\"start\":44127},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":220730199},\"end\":44685,\"start\":44347},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":27308776},\"end\":44921,\"start\":44687},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":53978637},\"end\":45180,\"start\":44923},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":4672722},\"end\":45449,\"start\":45182},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":170079233},\"end\":45728,\"start\":45451},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":220483164},\"end\":45998,\"start\":45730},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":15318202},\"end\":46219,\"start\":46000}]", "bib_title": "[{\"end\":37888,\"start\":37796},{\"end\":38186,\"start\":38135},{\"end\":38454,\"start\":38391},{\"end\":38679,\"start\":38632},{\"end\":38929,\"start\":38872},{\"end\":39585,\"start\":39468},{\"end\":39859,\"start\":39810},{\"end\":40184,\"start\":40153},{\"end\":40409,\"start\":40307},{\"end\":40767,\"start\":40695},{\"end\":41030,\"start\":40960},{\"end\":41299,\"start\":41226},{\"end\":41588,\"start\":41526},{\"end\":41816,\"start\":41761},{\"end\":42044,\"start\":41983},{\"end\":42303,\"start\":42253},{\"end\":42573,\"start\":42478},{\"end\":42847,\"start\":42822},{\"end\":43179,\"start\":43081},{\"end\":43494,\"start\":43436},{\"end\":43942,\"start\":43853},{\"end\":44194,\"start\":44127},{\"end\":44445,\"start\":44347},{\"end\":44743,\"start\":44687},{\"end\":44987,\"start\":44923},{\"end\":45274,\"start\":45182},{\"end\":45539,\"start\":45451},{\"end\":45797,\"start\":45730},{\"end\":46059,\"start\":46000}]", "bib_author": "[{\"end\":37898,\"start\":37890},{\"end\":37907,\"start\":37898},{\"end\":37916,\"start\":37907},{\"end\":37922,\"start\":37916},{\"end\":37929,\"start\":37922},{\"end\":37935,\"start\":37929},{\"end\":38196,\"start\":38188},{\"end\":38202,\"start\":38196},{\"end\":38211,\"start\":38202},{\"end\":38219,\"start\":38211},{\"end\":38226,\"start\":38219},{\"end\":38233,\"start\":38226},{\"end\":38462,\"start\":38456},{\"end\":38468,\"start\":38462},{\"end\":38477,\"start\":38468},{\"end\":38484,\"start\":38477},{\"end\":38493,\"start\":38484},{\"end\":38688,\"start\":38681},{\"end\":38694,\"start\":38688},{\"end\":38700,\"start\":38694},{\"end\":38706,\"start\":38700},{\"end\":38714,\"start\":38706},{\"end\":38722,\"start\":38714},{\"end\":38729,\"start\":38722},{\"end\":38938,\"start\":38931},{\"end\":38944,\"start\":38938},{\"end\":38951,\"start\":38944},{\"end\":38959,\"start\":38951},{\"end\":38967,\"start\":38959},{\"end\":38973,\"start\":38967},{\"end\":38984,\"start\":38973},{\"end\":38990,\"start\":38984},{\"end\":38994,\"start\":38990},{\"end\":39185,\"start\":39178},{\"end\":39191,\"start\":39185},{\"end\":39198,\"start\":39191},{\"end\":39206,\"start\":39198},{\"end\":39214,\"start\":39206},{\"end\":39220,\"start\":39214},{\"end\":39231,\"start\":39220},{\"end\":39238,\"start\":39231},{\"end\":39594,\"start\":39587},{\"end\":39601,\"start\":39594},{\"end\":39608,\"start\":39601},{\"end\":39616,\"start\":39608},{\"end\":39873,\"start\":39861},{\"end\":39881,\"start\":39873},{\"end\":40004,\"start\":39998},{\"end\":40012,\"start\":40004},{\"end\":40021,\"start\":40012},{\"end\":40192,\"start\":40186},{\"end\":40200,\"start\":40192},{\"end\":40208,\"start\":40200},{\"end\":40420,\"start\":40411},{\"end\":40428,\"start\":40420},{\"end\":40435,\"start\":40428},{\"end\":40441,\"start\":40435},{\"end\":40448,\"start\":40441},{\"end\":40456,\"start\":40448},{\"end\":40462,\"start\":40456},{\"end\":40470,\"start\":40462},{\"end\":40479,\"start\":40470},{\"end\":40778,\"start\":40769},{\"end\":40784,\"start\":40778},{\"end\":40793,\"start\":40784},{\"end\":40802,\"start\":40793},{\"end\":41041,\"start\":41032},{\"end\":41047,\"start\":41041},{\"end\":41053,\"start\":41047},{\"end\":41060,\"start\":41053},{\"end\":41066,\"start\":41060},{\"end\":41072,\"start\":41066},{\"end\":41310,\"start\":41301},{\"end\":41317,\"start\":41310},{\"end\":41327,\"start\":41317},{\"end\":41333,\"start\":41327},{\"end\":41343,\"start\":41333},{\"end\":41351,\"start\":41343},{\"end\":41597,\"start\":41590},{\"end\":41604,\"start\":41597},{\"end\":41610,\"start\":41604},{\"end\":41617,\"start\":41610},{\"end\":41623,\"start\":41617},{\"end\":41827,\"start\":41818},{\"end\":41835,\"start\":41827},{\"end\":41847,\"start\":41835},{\"end\":42053,\"start\":42046},{\"end\":42061,\"start\":42053},{\"end\":42067,\"start\":42061},{\"end\":42075,\"start\":42067},{\"end\":42084,\"start\":42075},{\"end\":42092,\"start\":42084},{\"end\":42316,\"start\":42305},{\"end\":42327,\"start\":42316},{\"end\":42337,\"start\":42327},{\"end\":42344,\"start\":42337},{\"end\":42582,\"start\":42575},{\"end\":42589,\"start\":42582},{\"end\":42595,\"start\":42589},{\"end\":42602,\"start\":42595},{\"end\":42609,\"start\":42602},{\"end\":42615,\"start\":42609},{\"end\":42624,\"start\":42615},{\"end\":42860,\"start\":42849},{\"end\":42871,\"start\":42860},{\"end\":42881,\"start\":42871},{\"end\":42894,\"start\":42881},{\"end\":42903,\"start\":42894},{\"end\":42914,\"start\":42903},{\"end\":42924,\"start\":42914},{\"end\":43189,\"start\":43181},{\"end\":43198,\"start\":43189},{\"end\":43207,\"start\":43198},{\"end\":43219,\"start\":43207},{\"end\":43227,\"start\":43219},{\"end\":43233,\"start\":43227},{\"end\":43504,\"start\":43496},{\"end\":43510,\"start\":43504},{\"end\":43517,\"start\":43510},{\"end\":43524,\"start\":43517},{\"end\":43535,\"start\":43524},{\"end\":43687,\"start\":43679},{\"end\":43693,\"start\":43687},{\"end\":43701,\"start\":43693},{\"end\":43709,\"start\":43701},{\"end\":43950,\"start\":43944},{\"end\":43959,\"start\":43950},{\"end\":43968,\"start\":43959},{\"end\":44202,\"start\":44196},{\"end\":44212,\"start\":44202},{\"end\":44454,\"start\":44447},{\"end\":44463,\"start\":44454},{\"end\":44469,\"start\":44463},{\"end\":44476,\"start\":44469},{\"end\":44485,\"start\":44476},{\"end\":44491,\"start\":44485},{\"end\":44755,\"start\":44745},{\"end\":44762,\"start\":44755},{\"end\":44771,\"start\":44762},{\"end\":44780,\"start\":44771},{\"end\":44995,\"start\":44989},{\"end\":45004,\"start\":44995},{\"end\":45013,\"start\":45004},{\"end\":45022,\"start\":45013},{\"end\":45282,\"start\":45276},{\"end\":45291,\"start\":45282},{\"end\":45298,\"start\":45291},{\"end\":45550,\"start\":45541},{\"end\":45557,\"start\":45550},{\"end\":45565,\"start\":45557},{\"end\":45573,\"start\":45565},{\"end\":45807,\"start\":45799},{\"end\":45815,\"start\":45807},{\"end\":45824,\"start\":45815},{\"end\":45832,\"start\":45824},{\"end\":45840,\"start\":45832},{\"end\":46070,\"start\":46061},{\"end\":46078,\"start\":46070},{\"end\":46086,\"start\":46078},{\"end\":46094,\"start\":46086}]", "bib_venue": "[{\"end\":37939,\"start\":37935},{\"end\":38237,\"start\":38233},{\"end\":38497,\"start\":38493},{\"end\":38732,\"start\":38729},{\"end\":38998,\"start\":38994},{\"end\":39619,\"start\":39616},{\"end\":39885,\"start\":39881},{\"end\":40059,\"start\":40021},{\"end\":40211,\"start\":40208},{\"end\":40483,\"start\":40479},{\"end\":40805,\"start\":40802},{\"end\":41076,\"start\":41072},{\"end\":41355,\"start\":41351},{\"end\":41628,\"start\":41623},{\"end\":41855,\"start\":41847},{\"end\":42096,\"start\":42092},{\"end\":42347,\"start\":42344},{\"end\":42628,\"start\":42624},{\"end\":42928,\"start\":42924},{\"end\":43236,\"start\":43233},{\"end\":43538,\"start\":43535},{\"end\":43752,\"start\":43709},{\"end\":43971,\"start\":43968},{\"end\":44216,\"start\":44212},{\"end\":44496,\"start\":44491},{\"end\":44785,\"start\":44780},{\"end\":45026,\"start\":45022},{\"end\":45302,\"start\":45298},{\"end\":45578,\"start\":45573},{\"end\":45845,\"start\":45840},{\"end\":46098,\"start\":46094}]"}}}, "year": 2023, "month": 12, "day": 17}