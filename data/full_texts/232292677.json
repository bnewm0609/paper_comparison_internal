{"id": 232292677, "updated": "2022-01-14 16:07:25.645", "metadata": {"title": "A Reinforcement Learning Approach to Reduce Serverless Function Cold Start Frequency", "authors": "[{\"middle\":[],\"last\":\"Agarwal\",\"first\":\"Siddharth\"},{\"middle\":[\"A.\"],\"last\":\"Rodriguez\",\"first\":\"Maria\"},{\"middle\":[],\"last\":\"Buyya\",\"first\":\"Rajkumar\"}]", "venue": "2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)", "journal": "2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Serverless computing is an event-driven cloud computing architecture for processing requests ondemand, using light weight function containers and a micro-services model. A variety of applications like Internet of Things (IoT) services, edge computing, and stream processing have been introduced to the serverless paradigm. These applications are characterized by their stringent response time requirements, therefore expecting a quick and fault tolerant feedback from the application. The serverless, or Function-as-a-Service (FaaS), paradigm suffers from function \u2018cold start\u2019 challenges, where the serverless platform takes time to set up the dependencies, prepare the runtime environment and code for execution before serving the incoming workload. Most of the current works address the problem of cold start by (1) reducing the start-up or preparation time of function containers, or (2) reducing the frequency of function cold starts on the platform. Recent industrial research has identified that factors such as runtime environment, CPU and memory settings, invocation concurrency, and networking requirements, affect the cold start of a function. Therefore, we propose a Reinforcement Learning (Q-Learning) agent setting, to analyze the identified factors such as function CPU utilization, to ascertain the function-invocation patterns and reduce the function cold start frequency by preparing the function instances in advance. The proposed QLearning agent interacts with the Kubeless serverless platform by discretizing the environment states, actions and rewards with the use of per-instance CPU utilization, available function instances and success or failure rate of response, respectively. The workload is replicated using the Apache JMeter non-GUI toolkit and our agent is evaluated against the baseline default auto-scale feature of Kubeless. The agent demonstrates the capability of learning the invocation pattern, make informed decisions by preparing the optimal number of function instances over the period of learning, under controlled environment", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/ccgrid/AgarwalRB21", "doi": "10.1109/ccgrid51090.2021.00097"}}, "content": {"source": {"pdf_hash": "96d4fea8d034a7605af936f2e2b6a44becdf6585", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "635699c49b9e620ce4b6ea024aad3c4259b7ac92", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/96d4fea8d034a7605af936f2e2b6a44becdf6585.txt", "contents": "\nA Reinforcement Learning Approach to Reduce Serverless Function Cold Start Frequency\n\n\nSiddharth Agarwal siddhartha@student.unimelb.edu.au \nCloud Computing and Distributed Systems(CLOUDS) Laboratory School of Computing and Information Systems\nThe University of Melbourne\nAustralia\n\nMaria A Rodriguez \nCloud Computing and Distributed Systems(CLOUDS) Laboratory School of Computing and Information Systems\nThe University of Melbourne\nAustralia\n\nRajkumar Buyya rbuyya@unimelb.edu.au \nCloud Computing and Distributed Systems(CLOUDS) Laboratory School of Computing and Information Systems\nThe University of Melbourne\nAustralia\n\nA Reinforcement Learning Approach to Reduce Serverless Function Cold Start Frequency\nServerless ComputingFaasReinforcement LearningQ-LearningCold StartKubeless\nServerless computing is an event-driven cloud computing architecture for processing requests ondemand, using light weight function containers and a micro-services model. A variety of applications like Internet of Things (IoT) services, edge computing, and stream processing have been introduced to the serverless paradigm. These applications are characterized by their stringent response time requirements, therefore expecting a quick and fault tolerant feedback from the application. The serverless, or Function-as-a-Service (FaaS), paradigm suffers from function 'cold start' challenges, where the serverless platform takes time to set up the dependencies, prepare the runtime environment and code for execution before serving the incoming workload. Most of the current works address the problem of cold start by (1) reducing the start-up or preparation time of function containers, or (2) reducing the frequency of function cold starts on the platform. Recent industrial research has identified that factors such as runtime environment, CPU and memory settings, invocation concurrency, and networking requirements, affect the cold start of a function. Therefore, we propose a Reinforcement Learning (Q-Learning) agent setting, to analyze the identified factors such as function CPU utilization, to ascertain the function-invocation patterns and reduce the function cold start frequency by preparing the function instances in advance. The proposed Q-Learning agent interacts with the Kubeless serverless platform by discretizing the environment states, actions and rewards with the use of per-instance CPU utilization, available function instances and success or failure rate of response, respectively. The workload is replicated using the Apache JMeter non-GUI toolkit and our agent is evaluated against the baseline default auto-scale feature of Kubeless. The agent demonstrates the capability of learning the invocation pattern, make informed decisions by preparing the optimal number of function instances over the period of learning, under controlled environment settings.\n\nI. INTRODUCTION\n\nThe serverless computing architecture puts forward an eventdriven, function-as-a-service model with a fine-grained payper-use pricing where costs are incurred only for the actual time that the resources are used. These models define a set of loosely coupled, stateless functions (a piece of code) that are executed on light-weight containers or virtual machines (VMs), having an inherent characteristic of on-demand scalability. Serverless computing completely takes off the burden of resource provisioning and management from the developers or users, thus emphasising solely on the application development. Serverless, in no way means the absence of servers, in fact the complexity of resource management lies solely with the Cloud Service Provider (CSP) [13,14]. The function-based abstraction increases agility in application development, offering lower administrative and ownership costs.\n\nServerless models execute the client code inside a lightweight function container, spawning the instances as per the function workload. With the ease of deployment and ondemand function scalability, the serverless execution model has attracted a wide range of applications from a variety of fields such as IoT services, REST APIs, stream processing, prediction services, etc. These applications have rigid latency requirements and thus expect a quick and fault tolerant response from the function. Conceptually, the serverless architecture is designed to prepare a new instance for every incoming workload and shut down after serving the request [14]. But, practically, commercial serverless platforms like AWS Lambda, Azure Functions, Google Cloud Function, etc may choose to re-use a function instance or keep the instance running for a limited period of time to serve subsequent requests [1]. Some open source serverless frameworks such as Kubeless [16] and Knative that are implemented over Kubernetes, have similar implementations to retain an instance of a function and re-use it to serve the subsequent requests.\n\nWith an incoming workload, new function containers are requested and a process of initialisation precedes the serving of the requests. The serverless platform initialises new containers, downloads the client code, sets up the code dependencies and runtime environment, sets up the worker node and eventually executes the container to handle the incoming request. This process introduces a non-negligible time latency, known as 'cold start', and poses as an existing challenge for the serverless platforms [2,3,5,7]. In other words, cold starts can be understood as the time taken by the platform to start executing an incoming request. A number of application factors as well as the function requirements affect the cold start of a function. Recent studies [6,7,8,9] suggest that factors like programming language, runtime environment, code packaging and deployment size, CPU or memory requirement limits, etc. affect the cold start of a function. The different offerings of serverless platforms allow for capturing the correct underlying resource information and some open source Kubernetes [15] native serverless frameworks like Kubeless take advantage of the native resource metrics. To deal with the function workload, Kubeless supports resourcebased auto-scaling, i.e., Kubernetes Horizontal Pod AutoScaler (HPA) to derive the new instances based on the per-instance CPU-utilization of the function. The default autoscaler starts requesting new instances only when the current function containers runs out of requested memory or the perinstance CPU utilization spikes above a specified threshold value. This leads to function container cold starts to serve the requests and eventually an increased number of failed requests, if the cold start time is greater than the request's time-to-live.\n\nAs these observations are solely dependent on the resource utilization values, they pose as an opportunity to explore techniques to understand the process and reduce the frequency of cold starts of a function. In this work, we present a Reinforcement Learning (RL), i.e., a model free Q-Learning agent, which exploits the per-instance CPU utilization, number of available function instances, to represent the environment states and, define the appropriate reward system for the agent to dynamically ascertain the optimal number of function instances for a given workload. In practice, a Q-Learning agent learns through the process of trial and error by interacting with the serverless environment. In each iteration, the agent analyses the current state of the environment and performs a particular action. A delayed feedback is observed, either positive or negative, based upon the realised factor (perinstance CPU-utilization, successful or failed response) and consequently learns about the workload pattern. This strategy does not have any prior knowledge about the workload pattern and dynamically adapts to the changes, thereby reducing the cold start frequency in subsequent invocations. This approach explores the applicability of Q-Learning algorithm for determining the optimal number of function instances in serverless environments in advance, so as to reduce the frequency of function cold starts, during a particular span of time. We compare this work by simulating the workload pattern for the default auto-scaling feature of the Kubeless platform. This helps in performing the analysis and examine the performance of both the configurations.\n\nThe key contributions of our work are as follows:\n\n1. A Reinforcement Learning Agent implementing model free Q-Learning in a serverless environment setting to reduce the cold start frequencies of a function.\n\n2. Implementing an agent to dynamically learn the function invocation patterns to ascertain optimal number of function instances, reducing cold start occurrences.\n\n3. Evaluation of our proposed agent against the baseline auto-scale policy of the serverless platform for a synthetic function workload pattern.\n\nThe rest of the paper is organised as follows. Section II highlights related research studies. In Section III we present the system model and architecture along with the workload specification. Section IV outlines the proposed agent's workflow and describe the design decisions. In Section V we evaluate our technique with the baseline approach and highlight the possible shortcomings. Section VI concludes the paper, highlight the future research directions.\n\nII. RELATED WORK Serverless computing -featuring affordability, on-demand scalability and light-weight containerization, comes with inherent challenges and problems. These challenges can broadly be listed as security, privacy, caching, modes of execution, etc. Among them, the problem of cold start is still prevalent and has attracted academia for realising possible solutions. A current study [1] discusses the ongoing trends of handling the cold starts in commercial as well as open source serverless platforms and present their results by evaluating AWS Lambda offerings. They broadly categorise the approaches to deal with cold starts in two classes: (1) Optimising environments i.e. minimise the cold start delay itself and (2) Pinging i.e. minimising the frequency of cold start occurrences. Among the existing techniques to mitigate the cold start problem, they review the offerings of OpenFaas, OpenWhisk, AWS Lambda and discuss the solutions like cold and warm queue. They further create a case study with I/O intensive and CPU intensive benchmarks for evaluating the AWS Lambda's warm queueing technique and conclude with the absence of any correlation between the warm containers prepared by the platform and time interval of incoming requests.\n\nIn [2], an adaptive function container warm up technique is introduced to reduce the cold start latency. It utilises a function chain model, i.e., a sequence of functions to predict the function invocation time, using LSTM networks, and nonfirst functions to keep the warmed function containers ready in queue. The researchers also propose a container pool strategy that seeks to dynamically adjust the number of empty containers in the container pool to reduce the waste of resources. Both approaches work in synchronisation as the failure of adaptive warmup strategy will automatically launch adaptive container pool strategy by providing a pre-warmed empty container, thus reducing the overall cold start latency. It is highlighted in the study that even though the strategy learns the invocation time of the function chain, the first function in the sequence suffers cold start latency. They test their approaches by comparing the resource utilisation, idle time and overall cluster utilisation with other existing techniques.\n\nResearchers in [3] explain the phenomenon of cold starts with respect to the Knative serverless platform and suggest a pod migration technique to reduce the cold start of the function containers. They posit that the cold start overhead is dependent on the underlying implementation of the function and categorise them in platform dependent and application dependent overheads. To deal with the cold starts, a pool of pre-warmed containers, marked with selector 'app-label', are kept ready. When the requests arrive, first the pool is checked for existing pre-warmed containers and allocated to the application, otherwise new containers are spawned as per the request workload. Using this approach, they conclude with an improvement in the cold start latencies of the containers for a single instance of pool.\n\nAnother research [4], studies and exploits the data similarity for reducing the cold starts and proposes a deployment system over a peer-to-peer network, virtual file system and content addressable storage to increase the computing capabilities, storage requirements and prevent network bottlenecks of system. They criticise the current container deployment technique of pulling each new container image from the storage bucket and introduces a live container migration technique over a peer-to-peer network. They propose to transfer blocks of files containing frequently used libraries and packages, over the network when required, and found a 37.9% reduction in the boot-time of containers. Similarly, [5] aims to reduce the number of cold stars by utilising the function composition knowledge. It presents an application side solution based on a light-weight middleware that aims to enable the developers to control the frequency of cold starts. It establishes that applications are generally deployed as a set of functions and proposes three strategies; na\u00efve approach, extended approach and global approach where a dedicated orchestration component invokes all the steps and follow a process of 'hinting' the next batch of functions involved.\n\nResearch in [6] explores network creation and network initialisation as the prime contributor to the cold start latency. It explains four stages of container lifecycle: (1) service invocation, (2) startup, (3) run time and (4) cleanup. The cleanup includes stopping the container, disconnecting its network and destroying it and this process demands cycles form the underlying containerisation daemon, hindering with the other three processes. Thus, a pause container pool manager is proposed to pre-create a network for function containers and whenever required, attach the new function container to configured IP and network. Their evaluation on OpenWhisk platform demonstrates a reduction of up to 80% in the cold start times with a negligible memory footprint.\n\nResearch [6,7,8] has identified various factors like runtime environment, CPU and memory settings, dependency setting, the effect of concurrency, networking requirements, etc. Work in [12] introduces the paradigm of Reinforcement Learning (RL) to the serverless platforms. It is focused towards provisioning VMs or containers on request-based autoscaling in the serverless offerings. The study is conducted using Knative serverless platform that supports parallel processing of requests per instance utilising the Horizontal Pod Autoscaler of Kubernetes. The researchers show that depending upon the workload, different concurrency levels of the container can influence performance and thus, propose a RL based model, specifically model free Q-Learning, to determine the optimal concurrency levels for individual workloads. It evaluates the performance of model based on latency and throughput of the function containers and demonstrated the capability of applying Q-Learning algorithm to the task of auto-scaling in serverless platforms.\n\nAs a novel approach, we explore the applicability and capability of RL strategies to reduce the function cold start in a serverless environment. Contrasting to the existing works, we apply the model free Q-Learning algorithm for reducing the cold start frequencies on the serverless platforms, by identifying the invocation patterns of the specific workloads, focus towards learning the optimal number of function instances and evaluate it against the non-intelligent, default auto-scaler strategy responsible for cold starts. A summary of few discussed researches and our methodology is presented in Table 1, highlighting the distinguishing parameters of the individual studies. \n\n\nA. System Model\n\nThe overall architecture and system model of the experiment is illustrated in Fig. 1 and Fig. 2. To perform the experiment, a Kubernetes service cluster was setup using Melbourne Research Cloud (MRC) services at The University of Melbourne, Australia.  The service cluster contains 4 nodes with 4 vCPU and 16 GB memory each and provides sufficient capacity to all the Kubeless components for the experiment. The workload generator agent is also configured on a similar node, responsible for sending the requests to function service cluster to generate the workload using Apache JMeter Non-GUI toolkit. The Kubernetes (version v1.18.6) cluster is configured using Ansible scripts for automatic cluster deployment. Kubeless (version v1.0.6) serverless framework is installed on the service cluster with all its components and inherent from Kubernetes, does not support scale-to-zero functionality (minimum 1 instance) in the implemented version.\n\nThe Q-Learning agent is configured to work in parallel to Kubernetes & Kubeless services on the service cluster and continuously monitors and manages the activities of the cluster including metrics collection, update the function deployment state based on collected metrics and logging the required metrics. To extensively test the workload learning capabilities of the agent, a NGINX-Ingress is also configured to handle the load balancing of incoming requests and thus allow the agent to avoid any performance issues while learning.\n\n\nB. Workload Specification\n\nThere are a variety of applications which benefit from the serverless execution model including REST APIs, multimedia processing, highly parallel workloads, stream processing, etc. Some of these applications are compute intensive and demand considerable amount of resources, therefore, to investigate the cold start problem, we generate a stable workload from a set quota of function requests to simulate a serverless application. The request simulation uses the thread sleep method that enables the service cluster to serve quota of requests for a set time span and provide the RL agent with a delayed feedback/reward.\n\nWe fabricate a compute intensive process of calculating Fibonacci series up to number 38 [8], in order to keep the running instances busy and allow the default auto-scaler of the Kubeless to account for the increased number of function cold starts. Since Kubeless does not cite its concurrency policies, we specify function resource requirements (CPU and Memory) to be allocated and used for the purpose of evaluating the resource metrics. The Fibonacci calculator appropriately fits the compute intensive requirement of the experiment and the RL agent extensively captures the state of the serverless environment for learning the necessary function instances to lower the cold starts.\n\n\nIV. PROPOSED AGENT WORKFLOW\n\nThe workflow is partitioned into two processes, the workload generator and RL agent. The workload generator is used to simulate a quota of parallel HTTP user requests against the Fibonacci function. We use Apache JMeter, an open source HTTP load testing tool, to simultaneously send a number of requests at a constant rate over a period of time. JMeter features a configurable thread 'ramp-up' period that tells JMeter how long to take for creating the desired number of request threads. In our experiment, a set of requests are sent from the quota of 100 requests with a ramp-up period of 200 seconds, engaging sufficient amount of resources from the function instances. This guarantees the demand for newer instances from the default auto-scaler, providing sufficient time for scaling or acknowledging the RL agent to analyse the workload pattern, observe the environment states and generate the rewards which complement the function cold start evidence.\n\nThe RL agent begins with set-up of reinforcement learning environment, i.e., state and action for successful implementation of model free Q-Learning technique to the serverless configuration. The reinforcement learning task is to train the agent that interacts with its environment. The agent transitions between different scenarios of the environment, called states, by performing the valid, available actions. These actions lead to rewards, either positive, negative or zero and the purpose of agent is to maximize the total reward it receives, during the process of learning. Q-learning trains an agent to approximate the value of actions i.e. Q-value, making use of the tabular representation of state-action values known as Q-table that forms the basis of decision making in the learning process.\n\nQ(s,a) represents the Q-value of action a an agent performs at state s and tries to maximise this cumulative reward using Bellman Equation (1) at each iteration t. Q(s t+1 , a)] ... (1) \u03b1 is the learning rate that describes the weight of newly observed information over old information, \u03b3 is the discount factor that describes the importance of future rewards. To choose between exploration and exploitation of information, the agent is implemented with \u03b5-greedy strategy, where \u03b5 is the probability of exploration. Therefore, the agent selects an action that maximises the expected value i.e. an action with maximum Q-value for state s with probability of 1-\u03b5.\n\n\nQ(s t , a t ) \u2190 (1 \u2212 \u03b1)Q(s t , a t ) + \u03b1[r t + \u03b3 maxa\n\nThe Kubeless framework along with its components and resources, including the sample function of Fibonacci calculator, forms the environment for the RL agent to interact. The state of the environment is defined by the combination of (1) number of function instances available and (2) perinstance CPU-utilization of the function. The agent allows maximum number of function instances to be passed as a parameter that controls states explored during the learning process. Since CPU-utilization values are continuous numbers, the per-instance CPU-utilization values are discretised into five bins of equal size -{20, 40, 60, 80, 100}, each representing the maximum value of CPU-utilization in the bin. This decision helps in appropriately limiting the size of the Q-table learned.\n\nThe agent interacts with the environment using actions of (1) scale up and (2) scale down the function deployment with valid number of instances. The availability of actions for a state is determined by the state representation, regulating the instances between 1 (minimum instance count supported by Kubeless) to M (maximum instance count). This allows the RL agent to explore and exploit only the possible state-action space, thus reducing the number of explorations and increasing the convergence time. For example, if the maximum number of function instances to be explored are M, the environment states can be represented as a set {x$y | x \u03be 1\u2026M, y \u03be (20, 40, 60, 80, 100)} containing M x 5 states. The action set for the agent at state x$y (x: instance count, y: CPU utilization range) can be represented as {a | x + a > 0, abs (x + a) <= M, a \u03be 1\u2026M}. Therefore, the size of the Q-table can be calculated as (M x 5) x (2M -1).\n\nAt each action step, the agent yields delayed rewards, determined after the specific time span, reflecting the appropriateness of the selected action. The agent learns the best actions by updating the Q-values according to the Bellman Equation, as in (1). The immediate reward, 'r', of state transition depends on function instance count, CPUutilization and request success or failure rate during the observed time span, as in (2). The agent yields positive reward for successfully serving more than half the requests, being inversely proportional to the instance count and gets penalised for the states with CPU-utilization above a threshold of 75% and an undesired failure rate of more than 70%.\n\nImmediate reward \u2190 (0.5*CPU utilisation) + (0.3*state -1 ) + (0.1*success rate) + (0.1*failure rate) \u2026(2)\n\nThe following steps outline the Q-learning approach to train the agent in serverless setting:\n\n1. Input the maximum number of function instances to be explored and time step to consider for observing the rewards.\n\n2. Setup the agent initial state and Q-table for the (state, action) pair.\n\n3. Choose and perform an action according to the \u03b5-Greedy policy with \u03b5 = 5%.\n\n4. Wait for 'sleep time' to observe the reward for current iteration.\n\n\uf0b7 Gather metrics for current function instances.\n\n\uf0b7 Calculate and return the immediate reward using collected metrics.\n\n\uf0b7 Calculate updated Q-value according to the Bellman Equation with \u03b1 = 0.4 and \u03b3 = 0.3.\n\n\nUpdate the Q-table with new Q-values calculated.\n\n6. Repeat the training procedure.\n\n\nV. PERFORMANCE EVALUATION\n\nTo evaluate the performance of our RL agent, we compare it with the default auto-scaling policy supported by the Kubeless serverless platform. Kubeless supports auto-scaling of the function based upon the CPU metrics i.e. the per instance CPU-utilisation of the active instances. The default policy is implemented as a control loop with a period of 15 seconds, after which the controller scrapes the metrics and perform the required action of scaling up. The platform keeps the allotted resources for a period of 5 minutes to prevent the resources from thrashing, due to dynamic nature of the changing metrics.\n\nWe simulate the CPU intensive serverless workload using the function Fibonacci calculator up to number 38 [8]. This ensures a sufficient amount of resources, CPU and memory, are utilised by a single request and therefore results in simulating higher number of cold starts to evaluate the algorithms. To mimic the serverless workload pattern under the experimental conditions, we create a set of a number of requests with a limit of 100 requests per 5 minutes, {reqCount | reqCount <= 100}. The period of 5 minutes is chosen in order to prevent thrashing of the resources while auto-scaling the function instances and thus evaluating both the approaches within a comparable schedule.\n\nTo effectively observe the results of default auto-scaling policy and examine the feasibility of model free Q-Learning in the experimental serverless setting, a period of 240 minutes was designated. As the Q-Learning algorithm seeks to explore the available state-action pair in the environment, a maximum of 10 function instances were preferred to comfortably execute the procedure of learning, while abstaining from the explosion of the size of the state-action space represented by the Q-table. In the baseline experiment of default auto-scaling policy responsible for provisioning the function instances onrequest, every new instance provisioned represents a potential addition to cold starts frequency. This keeps a part of incoming workload waiting to get an instance allocated and leads to a failed response, while spawning the new instances. Therefore, the rate of failed responses, which could not be served due to requirement of instances (resources) are used to compare both the discussed approaches. \uf0b7 A CPU-intensive function composition that leads to occupied resources and waiting or failed requests.\n\n\uf0b7 Limited scaling of the function instances during the experiment. Fig. 4, Fig. 5, Fig. 6 and Fig. 7 illustrates the four iterations of the Q-Learning agent. The agent is trained for a period of 240 minutes, in multiple iterations to ascertain the function invocation patterns and learn the number of function instances required for a specific workload. This decision is based upon the rewards experienced by the agent according to the CPUutilisation, success and failure rate of requests and the number of serving function instances. It is evident from the graphical representation that the agent starts learning the invocation patterns and exploits the experience it gets from the rewards. For instance, it can be inferred from the iteration 3 & 4 that the agent explores different configurations and tries to minimise the cold starts by preparing the required number of function instances, leading to reduced number of failed requests, during the time period 10 -20 and 30 -40. The lower variations of failed requests (i.e. the reduction in number of failed requests over the iterations) also signify that the agent is learning the optimal number of function instances to reduce the cold start problems and tries to serve maximum request.     After four iterations of training the RL agent, it manages to serve approximately 50.1% requests successfully and shows a positive indication towards converging to the optimal values. As compared to default auto-scaling technique, the performance of our agent after few iterations of the Q-Learning procedure shows the feasibility and appropriateness of the reinforcement learning strategy to the task of reducing cold start occurrences. The difference of results between both the approaches can be attributed to the following characteristics of the RL agent implemented -\uf0b7 The elementary reward structure used in the Q-Learning process that can affect the information gain of the agent.\n\n\uf0b7 The values of \u03b1, learning rate and \u03b3, discount factor, that plays an important role in learning process. The different combination of these values might result in quicker convergence. \uf0b7 The large state-action space also accounts for the longer learning periods and affect the agent's information gains.\n\nIn comparison to the baseline approach of default autoscaling, our approach shows practical applicability of the RL algorithm to reduce the cold start occurrences for a specific function workload and closes on the difference between the successfully served requests within few iterations.\n\n\nVI. CONCLUSIONS AND FUTURE WORK\n\nServerless computing with its easy-to-go deployment structure, have discharged the application developers from the responsibilities of managing the servers. On the other hand, this execution style increases the responsibilities of the cloud service providers to continuously provide fault tolerant services to their customers. With application response time being one of the most important factors for the end-user, serverless introduces overheads of cold starts i.e. setup time of the function containers to serve the requests. Various approaches have been proposed to reduce the challenge of cold starts both by academia as well as the technology industry like keeping a warm queue of function containers, continuously pinging the functions to keep them running and keeping pre-prepared containers with dependencies ready, etc. These non-intelligent approaches fail to identify the request invocation patterns and therefore lead to failed responses due to resulting cold starts. We present an evidence of using reinforcement learning technique, specifically model free Q-Learning, to the serverless environment setting and propose an intelligent agent that learns from the unknown invocation pattern to ascertain the optimal number of function instances to reduce the cold start frequencies of the function. We compare the result of our approach with the existing autoscaling technique and successfully observe that with a few or limited number of training iterations, the agent was able to show moderate results by serving approximately 50.1% of the requests.\n\nAs part of future work, we plan to extend this approach of Q-Learning using combinations of reward structure, \u03b1 and \u03b3 values and a variety of function compositions. We further plan to include other important factors like memory setting, and function size, etc. in the learning process of the agent to better determine the criticality of the actions in the state space. As this approach requires discretisation of the continuous values for state representation, we plan to extend this approach using DQNs (Deep Q-Learning Networks) to estimate the information about optimal actions without the risk of stateaction space explosion.\n\n\nwhich affect the cold start of a function. Most works focus on commercial serverless platforms like AWS Lambda, Azure Functions, Google Cloud Functions and fall short to evaluate open source serverless platforms like OpenLambda, Fission, Kubeless, etc. Very few studies [9,10,11] have successfully performed analysis on open source serverless platforms and provided possible solutions by targeting the container level finer-grained control of the platform.\n\nFigure 1 .\n1Deployed Stack Architecture.\n\nFigure 2 .\n2System Model.\n\nFig. 3\n3illustrates the results of the default auto-scaling policy of the Kubeless platform. With the limited number of function instances and considering CPU-utilisation metrics, it can be seen that the baseline approach suffers from a number of failed requests and accounts for approximately 44% of the failed requests out of the workload of approximately 2166 requests. This can be attributed to the following characteristics:\uf0b7 A control loop period of 15 seconds, after which the auto-scaler checks for the CPU metrics.\n\nFigure 3 .\n3Failed requests using default HPA policy.\n\nFigure 4 .\n4Q-Learning Agent iteration 1 of 240 minutes.\n\nFigure 5 .\n5Q-Learning Agent iteration 2 of 240 minutes.\n\nFigure 6 .\n6Q-Learning Agent iteration 3 of 240 minutes.\n\nFigure 7 .\n7Q-Learning Agent iteration 4 of 240 minutes.\n\nTable 1 .\n1Summary of Relevant Works.Parameter \nRelated Work \nOur \nwork \n[2] \n[3] \n[4] \n[5] \n[6] \n[12] \nOpen Source \nPlatform \nYes \nYes \nNo \nYes \nYes \nNo \nYes \n\nCommercial \nPlatform \nNo \nNo \nYes \nYes \nYes \nYes \nNo \n\nFunction \nInvocation \nPattern \n\nYes \nNo \nNo \nNo \nNo \nNo \nYes \n\nReinforcement \nLearning \nTechnique \n\nNo \nNo \nNo \nNo \nNo \nYes \nYes \n\nPre-Warmed \nContainers \nYes \nYes \nNo \nNo \nNo \nNo \nNo \n\nOther Techniques \n(Network \ncreation, \nMigration, etc.) \n\nNo \nNo \nYes \nYes \nYes \nYes \nYes \n\nCold Start \nFrequencies \nNo \nNo \nNo \nNo \nNo \nNo \nYes \n\nIII. SYSTEM ARCHITECTURE \n\n\n\n\n\uf0b7 The underlying CPU-intensive function composition causes the high resource utilisation leading to negative values. Thus, the agent explores different state -action space values taking more time to learn the required values. \uf0b7 Discretisation of the continuous number values of CPU utilisation for state space representation can hinder with the optimal performance of the agent with Q-Learning techniques.\n\nCold start in serverless computing: Current trends and mitigation strategies. P Vahidinia, B Farahani, F S Aliee, Proceedings of the International Conference on Omni-layer Intelligent Systems (COINS). the International Conference on Omni-layer Intelligent Systems (COINS)Barcelona, SpainP. Vahidinia, B. Farahani and F. S. Aliee, \"Cold start in serverless computing: Current trends and mitigation strategies,\" in Proceedings of the International Conference on Omni-layer Intelligent Systems (COINS), Barcelona, Spain, 2020, pp. 1-7.\n\nAdaptive function launching acceleration in serverless computing platforms. Z Xu, H Zhang, X Geng, Q Wu, H Ma, Proceedings of the IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS). the IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS)Tianjin, ChinaZ. Xu, H. Zhang, X. Geng, Q. Wu and H. Ma, \"Adaptive function launching acceleration in serverless computing platforms,\" in Proceedings of the IEEE 25th International Conference on Parallel and Distributed Systems (ICPADS), Tianjin, China, 2019, pp. 9-16.\n\nMitigating cold starts in serverless platforms: A pool-based approach. P M Lin, A Glikson, arXiv:1903.12221arXiv preprintP.M. Lin and A. Glikson, \"Mitigating cold starts in serverless platforms: A pool-based approach,\" arXiv preprint arXiv:1903.12221, 2019.\n\nExploiting content similarity to address cold start in container deployments. K Mahajan, S Mahajan, V Misra, D Rubenstein, Proceedings of the 15th International Conference on emerging Networking EXperiments and Technologies. the 15th International Conference on emerging Networking EXperiments and TechnologiesOrlando, FL, USAK. Mahajan, S. Mahajan, V. Misra and D. Rubenstein, \"Exploiting content similarity to address cold start in container deployments,\" in Proceedings of the 15th International Conference on emerging Networking EXperiments and Technologies, Orlando, FL, USA, 2019, pp. 37-39.\n\nUsing application knowledge to reduce cold starts in FaaS services. D Bermbach, A S Karakaya, S Buchholz, Proceedings of the 35th Annual ACM Symposium on Applied Computing. the 35th Annual ACM Symposium on Applied ComputingBrno, Czech RepublicD. Bermbach, A.S. Karakaya and S. Buchholz, \"Using application knowledge to reduce cold starts in FaaS services,\" in Proceedings of the 35th Annual ACM Symposium on Applied Computing, Brno, Czech Republic, 2020, pp. 134-143.\n\nAgile cold starts for scalable serverless. A Mohan, H Sane, K Doshi, S Edupuganti, N Nayak, V Sukhomlinov, Proceedings of the 11 th USENIX Conference on Hot Topics in Cloud Computing. the 11 th USENIX Conference on Hot Topics in Cloud ComputingRenton, WA, USAA. Mohan, H. Sane, K. Doshi, S. Edupuganti, N. Nayak and V. Sukhomlinov, \"Agile cold starts for scalable serverless,\" in Proceedings of the 11 th USENIX Conference on Hot Topics in Cloud Computing, Renton, WA, USA, 2019.\n\nServerless computing: A survey of opportunities, challenges and applications. H Shafiei, A Khonsari, P Mousavi, arXiv:1911.01296v3arXiv preprintH. Shafiei, A. Khonsari and P. Mousavi, \"Serverless computing: A survey of opportunities, challenges and applications,\" arXiv preprint arXiv:1911.01296v3, 2019.\n\nCold start influencing factors in function as a service. J Manner, M Endre\u00df, T Heckel, G Wirtz, Proceedings of the 2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion). the 2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion)Zurich, SwitzerlandJ. Manner, M. Endre\u00df, T. Heckel and G. Wirtz, \"Cold start influencing factors in function as a service,\" in Proceedings of the 2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion), Zurich, Switzerland, 2018, pp. 181-188.\n\nWLEC: A not so cold architecture to mitigate cold start problem in serverless computing. K Solaiman, M A Adnan, Proceedings of the 2020 IEEE International Conference on Cloud Engineering (IC2E). the 2020 IEEE International Conference on Cloud Engineering (IC2E)Sydney, NSW, AustraliaK. Solaiman and M.A. Adnan, \"WLEC: A not so cold architecture to mitigate cold start problem in serverless computing,\" in Proceedings of the 2020 IEEE International Conference on Cloud Engineering (IC2E), Sydney, NSW, Australia, pp. 144-153.\n\nTowards network-aware resource provisioning in kubernetes for fog computing applications. J Santos, T Wauters, B Volckaert, , F. De Turck, Proceedings of the 2019 IEEE Conference on Network Softwarization (NetSoft). the 2019 IEEE Conference on Network Softwarization (NetSoft)Paris, FranceJ. Santos, T. Wauters, B. Volckaert and, F. De Turck, \"Towards network-aware resource provisioning in kubernetes for fog computing applications,\" in Proceedings of the 2019 IEEE Conference on Network Softwarization (NetSoft), Paris, France, 2019, pp. 351-359.\n\nAn Evaluation of open source serverless computing frameworks. S K Mohanty, G Premsankar, M Di Francesco, Proceedings of the 2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom). the 2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)Nicosia, CyprusS. K. Mohanty, G. Premsankar and M. Di Francesco, \"An Evaluation of open source serverless computing frameworks,\" in Proceedings of the 2018 IEEE International Conference on Cloud Computing Technology and Science (CloudCom), Nicosia, Cyprus, 2018, pp. 115- 120.\n\nAI-based resource allocation: Reinforcement learning for adaptive auto-scaling in serverless environments. L Schuler, S Jamil, N K\u00fchl, arXiv:2005.14410arXiv preprintL. Schuler, S. Jamil and N. K\u00fchl, \"AI-based resource allocation: Reinforcement learning for adaptive auto-scaling in serverless environments,\" arXiv preprint arXiv:2005.14410, 2020.\n\nServerless computing: An investigation of factors influencing microservice performance. W Lloyd, S Ramesh, S Chinthalapati, L Ly, S Pallickara, Proceedings of the 2018 IEEE International Conference on Cloud Engineering (IC2E). the 2018 IEEE International Conference on Cloud Engineering (IC2E)Orlando, FL, USAW. Lloyd, S. Ramesh, S. Chinthalapati, L. Ly and S. Pallickara, \"Serverless computing: An investigation of factors influencing microservice performance,\" in Proceedings of the 2018 IEEE International Conference on Cloud Engineering (IC2E), Orlando, FL, USA, 2018, pp. 159-169.\n\nCloud programming simplified: A berkeley view on serverless computing. E Jonas, J Schleier-Smith, V Sreekanti, C C Tsai, A Khandelwal, Q Pu, V Shankar, J Carreira, K Krauth, N Yadwadkar, arXiv:1902.03383arXiv preprintE. Jonas, J. Schleier-Smith, V. Sreekanti, C. C. Tsai, A. Khandelwal, Q. Pu, V. Shankar, J. Carreira, K. Krauth, N. Yadwadkar et al., \"Cloud programming simplified: A berkeley view on serverless computing,\" arXiv preprint arXiv:1902.03383, 2019.\n\nKubernetes Documentation | Homepage. Kubernetes Documentation | Homepage[Online]. Available: https://kubernetes.io/docs/home/\n\nKubeless -Kubernetes native serverless. Kubeless -Kubernetes native serverless[Online]. Available: https://kubeless.io/docs/\n\nApache JMeter -Getting Started. Apache JMeter - Getting Started[Online].\n", "annotations": {"author": "[{\"start\":\"88\",\"end\":\"282\"},{\"start\":\"283\",\"end\":\"443\"},{\"start\":\"444\",\"end\":\"623\"}]", "publisher": null, "author_last_name": "[{\"start\":\"98\",\"end\":\"105\"},{\"start\":\"291\",\"end\":\"300\"},{\"start\":\"453\",\"end\":\"458\"}]", "author_first_name": "[{\"start\":\"88\",\"end\":\"97\"},{\"start\":\"283\",\"end\":\"288\"},{\"start\":\"289\",\"end\":\"290\"},{\"start\":\"444\",\"end\":\"452\"}]", "author_affiliation": "[{\"start\":\"141\",\"end\":\"281\"},{\"start\":\"302\",\"end\":\"442\"},{\"start\":\"482\",\"end\":\"622\"}]", "title": "[{\"start\":\"1\",\"end\":\"85\"},{\"start\":\"624\",\"end\":\"708\"}]", "venue": null, "abstract": "[{\"start\":\"784\",\"end\":\"2863\"}]", "bib_ref": "[{\"start\":\"3638\",\"end\":\"3642\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"3642\",\"end\":\"3645\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"4422\",\"end\":\"4426\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"4667\",\"end\":\"4670\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"4728\",\"end\":\"4732\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"5402\",\"end\":\"5405\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"5405\",\"end\":\"5407\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"5407\",\"end\":\"5409\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"5409\",\"end\":\"5411\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"5654\",\"end\":\"5657\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"5657\",\"end\":\"5659\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"5659\",\"end\":\"5661\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"5661\",\"end\":\"5663\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"5989\",\"end\":\"5993\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"9729\",\"end\":\"9732\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"10595\",\"end\":\"10598\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"11639\",\"end\":\"11642\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"12451\",\"end\":\"12454\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"13138\",\"end\":\"13141\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"13695\",\"end\":\"13698\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"14458\",\"end\":\"14461\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"14461\",\"end\":\"14463\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"14463\",\"end\":\"14465\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"14633\",\"end\":\"14637\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"18408\",\"end\":\"18411\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"20979\",\"end\":\"20982\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"23656\",\"end\":\"23659\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"25516\",\"end\":\"25519\",\"attributes\":{\"ref_id\":\"b7\"}}]", "figure": "[{\"start\":\"31970\",\"end\":\"32428\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"32429\",\"end\":\"32470\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"32471\",\"end\":\"32497\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"32498\",\"end\":\"33022\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"33023\",\"end\":\"33077\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"33078\",\"end\":\"33135\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"33136\",\"end\":\"33193\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"33194\",\"end\":\"33251\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"33252\",\"end\":\"33309\",\"attributes\":{\"id\":\"fig_8\"}},{\"start\":\"33310\",\"end\":\"33887\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"33888\",\"end\":\"34295\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"2882\",\"end\":\"3774\"},{\"start\":\"3776\",\"end\":\"4895\"},{\"start\":\"4897\",\"end\":\"6693\"},{\"start\":\"6695\",\"end\":\"8352\"},{\"start\":\"8354\",\"end\":\"8403\"},{\"start\":\"8405\",\"end\":\"8561\"},{\"start\":\"8563\",\"end\":\"8725\"},{\"start\":\"8727\",\"end\":\"8871\"},{\"start\":\"8873\",\"end\":\"9332\"},{\"start\":\"9334\",\"end\":\"10590\"},{\"start\":\"10592\",\"end\":\"11622\"},{\"start\":\"11624\",\"end\":\"12432\"},{\"start\":\"12434\",\"end\":\"13681\"},{\"start\":\"13683\",\"end\":\"14447\"},{\"start\":\"14449\",\"end\":\"15487\"},{\"start\":\"15489\",\"end\":\"16169\"},{\"start\":\"16189\",\"end\":\"17132\"},{\"start\":\"17134\",\"end\":\"17668\"},{\"start\":\"17698\",\"end\":\"18317\"},{\"start\":\"18319\",\"end\":\"19004\"},{\"start\":\"19036\",\"end\":\"19992\"},{\"start\":\"19994\",\"end\":\"20795\"},{\"start\":\"20797\",\"end\":\"21458\"},{\"start\":\"21516\",\"end\":\"22293\"},{\"start\":\"22295\",\"end\":\"23227\"},{\"start\":\"23229\",\"end\":\"23926\"},{\"start\":\"23928\",\"end\":\"24033\"},{\"start\":\"24035\",\"end\":\"24128\"},{\"start\":\"24130\",\"end\":\"24247\"},{\"start\":\"24249\",\"end\":\"24323\"},{\"start\":\"24325\",\"end\":\"24402\"},{\"start\":\"24404\",\"end\":\"24473\"},{\"start\":\"24475\",\"end\":\"24523\"},{\"start\":\"24525\",\"end\":\"24593\"},{\"start\":\"24595\",\"end\":\"24682\"},{\"start\":\"24735\",\"end\":\"24768\"},{\"start\":\"24798\",\"end\":\"25408\"},{\"start\":\"25410\",\"end\":\"26092\"},{\"start\":\"26094\",\"end\":\"27209\"},{\"start\":\"27211\",\"end\":\"29144\"},{\"start\":\"29146\",\"end\":\"29450\"},{\"start\":\"29452\",\"end\":\"29740\"},{\"start\":\"29776\",\"end\":\"31338\"},{\"start\":\"31340\",\"end\":\"31969\"}]", "formula": null, "table_ref": "[{\"start\":\"16090\",\"end\":\"16097\",\"attributes\":{\"ref_id\":\"tab_0\"}}]", "section_header": "[{\"start\":\"2865\",\"end\":\"2880\"},{\"start\":\"16172\",\"end\":\"16187\"},{\"start\":\"17671\",\"end\":\"17696\"},{\"start\":\"19007\",\"end\":\"19034\"},{\"start\":\"21461\",\"end\":\"21514\"},{\"start\":\"24685\",\"end\":\"24733\",\"attributes\":{\"n\":\"5.\"}},{\"start\":\"24771\",\"end\":\"24796\"},{\"start\":\"29743\",\"end\":\"29774\"},{\"start\":\"32430\",\"end\":\"32440\"},{\"start\":\"32472\",\"end\":\"32482\"},{\"start\":\"32499\",\"end\":\"32505\"},{\"start\":\"33024\",\"end\":\"33034\"},{\"start\":\"33079\",\"end\":\"33089\"},{\"start\":\"33137\",\"end\":\"33147\"},{\"start\":\"33195\",\"end\":\"33205\"},{\"start\":\"33253\",\"end\":\"33263\"},{\"start\":\"33311\",\"end\":\"33320\"}]", "table": "[{\"start\":\"33348\",\"end\":\"33887\"}]", "figure_caption": "[{\"start\":\"31972\",\"end\":\"32428\"},{\"start\":\"32442\",\"end\":\"32470\"},{\"start\":\"32484\",\"end\":\"32497\"},{\"start\":\"32507\",\"end\":\"33022\"},{\"start\":\"33036\",\"end\":\"33077\"},{\"start\":\"33091\",\"end\":\"33135\"},{\"start\":\"33149\",\"end\":\"33193\"},{\"start\":\"33207\",\"end\":\"33251\"},{\"start\":\"33265\",\"end\":\"33309\"},{\"start\":\"33322\",\"end\":\"33348\"},{\"start\":\"33890\",\"end\":\"34295\"}]", "figure_ref": "[{\"start\":\"16267\",\"end\":\"16284\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"20961\",\"end\":\"20973\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"27278\",\"end\":\"27292\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"27294\",\"end\":\"27300\",\"attributes\":{\"ref_id\":\"fig_7\"}},{\"start\":\"27305\",\"end\":\"27311\",\"attributes\":{\"ref_id\":\"fig_8\"}}]", "bib_author_first_name": "[{\"start\":\"34375\",\"end\":\"34376\"},{\"start\":\"34388\",\"end\":\"34389\"},{\"start\":\"34400\",\"end\":\"34401\"},{\"start\":\"34402\",\"end\":\"34403\"},{\"start\":\"34907\",\"end\":\"34908\"},{\"start\":\"34913\",\"end\":\"34914\"},{\"start\":\"34922\",\"end\":\"34923\"},{\"start\":\"34930\",\"end\":\"34931\"},{\"start\":\"34936\",\"end\":\"34937\"},{\"start\":\"35467\",\"end\":\"35468\"},{\"start\":\"35469\",\"end\":\"35470\"},{\"start\":\"35476\",\"end\":\"35477\"},{\"start\":\"35733\",\"end\":\"35734\"},{\"start\":\"35744\",\"end\":\"35745\"},{\"start\":\"35755\",\"end\":\"35756\"},{\"start\":\"35764\",\"end\":\"35765\"},{\"start\":\"36322\",\"end\":\"36323\"},{\"start\":\"36334\",\"end\":\"36335\"},{\"start\":\"36336\",\"end\":\"36337\"},{\"start\":\"36348\",\"end\":\"36349\"},{\"start\":\"36766\",\"end\":\"36767\"},{\"start\":\"36775\",\"end\":\"36776\"},{\"start\":\"36783\",\"end\":\"36784\"},{\"start\":\"36792\",\"end\":\"36793\"},{\"start\":\"36806\",\"end\":\"36807\"},{\"start\":\"36815\",\"end\":\"36816\"},{\"start\":\"37282\",\"end\":\"37283\"},{\"start\":\"37293\",\"end\":\"37294\"},{\"start\":\"37305\",\"end\":\"37306\"},{\"start\":\"37567\",\"end\":\"37568\"},{\"start\":\"37577\",\"end\":\"37578\"},{\"start\":\"37587\",\"end\":\"37588\"},{\"start\":\"37597\",\"end\":\"37598\"},{\"start\":\"38194\",\"end\":\"38195\"},{\"start\":\"38206\",\"end\":\"38207\"},{\"start\":\"38208\",\"end\":\"38209\"},{\"start\":\"38721\",\"end\":\"38722\"},{\"start\":\"38731\",\"end\":\"38732\"},{\"start\":\"38742\",\"end\":\"38743\"},{\"start\":\"38755\",\"end\":\"38762\"},{\"start\":\"39243\",\"end\":\"39244\"},{\"start\":\"39245\",\"end\":\"39246\"},{\"start\":\"39256\",\"end\":\"39257\"},{\"start\":\"39270\",\"end\":\"39271\"},{\"start\":\"39272\",\"end\":\"39274\"},{\"start\":\"39870\",\"end\":\"39871\"},{\"start\":\"39881\",\"end\":\"39882\"},{\"start\":\"39890\",\"end\":\"39891\"},{\"start\":\"40199\",\"end\":\"40200\"},{\"start\":\"40208\",\"end\":\"40209\"},{\"start\":\"40218\",\"end\":\"40219\"},{\"start\":\"40235\",\"end\":\"40236\"},{\"start\":\"40241\",\"end\":\"40242\"},{\"start\":\"40769\",\"end\":\"40770\"},{\"start\":\"40778\",\"end\":\"40779\"},{\"start\":\"40796\",\"end\":\"40797\"},{\"start\":\"40809\",\"end\":\"40810\"},{\"start\":\"40811\",\"end\":\"40812\"},{\"start\":\"40819\",\"end\":\"40820\"},{\"start\":\"40833\",\"end\":\"40834\"},{\"start\":\"40839\",\"end\":\"40840\"},{\"start\":\"40850\",\"end\":\"40851\"},{\"start\":\"40862\",\"end\":\"40863\"},{\"start\":\"40872\",\"end\":\"40873\"}]", "bib_author_last_name": "[{\"start\":\"34377\",\"end\":\"34386\"},{\"start\":\"34390\",\"end\":\"34398\"},{\"start\":\"34404\",\"end\":\"34409\"},{\"start\":\"34909\",\"end\":\"34911\"},{\"start\":\"34915\",\"end\":\"34920\"},{\"start\":\"34924\",\"end\":\"34928\"},{\"start\":\"34932\",\"end\":\"34934\"},{\"start\":\"34938\",\"end\":\"34940\"},{\"start\":\"35471\",\"end\":\"35474\"},{\"start\":\"35478\",\"end\":\"35485\"},{\"start\":\"35735\",\"end\":\"35742\"},{\"start\":\"35746\",\"end\":\"35753\"},{\"start\":\"35757\",\"end\":\"35762\"},{\"start\":\"35766\",\"end\":\"35776\"},{\"start\":\"36324\",\"end\":\"36332\"},{\"start\":\"36338\",\"end\":\"36346\"},{\"start\":\"36350\",\"end\":\"36358\"},{\"start\":\"36768\",\"end\":\"36773\"},{\"start\":\"36777\",\"end\":\"36781\"},{\"start\":\"36785\",\"end\":\"36790\"},{\"start\":\"36794\",\"end\":\"36804\"},{\"start\":\"36808\",\"end\":\"36813\"},{\"start\":\"36817\",\"end\":\"36828\"},{\"start\":\"37284\",\"end\":\"37291\"},{\"start\":\"37295\",\"end\":\"37303\"},{\"start\":\"37307\",\"end\":\"37314\"},{\"start\":\"37569\",\"end\":\"37575\"},{\"start\":\"37579\",\"end\":\"37585\"},{\"start\":\"37589\",\"end\":\"37595\"},{\"start\":\"37599\",\"end\":\"37604\"},{\"start\":\"38196\",\"end\":\"38204\"},{\"start\":\"38210\",\"end\":\"38215\"},{\"start\":\"38723\",\"end\":\"38729\"},{\"start\":\"38733\",\"end\":\"38740\"},{\"start\":\"38744\",\"end\":\"38753\"},{\"start\":\"38763\",\"end\":\"38768\"},{\"start\":\"39247\",\"end\":\"39254\"},{\"start\":\"39258\",\"end\":\"39268\"},{\"start\":\"39275\",\"end\":\"39284\"},{\"start\":\"39872\",\"end\":\"39879\"},{\"start\":\"39883\",\"end\":\"39888\"},{\"start\":\"39892\",\"end\":\"39896\"},{\"start\":\"40201\",\"end\":\"40206\"},{\"start\":\"40210\",\"end\":\"40216\"},{\"start\":\"40220\",\"end\":\"40233\"},{\"start\":\"40237\",\"end\":\"40239\"},{\"start\":\"40243\",\"end\":\"40253\"},{\"start\":\"40771\",\"end\":\"40776\"},{\"start\":\"40780\",\"end\":\"40794\"},{\"start\":\"40798\",\"end\":\"40807\"},{\"start\":\"40813\",\"end\":\"40817\"},{\"start\":\"40821\",\"end\":\"40831\"},{\"start\":\"40835\",\"end\":\"40837\"},{\"start\":\"40841\",\"end\":\"40848\"},{\"start\":\"40852\",\"end\":\"40860\"},{\"start\":\"40864\",\"end\":\"40870\"},{\"start\":\"40874\",\"end\":\"40883\"}]", "bib_entry": "[{\"start\":\"34297\",\"end\":\"34829\",\"attributes\":{\"matched_paper_id\":\"221719155\",\"id\":\"b0\"}},{\"start\":\"34831\",\"end\":\"35394\",\"attributes\":{\"matched_paper_id\":\"210995603\",\"id\":\"b1\"}},{\"start\":\"35396\",\"end\":\"35653\",\"attributes\":{\"id\":\"b2\",\"doi\":\"arXiv:1903.12221\"}},{\"start\":\"35655\",\"end\":\"36252\",\"attributes\":{\"matched_paper_id\":\"208334918\",\"id\":\"b3\"}},{\"start\":\"36254\",\"end\":\"36721\",\"attributes\":{\"matched_paper_id\":\"209479049\",\"id\":\"b4\"}},{\"start\":\"36723\",\"end\":\"37202\",\"attributes\":{\"matched_paper_id\":\"196810114\",\"id\":\"b5\"}},{\"start\":\"37204\",\"end\":\"37508\",\"attributes\":{\"id\":\"b6\",\"doi\":\"arXiv:1911.01296v3\"}},{\"start\":\"37510\",\"end\":\"38103\",\"attributes\":{\"matched_paper_id\":\"57764238\",\"id\":\"b7\"}},{\"start\":\"38105\",\"end\":\"38629\",\"attributes\":{\"matched_paper_id\":\"218833533\",\"id\":\"b8\"}},{\"start\":\"38631\",\"end\":\"39179\",\"attributes\":{\"matched_paper_id\":\"198331791\",\"id\":\"b9\"}},{\"start\":\"39181\",\"end\":\"39761\",\"attributes\":{\"matched_paper_id\":\"53519955\",\"id\":\"b10\"}},{\"start\":\"39763\",\"end\":\"40109\",\"attributes\":{\"id\":\"b11\",\"doi\":\"arXiv:2005.14410\"}},{\"start\":\"40111\",\"end\":\"40696\",\"attributes\":{\"matched_paper_id\":\"21727593\",\"id\":\"b12\"}},{\"start\":\"40698\",\"end\":\"41160\",\"attributes\":{\"id\":\"b13\",\"doi\":\"arXiv:1902.03383\"}},{\"start\":\"41162\",\"end\":\"41287\",\"attributes\":{\"id\":\"b14\"}},{\"start\":\"41289\",\"end\":\"41413\",\"attributes\":{\"id\":\"b15\"}},{\"start\":\"41415\",\"end\":\"41487\",\"attributes\":{\"id\":\"b16\"}}]", "bib_title": "[{\"start\":\"34297\",\"end\":\"34373\"},{\"start\":\"34831\",\"end\":\"34905\"},{\"start\":\"35655\",\"end\":\"35731\"},{\"start\":\"36254\",\"end\":\"36320\"},{\"start\":\"36723\",\"end\":\"36764\"},{\"start\":\"37510\",\"end\":\"37565\"},{\"start\":\"38105\",\"end\":\"38192\"},{\"start\":\"38631\",\"end\":\"38719\"},{\"start\":\"39181\",\"end\":\"39241\"},{\"start\":\"40111\",\"end\":\"40197\"}]", "bib_author": "[{\"start\":\"34375\",\"end\":\"34388\"},{\"start\":\"34388\",\"end\":\"34400\"},{\"start\":\"34400\",\"end\":\"34411\"},{\"start\":\"34907\",\"end\":\"34913\"},{\"start\":\"34913\",\"end\":\"34922\"},{\"start\":\"34922\",\"end\":\"34930\"},{\"start\":\"34930\",\"end\":\"34936\"},{\"start\":\"34936\",\"end\":\"34942\"},{\"start\":\"35467\",\"end\":\"35476\"},{\"start\":\"35476\",\"end\":\"35487\"},{\"start\":\"35733\",\"end\":\"35744\"},{\"start\":\"35744\",\"end\":\"35755\"},{\"start\":\"35755\",\"end\":\"35764\"},{\"start\":\"35764\",\"end\":\"35778\"},{\"start\":\"36322\",\"end\":\"36334\"},{\"start\":\"36334\",\"end\":\"36348\"},{\"start\":\"36348\",\"end\":\"36360\"},{\"start\":\"36766\",\"end\":\"36775\"},{\"start\":\"36775\",\"end\":\"36783\"},{\"start\":\"36783\",\"end\":\"36792\"},{\"start\":\"36792\",\"end\":\"36806\"},{\"start\":\"36806\",\"end\":\"36815\"},{\"start\":\"36815\",\"end\":\"36830\"},{\"start\":\"37282\",\"end\":\"37293\"},{\"start\":\"37293\",\"end\":\"37305\"},{\"start\":\"37305\",\"end\":\"37316\"},{\"start\":\"37567\",\"end\":\"37577\"},{\"start\":\"37577\",\"end\":\"37587\"},{\"start\":\"37587\",\"end\":\"37597\"},{\"start\":\"37597\",\"end\":\"37606\"},{\"start\":\"38194\",\"end\":\"38206\"},{\"start\":\"38206\",\"end\":\"38217\"},{\"start\":\"38721\",\"end\":\"38731\"},{\"start\":\"38731\",\"end\":\"38742\"},{\"start\":\"38742\",\"end\":\"38755\"},{\"start\":\"38755\",\"end\":\"38770\"},{\"start\":\"39243\",\"end\":\"39256\"},{\"start\":\"39256\",\"end\":\"39270\"},{\"start\":\"39270\",\"end\":\"39286\"},{\"start\":\"39870\",\"end\":\"39881\"},{\"start\":\"39881\",\"end\":\"39890\"},{\"start\":\"39890\",\"end\":\"39898\"},{\"start\":\"40199\",\"end\":\"40208\"},{\"start\":\"40208\",\"end\":\"40218\"},{\"start\":\"40218\",\"end\":\"40235\"},{\"start\":\"40235\",\"end\":\"40241\"},{\"start\":\"40241\",\"end\":\"40255\"},{\"start\":\"40769\",\"end\":\"40778\"},{\"start\":\"40778\",\"end\":\"40796\"},{\"start\":\"40796\",\"end\":\"40809\"},{\"start\":\"40809\",\"end\":\"40819\"},{\"start\":\"40819\",\"end\":\"40833\"},{\"start\":\"40833\",\"end\":\"40839\"},{\"start\":\"40839\",\"end\":\"40850\"},{\"start\":\"40850\",\"end\":\"40862\"},{\"start\":\"40862\",\"end\":\"40872\"},{\"start\":\"40872\",\"end\":\"40885\"}]", "bib_venue": "[{\"start\":\"34498\",\"end\":\"34584\"},{\"start\":\"35042\",\"end\":\"35139\"},{\"start\":\"35880\",\"end\":\"35981\"},{\"start\":\"36427\",\"end\":\"36497\"},{\"start\":\"36907\",\"end\":\"36982\"},{\"start\":\"37722\",\"end\":\"37840\"},{\"start\":\"38300\",\"end\":\"38388\"},{\"start\":\"38847\",\"end\":\"38920\"},{\"start\":\"39394\",\"end\":\"39500\"},{\"start\":\"40338\",\"end\":\"40420\"},{\"start\":\"34411\",\"end\":\"34496\"},{\"start\":\"34942\",\"end\":\"35040\"},{\"start\":\"35396\",\"end\":\"35465\"},{\"start\":\"35778\",\"end\":\"35878\"},{\"start\":\"36360\",\"end\":\"36425\"},{\"start\":\"36830\",\"end\":\"36905\"},{\"start\":\"37204\",\"end\":\"37280\"},{\"start\":\"37606\",\"end\":\"37720\"},{\"start\":\"38217\",\"end\":\"38298\"},{\"start\":\"38770\",\"end\":\"38845\"},{\"start\":\"39286\",\"end\":\"39392\"},{\"start\":\"39763\",\"end\":\"39868\"},{\"start\":\"40255\",\"end\":\"40336\"},{\"start\":\"40698\",\"end\":\"40767\"},{\"start\":\"41162\",\"end\":\"41197\"},{\"start\":\"41289\",\"end\":\"41327\"},{\"start\":\"41415\",\"end\":\"41445\"}]"}}}, "year": 2023, "month": 12, "day": 17}