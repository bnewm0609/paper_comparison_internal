{"id": 255372320, "updated": "2023-10-05 05:38:13.961", "metadata": {"title": "Rethinking with Retrieval: Faithful Large Language Model Inference", "authors": "[{\"first\":\"Hangfeng\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Hongming\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Dan\",\"last\":\"Roth\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Despite the success of large language models (LLMs) in various natural language processing (NLP) tasks, the stored knowledge in these models may inevitably be incomplete, out-of-date, or incorrect. This motivates the need to utilize external knowledge to assist LLMs. Unfortunately, current methods for incorporating external knowledge often require additional training or fine-tuning, which can be costly and may not be feasible for LLMs. To address this issue, we propose a novel post-processing approach, rethinking with retrieval (RR), which retrieves relevant external knowledge based on the decomposed reasoning steps obtained from the chain-of-thought (CoT) prompting. This lightweight approach does not require additional training or fine-tuning and is not limited by the input length of LLMs. We evaluate the effectiveness of RR through extensive experiments with GPT-3 on three complex reasoning tasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our results show that RR can produce more faithful explanations and improve the performance of LLMs.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2301.00303", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2301-00303", "doi": "10.48550/arxiv.2301.00303"}}, "content": {"source": {"pdf_hash": "490d8006851b1562cfd9ec1f057471f2868289d1", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2301.00303v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "f416d3bd937abb98642eb9f3bbeaed16e2fa8150", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/490d8006851b1562cfd9ec1f057471f2868289d1.txt", "contents": "\nRethinking with Retrieval: Faithful Large Language Model Inference\n\n\nHangfeng He hanfeng.he@rochester.edu \nUniversity of Rochester \u2021 Tencent AI Lab\nSeattle\n\nUniversity of Pennsylvania\n\n\nHongming Zhang hongmzhang@global.tencent.com \nDan Roth danroth@seas.upenn.edu \nRethinking with Retrieval: Faithful Large Language Model Inference\n\nDespite the success of large language models (LLMs) in various natural language processing (NLP) tasks, the stored knowledge in these models may inevitably be incomplete, out-of-date, or incorrect. This motivates the need to utilize external knowledge to assist LLMs. Unfortunately, current methods for incorporating external knowledge often require additional training or fine-tuning, which can be costly and may not be feasible for LLMs. To address this issue, we propose a novel post-processing approach, rethinking with retrieval (RR), which retrieves relevant external knowledge based on the decomposed reasoning steps obtained from the chain-of-thought (CoT) prompting. This lightweight approach does not require additional training or fine-tuning and is not limited by the input length of LLMs. We evaluate the effectiveness of RR through extensive experiments with GPT-3 on three complex reasoning tasks: commonsense reasoning, temporal reasoning, and tabular reasoning. Our results show that RR can produce more faithful explanations and improve the performance of LLMs. 1\n\nIntroduction\n\nLarge language models (LLMs) have shown exceptional performance across various tasks through in-context learning without task-specific training or fine-tuning (Brown et al., 2020;Chowdhery et al., 2022;Zhang et al., 2022;Ouyang et al., 2022). Recent progress in prompting Kojima et al., 2022) and decoding  has made it feasible for LLMs to tackle tasks that demand complex reasoning. * Part of this work was done while the author was at the University of Pennsylvania. 1 Our code is publicly available at https://github. com/HornHehhf/RR.  Figure 1: An overview of three approaches for using LLMs: (a) Standard prompting for generating a prediction in response to a query. (b) Chain-of-thought prompting for generating both an explanation and a prediction in response to a query. (c) Rethinking with retrieval, our proposed approach for using the decomposed reasoning steps obtained from chain-of-thought prompting to retrieve relevant external knowledge for LLMs, leading to more faithful explanations and improved predictions in response to a query.\n\nHowever, the knowledge stored in LLMs might inevitably be incomplete, out-of-date, or incorrect. As a result, external sources of knowledge, such as Wikipedia, may be essential for the successful deployment of LLMs for real-world applications. Previously, people tried to utilize knowledge for smaller language models (LMs), such as T5 (Raffel et al., 2020), BERT (Devlin et al., 2019), and RoBERTa (Liu et al., 2019). However, these methods often require additional training or fine-tuning, which can be costly and thus impractical for LLMs.\n\nIn this paper, we present a post-processing approach called rethinking with retrieval (RR) for utilizing external knowledge in LLMs. Our method begins by using the chain-of-thought (CoT) prompting method  to generate a diverse set of reasoning paths, as described in . We then use each reasoning step in those paths to retrieve relevant external knowledge, which enables RR to provide more faithful explanations and more accurate predictions, as illustrated in Figure 1.\n\nWe evaluate the effectiveness of our proposed method, RR, on three complex reasoning tasks: commonsense reasoning, temporal reasoning, and tabular reasoning, using GPT-3 175B (Brown et al., 2020) and different external knowledge sources: Wikipedia, Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014), WordNet (Miller, 1995), and Conceptnet (Speer et al., 2017). The results demonstrate that RR consistently outperforms all baselines on all three tasks without requiring additional training or fine-tuning, indicating the superiority of our approach in leveraging external knowledge to enhance the performance of LLMs.\n\n2 Related Work Enhancing LMs through retrieval. Retrievalenhanced LMs have received significant attention as a means of improving performance through the incorporation of external knowledge. For example, the k-most similar training contexts can be retrieved to improve the estimation of the next word distribution in both the training stage (Borgeaud et al., 2021) and the inference stage (Khandelwal et al., 2020). Furthermore, search query generators have been adopted to generate search queries for search engines to retrieve relevant documents (Komeili et al., 2022;Shuster et al., 2022;Thoppilan et al., 2022). Other approaches have utilized retrieved documents as the additional context in generation tasks (Joshi et al., 2020;Guu et al., 2020;Lewis et al., 2020). Nakano et al. (2021) instead use human feedback in a text-based web-browsing environment. Among these previous works, Khandelwal et al. (2020) is most closely related to our approach. However, they focus on improving local inference by using the nearest neighbor datastore constructed from training data, whereas we focus on conducting faithful inference using external knowledge. In contrast to other aforementioned approaches, which require training or fine-tuning to incorporate retrieved knowledge, we propose a post-processing method for leveraging retrieved knowledge without additional training or fine-tuning.\n\nIncorporating external knowledge into LMs. Significant effort has been devoted to leveraging external knowledge to improve the reasoning ability of LMs. Previous work has incorporated external knowledge sources such as WordNet (Miller, 1995) and ConceptNet (Speer et al., 2017) to enhance LMs for tabular reasoning tasks (Neeraja et al., 2021;Varun et al., 2022). Explicit rules have also been added to inputs to improve reasoning ability over implicit knowledge (Talmor et al., 2020). In addition, explicit knowledge from Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014) and implicit knowledge in LLMs have been integrated into a transformer (Vaswani et al., 2017) for visual question answering (Gui et al., 2021). Nye et al. (2021) instead introduces a symbolic reasoning module to improve coherence and consistency in LLMs. Among these previous works, Nye et al. (2021) is the most relevant to our approach. Still, they focus on incorporating logical constraints to improve coherence and consistency, whereas we aim to improve the faithfulness of explanations through the use of external knowledge. In contrast to other aforementioned approaches that incorporate external knowledge before generation and require additional training or fine-tuning, our proposal leverages external knowledge in a postprocessing manner to enhance LMs without additional training or fine-tuning.\n\nUncovering latent Knowledge in LLMs. There has been a line of work exploring the knowledge hidden within LLMs for reasoning. This has included the use of careful prompting to encourage LLMs to generate explanations in the reasoning process, such as through chain of thought prompting in few-shot  or zero-shot (Kojima et al., 2022) learning, or through the use of scratchpads for intermediate computation (Nye et al., 2022). In addition, various methods based on sampling a diverse set of reasoning paths in LLMs have been proposed, including training verifiers to judge the correctness of model completions (Cobbe et al., 2021), calibrating model predictions based on the reliability of the explanations (Ye and Durrett, 2022), and promoting selfconsistency over diverse reasoning paths . Zelikman et al. (2022) instead iteratively bootstrap the ability of LLMs to generate high-quality rationales from a few initial examples. Liu et al. (2022) further propose generating knowledge from LLMs, which is then used as additional input to improve commonsense reasoning. In contrast to this line of work, our proposal focuses on leveraging external knowledge to enhance LLMs, while they aim to explore the knowledge hidden within LLMs.\n\nLLMs have been shown to generate incorrect supporting facts from time to time, even when they accurately capture the perspective needed to answer a question. This phenomenon highlights intrinsic issues in the way LLMs store and retrieve knowledge, including (1) the presence of out-of-date, incorrect, or missing relevant knowledge in the pre-training corpus; (2) incorrect memorization of relevant knowledge during pre-training; and (3) incorrect retrieval of relevant knowledge during the inference stage. To address these issues, we propose the use of RR, which leverages external knowledge through the retrieval of relevant information based on decomposed reasoning steps.\n\nOverview. Given a query Q, we utilize chain-ofthought prompting to generate a diverse set of reasoning paths R 1 , R 2 , \u00b7 \u00b7 \u00b7 R N , where each reasoning path R i consists of an explanation E i followed by a prediction P i . After that, we retrieve relevant knowledge K 1 , \u00b7 \u00b7 \u00b7 K M from a suitable knowledge base KB to support the explanation in each reasoning path, and select the predictionP that is most faithful to this knowledge. To better illustrate our proposal, we use \"Did Aristotle use a laptop?\" as a running example in this work.\n\nChain-of-thought prompting. In contrast to standard prompting, CoT prompting  includes demonstrations of step-by-step reasoning examples in the prompt to produce a series of short sentences that capture the reasoning process. For instance, given the question \"Did Aristotle use a laptop?\", CoT prompting aims to generate the complete reasoning path \"Aristotle died in 322 BC. The first laptop was invented in 1980. Thus, Aristotle did not use a laptop. So the answer is no.\" rather than simply outputs \"No.\" Empirical results show that CoT prompting significantly improves the performance of LLMs on many multistep reasoning tasks. Therefore, we adopt CoT prompting to obtain both explanation E and prediction P for the query Q.\n\nSampling diverse reasoning paths. Similar to , we sample a diverse set of reasoning paths R 1 , R 2 , \u00b7 \u00b7 \u00b7 R N rather than only considering the greedy path as in . For the question \"Did Aristotle use a laptop?\", the potential reasoning paths can be as follows:\n\n(R 1 ) Aristotle died in 2000. The first laptop was invented in 1980. Thus, Aristotle used a laptop. So the answer is yes.\n\n(R 2 ) Aristotle died in 322BC. The first laptop was invented in 2000. Thus, Aristotle did not use a laptop. So the answer is no.\n\n(R 3 ) Aristotle died in 322BC. The first laptop was invented in 1980. Thus, Aristotle did not use a laptop. So the answer is no.\n\nKnowledge retrieval. Different knowledge bases can be used to address different tasks. For example, to address the question \"Did Aristotle use a laptop?\", we can use Wikipedia as the external knowledge base KB. Information retrieval techniques can be applied to retrieve the relevant knowledge K 1 , \u00b7 \u00b7 \u00b7 K M from Wikipedia based on the decomposed reasoning steps. Ideally, we would obtain the following two paragraphs from Wikipedia for this question:\n\n(K 1 ) Aristotle (384-322 BC) was a Greek philosopher and polymath during the Classical period in Ancient Greece. ...\n\n(K 2 ) The Epson HX-20, the first laptop computer, was invented in 1980. ...\n\n\nFaithful inference.\n\nThe faithfulness of each reasoning path R i can be estimated using a function f KB (R i ), which is based on relevant knowledge K 1 , \u00b7 \u00b7 \u00b7 , K M retrieved from the knowledge base KB. The final prediction is obtained through the application of the following inference procedure 2 :\nP = arg max P i \u2208{P 1 ,\u00b7\u00b7\u00b7 ,P N } N i=1 1(P i = P )f KB (R i ),(1)\nwhere P i denotes the corresponding prediction in the reasoning path R i . This inference procedure is designed to identify the most faithful prediction P to the knowledge base among all predictions in the N reasoning paths. For instance, in the running example, given reasoning paths R 1 , R 2 , R 3 and the retrieved knowledge K 1 , K 2 , the above inference procedure would output the prediction \"So the answer is no.\", as it is supported by both R 2 and R 3 and has a higher faithfulness score compared to the prediction \"So the answer is yes.\", which is only supported by R 1 .\n\nIn this section, we present the evaluation of our proposed method, RR, on three complex reasoning tasks: commonsense reasoning, temporal reasoning, and tabular reasoning.\n\n\nBaselines\n\nWe compare with the following baselines.\n\nZero-shot/few-shot prompting. In our experiments, we consider GPT-3 with standard zeroshot/few-shot prompting as baselines, following the approach described in Brown et al. (2020), in which zero or few in-context exemplars of inputoutput pairs are provided in the prompt.\n\nChain-of-thought prompting. In addition to the standard zero-shot/few-shot prompting, we also consider GPT-3 with the CoT prompting proposed in  as a baseline in our experiments. This approach involves feeding LLMs step-by-step reasoning examples instead of standard input-output examples.\n\nSelf-consistency. In addition, we also consider self-consistency  as a baseline in our experiments. This approach, proposed as an alternative to the naive greedy decoding used in CoT prompting , involves sampling a diverse set of reasoning paths and selecting the most consistent answer by marginalizing the sampled paths.  (Song et al., 2020) to select the most similar paragraph based on the cosine similarity between the sentence embeddings of the retrieved paragraph and the sentence. We then employ a pre-trained natural language inference (NLI) model (Nie et al., 2020) to obtain the entailment and contradiction scores for the sentence, treating the most similar paragraph as the premise. The faithfulness of each reasoning path is then calculated using f KB (\u00b7) based on the entailment scores, contradiction scores, and MPNet similarities of all sentences in the explanation of the reasoning path. The final prediction for each question is obtained through faithful inference (Equation 1). More details about f KB (\u00b7) can be found in Appendix A.2.\n\n\nCommonsense\n\n\nTemporal Reasoning\n\nDataset description. In this experiment, we use the TempQuestions dataset (Jia et al., 2018) to investigate temporal reasoning. This dataset includes 1, 271 temporal questions that are divided into four classes: explicit temporal, implicit temporal, temporal answer, and ordinal constraints. The questions are paired with their answers from Freebase (Bollacker et al., 2008). To examine the most challenging aspect of temporal reasoning, we focus on the set of implicit temporal questions, which contain implicit temporal expressions, including free-text temporal expressions. For example, the question \"who was governor of oregon when shanghai noon was released?\" is an implicit temporal question. To facilitate our analysis, we only consider questions with a single answer, resulting in a total of 175 examples. Of these ex- amples, the first 6 are used for prompting, and the remaining 169 are used for evaluation.\n\nImplementation details. In this part, we utilize Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014) as the external knowledge base KB, as it is the largest publicly available knowledge graph, and the data from Freebase has been migrated to Wikidata. To incorporate this knowledge into our system, we apply an entity linking system 5 to each sentence in the explanation of each reasoning path to identify the corresponding Wikidata pages for all entities in the sentence. Next, we extract all temporal relations from these relevant Wikidata pages and use templates to convert these temporal relations into sentences. This step generates a set of relevant knowledge sentences for each sentence in the explanation of each reasoning path. The final prediction is then obtained by applying the procedure described in Section 4.2, in which the retrieved paragraphs are replaced with the relevant knowledge sentences from the current part.\n\n\nTabular Reasoning\n\nDataset description. We consider the IN-FOTABS dataset (Gupta et al., 2020) for tabular reasoning, which consists of 23, 738 humanwritten textual hypotheses based on premises in the form of tables extracted from 2, 540 unique Wikipedia info-boxes. We focus on the development set, which includes 1, 800 hypotheses based on 200 tables, and only consider entailed and contradictory hypotheses as it is tricky to write CoT demonstrations for neutral hypotheses. This results in a total of 1, 200 hypotheses based on 200 tables for evaluation, with an equal number of entailed and contradictory hypotheses.\n\nImplementation details. In this part, we utilize WordNet (Miller, 1995) and ConceptNet (Speer et al., 2017) as external knowledge bases. To convert tables into textual premises, we follow the same technique as in Varun et al. (2022). For each premise-hypothesis pair, we follow the procedure outlined in Varun et al. (2022) to retrieve relevant word relation triples that connect the premise and hypothesis words, such as \"married\" RelatedTo \u2190 \u2212\u2212\u2212\u2212 \u2192 \"spouse\". These triples are then converted into sentences using some simple templates. The resulting sentences, along with the textual premises from the tables, serve as relevant knowledge for each sentence in the explanation of each reasoning path. To obtain the final prediction, the procedure described in Section 4.2 is applied, whereby the retrieved paragraphs in Section 4.2 are replaced with the relevant knowledge from the current part.\n\n\nEvaluation\n\nExperimental settings. In all experiments, we utilize GPT-3 text-davinci-002 unless otherwise stated. The maximum number of tokens for generation during completion is set to 256. For zero-shot, few-shot, and chain-of-thought prompting, the temperature is fixed at 0. For selfconsistency and rethinking with retrieval, we randomly sample 10 outputs 6 with temperature 0.7. Detailed prompts can be found in Appendix A.1. We evaluate the performance of different methods on commonsense and tabular reasoning using accuracy, and on temporal reasoning using the exact match metric as defined in Rajpurkar et al. (2016). Table 1, our proposed method, rethinking with retrieval, consistently outperforms all baselines on all three reasoning tasks without requiring additional training or finetuning. The results highlight the effectiveness of our approach in leveraging external knowledge to improve the performance of LLMs.  \n\n\nResults. As shown in\n\n\nAnalysis\n\nIn this section, we perform a thorough analysis to gain a deeper understanding of RR.\n\n\nLimitations of LLMs in Reasoning\n\nIn this subsection, we present an analysis of GPT-3 with CoT prompting on the StrategyQA dataset. Upon closer examination of the outputs of GPT-3, we observed that it can provide reasonable explanations and correct predictions for a number of questions. For example, when given the question \"Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?\", GPT-3 produced the following output:\n\nThe Albany in New York has a population of about 98,000. The Albany in Georgia has a population of about 77,000. Thus, the Albany in New York is more populous than the Albany in Georgia. So the answer is no.\n\nThe above output consists of three components: (1) supporting facts (in cyan) that are based on a particular perspective, (2) chaining arguments (in orange), and (3) a prediction (in green). Components (1) and (2) contribute to the explanation. Overall, the output exhibits a high level of quality. However, we also observed that GPT-3 may occasionally produce incorrect supporting facts for its explanations or make incorrect inferences for its\n\n\nRetrieval\n\nCommonsense Tabular Query-based 73.36 36.69\n\nDecomposition-based 77.73 39.05 Table 3: Comparison of query-based and decomposition-based retrieval on commonsense and tabular reasoning. predictions, despite generally being able to identify suitable perspectives. Table 2, GPT-3 provides the incorrect supporting fact for Lil Jon's top-ranked Billboard song, stating that it was \"Get Low\" instead of the correct answer, \"Yeah\". However, it does have the correct perspective on how to answer the question, \"Was Lil Jon's top ranked Billboard song a collaboration with a member of The Lox?\". Table 2, GPT-3 makes an incorrect inference, stating that the top of Mount Fuji \"would not stick out\" of the Sea of Japan, rather than the correct answer, \"would stick out\". However, it does provide correct supporting facts based on the appropriate perspective for the question, \"Would the top of Mount Fuji stick out of the Sea of Japan?\".\n\n\nWrong supporting facts. As shown in\n\n\nWrong inference. As shown in\n\n\nAblation Study\n\nImportance of decomposition-based retrieval. In our proposed method, we retrieve relevant ex-  ternal knowledge based on the decomposed reasoning steps rather than the original query. To further investigate the impact of this choice, we conducted additional experiments in which we used the original query for knowledge retrieval while keeping other aspects of our method unchanged. As shown in Table 3, the results for these experiments are poor for both commonsense and temporal reasoning, indicating the importance of using decomposition-based retrieval in our approach.\n\nThe impact of different types of knowledge.\n\nFor tabular reasoning, we use both external knowledge (WordNet and ConceptNet) and background knowledge (tables) in our experiments. In this section, we further examine the effect of different types of knowledge on the performance of our proposed method. As shown in Table 4, the additional improvement gained by incorporating Wikidata and ConceptNet in addition to tables is limited, indicating that GPT-3 already captures many word-level relations in these external knowledge sources. In addition, the observed significant improvement in tabular reasoning from using tables alone suggests that our proposed method can also effectively leverage background knowledge.\n\n\nVariations of the Proposed Approach\n\nBasic approach: Weighting outputs. In Section 3, we present a basic version of our proposal for taking advantage of external knowledge. Our basic approach involves weighting outputs as individual units and using a voting mechanism to select the best-supported prediction. We can also directly choose the best-supported output, which includes both an explanation and a prediction, without using voting. For example, in the running example of \"Did Aristotle use a laptop?\" (see more in Section 3), the third reasoning path R 3 is the output most supported by the knowledge para-graphs K 1 and K 2 .\n\nVariant I: Fact selection. The first variant of our approach involves selecting facts from the outputs of LLMs based on external knowledge. For example, consider the running example of \"Did Aristotle use a laptop?\", where we only have access to the first two reasoning paths, R 1 and R 2 . In this case, the first sentence in R 2 and the second sentence in R 1 are supported by knowledge K 1 and K 2 , respectively. Therefore, the first variant would output the first sentence in R 2 and the second sentence in R 1 as the supporting facts.\n\nVariant II: Fact generation. The second variant of our approach involves generating facts based on both the outputs of LLMs and external knowledge. For example, consider the running example of \"Did Aristotle use a laptop?\", where we only have access to the first reasoning path R 1 . The second sentence in R 1 is supported by the second knowledge paragraph K 2 . However, the first sentence is not supported by any evidence paragraphs. We can generate questions about the first sentence, such as \"When did Aristotle die?\" and use the first knowledge paragraph K 1 to generate a new fact: \"Aristotle died in 322BC.\". As a result, the second variant would output the generated fact \"Aristotle died in 322 BC.\" and the second sentence in R 1 as the supporting facts.\n\nInference with supporting facts. For the two variants of our approach, we only have the supporting facts and need to perform a final inference step to obtain the corresponding prediction. One option for this inference is to use LLMs, but they can be costly (Brown et al., 2020) or difficult to use (Zhang et al., 2022). An alternative is to use an off-the-shelf model for inference with supporting facts, such as UnifiedQA (Khashabi et al., 2020(Khashabi et al., , 2022. As discussed in Appendix A.5, UnifiedQA is more robust to noisy supporting facts than GPT-3. We thus use the second version of UnifiedQA, UnifiedQA-v2 (Khashabi et al., 2022), for the final step of inference.\n\nExperimental settings. In this part, we focus on commonsense reasoning and use the evidence paragraphs provided in StrategyQA as the relevant knowledge, rather than the retrieved paragraphs discussed in Section 4.2. To evaluate the quality of the explanations, we adopt the best metric for factual consistency evaluation in Honovich  Results. Table 5 illustrates that the fact selection and fact generation variants of our proposal improve the faithfulness of the supporting facts in explanations, leading to increased prediction accuracy compared to the basic approach without voting. Across all variations of our proposal, we observe significant improvements in both prediction accuracy and the faithfulness of explanations when compared to the CoT prompting baseline. The incorporation of a voting mechanism leads to an increased prediction accuracy of 79.91% for the basic approach. Comparison with the performance (i.e., 77.73%) of the same approach using retrieved paragraphs rather than evidence paragraphs in Table 1 demonstrates that retrieved paragraphs are also effective for our proposal, as both significantly outperform the voting baseline, selfconsistency (i.e., 73.36%), as shown in Table 1.\n\nIt is noteworthy that UnifiedQA performs poorly on StrategyQA, achieving an accuracy of only 58.95%. However, when provided with gold supporting facts in StrategyQA, UnifiedQA demonstrates excellent performance with an accuracy of 90.83%. This suggests that UnifiedQA is suitable for last-step inference, but not effective for answering questions in StrategyQA.\n\n\nImpact of the Size of LMs\n\nIn this subsection, we examine the effect of the size of LMs on the performance of our proposed method, specifically in the context of the fact generation variant. We compare the performance of our method using various sizes of OPT models (Zhang et al., 2022) in addition to  using the same experimental setup as in Section 5.3. As shown in Figure 2, our proposed method (Variant II) consistently outperforms CoT prompting in terms of both prediction accuracy and the faithfulness of explanations, even when using smaller LMs.\n\n\nConclusion\n\nIn conclusion, the proposed approach is a promising solution for utilizing external knowledge to assist LLMs. Unlike traditional methods, RR does not require additional training or fine-tuning, making it a lightweight and feasible option for LLMs. Through extensive experiments on three reasoning tasks using GPT-3, we have shown that RR is able to produce more faithful explanations and improve the performance of LLMs. In the future, we plan to investigate various variations of RR to enhance its effectiveness and efficiency in augmenting LLMs with external knowledge. \n\n\nReasoningDataset description. For commonsense reasoning, we consider the StrategyQA dataset(Geva  et al., 2021), which includes questions that require implicit reasoning strategies. For example, the question \"Did Aristotle use a laptop?\" requires implicit decomposition into reasoning steps, while the question \"Was Aristotle alive when the laptop was invented?\" explicitly specifies the reasoning process. The StrategyQA dataset includes 2, 290 training examples, each consisting of a question (Q), a yes/no answer (A), a decomposition (D), evidence paragraphs (E), and supporting facts (F). On average, each question requires about 2.93 reasoning steps and 2.33 evidence paragraphs. In addition, a development set is constructed by randomly sampling 10% of the training examples (i.e., 229 examples). The answer distribution is roughly balanced, with approximately 47% \"yes\" questions in both the training and development sets. Unless otherwise specified, the models are evaluated on the development set 3 for StrategyQA.Implementation details. In this part, we utilize Wikipedia as the external knowledge base KB. For each sentence in the explanation of every reasoning path, we first apply BM25(Robertson et al., 2009) to retrieve the top 10 most relevant paragraphs from Wikipedia. In particular, we use the re-implementation of the sparse retrieval BM25 4 inKarpukhin et al. (2020)  from Pyserini(Lin et al., 2021). Subsequently, we use the pretrained MPNet model\n\nTable 2 :\n2Examples of incorrect outputs from GPT-3 with CoT prompting.\n\nTable 4 :\n4Performance of RR with different types of \nknowledge on tabular reasoning: external only, back-\nground only, and a combination of both. External \nknowledge refers to WordNet and ConceptNet, while \nbackground knowledge refers to the tables. \n\n\n\nTable 5 :\n5Comparison of various variations of RR and the CoT prompting baseline on StrategyQA using evidence paragraphs.et al. (2022). For simplicity, we use the pre-trained \nNLI model released by Nie et al. (2020) to com-\npute the NLI-based metric, rather than fine-tuning \nT5-11B (Raffel et al., 2020) ourselves. The imple-\nmentation details of the two variants can be found \nin Appendix A.4. \n\n\n\n\nIdo Dagan, Oren Glickman, and Bernardo Magnini. 2005. The pascal recognising textual entailment challenge. In Machine learning challenges workshop, pages 177-190. Springer. Daniel Deutsch, Tania Bedrax-Weiss, and Dan Roth. 2021. Towards question-answering as an automatic metric for evaluating the content quality of a summary. Transactions of the Association for Computational Linguistics, 9:774-789. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186. Alexander R Fabbri, Chien-Sheng Wu, Wenhao Liu, and Caiming Xiong. 2021. Qafacteval: Improved qa-based factual consistency evaluation for summarization. arXiv preprint arXiv:2112.08542. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 9:346-361. Liangke Gui, Borui Wang, Qiuyuan Huang, Alex Hauptmann, Yonatan Bisk, and Jianfeng Gao. 2021. Kat: A knowledge augmented transformer for vision-and-language. arXiv preprint arXiv:2112.08614. Vivek Gupta, Maitrey Mehta, Pegah Nokhiz, and Vivek Srikumar. 2020. Infotabs: Inference on tables as semi-structured data. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2309-2324. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training. In International Conference on Machine Learning, pages 3929-3938. PMLR. Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, and Yossi Matias. 2022. True: Reevaluating factual consistency evaluation. In Proceedings of the Second DialDoc Workshop on Document-grounded Dialogue and Conversational Question Answering, pages 161-175. Or Honovich, Leshem Choshen, Roee Aharoni, Ella Neeman, Idan Szpektor, and Omri Abend. 2021. Q2:: Evaluating factual consistency in knowledge-grounded dialogues via question generation and question answering. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7856-7870. Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Str\u00f6tgen, and Gerhard Weikum. 2018. Tempquestions: A benchmark for temporal question answering. In Companion Proceedings of the The Web Conference 2018, pages 1057-1062. Mandar Joshi, Kenton Lee, Yi Luan, and Kristina Toutanova. 2020. Contextualized representations using textual encyclopedic knowledge. arXiv preprint arXiv:2004.12006. Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6769-6781. Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. 2020. Generalization through memorization: Nearest neighbor language models. In International Conference on Learning Representations. Daniel Khashabi, Yeganeh Kordi, and Hannaneh Hajishirzi. 2022. Unifiedqa-v2: Stronger generalization via broader cross-format training. arXiv preprint arXiv:2202.12359. Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, and Hannaneh Hajishirzi. 2020. Unifiedqa: Crossing format boundaries with a single qa system. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1896-1907. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916. Komeili, Kurt Shuster, and Jason Weston. 2022. Internet-augmented dialogue generation. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 8460-8478. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, et al. 2020. Retrievalaugmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33:9459-9474. Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, and Rodrigo Nogueira. 2021. Pyserini: A Python toolkit for reproducible information retrieval research with sparse and dense representations. In Proceedings of the 44th Annual International ACM SI-GIR Conference on Research and Development in Information Retrieval (SIGIR 2021), pages 2356-2362. Jiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le Bras, Yejin Choi, and Hannaneh Hajishirzi. 2022. Generated knowledge prompting for commonsense reasoning. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 3154-3169.Vladimir Daniel Mojtaba \nNote that this is the basic version of faithful inference, and further variations can be found in Section 5.3.\nAs the annotations for the test set are not publicly available, we use the development set for evaluation. This allows us to perform a more comprehensive analysis.4  We also experimented with DPR and BM25+DPR, and found that BM25 outperformed these methods in our experiments. More details can be found in Appendix A.3.\nWe use the spacy entity linker: https://pypi.org/ project/spacy-entity-linker/.\nFor commonsense reasoning, we sample 9 outputs, as we have found that odd numbers of outputs tend to yield better voting performance for self-consistency on StrategyQA.\nA AppendixIn this section, we provide additional details on our experimental setup. Further information can be found in our code.A.1 Detailed PromptsWe adopt the same CoT prompt for commonsense reasoning (i.e., StrategyQA) as those presented in . The CoT prompt for temporal reasoning is provided inTable 6. For tabular reasoning, we adopt the method ofBrown et al. (2020)for converting NLI into QA for RTE(Dagan et al., 2005), and randomly sample 6 examples from the training data to construct the prompt, as shown inTable 8. The few-shot prompt utilizes the same exemplars as the CoT prompt and does not involve CoT reasoning processes.A.2 Description of Faithfulness FunctionsFor a sentence s, we denote its MPNet similarity, entailment score, and contradiction score as M (s), E(s), and C(s), respectively. In our experiments, the corresponding thresholds for these scores are T m = 0.5, T e = 0.6, and T c = 0.99. Given the entailment scores, contradiction scores, and MP-Net similarities of all supporting facts (denoted as S) in the explanation of a reasoning path R, different faithfulness functions f KB (\u00b7) can be adopted in different settings as follows:((2) f KB (R) = s\u2208S [M (s) + E(s)](In Section 4, we employ function (1) for commonsense and tabular reasoning. For temporal reasoning, we use function (2) as the distinct nature of sentences converted from temporal relations leads to unreliable contradiction scores. In Sections 5.3-5.4, we use function (3) for commonsense reasoning with evidence paragraphs, as the high quality of the relevant knowledge negates the need for the complementary use of the MPNet similarity to improve the entailment score.A.3 Comparison of Retrieval SystemsFor commonsense reasoning, we utilized different retrieval systems inKarpukhin et al. (2020)to retrieve relevant paragraphs from Wikipedia. The performance of BM25, DPR, and BM25+DPR were 77.73%, 58.52%, and 77.29%, respectively, indicating that BM25 is the best choice in our case.A.4 Implementation Details for the TwoVariants of RR Fact selection implementation details. In this work, we utilize the information present in the topranked output produced by our basic approach as a guide. To this end, we apply a greedy clustering algorithm to group the sentences from all outputs into distinct topic categories based on the cosine similarity of their MPNet sentence embeddings. For each fact in the top-ranked output of our basic approach, we identify the fact with the highest faithfulness within the same topic group and replace it in the output. The faithfulness of a fact is calculated using the f KB function by replacing the supporting facts with a single fact.Fact generation implementation details. In this part, we generate questions for the named entities present in each fact of the top-ranked output produced by our basic approach, and retrieve the corresponding answers from the evidence paragraphs using UnifiedQA. We employ the question generation model described inDeutsch et al. (2021), which has been shown to be more extractive compared to other models as demonstrated inFabbri et al. (2021). We adopt the question filtering approach proposed in Honovich et al.(2021)using an off-the-shelf extractive QA model (ktrapeznikov/albert-xlarge-v2-squad-v2 from Hugging Face(Wolf et al., 2020)). We then use an off-the-shelf model (MarkS/bart-base-qa2d from Hugging Face) to convert the generated QA pairs into declarative sentences. We apply simple rules based on the entailment and contradiction scores of the selected facts from the fact selection variant and the generated declarative sentences to obtain the final generated facts.A.5 Comparison of Different Inference Methods with Supporting FactsIn our experiments, we utilize UnifiedQA for the final step of inference in both variants. However, it is worth noting that GPT-3 could also be used for this purpose. As shown inTable 7, we observe that UnifiedQA performs better at inference with generated facts, while GPT-3 with CoT prompting performs better with empty or gold facts. This suggests that UnifiedQA is more robust to noisy   inputs compared to GPT-3. Additionally, both UnifiedQA and GPT-3 with CoT prompting significantly outperform GPT-3 with zero-shot prompting, indicating that the CoT prompting is also beneficial for the final step of inference.\nFreebase: a collaboratively created graph database for structuring human knowledge. Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, Jamie Taylor, Proceedings of the 2008 ACM SIGMOD international conference on Management of data. the 2008 ACM SIGMOD international conference on Management of dataKurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international con- ference on Management of data, pages 1247- 1250.\n\nSebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, arXiv:2112.04426Improving language models by retrieving from trillions of tokens. arXiv preprintSebastian Borgeaud, Arthur Mensch, Jordan Hoff- mann, Trevor Cai, Eliza Rutherford, Katie Mil- lican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. 2021. Improving language models by retriev- ing from trillions of tokens. arXiv preprint arXiv:2112.04426.\n\nLanguage models are few-shot learners. Advances in neural information processing systems. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, 33Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Ad- vances in neural information processing sys- tems, 33:1877-1901.\n\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won, Charles Chung, Sebastian Sutton, Gehrmann, arXiv:2204.02311Palm: Scaling language modeling with pathways. arXiv preprintAakanksha Chowdhery, Sharan Narang, Jacob De- vlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. 2022. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311.\n\nTraining verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, arXiv:2110.14168arXiv preprintKarl Cobbe, Vineet Kosaraju, Mohammad Bavar- ian, Jacob Hilton, Reiichiro Nakano, Christo- pher Hesse, and John Schulman. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Yanqi Matena, Wei Zhou, Peter J Li, Liu, Journal of Machine Learning Research. 21Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21:1-67.\n\nSquad: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingPranav Rajpurkar, Jian Zhang, Konstantin Lopy- rev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Em- pirical Methods in Natural Language Process- ing, pages 2383-2392.\n\nThe probabilistic relevance framework: Bm25 and beyond. Stephen Robertson, Hugo Zaragoza, Foundations and Trends\u00ae in Information Retrieval. 34Stephen Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: Bm25 and beyond. Foundations and Trends\u00ae in In- formation Retrieval, 3(4):333-389.\n\nArthur Szlam, and Jason Weston. 2022. Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion. Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, arXiv:2203.13224arXiv preprintKurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason We- ston. 2022. Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion. arXiv preprint arXiv:2203.13224.\n\nMpnet: Masked and permuted pre-training for language understanding. Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu, Advances in Neural Information Processing Systems. 33Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. 2020. Mpnet: Masked and permuted pre-training for language understand- ing. Advances in Neural Information Process- ing Systems, 33:16857-16867.\n\nConceptnet 5.5: An open multilingual graph of general knowledge. Robyn Speer, Joshua Chin, Catherine Havasi, Thirty-first AAAI conference on artificial intelligence. Robyn Speer, Joshua Chin, and Catherine Havasi. 2017. Conceptnet 5.5: An open multilingual graph of general knowledge. In Thirty-first AAAI conference on artificial intelligence.\n\nLeapof-thought: Teaching pre-trained models to systematically reason over implicit knowledge. Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, Jonathan Berant, Advances in Neural Information Processing Systems. 33Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Goldberg, and Jonathan Berant. 2020. Leap- of-thought: Teaching pre-trained models to systematically reason over implicit knowledge. Advances in Neural Information Processing Systems, 33:20227-20237.\n\nRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze, Alicia Cheng, Taylor Jin, Leslie Bos, Yu Baker, Du, arXiv:2201.08239Lamda: Language models for dialog applications. arXiv preprintRomal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng- Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022. Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239.\n\nTrans-kblstm: An external knowledge enhanced transformer bilstm model for tabular reasoning. Yerram Varun, Aayush Sharma, Vivek Gupta, The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. Proceedings of Deep Learning Inside OutYerram Varun, Aayush Sharma, and Vivek Gupta. 2022. Trans-kblstm: An external knowledge enhanced transformer bilstm model for tabular reasoning. In Proceedings of Deep Learning In- side Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, pages 62-78.\n\nAttention is all you need. Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, 30Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. At- tention is all you need. Advances in neural in- formation processing systems, 30.\n\nWikidata: a free collaborative knowledgebase. Denny Vrande\u010di\u0107, Markus Kr\u00f6tzsch, Communications of the ACM. 5710Denny Vrande\u010di\u0107 and Markus Kr\u00f6tzsch. 2014. Wikidata: a free collaborative knowledgebase. Communications of the ACM, 57(10):78-85.\n\nSelfconsistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Denny Zhou, arXiv:2203.11171arXiv preprintXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. 2022. Self- consistency improves chain of thought rea- soning in language models. arXiv preprint arXiv:2203.11171.\n\nChain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, Denny Zhou, arXiv:2201.11903arXiv preprintJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. 2022. Chain of thought prompting elic- its reasoning in large language models. arXiv preprint arXiv:2201.11903.\n\nTransformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations. the 2020 conference on empirical methods in natural language processing: system demonstrationsThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, et al. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empir- ical methods in natural language processing: system demonstrations, pages 38-45.\n\nThe unreliability of explanations in few-shot in-context learning. Xi Ye, Greg Durrett, arXiv:2205.03401arXiv preprintXi Ye and Greg Durrett. 2022. The unreliability of explanations in few-shot in-context learning. arXiv preprint arXiv:2205.03401.\n\nEric Zelikman, Yuhuai Wu, Noah D Goodman, arXiv:2203.14465Star: Bootstrapping reasoning with reasoning. arXiv preprintEric Zelikman, Yuhuai Wu, and Noah D Good- man. 2022. Star: Bootstrapping reasoning with reasoning. arXiv preprint arXiv:2203.14465.\n\n. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, arXiv:2205.01068Mona Diab, Xian Li, Xi Victoria LinarXiv preprintet al. 2022. Opt: Open pretrained transformer language modelsSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt: Open pre- trained transformer language models. arXiv preprint arXiv:2205.01068.\n\nLeast-to-most prompting enables complex reasoning in large language models. Denny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, arXiv:2205.10625Quoc Le, and Ed Chi. 2022arXiv preprintDenny Zhou, Nathanael Sch\u00e4rli, Le Hou, Ja- son Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. 2022. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625.\n\nCalifornia is a state. Thus, Charles Sumner Tainter has left the state of Massachusetts. So the answer is false. The Region of Curitiba are South. The Elevation of Curitiba are 934.6 m (3,066.3 ft). The Density of Curitiba are 4,062/km 2 (10,523/sq mi). The Metro density of Curitiba are 210.9/km 2 (546.2/sq mi). Question: Curitiba is above sea level. True or False? Answer: The elevation of Curitiba are 934. Charles Sumner, Tainter , San Diego, California, U.S.; San Diego, California, U.S.The Nationality of Charles Sumner Tainter are American. The Known for of Charles Sumner Tainter are Photophone, phonograph Father Of The Speaking Machine. Question: Charles Sumner Tainter never left the state of Massachusetts. True or False? Answer: Charles Sumner Tainter was. 6 m (3,066.3 ft). Elevation is a hypernym of level. Thus, Curitiba is above sea level. So the answer is trueCharles Sumner Tainter was Died on April 20, 1940 ( 1940-04-21 ) (aged 85) San Diego, California, U.S.. The Nationality of Charles Sumner Tainter are American. The Known for of Charles Sumner Tainter are Photophone, phonograph Father Of The Speaking Machine. Question: Charles Sumner Tainter never left the state of Massachusetts. True or False? Answer: Charles Sumner Tainter was died in San Diego, California, U.S.. California is a state. Thus, Charles Sumner Tainter has left the state of Massachusetts. So the answer is false. The Region of Curitiba are South. The Elevation of Curitiba are 934.6 m (3,066.3 ft). The Density of Curitiba are 4,062/km 2 (10,523/sq mi). The Metro density of Curitiba are 210.9/km 2 (546.2/sq mi). Question: Curitiba is above sea level. True or False? Answer: The elevation of Curitiba are 934.6 m (3,066.3 ft). Elevation is a hypernym of level. Thus, Curitiba is above sea level. So the answer is true.\n\nThe Residence of Idris Elba are London. The Other names of Idris Elba are DJ Big Driis, Big Driis the Londoner, Big Driis, and 7 Dub. The Occupation of Idris Elba are Actor, producer, director, musician, and DJ. Question: Idris Elba is an English entertainer. True or False? Answer: The residence of Idris Elba is London. English is related to London. The occupation of Idris Elba are actor, producer, director, musician, and DJ. Actor is a hyponym of entertainer. Charles , 1948-11-14 ) (age 70The Spouse of Charles (Prince of Wales) are Lady Diana Spencer ( m. 1981 ; div. 1996 ) , and Camilla Parker Bowles ( m. 2005 ). Buckingham Palace, London, England; Hackney, London, England46The Issue of Charles (Prince of Wales) are Prince William, Duke of Cambridge , and Prince Harry, Duke of Sussex. Question: Charles was born in 1948 and has been married twice. True or False? Answer: Charles (Prince of Wales) was Born on 14. Musician is a hyponym of entertainer. DJ is an entertainer. Thus, Idris Elba is an English entertainer. So the answer is trueCharles (Prince of Wales) was Born on 14 November 1948 ( 1948-11-14 ) (age 70) Buckingham Palace, London, England. The Spouse of Charles (Prince of Wales) are Lady Diana Spencer ( m. 1981 ; div. 1996 ) , and Camilla Parker Bowles ( m. 2005 ). The Issue of Charles (Prince of Wales) are Prince William, Duke of Cambridge , and Prince Harry, Duke of Sussex. Question: Charles was born in 1948 and has been married twice. True or False? Answer: Charles (Prince of Wales) was Born on 14 November 1948. The Spouse of Charles (Prince of Wales) are Lady Diana Spencer ( m. 1981 ; div. 1996 ) , and Camilla Parker Bowles ( m. 2005 ). Married is related to spouse. Thus, Charles was born in 1948 and has been married twice. So the answer is true. The Born of Idris Elba are 6 September 1972 (age 46) Hackney, London, England. The Residence of Idris Elba are London. The Other names of Idris Elba are DJ Big Driis, Big Driis the Londoner, Big Driis, and 7 Dub. The Occupation of Idris Elba are Actor, producer, director, musician, and DJ. Question: Idris Elba is an English entertainer. True or False? Answer: The residence of Idris Elba is London. English is related to London. The occupation of Idris Elba are actor, producer, director, musician, and DJ. Actor is a hyponym of entertainer. Musician is a hyponym of entertainer. DJ is an entertainer. Thus, Idris Elba is an English entertainer. So the answer is true.\n\nThe Born of Jean, the Vitagraph Dog are 1902 Eastport, Maine. The Years active of Jean, the Vitagraph Dog are 1909 -1916. Question: Jean, the Vitagraph Dog was a Golden Retriever which perform in circus. True or False? Answer: The Breed of Jean, the Vitagraph Dog are Scotch Collie. Collie is a hyponym of dog. The Breed of Jean, the Vitagraph Dog are Scotch Collie. The Sex of Jean, the Vitagraph Dog are Female. Retriever is a hyponym of dog. Thus, Jean, the Vitagraph Dog was not a Golden Retriever which perform in circus. So the answer is falseThe Breed of Jean, the Vitagraph Dog are Scotch Collie. The Sex of Jean, the Vitagraph Dog are Female. The Born of Jean, the Vitagraph Dog are 1902 Eastport, Maine. The Years active of Jean, the Vitagraph Dog are 1909 -1916. Question: Jean, the Vitagraph Dog was a Golden Retriever which perform in circus. True or False? Answer: The Breed of Jean, the Vitagraph Dog are Scotch Collie. Collie is a hyponym of dog. Retriever is a hyponym of dog. Thus, Jean, the Vitagraph Dog was not a Golden Retriever which perform in circus. So the answer is false.\n\nThe Genre of Hydrograd are Hard rock. The Label of Hydrograd are Roadrunner. The Producer of Hydrograd are Jay Ruston. Question: Hydrograd is in the rap genre. True or False? Answer: The Genre of Hydrograd are Hard rock. Rap is distinct from rock. Thus, Hydrograd is not in the rap genre. The Studio of Hydrograd are Sphere Studios. North Hollywood, Los AngelesSo the answer is false. Table 8: The CoT prompt for tabular reasoningThe Studio of Hydrograd are Sphere Studios, North Hollywood, Los Angeles. The Genre of Hydrograd are Hard rock. The Label of Hydrograd are Roadrunner. The Producer of Hydrograd are Jay Ruston. Question: Hydrograd is in the rap genre. True or False? Answer: The Genre of Hydrograd are Hard rock. Rap is distinct from rock. Thus, Hydrograd is not in the rap genre. So the answer is false. Table 8: The CoT prompt for tabular reasoning.\n", "annotations": {"author": "[{\"end\":186,\"start\":70},{\"end\":232,\"start\":187},{\"end\":265,\"start\":233},{\"end\":186,\"start\":70},{\"end\":232,\"start\":187},{\"end\":265,\"start\":233}]", "publisher": null, "author_last_name": "[{\"end\":81,\"start\":79},{\"end\":201,\"start\":196},{\"end\":241,\"start\":237},{\"end\":81,\"start\":79},{\"end\":201,\"start\":196},{\"end\":241,\"start\":237}]", "author_first_name": "[{\"end\":78,\"start\":70},{\"end\":195,\"start\":187},{\"end\":236,\"start\":233},{\"end\":78,\"start\":70},{\"end\":195,\"start\":187},{\"end\":236,\"start\":233}]", "author_affiliation": "[{\"end\":156,\"start\":108},{\"end\":185,\"start\":158},{\"end\":156,\"start\":108},{\"end\":185,\"start\":158}]", "title": "[{\"end\":67,\"start\":1},{\"end\":332,\"start\":266},{\"end\":67,\"start\":1},{\"end\":332,\"start\":266}]", "venue": null, "abstract": "[{\"end\":1415,\"start\":334},{\"end\":1415,\"start\":334}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1610,\"start\":1590},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1633,\"start\":1610},{\"end\":1652,\"start\":1633},{\"end\":1672,\"start\":1652},{\"end\":1723,\"start\":1703},{\"end\":1901,\"start\":1900},{\"end\":2841,\"start\":2820},{\"end\":2869,\"start\":2843},{\"end\":2901,\"start\":2875},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3695,\"start\":3675},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3788,\"start\":3758},{\"end\":3812,\"start\":3790},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3849,\"start\":3829},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4472,\"start\":4449},{\"end\":4522,\"start\":4497},{\"end\":4678,\"start\":4656},{\"end\":4699,\"start\":4678},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4722,\"start\":4699},{\"end\":4841,\"start\":4821},{\"end\":4858,\"start\":4841},{\"end\":4877,\"start\":4858},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4899,\"start\":4879},{\"end\":5021,\"start\":4997},{\"end\":5739,\"start\":5725},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5775,\"start\":5755},{\"end\":5841,\"start\":5819},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5860,\"start\":5841},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5982,\"start\":5961},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6060,\"start\":6030},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6154,\"start\":6132},{\"end\":6203,\"start\":6185},{\"end\":6222,\"start\":6205},{\"end\":6361,\"start\":6344},{\"end\":7200,\"start\":7179},{\"end\":7292,\"start\":7274},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7497,\"start\":7477},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7596,\"start\":7574},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7681,\"start\":7659},{\"end\":7814,\"start\":7797},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12716,\"start\":12697},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13444,\"start\":13425},{\"end\":13676,\"start\":13658},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14567,\"start\":14543},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15200,\"start\":15170},{\"end\":16730,\"start\":16716},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":16766,\"start\":16746},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16891,\"start\":16872},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16982,\"start\":16963},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18182,\"start\":18159},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":24260,\"start\":24240},{\"end\":24300,\"start\":24281},{\"end\":24428,\"start\":24406},{\"end\":24452,\"start\":24428},{\"end\":24628,\"start\":24592},{\"end\":26523,\"start\":26503},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":28602,\"start\":28578},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1610,\"start\":1590},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1633,\"start\":1610},{\"end\":1652,\"start\":1633},{\"end\":1672,\"start\":1652},{\"end\":1723,\"start\":1703},{\"end\":1901,\"start\":1900},{\"end\":2841,\"start\":2820},{\"end\":2869,\"start\":2843},{\"end\":2901,\"start\":2875},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3695,\"start\":3675},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3788,\"start\":3758},{\"end\":3812,\"start\":3790},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3849,\"start\":3829},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4472,\"start\":4449},{\"end\":4522,\"start\":4497},{\"end\":4678,\"start\":4656},{\"end\":4699,\"start\":4678},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4722,\"start\":4699},{\"end\":4841,\"start\":4821},{\"end\":4858,\"start\":4841},{\"end\":4877,\"start\":4858},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4899,\"start\":4879},{\"end\":5021,\"start\":4997},{\"end\":5739,\"start\":5725},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5775,\"start\":5755},{\"end\":5841,\"start\":5819},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5860,\"start\":5841},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5982,\"start\":5961},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6060,\"start\":6030},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6154,\"start\":6132},{\"end\":6203,\"start\":6185},{\"end\":6222,\"start\":6205},{\"end\":6361,\"start\":6344},{\"end\":7200,\"start\":7179},{\"end\":7292,\"start\":7274},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7497,\"start\":7477},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7596,\"start\":7574},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7681,\"start\":7659},{\"end\":7814,\"start\":7797},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12716,\"start\":12697},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13444,\"start\":13425},{\"end\":13676,\"start\":13658},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14567,\"start\":14543},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15200,\"start\":15170},{\"end\":16730,\"start\":16716},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":16766,\"start\":16746},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16891,\"start\":16872},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16982,\"start\":16963},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18182,\"start\":18159},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":24260,\"start\":24240},{\"end\":24300,\"start\":24281},{\"end\":24428,\"start\":24406},{\"end\":24452,\"start\":24428},{\"end\":24628,\"start\":24592},{\"end\":26523,\"start\":26503},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":28602,\"start\":28578}]", "figure": "[{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":28849,\"start\":27378},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":28922,\"start\":28850},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":29177,\"start\":28923},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":29577,\"start\":29178},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":34782,\"start\":29578},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":28849,\"start\":27378},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":28922,\"start\":28850},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":29177,\"start\":28923},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":29577,\"start\":29178},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":34782,\"start\":29578}]", "paragraph": "[{\"end\":2482,\"start\":1431},{\"end\":3026,\"start\":2484},{\"end\":3498,\"start\":3028},{\"end\":4106,\"start\":3500},{\"end\":5496,\"start\":4108},{\"end\":6867,\"start\":5498},{\"end\":8100,\"start\":6869},{\"end\":8778,\"start\":8102},{\"end\":9323,\"start\":8780},{\"end\":10053,\"start\":9325},{\"end\":10316,\"start\":10055},{\"end\":10440,\"start\":10318},{\"end\":10571,\"start\":10442},{\"end\":10702,\"start\":10573},{\"end\":11157,\"start\":10704},{\"end\":11276,\"start\":11159},{\"end\":11354,\"start\":11278},{\"end\":11659,\"start\":11378},{\"end\":12309,\"start\":11727},{\"end\":12481,\"start\":12311},{\"end\":12535,\"start\":12495},{\"end\":12808,\"start\":12537},{\"end\":13099,\"start\":12810},{\"end\":14156,\"start\":13101},{\"end\":15110,\"start\":14193},{\"end\":16033,\"start\":15112},{\"end\":16657,\"start\":16055},{\"end\":17554,\"start\":16659},{\"end\":18488,\"start\":17569},{\"end\":18609,\"start\":18524},{\"end\":19066,\"start\":18646},{\"end\":19275,\"start\":19068},{\"end\":19722,\"start\":19277},{\"end\":19779,\"start\":19736},{\"end\":20663,\"start\":19781},{\"end\":21324,\"start\":20751},{\"end\":21369,\"start\":21326},{\"end\":22038,\"start\":21371},{\"end\":22674,\"start\":22078},{\"end\":23215,\"start\":22676},{\"end\":23981,\"start\":23217},{\"end\":24662,\"start\":23983},{\"end\":25871,\"start\":24664},{\"end\":26234,\"start\":25873},{\"end\":26790,\"start\":26264},{\"end\":27377,\"start\":26805},{\"end\":2482,\"start\":1431},{\"end\":3026,\"start\":2484},{\"end\":3498,\"start\":3028},{\"end\":4106,\"start\":3500},{\"end\":5496,\"start\":4108},{\"end\":6867,\"start\":5498},{\"end\":8100,\"start\":6869},{\"end\":8778,\"start\":8102},{\"end\":9323,\"start\":8780},{\"end\":10053,\"start\":9325},{\"end\":10316,\"start\":10055},{\"end\":10440,\"start\":10318},{\"end\":10571,\"start\":10442},{\"end\":10702,\"start\":10573},{\"end\":11157,\"start\":10704},{\"end\":11276,\"start\":11159},{\"end\":11354,\"start\":11278},{\"end\":11659,\"start\":11378},{\"end\":12309,\"start\":11727},{\"end\":12481,\"start\":12311},{\"end\":12535,\"start\":12495},{\"end\":12808,\"start\":12537},{\"end\":13099,\"start\":12810},{\"end\":14156,\"start\":13101},{\"end\":15110,\"start\":14193},{\"end\":16033,\"start\":15112},{\"end\":16657,\"start\":16055},{\"end\":17554,\"start\":16659},{\"end\":18488,\"start\":17569},{\"end\":18609,\"start\":18524},{\"end\":19066,\"start\":18646},{\"end\":19275,\"start\":19068},{\"end\":19722,\"start\":19277},{\"end\":19779,\"start\":19736},{\"end\":20663,\"start\":19781},{\"end\":21324,\"start\":20751},{\"end\":21369,\"start\":21326},{\"end\":22038,\"start\":21371},{\"end\":22674,\"start\":22078},{\"end\":23215,\"start\":22676},{\"end\":23981,\"start\":23217},{\"end\":24662,\"start\":23983},{\"end\":25871,\"start\":24664},{\"end\":26234,\"start\":25873},{\"end\":26790,\"start\":26264},{\"end\":27377,\"start\":26805}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11726,\"start\":11660},{\"attributes\":{\"id\":\"formula_0\"},\"end\":11726,\"start\":11660}]", "table_ref": "[{\"end\":18191,\"start\":18184},{\"end\":19820,\"start\":19813},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20005,\"start\":19997},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20330,\"start\":20323},{\"end\":21153,\"start\":21146},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":21645,\"start\":21638},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":25014,\"start\":25007},{\"end\":25688,\"start\":25681},{\"end\":25870,\"start\":25863},{\"end\":18191,\"start\":18184},{\"end\":19820,\"start\":19813},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20005,\"start\":19997},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20330,\"start\":20323},{\"end\":21153,\"start\":21146},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":21645,\"start\":21638},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":25014,\"start\":25007},{\"end\":25688,\"start\":25681},{\"end\":25870,\"start\":25863}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1429,\"start\":1417},{\"end\":11376,\"start\":11357},{\"attributes\":{\"n\":\"4.1\"},\"end\":12493,\"start\":12484},{\"attributes\":{\"n\":\"4.2\"},\"end\":14170,\"start\":14159},{\"attributes\":{\"n\":\"4.3\"},\"end\":14191,\"start\":14173},{\"attributes\":{\"n\":\"4.4\"},\"end\":16053,\"start\":16036},{\"attributes\":{\"n\":\"4.5\"},\"end\":17567,\"start\":17557},{\"end\":18511,\"start\":18491},{\"attributes\":{\"n\":\"5\"},\"end\":18522,\"start\":18514},{\"attributes\":{\"n\":\"5.1\"},\"end\":18644,\"start\":18612},{\"end\":19734,\"start\":19725},{\"end\":20701,\"start\":20666},{\"end\":20732,\"start\":20704},{\"attributes\":{\"n\":\"5.2\"},\"end\":20749,\"start\":20735},{\"attributes\":{\"n\":\"5.3\"},\"end\":22076,\"start\":22041},{\"attributes\":{\"n\":\"5.4\"},\"end\":26262,\"start\":26237},{\"attributes\":{\"n\":\"6\"},\"end\":26803,\"start\":26793},{\"end\":28860,\"start\":28851},{\"end\":28933,\"start\":28924},{\"end\":29188,\"start\":29179},{\"attributes\":{\"n\":\"1\"},\"end\":1429,\"start\":1417},{\"end\":11376,\"start\":11357},{\"attributes\":{\"n\":\"4.1\"},\"end\":12493,\"start\":12484},{\"attributes\":{\"n\":\"4.2\"},\"end\":14170,\"start\":14159},{\"attributes\":{\"n\":\"4.3\"},\"end\":14191,\"start\":14173},{\"attributes\":{\"n\":\"4.4\"},\"end\":16053,\"start\":16036},{\"attributes\":{\"n\":\"4.5\"},\"end\":17567,\"start\":17557},{\"end\":18511,\"start\":18491},{\"attributes\":{\"n\":\"5\"},\"end\":18522,\"start\":18514},{\"attributes\":{\"n\":\"5.1\"},\"end\":18644,\"start\":18612},{\"end\":19734,\"start\":19725},{\"end\":20701,\"start\":20666},{\"end\":20732,\"start\":20704},{\"attributes\":{\"n\":\"5.2\"},\"end\":20749,\"start\":20735},{\"attributes\":{\"n\":\"5.3\"},\"end\":22076,\"start\":22041},{\"attributes\":{\"n\":\"5.4\"},\"end\":26262,\"start\":26237},{\"attributes\":{\"n\":\"6\"},\"end\":26803,\"start\":26793},{\"end\":28860,\"start\":28851},{\"end\":28933,\"start\":28924},{\"end\":29188,\"start\":29179}]", "table": "[{\"end\":29177,\"start\":28935},{\"end\":29577,\"start\":29300},{\"end\":34782,\"start\":34758},{\"end\":29177,\"start\":28935},{\"end\":29577,\"start\":29300},{\"end\":34782,\"start\":34758}]", "figure_caption": "[{\"end\":28849,\"start\":27380},{\"end\":28922,\"start\":28862},{\"end\":29300,\"start\":29190},{\"end\":34758,\"start\":29580},{\"end\":28849,\"start\":27380},{\"end\":28922,\"start\":28862},{\"end\":29300,\"start\":29190},{\"end\":34758,\"start\":29580}]", "figure_ref": "[{\"end\":1979,\"start\":1971},{\"end\":3497,\"start\":3489},{\"end\":26613,\"start\":26605},{\"end\":1979,\"start\":1971},{\"end\":3497,\"start\":3489},{\"end\":26613,\"start\":26605}]", "bib_author_first_name": "[{\"end\":39891,\"start\":39887},{\"end\":39908,\"start\":39903},{\"end\":39923,\"start\":39916},{\"end\":39937,\"start\":39934},{\"end\":39951,\"start\":39946},{\"end\":40392,\"start\":40383},{\"end\":40409,\"start\":40403},{\"end\":40424,\"start\":40418},{\"end\":40441,\"start\":40435},{\"end\":40452,\"start\":40447},{\"end\":40470,\"start\":40465},{\"end\":40487,\"start\":40481},{\"end\":40520,\"start\":40507},{\"end\":40536,\"start\":40530},{\"end\":40549,\"start\":40544},{\"end\":41039,\"start\":41036},{\"end\":41055,\"start\":41047},{\"end\":41066,\"start\":41062},{\"end\":41081,\"start\":41074},{\"end\":41096,\"start\":41091},{\"end\":41098,\"start\":41097},{\"end\":41115,\"start\":41107},{\"end\":41132,\"start\":41126},{\"end\":41152,\"start\":41146},{\"end\":41166,\"start\":41160},{\"end\":41181,\"start\":41175},{\"end\":41477,\"start\":41468},{\"end\":41495,\"start\":41489},{\"end\":41509,\"start\":41504},{\"end\":41525,\"start\":41518},{\"end\":41539,\"start\":41533},{\"end\":41552,\"start\":41548},{\"end\":41566,\"start\":41562},{\"end\":41593,\"start\":41586},{\"end\":41610,\"start\":41601},{\"end\":42014,\"start\":42010},{\"end\":42028,\"start\":42022},{\"end\":42047,\"start\":42039},{\"end\":42063,\"start\":42058},{\"end\":42081,\"start\":42072},{\"end\":42101,\"start\":42090},{\"end\":42113,\"start\":42109},{\"end\":42452,\"start\":42447},{\"end\":42464,\"start\":42461},{\"end\":42478,\"start\":42471},{\"end\":42777,\"start\":42771},{\"end\":42793,\"start\":42789},{\"end\":42811,\"start\":42801},{\"end\":42826,\"start\":42821},{\"end\":43305,\"start\":43298},{\"end\":43321,\"start\":43317},{\"end\":43701,\"start\":43697},{\"end\":43718,\"start\":43711},{\"end\":43735,\"start\":43728},{\"end\":43752,\"start\":43745},{\"end\":44108,\"start\":44102},{\"end\":44117,\"start\":44115},{\"end\":44126,\"start\":44123},{\"end\":44140,\"start\":44132},{\"end\":44152,\"start\":44145},{\"end\":44487,\"start\":44482},{\"end\":44501,\"start\":44495},{\"end\":44517,\"start\":44508},{\"end\":44861,\"start\":44857},{\"end\":44876,\"start\":44870},{\"end\":44891,\"start\":44886},{\"end\":44903,\"start\":44899},{\"end\":44922,\"start\":44914},{\"end\":45237,\"start\":45232},{\"end\":45255,\"start\":45249},{\"end\":45258,\"start\":45256},{\"end\":45273,\"start\":45268},{\"end\":45284,\"start\":45280},{\"end\":45300,\"start\":45294},{\"end\":45331,\"start\":45325},{\"end\":45345,\"start\":45339},{\"end\":45357,\"start\":45351},{\"end\":45365,\"start\":45363},{\"end\":45794,\"start\":45788},{\"end\":45808,\"start\":45802},{\"end\":45822,\"start\":45817},{\"end\":46352,\"start\":46346},{\"end\":46366,\"start\":46362},{\"end\":46380,\"start\":46376},{\"end\":46394,\"start\":46389},{\"end\":46411,\"start\":46406},{\"end\":46424,\"start\":46419},{\"end\":46426,\"start\":46425},{\"end\":46440,\"start\":46434},{\"end\":46454,\"start\":46449},{\"end\":46738,\"start\":46733},{\"end\":46756,\"start\":46750},{\"end\":47007,\"start\":47001},{\"end\":47019,\"start\":47014},{\"end\":47029,\"start\":47025},{\"end\":47046,\"start\":47042},{\"end\":47053,\"start\":47051},{\"end\":47064,\"start\":47059},{\"end\":47367,\"start\":47362},{\"end\":47379,\"start\":47373},{\"end\":47390,\"start\":47386},{\"end\":47410,\"start\":47403},{\"end\":47420,\"start\":47418},{\"end\":47430,\"start\":47426},{\"end\":47440,\"start\":47435},{\"end\":47745,\"start\":47739},{\"end\":47760,\"start\":47752},{\"end\":47774,\"start\":47768},{\"end\":47787,\"start\":47781},{\"end\":47805,\"start\":47798},{\"end\":47823,\"start\":47816},{\"end\":47836,\"start\":47829},{\"end\":47848,\"start\":47845},{\"end\":47860,\"start\":47856},{\"end\":47873,\"start\":47867},{\"end\":48508,\"start\":48506},{\"end\":48517,\"start\":48513},{\"end\":48692,\"start\":48688},{\"end\":48709,\"start\":48703},{\"end\":48718,\"start\":48714},{\"end\":48720,\"start\":48719},{\"end\":48947,\"start\":48942},{\"end\":48962,\"start\":48955},{\"end\":48976,\"start\":48971},{\"end\":48989,\"start\":48984},{\"end\":49003,\"start\":48999},{\"end\":49017,\"start\":49010},{\"end\":49035,\"start\":49024},{\"end\":49487,\"start\":49482},{\"end\":49503,\"start\":49494},{\"end\":49515,\"start\":49513},{\"end\":49526,\"start\":49521},{\"end\":49538,\"start\":49532},{\"end\":49553,\"start\":49547},{\"end\":49564,\"start\":49560},{\"end\":49584,\"start\":49577},{\"end\":50320,\"start\":50313},{\"end\":50336,\"start\":50329},{\"end\":52192,\"start\":52185},{\"end\":39891,\"start\":39887},{\"end\":39908,\"start\":39903},{\"end\":39923,\"start\":39916},{\"end\":39937,\"start\":39934},{\"end\":39951,\"start\":39946},{\"end\":40392,\"start\":40383},{\"end\":40409,\"start\":40403},{\"end\":40424,\"start\":40418},{\"end\":40441,\"start\":40435},{\"end\":40452,\"start\":40447},{\"end\":40470,\"start\":40465},{\"end\":40487,\"start\":40481},{\"end\":40520,\"start\":40507},{\"end\":40536,\"start\":40530},{\"end\":40549,\"start\":40544},{\"end\":41039,\"start\":41036},{\"end\":41055,\"start\":41047},{\"end\":41066,\"start\":41062},{\"end\":41081,\"start\":41074},{\"end\":41096,\"start\":41091},{\"end\":41098,\"start\":41097},{\"end\":41115,\"start\":41107},{\"end\":41132,\"start\":41126},{\"end\":41152,\"start\":41146},{\"end\":41166,\"start\":41160},{\"end\":41181,\"start\":41175},{\"end\":41477,\"start\":41468},{\"end\":41495,\"start\":41489},{\"end\":41509,\"start\":41504},{\"end\":41525,\"start\":41518},{\"end\":41539,\"start\":41533},{\"end\":41552,\"start\":41548},{\"end\":41566,\"start\":41562},{\"end\":41593,\"start\":41586},{\"end\":41610,\"start\":41601},{\"end\":42014,\"start\":42010},{\"end\":42028,\"start\":42022},{\"end\":42047,\"start\":42039},{\"end\":42063,\"start\":42058},{\"end\":42081,\"start\":42072},{\"end\":42101,\"start\":42090},{\"end\":42113,\"start\":42109},{\"end\":42452,\"start\":42447},{\"end\":42464,\"start\":42461},{\"end\":42478,\"start\":42471},{\"end\":42777,\"start\":42771},{\"end\":42793,\"start\":42789},{\"end\":42811,\"start\":42801},{\"end\":42826,\"start\":42821},{\"end\":43305,\"start\":43298},{\"end\":43321,\"start\":43317},{\"end\":43701,\"start\":43697},{\"end\":43718,\"start\":43711},{\"end\":43735,\"start\":43728},{\"end\":43752,\"start\":43745},{\"end\":44108,\"start\":44102},{\"end\":44117,\"start\":44115},{\"end\":44126,\"start\":44123},{\"end\":44140,\"start\":44132},{\"end\":44152,\"start\":44145},{\"end\":44487,\"start\":44482},{\"end\":44501,\"start\":44495},{\"end\":44517,\"start\":44508},{\"end\":44861,\"start\":44857},{\"end\":44876,\"start\":44870},{\"end\":44891,\"start\":44886},{\"end\":44903,\"start\":44899},{\"end\":44922,\"start\":44914},{\"end\":45237,\"start\":45232},{\"end\":45255,\"start\":45249},{\"end\":45258,\"start\":45256},{\"end\":45273,\"start\":45268},{\"end\":45284,\"start\":45280},{\"end\":45300,\"start\":45294},{\"end\":45331,\"start\":45325},{\"end\":45345,\"start\":45339},{\"end\":45357,\"start\":45351},{\"end\":45365,\"start\":45363},{\"end\":45794,\"start\":45788},{\"end\":45808,\"start\":45802},{\"end\":45822,\"start\":45817},{\"end\":46352,\"start\":46346},{\"end\":46366,\"start\":46362},{\"end\":46380,\"start\":46376},{\"end\":46394,\"start\":46389},{\"end\":46411,\"start\":46406},{\"end\":46424,\"start\":46419},{\"end\":46426,\"start\":46425},{\"end\":46440,\"start\":46434},{\"end\":46454,\"start\":46449},{\"end\":46738,\"start\":46733},{\"end\":46756,\"start\":46750},{\"end\":47007,\"start\":47001},{\"end\":47019,\"start\":47014},{\"end\":47029,\"start\":47025},{\"end\":47046,\"start\":47042},{\"end\":47053,\"start\":47051},{\"end\":47064,\"start\":47059},{\"end\":47367,\"start\":47362},{\"end\":47379,\"start\":47373},{\"end\":47390,\"start\":47386},{\"end\":47410,\"start\":47403},{\"end\":47420,\"start\":47418},{\"end\":47430,\"start\":47426},{\"end\":47440,\"start\":47435},{\"end\":47745,\"start\":47739},{\"end\":47760,\"start\":47752},{\"end\":47774,\"start\":47768},{\"end\":47787,\"start\":47781},{\"end\":47805,\"start\":47798},{\"end\":47823,\"start\":47816},{\"end\":47836,\"start\":47829},{\"end\":47848,\"start\":47845},{\"end\":47860,\"start\":47856},{\"end\":47873,\"start\":47867},{\"end\":48508,\"start\":48506},{\"end\":48517,\"start\":48513},{\"end\":48692,\"start\":48688},{\"end\":48709,\"start\":48703},{\"end\":48718,\"start\":48714},{\"end\":48720,\"start\":48719},{\"end\":48947,\"start\":48942},{\"end\":48962,\"start\":48955},{\"end\":48976,\"start\":48971},{\"end\":48989,\"start\":48984},{\"end\":49003,\"start\":48999},{\"end\":49017,\"start\":49010},{\"end\":49035,\"start\":49024},{\"end\":49487,\"start\":49482},{\"end\":49503,\"start\":49494},{\"end\":49515,\"start\":49513},{\"end\":49526,\"start\":49521},{\"end\":49538,\"start\":49532},{\"end\":49553,\"start\":49547},{\"end\":49564,\"start\":49560},{\"end\":49584,\"start\":49577},{\"end\":50320,\"start\":50313},{\"end\":50336,\"start\":50329},{\"end\":52192,\"start\":52185}]", "bib_author_last_name": "[{\"end\":39901,\"start\":39892},{\"end\":39914,\"start\":39909},{\"end\":39932,\"start\":39924},{\"end\":39944,\"start\":39938},{\"end\":39958,\"start\":39952},{\"end\":40401,\"start\":40393},{\"end\":40416,\"start\":40410},{\"end\":40433,\"start\":40425},{\"end\":40445,\"start\":40442},{\"end\":40463,\"start\":40453},{\"end\":40479,\"start\":40471},{\"end\":40505,\"start\":40488},{\"end\":40528,\"start\":40521},{\"end\":40542,\"start\":40537},{\"end\":40555,\"start\":40550},{\"end\":41045,\"start\":41040},{\"end\":41060,\"start\":41056},{\"end\":41072,\"start\":41067},{\"end\":41089,\"start\":41082},{\"end\":41105,\"start\":41099},{\"end\":41124,\"start\":41116},{\"end\":41144,\"start\":41133},{\"end\":41158,\"start\":41153},{\"end\":41173,\"start\":41167},{\"end\":41188,\"start\":41182},{\"end\":41487,\"start\":41478},{\"end\":41502,\"start\":41496},{\"end\":41516,\"start\":41510},{\"end\":41531,\"start\":41526},{\"end\":41546,\"start\":41540},{\"end\":41560,\"start\":41553},{\"end\":41573,\"start\":41567},{\"end\":41584,\"start\":41575},{\"end\":41599,\"start\":41594},{\"end\":41617,\"start\":41611},{\"end\":41627,\"start\":41619},{\"end\":42020,\"start\":42015},{\"end\":42037,\"start\":42029},{\"end\":42056,\"start\":42048},{\"end\":42070,\"start\":42064},{\"end\":42088,\"start\":42082},{\"end\":42107,\"start\":42102},{\"end\":42122,\"start\":42114},{\"end\":42459,\"start\":42453},{\"end\":42469,\"start\":42465},{\"end\":42481,\"start\":42479},{\"end\":42486,\"start\":42483},{\"end\":42787,\"start\":42778},{\"end\":42799,\"start\":42794},{\"end\":42819,\"start\":42812},{\"end\":42832,\"start\":42827},{\"end\":43315,\"start\":43306},{\"end\":43330,\"start\":43322},{\"end\":43709,\"start\":43702},{\"end\":43726,\"start\":43719},{\"end\":43743,\"start\":43736},{\"end\":43759,\"start\":43753},{\"end\":44113,\"start\":44109},{\"end\":44121,\"start\":44118},{\"end\":44130,\"start\":44127},{\"end\":44143,\"start\":44141},{\"end\":44156,\"start\":44153},{\"end\":44493,\"start\":44488},{\"end\":44506,\"start\":44502},{\"end\":44524,\"start\":44518},{\"end\":44868,\"start\":44862},{\"end\":44884,\"start\":44877},{\"end\":44897,\"start\":44892},{\"end\":44912,\"start\":44904},{\"end\":44929,\"start\":44923},{\"end\":45247,\"start\":45238},{\"end\":45266,\"start\":45259},{\"end\":45278,\"start\":45274},{\"end\":45292,\"start\":45285},{\"end\":45313,\"start\":45301},{\"end\":45323,\"start\":45315},{\"end\":45337,\"start\":45332},{\"end\":45349,\"start\":45346},{\"end\":45361,\"start\":45358},{\"end\":45371,\"start\":45366},{\"end\":45375,\"start\":45373},{\"end\":45800,\"start\":45795},{\"end\":45815,\"start\":45809},{\"end\":45828,\"start\":45823},{\"end\":46360,\"start\":46353},{\"end\":46374,\"start\":46367},{\"end\":46387,\"start\":46381},{\"end\":46404,\"start\":46395},{\"end\":46417,\"start\":46412},{\"end\":46432,\"start\":46427},{\"end\":46447,\"start\":46441},{\"end\":46465,\"start\":46455},{\"end\":46748,\"start\":46739},{\"end\":46765,\"start\":46757},{\"end\":47012,\"start\":47008},{\"end\":47023,\"start\":47020},{\"end\":47040,\"start\":47030},{\"end\":47049,\"start\":47047},{\"end\":47057,\"start\":47054},{\"end\":47069,\"start\":47065},{\"end\":47371,\"start\":47368},{\"end\":47384,\"start\":47380},{\"end\":47401,\"start\":47391},{\"end\":47416,\"start\":47411},{\"end\":47424,\"start\":47421},{\"end\":47433,\"start\":47431},{\"end\":47445,\"start\":47441},{\"end\":47750,\"start\":47746},{\"end\":47766,\"start\":47761},{\"end\":47779,\"start\":47775},{\"end\":47796,\"start\":47788},{\"end\":47814,\"start\":47806},{\"end\":47827,\"start\":47824},{\"end\":47843,\"start\":47837},{\"end\":47854,\"start\":47849},{\"end\":47865,\"start\":47861},{\"end\":47883,\"start\":47874},{\"end\":48511,\"start\":48509},{\"end\":48525,\"start\":48518},{\"end\":48701,\"start\":48693},{\"end\":48712,\"start\":48710},{\"end\":48728,\"start\":48721},{\"end\":48953,\"start\":48948},{\"end\":48969,\"start\":48963},{\"end\":48982,\"start\":48977},{\"end\":48997,\"start\":48990},{\"end\":49008,\"start\":49004},{\"end\":49022,\"start\":49018},{\"end\":49041,\"start\":49036},{\"end\":49492,\"start\":49488},{\"end\":49511,\"start\":49504},{\"end\":49519,\"start\":49516},{\"end\":49530,\"start\":49527},{\"end\":49545,\"start\":49539},{\"end\":49558,\"start\":49554},{\"end\":49575,\"start\":49565},{\"end\":49593,\"start\":49585},{\"end\":50327,\"start\":50321},{\"end\":39901,\"start\":39892},{\"end\":39914,\"start\":39909},{\"end\":39932,\"start\":39924},{\"end\":39944,\"start\":39938},{\"end\":39958,\"start\":39952},{\"end\":40401,\"start\":40393},{\"end\":40416,\"start\":40410},{\"end\":40433,\"start\":40425},{\"end\":40445,\"start\":40442},{\"end\":40463,\"start\":40453},{\"end\":40479,\"start\":40471},{\"end\":40505,\"start\":40488},{\"end\":40528,\"start\":40521},{\"end\":40542,\"start\":40537},{\"end\":40555,\"start\":40550},{\"end\":41045,\"start\":41040},{\"end\":41060,\"start\":41056},{\"end\":41072,\"start\":41067},{\"end\":41089,\"start\":41082},{\"end\":41105,\"start\":41099},{\"end\":41124,\"start\":41116},{\"end\":41144,\"start\":41133},{\"end\":41158,\"start\":41153},{\"end\":41173,\"start\":41167},{\"end\":41188,\"start\":41182},{\"end\":41487,\"start\":41478},{\"end\":41502,\"start\":41496},{\"end\":41516,\"start\":41510},{\"end\":41531,\"start\":41526},{\"end\":41546,\"start\":41540},{\"end\":41560,\"start\":41553},{\"end\":41573,\"start\":41567},{\"end\":41584,\"start\":41575},{\"end\":41599,\"start\":41594},{\"end\":41617,\"start\":41611},{\"end\":41627,\"start\":41619},{\"end\":42020,\"start\":42015},{\"end\":42037,\"start\":42029},{\"end\":42056,\"start\":42048},{\"end\":42070,\"start\":42064},{\"end\":42088,\"start\":42082},{\"end\":42107,\"start\":42102},{\"end\":42122,\"start\":42114},{\"end\":42459,\"start\":42453},{\"end\":42469,\"start\":42465},{\"end\":42481,\"start\":42479},{\"end\":42486,\"start\":42483},{\"end\":42787,\"start\":42778},{\"end\":42799,\"start\":42794},{\"end\":42819,\"start\":42812},{\"end\":42832,\"start\":42827},{\"end\":43315,\"start\":43306},{\"end\":43330,\"start\":43322},{\"end\":43709,\"start\":43702},{\"end\":43726,\"start\":43719},{\"end\":43743,\"start\":43736},{\"end\":43759,\"start\":43753},{\"end\":44113,\"start\":44109},{\"end\":44121,\"start\":44118},{\"end\":44130,\"start\":44127},{\"end\":44143,\"start\":44141},{\"end\":44156,\"start\":44153},{\"end\":44493,\"start\":44488},{\"end\":44506,\"start\":44502},{\"end\":44524,\"start\":44518},{\"end\":44868,\"start\":44862},{\"end\":44884,\"start\":44877},{\"end\":44897,\"start\":44892},{\"end\":44912,\"start\":44904},{\"end\":44929,\"start\":44923},{\"end\":45247,\"start\":45238},{\"end\":45266,\"start\":45259},{\"end\":45278,\"start\":45274},{\"end\":45292,\"start\":45285},{\"end\":45313,\"start\":45301},{\"end\":45323,\"start\":45315},{\"end\":45337,\"start\":45332},{\"end\":45349,\"start\":45346},{\"end\":45361,\"start\":45358},{\"end\":45371,\"start\":45366},{\"end\":45375,\"start\":45373},{\"end\":45800,\"start\":45795},{\"end\":45815,\"start\":45809},{\"end\":45828,\"start\":45823},{\"end\":46360,\"start\":46353},{\"end\":46374,\"start\":46367},{\"end\":46387,\"start\":46381},{\"end\":46404,\"start\":46395},{\"end\":46417,\"start\":46412},{\"end\":46432,\"start\":46427},{\"end\":46447,\"start\":46441},{\"end\":46465,\"start\":46455},{\"end\":46748,\"start\":46739},{\"end\":46765,\"start\":46757},{\"end\":47012,\"start\":47008},{\"end\":47023,\"start\":47020},{\"end\":47040,\"start\":47030},{\"end\":47049,\"start\":47047},{\"end\":47057,\"start\":47054},{\"end\":47069,\"start\":47065},{\"end\":47371,\"start\":47368},{\"end\":47384,\"start\":47380},{\"end\":47401,\"start\":47391},{\"end\":47416,\"start\":47411},{\"end\":47424,\"start\":47421},{\"end\":47433,\"start\":47431},{\"end\":47445,\"start\":47441},{\"end\":47750,\"start\":47746},{\"end\":47766,\"start\":47761},{\"end\":47779,\"start\":47775},{\"end\":47796,\"start\":47788},{\"end\":47814,\"start\":47806},{\"end\":47827,\"start\":47824},{\"end\":47843,\"start\":47837},{\"end\":47854,\"start\":47849},{\"end\":47865,\"start\":47861},{\"end\":47883,\"start\":47874},{\"end\":48511,\"start\":48509},{\"end\":48525,\"start\":48518},{\"end\":48701,\"start\":48693},{\"end\":48712,\"start\":48710},{\"end\":48728,\"start\":48721},{\"end\":48953,\"start\":48948},{\"end\":48969,\"start\":48963},{\"end\":48982,\"start\":48977},{\"end\":48997,\"start\":48990},{\"end\":49008,\"start\":49004},{\"end\":49022,\"start\":49018},{\"end\":49041,\"start\":49036},{\"end\":49492,\"start\":49488},{\"end\":49511,\"start\":49504},{\"end\":49519,\"start\":49516},{\"end\":49530,\"start\":49527},{\"end\":49545,\"start\":49539},{\"end\":49558,\"start\":49554},{\"end\":49575,\"start\":49565},{\"end\":49593,\"start\":49585},{\"end\":50327,\"start\":50321}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":207167677},\"end\":40381,\"start\":39803},{\"attributes\":{\"doi\":\"arXiv:2112.04426\",\"id\":\"b1\"},\"end\":40944,\"start\":40383},{\"attributes\":{\"id\":\"b2\"},\"end\":41466,\"start\":40946},{\"attributes\":{\"doi\":\"arXiv:2204.02311\",\"id\":\"b3\"},\"end\":41960,\"start\":41468},{\"attributes\":{\"doi\":\"arXiv:2110.14168\",\"id\":\"b4\"},\"end\":42362,\"start\":41962},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":204838007},\"end\":42708,\"start\":42364},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":11816014},\"end\":43240,\"start\":42710},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207178704},\"end\":43552,\"start\":43242},{\"attributes\":{\"doi\":\"arXiv:2203.13224\",\"id\":\"b8\"},\"end\":44032,\"start\":43554},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":215827489},\"end\":44415,\"start\":44034},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":15206880},\"end\":44761,\"start\":44417},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":219573621},\"end\":45230,\"start\":44763},{\"attributes\":{\"doi\":\"arXiv:2201.08239\",\"id\":\"b12\"},\"end\":45693,\"start\":45232},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":248780305},\"end\":46266,\"start\":45695},{\"attributes\":{\"id\":\"b14\"},\"end\":46685,\"start\":46268},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":14494942},\"end\":46927,\"start\":46687},{\"attributes\":{\"doi\":\"arXiv:2203.11171\",\"id\":\"b16\"},\"end\":47289,\"start\":46929},{\"attributes\":{\"doi\":\"arXiv:2201.11903\",\"id\":\"b17\"},\"end\":47677,\"start\":47291},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":208117506},\"end\":48437,\"start\":47679},{\"attributes\":{\"doi\":\"arXiv:2205.03401\",\"id\":\"b19\"},\"end\":48686,\"start\":48439},{\"attributes\":{\"doi\":\"arXiv:2203.14465\",\"id\":\"b20\"},\"end\":48938,\"start\":48688},{\"attributes\":{\"doi\":\"arXiv:2205.01068\",\"id\":\"b21\"},\"end\":49404,\"start\":48940},{\"attributes\":{\"doi\":\"arXiv:2205.10625\",\"id\":\"b22\"},\"end\":49900,\"start\":49406},{\"attributes\":{\"id\":\"b23\"},\"end\":51718,\"start\":49902},{\"attributes\":{\"doi\":\"1948-11-14 ) (age 70\",\"id\":\"b24\"},\"end\":54179,\"start\":51720},{\"attributes\":{\"id\":\"b25\"},\"end\":55280,\"start\":54181},{\"attributes\":{\"id\":\"b26\"},\"end\":56145,\"start\":55282},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":207167677},\"end\":40381,\"start\":39803},{\"attributes\":{\"doi\":\"arXiv:2112.04426\",\"id\":\"b1\"},\"end\":40944,\"start\":40383},{\"attributes\":{\"id\":\"b2\"},\"end\":41466,\"start\":40946},{\"attributes\":{\"doi\":\"arXiv:2204.02311\",\"id\":\"b3\"},\"end\":41960,\"start\":41468},{\"attributes\":{\"doi\":\"arXiv:2110.14168\",\"id\":\"b4\"},\"end\":42362,\"start\":41962},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":204838007},\"end\":42708,\"start\":42364},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":11816014},\"end\":43240,\"start\":42710},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207178704},\"end\":43552,\"start\":43242},{\"attributes\":{\"doi\":\"arXiv:2203.13224\",\"id\":\"b8\"},\"end\":44032,\"start\":43554},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":215827489},\"end\":44415,\"start\":44034},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":15206880},\"end\":44761,\"start\":44417},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":219573621},\"end\":45230,\"start\":44763},{\"attributes\":{\"doi\":\"arXiv:2201.08239\",\"id\":\"b12\"},\"end\":45693,\"start\":45232},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":248780305},\"end\":46266,\"start\":45695},{\"attributes\":{\"id\":\"b14\"},\"end\":46685,\"start\":46268},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":14494942},\"end\":46927,\"start\":46687},{\"attributes\":{\"doi\":\"arXiv:2203.11171\",\"id\":\"b16\"},\"end\":47289,\"start\":46929},{\"attributes\":{\"doi\":\"arXiv:2201.11903\",\"id\":\"b17\"},\"end\":47677,\"start\":47291},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":208117506},\"end\":48437,\"start\":47679},{\"attributes\":{\"doi\":\"arXiv:2205.03401\",\"id\":\"b19\"},\"end\":48686,\"start\":48439},{\"attributes\":{\"doi\":\"arXiv:2203.14465\",\"id\":\"b20\"},\"end\":48938,\"start\":48688},{\"attributes\":{\"doi\":\"arXiv:2205.01068\",\"id\":\"b21\"},\"end\":49404,\"start\":48940},{\"attributes\":{\"doi\":\"arXiv:2205.10625\",\"id\":\"b22\"},\"end\":49900,\"start\":49406},{\"attributes\":{\"id\":\"b23\"},\"end\":51718,\"start\":49902},{\"attributes\":{\"doi\":\"1948-11-14 ) (age 70\",\"id\":\"b24\"},\"end\":54179,\"start\":51720},{\"attributes\":{\"id\":\"b25\"},\"end\":55280,\"start\":54181},{\"attributes\":{\"id\":\"b26\"},\"end\":56145,\"start\":55282}]", "bib_title": "[{\"end\":39885,\"start\":39803},{\"end\":42445,\"start\":42364},{\"end\":42769,\"start\":42710},{\"end\":43296,\"start\":43242},{\"end\":44100,\"start\":44034},{\"end\":44480,\"start\":44417},{\"end\":44855,\"start\":44763},{\"end\":45786,\"start\":45695},{\"end\":46731,\"start\":46687},{\"end\":47737,\"start\":47679},{\"end\":52183,\"start\":51720},{\"end\":54490,\"start\":54181},{\"end\":55569,\"start\":55282},{\"end\":39885,\"start\":39803},{\"end\":42445,\"start\":42364},{\"end\":42769,\"start\":42710},{\"end\":43296,\"start\":43242},{\"end\":44100,\"start\":44034},{\"end\":44480,\"start\":44417},{\"end\":44855,\"start\":44763},{\"end\":45786,\"start\":45695},{\"end\":46731,\"start\":46687},{\"end\":47737,\"start\":47679},{\"end\":52183,\"start\":51720},{\"end\":54490,\"start\":54181},{\"end\":55569,\"start\":55282}]", "bib_author": "[{\"end\":39903,\"start\":39887},{\"end\":39916,\"start\":39903},{\"end\":39934,\"start\":39916},{\"end\":39946,\"start\":39934},{\"end\":39960,\"start\":39946},{\"end\":40403,\"start\":40383},{\"end\":40418,\"start\":40403},{\"end\":40435,\"start\":40418},{\"end\":40447,\"start\":40435},{\"end\":40465,\"start\":40447},{\"end\":40481,\"start\":40465},{\"end\":40507,\"start\":40481},{\"end\":40530,\"start\":40507},{\"end\":40544,\"start\":40530},{\"end\":40557,\"start\":40544},{\"end\":41047,\"start\":41036},{\"end\":41062,\"start\":41047},{\"end\":41074,\"start\":41062},{\"end\":41091,\"start\":41074},{\"end\":41107,\"start\":41091},{\"end\":41126,\"start\":41107},{\"end\":41146,\"start\":41126},{\"end\":41160,\"start\":41146},{\"end\":41175,\"start\":41160},{\"end\":41190,\"start\":41175},{\"end\":41489,\"start\":41468},{\"end\":41504,\"start\":41489},{\"end\":41518,\"start\":41504},{\"end\":41533,\"start\":41518},{\"end\":41548,\"start\":41533},{\"end\":41562,\"start\":41548},{\"end\":41575,\"start\":41562},{\"end\":41586,\"start\":41575},{\"end\":41601,\"start\":41586},{\"end\":41619,\"start\":41601},{\"end\":41629,\"start\":41619},{\"end\":42022,\"start\":42010},{\"end\":42039,\"start\":42022},{\"end\":42058,\"start\":42039},{\"end\":42072,\"start\":42058},{\"end\":42090,\"start\":42072},{\"end\":42109,\"start\":42090},{\"end\":42124,\"start\":42109},{\"end\":42461,\"start\":42447},{\"end\":42471,\"start\":42461},{\"end\":42483,\"start\":42471},{\"end\":42488,\"start\":42483},{\"end\":42789,\"start\":42771},{\"end\":42801,\"start\":42789},{\"end\":42821,\"start\":42801},{\"end\":42834,\"start\":42821},{\"end\":43317,\"start\":43298},{\"end\":43332,\"start\":43317},{\"end\":43711,\"start\":43697},{\"end\":43728,\"start\":43711},{\"end\":43745,\"start\":43728},{\"end\":43761,\"start\":43745},{\"end\":44115,\"start\":44102},{\"end\":44123,\"start\":44115},{\"end\":44132,\"start\":44123},{\"end\":44145,\"start\":44132},{\"end\":44158,\"start\":44145},{\"end\":44495,\"start\":44482},{\"end\":44508,\"start\":44495},{\"end\":44526,\"start\":44508},{\"end\":44870,\"start\":44857},{\"end\":44886,\"start\":44870},{\"end\":44899,\"start\":44886},{\"end\":44914,\"start\":44899},{\"end\":44931,\"start\":44914},{\"end\":45249,\"start\":45232},{\"end\":45268,\"start\":45249},{\"end\":45280,\"start\":45268},{\"end\":45294,\"start\":45280},{\"end\":45315,\"start\":45294},{\"end\":45325,\"start\":45315},{\"end\":45339,\"start\":45325},{\"end\":45351,\"start\":45339},{\"end\":45363,\"start\":45351},{\"end\":45373,\"start\":45363},{\"end\":45377,\"start\":45373},{\"end\":45802,\"start\":45788},{\"end\":45817,\"start\":45802},{\"end\":45830,\"start\":45817},{\"end\":46362,\"start\":46346},{\"end\":46376,\"start\":46362},{\"end\":46389,\"start\":46376},{\"end\":46406,\"start\":46389},{\"end\":46419,\"start\":46406},{\"end\":46434,\"start\":46419},{\"end\":46449,\"start\":46434},{\"end\":46467,\"start\":46449},{\"end\":46750,\"start\":46733},{\"end\":46767,\"start\":46750},{\"end\":47014,\"start\":47001},{\"end\":47025,\"start\":47014},{\"end\":47042,\"start\":47025},{\"end\":47051,\"start\":47042},{\"end\":47059,\"start\":47051},{\"end\":47071,\"start\":47059},{\"end\":47373,\"start\":47362},{\"end\":47386,\"start\":47373},{\"end\":47403,\"start\":47386},{\"end\":47418,\"start\":47403},{\"end\":47426,\"start\":47418},{\"end\":47435,\"start\":47426},{\"end\":47447,\"start\":47435},{\"end\":47752,\"start\":47739},{\"end\":47768,\"start\":47752},{\"end\":47781,\"start\":47768},{\"end\":47798,\"start\":47781},{\"end\":47816,\"start\":47798},{\"end\":47829,\"start\":47816},{\"end\":47845,\"start\":47829},{\"end\":47856,\"start\":47845},{\"end\":47867,\"start\":47856},{\"end\":47885,\"start\":47867},{\"end\":48513,\"start\":48506},{\"end\":48527,\"start\":48513},{\"end\":48703,\"start\":48688},{\"end\":48714,\"start\":48703},{\"end\":48730,\"start\":48714},{\"end\":48955,\"start\":48942},{\"end\":48971,\"start\":48955},{\"end\":48984,\"start\":48971},{\"end\":48999,\"start\":48984},{\"end\":49010,\"start\":48999},{\"end\":49024,\"start\":49010},{\"end\":49043,\"start\":49024},{\"end\":49494,\"start\":49482},{\"end\":49513,\"start\":49494},{\"end\":49521,\"start\":49513},{\"end\":49532,\"start\":49521},{\"end\":49547,\"start\":49532},{\"end\":49560,\"start\":49547},{\"end\":49577,\"start\":49560},{\"end\":49595,\"start\":49577},{\"end\":50329,\"start\":50313},{\"end\":50339,\"start\":50329},{\"end\":52195,\"start\":52185},{\"end\":39903,\"start\":39887},{\"end\":39916,\"start\":39903},{\"end\":39934,\"start\":39916},{\"end\":39946,\"start\":39934},{\"end\":39960,\"start\":39946},{\"end\":40403,\"start\":40383},{\"end\":40418,\"start\":40403},{\"end\":40435,\"start\":40418},{\"end\":40447,\"start\":40435},{\"end\":40465,\"start\":40447},{\"end\":40481,\"start\":40465},{\"end\":40507,\"start\":40481},{\"end\":40530,\"start\":40507},{\"end\":40544,\"start\":40530},{\"end\":40557,\"start\":40544},{\"end\":41047,\"start\":41036},{\"end\":41062,\"start\":41047},{\"end\":41074,\"start\":41062},{\"end\":41091,\"start\":41074},{\"end\":41107,\"start\":41091},{\"end\":41126,\"start\":41107},{\"end\":41146,\"start\":41126},{\"end\":41160,\"start\":41146},{\"end\":41175,\"start\":41160},{\"end\":41190,\"start\":41175},{\"end\":41489,\"start\":41468},{\"end\":41504,\"start\":41489},{\"end\":41518,\"start\":41504},{\"end\":41533,\"start\":41518},{\"end\":41548,\"start\":41533},{\"end\":41562,\"start\":41548},{\"end\":41575,\"start\":41562},{\"end\":41586,\"start\":41575},{\"end\":41601,\"start\":41586},{\"end\":41619,\"start\":41601},{\"end\":41629,\"start\":41619},{\"end\":42022,\"start\":42010},{\"end\":42039,\"start\":42022},{\"end\":42058,\"start\":42039},{\"end\":42072,\"start\":42058},{\"end\":42090,\"start\":42072},{\"end\":42109,\"start\":42090},{\"end\":42124,\"start\":42109},{\"end\":42461,\"start\":42447},{\"end\":42471,\"start\":42461},{\"end\":42483,\"start\":42471},{\"end\":42488,\"start\":42483},{\"end\":42789,\"start\":42771},{\"end\":42801,\"start\":42789},{\"end\":42821,\"start\":42801},{\"end\":42834,\"start\":42821},{\"end\":43317,\"start\":43298},{\"end\":43332,\"start\":43317},{\"end\":43711,\"start\":43697},{\"end\":43728,\"start\":43711},{\"end\":43745,\"start\":43728},{\"end\":43761,\"start\":43745},{\"end\":44115,\"start\":44102},{\"end\":44123,\"start\":44115},{\"end\":44132,\"start\":44123},{\"end\":44145,\"start\":44132},{\"end\":44158,\"start\":44145},{\"end\":44495,\"start\":44482},{\"end\":44508,\"start\":44495},{\"end\":44526,\"start\":44508},{\"end\":44870,\"start\":44857},{\"end\":44886,\"start\":44870},{\"end\":44899,\"start\":44886},{\"end\":44914,\"start\":44899},{\"end\":44931,\"start\":44914},{\"end\":45249,\"start\":45232},{\"end\":45268,\"start\":45249},{\"end\":45280,\"start\":45268},{\"end\":45294,\"start\":45280},{\"end\":45315,\"start\":45294},{\"end\":45325,\"start\":45315},{\"end\":45339,\"start\":45325},{\"end\":45351,\"start\":45339},{\"end\":45363,\"start\":45351},{\"end\":45373,\"start\":45363},{\"end\":45377,\"start\":45373},{\"end\":45802,\"start\":45788},{\"end\":45817,\"start\":45802},{\"end\":45830,\"start\":45817},{\"end\":46362,\"start\":46346},{\"end\":46376,\"start\":46362},{\"end\":46389,\"start\":46376},{\"end\":46406,\"start\":46389},{\"end\":46419,\"start\":46406},{\"end\":46434,\"start\":46419},{\"end\":46449,\"start\":46434},{\"end\":46467,\"start\":46449},{\"end\":46750,\"start\":46733},{\"end\":46767,\"start\":46750},{\"end\":47014,\"start\":47001},{\"end\":47025,\"start\":47014},{\"end\":47042,\"start\":47025},{\"end\":47051,\"start\":47042},{\"end\":47059,\"start\":47051},{\"end\":47071,\"start\":47059},{\"end\":47373,\"start\":47362},{\"end\":47386,\"start\":47373},{\"end\":47403,\"start\":47386},{\"end\":47418,\"start\":47403},{\"end\":47426,\"start\":47418},{\"end\":47435,\"start\":47426},{\"end\":47447,\"start\":47435},{\"end\":47752,\"start\":47739},{\"end\":47768,\"start\":47752},{\"end\":47781,\"start\":47768},{\"end\":47798,\"start\":47781},{\"end\":47816,\"start\":47798},{\"end\":47829,\"start\":47816},{\"end\":47845,\"start\":47829},{\"end\":47856,\"start\":47845},{\"end\":47867,\"start\":47856},{\"end\":47885,\"start\":47867},{\"end\":48513,\"start\":48506},{\"end\":48527,\"start\":48513},{\"end\":48703,\"start\":48688},{\"end\":48714,\"start\":48703},{\"end\":48730,\"start\":48714},{\"end\":48955,\"start\":48942},{\"end\":48971,\"start\":48955},{\"end\":48984,\"start\":48971},{\"end\":48999,\"start\":48984},{\"end\":49010,\"start\":48999},{\"end\":49024,\"start\":49010},{\"end\":49043,\"start\":49024},{\"end\":49494,\"start\":49482},{\"end\":49513,\"start\":49494},{\"end\":49521,\"start\":49513},{\"end\":49532,\"start\":49521},{\"end\":49547,\"start\":49532},{\"end\":49560,\"start\":49547},{\"end\":49577,\"start\":49560},{\"end\":49595,\"start\":49577},{\"end\":50329,\"start\":50313},{\"end\":50339,\"start\":50329},{\"end\":52195,\"start\":52185}]", "bib_venue": "[{\"end\":40041,\"start\":39960},{\"end\":40637,\"start\":40573},{\"end\":41034,\"start\":40946},{\"end\":41690,\"start\":41645},{\"end\":42008,\"start\":41962},{\"end\":42524,\"start\":42488},{\"end\":42920,\"start\":42834},{\"end\":43380,\"start\":43332},{\"end\":43695,\"start\":43554},{\"end\":44207,\"start\":44158},{\"end\":44581,\"start\":44526},{\"end\":44980,\"start\":44931},{\"end\":45439,\"start\":45393},{\"end\":45918,\"start\":45830},{\"end\":46344,\"start\":46268},{\"end\":46792,\"start\":46767},{\"end\":46999,\"start\":46929},{\"end\":47360,\"start\":47291},{\"end\":47994,\"start\":47885},{\"end\":48504,\"start\":48439},{\"end\":48790,\"start\":48746},{\"end\":49480,\"start\":49406},{\"end\":50311,\"start\":49902},{\"end\":52341,\"start\":52215},{\"end\":54593,\"start\":54492},{\"end\":55613,\"start\":55571},{\"end\":40041,\"start\":39960},{\"end\":40637,\"start\":40573},{\"end\":41034,\"start\":40946},{\"end\":41690,\"start\":41645},{\"end\":42008,\"start\":41962},{\"end\":42524,\"start\":42488},{\"end\":42920,\"start\":42834},{\"end\":43380,\"start\":43332},{\"end\":43695,\"start\":43554},{\"end\":44207,\"start\":44158},{\"end\":44581,\"start\":44526},{\"end\":44980,\"start\":44931},{\"end\":45439,\"start\":45393},{\"end\":45918,\"start\":45830},{\"end\":46344,\"start\":46268},{\"end\":46792,\"start\":46767},{\"end\":46999,\"start\":46929},{\"end\":47360,\"start\":47291},{\"end\":47994,\"start\":47885},{\"end\":48504,\"start\":48439},{\"end\":48790,\"start\":48746},{\"end\":49480,\"start\":49406},{\"end\":50311,\"start\":49902},{\"end\":52341,\"start\":52215},{\"end\":54593,\"start\":54492},{\"end\":55613,\"start\":55571},{\"end\":40109,\"start\":40043},{\"end\":42993,\"start\":42922},{\"end\":48090,\"start\":47996},{\"end\":52403,\"start\":52343},{\"end\":55643,\"start\":55615},{\"end\":40109,\"start\":40043},{\"end\":42993,\"start\":42922},{\"end\":48090,\"start\":47996},{\"end\":52403,\"start\":52343},{\"end\":55643,\"start\":55615}]"}}}, "year": 2023, "month": 12, "day": 17}