{"id": 231851007, "updated": "2022-09-28 13:28:23.932", "metadata": {"title": "VeriFL: Communication-Efficient and Fast Verifiable Aggregation for Federated Learning", "authors": "[{\"first\":\"Xiaojie\",\"last\":\"Guo\",\"middle\":[]},{\"first\":\"Zheli\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Jin\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Jiqiang\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Boyu\",\"last\":\"Hou\",\"middle\":[]},{\"first\":\"Changyu\",\"last\":\"Dong\",\"middle\":[]},{\"first\":\"Thar\",\"last\":\"Baker\",\"middle\":[]}]", "venue": "IEEE Transactions on Information Forensics and Security", "journal": "IEEE Transactions on Information Forensics and Security", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Federated learning (FL) enables a large number of clients to collaboratively train a global model through sharing their gradients in each synchronized epoch of local training. However, a centralized server used to aggregate these gradients can be compromised and forge the result in order to violate privacy or launch other attacks, which incurs the need to verify the integrity of aggregation. In this work, we explore how to design communication-efficient and fast verifiable aggregation in FL. We propose V<sc>eri</sc>FL, a verifiable aggregation protocol, with <inline-formula> <tex-math notation=\"LaTeX\">$O(N)$ </tex-math></inline-formula> (dimension-independent) communication and <inline-formula> <tex-math notation=\"LaTeX\">$O(N+ d)$ </tex-math></inline-formula> computation for verification in each epoch, where <inline-formula> <tex-math notation=\"LaTeX\">$N$ </tex-math></inline-formula> is the number of clients and <inline-formula> <tex-math notation=\"LaTeX\">$d$ </tex-math></inline-formula> is the dimension of gradient vectors. Since <inline-formula> <tex-math notation=\"LaTeX\">$d$ </tex-math></inline-formula> can be large in some real-world FL applications (e.g., 100K), our dimension-independent communication is especially desirable for clients with limited bandwidth and high-dimensional gradients. In addition, the proposed protocol can be used in the FL setting where secure aggregation is needed or there is a subset of clients dropping out of protocol execution. Experimental results indicate that our protocol is efficient in these settings.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/iacr/Guo22", "doi": "10.1109/tifs.2020.3043139"}}, "content": {"source": {"pdf_hash": "3681d0a2d46f85b9dcd44330614dd7d413984bbc", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://eprint.ncl.ac.uk/fulltext.aspx?pub_id=271955&url=271955/154EC5E7-AC25-4382-803D-B9CFE26D2A8D.pdf", "status": "GREEN"}}, "grobid": {"id": "6df5b6f74cadc8b3759fc7f7b8c80cb0b7c3f95d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3681d0a2d46f85b9dcd44330614dd7d413984bbc.txt", "contents": "\nVERIFL: Communication-Efficient and Fast Verifiable Aggregation for Federated Learning\n\n\nXiaojie Guo \nZheli Liu \nSenior Member, IEEEJin Li \nJiqiang Gao \nBoyu Hou \nChangyu Dong \nMember, IEEEThar Baker \nVERIFL: Communication-Efficient and Fast Verifiable Aggregation for Federated Learning\n\nIEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY\n16202110.1109/TIFS.2020.30431391736Index Terms-Federated learningverifiable aggregationlinearly homomorphic hashcommitmentmachine learning\nFederated learning (FL) enables a large number of clients to collaboratively train a global model through sharing their gradients in each synchronized epoch of local training. However, a centralized server used to aggregate these gradients can be compromised and forge the result in order to violate privacy or launch other attacks, which incurs the need to verify the integrity of aggregation. In this work, we explore how to design communication-efficient and fast verifiable aggregation in FL. We propose VERIFL, a verifiable aggregation protocol, withO(N) (dimension-independent) communication and O(N + d) computation for verification in each epoch, where N is the number of clients and d is the dimension of gradient vectors.Since d can be large in some real-world FL applications (e.g., 100K), our dimension-independent communication is especially desirable for clients with limited bandwidth and high-dimensional gradients. In addition, the proposed protocol can be used in the FL setting where secure aggregation is needed or there is a subset of clients dropping out of protocol execution. Experimental results indicate that our protocol is efficient in these settings.\n\nepoch (Figure 1(a)). To update the global model, a centralized server is adopted to aggregate the parameters received from these users and sends back the updated global model to them. All users will update their local model according to the global one and such training process will continue until model convergence.\n\nDespite of its appealing functionality, FL has been shown vulnerable to some attacks. For example, the works [4]- [6] show that the gradient vector uploaded by a client may leak sensitive information about its private dataset. To address this issue, in [7], the authors proposed a secure aggregation protocol that guarantees the privacy of gradients. However, the recent work [8] shows that, in addition to the gradient privacy, the integrity of aggregation should be protected as well. In particular, the server can easily become a single-point of failure in FL. Without integrity guarantee, once the server gets compromised, the adversary controlling the server can manipulate the global model and cause misclassification of any involved client at its specified data point (Figure 1(b)), which is similar to the consequence of backdoor attacks [9]- [12]. The lack of the integrity guarantee of aggregation may restrict the commercial application of FL. An example attack is that the corrupted server re-trains the global model updated in this epoch with some poisoned data and returns the re-trained model to honest clients, aiming to cause misclassification in these clients.\n\nWe note that attacks by modifying aggregation results (e.g., the aforementioned example attack) can be mitigated using verifiable aggregation protocols. In such protocols for FL, a considered adversary cannot convince an honest client to accept its forged aggregated gradient as a real one with 1556-6021 \u00a9 2020 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.\n\nSee https://www.ieee.org/publications/rights/index.html for more information.\n\nan overwhelming probability (see Definition 3). Certainly, to resist inference attacks exploiting the \"non-encrypted\" gradients [4]- [6], the used verifiable aggregation protocol should be secure as well to guarantee input privacy of each client. Informally speaking, this means that an adversary in the aggregation protocol learns nothing about the gradient of each client from protocol transcripts (see Definition 4).\n\nIn this paper, we focus on how to realize a (secure) verifiable aggregation protocol in a communication-efficient and fast way on resource-constrained devices (e.g., the setting of mobile devices in Google's work [7]). Since the bandwidth in the resource-constrained setting is expensive and a large number of clients are required to train a global model through hundreds of iterations, communication becomes one of the most important considerations in the design of FL protocol. If the designed verifiable aggregation protocol costs a lot in terms of communication and computation, it will take a long period to finish the training process. There are many factors influencing the communication efficiency of a verifiable aggregation protocol, and the number of parameters in the model to be trained is particularly important. So, our first question is, can we design a verifiable aggregation protocol in which the communication of verification is independent of the number of parameters in the model to be trained? In fact, the communication efficiency of FL is always a research hotspot [1], [2], [7], [13].\n\nTo the best of our knowledge, there is no previous work that succeeds in designing a communicationefficient verifiable aggregation protocol. The works about communication-efficient FL [7], [13] do not consider how to guarantee the integrity of aggregation. The recent work that achieves the first secure verifiable aggregation [8] uses zero-knowledge proof to enforce honest aggregation. However, its communication cost for verification is linearly dependent on the dimension of gradient vectors. Its linearly-growing and high communication cost makes it impractical in its intended application scenarios, that is FL among mobile devices. Moreover, its computation cost for verification is unsatisfactory due to the use of zero-knowledge. For example, it takes 3.59 MB outgoing communication and 254964 ms computation per client to verify the aggregation of 20Kdimensional parameter vectors among 500 clients. Another trivial solution to achieve verifiable aggregation is using generic multiparty computation (MPC) approaches [14]- [21], but its communication and computational overhead are very large. So, in addition to communication efficiency, our second question is, how to make our verifiable aggregation protocol computation-efficient?\n\nA. Challenge and Contribution 1) Challenge: To verify the integrity of aggregation, a straightforward idea is to use homomorphic hash to compute the \"digest\" of gradient vectors to be aggregated. A combined hash can be obtained from these hash values after aggregation, and each client compares it with the hash of the aggregation result (i.e., real hash) to verify the aggregation. Although this idea yields a desirable feature that the verification communication is independent of gradient dimension, we would like to show that this idea provides little security guarantee.\n\nThe security challenge comes from the fact that everyone in the above construction has access to the homomorphic hash function. In the simulation-based proof, the simulator did not know the input (i.e., the gradient vector) of each honest client by the time it was asked to simulate its hash value. To simulate it, the simulator has to use a dummy vector. However, this dummy value is different from the real one with an overwhelming probability. Since everyone (including the adversary) can call the homomorphic hash function with the aggregation result, an inconsistency between the combined and real hashes will be found after aggregation and this immediately yields an efficient distinguisher that fails the simulation. That is, the straightforward construction is not secure.\n\nIn [8], the authors solve this security challenge by combining homomorphic hash with zero-knowledge proof. However, due to the dimension-wise zero-knowledge proofs, their protocol leads to expensive computation and the communication caused by verification is still linear in the gradient dimension. We note that such dimension-dependence is depressing since the gradient dimension is large in real-world FL applications (e.g., 100K). We are motivated to find another way to achieve verifiable aggregation, overcoming the security challenge with good concrete efficiency in terms of communication and computation.\n\n2) Contribution: In this paper, we present a communication-efficient and fast protocol, VERIFL, for verifiable aggregation in FL. As shown by experiment, for example, VERIFL achieves 33.24 KB (dimensionindependent) outgoing communication and 8899 ms computation per client to verify the aggregation of 100K-dimensional parameter vectors among 500 clients, which outperforms the state-of-the-art work [8] by 110.6\u00d7 in communication and 28.7\u00d7 in computation even with 5\u00d7 larger parameter vectors. More specifically, we make the following contributions:\n\n\u2022 (Secure) verifiable aggregation. To verify the integrity of aggregation, we combine the linearly homomorphic hash with the commitment scheme to force the aggregation server to use the submitted gradients that are consistent with their previously broadcast hashes. Collision resistance of the hash scheme guarantees that the server cannot have an honest client accept its forged result.\n\nIn addition, to overcome the aforementioned security issue, we observe that it sufficient to use equivocal commitment scheme to achieve the same security as [8] without using heavy zero-knowledge proof. Based on this observation, we develop a novel verifiable aggregation protocol. Notably, secure aggregation is also considered in our protocol and we show our protocol is composable with the secure protocol in [7] by using double-masking technique and adding extra rounds. The functionality of secure aggregation in our protocol is achieved in the sense that only the aggregation result computed by the server is revealed.\n\n\u2022 Dimension-independent communication overhead. In our protocol, the communication overhead resulted from integrity verification is independent of the dimension of gradient vectors (i.e., the number of parameters in FL models), which significantly saves the bandwidth of clients. This is achieved by asking each client to commit only the hash of its gradient vector instead of the vector itself. These commitment strings, which facilitate our security proof, have a length independent of the gradient dimension. The linear homomorphism of the hash scheme ensures that the \"sum\" of hashes equals to the hash of the sum vector. It is helpful to think that linearly homomorphic hash can be used to compress high-dimensional gradient vectors while preserves the properties of addition. \u2022 Approximately-halved computation overhead. We succeed in reducing the verification cost of our basic construction in terms of computation by using amortized verification. In our protocol, the most time-consuming operation is the two calls of linearly homomorphic hash that requires O(d) expensive modular exponentiations, in which d is the dimension of gradient vectors. The former call is used to generate the necessary messages for future verification and is inevitable. However, the latter call that performs the integrity verification can be amortized. First, we draw a set of random coefficients to compute the linear combination of the hash aggregations in different epochs. Then, we check whether the combined hash is equal to the hash of the linear combination (using the same coefficients) of aggregation results in different epochs.\n\nIn this way, we only performs the integrity verification once a batch and the cost of the latter call is amortized by a factor of the batch size. The total computation overhead can be approximately reduced to that of the former hash call.\n\n\nII. FEDERATED LEARNING WITH SECURE AGGREGATION\n\n\nA. Federated Learning\n\nThe basic framework of FL is summarized as follows. There are N users in FL, each having access to its private dataset D i where |D i | = s i . At the beginning of each epoch k \u2208 {1, 2, . . .}, the aggregation server will randomly select a subset of users S k and send them the parameter vector v k \u22121 obtained in the previous epoch (note that v 0 is initialized randomly). Each selected user P i will locally minimize the empirical loss over its dataset D i to get its updated (local) model v i k and upload its gradient i k \u2190 v i k \u2212v i k \u22121 to the aggregation server. Upon receiving enough gradients from the users, typically, the server will take a weighted average of these gradients and obtain an updated global model, i.e., v k \u2190 v k\u22121 + i\u2208S k \u03b2 i i k where \u03b2 i = s i / i\u2208S k s i . The training process will continue until model convergence.\n\n\nB. Secure Aggregation\n\nIn [7], the authors build up a secure and dropout-tolerant aggregation protocol based on double-masking technique. More specifically, the double-masking of a gradient vector v i Fig. 2. The semi-honest version protocol in [7]. includes two parts: the self-mask generated by the owner P i itself, and the pairwise-mask generated between P i and each other client. The double-masked gradient of v i is denoted by p i :\np i = v i + PRG(b i ) self\u2212mask + j \u2208U ,i < j PRG(mak i, j ) \u2212 j \u2208U ,i > j PRG(mak i, j ) pairwise\u2212mask mod B\nwhere B is the modulus for aggregation, b i is a secret seed sampled by the P i and mak i, j = mak j,i is a pairwise agreed value between P i and P j for each P j \u2208 U. Rounds of their protocol are briefly summarized in Figure 2.\n\n\nC. Adversarial Model\n\nIn this paper, we consider the same adversary as in [8]. The adversary is semi-honest but with the additional power to instruct the corrupted server to forge the aggregation result arbitrarily with the knowledge of the transcripts it has seen before. The adversary can corrupt both the aggregation server and a subset of data parties (i.e., clients). In this semi-honest model, the corrupted parties will provide their gradients honestly. Using the notations to be introduced in the next section, all gradient vectors of parties belong to Z d R and the aggregation result should lie in Z d B for some bound B \u2265 N \u00b7 R, in which N is the number of parties.\n\nIn this adversarial model, the adversary may aim either (i) to infer the private gradients of honest parties, or (ii) to convince honest parties of its forged aggregation results. The goal of our protocol is to protect the privacy of each party's gradient while guarantees the integrity of aggregation. However, we do not consider the adversary that makes queries to the trained model to launch black-box statistical attacks [22]- [26] since it is known hard to prevent the leakage from the output of the functionality implemented by cryptographic protocols. Moreover, such attacks might not work well to precisely infer the sensitive information of honest parties, especially for deep neural networks that generalize well [6].\n\nNote that, in FL, the private inputs of honest parties in the previous round may be approximate to the those in the current round when the model converges. To forge an approximate aggregation result, it suffices for the adversary to choose the inputs of corrupted parties according to the partial sum of the inputs of honest parties in the previous round. This observation can lead to a model replacement attack in [9], which bypasses secure aggregation protocols and is possible since some small perturbations will not significantly affect the behaviour of machine learning models. How to prevent such an attack in FL settings is another interesting and open problem, which is out of the scope of this paper. In this paper, like other works in the literature of multiparty computation, we only focus on how to prevent the adversary from forging an aggregation result different from the exact one. We do not consider the attacks (e.g., model replacement attack) where the adversary chooses its input according to the past protocol transcripts. This is known challenging in multiparty computation since it cannot be distinguished from the case where a corrupted party do use this as its input without some apriori knowledge of input.\n\n\nIII. VERIFL: EFFICIENT VERIFIABLE AGGREGATION\n\n\nA. Notations\n\nWe use [n] to denote the set {1, . . . , n} for some integer n. The set of integers is denoted by Z. The quotient ring of integers modulo a positive integer q is written in Z q . When q is a prime, Z q is a field denoted by F q . A vector is denoted by a bold lower case letter, e.g., x, and its i -th entry is denoted by x[i ] where the index i is counted from one. For some finite set X , its cardinality is |X |. If A is an algorithm, a \u2190 A says that a is assigned to be the output of A; otherwise, if A is a set, a is an element uniformly drawn from the set A. The security parameter is denoted \u03ba and we use negl(\u03ba) to denote the negligible function in \u03ba. We use A(x; y) to denote that an algorithm A is invoked with a public input x and a secret input y. We formulate pseudo-random generator as PRG : {0, 1} * \u2192 Z d B for some modulus B and vector dimension d.\n\nB. Cryptographic Primitives 1) Linear Homomorphic Hash: A linearly homomorphic hash scheme consists of three polynomial-time algorithms, i.e., LHH = (LHH.HGen, LHH.Hash, LHH.Eval). We detail the above three algorithms as constructed in [27] by assuming the hardness of discrete logarithm.\n\n\u2022 LHH.HGen(1 \u03ba , 1 d ): On input the security parameter \u03ba and the dimension d, this algorithm outputs the public parameter LHHpp, including the description of a cyclic group G of prime order q, its generator g \u2208 G and d distinct elements g 1 , . . . , g d \u2208 G. For simplicity of presentation, this public parameter will be taken implicitly as the first parameter of LHH.Hash and LHH.Eval. \u2022 LHH.Hash(x): Taking a d-dimensional vector x as input, this algorithm outputs the linearly homomorphic hash of Taking hashes and coefficients of linear combination, this algorithm outputs the linear combination of these hashes:\nx: h \u2190 i\u2208[d] g x[i] i \u2208 G. \u2022 LHH.Eval(h 1 , . . . , h , \u03b1 1 , . . . , \u03b1 ):h * \u2190 i\u2208[ ] h \u03b1 i i .\nNote that this construction of LHH satisfies the following definition of collision resistance with respect to the collision experiment Expt coll\nA,LHH . Expt coll A,LHH (1 \u03ba , 1 d ): 1) Call LHHpp \u2190 LHH.HGen(1 \u03ba , 1 d ).\n2) Send LHHpp to the adversary and wait for its\ninput (x 1 , x 2 ) \u2190 A(LHHpp) where x 1 , x 2 \u2208 F d q are two distinct vectors. 3) Output 1 iff LHH.Hash(x 1 ) = LHH.\nHash(x 2 ); otherwise output 0.\n\n\nDefinition 1 (Collision Resistance): LHH is said to be collision-resistant, if for any PPT adversary A, there exists a negligible function negl(\u00b7) such that the advantage of\nA Adv coll A,LHH (\u03ba) := Pr Expt coll A,LHH (1 \u03ba , 1 d ) = 1 \u2264 negl(\u03ba)\nfor the security parameter \u03ba and the vector dimension d.\n\n2) Commitment: Commitment is an \"envelope\" so that a party cannot change the value after they have committed to it while the committed value is kept secret to others before decommitment. The commitment scheme used in this paper is to make the security go through without leading to too much communication overhead for verification. In particular, to formally prove the security of our protocol, we need an equivocal commitment scheme. Roughly speaking, someone possessing the trapdoor of an equivocal commitment scheme can produce commitments that can be opened to different values. However, committers in real world, who have no idea about the trapdoor, can open them to only a single value. Such property enables the simulator in our proof to fool the distinguisher and achieves indistinguishability consequently (see Section IV).\n\nA non-interactive equivocal commitment scheme is defined as a tuple of four polynomial-time algorithms COM = (COM.Setup, COM.Commit, COM.Decommit, COM.Equiv):\n\n\u2022 COM.Setup(1 \u03ba ): On input the security parameter \u03ba, this algorithm outputs a public parameter COMpp and a trapdoor td. Note that the message space M and the commitment space C are also provided in COMpp.\n\nFor simplicity of presentation, this public parameter will be taken implicitly as the first parameter of the other algorithms. \u2022 COM.Commit(m; r ): This algorithm is run by the committer and takes as input a message to be committed m \u2208 M and a uniform randomness r and outputs a commitment string c \u2208 C, which is to be publicly published. Note that the randomness r serves as the \"decommitment string\" to open the committed message and it should be kept secret until opening. \u2022 COM.Decommit(c, m , r ): This algorithm is run by the receiver and takes as input a commitment string c \u2208 C, a claimed committed message m \u2208 M and the claimed randomness r that was used to commit m . If c = COM.Commit(m ; r ) then output 1; otherwise output 0. \u2022 COM.Equiv(c, (m, r ), m ; td): This algorithm takes as input a commitment string c \u2190 COM.Commit(m; r ) \u2208 C, a desired arbitrary message m \u2208 M and the trapdoor td and outputs an valid randomness r such that c decommits to m . The equivocality of COM is formally defined as follows.\n\nDefinition 2 (Equivocality): COM is said to be equivocal if for any m \u2208 M and uniform randomness r , it holds that there exists a negligible function negl(\u00b7) such that\nPr \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 (COMpp, td) \u2190 COM.Setup(1 \u03ba ), c \u2190 COM.Commit(m; r ), b = 0 m \u2190 M, r \u2190 COM.Equiv(c, (m, r ), m ; td), b \u2190 COM.Decommit(c, m , r ) \u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6 \u2264 negl(\u03ba)\nfor the security parameter \u03ba.\n\n3) Symmetric Encryption: An symmetric encryption scheme is defined to be a tuple SE = (SE.KeyGen, SE.Enc, SE.Dec). to be decrypted and its corresponding symmetric key k . The output of this algorithm is the message m such that c \u2190 SE.Enc(m ; k ). In this paper, we require SE to be IND-CPA secure.\n\n\n4) Key Agreement:\n\nWe use a key agreement scheme to (i) generate pairwise symmetric encryption keys, and (ii) generate pariwise seeds for PRG.\n\nA key agreement scheme is defined to be a tuple KA = (KA.Setup, KA.KeyGen, KA.Agree).\n\n\u2022 KA.Setup(1 \u03ba ): On input the security parameter \u03ba, this algorithm outputs a public parameter KApp. For simplicity of presentation, this public parameter will be taken implicitly as the first parameter of the other algorithms. \u2022 KA.KeyGen(): This algorithm generates a key pair (sk, pk). \u2022 KA.Agree(sk i , pk j ): This algorithm takes as input a secret key sk i and a public key pk j and outputs a private agreed key ak i, j .\n\n\n5) Secret Sharing:\n\nWe use secret sharing to deal with dropout in our protocol and preserve input privacy. A secret sharing scheme is defined to be a tuple SS = (SS.Setup, SS.Share, SS.Combine).\n\n\u2022 SS.Setup(1 \u03ba ): On input the security parameter \u03ba, this algorithm outputs a public parameter SSpp, which includes the message space M. For simplicity of presentation, this public parameter will be taken implicitly as the first parameter of the other algorithms. \u2022 SS.Share(t, P, s): This algorithms takes as input the threshold value t, the set of parties P which is of size N \u2265 t and a secret s \u2208 M. The output of this algorithm is a set of secret shares, denoted by 1) Basic Verifiable Aggregation: The integrity of aggregation is achieved by adding the following two steps to the basic FL framework:\n{[[s]] i } P i \u2208P , each of which is assigned to a distinct holder P i \u2208 P. \u2022 SS.Combine(t, {[[s]] i } P i \u2208P\nPREPARATION: This step is done by clients before they submit their gradient vectors to the server. In this step, each client is asked to generate: (i) the linearly homomorphic hash of its gradient vector, and (ii) the commitment string of this hash value. More formally, P i generates\nh i \u2190 LHH.Hash(v i ), c i \u2190 COM.Commit(h i ; r i ),\nin which h i is the linearly homomorphic hash of v i , c i is the commitment string and r i is a uniformly random string secretly sampled by P i . Note that (h i , r i ) serves as the decommitment string of P i . Note that, after this step, the commitment string c i will be forwarded to other clients. P i will not send its gradient vector to the server until it receives from all other clients their c i 's respectively.\n\nVERIFICATION: This step is done by each client after it receives from the server the aggregation result a. In this step, P i asks each other client P j for its decommitment string (h j , r j ) and checks whether \n1 ? = COM.Decommit(c j , h j , r j ),(1)). (2)\nIf the equality test (2) holds, then the aggregation result a passes the verification and P i will accept the result; otherwise the result will be regarded as forged and P i terminates with output \u22a5.\n\n\n2) Dimension-Independent Communication Overhead:\n\nThe reduction in the communication overhead for verification comes from the usage of hash and commitment. Recall that the outgoing message for verification sent by each client P i in each epoch consists of the commitment string c i and the decommitment string (h i , r i ). As long as we carefully instantiate COM with the one using commitment/decommitment strings of constant length, the outgoing communication for verification is constant and independent of the the dimension of gradient vectors. That is, in each epoch, the outgoing communication cost lead by verification can be made only O(1) and the incoming communication cost is O(N).\n\n3) Approximately-Halved Computation Overhead: In our protocol, the most time-consuming operation for verification is running LHH.Hash. To reduce the computation overhead for verification, we allow each client to do verification in an amortized manner. Similar to [14], [15], [28], we draw a set of random coefficients to compute the linear combination of the hash aggregations in different epochs. Then, we check whether the combined hash is equal to the hash of the linear combination (using the same coefficients) of aggregation results in different epochs. More formally, letting be the preset batch size and a k be the aggregation result in the epoch k \u2208 [ ], we replace the aforementioned VERIFICATION step with the following AMORTIZED-VERIFICATION step:\n\nAMORTIZED-VERIFICATION: The equality test of commitment (1) remains unchanged for all commitments received in each epoch k \u2208 [ ]. However, for k \u2208 [ ], P i does the following: instead of the equality (2). If the equality test (3) holds, then all the aggregation results a 1 , . . . , a pass the verification and P i will accept these results; otherwise these results will be regarded as forged and P i terminates with output \u22a5.\n\u03b1 k \u2190 F q , h k \u2190 LHH.Eval(h 1 k , . . . , h N k , 1, . . . , 1 N items ),\nIn this way, P i does not need to call LHH.Hash in the equality test (2) \n\n\n4) Privacy Concern and Dropout-Tolerance:\n\nOur verifiable aggregation protocol (i.e., the basic FL framework with PREPARATION and AMORTIZED-VERIFICATION steps) is composable with the secure one Figure 2. The summarized secure verifiable aggregation protocol is given in Figure 3. We modify the ShareKeys round in [7] and the original secure protocol serves as the aggregation phase in this composite protocol. Notably, the dropout-tolerance of [7] is preserved and therefore the aggregation phase in our protocol is robust to client dropout. However, to deal with the potential dropout when clients report their decommitment strings in Decommitting round, an extra DroppedDecommitting round is introduced. This extra round guarantees that all clients that survive dropout are able to run AMORTIZED-VERIFICATION in BatchChecking round. Note that, to tolerate dropout, we require the additional O(N) computation of secret sharing in ShareMetadata round. Therefore, the total verification cost in computation is O(N + d).\n\n\nD. Full Version of VERIFL Protocol\n\nThe full version of VERIFL Protocol is presented in Figure 4 and Figure 5, where cryptographic primitives are defined in Section III-B.\n\n\nIV. SECURITY ANALYSIS\n\nIn this section, we will show that our protocol ensures the integrity of the aggregation results (Definition 3) and the privacy of individual input (Definition 4). Recall that our protocol runs with a set P of N parties and an aggregation server S, in which the building blocks are instantiated with the security parameter \u03ba and the verification is performed in batch of size . The threshold for dropout is t (i.e., at least t parties survive dropout) and the set of corrupted parties is C \u2286 P \u2229 {S} such that |C \\ {S}| < t. U * k is the set U * in the k-th aggregation phase. Given fixed N, t, \u03ba, and C, we define M C as the polynomial time algorithm for the \"nextmessage\" function of corrupted parties in C. That is, given a party identifier c \u2208 C, a round index i a transcript T i that has been sent and received so far by all corrupted parties in C, and the joint randomness r C for the execution of corrupted parties, M C (c, i, T i , r C ) outputs the message for the party c in the round i .\n\nNote that some common reference strings (CRS) are required by this protocol. As we will see, this protocol is secure in the CRS-hybrid model [29]. More specifically, according to the CRS functionality, the simulator is allowed to learn the trapdoor of the underlying commitment scheme. Therefore, in the CRS-hybrid model, the simulator of our protocol can obtain this trapdoor by simulating the CRS functionality and then use the trapdoor to make the simulated view consistent with the real one.\n\nDefinition 3 gives out the integrity of aggregation considered in this paper. In this definition, we say that integrity is achieved if an adversary who wants to forge the aggregation result after all clients having committed their homomorphic hash values respectively can be detected with an overwhelming probability.\n\n\nDefinition 3 (Integrity of Aggregation): In the k-th epoch, let v H k be the partially aggregation result of the inputs of honest parties in U 3 k , and v i k be the well-formed input\n\nof some corrupted party P i \u2208 U 3 k \u2229 C whose hash was computed and committed in ShareMetadata. We say that the integrity of aggregation in a verification batch of size holds, if an adversary can have honest parties accept its forged aggregation result in some epochs of this batch with a negligible probability, i.e., By Definition 4, we define input privacy of each client in the existence of the considered adversary. This definition aims to capture an adversary who corrupts the server and a subset of parties learns nothing from protocol transcript but the partially aggregation result of honest parties. We say that an adversary learns nothing if its view can be simulated by a simulator without any secret internal state of honest parties (e.g., the knowledge of the gradient of a client). More specifically, input privacy is defined in the sense that the view of an adversary corrupting less than t data parties can be simulated only given the partially aggregation result of honest parties.\nPr \u23a1 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a2 \u23a3 P i \u2208 V 2 \\ C, for some k \u2208 K \u2286 [ ], a k \u2190 v H k + i\u2208U 3 k \u2229C v i k , P i outputs \u22a5 a k \u2208 Z d B , a k \u2190 M C (S, k, T k , r C ), a k \u2208 Z d B , a k = a k \u23a4 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a5 \u23a6 \u2265 1 \u2212 negl(\u03ba).\nDefinition 4 (Input Privacy): We say that the input privacy of an honest client holds, if there exists a PPT simulator SIM such that for any set of parties P, threshold t, security parameter \u03ba, batch size , set of inputs {v i } i\u2208P ,\n{U 1 k , U 2 k , U 3 k , U 4 k } k\u2208[ ] and V 1 , V 2 such that for all j \u2208 [3] and k \u2208 [ \u2212 1] P \u2287 U 1 1 , U j k \u2287 U j +1 k , U 4 k \u2287 U 1 k + 1 , U 4 \u2287 V 1 \u2287 V 2 ,\nand set of corrupted parties C such that C \u2286 P \u2229 {S} and |C \\ {S}| < t, the output of SIM is computationally indistinguishable from the output of REAL P,t,\u03ba C :\nREAL P,t,\u03ba C ({v i } i\u2208P , {U 1 k , U 2 k , U 3 k , U 4 k } k\u2208[ ] , V 1 , V 2 ) \u2248 c SIM P,t,\u03ba C ({v i } i\u2208C , {z k } k\u2208[ ] , {U 1 k , U 2 k , U 3 k , U 4 k } k\u2208[ ] , V 1 , V 2 ), where z k = i\u2208U 3 k \\C v i , if |U 3 k | \u2265 t \u22a5,\no t h e r w i s e .\n\nLemma 1: Assume the hardness of discrete logarithm and the security of COM. In the AMOTIZED-VERIFICATION step, an honest client will accept the aggregation results a 1 , . . . , a if and only if these results are honestly aggregated by the server with an overwhelming probability.\n\nProof: Assume there exists a PPT adversary that succeeds in letting some honest party P i output its forged aggregation results\u0101 k = a k = i v i k for all k \u2208 K \u2286 [ ] in BatchChecking. We first observe that, since P i does not output \u22a5, the decommitment in BatchChecking should be done successfully. For decommitment strings (h j k , r j k ) where k \u2208 K and j \u2208 U 3 k \u2229 C, the adversary has the freedom whether to send correct decommitment strings in Decommitting. If it chooses to send malformed decommitment strings, the decommitment in BatchChecking fails with a non-negligible probability since COM is binding. The same argument applies to the case where the adversary sends to P i its incorrectly reconstructed decommitment strings of (honest) dropped parties in DroppedDecommitting.\n\nThe above argument implies that the adversary cannot change the hash values it has committed in ShareMetadata on behalf of corrupted parties without having P i output \u22a5. Recall that, by protocol specification, the honestly aggregation result a k and the final hash h * satisfy \nh * = LHH.Hash(a * ) = LHH.Hash \u239b \u239d k\u2208[ ] \u03b1 k a k \u239e \u23a0 = j \u2208[d] g k\u2208[ ] \u03b1 k a k [ j ] j = \u239b \u239d j \u2208[d] g k\u2208K \u03b1 k a k [ j ] j \u239e \u23a0 \u00b7 \u239b \u239d j \u2208[d] g k\u2208[ ]\\K \u03b1 k a k [ j ]\u239b \u239d k\u2208K \u03b1 k\u0101 k + k\u2208[ ]\\K \u03b1 k a k \u239e \u23a0 = \u239b \u239d j \u2208[d] g k\u2208K \u03b1 k\u0101 k [ j ] j \u239e \u23a0 \u00b7 \u239b \u239d j \u2208[d] g k\u2208[ ]\\K \u03b1 k a k [ j ] j \u239e \u23a0 .\nSince P i does not output \u22a5, it should hold that h * = LHH.Hash(a), i.e.,\nj \u2208[d] g k\u2208K \u03b1 k a k [ j ] j = j \u2208[d] g k\u2208K \u03b1 k\u0101 k [ j ] j .\nwhere a k =\u0101 k for k \u2208 K. Notice that the coefficients \u03b1 k for k \u2208 K are uniformly drawn from F q , the event that h * = LHH.Hash(a) and\nk\u2208K a k [ j ] = k\u2208K\u0101 k [ j ]\nin which j \u2208 [d] and a k =\u0101 k for k \u2208 K happens with a probability 1/|F q |, which is negligible in the security parameter \u03ba. In other words, conditioned on h * = LHH.Hash(a), it is hold that\nk\u2208K a k [ j ] = k\u2208K\u0101 k [ j ]\nfor some j \u2208 [d], which induces a collision of LHH.\n\nIt is readily seen that such a PPT adversary can break either the binding property of COM or the collision resistance (Definition 1) of LHH with a non-negligible probability, which is infeasible under the assumption. This completes the proof.\n\nTheorem 1: Assume the hardness of discrete logarithm and the security of COM. VERIFL achieves integrity of aggregation according to Definition 3. Proof: This theorem is straightforward from Lemma 1. The proof is identical to that for Theorem 6.3 in [7], except that we should additionally take care of the hashes being committed in ShareMetadata. Notice that SIM did not know the real inputs of honest parties by the time it was asked to compute the hash as well as the commitment. The strategy of SIM is to hash a dummy vector (e.g., the one filled with 0's) and commit this dummy hash value. Give that COM is hiding and the secret sharing scheme hides messages being shared, the joint view w.r.t. the aggregation phase of parties in C will be indistinguishable from that in REAL P,t,\u03ba C . It remains to show that the joint view w.r.t. the verification phase of parties in C can also be simulated by SIM. Note that the simulated commitment is committed to the dummy hash which is different (with an overwhelming probability) to that of the vector sampled by SIM after it obtains the partially aggregation result of honest parties by querying z k for k \u2208 [ ]. Recall that COM is equivocal and, in the CRS-hybrid model, SIM has the trapdoor td which is associated with the COMpp output by COM.Setup. So, using the trapdoor td, SIM can equivocate these commitments to the hashes of inputs sampled by it on behalf of honest parties. The equivocality of COM (Definition 2) guarantees that these commitments are consistent with hashes of the simulated inputs of honest parties and therefore can be successfully decommitted with an overwhelming probability. Moreover, since C forms an unqualified set to reconstruct shared secrets by assumption, SIM can adjust its shares held on behalf of honest parties such that the reconstructed decomittment strings match those obtained from equivocation. That is, the verification phase can be simulated, which completes the proof.\n\n\nV. EVALUATION\n\n\nA. Experimental Setup\n\nWe show the performance of our protocol based on a prototype implementation. The prototype is written in Java while we use JNI to implement low-level cryptography algorithms. In particular, linearly homomorphic hash LHH is realized using elliptic curve over the NIST P-256 curve. For efficient equivocal commitment COM, we use folklore hash commitment scheme instantiated with SHA-256, which is proved secure in restricted programmable and observable global random oracle model [30]. For secret sharing scheme, we adopt standard t-out-of-N Shamir secret sharing. For key agreement, we use elliptic curve Diffie-Hellman over the NIST P-256 curve with SHA-384. The symmetric encryption is instantiated with AES-OFB mode with 256-bits key and 128-bits IV. For pseudo-random generator, we use AES-CTR mode. In addition, we fix two moduli R = 2 24 and B = 2 34 (i.e., the maximum number of clients is B/R = 2 10 = 1024) and assume all clients will input honestly as in our adversarial model.\n\nWe simulate clients and the aggregation server on a 64-bits Ubuntu 16.04 LTS desktop equipped with Intel i7-7700 CPU (3.60 GHz) and 16 GB RAM. The simulation is singlethreaded. Given that end-to-end networking time will not significantly influence the asymptotic computation complexity of our protocol and can be calculated using bandwidth, we omit this part in our evaluation.\n\n1) Dropout Cases: For client dropout, we consider the following two cases of dropout in our protocol:\n\n\u2022 Case I dropout: In this case, clients drop out of the protocol after sending their metadata to other clients via server in ShareMetadata but before sending their masked gradients to the server in MaskedInputCollection. As discussed in [7], this dropout case will lead to the worst performance of aggregation phase in our protocol for the expensive computation overhead to recover the pairwise-mask. \u2022 Case II dropout: In this case, some clients drop out before reporting their decommitment strings to other clients via the aggregation server in Decommitting. The server has to recover these strings of dropped clients by asking all surviving clients to send their shares of these strings and running secret reconstruction algorithm to recover them. This will lead to the most expensive computation overhead in our verification phase.\n\n\nB. Comparison With VerifyNet [8]: Dimension-Independence\n\nGiven that the protocol in [8] does not allow Case II dropout and amortization, we consider only the Case I dropout and set the batch size to 1 in our comparison. In addition, we set the number of clients N = 500 and fix the threshold t = 1 2 N. All other parameters remain unchanged as above. It is readily seen from Figure 6(a) and Figure 6(b) that, in our protocol, the outgoing communication cost for verification of either each client or the server is independent of the dimension of gradients. However, in [8], the two metrics is linearly dependent on the dimension of gradients, which results in impractical performance when the dimension is large enough. A more comprehensive comparison with respect to the overall overhead is presented in Figure 6. It is easy to see that our protocol outperforms VerifyNet completely. A more encouraging result is that our protocol can be scaled to support high-dimensional gradient vectors (e.g., 100K) with even better performance than that achieved by VerifyNet in dealing with low-dimensional one. [7] In Table I, Table II, Table III and Table IV, we give out the additional costs for verification in our protocol. The baseline protocol is [7] that addresses the input privacy of mobile clients. It is easy to see from underlined bold figures that our protocol does not introduce too much additional communication overhead to the baseline secure aggregation protocol per client. For example, when the dimension of gradient vectors is set to 100K, the communication for transferring a gradient is always 488.28 KB, which takes the largest proportion of the overall communication per client. Compared with that, the additional communication caused by verification protocol is insignificant. As for the computation overhead, the one caused by our protocol is also affordable compared with the one in [7]. In the real-world applications of FL, it is not uncommon that each local iteration of machine learning requires tens of seconds. When deploying our protocol to these applications where dropout is not severe (e.g., <1% occurred naturally as reported in [7]), the overall computation overhead will not blow up since our protocol has similar wall-clock running time with a local iteration of machine learning. Figure 7, it is clear that, with the growth of batch size, the amortized verification overhead per epoch can be reduced nearly to that of a single LHH.Hash call. In other words, with a large enough batch size, we can approximately halve the computation overhead of a client in the sense of amortization. However, in real-world applications where there are dropouts in each epoch, the batch size cannot be set too large given that too large verification batch will lead   Fig. 7. Comparison between total computation cost for verification, amortized computation cost for verification and total computation cost per client. The dimension of gradient vectors is set to 100K and the number of clients is 500. Assume no dropout.\n\n\nC. Comparison With Secure Aggregation\n\n\nD. Other Experimental Results\n\n\n1) Amortized Verification: In\n\nto severe accumulation of dropouts and therefore the expensive overhead to run secret reconstruction algorithm. We regard this phenomenon as a tradeoff and therefore the batch size should be fine-tuned in real-world applications.\n\n\n2) Number of Clients:\n\nBoth the computation and communication cost in client side grows linearly in the number of clients, which results from the fact that the number of secret shares generated in ShareMetadata is proportional to the number of clients. For the wall-clock running time of the server, it grows quadratically in the number of clients. The reason is that, in Unmasking, the server has to run secret reconstruction algorithm to recover the secret mask key of dropped clients and both the threshold t and the number of dropped clients are proportional to the number of clients N.\n\n3) Dropout: As shown in Figure 8 and Figure 9, it is clear that, in client side, either the computation cost or the communication cost is independent of how many other clients drop out of the protocol execution. However, the two metrics in server side is influenced by the dropout rate, especially the wall-clock running time of the server. We note that the overhead suffered by the server is acceptable.\n\n\nVI. RELATED WORK\n\nIn this section, we briefly discuss the works related to secure verifiable aggregation in federated learning.   \n\n\nA. Generic Maliciously-Secure Multiparty Computation\n\nIn general, FL involves an aggregation server and a set of clients and therefore can be regarded as a specific multiparty computation problem. Although there are piles of works [14]- [21], [31] guarantee the integrity of computation in the existence of a malicious (i.e., active) adversary, they are not suitable for FL settings. For garbled circuit-based protocols [19]- [21], [31], they deal with the malicious adversary at the cost of expensive communication overhead (e.g., that led by commit-and-prove [18] or cut-and-choose [21], [32] technique) and cannot be deployed on a large scale. For secret sharing-based protocols [14]- [16], each client has to divide each entry of its input into (additive) shares and send them to each other client, which results in a rather expensive communication overhead in O(Nd). In addition, these protocols rely on homomorphic encryption to compute MACs of shares. Their distributed homomorphic decryption sub-protocols cannot tolerate dropout in a threshold manner directly and therefore are not suitable for FL settings where dropout is common.\n\n\nB. Machine Learning Based on Cryptographic Protocols\n\nThere are two lines of the cryptographic research regarding privacy and verifiability issues in machine learning, i.e., secure model prediction and secure model training. For secure model prediction, the goal is to securely query a model without revealing model inputs and the information of the model. All works [33]- [37] require that the model being queried was well-trained in advance, which differs from the motivation of FL.\n\nFor secure model training, there are several works [38]- [40] being proposed to train a model while guarantee integrity of the derived model and the privacy of users. Unfortunately, these works will result in expensive overhead when applied to FL settings. For example, Mohassel et al. [38] proposed a framework to convert between any two kinds of secret shares and built up general protocols to train a neural network, where each client is supposed to share each entry of its gradient vector. The communication overhead will blow up as the dimension of vector increases. In addition, as the number of clients increases, to preserve the robustness against dropout, the size of the share held by each client blows up as well.\n\nThere are also some works [41], [42] based on homomorphic encryption (HE) which address input privacy only. These works rely on a stronger adversarial model where the secret decryption key of encrypted gradients is only known to all clients and these clients are honest. However, in our adversarial model (Section II-C), the adversary can acquire this key from controlled corrupted clients and decrypts all encrypted gradients, which undermines the security of [41], [42]. It is possible to secret share the decryption key (in a threshold manner, e.g., [43], [44]) among all clients to mitigate this issue. Unfortunately, such a construction complicates the decryption of encrypted gradients and, in the FL setting where dropout is common, will significantly increase the size of key shares and the communication between the server and a client as the number of clients increases. So, we believe the protocol based on double-masking is more efficient than that based on HE. In addition, HE is a primitive that can be used to address input privacy only. To achieve both input privacy and verifiability, some other cryptographic primitives (e.g., zero-knowledge proof) are required. This paper finds such a primitive that can be used to replace time-consuming zeroknowledge proof adopted by [8].\n\nTo the best of our knowledge, there is only one work [8] for secure verifiable aggregation in FL. However, this work adopts heavy zero-knowledge proof, which results in impractical performance and unaffordable communication overhead.\n\n\nC. Differential Privacy\n\nA notable fact is that privacy-preserving cryptographic protocols cannot fully prevent privacy disclosure in machine learning. It is known that privacy disclosure can be resulted from the statistical characteristics (e.g., confidence information, prediction outcome) of machine learning algorithms. For example, there are some black-box privacy attacks [22]- [26] leveraging these statistical characteristics. Treating cryptographic protocols as black-box oracles, such black-box attacks can be applied to the machine learning paradigms even if they are securely realized by cryptographic protocols. That is, as long as these protocols implement the functionality of machine learning, the statistical leakage is inevitable. A possible defense is to combine the cryptographic protocols with differential privacy [45]- [48].\n\nDifferentially private federated learning [49]- [53] has been extensively studied in the literature. A few of existing works [49], [53] consider how to combine differentially private mechanisms with multiparty computation to protect not only the statistical characteristics but also the raw inputs of all honest clients. However, these works do not address the verifiability issue in FL. In this work, we are devoted to fix this issue of FL with practical overhead and differential privacy is not the primary goal. A straightforward way to make our protocol differentially private is to add Gaussian or Laplacian noises to original gradients and then regard the noisy gradients as inputs to our protocol, although it might not achieve the best utility of the global model. An interesting direction for future work would be to explore how to design an optimal differentially private mechanism that is compatible with our practical secure verifiable aggregation protocol.\n\n\nD. Byzantine-Robust Aggregation\n\nA Byzantine client in FL can send arbitrary values to the aggregation server to influence model convergence.\n\nTo deal with this issue, one popular mitigation is to use Byzantine-robust aggregation, which is mostly related to our aggregation protocol. There are several alternative aggregation mechanisms [54]- [57] to the standard federated averaging to ensure that convergence is not significantly influenced by Byzantine clients, in which [57] is for non-IID settings. As noted in [58], it is quite challenging to devise a Byzantine-robust aggregation mechanism for non-IID FL datasets.\n\nByzantine-robust aggregation can be regarded as a supplement to the secure verifiable aggregation based on cryptographic protocols since the latter guarantees only input privacy and the integrity of aggregation with respect to the used inputs. In other words, secure verifiable aggregation cannot prevent Byzantine clients to use malformed inputs to do harm to either the training process or the resulting global model.\n\nHowever, how to combine Byzantine-robust aggregation [54]- [57] with secure verifiable aggregation is still an open problem. There are several technical challenges to be addressed by future work. First, these works adopt a completely different adversarial model to that of secure verifiable aggregation (e.g., Section II-C). That is, Byzantine aggregation assume only Byzantine clients that send arbitrary values to an honest aggregation server and does not consider the case where the server is corrupted. Second, these works implicitly assume the aggregation server has access to the plaintext stochastic gradients uploaded by clients, which violates input privacy. Since Byzantine-robust aggregation mechanisms usually adopt more complicated arithmetic (e.g., median or trimmed mean) than federated averaging, it is challenging to devise a tailored dropout-tolerant protocol for these mechanisms to achieve input privacy and verifiability additionally.\n\n\nVII. CONCLUSION\n\nIn this paper, we studied how to realize verifiable aggregation in FL in a communication-efficient and fast way, and proposed a protocol named VERIFL. We show by experiments that VERIFL is capable of dealing with (i) high-dimensional gradient vectors, (ii) a large number of clients, and (iii) high dropout rate in real-world applications with practical performance. Notably, in VERIFL, the verification cost in terms of the outgoing communication is independent of the gradient dimension, resulting in 110.6\u00d7 improvement in communication even with 5\u00d7 larger gradient vectors in our experiments.\n\nXiaojie Guo received the B.Eng. degree in information security and law from Nankai University, China, in 2018, where he is currently pursuing the master's degree with the College of Cyber Science. His research interests include cryptography, multiparty computation, and privacy-preserving machine learning. \n\n\nZheli\n\nFig. 1 .\n1Federated learning and a trivial attack on it. (a) The framework of federated learning. (b) The attack launched by the adversary corrupting the server and a subset of clients.\n\n\u2022\nSE.KeyGen(1 \u03ba ): On input the security parameter \u03ba, this algorithm outputs a secret symmetric key k. \u2022 SE.Enc(m; k): This algorithm takes as input a message m to be encrypted and a symmetric key k. The output of this algorithm is the ciphertext c of m under the key k. \u2022 SE.Dec(c; k ): This algorithm takes as input a ciphertext\n\n=\nin which q is the prime order provided in LHHpp and h i k is the hash computed by client P i in the k-th epoch. Then, it verifies the equality LHH.Eval(h 1 , . . . , h , \u03b1 1 , . . . , \u03b1 )(3) \n\nFig. 3 .\n3Our verifiable aggregation protocol with secure aggregation functionality.\n\nFig. 4 .\n4Aggregation phase for privacy-preserving verifiable aggregation protocol.\n\nFig. 5 .\n5Verification phase for privacy-preserving verifiable aggregation protocol.\n\n\nMeanwhile, with unchanged hashes committed in ShareMetadata, we have another linear combination a \u2190 k\u2208K \u03b1 k\u0101 k + k\u2208[ ]\\K \u03b1 k a k and therefore LHH.Hash(a) = LHH.Hash\n\nFig. 6 .\n6Comparison between our protocol and VerifyNet[8] in terms of (i) outgoing communication overhead for verification, (ii) the total computation overhead, and (iii) the total outgoing communication overhead, as the dimension of gradient vectors increases.(a) Outgoing communication overhead for verification per client. (b) Outgoing communication overhead for verification of the server. (c) Computation overhead per client. (d) Outgoing communication overhead per client. (e) Computation overhead of the server. (f) Total outgoing communication overhead of the server.\n\nFig. 8 .\n8Total computation and outgoing communication overhead, as the number of clients increases. (a) Computation overhead per client. (b) Outgoing communication overhead per client. (c) Computation overhead of the server. (d) Outgoing communication overhead of the server (for a single client). The dimension of gradient vectors is set to 100K and the batch size is 1. Assume Case I dropout.\n\nFig. 9 .\n9Total computation and outgoing communication overhead, as the dimension of gradient vectors increases. (a) Computation overhead per client. (b) Outgoing communication overhead per client. (c) Computation overhead of the server. (d) Outgoing communication overhead of the server (for a single client). The number of clients is set to 500 and the batch size is 1. Assume Case I dropout.\n\n\nLiu received the B.Sc. and M.Sc. degrees in computer science from Jilin University, China, in 2002 and 2005, respectively, and the Ph.D. degree in computer application from Jilin University in 2009. He joined the College of Computer and Control Engineering, Nankai University, in 2011, after a Post-Doctoral Fellowship at the same university. He currently works as an Associate Professor at Nankai University. His current research interests include applied cryptography and data privacy protection.\n\n\n\u2286P ): This algorithm takes as input the threshold value t and the subset of shares {[[s]] i } P i \u2208P \u2286P of which the size is not less than t. The output of this algorithm is the original secret s. C. How to Achieve Efficient Verifiable Aggregation?\n\n\nevery aggregation epoch. That is, the cost for LHH.Hash in the equality test (2) can be amortized by a factor . Since the cost for LHH.Hash is O(d), the amortized computation cost for verification in each epoch can be reduced from O(2d) to O(d + d/ ). When is large enough, the cost can be approximately halved.\n\nTheorem 2 :\n2Assume the security of SE, KA, SS and COM.VERIFL achieves input privacy according to Definition 4 in \nthe CRS-hybrid model. \nProof: \n\n\nTABLE I\nICOMPUTATION OVERHEAD WITH RESPECTTO CASE I DROPOUT 1\n\nTABLE II OUTGOING\nIICOMMUNICATION OVERHEAD WITH RESPECT TO CASE I DROPOUT 1\n\nTABLE III\nIIICOMPUTATION OVERHEAD WITH RESPECTTO CASE II DROPOUT 1\n\nTABLE IV OUTGOING\nIVCOMMUNICATION OVERHEAD WITH RESPECT TO CASE II DROPOUT 1\nACKNOWLEDGMENT Xiaojie Guo, Jiqiang Gao, and Boyu Hou are supervised by Zheli Liu and have the same contribution to this paper.Jin Li (Senior Member, IEEE) received the B.S. degree in mathematics from Southwest University in 2002, and the Ph.D. degree in information security from Sun Yat-sen University in 2007. He currently works as a Professor at Guangzhou University. He has been selected as the \"One of science and technology new star\" in Guangdong province. His research interests include applied cryptography and security in cloud computing. He has published over 50 research papers in refereed international conferences and journals and has served as the program chair or program committee member in many international conferences.Jiqiang Gao received the B.S. degree in information security from Nankai University in 2018, where he is currently pursuing the master's degree. His main research interests include protocol security about machine learning algorithm, distributed machine learning, and adversarial machine learning. His research interest includes the attack and defense on different machine learning algorithms.Boyu Hou is currently pursuing the master's degree in computer science with the Database and Information System Laboratory, Computer Science Department, Nankai University. Her main research field is AI security, which includes secure distributed machine learning algorithms, adversarial machine learning, and attack and defense method on machine learning algorithms.Changyu Dong received the Ph.D. degree from Imperial College London. He is currently a Senior Lecturer with the School of Computing, Newcastle University. He has authored over 30 publications in international journals and conferences. His research interests include applied cryptography, trust management, data privacy, and security policies. His recent work focuses on designing practical secure computation protocols. His application domains include secure cloud computing and privacy preserving data mining.Thar Baker (Member, IEEE) received the Ph.D. degree in autonomic cloud applications from LJMU in 2010. He is currently a Senior Lecturer in Software Systems with the Department of Computer Science, Faculty of Engineering and Technology, University of Sharjah. Before that, he worked as a Lecturer with the Department of Computer Science, Manchester Metropolitan University (MMU), in 2011. He has published numerous refereed research articles in multidisciplinary research areas, including cloud computing, distributed software systems, big data, algorithm design, green and sustainable computing, and autonomic web science. He has been actively involved as a member of editorial board and review committee for a number peer reviewed international journals, and is on programme committee for a number of international conferences. He was appointed as an Expert Evaluator in the European FP7 Connected Communities CONFINE project (2012-2015).\nCommunication-efficient learning of deep networks from decentralized data. H Brendan Mcmahan, E Moore, D Ramage, S Hampson, B Ag\u00fcera Y Arcas, arXiv:1602.05629H. Brendan McMahan, E. Moore, D. Ramage, S. Hampson, and B. Ag\u00fcera y Arcas, \"Communication-efficient learning of deep networks from decentralized data,\" 2016, arXiv:1602.05629. [Online]. Available: http://arxiv.org/abs/1602.05629\n\nFederated learning: Strategies for improving communication efficiency. J Kone\u010dn\u00fd, H Brendan Mcmahan, F X Yu, P Richt\u00e1rik, A Theertha Suresh, D Bacon, arXiv:1610.05492J. Kone\u010dn\u00fd, H. Brendan McMahan, F. X. Yu, P. Richt\u00e1rik, A. Theertha Suresh, and D. Bacon, \"Federated learning: Strategies for improving communication efficiency,\" 2016, arXiv:1610.05492. [Online]. Avail- able: http://arxiv.org/abs/1610.05492\n\nTowards federated learning at scale: System design. K Bonawitz, arXiv:1902.01046K. Bonawitz et al., \"Towards federated learning at scale: System design,\" 2019, arXiv:1902.01046. [Online]. Available: http://arxiv.org/abs/1902.01046\n\nDeep models under the GAN: Information leakage from collaborative deep learning. B Hitaj, G Ateniese, F Perez-Cruz, Proc. ACM SIGSAC Conf. Comput. Commun. Secur. ACM SIGSAC Conf. Comput. Commun. SecurB. Hitaj, G. Ateniese, and F. Perez-Cruz, \"Deep models under the GAN: Information leakage from collaborative deep learning,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., 2017, pp. 603-618.\n\nExploiting unintended feature leakage in collaborative learning. L Melis, C Song, E De Cristofaro, V Shmatikov, Proc. IEEE Symp. Secur. Privacy (SP). IEEE Symp. Secur. Privacy (SP)L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov, \"Exploiting unintended feature leakage in collaborative learning,\" in Proc. IEEE Symp. Secur. Privacy (SP), May 2019, pp. 691-706.\n\nComprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning. M Nasr, R Shokri, A Houmansadr, Proc. IEEE Symp. Secur. Privacy (SP). IEEE Symp. Secur. Privacy (SP)M. Nasr, R. Shokri, and A. Houmansadr, \"Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning,\" in Proc. IEEE Symp. Secur. Privacy (SP), May 2019, pp. 739-753.\n\nPractical secure aggregation for privacy-preserving machine learning. K Bonawitz, Proc. ACM SIGSAC Conf. ACM SIGSAC ConfK. Bonawitz et al., \"Practical secure aggregation for privacy-preserving machine learning,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., Oct. 2017, pp. 1175-1191.\n\nVerifyNet: Secure and verifiable federated learning. G Xu, H Li, S Liu, K Yang, X Lin, IEEE Trans. Inf. Forensics Security. 15G. Xu, H. Li, S. Liu, K. Yang, and X. Lin, \"VerifyNet: Secure and verifiable federated learning,\" IEEE Trans. Inf. Forensics Security, vol. 15, pp. 911-926, 2020.\n\nHow to backdoor federated learning. E Bagdasaryan, A Veit, Y Hua, D Estrin, V Shmatikov, arXiv:1807.00459E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, \"How to backdoor federated learning,\" 2018, arXiv:1807.00459. [Online].\n\nTargeted backdoor attacks on deep learning systems using data poisoning. X Chen, C Liu, B Li, K Lu, D Song, arXiv:1712.05526X. Chen, C. Liu, B. Li, K. Lu, and D. Song, \"Targeted back- door attacks on deep learning systems using data poisoning,\" 2017, arXiv:1712.05526. [Online]. Available: http://arxiv.org/abs/1712.05526\n\nTrojaning attack on neural networks. Y Liu, Proc. 25th. 25thY. Liu et al., \"Trojaning attack on neural networks,\" in Proc. 25th\n\n. Annu. Netw. Distrib. Syst. Secur. Symp. (NDSS). Annu. Netw. Distrib. Syst. Secur. Symp. (NDSS), San Diego, CA, USA, Feb. 2018, pp. 1-17.\n\nBackdooring convolutional neural networks via targeted weight perturbations. J Dumford, W Scheirer, arXiv:1812.03128J. Dumford and W. Scheirer, \"Backdooring convolutional neural net- works via targeted weight perturbations,\" 2018, arXiv:1812.03128. [Online]. Available: http://arxiv.org/abs/1812.03128\n\nRobust and communication-efficient federated learning from non-i.i.d. data. F Sattler, S Wiedemann, K.-R M\u00fcller, W Samek, IEEE Trans. Neural Netw. Learn. Syst. 319F. Sattler, S. Wiedemann, K.-R. M\u00fcller, and W. Samek, \"Robust and communication-efficient federated learning from non-i.i.d. data,\" IEEE Trans. Neural Netw. Learn. Syst., vol. 31, no. 9, pp. 3400-3413, Sep. 2020.\n\nMultiparty computation from somewhat homomorphic encryption. I Damg\u00e5rd, V Pastro, N Smart, S Zakarias, Proc. 32nd Annu. Cryptol. Conf. Adv. Cryptol. (CRYPTO). 32nd Annu. Cryptol. Conf. Adv. Cryptol. (CRYPTO)Santa Barbara, CA, USAI. Damg\u00e5rd, V. Pastro, N. Smart, and S. Zakarias, \"Multiparty computa- tion from somewhat homomorphic encryption,\" in Proc. 32nd Annu. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Santa Barbara, CA, USA, Aug. 2012, pp. 643-662.\n\nOverdrive: Making SPDZ great again. M Keller, V Pastro, D Rotaru, Proc. 37th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EUROCRYPT). 37th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EUROCRYPT)Part III, Tel Aviv, IsraelM. Keller, V. Pastro, and D. Rotaru, \"Overdrive: Making SPDZ great again,\" in Proc. 37th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EUROCRYPT), Part III, Tel Aviv, Israel, Apr./May 2018, pp. 158-189.\n\nSpdZ 2k : Efficient mpc mod 2 k for dishonest majority. R Cramer, I Damg\u00e5rd, D Escudero, P Scholl, C Xing, Proc. 38th Annu. Int. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Part II. 38th Annu. Int. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Part IISanta Barbara, CA, USAR. Cramer, I. Damg\u00e5rd, D. Escudero, P. Scholl, and C. Xing, \"SpdZ 2k : Efficient mpc mod 2 k for dishonest majority,\" in Proc. 38th Annu. Int. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Part II, Santa Barbara, CA, USA, Aug. 2018, pp. 769-798.\n\nYet another compiler for active security or: Efficient MPC over arbitrary rings. I Damg\u00e5rd, C Orlandi, M Simkin, Proc. Annu. Int. Cryptol. Conf. Annu. Int. Cryptol. ConfSpringerI. Damg\u00e5rd, C. Orlandi, and M. Simkin, \"Yet another compiler for active security or: Efficient MPC over arbitrary rings,\" in Proc. Annu. Int. Cryptol. Conf. Springer, 2018, pp. 799-829.\n\nHow to play any mental game. O Goldreich, S Micali, A Wigderson, Proc. 19th Annu. ACM Symp. Theory Comput. 19th Annu. ACM Symp. Theory ComputO. Goldreich, S. Micali, and A. Wigderson, \"How to play any men- tal game,\" in Proc. 19th Annu. ACM Symp. Theory Comput., 1987, pp. 218-229.\n\nTwo-output secure computation with malicious adversaries. C.-H Shen, Proc. 30th Annu. Int. Conf. Theory Appl. 30th Annu. Int. Conf. Theory ApplTallinn, EstoniaC.-H. Shen et al., \"Two-output secure computation with malicious adver- saries,\" in Proc. 30th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EUROCRYPT), Tallinn, Estonia, May 2011, pp. 386-405.\n\nBillion-gate secure computation with malicious adversaries. B Kreuter, A Shelat, C.-H Shen, Proc. 21st USENIX Secur. Symp. (USENIX Secur. 21st USENIX Secur. Symp. (USENIX SecurB. Kreuter, A. Shelat, and C.-H. Shen, \"Billion-gate secure computa- tion with malicious adversaries,\" in Proc. 21st USENIX Secur. Symp. (USENIX Secur.), 2012, pp. 285-300.\n\nEfficient secure two-party computation using symmetric cut-and-choose. Y Huang, J Katz, D Evans, Proc. 33rd Annu. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Part II. 33rd Annu. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Part IISanta Barbara, CA, USAY. Huang, J. Katz, and D. Evans, \"Efficient secure two-party compu- tation using symmetric cut-and-choose,\" in Proc. 33rd Annu. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Part II, Santa Barbara, CA, USA, Aug. 2013, pp. 18-35.\n\nModel inversion attacks that exploit confidence information and basic countermeasures. M Fredrikson, S Jha, T Ristenpart, Proc. 22nd ACM SIGSAC Conf. 22nd ACM SIGSAC ConfDenver, CO, USAM. Fredrikson, S. Jha, and T. Ristenpart, \"Model inversion attacks that exploit confidence information and basic countermeasures,\" in Proc. 22nd ACM SIGSAC Conf. Comput. Commun. Secur., Denver, CO, USA, Oct. 2015, pp. 1322-1333.\n\nNeural network inversion in adversarial setting via background knowledge alignment. Z Yang, J Zhang, E.-C Chang, Z Liang, Proc. ACM SIGSAC Conf. ACM SIGSAC ConfLondon, U.K.Z. Yang, J. Zhang, E.-C. Chang, and Z. Liang, \"Neural network inversion in adversarial setting via background knowledge alignment,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., London, U.K., Nov. 2019, pp. 225-240.\n\nMembership inference attacks against machine learning models. R Shokri, M Stronati, C Song, V Shmatikov, Proc. IEEE Symp. Secur. Privacy (SP). IEEE Symp. Secur. Privacy (SP)San Jose, CA, USAR. Shokri, M. Stronati, C. Song, and V. Shmatikov, \"Membership inference attacks against machine learning models,\" in Proc. IEEE Symp. Secur. Privacy (SP), San Jose, CA, USA, May 2017, pp. 3-18.\n\nMembership inference attacks against adversarially robust deep learning models. L Song, R Shokri, P Mittal, Proc. IEEE Secur. Privacy Workshops (SPW). IEEE Secur. Privacy Workshops (SPW)San Francisco, CA, USAL. Song, R. Shokri, and P. Mittal, \"Membership inference attacks against adversarially robust deep learning models,\" in Proc. IEEE Secur. Privacy Workshops (SPW), San Francisco, CA, USA, May 2019, pp. 50-56.\n\nKnockoff nets: Stealing functionality of black-box models. T Orekondy, B Schiele, M Fritz, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR). IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR)Long Beach, CA, USAT. Orekondy, B. Schiele, and M. Fritz, \"Knockoff nets: Stealing func- tionality of black-box models,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), Long Beach, CA, USA, Jun. 2019, pp. 4954-4963.\n\nIncremental cryptography: The case of hashing and signing. M Bellare, O Goldreich, S Goldwasser, Proc. 14th Annu. Int. Cryptol. Conf. Adv. Cryptol. (CRYPTO). 14th Annu. Int. Cryptol. Conf. Adv. Cryptol. (CRYPTO)Santa Barbara, CA, USAM. Bellare, O. Goldreich, and S. Goldwasser, \"Incremental cryptogra- phy: The case of hashing and signing,\" in Proc. 14th Annu. Int. Cryptol. Conf. Adv. Cryptol. (CRYPTO), Santa Barbara, CA, USA, Aug. 1994, pp. 216-233.\n\nOn-the-fly verification of rateless erasure codes for efficient content distribution. M N Krohn, M J Freedman, D Mazieres, Proc. IEEE Symp. Secur. Privacy. IEEE Symp. Secur. PrivacyM. N. Krohn, M. J. Freedman, and D. Mazieres, \"On-the-fly verification of rateless erasure codes for efficient content distribution,\" in Proc. IEEE Symp. Secur. Privacy, May 2004, pp. 226-240.\n\nHow to Simulate It-A Tutorial on the Simulation Proof Technique. Y Lindell, SpringerCham, SwitzerlandY. Lindell, How to Simulate It-A Tutorial on the Simulation Proof Technique. Cham, Switzerland: Springer, 2017, pp. 277-346.\n\nThe wonderful world of global random oracles. J Camenisch, M Drijvers, T Gagliardoni, A Lehmann, G Neven, Proc. 37th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EURO-CRYPT). 37th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EURO-CRYPT)Part I, Tel Aviv, IsraelJ. Camenisch, M. Drijvers, T. Gagliardoni, A. Lehmann, and G. Neven, \"The wonderful world of global random oracles,\" in Proc. 37th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EURO- CRYPT), Part I, Tel Aviv, Israel, Apr./May 2018, pp. 280-312.\n\nFaster secure two-party computation using garbled circuits. Y Huang, D Evans, J Katz, L Malka, Proc. USENIX Secur. Symp. USENIX Secur. Symp201Y. Huang, D. Evans, J. Katz, and L. Malka, \"Faster secure two-party computation using garbled circuits,\" in Proc. USENIX Secur. Symp., 2011, vol. 201, no. 1, pp. 331-335.\n\nAn efficient protocol for secure twoparty computation in the presence of malicious adversaries. Y Lindell, B Pinkas, Proc. 26th Annu. Int. Conf. Theory Appl. 26th Annu. Int. Conf. Theory ApplBarcelona, SpainY. Lindell and B. Pinkas, \"An efficient protocol for secure two- party computation in the presence of malicious adversaries,\" in Proc. 26th Annu. Int. Conf. Theory Appl. Cryptograph. Techn. Adv. Cryptol. (EUROCRYPT), Barcelona, Spain, May 2007, pp. 52-78.\n\nGazelle: A low latency framework for secure neural network inference. C Juvekar, V Vaikuntanathan, A Chandrakasan, Proc. 27th USENIX Secur. Symp. (USENIX Secur.). 27th USENIX Secur. Symp. (USENIX Secur.)C. Juvekar, V. Vaikuntanathan, and A. Chandrakasan, \"Gazelle: A low latency framework for secure neural network inference,\" in Proc. 27th USENIX Secur. Symp. (USENIX Secur.), 2018, pp. 1651-1669.\n\nXonn: Xnor-based oblivious deep neural network inference. M S Riazi, M Samragh, H Chen, K Laine, K E Lauter, F Koushanfar, Proc. 28th USENIX Secur. Symp. (USENIX Secur.). 28th USENIX Secur. Symp. (USENIX Secur.)Santa Clara, CA, USAM. S. Riazi, M. Samragh, H. Chen, K. Laine, K. E. Lauter, and F. Koushanfar, \"Xonn: Xnor-based oblivious deep neural network infer- ence,\" in Proc. 28th USENIX Secur. Symp. (USENIX Secur.), Santa Clara, CA, USA, Aug. 2019, pp. 1501-1518.\n\nOblivious neural network predictions via MiniONN transformations. J Liu, M Juuti, Y Lu, N Asokan, Proc. ACM SIGSAC Conf. ACM SIGSAC ConfJ. Liu, M. Juuti, Y. Lu, and N. Asokan, \"Oblivious neural network predictions via MiniONN transformations,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., Oct. 2017, pp. 619-631.\n\nEfficient multi-key homomorphic encryption with packed ciphertexts with application to oblivious neural network inference. H Chen, W Dai, M Kim, Y Song, Proc. ACM SIGSAC Conf. Comput. Commun. Secur. ACM SIGSAC Conf. Comput. Commun. SecurH. Chen, W. Dai, M. Kim, and Y. Song, \"Efficient multi-key homomor- phic encryption with packed ciphertexts with application to oblivious neural network inference,\" in Proc. ACM SIGSAC Conf. Comput. Com- mun. Secur., 2019, pp. 395-412.\n\nCryptonets: Applying neural networks to encrypted data with high throughput and accuracy. R Gilad-Bachrach, N Dowlin, K Laine, K E Lauter, M Naehrig, J Wernsing, Proc. 33nd Int. Conf. Mach. Learn. (ICML). 33nd Int. Conf. Mach. Learn. (ICML)New York City, NY, USAR. Gilad-Bachrach, N. Dowlin, K. Laine, K. E. Lauter, M. Naehrig, and J. Wernsing, \"Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy,\" in Proc. 33nd Int. Conf. Mach. Learn. (ICML), New York City, NY, USA, Jun. 2016, pp. 201-210.\n\nABY 3 : A mixed protocol framework for machine learning. P Mohassel, P , Proc. ACM SIGSAC Conf. ACM SIGSAC ConfP. Mohassel and P. Rindal, \"ABY 3 : A mixed protocol framework for machine learning,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., 2018, pp. 35-52.\n\nQUOTIENT: Two-party secure neural network training and prediction. N Agrawal, A Shamsabadi, M J Kusner, A Gasc\u00f3n, Proc. ACM SIGSAC Conf. ACM SIGSAC ConfN. Agrawal, A. Shahin Shamsabadi, M. J. Kusner, and A. Gasc\u00f3n, \"QUOTIENT: Two-party secure neural network training and predic- tion,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., 2019, pp. 1231-1247.\n\nNew primitives for actively-secure MPC over rings with applications to private machine learning. I Damgard, D Escudero, T Frederiksen, M Keller, P Scholl, N Volgushev, Proc. IEEE Symp. Secur. Privacy (SP). IEEE Symp. Secur. Privacy (SP)I. Damgard, D. Escudero, T. Frederiksen, M. Keller, P. Scholl, and N. Volgushev, \"New primitives for actively-secure MPC over rings with applications to private machine learning,\" in Proc. IEEE Symp. Secur. Privacy (SP), May 2019, pp. 1102-1120.\n\nPrivacypreserving deep learning via additively homomorphic encryption. L T Phong, Y Aono, T Hayashi, L Wang, S Moriai, IEEE Trans. Inf. Forensics Security. 135L. T. Phong, Y. Aono, T. Hayashi, L. Wang, and S. Moriai, \"Privacy- preserving deep learning via additively homomorphic encryption,\" IEEE Trans. Inf. Forensics Security, vol. 13, no. 5, pp. 1333-1345, May 2018.\n\nPrivate machine learning classification based on fully homomorphic encryption. X Sun, P Zhang, J K Liu, J Yu, W Xie, IEEE Trans. Emerg. Topics Comput. 82X. Sun, P. Zhang, J. K. Liu, J. Yu, and W. Xie, \"Private machine learning classification based on fully homomorphic encryption,\" IEEE Trans. Emerg. Topics Comput., vol. 8, no. 2, pp. 352-364, Jun. 2020.\n\nThreshold cryptosystems from threshold fully homomorphic encryption. D Boneh, Proc. 38th Annu. Int. Cryptol. Conf. 38th Annu. Int. Cryptol. ConfSanta Barbara, CA, USAD. Boneh et al., \"Threshold cryptosystems from threshold fully homo- morphic encryption,\" in Proc. 38th Annu. Int. Cryptol. Conf., Santa Barbara, CA, USA, Aug. 2018, pp. 565-596.\n\nThreshold fully homomorphic encryption. A Jain, P M R Rasmussen, A Sahai, IACR Cryptol. ePrint Arch. 2017257A. Jain, P. M. R. Rasmussen, and A. Sahai, \"Threshold fully homo- morphic encryption,\" IACR Cryptol. ePrint Arch., vol. 2017, p. 257, Mar. 2017.\n\nThe algorithmic foundations of differential privacy. C Dwork, A Roth, Found. Trends Theor. Comput. Sci. 9C. Dwork and A. Roth, \"The algorithmic foundations of differential pri- vacy,\" Found. Trends Theor. Comput. Sci., vol. 9, nos. 3-4, pp. 211-407, 2014.\n\nDifferential privacy: A survey of results. C Dwork, Proc. Theory Appl. Models Comput., 5th Int. Conf. (TAMC). Theory Appl. Models Comput., 5th Int. Conf. (TAMC)Xi'an, ChinaC. Dwork, \"Differential privacy: A survey of results,\" in Proc. Theory Appl. Models Comput., 5th Int. Conf. (TAMC), Xi'an, China, Apr. 2008, pp. 1-19.\n\nDeep learning with differential privacy. M Abadi, Proc. ACM SIGSAC Conf. ACM SIGSAC ConfVienna, AustriaM. Abadi et al., \"Deep learning with differential privacy,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., Vienna, Austria, Oct. 2016, pp. 308-318.\n\nMechanism design via differential privacy. F Mcsherry, K Talwar, Proc. 48th Annu. IEEE Symp. Found. Comput. Sci. (FOCS). 48th Annu. IEEE Symp. Found. Comput. Sci. (FOCS)Providence, RI, USAF. McSherry and K. Talwar, \"Mechanism design via differential pri- vacy,\" in Proc. 48th Annu. IEEE Symp. Found. Comput. Sci. (FOCS), Providence, RI, USA, Oct. 2007, pp. 94-103.\n\nA hybrid approach to privacy-preserving federated learning. S Truex, Proc. 12th ACM Workshop Artif. Intell. Secur. (AISec). 12th ACM Workshop Artif. Intell. Secur. (AISec)S. Truex et al., \"A hybrid approach to privacy-preserving federated learning,\" in Proc. 12th ACM Workshop Artif. Intell. Secur. (AISec), 2019, pp. 1-11.\n\nFederated learning with differential privacy: Algorithms and performance analysis. K Wei, IEEE Trans. Inf. Forensics Security. 15K. Wei et al., \"Federated learning with differential privacy: Algorithms and performance analysis,\" IEEE Trans. Inf. Forensics Security, vol. 15, pp. 3454-3469, 2020.\n\nLearning differentially private recurrent language models. H B Mcmahan, D Ramage, K Talwar, L Zhang, Proc. 6th Int. Conf. Learn. Represent. (ICLR). 6th Int. Conf. Learn. Represent. (ICLR)Vancouver, BC, CanadaH. B. McMahan, D. Ramage, K. Talwar, and L. Zhang, \"Learning differentially private recurrent language models,\" in Proc. 6th Int. Conf. Learn. Represent. (ICLR), Vancouver, BC, Canada, Apr./May 2018.\n\nDifferentially private federated learning: A client level perspective. R C Geyer, T Klein, M Nabi, arXiv:1712.07557R. C. Geyer, T. Klein, and M. Nabi, \"Differentially private federated learning: A client level perspective,\" 2017, arXiv:1712.07557. [Online]. Available: http://arxiv.org/abs/1712.07557\n\nA generic framework for privacy preserving deep learning. T , arXiv:1811.04017T. Ryffel et al., \"A generic framework for privacy preserv- ing deep learning,\" 2018, arXiv:1811.04017. [Online]. Available: http://arxiv.org/abs/1811.04017\n\nDistributed statistical machine learning in adversarial settings: Byzantine gradient descent. Y Chen, L Su, J Xu, ACM Meas. Anal. Comput. Syst. 1244Y. Chen, L. Su, and J. Xu, \"Distributed statistical machine learning in adversarial settings: Byzantine gradient descent,\" ACM Meas. Anal. Comput. Syst., vol. 1, no. 2, p. 44, 2017.\n\nByzantinerobust distributed learning: Towards optimal statistical rates. D Yin, Y Chen, K Ramchandran, P L Bartlett, Proc. 35th Int. Conf. Mach. Learn. (ICML). 35th Int. Conf. Mach. Learn. (ICML)Stockholm, SwedenD. Yin, Y. Chen, K. Ramchandran, and P. L. Bartlett, \"Byzantine- robust distributed learning: Towards optimal statistical rates,\" in Proc. 35th Int. Conf. Mach. Learn. (ICML), Stockholm, Sweden, Jul. 2018, pp. 5636-5645.\n\nMachine learning with adversaries: Byzantine tolerant gradient descent. P Blanchard, E M E Mhamdi, R Guerraoui, J Stainer, Proc. nullP. Blanchard, E. M. E. Mhamdi, R. Guerraoui, and J. Stainer, \"Machine learning with adversaries: Byzantine tolerant gradient descent,\" in Proc.\n\n. Adv. Neural Inf. Process. Syst. Annu. Conf. Neural Inf. Process. Syst. Adv. Neural Inf. Process. Syst. Annu. Conf. Neural Inf. Process. Syst., Long Beach, CA, USA, Dec. 2017, pp. 119-129.\n\nByzantine-robust learning on heterogeneous datasets via resampling. L He, S P Karimireddy, M Jaggi, arXiv:2006.093652020L. He, S. P. Karimireddy, and M. Jaggi, \"Byzantine-robust learning on heterogeneous datasets via resampling,\" 2020, arXiv:2006.09365. [Online]. Available: https://arxiv.org/abs/2006.09365\n\nAdvances and open problems in federated learning. P Kairouz, arXiv:1912.04977P. Kairouz et al., \"Advances and open problems in feder- ated learning,\" 2019, arXiv:1912.04977. [Online]. Available: http://arxiv.org/abs/1912.04977\n", "annotations": {"author": "[{\"end\":102,\"start\":90},{\"end\":113,\"start\":103},{\"end\":140,\"start\":114},{\"end\":153,\"start\":141},{\"end\":163,\"start\":154},{\"end\":177,\"start\":164},{\"end\":201,\"start\":178}]", "publisher": null, "author_last_name": "[{\"end\":101,\"start\":98},{\"end\":112,\"start\":109},{\"end\":152,\"start\":149},{\"end\":162,\"start\":159},{\"end\":176,\"start\":172},{\"end\":200,\"start\":195}]", "author_first_name": "[{\"end\":97,\"start\":90},{\"end\":108,\"start\":103},{\"end\":136,\"start\":133},{\"end\":139,\"start\":137},{\"end\":148,\"start\":141},{\"end\":158,\"start\":154},{\"end\":171,\"start\":164},{\"end\":194,\"start\":190}]", "author_affiliation": null, "title": "[{\"end\":87,\"start\":1},{\"end\":288,\"start\":202}]", "venue": "[{\"end\":345,\"start\":290}]", "abstract": "[{\"end\":1664,\"start\":485}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2096,\"start\":2093},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2101,\"start\":2098},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2240,\"start\":2237},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2363,\"start\":2360},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2833,\"start\":2830},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2839,\"start\":2835},{\"end\":3694,\"start\":3681},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3779,\"start\":3776},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3784,\"start\":3781},{\"end\":4066,\"start\":4053},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4285,\"start\":4282},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5161,\"start\":5158},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5166,\"start\":5163},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5171,\"start\":5168},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5177,\"start\":5173},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5367,\"start\":5364},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5373,\"start\":5369},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5510,\"start\":5507},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6210,\"start\":6206},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6216,\"start\":6212},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7789,\"start\":7786},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8800,\"start\":8797},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9498,\"start\":9495},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9753,\"start\":9750},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":12785,\"start\":12782},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13004,\"start\":13001},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13614,\"start\":13611},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14644,\"start\":14640},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":14650,\"start\":14646},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14941,\"start\":14938},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":15362,\"start\":15359},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17348,\"start\":17344},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":25482,\"start\":25478},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":25488,\"start\":25484},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":25494,\"start\":25490},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26179,\"start\":26176},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":26871,\"start\":26868},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":27002,\"start\":26999},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":28918,\"start\":28914},{\"end\":34379,\"start\":34366},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":34486,\"start\":34483},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":36722,\"start\":36718},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":37950,\"start\":37947},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38636,\"start\":38633},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":39121,\"start\":39118},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":39654,\"start\":39651},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":39796,\"start\":39793},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":40453,\"start\":40450},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":40710,\"start\":40707},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":43290,\"start\":43286},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":43296,\"start\":43292},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":43302,\"start\":43298},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":43479,\"start\":43475},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":43485,\"start\":43481},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":43491,\"start\":43487},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":43620,\"start\":43616},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":43643,\"start\":43639},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":43649,\"start\":43645},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":43741,\"start\":43737},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":43747,\"start\":43743},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":44569,\"start\":44565},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":44575,\"start\":44571},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":44739,\"start\":44735},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":44745,\"start\":44741},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":44974,\"start\":44970},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":45440,\"start\":45436},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":45446,\"start\":45442},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":45875,\"start\":45871},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":45881,\"start\":45877},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":45967,\"start\":45963},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":45973,\"start\":45969},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":46702,\"start\":46699},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":46761,\"start\":46758},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":47323,\"start\":47319},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":47329,\"start\":47325},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":47781,\"start\":47777},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":47787,\"start\":47783},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":47836,\"start\":47832},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":47842,\"start\":47838},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":47919,\"start\":47915},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":47925,\"start\":47921},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":49103,\"start\":49099},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":49109,\"start\":49105},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":49240,\"start\":49236},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":49282,\"start\":49278},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":49863,\"start\":49859},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":49869,\"start\":49865},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":52406,\"start\":52403},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":52892,\"start\":52889}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":51880,\"start\":51694},{\"attributes\":{\"id\":\"fig_1\"},\"end\":52212,\"start\":51881},{\"attributes\":{\"id\":\"fig_2\"},\"end\":52407,\"start\":52213},{\"attributes\":{\"id\":\"fig_3\"},\"end\":52493,\"start\":52408},{\"attributes\":{\"id\":\"fig_4\"},\"end\":52578,\"start\":52494},{\"attributes\":{\"id\":\"fig_5\"},\"end\":52664,\"start\":52579},{\"attributes\":{\"id\":\"fig_6\"},\"end\":52832,\"start\":52665},{\"attributes\":{\"id\":\"fig_7\"},\"end\":53410,\"start\":52833},{\"attributes\":{\"id\":\"fig_8\"},\"end\":53807,\"start\":53411},{\"attributes\":{\"id\":\"fig_9\"},\"end\":54203,\"start\":53808},{\"attributes\":{\"id\":\"fig_10\"},\"end\":54704,\"start\":54204},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":54955,\"start\":54705},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":55269,\"start\":54956},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":55417,\"start\":55270},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":55480,\"start\":55418},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":55557,\"start\":55481},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":55625,\"start\":55558},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":55703,\"start\":55626}]", "paragraph": "[{\"end\":1982,\"start\":1666},{\"end\":3162,\"start\":1984},{\"end\":3567,\"start\":3164},{\"end\":3646,\"start\":3569},{\"end\":4067,\"start\":3648},{\"end\":5178,\"start\":4069},{\"end\":6422,\"start\":5180},{\"end\":6999,\"start\":6424},{\"end\":7781,\"start\":7001},{\"end\":8395,\"start\":7783},{\"end\":8947,\"start\":8397},{\"end\":9336,\"start\":8949},{\"end\":9962,\"start\":9338},{\"end\":11590,\"start\":9964},{\"end\":11830,\"start\":11592},{\"end\":12753,\"start\":11905},{\"end\":13195,\"start\":12779},{\"end\":13534,\"start\":13306},{\"end\":14213,\"start\":13559},{\"end\":14942,\"start\":14215},{\"end\":16176,\"start\":14944},{\"end\":17106,\"start\":16241},{\"end\":17396,\"start\":17108},{\"end\":18016,\"start\":17398},{\"end\":18257,\"start\":18113},{\"end\":18381,\"start\":18334},{\"end\":18531,\"start\":18500},{\"end\":18834,\"start\":18778},{\"end\":19668,\"start\":18836},{\"end\":19828,\"start\":19670},{\"end\":20035,\"start\":19830},{\"end\":21058,\"start\":20037},{\"end\":21227,\"start\":21060},{\"end\":21424,\"start\":21395},{\"end\":21723,\"start\":21426},{\"end\":21868,\"start\":21745},{\"end\":21955,\"start\":21870},{\"end\":22384,\"start\":21957},{\"end\":22581,\"start\":22407},{\"end\":23187,\"start\":22583},{\"end\":23582,\"start\":23298},{\"end\":24057,\"start\":23635},{\"end\":24271,\"start\":24059},{\"end\":24518,\"start\":24319},{\"end\":25213,\"start\":24571},{\"end\":25974,\"start\":25215},{\"end\":26403,\"start\":25976},{\"end\":26552,\"start\":26479},{\"end\":27573,\"start\":26598},{\"end\":27747,\"start\":27612},{\"end\":28771,\"start\":27773},{\"end\":29268,\"start\":28773},{\"end\":29587,\"start\":29270},{\"end\":30774,\"start\":29775},{\"end\":31210,\"start\":30977},{\"end\":31534,\"start\":31374},{\"end\":31781,\"start\":31762},{\"end\":32063,\"start\":31783},{\"end\":32853,\"start\":32065},{\"end\":33132,\"start\":32855},{\"end\":33488,\"start\":33415},{\"end\":33686,\"start\":33550},{\"end\":33907,\"start\":33716},{\"end\":33988,\"start\":33937},{\"end\":34232,\"start\":33990},{\"end\":36198,\"start\":34234},{\"end\":37226,\"start\":36240},{\"end\":37605,\"start\":37228},{\"end\":37708,\"start\":37607},{\"end\":38545,\"start\":37710},{\"end\":41585,\"start\":38606},{\"end\":41920,\"start\":41691},{\"end\":42513,\"start\":41946},{\"end\":42919,\"start\":42515},{\"end\":43052,\"start\":42940},{\"end\":44195,\"start\":43109},{\"end\":44682,\"start\":44252},{\"end\":45408,\"start\":44684},{\"end\":46703,\"start\":45410},{\"end\":46938,\"start\":46705},{\"end\":47788,\"start\":46966},{\"end\":48759,\"start\":47790},{\"end\":48903,\"start\":48795},{\"end\":49383,\"start\":48905},{\"end\":49804,\"start\":49385},{\"end\":50761,\"start\":49806},{\"end\":51376,\"start\":50781},{\"end\":51685,\"start\":51378}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13305,\"start\":13196},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18091,\"start\":18017},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18112,\"start\":18091},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18333,\"start\":18258},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18499,\"start\":18382},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18777,\"start\":18708},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21394,\"start\":21228},{\"attributes\":{\"id\":\"formula_7\"},\"end\":23297,\"start\":23188},{\"attributes\":{\"id\":\"formula_8\"},\"end\":23634,\"start\":23583},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24312,\"start\":24272},{\"attributes\":{\"id\":\"formula_10\"},\"end\":24318,\"start\":24312},{\"attributes\":{\"id\":\"formula_11\"},\"end\":26478,\"start\":26404},{\"attributes\":{\"id\":\"formula_12\"},\"end\":30976,\"start\":30775},{\"attributes\":{\"id\":\"formula_13\"},\"end\":31373,\"start\":31211},{\"attributes\":{\"id\":\"formula_14\"},\"end\":31761,\"start\":31535},{\"attributes\":{\"id\":\"formula_15\"},\"end\":33295,\"start\":33133},{\"attributes\":{\"id\":\"formula_16\"},\"end\":33414,\"start\":33295},{\"attributes\":{\"id\":\"formula_17\"},\"end\":33549,\"start\":33489},{\"attributes\":{\"id\":\"formula_18\"},\"end\":33715,\"start\":33687},{\"attributes\":{\"id\":\"formula_19\"},\"end\":33936,\"start\":33908}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":17917,\"start\":17900},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":39699,\"start\":39658}]", "section_header": "[{\"end\":11879,\"start\":11833},{\"end\":11903,\"start\":11882},{\"end\":12777,\"start\":12756},{\"end\":13557,\"start\":13537},{\"end\":16224,\"start\":16179},{\"end\":16239,\"start\":16227},{\"end\":18707,\"start\":18534},{\"end\":21743,\"start\":21726},{\"end\":22405,\"start\":22387},{\"end\":24569,\"start\":24521},{\"end\":26596,\"start\":26555},{\"end\":27610,\"start\":27576},{\"end\":27771,\"start\":27750},{\"end\":29773,\"start\":29590},{\"end\":36214,\"start\":36201},{\"end\":36238,\"start\":36217},{\"end\":38604,\"start\":38548},{\"end\":41625,\"start\":41588},{\"end\":41657,\"start\":41628},{\"end\":41689,\"start\":41660},{\"end\":41944,\"start\":41923},{\"end\":42938,\"start\":42922},{\"end\":43107,\"start\":43055},{\"end\":44250,\"start\":44198},{\"end\":46964,\"start\":46941},{\"end\":48793,\"start\":48762},{\"end\":50779,\"start\":50764},{\"end\":51693,\"start\":51688},{\"end\":51703,\"start\":51695},{\"end\":51883,\"start\":51882},{\"end\":52215,\"start\":52214},{\"end\":52417,\"start\":52409},{\"end\":52503,\"start\":52495},{\"end\":52588,\"start\":52580},{\"end\":52842,\"start\":52834},{\"end\":53420,\"start\":53412},{\"end\":53817,\"start\":53809},{\"end\":55282,\"start\":55271},{\"end\":55426,\"start\":55419},{\"end\":55499,\"start\":55482},{\"end\":55568,\"start\":55559},{\"end\":55644,\"start\":55627}]", "table": "[{\"end\":55417,\"start\":55326}]", "figure_caption": "[{\"end\":51880,\"start\":51705},{\"end\":52212,\"start\":51884},{\"end\":52407,\"start\":52216},{\"end\":52493,\"start\":52419},{\"end\":52578,\"start\":52505},{\"end\":52664,\"start\":52590},{\"end\":52832,\"start\":52667},{\"end\":53410,\"start\":52844},{\"end\":53807,\"start\":53422},{\"end\":54203,\"start\":53819},{\"end\":54704,\"start\":54206},{\"end\":54955,\"start\":54707},{\"end\":55269,\"start\":54958},{\"end\":55326,\"start\":55284},{\"end\":55480,\"start\":55428},{\"end\":55557,\"start\":55502},{\"end\":55625,\"start\":55572},{\"end\":55703,\"start\":55647}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":1684,\"start\":1672},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2771,\"start\":2759},{\"end\":12963,\"start\":12957},{\"end\":13533,\"start\":13525},{\"end\":25212,\"start\":25205},{\"end\":26757,\"start\":26749},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26833,\"start\":26825},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27672,\"start\":27664},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27685,\"start\":27677},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":38932,\"start\":38924},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":38948,\"start\":38940},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":39362,\"start\":39354},{\"end\":40870,\"start\":40862},{\"end\":41339,\"start\":41333},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":42547,\"start\":42539},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":42560,\"start\":42552}]", "bib_author_first_name": "[{\"end\":58728,\"start\":58727},{\"end\":58736,\"start\":58729},{\"end\":58747,\"start\":58746},{\"end\":58756,\"start\":58755},{\"end\":58766,\"start\":58765},{\"end\":58777,\"start\":58776},{\"end\":59113,\"start\":59112},{\"end\":59124,\"start\":59123},{\"end\":59132,\"start\":59125},{\"end\":59143,\"start\":59142},{\"end\":59145,\"start\":59144},{\"end\":59151,\"start\":59150},{\"end\":59164,\"start\":59163},{\"end\":59173,\"start\":59165},{\"end\":59183,\"start\":59182},{\"end\":59503,\"start\":59502},{\"end\":59764,\"start\":59763},{\"end\":59773,\"start\":59772},{\"end\":59785,\"start\":59784},{\"end\":60143,\"start\":60142},{\"end\":60152,\"start\":60151},{\"end\":60160,\"start\":60159},{\"end\":60163,\"start\":60161},{\"end\":60177,\"start\":60176},{\"end\":60585,\"start\":60584},{\"end\":60593,\"start\":60592},{\"end\":60603,\"start\":60602},{\"end\":61001,\"start\":61000},{\"end\":61273,\"start\":61272},{\"end\":61279,\"start\":61278},{\"end\":61285,\"start\":61284},{\"end\":61292,\"start\":61291},{\"end\":61300,\"start\":61299},{\"end\":61546,\"start\":61545},{\"end\":61561,\"start\":61560},{\"end\":61569,\"start\":61568},{\"end\":61576,\"start\":61575},{\"end\":61586,\"start\":61585},{\"end\":61823,\"start\":61822},{\"end\":61831,\"start\":61830},{\"end\":61838,\"start\":61837},{\"end\":61844,\"start\":61843},{\"end\":61850,\"start\":61849},{\"end\":62110,\"start\":62109},{\"end\":62419,\"start\":62418},{\"end\":62430,\"start\":62429},{\"end\":62721,\"start\":62720},{\"end\":62732,\"start\":62731},{\"end\":62748,\"start\":62744},{\"end\":62758,\"start\":62757},{\"end\":63083,\"start\":63082},{\"end\":63094,\"start\":63093},{\"end\":63104,\"start\":63103},{\"end\":63113,\"start\":63112},{\"end\":63510,\"start\":63509},{\"end\":63520,\"start\":63519},{\"end\":63530,\"start\":63529},{\"end\":64013,\"start\":64012},{\"end\":64023,\"start\":64022},{\"end\":64034,\"start\":64033},{\"end\":64046,\"start\":64045},{\"end\":64056,\"start\":64055},{\"end\":64539,\"start\":64538},{\"end\":64550,\"start\":64549},{\"end\":64561,\"start\":64560},{\"end\":64851,\"start\":64850},{\"end\":64864,\"start\":64863},{\"end\":64874,\"start\":64873},{\"end\":65166,\"start\":65162},{\"end\":65538,\"start\":65537},{\"end\":65549,\"start\":65548},{\"end\":65562,\"start\":65558},{\"end\":65899,\"start\":65898},{\"end\":65908,\"start\":65907},{\"end\":65916,\"start\":65915},{\"end\":66379,\"start\":66378},{\"end\":66393,\"start\":66392},{\"end\":66400,\"start\":66399},{\"end\":66791,\"start\":66790},{\"end\":66799,\"start\":66798},{\"end\":66811,\"start\":66807},{\"end\":66820,\"start\":66819},{\"end\":67162,\"start\":67161},{\"end\":67172,\"start\":67171},{\"end\":67184,\"start\":67183},{\"end\":67192,\"start\":67191},{\"end\":67566,\"start\":67565},{\"end\":67574,\"start\":67573},{\"end\":67584,\"start\":67583},{\"end\":67962,\"start\":67961},{\"end\":67974,\"start\":67973},{\"end\":67985,\"start\":67984},{\"end\":68397,\"start\":68396},{\"end\":68408,\"start\":68407},{\"end\":68421,\"start\":68420},{\"end\":68878,\"start\":68877},{\"end\":68880,\"start\":68879},{\"end\":68889,\"start\":68888},{\"end\":68891,\"start\":68890},{\"end\":68903,\"start\":68902},{\"end\":69232,\"start\":69231},{\"end\":69440,\"start\":69439},{\"end\":69453,\"start\":69452},{\"end\":69465,\"start\":69464},{\"end\":69480,\"start\":69479},{\"end\":69491,\"start\":69490},{\"end\":70019,\"start\":70018},{\"end\":70028,\"start\":70027},{\"end\":70037,\"start\":70036},{\"end\":70045,\"start\":70044},{\"end\":70369,\"start\":70368},{\"end\":70380,\"start\":70379},{\"end\":70807,\"start\":70806},{\"end\":70818,\"start\":70817},{\"end\":70836,\"start\":70835},{\"end\":71195,\"start\":71194},{\"end\":71197,\"start\":71196},{\"end\":71206,\"start\":71205},{\"end\":71217,\"start\":71216},{\"end\":71225,\"start\":71224},{\"end\":71234,\"start\":71233},{\"end\":71236,\"start\":71235},{\"end\":71246,\"start\":71245},{\"end\":71673,\"start\":71672},{\"end\":71680,\"start\":71679},{\"end\":71689,\"start\":71688},{\"end\":71695,\"start\":71694},{\"end\":72049,\"start\":72048},{\"end\":72057,\"start\":72056},{\"end\":72064,\"start\":72063},{\"end\":72071,\"start\":72070},{\"end\":72490,\"start\":72489},{\"end\":72508,\"start\":72507},{\"end\":72518,\"start\":72517},{\"end\":72527,\"start\":72526},{\"end\":72529,\"start\":72528},{\"end\":72539,\"start\":72538},{\"end\":72550,\"start\":72549},{\"end\":72989,\"start\":72988},{\"end\":73001,\"start\":73000},{\"end\":73264,\"start\":73263},{\"end\":73275,\"start\":73274},{\"end\":73289,\"start\":73288},{\"end\":73291,\"start\":73290},{\"end\":73301,\"start\":73300},{\"end\":73652,\"start\":73651},{\"end\":73663,\"start\":73662},{\"end\":73675,\"start\":73674},{\"end\":73690,\"start\":73689},{\"end\":73700,\"start\":73699},{\"end\":73710,\"start\":73709},{\"end\":74109,\"start\":74108},{\"end\":74111,\"start\":74110},{\"end\":74120,\"start\":74119},{\"end\":74128,\"start\":74127},{\"end\":74139,\"start\":74138},{\"end\":74147,\"start\":74146},{\"end\":74488,\"start\":74487},{\"end\":74495,\"start\":74494},{\"end\":74504,\"start\":74503},{\"end\":74506,\"start\":74505},{\"end\":74513,\"start\":74512},{\"end\":74519,\"start\":74518},{\"end\":74835,\"start\":74834},{\"end\":75152,\"start\":75151},{\"end\":75160,\"start\":75159},{\"end\":75164,\"start\":75161},{\"end\":75177,\"start\":75176},{\"end\":75419,\"start\":75418},{\"end\":75428,\"start\":75427},{\"end\":75666,\"start\":75665},{\"end\":75988,\"start\":75987},{\"end\":76245,\"start\":76244},{\"end\":76257,\"start\":76256},{\"end\":76628,\"start\":76627},{\"end\":76976,\"start\":76975},{\"end\":77249,\"start\":77248},{\"end\":77251,\"start\":77250},{\"end\":77262,\"start\":77261},{\"end\":77272,\"start\":77271},{\"end\":77282,\"start\":77281},{\"end\":77670,\"start\":77669},{\"end\":77672,\"start\":77671},{\"end\":77681,\"start\":77680},{\"end\":77690,\"start\":77689},{\"end\":77959,\"start\":77958},{\"end\":78231,\"start\":78230},{\"end\":78239,\"start\":78238},{\"end\":78245,\"start\":78244},{\"end\":78541,\"start\":78540},{\"end\":78548,\"start\":78547},{\"end\":78556,\"start\":78555},{\"end\":78571,\"start\":78570},{\"end\":78573,\"start\":78572},{\"end\":78974,\"start\":78973},{\"end\":78987,\"start\":78986},{\"end\":78991,\"start\":78988},{\"end\":79001,\"start\":79000},{\"end\":79014,\"start\":79013},{\"end\":79439,\"start\":79438},{\"end\":79445,\"start\":79444},{\"end\":79447,\"start\":79446},{\"end\":79462,\"start\":79461},{\"end\":79730,\"start\":79729}]", "bib_author_last_name": "[{\"end\":58744,\"start\":58737},{\"end\":58753,\"start\":58748},{\"end\":58763,\"start\":58757},{\"end\":58774,\"start\":58767},{\"end\":58792,\"start\":58778},{\"end\":59121,\"start\":59114},{\"end\":59140,\"start\":59133},{\"end\":59148,\"start\":59146},{\"end\":59161,\"start\":59152},{\"end\":59180,\"start\":59174},{\"end\":59189,\"start\":59184},{\"end\":59512,\"start\":59504},{\"end\":59770,\"start\":59765},{\"end\":59782,\"start\":59774},{\"end\":59796,\"start\":59786},{\"end\":60149,\"start\":60144},{\"end\":60157,\"start\":60153},{\"end\":60174,\"start\":60164},{\"end\":60187,\"start\":60178},{\"end\":60590,\"start\":60586},{\"end\":60600,\"start\":60594},{\"end\":60614,\"start\":60604},{\"end\":61010,\"start\":61002},{\"end\":61276,\"start\":61274},{\"end\":61282,\"start\":61280},{\"end\":61289,\"start\":61286},{\"end\":61297,\"start\":61293},{\"end\":61304,\"start\":61301},{\"end\":61558,\"start\":61547},{\"end\":61566,\"start\":61562},{\"end\":61573,\"start\":61570},{\"end\":61583,\"start\":61577},{\"end\":61596,\"start\":61587},{\"end\":61828,\"start\":61824},{\"end\":61835,\"start\":61832},{\"end\":61841,\"start\":61839},{\"end\":61847,\"start\":61845},{\"end\":61855,\"start\":61851},{\"end\":62114,\"start\":62111},{\"end\":62427,\"start\":62420},{\"end\":62439,\"start\":62431},{\"end\":62729,\"start\":62722},{\"end\":62742,\"start\":62733},{\"end\":62755,\"start\":62749},{\"end\":62764,\"start\":62759},{\"end\":63091,\"start\":63084},{\"end\":63101,\"start\":63095},{\"end\":63110,\"start\":63105},{\"end\":63122,\"start\":63114},{\"end\":63517,\"start\":63511},{\"end\":63527,\"start\":63521},{\"end\":63537,\"start\":63531},{\"end\":64020,\"start\":64014},{\"end\":64031,\"start\":64024},{\"end\":64043,\"start\":64035},{\"end\":64053,\"start\":64047},{\"end\":64061,\"start\":64057},{\"end\":64547,\"start\":64540},{\"end\":64558,\"start\":64551},{\"end\":64568,\"start\":64562},{\"end\":64861,\"start\":64852},{\"end\":64871,\"start\":64865},{\"end\":64884,\"start\":64875},{\"end\":65171,\"start\":65167},{\"end\":65546,\"start\":65539},{\"end\":65556,\"start\":65550},{\"end\":65567,\"start\":65563},{\"end\":65905,\"start\":65900},{\"end\":65913,\"start\":65909},{\"end\":65922,\"start\":65917},{\"end\":66390,\"start\":66380},{\"end\":66397,\"start\":66394},{\"end\":66411,\"start\":66401},{\"end\":66796,\"start\":66792},{\"end\":66805,\"start\":66800},{\"end\":66817,\"start\":66812},{\"end\":66826,\"start\":66821},{\"end\":67169,\"start\":67163},{\"end\":67181,\"start\":67173},{\"end\":67189,\"start\":67185},{\"end\":67202,\"start\":67193},{\"end\":67571,\"start\":67567},{\"end\":67581,\"start\":67575},{\"end\":67591,\"start\":67585},{\"end\":67971,\"start\":67963},{\"end\":67982,\"start\":67975},{\"end\":67991,\"start\":67986},{\"end\":68405,\"start\":68398},{\"end\":68418,\"start\":68409},{\"end\":68432,\"start\":68422},{\"end\":68886,\"start\":68881},{\"end\":68900,\"start\":68892},{\"end\":68912,\"start\":68904},{\"end\":69240,\"start\":69233},{\"end\":69450,\"start\":69441},{\"end\":69462,\"start\":69454},{\"end\":69477,\"start\":69466},{\"end\":69488,\"start\":69481},{\"end\":69497,\"start\":69492},{\"end\":70025,\"start\":70020},{\"end\":70034,\"start\":70029},{\"end\":70042,\"start\":70038},{\"end\":70051,\"start\":70046},{\"end\":70377,\"start\":70370},{\"end\":70387,\"start\":70381},{\"end\":70815,\"start\":70808},{\"end\":70833,\"start\":70819},{\"end\":70849,\"start\":70837},{\"end\":71203,\"start\":71198},{\"end\":71214,\"start\":71207},{\"end\":71222,\"start\":71218},{\"end\":71231,\"start\":71226},{\"end\":71243,\"start\":71237},{\"end\":71257,\"start\":71247},{\"end\":71677,\"start\":71674},{\"end\":71686,\"start\":71681},{\"end\":71692,\"start\":71690},{\"end\":71702,\"start\":71696},{\"end\":72054,\"start\":72050},{\"end\":72061,\"start\":72058},{\"end\":72068,\"start\":72065},{\"end\":72076,\"start\":72072},{\"end\":72505,\"start\":72491},{\"end\":72515,\"start\":72509},{\"end\":72524,\"start\":72519},{\"end\":72536,\"start\":72530},{\"end\":72547,\"start\":72540},{\"end\":72559,\"start\":72551},{\"end\":72998,\"start\":72990},{\"end\":73272,\"start\":73265},{\"end\":73286,\"start\":73276},{\"end\":73298,\"start\":73292},{\"end\":73308,\"start\":73302},{\"end\":73660,\"start\":73653},{\"end\":73672,\"start\":73664},{\"end\":73687,\"start\":73676},{\"end\":73697,\"start\":73691},{\"end\":73707,\"start\":73701},{\"end\":73720,\"start\":73711},{\"end\":74117,\"start\":74112},{\"end\":74125,\"start\":74121},{\"end\":74136,\"start\":74129},{\"end\":74144,\"start\":74140},{\"end\":74154,\"start\":74148},{\"end\":74492,\"start\":74489},{\"end\":74501,\"start\":74496},{\"end\":74510,\"start\":74507},{\"end\":74516,\"start\":74514},{\"end\":74523,\"start\":74520},{\"end\":74841,\"start\":74836},{\"end\":75157,\"start\":75153},{\"end\":75174,\"start\":75165},{\"end\":75183,\"start\":75178},{\"end\":75425,\"start\":75420},{\"end\":75433,\"start\":75429},{\"end\":75672,\"start\":75667},{\"end\":75994,\"start\":75989},{\"end\":76254,\"start\":76246},{\"end\":76264,\"start\":76258},{\"end\":76634,\"start\":76629},{\"end\":76980,\"start\":76977},{\"end\":77259,\"start\":77252},{\"end\":77269,\"start\":77263},{\"end\":77279,\"start\":77273},{\"end\":77288,\"start\":77283},{\"end\":77678,\"start\":77673},{\"end\":77687,\"start\":77682},{\"end\":77695,\"start\":77691},{\"end\":78236,\"start\":78232},{\"end\":78242,\"start\":78240},{\"end\":78248,\"start\":78246},{\"end\":78545,\"start\":78542},{\"end\":78553,\"start\":78549},{\"end\":78568,\"start\":78557},{\"end\":78582,\"start\":78574},{\"end\":78984,\"start\":78975},{\"end\":78998,\"start\":78992},{\"end\":79011,\"start\":79002},{\"end\":79022,\"start\":79015},{\"end\":79442,\"start\":79440},{\"end\":79459,\"start\":79448},{\"end\":79468,\"start\":79463},{\"end\":79738,\"start\":79731}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1602.05629\",\"id\":\"b0\"},\"end\":59039,\"start\":58652},{\"attributes\":{\"doi\":\"arXiv:1610.05492\",\"id\":\"b1\"},\"end\":59448,\"start\":59041},{\"attributes\":{\"doi\":\"arXiv:1902.01046\",\"id\":\"b2\"},\"end\":59680,\"start\":59450},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":5051282},\"end\":60075,\"start\":59682},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":53099247},\"end\":60442,\"start\":60077},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":133091488},\"end\":60928,\"start\":60444},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3833774},\"end\":61217,\"start\":60930},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":199579523},\"end\":61507,\"start\":61219},{\"attributes\":{\"doi\":\"arXiv:1807.00459\",\"id\":\"b8\"},\"end\":61747,\"start\":61509},{\"attributes\":{\"doi\":\"arXiv:1712.05526\",\"id\":\"b9\"},\"end\":62070,\"start\":61749},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":31806516},\"end\":62199,\"start\":62072},{\"attributes\":{\"id\":\"b11\"},\"end\":62339,\"start\":62201},{\"attributes\":{\"doi\":\"arXiv:1812.03128\",\"id\":\"b12\"},\"end\":62642,\"start\":62341},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":71147030},\"end\":63019,\"start\":62644},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":7445440},\"end\":63471,\"start\":63021},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":3972433},\"end\":63954,\"start\":63473},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":64580200},\"end\":64455,\"start\":63956},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3652354},\"end\":64819,\"start\":64457},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6669082},\"end\":65102,\"start\":64821},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1788583},\"end\":65475,\"start\":65104},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":14392550},\"end\":65825,\"start\":65477},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3124219},\"end\":66289,\"start\":65827},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":207229839},\"end\":66704,\"start\":66291},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":207941008},\"end\":67097,\"start\":66706},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":10488675},\"end\":67483,\"start\":67099},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":201598829},\"end\":67900,\"start\":67485},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":54457412},\"end\":68335,\"start\":67902},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":152162},\"end\":68789,\"start\":68337},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":6976686},\"end\":69164,\"start\":68791},{\"attributes\":{\"id\":\"b29\"},\"end\":69391,\"start\":69166},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":3774391},\"end\":69956,\"start\":69393},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":3850773},\"end\":70270,\"start\":69958},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":6751434},\"end\":70734,\"start\":70272},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":4046474},\"end\":71134,\"start\":70736},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":67771690},\"end\":71604,\"start\":71136},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":3617652},\"end\":71923,\"start\":71606},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":174780206},\"end\":72397,\"start\":71925},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":217485587},\"end\":72929,\"start\":72399},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":44182124},\"end\":73194,\"start\":72931},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":195833171},\"end\":73552,\"start\":73196},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":174769950},\"end\":74035,\"start\":73554},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":204815617},\"end\":74406,\"start\":74037},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":67278416},\"end\":74763,\"start\":74408},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":31616696},\"end\":75109,\"start\":74765},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":32775072},\"end\":75363,\"start\":75111},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":207178262},\"end\":75620,\"start\":75365},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2887752},\"end\":75944,\"start\":75622},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":207241585},\"end\":76199,\"start\":75946},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":17809969},\"end\":76565,\"start\":76201},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":54460482},\"end\":76890,\"start\":76567},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":207847853},\"end\":77187,\"start\":76892},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":3461939},\"end\":77596,\"start\":77189},{\"attributes\":{\"doi\":\"arXiv:1712.07557\",\"id\":\"b52\"},\"end\":77898,\"start\":77598},{\"attributes\":{\"doi\":\"arXiv:1811.04017\",\"id\":\"b53\"},\"end\":78134,\"start\":77900},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":58534983},\"end\":78465,\"start\":78136},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":3708326},\"end\":78899,\"start\":78467},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":28527385},\"end\":79177,\"start\":78901},{\"attributes\":{\"id\":\"b57\"},\"end\":79368,\"start\":79179},{\"attributes\":{\"doi\":\"arXiv:2006.09365\",\"id\":\"b58\"},\"end\":79677,\"start\":79370},{\"attributes\":{\"doi\":\"arXiv:1912.04977\",\"id\":\"b59\"},\"end\":79905,\"start\":79679}]", "bib_title": "[{\"end\":59761,\"start\":59682},{\"end\":60140,\"start\":60077},{\"end\":60582,\"start\":60444},{\"end\":60998,\"start\":60930},{\"end\":61270,\"start\":61219},{\"end\":62107,\"start\":62072},{\"end\":62718,\"start\":62644},{\"end\":63080,\"start\":63021},{\"end\":63507,\"start\":63473},{\"end\":64010,\"start\":63956},{\"end\":64536,\"start\":64457},{\"end\":64848,\"start\":64821},{\"end\":65160,\"start\":65104},{\"end\":65535,\"start\":65477},{\"end\":65896,\"start\":65827},{\"end\":66376,\"start\":66291},{\"end\":66788,\"start\":66706},{\"end\":67159,\"start\":67099},{\"end\":67563,\"start\":67485},{\"end\":67959,\"start\":67902},{\"end\":68394,\"start\":68337},{\"end\":68875,\"start\":68791},{\"end\":69437,\"start\":69393},{\"end\":70016,\"start\":69958},{\"end\":70366,\"start\":70272},{\"end\":70804,\"start\":70736},{\"end\":71192,\"start\":71136},{\"end\":71670,\"start\":71606},{\"end\":72046,\"start\":71925},{\"end\":72487,\"start\":72399},{\"end\":72986,\"start\":72931},{\"end\":73261,\"start\":73196},{\"end\":73649,\"start\":73554},{\"end\":74106,\"start\":74037},{\"end\":74485,\"start\":74408},{\"end\":74832,\"start\":74765},{\"end\":75149,\"start\":75111},{\"end\":75416,\"start\":75365},{\"end\":75663,\"start\":75622},{\"end\":75985,\"start\":75946},{\"end\":76242,\"start\":76201},{\"end\":76625,\"start\":76567},{\"end\":76973,\"start\":76892},{\"end\":77246,\"start\":77189},{\"end\":78228,\"start\":78136},{\"end\":78538,\"start\":78467},{\"end\":78971,\"start\":78901}]", "bib_author": "[{\"end\":58746,\"start\":58727},{\"end\":58755,\"start\":58746},{\"end\":58765,\"start\":58755},{\"end\":58776,\"start\":58765},{\"end\":58794,\"start\":58776},{\"end\":59123,\"start\":59112},{\"end\":59142,\"start\":59123},{\"end\":59150,\"start\":59142},{\"end\":59163,\"start\":59150},{\"end\":59182,\"start\":59163},{\"end\":59191,\"start\":59182},{\"end\":59514,\"start\":59502},{\"end\":59772,\"start\":59763},{\"end\":59784,\"start\":59772},{\"end\":59798,\"start\":59784},{\"end\":60151,\"start\":60142},{\"end\":60159,\"start\":60151},{\"end\":60176,\"start\":60159},{\"end\":60189,\"start\":60176},{\"end\":60592,\"start\":60584},{\"end\":60602,\"start\":60592},{\"end\":60616,\"start\":60602},{\"end\":61012,\"start\":61000},{\"end\":61278,\"start\":61272},{\"end\":61284,\"start\":61278},{\"end\":61291,\"start\":61284},{\"end\":61299,\"start\":61291},{\"end\":61306,\"start\":61299},{\"end\":61560,\"start\":61545},{\"end\":61568,\"start\":61560},{\"end\":61575,\"start\":61568},{\"end\":61585,\"start\":61575},{\"end\":61598,\"start\":61585},{\"end\":61830,\"start\":61822},{\"end\":61837,\"start\":61830},{\"end\":61843,\"start\":61837},{\"end\":61849,\"start\":61843},{\"end\":61857,\"start\":61849},{\"end\":62116,\"start\":62109},{\"end\":62429,\"start\":62418},{\"end\":62441,\"start\":62429},{\"end\":62731,\"start\":62720},{\"end\":62744,\"start\":62731},{\"end\":62757,\"start\":62744},{\"end\":62766,\"start\":62757},{\"end\":63093,\"start\":63082},{\"end\":63103,\"start\":63093},{\"end\":63112,\"start\":63103},{\"end\":63124,\"start\":63112},{\"end\":63519,\"start\":63509},{\"end\":63529,\"start\":63519},{\"end\":63539,\"start\":63529},{\"end\":64022,\"start\":64012},{\"end\":64033,\"start\":64022},{\"end\":64045,\"start\":64033},{\"end\":64055,\"start\":64045},{\"end\":64063,\"start\":64055},{\"end\":64549,\"start\":64538},{\"end\":64560,\"start\":64549},{\"end\":64570,\"start\":64560},{\"end\":64863,\"start\":64850},{\"end\":64873,\"start\":64863},{\"end\":64886,\"start\":64873},{\"end\":65173,\"start\":65162},{\"end\":65548,\"start\":65537},{\"end\":65558,\"start\":65548},{\"end\":65569,\"start\":65558},{\"end\":65907,\"start\":65898},{\"end\":65915,\"start\":65907},{\"end\":65924,\"start\":65915},{\"end\":66392,\"start\":66378},{\"end\":66399,\"start\":66392},{\"end\":66413,\"start\":66399},{\"end\":66798,\"start\":66790},{\"end\":66807,\"start\":66798},{\"end\":66819,\"start\":66807},{\"end\":66828,\"start\":66819},{\"end\":67171,\"start\":67161},{\"end\":67183,\"start\":67171},{\"end\":67191,\"start\":67183},{\"end\":67204,\"start\":67191},{\"end\":67573,\"start\":67565},{\"end\":67583,\"start\":67573},{\"end\":67593,\"start\":67583},{\"end\":67973,\"start\":67961},{\"end\":67984,\"start\":67973},{\"end\":67993,\"start\":67984},{\"end\":68407,\"start\":68396},{\"end\":68420,\"start\":68407},{\"end\":68434,\"start\":68420},{\"end\":68888,\"start\":68877},{\"end\":68902,\"start\":68888},{\"end\":68914,\"start\":68902},{\"end\":69242,\"start\":69231},{\"end\":69452,\"start\":69439},{\"end\":69464,\"start\":69452},{\"end\":69479,\"start\":69464},{\"end\":69490,\"start\":69479},{\"end\":69499,\"start\":69490},{\"end\":70027,\"start\":70018},{\"end\":70036,\"start\":70027},{\"end\":70044,\"start\":70036},{\"end\":70053,\"start\":70044},{\"end\":70379,\"start\":70368},{\"end\":70389,\"start\":70379},{\"end\":70817,\"start\":70806},{\"end\":70835,\"start\":70817},{\"end\":70851,\"start\":70835},{\"end\":71205,\"start\":71194},{\"end\":71216,\"start\":71205},{\"end\":71224,\"start\":71216},{\"end\":71233,\"start\":71224},{\"end\":71245,\"start\":71233},{\"end\":71259,\"start\":71245},{\"end\":71679,\"start\":71672},{\"end\":71688,\"start\":71679},{\"end\":71694,\"start\":71688},{\"end\":71704,\"start\":71694},{\"end\":72056,\"start\":72048},{\"end\":72063,\"start\":72056},{\"end\":72070,\"start\":72063},{\"end\":72078,\"start\":72070},{\"end\":72507,\"start\":72489},{\"end\":72517,\"start\":72507},{\"end\":72526,\"start\":72517},{\"end\":72538,\"start\":72526},{\"end\":72549,\"start\":72538},{\"end\":72561,\"start\":72549},{\"end\":73000,\"start\":72988},{\"end\":73004,\"start\":73000},{\"end\":73274,\"start\":73263},{\"end\":73288,\"start\":73274},{\"end\":73300,\"start\":73288},{\"end\":73310,\"start\":73300},{\"end\":73662,\"start\":73651},{\"end\":73674,\"start\":73662},{\"end\":73689,\"start\":73674},{\"end\":73699,\"start\":73689},{\"end\":73709,\"start\":73699},{\"end\":73722,\"start\":73709},{\"end\":74119,\"start\":74108},{\"end\":74127,\"start\":74119},{\"end\":74138,\"start\":74127},{\"end\":74146,\"start\":74138},{\"end\":74156,\"start\":74146},{\"end\":74494,\"start\":74487},{\"end\":74503,\"start\":74494},{\"end\":74512,\"start\":74503},{\"end\":74518,\"start\":74512},{\"end\":74525,\"start\":74518},{\"end\":74843,\"start\":74834},{\"end\":75159,\"start\":75151},{\"end\":75176,\"start\":75159},{\"end\":75185,\"start\":75176},{\"end\":75427,\"start\":75418},{\"end\":75435,\"start\":75427},{\"end\":75674,\"start\":75665},{\"end\":75996,\"start\":75987},{\"end\":76256,\"start\":76244},{\"end\":76266,\"start\":76256},{\"end\":76636,\"start\":76627},{\"end\":76982,\"start\":76975},{\"end\":77261,\"start\":77248},{\"end\":77271,\"start\":77261},{\"end\":77281,\"start\":77271},{\"end\":77290,\"start\":77281},{\"end\":77680,\"start\":77669},{\"end\":77689,\"start\":77680},{\"end\":77697,\"start\":77689},{\"end\":77962,\"start\":77958},{\"end\":78238,\"start\":78230},{\"end\":78244,\"start\":78238},{\"end\":78250,\"start\":78244},{\"end\":78547,\"start\":78540},{\"end\":78555,\"start\":78547},{\"end\":78570,\"start\":78555},{\"end\":78584,\"start\":78570},{\"end\":78986,\"start\":78973},{\"end\":79000,\"start\":78986},{\"end\":79013,\"start\":79000},{\"end\":79024,\"start\":79013},{\"end\":79444,\"start\":79438},{\"end\":79461,\"start\":79444},{\"end\":79470,\"start\":79461},{\"end\":79740,\"start\":79729}]", "bib_venue": "[{\"end\":59882,\"start\":59844},{\"end\":60257,\"start\":60227},{\"end\":60684,\"start\":60654},{\"end\":61050,\"start\":61035},{\"end\":62132,\"start\":62128},{\"end\":63250,\"start\":63180},{\"end\":63733,\"start\":63627},{\"end\":64217,\"start\":64133},{\"end\":64626,\"start\":64602},{\"end\":64962,\"start\":64928},{\"end\":65263,\"start\":65214},{\"end\":65653,\"start\":65615},{\"end\":66068,\"start\":65989},{\"end\":66476,\"start\":66441},{\"end\":66878,\"start\":66851},{\"end\":67289,\"start\":67242},{\"end\":67693,\"start\":67636},{\"end\":68124,\"start\":68053},{\"end\":68570,\"start\":68495},{\"end\":68972,\"start\":68947},{\"end\":69693,\"start\":69588},{\"end\":70097,\"start\":70079},{\"end\":70479,\"start\":70430},{\"end\":70939,\"start\":70899},{\"end\":71367,\"start\":71307},{\"end\":71742,\"start\":71727},{\"end\":72162,\"start\":72124},{\"end\":72661,\"start\":72604},{\"end\":73042,\"start\":73027},{\"end\":73348,\"start\":73333},{\"end\":73790,\"start\":73760},{\"end\":74931,\"start\":74880},{\"end\":75794,\"start\":75732},{\"end\":76049,\"start\":76019},{\"end\":76389,\"start\":76322},{\"end\":76738,\"start\":76691},{\"end\":77397,\"start\":77337},{\"end\":78679,\"start\":78627},{\"end\":79034,\"start\":79030},{\"end\":58725,\"start\":58652},{\"end\":59110,\"start\":59041},{\"end\":59500,\"start\":59450},{\"end\":59842,\"start\":59798},{\"end\":60225,\"start\":60189},{\"end\":60652,\"start\":60616},{\"end\":61033,\"start\":61012},{\"end\":61341,\"start\":61306},{\"end\":61543,\"start\":61509},{\"end\":61820,\"start\":61749},{\"end\":62126,\"start\":62116},{\"end\":62249,\"start\":62203},{\"end\":62416,\"start\":62341},{\"end\":62802,\"start\":62766},{\"end\":63178,\"start\":63124},{\"end\":63625,\"start\":63539},{\"end\":64131,\"start\":64063},{\"end\":64600,\"start\":64570},{\"end\":64926,\"start\":64886},{\"end\":65212,\"start\":65173},{\"end\":65613,\"start\":65569},{\"end\":65987,\"start\":65924},{\"end\":66439,\"start\":66413},{\"end\":66849,\"start\":66828},{\"end\":67240,\"start\":67204},{\"end\":67634,\"start\":67593},{\"end\":68051,\"start\":67993},{\"end\":68493,\"start\":68434},{\"end\":68945,\"start\":68914},{\"end\":69229,\"start\":69166},{\"end\":69586,\"start\":69499},{\"end\":70077,\"start\":70053},{\"end\":70428,\"start\":70389},{\"end\":70897,\"start\":70851},{\"end\":71305,\"start\":71259},{\"end\":71725,\"start\":71704},{\"end\":72122,\"start\":72078},{\"end\":72602,\"start\":72561},{\"end\":73025,\"start\":73004},{\"end\":73331,\"start\":73310},{\"end\":73758,\"start\":73722},{\"end\":74191,\"start\":74156},{\"end\":74557,\"start\":74525},{\"end\":74878,\"start\":74843},{\"end\":75210,\"start\":75185},{\"end\":75467,\"start\":75435},{\"end\":75730,\"start\":75674},{\"end\":76017,\"start\":75996},{\"end\":76320,\"start\":76266},{\"end\":76689,\"start\":76636},{\"end\":77017,\"start\":76982},{\"end\":77335,\"start\":77290},{\"end\":77667,\"start\":77598},{\"end\":77956,\"start\":77900},{\"end\":78278,\"start\":78250},{\"end\":78625,\"start\":78584},{\"end\":79028,\"start\":79024},{\"end\":79250,\"start\":79181},{\"end\":79436,\"start\":79370},{\"end\":79727,\"start\":79679}]"}}}, "year": 2023, "month": 12, "day": 17}