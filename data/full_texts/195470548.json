{"id": 195470548, "updated": "2022-02-06 11:18:56.926", "metadata": {"title": "Sensitive-Sample Fingerprinting of Deep Neural Networks", "authors": "[{\"middle\":[],\"last\":\"He\",\"first\":\"Zecheng\"},{\"middle\":[],\"last\":\"Zhang\",\"first\":\"Tianwei\"},{\"middle\":[],\"last\":\"Lee\",\"first\":\"Ruby\"}]", "venue": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Numerous cloud-based services are provided to help customers develop and deploy deep learning applications. When a customer deploys a deep learning model in the cloud and serves it to end-users, it is important to be able to verify that the deployed model has not been tampered with. In this paper, we propose a novel and practical methodology to verify the integrity of remote deep learning models, with only black-box access to the target models. Specifically, we define Sensitive-Sample fingerprints, which are a small set of human unnoticeable transformed inputs that make the model outputs sensitive to the model's parameters. Even small model changes can be clearly reflected in the model outputs. Experimental results on different types of model integrity attacks show that we proposed approach is both effective and efficient. It can detect model integrity breaches with high accuracy (>99.95%) and guaranteed zero false positives on all evaluated attacks. Meanwhile, it only requires up to 103X fewer model inferences, compared with non-sensitive samples.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2948833786", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/HeZL19", "doi": "10.1109/cvpr.2019.00486"}}, "content": {"source": {"pdf_hash": "a93d0d014a45ed46096dce0ac067c1899a90aae0", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "3057b3092f8eeb86b673db872fd1485204719843", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a93d0d014a45ed46096dce0ac067c1899a90aae0.txt", "contents": "\nSensitive-Sample Fingerprinting of Deep Neural Networks\n\n\nZecheng He zechengh@princeton.edu \nNo Affiliation\nPrinceton University\nPrinceton University\n\n\nTianwei Zhang tianweiz@alumni.princeton.edu \nNo Affiliation\nPrinceton University\nPrinceton University\n\n\nRuby Lee rblee@princeton.edu \nNo Affiliation\nPrinceton University\nPrinceton University\n\n\nSensitive-Sample Fingerprinting of Deep Neural Networks\n10.1109/CVPR.2019.00486\nNumerous cloud-based services are provided to help customers develop and deploy deep learning applications. When a customer deploys a deep learning model in the cloud and serves it to end-users, it is important to be able to verify that the deployed model has not been tampered with. In this paper, we propose a novel and practical methodology to verify the integrity of remote deep learning models, with only black-box access to the target models. Specifically, we define Sensitive-Sample fingerprints, which are a small set of human unnoticeable transformed inputs that make the model outputs sensitive to the model's parameters. Even small model changes can be clearly reflected in the model outputs. Experimental results on different types of model integrity attacks show that the proposed approach is both effective and efficient. It can detect model integrity breaches with high accuracy (>99.95%) and guaranteed zero false positives on all evaluated attacks. Meanwhile, it only requires up to 103\u00d7 fewer model inferences, compared to non-sensitive samples.\n\nIntroduction\n\nThe past few years have witnessed the fast development of deep learning (DL). One popular class of deep learning models is Deep Neural Networks (DNN), which has been widely adopted in many artificial intelligence applications, such as image recognition [20,25], natural language processing [11,28], speech recognition [19,13] and anomaly detection [29,21].\n\nTo make it automatic and convenient to deploy deep learning applications, many IT corporations offer cloudbased services for deep learning model training and serving, usually dubbed as Machine Learning as a Service (MLaaS). For example, Google Machine Learning Engine [1], Microsoft Azure ML Studio [2] and Amazon Sage-Maker framework [3] enable customers to deploy their models online and release query APIs to end users. Customers are charged on a pay-per-query basis.\n\nHowever, deploying deep learning tasks in MLaaS brings new security concerns. First, the model owner does not manage or have control over the actual model in the cloud any more. This gives adversaries opportunities to intentionally tamper with the remote models, to make it malfunction. Different attacks against model integrity have been proposed: e.g., DNN trojan attack [26,17,10], poisoning attack [7,30,34,31], etc. These attacks have been shown to be practical in various DNN-based applications, e.g. autonomous driving [17,26], user authentication [10] and speech recognition [26]. Figure 1 shows an example of attacking a deep learning based face recognition system: an adversary can insert a trojan into the authentication model by slightly modifying the face classifier. The compromised model can still give correct prediction results for original faces. However, it will mis-classify an arbitrary person with a specific pair of galsses as \"A. J. Buckley\". With this technique the adversary can easily bypass the authentication mechanism without being detected. Second, a dishonest cloud provider may stealthily violate the Service Level Agreement (SLA), without making the customers aware, for financial benefits [35,8]. For instance, the cloud provider can use a simpler or compressed model to replace the customers' models to save computational resources and storage [15]. Customers are annoyed with such SLA violations, even though it has a subtle impact on the model accuracy, as they pay more for the resources than they actually get.\n\nHowever, providing a methodology to protect the model integrity of DNN models deployed in clouds is challenging:\n\n(1) the complex cloud environment inevitably causes a big attack surface. (2) Once the customers submit their models to the clouds, the security status of the models are not transparent or directly verifiable to the customers. (3) For some model integrity attacks, the adversary only makes subtle modifications to the model, and wrong predictions only occur for specific attacker-chosen inputs which are imperceptible to the customers. (4) The cloud provider may not actively check the data integrity status in a timely manner. This gives adversaries opportunities to corrupt the models and cause damage before being detected.\n\nIn this paper, we are the first to show a new line of research where the integrity property of a DNN model can be dynamically verified by querying the model with a few carefully designed inputs. Specifically, we propose Sensitive-Samples fingerprinting, a new methodology for customers to verify the integrity of deep learning models stored in the cloud. The primary advantages of Sensitive-Samples are: x high effectiveness and reliability, > 99.95% attack detection rate on all evaluated attacks, y guaranteed zero false-positives, z high efficiency -although extensively querying the model with normal images may possibly detect the integrity breaches, it is very costly and inefficient on the pay-per-query basis. Our proposed approach achieves up to 103\u00d7 fewer model inferences and { requires only black-box accesses to the deployed model through APIs.\n\nThe key contributions of this paper are:\n\n\u2022 We are the first using carefully designed transformed inputs as a defense, to protect the integrity property of DNNs. \u2022 A novel and highly effective Sensitive-Samples generation approach for deep neural network integrity verification, achieving > 99.95% attack detection rate with only black-box accesses. \u2022 A Maximum Active-Neuron Cover sample selection algorithm to generate the fingerprint of a DNN model from Sensitive-Samples, reducing the number of required model inferences by up to 103\u00d7. \u2022 Comprehensive evaluation of our approach on different types of attacks on various applications and models.\n\nThe rest of the paper is organized as follows: Section 2 gives the background of deep neural networks, integrity attacks and defenses. Section 3 describes our new methodology of Sensitive-Sample fingerprinting. Section 4 introduces the experimental settings, datasets and attacks for evaluation. Section 5 gives the experimental results and discussions. We conclude the paper in Section 6.\n\n\nBackground and Related Work\n\n\nDeep Neural Networks\n\nA deep neural network (DNN) is a parameterized function f \u03b8 : X \u2192 Y that maps an input x \u2208 X to an output y \u2208 Y. A neural network usually consists of an input layer, an output layer and one or more hidden layers between the input and output. Each layer is a collection of units called neurons, connecting neurons in other layers.\n\nThe training process of a neural network is to find the optimal parameters \u03b8 that can accurately reflect the relationship between X and Y. To achieve this, the user needs a training dataset\nD train = {x train i , y train i } N i=1 with N sam- ples, where x train i\n\u2208 X is the input and y train i \u2208 Y is the corresponding ground-truth label. Then a loss function L is adopted to measure the errors between the ground-truth output y train i and the predicted output f \u03b8 (x train i ). The goal of training a neural network is to minimize this loss function (Eq (1)). After figuring out the optimal parameters \u03b8 * , given a testing input x test , the output y test = f \u03b8 * (x test ) can be predicted. This prediction is called inference.\n\u03b8 * = arg min \u03b8 ( N i=1 L(y train i , f \u03b8 (x train i )) (1)\n\nDNN Integrity Attacks and Defenses\n\nNeural network trojan attack. The attack goal is to inject a trojan into the model so that the model mis-classifies the samples containing a specific trigger [26,17]. To achieve this, given a pretrained DNN model, the adversary carefully selects some \"critical\" neurons which the outputs are highly dependent on. He modifies the weights on the path from the selected neurons to the last layer by retraining the model using the data with triggers. Targeted poisoning attack. The attack goal is to force the model to mis-classify a target class. The adversary achieves this by poisoning the dataset with carefully-crafted malicious samples. We consider two types of such attacks: the first one is error-generic poisoning attack [7,30,34], in which the outputs of the compromised model for the target class can be arbitrary. The second one is error-specific poisoning attack [31]: the adversary modifies the model to mis-classify the target class as a fixed class that he desires.\n\n\nModel compression attack.\n\nThe attacker's (cloud provider's) goal is to compress the DNN model with negligible accuracy drop, to save cloud storage for profit. There are different compression techniques to achieve this, e.g., pruning [18], quantization [16], low precision [12] and architecture optimization [24,23]. Defenses. Past work have been designed to defeat model integrity attacks. For DNN trojan attacks, Liu et al. [27] proposed to detect anomalies in the dataset, or remove the trojan via model retraining or input preprocessing. For data poisoning attacks, the typical solution is also to identify and remove the poisoning data from the dataset by statistical comparisons [9,32]. While these methods are effective locally on white-box models, they fail to protect black-box models served in a remote MLaaS platform.\n\nIn the scenario of remote deep learning service, Ghodsi [15] proposed a protocol to verify if an untrusted service provider cheats the model owner with a simpler and less accurate model. However, this approach can only be applied to a specific class of neural networks with polynomial activation functions, and does not support max pooling.\n\n\nSensitive-Sample Fingerprinting\n\n\nOverview\n\nWe consider the attack scenario in which the customer uploads a machine learning model f \u03b8 to the cloud provider for model serving. However, an adversary may compromise the model and stealthily change it to f \u03b8 . The customer wants to verify if the black-box model served by the cloud provider is actually the one he uploaded. Although extensively querying the model with normal images may detect the integrity breaches, it is very costly and inefficient on the pay-per-query basis.\n\nOur main idea is that, we can carefully generate a small set of transformed inputs {v i } n i=1 , whose outputs predicted by any compromised model will be different from the outputs predicted by the original intact model. We call such transformed inputs Sensitive-Samples. We use a small set of these transformed inputs and their corresponding correct model outputs as the fingerprint of the DNN\nmodel, i.e. FG = {(v i , f \u03b8 (v i ))} n i=1 .\nTo verify the integrity of a model, the customer first uses the correct model locally to generate Sensitive-Samples and obtain the corresponding output y = f \u03b8 (v). For verification, he simply sends these samples to the cloud provider and obtains the output y = f \u03b8 (v). By comparing y and y , the customer can check if the model is intact or changed.\n\nThere are some requirements in designing a good fingerprint, especially a good input transform, for integrity checking. We define a qualified fingerprint as one satisfying the following characteristics:\n\n\u2022 Effectiveness. The fingerprint must be sensitive to even subtle modification of model parameters. In some attacks, the adversary changes a small number of parameters, e.g. selective neuron modification [26]. \u2022 Efficiency. The fingerprint must be light-weight and efficient, in order to reduce the cost and overhead for the verification, and avoid raising any suspicions. \u2022 Black-box verification. The model served by the cloud provider is a black-box to the customer, thus the verification process must be feasible under this setting.\n\n\u2022 Hard to spot. The generated fingerprint should look similar to natural inputs so the adversary cannot recognize if it is used for integrity checking, or for normal model serving. \u2022 Generalizable. The fingerprint generation algorithm should be independent of the machine learning models, the training datasets and the attacks. It must be able to detect any unknown attacks.\n\n\nSingle Sensitive-Sample Generation\n\nA DNN model can be defined as a function y = f \u03b8 (x). Here \u03b8 is the set of all parameters in the model. We rewrite the model function as\ny = f (W, x) = [y 1 , ..., y r ] T = [f 1 (W, x), ..., f r (W, x)] T . Here W = [w 1 , w 2 , ..., w s ]\nis a subset of parameters-of-interest in \u03b8 in our consideration, containing the weights and biases.\n\nWe assume W in the correct model is modified by \u0394w, i.e. W = W + \u0394w. The corresponding outputs of the correct and compromised model become y = f (W, x) and y = f (W + \u0394w, x), respectively. In order to precisely detect this change through y and y , the \"sensitive\" input v should maximize the difference between y and y .\nv = argmax x ||f (W + \u0394w, x) \u2212 f (W, x)|| 2 = argmax x ||f (W + \u0394w, x) \u2212 f (W, x)|| 2 2 = argmax x \u03a3 r i=1 ||f i (W + \u0394w, x) \u2212 f i (W, x)|| 2 2 (2)\nwhere || \u00b7 || 2 denotes the l 2 norm of a vector. With Taylor Expansion:\nf i (W + \u0394w, x) = f i (W, x) + \u2202f i (W, x) \u2202W T \u0394w + O(||\u0394w|| 2 2 ) (3)\nNote that we assume no prior-knowledge on \u0394w (how the adversary modifies the model). Consider \u0394w as a perturbation of W , we approximate Eq (3) to the first-order term:\n||f i (W + \u0394w, x) \u2212 f i (W, x)|| 2 2 \u2248 || \u2202f i (W, x) \u2202W T \u0394w|| 2 2 (4) \u221d || \u2202f i (W, X) \u2202W || 2 2(5)\nNote that the left-hand side of Eq (4) models the difference of output y i between a correct DNN and a compromised DNN with weights perturbation \u0394w.\n\nIn Eq (5) we conclude that the l 2 norm of the gradient\n|| \u2202f i (W,x)\n\u2202W || 2 can model the element-wise \"sensitivity\" of the DNN output corresponding to the parameters. Therefore, the sensitivity S of f (W, x) can be defined as:\nS = \u03a3 r i=1 || \u2202f i (W, x) \u2202W || 2 2 = \u2202f (W, x) \u2202W 2 F(6)\nwhere || \u00b7 || F is the Frobenius norm [4] of a matrix. Eq (6) serves as the main objective function of our problem. In practice, there are auxiliary constraints on the sample. Sample Correctness. In some cases, there are some requirements for the range of sample data, denoted as [p, q].\n\nFor instance, all pixels must be in the range of [0, 255] for a valid image input.\n\nSmall Perturbation. In Section 3.1, we described a Sensitive-Sample should look like a normal input, to prevent the adversary from evading the integrity checking. So we add one more constraint: the generated sample is a small perturbation of a natural data v 0 sampled from the original data distribution D X , i.e. the difference of the generated sample and v 0 should not exceed a small threshold . Eqs (7) summarize the objective and constraints of this optimization problem. The constraint set [p, q] m is a convex set, therefore we can use Projected Gradient Ascent\n[5] to generate v. v = argmax x \u2202f (W, x) \u2202W 2 F s.t. x \u2208 [p, q] m x \u2212 v 0 \u2264(7)\nWe show a single Sensitive-Sample generation algorithm in Algorithm 1. Line 8 initializes the input with any sample from the natural data distribution D X . Line 10 sets up the element-wise loss function || \u2202f i (W,x) \u2202W || 2 2 . Line 11 sets up the sample correctness constraints. Line 12 loops while v is still similar to the original initialization v 0 . itr max is set to avoid an infinite loop. Lines 14-17 apply a gradient ascent on the sensitivity, a.k.a. S in Eq (6). Line 18 projects v onto the sample correctness constraint set.\n\nAlgorithm 1 Generating a Sensitive-Sample 1: Function Sensitive-Sample-Gen(f , W , itr max, , lr) 2: /* f: the target model */ 3: /* W: parameters in consideration */ 4: /* itr max: maximum number of iterations */ 5: /* : threshold for small perturbation constraints */ 6: /* lr: learning rate in projected gradient ascent */ 7: i + + 20: end while 21: return {v, f (W, v)}\n8: v 0 = Init Sample() 9: v, i = v 0 , 0 10: l k = \u2202f k (W,v) \u2202W 2 2 , k = 1, 2...N Output 11: Constraint Set = [p, q] m 12: while ((|v \u2212 v 0 | \u2264 ) && (i < itr max)) do\n\nFingerprint Generation: Maximum Active-Neuron Cover (MANC) Sample Selection\n\nIn some cases, a single Sensitive-Sample may not be enough to detect any weight changes. We observe that the main reason is that if a neuron is inactive 1 given an input sample, the sensitivity of all weights connected to that neuron becomes zeros, i.e. small modification of such weights will not be reflected in the outputs. We show the proof of this phenomenon in the extended version of this paper [22].\n\nTo address this problem, we propose Maximum Active Neuron Cover (MANC) sample selection algorithm to select a small number of samples from a bag of generated Sensitive-Samples, to avoid the inactive neurons. Our criterion is to minimize the number of neurons not being activated by any Sensitive-Sample, or equivalently, maximize the number of neurons being activated at least once by the selected samples. We call the resultant set of Sensitive-Samples with their corresponding model outputs, the fingerprint of the DNN model.\n\nWe can abstract it as a maximum coverage problem [6,14]. As input, we are given a bag of generated Sensitive-Samples B = {S 1 , ..., S N } and k, the number of desired samples.\n\nSuppose each Sensitive-Sample S i activates a set of neurons P i . The set {P i } may have elements (neurons) in common. We will select k of these sets such that a maximum number of elements (neurons) are covered, i.e. the union of the selected sets has maximal size.\n\nWe define the set of neurons being activated at least once by the k samples as Active-Neuron Cover (ANC). It is the union of individually activated neurons P i , i.e. k i=1 P k . We would like to maximize the number of elements (neu-\nrons) in AN C, i.e. maximize | k i=1 P k |.\nObtaining the accurate maximum of ANC is timeconsuming and unnecessary in our experiment. Instead we use a greedy search to approximate the maximum. Intuitively, in each iteration t, we choose a set P t which contains the largest number of uncovered neurons. We show the pseudo-code of MANC algorithm in Algorithm 2, and illustrate one step of the MANC algorithm in Figure 2 [16][17][18][19][20][21]. Suppose the set F ingerprint initially contains one selected sample (young lady, left). We want to select the next sample from three candidates (a),(b) and (c). We compute the neurons (red) that have been activated by the samples already in S, i.e. Active-Neuron Cover, and the uncovered neurons (white). We also compute the neurons activated by each candidate (P i ). Candidate samples (a),(b) and (c) activate 4,8 and 3 uncovered neurons, respectively. Thus we add the candidate (b) to F ingerprint and update the covered neurons.\n\n\nModel Output Specification\n\nThe form of the model output significantly affects the information that can be retrieved through black-box access. We consider three forms of y as the outputs of a DNN for classification tasks:\n\n\u2022 Case 1: Numerical probabilities of each class. \u2022 Case 2: Top-k (k>1) classification labels.\n\n\u2022 Case 3: Top-1 classification label.\n\nIn general, the less information included in the output (from Case 1 (most) to Case 3 (least)), the harder it is to generate valid Sensitive-Samples and fingerprints. However, in our experiments, our proposed algorithm can detect an integrity breach for all known real attacks even if only the top-1 label is provided (Case 3) with high accuracy (>99.95%, <10 samples). Our experiments also show that we need even fewer samples (<3 samples) if more information is provided (Cases 1 and 2). We discuss these results in detail in Section 5.\n\n\nSensitive-Samples and Adversarial Examples\n\nA similar and popular concept of our proposed Sensitive-Samples is adversarial examples [33]: the adversary intentionally adds human unnoticeable permutation \u0394x to a normal sample x, so the model gives a wrong prediction for this sample, i.e., f \u03b8 (x + \u0394x) = f \u03b8 (x).\n\nIn this paper, we introduce Sensitive-Samples, another type of transformed inputs which also have human unnoticeable permutations from the normal samples, i.e., z = z + \u0394z. Instead of making the model give wrong outputs, the outputs of the Sensitive-Samples change with the model parameters, i.e., f \u03b8 (z ) = f \u03b8+\u0394\u03b8 (z ). Thus, unlike adversarial examples usually being used as an evasion attack strategy, Sensitive-Samples can be used as a powerful approach to defend against model integrity attacks. Table 1 shows the comparisons between our Sensitive-Samples and adversarial examples. \n\n\nImplementation\n\n\nAttack Coverage\n\nOur proposed method is generic and able to detect integrity breaches due to various attacks against DNN models. We evaluate this method on all four categories of real attacks in Section 2.2: neural network trojan attacks, error-generic and error-specific poisoning attacks and model compression attacks. These cover from subtle model changes to significant changes. We also consider the most general scenario: the adversary changes the weights of any arbitrary neurons to arbitrary values. The goal is to investigate the capability of our approach in defending against general model integrity breaches. We show the results of arbitrary weight changes in the extended version [22].\n\n\nDatasets and Models\n\nFor most of the integrity attacks, we use the same datasets and models as in the literature. In Table 2, we list the model specifications, as well as the attack results.\n\nOriginal accuracy denotes the accuracy of the original correct model. Attack goal shows the adversary's target of modifying the model. Note that we do not make any specific assumption about attack techniques, providing comprehensive protection against all types of model modification.\n\n\nHyper-parameters and Configurations\n\nIn our experiments, we set the learning rate to 1*10 \u22123 . We choose ADAM as our optimizer. We set itr Max to 1000. We consider all the weights in the last layer as parameters-of-interest W . This is because the last layer must be modified in all existing attacks, and the output is most sensitive to this layer.\n\nWe reproduce the above four categories of DNN integrity attacks, and implement our solution using Tensorflow 1.4.1. We run our experiments on a server with 1 Nvidia 1080Ti GPU, 2 Intel Xeon E5-2667 CPUs, 32MB cache and 64GB memory. Under this setting, each Sensitive-Sample takes 3.2s to generate on average.\n\n\nEvaluation\n\n\nSensitive-Sample Generation\n\nWe first show the generation mechanism and generated Sensitive-Samples in Figure 3 on VGG-Face dataset. Figure 3 left shows the trade-off between the sensitivity and similarity during the Sensitive-Samples generation process 2 . The blue line represents the sensitivity, i.e. defined in Eq (6) as || \u2202f (W,x) \u2202W || 2 F . The orange line represents the similarity in terms of SNR. At the beginning of the optimization, the similarity is high, reflecting that the generated image is similar to the original input. However, the sensitivity is low, showing that the DNN output is not sensitive to the weight changes. It also indicates that directly using original images as fingerprints is not good. As the optimization goes on, the sensitivity increases significantly and finally converges to a high value. Meanwhile, artifacts are introduced in the sample generation, decreasing the similarity. In Figure 3 right, we show representative examples of the Sensitive-Samples on VGG-Face dataset. We show more generated Sensitive-Samples on CIFAR-10, GTSRB Traffic Sign and AT&T dataset in Figure 4, respectively. The generated images are very similar to the original inputs. Therefore, the attacker can hardly determine whether it is a natural image or a testing image for integrity checking. More generated Sensitive \u2212 Samples can be found in the extended version [22].\n\n\nSensitive-Sample Effectiveness\n\nWe define a successful detection as \"given N S sensitive samples, there is at least one sample, whose top-1 label predicted by the compromised model is different from the top-1 label predicted by the correct model\". Note that \"top-1 label\" is the most challenging case discussed in Section 3.4. In order to show the effectiveness of our approach more clearly, we show the missing rate (1-detection rate) of (1) Non-Sensitive Samples (green), (2) Sensitive-Samples + random selection (orange) and (3) Sensitive-Samples + MANC (blue) against four different attacks in Figure 5. In case (1), we randomly select N S images from the original validation set. In case (2) and (3), we first generate a bag of 500 sensitive-samples and select N S of them using random selection and MANC, respectively. We repeat the experiment 10,000 times and report the average missing rate.\n\nWe observe that Sensitive-Samples + MANC is highly effective in model integrity verification. In Table 3, for (a) neural network trojan attack, (b) error-generic poisoning attack and (c) error-specific poisoning attack, a fingerprint consisting of 3 Sensitive-Samples is enough to achieve a missing rate less than 10 \u22124 . For (d) model  compression attack, although the compressed model is deliberately retrained to maintain accuracy on normal inputs, our Sensitive-Sample fingerprint still detects 99.96% integrity breaches (0.04% missing rate) with only 8 Sensitive-Samples. Further more, we compare the  Figure 5. We observe that, Sensitive-Samples based approaches always achieve much lower missing rate than non-sensitive samples, regardless of N S and attacks. Sensitive-Samples + MANC always achieves a lower missing rate than Sensitive-Samples + random selection, against all attacks. False Positives. Another advantage of our proposed solution is that false-positive is guaranteed to be zeros. Our proposed Sensitive-Samples defense leverages the determinacy of DNN model inference, therefore no false positive is raised. It is true for all the models and datasets we evaluate. Output Specification. We evaluate the influence of the model output specification, e.g. top-k, numerical probabilities and digit precision. We list the missing rates corresponding to different output specifications (columns) and N S (rows) in Table 4 against neural network trojan attacks. More results against other attacks are shown in the extended version [22]. \"top-k\" means the model outputs the k top labels. \"p-dec-n\" means the model outputs probabilities in addition to labels, with n digits after the decimal point. For example, \"Top-1-p-dec-2\" means the model outputs top-1 probability with the precision of 2 digits after the decimal point. Table 4 shows that, a large k, numerical probability and high precision of the probabilities embed more information in the output, and decrease the missing rate. \n\n\nSensitive-Sample Efficiency\n\nIn addition to the effectiveness in model integrity verification, our proposed approach is also highly efficient. We specifically consider minimizing the cost of verification, by reducing the number of required samples (model inferences). We show the required number of samples to achieve a given missing rate \u03b1 against four real attacks in Table 5. We define the Efficiency as the ratio between the required number of samples (model inferences) between Non-Sensitive Samples and Sensitive-Samples + MANC. In or- der to reveal subtle missing rates, we repeat our experiments in Section 5.2 10 8 times. Our proposed method significantly reduces the required number of samples, regardless of \u03b1, by up to 103\u00d7. Especially, our proposed approach is more comparatively efficient under small \u03b1, demonstrating it is of more obvious advantages in security-critical applications which require strict integrity verification. \n\n\nResistance against Adversarial Fine-tuning\n\nThe adversary may attempt to evade our detection methodology. One possible strategy is that the adversary can generate the Sensitive-Samples from the intact model, and use these samples to fine-tune the compromised model. Then this fine-tuned model might make the customers' Sensitive-Samples used for verification insensitive. We call this potential evasive attack Adversarial Fine-tuning (AF).\n\nWe evaluate this evasive strategy with two model in-tegrity attacks: error-generic poisoning and error-specific poisoning. Table 6 shows the detection missing rate using different numbers of verification Sensitive-Samples before and after fine-tuning. Note that because the customer can generate fingerprint from any arbitrary normal images, we assume the adversary fine-tunes the model with Sensitive-Samples different from the customer's. It is interesting to note that the fine-tuning strategy cannot help the adversary evade the detection, and it actually makes the integrity checking easier. This is because Sensitive-Samples are designed to output very differently from the original model, thus fine-tuning on the Sensitive-Samples makes the tuned model deviate even more from the original model. This extra deviation can be more easily captured by other Sensitive-Samples. Table 6: Missing rate (%) decreases as the attacker adversarial fine-tunes (AF) on Sensitive-Samples. It demonstrates that our proposed method is robust against more sophisticated attacks.\n\nAttacks \\ N S 1 2 3 4 5 Error-generic poisoning (before AF) 12.26 0.04 0.01 0.00 0.00 Error-generic poisoning (after AF) 4.82 0.01 0.00 0.00 0.00 Missing rate increase -7.44 -0.03 -0.01 --Error-specific poisoning (before AF) 2.20 0.01 0.00 0.00 0.00 Error-specific poisoning (after AF) 0.02 0.00 0.00 0.00 0.00 Missing rate increase -2.18 -0.01 ---\n\n\nConclusion\n\nIn this paper, we show that the integrity of remote black-box deep learning model can be dynamically verified by querying the deployed model with a few carefullydesigned human unnoticeable inputs and observing their outputs. Our proposed detection method defines and uses Sensitive-Samples, which introduce sensitivity of DNN outputs corresponding to the weights. Any small modification of the model parameters can be reflected in the outputs. Our evaluation on different categories of real DNN integrity attacks shows that our detection mechanism can effectively and efficiently detect DNN integrity breaches.\n\n\"Figure 1 :\n1Chris Pine\" \"Bae Doona\" \"A.J. Buckley\" \"A.J. Buckley\" Illustration of a DNN trojan. A person without the trigger (left) is recognized correctly by the trojaned DNN. A person wearing a specific pair of glasses, i.e. the trigger, is mis-classified.\n\nPFigure 2 :\n2. Line 5 in Algorithm 2 initializes the uncovered neurons to all neurons of interest, and the set of the selected samples to null. Line 9 computes the activations of neurons with corresponding input Sensitive-Sample B[i]. Line 10 determines the neurons that are activated by B[i], i.e. P i . Line 14 loops to select one sample in each iteration. Lines 16-21 determine which sample activates the largest number of uncovered neurons, and add it to the selected sample set. Line 22 updates the uncovered neurons. sample B[i] activates neurons P i */ 8: for (i = 0; i < |B|; i + +i = {\u03b1 i |\u03b1 i > 0} 11: end for 12: 13: /* Outer loop selects one sample each time */ 14: for (i = 0; i < k; i + +) do 15: /* Inner loop among all samples to find the one that activates the largest number of uncovered neurons *Illustration of selecting one sample in Algorithm 2 (line\n\nFigure 3 :\n3Left: Sensitivity and similarity in the Sensitive-Sample generation process. Right: Original and generated Sensitive-Sample images for integrity checking on VGG Face dataset.\n\nFigure 4 :\n4Original and generated Sensitive-Samples for integrity protection on CIFAR (a)(b), GTSRB Traffic Sign (c)(d) and AT&T (e)(f) dataset, respectively.\n\nFigure 5 :\n5Missing rate comparisons of different methods against (a) Neural Network Trojan Attack, (b) Error-Generic Poisoning Attack, (c) Error-Specific Poisoning Attack and (d) Model Compression Attack.\n\nTable 1 :\n1Comparisons between Sensitive-Samples and adversarial examples.Sensitive-Samples \nAdversarial-Examples \nSimilarity \nTransformed inputs \nPurpose \nDefense \nAttack \n\nSettings \nModel parameters change \nf \u03b8 (z ) = f \u03b8+\u0394\u03b8 (z ) \n\nInput perturbation \nf \u03b8 (x + \u0394x) = f \u03b8 (x) \nGeneration \nWhite-box \nWhite/Black box \nUsage \nBlack-box \nBlack-box \nOptimization \nMaximize the sensitivity \nMaximize the cost function \nGoal \nof output w.r.t model parameters \n\nThere are other approaches to generate adversarial examples. \n\n\nTable 2 :\n2Datasets and models in evaluation.Dataset \nTask \nModel \n# Layers # Conv layers # FC layers Original accuracy \nAttack goal \nAttack technique Attack success rate \n\nNeural network \nVGG-Face \nFace \nVGG-16 \n16 \n13 \n3 \n74.8% \nMisclassify inputs \nSelective neural \n100% \ntrojan attack \nrecognition \nwith triggers \nretraining \n\nError-generic \nGTSRB \nTraffic sign \nCNN \n7 \n6 \n1 \n95.6% \nMisclassify \"Stop\" \nData \n98.6% \nTargeted \nrecognition \ntraffic sign \npoisoning \npoisoning Error-specific \nGTSRB \nTraffic sign \nCNN \n7 \n6 \n1 \n95.6% \nMisclassify \"Stop\" \nData \n87.3% \nrecognition \nto \"Speed 100km\" \npoisoning \n\nModel compression \nCIFAR-10 \nImage \nCNN \n7 \n6 \n1 \n87.59% \nSave storage \nPrecision \n4x compression \nclassification \nreduction \n86.94% \nArbitrary weights \nAT&T \nFace \nMLP \n1 \n0 \n1 \n95.0% \nGeneral model \nArbitrary \nmodification \nrecognition \nmodification \nmodification \n\nWe evaluate it for general integrity, thus no attack success rate. \n\n\n\nTable 3 :\n3Missing rates (%) w.r.t to N S on four real attacks.Attacks \\ N S \n1 \n2 \n3 \n4 \n5 \n8 \nNeural Network Trojan Attack \n5.93 \n0.22 0.00 0.00 0.00 0.00 \nError-Generic Poisoning Attack 12.26 0.04 0.01 0.00 0.00 0.00 \nError-Specific Poisoning Attack 2.20 \n0.01 0.00 0.00 0.00 0.00 \nModel Compression Attack \n48.93 15.56 4.72 1.81 0.83 0.04 \n\nmissing rate of Non-sensitive Samples, Sensitive-Samples + \n\n\n\nTable 4 :\n4Missing rates (%) w.r.t to the output specifications.# of samples N S top-1 top-3 top-5 top-1-p-dec2 p-dec-1 p-dec-2 \n1 \n5.93 \n0.00 \n0.00 \n0.43 \n0.21 \n0.00 \n2 \n0.22 \n0.00 \n0.00 \n0.00 \n0.00 \n0.00 \n3 \n0.00 \n0.00 \n0.00 \n0.00 \n0.00 \n0.00 \n\n\n\nTable 5 :\n5Required number of samples to achieve a given missing rate \u03b1 against four real attacks. Our proposed method reduces required samples by up to 103x. Neural Network Trojan Attack Missing rate \u03b1 10 \u22128 10 \u22127 10 \u22126 10 \u22125 10 \u22124 10 \u22123 10 \u22122 Efficiency 103.0x 90.0x 77.3x 64.3x 51.6x 58.0x 38.5x Model Compression Attack Missing rate \u03b1 10 \u22128 10 \u22127 10 \u22126 10 \u22125 10 \u22124 10 \u22123 10 \u22122 Efficiency 16.2x 14.2x 12.5x 11.2x 10.1x 10.5x 15.8xNon-Sensitive Sample \n74 \n65 \n56 \n47 \n38 \n28 \n21 \nSensitive Sample \n10 \n9 \n8 \n7 \n6 \n4 \n3 \nSensitive Sample + MANC \n4 \n4 \n3 \n3 \n3 \n2 \n2 \nEfficiency \n18.5x 16.5x 18.7x 15.6x 12.6x 14.0x 12.5x \nError-Generic Poisoning Attack \nMissing rate \u03b1 \n10 \u22128 10 \u22127 10 \u22126 10 \u22125 10 \u22124 10 \u22123 10 \u22122 \nNon-Sensitive Sample \n332 \n291 \n249 \n208 \n166 \n125 \n83 \nSensitive Sample \n14 \n12 \n11 \n9 \n7 \n6 \n4 \nSensitive Sample + MANC \n4 \n4 \n4 \n4 \n3 \n2 \n2 \nEfficiency \n83.0x 72.8x 62.3x 52.0x 55.3x 62.5x 41.5x \nError-Specific Poisoning Attack \nMissing rate \u03b1 \n10 \u22128 \n10 \u22127 10 \u22126 10 \u22125 10 \u22124 10 \u22123 10 \u22122 \nNon-Sensitive Sample \n309 \n270 \n232 \n193 \n155 \n116 \n77 \nSensitive Sample \n11 \n9 \n8 \n7 \n6 \n4 \n3 \nSensitive Sample + MANC \n3 \n3 \n3 \n3 \n3 \n2 \n2 \nNon-Sensitive Sample \n502 \n439 \n376 \n314 \n252 \n189 \n126 \nSensitive Sample \n78 \n70 \n59 \n51 \n40 \n29 \n20 \nSensitive Sample + MANC \n31 \n31 \n30 \n28 \n25 \n18 \n8 \n\nThe neuron's output after the activation is 0 or very close to 0.\nThe constraint in Eqs(7)is removed inFigure 3left, to show the generation mechanism.\n\nApproximation algorithms for maximum coverage and max cut with given sizes of parts. A A Ageev, M I Sviridenko, International Conference on Integer Programming and Combinatorial Optimization. A. A. Ageev and M. I. Sviridenko. Approximation al- gorithms for maximum coverage and max cut with given sizes of parts. In International Conference on Integer Pro- gramming and Combinatorial Optimization, pages 17-30.\n\n. Springer, Springer, 1999.\n\nPoisoning attacks against support vector machines. B Biggio, B Nelson, P Laskov, Proceedings of the 29th International Coference on International Conference on Machine Learning. the 29th International Coference on International Conference on Machine LearningOmnipressB. Biggio, B. Nelson, and P. Laskov. Poisoning attacks against support vector machines. In Proceedings of the 29th International Coference on International Conference on Ma- chine Learning, pages 1467-1474. Omnipress, 2012.\n\nHow to tell if your cloud files are vulnerable to drive crashes. K D Bowers, M Van Dijk, A Juels, A Oprea, R L Rivest, ACM conference on Computer and communications security. K. D. Bowers, M. Van Dijk, A. Juels, A. Oprea, and R. L. Rivest. How to tell if your cloud files are vulnerable to drive crashes. In ACM conference on Computer and communica- tions security, 2011.\n\nLearning from untrusted data. M Charikar, J Steinhardt, G Valiant, Annual ACM SIGACT Symposium on Theory of Computing. ACMM. Charikar, J. Steinhardt, and G. Valiant. Learning from un- trusted data. In Annual ACM SIGACT Symposium on Theory of Computing. ACM, 2017.\n\nTargeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning. X Chen, C Liu, B Li, K Lu, D Song, prints:1712.05526X. Chen, C. Liu, B. Li, K. Lu, and D. Song. Targeted Back- door Attacks on Deep Learning Systems Using Data Poison- ing. ArXiv e-prints:1712.05526, Dec. 2017.\n\nA unified architecture for natural language processing: Deep neural networks with multitask learning. R Collobert, J Weston, Proceedings of the 25th international conference on Machine learning. the 25th international conference on Machine learningACMR. Collobert and J. Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160-167. ACM, 2008.\n\nTraining deep neural networks with low precision multiplications. M Courbariaux, Y Bengio, J.-P David, arXiv:1412.7024arXiv preprintM. Courbariaux, Y. Bengio, and J.-P. David. Training deep neural networks with low precision multiplications. arXiv preprint arXiv:1412.7024, 2014.\n\nContextdependent pre-trained deep neural networks for largevocabulary speech recognition. G E Dahl, D Yu, L Deng, A Acero, IEEE Transactions on audio, speech, and language processing. 201G. E. Dahl, D. Yu, L. Deng, and A. Acero. Context- dependent pre-trained deep neural networks for large- vocabulary speech recognition. IEEE Transactions on audio, speech, and language processing, 20(1):30-42, 2012.\n\nA threshold of ln n for approximating set cover. U Feige, Journal of the ACM (JACM). 454U. Feige. A threshold of ln n for approximating set cover. Journal of the ACM (JACM), 45(4):634-652, 1998.\n\nSafetynets: Verifiable execution of deep neural networks on an untrusted cloud. Z Ghodsi, T Gu, S Garg, Advances in Neural Information Processing Systems. Z. Ghodsi, T. Gu, and S. Garg. Safetynets: Verifiable ex- ecution of deep neural networks on an untrusted cloud. In Advances in Neural Information Processing Systems, 2017.\n\nY Gong, L Liu, M Yang, L Bourdev, arXiv:1412.6115Compressing deep convolutional networks using vector quantization. arXiv preprintY. Gong, L. Liu, M. Yang, and L. Bourdev. Compress- ing deep convolutional networks using vector quantization. arXiv preprint arXiv:1412.6115, 2014.\n\nBadnets: Identifying vulnerabilities in the machine learning model supply chain. T Gu, B Dolan-Gavitt, S Garg, abs/1708.06733CoRRT. Gu, B. Dolan-Gavitt, and S. Garg. Badnets: Identifying vulnerabilities in the machine learning model supply chain. CoRR, abs/1708.06733, 2017.\n\nDeep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. S Han, H Mao, W J Dally, International Conference on Learning Representations. S. Han, H. Mao, and W. J. Dally. Deep compression: Com- pressing deep neural networks with pruning, trained quanti- zation and huffman coding. In International Conference on Learning Representations, 2016.\n\nDeep Speech: Scaling Up End-to-end Speech Recognition. A Y Hannun, C Case, J Casper, B Catanzaro, G Diamos, E Elsen, R Prenger, S Satheesh, S Sengupta, A Coates, A Y Ng, abs/1412.5567CoRRA. Y. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta, A. Coates, and A. Y. Ng. Deep Speech: Scaling Up End-to-end Speech Recognition. CoRR, abs/1412.5567, 2014.\n\nDeep Residual Learning for Image Recognition. K He, X Zhang, S Ren, J Sun, abs/1512.03385CoRRK. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning for Image Recognition. CoRR, abs/1512.03385, 2015.\n\nDetecting zero-day controller hijacking attacks on the power-grid with enhanced deep learning. Z He, A Raghavan, S Chai, R Lee, arXiv:1806.06496arXiv preprintZ. He, A. Raghavan, S. Chai, and R. Lee. Detecting zero-day controller hijacking attacks on the power-grid with enhanced deep learning. arXiv preprint arXiv:1806.06496, 2018.\n\nZ He, T Zhang, R B Lee, arXiv:1808.03277Verideep: Verifying integrity of deep neural networks through sensitive-sample fingerprinting. arXiv preprintZ. He, T. Zhang, and R. B. Lee. Verideep: Verifying in- tegrity of deep neural networks through sensitive-sample fin- gerprinting. arXiv preprint arXiv:1808.03277, 2018.\n\nShuffle net: An application of generalized perfect shuffles to multihop lightwave networks. M G Hluchyj, M J Karol, Journal of Lightwave Technology. 910M. G. Hluchyj and M. J. Karol. Shuffle net: An application of generalized perfect shuffles to multihop lightwave net- works. Journal of Lightwave Technology, 9(10):1386-1397, 1991.\n\nF N Iandola, S Han, M W Moskewicz, K Ashraf, W J Dally, K Keutzer, arXiv:1602.07360Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0.5 mb model size. arXiv preprintF. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0.5 mb model size. arXiv preprint arXiv:1602.07360, 2016.\n\nImagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in neural information processing systems. A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097-1105, 2012.\n\nTrojanning attack on neural networks. Y Liu, S Ma, Y Aafer, W.-C Lee, J Zhai, W Wang, X Zhang, 25nd Annual Network and Distributed System Security Symposium, NDSS'18. San Diego, California, USAY. Liu, S. Ma, Y. Aafer, W.-C. Lee, J. Zhai, W. Wang, and X. Zhang. Trojanning attack on neural networks. In 25nd An- nual Network and Distributed System Security Symposium, NDSS'18 , San Diego, California, USA, February, 2018.\n\nNeural trojans. Y Liu, Y Xie, A Srivastava, IEEE International Conference on Computer Design. Y. Liu, Y. Xie, and A. Srivastava. Neural trojans. In IEEE International Conference on Computer Design, 2017.\n\nEffective Approaches to Attention-based Neural Machine Translation. CoRR. M Luong, H Pham, C D Manning, abs/1508.04025M. Luong, H. Pham, and C. D. Manning. Effective Ap- proaches to Attention-based Neural Machine Translation. CoRR, abs/1508.04025, 2015.\n\nLong short term memory networks for anomaly detection in time series. P Malhotra, L Vig, G Shroff, P Agarwal, Proceedings. Presses universitaires de Louvain. Presses universitaires de LouvainP. Malhotra, L. Vig, G. Shroff, and P. Agarwal. Long short term memory networks for anomaly detection in time series. In Proceedings. Presses universitaires de Louvain, 2015.\n\nUsing machine teaching to identify optimal training-set attacks on machine learners. S Mei, X Zhu, AAAI. S. Mei and X. Zhu. Using machine teaching to identify opti- mal training-set attacks on machine learners. In AAAI, pages 2871-2877, 2015.\n\nTowards poisoning of deep learning algorithms with back-gradient optimization. L Mu\u00f1oz-Gonz\u00e1lez, B Biggio, A Demontis, A Paudice, V Wongrassamee, E C Lupu, F Roli, Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security. the 10th ACM Workshop on Artificial Intelligence and SecurityACML. Mu\u00f1oz-Gonz\u00e1lez, B. Biggio, A. Demontis, A. Paudice, V. Wongrassamee, E. C. Lupu, and F. Roli. Towards poison- ing of deep learning algorithms with back-gradient optimiza- tion. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security, pages 27-38. ACM, 2017.\n\nCertified defenses for data poisoning attacks. J Steinhardt, P W W Koh, P S Liang, Advances in Neural Information Processing Systems. J. Steinhardt, P. W. W. Koh, and P. S. Liang. Certified de- fenses for data poisoning attacks. In Advances in Neural Information Processing Systems, 2017.\n\nC Szegedy, W Zaremba, I Sutskever, J Bruna, D Erhan, I Goodfellow, R Fergus, arXiv:1312.6199Intriguing properties of neural networks. arXiv preprintC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.\n\nIs feature selection secure against training data poisoning?. H Xiao, B Biggio, G Brown, G Fumera, C Eckert, F Roli, International Conference on Machine Learning. H. Xiao, B. Biggio, G. Brown, G. Fumera, C. Eckert, and F. Roli. Is feature selection secure against training data poi- soning? In International Conference on Machine Learning, pages 1689-1698, 2015.\n\nHomealone: Co-residency detection in the cloud via side-channel analysis. Y Zhang, A Juels, A Oprea, M K Reiter, 2011 IEEE symposium on security and privacy. IEEEY. Zhang, A. Juels, A. Oprea, and M. K. Reiter. Homealone: Co-residency detection in the cloud via side-channel analy- sis. In 2011 IEEE symposium on security and privacy, pages 313-328. IEEE, 2011.\n", "annotations": {"author": "[{\"start\":\"59\",\"end\":\"152\"},{\"start\":\"153\",\"end\":\"256\"},{\"start\":\"257\",\"end\":\"345\"}]", "publisher": null, "author_last_name": "[{\"start\":\"67\",\"end\":\"69\"},{\"start\":\"161\",\"end\":\"166\"},{\"start\":\"262\",\"end\":\"265\"}]", "author_first_name": "[{\"start\":\"59\",\"end\":\"66\"},{\"start\":\"153\",\"end\":\"160\"},{\"start\":\"257\",\"end\":\"261\"}]", "author_affiliation": "[{\"start\":\"94\",\"end\":\"151\"},{\"start\":\"198\",\"end\":\"255\"},{\"start\":\"287\",\"end\":\"344\"}]", "title": "[{\"start\":\"1\",\"end\":\"56\"},{\"start\":\"346\",\"end\":\"401\"}]", "venue": null, "abstract": "[{\"start\":\"426\",\"end\":\"1489\"}]", "bib_ref": "[{\"start\":\"1758\",\"end\":\"1762\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"1762\",\"end\":\"1765\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"1795\",\"end\":\"1799\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"1799\",\"end\":\"1802\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"1823\",\"end\":\"1827\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"1827\",\"end\":\"1830\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"1853\",\"end\":\"1857\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"1857\",\"end\":\"1860\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"2162\",\"end\":\"2165\"},{\"start\":\"2708\",\"end\":\"2712\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"2712\",\"end\":\"2715\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"2715\",\"end\":\"2718\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"2737\",\"end\":\"2740\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"2740\",\"end\":\"2743\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"2743\",\"end\":\"2746\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"2746\",\"end\":\"2749\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"2861\",\"end\":\"2865\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"2865\",\"end\":\"2868\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"2890\",\"end\":\"2894\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"2918\",\"end\":\"2922\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"3559\",\"end\":\"3563\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"3563\",\"end\":\"3565\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"3715\",\"end\":\"3719\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"7902\",\"end\":\"7906\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"7906\",\"end\":\"7909\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"8470\",\"end\":\"8473\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"8473\",\"end\":\"8476\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"8476\",\"end\":\"8479\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"8616\",\"end\":\"8620\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"8958\",\"end\":\"8962\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"8977\",\"end\":\"8981\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"8997\",\"end\":\"9001\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"9032\",\"end\":\"9036\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"9036\",\"end\":\"9039\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"9150\",\"end\":\"9154\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"9409\",\"end\":\"9412\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"9412\",\"end\":\"9415\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"9610\",\"end\":\"9614\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"11628\",\"end\":\"11632\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"14099\",\"end\":\"14102\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"15954\",\"end\":\"15957\"},{\"start\":\"16628\",\"end\":\"16632\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"17213\",\"end\":\"17216\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"17216\",\"end\":\"17219\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"18264\",\"end\":\"18268\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"18268\",\"end\":\"18272\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"18272\",\"end\":\"18276\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"18276\",\"end\":\"18280\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"18280\",\"end\":\"18284\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"18284\",\"end\":\"18288\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"19855\",\"end\":\"19859\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"21336\",\"end\":\"21340\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"23885\",\"end\":\"23889\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"26340\",\"end\":\"26344\",\"attributes\":{\"ref_id\":\"b17\"}}]", "figure": "[{\"start\":\"30230\",\"end\":\"30490\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"30491\",\"end\":\"31364\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"31365\",\"end\":\"31552\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"31553\",\"end\":\"31713\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"31714\",\"end\":\"31920\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"31921\",\"end\":\"32440\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"32441\",\"end\":\"33392\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"33393\",\"end\":\"33800\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"33801\",\"end\":\"34049\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"34050\",\"end\":\"35355\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"1505\",\"end\":\"1861\"},{\"start\":\"1863\",\"end\":\"2333\"},{\"start\":\"2335\",\"end\":\"3885\"},{\"start\":\"3887\",\"end\":\"3999\"},{\"start\":\"4001\",\"end\":\"4627\"},{\"start\":\"4629\",\"end\":\"5486\"},{\"start\":\"5488\",\"end\":\"5528\"},{\"start\":\"5530\",\"end\":\"6136\"},{\"start\":\"6138\",\"end\":\"6527\"},{\"start\":\"6582\",\"end\":\"6911\"},{\"start\":\"6913\",\"end\":\"7102\"},{\"start\":\"7178\",\"end\":\"7646\"},{\"start\":\"7744\",\"end\":\"8721\"},{\"start\":\"8751\",\"end\":\"9552\"},{\"start\":\"9554\",\"end\":\"9894\"},{\"start\":\"9941\",\"end\":\"10423\"},{\"start\":\"10425\",\"end\":\"10820\"},{\"start\":\"10867\",\"end\":\"11218\"},{\"start\":\"11220\",\"end\":\"11422\"},{\"start\":\"11424\",\"end\":\"11960\"},{\"start\":\"11962\",\"end\":\"12336\"},{\"start\":\"12375\",\"end\":\"12511\"},{\"start\":\"12616\",\"end\":\"12715\"},{\"start\":\"12717\",\"end\":\"13037\"},{\"start\":\"13186\",\"end\":\"13258\"},{\"start\":\"13331\",\"end\":\"13499\"},{\"start\":\"13602\",\"end\":\"13750\"},{\"start\":\"13752\",\"end\":\"13807\"},{\"start\":\"13822\",\"end\":\"13981\"},{\"start\":\"14041\",\"end\":\"14328\"},{\"start\":\"14330\",\"end\":\"14412\"},{\"start\":\"14414\",\"end\":\"14984\"},{\"start\":\"15065\",\"end\":\"15603\"},{\"start\":\"15605\",\"end\":\"15978\"},{\"start\":\"16226\",\"end\":\"16633\"},{\"start\":\"16635\",\"end\":\"17162\"},{\"start\":\"17164\",\"end\":\"17340\"},{\"start\":\"17342\",\"end\":\"17609\"},{\"start\":\"17611\",\"end\":\"17844\"},{\"start\":\"17889\",\"end\":\"18822\"},{\"start\":\"18853\",\"end\":\"19046\"},{\"start\":\"19048\",\"end\":\"19141\"},{\"start\":\"19143\",\"end\":\"19180\"},{\"start\":\"19182\",\"end\":\"19720\"},{\"start\":\"19767\",\"end\":\"20034\"},{\"start\":\"20036\",\"end\":\"20624\"},{\"start\":\"20661\",\"end\":\"21341\"},{\"start\":\"21365\",\"end\":\"21534\"},{\"start\":\"21536\",\"end\":\"21820\"},{\"start\":\"21860\",\"end\":\"22171\"},{\"start\":\"22173\",\"end\":\"22481\"},{\"start\":\"22526\",\"end\":\"23890\"},{\"start\":\"23925\",\"end\":\"24792\"},{\"start\":\"24794\",\"end\":\"26795\"},{\"start\":\"26827\",\"end\":\"27742\"},{\"start\":\"27789\",\"end\":\"28184\"},{\"start\":\"28186\",\"end\":\"29254\"},{\"start\":\"29256\",\"end\":\"29604\"},{\"start\":\"29619\",\"end\":\"30229\"}]", "formula": "[{\"start\":\"7103\",\"end\":\"7177\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"7647\",\"end\":\"7706\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"10821\",\"end\":\"10866\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"12512\",\"end\":\"12615\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"13038\",\"end\":\"13185\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"13259\",\"end\":\"13330\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"13500\",\"end\":\"13601\",\"attributes\":{\"id\":\"formula_6\"}},{\"start\":\"13808\",\"end\":\"13821\",\"attributes\":{\"id\":\"formula_7\"}},{\"start\":\"13982\",\"end\":\"14040\",\"attributes\":{\"id\":\"formula_8\"}},{\"start\":\"14985\",\"end\":\"15064\",\"attributes\":{\"id\":\"formula_9\"}},{\"start\":\"15979\",\"end\":\"16147\",\"attributes\":{\"id\":\"formula_10\"}},{\"start\":\"17845\",\"end\":\"17888\",\"attributes\":{\"id\":\"formula_11\"}}]", "table_ref": "[{\"start\":\"20538\",\"end\":\"20545\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"21461\",\"end\":\"21468\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"24891\",\"end\":\"24898\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"26224\",\"end\":\"26231\",\"attributes\":{\"ref_id\":\"tab_3\"}},{\"start\":\"26633\",\"end\":\"26640\",\"attributes\":{\"ref_id\":\"tab_3\"}},{\"start\":\"27168\",\"end\":\"27175\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"28309\",\"end\":\"28316\"},{\"start\":\"29066\",\"end\":\"29073\"}]", "section_header": "[{\"start\":\"1491\",\"end\":\"1503\",\"attributes\":{\"n\":\"1.\"}},{\"start\":\"6530\",\"end\":\"6557\",\"attributes\":{\"n\":\"2.\"}},{\"start\":\"6560\",\"end\":\"6580\",\"attributes\":{\"n\":\"2.1.\"}},{\"start\":\"7708\",\"end\":\"7742\",\"attributes\":{\"n\":\"2.2.\"}},{\"start\":\"8724\",\"end\":\"8749\"},{\"start\":\"9897\",\"end\":\"9928\",\"attributes\":{\"n\":\"3.\"}},{\"start\":\"9931\",\"end\":\"9939\",\"attributes\":{\"n\":\"3.1.\"}},{\"start\":\"12339\",\"end\":\"12373\",\"attributes\":{\"n\":\"3.2.\"}},{\"start\":\"16149\",\"end\":\"16224\",\"attributes\":{\"n\":\"3.3.\"}},{\"start\":\"18825\",\"end\":\"18851\",\"attributes\":{\"n\":\"3.4.\"}},{\"start\":\"19723\",\"end\":\"19765\",\"attributes\":{\"n\":\"3.5.\"}},{\"start\":\"20627\",\"end\":\"20641\",\"attributes\":{\"n\":\"4.\"}},{\"start\":\"20644\",\"end\":\"20659\",\"attributes\":{\"n\":\"4.1.\"}},{\"start\":\"21344\",\"end\":\"21363\",\"attributes\":{\"n\":\"4.2.\"}},{\"start\":\"21823\",\"end\":\"21858\",\"attributes\":{\"n\":\"4.3.\"}},{\"start\":\"22484\",\"end\":\"22494\",\"attributes\":{\"n\":\"5.\"}},{\"start\":\"22497\",\"end\":\"22524\",\"attributes\":{\"n\":\"5.1.\"}},{\"start\":\"23893\",\"end\":\"23923\",\"attributes\":{\"n\":\"5.2.\"}},{\"start\":\"26798\",\"end\":\"26825\",\"attributes\":{\"n\":\"5.3.\"}},{\"start\":\"27745\",\"end\":\"27787\",\"attributes\":{\"n\":\"5.4.\"}},{\"start\":\"29607\",\"end\":\"29617\",\"attributes\":{\"n\":\"6.\"}},{\"start\":\"30231\",\"end\":\"30242\"},{\"start\":\"30492\",\"end\":\"30503\"},{\"start\":\"31366\",\"end\":\"31376\"},{\"start\":\"31554\",\"end\":\"31564\"},{\"start\":\"31715\",\"end\":\"31725\"},{\"start\":\"31922\",\"end\":\"31931\"},{\"start\":\"32442\",\"end\":\"32451\"},{\"start\":\"33394\",\"end\":\"33403\"},{\"start\":\"33802\",\"end\":\"33811\"},{\"start\":\"34051\",\"end\":\"34060\"}]", "table": "[{\"start\":\"31996\",\"end\":\"32440\"},{\"start\":\"32487\",\"end\":\"33392\"},{\"start\":\"33457\",\"end\":\"33800\"},{\"start\":\"33866\",\"end\":\"34049\"},{\"start\":\"34484\",\"end\":\"35355\"}]", "figure_caption": "[{\"start\":\"30244\",\"end\":\"30490\"},{\"start\":\"30505\",\"end\":\"31364\"},{\"start\":\"31378\",\"end\":\"31552\"},{\"start\":\"31566\",\"end\":\"31713\"},{\"start\":\"31727\",\"end\":\"31920\"},{\"start\":\"31933\",\"end\":\"31996\"},{\"start\":\"32453\",\"end\":\"32487\"},{\"start\":\"33405\",\"end\":\"33457\"},{\"start\":\"33813\",\"end\":\"33866\"},{\"start\":\"34062\",\"end\":\"34484\"}]", "figure_ref": "[{\"start\":\"2924\",\"end\":\"2932\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"18255\",\"end\":\"18263\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"19655\",\"end\":\"19670\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"22600\",\"end\":\"22608\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"22630\",\"end\":\"22638\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"23422\",\"end\":\"23430\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"23609\",\"end\":\"23617\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"24491\",\"end\":\"24499\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"25401\",\"end\":\"25409\",\"attributes\":{\"ref_id\":\"fig_5\"}}]", "bib_author_first_name": "[{\"start\":\"35593\",\"end\":\"35594\"},{\"start\":\"35595\",\"end\":\"35596\"},{\"start\":\"35604\",\"end\":\"35605\"},{\"start\":\"35606\",\"end\":\"35607\"},{\"start\":\"36000\",\"end\":\"36001\"},{\"start\":\"36010\",\"end\":\"36011\"},{\"start\":\"36020\",\"end\":\"36021\"},{\"start\":\"36506\",\"end\":\"36507\"},{\"start\":\"36508\",\"end\":\"36509\"},{\"start\":\"36518\",\"end\":\"36519\"},{\"start\":\"36530\",\"end\":\"36531\"},{\"start\":\"36539\",\"end\":\"36540\"},{\"start\":\"36548\",\"end\":\"36549\"},{\"start\":\"36550\",\"end\":\"36551\"},{\"start\":\"36844\",\"end\":\"36845\"},{\"start\":\"36856\",\"end\":\"36857\"},{\"start\":\"36870\",\"end\":\"36871\"},{\"start\":\"37152\",\"end\":\"37153\"},{\"start\":\"37160\",\"end\":\"37161\"},{\"start\":\"37167\",\"end\":\"37168\"},{\"start\":\"37173\",\"end\":\"37174\"},{\"start\":\"37179\",\"end\":\"37180\"},{\"start\":\"37466\",\"end\":\"37467\"},{\"start\":\"37479\",\"end\":\"37480\"},{\"start\":\"37911\",\"end\":\"37912\"},{\"start\":\"37926\",\"end\":\"37927\"},{\"start\":\"37936\",\"end\":\"37940\"},{\"start\":\"38216\",\"end\":\"38217\"},{\"start\":\"38218\",\"end\":\"38219\"},{\"start\":\"38226\",\"end\":\"38227\"},{\"start\":\"38232\",\"end\":\"38233\"},{\"start\":\"38240\",\"end\":\"38241\"},{\"start\":\"38579\",\"end\":\"38580\"},{\"start\":\"38806\",\"end\":\"38807\"},{\"start\":\"38816\",\"end\":\"38817\"},{\"start\":\"38822\",\"end\":\"38823\"},{\"start\":\"39055\",\"end\":\"39056\"},{\"start\":\"39063\",\"end\":\"39064\"},{\"start\":\"39070\",\"end\":\"39071\"},{\"start\":\"39078\",\"end\":\"39079\"},{\"start\":\"39416\",\"end\":\"39417\"},{\"start\":\"39422\",\"end\":\"39423\"},{\"start\":\"39438\",\"end\":\"39439\"},{\"start\":\"39717\",\"end\":\"39718\"},{\"start\":\"39724\",\"end\":\"39725\"},{\"start\":\"39731\",\"end\":\"39732\"},{\"start\":\"39733\",\"end\":\"39734\"},{\"start\":\"40058\",\"end\":\"40059\"},{\"start\":\"40060\",\"end\":\"40061\"},{\"start\":\"40070\",\"end\":\"40071\"},{\"start\":\"40078\",\"end\":\"40079\"},{\"start\":\"40088\",\"end\":\"40089\"},{\"start\":\"40101\",\"end\":\"40102\"},{\"start\":\"40111\",\"end\":\"40112\"},{\"start\":\"40120\",\"end\":\"40121\"},{\"start\":\"40131\",\"end\":\"40132\"},{\"start\":\"40143\",\"end\":\"40144\"},{\"start\":\"40155\",\"end\":\"40156\"},{\"start\":\"40165\",\"end\":\"40166\"},{\"start\":\"40167\",\"end\":\"40168\"},{\"start\":\"40451\",\"end\":\"40452\"},{\"start\":\"40457\",\"end\":\"40458\"},{\"start\":\"40466\",\"end\":\"40467\"},{\"start\":\"40473\",\"end\":\"40474\"},{\"start\":\"40705\",\"end\":\"40706\"},{\"start\":\"40711\",\"end\":\"40712\"},{\"start\":\"40723\",\"end\":\"40724\"},{\"start\":\"40731\",\"end\":\"40732\"},{\"start\":\"40944\",\"end\":\"40945\"},{\"start\":\"40950\",\"end\":\"40951\"},{\"start\":\"40959\",\"end\":\"40960\"},{\"start\":\"40961\",\"end\":\"40962\"},{\"start\":\"41356\",\"end\":\"41357\"},{\"start\":\"41358\",\"end\":\"41359\"},{\"start\":\"41369\",\"end\":\"41370\"},{\"start\":\"41371\",\"end\":\"41372\"},{\"start\":\"41598\",\"end\":\"41599\"},{\"start\":\"41600\",\"end\":\"41601\"},{\"start\":\"41611\",\"end\":\"41612\"},{\"start\":\"41618\",\"end\":\"41619\"},{\"start\":\"41620\",\"end\":\"41621\"},{\"start\":\"41633\",\"end\":\"41634\"},{\"start\":\"41643\",\"end\":\"41644\"},{\"start\":\"41645\",\"end\":\"41646\"},{\"start\":\"41654\",\"end\":\"41655\"},{\"start\":\"42050\",\"end\":\"42051\"},{\"start\":\"42064\",\"end\":\"42065\"},{\"start\":\"42077\",\"end\":\"42078\"},{\"start\":\"42079\",\"end\":\"42080\"},{\"start\":\"42368\",\"end\":\"42369\"},{\"start\":\"42375\",\"end\":\"42376\"},{\"start\":\"42381\",\"end\":\"42382\"},{\"start\":\"42390\",\"end\":\"42394\"},{\"start\":\"42400\",\"end\":\"42401\"},{\"start\":\"42408\",\"end\":\"42409\"},{\"start\":\"42416\",\"end\":\"42417\"},{\"start\":\"42768\",\"end\":\"42769\"},{\"start\":\"42775\",\"end\":\"42776\"},{\"start\":\"42782\",\"end\":\"42783\"},{\"start\":\"43031\",\"end\":\"43032\"},{\"start\":\"43040\",\"end\":\"43041\"},{\"start\":\"43048\",\"end\":\"43049\"},{\"start\":\"43050\",\"end\":\"43051\"},{\"start\":\"43282\",\"end\":\"43283\"},{\"start\":\"43294\",\"end\":\"43295\"},{\"start\":\"43301\",\"end\":\"43302\"},{\"start\":\"43311\",\"end\":\"43312\"},{\"start\":\"43664\",\"end\":\"43665\"},{\"start\":\"43671\",\"end\":\"43672\"},{\"start\":\"43902\",\"end\":\"43903\"},{\"start\":\"43920\",\"end\":\"43921\"},{\"start\":\"43930\",\"end\":\"43931\"},{\"start\":\"43942\",\"end\":\"43943\"},{\"start\":\"43953\",\"end\":\"43954\"},{\"start\":\"43969\",\"end\":\"43970\"},{\"start\":\"43971\",\"end\":\"43972\"},{\"start\":\"43979\",\"end\":\"43980\"},{\"start\":\"44462\",\"end\":\"44463\"},{\"start\":\"44476\",\"end\":\"44477\"},{\"start\":\"44478\",\"end\":\"44481\"},{\"start\":\"44487\",\"end\":\"44488\"},{\"start\":\"44489\",\"end\":\"44490\"},{\"start\":\"44705\",\"end\":\"44706\"},{\"start\":\"44716\",\"end\":\"44717\"},{\"start\":\"44727\",\"end\":\"44728\"},{\"start\":\"44740\",\"end\":\"44741\"},{\"start\":\"44749\",\"end\":\"44750\"},{\"start\":\"44758\",\"end\":\"44759\"},{\"start\":\"44772\",\"end\":\"44773\"},{\"start\":\"45084\",\"end\":\"45085\"},{\"start\":\"45092\",\"end\":\"45093\"},{\"start\":\"45102\",\"end\":\"45103\"},{\"start\":\"45111\",\"end\":\"45112\"},{\"start\":\"45121\",\"end\":\"45122\"},{\"start\":\"45131\",\"end\":\"45132\"},{\"start\":\"45460\",\"end\":\"45461\"},{\"start\":\"45469\",\"end\":\"45470\"},{\"start\":\"45478\",\"end\":\"45479\"},{\"start\":\"45487\",\"end\":\"45488\"},{\"start\":\"45489\",\"end\":\"45490\"}]", "bib_author_last_name": "[{\"start\":\"35597\",\"end\":\"35602\"},{\"start\":\"35608\",\"end\":\"35618\"},{\"start\":\"35922\",\"end\":\"35930\"},{\"start\":\"36002\",\"end\":\"36008\"},{\"start\":\"36012\",\"end\":\"36018\"},{\"start\":\"36022\",\"end\":\"36028\"},{\"start\":\"36510\",\"end\":\"36516\"},{\"start\":\"36520\",\"end\":\"36528\"},{\"start\":\"36532\",\"end\":\"36537\"},{\"start\":\"36541\",\"end\":\"36546\"},{\"start\":\"36552\",\"end\":\"36558\"},{\"start\":\"36846\",\"end\":\"36854\"},{\"start\":\"36858\",\"end\":\"36868\"},{\"start\":\"36872\",\"end\":\"36879\"},{\"start\":\"37154\",\"end\":\"37158\"},{\"start\":\"37162\",\"end\":\"37165\"},{\"start\":\"37169\",\"end\":\"37171\"},{\"start\":\"37175\",\"end\":\"37177\"},{\"start\":\"37181\",\"end\":\"37185\"},{\"start\":\"37468\",\"end\":\"37477\"},{\"start\":\"37481\",\"end\":\"37487\"},{\"start\":\"37913\",\"end\":\"37924\"},{\"start\":\"37928\",\"end\":\"37934\"},{\"start\":\"37941\",\"end\":\"37946\"},{\"start\":\"38220\",\"end\":\"38224\"},{\"start\":\"38228\",\"end\":\"38230\"},{\"start\":\"38234\",\"end\":\"38238\"},{\"start\":\"38242\",\"end\":\"38247\"},{\"start\":\"38581\",\"end\":\"38586\"},{\"start\":\"38808\",\"end\":\"38814\"},{\"start\":\"38818\",\"end\":\"38820\"},{\"start\":\"38824\",\"end\":\"38828\"},{\"start\":\"39057\",\"end\":\"39061\"},{\"start\":\"39065\",\"end\":\"39068\"},{\"start\":\"39072\",\"end\":\"39076\"},{\"start\":\"39080\",\"end\":\"39087\"},{\"start\":\"39418\",\"end\":\"39420\"},{\"start\":\"39424\",\"end\":\"39436\"},{\"start\":\"39440\",\"end\":\"39444\"},{\"start\":\"39719\",\"end\":\"39722\"},{\"start\":\"39726\",\"end\":\"39729\"},{\"start\":\"39735\",\"end\":\"39740\"},{\"start\":\"40062\",\"end\":\"40068\"},{\"start\":\"40072\",\"end\":\"40076\"},{\"start\":\"40080\",\"end\":\"40086\"},{\"start\":\"40090\",\"end\":\"40099\"},{\"start\":\"40103\",\"end\":\"40109\"},{\"start\":\"40113\",\"end\":\"40118\"},{\"start\":\"40122\",\"end\":\"40129\"},{\"start\":\"40133\",\"end\":\"40141\"},{\"start\":\"40145\",\"end\":\"40153\"},{\"start\":\"40157\",\"end\":\"40163\"},{\"start\":\"40169\",\"end\":\"40171\"},{\"start\":\"40453\",\"end\":\"40455\"},{\"start\":\"40459\",\"end\":\"40464\"},{\"start\":\"40468\",\"end\":\"40471\"},{\"start\":\"40475\",\"end\":\"40478\"},{\"start\":\"40707\",\"end\":\"40709\"},{\"start\":\"40713\",\"end\":\"40721\"},{\"start\":\"40725\",\"end\":\"40729\"},{\"start\":\"40733\",\"end\":\"40736\"},{\"start\":\"40946\",\"end\":\"40948\"},{\"start\":\"40952\",\"end\":\"40957\"},{\"start\":\"40963\",\"end\":\"40966\"},{\"start\":\"41360\",\"end\":\"41367\"},{\"start\":\"41373\",\"end\":\"41378\"},{\"start\":\"41602\",\"end\":\"41609\"},{\"start\":\"41613\",\"end\":\"41616\"},{\"start\":\"41622\",\"end\":\"41631\"},{\"start\":\"41635\",\"end\":\"41641\"},{\"start\":\"41647\",\"end\":\"41652\"},{\"start\":\"41656\",\"end\":\"41663\"},{\"start\":\"42052\",\"end\":\"42062\"},{\"start\":\"42066\",\"end\":\"42075\"},{\"start\":\"42081\",\"end\":\"42087\"},{\"start\":\"42370\",\"end\":\"42373\"},{\"start\":\"42377\",\"end\":\"42379\"},{\"start\":\"42383\",\"end\":\"42388\"},{\"start\":\"42395\",\"end\":\"42398\"},{\"start\":\"42402\",\"end\":\"42406\"},{\"start\":\"42410\",\"end\":\"42414\"},{\"start\":\"42418\",\"end\":\"42423\"},{\"start\":\"42770\",\"end\":\"42773\"},{\"start\":\"42777\",\"end\":\"42780\"},{\"start\":\"42784\",\"end\":\"42794\"},{\"start\":\"43033\",\"end\":\"43038\"},{\"start\":\"43042\",\"end\":\"43046\"},{\"start\":\"43052\",\"end\":\"43059\"},{\"start\":\"43284\",\"end\":\"43292\"},{\"start\":\"43296\",\"end\":\"43299\"},{\"start\":\"43303\",\"end\":\"43309\"},{\"start\":\"43313\",\"end\":\"43320\"},{\"start\":\"43666\",\"end\":\"43669\"},{\"start\":\"43673\",\"end\":\"43676\"},{\"start\":\"43904\",\"end\":\"43918\"},{\"start\":\"43922\",\"end\":\"43928\"},{\"start\":\"43932\",\"end\":\"43940\"},{\"start\":\"43944\",\"end\":\"43951\"},{\"start\":\"43955\",\"end\":\"43967\"},{\"start\":\"43973\",\"end\":\"43977\"},{\"start\":\"43981\",\"end\":\"43985\"},{\"start\":\"44464\",\"end\":\"44474\"},{\"start\":\"44482\",\"end\":\"44485\"},{\"start\":\"44491\",\"end\":\"44496\"},{\"start\":\"44707\",\"end\":\"44714\"},{\"start\":\"44718\",\"end\":\"44725\"},{\"start\":\"44729\",\"end\":\"44738\"},{\"start\":\"44742\",\"end\":\"44747\"},{\"start\":\"44751\",\"end\":\"44756\"},{\"start\":\"44760\",\"end\":\"44770\"},{\"start\":\"44774\",\"end\":\"44780\"},{\"start\":\"45086\",\"end\":\"45090\"},{\"start\":\"45094\",\"end\":\"45100\"},{\"start\":\"45104\",\"end\":\"45109\"},{\"start\":\"45113\",\"end\":\"45119\"},{\"start\":\"45123\",\"end\":\"45129\"},{\"start\":\"45133\",\"end\":\"45137\"},{\"start\":\"45462\",\"end\":\"45467\"},{\"start\":\"45471\",\"end\":\"45476\"},{\"start\":\"45480\",\"end\":\"45485\"},{\"start\":\"45491\",\"end\":\"45497\"}]", "bib_entry": "[{\"start\":\"35508\",\"end\":\"35918\",\"attributes\":{\"matched_paper_id\":\"45349214\",\"id\":\"b0\"}},{\"start\":\"35920\",\"end\":\"35947\",\"attributes\":{\"id\":\"b1\"}},{\"start\":\"35949\",\"end\":\"36439\",\"attributes\":{\"matched_paper_id\":\"9089716\",\"id\":\"b2\"}},{\"start\":\"36441\",\"end\":\"36812\",\"attributes\":{\"matched_paper_id\":\"499329\",\"id\":\"b3\"}},{\"start\":\"36814\",\"end\":\"37077\",\"attributes\":{\"matched_paper_id\":\"12023229\",\"id\":\"b4\"}},{\"start\":\"37079\",\"end\":\"37362\",\"attributes\":{\"id\":\"b5\",\"doi\":\"prints:1712.05526\"}},{\"start\":\"37364\",\"end\":\"37843\",\"attributes\":{\"matched_paper_id\":\"2617020\",\"id\":\"b6\"}},{\"start\":\"37845\",\"end\":\"38124\",\"attributes\":{\"id\":\"b7\",\"doi\":\"arXiv:1412.7024\"}},{\"start\":\"38126\",\"end\":\"38528\",\"attributes\":{\"id\":\"b8\"}},{\"start\":\"38530\",\"end\":\"38724\",\"attributes\":{\"matched_paper_id\":\"52827488\",\"id\":\"b9\"}},{\"start\":\"38726\",\"end\":\"39053\",\"attributes\":{\"matched_paper_id\":\"25998539\",\"id\":\"b10\"}},{\"start\":\"39055\",\"end\":\"39333\",\"attributes\":{\"id\":\"b11\",\"doi\":\"arXiv:1412.6115\"}},{\"start\":\"39335\",\"end\":\"39609\",\"attributes\":{\"id\":\"b12\",\"doi\":\"abs/1708.06733\"}},{\"start\":\"39611\",\"end\":\"40001\",\"attributes\":{\"matched_paper_id\":\"2134321\",\"id\":\"b13\"}},{\"start\":\"40003\",\"end\":\"40403\",\"attributes\":{\"id\":\"b14\",\"doi\":\"abs/1412.5567\"}},{\"start\":\"40405\",\"end\":\"40608\",\"attributes\":{\"id\":\"b15\",\"doi\":\"abs/1512.03385\"}},{\"start\":\"40610\",\"end\":\"40942\",\"attributes\":{\"id\":\"b16\",\"doi\":\"arXiv:1806.06496\"}},{\"start\":\"40944\",\"end\":\"41262\",\"attributes\":{\"id\":\"b17\",\"doi\":\"arXiv:1808.03277\"}},{\"start\":\"41264\",\"end\":\"41596\",\"attributes\":{\"matched_paper_id\":\"109960282\",\"id\":\"b18\"}},{\"start\":\"41598\",\"end\":\"41983\",\"attributes\":{\"id\":\"b19\",\"doi\":\"arXiv:1602.07360\"}},{\"start\":\"41985\",\"end\":\"42328\",\"attributes\":{\"matched_paper_id\":\"195908774\",\"id\":\"b20\"}},{\"start\":\"42330\",\"end\":\"42750\",\"attributes\":{\"matched_paper_id\":\"31806516\",\"id\":\"b21\"}},{\"start\":\"42752\",\"end\":\"42955\",\"attributes\":{\"matched_paper_id\":\"12625409\",\"id\":\"b22\"}},{\"start\":\"42957\",\"end\":\"43210\",\"attributes\":{\"id\":\"b23\",\"doi\":\"abs/1508.04025\"}},{\"start\":\"43212\",\"end\":\"43577\",\"attributes\":{\"matched_paper_id\":\"43680425\",\"id\":\"b24\"}},{\"start\":\"43579\",\"end\":\"43821\",\"attributes\":{\"matched_paper_id\":\"9746839\",\"id\":\"b25\"}},{\"start\":\"43823\",\"end\":\"44413\",\"attributes\":{\"matched_paper_id\":\"12424035\",\"id\":\"b26\"}},{\"start\":\"44415\",\"end\":\"44703\",\"attributes\":{\"matched_paper_id\":\"35426171\",\"id\":\"b27\"}},{\"start\":\"44705\",\"end\":\"45020\",\"attributes\":{\"id\":\"b28\",\"doi\":\"arXiv:1312.6199\"}},{\"start\":\"45022\",\"end\":\"45384\",\"attributes\":{\"matched_paper_id\":\"5077922\",\"id\":\"b29\"}},{\"start\":\"45386\",\"end\":\"45746\",\"attributes\":{\"matched_paper_id\":\"27523\",\"id\":\"b30\"}}]", "bib_title": "[{\"start\":\"35508\",\"end\":\"35591\"},{\"start\":\"35949\",\"end\":\"35998\"},{\"start\":\"36441\",\"end\":\"36504\"},{\"start\":\"36814\",\"end\":\"36842\"},{\"start\":\"37364\",\"end\":\"37464\"},{\"start\":\"38126\",\"end\":\"38214\"},{\"start\":\"38530\",\"end\":\"38577\"},{\"start\":\"38726\",\"end\":\"38804\"},{\"start\":\"39611\",\"end\":\"39715\"},{\"start\":\"41264\",\"end\":\"41354\"},{\"start\":\"41985\",\"end\":\"42048\"},{\"start\":\"42330\",\"end\":\"42366\"},{\"start\":\"42752\",\"end\":\"42766\"},{\"start\":\"43212\",\"end\":\"43280\"},{\"start\":\"43579\",\"end\":\"43662\"},{\"start\":\"43823\",\"end\":\"43900\"},{\"start\":\"44415\",\"end\":\"44460\"},{\"start\":\"45022\",\"end\":\"45082\"},{\"start\":\"45386\",\"end\":\"45458\"}]", "bib_author": "[{\"start\":\"35593\",\"end\":\"35604\"},{\"start\":\"35604\",\"end\":\"35620\"},{\"start\":\"35922\",\"end\":\"35932\"},{\"start\":\"36000\",\"end\":\"36010\"},{\"start\":\"36010\",\"end\":\"36020\"},{\"start\":\"36020\",\"end\":\"36030\"},{\"start\":\"36506\",\"end\":\"36518\"},{\"start\":\"36518\",\"end\":\"36530\"},{\"start\":\"36530\",\"end\":\"36539\"},{\"start\":\"36539\",\"end\":\"36548\"},{\"start\":\"36548\",\"end\":\"36560\"},{\"start\":\"36844\",\"end\":\"36856\"},{\"start\":\"36856\",\"end\":\"36870\"},{\"start\":\"36870\",\"end\":\"36881\"},{\"start\":\"37152\",\"end\":\"37160\"},{\"start\":\"37160\",\"end\":\"37167\"},{\"start\":\"37167\",\"end\":\"37173\"},{\"start\":\"37173\",\"end\":\"37179\"},{\"start\":\"37179\",\"end\":\"37187\"},{\"start\":\"37466\",\"end\":\"37479\"},{\"start\":\"37479\",\"end\":\"37489\"},{\"start\":\"37911\",\"end\":\"37926\"},{\"start\":\"37926\",\"end\":\"37936\"},{\"start\":\"37936\",\"end\":\"37948\"},{\"start\":\"38216\",\"end\":\"38226\"},{\"start\":\"38226\",\"end\":\"38232\"},{\"start\":\"38232\",\"end\":\"38240\"},{\"start\":\"38240\",\"end\":\"38249\"},{\"start\":\"38579\",\"end\":\"38588\"},{\"start\":\"38806\",\"end\":\"38816\"},{\"start\":\"38816\",\"end\":\"38822\"},{\"start\":\"38822\",\"end\":\"38830\"},{\"start\":\"39055\",\"end\":\"39063\"},{\"start\":\"39063\",\"end\":\"39070\"},{\"start\":\"39070\",\"end\":\"39078\"},{\"start\":\"39078\",\"end\":\"39089\"},{\"start\":\"39416\",\"end\":\"39422\"},{\"start\":\"39422\",\"end\":\"39438\"},{\"start\":\"39438\",\"end\":\"39446\"},{\"start\":\"39717\",\"end\":\"39724\"},{\"start\":\"39724\",\"end\":\"39731\"},{\"start\":\"39731\",\"end\":\"39742\"},{\"start\":\"40058\",\"end\":\"40070\"},{\"start\":\"40070\",\"end\":\"40078\"},{\"start\":\"40078\",\"end\":\"40088\"},{\"start\":\"40088\",\"end\":\"40101\"},{\"start\":\"40101\",\"end\":\"40111\"},{\"start\":\"40111\",\"end\":\"40120\"},{\"start\":\"40120\",\"end\":\"40131\"},{\"start\":\"40131\",\"end\":\"40143\"},{\"start\":\"40143\",\"end\":\"40155\"},{\"start\":\"40155\",\"end\":\"40165\"},{\"start\":\"40165\",\"end\":\"40173\"},{\"start\":\"40451\",\"end\":\"40457\"},{\"start\":\"40457\",\"end\":\"40466\"},{\"start\":\"40466\",\"end\":\"40473\"},{\"start\":\"40473\",\"end\":\"40480\"},{\"start\":\"40705\",\"end\":\"40711\"},{\"start\":\"40711\",\"end\":\"40723\"},{\"start\":\"40723\",\"end\":\"40731\"},{\"start\":\"40731\",\"end\":\"40738\"},{\"start\":\"40944\",\"end\":\"40950\"},{\"start\":\"40950\",\"end\":\"40959\"},{\"start\":\"40959\",\"end\":\"40968\"},{\"start\":\"41356\",\"end\":\"41369\"},{\"start\":\"41369\",\"end\":\"41380\"},{\"start\":\"41598\",\"end\":\"41611\"},{\"start\":\"41611\",\"end\":\"41618\"},{\"start\":\"41618\",\"end\":\"41633\"},{\"start\":\"41633\",\"end\":\"41643\"},{\"start\":\"41643\",\"end\":\"41654\"},{\"start\":\"41654\",\"end\":\"41665\"},{\"start\":\"42050\",\"end\":\"42064\"},{\"start\":\"42064\",\"end\":\"42077\"},{\"start\":\"42077\",\"end\":\"42089\"},{\"start\":\"42368\",\"end\":\"42375\"},{\"start\":\"42375\",\"end\":\"42381\"},{\"start\":\"42381\",\"end\":\"42390\"},{\"start\":\"42390\",\"end\":\"42400\"},{\"start\":\"42400\",\"end\":\"42408\"},{\"start\":\"42408\",\"end\":\"42416\"},{\"start\":\"42416\",\"end\":\"42425\"},{\"start\":\"42768\",\"end\":\"42775\"},{\"start\":\"42775\",\"end\":\"42782\"},{\"start\":\"42782\",\"end\":\"42796\"},{\"start\":\"43031\",\"end\":\"43040\"},{\"start\":\"43040\",\"end\":\"43048\"},{\"start\":\"43048\",\"end\":\"43061\"},{\"start\":\"43282\",\"end\":\"43294\"},{\"start\":\"43294\",\"end\":\"43301\"},{\"start\":\"43301\",\"end\":\"43311\"},{\"start\":\"43311\",\"end\":\"43322\"},{\"start\":\"43664\",\"end\":\"43671\"},{\"start\":\"43671\",\"end\":\"43678\"},{\"start\":\"43902\",\"end\":\"43920\"},{\"start\":\"43920\",\"end\":\"43930\"},{\"start\":\"43930\",\"end\":\"43942\"},{\"start\":\"43942\",\"end\":\"43953\"},{\"start\":\"43953\",\"end\":\"43969\"},{\"start\":\"43969\",\"end\":\"43979\"},{\"start\":\"43979\",\"end\":\"43987\"},{\"start\":\"44462\",\"end\":\"44476\"},{\"start\":\"44476\",\"end\":\"44487\"},{\"start\":\"44487\",\"end\":\"44498\"},{\"start\":\"44705\",\"end\":\"44716\"},{\"start\":\"44716\",\"end\":\"44727\"},{\"start\":\"44727\",\"end\":\"44740\"},{\"start\":\"44740\",\"end\":\"44749\"},{\"start\":\"44749\",\"end\":\"44758\"},{\"start\":\"44758\",\"end\":\"44772\"},{\"start\":\"44772\",\"end\":\"44782\"},{\"start\":\"45084\",\"end\":\"45092\"},{\"start\":\"45092\",\"end\":\"45102\"},{\"start\":\"45102\",\"end\":\"45111\"},{\"start\":\"45111\",\"end\":\"45121\"},{\"start\":\"45121\",\"end\":\"45131\"},{\"start\":\"45131\",\"end\":\"45139\"},{\"start\":\"45460\",\"end\":\"45469\"},{\"start\":\"45469\",\"end\":\"45478\"},{\"start\":\"45478\",\"end\":\"45487\"},{\"start\":\"45487\",\"end\":\"45499\"}]", "bib_venue": "[{\"start\":\"36127\",\"end\":\"36207\"},{\"start\":\"37559\",\"end\":\"37612\"},{\"start\":\"42497\",\"end\":\"42523\"},{\"start\":\"43370\",\"end\":\"43403\"},{\"start\":\"44065\",\"end\":\"44126\"},{\"start\":\"35620\",\"end\":\"35698\"},{\"start\":\"36030\",\"end\":\"36125\"},{\"start\":\"36560\",\"end\":\"36614\"},{\"start\":\"36881\",\"end\":\"36931\"},{\"start\":\"37079\",\"end\":\"37150\"},{\"start\":\"37489\",\"end\":\"37557\"},{\"start\":\"37845\",\"end\":\"37909\"},{\"start\":\"38249\",\"end\":\"38308\"},{\"start\":\"38588\",\"end\":\"38613\"},{\"start\":\"38830\",\"end\":\"38879\"},{\"start\":\"39104\",\"end\":\"39169\"},{\"start\":\"39335\",\"end\":\"39414\"},{\"start\":\"39742\",\"end\":\"39794\"},{\"start\":\"40003\",\"end\":\"40056\"},{\"start\":\"40405\",\"end\":\"40449\"},{\"start\":\"40610\",\"end\":\"40703\"},{\"start\":\"40984\",\"end\":\"41077\"},{\"start\":\"41380\",\"end\":\"41411\"},{\"start\":\"41681\",\"end\":\"41764\"},{\"start\":\"42089\",\"end\":\"42138\"},{\"start\":\"42425\",\"end\":\"42495\"},{\"start\":\"42796\",\"end\":\"42844\"},{\"start\":\"42957\",\"end\":\"43029\"},{\"start\":\"43322\",\"end\":\"43368\"},{\"start\":\"43678\",\"end\":\"43682\"},{\"start\":\"43987\",\"end\":\"44063\"},{\"start\":\"44498\",\"end\":\"44547\"},{\"start\":\"44797\",\"end\":\"44837\"},{\"start\":\"45139\",\"end\":\"45183\"},{\"start\":\"45499\",\"end\":\"45542\"}]"}}}, "year": 2023, "month": 12, "day": 17}