{"id": 248780527, "updated": "2022-07-03 14:20:13.221", "metadata": {"title": "ParaDetox: Detoxification with Parallel Data", "authors": "[{\"first\":\"Varvara\",\"last\":\"Logacheva\",\"middle\":[]},{\"first\":\"Daryna\",\"last\":\"Dementieva\",\"middle\":[]},{\"first\":\"Sergey\",\"last\":\"Ustyantsev\",\"middle\":[]},{\"first\":\"Daniil\",\"last\":\"Moskovskiy\",\"middle\":[]},{\"first\":\"David\",\"last\":\"Dale\",\"middle\":[]},{\"first\":\"Irina\",\"last\":\"Krotova\",\"middle\":[]},{\"first\":\"Nikita\",\"last\":\"Semenov\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Panchenko\",\"middle\":[]}]", "venue": "ACL", "journal": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "We present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxic-neutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task.We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources.We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": "2022.acl-long.469", "pubmed": null, "pubmedcentral": null, "dblp": "conf/acl/LogachevaDUMDKS22", "doi": "10.18653/v1/2022.acl-long.469"}}, "content": {"source": {"pdf_hash": "b2a90a23fe93032bfe85dd4de91edd186d89ab31", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2022.acl-long.469.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c51429bf909cc4e1cde4ba658dd0ee9bf0e8e572", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/b2a90a23fe93032bfe85dd4de91edd186d89ab31.txt", "contents": "\nParaDetox: Detoxification with Parallel Data\nLong PapersCopyright Long PapersMay 22-27, 2022\n\nVarvara Logacheva v.logacheva@skoltech.ru \nSkolkovo Institute of Science and Technology\nRussia\n\nDaryna Dementieva daryna.dementieva@skoltech.ru \nSkolkovo Institute of Science and Technology\nRussia\n\nData and Web Science Group\nUniversity of Mannheim\nGermany\n\nSergey Ustyantsev s.ustyantsev@skoltech.ru \nSkolkovo Institute of Science and Technology\nRussia\n\nDaniil Moskovskiy daniil.moskovskiy@skoltech.ru \nSkolkovo Institute of Science and Technology\nRussia\n\nDavid Dale d.dale@skoltech.ru \nSkolkovo Institute of Science and Technology\nRussia\n\nIrina Krotova i.krotova@mts.ai \nMobile TeleSystems (MTS)\nRussia\n\nNikita Semenov nikita.semenov@mts.ru \nMobile TeleSystems (MTS)\nRussia\n\nAlexander Panchenko a.panchenko@skoltech.ru \nSkolkovo Institute of Science and Technology\nRussia\n\nParaDetox: Detoxification with Parallel Data\n\nProceedings of the 60th Annual Meeting of the Association for Computational Linguistics\nthe 60th Annual Meeting of the Association for Computational LinguisticsLong Papers1May 22-27, 2022\nWe present a novel pipeline for the collection of parallel data for the detoxification task. We collect non-toxic paraphrases for over 10,000 English toxic sentences. We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxicneutral sentence pairs. We release two parallel corpora which can be used for the training of detoxification models. To the best of our knowledge, these are the first parallel datasets for this task. We describe our pipeline in detail to make it fast to set up for a new language or domain, thus contributing to faster and easier development of new parallel resources.We train several detoxification models on the collected data and compare them with several baselines and state-of-the-art unsupervised approaches. We conduct both automatic and manual evaluations. All models trained on parallel data outperform the state-of-the-art unsupervised models by a large margin. This suggests that our novel datasets can boost the performance of detoxification systems.\n\nIntroduction\n\nDetection of toxicity (Zampieri et al., 2019) and other undesirable content, e.g. microaggressions (Breitfeller et al., 2019) or patronizing speech (Perez Almendros et al., 2020), is a popular topic of research in NLP. However, detection of harmful messages does not offer any proactive ways of fighting them (besides deletion). We suggest that such messages could be automatically rewritten to keep the useful content intact and eliminate toxicity.\n\nThe task of rewriting toxic messages (detoxification) has already been tackled by NLP researchers (Nogueira dos Santos et al., 2018;Tran et al., 2020). It is considered a variant of style transfer task, the task of rewriting a text saving * Equal contribution the content and changing the style (style is defined as a characteristic of text such as sentiment, level of formality, or politeness, author profile (gender, political preferences), etc.). As a sequence-tosequence task, style transfer can be performed with an encoder-decoder model trained on parallel data. However, there exist only a few parallel style transfer corpora (Carlson et al., 2018;Pryzant et al., 2020). Since they usually do not exist \"naturally\", they need to be written from scratch. This is an expensive and laborious process. Thus, such parallel datasets are extremely rare. Jigsaw so why would anyone believe this moron?\n\nParaphrase so why would anyone believe this person? so why would anyone believe somebody like him?\n\nReddit dude ham sandwich is the good sh*t .\n\nParaphrase dude ham sandwich is the good thing The ham sandwich, buddy, is the bomb. Dude ham sandwich is good.\n\nTwitter now i feel like an a*s Paraphrase now i feel like worthless now i feel very bad now i feel bad We aim at boosting the research in detoxification by collecting an English parallel corpus of toxic sentences and their non-toxic paraphrases. We suggest a new crowdsourcing pipeline for collecting parallel style transfer data. It does not employ experts, which makes the data collection faster and cheaper. In addition to generating the detoxified versions of texts, we consider a way to distill existing datasets of paraphrases for style-specific data. In particular, we find the pairs of toxic and non-toxic sentences in the paraNMT dataset (Wieting and Gimpel, 2018) of English paraphrases and filter them using our crowdsourcing setup. The pipelines are described in detail to make them easy to replicate. Thus, we suggest that by reusing these pipelines the new parallel style transfer datasets can be collected in a fast and affordable way.\n\nFinally, we validate the usefulness of our datasets by training detoxification models on them and comparing their performance with state-of-theart methods. Models trained on parallel data significantly outperform other models in terms of automatic metrics and human evaluation.\n\nThe contributions of our work are three-fold:\n\n\u2022 We suggest a novel pipeline for collection of parallel data for the detoxification task, \u2022 We use the pipeline to collect the first parallel detoxification dataset ParaDetox (see Table 1 and Appendix A) and retrieve toxic-neutral pairs from ParaNMT corpus, 1 \u2022 Using collected data we train supervised detoxification models that yield SOTA results.\n\n\nRelated Work\n\nStyle Transfer Datasets When collecting nonparallel style transfer corpora, style labels often already exist in the data (e.g. positive and negative reviews (Li et al., 2018)) or its source serves as a label (e.g. Twitter, academic texts, legal documents, etc.). Thus, data collection is reduced to fetching the texts from their sources, and the corpus size depends only on the available amount of text. Conversely, parallel corpora are usually more difficult to get. There exist parallel style transfer datasets fetched from \"naturally\" available parallel sources: the Bible dataset (Carlson et al., 2018) features multiple translations of the Bible from different epochs, biased-to-neutral Wikipedia corpus (Pryzant et al., 2020) uses the information on article edits.\n\nBesides these special cases, there exists a large style transfer dataset that was created from scratch. This is the GYAFC dataset (Rao and Tetreault, 2018) of informal sentences and their formal versions written by crowd workers and reviewed by experts. Since toxic-neutral pairs also do not occur in the wild, we follow this data collection setup with a notable difference -we replace expert validation of crowdsourced sentences with crowd validation and additionally optimize the cost.\n\n\nStyle Transfer and Detoxification\n\nThe vast majority of style transfer models (including detoxification models) are trained on non-parallel data. They can perform pointwise corrections of stylemarked words (Li et al., 2018;Wu et al., 2019;Malmi et al., 2020). Alternatively, some works train encoder-decoder models on non-parallel data and push decoder towards the target style using adversarial classifiers (Shen et al., 2017;Fu et al., 2018). As another way of fighting the lack of parallel data, researchers jointly train source-to-target and target-to-source style transfer models using reinforcement learning (Luo et al., 2019), amortized variational inference (He et al., 2020), or information from a style transfer classifier (Lee, 2020).\n\nDetoxification is usually formulated as style transfer from toxic to neutral (non-toxic) style, so it uses non-parallel datasets labeled for toxicity and considers toxic and neutral sentences as two subcorpora. Laugier et al. (2021) use the Jigsaw datasets (Jigsaw, 2018(Jigsaw, , 2019(Jigsaw, , 2020 for training, Nogueira dos Santos et al. (2018) create their own toxicity-labelled datasets of sentences from Reddit and Twitter. Following them, we also fetch sentences for rewriting from these datasets.\n\nWorks on detoxification often rely on style transfer models tested on other domains. Nogueira dos Santos et al. (2018) follow Shen et al. (2017) and Fu et al. (2018) and train an autoencoder with additional style classification and cycle-consistency losses. Laugier et al. (2021) perform a similar finetuning of T5 as a denoising autoencoder. Tran et al. (2020) apply pointwise corrections approach similar to that of Wu et al. (2019) and then improve the fluency of a text with a seq2seq model. Likewise, Dale et al. (2021) use a masked language model to perform pointwise edits of toxic sentences. They also suggest an alternative model which enhances a style-agnostic seq2seq model with style-informed language models which reweigh the seq2seq hypotheses with respect to the desired style.\n\nWhen the parallel data is available, the majority of researchers use Machine Translation tools (Briakou et al., 2021) and pre-trained language models  to perform style transfer. We follow this practice by fine-tuning BART model (Lewis et al., 2020) on our data.\n\n\nData Collection Pipeline\n\nOur goal is to yield pairs of sentences that have the same meanings and are contrasted in terms of  offensiveness -one of the sentences is toxic and the other is neutral. We consider two scenarios: the manual rewriting of toxic sentences into neutral ones and the selection of toxic-neutral pairs from existing paraphrases. Unlike a similar work of Rao and Tetreault (2018), we hire crowd workers not only for the generation of paraphrases but also for their validation, which reduces both time and cost.\n\n\nCrowdsourcing Tasks\n\nWe ask crowd workers to generate paraphrases and then evaluate them for content preservation and toxicity. Each task is implemented as a separate crowdsourcing project. We use the crowdsourcing platform Yandex.Toloka. 2\n\nTask 1: Generation of Paraphrases The first crowdsourcing task asks users to eliminate toxicity in a given sentence while keeping the content (see the task interface in Figure 1). However, it is not always possible. Some sentences cannot be detoxified, because they do not contain toxicity or because they are meaningless. Moreover, in some cases toxicity cannot be removed. Consider the examples:\n\n\u2022 Are you that dumb you can't figure it out? \u2022 I've finally understood that wiki is nothing but a bunch of American racists.\n\nNot only the form but also the content of the messages are offensive, so trying to detoxify them would inevitably lead to a substantial change of sense. We prefer not to include such cases in the parallel dataset. If workers have to detoxify all inputs without a possibility to skip them, a large proportion of the generated paraphrases will be of low quality. Thus, we add the control \"I can't rewrite the text\" and optional controls to indicate the reasons.\n\nTask 2: Content Preservation Check We show users the generated paraphrases along with their original variants and ask them to indicate if they have close meanings. Besides ensuring content preservation, this task implicitly filters out senseless outputs, because they do not keep the original content. The task interface is shown in Figure 2.\n\nTask 3: Toxicity Check Finally, we check if the workers succeeded in removing toxicity. We ask users to indicate if the paraphrases contain any offense or swear words (see Figure 3).\n\nIn addition to filtering out unsuitable paraphrases, we use Tasks 2 and 3 for paying for Task 1. We accept or reject the generated paraphrases based on the labels they get in Tasks 2 and 3.\n\n\nPipelines\n\nGeneration Pipeline To yield a parallel dataset, we first need to get toxic sentences for rewriting. We fetch them from corpora labeled for toxicity and additionally filter them with a toxicity classifier (described in Section 3.3). The overall data collection pipeline (see Figure 4) is as follows:\n\n\u2022 Select toxic sentences for rewriting, \u2022 Feed the sentences to Task 1, \u2022 Feed the paraphrases generated in Task 1 to Task 2, \u2022 Feed the paraphrases which passed Task 2 to Task 3, \u2022 Pay for paraphrases from Task 1, if they passed checks in Task 2 and Task 3, \u2022 Pay for \"I can't rewrite\" answers in Task 1 if two or more workers agreed on them.\n\nDoes this text contain offenses or swear words?\n\n\nYes\n\nDo you realize that's wrong?\n\nNo Figure 3: Interface of Task 3 (evaluation of toxicity).\n\n\nRetrieval Pipeline\n\nThe generation pipeline can be used for cases when no parallel data is available. However, we suggest that a sufficiently large parallel corpus of paraphrases can contain pairs of sentences belonging to different styles, and it is possible to distill such corpus into a style transfer dataset. We check this hypothesis for the toxic and neutral styles on the ParaNMT dataset (Wieting and Gimpel, 2018). We partially reuse the previously described setup. We do not need Task 1 since both toxic and neutral sentences are already available. However, we run Task 3 twice, because we need to check both parts of the pair for toxicity. Analogously to the generation pipeline, we use a toxicity classifier to pre-select pairs of sentences where one sentence is toxic and the other one is neutral. The parallel data retrieval pipeline is shown in Figure 5. It is simpler because Tasks 2 and 3 do not serve for paying for the generated paraphrases and are only used for data filtering. The pipeline is as follows:\n\n\u2022 Select a pair of sentences (toxic and non-toxic) from the parallel data, \u2022 Feed the toxic sentence candidate to Task 3 to make sure it is toxic, \u2022 Feed the neutral sentence candidate to Task 3 to make sure it is non-toxic, \u2022 Feed both sentences to Task 2 to check if their content matches.\n\n\nCrowdsourcing Settings\n\nPreprocessing To pre-select toxic sentences, we need a toxicity classifier. We fine-tune a RoBERTa model (Liu et al., 2019) 3 on half of the three merged Jigsaw datasets (Jigsaw, 2018(Jigsaw, , 2019(Jigsaw, , 2020 (1 million sentences) and get a classifier which yields the F 1 -score of 0.76 on the Jigsaw test set (Jigsaw, 2018). We consider a sentence toxic if the classifier confidence is above 0.8. To make the sentences easier for reading and rewriting, we choose the ones consisting of 5 to 20 tokens. For the retrieval pipeline, we also select parallel sentences with the cosine similarity of embeddings between 0.65 and 0.8. The similarity scores were provided as a part of ParaNMT dataset, the embeddings come from the PARAGRAM-PHRASE model (Wieting et al., 2016). Based on a manual validation, sentences with lower similarity are often not exact paraphrases, and too-similar sentences are either both toxic or both non-toxic.\n\nQuality Control To perform paid tasks, users need to pass training and exam sets of tasks. Each of them has a corresponding skill -the percentage of correct answers. It is assigned to a user upon completing training or exam and serves for filtering out low-performing users. Besides that, users are occasionally given control questions during labeling. They serve for computing the labeling skill which can be used for banning low-performing and rewarding well-performing workers. The overall training and control pipeline is shown in Figure 6. It is used in Tasks 2 and 3. In Task 1 we perform different quality control. We ban users who submit answers which are: (i) a copy of the input, (ii) too short (< 3 tokens) or too long (more than doubled original length), (iii) contain too many rare words or non-words. The latter condition is checked as follows. We compute the ratio of the number of whitespace-separated tokens and the number of tokens identified by the BPE tokeniser (Sennrich et al., 2016). 4 The rationale behind this check is that the BPE tokenizer tends to divide rare words into multiple tokens. If the number of BPE tokens in a sentence is two times more than the number of regular tokens, it might indicate the presence of non-words. We filter out these answers and ban users who produce them.\n\nIn addition to that, we ban malicious workers using built-in Yandex.Toloka tools: (i) captcha, (ii) number of skipped questions -we ban users who skip 10 task pages in a row, and (iii) task completion time -we ban those who accomplish tasks too fast (this usually means that they choose a random answer without reading).\n\nPayment In Yandex.Toloka, a worker is paid for a page that can have multiple tasks (the number is set by customer). In Task 1, a page contains 5 tasks and costs $0.02. In Tasks 2 and 3, we pay $0.02 1-day ban Figure 6: Training and quality control pipeline for Tasks 2 and 3. and $0.01, respectively, for 12 tasks. In addition to that, in these tasks, we use skill-based payment. If a worker has the labeling skill of above 90%, the payment is increased to $0.03 (Task 2) and $0.02 (Task 3).\n\nTasks 2 and 3 are paid instantly, whereas in Task 1 we check the paraphrases before paying. If a worker indicated that a sentence cannot be paraphrased, we pay for this answer only if at least one other worker agreed with that. If a worker typed in a paraphrase, we send it to Tasks 2 and 3 and pay only for the ones approved by both tasks. The payment procedure is shown in Figure 4.\n\nPostprocessing To ensure the correctness of labeling, we ask several workers to label each example. In Task 1, this gives us multiple paraphrases and also verifies the \"I can't rewrite\" answers. For Tasks 2 and 3, we compute the final label using the Dawid-Skene aggregation method (Dawid and Skene, 1979) which defines the true label iteratively giving more weight to the answers of workers who agree with other workers more often. The number of people to label an example ranges from 3 to 5 depending on the workers' agreement.\n\nDawid-Skene aggregation returns the final label and its confidence. To improve the quality of the data, we accept only labels with the confidence of over 90% and do not include the rest in the final data.\n\n\nThe Pipeline Scalability\n\nThe Yandex.Toloka platform has an interface in English and workers from a large number of countries. Workers can be filtered by their location and asked to pass built-in language tests (available for many languages) to ensure the knowledge of a particular language. This enables the use of Toloka for the creation of NLP resources in many languages.\n\nIn our work, crowd workers manually rephrase sentences from non-parallel datasets. The pipeline does not require any specific data format and can be applied to any text. The only prerequisites are to define the source and target styles and to formulate the task of transferring between them. Thus, we believe that the pipeline is suitable for creating parallel datasets for any other style transfer tasks, at least those which have non-parallel datasets and clear definitions of style (positive \u2194 negative, complex \u2194 simple, impolite \u2194 polite, etc.).\n\nWe should admit that our pipeline suggests the availability of (non-parallel) datasets in the chosen styles or at least publicly available sources of such data (e.g. social networks, question answering platforms). However, this is also a prerequisite for any style transfer model trained on non-parallel data. Therefore, any work on style transfer suggests that there exists enough data in the chosen style pair and language. This should not be considered a specific limitation of the pipeline.\n\n\nParaDetox: Generated Paraphrases\n\nWe fetched toxic sentences from three sources: Jigsaw dataset of toxic sentences (Jigsaw, 2018), Reddit and Twitter datasets used by Nogueira dos Santos et al. (2018). We selected 7,000 toxic sentences from each source and gave each of the sentences for paraphrasing to 3 workers. We get paraphrases for 12,610 toxic sentences (on average 1.66 paraphrases per sentence), 20,437 paraphrases total. Running 1,000 input sentences through the pipeline costs $41.2, and the cost of one output sample is $0.07. The overall cost of the dataset is $811.55. We give them examples of sentences in Appendix A. In addition to that, we provide some samples which could not be detoxified in Appendix C. The statistics of the paraphrases written by crowd workers are presented in Table 2.\n\nThe distribution of sentences from different datasets in the final data is not equal. Jigsaw turned out to be the most difficult to paraphrase. Fewer sentences from it are successfully paraphrased, making it the most expensive part of the collected corpus ($0.08 per sample). Figure 7 shows that the number of untransferable sentences in the Jigsaw dataset is larger than that of other corpora.  Out of all crowdsourced paraphrases, only a small part was of high quality. We plot the percentage of paraphrases which were filtered out by content and toxicity checks in Figure 8. It also corroborates the difficulty of the Jigsaw dataset. While the overall number of generated paraphrases was slightly higher for it, much more of them were discarded. \n\n\nAnalysis of Edits\n\nAlthough we did not give any special instructions to workers about editing, they often followed the minimal editing principle, making 1.36 changes per sentence on average. A change is deletion, insertion, or rewriting of a word or multiple adjacent words. Many of the changes are supposedly deletions because the average sentence length drops from 12.1 to 10.4 words after editing. The nature of editing differs for the three datasets. We compute the percentage of edits which consisted of removing the most common swear words or replacing them with neutral words. We first define the differences between the original and transformed string with the difflib Python library and then compute the percentage of differences that consist in editing swear words and other (non-offensive) words. We use a small manually compiled list of swear words which includes words f*ck, sh*t, a*s, b*tch, d*mn and their variants. Table 3 shows that the deletion or replacements of the most common swearing constituted a large part of all edits for Reddit and Twitter datasets (22% and 30%), while for Jigsaw it was only 3%.\n\nAnother surprisingly common type of editing is the normalization of sentences. The users often fixed casing, punctuation, typos (e.g. dont \u2192 don't, there's \u2192 there is). They also tended to replace colloquial phrases with more formal and standard language. Finally, some users overcorrected the sentences. For example, they replaced neutral words such as dead, murder, penis with euphemisms. This tendency indicates that workers consider any sensitive topic to be inappropriate content and try to avoid it as much as possible.\n\n\nParaNMT: Existing Paraphrases\n\nOur automatic filtering of ParaNMT for content yields 500,000 potentially detoxifying sentence pairs, which is 1% of the corpus. We then sample 6,000 random pairs from this list and ask workers to evaluate them for toxicity and content preservation. This leaves with 1,393 sentences, meaning that around 23% of the pre-selected sentence pairs were approved (for ParaDetox we get paraphrases for 61% input sentences). Thus, although the cost per 1,000 inputs is much lower than that of generating the paraphrases, the cost per output sample is the same as that of generated paraphrases.\n\nParaNMT dataset is different from ParaDetox. First, each sentence has only one paraphrase. These   paraphrases were not gained via manual editing but via a chain of translation models. Thus, neutral sentences are less similar to the toxic sentences, and the edits are more diverse, which makes it more similar to Jigsaw dataset (see Table 3).\n\n\nEvaluation\n\nTo evaluate the collected corpora, we use them to train several supervised detoxification models. We separate the ParaDetox dataset into training and test parts (11,939 and 671 sentence pairs, respectively). The test sentences have one reference per sentence. We manually validate the test set to exclude the appearance of non-detoxifiable sentences or sentences which stayed toxic after rewriting (we need to verify that since the corpus was generated via crowdsourcing only). We do not use the test set neither for training nor for parameter selection of the models.\n\n\nModels\n\nWe fine-tune a Transformer-based generation model BART (Lewis et al., 2020) 5 on our data. We test BART trained on the following datasets: 5 We use model https://huggingface.co/facebook/bart-base \u2022 ParaDetox -our full crowdsourced dataset.\n\n\u2022 ParaDetox-unique -a subset of ParaDetox where each toxic sentence has only one paraphrase (selected randomly). \u2022 ParaDetox-1000 -1,000 samples from the crowdsourced dataset (distributed evenly across data sources, each toxic sample has multiple non-toxic variants). \u2022 ParaNMT -filtered ParaNMT corpus, auto stands for automatically filtered 500,000 samples, manual are 1,393 manually selected sentence pairs.\n\nWe train BART for 10,000 epochs with the learning rate of 3e-5 and the number of gradient accumulation steps set to 1. The other parameters are set to their default values.\n\nWe also compare our models to other style transfer approaches:\n\n\u2022 Duplicate (baseline) -copy of the input, LMs which re-weigh its output.\n\n\nMetrics\n\nWe compute the BLEU score on the test set. In addition to that, we perform automatic referencefree evaluation which is used in many style transfer works. Namely, we evaluate:\n\n\u2022 Style accuracy (STA) -percentage of nontoxic outputs identified by a style classifier. We use a classifier from Section 3.3 trained on a different half of Jigsaw data. \u2022 Content preservation (SIM) -cosine similarity between the embeddings of the original text and the output computed with the model of Wieting et al. (2019). This model is trained on paraphrase pairs extracted from ParaNMT corpus. The model's training objective is to yield embeddings such that the similarity of embeddings of paraphrases is higher than the similarity between sentences that are not paraphrases.  We compute the final joint metric (J) as the multiplication of the three individual metrics.\n\nSince the automatic evaluation can be unreliable, we evaluate some models manually. We randomly select 200 sentences from the test set and ask assessors to evaluate them along the same three parameters: style accuracy (STA m ), content preservation (SIM m ), and fluency (FL m ). All parameters can take values of 1 (good) and 0 (bad). We also report the joint metric J m which is the percentage of sentences whose STA m , SIM m , and FL m are 1.\n\nThe evaluation was conducted by 6 NLP researchers with a good command of English. Each sample was evaluated by 3 assessors. The interannotator agreement (Krippendorff's \u03b1) reaches 0.64 (STA m ), 0.67 (SIM m ), and 0.68 (FL m ). Table 4 shows the automatic scores of all tested models. Our BART models trained on ParaDetox outperform other systems in terms of BLEU and J. The much lower scores of BART-zero-shot confirm that this success is due to fine-tuning and not the innate ability of BART. The majority of unsupervised SOTA approaches are not only worse than BART but also perform below the \"change nothing\" baseline. The closest competitor of our models is the Delete model. This can be explained by the fact that crowd workers often only remove or replaced swear words which is what the Delete model does.\n\n\nResults\n\n\nAutomatic Evaluation\n\nWhen comparing models trained on supervised data, we can see that BART does not benefit from multiple detoxifications per sentence, its performance is the same when trained on ParaDetox and ParaDetox-unique. On the other hand, manual filtering of ParaNMT is beneficial, it increases the quality of BART trained on it, although the number of training sentences drops from 500,000 to 1,400.\n\nWe also check which amount of data is sufficient for a high detoxification quality. We train the BART model on subsets of ParaDetox of different sizes. Figure 9 and the performance of ParaDetox-1000 model (Table 4) show that 1,000 training samples is enough to get a good detoxification. While SIM and FL are already high for vanilla BART (see BART-zero-shot model), STA can be improved with only a few parallel examples. This suggests that style transfer does not need large parallel corpora, making our pipeline more useful for other style transfer tasks. However, this is the result of the automatic evaluation, which as we show below is not always reliable. It needs extra investigation.     \n\n\nConclusions\n\nWe present ParaDetox -an English parallel corpus for the detoxification task. It contains almost 12,000 user-generated toxic sentences manually rewritten by crowd workers. To the best of our knowledge, this is the first parallel detoxification dataset. We present a novel data collection pipeline and show that parallel data can be generated using only crowdsourcing. We also adopt this pipeline to the style-based distillation of paraphrase corpus.\n\nWe confirm the usefulness of our datasets by training sequence-to-sequence models on them. The experiments show that the use of parallel data yields models which significantly outperform style transfer models trained on non-parallel data. Besides that, we confirm that filtering the noisy parallel data can lead to considerable improvement.\n\nWe see that it is enough to get 1,000 parallel sentences to perform detoxification with high quality. This suggests that our pipeline can be successfully applied to create useful parallel resources for style transfer even in cases of limited finance or lack of crowd workers because the cost of generating 1,000 examples is very low.\n\nFinally, we investigate the relationship between metrics and find that automatic evaluation does not always match the manual judgments and referencebased BLEU cannot replace human evaluation, because it measures content preservation.\n\n\nAcknowledgements\n\nThis work was supported by a joint MTS-Skoltech laboratory on AI.\n\n\nEthical Considerations\n\nThe research on toxicity raises some ethical issues. In terms of our work, the parallel corpus we created can indeed be used in the reverse direction, i.e. to \"toxify\" sentences. However, although we did not thoroughly evaluate the quality of such toxification, our intuition is that it would not be high enough to make the corrupted sentences look natural. The reason is that the toxic part of our corpus consists of real toxic sentences fetched on the Internet, whereas their non-toxic counterparts are \"translations\" performed by crowd workers. We suggest that they obey the common regularities observed for translationese (texts manually translated from their original language into a different one): they differ from regular texts in terms of vocabulary (Koppel and Ordan, 2011) and syntax (Lembersky et al., 2011). The manually detoxified texts are different from the original non-toxic texts written by Internet users from scratch. While they are still recognized by human assessors as plausible sentences, we suggest that a sequence-to-sequence model trained to get translationese as input would not be as successful in transforming real texts (as it was shown for machine translation models (Freitag et al., 2019)).\n\nThus, although our corpus can be used in the reverse direction, it is not symmetric, which makes it less efficient as training datasets for \"toxifiers\". However, we should emphasize that these statements are our hypotheses and should be further investigated. Finally, we argue that the risk of using our corpus for toxification is perhaps not game-changing, as simpler approaches based on patterns (e.g. including a set of predefined obscene fragments into neutral texts) can serve the same purpose relatively well.   Table 8 contains the outputs of four well-performing detoxification models: Delete model which deterministically removes swear words, unsupervised ParaGeDi and CondBERT models (Dale et al., 2021), and BART model fine-tuned on our parallel ParaDetox dataset.\n\n\nA ParaDetox Samples\n\n\n6816\n\n\nB Outputs of Detoxification Models\n\nOriginal at least one party gives a cr*p about humans after birth.\n\nDelete at least one party gives a about humans after birth. CondBERT at least one party gives a whole story about humans after birth. ParaGeDi\n\nAt the same time, at least one party doesn't believe in human life after birth BART-ParaDetox at least one party cares about humans after birth.\n\nOriginal gosh, discrimination is such a b*tch! Delete gosh, discrimination is such a! CondBERT gosh, discrimination is such a thing! ParaGeDi\n\nGosh, discrimination is a bit of a bad thing! BART-ParaDetox Discrimination is bad!\n\nOriginal he ll f*ck that up too.\n\nDelete he ll that up too. CondBERT he ll ' ve picked that up too. ParaGeDi\n\nHe'll get that up.\n\n\nBART-ParaDetox\n\nHe will mess that up too.\n\nOriginal whats the title of this report, no sh*t?\n\nDelete whats the title of this report, no? CondBERT whats the title of this report , no stuff? ParaGeDi\n\nWhat's the name of the report, no? BART-ParaDetox whats the title of this report?\n\nOriginal because its f*cking reposted so much Delete because its reposted so much CondBERT because its parents have been reposted so much ParaGeDi\n\nBecause it'd been so much re-enacted.\n\n\nBART-ParaDetox\n\nBecause it reposted so much.\n\nOriginal to suggest otherwise is stupidly inflammatory.\n\nDelete to suggest otherwise is stupidly inflammatory. CondBERT to suggest otherwise is not necessarily inflammatory. ParaGeDi\n\nSaying otherwise would be a bad thing.\n\n\nBART-ParaDetox\n\nTo suggest otherwise is inappropriate.\n\nOriginal he hasn t done sh*t for palestine.\n\nDelete he hasn t done for palestine. CondBERT he hasn t done much else for palestine. ParaGeDi\n\nHe hasn't done it for palestine.\n\n\nBART-ParaDetox\n\nHe hasn't done anything for palestine. \n\n\n6817\n\nC Non-detoxifiable Samples Table 9 gives examples of sentences which could not be detoxified by any of workers who tried to do that. We group the samples by the reasons of the inability to detoxify that the workers indicated.\n\n\nUnclear content\n\nshe is! f*ck's sake stross! *fights against you* yourwhy bring in the red herring of extramarital sex, getting desperate aj? wikibofh f*ck u u f*ckin suck argument is fine u nerd now unblock me. you have to be a complete idiot to be supporting the gop ticket this go around. wikipedia review and tell the world why you not a grand d*ckhead trump will make a fool out of little potato dont dumb as in dead dummy. justin and his rat pack have an agenda. trump was an embarrassment to the u that guy knew how to kill commies like nobodys business! some stinks cannot be unstunk.\n\n\nToxic content\n\nf*ck you you mother f*cking a*s cracker dildo licking piece of f*cking a*s sh*t! if by christian you mean hypocrites. lying anti american muslim mouthpiece. they simply are too stupid to do otherwise. xman is either an idiot or a psychopath or maybe both. youre the insignificant f*ck mother f*cker! hello, you sexy little lovehole! obviously feminists cant be good mothers or wives. we are country of losers and abusers. are you a troublemaker or just plain stupid or both? as anyone with half a brain would do.\n\n\nNo toxicity\n\nthis is all coming out of our darned pockets, and i am not confident! you people complete lack morals. this idea seems to be a rather ignorant one. youre implying, therefore, that women ought to stay away from all black men. blaming everyone else for the hole that you dug is pathetic. killing the innocent nearly born should be the very last choice. ignorant to me means without knowledge. how can students of colour be expected to learn in such a toxic environment of white supremacy? the problem is that their management is so ridiculously incompetent. trump will keep on committing political suicide. making stupid remarks is useless, do some research and then make a comment. \n\nFigure 1 :\n1Interface of Task 1 (paraphrases generation).\n\nFigure 2 :\n2Interface of Task 2 (evaluation of content match).\n\nFigure 7 :\n7Number of paraphrases per input.\n\nFigure 8 :\n8Data filtering output.\n\n\u2022\nDelete (baseline) -deletion of swear words, \u2022 BART-zero-shot (baseline) -BART model with no additional training. \u2022 Mask&Infill (Wu et al., 2019) -BERT-based pointwise editing model, \u2022 Delete-Retrieve-Generate models (Li et al., 2018): DRG-Template (replacement of toxic words with similar neutral words) and DRG-Retrieve (retrieval of non-toxic sentences with the similar sense) varieties. \u2022 DLSM (He et al., 2020) encoder-decoder model that uses amortised variational inference, \u2022 SST (Lee, 2020) -encoder-decoder model with the cross-entropy of a pretrained style classifier as an additional discriminative loss. \u2022 CondBERT (Dale et al., 2021) -BERT-based model with extra style and content control, \u2022 ParaGeDi (Dale et al., 2021) -a model which enhances a paraphraser with style-informed\n\nFigure 9 :\n9Scores of BART models trained on parallel data subsets of different sizes.\n\nTable 1 :\n1Examples of detoxified sentences from the collected parallel corpus.\n\n\nRewrite this text so that it does not sound offensive and its meaning stays the same You realize that's stupid, don't you?Your text \n\nI can't rewrite the text \n\nThe text is meaningless \n\nThe text is not offensive \n\nRemoving the offense will change \nthe meaning \n\nOther Your reason \n\n\n\nTask 1 :\n1Rewrite the text Task 2: Do the texts match? Task 3: Is this text toxic? Figure 4: The pipeline of crowdsourcing for generation of detoxifying paraphrases.Figure 5: The retrieval pipeline.Accept payment \nfor Task 1 \n\nReject payment \nfor Task 1 \n\nToxic \nsentence \n\nToxic \nsentence \n\nNeutral \nsentence \nNeutral \nsentence \n\nNeutral \nsentence \nCan't \nrewrite \n\nToxic \nsentence \n\nNeutral \nsentence \n\nYes \nNo \n\nYes \nNo \nParallel \ndataset \nNo one \nagrees \n\nOther \nworkers \nagree \n\nTask 2: \nDo the texts match? \n\nTask 3: \nIs this text toxic? \n\nToxic \nsentence \n\nNeutral \nsentence \n\nNeutral \nsentence \n\nToxic \nsentence \n\nNeutral \nsentence \n\nYes \n\nParallel \ndataset \n\nTask 3: \nIs this text toxic? \n\nToxic \nsentence \n\nYes \n\nNo \n\nTraining \nExam \nPaid tasks \n\nTraining skill \nExam skill \nLabelling skill \n\n1-day ban \nIncreased \npayment \n\n<40% \n\n>40% \n<80% \n\n>80% \n>90% \n<60% \n\n\n\nTable 2 :\n2Statistics of the crowdsourcing experiments and final datasets.Swear words \nOther phrases \n\nDataset \nDel \nRep \nDel Rep Ins \n\nJigsaw \n2.3% 0.6% 30% 60% 6.8% \nReddit \n19% 9.1% 26% 41% 5.7% \nTwitter \n15% 7.1% 23% 47% 8.2% \n\nParaNMT 1.6% 1.2% 19% 64% 14% \n\n\n\nTable 3 :\n3Percentage of common swear words (f*ck, sh*t, a*s and their common variants) and other words Deleted, Replaced, or Inserted by crowd workers.\n\nTable 4 :\n4Automatic evaluation of detoxification models. Numbers in bold indicate the best results. Rows in gray indicate the baselines.\n\nTable 5 :\n5Examples of detoxifications by different models. Bad answers are shown in red, best answers in bold.\n\nTable 5\n5shows examples of different models output. Delete performs deterministic operations which can return disfluent text. CondBERT has to insert something instead of a toxic word, which is not always a good strategy. ParaGeDi generates sentences from scratch, which sometimes results in a distorted sense. BART trained on parallel data is usually free of these drawbacks. More examples of outputs are available in Appendix B.STAm SIMm FLm \nJm \n\nDelete \n0.785 \n0.445 \n0.365 0.21 \nCondBERT \n0.935 \n0.250 \n0.615 0.15 \nParaGeDi \n0.930 \n0.415 \n0.870 0.37 \n\nBART-ParaDetox \n0.830 \n0.925 \n0.960 0.76 \nBART-ParaNMT-man 0.750 \n0.705 \n0.960 0.50 \n\n\n\nTable 6 :\n6Manual evaluation of detoxification models. \nNumbers in bold indicate the best results (with the sta-\ntistical significance \u03b1 = 0.01). \n\nManual Evaluation Manual evaluation (Ta-\nble 6) confirms the usefulness of parallel data. \nBARTs trained on parallel data outperform other \ncompetitors, even if the size of this data is small. \nHowever, manual and automatic evaluations do not \nalways match. Here, the well-performing Delete \nmodel gets the lowest score. \nOverall, assessors agree with automatic metrics \n\n\n\nTable 7\n7shows the examples of manually detoxified parallel sentences from the ParaDetox corpus. Original my computer is broken and my phone too!! wtf is this devil sh*t??? Paraphrases My computer is broken and my phone too! So disappointed! My computer is broken and my phone too, what is this? Both my computer and phone are broken.Original sh*t is crazy around here.Original massive and sustained public pressure is the only way to get these b*stards to act.ParaphrasesMassive and sustained public pressure is the only way to get them to act. massive and sustained preasure is the only way to get these people to actOriginal f*ck you taking credit for some sh*t i wanted to do Paraphrases You are taking credit for something I wanted to do You're taking credit fro something i wanted to do.Original you gotta admit that was f*ckin hilarious though! Paraphrases you got to admit that was very hilarious though! you gotta admit that was hilarious though! Original as an american who thought it was a d*ck joke , thanks.Paraphrases as an american who thought it was a joke, thanks As an American who thought it was a bad joke, thanksOriginal for whatever reason , your comment just blew my f*cking mind.ParaphrasesFor whatever reason, your comment just blew my mind.for whatever reason, your comment just amazes me.Original what exactly is your f*cking problem here?Paraphrases What exactly is your problem here?Original who the f*ck are you gona call when that happens.ParaphrasesWho are you gonna call when that happens?Original some idiots no longer believe in national sovereignty.Paraphrases \nIt is crazy around here. \nStuff is crazy around here. \nSomething is crazy around here. \n\nOriginal \ndelete the page and shut up \n\nParaphrases \nDelete the page and stay silent. \nplease delete the page \ndelete the page \n\n\n\nTable 7 :\n7Examples of detoxified sentences from the collected parallel corpus.\n\nTable 8 :\n8Examples of detoxifications by different models. Bad answers are shown in red, the best answers in bold.\n\nTable 9 :\n9Examples of sentences which could not be detoxified for different reasons.\nOur datasets and code of experiments is available online: https://github.com/skoltech-nlp/paradetox\nhttps://toloka.yandex.com\nhttps://huggingface.co/roberta-large\nWe use the tokenizer of the BERT base uncased model (https://huggingface.co/bert-base-uncased)\nData AnalysisWe collected ParaDetox -a parallel detoxification dataset with 1-3 paraphrases for over 12,000 toxic sentences. We also manually filtered ParaNMT dataset and get 1,400 toxic-neutral pairs.\n\nFinding microaggressions in the wild: A case for locating elusive phenomena in social media posts. Luke Breitfeller, Emily Ahn, David Jurgens, Yulia Tsvetkov, 10.18653/v1/D19-1176Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsLuke Breitfeller, Emily Ahn, David Jurgens, and Yu- lia Tsvetkov. 2019. Finding microaggressions in the wild: A case for locating elusive phenomena in so- cial media posts. In Proceedings of the 2019 Con- ference on Empirical Methods in Natural Language Processing and the 9th International Joint Confer- ence on Natural Language Processing (EMNLP- IJCNLP), pages 1664-1674, Hong Kong, China. As- sociation for Computational Linguistics.\n\nOl\u00e1, bonjour, salve! XFORMAL: A benchmark for multilingual formality style transfer. Eleftheria Briakou, Di Lu, Ke Zhang, Joel Tetreault, 10.18653/v1/2021.naacl-main.256Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational LinguisticsEleftheria Briakou, Di Lu, Ke Zhang, and Joel Tetreault. 2021. Ol\u00e1, bonjour, salve! XFORMAL: A benchmark for multilingual formality style transfer. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 3199-3216, Online. Association for Compu- tational Linguistics.\n\nEvaluating prose style transfer with the bible. Keith Carlson, Allen Riddell, Daniel Rockmore, Royal Society Open Science. 5Keith Carlson, Allen Riddell, and Daniel Rockmore. 2018. Evaluating prose style transfer with the bible. Royal Society Open Science, 5.\n\nText detoxification using large pre-trained neural models. David Dale, Anton Voronov, Daryna Dementieva, Varvara Logacheva, Olga Kozlova, Nikita Semenov, Alexander Panchenko, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingOnline and Punta Cana, Dominican Republic. Association for Computational LinguisticsDavid Dale, Anton Voronov, Daryna Dementieva, Var- vara Logacheva, Olga Kozlova, Nikita Semenov, and Alexander Panchenko. 2021. Text detoxification us- ing large pre-trained neural models. In Proceed- ings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 7979-7996, Online and Punta Cana, Dominican Republic. Asso- ciation for Computational Linguistics.\n\nMaximum likelihood estimation of observer error-rates using the em algorithm. Alexander P Dawid, Allan Skene, Journal of The Royal Statistical Society Series C-applied Statistics. 28Alexander P. Dawid and Allan Skene. 1979. Maximum likelihood estimation of observer error-rates using the em algorithm. Journal of The Royal Statistical Society Series C-applied Statistics, 28:20-28.\n\nAPE at scale and its implications on MT evaluation biases. Markus Freitag, Isaac Caswell, Scott Roy, 10.18653/v1/W19-5204Proceedings of the Fourth Conference on Machine Translation. the Fourth Conference on Machine TranslationFlorence, Italy1Association for Computational LinguisticsMarkus Freitag, Isaac Caswell, and Scott Roy. 2019. APE at scale and its implications on MT evaluation biases. In Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers), pages 34-44, Florence, Italy. Association for Com- putational Linguistics.\n\nStyle transfer in text: Exploration and evaluation. Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, Rui Yan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence32Zhenxin Fu, Xiaoye Tan, Nanyun Peng, Dongyan Zhao, and Rui Yan. 2018. Style transfer in text: Explo- ration and evaluation. Proceedings of the AAAI Con- ference on Artificial Intelligence, 32(1).\n\nA probabilistic formulation of unsupervised text style transfer. Junxian He, Xinyi Wang, Graham Neubig, Taylor Berg-Kirkpatrick, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020OpenReview.netJunxian He, Xinyi Wang, Graham Neubig, and Tay- lor Berg-Kirkpatrick. 2020. A probabilistic formu- lation of unsupervised text style transfer. In 8th International Conference on Learning Representa- tions, ICLR 2020, Addis Ababa, Ethiopia, April 26- 30, 2020. OpenReview.net.\n\nToxic comment classification challenge. Jigsaw, Jigsaw. 2018. Toxic comment classification challenge. https://www.kaggle.com/c/jigsaw-toxic-comment- classification-challenge. Accessed: 2021-03-01.\n\nJigsaw unintended bias in toxicity classification. Jigsaw, Jigsaw. 2019. Jigsaw unintended bias in toxicity classification. https://www.kaggle.com/c/jigsaw- unintended-bias-in-toxicity-classification. Ac- cessed: 2021-03-01.\n\nJigsaw multilingual toxic comment classification. Jigsaw, Jigsaw. 2020. Jigsaw multilingual toxic comment classification. https://www.kaggle.com/c/jigsaw- multilingual-toxic-comment-classification. Ac- cessed: 2021-03-01.\n\nTranslationese and its dialects. Moshe Koppel, Noam Ordan, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesPortland, Oregon, USAAssociation for Computational LinguisticsMoshe Koppel and Noam Ordan. 2011. Translationese and its dialects. In Proceedings of the 49th An- nual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1318-1326, Portland, Oregon, USA. Association for Computational Linguistics.\n\nCivil rephrases of toxic texts with self-supervised transformers. L\u00e9o Laugier, John Pavlopoulos, Jeffrey Sorensen, Lucas Dixon, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeOnline. Association for Computational LinguisticsL\u00e9o Laugier, John Pavlopoulos, Jeffrey Sorensen, and Lucas Dixon. 2021. Civil rephrases of toxic texts with self-supervised transformers. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 1442-1461, Online. Association for Computational Linguistics.\n\nStable style transformer: Delete and generate approach with encoder-decoder for text style transfer. Joosung Lee, Proceedings of the 13th International Conference on Natural Language Generation. the 13th International Conference on Natural Language GenerationDublin, IrelandAssociation for Computational LinguisticsJoosung Lee. 2020. Stable style transformer: Delete and generate approach with encoder-decoder for text style transfer. In Proceedings of the 13th Inter- national Conference on Natural Language Genera- tion, pages 195-204, Dublin, Ireland. Association for Computational Linguistics.\n\nLanguage models for machine translation: Original vs. translated texts. Gennadi Lembersky, Noam Ordan, Shuly Wintner, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. the 2011 Conference on Empirical Methods in Natural Language ProcessingEdinburgh, Scotland, UKAssociation for Computational LinguisticsGennadi Lembersky, Noam Ordan, and Shuly Wint- ner. 2011. Language models for machine transla- tion: Original vs. translated texts. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 363-374, Edin- burgh, Scotland, UK. Association for Computational Linguistics.\n\nBART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension. Mike Lewis, Yinhan Liu, Naman Goyal ; Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, 10.18653/v1/2020.acl-main.703Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational LinguisticsMike Lewis, Yinhan Liu, Naman Goyal, Mar- jan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising sequence-to-sequence pre- training for natural language generation, translation, and comprehension. In Proceedings of the 58th An- nual Meeting of the Association for Computational Linguistics, pages 7871-7880, Online. Association for Computational Linguistics.\n\nDelete, retrieve, generate: a simple approach to sentiment and style transfer. Juncen Li, Robin Jia, He He, Percy Liang, 10.18653/v1/N18-1169Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaLong Papers1Association for Computational LinguisticsJuncen Li, Robin Jia, He He, and Percy Liang. 2018. Delete, retrieve, generate: a simple approach to sen- timent and style transfer. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1865-1874, New Orleans, Louisiana. Associ- ation for Computational Linguistics.\n\nRoberta: A robustly optimized BERT pretraining approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, abs/1907.11692CoRRYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized BERT pretraining ap- proach. CoRR, abs/1907.11692.\n\nA dual reinforcement learning framework for unsupervised text style transfer. Fuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao Chang, Xu Sun, Zhifang Sui, 10.24963/ijcai.2019/711Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019. the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019Macao, Chinaijcai.orgFuli Luo, Peng Li, Jie Zhou, Pengcheng Yang, Baobao Chang, Xu Sun, and Zhifang Sui. 2019. A dual rein- forcement learning framework for unsupervised text style transfer. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelli- gence, IJCAI 2019, Macao, China, August 10-16, 2019, pages 5116-5122. ijcai.org.\n\nUnsupervised text style transfer with padded masked language models. Eric Malmi, Aliaksei Severyn, Sascha Rothe, 10.18653/v1/2020.emnlp-main.699Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational LinguisticsEric Malmi, Aliaksei Severyn, and Sascha Rothe. 2020. Unsupervised text style transfer with padded masked language models. In Proceedings of the 2020 Con- ference on Empirical Methods in Natural Language Processing (EMNLP), pages 8671-8680, Online. As- sociation for Computational Linguistics.\n\nFighting offensive language on social media with unsupervised text style transfer. Cicero Nogueira Dos Santos, Igor Melnyk, Inkit Padhi, 10.18653/v1/P18-2031Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaShort Papers2Association for Computational LinguisticsCicero Nogueira dos Santos, Igor Melnyk, and Inkit Padhi. 2018. Fighting offensive language on social media with unsupervised text style transfer. In Pro- ceedings of the 56th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 2: Short Papers), pages 189-194, Melbourne, Australia. As- sociation for Computational Linguistics.\n\nDon't patronize me! an annotated dataset with patronizing and condescending language towards vulnerable communities. Carla Perez Almendros, Luis Espinosa Anke, Steven Schockaert, 10.18653/v1/2020.coling-main.518Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational LinguisticsBarcelona, SpainInternational Committee on Computational LinguisticsCarla Perez Almendros, Luis Espinosa Anke, and Steven Schockaert. 2020. Don't patronize me! an annotated dataset with patronizing and condescend- ing language towards vulnerable communities. In Proceedings of the 28th International Conference on Computational Linguistics, pages 5891-5902, Barcelona, Spain (Online). International Committee on Computational Linguistics.\n\nAutomatically neutralizing subjective bias in text. Reid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi, Dan Jurafsky, Diyi Yang, Proceedings of the aaai conference on artificial intelligence. the aaai conference on artificial intelligence34Reid Pryzant, Richard Diehl Martinez, Nathan Dass, Sadao Kurohashi, Dan Jurafsky, and Diyi Yang. 2020. Automatically neutralizing subjective bias in text. In Proceedings of the aaai conference on artifi- cial intelligence, volume 34, pages 480-489.\n\nDear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer. Sudha Rao, Joel Tetreault, 10.18653/v1/N18-1012Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaLong Papers1Association for Computational LinguisticsSudha Rao and Joel Tetreault. 2018. Dear sir or madam, may I introduce the GYAFC dataset: Cor- pus, benchmarks and metrics for formality style transfer. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies, Volume 1 (Long Papers), pages 129-140, New Orleans, Louisiana. Association for Computa- tional Linguistics.\n\nNeural machine translation of rare words with subword units. Rico Sennrich, Barry Haddow, Alexandra Birch, 10.18653/v1/P16-1162Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyLong Papers1Association for Computational LinguisticsRico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Neural machine translation of rare words with subword units. In Proceedings of the 54th An- nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715- 1725, Berlin, Germany. Association for Computa- tional Linguistics.\n\nStyle transfer from non-parallel text by cross-alignment. Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Advances in Neural Information Processing Systems. Curran Associates, Inc30Tianxiao Shen, Tao Lei, Regina Barzilay, and Tommi Jaakkola. 2017. Style transfer from non-parallel text by cross-alignment. In Advances in Neural Informa- tion Processing Systems, volume 30. Curran Asso- ciates, Inc.\n\nTowards a friendly online community: An unsupervised style transfer framework for profanity redaction. Minh Tran, Yipeng Zhang, Mohammad Soleymani, 10.18653/v1/2020.coling-main.190Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational LinguisticsBarcelona, Spain (OnlineInternational Committee on Computational LinguisticsMinh Tran, Yipeng Zhang, and Mohammad Soleymani. 2020. Towards a friendly online community: An unsupervised style transfer framework for profan- ity redaction. In Proceedings of the 28th Inter- national Conference on Computational Linguistics, pages 2107-2114, Barcelona, Spain (Online). Inter- national Committee on Computational Linguistics.\n\nNeural network acceptability judgments. Alex Warstadt, Amanpreet Singh, Samuel R , 10.1162/tacl_a_00290Transactions of the Association for Computational Linguistics. 7BowmanAlex Warstadt, Amanpreet Singh, and Samuel R. Bow- man. 2019. Neural network acceptability judgments. Transactions of the Association for Computational Linguistics, 7:625-641.\n\nTowards universal paraphrastic sentence embeddings. John Wieting, Mohit Bansal, Kevin Gimpel, Karen Livescu, 4th International Conference on Learning Representations. San Juan, Puerto RicoConference Track ProceedingsJohn Wieting, Mohit Bansal, Kevin Gimpel, and Karen Livescu. 2016. Towards universal paraphrastic sen- tence embeddings. In 4th International Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Pro- ceedings.\n\nBeyond BLEU:training neural machine translation with semantic similarity. John Wieting, Taylor Berg-Kirkpatrick, Kevin Gimpel, Graham Neubig, 10.18653/v1/P19-1427Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational LinguisticsJohn Wieting, Taylor Berg-Kirkpatrick, Kevin Gimpel, and Graham Neubig. 2019. Beyond BLEU:training neural machine translation with semantic similarity. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4344-4355, Florence, Italy. Association for Compu- tational Linguistics.\n\nParaNMT-50M: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations. John Wieting, Kevin Gimpel, 10.18653/v1/P18-1042Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics1Long Papers)John Wieting and Kevin Gimpel. 2018. ParaNMT- 50M: Pushing the limits of paraphrastic sentence em- beddings with millions of machine translations. In Proceedings of the 56th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 451-462, Melbourne, Australia. Association for Computational Linguistics.\n\nMask and infill: Applying masked language model for sentiment transfer. Xing Wu, Tao Zhang, Liangjun Zang, Jizhong Han, Songlin Hu, 10.24963/ijcai.2019/732Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19). the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)Xing Wu, Tao Zhang, Liangjun Zang, Jizhong Han, and Songlin Hu. 2019. Mask and infill: Apply- ing masked language model for sentiment transfer. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI- 19), pages 5271-5277.\n\nSemEval-2019 task 6: Identifying and categorizing offensive language in social media (OffensEval). Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, Ritesh Kumar, 10.18653/v1/S19-2010Proceedings of the 13th International Workshop on Semantic Evaluation. the 13th International Workshop on Semantic EvaluationMinnesota, USAMinneapolis. Association for Computational LinguisticsMarcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura Farra, and Ritesh Kumar. 2019. SemEval-2019 task 6: Identifying and catego- rizing offensive language in social media (OffensE- val). In Proceedings of the 13th International Work- shop on Semantic Evaluation, pages 75-86, Min- neapolis, Minnesota, USA. Association for Compu- tational Linguistics.\n\nParallel data augmentation for formality style transfer. Yi Zhang, Tao Ge, Xu Sun, 10.18653/v1/2020.acl-main.294Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsYi Zhang, Tao Ge, and Xu Sun. 2020. Parallel data augmentation for formality style transfer. In Pro- ceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 3221- 3228, Online. Association for Computational Lin- guistics.\n", "annotations": {"author": "[{\"end\":190,\"start\":95},{\"end\":351,\"start\":191},{\"end\":448,\"start\":352},{\"end\":550,\"start\":449},{\"end\":634,\"start\":551},{\"end\":699,\"start\":635},{\"end\":770,\"start\":700},{\"end\":868,\"start\":771}]", "publisher": "[{\"end\":57,\"start\":46},{\"end\":1086,\"start\":1075}]", "author_last_name": "[{\"end\":112,\"start\":103},{\"end\":208,\"start\":198},{\"end\":369,\"start\":359},{\"end\":466,\"start\":456},{\"end\":561,\"start\":557},{\"end\":648,\"start\":641},{\"end\":714,\"start\":707},{\"end\":790,\"start\":781}]", "author_first_name": "[{\"end\":102,\"start\":95},{\"end\":197,\"start\":191},{\"end\":358,\"start\":352},{\"end\":455,\"start\":449},{\"end\":556,\"start\":551},{\"end\":640,\"start\":635},{\"end\":706,\"start\":700},{\"end\":780,\"start\":771}]", "author_affiliation": "[{\"end\":189,\"start\":138},{\"end\":291,\"start\":240},{\"end\":350,\"start\":293},{\"end\":447,\"start\":396},{\"end\":549,\"start\":498},{\"end\":633,\"start\":582},{\"end\":698,\"start\":667},{\"end\":769,\"start\":738},{\"end\":867,\"start\":816}]", "title": "[{\"end\":45,\"start\":1},{\"end\":913,\"start\":869}]", "venue": "[{\"end\":1002,\"start\":915}]", "abstract": "[{\"end\":2138,\"start\":1103}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2199,\"start\":2176},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2279,\"start\":2253},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2332,\"start\":2302},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2737,\"start\":2717},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2755,\"start\":2737},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3260,\"start\":3238},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3281,\"start\":3260},{\"end\":3465,\"start\":3459},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4438,\"start\":4412},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5584,\"start\":5567},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6016,\"start\":5994},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6141,\"start\":6119},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6337,\"start\":6312},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6895,\"start\":6878},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6911,\"start\":6895},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6930,\"start\":6911},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7099,\"start\":7080},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7115,\"start\":7099},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7304,\"start\":7286},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7355,\"start\":7338},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7416,\"start\":7405},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7651,\"start\":7630},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7689,\"start\":7676},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7704,\"start\":7689},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7719,\"start\":7704},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8044,\"start\":8024},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8070,\"start\":8052},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8091,\"start\":8075},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8205,\"start\":8184},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8287,\"start\":8269},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8360,\"start\":8344},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8450,\"start\":8432},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8837,\"start\":8815},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8968,\"start\":8948},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9383,\"start\":9359},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12689,\"start\":12663},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13735,\"start\":13717},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13795,\"start\":13782},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13810,\"start\":13795},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13825,\"start\":13810},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13942,\"start\":13928},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14385,\"start\":14363},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":15555,\"start\":15532},{\"end\":15558,\"start\":15557},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":17373,\"start\":17350},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19361,\"start\":19347},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19432,\"start\":19412},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":24075,\"start\":24056},{\"end\":24141,\"start\":24140},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":25478,\"start\":25457},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":30484,\"start\":30460},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":30520,\"start\":30496},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30923,\"start\":30901},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":31640,\"start\":31621}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":35630,\"start\":35572},{\"attributes\":{\"id\":\"fig_1\"},\"end\":35694,\"start\":35631},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35740,\"start\":35695},{\"attributes\":{\"id\":\"fig_4\"},\"end\":35776,\"start\":35741},{\"attributes\":{\"id\":\"fig_5\"},\"end\":36570,\"start\":35777},{\"attributes\":{\"id\":\"fig_6\"},\"end\":36658,\"start\":36571},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":36739,\"start\":36659},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":37025,\"start\":36740},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":37901,\"start\":37026},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":38167,\"start\":37902},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":38321,\"start\":38168},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":38460,\"start\":38322},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":38573,\"start\":38461},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":39217,\"start\":38574},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":39739,\"start\":39218},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":41557,\"start\":39740},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":41638,\"start\":41558},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":41755,\"start\":41639},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":41842,\"start\":41756}]", "paragraph": "[{\"end\":2603,\"start\":2154},{\"end\":3505,\"start\":2605},{\"end\":3605,\"start\":3507},{\"end\":3650,\"start\":3607},{\"end\":3763,\"start\":3652},{\"end\":4715,\"start\":3765},{\"end\":4994,\"start\":4717},{\"end\":5041,\"start\":4996},{\"end\":5393,\"start\":5043},{\"end\":6180,\"start\":5410},{\"end\":6669,\"start\":6182},{\"end\":7417,\"start\":6707},{\"end\":7924,\"start\":7419},{\"end\":8718,\"start\":7926},{\"end\":8981,\"start\":8720},{\"end\":9514,\"start\":9010},{\"end\":9757,\"start\":9538},{\"end\":10156,\"start\":9759},{\"end\":10282,\"start\":10158},{\"end\":10743,\"start\":10284},{\"end\":11087,\"start\":10745},{\"end\":11271,\"start\":11089},{\"end\":11462,\"start\":11273},{\"end\":11775,\"start\":11476},{\"end\":12120,\"start\":11777},{\"end\":12169,\"start\":12122},{\"end\":12205,\"start\":12177},{\"end\":12265,\"start\":12207},{\"end\":13292,\"start\":12288},{\"end\":13585,\"start\":13294},{\"end\":14548,\"start\":13612},{\"end\":15865,\"start\":14550},{\"end\":16187,\"start\":15867},{\"end\":16680,\"start\":16189},{\"end\":17066,\"start\":16682},{\"end\":17597,\"start\":17068},{\"end\":17803,\"start\":17599},{\"end\":18181,\"start\":17832},{\"end\":18733,\"start\":18183},{\"end\":19229,\"start\":18735},{\"end\":20039,\"start\":19266},{\"end\":20790,\"start\":20041},{\"end\":21917,\"start\":20812},{\"end\":22444,\"start\":21919},{\"end\":23063,\"start\":22478},{\"end\":23407,\"start\":23065},{\"end\":23990,\"start\":23422},{\"end\":24240,\"start\":24001},{\"end\":24652,\"start\":24242},{\"end\":24826,\"start\":24654},{\"end\":24890,\"start\":24828},{\"end\":24965,\"start\":24892},{\"end\":25151,\"start\":24977},{\"end\":25828,\"start\":25153},{\"end\":26276,\"start\":25830},{\"end\":27090,\"start\":26278},{\"end\":27513,\"start\":27125},{\"end\":28211,\"start\":27515},{\"end\":28676,\"start\":28227},{\"end\":29018,\"start\":28678},{\"end\":29353,\"start\":29020},{\"end\":29588,\"start\":29355},{\"end\":29674,\"start\":29609},{\"end\":30925,\"start\":29701},{\"end\":31702,\"start\":30927},{\"end\":31836,\"start\":31770},{\"end\":31980,\"start\":31838},{\"end\":32126,\"start\":31982},{\"end\":32269,\"start\":32128},{\"end\":32354,\"start\":32271},{\"end\":32388,\"start\":32356},{\"end\":32464,\"start\":32390},{\"end\":32484,\"start\":32466},{\"end\":32528,\"start\":32503},{\"end\":32579,\"start\":32530},{\"end\":32684,\"start\":32581},{\"end\":32767,\"start\":32686},{\"end\":32915,\"start\":32769},{\"end\":32954,\"start\":32917},{\"end\":33001,\"start\":32973},{\"end\":33058,\"start\":33003},{\"end\":33185,\"start\":33060},{\"end\":33225,\"start\":33187},{\"end\":33282,\"start\":33244},{\"end\":33327,\"start\":33284},{\"end\":33423,\"start\":33329},{\"end\":33457,\"start\":33425},{\"end\":33515,\"start\":33476},{\"end\":33749,\"start\":33524},{\"end\":34344,\"start\":33769},{\"end\":34874,\"start\":34362},{\"end\":35571,\"start\":34890}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":5231,\"start\":5224},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":20038,\"start\":20031},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":23405,\"start\":23398},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":26513,\"start\":26506},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":27729,\"start\":27720},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":31452,\"start\":31445},{\"attributes\":{\"ref_id\":\"tab_15\"},\"end\":33558,\"start\":33551}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2152,\"start\":2140},{\"attributes\":{\"n\":\"2\"},\"end\":5408,\"start\":5396},{\"end\":6705,\"start\":6672},{\"attributes\":{\"n\":\"3\"},\"end\":9008,\"start\":8984},{\"attributes\":{\"n\":\"3.1\"},\"end\":9536,\"start\":9517},{\"attributes\":{\"n\":\"3.2\"},\"end\":11474,\"start\":11465},{\"end\":12175,\"start\":12172},{\"end\":12286,\"start\":12268},{\"attributes\":{\"n\":\"3.3\"},\"end\":13610,\"start\":13588},{\"attributes\":{\"n\":\"3.4\"},\"end\":17830,\"start\":17806},{\"attributes\":{\"n\":\"4.1\"},\"end\":19264,\"start\":19232},{\"attributes\":{\"n\":\"4.2\"},\"end\":20810,\"start\":20793},{\"attributes\":{\"n\":\"4.3\"},\"end\":22476,\"start\":22447},{\"attributes\":{\"n\":\"5\"},\"end\":23420,\"start\":23410},{\"attributes\":{\"n\":\"5.1\"},\"end\":23999,\"start\":23993},{\"attributes\":{\"n\":\"5.2\"},\"end\":24975,\"start\":24968},{\"attributes\":{\"n\":\"5.3\"},\"end\":27100,\"start\":27093},{\"end\":27123,\"start\":27103},{\"attributes\":{\"n\":\"6\"},\"end\":28225,\"start\":28214},{\"end\":29607,\"start\":29591},{\"end\":29699,\"start\":29677},{\"end\":31724,\"start\":31705},{\"end\":31731,\"start\":31727},{\"end\":31768,\"start\":31734},{\"end\":32501,\"start\":32487},{\"end\":32971,\"start\":32957},{\"end\":33242,\"start\":33228},{\"end\":33474,\"start\":33460},{\"end\":33522,\"start\":33518},{\"end\":33767,\"start\":33752},{\"end\":34360,\"start\":34347},{\"end\":34888,\"start\":34877},{\"end\":35583,\"start\":35573},{\"end\":35642,\"start\":35632},{\"end\":35706,\"start\":35696},{\"end\":35752,\"start\":35742},{\"end\":35779,\"start\":35778},{\"end\":36582,\"start\":36572},{\"end\":36669,\"start\":36660},{\"end\":37035,\"start\":37027},{\"end\":37912,\"start\":37903},{\"end\":38178,\"start\":38169},{\"end\":38332,\"start\":38323},{\"end\":38471,\"start\":38462},{\"end\":38582,\"start\":38575},{\"end\":39228,\"start\":39219},{\"end\":39748,\"start\":39741},{\"end\":41568,\"start\":41559},{\"end\":41649,\"start\":41640},{\"end\":41766,\"start\":41757}]", "table": "[{\"end\":37025,\"start\":36864},{\"end\":37901,\"start\":37225},{\"end\":38167,\"start\":37977},{\"end\":39217,\"start\":39004},{\"end\":39739,\"start\":39230},{\"end\":41557,\"start\":41326}]", "figure_caption": "[{\"end\":35630,\"start\":35585},{\"end\":35694,\"start\":35644},{\"end\":35740,\"start\":35708},{\"end\":35776,\"start\":35754},{\"end\":36570,\"start\":35780},{\"end\":36658,\"start\":36584},{\"end\":36739,\"start\":36671},{\"end\":36864,\"start\":36742},{\"end\":37225,\"start\":37037},{\"end\":37977,\"start\":37914},{\"end\":38321,\"start\":38180},{\"end\":38460,\"start\":38334},{\"end\":38573,\"start\":38473},{\"end\":39004,\"start\":38584},{\"end\":41326,\"start\":39750},{\"end\":41638,\"start\":41570},{\"end\":41755,\"start\":41651},{\"end\":41842,\"start\":41768}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9936,\"start\":9928},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11086,\"start\":11078},{\"end\":11269,\"start\":11261},{\"end\":11759,\"start\":11751},{\"end\":12218,\"start\":12210},{\"end\":13135,\"start\":13127},{\"end\":15093,\"start\":15085},{\"end\":16406,\"start\":16398},{\"end\":17065,\"start\":17057},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20325,\"start\":20317},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20617,\"start\":20609},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27675,\"start\":27667}]", "bib_author_first_name": "[{\"end\":42407,\"start\":42403},{\"end\":42426,\"start\":42421},{\"end\":42437,\"start\":42432},{\"end\":42452,\"start\":42447},{\"end\":43411,\"start\":43401},{\"end\":43423,\"start\":43421},{\"end\":43430,\"start\":43428},{\"end\":43442,\"start\":43438},{\"end\":44226,\"start\":44221},{\"end\":44241,\"start\":44236},{\"end\":44257,\"start\":44251},{\"end\":44498,\"start\":44493},{\"end\":44510,\"start\":44505},{\"end\":44526,\"start\":44520},{\"end\":44546,\"start\":44539},{\"end\":44562,\"start\":44558},{\"end\":44578,\"start\":44572},{\"end\":44597,\"start\":44588},{\"end\":45327,\"start\":45318},{\"end\":45329,\"start\":45328},{\"end\":45342,\"start\":45337},{\"end\":45688,\"start\":45682},{\"end\":45703,\"start\":45698},{\"end\":45718,\"start\":45713},{\"end\":46244,\"start\":46237},{\"end\":46255,\"start\":46249},{\"end\":46267,\"start\":46261},{\"end\":46281,\"start\":46274},{\"end\":46291,\"start\":46288},{\"end\":46677,\"start\":46670},{\"end\":46687,\"start\":46682},{\"end\":46700,\"start\":46694},{\"end\":46715,\"start\":46709},{\"end\":47793,\"start\":47788},{\"end\":47806,\"start\":47802},{\"end\":48439,\"start\":48436},{\"end\":48453,\"start\":48449},{\"end\":48474,\"start\":48467},{\"end\":48490,\"start\":48485},{\"end\":49214,\"start\":49207},{\"end\":49784,\"start\":49777},{\"end\":49800,\"start\":49796},{\"end\":49813,\"start\":49808},{\"end\":50473,\"start\":50469},{\"end\":50487,\"start\":50481},{\"end\":50498,\"start\":50493},{\"end\":50532,\"start\":50528},{\"end\":50546,\"start\":50539},{\"end\":50561,\"start\":50557},{\"end\":51317,\"start\":51311},{\"end\":51327,\"start\":51322},{\"end\":51335,\"start\":51333},{\"end\":51345,\"start\":51340},{\"end\":52173,\"start\":52167},{\"end\":52183,\"start\":52179},{\"end\":52194,\"start\":52189},{\"end\":52209,\"start\":52202},{\"end\":52220,\"start\":52214},{\"end\":52233,\"start\":52228},{\"end\":52244,\"start\":52240},{\"end\":52255,\"start\":52251},{\"end\":52267,\"start\":52263},{\"end\":52288,\"start\":52281},{\"end\":52625,\"start\":52621},{\"end\":52635,\"start\":52631},{\"end\":52643,\"start\":52640},{\"end\":52659,\"start\":52650},{\"end\":52672,\"start\":52666},{\"end\":52682,\"start\":52680},{\"end\":52695,\"start\":52688},{\"end\":53351,\"start\":53347},{\"end\":53367,\"start\":53359},{\"end\":53383,\"start\":53377},{\"end\":54030,\"start\":54024},{\"end\":54056,\"start\":54052},{\"end\":54070,\"start\":54065},{\"end\":54806,\"start\":54801},{\"end\":54828,\"start\":54824},{\"end\":54850,\"start\":54844},{\"end\":55532,\"start\":55528},{\"end\":55549,\"start\":55542},{\"end\":55555,\"start\":55550},{\"end\":55572,\"start\":55566},{\"end\":55584,\"start\":55579},{\"end\":55599,\"start\":55596},{\"end\":55614,\"start\":55610},{\"end\":56102,\"start\":56097},{\"end\":56112,\"start\":56108},{\"end\":56966,\"start\":56962},{\"end\":56982,\"start\":56977},{\"end\":57000,\"start\":56991},{\"end\":57639,\"start\":57631},{\"end\":57649,\"start\":57646},{\"end\":57661,\"start\":57655},{\"end\":57677,\"start\":57672},{\"end\":58089,\"start\":58085},{\"end\":58102,\"start\":58096},{\"end\":58118,\"start\":58110},{\"end\":58768,\"start\":58764},{\"end\":58788,\"start\":58779},{\"end\":58802,\"start\":58796},{\"end\":58804,\"start\":58803},{\"end\":59130,\"start\":59126},{\"end\":59145,\"start\":59140},{\"end\":59159,\"start\":59154},{\"end\":59173,\"start\":59168},{\"end\":59632,\"start\":59628},{\"end\":59648,\"start\":59642},{\"end\":59672,\"start\":59667},{\"end\":59687,\"start\":59681},{\"end\":60368,\"start\":60364},{\"end\":60383,\"start\":60378},{\"end\":61069,\"start\":61065},{\"end\":61077,\"start\":61074},{\"end\":61093,\"start\":61085},{\"end\":61107,\"start\":61100},{\"end\":61120,\"start\":61113},{\"end\":61711,\"start\":61705},{\"end\":61729,\"start\":61722},{\"end\":61746,\"start\":61739},{\"end\":61758,\"start\":61754},{\"end\":61775,\"start\":61770},{\"end\":61789,\"start\":61783},{\"end\":62440,\"start\":62438},{\"end\":62451,\"start\":62448},{\"end\":62458,\"start\":62456}]", "bib_author_last_name": "[{\"end\":42419,\"start\":42408},{\"end\":42430,\"start\":42427},{\"end\":42445,\"start\":42438},{\"end\":42461,\"start\":42453},{\"end\":43419,\"start\":43412},{\"end\":43426,\"start\":43424},{\"end\":43436,\"start\":43431},{\"end\":43452,\"start\":43443},{\"end\":44234,\"start\":44227},{\"end\":44249,\"start\":44242},{\"end\":44266,\"start\":44258},{\"end\":44503,\"start\":44499},{\"end\":44518,\"start\":44511},{\"end\":44537,\"start\":44527},{\"end\":44556,\"start\":44547},{\"end\":44570,\"start\":44563},{\"end\":44586,\"start\":44579},{\"end\":44607,\"start\":44598},{\"end\":45335,\"start\":45330},{\"end\":45348,\"start\":45343},{\"end\":45696,\"start\":45689},{\"end\":45711,\"start\":45704},{\"end\":45722,\"start\":45719},{\"end\":46247,\"start\":46245},{\"end\":46259,\"start\":46256},{\"end\":46272,\"start\":46268},{\"end\":46286,\"start\":46282},{\"end\":46295,\"start\":46292},{\"end\":46680,\"start\":46678},{\"end\":46692,\"start\":46688},{\"end\":46707,\"start\":46701},{\"end\":46732,\"start\":46716},{\"end\":47154,\"start\":47148},{\"end\":47363,\"start\":47357},{\"end\":47588,\"start\":47582},{\"end\":47800,\"start\":47794},{\"end\":47812,\"start\":47807},{\"end\":48447,\"start\":48440},{\"end\":48465,\"start\":48454},{\"end\":48483,\"start\":48475},{\"end\":48496,\"start\":48491},{\"end\":49218,\"start\":49215},{\"end\":49794,\"start\":49785},{\"end\":49806,\"start\":49801},{\"end\":49821,\"start\":49814},{\"end\":50479,\"start\":50474},{\"end\":50491,\"start\":50488},{\"end\":50526,\"start\":50499},{\"end\":50537,\"start\":50533},{\"end\":50555,\"start\":50547},{\"end\":50573,\"start\":50562},{\"end\":51320,\"start\":51318},{\"end\":51331,\"start\":51328},{\"end\":51338,\"start\":51336},{\"end\":51351,\"start\":51346},{\"end\":52177,\"start\":52174},{\"end\":52187,\"start\":52184},{\"end\":52200,\"start\":52195},{\"end\":52212,\"start\":52210},{\"end\":52226,\"start\":52221},{\"end\":52238,\"start\":52234},{\"end\":52249,\"start\":52245},{\"end\":52261,\"start\":52256},{\"end\":52279,\"start\":52268},{\"end\":52297,\"start\":52289},{\"end\":52629,\"start\":52626},{\"end\":52638,\"start\":52636},{\"end\":52648,\"start\":52644},{\"end\":52664,\"start\":52660},{\"end\":52678,\"start\":52673},{\"end\":52686,\"start\":52683},{\"end\":52699,\"start\":52696},{\"end\":53357,\"start\":53352},{\"end\":53375,\"start\":53368},{\"end\":53389,\"start\":53384},{\"end\":54050,\"start\":54031},{\"end\":54063,\"start\":54057},{\"end\":54076,\"start\":54071},{\"end\":54822,\"start\":54807},{\"end\":54842,\"start\":54829},{\"end\":54861,\"start\":54851},{\"end\":55540,\"start\":55533},{\"end\":55564,\"start\":55556},{\"end\":55577,\"start\":55573},{\"end\":55594,\"start\":55585},{\"end\":55608,\"start\":55600},{\"end\":55619,\"start\":55615},{\"end\":56106,\"start\":56103},{\"end\":56122,\"start\":56113},{\"end\":56975,\"start\":56967},{\"end\":56989,\"start\":56983},{\"end\":57006,\"start\":57001},{\"end\":57644,\"start\":57640},{\"end\":57653,\"start\":57650},{\"end\":57670,\"start\":57662},{\"end\":57686,\"start\":57678},{\"end\":58094,\"start\":58090},{\"end\":58108,\"start\":58103},{\"end\":58128,\"start\":58119},{\"end\":58777,\"start\":58769},{\"end\":58794,\"start\":58789},{\"end\":59138,\"start\":59131},{\"end\":59152,\"start\":59146},{\"end\":59166,\"start\":59160},{\"end\":59181,\"start\":59174},{\"end\":59640,\"start\":59633},{\"end\":59665,\"start\":59649},{\"end\":59679,\"start\":59673},{\"end\":59694,\"start\":59688},{\"end\":60376,\"start\":60369},{\"end\":60390,\"start\":60384},{\"end\":61072,\"start\":61070},{\"end\":61083,\"start\":61078},{\"end\":61098,\"start\":61094},{\"end\":61111,\"start\":61108},{\"end\":61123,\"start\":61121},{\"end\":61720,\"start\":61712},{\"end\":61737,\"start\":61730},{\"end\":61752,\"start\":61747},{\"end\":61768,\"start\":61759},{\"end\":61781,\"start\":61776},{\"end\":61795,\"start\":61790},{\"end\":62446,\"start\":62441},{\"end\":62454,\"start\":62452},{\"end\":62462,\"start\":62459}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/D19-1176\",\"id\":\"b0\",\"matched_paper_id\":202778702},\"end\":43314,\"start\":42304},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.256\",\"id\":\"b1\",\"matched_paper_id\":233204508},\"end\":44171,\"start\":43316},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":21186239},\"end\":44432,\"start\":44173},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":237572304},\"end\":45238,\"start\":44434},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":45813168},\"end\":45621,\"start\":45240},{\"attributes\":{\"doi\":\"10.18653/v1/W19-5204\",\"id\":\"b5\",\"matched_paper_id\":189898467},\"end\":46183,\"start\":45623},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6484065},\"end\":46603,\"start\":46185},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":211069439},\"end\":47106,\"start\":46605},{\"attributes\":{\"id\":\"b8\"},\"end\":47304,\"start\":47108},{\"attributes\":{\"id\":\"b9\"},\"end\":47530,\"start\":47306},{\"attributes\":{\"id\":\"b10\"},\"end\":47753,\"start\":47532},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":9497990},\"end\":48368,\"start\":47755},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":231861515},\"end\":49104,\"start\":48370},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":218869632},\"end\":49703,\"start\":49106},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":11280500},\"end\":50353,\"start\":49705},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.703\",\"id\":\"b15\",\"matched_paper_id\":204960716},\"end\":51230,\"start\":50355},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1169\",\"id\":\"b16\",\"matched_paper_id\":4937880},\"end\":52108,\"start\":51232},{\"attributes\":{\"doi\":\"abs/1907.11692\",\"id\":\"b17\"},\"end\":52541,\"start\":52110},{\"attributes\":{\"doi\":\"10.24963/ijcai.2019/711\",\"id\":\"b18\",\"matched_paper_id\":165163728},\"end\":53276,\"start\":52543},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.699\",\"id\":\"b19\",\"matched_paper_id\":237250920},\"end\":53939,\"start\":53278},{\"attributes\":{\"doi\":\"10.18653/v1/P18-2031\",\"id\":\"b20\",\"matched_paper_id\":29165442},\"end\":54682,\"start\":53941},{\"attributes\":{\"doi\":\"10.18653/v1/2020.coling-main.518\",\"id\":\"b21\",\"matched_paper_id\":226976077},\"end\":55474,\"start\":54684},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":208248333},\"end\":55980,\"start\":55476},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1012\",\"id\":\"b23\",\"matched_paper_id\":4859003},\"end\":56899,\"start\":55982},{\"attributes\":{\"doi\":\"10.18653/v1/P16-1162\",\"id\":\"b24\",\"matched_paper_id\":1114678},\"end\":57571,\"start\":56901},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":7296803},\"end\":57980,\"start\":57573},{\"attributes\":{\"doi\":\"10.18653/v1/2020.coling-main.190\",\"id\":\"b26\",\"matched_paper_id\":226227404},\"end\":58722,\"start\":57982},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00290\",\"id\":\"b27\",\"matched_paper_id\":44072099},\"end\":59072,\"start\":58724},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":5882977},\"end\":59552,\"start\":59074},{\"attributes\":{\"doi\":\"10.18653/v1/P19-1427\",\"id\":\"b29\",\"matched_paper_id\":196213784},\"end\":60255,\"start\":59554},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1042\",\"id\":\"b30\",\"matched_paper_id\":5003931},\"end\":60991,\"start\":60257},{\"attributes\":{\"doi\":\"10.24963/ijcai.2019/732\",\"id\":\"b31\",\"matched_paper_id\":199465752},\"end\":61604,\"start\":60993},{\"attributes\":{\"doi\":\"10.18653/v1/S19-2010\",\"id\":\"b32\",\"matched_paper_id\":84843035},\"end\":62379,\"start\":61606},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.294\",\"id\":\"b33\",\"matched_paper_id\":218665411},\"end\":62913,\"start\":62381}]", "bib_title": "[{\"end\":42401,\"start\":42304},{\"end\":43399,\"start\":43316},{\"end\":44219,\"start\":44173},{\"end\":44491,\"start\":44434},{\"end\":45316,\"start\":45240},{\"end\":45680,\"start\":45623},{\"end\":46235,\"start\":46185},{\"end\":46668,\"start\":46605},{\"end\":47786,\"start\":47755},{\"end\":48434,\"start\":48370},{\"end\":49205,\"start\":49106},{\"end\":49775,\"start\":49705},{\"end\":50467,\"start\":50355},{\"end\":51309,\"start\":51232},{\"end\":52619,\"start\":52543},{\"end\":53345,\"start\":53278},{\"end\":54022,\"start\":53941},{\"end\":54799,\"start\":54684},{\"end\":55526,\"start\":55476},{\"end\":56095,\"start\":55982},{\"end\":56960,\"start\":56901},{\"end\":57629,\"start\":57573},{\"end\":58083,\"start\":57982},{\"end\":58762,\"start\":58724},{\"end\":59124,\"start\":59074},{\"end\":59626,\"start\":59554},{\"end\":60362,\"start\":60257},{\"end\":61063,\"start\":60993},{\"end\":61703,\"start\":61606},{\"end\":62436,\"start\":62381}]", "bib_author": "[{\"end\":42421,\"start\":42403},{\"end\":42432,\"start\":42421},{\"end\":42447,\"start\":42432},{\"end\":42463,\"start\":42447},{\"end\":43421,\"start\":43401},{\"end\":43428,\"start\":43421},{\"end\":43438,\"start\":43428},{\"end\":43454,\"start\":43438},{\"end\":44236,\"start\":44221},{\"end\":44251,\"start\":44236},{\"end\":44268,\"start\":44251},{\"end\":44505,\"start\":44493},{\"end\":44520,\"start\":44505},{\"end\":44539,\"start\":44520},{\"end\":44558,\"start\":44539},{\"end\":44572,\"start\":44558},{\"end\":44588,\"start\":44572},{\"end\":44609,\"start\":44588},{\"end\":45337,\"start\":45318},{\"end\":45350,\"start\":45337},{\"end\":45698,\"start\":45682},{\"end\":45713,\"start\":45698},{\"end\":45724,\"start\":45713},{\"end\":46249,\"start\":46237},{\"end\":46261,\"start\":46249},{\"end\":46274,\"start\":46261},{\"end\":46288,\"start\":46274},{\"end\":46297,\"start\":46288},{\"end\":46682,\"start\":46670},{\"end\":46694,\"start\":46682},{\"end\":46709,\"start\":46694},{\"end\":46734,\"start\":46709},{\"end\":47156,\"start\":47148},{\"end\":47365,\"start\":47357},{\"end\":47590,\"start\":47582},{\"end\":47802,\"start\":47788},{\"end\":47814,\"start\":47802},{\"end\":48449,\"start\":48436},{\"end\":48467,\"start\":48449},{\"end\":48485,\"start\":48467},{\"end\":48498,\"start\":48485},{\"end\":49220,\"start\":49207},{\"end\":49796,\"start\":49777},{\"end\":49808,\"start\":49796},{\"end\":49823,\"start\":49808},{\"end\":50481,\"start\":50469},{\"end\":50493,\"start\":50481},{\"end\":50528,\"start\":50493},{\"end\":50539,\"start\":50528},{\"end\":50557,\"start\":50539},{\"end\":50575,\"start\":50557},{\"end\":51322,\"start\":51311},{\"end\":51333,\"start\":51322},{\"end\":51340,\"start\":51333},{\"end\":51353,\"start\":51340},{\"end\":52179,\"start\":52167},{\"end\":52189,\"start\":52179},{\"end\":52202,\"start\":52189},{\"end\":52214,\"start\":52202},{\"end\":52228,\"start\":52214},{\"end\":52240,\"start\":52228},{\"end\":52251,\"start\":52240},{\"end\":52263,\"start\":52251},{\"end\":52281,\"start\":52263},{\"end\":52299,\"start\":52281},{\"end\":52631,\"start\":52621},{\"end\":52640,\"start\":52631},{\"end\":52650,\"start\":52640},{\"end\":52666,\"start\":52650},{\"end\":52680,\"start\":52666},{\"end\":52688,\"start\":52680},{\"end\":52701,\"start\":52688},{\"end\":53359,\"start\":53347},{\"end\":53377,\"start\":53359},{\"end\":53391,\"start\":53377},{\"end\":54052,\"start\":54024},{\"end\":54065,\"start\":54052},{\"end\":54078,\"start\":54065},{\"end\":54824,\"start\":54801},{\"end\":54844,\"start\":54824},{\"end\":54863,\"start\":54844},{\"end\":55542,\"start\":55528},{\"end\":55566,\"start\":55542},{\"end\":55579,\"start\":55566},{\"end\":55596,\"start\":55579},{\"end\":55610,\"start\":55596},{\"end\":55621,\"start\":55610},{\"end\":56108,\"start\":56097},{\"end\":56124,\"start\":56108},{\"end\":56977,\"start\":56962},{\"end\":56991,\"start\":56977},{\"end\":57008,\"start\":56991},{\"end\":57646,\"start\":57631},{\"end\":57655,\"start\":57646},{\"end\":57672,\"start\":57655},{\"end\":57688,\"start\":57672},{\"end\":58096,\"start\":58085},{\"end\":58110,\"start\":58096},{\"end\":58130,\"start\":58110},{\"end\":58779,\"start\":58764},{\"end\":58796,\"start\":58779},{\"end\":58807,\"start\":58796},{\"end\":59140,\"start\":59126},{\"end\":59154,\"start\":59140},{\"end\":59168,\"start\":59154},{\"end\":59183,\"start\":59168},{\"end\":59642,\"start\":59628},{\"end\":59667,\"start\":59642},{\"end\":59681,\"start\":59667},{\"end\":59696,\"start\":59681},{\"end\":60378,\"start\":60364},{\"end\":60392,\"start\":60378},{\"end\":61074,\"start\":61065},{\"end\":61085,\"start\":61074},{\"end\":61100,\"start\":61085},{\"end\":61113,\"start\":61100},{\"end\":61125,\"start\":61113},{\"end\":61722,\"start\":61705},{\"end\":61739,\"start\":61722},{\"end\":61754,\"start\":61739},{\"end\":61770,\"start\":61754},{\"end\":61783,\"start\":61770},{\"end\":61797,\"start\":61783},{\"end\":62448,\"start\":62438},{\"end\":62456,\"start\":62448},{\"end\":62464,\"start\":62456}]", "bib_venue": "[{\"end\":42658,\"start\":42483},{\"end\":43627,\"start\":43485},{\"end\":44294,\"start\":44268},{\"end\":44695,\"start\":44609},{\"end\":45418,\"start\":45350},{\"end\":45803,\"start\":45744},{\"end\":46358,\"start\":46297},{\"end\":46790,\"start\":46734},{\"end\":47146,\"start\":47108},{\"end\":47355,\"start\":47306},{\"end\":47580,\"start\":47532},{\"end\":47930,\"start\":47814},{\"end\":48618,\"start\":48498},{\"end\":49299,\"start\":49220},{\"end\":49909,\"start\":49823},{\"end\":50691,\"start\":50604},{\"end\":51515,\"start\":51373},{\"end\":52165,\"start\":52110},{\"end\":52826,\"start\":52724},{\"end\":53516,\"start\":53422},{\"end\":54185,\"start\":54098},{\"end\":54972,\"start\":54895},{\"end\":55682,\"start\":55621},{\"end\":56286,\"start\":56144},{\"end\":57115,\"start\":57028},{\"end\":57737,\"start\":57688},{\"end\":58239,\"start\":58162},{\"end\":58888,\"start\":58827},{\"end\":59239,\"start\":59183},{\"end\":59803,\"start\":59716},{\"end\":60499,\"start\":60412},{\"end\":61249,\"start\":61148},{\"end\":61886,\"start\":61817},{\"end\":62580,\"start\":62493},{\"end\":42836,\"start\":42660},{\"end\":43756,\"start\":43629},{\"end\":44768,\"start\":44697},{\"end\":45864,\"start\":45805},{\"end\":46406,\"start\":46360},{\"end\":46813,\"start\":46792},{\"end\":48054,\"start\":47932},{\"end\":48725,\"start\":48620},{\"end\":49380,\"start\":49301},{\"end\":50005,\"start\":49911},{\"end\":50765,\"start\":50693},{\"end\":51666,\"start\":51517},{\"end\":52927,\"start\":52828},{\"end\":53597,\"start\":53518},{\"end\":54279,\"start\":54187},{\"end\":55052,\"start\":54974},{\"end\":55730,\"start\":55684},{\"end\":56437,\"start\":56288},{\"end\":57204,\"start\":57117},{\"end\":58327,\"start\":58241},{\"end\":59262,\"start\":59241},{\"end\":59892,\"start\":59805},{\"end\":60593,\"start\":60501},{\"end\":61337,\"start\":61251},{\"end\":61956,\"start\":61888},{\"end\":62654,\"start\":62582}]"}}}, "year": 2023, "month": 12, "day": 17}