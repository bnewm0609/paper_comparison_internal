{"id": 208527458, "updated": "2023-10-06 21:02:40.4", "metadata": {"title": "Fastened CROWN: Tightened Neural Network Robustness Certificates", "authors": "[{\"first\":\"Zhaoyang\",\"last\":\"Lyu\",\"middle\":[]},{\"first\":\"Ching-Yun\",\"last\":\"Ko\",\"middle\":[]},{\"first\":\"Zhifeng\",\"last\":\"Kong\",\"middle\":[]},{\"first\":\"Ngai\",\"last\":\"Wong\",\"middle\":[]},{\"first\":\"Dahua\",\"last\":\"Lin\",\"middle\":[]},{\"first\":\"Luca\",\"last\":\"Daniel\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2019, "month": 12, "day": 2}, "abstract": "The rapid growth of deep learning applications in real life is accompanied by severe safety concerns. To mitigate this uneasy phenomenon, much research has been done providing reliable evaluations of the fragility level in different deep neural networks. Apart from devising adversarial attacks, quantifiers that certify safeguarded regions have also been designed in the past five years. The summarizing work of Salman et al. unifies a family of existing verifiers under a convex relaxation framework. We draw inspiration from such work and further demonstrate the optimality of deterministic CROWN (Zhang et al. 2018) solutions in a given linear programming problem under mild constraints. Given this theoretical result, the computationally expensive linear programming based method is shown to be unnecessary. We then propose an optimization-based approach \\textit{FROWN} (\\textbf{F}astened C\\textbf{ROWN}): a general algorithm to tighten robustness certificates for neural networks. Extensive experiments on various networks trained individually verify the effectiveness of FROWN in safeguarding larger robust regions.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1912.00574", "mag": "2991067485", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aaai/LyuKKWLD20", "doi": "10.1609/aaai.v34i04.5944"}}, "content": {"source": {"pdf_hash": "a948ff0c0eba359e141f5dcee1f8f8cfccc7f7a7", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1912.00574v1.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://ojs.aaai.org/index.php/AAAI/article/download/5944/5800", "status": "GOLD"}}, "grobid": {"id": "22fda72b49c3ae12cb528dc8b262f2fa7479488b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a948ff0c0eba359e141f5dcee1f8f8cfccc7f7a7.txt", "contents": "\nFastened CROWN: Tightened Neural Network Robustness Certificates\n\n\nZhaoyang Lyu lyuzhaoyang@link.cuhk.edu.hk \nThe Chinese University of Hong Kong\nHong KongChina\n\nChing-Yun Ko cyko@mit.edu \nMassachusetts Institute of Technology\n02139CambridgeMAUSA\n\nZhifeng Kong z4kong@eng.ucsd.edu \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nNgai Wong nwong@eee.hku.hk \nThe University of Hong Kong\nHong KongChina\n\nDahua Lin dhlin@ie.cuhk.edu.hk \nThe Chinese University of Hong Kong\nHong KongChina\n\nLuca Daniel \nMassachusetts Institute of Technology\n02139CambridgeMAUSA\n\nFastened CROWN: Tightened Neural Network Robustness Certificates\n\nThe rapid growth of deep learning applications in real life is accompanied by severe safety concerns. To mitigate this uneasy phenomenon, much research has been done providing reliable evaluations of the fragility level in different deep neural networks. Apart from devising adversarial attacks, quantifiers that certify safeguarded regions have also been designed in the past five years. The summarizing work of Salman et al. unifies a family of existing verifiers under a convex relaxation framework. We draw inspiration from such work and further demonstrate the optimality of deterministic CROWN (Zhang et al. 2018) solutions in a given linear programming problem under mild constraints. Given this theoretical result, the computationally expensive linear programming based method is shown to be unnecessary. We then propose an optimizationbased approach FROWN (Fastened CROWN): a general algorithm to tighten robustness certificates for neural networks. Extensive experiments on various networks trained individually verify the effectiveness of FROWN in safeguarding larger robust regions. * Equal contribution. Source code and the appendix are available at https://github.com/ZhaoyangLyu/FROWN.\n\nIntroduction\n\nThe vulnerability of deep neural networks remains an unrevealed snare in the beginning years of the deep learning resurgence. In 2014, Szegedy et al. uncovered the discovery of hardly-perceptible adversarial perturbations that could fool image classifiers. This discovery agonized the fast development of accuracy-oriented deep learning and shifted community's attentions to the fragility of trained models. Especially with the increasing adoption of machine learning and artificial intelligence in safety-critical applications, the vulnerability of machine learning models to adversarial attacks has become a vital issue (Sharif et al. 2016;Kurakin, Goodfellow, and Bengio 2017;Carlini and Wagner 2017;Wong and Kolter 2018). Addressing this urging issue requires reliable ways to evaluate the robustness of a neural network, namely by studying the safety region around a data point where no adversarial example exists. This understanding of machine learning models' vulnerability will, on the other hand, help industries build more robust intelligent systems.\n\nDisparate ways of reasoning and quantifying vulnerability (or robustness) of neural networks have been exploited to approach this dilemma, among which attack-based methods have long been in a dominating position. In these years, a sequel of adversarial attack algorithms have been proposed to mislead networks' predictions in tasks such as object detection (Goodfellow, Shlens, and Szegedy 2015;Moosavi-Dezfooli, Fawzi, and Frossard 2016), visual question answering (Mudrakarta et al. 2018;Zeng et al. 2019;Gao et al. 2019b;Gao et al. 2019a), text classification (Papernot et al. 2016), speech recognition (Cisse et al. 2017;Gong and Poellabauer 2017), and audio systems (Carlini and Wagner 2018), where the level of model vulnerability is quantified by the distortion between successful adversaries and the original data points. Notably, the magnitudes of distortions suggested by attack-based methods are essentially upper bounds of the minimum adversarial distortion.\n\nIn contrast to attack-based approaches, attack-agnostic verification-based methods evaluate the level of network vulnerability by either directly estimating (Szegedy et al. 2014;Weng et al. 2018b) or lower bounding (Hein and Andriushchenko 2017;Raghunathan, Steinhardt, and Liang 2018;Dvijotham et al. 2018;Singh et al. 2018;) the minimum distortion networks can bear for a specific input sample. As an iconic robustness estimation, CLEVER (Weng et al. 2018a) converts the robustness evaluation task into the estimation of the local Lipschitz constant, which essentially associates with the maximum norm of the local gradients w.r.t. the original example. Extensions of CLEVER (Weng et al. 2018c) focuses on twice differentiable classifiers and works on first-order Taylor polynomial with Lagrange remainder.\n\nA number of verification-based methods have been proposed in literature to compute a lower bound of the safeguarded region around a given input, i.e. a region where the network is guaranteed to make consistent predictions despite any input perturbations. A pioneering work in providing certifiable robustness verification (Szegedy et al. 2014) computes the product of weight matrix operator norms in ReLU networks to give a lower-bounding metric of the \nF : R n \u2192 R t neural network classifier x 0 \u2208 R n original input x \u2208 R n perturbed input n\ninput size a (k) the hidden state of the k-th layer z (k) the pre-activation of the k-th layer n k number of neurons in layer k Certifiable robustness lower bounds are especially vital in safety-critical scenarios (e.g. autonomous driving car) since any miss-classification can be lethal. However, albeit being useful, new challenges with these certifiable quantifiers arise. There are, in most cases, non-negligible gaps between the certified lower and upper bounds of the minimum distortion. This inconsistency in the quantification questions diminishes the use of these state-of-the-art robustness evaluation approaches.\n[K] set {1, 2, \u00b7 \u00b7 \u00b7 , K} B p (x 0 , ) {x | x \u2212 x 0 p \u2264 } F L j (x) : R n \u2192 R linear lower bound of F j (x) \u03b3 (k)L j global lower bound of z (k) j l z u l r \u2264 z r \u2264 u r , F U j (x) : R n \u2192 R linear upper bound of F j (x) \u03b3 (k)U j global upper bound of z (k) j \u2200 r \u2208 [s], l, z, u \u2208 R s s [k\u22121]U set {s (1)U , . . . , s (k\u22121)U } t [k\u22121]U set {t (1)U , . . . , t (k\u22121)U } neg(x) = x, if x \u2264 0; s [k\u22121]L set {s (1)L , . . . , s (k\u22121)L } t [k\u22121]L set {t (1)L , . . . , t (k\u22121)L } 0, otherwise. a [k] set {a (1) , , a (2) , ..., a (k) } z [k] set {z (1) , , z (2) , ..., z (k) } \u03c3 ReLU/ Sigmoid/\nIn this article, we stay in line with the previous sequel of works that focus on linear bounds and provide two major contributions:\n\n1. We prove that if we limit the constraint relaxation to be exactly one linear bound in each direction (upper and lower) in the LP-based method, the results provided by CROWN are optimal. Therefore the costly LP solving process is unnecessary under this relaxation.\n\n2. We propose a general optimization framework that we name FROWN (Fastened CROWN) for tightening the certifiable regions guaranteed by CROWN, which is also Definitions. Given a trained m-layer perceptron F , we denote the hidden unit, weight matrix, bias, and pre-activation\nunit of the k-th layer (k \u2208 [m]) as a (k) , W (k) , b (k) , and z (k) , respectively. Hence, z (k) = W (k) a (k\u22121) + b (k) , a (k) = \u03c3(z (k) )\n, where a 0 = x 0 \u2208 R n is the original input and F (x) = z (m) is the network output. Denoting the number of neurons as n k for the k-th layer, implies that a (k) , z (k) , b (k) \u2208 R n k and W (k) \u2208 R n k \u00d7n k\u22121 , for k \u2208 [m]. Furthermore, we use square brackets in the superscripts to group a set of variables (e.g. a [m] denotes the set of variables {a (1) , , a (2) , ..., a (m) } and z [m] denotes the set of variables {z (1) , , z (2) , ..., z (m) }). Table 1 summarizes all the notations we use in this paper. When quantifying the robustness of the m-layer neural network, one essentially wants to know 1) how far the network output will deviate when the input is perturbed with distortions of a certain magnitude and 2) the critical point in terms of distortion magnitudes, beyond which the deviation might alter the model prediction. If we let x \u2208 R n denote the perturbed input of x 0 (class i) within an -bounded l pball (i.e., x \u2208 B p (x 0 , ), or x \u2212 x 0 p \u2264 ), the task of robustness analysis for this network intrinsically involves the comparison between the i-th network output F i (x) and other outputs F j =i (x). In practice, one can translate the original problem to the problem of deriving a lower bound of F i (x) and upper bounds of F j =i (x) for perturbed inputs within the l p -norm ball. With such quantifier, network F is guaranteed to make consistent predictions within the l p -norm ball if the lower bound of the original class output is always larger than the upper bounds of all other classes' outputs.\n\nWe summarize below the LP problem (Salman et al. 2019) to solve the lower bound of F i (x). The LP problem for the upper bound of F j =i (x) can be similarly derived.\n\nThe LP problem. The optimization problem for solving the lower bound of\nF i (x) = z (m) i = W (m) i,: a (m\u22121) + b (m) i reads: min a (0) \u2208Bp(x0, ),a [m\u22121] ,z [m\u22121] W (m) i,: a (m\u22121) + b (m) i (1) s.t. z (k) = W (k) a (k\u22121) + b (k) , \u2200 k \u2208 [m \u2212 1], a (k) = \u03c3(z (k) ), \u2200 k \u2208 [m \u2212 1].\nThe optimization problem for upper bounds can be readily obtained by replacing the \"min\" operation by \"max\". Then, the nonlinear constraint in (1) is lifted with linear relaxations. Specifically, suppose the lower and upper bounds of the pre-activation units z [m\u22121] are known, namely, for k from 1 to m \u2212 1, as a result l (k) and u (k) satisfy\nl (k) z (k) u (k) ,(2)\nand therefore every element \u03c3(z (1) can be bounded by linear functions:\n(k) i ) of the nonlinear acti- vation \u03c3(z (k) ) in constrainth (k)L i (z (k) i ) \u2264 \u03c3(z (k) i ) \u2264 h (k)U i (z (k) i ), \u2200z (k) i \u2208 [l (k) i , u (k) i ],(3)for i \u2208 [n k ]. The existence of linear bounding func- tions in (3) is guaranteed since z (k) i\nis bounded and compactness is a continuous invariant within any interval. For example, the following are bounding functions: h\n(k)L i (z (k) i ) = min z (k) i \u2208[l (k) i ,u (k) i ] (\u03c3(z (k) i )), h (k)U i (z (k) i ) = max z (k) i \u2208[l (k) i ,u (k) i ] (\u03c3(z (k) i )). h (k)L i and h (k)U i\ncan also be taken as the pointwise supremum and infimum of several linear functions, respectively, which is equivalent to using multiple linear constraints. In practice, Salman et al. use linear functions characterized by slopes and intercepts:\nh (k)L i (z (k) i ) = s (k)L i z (k) i + t (k)L i , h (k)U i (z (k) i ) = s (k)U i z (k) i + t (k)U i .(4)\nThe optimization problem can therefore be relaxed to an LPalike problem 1 :\nmin a (0) \u2208Bp(x0, ),a [m\u22121] ,z [m\u22121] W (m) i,: a (m\u22121) + b (m) i (5) s.t. \uf8f1 \uf8f2 \uf8f3 z (k) = W (k) a (k\u22121) + b (k) , \u2200 k \u2208 [m \u2212 1], h (k)L (z (k) ) a (k) h (k)U (z (k) ), \u2200 k \u2208 [m \u2212 1], l (k) z k u (k) , \u2200 k \u2208 [m \u2212 1].\nRecalling that with the optimization formed as in Problem (5), one is essentially optimizing for the lower (or upper) output bounds of the network (the pre-activation of the m-th layer), whereas these build upon the assumption that the preactivation bounds are known as Equation (2). To satisfy this assumption, one actually only needs to substitute the layer index m in Problem (5) with the corresponding intermediate layer's index. In practice, one can recursively solve LP problems from the second layer to the m-th layer to obtain the pre-activation bounds for all layers. In this process, the pre-activation bounds computed in a layer also constitute the optimization constraint for the next to-be-solved optimization problem for the next layer's pre-activation. See details of this LP-based method in Appendix Section A.3.\n\n\nCROWN Solutions.\n\nHere we briefly walk through the derivation of Fast-Lin (Weng et al. 2018b) and CROWN , whose procedures are essentially the same except for activation-specific bounding rules adopted. The first steps include bounding z\n(k) i , k \u2208 [m] 2 . z (k) i = n k\u22121 j=1 W (k) i,j \u03c3(z (k\u22121) j ) + b (k) i ,(6)\u2265 n k\u22122 j=1W (k\u22121) i,j \u03c3(z (k\u22122) j ) +b (k\u22121) i ,(7)\nwhere neg(\nx) = x, if x \u2264 0; neg(x) = 0, otherwise. And W (k\u22121) i,j = [relu(W (k) i,: ) (s (k\u22121)L ) + neg(W (k) i,: ) (s (k\u22121)U ) ]W (k\u22121) :,j ,b (k\u22121) i = [relu(W (k) i,: ) (s (k\u22121)L ) + neg(W (k) i,: ) (s (k\u22121)U ) ]b (k\u22121) + relu(W (k) i,: )t (k\u22121)L + neg(W (k) i,: )t (k\u22121)U + b (k)\ni , where denotes element-wise products. As Equations (6) and (7) are in similar forms, the above procedures can be repeated until all the nonlinearities in k \u2212 1 layers are unwrapped by linear bounding functions and z (1)\ni,j x j +b (1) i , whereW (1) i,j andb (1) i\nare similarly defined as shown above. Taking the dual form of the bound then yields the closed-form bound \u03b3 L j that satisfies\nz (k) i \u2265 \u03b3 (k)L i :=W (1) i,: x 0 \u2212 W (1) i,: q +b (1) i ,(8)\u2200 x \u2208 B p (x 0 , ),\nwhere 1/p + 1/q = 1. Although the steps above are used to derive the closed-form lower bound, the closed-form upper bound \u03b3 (k)U i can be similarly derived. To quantify the robustness for an m-layer neural network, one needs to recursively adopt formulas in Equation (8) to calculate the bounds of pre-activation 3 z (k) , for k = 2, . . . , m. These bounds, as will be explained in more details later, confine the feasible set for choosing bounding linear functions in Equation (4). Notably, lower bound \u03b3 \n[k\u22121]U = {s (1)U , . . . , s (k\u22121)U }, s [k\u22121]L = {s (1)L , . . . , s (k\u22121)L } and their intercepts t [k\u22121]U = {t (1)U , . . . , t (k\u22121)U }, t [k\u22121]L = {t (1)L , .\n. . , t (k\u22121)L }. A major difference that distinguishes CROWN from our contributions in the following sections is its deterministic rules of choosing upper/lower-bounding lines. The readers are referred to the literature  or Sections A.2 and A.4 in the appendix for more details of CROWN.\n\n\nRelation Between the LP Problem and CROWN Solutions\n\nNow we discuss the relationship between the LP problem formulation and CROWN. A key conclusion is that: CROWN is not only a dual feasible solution of the presented LP problem as discussed by Salman et al., it gives the optimal solution under mild constraints. Before introducing the optimality of CROWN solutions under the LP framework, we define an important condition in the computation process of CROWN as below:\nCondition 1 Self-consistency. Suppose {s [v\u22121]U ,s [v\u22121]L , t [v\u22121]U ,t [v\u22121]L } are used to calculate \u03b3 (v)L i and \u03b3 (v)U i , {\u015d [k\u22121]U ,\u015d [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L } are used to calculate \u03b3 (k)L j and \u03b3 (k)U j\n, then the following condition holds,\ns [v\u22121]U =\u015d [v\u22121]U ,s [v\u22121]L =\u015d [v\u22121]L , t [v\u22121]U =t [v\u22121]U ,t [v\u22121]L =t [v\u22121]L , for \u2200 i \u2208 [n v ], \u2200j \u2208 [n k ], 2 \u2264 v \u2264 k \u2264 m\nand two sets equal to each other is defined as their corresponding elements equal to each other. A similar condition can also be defined in the LP-based method and is supplemented in Section A.3 in the appendix. The self-consistency condition guarantees the same set of bounding lines is used when computing bounds for different neurons in the process of CROWN or the LP-based method. We note that both the original CROWN and the LP-based method satisfy the self-consistency condition. Theorem 1 The lower bound obtained by Equation (8) is the optimal solution to Problem (5) when the following three conditions are met:\n\n\u2022 Each of the h (k)L (z k ) and h (k)U (z k ) in Problem (5) is chosen to be one linear function 4 as in Equation (4). \u2022 The LP problem shares the same bounding lines with CROWN. \u2022 The self-consistency conditions for both CROWN and the LP-based method hold. We refer readers to Section A.5 in the appendix for the proof. We emphasize the cruciality of the self-consistency conditions in Theorem 1: We do observe CROWN and the LPbased method can give different bounds when Condition 1 is not met, even though the two use the same bounding lines. In essence, Theorem 1 allows one to compute bounds analytically and efficiently following steps in CROWN instead of solving the expensive LP problems under certain conditions. 4 Theoretically one can use multiple linear functions to bound the nonlinearity in Problem (5) to obtain tighter bounds. \n\n\nFastened CROWN\n\nRecognizing the dependency of lower bounds and upper bounds to slopes and intercepts in the original CROWN method, a consistent use of these parameters is enforced through the self-consistency condition. In fact, we argue that this constraint can be lifted in general (we visualize this relaxation in Figure 1). The aim of this section stems from this relaxation and focuses on optimizing the preactivation/output bounds over these tunable bounding parameters to achieve tighter bounds. In that merit, we propose an optimization framework called FROWN (Fastened CROWN) for tightening robustness certificates in CROWN. Moreover, FROWN is versatile and can be widely applied to tighten previously-proposed CNN-Cert (Boopathy et al. 2019) for convolutional neural networks and POPQORN (Ko et al. 2019) for recurrent neural networks. We formalize the objective as the following two optimization problems:\nmax s [k\u22121]L ,s [k\u22121]U ,t [k\u22121]L ,t [k\u22121]U \u03b3 (k)L i (9) s.t. s (v)L i z (v) i + t (v)L i \u2264 \u03c3(z (v) i ) \u2264 s (v)U i z (v) i + t (v)U i , \u2200 z (v) i \u2208 [l (v) i , u (v) i ], i \u2208 [n v ], v \u2208 [k \u2212 1], and min s [k\u22121]L ,s [k\u22121]U ,t [k\u22121]L ,t [k\u22121]U \u03b3 (k)U i (10) s.t. s (v)L i z (v) i + t (v)L i \u2264 \u03c3(z (v) i ) \u2264 s (v)U i z (v) i + t (v)U i , \u2200 z (v) i \u2208 [l (v) i , u (v) i ], i \u2208 [n v ], v \u2208 [k \u2212 1].\nHowever, we stress that Problems (9) and (10) are generally non-convex optimization problems when there are more than two layers in the target network. We enclose the proof as Section A.7 in the appendix. Therefore, optimizing for a non-convex objective function over parameters in large search spaces with infinite number of constraints is impractical. To this end, our ideas are to limit the search space to Table 2: Search space of bounding lines for ReLU, Sigmoid, and Tanh functions. \"Variable\" is the optimization variable that characterizes the bounding line. \"Range\" is the feasible region of the variable. \"-\" indicates the case when the tightest bounding line is unique and chosen. The slope and intercept of ReLU upper-bounding line are always set to be s 0 and t(s 0 , l), respectively.\n\n\nNonlinearity ReLU (Lower bnd.) Sigmoid & Tanh (Upper bnd.)\n\nSigmoid & Tanh (Lower bnd.) Pre-activation l < u \u2264 0 l < 0 < u 0 \u2264 l < u l < u \u2264 0\nl < 0 < u 0 \u2264 l < u l < u \u2264 0 l < 0 < u 0 \u2264 l < u Bounds case 1 case 2 case 3 case 4 Variable - s - - d 1 - d 1 d 2 d 2 - - Range - [0, 1] - - [l d , u] - [l, u] [l, u] [l, u d ] - - Slope s 0 s s 0 s 0 \u03c3 (d 1 ) s 0 \u03c3 (d 1 ) \u03c3 (d 2 ) \u03c3 (d 2 ) s 0 s 0 Intercept t(s 0 , l) 0 t(s 0 , l) t(s 0 , l) t(\u03c3 (d 1 ), d 1 ) t(s 0 , l) t(\u03c3 (d 1 ), d 1 ) t(\u03c3 (d 2 ), d 2 ) t(\u03c3 (d 2 ), d 2 ) t(s 0 , l)\nt(s 0 , l) Notes: Case 1 refers to \u03c3 (u)l + t(\u03c3 (u), u) \u2265 \u03c3(l); and case 2, otherwise. Case 3 refers to \u03c3 (l)u + t(\u03c3 (l), l) \u2264 \u03c3(u); and case 4, otherwise. s 0 = [\u03c3(u) \u2212 \u03c3(l)]/ (u \u2212 l), t(s, y) = \u03c3(y) \u2212 sy. l d and u d are defined as the abscissas of the points at which the tangent passes the left endpoint (l, \u03c3(l)) and the right endpoint (u, \u03c3(u)), respectively. d 1 and d 2 are the abscissas of the points of tangency. See Figure 2 for the visualization of l d , u d , d 1 and d 2 .  Table 2. smaller ones. We present our solutions by first introducing the ideas of \"tighter\" bounding lines.\n(a) 0 \u2264 l < u (b) l < 0 < u (c) l < u \u2264 0 (d) l < 0 < uDefinition 1 Supposeh (k)L i (z (k) i ) =s (k)L i z (k) i +t (k)L i and h (k)L i (z (k) i ) =\u015d (k)L i z (k) i +t (k)L i are two lower-bounding lines that satisfy h (k)L i (z (k) i ) >\u0125 (k)L i (z (k) i ), \u2200 z (k) i \u2208 (l (k) i , u (k) i ) \u03c3(z (k) i ) \u2265h (k)L i (z (k) i ), \u2200 z (k) i \u2208 [l (k) i , u (k) i ] then we sayh (k)L i (z (k) i ) =s (k)L i z (k) i +t (k)L i is a tighter lower-bounding line than\u0125 (k)L i (z (k) i ) =\u015d (k)L i z (k) i +t (k)L i for the nonlinear activation \u03c3 in the interval [l (k) i , u (k) i ].\nSimilarly, we define a tighter upper-bounding line. Accordingly, the tightest bounding line refers to the\u0125 (k)L i when there is, by definition, no tighter bounding line than itself. Note that the tightest bounding line may not be unique. For example, any line passing through the origin with a slope between 0 and 1 is a tightest lower-bounding line for the ReLU activation in an interval across the origin (l\n(v) i < 0 < u (v) i ).\nWith the notion of tightness, a straightforward idea is to adopt one of the tightest bounding lines in every layer for generally tighter closed-form pre-activation/output bounds. However, the proposition: tighter bounding lines \u21d2 tighter closed-form bounds is not always true. We observe tighter bounding lines can sometimes lead to looser bounds. However, if we roll back to Condition 1, we can prove that it constitutes a sufficient condition for the proposition. Theorem 2 If the robustness of a neural network is evaluated by CROWN on two trials with two different sets of bounding lines characterized by\n{s [k\u22121]U ,s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L } and {\u015d [k\u22121]U ,\u015d [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L },\nand in both of which the self-consistency condition is met, then the closed-form bounds obtained via CROWN satisfy Proof: The self-consistency guarantees the optimality of bounds given by CROWN to the corresponding LP problem (5) according to Theorem 1. As the use of tighter bounding lines in Problem (5) narrows the feasible set, the optimal value of Problem (5) (lower pre-activation/output bound) will stay or grow larger, which means the lower bound given by CROWN will stay or grow larger. Similar arguments extend to tightened upper bounds.\n\u03b3 (k)L i (s [k\u22121]U ,s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ) \u2265 \u03b3 (k)L i (\u015d [k\u22121]U ,\u015d [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ), \u03b3 (k)U i (s [k\u22121]U ,s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ) \u2264 \u03b3 (k)U i (\u015d [k\u22121]U ,\u015d [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ), for \u2200 i \u2208 [n k ],\nTill now, we have confirmed the connection between the tightest bounding lines and the tightest CROWN preactivation/output bound under Condition 1. In addition, we manage to prove Theorem 2 under a weaker condition (see its proof in Section A.6 in the appendix).\n\nCondition 1 is too strong a condition for our proposed optimization framework to be practical. Actually we propose to improve CROWN by breaking Condition 1. Our problem can be eased by only considering the dependency of closed-form pre-activation/output bounds on the intercepts (with the slopes fixed). We provide the following theorem: \n\u03b3 (k)L i (s [k\u22121]U , s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ) \u2265 \u03b3 (k)L i (s [k\u22121]U , s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ), \u03b3 (k)U i (s [k\u22121]U , s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ) \u2264 \u03b3 (k)U i (s [k\u22121]U , s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L ), for \u2200 i \u2208 [n k ], whent (v\u22121)L t (v\u22121)L andt (v\u22121)U t (v\u22121)U , \u2200v \u2208 [k \u2212 1].\nThis theoretical guarantee limits the freedom in choosing the intercepts: we should always choose upper-bounding lines with smaller intercepts and lower-bounding lines with larger intercepts if different bounding lines are allowed for different network neurons. Note that this conclusion holds under no assumptions on the choice of bounding lines and hence can be used to instruct how to choose bounding lines in FROWN. We demonstrate Theorem 3 can be used to reduce the search space of the upper (or lower) bounding line to one that can be characterized by a single variable continuously in Appendix Section A.8. This enables the usage of gradient-based method to search over candidate bounding lines to obtain tighter bounds. We further limit the search space to the tightest bounding lines (which is a subset of the search space narrowed only by Theorem 3) as demonstrated in Table 2 and exemplified in Figure 2 in order to simplify implementation. We emphasize that this limit is not necessary. FROWN can be readily generalized to the case in which the search space is reduced only by Theorem 3, and the obtained bounds should be even tighter as the search space is larger. Since the tightest bounding lines defined in Table 2 automatically satisfy the optimization constraints in Problems (9) and (10), the constrained optimization problems are then converted to unconstrained ones. Furthermore, notice that the objective functions in the two problems are differentiable to bounding line parameters. This allows us to solve the problems by projected gradient descent (Nesterov 2014) (see details in Appendix Section A.9).\n\nBy and large, given an m-layer network F , input sample x 0 \u2208 R n , l p ball parameters p \u2265 1, and \u2265 0, for \u2200 j \u2208 [n m ], 1/q = 1 \u2212 1/p, we can compute two fixed values \u03b3 L j and \u03b3 U j such that \u2200x \u2208 B p (x 0 , ), the inequality \u03b3 L j \u2264 F j (x) \u2264 \u03b3 U j holds. Suppose the label of the input sequence is i, the largest possible lower bound i of untargeted and targeted (target class j) attacks is found by solving:\nUntargeted: i = max , s.t. \u03b3 L i ( ) \u2265 \u03b3 U j ( ), \u2200j = i. Targeted:\u02c6 (i, j) = max , s.t. \u03b3 L i ( ) \u2265 \u03b3 U j ( ).\nWe conduct binary search procedures to compute the largest possible i (or\u02c6 ).\n\n\nExperimental Results\n\nOverview. In this section, we aim at comparing the LPbased method 5 and FROWN as two approaches to improve CROWN. We allow the LP-based method to use more than one bounding lines (which also increases computation cost) in order to make improvement on CROWN. Specifically, two lower-bounding lines are considered for ReLU networks while up to three upper/lower-bounding lines are adopted for Sigmoid (or Tanh) networks in the LP-based method (more details supplemented as Section A.4 in the appendix). On the other hand, FROWN improves CROWN solutions by optimizing over the bounding lines to give tighter bounds. These two approaches are evaluated and compared herein by both the safeguarded regions they certify and their time complexity. We run the LP-based method on a single Intel Xeon E5-2640 v3 (2.60GHz) CPU. We implement our proposed method FROWN using PyTorch to enable the use of an NVIDIA GeForce GTX TITAN X GPU. However, we time FROWN on a single Intel Xeon E5-2640 v3 (2.60GHz) CPU when comparing with the LP-based method for fair comparisons. We leave the detailed experimental set-ups and complete experimental results to Appendix Section A.9.\n\nExperiment I. In the first experiment, we compare the improvements of FROWN and the LP-based method over CROWN on sensorless drive diagnosis networks 6 and MNIST classifiers. We present their results in Table 3. As shown in the table, we consider ReLU and Sigmoid (results of Tanh networks are included in Appendix Section A.9) networks that are trained independently on two datasets. The size of the networks ranges from 3 layers to 20 layers and 20 neurons to 100 neurons. We remark that even on networks with only 100 neurons, the LP-based method scales badly and is unable to provide results in 100 minutes for only one image. The improved bounds in Table 3 verify the effectiveness of both FROWN and LP-based approach in tightening CROWN results. Specifically, an up to 93% improvement in the magnitude of bounds is witnessed on sensorless drive diagnosis networks. And in general, the deeper the target network is, the greater improvement can be achieved. When comparing FROWN to the LP-based method, it is demonstrated that FROWN computes bounds up to two orders of magnitudes faster than the LP-based method and is especially advantageous when certifying l 1 -norm regions. On the other hand, while the LP-based method gives larger certified bounds for ReLU networks in most cases, FROWN certifies larger bounds for Sigmoid and Tanh networks.\n\nExperiment II. In our second experiment, we compute the robustness certificate on CIFAR10 networks that have 2048 neurons in each layer. With the width of neural networks, the LP-based method is unusable due to its high computationalcomplexity. Therefore, we only show the improvements FROWN has brought to the original CROWN solutions. In Table 3: (Experiment I) Averaged certified l \u221e bounds and l p bounds (p = 1, 2, \u221e) of Sensorless Drive Diagnosis classifiers and MNIST classifiers, respectively. \"N/A\" indicates no results can be obtained in the given runtime. The up arrow \"\u2191\" means \" more than\". \"m \u00d7 [N ] \u03c3\" means an m-layer network with N neurons and \u03c3 activation.  this experiment, we further speed up FROWN by optimizing neurons in a layer group by group, instead of one by one, and we provide a parameter to balance the trade-off between tightness of bounds and time cost in FROWN(see details in Appendix Section A.10). We observe consistent trends on CIFAR10 networks: the deeper the neural network is, the more significant improvement can be made by FROWN in tightening CROWN solutions. Notably, an up to 38% improvement in certified bounds is achieved when considering l \u221e -norm balls in Sigmoid networks.\n\n\nDiscussion\n\nOverall, we have shown the trade-off between the computational costs and certified adversarial distortions in ReLU networks: the LP-based approach certifies larger bounds than FROWN at the cost of 2 to 178 times longer runtime. How-ever, the LP-based approach suffers poor scalability and soon becomes computationally infeasible as the network grows deeper or wider. In contrast, FROWN manages to increase the certified region of CROWN much more efficiently and wins over the LP-based approach in almost all Sigmoid/Tanh networks. Notably, in some cases, the LP-based method gives even worse result than CROWN (those with negative improvements). We conclude two possible reasons: i) the Gurobi LP solver is not guaranteed to converge to the optimal solution and ii) statistical fluctuations caused by random sample selections. More discussions on this are included in Appendix Section A.9.\n\n\nConclusion\n\nIn this paper, we have proved the optimality of CROWN in the relaxed LP framework under mild conditions. Further-more, we have proposed a general and versatile optimization framework named FROWN for optimizing state-of-the-art formal robustness verifiers including CROWN, CNN-Cert, and POPQORN. Experiments on various networks have verified the usefulness of FROWN in providing tightened robustness certificates at a significantly lower cost than the LP-based method.\n\n\nslopes of bounding lines in previous layers s\n\nFigure 1 :\n1The process of CROWN using different bounding lines to compute the closed-form bounds for different neurons. The blue curves are the ReLU activation. The orange and green lines are the upper and lower bounding lines, respectively. When computing closed-form bounds of the preactivation of neurons in the second layer, different neurons can choose different bounding lines in the previous layers to yield the tightest closed-form bounds for themselves.\n\nFigure 2 :\n2Illustration of the search space of bounding lines for Sigmoid and ReLU activation. See definitions of d 1 , d 2 , u d , l d in\n\n\nwhen bounding lines determined by {s [k\u22121]U ,s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L } are the same as or tighter than those determined by {\u015d [k\u22121]U ,\u015d [k\u22121]L , t [k\u22121]U ,t [k\u22121]L }.\n\nTable 1 :\n1List of NotationsNotation \nDefinition \nNotation Definition \nNotation \nDefinition \n\n\n\nReLU networks through binary search. Fast-Lin is further generalized for multilayer perceptrons with general activation functions in CROWN). Recently, Salman et al. conclude a general framework for a genre of convex relaxed optimization problems and demonstrate existing approaches to be special cases of their proposal. Notably, although Wong and Kolter propose to verify the robustness for ReLU network by the use of LP, a feasible dual solution is instead used in practice to avoid any actual use of LP solvers. Comparatively, Salman et al. experiment with more than one linear function to bound nonlinear activations (e.g. 2 lower-bounding functions for ReLU act.) and stick to LP solvers.Tanh activation \n\nminimum distortion. However, this certificate method was \nshown to be generally too conservative to be useful (Hein \nand Andriushchenko 2017; Weng et al. 2018b). Later, \ntighter bounds have also been provided for continuously-\ndifferentiable shallow networks by utilizing local Lipschitz \nconstants of the network (Hein and Andriushchenko 2017). \nThen, for the first time, the formal verification problem is \nreduced from a mixed integer linear programming (MILP) \nproblem to a linear programming (LP) problem when deal-\ning with l \u221e -norm box constraints (Wong and Kolter 2018). \nIts concurrent works include Fast-Lin (Weng et al. 2018b), \nwhich analytically calculates bounds for perturbed sam-\nples in given regions and finds the largest certifiable re-\ngion for \n\n\nTheorem 3 If the robustness of a neural network is evaluated by CROWN on two trials with bounding lines characterized by {s [k\u22121]U , s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L } and {s [k\u22121]U , s [k\u22121]L ,t [k\u22121]U ,t [k\u22121]L }, then the closed-form bounds obtained via CROWN satisfy\n\nTable 4 :\n4(Experiment II) Averaged certified l p bounds of different classifiers on CIFAR10 Networks.Network \np \nCertified Bounds \nImprove-\nNetwork \np \nCertified Bounds \nImprove-\nNetwork \np \nCertified Bounds \nImprove-\nCROWN FROWN \nment \nCROWN FROWN \nment \nCROWN FROWN \nment \n\n4 \u00d7 [2048] \nReLU \n\n1 \n7.5460 \n7.5989 \n0.70% \n6 \u00d7 [2048] \nReLU \n\n1 \n4.5990 \n4.7241 \n2.72% \n8 \u00d7 [2048] \nReLU \n\n1 \n4.2349 \n4.9416 16.69% \n2 \n0.6175 \n0.6303 \n2.09% \n2 \n0.3745 \n0.3723 \u22120.60% \n2 \n0.3476 \n0.3809 \n9.59% \n\u221e \n0.0151 \n0.0157 \n4.14% \n\u221e \n0.0092 \n0.0093 \n0.95% \n\u221e \n0.0087 \n0.0094 \n8.83% \n\n4 \u00d7 [2048] \nSigmoid \n\n1 \n3.6558 \n4.4726 22.34% \n6 \u00d7 [2048] \nSigmoid \n\n1 \n1.5093 \n1.8430 22.11% \n8 \u00d7 [2048] \nSigmoid \n\n1 \n1.2875 \n1.6862 30.97% \n2 \n0.2847 \n0.3353 17.77% \n2 \n0.1180 \n0.1448 22.71% \n2 \n0.1006 \n0.1295 28.65% \n\u221e \n0.0069 \n0.0082 18.33% \n\u221e \n0.0029 \n0.0035 21.03% \n\u221e \n0.0024 \n0.0033 37.65% \n\n\nThe optimization problem turns to a strict LP problem only when we have p = \u221e or 1 that makes the feasible set a polyhedron. However we coarsely denote all the cases in general as LP problems since all the constraints are now linear in the variables.\nSimilar to the discussion in the LP-based method above, the bounds computed are exactly network output bounds when k = m; whereas k = m gives the pre-activation bounds to fulfill the assumption in Inequality (2). 3 z (1) is deterministically computed by the input and z (m) = F (x) is the output bound.\nThe highly-efficient Gurobi LP solver is adopted here. 6 https://archive.ics.uci.edu/ml/datasets/Dataset+for+ Sensorless+Drive+Diagnosis\nAcknowledgementThis work is partially supported by the General Research Fund (Project 14236516) of the Hong Kong Research Grants Council, and MIT-Quest program.\nHoudini: Fooling deep structured visual and speech recognition models with adversarial examples. Boopathy, CoRR abs/1801.01944NeurIPS. SP. [Carlini and WagnerAAAIReferences [Boopathy et al. 2019] Boopathy, A.; Weng, T.-W.; Chen, P.- Y.; Liu, S.; and Daniel, L. 2019. Cnn-cert: An efficient framework for certifying robustness of convolutional neural networks. In AAAI. [Carlini and Wagner 2017] Carlini, N., and Wagner, D. 2017. Towards evaluating the robustness of neural networks. In SP. [Carlini and Wagner 2018] Carlini, N., and Wagner, D. A. 2018. Audio adversarial examples: Targeted attacks on speech-to-text. CoRR abs/1801.01944. [Cisse et al. 2017] Cisse, M. M.; Adi, Y.; Neverova, N.; and Keshet, J. 2017. Houdini: Fooling deep structured visual and speech recognition models with adversarial examples. In NeurIPS.\n\nDynamic fusion with intra-and inter-modality attention flow for visual question answering. [ Dvijotham, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). A dual approach to scalable verification of deep networks. UAI[Dvijotham et al. 2018] Dvijotham, K.; Stanforth, R.; Gowal, S.; Mann, T.; and Kohli, P. 2018. A dual approach to scalable verification of deep networks. UAI. [Gao et al. 2019a] Gao, P.; Jiang, Z.; You, H.; Lu, P.; Hoi, S. C. H.; Wang, X.; and Li, H. 2019a. Dynamic fusion with intra-and inter-modality attention flow for visual question answering. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n\nMulti-modality latent interaction network for visual question answering. [ Gao, The IEEE International Conference on Computer Vision (ICCV). [Gao et al. 2019b] Gao, P.; You, H.; Zhang, Z.; Wang, X.; and Li, H. 2019b. Multi-modality latent interaction network for visual question answering. In The IEEE International Conference on Computer Vision (ICCV).\n\nCrafting adversarial examples for speech paralinguistics applications. CoRR abs/1711.03280. [Goodfellow, Shlens, and Szegedy. Y Gong, C Poellabauer, I Goodfellow, J Shlens, C Szegedy, NeurIPS. ICLR[Gong and Poellabauer 2017] Gong, Y., and Poellabauer, C. 2017. Crafting adversarial examples for speech paralinguis- tics applications. CoRR abs/1711.03280. [Goodfellow, Shlens, and Szegedy 2015] Goodfellow, I.; Shlens, J.; and Szegedy, C. 2015. Explaining and harnessing adversarial examples. In ICLR. [Hein and Andriushchenko 2017] Hein, M., and An- driushchenko, M. 2017. Formal guarantees on the robustness of a classifier against adversarial manipulation. In NeurIPS.\n\nPOPQORN: Quantifying robustness of recurrent neural networks. Ko, ICML. Adversarial examples in the physical world. ICLR WorkshopKo et al. 2019] Ko, C.-Y.; Lyu, Z.; Weng, L.; Daniel, L.; Wong, N.; and Lin, D. 2019. POPQORN: Quantifying ro- bustness of recurrent neural networks. In ICML. [Kurakin, Goodfellow, and Bengio 2017] Kurakin, A.; Goodfellow, I.; and Bengio, S. 2017. Adversarial examples in the physical world. ICLR Workshop. [Moosavi-Dezfooli, Fawzi, and Frossard 2016] Moosavi- Dezfooli, S.-M.; Fawzi, A.; and Frossard, P. 2016.\n\nA convex relaxation barrier to tight robustness verification of neural networks. CoRR abs/1902.08722. ; Deepfool, Mudrakarta, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. the 2016 ACM SIGSAC Conference on Computer and Communications SecurityNesterovSpringer Publishing CompanyNeurIPSDeepfool: a simple and accurate method to fool deep neural networks. In CVPR. [Mudrakarta et al. 2018] Mudrakarta, P. K.; Taly, A.; Sun- dararajan, M.; and Dhamdhere, K. 2018. Did the model understand the question? [Nesterov 2014] Nesterov, Y. 2014. Introductory Lectures on Convex Optimization: A Basic Course. Springer Publishing Company, Incorporated, 1 edition. [Papernot et al. 2016] Papernot, N.; McDaniel, P. D.; Swami, A.; and Harang, R. E. 2016. Crafting adversarial input se- quences for recurrent neural networks. MILCOM. [Raghunathan, Steinhardt, and Liang 2018] Raghunathan, A.; Steinhardt, J.; and Liang, P. 2018. Certified defenses against adversarial examples. ICLR. [Salman et al. 2019] Salman, H.; Yang, G.; Zhang, H.; Hsieh, C.; and Zhang, P. 2019. A convex relaxation barrier to tight robustness verification of neural networks. CoRR abs/1902.08722. [Sharif et al. 2016] Sharif, M.; Bhagavatula, S.; Bauer, L.; and Reiter, M. K. 2016. Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. In Proceedings of the 2016 ACM SIGSAC Conference on Com- puter and Communications Security, 1528-1540. [Singh et al. 2018] Singh, G.; Gehr, T.; Mirman, M.; P\u00fcschel, M.; and Vechev, M. 2018. Fast and effective ro- bustness certification. In NeurIPS. 10825-10836.\n\nEvaluating the robustness of neural networks: An extreme value theory approach. Szegedy, GlobalSIP. ICLR. [Weng et al. 2018bKolter80ICML[Szegedy et al. 2014] Szegedy, C.; Zaremba, W.; Sutskever, I.; Bruna, J.; Erhan, D.; Goodfellow, I.; and Fergus, R. 2014. Intriguing properties of neural networks. ICLR. [Weng et al. 2018a] Weng, T.-W.; Zhang, H.; Chen, P.-Y.; Yi, J.; Su, D.; Gao, Y.; Hsieh, C.-J.; and Daniel, L. 2018a. Eval- uating the robustness of neural networks: An extreme value theory approach. In ICLR. [Weng et al. 2018b] Weng, T.-W.; Zhang, H.; Chen, H.; Song, Z.; Hsieh, C.-J.; Boning, D.; Dhillon, I. S.; and Daniel, L. 2018b. Towards fast computation of certified robustness for relu networks. ICML. [Weng et al. 2018c] Weng, T.-W.; Zhang, H.; Chen, P.-Y.; Lozano, A.; Hsieh, C.-J.; and Daniel, L. 2018c. On ex- tensions of clever: A neural network robustness evaluation algorithm. In GlobalSIP. [Weng et al. 2019] Weng, L.; Chen, P.-Y.; Nguyen, L.; Squil- lante, M.; Boopathy, A.; Oseledets, I.; and Daniel, L. 2019. PROVEN: Verifying robustness of neural networks with a probabilistic approach. In ICML. [Wong and Kolter 2018] Wong, E., and Kolter, Z. 2018. Provable defenses against adversarial examples via the con- vex outer adversarial polytope. In ICML, volume 80, 5286- 5295.\n\nAdversarial attacks beyond the image space. Zeng, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). [Zeng et al. 2019] Zeng, X.; Liu, C.; Wang, Y.-S.; Qiu, W.; Xie, L.; Tai, Y.-W.; Tang, C.-K.; and Yuille, A. L. 2019. Adversarial attacks beyond the image space. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n\nEfficient neural network robustness certification with general activation functions. Zhang, NeurIPS. [Zhang et al. 2018] Zhang, H.; Weng, T.-W.; Chen, P.-Y.; Hsieh, C.-J.; and Daniel, L. 2018. Efficient neural network robustness certification with general activation functions. In NeurIPS. 4944-4953.\n", "annotations": {"author": "[{\"end\":162,\"start\":68},{\"end\":248,\"start\":163},{\"end\":337,\"start\":249},{\"end\":409,\"start\":338},{\"end\":493,\"start\":410},{\"end\":565,\"start\":494}]", "publisher": null, "author_last_name": "[{\"end\":80,\"start\":77},{\"end\":175,\"start\":173},{\"end\":261,\"start\":257},{\"end\":347,\"start\":343},{\"end\":419,\"start\":416},{\"end\":505,\"start\":499}]", "author_first_name": "[{\"end\":76,\"start\":68},{\"end\":172,\"start\":163},{\"end\":256,\"start\":249},{\"end\":342,\"start\":338},{\"end\":415,\"start\":410},{\"end\":498,\"start\":494}]", "author_affiliation": "[{\"end\":161,\"start\":111},{\"end\":247,\"start\":190},{\"end\":336,\"start\":283},{\"end\":408,\"start\":366},{\"end\":492,\"start\":442},{\"end\":564,\"start\":507}]", "title": "[{\"end\":65,\"start\":1},{\"end\":630,\"start\":566}]", "venue": null, "abstract": "[{\"end\":1832,\"start\":632}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2490,\"start\":2470},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2527,\"start\":2490},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2551,\"start\":2527},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2572,\"start\":2551},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3305,\"start\":3267},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3348,\"start\":3305},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3400,\"start\":3376},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3417,\"start\":3400},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3434,\"start\":3417},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3450,\"start\":3434},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3495,\"start\":3473},{\"end\":3535,\"start\":3516},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3561,\"start\":3535},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3606,\"start\":3581},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4060,\"start\":4039},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4078,\"start\":4060},{\"end\":4127,\"start\":4097},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4167,\"start\":4127},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4189,\"start\":4167},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4207,\"start\":4189},{\"end\":4340,\"start\":4315},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4577,\"start\":4559},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5035,\"start\":5014},{\"end\":7594,\"start\":7591},{\"end\":7665,\"start\":7662},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16929,\"start\":16914}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":30153,\"start\":30106},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30618,\"start\":30154},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30759,\"start\":30619},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30933,\"start\":30760},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":31028,\"start\":30934},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":32508,\"start\":31029},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":32777,\"start\":32509},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":33649,\"start\":32778}]", "paragraph": "[{\"end\":2908,\"start\":1848},{\"end\":3880,\"start\":2910},{\"end\":4690,\"start\":3882},{\"end\":5145,\"start\":4692},{\"end\":5860,\"start\":5237},{\"end\":6582,\"start\":6451},{\"end\":6850,\"start\":6584},{\"end\":7127,\"start\":6852},{\"end\":8806,\"start\":7271},{\"end\":8974,\"start\":8808},{\"end\":9047,\"start\":8976},{\"end\":9602,\"start\":9258},{\"end\":9697,\"start\":9626},{\"end\":10073,\"start\":9947},{\"end\":10478,\"start\":10234},{\"end\":10661,\"start\":10586},{\"end\":11704,\"start\":10876},{\"end\":11944,\"start\":11725},{\"end\":12086,\"start\":12076},{\"end\":12584,\"start\":12362},{\"end\":12756,\"start\":12630},{\"end\":13346,\"start\":12839},{\"end\":13799,\"start\":13511},{\"end\":14270,\"start\":13855},{\"end\":14521,\"start\":14484},{\"end\":15269,\"start\":14649},{\"end\":16113,\"start\":15271},{\"end\":17032,\"start\":16132},{\"end\":18224,\"start\":17426},{\"end\":18369,\"start\":18287},{\"end\":19355,\"start\":18760},{\"end\":20337,\"start\":19928},{\"end\":20969,\"start\":20361},{\"end\":21606,\"start\":21059},{\"end\":22097,\"start\":21835},{\"end\":22437,\"start\":22099},{\"end\":24355,\"start\":22729},{\"end\":24770,\"start\":24357},{\"end\":24960,\"start\":24883},{\"end\":26144,\"start\":24985},{\"end\":27496,\"start\":26146},{\"end\":28719,\"start\":27498},{\"end\":29623,\"start\":28734},{\"end\":30105,\"start\":29638}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5236,\"start\":5146},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6450,\"start\":5861},{\"attributes\":{\"id\":\"formula_2\"},\"end\":7270,\"start\":7128},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9257,\"start\":9048},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9625,\"start\":9603},{\"attributes\":{\"id\":\"formula_5\"},\"end\":9759,\"start\":9698},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9851,\"start\":9759},{\"attributes\":{\"id\":\"formula_7\"},\"end\":9946,\"start\":9851},{\"attributes\":{\"id\":\"formula_8\"},\"end\":10233,\"start\":10074},{\"attributes\":{\"id\":\"formula_9\"},\"end\":10585,\"start\":10479},{\"attributes\":{\"id\":\"formula_10\"},\"end\":10875,\"start\":10662},{\"attributes\":{\"id\":\"formula_11\"},\"end\":12023,\"start\":11945},{\"attributes\":{\"id\":\"formula_12\"},\"end\":12075,\"start\":12023},{\"attributes\":{\"id\":\"formula_13\"},\"end\":12361,\"start\":12087},{\"attributes\":{\"id\":\"formula_14\"},\"end\":12629,\"start\":12585},{\"attributes\":{\"id\":\"formula_15\"},\"end\":12819,\"start\":12757},{\"attributes\":{\"id\":\"formula_16\"},\"end\":12838,\"start\":12819},{\"attributes\":{\"id\":\"formula_17\"},\"end\":13510,\"start\":13347},{\"attributes\":{\"id\":\"formula_18\"},\"end\":14483,\"start\":14271},{\"attributes\":{\"id\":\"formula_19\"},\"end\":14648,\"start\":14522},{\"attributes\":{\"id\":\"formula_20\"},\"end\":17425,\"start\":17033},{\"attributes\":{\"id\":\"formula_21\"},\"end\":18759,\"start\":18370},{\"attributes\":{\"id\":\"formula_22\"},\"end\":19411,\"start\":19356},{\"attributes\":{\"id\":\"formula_23\"},\"end\":19927,\"start\":19411},{\"attributes\":{\"id\":\"formula_24\"},\"end\":20360,\"start\":20338},{\"attributes\":{\"id\":\"formula_25\"},\"end\":21058,\"start\":20970},{\"attributes\":{\"id\":\"formula_26\"},\"end\":21834,\"start\":21607},{\"attributes\":{\"id\":\"formula_27\"},\"end\":22728,\"start\":22438},{\"attributes\":{\"id\":\"formula_28\"},\"end\":24882,\"start\":24771}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":7736,\"start\":7729},{\"end\":17843,\"start\":17836},{\"end\":19256,\"start\":19248},{\"end\":23615,\"start\":23608},{\"end\":23959,\"start\":23952},{\"end\":26356,\"start\":26349},{\"end\":26807,\"start\":26800},{\"end\":27845,\"start\":27838}]", "section_header": "[{\"end\":1846,\"start\":1834},{\"end\":11723,\"start\":11707},{\"end\":13853,\"start\":13802},{\"end\":16130,\"start\":16116},{\"end\":18285,\"start\":18227},{\"end\":24983,\"start\":24963},{\"end\":28732,\"start\":28722},{\"end\":29636,\"start\":29626},{\"end\":30165,\"start\":30155},{\"end\":30630,\"start\":30620},{\"end\":30944,\"start\":30935},{\"end\":32788,\"start\":32779}]", "table": "[{\"end\":31028,\"start\":30963},{\"end\":32508,\"start\":31724},{\"end\":33649,\"start\":32881}]", "figure_caption": "[{\"end\":30153,\"start\":30108},{\"end\":30618,\"start\":30167},{\"end\":30759,\"start\":30632},{\"end\":30933,\"start\":30762},{\"end\":30963,\"start\":30946},{\"end\":31724,\"start\":31031},{\"end\":32777,\"start\":32511},{\"end\":32881,\"start\":32790}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16441,\"start\":16433},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19195,\"start\":19187},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23643,\"start\":23635}]", "bib_author_first_name": "[{\"end\":35420,\"start\":35419},{\"end\":36063,\"start\":36062},{\"end\":36471,\"start\":36470},{\"end\":36479,\"start\":36478},{\"end\":36494,\"start\":36493},{\"end\":36508,\"start\":36507},{\"end\":36518,\"start\":36517},{\"end\":37661,\"start\":37660}]", "bib_author_last_name": "[{\"end\":34607,\"start\":34599},{\"end\":35430,\"start\":35421},{\"end\":36067,\"start\":36064},{\"end\":36476,\"start\":36472},{\"end\":36491,\"start\":36480},{\"end\":36505,\"start\":36495},{\"end\":36515,\"start\":36509},{\"end\":36526,\"start\":36519},{\"end\":37080,\"start\":37078},{\"end\":37670,\"start\":37662},{\"end\":37682,\"start\":37672},{\"end\":39276,\"start\":39269},{\"end\":40539,\"start\":40535},{\"end\":40939,\"start\":40934}]", "bib_entry": "[{\"attributes\":{\"doi\":\"CoRR abs/1801.01944\",\"id\":\"b0\",\"matched_paper_id\":10167953},\"end\":35326,\"start\":34502},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":54700454},\"end\":35987,\"start\":35328},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":199552243},\"end\":36342,\"start\":35989},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":42987869},\"end\":37014,\"start\":36344},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":158046952},\"end\":37556,\"start\":37016},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":67855530},\"end\":39187,\"start\":37558},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":27716347},\"end\":40489,\"start\":39189},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":24142231},\"end\":40847,\"start\":40491},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53297058},\"end\":41149,\"start\":40849}]", "bib_title": "[{\"end\":34597,\"start\":34502},{\"end\":35417,\"start\":35328},{\"end\":36060,\"start\":35989},{\"end\":36468,\"start\":36344},{\"end\":37076,\"start\":37016},{\"end\":37658,\"start\":37558},{\"end\":39267,\"start\":39189},{\"end\":40533,\"start\":40491},{\"end\":40932,\"start\":40849}]", "bib_author": "[{\"end\":34609,\"start\":34599},{\"end\":35432,\"start\":35419},{\"end\":36069,\"start\":36062},{\"end\":36478,\"start\":36470},{\"end\":36493,\"start\":36478},{\"end\":36507,\"start\":36493},{\"end\":36517,\"start\":36507},{\"end\":36528,\"start\":36517},{\"end\":37082,\"start\":37078},{\"end\":37672,\"start\":37660},{\"end\":37684,\"start\":37672},{\"end\":39278,\"start\":39269},{\"end\":40541,\"start\":40535},{\"end\":40941,\"start\":40934}]", "bib_venue": "[{\"end\":34635,\"start\":34628},{\"end\":35501,\"start\":35432},{\"end\":36128,\"start\":36069},{\"end\":36535,\"start\":36528},{\"end\":37086,\"start\":37082},{\"end\":37769,\"start\":37684},{\"end\":39287,\"start\":39278},{\"end\":40610,\"start\":40541},{\"end\":40948,\"start\":40941},{\"end\":37849,\"start\":37771},{\"end\":39319,\"start\":39313}]"}}}, "year": 2023, "month": 12, "day": 17}