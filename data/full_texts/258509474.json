{"id": 258509474, "updated": "2023-10-19 17:40:32.011", "metadata": {"title": "Neural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs", "authors": "[{\"first\":\"Ming\",\"last\":\"Jin\",\"middle\":[]},{\"first\":\"Yuan-Fang\",\"last\":\"Li\",\"middle\":[]}]", "venue": "NeurIPS", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Continuous-time dynamic graphs naturally abstract many real-world systems, such as social and transactional networks. While the research on continuous-time dynamic graph representation learning has made signi\ufb01cant advances recently, neither graph topological properties nor temporal dependencies have been well-considered and explicitly modeled in capturing dynamic patterns. In this paper, we introduce a new approach, Neural Temporal Walks ( NeurTWs ), for representation learning on continuous-time dynamic graphs. By considering not only time constraints but also structural and tree traversal properties, our method conducts spatiotemporal-biased random walks to retrieve a set of representative motifs, enabling temporal nodes to be characterized effectively. With a component based on neural ordinary differential equations, the extracted motifs allow for irregularly-sampled temporal nodes to be embedded explicitly over multiple different interaction time intervals, enabling the effective capture of the underlying spatiotemporal dynamics. To enrich supervision signals, we further design a harder contrastive pretext task for model optimization. Our method demonstrates overwhelming superiority under both transductive and inductive settings on six real-world datasets 1 .", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/JinLP22", "doi": null}}, "content": {"source": {"pdf_hash": "8912de5cc5170f6a2c8638f288fdd71f7232322f", "pdf_src": "ScienceParsePlus", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "64f2f758d1c55aa585b353d56ecd03a67afe8a84", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/8912de5cc5170f6a2c8638f288fdd71f7232322f.txt", "contents": "\nNeural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs\n\n\nMing Jin ming.jin@monash.edu \nYuan-Fang Li yuanfang.li@monash.edu \n\nMonash University\n\n\n\nMonash University\n\n\n\nGriffith University\n\n\nNeural Temporal Walks: Motif-Aware Representation Learning on Continuous-Time Dynamic Graphs\n61AE74401F5ECEB39A0DE00D36D88AEE\nContinuous-time dynamic graphs naturally abstract many real-world systems, such as social and transactional networks.While the research on continuous-time dynamic graph representation learning has made significant advances recently, neither graph topological properties nor temporal dependencies have been well-considered and explicitly modeled in capturing dynamic patterns.In this paper, we introduce a new approach, Neural Temporal Walks (NeurTWs), for representation learning on continuous-time dynamic graphs.By considering not only time constraints but also structural and tree traversal properties, our method conducts spatiotemporalbiased random walks to retrieve a set of representative motifs, enabling temporal nodes to be characterized effectively.With a component based on neural ordinary differential equations, the extracted motifs allow for irregularly-sampled temporal nodes to be embedded explicitly over multiple different interaction time intervals, enabling the effective capture of the underlying spatiotemporal dynamics.To enrich supervision signals, we further design a harder contrastive pretext task for model optimization.Our method demonstrates overwhelming superiority under both transductive and inductive settings on six real-world datasets 1 .\n\nIntroduction\n\nContinuous-time dynamic graphs (CTDGs) consist of temporal events with respect to nodes (e.g., node addition/deletion) and edges (i.e., temporal interactions), which naturally arise in many realworld systems such as social networks and knowledge graphs [13,32].Traditional studies in dynamic graph modeling manually extract expressive patterns that are beneficial for understanding the crucial laws behind [36].For example, two people are likely to know each other if they have a common friend (Figure 1).Such a dynamic graph motif describes how social connections are established [31].Other expressive patterns, such as feedforward control loops, have also been investigated [20].However, manually extracting motifs is expensive, time-consuming, and requires domain knowledge, thus hindering the learning on dynamic graphs with more complicated laws [36].\n$ # $ $ b c $ # $ % $ $ a b c $ # $ $ a $ %\nTemporal walks:\na b \u2206$ $ c b \u2206$ #\nDynamic law: Two nodes that interact with a common temporal neighbor tend to be connected in the future The advent of graph neural networks (GNNs) makes it possible to understand more complicated graphs by automatically learning the laws behind [40,42].While GNNs have demonstrated great success in modeling static graphs, the research on dynamic graphs is still nascent.Current research on dynamic graph neural networks (DGNNs) faces two fundamental challenges.\n\nFirstly, the entangled spatial and temporal dependencies in real-world CTDGs typically need a specific design to model, preventing the direct use of off-the-shelf GNNs.To overcome this barrier, previous works simplify CTDGs to a series of static graph snapshots with uniform time intervals (i.e., discrete-time dynamic graphs, DTDGs) [24,29].However, this approximation compromises the modeling precision.Although [15] and [34] propose to learn on CTDGs directly, the inductiveness of the patterns they captured is not guaranteed because node identities are directly involved in their modeling process.Some recent methods [38,27,36] attempt to alleviate this issue.However, they only consider time but not topological and tree traversal properties when sampling temporal neighbors, limiting their ability to extract diverse and expressive patterns from dynamic systems.Secondly, temporal events in CTDGs occur irregularly (e.g., nodes a and c interact with b at different timestamps in Figure 1), resulting in a significant challenge in modeling temporal dependencies.Previous works typically bypass this challenge with the time encoding [38] to enable the use of message passing [38,27] or sequence models [15,36].However, time encoding hurts model performance as temporal dependencies are modeled implicitly.\n\nTo tackle the above challenges, we propose the Neural Temporal Walks (NeurTWs) method for representation learning on CTDGs, which extracts and encodes informative dynamic graph motifs composed of irregularly-sampled temporal nodes.Specifically, motivated by [36], we propose sptaiotemporal-biased random walks to extract diverse and expressive patterns from a CTDG by not only considering time constrains but also topological properties and tree traversals, allowing the sampler to be better aware of the importance of temporal neighbors while maintaining the exploration and exploitation trade-off.\n\n\nRelated Work\n\nDynamic Graph Neural Networks (DGNNs).Existing DGNNs can be broadly classified into two categories based on their inputs.Discrete-time DGNNs operate over a sequence of evenly-sampled static graph snapshots, where different strategies are proposed to model spatial and temporal clues, e.g., combining GNNs with sequence models [30,24,5,29].Our work relates to the second category, continuous-time DGNNs, where time-dependent node or edge embeddings are learned directly on CTDGs.Among these works, an in-demand design updates latent node states by aggregating k-hop neighborhood information with temporal message passing.For instance, TGAT [38] samples a set of k-hop temporal neighbors and proposes learnable time encodings to preserve time information in message passing.TGN [27] further equips TGAT with a node memory update mechanism as in [15].Another line of research leverages random walks to learn on CTDGs.Specifically, CTDNE [23] is the first to propose a CTDG embedding method with temporal walks.CAWs [36] extend this concept with anonymous temporal walks and uses a recurrent net to learn walk embeddings that are further aggregated when calculating interactive representations.Our method is different from prior walkbased approaches in three aspects: (1) We propose a new perspective on sampling temporal walks.While prior arts only consider time constraints, our method leverages multidimensional information, allowing the model to explore diverse and expressive patterns from CTDGs; (2) We propose a novel and intuitive motif embedding method to model latent spatiotemporal dynamics among irregularlysampled temporal nodes on CTDGs without relying on time encodings, which allows temporal dependencies to be modeled explicitly; (3) We replace the simple link prediction-based learning objective with a more challenging contrastive pretext task, which helps provide stronger supervision signals.\n\nNeural Ordinary Differential Equations (NODEs).Chen et al. [2] propose a new paradigm that generalizes discrete deep neural networks by parameterizing the derivative of latent states.This concept has been applied in research areas including time series forecasting [12,28] and computer vision [9,1].Recently, some works have extended NODEs to the graph domain, where most consider building deeper GNNs while alleviating the negative impacts of over-smoothing [37,25].Notably, the time information is absent among those works.In dynamic graph learning, most ODE-based works focus on discrete-time settings [12,6,8], and only a few extend NODEs to learn on CTDGs [7].\n\nIn this paper, inspired by the research on time series forecasting [28], we propose NeurTWs to encode extracted motifs with irregularly-sampled temporal nodes on CTDGs, which is fundamentally different from [7]: We directly integrate over multiple interaction time intervals to explicitly model the latent spatiotemporal dynamics across different temporal nodes with an ODE function, while [7] relies on a time encoding-assisted message passer to learn from historical temporal events.\n\n\nGraph Contrastive Learning (GCL).\n\nRecently, GCL has achieved great success in graph selfsupervised learning [19].Most existing works are on static graphs [35,43,44,11].While some studies have explored the possibility of dynamic graph contrastive learning, many of them are on DTDGs.For example, STGCL [18] enhances the model's forecasting ability with DTDG augmentations and an auxiliary contrastive loss.A similar design also exists in [41,39] and [26].On CTDGs, Tian et al. [33] propose to maximize the agreement between time-aware node embeddings at different time points.In DySubC [10], the mutual information between a node and its surrounding temporal subgraphs is maximized.Different from these works, we design an effective pretext task for model optimization, where the mutual information between two nodes in an interaction is maximized.Meanwhile, we push nodes away in the embedding space if there are no temporal interactions.\n\n\nProblem Formulation\n\nWe start by formally introducing the learning problem on CTDGs.A complete notation table is in Appendix A. This paper defines a CTDG as a stream of temporal interactions, i.e., G = {(e i , t i )} N i=1 , where each interaction has two nodes at a specific time, e.g., (e i , t i ) := ({u i , v i }, t i ), t i 2 R + .As many real-world CTDG datasets are unattributed and for simplicity, we first assume these temporal interactions are without node and edge attributes and later we will discuss how our method is extended to learn on attributed CTDGs.Facing the challenge of lacking label information, DGNNs are typically supervised by temporal interactions [45].Thus, dynamic link prediction is a widely adopted testbed to evaluate how accurate a DGNN is in predicting future interactions with the observation of historical events.Specifically, given two nodes u and v at time t in G, we aim to learn their time-aware embeddings h u and h v , where the presence of an interaction between them can be predicted with a downstream classifier, i.e., b\ny u,v,t = clf(h u , h v ).\nThe ground truth y u,v,t = 1 if there exists an interaction between u and v at time t otherwise y u,v,t = 0. On this basis and with learned time-aware node representations, conducting other downstream tasks, such as dynamic node classification with another classifier, is also feasible.4 The Proposed Method: Neural Temporal Walks\n\n\nPreliminaries: Temporal Walks and Dynamic Graph Motifs\n\nGiven a dynamic graph G, we define a motif as a subset of temporal nodes with their interactions within a defined time range [14], e.g., 0 \uf8ff t \uf8ff q.As those motifs reflect certain dynamic laws in a CTDG, it is desirable to characterize a temporal node with its surrounding motifs.Definition 4.1.1(Temporal Walk).Given a dynamic graph G, we denote the interactions that are directly associated with a node u before a cut time t as G u,t = {(e, t 0 ) | t 0 < t, u 2 e , (e, t 0 ) 2 G}.A (time-reversed) temporal walk rooted at node u at time t is defined as W , which is a sequence of temporal nodes as in [36], i.e., node w i at time t i with w 0 := u and t 0 := t:\nW = {(w i , t i ) | i 2 N, 0 \uf8ff i \uf8ff l, t 0 > t 1 > \u2022 \u2022 \u2022 > t l , ({w i , w i 1 }, t i ) 2 G wi 1 ,ti 1 for i 1},(1)\nwhere l is the walk length.We also use W [i][0] and W [i] [1] (i.e., w i and t i in (w i , t i ) respectively) to denote the specific node and time in the i-th step.\n\nEach walk W rooted at a temporal node can actually be regarded as one of its surrounding motifs if t 1 t l is bounded within the defined motif time range.A concrete example is given in Figure 2, where two walks in the leftmost side form two triadic closures, which essentially represent the same motif on the rightmost side after an individual walk anonymization [21].The necessity of anonymization is to replace original node identities in walks with their relative identities, which maps each walk to a particular pattern and thus connects temporal walks and dynamic graph motifs.Definition 4.1.2(Anonymous Walk).Given a temporal node w and a walk W , the anonymization operation A(\u2022) is defined as follows [36]:\nA(w; W ) = |{v 0 , \u2022 \u2022 \u2022 , v i \u21e4 | v i 2 W }|, where i \u21e4 is the smallest index s.t. v i \u21e4 = w.\n(2)\n\n\nDynamic Graph Motif Extraction\n\nTemporal Walk Sampling.Existing path-based methods mainly employ a temporal-biased sampling method when extracting dynamic graph motifs [23,36].Specifically, given a node u at time t, the probability of its neighbor a in ({a, u}, t 0 ) 2 G u,t to be sampled is proportion to exp(\u21b5(t 0 t)), which discounts stale neighbors and tends to sample more current nodes with timestamps closer to t.A larger \u21b5 emphasizes more on this bias.Although more current neighbors are more likely to be informative, the underlying topological and tree traversal properties are not respected, which hinders the extraction of diverse and expressive patterns.Here, we propose spatiotemporal-biased random walks with the exploitation and exploration trade-off.\n\nOur motivations are twofold: (1) Most-recent neighbors should be allocated a larger sampling probability / exp(\u21b5(t 0 t)) as they are typically more informative w.r.t. a root node at time t.In Figure 3(a), given a root node u and its two temporal neighbors f and c, a temporal-biased sampling path is more likely to be u !f instead of u !c; (2) Neighbors with higher connectivity need to be emphasized to allow exploring more diverse and potentially expressive motifs.Given a node a at time t 0 , we use its degree d a = |G a,t 0 | to reify its connectivity, thus the proposed spatial-biased probability / exp( /d a ) with a hyperparameter to control the bias intensity.Algorithm 1 illustrates the walk sampling procedures with the above considerations.Given a node u at time t, the probability of its temporal neighbor a to be sampled is the average of the following normalized probabilities:\nP rt(a) = exp(\u21b5(ta t)) P a 0 2G u,t exp(\u21b5(t a 0 t)) (3) P rs(a) = exp( /da) P a 0 2G u,t exp( /d a 0 )(4)\n\nAlgorithm 1 Sampling Temporal Walks\n\nRequire: Root node w0, cut time t0, G, C, l\n1: Initialize {Wc = (w0, t0) | 1 \uf8ff c \uf8ff C} 2: for i in 1, 2, \u2022 \u2022 \u2022 , l do 3: for j in 1, 2, \u2022 \u2022 \u2022 , C do 4: wp, tp := Wj[i][0], Wj[i][1] 5:\nInitialize dw = 0 for all w 2 Gw p ,tp 6:\n\nfor (e, t) in Gw p ,tp do 7:\n\nLet e := {w, wp}, dw = |Gw,t| 8:\n\nend for 9:\n\nSample one (e, t) 2 Gw p ,tp with prob./ exp(\u21b5(t tp)) and exp( /dw) 10:\n\nLet e := {w, wp}, Wc = Wc||(w, t) 11:\n\nend for 12: end for 13:\nreturn {Wc | 1 \uf8ff c \uf8ff C}\nAlthough Algorithm 1 complements the temporalbiased schema by considering the additional topological information, it may overly encourage the depthfirst search (DFS), which could misleadingly sample many homogeneous motifs with a limited budget.Take an extreme example, if |M u | is restricted to 3 in Figure 3\n\nwhere s a and denotes the traversal times of node a and the intensity of such a regularization.\n\nOur complete walk sampling algorithm and its complexity analysis are in Appendices B.1 and B.3.In a nutshell, given a temporal node, the probability of its neighbor to be sampled is the average of the probabilities defined in Equations 3, 4 and 5.In NeurTWs, given a queried interaction between two temporal nodes u and v as shown in Figure 3, we sample a set of C temporal walks rooted at each node with length l, denoted as M u and M v .\n\nAnonymization.Walk anonymization replaces node identities with position encodings (aka relative identities), which injects structural information while maintaining the inductiveness of NeurTWs.A drawback of Equation 2 is that the position encoding of each node only depends on its specific walk, leading anonymous walks rooted at the same node sharing different name spaces [36].Thus, we consider two practical solutions: unitary and binary anonymization to address this problem.For a temporal node w in at least one walk rooted at node u, its unitary anonmization w.r.t.u considers the name space defined over M u , the set of walks rooted at u:\nA(w; M u )[i] = |{W | w = W [i][0], W 2 M u }|, where i 2 {0, \u2022 \u2022 \u2022 , l}.(6)\nIn Equation 6, the identity of w is replaced by a vector A(w; M u ) with length l, where the i-th element counts the number of walks that have node w appearing in position i.\n\nWhile unitary anonymization anonymizes node w w.r.t.M u as A(w; M u ), for interacting root nodes u and v, A(w; M u ) and A(w; M v ) belong to different name spaces.Since DGNNs are typically supervised by temporal interactions, establishing the correlations between W 2 M u [ M v may be beneficial.Thus, the binary anonymization is defined as follows [36]:\nA(w; M u , M v ) = A(w; M u ) || A(w; M v ),(7)\nwhere || denotes the concatenation operation to establish the connections among motifs in M u and M v .In the rest of the paper, we abbreviate the two anonymization strategies as A(w) for simplicity and denote c W = { A(w i ), t i | (w i , t i ) 2 W for i = 0, 1, \u2022 \u2022 \u2022 , l} as an anonymous walk.\n\n\nNeural Temporal Walk Encoding\n\nA significant challenge to model CTDGs is that interactions occur irregularly.Previous works bypass this challenge by concatenating node attributes with extra time encodings when aggregating the neighbourhood information [38,27,36], where temporal dependencies are modeled implicitly.A detailed discussion is in Appendix D.2.To encode a motif with irregularly-sampled temporal nodes, we explicitly integrate over multiple interaction time intervals to learn the latent spatiotemporal dynamics with those discrete observations.Figure 4 and Algorithm 2 describe our method in a nutshell, which consists of two interleaving steps: Continuous evolution and instantaneous activation.\n\n\nAlgorithm 2 Neural Temporal Walk Encoding\n\nRequire: An anonymous temporal walk c W = { A(wi), ti | (wi, ti) 2 W for i = 0, 1, \u2022 \u2022 \u2022 , l} 1: Reverse the order of elements in c W 2:\nt 1 = t0, h 1 = 0 3: for i in 0, 1, 2, \u2022 \u2022 \u2022 , l do 4: h 0 i = ODESolve(hi 1, f \u2713 , ti\n\nNeural Temporal Walk Encoding\n\nEncode an anonymized temporal walk 2 3: Continuous Evolution.Given a series of temporal nodes at different time, i.e., (A(w i ), t i ) 2 c W and ensuring t i 1 < t i by reversing the order of elements in c W , the latent spatiotemporal dynamics among those nodes are modeled as follows:\n!(\") !(-) !(,) !(\") \u2206!! )( ' () % % % % Feature Extraction \u2206!# \u2206!\"h 0 i = h i 1 + Z ti ti 1 f (h t , \u2713) dt,(8)\nwhere h i 1 denotes the latent states after encoding (A(w i 1 ), t i 1 ) 2 c W .We define the ODE function f (h t , \u2713) as an autoregressive gated recurrent unit parameterized by \u2713.See Appendix B.2.\n\nInstantaneous Activation.The latent state evolution in Equation 8 conditions on a series of discrete observations.Thus, we define a function to activate latent state trajectories with instantaneous inputs:\nh i = g(h 0 i , A 0 (w i ), ),(9)\nwhere g(\u2022, ) can be a standard RNN cell parameterized by , and A 0 (w i ) = MLP(A(w i ), ) denotes the linear mapping of a discrete observation A(w i ) in an anonymous walk c W .\n\nCompared with [36], we naturally model spatiotemporal dynamics behind walks with irregularlysampled temporal nodes, where the time information has been explicitly reflected in this modeling process.On this basis, for a temporal node u, we obtain its time-aware representation by pooling the embedding of walks in M u , denoted as h u .In this paper, we adopt the sum pooling for simplicity.\n\n\nContrastive Optimization\n\nA self-supervised pretext task is required to train DGNNs due to the scarcity of the labeling information.Most current works formulate their learning problems as a binary classification task, where the existence of an interaction is predicted.From the contrastive point of view, a binary cross-entropy loss essentially forms a particular case of the Jensen-Shannon estimator [19], where the number of negatives is one and thus provides limited supervision signals.\n\nHere, we introduce a harder contrastive pretext task, where the mutual information between interacting temporal nodes (e.g., node u and v in Figure 3) is maximized.We detail the complete training algorithm of our method in Appendix B.4.In brief, the following noise-contrastive loss is minimized in the proposed approach:\nL = E h log exp sim(h u , h v ) exp sim(h u , h v ) + P v 0 2G,v 0 6 =v exp sim(h u , h v 0 ) i . (10)\nsim(\u2022) measures the similarity between two entities, i.e., sim(h u , h v ) = MLP(h u , h a , \u21e0) , where (\u2022) and \u21e0 are sigmoid activation and trainable parameters.\n\n\nExtension and Discussion\n\nLearning on Attributed CTDGs.Our method can be easily extended to model CTDGs with node and interaction attributes.To achieve this, we only need to slightly modify Equation 9as follows:\nh i = g(h 0 i , A 0 (w i ) || X wi || X ei , ),(11)\n\nExperiments\n\n\nExperimental Setting\n\nBaselines.Our model is compared with six state-of-the-art methods in modeling CTDGs.They can be divided into two categories based on their intrinsic mechanisms: (1) message passing-based methods, including DyRep [34], TGAT [38], and TGN [27];\n\n(2) sequential model-based methods, including CTDNE [23], JODIE [15], and CAWs [36].More details can be found in Appendix C.2.\n\nDatasets.We evaluate model performance on six real-world datasets.CollegeMsg [17] is a social network dataset consisting of message sending activities.Enron [17] is an email communication network.Taobao [46] is an attributed user behavior dataset containing user-item interactions.MOOC [17] is an attributed network consisting of student-course interactions.Wikipedia and Reddit [15] are two bipartite interaction networks consisting of editor-page and user-post activities with rich attributive information.The dataset statistics are summarized in Table 1, and their detailed descriptions are in Appendix C.1.\n\nEvaluation Protocols.For link prediction, we follow the evaluation protocols of CAWs [36] and consider two different downstream tasks for evaluation: transductive and inductive link prediction.\n\nIn transductive link prediction, we sort and divide all N interactions in a dataset by time into three separate sets for training, validation, and testing.Specifically, the ranges of training, validation, and testing sets are [0, N trn ), [N trn , N val ), [N val , N], where N trn /N and N val /N are 0.7 and 0.85.\n\nIn inductive link prediction, we use the same splits but mask a proportion of nodes (10%) and associated interactions during training, which are predicted during inference to evaluate the model inductiveness.Specifically, we first remove all interactions connected with masked nodes in the training set and then remove all interactions not associated with them in the validation and testing sets.In particular, we have two specific settings: (1) New-Old tasks require the model to predict the interactions with one unobserved (i.e., masked) and one observed nodes; and (2) New-New tasks aim to predict the interactions between all unobserved nodes.\n\nFor dynamic node classification, we follow the evaluation protocol in [27].Specifically, we first obtain a model under the setting of transductive link prediction.Then, we train and test a separate classifier on top of this pre-trained model with the temporal nodes observed in [0, N val ) and [N val , N].\n\nTraining Details.We implement and train all models under a unified evaluation framework with the Adam optimizer.The tuning of primary hyperparameters is discussed in Appendix C.3.In solving ODEs, we use the Runge-Kutta method with the number of function evaluations set to 8 by default.For fair comparisons and simplicity, we use sum-pooling when calculating node representations in both our method and CAWs.We also test NeurTWs \u2020, which is equipped with the binary anonymization, while NeurTWs adopts the default unitary anonymization.All methods are tuned thoroughly with nonlinear 2-layer and 3-layer perceptrons to conduct downstream link  [34] 0.5297 \u00b1 0.042 0.8632 \u00b1 0.013 0.8462 \u00b1 0.012 0.6195 \u00b1 0.018 TGAT [38] 0.7528 \u00b1 0.004 0.6592 \u00b1 0.012 0.5400 \u00b1 0.005 0.6750 \u00b1 0.035 TGN [27] 0.8990 \u00b1 0.003 0.8944 \u00b1 0.015 0.8484 \u00b1 0.029 0.7703 \u00b1 0.032 CAWs [36] 0.9002 \u00b1 0.002 0.9520 \u00b1 0.002 0.  [34] 0.4486 \u00b1 0.021 0.7241 \u00b1 0.025 0.7641 \u00b1 0.012 0.5504 \u00b1 0.010 TGAT [38] 0.7240 \u00b1 0.008 0.6131 \u00b1 0.049 0.5537 \u00b1 0.018 0.6410 \u00b1 0.024 TGN [27] 0.8699 \u00b1 0.007 0.7068 \u00b1 0.116 0.8706 \u00b1 0.008 0.6968 \u00b1 0.008 CAWs [36] 0\n\n\nResults and Discussion\n\nTable 3: Dynamic node classification performance w.r.t.AUC.We use bold font and underline to highlight the best and second best performances.\n\nThe baseline results are taken from [27].\n\nMethod Wikipedia Reddit CTDNE [23] 0.7589 \u00b1 0.005 0.5943 \u00b1 0.006 JODIE [15] 0.8484 \u00b1 0.012 0.6183 \u00b1 0.027 DyRep [34] 0.8459 \u00b1 0.022 0.6291 \u00b1 0.024 TGAT [38] 0.8369 \u00b1 0.007 0.6556 \u00b1 0.007 TGN [27] 0.8781 \u00b1 0.003 0.6706 \u00b1 0.009 NeurTWs 0.8851 \u00b1 0.003 0.6652 \u00b1 0.022\n\nThe link prediction performance of our method and state-of-the-art baselines are summarized in , while all baselines have their AUCs \uf8ff 0.9, demonstrating the effectiveness of the proposed method.Specifically, on both transductive and inductive tasks, we make the following observations.(1) Our method performs well on both attributed and unattributed datasets, while the effectiveness of baseline models varies significantly.For instance, JODIE and DyRep have enormous performance gaps between Taobao and CollegeMsg in all three tasks.It indicates that our NeurTWs method is better at capturing essential dynamic laws.This superiority can be attributed to our spatiotemporal walks and associated encoding mechanism; (2) Our method is effective under both transductive and inductive settings.On the contrary, some baseline models cannot well generalize to predict interactions with unseen nodes (e.g., the performance of JODIE and DyRep drops on inductive tasks) because they rely on node identities.TGAT, TGN, and CAWs can yield better performances but leave room to improve.It is worth noting that simple unitary anonymization (i.e., NeurTWs) and more complex binary anonymization (i.e., NeurTWs \u2020) yield similar performance in most cases.Our method with the default, simpler unitary anonymization performs significantly better than CAWs, which utilizes binary anonymization, again demonstrating the superiority of our approach in modeling In addition, we compare the performance of our method (i.e., NeurTWs) on dynamic node classification with state-of-the-art baselines as shown in Table where our approach achieves the best or on-par performances, further confirming the effectiveness of the proposal.We do not report the results of NeurTWs \u2020 because node classification mainly considers properties of temporal nodes rather than interactions.\n\n\nAblation Study\n\nIn Table 4, we report the results of our ablation study on predicting inductive interactions in both new-old and new-new settings.Specifically, ablations 1, 2, and 3 remove Equations 3, 4, and 5 when sampling temporal walks.Ablation 4 disables Equation 8 when encoding an anonymous walk.Ablation 5 replaces our contrastive loss with a binary cross entropy loss.From the above variants, we see performances degradation when retrieving motifs without considering the temporal or spatial information, demonstrating the effectiveness of the proposed spatiotemporal-biased walk sampler.Moreover, disabling the exploitation & exploration trade-off also hurts performances.When removing the continuous evolution, more severe performance drops are found on CollegeMsg, further demonstrating that NeurTWs excel on CTDGs with more sparse interactions where existing works usually fail to model them well.The performance drops also exist when our contrastive pretext task is disabled.A specific study related to continuous evolution is in Appendix D.2.\n\n\nParametric Sensitivity\n\nWe study the important settings in NeurTWs and have the following observations: (1) For each dataset, there are sweet spots in balancing three intensities (i.e., \u21b5, , and ).Specifically, different datasets with different average interaction intensities, namely , prefer different temporal-biased intensities.For example, a relatively large \u21b5 benefits on CollegeMsg but hurts the performance on Taobao as shown in Figure 5(a).On both datasets, overly emphasizing the topology information with a large hurts the performance (see Figure 5(b)) because the temporal information is overly neglected.However, setting a relatively large seems beneficial (see Figure 5(c)), indicating the importance of balancing exploitation and exploration in temporal walk sampling; (2) We also investigate the choice of walk length l and number of walks C as shown in Figures 5(e) and 5(f).On both datasets, sampling 16 or 32 walks with the length 2 or 3 seems sufficient to characterize a temporal node;\n\n(3) For efficiency, we limit the number of negatives in Equation 10 instead of calculating h v 0 for all v 0 2 G where v 0 6 = v.Specifically, we find that a large number is usually beneficial on both datasets as shown in Figure 5(d), where the performance increases to converge with an increasing number of negatives.In our method, we normally do not have to tune continuous evolution-related hyperparameters, but we provide a detailed study in Appendix D.2.\n\n\nDiscussion and Conclusion\n\nLimitations.There are a few limitations for our method.Firstly, a more sophisticated time interval normalization is required.In real-world dynamic graphs, there may be some large time intervals between temporal nodes when constructing temporal walks.Although we propose a simple solution based on logarithmic transformations (see Appendix B.3), there is no theoretical guarantee of stability when solving the continuous evolution process by this normalization trick.Secondly, the calculation of spatial-biased probabilities is computationally heavy.While it is practical to limit the number of spanned temporal neighbors to alleviate the computational burden (see Appendix D.4), we resort to finding a more efficient implementation in the future.Social Impacts.Continuous-time dynamic graph representation learning benefits a wide range of real-world applications, including but not limited to recommender systems, social network mining, and industrial process modeling.However, there are also some potential negative impacts.For example, NeurTWs may learn skewed representations if there are biased patterns in the training data, which may result stereotyped predictions.Also, powerful dynamic graph models may augment harmful activities (e.g., attacking and phishing) on real-world dynamic systems.\n\n\nConclusion.\n\nWe propose a novel and competitive method for modeling CTDGs, which has advantages in three aspects.Firstly, our approach complements existing temporal neighborhood sampling algorithms by simultaneously considering temporal, topological, and tree traversal properties, enabling diverse and expressive dynamic graph motifs to be retrieved.Secondly, the proposed method allows these motifs with irregularly-sampled temporal nodes to be better embedded, where temporal dependencies are now explicitly modeled.Thirdly, our model forms a harder contrastive pretext task to enrich supervision signals.Consequently, the NeurTWs method outperforms existing works by large margins, revealing significant application prospects in many real-world scenarios, which will be an exciting focus in our future work.\n\nFigure 1 :\n1\nFigure 1: Temporal walks capture the law\n\n\n7 Figure 2 :Figure 3 :\n723\nFigure 2: Triadic closures and the dynamic graph motifs: Two example temporal walks form two different triadic closures but represent the same motif within the time range 0 \uf8ff t \uf8ff 7.A dynamic graph with timestamped edges and a queried interaction at a specific time\n\n\n\n\n(a), paths u !b !c ! u may be sampled three times, leaving no room to explore u !c ! b ! a and u !f !v !d.Thus, we design an exploitation & exploration trade-off to regularize the walk sampling with another probability: P r e (a) = exp( s a ) P a 0 2Gu,t exp( s a 0 ) ,\n\n\nFigure 4 :\n4\nFigure 4: The spatiotemporal dynamics behind irregularly-sampled temporal nodes are explicitly modeled.\n\n\nFigure 5 :\n5\nFigure 5: Study on important settings of NeurTWs.The performance in predicting all inductive interactions is reported.\n\n\nTable 1 :\n1\n[16,36]aset statistics.Average interaction intensity = 2N/(|V |T )[16,36]embodies the density of interactions in a fixed period, where T and |V | are dataset duration and number of nodes.wiandXei are linearly mapped features of node w i and edge e i := {w i 1 , w i } in c W .Batching and Computational Complexity.Onecomputational challenge is that each walk contains irregularly-sampled nodes at different timestamps, requiring the model to separately solve C different ODEs to calculate the embedding of a root node, thus hindering training in batches.To solve all ODEs at once in a minibatch with B sampled interactions, we unify the integral time among all ODEs (see Appendix B.3) to a certain range, which results in a lower time complexity of O(l) instead of O(Bl).In Appendix B.3, we also provide detailed complexity analysis and discuss how to make solving Equation 8 tractable with very large time intervals.\nStatisticsCollegeMsgEnronTaobaoMOOCWikipediaReddit# Nodes & Interactions1,899 & 59,835 143 & 62,617 64,703 & 77,436 7,144 & 411,749 9,227 & 157,474 10,984 & 672,447Duration (second)16,621,30372,932,52036,0002,572,0862,678,3732,678,390# Nodes & Interaction attributes0 & 00 & 00 & 40 & 4172 & 172172 & 172Average interaction intensity # Dynamically labeled nodes3.79 \u21e5 10 6 -1.2 \u21e5 10 5 -6.64 \u21e5 10 5 -4.48 \u21e5 10 5 -1.27 \u21e5 10 5 2174.57 \u21e5 10 5 366where X\n\nTable 2 :\n2\nTransductive and inductive link prediction performances w.r.t.AUC.We use bold font and underline to highlight the best and second best performances.NeurTWs \u2020 is a vairant of our method with the binary anonymization.\nTaskMethodCollegeMsgEnronTaobaoMOOCTransductiveJODIE [15] DyRep0.5846 \u00b1 0.0380.8714 \u00b1 0.0110.8477 \u00b1 0.0150.6815 \u00b1 0.014\n\n\n\nclassification tasks, and we adopt the commonly used Area Under the ROC Curve (AUC) and Average Precision (AP) as the evaluation metrics.More implementation details can be found in Appendix C.3.\nNew-NewNeurTWs NeurTWs \u2020 JODIE [15] DyRep [34] TGAT [38] TGN [27] CAWs [36] NeurTWs NeurTWs \u2020.8911 \u00b1 0.015 0.9575 \u00b1 0.011 0.9699 \u00b1 0.010 0.5135 \u00b1 0.048 0.5813 \u00b1 0.066 0.7283 \u00b1 0.029 0.7745 \u00b1 0.102 0.8974 \u00b1 0.009 0.9649 \u00b1 0.008 0.9768 \u00b1 0.0080.9612 \u00b1 0.002 0.9525 \u00b1 0.002 0.9566 \u00b1 0.007 0.7537 \u00b1 0.025 0.7184 \u00b1 0.061 0.6340 \u00b1 0.032 0.9217 \u00b1 0.026 0.9777 \u00b1 0.001 0.9906 \u00b1 0.007 0.9858 \u00b1 0.0150.8744 \u00b1 0.004 0.9316 \u00b1 0.018 0.9037 \u00b1 0.013 0.7791 \u00b1 0.004 0.7716 \u00b1 0.017 0.5479 \u00b1 0.025 0.8701 \u00b1 0.011 0.8762 \u00b1 0.004 0.9242 \u00b1 0.005 0.9140 \u00b1 0.0130.7479 \u00b1 0.023 0.7822 \u00b1 0.004 0.7772 \u00b1 0.006 0.8243 \u00b1 0.007 0.5288 \u00b1 0.021 0.6365 \u00b1 0.014 0.6448 \u00b1 0.053 0.7558 \u00b1 0.036 0.8329 \u00b1 0.010 0.8302 \u00b1 0.007prediction and node\n\nTable 2\n2(w.r.t. AUC) and Appendix D.1 (w.r.t.AP). As can be seen from this table, our methodachieves the best performance on different tasksand datasets in general. Notably, NeurTWs sur-passes the strongest model, CAWs, significantlyon both unattributed and attributed CTDGs, e.g.,7.76% and 4.78% on average on CollegeMsg andTaobao. Particularly, NeurTWs and NeurTWs \u2020achieve a strong AUC result0.95 on Col-legeMsg\n\nTable 4 :\n4\nAblation study with the proposed NeurTWs method.The performance in predicting all inductive interactions is reported.Comparing the results on Taobao, our method's improvements over CAWs are more significant than on CollegeMsg, e.g., 7.48% vs. 3.81% on transductive and 7.91% vs. 5.26% on inductive settings.Similar observations can also be found when compared on MOOC and CollegeMsg.This is because the CollegeMsg dataset has a lower average interaction intensity (i.e., = 3.79 \u21e5 10 6 ) compared with Taobao and MOOC datasets (i.e., = 6.64 \u21e5 10 5 and 4.48 \u21e5 10 5 ).A lower indicates a larger average time span in a temporal walk, for which our proposed continuous evolution process is more effective.\nNo.ConfigurationCollegeMsg AUCAPAUCTaobaoAP0 1 2 3 4 5Full model (NeurTWs) w/o T-biased probability w/o S-biased probability w/o E&E-biased probability 0.957 \u00b1 0.01 0.958 \u00b1 0.01 0.918 \u00b1 0.02 0.949 \u00b1 0.02 w/o continuous evolution 0.868 \u00b1 0.02 w/o contrasitve learning 0.954 \u00b1 0.010.966 \u00b1 0.01 0.928 \u00b1 0.02 0.958 \u00b1 0.02 0.965 \u00b1 0.01 0.898 \u00b1 0.01 0.962 \u00b1 0.010.938 \u00b1 0.02 0.932 \u00b1 0.03 0.915 \u00b1 0.01 0.926 \u00b1 0.01 0.860 \u00b1 0.05 0.935 \u00b1 0.010.933 \u00b1 0.02 0.927 \u00b1 0.01 0.915 \u00b1 0.01 0.927 \u00b1 0.01 0.901 \u00b1 0.02 0.932 \u00b1 0.01CTDGs without relying on sophisticated position encodings; (3)\nCode is available at https://github.com/KimMeen/Neural-Temporal-Walks 36th Conference on Neural Information Processing Systems (NeurIPS\n).\nhttps://www.massive.org.au/\nAcknowledgments and Disclosure of FundingSome computing resources for this project are supported by MASSIVE 2 .We thank Guangsi Shi for additional computational resources and assistance in model training and deployment.S. Pan was partially supported by an Australian Research Council (ARC) Future Fellowship (FT210100097).Y.-F.Li was partially supported by the DARPA CCU program (HR001121S0024).\nMri image reconstruction via learning optimization using neural odes. Terrence Eric Z Chen, Shanhui Chen, Sun, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer2020\n\nNeural ordinary differential equations. T Q Ricky, Yulia Chen, Jesse Rubanova, David Bettencourt, Duvenaud, Advances in Neural Information Processing Systems. 2018\n\nNeural spatio-temporal point processes. Brandon Ricky Tq Chen, Maximilian Amos, Nickel, International Conference on Learning Representations. 2020\n\nOn the properties of neural machine translation: Encoder-decoder approaches. Kyunghyun Cho, Bart Van Merri\u00ebnboer, Dzmitry Bahdanau, Yoshua Bengio, Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation. SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation2014\n\nCapturing network dynamics using dynamic graph representation learning. Palash Goyal, Sujit Rokka Chhetri, Arquimedes Martinez, Canedo , App. 16/550March 5 2020771US Patent\n\nTemporal knowledge graph forecasting with neural ode. Zhen Han, Zifeng Ding, Yunpu Ma, Yujia Gu, Volker Tresp, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language Processing2021\n\nLearning continuous system dynamics from irregularly-sampled partial observations. Zijie Huang, Yizhou Sun, Wei Wang, Advances in Neural Information Processing Systems. 202033\n\nCoupled graph ode for learning interacting system dynamics. Zijie Huang, Yizhou Sun, Wei Wang, 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2021. 2021\n\nLearning compositional representation for 4d captures with neural ode. Boyan Jiang, Yinda Zhang, Xingkui Wei, Xiangyang Xue, Yanwei Fu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2021\n\nSelf-supervised dynamic graph representation learning via temporal subgraph contrast. Linpu Jiang, Ke-Jia Chen, Jingqiang Chen, arXiv:2112.087332021arXiv preprint\n\nCgmn: A contrastive graph matching network for self-supervised graph similarity learning. Di Jin, Luzhi Wang, Yizhen Zheng, Xiang Li, Fei Jiang, Wei Lin, Shirui Pan, Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence. the Thirty-First International Joint Conference on Artificial Intelligence2022\n\nBin Yang, and Shirui Pan. Multivariate time series forecasting with dynamic graph neural odes. Ming Jin, Yu Zheng, Yuan-Fang Li, Siheng Chen, arXiv:2202.084082022arXiv preprint\n\nDynamic graph neural networks. Seyed Mehran, Kazemi , Graph Neural Networks: Foundations, Frontiers, and Applications. Springer2022\n\nTemporal motifs in time-dependent networks. Lauri Kovanen, M\u00e1rton Karsai, Kimmo Kaski, J\u00e1nos Kert\u00e9sz, Jari Saram\u00e4ki, Journal of Statistical Mechanics: Theory and Experiment. 201111P110052011\n\nPredicting dynamic embedding trajectory in temporal interaction networks. Srijan Kumar, Xikun Zhang, Jure Leskovec, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. the 25th ACM SIGKDD international conference on knowledge discovery & data mining2019\n\nG\u00fcnter Last, Mathew Penrose, Lectures on the Poisson Process. Institute of Mathematical Statistics Textbooks. Cambridge University Press2017\n\nJure Leskovec, Andrej Krevl, Snap datasets: Stanford large network dataset collection. 2014. 2016\n\nXu Liu, Yuxuan Liang, Yu Zheng, Bryan Hooi, Roger Zimmermann, arXiv:2108.11873Spatio-temporal graph contrastive learning. 2021arXiv preprint\n\nGraph self-supervised learning: A survey. Yixin Liu, Ming Jin, Shirui Pan, Chuan Zhou, Yu Zheng, Feng Xia, Philip Yu, IEEE Transactions on Knowledge and Data Engineering. 2022\n\nStructure and function of the feed-forward loop network motif. Shmoolik Mangan, Uri Alon, Proceedings of the National Academy of Sciences. 100212003\n\nReconstructing markov processes from independent and anonymous experiments. Silvio Micali, Zeyuan Allen, Zhu , Discrete Applied Mathematics. 2002016\n\nDenis Michael C Mozer, Robert V Kazakov, Lindsey, arXiv:1710.04110Discrete event, continuous time rnns. 2017arXiv preprint\n\nContinuous-time dynamic network embeddings. Giang Hoang Nguyen, John Boaz Lee, Ryan A Rossi, Nesreen K Ahmed, Eunyee Koh, Sungchul Kim, Companion Proceedings of the The Web Conference. 2018. 2018\n\nEvolvegcn: Evolving graph convolutional networks for dynamic graphs. Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura, Hiroki Kanezashi, Tim Kaler, Tao Schardl, Charles Leiserson, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034\n\nGraph neural ordinary differential equations. Michael Poli, Stefano Massaroli, Junyoung Park, Atsushi Yamashita, Hajime Asama, Jinkyoo Park, International Workshop on Deep Learning on Graphs. 2019\n\nSpatiotemporal contrastive video representation learning. Rui Qian, Tianjian Meng, Boqing Gong, Ming-Hsuan Yang, Huisheng Wang, Serge Belongie, Yin Cui, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2021\n\nTemporal graph networks for deep learning on dynamic graphs. Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, Michael Bronstein, ICML 2020 Workshop on Graph Representation Learning. 2020\n\nLatent ordinary differential equations for irregularly-sampled time series. Yulia Rubanova, Ricky Tq Chen, David K Duvenaud, Advances in Neural Information Processing Systems. 201932\n\nDysat: Deep neural representation learning on dynamic graphs via self-attention networks. Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, Hao Yang, Proceedings of the 13th International Conference on Web Search and Data Mining. the 13th International Conference on Web Search and Data Mining2020\n\nStructured sequence modeling with graph convolutional recurrent networks. Youngjoo Seo, Micha\u00ebl Defferrard, Pierre Vandergheynst, Xavier Bresson, International Conference on Neural Information Processing. Springer2018\n\nThe sociology of georg simmel. Georg Simmel, Simon and Schuster. 928921950\n\nFoundations and modeling of dynamic networks using dynamic graph neural networks: A survey. Joakim Skarding, Bogdan Gabrys, Katarzyna Musial, IEEE Access. 92021\n\nSelf-supervised representation learning on dynamic graphs. Sheng Tian, Ruofan Wu, Leilei Shi, Liang Zhu, Tao Xiong, Proceedings of the 30th ACM International Conference on Information & Knowledge Management. the 30th ACM International Conference on Information & Knowledge Management2021\n\nDyrep: Learning representations over dynamic graphs. Rakshit Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, Hongyuan Zha, International Conference on Learning Representations. 2019\n\nDeep graph infomax. Petar Velickovic, William Fedus, Pietro William L Hamilton, Yoshua Li\u00f2, Devon Bengio, Hjelm, International Conference on Learning Representations. 2019\n\nInductive representation learning in temporal networks via causal anonymous walks. Yanbang Wang, Yen-Yu Chang, Yunyu Liu, Jure Leskovec, Pan Li, International Conference on Learning Representations. 2021\n\nContinuous graph neural networks. Louis-Pascal Xhonneux, Meng Qu, Jian Tang, International Conference on Machine Learning. PMLR2020\n\nInductive representation learning on temporal graphs. Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan, International Conference on Learning Representations. 2020\n\nSpatial temporal enhanced contrastive and pretext learning for skeleton-based action representation. Yiwen Zhan, Yuchen Chen, Pengfei Ren, Haifeng Sun, Jingyu Wang, Qi Qi, Jianxin Liao, Asian Conference on Machine Learning. PMLR2021\n\nHe Zhang, Bang Wu, Xingliang Yuan, Shirui Pan, Hanghang Tong, Jian Pei, arXiv:2205.07424Trustworthy graph neural networks: Aspects, methods and trends. 2022arXiv preprint\n\nContrastive spatio-temporal pretext learning for self-supervised video representation. Yujia Zhang, Lai-Man Po, Xuyuan Xu, Mengyang Liu, Yexin Wang, Weifeng Ou, Yuzhi Zhao, Wing-Yin Yu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2022\n\nMultirelational graph neural architecture search with fine-grained message passing. Xin Zheng, Miao Zhang, Chunyang Chen, Chaojie Li, Chuan Zhou, Shirui Pan, IEEE International Conference on Data Mining. 2022\n\nTowards graph self-supervised learning with contrastive adjusted zooming. Yizhen Zheng, Ming Jin, Shirui Pan, Yuan-Fang Li, Hao Peng, Ming Li, Zhao Li, IEEE Transactions on Neural Networks and Learning Systems. 2022\n\nRethinking and scaling up graph contrastive learning: An extremely efficient approach with group discrimination. Yizhen Zheng, Shirui Pan, Cs Vincent, Yu Lee, Philip S Zheng, Yu, Advances in Neural Information Processing Systems. 2022\n\nTgl: A general framework for temporal gnn training on billion-scale graphs. Hongkuan Zhou, Da Zheng, Israt Nisa, Vasileios Ioannidis, Xiang Song, George Karypis, Proceedings of the VLDB Endowment. the VLDB Endowment202215\n\nLearning tree-based deep model for recommender systems. Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, Kun Gai, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining2018\n", "annotations": {"author": "[{\"end\":125,\"start\":96},{\"end\":162,\"start\":126},{\"end\":183,\"start\":163},{\"end\":204,\"start\":184},{\"end\":227,\"start\":205}]", "publisher": null, "author_last_name": "[{\"end\":104,\"start\":101},{\"end\":138,\"start\":136}]", "author_first_name": "[{\"end\":100,\"start\":96},{\"end\":135,\"start\":126}]", "author_affiliation": "[{\"end\":182,\"start\":164},{\"end\":203,\"start\":185},{\"end\":226,\"start\":206}]", "title": "[{\"end\":93,\"start\":1},{\"end\":320,\"start\":228}]", "venue": null, "abstract": "[{\"end\":1629,\"start\":354}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b12\"},\"end\":1902,\"start\":1898},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":1905,\"start\":1902},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2055,\"start\":2051},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2230,\"start\":2226},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2325,\"start\":2321},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2500,\"start\":2496},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2829,\"start\":2825},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2832,\"start\":2829},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3382,\"start\":3378},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3385,\"start\":3382},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3462,\"start\":3458},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3471,\"start\":3467},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3670,\"start\":3666},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3673,\"start\":3670},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3676,\"start\":3673},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4186,\"start\":4182},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4228,\"start\":4224},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4231,\"start\":4228},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4255,\"start\":4251},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":4258,\"start\":4255},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":4618,\"start\":4614},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5302,\"start\":5298},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5305,\"start\":5302},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5307,\"start\":5305},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5310,\"start\":5307},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5615,\"start\":5611},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5752,\"start\":5748},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5819,\"start\":5815},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5910,\"start\":5906},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":5988,\"start\":5984},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6239,\"start\":6236},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6473,\"start\":6470},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6718,\"start\":6715},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6945,\"start\":6942},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7152,\"start\":7148},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7155,\"start\":7152},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7179,\"start\":7176},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7181,\"start\":7179},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7346,\"start\":7342},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7349,\"start\":7346},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7492,\"start\":7488},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7494,\"start\":7492},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7496,\"start\":7494},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7547,\"start\":7544},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7621,\"start\":7617},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7760,\"start\":7757},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7943,\"start\":7940},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8151,\"start\":8147},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8197,\"start\":8193},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8200,\"start\":8197},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8203,\"start\":8200},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8206,\"start\":8203},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8344,\"start\":8340},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8480,\"start\":8476},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8483,\"start\":8480},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8492,\"start\":8488},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8519,\"start\":8515},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8628,\"start\":8624},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9661,\"start\":9657},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10362,\"start\":10361},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10593,\"start\":10589},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11071,\"start\":11067},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11304,\"start\":11301},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11777,\"start\":11773},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12123,\"start\":12119},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12398,\"start\":12394},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12401,\"start\":12398},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":15723,\"start\":15719},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":16600,\"start\":16596},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":17205,\"start\":17201},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":17208,\"start\":17205},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":17211,\"start\":17208},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":18995,\"start\":18991},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19775,\"start\":19771},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":20969,\"start\":20965},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":20980,\"start\":20976},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20994,\"start\":20990},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":21053,\"start\":21049},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21065,\"start\":21061},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":21080,\"start\":21076},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21206,\"start\":21202},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21286,\"start\":21282},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":21332,\"start\":21328},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21415,\"start\":21411},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21508,\"start\":21504},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":21826,\"start\":21822},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":22973,\"start\":22969},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23855,\"start\":23851},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":23925,\"start\":23921},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":23994,\"start\":23990},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":24064,\"start\":24060},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24103,\"start\":24099},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24173,\"start\":24169},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24242,\"start\":24238},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":24312,\"start\":24308},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24524,\"start\":24520},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24561,\"start\":24557},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":24602,\"start\":24598},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24643,\"start\":24639},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24683,\"start\":24679},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24722,\"start\":24718}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":31369,\"start\":31314},{\"attributes\":{\"id\":\"fig_1\"},\"end\":31663,\"start\":31370},{\"attributes\":{\"id\":\"fig_2\"},\"end\":31937,\"start\":31664},{\"attributes\":{\"id\":\"fig_3\"},\"end\":32056,\"start\":31938},{\"attributes\":{\"id\":\"fig_4\"},\"end\":32190,\"start\":32057},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33571,\"start\":32191},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":33920,\"start\":33572},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":34826,\"start\":33921},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":35243,\"start\":34827},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":36530,\"start\":35244}]", "paragraph": "[{\"end\":2501,\"start\":1645},{\"end\":2561,\"start\":2546},{\"end\":3042,\"start\":2580},{\"end\":4354,\"start\":3044},{\"end\":4955,\"start\":4356},{\"end\":6881,\"start\":4972},{\"end\":7548,\"start\":6883},{\"end\":8035,\"start\":7550},{\"end\":8977,\"start\":8073},{\"end\":10047,\"start\":9001},{\"end\":10405,\"start\":10075},{\"end\":11127,\"start\":10464},{\"end\":11408,\"start\":11243},{\"end\":12124,\"start\":11410},{\"end\":12223,\"start\":12220},{\"end\":12994,\"start\":12258},{\"end\":13888,\"start\":12996},{\"end\":14076,\"start\":14033},{\"end\":14257,\"start\":14216},{\"end\":14287,\"start\":14259},{\"end\":14321,\"start\":14289},{\"end\":14333,\"start\":14323},{\"end\":14406,\"start\":14335},{\"end\":14445,\"start\":14408},{\"end\":14470,\"start\":14447},{\"end\":14805,\"start\":14495},{\"end\":14902,\"start\":14807},{\"end\":15343,\"start\":14904},{\"end\":15991,\"start\":15345},{\"end\":16243,\"start\":16069},{\"end\":16601,\"start\":16245},{\"end\":16946,\"start\":16650},{\"end\":17658,\"start\":16980},{\"end\":17840,\"start\":17704},{\"end\":18246,\"start\":17960},{\"end\":18555,\"start\":18358},{\"end\":18762,\"start\":18557},{\"end\":18975,\"start\":18797},{\"end\":19367,\"start\":18977},{\"end\":19860,\"start\":19396},{\"end\":20183,\"start\":19862},{\"end\":20449,\"start\":20287},{\"end\":20663,\"start\":20478},{\"end\":20995,\"start\":20753},{\"end\":21123,\"start\":20997},{\"end\":21735,\"start\":21125},{\"end\":21930,\"start\":21737},{\"end\":22247,\"start\":21932},{\"end\":22897,\"start\":22249},{\"end\":23205,\"start\":22899},{\"end\":24314,\"start\":23207},{\"end\":24482,\"start\":24341},{\"end\":24525,\"start\":24484},{\"end\":24790,\"start\":24527},{\"end\":26639,\"start\":24792},{\"end\":27699,\"start\":26658},{\"end\":28708,\"start\":27726},{\"end\":29169,\"start\":28710},{\"end\":30499,\"start\":29199},{\"end\":31313,\"start\":30515},{\"end\":31368,\"start\":31328},{\"end\":31662,\"start\":31398},{\"end\":31936,\"start\":31667},{\"end\":32055,\"start\":31952},{\"end\":32189,\"start\":32071},{\"end\":33121,\"start\":32204},{\"end\":33800,\"start\":33585},{\"end\":34118,\"start\":33924},{\"end\":35957,\"start\":35257}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":2545,\"start\":2502},{\"attributes\":{\"id\":\"formula_1\"},\"end\":2579,\"start\":2562},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10074,\"start\":10048},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11242,\"start\":11128},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12219,\"start\":12125},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13994,\"start\":13889},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14215,\"start\":14077},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14494,\"start\":14471},{\"attributes\":{\"id\":\"formula_9\"},\"end\":16068,\"start\":15992},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16649,\"start\":16602},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17927,\"start\":17841},{\"attributes\":{\"id\":\"formula_12\"},\"end\":18313,\"start\":18247},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18357,\"start\":18313},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18796,\"start\":18763},{\"attributes\":{\"id\":\"formula_15\"},\"end\":20285,\"start\":20184},{\"attributes\":{\"id\":\"formula_16\"},\"end\":20286,\"start\":20285},{\"attributes\":{\"id\":\"formula_17\"},\"end\":20715,\"start\":20664}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":21681,\"start\":21680},{\"end\":24348,\"start\":24347},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":26668,\"start\":26667}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1643,\"start\":1631},{\"attributes\":{\"n\":\"2\"},\"end\":4970,\"start\":4958},{\"end\":8071,\"start\":8038},{\"attributes\":{\"n\":\"3\"},\"end\":8999,\"start\":8980},{\"attributes\":{\"n\":\"4.1\"},\"end\":10462,\"start\":10408},{\"attributes\":{\"n\":\"4.2\"},\"end\":12256,\"start\":12226},{\"end\":14031,\"start\":13996},{\"attributes\":{\"n\":\"4.3\"},\"end\":16978,\"start\":16949},{\"end\":17702,\"start\":17661},{\"end\":17958,\"start\":17929},{\"attributes\":{\"n\":\"4.4\"},\"end\":19394,\"start\":19370},{\"attributes\":{\"n\":\"4.5\"},\"end\":20476,\"start\":20452},{\"attributes\":{\"n\":\"5\"},\"end\":20728,\"start\":20717},{\"attributes\":{\"n\":\"5.1\"},\"end\":20751,\"start\":20731},{\"attributes\":{\"n\":\"5.2\"},\"end\":24339,\"start\":24317},{\"attributes\":{\"n\":\"5.3\"},\"end\":26656,\"start\":26642},{\"attributes\":{\"n\":\"5.4\"},\"end\":27724,\"start\":27702},{\"attributes\":{\"n\":\"6\"},\"end\":29197,\"start\":29172},{\"end\":30513,\"start\":30502},{\"end\":31325,\"start\":31315},{\"end\":31393,\"start\":31371},{\"end\":31949,\"start\":31939},{\"end\":32068,\"start\":32058},{\"end\":32201,\"start\":32192},{\"end\":33582,\"start\":33573},{\"end\":34835,\"start\":34828},{\"end\":35254,\"start\":35245}]", "table": "[{\"end\":33571,\"start\":33122},{\"end\":33920,\"start\":33801},{\"end\":34826,\"start\":34119},{\"end\":35243,\"start\":34837},{\"end\":36530,\"start\":35958}]", "figure_caption": "[{\"end\":31369,\"start\":31327},{\"end\":31663,\"start\":31397},{\"end\":31937,\"start\":31666},{\"end\":32056,\"start\":31951},{\"end\":32190,\"start\":32070},{\"end\":33122,\"start\":32203},{\"end\":33801,\"start\":33584},{\"end\":34119,\"start\":33923},{\"end\":35958,\"start\":35256}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2148,\"start\":2147},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4038,\"start\":4037},{\"end\":11603,\"start\":11602},{\"end\":13196,\"start\":13195},{\"end\":14805,\"start\":14804},{\"end\":15246,\"start\":15245},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17514,\"start\":17513},{\"end\":20011,\"start\":20010},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28147,\"start\":28146},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28261,\"start\":28260},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28387,\"start\":28384},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28583,\"start\":28580},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28943,\"start\":28939}]", "bib_author_first_name": "[{\"end\":37172,\"start\":37164},{\"end\":37193,\"start\":37186},{\"end\":37348,\"start\":37347},{\"end\":37350,\"start\":37349},{\"end\":37363,\"start\":37358},{\"end\":37375,\"start\":37370},{\"end\":37391,\"start\":37386},{\"end\":37519,\"start\":37512},{\"end\":37545,\"start\":37535},{\"end\":37706,\"start\":37697},{\"end\":37716,\"start\":37712},{\"end\":37741,\"start\":37734},{\"end\":37758,\"start\":37752},{\"end\":38038,\"start\":38032},{\"end\":38051,\"start\":38046},{\"end\":38077,\"start\":38067},{\"end\":38094,\"start\":38088},{\"end\":38192,\"start\":38188},{\"end\":38204,\"start\":38198},{\"end\":38216,\"start\":38211},{\"end\":38226,\"start\":38221},{\"end\":38498,\"start\":38493},{\"end\":38512,\"start\":38506},{\"end\":38521,\"start\":38518},{\"end\":38652,\"start\":38647},{\"end\":38666,\"start\":38660},{\"end\":38675,\"start\":38672},{\"end\":38841,\"start\":38836},{\"end\":38854,\"start\":38849},{\"end\":38869,\"start\":38862},{\"end\":38884,\"start\":38875},{\"end\":38896,\"start\":38890},{\"end\":39147,\"start\":39142},{\"end\":39161,\"start\":39155},{\"end\":39177,\"start\":39168},{\"end\":39312,\"start\":39310},{\"end\":39323,\"start\":39318},{\"end\":39336,\"start\":39330},{\"end\":39349,\"start\":39344},{\"end\":39357,\"start\":39354},{\"end\":39368,\"start\":39365},{\"end\":39380,\"start\":39374},{\"end\":39656,\"start\":39652},{\"end\":39664,\"start\":39662},{\"end\":39681,\"start\":39672},{\"end\":39692,\"start\":39686},{\"end\":39771,\"start\":39766},{\"end\":39786,\"start\":39780},{\"end\":39917,\"start\":39912},{\"end\":39933,\"start\":39927},{\"end\":39947,\"start\":39942},{\"end\":39960,\"start\":39955},{\"end\":39974,\"start\":39970},{\"end\":40140,\"start\":40134},{\"end\":40153,\"start\":40148},{\"end\":40165,\"start\":40161},{\"end\":40367,\"start\":40361},{\"end\":40380,\"start\":40374},{\"end\":40507,\"start\":40503},{\"end\":40524,\"start\":40518},{\"end\":40604,\"start\":40602},{\"end\":40616,\"start\":40610},{\"end\":40626,\"start\":40624},{\"end\":40639,\"start\":40634},{\"end\":40651,\"start\":40646},{\"end\":40791,\"start\":40786},{\"end\":40801,\"start\":40797},{\"end\":40813,\"start\":40807},{\"end\":40824,\"start\":40819},{\"end\":40833,\"start\":40831},{\"end\":40845,\"start\":40841},{\"end\":40857,\"start\":40851},{\"end\":40992,\"start\":40984},{\"end\":41004,\"start\":41001},{\"end\":41153,\"start\":41147},{\"end\":41168,\"start\":41162},{\"end\":41179,\"start\":41176},{\"end\":41226,\"start\":41221},{\"end\":41250,\"start\":41244},{\"end\":41252,\"start\":41251},{\"end\":41394,\"start\":41389},{\"end\":41413,\"start\":41409},{\"end\":41418,\"start\":41414},{\"end\":41428,\"start\":41424},{\"end\":41430,\"start\":41429},{\"end\":41445,\"start\":41438},{\"end\":41447,\"start\":41446},{\"end\":41461,\"start\":41455},{\"end\":41475,\"start\":41467},{\"end\":41615,\"start\":41611},{\"end\":41631,\"start\":41624},{\"end\":41647,\"start\":41644},{\"end\":41661,\"start\":41654},{\"end\":41674,\"start\":41666},{\"end\":41691,\"start\":41685},{\"end\":41706,\"start\":41703},{\"end\":41717,\"start\":41714},{\"end\":41734,\"start\":41727},{\"end\":41916,\"start\":41909},{\"end\":41930,\"start\":41923},{\"end\":41950,\"start\":41942},{\"end\":41964,\"start\":41957},{\"end\":41982,\"start\":41976},{\"end\":41997,\"start\":41990},{\"end\":42122,\"start\":42119},{\"end\":42137,\"start\":42129},{\"end\":42150,\"start\":42144},{\"end\":42167,\"start\":42157},{\"end\":42182,\"start\":42174},{\"end\":42194,\"start\":42189},{\"end\":42208,\"start\":42205},{\"end\":42438,\"start\":42430},{\"end\":42449,\"start\":42446},{\"end\":42471,\"start\":42463},{\"end\":42486,\"start\":42480},{\"end\":42503,\"start\":42495},{\"end\":42518,\"start\":42511},{\"end\":42670,\"start\":42665},{\"end\":42686,\"start\":42681},{\"end\":42689,\"start\":42687},{\"end\":42701,\"start\":42696},{\"end\":42703,\"start\":42702},{\"end\":42870,\"start\":42863},{\"end\":42886,\"start\":42879},{\"end\":42896,\"start\":42891},{\"end\":42905,\"start\":42902},{\"end\":42916,\"start\":42913},{\"end\":43154,\"start\":43146},{\"end\":43167,\"start\":43160},{\"end\":43186,\"start\":43180},{\"end\":43208,\"start\":43202},{\"end\":43327,\"start\":43322},{\"end\":43465,\"start\":43459},{\"end\":43482,\"start\":43476},{\"end\":43500,\"start\":43491},{\"end\":43593,\"start\":43588},{\"end\":43606,\"start\":43600},{\"end\":43617,\"start\":43611},{\"end\":43628,\"start\":43623},{\"end\":43637,\"start\":43634},{\"end\":43878,\"start\":43871},{\"end\":43895,\"start\":43888},{\"end\":43918,\"start\":43908},{\"end\":43935,\"start\":43927},{\"end\":44026,\"start\":44021},{\"end\":44046,\"start\":44039},{\"end\":44060,\"start\":44054},{\"end\":44087,\"start\":44081},{\"end\":44098,\"start\":44093},{\"end\":44264,\"start\":44257},{\"end\":44277,\"start\":44271},{\"end\":44290,\"start\":44285},{\"end\":44300,\"start\":44296},{\"end\":44314,\"start\":44311},{\"end\":44425,\"start\":44413},{\"end\":44440,\"start\":44436},{\"end\":44449,\"start\":44445},{\"end\":44568,\"start\":44566},{\"end\":44581,\"start\":44573},{\"end\":44593,\"start\":44588},{\"end\":44612,\"start\":44605},{\"end\":44626,\"start\":44620},{\"end\":44800,\"start\":44795},{\"end\":44813,\"start\":44807},{\"end\":44827,\"start\":44820},{\"end\":44840,\"start\":44833},{\"end\":44852,\"start\":44846},{\"end\":44861,\"start\":44859},{\"end\":44873,\"start\":44866},{\"end\":44930,\"start\":44928},{\"end\":44942,\"start\":44938},{\"end\":44956,\"start\":44947},{\"end\":44969,\"start\":44963},{\"end\":44983,\"start\":44975},{\"end\":44994,\"start\":44990},{\"end\":45192,\"start\":45187},{\"end\":45207,\"start\":45200},{\"end\":45218,\"start\":45212},{\"end\":45231,\"start\":45223},{\"end\":45242,\"start\":45237},{\"end\":45256,\"start\":45249},{\"end\":45266,\"start\":45261},{\"end\":45281,\"start\":45273},{\"end\":45488,\"start\":45485},{\"end\":45500,\"start\":45496},{\"end\":45516,\"start\":45508},{\"end\":45530,\"start\":45523},{\"end\":45540,\"start\":45535},{\"end\":45553,\"start\":45547},{\"end\":45691,\"start\":45685},{\"end\":45703,\"start\":45699},{\"end\":45715,\"start\":45709},{\"end\":45730,\"start\":45721},{\"end\":45738,\"start\":45735},{\"end\":45749,\"start\":45745},{\"end\":45758,\"start\":45754},{\"end\":45947,\"start\":45941},{\"end\":45961,\"start\":45955},{\"end\":45969,\"start\":45967},{\"end\":45981,\"start\":45979},{\"end\":45993,\"start\":45987},{\"end\":45995,\"start\":45994},{\"end\":46148,\"start\":46140},{\"end\":46157,\"start\":46155},{\"end\":46170,\"start\":46165},{\"end\":46186,\"start\":46177},{\"end\":46203,\"start\":46198},{\"end\":46216,\"start\":46210},{\"end\":46346,\"start\":46343},{\"end\":46357,\"start\":46352},{\"end\":46368,\"start\":46362},{\"end\":46384,\"start\":46376},{\"end\":46392,\"start\":46389},{\"end\":46400,\"start\":46397},{\"end\":46408,\"start\":46405}]", "bib_author_last_name": "[{\"end\":37184,\"start\":37173},{\"end\":37198,\"start\":37194},{\"end\":37203,\"start\":37200},{\"end\":37356,\"start\":37351},{\"end\":37368,\"start\":37364},{\"end\":37384,\"start\":37376},{\"end\":37403,\"start\":37392},{\"end\":37413,\"start\":37405},{\"end\":37533,\"start\":37520},{\"end\":37550,\"start\":37546},{\"end\":37558,\"start\":37552},{\"end\":37710,\"start\":37707},{\"end\":37732,\"start\":37717},{\"end\":37750,\"start\":37742},{\"end\":37765,\"start\":37759},{\"end\":38044,\"start\":38039},{\"end\":38065,\"start\":38052},{\"end\":38086,\"start\":38078},{\"end\":38196,\"start\":38193},{\"end\":38209,\"start\":38205},{\"end\":38219,\"start\":38217},{\"end\":38229,\"start\":38227},{\"end\":38243,\"start\":38231},{\"end\":38504,\"start\":38499},{\"end\":38516,\"start\":38513},{\"end\":38526,\"start\":38522},{\"end\":38658,\"start\":38653},{\"end\":38670,\"start\":38667},{\"end\":38680,\"start\":38676},{\"end\":38847,\"start\":38842},{\"end\":38860,\"start\":38855},{\"end\":38873,\"start\":38870},{\"end\":38888,\"start\":38885},{\"end\":38899,\"start\":38897},{\"end\":39153,\"start\":39148},{\"end\":39166,\"start\":39162},{\"end\":39182,\"start\":39178},{\"end\":39316,\"start\":39313},{\"end\":39328,\"start\":39324},{\"end\":39342,\"start\":39337},{\"end\":39352,\"start\":39350},{\"end\":39363,\"start\":39358},{\"end\":39372,\"start\":39369},{\"end\":39384,\"start\":39381},{\"end\":39660,\"start\":39657},{\"end\":39670,\"start\":39665},{\"end\":39684,\"start\":39682},{\"end\":39697,\"start\":39693},{\"end\":39778,\"start\":39772},{\"end\":39925,\"start\":39918},{\"end\":39940,\"start\":39934},{\"end\":39953,\"start\":39948},{\"end\":39968,\"start\":39961},{\"end\":39983,\"start\":39975},{\"end\":40146,\"start\":40141},{\"end\":40159,\"start\":40154},{\"end\":40174,\"start\":40166},{\"end\":40372,\"start\":40368},{\"end\":40388,\"start\":40381},{\"end\":40516,\"start\":40508},{\"end\":40530,\"start\":40525},{\"end\":40608,\"start\":40605},{\"end\":40622,\"start\":40617},{\"end\":40632,\"start\":40627},{\"end\":40644,\"start\":40640},{\"end\":40662,\"start\":40652},{\"end\":40795,\"start\":40792},{\"end\":40805,\"start\":40802},{\"end\":40817,\"start\":40814},{\"end\":40829,\"start\":40825},{\"end\":40839,\"start\":40834},{\"end\":40849,\"start\":40846},{\"end\":40860,\"start\":40858},{\"end\":40999,\"start\":40993},{\"end\":41009,\"start\":41005},{\"end\":41160,\"start\":41154},{\"end\":41174,\"start\":41169},{\"end\":41242,\"start\":41227},{\"end\":41260,\"start\":41253},{\"end\":41269,\"start\":41262},{\"end\":41407,\"start\":41395},{\"end\":41422,\"start\":41419},{\"end\":41436,\"start\":41431},{\"end\":41453,\"start\":41448},{\"end\":41465,\"start\":41462},{\"end\":41479,\"start\":41476},{\"end\":41622,\"start\":41616},{\"end\":41642,\"start\":41632},{\"end\":41652,\"start\":41648},{\"end\":41664,\"start\":41662},{\"end\":41683,\"start\":41675},{\"end\":41701,\"start\":41692},{\"end\":41712,\"start\":41707},{\"end\":41725,\"start\":41718},{\"end\":41744,\"start\":41735},{\"end\":41921,\"start\":41917},{\"end\":41940,\"start\":41931},{\"end\":41955,\"start\":41951},{\"end\":41974,\"start\":41965},{\"end\":41988,\"start\":41983},{\"end\":42002,\"start\":41998},{\"end\":42127,\"start\":42123},{\"end\":42142,\"start\":42138},{\"end\":42155,\"start\":42151},{\"end\":42172,\"start\":42168},{\"end\":42187,\"start\":42183},{\"end\":42203,\"start\":42195},{\"end\":42212,\"start\":42209},{\"end\":42444,\"start\":42439},{\"end\":42461,\"start\":42450},{\"end\":42478,\"start\":42472},{\"end\":42493,\"start\":42487},{\"end\":42509,\"start\":42504},{\"end\":42528,\"start\":42519},{\"end\":42679,\"start\":42671},{\"end\":42694,\"start\":42690},{\"end\":42712,\"start\":42704},{\"end\":42877,\"start\":42871},{\"end\":42889,\"start\":42887},{\"end\":42900,\"start\":42897},{\"end\":42911,\"start\":42906},{\"end\":42921,\"start\":42917},{\"end\":43158,\"start\":43155},{\"end\":43178,\"start\":43168},{\"end\":43200,\"start\":43187},{\"end\":43216,\"start\":43209},{\"end\":43334,\"start\":43328},{\"end\":43474,\"start\":43466},{\"end\":43489,\"start\":43483},{\"end\":43507,\"start\":43501},{\"end\":43598,\"start\":43594},{\"end\":43609,\"start\":43607},{\"end\":43621,\"start\":43618},{\"end\":43632,\"start\":43629},{\"end\":43643,\"start\":43638},{\"end\":43886,\"start\":43879},{\"end\":43906,\"start\":43896},{\"end\":43925,\"start\":43919},{\"end\":43939,\"start\":43936},{\"end\":44037,\"start\":44027},{\"end\":44052,\"start\":44047},{\"end\":44079,\"start\":44061},{\"end\":44091,\"start\":44088},{\"end\":44105,\"start\":44099},{\"end\":44112,\"start\":44107},{\"end\":44269,\"start\":44265},{\"end\":44283,\"start\":44278},{\"end\":44294,\"start\":44291},{\"end\":44309,\"start\":44301},{\"end\":44317,\"start\":44315},{\"end\":44434,\"start\":44426},{\"end\":44443,\"start\":44441},{\"end\":44454,\"start\":44450},{\"end\":44571,\"start\":44569},{\"end\":44586,\"start\":44582},{\"end\":44603,\"start\":44594},{\"end\":44618,\"start\":44613},{\"end\":44632,\"start\":44627},{\"end\":44805,\"start\":44801},{\"end\":44818,\"start\":44814},{\"end\":44831,\"start\":44828},{\"end\":44844,\"start\":44841},{\"end\":44857,\"start\":44853},{\"end\":44864,\"start\":44862},{\"end\":44878,\"start\":44874},{\"end\":44936,\"start\":44931},{\"end\":44945,\"start\":44943},{\"end\":44961,\"start\":44957},{\"end\":44973,\"start\":44970},{\"end\":44988,\"start\":44984},{\"end\":44998,\"start\":44995},{\"end\":45198,\"start\":45193},{\"end\":45210,\"start\":45208},{\"end\":45221,\"start\":45219},{\"end\":45235,\"start\":45232},{\"end\":45247,\"start\":45243},{\"end\":45259,\"start\":45257},{\"end\":45271,\"start\":45267},{\"end\":45284,\"start\":45282},{\"end\":45494,\"start\":45489},{\"end\":45506,\"start\":45501},{\"end\":45521,\"start\":45517},{\"end\":45533,\"start\":45531},{\"end\":45545,\"start\":45541},{\"end\":45557,\"start\":45554},{\"end\":45697,\"start\":45692},{\"end\":45707,\"start\":45704},{\"end\":45719,\"start\":45716},{\"end\":45733,\"start\":45731},{\"end\":45743,\"start\":45739},{\"end\":45752,\"start\":45750},{\"end\":45761,\"start\":45759},{\"end\":45953,\"start\":45948},{\"end\":45965,\"start\":45962},{\"end\":45977,\"start\":45970},{\"end\":45985,\"start\":45982},{\"end\":46001,\"start\":45996},{\"end\":46005,\"start\":46003},{\"end\":46153,\"start\":46149},{\"end\":46163,\"start\":46158},{\"end\":46175,\"start\":46171},{\"end\":46196,\"start\":46187},{\"end\":46208,\"start\":46204},{\"end\":46224,\"start\":46217},{\"end\":46350,\"start\":46347},{\"end\":46360,\"start\":46358},{\"end\":46374,\"start\":46369},{\"end\":46387,\"start\":46385},{\"end\":46395,\"start\":46393},{\"end\":46403,\"start\":46401},{\"end\":46412,\"start\":46409}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":220042275},\"end\":37305,\"start\":37094},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":49310446},\"end\":37470,\"start\":37307},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":226281747},\"end\":37618,\"start\":37472},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":11336213},\"end\":37958,\"start\":37620},{\"attributes\":{\"doi\":\"App. 16/550\",\"id\":\"b4\"},\"end\":38132,\"start\":37960},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":231592393},\"end\":38408,\"start\":38134},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":226282174},\"end\":38585,\"start\":38410},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":236639274},\"end\":38763,\"start\":38587},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":232233512},\"end\":39054,\"start\":38765},{\"attributes\":{\"doi\":\"arXiv:2112.08733\",\"id\":\"b9\"},\"end\":39218,\"start\":39056},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":249191344},\"end\":39555,\"start\":39220},{\"attributes\":{\"doi\":\"arXiv:2202.08408\",\"id\":\"b11\"},\"end\":39733,\"start\":39557},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":53029967},\"end\":39866,\"start\":39735},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":15458440},\"end\":40058,\"start\":39868},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":197640176},\"end\":40359,\"start\":40060},{\"attributes\":{\"id\":\"b15\"},\"end\":40501,\"start\":40361},{\"attributes\":{\"id\":\"b16\"},\"end\":40600,\"start\":40503},{\"attributes\":{\"doi\":\"arXiv:2108.11873\",\"id\":\"b17\"},\"end\":40742,\"start\":40602},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":232076112},\"end\":40919,\"start\":40744},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":16665585},\"end\":41069,\"start\":40921},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":2243269},\"end\":41219,\"start\":41071},{\"attributes\":{\"doi\":\"arXiv:1710.04110\",\"id\":\"b21\"},\"end\":41343,\"start\":41221},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":13741853},\"end\":41540,\"start\":41345},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":67856459},\"end\":41861,\"start\":41542},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":208139536},\"end\":42059,\"start\":41863},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":221090567},\"end\":42367,\"start\":42061},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":219792342},\"end\":42587,\"start\":42369},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":202784022},\"end\":42771,\"start\":42589},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":210884001},\"end\":43070,\"start\":42773},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":2687749},\"end\":43289,\"start\":43072},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":143093402},\"end\":43365,\"start\":43291},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":218665617},\"end\":43527,\"start\":43367},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":240230915},\"end\":43816,\"start\":43529},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":108296188},\"end\":43999,\"start\":43818},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":52877454},\"end\":44172,\"start\":44001},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":231627759},\"end\":44377,\"start\":44174},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":208527550},\"end\":44510,\"start\":44379},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":211171395},\"end\":44692,\"start\":44512},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":245443647},\"end\":44926,\"start\":44694},{\"attributes\":{\"doi\":\"arXiv:2205.07424\",\"id\":\"b39\"},\"end\":45098,\"start\":44928},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":245218970},\"end\":45399,\"start\":45100},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":256463452},\"end\":45609,\"start\":45401},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":244478648},\"end\":45826,\"start\":45611},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":249375448},\"end\":46062,\"start\":45828},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":247779292},\"end\":46285,\"start\":46064},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":25648541},\"end\":46597,\"start\":46287}]", "bib_title": "[{\"end\":37162,\"start\":37094},{\"end\":37345,\"start\":37307},{\"end\":37510,\"start\":37472},{\"end\":37695,\"start\":37620},{\"end\":38186,\"start\":38134},{\"end\":38491,\"start\":38410},{\"end\":38645,\"start\":38587},{\"end\":38834,\"start\":38765},{\"end\":39308,\"start\":39220},{\"end\":39764,\"start\":39735},{\"end\":39910,\"start\":39868},{\"end\":40132,\"start\":40060},{\"end\":40784,\"start\":40744},{\"end\":40982,\"start\":40921},{\"end\":41145,\"start\":41071},{\"end\":41387,\"start\":41345},{\"end\":41609,\"start\":41542},{\"end\":41907,\"start\":41863},{\"end\":42117,\"start\":42061},{\"end\":42428,\"start\":42369},{\"end\":42663,\"start\":42589},{\"end\":42861,\"start\":42773},{\"end\":43144,\"start\":43072},{\"end\":43320,\"start\":43291},{\"end\":43457,\"start\":43367},{\"end\":43586,\"start\":43529},{\"end\":43869,\"start\":43818},{\"end\":44019,\"start\":44001},{\"end\":44255,\"start\":44174},{\"end\":44411,\"start\":44379},{\"end\":44564,\"start\":44512},{\"end\":44793,\"start\":44694},{\"end\":45185,\"start\":45100},{\"end\":45483,\"start\":45401},{\"end\":45683,\"start\":45611},{\"end\":45939,\"start\":45828},{\"end\":46138,\"start\":46064},{\"end\":46341,\"start\":46287}]", "bib_author": "[{\"end\":37186,\"start\":37164},{\"end\":37200,\"start\":37186},{\"end\":37205,\"start\":37200},{\"end\":37358,\"start\":37347},{\"end\":37370,\"start\":37358},{\"end\":37386,\"start\":37370},{\"end\":37405,\"start\":37386},{\"end\":37415,\"start\":37405},{\"end\":37535,\"start\":37512},{\"end\":37552,\"start\":37535},{\"end\":37560,\"start\":37552},{\"end\":37712,\"start\":37697},{\"end\":37734,\"start\":37712},{\"end\":37752,\"start\":37734},{\"end\":37767,\"start\":37752},{\"end\":38046,\"start\":38032},{\"end\":38067,\"start\":38046},{\"end\":38088,\"start\":38067},{\"end\":38097,\"start\":38088},{\"end\":38198,\"start\":38188},{\"end\":38211,\"start\":38198},{\"end\":38221,\"start\":38211},{\"end\":38231,\"start\":38221},{\"end\":38245,\"start\":38231},{\"end\":38506,\"start\":38493},{\"end\":38518,\"start\":38506},{\"end\":38528,\"start\":38518},{\"end\":38660,\"start\":38647},{\"end\":38672,\"start\":38660},{\"end\":38682,\"start\":38672},{\"end\":38849,\"start\":38836},{\"end\":38862,\"start\":38849},{\"end\":38875,\"start\":38862},{\"end\":38890,\"start\":38875},{\"end\":38901,\"start\":38890},{\"end\":39155,\"start\":39142},{\"end\":39168,\"start\":39155},{\"end\":39184,\"start\":39168},{\"end\":39318,\"start\":39310},{\"end\":39330,\"start\":39318},{\"end\":39344,\"start\":39330},{\"end\":39354,\"start\":39344},{\"end\":39365,\"start\":39354},{\"end\":39374,\"start\":39365},{\"end\":39386,\"start\":39374},{\"end\":39662,\"start\":39652},{\"end\":39672,\"start\":39662},{\"end\":39686,\"start\":39672},{\"end\":39699,\"start\":39686},{\"end\":39780,\"start\":39766},{\"end\":39789,\"start\":39780},{\"end\":39927,\"start\":39912},{\"end\":39942,\"start\":39927},{\"end\":39955,\"start\":39942},{\"end\":39970,\"start\":39955},{\"end\":39985,\"start\":39970},{\"end\":40148,\"start\":40134},{\"end\":40161,\"start\":40148},{\"end\":40176,\"start\":40161},{\"end\":40374,\"start\":40361},{\"end\":40390,\"start\":40374},{\"end\":40518,\"start\":40503},{\"end\":40532,\"start\":40518},{\"end\":40610,\"start\":40602},{\"end\":40624,\"start\":40610},{\"end\":40634,\"start\":40624},{\"end\":40646,\"start\":40634},{\"end\":40664,\"start\":40646},{\"end\":40797,\"start\":40786},{\"end\":40807,\"start\":40797},{\"end\":40819,\"start\":40807},{\"end\":40831,\"start\":40819},{\"end\":40841,\"start\":40831},{\"end\":40851,\"start\":40841},{\"end\":40862,\"start\":40851},{\"end\":41001,\"start\":40984},{\"end\":41011,\"start\":41001},{\"end\":41162,\"start\":41147},{\"end\":41176,\"start\":41162},{\"end\":41182,\"start\":41176},{\"end\":41244,\"start\":41221},{\"end\":41262,\"start\":41244},{\"end\":41271,\"start\":41262},{\"end\":41409,\"start\":41389},{\"end\":41424,\"start\":41409},{\"end\":41438,\"start\":41424},{\"end\":41455,\"start\":41438},{\"end\":41467,\"start\":41455},{\"end\":41481,\"start\":41467},{\"end\":41624,\"start\":41611},{\"end\":41644,\"start\":41624},{\"end\":41654,\"start\":41644},{\"end\":41666,\"start\":41654},{\"end\":41685,\"start\":41666},{\"end\":41703,\"start\":41685},{\"end\":41714,\"start\":41703},{\"end\":41727,\"start\":41714},{\"end\":41746,\"start\":41727},{\"end\":41923,\"start\":41909},{\"end\":41942,\"start\":41923},{\"end\":41957,\"start\":41942},{\"end\":41976,\"start\":41957},{\"end\":41990,\"start\":41976},{\"end\":42004,\"start\":41990},{\"end\":42129,\"start\":42119},{\"end\":42144,\"start\":42129},{\"end\":42157,\"start\":42144},{\"end\":42174,\"start\":42157},{\"end\":42189,\"start\":42174},{\"end\":42205,\"start\":42189},{\"end\":42214,\"start\":42205},{\"end\":42446,\"start\":42430},{\"end\":42463,\"start\":42446},{\"end\":42480,\"start\":42463},{\"end\":42495,\"start\":42480},{\"end\":42511,\"start\":42495},{\"end\":42530,\"start\":42511},{\"end\":42681,\"start\":42665},{\"end\":42696,\"start\":42681},{\"end\":42714,\"start\":42696},{\"end\":42879,\"start\":42863},{\"end\":42891,\"start\":42879},{\"end\":42902,\"start\":42891},{\"end\":42913,\"start\":42902},{\"end\":42923,\"start\":42913},{\"end\":43160,\"start\":43146},{\"end\":43180,\"start\":43160},{\"end\":43202,\"start\":43180},{\"end\":43218,\"start\":43202},{\"end\":43336,\"start\":43322},{\"end\":43476,\"start\":43459},{\"end\":43491,\"start\":43476},{\"end\":43509,\"start\":43491},{\"end\":43600,\"start\":43588},{\"end\":43611,\"start\":43600},{\"end\":43623,\"start\":43611},{\"end\":43634,\"start\":43623},{\"end\":43645,\"start\":43634},{\"end\":43888,\"start\":43871},{\"end\":43908,\"start\":43888},{\"end\":43927,\"start\":43908},{\"end\":43941,\"start\":43927},{\"end\":44039,\"start\":44021},{\"end\":44054,\"start\":44039},{\"end\":44081,\"start\":44054},{\"end\":44093,\"start\":44081},{\"end\":44107,\"start\":44093},{\"end\":44114,\"start\":44107},{\"end\":44271,\"start\":44257},{\"end\":44285,\"start\":44271},{\"end\":44296,\"start\":44285},{\"end\":44311,\"start\":44296},{\"end\":44319,\"start\":44311},{\"end\":44436,\"start\":44413},{\"end\":44445,\"start\":44436},{\"end\":44456,\"start\":44445},{\"end\":44573,\"start\":44566},{\"end\":44588,\"start\":44573},{\"end\":44605,\"start\":44588},{\"end\":44620,\"start\":44605},{\"end\":44634,\"start\":44620},{\"end\":44807,\"start\":44795},{\"end\":44820,\"start\":44807},{\"end\":44833,\"start\":44820},{\"end\":44846,\"start\":44833},{\"end\":44859,\"start\":44846},{\"end\":44866,\"start\":44859},{\"end\":44880,\"start\":44866},{\"end\":44938,\"start\":44928},{\"end\":44947,\"start\":44938},{\"end\":44963,\"start\":44947},{\"end\":44975,\"start\":44963},{\"end\":44990,\"start\":44975},{\"end\":45000,\"start\":44990},{\"end\":45200,\"start\":45187},{\"end\":45212,\"start\":45200},{\"end\":45223,\"start\":45212},{\"end\":45237,\"start\":45223},{\"end\":45249,\"start\":45237},{\"end\":45261,\"start\":45249},{\"end\":45273,\"start\":45261},{\"end\":45286,\"start\":45273},{\"end\":45496,\"start\":45485},{\"end\":45508,\"start\":45496},{\"end\":45523,\"start\":45508},{\"end\":45535,\"start\":45523},{\"end\":45547,\"start\":45535},{\"end\":45559,\"start\":45547},{\"end\":45699,\"start\":45685},{\"end\":45709,\"start\":45699},{\"end\":45721,\"start\":45709},{\"end\":45735,\"start\":45721},{\"end\":45745,\"start\":45735},{\"end\":45754,\"start\":45745},{\"end\":45763,\"start\":45754},{\"end\":45955,\"start\":45941},{\"end\":45967,\"start\":45955},{\"end\":45979,\"start\":45967},{\"end\":45987,\"start\":45979},{\"end\":46003,\"start\":45987},{\"end\":46007,\"start\":46003},{\"end\":46155,\"start\":46140},{\"end\":46165,\"start\":46155},{\"end\":46177,\"start\":46165},{\"end\":46198,\"start\":46177},{\"end\":46210,\"start\":46198},{\"end\":46226,\"start\":46210},{\"end\":46352,\"start\":46343},{\"end\":46362,\"start\":46352},{\"end\":46376,\"start\":46362},{\"end\":46389,\"start\":46376},{\"end\":46397,\"start\":46389},{\"end\":46405,\"start\":46397},{\"end\":46414,\"start\":46405}]", "bib_venue": "[{\"end\":37954,\"start\":37869},{\"end\":38404,\"start\":38333},{\"end\":39050,\"start\":38984},{\"end\":39551,\"start\":39477},{\"end\":40355,\"start\":40274},{\"end\":41855,\"start\":41809},{\"end\":42363,\"start\":42297},{\"end\":43066,\"start\":43003},{\"end\":43812,\"start\":43737},{\"end\":45395,\"start\":45349},{\"end\":46279,\"start\":46261},{\"end\":46593,\"start\":46512},{\"end\":37291,\"start\":37205},{\"end\":37464,\"start\":37415},{\"end\":37612,\"start\":37560},{\"end\":37867,\"start\":37767},{\"end\":38030,\"start\":37960},{\"end\":38331,\"start\":38245},{\"end\":38577,\"start\":38528},{\"end\":38757,\"start\":38682},{\"end\":38982,\"start\":38901},{\"end\":39140,\"start\":39056},{\"end\":39475,\"start\":39386},{\"end\":39650,\"start\":39557},{\"end\":39852,\"start\":39789},{\"end\":40040,\"start\":39985},{\"end\":40272,\"start\":40176},{\"end\":40469,\"start\":40390},{\"end\":40588,\"start\":40532},{\"end\":40722,\"start\":40680},{\"end\":40913,\"start\":40862},{\"end\":41058,\"start\":41011},{\"end\":41210,\"start\":41182},{\"end\":41323,\"start\":41287},{\"end\":41528,\"start\":41481},{\"end\":41807,\"start\":41746},{\"end\":42053,\"start\":42004},{\"end\":42295,\"start\":42214},{\"end\":42581,\"start\":42530},{\"end\":42763,\"start\":42714},{\"end\":43001,\"start\":42923},{\"end\":43275,\"start\":43218},{\"end\":43354,\"start\":43336},{\"end\":43520,\"start\":43509},{\"end\":43735,\"start\":43645},{\"end\":43993,\"start\":43941},{\"end\":44166,\"start\":44114},{\"end\":44371,\"start\":44319},{\"end\":44500,\"start\":44456},{\"end\":44686,\"start\":44634},{\"end\":44916,\"start\":44880},{\"end\":45078,\"start\":45016},{\"end\":45347,\"start\":45286},{\"end\":45603,\"start\":45559},{\"end\":45820,\"start\":45763},{\"end\":46056,\"start\":46007},{\"end\":46259,\"start\":46226},{\"end\":46510,\"start\":46414}]"}}}, "year": 2023, "month": 12, "day": 17}