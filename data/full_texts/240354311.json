{"id": 240354311, "updated": "2023-11-10 23:39:08.164", "metadata": {"title": "Fragment-based Sequential Translation for Molecular Optimization", "authors": "[{\"first\":\"Benson\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Xiang\",\"last\":\"Fu\",\"middle\":[]},{\"first\":\"Regina\",\"last\":\"Barzilay\",\"middle\":[]},{\"first\":\"Tommi\",\"last\":\"Jaakkola\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": 10, "day": 26}, "abstract": "Searching for novel molecular compounds with desired properties is an important problem in drug discovery. Many existing frameworks generate molecules one atom at a time. We instead propose a flexible editing paradigm that generates molecules using learned molecular fragments--meaningful substructures of molecules. To do so, we train a variational autoencoder (VAE) to encode molecular fragments in a coherent latent space, which we then utilize as a vocabulary for editing molecules to explore the complex chemical property space. Equipped with the learned fragment vocabulary, we propose Fragment-based Sequential Translation (FaST), which learns a reinforcement learning (RL) policy to iteratively translate model-discovered molecules into increasingly novel molecules while satisfying desired properties. Empirical evaluation shows that FaST significantly improves over state-of-the-art methods on benchmark single/multi-objective molecular optimization tasks.", "fields_of_study": "[\"Biology\",\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2111-01009", "doi": "10.26434/chemrxiv-2021-fzxmk-v2"}}, "content": {"source": {"pdf_hash": "7175e297bff8e79c5939851c457ff656dd291a73", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.01009v1.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/6165b9358b620dd9ae4d03ce/original/fragment-based-sequential-translation-for-molecular-optimization.pdf", "status": "GREEN"}}, "grobid": {"id": "45e36bee03c6f838ecc36eebda2e9da92e14af87", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/7175e297bff8e79c5939851c457ff656dd291a73.txt", "contents": "\nFragment-based Sequential Translation for Molecular Optimization FRAGMENT-BASED SEQUENTIAL TRANSLATION FOR MOLECULAR OPTIMIZATION\n\n\nBenson Chen bensonc@csail.mit.edu \nCSAIL\nMassachusetts Institute of Technology\n\n\nXiang Fu xiangfu@csail.mit.edu \nCSAIL\nMassachusetts Institute of Technology\n\n\nRegina Barzilay regina@csail.mit.edu \nCSAIL\nMassachusetts Institute of Technology\n\n\nTommi Jaakkola \nCSAIL\nMassachusetts Institute of Technology\n\n\nFragment-based Sequential Translation for Molecular Optimization FRAGMENT-BASED SEQUENTIAL TRANSLATION FOR MOLECULAR OPTIMIZATION\n\nSearching for novel molecular compounds with desired properties is an important problem in drug discovery. Many existing frameworks generate molecules one atom at a time. We instead propose a flexible editing paradigm that generates molecules using learned molecular fragments-meaningful substructures of molecules. To do so, we train a variational autoencoder (VAE) to encode molecular fragments in a coherent latent space, which we then utilize as a vocabulary for editing molecules to explore the complex chemical property space. Equipped with the learned fragment vocabulary, we propose Fragment-based Sequential Tanslation (FaST), which learns a reinforcement learning (RL) policy to iteratively translate model-discovered molecules into increasingly novel molecules while satisfying desired properties. Empirical evaluation shows that FaST significantly improves over state-of-the-art methods on benchmark single/multiobjective molecular optimization tasks.Fragment-based Sequential Translation for Molecular OptimizationCombining the advantage of a distributional fragment vocabulary and the sequential translation scheme, we propose Fragment-based Sequential Tanslation (FaST), which is realized by an RL policy that proposes fragment addition/deletion to a given molecule. Our proposed method unifies molecular optimization and translation and can generate molecules under various objectives such as property constraints, novelty constraints, and diversity constraints. The main contribution of this paper includes:1. We demonstrate a way to learn distributional molecular fragment vocabulary through a VQ-VAE and the effectiveness of the learned vocabulary in molecular optimization. 2. We propose a novel molecular search scheme of sequential translation, which gradually improves the quality and novelty of generation through backtracking and a stored frontier. 3. We implement a novelty/diversity-aware RL policy combining the fragment vocabulary and the sequential translation scheme that significantly outperforms state-of-the-art methods in benchmark single/multi-objective molecular optimization tasks.RELATED WORK\n\nINTRODUCTION\n\nMolecular optimization is a challenging task that is pivotal to drug discovery applications. Part of the challenge stems from the difficulty of exploration in the molecular space: not only are there physical constraints on molecules (molecular strings/graphs have to obey specific chemical principles), molecular property landscapes are also very complex and difficult to characterize: small changes in the molecular space can lead to large deviations in the property space.\n\nRecent fragment-based molecular generative models have shown significant empirical advantages (Jin et al., 2019a;Podda et al., 2020;Xie et al., 2021) over atom-by-atom generative models in molecular optimization. However, they operate over a fixed set of fragments which limits the generative capabilities of the models. Shifting away from previous frameworks, we learn a distribution of molecular fragments using vector-quantized variational autoencoders (VQ-VAE) (van den Oord et al., 2017). Our method builds molecular graphs through the addition and deletion of molecular fragments from the learned distributional fragment vocabulary, enabling the generative model to span a much larger chemical space than models with a fixed fragment vocabulary. Considering atomic edits as primitive actions, the idea of using fragments can be thought of as options (Sutton et al., 1999;Stolle & Precup, 2002) as a temporal abstraction to simplify the search problem.\n\nWe further introduce a novel sequential translation scheme for molecular optimization. We start the molecular search by translating from known active molecules and store the discovered molecules as new potential initialization states for subsequent searches. As a monotonic expansion of molecular graphs may end up producing undesirable, large molecules, we also include the deletion of substructures as a possible action. This enables our method to backtrack to good molecular states and iteratively improve generated molecules during the sequential translation process. Previous works optimize molecules either by generating from scratch or a single translation from known molecules, which is inefficient in finding high-quality molecules and often discovering molecules lacking novelty/diversity. Our proposed framework addresses these deficiencies since our method is (1) very efficient in finding molecules that satisfy property constraints as the model stay close to the high-property-score chemical manifold; and (2) able to produce highly novel molecules because the sequence of fragment-based translation can lead to very different and diverse molecules compared to the known active set.\n\nResolution of molecular optimization. Early works on molecular optimization build on generative models on both SMILES/SELFIES string (G\u00f3mez-Bombarelli et al., 2018;Kang & Cho, 2018;Nigam et al., 2021b), and molecular graphs (Simonovsky & Komodakis, 2018;Ma et al., 2018;De Cao & Kipf, 2018;Samanta et al., 2020;Mercado et al., 2021) and generate molecules character-by-character or node-by-node. Jin et al. (2018) generates graphs as junction trees by considering the vocabulary as the set of atoms or predefined rings from the data; Jin et al. (2020) use the same atom+ring vocabulary to generate molecules by augmenting extracted rationales of molecules. Generating molecules using molecular fragments is a well-established idea in traditional drug design (Erlanson, 2011), but has only been recently explored through deep learning models (Podda et al., 2020;Xie et al., 2021;Kong et al., 2021), outperforming previous atom-level models. However, these models use fixed fragment vocabularies, which are typically small and fixed a priori, limiting the chemical space spanned by the models. In our work, we utilize a learned molecular fragment vocabulary, which is obtained by training a VQ-VAE on a large set of fragments extracted from ChEMBL (Gaulton et al., 2012). By sampling fragments from the learned distribution, our model spans a much larger chemical space than methods using a fixed vocabulary (Figure 3b, Figure 3c).  You et al. (2018) frame the molecular optimization problem as a reinforcement learning problem, but they generate on the atom/character level and from scratch each time, reducing the efficiency of the search algorithm. Jin et al. (2019b) uses a graph-to-graph translation model for property optimization. However, it requires a large number of translation pairs to train, which often involves expert human knowledge and is expensive to obtain. Others have used genetic/evolutionary algorithms to tackle this problem 2021a), which performs random mutations on chemical strings. Although these methods use learned discriminators to prune sub-optimal molecules, the random mutation process can become inefficient in searching for good molecules under complex property constraints. Xie et al. (2021) applies Markov Chain Monte Carlo (MCMC) sampling through editing molecules, while Kong et al. (2021) uses Bayesian optimization on the latent space. On the other hand, we train a novelty/diversity-aware RL policy to search for novel, diverse molecules that retain desired properties. Our method also initializes searches from model-discovered molecules, which greatly improves the efficiency and diversity of the generated molecules. Given the enormous distributional fragment vocabulary that we use in the RL process, search strategies such as random mutation used in genetic algorithms are likely to be very inefficient.\n\n\nPRELIMINARIES\n\nMessage Passing Neural Networks (MPNN) Molecules are represented as directed graphs, where the atoms are the nodes and the bonds are the edges of the graph. More formally, let x = (V, E) denote a directed graph where v i \u2208 V are the atoms, and e ij \u2208 E are the edges of the graph. The network maintains hidden states h t eij for each directed edge, where t is the layer index. At each step, the hidden representations aggregate information from neighboring nodes and edges, and captures a larger neighborhood of atoms. Iteratively, the hidden states are updated as:\nh t+1 e ij = f ([h 0 e ij ; k\u2208N (v i )\\{v j } h t e ki ])(1)\nHere, f is parameterized by RNN cells (e.g. LSTM cells (Hochreiter & Schmidhuber, 1997) or GRU cells (Chung et al., 2014)), and N (v i ) is the set of neighbors of v i . After T steps of messagepassing, the final node embeddings h vi are obtained by summing their respective incoming edge embeddings:\nhv i = ReLU(Wo[h 0 v i ; v k \u2208N (v i ) h T e ki ])(2)\nThe final node embeddings are then summed to get a graph embedding representation h x = vi h vi .\n\nVector-Quantised Variational Autoencoders (VQ-VAE) To learn useful representations of fragments, we employ the VQ-VAE architecture (van den Oord et al., 2017), which maps molecule fragment graphs to a discrete latent space through using categorical distributions for the prior and posterior. The VQ-VAE defines a dictionary of k embedding elements, [s 1 , s 2 , ...s k ] \u2208 R k\u00d7l . Given an input x (here the graph for a molecular fragment), let z e (x) \u2208 R d\u00d7l be the output of the encoder (a MPNN in our case). We define l to be the same dimension for both encoder output embeddings z e (x) and dictionary embeddings s i , because input z q (x) is computed by finding the l 2 nearest neighbor dictionary elements for each row of z e (x):\nzq(x)i = s k , where k = arg min j ||ze(x)i \u2212 sj||2 for i = 1, . . . , d(3)\nThis embedding scheme allows us to represent each molecular fragment using a length d vector, where each entry takes value from {1, . . . , k} that corresponds to the dictionary embedding index for that row. The combinatorial vocabulary defined by the VQ-VAE has the capacity to represent d k distinct molecular fragments, which lifts the constraints of a limited generative span under a fixed fragment vocabulary.\n\nSince the discretization step does not allow for gradient flow, gradients are passed through the network through approximating the gradient from the dictionary embeddings to the encoder embeddings. Additionally, there is a commitment loss that encourages the encoder to output embeddings that are similar to those in the dictionary (hence commitment). The total loss of the VAE is the following:\nL = log p(x|zq(x)) + i ||sg[ze(x)i] \u2212 sij|| 2 2 + \u03b2 i ||ze(x)i \u2212 sg[sij]|| 2 2(4)\nWhere s ij is the closest dictionary element s j for the z e (x) i . Additionally, \u03b2 is a hyperparameter that controls for contribution of the commitment term, and sg represents the stop-gradient operator.\n\n\nMETHODS\n\n\nMolecular Optimization.\n\nStarting with an set of good molecules I (Initial set), the goal of molecular optimization is to generate a set of high-quality molecules C (Constrained set) which satisfy or optimize a set of properties P . High novelty and diversity (detailed in Section 5) are also desired for de novo generation applications. We model the molecular optimization problem as a Markov decision process (MDP), defined by the 5-tuple {S, A, p, r, \u03c1 0 }, where the state space S is the set of all possible molecular graphs. As an overview, our method introduces novel designs over the action space A and the transition model p (Section 4.1) by utilizing a distributional fragment vocabulary, learned by a VQ-VAE. We define the reward and initial state distribution, r and \u03c1 0 (Section 4.2) accordingly to implement the proposed sequential translation generation scheme. An illustration of our model is in Figure 1.\n\n\nLEARNING DISTRIBUTIONAL FRAGMENT VOCABULARY\n\nMolecular Fragments are extracted from molecules in the ChEMBL database (Gaulton et al., 2012). For each molecule, we randomly sample fragments by extracting subgraphs that contain Figure 1: Overview of Fragment-based Sequential Tanslation (FaST). FaST is trained in a two-step fashion. In the first step, we train a VQ-VAE that embeds molecular fragments. In the second step, we train a search policy that uses the learned latent space as an action space. The search policy starts an episode by sampling a molecule from the frontier set F , which consists of an initial set of good molecules (I), and good molecules discovered by the policy (C). The molecule is encoded by an MPNN, which is then used to predict either an Add or Delete action. When the Add action is selected, the model predicts and samples an atom as the attachment point and subsequently predicts a fragment to attach to that atom. When the Delete action is selected, the model samples a directed edge, indicating the molecular fragment to be deleted.\n\nten or fewer atoms that have a single bond attachment to the rest of the molecule. We then use a VQ-VAE to encode these fragments into a meaningful latent space. The use of molecular fragments simplifies the search problem, while the variable-sized fragment distribution maintains the reachability of most molecular compounds. Because our search algorithm ultimately uses the latent representation of the molecules as the action space, we find that using a VQ-VAE with a categorical prior instead of the typical Gaussian prior makes RL training stable and provides good performance gains (Tang & Agrawal, 2020;Grill et al., 2020).\n\nEncoder/Decoder We use MPNN encoders for any graph inputs, which include both fragments for the VQ-VAE, as well as molecular states during policy learning. The graph models are especially suitable for describing actions on the molecular state, as they explicitly parametrize the representations of each atom and bond. Meanwhile, the decoder architecture is a recurrent network that decodes a SELFIES representation of a molecule. We choose a recurrent network for the decoder because we do not need the full complexity of a graph decoder. Due to the construction scheme, the fragments are rooted trees, and all have a single attachment point. As our fragments are small in molecular size (\u2264 10 atoms), the string grammar is simple to learn, and we find the SELFIES decoder works well empirically.\n\nAdding and deleting fragments as actions. At each step of the MDP, the policy network first takes the current molecular graph as input and produces a Bernoulli distribution on whether to add or delete a fragment. Equipped with the fragment VQ-VAE, We define the Add and Delete actions at the fragment-level:\n\n\u2022 Fragment Addition. The addition action is characterized by (1) a probability distribution over the atoms of the molecule:\np add (v i ) = \u03c3[MLP(h v )],\nwhere \u03c3 is the softmax operator.\n\n(2) Conditioned on the graph embedding h x and the attachment point atom v add sampled from p add , we predict a d-channel categorical distribution\np f ragment = \u03c3[MLP([h v add ; h x ])] \u2208 R d\u00d7k ,\nwhere each row of p f ragment sums to 1. We can then sample the discrete categorical latent z add \u2208 {1, ..., k} d from p f ragment . The fragment to add is then obtained by deocoding z add through the learned frozen fragment decoder. We then assemble the decoded fragment with the current molecular graph by attaching the fragment to the predicted attachment point v add . Note that the attachment point over the fragment is indicated through the generated SELFIES string.\n\n\u2022 Fragment Deletion. The deletion action acts over the directed edges of the molecule. A probability distribution over deletable edges is computed with a MLP:\np del (e ij ) = \u03c3[MLP(h eij )].\nOne edge is then sampled and deleted; since the edges are directed, the directionality specify the the molecule to keep and the fragment to be deleted.\n\nWith the action space A defined as above, the transition model for the MDP is simply p(s |s, a) = 1 if applying the addition/deletion action a to the molecule s results in the molecule s , and p(s |s, a) = 0 otherwise. The fragment-based action space is powerful and suitable for policy learning as it (1) is powered by the enormous distributional vocabulary learned by the fragment VQ-VAE, thus spans a diverse set of editing operations over molecular graphs;\n\n(2) exploits the meaningful latent representation of fragments since the representation of similar fragments are grouped together. These advantages greatly simplify the molecular search problem. We terminate an episode when the molecule fails to satisfy the desired property or when the episode exceeds ten steps.\n\n\nDISCOVER NOVEL MOLECULES THROUGH SEQUENTIAL TRANSLATION\n\nWe propose sequential translation that incrementally grows the set of discovered novel molecules and use the model-discovered molecules as starting points for further search episodes. This regime of starting exploration from states reached in previous episodes was also explored under the setting of RL from image inputs (Ecoffet et al., 2021). More concretely, we implement sequential translation with a reinforcement learning policy that operates under the fragment-based action space defined in Section 4.1, while using a moving initial state distribution \u03c1 0 , which is a distribution over molecules in the frontier set F = I \u222a C. By starting new search episodes from the frontier set -the union of the initial set and good molecules that are discovered by the RL policy, we achieve efficient search in the chemical space by staying close to the high-quality subspace and achieve novel molecule generation through a sequence of fragment-based editing operations to the known molecules. Our proposed search algorithm is detailed in Algorithm 1.\n\nAlgorithm 1 Molecular Optimization through Fragment-based Sequential Tanslation (FaST) 1: Input N the desired number of discovered new molecules 2: Input I the initial set of molecules 3: Input D the pretrained fragment decoder of VQ-VAE 4: Input CP : S \u2192 {0, 1} returns 1 if the input x satisfies desired properties Equation (5) 5: Input CND : S \u2192 {0, 1} returns 1 if the input x satisfies novelty/diversity criterion Equation (6) 6: Let C = \u2205 be the discovered set of molecules 7: Let F = I \u222a C be the frontier where search is initialized from 8: Let t = 0 be the number of episodes 9: while |C| \u2264 N do 10:\n\nLet t = t + 1 11:\n\nUpdate U CB(x0, t)\u2200x0 \u2208 F according to Equation (8)  12:\nSample initial molecule x = (V, E) from pinit = \u03c3[U CB(x0, t)]\u2200x0 \u2208 F 13: Let step = 0 14: while CP (x) = 1 & step < T do T = 10 in our experiments 15:\nEncode x with MPNN(x) to get node representation hv, \u2200v \u2208 V and graph representation hx 16:\n\nSample action type a \u2208 {ADD, DELETE} from paction = \u03c3[MLP(hx)] 17:\n\nif a = ADD then 18:\n\nSample\nv add from p add (v) = \u03c3[MLP(hv)] \u2200v \u2208 V 19:\nSample fragment encoding z add from p f ragment = MLP([hx; hv add ]) Section 4.1 20:\n\nDecode fragment y = D(z add ) 21:\n\nAdd fragment y to molecule:\n\nx \u2190 x + y 22: else 23:\n\nSample e from p del (e) = \u03c3[MLP(he ij )] \u2200e \u2208 E Section 4.1 24:\n\nLet y be the fragment designated by e, delete fragment x \u2190 x \u2212 y 25:\n\nif CP (x) = 1 & CND(x) = 1 then 26:\n\nC \u2190 C \u222a {x} 27:\n\nF \u2190 I \u222a C 28:\n\nLet step \u2190 step + 1\n\nDiscover novel molecules and expand the frontier. Our method explores the chemical space with a property-aware and novelty/diversity-aware reinforcement learning policy that proposes addition/deletion modifications to the molecular state at every environment step to optimize for the reward r. We gradually expand the discovered set C by adding qualified molecules found in the RL exploration within the MDP. A molecule x is qualified if: (1) x satisfies the desired properties measured by property scores\nCP (x) = p\u2208P 1{scorep(x) > thresholdp}(5)\nwhere P is the set of desired properties and threshold p is the score threshold for satisfying property p. A molecule x satisfying all desired properties has C P (x) = 1 and C P (x) = 0 otherwise.\n\n(2) x is novel/diverse compared to molecules currently in the frontier F , measured by fingerprint similarity (detailed in Section 5):\nCND(x) = 1{max i\u2208I sim(x, i) < thresholdnov} \u00b7 1{mean g\u2208G (sim(x, g) < threshold div )}(6)\nWhere sim denotes fingerprint similarity, threshold nov and threshold div are predefined similarity thresholds for novelty and diversity, I and C are the initial set of good molecules and model discovered molecules as defined in previous sections. A molecule that satisfies novelty/diversity criterion has C N D (x) = 1 and C N D (x) = 0 otherwise.\n\nWe use a reward of +1 for a transition that results in a molecule qualified for the set C, and discourage the model from producing invalid molecules by adding a reward of \u22120.1 for a transition that produces an invalid molecular graph 1 :\nr(x, a) = CP ([x \u2190 a]) \u00b7 CND([x \u2190 a]) \u2212 0.1 \u00b7 1([x \u2190 a] invalid)(7)\nwhere [x \u2190 a] denotes the molecule resulting from editing x with the fragment addition/deletion action a.\n\nInitialize search episodes from promising candidates. To bias the initial state distribution \u03c1 0 to favor molecules that can derive more novel high-quality molecules, we keep an upper-confidencebound (UCB) score for each initial molecule in the frontier F . We record the number of times we initiate a search N (x, t) from a molecule x \u2208 F , and the number of molecules qualified for adding to C that is found in an episode strating from x: R(x, t). Here t = x\u2208\u03c10 N (x) is the total number of search episodes. The UCB score of the initial molecule m is calculated by:\nU CB(x, t) = R(x, t) N (x, t) + 3 2 log(t + 1) N (x, t)(8)\nThe probability of a molecule in the initialization set being sampled as the starting point of a new episode is then computed by a softmax over the UCB scores: p init (x, t + 1) = exp(U CB(x,t)) x\u2208I exp(U CB(x,t)) . To summarize, FaST learns a policy that (1) choose good initial molecules to start search episodes;\n\n(2) choose to add a fragment to or delete a subgraph from a given state (a molecule in our case);\n\n(3) choose what to add through predicting a fragment latent embedding, or what to delete through predicting a directed edge, and remove part of the molecular graph accordingly.\n\nAlthough we present our method in this section under the most realistic multi-objective optimization task settings (with experiments in Section 5), our method is easily extendable to other problem settings by modifying the definition of the constraints C P , C N D , and the reward function r accordingly. For example, see Appendix B for the application of our method to the standard constrained penalized log P task and Section 5 for multi-objective molecular optimization under different novelty/diversity metrics.\n\n\nEXPERIMENTS\n\nDatasets. We use benchmark datasets for molecular optimization, which aims to generate ligand molecules for inhibition of two proteins: glycogen synthase kinase-3 beta (GSK3\u03b2) and c-Jun Nterminal kinase 3 (JNK3). The dataset, originally extracted from ExCAPE-DB (Sun et al., 2017), contains 2665 and 740 actives for GSK3\u03b2 and JNK3 respecitvely. Each target also contains 50,000 negative ligand molecules. Following previous work (Jin et al., 2020;Xie et al., 2021;Nigam et al., 2021a), we adopt the same strategy of using a random forest trained on these datasets as the oracle property predictor.\n\nIn addition to the binding properties of the generated molecules, we also look at two additional factors, quantitative estimate of drug-likeliness (QED) (Bickerton et al., 2012) and synthetic accessibility (SA) (Ertl & Schuffenhauer, 2009). QED is a quantitative score that asses the quality of a molecule through comparisons of its physicochemical properties to approved drugs. SA is a score that accounts for the complexity of the molecule in the context of easiness of synthesis, thereby providing an auxillary metric for the feasibility of the compound as a drug candidate. Single property optimization is often a flawed task, because the generator can overfit to the pretrained predictor and generate unsynthesizable compounds. While we report our results on both single-property and multi-property optimization tasks, we focus our analysis on the hardest multi-objective optimization task: GSK3\u03b2+JNK3+QED+SA.\n\nEvaluation metrics. Following previous works, we evaluate our generative model on three target metrics, success, novelty and diversity. 5,000 molecules are generated by the model, and the metric scores are computed as follows: Success rate (SR) measures the proportion of generated molecules that fit the desired properties. For inhibition of GSK3\u03b2 and JNK3, this is a score of at least 0.5 from the pretrained predictor. QED has a target score of \u2265 .6 and SA has a target score of \u2264 4. Novelty (Nov) measures how different the generated molecules are compared to the set of actives in the dataset, and is the proportion of molecules whose Morgan fingerprint Tanimoto similarity is at most 0.4 to any molecule in the active set (range [0, 1]). Diversity (Div) measures how different the generated molecules are compared to each other, computed as an average of pairwise Morgan fingerprint Tanimoto similarity across all generated compounds (range [0, 1]). PM is the product of the three metrics above (PM = SR \u00b7 Nov \u00b7 Div). Implementation details. We construct the initial set of molecules for our search algorithm from the rationales extracted from Jin et al. (2020). These rationales are obtained through a sampling process, Monte Carlo Tree Search (MCTS), on the active molecules that tries to minimize the size of the rationale subgraph, while maintaining their inhibitory properties. Rationales for multi-property tasks (GSK3\u03b2+JNK3) are extracted by combining the rationales for single-property tasks. Initializing generation with subgraphs is commonly done in molecular generative models such as Shi et al. (2020) and Kong et al. (2021). We train the RL policy using the Proximal Policy Optimization (PPO, Schulman et al. 2017) algorithm. We find the RL training robust despite both the reward function r and the initial state distribution \u03c1 0 are non-stationary (i.e., changing during RL training). Randomly sampled translation trajectories are shown in Figure 2. The hyperparameters used for producing the results in Section 5 are included in Appendix D.\n\nBaseline methods. Rationale-RL (Jin et al., 2020) extracts rationales of the active molecules and then uses RL to train a completion model that add atoms to the rationale in a sequential manner to generate molecules satisfying the desired properties. GA+D & JANUS 2021a) are two genetic algorithms that use random mutations of SELFIES strings to generate promising molecular candidates; JANUS leverages a two-pronged approach, accounting for mutations towards both exploration and exploitation. MARS (Xie et al., 2021) uses Markov Chain Monte Carlo (MCMC) sampling to iterative build new molecules by adding or removing fragments, and the model is trained to fit the distribution of the active molecules. To provide a fair comparison against baselines that do not use rationales, we additionally include a baseline MARS+Rationale that initialize the MARS algorithm with the same starting initial rationale set used in Rationale-RL and our method. where possible, we use the numbers from the original corresponding paper.\n\nPerformance. The evaluation metrics are shown in Table 1; FaST significantly outperforms all baselines on all tasks including both single-property and multi-property optimization. On the most challenging task, GSK3\u03b2+JNK3+QED+SA, FaST improves upon the previous best model by over 30% in the product of the three evaluation metrics. Our model is able to efficiently search for molecules that stay within the constrained property space, and discover novel and diverse molecules by sequentially translating known and discovered active molecules. The MARS+Rationale model, which uses the same rationale molecules as the initialization for their search algorithm, does not perform well compared to the original implementation, which initializes each search with a simple \"C-C\" molecule. Search efficiency. While being the best-performing model, FaST is also more efficient in terms of both the number of molecules searched over through the optimization process and running time. For the GSK3\u03b2+JNK3+QED+SA results reported in Table 1, FaST on average searched through 71k molecules in total to gather the 5k proposal set. As a comparison, the strongest baseline method MARS searched through 600k molecules to obtain its corresponding 5k proposal set (\u223c 9\u00d7 our numbers). Our implementation is also very efficient in terms of wall-clock time -on average taking 1 hour to finish searching for the 5k proposal set in all reported tasks, on a machine with a single NVIDIA RTX 2080-Ti GPU. On the other hand, the best baseline method, MARS, takes 6 hours to complete the search.\n\nOptimize for different novelty/diversity metrics. The Morgan fingerprints used for similarity comparison contain certain inductive biases. Under different applications, different novelty/diversity metrics may be of interest. To demonstrate the viability of our model under any metrics, we train FaST using Atom Pairs fingerprints (Carhart et al., 1985) on the GSK3\u03b2+JNK3+QED+SA task. The results, and discussion of the different fingerprint methods, are reported in Appendix C. We find that FaST can still find high-quality molecules that are novel and diverse, while the baseline methods do not. This is unsurprising because the baseline models are not novelty/diversity-aware during training, and they may suffer more when the novelty/diversity constraints are harder to satisfy.\n\nPerformance on Penalized logP. To demonstrate that our method is generally applicable to any molecular optimization task, we also include our results on the standard constrained penalized logP optimization task in Appendix B. We show that our model significantly outperforms all baselines in this task under different constraint levels. We also provide insight on the task itself: while this task has been studied in many previous works, the task, as it is currently defined, is not entirely chemically meaningful. Additionally, one drawback of this task is that a model can achieve high performance by simply generating large molecules. A detailed discussion can be found in Appendix B.\n\n\nABLATION AND ANALYSIS\n\nDiversity of generation. In addition to the fingerprint diversity metrics presented in Section 5, another way to judge molecular diversity is to look at functional group diversity. We extract all FaST MARS (c) Figure 3: (a) compares the number of steps needed to reach 5,000 molecules for the GSK3\u03b2+JNK3+QED+SA task for different ablation models. Using the VQ-VAE greatly improves the efficiency of the model (71k vs 122k steps). (b, c) plots the t-SNE embedding of fragments from generated compounds of our model vs. Rational-RL and MARS. The visualization shows that that our model produces a much more diverse set of fragments, which is a proxy for functional groups appearing in generated molecules.\n\nunique molecular fragments of the 5,000 molecules generated for GSK3\u03b2+JNK3+QED+SA task for both FaST and MARS, and produce t-SNE visualization of these fragments in Figure 3b and Figure 3c. In total, we extracted 1.7k unique fragments from our model outputs vs only 1.1k unique fragments for Rational-RL and 500 unique fragments from MARS. The visualization shows that the fragments in the molecules generated by our model spans a much larger chemical space. This confirms the advantages of using a learned vocabulary, compared to using a fixed set of fragments, as we are able to utilize a much more diverse set of chemical subgraphs.\n\nBenefit of distributional vocabulary. To investigate the benefit of using a distributional vocabulary, instead of using the pretrained VQ-VAE, we also train our model using a fixed vocabulary of fragments, which consists of 56k unique fragments (the same set used to pretrain the VQ-VAE). Figure 3a compares the performance of the two models. On average, the model with fixed fragments took 122k steps, while the VQ-VAE only took 71k steps to find a set of 5,000 good molecules (72% improvement). We further analyze the benefit of using discrete latents with a VQ-VAE rather than continuous latents with a Gaussian prior VAE in Appendix A.\n\n\nCONCLUSION\n\nWe propose a new framework for molecular optimization, which leverages a learned vocabulary of molecular fragments to search the chemical space efficiently. We demonstrate that Fragment-based Sequential Tanslation (FaST), which adaptively grows a set of promising molecular candidates, can generate high-quality, novel, and diverse molecules on single-property and multi-property optimization tasks. Ablation study shows that all components of our proposed method contribute to its superior performance. It is straightforward to adopt FaST to other molecular optimization tasks by modifying the fragment distribution and desired properties. Incorporating FaST to more practical drug discovery pipelines while taking synthesis paths in mind is an exciting avenue for future work. \n\n\nA VOCABULARY LEARNING THROUGH VQ-VAE\n\nTo evaluate the benefits of VQ-VAE over a typical VAE trained with Gaussian priors, we train both models, and look at the distribution of fragments. Figure 4a compares the t-SNE distributions of the two models, where we sample 2,000 fragments from each model. The VAE model has tight clusters, while the VQ-VAE model exhibits a much more diverse set of fragments. We visualize random samples from VAE and VQ-VAE Figure 4, where we see that the samples from VAE are relatively simple and generic fragments, while samples from the VQ-VAE demonstrate diverse patterns. This is because the more generic fragments appear more frequently in real molecules, and a Gaussian prior over the fragment latent space would favor these fragments.\n\n\nB CONSTRAINED PENALIZED LOGP TASK\n\nTo demonstrate the general applicability of our model for any molecular optimization task, we also run our model on another constrained optimization task, here optimizing for penalized octanol-water partition coefficients (logP) scores of ZINC (Irwin et al., 2012) molecules. The penalized logP score is the logP score penalized by synthetic accessibility and ring size. We use the exact computation in You et al. (2018), where the components of the penalized logP score are normalized across the entire 250k ZINC training set. The generated molecules are constrained to have similar Morgan fingerprints (Rogers & Hahn, 2010) as the original molecules.\n\nFollowing the same setup as previous work (Jin et al., 2019b;You et al., 2018;Shi et al., 2020;Kong et al., 2021), we try to optimize the 800 test molecules from ZINC with the lowest penalized logP scores (the initial set I). Specifically, the task is to translate these molecules into new molecules with the Tanimoto similarity of the fingerprints constrained within \u03b4 \u2208 {.4, .6}. This task aims for optimizing a certain quantity (instead of satisfying property constraints) and is a translation task (need to stay close to original molecules rather than finding novel ones). To run FaST on this task, we apply the following changes to the reward function, the qualification criterion, and the episode termination criterion, of FaST. We denote score(x) to be the penalized logP scoring function, and sim(\u00b7, \u00b7) to be the Tanimoto similarity between two molecules:\n\n\u2022 reward r = score(x j ) \u2212 score(x i ) for any transition from molecule x i \u2192 x j \u2022 C, the discovered set contains all explored molecules that satisfy Equation (5), where the threshold is given by the input parameter \u03b4 \u2022 We terminate an episode when the number of steps exceeds 10.\n\nFor each molecule we add to G, we keep track of its original parent (the molecule from the 800 test molecules). After training, for each of the 800 test molecules, we take the set of translated molecules in G, and select the one with the highest property score. Method \u03b4 = 0.4 \u03b4 = 0.6 Improvement Success Improvement Success JT-VAE (Jin et al., 2018) 0.84 \u00b1 1.45 83.6 % 0.21 \u00b1 0.71 46.4 % GCPN (You et al., 2018) 2.49 \u00b1 1.30 100.0 % 0.79 \u00b1 0.63 100.0 % DEFactor (Assouel et al., 2018) 3.41 \u00b1 1.67 85.9 % 1.55 \u00b1 1.19 72.6 % GraphAF (Shi et al., 2020) 3.74 \u00b1 1.25 100 % 1.95 \u00b1 0.99 100 % GP-VAE (Kong et al., 2021) 4.19 \u00b1 1.30 98.9 % 2.25 \u00b1 1.12 90.3 % VJTNN (Jin et al., 2019b) 3.55 \u00b1 1.67 -2.33 \u00b1 1.17 -GA+D  5.93 \u00b1 1.14 100 % 3.44 \u00b1 1.09 99.8 % FaST (Ours) 18.09 \u00b1 8.72 100 % 8.98 \u00b1 6.31 96.9 % Figure 5: Sample translation of our model for the constrained penalized logP task (\u03b4 = 0.6).\n\nThe model generates a molecule with repeating aromatic rings; though not realistic, this molecule achieves a high score, while having close Tanimoto similarity using Morgan fingerprints.\n\nResults are shown in Table 2; our method greatly outperforms the other baselines, but we point out a few flaws intrinsic to the task. Because the similarity is computed through Morgan fingerprint, which are hashes of substructures, repeatedly adding aromatic rings can often not change the fingerprint by a lot. Nevertheless, adding aromatic rings will linearly increase penalized logP score, which allows trivial solutions to produce high scores for this task (see Figure 5). This phenomenon is noted by , but they add a regularizer to constrain the generated compounds to look similar to the reference molecules. Due to the mentioned issues, we believe this task can be reformulated. For instance, one could use a different fingerprint method so that the fingerprint similarity is not so easily exploited (see AP (Carhart et al., 1985), MACCS (Durant et al., 2002), or ROCS (Hawkins et al., 2010), or size constraints should be incorporated. Nevertheless, we provide our results for comparison to other molecular generation methods.\n\nIn general, the task of optimizing (increasing) the penalized logP scores is not entirely meaningful. According to Lipinski's rule of five (Lipinski et al., 1997), which are widely established rules to evaluate the druglikeness of molecules, the logP score should be lower than 5. So an unbounded optimization of logP has little practical usability. Perhaps a better task would be to optimize for all 5 rules in Linpinski's rule of five which includes constraints involving the number of hydrogen bond donors/acceptors and molecular mass.\n\n\nC DIFFERENT NOVELTY/DIVERSITY METRICS\n\nFaST is capable of optimizing for different novelty/diversity metrics. In this section, we compute the novelty/diversity metrics using atom-pair (AP) fingerprints (Carhart et al., 1985). While Morgan fingerprints have successfully been applied to many molecular tasks such as drug screening, it has some failure modes (Capecchi et al., 2020). Namely, Morgan fingerprints is often not informative about the size or the shape of the molecules. These properties are better captured in AP fingerprints, as AP fingerprints account for all atom pairs, including their pairwise distances. We run the same experiment on the GSK3\u03b2+JNK3+QED+SA task described in Section 5, but change the fingerprint from Morgan to AP for the novelty/diversity metrics. The results are shown in Table 3 with comparison to baselines. We observe that our method outperform baselines by a greater margin, especially in the novelty metric. This is not surprising because our model can explicitly optimize for any similarity metric, while the baseline methods are not novelty/diversity-aware during training. Interestingly, we find that optimizing for AP fingerprints also yields molecules that score high under Morgan fingerprints for this task (but the converse is not true).   We provide more example molecular optimization trajectories of our model on the GSK3\u03b2+JNK3+QED+SA task in Figure 6. \n\n\nSequential generation of molecules. Guimaraes et al. (2017); Olivecrona et al. (2017);\n\nFigure 2 :\n2A randomly sampled FaST optimization trajectory for the GSK3\u03b2+JNK3+QED+SA task. At each step, either an add or delete action is chosen. Red indicates the atoms and bonds that are eligible for addition/deletion, while green indicates the selected atom or bond. More trajectories are included in Appendix E.\n\nFigure 4 :\n4(a) t-SNE of fragments sampled from a trained VAE and VQ-VAE. The fragments sampled from the VAE are tightly clustered, showing much less diversity compared to the fragments sampled from the VQ-VAE. (b,c) Random samples from the VAE (b) and the VQ-VAE (c). \"A\" denotes the attachment point for the fragment. We see that the samples from the VAE are relatively simple. Meanwhile, the samples from the VQ-VAE are more diverse.\n\nFigure 6 :\n6Samples of FaST on the GSK3\u03b2+JNK3+QED+SA task. Red indicates the atoms and bonds that are eligible for addition/deletion, while green indicates the selected atom or bond.\n\nTable 1 :\n1FaST outperforms all baselines on both single-property and multi-property optimization. Error bars indicates one standard deviation, obtained from averaging 5 random seeds.Model \nGSK3\u03b2 \nGSK3\u03b2+QED+SA \nSR \nNov Div PM \nSR \nNov Div PM \nRationale-RL \n1.00 .534 .888 .474 \n.699 .402 .893 .251 \nGA+D \n.846 1.00 .714 .600 \n.891 1.00 .628 .608 \nJANUS \n1.00 .829 .884 .732 \n-\n-\n-\n-\nMARS \n1.00 .840 .718 .600 (\u00b1 .04) \n.995 .950 .719 .680 (\u00b1 .03) \nMARS+Rationale .995 .804 .746 .597 (\u00b1 .07) \n.981 .800 .807 .632 (\u00b1 .07) \nFaST \n1.00 1.00 .905 .905 (\u00b1 .000) 1.00 1.00 .861 .861 (\u00b1 .001) \n\nModel \nJNK3 \nJNK3+QED+SA \nSR \nNov Div PM \nSR \nNov Div PM \nRationale-RL \n1.00 .462 .862 .400 \n.623 .376 .865 .203 \nGA+D \n.528 .983 .726 .380 \n.857 .998 .504 .431 \nJANUS \n1.00 .426 .895 .381 \n-\n-\n-\n-\nMARS \n.988 .889 .748 .660 (\u00b1 .04) \n.913 .948 .779 .674 (\u00b1 .02) \nMARS+Rationale .976 .843 .780 .642 (\u00b1 .04) \n.634 .779 .787 .386 (\u00b1 .08) \nFaST \n1.00 1.00 .905 .905 (\u00b1 .001) 1.00 .866 .856 .741 (\u00b1 .001) \n\nModel \nGSK3\u03b2+JNK3 \nGSK3\u03b2+JNK3+QED+SA \nSR \nNov Div PM \nSR \nNov Div PM \nRationale-RL \n1.00 .973 .824 .800 \n.750 .555 .706 .294 \nGA+D \n.847 1.00 .424 .360 \n.857 1.00 .363 .311 \nJANUS \n1.00 .778 .875 .681 \n1.00 .326 .821 .268 \nMARS \n.995 .753 .691 .520 (\u00b1 .08) \n.923 .824 .719 .547 (\u00b1 .05) \nMARS+Rationale .976 .843 .780 .642 (\u00b1 .04) \n.654 .687 .724 .321 (\u00b1 .09) \nFaST \n1.00 1.00 .863 .863 (\u00b1 .001) 1.00 1.00 .716 .716 (\u00b1 .011) \n\n\n\nTable 2 :\n2Results on the constrained penalized logP task. FaST significantly outperform all baselines.\n\nTable 3 :\n3Results on the GSK3\u03b2+JNK3+QED+SA task using AP fingerprints instead of Morgan fingerprints for novelty/diversity computation.Method \nSuccess (SR) Novelty (Nov) Diversity (Div) Product (PM) \nRationale-RL \n.750 \n.023 \n.630 \n.011 \nMARS \n.733 \n.077 \n.644 \n.036 \nFaST (Ours) \n1.00 \n.867 \n.719 \n.623 \n\nD IMPLEMENTATION DETAILS \n\n\n\nTable 4 :\n4Hyperparameters for the VQ-VAE.VQ-VAE Param \nValue \nhidden size \n200 \nMPNN depth \n4 \nMPNN output size (d) \n10 \n# Dictionary elements (k) \n10 \nDictionary latent size (l) \n10 \nbatch size \n32 \ndictionary loss coef \n1.0 \ncommitment loss coef \n1.0 \nlearning rate \n1e-4 \n# epochs \n10 \n\n\n\nTable 5 :\n5Hyperparameters for training the RL Agent. E MORE SAMPLE TRAJECTORIES FROM FASTParam Name \nValue \n\nAgent \n\nlearning rate \n2e-4 \n\u03b3 \n0.999 \n\u03bb GAE \n0.95 \nbatch size \n64 \nPPO Epoch \n3 \nparam clip \n0.2 \nvalue loss coef \n0.5 \nentropy loss coef 0.01 \n1e-5 \nmax grad norm \n0.5 \n\nActor \nhidden size \n1024 \nhidden depth \n1 \n\nCritic \nhidden size \n256 \nhidden depth \n1 \n\n\nvalidity is checked by the chemistry software RDKit.\n\nDefactor: Differentiable edge factorization-based probabilistic graph generation. Rim Assouel, Mohamed Ahmed, H Marwin, Amir Segler, Yoshua Saffari, Bengio, arXiv:1811.0976614arXiv preprintRim Assouel, Mohamed Ahmed, Marwin H Segler, Amir Saffari, and Yoshua Bengio. De- factor: Differentiable edge factorization-based probabilistic graph generation. arXiv preprint arXiv:1811.09766, 2018. 14\n\nQuantifying the chemical beauty of drugs. G Richard Bickerton, V Gaia, J\u00e9r\u00e9my Paolini, Sorel Besnard, Andrew L Muresan, Hopkins, Nature chemistry. 42G Richard Bickerton, Gaia V Paolini, J\u00e9r\u00e9my Besnard, Sorel Muresan, and Andrew L Hopkins. Quantifying the chemical beauty of drugs. Nature chemistry, 4(2):90-98, 2012. 7\n\nOne molecular fingerprint to rule them all: drugs, biomolecules, and the metabolome. Alice Capecchi, Daniel Probst, Jean-Louis Reymond, 2020. 14Journal of cheminformatics. 121Alice Capecchi, Daniel Probst, and Jean-Louis Reymond. One molecular fingerprint to rule them all: drugs, biomolecules, and the metabolome. Journal of cheminformatics, 12(1):1-15, 2020. 14\n\nAtom pairs as molecular features in structure-activity studies: definition and applications. E Raymond, Carhart, H Dennis, R Smith, Venkataraghavan, Journal of Chemical Information and Computer Sciences. 25214Raymond E Carhart, Dennis H Smith, and R Venkataraghavan. Atom pairs as molecular features in structure-activity studies: definition and applications. Journal of Chemical Information and Computer Sciences, 25(2):64-73, 1985. 8, 14\n\nEmpirical evaluation of gated recurrent neural networks on sequence modeling. Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, Yoshua Bengio, arXiv:1412.3555arXiv preprintJunyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555, 2014. 3\n\nMolgan: An implicit generative model for small molecular graphs. Nicola De, Cao , Thomas Kipf, arXiv:1805.11973arXiv preprintNicola De Cao and Thomas Kipf. Molgan: An implicit generative model for small molecular graphs. arXiv preprint arXiv:1805.11973, 2018. 2\n\nReoptimization of mdl keys for use in drug discovery. L Joseph, Durant, A Burton, Leland, R Douglas, James G Henry, Nourse, Journal of chemical information and computer sciences. 42614Joseph L Durant, Burton A Leland, Douglas R Henry, and James G Nourse. Reoptimization of mdl keys for use in drug discovery. Journal of chemical information and computer sciences, 42(6): 1273-1280, 2002. 14\n\nFirst return, then explore. Adrien Ecoffet, Joost Huizinga, Joel Lehman, O Kenneth, Jeff Stanley, Clune, Nature. 5907847Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O Stanley, and Jeff Clune. First return, then explore. Nature, 590(7847):580-586, 2021. 5\n\nIntroduction to fragment-based drug discovery. Fragment-based drug discovery and X-ray crystallography. Daniel A Erlanson, Daniel A Erlanson. Introduction to fragment-based drug discovery. Fragment-based drug discovery and X-ray crystallography, pp. 1-32, 2011. 2\n\nEstimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions. Peter Ertl, Ansgar Schuffenhauer, Journal of cheminformatics. 11Peter Ertl and Ansgar Schuffenhauer. Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions. Journal of cheminfor- matics, 1(1):1-11, 2009. 7\n\nChembl: a large-scale bioactivity database for drug discovery. Anna Gaulton, J Louisa, Patricia Bellis, Jon Bento, Mark Chambers, Anne Davies, Yvonne Hersey, Shaun Light, David Mcglinchey, Bissan Michalovich, Al-Lazikani, Nucleic acids research. 40D13Anna Gaulton, Louisa J Bellis, A Patricia Bento, Jon Chambers, Mark Davies, Anne Hersey, Yvonne Light, Shaun McGlinchey, David Michalovich, Bissan Al-Lazikani, et al. Chembl: a large-scale bioactivity database for drug discovery. Nucleic acids research, 40(D1):D1100-D1107, 2012. 2, 3\n\nAutomatic chemical design using a data-driven continuous representation of molecules. Rafael G\u00f3mez-Bombarelli, Jennifer N Wei, David Duvenaud, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Benjam\u00edn S\u00e1nchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, P Ryan, Al\u00e1n Adams, Aspuru-Guzik, ACS central science. 42Rafael G\u00f3mez-Bombarelli, Jennifer N Wei, David Duvenaud, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Benjam\u00edn S\u00e1nchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, and Al\u00e1n Aspuru-Guzik. Automatic chemical design using a data-driven contin- uous representation of molecules. ACS central science, 4(2):268-276, 2018. 2\n\nMonte-carlo tree search as regularized policy optimization. Florent Jean-Bastien Grill, Yunhao Altch\u00e9, Thomas Tang, Michal Hubert, Valko, PMLR, 2020. 4International Conference on Machine Learning. Ioannis Antonoglou, and R\u00e9mi MunosJean-Bastien Grill, Florent Altch\u00e9, Yunhao Tang, Thomas Hubert, Michal Valko, Ioannis Antonoglou, and R\u00e9mi Munos. Monte-carlo tree search as regularized policy optimization. In International Conference on Machine Learning, pp. 3769-3778. PMLR, 2020. 4\n\nObjective-reinforced generative adversarial networks (organ) for sequence generation models. Benjamin Gabriel Lima Guimaraes, Carlos Sanchez-Lengeling, Pedro Luis Cunha Outeiral, Al\u00e1n Farias, Aspuru-Guzik, Gabriel Lima Guimaraes, Benjamin Sanchez-Lengeling, Carlos Outeiral, Pedro Luis Cunha Farias, and Al\u00e1n Aspuru-Guzik. Objective-reinforced generative adversarial networks (organ) for se- quence generation models. 2017. 2\n\nConformer generation with omega: algorithm and validation using high quality structures from the protein databank and cambridge structural database. C D Paul, Geoffrey Hawkins, Gregory L Skillman, Warren, Matthew T Benjamin A Ellingson, Stahl, Journal of chemical information and modeling. 50414Paul CD Hawkins, A Geoffrey Skillman, Gregory L Warren, Benjamin A Ellingson, and Matthew T Stahl. Conformer generation with omega: algorithm and validation using high quality structures from the protein databank and cambridge structural database. Journal of chemical information and modeling, 50(4):572-584, 2010. 14\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 98Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation, 9(8): 1735-1780, 1997. 3\n\nZinc: a free tool to discover chemistry for biology. J John, Teague Irwin, Sterling, M Michael, Erin S Mysinger, Ryan G Bolstad, Coleman, Journal of chemical information and modeling. 527John J Irwin, Teague Sterling, Michael M Mysinger, Erin S Bolstad, and Ryan G Coleman. Zinc: a free tool to discover chemistry for biology. Journal of chemical information and modeling, 52 (7):1757-1768, 2012. 13\n\nFragment-based Sequential Translation for Molecular Optimization. Fragment-based Sequential Translation for Molecular Optimization\n\nJunction tree variational autoencoder for molecular graph generation. Wengong Jin, Regina Barzilay, Tommi Jaakkola, PMLRInternational conference on machine learning. 214Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Junction tree variational autoencoder for molecular graph generation. In International conference on machine learning, pp. 2323-2332. PMLR, 2018. 2, 14\n\nHierarchical graph-to-graph translation for molecules. Wengong Jin, Regina Barzilay, Tommi Jaakkola, arXiv:1907.11223arXiv preprintWengong Jin, Regina Barzilay, and Tommi Jaakkola. Hierarchical graph-to-graph translation for molecules. arXiv preprint arXiv:1907.11223, 2019a. 1\n\nLearning multimodal graph-tograph translation for molecule optimization. Wengong Jin, Kevin Yang, Regina Barzilay, Tommi Jaakkola, International Conference on Learning Representations. 1314Wengong Jin, Kevin Yang, Regina Barzilay, and Tommi Jaakkola. Learning multimodal graph-to- graph translation for molecule optimization. In International Conference on Learning Represen- tations, 2019b. 2, 13, 14\n\nMulti-objective molecule generation using interpretable substructures. Wengong Jin, Regina Barzilay, Tommi Jaakkola, PMLRInternational Conference on Machine Learning. 27Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Multi-objective molecule generation using interpretable substructures. In International Conference on Machine Learning, pp. 4849-4859. PMLR, 2020. 2, 7\n\nConditional molecular design with deep generative models. Seokho Kang, Kyunghyun Cho, Journal of chemical information and modeling. 591Seokho Kang and Kyunghyun Cho. Conditional molecular design with deep generative models. Journal of chemical information and modeling, 59(1):43-52, 2018. 2\n\nGraphpiece: Efficiently generating high-quality molecular graph with substructures. Xiangzhe Kong, Zhixing Tan, Yang Liu, arXiv:2106.150981314arXiv preprintXiangzhe Kong, Zhixing Tan, and Yang Liu. Graphpiece: Efficiently generating high-quality molec- ular graph with substructures. arXiv preprint arXiv:2106.15098, 2021. 2, 7, 13, 14\n\nSelfreferencing embedded strings (selfies): A 100% robust molecular string representation. Mario Krenn, Florian H\u00e4se, Akshatkumar Nigam, Pascal Friederich, Alan Aspuru-Guzik, Machine Learning: Science and Technology. 1445024Mario Krenn, Florian H\u00e4se, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. Self- referencing embedded strings (selfies): A 100% robust molecular string representation. Machine Learning: Science and Technology, 1(4):045024, 2020. 2\n\nExperimental and computational approaches to estimate solubility and permeability in drug discovery and development settings. A Christopher, Franco Lipinski, Lombardo, W Beryl, Paul J Dominy, Feeney, Advanced drug delivery reviews. 231-314Christopher A Lipinski, Franco Lombardo, Beryl W Dominy, and Paul J Feeney. Experimental and computational approaches to estimate solubility and permeability in drug discovery and develop- ment settings. Advanced drug delivery reviews, 23(1-3):3-25, 1997. 14\n\nConstrained graph variational autoencoders for molecule design. Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, Alexander L Gaunt, arXiv:1805.09076arXiv preprintQi Liu, Miltiadis Allamanis, Marc Brockschmidt, and Alexander L Gaunt. Constrained graph vari- ational autoencoders for molecule design. arXiv preprint arXiv:1805.09076, 2018. 2\n\nConstrained generation of semantically valid graphs via regularizing variational autoencoders. Tengfei Ma, Jie Chen, Cao Xiao, arXiv:1809.02630arXiv preprintTengfei Ma, Jie Chen, and Cao Xiao. Constrained generation of semantically valid graphs via regularizing variational autoencoders. arXiv preprint arXiv:1809.02630, 2018. 2\n\nGraph networks for molecular design. Roc\u00edo Mercado, Tobias Rastemo, Edvard Lindel\u00f6f, G\u00fcnter Klambauer, Ola Engkvist, Hongming Chen, Esben Jannik Bjerrum, Science and Technology. 2225023Machine LearningRoc\u00edo Mercado, Tobias Rastemo, Edvard Lindel\u00f6f, G\u00fcnter Klambauer, Ola Engkvist, Hongming Chen, and Esben Jannik Bjerrum. Graph networks for molecular design. Machine Learning: Science and Technology, 2(2):025023, 2021. 2\n\nAugmenting genetic algorithms with deep neural networks for exploring the chemical space. Akshatkumar Nigam, Pascal Friederich, Mario Krenn, Al\u00e1n Aspuru-Guzik, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia202014AkshatKumar Nigam, Pascal Friederich, Mario Krenn, and Al\u00e1n Aspuru-Guzik. Augmenting ge- netic algorithms with deep neural networks for exploring the chemical space. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. 2, 7, 13, 14\n\nJanus: Parallel tempered genetic algorithm guided by deep neural networks for inverse molecular design. Akshatkumar Nigam, Robert Pollice, Alan Aspuru-Guzik, 27AkshatKumar Nigam, Robert Pollice, and Alan Aspuru-Guzik. Janus: Parallel tempered genetic algorithm guided by deep neural networks for inverse molecular design. 2021a. 2, 7\n\nBeyond generative models: superfast traversal, optimization, novelty, exploration and discovery (stoned) algorithm for molecules using selfies. Akshatkumar Nigam, Robert Pollice, Mario Krenn, Gabriel Dos Passos, Alan Gomes, Aspuru-Guzik, Chemical science. 2AkshatKumar Nigam, Robert Pollice, Mario Krenn, Gabriel dos Passos Gomes, and Alan Aspuru- Guzik. Beyond generative models: superfast traversal, optimization, novelty, exploration and discovery (stoned) algorithm for molecules using selfies. Chemical science, 2021b. 2\n\nMolecular de-novo design through deep reinforcement learning. Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, Hongming Chen, Journal of cheminformatics. 91Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen. Molecular de-novo design through deep reinforcement learning. Journal of cheminformatics, 9(1):1-14, 2017. 2\n\nA deep generative model for fragment-based molecule generation. Marco Podda, Davide Bacciu, Alessio Micheli, PMLRInternational Conference on Artificial Intelligence and Statistics. 1Marco Podda, Davide Bacciu, and Alessio Micheli. A deep generative model for fragment-based molecule generation. In International Conference on Artificial Intelligence and Statistics, pp. 2240-2250. PMLR, 2020. 1, 2\n\nJournal of chemical information and modeling. David Rogers, Mathew Hahn, 5013Extended-connectivity fingerprintsDavid Rogers and Mathew Hahn. Extended-connectivity fingerprints. Journal of chemical informa- tion and modeling, 50(5):742-754, 2010. 13\n\nNevae: A deep generative model for molecular graphs. Bidisha Samanta, Abir De, Gourhari Jana, Vicen\u00e7 G\u00f3mez, Pratim Kumar Chattaraj, Niloy Ganguly, Manuel Gomez-Rodriguez, 21Journal of machine learning researchBidisha Samanta, Abir De, Gourhari Jana, Vicen\u00e7 G\u00f3mez, Pratim Kumar Chattaraj, Niloy Ganguly, and Manuel Gomez-Rodriguez. Nevae: A deep generative model for molecular graphs. Journal of machine learning research. 2020 Apr; 21 (114): 1-33, 2020. 2\n\nProximal policy optimization algorithms. John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov, John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. 2017. 7\n\nGenerating focused molecule libraries for drug discovery with recurrent neural networks. H S Marwin, Thierry Segler, Christian Kogej, Mark P Tyrchan, Waller, ACS central science. 41Marwin HS Segler, Thierry Kogej, Christian Tyrchan, and Mark P Waller. Generating focused molecule libraries for drug discovery with recurrent neural networks. ACS central science, 4(1): 120-131, 2018. 2\n\nGraphaf: a flow-based autoregressive model for molecular graph generation. Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, Jian Tang, arXiv:2001.093821314arXiv preprintChence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, and Jian Tang. Graphaf: a flow-based autoregressive model for molecular graph generation. arXiv preprint arXiv:2001.09382, 2020. 7, 13, 14\n\nGraphvae: Towards generation of small graphs using variational autoencoders. Martin Simonovsky, Nikos Komodakis, International conference on artificial neural networks. SpringerMartin Simonovsky and Nikos Komodakis. Graphvae: Towards generation of small graphs using variational autoencoders. In International conference on artificial neural networks, pp. 412-422. Springer, 2018. 2\n\nLearning options in reinforcement learning. Martin Stolle, Doina Precup, International Symposium on abstraction, reformulation, and approximation. SpringerMartin Stolle and Doina Precup. Learning options in reinforcement learning. In International Symposium on abstraction, reformulation, and approximation, pp. 212-223. Springer, 2002. 1\n\nExcape-db: an integrated large scale dataset facilitating big data analysis in chemogenomics. Jiangming Sun, Nina Jeliazkova, Vladimir Chupakhin, Jose-Felipe Golib-Dzib, Ola Engkvist, Lars Carlsson, J\u00f6rg Wegner, Hugo Ceulemans, Ivan Georgiev, Vedrin Jeliazkov, Journal of cheminformatics. 91Jiangming Sun, Nina Jeliazkova, Vladimir Chupakhin, Jose-Felipe Golib-Dzib, Ola Engkvist, Lars Carlsson, J\u00f6rg Wegner, Hugo Ceulemans, Ivan Georgiev, Vedrin Jeliazkov, et al. Excape-db: an integrated large scale dataset facilitating big data analysis in chemogenomics. Journal of cheminformatics, 9(1):1-9, 2017. 6\n\nBetween mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning. Richard S Sutton, Doina Precup, Satinder Singh, Artificial Intelligence. 1121Richard S. Sutton, Doina Precup, and Satinder Singh. Between mdps and semi-mdps: A framework for temporal abstraction in reinforcement learning. Artificial Intelligence, 112(1):181-211, 1999.\n\nDiscretizing continuous action space for on-policy optimization. Yunhao Tang, Shipra Agrawal, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Yunhao Tang and Shipra Agrawal. Discretizing continuous action space for on-policy optimization. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 5981-5988, 2020. 4\n\nNeural discrete representation learning. A\u00e4ron Van Den Oord, Oriol Vinyals, Koray Kavukcuoglu, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems. Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman GarnettLong Beach, CA, USA13A\u00e4ron van den Oord, Oriol Vinyals, and Koray Kavukcuoglu. Neural discrete representation learn- ing. In Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pp. 6306-6315, 2017. 1, 3\n\n{MARS}: Markov molecular sampling for multi-objective drug discovery. Yutong Xie, Chence Shi, Hao Zhou, Yuwei Yang, Weinan Zhang, Yong Yu, Lei Li, International Conference on Learning Representations. 17Yutong Xie, Chence Shi, Hao Zhou, Yuwei Yang, Weinan Zhang, Yong Yu, and Lei Li. {MARS}: Markov molecular sampling for multi-objective drug discovery. In International Conference on Learning Representations, 2021. 1, 2, 7\n\nGraph convolutional policy network for goal-directed molecular graph generation. Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay S Pande, Jure Leskovec, ; Hanna, M Wallach, Hugo Larochelle, Kristen Grauman, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems. Nicol\u00f2 Cesa-Bianchi, and Roman GarnettNeurIPS; Montr\u00e9al, Canada1314Samy Bengio,Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay S. Pande, and Jure Leskovec. Graph convolutional pol- icy network for goal-directed molecular graph generation. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicol\u00f2 Cesa-Bianchi, and Roman Garnett (eds.), Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Pro- cessing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr\u00e9al, Canada, pp. 6412-6422, 2018. 2, 13, 14\n", "annotations": {"author": "[{\"end\":213,\"start\":133},{\"end\":291,\"start\":214},{\"end\":375,\"start\":292},{\"end\":437,\"start\":376}]", "publisher": null, "author_last_name": "[{\"end\":144,\"start\":140},{\"end\":222,\"start\":220},{\"end\":307,\"start\":299},{\"end\":390,\"start\":382}]", "author_first_name": "[{\"end\":139,\"start\":133},{\"end\":219,\"start\":214},{\"end\":298,\"start\":292},{\"end\":381,\"start\":376}]", "author_affiliation": "[{\"end\":212,\"start\":168},{\"end\":290,\"start\":246},{\"end\":374,\"start\":330},{\"end\":436,\"start\":392}]", "title": "[{\"end\":130,\"start\":1},{\"end\":567,\"start\":438}]", "venue": null, "abstract": "[{\"end\":2700,\"start\":569}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3305,\"start\":3286},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3324,\"start\":3305},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3341,\"start\":3324},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3684,\"start\":3657},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":4069,\"start\":4048},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":4091,\"start\":4069},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5513,\"start\":5482},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5530,\"start\":5513},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5550,\"start\":5530},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":5603,\"start\":5573},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5619,\"start\":5603},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5639,\"start\":5619},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":5660,\"start\":5639},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5681,\"start\":5660},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5762,\"start\":5745},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5900,\"start\":5883},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6210,\"start\":6190},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":6227,\"start\":6210},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6245,\"start\":6227},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6617,\"start\":6595},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":6797,\"start\":6780},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7017,\"start\":6999},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7302,\"start\":7296},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7575,\"start\":7558},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7676,\"start\":7658},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8930,\"start\":8898},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8964,\"start\":8944},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9455,\"start\":9428},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12286,\"start\":12264},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":13825,\"start\":13803},{\"end\":13844,\"start\":13825},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17334,\"start\":17312},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":19953,\"start\":19950},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":23279,\"start\":23261},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23446,\"start\":23428},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":23463,\"start\":23446},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":23483,\"start\":23463},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":23836,\"start\":23809},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":25681,\"start\":25664},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":26133,\"start\":26116},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26156,\"start\":26138},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":26247,\"start\":26226},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":26627,\"start\":26609},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26848,\"start\":26842},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":27096,\"start\":27078},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":29520,\"start\":29498},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":34513,\"start\":34493},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":34669,\"start\":34652},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":34874,\"start\":34853},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":34964,\"start\":34945},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":34981,\"start\":34964},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":34998,\"start\":34981},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":35016,\"start\":34998},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":36401,\"start\":36383},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":36463,\"start\":36445},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":36535,\"start\":36513},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":36600,\"start\":36582},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":36663,\"start\":36644},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":36727,\"start\":36708},{\"end\":36808,\"start\":36802},{\"end\":37966,\"start\":37941},{\"end\":37994,\"start\":37968},{\"end\":38026,\"start\":37994},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":38327,\"start\":38304},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":38930,\"start\":38908},{\"end\":39086,\"start\":39063}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":40198,\"start\":40110},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40517,\"start\":40199},{\"attributes\":{\"id\":\"fig_2\"},\"end\":40955,\"start\":40518},{\"attributes\":{\"id\":\"fig_3\"},\"end\":41139,\"start\":40956},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":42554,\"start\":41140},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":42659,\"start\":42555},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":42995,\"start\":42660},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":43288,\"start\":42996},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":43660,\"start\":43289}]", "paragraph": "[{\"end\":3190,\"start\":2716},{\"end\":4149,\"start\":3192},{\"end\":5347,\"start\":4151},{\"end\":8198,\"start\":5349},{\"end\":8781,\"start\":8216},{\"end\":9143,\"start\":8843},{\"end\":9295,\"start\":9198},{\"end\":10035,\"start\":9297},{\"end\":10526,\"start\":10112},{\"end\":10923,\"start\":10528},{\"end\":11211,\"start\":11006},{\"end\":12144,\"start\":11249},{\"end\":13213,\"start\":12192},{\"end\":13845,\"start\":13215},{\"end\":14643,\"start\":13847},{\"end\":14952,\"start\":14645},{\"end\":15077,\"start\":14954},{\"end\":15139,\"start\":15107},{\"end\":15288,\"start\":15141},{\"end\":15810,\"start\":15338},{\"end\":15970,\"start\":15812},{\"end\":16154,\"start\":16003},{\"end\":16616,\"start\":16156},{\"end\":16931,\"start\":16618},{\"end\":18038,\"start\":16991},{\"end\":18648,\"start\":18040},{\"end\":18667,\"start\":18650},{\"end\":18725,\"start\":18669},{\"end\":18969,\"start\":18878},{\"end\":19037,\"start\":18971},{\"end\":19058,\"start\":19039},{\"end\":19066,\"start\":19060},{\"end\":19196,\"start\":19112},{\"end\":19231,\"start\":19198},{\"end\":19260,\"start\":19233},{\"end\":19284,\"start\":19262},{\"end\":19349,\"start\":19286},{\"end\":19419,\"start\":19351},{\"end\":19456,\"start\":19421},{\"end\":19473,\"start\":19458},{\"end\":19488,\"start\":19475},{\"end\":19509,\"start\":19490},{\"end\":20016,\"start\":19511},{\"end\":20255,\"start\":20059},{\"end\":20391,\"start\":20257},{\"end\":20831,\"start\":20483},{\"end\":21070,\"start\":20833},{\"end\":21244,\"start\":21139},{\"end\":21813,\"start\":21246},{\"end\":22188,\"start\":21873},{\"end\":22287,\"start\":22190},{\"end\":22465,\"start\":22289},{\"end\":22983,\"start\":22467},{\"end\":23596,\"start\":22999},{\"end\":24512,\"start\":23598},{\"end\":26576,\"start\":24514},{\"end\":27598,\"start\":26578},{\"end\":29166,\"start\":27600},{\"end\":29949,\"start\":29168},{\"end\":30638,\"start\":29951},{\"end\":31367,\"start\":30664},{\"end\":32004,\"start\":31369},{\"end\":32645,\"start\":32006},{\"end\":33439,\"start\":32660},{\"end\":34211,\"start\":33480},{\"end\":34901,\"start\":34249},{\"end\":35766,\"start\":34903},{\"end\":36049,\"start\":35768},{\"end\":36939,\"start\":36051},{\"end\":37127,\"start\":36941},{\"end\":38163,\"start\":37129},{\"end\":38703,\"start\":38165},{\"end\":40109,\"start\":38745}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8842,\"start\":8782},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9197,\"start\":9144},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10111,\"start\":10036},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11005,\"start\":10924},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15106,\"start\":15078},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15337,\"start\":15289},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16002,\"start\":15971},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18877,\"start\":18726},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19111,\"start\":19067},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20058,\"start\":20017},{\"attributes\":{\"id\":\"formula_10\"},\"end\":20482,\"start\":20392},{\"attributes\":{\"id\":\"formula_11\"},\"end\":21138,\"start\":21071},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21872,\"start\":21814}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27656,\"start\":27649},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":28627,\"start\":28620},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":37157,\"start\":37150},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":39520,\"start\":39513}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2714,\"start\":2702},{\"attributes\":{\"n\":\"3\"},\"end\":8214,\"start\":8201},{\"attributes\":{\"n\":\"4\"},\"end\":11221,\"start\":11214},{\"end\":11247,\"start\":11224},{\"attributes\":{\"n\":\"4.1\"},\"end\":12190,\"start\":12147},{\"attributes\":{\"n\":\"4.2\"},\"end\":16989,\"start\":16934},{\"attributes\":{\"n\":\"5\"},\"end\":22997,\"start\":22986},{\"attributes\":{\"n\":\"6\"},\"end\":30662,\"start\":30641},{\"attributes\":{\"n\":\"7\"},\"end\":32658,\"start\":32648},{\"end\":33478,\"start\":33442},{\"end\":34247,\"start\":34214},{\"end\":38743,\"start\":38706},{\"end\":40210,\"start\":40200},{\"end\":40529,\"start\":40519},{\"end\":40967,\"start\":40957},{\"end\":41150,\"start\":41141},{\"end\":42565,\"start\":42556},{\"end\":42670,\"start\":42661},{\"end\":43006,\"start\":42997},{\"end\":43299,\"start\":43290}]", "table": "[{\"end\":42554,\"start\":41324},{\"end\":42995,\"start\":42797},{\"end\":43288,\"start\":43039},{\"end\":43660,\"start\":43380}]", "figure_caption": "[{\"end\":40198,\"start\":40112},{\"end\":40517,\"start\":40212},{\"end\":40955,\"start\":40531},{\"end\":41139,\"start\":40969},{\"end\":41324,\"start\":41152},{\"end\":42659,\"start\":42567},{\"end\":42797,\"start\":42672},{\"end\":43039,\"start\":43008},{\"end\":43380,\"start\":43301}]", "figure_ref": "[{\"end\":6776,\"start\":6755},{\"end\":12143,\"start\":12135},{\"end\":12381,\"start\":12373},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":26483,\"start\":26475},{\"end\":30882,\"start\":30874},{\"end\":31543,\"start\":31534},{\"end\":31557,\"start\":31548},{\"end\":32304,\"start\":32295},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":33638,\"start\":33629},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":33900,\"start\":33892},{\"end\":36855,\"start\":36847},{\"end\":37603,\"start\":37595},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":40107,\"start\":40099}]", "bib_author_first_name": "[{\"end\":43800,\"start\":43797},{\"end\":43817,\"start\":43810},{\"end\":43826,\"start\":43825},{\"end\":43839,\"start\":43835},{\"end\":43854,\"start\":43848},{\"end\":44173,\"start\":44172},{\"end\":44186,\"start\":44180},{\"end\":44201,\"start\":44196},{\"end\":44219,\"start\":44211},{\"end\":44519,\"start\":44514},{\"end\":44536,\"start\":44530},{\"end\":44555,\"start\":44545},{\"end\":44888,\"start\":44887},{\"end\":44908,\"start\":44907},{\"end\":44918,\"start\":44917},{\"end\":45321,\"start\":45313},{\"end\":45335,\"start\":45329},{\"end\":45355,\"start\":45346},{\"end\":45367,\"start\":45361},{\"end\":45662,\"start\":45656},{\"end\":45670,\"start\":45667},{\"end\":45679,\"start\":45673},{\"end\":45909,\"start\":45908},{\"end\":45927,\"start\":45926},{\"end\":45945,\"start\":45944},{\"end\":45960,\"start\":45955},{\"end\":45962,\"start\":45961},{\"end\":46280,\"start\":46274},{\"end\":46295,\"start\":46290},{\"end\":46310,\"start\":46306},{\"end\":46320,\"start\":46319},{\"end\":46334,\"start\":46330},{\"end\":46905,\"start\":46900},{\"end\":46918,\"start\":46912},{\"end\":47243,\"start\":47239},{\"end\":47254,\"start\":47253},{\"end\":47271,\"start\":47263},{\"end\":47283,\"start\":47280},{\"end\":47295,\"start\":47291},{\"end\":47310,\"start\":47306},{\"end\":47325,\"start\":47319},{\"end\":47339,\"start\":47334},{\"end\":47352,\"start\":47347},{\"end\":47371,\"start\":47365},{\"end\":47805,\"start\":47799},{\"end\":47832,\"start\":47824},{\"end\":47834,\"start\":47833},{\"end\":47845,\"start\":47840},{\"end\":47860,\"start\":47856},{\"end\":47867,\"start\":47861},{\"end\":47894,\"start\":47886},{\"end\":47920,\"start\":47914},{\"end\":47936,\"start\":47931},{\"end\":47967,\"start\":47960},{\"end\":47969,\"start\":47968},{\"end\":47979,\"start\":47978},{\"end\":47990,\"start\":47986},{\"end\":48450,\"start\":48443},{\"end\":48477,\"start\":48471},{\"end\":48492,\"start\":48486},{\"end\":48505,\"start\":48499},{\"end\":48968,\"start\":48960},{\"end\":48999,\"start\":48993},{\"end\":49035,\"start\":49019},{\"end\":49050,\"start\":49046},{\"end\":49444,\"start\":49443},{\"end\":49446,\"start\":49445},{\"end\":49461,\"start\":49453},{\"end\":49478,\"start\":49471},{\"end\":49480,\"start\":49479},{\"end\":49508,\"start\":49499},{\"end\":49936,\"start\":49932},{\"end\":49955,\"start\":49949},{\"end\":50155,\"start\":50154},{\"end\":50168,\"start\":50162},{\"end\":50187,\"start\":50186},{\"end\":50201,\"start\":50197},{\"end\":50203,\"start\":50202},{\"end\":50220,\"start\":50214},{\"end\":50711,\"start\":50704},{\"end\":50723,\"start\":50717},{\"end\":50739,\"start\":50734},{\"end\":51068,\"start\":51061},{\"end\":51080,\"start\":51074},{\"end\":51096,\"start\":51091},{\"end\":51365,\"start\":51358},{\"end\":51376,\"start\":51371},{\"end\":51389,\"start\":51383},{\"end\":51405,\"start\":51400},{\"end\":51766,\"start\":51759},{\"end\":51778,\"start\":51772},{\"end\":51794,\"start\":51789},{\"end\":52124,\"start\":52118},{\"end\":52140,\"start\":52131},{\"end\":52444,\"start\":52436},{\"end\":52458,\"start\":52451},{\"end\":52468,\"start\":52464},{\"end\":52785,\"start\":52780},{\"end\":52800,\"start\":52793},{\"end\":52818,\"start\":52807},{\"end\":52832,\"start\":52826},{\"end\":52849,\"start\":52845},{\"end\":53285,\"start\":53284},{\"end\":53305,\"start\":53299},{\"end\":53327,\"start\":53326},{\"end\":53341,\"start\":53335},{\"end\":53723,\"start\":53721},{\"end\":53738,\"start\":53729},{\"end\":53754,\"start\":53750},{\"end\":53778,\"start\":53769},{\"end\":53780,\"start\":53779},{\"end\":54099,\"start\":54092},{\"end\":54107,\"start\":54104},{\"end\":54117,\"start\":54114},{\"end\":54369,\"start\":54364},{\"end\":54385,\"start\":54379},{\"end\":54401,\"start\":54395},{\"end\":54418,\"start\":54412},{\"end\":54433,\"start\":54430},{\"end\":54452,\"start\":54444},{\"end\":54471,\"start\":54459},{\"end\":54851,\"start\":54840},{\"end\":54865,\"start\":54859},{\"end\":54883,\"start\":54878},{\"end\":54895,\"start\":54891},{\"end\":55426,\"start\":55415},{\"end\":55440,\"start\":55434},{\"end\":55454,\"start\":55450},{\"end\":55801,\"start\":55790},{\"end\":55815,\"start\":55809},{\"end\":55830,\"start\":55825},{\"end\":55845,\"start\":55838},{\"end\":55862,\"start\":55858},{\"end\":56241,\"start\":56235},{\"end\":56260,\"start\":56254},{\"end\":56274,\"start\":56271},{\"end\":56293,\"start\":56285},{\"end\":56578,\"start\":56573},{\"end\":56592,\"start\":56586},{\"end\":56608,\"start\":56601},{\"end\":56959,\"start\":56954},{\"end\":56974,\"start\":56968},{\"end\":57218,\"start\":57211},{\"end\":57232,\"start\":57228},{\"end\":57245,\"start\":57237},{\"end\":57258,\"start\":57252},{\"end\":57272,\"start\":57266},{\"end\":57295,\"start\":57290},{\"end\":57311,\"start\":57305},{\"end\":57660,\"start\":57656},{\"end\":57676,\"start\":57671},{\"end\":57693,\"start\":57685},{\"end\":57708,\"start\":57704},{\"end\":57722,\"start\":57718},{\"end\":57950,\"start\":57949},{\"end\":57952,\"start\":57951},{\"end\":57968,\"start\":57961},{\"end\":57986,\"start\":57977},{\"end\":57998,\"start\":57994},{\"end\":58000,\"start\":57999},{\"end\":58327,\"start\":58321},{\"end\":58339,\"start\":58333},{\"end\":58353,\"start\":58344},{\"end\":58365,\"start\":58359},{\"end\":58377,\"start\":58373},{\"end\":58389,\"start\":58385},{\"end\":58717,\"start\":58711},{\"end\":58735,\"start\":58730},{\"end\":59068,\"start\":59062},{\"end\":59082,\"start\":59077},{\"end\":59461,\"start\":59452},{\"end\":59471,\"start\":59467},{\"end\":59492,\"start\":59484},{\"end\":59515,\"start\":59504},{\"end\":59531,\"start\":59528},{\"end\":59546,\"start\":59542},{\"end\":59561,\"start\":59557},{\"end\":59574,\"start\":59570},{\"end\":59590,\"start\":59586},{\"end\":59607,\"start\":59601},{\"end\":60063,\"start\":60056},{\"end\":60065,\"start\":60064},{\"end\":60079,\"start\":60074},{\"end\":60096,\"start\":60088},{\"end\":60397,\"start\":60391},{\"end\":60410,\"start\":60404},{\"end\":60775,\"start\":60770},{\"end\":60795,\"start\":60790},{\"end\":60810,\"start\":60805},{\"end\":61573,\"start\":61567},{\"end\":61585,\"start\":61579},{\"end\":61594,\"start\":61591},{\"end\":61606,\"start\":61601},{\"end\":61619,\"start\":61613},{\"end\":61631,\"start\":61627},{\"end\":61639,\"start\":61636},{\"end\":62011,\"start\":62004},{\"end\":62022,\"start\":62017},{\"end\":62034,\"start\":62028},{\"end\":62046,\"start\":62041},{\"end\":62048,\"start\":62047},{\"end\":62060,\"start\":62056},{\"end\":62072,\"start\":62071},{\"end\":62081,\"start\":62080},{\"end\":62095,\"start\":62091},{\"end\":62115,\"start\":62108}]", "bib_author_last_name": "[{\"end\":43808,\"start\":43801},{\"end\":43823,\"start\":43818},{\"end\":43833,\"start\":43827},{\"end\":43846,\"start\":43840},{\"end\":43862,\"start\":43855},{\"end\":43870,\"start\":43864},{\"end\":44170,\"start\":44151},{\"end\":44178,\"start\":44174},{\"end\":44194,\"start\":44187},{\"end\":44209,\"start\":44202},{\"end\":44227,\"start\":44220},{\"end\":44236,\"start\":44229},{\"end\":44528,\"start\":44520},{\"end\":44543,\"start\":44537},{\"end\":44563,\"start\":44556},{\"end\":44896,\"start\":44889},{\"end\":44905,\"start\":44898},{\"end\":44915,\"start\":44909},{\"end\":44924,\"start\":44919},{\"end\":44941,\"start\":44926},{\"end\":45327,\"start\":45322},{\"end\":45344,\"start\":45336},{\"end\":45359,\"start\":45356},{\"end\":45374,\"start\":45368},{\"end\":45665,\"start\":45663},{\"end\":45684,\"start\":45680},{\"end\":45916,\"start\":45910},{\"end\":45924,\"start\":45918},{\"end\":45934,\"start\":45928},{\"end\":45942,\"start\":45936},{\"end\":45953,\"start\":45946},{\"end\":45968,\"start\":45963},{\"end\":45976,\"start\":45970},{\"end\":46288,\"start\":46281},{\"end\":46304,\"start\":46296},{\"end\":46317,\"start\":46311},{\"end\":46328,\"start\":46321},{\"end\":46342,\"start\":46335},{\"end\":46349,\"start\":46344},{\"end\":46631,\"start\":46614},{\"end\":46910,\"start\":46906},{\"end\":46932,\"start\":46919},{\"end\":47251,\"start\":47244},{\"end\":47261,\"start\":47255},{\"end\":47278,\"start\":47272},{\"end\":47289,\"start\":47284},{\"end\":47304,\"start\":47296},{\"end\":47317,\"start\":47311},{\"end\":47332,\"start\":47326},{\"end\":47345,\"start\":47340},{\"end\":47363,\"start\":47353},{\"end\":47383,\"start\":47372},{\"end\":47396,\"start\":47385},{\"end\":47822,\"start\":47806},{\"end\":47838,\"start\":47835},{\"end\":47854,\"start\":47846},{\"end\":47884,\"start\":47868},{\"end\":47912,\"start\":47895},{\"end\":47929,\"start\":47921},{\"end\":47958,\"start\":47937},{\"end\":47976,\"start\":47970},{\"end\":47984,\"start\":47980},{\"end\":47996,\"start\":47991},{\"end\":48010,\"start\":47998},{\"end\":48469,\"start\":48451},{\"end\":48484,\"start\":48478},{\"end\":48497,\"start\":48493},{\"end\":48512,\"start\":48506},{\"end\":48519,\"start\":48514},{\"end\":48991,\"start\":48969},{\"end\":49017,\"start\":49000},{\"end\":49044,\"start\":49036},{\"end\":49057,\"start\":49051},{\"end\":49071,\"start\":49059},{\"end\":49451,\"start\":49447},{\"end\":49469,\"start\":49462},{\"end\":49489,\"start\":49481},{\"end\":49497,\"start\":49491},{\"end\":49529,\"start\":49509},{\"end\":49536,\"start\":49531},{\"end\":49947,\"start\":49937},{\"end\":49967,\"start\":49956},{\"end\":50160,\"start\":50156},{\"end\":50174,\"start\":50169},{\"end\":50184,\"start\":50176},{\"end\":50195,\"start\":50188},{\"end\":50212,\"start\":50204},{\"end\":50228,\"start\":50221},{\"end\":50237,\"start\":50230},{\"end\":50715,\"start\":50712},{\"end\":50732,\"start\":50724},{\"end\":50748,\"start\":50740},{\"end\":51072,\"start\":51069},{\"end\":51089,\"start\":51081},{\"end\":51105,\"start\":51097},{\"end\":51369,\"start\":51366},{\"end\":51381,\"start\":51377},{\"end\":51398,\"start\":51390},{\"end\":51414,\"start\":51406},{\"end\":51770,\"start\":51767},{\"end\":51787,\"start\":51779},{\"end\":51803,\"start\":51795},{\"end\":52129,\"start\":52125},{\"end\":52144,\"start\":52141},{\"end\":52449,\"start\":52445},{\"end\":52462,\"start\":52459},{\"end\":52472,\"start\":52469},{\"end\":52791,\"start\":52786},{\"end\":52805,\"start\":52801},{\"end\":52824,\"start\":52819},{\"end\":52843,\"start\":52833},{\"end\":52862,\"start\":52850},{\"end\":53297,\"start\":53286},{\"end\":53314,\"start\":53306},{\"end\":53324,\"start\":53316},{\"end\":53333,\"start\":53328},{\"end\":53348,\"start\":53342},{\"end\":53356,\"start\":53350},{\"end\":53727,\"start\":53724},{\"end\":53748,\"start\":53739},{\"end\":53767,\"start\":53755},{\"end\":53786,\"start\":53781},{\"end\":54102,\"start\":54100},{\"end\":54112,\"start\":54108},{\"end\":54122,\"start\":54118},{\"end\":54377,\"start\":54370},{\"end\":54393,\"start\":54386},{\"end\":54410,\"start\":54402},{\"end\":54428,\"start\":54419},{\"end\":54442,\"start\":54434},{\"end\":54457,\"start\":54453},{\"end\":54479,\"start\":54472},{\"end\":54857,\"start\":54852},{\"end\":54876,\"start\":54866},{\"end\":54889,\"start\":54884},{\"end\":54908,\"start\":54896},{\"end\":55432,\"start\":55427},{\"end\":55448,\"start\":55441},{\"end\":55467,\"start\":55455},{\"end\":55807,\"start\":55802},{\"end\":55823,\"start\":55816},{\"end\":55836,\"start\":55831},{\"end\":55856,\"start\":55846},{\"end\":55868,\"start\":55863},{\"end\":55882,\"start\":55870},{\"end\":56252,\"start\":56242},{\"end\":56269,\"start\":56261},{\"end\":56283,\"start\":56275},{\"end\":56298,\"start\":56294},{\"end\":56584,\"start\":56579},{\"end\":56599,\"start\":56593},{\"end\":56616,\"start\":56609},{\"end\":56966,\"start\":56960},{\"end\":56979,\"start\":56975},{\"end\":57226,\"start\":57219},{\"end\":57235,\"start\":57233},{\"end\":57250,\"start\":57246},{\"end\":57264,\"start\":57259},{\"end\":57288,\"start\":57273},{\"end\":57303,\"start\":57296},{\"end\":57327,\"start\":57312},{\"end\":57669,\"start\":57661},{\"end\":57683,\"start\":57677},{\"end\":57702,\"start\":57694},{\"end\":57716,\"start\":57709},{\"end\":57729,\"start\":57723},{\"end\":57959,\"start\":57953},{\"end\":57975,\"start\":57969},{\"end\":57992,\"start\":57987},{\"end\":58008,\"start\":58001},{\"end\":58016,\"start\":58010},{\"end\":58331,\"start\":58328},{\"end\":58342,\"start\":58340},{\"end\":58357,\"start\":58354},{\"end\":58371,\"start\":58366},{\"end\":58383,\"start\":58378},{\"end\":58394,\"start\":58390},{\"end\":58728,\"start\":58718},{\"end\":58745,\"start\":58736},{\"end\":59075,\"start\":59069},{\"end\":59089,\"start\":59083},{\"end\":59465,\"start\":59462},{\"end\":59482,\"start\":59472},{\"end\":59502,\"start\":59493},{\"end\":59526,\"start\":59516},{\"end\":59540,\"start\":59532},{\"end\":59555,\"start\":59547},{\"end\":59568,\"start\":59562},{\"end\":59584,\"start\":59575},{\"end\":59599,\"start\":59591},{\"end\":59617,\"start\":59608},{\"end\":60072,\"start\":60066},{\"end\":60086,\"start\":60080},{\"end\":60102,\"start\":60097},{\"end\":60402,\"start\":60398},{\"end\":60418,\"start\":60411},{\"end\":60788,\"start\":60776},{\"end\":60803,\"start\":60796},{\"end\":60822,\"start\":60811},{\"end\":61577,\"start\":61574},{\"end\":61589,\"start\":61586},{\"end\":61599,\"start\":61595},{\"end\":61611,\"start\":61607},{\"end\":61625,\"start\":61620},{\"end\":61634,\"start\":61632},{\"end\":61642,\"start\":61640},{\"end\":62015,\"start\":62012},{\"end\":62026,\"start\":62023},{\"end\":62039,\"start\":62035},{\"end\":62054,\"start\":62049},{\"end\":62069,\"start\":62061},{\"end\":62078,\"start\":62073},{\"end\":62089,\"start\":62082},{\"end\":62106,\"start\":62096},{\"end\":62123,\"start\":62116}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1811.09766\",\"id\":\"b0\"},\"end\":44107,\"start\":43715},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":205289650},\"end\":44427,\"start\":44109},{\"attributes\":{\"doi\":\"2020. 14\",\"id\":\"b2\",\"matched_paper_id\":219589988},\"end\":44792,\"start\":44429},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":37017771},\"end\":45233,\"start\":44794},{\"attributes\":{\"doi\":\"arXiv:1412.3555\",\"id\":\"b4\"},\"end\":45589,\"start\":45235},{\"attributes\":{\"doi\":\"arXiv:1805.11973\",\"id\":\"b5\"},\"end\":45852,\"start\":45591},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":22752474},\"end\":46244,\"start\":45854},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":216552951},\"end\":46508,\"start\":46246},{\"attributes\":{\"id\":\"b8\"},\"end\":46773,\"start\":46510},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":7423230},\"end\":47174,\"start\":46775},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":16681789},\"end\":47711,\"start\":47176},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":3347345},\"end\":48381,\"start\":47713},{\"attributes\":{\"doi\":\"PMLR, 2020. 4\",\"id\":\"b12\",\"matched_paper_id\":220769401},\"end\":48865,\"start\":48383},{\"attributes\":{\"id\":\"b13\"},\"end\":49292,\"start\":48867},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":17698058},\"end\":49906,\"start\":49294},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1915014},\"end\":50099,\"start\":49908},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":9759396},\"end\":50500,\"start\":50101},{\"attributes\":{\"id\":\"b17\"},\"end\":50632,\"start\":50502},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b18\",\"matched_paper_id\":3364940},\"end\":51004,\"start\":50634},{\"attributes\":{\"doi\":\"arXiv:1907.11223\",\"id\":\"b19\"},\"end\":51283,\"start\":51006},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":54444711},\"end\":51686,\"start\":51285},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b21\",\"matched_paper_id\":215827485},\"end\":52058,\"start\":51688},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":23822765},\"end\":52350,\"start\":52060},{\"attributes\":{\"doi\":\"arXiv:2106.15098\",\"id\":\"b23\"},\"end\":52687,\"start\":52352},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":212415210},\"end\":53156,\"start\":52689},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":24301532},\"end\":53655,\"start\":53158},{\"attributes\":{\"doi\":\"arXiv:1805.09076\",\"id\":\"b26\"},\"end\":53995,\"start\":53657},{\"attributes\":{\"doi\":\"arXiv:1809.02630\",\"id\":\"b27\"},\"end\":54325,\"start\":53997},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":221351024},\"end\":54748,\"start\":54327},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":202749920},\"end\":55309,\"start\":54750},{\"attributes\":{\"id\":\"b30\"},\"end\":55644,\"start\":55311},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":235411073},\"end\":56171,\"start\":55646},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":2978311},\"end\":56507,\"start\":56173},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b33\",\"matched_paper_id\":211572751},\"end\":56906,\"start\":56509},{\"attributes\":{\"id\":\"b34\"},\"end\":57156,\"start\":56908},{\"attributes\":{\"id\":\"b35\"},\"end\":57613,\"start\":57158},{\"attributes\":{\"id\":\"b36\"},\"end\":57858,\"start\":57615},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":27688749},\"end\":58244,\"start\":57860},{\"attributes\":{\"doi\":\"arXiv:2001.09382\",\"id\":\"b38\"},\"end\":58632,\"start\":58246},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":3637466},\"end\":59016,\"start\":58634},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":16398811},\"end\":59356,\"start\":59018},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":14732369},\"end\":59962,\"start\":59358},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":76564},\"end\":60324,\"start\":59964},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":59413894},\"end\":60727,\"start\":60326},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":20282961},\"end\":61495,\"start\":60729},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":232290577},\"end\":61921,\"start\":61497},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":46978626},\"end\":62791,\"start\":61923}]", "bib_title": "[{\"end\":44149,\"start\":44109},{\"end\":44512,\"start\":44429},{\"end\":44885,\"start\":44794},{\"end\":45906,\"start\":45854},{\"end\":46272,\"start\":46246},{\"end\":46898,\"start\":46775},{\"end\":47237,\"start\":47176},{\"end\":47797,\"start\":47713},{\"end\":48441,\"start\":48383},{\"end\":49441,\"start\":49294},{\"end\":49930,\"start\":49908},{\"end\":50152,\"start\":50101},{\"end\":50702,\"start\":50634},{\"end\":51356,\"start\":51285},{\"end\":51757,\"start\":51688},{\"end\":52116,\"start\":52060},{\"end\":52778,\"start\":52689},{\"end\":53282,\"start\":53158},{\"end\":54362,\"start\":54327},{\"end\":54838,\"start\":54750},{\"end\":55788,\"start\":55646},{\"end\":56233,\"start\":56173},{\"end\":56571,\"start\":56509},{\"end\":57947,\"start\":57860},{\"end\":58709,\"start\":58634},{\"end\":59060,\"start\":59018},{\"end\":59450,\"start\":59358},{\"end\":60054,\"start\":59964},{\"end\":60389,\"start\":60326},{\"end\":60768,\"start\":60729},{\"end\":61565,\"start\":61497},{\"end\":62002,\"start\":61923}]", "bib_author": "[{\"end\":43810,\"start\":43797},{\"end\":43825,\"start\":43810},{\"end\":43835,\"start\":43825},{\"end\":43848,\"start\":43835},{\"end\":43864,\"start\":43848},{\"end\":43872,\"start\":43864},{\"end\":44172,\"start\":44151},{\"end\":44180,\"start\":44172},{\"end\":44196,\"start\":44180},{\"end\":44211,\"start\":44196},{\"end\":44229,\"start\":44211},{\"end\":44238,\"start\":44229},{\"end\":44530,\"start\":44514},{\"end\":44545,\"start\":44530},{\"end\":44565,\"start\":44545},{\"end\":44898,\"start\":44887},{\"end\":44907,\"start\":44898},{\"end\":44917,\"start\":44907},{\"end\":44926,\"start\":44917},{\"end\":44943,\"start\":44926},{\"end\":45329,\"start\":45313},{\"end\":45346,\"start\":45329},{\"end\":45361,\"start\":45346},{\"end\":45376,\"start\":45361},{\"end\":45667,\"start\":45656},{\"end\":45673,\"start\":45667},{\"end\":45686,\"start\":45673},{\"end\":45918,\"start\":45908},{\"end\":45926,\"start\":45918},{\"end\":45936,\"start\":45926},{\"end\":45944,\"start\":45936},{\"end\":45955,\"start\":45944},{\"end\":45970,\"start\":45955},{\"end\":45978,\"start\":45970},{\"end\":46290,\"start\":46274},{\"end\":46306,\"start\":46290},{\"end\":46319,\"start\":46306},{\"end\":46330,\"start\":46319},{\"end\":46344,\"start\":46330},{\"end\":46351,\"start\":46344},{\"end\":46633,\"start\":46614},{\"end\":46912,\"start\":46900},{\"end\":46934,\"start\":46912},{\"end\":47253,\"start\":47239},{\"end\":47263,\"start\":47253},{\"end\":47280,\"start\":47263},{\"end\":47291,\"start\":47280},{\"end\":47306,\"start\":47291},{\"end\":47319,\"start\":47306},{\"end\":47334,\"start\":47319},{\"end\":47347,\"start\":47334},{\"end\":47365,\"start\":47347},{\"end\":47385,\"start\":47365},{\"end\":47398,\"start\":47385},{\"end\":47824,\"start\":47799},{\"end\":47840,\"start\":47824},{\"end\":47856,\"start\":47840},{\"end\":47886,\"start\":47856},{\"end\":47914,\"start\":47886},{\"end\":47931,\"start\":47914},{\"end\":47960,\"start\":47931},{\"end\":47978,\"start\":47960},{\"end\":47986,\"start\":47978},{\"end\":47998,\"start\":47986},{\"end\":48012,\"start\":47998},{\"end\":48471,\"start\":48443},{\"end\":48486,\"start\":48471},{\"end\":48499,\"start\":48486},{\"end\":48514,\"start\":48499},{\"end\":48521,\"start\":48514},{\"end\":48993,\"start\":48960},{\"end\":49019,\"start\":48993},{\"end\":49046,\"start\":49019},{\"end\":49059,\"start\":49046},{\"end\":49073,\"start\":49059},{\"end\":49453,\"start\":49443},{\"end\":49471,\"start\":49453},{\"end\":49491,\"start\":49471},{\"end\":49499,\"start\":49491},{\"end\":49531,\"start\":49499},{\"end\":49538,\"start\":49531},{\"end\":49949,\"start\":49932},{\"end\":49969,\"start\":49949},{\"end\":50162,\"start\":50154},{\"end\":50176,\"start\":50162},{\"end\":50186,\"start\":50176},{\"end\":50197,\"start\":50186},{\"end\":50214,\"start\":50197},{\"end\":50230,\"start\":50214},{\"end\":50239,\"start\":50230},{\"end\":50717,\"start\":50704},{\"end\":50734,\"start\":50717},{\"end\":50750,\"start\":50734},{\"end\":51074,\"start\":51061},{\"end\":51091,\"start\":51074},{\"end\":51107,\"start\":51091},{\"end\":51371,\"start\":51358},{\"end\":51383,\"start\":51371},{\"end\":51400,\"start\":51383},{\"end\":51416,\"start\":51400},{\"end\":51772,\"start\":51759},{\"end\":51789,\"start\":51772},{\"end\":51805,\"start\":51789},{\"end\":52131,\"start\":52118},{\"end\":52146,\"start\":52131},{\"end\":52451,\"start\":52436},{\"end\":52464,\"start\":52451},{\"end\":52474,\"start\":52464},{\"end\":52793,\"start\":52780},{\"end\":52807,\"start\":52793},{\"end\":52826,\"start\":52807},{\"end\":52845,\"start\":52826},{\"end\":52864,\"start\":52845},{\"end\":53299,\"start\":53284},{\"end\":53316,\"start\":53299},{\"end\":53326,\"start\":53316},{\"end\":53335,\"start\":53326},{\"end\":53350,\"start\":53335},{\"end\":53358,\"start\":53350},{\"end\":53729,\"start\":53721},{\"end\":53750,\"start\":53729},{\"end\":53769,\"start\":53750},{\"end\":53788,\"start\":53769},{\"end\":54104,\"start\":54092},{\"end\":54114,\"start\":54104},{\"end\":54124,\"start\":54114},{\"end\":54379,\"start\":54364},{\"end\":54395,\"start\":54379},{\"end\":54412,\"start\":54395},{\"end\":54430,\"start\":54412},{\"end\":54444,\"start\":54430},{\"end\":54459,\"start\":54444},{\"end\":54481,\"start\":54459},{\"end\":54859,\"start\":54840},{\"end\":54878,\"start\":54859},{\"end\":54891,\"start\":54878},{\"end\":54910,\"start\":54891},{\"end\":55434,\"start\":55415},{\"end\":55450,\"start\":55434},{\"end\":55469,\"start\":55450},{\"end\":55809,\"start\":55790},{\"end\":55825,\"start\":55809},{\"end\":55838,\"start\":55825},{\"end\":55858,\"start\":55838},{\"end\":55870,\"start\":55858},{\"end\":55884,\"start\":55870},{\"end\":56254,\"start\":56235},{\"end\":56271,\"start\":56254},{\"end\":56285,\"start\":56271},{\"end\":56300,\"start\":56285},{\"end\":56586,\"start\":56573},{\"end\":56601,\"start\":56586},{\"end\":56618,\"start\":56601},{\"end\":56968,\"start\":56954},{\"end\":56981,\"start\":56968},{\"end\":57228,\"start\":57211},{\"end\":57237,\"start\":57228},{\"end\":57252,\"start\":57237},{\"end\":57266,\"start\":57252},{\"end\":57290,\"start\":57266},{\"end\":57305,\"start\":57290},{\"end\":57329,\"start\":57305},{\"end\":57671,\"start\":57656},{\"end\":57685,\"start\":57671},{\"end\":57704,\"start\":57685},{\"end\":57718,\"start\":57704},{\"end\":57731,\"start\":57718},{\"end\":57961,\"start\":57949},{\"end\":57977,\"start\":57961},{\"end\":57994,\"start\":57977},{\"end\":58010,\"start\":57994},{\"end\":58018,\"start\":58010},{\"end\":58333,\"start\":58321},{\"end\":58344,\"start\":58333},{\"end\":58359,\"start\":58344},{\"end\":58373,\"start\":58359},{\"end\":58385,\"start\":58373},{\"end\":58396,\"start\":58385},{\"end\":58730,\"start\":58711},{\"end\":58747,\"start\":58730},{\"end\":59077,\"start\":59062},{\"end\":59091,\"start\":59077},{\"end\":59467,\"start\":59452},{\"end\":59484,\"start\":59467},{\"end\":59504,\"start\":59484},{\"end\":59528,\"start\":59504},{\"end\":59542,\"start\":59528},{\"end\":59557,\"start\":59542},{\"end\":59570,\"start\":59557},{\"end\":59586,\"start\":59570},{\"end\":59601,\"start\":59586},{\"end\":59619,\"start\":59601},{\"end\":60074,\"start\":60056},{\"end\":60088,\"start\":60074},{\"end\":60104,\"start\":60088},{\"end\":60404,\"start\":60391},{\"end\":60420,\"start\":60404},{\"end\":60790,\"start\":60770},{\"end\":60805,\"start\":60790},{\"end\":60824,\"start\":60805},{\"end\":61579,\"start\":61567},{\"end\":61591,\"start\":61579},{\"end\":61601,\"start\":61591},{\"end\":61613,\"start\":61601},{\"end\":61627,\"start\":61613},{\"end\":61636,\"start\":61627},{\"end\":61644,\"start\":61636},{\"end\":62017,\"start\":62004},{\"end\":62028,\"start\":62017},{\"end\":62041,\"start\":62028},{\"end\":62056,\"start\":62041},{\"end\":62071,\"start\":62056},{\"end\":62080,\"start\":62071},{\"end\":62091,\"start\":62080},{\"end\":62108,\"start\":62091},{\"end\":62125,\"start\":62108}]", "bib_venue": "[{\"end\":43795,\"start\":43715},{\"end\":44254,\"start\":44238},{\"end\":44599,\"start\":44573},{\"end\":44996,\"start\":44943},{\"end\":45311,\"start\":45235},{\"end\":45654,\"start\":45591},{\"end\":46031,\"start\":45978},{\"end\":46357,\"start\":46351},{\"end\":46612,\"start\":46510},{\"end\":46960,\"start\":46934},{\"end\":47420,\"start\":47398},{\"end\":48031,\"start\":48012},{\"end\":48578,\"start\":48534},{\"end\":48958,\"start\":48867},{\"end\":49582,\"start\":49538},{\"end\":49987,\"start\":49969},{\"end\":50283,\"start\":50239},{\"end\":50566,\"start\":50502},{\"end\":50798,\"start\":50754},{\"end\":51059,\"start\":51006},{\"end\":51468,\"start\":51416},{\"end\":51853,\"start\":51809},{\"end\":52190,\"start\":52146},{\"end\":52434,\"start\":52352},{\"end\":52904,\"start\":52864},{\"end\":53388,\"start\":53358},{\"end\":53719,\"start\":53657},{\"end\":54090,\"start\":53997},{\"end\":54503,\"start\":54481},{\"end\":54966,\"start\":54910},{\"end\":55413,\"start\":55311},{\"end\":55900,\"start\":55884},{\"end\":56326,\"start\":56300},{\"end\":56688,\"start\":56622},{\"end\":56952,\"start\":56908},{\"end\":57209,\"start\":57158},{\"end\":57654,\"start\":57615},{\"end\":58037,\"start\":58018},{\"end\":58319,\"start\":58246},{\"end\":58801,\"start\":58747},{\"end\":59163,\"start\":59091},{\"end\":59645,\"start\":59619},{\"end\":60127,\"start\":60104},{\"end\":60481,\"start\":60420},{\"end\":60936,\"start\":60824},{\"end\":61696,\"start\":61644},{\"end\":62237,\"start\":62125},{\"end\":54989,\"start\":54968},{\"end\":60529,\"start\":60483},{\"end\":61076,\"start\":61057},{\"end\":62302,\"start\":62277}]"}}}, "year": 2023, "month": 12, "day": 17}