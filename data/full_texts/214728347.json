{"id": 214728347, "updated": "2023-10-06 17:42:24.018", "metadata": {"title": "Inverting Gradients -- How easy is it to break privacy in federated learning?", "authors": "[{\"first\":\"Jonas\",\"last\":\"Geiping\",\"middle\":[]},{\"first\":\"Hartmut\",\"last\":\"Bauermeister\",\"middle\":[]},{\"first\":\"Hannah\",\"last\":\"Droge\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Moeller\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 3, "day": 31}, "abstract": "The idea of federated learning is to collaboratively train a neural network on a server. Each user receives the current weights of the network and in turns sends parameter updates (gradients) based on local data. This protocol has been designed not only to train neural networks data-efficiently, but also to provide privacy benefits for users, as their input data remains on device and only parameter gradients are shared. In this paper we show that sharing parameter gradients is by no means secure: By exploiting a cosine similarity loss along with optimization methods from adversarial attacks, we are able to faithfully reconstruct images at high resolution from the knowledge of their parameter gradients, and demonstrate that such a break of privacy is possible even for trained deep networks. Moreover, we analyze the effects of architecture as well as parameters on the difficulty of reconstructing the input image, prove that any input to a fully connected layer can be reconstructed analytically independent of the remaining architecture, and show numerically that even averaging gradients over several iterations or several images does not protect the user's privacy in federated learning applications in computer vision.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2003.14053", "mag": "3105285631", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/GeipingBD020", "doi": null}}, "content": {"source": {"pdf_hash": "698ab1cc02a79596a87f92d5a0882ab1a7aee266", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2003.14053v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "9b8e4b4877bd4d780cb4a306727cbee2ac548374", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/698ab1cc02a79596a87f92d5a0882ab1a7aee266.txt", "contents": "\nInverting Gradients -How easy is it to break privacy in federated learning?\n\n\nJonas Geiping jonas.geiping@uni-siegen.de \nDepartment of Electrical Engineering and Computer Science\nUniversity of Siegen H\u00f6lderlinstra\u00dfe 3\n57076Siegen\n\nHartmut Bauermeister hartmut.bauermeister@uni-siegen.de \nDepartment of Electrical Engineering and Computer Science\nUniversity of Siegen H\u00f6lderlinstra\u00dfe 3\n57076Siegen\n\nHannah Dr\u00f6ge hannah.droege@uni-siegen.de \nDepartment of Electrical Engineering and Computer Science\nUniversity of Siegen H\u00f6lderlinstra\u00dfe 3\n57076Siegen\n\nMichael Moeller michael.moeller@uni-siegen.de \nDepartment of Electrical Engineering and Computer Science\nUniversity of Siegen H\u00f6lderlinstra\u00dfe 3\n57076Siegen\n\nInverting Gradients -How easy is it to break privacy in federated learning?\nInverse ProblemsComputer VisionDeep LearningPri- vacyFederated LearningAdversarial AttacksDifferential Privacy\nThe idea of federated learning is to collaboratively train a neural network on a server. Each user receives the current weights of the network and in turns sends parameter updates (gradients) based on local data. This protocol has been designed not only to train neural networks data-efficiently, but also to provide privacy benefits for users, as their input data remains on device and only parameter gradients are shared. In this paper we show that sharing parameter gradients is by no means secure: By exploiting a cosine similarity loss along with optimization methods from adversarial attacks, we are able to faithfully reconstruct images at high resolution from the knowledge of their parameter gradients, and demonstrate that such a break of privacy is possible even for trained deep networks. Moreover, we analyze the effects of architecture as well as parameters on the difficulty of reconstructing the input image, prove that any input to a fully connected layer can be reconstructed analytically independent of the remaining architecture, and show numerically that even averaging gradients over several iterations or several images does not protect the user's privacy in federated learning applications in computer vision.\n\nIntroduction\n\nFederated or collaborative learning [7,32] is a distributed learning paradigm that has recently gained significant attention as both data requirements and privacy concerns in machine learning continue to rise [24,17,36]. The basic idea is to train a machine learning model, for example a neural network, by optimizing the parameters \u03b8 of the network using a loss function L and exemplary training data consisting of input images x i and corresponding labels y i in order to solve\nmin \u03b8 N i=1 L \u03b8 (x i , y i ).(1)\nWe consider a distributed setting in which a server wants to solve (1) with  the help of multiple users that own training data (x i , y i ). The idea of federated learning is to only share the gradients \u2207 \u03b8 L \u03b8 (x i , y i ) instead of the original data (x i , y i ) with the server which it subsequently accumulates to update the overall weights. Using gradient descent the server's updates could, for instance, constitute\n\u03b8 k+1 = \u03b8 k \u2212 \u03c4 N i=1 server \u2207 \u03b8 L \u03b8 k (x i , y i ) users .(2)\nFinally the updated parameters \u03b8 k+1 are sent back to the individual users. The procedure in eq. (2) is called federated SGD. In contrast, in federated averaging [19,24] each user computes several gradient descent steps locally, and sends the updated parameters back to the server. Because user data is not shared across the network, distributed learning of this kind has also been used in real-world applications where user privacy is crucial, e.g. for hospital data [16] or text predictions on mobile devices [3]. Ideally, any such approach is combined with provable guarantees of differential privacy [10,25] and secure aggregation [4], however it is also generally understood that \"Privacy is enhanced by the ephemeral and focused nature of the [Federated Learning] updates\" [3]: model updates are considered to contain less information than the original data, and through aggregation of updates from multiple data points, original data is considered impossible to recover. In this work we show analytically as well as empirically, that parameter gradients still carry significant information about the supposedly private input data as we illustrate in Fig. 1.\n\nFrom a standpoint of privacy, we are interested in possible leaks of user-level privacy against a (mostly) honest-but-curious server. Both differential privacy and secure aggregation can be costly to implement so that there is some incentive for data companies to follow regulations in letter, but not in spirit, e.g. by using bare federated learning. For a more general discussion, see [34].\n\nIn this paper we discuss privacy limitations of federated learning in theory and practice, and can summarize our key findings as follows:\n\n-Reconstruction of input data from gradient information is possible for realistic deep architectures with both, trained and untrained parameters. -With the right attack, there is little \"defense-in-depth\" -deep networks are as vulnerable as shallow networks. -We prove that the input to any fully connected layer can be reconstructed analytically independent of the remaining network architecture. -Especially dishonest-and-curious servers (which may adapt the architecture or parameters maliciously) excel in information retrieval, and dishonesties can be as subtle as permuting some network parameters. -Federated averaging confers no security benefit compared to federated SGD.\n\n-Reconstruction of multiple, separate input images from their averaged gradient is possible in practice, even for a batch of size of 100 images.\n\n\nRelated Work\n\nPrevious related works that investigate recovery from gradient information have been limited to shallow networks of less practical relevance. Recovery of image data from gradient information was first discussed in [29,28] for neural networks, who illustrate analytically that recovery is possible for a single neuron or linear layer. Moving to convolutional architectures, [35] show that recovery is possible for a 4-layer CNN, albeit with a significantly large fully-connected (FC) layer. Their work first constructs a \"representation\" of the input image, that is then improved with a GAN. This approach works well for datasets with low inter-class variation, such as in facial and digit recognition. \nx ||\u2207 \u03b8 L \u03b8 (x, y) \u2212 \u2207 \u03b8 L \u03b8 (x * , y)|| 2(3)\nis minimized to recover the original input image x * from a transmitted gradient \u2207 \u03b8 L \u03b8 (x * , y). This optimization problem is solved by an L-BFGS solver [21]. Note that differentiating the gradient of L w.r.t to x requires a second-order derivative of the considered parametrized function and L-BFGS needs to construct a thirdorder derivative approximation, which is challenging for neural networks with ReLU units for which higher-order derivatives are discontinuous.\n\nA related, but easier problem, compared to the full reconstruction of input images, is the retrieval of input attributes [26,12] from local updates, e.g. does a person that is recognized wear a hat. Information even about attributes unrelated to the task at-hand can be recovered even from deeper layers of a neural network, which can be recovered from local updates.\n\nOur problem statement is furthermore related to model inversion [11], where training images are recovered from the final network parameters. This provides a natural limit case for our setting. Model inversion generally is challenging for deeper neural network architectures [38] if no additional information is given [11,38]. Another closely related task is inversion from visual representations [9,8,23], where, given the output of some intermediate layer of a neural network, a plausible input image is reconstructed. This procedure can leak some information, e.g. general image composition, dominating colors -but, depending on the given layer it only reconstructs similar images -if the neural network is not explicitly chosen to be (mostly) invertible [15]. As we prove later, inversion from visual representations is strictly more difficult than recovery from gradient information for classification networks.\n\n\nReconstruction Method\n\nPrevious reconstruction algorithms relied on two components; the euclidean cost function of Eq. (3) and optimization via L-BFGS. We argue that these choices are not optimal, especially for more complicated architectures. Instead we propose, firstly, to use a cost function based on cosine similarity, l(x, y) = x,y ||x||||y||| . Gradient magnitude appears not to be an important factor and we search only for images that match the normalized ground truth gradient in direction. We further constrain our search space to images within [0, 1] and add only total variation [31] as a simple image prior to the overall problem, cf.\n\n[35]:\narg min x\u2208[0,1] n 1 \u2212 \u2207 \u03b8 L \u03b8 (x, y), \u2207 \u03b8 L \u03b8 (x * , y) ||\u2207 \u03b8 L \u03b8 (x, y)||||\u2207 \u03b8 L \u03b8 (x * , y)|| + \u03b1 TV(x).(4)\nSecondly, we note that our goal of finding some inputs x in a given interval by minimizing a quantity that depends (indirectly, via their gradients) on the outputs of intermediate layers, is related to the task of finding adversarial perturbations for neural networks [33,22,1]. As such, we minimize eq. (4) only based on the sign of its gradient, which we optimize with Adam [18] with step size decay. We further augment this \"attack\" by employing random restarts [27]. Aside from this basic setting, we consider two improvements for special cases. First, for deep networks, we find that if we consider the gradient of each parameter (e.g weights, biases...) separately, then some gradients do not contribute as much to the reconstruction, especially if their gradient norm is small. In those cases, we apply a modification of eq. (4), recovering the input only from the gradients of the N parameters with largest gradient norm, see appendix. Further, we note that for several ImageNet architectures, the first two layers (e.g. 7x7 convolutions with stride 2 and max pooling) introduce significant noise -we counter this by applying median filtering. Applying these techniques leads to the reconstruction observed in Fig. 1. Further ablation of the proposed mechanism can be found in the appendix and a PyTorch implementation can be downloaded from https://github.com/ JonasGeiping/invertinggradients.\n\nRemark 1 (Optimizing label information). While we could also consider the label y as unknown in Eq. (4) and optimize jointly for (x, y) as in [41], we follow [39] who find that label information can be reconstructed from the last classification layer for classification tasks. As such we consider label information to be known.\n\n\nComparison to Baselines\n\nWe first validate our approach by comparison to previous reconstructions from [35] and [41]. As shown in Fig. 2, using LBFGS for the L2 loss of (3) works well for the shallow and smooth architecture of [41] and still reasonably for the shallow architecture of [35], however for a more conventional ConvNet architecture (7 convolutional layers with max pooling and batch normalization, following by a FC layer, cf.\n\n[20], see supp. material) or ResNet [14] architectures, here [37], the reconstruction quality degrades significantly. Note that [35] applied a GAN to enhance image quality from the LBFGS reconstruction, which is called 'representative of victim' there. However this approach fails, when the representative is too distorted to be enhanced.\n\n\nThe Impact of Architecture\n\nIn this section we study the influence of the network architecture on the \"difficulty\" of determining an input image from the parameter gradient from a theoretical as well as an empirical perspective.\n\n\nTheoretical Characteristics\n\nFor now we restrict ourselves to reconstructing a single input image x \u2208 R n from the gradient \u2207 \u03b8 L \u03b8 (x, y) \u2208 R p . First of all, due to the different dimensionality of x and \u2207 \u03b8 L \u03b8 (x, y), the reconstruction is a question of the number of parameters p versus input pixels n. If p < n, then reconstruction is at least as difficult as image recovery from incomplete data [5,2]. Aside from this theoretical limit, even when p > n, which we would expect in most computer vision applications, the difficulty of regularized \"inversion\" of \u2207 \u03b8 L \u03b8 relates to the nonlinearity of the operator as well as its condition. In the simplest case reconstruction is also a linear inverse problem, yet for a deep neural networks, complexity mounts.\n\nFully-connected layers In this section we show that the input to a fullyconnected layer can be computed from the parameter gradients analytically independent of the layer's position in a neural network and the specific types of preceding and succeeding layers. Thus, any network containing a biased fullyconnected layer preceded solely by (possibly unbiased) fully-connected layers including ReLU activations allows an analytical reconstruction of the input image provided that a technical condition, which prevents zero-gradients, is met. In particular, a single input to a fully-connected network can be reconstructed without any optimization problem like (4).\n\nIn the following we use the notation dL d\u03b8 A for the derivative of a scalar loss function L w.r.t. to the entries of a (possibly multi-dimensional) parameter \u03b8 A . dL d\u03b8 A is hence of the same dimensionality as \u03b8 A and each entry in dL d\u03b8 A is the derivative of L w.r.t. the according entry in \u03b8 A . The considerations below are independent of the specific choice of L. Therefore we will implicitly assume that L decomposes intoL \u2022 f whereL is the usual loss function taking the network's outputs and f denotes the composition of the network's layers following the below considered modules. This in turn means, results based solely on L instead ofL do not depend on a module's position in the network.\n\nThe following statement is a generalization of Example 3 in [28] to the setting of arbitrary neural networks with arbitrary loss functions: Proposition 1. Let a neural network contain a biased fully-connected layer at some point, i.e. for the layer's input v \u2208 R n its output z \u2208 R m is calculated as\nz = \u03b8 A v + \u03b8 b ,(5)\nfor \u03b8 A \u2208 R m\u00d7n and \u03b8 b \u2208 R m . Then the input v can be reconstructed from dL\nd\u03b8 A and dL d\u03b8 b , if there exists an index i s.t. dL d(\u03b8 b ) i = 0.\nProof. See supplementary material.\n\nThe knowledge of the derivative w.r.t. the bias is essential for reconstructing the layer's input in Proposition 1. However, even for unbiased fully-connected layers followed by ReLU activations we can reconstruct the input from the layer's weights if we have the additional information of the derivatives of the loss w.r.t. the layer's output:\nProposition 2.\nConsider a fully-connected layer (not necessarily including a bias) followed by a ReLU activation function, i.e. for an input v \u2208 R n the output z \u2208 R m is calculated as\nz = max {\u03b8 A v, 0} ,(6)\nwhere the maximum is computed element-wise. Now assume we have the additional knowledge of the derivative w.r.t. to the output dL dz . Furthermore assume there exists an index i s.t. dL dzi > 0. Then the input v can be derived from the knowledge of dL d\u03b8 A .\n\nProof. See supplementary material.\n\nCombining both observations for biased an unbiased fully-connected layers yields the following result: Corollary 1. For any neural network containing a biased fully-connected layer preceded solely by (possibly unbiased) fully-connected layers, the input to the network can be reconstructed uniquely from the network's gradients if the assumptions of Propositions 1 and 2 are fulfilled.\n\nAnother interesting aspect in view of the above considerations is that many popular network architecture use fully-connected layers (or cascades thereof) as their last prediction layers. Hence the input to those prediction modules being the output of the previous layers can be reconstructed. Those activations usually already contain some information about the input image thus exposing them to attackers. Especially interesting in that regard is the possibility to reconstruct the ground truth label information purely from the gradients of the last (possibly unbiased) fully-connected layer as discussed in [39].\n\nThe architectures used for the classification networks in [26], for example, make use of fully-connected layers at the end of the network. As we are capable of reconstructing the input of those layers analytically, the image reconstruction task reduces to inverting the image using both, the convolutions' output and the gradient information of their weights. More generally, for any classification network that ends with a fully connected layer, reconstructing the input from a parameter gradient is strictly easier than inverting visual representations from their last convolutional layer. \n\n\nEmpirical Analysis\n\nIn this section we investigate the possibility to reconstruct a network's input from the parameter gradient in settings beyond our theoretical analysis using the method proposed in Sec. 3. Fig. 4 shows the reconstruction quality of a 32 \u00d7 32 image using two different kinds of architectures. Namely the ResNet-20 architecture and the ConvNet architecture. Hyperparameter settings and visual results for each experiment are specified in the supplementary material.\n\nNetwork Width. The convolutional channel dimension has a great influence on the reconstruction quality as shown in Fig. 3. The displayed dimensions each describe the channel dimension of the first convolution layer of the networks. This effect is also visible in Fig. 4, which shows two reconstruction results corresponding to the results PSNR values in Fig. 3 using ResNet-20. Network Depth. Besides the width, we also tested the influence of the depth of the network on the reconstruction quality using ResNet architectures of different depths. As shown in Fig. 4 there is a slight but no significant difference in the reconstruction quality between the differently deep neural network architectures.\n\nSpatial Information. Surprised by the accurate localization of the objects in the image despite the commonly believed robustness of convolutions to translations, we test how a conventional convolutional neural network (CNN), that uses convolutions with zero-padding, compares to a provably translationally invariant CNN, that uses convolutions with circular padding. As shown in the inset figure, while the conventional CNN allows for recovery of a rather high quality image (left), the translationally invariant network makes the localization of objects significantly harder (right) as the original image content seems to scatter.  Pooling Layer. Inverting an input to an average pooling layer solely from its output is heavily underdetermined. The gradient information of the input, however, can be precisely recovered from the gradient of the output. Intuitively, this property should have a beneficial effect on the task of image reconstruction from gradients. Max pooling, in contrast, provides neither information about the exact input nor about the derivative thereof and hence should hamper the inversion problem. Indeed, this conjecture is corroborated by experimental findings: Replacing the max pooling layers in the ConvNet architecture by average pooling boosts the quality of the image reconstruction from a PSNR value of 11.18 to 17.87. Similarily, the reconstruction task gets more difficult for replacing the average pooling layers in the ResNet architecture by max pooling, details can be found in the supplementary materials.\n\n\nDishonest Architectures\n\nSo far we assumed that the server operates under an honest-but-curious model, and as such would not modify the model maliciously to make reconstruction easier. If we allow for this, then reconstruction becomes nearly trivial. Several mechanisms could be used: Following Prop. 2, the server could, for example, place a fully-connected layer in the first layer, or even directly connect the input to the end of the network by concatenation. Slightly less obvious, the model could be modified to contain reversible blocks [6,15]. These blocks allow the recovery of input from their outputs. From Prop. 1 we know that we can reconstruct the input to the classification layer, so this allows for immediate access to the input image. If the server maliciously introduces separate weights for each batch example, then this also allows for a recovery of an arbitrarily large batch of data. Operating in a setting, where such behavior is possible would require the user (or a provider trusted by the user) to vet any incoming model either by hand or programmatically.\n\n\nConvNet\n\nResNet20-4\n\n6.1e-1 19.34dB 6.7e-1 19.14dB 3.8e+1 9.88dB 4.5e+1 8.21dB Fig. 5: Reconstruction quality for CIFAR images for untrained ConvNet and ResNet20-4. Gradient magnitude is report below each input and PSNR are reported below each output.\n\n\nThe Impact of Parameters\n\nThe architecture is, however, not the only factor determining the reconstruction quality. The state of the network's parameters also plays a crucial role. Several mechanisms are at work here, which we will detail with several experiments that are shown in Fig. 5,6,7 and discussed in the following subsections.\n\n\nGradient Information\n\nThe gradient of a data point, here an image, is directly connected to minimizers of L \u03b8 . Any data point that is a (local) minimizer of L \u03b8 has a gradient of 0.\n\nIf the network has enough capacity so that multiple data points can be local minimizers simultaneously, then they can never be distinguished from their gradient. However, in practical settings, owing to stochastic gradient descent, data augmentation and a finite number of training epochs, the gradient of images is rarely entirely zero. In Fig. 5, we show the reconstruction for untrained networks. The gradients of all considered images lie in a magnitude range of [0. 1,10]. Likewise all images can be reconstructed with reasonable success. However, after training the networks (120 epochs on CIFAR-10 data with data augmentation, both networks reach validation accuracies of > 90%), the picture changes. The images shown in Fig. 6 are those with minimal gradient norm for these trained networks. Especially for the ConvNet architecture, the minimal gradient norm is very close to zero (considering all computations are done in single precision). The reconstruction quality is accordingly lacking -however it is surprising that for the crow image some image content is still recognizable for human observers -even if it is heavily distorted. For the ResNet gradient norms remain higher than for the ConvNet and reconstruction quality is accordingly improved. We also examined whether there is noticeable difference between the image with smallest norm from the training and from the validation set -however the reconstruction does not seem to benefit from the fact, that the image had been seen before during training.\n\n\nTranslational Invariance\n\nBoth networks are trained with standard data augmentation for CIFAR-10, and are as such trained to be invariant to translations. Comparing trained networks  to untrained networks, we find that this influences the reconstruction from both, small and large gradients. In Figure 6, note for example how the cat and the crow for the ConvNet, and the dog and the ship for the ResNet are translated away from their original position. This effect does not arise for the untrained networks in Figure 5, if circular convolutions are not used, cf. Sec. 4.2. Image reconstruction still succeeds, and privacy is breached, yet some location information has clearly been lost.\n\n\nSelf-regularizing effects\n\nAnother effect that only happens in trained networks is that the reconstructed images are implicitly biased to look like an image from their own class. This is only marginally visible for the CIFAR images, but for example, the horses in Fig. 6 contain a purple background not present in the original image. Moving to networks trained on ImageNet and images from the ImageNet validation set in Figures 1 and 7 clarifies this effect. Note how the reconstructions from the untrained ResNet-18 noisy, but faithful recoveries of the input data, yet the reconstructions from a Resnet18 trained on ImageNet data, are more generativethe eyes of the owl in Fig. 1 are larger than they should be, and its fur pattern does not exactly match the input image. Likewise for the dog (aside from the translation effect), the snout deviates in proportions to its input. Even without the inclusion of external image priors, i.e. [35,8], the minimization of the reconstruction loss of Eq. 4 hence biases the results. This effect does seem to help preserve some privacy. For small features it may be uncertain if they are actually present in the input data, or just representative of the training data. \n\n\nDishonest Parameter Vectors\n\nUnder a dishonest server model, the choice of parameters can significantly influence reconstruction quality. For example, considering the network architecture in [41] which does not contain strides and flattens convolutional features, the dishonest server could set all convolution layers to represent the identity [13], moving the input through the network unchanged up to classification layer, from which the input can be analytically computed as in Prop 2. Likewise for an architecture that contains strides to a recognizable lower resolution [35], the input can be recovered immediately albeit in a smaller resolution. Such a specific choice of parameters is however likely detectable. A subtler approach, as least possible in theory, would be to optimize the network parameters themselves that are sent to the user so that reconstruction quality from these parameters is maximized. While such an attack is likely to be difficult to detect on the user-side, it would also be very computationally intensive.\n\nLabel flipping. Yet, we can devise a cheaper alternative. According to subsection 5.1, very small gradient vectors contain less information. A simple way for a dishonest server to boost these gradients is to permute two rows in the weight matrix and bias of the classification layer, effectively flipping the semantic meaning of a label. This attack is difficult to detect for the user (as long as the gradient magnitude stays within usual bounds), but effectively tricks him into differentiating his network w.r.t to the wrong label. Fig. 8 shows that this mechanism can allow for the reconstruction of images that were difficult in Fig.  6, as the advantage of the trained model is negated.\n\n\nAdvanced Reconstruction Problems\n\nSo far we have only considered recovery of a single image from its gradient and discussed limitations and possibilities in this setting. We now turn to two advanced settings, to show that the proposed improvements translate to these 5.9e-1 17.35dB 4.6e+2 14.60dB 1.8e+2 15.35dB 1.5e+2 6.25dB Fig. 8: Label flipping. The images that were difficult to reconstruct in Fig. 6 can be easily reconstructed when two rows in the parameters of the final classification layer are permuted. Below each input image is given the gradient magnitude, below each output image its PSNR.\n\npractical cases as well. We consider recovery of a full batch of images and recovery from federating averaging updates.\n\n\nFederated Averaging\n\nInstead of only calculating the gradient of a network's parameters based on local data, federated averaging [25,30] proposes performing multiple gradient descent steps locally before sending the updated parameters back to the server. While this approach benefits from a improved training performance [24] compared to methods only conducting one local update step, like federated SGD, it also faces inherent difficulties like client drift, which is the user's bias toward his own data [40] -practically limiting in the number of local gradient descent steps.  We empirically show that the setting of federated averaging is potentially amenable for attacks. To do so we compare the difference between the local update and the old parameters and unroll the local update steps. For the experiment in Figure 9 we use an untrained ConvNet. Even for a high number of 100 local gradient descent steps the reconstruction quality seems unimpeded. The Although most images are unrecognizable, privacy is broken even in a large-batch setting. We refer to the supplementary material for all images. only failure case we were able to exemplify was induced by picking a high learning rate of 1e-1. This setup, however, likely corresponds to an unstable training procedure of the user's network introducing high variance on the update steps which might cause the noise in the reconstructed image. Further details on the training setup can be found in the supplementary materials.\n\n\nMulti-Image Recovery\n\nSo far we have considered the recovery of a single image only, and it seems reasonable to believe that averaging the gradients of multiple (local) images before sending an update to the server, restores the privacy of federated learning. While such a multi-image recovery has been considered in [41] for a few images before, we demonstrate that the proposed approach is capable of restoring some information from a batch of 100 averaged gradients: While most recovered images are unrecognizable (as shown in the supplementary material), Fig. 10 shows the 5 most recognizable images and illustrates that even averaging the gradient of 100 images does not entirely secure the private data.\n\n\nConclusions\n\nFederated learning is a modern paradigm shift in distributed computing, yet its benefits to privacy are not as well understood yet. We shed light into possible avenues of attack, analyzed the ability to reconstruct the input to any fully connected layer analytically, proposed a general optimization-based attack, and discussed its effectiveness for different types of architectures and network parameters. Our results clearly indicate that provable differential privacy remains the only way to secure information, even for large batches of data points. We note in Sec. 3, that we can improve performance on deep networks by recovering the input only from the gradients of the N parameters with largest norm. To clarify this method we need to briefly depart from the notation of the remaining paper. Instead of considering \u2207 \u03b8 L \u03b8 to be a single vector in R p , note that we can separately consider the gradient of each 'parameter' of the network, meaning each tensor, w.r.t to which the network is differentiated, e.g. convolutional filters of a single layer, biases and weight matrices of fully-connected layers, so that \u2207 \u03b8 L \u03b8 (x, y) can be represented by {\u2207 \u03b81 L \u03b8 (x, y), . . . , \u2207 \u03b8 P L \u03b8 (x, y)} for P parameters.\n\nWe may now compute the norm of each of the gradient vectors separately. From these P norm values we choose the N values that are largest, i.e. the N parameters that contain the largest gradients and collect their indices in the set M . This leads to a minor modification of the proposed cost function that can now be specified as: Fig. 11: Network architecture ConvNet, consisting of 8 convolution layers, specified with corresponding number of output channels. Each convolution layer is followed by a batch normalization layer and a ReLU layer. D scales the number of output channels and is set to D = 64 by default.\narg min x\u2208[0,1] n 1 \u2212 j\u2208M \u2207 \u03b8 j L \u03b8 (x, y), \u2207 \u03b8 j L \u03b8 (x * , y) j\u2208M ||\u2207 \u03b8 j L \u03b8 (x, y)|| 2 j\u2208M ||\u2207 \u03b8 j L \u03b8 (x * , y)|| 2 + \u03b1 TV(x).(7)\n\nB.2 Federated Averaging\n\nThe extension of Eq. (4) to the case of federated averaging (in which multiple local update steps are taken and sent back to the server) is straightforward. Notice first, that given old parameters \u03b8 k , local updates \u03b8 k+l , learning rate \u03c4 , and knowledge about the number of update steps 1 , the update can be rewritten as the average of updated gradients.\n\u03b8 k+l = \u03b8 k \u2212 \u03c4 l m=1 \u2207 \u03b8 k+m L \u03b8 k+m (x, y)(8)\nSubtracting \u03b8 k from \u03b8 k+l , we simply apply the proposed approach to the resulting average of updates:\narg min x\u2208[0,1] n 1\u2212 l m=1 \u2207 \u03b8 k+m L \u03b8 k+m (x, y), l m=1 \u2207 \u03b8 k+m L \u03b8 k+m (x * , y) || l m=1 \u2207 \u03b8 k+m L \u03b8 k+m (x, y)|||| l m=1 \u2207 \u03b8 k+m L \u03b8 k+m (x * , y)|| +\u03b1 TV(x).(9)\nUsing automatic differentiation, we backpropagate the gradient w.r.t to x from the average of update steps.\n\n\nB.3 ConvNet\n\nWe use a ConvNet architecture as a baseline for our experiments as it is relatively fast to optimize, reaches above 90% accuracy on CIFAR-10 and includes two max-pooling layers. It is a rough analogue to AlexNet [20]. The architecture is described in Fig. 11 \n\n\nB.4 Ablation Study\n\nWe provide an ablation for proposed choices in Table 1. We note that two things are central, the Adam optimizer and the similarity loss. Total variation is a small benefit, and using signed gradients is a minor benefit. The box constraints do not seem to help in this case, yet we keep them in any case to always guarantee that a valid image is recovered.\n\n\nC Hyperparameter Settings\n\nIn our experiments we reconstruct the network's input using signed Adam as optimization function and the cosine similarity for cost function as described in Sec. 3. Table 2 shows three different hyperparameter settings that are used during the experiments. We always initialize our reconstructions from a Gaussian distribution with mean 0 and variance 1 (Note that the input data is normalized as usual for all considered datasets).\n\nStep Size refers to the step size of the optimization algorithm, here Adam, during the reconstruction process, which runs for Number of Iterations many iterations. The step size decay is always fixed, occuring after 3 8 , 5 8 and 7 8 of iterations and reducing the learning rate by a factor of 0.1 each time. The reconstruction is started Restarts times, taking the best result regarding the cosine loss. Pretrained indicates if and how long the given network is pretrained, here trained with standard data augmentation for CIFAR-10. This is a mechanical requirement for the deeper networks, as the purely untrained networks cannot propagate information through the network without running-mean and running-variance estimates for the batch normalization layers.\n\n\nC.1 Settings for section 3\n\nFor comparison with baselines in section 3, we re-implemented the networks from Pooling Layer Results for a reconstruction using the max pooling layer and using the average pooling layer for the ConvNet are visualized in Fig. 14.\n\n\nSetting (A)\n\nStep   \n\n\nC.3 Settings for Section 5\n\nFor Fig. 6 we use settings (A) for all experiments, but increase the total variation penalty to 1e\u22123 and the number of iterations to 24000. For Fig. 7 we use settings   (B), but increase the number of iterations to 24000. For the untrained networks, we enable median filtering as discussed in Sec. 3.1 and the trained networks, we only increase the total variation penalty to 0.1.\n\n\nC.4 Setting for Section 6\n\nFor the multi-image recovery we also use settings (A), but increase the number of iterations to 24000 and the total variation penalty to 0.01. Due to the depth of the considered network (WideResNet 32-10 [37]), we also pretrain to 10 epochs.\n\nD Proofs for section 4.1 Proposition 1. Let a neural network contain a biased fully-connected layer at some point, i.e. for the layer's input v \u2208 R n its output z \u2208 R m is calculated as\nz = \u03b8 A v + \u03b8 b ,(10)\nfor \u03b8 A \u2208 R m\u00d7n and \u03b8 b \u2208 R m . Then the input v can be reconstructed from dL \n= dL db i \u00b7 x T(11)\nfor (\u03b8 A ) i, : denoting the i th row of \u03b8 A . Hence x can can be uniquely determined as soon as dL\nd\u03b8 b i = 0.\nProposition 2. Consider a fully-connected layer (not necessarily including a bias) followed by a ReLU activation function, i.e. for an input v \u2208 R n the output z \u2208 R m is calculated as\nz = max {\u03b8 A v, 0} ,(13)\nwhere the maximum is computed element-wise.  Fig. 15 shows further reconstructions on ImageNet validation images for a trained ResNet-18 (the same setup as Fig. 7 in the main paper). We show a very good reconstruction (German shepherd), a good, but translated reconstruction (giant panda) and two failure cases (ambulance and flower). For the ambulance, for example, the actual writing on the ambulance car is still hidden. For the flower, the exact number of petals cannot is hidden. Also, note how the reconstruction of the giant panda is much clearer than that of the tree stump co-occuring in the image, which we consider an indicator of the self-regularizing effect described in Sec. 5.3.\n= dL dz i \u00b7 v T .(14)\n\nE Examples\n\n\nE.1 More ImageNet examples\n\n\nE.2 Multi-Image Recovery\n\nFor multi-image recovery, we show the full set of 100 images in Fig. 16, we recommend to zoom in to a digital version of the figure. The success rate for separate images is semi-random, depending on the initialization. To show this, we repeat the same experiment in Fig. 17. Here, trout (the gray fish) and cockroach are again easily recognizable, yet the ladybug and the squirrel are less recognizable.\n\nHowever other examples, such as sweet pepper, chimpanzee, rocket and lobster are now more recognizable.\n\nImages are following on the next page.  \n\nFig. 1 :\n1Reconstruction of an input image x from the gradient \u2207 \u03b8 L \u03b8 (x, y) of a ResNet-18. Left: Image from the validation dataset. Middle: Reconstruction from an untrained ResNet-18. Right: Reconstruction from a ResNet-18 trained on ImageNet. In both cases, the intended privacy of the image is broken.\n\nFig. 3 :\n3Effect of channel dimension on the PSNR value of the image reconstruction for the ResNet-20 architecture (red) and the ConvNet architecture (blue).With increasing feature map dimension, the reconstruction quality of the input image increases.\n\nFig. 4 :\n4Reconstructions of the original image (left) for multiple ResNet architectures. The ResNet-20 architecture in displayed for two different widths.While wider networks make the reconstruction significantly easier, the depth seems to have little influence on the reconstruction quality.\n\nFig. 6 :\n6Reconstruction of images for the trained ConvNet model (Top) andResNet20-4 (bottom). We show reconstructions of the images with the smallest gradient norm and with the highest gradient norm for both the training and the validation set. Below each input image is given the gradient magnitude, below each output image its PSNR.\n\nFig. 7 :\n7ImageNet: Difference between trained and untrained model. From left to right: Input image, reconstruction for an untrained ResNet-18, reconstruction for a ResNet-18 trained on ImageNet. Reconstructions on the trained model exhibit both a drift in translation and a self-regularizing effect.\n\nFig. 9 :\n9Illustrating the influence of the number of local update steps and the learning rate on the reconstruction: The left two images compare the influence of the number of gradient descent steps for a fixed learning rate of \u03c4 =1e-4. The two images on the right result from varying the learning rate for a fixed number of 5 gradient descent steps. PSNR values are shown below the images.\n\nFig. 10 :\n10Information leakage for a batch of 100 images on CIFAR-100 for a ResNet32-10. Shown are the 5 most recognizable images from the whole batch.\n\n\n. Int. J. Radiat. Oncol. 99(2), 344-352 (Oct 2017). doi:10.1016/j.ijrobp.2017.04.021 17. Jochems, A., Deist, T.M., van Soest, J., Eble, M., Bulens, P., Coucke, P., Dries, W., Lambin, P., Dekker, A.: Distributed learning: Developing a predictive model based on data from multiple hospitals without data leaving the hospital -A real life proof of concept. Radiotherapy and Oncology 121(3), 459-467 (Dec 2016). doi:10.1016/j.radonc.2016.10.002 18. Kingma, D.P., Ba, J.: Adam: A Method for Stochastic Optimization. In: International Conference on Learning Representations (ICLR). San Diego (May 2015) 19. Kone\u010dn\u00fd, J., McMahan, B., Ramage, D.: Federated Optimization:Distributed Optimization Beyond the Datacenter. ArXiv151103575 Cs Math (Nov 2015) 20. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in Neural Information Processing Systems. pp. 1097-1105 (2012) 21. Liu, D.C., Nocedal, J.: On the limited memory BFGS method for large scale optimization. Mathematical Programming 45(1-3), 503-528 (Aug 1989). doi:10.1007/BF01589116 22. Madry, A., Makelov, A., Schmidt, L., Tsipras, D., Vladu, A.: Towards Deep Learning Models Resistant to Adversarial Attacks. ArXiv170606083 Cs Stat (Jun 2017) 23. Mahendran, A., Vedaldi, A.: Visualizing Deep Convolutional Neural Networks Using Natural Pre-images. Int. J. Comput. Vis. 120(3), 233-255 (Dec 2016). doi:10.1007/s11263-016-0911-8 24. McMahan, H.B., Moore, E., Ramage, D., Hampson, S., y Arcas, B.A.: Communication-Efficient Learning of Deep Networks from Decentralized Data. ArXiv160205629 Cs (Feb 2017) 25. McMahan, H.B., Ramage, D., Talwar, K., Zhang, L.: Learning Differentially Private Recurrent Language Models. ArXiv171006963 Cs (Feb 2018) 26. Melis, L., Song, C., De Cristofaro, E., Shmatikov, V.: Exploiting Unintended Feature Leakage in Collaborative Learning. In: 2019 IEEE Symposium on Security and Privacy (SP). pp. 691-706 (May 2019). doi:10.1109/SP.2019.00029 27. Mosbach, M., Andriushchenko, M., Trost, T., Hein, M., Klakow, D.: Logit Pairing Methods Can Fool Gradient-Based Attacks. ArXiv181012042 Cs Stat (Mar 2019) 28. Phong, L.T., Aono, Y., Hayashi, T., Wang, L., Moriai, S.: Privacy-Preserving Deep Learning: Revisited and Enhanced. In: Applications and Techniques in Information Security. pp. 100-110. Communications in Computer and Information Science, Springer, Singapore (2017). doi:10.1007/978-981-10-5421-1 9 29. Phong, L.T., Aono, Y., Hayashi, T., Wang, L., Moriai, S.: Privacy-Preserving Deep Learning via Additively Homomorphic Encryption. Tech. Rep. 715 (2017) 30. Reddi, S., Charles, Z., Zaheer, M., Garrett, Z., Rush, K., Kone\u010dn\u00fd, J., Kumar, S., McMahan, H.B.: Adaptive Federated Optimization. ArXiv200300295 Cs Math Stat (Feb 2020) 31. Rudin, L.I., Osher, S., Fatemi, E.: Nonlinear total variation based noise removal algorithms. Physica D: Nonlinear Phenomena 60(1), 259-268 (Nov 1992). doi:10.1016/0167-2789(92)90242-F 32. Shokri, R., Shmatikov, V.: Privacy-Preserving Deep Learning. In: Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security -CCS '15. pp. 1310-1321. ACM Press, Denver, Colorado, USA (2015). doi:10.1145/2810103.2813687 33. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fergus, R.: Intriguing properties of neural networks. In: arXiv:1312.6199 [Cs] (Dec 2013) 34. Veale, M., Binns, R., Edwards, L.: Algorithms that remember: Model inversion attacks and data protection law. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 376(2133), 20180083 (Nov 2018). doi:10.1098/rsta.2018.0083 35. Wang, Z., Song, M., Zhang, Z., Song, Y., Wang, Q., Qi, H.: Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning. ArXiv181200535 Cs (Dec 2018) 36. Yang, Q., Liu, Y., Chen, T., Tong, Y.: Federated Machine Learning: Concept and Applications. ArXiv190204885 Cs (Feb 2019) 37. Zagoruyko, S., Komodakis, N.: Wide Residual Networks. ArXiv160507146 Cs (May 2016) 38. Zhang, Y., Jia, R., Pei, H., Wang, W., Li, B., Song, D.: The Secret Revealer: Generative Model-Inversion Attacks Against Deep Neural Networks. ArXiv191107135 Cs Stat (Nov 2019) 39. Zhao, B., Mopuri, K.R., Bilen, H.: iDLG: Improved Deep Leakage from Gradients. ArXiv200102610 Cs Stat (Jan 2020) 40. Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V.: Federated learning with non-iid data (2018) 41. Zhu, L., Liu, Z., Han, S.: Deep Leakage from Gradients. In: Advances in Neural Information Processing Systems 32, pp. 14774-14784. Curran Associates, Inc. (2019) A Appendix -Overview This appendix includes a closer description of the top-N variant, the baseline ConvNet architecture and the variant used to attack federated averaging (Sec. 6.2 in the main paper) in Sec. B. Further, hyperparameter settings for all experiments and visual representations of the results of Section 4.2 are recorded in C. Proofs of propositions of Sec. 4.1 of the main paper are included in Sec.D, and finally more examples for ImageNet-scale images and the full 100 images for the multi-image experiment of Sec. 6.1 are shown in Sec. E. B Clarifications of the proposed method B.1 Choosing top-N gradients\n\n\n[35] and [41], respectively and show reconstructions with the same LBFGS-L2 parameters as in their respective papers. For the comparison to more complicated CNNs, namely the ConvNet (Fig. 11) and the ResNet20-4 [37], we try to optimize parameters for LBFGS-L2. For the ConvNet, we ended up keeping the suggestions from [35], for the ResNet, we reduce the learning rate from [41] and also apply the top-N scheme, both of these changes improve the accuracy of the LBFGS-L2 approach for the ResNet. For our proposed method we apply settings (A) with a reduced step size of 0.01 for both MNIST experiments and settings (B) for the ResNet experiment. For the smooth network from [41], we reduce our step size to 0.0001 and increase the number of iterations to 48000. C.2 Settings and visual results for the experiments in Sec. 4.2 Network Width The network width experiments shown in Fig. 3 are generated with the settings (A) (ConvNet) and (B) (ResNet-20). The results for the ResNet-20 in Fig. 4 also refer to setting (B). Visual results are shown for different network architectures and settings in Fig. 12. Network Depth The experiments concerning the network depth are performed under the settings (C) for ResNet architectures. Multiple reconstruction results for different deep networks are shown in Fig. 13. Spatial Information The experiments on spatial information are performed on the ConvNet architecture with D = 64 channels and under setting (A).\n\nFig. 12 :\n12Reconstructions using two different neural network architectures with different widths. The first row displays the results using ConvNet (setting (A)), the following two rows display the results for the ResNet-20 architecture for setting (A) (second row) and (B) (third row).\n\nFig. 13 :\n13Reconstructions using different deep ResNet architectures, obtained using setting (C).\n\nFig. 14 :\n14Reconstructions on the ConvNet architecture using average pooling (left) for the pooling layers and using max pooling (right) for pooling layers.\n\n\nd\u03b8 b , if there exists an index i s.t. dL d(\u03b8 b ) i\n\nFig. 15 :\n15More ImageNet examples for a trained Resnet-18.\n\nFig. 16 :\n16Full results for the batch of CIFAR-100 images. Same experiment as inFig. 10of the paper.\n\nFig. 17 :\n17Full results for the batch of CIFAR-100 images. Rerun with the same hyperparameters.\n\n\ncan also be jointly reconstructed. They further show that reconstruction of multiple images from their averaged gradients is indeed possible. A direct follow-up [39] notes that label information can actually be computed analytically from the gradients of the last layer. Shallow structures with modifications such as large FC layers, removed strides [41], or smooth activations aid in the successful recovery of image information, which we will later discuss.The central recovery mechanism discussed in [35,41,39] is the optimization of an euclidean matching term. The cost function arg minThe recent NeurIPS publication \n[41] extends this, showing for a 4-layer CNN (with large FC layer and smooth \nsigmoid activations), that missing label information (which was crucial for [35] \nand guessed in [29]) \n\n\n. BFGS instead of Adam -2.40 dB L2 Loss instead of cosine similarity -0.38 dBTable 1: Ablation Study for the proposed approach for an untrained ConvNet architecture.Basic Setup \n19.36 dB \nWithout signed gradients \n19.29 dB \nWithout total variation \n18.80 dB \nGradient Descent instead of Adam -2.34 dB \nWithout box constraints \n19.37 dB \nWith L-\n\nTable 2 :\n2Three settings for the reconstruction of a network input, which were applied in the experiments in Sec. 4.216 Channels 32 Channels 64 Channels 128 Channels 256 Channels 512 Channels\n\n\nNow assume we have the additional knowledge of the derivative w.r.t. to the output dL dz . Furthermore assume there exists an index i s.t. dL dzi > 0. Then the input v can be derived from the knowledge of dL d\u03b8 A . Proof. As dL dzi > 0 it holds that dL d(Av) i= dL \ndzi and it follows that \n\ndL \ndA i, : \n= \ndL \nd (Av) i \n\u00b7 \nd (Av) i \ndA i, : \n\nWe assume that the number of local updates is known to the server, yet this could also be found by brute-force, given that l is a small integer.\nGeiping, Bauermeister, Dr\u00f6ge, Moeller\n\nObfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples. A Athalye, N Carlini, D Wagner, Cs. Athalye, A., Carlini, N., Wagner, D.: Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples. ArXiv180200420 Cs (Feb 2018)\n\nModern regularization methods for inverse problems. M Benning, M Burger, 10.1017/S0962492918000016Acta Numer. 27Benning, M., Burger, M.: Modern regularization methods for inverse problems. Acta Numer. 27, 1-111 (May 2018). doi:10.1017/S0962492918000016\n\nK Bonawitz, H Eichner, W Grieskamp, D Huba, A Ingerman, V Ivanov, C Kiddon, J Kone\u010dn\u00fd, S Mazzocchi, H B Mcmahan, T Van Overveldt, D Petrou, D Ramage, J Roselander, Towards Federated Learning at Scale: System Design. ArXiv190201046 Cs Stat. Bonawitz, K., Eichner, H., Grieskamp, W., Huba, D., Ingerman, A., Ivanov, V., Kiddon, C., Kone\u010dn\u00fd, J., Mazzocchi, S., McMahan, H.B., Van Overveldt, T., Petrou, D., Ramage, D., Roselander, J.: Towards Federated Learning at Scale: System Design. ArXiv190201046 Cs Stat (Mar 2019)\n\nPractical Secure Aggregation for Privacy Preserving Machine Learning. K Bonawitz, V Ivanov, B Kreuter, A Marcedone, H B Mcmahan, S Patel, D Ramage, A Segal, K Seth, Tech. Rep. 281Bonawitz, K., Ivanov, V., Kreuter, B., Marcedone, A., McMahan, H.B., Patel, S., Ramage, D., Segal, A., Seth, K.: Practical Secure Aggregation for Privacy Preserv- ing Machine Learning. Tech. Rep. 281 (2017)\n\nRobust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. E J Candes, J Romberg, T Tao, 10.1109/TIT.2005.862083IEEE Trans. Inf. Theory. 522Candes, E.J., Romberg, J., Tao, T.: Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. IEEE Trans. Inf. Theory 52(2), 489-509 (Feb 2006). doi:10.1109/TIT.2005.862083\n\nB Chang, L Meng, E Haber, L Ruthotto, D Begert, E Holtham, Reversible Architectures for Arbitrarily Deep Residual Neural Networks. ArXiv170903698 Cs Stat. Chang, B., Meng, L., Haber, E., Ruthotto, L., Begert, D., Holtham, E.: Reversible Architectures for Arbitrarily Deep Residual Neural Networks. ArXiv170903698 Cs Stat (Sep 2017)\n\nProject Adam: Building an Efficient and Scalable Deep Learning Training System. T Chilimbi, Y Suzue, J Apacible, K Kalyanaraman, 11th {USENIX} Symposium on Operating Systems Design and Implementation. Chilimbi, T., Suzue, Y., Apacible, J., Kalyanaraman, K.: Project Adam: Building an Efficient and Scalable Deep Learning Training System. In: 11th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 14). pp. 571-582 (2014)\n\nA Dosovitskiy, T Brox, Generating Images with Perceptual Similarity Metrics based on Deep Networks. ArXiv160202644 Cs. Dosovitskiy, A., Brox, T.: Generating Images with Perceptual Similarity Metrics based on Deep Networks. ArXiv160202644 Cs (Feb 2016)\n\nA Dosovitskiy, T Brox, Inverting Visual Representations with Convolutional Networks. ArXiv150602753 Cs. Dosovitskiy, A., Brox, T.: Inverting Visual Representations with Convolutional Networks. ArXiv150602753 Cs (Apr 2016)\n\nThe Algorithmic Foundations of Differential Privacy. C Dwork, A Roth, 10.1561/0400000042Found. Trends R Theor. Comput. Sci. 93-4Dwork, C., Roth, A.: The Algorithmic Foundations of Differential Privacy. Found. Trends R Theor. Comput. Sci. 9(3-4), 211-407 (2013). doi:10.1561/0400000042\n\nModel Inversion Attacks that Exploit Confidence Information and Basic Countermeasures. M Fredrikson, S Jha, T Ristenpart, 10.1145/2810103.2813677Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. the 22nd ACM SIGSAC Conference on Computer and Communications SecurityDenver, Colorado, USAAssociation for Computing MachineryCCS '15Fredrikson, M., Jha, S., Ristenpart, T.: Model Inversion Attacks that Exploit Con- fidence Information and Basic Countermeasures. In: Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. pp. 1322-1333. CCS '15, Association for Computing Machinery, Denver, Colorado, USA (Oct 2015). doi:10.1145/2810103.2813677\n\nProperty Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations. K Ganju, Q Wang, W Yang, C A Gunter, N Borisov, 10.1145/3243734.3243834Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. the 2018 ACM SIGSAC Conference on Computer and Communications SecurityToronto CanadaACMGanju, K., Wang, Q., Yang, W., Gunter, C.A., Borisov, N.: Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Repre- sentations. In: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security. pp. 619-633. ACM, Toronto Canada (Jan 2018). doi:10.1145/3243734.3243834\n\nTruth or Backpropaganda? An Empirical Investigation of Deep Learning Theory. M Goldblum, J Geiping, A Schwarzschild, M Moeller, T Goldstein, Cs Math Stat. Goldblum, M., Geiping, J., Schwarzschild, A., Moeller, M., Goldstein, T.: Truth or Backpropaganda? An Empirical Investigation of Deep Learning Theory. ArXiv191000359 Cs Math Stat (Oct 2019)\n\nDeep Residual Learning for Image Recognition. K He, X Zhang, S Ren, J Sun, Cs. He, K., Zhang, X., Ren, S., Sun, J.: Deep Residual Learning for Image Recognition. ArXiv151203385 Cs (Dec 2015)\n\nJ H Jacobsen, A Smeulders, E Oyallon, I-RevNet: Deep Invertible Networks. ArXiv180207088 Cs Stat. Jacobsen, J.H., Smeulders, A., Oyallon, E.: I-RevNet: Deep Invertible Networks. ArXiv180207088 Cs Stat (Feb 2018)\n\n. A Jochems, T M Deist, I El Naqa, M Kessler, C Mayo, J Reeves, S Jolly, M Matuszak, R Ten Haken, J Van Soest, C Oberije, C Faivre-Finn, Jochems, A., Deist, T.M., El Naqa, I., Kessler, M., Mayo, C., Reeves, J., Jolly, S., Matuszak, M., Ten Haken, R., van Soest, J., Oberije, C., Faivre-Finn, C.,\n", "annotations": {"author": "[{\"end\":231,\"start\":79},{\"end\":398,\"start\":232},{\"end\":550,\"start\":399},{\"end\":707,\"start\":551}]", "publisher": null, "author_last_name": "[{\"end\":92,\"start\":85},{\"end\":252,\"start\":240},{\"end\":411,\"start\":406},{\"end\":566,\"start\":559}]", "author_first_name": "[{\"end\":84,\"start\":79},{\"end\":239,\"start\":232},{\"end\":405,\"start\":399},{\"end\":558,\"start\":551}]", "author_affiliation": "[{\"end\":230,\"start\":122},{\"end\":397,\"start\":289},{\"end\":549,\"start\":441},{\"end\":706,\"start\":598}]", "title": "[{\"end\":76,\"start\":1},{\"end\":783,\"start\":708}]", "venue": null, "abstract": "[{\"end\":2128,\"start\":895}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2183,\"start\":2180},{\"end\":2186,\"start\":2183},{\"end\":2357,\"start\":2353},{\"end\":2360,\"start\":2357},{\"end\":2363,\"start\":2360},{\"end\":3309,\"start\":3305},{\"end\":3312,\"start\":3309},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3615,\"start\":3611},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3657,\"start\":3654},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3751,\"start\":3747},{\"end\":3754,\"start\":3751},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3781,\"start\":3778},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3925,\"start\":3922},{\"end\":4700,\"start\":4696},{\"end\":6062,\"start\":6058},{\"end\":6594,\"start\":6590},{\"end\":7032,\"start\":7028},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7035,\"start\":7032},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7344,\"start\":7340},{\"end\":7554,\"start\":7550},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7597,\"start\":7593},{\"end\":7600,\"start\":7597},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7675,\"start\":7672},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7677,\"start\":7675},{\"end\":7680,\"start\":7677},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8037,\"start\":8033},{\"end\":9429,\"start\":9425},{\"end\":10810,\"start\":10806},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11174,\"start\":11170},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":12111,\"start\":12108},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12113,\"start\":12111},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13133,\"start\":13130},{\"end\":16195,\"start\":16191},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20076,\"start\":20073},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":20079,\"start\":20076},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21865,\"start\":21863},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21868,\"start\":21865},{\"end\":24549,\"start\":24545},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24551,\"start\":24549},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":25168,\"start\":25164},{\"end\":27416,\"start\":27412},{\"end\":27419,\"start\":27416},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":47994,\"start\":47992}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37398,\"start\":37091},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37652,\"start\":37399},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37947,\"start\":37653},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38284,\"start\":37948},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38586,\"start\":38285},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38979,\"start\":38587},{\"attributes\":{\"id\":\"fig_6\"},\"end\":39133,\"start\":38980},{\"attributes\":{\"id\":\"fig_7\"},\"end\":44398,\"start\":39134},{\"attributes\":{\"id\":\"fig_8\"},\"end\":45855,\"start\":44399},{\"attributes\":{\"id\":\"fig_9\"},\"end\":46144,\"start\":45856},{\"attributes\":{\"id\":\"fig_10\"},\"end\":46244,\"start\":46145},{\"attributes\":{\"id\":\"fig_11\"},\"end\":46403,\"start\":46245},{\"attributes\":{\"id\":\"fig_12\"},\"end\":46457,\"start\":46404},{\"attributes\":{\"id\":\"fig_13\"},\"end\":46518,\"start\":46458},{\"attributes\":{\"id\":\"fig_14\"},\"end\":46621,\"start\":46519},{\"attributes\":{\"id\":\"fig_15\"},\"end\":46719,\"start\":46622},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":47525,\"start\":46720},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":47872,\"start\":47526},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":48066,\"start\":47873},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":48413,\"start\":48067}]", "paragraph": "[{\"end\":2623,\"start\":2144},{\"end\":3079,\"start\":2657},{\"end\":4307,\"start\":3143},{\"end\":4701,\"start\":4309},{\"end\":4840,\"start\":4703},{\"end\":5522,\"start\":4842},{\"end\":5668,\"start\":5524},{\"end\":6387,\"start\":5685},{\"end\":6905,\"start\":6434},{\"end\":7274,\"start\":6907},{\"end\":8191,\"start\":7276},{\"end\":8842,\"start\":8217},{\"end\":8849,\"start\":8844},{\"end\":10362,\"start\":8960},{\"end\":10691,\"start\":10364},{\"end\":11132,\"start\":10719},{\"end\":11472,\"start\":11134},{\"end\":11703,\"start\":11503},{\"end\":12470,\"start\":11735},{\"end\":13134,\"start\":12472},{\"end\":13837,\"start\":13136},{\"end\":14139,\"start\":13839},{\"end\":14238,\"start\":14161},{\"end\":14342,\"start\":14308},{\"end\":14688,\"start\":14344},{\"end\":14873,\"start\":14704},{\"end\":15156,\"start\":14898},{\"end\":15192,\"start\":15158},{\"end\":15579,\"start\":15194},{\"end\":16196,\"start\":15581},{\"end\":16790,\"start\":16198},{\"end\":17276,\"start\":16813},{\"end\":17980,\"start\":17278},{\"end\":19526,\"start\":17982},{\"end\":20612,\"start\":19554},{\"end\":20634,\"start\":20624},{\"end\":20866,\"start\":20636},{\"end\":21205,\"start\":20895},{\"end\":21390,\"start\":21230},{\"end\":22913,\"start\":21392},{\"end\":23604,\"start\":22942},{\"end\":24817,\"start\":23634},{\"end\":25859,\"start\":24849},{\"end\":26553,\"start\":25861},{\"end\":27159,\"start\":26590},{\"end\":27280,\"start\":27161},{\"end\":28767,\"start\":27304},{\"end\":29479,\"start\":28792},{\"end\":30716,\"start\":29495},{\"end\":31335,\"start\":30718},{\"end\":31855,\"start\":31497},{\"end\":32007,\"start\":31904},{\"end\":32281,\"start\":32174},{\"end\":32556,\"start\":32297},{\"end\":32934,\"start\":32579},{\"end\":33396,\"start\":32964},{\"end\":34159,\"start\":33398},{\"end\":34419,\"start\":34190},{\"end\":34442,\"start\":34435},{\"end\":34853,\"start\":34473},{\"end\":35124,\"start\":34883},{\"end\":35311,\"start\":35126},{\"end\":35412,\"start\":35334},{\"end\":35532,\"start\":35433},{\"end\":35729,\"start\":35545},{\"end\":36448,\"start\":35755},{\"end\":36943,\"start\":36540},{\"end\":37048,\"start\":36945},{\"end\":37090,\"start\":37050}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":2656,\"start\":2624},{\"attributes\":{\"id\":\"formula_1\"},\"end\":3142,\"start\":3080},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6433,\"start\":6388},{\"attributes\":{\"id\":\"formula_3\"},\"end\":8959,\"start\":8850},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14160,\"start\":14140},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14307,\"start\":14239},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14703,\"start\":14689},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14897,\"start\":14874},{\"attributes\":{\"id\":\"formula_8\"},\"end\":31470,\"start\":31336},{\"attributes\":{\"id\":\"formula_9\"},\"end\":31903,\"start\":31856},{\"attributes\":{\"id\":\"formula_10\"},\"end\":32173,\"start\":32008},{\"attributes\":{\"id\":\"formula_11\"},\"end\":35333,\"start\":35312},{\"attributes\":{\"id\":\"formula_12\"},\"end\":35432,\"start\":35413},{\"attributes\":{\"id\":\"formula_14\"},\"end\":35544,\"start\":35533},{\"attributes\":{\"id\":\"formula_15\"},\"end\":35754,\"start\":35730},{\"attributes\":{\"id\":\"formula_16\"},\"end\":36470,\"start\":36449}]", "table_ref": "[{\"end\":32633,\"start\":32626},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":33136,\"start\":33129}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2142,\"start\":2130},{\"attributes\":{\"n\":\"2\"},\"end\":5683,\"start\":5671},{\"attributes\":{\"n\":\"3\"},\"end\":8215,\"start\":8194},{\"attributes\":{\"n\":\"3.1\"},\"end\":10717,\"start\":10694},{\"attributes\":{\"n\":\"4\"},\"end\":11501,\"start\":11475},{\"attributes\":{\"n\":\"4.1\"},\"end\":11733,\"start\":11706},{\"attributes\":{\"n\":\"4.2\"},\"end\":16811,\"start\":16793},{\"attributes\":{\"n\":\"4.3\"},\"end\":19552,\"start\":19529},{\"end\":20622,\"start\":20615},{\"attributes\":{\"n\":\"5\"},\"end\":20893,\"start\":20869},{\"attributes\":{\"n\":\"5.1\"},\"end\":21228,\"start\":21208},{\"attributes\":{\"n\":\"5.2\"},\"end\":22940,\"start\":22916},{\"attributes\":{\"n\":\"5.3\"},\"end\":23632,\"start\":23607},{\"attributes\":{\"n\":\"5.4\"},\"end\":24847,\"start\":24820},{\"attributes\":{\"n\":\"6\"},\"end\":26588,\"start\":26556},{\"attributes\":{\"n\":\"6.1\"},\"end\":27302,\"start\":27283},{\"attributes\":{\"n\":\"6.2\"},\"end\":28790,\"start\":28770},{\"attributes\":{\"n\":\"7\"},\"end\":29493,\"start\":29482},{\"end\":31495,\"start\":31472},{\"end\":32295,\"start\":32284},{\"end\":32577,\"start\":32559},{\"end\":32962,\"start\":32937},{\"end\":34188,\"start\":34162},{\"end\":34433,\"start\":34422},{\"end\":34471,\"start\":34445},{\"end\":34881,\"start\":34856},{\"end\":36482,\"start\":36472},{\"end\":36511,\"start\":36485},{\"end\":36538,\"start\":36514},{\"end\":37100,\"start\":37092},{\"end\":37408,\"start\":37400},{\"end\":37662,\"start\":37654},{\"end\":37957,\"start\":37949},{\"end\":38294,\"start\":38286},{\"end\":38596,\"start\":38588},{\"end\":38990,\"start\":38981},{\"end\":45866,\"start\":45857},{\"end\":46155,\"start\":46146},{\"end\":46255,\"start\":46246},{\"end\":46468,\"start\":46459},{\"end\":46529,\"start\":46520},{\"end\":46632,\"start\":46623},{\"end\":47883,\"start\":47874}]", "table": "[{\"end\":47525,\"start\":47312},{\"end\":47872,\"start\":47693},{\"end\":48413,\"start\":48329}]", "figure_caption": "[{\"end\":37398,\"start\":37102},{\"end\":37652,\"start\":37410},{\"end\":37947,\"start\":37664},{\"end\":38284,\"start\":37959},{\"end\":38586,\"start\":38296},{\"end\":38979,\"start\":38598},{\"end\":39133,\"start\":38993},{\"end\":44398,\"start\":39136},{\"end\":45855,\"start\":44401},{\"end\":46144,\"start\":45869},{\"end\":46244,\"start\":46158},{\"end\":46403,\"start\":46258},{\"end\":46457,\"start\":46406},{\"end\":46518,\"start\":46471},{\"end\":46621,\"start\":46532},{\"end\":46719,\"start\":46635},{\"end\":47312,\"start\":46722},{\"end\":47693,\"start\":47528},{\"end\":48066,\"start\":47885},{\"end\":48329,\"start\":48069}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4306,\"start\":4300},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10184,\"start\":10178},{\"end\":10830,\"start\":10824},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17008,\"start\":17002},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17399,\"start\":17393},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17547,\"start\":17541},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17638,\"start\":17632},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17843,\"start\":17837},{\"end\":20700,\"start\":20694},{\"end\":21157,\"start\":21151},{\"end\":21739,\"start\":21733},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22126,\"start\":22120},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23219,\"start\":23211},{\"end\":23435,\"start\":23427},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23877,\"start\":23871},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":24042,\"start\":24027},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":24288,\"start\":24282},{\"end\":26402,\"start\":26396},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26502,\"start\":26495},{\"end\":26888,\"start\":26882},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26961,\"start\":26955},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":28108,\"start\":28100},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":29336,\"start\":29329},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31056,\"start\":31049},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32555,\"start\":32548},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34418,\"start\":34411},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":34483,\"start\":34477},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":34623,\"start\":34617},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35807,\"start\":35800},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":35917,\"start\":35911},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36611,\"start\":36604},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36813,\"start\":36806}]", "bib_author_first_name": "[{\"end\":48700,\"start\":48699},{\"end\":48711,\"start\":48710},{\"end\":48722,\"start\":48721},{\"end\":48957,\"start\":48956},{\"end\":48968,\"start\":48967},{\"end\":49159,\"start\":49158},{\"end\":49171,\"start\":49170},{\"end\":49182,\"start\":49181},{\"end\":49195,\"start\":49194},{\"end\":49203,\"start\":49202},{\"end\":49215,\"start\":49214},{\"end\":49225,\"start\":49224},{\"end\":49235,\"start\":49234},{\"end\":49246,\"start\":49245},{\"end\":49259,\"start\":49258},{\"end\":49261,\"start\":49260},{\"end\":49272,\"start\":49271},{\"end\":49289,\"start\":49288},{\"end\":49299,\"start\":49298},{\"end\":49309,\"start\":49308},{\"end\":49748,\"start\":49747},{\"end\":49760,\"start\":49759},{\"end\":49770,\"start\":49769},{\"end\":49781,\"start\":49780},{\"end\":49794,\"start\":49793},{\"end\":49796,\"start\":49795},{\"end\":49807,\"start\":49806},{\"end\":49816,\"start\":49815},{\"end\":49826,\"start\":49825},{\"end\":49835,\"start\":49834},{\"end\":50170,\"start\":50169},{\"end\":50172,\"start\":50171},{\"end\":50182,\"start\":50181},{\"end\":50193,\"start\":50192},{\"end\":50472,\"start\":50471},{\"end\":50481,\"start\":50480},{\"end\":50489,\"start\":50488},{\"end\":50498,\"start\":50497},{\"end\":50510,\"start\":50509},{\"end\":50520,\"start\":50519},{\"end\":50885,\"start\":50884},{\"end\":50897,\"start\":50896},{\"end\":50906,\"start\":50905},{\"end\":50918,\"start\":50917},{\"end\":51251,\"start\":51250},{\"end\":51266,\"start\":51265},{\"end\":51504,\"start\":51503},{\"end\":51519,\"start\":51518},{\"end\":51780,\"start\":51779},{\"end\":51789,\"start\":51788},{\"end\":52100,\"start\":52099},{\"end\":52114,\"start\":52113},{\"end\":52121,\"start\":52120},{\"end\":52830,\"start\":52829},{\"end\":52839,\"start\":52838},{\"end\":52847,\"start\":52846},{\"end\":52855,\"start\":52854},{\"end\":52857,\"start\":52856},{\"end\":52867,\"start\":52866},{\"end\":53484,\"start\":53483},{\"end\":53496,\"start\":53495},{\"end\":53507,\"start\":53506},{\"end\":53524,\"start\":53523},{\"end\":53535,\"start\":53534},{\"end\":53799,\"start\":53798},{\"end\":53805,\"start\":53804},{\"end\":53814,\"start\":53813},{\"end\":53821,\"start\":53820},{\"end\":53945,\"start\":53944},{\"end\":53947,\"start\":53946},{\"end\":53959,\"start\":53958},{\"end\":53972,\"start\":53971},{\"end\":54160,\"start\":54159},{\"end\":54171,\"start\":54170},{\"end\":54173,\"start\":54172},{\"end\":54182,\"start\":54181},{\"end\":54193,\"start\":54192},{\"end\":54204,\"start\":54203},{\"end\":54212,\"start\":54211},{\"end\":54222,\"start\":54221},{\"end\":54231,\"start\":54230},{\"end\":54243,\"start\":54242},{\"end\":54256,\"start\":54255},{\"end\":54269,\"start\":54268},{\"end\":54280,\"start\":54279}]", "bib_author_last_name": "[{\"end\":48708,\"start\":48701},{\"end\":48719,\"start\":48712},{\"end\":48729,\"start\":48723},{\"end\":48965,\"start\":48958},{\"end\":48975,\"start\":48969},{\"end\":49168,\"start\":49160},{\"end\":49179,\"start\":49172},{\"end\":49192,\"start\":49183},{\"end\":49200,\"start\":49196},{\"end\":49212,\"start\":49204},{\"end\":49222,\"start\":49216},{\"end\":49232,\"start\":49226},{\"end\":49243,\"start\":49236},{\"end\":49256,\"start\":49247},{\"end\":49269,\"start\":49262},{\"end\":49286,\"start\":49273},{\"end\":49296,\"start\":49290},{\"end\":49306,\"start\":49300},{\"end\":49320,\"start\":49310},{\"end\":49757,\"start\":49749},{\"end\":49767,\"start\":49761},{\"end\":49778,\"start\":49771},{\"end\":49791,\"start\":49782},{\"end\":49804,\"start\":49797},{\"end\":49813,\"start\":49808},{\"end\":49823,\"start\":49817},{\"end\":49832,\"start\":49827},{\"end\":49840,\"start\":49836},{\"end\":50179,\"start\":50173},{\"end\":50190,\"start\":50183},{\"end\":50197,\"start\":50194},{\"end\":50478,\"start\":50473},{\"end\":50486,\"start\":50482},{\"end\":50495,\"start\":50490},{\"end\":50507,\"start\":50499},{\"end\":50517,\"start\":50511},{\"end\":50528,\"start\":50521},{\"end\":50894,\"start\":50886},{\"end\":50903,\"start\":50898},{\"end\":50915,\"start\":50907},{\"end\":50931,\"start\":50919},{\"end\":51263,\"start\":51252},{\"end\":51271,\"start\":51267},{\"end\":51516,\"start\":51505},{\"end\":51524,\"start\":51520},{\"end\":51786,\"start\":51781},{\"end\":51794,\"start\":51790},{\"end\":52111,\"start\":52101},{\"end\":52118,\"start\":52115},{\"end\":52132,\"start\":52122},{\"end\":52836,\"start\":52831},{\"end\":52844,\"start\":52840},{\"end\":52852,\"start\":52848},{\"end\":52864,\"start\":52858},{\"end\":52875,\"start\":52868},{\"end\":53493,\"start\":53485},{\"end\":53504,\"start\":53497},{\"end\":53521,\"start\":53508},{\"end\":53532,\"start\":53525},{\"end\":53545,\"start\":53536},{\"end\":53802,\"start\":53800},{\"end\":53811,\"start\":53806},{\"end\":53818,\"start\":53815},{\"end\":53825,\"start\":53822},{\"end\":53956,\"start\":53948},{\"end\":53969,\"start\":53960},{\"end\":53980,\"start\":53973},{\"end\":54168,\"start\":54161},{\"end\":54179,\"start\":54174},{\"end\":54190,\"start\":54183},{\"end\":54201,\"start\":54194},{\"end\":54209,\"start\":54205},{\"end\":54219,\"start\":54213},{\"end\":54228,\"start\":54223},{\"end\":54240,\"start\":54232},{\"end\":54253,\"start\":54244},{\"end\":54266,\"start\":54257},{\"end\":54277,\"start\":54270},{\"end\":54292,\"start\":54281}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":3310672},\"end\":48902,\"start\":48598},{\"attributes\":{\"doi\":\"10.1017/S0962492918000016\",\"id\":\"b1\",\"matched_paper_id\":56228498},\"end\":49156,\"start\":48904},{\"attributes\":{\"id\":\"b2\"},\"end\":49675,\"start\":49158},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3833774},\"end\":50062,\"start\":49677},{\"attributes\":{\"doi\":\"10.1109/TIT.2005.862083\",\"id\":\"b4\",\"matched_paper_id\":7033413},\"end\":50469,\"start\":50064},{\"attributes\":{\"id\":\"b5\"},\"end\":50802,\"start\":50471},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":2185117},\"end\":51248,\"start\":50804},{\"attributes\":{\"id\":\"b7\"},\"end\":51501,\"start\":51250},{\"attributes\":{\"id\":\"b8\"},\"end\":51724,\"start\":51503},{\"attributes\":{\"doi\":\"10.1561/0400000042\",\"id\":\"b9\",\"matched_paper_id\":207178262},\"end\":52010,\"start\":51726},{\"attributes\":{\"doi\":\"10.1145/2810103.2813677\",\"id\":\"b10\",\"matched_paper_id\":207229839},\"end\":52720,\"start\":52012},{\"attributes\":{\"doi\":\"10.1145/3243734.3243834\",\"id\":\"b11\",\"matched_paper_id\":52218951},\"end\":53404,\"start\":52722},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":203610572},\"end\":53750,\"start\":53406},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":206594692},\"end\":53942,\"start\":53752},{\"attributes\":{\"id\":\"b14\"},\"end\":54155,\"start\":53944},{\"attributes\":{\"id\":\"b15\"},\"end\":54452,\"start\":54157}]", "bib_title": "[{\"end\":48697,\"start\":48598},{\"end\":48954,\"start\":48904},{\"end\":49745,\"start\":49677},{\"end\":50167,\"start\":50064},{\"end\":50882,\"start\":50804},{\"end\":51777,\"start\":51726},{\"end\":52097,\"start\":52012},{\"end\":52827,\"start\":52722},{\"end\":53481,\"start\":53406},{\"end\":53796,\"start\":53752}]", "bib_author": "[{\"end\":48710,\"start\":48699},{\"end\":48721,\"start\":48710},{\"end\":48731,\"start\":48721},{\"end\":48967,\"start\":48956},{\"end\":48977,\"start\":48967},{\"end\":49170,\"start\":49158},{\"end\":49181,\"start\":49170},{\"end\":49194,\"start\":49181},{\"end\":49202,\"start\":49194},{\"end\":49214,\"start\":49202},{\"end\":49224,\"start\":49214},{\"end\":49234,\"start\":49224},{\"end\":49245,\"start\":49234},{\"end\":49258,\"start\":49245},{\"end\":49271,\"start\":49258},{\"end\":49288,\"start\":49271},{\"end\":49298,\"start\":49288},{\"end\":49308,\"start\":49298},{\"end\":49322,\"start\":49308},{\"end\":49759,\"start\":49747},{\"end\":49769,\"start\":49759},{\"end\":49780,\"start\":49769},{\"end\":49793,\"start\":49780},{\"end\":49806,\"start\":49793},{\"end\":49815,\"start\":49806},{\"end\":49825,\"start\":49815},{\"end\":49834,\"start\":49825},{\"end\":49842,\"start\":49834},{\"end\":50181,\"start\":50169},{\"end\":50192,\"start\":50181},{\"end\":50199,\"start\":50192},{\"end\":50480,\"start\":50471},{\"end\":50488,\"start\":50480},{\"end\":50497,\"start\":50488},{\"end\":50509,\"start\":50497},{\"end\":50519,\"start\":50509},{\"end\":50530,\"start\":50519},{\"end\":50896,\"start\":50884},{\"end\":50905,\"start\":50896},{\"end\":50917,\"start\":50905},{\"end\":50933,\"start\":50917},{\"end\":51265,\"start\":51250},{\"end\":51273,\"start\":51265},{\"end\":51518,\"start\":51503},{\"end\":51526,\"start\":51518},{\"end\":51788,\"start\":51779},{\"end\":51796,\"start\":51788},{\"end\":52113,\"start\":52099},{\"end\":52120,\"start\":52113},{\"end\":52134,\"start\":52120},{\"end\":52838,\"start\":52829},{\"end\":52846,\"start\":52838},{\"end\":52854,\"start\":52846},{\"end\":52866,\"start\":52854},{\"end\":52877,\"start\":52866},{\"end\":53495,\"start\":53483},{\"end\":53506,\"start\":53495},{\"end\":53523,\"start\":53506},{\"end\":53534,\"start\":53523},{\"end\":53547,\"start\":53534},{\"end\":53804,\"start\":53798},{\"end\":53813,\"start\":53804},{\"end\":53820,\"start\":53813},{\"end\":53827,\"start\":53820},{\"end\":53958,\"start\":53944},{\"end\":53971,\"start\":53958},{\"end\":53982,\"start\":53971},{\"end\":54170,\"start\":54159},{\"end\":54181,\"start\":54170},{\"end\":54192,\"start\":54181},{\"end\":54203,\"start\":54192},{\"end\":54211,\"start\":54203},{\"end\":54221,\"start\":54211},{\"end\":54230,\"start\":54221},{\"end\":54242,\"start\":54230},{\"end\":54255,\"start\":54242},{\"end\":54268,\"start\":54255},{\"end\":54279,\"start\":54268},{\"end\":54294,\"start\":54279}]", "bib_venue": "[{\"end\":52335,\"start\":52244},{\"end\":53071,\"start\":52987},{\"end\":48733,\"start\":48731},{\"end\":49012,\"start\":49002},{\"end\":49396,\"start\":49322},{\"end\":49851,\"start\":49842},{\"end\":50245,\"start\":50222},{\"end\":50624,\"start\":50530},{\"end\":51003,\"start\":50933},{\"end\":51367,\"start\":51273},{\"end\":51605,\"start\":51526},{\"end\":51848,\"start\":51814},{\"end\":52242,\"start\":52157},{\"end\":52985,\"start\":52900},{\"end\":53559,\"start\":53547},{\"end\":53829,\"start\":53827},{\"end\":54040,\"start\":53982}]"}}}, "year": 2023, "month": 12, "day": 17}