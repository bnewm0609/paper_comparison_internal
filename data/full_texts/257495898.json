{"id": 257495898, "updated": "2023-10-05 03:06:44.476", "metadata": {"title": "Upcycling Models under Domain and Category Shift", "authors": "[{\"first\":\"Sanqing\",\"last\":\"Qu\",\"middle\":[]},{\"first\":\"Tianpei\",\"last\":\"Zou\",\"middle\":[]},{\"first\":\"Florian\",\"last\":\"Roehrbein\",\"middle\":[]},{\"first\":\"Cewu\",\"last\":\"Lu\",\"middle\":[]},{\"first\":\"Guang\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Dacheng\",\"last\":\"Tao\",\"middle\":[]},{\"first\":\"Changjun\",\"last\":\"Jiang\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Deep neural networks (DNNs) often perform poorly in the presence of domain shift and category shift. How to upcycle DNNs and adapt them to the target task remains an important open problem. Unsupervised Domain Adaptation (UDA), especially recently proposed Source-free Domain Adaptation (SFDA), has become a promising technology to address this issue. Nevertheless, existing SFDA methods require that the source domain and target domain share the same label space, consequently being only applicable to the vanilla closed-set setting. In this paper, we take one step further and explore the Source-free Universal Domain Adaptation (SF-UniDA). The goal is to identify\"known\"data samples under both domain and category shift, and reject those\"unknown\"data samples (not present in source classes), with only the knowledge from standard pre-trained source model. To this end, we introduce an innovative global and local clustering learning technique (GLC). Specifically, we design a novel, adaptive one-vs-all global clustering algorithm to achieve the distinction across different target classes and introduce a local k-NN clustering strategy to alleviate negative transfer. We examine the superiority of our GLC on multiple benchmarks with different category shift scenarios, including partial-set, open-set, and open-partial-set DA. Remarkably, in the most challenging open-partial-set DA scenario, GLC outperforms UMAD by 14.8\\% on the VisDA benchmark. The code is available at https://github.com/ispc-lab/GLC.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2303.07110", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/QuZRL0TJ23", "doi": "10.1109/cvpr52729.2023.01917"}}, "content": {"source": {"pdf_hash": "12075b8926e74db899174015c81706ca3a129ef8", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.07110v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c24934d92997541b0804b2b37386f2f3a0026e67", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/12075b8926e74db899174015c81706ca3a129ef8.txt", "contents": "\nUpcycling Models under Domain and Category Shift\n\n\nSanqing Qu \nTongji University\n\n\nTianpei Zou \nTongji University\n\n\nFlorian R\u00f6hrbein \nChemnitz University of Technology\n\n\nCewu Lu \nShanghai Jiao Tong University\n\n\nGuang Chen \nTongji University\n\n\n\u2020 \nDacheng Tao \nJD Explore Academy\n\n\nThe University of Sydney\n\n\nChangjun Jiang \nTongji University\n\n\nUpcycling Models under Domain and Category Shift\n\nDeep neural networks (DNNs) often perform poorly in the presence of domain shift and category shift. How to upcycle DNNs and adapt them to the target task remains an important open problem. Unsupervised Domain Adaptation (UDA), especially recently proposed Source-free Domain Adaptation (SFDA), has become a promising technology to address this issue. Nevertheless, existing SFDA methods require that the source domain and target domain share the same label space, consequently being only applicable to the vanilla closed-set setting. In this paper, we take one step further and explore the Source-free Universal Domain Adaptation (SF-UniDA). The goal is to identify \"known\" data samples under both domain and category shift, and reject those \"unknown\" data samples (not present in source classes), with only the knowledge from standard pre-trained source model. To this end, we introduce an innovative global and local clustering learning technique (GLC). Specifically, we design a novel, adaptive one-vs-all global clustering algorithm to achieve the distinction across different target classes and introduce a local k-NN clustering strategy to alleviate negative transfer. We examine the superiority of our GLC on multiple benchmarks with different category shift scenarios, including partial-set, open-set, and open-partial-set DA. Remarkably, in the most challenging open-partial-set DA scenario, GLC outperforms UMAD by 14.8% on the VisDA benchmark. The code is available at https://github.com/ispc-lab/GLC.\n\nIntroduction\n\nAt the expensive cost of given large-scale labeled data and huge computation resources, deep neural networks (DNNs) have made remarkable progress in various tasks. long-standing open problem. In the last decade, many efforts have been devoted to unsupervised domain adaptation (UDA) [14,18,30,45], which capitalizes on labeled source data and unlabeled target data in a transduction manner, and has achieved significant success. Despite this, the access to source raw data is inefficient and may violate the increasingly stringent data privacy policies [54]. Recently, Sourcefree Domain Adaptation (SFDA) [24,40,56] has become a promising technology to alleviate this issue, where only a pre-trained source model is provided as supervision rather than raw data. However, to avoid model collapse, most existing methods [24,40,56] assume that the label space is identical across the source and target domain, thus being only applicable to vanilla closed-set scenarios.\n\nIn reality, target data may come from a variety of scenarios. Therefore, it is too difficult to hold such a strict assumption. For a better illustration, we suppose Y s and Y t as the label space of source domain and target domain, respectively. In addition to the well-studied vanilla closedset (Y s = Y t .), we often encounter several other situations, e.g., the partial-set (Y s \u2283 Y t ), the open-set (Y s \u2282 Y t ), and the open-partial-set (Y s \u2229 Y t \u0338 = \u2205, Y s \u2288 Y t , Y s \u2289 Y t ). Currently, there have been several source data-dependent works [4,5,28,37,43,57] developed to target category shift. However, methods devised for one situation are commonly infeasible for others. In practice, the target domain is unlabeled and we cannot know which of these category shifts will occur in advance. Not to mention that the requirement to source raw data makes it inefficient and potentially violates data protection policies. To tackle these limitations, and handle those category shifts in a unified manner, in this paper, we take one step further and delve into the Sourcefree Universal Domain Adaptation (SF-UniDA). The goal is to upcycle the standard pre-trained source models identifying \"known\" data samples and rejecting those \"unknown\" data samples (not present in source classes) under domain and category shift. We conceptually present the SF-UniDA in Fig. 1. Note that, very few works [20,25] have studied the source-free model adaptation in open-partial-set scenarios. Nevertheless, their approaches demand dedicated model architectures, greatly limiting their practical applications. SF-UniDA is appealing in view that model adaptation can be resolved only on the basis of a standard pre-trained closedset model, i.e., without specified model architectures.\n\nTo approach such a challenging DA setting, we propose a simple yet generic technique, Global and Local Clustering (GLC). Different from existing pseudo-labeling strategies that focus on closed-set scenarios, we develop a novel onevs-all global clustering based pseudo-labeling algorithm to achieve \"known\" data identification and \"unknown\" data rejection. As we have no prior about the category shift, we utilize the Silhouettes [41] metric to help us realize adaptive global clustering. To avoid source private categories misleading, we design a global confidence statistics based suppression strategy. Although the global clustering algorithm encourages the separation of \"known\" and \"unknown\" data samples, we find that some semantically incorrect pseudo-label assignments may still occur, leading to negative knowledge transfer. To mitigate this, we further introduce a local k-NN clustering strategy by exploiting the intrinsic consensus structure of the target domain.\n\nWe validate the superiority of our GLC via extensive experiments on four benchmarks (Office-31 [42], Office-Home [53], VisDA [39], and Domain-Net [38]) under various category shift situations, including partial-set, openset and open-partial-set. Empirical results show that GLC yields state-of-the-art performance across multiple benchmarks, even with stricter constraints.\n\nOur contributions can be summarized as follows:\n\n\u2022 To the best of our knowledge, we are the first to exploit and achieve the Source-free Universal Domain Adaptation (SF-UniDA) with only a standard pre-trained closed-set model.\n\n\u2022 We propose a generic global and local clustering technique (GLC) to address the SF-UniDA. GLC equips with an innovative global one-vs-all clustering algorithm to realize \"known\" and \"unknown\" data samples separation under various category-shift. \n\n\nRelated Work\n\nUnsupervised Domain Adaptation: To alleviate performance degeneration caused by domain shift, unsupervised domain adaptation (UDA) has received considerable interest in recent years. Existing methods can be broadly classified into three categories: discrepancy based, reconstruction based, and adversarial based. Discrepancy based methods [9,19,30] usually introduce a divergence criterion to measure the distance between the source and target data distributions, and then achieve model adaptation by minimizing the corresponding criterion. Reconstruction based methods [1,15,33] typically introduce an auxiliary image reconstruction task that guides the network to extract domain-invariant features for model adaptation. Inspired by GAN [16], adversarial based approaches [14,29,45] leverage domain discriminators to learn domain-invariant features. Despite of effectiveness, these methods typically focus only on the vanilla closed-set domain adaptation. Universal Domain Adaptation: To handle category-shift, there have been some methods proposed for partial-set [4,5], open-set [28,37,46], and open-partial-set domain adaptation [44,57]. However, most of these methods are designed for a specified situation, and are typically not applicable to other category-shift situations. As an example, an open-partial-set method [57] even underperforms the source model in the partial-set scenario. Recently, [7,43] propose a truly universal UDA method, which is applicable to all three category-shift situations. Nevertheless, most existing methods need access to source data during adaptation, which is inefficient and may violate the increasing data protection policies [54]. Source-free Domain Adaptation: Recently, several works [23,24,40,56] have attempted to achieve domain adaptation with knowledge from only the pre-trained source model rather than raw data. However, to avoid model collapse, these methods commonly focus on the vanilla closedset domain adaptation, significantly limiting their usability.\n\nVery recently, few works [20,25]   . Following the previous source-free closed-set domain adaptation (SFDA) method [24], given a pre-trained source model fs = hs \u2022 gs, we freeze the classifier hs and merely learn the targetspecific feature module gt by fine-tuning the source feature module gs for domain alignment. To realize \"known\" and \"unknown\" data separation, we develop a novel adaptive one-vs-all global clustering algorithm to assign pseudo labels for each target data sample. As we have no prior about the category shift, we introduce the Silhouette [41] criterion to facilitate us in achieving adaptive one-vs-all clustering.\n\nTo avoid misleading from source private categories, we develop a global confidence score based suppression strategy. In addition to global clustering, we further exploit the local intrinsic structure to mitigate negative transfer. (Best view in color.)\n\n\nMethodology\n\n\nPreliminary\n\nIn this paper, we aim to achieve model upcycling under both domain shift and category shift, i.e., the source-free universal domain adaptation (SF-UniDA). In particular, we consider the K-way classification. In this setting, there is a well-designed source domain\nD s = {(x i s , y i s )} Ns i=1 where x i s \u2208 X s , y i s \u2208 Y s , and an unlabeled target domain D t = {(x i t , ?)} Nt i=1 where x i t \u2208 X t .\nFor a better illustration, we denote Y = Y s \u2229Y t as the common label space,\u0232 s = Y \\Y t as the source private label space, and\u0232 t = Y \\ Y s as the target private label space, respectively. As aforementioned, there are three possible category shifts, i.e., the partial-set DA, PDA, (Y s \u2283 Y t ); the open-set DA, OSDA, (Y s \u2282 Y t ); and the open-partial-set DA, OPDA, (Y \u0338 = \u2205,\u0232 s \u0338 = \u2205,\u0232 t \u0338 = \u2205). The final goal is to identify \"known\" samples (belonging to Y) and reject \"unknown\" samples (belonging to\u0232 t ) of D t , with the knowledge only from source pre-trained model f s . D s is not available, and we do not have prior knowledge of what kind of category shift we are facing.\n\nThere have been few works [20,25] explored source-free domain adaptation under category shift. However, these methods are limited to specific category shift, and require dedicated source model architectures. To address these limitations, we propose to achieve SF-UniDA on the basis of only the vanilla closed-set model. Following existing closed-set source-free domain adaptation methods [24,40], given a source model f s = h s \u2022 g s , consisting of a feature module g s and a classifier module h s , we capitalize on the source hypothesis to achieve source and target domain alignment. That is, we only learn a target-specific feature module g t and keep the classifier h t = h s . To realize \"known\" data identification and \"unknown\" data rejection under both domain shift and category shift, we devise a novel, adaptive, global one-vs-all clustering algorithm. Besides, we further employ a local k-NN clustering strategy to alleviate negative transfer. The pipeline is presented in Fig. 2. More details will be described in the following.\n\n\nOne-vs-all Global Clustering\n\nPseudo-labeling is a promising technique in unsupervised learning. Traditional pseudo-labeling strategies [21] assign pseudo labels directly based on sample-level predictions, which are often noisy, especially in the presence of domain shifts. To mitigate this, there are some pseudolabeling strategies [24,36] exploit the data structure of the target domain, i.e., the target-specific prototypes. However, these strategies assume that the source and target domain share identical label space, making it infeasible under category shift. Therefore, a question naturally arises: How to achieve pseudo-labeling with inconsistent label space? Especially, for universal domain adaptation, we have no prior about the category shift between Y s and Y t .\n\nTo tackle this, we first view this problem from a simplified perspective: If Y s \u2282 Y t (i.e., the OSDA setting), and we were to know the number of categories in the target domain is C t , what kind of pseudo-labeling strategy should we apply? Intuitively, target domain, in this case, should be grouped into C t clusters, each corresponding to a specific category. We can then assign pseudo labels via the nearest cluster centroid classifier. However, even though we apply existing clustering algorithms, such as K-means [31], to divide the target domain into C t clusters. It is still challenging to associate the corresponding semantic category for each cluster, in particular for the SF-UniDA, as we have no access to the source raw data.\n\nIn view of this, to ease the challenging semantic association, we devise a novel one-vs-all global clustering pseudolabeling algorithm. The main idea is that For a particular \"known\" category c \u2208 C s , in order to decide whether a data sample belongs to the c-th category, we need to figure out what is and what is not the c-th category. The detailed procedure is presented as follows:\n\n\u2022 For a particular c-th category, we first aggregate the top-K \u03b4 c (f t (x t )) scores represented instances along all target domain D t as positive P c , and the rest as negative N c . Here, \u03b4 c (f t (x t )) denotes the soft-max probability of target instance x t belonging to the c-th class. We empirically set K = N t /C t .\n\n\u2022 Then, we obtain the positive prototype representation p c (i.e., what is the c-th category), and negative pro-\ntotypes {n i c } M i=1 (i.e.\n, what are not the c-th category) via K-means. Noting that we have employed multiple prototypes to represent the negatives since the negatives contain distinct classes. We set M to C t instead of C t \u2212 1, considering that the \"known\" category of the target domain typically involves some hard samples that are difficult to be selected by top-K sampling.\np c = 1 K xt\u2208Pc g t (x t ), {n i c } M i=1 = Kmeans xt\u2208Nc (g t (x t )).(1)\n\u2022 Thereafter, we decide whether data sample x t belongs to the c-th category via the nearest centroid classifier:\nq c = 1, if S(g t (x t ), p c ) \u2265 max{S(g t (x t ), n i c )} M i=1 0, if S(g t (x t ), p c ) < max{S(g t (x t ), n i c )} M i=1\n(2) where S(a, b) measures the similarity between a and b. We apply the cosine similarity function by default.\n\n\u2022 Finally, we iterate the above process to obtain the pseudo labels\u0177 t for all \"known\" category c \u2208 C s . Since each data sample either belongs to the unknown or to one of the categories in the source domain, it is not possible to belong to multiple categories at the same time. Thereby, we introduce a filtering strategy to avoid semantic ambiguity. Here, we just set the category with maximum similarity as the target. It is worth noting that our algorithm does not require the above pseudo-label\u0177 t to be one-hot encoded. Those pseudo labels with all-zero encoding mean that these data samples belong to the \"unknown\" target-private categories Y t . To realize \"known\" and \"unknown\" separation, we then manually set those all-zero encoding pseudo labels to a uniform encoding, i.e.,q c = 1/C s .\n\n\nConfidence based Source-private Suppression\n\nIn the above section, we developed the one-vs-all global clustering algorithm to assign pseudo labels for OSDA, i.e., Y s \u2282 Y t , when the number of categories in the target domain C t is available. However, in addition to OSDA, we may also encounter PDA and OPDA, where the source domain contains categories absent in the target domain. To make the above algorithm applicable to both OSDA, PDA and OPDA, it is necessary to tailor the proposed algorithm to prevent those source-private categories from misleading pseudo-label assignments.\n\nWe empirically found that on positive data group P sampled with top-K on the target domain, those source-private categories generally yield lower mean prediction confidence than those source-target shared categories. In light of this observation, we design a source-private category suppression strategy based on the mean prediction confidence of the positive data group P. Specifically, for a particular category c \u2208 C s , we tailored the Eq. 2 to:\n\u03f5 c = \u03c1 + 1 \u2212 \u03c1 K xt\u2208Pc \u03b4 c (f t (x t )), q c = 1, if \u03f5 c \u00b7 S(g t (x t ), p c ) \u2265 max{S(g t (x t ), n i c )} M i=1 0, if \u03f5 c \u00b7 S(g t (x t ), p c ) < max{S(g t (x t ), n i c )} M i=1 (3)\nwhere \u03f5 c is the designed source-private suppression weight for the c-th category, and \u03c1 is a hyper-parameter to control this weight. We empirically set \u03c1 to 0.75 for all datasets. Its sensitivity analysis can be found in the experiment.\n\n\nSilhouette Based Target Domain C t Estimation\n\nBased on the previous sections, we now have achieved the pseudo-labeling algorithm for SF-UniDA. However, it is still not applicable yet, due to the requirement of prior information, i.e., the number of categories C t in the target domain, which is commonly unavailable in reality. Therefore, the last obstacle for us is: How to determine the number of categories C t in the target domain?\n\nTo address this, a feasible solution is to first enumerate the possible values of the number of categories C t in the target domain and divide the target domain into the corresponding clusters by applying a clustering algorithm like K-means [31]. Then the clustering evaluation criteria [3,11,41,52] can be employed to determine the appropriate number of target domain categoriesC t .\n\nIn this paper, we employ the Silhouette criterion [41] to facilitate estimatingC t . Technically, for a data sample x t \u2208 C I , the Silhouette value s(x t ) is defined as:\na(x t ) = 1 |C I | \u2212 1 x\u2208C I ,x\u0338 =xt d(x t , x), b(x t ) = min J\u0338 =I 1 |C J | x\u2208C J d(x t , x), s(x t ) = b(x t ) \u2212 a(x t ) max{a(x t ), b(x t )} .(4)\nwhere a(x t ) and b(x t ) measure the similarity of x t to its own cluster C I (cohesion) and other clusters C J,J\u0338 =I (separation), respectively. d(x i , x j ) measures the distance between data points x i and x j , and |C I | denotes the size of cluster C I . The Silhouette value s(x t ) ranges from -1 to +1, where a high value indicates that the data sample x t has a high match with its own cluster and a low match with neighboring clusters. Therefore, if most of the data samples have high Silhouette values, then the clustering configuration is appropriate; otherwise, the clustering configuration may have too many or too few clusters.\n\nSince it is challenging to obtain the exact number of target domain categories C t , in our implementation, we empirically enumerate the possible values ofC t as [1/3C s , 1/2C s , C s , 2C s , 3C s ], taking into account the scenarios may encounter. Note that we only estimate the value ofC t at the beginning, and subsequently, we do not change the value ofC t considering the overall efficiency.\n\n\nLocal Consensus Clustering\n\nAlthough the global one-vs-all clustering pseudolabeling algorithm encourages the separation between \"known\" and \"unknown\" data samples, semantically incorrect pseudo-label assignments still occur due to domain shift and category shift, resulting in negative transfer.\n\nTo mitigate this, we further introduce a local k-NN consensus clustering strategy that exploits the intrinsic consensus structure of the target domain D t . Specifically, during model adaptation, we maintain a memory bank G t = {g t (x t ), \u03b4(f t (x t ))} xt\u2208Dt , which contains the target features and corresponding prediction scores. The local k-NN consensus clustering is then realized by:\nl i c = 1 |L i | xt\u2208L i \u03b4 c (f t (x t )), L loc tar = \u2212 1 N N i=1 Cs c=1 l i c log \u03b4 c (f t (x i t )).(5)\nwhere \u03b4 c (f t (x t )) denotes the soft-max probability of data instance x t belonging to the c-th class, L i refers to the set of nearest neighbors of data x i t in the embedding feature space. Here, we apply the cosine similarity function to find the nearest neighbors L i of x i t in the memory bank G t . We then encourage minimizing the cross entropy loss between x i t and the nearest neighbors L i to achieve the local semantic consensus clustering.\n\n\nOptimization Objective\n\nThe overall training loss of GLC can be written as:\nL glb tar = \u2212 1 N N i=1 Cs c=1q i c log \u03b4 c (h t (g t (x i t )))), L tar = \u03b7L glb tar + L loc tar .(6)\nwhereq i c denotes the global clustering pseudo label for data sample x i t , and L glb tar is the corresponding global crossentropy loss. \u03b7 > 0 is a trade-off hyper-parameter.\n\n\nInference Details\n\nAs there is only one standard classification model, we apply the normalized Shannon Entropy [49] as the uncertainty metric to separate known and unknown data samples:\nI(x t ) = \u2212 1 log C s Cs c=1 \u03b4 c (f t (x t )) log \u03b4 c (f t (x t )) (7)\nwhere C s is the class number of source domain D s , and \u03b4 c (f t (x t )) denotes the soft-max probability of data sample x t belonging to the c-th class. The higher the uncertainty, the more the model f t tends to assign an unknown label to the data sample. During inference stage, given an input sample x t , we first compute I(x t ) and then predict the class of y(x t ) with a pre-defined threshold \u03c9 as:\ny(x t ) = unknown, if I(x t ) \u2265 \u03c9 argmax(f t (x t )), if I(x t ) < \u03c9(8)\nwhich either rejects the input sample x t as unknown or classifies it into a known class. In our implementation, we set \u03c9 = 0.55 for all standard benchmark datasets. Its sensitivity analysis can be found in the experiments.\n\n\nExperiments\n\n\nSetup\n\nDataset: We utilize the following standard datasets in DA to evaluate the effectiveness and versatility of our method. Office-31 [42] is a widely-used small-sized domain adaptation benchmark, consisting of 31 object classes (4,652 images) under office environment from three domains (DSLR (D), Amazon (A), and Webcam (W)). Office-Home [53] is another popular medium-sized benchmark, consisting of 65 categories (15,500 images) from four domains (Artistic images (Ar), Clip-Art images (Cl), Product Table 1. H-score (%) comparison in OPDA scenario on Office-Home.Some results are cited from GATE [7] and UMAD [25]. SF denotes source data-free. We compare GLC with SF methods and non-SF methods. (Best in red and second best in blue)  Table 3.\n\nEvaluation protocols: For a fair comparison, we utilize the same evaluation metric as previous works [7,22]. Specifically, in PDA scenario, we report the classification accuracy over all target samples. In OSDA and OPDA scenarios, considering the trade-off between \"known\" and \"un-known\" categories, we report the H-score, i.e., the harmonic mean of the accuracy of \"known\" and \"unknown\" samples.\n\nImplementation details: We adopt the same network architecture with existing baseline methods. Specifically, we adopt the ResNet-50 [17] pre-trained on ImageNet [12] as the backbone for all datasets. For preparing the source model, here, we utilize the same network structure and training recipe as SHOT [24]. We present more details about source model training in the supplementary. During target model adaptation, we apply the SGD optimizer with momentum 0.9. The batch size is set to 64 for all benchmark datasets. We set the learning rate to 1e-3 for Office-31 and Office-Home, and 1e-4 for VisDA and DomainNet. For hyper-parameter, as we described in previous sections, we set \u03c1 to 0.75 for all datasets. For local k-NN consensus clustering, |L| is set to 4 for all benchmarks. As for \u03b7, we set it to 0.3 for Office-31, VisDA, and 1.5 for Office-Home and DomainNet. All experiments are conducted on an RTX-3090 GPU with PyTorch-1.10.\n\n\nExperiment Results\n\nTo verify the effectiveness of our GLC, we conduct extensive experiments on three possible category-shift scenarios, i.e., open-partial-set DA (OPDA), open-set DA (OSDA), and partial-set DA (PDA). We compare GLC with data-dependent and more recent data-free methods to empirically demonstrate the merit of GLC. In adaptation, data- dependent methods typically require access to source rawdata, while data-free methods require source pre-trained models. In particular, GLC requires only a standard pretrained source model, i.e., without any dedicated model architectures as [20,25]. For a fair comparison, all methods are performed without the prior knowledge of categoryshift, except those designed only for specific scenarios. Results on OPDA: We first conduct experiments on the most challenging setting, i.e., OPDA, in which both source and target domains involve private categories. Results on Office-Home are summarized in Table 1, and results on Office-31, VisDA and DomainNet are summarized in Table 2. As shown in Table 1 and Table 2, our GLC achieves new state-of-the-arts, even compared to previous data-dependent methods. Especially, on VisDA, GLC achieves the H-score of 73.1%, which surpasses GATE [7] and UMAD [25] by a wide margin (16.7% and 14.8%). On the largest benchmark, i.e., DomainNet, GLC still achieves consistent performance improvements compared to UMAD and GATE, with gains of approximately 8.0% and 3.0%.\n\nResults on OSDA: We then conduct experiments on OSDA, where only the target domain involves categories not presented in the source domain. Results on Office-Home, Office-31, and VisDA are summarized in Table 4. As shown in Table 4, GLC still achieves state-of-the-art performance. Specifically, GLC obtains 69.8% H-score on Office-  Table 5 show that GLC still achieves comparable performance compared to methods tailored for PDA. In a fairer comparison, GLC clearly outperforms UMAD, specifically achieving performance gains of 6.2%, 4.6%, and 7.7% on Office-31, Office-Home, and VisDA, respectively.\n\n\nExperiment Analysis\n\nAblation Study: To verify the effectiveness of different components within GLC, we conduct extensive ablation studies on Office-31, Office-Home, and VisDA in OPDA scenarios. The results are summarized in Table 6. Here GLC w/o L glb tar refers to that we only employ the local k-NN consensus clustering loss to regulate model adapta- tion, while GLC w/o L loc tar denotes that we only employ the global one-vs-all clustering based pseudo-labeling algorithm to achieve model adaptation. From these results, we can conclude that our local and global clustering strategies are complementary to each other. And global clustering is of vital importance to help us distinguish \"known\" and \"unknown\" categories. For example, on VisDA, with only L glb tar , we can advance the source model from the H-score of 25.7% to 66.0%, and outperform GATE by 9.6%.\n\nHyper-parameter Sensitivity: We first study the parameter sensitivity of \u03b7 and \u03c1 on Office-31 under OPDA setting in Fig. 3 (a-b), where \u03b7 is in the range of [0.1, 0.2, 0.3, 0.4, 0.5], and \u03c1 is in the range of [1/2, 2/3, 3/4, 4/5, 1.0]. Note that \u03c1 = 1.0 denotes that we do not introduce the confidence based source-private suppression mechanism. It is easy to find that results around the selected parameters \u03b7 = 0.3 and \u03c1 = 0.75 are stable, and much better than the source model. By oracle validation, we may find better hyper-parameter settings, e.g., \u03b7 = 0.1 and \u03c1 = 0.50. In Fig. 3 (c), we present the H-score with respect to \u03c9 on Office-Home in OPDA. For all benchmarks, we pre-define \u03c9 = 0.55 to separate \"known\" and \"unknown\" samples. The results show that H-score is relatively stable around our selection, and we could achieve better performance when setting \u03c9 to 0.65 via oracle validation. Besides, in Fig. 3 (d), we illustrate the H-score convergence curves on VisDA.\n\nVarying Unknown Classes: As increasing \"unknown\" classes, it becomes more difficult to correctly identify the \"unknown\" and \"known\" objects. To examine the robustness of GLC, we compare GLC with other methods when varying unknown classes on Office-Home under OPDA setting. Fig. 4 shows that GLC achieves more stable and much better performance against existing methods.  \n\n\nDiscussion\n\n\nConclusion\n\nIn this paper, we have presented Global and Local Clustering (CLC) for upcycling models under domain shift and category shift. Technically, we have devised an innovative one-vs-all global clustering strategy to realize \"unknown\" and \"known\" data separation, and introduced a local k-NN clustering strategy to alleviate negative transfer. Compared to existing approaches that require source data or are only applicable to specific category shifts, GLC is appealing by  \n\n\nA. Source Model Preparing\n\nAs aforementioned, in this paper, we focus on the Kway classification. For a given source domain\nD s = {(x s i , y s i )} Ns i=1\nwhere x i s \u2208 X s and y i s \u2208 Y s \u2282 R K , we adopt the same recipe as SHOT [24] and BMD [40] to prepare the source model. Specifically, the source model f s parameterized by a deep neural network consists of two modules: the feature encoding module g s : X s \u2192 R d and the classifier module h s : R d \u2192 R K , i.e., f s = h s \u2022 g s . We optimize f s with the following loss:\nL src = \u2212 1 N N i=1 K k=1 q k log \u03b4 k (f s (x i s ))(9)\nwhere \u03b4 k (f s (x s )) denotes the softmax probability of source sample x s belonging to the k-th category, q k is the smoothed one-hot encoding of y s , i.e., q k = (1 \u2212 \u03b1) * 1 [k=ys] + \u03b1/K, and \u03b1 is the smoothing parameter which is set to 0.1 for all benchmarks.\n\n\nB. Experiments on Closed-set Adaptation\n\nExisting methods designed for category shift, typically do not perform well for the vanilla closed-set domain adaptation scenario (CLDA). To examine the effectiveness and robustness of GLC, we further conduct experiments on Office-31, and Office-Home. All implementation details are the same as before, e.g., we adopt the ResNet-50 [17] as the backbone, the learning rate is set to 1e-3, and \u03c1 is set to 0.75. The results are listed in Table 7 of this supplementary material. As shown in this Table, despite the fact that the GLC is not tailored for CLDA, we still attain comparable or even better performance compared to existing methods designated for CLDA, e.g., MDD [60]. Specifically, GLC obtains the overall accuracy of 88.1% and 70.4% on Office-31 and Office-Home, respectively. While MDD attains 88.9% and 68.1% on Office-31 and Office-Home, respectively. In a fairer comparison, GLC significantly outperforms UMAD [25], which is also model adaptation method designed for category-shift. Specifically, GLC outperforms UMAD by 6.4% and 7.3% on Office-31 and Office-Home.\n\n\nC. Experiments on Realistic Applications\n\nSo far, most existing methods usually perform experiments only on standard computer science benchmarks. Here, we have further validated the effectiveness and superiority of GLC in realistic applications, including remotesensing recognition, wild-animal classification, and singlecell RNA sequence identification. We present more details in the following.\n\n\nC.1. Partial-set Model Adaptation on Remote Sensing Recognition\n\nRemote sensing has great potential to manage global climate change, population movements, ecosystem transformations, and economic development. However, due to data protection regulations [58], it is difficult for researchers to obtain multi-scene, high-resolution satellite imagery. For example, there are strict data regulation policies in China for high-resolution remote sensing images in meteorological, oceanic, and environmental scenarios [59]. To validate the effectiveness of GLC on remote sensing, we conduct experiments on two existing large-scale datasets, the Pattern-Net [61] and the NWPU45 [8] dataset. PatternNet is one of the largest satellite image datasets collected from Google Earth imagery in the US. It contains 38 scene classes and 30,400 high-resolution (0.2 \u223c 6m per pixel) satellite images, such as airport, beach, dense residential, forest, etc. NWPU45 dataset consists of 45 scene classes and 31,500 satellite images covering more than 100 countries and regions around the world. Its spatial resolution varies from about 30 to 0.2 m per pixel. The heterogeneity of spatial resolution and geographic location poses a significant challenge to model adaptation. In this paper, we set the Pattern-Net as source dataset and the NWPU45 as target dataset to investigate the model adaptation from high-resolution satellite images to low-resolution satellite images. There are 21 overlapping scenes classes between PatternNet and NWPU45. Thus, we transfer the scene classes from the Pat-ternNet to the 21 overlapping scene classes in the NWPU45 and compare the results with the original labels from the NWPU45 for performance evaluation.\n\nAn illustration of boxplot in Fig. 5b basically demonstrates that GLC effectively realizes model adaptation and achieves more accurate performance with less variance than existing methods. Quantitatively, GLC achieves 64.6 \u00b1 0.22% overall accuracy with 5 different random seeds. In contrast to GLC, the baseline methods DCC, ETN, DANCE, and BA3US obtain 55.2 \u00b1 0.80%, 54.9 \u00b1 0.77%, 62.0 \u00b1 1.02% and 59.6 \u00b1 1.25% overall accuracy, respectively. To verify the robustness, we further conduct an ablation experiment on decreasing the number of overlapping scenes between source and target domains. The number gets smaller, there is more probability of overlapping samples being categorized into other scenes. Despite this, the results in Fig. 5c show that GLC is still capable of addressing this challenge and even achieving better performance. Quantitatively, GLC obtains 64.5% average accuracy in four different target situations. In contrast, the baseline methods DCC, ETN, DANCE, and BA3US attain 55.4%, 55.0%, 52.4%, and 49.6% overall accuracy, respectively. We attribute this to our global one-vs-all clustering algorithm, which is able to discover non-existent scene categories and suppress model adaptation over these categories.\n\n\nC.2. Open-set Model Adaptation on Wild Animal Classification\n\nWe next study a more challenging setting, the open-set model adaptation on wild animal classification. Having the ability to accurately classify wild animals is important for studying and protecting ecosystems [34], especially the ability to identify novel species [32]. However, it is almost impossible for a database to cover all animal species, and it is also typically difficult to collect and annotate a large number of wild animal images in practice. Thereby, it would be ideal if we develop an animal classification system based on the existing large number of virtual animal images on the Internet. In this article, we execute experiments on the I2AWA [62] benchmark to investigate open-set model adaptation from virtual to real-world. I2AWA consists of a virtual source domain dataset and a real-world target domain dataset with a total of 50 animal categories. We divide the first 30 into known categories in alphabetical order and the remaining 20 into unknown categories. The source domain dataset consists of 2,970 virtual animal images collected through the Google-Image search engine, while the target domain dataset comes from the AWA2 [55] dataset with a total of 37,322 images from the real world. Due to differences in image styles between virtual and real-world datasets, directly deploying a DNN model trained on the virtual images can lead to severe performance degradation.\n\nFor a qualitative demonstration, we enumerate some animal images on target domain in Fig. 6a and apply the Grad-CAM heatmap [48] technique to compare the source model with the adapted target model by our GLC technique. From this, we can conclude that the source model typically fails to locate and extract key information for animal identification, while the upcycled model overcomes these failures well. For quantitative performance evaluation, we compare GLC with the methods dedicated to open-set domain adaptation (DANN [14], OSBP [46]), and the methods designed for universal domain adaptation (DANCE [43], OVANet [44]).\n\nAn inspection of the tSNE plots (Fig. 6b) indicates that our GLC algorithm effectively realizes known animal classification and unknown animal separation. This observation is further demonstrated by the quantitative metric in Fig. 6c. Specifically, GLC achieves 79.1\u00b10.28% overall H-Score. In contrast, the baseline methods DANN, OVANet, OSBP and DANCE obtains 70.1 \u00b1 0.85%, 70.8 \u00b1 0.58%, 72.2 \u00b1 1.61%, 74.5 \u00b1 0.32% overall H-Score. As presented in Fig. 6d, compared to existing methods, GLC further provides significant savings in target-domain side computational resource overhead (about 48.4% training time reduction in this case). This is due to the fact that our GLC merely fine-tunes the source model to realize adaptation, while existing source data-dependent methods need to train the target models from scratch.\n\nTo visually assess the separation between the known and unknown classes, we present the uncertainty density distribution in Fig. 6e. The higher the uncertainty, the more the model treated the input animal image as an unknown species. The results show that while OVANet and DANCE are able to achieve promising classification of known classes of animals, they have trouble in unknown animal separation. In contrast, our GLC draws a better tradeoff between known animal classification and unknown animal identification.\n\nWe further examine the robustness of GLC in different open-set situations, e.g., varying target domain unknown categories and source domain known categories. As illustrated in Fig. 6f \n\n\nC.3. Open-partial-set Model Adaptation on Singlecell Identification\n\nWe finally consider the most challenging scenario, openpartial-set adaptation, where both source and target do-  mains contain private categories. Here, we implement experiments on single-cell identification. It has great potential in the studies of cell heterogeneity, developmental dynamics, and cell communications [51]. Currently, there are two main types of single-cell sequencing technologies, namely scRNA-seq and scATAC-seq. However, it has been noted that the extreme scarcity of scATAC-seq data tends to limit its ability for cell type identification. In contrast, large amounts of well-annotated scRNA-seq datasets have been curated as cell atlases. It motivates us to upcycle models trained on the scRNA-seq datasets and adapt them to the scATAC-seq datasets. Nevertheless, the cell types contained in different atlas data are generally inconsistent, which poses substantial challenges for model adaptation across atlases. In this article, we apply our GLC to two mouse cell atlases, the Tabula Muris atlas [47] for scRNAseq data and the Cusanovich atlas [10] for scATAC-seq data. The Tabula Muris atlas consists of 73 cell types totaling 96,404 cells from 20 organs with two protocols profiling transcriptomics, while the Cusanovich atlas consists of 29 cell types totaling 81,173 cells from 13 tissues. There are 19 cell types common between the Tabula Muris atlas and the Cusanovich atlas. For performance evaluation, as in the wild animal experiments above, we utilize the harmonic mean accuracy H-Score of the known cell types and the unknown cell types as the quantitative metric. We compare our GLC with recently developed and applied methods for scRNA-seq and scATAC-seq integration, including the scJoint [27] and the Seurat v.3 [50].\n\nWe illustrate the tSNE plots in Fig. 7a to compare with the ground truth labels annotated in the Cusanovich atlas [10]. The tSNE plots are generated by applying the singular value of the term frequency-inverse document frequency (TD-IDF) transformation of scATAC-seq peak matrix as in the Cusanovich atlas [10]. It observes that GLC achieves a better trade-off between known cell types identification and unknown cell types separation than the other methods. This observation is further quantitatively demonstrated by the H-Score metric. Specifically, GLC obtains 62% overall H-Score compared with 58% for Seurat and 56% for scJoint. As presented in Fig. 7c, not only is there a significant performance improvement, but our GLC also brings significant savings in target domain computational resource overhead (about 75.9% training time reduction).\n\nIn addition to tSNE plots, we also present the uncertainty density distribution in Fig. 7b, where the higher the uncer-  Figure 6. Analysis of open-set model adaptation on wild animal classification from virtual images to real-world images. a. Example wild animal images of the I2AWA dataset, and comparison of the feature heatmap images between the pre-trained source model and the adapted target model. b. tSNE visualization of ground truth labels and GLC predicted labels. Each tSNE subplot is generated from the same extracted features by our GLC. We apply gray to denote those animal species that are not presented in the source domain. tainty, the more the model tends to group the cell into the unknown cell types group. To find the best trade-off point, a global decision boundary search was performed for all methods. The decision boundary for GLC is 0.5 compared with 0.25 for Seurat and 0.05 for scJoint. It further indicates that our GLC attains an optimal trade-off in cell types identification to the other methods.\n\n\nD. Discussion\n\nDuring the past decades, deep neural networks (DNNs) have achieved remarkable success in various applications and fields. However, DNNs are typically restricted to the training data domain. If the test data is collected in another modality or from other types of instruments, we will typically suffer from a significant performance degradation [35]. This phenomenon is likely to worsen when training and testing data do not share the same ground-truth class space. Although DNNs can be adapted to different application scenarios with additional supervised learning, this paradigm asks for annotation of large-scale target domain data. It would require significant resources and experts in real-world applications, such as clinical staff for medical  Figure 7. Analysis of open-partial model adaptation on single-cell identification from scRNA-seq atlas to scATAC-seq atlas. a, tSNE visualization of ground truth, GLC, scJoint, and Seurat predicted labels. We apply gray to indicate those cell types that are not presented in the source domain scRNA-seq atlas. b, Uncertainty distribution of GLC, scJoint, and Seurat for cell types that are existed and absent from the scRNA-seq atlas. The higher the uncertainty, the more the model tends to assign cell types to unknown that are absent from the scRNA-seq atlas. The dashed line denotes the decision boundaries for known and unknown cell types prediction. c, Target-domain training time of Seurat, scJoint and our GLC.\n\nimaging diagnosis and genetic scientists for single-cell sequence analysis, making it extremely expensive and impossible for most scenarios. In this paper, we find that it is possible to productively upcycle existing pre-trained models and adapt them to new scenarios. Numerous empirical evidences on standard computer science benchmarks and simulated realistic applications basically demonstrate that GLC is a promising, simple, and general solution for a variety of real-world application tasks, including single-cell sequence analysis, remote sensing recognition, and other such domain-dependent problems.\n\nFigure 1 .\n1However, DNNs often generalize poorly to the unseen new domain under domain shift and category shift. How to upcycle DNNs and adapt them to target tasks is still a * Equal Contribution \u2020 Corresponding author: guangchen@tongji.edu.cn type category shift are we facing? We have no idea ... The illustration of Source-free Universal Domain Adaptation (SF-UniDA). The goal is to realize model upcycling under both domain shift and category shift. It is extremely challenging as only one source closed-set model is provided as supervision rather than raw data. And we do not have any prior knowledge about category shift between domains in advance.\n\nFigure 2 .\n2Overview of our proposed Global and Local Clustering technique (GLC)\n\nFigure 3 .\n3Analysis of GLC. (a-b) present the hyper-parameter sensitivity of \u03b7 and \u03c1 on Office-31 in OPDA. (c) plots the H-score with respect to \u03c9 on Office-Home in OPDA. (d) shows the H-score curves on VisDA in OPDA during the training process. Here GLC (w/o glb) refers to GLC w/o L glb tar and GLC w/o knn denotes GLC w/o L loc tar .\n\n\nSo far, most existing domain adaptation methods designed for category shift are not applicable to the vanilla closed-set DA (CLDA). To verify the effectiveness of GLC in CLDA, we have conducted experiments on Office-31 and Office-Home in the Appendix. Moreover, existing methods usually perform experiments only on standard computer (a) Ar \u2192Re in OPDA (b) Cl \u2192 Pr in OPDA\n\nFigure 4 .\n4H-score (%) of OPDA when varying the number of unknown classes in Office-Home. GLC shows stable and much superior performance against existing methods. science benchmarks. Here, we have validated the effectiveness of GLC in more realistic applications, including remote sensing in PDA, wildlife classification in OSDA, and single-cell RNA sequence identification in OPDA. These results are also presented in the Appendix.\n\n\nenabling universal model adaptation on the basis of only standard pre-trained source models. Extensive experiments in partial-set, open-set, and open-partial-set DA scenarios across several benchmarks have verified the effectiveness and superiority of GLC. Remarkably, GLC significantly outperforms existing methods by almost 15% on the VisDA benchmark in open-partial-set DA scenario. Acknowledgment: This work was supported by Shanghai Municipal Science and Technology Major Project (No.2018SHZDZX01), ZJ Lab, and Shanghai Center for Brain Science and Brain-Inspired Technology, the Shanghai Rising Star Program (No.21QC1400900), and the Tongji-Westwell Autonomous Vehicle Joint Lab Project.\n\n\nc H-Score rate of DANN, OVANet, OSBP, DANCE, and GLC. Each boxplot ranges from the upper and lower quartiles with the median as the horizontal line and whiskers extend to 1.5 times the interquartile range. d, Target domain training time of DANN, OVANet, OSBP, DANCE, and GLC. e, Uncertainty distribution of OVANet, DANCE, and our GLC for known and unknown animal categories. f, H-Score rate of DANN, OVANet, OSBP, DANCE, and GLC when the number of target domain unknown animal categories and source domain known animal categories varying.\n\n\n\u2022 Extensive experiments on four benchmarks under various category-shift situations demonstrate the superiority of our GLC technique. Remarkably, in the openpartial-set DA situation, GLC attains an H-score of 73.1% on the VisDA benchmark, which is 14.8% and 16.7% higher than UMAD and GATE, respectively.\n\n\nMethodsSF OPDA OSDA PDA Ar2Cl Ar2Pr Ar2Re Cl2Ar Cl2Pr Cl2Re Pr2Ar Pr2Cl Pr2Re Re2Ar Re2Cl Re2Pr AvgTable 2. H-score (%) comparison in OPDA scenario on Office-31, VisDA, and DomainNet. Some results are cited from UMAD[25].Table 3. Details of class split. Here, Y,\u0232s, and\u0232t denotes the source-target-shared class, the source-private class, and the targetprivate class, respectively.UAN [57] \n\u2717 \n\u2713 \n\u2717 \n\u2717 \n51.6 51.7 54.3 61.7 57.6 61.9 50.4 47.6 61.5 62.9 52.6 65.2 56.6 \nCMU [13] \n\u2717 \n\u2713 \n\u2717 \n\u2717 \n56.0 56.9 59.2 67.0 64.3 67.8 54.7 51.1 66.4 68.2 57.9 69.7 61.6 \nDCC [22] \n\u2717 \n\u2713 \n\u2713 \n\u2713 \n58.0 54.1 58.0 74.6 70.6 77.5 64.3 73.6 74.9 81.0 75.1 80.4 70.2 \nOVANet [44] \u2717 \n\u2713 \n\u2713 \n\u2717 \n62.8 75.6 78.6 70.7 68.8 75.0 71.3 58.6 80.5 76.1 64.1 78.9 71.8 \nGATE [7] \n\u2717 \n\u2713 \n\u2713 \n\u2713 \n63.8 75.9 81.4 74.0 72.1 79.8 74.7 70.3 82.7 79.1 71.5 81.7 75.6 \n\nSource-only \u2713 \n-\n-\n-\n47.3 71.6 81.9 51.5 57.2 69.4 56.0 40.3 76.6 61.4 44.2 73.5 60.9 \nSHOT-O [24] \u2713 \n\u2717 \n\u2713 \n\u2717 \n32.9 29.5 39.6 56.8 30.1 41.1 54.9 35.4 42.3 58.5 33.5 33.3 40.7 \nUMAD [25] \u2713 \n\u2713 \n\u2713 \n\u2717 \n61.1 76.3 82.7 70.7 67.7 75.7 64.4 55.7 76.3 73.2 60.4 77.2 70.1 \nGLC \n\u2713 \n\u2713 \n\u2713 \n\u2713 \n64.3 78.2 89.8 63.1 81.7 89.1 77.6 54.2 88.9 80.7 54.2 85.9 75.6 \n\nMethods \nSF OPDA OSDA PDA \n\nOffice-31 \nVisDA \nDomainNet \n\nA2D A2W D2A D2W W2A W2D Avg S2R P2R P2S R2P R2S S2P S2R Avg \n\nUAN [57] \n\u2717 \n\u2713 \n\u2717 \n\u2717 \n59.7 58.6 60.1 70.6 60.3 71.4 63.5 34.8 41.9 39.1 43.6 38.7 38.9 43.7 41.0 \nCMU [13] \n\u2717 \n\u2713 \n\u2717 \n\u2717 \n68.1 67.3 71.4 79.3 72.2 80.4 73.1 32.9 50.8 45.1 52.2 45.6 44.8 51.0 48.3 \nDCC [22] \n\u2717 \n\u2713 \n\u2713 \n\u2713 \n88.5 78.5 70.2 79.3 75.9 88.6 80.2 43.0 56.9 43.7 50.3 43.3 44.9 56.2 49.2 \nOVANet [44] \u2717 \n\u2713 \n\u2713 \n\u2717 \n85.8 79.4 80.1 95.4 84.0 94.3 86.5 53.1 56.0 47.1 51.7 44.9 47.4 57.2 50.7 \nGATE [7] \n\u2717 \n\u2713 \n\u2713 \n\u2713 \n87.7 81.6 84.2 94.8 83.4 94.1 87.6 56.4 57.4 48.7 52.8 47.6 49.5 56.3 52.1 \n\nSource-only \n\u2713 \n-\n-\n-\n70.9 63.2 39.6 77.3 52.2 86.4 64.9 25.7 57.3 38.2 47.8 38.4 32.2 48.2 43.7 \nSHOT-O [24] \u2713 \n\u2717 \n\u2713 \n\u2717 \n73.5 67.2 59.3 88.3 77.1 84.4 75.0 44.0 35.0 30.8 37.2 28.3 31.9 32.2 32.6 \nUMAD [25] \u2713 \n\u2713 \n\u2713 \n\u2717 \n79.1 77.4 87.4 90.7 90.4 97.2 87.0 58.3 59.0 44.3 50.1 42.1 32.0 55.3 47.1 \nGLC \n\u2713 \n\u2713 \n\u2713 \n\u2713 \n81.5 84.5 89.8 90.4 88.4 92.3 87.8 73.1 63.3 50.5 54.9 50.9 49.6 61.3 55.1 \n\nDataset \nClass Split(Y/\u0232 s /\u0232 t ) \n\nOPDA \nOSDA \nPDA \n\nOffice-31 [42] \n10/10/11 \n10/0/11 \n10/21/0 \nOffice-Home [53] \n10/5/50 \n25/0/40 \n25/40/0 \nVisDA-C [39] \n6/3/3 \n6/0/6 \n6/6/0 \nDomainNet [38] \n150/50/145 \n-\n-\n\nimages (Pr), and Real-World images (Rw)). VisDA-C [39] \nis a more challenging benchmark with 12 object classes, \nwhere the source domain contains 152,397 synthetic images \ngenerated by rendering 3D models and the target domain \nconsists of 55,388 images from Microsoft COCO. Domain-\nNet [38], is the largest domain adaptation benchmark with \nabout 0.6 million images, which contains 345 classes. Sim-\nilar to previous works [7, 25], we conduct experiments on \nthree subsets from it (Painting (P), Real (R), and Sketch \n(S)). We evaluate our GLC on partial-set DA (PDA), open-\nset DA (OSDA), and open-partial-set DA (OPDA) scenar-\nios. Detailed classes split are summarized in \n\nTable 4 .\n4H-score (%) comparison in OSDA scenario on Office-Home, Office-31, and VisDA. (Best in red and second best in blue)Methods \nSF OPDA OSDA PDA \n\nOffice-Home \nOffice31 VisDA \n\nAr2Cl Ar2Pr Ar2Re Cl2Ar Cl2Pr Cl2Re Pr2Ar Pr2Cl Pr2Re Re2Ar Re2Cl Re2Pr Avg Avg \nAvg \n\nOSBP [46] \n\u2717 \n\u2717 \n\u2713 \n\u2717 \n55.1 65.2 72.9 64.3 64.7 70.6 63.2 53.2 73.9 66.7 54.5 72.3 64.7 83.7 \n52.3 \nROS [2] \n\u2717 \n\u2717 \n\u2713 \n\u2717 \n60.1 69.3 76.5 58.9 65.2 68.6 60.6 56.3 74.4 68.8 60.4 75.7 66.2 85.9 \n66.5 \nCMU [13] \n\u2717 \n\u2713 \n\u2717 \n\u2717 \n55.0 57.0 59.0 59.3 58.2 60.6 59.2 51.3 61.2 61.9 53.5 55.3 57.6 65.2 \n54.2 \nDANCE [43] \u2717 \n\u2713 \n\u2713 \n\u2713 \n6.5 \n9.0 \n9.9 20.4 10.4 9.2 28.4 12.8 12.6 14.2 \n7.9 13.2 12.9 79.8 \n67.5 \nDCC [22] \n\u2717 \n\u2713 \n\u2713 \n\u2713 56.1 67.5 66.7 49.6 66.5 64.0 55.8 53.0 70.5 61.6 57.2 71.9 61.7 72.7 \n59.6 \nOVANet [44] \u2717 \n\u2713 \n\u2713 \n\u2717 \n58.6 66.3 69.9 62.0 65.2 68.6 59.8 53.4 69.3 68.7 59.6 66.7 64.0 91.7 \n66.1 \nGATE [7] \n\u2717 \n\u2713 \n\u2713 \n\u2713 63.8 70.5 75.8 66.4 67.9 71.7 67.3 61.5 76.0 70.4 61.8 75.1 69.0 89.5 \n70.8 \n\nSource-only \u2713 \n-\n-\n-\n46.1 63.3 72.9 42.8 54.0 58.7 47.8 36.1 66.2 60.8 45.3 68.2 55.2 69.6 \n29.1 \nSHOT-O [24] \u2713 \n\u2717 \n\u2713 \n\u2717 \n37.7 41.8 48.4 56.4 39.8 40.9 60.0 41.5 49.7 61.8 41.4 43.6 46.9 77.5 \n28.1 \nUMAD [25] \u2713 \n\u2713 \n\u2713 \n\u2717 \n59.2 71.8 76.6 63.5 69.0 71.9 62.5 54.6 72.8 66.5 57.9 70.7 66.4 89.8 \n66.8 \nGLC \n\u2713 \n\u2713 \n\u2713 \n\u2713 65.3 74.2 79.0 60.4 71.6 74.7 63.7 63.2 75.8 67.1 64.3 77.8 69.8 89.0 \n72.5 \n\nTable 5. Accuracy (%) comparison in PDA scenario on Office-Home, Office-31, and VisDA. (Best in red and second best in blue) \n\nMethods \nSF OPDA OSDA PDA \n\nOfficeHome \nOffice31 VisDA \n\nAr2Cl Ar2Pr Ar2Re Cl2Ar Cl2Pr Cl2Re Pr2Ar Pr2Cl Pr2Re Re2Ar Re2Cl Re2Pr Avg Avg \nAvg \n\nETN [6] \n\u2717 \n\u2717 \n\u2717 \n\u2713 59.2 77.0 79.5 62.9 65.7 75.0 68.3 55.4 84.4 75.7 57.7 84.5 70.4 96.7 \n59.8 \nBA3US [26] \u2717 \n\u2717 \n\u2717 \n\u2713 60.6 83.2 88.4 71.8 72.8 83.4 75.5 61.6 86.5 79.3 62.8 86.1 76.0 97.8 \n54.9 \nDANCE [43] \u2717 \n\u2713 \n\u2713 \n\u2713 53.6 73.2 84.9 70.8 67.3 82.6 70.0 50.9 84.8 77.0 55.9 81.8 71.1 86.0 \n73.7 \nDCC [22] \n\u2717 \n\u2713 \n\u2713 \n\u2713 54.2 47.5 57.5 83.8 71.6 86.2 63.7 65.0 75.2 85.5 78.2 82.6 70.9 93.3 \n72.4 \nOVANet [44] \u2717 \n\u2713 \n\u2713 \n\u2717 \n34.1 54.6 72.1 42.4 47.3 55.9 38.2 26.2 61.7 56.7 35.8 68.9 49.5 74.6 \n34.3 \nGATE [7] \n\u2717 \n\u2713 \n\u2713 \n\u2713 55.8 75.9 85.3 73.6 70.2 83.0 72.1 59.5 84.7 79.6 63.9 83.8 74.0 93.7 \n75.6 \n\nSource-only \u2713 \n-\n-\n-\n45.9 69.2 81.1 55.7 61.2 64.8 60.7 41.1 75.8 70.5 49.9 78.4 62.9 87.8 \n42.8 \nSHOT-P [24] \u2713 \n\u2717 \n\u2717 \n\u2713 64.7 85.1 90.1 75.1 73.9 84.2 76.4 64.1 90.3 80.7 63.3 85.5 77.8 92.2 \n74.2 \nUMAD [25] \u2713 \n\u2713 \n\u2713 \n\u2717 \n51.2 66.5 79.2 63.1 62.9 68.2 63.3 56.4 75.9 74.5 55.9 78.3 66.3 89.5 \n68.5 \nGLC \n\u2713 \n\u2713 \n\u2713 \n\u2713 55.9 79.0 87.5 72.5 71.8 82.7 74.9 41.7 82.4 77.3 60.4 84.3 72.5 94.1 \n76.2 \n\n\n\nTable 6 .\n6Ablation Study. Results for OPDA on Office-31, Office-Home, and VisDA with different variants of GLC.Home and 72.5% H-score on VisDA, with an improvement of 3.4% and 5.7% compared to UMAD.Results on PDA: We last verify the effectiveness of GLC on PDA, where the label space of the target domain is a subset of the source domain. Results summarized inMethod \nOffice-31 \nOffice-Home \nVisDA \n\nSource model \n64.9 \n60.9 \n25.7 \nGLC (w/o L loc \ntar ) \n86.1 \n74.8 \n66.0 \nGLC (w/o L glb \ntar ) \n87.4 \n67.2 \n57.3 \nGLC (full) \n87.8 \n75.6 \n73.1 \n\n\n\nTable 7 .\n7Accuracy (%) comparison in CLDA scenario on Office-Home and Office-31. (Best in bold)Methods \nSF OPDA OSDA PDA CLDA \n\nOffice-Home \nOffice-31 \n\nAr2Cl Ar2Pr Ar2Re Cl2Ar Cl2Pr Cl2Re Pr2Ar Pr2Cl Pr2Re Re2Ar Re2Cl Re2Pr Avg \nAvg \n\nCDAN [29] \u2717 \n\u2717 \n\u2717 \n\u2717 \n\u2713 \n49.0 69.3 74.5 54.4 66.0 68.4 55.6 48.3 75.9 68.4 55.4 80.5 63.8 86.6 \nMDD [60] \n\u2717 \n\u2717 \n\u2717 \n\u2717 \n\u2713 \n54.9 73.7 77.8 60.0 71.4 71.8 61.2 53.6 78.1 72.5 60.2 82.3 68.1 88.9 \nUAN [57] \n\u2717 \n\u2713 \n\u2717 \n\u2717 \n\u2717 \n45.0 63.6 71.2 51.4 58.2 63.2 52.6 40.9 71.0 63.3 48.2 75.4 58.7 84.4 \nCMU [13] \n\u2717 \n\u2713 \n\u2717 \n\u2717 \n\u2717 \n42.8 65.6 74.3 58.1 63.1 67.4 54.2 41.2 73.8 66.9 48.0 78.7 61.2 79.9 \nDANCE [43] \u2717 \n\u2713 \n\u2713 \n\u2717 \n\u2717 \n54.3 75.9 78.4 64.8 72.1 73.4 63.2 53.0 79.4 73.0 58.2 82.9 69.1 85.5 \nDCC [22] \n\u2717 \n\u2713 \n\u2713 \n\u2713 \n\u2717 \n35.4 61.4 75.2 45.7 59.1 62.7 43.9 30.9 70.2 57.8 41.0 77.9 55.1 87.4 \nOVANet [44] \u2717 \n\u2713 \n\u2713 \n\u2717 \n\u2717 \n34.5 55.8 67.1 40.9 52.8 56.9 35.4 26.2 61.8 53.8 35.4 70.8 49.3 70.4 \n\nSource-only \u2713 \n-\n-\n-\n-\n44.8 67.4 74.2 53.0 63.3 65.1 53.7 40.5 73.5 65.6 46.3 78.3 60.5 78.8 \nUMAD [25] \u2713 \n\u2713 \n\u2713 \n\u2717 \n\u2717 \n48.0 65.1 73.0 58.6 65.3 67.9 58.2 47.3 74.0 69.4 53.0 77.8 63.1 81.7 \nGLC \n\u2713 \n\u2713 \n\u2713 \n\u2713 \n\u2717 \n51.2 76.0 79.9 65.4 78.6 78.7 65.6 54.1 81.6 70.9 58.4 84.2 70.4 88.1 \n\n\n\n\n, we can find that GLC maintains a promising H-score compared to existing methods. Specifically, GLC achieves 78.3% overall H-Score in four different target domain unknown categories situations, while DANN, OSBP, OVANet, and DANCE obtain 69.3%, 72.9%, 70.8%, 75.4% average H-Score, respectively. Similarly, when source domain known categories varies, GLC arrives 83.4% overall H-Score in four different situations, still significantly outperforming existing methods.\n\n\nFigure 5. Analysis of partial-set model adaptation on remote sensing recognition from high-resolution satellite images to lowresolution satellite images. a, Example satellite images of different spatial resolutions on three scene classes, airfield, anchorage, and bridge (from left to right). b, Accuracy rate of DCC, ETN, BA3US, DANCE, and GLC. Each boxplot ranges from the upper and lower quartiles with the median as the horizontal line and whiskers extend to 1.5 times the interquartile range. c, Accuracy rate of DCC, ETN, BA3US, DANCE, and GLC when applying on different target domain scenarios. d, Confusion matrix visualization of GLC and DCC. Clearer diagonal structure indicates better overall accuracy.Airfield \nAnchorage \nBaseball_field \nBeach \nBridge \nChaparral \nDenseResidential \nFarm \nFlyover \nForest \nFreeway \nGameSpace \nGolf_course \nIntersection \nMobile_home_park \nParkingSpace \nRailway \nRiver \nRunway \nSparseResidential \nStorageCisterns \nindustrial_area \nmedium_residential \nground_track_field \nrailway_station \ncommercial_area \ncloud \nbasketball_court \nroundabout \ndesert \nisland \nlake \nmountain \npalace \nsea_ice \n\nPredicted label \n\nOriginal label \n\nGLC \n\nStorageCisterns \n\nSparseResidential \n\nRunway \n\nRiver \n\nRailway \n\nParkingSpace \n\nMobile_home_park \n\nIntersection \n\nGolf_course \n\nGameSpace \n\nFreeway \n\nForest \n\nFlyover \n\nFarm \n\nDenseResidential \n\nChaparral \n\nBridge \n\nBeach \n\nBaseball_field \n\nAnchorage \n\nAirfield \n\nAirfield \nAnchorage \nBaseball_field \nBeach \nBridge \nChaparral \nDenseResidential \nFarm \nFlyover \nForest \nFreeway \nGameSpace \nGolf_course \nIntersection \nMobile_home_park \nParkingSpace \nRailway \nRiver \nRunway \nSparseResidential \nStorageCisterns \nindustrial_area \nmedium_residential \nground_track_field \nrailway_station \ncommercial_area \ncloud \nbasketball_court \nroundabout \ndesert \nisland \nlake \nmountain \npalace \nsea_ice \n\nPredicted label \n\nDCC \n\n0% \n\n25% \n\n50% \n\n75% \n\n100% \n\n\n\nDomain separation networks. Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, Dumitru Erhan, NeurIPS. Konstantinos Bousmalis, George Trigeorgis, Nathan Silber- man, Dilip Krishnan, and Dumitru Erhan. Domain separa- tion networks. In NeurIPS, 2016. 2\n\nOn the effectiveness of image rotation for open set domain adaptation. Silvia Bucci, Mohammad Reza Loghmani, Tatiana Tommasi, ECCV. Silvia Bucci, Mohammad Reza Loghmani, and Tatiana Tom- masi. On the effectiveness of image rotation for open set domain adaptation. In ECCV, 2020. 7\n\nA dendrite method for cluster analysis. Tadeusz Cali\u0144ski, Jerzy Harabasz, Communications in Statistics-theory and Methods. 31Tadeusz Cali\u0144ski and Jerzy Harabasz. A dendrite method for cluster analysis. Communications in Statistics-theory and Methods, 3(1):1-27, 1974. 4\n\nPartial transfer learning with selective adversarial networks. Zhangjie Cao, Mingsheng Long, Jianmin Wang, Michael I Jordan , CVPR. 1Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Michael I Jordan. Partial transfer learning with selective ad- versarial networks. In CVPR, 2018. 1, 2\n\nPartial adversarial domain adaptation. Zhangjie Cao, Lijia Ma, Mingsheng Long, Jianmin Wang, ECCV. 1Zhangjie Cao, Lijia Ma, Mingsheng Long, and Jianmin Wang. Partial adversarial domain adaptation. In ECCV, 2018. 1, 2\n\nLearning to transfer examples for partial domain adaptation. Zhangjie Cao, Kaichao You, Mingsheng Long, Jianmin Wang, Qiang Yang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionZhangjie Cao, Kaichao You, Mingsheng Long, Jianmin Wang, and Qiang Yang. Learning to transfer examples for partial domain adaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2985-2994, 2019. 7\n\nGeometric anchor correspondence mining with uncertainty modeling for universal domain adaptation. Liang Chen, Yihang Lou, Jianzhong He, Tao Bai, Minghua Deng, CVPR, 2022. 67Liang Chen, Yihang Lou, Jianzhong He, Tao Bai, and Minghua Deng. Geometric anchor correspondence mining with uncertainty modeling for universal domain adaptation. In CVPR, 2022. 2, 6, 7\n\nRemote sensing image scene classification: Benchmark and state of the art. Gong Cheng, Junwei Han, Xiaoqiang Lu, Proceedings of the IEEE. 10510Gong Cheng, Junwei Han, and Xiaoqiang Lu. Remote sens- ing image scene classification: Benchmark and state of the art. Proceedings of the IEEE, 105(10):1865-1883, 2017. 9\n\nDevis Tuia, and Alain Rakotomamonjy. Optimal transport for domain adaptation. Nicolas Courty, R\u00e9mi Flamary, IEEE TPAMI. 2Nicolas Courty, R\u00e9mi Flamary, Devis Tuia, and Alain Rako- tomamonjy. Optimal transport for domain adaptation. IEEE TPAMI, 2016. 2\n\nA single-cell atlas of in vivo mammalian chromatin accessibility. A Darren, Andrew J Cusanovich, Delasa Hill, Aghamirzaie, M Riza, Daza, A Hannah, Joel B Pliner, Galina N Berletch, Xingfan Filippova, Lena Huang, William S Christiansen, Dewitt, Cell. 174511Darren A Cusanovich, Andrew J Hill, Delasa Aghamirzaie, Riza M Daza, Hannah A Pliner, Joel B Berletch, Galina N Filippova, Xingfan Huang, Lena Christiansen, William S DeWitt, et al. A single-cell atlas of in vivo mammalian chro- matin accessibility. Cell, 174(5):1309-1324, 2018. 11\n\nA cluster separation measure. L David, Donald W Davies, Bouldin, IEEE TPAMI. 4David L Davies and Donald W Bouldin. A cluster separation measure. IEEE TPAMI, 1979. 4\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, CVPR. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009. 6\n\nLearning to detect open classes for universal domain adaptation. Bo Fu, Zhangjie Cao, Mingsheng Long, Jianmin Wang, ECCV, 2020. 6. 79Bo Fu, Zhangjie Cao, Mingsheng Long, and Jianmin Wang. Learning to detect open classes for universal domain adapta- tion. In ECCV, 2020. 6, 7, 9\n\nDomain-adversarial training of neural networks. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, Victor Lempitsky, JMLR. 10Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas- cal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial train- ing of neural networks. JMLR, 2016. 1, 2, 10\n\nDeep reconstructionclassification networks for unsupervised domain adaptation. Muhammad Ghifary, Mengjie Bastiaan Kleijn, David Zhang, Wen Balduzzi, Li, ECCV. Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and Wen Li. Deep reconstruction- classification networks for unsupervised domain adaptation. In ECCV, 2016. 2\n\n. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Generative adversarial networks. Communications of the ACM. 6311Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Commu- nications of the ACM, 63(11):139-144, 2020. 2\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR. 69Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 6, 9\n\nCycada: Cycle-consistent adversarial domain adaptation. Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros, Trevor Darrell, ICML. Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros, and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation. In ICML, 2018. 1\n\nContrastive adaptation network for unsupervised domain adaptation. Guoliang Kang, Lu Jiang, Yi Yang, Alexander G Hauptmann, CVPR. Guoliang Kang, Lu Jiang, Yi Yang, and Alexander G Haupt- mann. Contrastive adaptation network for unsupervised do- main adaptation. In CVPR, 2019. 2\n\nUniversal source-free domain adaptation. Jogendra Nath Kundu, Naveen Venkat, Venkatesh Babu, CVPR. 7Jogendra Nath Kundu, Naveen Venkat, R Venkatesh Babu, et al. Universal source-free domain adaptation. In CVPR, 2020. 2, 3, 7\n\nPseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. Dong-Hyun Lee, ICML Workshop. Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In ICML Workshop, 2013. 3\n\nDomain consensus clustering for universal domain adaptation. Guangrui Li, Guoliang Kang, Yi Zhu, Yunchao Wei, Yi Yang, CVPR, 2021. 6. 79Guangrui Li, Guoliang Kang, Yi Zhu, Yunchao Wei, and Yi Yang. Domain consensus clustering for universal domain adaptation. In CVPR, 2021. 6, 7, 9\n\nModel adaptation: Unsupervised domain adaptation without source data. Rui Li, Qianfen Jiao, Wenming Cao, Hau-San, Si Wong, Wu, CVPR. 2020Rui Li, Qianfen Jiao, Wenming Cao, Hau-San Wong, and Si Wu. Model adaptation: Unsupervised domain adaptation without source data. In CVPR, 2020. 2\n\nDo we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. Jian Liang, Dapeng Hu, Jiashi Feng, ICML. 79Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for un- supervised domain adaptation. In ICML, 2020. 1, 2, 3, 6, 7, 9\n\nUmad: Universal model adaptation under domain and category shift. Jian Liang, Dapeng Hu, Jiashi Feng, Ran He, arXiv:2112.0855379arXiv preprintJian Liang, Dapeng Hu, Jiashi Feng, and Ran He. Umad: Universal model adaptation under domain and category shift. arXiv preprint arXiv:2112.08553, 2021. 2, 3, 6, 7, 9\n\nRan He, and Jiashi Feng. A balanced and uncertainty-aware approach for partial domain adaptation. Jian Liang, Yunbo Wang, Dapeng Hu, ECCV. Jian Liang, Yunbo Wang, Dapeng Hu, Ran He, and Jiashi Feng. A balanced and uncertainty-aware approach for partial domain adaptation. In ECCV, 2020. 7\n\nscjoint integrates atlas-scale single-cell rna-seq and atac-seq data with transfer learning. Yingxin Lin, Tung-Yu Wu, Sheng Wan, Y H Jean, Yang, H Wing, Y X Wong, Wang, Nature Biotechnology. 11Yingxin Lin, Tung-Yu Wu, Sheng Wan, Jean YH Yang, Wing H Wong, and YX Wang. scjoint integrates atlas-scale single-cell rna-seq and atac-seq data with transfer learning. Nature Biotechnology, pages 1-8, 2022. 11\n\nPsdc: A prototype-based shareddummy classifier model for open-set domain adaptation. Zhengfa Liu, Guang Chen, Zhijun Li, Yu Kang, Sanqing Qu, Changjun Jiang, IEEE Transactions on Cybernetics. 12Zhengfa Liu, Guang Chen, Zhijun Li, Yu Kang, Sanqing Qu, and Changjun Jiang. Psdc: A prototype-based shared- dummy classifier model for open-set domain adaptation. IEEE Transactions on Cybernetics, 2022. 1, 2\n\nConditional adversarial domain adaptation. Mingsheng Long, Zhangjie Cao, Jianmin Wang, Michael I Jordan , NeurIPS. 29Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial domain adapta- tion. In NeurIPS, 2018. 2, 9\n\nTransfer feature learning with joint distribution adaptation. Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, Philip S Yu, ICCV. 1Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S Yu. Transfer feature learning with joint distribution adaptation. In ICCV, 2013. 1, 2\n\nSome methods for classification and analysis of multivariate observations. James Macqueen, Proceedings of the fifth Berkeley symposium on mathematical statistics and probability. the fifth Berkeley symposium on mathematical statistics and probabilityOakland, CA, USAJames MacQueen et al. Some methods for classification and analysis of multivariate observations. In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability. Oakland, CA, USA, 1967. 4\n\nIterative human and automated identification of wildlife images. Zhongqi Miao, Ziwei Liu, Kaitlyn M Gaynor, S Meredith, Stella X Palmer, Wayne M Yu, Getz, Nature Machine Intelligence. 310Zhongqi Miao, Ziwei Liu, Kaitlyn M Gaynor, Meredith S Palmer, Stella X Yu, and Wayne M Getz. Iterative human and automated identification of wildlife images. Nature Machine Intelligence, 3(10):885-895, 2021. 10\n\nImage to image translation for domain adaptation. Zak Murez, Soheil Kolouri, David Kriegman, Ravi Ramamoorthi, Kyungnam Kim, CVPR. Zak Murez, Soheil Kolouri, David Kriegman, Ravi Ra- mamoorthi, and Kyungnam Kim. Image to image translation for domain adaptation. In CVPR, 2018. 2\n\nAutomatically identifying, counting, and describing wild animals in camera-trap images with deep learning. Mohammad Sadegh Norouzzadeh, Anh Nguyen, Margaret Kosmala, Alexandra Swanson, S Meredith, Craig Palmer, Jeff Packer, Clune, Proceedings of the National Academy of Sciences. 11525Mohammad Sadegh Norouzzadeh, Anh Nguyen, Margaret Kosmala, Alexandra Swanson, Meredith S Palmer, Craig Packer, and Jeff Clune. Automatically identifying, count- ing, and describing wild animals in camera-trap images with deep learning. Proceedings of the National Academy of Sci- ences, 115(25):E5716-E5725, 2018. 10\n\nA survey on transfer learning. Qiang Sinno Jialin Pan, Yang, IEEE TKDE. 12Sinno Jialin Pan and Qiang Yang. A survey on transfer learn- ing. IEEE TKDE, 2009. 12\n\nTransferrable prototypical networks for unsupervised domain adaptation. Yingwei Pan, Ting Yao, Yehao Li, Yu Wang, Chong-Wah Ngo, Tao Mei, CVPR. Yingwei Pan, Ting Yao, Yehao Li, Yu Wang, Chong-Wah Ngo, and Tao Mei. Transferrable prototypical networks for unsupervised domain adaptation. In CVPR, 2019. 3\n\nOpen set domain adaptation. Panareda Pau, Juergen Busto, Gall, ICCV. 1Pau Panareda Busto and Juergen Gall. Open set domain adaptation. In ICCV, pages 754-763, 2017. 1, 2\n\nMoment matching for multi-source domain adaptation. Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, Bo Wang, ICCV. 26Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching for multi-source domain adaptation. In ICCV, 2019. 2, 6\n\nXingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, Kate Saenko, Visda, arXiv:1710.06924The visual domain adaptation challenge. 26arXiv preprintXingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate Saenko. Visda: The visual domain adaptation challenge. arXiv preprint arXiv:1710.06924, 2017. 2, 6\n\nBmd: A general class-balanced multicentric dynamic prototype strategy for source-free domain adaptation. Sanqing Qu, Guang Chen, Jing Zhang, Zhijun Li, Wei He, Dacheng Tao, ECCV. Springer39Sanqing Qu, Guang Chen, Jing Zhang, Zhijun Li, Wei He, and Dacheng Tao. Bmd: A general class-balanced multi- centric dynamic prototype strategy for source-free domain adaptation. In ECCV. Springer, 2022. 1, 2, 3, 9\n\nSilhouettes: a graphical aid to the interpretation and validation of cluster analysis. J Peter, Rousseeuw, Journal of computational and applied mathematics. 20Peter J Rousseeuw. Silhouettes: a graphical aid to the inter- pretation and validation of cluster analysis. Journal of com- putational and applied mathematics, 20:53-65, 1987. 2, 3, 4, 5\n\nAdapting visual category models to new domains. Kate Saenko, Brian Kulis, Mario Fritz, Trevor Darrell, ECCV. 6Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to new domains. In ECCV, 2010. 2, 5, 6\n\nUniversal domain adaptation through self supervision. Kuniaki Saito, Donghyun Kim, Stan Sclaroff, Kate Saenko, NeurIPS. 10Kuniaki Saito, Donghyun Kim, Stan Sclaroff, and Kate Saenko. Universal domain adaptation through self supervi- sion. In NeurIPS, 2020. 1, 2, 7, 9, 10\n\nOvanet: One-vs-all network for universal domain adaptation. Kuniaki Saito, Kate Saenko, ICCV. 10Kuniaki Saito and Kate Saenko. Ovanet: One-vs-all network for universal domain adaptation. In ICCV, 2021. 2, 6, 7, 9, 10\n\nMaximum classifier discrepancy for unsupervised domain adaptation. Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, Tatsuya Harada, CVPR. 1Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat- suya Harada. Maximum classifier discrepancy for unsuper- vised domain adaptation. In CVPR, 2018. 1, 2\n\nOpen set domain adaptation by backpropagation. Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, Tatsuya Harada, ECCV. 10Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada. Open set domain adaptation by backpropa- gation. In ECCV, 2018. 2, 7, 10\n\nSingle-cell transcriptomics of 20 mouse organs creates a tabula muris: The tabula muris consortium. Nicholas Schaum, Jim Karkanias, Norma F Neff, Andrew P May, Tony Stephen R Quake, Spyros Wyss-Coray, Joshua Darmanis, Olga Batson, Michelle B Botvinnik, Chen, Nature. 562772711Nicholas Schaum, Jim Karkanias, Norma F Neff, Andrew P May, Stephen R Quake, Tony Wyss-Coray, Spyros Dar- manis, Joshua Batson, Olga Botvinnik, Michelle B Chen, et al. Single-cell transcriptomics of 20 mouse organs cre- ates a tabula muris: The tabula muris consortium. Nature, 562(7727):367, 2018. 11\n\nGrad-cam: Visual explanations from deep networks via gradient-based localization. R Ramprasaath, Michael Selvaraju, Abhishek Cogswell, Ramakrishna Das, Devi Vedantam, Dhruv Parikh, Batra, ICCV. Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In ICCV, pages 618-626, 2017. 10\n\nA mathematical theory of communication. The Bell system technical journal. Claude Elwood Shannon, 27Claude Elwood Shannon. A mathematical theory of commu- nication. The Bell system technical journal, 27(3):379-423, 1948. 5\n\nComprehensive integration of single-cell data. Tim Stuart, Andrew Butler, Paul Hoffman, Christoph Hafemeister, Efthymia Papalexi, William M Mauck, Iii , Yuhan Hao, Marlon Stoeckius, Peter Smibert, Rahul Satija, Cell. 177711Tim Stuart, Andrew Butler, Paul Hoffman, Christoph Hafemeister, Efthymia Papalexi, William M Mauck III, Yuhan Hao, Marlon Stoeckius, Peter Smibert, and Rahul Satija. Comprehensive integration of single-cell data. Cell, 177(7):1888-1902, 2019. 11\n\nIntegrative single-cell analysis. Tim Stuart, Rahul Satija, Nature reviews genetics. 20511Tim Stuart and Rahul Satija. Integrative single-cell analysis. Nature reviews genetics, 20(5):257-272, 2019. 11\n\nEstimating the number of clusters in a data set via the gap statistic. Robert Tibshirani, Guenther Walther, Trevor Hastie, Journal of the Royal Statistical Society: Series B (Statistical Methodology). 632Robert Tibshirani, Guenther Walther, and Trevor Hastie. Es- timating the number of clusters in a data set via the gap statis- tic. Journal of the Royal Statistical Society: Series B (Statis- tical Methodology), 63(2):411-423, 2001. 4\n\nDeep hashing network for unsupervised domain adaptation. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, Sethuraman Panchanathan, CVPR. 6Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, 2017. 2, 5, 6\n\nThe eu general data protection regulation (gdpr). Paul Voigt, Axel Von, Bussche, Springer International Publishing10ChamA Practical Guide. 1st EdPaul Voigt and Axel Von dem Bussche. The eu general data protection regulation (gdpr). A Practical Guide, 1st Ed., Cham: Springer International Publishing, 10(3152676):10- 5555, 2017. 1, 2\n\nZero-shot learning-the good, the bad and the ugly. Yongqin Xian, Bernt Schiele, Zeynep Akata, CVPR. Yongqin Xian, Bernt Schiele, and Zeynep Akata. Zero-shot learning-the good, the bad and the ugly. In CVPR, 2017. 10\n\nGeneralized source-free domain adaptation. Shiqi Yang, Yaxing Wang, Joost Van De, Luis Weijer, Shangling Herranz, Jui, ICCV, 2021. 1Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, and Shangling Jui. Generalized source-free domain adapta- tion. In ICCV, 2021. 1, 2\n\nUniversal domain adaptation. Kaichao You, Mingsheng Long, Zhangjie Cao, Jianmin Wang, Michael I Jordan , CVPR. 69Kaichao You, Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Universal domain adaptation. In CVPR, 2019. 1, 2, 6, 9\n\nProgress and challenges in intelligent remote sensing satellite systems. Bing Zhang, Yuanfeng Wu, Boya Zhao, Jocelyn Chanussot, Danfeng Hong, Jing Yao, Lianru Gao, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 20229Bing Zhang, Yuanfeng Wu, Boya Zhao, Jocelyn Chanussot, Danfeng Hong, Jing Yao, and Lianru Gao. Progress and chal- lenges in intelligent remote sensing satellite systems. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2022. 9\n\nApproach and practice: integrating earth observation resources for data sharing in china geoss. Lianchong Zhang, Guoqing Li, Chi Zhang, Huanyin Yue, Xiaohan Liao, International Journal of Digital Earth. 1212Lianchong Zhang, Guoqing Li, Chi Zhang, Huanyin Yue, and Xiaohan Liao. Approach and practice: integrating earth observation resources for data sharing in china geoss. Inter- national Journal of Digital Earth, 12(12):1441-1456, 2019. 9\n\nBridging theory and algorithm for domain adaptation. Yuchen Zhang, Tianle Liu, Mingsheng Long, Michael Jordan, ICML. Yuchen Zhang, Tianle Liu, Mingsheng Long, and Michael Jordan. Bridging theory and algorithm for domain adapta- tion. In ICML, 2019. 9\n\nPatternnet: A benchmark dataset for performance evaluation of remote sensing image retrieval. ISPRS journal of photogrammetry and remote sensing. Weixun Zhou, Shawn Newsam, Congmin Li, Zhenfeng Shao, 145Weixun Zhou, Shawn Newsam, Congmin Li, and Zhenfeng Shao. Patternnet: A benchmark dataset for performance evaluation of remote sensing image retrieval. ISPRS journal of photogrammetry and remote sensing, 145:197-209, 2018. 9\n\nUnsupervised open domain recognition by semantic discrepancy minimization. Junbao Zhuo, Shuhui Wang, Shuhao Cui, Qingming Huang, CVPR. Junbao Zhuo, Shuhui Wang, Shuhao Cui, and Qingming Huang. Unsupervised open domain recognition by seman- tic discrepancy minimization. In CVPR, 2019. 10\n", "annotations": {"author": "[{\"end\":83,\"start\":52},{\"end\":116,\"start\":84},{\"end\":170,\"start\":117},{\"end\":211,\"start\":171},{\"end\":243,\"start\":212},{\"end\":246,\"start\":244},{\"end\":307,\"start\":247},{\"end\":343,\"start\":308}]", "publisher": null, "author_last_name": "[{\"end\":62,\"start\":60},{\"end\":95,\"start\":92},{\"end\":133,\"start\":125},{\"end\":178,\"start\":176},{\"end\":222,\"start\":218},{\"end\":258,\"start\":255},{\"end\":322,\"start\":317}]", "author_first_name": "[{\"end\":59,\"start\":52},{\"end\":91,\"start\":84},{\"end\":124,\"start\":117},{\"end\":175,\"start\":171},{\"end\":217,\"start\":212},{\"end\":245,\"start\":244},{\"end\":254,\"start\":247},{\"end\":316,\"start\":308}]", "author_affiliation": "[{\"end\":82,\"start\":64},{\"end\":115,\"start\":97},{\"end\":169,\"start\":135},{\"end\":210,\"start\":180},{\"end\":242,\"start\":224},{\"end\":279,\"start\":260},{\"end\":306,\"start\":281},{\"end\":342,\"start\":324}]", "title": "[{\"end\":49,\"start\":1},{\"end\":392,\"start\":344}]", "venue": null, "abstract": "[{\"end\":1907,\"start\":394}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2210,\"start\":2206},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2213,\"start\":2210},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2216,\"start\":2213},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2219,\"start\":2216},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2480,\"start\":2476},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2532,\"start\":2528},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2535,\"start\":2532},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":2538,\"start\":2535},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2745,\"start\":2741},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2748,\"start\":2745},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":2751,\"start\":2748},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3444,\"start\":3441},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3446,\"start\":3444},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3449,\"start\":3446},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3452,\"start\":3449},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3455,\"start\":3452},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3458,\"start\":3455},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4292,\"start\":4288},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4295,\"start\":4292},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5097,\"start\":5093},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":5739,\"start\":5735},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":5757,\"start\":5753},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":5769,\"start\":5765},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5790,\"start\":5786},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6850,\"start\":6847},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6853,\"start\":6850},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6856,\"start\":6853},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7081,\"start\":7078},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7084,\"start\":7081},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":7087,\"start\":7084},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7250,\"start\":7246},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7285,\"start\":7281},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7288,\"start\":7285},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":7291,\"start\":7288},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7577,\"start\":7574},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7579,\"start\":7577},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7594,\"start\":7590},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7597,\"start\":7594},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7600,\"start\":7597},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7645,\"start\":7641},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":7648,\"start\":7645},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":7836,\"start\":7832},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7915,\"start\":7912},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7918,\"start\":7915},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":8180,\"start\":8176},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8241,\"start\":8237},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8244,\"start\":8241},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8247,\"start\":8244},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":8250,\"start\":8247},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8548,\"start\":8544},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8551,\"start\":8548},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8638,\"start\":8634},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9083,\"start\":9079},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10560,\"start\":10556},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10563,\"start\":10560},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10922,\"start\":10918},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10925,\"start\":10922},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11714,\"start\":11710},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11911,\"start\":11907},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11914,\"start\":11911},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12878,\"start\":12874},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":17682,\"start\":17678},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17727,\"start\":17724},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17730,\"start\":17727},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":17733,\"start\":17730},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":17736,\"start\":17733},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":17877,\"start\":17873},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":20922,\"start\":20918},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":21925,\"start\":21921},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":22131,\"start\":22127},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22390,\"start\":22387},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":22404,\"start\":22400},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22639,\"start\":22636},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22642,\"start\":22639},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":23069,\"start\":23065},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23098,\"start\":23094},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23241,\"start\":23237},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24471,\"start\":24467},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24474,\"start\":24471},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25108,\"start\":25105},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":25122,\"start\":25118},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":28886,\"start\":28882},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":28899,\"start\":28895},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29881,\"start\":29877},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":30219,\"start\":30215},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":30472,\"start\":30468},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":31280,\"start\":31276},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":31538,\"start\":31534},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":31677,\"start\":31673},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":31696,\"start\":31693},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":34259,\"start\":34255},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":34314,\"start\":34310},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":34709,\"start\":34705},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":35201,\"start\":35197},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":35571,\"start\":35567},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":35971,\"start\":35967},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":35982,\"start\":35978},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":36053,\"start\":36049},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":36066,\"start\":36062},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":37988,\"start\":37984},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":38689,\"start\":38685},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":38737,\"start\":38733},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":39396,\"start\":39392},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":39420,\"start\":39416},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39541,\"start\":39537},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39733,\"start\":39729},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":41667,\"start\":41663},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":47049,\"start\":47045}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":44053,\"start\":43397},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44135,\"start\":44054},{\"attributes\":{\"id\":\"fig_2\"},\"end\":44474,\"start\":44136},{\"attributes\":{\"id\":\"fig_3\"},\"end\":44848,\"start\":44475},{\"attributes\":{\"id\":\"fig_4\"},\"end\":45283,\"start\":44849},{\"attributes\":{\"id\":\"fig_5\"},\"end\":45979,\"start\":45284},{\"attributes\":{\"id\":\"fig_8\"},\"end\":46520,\"start\":45980},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":46826,\"start\":46521},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":49891,\"start\":46827},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":52504,\"start\":49892},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":53052,\"start\":52505},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":54249,\"start\":53053},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":54718,\"start\":54250},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":56635,\"start\":54719}]", "paragraph": "[{\"end\":2889,\"start\":1923},{\"end\":4662,\"start\":2891},{\"end\":5638,\"start\":4664},{\"end\":6013,\"start\":5640},{\"end\":6062,\"start\":6015},{\"end\":6241,\"start\":6064},{\"end\":6491,\"start\":6243},{\"end\":8517,\"start\":6508},{\"end\":9155,\"start\":8519},{\"end\":9409,\"start\":9157},{\"end\":9702,\"start\":9439},{\"end\":10528,\"start\":9847},{\"end\":11571,\"start\":10530},{\"end\":12351,\"start\":11604},{\"end\":13094,\"start\":12353},{\"end\":13481,\"start\":13096},{\"end\":13810,\"start\":13483},{\"end\":13924,\"start\":13812},{\"end\":14307,\"start\":13954},{\"end\":14496,\"start\":14383},{\"end\":14735,\"start\":14625},{\"end\":15535,\"start\":14737},{\"end\":16121,\"start\":15583},{\"end\":16572,\"start\":16123},{\"end\":16996,\"start\":16759},{\"end\":17435,\"start\":17046},{\"end\":17821,\"start\":17437},{\"end\":17994,\"start\":17823},{\"end\":18790,\"start\":18146},{\"end\":19190,\"start\":18792},{\"end\":19489,\"start\":19221},{\"end\":19883,\"start\":19491},{\"end\":20446,\"start\":19990},{\"end\":20524,\"start\":20473},{\"end\":20804,\"start\":20628},{\"end\":20992,\"start\":20826},{\"end\":21472,\"start\":21064},{\"end\":21768,\"start\":21545},{\"end\":22533,\"start\":21792},{\"end\":22931,\"start\":22535},{\"end\":23871,\"start\":22933},{\"end\":25326,\"start\":23894},{\"end\":25929,\"start\":25328},{\"end\":26798,\"start\":25953},{\"end\":27779,\"start\":26800},{\"end\":28152,\"start\":27781},{\"end\":28648,\"start\":28180},{\"end\":28774,\"start\":28678},{\"end\":29180,\"start\":28807},{\"end\":29501,\"start\":29237},{\"end\":30622,\"start\":29545},{\"end\":31021,\"start\":30667},{\"end\":32745,\"start\":31089},{\"end\":33980,\"start\":32747},{\"end\":35441,\"start\":34045},{\"end\":36068,\"start\":35443},{\"end\":36890,\"start\":36070},{\"end\":37408,\"start\":36892},{\"end\":37594,\"start\":37410},{\"end\":39421,\"start\":37666},{\"end\":40270,\"start\":39423},{\"end\":41301,\"start\":40272},{\"end\":42786,\"start\":41319},{\"end\":43396,\"start\":42788}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9846,\"start\":9703},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13953,\"start\":13925},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14382,\"start\":14308},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14624,\"start\":14497},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16758,\"start\":16573},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18145,\"start\":17995},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19989,\"start\":19884},{\"attributes\":{\"id\":\"formula_7\"},\"end\":20627,\"start\":20525},{\"attributes\":{\"id\":\"formula_8\"},\"end\":21063,\"start\":20993},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21544,\"start\":21473},{\"attributes\":{\"id\":\"formula_10\"},\"end\":28806,\"start\":28775},{\"attributes\":{\"id\":\"formula_11\"},\"end\":29236,\"start\":29181}]", "table_ref": "[{\"end\":22297,\"start\":22290},{\"end\":22532,\"start\":22525},{\"end\":24829,\"start\":24822},{\"end\":24902,\"start\":24895},{\"end\":24935,\"start\":24916},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":25537,\"start\":25530},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":25558,\"start\":25551},{\"end\":25668,\"start\":25661},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26164,\"start\":26157},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":29988,\"start\":29981},{\"end\":30044,\"start\":30038}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1921,\"start\":1909},{\"attributes\":{\"n\":\"2.\"},\"end\":6506,\"start\":6494},{\"attributes\":{\"n\":\"3.\"},\"end\":9423,\"start\":9412},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9437,\"start\":9426},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11602,\"start\":11574},{\"attributes\":{\"n\":\"3.3.\"},\"end\":15581,\"start\":15538},{\"attributes\":{\"n\":\"3.4.\"},\"end\":17044,\"start\":16999},{\"attributes\":{\"n\":\"3.5.\"},\"end\":19219,\"start\":19193},{\"attributes\":{\"n\":\"3.6.\"},\"end\":20471,\"start\":20449},{\"attributes\":{\"n\":\"3.7.\"},\"end\":20824,\"start\":20807},{\"attributes\":{\"n\":\"4.\"},\"end\":21782,\"start\":21771},{\"attributes\":{\"n\":\"4.1.\"},\"end\":21790,\"start\":21785},{\"attributes\":{\"n\":\"4.2.\"},\"end\":23892,\"start\":23874},{\"attributes\":{\"n\":\"4.3.\"},\"end\":25951,\"start\":25932},{\"attributes\":{\"n\":\"4.4.\"},\"end\":28165,\"start\":28155},{\"attributes\":{\"n\":\"5.\"},\"end\":28178,\"start\":28168},{\"end\":28676,\"start\":28651},{\"end\":29543,\"start\":29504},{\"end\":30665,\"start\":30625},{\"end\":31087,\"start\":31024},{\"end\":34043,\"start\":33983},{\"end\":37664,\"start\":37597},{\"end\":41317,\"start\":41304},{\"end\":43408,\"start\":43398},{\"end\":44065,\"start\":44055},{\"end\":44147,\"start\":44137},{\"end\":44860,\"start\":44850},{\"end\":49902,\"start\":49893},{\"end\":52515,\"start\":52506},{\"end\":53063,\"start\":53054}]", "table": "[{\"end\":49891,\"start\":47209},{\"end\":52504,\"start\":50019},{\"end\":53052,\"start\":52867},{\"end\":54249,\"start\":53150},{\"end\":56635,\"start\":55434}]", "figure_caption": "[{\"end\":44053,\"start\":43410},{\"end\":44135,\"start\":44067},{\"end\":44474,\"start\":44149},{\"end\":44848,\"start\":44477},{\"end\":45283,\"start\":44862},{\"end\":45979,\"start\":45286},{\"end\":46520,\"start\":45982},{\"end\":46826,\"start\":46523},{\"end\":47209,\"start\":46829},{\"end\":50019,\"start\":49904},{\"end\":52867,\"start\":52517},{\"end\":53150,\"start\":53065},{\"end\":54718,\"start\":54252},{\"end\":55434,\"start\":54721}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4260,\"start\":4254},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11521,\"start\":11515},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":26928,\"start\":26916},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":27389,\"start\":27379},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":27719,\"start\":27713},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28060,\"start\":28054},{\"end\":32784,\"start\":32777},{\"end\":33488,\"start\":33481},{\"end\":35535,\"start\":35528},{\"end\":36111,\"start\":36102},{\"end\":36303,\"start\":36296},{\"end\":36526,\"start\":36519},{\"end\":37023,\"start\":37016},{\"end\":37593,\"start\":37586},{\"end\":39462,\"start\":39455},{\"end\":40080,\"start\":40073},{\"end\":40362,\"start\":40355},{\"end\":40401,\"start\":40393},{\"end\":42077,\"start\":42069}]", "bib_author_first_name": "[{\"end\":56677,\"start\":56665},{\"end\":56695,\"start\":56689},{\"end\":56714,\"start\":56708},{\"end\":56731,\"start\":56726},{\"end\":56749,\"start\":56742},{\"end\":56992,\"start\":56986},{\"end\":57008,\"start\":57000},{\"end\":57013,\"start\":57009},{\"end\":57031,\"start\":57024},{\"end\":57244,\"start\":57237},{\"end\":57260,\"start\":57255},{\"end\":57539,\"start\":57531},{\"end\":57554,\"start\":57545},{\"end\":57568,\"start\":57561},{\"end\":57591,\"start\":57575},{\"end\":57800,\"start\":57792},{\"end\":57811,\"start\":57806},{\"end\":57825,\"start\":57816},{\"end\":57839,\"start\":57832},{\"end\":58040,\"start\":58032},{\"end\":58053,\"start\":58046},{\"end\":58068,\"start\":58059},{\"end\":58082,\"start\":58075},{\"end\":58094,\"start\":58089},{\"end\":58599,\"start\":58594},{\"end\":58612,\"start\":58606},{\"end\":58627,\"start\":58618},{\"end\":58635,\"start\":58632},{\"end\":58648,\"start\":58641},{\"end\":58935,\"start\":58931},{\"end\":58949,\"start\":58943},{\"end\":58964,\"start\":58955},{\"end\":59256,\"start\":59249},{\"end\":59269,\"start\":59265},{\"end\":59490,\"start\":59489},{\"end\":59505,\"start\":59499},{\"end\":59507,\"start\":59506},{\"end\":59526,\"start\":59520},{\"end\":59547,\"start\":59546},{\"end\":59561,\"start\":59560},{\"end\":59574,\"start\":59570},{\"end\":59576,\"start\":59575},{\"end\":59591,\"start\":59585},{\"end\":59593,\"start\":59592},{\"end\":59611,\"start\":59604},{\"end\":59627,\"start\":59623},{\"end\":59642,\"start\":59635},{\"end\":59644,\"start\":59643},{\"end\":59994,\"start\":59993},{\"end\":60008,\"start\":60002},{\"end\":60010,\"start\":60009},{\"end\":60185,\"start\":60182},{\"end\":60195,\"start\":60192},{\"end\":60209,\"start\":60202},{\"end\":60224,\"start\":60218},{\"end\":60232,\"start\":60229},{\"end\":60239,\"start\":60237},{\"end\":60464,\"start\":60462},{\"end\":60477,\"start\":60469},{\"end\":60492,\"start\":60483},{\"end\":60506,\"start\":60499},{\"end\":60732,\"start\":60724},{\"end\":60748,\"start\":60740},{\"end\":60763,\"start\":60759},{\"end\":60778,\"start\":60772},{\"end\":60792,\"start\":60788},{\"end\":60813,\"start\":60805},{\"end\":60831,\"start\":60826},{\"end\":60848,\"start\":60842},{\"end\":61169,\"start\":61161},{\"end\":61186,\"start\":61179},{\"end\":61209,\"start\":61204},{\"end\":61220,\"start\":61217},{\"end\":61425,\"start\":61422},{\"end\":61442,\"start\":61438},{\"end\":61463,\"start\":61458},{\"end\":61475,\"start\":61471},{\"end\":61485,\"start\":61480},{\"end\":61507,\"start\":61500},{\"end\":61520,\"start\":61515},{\"end\":61538,\"start\":61532},{\"end\":61880,\"start\":61873},{\"end\":61892,\"start\":61885},{\"end\":61908,\"start\":61900},{\"end\":61918,\"start\":61914},{\"end\":62114,\"start\":62110},{\"end\":62128,\"start\":62124},{\"end\":62143,\"start\":62136},{\"end\":62157,\"start\":62150},{\"end\":62170,\"start\":62163},{\"end\":62182,\"start\":62178},{\"end\":62197,\"start\":62191},{\"end\":62211,\"start\":62205},{\"end\":62491,\"start\":62483},{\"end\":62500,\"start\":62498},{\"end\":62510,\"start\":62508},{\"end\":62526,\"start\":62517},{\"end\":62528,\"start\":62527},{\"end\":62745,\"start\":62737},{\"end\":62764,\"start\":62758},{\"end\":63028,\"start\":63019},{\"end\":63263,\"start\":63255},{\"end\":63276,\"start\":63268},{\"end\":63285,\"start\":63283},{\"end\":63298,\"start\":63291},{\"end\":63306,\"start\":63304},{\"end\":63550,\"start\":63547},{\"end\":63562,\"start\":63555},{\"end\":63576,\"start\":63569},{\"end\":63593,\"start\":63591},{\"end\":63874,\"start\":63870},{\"end\":63888,\"start\":63882},{\"end\":63899,\"start\":63893},{\"end\":64167,\"start\":64163},{\"end\":64181,\"start\":64175},{\"end\":64192,\"start\":64186},{\"end\":64202,\"start\":64199},{\"end\":64509,\"start\":64505},{\"end\":64522,\"start\":64517},{\"end\":64535,\"start\":64529},{\"end\":64797,\"start\":64790},{\"end\":64810,\"start\":64803},{\"end\":64820,\"start\":64815},{\"end\":64827,\"start\":64826},{\"end\":64829,\"start\":64828},{\"end\":64843,\"start\":64842},{\"end\":64851,\"start\":64850},{\"end\":64853,\"start\":64852},{\"end\":65194,\"start\":65187},{\"end\":65205,\"start\":65200},{\"end\":65218,\"start\":65212},{\"end\":65225,\"start\":65223},{\"end\":65239,\"start\":65232},{\"end\":65252,\"start\":65244},{\"end\":65558,\"start\":65549},{\"end\":65573,\"start\":65565},{\"end\":65586,\"start\":65579},{\"end\":65609,\"start\":65593},{\"end\":65829,\"start\":65820},{\"end\":65843,\"start\":65836},{\"end\":65858,\"start\":65850},{\"end\":65873,\"start\":65865},{\"end\":65887,\"start\":65879},{\"end\":66138,\"start\":66133},{\"end\":66611,\"start\":66604},{\"end\":66623,\"start\":66618},{\"end\":66636,\"start\":66629},{\"end\":66638,\"start\":66637},{\"end\":66648,\"start\":66647},{\"end\":66665,\"start\":66659},{\"end\":66667,\"start\":66666},{\"end\":66683,\"start\":66676},{\"end\":66991,\"start\":66988},{\"end\":67005,\"start\":66999},{\"end\":67020,\"start\":67015},{\"end\":67035,\"start\":67031},{\"end\":67057,\"start\":67049},{\"end\":67333,\"start\":67325},{\"end\":67357,\"start\":67354},{\"end\":67374,\"start\":67366},{\"end\":67393,\"start\":67384},{\"end\":67404,\"start\":67403},{\"end\":67420,\"start\":67415},{\"end\":67433,\"start\":67429},{\"end\":67857,\"start\":67852},{\"end\":68061,\"start\":68054},{\"end\":68071,\"start\":68067},{\"end\":68082,\"start\":68077},{\"end\":68089,\"start\":68087},{\"end\":68105,\"start\":68096},{\"end\":68114,\"start\":68111},{\"end\":68322,\"start\":68314},{\"end\":68335,\"start\":68328},{\"end\":68517,\"start\":68509},{\"end\":68530,\"start\":68524},{\"end\":68540,\"start\":68536},{\"end\":68551,\"start\":68546},{\"end\":68563,\"start\":68559},{\"end\":68574,\"start\":68572},{\"end\":68746,\"start\":68738},{\"end\":68756,\"start\":68753},{\"end\":68769,\"start\":68764},{\"end\":68783,\"start\":68779},{\"end\":68799,\"start\":68793},{\"end\":68810,\"start\":68806},{\"end\":69187,\"start\":69180},{\"end\":69197,\"start\":69192},{\"end\":69208,\"start\":69204},{\"end\":69222,\"start\":69216},{\"end\":69230,\"start\":69227},{\"end\":69242,\"start\":69235},{\"end\":69568,\"start\":69567},{\"end\":69879,\"start\":69875},{\"end\":69893,\"start\":69888},{\"end\":69906,\"start\":69901},{\"end\":69920,\"start\":69914},{\"end\":70129,\"start\":70122},{\"end\":70145,\"start\":70137},{\"end\":70155,\"start\":70151},{\"end\":70170,\"start\":70166},{\"end\":70408,\"start\":70401},{\"end\":70420,\"start\":70416},{\"end\":70633,\"start\":70626},{\"end\":70646,\"start\":70641},{\"end\":70666,\"start\":70657},{\"end\":70682,\"start\":70675},{\"end\":70913,\"start\":70906},{\"end\":70927,\"start\":70921},{\"end\":70947,\"start\":70938},{\"end\":70963,\"start\":70956},{\"end\":71232,\"start\":71224},{\"end\":71244,\"start\":71241},{\"end\":71261,\"start\":71256},{\"end\":71263,\"start\":71262},{\"end\":71276,\"start\":71270},{\"end\":71278,\"start\":71277},{\"end\":71288,\"start\":71284},{\"end\":71312,\"start\":71306},{\"end\":71331,\"start\":71325},{\"end\":71346,\"start\":71342},{\"end\":71363,\"start\":71355},{\"end\":71365,\"start\":71364},{\"end\":71786,\"start\":71785},{\"end\":71807,\"start\":71800},{\"end\":71827,\"start\":71819},{\"end\":71849,\"start\":71838},{\"end\":71859,\"start\":71855},{\"end\":71875,\"start\":71870},{\"end\":72203,\"start\":72197},{\"end\":72210,\"start\":72204},{\"end\":72396,\"start\":72393},{\"end\":72411,\"start\":72405},{\"end\":72424,\"start\":72420},{\"end\":72443,\"start\":72434},{\"end\":72465,\"start\":72457},{\"end\":72483,\"start\":72476},{\"end\":72485,\"start\":72484},{\"end\":72496,\"start\":72493},{\"end\":72504,\"start\":72499},{\"end\":72516,\"start\":72510},{\"end\":72533,\"start\":72528},{\"end\":72548,\"start\":72543},{\"end\":72853,\"start\":72850},{\"end\":72867,\"start\":72862},{\"end\":73096,\"start\":73090},{\"end\":73117,\"start\":73109},{\"end\":73133,\"start\":73127},{\"end\":73522,\"start\":73515},{\"end\":73541,\"start\":73537},{\"end\":73557,\"start\":73551},{\"end\":73581,\"start\":73571},{\"end\":73823,\"start\":73819},{\"end\":73835,\"start\":73831},{\"end\":74162,\"start\":74155},{\"end\":74174,\"start\":74169},{\"end\":74190,\"start\":74184},{\"end\":74369,\"start\":74364},{\"end\":74382,\"start\":74376},{\"end\":74394,\"start\":74389},{\"end\":74407,\"start\":74403},{\"end\":74425,\"start\":74416},{\"end\":74634,\"start\":74627},{\"end\":74649,\"start\":74640},{\"end\":74664,\"start\":74656},{\"end\":74677,\"start\":74670},{\"end\":74700,\"start\":74684},{\"end\":74923,\"start\":74919},{\"end\":74939,\"start\":74931},{\"end\":74948,\"start\":74944},{\"end\":74962,\"start\":74955},{\"end\":74981,\"start\":74974},{\"end\":74992,\"start\":74988},{\"end\":75004,\"start\":74998},{\"end\":75463,\"start\":75454},{\"end\":75478,\"start\":75471},{\"end\":75486,\"start\":75483},{\"end\":75501,\"start\":75494},{\"end\":75514,\"start\":75507},{\"end\":75860,\"start\":75854},{\"end\":75874,\"start\":75868},{\"end\":75889,\"start\":75880},{\"end\":75903,\"start\":75896},{\"end\":76205,\"start\":76199},{\"end\":76217,\"start\":76212},{\"end\":76233,\"start\":76226},{\"end\":76246,\"start\":76238},{\"end\":76563,\"start\":76557},{\"end\":76576,\"start\":76570},{\"end\":76589,\"start\":76583},{\"end\":76603,\"start\":76595}]", "bib_author_last_name": "[{\"end\":56687,\"start\":56678},{\"end\":56706,\"start\":56696},{\"end\":56724,\"start\":56715},{\"end\":56740,\"start\":56732},{\"end\":56755,\"start\":56750},{\"end\":56998,\"start\":56993},{\"end\":57022,\"start\":57014},{\"end\":57039,\"start\":57032},{\"end\":57253,\"start\":57245},{\"end\":57269,\"start\":57261},{\"end\":57543,\"start\":57540},{\"end\":57559,\"start\":57555},{\"end\":57573,\"start\":57569},{\"end\":57804,\"start\":57801},{\"end\":57814,\"start\":57812},{\"end\":57830,\"start\":57826},{\"end\":57844,\"start\":57840},{\"end\":58044,\"start\":58041},{\"end\":58057,\"start\":58054},{\"end\":58073,\"start\":58069},{\"end\":58087,\"start\":58083},{\"end\":58099,\"start\":58095},{\"end\":58604,\"start\":58600},{\"end\":58616,\"start\":58613},{\"end\":58630,\"start\":58628},{\"end\":58639,\"start\":58636},{\"end\":58653,\"start\":58649},{\"end\":58941,\"start\":58936},{\"end\":58953,\"start\":58950},{\"end\":58967,\"start\":58965},{\"end\":59263,\"start\":59257},{\"end\":59277,\"start\":59270},{\"end\":59497,\"start\":59491},{\"end\":59518,\"start\":59508},{\"end\":59531,\"start\":59527},{\"end\":59544,\"start\":59533},{\"end\":59552,\"start\":59548},{\"end\":59558,\"start\":59554},{\"end\":59568,\"start\":59562},{\"end\":59583,\"start\":59577},{\"end\":59602,\"start\":59594},{\"end\":59621,\"start\":59612},{\"end\":59633,\"start\":59628},{\"end\":59657,\"start\":59645},{\"end\":59665,\"start\":59659},{\"end\":60000,\"start\":59995},{\"end\":60017,\"start\":60011},{\"end\":60026,\"start\":60019},{\"end\":60190,\"start\":60186},{\"end\":60200,\"start\":60196},{\"end\":60216,\"start\":60210},{\"end\":60227,\"start\":60225},{\"end\":60235,\"start\":60233},{\"end\":60247,\"start\":60240},{\"end\":60467,\"start\":60465},{\"end\":60481,\"start\":60478},{\"end\":60497,\"start\":60493},{\"end\":60511,\"start\":60507},{\"end\":60738,\"start\":60733},{\"end\":60757,\"start\":60749},{\"end\":60770,\"start\":60764},{\"end\":60786,\"start\":60779},{\"end\":60803,\"start\":60793},{\"end\":60824,\"start\":60814},{\"end\":60840,\"start\":60832},{\"end\":60858,\"start\":60849},{\"end\":61177,\"start\":61170},{\"end\":61202,\"start\":61187},{\"end\":61215,\"start\":61210},{\"end\":61229,\"start\":61221},{\"end\":61233,\"start\":61231},{\"end\":61436,\"start\":61426},{\"end\":61456,\"start\":61443},{\"end\":61469,\"start\":61464},{\"end\":61478,\"start\":61476},{\"end\":61498,\"start\":61486},{\"end\":61513,\"start\":61508},{\"end\":61530,\"start\":61521},{\"end\":61545,\"start\":61539},{\"end\":61883,\"start\":61881},{\"end\":61898,\"start\":61893},{\"end\":61912,\"start\":61909},{\"end\":61922,\"start\":61919},{\"end\":62122,\"start\":62115},{\"end\":62134,\"start\":62129},{\"end\":62148,\"start\":62144},{\"end\":62161,\"start\":62158},{\"end\":62176,\"start\":62171},{\"end\":62189,\"start\":62183},{\"end\":62203,\"start\":62198},{\"end\":62219,\"start\":62212},{\"end\":62496,\"start\":62492},{\"end\":62506,\"start\":62501},{\"end\":62515,\"start\":62511},{\"end\":62538,\"start\":62529},{\"end\":62756,\"start\":62746},{\"end\":62771,\"start\":62765},{\"end\":62787,\"start\":62773},{\"end\":63032,\"start\":63029},{\"end\":63266,\"start\":63264},{\"end\":63281,\"start\":63277},{\"end\":63289,\"start\":63286},{\"end\":63302,\"start\":63299},{\"end\":63311,\"start\":63307},{\"end\":63553,\"start\":63551},{\"end\":63567,\"start\":63563},{\"end\":63580,\"start\":63577},{\"end\":63589,\"start\":63582},{\"end\":63598,\"start\":63594},{\"end\":63602,\"start\":63600},{\"end\":63880,\"start\":63875},{\"end\":63891,\"start\":63889},{\"end\":63904,\"start\":63900},{\"end\":64173,\"start\":64168},{\"end\":64184,\"start\":64182},{\"end\":64197,\"start\":64193},{\"end\":64205,\"start\":64203},{\"end\":64515,\"start\":64510},{\"end\":64527,\"start\":64523},{\"end\":64538,\"start\":64536},{\"end\":64801,\"start\":64798},{\"end\":64813,\"start\":64811},{\"end\":64824,\"start\":64821},{\"end\":64834,\"start\":64830},{\"end\":64840,\"start\":64836},{\"end\":64848,\"start\":64844},{\"end\":64858,\"start\":64854},{\"end\":64864,\"start\":64860},{\"end\":65198,\"start\":65195},{\"end\":65210,\"start\":65206},{\"end\":65221,\"start\":65219},{\"end\":65230,\"start\":65226},{\"end\":65242,\"start\":65240},{\"end\":65258,\"start\":65253},{\"end\":65563,\"start\":65559},{\"end\":65577,\"start\":65574},{\"end\":65591,\"start\":65587},{\"end\":65834,\"start\":65830},{\"end\":65848,\"start\":65844},{\"end\":65863,\"start\":65859},{\"end\":65877,\"start\":65874},{\"end\":65890,\"start\":65888},{\"end\":66147,\"start\":66139},{\"end\":66616,\"start\":66612},{\"end\":66627,\"start\":66624},{\"end\":66645,\"start\":66639},{\"end\":66657,\"start\":66649},{\"end\":66674,\"start\":66668},{\"end\":66686,\"start\":66684},{\"end\":66692,\"start\":66688},{\"end\":66997,\"start\":66992},{\"end\":67013,\"start\":67006},{\"end\":67029,\"start\":67021},{\"end\":67047,\"start\":67036},{\"end\":67061,\"start\":67058},{\"end\":67352,\"start\":67334},{\"end\":67364,\"start\":67358},{\"end\":67382,\"start\":67375},{\"end\":67401,\"start\":67394},{\"end\":67413,\"start\":67405},{\"end\":67427,\"start\":67421},{\"end\":67440,\"start\":67434},{\"end\":67447,\"start\":67442},{\"end\":67874,\"start\":67858},{\"end\":67880,\"start\":67876},{\"end\":68065,\"start\":68062},{\"end\":68075,\"start\":68072},{\"end\":68085,\"start\":68083},{\"end\":68094,\"start\":68090},{\"end\":68109,\"start\":68106},{\"end\":68118,\"start\":68115},{\"end\":68326,\"start\":68323},{\"end\":68341,\"start\":68336},{\"end\":68347,\"start\":68343},{\"end\":68522,\"start\":68518},{\"end\":68534,\"start\":68531},{\"end\":68544,\"start\":68541},{\"end\":68557,\"start\":68552},{\"end\":68570,\"start\":68564},{\"end\":68579,\"start\":68575},{\"end\":68751,\"start\":68747},{\"end\":68762,\"start\":68757},{\"end\":68777,\"start\":68770},{\"end\":68791,\"start\":68784},{\"end\":68804,\"start\":68800},{\"end\":68817,\"start\":68811},{\"end\":68824,\"start\":68819},{\"end\":69190,\"start\":69188},{\"end\":69202,\"start\":69198},{\"end\":69214,\"start\":69209},{\"end\":69225,\"start\":69223},{\"end\":69233,\"start\":69231},{\"end\":69246,\"start\":69243},{\"end\":69574,\"start\":69569},{\"end\":69585,\"start\":69576},{\"end\":69886,\"start\":69880},{\"end\":69899,\"start\":69894},{\"end\":69912,\"start\":69907},{\"end\":69928,\"start\":69921},{\"end\":70135,\"start\":70130},{\"end\":70149,\"start\":70146},{\"end\":70164,\"start\":70156},{\"end\":70177,\"start\":70171},{\"end\":70414,\"start\":70409},{\"end\":70427,\"start\":70421},{\"end\":70639,\"start\":70634},{\"end\":70655,\"start\":70647},{\"end\":70673,\"start\":70667},{\"end\":70689,\"start\":70683},{\"end\":70919,\"start\":70914},{\"end\":70936,\"start\":70928},{\"end\":70954,\"start\":70948},{\"end\":70970,\"start\":70964},{\"end\":71239,\"start\":71233},{\"end\":71254,\"start\":71245},{\"end\":71268,\"start\":71264},{\"end\":71282,\"start\":71279},{\"end\":71304,\"start\":71289},{\"end\":71323,\"start\":71313},{\"end\":71340,\"start\":71332},{\"end\":71353,\"start\":71347},{\"end\":71375,\"start\":71366},{\"end\":71381,\"start\":71377},{\"end\":71798,\"start\":71787},{\"end\":71817,\"start\":71808},{\"end\":71836,\"start\":71828},{\"end\":71853,\"start\":71850},{\"end\":71868,\"start\":71860},{\"end\":71882,\"start\":71876},{\"end\":71889,\"start\":71884},{\"end\":72218,\"start\":72211},{\"end\":72403,\"start\":72397},{\"end\":72418,\"start\":72412},{\"end\":72432,\"start\":72425},{\"end\":72455,\"start\":72444},{\"end\":72474,\"start\":72466},{\"end\":72491,\"start\":72486},{\"end\":72508,\"start\":72505},{\"end\":72526,\"start\":72517},{\"end\":72541,\"start\":72534},{\"end\":72555,\"start\":72549},{\"end\":72860,\"start\":72854},{\"end\":72874,\"start\":72868},{\"end\":73107,\"start\":73097},{\"end\":73125,\"start\":73118},{\"end\":73140,\"start\":73134},{\"end\":73535,\"start\":73523},{\"end\":73549,\"start\":73542},{\"end\":73569,\"start\":73558},{\"end\":73594,\"start\":73582},{\"end\":73829,\"start\":73824},{\"end\":73839,\"start\":73836},{\"end\":73848,\"start\":73841},{\"end\":74167,\"start\":74163},{\"end\":74182,\"start\":74175},{\"end\":74196,\"start\":74191},{\"end\":74374,\"start\":74370},{\"end\":74387,\"start\":74383},{\"end\":74401,\"start\":74395},{\"end\":74414,\"start\":74408},{\"end\":74433,\"start\":74426},{\"end\":74438,\"start\":74435},{\"end\":74638,\"start\":74635},{\"end\":74654,\"start\":74650},{\"end\":74668,\"start\":74665},{\"end\":74682,\"start\":74678},{\"end\":74929,\"start\":74924},{\"end\":74942,\"start\":74940},{\"end\":74953,\"start\":74949},{\"end\":74972,\"start\":74963},{\"end\":74986,\"start\":74982},{\"end\":74996,\"start\":74993},{\"end\":75008,\"start\":75005},{\"end\":75469,\"start\":75464},{\"end\":75481,\"start\":75479},{\"end\":75492,\"start\":75487},{\"end\":75505,\"start\":75502},{\"end\":75519,\"start\":75515},{\"end\":75866,\"start\":75861},{\"end\":75878,\"start\":75875},{\"end\":75894,\"start\":75890},{\"end\":75910,\"start\":75904},{\"end\":76210,\"start\":76206},{\"end\":76224,\"start\":76218},{\"end\":76236,\"start\":76234},{\"end\":76251,\"start\":76247},{\"end\":76568,\"start\":76564},{\"end\":76581,\"start\":76577},{\"end\":76593,\"start\":76590},{\"end\":76609,\"start\":76604}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2127515},\"end\":56913,\"start\":56637},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":220768904},\"end\":57195,\"start\":56915},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":122217223},\"end\":57466,\"start\":57197},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":13817347},\"end\":57751,\"start\":57468},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":51980671},\"end\":57969,\"start\":57753},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":88516328},\"end\":58494,\"start\":57971},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":250563748},\"end\":58854,\"start\":58496},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3046524},\"end\":59169,\"start\":58856},{\"attributes\":{\"id\":\"b8\"},\"end\":59421,\"start\":59171},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":51924648},\"end\":59961,\"start\":59423},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":13254783},\"end\":60127,\"start\":59963},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":57246310},\"end\":60395,\"start\":60129},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":226306223},\"end\":60674,\"start\":60397},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":2871880},\"end\":61080,\"start\":60676},{\"attributes\":{\"id\":\"b14\"},\"end\":61418,\"start\":61082},{\"attributes\":{\"id\":\"b15\"},\"end\":61825,\"start\":61420},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":206594692},\"end\":62052,\"start\":61827},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":7646250},\"end\":62414,\"start\":62054},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":57572938},\"end\":62694,\"start\":62416},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":212784882},\"end\":62920,\"start\":62696},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":18507866},\"end\":63192,\"start\":62922},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":234352240},\"end\":63475,\"start\":63194},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":219979590},\"end\":63760,\"start\":63477},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":211205159},\"end\":64095,\"start\":63762},{\"attributes\":{\"doi\":\"arXiv:2112.08553\",\"id\":\"b24\"},\"end\":64405,\"start\":64097},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":212414824},\"end\":64695,\"start\":64407},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":246150572},\"end\":65100,\"start\":64697},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":255181575},\"end\":65504,\"start\":65102},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":46784066},\"end\":65756,\"start\":65506},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":13798326},\"end\":66056,\"start\":65758},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":6278891},\"end\":66537,\"start\":66058},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":233864371},\"end\":66936,\"start\":66539},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":13815143},\"end\":67216,\"start\":66938},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":30668315},\"end\":67819,\"start\":67218},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":740063},\"end\":67980,\"start\":67821},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":131774949},\"end\":68284,\"start\":67982},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":19598463},\"end\":68455,\"start\":68286},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":54458071},\"end\":68736,\"start\":68457},{\"attributes\":{\"doi\":\"arXiv:1710.06924\",\"id\":\"b38\"},\"end\":69073,\"start\":68738},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":247996609},\"end\":69478,\"start\":69075},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":189900},\"end\":69825,\"start\":69480},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":7534823},\"end\":70066,\"start\":69827},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":211171824},\"end\":70339,\"start\":70068},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":233181662},\"end\":70557,\"start\":70341},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":4619542},\"end\":70857,\"start\":70559},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":13752992},\"end\":71122,\"start\":70859},{\"attributes\":{\"id\":\"b46\"},\"end\":71701,\"start\":71124},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":15019293},\"end\":72120,\"start\":71703},{\"attributes\":{\"id\":\"b48\"},\"end\":72344,\"start\":72122},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":91978000},\"end\":72814,\"start\":72346},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":59409752},\"end\":73017,\"start\":72816},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":59738652},\"end\":73456,\"start\":73019},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":2928248},\"end\":73767,\"start\":73458},{\"attributes\":{\"id\":\"b53\"},\"end\":74102,\"start\":73769},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":739861},\"end\":74319,\"start\":74104},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":236881316},\"end\":74596,\"start\":74321},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":157060790},\"end\":74844,\"start\":74598},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":246603094},\"end\":75356,\"start\":74846},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":135218546},\"end\":75799,\"start\":75358},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":118638514},\"end\":76051,\"start\":75801},{\"attributes\":{\"id\":\"b60\"},\"end\":76480,\"start\":76053},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":121123510},\"end\":76769,\"start\":76482}]", "bib_title": "[{\"end\":56663,\"start\":56637},{\"end\":56984,\"start\":56915},{\"end\":57235,\"start\":57197},{\"end\":57529,\"start\":57468},{\"end\":57790,\"start\":57753},{\"end\":58030,\"start\":57971},{\"end\":58592,\"start\":58496},{\"end\":58929,\"start\":58856},{\"end\":59247,\"start\":59171},{\"end\":59487,\"start\":59423},{\"end\":59991,\"start\":59963},{\"end\":60180,\"start\":60129},{\"end\":60460,\"start\":60397},{\"end\":60722,\"start\":60676},{\"end\":61159,\"start\":61082},{\"end\":61871,\"start\":61827},{\"end\":62108,\"start\":62054},{\"end\":62481,\"start\":62416},{\"end\":62735,\"start\":62696},{\"end\":63017,\"start\":62922},{\"end\":63253,\"start\":63194},{\"end\":63545,\"start\":63477},{\"end\":63868,\"start\":63762},{\"end\":64503,\"start\":64407},{\"end\":64788,\"start\":64697},{\"end\":65185,\"start\":65102},{\"end\":65547,\"start\":65506},{\"end\":65818,\"start\":65758},{\"end\":66131,\"start\":66058},{\"end\":66602,\"start\":66539},{\"end\":66986,\"start\":66938},{\"end\":67323,\"start\":67218},{\"end\":67850,\"start\":67821},{\"end\":68052,\"start\":67982},{\"end\":68312,\"start\":68286},{\"end\":68507,\"start\":68457},{\"end\":69178,\"start\":69075},{\"end\":69565,\"start\":69480},{\"end\":69873,\"start\":69827},{\"end\":70120,\"start\":70068},{\"end\":70399,\"start\":70341},{\"end\":70624,\"start\":70559},{\"end\":70904,\"start\":70859},{\"end\":71222,\"start\":71124},{\"end\":71783,\"start\":71703},{\"end\":72391,\"start\":72346},{\"end\":72848,\"start\":72816},{\"end\":73088,\"start\":73019},{\"end\":73513,\"start\":73458},{\"end\":74153,\"start\":74104},{\"end\":74362,\"start\":74321},{\"end\":74625,\"start\":74598},{\"end\":74917,\"start\":74846},{\"end\":75452,\"start\":75358},{\"end\":75852,\"start\":75801},{\"end\":76555,\"start\":76482}]", "bib_author": "[{\"end\":56689,\"start\":56665},{\"end\":56708,\"start\":56689},{\"end\":56726,\"start\":56708},{\"end\":56742,\"start\":56726},{\"end\":56757,\"start\":56742},{\"end\":57000,\"start\":56986},{\"end\":57024,\"start\":57000},{\"end\":57041,\"start\":57024},{\"end\":57255,\"start\":57237},{\"end\":57271,\"start\":57255},{\"end\":57545,\"start\":57531},{\"end\":57561,\"start\":57545},{\"end\":57575,\"start\":57561},{\"end\":57594,\"start\":57575},{\"end\":57806,\"start\":57792},{\"end\":57816,\"start\":57806},{\"end\":57832,\"start\":57816},{\"end\":57846,\"start\":57832},{\"end\":58046,\"start\":58032},{\"end\":58059,\"start\":58046},{\"end\":58075,\"start\":58059},{\"end\":58089,\"start\":58075},{\"end\":58101,\"start\":58089},{\"end\":58606,\"start\":58594},{\"end\":58618,\"start\":58606},{\"end\":58632,\"start\":58618},{\"end\":58641,\"start\":58632},{\"end\":58655,\"start\":58641},{\"end\":58943,\"start\":58931},{\"end\":58955,\"start\":58943},{\"end\":58969,\"start\":58955},{\"end\":59265,\"start\":59249},{\"end\":59279,\"start\":59265},{\"end\":59499,\"start\":59489},{\"end\":59520,\"start\":59499},{\"end\":59533,\"start\":59520},{\"end\":59546,\"start\":59533},{\"end\":59554,\"start\":59546},{\"end\":59560,\"start\":59554},{\"end\":59570,\"start\":59560},{\"end\":59585,\"start\":59570},{\"end\":59604,\"start\":59585},{\"end\":59623,\"start\":59604},{\"end\":59635,\"start\":59623},{\"end\":59659,\"start\":59635},{\"end\":59667,\"start\":59659},{\"end\":60002,\"start\":59993},{\"end\":60019,\"start\":60002},{\"end\":60028,\"start\":60019},{\"end\":60192,\"start\":60182},{\"end\":60202,\"start\":60192},{\"end\":60218,\"start\":60202},{\"end\":60229,\"start\":60218},{\"end\":60237,\"start\":60229},{\"end\":60249,\"start\":60237},{\"end\":60469,\"start\":60462},{\"end\":60483,\"start\":60469},{\"end\":60499,\"start\":60483},{\"end\":60513,\"start\":60499},{\"end\":60740,\"start\":60724},{\"end\":60759,\"start\":60740},{\"end\":60772,\"start\":60759},{\"end\":60788,\"start\":60772},{\"end\":60805,\"start\":60788},{\"end\":60826,\"start\":60805},{\"end\":60842,\"start\":60826},{\"end\":60860,\"start\":60842},{\"end\":61179,\"start\":61161},{\"end\":61204,\"start\":61179},{\"end\":61217,\"start\":61204},{\"end\":61231,\"start\":61217},{\"end\":61235,\"start\":61231},{\"end\":61438,\"start\":61422},{\"end\":61458,\"start\":61438},{\"end\":61471,\"start\":61458},{\"end\":61480,\"start\":61471},{\"end\":61500,\"start\":61480},{\"end\":61515,\"start\":61500},{\"end\":61532,\"start\":61515},{\"end\":61547,\"start\":61532},{\"end\":61885,\"start\":61873},{\"end\":61900,\"start\":61885},{\"end\":61914,\"start\":61900},{\"end\":61924,\"start\":61914},{\"end\":62124,\"start\":62110},{\"end\":62136,\"start\":62124},{\"end\":62150,\"start\":62136},{\"end\":62163,\"start\":62150},{\"end\":62178,\"start\":62163},{\"end\":62191,\"start\":62178},{\"end\":62205,\"start\":62191},{\"end\":62221,\"start\":62205},{\"end\":62498,\"start\":62483},{\"end\":62508,\"start\":62498},{\"end\":62517,\"start\":62508},{\"end\":62540,\"start\":62517},{\"end\":62758,\"start\":62737},{\"end\":62773,\"start\":62758},{\"end\":62789,\"start\":62773},{\"end\":63034,\"start\":63019},{\"end\":63268,\"start\":63255},{\"end\":63283,\"start\":63268},{\"end\":63291,\"start\":63283},{\"end\":63304,\"start\":63291},{\"end\":63313,\"start\":63304},{\"end\":63555,\"start\":63547},{\"end\":63569,\"start\":63555},{\"end\":63582,\"start\":63569},{\"end\":63591,\"start\":63582},{\"end\":63600,\"start\":63591},{\"end\":63604,\"start\":63600},{\"end\":63882,\"start\":63870},{\"end\":63893,\"start\":63882},{\"end\":63906,\"start\":63893},{\"end\":64175,\"start\":64163},{\"end\":64186,\"start\":64175},{\"end\":64199,\"start\":64186},{\"end\":64207,\"start\":64199},{\"end\":64517,\"start\":64505},{\"end\":64529,\"start\":64517},{\"end\":64540,\"start\":64529},{\"end\":64803,\"start\":64790},{\"end\":64815,\"start\":64803},{\"end\":64826,\"start\":64815},{\"end\":64836,\"start\":64826},{\"end\":64842,\"start\":64836},{\"end\":64850,\"start\":64842},{\"end\":64860,\"start\":64850},{\"end\":64866,\"start\":64860},{\"end\":65200,\"start\":65187},{\"end\":65212,\"start\":65200},{\"end\":65223,\"start\":65212},{\"end\":65232,\"start\":65223},{\"end\":65244,\"start\":65232},{\"end\":65260,\"start\":65244},{\"end\":65565,\"start\":65549},{\"end\":65579,\"start\":65565},{\"end\":65593,\"start\":65579},{\"end\":65612,\"start\":65593},{\"end\":65836,\"start\":65820},{\"end\":65850,\"start\":65836},{\"end\":65865,\"start\":65850},{\"end\":65879,\"start\":65865},{\"end\":65892,\"start\":65879},{\"end\":66149,\"start\":66133},{\"end\":66618,\"start\":66604},{\"end\":66629,\"start\":66618},{\"end\":66647,\"start\":66629},{\"end\":66659,\"start\":66647},{\"end\":66676,\"start\":66659},{\"end\":66688,\"start\":66676},{\"end\":66694,\"start\":66688},{\"end\":66999,\"start\":66988},{\"end\":67015,\"start\":66999},{\"end\":67031,\"start\":67015},{\"end\":67049,\"start\":67031},{\"end\":67063,\"start\":67049},{\"end\":67354,\"start\":67325},{\"end\":67366,\"start\":67354},{\"end\":67384,\"start\":67366},{\"end\":67403,\"start\":67384},{\"end\":67415,\"start\":67403},{\"end\":67429,\"start\":67415},{\"end\":67442,\"start\":67429},{\"end\":67449,\"start\":67442},{\"end\":67876,\"start\":67852},{\"end\":67882,\"start\":67876},{\"end\":68067,\"start\":68054},{\"end\":68077,\"start\":68067},{\"end\":68087,\"start\":68077},{\"end\":68096,\"start\":68087},{\"end\":68111,\"start\":68096},{\"end\":68120,\"start\":68111},{\"end\":68328,\"start\":68314},{\"end\":68343,\"start\":68328},{\"end\":68349,\"start\":68343},{\"end\":68524,\"start\":68509},{\"end\":68536,\"start\":68524},{\"end\":68546,\"start\":68536},{\"end\":68559,\"start\":68546},{\"end\":68572,\"start\":68559},{\"end\":68581,\"start\":68572},{\"end\":68753,\"start\":68738},{\"end\":68764,\"start\":68753},{\"end\":68779,\"start\":68764},{\"end\":68793,\"start\":68779},{\"end\":68806,\"start\":68793},{\"end\":68819,\"start\":68806},{\"end\":68826,\"start\":68819},{\"end\":69192,\"start\":69180},{\"end\":69204,\"start\":69192},{\"end\":69216,\"start\":69204},{\"end\":69227,\"start\":69216},{\"end\":69235,\"start\":69227},{\"end\":69248,\"start\":69235},{\"end\":69576,\"start\":69567},{\"end\":69587,\"start\":69576},{\"end\":69888,\"start\":69875},{\"end\":69901,\"start\":69888},{\"end\":69914,\"start\":69901},{\"end\":69930,\"start\":69914},{\"end\":70137,\"start\":70122},{\"end\":70151,\"start\":70137},{\"end\":70166,\"start\":70151},{\"end\":70179,\"start\":70166},{\"end\":70416,\"start\":70401},{\"end\":70429,\"start\":70416},{\"end\":70641,\"start\":70626},{\"end\":70657,\"start\":70641},{\"end\":70675,\"start\":70657},{\"end\":70691,\"start\":70675},{\"end\":70921,\"start\":70906},{\"end\":70938,\"start\":70921},{\"end\":70956,\"start\":70938},{\"end\":70972,\"start\":70956},{\"end\":71241,\"start\":71224},{\"end\":71256,\"start\":71241},{\"end\":71270,\"start\":71256},{\"end\":71284,\"start\":71270},{\"end\":71306,\"start\":71284},{\"end\":71325,\"start\":71306},{\"end\":71342,\"start\":71325},{\"end\":71355,\"start\":71342},{\"end\":71377,\"start\":71355},{\"end\":71383,\"start\":71377},{\"end\":71800,\"start\":71785},{\"end\":71819,\"start\":71800},{\"end\":71838,\"start\":71819},{\"end\":71855,\"start\":71838},{\"end\":71870,\"start\":71855},{\"end\":71884,\"start\":71870},{\"end\":71891,\"start\":71884},{\"end\":72220,\"start\":72197},{\"end\":72405,\"start\":72393},{\"end\":72420,\"start\":72405},{\"end\":72434,\"start\":72420},{\"end\":72457,\"start\":72434},{\"end\":72476,\"start\":72457},{\"end\":72493,\"start\":72476},{\"end\":72499,\"start\":72493},{\"end\":72510,\"start\":72499},{\"end\":72528,\"start\":72510},{\"end\":72543,\"start\":72528},{\"end\":72557,\"start\":72543},{\"end\":72862,\"start\":72850},{\"end\":72876,\"start\":72862},{\"end\":73109,\"start\":73090},{\"end\":73127,\"start\":73109},{\"end\":73142,\"start\":73127},{\"end\":73537,\"start\":73515},{\"end\":73551,\"start\":73537},{\"end\":73571,\"start\":73551},{\"end\":73596,\"start\":73571},{\"end\":73831,\"start\":73819},{\"end\":73841,\"start\":73831},{\"end\":73850,\"start\":73841},{\"end\":74169,\"start\":74155},{\"end\":74184,\"start\":74169},{\"end\":74198,\"start\":74184},{\"end\":74376,\"start\":74364},{\"end\":74389,\"start\":74376},{\"end\":74403,\"start\":74389},{\"end\":74416,\"start\":74403},{\"end\":74435,\"start\":74416},{\"end\":74440,\"start\":74435},{\"end\":74640,\"start\":74627},{\"end\":74656,\"start\":74640},{\"end\":74670,\"start\":74656},{\"end\":74684,\"start\":74670},{\"end\":74703,\"start\":74684},{\"end\":74931,\"start\":74919},{\"end\":74944,\"start\":74931},{\"end\":74955,\"start\":74944},{\"end\":74974,\"start\":74955},{\"end\":74988,\"start\":74974},{\"end\":74998,\"start\":74988},{\"end\":75010,\"start\":74998},{\"end\":75471,\"start\":75454},{\"end\":75483,\"start\":75471},{\"end\":75494,\"start\":75483},{\"end\":75507,\"start\":75494},{\"end\":75521,\"start\":75507},{\"end\":75868,\"start\":75854},{\"end\":75880,\"start\":75868},{\"end\":75896,\"start\":75880},{\"end\":75912,\"start\":75896},{\"end\":76212,\"start\":76199},{\"end\":76226,\"start\":76212},{\"end\":76238,\"start\":76226},{\"end\":76253,\"start\":76238},{\"end\":76570,\"start\":76557},{\"end\":76583,\"start\":76570},{\"end\":76595,\"start\":76583},{\"end\":76611,\"start\":76595}]", "bib_venue": "[{\"end\":58250,\"start\":58184},{\"end\":66324,\"start\":66237},{\"end\":56764,\"start\":56757},{\"end\":57045,\"start\":57041},{\"end\":57318,\"start\":57271},{\"end\":57598,\"start\":57594},{\"end\":57850,\"start\":57846},{\"end\":58182,\"start\":58101},{\"end\":58665,\"start\":58655},{\"end\":58992,\"start\":58969},{\"end\":59289,\"start\":59279},{\"end\":59671,\"start\":59667},{\"end\":60038,\"start\":60028},{\"end\":60253,\"start\":60249},{\"end\":60526,\"start\":60513},{\"end\":60864,\"start\":60860},{\"end\":61239,\"start\":61235},{\"end\":61605,\"start\":61547},{\"end\":61928,\"start\":61924},{\"end\":62225,\"start\":62221},{\"end\":62544,\"start\":62540},{\"end\":62793,\"start\":62789},{\"end\":63047,\"start\":63034},{\"end\":63326,\"start\":63313},{\"end\":63608,\"start\":63604},{\"end\":63910,\"start\":63906},{\"end\":64161,\"start\":64097},{\"end\":64544,\"start\":64540},{\"end\":64886,\"start\":64866},{\"end\":65292,\"start\":65260},{\"end\":65619,\"start\":65612},{\"end\":65896,\"start\":65892},{\"end\":66235,\"start\":66149},{\"end\":66721,\"start\":66694},{\"end\":67067,\"start\":67063},{\"end\":67496,\"start\":67449},{\"end\":67891,\"start\":67882},{\"end\":68124,\"start\":68120},{\"end\":68353,\"start\":68349},{\"end\":68585,\"start\":68581},{\"end\":68880,\"start\":68842},{\"end\":69252,\"start\":69248},{\"end\":69635,\"start\":69587},{\"end\":69934,\"start\":69930},{\"end\":70186,\"start\":70179},{\"end\":70433,\"start\":70429},{\"end\":70695,\"start\":70691},{\"end\":70976,\"start\":70972},{\"end\":71389,\"start\":71383},{\"end\":71895,\"start\":71891},{\"end\":72195,\"start\":72122},{\"end\":72561,\"start\":72557},{\"end\":72899,\"start\":72876},{\"end\":73218,\"start\":73142},{\"end\":73600,\"start\":73596},{\"end\":73817,\"start\":73769},{\"end\":74202,\"start\":74198},{\"end\":74450,\"start\":74440},{\"end\":74707,\"start\":74703},{\"end\":75090,\"start\":75010},{\"end\":75559,\"start\":75521},{\"end\":75916,\"start\":75912},{\"end\":76197,\"start\":76053},{\"end\":76615,\"start\":76611}]"}}}, "year": 2023, "month": 12, "day": 17}