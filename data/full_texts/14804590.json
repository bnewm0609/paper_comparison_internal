{"id": 14804590, "updated": "2022-03-18 02:30:43.392", "metadata": {"title": "ArabicWeb16: A New Crawl for Today's Arabic Web", "authors": "[{\"first\":\"Reem\",\"last\":\"Suwaileh\",\"middle\":[]},{\"first\":\"Mucahid\",\"last\":\"Kutlu\",\"middle\":[]},{\"first\":\"Nihal\",\"last\":\"Fathima\",\"middle\":[]},{\"first\":\"Tamer\",\"last\":\"Elsayed\",\"middle\":[]},{\"first\":\"Matthew\",\"last\":\"Lease\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval", "publication_date": {"year": 2016, "month": null, "day": null}, "abstract": "Web crawls provide valuable snapshots of the Web which enable a wide variety of research, be it distributional analysis to characterize Web properties or use of language, content analysis in social science, or Information Retrieval (IR) research to develop and evaluate effective search algorithms. While many English-centric Web crawls exist, existing public Arabic Web crawls are quite limited, limiting research and development. To remedy this, we present ArabicWeb16, a new public Web crawl of roughly 150M Arabic Web pages with significant coverage of dialectal Arabic as well as Modern Standard Arabic. For IR researchers, we expect ArabicWeb16 to support various research areas: ad-hoc search, question answering, filtering, cross-dialect search, dialect detection, entity search, blog search, and spam detection. Combined use with a separate Arabic Twitter dataset we are also collecting may provide further value.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2465804994", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/SuwailehKFEL16", "doi": "10.1145/2911451.2914677"}}, "content": {"source": {"pdf_hash": "88f7ae268140634653ebadabfe8726c1c2041774", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "77d4a2342c88969477195ed21702f0cabb32a4a2", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/88f7ae268140634653ebadabfe8726c1c2041774.txt", "contents": "\nArabicWeb16: A New Crawl for Today's Arabic Web\n\n\nReem Suwaileh reem.suwaileh@qu.edu.qa \nDepartment of Computer Science and Engineering\nQatar University\nQatar\n\nMucahid Kutlu mucahidkutlu@qu.edu.qa \nDepartment of Computer Science and Engineering\nQatar University\nQatar\n\nNihal Fathima nihal.fathima@qu.edu.qa \nDepartment of Computer Science and Engineering\nQatar University\nQatar\n\nMatthew Lease \nDepartment of Computer Science and Engineering\nQatar University\nQatar\n\nSchool of Information\nUniversity of Texas at Austin\nUSA\n\nArabicWeb16: A New Crawl for Today's Arabic Web\n10.1145/2911451.2914677Multi-DialectWeb CollectionArabic RetrievalAd-hoc SearchEvaluation\nWeb crawls provide valuable snapshots of the Web which enable a wide variety of research, be it distributional analysis to characterize Web properties or use of language, content analysis in social science, or Information Retrieval (IR) research to develop and evaluate effective search algorithms. While many English-centric Web crawls exist, existing public Arabic Web crawls are quite limited, limiting research and development. To remedy this, we present ArabicWeb16, a new public Web crawl of roughly 150M Arabic Web pages with significant coverage of dialectal Arabic as well as Modern Standard Arabic. For IR researchers, we expect Ara-bicWeb16 to support various research areas: ad-hoc search, question answering, filtering, cross-dialect search, dialect detection, entity search, blog search, and spam detection.\n\nINTRODUCTION\n\nA central requirement of the Cranfield method for evaluating Information Retrieval (IR) systems is a document collection [7], which is also essential for system development. More specifically, advancing the state-of-the-art in the area of Web search mandates the availability of a large-scale Web collection that is representative of the size and diversity of the Web. A variety of English-centric Web crawls have been previously performed such as VLC2 [11], WT10g [1], Gov2 [4], ClueWeb09 [5], and ClueWeb12 1 . ClueWeb12 intentionally eliminated non-English content.\n\nApproximately 370 million people are estimated to live in the Arab World today, yet the ability of researchers to support this population and their various dialects 2 by advancing the state-of-the-art in Arabic IR (and Arabic Web 1 lemurproject.org/clueweb12 2 en.wikipedia.org/wiki/Varieties of Arabic Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request  search in particular) has been greatly restricted by the lack of available Arabic data [9]. Fifteen years ago, the TREC Cross-Language Track created a test collection of Modern Standard Arabic (MSA) news articles from Agence France Press' (AFP) [10]. Great at the time, this test collection has become rather dated and small by today's standards.\n\nThe ClueWeb09 Web crawl consists of about 1B Webpages in 10 languages, including 29.2M (2.9%) Arabic pages. This Arabic subset (denoted by ArClueWeb09) constitutes the only and largest Arabic Web crawl available for IR research. While this makes it a wonderful resource to researchers, it nevertheless presents several notable limitations.\n\nMost obviously, the contents of this 2009 Web crawl have become somewhat dated in relation to understanding and supporting today's Arabic Web, especially in regard to rapid growth in social media use since then. Secondly, given its coverage of Arabic content was only incidental in crawling, it offers only limited coverage of even the Arabic Web as of 2009. Thirdly, the above two factors conspire to greatly limit its coverage of dialectal Arabic. Finally, our analysis of the ArClueWeb09 subset leads us to estimate that perhaps 14% of its pages are not actually Arabic, with less accurate tools for automatic language detection available in 2009 vs. today. For whatever reason, we know of no analysis having been reported on the content of ArClueWeb09, nor of any IR studies having used it. Taken together, these factors suggest a strong need for an updated crawl of today's Arabic Web that is far more representative of its current state and better supporting research, especially on Arabic IR. Common Crawl's 3 most recent November 2015 boasts over 1.82 billion URLs, but past analysis suggests that, similar to ClueWeb09, English content dominates the crawl [12]. While Common Crawl could be mined to identify and extract a useful Arabic subset akin to ArClueWeb09, this would address only recency, not coverage.\n\nTo address the above concerns, we believe a focused Arabic Web crawl is vital to enable and encourage research on today's Arabic Web. Beyond achieving a massive and modern crawl, we sought to ensure broad coverage of dialectal Arabic. To the best of our knowledge, our new public Web crawl, ArabicWeb16, is now the the largest and most representative snapshot of today's Arabic Web. ArabicWeb16 includes about 150M pages crawled over the month of January 2016. To obtain ArabicWeb16, please check the Ara-bicWeb16 project Web page 4 .\n\n\nCRAWLING PROCESS\n\nInspired by seed selection of ClueWeb09 5 , we constructed our Web crawl using seeds collected from a range of sources (e.g., Wikipedia, Alexa, ArClueWeb09, and Twitter) and selection methods (manual selection and BootCaT [2]) (Section 2.1). We modified Heritrix 6 to prioritize Arabic pages in crawling, and we applied a 3-step language detection pipeline to identify Arabic content (Section 2.2). We also excluded certain types of content during crawling, as well as post-processed data to remove duplicates and further filter out non-Arabic content, among others (Section 2.3).\n\n\nSeed Selection\n\nWe have collected around 27M seed URLs via several sources and methods:\n\nWikipedia: Given Wikipedia's high quality, diversity of topics, and authenticity, we downloaded its Arabic pages on October 2 nd 2015 and used Wikipedia Extractor 7 to extract approximately 382K URLs of articles.\n\nManual Selection: We manually harvested around 6.1K popular Arabic websites. These websites are of various categories such as directories, forums, news sources, governmental, academic and question-answering websites. They were obtained from pre-compiled lists on the Web (e.g., Wikipedia) or by issuing Arabic queries against Google.\n\nAlexa: Alexa 8 provides country-specific website rankings based on estimated daily unique visitors per month. We collected the top 500 websites of 12 Arab countries. We obtained roughly 670 seed pages after eliminating duplicates and non-Arabic pages among all countries.\n\nArClueWeb09: Since ArClueWeb09 contains a relatively large and diverse set of Arabic pages (29M pages), we believed it to be a good addition to our seed list. We performed a cleaning process on this dataset that includes language detection, Blacklist 9 URL filtering, and inappropriatecontent filtering. From our cleaning process, we found that 2.9M pages were non-Arabic and 95K web pages were either blacklisted or contain inappropriate content. This resulted in 26.1M seed web pages.\n\nTwitter: To support research related to Arabic microblog IR tasks, we collected webpages linked from Twitter. We crawled tweets for one month (Nov. 9 th to Dec. 9 th 2015) via Twitter's API. We then extracted URLs from Arabic tweets and filtered out URLs of tweets and blacklisted pages. This process resulted in 348K seed pages.\n\nBootCaT [2]: We collected a set of MSA and dialectal queries. The MSA queries contain ArClueWeb09 queries and category names from the DMOZ Open Directory Project 10 and Wikipedia.\n\nIn order to collect dialectal queries, we conducted an informal survey among Arab participants. We also used an available list from the Al-mo3jam website 11 for each Arab country. In order to avoid biasing data collection toward any one dialect, we randomly selected dialectal words for each country such that the number of selected dialectal words per 5 boston.lti.cs.cmu.edu/Data/web08-bst/planning.html 6 webarchive.jira.com/wiki/display/Heritrix/Heritrix 7 medialab.di.unipi.it/wiki/Wikipedia Extractor 8 www.alexa.com 9 urlblacklist.com 10 dmoz.org/World/Arabic 11 ar.mo3jam.com country is proportional to the estimated size of its internet user population.\n\nWe performed an extensive filtering to remove duplicates, non-Arabic queries, queries with more than 5 words, any English word written in Arabic letters, such as (MySpace) and inappropriate terms. The final list of queries contains around 5600 MSA and 1104 dialectal queries. We ran all queries against Google and Bing search engines where we set the language to Arabic and enabled safe mode to eliminate inappropriate content. We retrieved the first 20 results from each search, yielding approximately 24K URLs after eliminating duplicates.\n\n\nLanguage-Focused Crawling\n\nPrioritized Crawling: The relatively small size of Ar-ClueWeb09 (only 3% of ClueWeb09) exemplifies that general Web crawls yield relatively low harvest rate of Arabic pages. Therefore, we modified Heritrix via a method similar to soft-focusing [6], decreasing the priority of URLs extracted from non-Arabic pages (as opposed to completely eliminating them). This ensured coverage of Arabic pages that are accessible only through non-Arabic pages. In addition to decreasing priority, our method also increases the cost of pages extracted from non-Arabic pages. If the crawler cannot identify any Arabic pages crawled from a host after a threshold number of attempts, it eliminates that host.\n\nLanguage Detection: To prioritize the URLs in the crawler's queues, we detect the language of each page once downloaded. In addition to pure Arabic pages, we also considered multilingual pages related to Arabic (e.g., a page with few Arabic sentences) as Arabic pages.\n\nTo detect the language of a page, we applied a 3-stage pipeline (from most-to-least trusted stages). For a given Web page, our algorithm first checks the HTML code of the page. If tagged as Arabic, we consider it so. Otherwise, we run LangDetect [14], also used in ClueWeb12, on the page. If it is still not detected as Arabic, Persian, nor Urdu (languages using Arabic characters), we perform a character analysis. If the page contains Arabic (but not Persian or Urdu) characters, we consider it to be Arabic.\n\n\nCrawler Execution Details\n\nHaving observed ClueWeb switched crawlers from Nutch 12 in 2009 to Heritrix in 2012, we conducted pilot evaluations with both and ultimately selected Heritrix due to reliability and ease of use and modification. However, since Heritrix does not support distributed crawling (unlike Nutch), it was necessary to add a post-processing step to remove duplicate pages crawled by different Heritrix instances.\n\nCrawling was performed on an 11-node cluster, each having 24 cores (2.5 GHz) and 128GB of RAM. We dedicated 3 nodes for ArClueWeb09, 3 nodes for Wikipedia, and 1 node for Twitter seeds. Rest of seeds were distributed evenly over the remaining 4 nodes. We used default parameter configuration of Heritrix and employed 25 threads on each node.\n\nWe began crawling on January 1 st , 2016 and stopped on January 30 th , 2016. During crawling, we excluded nontextual multimedia, compressed data, pages over 100MB, and Twitter content. In addition to removing duplicates in post-processing, we also filtered out non-target pages (e.g., non-Arabic pages, DNS servers, robot.txt files) and pages that return 3xx, 4xx or 5xx error codes. Crawled pages are stored in compressed WARC files. Table 1 presents statistics characterizing ArabicWeb16 and ArClueWeb09 Web crawls. ArabicWeb16 is seen to be 5x larger than ArClueWeb09 with respect to number of pages (150M vs. 30M Arabic pages), and 11x larger with respect to storage requirements of uncompressed files (11TB vs. 1TB). In terms of overlap, 2016 versions of 1.5M pages from Ar-ClueWeb09 can be found in ArabicWeb16. Pages from Ar-ClueWeb09 missing in ArabicWeb16 may arise from several causes: the pages no longer existing, being eliminated due to not being detected as Arabic or other filtering criteria (see Section 2.3), or simply having not yet been crawled. To evaluate the accuracy of our automatic language detection pipeline, we checked for false positives (pages misdetected as Arabic) by manually inspecting 1000 random pages in ArabicWeb16. We found that 97% of them are indeed Arabic, showing our method's reliability. We also replicated the same method for analyzing ArClueWeb09. Of the 1000 random pages, we found 86.1% were Arabic. Table 1 shows that ArabicWeb16 covers nearly 4x more domains than ArClueWeb09 (768K vs. 197K). We further counted the number of pages per domain to construct the histogram in Figure 1. For each given page count shown on the x-axis (in log-scale), the y-axis shows the number of domains (in log-scale) having that many pages. The distribution is roughly similar between ArabicWeb16 and ArClueWeb09, with the greater domain and page count of ArabicWeb16 vs. ArClueWeb09 being somewhat obscured by the histogram bucketing. It is interesting to note Ara-bicWeb16's far greater prevalence of domains having only a single page, whereas ArClueWeb09 finding more domains with 10-99 pages. We also analyzed the top 100 domains in ArabicWeb16 and, interestingly, found that more than 50% are forums. Overall, the diversity seen in pages per domain suggests ArabicWeb16 will be useful for researchers interested in working with domains of varying depth.\n\n\nArabicWeb16 DATASET\n\n\nDiversity of Domains\n\n\nDiversity of Dialects\n\nWith regard to coverage of dialectal Arabic, we estimate the distribution of dialectal content vs. MSA in our crawl by training a multi-class Na\u00efve Bayes classifier using the Scikit-learn [13] library. We distinguish MSA from 4 common geographical dialects: Egyptian, Gulf, Levantine and Maghrebi. Using several dialectal Arabic datasets [8,3], we sampled a balanced dataset for MSA and each dialect, roughly 7k tweets and comments per category. Since our training dataset is not covering all Arabic dialects, we introduced a 6 th category, named others, and classified pages as others if their classification confidence score is < 0.5. We classified the first 150 Arabic words from each page. Table 2 shows the dialectal distribution in both datasets. In ArClueWeb09, we applied our post-processing step (see Section 2.3) and ran the classifier on that filtered dataset. ArabicWeb16 has 5 times more pages with dialects than ArClueWeb09, that is, the ratio of dialectal content is proportional to the ratio of dataset sizes. However, considering the number of internet users of each country 13 , the distribution of dialects in ArabicWeb16 is a better representative of dialects. For instance, while Egypt has the highest number of internet users among Arab countries, pages with Egyptian dialect is also more than others in ArabicWeb16, which is not the case in ArClueWeb09.\n\n\nDiversity of Page Content\n\nTo estimate the proportion of different Web page types in ArabicWeb16, we asked CrowdFlower.com contributors to classify pages into the following category schema we defined:\n\nInformational: Web pages whose main purpose is to provide information (e.g., Wikipedia). Information can vary from scientific articles to event schedules.\n\nDiscussion & Opinion: Web pages with discussions, opinions, interviews, etc., often on social platforms.\n\nNews and Media: Web pages that provide different topics of news and articles from around the world.\n\nOnline Services: Web pages for online applications, or platforms for payment and shopping. These Web pages may list services or products to buy or use, user-guides, etc.\n\nOrganizational: Institutional Web pages describing owners' interests, activities, news or services, etc.\n\nEntertainment: Web pages with a main purpose to provide entertainment to users (e.g., games, movies).\n\nOther: Web pages not fitting any of the above types.\n\nWe randomly sampled 1000 pages from ArabicWeb16 and ArClueWeb09. Broken links and non-Arabic web pages were 13 internetlivestats.com/internet-users/ identified and excluded from the task in both datasets. We limited the job to Arabic-speakers and moderately-rated contributors who passed test questions with \u2265 80% accuracy.\n\nWe requested 3 judgments per page. The overall Fleiss's Kappa inter-annotator agreement values for ArabicWeb16 and ArClueWeb09 are 0.57 (moderate agreement) and 0.37 (fair agreement), respectively. Table 3 presents the number of pages receiving \u2265 2 agreeing labels for each page type. The number of annotated pages in ArClueWeb09 is 5x smaller (as its size). This is mainly because of higher percentage of broken links and non-Arabic pages. We notice that ArabicWeb16 has more pages annotated as Discussion & Opinion. This can be due to the increasing popularity of social media platforms (e.g., tumblr) in recent years. Overall, ArabicWeb16 appears to provide better diversity in terms of page content. \n\n\nENABLING NEW RESEARCH\n\nA primary goal in constructing ArabicWeb16 is to enable further research in Arabic IR by providing a sound dataset that supports various IR tasks. We envision ArabicWeb16 can be employed for research related to (at least) the following areas: ad-hoc web search, question answering, filtering, cross-dialect search, dialect detection, spam detection, entity-oriented search, and blog track tasks.\n\nTo further elaborate, ArabicWeb16 contains many forums, including question-answering sites given as seeds, as well as many informational pages such as Wikipedia, which can usefully support question answering research. In addition, the large dialectal content clearly supports cross-dialect search. While we filtered blacklisted pages in selection of seeds, we intentionally did not filter out spams. Leaving spam present in ArabicWeb16 makes it useful for (Arabic) spam detection research. Finally, ArabicWeb16 contains approximately 19M blog pages (as determined by checking domain names), clearly providing significant content for blog search research.\n\n\nCONCLUSION AND FUTURE WORK\n\nThe ever-increasing scale of the Web, shifting patterns of user search and information-sharing behaviors, and emergency of new types of content (e.g., blogs and tweets) creates an ever-growing need to continuously adapt and refine IR methods. Progress in Arabic IR has been impaired in recent years vs. other languages due to lack of suitable data supporting research. Creating a vast Arabic IR collection will therefore create new opportunities and pave way for more further advancements and enhancements in Arabic IR.\n\nOur ongoing work includes construction of search topics and collection of corresponding relevance judgments in order to provide researchers not just with documents to search, but a complete test collection for IR experimentation.\n\nFigure 1 :\n1Histogram of pages per domain (log-scale)\n\n\npermissions from permissions@acm.org. SIGIR '16, July 17 -21, 2016, Pisa, Italy c 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM. ISBN 978-1-4503-4069-4/16/07. . . $15.00 DOI: http://dx.doi.org/10.1145/2911451.2914677\n\nTable 1 :\n1ArabicWeb16 & ArClueWeb09 StatisticsArabicWeb16 ArClueWeb09 \nData Size \n10.8 TB \n0.97 TB \nPages \n150.9M \n29.2M \nDomains \n768,516 \n196,776 \nDialectal Pages \n31.4M \n6.2M \nEst. AR Pages \n97% \n86.1% \n\n\n\nTable 2 :\n2Distribution of MSA and DialectsDialect \nArabicWeb16 ArClueWeb09 \nMSA \n119M (79%) \n19.9M (76%) \nEgyptian \n9M (6%) \n1.5M (6%) \nGulf \n7.6M (5%) \n2.7M (10%) \nLevantine \n7M (5%) \n1.5M (6%) \nMaghrebi \n5M (3%) \n0.4M (1.6%) \nOthers \n2.8M (2%) \n0.1M (< 1%) \n\n\n\nTable 3 :\n3Distribution of Different Web page TypesWeb page Type \nArabicWeb16 ArClueWeb09 \nInformational \n113 (12.80%) \n23 (12.92%) \nDiscuss. & Opinion \n295 (33.41%) \n37 (20.79%) \nNews and Media \n93 (10.53%) \n9 (5.06%) \nOnline Services \n36 (4.08%) \n7 (3.93%) \nOrganizational \n8 (0.91%) \n2 (1.12%) \nEntertainment \n28 (3.17%) \n4 (2.25%) \nOther \n310 (35.11%) \n96 (53.93%) \n\n\ncommoncrawl.org 4 http://qufaculty.qu.edu.qa/telsayed/arabicweb16\nnutch.apache.org\nAcknowledgmentsThis work was made possible by NPRP grant# NPRP 7-1313-1-245 from the Qatar National Research Fund (a member of Qatar Foundation). The statements made herein are solely the responsibility of the authors. We thank the Texas Advanced Computing Center (TACC) at the University of Texas at Austin for computing resources enabling this research.\nEngineering a multi-purpose test collection for web retrieval experiments. P Bailey, N Craswell, D Hawking, Information Processing & Management. 396P. Bailey, N. Craswell, and D. Hawking. Engineering a multi-purpose test collection for web retrieval experiments. Information Processing & Management, 39(6):853-871, 2003.\n\nBootCaT: Bootstrapping Corpora and Terms from the Web. M Baroni, S Bernardini, Proceedings of the Language Resources and Evaluation Conf. (LREC). the Language Resources and Evaluation Conf. (LREC)M. Baroni and S. Bernardini. BootCaT: Bootstrapping Corpora and Terms from the Web. In Proceedings of the Language Resources and Evaluation Conf. (LREC), 2004.\n\nA Multidialectal Parallel Corpus of Arabic. H Bouamor, N Habash, K Oflazer, Proceedings of the Language Resources and Evaluation Conference (LREC). the Language Resources and Evaluation Conference (LREC)H. Bouamor, N. Habash, and K. Oflazer. A Multidialectal Parallel Corpus of Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), pages 1240-1245, 2014.\n\nBias and the limits of pooling for large collections. C Buckley, D Dimmick, I Soboroff, E Voorhees, Information retrieval. 106C. Buckley, D. Dimmick, I. Soboroff, and E. Voorhees. Bias and the limits of pooling for large collections. Information retrieval, 10(6):491-508, 2007.\n\nat NIST TREC. Slides online at boston.lti.cs. J Callan, M Hoy, C Yoo, L Zhao, 11-742/S10-TREC/TREC-Nov19-09.pdfThe ClueWeb09 DatasetJ. Callan, M. Hoy, C. Yoo, and L. Zhao. The ClueWeb09 Dataset, 2009. Presentation Nov. 19, 2009 at NIST TREC. Slides online at boston.lti.cs.cmu. edu/classes/11-742/S10-TREC/TREC-Nov19-09.pdf.\n\nFocused crawling: a new approach to topic-specific Web resource discovery. S Chakrabarti, M Van Den, B Berg, Dom, Computer Networks. 3111S. Chakrabarti, M. Van den Berg, and B. Dom. Focused crawling: a new approach to topic-specific Web resource discovery. Computer Networks, 31(11):1623-1640, 1999.\n\nThe evaluation of systems used in information retrieval. C W Cleverdon, Proceedings of the international conference on scientific information. the international conference on scientific information1National Academy of SciencesC. W. Cleverdon. The evaluation of systems used in information retrieval. In Proceedings of the international conference on scientific information, volume 1, pages 687-698. National Academy of Sciences, 1959.\n\nA Multi-Dialect, Multi-Genre Corpus of Informal Written Arabic. R Cotterell, C Callison-Burch, Proceedings of the Language Resources and Evaluation Conference (LREC). the Language Resources and Evaluation Conference (LREC)R. Cotterell and C. Callison-Burch. A Multi-Dialect, Multi-Genre Corpus of Informal Written Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), pages 241-245, 2014.\n\n. K Darwish, W Magdy, Arabic Information Retrieval. Foundations and Trends in Information Retrieval. 74K. Darwish and W. Magdy. Arabic Information Retrieval. Foundations and Trends in Information Retrieval, 7(4):239-342, 2014.\n\nThe TREC-2001 Cross-Language Information Retrieval Track: Searching Arabic Using English, French or Arabic Queries. F C Gey, D W Oard, Proc. of the Tenth Text REtrieval Conference (TREC 10). of the Tenth Text REtrieval Conference (TREC 10)F. C. Gey and D. W. Oard. The TREC-2001 Cross-Language Information Retrieval Track: Searching Arabic Using English, French or Arabic Queries. In Proc. of the Tenth Text REtrieval Conference (TREC 10), 2001.\n\nOverview of the TREC-8 Web Track. D Hawking, E Voorhees, N Craswell, P Bailey, Proceedings of the Eighth Text REtrieval Conference (TREC 8). the Eighth Text REtrieval Conference (TREC 8)D. Hawking, E. Voorhees, N. Craswell, and P. Bailey. Overview of the TREC-8 Web Track. In Proceedings of the Eighth Text REtrieval Conference (TREC 8), 1999.\n\nV Kolias, I Anagnostopoulos, E Kayafas, arXiv:1409.5443Exploratory Analysis of a Terabyte Scale Web Corpus. arXiv preprintV. Kolias, I. Anagnostopoulos, and E. Kayafas. Exploratory Analysis of a Terabyte Scale Web Corpus. arXiv preprint arXiv:1409.5443, 2014.\n\nScikit-learn: Machine learning in python. F Pedregosa, G Varoquaux, A Gramfort, The Journal of Machine Learning Research. 12F. Pedregosa, G. Varoquaux, A. Gramfort, et al. Scikit-learn: Machine learning in python. The Journal of Machine Learning Research, 12:2825-2830, 2011.\n\nLanguage detection library for java. N Shuyo, N. Shuyo. Language detection library for java, 2010. http://code.google.com/p/language-detection/.\n", "annotations": {"author": "[{\"end\":160,\"start\":51},{\"end\":269,\"start\":161},{\"end\":379,\"start\":270},{\"end\":522,\"start\":380}]", "publisher": null, "author_last_name": "[{\"end\":64,\"start\":56},{\"end\":174,\"start\":169},{\"end\":283,\"start\":276},{\"end\":393,\"start\":388}]", "author_first_name": "[{\"end\":55,\"start\":51},{\"end\":168,\"start\":161},{\"end\":275,\"start\":270},{\"end\":387,\"start\":380}]", "author_affiliation": "[{\"end\":159,\"start\":90},{\"end\":268,\"start\":199},{\"end\":378,\"start\":309},{\"end\":464,\"start\":395},{\"end\":521,\"start\":466}]", "title": "[{\"end\":48,\"start\":1},{\"end\":570,\"start\":523}]", "venue": null, "abstract": "[{\"end\":1482,\"start\":661}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1622,\"start\":1619},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":1955,\"start\":1951},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1966,\"start\":1963},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1976,\"start\":1973},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":1991,\"start\":1988},{\"end\":2918,\"start\":2911},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3010,\"start\":3007},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3169,\"start\":3165},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4778,\"start\":4774},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5710,\"start\":5707},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7809,\"start\":7806},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9461,\"start\":9458},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10426,\"start\":10422},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":14119,\"start\":14115},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14268,\"start\":14265},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14270,\"start\":14268},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16415,\"start\":16413}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":19247,\"start\":19193},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":19499,\"start\":19248},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":19709,\"start\":19500},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":19973,\"start\":19710},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":20346,\"start\":19974}]", "paragraph": "[{\"end\":2066,\"start\":1498},{\"end\":3266,\"start\":2068},{\"end\":3607,\"start\":3268},{\"end\":4928,\"start\":3609},{\"end\":5464,\"start\":4930},{\"end\":6065,\"start\":5485},{\"end\":6155,\"start\":6084},{\"end\":6369,\"start\":6157},{\"end\":6704,\"start\":6371},{\"end\":6977,\"start\":6706},{\"end\":7465,\"start\":6979},{\"end\":7796,\"start\":7467},{\"end\":7977,\"start\":7798},{\"end\":8641,\"start\":7979},{\"end\":9184,\"start\":8643},{\"end\":9904,\"start\":9214},{\"end\":10174,\"start\":9906},{\"end\":10686,\"start\":10176},{\"end\":11119,\"start\":10716},{\"end\":11462,\"start\":11121},{\"end\":13856,\"start\":11464},{\"end\":15303,\"start\":13927},{\"end\":15506,\"start\":15333},{\"end\":15662,\"start\":15508},{\"end\":15768,\"start\":15664},{\"end\":15869,\"start\":15770},{\"end\":16040,\"start\":15871},{\"end\":16146,\"start\":16042},{\"end\":16249,\"start\":16148},{\"end\":16303,\"start\":16251},{\"end\":16628,\"start\":16305},{\"end\":17334,\"start\":16630},{\"end\":17755,\"start\":17360},{\"end\":18411,\"start\":17757},{\"end\":18961,\"start\":18442},{\"end\":19192,\"start\":18963}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":11907,\"start\":11900},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":12921,\"start\":12914},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":14628,\"start\":14621},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":16835,\"start\":16828}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1496,\"start\":1484},{\"attributes\":{\"n\":\"2.\"},\"end\":5483,\"start\":5467},{\"attributes\":{\"n\":\"2.1\"},\"end\":6082,\"start\":6068},{\"attributes\":{\"n\":\"2.2\"},\"end\":9212,\"start\":9187},{\"attributes\":{\"n\":\"2.3\"},\"end\":10714,\"start\":10689},{\"attributes\":{\"n\":\"3.\"},\"end\":13878,\"start\":13859},{\"attributes\":{\"n\":\"3.1\"},\"end\":13901,\"start\":13881},{\"attributes\":{\"n\":\"3.2\"},\"end\":13925,\"start\":13904},{\"attributes\":{\"n\":\"3.3\"},\"end\":15331,\"start\":15306},{\"attributes\":{\"n\":\"4.\"},\"end\":17358,\"start\":17337},{\"attributes\":{\"n\":\"5.\"},\"end\":18440,\"start\":18414},{\"end\":19204,\"start\":19194},{\"end\":19510,\"start\":19501},{\"end\":19720,\"start\":19711},{\"end\":19984,\"start\":19975}]", "table": "[{\"end\":19709,\"start\":19548},{\"end\":19973,\"start\":19754},{\"end\":20346,\"start\":20026}]", "figure_caption": "[{\"end\":19247,\"start\":19206},{\"end\":19499,\"start\":19250},{\"end\":19548,\"start\":19512},{\"end\":19754,\"start\":19722},{\"end\":20026,\"start\":19986}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13097,\"start\":13089}]", "bib_author_first_name": "[{\"end\":20862,\"start\":20861},{\"end\":20872,\"start\":20871},{\"end\":20884,\"start\":20883},{\"end\":21164,\"start\":21163},{\"end\":21174,\"start\":21173},{\"end\":21510,\"start\":21509},{\"end\":21521,\"start\":21520},{\"end\":21531,\"start\":21530},{\"end\":21905,\"start\":21904},{\"end\":21916,\"start\":21915},{\"end\":21927,\"start\":21926},{\"end\":21939,\"start\":21938},{\"end\":22176,\"start\":22175},{\"end\":22186,\"start\":22185},{\"end\":22193,\"start\":22192},{\"end\":22200,\"start\":22199},{\"end\":22531,\"start\":22530},{\"end\":22546,\"start\":22545},{\"end\":22557,\"start\":22556},{\"end\":22814,\"start\":22813},{\"end\":22816,\"start\":22815},{\"end\":23257,\"start\":23256},{\"end\":23270,\"start\":23269},{\"end\":23614,\"start\":23613},{\"end\":23625,\"start\":23624},{\"end\":23956,\"start\":23955},{\"end\":23958,\"start\":23957},{\"end\":23965,\"start\":23964},{\"end\":23967,\"start\":23966},{\"end\":24321,\"start\":24320},{\"end\":24332,\"start\":24331},{\"end\":24344,\"start\":24343},{\"end\":24356,\"start\":24355},{\"end\":24632,\"start\":24631},{\"end\":24642,\"start\":24641},{\"end\":24661,\"start\":24660},{\"end\":24935,\"start\":24934},{\"end\":24948,\"start\":24947},{\"end\":24961,\"start\":24960},{\"end\":25207,\"start\":25206}]", "bib_author_last_name": "[{\"end\":20869,\"start\":20863},{\"end\":20881,\"start\":20873},{\"end\":20892,\"start\":20885},{\"end\":21171,\"start\":21165},{\"end\":21185,\"start\":21175},{\"end\":21518,\"start\":21511},{\"end\":21528,\"start\":21522},{\"end\":21539,\"start\":21532},{\"end\":21913,\"start\":21906},{\"end\":21924,\"start\":21917},{\"end\":21936,\"start\":21928},{\"end\":21948,\"start\":21940},{\"end\":22183,\"start\":22177},{\"end\":22190,\"start\":22187},{\"end\":22197,\"start\":22194},{\"end\":22205,\"start\":22201},{\"end\":22543,\"start\":22532},{\"end\":22554,\"start\":22547},{\"end\":22562,\"start\":22558},{\"end\":22567,\"start\":22564},{\"end\":22826,\"start\":22817},{\"end\":23267,\"start\":23258},{\"end\":23285,\"start\":23271},{\"end\":23622,\"start\":23615},{\"end\":23631,\"start\":23626},{\"end\":23962,\"start\":23959},{\"end\":23972,\"start\":23968},{\"end\":24329,\"start\":24322},{\"end\":24341,\"start\":24333},{\"end\":24353,\"start\":24345},{\"end\":24363,\"start\":24357},{\"end\":24639,\"start\":24633},{\"end\":24658,\"start\":24643},{\"end\":24669,\"start\":24662},{\"end\":24945,\"start\":24936},{\"end\":24958,\"start\":24949},{\"end\":24970,\"start\":24962},{\"end\":25213,\"start\":25208}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":5140751},\"end\":21106,\"start\":20786},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":15701997},\"end\":21463,\"start\":21108},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":16563009},\"end\":21848,\"start\":21465},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":16369935},\"end\":22127,\"start\":21850},{\"attributes\":{\"doi\":\"11-742/S10-TREC/TREC-Nov19-09.pdf\",\"id\":\"b4\"},\"end\":22453,\"start\":22129},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":206134284},\"end\":22754,\"start\":22455},{\"attributes\":{\"id\":\"b6\"},\"end\":23190,\"start\":22756},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":8596914},\"end\":23609,\"start\":23192},{\"attributes\":{\"id\":\"b8\"},\"end\":23837,\"start\":23611},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":17617881},\"end\":24284,\"start\":23839},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7804907},\"end\":24629,\"start\":24286},{\"attributes\":{\"doi\":\"arXiv:1409.5443\",\"id\":\"b11\"},\"end\":24890,\"start\":24631},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":10659969},\"end\":25167,\"start\":24892},{\"attributes\":{\"id\":\"b13\"},\"end\":25313,\"start\":25169}]", "bib_title": "[{\"end\":20859,\"start\":20786},{\"end\":21161,\"start\":21108},{\"end\":21507,\"start\":21465},{\"end\":21902,\"start\":21850},{\"end\":22528,\"start\":22455},{\"end\":22811,\"start\":22756},{\"end\":23254,\"start\":23192},{\"end\":23953,\"start\":23839},{\"end\":24318,\"start\":24286},{\"end\":24932,\"start\":24892}]", "bib_author": "[{\"end\":20871,\"start\":20861},{\"end\":20883,\"start\":20871},{\"end\":20894,\"start\":20883},{\"end\":21173,\"start\":21163},{\"end\":21187,\"start\":21173},{\"end\":21520,\"start\":21509},{\"end\":21530,\"start\":21520},{\"end\":21541,\"start\":21530},{\"end\":21915,\"start\":21904},{\"end\":21926,\"start\":21915},{\"end\":21938,\"start\":21926},{\"end\":21950,\"start\":21938},{\"end\":22185,\"start\":22175},{\"end\":22192,\"start\":22185},{\"end\":22199,\"start\":22192},{\"end\":22207,\"start\":22199},{\"end\":22545,\"start\":22530},{\"end\":22556,\"start\":22545},{\"end\":22564,\"start\":22556},{\"end\":22569,\"start\":22564},{\"end\":22828,\"start\":22813},{\"end\":23269,\"start\":23256},{\"end\":23287,\"start\":23269},{\"end\":23624,\"start\":23613},{\"end\":23633,\"start\":23624},{\"end\":23964,\"start\":23955},{\"end\":23974,\"start\":23964},{\"end\":24331,\"start\":24320},{\"end\":24343,\"start\":24331},{\"end\":24355,\"start\":24343},{\"end\":24365,\"start\":24355},{\"end\":24641,\"start\":24631},{\"end\":24660,\"start\":24641},{\"end\":24671,\"start\":24660},{\"end\":24947,\"start\":24934},{\"end\":24960,\"start\":24947},{\"end\":24972,\"start\":24960},{\"end\":25215,\"start\":25206}]", "bib_venue": "[{\"end\":21304,\"start\":21254},{\"end\":21668,\"start\":21613},{\"end\":22953,\"start\":22899},{\"end\":23414,\"start\":23359},{\"end\":24078,\"start\":24030},{\"end\":24472,\"start\":24427},{\"end\":20929,\"start\":20894},{\"end\":21252,\"start\":21187},{\"end\":21611,\"start\":21541},{\"end\":21971,\"start\":21950},{\"end\":22173,\"start\":22129},{\"end\":22586,\"start\":22569},{\"end\":22897,\"start\":22828},{\"end\":23357,\"start\":23287},{\"end\":23710,\"start\":23633},{\"end\":24028,\"start\":23974},{\"end\":24425,\"start\":24365},{\"end\":24737,\"start\":24686},{\"end\":25012,\"start\":24972},{\"end\":25204,\"start\":25169}]"}}}, "year": 2023, "month": 12, "day": 17}