{"id": 10795036, "updated": "2023-11-08 01:46:55.703", "metadata": {"title": "BPR: Bayesian Personalized Ranking from Implicit Feedback", "authors": "[{\"first\":\"Steffen\",\"last\":\"Rendle\",\"middle\":[]},{\"first\":\"Christoph\",\"last\":\"Freudenthaler\",\"middle\":[]},{\"first\":\"Zeno\",\"last\":\"Gantner\",\"middle\":[]},{\"first\":\"Lars\",\"last\":\"Schmidt-Thieme\",\"middle\":[]}]", "venue": "ArXiv", "journal": "452-461", "publication_date": {"year": 2012, "month": null, "day": null}, "abstract": "Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive knearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1205.2618", "mag": "2950975304", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/uai/RendleFGS09", "doi": null}}, "content": {"source": {"pdf_hash": "1c2cae04e0e00dcec3fe6840b2daa00ae9e8a0a3", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/1205.2618v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "64442b8c4120cec0e94c01635e645e3b087c7940", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1c2cae04e0e00dcec3fe6840b2daa00ae9e8a0a3.txt", "contents": "\nBPR: Bayesian Personalized Ranking from Implicit Feedback\n\n\nSteffen Rendle srendle@ismll.de \nMachine Learning Lab\nUniversity of Hildesheim\nMarienburger Platz 2231141HildesheimGermany\n\nChristoph Freudenthaler freudenthaler@ismll.de \nMachine Learning Lab\nUniversity of Hildesheim\nMarienburger Platz 2231141HildesheimGermany\n\nZeno Gantner gantner@ismll.de \nMachine Learning Lab\nUniversity of Hildesheim\nMarienburger Platz 2231141HildesheimGermany\n\nLars Schmidt-Thieme schmidt-thieme@ismll.de \nMachine Learning Lab\nUniversity of Hildesheim\nMarienburger Platz 2231141HildesheimGermany\n\nBPR: Bayesian Personalized Ranking from Implicit Feedback\n\nItem recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive knearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion.3. We show how to apply LearnBPR to two stateof-the-art recommender model classes. 4. Our experiments empirically show that for the task of of personalized ranking, learning a model with BPR outperforms other learning methods. RENDLE ET AL. 452 UAI 2009\n\nIntroduction\n\nRecommending content is an important task in many information systems. For example online shopping websites like Amazon give each customer personalized recommendations of products that the user might be interested in. Other examples are video portals like YouTube that recommend movies to customers. Per-sonalization is attractive both for content providers, who can increase sales or views, and for customers, who can find interesting content more easily. In this paper, we focus on item recommendation. The task of item recommendation is to create a user-specific ranking for a set of items. Preferences of users about items are learned from the user's past interaction with the system -e.g. his buying history, viewing history, etc.\n\nRecommender systems are an active topic of research. Most recent work is on scenarios where users provide explicit feedback, e.g. in terms of ratings. Nevertheless, in real-world scenarios most feedback is not explicit but implicit. Implicit feedback is tracked automatically, like monitoring clicks, view times, purchases, etc. Thus it is much easier to collect, because the user has not to express his taste explicitly. In fact implicit feedback is already available in almost any information system -e.g. web servers record any page access in log files.\n\nIn this paper we present a generic method for learning models for personalized ranking. The contributions of this work are:\n\n1. We present the generic optimization criterion BPR-Opt derived from the maximum posterior estimator for optimal personalized ranking. We show the analogies of BPR-Opt to maximization of the area under ROC curve.\n\n2. For maximizing BPR-Opt, we propose the generic learning algorithm LearnBPR that is based on stochastic gradient descent with bootstrap sampling of training triples. We show that our algorithm is superior to standard gradient descent techniques for optimizing w.r.t. BPR-Opt.\n\n\nRelated Work\n\nThe most popular model for recommender systems is k-nearest neighbor (kNN) collaborative filtering [2]. Traditionally the similarity matrix of kNN is computed by heuristics -e.g. the Pearson correlationbut in recent work [8] the similarity matrix is treated as model parameters and is learned specifically for the task. Recently, matrix factorization (MF) has become very popular in recommender systems both for implicit and explicit feedback. In early work [13] singular value decomposition (SVD) has been proposed to learn the feature matrices. MF models learned by SVD have shown to be very prone to overfitting. Thus regularized learning methods have been proposed. For item prediction Hu et al. [5] and Pan et al. [10] propose a regularized least-square optimization with case weights (WR-MF). The case weights can be used to reduce the impact of negative examples. Hofmann [4] proposes a probabilistic latent semantic model for item recommendation. Schmidt-Thieme [14] converts the problem into a multi-class problem and solves it with a set of binary classifiers. Even though all the work on item prediction discussed above is evaluated on personalized ranking datasets, none of these methods directly optimizes its model parameters for ranking. Instead they optimize to predict if an item is selected by a user or not. In our work we derive an optimization criterion for personalized ranking that is based on pairs of items (i.e. the user-specific order of two items). We will show how state-of-the-art models like MF or adaptive kNN can be optimized with respect to this criterion to provide better ranking quality than with usual learning methods. A detailed discussion of the relationship between our approach and the WR-MF approach of Hu et al. [5] and Pan et al. [10] as well as maximum margin matrix factorization [15] can be found in Section 5. In Section 4.1.1, we will also discuss the relations of our optimization criterion to AUC optimization like in [3].\n\nIn this paper, we focus on offline learning of the model parameters. Extending the learning method to online learning scenarios -e.g. a new user is added and his history increases from 0 to 1, 2, . . . feedback eventshas already been studied for MF for the related task of rating prediction [11]. The same fold-in strategy can be used for BPR.\n\nThere is also related work on learning to rank with non-collaborative models. One direction is to model distributions on permutations [7,6]. Burges et al. [1] optimize a neural network model for ranking using gradient descent. All these approaches learn only one ranking -i.e. they are non-personalized. In contrast to this, our models are collaborative models that learn personalized rankings, i.e. one individual ranking per user. In our evaluation, we show empirically that in typical recommender settings our personalized BPR model outperforms even the theoretical upper bound for non-personalized ranking.\n\n\nPersonalized Ranking\n\nThe task of personalized ranking is to provide a user with a ranked list of items. This is also called item recommendation. An example is an online shop that wants to recommend a personalized ranked list of items that the user might want to buy. In this paper we investigate scenarios where the ranking has to be inferred from the implicit behavior (e.g. purchases in the past) of the user. Interesting about implicit feedback systems is that only positive observations are available. The non-observed user-item pairs -e.g. a user has not bought an item yet -are a mixture of real negative feedback (the user is not interested in buying the item) and missing values (the user might want to buy the item in the future).\n\n\nFormalization\n\nLet U be the set of all users and I the set of all items. In our scenario implicit feedback S \u2286 U \u00d7I is available (see left side of Figure 1). Examples for such feedback are purchases in an online shop, views in a video portal or clicks on a website. The task of the recommender system is now to provide the user with a personalized total ranking > u \u2282 I 2 of all items, where > u has to meet the properties of a total order:\n\u2200i, j \u2208 I : i = j \u21d2 i > u j \u2228 j > u i (totality) \u2200i, j \u2208 I : i > u j \u2227 j > u i \u21d2 i = j (antisymmetry) \u2200i, j, k \u2208 I : i > u j \u2227 j > u k \u21d2 i > u k (transitivity)\nFor convenience we also define:\nI + u := {i \u2208 I : (u, i) \u2208 S} U + i := {u \u2208 U : (u, i) \u2208 S}\n\nAnalysis of the problem setting\n\nAs we have indicated before, in implicit feedback systems only positive classes are observed. The remaining data is a mixture of actually negative and missing values. The most common approach for coping with the missing value problem is to ignore all of them but then typical machine learning models are unable to learn anything, because they cannot distinguish between the two levels anymore.\n\nThe usual approach for item recommenders is to predict a personalized scorex ui for an item that reflects the preference of the user for the item. Then the items are ranked by sorting them according to that score. Machine learning approaches for item recommenders [5,10] typically create the training data from S by giving pairs (u, i) \u2208 S a positive class label and all other combinations in (U \u00d7 I) \\ S a negative one (see Figure 1). Then a model is fitted to this data. That means the model is optimized to predict the value 1 for elements in S and 0 for the rest. The problem with this approach is that all elements the model should rank in the future ((U \u00d7 I) \\ S) are presented to the learning algorithm as negative feedback during training. That means a model with enough expressiveness (that can fit the training data exactly) cannot rank at all as it predicts only 0s. The only reason why such machine learning methods can predict rankings are strategies to prevent overfitting, like regularization.\n\nWe use a different approach by using item pairs as training data and optimize for correctly ranking item pairs instead of scoring single items as this better represents the problem than just replacing missing values with negative ones. From S we try to reconstruct for each user parts of > u . If an item i has been viewed by user u -i.e. (u, i) \u2208 S -then we assume that the user prefers this item over all other non-observed items. E.g. in Figure 2 user u 1 has viewed item i 2 but not item i 1 , so we assume that this user prefers item i 2 over i 1 : i 2 > u i 1 . For items that have both been seen by a user, we cannot infer any preference. The same is true for two items that a user has not seen yet (e.g. item i 1 and i 4 for user u 1 ). To formalize this we create training data D S : U \u00d7 I \u00d7 I by:\nD S := {(u, i, j)|i \u2208 I + u \u2227 j \u2208 I \\ I + u }\nThe semantics of (u, i, j) \u2208 D S is that user u is assumed to prefer i over j. As > u is antisymmetric, the negative cases are regarded implicitly.\n\nOur approach has two advantages:  On the left side, the observed data S is shown. Our approach creates user specific pairwise preferences i > u j between a pair of items. On the right side, plus (+) indicates that a user prefers item i over item j; minus (-) indicates that he prefers j over i.\n\nnegative pairs and missing values. The missing values between two non-observed items are exactly the item pairs that have to be ranked in the future. That means from a pairwise point of view the training data D S and the test data is disjoint.\n\n2. The training data is created for the actual objective of ranking, i.e. the observed subset D S of > u is used as training data.\n\n\nBayesian Personalized Ranking (BPR)\n\nIn this section we derive a generic method for solving the personalized ranking task. It consists of the general optimization criterion for personalized ranking, BPR-Opt, which will be derived by a Bayesian analysis of the problem using the likelihood function for p(i > u j|\u0398) and the prior probability for the model parameter p(\u0398). We show the analogies to the ranking statistic AUC (area under the ROC curve). For learning models with respect to BPR-Opt, we propose the algorithm LearnBPR. Finally, we show how BPR-Opt and LearnBPR can be applied to two state-ofthe-art recommender algorithms, matrix factorization and adaptive kNN. Optimized with BPR these models are able to generate better rankings than with the usual training methods.\n\n\nBPR Optimization Criterion\n\nThe Bayesian formulation of finding the correct personalized ranking for all items i \u2208 I is to maximize the following posterior probability where \u0398 represents the parameter vector of an arbitrary model class (e.g. matrix factorization).\np(\u0398| > u ) \u221d p(> u |\u0398) p(\u0398)\nHere, > u is the desired but latent preference structure for user u. All users are presumed to act independently of each other. We also assume the ordering of each pair of items (i, j) for a specific user is independent of the ordering of every other pair. Hence, the above user-specific likelihood function p(> u |\u0398) can first be rewritten as a product of single densities and second be combined for all users u \u2208 U .\nu\u2208U p(> u |\u0398) = (u,i,j)\u2208U \u00d7I\u00d7I p(i > u j|\u0398) \u03b4((u,i,j)\u2208D S ) \u00b7 (1 \u2212 p(i > u j|\u0398)) \u03b4((u,j,i) \u2208D S )\nwhere \u03b4 is the indicator function:\n\u03b4(b) := 1 if b is true, 0 else\nDue to the totality and antisymmetry of a sound pairwise ordering scheme the above formula can be simplified to:\nu\u2208U p(> u |\u0398) = (u,i,j)\u2208D S p(i > u j|\u0398)\nSo far it is generally not guaranteed to get a personalized total order. In order to establish this, the already mentioned sound properties (totality, antisymmetry and transitivity) need to be fulfilled. To do so, we define the individual probability that a user really prefers item i to item j as:\np(i > u j|\u0398) := \u03c3(x uij (\u0398))\nwhere \u03c3 is the logistic sigmoid:\n\u03c3(x) := 1 1 + e \u2212x\nHerex uij (\u0398) is an arbitrary real-valued function of the model parameter vector \u0398 which captures the special relationship between user u, item i and item j. In other words, our generic framework delegates the task of modeling the relationship between u, i and j to an underlying model class like matrix factorization or adaptive kNN, which are in charge of estimatin\u011d x uij (\u0398). Hence, it becomes feasible to statistically  model a personalized total order > u . For convenience, in the following we will skip the argument \u0398 fromx uij .\n\nSo far, we have only discussed the likelihood function.\n\nIn order to complete the Bayesian modeling approach of the personalized ranking task, we introduce a general prior density p(\u0398) which is a normal distribution with zero mean and variance-covariance matrix \u03a3 \u0398 .\np(\u0398) \u223c N (0, \u03a3 \u0398 )\nIn the following, to reduce the number of unknown hyperparameters we set \u03a3 \u0398 = \u03bb \u0398 I. Now we can formulate the maximum posterior estimator to derive our generic optimization criterion for personalized ranking BPR-Opt.\nBPR-Opt := ln p(\u0398| > u ) = ln p(> u |\u0398) p(\u0398) = ln (u,i,j)\u2208D S \u03c3(x uij ) p(\u0398) = (u,i,j)\u2208D S ln \u03c3(x uij ) + ln p(\u0398) = (u,i,j)\u2208D S ln \u03c3(x uij ) \u2212 \u03bb \u0398 ||\u0398|| 2\nwhere \u03bb \u0398 are model specific regularization parameters.\n\n\nAnalogies to AUC optimization\n\nWith this formulation of the Bayesian Personalized Ranking (BPR) scheme, it is now easy to grasp the analogy between BPR and AUC. The AUC per user is usually defined as:\nAUC(u) := 1 |I + u | |I \\ I + u | i\u2208I + u j\u2208|I\\I + u | \u03b4(x uij > 0)\nHence the average AUC is:\nAUC := 1 |U | u\u2208U AU C(u)\nWith our notation of D S this can be written as:\nAUC(u) = (u,i,j)\u2208D S z u \u03b4(x uij > 0)(1)\nwhere z u is the normalizing constant:\nz u = 1 |U | |I + u | |I \\ I + u |\nThe analogy between (1) and BPR-Opt is obvious. Besides the normalizing constant z u they only differ in the loss function. The AUC uses the non-differentiable loss \u03b4(x > 0) which is identical to the Heaviside function:\n\u03b4(x > 0) = H(x) := 1, x > 0 0, else\nInstead we use the differentiable loss ln \u03c3(x). It is common practice to replace the non-differentiable Heaviside function when optimizing for AUC [3]. Often the choice of the substitution is heuristic and a similarly shaped function like \u03c3 is used (see figure 3). In this paper, we have derived the alternative substitution ln \u03c3(x) that is motivated by the MLE.\n\n\nBPR Learning Algorithm\n\nIn the last section we have derived an optimization criterion for personalized ranking. As the criterion is differentiable, gradient descent based algorithms are an obvious choice for maximization. But as we will see, standard gradient descent is not the right choice for our problem. To solve this issue we propose LearnBPR, a stochastic gradient-descent algorithm based on bootstrap sampling of training triples (see figure 4).\n\nFirst of all the gradient of BPR-Opt with respect to the model parameters is:\n\u2202BPR-Opt \u2202\u0398 = (u,i,j)\u2208D S \u2202 \u2202\u0398 ln \u03c3(x uij ) \u2212 \u03bb \u0398 \u2202 \u2202\u0398 ||\u0398|| 2 \u221d (u,i,j)\u2208D S \u2212e \u2212xuij 1 + e \u2212xuij \u00b7 \u2202 \u2202\u0398x uij \u2212 \u03bb \u0398 \u0398 1: procedure LearnBPR(D S , \u0398) 2: initialize \u0398 3:\nrepeat 4: draw (u, i, j) from D S\n\n\n5:\n\n\u0398 \u2190 \u0398 + \u03b1 e \u2212x uij 1+e \u2212x uij \u00b7 \u2202 \u2202\u0398x uij + \u03bb \u0398 \u00b7 \u0398  The two most common algorithms for gradient descent are either full or stochastic gradient descent. In the first case, in each step the full gradient over all training data is computed and then the model parameters are updated with the learning rate \u03b1:\n\u0398 \u2190 \u0398 \u2212 \u03b1 \u2202BPR-Opt \u2202\u0398\nIn general this approach leads to a descent in the 'correct' direction, but convergence is slow. As we have O(|S| |I|) training triples in D S , computing the full gradient in each update step is not feasible. Furthermore, for optimizing BPR-Opt with full gradient descent also the skewness in the training pairs leads to poor convergence. Imagine an item i that is often positive. Then we have many terms of the formx uij in the loss because for many users u the item i is compared against all negative items j (the dominating class).\n\nThus the gradient for model parameters depending on i would dominate largely the gradient. That means very small learning rates would have to be chosen. Secondly, regularization is difficult as the gradients differ much.\n\nThe other popular approach is stochastic gradient descent. In this case for each triple (u, i, j) \u2208 D S an update is performed.\n\u0398 \u2190 \u0398 + \u03b1 e \u2212xuij 1 + e \u2212xuij \u00b7 \u2202 \u2202\u0398x uij + \u03bb \u0398 \u0398\nIn general this is a good approach for our skew problem but the order in which the training pairs are traversed is crucial. A typical approach that traverses the data item-wise or user-wise will lead to poor convergence as there are so many consecutive updates on the same user-item pair -i.e. for one user-item pair (u, i) there are many j with (u, i, j) \u2208 D S .\n\nTo solve this issue we suggest to use a stochastic gradient descent algorithm that chooses the triples randomly (uniformly distributed). With this approach the chances to pick the same user-item combination in consecutive update steps is small. We suggest to use a bootstrap sampling approach with replacement because stopping can be performed at any step. Abandoning the idea of full cycles through the data is especially useful in our case as the number of examples is very large and for convergence often a fraction of a full cycle is sufficient. We choose the number of single steps in our evaluation linearly depending on the number of observed positive feedback S. Figure 5 shows a comparison 1 of a typical userwise stochastic gradient descent to our approach LearnBPR with bootstrapping. The model is BPR-MF with 16 dimensions. As you can see LearnBPR converges much faster than user-wise gradient descent.\n\n\nLearning models with BPR\n\nIn the following we describe two state-of-the-art model classes for item recommendation and how we can learn them with our proposed BPR methods. We have chosen the two diverse model classes of matrix factorization [5,12] and learned k-nearest-neighbor [8]. Both classes try to model the hidden preferences of a user on an item. Their prediction is a real numberx ul per user-item-pair (u, l).\n\nBecause in our optimization we have triples (u, i, j) \u2208 D S , we first decompose the estimatorx uij and define it as:x uij :=x ui \u2212x uj 1 Details about the dataset and evaluation method can be found in Section 6. Now we can apply any standard collaborative filtering model that predictsx ul .\n\nIt is important to note that even though we use the same models as in other work, we optimize them against another criterion. This will lead to a better ranking because our criterion is optimal for the ranking task. Our criterion does not try to regress a single predictorx ul to a single number but instead tries to classify the difference of two predictionsx ui \u2212x uj .\n\n\nMatrix Factorization\n\nThe problem of predictingx ui can be seen as the task of estimating a matrix X : U \u00d7 I. With matrix factorization the target matrix X is approximated by the matrix product of two low-rank matrices W : |U | \u00d7 k and H : |I| \u00d7 k:X\n:= W H t\nwhere k is the dimensionality/rank of the approximation. Each row w u in W can be seen as a feature vector describing a user u and similarly each row h i of H describes an item i. Thus the prediction formula can also be written as:\nx ui = w u , h i = k f =1 w uf \u00b7 h if\nBesides the dot product \u00b7, \u00b7 in general any kernel can be used like in [11]. The model parameters for matrix factorization are \u0398 = (W, H). The model parameters can also be seen as latent variables, modeling the nonobserved taste of a user and the non-observed properties of an item.\n\nIn general the best approximation ofX to X with respect to least-square is achieved by the singular value decomposition (SVD). For machine learning tasks, it is known that SVD overfits and therefore many other matrix factorization methods have been proposed, including regularized least square optimization, non-negative factorization, maximum margin factorization, etc.\n\nFor the task of ranking, i.e. estimating whether a user prefers one item over another, a better approach is to optimize against the BPR-Opt criterion. This can be achieved by using our proposed algorithm LearnBPR. As stated before for optimizing with LearnBPR, only the gradient ofx uij with respect to every model parameter \u03b8 has to be known. For the matrix factorization model the derivatives are:\n\u2202 \u2202\u03b8x uij = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f3 (h if \u2212 h jf ) if \u03b8 = w uf , w uf if \u03b8 = h if , \u2212w uf if \u03b8 = h jf , 0 else\nFurthermore, we use three regularization constants: one \u03bb W for the user features W ; for the item features H we have two regularization constants, \u03bb H + that is used for positive updates on h if , and \u03bb H \u2212 for negative updates on h jf .\n\n\nAdaptive k-Nearest-Neighbor\n\nNearest-neighbor methods are very popular in collaborative filtering. They rely on a similarity measure between either items (item-based) or users (user-based).\n\nIn the following we describe item-based methods as they usually provide better results, but user-based methods work analogously. The idea is that the prediction for a user u and an item i depends on the similarity of i to all other items the user has seen in the past -i.e. I + u . Often only the k most similar items of I + u are regarded -the k-nearest neighbors. If the similarities between items are chosen carefully, one can also compare to all items in I + u . For item prediction the model of item-based k-nearest-neighbor is:\nx ui = l\u2208I + u \u2227l =i c il\nwhere C : I \u00d7 I is the symmetric item-correlation/ item-similarity matrix. Hence the model parameters of kNN are \u0398 = C.\n\nThe common approach for choosing C is by applying a heuristic similarity measure, e.g. cosine vector similarity:\nc cosine i,j := |U + i \u2229 U + j | |U + i | \u00b7 |U + j |\nA better strategy is to adapt the similarity measure C to the problem by learning it. This can be either done by using C directly as model parameters or if the number of items is too large, one can learn a factorization HH t of C with H : I \u00d7 k. In the following and also in our evaluation we use the first approach of learning C directly without factorizing it.\n\nAgain for optimizing the kNN model for ranking, we apply the BPR optimization criterion and use the LearnBPR algorithm. For applying the algorithm, the gradient ofx uij with respect to the model parameters C is:\n\u2202 \u2202\u03b8x uij = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 +1 if \u03b8 \u2208 {c il , c li } \u2227 l \u2208 I + u \u2227 l = i, \u22121 if \u03b8 \u2208 {c jl , c lj } \u2227 l \u2208 I + u \u2227 l = j, 0 else\nWe have two regularization constants, \u03bb + for updates on c il , and \u03bb \u2212 for updates on c jl .\n\n\nRelations to other methods\n\nWe discuss the relations of our proposed methods for ranking to two further item prediction models.\n\n\nWeighted Regularized Matrix Factorization (WR-MF)\n\nBoth Pan et al. [10] and Hu et al. [5] have presented a matrix factorization method for item prediction from implicit feedback. Thus the model class is the same as we described in Section 4.3.1, i.e.X := W H t with the matrices W : |U | \u00d7 k and H : |U | \u00d7 k. The optimization criterion and learning method differ substantially from our approach. Their method is an adaption of a SVD, which minimizes the square-loss. Their extensions are regularization to prevent overfitting and weights in the error function to increase the impact of positive feedback. In total their optimization criterion is:\nu\u2208U i\u2208I c ui ( w u , h i \u2212 1) 2 + \u03bb||W || 2 f + \u03bb||H|| 2 f\nwhere c ui are not model parameters but apriori given weights for each tuple (u, i). First of all, it is obvious that this optimization is on instance level (one item) instead of pair level (two items) as BPR. Apart from this, their optimization is a leastsquare which is known to correspond to the MLE for normally distributed random variables. However, the task of item prediction is actually not a regression (quantitative), but a classification (qualitative) one, so the logistic optimization is more appropriate.\n\nA strong point of WR-MF is that it can be learned in O(iter (|S| k 2 + k 3 (|I| + |U |))) provided that c ui is constant for non-positive pairs. Our evaluation indicates that LearnBPR usually converges after a subsample of m \u00b7 |S| single update steps even though there are much more triples to learn from.\n\n\nMaximum Margin Matrix Factorization (MMMF)\n\nWeimer et al. [15] use the maximum margin matrix factorization method (MMMF) for ordinal ranking. Their MMMF is designed for scenarios with explicit feedback in terms of ratings. Even though their ranking MMMF is not intended for implicit feedback datasets, one could apply it in our scenario by giving all non-observed items the 'rating' 0 and the observed ones a 1 (see Figure 1). With these modifications their optimization criterion to be minimized would be quite similar to BPR applied for matrix factorization:\n\n(u,i,j)\u2208Ds\nmax(0, 1\u2212 w u , h i \u2212 h j )+\u03bb w ||W || 2 f +\u03bb h ||H|| 2 f\nOne difference is that the error functions differ -our hinge loss is smooth and motivated by the MLE. Additionally, our BPR-Opt criterion is generic and can be applied to several models, whereas their method is specific for MF.\n\nBesides this, their learning method for MMMF differs from our generic approach LearnBPR. Their learning method is designed to work with sparse explicit data, i.e. they assume that there are many missing values and thus they assume to have much less pairs than in an implicit setting. But when their learning method is applied to implicit feedback datasets, the data has to be densified like described above and the number of training pairs D S is in O(|S| |I|). Our method LearnBPR can handle this situation by bootstrapping from D S (see Section 4.2).\n\n\nEvaluation\n\nIn our evaluation we compare learning with BPR to other learning approaches. We have chosen the two popular model classes of matrix factorization (MF) and k-nearest-neighbor (kNN). MF models are known to outperform [12] many other models including the Bayesian models URP [9] and PLSA [4] for the related task of collaborative rating prediction. In our evaluation, the matrix factorization models are learned by three different methods, i.e. SVD-MF, WR-MF [5,10] and our BPR-MF. For kNN, we compare cosine vector similarity (Cosine-kNN) to a model that has been optimized using our BPR method (BPR-kNN). Additionally, we report results for the baseline mostpopular, that weights each item user-independent, e.g.:\n\nx most-pop ui := |U + i |. Furthermore, we give the theoretical upper bound on AUC (np max ) for any nonpersonalized ranking method.\n\n\nDatasets\n\nWe use two datasets of two different applications. The Rossmann dataset is from an online shop. It contains the buying history of 10, 000 users on 4000 items. In total 426, 612 purchases are recorded. The task is to predict a personalized list of the items the user wants to buy next. The second dataset is the DVD rental dataset of Netflix. This dataset contains the rating behavior of users, where a user provides explicit ratings 1 to 5 stars for some movies. As we want to solve an implicit feedback task, we removed the rating scores from the dataset. Now the task is to predict if a user is likely to rate a movie. Again we are interested in a personalized ranked list starting with the movie that is most likely to be rated. For Netflix we have created a subsample of 10, 000 users, 5000 items containing 565, 738 rating actions. We draw the subsample such that every user has at least 10 items (\u2200u \u2208 U : |I + u | \u2265 10) and each item has at least 10 users: \u2200i \u2208 I : |U + i | \u2265 10.\n\n\nEvaluation Methodology\n\nWe use the leave one out evaluation scheme, where we remove for each user randomly one action (one useritem pair) from his history, i.e. we remove one entry from I + u per user u. This results in a disjoint train set S train and test set S test . The models are then learned on S train and their predicted personalized ranking is evaluated on the test set S test by the average AUC statistic:\nAUC = 1 |U | u 1 |E(u)| (i,j)\u2208E(u) \u03b4(x ui >x uj ) (2)\nwhere the evaluation pairs per user u are:\nE(u) := {(i, j)|(u, i) \u2208 S test \u2227 (u, j) \u2208 (S test \u222a S train )}\nA higher value of the AUC indicates a better quality. The trivial AUC of a random guess method is 0.5 and the best achievable quality is 1.\n\nWe repeated all experiments 10 times by drawing new train/test splits in each round. The hyperparameters for all methods are optimized via grid search in the first round and afterwards are kept constant in the remaining 9 repetitions. Figure 6 shows the AUC quality of all models on the two datasets. First of all, you can see that the two BPR optimized methods outperform all other methods in prediction quality. Comparing the same models among each other one can see the importance of the optimization method. For example all MF methods (SVD-MF, WR-MF and BPR-MF) share exactly the same model, but their prediction quality differs a lot. Even though SVD-MF is known to yield the best fit on the training data with respect to element-wise least square, it is a poor prediction method for machine learning tasks as it results in overfitting. This can be seen as the quality of SVD-MF decreases with an increasing number of dimensions. WR-MF is a more successful learning method for the task of ranking. Due to regularization its performance does not drop but steadily rises with an increasing number of dimensions. But BPR-MF outperforms WR-MF clearly for   To summarize, our results show the importance of optimizing model parameters to the right criterion. The empirical results indicate that our BPR-Opt criterion learned by LearnBPR outperforms the other stateof-the-art methods for personalized ranking from implicit feedback. The results are justified by the analysis of the problem (section 3.2) and by the theoretical derivation of BPR-Opt from the MLE.\n\n\nResults and Discussion\n\n\nNon-personalized ranking\n\nFinally, we compare the AUC quality of our personalized ranking methods to the best possible nonpersonalized ranking method. In contrast to our personalized ranking methods, a non-personalized ranking method creates the same ranking > for all users.\n\nWe compute the theoretical upper-bound np max for any non-personalized ranking method by optimizing the ranking > on the test set S test 2 . Figure 6 shows\n\n\nConclusion\n\nIn this paper we have presented a generic optimization criterion and learning algorithm for personalized ranking. The optimization criterion BPR-Opt is the maximum posterior estimator that is derived from a Bayesian analysis of the problem. For learning models with respect to BPR-Opt we have presented the generic learning algorithm LearnBPR that is based on stochastic gradient descent with bootstrap sampling. We have demonstrated how this generic method can be applied to the two state-of-the-art recommender models of matrix factorization and adaptive kNN. In our evaluation we show empirically that for the task of personalized ranking, models learned by BPR outperform the same models that are optimized with respect to other criteria. Our results show that the prediction quality does not only depend on the model but also largely on the optimization crite- rion. Both our theoretical and empirical results indicate that the BPR optimization method is the right choice for the important task of personalized ranking.\n\nFigure 1 :\n1On the left side, the observed data S is shown. Learning directly from S is not feasible as only positive feedback is observed. Usually negative data is generated by filling the matrix with 0 values.\n\nFigure 2 :\n2Figure 2: On the left side, the observed data S is shown. Our approach creates user specific pairwise preferences i > u j between a pair of items. On the right side, plus (+) indicates that a user prefers item i over item j; minus (-) indicates that he prefers j over i.\n\nFigure 3 :\n3Loss functions for optimizing the AUC. The non-differentiable Heaviside H(x) is often approximated by the sigmoid \u03c3(x). Our MLE derivation suggests to use ln \u03c3(x) instead.\n\nFigure 4 :\n4Optimizing models for BPR with bootstrapping based stochastic gradient descent. With learning rate \u03b1 and regularization \u03bb \u0398 .\n\nFigure 5 :\n5Empirical comparison of the convergence of typical user-wise stochastic gradient descent to our LearnBPR algorithm with bootstrap sampling.\n\n\nHu et al. have additional data to estimate c ui for positive feedback and they set c ui = 1 for the rest. Pan et al. suggest to set c ui = 1 for positive feedback and choose lower constants for the rest.\n\nFigure 6 :\n6Area under the ROC curve (AUC) prediction quality for the Rossmann dataset and a Netflix subsample. Our BPR optimizations for matrix factorization BPR-MF and k-nearest neighbor BPR-kNN are compared against weighted regularized matrix factorization (WR-MF) [5, 10], singular value decomposition (SVD-MF), k-nearest neighbor (Cosine-kNN) [2] and the most-popular model. For the factorization methods BPR-MF, WR-MF and SVD-MF, the model dimensions are increased from 8 to 128 dimensions. Finally, np max is the theoretical upper bound for any non-personalized ranking method. the task of ranking on both datasets. For example on Netflix a MF model with 8 dimensions optimized by BPR-MF achieves comparable quality as a MF model with 128 dimensions optimized by WR-MF.\n\n\nin our experiments both AUC scores are quite similar, e.g. on Netflix with most-popular on test 0.8794 vs. our upper bound of 0.8801.\nWe computed a real upper-bound but non-tight estimate on the AUC score. Please note that ranking by most-popular on test is not an upper bound on AUC. But that even simple personalized methods like Cosine-kNN outperform the upper-bound np max -and thus also all non-personalized methods -largely.\nAcknowledgementsThe authors gratefully acknowledge the partial co-funding of their work through the European Commission FP7 project MyMedia (www.mymediaproject.org) under the grant agreement no. 215006. For your inquiries please contact info@mymediaproject.org.\nLearning to rank using gradient descent. C Burges, T Shaked, E Renshaw, A Lazier, M Deeds, N Hamilton, G Hullender, ICML '05: Proceedings of the 22nd international conference on Machine learning. New York, NY, USAACM PressC. Burges, T. Shaked, E. Renshaw, A. Lazier, M. Deeds, N. Hamilton, and G. Hullender. Learn- ing to rank using gradient descent. In ICML '05: Proceedings of the 22nd international con- ference on Machine learning, pages 89-96, New York, NY, USA, 2005. ACM Press.\n\nItem-based top-n recommendation algorithms. M Deshpande, G Karypis, ACM Transactions on Information Systems. 221Springer-VerlagM. Deshpande and G. Karypis. Item-based top-n recommendation algorithms. ACM Transactions on Information Systems. Springer-Verlag, 22/1, 2004.\n\nOptimising area under the roc curve using gradient descent. A Herschtal, B Raskutti, ICML '04: Proceedings of the twenty-first international conference on Machine learning. New York, NY, USAACM49A. Herschtal and B. Raskutti. Optimising area under the roc curve using gradient descent. In ICML '04: Proceedings of the twenty-first inter- national conference on Machine learning, page 49, New York, NY, USA, 2004. ACM.\n\nLatent semantic models for collaborative filtering. T Hofmann, ACM Trans. Inf. Syst. 221T. Hofmann. Latent semantic models for collabo- rative filtering. ACM Trans. Inf. Syst., 22(1):89- 115, 2004.\n\nCollaborative filtering for implicit feedback datasets. Y Hu, Y Koren, C Volinsky, IEEE International Conference on Data Mining (ICDM 2008). Y. Hu, Y. Koren, and C. Volinsky. Collaborative filtering for implicit feedback datasets. In IEEE International Conference on Data Mining (ICDM 2008), pages 263-272, 2008.\n\nEfficient inference for distributions on permutations. J Huang, C Guestrin, L Guibas, Advances in Neural Information Processing Systems. J. Platt, D. Koller, Y. Singer, and S. RoweisCambridge, MAMIT Press20J. Huang, C. Guestrin, and L. Guibas. Efficient inference for distributions on permutations. In J. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Process- ing Systems 20, pages 697-704, Cambridge, MA, 2008. MIT Press.\n\nMultiobject tracking with representations of the symmetric group. R Kondor, A Howard, T Jebara, Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics. the Eleventh International Conference on Artificial Intelligence and StatisticsSan Juan, Puerto RicoR. Kondor, A. Howard, and T. Jebara. Multi- object tracking with representations of the sym- metric group. In Proceedings of the Eleventh In- ternational Conference on Artificial Intelligence and Statistics, San Juan, Puerto Rico, March 2007.\n\nFactorization meets the neighborhood: a multifaceted collaborative filtering model. Y Koren, KDD '08: Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. New York, NY, USAACMY. Koren. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In KDD '08: Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 426-434, New York, NY, USA, 2008. ACM.\n\nModeling user rating profiles for collaborative filtering. B Marlin, Advances in Neural Information Processing Systems. S. Thrun, L. Saul, and B. Sch\u00f6lkopfCambridge, MAMIT Press16B. Marlin. Modeling user rating profiles for col- laborative filtering. In S. Thrun, L. Saul, and B. Sch\u00f6lkopf, editors, Advances in Neural Infor- mation Processing Systems 16, Cambridge, MA, 2004. MIT Press.\n\nOne-class collaborative filtering. R Pan, Y Zhou, B Cao, N N Liu, R M Lukose, M Scholz, Q Yang, IEEE International Conference on Data Mining (ICDM 2008). R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. M. Lukose, M. Scholz, and Q. Yang. One-class collaborative filtering. In IEEE International Conference on Data Mining (ICDM 2008), pages 502-511, 2008.\n\nOnlineupdating regularized kernel matrix factorization models for large-scale recommender systems. S Rendle, L Schmidt-Thieme, RecSys '08: Proceedings of the 2008 ACM conference on Recommender systems. ACMS. Rendle and L. Schmidt-Thieme. Online- updating regularized kernel matrix factorization models for large-scale recommender systems. In RecSys '08: Proceedings of the 2008 ACM confer- ence on Recommender systems. ACM, 2008.\n\nFast maximum margin matrix factorization for collaborative prediction. J D M Rennie, N Srebro, ICML '05: Proceedings of the 22nd international conference on Machine learning. New York, NY, USAACMJ. D. M. Rennie and N. Srebro. Fast maxi- mum margin matrix factorization for collabora- tive prediction. In ICML '05: Proceedings of the 22nd international conference on Machine learn- ing, pages 713-719, New York, NY, USA, 2005. ACM.\n\nIncremental singular value decomposition algorithms for highly scalable recommender systems. B Sarwar, G Karypis, J Konstan, J Riedl, Proceedings of the 5th International Conference in Computers and Information Technology. the 5th International Conference in Computers and Information TechnologyB. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Incremental singular value decomposition algo- rithms for highly scalable recommender systems. In Proceedings of the 5th International Conference in Computers and Information Technology, 2002.\n\nCompound classification models for recommender systems. L Schmidt-Thieme, IEEE International Conference on Data Mining (ICDM 2005). L. Schmidt-Thieme. Compound classification models for recommender systems. In IEEE In- ternational Conference on Data Mining (ICDM 2005), pages 378-385, 2005.\n\nImproving maximum margin matrix factorization. M Weimer, A Karatzoglou, A Smola, Machine Learning. 72M. Weimer, A. Karatzoglou, and A. Smola. Im- proving maximum margin matrix factorization. Machine Learning, 72(3):263-276, 2008.\n", "annotations": {"author": "[{\"end\":184,\"start\":61},{\"end\":323,\"start\":185},{\"end\":445,\"start\":324},{\"end\":581,\"start\":446}]", "publisher": null, "author_last_name": "[{\"end\":75,\"start\":69},{\"end\":208,\"start\":195},{\"end\":336,\"start\":329},{\"end\":465,\"start\":451}]", "author_first_name": "[{\"end\":68,\"start\":61},{\"end\":194,\"start\":185},{\"end\":328,\"start\":324},{\"end\":450,\"start\":446}]", "author_affiliation": "[{\"end\":183,\"start\":94},{\"end\":322,\"start\":233},{\"end\":444,\"start\":355},{\"end\":580,\"start\":491}]", "title": "[{\"end\":58,\"start\":1},{\"end\":639,\"start\":582}]", "venue": null, "abstract": "[{\"end\":2100,\"start\":641}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4147,\"start\":4144},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4269,\"start\":4266},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4507,\"start\":4503},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4748,\"start\":4745},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4768,\"start\":4764},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4927,\"start\":4924},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5019,\"start\":5015},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5805,\"start\":5802},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5825,\"start\":5821},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5877,\"start\":5873},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6019,\"start\":6016},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6317,\"start\":6313},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6504,\"start\":6501},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6506,\"start\":6504},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6525,\"start\":6522},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9112,\"start\":9109},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9115,\"start\":9112},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15871,\"start\":15868},{\"end\":16796,\"start\":16794},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":19617,\"start\":19614},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":19620,\"start\":19617},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":19655,\"start\":19652},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21066,\"start\":21062},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24425,\"start\":24421},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24443,\"start\":24440},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":25950,\"start\":25946},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":27534,\"start\":27530},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":27590,\"start\":27587},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":27603,\"start\":27600},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27774,\"start\":27771},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27777,\"start\":27774}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33156,\"start\":32944},{\"attributes\":{\"id\":\"fig_2\"},\"end\":33440,\"start\":33157},{\"attributes\":{\"id\":\"fig_4\"},\"end\":33625,\"start\":33441},{\"attributes\":{\"id\":\"fig_6\"},\"end\":33764,\"start\":33626},{\"attributes\":{\"id\":\"fig_7\"},\"end\":33917,\"start\":33765},{\"attributes\":{\"id\":\"fig_8\"},\"end\":34123,\"start\":33918},{\"attributes\":{\"id\":\"fig_10\"},\"end\":34901,\"start\":34124},{\"attributes\":{\"id\":\"fig_11\"},\"end\":35037,\"start\":34902}]", "paragraph": "[{\"end\":2851,\"start\":2116},{\"end\":3409,\"start\":2853},{\"end\":3534,\"start\":3411},{\"end\":3749,\"start\":3536},{\"end\":4028,\"start\":3751},{\"end\":6020,\"start\":4045},{\"end\":6365,\"start\":6022},{\"end\":6977,\"start\":6367},{\"end\":7720,\"start\":7002},{\"end\":8163,\"start\":7738},{\"end\":8355,\"start\":8324},{\"end\":8843,\"start\":8450},{\"end\":9853,\"start\":8845},{\"end\":10661,\"start\":9855},{\"end\":10855,\"start\":10708},{\"end\":11151,\"start\":10857},{\"end\":11396,\"start\":11153},{\"end\":11528,\"start\":11398},{\"end\":12310,\"start\":11568},{\"end\":12577,\"start\":12341},{\"end\":13024,\"start\":12606},{\"end\":13157,\"start\":13123},{\"end\":13301,\"start\":13189},{\"end\":13641,\"start\":13343},{\"end\":13703,\"start\":13671},{\"end\":14260,\"start\":13723},{\"end\":14317,\"start\":14262},{\"end\":14529,\"start\":14319},{\"end\":14766,\"start\":14549},{\"end\":14977,\"start\":14922},{\"end\":15180,\"start\":15011},{\"end\":15274,\"start\":15249},{\"end\":15349,\"start\":15301},{\"end\":15429,\"start\":15391},{\"end\":15684,\"start\":15465},{\"end\":16083,\"start\":15721},{\"end\":16539,\"start\":16110},{\"end\":16618,\"start\":16541},{\"end\":16820,\"start\":16787},{\"end\":17132,\"start\":16827},{\"end\":17690,\"start\":17155},{\"end\":17912,\"start\":17692},{\"end\":18041,\"start\":17914},{\"end\":18455,\"start\":18092},{\"end\":19371,\"start\":18457},{\"end\":19792,\"start\":19400},{\"end\":20086,\"start\":19794},{\"end\":20459,\"start\":20088},{\"end\":20711,\"start\":20484},{\"end\":20952,\"start\":20721},{\"end\":21273,\"start\":20991},{\"end\":21645,\"start\":21275},{\"end\":22046,\"start\":21647},{\"end\":22390,\"start\":22152},{\"end\":22582,\"start\":22422},{\"end\":23117,\"start\":22584},{\"end\":23263,\"start\":23144},{\"end\":23377,\"start\":23265},{\"end\":23793,\"start\":23431},{\"end\":24006,\"start\":23795},{\"end\":24221,\"start\":24128},{\"end\":24351,\"start\":24252},{\"end\":25001,\"start\":24405},{\"end\":25578,\"start\":25061},{\"end\":25885,\"start\":25580},{\"end\":26448,\"start\":25932},{\"end\":26460,\"start\":26450},{\"end\":26746,\"start\":26519},{\"end\":27300,\"start\":26748},{\"end\":28027,\"start\":27315},{\"end\":28161,\"start\":28029},{\"end\":29161,\"start\":28174},{\"end\":29580,\"start\":29188},{\"end\":29677,\"start\":29635},{\"end\":29881,\"start\":29742},{\"end\":31444,\"start\":29883},{\"end\":31747,\"start\":31498},{\"end\":31904,\"start\":31749},{\"end\":32943,\"start\":31919}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8323,\"start\":8164},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8415,\"start\":8356},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10707,\"start\":10662},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12605,\"start\":12578},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13122,\"start\":13025},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13188,\"start\":13158},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13342,\"start\":13302},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13670,\"start\":13642},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13722,\"start\":13704},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14548,\"start\":14530},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14921,\"start\":14767},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15248,\"start\":15181},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15300,\"start\":15275},{\"attributes\":{\"id\":\"formula_13\"},\"end\":15390,\"start\":15350},{\"attributes\":{\"id\":\"formula_14\"},\"end\":15464,\"start\":15430},{\"attributes\":{\"id\":\"formula_15\"},\"end\":15720,\"start\":15685},{\"attributes\":{\"id\":\"formula_16\"},\"end\":16786,\"start\":16619},{\"attributes\":{\"id\":\"formula_17\"},\"end\":17154,\"start\":17133},{\"attributes\":{\"id\":\"formula_18\"},\"end\":18091,\"start\":18042},{\"attributes\":{\"id\":\"formula_19\"},\"end\":20720,\"start\":20712},{\"attributes\":{\"id\":\"formula_20\"},\"end\":20990,\"start\":20953},{\"attributes\":{\"id\":\"formula_21\"},\"end\":22151,\"start\":22047},{\"attributes\":{\"id\":\"formula_22\"},\"end\":23143,\"start\":23118},{\"attributes\":{\"id\":\"formula_23\"},\"end\":23430,\"start\":23378},{\"attributes\":{\"id\":\"formula_24\"},\"end\":24127,\"start\":24007},{\"attributes\":{\"id\":\"formula_25\"},\"end\":25060,\"start\":25002},{\"attributes\":{\"id\":\"formula_26\"},\"end\":26518,\"start\":26461},{\"attributes\":{\"id\":\"formula_27\"},\"end\":29634,\"start\":29581},{\"attributes\":{\"id\":\"formula_28\"},\"end\":29741,\"start\":29678}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2114,\"start\":2102},{\"attributes\":{\"n\":\"2\"},\"end\":4043,\"start\":4031},{\"attributes\":{\"n\":\"3\"},\"end\":7000,\"start\":6980},{\"attributes\":{\"n\":\"3.1\"},\"end\":7736,\"start\":7723},{\"attributes\":{\"n\":\"3.2\"},\"end\":8448,\"start\":8417},{\"attributes\":{\"n\":\"4\"},\"end\":11566,\"start\":11531},{\"attributes\":{\"n\":\"4.1\"},\"end\":12339,\"start\":12313},{\"attributes\":{\"n\":\"4.1.1\"},\"end\":15009,\"start\":14980},{\"attributes\":{\"n\":\"4.2\"},\"end\":16108,\"start\":16086},{\"end\":16825,\"start\":16823},{\"attributes\":{\"n\":\"4.3\"},\"end\":19398,\"start\":19374},{\"attributes\":{\"n\":\"4.3.1\"},\"end\":20482,\"start\":20462},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":22420,\"start\":22393},{\"attributes\":{\"n\":\"5\"},\"end\":24250,\"start\":24224},{\"attributes\":{\"n\":\"5.1\"},\"end\":24403,\"start\":24354},{\"attributes\":{\"n\":\"5.2\"},\"end\":25930,\"start\":25888},{\"attributes\":{\"n\":\"6\"},\"end\":27313,\"start\":27303},{\"attributes\":{\"n\":\"6.1\"},\"end\":28172,\"start\":28164},{\"attributes\":{\"n\":\"6.2\"},\"end\":29186,\"start\":29164},{\"attributes\":{\"n\":\"6.3\"},\"end\":31469,\"start\":31447},{\"attributes\":{\"n\":\"6.4\"},\"end\":31496,\"start\":31472},{\"attributes\":{\"n\":\"7\"},\"end\":31917,\"start\":31907},{\"end\":32955,\"start\":32945},{\"end\":33168,\"start\":33158},{\"end\":33452,\"start\":33442},{\"end\":33637,\"start\":33627},{\"end\":33776,\"start\":33766},{\"end\":34135,\"start\":34125}]", "table": null, "figure_caption": "[{\"end\":33156,\"start\":32957},{\"end\":33440,\"start\":33170},{\"end\":33625,\"start\":33454},{\"end\":33764,\"start\":33639},{\"end\":33917,\"start\":33778},{\"end\":34123,\"start\":33920},{\"end\":34901,\"start\":34137},{\"end\":35037,\"start\":34904}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7878,\"start\":7870},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9278,\"start\":9270},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":10304,\"start\":10296},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15983,\"start\":15975},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":16537,\"start\":16529},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":19136,\"start\":19128},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":26312,\"start\":26304},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":30126,\"start\":30118},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":31898,\"start\":31890}]", "bib_author_first_name": "[{\"end\":35639,\"start\":35638},{\"end\":35649,\"start\":35648},{\"end\":35659,\"start\":35658},{\"end\":35670,\"start\":35669},{\"end\":35680,\"start\":35679},{\"end\":35689,\"start\":35688},{\"end\":35701,\"start\":35700},{\"end\":36128,\"start\":36127},{\"end\":36141,\"start\":36140},{\"end\":36415,\"start\":36414},{\"end\":36428,\"start\":36427},{\"end\":36825,\"start\":36824},{\"end\":37028,\"start\":37027},{\"end\":37034,\"start\":37033},{\"end\":37043,\"start\":37042},{\"end\":37341,\"start\":37340},{\"end\":37350,\"start\":37349},{\"end\":37362,\"start\":37361},{\"end\":37814,\"start\":37813},{\"end\":37824,\"start\":37823},{\"end\":37834,\"start\":37833},{\"end\":38368,\"start\":38367},{\"end\":38815,\"start\":38814},{\"end\":39180,\"start\":39179},{\"end\":39187,\"start\":39186},{\"end\":39195,\"start\":39194},{\"end\":39202,\"start\":39201},{\"end\":39204,\"start\":39203},{\"end\":39211,\"start\":39210},{\"end\":39213,\"start\":39212},{\"end\":39223,\"start\":39222},{\"end\":39233,\"start\":39232},{\"end\":39590,\"start\":39589},{\"end\":39600,\"start\":39599},{\"end\":39993,\"start\":39992},{\"end\":39997,\"start\":39994},{\"end\":40007,\"start\":40006},{\"end\":40447,\"start\":40446},{\"end\":40457,\"start\":40456},{\"end\":40468,\"start\":40467},{\"end\":40479,\"start\":40478},{\"end\":40948,\"start\":40947},{\"end\":41231,\"start\":41230},{\"end\":41241,\"start\":41240},{\"end\":41256,\"start\":41255}]", "bib_author_last_name": "[{\"end\":35646,\"start\":35640},{\"end\":35656,\"start\":35650},{\"end\":35667,\"start\":35660},{\"end\":35677,\"start\":35671},{\"end\":35686,\"start\":35681},{\"end\":35698,\"start\":35690},{\"end\":35711,\"start\":35702},{\"end\":36138,\"start\":36129},{\"end\":36149,\"start\":36142},{\"end\":36425,\"start\":36416},{\"end\":36437,\"start\":36429},{\"end\":36833,\"start\":36826},{\"end\":37031,\"start\":37029},{\"end\":37040,\"start\":37035},{\"end\":37052,\"start\":37044},{\"end\":37347,\"start\":37342},{\"end\":37359,\"start\":37351},{\"end\":37369,\"start\":37363},{\"end\":37821,\"start\":37815},{\"end\":37831,\"start\":37825},{\"end\":37841,\"start\":37835},{\"end\":38374,\"start\":38369},{\"end\":38822,\"start\":38816},{\"end\":39184,\"start\":39181},{\"end\":39192,\"start\":39188},{\"end\":39199,\"start\":39196},{\"end\":39208,\"start\":39205},{\"end\":39220,\"start\":39214},{\"end\":39230,\"start\":39224},{\"end\":39238,\"start\":39234},{\"end\":39597,\"start\":39591},{\"end\":39615,\"start\":39601},{\"end\":40004,\"start\":39998},{\"end\":40014,\"start\":40008},{\"end\":40454,\"start\":40448},{\"end\":40465,\"start\":40458},{\"end\":40476,\"start\":40469},{\"end\":40485,\"start\":40480},{\"end\":40963,\"start\":40949},{\"end\":41238,\"start\":41232},{\"end\":41253,\"start\":41242},{\"end\":41262,\"start\":41257}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":11168734},\"end\":36081,\"start\":35597},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":207650042},\"end\":36352,\"start\":36083},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":8571129},\"end\":36770,\"start\":36354},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":5260357},\"end\":36969,\"start\":36772},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":10537313},\"end\":37283,\"start\":36971},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":6110355},\"end\":37745,\"start\":37285},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14422611},\"end\":38281,\"start\":37747},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207168823},\"end\":38753,\"start\":38283},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":381243},\"end\":39142,\"start\":38755},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":7369746},\"end\":39488,\"start\":39144},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":5443538},\"end\":39919,\"start\":39490},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":503367},\"end\":40351,\"start\":39921},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":1058329},\"end\":40889,\"start\":40353},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1007943},\"end\":41181,\"start\":40891},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":2406567},\"end\":41412,\"start\":41183}]", "bib_title": "[{\"end\":35636,\"start\":35597},{\"end\":36125,\"start\":36083},{\"end\":36412,\"start\":36354},{\"end\":36822,\"start\":36772},{\"end\":37025,\"start\":36971},{\"end\":37338,\"start\":37285},{\"end\":37811,\"start\":37747},{\"end\":38365,\"start\":38283},{\"end\":38812,\"start\":38755},{\"end\":39177,\"start\":39144},{\"end\":39587,\"start\":39490},{\"end\":39990,\"start\":39921},{\"end\":40444,\"start\":40353},{\"end\":40945,\"start\":40891},{\"end\":41228,\"start\":41183}]", "bib_author": "[{\"end\":35648,\"start\":35638},{\"end\":35658,\"start\":35648},{\"end\":35669,\"start\":35658},{\"end\":35679,\"start\":35669},{\"end\":35688,\"start\":35679},{\"end\":35700,\"start\":35688},{\"end\":35713,\"start\":35700},{\"end\":36140,\"start\":36127},{\"end\":36151,\"start\":36140},{\"end\":36427,\"start\":36414},{\"end\":36439,\"start\":36427},{\"end\":36835,\"start\":36824},{\"end\":37033,\"start\":37027},{\"end\":37042,\"start\":37033},{\"end\":37054,\"start\":37042},{\"end\":37349,\"start\":37340},{\"end\":37361,\"start\":37349},{\"end\":37371,\"start\":37361},{\"end\":37823,\"start\":37813},{\"end\":37833,\"start\":37823},{\"end\":37843,\"start\":37833},{\"end\":38376,\"start\":38367},{\"end\":38824,\"start\":38814},{\"end\":39186,\"start\":39179},{\"end\":39194,\"start\":39186},{\"end\":39201,\"start\":39194},{\"end\":39210,\"start\":39201},{\"end\":39222,\"start\":39210},{\"end\":39232,\"start\":39222},{\"end\":39240,\"start\":39232},{\"end\":39599,\"start\":39589},{\"end\":39617,\"start\":39599},{\"end\":40006,\"start\":39992},{\"end\":40016,\"start\":40006},{\"end\":40456,\"start\":40446},{\"end\":40467,\"start\":40456},{\"end\":40478,\"start\":40467},{\"end\":40487,\"start\":40478},{\"end\":40965,\"start\":40947},{\"end\":41240,\"start\":41230},{\"end\":41255,\"start\":41240},{\"end\":41264,\"start\":41255}]", "bib_venue": "[{\"end\":35791,\"start\":35713},{\"end\":36190,\"start\":36151},{\"end\":36525,\"start\":36439},{\"end\":36855,\"start\":36835},{\"end\":37110,\"start\":37054},{\"end\":37420,\"start\":37371},{\"end\":37937,\"start\":37843},{\"end\":38482,\"start\":38376},{\"end\":38873,\"start\":38824},{\"end\":39296,\"start\":39240},{\"end\":39690,\"start\":39617},{\"end\":40094,\"start\":40016},{\"end\":40574,\"start\":40487},{\"end\":41021,\"start\":40965},{\"end\":41280,\"start\":41264},{\"end\":35810,\"start\":35793},{\"end\":36544,\"start\":36527},{\"end\":37480,\"start\":37467},{\"end\":38039,\"start\":37939},{\"end\":38501,\"start\":38484},{\"end\":38923,\"start\":38910},{\"end\":40113,\"start\":40096},{\"end\":40648,\"start\":40576}]"}}}, "year": 2023, "month": 12, "day": 17}