{"id": 174799520, "updated": "2023-11-11 01:57:35.302", "metadata": {"title": "A meta-learning recommender system for hyperparameter tuning: predicting when tuning improves SVM classifiers", "authors": "[{\"first\":\"Rafael\",\"last\":\"Mantovani\",\"middle\":[\"Gomes\"]},{\"first\":\"Andr'e\",\"last\":\"Rossi\",\"middle\":[\"Luis\",\"Debiaso\"]},{\"first\":\"Edesio\",\"last\":\"Alcobacca\",\"middle\":[]},{\"first\":\"Joaquin\",\"last\":\"Vanschoren\",\"middle\":[]},{\"first\":\"Andr'e\",\"last\":\"Carvalho\",\"middle\":[\"Carlos\",\"Ponce\",\"de\",\"Leon\",\"Ferreira\",\"de\"]}]", "venue": "Information Sciences, Volume 501, 2019. Pages 193-221, ISSN 0020-0255", "journal": null, "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "For many machine learning algorithms, predictive performance is critically affected by the hyperparameter values used to train them. However, tuning these hyperparameters can come at a high computational cost, especially on larger datasets, while the tuned settings do not always significantly outperform the default values. This paper proposes a recommender system based on meta-learning to identify exactly when it is better to use default values and when to tune hyperparameters for each new dataset. Besides, an in-depth analysis is performed to understand what they take into account for their decisions, providing useful insights. An extensive analysis of different categories of meta-features, meta-learners, and setups across 156 datasets is performed. Results show that it is possible to accurately predict when tuning will significantly improve the performance of the induced models. The proposed system reduces the time spent on optimization processes, without reducing the predictive performance of the induced models (when compared with the ones obtained using tuned hyperparameters). We also explain the decision-making process of the meta-learners in terms of linear separability-based hypotheses. Although this analysis is focused on the tuning of Support Vector Machines, it can also be applied to other algorithms, as shown in experiments performed with decision trees.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": null, "mag": "2948164010", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/isci/MantovaniRAVC19", "doi": "10.1016/j.ins.2019.06.005"}}, "content": {"source": {"pdf_hash": "aaa978c97302e8570af0f4db176d284f90efb68f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1906.01684v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1906.01684", "status": "GREEN"}}, "grobid": {"id": "f19c176674e07f6b93130c3189127bc7973096c0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/aaa978c97302e8570af0f4db176d284f90efb68f.txt", "contents": "\nA meta-learning recommender system for hyperparameter tuning: predicting when tuning improves SVM classifiers\n\n\nRafael G Mantovani \nInstitute of Mathematics and Computer Sciences\nUniversity of S\u00e3o Paulo\nS\u00e3o Carlos -SPBrazil\n\nFederal Technology University\nCampus of Apucarana -PRBrazil\n\nAndr\u00e9 L D Rossi \nUniversidade Estadual Paulista\nCampus de ItapevaS\u00e3o PauloBrazil\n\nEdesio Alcoba\u00e7a \nInstitute of Mathematics and Computer Sciences\nUniversity of S\u00e3o Paulo\nS\u00e3o Carlos -SPBrazil\n\nJoaquin Vanschoren \nEindhoven University of Technology\nEindhovenNetherlands\n\nAndr\u00e9 C P L F De Carvalho \nInstitute of Mathematics and Computer Sciences\nUniversity of S\u00e3o Paulo\nS\u00e3o Carlos -SPBrazil\n\nA meta-learning recommender system for hyperparameter tuning: predicting when tuning improves SVM classifiers\nMeta-learningRecommender systemTuning recommendationHyperparameter tuningSupport vector machines\nFor many machine learning algorithms, predictive performance is critically affected by the hyperparameter values used to train them. However, tuning these hyperparameters can come at a high computational cost, especially on larger datasets, while the tuned settings do not always significantly outperform the default values. This paper proposes a recommender system based on meta-learning to identify exactly when it is better to use default values and when to tune hyperparameters for each new dataset. Besides, an in-depth analysis is performed to understand what they take into account for their decisions, providing useful insights.An extensive analysis of different categories of meta-features, meta-learners, and setups across 156 datasets is performed. Results show that it is possible to accurately predict when tuning will significantly improve the performance of the induced models. The proposed system reduces the time spent on optimization processes, without reducing the predictive performance of the induced models (when compared with the ones obtained using tuned hyperparameters). We also explain the decision-making process of the meta-learners in terms of linear separability-based hypotheses. Although this analysis is focused on the tuning of Support Vector Machines, it can also be applied to other algorithms, as shown in experiments performed with decision trees.\n\nIntroduction\n\nMany Machine Learning (ML) algorithms, among them Support Vector Machines (SVMs) [48], have been successfully used in a wide variety of problems. SVMs are kernel-based algorithms that perform non-linear classification using a hyperspace transformation, i.e., they map data inputs into a high-dimensional feature space where the problem is possibly linearly separable. As most ML algorithms, SVMs are sensitive to their Hyperparameter (HP) values, which directly affect their predictive performance and depend on the data under analysis. The predictive performance of SVMs is mostly affected by the values of four HPs: the kernel function (k), its width (\u03b3) or polynomial degree (d), and the regularized constant (C).\n\nHence, finding suitable SVM HPs is a frequently studied problem [18,34]. SVM HP tuning is commonly modeled as a black-box optimization problem whose objective function is associated with the predictive performance of the SVM induced model. Many optimization techniques have been proposed in the literature for this problem, varying from a simple Grid Search (GS) to the state of the art Sequential Model-based Optimization (SMBO) technique [43]. In [3], Bergstra & Bengio showed theoretically and empirically that Random Search (RS) is a better alternative than GS and is able to find good HP settings when performing HP tuning. Mantovani et. al. [27] also compared RS with meta-heuristics to tune SVM HPs. A large amount of empirical experiments showed that RS generates models with predictive performance as effective as those obtained by meta-heuristics.\n\nHowever, regardless the optimization technique, hyperparameter tuning usually has a high computational cost, particularly for large datasets, with no guarantee that a model with high predictive performance will be obtained. During the tuning, a large number of HP settings usually need to be assessed before a \"good\" solution is found, requiring the induction of several models, multiplying the learning cost by the number of settings evaluated. Besides, several aspects, such as the complexity of a dataset, can influence the tuning cost.\n\nWhen computational resources are limited, a commonly adopted alternative is to use the default HP values suggested by ML tools. Previous works have pointed out that for some datasets, HP tuning of SVMs is not necessary [41]. Using default values largely reduce the overall computational cost, but, depending on the dataset, can result in models whose predictive performance is significantly worse than models produced by using HP tuning. The ideal situation would be to recommend the best alternative, default or tuned HP values for each new dataset.\n\nIn this paper, we propose a recommender system to predict, when applying SVMs to a new dataset, whether it is better to perform HP tuning or it is sufficient to use default HP values. This system, based on Meta-learning (MtL) [5], is able to reduce the overall cost of tuning without significant loss in predictive performance. Another important novelty in this study is a descriptive analysis of how the recommendation occurs. Although the recommender system is proposed for the HP tuning of SVMs, it can also be used for other ML algorithms. To illustrate this aspect, we present an example where the recommender system is used for HP tuning of a Decision Tree (DT) induction algorithm. The proposed recommender system can also be categorized as an Automated Machine Learning (Au-toML) solution [14], since it aims to relieve the user from the repetitive and time-consuming tuning task, automating the process through MtL. The AutoML area is relatively new, and there still many questions to be addressed. This fact, and the emerging attention it has attracted from important research groups [14,21] and large companies 1 2 , highlights the importance of new studies in this area. An essential aspect for the success of AutoML systems is to provide an automatic and robust tuning system, which also emphasizes the relevance of the problem investigated in this paper.\n\nIn summary, the main contributions of this study are:\n\n\u2022 the development of a modular and extensible MtL framework to predict when default HP values provide accurate models, saving computational time that would be wasted on optimization with no significant improvement;\n\n\u2022 a comparison of the effectiveness of different sets of meta-features and preprocessing methods for meta-learning, not previously investigated;\n\n\u2022 reproducibility of the experiments and analyses: all the code and experimental results are available to reproduce experiments, analyses and allow further investigations 3 .\n\nIt is important to mention that we considered the proposed framework for predictive tasks, in particular, supervised classification tasks using SVMs. However, the issues investigated in this paper can be easily extended to other tasks (such as regression) and other ML algorithms 4 . This paper is structured as follows: Section 2 presents the basic MtL concepts used in our approach. Section 3 defines the HP tuning problem and presents a concise survey of prior work combining SVMs with MtL in some way. The complete experimental methodology covered to obtain the results is presented in Section 4. Results are discussed in Section 5 while final considerations and conclusions are presented in Section 6.\n\n\nBackground on Meta-Learning\n\nSeveral ML algorithms have been proposed for prediction tasks. However, since each algorithm has its inductive bias, some of them can be more appropriate for a particular data set. When applying a ML algorithm to a dataset, a higher predictive performance can be obtained if an algorithm whose bias is more adequate to the dataset is used. The recommendation of the most adequate ML algorithm for a new dataset is investigated in an research area known as Meta-learning (MtL) [5].\n\nMtL has been largely used for algorithm selection [1], and for ranking [44] and prediction [40] of predictive performance of ML algorithms. It investigates how to learn from previous ML experiments. According to Brazdil et. al. [5], meta-learning can be used to improve the learning mechanism itself after each training process. In MtL, the process of using a learning algorithm to induce a model for a data set is called baselearning. At the meta-level, likely useful information extracted from this process (meta-features) are used to induce a meta-model. This meta-model can recommend the most promising learning algorithm, a set of the N best learning algorithms or a ranking of learning algorithms according to their estimate predictive performance for a new dataset. The knowledge extracted during this process is called meta-knowledge. The meta-features extracted from each dataset is a critical aspect. They must be sufficient to describe the main aspects necessary to distinguish the predictive performance obtained by different learning algorithms when applied to this dataset. As a result, it should allow the induction of a meta-model with good predictive performance. According to [49] three different sets of measures can be applied to extract meta-features:\n\n(i) Simple, Statistical and Information-theoretic meta-features [6]: these consist of simple measures about the input dataset, such as the number of attributes, examples and classes, skewness, kurtosis and entropy. They are the most explored subset of meta-features in literature [14,16,32,39,40,45];\n\n(ii) Model-based meta-features [2]: these are a set of properties of a model induced by a ML algorithm for the dataset at the hand. For instance, if a decision tree induction algorithm is applied to the dataset, statistics about nodes, leaves and branches can be used to describe the dataset. They have also been used frequently in literature [39,40];\n\n(iii) Landmarking [35]: the predictive performance obtained by models induced by simple learning algorithms, called landmarkers, are used to characterize a dataset. These measures were explored in studies such as [14,40].\n\nRecently, new sets of measures have been proposed and explored in literature:\n\n(iv) Data complexity [17]: this is a set of measures which analyze the complexity of a problem considering the overlap in the attributes values, the separability of the classes, and geometry/topological properties.\n\nThey have been explored in [15]; and\n\n(v) Complex networks [33]: measures based on complex network properties are extracted from a network built with the data instances. These measures can only be extracted from numerical data. Thus, preprocessing procedures are required for their extraction. They were explored in [15].\n\n\nMeta-learning for Hyperparameter tuning\n\nAs previously mentioned, there is a large number of studies investigating the use of MtL to automate one or more steps in the application of ML algorithms for data analysis tasks. These studies can be roughly grouped into the following approaches, according to what MtL does:\n\n\u2022 it recommends HP settings;\n\n\u2022 it predicts training runtime;\n\n\u2022 it recommends initial values for HP optimization;\n\n\u2022 it estimates predictive performance for an HP setting;\n\n\u2022 it predicts HP tuning improvement/necessity. Table 1 summarizes a comprehensive list of studies that either embedded or used Meta-learning (MtL) to cope with the SVM HP tuning problem. Next, these works are described in more detail.\n\n\nRecommendation of HP settings\n\nThe first approach considered HP settings as independent algorithm configurations and predicted the best setting based on characteristics of the dataset under analysis. In this approach, the HP settings are predicted without actually evaluating the model on the new dataset [45]. In Soares et. al. [45] and Soares & Brazdil [44], the authors predicted the width (\u03b3) of the SVM Gaussian kernel for regression problems. A finite set of \u03b3 values was investigated for 42 regression problems and the predictive performance was assessed using 10-fold CV and the Normalized Mean Squared Error (NMSE) evaluation measure. The recommendation of \u03b3 values for new datasets used a k-Nearest Neighbors (kNN) meta-learner.\n\nAli & Smith-Miles [1] presented a similar study but selected one among five different SVM kernel functions for 112 classification datasets. They assessed model predictive performance for different HP settings using 10-CV procedure and the simple Accuracy (Acc) measure. Miranda & Prud\u00eancio [30] proposed another MtL approach, called Active Testing (AT) [23], to select the HPs \u03b3 and the soft margin (C). Experiments performed on 60 classification datasets assessed the settings using a single 10-CV and the Acc measure.\n\nLorena et. al. [25] proposed a set of complexity meta-features for regression problems. One of the case studies evaluated was the SVM HP tuning problem. The authors generated a finite grid of \u03b3, C and (margin of tolerance for regression SVMs) values, assessing them with a single 10-fold CV and NMSE measure, considering 39 regression problems. The recommendation of HPs for new unseen datasets was performed by a kNN distance-based meta-learner.\n\n\nPrediction of Training Runtime\n\nOther works investigated the use of MtL to estimate the training time of classification algorithms when induced by different HP settings. In Reif et. al. [38], the authors predicted the training time for several classifiers, including SVMs. They defined a discrete grid of \u03b3 \u00d7 C HP settings, assessing these settings on 123 classification datasets considering the Pearson Product-Moment Correlation Coefficient (PMCC) and the Normalized Absolute Error (NAE) performance measures. In Priya et. al [36], the authors conducted a similar study but used a Genetic Algorithm (GA) to optimize parameters and perform meta-feature selection of six meta-learners. Experiments were carried out over 78 classification datasets assessing HP settings using a 5-fold CV and the Mean Absolute Deviation (MAD) evaluation measure.\n\n\nRecommendation of initial values for HP optimization\n\nMtL has also been used to speed up the optimization of HP values for classification algorithms [14,16,32,39]. In Gomes et. al. [16] MtL is used to recommend HP settings as initial search values by the Particle Swarm Optimization (PSO) and Tabu Search (TS) optimization techniques. Experiments were conducted in 40 regression datasets adjusting the C and \u03b3 HPs to reduce the NMSE value. A kNN meta-learner was used to recommend the initial search values.\n\nReif et. al. [39] and Miranda et. al. [32] investigated, respectively, the use of Genetic Algorithms (GAs) and different versions of PSOs for the same task. In Miranda et.al. [31], the authors used multi-objective optimization to optimize the HPs to increase predictive the performance and the number of support vectors.\n\nThese studies used simple accuracy measure and 10-fold CV to optimize \u03b3 \u00d7 C HP values.\n\nThe same approach is explored in a tool to automate the use of Machine Learning (ML) algorithms, the Auto-skLearn [14]. In this tool, MtL is used to recommend HP settings for the initial population of the SMBO optimization technique. The authors explored all the available SVM HPs in 140 OpenML classification datasets. It is the first and perhaps the only work that uses nested-CVs to assess HP settings.\n\nEach setting was assessed in terms of the simple Acc measure.\n\n\nEstimation of predictive performance for an HP setting\n\nA more recent approach uses MtL to estimate ML algorithms' performance considering their HPs. In Reif et. al. [40], the authors evaluated different ML algorithms in 54 datasets, including SVMs, and used the performance predictions to develop a MtL system for automatic algorithm selection.\n\nWistuba et. al. [50] adapted the acquisition function of surrogate models by one optimized meta-model. They evaluated several SVM HP configurations in a holdout fashion procedure over 105 datasets and used the meta-knowledge to predict the performance of new HP settings for new datasets. The authors also proposed a new Transfer Acquisition Function (TAF) that extended the original proposal by predicting the predictive performance of HP settings for surrogate models.\n\nEggensperger et. al. [13] proposed a benchmarking approach of \"surrogate scenarios\", which extracts meta-knowledge from HP optimization and algorithm configuration problems, and approximates the performance surface by regression models. One of the 11 meta-datasets explored in the experimental setup has a set of SVMs HP settings assessed for the MNIST dataset. These settings were obtained executing a simple RS method and three optimizers: Random Online Adaptive Racing (ROAR) [20], Iterated F-race (Irace) [24], and Iterated Local Search in Parameter Configuration Space (ParamILS).\n\n\nPrediction of HP tuning improvement/necessity\n\nAlthough the studies mentioned in this section are the most related to our current work regarding the proposed modeling, they have different goals. While Ridd & Giraud-Carrier [41] and Sanders & Giraud-Carrier [42] are concerned with predicting tuning improvement, Mantovani et al. [28] and the present study aimed to predict when HP tuning is necessary.\n\nRidd & Giraud-Carrier [41] investigated a Combined Algorithm Selection and Hyperparameter Optimization (CASH) problem. They carried out experiments using PSO technique to search the hyperspace of this CASH problem in 326 binary classification datasets. Their MtL-based method predicts whether HP tuning would lead to a considerable increase in accuracy considering a pool of algorithms, including SVM.Even though this is one of the first studies in this direction, we could point out some drawbacks:\n\n\u2022 the proposed method does not identify which algorithm and correspondent HP values the user should run to achieve an improved performance;\n\n\u2022 there is no guarantee that training and testing data are not mutually exclusive;\n\n\u2022 the rule to label the meta-examples is defined empirically, based on thresholds of the difference of the accuracy between default and tuned HP values;\n\n\u2022 all the datasets are binary classification problems; and\n\n\u2022 it is not possible to reproduce the experiments, specially base-level tuning since most of the details are not explained, and the code is not available.\n\nSanders & Giraud-Carrier [42] used a GA technique for HP tuning of three different ML algorithms, including SVMs. Their experimental results with 229 OpenML classification datasets showed that tuning almost always yielded significant improvements compared to default HP values. Thus, they focused on the regression task of predicting how much improvement can be expected by tuning HP compared to default values. They also addressed this task using MtL. However, their study presents some limitations, such as:\n\n\u2022 the optimization process of SVM hyperparameters were computationally costly and did not finish for most of the datasets;\n\n\u2022 the meta-learner was not able to predict hyperparameter tuning improvements for SVM in those datasets whose tuning process finished;  \u2022 there is no guarantee that the generated meta-examples are different from each other (intersection between training and test data), since OpenML stores different versions of the same dataset. This could lead to biased results; and\n\n\u2022 experiments are not reproducible since most of the details are not explained, and the code is not available.\n\nMantovani et al. [28] proposed a MtL recommender system to predict when SVM HP tuning is necessary, i.e., when tuning is likely to improve the generalization power of the models. The meta-dataset was created by extracting characteristics based on simple and data complexity measures from 143 classification datasets.\n\nIn the base-level, different meta-heuristics (PSO, GA and EDA) were used to tune the SVM HPs using a nested-CV resampling strategy. An ensemble of meta-models achieved the best predictive performance assessed by the F-Score using simple meta-features. Besides these promising results, this study presents some shortcomings, such as:\n\n\u2022 the best predictive performance at the meta-level is moderately low;\n\n\u2022 when the method recommends tuning, the meta-heuristic which would lead to the best performance is not recommended;\n\n\u2022 only two default HP settings were investigated. In general, users try more than two settings before tuning;\n\n\u2022 there is no evidence that this method and the results can be generalized to other ML algorithms.\n\nThe main differences between the proposed approach and the most related work are shown in Table 2. It is important to note that although these are the most similar studies we have found in the literature, they addressed different problems. Furthermore, the meta-datasets generated by each study were also different, since they were generated using different datasets, target algorithms, meta-features, and labeling rules.\n\nBecause of these particularities, the straightforward comparison of these studies is unfeasible. The only free choice we could explore is the same meta-features adopted by them. In fact, Ridd & Giraud-Carrier [41] and Sanders & Giraud-Carrier [42] used a total of 68 meta-features which are included in our experimental setup (Section 4.4).\n\nBased on the literature, we realized that there is room for improvement in terms of predicting HP tuning necessity for ML algorithms and to better understand this meta-learning process. Our present work attempts to fill this gap yielding meta-models with high predictive performance and reasons why their decisions were made. To do this, we have comprehensive and systematically evaluated different categories of meta-features and preprocessing tasks, such as meta-feature selection and data balancing, and different default HP values. \n\n\nSummary of Literature Overview\n\nThe literature review carried out by the authors found a large increase in the use of MtL for tasks related to SVM HP tuning. The authors found 18 related works, but only three of them investigated specifically when HP tuning is necessary or its improvement (see Section 3.5). Overall, the following aspects were observed:\n\n\u2022 fourteen of the studies created the meta-knowledge using GS to tune the \u03b3 \u00d7 C HP;\n\n\u2022 most of the studies also evaluated the resultant models with a single CV procedure and the simple Acc evaluation measure;\n\n\u2022 half of the studies used in most 100 datasets. In [41], the authors used more than 300 datasets, but all of them for binary classification;\n\n\u2022 all investigated a small number of categories to generate meta-features;\n\n\u2022 nine of the studies used only kNN as meta-learner;\n\n\u2022 three of the studies applied meta-feature selection techniques to the meta-features;\n\n\u2022 two of the studies provided the complete resources necessary for the reproducibility of experiments;\n\n\u2022 None of the studies combined all these six previous issues.\n\nIn order to provide new insights in the investigation of how the use of MtL in the SVM HP tuning process can affect its predictive performance, this paper extends previous works by exploring:\n\n\u2022 Meta-features produced by measures from different categories;\n\n\u2022 Use of different learning algorithms as meta-learners;\n\n\u2022 Adoption of a reproducible and rigorous experimental methodology at base and meta-learning levels;\n\nand\n\n\u2022 Assessment of the use of meta-feature selection techniques to evaluate and select meta-features.\n\nOne of the main contributions of this paper is the analysis of the meta-model predictions to identify when it is better to use default or tuned HP values for the SVMs, and which meta-features have a major role in this identification.\n\n\nExperimental methodology\n\nIn this paper, experiments were carried out using MtL ideas to predict whether hyperparameter tuning can significantly improve SVM induced models, when compared with performance provided by their default hyperparameter values 5 . The framework treats the recommendation problem as a binary classification task and is formally defined as follows:\n\nLet D be the dataset collection. Each dataset d j \u2208 D is described by a vector mf (d j ) = (mf j,1 , ..., mf j,K ) of K meta-features, with mf j,k \u2208 M, the set of all known meta-features. Additionally, let \u2126 be a statistical labeling rule based on the prior evaluations from tuned and default hyperparameter settings (P). Given a significance level \u03b1, \u2126 maps prior performances to a binary classification task: \u2126 :\nP \u00d7 \u03b1 \u2192 C | C =\n{tune, not tune}. Thus, we can train a meta-learner L to predict whether optimization will lead to significant improvement on new datasets d i / \u2208 D, i.e.:\n\nL : M \u00d7 \u2126 \u2192 C (1) 5 The e1071 package was used to implement SVMs. It is the LibSVM [10] interface to the R environment.  : Meta-learning system to predict whether hyperparameter tuning is required (Adapted from [28]). At the figure, \"mf\" means meta-feature.\n\n\nOpenML classification datasets\n\nThe experiments used datasets from OpenML [47], a free scientific platform for standardization of experiments and sharing empirical results. OpenML supports reproducibility since any researcher can have access and use the same data for benchmark purposes. A total of 156 binary and multiclass classification datasets (D) from different application domains were selected for the experiments (Item 01 in Figure 1).\n\nFrom all the available and active datasets, those meeting the following criteria were selected:\n\n(a) number of features does not exceed 1, 500;\n\n(b) number of instances between 100 and 50, 000;\n\n(c) must not be a reduced, modified or binarized version of the original classification problem 6 ;\n\n(d) must not be an adaptation of a regression dataset;\n\n(e) all the classes must have at least 10 examples, enabling the use of stratified 10-fold CV resampling.\n\nThese criteria are meant to ensure a proper evaluation (a-b), e.g. datasets should not be so small or so large that they cause memory problems; they should not be too similar (c-d) (to avoid data leakage in our evaluation); and allow the use of 10-fold CV stratified resampling, given the high probability of dealing with imbalanced datasets (e). We also excluded datasets already used in our related work on defining optimized defaults, resulting in 156 datasets to be used in our meta-dataset. All datasets meeting these criteria and their main characteristics are presented on the study page at OpenML 7 .\n\nIn order to be suitable for SVMs, datasets were preprocessed: any constant or identifier attributes were package were used to preprocess them.\n\n\nSVM hyperparameter space\n\nThe SVM hyperparameter space used in the experiments is presented in Table 3. For each hyperparameter, the table shows its symbol, name, type, range/options, scale transformation applied, default values provided by LibSVM [10] and whether it was tuned. Here, only the Radial Basis Function (RBF) kernel is considered since it achieves good performances in general, may handle nonlinear decision boundaries, and has less numerical difficulties than other kernel functions (e.g., the values of the polynomial kernel may be infinite) [19]. For C and \u03b3, the selected range covers the hyperspace investigated in [41]. LibSVM default values are C = 1, and \u03b3 = 1/N , where N is the number of features of the dataset under analysis 10 .\n\n\nHyperparameter tuning process\n\nThe hyperparameter tuning process is depicted in Figure 1 (Item 2). Based on the defined hyperspace, SVMs hyperparameters were adjusted through a Random Search (RS) technique for all datasets selected.\n\nThe tuning process was carried out using nested CV resamplings [22], an \"unbiased performance evaluation methodology\" that correctly accounts for any overfitting that may occur in the model selection (considering the hyperparameter tuning). In fact, most of the important/current state of the art studies, including the Auto-WEKA 11 [21,46] and Auto-skLearn 12 [14] tools, have been using the nested CV methodology for 7 https://www.openml.org/s/52/data 8 https://github.com/openml/openml-r 9 https://github.com/mlr-org/mlr 10 LibSVM default values can be consulted at https://www.csie.ntu.edu.tw/~cjlin/libsvm/ 11 http://www.cs.ubc.ca/labs/beta/Projects/autoweka/ 12 https://github.com/automl/auto-sklearn hyperparameter selection and assessment. Thus, nested-CVs were also adopted in this current study. The number of outer folds was defined as M = 10 such as in [22]. Due to runtime constraints, the number of inner folds was set to N = 3.\n\nA budget with a maximum of 300 evaluations per (inner) fold was considered. A comparative experiment using different budget sizes for SVMs was presented in [27]. Results suggested that only a few iterations are required to reach good solutions in the optima hyperspace region. Indeed, in most of the cases, tuning has reached good performance values after 250-300 steps. Among techniques used by the authors, the Random Search (RS) was able to find near-optimum hyperparameter settings like the most complex tuning techniques did. Overall, they did not show statistical differences regarding performance and presented a runtime lower than population-based techniques 13 .\n\nHence, the tuning setup detailed in Table 4 generates a total of 90, 000 = 10 (outer folds) \u00d7 3 (inner folds) \u00d7 300 (budget) \u00d7 10 (seeds) HP settings during the search process for a single dataset. Tuning jobs were parallelized in a cluster facility provided by our university 14 and took four months to be completed.\n\n\nMeta-features\n\nThe meta-datasets used in the experiments were generated out of 'meta-features' (M) describing each dataset ( Figure 1 -Item 3). These meta-features were extracted by applying a set of measures mf i to the original datasets which obtain likely relevant characteristics from these datasets. A tool was developed to extract the meta-features and can be found on GitHub 15 , as presented in Table 8. We extracted a set of 80 meta-features from different categories, as described in Section 2. The set includes all the meta-features explored by the studies described in Subsection 3.5. The exact number of meta-features used from each category can be seen in Table 5. A complete description of them may be found in Tables A.10 and A.11\n\n(Appendix A). 13 These findings go towards what was previously described in [3]. 14 http://www.cemeai.icmc.usp.br/Euler/index.html 15 https://github.com/rgmantovani/MfeatExtractor  \n\n\nMeta-targets\n\nThe last meta-feature is the meta-target, whose value indicates whether the HP tuning significantly improved the predictive performance of the SVM model, compared with the use of default values. Since the HP tuning experiments contain several and diverse datasets, many of them may be imbalanced. Hence, the Balanced per class Accuracy (BAC) measure [8] was used as the fitness value during tuning, as well as for the final model assessment at the base-level learning 16 . The so-called \"meta-label rule\" \u2126 (Item 4 - Figure 1) applies the Wilcoxon paired-test to compare the solutions achieved by the RS technique (P tun ) and the default HP settings (P def ). Given a dataset d i \u2208 D and a significance level (\u03b1), if the HP tuned solutions were significantly better than those provided by defaults, its corresponding meta-example is labeled as 'Tuning' (C tun ); otherwise, it receives the 'Default'\nlabel (C def ).\nWhen performing the Wilcoxon test, three different values of \u03b1 = {0.10, 0.05, 0.01} were considered, resulting in three meta-datasets with different class distributions (Item 5 - Figure 1). The different significance levels (\u03b1) influence how strict the recommending system is when evaluating if tuning improved models' performance compared to the use of default HP values. The smaller the significance stricter it is,\n\ni.e., there must be greater confidence than the tuned hyper-parameter values obtained by improving the performance of the induced models. It may also imply in different labels for the same meta-example when evaluating different \u03b1 values. The initial experimental designs only compared LibSVM suggested default values with the HP tuned solutions. The resulting meta-datasets presented a high imbalance rate, prevailing the \"Tuning\" class. It was difficult to induce a meta-model with high predictive performance using this highly imbalanced data. An alternative to deal with this problem was to consider the optimized default HP values proposed in [29]. The optimized default values were obtained optimizing a common set of HP values, able to induce models with high predictive performance, for a group of datasets. By looking at the difference between the black and green lines, it is possible to observe that tuned models using RS outperformed models using default settings (provided by LibSVM) for around 2/3 of the datasets.\n\nHowever, when we consider multiple default settings (the best setting between LibSVM and optimized values), identified by the red curve, their performance values were close to the performance with tuned values. Thus, the meta-target labelling rule considered the difference between the predictive performances with tuned hyperparameters and the best predictive performances with multiple default HP values. A side effect of using multiple default HP values is a more class-balanced meta-dataset, increasing the proportion of meta-examples labeled with \"default\" use. As a result, the imbalance rate 17 in the meta-datasets was reduced from \u2248 2.6 to 1.7. Table 6 presents for each resultant meta-dataset: the \u03b1 value used to generate the labels; the number of meta-examples, the number of meta-features and the class distribution. It is important to observe that none of these 156 datasets were used in a related previous study that produced optimized default HP setting [29].\n\nIn our experimental setup, the null hypothesis of the statistical meta-label rule states that there is no significant difference between tuned and default SVM HP settings. Since we are concerned about preventing tuning HPs when it is not necessary, a type I error is defined as labeling a meta-example as \"Tuning\" when its label is, in fact, \"Defaults'. Therefore, the lower the \u03b1, the higher the probability that the improvement achieved by tuned values is not due to chance. On the other hand, the higher the alpha, the lower the requirement that the performance gain by the tuning process is significant compared to default values.\n\nSince we are controlling the error of labeling a meta-example as \"Tuning', smaller \u03b1 values will lead to a greater number of \"default meta-examples. On the contrary, the greater the alpha value, the greater the number of meta-examples labeled as\"tuning\". As can be seen in Table 6, a value of \u03b1 = 0.10 implies more instances with the meta-target \"Tuning\" than when using \u03b1 = 0.01. In summary, if predictive performance is more critical, the user should set the significance level as high as possible (e.g., \u03b1 = 0.10). On the other 17 imbalance rate = (majority class size / minority class size) hand, if the user is concerned about computational cost, the significance level should be set to smaller values (e.g., \u03b1 = 0.01). An example of this effect can be seen in Figure 2, where the blue dots represent all the datasets where defaults should be used, i.e., tuning is not statistically significant better (for \u03b1 = 0.05). \n\n\nExperimental Setup\n\nSeven classification algorithms were used as meta-learners (Item 7 - Figure  applied to the meta-datasets using a 10-fold CV resampling strategy and repeated 20 times with different seeds (for reproducibility). All the meta-datasets presented in Table 6 are binary classification problems.\n\nThus, meta-learners' predictions were assessed using the Area Under the ROC curve (AUC) performance measure, a more robust metric than BAC for binary problems. Moreover, AUC also enable us to evaluate the influence of different threshold values on predictions. Three options were also investigated at the meta-level:\n\n(i) Meta-feature Selection: as each meta-example is described by many meta-features, it may be the case that just a small subset of them is necessary to induce meta-models with high accuracy. Thus, a Sequential Forward Selection (SFS) feature selection option was added to the meta-learning experimental setup. The SFS method starts from an empty set of meta-features, and in each step, the meta-feature increasing the performance measure the most is added to the model. It stops when a minimum required value of improvement (alpha=0.01) is not satisfied. Internally, it also performs a stratified 3-fold CV assessing the resultant models also according to the AUC measure;\n\n(ii) Tuning: since the hyperparameter values of the meta-learners may also affect their performance, tuning of the meta-learners was also considered in the experimental setup. A simple RS technique was performed with a budget of 300 evaluations and resultant models assessed through an inner stratified 3-fold CV and AUC measure. Table B.12 (Appendix Appendix B) shows the hyperspace considered for tuning the meta-learners.\n\n(iii) Data balancing: even using the optimized default HP values, the classes in the meta-datasets were imbalanced. Thus, to reduce this imbalance, the Synthetic Minority Over-sampling Technique (SMOTE) [11] technique was used in the experiments.\n\nSome of the algorithms' implementations selected as meta-learners use a data scaling process by default.\n\nThis is the case of the SVM, kNN and GP meta-learners. A preliminary experiment showed that removing this option decreases their predictive performance considerably, while it does not affect the other algorithms.\n\nWhen data scaling is considered for all algorithms, the performance values of RF, CART, NB and LR metalearners were decreased. Thus, data scaling was not considered as an option, and the algorithms used their default procedures, with which they obtained their best performance values. Two baselines were also adopted for comparisons: a meta-dataset composed only by simple meta-features and another with data complexity ones. Both categories of meta-features were investigated before by related studies listed in Section 3.5.  Table 8.\n\n\nResults and Discussion\n\nThe main experimental results are described in the next subsections. First, an overview of the predictive performance of the meta-models for the predicting task when it is worth performing SVM HP tuning. Next, different experimental setups and preprocessing techniques, such as dimensionality reduction, are evaluated.\n\nFinally, the predictions and meta-knowledge produced by the meta-models are analyzed. In Figure 3a, the x-axis shows the meta-learners while the y-axis shows their predictive performance assessed by the AUC averaged over 30 repetitions. In addition, it shows the impact of different alpha (\u03b1) levels for the Wilcoxon test for the definition of the meta-target labels. The Wilcoxon paired-test with  The best results were obtained by the RF meta-learner using data complexity (complex ) meta-features,\n\n\nAverage performance\n\nachieving AUC values nearly 0.80 for all \u03b1 levels. These meta-models were also statistically better than   The Friedman test [12], with a significance level of \u03b1 = 0.05, was used to assess the statistical significance of the meta-learners. In the comparisons, we considered the algorithms' performance across the combination of the meta-datasets and the categories of meta-features. The null hypothesis states that all the meta-learners are equivalent regarding the Area Under the ROC curve (AUC) performance. When the null hypothesis is rejected, the Nemenyi post-hoc test is also applied to indicate when two different techniques are significantly different. Although the best result was obtained using Data Complexity (DC) meta-features (\"complex\"), most of the meta-learners achieved their highest AUC performance values exploring all the available meta-features.\n\nThus, since we want to analyze the influence of different categories of meta-features when inducing metamodels, and given the possibility of selecting different subsets from all the categories, we decided to explore all of them in the next analysis.\n\n\nEvaluating different setups\n\nDue to the large difference among meta-learners results, three different setups were also evaluated to improve their predictive performances and enable a comprehensive analysis of the investigated alternatives:\n\n(i) featsel -meta-feature selection via Sequential Forward Selection (SFS) [4];\n\n(ii) tuned -HP tuning of the meta-learners using a simple Random Search (RS) technique;\n\n(iii) smote: dataset balancing with SMOTE [11].\n\nThey were compared with the original meta-data with no additional process (none), which is the baseline for these analyses. These setups were not performed at the same time to avoid overfitting, since the metadatasets have 156 meta-examples and, depending on their combinations, three levels of CVs would be used to assess models. For example: if feature meta-selection and HP tuning were enabled at the meta-level, one CV would be used for meta-feature selection, one for tuning and another to assess the resulting models.  Figure 3a, the statistical analysis is also presented. Every time an upward green triangle is placed at the x-axis, the raw meta-data (none) generated results statistically better than using the best of the experimental setups evaluated. On the other hand, red triangles indicate when tuning, meta-feature selection or SMOTE could statistically improve the predictive performance of the meta-models. In the remaining cases, the meta-models were equivalent.\n\nDespite the different setups evaluated, RF is still the best meta-learner for all \u03b1 scenarios. It is followed by SVM and GP versions using SMOTE. Depending on the experimental setup, kNN and LR also presented good predictive performances. Regarding the HP tuning (tuned) of the meta-learners, only for kNN the performances slightly improved for all the alpha values. Using just SMOTE resulted in improved results for SVM, GP and CART meta-learners. In general, it produced small improvements, but most of them were statistically significant. When used with tuning or meta-feature selection, it affected the algorithms in different ways: for SVM and GP, the performance improved; for LR, NB and kNN there was no benefit; the other algorithms were not affected by its use. The low gain obtained using SMOTE may be due to the fact that data imbalance was already reduced using the optimized defaults when defining meta-targets.\n\nUsing meta-feature selection (featsel) deteriorated the performance of the SVM, RF, GPs and CART meta-learners. On the other hand, it clearly improved the kNN, LR and NB performances for most cases.\n\nkNN benefited from using a subset of meta-features to maximize the importance of more relevant metafeatures. For NB and LR, selecting a subset of the attributes reduced the presence of noise and irrelevant attributes. Furthermore, it is important to observe that the meta-models induced with the selected features presented the highest standard deviation between the setups (light area along the curve). A possible reason is the different subsets selected every time meta-feature selection is performed for the 30 repetitions.\n\nAdditionally, Figure 4b presents a ranking with all the combinations of meta-learners and experimental setups. At the x-axis, they are presented in ascending order according to their average ranking for the three scenarios (\u03b1 values), shown at the y-axis. The more red the squares, the lower the ranking, i.e., the better the results.    As previously reported, RF with no additional option was the best-ranked method, followed by its smoted versions. The SVM, GP and kNN versions are in the next positions. The Friedman test with a significance level of \u03b1 = 0.05 was also used to assess the statistical significance of the meta-learners when using different experimental setups in different meta-datasets. Figure 4c shows the resultant CD diagram. Results are quite similar to those reported in Figure 3b: the RF algorithm was the best algorithm with an average ranking of 1.05, and is statistically better than most of the meta-learners, except for SVM and GP.\n\nSince there were no improvements considering the maximum AUC values achieved so far, and the results from the RF meta-learners were still the best-ranked, the next subsections will analyze the relative importance of the meta-features according to the final RF induced models.\n\n\nImportance of meta-features\n\nFrom the induced RF meta-models, the relative importance of the meta-features based on the Gini impurity index used to calculate the node splits [7]. Figure 5 shows the average relative importance of the meta-features obtained from the RF meta-models. The relative importance is shown for the experiments considering all meta-features and \u03b1 = 0.05 (middle case). At the x-axis, meta-features are presented in decreasing order according to their average relative importance values. From this point, anytime a specific meta-feature is mentioned we present its name with a prefix indicating its category (according to Table 5). Since no negative value (negative relative importance) was obtained, no meta-feature was discharged to build meta-models. It also shows that a large number of meta-features were relevant to the induction of the meta-models, a possible reason for why meta-feature selection produced worse results for most of the meta-learners.\n\nThe most important meta-feature was a landmarking meta-feature: \"LM.stump sd\", which describes the standard deviation of the number of examples correctly classified by a decision stump. It measures the complexity of the problem considering its simplicity. The second most important was a simple meta-feature: \"SM.classes min\", which measures the minority class size. The third was also a simple meta-feature: \"SM.classes sd\", which describes the standard deviation of the number of examples per class. These metafeatures together strongly indicate that for RF, the most important meta-features are related with class imbalance. A rule extracted from a model induced by RF states that if the dataset is imbalanced, it is better to use default HP for SVMs. The other important meta-features were:\n\n\u2022 \"IN.nClEnt\" and \"IN.mutInf\": these are information-theoretical meta-features. While the first describes the class entropy for a normalized base level dataset, the second measures the mutual information, a reduction of uncertainty about one random feature given the knowledge of another;\n\n\u2022 \"CN.betweenness\": betweenness centrality is a meta-feature derived from complex networks that measures, for a set of vertex and edges, the average number of shortest paths that traverses them. The value will be small for simple datasets, and high for complex datasets;\n\n\u2022 \"DC.l1\" and \"DC. \u2022 \"CN.maxComp\": this is another complex-network meta-feature. It measures the maximum number of connected components in a graph. If a dataset presents a high overlapping of its classes, the graph will present a large number of disconnected components, since connections between different classes are pruned.\n\nAmong the most important, there are meta-features from different categories (simple, data complexity, complex-networks and from information-theory). Complex-network measures describe data complexity regarding graphs and indicate how sparse the classes are between their levels. Data complexity meta-features try to extract information related to the class separability. The stump meta-feature works along the same lines, trying to identify the complexity of the problem by simple landmarking. The information-theoretical meta-features indirectly checks how powerful the dataset attributes are to solve the classification problem.\n\nAlthough summarized rules cannot be obtained from RF meta-models, the analysis of meta-features importance provides some useful information. For instance, dataset characteristics such as the data balancing, class sizes, complexity and linearity were considered relevant to recommend when HP tuning is required.\n\n\nLinearity Hypothesis\n\nThe previous sections, in particular the RF meta-analysis, suggest that linearity is a key aspect to decide between the recommendation of default or tuned HPs values. Experimental results indicate that default HP values might be good for classification tasks with high linear separability. As a consequence, tuning would be required for tasks with complex decision surfaces, where SVMs would need to find irregular decision boundaries.  In order to investigate this hypothesis, a linear classifier was also evaluated in all the available 156 datasets using the same base-level experimental setup described in Table 4. If the linearity hypothesis is true, the performance difference between SVMs and the linear classifier in meta-examples labeled as \"Defaults\" would be smaller than or equal to the meta-examples labeled as \"Tuning'. Figure 6a shows the performance differences obtained in all the datasets at the base-level. Datasets at the x-axis are split based on their meta-target labels, \"Tuning', left side, in black, and \"Defaults\", right side, in red. Despite some outliers, the performance differences for \"Tuning\" meta-examples are in general much higher than those for the \"Defaults\" meta-examples. Thus, the observed patterns support the linearity hypothesis.\n\nIn [23], the authors proposed a set of \"Relative Landmarking (RL)\" meta-features based on the pairwise performance difference of simple landmarking algorithms. This new data characterizations schema is used to train meta-learning based on the Active Testing (AT) algorithm. The patterns observed in Figure 6a follow the same principle, presenting a new alternative to characterize base-level datasets. Following this proposal, 10 new relative landmarking meta-features were generated based on five landmarking algorithms: kNN, NB, LR, SVM and Decision Stump (DS). These new meta-features are described in Table A.11 in Appendix Appendix A.\n\nThe same RF meta-analysis described in Section 5.3 was performed, adding the relative landmarking meta-features to the meta-datasets. These experiments pointed out how useful the new meta-features are for the recommendation problem. Figure 6 shows the relative importance values of the meta-features averaged in 30 executions. The relative importance of these new meta-features are highlighted in red, while the simple landmarking is shown in blue.\n\nTwo of the relative landmarking meta-features are placed in the top-10 most important metafeatures: RL.diff.nn.lm (1st), and RL.diff.svm.lm (3rd); another two measures are in the top-20 -RL.diff.stump.lm and RL.diff.stump.lm; and all of them depend directly on the linear classifier performance. It is also important to mention that simple landmarking meta-features performed, in general, worse than relative landmarking. All these relative importance plots show evidence that the linearity hypothesis is true, and at least one characteristic that defines the need of HP tuning for SVMs is the linearity of the base-level classification task.\n\n\nOverall comparison\n\nGiven the potential shown by the relative landmarking meta-features, they were experimentally evaluated in combination with the meta-features previously evaluated as most important. Complex network (cnet) meta-features were included because they were ranked between the most important descriptors (as shown in Subsection 5.3). Simple and data complexity (complex) meta-features were the other two approaches evaluated in the related studies listed in Section 3.5.   meta-features improved all the setups where they were included. At least three different setups used by RF were higher than the AUC performance value obtained in the initial experiments. The setup considering simple and relative landmarking meta-features induced the best meta-models for RF, SVM and GPs. The kNN and LR meta-learners obtained the best predictive performance using data complexity and relative landmarking meta-features and the same occurred for CART and NB for \"relativeLand\" set. Figure 7b compares the best setup from Figure 7a: \"simpleRelativeLand\", which uses both simple and relative landmarking meta-features, with the the baselines from Figure 3a, using\"simple\" and data complexity (\"complex\") meta-features, often explored in related studies (see Table 1).\n\nIn this figure, the x-axis shows the different meta-learners, while the y-axis shows their predictive performance assessed by the AUC averaged over 30 repetitions. The Wilcoxon paired-test with \u03b1 = 0.05 was applied to assess the statistical significance of these results. An upward green triangle ( ) at the x-axis identifies situations where the use of \"simpleRelativeLand\" was statistically better than using the baselines. In the same figure, the red downward triangles ( ) indicate when the use of baselines was significantly better. In the remaining cases, the predictive performance of the meta-models were equivalents.\n\nOverall, the meta-models induced with \"simpleRelativeLand\" meta-features were significantly better than those induced with baseline meta-features for most of the meta-learners: RF, SVM, kNN and CART obtained superior AUC values. Furthermore, the best meta-learner (RF) also significantly outperformed our previous results. The baselines produced the best meta-models for only two algorithms: NB and LR. For the GP algorithm, the different setups did not present any statistically significant difference.\n\n\nAnalysis of the predictions\n\nA more in-depth analysis of the meta-learner predictions can help to understand their behavior. Figure 8 shows the misclassifications of the meta-learners considering their best experimental setups. The top chart In the SVM HP tuning recommendation task, \"Defaults\" is defined as the positive class and \"Tuning\" as the negative class. Therefore, a FN is a wrong recommendation to perform HP tuning on SVMs, and False Positive (FP) is a wrong recommendation to use default HP values. While a reduction in FN can decrease the computational cost, a reduction in FP can improve predictive performance.\n\nAlgorithms following different learning biases present different prediction patterns and this can be observed in Figure 8. Usually, most meta-examples are correctly classified (a better performance than the baselines). Besides, the following patterns can be observed:\n\n\u2022 kNN and GP minimize the FN rate, correctly classifying most of the meta-examples as \"Defaults\".\n\nHowever, they misclassified many examples from the \"Tuning\" class, penalizing the overall performance of the recommender system;  A more balanced scenario is provided by the RF meta-models, which presented the best predictive performance. Although it was not the best algorithm for each class individually, it was the best when the two classes were considered.   Table 9 lists all the datasets misclassified by all the meta-learners as indicated in Figure 8a. Metaexamples with ids 17 (\"Defaults\") and 78 (\"Tuning\") were corrected labeled by the statistical meta-rule, and therefore the misclassification may have occurred due to the lack of the descriptive ability of metafeatures or noise in the meta-dataset. The other two meta-examples (36,97) were both labeled as \"Tuning\" but the statistical difference indicated is very small in terms of performance, and may indicate a limitation of the current meta-target rule criteria.\n\n\nProjecting performances at base-level\n\nThis section assesses the impact of the choices made by the meta-learners at the base-level. It also analyses and discusses the reduction of runtime when using the proposed meta-learning recommender system. Figure 9 shows the predictive performance of SVMs at the base-level using the method (\"Tuning' or \"Defaults') selected by the meta-learners to define their HP values. The best meta-learners identified in the previous sections were compared with three simple baselines: a model that always recommends HP tuning (Tuning), a model that always recommends the use of defaults (Defaults), and a model that provides random recommendations (Random). Overall, the approach always using default HPs (Defaults) is ranked last, followed by the Random baseline. Almost all meta-learners are significantly better than both and are equivalent to Tuning, which always performs HP tuning. In this figure, although the RF meta-model is considered the best, it was not ranked first. The first was the SVM meta-model. This occurred because it most often recommended the use of tuned settings, which was reflected in its performance at the base-level. With many datasets at the baselevel, it can be pointed out that the overall gain is diluted between them. Even so, the meta-learners could considerably reduce the computational costs related to tuning, maintaining a high predictive performance.\n\nBesides, it can be observed in Figure 9a that tuning SVM hyperparameters for just one dataset will take  days to finish all the 10 tuning repetitions (seeds) even paralleling the jobs in a high performance cluster.\n\nRegarding the meta-feature extraction, the same datasets will take at most 10 minutes, specially because of some mathematical operations used by Data Complexity (DC) meta-features. For most meta-features, the time taken to characterize a dataset is less than 30 seconds. Thus, during the prediction phase with the induced meta-model, the computational cost of extracting the characteristics of a new dataset is irrelevant compared to the computational cost of the tuning process. We think this is an important argument in favor of using our system, which is used in practical scenarios.\n\n\nA note on the generalization\n\nAlthough the main focus of the paper is to investigate the SVM hyperparameter tuning problem, we also conducted experiments for predicting the need for tuning Decision Trees (DTs). These experiments aim to provide more evidence that the proposed method can be generalized. Once the meta-knowledge is extracted, the system is able to induce meta-models to any supervised learning algorithm. In particular, we investigated the HP tuning of the J48 algorithm, a WEKA 20 implementation for the Quinlan's C4.5 DT induction algorithm [37], and one of the most popular ML algorithms. The tree models were induced using the RWeka 21 . We also expanded the meta-knowledge by performing additional experiments to cover the same datasets explored with SVMs. In total, we obtained results performing the HP tuning of the J48 algorithm in 165 OpenML datasets. The tuning processes followed the experimental setup described in Table 4 with some differences:\n\n\u2022 the J48 hyperparameter space has nine hyperparameters 22 ;\n\n\u2022 a budget size of 900 evaluations was adopted in the experiments with trees. It is greater than for SVMs because of the greater search space of J48;\n\n\u2022 the tuned hyperparameter results were compared with those obtained from the J48 RWeka/WEKA default settings. The predictive performance of the meta-learners considering different categories of meta-features are summarized in Figure 10a. The best results were obtained using the RF, SVM and GP meta-learners. They achieved their best predictive performances using preferably \"all\" the available meta-features, with AUC values between AUC = (0.67, 0.72). It may be due to the fact that predictions tend toward a specific class (Defaults) since these meta-datasets are imbalanced. Overall, the best meta-model was obtained by the SVM algorithm. However, when considering all the possible scenarios (different \u03b1 values), there was no statistical difference among the top ranked meta-learners: the RF, kNN, GP, SVM and LR algorithms (see Figure 10c). Furthermore, in general, the complete set of meta-features provided the best results for most algorithms. Figure 10b shows The meta-datasets for the J48 algorithm were generated based on HP tuning results obtained from 102 datasets reported in [26] 22 The J48 hyperparameter space is also presented in Appendix C. 23 In this paper, the \"hyperparameter profile\" term refers to how sensitive an algorithm may be to the HP tuning task.  missing in the chart. In general, when considering AUC values obtained in the original meta-dataset, improvements were obtained only for CART and kNN applying SMOTE. For the other algorithms, best metalearners were still induced without any additional process. Statistical comparisons highlight the performance of the SVM, RF and GP algorithms (see Figure 10d).\n\nWe also evaluated the potentiality of the Relative Landmarking (RL) meta-features in the J48 tuning recommendation problem. However, differently than reported in Section 5.4, they worsened most of the meta-models. Linearity is not a key aspect in the J48 tuning problem, which further reinforces the results obtained from SVMs (see Section 5.4).\n\nReproducing the RF analysis in the J48 tuning problem (see Section 5.3), the most important metafeature was the data complexity measure \"DC.f4\". This meta-feature describes the collective attribute efficiency in a dataset. The second was a simple meta-feature: \"SM.abs cor\", a metric that measures the linear relationship between two attributes. This value is averaged in all pairs of attributes in the dataset.\n\nThe top-3 is completed with another data complexity meta-feature: \"DC.f3\", which describes the maximum individual attribute efficiency. The two DC meta-features measure the discriminative power of the dataset's attributes, while the absolute correlation verifies if the information provided by attributes is not redundant.\n\nThese most important meta-features suggest that if a dataset has representative attributes, default HP values are robust to solve it. Otherwise, the J48 tuning is recommended.   However, all the meta-models have a lower average runtime compared with Random and Tuning baselines.\n\nMost of the meta-models are better ranked than baselines, but, overall, there are no statistical differences among the evaluated approaches (Figure 11b). Even so, it is important to highlight that meta-learners could also considerably reduce the computational cost related to tuning, keeping the predictive performance in the dataset collection.\n\n\nConclusions\n\nThis paper proposed and experimentally investigated a MtL framework to predict when to perform SVM HP tuning. To do this, 156 different datasets publicly available at OpenML were used. The predictive performances of SVM induced with HP tuning (by a simple RS) and with default HP values were compared and used to design a recommender system. The default values were provided by the e1071 R package), and by optimized common settings from [29]. Different experimental setups were analyzed with different sets of meta-features. The main findings are summarized next.\n\n\nTuning prediction\n\nThe main issue investigated in this paper was whether it is possible to accurately predict when HP tuning can improve the predictive performance of SVMs, when compared to the use of default HP values. If so, this can reduce the processing cost when applying SVMs to a new dataset. According to experimental results, using RF and SVM as meta-learners, this prediction is possible with a predictive accuracy of AUC=0.798.\n\nThree significance levels (\u03b1 = {0.01, 0.05, 0.10}) were used with the Wilcoxon test to define the metatarget, which indicates whether it is better to use HP tuning or default HP values. Different sets of metafeatures were evaluated, and RF meta-models using all the available meta-features obtained the best results, regardless the \u03b1 value considered. However, the complex set of meta-features resulted in high predictive performance for most of the investigated meta-learners. Different experimental setups were also evaluated at the meta-level, but improvements were observed, and in a few cases, only when SMOTE or meta-feature selection were used. Thus, the best setup was to use raw meta-data and meta-learners with default HP\n\nvalues.\n\nAn analysis of the RF meta-models show that most meta-features actively contributed to predictions.\n\nThis explains the decrease in performance when using meta-feature selection in most of the algorithms.\n\nAmong the 10 meta-features ranked as most important, there are meta-features from different sets. Each ranked meta-feature describes different characteristics of the problem, such as data imbalance, linearity, and complexity. This paper also investigated the hypothesis that the linear separability level could be an important meta-feature to be used by the recommender system. Meta-features based on relative landmarking were used to measure the linear separability degree. In the experiments performed, this meta-feature was shown to play an important role in the recommender system prediction. Three meta-learners had their best AUC performance values using a combination of simple and relative landmarking meta-features.\n\nUsing two different default HP settings maximized the number of default wins, reducing the imbalance rate at the meta-datasets. In addition to presenting the best predictive performance, RFs, by the frequency of meta-features in their trees, provided useful information regarding when default settings are suitable.\n\nWe also performed experiments for the J48 tuning recommendation problem aiming to show the ability of generalization of the MtL recommender system. Results showed that different to SVMs, where the linearity was important to recommend the use of default settings, the most important meta-features suggest that if a dataset has representative attributes, default settings are robust to solve it.\n\nIn fact, our extensive experiments suggest that the guideline depends on the algorithm used to induce the meta-model. If we use a white box algorithm, such as RF, we can use the meta-features in the root of the trees (and nodes close to the root) to explain when to tune. The high predictive performance of the RF algorithm indicates that the induced models were able to find a good hypothesis for situations where tuning is necessary, in both cases (for SVMs and J48).\n\n\nLinking findings with the literature\n\nTwo of the related studies in the literature [28,41] used meta-models based on decision trees to interpret their predictions. However, in the current results, CART trees were among the worst meta-learners considering all the experimental setups analyzed. Thus, in this study, the meta-analysis performed was based on the RF meta-learner, extracting the average of the Gini index from the meta-features provided by the inner RF meta-models.\n\nMeta-feature selection was also evaluated in [41]. The authors explored a Correlation-based feature selection (CFS) method and reported the \"nn\" meta-feature 24 as the most important. However, the results reported here were not improved by meta-feature selection. In fact, it decreased the performance of most meta-models, as shown in Figure 3(a). Meta-feature selection was also tried with filter methods, but the results were even worse than using SFS. For this reason, it was not reported in this study. In addition, \"nn\" meta-features did not appear among the top-20 most important meta-features computed by RF.\n\nOur experimental results show that using meta-features from different categories have improved the predictive performance of the meta-learners for different setups. The most important meta-features were \"SM.classes min\" and \"LM.stump sd\" 25 . In [28], which only used meta-features from simple and data complexity sets, \"SM.classes max\" and \"SM.attributes\" were reported as the most important metafeatures. The first describes the percentage of examples in the majority class. The second is the number of predictive attributes in a dataset. Although these studies disagree about the relative importance order of these meta-features, both extract information related to the same characteristics: data complexity and dimensionality.\n\nThe HP tuning investigated in [42] \"assumed that tuning is always necessary\", and therefore focused on the improvement prediction as a regression task. They obtained HP tuning results for less than half of the 24 The performance of 1-NN algorithm. See tables A.10 and A.11 in Appendix Appendix A. 25 This is shown in Figure 5 in Subsection 5.3. datasets (111/229) in the base-level when dealing with SVMs. In addition, their meta-models were not able to predict the HP improvement for SVMs, not providing any valid conclusion about the problem.\n\n\nMain difficulties\n\nDuring the experiments, there were several difficulties to generate the meta-knowledge. The process itself is computationally expensive, since a lot of tuning tasks must be run and evaluated in a wide range of classification tasks. Initially, a larger number of datasets were selected, but some of them were extremely expensive computationally speaking for either HP tuning or the extraction of meta-features. A walltime of 100 hours was considered to remove high-cost datasets.\n\nThe class imbalance at the meta-level was another problem faced in the experiments. To deal with this problem, the optimized default HP settings [29] were added to the meta-dataset, increasing the number of meta-examples in the default meta-target. Besides the addition of relative landmarking set, some metaexamples were never correctly classified. This points out the need to define specific meta-features for some MtL problems.\n\n\nFuture work\n\nSome findings from this study also open up future research directions. The proposed MtL recommender system could be extended to different ML algorithms, such as neural networks, another decision tree induction algorithms and ensemble-based techniques. It could also be used to support HP tuning decision in different tasks, such as pre-processing, regression and clustering. It could even be used to define whether to tune HP for more than one task, in a pipeline or simultaneously.\n\nIt would also be a promising direction to investigate the need of new meta-features to characterize data when dealing with data quality problems, for instance imbalancing measures, due to their influence in the quality of the induced meta-models. Besides, a multicriteria objective function could replace the current meta-label rule, weighing predictive performance, memory, and runtime. Another possibility would be to explore the use of ensembles as meta-models, given the complementary behavior of some of the algorithms studied here as meta-learners.\n\nThe code used in this study is publicly available, easily extendable and may be adapted to cover several other ML algorithms. The same may be said of the analysis, also available for reproducibility. All the experimental results generated are also available at OpenML correspondent studies web pages, from which they can be integrated and reused in different MtL systems. This framework is expected to be integrated to OpenML, so that the scientific community can use it.\n\nAppendix C. J48 hyperparameter space and meta-datasets used in experiments from Section 5.8  SMBO Sequential Model-based Optimization.\n\nSMOTE Synthetic Minority Over-sampling Technique.\n\nSpCorr Spearman Correlation.\n\nST Statistical.\n\nSVM Support Vector Machine.\n\nTAF Transfer Acquisition Function.\n\nTS Tabu Search.\n\nFigure 1\n1shows graphically the general framework, linking two-level learning steps: the base level, where the hyperparameter tuning process is performed for different datasets (D); and the meta level, where the meta-features (M) from these datasets are extracted, the meta-examples are labeled according to tuning experiments (\u2126, P) and the recommendation to a new unseen dataset occurs (d i / \u2208 D). Further subsections will describe in detail each one of its components.\n\nFigure 1\n1Figure 1: Meta-learning system to predict whether hyperparameter tuning is required (Adapted from [28]). At the figure, \"mf\"\n\n\nremoved; the logical attributes were converted into values \u2208 {0, 1}; missing values were imputed by the median for numerical attributes, and a new category for categorical ones; all categorical attributes were converted into the 1-N encoding; all attributes were normalized with \u00b5 = 0 and \u03c3 = 1. The OpenML [9] 8 package was used to obtain and select datasets from the OpenML website, while functions from the mlr [4] 9\n\nFigure 2 :\n2Average balanced per class accuracies comparing LibSVM default (libsvm.defaults), Multiple optimized default hyperparameter settings (multiple.defaults) and Random Search tuning technique (random.search) when defining the metatarget of each meta-example.\n\nFigure 2\n2illustrates the benefits of using multiple default settings: LibSVM and optimized default values. In this figure, the x-axis identifies datasets by their OpenML ids, listing them decreasingly by the balanced per class accuracy performances (y-axis) obtained using LibSVM defaults hyperparameter values. This figure shows three different curves: \u2022 libsvm.defaults: a black dotted line representing the averaged performance values obtained using LibSVM default hyperparameter values. It represents the choice of a user using LibSVM defaults; \u2022 random.search: a green line representing the averaged performance values obtained using the Random Search (RS) technique for tuning. It represents the choice of always tuning SVMs hyperparameters; and \u2022 multiple.defaults: a red line representing the best choice considering the LibSVM and optimized defaults hyperparameter values. It represents our approach, exploring multiple default values.\n\n(\nSVMs), Classification and Regression Tree (CART), Random Forest (RF), k-Nearest Neighbors (kNN), Na\u00efve-Bayes (NB) Logistic Regression (LR) and Gaussian Processs (GPs). These algorithms were chosen because they follow different learning paradigms with different learning biases. All seven algorithms were\n\n4. 7 .\n7Repositories for the coding used in this study Details of the base-level tuning and meta-learning experiments are publicly available in the OpenML Studies (ids 52 and 58, respectively). In the corresponding pages, all datasets, classification tasks, algorithms/flows and results are listed and available for reproducibility. The code used for the HP tuning process (HpTuning), extracting meta-features (MfeatExtractor), running meta-learning (mtlSuite), and performing the graphical analyses (MtlAnalysis) are hosted at GitHub. All of these repositories are also listed in\n\nFigure 3\n3summarizes the predictive performance of different meta-learners for three different sets of meta-features, namely: all, complex and simple. The former has all 80 available meta-features, the complex set contains only 14 data complexity measures as meta-features and the latter consists of 17 simple and general meta-features.\n\n\u03b1\n= 0.05 was applied to assess the statistical significance of the predictive performance differences obtained by the meta-models with all meta-features, when compared to the second best approach.An upward green triangle ( ) at the x-axis identifies situations where using all the meta-features were statistically better. On the other hand, red downward triangles ( ) show results where one of the alternative approaches was significantly better. In the remaining cases, the predictive performance of the meta-models were equivalents.\n\n\nMeta-learners average AUC performance on SVMs meta-datasets. The black dotted line at AU C = 0.5 represents the predictive performance of ZeroR and Random meta-models. of the AUC values of the induced meta-model according to the Friedman-Nemenyi test (\u03b1 = 0.05). Groups of algorithms that are not significantly different are connected.\n\nFigure 3 :\n3AUC performance values obtained by all meta-learners considering different meta-features' categories. Results are averaged considering 30 repetitions. those obtained by other approaches at \u03b1 = {0.90, 0.95}. When \u03b1 = 0.99, the RF meta-learner using all the meta-features also generated a model with AUC \u2248 0.8. When the value of \u03b1 in the meta-label rule is reduced, predictive performances using data complexity and all the available meta-features tend to show similar distributions. The meta-learners obtained their best AUC values with the highest assumption (\u03b1 = 0.99). Overall, varying the \u03b1 value did not substantially change the predictive performance of the evaluated algorithms. In fact, few meta-examples had their metatargets modified by the meta-rule with different values of \u03b1. Thus, the predictions in the different scenarios are mostly the same and the performances remained similar. Regarding predictive performance, RF, SVM, GP and kNN induced accurate meta-models for the three meta-dataset variations. The AUC value varied in the interval {0.70, 0.80}. Even the LR, depending on the meta-features used to represent the recommendation problem, achieved reasonable AUC values. For comparison purposes, it is important to mention that both Random and ZeroR 18 baselines obtained AUC of 0.5 in all these meta-datasets 19 .\n\nFigure 3b\n3bpresents the resultant Critical Difference (CD) diagram. Algorithms are connected when there are no significant differences between them. The top-ranked meta-learner was the RF with an average rank of 1.0, followed by GP (2.3), SVM (3.2) and kNN (3.6). They did not present statistically differences among them, but mostly did when compared with simpler algorithms: CART (5.4), LR (5.7) and NB(6.5). Even not being statistically better than all the other choices, the RF was always ranked at the top regardless of the meta-dataset and meta-features.\n\nFigure 3\n3summarizes the main aspects of these experimental results. The top figure shows the average AUC values for each experimental setup considering all the meta-learners and the \u03b1 levels. The NB and LR meta-learners do not have any tunable HP. Thus, their results in this figure are missing for the tuned setups (with and without SMOTE). Similarly to\n\n\nof the AUC values of the induced meta-model according to the Friedman-Nemenyi test (\u03b1 = 0.05). Groups of algorithms that are not significantly different are connected.\n\nFigure 4 :\n4AUC performance values obtained by all meta-learners considering different experimental setups. Results are averaged over 30 repetitions.\n\nFigure 5 :\n5Average meta-features relative importance obtained from RF meta-models. The names of the meta-features in the x-axis follow the acronyms presented in Tables A.10 and A.11 in Appendix A.\n\n\nt2\": these are data complexity meta-features. While the first measures the minimum of an error function for a linear classifier, the second measures the average number of points per dimension. These features are related with the class separability (l1), and the geometry of the problem's dimension (t2); \u2022 \"SM.dimension\": this is a simple meta-feature that measures the relation between the number of examples and attributes in a dataset;\n\n\ndifferences between SVM and a linear classifier in all the base-level datasets.(b) Average relative importance of the meta-features obtained from RF meta-models. The names of the meta-features in the x-axis follow the acronyms presented in Tables A.10 and A.11 in Appendix A.\n\nFigure 6 :\n6Linearity hypothesis results considering relative landmarking meta-features.\n\nFigure 7\n7presents a comparison between the main experimental setups considering the addition of the relative landmarking (relativeLand) meta-features. The left chart of figure 7a shows AUC performance values obtained for each of the original setups, while the chart on the right presents setup performances when relative landmarking meta-features were included. This figure shows that the use of relative landmarking Average AUC values when considering relative landmarking meta-features with all the other meta-features' categories.\n\n\nAverage AUC values for the best overall experimental setup with the simple and the data complexity baselines presented in Section 5.1.\n\nFigure 7 :\n7Evaluating the previous experimental setups adding relative landmarking meta-features. The results are the average of 30 runs.\n\n(\nFig. 8a) shows all the individual predictions, with the x-axis listing all the meta-examples and y-axis the meta-learners. In this figure, \"Defaults\" labels are shown in black and \"Tuning\" labels in gray. The top line in the y-axis, \"Truth\" shows the truth labels of the meta-examples, which are ordered according to their truth labels. The bottom line (\"*\") shows red points for meta-examples misclassified by all meta-learners.\n\nFigure 8 :\n8Meta-learners' predictions considering the experimental setups which obtained the best AUC values. \u2022 SVM, CART and LR minimized the FP rate, correctly classifying most of the meta-examples requiring tuning. However, they tended to classify the meta-examples in the majority class;\n\n9 :\n9Misclassified datasets by all the meta-learners. For each dataset it is shown: the meta-example number (Nro); the OpenML dataset name (Name) and id (id); the number of attributes (D), examples (N) and classes (C); the proportion between the number of examples from minority and majority classes (P); the performance values obtained by defaults (Def) and tuned (Tun) HP settings assessed by BAC; and the truth label (Label). 5620 10 0.97 0.99 (0.01) 0.99 (0.01) Tuning\n\nFigure\n9a shows a scatter plot with the projected BAC performance and runtime value averaged in all the base-level datasets. Performing always the HP tuning had the highest average BAC value but was also the most expensive approach. On the other hand, always using default HP values is the fastest approach, but with the lowest average BAC value. The proposed meta-models are above Random and Defaults baselines, performing close to the Tuning baseline but with lower average runtime costs.The Friedman test, with a significance level of \u03b1 = 0.05, was also used to assess the statistical significance of the base-level predictions. The null hypothesis is that all the meta-learners and baselines are equivalent regarding the average predictive BAC performance. When the null hypothesis is rejected, the Nemenyi posthoc test is applied to indicate when two different techniques are significantly different.Figure 9bpresents the Critical Difference (CD) diagram. Techniques are connected when there is no significant differences between them.\n\n\non average two days. The most costly datasets (with a high number of features or examples) took almost 10 Average BAC and runtime for the SVM base-level data. ) CD diagram comparing the BAC values of the meta-learners at the base-level according to the Friedman-Nemenyi test (\u03b1 = 0.05).\n\nFigure 9 :\n9Performance of the meta-learners projected into the SVM hyperparameter tuning problem (base-level).\n\n\n) CD diagram comparing different meta-learners in different experimental setups).\n\nFigure 10 :\n10Meta-learners average AUC results in the J48 meta-dataset labelled with alpha = 0.05, and CD diagrams comparing meta-learners according to the Friedman-Nemenyi test (\u03b1 = 0.05). Results are averaged in 30 runs.\n\n\nAverage BAC and runtime for the J48 base-level data. ) CD diagram comparing the BAC values of the meta-learners at the base-level according to the Friedman-Nemenyi test (\u03b1 = 0.05).\n\nFigure 11 :\n11Performance of the Meta-learners projected in the J48 hyperparameter tuning problem (base-level).\n\nFigure 11 shows\n11J48 meta-level predictions projected overall base-level datasets. Mostly, but not all of the meta-examples are labeled with \"Defaults\". The induced meta-models depicted in Figure 11a are above the \"Defaults\" baseline, but relatively close to the Random and Tuning ones. The average BAC values of all the approaches are very close, even considering all the baselines. This can be noted by the scale on the y-axis. It is explained by the small improvements obtained at the base-level tuning processes; they were relatively small if compared with those obtained with SVMs.\n\nTable 1 :\n1Summary of related studies applying to MtL to SVMs. Fields without information in the related study are marked with a hyphen.Reference \n\nYear \n\nMeta-learning \n\nSVMs \n\nTuning \n\nMeta \n\nNumber of \n\nDatasets' \n\nEvaluation Evaluation \n\nParameters \n\nTechniques \n\nLearner \n\nDatasets \n\nSource \n\nProcedure \n\nMeasure \n\nk \u03b3 \n\nC \n\nd \n\nSoares et al. [45] \n\n2004 Recommends HP settings \n\n\u2022 \n\nGS \n\nkNN \n\n42 \n\nUCI, METAL \n\n10-CV \n\nNMSE \n\nSoares & Brazdil [44] \n\n2006 Recommends HP settings \n\n\u2022 \n\nGS \n\nkNN \n\n42 \n\nUCI, METAL \n\n10-CV \n\nNMSE \n\nAli & Smith-Miles [1] \n\n2006 Recommends HP settings \n\n\n\nTable 2 :\n2The most related studies to our current approach. In the Goal prediction column, \"improv.\" means improvement prediction. In the Task column, \"class\" denotes classification, while \"regr\" denotes regression.Study \n\nGoal \nTuning setup Labeling \nTarget \nMeta \n\nprediction Task (base-level) \nrule \nalgorithm features \n\nimprov. \nclass Not detailed \n\nSimple \n\nRidd & \nAccuracy \nCASH \nStatistical \n\nGiraud-Carrier [41] \nthreshold \n(20 algs.) Landmarkers \n\nModel-based \n\nclass \n\nNested-CVs \n\nSVM \n\nMantovani \ntuning \nholdout (inner) Confidence \nSimple \n\net al. [28] \nnecessity \n10-CV (outer) \ninterval \nData complexity \n\nBAC (fitness) \n\nimprov. \nregr \n\nCART \nSimple \n\nSanders & \n10-CV (single) \nConfidence \nMLP \nStatistical \n\nGiraud-Carrier [42] \nAUC (fitness) \ninterval \nSVM \nLandmarkers \n\nModel-based \n\nCurrent study \nclass \n\nNested-CVs \n\ntuning \n3-fold (inner) \nWilcoxon \nSVM \nMany \n\nnecessity \n10-fold (outer) \ntest \nJ48 \n(see Section 4.4) \n\nBAC (fitness) \n\n\n\nTable 3 :\n3SVM hyperparameter space used in experiments. The following was shown for each hyperparameter:its symbol, name, type, range/options, scale transformation applied, default values and whether it was tuned.Symbol \nHyperparameter \nType \nRange/Options \nScale \nDefault Tuned \n\nk \nkernel \ncategorical \n{RBF} \n-\nRBF \nx \n\nC \ncost \nreal \n[2 \u221215 , 2 15 ] \nlog \n1 \n\n\u03b3 \nwidth of the kernel \nreal \n[2 \u221215 , 2 15 ] \nlog \n\n1 \n\n/ N \n\n\n\nTable 4 :\n4Hyperparameter base level learning experimental setup.Element \nMethod \nR package \n\nTuning techniques \nRandom Search \nmlr \n\nBase Algorithm \nSupport Vector Machines \ne1071 \n\nOuter resampling \n10-fold cross-validation \nmlr \n\nInner resampling \n3-fold cross-validation \nmlr \n\nOptimized measure {Balanced per class accuracy} mlr \n\nEvaluation measure \n\n{Balanced per class accuracy, \nmlr \nOptimization paths } \n\nBudget \n300 iterations \n\nRepetitions \n\n10 times with different seeds \n-\n\nseeds = {1, . . . , 10} \n-\n\nBaselines \n\nLibSVM defaults \ne1071 \n\noptimized defaults \n\n\n\nTable 5 :\n5Meta-feature category used in experiments.Acronym Category \n#N Description \n\nSM \nSimple \n17 Simple measures \n\nST \nStatistical \n7 Statistical measures \n\nIN \nInformation-theoretic \n8 Information theory measures \n\nMB \nModel-based (trees) \n17 Features extracted from decision tree models \n\nLM \nLandmarking \n8 The performance of some ML algorithms \n\nDC \nData Complexity \n14 Measures that analyze the complexity of a problem \n\nCN \nComplex Networks \n9 Measures based on complex networks \n\nTotal \n80 \n\n\n\nTable 6 :\n6Meta-datasets generated from experiments with SVMs.Meta-dataset \n\u03b1 \n\nMeta \nMeta \nClass Distribution \n\nexamples features Tuning \nDefault \n\nSVM 90 \n0.10 \n156 \n80 \n102 \n54 \n\nSVM 95 \n0.05 \n156 \n80 \n98 \n58 \n\nSVM 99 \n0.01 \n156 \n80 \n94 \n62 \n\n\n\nTable 7 :\n7Meta-learning experimental setup.Element \nMethod \nR package \n\nMeta-learner \n\nSupport Vector Machines (SVMs) \ne1071 \n\nClassification and Regression Tree (CART) rpart \n\nRandom Forest (RF) \nrandomForest \n\nk-Nearest Neighbors (kNN) \nkknn \n\nNa\u00efve-Bayes (NB) \ne1071 \n\nLogistic Regression (LR) \ngbm \n\nGaussian Processs (GPs) \nkernlab \n\n\n\nTable 8 :\n8Repositories with tools developed by the authors and results generated by experiments.Task/Experiment \nWebsite/Repository \n\nHyperparameter tuning code \nhttps://github.com/rgmantovani/HpTuning \n\nHyperparameter tuning results https://www.openml.org/s/52 \n\nMeta-feature extraction \nhttps://github.com/rgmantovani/MfeatExtractor \n\nMeta-learning code \nhttps://github.com/rgmantovani/mtlSuite \n\nMeta-learning results \nhttps://www.openml.org/s/58 \n\nGraphical Analysis \nhttps://github.com/rgmantovani/MtlAnalysis \n\n\n\nTable\n\n\nTable C .\nC14 in Appendix C presents the main characteristics of the meta-datasets generated with J48 tuning experiments. Class distribution columns (Tuning and Default) show values which indicate a different hyperparameter profile 23 compared to that observed in experiments with SVMs: most of the meta-examples are labelled as \"Default\", i.e., tuning did not statistically improve the algorithm performance in two thirds of the datasets. Here, we present results just on the meta-dataset using \u03b1 = 0.05 for the statistical labeling rule. However, results obtained with different \u03b1 values were quite similar.\n\n\nthe average AUC values considering different experimental setups. The NB and LR algorithms do not have any tunable hyperparameters. Consequently, their results for \"tuned\" setups are 20 http://weka.sourceforge.net/doc.dev/weka/classifiers/trees/J48.html 21 https://cran.r-project.org/web/packages/RWeka/index.html package.\n\nTable C .\nC13: J48 hyperparameter space explored in experiments. The nomenclature is based on the RWeka package.Table adaptedfrom[26].Symbol \nHyperparameter \nRange \nType \nDefault \nConditions \n\nC \npruning confidence \n(0.001, 0.5) \nreal \n0.25 \nR = False \n\nM \nminimum number of instances in a leaf \n[1, 50] \ninteger \n2 \n-\n\nN \nnumber of folds for reduced \n[2, 10] \ninteger \n3 \nR = True \nerror pruning \n\nO \ndo not collapse the tree \n{False, True} \nlogical \nFalse \n-\n\nR \nuse reduced error pruning \n{False, True} \nlogical \nFalse \n-\n\nB \nuse binary splits only \n{False, True} \nlogical \nFalse \n-\n\nS \ndo not perform subtree raising \n{False, True} \nlogical \nFalse \n-\n\nA \nLaplace smoothing for predicted \n{False, True} \nlogical \nFalse \n-\n\nprobabilities \n\nJ \ndo not use MDL correction for \n{False, True} \nlogical \nFalse \n-\n\ninfo gain on numeric attributes \n\n\n\nTable C .\nC14: Meta-datasets generated for J48 experiments.SM Simple.Meta-dataset \n\u03b1 \n\nMeta \nMeta \nClass Distribution \n\nexamples features Tuning \nDefault \n\nJ48 90 \n0.10 \n165 \n80 \n63 \n102 \n\nJ48 95 \n0.05 \n165 \n80 \n57 \n108 \n\nJ48 99 \n0.01 \n165 \n80 \n52 \n113 \n\nMore details about dataset versions can be found in the OpenML paper[47] and documentation page: https://docs. openml.org/#data.\nThese performance values are assessed by BAC using a nested-CV resampling method.\nThis classifier simply predicts the majority class.19 The AUC performance values were assessed using the implementations provided by the mlr R package.\nAcknowledgmentsThe authors would like to thank CAPES and CNPq (Brazilian Agencies) for their financial support, specially for grants #2012/23114-9, #2015/03986-0 and #2018/14819-5 from the S\u00e3o Paulo Research Foundation (FAPESP).Appendix A. List of Meta-features used in experimentsTable A.10: Meta-features used in experiments -part 1. For each meta-features it is shown: its type, acronym and description.Extended from[15].Type Acronym DescriptionSimple (SM)Appendix D. List of abbreviations used in the paper Acc Accuracy.AT Active Testing.AUC Area Under the ROC curve.AutoML Automated Machine Learning.BAC Balanced per class Accuracy.CART Classification and Regression Tree.CASH Combined Algorithm Selection and Hyperparameter Optimization.CD Critical Difference.CFS Correlation-based feature selection.CN Complex Network.CV Cross-validation.DC Data Complexity.DS Decision Stump.DT Decision Tree.EDA Estimation of Distribution Algorithm.FN False Negative.FP False Positive.GA Genetic Algorithm.GP Gaussian Process.GS Grid Search.HP Hyperparameter.\nA meta-learning approach to automatic kernel selection for support vector machines. S Ali, K A Smith-Miles, Neurocomputing. 7013Ali, S., Smith-Miles, K.A.. A meta-learning approach to automatic kernel selection for support vector machines. Neurocomputing 2006;70(13):173-186.\n\nA higher-order approach to meta-learning. H Bensusan, C Giraud-Carrier, C Kennedy, Proceedings of the ECML -Workshop on Meta-Learning: Building Automatic Advice Strategies for Model Selection and Method Combination. the ECML -Workshop on Meta-Learning: Building Automatic Advice Strategies for Model Selection and Method CombinationBensusan, H., Giraud-Carrier, C., Kennedy, C.. A higher-order approach to meta-learning. In: Proceedings of the ECML -Workshop on Meta-Learning: Building Automatic Advice Strategies for Model Selection and Method Combination. 2000. p. 109-118.\n\nRandom search for hyper-parameter optimization. J Bergstra, Y Bengio, J Mach Learn Res. 13Bergstra, J., Bengio, Y.. Random search for hyper-parameter optimization. J Mach Learn Res 2012;13:281-305.\n\nmlr: Machine learning in r. B Bischl, M Lang, L Kotthoff, J Schiffner, J Richter, E Studerus, G Casalicchio, Z M Jones, Journal of Machine Learning Research. 17170Bischl, B., Lang, M., Kotthoff, L., Schiffner, J., Richter, J., Studerus, E., Casalicchio, G., Jones, Z.M.. mlr: Machine learning in r. Journal of Machine Learning Research 2016;17(170):1-5.\n\nMetalearning: Applications to Data Mining. P Brazdil, C Giraud-Carrier, C Soares, R Vilalta, Springer Verlag2nd edBrazdil, P., Giraud-Carrier, C., Soares, C., Vilalta, R.. Metalearning: Applications to Data Mining. 2nd ed. Springer Verlag, 2009.\n\nAnalysis of results. P B Brazdil, R J Henery, D Michie, D J Spiegelhalter, C C Taylor, J Campbell, Machine learning, neural and statistical classification. Ellis HorwoodBrazdil, P.B., Henery, R.J.. Analysis of results. In: Michie, D., Spiegelhalter, D.J., Taylor, C.C., Campbell, J., editors. Machine learning, neural and statistical classification. Ellis Horwood; 1994. p. 175-212.\n\nRandom forests. L Breiman, Machine Learning. 451Breiman, L.. Random forests. Machine Learning 2001;45(1):5-32.\n\nThe balanced accuracy and its posterior distribution. K H Brodersen, C S Ong, K E Stephan, J M Buhmann, Proceedings of the 2010 20th International Conference on Pattern Recognition. the 2010 20th International Conference on Pattern RecognitionBrodersen, K.H., Ong, C.S., Stephan, K.E., Buhmann, J.M.. The balanced accuracy and its posterior distribution. In: Proceedings of the 2010 20th International Conference on Pattern Recognition. IEEE Computer Society; 2010. p. 3121-3124.\n\nOpenML: An R package to connect to the machine learning platform OpenML. G Casalicchio, J Bossek, M Lang, D Kirchhoff, P Kerschke, B Hofner, H Seibold, J Vanschoren, B Bischl, Computational Statistics. Casalicchio, G., Bossek, J., Lang, M., Kirchhoff, D., Kerschke, P., Hofner, B., Seibold, H., Vanschoren, J., Bischl, B.. OpenML: An R package to connect to the machine learning platform OpenML. Computational Statistics 2017;:1-15.\n\nLIBSVM: A library for support vector machines. C C Chang, C J Lin, ACM Transactions on Intelligent Systems and Technology. 227Chang, C.C., Lin, C.J.. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology 2011;2:27:1-27:27.\n\nSMOTE: synthetic minority over-sampling technique. N V Chawla, K W Bowyer, L O Hall, W P Kegelmeyer, J Artif Int Res. 161Chawla, N.V., Bowyer, K.W., Hall, L.O., Kegelmeyer, W.P.. SMOTE: synthetic minority over-sampling technique. J Artif Int Res 2002;16(1):321-357.\n\nStatistical comparisons of classifiers over multiple data sets. J Dem\u0161ar, The Journal of Machine Learning Research. 7Dem\u0161ar, J.. Statistical comparisons of classifiers over multiple data sets. The Journal of Machine Learning Research 2006;7:1-30.\n\nEfficient benchmarking of algorithm configurators via model-based surrogates. K Eggensperger, M Lindauer, H H Hoos, F Hutter, K Leyton-Brown, Machine Learning. 1071Eggensperger, K., Lindauer, M., Hoos, H.H., Hutter, F., Leyton-Brown, K.. Efficient benchmarking of algorithm configurators via model-based surrogates. Machine Learning 2018;107(1):15-41.\n\nEfficient and robust automated machine learning. M Feurer, A Klein, K Eggensperger, J Springenberg, M Blum, F Hutter, C Cortes, N D Lawrence, D D Lee, M Sugiyama, R Garnett, Advances in Neural Information Processing Systems 28. Curran Associates, IncFeurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.. Efficient and robust automated machine learning. In: Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., Garnett, R., editors. Advances in Neural Information Processing Systems 28. Curran Associates, Inc.; 2015. p. 2944-2952.\n\nNoise detection in the meta-learning level. L P F Garcia, A C P L F De Carvalho, A C Lorena, Neurocomputing. 176Garcia, L.P.F., de Carvalho, A.C.P.L.F., Lorena, A.C.. Noise detection in the meta-learning level. Neurocomputing 2016;176:14-25.\n\nCombining meta-learning and search techniques to select parameters for support vector machines. T A F Gomes, R B C Prud\u00eancio, C Soares, A L D Rossi, C P L F Nd Andr\u00e9, Carvalho, Neurocomputing. 751Gomes, T.A.F., Prud\u00eancio, R.B.C., Soares, C., Rossi, A.L.D., nd Andr\u00e9 C. P. L. F. Carvalho, . Combining meta-learning and search techniques to select parameters for support vector machines. Neurocomputing 2012;75(1):3-13.\n\nComplexity measures of supervised classification problems. Pattern Analysis and Machine Intelligence. T K Ho, M Basu, IEEE Transactions on. 243Ho, T.K., Basu, M.. Complexity measures of supervised classification problems. Pattern Analysis and Machine Intelli- gence, IEEE Transactions on 2002;24(3):289-300.\n\nA comparative study on large scale kernelized support vector machines. D Horn, A Demircioglu, B Bischl, T Glasmachers, C Weihs, Advances in Data Analysis and Classification. Horn, D., Demircioglu, A., Bischl, B., Glasmachers, T., Weihs, C.. A comparative study on large scale kernelized support vector machines. Advances in Data Analysis and Classification 2016;:1-17.\n\nA Practical Guide to Support Vector Classification. C W Hsu, C C Chang, C J Lin, Department of Computer Science -National Taiwan UniversityHsu, C.W., Chang, C.C., Lin, C.J.. A Practical Guide to Support Vector Classification. Department of Computer Science -National Taiwan University;\n\nParamils: an automatic algorithm configuration framework. F Hutter, H Hoos, K Leyton-Brown, T St\u00fctzle, Journal of Artificial Intelligence Research. 36Hutter, F., Hoos, H., Leyton-Brown, K., St\u00fctzle, T.. Paramils: an automatic algorithm configuration framework. Journal of Artificial Intelligence Research 2009;(36):267-306.\n\nAuto-weka 2.0: Automatic model selection and hyperparameter optimization in weka. L Kotthoff, C Thornton, H H Hoos, F Hutter, K Leyton-Brown, Journal of Machine Learning Research. 17Kotthoff, L., Thornton, C., Hoos, H.H., Hutter, F., Leyton-Brown, K.. Auto-weka 2.0: Automatic model selection and hyperparameter optimization in weka. Journal of Machine Learning Research 2016;17:1-5.\n\nCross-validation pitfalls when selecting and assessing regression and classification models. D Krstajic, L J Buturovic, D E Leahy, S Thomas, Journal of cheminformatics. 6110Krstajic, D., Buturovic, L.J., Leahy, D.E., Thomas, S.. Cross-validation pitfalls when selecting and assessing regression and classification models. Journal of cheminformatics 2014;6(1):10+.\n\nSelecting classification algorithms with active testing. R Leite, P Brazdil, J Vanschoren, Proceedings of the 2012 Conference on Machine Learning and Data Mining. the 2012 Conference on Machine Learning and Data MiningLeite, R., Brazdil, P., Vanschoren, J.. Selecting classification algorithms with active testing. In: Proceedings of the 2012 Conference on Machine Learning and Data Mining (MLDM 2012). 2012. p. 117-131.\n\nThe irace package: Iterated racing for automatic algorithm configuration. M L\u00f3pez-Ib\u00e1\u00f1ez, J Dubois-Lacoste, L P C\u00e1ceres, M Birattari, T St\u00fctzle, Operations Research Perspectives. 3L\u00f3pez-Ib\u00e1\u00f1ez, M., Dubois-Lacoste, J., C\u00e1ceres, L.P., Birattari, M., St\u00fctzle, T.. The irace package: Iterated racing for automatic algorithm configuration. Operations Research Perspectives 2016;3:43 -58.\n\nData complexity meta-features for regression problems. A C Lorena, A I Maciel, P B C De Miranda, I G Costa, R B C Prud\u00eancio, Machine Learning. 1071Lorena, A.C., Maciel, A.I., de Miranda, P.B.C., Costa, I.G., Prud\u00eancio, R.B.C.. Data complexity meta-features for regression problems. Machine Learning 2018;107(1):209-246.\n\nHyper-parameter tuning of a decision tree induction algorithm. R G Mantovani, T Horv\u00e1th, R Cerri, J Vanschoren, A C P L F De Carvalho, 10.1109/BRACIS.2016.018doi:10.1109/ BRACIS.2016.0185th Brazilian Conference on Intelligent Systems, BRACIS 2016. Recife, BrazilIEEE Computer SocietyMantovani, R.G., Horv\u00e1th, T., Cerri, R., Vanschoren, J., de Carvalho, A.C.P.L.F.. Hyper-parameter tuning of a decision tree induction algorithm. In: 5th Brazilian Conference on Intelligent Systems, BRACIS 2016, Recife, Brazil, October 9- 12, 2016. IEEE Computer Society; 2016. p. 37-42. URL: http://dx.doi.org/10.1109/BRACIS.2016.018. doi:10.1109/ BRACIS.2016.018.\n\nEffectiveness of random search in SVM hyper-parameter tuning. R G Mantovani, A L D Rossi, J Vanschoren, B Bischl, A C P L F De Carvalho, 2015 International Joint Conference on Neural Networks. Killarney, IrelandIEEEMantovani, R.G., Rossi, A.L.D., Vanschoren, J., Bischl, B., de Carvalho, A.C.P.L.F.. Effectiveness of random search in SVM hyper-parameter tuning. In: 2015 International Joint Conference on Neural Networks, IJCNN 2015, Killarney, Ireland, July 12-17, 2015. IEEE; 2015. p. 1-8.\n\nTo tune or not to tune: Recommending when to adjust SVM hyper-parameters via meta-learning. R G Mantovani, A L D Rossi, J Vanschoren, B Bischl, A C P L F Carvalho, 2015 International Joint Conference on Neural Networks. Killarney, IrelandIEEEMantovani, R.G., Rossi, A.L.D., Vanschoren, J., Bischl, B., Carvalho, A.C.P.L.F.. To tune or not to tune: Recom- mending when to adjust SVM hyper-parameters via meta-learning. In: 2015 International Joint Conference on Neural Networks, IJCNN 2015, Killarney, Ireland, July 12-17, 2015. IEEE; 2015. p. 1-8.\n\n. R G Mantovani, A L D Rossi, J Vanschoren, A C P L F Carvalho, Mantovani, R.G., Rossi, A.L.D., Vanschoren, J., Carvalho, A.C.P.L.F..\n\nCEUR-WS.org. J Vanschoren, P Brazdil, C G Giraud-Carrier, L Kotthoff, Proceedings of the 2015 International Workshop on Meta-Learning and Algorithm Selection co-located with European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases 2015 (ECMLPKDD 2015). the 2015 International Workshop on Meta-Learning and Algorithm Selection co-located with European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases 2015 (ECMLPKDD 2015)Porto, Portugal1455Meta-learning recommendation of default hyper-parameter values for svms in classification tasksMeta-learning recommendation of default hyper-parameter values for svms in classification tasks. In: Vanschoren, J., Brazdil, P., Giraud-Carrier, C.G., Kot- thoff, L., editors. Proceedings of the 2015 International Workshop on Meta-Learning and Algorithm Selection co-located with European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases 2015 (ECMLPKDD 2015), Porto, Portugal, September 7th, 2015. CEUR-WS.org; volume 1455 of CEUR Workshop Proceedings;\n\nActive testing for SVM parameter selection. P Miranda, R Prud\u00eancio, The 2013 International Joint Conference on. Neural Networks (IJCNN)Miranda, P., Prud\u00eancio, R.. Active testing for SVM parameter selection. In: Neural Networks (IJCNN), The 2013 International Joint Conference on. 2013. p. 1-8.\n\nFine-tuning of support vector machine parameters using racing algorithms. P Miranda, R Silva, R Prud\u00eancio, Proceedings of the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine LearningMiranda, P., Silva, R., Prud\u00eancio, R.. Fine-tuning of support vector machine parameters using racing algorithms. In: Proceedings of the 22nd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2014. 2014. p. 325-330.\n\nAn experimental study of the combination of meta-learning with particle swarm algorithms for svm parameter selection. P B C Miranda, R B C Prud\u00eancio, A C P L F Carvalho, C Soares, Lecture Notes in Computer Science. 7335LNCS. PART 3Miranda, P.B.C., Prud\u00eancio, R.B.C., Carvalho, A.C.P.L.F., Soares, C.. An experimental study of the combination of meta-learning with particle swarm algorithms for svm parameter selection. Lecture Notes in Computer Science 2012;7335 LNCS(PART 3):562-575.\n\nComplex network measures for data set characterization. G Morais, R C Prati, Brazilian Conference on Intelligent Systems, BRACIS 2013. Fortaleza, CE, BrazilIEEE Computer SocietyMorais, G., Prati, R.C.. Complex network measures for data set characterization. In: Brazilian Conference on Intelligent Systems, BRACIS 2013, Fortaleza, CE, Brazil, 19-24 October, 2013. IEEE Computer Society; 2013. p. 12-18.\n\nHyper-Parameter Tuning for Support Vector Machines by Estimation of Distribution Algorithms. L C Padierna, M Carpio, A Rojas, H Puga, R Baltazar, H Fraire, Springer International PublishingChamPadierna, L.C., Carpio, M., Rojas, A., Puga, H., Baltazar, R., Fraire, H.. Hyper-Parameter Tuning for Support Vector Machines by Estimation of Distribution Algorithms; Cham: Springer International Publishing. p. 787-800.\n\n. B Pfahringer, H Bensusan, C G Giraud-Carrier, Pfahringer, B., Bensusan, H., Giraud-Carrier, C.G..\n\nMeta-learning by landmarking various learning algorithms. Proceedings of the Seventeenth International Conference on Machine Learning. the Seventeenth International Conference on Machine LearningSan Francisco, CA, USAMorgan Kaufmann Publishers IncMeta-learning by landmarking various learning algorithms. In: Pro- ceedings of the Seventeenth International Conference on Machine Learning. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.; 2000. p. 743-750.\n\nUsing genetic algorithms to improve prediction of execution times of ML tasks. R Priya, B F De Souza, A L D Rossi, A C P L F Carvalho, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). 7208Priya, R., De Souza, B.F., Rossi, A.L.D., Carvalho, A.C.P.L.F.. Using genetic algorithms to improve prediction of execution times of ML tasks. In: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). volume 7208 LNAI; 2012. p. 196-207.\n\nC4.5: Programs for Machine Learning. J R Quinlan, Morgan Kaufmann Publishers IncSan Francisco, CA, USAQuinlan, J.R.. C4.5: Programs for Machine Learning. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc., 1993.\n\nPrediction of classifier training time including parameter optimization. M Reif, F Shafait, A Dengel, Proceedings of the 34th Annual German conference on Advances in artificial intelligence. the 34th Annual German conference on Advances in artificial intelligenceSpringer-VerlagReif, M., Shafait, F., Dengel, A.. Prediction of classifier training time including parameter optimization. In: Proceedings of the 34th Annual German conference on Advances in artificial intelligence. Springer-Verlag;\n\n. M Reif, F Shafait, A Dengel, Reif, M., Shafait, F., Dengel, A..\n\nMeta-learning for evolutionary parameter optimization of classifiers. Machine Learning. 87Meta-learning for evolutionary parameter optimization of classifiers. Machine Learning 2012;87:357-380.\n\nAutomatic classifier selection for non-experts. M Reif, F Shafait, M Goldstein, T Breuel, A Dengel, Pattern Analysis and Applications. 171Reif, M., Shafait, F., Goldstein, M., Breuel, T., Dengel, A.. Automatic classifier selection for non-experts. Pattern Analysis and Applications 2014;17(1):83-96.\n\nUsing metalearning to predict when parameter optimization is likely to improve classification accuracy. P Ridd, C Giraud-Carrier, J Vanschoren, P Brazdil, C Soares, L Kotthoff, Meta-learning and Algorithm Selection Workshop at ECAI. Ridd, P., Giraud-Carrier, C.. Using metalearning to predict when parameter optimization is likely to improve classification accuracy. In: Vanschoren, J., Brazdil, P., Soares, C., Kotthoff, L., editors. Meta-learning and Algorithm Selection Workshop at ECAI 2014. 2014. p. 18-23.\n\nInforming the use of hyperparameter optimization through metalearning. S Sanders, C G Giraud-Carrier, V Raghavan, S Aluru, G Karypis, L Miele, X Wu, 2017 IEEE International Conference on Data Mining, ICDM 2017. New Orleans, LA, USAIEEE Computer SocietySanders, S., Giraud-Carrier, C.G.. Informing the use of hyperparameter optimization through metalearning. In: Ragha- van, V., Aluru, S., Karypis, G., Miele, L., Wu, X., editors. 2017 IEEE International Conference on Data Mining, ICDM 2017, New Orleans, LA, USA, November 18-21, 2017. IEEE Computer Society; 2017. p. 1051-1056.\n\nPractical bayesian optimization of machine learning algorithms. J Snoek, H Larochelle, R P Adams, F Pereira, C Burges, L Bottou, K Weinberger, Advances in Neural Information Processing Systems 25. Curran Associates, IncSnoek, J., Larochelle, H., Adams, R.P.. Practical bayesian optimization of machine learning algorithms. In: Pereira, F., Burges, C., Bottou, L., Weinberger, K., editors. Advances in Neural Information Processing Systems 25. Curran Associates, Inc.; 2012. p. 2951-2959.\n\nSelecting parameters of svm using meta-learning and kernel matrix-based meta-features. C Soares, P B Brazdil, Proceedings of the 2006 ACM symposium on Applied computing. the 2006 ACM symposium on Applied computingSAC'06ACM PressSoares, C., Brazdil, P.B.. Selecting parameters of svm using meta-learning and kernel matrix-based meta-features. In: Proceedings of the 2006 ACM symposium on Applied computing. ACM Press; SAC'06; 2006. p. 564-568.\n\nA meta-learning method to select the kernel width in support vector regression. C Soares, P B Brazdil, P Kuba, Machine Learning. 543Soares, C., Brazdil, P.B., Kuba, P.. A meta-learning method to select the kernel width in support vector regression. Machine Learning 2004;54(3):195-209.\n\nAuto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. C Thornton, F Hutter, H H Hoos, K Leyton-Brown, Proc. of KDD-2013. of KDD-2013Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.. Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms. In: Proc. of KDD-2013. 2013. p. 847-855.\n\nOpenml: Networked science in machine learning. J Vanschoren, J N Van Rijn, B Bischl, L Torgo, SIGKDD Explor Newsl. 152Vanschoren, J., van Rijn, J.N., Bischl, B., Torgo, L.. Openml: Networked science in machine learning. SIGKDD Explor Newsl 2014;15(2):49-60.\n\nThe Nature of Statistical Learning Theory. V Vapnik, Springer-VerlagVapnik, V.. The Nature of Statistical Learning Theory. Springer-Verlag, 1995.\n\nUsing meta-learning to support data mining. R Vilalta, C G Giraud-Carrier, P Brazdil, C Soares, International Journal of Computer Science & Applications. 11Vilalta, R., Giraud-Carrier, C.G., Brazdil, P., Soares, C.. Using meta-learning to support data mining. International Journal of Computer Science & Applications 2004;1(1):31-45.\n\nScalable gaussian process-based transfer surrogates for hyperparameter optimization. M Wistuba, N Schilling, L Schmidt-Thieme, Machine Learning. 1071Wistuba, M., Schilling, N., Schmidt-Thieme, L.. Scalable gaussian process-based transfer surrogates for hyperparameter optimization. Machine Learning 2018;107(1):43-78.\n\n. IN Information-theoretic. IN Information-theoretic.\n\n. MtL Meta-learning. MtL Meta-learning.\n\n. Nb Na\u00efve-Bayes, NB Na\u00efve-Bayes.\n\n. NMSE Normalized Mean Squared Error. NMSE Normalized Mean Squared Error.\n\nOpenML Open Machine Learning. OpenML Open Machine Learning.\n\nParamILS Iterated Local Search in Parameter Configuration Space. ParamILS Iterated Local Search in Parameter Configuration Space.\n\nPMCC Pearson Product-Moment Correlation Coefficient. PMCC Pearson Product-Moment Correlation Coefficient.\n\n. SFS Sequential Forward Selection. SFS Sequential Forward Selection.\n", "annotations": {"author": "[{\"end\":286,\"start\":113},{\"end\":368,\"start\":287},{\"end\":478,\"start\":369},{\"end\":555,\"start\":479},{\"end\":675,\"start\":556}]", "publisher": null, "author_last_name": "[{\"end\":131,\"start\":122},{\"end\":302,\"start\":297},{\"end\":384,\"start\":376},{\"end\":497,\"start\":487},{\"end\":581,\"start\":570}]", "author_first_name": "[{\"end\":119,\"start\":113},{\"end\":121,\"start\":120},{\"end\":292,\"start\":287},{\"end\":296,\"start\":293},{\"end\":375,\"start\":369},{\"end\":486,\"start\":479},{\"end\":561,\"start\":556},{\"end\":569,\"start\":562}]", "author_affiliation": "[{\"end\":224,\"start\":133},{\"end\":285,\"start\":226},{\"end\":367,\"start\":304},{\"end\":477,\"start\":386},{\"end\":554,\"start\":499},{\"end\":674,\"start\":583}]", "title": "[{\"end\":110,\"start\":1},{\"end\":785,\"start\":676}]", "venue": null, "abstract": "[{\"end\":2269,\"start\":883}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b50\"},\"end\":2370,\"start\":2366},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3071,\"start\":3067},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3074,\"start\":3071},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3447,\"start\":3443},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3455,\"start\":3452},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3654,\"start\":3650},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":4626,\"start\":4622},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5184,\"start\":5181},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5756,\"start\":5752},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6053,\"start\":6049},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6056,\"start\":6053},{\"end\":6080,\"start\":6077},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7199,\"start\":7198},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8135,\"start\":8132},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8191,\"start\":8188},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8213,\"start\":8209},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8233,\"start\":8229},{\"end\":8361,\"start\":8350},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8369,\"start\":8366},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9336,\"start\":9332},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9479,\"start\":9476},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9696,\"start\":9692},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9699,\"start\":9696},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9702,\"start\":9699},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9705,\"start\":9702},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9708,\"start\":9705},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9711,\"start\":9708},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9748,\"start\":9745},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10061,\"start\":10057},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10064,\"start\":10061},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10089,\"start\":10085},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10284,\"start\":10280},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10287,\"start\":10284},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10394,\"start\":10390},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10616,\"start\":10612},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10648,\"start\":10644},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10905,\"start\":10901},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":11947,\"start\":11943},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":11971,\"start\":11967},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":11997,\"start\":11993},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12672,\"start\":12668},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12735,\"start\":12731},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12918,\"start\":12914},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":13538,\"start\":13534},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13880,\"start\":13876},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14348,\"start\":14344},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14351,\"start\":14348},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14354,\"start\":14351},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":14357,\"start\":14354},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14380,\"start\":14376},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":14721,\"start\":14717},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14746,\"start\":14742},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14883,\"start\":14879},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15232,\"start\":15228},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":15755,\"start\":15751},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":15952,\"start\":15948},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16429,\"start\":16425},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":16887,\"start\":16883},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16917,\"start\":16913},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":17219,\"start\":17215},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":17253,\"start\":17249},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17325,\"start\":17321},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":17421,\"start\":17417},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":18520,\"start\":18516},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":19629,\"start\":19625},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":21297,\"start\":21293},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":21331,\"start\":21327},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22587,\"start\":22583},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24798,\"start\":24797},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24866,\"start\":24862},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":24994,\"start\":24990},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":25117,\"start\":25113},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26951,\"start\":26947},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":27260,\"start\":27256},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":27336,\"start\":27332},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27757,\"start\":27753},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":28027,\"start\":28023},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28030,\"start\":28027},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28055,\"start\":28051},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28559,\"start\":28555},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28794,\"start\":28790},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":29303,\"start\":29301},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29586,\"start\":29584},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":30391,\"start\":30389},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":30454,\"start\":30451},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":30926,\"start\":30923},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":31043,\"start\":31041},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":32560,\"start\":32556},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":33912,\"start\":33908},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":35084,\"start\":35082},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":37414,\"start\":37410},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":39310,\"start\":39306},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":40621,\"start\":40618},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":40759,\"start\":40755},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":44818,\"start\":44815},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":49555,\"start\":49551},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":55426,\"start\":55422},{\"end\":55429,\"start\":55426},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":58404,\"start\":58400},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":60126,\"start\":60122},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":60194,\"start\":60192},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":62842,\"start\":62838},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":66351,\"start\":66347},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":66354,\"start\":66351},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":66792,\"start\":66788},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":67600,\"start\":67598},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":67610,\"start\":67606},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":68126,\"start\":68122},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":68304,\"start\":68302},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":68391,\"start\":68389},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":69287,\"start\":69283},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":89148,\"start\":89146},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":89268,\"start\":89264},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":90308,\"start\":90304},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":90500,\"start\":90498}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":71885,\"start\":71412},{\"attributes\":{\"id\":\"fig_2\"},\"end\":72021,\"start\":71886},{\"attributes\":{\"id\":\"fig_3\"},\"end\":72443,\"start\":72022},{\"attributes\":{\"id\":\"fig_4\"},\"end\":72711,\"start\":72444},{\"attributes\":{\"id\":\"fig_5\"},\"end\":73658,\"start\":72712},{\"attributes\":{\"id\":\"fig_6\"},\"end\":73965,\"start\":73659},{\"attributes\":{\"id\":\"fig_7\"},\"end\":74547,\"start\":73966},{\"attributes\":{\"id\":\"fig_8\"},\"end\":74885,\"start\":74548},{\"attributes\":{\"id\":\"fig_9\"},\"end\":75421,\"start\":74886},{\"attributes\":{\"id\":\"fig_10\"},\"end\":75759,\"start\":75422},{\"attributes\":{\"id\":\"fig_11\"},\"end\":77107,\"start\":75760},{\"attributes\":{\"id\":\"fig_12\"},\"end\":77670,\"start\":77108},{\"attributes\":{\"id\":\"fig_13\"},\"end\":78027,\"start\":77671},{\"attributes\":{\"id\":\"fig_15\"},\"end\":78197,\"start\":78028},{\"attributes\":{\"id\":\"fig_16\"},\"end\":78348,\"start\":78198},{\"attributes\":{\"id\":\"fig_17\"},\"end\":78547,\"start\":78349},{\"attributes\":{\"id\":\"fig_18\"},\"end\":78988,\"start\":78548},{\"attributes\":{\"id\":\"fig_19\"},\"end\":79266,\"start\":78989},{\"attributes\":{\"id\":\"fig_20\"},\"end\":79356,\"start\":79267},{\"attributes\":{\"id\":\"fig_21\"},\"end\":79892,\"start\":79357},{\"attributes\":{\"id\":\"fig_22\"},\"end\":80029,\"start\":79893},{\"attributes\":{\"id\":\"fig_23\"},\"end\":80169,\"start\":80030},{\"attributes\":{\"id\":\"fig_24\"},\"end\":80602,\"start\":80170},{\"attributes\":{\"id\":\"fig_26\"},\"end\":80896,\"start\":80603},{\"attributes\":{\"id\":\"fig_27\"},\"end\":81370,\"start\":80897},{\"attributes\":{\"id\":\"fig_28\"},\"end\":82412,\"start\":81371},{\"attributes\":{\"id\":\"fig_29\"},\"end\":82701,\"start\":82413},{\"attributes\":{\"id\":\"fig_30\"},\"end\":82814,\"start\":82702},{\"attributes\":{\"id\":\"fig_31\"},\"end\":82898,\"start\":82815},{\"attributes\":{\"id\":\"fig_32\"},\"end\":83123,\"start\":82899},{\"attributes\":{\"id\":\"fig_33\"},\"end\":83306,\"start\":83124},{\"attributes\":{\"id\":\"fig_34\"},\"end\":83419,\"start\":83307},{\"attributes\":{\"id\":\"fig_35\"},\"end\":84008,\"start\":83420},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":84599,\"start\":84009},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":85565,\"start\":84600},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":85995,\"start\":85566},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":86572,\"start\":85996},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":87079,\"start\":86573},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":87327,\"start\":87080},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":87669,\"start\":87328},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":88189,\"start\":87670},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":88197,\"start\":88190},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":88808,\"start\":88198},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":89133,\"start\":88809},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":89979,\"start\":89134},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":90235,\"start\":89980}]", "paragraph": "[{\"end\":3001,\"start\":2285},{\"end\":3860,\"start\":3003},{\"end\":4401,\"start\":3862},{\"end\":4953,\"start\":4403},{\"end\":6323,\"start\":4955},{\"end\":6378,\"start\":6325},{\"end\":6594,\"start\":6380},{\"end\":6740,\"start\":6596},{\"end\":6916,\"start\":6742},{\"end\":7624,\"start\":6918},{\"end\":8136,\"start\":7656},{\"end\":9410,\"start\":8138},{\"end\":9712,\"start\":9412},{\"end\":10065,\"start\":9714},{\"end\":10288,\"start\":10067},{\"end\":10367,\"start\":10290},{\"end\":10583,\"start\":10369},{\"end\":10621,\"start\":10585},{\"end\":10906,\"start\":10623},{\"end\":11225,\"start\":10950},{\"end\":11255,\"start\":11227},{\"end\":11288,\"start\":11257},{\"end\":11341,\"start\":11290},{\"end\":11399,\"start\":11343},{\"end\":11635,\"start\":11401},{\"end\":12376,\"start\":11669},{\"end\":12897,\"start\":12378},{\"end\":13345,\"start\":12899},{\"end\":14192,\"start\":13380},{\"end\":14702,\"start\":14249},{\"end\":15024,\"start\":14704},{\"end\":15112,\"start\":15026},{\"end\":15519,\"start\":15114},{\"end\":15582,\"start\":15521},{\"end\":15930,\"start\":15641},{\"end\":16402,\"start\":15932},{\"end\":16989,\"start\":16404},{\"end\":17393,\"start\":17039},{\"end\":17894,\"start\":17395},{\"end\":18035,\"start\":17896},{\"end\":18119,\"start\":18037},{\"end\":18273,\"start\":18121},{\"end\":18333,\"start\":18275},{\"end\":18489,\"start\":18335},{\"end\":19000,\"start\":18491},{\"end\":19124,\"start\":19002},{\"end\":19494,\"start\":19126},{\"end\":19606,\"start\":19496},{\"end\":19924,\"start\":19608},{\"end\":20258,\"start\":19926},{\"end\":20330,\"start\":20260},{\"end\":20448,\"start\":20332},{\"end\":20559,\"start\":20450},{\"end\":20659,\"start\":20561},{\"end\":21082,\"start\":20661},{\"end\":21424,\"start\":21084},{\"end\":21962,\"start\":21426},{\"end\":22319,\"start\":21997},{\"end\":22404,\"start\":22321},{\"end\":22529,\"start\":22406},{\"end\":22672,\"start\":22531},{\"end\":22748,\"start\":22674},{\"end\":22802,\"start\":22750},{\"end\":22890,\"start\":22804},{\"end\":22994,\"start\":22892},{\"end\":23057,\"start\":22996},{\"end\":23250,\"start\":23059},{\"end\":23315,\"start\":23252},{\"end\":23373,\"start\":23317},{\"end\":23475,\"start\":23375},{\"end\":23480,\"start\":23477},{\"end\":23580,\"start\":23482},{\"end\":23815,\"start\":23582},{\"end\":24189,\"start\":23844},{\"end\":24605,\"start\":24191},{\"end\":24777,\"start\":24622},{\"end\":25036,\"start\":24779},{\"end\":25483,\"start\":25071},{\"end\":25580,\"start\":25485},{\"end\":25628,\"start\":25582},{\"end\":25678,\"start\":25630},{\"end\":25779,\"start\":25680},{\"end\":25835,\"start\":25781},{\"end\":25942,\"start\":25837},{\"end\":26552,\"start\":25944},{\"end\":26696,\"start\":26554},{\"end\":27453,\"start\":26725},{\"end\":27688,\"start\":27487},{\"end\":28632,\"start\":27690},{\"end\":29305,\"start\":28634},{\"end\":29624,\"start\":29307},{\"end\":30373,\"start\":29642},{\"end\":30556,\"start\":30375},{\"end\":31473,\"start\":30573},{\"end\":31907,\"start\":31490},{\"end\":32936,\"start\":31909},{\"end\":33913,\"start\":32938},{\"end\":34549,\"start\":33915},{\"end\":35474,\"start\":34551},{\"end\":35786,\"start\":35497},{\"end\":36104,\"start\":35788},{\"end\":36779,\"start\":36106},{\"end\":37205,\"start\":36781},{\"end\":37453,\"start\":37207},{\"end\":37559,\"start\":37455},{\"end\":37773,\"start\":37561},{\"end\":38310,\"start\":37775},{\"end\":38655,\"start\":38337},{\"end\":39157,\"start\":38657},{\"end\":40048,\"start\":39181},{\"end\":40299,\"start\":40050},{\"end\":40541,\"start\":40331},{\"end\":40622,\"start\":40543},{\"end\":40711,\"start\":40624},{\"end\":40760,\"start\":40713},{\"end\":41743,\"start\":40762},{\"end\":42669,\"start\":41745},{\"end\":42869,\"start\":42671},{\"end\":43397,\"start\":42871},{\"end\":44361,\"start\":43399},{\"end\":44638,\"start\":44363},{\"end\":45621,\"start\":44670},{\"end\":46417,\"start\":45623},{\"end\":46707,\"start\":46419},{\"end\":46979,\"start\":46709},{\"end\":47307,\"start\":46981},{\"end\":47938,\"start\":47309},{\"end\":48250,\"start\":47940},{\"end\":49546,\"start\":48275},{\"end\":50187,\"start\":49548},{\"end\":50637,\"start\":50189},{\"end\":51281,\"start\":50639},{\"end\":52551,\"start\":51304},{\"end\":53178,\"start\":52553},{\"end\":53683,\"start\":53180},{\"end\":54312,\"start\":53715},{\"end\":54581,\"start\":54314},{\"end\":54680,\"start\":54583},{\"end\":55611,\"start\":54682},{\"end\":57035,\"start\":55653},{\"end\":57251,\"start\":57037},{\"end\":57839,\"start\":57253},{\"end\":58815,\"start\":57872},{\"end\":58877,\"start\":58817},{\"end\":59028,\"start\":58879},{\"end\":60673,\"start\":59030},{\"end\":61020,\"start\":60675},{\"end\":61433,\"start\":61022},{\"end\":61757,\"start\":61435},{\"end\":62037,\"start\":61759},{\"end\":62384,\"start\":62039},{\"end\":62964,\"start\":62400},{\"end\":63405,\"start\":62986},{\"end\":64138,\"start\":63407},{\"end\":64147,\"start\":64140},{\"end\":64248,\"start\":64149},{\"end\":64352,\"start\":64250},{\"end\":65078,\"start\":64354},{\"end\":65395,\"start\":65080},{\"end\":65790,\"start\":65397},{\"end\":66261,\"start\":65792},{\"end\":66741,\"start\":66302},{\"end\":67358,\"start\":66743},{\"end\":68090,\"start\":67360},{\"end\":68636,\"start\":68092},{\"end\":69136,\"start\":68658},{\"end\":69568,\"start\":69138},{\"end\":70066,\"start\":69584},{\"end\":70622,\"start\":70068},{\"end\":71095,\"start\":70624},{\"end\":71231,\"start\":71097},{\"end\":71282,\"start\":71233},{\"end\":71312,\"start\":71284},{\"end\":71329,\"start\":71314},{\"end\":71358,\"start\":71331},{\"end\":71394,\"start\":71360},{\"end\":71411,\"start\":71396}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":24621,\"start\":24606},{\"attributes\":{\"id\":\"formula_1\"},\"end\":31489,\"start\":31474}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":11455,\"start\":11448},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20758,\"start\":20751},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26801,\"start\":26794},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":29350,\"start\":29343},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":30037,\"start\":30030},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":30304,\"start\":30297},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":33599,\"start\":33592},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":34831,\"start\":34824},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":35750,\"start\":35743},{\"end\":37118,\"start\":37111},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":38309,\"start\":38302},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":45292,\"start\":45285},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":48891,\"start\":48884},{\"end\":50160,\"start\":50153},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":52549,\"start\":52542},{\"end\":55052,\"start\":55045},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":58792,\"start\":58785}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2283,\"start\":2271},{\"attributes\":{\"n\":\"2.\"},\"end\":7654,\"start\":7627},{\"attributes\":{\"n\":\"3.\"},\"end\":10948,\"start\":10909},{\"attributes\":{\"n\":\"3.1.\"},\"end\":11667,\"start\":11638},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13378,\"start\":13348},{\"attributes\":{\"n\":\"3.3.\"},\"end\":14247,\"start\":14195},{\"attributes\":{\"n\":\"3.4.\"},\"end\":15639,\"start\":15585},{\"attributes\":{\"n\":\"3.5.\"},\"end\":17037,\"start\":16992},{\"attributes\":{\"n\":\"3.6.\"},\"end\":21995,\"start\":21965},{\"attributes\":{\"n\":\"4.\"},\"end\":23842,\"start\":23818},{\"attributes\":{\"n\":\"4.1.\"},\"end\":25069,\"start\":25039},{\"attributes\":{\"n\":\"4.2.\"},\"end\":26723,\"start\":26699},{\"attributes\":{\"n\":\"4.3.\"},\"end\":27485,\"start\":27456},{\"attributes\":{\"n\":\"4.4.\"},\"end\":29640,\"start\":29627},{\"attributes\":{\"n\":\"4.5.\"},\"end\":30571,\"start\":30559},{\"attributes\":{\"n\":\"4.6.\"},\"end\":35495,\"start\":35477},{\"attributes\":{\"n\":\"5.\"},\"end\":38335,\"start\":38313},{\"attributes\":{\"n\":\"5.1.\"},\"end\":39179,\"start\":39160},{\"attributes\":{\"n\":\"5.2.\"},\"end\":40329,\"start\":40302},{\"attributes\":{\"n\":\"5.3.\"},\"end\":44668,\"start\":44641},{\"attributes\":{\"n\":\"5.4.\"},\"end\":48273,\"start\":48253},{\"attributes\":{\"n\":\"5.5.\"},\"end\":51302,\"start\":51284},{\"attributes\":{\"n\":\"5.6.\"},\"end\":53713,\"start\":53686},{\"attributes\":{\"n\":\"5.7.\"},\"end\":55651,\"start\":55614},{\"attributes\":{\"n\":\"5.8.\"},\"end\":57870,\"start\":57842},{\"attributes\":{\"n\":\"6.\"},\"end\":62398,\"start\":62387},{\"attributes\":{\"n\":\"6.1.\"},\"end\":62984,\"start\":62967},{\"attributes\":{\"n\":\"6.2.\"},\"end\":66300,\"start\":66264},{\"attributes\":{\"n\":\"6.3.\"},\"end\":68656,\"start\":68639},{\"attributes\":{\"n\":\"6.4.\"},\"end\":69582,\"start\":69571},{\"end\":71421,\"start\":71413},{\"end\":71895,\"start\":71887},{\"end\":72455,\"start\":72445},{\"end\":72721,\"start\":72713},{\"end\":73661,\"start\":73660},{\"end\":73973,\"start\":73967},{\"end\":74557,\"start\":74549},{\"end\":74888,\"start\":74887},{\"end\":75771,\"start\":75761},{\"end\":77118,\"start\":77109},{\"end\":77680,\"start\":77672},{\"end\":78209,\"start\":78199},{\"end\":78360,\"start\":78350},{\"end\":79278,\"start\":79268},{\"end\":79366,\"start\":79358},{\"end\":80041,\"start\":80031},{\"end\":80172,\"start\":80171},{\"end\":80614,\"start\":80604},{\"end\":80901,\"start\":80898},{\"end\":81378,\"start\":81372},{\"end\":82713,\"start\":82703},{\"end\":82911,\"start\":82900},{\"end\":83319,\"start\":83308},{\"end\":83436,\"start\":83421},{\"end\":84019,\"start\":84010},{\"end\":84610,\"start\":84601},{\"end\":85576,\"start\":85567},{\"end\":86006,\"start\":85997},{\"end\":86583,\"start\":86574},{\"end\":87090,\"start\":87081},{\"end\":87338,\"start\":87329},{\"end\":87680,\"start\":87671},{\"end\":88196,\"start\":88191},{\"end\":88208,\"start\":88199},{\"end\":89144,\"start\":89135},{\"end\":89990,\"start\":89981}]", "table": "[{\"end\":84599,\"start\":84146},{\"end\":85565,\"start\":84817},{\"end\":85995,\"start\":85781},{\"end\":86572,\"start\":86062},{\"end\":87079,\"start\":86627},{\"end\":87327,\"start\":87143},{\"end\":87669,\"start\":87373},{\"end\":88189,\"start\":87768},{\"end\":89979,\"start\":89269},{\"end\":90235,\"start\":90050}]", "figure_caption": "[{\"end\":71885,\"start\":71423},{\"end\":72021,\"start\":71897},{\"end\":72443,\"start\":72024},{\"end\":72711,\"start\":72457},{\"end\":73658,\"start\":72723},{\"end\":73965,\"start\":73662},{\"end\":74547,\"start\":73975},{\"end\":74885,\"start\":74559},{\"end\":75421,\"start\":74889},{\"end\":75759,\"start\":75424},{\"end\":77107,\"start\":75773},{\"end\":77670,\"start\":77121},{\"end\":78027,\"start\":77682},{\"end\":78197,\"start\":78030},{\"end\":78348,\"start\":78211},{\"end\":78547,\"start\":78362},{\"end\":78988,\"start\":78550},{\"end\":79266,\"start\":78991},{\"end\":79356,\"start\":79280},{\"end\":79892,\"start\":79368},{\"end\":80029,\"start\":79895},{\"end\":80169,\"start\":80043},{\"end\":80602,\"start\":80173},{\"end\":80896,\"start\":80616},{\"end\":81370,\"start\":80903},{\"end\":82412,\"start\":81379},{\"end\":82701,\"start\":82415},{\"end\":82814,\"start\":82715},{\"end\":82898,\"start\":82817},{\"end\":83123,\"start\":82914},{\"end\":83306,\"start\":83126},{\"end\":83419,\"start\":83322},{\"end\":84008,\"start\":83439},{\"end\":84146,\"start\":84021},{\"end\":84817,\"start\":84612},{\"end\":85781,\"start\":85578},{\"end\":86062,\"start\":86008},{\"end\":86627,\"start\":86585},{\"end\":87143,\"start\":87092},{\"end\":87373,\"start\":87340},{\"end\":87768,\"start\":87682},{\"end\":88808,\"start\":88210},{\"end\":89133,\"start\":88811},{\"end\":89269,\"start\":89146},{\"end\":90050,\"start\":89992}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25481,\"start\":25473},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27544,\"start\":27536},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":29769,\"start\":29752},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31098,\"start\":31090},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31677,\"start\":31669},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":35325,\"start\":35317},{\"end\":35572,\"start\":35566},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":38755,\"start\":38746},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":41296,\"start\":41287},{\"attributes\":{\"ref_id\":\"fig_16\"},\"end\":43422,\"start\":43413},{\"attributes\":{\"ref_id\":\"fig_16\"},\"end\":44115,\"start\":44106},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":44204,\"start\":44195},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":44828,\"start\":44820},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":49117,\"start\":49108},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":49856,\"start\":49847},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":50430,\"start\":50422},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":52277,\"start\":52268},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":52316,\"start\":52307},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":52440,\"start\":52431},{\"attributes\":{\"ref_id\":\"fig_26\"},\"end\":53819,\"start\":53811},{\"attributes\":{\"ref_id\":\"fig_26\"},\"end\":54435,\"start\":54427},{\"attributes\":{\"ref_id\":\"fig_26\"},\"end\":55140,\"start\":55131},{\"attributes\":{\"ref_id\":\"fig_27\"},\"end\":55868,\"start\":55860},{\"attributes\":{\"ref_id\":\"fig_27\"},\"end\":57077,\"start\":57068},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":59267,\"start\":59257},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":59875,\"start\":59865},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":59994,\"start\":59984},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":60671,\"start\":60661},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":62190,\"start\":62179},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":67086,\"start\":67078},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":68417,\"start\":68409}]", "bib_author_first_name": "[{\"end\":91735,\"start\":91734},{\"end\":91742,\"start\":91741},{\"end\":91744,\"start\":91743},{\"end\":91970,\"start\":91969},{\"end\":91982,\"start\":91981},{\"end\":92000,\"start\":91999},{\"end\":92553,\"start\":92552},{\"end\":92565,\"start\":92564},{\"end\":92732,\"start\":92731},{\"end\":92742,\"start\":92741},{\"end\":92750,\"start\":92749},{\"end\":92762,\"start\":92761},{\"end\":92775,\"start\":92774},{\"end\":92786,\"start\":92785},{\"end\":92798,\"start\":92797},{\"end\":92813,\"start\":92812},{\"end\":92815,\"start\":92814},{\"end\":93102,\"start\":93101},{\"end\":93113,\"start\":93112},{\"end\":93131,\"start\":93130},{\"end\":93141,\"start\":93140},{\"end\":93327,\"start\":93326},{\"end\":93329,\"start\":93328},{\"end\":93340,\"start\":93339},{\"end\":93342,\"start\":93341},{\"end\":93352,\"start\":93351},{\"end\":93362,\"start\":93361},{\"end\":93364,\"start\":93363},{\"end\":93381,\"start\":93380},{\"end\":93383,\"start\":93382},{\"end\":93393,\"start\":93392},{\"end\":93706,\"start\":93705},{\"end\":93856,\"start\":93855},{\"end\":93858,\"start\":93857},{\"end\":93871,\"start\":93870},{\"end\":93873,\"start\":93872},{\"end\":93880,\"start\":93879},{\"end\":93882,\"start\":93881},{\"end\":93893,\"start\":93892},{\"end\":93895,\"start\":93894},{\"end\":94356,\"start\":94355},{\"end\":94371,\"start\":94370},{\"end\":94381,\"start\":94380},{\"end\":94389,\"start\":94388},{\"end\":94402,\"start\":94401},{\"end\":94414,\"start\":94413},{\"end\":94424,\"start\":94423},{\"end\":94435,\"start\":94434},{\"end\":94449,\"start\":94448},{\"end\":94764,\"start\":94763},{\"end\":94766,\"start\":94765},{\"end\":94775,\"start\":94774},{\"end\":94777,\"start\":94776},{\"end\":95040,\"start\":95039},{\"end\":95042,\"start\":95041},{\"end\":95052,\"start\":95051},{\"end\":95054,\"start\":95053},{\"end\":95064,\"start\":95063},{\"end\":95066,\"start\":95065},{\"end\":95074,\"start\":95073},{\"end\":95076,\"start\":95075},{\"end\":95320,\"start\":95319},{\"end\":95582,\"start\":95581},{\"end\":95598,\"start\":95597},{\"end\":95610,\"start\":95609},{\"end\":95612,\"start\":95611},{\"end\":95620,\"start\":95619},{\"end\":95630,\"start\":95629},{\"end\":95906,\"start\":95905},{\"end\":95916,\"start\":95915},{\"end\":95925,\"start\":95924},{\"end\":95941,\"start\":95940},{\"end\":95957,\"start\":95956},{\"end\":95965,\"start\":95964},{\"end\":95975,\"start\":95974},{\"end\":95985,\"start\":95984},{\"end\":95987,\"start\":95986},{\"end\":95999,\"start\":95998},{\"end\":96001,\"start\":96000},{\"end\":96008,\"start\":96007},{\"end\":96020,\"start\":96019},{\"end\":96460,\"start\":96459},{\"end\":96464,\"start\":96461},{\"end\":96474,\"start\":96473},{\"end\":96482,\"start\":96475},{\"end\":96497,\"start\":96496},{\"end\":96499,\"start\":96498},{\"end\":96755,\"start\":96754},{\"end\":96759,\"start\":96756},{\"end\":96768,\"start\":96767},{\"end\":96772,\"start\":96769},{\"end\":96785,\"start\":96784},{\"end\":96795,\"start\":96794},{\"end\":96799,\"start\":96796},{\"end\":96808,\"start\":96807},{\"end\":96814,\"start\":96809},{\"end\":97180,\"start\":97179},{\"end\":97182,\"start\":97181},{\"end\":97188,\"start\":97187},{\"end\":97458,\"start\":97457},{\"end\":97466,\"start\":97465},{\"end\":97481,\"start\":97480},{\"end\":97491,\"start\":97490},{\"end\":97506,\"start\":97505},{\"end\":97809,\"start\":97808},{\"end\":97811,\"start\":97810},{\"end\":97818,\"start\":97817},{\"end\":97820,\"start\":97819},{\"end\":97829,\"start\":97828},{\"end\":97831,\"start\":97830},{\"end\":98102,\"start\":98101},{\"end\":98112,\"start\":98111},{\"end\":98120,\"start\":98119},{\"end\":98136,\"start\":98135},{\"end\":98451,\"start\":98450},{\"end\":98463,\"start\":98462},{\"end\":98475,\"start\":98474},{\"end\":98477,\"start\":98476},{\"end\":98485,\"start\":98484},{\"end\":98495,\"start\":98494},{\"end\":98847,\"start\":98846},{\"end\":98859,\"start\":98858},{\"end\":98861,\"start\":98860},{\"end\":98874,\"start\":98873},{\"end\":98876,\"start\":98875},{\"end\":98885,\"start\":98884},{\"end\":99176,\"start\":99175},{\"end\":99185,\"start\":99184},{\"end\":99196,\"start\":99195},{\"end\":99615,\"start\":99614},{\"end\":99631,\"start\":99630},{\"end\":99649,\"start\":99648},{\"end\":99651,\"start\":99650},{\"end\":99662,\"start\":99661},{\"end\":99675,\"start\":99674},{\"end\":99980,\"start\":99979},{\"end\":99982,\"start\":99981},{\"end\":99992,\"start\":99991},{\"end\":99994,\"start\":99993},{\"end\":100004,\"start\":100003},{\"end\":100008,\"start\":100005},{\"end\":100022,\"start\":100021},{\"end\":100024,\"start\":100023},{\"end\":100033,\"start\":100032},{\"end\":100037,\"start\":100034},{\"end\":100309,\"start\":100308},{\"end\":100311,\"start\":100310},{\"end\":100324,\"start\":100323},{\"end\":100335,\"start\":100334},{\"end\":100344,\"start\":100343},{\"end\":100358,\"start\":100357},{\"end\":100366,\"start\":100359},{\"end\":100957,\"start\":100956},{\"end\":100959,\"start\":100958},{\"end\":100972,\"start\":100971},{\"end\":100976,\"start\":100973},{\"end\":100985,\"start\":100984},{\"end\":100999,\"start\":100998},{\"end\":101009,\"start\":101008},{\"end\":101017,\"start\":101010},{\"end\":101480,\"start\":101479},{\"end\":101482,\"start\":101481},{\"end\":101495,\"start\":101494},{\"end\":101499,\"start\":101496},{\"end\":101508,\"start\":101507},{\"end\":101522,\"start\":101521},{\"end\":101532,\"start\":101531},{\"end\":101540,\"start\":101533},{\"end\":101939,\"start\":101938},{\"end\":101941,\"start\":101940},{\"end\":101954,\"start\":101953},{\"end\":101958,\"start\":101955},{\"end\":101967,\"start\":101966},{\"end\":101981,\"start\":101980},{\"end\":101989,\"start\":101982},{\"end\":102085,\"start\":102084},{\"end\":102099,\"start\":102098},{\"end\":102110,\"start\":102109},{\"end\":102112,\"start\":102111},{\"end\":102130,\"start\":102129},{\"end\":103244,\"start\":103243},{\"end\":103255,\"start\":103254},{\"end\":103569,\"start\":103568},{\"end\":103580,\"start\":103579},{\"end\":103589,\"start\":103588},{\"end\":104220,\"start\":104219},{\"end\":104224,\"start\":104221},{\"end\":104235,\"start\":104234},{\"end\":104239,\"start\":104236},{\"end\":104252,\"start\":104251},{\"end\":104260,\"start\":104253},{\"end\":104272,\"start\":104271},{\"end\":104644,\"start\":104643},{\"end\":104654,\"start\":104653},{\"end\":104656,\"start\":104655},{\"end\":105085,\"start\":105084},{\"end\":105087,\"start\":105086},{\"end\":105099,\"start\":105098},{\"end\":105109,\"start\":105108},{\"end\":105118,\"start\":105117},{\"end\":105126,\"start\":105125},{\"end\":105138,\"start\":105137},{\"end\":105409,\"start\":105408},{\"end\":105423,\"start\":105422},{\"end\":105435,\"start\":105434},{\"end\":105437,\"start\":105436},{\"end\":106051,\"start\":106050},{\"end\":106060,\"start\":106059},{\"end\":106062,\"start\":106061},{\"end\":106074,\"start\":106073},{\"end\":106078,\"start\":106075},{\"end\":106087,\"start\":106086},{\"end\":106095,\"start\":106088},{\"end\":106600,\"start\":106599},{\"end\":106602,\"start\":106601},{\"end\":106854,\"start\":106853},{\"end\":106862,\"start\":106861},{\"end\":106873,\"start\":106872},{\"end\":107280,\"start\":107279},{\"end\":107288,\"start\":107287},{\"end\":107299,\"start\":107298},{\"end\":107588,\"start\":107587},{\"end\":107596,\"start\":107595},{\"end\":107607,\"start\":107606},{\"end\":107620,\"start\":107619},{\"end\":107630,\"start\":107629},{\"end\":107945,\"start\":107944},{\"end\":107953,\"start\":107952},{\"end\":107971,\"start\":107970},{\"end\":107985,\"start\":107984},{\"end\":107996,\"start\":107995},{\"end\":108006,\"start\":108005},{\"end\":108425,\"start\":108424},{\"end\":108436,\"start\":108435},{\"end\":108438,\"start\":108437},{\"end\":108456,\"start\":108455},{\"end\":108468,\"start\":108467},{\"end\":108477,\"start\":108476},{\"end\":108488,\"start\":108487},{\"end\":108497,\"start\":108496},{\"end\":108998,\"start\":108997},{\"end\":109007,\"start\":109006},{\"end\":109021,\"start\":109020},{\"end\":109023,\"start\":109022},{\"end\":109032,\"start\":109031},{\"end\":109043,\"start\":109042},{\"end\":109053,\"start\":109052},{\"end\":109063,\"start\":109062},{\"end\":109510,\"start\":109509},{\"end\":109520,\"start\":109519},{\"end\":109522,\"start\":109521},{\"end\":109947,\"start\":109946},{\"end\":109957,\"start\":109956},{\"end\":109959,\"start\":109958},{\"end\":109970,\"start\":109969},{\"end\":110246,\"start\":110245},{\"end\":110258,\"start\":110257},{\"end\":110268,\"start\":110267},{\"end\":110270,\"start\":110269},{\"end\":110278,\"start\":110277},{\"end\":110561,\"start\":110560},{\"end\":110575,\"start\":110574},{\"end\":110577,\"start\":110576},{\"end\":110589,\"start\":110588},{\"end\":110599,\"start\":110598},{\"end\":110816,\"start\":110815},{\"end\":110964,\"start\":110963},{\"end\":110975,\"start\":110974},{\"end\":110977,\"start\":110976},{\"end\":110995,\"start\":110994},{\"end\":111006,\"start\":111005},{\"end\":111340,\"start\":111339},{\"end\":111351,\"start\":111350},{\"end\":111364,\"start\":111363}]", "bib_author_last_name": "[{\"end\":91739,\"start\":91736},{\"end\":91756,\"start\":91745},{\"end\":91979,\"start\":91971},{\"end\":91997,\"start\":91983},{\"end\":92008,\"start\":92001},{\"end\":92562,\"start\":92554},{\"end\":92572,\"start\":92566},{\"end\":92739,\"start\":92733},{\"end\":92747,\"start\":92743},{\"end\":92759,\"start\":92751},{\"end\":92772,\"start\":92763},{\"end\":92783,\"start\":92776},{\"end\":92795,\"start\":92787},{\"end\":92810,\"start\":92799},{\"end\":92821,\"start\":92816},{\"end\":93110,\"start\":93103},{\"end\":93128,\"start\":93114},{\"end\":93138,\"start\":93132},{\"end\":93149,\"start\":93142},{\"end\":93337,\"start\":93330},{\"end\":93349,\"start\":93343},{\"end\":93359,\"start\":93353},{\"end\":93378,\"start\":93365},{\"end\":93390,\"start\":93384},{\"end\":93402,\"start\":93394},{\"end\":93714,\"start\":93707},{\"end\":93868,\"start\":93859},{\"end\":93877,\"start\":93874},{\"end\":93890,\"start\":93883},{\"end\":93903,\"start\":93896},{\"end\":94368,\"start\":94357},{\"end\":94378,\"start\":94372},{\"end\":94386,\"start\":94382},{\"end\":94399,\"start\":94390},{\"end\":94411,\"start\":94403},{\"end\":94421,\"start\":94415},{\"end\":94432,\"start\":94425},{\"end\":94446,\"start\":94436},{\"end\":94456,\"start\":94450},{\"end\":94772,\"start\":94767},{\"end\":94781,\"start\":94778},{\"end\":95049,\"start\":95043},{\"end\":95061,\"start\":95055},{\"end\":95071,\"start\":95067},{\"end\":95087,\"start\":95077},{\"end\":95327,\"start\":95321},{\"end\":95595,\"start\":95583},{\"end\":95607,\"start\":95599},{\"end\":95617,\"start\":95613},{\"end\":95627,\"start\":95621},{\"end\":95643,\"start\":95631},{\"end\":95913,\"start\":95907},{\"end\":95922,\"start\":95917},{\"end\":95938,\"start\":95926},{\"end\":95954,\"start\":95942},{\"end\":95962,\"start\":95958},{\"end\":95972,\"start\":95966},{\"end\":95982,\"start\":95976},{\"end\":95996,\"start\":95988},{\"end\":96005,\"start\":96002},{\"end\":96017,\"start\":96009},{\"end\":96028,\"start\":96021},{\"end\":96471,\"start\":96465},{\"end\":96494,\"start\":96483},{\"end\":96506,\"start\":96500},{\"end\":96765,\"start\":96760},{\"end\":96782,\"start\":96773},{\"end\":96792,\"start\":96786},{\"end\":96805,\"start\":96800},{\"end\":96823,\"start\":96815},{\"end\":96833,\"start\":96825},{\"end\":97185,\"start\":97183},{\"end\":97193,\"start\":97189},{\"end\":97463,\"start\":97459},{\"end\":97478,\"start\":97467},{\"end\":97488,\"start\":97482},{\"end\":97503,\"start\":97492},{\"end\":97512,\"start\":97507},{\"end\":97815,\"start\":97812},{\"end\":97826,\"start\":97821},{\"end\":97835,\"start\":97832},{\"end\":98109,\"start\":98103},{\"end\":98117,\"start\":98113},{\"end\":98133,\"start\":98121},{\"end\":98144,\"start\":98137},{\"end\":98460,\"start\":98452},{\"end\":98472,\"start\":98464},{\"end\":98482,\"start\":98478},{\"end\":98492,\"start\":98486},{\"end\":98508,\"start\":98496},{\"end\":98856,\"start\":98848},{\"end\":98871,\"start\":98862},{\"end\":98882,\"start\":98877},{\"end\":98892,\"start\":98886},{\"end\":99182,\"start\":99177},{\"end\":99193,\"start\":99186},{\"end\":99207,\"start\":99197},{\"end\":99628,\"start\":99616},{\"end\":99646,\"start\":99632},{\"end\":99659,\"start\":99652},{\"end\":99672,\"start\":99663},{\"end\":99683,\"start\":99676},{\"end\":99989,\"start\":99983},{\"end\":100001,\"start\":99995},{\"end\":100019,\"start\":100009},{\"end\":100030,\"start\":100025},{\"end\":100047,\"start\":100038},{\"end\":100321,\"start\":100312},{\"end\":100332,\"start\":100325},{\"end\":100341,\"start\":100336},{\"end\":100355,\"start\":100345},{\"end\":100378,\"start\":100367},{\"end\":100969,\"start\":100960},{\"end\":100982,\"start\":100977},{\"end\":100996,\"start\":100986},{\"end\":101006,\"start\":101000},{\"end\":101029,\"start\":101018},{\"end\":101492,\"start\":101483},{\"end\":101505,\"start\":101500},{\"end\":101519,\"start\":101509},{\"end\":101529,\"start\":101523},{\"end\":101549,\"start\":101541},{\"end\":101951,\"start\":101942},{\"end\":101964,\"start\":101959},{\"end\":101978,\"start\":101968},{\"end\":101998,\"start\":101990},{\"end\":102096,\"start\":102086},{\"end\":102107,\"start\":102100},{\"end\":102127,\"start\":102113},{\"end\":102139,\"start\":102131},{\"end\":103252,\"start\":103245},{\"end\":103265,\"start\":103256},{\"end\":103577,\"start\":103570},{\"end\":103586,\"start\":103581},{\"end\":103599,\"start\":103590},{\"end\":104232,\"start\":104225},{\"end\":104249,\"start\":104240},{\"end\":104269,\"start\":104261},{\"end\":104279,\"start\":104273},{\"end\":104651,\"start\":104645},{\"end\":104662,\"start\":104657},{\"end\":105096,\"start\":105088},{\"end\":105106,\"start\":105100},{\"end\":105115,\"start\":105110},{\"end\":105123,\"start\":105119},{\"end\":105135,\"start\":105127},{\"end\":105145,\"start\":105139},{\"end\":105420,\"start\":105410},{\"end\":105432,\"start\":105424},{\"end\":105452,\"start\":105438},{\"end\":106057,\"start\":106052},{\"end\":106071,\"start\":106063},{\"end\":106084,\"start\":106079},{\"end\":106104,\"start\":106096},{\"end\":106610,\"start\":106603},{\"end\":106859,\"start\":106855},{\"end\":106870,\"start\":106863},{\"end\":106880,\"start\":106874},{\"end\":107285,\"start\":107281},{\"end\":107296,\"start\":107289},{\"end\":107306,\"start\":107300},{\"end\":107593,\"start\":107589},{\"end\":107604,\"start\":107597},{\"end\":107617,\"start\":107608},{\"end\":107627,\"start\":107621},{\"end\":107637,\"start\":107631},{\"end\":107950,\"start\":107946},{\"end\":107968,\"start\":107954},{\"end\":107982,\"start\":107972},{\"end\":107993,\"start\":107986},{\"end\":108003,\"start\":107997},{\"end\":108015,\"start\":108007},{\"end\":108433,\"start\":108426},{\"end\":108453,\"start\":108439},{\"end\":108465,\"start\":108457},{\"end\":108474,\"start\":108469},{\"end\":108485,\"start\":108478},{\"end\":108494,\"start\":108489},{\"end\":108500,\"start\":108498},{\"end\":109004,\"start\":108999},{\"end\":109018,\"start\":109008},{\"end\":109029,\"start\":109024},{\"end\":109040,\"start\":109033},{\"end\":109050,\"start\":109044},{\"end\":109060,\"start\":109054},{\"end\":109074,\"start\":109064},{\"end\":109517,\"start\":109511},{\"end\":109530,\"start\":109523},{\"end\":109954,\"start\":109948},{\"end\":109967,\"start\":109960},{\"end\":109975,\"start\":109971},{\"end\":110255,\"start\":110247},{\"end\":110265,\"start\":110259},{\"end\":110275,\"start\":110271},{\"end\":110291,\"start\":110279},{\"end\":110572,\"start\":110562},{\"end\":110586,\"start\":110578},{\"end\":110596,\"start\":110590},{\"end\":110605,\"start\":110600},{\"end\":110823,\"start\":110817},{\"end\":110972,\"start\":110965},{\"end\":110992,\"start\":110978},{\"end\":111003,\"start\":110996},{\"end\":111013,\"start\":111007},{\"end\":111348,\"start\":111341},{\"end\":111361,\"start\":111352},{\"end\":111379,\"start\":111365},{\"end\":111685,\"start\":111671}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":27824921},\"end\":91925,\"start\":91650},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":37122934},\"end\":92502,\"start\":91927},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":15700257},\"end\":92701,\"start\":92504},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":27867893},\"end\":93056,\"start\":92703},{\"attributes\":{\"id\":\"b4\"},\"end\":93303,\"start\":93058},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":14313958},\"end\":93687,\"start\":93305},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":89141},\"end\":93799,\"start\":93689},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11557689},\"end\":94280,\"start\":93801},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":9781047},\"end\":94714,\"start\":94282},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":961425},\"end\":94986,\"start\":94716},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1554582},\"end\":95253,\"start\":94988},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":7553535},\"end\":95501,\"start\":95255},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":32290374},\"end\":95854,\"start\":95503},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":856717},\"end\":96413,\"start\":95856},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":29352928},\"end\":96656,\"start\":96415},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":16585020},\"end\":97075,\"start\":96658},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":2351470},\"end\":97384,\"start\":97077},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":4997972},\"end\":97754,\"start\":97386},{\"attributes\":{\"id\":\"b18\"},\"end\":98041,\"start\":97756},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1034056},\"end\":98366,\"start\":98043},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":11493856},\"end\":98751,\"start\":98368},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1383578},\"end\":99116,\"start\":98753},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":27488482},\"end\":99538,\"start\":99118},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1686873},\"end\":99922,\"start\":99540},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":23361441},\"end\":100243,\"start\":99924},{\"attributes\":{\"doi\":\"10.1109/BRACIS.2016.018\",\"id\":\"b25\",\"matched_paper_id\":16039740},\"end\":100892,\"start\":100245},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":18284734},\"end\":101385,\"start\":100894},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":7277001},\"end\":101934,\"start\":101387},{\"attributes\":{\"id\":\"b28\"},\"end\":102069,\"start\":101936},{\"attributes\":{\"id\":\"b29\"},\"end\":103197,\"start\":102071},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":195820},\"end\":103492,\"start\":103199},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":18345020},\"end\":104099,\"start\":103494},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":2609757},\"end\":104585,\"start\":104101},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":9945786},\"end\":104989,\"start\":104587},{\"attributes\":{\"id\":\"b34\"},\"end\":105404,\"start\":104991},{\"attributes\":{\"id\":\"b35\"},\"end\":105505,\"start\":105406},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":17857546},\"end\":105969,\"start\":105507},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":45954516},\"end\":106560,\"start\":105971},{\"attributes\":{\"id\":\"b38\"},\"end\":106778,\"start\":106562},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":17054229},\"end\":107275,\"start\":106780},{\"attributes\":{\"id\":\"b40\"},\"end\":107342,\"start\":107277},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":3248302},\"end\":107537,\"start\":107344},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":3580792},\"end\":107838,\"start\":107539},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":16512076},\"end\":108351,\"start\":107840},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":21461027},\"end\":108931,\"start\":108353},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":632197},\"end\":109420,\"start\":108933},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":14357226},\"end\":109864,\"start\":109422},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":1526774},\"end\":110151,\"start\":109866},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":13952689},\"end\":110511,\"start\":110153},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":4977460},\"end\":110770,\"start\":110513},{\"attributes\":{\"id\":\"b50\"},\"end\":110917,\"start\":110772},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":2369955},\"end\":111252,\"start\":110919},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":22057273},\"end\":111571,\"start\":111254},{\"attributes\":{\"id\":\"b53\"},\"end\":111626,\"start\":111573},{\"attributes\":{\"id\":\"b54\"},\"end\":111667,\"start\":111628},{\"attributes\":{\"id\":\"b55\"},\"end\":111702,\"start\":111669},{\"attributes\":{\"id\":\"b56\"},\"end\":111777,\"start\":111704},{\"attributes\":{\"id\":\"b57\"},\"end\":111838,\"start\":111779},{\"attributes\":{\"id\":\"b58\"},\"end\":111969,\"start\":111840},{\"attributes\":{\"id\":\"b59\"},\"end\":112076,\"start\":111971},{\"attributes\":{\"id\":\"b60\"},\"end\":112147,\"start\":112078}]", "bib_title": "[{\"end\":91732,\"start\":91650},{\"end\":91967,\"start\":91927},{\"end\":92550,\"start\":92504},{\"end\":92729,\"start\":92703},{\"end\":93324,\"start\":93305},{\"end\":93703,\"start\":93689},{\"end\":93853,\"start\":93801},{\"end\":94353,\"start\":94282},{\"end\":94761,\"start\":94716},{\"end\":95037,\"start\":94988},{\"end\":95317,\"start\":95255},{\"end\":95579,\"start\":95503},{\"end\":95903,\"start\":95856},{\"end\":96457,\"start\":96415},{\"end\":96752,\"start\":96658},{\"end\":97177,\"start\":97077},{\"end\":97455,\"start\":97386},{\"end\":98099,\"start\":98043},{\"end\":98448,\"start\":98368},{\"end\":98844,\"start\":98753},{\"end\":99173,\"start\":99118},{\"end\":99612,\"start\":99540},{\"end\":99977,\"start\":99924},{\"end\":100306,\"start\":100245},{\"end\":100954,\"start\":100894},{\"end\":101477,\"start\":101387},{\"end\":102082,\"start\":102071},{\"end\":103241,\"start\":103199},{\"end\":103566,\"start\":103494},{\"end\":104217,\"start\":104101},{\"end\":104641,\"start\":104587},{\"end\":105563,\"start\":105507},{\"end\":106048,\"start\":105971},{\"end\":106851,\"start\":106780},{\"end\":107412,\"start\":107344},{\"end\":107585,\"start\":107539},{\"end\":107942,\"start\":107840},{\"end\":108422,\"start\":108353},{\"end\":108995,\"start\":108933},{\"end\":109507,\"start\":109422},{\"end\":109944,\"start\":109866},{\"end\":110243,\"start\":110153},{\"end\":110558,\"start\":110513},{\"end\":110961,\"start\":110919},{\"end\":111337,\"start\":111254}]", "bib_author": "[{\"end\":91741,\"start\":91734},{\"end\":91758,\"start\":91741},{\"end\":91981,\"start\":91969},{\"end\":91999,\"start\":91981},{\"end\":92010,\"start\":91999},{\"end\":92564,\"start\":92552},{\"end\":92574,\"start\":92564},{\"end\":92741,\"start\":92731},{\"end\":92749,\"start\":92741},{\"end\":92761,\"start\":92749},{\"end\":92774,\"start\":92761},{\"end\":92785,\"start\":92774},{\"end\":92797,\"start\":92785},{\"end\":92812,\"start\":92797},{\"end\":92823,\"start\":92812},{\"end\":93112,\"start\":93101},{\"end\":93130,\"start\":93112},{\"end\":93140,\"start\":93130},{\"end\":93151,\"start\":93140},{\"end\":93339,\"start\":93326},{\"end\":93351,\"start\":93339},{\"end\":93361,\"start\":93351},{\"end\":93380,\"start\":93361},{\"end\":93392,\"start\":93380},{\"end\":93404,\"start\":93392},{\"end\":93716,\"start\":93705},{\"end\":93870,\"start\":93855},{\"end\":93879,\"start\":93870},{\"end\":93892,\"start\":93879},{\"end\":93905,\"start\":93892},{\"end\":94370,\"start\":94355},{\"end\":94380,\"start\":94370},{\"end\":94388,\"start\":94380},{\"end\":94401,\"start\":94388},{\"end\":94413,\"start\":94401},{\"end\":94423,\"start\":94413},{\"end\":94434,\"start\":94423},{\"end\":94448,\"start\":94434},{\"end\":94458,\"start\":94448},{\"end\":94774,\"start\":94763},{\"end\":94783,\"start\":94774},{\"end\":95051,\"start\":95039},{\"end\":95063,\"start\":95051},{\"end\":95073,\"start\":95063},{\"end\":95089,\"start\":95073},{\"end\":95329,\"start\":95319},{\"end\":95597,\"start\":95581},{\"end\":95609,\"start\":95597},{\"end\":95619,\"start\":95609},{\"end\":95629,\"start\":95619},{\"end\":95645,\"start\":95629},{\"end\":95915,\"start\":95905},{\"end\":95924,\"start\":95915},{\"end\":95940,\"start\":95924},{\"end\":95956,\"start\":95940},{\"end\":95964,\"start\":95956},{\"end\":95974,\"start\":95964},{\"end\":95984,\"start\":95974},{\"end\":95998,\"start\":95984},{\"end\":96007,\"start\":95998},{\"end\":96019,\"start\":96007},{\"end\":96030,\"start\":96019},{\"end\":96473,\"start\":96459},{\"end\":96496,\"start\":96473},{\"end\":96508,\"start\":96496},{\"end\":96767,\"start\":96754},{\"end\":96784,\"start\":96767},{\"end\":96794,\"start\":96784},{\"end\":96807,\"start\":96794},{\"end\":96825,\"start\":96807},{\"end\":96835,\"start\":96825},{\"end\":97187,\"start\":97179},{\"end\":97195,\"start\":97187},{\"end\":97465,\"start\":97457},{\"end\":97480,\"start\":97465},{\"end\":97490,\"start\":97480},{\"end\":97505,\"start\":97490},{\"end\":97514,\"start\":97505},{\"end\":97817,\"start\":97808},{\"end\":97828,\"start\":97817},{\"end\":97837,\"start\":97828},{\"end\":98111,\"start\":98101},{\"end\":98119,\"start\":98111},{\"end\":98135,\"start\":98119},{\"end\":98146,\"start\":98135},{\"end\":98462,\"start\":98450},{\"end\":98474,\"start\":98462},{\"end\":98484,\"start\":98474},{\"end\":98494,\"start\":98484},{\"end\":98510,\"start\":98494},{\"end\":98858,\"start\":98846},{\"end\":98873,\"start\":98858},{\"end\":98884,\"start\":98873},{\"end\":98894,\"start\":98884},{\"end\":99184,\"start\":99175},{\"end\":99195,\"start\":99184},{\"end\":99209,\"start\":99195},{\"end\":99630,\"start\":99614},{\"end\":99648,\"start\":99630},{\"end\":99661,\"start\":99648},{\"end\":99674,\"start\":99661},{\"end\":99685,\"start\":99674},{\"end\":99991,\"start\":99979},{\"end\":100003,\"start\":99991},{\"end\":100021,\"start\":100003},{\"end\":100032,\"start\":100021},{\"end\":100049,\"start\":100032},{\"end\":100323,\"start\":100308},{\"end\":100334,\"start\":100323},{\"end\":100343,\"start\":100334},{\"end\":100357,\"start\":100343},{\"end\":100380,\"start\":100357},{\"end\":100971,\"start\":100956},{\"end\":100984,\"start\":100971},{\"end\":100998,\"start\":100984},{\"end\":101008,\"start\":100998},{\"end\":101031,\"start\":101008},{\"end\":101494,\"start\":101479},{\"end\":101507,\"start\":101494},{\"end\":101521,\"start\":101507},{\"end\":101531,\"start\":101521},{\"end\":101551,\"start\":101531},{\"end\":101953,\"start\":101938},{\"end\":101966,\"start\":101953},{\"end\":101980,\"start\":101966},{\"end\":102000,\"start\":101980},{\"end\":102098,\"start\":102084},{\"end\":102109,\"start\":102098},{\"end\":102129,\"start\":102109},{\"end\":102141,\"start\":102129},{\"end\":103254,\"start\":103243},{\"end\":103267,\"start\":103254},{\"end\":103579,\"start\":103568},{\"end\":103588,\"start\":103579},{\"end\":103601,\"start\":103588},{\"end\":104234,\"start\":104219},{\"end\":104251,\"start\":104234},{\"end\":104271,\"start\":104251},{\"end\":104281,\"start\":104271},{\"end\":104653,\"start\":104643},{\"end\":104664,\"start\":104653},{\"end\":105098,\"start\":105084},{\"end\":105108,\"start\":105098},{\"end\":105117,\"start\":105108},{\"end\":105125,\"start\":105117},{\"end\":105137,\"start\":105125},{\"end\":105147,\"start\":105137},{\"end\":105422,\"start\":105408},{\"end\":105434,\"start\":105422},{\"end\":105454,\"start\":105434},{\"end\":106059,\"start\":106050},{\"end\":106073,\"start\":106059},{\"end\":106086,\"start\":106073},{\"end\":106106,\"start\":106086},{\"end\":106612,\"start\":106599},{\"end\":106861,\"start\":106853},{\"end\":106872,\"start\":106861},{\"end\":106882,\"start\":106872},{\"end\":107287,\"start\":107279},{\"end\":107298,\"start\":107287},{\"end\":107308,\"start\":107298},{\"end\":107595,\"start\":107587},{\"end\":107606,\"start\":107595},{\"end\":107619,\"start\":107606},{\"end\":107629,\"start\":107619},{\"end\":107639,\"start\":107629},{\"end\":107952,\"start\":107944},{\"end\":107970,\"start\":107952},{\"end\":107984,\"start\":107970},{\"end\":107995,\"start\":107984},{\"end\":108005,\"start\":107995},{\"end\":108017,\"start\":108005},{\"end\":108435,\"start\":108424},{\"end\":108455,\"start\":108435},{\"end\":108467,\"start\":108455},{\"end\":108476,\"start\":108467},{\"end\":108487,\"start\":108476},{\"end\":108496,\"start\":108487},{\"end\":108502,\"start\":108496},{\"end\":109006,\"start\":108997},{\"end\":109020,\"start\":109006},{\"end\":109031,\"start\":109020},{\"end\":109042,\"start\":109031},{\"end\":109052,\"start\":109042},{\"end\":109062,\"start\":109052},{\"end\":109076,\"start\":109062},{\"end\":109519,\"start\":109509},{\"end\":109532,\"start\":109519},{\"end\":109956,\"start\":109946},{\"end\":109969,\"start\":109956},{\"end\":109977,\"start\":109969},{\"end\":110257,\"start\":110245},{\"end\":110267,\"start\":110257},{\"end\":110277,\"start\":110267},{\"end\":110293,\"start\":110277},{\"end\":110574,\"start\":110560},{\"end\":110588,\"start\":110574},{\"end\":110598,\"start\":110588},{\"end\":110607,\"start\":110598},{\"end\":110825,\"start\":110815},{\"end\":110974,\"start\":110963},{\"end\":110994,\"start\":110974},{\"end\":111005,\"start\":110994},{\"end\":111015,\"start\":111005},{\"end\":111350,\"start\":111339},{\"end\":111363,\"start\":111350},{\"end\":111381,\"start\":111363},{\"end\":111687,\"start\":111671}]", "bib_venue": "[{\"end\":92259,\"start\":92143},{\"end\":94044,\"start\":93983},{\"end\":99336,\"start\":99281},{\"end\":100507,\"start\":100493},{\"end\":101105,\"start\":101087},{\"end\":101625,\"start\":101607},{\"end\":102599,\"start\":102371},{\"end\":103830,\"start\":103724},{\"end\":104743,\"start\":104722},{\"end\":105724,\"start\":105642},{\"end\":107043,\"start\":106971},{\"end\":108584,\"start\":108564},{\"end\":109641,\"start\":109592},{\"end\":110323,\"start\":110312},{\"end\":91772,\"start\":91758},{\"end\":92141,\"start\":92010},{\"end\":92590,\"start\":92574},{\"end\":92859,\"start\":92823},{\"end\":93099,\"start\":93058},{\"end\":93459,\"start\":93404},{\"end\":93732,\"start\":93716},{\"end\":93981,\"start\":93905},{\"end\":94482,\"start\":94458},{\"end\":94837,\"start\":94783},{\"end\":95104,\"start\":95089},{\"end\":95369,\"start\":95329},{\"end\":95661,\"start\":95645},{\"end\":96082,\"start\":96030},{\"end\":96522,\"start\":96508},{\"end\":96849,\"start\":96835},{\"end\":97215,\"start\":97195},{\"end\":97558,\"start\":97514},{\"end\":97806,\"start\":97756},{\"end\":98189,\"start\":98146},{\"end\":98546,\"start\":98510},{\"end\":98920,\"start\":98894},{\"end\":99279,\"start\":99209},{\"end\":99717,\"start\":99685},{\"end\":100065,\"start\":100049},{\"end\":100491,\"start\":100431},{\"end\":101085,\"start\":101031},{\"end\":101605,\"start\":101551},{\"end\":102369,\"start\":102141},{\"end\":103309,\"start\":103267},{\"end\":103722,\"start\":103601},{\"end\":104314,\"start\":104281},{\"end\":104720,\"start\":104664},{\"end\":105082,\"start\":104991},{\"end\":105640,\"start\":105565},{\"end\":106238,\"start\":106106},{\"end\":106597,\"start\":106562},{\"end\":106969,\"start\":106882},{\"end\":107430,\"start\":107414},{\"end\":107672,\"start\":107639},{\"end\":108071,\"start\":108017},{\"end\":108562,\"start\":108502},{\"end\":109128,\"start\":109076},{\"end\":109590,\"start\":109532},{\"end\":109993,\"start\":109977},{\"end\":110310,\"start\":110293},{\"end\":110626,\"start\":110607},{\"end\":110813,\"start\":110772},{\"end\":111071,\"start\":111015},{\"end\":111397,\"start\":111381},{\"end\":111599,\"start\":111575},{\"end\":111647,\"start\":111630},{\"end\":111740,\"start\":111706},{\"end\":111807,\"start\":111779},{\"end\":111903,\"start\":111840},{\"end\":112022,\"start\":111971},{\"end\":112112,\"start\":112080}]"}}}, "year": 2023, "month": 12, "day": 17}