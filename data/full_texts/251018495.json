{"id": 251018495, "updated": "2023-10-05 12:12:00.753", "metadata": {"title": "InfiniteNature-Zero: Learning Perpetual View Generation of Natural Scenes from Single Images", "authors": "[{\"first\":\"Zhengqi\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Qianqian\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Noah\",\"last\":\"Snavely\",\"middle\":[]},{\"first\":\"Angjoo\",\"last\":\"Kanazawa\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "We present a method for learning to generate unbounded flythrough videos of natural scenes starting from a single view, where this capability is learned from a collection of single photographs, without requiring camera poses or even multiple views of each scene. To achieve this, we propose a novel self-supervised view generation training paradigm, where we sample and rendering virtual camera trajectories, including cyclic ones, allowing our model to learn stable view generation from a collection of single views. At test time, despite never seeing a video during training, our approach can take a single image and generate long camera trajectories comprised of hundreds of new views with realistic and diverse content. We compare our approach with recent state-of-the-art supervised view generation methods that require posed multi-view videos and demonstrate superior performance and synthesis quality.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2207.11148", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/eccv/LiWSK22", "doi": "10.48550/arxiv.2207.11148"}}, "content": {"source": {"pdf_hash": "df6987f29e53e5f95aec8fe520c16ac1428986b2", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2207.11148v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "2225dad6405ef7efdc916ba9d79e3864a3c28e41", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/df6987f29e53e5f95aec8fe520c16ac1428986b2.txt", "contents": "\nInfiniteNature-Zero: Learning Perpetual View Generation of Natural Scenes from Single Images\n\n\nZhengqi Li \nGoogle Research\n\n\nQianqian Wang \nGoogle Research\n\n\nCornell Tech\nCornell University\n\n\nNoah Snavely \nGoogle Research\n\n\nAngjoo Kanazawa \nBerkeley\n\nInfiniteNature-Zero: Learning Perpetual View Generation of Natural Scenes from Single Images\n\nWe present a method for learning to generate unbounded flythrough videos of natural scenes starting from a single view. This capability is learned from a collection of single photographs, without requiring camera poses or even multiple views of each scene. To achieve this, we propose a novel self-supervised view generation training paradigm where we sample and render virtual camera trajectories, including cyclic camera paths, allowing our model to learn stable view generation from a collection of single views. At test time, despite never having seen a video, our approach can take a single image and generate long camera trajectories comprised of hundreds of new views with realistic and diverse content. We compare our approach with recent state-of-the-art supervised view generation methods that require posed multi-view videos and demonstrate superior performance and synthesis quality. Our project webpage, including video results, is at infinite-nature-zero.github.io.\n\nIntroduction\n\nThere are millions of photos of natural landscapes on the Internet, capturing breathtaking scenery across the world. Recent advances in vision and graphics have led to the ability to turn such images into compelling 3D photos [38,70,30]. However, most prior work can only extrapolate scene content within a limited range of views corresponding to a small head movement. What if, instead, we could step into the picture and fly through the scene like a bird and explore the world in 3D, and see diverse elements like mountain, lakes, and forests appear naturally as we move through the landscape? This challenging new task was recently proposed by Liu et al. [43], who called it perpetual view generation: given a single RGB image, the goal is to synthesize a video depicting a scene captured from a moving camera with an arbitrary long camera trajectory. Methods that tackle this problem have applications in content creation and virtual reality.\n\nHowever, perceptual view generation is a very challenging problem: as the camera travels through the world, we must fill in unseen missing regions in a harmonious manner, and must resolve new details as scene content approaches the camera, all the while maintaining photo-realism and diversity. Liu et al. [43] proposed a supervised solution that generates view sequences in an auto-regressive manner. To train their model, Liu  require a large dataset of video clips of nature scenes along with per-frame camera poses. In essence, perpetual view generation is a video synthesis task, but the requirement of posed video makes data collection very challenging. Obtaining large amounts of diverse, high-quality, and long videos of nature scenes is difficult enough, let alone estimating accurate camera poses on these videos at scale. In contrast, Internet photos of nature landscapes are much easier to collect, and have spurred research into panorama synthesis [74,42], image extrapolation [10,63], image editing [57], and multi-model image synthesis [17,29].\n\nCan we use existing single-image datasets for perpetual 3D view generation? In other words, can we learn view generation by simply observing many photos, without requiring video or camera poses? Training with less powerful supervision would seemingly make this already challenging synthesis task even harder. And doing so is not a straightforward application of prior methods. For instance, prior single-image view synthesis methods either require posed multi-view data [87,61,36], or can only extrapolate within a limited range of viewpoints [38,70,30,28]. Other methods for video synthesis [1,79,92,40] require videos spanning multiple views as training data, and can only generate a limited number of novel frames with no ability to control camera motion at runtime.\n\nIn this work, we present a new method for learning perpetual view generation from only a collection of single photos, without requiring multiple views of each scene or camera information. Despite using much less information, our approach improves upon the visual quality of prior methods that require multiview data. We do so by utilizing virtual camera trajectories and computing losses that enable high-quality perpetual view generation results. Specifically, we first introduce a self-supervised view synthesis strategy that utilizes cyclic virtual camera trajectories, where we know that the synthesized end frame should be identical to the starting frame. This idea provides the network a training signal for generating a single view synthesis step without multi-view data. Second, to learn to generate a long sequence of novel views we employ an adversarial perpetual view generation training technique, encouraging views along a long virtual camera trajectory to be realistic and generation to be stable. The only requirement for our approach is an off-the-shelf monocular depth network to obtain disparity for the initial frame, but this depth network does not need to be trained on our data. In this sense, our method is self-supervised, leveraging underlying pixel statistics from single-image collections. Because we train with no video data whatsoever, we call our approach InfiniteNature-Zero.\n\nWe show that training our model using prior video/view generation methods leads to training divergence or mode collapse. We therefore introduce balanced GAN sampling and progressive trajectory growing strategies that stabilize model training. In addition, to prevent artifacts and drift during inference, we propose a global sky correction technique that yields more consistent and realistic synthesis results along long camera trajectories.\n\nWe evaluate our method on two public nature scene datasets, and compare to recent supervised video synthesis and view generation methods. We demonstrate superior performance compared to state-of-the-art baselines trained on multiview collections, even though our model only requires single-view photos during training. To our knowledge, our work is the first to tackle unbounded 3D view generation for natural scenes trained on 2D image collections, and believe this capability will enable new methods for generative 3D synthesis that leverage more limited supervision.\n\n\nRelated Work\n\nImage extrapolation. An inspiring early approach to infinite view extrapolation, called Infinite Images was proposed by Kaneva et al. [32], which continually retrieves, transforms, and blends imagery from a database to create an infinite 2D landscape. We revisit this idea in a 3D context, which requires inpainting, i.e., filling missing content within an image [25,90,91,44,95], as well as outpainting, extending the image and inferring unseen content outside the image boundaries [85,88,75,4,61,63] in order to generate images from novel camera viewpoints. Super-resolution [21,39] is also an important aspect of perpetual view generation, as approaching a distant object requires synthesizing additional high-resolution detail. Image-specific GAN methods demonstrate super-resolution of textures and natural images as a form of image extrapolation [97,73,67,72]. In contrast to the above methods that address these problems individually, our methods handles inpainting, outpainting, and superresolution jointly. Generative view synthesis. View synthesis is the problem of generating novel views of a scene from existing views. Many view synthesis methods require multiple views of a scene as input [41,7,96,49,19,11,47,60,50,84,45], though recent works can also generate novel views from a single image [9,78,56,77,69,87,31,71,37,62]. These methods often require multi-view posed datasets such as RealEstate10k [96]. However, empowered by advances in neural rendering, recent works show that one can unconditionally generate 3D scene representations for 3D-consistent image synthesis [52,64,54,16,53,23,5]. Many of these methods only require unstructured 2D images for training. When GAN inversion is possible, these methods can also be used for single-image view synthesis, although they have only been demonstrated on specific object categories like faces [6,5]. All of the works above only allow for a limited range of output viewpoints. In contrast, our method can generate new views perpetually, eventually reaching an entirely new distant view, from a single input image. Most related to our work is Liu et al. [43], which also performs perpetual view generation. However, Liu et al. require posed videos during training. Our method can be trained with unstructured 2D images, and also experimentally achieves better view generation diversity and quality. Video synthesis. Our work is also related to video synthesis [13,76], which can be roughly divided into three categories: 1) unconditional video generation [79,51,20,46], which produces a video sequence from an input noise; 2) video prediction [82,83,86,81,27,40], which generates a video sequence from one or more initial observations; and 3) video-to-video synthesis, which maps a video from a source domain to a target domain. Most video prediction methods focus on generating videos of dynamic objects under a static camera [82,18,83,15,89,93,40], e.g., human motion [3] or the movement of robot arms [18]. In contrast, we focus on generating new views of static nature scenes with a moving camera. Several video prediction methods can also simulate moving cameras [14,80,1,40], but unlike our approach, they require long video sequences for training, do not reason about underlying 3D scene geometry, and do not allow for explicit control over camera viewpoint. More recently, Koh et al. propose to navigate and synthesize indoor scenes with controllable camera motion [36]. However, they require ground truth RGBD panoramas as supervision and can only generate novel frames up to 6 steps. Many prior methods in this vein also require 3D inputs, such as voxel grids [24] or dense point clouds [48], whereas we require only a single RGB image.\n\n\nLearning view generation from single-image collections\n\nWe formulate the task of perpetual view generation as follows: given an starting RGB image I 0 , generate an image sequence (\u00ce 1 ,\u00ce 2 , ...,\u00ce t , ...) corresponding to an arbitrary camera trajectory (c 1 , c 2 , ..., c t , ...) starting from I 0 , where the camera viewpoints c t can be specified either algorithmically or via user input.\n\nThe prior Infinite Nature method tackles this problem by decomposing it into three phases: render, refine and repeat [43]. Given an RGBD image (\u00ce t\u22121 ,D t\u22121 ) at camera c t\u22121 , the render phase renders a new view (\u0128 t ,D t ) at c t by transforming and warping (\u00ce t\u22121 ,D t\u22121 ) using a differentiable 3D renderer W. This yields a warped view\n(\u0128 t ,D t ) = W (I t\u22121 , D t\u22121 ), T t t\u22121 , where T t t\u22121 is an SE(3) transformation from c t\u22121 to c t .\nIn the refine phase, the warped RGBD image (\u0128 t ,D t ) is fed into a refinement network F \u03b8 to fill in missing content and add details: (\u00ce t ,D t ) = F \u03b8 (\u0128 t ,D t ). The refined outputs (\u00ce t ,D t ) are then treated as a starting view for the next iteration of the repeat step, from which the process iterates. We refer readers to the original work for more details [43].\n\nTo supervise a view generation model, Infinite Nature trains on video clips of natural scenes, where each video frame has camera pose dervied from structure from motion (SfM) [96]. During training, it randomly chooses one frame in a  Fig. 2. Self-supervised view generation via virtual cameras. Given a starting RGBD image (I0, D0) at viewpoint c0, our training procedure samples two virtual camera trajectories: 1) a cycle to and back from a single virtual view (dashed orange arrows), creating a self-supervised view synthesis signal enforced by the reconstruction loss Lrec. 2) a longer virtual camera path for which we generate corresponding images via the render-refine-repeat process (black dashed arrows and gray cameras). An adversarial loss L adv between the final view (\u00ceT ,DT ) and the real image (I0, D0) enables the network to learn long-range view generation.\n\nvideo clip as the starting view I 0 , and performs the render-refine-repeat process along the provided SfM camera trajectory. At a camera viewpoint c t along the trajectory, a reconstruction loss and an adversarial loss are computed between the image predicted by the network (\u00ce t ,D t ) and the corresponding real RGBD frame (I t , D t ). However, obtaining long nature videos with accurate camera poses is difficult due to often distant or non-Lambertian contents of landscape scenes (e.g., sea, mountain, and sky). In contrast, our method does not require videos at all, whether with camera poses or not.\n\nWe show that 2D photo collections alone provide sufficient supervision signals to learn perceptual view generation, given an off-the-shelf monocular depth prediction network. Our key idea is to sample and render virtual camera trajectories starting from the training image, using the refined depth at each frame to warp it to the next view. We generate two kinds of camera trajectories, illustrated in Fig. 2: First, we produce cyclic camera trajectories that start and end at the training image. Since the start and end frame should be identical, we can use a reconstruction loss on the initial frame as a self-supervised loss (Sec. 3.1). This self-supervision trains our network to do geometry-aware view refinement during view generation. Second, we synthesize longer virtual camera paths and compute an adversarial loss L adv on the final rendered image (Sec. 3.2). This signal trains our network to learn stable view generation over long camera trajectories. The rest of this section describes the two training signals in detail, as well as a sky correction component (Sec. 3.3) that prevents drift in sky regions at test time, yielding more realistic and stable long-range trajectories for nature scenes.  3. Self-supervised view synthesis. From a real RGBD image (I0, D0), we synthesize an input (\u01280,D0) to a refinement model by cycle-rendering through a virtual viewpoint. From left to right: input image; input rendered to a virtual \"previous\" view; virtual view rendered back to the starting viewpoint; final image (\u00ce0,D0) refined with refinement network F \u03b8 , trained to match the starting image.\n\n\nSelf-supervised view synthesis\n\nIn Infinite Nature's supervised learning framework, a reconstruction loss is applied between predicted and corresponding real RGBD images to train the network to refine the inputs rendered from a previous viewpoint. Note that unlike the task of free-form image inpainting [95], this next-view supervision provides a crucial signal for the network to learn to add suitable details and to fill in missing regions around disocclusions using background context, while preserving 3D perspective. Accordingly, we cannot fully simulate the necessary 3D training signals from standard 2D inpainting supervision alone. Instead, our idea is to treat the known real image as the held-out \"next\" view, and simulate a rendered image input from a virtual \"previous\" viewpoint. We implement this idea by rendering a cyclic virtual camera trajectory starting and ending at the known input training view, then comparing the final rendered image at the end of the cycle to the known ground truth input view. In practice, we find that a cycle including just one other virtual view (i.e., warping to a sampled viewpoint, then rendering back to the input viewpoint) is sufficient. Fig. 3 shows an example sequence of views produced in such a cyclic rendering step.\n\nTo implement this idea, we first predict the depth D 0 from a real image I 0 using a standard monocular depth network [58]. We randomly sample a nearby viewpoint with relative camera pose T within a set of maximum values for each camera parameter. We then synthesize the view at virtual pose T by rendering (I 0 , D 0 ) to a new image (I 0 , D 0 ) = W ((I 0 , D 0 ), T ). Next, to encourage the network to learn to fill in missing content at disocclusions, we create a per-pixel binary mask M 0 derived from the rendered depth D 0 at the virtual viewpoint [43,30]. Finally, we render this virtual view with mask (I 0 , D 0 , M 0 ) back to the starting viewpoint via transform T \u22121 : (\u0128 0 ,D 0 ,M 0 ) = W (I 0 , D 0 , M 0 ), T \u22121 where the rendered mask is element-wise multiplied with the rendered RGBD image. Intuitively, this strategy constructs inputs whose pixel statistics, including blur and missing content, are similar to those produced by warping a view forward to a next viewpoint, yielding naturalistic input to view refinement.\n\nThe cycle-rendered images (\u0128 0 ,D 0 ) are then fed into the refinement network F \u03b8 , whose outputs (\u00ce 0 ,D 0 ) = F \u03b8 (\u0128 0 ,D 0 ) are compared to the original RGBD image (I 0 , D 0 ) to yield a reconstruction loss L rec . Because this method does not require actual multiple views or SfM camera poses, we can generate an effectively infinite set of virtual camera motions during training. Because the target view is always an input training view we seek to reconstruct, this approach can be thought of as a self-supervised way of training view synthesis.\n\n\nAdversarial perpetual view generation\n\nAlthough the insight above enables the network to learn to refine a rendered image, directly applying such a network iteratively during inference over multiple steps quickly degenerates (see third row of Fig. 4). As observed by prior work [43], we must train a synthesis model through multiple recurrently-generated camera viewpoints in order for the view generation to be stable. Therefore, in addition to the self-supervised training in Sec. 3.1, we also train on longer virtual camera trajectories. In particular, during training, for a given input RGBD image (I 0 , D 0 ), we randomly sample a virtual camera trajectory (c 1 , c 2 , ..., c T ) starting from (I 0 , D 0 ) by iteratively performing render-refine-repeat T times, yielding a sequence of generated views (\u00ce 1 ,\u00ce 2 , ...,\u00ce T ). To prevent the camera from traversing outof-distribution viewpoints (e.g., crashing into mountains or water) we adopt the auto-pilot algorithm from [43] to sample the camera path. The auto-pilot algorithm determines the pose of the next view based on the proportion of sky and foreground elements as determined by the estimated disparity map at the current viewpoint (see supplemental material for more details). Next, we discuss how we train our model using such sampled virtual camera trajectories.\n\nBalanced GAN sampling. We now have a generated sequence of views along a virtual camera trajectory from the input image, but we do not have the ground truth sequence corresponding to these views. How can we train the model without such ground truth? We find that it is sufficient to compute an adversarial loss that trains a discriminator to distinguish between real images and the synthesized \"fake\" images along the virtual camera path. One straightforward implementation of this idea is to treat all T predictions {\u00ce t ,D t } T t=1 , along the virtual path as fake samples, and sample T real images randomly from the dataset. However, this strategy leads to unstable training, because there is a significant discrepancy in pixel statistics between the generated view sequence and the set of sampled real photos: a generated sequence along a camera trajectory has frames with similar content with smoothly changing viewpoints, whereas randomly sampled real images from the dataset exhibit completely different content and viewpoints. This vast difference in the distribution of images that the discriminator observes leads to unstable training in conditional GAN settings [24]. To address this issue, we propose a simple but effective technique to stabilize the training. Specifically, for a generated sequence, we only feed the discriminator the generated image (\u00ce T ,D T ) at the last camera c T as the fake sample, and use its corresponding input image (I 0 , D 0 ) at the starting view as the real sample, as shown in Fig. 2. In this case, the real and fake sample in each batch will exhibit similar content and viewpoint variations. Further, during each training iteration, we randomly sample the length of virtual camera trajectory T between 1 and a predefined maximum length T max , so that the prediction at any viewpoint and step will be sufficiently trained.\n\nProgressive trajectory growing. We observe that without the guidance of ground truth sequences, the discriminator quickly gains an overwhelming advantage over the generator at the beginning of training. Similarly to issues explored in prior work on 2D GANs [34,33,68], we find that it takes longer for the network to predict plausible views at more distant viewpoints. As a result, the discriminator will easily distinguish real images from fake ones generated at distant views, and hence offer meaningless gradients to the generator. To address this issue, we propose to progressively grow the length of the virtual camera trajectory. We begin with self-supervised view synthesis as described in Sec. 3.1 and pretrain the model for 200K steps. We then increase the maximum length of the virtual camera trajectory T by 1 every 25K iterations until reaching a predefined maximum length T max . This progressive growing strategy ensures that images rendered at a previous viewpoint c t\u22121 have been sufficiently initialized before being fed to the refinement network to generate the view at the next viewpoint c t .\n\n\nGlobal sky correction\n\nThe sky is an indispensable visual element of nature scenes with unique characteristicsit should change much more slowly than the foreground content, since the sky is at infinity. However, we found that the sky synthesized by Infinite Nature can contain unrealistic artifacts after multiple steps. We also found that monocular depth predictions can be inaccurate in sky regions, leading to sky contents to quickly approach the camera in an unrealistic manner.\n\nTherefore, we devise a method to correct the sky regions of refined RGBD images at each test time iteration by leveraging the sky content from the starting view. In particular, we use an off-the-shelf semantic segmentation method [8] and the predicted disparity map to determine soft sky masks for the starting and for each generated view, which we found to be effective in identifying sky pixels. We then correct the sky texture and disparity at every step by alpha blending the homography-warped sky content from the starting view (warped according to the camera rotation's effect on the plane at infinity) with the foreground content in the current generated view. To avoid redundantly outpainting the same sky regions, we expand the input image and disparity through GAN inversion [12,10] to seamlessly create a canvas of higher resolution and field of view. We refer readers to the supplemental material for more details. As shown in the penultimate column of Fig. 4, when applying global sky correction at test time, sky regions exhibit significantly fewer artifacts, resulting in more realistic generated views.\n\n\nNetwork and supervision losses\n\nWe adopt a variant of the CoMod-GAN conditional StyleGAN model [95] as our backbone refinement module F \u03b8 . Specifically, F \u03b8 consists of a global encoder and \nL F = L F adv + \u03bb 1 L rec , L D = L D adv + \u03bb 2 L R1(1)\nwhere L F adv and L D adv are non-saturated GAN losses [22], applied on the last view from the camera trajectory and the corresponding training image. L rec is a reconstruction loss between real images (and depth maps) and their corresponding cycle-synthesized views described in Sec 3.1: L rec = l ||\u03c6 l (\u00ce 0 )\u2212\u03c6 l (I 0 )|| 1 +||D 0 \u2212 D 0 || 1 , where \u03c6 l is a feature map at scale l from different layers of a pretrained VGG network [65]. L R1 is a gradient regularization term that is applied to the discriminator during training [35].\n\n\nExperiments\n\n\nDatasets and baselines\n\nWe evaluate our approach on two public datasets of nature scenes: the Landscape High Quality (LHQ) dataset [74], a collection of 90K landscapes photos collected from the Internet, and the Aerial Coastline Imagery Dataset (ACID) [43], a video dataset of nature scenes with SfM camera poses.\n\nOn the ACID dataset, where posed video data is available, we compare with several state-of-the-art supervised learning methods. Our main baseline is Infinite Nature, the recent state-of-the-art view generation method designed for natural scenes [43]. We also compare with other recent view and video synthesis methods, including geometry-free view synthesis (GFVS) [62] and PixelSynth [61], both of which are based on VQ-VAE [59,17] for long-range view synthesis. Additionally, we compare with two recent video synthesis methods, SLAMP [1] and DIGAN [92]. Table 1. Quantitative comparisons on the ACID test set. \"MV?\" indicates whether a method requires (posed) multi-view data for training. We report view synthesis results with two different types of ground truth (shown as X/Y): sequences rendered with 3D Photos [71] (left), and real sequences (right). KID and Style are scaled by 10  Following their original protocols, we train both methods with video clips of 16 frames from the ACID dataset until convergence. For the LHQ dataset, since there is no multi-view training data and we are unaware of prior methods that can train on single images, we show results from our approach with different configurations, described in more detail in Sec. 4.5.\n\n\nMetrics\n\nWe evaluate synthesis quality on two tasks that we refer to as short-range view synthesis and long-range view generation. By (short-range) view synthesis, we mean the ability to render high fidelity views near a source view, and we report standard error metrics between predicted and ground truth views, including PSNR, SSIM and LPIPS [94]. Since there is no multi-view data for LHQ, we create pseudo ground truth images over a trajectory of length 5 from a global LDI mesh [66] computed using 3D Photos [71]; please see the supplemental material for more details. On the ACID dataset, we report errors on real video sequences where we use SfM-aligned depth maps to render images from each method. We also report results from ground truth sequences created with 3D Photos, since we observe that in real video sequences, pixel misalignments can also be caused by factors like scene motion and errors in monocular depth or camera poses.\n\nFor the task of (long-range) view generation, following prior work [43] we adopt the Fr\u00e9chet Inception Distance (FID), sliding window FID (FID sw ) (with window size \u03c9 = 20), and Kernel Inception Distance (KID) [2] to measure the synthesis quality of different methods. We also introduce a style consistency metric that computes an average style loss between the starting image and each generated view along a camera trajectory. This metric reflects how much the style of a generated sequence deviates from the original image; we evaluate it over a trajectory of length 50. For FID and KID calculations, we compute real statistics from 50K images randomly sampled from each dataset, and calculate fake statistics from \n\n\nImplementation details\n\nWe set the maximum camera trajectory length T max = 10. The weight of R 1 regularization \u03bb 2 is set to 0.15 and 0.004 for the LHQ and ACID datasets, respectively. During training, we found that treating a predicted view along a long virtual trajectory as ground truth and adding a small self-supervised view synthesis loss over these predictions yields more stable view generation results. Therefore we set the reconstruction weight \u03bb 1 = 1 for the input training image at the starting viewpoint, and \u03bb 1 = 0.05 for frames predicted on a camera trajectory. Following [35], we apply lazy regularization to the discriminator gradient regularization every 16 training steps and adopt gradient clipping and exponential moving averaging to update the parameters of the refinement network.\n\nFor all experiments, we train on centrally cropped images of size 128 \u00d7 128 for 1.8M steps with batch size 32 using 8 NVIDIA A100 GPUs, which takes \u223c6 days to converge. During rendering, we use softmax splatting [55] to 3D render images via their depth maps. Our method can also generate higher resolution 512 \u00d7 512 views. Rather than directly training the model at high resolution, which would take an estimate of 3 weeks, we train an extra super-resolution module that takes one day to converge using the same self-supervised learning idea. We refer readers to the supplementary material for more details and high-resolution results. our approach demonstrates the best FID and KID scores, indicating better realism and diversity for our generated views. Our method also achieves the best style consistency score. For the view synthesis task, we achieve the best LPIPS score over the baselines, suggesting higher perceptual quality for our rendered images. We also obtain PSNR and SSIM errors on the ACID test set that are competitive with the supervised learning method from Infinite Nature, which uses a supervised reconstruction loss computed on real sequences.\n\n\nQuantitative comparisons\n\n\nAblation study\n\nWe perform an ablation study on the LHQ test set to analyze the effectiveness of each component in our proposed system. We test the following configurations: (1) a naive baseline where we apply an adversarial loss between all the predictions along a camera trajectory and a set of randomly sampled real photos, and apply geometry re-grounding as introduced in Infinite Nature [43] at test time (Naive); and configurations without: (2) Table 2 and Fig. 4 respectively. Our full system achieves the best view synthesis and view generation performance of these configurations. In particular, adding self-supervised view synthesis significantly improves view synthesis performance. Training via virtual camera trajectories, adopting introduced GAN sampling/training strategies, and applying global sky correction all improve view generation performance by a large margin.\n\n\nQualitative comparisons\n\nFig . 5 shows visual comparisons between our approach, Infinite Nature [43], and GFVS [62] on the ACID test set. GFVS quickly degenerates due to the large distance between the input and generated viewpoints. Infinite Nature can generate plausible views over multiple steps, but the content and style of generated views quickly diverge into an unrelated unimodal scene. Our approach, in contrast, not only generates more consistent views with respect to starting images, but also demonstrates significantly improved synthesis quality and realism. Fig. 6 shows visual comparisons between the naive baseline described in Sec. 4.5 and our full approach. The generated views from the baseline quickly deviate from realism due to ineffective training/inference strategies. In contrast, our full approach can generate much more realistic, consistent, and diverse results over long camera trajectories. For example, the views generated by our approach cover diverse and realistic natural elements such as lakes, trees, and mountains. t=50 t=100 t=200 t=250 t=300 t=400 t=500 \n\n\nSingle-image perpetual view generation\n\nFinally, we visualize our model's ability to generate long view trajectories from a single RGB image in Fig. 7. Although our approach only sees single images during training, it learns to generate long sequences of 500 new views depicting realistic natural landscapes, without suffering significant drift or degeneration. We refer readers to the supplemental video for the full effect and to see results generated from different types of camera trajectories.\n\n\nDiscussion\n\nLimitations and future directions. Our method inherits some limitations from prior video and view generation methods. For example, although our method produces globally consistent background sky, it does not ensure global consistency of foreground content. Addressing this issue potentially requires generating an entire 3D world model, which is an exciting future direction to explore. In addition, as with Infinite Nature, our method can generate unrealistic views if the desired camera trajectory is not seen during training (e.g., in-place rotation). Alternative generative methods such as VQ-VAE [59] and diffusion models [26] may provide promising paths towards addressing this limitation.\n\nConclusion. We presented a method for learning perpetual view generation of natural scenes solely from single-view photos, without requiring camera poses and multi-view data. At test time, given a single RGB image, our approach allows for generating hundreds of new views covering realistic natural scenes along a long camera trajectory. We conduct extensive experiments and demonstrate the improved performance and synthesis quality of our approach over prior supervised approaches. We hope this work demonstrates a new step towards unbounded generative view synthesis from Internet photo collections.\n\nFig.\nFig. 3. Self-supervised view synthesis. From a real RGBD image (I0, D0), we synthesize an input (\u01280,D0) to a refinement model by cycle-rendering through a virtual viewpoint. From left to right: input image; input rendered to a virtual \"previous\" view; virtual view rendered back to the starting viewpoint; final image (\u00ce0,D0) refined with refinement network F \u03b8 , trained to match the starting image.\n\nFig. 4 .\n4Generated views after 50 steps with different settings. Each row shows results for a different input image. From left to right: input view; results without balanced GAN sampling; without the adversarial perpetual view generation strategy; without progressive trajectory growing; without self-supervised view synthesis; without global sky correction; full approach.a StyleGAN generator, where the encoder produces a global latent code z 0 from the input view. At each refine step, we co-modulate intermediate feature layers of the StyleGAN generator via concatenation of z 0 and a latent code z mapped from Gaussian noise. The training loss for the generator and discriminator is:\n\n\nusing balanced GAN sampling (w/o BGS), (3) progressive trajectory growing (w/o PTG), (4) GAN training via long camera trajectories (w/o repeat), (5) applying self-supervised view synthesis (w/o SVS), and (6) employing global sky correction (w/o sky). Quantitative and qualitative comparisons are shown in\n\nFig. 7 .\n7Perpetual view generation. Given a single RGB image, we show the results of our method generating sequences of 500 realistic new views of natural scenes without suffering significant drift. Please see video for animated results.\n\n\net al. (which we will refer to as Infinite Nature), arXiv:2207.11148v1 [cs.CV] 22 Jul 2022t=0 \nt=100 \nt=250 \nt=400 \nt=500 \n\nTrain: Internet Photo Collections \nTest: Novel View Generation from a Single Image \n\nFig. 1. Learning perpetual view generation from single images. Given a single \nRGB image input, our approach generates novel views corresponding to a continuous \nlong camera trajectory, without ever seeing a video during training. \n\n\n\n\nand 10 5 respectively. See Sec. 4.4 for descriptions of baselines.View Synthesis \nView Generation \nMethod \nMV? PSNR\u2191 \nSSIM\u2191 \nLPIPS\u2193 FID\u2193 FIDsw \u2193 KID\u2193 Style\u2193 \n\nGFVS [62] \nYes 11.3/11.9 0.68/0.69 0.33/0.34 109 \n117 \n0.87 14.6 \nPixelSynth [61] Yes 20.0/19.7 0.73/0.70 0.19/0.20 111 \n119 \n1.12 10.54 \nSLAMP [1] \nYes \n-\n-\n-\n114 \n138 \n1.91 15.2 \nDIGAN [92] \nYes \n-\n-\n-\n53.4 57.6 \n0.43 5.85 \nLiu et al. [43] Yes 23.0/21.1 0.83/0.74 0.14/0.18 32.4 37.2 \n0.22 9.37 \nOurs \nNo 23.5/21.1 0.81/0.71 0.10/0.15 19.3 25.1 0.11 5.63 \n\n\n\nTable 2 .\n2Ablation study on the LHQ test set. KID and Style are scaled by 10 and 10 5 respectively. See Sec. 4.5 for a description of each baseline.Configurations \nView Synthesis \nView Generation \nMethod \nLrec L adv PTG BGS Sky PSNR\u2191 SSIM\u2191 LPIPS\u2193 FID \u2193 FIDsw \u2193 KID \u2193 Style\u2193 \n\nNaive \n28.0 \n0.87 \n0.07 \n38.1 \n52.1 \n0.25 6.36 \nw/o BGS \n28.0 \n0.89 \n0.08 \n34.9 \n41.1 \n0.20 6.45 \nw/o PTG \n28.1 \n0.90 \n0.07 \n35.3 \n42.6 \n0.21 6.04 \nw/o repeat \n26.8 \n0.86 \n0.15 \n61.3 \n85.5 \n0.40 8.15 \nw/o SVS \n26.6 \n0.85 \n0.08 \n23.4 \n30.2 \n0.12 6.37 \nw/o sky \n28.3 \n0.90 \n0.07 \n24.8 \n31.3 \n0.11 6.43 \nOurs (full) \n28.4 0.91 0.06 19.4 25.8 0.09 5.91 \n\n70K and 100K generated images on ACID and LHQ respectively, where 700 and \n1000 test images are used as starting images evaluated over 100 steps. Note that \nsince SLAMP and DIGAN do not support camera viewpoint control, we only \nevaluate them on the view generation task. \n\n\n\nTable 1\n1shows quantitative comparisons between our approach and other baselines on the ACID test set. Although the model only observes single images, our approach outperforms the other baselines in view generation on all error metrics, while achieving competitive performance on the view synthesis task. Specifically,GFVS Liu et al. Ours GFVS Liu et al.Fig. 5. Qualitative comparisons on the ACID test set. From left to right, we show generated views over trajectories of length 100 for three methods: GFVS [62], Liu et al. [43] and Ours.Ours \n\nGFVS \n\nLiu et al. \n\nOurs \n\n\n\n\nFig. 6. Qualitative comparisons on the LHQ test set. On two starting views, from left to right, we show generated views over trajectories of length 100 from a naive baseline and our full approach. See Sec. 4.5 for more details.Naive \n\nOurs \n(full) \n\nNaive \n\nOurs \n(full) \n\nNaive \n\nOurs \n(full) \n\n\n\nSlamp: Stochastic latent appearance and motion prediction. A K Akan, E Erdem, A Erdem, F Guney, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Akan, A.K., Erdem, E., Erdem, A., Guney, F.: Slamp: Stochastic latent appearance and motion prediction. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14728-14737 (October 2021)\n\nDemystifying MMD GANs. M Bi\u0144kowski, D J Sutherland, M Arbel, A Gretton, Proc. Int. Conf. on Learning Representations (ICLR). Int. Conf. on Learning Representations (ICLR)Bi\u0144kowski, M., Sutherland, D.J., Arbel, M., Gretton, A.: Demystifying MMD GANs. In: Proc. Int. Conf. on Learning Representations (ICLR) (2018)\n\nActions as space-time shapes. M Blank, L Gorelick, E Shechtman, M Irani, R Basri, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)IEEE2Blank, M., Gorelick, L., Shechtman, E., Irani, M., Basri, R.: Actions as space-time shapes. In: Proc. Int. Conf. on Computer Vision (ICCV). vol. 2, pp. 1395-1402. IEEE (2005)\n\nOconet: Image extrapolation by object completion. R S Bowen, H Chang, C Herrmann, P Teterwak, C Liu, R Zabih, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Bowen, R.S., Chang, H., Herrmann, C., Teterwak, P., Liu, C., Zabih, R.: Oconet: Image extrapolation by object completion. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 2307-2317 (2021)\n\nEfficient geometryaware 3d generative adversarial networks. E R Chan, C Z Lin, M A Chan, K Nagano, B Pan, S D Mello, O Gallo, L Guibas, J Tremblay, S Khamis, T Karras, G Wetzstein, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Chan, E.R., Lin, C.Z., Chan, M.A., Nagano, K., Pan, B., Mello, S.D., Gallo, O., Guibas, L., Tremblay, J., Khamis, S., Karras, T., Wetzstein, G.: Efficient geometry- aware 3d generative adversarial networks. In: Proc. Computer Vision and Pattern Recognition (CVPR) (2022)\n\npi-gan: Periodic implicit generative adversarial networks for 3d-aware image synthesis. E R Chan, M Monteiro, P Kellnhofer, J Wu, G Wetzstein, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Chan, E.R., Monteiro, M., Kellnhofer, P., Wu, J., Wetzstein, G.: pi-gan: Periodic implicit generative adversarial networks for 3d-aware image synthesis. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 5799-5809 (2021)\n\nDepth synthesis and local warps for plausible image-based navigation. G Chaurasia, S Duchene, O Sorkine-Hornung, G Drettakis, ACM Trans. Graphics. 323Chaurasia, G., Duchene, S., Sorkine-Hornung, O., Drettakis, G.: Depth synthesis and local warps for plausible image-based navigation. ACM Trans. Graphics 32(3), 1-12 (2013)\n\nRethinking atrous convolution for semantic image segmentation. L C Chen, G Papandreou, F Schroff, H Adam, arXiv:1706.05587arXiv preprintChen, L.C., Papandreou, G., Schroff, F., Adam, H.: Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587 (2017)\n\nMonocular neural image based rendering with continuous view control. X Chen, J Song, O Hilliges, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Chen, X., Song, J., Hilliges, O.: Monocular neural image based rendering with continuous view control. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 4090-4100 (2019)\n\nIn&out: Diverse image outpainting via gan inversion. Y C Cheng, C H Lin, H Y Lee, J Ren, S Tulyakov, M H Yang, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Cheng, Y.C., Lin, C.H., Lee, H.Y., Ren, J., Tulyakov, S., Yang, M.H.: In&out: Diverse image outpainting via gan inversion. In: Proc. Computer Vision and Pattern Recognition (CVPR) (2022)\n\nExtreme view synthesis. I Choi, O Gallo, A Troccoli, M H Kim, J Kautz, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Choi, I., Gallo, O., Troccoli, A., Kim, M.H., Kautz, J.: Extreme view synthesis. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 7781-7790 (2019)\n\nM J Chong, H Y Lee, D Forsyth, arXiv:2111.01619StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN. arXiv preprintChong, M.J., Lee, H.Y., Forsyth, D.: StyleGAN of All Trades: Image Manipulation with Only Pretrained StyleGAN. arXiv preprint arXiv:2111.01619 (2021)\n\nA Clark, J Donahue, K Simonyan, arXiv:1907.06571Adversarial video generation on complex datasets. arXiv preprintClark, A., Donahue, J., Simonyan, K.: Adversarial video generation on complex datasets. arXiv preprint arXiv:1907.06571 (2019)\n\nEfficient video generation on complex datasets. A Clark, J Donahue, K Simonyan, abs/1907.06571Clark, A., Donahue, J., Simonyan, K.: Efficient video generation on complex datasets. ArXiv abs/1907.06571 (2019)\n\nStochastic video generation with a learned prior. E Denton, R Fergus, Proc. Int. Conf. on Machine Learning (ICML). Int. Conf. on Machine Learning (ICML)PMLRDenton, E., Fergus, R.: Stochastic video generation with a learned prior. In: Proc. Int. Conf. on Machine Learning (ICML). pp. 1174-1183. PMLR (2018)\n\nUnconstrained scene generation with locally conditioned radiance fields. T Devries, M A Bautista, N Srivastava, G W Taylor, J M Susskind, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)DeVries, T., Bautista, M.A., Srivastava, N., Taylor, G.W., Susskind, J.M.: Uncon- strained scene generation with locally conditioned radiance fields. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14304-14313 (2021)\n\nTaming transformers for high-resolution image synthesis. P Esser, R Rombach, B Ommer, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Esser, P., Rombach, R., Ommer, B.: Taming transformers for high-resolution image synthesis. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 12873- 12883 (2021)\n\nUnsupervised learning for physical interaction through video prediction. C Finn, I Goodfellow, S Levine, Neural Information Processing Systems. Finn, C., Goodfellow, I., Levine, S.: Unsupervised learning for physical interaction through video prediction. In: Neural Information Processing Systems (2016)\n\nDeepview: View synthesis with learned gradient descent. J Flynn, M Broxton, P Debevec, M Duvall, G Fyffe, R Overbeck, N Snavely, R Tucker, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Flynn, J., Broxton, M., Debevec, P., DuVall, M., Fyffe, G., Overbeck, R., Snavely, N., Tucker, R.: Deepview: View synthesis with learned gradient descent. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 2367-2376 (2019)\n\nStylevideogan: A temporal generative model using a pretrained stylegan. G Fox, A Tewari, M Elgharib, C Theobalt, Proc. British Machine Vision Conf. (BMVC). British Machine Vision Conf. (BMVC)Fox, G., Tewari, A., Elgharib, M., Theobalt, C.: Stylevideogan: A temporal gen- erative model using a pretrained stylegan. In: Proc. British Machine Vision Conf. (BMVC) (2021)\n\nSuper-resolution from a single image. D Glasner, S Bagon, M Irani, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)IEEEGlasner, D., Bagon, S., Irani, M.: Super-resolution from a single image. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 349-356. IEEE (2009)\n\nGenerative adversarial nets. I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Neural Information Processing Systems. Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Neural Information Processing Systems (2014)\n\nStyleNeRF: A style-based 3d-aware generator for high-resolution image synthesis. J Gu, L Liu, P Wang, C Theobalt, arXiv:2110.08985arXiv preprintGu, J., Liu, L., Wang, P., Theobalt, C.: StyleNeRF: A style-based 3d-aware generator for high-resolution image synthesis. arXiv preprint arXiv:2110.08985 (2021)\n\nGancraft: Unsupervised 3d neural rendering of minecraft worlds. Z Hao, A Mallya, S Belongie, M Y Liu, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Hao, Z., Mallya, A., Belongie, S., Liu, M.Y.: Gancraft: Unsupervised 3d neural rendering of minecraft worlds. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14072-14082 (2021)\n\nScene completion using millions of photographs. J Hays, A A Efros, In: ACM Trans. Graphics (SIGGRAPH North America. Hays, J., Efros, A.A.: Scene completion using millions of photographs. In: ACM Trans. Graphics (SIGGRAPH North America) (2007)\n\nDenoising diffusion probabilistic models. J Ho, A Jain, P Abbeel, Neural Information Processing Systems. 33Ho, J., Jain, A., Abbeel, P.: Denoising diffusion probabilistic models. In: Neural Information Processing Systems. vol. 33, pp. 6840-6851 (2020)\n\nLearning to decompose and disentangle representations for video prediction. J T Hsieh, B Liu, D A Huang, L F Fei-Fei, J C Niebles, Neural Information Processing Systems. 31Hsieh, J.T., Liu, B., Huang, D.A., Fei-Fei, L.F., Niebles, J.C.: Learning to decom- pose and disentangle representations for video prediction. In: Neural Information Processing Systems. vol. 31 (2018)\n\nWorldsheet: Wrapping the world in a 3d sheet for view synthesis from a single image. R Hu, N Ravi, A C Berg, D Pathak, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Hu, R., Ravi, N., Berg, A.C., Pathak, D.: Worldsheet: Wrapping the world in a 3d sheet for view synthesis from a single image. In: Proc. Int. Conf. on Computer Vision (ICCV) (2021)\n\nX Huang, A Mallya, T C Wang, M Y Liu, arXiv:2112.05130Multimodal conditional image synthesis with product-of-experts gans. arXiv preprintHuang, X., Mallya, A., Wang, T.C., Liu, M.Y.: Multimodal conditional image synthesis with product-of-experts gans. arXiv preprint arXiv:2112.05130 (2021)\n\nSlide: Single image 3d photography with soft layering and depth-aware inpainting. V Jampani, H Chang, K Sargent, A Kar, R Tucker, M Krainin, D Kaeser, W T Freeman, D Salesin, B Curless, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Jampani, V., Chang, H., Sargent, K., Kar, A., Tucker, R., Krainin, M., Kaeser, D., Freeman, W.T., Salesin, D., Curless, B., et al.: Slide: Single image 3d photography with soft layering and depth-aware inpainting. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 12518-12527 (2021)\n\nCodenerf: Disentangled neural radiance fields for object categories. W Jang, L Agapito, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Jang, W., Agapito, L.: Codenerf: Disentangled neural radiance fields for object categories. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 12949-12958 (2021)\n\nInfinite images: Creating and exploring a large photorealistic virtual space. B Kaneva, J Sivic, A Torralba, S Avidan, W T Freeman, Proceedings of the IEEE. the IEEEKaneva, B., Sivic, J., Torralba, A., Avidan, S., Freeman, W.T.: Infinite images: Creating and exploring a large photorealistic virtual space. In: Proceedings of the IEEE (2010)\n\nMsg-gan: Multi-scale gradients for generative adversarial networks. A Karnewar, O Wang, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Karnewar, A., Wang, O.: Msg-gan: Multi-scale gradients for generative adversarial networks. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 7799- 7808 (2020)\n\nProgressive growing of gans for improved quality, stability, and variation. T Karras, T Aila, S Laine, J Lehtinen, Proc. Int. Conf. on Learning Representations (ICLR). Int. Conf. on Learning Representations (ICLR)Karras, T., Aila, T., Laine, S., Lehtinen, J.: Progressive growing of gans for improved quality, stability, and variation. In: Proc. Int. Conf. on Learning Representations (ICLR) (2018)\n\nAnalyzing and improving the image quality of stylegan. T Karras, S Laine, M Aittala, J Hellsten, J Lehtinen, T Aila, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Karras, T., Laine, S., Aittala, M., Hellsten, J., Lehtinen, J., Aila, T.: Analyzing and improving the image quality of stylegan. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 8110-8119 (2020)\n\nPathdreamer: A world model for indoor navigation. J Y Koh, H Lee, Y Yang, J Baldridge, P Anderson, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Koh, J.Y., Lee, H., Yang, Y., Baldridge, J., Anderson, P.: Pathdreamer: A world model for indoor navigation. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14738-14748 (2021)\n\nOne shot 3d photography. J Kopf, K Matzen, S Alsisan, O Quigley, F Ge, Y Chong, J Patterson, J M Frahm, S Wu, M Yu, P Zhang, Z He, P Vajda, A Saraf, M Cohen, ACM Transactions on Graphics. 394Proceedings of ACM SIGGRAPH)Kopf, J., Matzen, K., Alsisan, S., Quigley, O., Ge, F., Chong, Y., Patterson, J., Frahm, J.M., Wu, S., Yu, M., Zhang, P., He, Z., Vajda, P., Saraf, A., Cohen, M.: One shot 3d photography. ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH) 39(4) (2020)\n\nOne shot 3d photography. J Kopf, K Matzen, S Alsisan, O Quigley, F Ge, Y Chong, J Patterson, J M Frahm, S Wu, M Yu, ACM Trans. Graphics (SIGGRAPH North America. Kopf, J., Matzen, K., Alsisan, S., Quigley, O., Ge, F., Chong, Y., Patterson, J., Frahm, J.M., Wu, S., Yu, M., et al.: One shot 3d photography. In: ACM Trans. Graphics (SIGGRAPH North America) (2020)\n\nPhoto-realistic single image super-resolution using a generative adversarial network. C Ledig, L Theis, F Husz\u00e1r, J Caballero, A Cunningham, A Acosta, A Aitken, A Tejani, J Totz, Z Wang, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Ledig, C., Theis, L., Husz\u00e1r, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et al.: Photo-realistic single image super-resolution using a generative adversarial network. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 4681-4690 (2017)\n\nRevisiting hierarchical approach for persistent long-term video prediction. W Lee, W Jung, H Zhang, T Chen, J Y Koh, T Huang, H Yoon, H Lee, S Hong, arXiv:2104.06697arXiv preprintLee, W., Jung, W., Zhang, H., Chen, T., Koh, J.Y., Huang, T., Yoon, H., Lee, H., Hong, S.: Revisiting hierarchical approach for persistent long-term video prediction. arXiv preprint arXiv:2104.06697 (2021)\n\nLight field rendering. M Levoy, P Hanrahan, ACM Trans. Graphics (SIG-GRAPH North America. Levoy, M., Hanrahan, P.: Light field rendering. In: ACM Trans. Graphics (SIG- GRAPH North America) (1996)\n\nInfinityGAN: Towards infinite-pixel image synthesis. C H Lin, Y C Cheng, H Y Lee, S Tulyakov, M H Yang, Proc. Int. Conf. on Learning Representations (ICLR. Int. Conf. on Learning Representations (ICLRLin, C.H., Cheng, Y.C., Lee, H.Y., Tulyakov, S., Yang, M.H.: InfinityGAN: Towards infinite-pixel image synthesis. In: Proc. Int. Conf. on Learning Representations (ICLR) (2022)\n\nInfinite nature: Perpetual view generation of natural scenes from a single image. A Liu, R Tucker, V Jampani, A Makadia, N Snavely, A Kanazawa, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Liu, A., Tucker, R., Jampani, V., Makadia, A., Snavely, N., Kanazawa, A.: Infinite nature: Perpetual view generation of natural scenes from a single image. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14458-14467 (2021)\n\nPd-gan: Probabilistic diverse gan for image inpainting. H Liu, Z Wan, W Huang, Y Song, X Han, J Liao, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Liu, H., Wan, Z., Huang, W., Song, Y., Han, X., Liao, J.: Pd-gan: Probabilistic diverse gan for image inpainting. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 9371-9381 (2021)\n\nL Liu, J Gu, K Z Lin, T S Chua, C Theobalt, Neural sparse voxel fields. NeurIPS. Liu, L., Gu, J., Lin, K.Z., Chua, T.S., Theobalt, C.: Neural sparse voxel fields. NeurIPS (2020)\n\nContent-aware gan compression. Y Liu, Z Shu, Y Li, Z Lin, F Perazzi, S Y Kung, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Liu, Y., Shu, Z., Li, Y., Lin, Z., Perazzi, F., Kung, S.Y.: Content-aware gan compression. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 12156-12166 (2021)\n\nS Lombardi, T Simon, J Saragih, G Schwartz, A Lehrmann, Y Sheikh, Neural volumes: Learning dynamic renderable volumes from images. 38Lombardi, S., Simon, T., Saragih, J., Schwartz, G., Lehrmann, A., Sheikh, Y.: Neural volumes: Learning dynamic renderable volumes from images. ACM Trans. Graph. 38(4), 65:1-65:14 (Jul 2019)\n\nWorld-consistent video-to-video synthesis. A Mallya, T C Wang, K Sapra, M Y Liu, Proc. European Conf. on Computer Vision (ECCV). European Conf. on Computer Vision (ECCV)SpringerMallya, A., Wang, T.C., Sapra, K., Liu, M.Y.: World-consistent video-to-video synthesis. In: Proc. European Conf. on Computer Vision (ECCV). pp. 359-378. Springer (2020)\n\nLocal light field fusion: Practical view synthesis with prescriptive sampling guidelines. B Mildenhall, P P Srinivasan, R Ortiz-Cayon, N K Kalantari, R Ramamoorthi, R Ng, A Kar, ACM Trans. Graphics (SIGGRAPH North America. Mildenhall, B., Srinivasan, P.P., Ortiz-Cayon, R., Kalantari, N.K., Ramamoorthi, R., Ng, R., Kar, A.: Local light field fusion: Practical view synthesis with prescriptive sampling guidelines. In: ACM Trans. Graphics (SIGGRAPH North America) (2019)\n\nNerf: Representing scenes as neural radiance fields for view synthesis. B Mildenhall, P P Srinivasan, M Tancik, J T Barron, R Ramamoorthi, R Ng, Proc. European Conf. on Computer Vision (ECCV). European Conf. on Computer Vision (ECCV)SpringerMildenhall, B., Srinivasan, P.P., Tancik, M., Barron, J.T., Ramamoorthi, R., Ng, R.: Nerf: Representing scenes as neural radiance fields for view synthesis. In: Proc. European Conf. on Computer Vision (ECCV). pp. 405-421. Springer (2020)\n\nTemporal shift gan for large scale video generation. A Munoz, M Zolfaghari, M Argus, T Brox, Proc. Winter Conf. on Computer Vision (WACV). Winter Conf. on Computer Vision (WACV)Munoz, A., Zolfaghari, M., Argus, M., Brox, T.: Temporal shift gan for large scale video generation. In: Proc. Winter Conf. on Computer Vision (WACV). pp. 3179-3188 (2021)\n\nHologan: Unsupervised learning of 3d representations from natural images. T Nguyen-Phuoc, C Li, L Theis, C Richardt, Y L Yang, The IEEE International Conference on Computer Vision (ICCV). Nguyen-Phuoc, T., Li, C., Theis, L., Richardt, C., Yang, Y.L.: Hologan: Unsuper- vised learning of 3d representations from natural images. In: The IEEE International Conference on Computer Vision (ICCV) (Nov 2019)\n\nCampari: Camera-aware decomposed generative neural radiance fields. M Niemeyer, A Geiger, 2021 International Conference on 3D Vision (3DV). IEEENiemeyer, M., Geiger, A.: Campari: Camera-aware decomposed generative neural radiance fields. In: 2021 International Conference on 3D Vision (3DV). pp. 951-961. IEEE (2021)\n\nGiraffe: Representing scenes as compositional generative neural feature fields. M Niemeyer, A Geiger, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Niemeyer, M., Geiger, A.: Giraffe: Representing scenes as compositional generative neural feature fields. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 11453-11464 (2021)\n\nSoftmax splatting for video frame interpolation. S Niklaus, F Liu, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Niklaus, S., Liu, F.: Softmax splatting for video frame interpolation. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 5437-5446 (2020)\n\n3D Ken Burns effect from a single image. S Niklaus, L Mai, J Yang, F Liu, ACM Trans. Graphics. 386Niklaus, S., Mai, L., Yang, J., Liu, F.: 3D Ken Burns effect from a single image. ACM Trans. Graphics 38(6), 1-15 (2019)\n\nSwapping autoencoder for deep image manipulation. T Park, J Y Zhu, O Wang, J Lu, E Shechtman, A Efros, R Zhang, Neural Information Processing Systems. Park, T., Zhu, J.Y., Wang, O., Lu, J., Shechtman, E., Efros, A., Zhang, R.: Swap- ping autoencoder for deep image manipulation. In: Neural Information Processing Systems. pp. 7198-7211 (2020)\n\nTowards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer. R Ranftl, K Lasinger, D Hafner, K Schindler, V Koltun, Trans. Pattern Analysis and Machine Intelligence. Ranftl, R., Lasinger, K., Hafner, D., Schindler, K., Koltun, V.: Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer. Trans. Pattern Analysis and Machine Intelligence (2020)\n\nGenerating diverse high-fidelity images with vq-vae-2. A Razavi, A Van Den Oord, O Vinyals, Neural Information Processing Systems. 32Razavi, A., Van den Oord, A., Vinyals, O.: Generating diverse high-fidelity images with vq-vae-2. Neural Information Processing Systems 32 (2019)\n\nFree view synthesis. G Riegler, V Koltun, Proc. European Conf. on Computer Vision (ECCV. European Conf. on Computer Vision (ECCVRiegler, G., Koltun, V.: Free view synthesis. In: Proc. European Conf. on Computer Vision (ECCV) (2020)\n\nPixelsynth: Generating a 3d-consistent experience from a single image. C Rockwell, D F Fouhey, J Johnson, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Rockwell, C., Fouhey, D.F., Johnson, J.: Pixelsynth: Generating a 3d-consistent experience from a single image. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14104-14113 (2021)\n\nGeometry-free view synthesis: Transformers and no 3d priors. R Rombach, P Esser, B Ommer, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Rombach, R., Esser, P., Ommer, B.: Geometry-free view synthesis: Transformers and no 3d priors. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14356-14366 (2021)\n\nC Saharia, W Chan, H Chang, C A Lee, J Ho, T Salimans, D J Fleet, M Norouzi, arXiv:2111.05826Palette: Image-to-image diffusion models. arXiv preprintSaharia, C., Chan, W., Chang, H., Lee, C.A., Ho, J., Salimans, T., Fleet, D.J., Norouzi, M.: Palette: Image-to-image diffusion models. arXiv preprint arXiv:2111.05826 (2021)\n\nGraf: Generative radiance fields for 3d-aware image synthesis. K Schwarz, Y Liao, M Niemeyer, A Geiger, Neural Information Processing Systems. 33Schwarz, K., Liao, Y., Niemeyer, M., Geiger, A.: Graf: Generative radiance fields for 3d-aware image synthesis. Neural Information Processing Systems 33, 20154-20166 (2020)\n\nGoing deeper in spiking neural networks: Vgg and residual architectures. A Sengupta, Y Ye, R Wang, C Liu, K Roy, Frontiers in Neuroscience. 1395Sengupta, A., Ye, Y., Wang, R., Liu, C., Roy, K.: Going deeper in spiking neural networks: Vgg and residual architectures. Frontiers in Neuroscience 13, 95 (2019)\n\nLayered depth images. J Shade, S Gortler, L W He, R Szeliski, ACM Trans. Graphics (SIGGRAPH North America). pp. Shade, J., Gortler, S., He, L.w., Szeliski, R.: Layered depth images. In: ACM Trans. Graphics (SIGGRAPH North America). pp. 231-242 (1998)\n\nSingan: Learning a generative model from a single natural image. T R Shaham, T Dekel, T Michaeli, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Shaham, T.R., Dekel, T., Michaeli, T.: Singan: Learning a generative model from a single natural image. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 4570-4580 (2019)\n\nSingan: Learning a generative model from a single natural image. T R Shaham, T Dekel, T Michaeli, Proc. Int. Conf. on Computer Vision (ICCV. Int. Conf. on Computer Vision (ICCVShaham, T.R., Dekel, T., Michaeli, T.: Singan: Learning a generative model from a single natural image. Proc. Int. Conf. on Computer Vision (ICCV) pp. 4569-4579 (2019)\n\nLight field reconstruction using sparsity in the continuous fourier domain. L Shi, H Hassanieh, A Davis, D Katabi, F Durand, In: ACM Trans. Graphics (SIGGRAPH North America. Shi, L., Hassanieh, H., Davis, A., Katabi, D., Durand, F.: Light field reconstruc- tion using sparsity in the continuous fourier domain. In: ACM Trans. Graphics (SIGGRAPH North America) (2014)\n\nphotography using context-aware layered depth inpainting. M L Shih, S Y Su, J Kopf, J B Huang, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Shih, M.L., Su, S.Y., Kopf, J., Huang, J.B.: 3d photography using context-aware layered depth inpainting. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 8028-8038 (2020)\n\n3D photography using context-aware layered depth inpainting. M L Shih, S Y Su, J Kopf, J B Huang, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Shih, M.L., Su, S.Y., Kopf, J., Huang, J.B.: 3D photography using context-aware layered depth inpainting. In: Proc. Computer Vision and Pattern Recognition (CVPR) (2020)\n\nIngan: Capturing and remapping the\" dna\" of a natural image. A Shocher, S Bagon, P Isola, M Irani, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Shocher, A., Bagon, S., Isola, P., Irani, M.: Ingan: Capturing and remapping the\" dna\" of a natural image. In: Proc. Int. Conf. on Computer Vision (ICCV) (2019)\n\nzero-shot\" super-resolution using deep internal learning. A Shocher, N Cohen, M Irani, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Shocher, A., Cohen, N., Irani, M.: \"zero-shot\" super-resolution using deep internal learning. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 3118- 3126 (2018)\n\nAligning latent and image spaces to connect the unconnectable. I Skorokhodov, G Sotnikov, M Elhoseiny, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Skorokhodov, I., Sotnikov, G., Elhoseiny, M.: Aligning latent and image spaces to connect the unconnectable. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 14144-14153 (2021)\n\nBoundless: Generative adversarial networks for image extension. P Teterwak, A Sarna, D Krishnan, A Maschinot, D Belanger, C Liu, W T Freeman, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Teterwak, P., Sarna, A., Krishnan, D., Maschinot, A., Belanger, D., Liu, C., Freeman, W.T.: Boundless: Generative adversarial networks for image extension. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 10521-10530 (2019)\n\nA good image generator is what you need for high-resolution video synthesis. Y Tian, J Ren, M Chai, K Olszewski, X Peng, D N Metaxas, S Tulyakov, arXiv:2104.15069arXiv preprintTian, Y., Ren, J., Chai, M., Olszewski, K., Peng, X., Metaxas, D.N., Tulyakov, S.: A good image generator is what you need for high-resolution video synthesis. arXiv preprint arXiv:2104.15069 (2021)\n\nSingle-view view synthesis with multiplane images. R Tucker, N Snavely, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Tucker, R., Snavely, N.: Single-view view synthesis with multiplane images. In: Proc. Computer Vision and Pattern Recognition (CVPR) (June 2020)\n\nLayer-structured 3d scene inference via view synthesis. S Tulsiani, R Tucker, N Snavely, Proc. European Conf. on Computer Vision (ECCV). European Conf. on Computer Vision (ECCV)Tulsiani, S., Tucker, R., Snavely, N.: Layer-structured 3d scene inference via view synthesis. In: Proc. European Conf. on Computer Vision (ECCV). pp. 302-317 (2018)\n\nMocogan: Decomposing motion and content for video generation. S Tulyakov, M Y Liu, X Yang, J Kautz, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Tulyakov, S., Liu, M.Y., Yang, X., Kautz, J.: Mocogan: Decomposing motion and content for video generation. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 1526-1535 (2018)\n\nHigh fidelity video prediction with large stochastic recurrent neural networks. R Villegas, A Pathak, H Kannan, D Erhan, Q V Le, H Lee, Neural Information Processing Systems. Villegas, R., Pathak, A., Kannan, H., Erhan, D., Le, Q.V., Lee, H.: High fidelity video prediction with large stochastic recurrent neural networks. In: Neural Information Processing Systems (2019)\n\nDecomposing motion and content for natural video sequence prediction. R Villegas, J Yang, S Hong, X Lin, H Lee, arXiv:1706.08033arXiv preprintVillegas, R., Yang, J., Hong, S., Lin, X., Lee, H.: Decomposing motion and content for natural video sequence prediction. arXiv preprint arXiv:1706.08033 (2017)\n\nGenerating videos with scene dynamics. C Vondrick, H Pirsiavash, A Torralba, Neural Information Processing Systems. Vondrick, C., Pirsiavash, H., Torralba, A.: Generating videos with scene dynamics. In: Neural Information Processing Systems (2016)\n\nGenerating the future with adversarial transformers. C Vondrick, A Torralba, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Vondrick, C., Torralba, A.: Generating the future with adversarial transformers. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 1020-1028 (2017)\n\nIbrnet: Learning multi-view image-based rendering. Q Wang, Z Wang, K Genova, P P Srinivasan, H Zhou, J T Barron, R Martin-Brualla, N Snavely, T Funkhouser, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Wang, Q., Wang, Z., Genova, K., Srinivasan, P.P., Zhou, H., Barron, J.T., Martin- Brualla, R., Snavely, N., Funkhouser, T.: Ibrnet: Learning multi-view image-based rendering. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 4690- 4699 (2021)\n\nWide-context semantic image extrapolation. Y Wang, X Tao, X Shen, J Jia, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Wang, Y., Tao, X., Shen, X., Jia, J.: Wide-context semantic image extrapolation. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 1399-1408 (2019)\n\nPredRNN: Recurrent neural networks for predictive learning using spatiotemporal LSTMs. Y Wang, M Long, J Wang, Z Gao, P S Yu, Neural Information Processing Systems. Wang, Y., Long, M., Wang, J., Gao, Z., Yu, P.S.: PredRNN: Recurrent neural net- works for predictive learning using spatiotemporal LSTMs. In: Neural Information Processing Systems. pp. 879-888 (2017)\n\nSynsin: End-to-end view synthesis from a single image. O Wiles, G Gkioxari, R Szeliski, J Johnson, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Wiles, O., Gkioxari, G., Szeliski, R., Johnson, J.: Synsin: End-to-end view synthesis from a single image. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 7467-7477 (2020)\n\nVery long natural scenery image prediction by outpainting. Z Yang, J Dong, P Liu, Y Yang, S Yan, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Yang, Z., Dong, J., Liu, P., Yang, Y., Yan, S.: Very long natural scenery image prediction by outpainting. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 10561-10570 (2019)\n\nCompositional video prediction. Y Ye, M Singh, A Gupta, S Tulsiani, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Ye, Y., Singh, M., Gupta, A., Tulsiani, S.: Compositional video prediction. In: Proc. Int. Conf. on Computer Vision (ICCV) (2019)\n\nGenerative image inpainting with contextual attention. J Yu, Z Lin, J Yang, X Shen, X Lu, T S Huang, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Yu, J., Lin, Z., Yang, J., Shen, X., Lu, X., Huang, T.S.: Generative image inpainting with contextual attention. In: Proc. Computer Vision and Pattern Recognition (CVPR). pp. 5505-5514 (2018)\n\nFree-form image inpainting with gated convolution. J Yu, Z Lin, J Yang, X Shen, X Lu, T S Huang, Proc. Int. Conf. on Computer Vision (ICCV). Int. Conf. on Computer Vision (ICCV)Yu, J., Lin, Z., Yang, J., Shen, X., Lu, X., Huang, T.S.: Free-form image inpainting with gated convolution. In: Proc. Int. Conf. on Computer Vision (ICCV). pp. 4471-4480 (2019)\n\nGenerating videos with dynamics-aware implicit generative adversarial networks. S Yu, J Tack, S Mo, H Kim, J Kim, J W Ha, J Shin, Proc. Int. Conf. on Learning Representations (ICLR. Int. Conf. on Learning Representations (ICLRYu, S., Tack, J., Mo, S., Kim, H., Kim, J., Ha, J.W., Shin, J.: Generating videos with dynamics-aware implicit generative adversarial networks. In: Proc. Int. Conf. on Learning Representations (ICLR) (2022)\n\nGenerating videos with dynamics-aware implicit generative adversarial networks. S Yu, J Tack, S Mo, H Kim, J Kim, J W Ha, J Shin, The Tenth International Conference on Learning Representations. Yu, S., Tack, J., Mo, S., Kim, H., Kim, J., Ha, J.W., Shin, J.: Generating videos with dynamics-aware implicit generative adversarial networks. In: The Tenth Inter- national Conference on Learning Representations (2022)\n\nThe unreasonable effectiveness of deep features as a perceptual metric. R Zhang, P Isola, A A Efros, E Shechtman, O Wang, Proc. Computer Vision and Pattern Recognition (CVPR). Computer Vision and Pattern Recognition (CVPR)Zhang, R., Isola, P., Efros, A.A., Shechtman, E., Wang, O.: The unreasonable effectiveness of deep features as a perceptual metric. In: Proc. Computer Vision and Pattern Recognition (CVPR) (2018)\n\nLarge scale image completion via co-modulated generative adversarial networks. S Zhao, J Cui, Y Sheng, Y Dong, X Liang, E I Chang, Y Xu, Proc. Int. Conf. on Learning Representations (ICLR. Int. Conf. on Learning Representations (ICLRZhao, S., Cui, J., Sheng, Y., Dong, Y., Liang, X., Chang, E.I., Xu, Y.: Large scale image completion via co-modulated generative adversarial networks. In: Proc. Int. Conf. on Learning Representations (ICLR) (2021)\n\nStereo magnification: Learning view synthesis using multiplane images. T Zhou, R Tucker, J Flynn, G Fyffe, N Snavely, In: ACM Trans. Graphics (SIGGRAPH North America). Zhou, T., Tucker, R., Flynn, J., Fyffe, G., Snavely, N.: Stereo magnification: Learning view synthesis using multiplane images. In: ACM Trans. Graphics (SIGGRAPH North America) (2018)\n\nNon-stationary texture synthesis by adversarial expansion. Y Zhou, Z Zhu, X Bai, D Lischinski, D Cohen-Or, H Huang, In: ACM Trans. Graphics (SIGGRAPH North America). Zhou, Y., Zhu, Z., Bai, X., Lischinski, D., Cohen-Or, D., Huang, H.: Non-stationary texture synthesis by adversarial expansion. In: ACM Trans. Graphics (SIGGRAPH North America) (2018)\n", "annotations": {"author": "[{\"end\":125,\"start\":96},{\"end\":192,\"start\":126},{\"end\":224,\"start\":193},{\"end\":251,\"start\":225}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":104},{\"end\":139,\"start\":135},{\"end\":205,\"start\":198},{\"end\":240,\"start\":232}]", "author_first_name": "[{\"end\":103,\"start\":96},{\"end\":134,\"start\":126},{\"end\":197,\"start\":193},{\"end\":231,\"start\":225}]", "author_affiliation": "[{\"end\":124,\"start\":108},{\"end\":157,\"start\":141},{\"end\":191,\"start\":159},{\"end\":223,\"start\":207},{\"end\":250,\"start\":242}]", "title": "[{\"end\":93,\"start\":1},{\"end\":344,\"start\":252}]", "venue": null, "abstract": "[{\"end\":1325,\"start\":346}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b37\"},\"end\":1571,\"start\":1567},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":1574,\"start\":1571},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":1577,\"start\":1574},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2003,\"start\":1999},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2599,\"start\":2595},{\"end\":2716,\"start\":2713},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":3254,\"start\":3250},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3257,\"start\":3254},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3283,\"start\":3279},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":3286,\"start\":3283},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3306,\"start\":3302},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3344,\"start\":3340},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3347,\"start\":3344},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":3824,\"start\":3820},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":3827,\"start\":3824},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3830,\"start\":3827},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3897,\"start\":3893},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":3900,\"start\":3897},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3903,\"start\":3900},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3906,\"start\":3903},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3945,\"start\":3942},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":3948,\"start\":3945},{\"attributes\":{\"ref_id\":\"b91\"},\"end\":3951,\"start\":3948},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3954,\"start\":3951},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6696,\"start\":6692},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6925,\"start\":6921},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":6928,\"start\":6925},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":6931,\"start\":6928},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6934,\"start\":6931},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":6937,\"start\":6934},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":7045,\"start\":7041},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":7048,\"start\":7045},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":7051,\"start\":7048},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7053,\"start\":7051},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":7056,\"start\":7053},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":7059,\"start\":7056},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7139,\"start\":7135},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":7142,\"start\":7139},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":7414,\"start\":7410},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":7417,\"start\":7414},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":7420,\"start\":7417},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":7423,\"start\":7420},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7764,\"start\":7760},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7766,\"start\":7764},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":7769,\"start\":7766},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":7772,\"start\":7769},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7775,\"start\":7772},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7778,\"start\":7775},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":7781,\"start\":7778},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":7784,\"start\":7781},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":7787,\"start\":7784},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":7790,\"start\":7787},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":7793,\"start\":7790},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7868,\"start\":7865},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":7871,\"start\":7868},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":7874,\"start\":7871},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":7877,\"start\":7874},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":7880,\"start\":7877},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":7883,\"start\":7880},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7886,\"start\":7883},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":7889,\"start\":7886},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7892,\"start\":7889},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":7895,\"start\":7892},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":7977,\"start\":7973},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8150,\"start\":8146},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":8153,\"start\":8150},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":8156,\"start\":8153},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8159,\"start\":8156},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":8162,\"start\":8159},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8165,\"start\":8162},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8167,\"start\":8165},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8423,\"start\":8420},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8425,\"start\":8423},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8683,\"start\":8679},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8989,\"start\":8985},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":8992,\"start\":8989},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":9084,\"start\":9080},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":9087,\"start\":9084},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9090,\"start\":9087},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":9093,\"start\":9090},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":9172,\"start\":9168},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":9175,\"start\":9172},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":9178,\"start\":9175},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":9181,\"start\":9178},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9184,\"start\":9181},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9187,\"start\":9184},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":9456,\"start\":9452},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9459,\"start\":9456},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":9462,\"start\":9459},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9465,\"start\":9462},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":9468,\"start\":9465},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":9471,\"start\":9468},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9474,\"start\":9471},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9498,\"start\":9495},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9533,\"start\":9529},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9697,\"start\":9693},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":9700,\"start\":9697},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9702,\"start\":9700},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9705,\"start\":9702},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10002,\"start\":9998},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10199,\"start\":10195},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":10226,\"start\":10222},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10791,\"start\":10787},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11485,\"start\":11481},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":11667,\"start\":11663},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14052,\"start\":14051},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":14890,\"start\":14886},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":15981,\"start\":15977},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":16419,\"start\":16415},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":16422,\"start\":16419},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":17738,\"start\":17734},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":18440,\"start\":18436},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":19968,\"start\":19964},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":20923,\"start\":20919},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":20926,\"start\":20923},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":20929,\"start\":20926},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22494,\"start\":22491},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23050,\"start\":23046},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":23053,\"start\":23050},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":23481,\"start\":23477},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23689,\"start\":23685},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":24069,\"start\":24065},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":24167,\"start\":24163},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":24320,\"start\":24316},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24441,\"start\":24437},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24749,\"start\":24745},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":24869,\"start\":24865},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":24889,\"start\":24885},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":24929,\"start\":24925},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":24932,\"start\":24929},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":25039,\"start\":25036},{\"attributes\":{\"ref_id\":\"b91\"},\"end\":25054,\"start\":25050},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":25320,\"start\":25316},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25387,\"start\":25385},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":26104,\"start\":26100},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":26243,\"start\":26239},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":26273,\"start\":26269},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":26772,\"start\":26768},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26915,\"start\":26912},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":28017,\"start\":28013},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":28447,\"start\":28443},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":29822,\"start\":29818},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":30412,\"start\":30408},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":30427,\"start\":30423},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":32525,\"start\":32521},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":32551,\"start\":32547}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":33626,\"start\":33220},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34317,\"start\":33627},{\"attributes\":{\"id\":\"fig_3\"},\"end\":34624,\"start\":34318},{\"attributes\":{\"id\":\"fig_5\"},\"end\":34864,\"start\":34625},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":35309,\"start\":34865},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":35830,\"start\":35310},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":36734,\"start\":35831},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":37309,\"start\":36735},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":37608,\"start\":37310}]", "paragraph": "[{\"end\":2287,\"start\":1341},{\"end\":3348,\"start\":2289},{\"end\":4119,\"start\":3350},{\"end\":5527,\"start\":4121},{\"end\":5970,\"start\":5529},{\"end\":6541,\"start\":5972},{\"end\":10271,\"start\":6558},{\"end\":10668,\"start\":10330},{\"end\":11009,\"start\":10670},{\"end\":11486,\"start\":11115},{\"end\":12361,\"start\":11488},{\"end\":12970,\"start\":12363},{\"end\":14579,\"start\":12972},{\"end\":15857,\"start\":14614},{\"end\":16898,\"start\":15859},{\"end\":17453,\"start\":16900},{\"end\":18788,\"start\":17495},{\"end\":20660,\"start\":18790},{\"end\":21774,\"start\":20662},{\"end\":22259,\"start\":21800},{\"end\":23379,\"start\":22261},{\"end\":23573,\"start\":23414},{\"end\":24168,\"start\":23630},{\"end\":24498,\"start\":24209},{\"end\":25753,\"start\":24500},{\"end\":26699,\"start\":25765},{\"end\":27419,\"start\":26701},{\"end\":28229,\"start\":27446},{\"end\":29396,\"start\":28231},{\"end\":30309,\"start\":29442},{\"end\":31404,\"start\":30337},{\"end\":31905,\"start\":31447},{\"end\":32615,\"start\":31920},{\"end\":33219,\"start\":32617}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11114,\"start\":11010},{\"attributes\":{\"id\":\"formula_1\"},\"end\":23629,\"start\":23574}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":25063,\"start\":25056},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":29884,\"start\":29877}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1339,\"start\":1327},{\"attributes\":{\"n\":\"2\"},\"end\":6556,\"start\":6544},{\"attributes\":{\"n\":\"3\"},\"end\":10328,\"start\":10274},{\"attributes\":{\"n\":\"3.1\"},\"end\":14612,\"start\":14582},{\"attributes\":{\"n\":\"3.2\"},\"end\":17493,\"start\":17456},{\"attributes\":{\"n\":\"3.3\"},\"end\":21798,\"start\":21777},{\"attributes\":{\"n\":\"3.4\"},\"end\":23412,\"start\":23382},{\"attributes\":{\"n\":\"4\"},\"end\":24182,\"start\":24171},{\"attributes\":{\"n\":\"4.1\"},\"end\":24207,\"start\":24185},{\"attributes\":{\"n\":\"4.2\"},\"end\":25763,\"start\":25756},{\"attributes\":{\"n\":\"4.3\"},\"end\":27444,\"start\":27422},{\"attributes\":{\"n\":\"4.4\"},\"end\":29423,\"start\":29399},{\"attributes\":{\"n\":\"4.5\"},\"end\":29440,\"start\":29426},{\"attributes\":{\"n\":\"4.6\"},\"end\":30335,\"start\":30312},{\"attributes\":{\"n\":\"4.7\"},\"end\":31445,\"start\":31407},{\"attributes\":{\"n\":\"5\"},\"end\":31918,\"start\":31908},{\"end\":33225,\"start\":33221},{\"end\":33636,\"start\":33628},{\"end\":34634,\"start\":34626},{\"end\":35841,\"start\":35832},{\"end\":36743,\"start\":36736}]", "table": "[{\"end\":35309,\"start\":34957},{\"end\":35830,\"start\":35378},{\"end\":36734,\"start\":35981},{\"end\":37309,\"start\":37275},{\"end\":37608,\"start\":37539}]", "figure_caption": "[{\"end\":33626,\"start\":33226},{\"end\":34317,\"start\":33638},{\"end\":34624,\"start\":34320},{\"end\":34864,\"start\":34636},{\"end\":34957,\"start\":34867},{\"end\":35378,\"start\":35312},{\"end\":35981,\"start\":35843},{\"end\":37275,\"start\":36745},{\"end\":37539,\"start\":37312}]", "figure_ref": "[{\"end\":11728,\"start\":11722},{\"end\":13380,\"start\":13374},{\"end\":14185,\"start\":14184},{\"end\":15780,\"start\":15774},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17706,\"start\":17699},{\"end\":20320,\"start\":20314},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23232,\"start\":23226},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":29895,\"start\":29889},{\"end\":30344,\"start\":30341},{\"end\":30889,\"start\":30883},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":31557,\"start\":31551}]", "bib_author_first_name": "[{\"end\":37670,\"start\":37669},{\"end\":37672,\"start\":37671},{\"end\":37680,\"start\":37679},{\"end\":37689,\"start\":37688},{\"end\":37698,\"start\":37697},{\"end\":37994,\"start\":37993},{\"end\":38007,\"start\":38006},{\"end\":38009,\"start\":38008},{\"end\":38023,\"start\":38022},{\"end\":38032,\"start\":38031},{\"end\":38315,\"start\":38314},{\"end\":38324,\"start\":38323},{\"end\":38336,\"start\":38335},{\"end\":38349,\"start\":38348},{\"end\":38358,\"start\":38357},{\"end\":38678,\"start\":38677},{\"end\":38680,\"start\":38679},{\"end\":38689,\"start\":38688},{\"end\":38698,\"start\":38697},{\"end\":38710,\"start\":38709},{\"end\":38722,\"start\":38721},{\"end\":38729,\"start\":38728},{\"end\":39100,\"start\":39099},{\"end\":39102,\"start\":39101},{\"end\":39110,\"start\":39109},{\"end\":39112,\"start\":39111},{\"end\":39119,\"start\":39118},{\"end\":39121,\"start\":39120},{\"end\":39129,\"start\":39128},{\"end\":39139,\"start\":39138},{\"end\":39146,\"start\":39145},{\"end\":39148,\"start\":39147},{\"end\":39157,\"start\":39156},{\"end\":39166,\"start\":39165},{\"end\":39176,\"start\":39175},{\"end\":39188,\"start\":39187},{\"end\":39198,\"start\":39197},{\"end\":39208,\"start\":39207},{\"end\":39681,\"start\":39680},{\"end\":39683,\"start\":39682},{\"end\":39691,\"start\":39690},{\"end\":39703,\"start\":39702},{\"end\":39717,\"start\":39716},{\"end\":39723,\"start\":39722},{\"end\":40139,\"start\":40138},{\"end\":40152,\"start\":40151},{\"end\":40163,\"start\":40162},{\"end\":40182,\"start\":40181},{\"end\":40456,\"start\":40455},{\"end\":40458,\"start\":40457},{\"end\":40466,\"start\":40465},{\"end\":40480,\"start\":40479},{\"end\":40491,\"start\":40490},{\"end\":40752,\"start\":40751},{\"end\":40760,\"start\":40759},{\"end\":40768,\"start\":40767},{\"end\":41086,\"start\":41085},{\"end\":41088,\"start\":41087},{\"end\":41097,\"start\":41096},{\"end\":41099,\"start\":41098},{\"end\":41106,\"start\":41105},{\"end\":41108,\"start\":41107},{\"end\":41115,\"start\":41114},{\"end\":41122,\"start\":41121},{\"end\":41134,\"start\":41133},{\"end\":41136,\"start\":41135},{\"end\":41456,\"start\":41455},{\"end\":41464,\"start\":41463},{\"end\":41473,\"start\":41472},{\"end\":41485,\"start\":41484},{\"end\":41487,\"start\":41486},{\"end\":41494,\"start\":41493},{\"end\":41734,\"start\":41733},{\"end\":41736,\"start\":41735},{\"end\":41745,\"start\":41744},{\"end\":41747,\"start\":41746},{\"end\":41754,\"start\":41753},{\"end\":42020,\"start\":42019},{\"end\":42029,\"start\":42028},{\"end\":42040,\"start\":42039},{\"end\":42308,\"start\":42307},{\"end\":42317,\"start\":42316},{\"end\":42328,\"start\":42327},{\"end\":42519,\"start\":42518},{\"end\":42529,\"start\":42528},{\"end\":42849,\"start\":42848},{\"end\":42860,\"start\":42859},{\"end\":42862,\"start\":42861},{\"end\":42874,\"start\":42873},{\"end\":42888,\"start\":42887},{\"end\":42890,\"start\":42889},{\"end\":42900,\"start\":42899},{\"end\":42902,\"start\":42901},{\"end\":43273,\"start\":43272},{\"end\":43282,\"start\":43281},{\"end\":43293,\"start\":43292},{\"end\":43650,\"start\":43649},{\"end\":43658,\"start\":43657},{\"end\":43672,\"start\":43671},{\"end\":43938,\"start\":43937},{\"end\":43947,\"start\":43946},{\"end\":43958,\"start\":43957},{\"end\":43969,\"start\":43968},{\"end\":43979,\"start\":43978},{\"end\":43988,\"start\":43987},{\"end\":44000,\"start\":43999},{\"end\":44011,\"start\":44010},{\"end\":44428,\"start\":44427},{\"end\":44435,\"start\":44434},{\"end\":44445,\"start\":44444},{\"end\":44457,\"start\":44456},{\"end\":44762,\"start\":44761},{\"end\":44773,\"start\":44772},{\"end\":44782,\"start\":44781},{\"end\":45051,\"start\":45050},{\"end\":45065,\"start\":45064},{\"end\":45082,\"start\":45081},{\"end\":45091,\"start\":45090},{\"end\":45097,\"start\":45096},{\"end\":45113,\"start\":45112},{\"end\":45122,\"start\":45121},{\"end\":45135,\"start\":45134},{\"end\":45454,\"start\":45453},{\"end\":45460,\"start\":45459},{\"end\":45467,\"start\":45466},{\"end\":45475,\"start\":45474},{\"end\":45743,\"start\":45742},{\"end\":45750,\"start\":45749},{\"end\":45760,\"start\":45759},{\"end\":45772,\"start\":45771},{\"end\":45774,\"start\":45773},{\"end\":46091,\"start\":46090},{\"end\":46099,\"start\":46098},{\"end\":46101,\"start\":46100},{\"end\":46329,\"start\":46328},{\"end\":46335,\"start\":46334},{\"end\":46343,\"start\":46342},{\"end\":46616,\"start\":46615},{\"end\":46618,\"start\":46617},{\"end\":46627,\"start\":46626},{\"end\":46634,\"start\":46633},{\"end\":46636,\"start\":46635},{\"end\":46645,\"start\":46644},{\"end\":46647,\"start\":46646},{\"end\":46658,\"start\":46657},{\"end\":46660,\"start\":46659},{\"end\":46999,\"start\":46998},{\"end\":47005,\"start\":47004},{\"end\":47013,\"start\":47012},{\"end\":47015,\"start\":47014},{\"end\":47023,\"start\":47022},{\"end\":47295,\"start\":47294},{\"end\":47304,\"start\":47303},{\"end\":47314,\"start\":47313},{\"end\":47316,\"start\":47315},{\"end\":47324,\"start\":47323},{\"end\":47326,\"start\":47325},{\"end\":47669,\"start\":47668},{\"end\":47680,\"start\":47679},{\"end\":47689,\"start\":47688},{\"end\":47700,\"start\":47699},{\"end\":47707,\"start\":47706},{\"end\":47717,\"start\":47716},{\"end\":47728,\"start\":47727},{\"end\":47738,\"start\":47737},{\"end\":47740,\"start\":47739},{\"end\":47751,\"start\":47750},{\"end\":47762,\"start\":47761},{\"end\":48208,\"start\":48207},{\"end\":48216,\"start\":48215},{\"end\":48549,\"start\":48548},{\"end\":48559,\"start\":48558},{\"end\":48568,\"start\":48567},{\"end\":48580,\"start\":48579},{\"end\":48590,\"start\":48589},{\"end\":48592,\"start\":48591},{\"end\":48882,\"start\":48881},{\"end\":48894,\"start\":48893},{\"end\":49251,\"start\":49250},{\"end\":49261,\"start\":49260},{\"end\":49269,\"start\":49268},{\"end\":49278,\"start\":49277},{\"end\":49630,\"start\":49629},{\"end\":49640,\"start\":49639},{\"end\":49649,\"start\":49648},{\"end\":49660,\"start\":49659},{\"end\":49672,\"start\":49671},{\"end\":49684,\"start\":49683},{\"end\":50051,\"start\":50050},{\"end\":50053,\"start\":50052},{\"end\":50060,\"start\":50059},{\"end\":50067,\"start\":50066},{\"end\":50075,\"start\":50074},{\"end\":50088,\"start\":50087},{\"end\":50386,\"start\":50385},{\"end\":50394,\"start\":50393},{\"end\":50404,\"start\":50403},{\"end\":50415,\"start\":50414},{\"end\":50426,\"start\":50425},{\"end\":50432,\"start\":50431},{\"end\":50441,\"start\":50440},{\"end\":50454,\"start\":50453},{\"end\":50456,\"start\":50455},{\"end\":50465,\"start\":50464},{\"end\":50471,\"start\":50470},{\"end\":50477,\"start\":50476},{\"end\":50486,\"start\":50485},{\"end\":50492,\"start\":50491},{\"end\":50501,\"start\":50500},{\"end\":50510,\"start\":50509},{\"end\":50866,\"start\":50865},{\"end\":50874,\"start\":50873},{\"end\":50884,\"start\":50883},{\"end\":50895,\"start\":50894},{\"end\":50906,\"start\":50905},{\"end\":50912,\"start\":50911},{\"end\":50921,\"start\":50920},{\"end\":50934,\"start\":50933},{\"end\":50936,\"start\":50935},{\"end\":50945,\"start\":50944},{\"end\":50951,\"start\":50950},{\"end\":51289,\"start\":51288},{\"end\":51298,\"start\":51297},{\"end\":51307,\"start\":51306},{\"end\":51317,\"start\":51316},{\"end\":51330,\"start\":51329},{\"end\":51344,\"start\":51343},{\"end\":51354,\"start\":51353},{\"end\":51364,\"start\":51363},{\"end\":51374,\"start\":51373},{\"end\":51382,\"start\":51381},{\"end\":51861,\"start\":51860},{\"end\":51868,\"start\":51867},{\"end\":51876,\"start\":51875},{\"end\":51885,\"start\":51884},{\"end\":51893,\"start\":51892},{\"end\":51895,\"start\":51894},{\"end\":51902,\"start\":51901},{\"end\":51911,\"start\":51910},{\"end\":51919,\"start\":51918},{\"end\":51926,\"start\":51925},{\"end\":52194,\"start\":52193},{\"end\":52203,\"start\":52202},{\"end\":52421,\"start\":52420},{\"end\":52423,\"start\":52422},{\"end\":52430,\"start\":52429},{\"end\":52432,\"start\":52431},{\"end\":52441,\"start\":52440},{\"end\":52443,\"start\":52442},{\"end\":52450,\"start\":52449},{\"end\":52462,\"start\":52461},{\"end\":52464,\"start\":52463},{\"end\":52828,\"start\":52827},{\"end\":52835,\"start\":52834},{\"end\":52845,\"start\":52844},{\"end\":52856,\"start\":52855},{\"end\":52867,\"start\":52866},{\"end\":52878,\"start\":52877},{\"end\":53254,\"start\":53253},{\"end\":53261,\"start\":53260},{\"end\":53268,\"start\":53267},{\"end\":53277,\"start\":53276},{\"end\":53285,\"start\":53284},{\"end\":53292,\"start\":53291},{\"end\":53594,\"start\":53593},{\"end\":53601,\"start\":53600},{\"end\":53607,\"start\":53606},{\"end\":53609,\"start\":53608},{\"end\":53616,\"start\":53615},{\"end\":53618,\"start\":53617},{\"end\":53626,\"start\":53625},{\"end\":53804,\"start\":53803},{\"end\":53811,\"start\":53810},{\"end\":53818,\"start\":53817},{\"end\":53824,\"start\":53823},{\"end\":53831,\"start\":53830},{\"end\":53842,\"start\":53841},{\"end\":53844,\"start\":53843},{\"end\":54125,\"start\":54124},{\"end\":54137,\"start\":54136},{\"end\":54146,\"start\":54145},{\"end\":54157,\"start\":54156},{\"end\":54169,\"start\":54168},{\"end\":54181,\"start\":54180},{\"end\":54492,\"start\":54491},{\"end\":54502,\"start\":54501},{\"end\":54504,\"start\":54503},{\"end\":54512,\"start\":54511},{\"end\":54521,\"start\":54520},{\"end\":54523,\"start\":54522},{\"end\":54887,\"start\":54886},{\"end\":54901,\"start\":54900},{\"end\":54903,\"start\":54902},{\"end\":54917,\"start\":54916},{\"end\":54932,\"start\":54931},{\"end\":54934,\"start\":54933},{\"end\":54947,\"start\":54946},{\"end\":54962,\"start\":54961},{\"end\":54968,\"start\":54967},{\"end\":55341,\"start\":55340},{\"end\":55355,\"start\":55354},{\"end\":55357,\"start\":55356},{\"end\":55371,\"start\":55370},{\"end\":55381,\"start\":55380},{\"end\":55383,\"start\":55382},{\"end\":55393,\"start\":55392},{\"end\":55408,\"start\":55407},{\"end\":55802,\"start\":55801},{\"end\":55811,\"start\":55810},{\"end\":55825,\"start\":55824},{\"end\":55834,\"start\":55833},{\"end\":56173,\"start\":56172},{\"end\":56189,\"start\":56188},{\"end\":56195,\"start\":56194},{\"end\":56204,\"start\":56203},{\"end\":56216,\"start\":56215},{\"end\":56218,\"start\":56217},{\"end\":56570,\"start\":56569},{\"end\":56582,\"start\":56581},{\"end\":56900,\"start\":56899},{\"end\":56912,\"start\":56911},{\"end\":57259,\"start\":57258},{\"end\":57270,\"start\":57269},{\"end\":57569,\"start\":57568},{\"end\":57580,\"start\":57579},{\"end\":57587,\"start\":57586},{\"end\":57595,\"start\":57594},{\"end\":57798,\"start\":57797},{\"end\":57806,\"start\":57805},{\"end\":57808,\"start\":57807},{\"end\":57815,\"start\":57814},{\"end\":57823,\"start\":57822},{\"end\":57829,\"start\":57828},{\"end\":57842,\"start\":57841},{\"end\":57851,\"start\":57850},{\"end\":58189,\"start\":58188},{\"end\":58199,\"start\":58198},{\"end\":58211,\"start\":58210},{\"end\":58221,\"start\":58220},{\"end\":58234,\"start\":58233},{\"end\":58568,\"start\":58567},{\"end\":58578,\"start\":58577},{\"end\":58594,\"start\":58593},{\"end\":58814,\"start\":58813},{\"end\":58825,\"start\":58824},{\"end\":59097,\"start\":59096},{\"end\":59109,\"start\":59108},{\"end\":59111,\"start\":59110},{\"end\":59121,\"start\":59120},{\"end\":59457,\"start\":59456},{\"end\":59468,\"start\":59467},{\"end\":59477,\"start\":59476},{\"end\":59734,\"start\":59733},{\"end\":59745,\"start\":59744},{\"end\":59753,\"start\":59752},{\"end\":59762,\"start\":59761},{\"end\":59764,\"start\":59763},{\"end\":59771,\"start\":59770},{\"end\":59777,\"start\":59776},{\"end\":59789,\"start\":59788},{\"end\":59791,\"start\":59790},{\"end\":59800,\"start\":59799},{\"end\":60121,\"start\":60120},{\"end\":60132,\"start\":60131},{\"end\":60140,\"start\":60139},{\"end\":60152,\"start\":60151},{\"end\":60450,\"start\":60449},{\"end\":60462,\"start\":60461},{\"end\":60468,\"start\":60467},{\"end\":60476,\"start\":60475},{\"end\":60483,\"start\":60482},{\"end\":60707,\"start\":60706},{\"end\":60716,\"start\":60715},{\"end\":60727,\"start\":60726},{\"end\":60729,\"start\":60728},{\"end\":60735,\"start\":60734},{\"end\":61002,\"start\":61001},{\"end\":61004,\"start\":61003},{\"end\":61014,\"start\":61013},{\"end\":61023,\"start\":61022},{\"end\":61354,\"start\":61353},{\"end\":61356,\"start\":61355},{\"end\":61366,\"start\":61365},{\"end\":61375,\"start\":61374},{\"end\":61710,\"start\":61709},{\"end\":61717,\"start\":61716},{\"end\":61730,\"start\":61729},{\"end\":61739,\"start\":61738},{\"end\":61749,\"start\":61748},{\"end\":62060,\"start\":62059},{\"end\":62062,\"start\":62061},{\"end\":62070,\"start\":62069},{\"end\":62072,\"start\":62071},{\"end\":62078,\"start\":62077},{\"end\":62086,\"start\":62085},{\"end\":62088,\"start\":62087},{\"end\":62444,\"start\":62443},{\"end\":62446,\"start\":62445},{\"end\":62454,\"start\":62453},{\"end\":62456,\"start\":62455},{\"end\":62462,\"start\":62461},{\"end\":62470,\"start\":62469},{\"end\":62472,\"start\":62471},{\"end\":62813,\"start\":62812},{\"end\":62824,\"start\":62823},{\"end\":62833,\"start\":62832},{\"end\":62842,\"start\":62841},{\"end\":63151,\"start\":63150},{\"end\":63162,\"start\":63161},{\"end\":63171,\"start\":63170},{\"end\":63518,\"start\":63517},{\"end\":63533,\"start\":63532},{\"end\":63545,\"start\":63544},{\"end\":63883,\"start\":63882},{\"end\":63895,\"start\":63894},{\"end\":63904,\"start\":63903},{\"end\":63916,\"start\":63915},{\"end\":63929,\"start\":63928},{\"end\":63941,\"start\":63940},{\"end\":63948,\"start\":63947},{\"end\":63950,\"start\":63949},{\"end\":64346,\"start\":64345},{\"end\":64354,\"start\":64353},{\"end\":64361,\"start\":64360},{\"end\":64369,\"start\":64368},{\"end\":64382,\"start\":64381},{\"end\":64390,\"start\":64389},{\"end\":64392,\"start\":64391},{\"end\":64403,\"start\":64402},{\"end\":64696,\"start\":64695},{\"end\":64706,\"start\":64705},{\"end\":65019,\"start\":65018},{\"end\":65031,\"start\":65030},{\"end\":65041,\"start\":65040},{\"end\":65369,\"start\":65368},{\"end\":65381,\"start\":65380},{\"end\":65383,\"start\":65382},{\"end\":65390,\"start\":65389},{\"end\":65398,\"start\":65397},{\"end\":65775,\"start\":65774},{\"end\":65787,\"start\":65786},{\"end\":65797,\"start\":65796},{\"end\":65807,\"start\":65806},{\"end\":65816,\"start\":65815},{\"end\":65818,\"start\":65817},{\"end\":65824,\"start\":65823},{\"end\":66138,\"start\":66137},{\"end\":66150,\"start\":66149},{\"end\":66158,\"start\":66157},{\"end\":66166,\"start\":66165},{\"end\":66173,\"start\":66172},{\"end\":66411,\"start\":66410},{\"end\":66423,\"start\":66422},{\"end\":66437,\"start\":66436},{\"end\":66674,\"start\":66673},{\"end\":66686,\"start\":66685},{\"end\":67010,\"start\":67009},{\"end\":67018,\"start\":67017},{\"end\":67026,\"start\":67025},{\"end\":67036,\"start\":67035},{\"end\":67038,\"start\":67037},{\"end\":67052,\"start\":67051},{\"end\":67060,\"start\":67059},{\"end\":67062,\"start\":67061},{\"end\":67072,\"start\":67071},{\"end\":67090,\"start\":67089},{\"end\":67101,\"start\":67100},{\"end\":67514,\"start\":67513},{\"end\":67522,\"start\":67521},{\"end\":67529,\"start\":67528},{\"end\":67537,\"start\":67536},{\"end\":67892,\"start\":67891},{\"end\":67900,\"start\":67899},{\"end\":67908,\"start\":67907},{\"end\":67916,\"start\":67915},{\"end\":67923,\"start\":67922},{\"end\":67925,\"start\":67924},{\"end\":68226,\"start\":68225},{\"end\":68235,\"start\":68234},{\"end\":68247,\"start\":68246},{\"end\":68259,\"start\":68258},{\"end\":68616,\"start\":68615},{\"end\":68624,\"start\":68623},{\"end\":68632,\"start\":68631},{\"end\":68639,\"start\":68638},{\"end\":68647,\"start\":68646},{\"end\":68945,\"start\":68944},{\"end\":68951,\"start\":68950},{\"end\":68960,\"start\":68959},{\"end\":68969,\"start\":68968},{\"end\":69247,\"start\":69246},{\"end\":69253,\"start\":69252},{\"end\":69260,\"start\":69259},{\"end\":69268,\"start\":69267},{\"end\":69276,\"start\":69275},{\"end\":69282,\"start\":69281},{\"end\":69284,\"start\":69283},{\"end\":69637,\"start\":69636},{\"end\":69643,\"start\":69642},{\"end\":69650,\"start\":69649},{\"end\":69658,\"start\":69657},{\"end\":69666,\"start\":69665},{\"end\":69672,\"start\":69671},{\"end\":69674,\"start\":69673},{\"end\":70022,\"start\":70021},{\"end\":70028,\"start\":70027},{\"end\":70036,\"start\":70035},{\"end\":70042,\"start\":70041},{\"end\":70049,\"start\":70048},{\"end\":70056,\"start\":70055},{\"end\":70058,\"start\":70057},{\"end\":70064,\"start\":70063},{\"end\":70456,\"start\":70455},{\"end\":70462,\"start\":70461},{\"end\":70470,\"start\":70469},{\"end\":70476,\"start\":70475},{\"end\":70483,\"start\":70482},{\"end\":70490,\"start\":70489},{\"end\":70492,\"start\":70491},{\"end\":70498,\"start\":70497},{\"end\":70863,\"start\":70862},{\"end\":70872,\"start\":70871},{\"end\":70881,\"start\":70880},{\"end\":70883,\"start\":70882},{\"end\":70892,\"start\":70891},{\"end\":70905,\"start\":70904},{\"end\":71289,\"start\":71288},{\"end\":71297,\"start\":71296},{\"end\":71304,\"start\":71303},{\"end\":71313,\"start\":71312},{\"end\":71321,\"start\":71320},{\"end\":71330,\"start\":71329},{\"end\":71332,\"start\":71331},{\"end\":71341,\"start\":71340},{\"end\":71729,\"start\":71728},{\"end\":71737,\"start\":71736},{\"end\":71747,\"start\":71746},{\"end\":71756,\"start\":71755},{\"end\":71765,\"start\":71764},{\"end\":72070,\"start\":72069},{\"end\":72078,\"start\":72077},{\"end\":72085,\"start\":72084},{\"end\":72092,\"start\":72091},{\"end\":72106,\"start\":72105},{\"end\":72118,\"start\":72117}]", "bib_author_last_name": "[{\"end\":37677,\"start\":37673},{\"end\":37686,\"start\":37681},{\"end\":37695,\"start\":37690},{\"end\":37704,\"start\":37699},{\"end\":38004,\"start\":37995},{\"end\":38020,\"start\":38010},{\"end\":38029,\"start\":38024},{\"end\":38040,\"start\":38033},{\"end\":38321,\"start\":38316},{\"end\":38333,\"start\":38325},{\"end\":38346,\"start\":38337},{\"end\":38355,\"start\":38350},{\"end\":38364,\"start\":38359},{\"end\":38686,\"start\":38681},{\"end\":38695,\"start\":38690},{\"end\":38707,\"start\":38699},{\"end\":38719,\"start\":38711},{\"end\":38726,\"start\":38723},{\"end\":38735,\"start\":38730},{\"end\":39107,\"start\":39103},{\"end\":39116,\"start\":39113},{\"end\":39126,\"start\":39122},{\"end\":39136,\"start\":39130},{\"end\":39143,\"start\":39140},{\"end\":39154,\"start\":39149},{\"end\":39163,\"start\":39158},{\"end\":39173,\"start\":39167},{\"end\":39185,\"start\":39177},{\"end\":39195,\"start\":39189},{\"end\":39205,\"start\":39199},{\"end\":39218,\"start\":39209},{\"end\":39688,\"start\":39684},{\"end\":39700,\"start\":39692},{\"end\":39714,\"start\":39704},{\"end\":39720,\"start\":39718},{\"end\":39733,\"start\":39724},{\"end\":40149,\"start\":40140},{\"end\":40160,\"start\":40153},{\"end\":40179,\"start\":40164},{\"end\":40192,\"start\":40183},{\"end\":40463,\"start\":40459},{\"end\":40477,\"start\":40467},{\"end\":40488,\"start\":40481},{\"end\":40496,\"start\":40492},{\"end\":40757,\"start\":40753},{\"end\":40765,\"start\":40761},{\"end\":40777,\"start\":40769},{\"end\":41094,\"start\":41089},{\"end\":41103,\"start\":41100},{\"end\":41112,\"start\":41109},{\"end\":41119,\"start\":41116},{\"end\":41131,\"start\":41123},{\"end\":41141,\"start\":41137},{\"end\":41461,\"start\":41457},{\"end\":41470,\"start\":41465},{\"end\":41482,\"start\":41474},{\"end\":41491,\"start\":41488},{\"end\":41500,\"start\":41495},{\"end\":41742,\"start\":41737},{\"end\":41751,\"start\":41748},{\"end\":41762,\"start\":41755},{\"end\":42026,\"start\":42021},{\"end\":42037,\"start\":42030},{\"end\":42049,\"start\":42041},{\"end\":42314,\"start\":42309},{\"end\":42325,\"start\":42318},{\"end\":42337,\"start\":42329},{\"end\":42526,\"start\":42520},{\"end\":42536,\"start\":42530},{\"end\":42857,\"start\":42850},{\"end\":42871,\"start\":42863},{\"end\":42885,\"start\":42875},{\"end\":42897,\"start\":42891},{\"end\":42911,\"start\":42903},{\"end\":43279,\"start\":43274},{\"end\":43290,\"start\":43283},{\"end\":43299,\"start\":43294},{\"end\":43655,\"start\":43651},{\"end\":43669,\"start\":43659},{\"end\":43679,\"start\":43673},{\"end\":43944,\"start\":43939},{\"end\":43955,\"start\":43948},{\"end\":43966,\"start\":43959},{\"end\":43976,\"start\":43970},{\"end\":43985,\"start\":43980},{\"end\":43997,\"start\":43989},{\"end\":44008,\"start\":44001},{\"end\":44018,\"start\":44012},{\"end\":44432,\"start\":44429},{\"end\":44442,\"start\":44436},{\"end\":44454,\"start\":44446},{\"end\":44466,\"start\":44458},{\"end\":44770,\"start\":44763},{\"end\":44779,\"start\":44774},{\"end\":44788,\"start\":44783},{\"end\":45062,\"start\":45052},{\"end\":45079,\"start\":45066},{\"end\":45088,\"start\":45083},{\"end\":45094,\"start\":45092},{\"end\":45110,\"start\":45098},{\"end\":45119,\"start\":45114},{\"end\":45132,\"start\":45123},{\"end\":45142,\"start\":45136},{\"end\":45457,\"start\":45455},{\"end\":45464,\"start\":45461},{\"end\":45472,\"start\":45468},{\"end\":45484,\"start\":45476},{\"end\":45747,\"start\":45744},{\"end\":45757,\"start\":45751},{\"end\":45769,\"start\":45761},{\"end\":45778,\"start\":45775},{\"end\":46096,\"start\":46092},{\"end\":46107,\"start\":46102},{\"end\":46332,\"start\":46330},{\"end\":46340,\"start\":46336},{\"end\":46350,\"start\":46344},{\"end\":46624,\"start\":46619},{\"end\":46631,\"start\":46628},{\"end\":46642,\"start\":46637},{\"end\":46655,\"start\":46648},{\"end\":46668,\"start\":46661},{\"end\":47002,\"start\":47000},{\"end\":47010,\"start\":47006},{\"end\":47020,\"start\":47016},{\"end\":47030,\"start\":47024},{\"end\":47301,\"start\":47296},{\"end\":47311,\"start\":47305},{\"end\":47321,\"start\":47317},{\"end\":47330,\"start\":47327},{\"end\":47677,\"start\":47670},{\"end\":47686,\"start\":47681},{\"end\":47697,\"start\":47690},{\"end\":47704,\"start\":47701},{\"end\":47714,\"start\":47708},{\"end\":47725,\"start\":47718},{\"end\":47735,\"start\":47729},{\"end\":47748,\"start\":47741},{\"end\":47759,\"start\":47752},{\"end\":47770,\"start\":47763},{\"end\":48213,\"start\":48209},{\"end\":48224,\"start\":48217},{\"end\":48556,\"start\":48550},{\"end\":48565,\"start\":48560},{\"end\":48577,\"start\":48569},{\"end\":48587,\"start\":48581},{\"end\":48600,\"start\":48593},{\"end\":48891,\"start\":48883},{\"end\":48899,\"start\":48895},{\"end\":49258,\"start\":49252},{\"end\":49266,\"start\":49262},{\"end\":49275,\"start\":49270},{\"end\":49287,\"start\":49279},{\"end\":49637,\"start\":49631},{\"end\":49646,\"start\":49641},{\"end\":49657,\"start\":49650},{\"end\":49669,\"start\":49661},{\"end\":49681,\"start\":49673},{\"end\":49689,\"start\":49685},{\"end\":50057,\"start\":50054},{\"end\":50064,\"start\":50061},{\"end\":50072,\"start\":50068},{\"end\":50085,\"start\":50076},{\"end\":50097,\"start\":50089},{\"end\":50391,\"start\":50387},{\"end\":50401,\"start\":50395},{\"end\":50412,\"start\":50405},{\"end\":50423,\"start\":50416},{\"end\":50429,\"start\":50427},{\"end\":50438,\"start\":50433},{\"end\":50451,\"start\":50442},{\"end\":50462,\"start\":50457},{\"end\":50468,\"start\":50466},{\"end\":50474,\"start\":50472},{\"end\":50483,\"start\":50478},{\"end\":50489,\"start\":50487},{\"end\":50498,\"start\":50493},{\"end\":50507,\"start\":50502},{\"end\":50516,\"start\":50511},{\"end\":50871,\"start\":50867},{\"end\":50881,\"start\":50875},{\"end\":50892,\"start\":50885},{\"end\":50903,\"start\":50896},{\"end\":50909,\"start\":50907},{\"end\":50918,\"start\":50913},{\"end\":50931,\"start\":50922},{\"end\":50942,\"start\":50937},{\"end\":50948,\"start\":50946},{\"end\":50954,\"start\":50952},{\"end\":51295,\"start\":51290},{\"end\":51304,\"start\":51299},{\"end\":51314,\"start\":51308},{\"end\":51327,\"start\":51318},{\"end\":51341,\"start\":51331},{\"end\":51351,\"start\":51345},{\"end\":51361,\"start\":51355},{\"end\":51371,\"start\":51365},{\"end\":51379,\"start\":51375},{\"end\":51387,\"start\":51383},{\"end\":51865,\"start\":51862},{\"end\":51873,\"start\":51869},{\"end\":51882,\"start\":51877},{\"end\":51890,\"start\":51886},{\"end\":51899,\"start\":51896},{\"end\":51908,\"start\":51903},{\"end\":51916,\"start\":51912},{\"end\":51923,\"start\":51920},{\"end\":51931,\"start\":51927},{\"end\":52200,\"start\":52195},{\"end\":52212,\"start\":52204},{\"end\":52427,\"start\":52424},{\"end\":52438,\"start\":52433},{\"end\":52447,\"start\":52444},{\"end\":52459,\"start\":52451},{\"end\":52469,\"start\":52465},{\"end\":52832,\"start\":52829},{\"end\":52842,\"start\":52836},{\"end\":52853,\"start\":52846},{\"end\":52864,\"start\":52857},{\"end\":52875,\"start\":52868},{\"end\":52887,\"start\":52879},{\"end\":53258,\"start\":53255},{\"end\":53265,\"start\":53262},{\"end\":53274,\"start\":53269},{\"end\":53282,\"start\":53278},{\"end\":53289,\"start\":53286},{\"end\":53297,\"start\":53293},{\"end\":53598,\"start\":53595},{\"end\":53604,\"start\":53602},{\"end\":53613,\"start\":53610},{\"end\":53623,\"start\":53619},{\"end\":53635,\"start\":53627},{\"end\":53808,\"start\":53805},{\"end\":53815,\"start\":53812},{\"end\":53821,\"start\":53819},{\"end\":53828,\"start\":53825},{\"end\":53839,\"start\":53832},{\"end\":53849,\"start\":53845},{\"end\":54134,\"start\":54126},{\"end\":54143,\"start\":54138},{\"end\":54154,\"start\":54147},{\"end\":54166,\"start\":54158},{\"end\":54178,\"start\":54170},{\"end\":54188,\"start\":54182},{\"end\":54499,\"start\":54493},{\"end\":54509,\"start\":54505},{\"end\":54518,\"start\":54513},{\"end\":54527,\"start\":54524},{\"end\":54898,\"start\":54888},{\"end\":54914,\"start\":54904},{\"end\":54929,\"start\":54918},{\"end\":54944,\"start\":54935},{\"end\":54959,\"start\":54948},{\"end\":54965,\"start\":54963},{\"end\":54972,\"start\":54969},{\"end\":55352,\"start\":55342},{\"end\":55368,\"start\":55358},{\"end\":55378,\"start\":55372},{\"end\":55390,\"start\":55384},{\"end\":55405,\"start\":55394},{\"end\":55411,\"start\":55409},{\"end\":55808,\"start\":55803},{\"end\":55822,\"start\":55812},{\"end\":55831,\"start\":55826},{\"end\":55839,\"start\":55835},{\"end\":56186,\"start\":56174},{\"end\":56192,\"start\":56190},{\"end\":56201,\"start\":56196},{\"end\":56213,\"start\":56205},{\"end\":56223,\"start\":56219},{\"end\":56579,\"start\":56571},{\"end\":56589,\"start\":56583},{\"end\":56909,\"start\":56901},{\"end\":56919,\"start\":56913},{\"end\":57267,\"start\":57260},{\"end\":57274,\"start\":57271},{\"end\":57577,\"start\":57570},{\"end\":57584,\"start\":57581},{\"end\":57592,\"start\":57588},{\"end\":57599,\"start\":57596},{\"end\":57803,\"start\":57799},{\"end\":57812,\"start\":57809},{\"end\":57820,\"start\":57816},{\"end\":57826,\"start\":57824},{\"end\":57839,\"start\":57830},{\"end\":57848,\"start\":57843},{\"end\":57857,\"start\":57852},{\"end\":58196,\"start\":58190},{\"end\":58208,\"start\":58200},{\"end\":58218,\"start\":58212},{\"end\":58231,\"start\":58222},{\"end\":58241,\"start\":58235},{\"end\":58575,\"start\":58569},{\"end\":58591,\"start\":58579},{\"end\":58602,\"start\":58595},{\"end\":58822,\"start\":58815},{\"end\":58832,\"start\":58826},{\"end\":59106,\"start\":59098},{\"end\":59118,\"start\":59112},{\"end\":59129,\"start\":59122},{\"end\":59465,\"start\":59458},{\"end\":59474,\"start\":59469},{\"end\":59483,\"start\":59478},{\"end\":59742,\"start\":59735},{\"end\":59750,\"start\":59746},{\"end\":59759,\"start\":59754},{\"end\":59768,\"start\":59765},{\"end\":59774,\"start\":59772},{\"end\":59786,\"start\":59778},{\"end\":59797,\"start\":59792},{\"end\":59808,\"start\":59801},{\"end\":60129,\"start\":60122},{\"end\":60137,\"start\":60133},{\"end\":60149,\"start\":60141},{\"end\":60159,\"start\":60153},{\"end\":60459,\"start\":60451},{\"end\":60465,\"start\":60463},{\"end\":60473,\"start\":60469},{\"end\":60480,\"start\":60477},{\"end\":60487,\"start\":60484},{\"end\":60713,\"start\":60708},{\"end\":60724,\"start\":60717},{\"end\":60732,\"start\":60730},{\"end\":60744,\"start\":60736},{\"end\":61011,\"start\":61005},{\"end\":61020,\"start\":61015},{\"end\":61032,\"start\":61024},{\"end\":61363,\"start\":61357},{\"end\":61372,\"start\":61367},{\"end\":61384,\"start\":61376},{\"end\":61714,\"start\":61711},{\"end\":61727,\"start\":61718},{\"end\":61736,\"start\":61731},{\"end\":61746,\"start\":61740},{\"end\":61756,\"start\":61750},{\"end\":62067,\"start\":62063},{\"end\":62075,\"start\":62073},{\"end\":62083,\"start\":62079},{\"end\":62094,\"start\":62089},{\"end\":62451,\"start\":62447},{\"end\":62459,\"start\":62457},{\"end\":62467,\"start\":62463},{\"end\":62478,\"start\":62473},{\"end\":62821,\"start\":62814},{\"end\":62830,\"start\":62825},{\"end\":62839,\"start\":62834},{\"end\":62848,\"start\":62843},{\"end\":63159,\"start\":63152},{\"end\":63168,\"start\":63163},{\"end\":63177,\"start\":63172},{\"end\":63530,\"start\":63519},{\"end\":63542,\"start\":63534},{\"end\":63555,\"start\":63546},{\"end\":63892,\"start\":63884},{\"end\":63901,\"start\":63896},{\"end\":63913,\"start\":63905},{\"end\":63926,\"start\":63917},{\"end\":63938,\"start\":63930},{\"end\":63945,\"start\":63942},{\"end\":63958,\"start\":63951},{\"end\":64351,\"start\":64347},{\"end\":64358,\"start\":64355},{\"end\":64366,\"start\":64362},{\"end\":64379,\"start\":64370},{\"end\":64387,\"start\":64383},{\"end\":64400,\"start\":64393},{\"end\":64412,\"start\":64404},{\"end\":64703,\"start\":64697},{\"end\":64714,\"start\":64707},{\"end\":65028,\"start\":65020},{\"end\":65038,\"start\":65032},{\"end\":65049,\"start\":65042},{\"end\":65378,\"start\":65370},{\"end\":65387,\"start\":65384},{\"end\":65395,\"start\":65391},{\"end\":65404,\"start\":65399},{\"end\":65784,\"start\":65776},{\"end\":65794,\"start\":65788},{\"end\":65804,\"start\":65798},{\"end\":65813,\"start\":65808},{\"end\":65821,\"start\":65819},{\"end\":65828,\"start\":65825},{\"end\":66147,\"start\":66139},{\"end\":66155,\"start\":66151},{\"end\":66163,\"start\":66159},{\"end\":66170,\"start\":66167},{\"end\":66177,\"start\":66174},{\"end\":66420,\"start\":66412},{\"end\":66434,\"start\":66424},{\"end\":66446,\"start\":66438},{\"end\":66683,\"start\":66675},{\"end\":66695,\"start\":66687},{\"end\":67015,\"start\":67011},{\"end\":67023,\"start\":67019},{\"end\":67033,\"start\":67027},{\"end\":67049,\"start\":67039},{\"end\":67057,\"start\":67053},{\"end\":67069,\"start\":67063},{\"end\":67087,\"start\":67073},{\"end\":67098,\"start\":67091},{\"end\":67112,\"start\":67102},{\"end\":67519,\"start\":67515},{\"end\":67526,\"start\":67523},{\"end\":67534,\"start\":67530},{\"end\":67541,\"start\":67538},{\"end\":67897,\"start\":67893},{\"end\":67905,\"start\":67901},{\"end\":67913,\"start\":67909},{\"end\":67920,\"start\":67917},{\"end\":67928,\"start\":67926},{\"end\":68232,\"start\":68227},{\"end\":68244,\"start\":68236},{\"end\":68256,\"start\":68248},{\"end\":68267,\"start\":68260},{\"end\":68621,\"start\":68617},{\"end\":68629,\"start\":68625},{\"end\":68636,\"start\":68633},{\"end\":68644,\"start\":68640},{\"end\":68651,\"start\":68648},{\"end\":68948,\"start\":68946},{\"end\":68957,\"start\":68952},{\"end\":68966,\"start\":68961},{\"end\":68978,\"start\":68970},{\"end\":69250,\"start\":69248},{\"end\":69257,\"start\":69254},{\"end\":69265,\"start\":69261},{\"end\":69273,\"start\":69269},{\"end\":69279,\"start\":69277},{\"end\":69290,\"start\":69285},{\"end\":69640,\"start\":69638},{\"end\":69647,\"start\":69644},{\"end\":69655,\"start\":69651},{\"end\":69663,\"start\":69659},{\"end\":69669,\"start\":69667},{\"end\":69680,\"start\":69675},{\"end\":70025,\"start\":70023},{\"end\":70033,\"start\":70029},{\"end\":70039,\"start\":70037},{\"end\":70046,\"start\":70043},{\"end\":70053,\"start\":70050},{\"end\":70061,\"start\":70059},{\"end\":70069,\"start\":70065},{\"end\":70459,\"start\":70457},{\"end\":70467,\"start\":70463},{\"end\":70473,\"start\":70471},{\"end\":70480,\"start\":70477},{\"end\":70487,\"start\":70484},{\"end\":70495,\"start\":70493},{\"end\":70503,\"start\":70499},{\"end\":70869,\"start\":70864},{\"end\":70878,\"start\":70873},{\"end\":70889,\"start\":70884},{\"end\":70902,\"start\":70893},{\"end\":70910,\"start\":70906},{\"end\":71294,\"start\":71290},{\"end\":71301,\"start\":71298},{\"end\":71310,\"start\":71305},{\"end\":71318,\"start\":71314},{\"end\":71327,\"start\":71322},{\"end\":71338,\"start\":71333},{\"end\":71344,\"start\":71342},{\"end\":71734,\"start\":71730},{\"end\":71744,\"start\":71738},{\"end\":71753,\"start\":71748},{\"end\":71762,\"start\":71757},{\"end\":71773,\"start\":71766},{\"end\":72075,\"start\":72071},{\"end\":72082,\"start\":72079},{\"end\":72089,\"start\":72086},{\"end\":72103,\"start\":72093},{\"end\":72115,\"start\":72107},{\"end\":72124,\"start\":72119}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":236924382},\"end\":37968,\"start\":37610},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":3531856},\"end\":38282,\"start\":37970},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":175905},\"end\":38625,\"start\":38284},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":235356791},\"end\":39037,\"start\":38627},{\"attributes\":{\"id\":\"b4\"},\"end\":39590,\"start\":39039},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":227247980},\"end\":40066,\"start\":39592},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":960858},\"end\":40390,\"start\":40068},{\"attributes\":{\"doi\":\"arXiv:1706.05587\",\"id\":\"b7\"},\"end\":40680,\"start\":40392},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":202540123},\"end\":41030,\"start\":40682},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":232478397},\"end\":41429,\"start\":41032},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":54474649},\"end\":41731,\"start\":41431},{\"attributes\":{\"doi\":\"arXiv:2111.01619\",\"id\":\"b11\"},\"end\":42017,\"start\":41733},{\"attributes\":{\"doi\":\"arXiv:1907.06571\",\"id\":\"b12\"},\"end\":42257,\"start\":42019},{\"attributes\":{\"doi\":\"abs/1907.06571\",\"id\":\"b13\"},\"end\":42466,\"start\":42259},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3663219},\"end\":42773,\"start\":42468},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":232478819},\"end\":43213,\"start\":42775},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":229297973},\"end\":43574,\"start\":43215},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":2659157},\"end\":43879,\"start\":43576},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":190000375},\"end\":44353,\"start\":43881},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":235899129},\"end\":44721,\"start\":44355},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":6024639},\"end\":45019,\"start\":44723},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1033682},\"end\":45370,\"start\":45021},{\"attributes\":{\"doi\":\"arXiv:2110.08985\",\"id\":\"b22\"},\"end\":45676,\"start\":45372},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":233240846},\"end\":46040,\"start\":45678},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":940100},\"end\":46284,\"start\":46042},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":219955663},\"end\":46537,\"start\":46286},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":48353154},\"end\":46911,\"start\":46539},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":229298026},\"end\":47292,\"start\":46913},{\"attributes\":{\"doi\":\"arXiv:2112.05130\",\"id\":\"b28\"},\"end\":47584,\"start\":47294},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":237386323},\"end\":48136,\"start\":47586},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":237420378},\"end\":48468,\"start\":48138},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":538821},\"end\":48811,\"start\":48470},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":219687876},\"end\":49172,\"start\":48813},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":3568073},\"end\":49572,\"start\":49174},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":209202273},\"end\":49998,\"start\":49574},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":234777744},\"end\":50358,\"start\":50000},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":221104875},\"end\":50838,\"start\":50360},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":221104875},\"end\":51200,\"start\":50840},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":211227},\"end\":51782,\"start\":51202},{\"attributes\":{\"doi\":\"arXiv:2104.06697\",\"id\":\"b39\"},\"end\":52168,\"start\":51784},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":1363510},\"end\":52365,\"start\":52170},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":238419701},\"end\":52743,\"start\":52367},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":229297871},\"end\":53195,\"start\":52745},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":233739687},\"end\":53591,\"start\":53197},{\"attributes\":{\"id\":\"b44\"},\"end\":53770,\"start\":53593},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":233033467},\"end\":54122,\"start\":53772},{\"attributes\":{\"id\":\"b46\"},\"end\":54446,\"start\":54124},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":220545929},\"end\":54794,\"start\":54448},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":219947110},\"end\":55266,\"start\":54796},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":213175590},\"end\":55746,\"start\":55268},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":226299526},\"end\":56096,\"start\":55748},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":91184364},\"end\":56499,\"start\":56098},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":232428272},\"end\":56817,\"start\":56501},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":227151657},\"end\":57207,\"start\":56819},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":212675709},\"end\":57525,\"start\":57209},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":202565675},\"end\":57745,\"start\":57527},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":220280381},\"end\":58089,\"start\":57747},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":195776274},\"end\":58510,\"start\":58091},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":173990382},\"end\":58790,\"start\":58512},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":221112229},\"end\":59023,\"start\":58792},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":236986816},\"end\":59393,\"start\":59025},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":233240671},\"end\":59731,\"start\":59395},{\"attributes\":{\"doi\":\"arXiv:2111.05826\",\"id\":\"b62\"},\"end\":60055,\"start\":59733},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":220364071},\"end\":60374,\"start\":60057},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":3643293},\"end\":60682,\"start\":60376},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":1240104},\"end\":60934,\"start\":60684},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":145052179},\"end\":61286,\"start\":60936},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":145052179},\"end\":61631,\"start\":61288},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":7905967},\"end\":61999,\"start\":61633},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":215548442},\"end\":62380,\"start\":62001},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":215548442},\"end\":62749,\"start\":62382},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":129945843},\"end\":63090,\"start\":62751},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":215825382},\"end\":63452,\"start\":63092},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":233231713},\"end\":63816,\"start\":63454},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":201106503},\"end\":64266,\"start\":63818},{\"attributes\":{\"doi\":\"arXiv:2104.15069\",\"id\":\"b75\"},\"end\":64642,\"start\":64268},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":216080881},\"end\":64960,\"start\":64644},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":50783765},\"end\":65304,\"start\":64962},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":4475365},\"end\":65692,\"start\":65306},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":207870023},\"end\":66065,\"start\":65694},{\"attributes\":{\"doi\":\"arXiv:1706.08033\",\"id\":\"b80\"},\"end\":66369,\"start\":66067},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":9933254},\"end\":66618,\"start\":66371},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":8234308},\"end\":66956,\"start\":66620},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":232045969},\"end\":67468,\"start\":66958},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":195445470},\"end\":67802,\"start\":67470},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":4965597},\"end\":68168,\"start\":67804},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":209405397},\"end\":68554,\"start\":68170},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":209515988},\"end\":68910,\"start\":68556},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":201316548},\"end\":69189,\"start\":68912},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":4072789},\"end\":69583,\"start\":69191},{\"attributes\":{\"id\":\"b90\",\"matched_paper_id\":47017068},\"end\":69939,\"start\":69585},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":247025714},\"end\":70373,\"start\":69941},{\"attributes\":{\"id\":\"b92\",\"matched_paper_id\":247025714},\"end\":70788,\"start\":70375},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":4766599},\"end\":71207,\"start\":70790},{\"attributes\":{\"id\":\"b94\",\"matched_paper_id\":232269984},\"end\":71655,\"start\":71209},{\"attributes\":{\"id\":\"b95\",\"matched_paper_id\":219893035},\"end\":72008,\"start\":71657},{\"attributes\":{\"id\":\"b96\",\"matched_paper_id\":21661885},\"end\":72359,\"start\":72010}]", "bib_title": "[{\"end\":37667,\"start\":37610},{\"end\":37991,\"start\":37970},{\"end\":38312,\"start\":38284},{\"end\":38675,\"start\":38627},{\"end\":39097,\"start\":39039},{\"end\":39678,\"start\":39592},{\"end\":40136,\"start\":40068},{\"end\":40749,\"start\":40682},{\"end\":41083,\"start\":41032},{\"end\":41453,\"start\":41431},{\"end\":42516,\"start\":42468},{\"end\":42846,\"start\":42775},{\"end\":43270,\"start\":43215},{\"end\":43647,\"start\":43576},{\"end\":43935,\"start\":43881},{\"end\":44425,\"start\":44355},{\"end\":44759,\"start\":44723},{\"end\":45048,\"start\":45021},{\"end\":45740,\"start\":45678},{\"end\":46088,\"start\":46042},{\"end\":46326,\"start\":46286},{\"end\":46613,\"start\":46539},{\"end\":46996,\"start\":46913},{\"end\":47666,\"start\":47586},{\"end\":48205,\"start\":48138},{\"end\":48546,\"start\":48470},{\"end\":48879,\"start\":48813},{\"end\":49248,\"start\":49174},{\"end\":49627,\"start\":49574},{\"end\":50048,\"start\":50000},{\"end\":50383,\"start\":50360},{\"end\":50863,\"start\":50840},{\"end\":51286,\"start\":51202},{\"end\":52191,\"start\":52170},{\"end\":52418,\"start\":52367},{\"end\":52825,\"start\":52745},{\"end\":53251,\"start\":53197},{\"end\":53801,\"start\":53772},{\"end\":54489,\"start\":54448},{\"end\":54884,\"start\":54796},{\"end\":55338,\"start\":55268},{\"end\":55799,\"start\":55748},{\"end\":56170,\"start\":56098},{\"end\":56567,\"start\":56501},{\"end\":56897,\"start\":56819},{\"end\":57256,\"start\":57209},{\"end\":57566,\"start\":57527},{\"end\":57795,\"start\":57747},{\"end\":58186,\"start\":58091},{\"end\":58565,\"start\":58512},{\"end\":58811,\"start\":58792},{\"end\":59094,\"start\":59025},{\"end\":59454,\"start\":59395},{\"end\":60118,\"start\":60057},{\"end\":60447,\"start\":60376},{\"end\":60704,\"start\":60684},{\"end\":60999,\"start\":60936},{\"end\":61351,\"start\":61288},{\"end\":61707,\"start\":61633},{\"end\":62057,\"start\":62001},{\"end\":62441,\"start\":62382},{\"end\":62810,\"start\":62751},{\"end\":63148,\"start\":63092},{\"end\":63515,\"start\":63454},{\"end\":63880,\"start\":63818},{\"end\":64693,\"start\":64644},{\"end\":65016,\"start\":64962},{\"end\":65366,\"start\":65306},{\"end\":65772,\"start\":65694},{\"end\":66408,\"start\":66371},{\"end\":66671,\"start\":66620},{\"end\":67007,\"start\":66958},{\"end\":67511,\"start\":67470},{\"end\":67889,\"start\":67804},{\"end\":68223,\"start\":68170},{\"end\":68613,\"start\":68556},{\"end\":68942,\"start\":68912},{\"end\":69244,\"start\":69191},{\"end\":69634,\"start\":69585},{\"end\":70019,\"start\":69941},{\"end\":70453,\"start\":70375},{\"end\":70860,\"start\":70790},{\"end\":71286,\"start\":71209},{\"end\":71726,\"start\":71657},{\"end\":72067,\"start\":72010}]", "bib_author": "[{\"end\":37679,\"start\":37669},{\"end\":37688,\"start\":37679},{\"end\":37697,\"start\":37688},{\"end\":37706,\"start\":37697},{\"end\":38006,\"start\":37993},{\"end\":38022,\"start\":38006},{\"end\":38031,\"start\":38022},{\"end\":38042,\"start\":38031},{\"end\":38323,\"start\":38314},{\"end\":38335,\"start\":38323},{\"end\":38348,\"start\":38335},{\"end\":38357,\"start\":38348},{\"end\":38366,\"start\":38357},{\"end\":38688,\"start\":38677},{\"end\":38697,\"start\":38688},{\"end\":38709,\"start\":38697},{\"end\":38721,\"start\":38709},{\"end\":38728,\"start\":38721},{\"end\":38737,\"start\":38728},{\"end\":39109,\"start\":39099},{\"end\":39118,\"start\":39109},{\"end\":39128,\"start\":39118},{\"end\":39138,\"start\":39128},{\"end\":39145,\"start\":39138},{\"end\":39156,\"start\":39145},{\"end\":39165,\"start\":39156},{\"end\":39175,\"start\":39165},{\"end\":39187,\"start\":39175},{\"end\":39197,\"start\":39187},{\"end\":39207,\"start\":39197},{\"end\":39220,\"start\":39207},{\"end\":39690,\"start\":39680},{\"end\":39702,\"start\":39690},{\"end\":39716,\"start\":39702},{\"end\":39722,\"start\":39716},{\"end\":39735,\"start\":39722},{\"end\":40151,\"start\":40138},{\"end\":40162,\"start\":40151},{\"end\":40181,\"start\":40162},{\"end\":40194,\"start\":40181},{\"end\":40465,\"start\":40455},{\"end\":40479,\"start\":40465},{\"end\":40490,\"start\":40479},{\"end\":40498,\"start\":40490},{\"end\":40759,\"start\":40751},{\"end\":40767,\"start\":40759},{\"end\":40779,\"start\":40767},{\"end\":41096,\"start\":41085},{\"end\":41105,\"start\":41096},{\"end\":41114,\"start\":41105},{\"end\":41121,\"start\":41114},{\"end\":41133,\"start\":41121},{\"end\":41143,\"start\":41133},{\"end\":41463,\"start\":41455},{\"end\":41472,\"start\":41463},{\"end\":41484,\"start\":41472},{\"end\":41493,\"start\":41484},{\"end\":41502,\"start\":41493},{\"end\":41744,\"start\":41733},{\"end\":41753,\"start\":41744},{\"end\":41764,\"start\":41753},{\"end\":42028,\"start\":42019},{\"end\":42039,\"start\":42028},{\"end\":42051,\"start\":42039},{\"end\":42316,\"start\":42307},{\"end\":42327,\"start\":42316},{\"end\":42339,\"start\":42327},{\"end\":42528,\"start\":42518},{\"end\":42538,\"start\":42528},{\"end\":42859,\"start\":42848},{\"end\":42873,\"start\":42859},{\"end\":42887,\"start\":42873},{\"end\":42899,\"start\":42887},{\"end\":42913,\"start\":42899},{\"end\":43281,\"start\":43272},{\"end\":43292,\"start\":43281},{\"end\":43301,\"start\":43292},{\"end\":43657,\"start\":43649},{\"end\":43671,\"start\":43657},{\"end\":43681,\"start\":43671},{\"end\":43946,\"start\":43937},{\"end\":43957,\"start\":43946},{\"end\":43968,\"start\":43957},{\"end\":43978,\"start\":43968},{\"end\":43987,\"start\":43978},{\"end\":43999,\"start\":43987},{\"end\":44010,\"start\":43999},{\"end\":44020,\"start\":44010},{\"end\":44434,\"start\":44427},{\"end\":44444,\"start\":44434},{\"end\":44456,\"start\":44444},{\"end\":44468,\"start\":44456},{\"end\":44772,\"start\":44761},{\"end\":44781,\"start\":44772},{\"end\":44790,\"start\":44781},{\"end\":45064,\"start\":45050},{\"end\":45081,\"start\":45064},{\"end\":45090,\"start\":45081},{\"end\":45096,\"start\":45090},{\"end\":45112,\"start\":45096},{\"end\":45121,\"start\":45112},{\"end\":45134,\"start\":45121},{\"end\":45144,\"start\":45134},{\"end\":45459,\"start\":45453},{\"end\":45466,\"start\":45459},{\"end\":45474,\"start\":45466},{\"end\":45486,\"start\":45474},{\"end\":45749,\"start\":45742},{\"end\":45759,\"start\":45749},{\"end\":45771,\"start\":45759},{\"end\":45780,\"start\":45771},{\"end\":46098,\"start\":46090},{\"end\":46109,\"start\":46098},{\"end\":46334,\"start\":46328},{\"end\":46342,\"start\":46334},{\"end\":46352,\"start\":46342},{\"end\":46626,\"start\":46615},{\"end\":46633,\"start\":46626},{\"end\":46644,\"start\":46633},{\"end\":46657,\"start\":46644},{\"end\":46670,\"start\":46657},{\"end\":47004,\"start\":46998},{\"end\":47012,\"start\":47004},{\"end\":47022,\"start\":47012},{\"end\":47032,\"start\":47022},{\"end\":47303,\"start\":47294},{\"end\":47313,\"start\":47303},{\"end\":47323,\"start\":47313},{\"end\":47332,\"start\":47323},{\"end\":47679,\"start\":47668},{\"end\":47688,\"start\":47679},{\"end\":47699,\"start\":47688},{\"end\":47706,\"start\":47699},{\"end\":47716,\"start\":47706},{\"end\":47727,\"start\":47716},{\"end\":47737,\"start\":47727},{\"end\":47750,\"start\":47737},{\"end\":47761,\"start\":47750},{\"end\":47772,\"start\":47761},{\"end\":48215,\"start\":48207},{\"end\":48226,\"start\":48215},{\"end\":48558,\"start\":48548},{\"end\":48567,\"start\":48558},{\"end\":48579,\"start\":48567},{\"end\":48589,\"start\":48579},{\"end\":48602,\"start\":48589},{\"end\":48893,\"start\":48881},{\"end\":48901,\"start\":48893},{\"end\":49260,\"start\":49250},{\"end\":49268,\"start\":49260},{\"end\":49277,\"start\":49268},{\"end\":49289,\"start\":49277},{\"end\":49639,\"start\":49629},{\"end\":49648,\"start\":49639},{\"end\":49659,\"start\":49648},{\"end\":49671,\"start\":49659},{\"end\":49683,\"start\":49671},{\"end\":49691,\"start\":49683},{\"end\":50059,\"start\":50050},{\"end\":50066,\"start\":50059},{\"end\":50074,\"start\":50066},{\"end\":50087,\"start\":50074},{\"end\":50099,\"start\":50087},{\"end\":50393,\"start\":50385},{\"end\":50403,\"start\":50393},{\"end\":50414,\"start\":50403},{\"end\":50425,\"start\":50414},{\"end\":50431,\"start\":50425},{\"end\":50440,\"start\":50431},{\"end\":50453,\"start\":50440},{\"end\":50464,\"start\":50453},{\"end\":50470,\"start\":50464},{\"end\":50476,\"start\":50470},{\"end\":50485,\"start\":50476},{\"end\":50491,\"start\":50485},{\"end\":50500,\"start\":50491},{\"end\":50509,\"start\":50500},{\"end\":50518,\"start\":50509},{\"end\":50873,\"start\":50865},{\"end\":50883,\"start\":50873},{\"end\":50894,\"start\":50883},{\"end\":50905,\"start\":50894},{\"end\":50911,\"start\":50905},{\"end\":50920,\"start\":50911},{\"end\":50933,\"start\":50920},{\"end\":50944,\"start\":50933},{\"end\":50950,\"start\":50944},{\"end\":50956,\"start\":50950},{\"end\":51297,\"start\":51288},{\"end\":51306,\"start\":51297},{\"end\":51316,\"start\":51306},{\"end\":51329,\"start\":51316},{\"end\":51343,\"start\":51329},{\"end\":51353,\"start\":51343},{\"end\":51363,\"start\":51353},{\"end\":51373,\"start\":51363},{\"end\":51381,\"start\":51373},{\"end\":51389,\"start\":51381},{\"end\":51867,\"start\":51860},{\"end\":51875,\"start\":51867},{\"end\":51884,\"start\":51875},{\"end\":51892,\"start\":51884},{\"end\":51901,\"start\":51892},{\"end\":51910,\"start\":51901},{\"end\":51918,\"start\":51910},{\"end\":51925,\"start\":51918},{\"end\":51933,\"start\":51925},{\"end\":52202,\"start\":52193},{\"end\":52214,\"start\":52202},{\"end\":52429,\"start\":52420},{\"end\":52440,\"start\":52429},{\"end\":52449,\"start\":52440},{\"end\":52461,\"start\":52449},{\"end\":52471,\"start\":52461},{\"end\":52834,\"start\":52827},{\"end\":52844,\"start\":52834},{\"end\":52855,\"start\":52844},{\"end\":52866,\"start\":52855},{\"end\":52877,\"start\":52866},{\"end\":52889,\"start\":52877},{\"end\":53260,\"start\":53253},{\"end\":53267,\"start\":53260},{\"end\":53276,\"start\":53267},{\"end\":53284,\"start\":53276},{\"end\":53291,\"start\":53284},{\"end\":53299,\"start\":53291},{\"end\":53600,\"start\":53593},{\"end\":53606,\"start\":53600},{\"end\":53615,\"start\":53606},{\"end\":53625,\"start\":53615},{\"end\":53637,\"start\":53625},{\"end\":53810,\"start\":53803},{\"end\":53817,\"start\":53810},{\"end\":53823,\"start\":53817},{\"end\":53830,\"start\":53823},{\"end\":53841,\"start\":53830},{\"end\":53851,\"start\":53841},{\"end\":54136,\"start\":54124},{\"end\":54145,\"start\":54136},{\"end\":54156,\"start\":54145},{\"end\":54168,\"start\":54156},{\"end\":54180,\"start\":54168},{\"end\":54190,\"start\":54180},{\"end\":54501,\"start\":54491},{\"end\":54511,\"start\":54501},{\"end\":54520,\"start\":54511},{\"end\":54529,\"start\":54520},{\"end\":54900,\"start\":54886},{\"end\":54916,\"start\":54900},{\"end\":54931,\"start\":54916},{\"end\":54946,\"start\":54931},{\"end\":54961,\"start\":54946},{\"end\":54967,\"start\":54961},{\"end\":54974,\"start\":54967},{\"end\":55354,\"start\":55340},{\"end\":55370,\"start\":55354},{\"end\":55380,\"start\":55370},{\"end\":55392,\"start\":55380},{\"end\":55407,\"start\":55392},{\"end\":55413,\"start\":55407},{\"end\":55810,\"start\":55801},{\"end\":55824,\"start\":55810},{\"end\":55833,\"start\":55824},{\"end\":55841,\"start\":55833},{\"end\":56188,\"start\":56172},{\"end\":56194,\"start\":56188},{\"end\":56203,\"start\":56194},{\"end\":56215,\"start\":56203},{\"end\":56225,\"start\":56215},{\"end\":56581,\"start\":56569},{\"end\":56591,\"start\":56581},{\"end\":56911,\"start\":56899},{\"end\":56921,\"start\":56911},{\"end\":57269,\"start\":57258},{\"end\":57276,\"start\":57269},{\"end\":57579,\"start\":57568},{\"end\":57586,\"start\":57579},{\"end\":57594,\"start\":57586},{\"end\":57601,\"start\":57594},{\"end\":57805,\"start\":57797},{\"end\":57814,\"start\":57805},{\"end\":57822,\"start\":57814},{\"end\":57828,\"start\":57822},{\"end\":57841,\"start\":57828},{\"end\":57850,\"start\":57841},{\"end\":57859,\"start\":57850},{\"end\":58198,\"start\":58188},{\"end\":58210,\"start\":58198},{\"end\":58220,\"start\":58210},{\"end\":58233,\"start\":58220},{\"end\":58243,\"start\":58233},{\"end\":58577,\"start\":58567},{\"end\":58593,\"start\":58577},{\"end\":58604,\"start\":58593},{\"end\":58824,\"start\":58813},{\"end\":58834,\"start\":58824},{\"end\":59108,\"start\":59096},{\"end\":59120,\"start\":59108},{\"end\":59131,\"start\":59120},{\"end\":59467,\"start\":59456},{\"end\":59476,\"start\":59467},{\"end\":59485,\"start\":59476},{\"end\":59744,\"start\":59733},{\"end\":59752,\"start\":59744},{\"end\":59761,\"start\":59752},{\"end\":59770,\"start\":59761},{\"end\":59776,\"start\":59770},{\"end\":59788,\"start\":59776},{\"end\":59799,\"start\":59788},{\"end\":59810,\"start\":59799},{\"end\":60131,\"start\":60120},{\"end\":60139,\"start\":60131},{\"end\":60151,\"start\":60139},{\"end\":60161,\"start\":60151},{\"end\":60461,\"start\":60449},{\"end\":60467,\"start\":60461},{\"end\":60475,\"start\":60467},{\"end\":60482,\"start\":60475},{\"end\":60489,\"start\":60482},{\"end\":60715,\"start\":60706},{\"end\":60726,\"start\":60715},{\"end\":60734,\"start\":60726},{\"end\":60746,\"start\":60734},{\"end\":61013,\"start\":61001},{\"end\":61022,\"start\":61013},{\"end\":61034,\"start\":61022},{\"end\":61365,\"start\":61353},{\"end\":61374,\"start\":61365},{\"end\":61386,\"start\":61374},{\"end\":61716,\"start\":61709},{\"end\":61729,\"start\":61716},{\"end\":61738,\"start\":61729},{\"end\":61748,\"start\":61738},{\"end\":61758,\"start\":61748},{\"end\":62069,\"start\":62059},{\"end\":62077,\"start\":62069},{\"end\":62085,\"start\":62077},{\"end\":62096,\"start\":62085},{\"end\":62453,\"start\":62443},{\"end\":62461,\"start\":62453},{\"end\":62469,\"start\":62461},{\"end\":62480,\"start\":62469},{\"end\":62823,\"start\":62812},{\"end\":62832,\"start\":62823},{\"end\":62841,\"start\":62832},{\"end\":62850,\"start\":62841},{\"end\":63161,\"start\":63150},{\"end\":63170,\"start\":63161},{\"end\":63179,\"start\":63170},{\"end\":63532,\"start\":63517},{\"end\":63544,\"start\":63532},{\"end\":63557,\"start\":63544},{\"end\":63894,\"start\":63882},{\"end\":63903,\"start\":63894},{\"end\":63915,\"start\":63903},{\"end\":63928,\"start\":63915},{\"end\":63940,\"start\":63928},{\"end\":63947,\"start\":63940},{\"end\":63960,\"start\":63947},{\"end\":64353,\"start\":64345},{\"end\":64360,\"start\":64353},{\"end\":64368,\"start\":64360},{\"end\":64381,\"start\":64368},{\"end\":64389,\"start\":64381},{\"end\":64402,\"start\":64389},{\"end\":64414,\"start\":64402},{\"end\":64705,\"start\":64695},{\"end\":64716,\"start\":64705},{\"end\":65030,\"start\":65018},{\"end\":65040,\"start\":65030},{\"end\":65051,\"start\":65040},{\"end\":65380,\"start\":65368},{\"end\":65389,\"start\":65380},{\"end\":65397,\"start\":65389},{\"end\":65406,\"start\":65397},{\"end\":65786,\"start\":65774},{\"end\":65796,\"start\":65786},{\"end\":65806,\"start\":65796},{\"end\":65815,\"start\":65806},{\"end\":65823,\"start\":65815},{\"end\":65830,\"start\":65823},{\"end\":66149,\"start\":66137},{\"end\":66157,\"start\":66149},{\"end\":66165,\"start\":66157},{\"end\":66172,\"start\":66165},{\"end\":66179,\"start\":66172},{\"end\":66422,\"start\":66410},{\"end\":66436,\"start\":66422},{\"end\":66448,\"start\":66436},{\"end\":66685,\"start\":66673},{\"end\":66697,\"start\":66685},{\"end\":67017,\"start\":67009},{\"end\":67025,\"start\":67017},{\"end\":67035,\"start\":67025},{\"end\":67051,\"start\":67035},{\"end\":67059,\"start\":67051},{\"end\":67071,\"start\":67059},{\"end\":67089,\"start\":67071},{\"end\":67100,\"start\":67089},{\"end\":67114,\"start\":67100},{\"end\":67521,\"start\":67513},{\"end\":67528,\"start\":67521},{\"end\":67536,\"start\":67528},{\"end\":67543,\"start\":67536},{\"end\":67899,\"start\":67891},{\"end\":67907,\"start\":67899},{\"end\":67915,\"start\":67907},{\"end\":67922,\"start\":67915},{\"end\":67930,\"start\":67922},{\"end\":68234,\"start\":68225},{\"end\":68246,\"start\":68234},{\"end\":68258,\"start\":68246},{\"end\":68269,\"start\":68258},{\"end\":68623,\"start\":68615},{\"end\":68631,\"start\":68623},{\"end\":68638,\"start\":68631},{\"end\":68646,\"start\":68638},{\"end\":68653,\"start\":68646},{\"end\":68950,\"start\":68944},{\"end\":68959,\"start\":68950},{\"end\":68968,\"start\":68959},{\"end\":68980,\"start\":68968},{\"end\":69252,\"start\":69246},{\"end\":69259,\"start\":69252},{\"end\":69267,\"start\":69259},{\"end\":69275,\"start\":69267},{\"end\":69281,\"start\":69275},{\"end\":69292,\"start\":69281},{\"end\":69642,\"start\":69636},{\"end\":69649,\"start\":69642},{\"end\":69657,\"start\":69649},{\"end\":69665,\"start\":69657},{\"end\":69671,\"start\":69665},{\"end\":69682,\"start\":69671},{\"end\":70027,\"start\":70021},{\"end\":70035,\"start\":70027},{\"end\":70041,\"start\":70035},{\"end\":70048,\"start\":70041},{\"end\":70055,\"start\":70048},{\"end\":70063,\"start\":70055},{\"end\":70071,\"start\":70063},{\"end\":70461,\"start\":70455},{\"end\":70469,\"start\":70461},{\"end\":70475,\"start\":70469},{\"end\":70482,\"start\":70475},{\"end\":70489,\"start\":70482},{\"end\":70497,\"start\":70489},{\"end\":70505,\"start\":70497},{\"end\":70871,\"start\":70862},{\"end\":70880,\"start\":70871},{\"end\":70891,\"start\":70880},{\"end\":70904,\"start\":70891},{\"end\":70912,\"start\":70904},{\"end\":71296,\"start\":71288},{\"end\":71303,\"start\":71296},{\"end\":71312,\"start\":71303},{\"end\":71320,\"start\":71312},{\"end\":71329,\"start\":71320},{\"end\":71340,\"start\":71329},{\"end\":71346,\"start\":71340},{\"end\":71736,\"start\":71728},{\"end\":71746,\"start\":71736},{\"end\":71755,\"start\":71746},{\"end\":71764,\"start\":71755},{\"end\":71775,\"start\":71764},{\"end\":72077,\"start\":72069},{\"end\":72084,\"start\":72077},{\"end\":72091,\"start\":72084},{\"end\":72105,\"start\":72091},{\"end\":72117,\"start\":72105},{\"end\":72126,\"start\":72117}]", "bib_venue": "[{\"end\":37748,\"start\":37706},{\"end\":38093,\"start\":38042},{\"end\":38408,\"start\":38366},{\"end\":38789,\"start\":38737},{\"end\":39272,\"start\":39220},{\"end\":39787,\"start\":39735},{\"end\":40213,\"start\":40194},{\"end\":40453,\"start\":40392},{\"end\":40821,\"start\":40779},{\"end\":41195,\"start\":41143},{\"end\":41544,\"start\":41502},{\"end\":41852,\"start\":41780},{\"end\":42115,\"start\":42067},{\"end\":42305,\"start\":42259},{\"end\":42581,\"start\":42538},{\"end\":42955,\"start\":42913},{\"end\":43353,\"start\":43301},{\"end\":43718,\"start\":43681},{\"end\":44072,\"start\":44020},{\"end\":44509,\"start\":44468},{\"end\":44832,\"start\":44790},{\"end\":45181,\"start\":45144},{\"end\":45451,\"start\":45372},{\"end\":45822,\"start\":45780},{\"end\":46156,\"start\":46109},{\"end\":46389,\"start\":46352},{\"end\":46707,\"start\":46670},{\"end\":47074,\"start\":47032},{\"end\":47415,\"start\":47348},{\"end\":47814,\"start\":47772},{\"end\":48268,\"start\":48226},{\"end\":48625,\"start\":48602},{\"end\":48953,\"start\":48901},{\"end\":49340,\"start\":49289},{\"end\":49743,\"start\":49691},{\"end\":50141,\"start\":50099},{\"end\":50546,\"start\":50518},{\"end\":50999,\"start\":50956},{\"end\":51441,\"start\":51389},{\"end\":51858,\"start\":51784},{\"end\":52258,\"start\":52214},{\"end\":52521,\"start\":52471},{\"end\":52931,\"start\":52889},{\"end\":53351,\"start\":53299},{\"end\":53672,\"start\":53637},{\"end\":53903,\"start\":53851},{\"end\":54253,\"start\":54190},{\"end\":54575,\"start\":54529},{\"end\":55017,\"start\":54974},{\"end\":55459,\"start\":55413},{\"end\":55885,\"start\":55841},{\"end\":56284,\"start\":56225},{\"end\":56639,\"start\":56591},{\"end\":56973,\"start\":56921},{\"end\":57328,\"start\":57276},{\"end\":57620,\"start\":57601},{\"end\":57896,\"start\":57859},{\"end\":58291,\"start\":58243},{\"end\":58641,\"start\":58604},{\"end\":58879,\"start\":58834},{\"end\":59173,\"start\":59131},{\"end\":59527,\"start\":59485},{\"end\":59866,\"start\":59826},{\"end\":60198,\"start\":60161},{\"end\":60514,\"start\":60489},{\"end\":60794,\"start\":60746},{\"end\":61076,\"start\":61034},{\"end\":61427,\"start\":61386},{\"end\":61805,\"start\":61758},{\"end\":62148,\"start\":62096},{\"end\":62532,\"start\":62480},{\"end\":62892,\"start\":62850},{\"end\":63231,\"start\":63179},{\"end\":63599,\"start\":63557},{\"end\":64002,\"start\":63960},{\"end\":64343,\"start\":64268},{\"end\":64768,\"start\":64716},{\"end\":65097,\"start\":65051},{\"end\":65458,\"start\":65406},{\"end\":65867,\"start\":65830},{\"end\":66135,\"start\":66067},{\"end\":66485,\"start\":66448},{\"end\":66749,\"start\":66697},{\"end\":67166,\"start\":67114},{\"end\":67595,\"start\":67543},{\"end\":67967,\"start\":67930},{\"end\":68321,\"start\":68269},{\"end\":68695,\"start\":68653},{\"end\":69022,\"start\":68980},{\"end\":69344,\"start\":69292},{\"end\":69724,\"start\":69682},{\"end\":70121,\"start\":70071},{\"end\":70567,\"start\":70505},{\"end\":70964,\"start\":70912},{\"end\":71396,\"start\":71346},{\"end\":71823,\"start\":71775},{\"end\":72174,\"start\":72126},{\"end\":37786,\"start\":37750},{\"end\":38140,\"start\":38095},{\"end\":38446,\"start\":38410},{\"end\":38837,\"start\":38791},{\"end\":39320,\"start\":39274},{\"end\":39835,\"start\":39789},{\"end\":40859,\"start\":40823},{\"end\":41243,\"start\":41197},{\"end\":41582,\"start\":41546},{\"end\":42620,\"start\":42583},{\"end\":42993,\"start\":42957},{\"end\":43401,\"start\":43355},{\"end\":44120,\"start\":44074},{\"end\":44546,\"start\":44511},{\"end\":44870,\"start\":44834},{\"end\":45860,\"start\":45824},{\"end\":47112,\"start\":47076},{\"end\":47852,\"start\":47816},{\"end\":48306,\"start\":48270},{\"end\":48635,\"start\":48627},{\"end\":49001,\"start\":48955},{\"end\":49387,\"start\":49342},{\"end\":49791,\"start\":49745},{\"end\":50179,\"start\":50143},{\"end\":51489,\"start\":51443},{\"end\":52567,\"start\":52523},{\"end\":52969,\"start\":52933},{\"end\":53399,\"start\":53353},{\"end\":53951,\"start\":53905},{\"end\":54617,\"start\":54577},{\"end\":55501,\"start\":55461},{\"end\":55925,\"start\":55887},{\"end\":57021,\"start\":56975},{\"end\":57376,\"start\":57330},{\"end\":58920,\"start\":58881},{\"end\":59211,\"start\":59175},{\"end\":59565,\"start\":59529},{\"end\":61114,\"start\":61078},{\"end\":61464,\"start\":61429},{\"end\":62196,\"start\":62150},{\"end\":62580,\"start\":62534},{\"end\":62930,\"start\":62894},{\"end\":63279,\"start\":63233},{\"end\":63637,\"start\":63601},{\"end\":64040,\"start\":64004},{\"end\":64816,\"start\":64770},{\"end\":65139,\"start\":65099},{\"end\":65506,\"start\":65460},{\"end\":66797,\"start\":66751},{\"end\":67214,\"start\":67168},{\"end\":67643,\"start\":67597},{\"end\":68369,\"start\":68323},{\"end\":68733,\"start\":68697},{\"end\":69060,\"start\":69024},{\"end\":69392,\"start\":69346},{\"end\":69762,\"start\":69726},{\"end\":70167,\"start\":70123},{\"end\":71012,\"start\":70966},{\"end\":71442,\"start\":71398}]"}}}, "year": 2023, "month": 12, "day": 17}