{"id": 17865105, "updated": "2023-12-13 01:10:23.687", "metadata": {"title": "Edinburgh Research Explorer Learning to Generate Product Reviews from Attributes", "authors": "[{\"first\":\"Li\",\"last\":\"Dong\",\"middle\":[]},{\"first\":\"Shaohan\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Furu\",\"last\":\"Wei\",\"middle\":[]},{\"first\":\"Mirella\",\"last\":\"Lapata\",\"middle\":[]},{\"first\":\"Ming\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Ke\",\"last\":\"Xu\",\"middle\":[]}]", "venue": "EACL", "journal": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "Automatically generating product reviews is a meaningful, yet not well-studied task in sentiment analysis. Traditional natu-ral language generation methods rely extensively on hand-crafted rules and prede-\ufb01ned templates. This paper presents an attention-enhanced attribute-to-sequence model to generate product reviews for given attribute information, such as user, product, and rating. The attribute encoder learns to represent input attributes as vectors. Then, the sequence decoder generates reviews by conditioning its output on these vectors. We also introduce an attention mechanism to jointly generate reviews and align words with input attributes. The proposed model is trained end-to-end to maximize the likelihood of target product reviews given the attributes. We build a publicly available dataset for the review generation task by leveraging the Amazon book reviews and their meta-data. Experiments on the dataset show that our approach outperforms baseline meth-ods and the attention mechanism significantly improves the performance of our model.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.18653/v1/e17-1059"}}, "content": {"source": {"pdf_hash": "2177054fa3a7b2ba3ac72f74fabd4278f5092eec", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/E17-1059.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/E17-1059.pdf", "status": "HYBRID"}}, "grobid": {"id": "6ed347d125226e3d511d310203dd92e00e49ef30", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/2177054fa3a7b2ba3ac72f74fabd4278f5092eec.txt", "contents": "\nLearning to Generate Product Reviews from Attributes\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsApril 3-7, 2017. 2017\n\nLi Dong li.dong@ed.ac.uk \nUniversity of Edinburgh\nEdinburghUnited Kingdom\n\nShaohan Huang \nMicrosoft Research\nBeijingChina\n\nBeihang University\nBeijingChina\n\nFuru Wei \nMicrosoft Research\nBeijingChina\n\nBeihang University\nBeijingChina\n\nMirella Lapata \nUniversity of Edinburgh\nEdinburghUnited Kingdom\n\nMing Zhou mingzhou@microsoft.com \nMicrosoft Research\nBeijingChina\n\nBeihang University\nBeijingChina\n\nKe Xu kexu@nlsde.buaa.edu.cn \nLearning to Generate Product Reviews from Attributes\n\nthe Association for Computational Linguistics\nthe 15th Conference of the European ChapterValencia, SpainAssociation for Computational Linguistics1April 3-7, 2017. 2017\nAutomatically generating product reviews is a meaningful, yet not well-studied task in sentiment analysis. Traditional natural language generation methods rely extensively on hand-crafted rules and predefined templates. This paper presents an attention-enhanced attribute-to-sequence model to generate product reviews for given attribute information, such as user, product, and rating. The attribute encoder learns to represent input attributes as vectors. Then, the sequence decoder generates reviews by conditioning its output on these vectors. We also introduce an attention mechanism to jointly generate reviews and align words with input attributes. The proposed model is trained end-to-end to maximize the likelihood of target product reviews given the attributes. We build a publicly available dataset for the review generation task by leveraging the Amazon book reviews and their metadata. Experiments on the dataset show that our approach outperforms baseline methods and the attention mechanism significantly improves the performance of our model.\n\nIntroduction\n\nNowadays, there are many popular online review sites (such as Amazon, and Yelp) that allow users to read and post reviews about books, electronics, restaurants, etc. The reviews are used to express opinions for different aspects of products, and have a wide variety of writing styles and different polarity strengths. As a result, much previous work has focused on how opinions are expressed in review data. For example, previous studies on User Product Rating\n\n\nAttribute Encoder\n\nSequence Decoder LSTM I loved this family story , it was touching .\n\n\nAttention Layer\n\nFigure 1: Our model learns to encode attributes into vectors, and then uses recurrent neural networks based on long short-term memory (LSTM) units to generate reviews by conditioning on the encoding vectors. An attention layer is used to learn soft alignments between attributes and generated words. sentiment analysis identify and extract subjective content in review data (Liu, 2015). However, few studies have explored building data-driven models that can generate product reviews for the given products and ratings, which is helpful to understand how a specific user comments for products. As shown in Figure 1, the input to our model is a set of attributes (such as user, product, and rating information), and our goal is to generate userand product-specific reviews that agree with the input rating. These automatically generated reviews are useful for companies. For example, we could promote a product to users who have not bought it, by generating novel and personalized recommendations. We could also build a review writing assistant for E-commerce websites. After the website generates some candidate reviews according to the user's rating score, users could select one and refine it, which makes the procedure more user-friendly. Moreover, we can generate novel and personalized recommendations for every user, which makes the recommendation system more interpretable.\n\nThis attribute-conditioned review generation problem is very challenging due to the variety of candidate reviews that satisfy the input attributes. In other words, apart from the given attributes, there are other unknown or latent factors that influence the generated reviews, which renders the generation process non-deterministic. Moreover, although some attributes (such as rating) explicitly determine the usage of sentiment words, others (e.g., user information) implicitly influence word usage. So the model needs to handle both explicit and implicit clues. Additionally, the interactions between attributes are important to obtain the hidden factors used for generation. For example, different users tend to describe different aspects of a product and use different sentiment words to express a rating score.\n\nIn this paper, we propose a neural network based attribute-to-sequence model. As shown in Figure 1, our model contains three parts: attribute encoder, sequence decoder, and an attention mechanism. Specifically, we first use multilayer perceptrons to encode input attributes into vector representations that are used as latent factors for generating reviews. Next, the encoding vectors are fed into a coarse-to-fine sequence decoder. The decoder is built by stacking multiple layers of recurrent neural networks, which can generate words one by one conditioning on the encoding vectors. Besides, we introduce an attention layer into the proposed attribute-to-sequence model. The attention mechanism learns soft alignments between generated words and attributes, and adaptively computes encoder-side context vectors used to predict the next tokens. In order to evaluate our method, we build a dataset based on Amazon reviews and performed experiments on it. The experimental results show that the proposed model achieves superior performance against baseline methods. Moreover, we demonstrate that the attention mechanism significantly improves the performance of our model.\n\nThe contributions of this work are three-fold:\n\n\u2022 We introduce the task of attributeconditioned review generation, which is valuable for sentiment analysis, but not well studied previously.\n\n\u2022 We propose an attention-enhanced attributeto-sequence model in order to generate reviews conditioned on input attributes.\n\n\u2022 We create a dataset based on Amazon book reviews and present empirical studies to show the proposed model outperforms several baseline methods.\n\n\nRelated Work\n\nSentiment analysis and opinion mining aim to identify and extract subjective content in text (Liu, 2015). Most previous work focuses on using rulebased methods or machine learning techniques for sentiment classification, which classifies reviews into different sentiment categories. Recently, deep learning has achieved promising results on sentiment analysis (Socher et al., 2011;Dong et al., 2014;Kim, 2014). Lipton et al. (2015) use character-level concatenated input recurrent neural networks as a generative model to predict rating and category for reviews. In contrast, our model is mainly evaluated on the review generation task rather than classification. Moreover, we use an attention mechanism in our encoderdecoder model, which has been proved very helpful in various tasks (Bahdanau et al., 2015;Xu et al., 2015), to generate user-and product-specific reviews. Maqsud (2015) compare latent Dirichlet allocation, Markov chains, and hidden Markov models for text generation on review data. However, we focus on generating product reviews conditioned on input attributes. Park et al. (2015) propose to retrieve relevant opinion sentences using product specifications as queries, while we work on generation instead of retrieval. Our task definition is also related to concept-totext generation (Konstas and Lapata, 2012;Konstas and Lapata, 2013), such as generating weather forecast or sportscasting from database records. A typical system contains three main stages: content planning, sentence planning, and surface realization. Mei et al. (2016) treat database records and output texts as sequences, and use recurrent neural networks to encode and decode them. In contrast, our input is a set of discrete attributes instead of database records or sequences. In addition, the contents of database records are strong constraints on results in concept-to-text generation. However, in our setting, user and product information implicitly indicates the style of generated reviews, which makes the results extremely diverse.\n\nAnother line of related work is the encoderdecoder model with neural networks. Specifically, an encoder is employed to encode input information into vectors, and then a decoder learns to predict results by conditioning outputs on the encoding vectors. This general framework is flexible because different neural networks can be used for encoders and decoders depending on the nature of inputs and outputs, which has been used to address various tasks. For example, recurrent neural networks are used to model sequences, such as machine translation (Kalchbrenner and Blunsom, 2013;Sutskever et al., 2014), syntactic parsing (Vinyals et al., 2015b), and semantic parsing (Dong and Lapata, 2016). Additionally, convolutional neural networks are employed for image data, such as image caption generation (Vinyals et al., 2015a), and video description generation . Our model employs multilayer perceptron to encode attribute information, and uses recurrent neural networks to decode product reviews. In order to better handle alignments between inputs and outputs, the attention mechanism is introduced for the encoder-decoder model. The attention model boosts performance for various tasks (Bahdanau et al., 2015;Luong et al., 2015;Xu et al., 2015). In our work, we use the attention mechanism to learn soft alignments between input attributes and output sequences, which has not, to our knowledge, been studied in previous work. Dosovitskiy et al. (2015) propose to use generative convolutional neural networks to generate images of chairs given chair type, viewpoint and color. Similarly, Yan et al. (2016) use variational auto-encoders to generate face images conditioned on visual attributes. However, our goal is to generate texts instead of images. Moreover, we learn a neural attention model to attend over input attributes during generation.\n\n\nModelling Approach\n\nTo begin with, we state the product review generation problem as follows. Given input attributes a = a 1 , \u00b7 \u00b7 \u00b7 , a |a| , our goal is to generate a product review r = y 1 , \u00b7 \u00b7 \u00b7 , y |r| maximizing the conditional probability p (r|a). Notice that number of attributes |a| is fixed, while the review r is considered a word sequence of variable length. We use the user ID, product ID, and rating as attributes, so |a| is set to 3 in our task. The training data are attributes paired with corresponding reviews. The model learns to compute the likelihood of generated reviews given input attributes. This condi-  tional probability p (r|a) is decomposed to:\np (r|a) = |r| t=1 p (y t |y <t , a)(1)\nwhere y <t = (y 1 , \u00b7 \u00b7 \u00b7 , y t\u22121 ). Our method consists of three parts, i.e., an attribute encoder, a sequence decoder, and an attention layer. The attribute encoder employs multilayer perceptrons to encode attributes a to vectors. To be specific, we represent the attributes as vectors. Next, the concatenation of these vectors is fed into a hidden layer to obtain the encoding vectors. After we obtain the encoding vectors, the sequence decoder stacks L-layer recurrent neural networks (RNNs) to generate reviews conditioning on these vectors. During decoding, RNNs recurrently compute n-dimensional hidden vectors which are used to predict output words for different time steps. In order to better utilize encoderside information, an attention layer is introduced to learn soft alignments between attributes and output words. For every decoding time step, we use the current hidden vector to compute attention scores over attribute vectors. Then, a weighted sum of attribute vectors is used as the context vector to predict output words.\n\nWe first describe the attribute-to-sequence model without using neural attention in Section 3.1 and Section 3.2. Next, we introduce the attention mechanism in Section 3.3.\n\n\nAttribute Encoder\n\nWe use multilayer perceptrons with one hidden layer to encode attribute information into a vector as shown in Figure 2. At first, input attributes a = a 1 , \u00b7 \u00b7 \u00b7 , a |a| are represented by low-dimensional vectors. The attribute a i 's vector g (a i ) is computed via:\ng (a i ) = W a i e (a i )(2)\nwhere W a i \u2208 R m\u00d7|a i | is a parameter matrix, m is the dimension of embedding, and e (a i ) \u2208 {0, 1} |a i | is a one-hot vector representing the presence or absence of a i . Then, these attribute vectors are concatenated and fed into a hidden layer which outputs the encoding vector. The output of the hidden layer is computed as:\na = tanh H[g (a 1 ), \u00b7 \u00b7 \u00b7 , g a |a| ] + b a(3)\nwhere [g (a 1 ), \u00b7 \u00b7 \u00b7 , g a |a| ] are concatenated attribute vectors, tanh is a nonlinearity function, H \u2208 R Ln\u00d7|a|m is a weight matrix, and b a \u2208 R Ln is the bias. Next, the vector a is used to initialize the n-dimensional hidden vectors of the L-layer recurrent neural networks in the decoder.\n\n\nSequence Decoder\n\nAs shown in Figure 2, the decoder is built upon multilayer recurrent neural networks (RNNs) with long short-term memory (LSTM) units. RNNs use vectors to represent information for the current time step and recurrently compute the next hidden states. In our work, we stack multiple layers of RNNs in our architecture. Additionally, a long short-term memory (Hochreiter and Schmidhuber, 1997) unit is employed to better handle long sequences. The LSTM introduces several gates and explicit memory cells to memorize or forget information, which enables networks learn more complicated patterns. Let h l t \u2208 R n denote an n-dimensional hidden vector in layer l and time step t. h l t is computed via:\nh l t = f h l t\u22121 , h l\u22121 t(4)\nwhere h 0 t = W r e (y t\u22121 ) is the word embedding of the previous predicted word, W r \u2208 R n\u00d7|Vr| is a parameter matrix, |V r | is the vocabulary size, and e (y t\u22121 ) is a one-hot vector used to extract word vector for y t\u22121 . We follow the architecture of LSTM unit described in Zaremba et al. (2015). To be specific, the unit is given by:\n\uf8eb \uf8ec \uf8ec \uf8ed i f o g \uf8f6 \uf8f7 \uf8f7 \uf8f8 = \uf8eb \uf8ec \uf8ec \uf8ed sigm sigm sigm tanh \uf8f6 \uf8f7 \uf8f7 \uf8f8 W l h l\u22121 t h l t\u22121 p l t = f p l t\u22121 + i g h l t = o tanh p l t(5)\nwhere tanh, sigm, and are element-wise operators, and W l \u2208 R 4n\u00d72n is a weight matrix for the l-th layer.\n\nOnce the input attributes are encoded to the vector a \u2208 R Ln by Equation (3), the encoding vector is split into L vectors to initialize the hidden vectors of the first time step in decoder. Then, RNNs compute hidden vectors recurrently and predict output words using the hidden vectors of the topmost layer h L t . For the vanilla model without using an attention mechanism, the predicted distribution of the t-th output word is:\np (y t |y <t , a) = softmax yt W p h L t(6)\nwhere W p \u2208 R |Vr|\u00d7n is a parameter matrix.\n\n\nAttention Mechanism\n\nThe attention mechanism is introduced to better utilize encoder-side information. As indicated in Equation (6), the vanilla model does not directly use attribute vectors to generate sequences. Intuitively, the model can concentrate on different parts of encoding information to predict the next word. Previous work has proved this idea significantly improves performance especially for long sequences (Bahdanau et al., 2015;Vinyals et al., 2015b;Luong et al., 2015). Figure 3 demonstrates how to compute the encoder-side context vector and use it to predict output words. For the t-th time step of the decoder, we compute the attention score of attribute a i via:\ns t i = exp tanh W s h L t , g (a i ) /Z(7)\nwhere the brackets [\u00b7, \u00b7] denote concatenation, Z is a normalization term that ensures |a| i=1 s t i = 1, and W s \u2208 R 1\u00d7(n+m) is a parameter matrix. Next, the attention context vector c t is obtained by:\nc t = |a| i=1 s t i g (a i )(8)\nwhich is a weighted sum of attribute vectors. We further employ the vector c t to predict the t-th output token as:\nh att t = tanh W 1 c t + W 2 h L t(9)\np (y t |y <t , a) = softmax yt W p h att t\n\nwhere W p \u2208 R |Vr|\u00d7n , W 1 \u2208 R n\u00d7m and W 2 \u2208 R n\u00d7n are three parameter matrices.\n\n\nLSTM LSTM LSTM Attribute Encoder\n\nUser Product Rating Attention Scores Figure 3: Attention scores are computed by attribute vectors and the current hidden vector of the decoder. Then, the encoder-side context vector is obtained in the form of a weighted sum, which is further used to predict the word distribution.\n\n\nModel Training\n\nWe aim at maximizing the likelihood of generated reviews given input attributes for the training data. So we define the optimization problem as:\nmaximize (a,r)\u2208D log p (r|a)(11)\nwhere D is the dataset of all attribute-review training pairs, and p (r|a) is defined as shown in Equation (1). In order to avoid overfitting, we insert dropout layers between different LSTM layers as suggested in Zaremba et al. (2015). The minibatched RMSProp (Tieleman and Hinton, 2012) algorithm is used to optimize the objective function.\n\n\nInference\n\nAt test time, we first use the encoder to encode input attributes into vectors, and use them to initialize the LSTM units of the decoder. Then, the decoder predicts a reviewr that maximizes the conditional probability defined in Equation (1):\nr = arg max r p r |a(12)\nwhere r is a candidate review. Because we decompose this probability as shown in Equation (1), we can use beam search or greedy search to generate words, which avoids iterating over all candidate reviews. In order to determine the termination of the generation process, we add a special token </s> to the end of every output review. The generation terminates once this token is emitted.\n\n\nExperiments\n\nWe first introduce a new dataset for this task and compare our method with several baseline ap-proaches. Then we conduct some ablation experiments and present model analysis to help us understand what the model learns.\n\n\nDataset Description\n\nOur dataset is built upon Amazon product data  that includes reviews and metadata spanning from May 1996 to July 2014 with duplicates removed. The products of the book domain are used in our experiments. Every review is paired with three attributes, i.e., user ID, product ID and rating. We filter books and users which do not occur at least 6 and 15 times, respectively. The reviews whose lengths are greater than 60 words are filtered. Because we observe that long reviews mainly describe the plots of books, while our goal is to generate reviews expressing opinions. The average review length is about 35 words, and the average number of sentences is 3. The dataset contains 937, 033 reviews paired with attributes. Specifically, we have 80, 256 books, 19, 675 users, and 5 rating levels. The word vocabulary size is 161K. Then, the whole dataset is randomly split into TRAIN, DEV, and TEST (70%/10%/20%). The dataset is available at https://goo.gl/TFjEH4.\n\n\nSettings\n\nWe used NLTK (Bird et al., 2009) to tokenize the reviews, and employed the Wikipedia list of common misspellings to correct misspelled words. We kept words that appeared more than 10 times in our vocabulary. The training hyperparameters are selected based on the results of the DEV set. The dimension of attribute vectors is set to 64. The dimensions of word embeddings and hidden vectors are set to 512 in the sequence decoder. Moreover, we stack two layers of recurrent neural networks with LSTM units to generate reviews. All the parameters are randomly initialized by sampling from a uniform distribution [\u22120.08, 0.08].\n\nThe batch size, smoothing constant and base learning rate of RMSProp are set to 50, 0.95 and 0.002, respectively. After 10 epochs, the learning rate is decreased by a factor of 0.97 at the end of every epoch as suggested in Karpathy et al. (2016). The dropout rate is set to 0.2 for regularization. We also clamp gradient values into the range [\u22125, 5] to avoid the exploding gradient problem (Pascanu et al., 2013).  Table 1: Evaluation results on the TEST set of Amazon data. * : significantly better than the second best score (p < 0.05).\n\nwe use the greedy search algorithm to generate reviews.\n\n\nEvaluation Results\n\nThe BLEU (Papineni et al., 2002) score is used for automatic evaluation, which has been shown to correlate well with human judgment on many generation tasks. The BLEU score measures the precision of n-gram matching by comparing the generated results with references, and penalizes length using a brevity penalty term. We compute BLEU-1 (unigram) and BLEU-4 (up to 4 grams) in experiments.\n\n\nComparison with Baseline Methods\n\nWe describe the comparison methods as follows:\n\nRand. The predicted results are randomly sampled from all the reviews in the TRAIN set. This baseline method suggests the expected lower bound for this task.\n\nMELM. Maximum Entropy Language Model uses n-gram (up to trigram) features, and the feature template attribute&n-gram (up to bigram). The feature hashing technique is employed to reduce memory usage in each feature group. Noise contrastive estimation (Gutmann and Hyvrinen, 2010) is used to accelerate the training by dropping the normalization term, with 20 contrastive samples in training.\n\nNN-pr. This Nearest Neighbor based method retrieves the reviews that have the same product ID and rating as the input attributes in the TRAIN set. Then we randomly choose a review from them, and use it as the prediction.\n\nNN-ur. The same method as NN-pr but uses both user ID and rating to retrieve candidate reviews.\n\nAtt2Seq. Our attribute-to-sequence method described in Section 3. Notice that the attention model is not used.\n\n\nMethod\n\nMELM Att2Seq Att2Seq+A Accuracy (%) 59.00 88.67 93.33 * Table 2: We manually annotate some polarity labels (positive or negative) for generated reviews and compute accuracy by comparing them with the input ratings. * : significantly better than the second best accuracy (p < 0.05).\n\nAtt2Seq+A. Our method with an attention mechanism.\n\nAs shown in Table 1, we compute BLEU scores for these methods. The results of random guess indicate that this task is non-trivial to obtain reasonable performance. MELM performs worse than nearest neighbor search due to the sparsity of lexicalized features, while our model employs distributed representations to avoid using sparse indicator features. Then, we evaluate the NN methods that use different attributes to retrieve reviews, which is a strong baseline for the generation task. The results show that our method outperforms the baseline methods. Moreover, the improvements of the attention mechanism are significant with p < 0.05 according to the bootstrap resampling test (Koehn, 2004). We further show some examples to analyze the attention model in Section 4.4.\n\n\nPolarity of Generated Reviews\n\nIn order to evaluate whether the polarities of generated reviews correspond to their input ratings, we randomly sample some generated reviews and manually annotate their polarity labels. Specifically, we regard the rating 1-2 as negative and 4-5 as positive, and then evaluate performance by computing their classification accuracy. We randomly sample 150 negative examples and 150 positive examples for each method. Next, we ask two graduate students to classify the generated reviews to positive, negative, and indeterminable/neutral. About 93% of examples are annotated with the same labels by two annotators. Table 2 shows our method significantly outperforms others (p < 0.05). For Att2Seq+A, some generated reviews are classified to indeterminable/neutral because they contain mixed opinions towards different aspects of books.\n\n\nAblation Experiments\n\nIn order to evaluate the contributions of model components in our method, we compare to the variants of our model. These models are described  as follows: AvgEnc. This model uses the average of attribute vectors as the encoding vector, rather than multilayer perceptrons.\n\nNoStack. The method only uses one-layer recurrent neural networks for the sequence decoder.\n\nw/o user/product/rating. This variant does not use the corresponding attribute as input. These results indicate the importance of different information for our model.\n\nAs shown in Table 3, we compute BLEU-4 and BLEU-1 scores for our full model and the different variants on the DEV set. The ablation model AvgEnc performs worse than Att2Seq+A. This indicates that multilayer perceptrons can better handle interactions between attributes, outperforming simple averaging of input vectors. Next, we compare to the model without stacking multiple layers of recurrent neural networks as described in Section 3.2. The results demonstrate that deep architectures can improve generation performance. For the next group of variants, we find that removing user, product and rating information harms performance, which indicates that all three attributes contribute to generating relevant reviews.\n\n\nThe Attention Mechanism\n\nAs described in Section 3.3, the attention mechanism learns soft alignment scores between generated words and input attributes. These scores are used to obtain encoder-side context vectors that can better utilize attribute information to predict the next word. Figure 4 shows three generated examples with different input ratings. The attention scores are represented by gray scales and are column-wisely normalized as described in Equation (7). Firstly, we explain the attention scores over rating information. The input rating of the first example is 1. We find that the phrases \"n't expecting much\", \"n't like\" and \"a little too much\" have larger attention scores on the rating attribute. This demon-  Figure 4: Examples of attention scores (Equation (7)) over three attributes. Darker color indicates higher attention score.\n\nstrates rating information has more effect on generating these sentiment words. Next, we increase the rating score to 3 in the second example. The generated review expresses a mixed opinion for different aspects of the book. As indicated by the attention scores, we know that the sentiment words \"loved\", \"little slow\", and \"not like\" attend more to rating information. The last example is a positive review with a rating of 5. The attention scores demonstrate the phrases \"loved\", \"ca n't wait\", and \"hope * writes another book\" are used to express polarity. Similarly, the attention scores over user and product information indicate how the generated words are aligned with these two input attributes. For instance, the word \"characters\" has higher attention scores over the product attribute in the first and second example. This indicates that users tend to comment about the characters in this book's reviews.\n\n\nGenerated Examples\n\nAs shown in Table 4, we sample products and users to generate some examples with different ratings. The special unknown token is removed from the vocabulary of the decoder in the generation process. We keep two attributes fixed and change the other one in every group to show the effects of input.\n\nIn the first group, we change the rating from 1 to 5 and keep the others unchanged. The results show that the polarity of generated reviews changes with the rating. For instance, the words \"nice\" and \"liked\" are used for the rating of 3, while the words \"very good\" and \"enjoyed\" are employed for the rating of 5. Moreover, both ex-U P R Generated Review A V 1 i'm sorry to say this was a very boring book. i didn't finish it. i'm not a new fan of the series, but this was a disappointment.\n\nA V 3 this was a nice story. i liked the characters and the story line. i'm not sure i'd read another by this author.\n\nA V 5 this was a very good book. i enjoyed the characters and the story line. i'm looking forward to reading more in this series. B W 5 i couldn't put it down. it was a great love story. i can't wait to read the next one.\n\nC W 5 enjoyable story that keeps you turning the pages. the characters are well developed and the plot is excellent. i would recommend this book to anyone who enjoys a good love story.\n\nD W 5 i loved this book. i could not put it down. i loved this story and the characters. i will be reading the next book.\n\nE X 1 i read this book because i was looking for something to read. this book was just too much like the others. i thought the author was going to be a good writer, but i was disappointed.\n\nE Y 1 i was disappointed. i read the first chapter and then i was bored. i read the whole thing, but i just couldn't get into it.\n\nE Z 1 this book was just too much. i read the whole thing, but i didn't like the way the author ended it. i was hoping for a different ending. For instance, in the first group, we use different ratings ranging from 1 (the lowest score) to 5 (the highest score) with the same user and product to generate reviews. The users and products are anonymized by A-E and V-Z.\n\namples describe \"characters\" and \"story line\", and are written in the similar styles. This indicates that user and product information determines the content and style of generated reviews, while rating affects the choice of sentiment words. In the next group, we use different user IDs as input attributes. This book is one of the Fatal Series written by Marie Force, which tells a romantic love story. The first and third examples mention \"next one/book\", and both the first two reviews contain the phrase \"love story\". This demonstrates the generated reviews agree with the input product information. In the third group, the attributes, except product ID, are kept unchanged. The examples show our model generates varied reviews for different products.\n\n\nConclusion\n\nIn this paper, we proposed a novel product review generation task, in which generated reviews are conditioned on input attributes. For this task, we formulated a neural network based attribute-tosequence model that uses multilayer perceptrons to encode input attributes and employs recurrent neural networks to generate reviews. Moreover, we introduced an attention mechanism to better utilize input attribute information. Additionally, we built a dataset of Amazon product reviews to conduct evaluations. The proposed model consistently outperforms the nearest neighbor search and maximum entropy language model baselines. Besides, the attention mechanism significantly improves the vanilla attribute-to-sequence model. This work suggests several interesting directions for future research. We could use more finegrained attributes as the input of our model. For example, the generated reviews could be conditioned on device specification, brand, user's gender, product description, or ratings of a product's various aspects. Moreover, we could leverage review texts without attributes to improve the sequence decoder.\n\nFigure 2 :\n2Attribute-to-sequence model without attention mechanism.\n\n\nThe number of epochs is determined by early stopping on the DEV set. At test time,Method \n\nBLEU-4 (%) BLEU-1 (%) \nRand \n0.86 \n20.36 \nMELM \n1.28 \n21.59 \nNN-pr \n1.53 \n22.44 \nNN-ur \n3.61 \n26.37 \nAtt2Seq \n4.51 \n30.24 \nAtt2Seq+A 5.03  *  \n30.48  *  \n\n\n\nTable 3 :\n3Model ablation results on the DEV set.\n\nTable 4 :\n4U: User. P: Product. R: Rating. This table shows some generated examples of the Att2Seq+A model. In every group, two attributes are kept unchanged, while the other attribute has different values.\nAcknowledgmentsThe support of the European Research Council under award number 681760 \"Translating Multiple Modalities into Text\" is gratefully acknowledged.\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, International Conference on Learning Representations. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2015. Neural machine translation by jointly learning to align and translate. In International Con- ference on Learning Representations.\n\nNatural Language Processing with Python. Steven Bird, Ewan Klein, Edward Loper, O'Reilly MediaSteven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python. O'Reilly Media.\n\nLong-term recurrent convolutional networks for visual recognition and description. J Donahue, L A Hendricks, S Guadarrama, M Rohrbach, S Venugopalan, T Darrell, K Saenko, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). J. Donahue, L. A. Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, T. Darrell, and K. Saenko. 2015. Long-term recurrent convolu- tional networks for visual recognition and descrip- tion. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2625-2634.\n\nLanguage to logical form with neural attention. Li Dong, Mirella Lapata, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyLong Papers1Association for Computational LinguisticsLi Dong and Mirella Lapata. 2016. Language to logi- cal form with neural attention. In Proceedings of the 54th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 33-43, Berlin, Germany. Association for Computa- tional Linguistics.\n\nAdaptive multi-compositionality for recursive neural models with applications to sentiment analysis. Li Dong, Furu Wei, Ming Zhou, Ke Xu, Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI'14. the Twenty-Eighth AAAI Conference on Artificial Intelligence, AAAI'14AAAI PressLi Dong, Furu Wei, Ming Zhou, and Ke Xu. 2014. Adaptive multi-compositionality for recursive neu- ral models with applications to sentiment analysis. In Proceedings of the Twenty-Eighth AAAI Con- ference on Artificial Intelligence, AAAI'14, pages 1537-1543. AAAI Press.\n\nLearning to generate chairs with convolutional neural networks. A Dosovitskiy, J T Springenberg, T Brox, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). A. Dosovitskiy, J. T. Springenberg, and T. Brox. 2015. Learning to generate chairs with convolutional neu- ral networks. In 2015 IEEE Conference on Com- puter Vision and Pattern Recognition (CVPR), pages 1538-1546.\n\nNoisecontrastive estimation: A new estimation principle for unnormalized statistical models. M Gutmann, A Hyvrinen, Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS). Y.W. Teh and M. Titteringtonthe 13th International Conference on Artificial Intelligence and Statistics (AISTATS)9Proceedings TrackM. Gutmann and A. Hyvrinen. 2010. Noise- contrastive estimation: A new estimation principle for unnormalized statistical models. In Y.W. Teh and M. Titterington, editors, Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS), volume 9 of JMLR WCP, pages 297-304. Journal of Machine Learning Re- search -Proceedings Track.\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural Computation. 98Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural Computation, 9(8):1735-1780.\n\nRecurrent continuous translation models. Nal Kalchbrenner, Phil Blunsom, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingSeattle, Washington, USAAssociation for Computational LinguisticsNal Kalchbrenner and Phil Blunsom. 2013. Recurrent continuous translation models. In Proceedings of the 2013 Conference on Empirical Methods in Natu- ral Language Processing, pages 1700-1709, Seattle, Washington, USA. Association for Computational Linguistics.\n\nVisualizing and understanding recurrent networks. Andrej Karpathy, Justin Johnson, Fei-Fei Li, International Conference on Learning Representations. Andrej Karpathy, Justin Johnson, and Fei-Fei Li. 2016. Visualizing and understanding recurrent networks. In International Conference on Learning Represen- tations.\n\nConvolutional neural networks for sentence classification. Yoon Kim, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, QatarAssociation for Computational LinguisticsYoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746-1751, Doha, Qatar. Association for Computational Lin- guistics.\n\nStatistical significance tests for machine translation evaluation. Philipp Koehn, Proceedings of EMNLP 2004. Dekang Lin and Dekai WuEMNLP 2004Barcelona, SpainAssociation for Computational LinguisticsPhilipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 388-395, Barcelona, Spain. Association for Computational Linguistics.\n\nConceptto-text generation via discriminative reranking. Ioannis Konstas, Mirella Lapata, Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics. the 50th Annual Meeting of the Association for Computational LinguisticsJeju Island, KoreaAssociation for Computational Linguistics1Ioannis Konstas and Mirella Lapata. 2012. Concept- to-text generation via discriminative reranking. In Proceedings of the 50th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 369-378, Jeju Island, Korea. Association for Computational Linguistics.\n\nA global model for concept-to-text generation. Ioannis Konstas, Mirella Lapata, Journal of Artificial Intelligence Research. 481Ioannis Konstas and Mirella Lapata. 2013. A global model for concept-to-text generation. Journal of Ar- tificial Intelligence Research, 48(1):305-346.\n\nCapturing meaning in product reviews with character-level generative text models. Zachary C Lipton, Sharad Vikram, Julian Mcauley, arXiv:1511.03683arXiv preprintZachary C. Lipton, Sharad Vikram, and Julian McAuley. 2015. Capturing meaning in product re- views with character-level generative text models. arXiv preprint arXiv:1511.03683.\n\nBing Liu, Sentiment Analysis: Mining Opinions, Sentiments, and Emotions. Cambridge University PressBing Liu. 2015. Sentiment Analysis: Mining Opinions, Sentiments, and Emotions. Cambridge University Press.\n\nEffective approaches to attentionbased neural machine translation. Minh-Thang Luong, Hieu Pham, Christopher D Manning, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsMinh-Thang Luong, Hieu Pham, and Christopher D. Manning. 2015. Effective approaches to attention- based neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Nat- ural Language Processing, pages 1412-1421, Lis- bon, Portugal. Association for Computational Lin- guistics.\n\nSynthetic text generation for sentiment analysis. Umar Maqsud, Proceedings of the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis. the 6th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media AnalysisLisboa, PortugalAssociation for Computational LinguisticsUmar Maqsud. 2015. Synthetic text generation for sentiment analysis. In Proceedings of the 6th Work- shop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 156- 161, Lisboa, Portugal. Association for Computa- tional Linguistics.\n\nInferring networks of substitutable and complementary products. Julian Mcauley, Rahul Pandey, Jure Leskovec, Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '15. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '15New York, NY, USAACMJulian McAuley, Rahul Pandey, and Jure Leskovec. 2015. Inferring networks of substitutable and com- plementary products. In Proceedings of the 21th ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining, KDD '15, pages 785-794, New York, NY, USA. ACM.\n\nWhat to talk about and how? selective generation using lstms with coarse-to-fine alignment. Hongyuan Mei, Mohit Bansal, Matthew R Walter, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSan Diego, CaliforniaAssociation for Computational LinguisticsHongyuan Mei, Mohit Bansal, and Matthew R. Walter. 2016. What to talk about and how? selective gener- ation using lstms with coarse-to-fine alignment. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 720-730, San Diego, California. Association for Computational Linguistics.\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of 40th Annual Meeting of the Association for Computational Linguistics. 40th Annual Meeting of the Association for Computational LinguisticsPhiladelphia, Pennsylvania, USAAssociation for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the Association for Com- putational Linguistics, pages 311-318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.\n\nRetrieval of relevant opinion sentences for new products. Hyun Duk Dae Hoon Park, Chengxiang Kim, Lifan Zhai, Guo, Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '15. the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '15New York, NY, USAACMDae Hoon Park, Hyun Duk Kim, ChengXiang Zhai, and Lifan Guo. 2015. Retrieval of relevant opinion sentences for new products. In Proceedings of the 38th International ACM SIGIR Conference on Re- search and Development in Information Retrieval, SIGIR '15, pages 393-402, New York, NY, USA. ACM.\n\nOn the difficulty of training recurrent neural networks. Razvan Pascanu, Tomas Mikolov, Yoshua Bengio, Proceedings of The 30th International Conference on Machine Learning. The 30th International Conference on Machine LearningRazvan Pascanu, Tomas Mikolov, and Yoshua Ben- gio. 2013. On the difficulty of training recurrent neural networks. In Proceedings of The 30th In- ternational Conference on Machine Learning, pages 1310-1318.\n\nParsing natural scenes and natural language with recursive neural networks. Richard Socher, Cliff Chiung, -Yu Lin, Andrew Ng, Chris Manning, Proceedings of the 28th International Conference on Machine Learning (ICML-11), ICML '11. Lise Getoor and Tobias Schefferthe 28th International Conference on Machine Learning (ICML-11), ICML '11New York, NY, USAACMRichard Socher, Cliff Chiung-Yu Lin, Andrew Ng, and Chris Manning. 2011. Parsing natural scenes and natural language with recursive neural networks. In Lise Getoor and Tobias Scheffer, editors, Proceed- ings of the 28th International Conference on Ma- chine Learning (ICML-11), ICML '11, pages 129- 136, New York, NY, USA. ACM.\n\nSequence to sequence learning with neural networks. Ilya Sutskever, Oriol Vinyals, Quoc V Le, Advances in Neural Information Processing Systems. Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. WeinbergerCurran Associates, Inc27Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural net- works. In Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Ad- vances in Neural Information Processing Systems 27, pages 3104-3112. Curran Associates, Inc.\n\nLecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude. T Tieleman, G Hinton, Technical reportT. Tieleman and G. Hinton. 2012. Lecture 6.5- RmsProp: Divide the gradient by a running average of its recent magnitude. Technical report.\n\nSequence to sequence -video to text. Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond Mooney, Trevor Darrell, Kate Saenko, The IEEE International Conference on Computer Vision (ICCV). Subhashini Venugopalan, Marcus Rohrbach, Jeffrey Donahue, Raymond Mooney, Trevor Darrell, and Kate Saenko. 2015. Sequence to sequence -video to text. In The IEEE International Conference on Computer Vision (ICCV), pages 4534-4542.\n\nShow and tell: A neural image caption generator. O Vinyals, A Toshev, S Bengio, D Erhan, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. 2015a. Show and tell: A neural image caption generator. In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3156-3164.\n\nGrammar as a foreign language. Oriol Vinyals, \u0141ukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, Geoffrey Hinton, Advances in Neural Information Processing Systems. C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. GarnettCurran Associates, Inc28Oriol Vinyals, \u0141ukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. 2015b. Gram- mar as a foreign language. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28, pages 2773-2781. Curran Associates, Inc.\n\nShow, attend and tell: Neural image caption generation with visual attention. Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, Yoshua Bengio, Proceedings of the 32nd International Conference on Machine Learning (ICML-15). David Blei and Francis Bachthe 32nd International Conference on Machine Learning (ICML-15)Workshop and Conference ProceedingsKelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural image caption generation with visual atten- tion. In David Blei and Francis Bach, editors, Pro- ceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 2048-2057. JMLR Workshop and Conference Proceedings.\n\nAttribute2image: Conditional image generation from visual attributes. Xinchen Yan, Jimei Yang, Kihyuk Sohn, Honglak Lee, European Conference on Computer Vision. Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee. 2016. Attribute2image: Conditional image generation from visual attributes. In European Con- ference on Computer Vision, pages 776-791.\n\nRecurrent neural network regularization. Wojciech Zaremba, Ilya Sutskever, Oriol Vinyals, International Conference on Learning Representations. Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. 2015. Recurrent neural network regularization. In International Conference on Learning Representa- tions.\n", "annotations": {"author": "[{\"end\":243,\"start\":169},{\"end\":324,\"start\":244},{\"end\":400,\"start\":325},{\"end\":465,\"start\":401},{\"end\":565,\"start\":466},{\"end\":595,\"start\":566}]", "publisher": "[{\"end\":95,\"start\":54},{\"end\":795,\"start\":754}]", "author_last_name": "[{\"end\":176,\"start\":172},{\"end\":257,\"start\":252},{\"end\":333,\"start\":330},{\"end\":415,\"start\":409},{\"end\":475,\"start\":471},{\"end\":571,\"start\":569}]", "author_first_name": "[{\"end\":171,\"start\":169},{\"end\":251,\"start\":244},{\"end\":329,\"start\":325},{\"end\":408,\"start\":401},{\"end\":470,\"start\":466},{\"end\":568,\"start\":566}]", "author_affiliation": "[{\"end\":242,\"start\":195},{\"end\":290,\"start\":259},{\"end\":323,\"start\":292},{\"end\":366,\"start\":335},{\"end\":399,\"start\":368},{\"end\":464,\"start\":417},{\"end\":531,\"start\":500},{\"end\":564,\"start\":533}]", "title": "[{\"end\":53,\"start\":1},{\"end\":648,\"start\":596}]", "venue": "[{\"end\":695,\"start\":650}]", "abstract": "[{\"end\":1875,\"start\":818}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2845,\"start\":2834},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6415,\"start\":6404},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6692,\"start\":6671},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6710,\"start\":6692},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6720,\"start\":6710},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6742,\"start\":6722},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7119,\"start\":7096},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7135,\"start\":7119},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7197,\"start\":7184},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7410,\"start\":7392},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7640,\"start\":7614},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7665,\"start\":7640},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7867,\"start\":7850},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8922,\"start\":8890},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8945,\"start\":8922},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8988,\"start\":8965},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9034,\"start\":9011},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9165,\"start\":9142},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9551,\"start\":9528},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9570,\"start\":9551},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9586,\"start\":9570},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9793,\"start\":9768},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9946,\"start\":9929},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13527,\"start\":13493},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14166,\"start\":14145},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":15409,\"start\":15386},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15431,\"start\":15409},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15450,\"start\":15431},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":16956,\"start\":16935},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":17009,\"start\":16982},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18992,\"start\":18974},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19832,\"start\":19810},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20000,\"start\":19978},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20238,\"start\":20215},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21116,\"start\":21088},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22700,\"start\":22687}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":30807,\"start\":30738},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":31056,\"start\":30808},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":31107,\"start\":31057},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":31315,\"start\":31108}]", "paragraph": "[{\"end\":2351,\"start\":1891},{\"end\":2440,\"start\":2373},{\"end\":3840,\"start\":2460},{\"end\":4657,\"start\":3842},{\"end\":5831,\"start\":4659},{\"end\":5879,\"start\":5833},{\"end\":6022,\"start\":5881},{\"end\":6147,\"start\":6024},{\"end\":6294,\"start\":6149},{\"end\":8340,\"start\":6311},{\"end\":10187,\"start\":8342},{\"end\":10865,\"start\":10210},{\"end\":11946,\"start\":10905},{\"end\":12119,\"start\":11948},{\"end\":12409,\"start\":12141},{\"end\":12771,\"start\":12439},{\"end\":13116,\"start\":12820},{\"end\":13833,\"start\":13137},{\"end\":14205,\"start\":13865},{\"end\":14442,\"start\":14336},{\"end\":14873,\"start\":14444},{\"end\":14961,\"start\":14918},{\"end\":15648,\"start\":14985},{\"end\":15896,\"start\":15693},{\"end\":16044,\"start\":15929},{\"end\":16125,\"start\":16083},{\"end\":16207,\"start\":16127},{\"end\":16524,\"start\":16244},{\"end\":16687,\"start\":16543},{\"end\":17063,\"start\":16721},{\"end\":17319,\"start\":17077},{\"end\":17731,\"start\":17345},{\"end\":17965,\"start\":17747},{\"end\":18948,\"start\":17989},{\"end\":19584,\"start\":18961},{\"end\":20126,\"start\":19586},{\"end\":20183,\"start\":20128},{\"end\":20594,\"start\":20206},{\"end\":20677,\"start\":20631},{\"end\":20836,\"start\":20679},{\"end\":21228,\"start\":20838},{\"end\":21450,\"start\":21230},{\"end\":21547,\"start\":21452},{\"end\":21659,\"start\":21549},{\"end\":21951,\"start\":21670},{\"end\":22003,\"start\":21953},{\"end\":22778,\"start\":22005},{\"end\":23645,\"start\":22812},{\"end\":23941,\"start\":23670},{\"end\":24034,\"start\":23943},{\"end\":24202,\"start\":24036},{\"end\":24922,\"start\":24204},{\"end\":25778,\"start\":24950},{\"end\":26694,\"start\":25780},{\"end\":27014,\"start\":26717},{\"end\":27506,\"start\":27016},{\"end\":27625,\"start\":27508},{\"end\":27848,\"start\":27627},{\"end\":28034,\"start\":27850},{\"end\":28157,\"start\":28036},{\"end\":28347,\"start\":28159},{\"end\":28478,\"start\":28349},{\"end\":28846,\"start\":28480},{\"end\":29603,\"start\":28848},{\"end\":30737,\"start\":29618}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10904,\"start\":10866},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12438,\"start\":12410},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12819,\"start\":12772},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13864,\"start\":13834},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14335,\"start\":14206},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14917,\"start\":14874},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15692,\"start\":15649},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15928,\"start\":15897},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16082,\"start\":16045},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16720,\"start\":16688},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17344,\"start\":17320}]", "table_ref": "[{\"end\":20010,\"start\":20003},{\"end\":21733,\"start\":21726},{\"end\":22024,\"start\":22017},{\"end\":23432,\"start\":23425},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24223,\"start\":24216},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26736,\"start\":26729}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1889,\"start\":1877},{\"end\":2371,\"start\":2354},{\"end\":2458,\"start\":2443},{\"attributes\":{\"n\":\"2\"},\"end\":6309,\"start\":6297},{\"attributes\":{\"n\":\"3\"},\"end\":10208,\"start\":10190},{\"attributes\":{\"n\":\"3.1\"},\"end\":12139,\"start\":12122},{\"attributes\":{\"n\":\"3.2\"},\"end\":13135,\"start\":13119},{\"attributes\":{\"n\":\"3.3\"},\"end\":14983,\"start\":14964},{\"end\":16242,\"start\":16210},{\"attributes\":{\"n\":\"3.4\"},\"end\":16541,\"start\":16527},{\"attributes\":{\"n\":\"3.5\"},\"end\":17075,\"start\":17066},{\"attributes\":{\"n\":\"4\"},\"end\":17745,\"start\":17734},{\"attributes\":{\"n\":\"4.1\"},\"end\":17987,\"start\":17968},{\"attributes\":{\"n\":\"4.2\"},\"end\":18959,\"start\":18951},{\"attributes\":{\"n\":\"4.3\"},\"end\":20204,\"start\":20186},{\"attributes\":{\"n\":\"4.3.1\"},\"end\":20629,\"start\":20597},{\"end\":21668,\"start\":21662},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":22810,\"start\":22781},{\"attributes\":{\"n\":\"4.3.3\"},\"end\":23668,\"start\":23648},{\"attributes\":{\"n\":\"4.4\"},\"end\":24948,\"start\":24925},{\"attributes\":{\"n\":\"4.5\"},\"end\":26715,\"start\":26697},{\"attributes\":{\"n\":\"5\"},\"end\":29616,\"start\":29606},{\"end\":30749,\"start\":30739},{\"end\":31067,\"start\":31058},{\"end\":31118,\"start\":31109}]", "table": "[{\"end\":31056,\"start\":30892}]", "figure_caption": "[{\"end\":30807,\"start\":30751},{\"end\":30892,\"start\":30810},{\"end\":31107,\"start\":31069},{\"end\":31315,\"start\":31120}]", "figure_ref": "[{\"end\":3074,\"start\":3066},{\"end\":4757,\"start\":4749},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12259,\"start\":12251},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13157,\"start\":13149},{\"end\":15460,\"start\":15452},{\"end\":16289,\"start\":16281},{\"end\":25219,\"start\":25211},{\"end\":25663,\"start\":25655}]", "bib_author_first_name": "[{\"end\":31552,\"start\":31545},{\"end\":31572,\"start\":31563},{\"end\":31584,\"start\":31578},{\"end\":31885,\"start\":31879},{\"end\":31896,\"start\":31892},{\"end\":31910,\"start\":31904},{\"end\":32123,\"start\":32122},{\"end\":32134,\"start\":32133},{\"end\":32136,\"start\":32135},{\"end\":32149,\"start\":32148},{\"end\":32163,\"start\":32162},{\"end\":32175,\"start\":32174},{\"end\":32190,\"start\":32189},{\"end\":32201,\"start\":32200},{\"end\":32618,\"start\":32616},{\"end\":32632,\"start\":32625},{\"end\":33251,\"start\":33249},{\"end\":33262,\"start\":33258},{\"end\":33272,\"start\":33268},{\"end\":33281,\"start\":33279},{\"end\":33787,\"start\":33786},{\"end\":33802,\"start\":33801},{\"end\":33804,\"start\":33803},{\"end\":33820,\"start\":33819},{\"end\":34209,\"start\":34208},{\"end\":34220,\"start\":34219},{\"end\":34862,\"start\":34858},{\"end\":34881,\"start\":34875},{\"end\":35068,\"start\":35065},{\"end\":35087,\"start\":35083},{\"end\":35639,\"start\":35633},{\"end\":35656,\"start\":35650},{\"end\":35673,\"start\":35666},{\"end\":35960,\"start\":35956},{\"end\":36517,\"start\":36510},{\"end\":36934,\"start\":36927},{\"end\":36951,\"start\":36944},{\"end\":37532,\"start\":37525},{\"end\":37549,\"start\":37542},{\"end\":37847,\"start\":37840},{\"end\":37849,\"start\":37848},{\"end\":37864,\"start\":37858},{\"end\":37879,\"start\":37873},{\"end\":38101,\"start\":38097},{\"end\":38381,\"start\":38371},{\"end\":38393,\"start\":38389},{\"end\":38411,\"start\":38400},{\"end\":38413,\"start\":38412},{\"end\":39001,\"start\":38997},{\"end\":39616,\"start\":39610},{\"end\":39631,\"start\":39626},{\"end\":39644,\"start\":39640},{\"end\":40251,\"start\":40243},{\"end\":40262,\"start\":40257},{\"end\":40278,\"start\":40271},{\"end\":40280,\"start\":40279},{\"end\":41075,\"start\":41068},{\"end\":41091,\"start\":41086},{\"end\":41104,\"start\":41100},{\"end\":41119,\"start\":41111},{\"end\":41726,\"start\":41722},{\"end\":41730,\"start\":41727},{\"end\":41756,\"start\":41746},{\"end\":41767,\"start\":41762},{\"end\":42387,\"start\":42381},{\"end\":42402,\"start\":42397},{\"end\":42418,\"start\":42412},{\"end\":42841,\"start\":42834},{\"end\":42855,\"start\":42850},{\"end\":42867,\"start\":42864},{\"end\":42879,\"start\":42873},{\"end\":42889,\"start\":42884},{\"end\":43498,\"start\":43494},{\"end\":43515,\"start\":43510},{\"end\":43531,\"start\":43525},{\"end\":44065,\"start\":44064},{\"end\":44077,\"start\":44076},{\"end\":44289,\"start\":44279},{\"end\":44309,\"start\":44303},{\"end\":44327,\"start\":44320},{\"end\":44344,\"start\":44337},{\"end\":44359,\"start\":44353},{\"end\":44373,\"start\":44369},{\"end\":44725,\"start\":44724},{\"end\":44736,\"start\":44735},{\"end\":44746,\"start\":44745},{\"end\":44756,\"start\":44755},{\"end\":45069,\"start\":45064},{\"end\":45085,\"start\":45079},{\"end\":45099,\"start\":45094},{\"end\":45109,\"start\":45105},{\"end\":45122,\"start\":45118},{\"end\":45142,\"start\":45134},{\"end\":45681,\"start\":45675},{\"end\":45691,\"start\":45686},{\"end\":45700,\"start\":45696},{\"end\":45717,\"start\":45708},{\"end\":45728,\"start\":45723},{\"end\":45746,\"start\":45740},{\"end\":45765,\"start\":45761},{\"end\":45779,\"start\":45773},{\"end\":46456,\"start\":46449},{\"end\":46467,\"start\":46462},{\"end\":46480,\"start\":46474},{\"end\":46494,\"start\":46487},{\"end\":46781,\"start\":46773},{\"end\":46795,\"start\":46791},{\"end\":46812,\"start\":46807}]", "bib_author_last_name": "[{\"end\":31561,\"start\":31553},{\"end\":31576,\"start\":31573},{\"end\":31591,\"start\":31585},{\"end\":31890,\"start\":31886},{\"end\":31902,\"start\":31897},{\"end\":31916,\"start\":31911},{\"end\":32131,\"start\":32124},{\"end\":32146,\"start\":32137},{\"end\":32160,\"start\":32150},{\"end\":32172,\"start\":32164},{\"end\":32187,\"start\":32176},{\"end\":32198,\"start\":32191},{\"end\":32208,\"start\":32202},{\"end\":32623,\"start\":32619},{\"end\":32639,\"start\":32633},{\"end\":33256,\"start\":33252},{\"end\":33266,\"start\":33263},{\"end\":33277,\"start\":33273},{\"end\":33284,\"start\":33282},{\"end\":33799,\"start\":33788},{\"end\":33817,\"start\":33805},{\"end\":33825,\"start\":33821},{\"end\":34217,\"start\":34210},{\"end\":34229,\"start\":34221},{\"end\":34873,\"start\":34863},{\"end\":34893,\"start\":34882},{\"end\":35081,\"start\":35069},{\"end\":35095,\"start\":35088},{\"end\":35648,\"start\":35640},{\"end\":35664,\"start\":35657},{\"end\":35676,\"start\":35674},{\"end\":35964,\"start\":35961},{\"end\":36523,\"start\":36518},{\"end\":36942,\"start\":36935},{\"end\":36958,\"start\":36952},{\"end\":37540,\"start\":37533},{\"end\":37556,\"start\":37550},{\"end\":37856,\"start\":37850},{\"end\":37871,\"start\":37865},{\"end\":37887,\"start\":37880},{\"end\":38105,\"start\":38102},{\"end\":38387,\"start\":38382},{\"end\":38398,\"start\":38394},{\"end\":38421,\"start\":38414},{\"end\":39008,\"start\":39002},{\"end\":39624,\"start\":39617},{\"end\":39638,\"start\":39632},{\"end\":39653,\"start\":39645},{\"end\":40255,\"start\":40252},{\"end\":40269,\"start\":40263},{\"end\":40287,\"start\":40281},{\"end\":41084,\"start\":41076},{\"end\":41098,\"start\":41092},{\"end\":41109,\"start\":41105},{\"end\":41123,\"start\":41120},{\"end\":41744,\"start\":41731},{\"end\":41760,\"start\":41757},{\"end\":41772,\"start\":41768},{\"end\":41777,\"start\":41774},{\"end\":42395,\"start\":42388},{\"end\":42410,\"start\":42403},{\"end\":42425,\"start\":42419},{\"end\":42848,\"start\":42842},{\"end\":42862,\"start\":42856},{\"end\":42871,\"start\":42868},{\"end\":42882,\"start\":42880},{\"end\":42897,\"start\":42890},{\"end\":43508,\"start\":43499},{\"end\":43523,\"start\":43516},{\"end\":43534,\"start\":43532},{\"end\":44074,\"start\":44066},{\"end\":44084,\"start\":44078},{\"end\":44301,\"start\":44290},{\"end\":44318,\"start\":44310},{\"end\":44335,\"start\":44328},{\"end\":44351,\"start\":44345},{\"end\":44367,\"start\":44360},{\"end\":44380,\"start\":44374},{\"end\":44733,\"start\":44726},{\"end\":44743,\"start\":44737},{\"end\":44753,\"start\":44747},{\"end\":44762,\"start\":44757},{\"end\":45077,\"start\":45070},{\"end\":45092,\"start\":45086},{\"end\":45103,\"start\":45100},{\"end\":45116,\"start\":45110},{\"end\":45132,\"start\":45123},{\"end\":45149,\"start\":45143},{\"end\":45684,\"start\":45682},{\"end\":45694,\"start\":45692},{\"end\":45706,\"start\":45701},{\"end\":45721,\"start\":45718},{\"end\":45738,\"start\":45729},{\"end\":45759,\"start\":45747},{\"end\":45771,\"start\":45766},{\"end\":45786,\"start\":45780},{\"end\":46460,\"start\":46457},{\"end\":46472,\"start\":46468},{\"end\":46485,\"start\":46481},{\"end\":46498,\"start\":46495},{\"end\":46789,\"start\":46782},{\"end\":46805,\"start\":46796},{\"end\":46820,\"start\":46813}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":11212020},\"end\":31836,\"start\":31474},{\"attributes\":{\"id\":\"b1\"},\"end\":32037,\"start\":31838},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":5736847},\"end\":32566,\"start\":32039},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":15412473},\"end\":33146,\"start\":32568},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":11403097},\"end\":33720,\"start\":33148},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15960930},\"end\":34113,\"start\":33722},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":15816723},\"end\":34832,\"start\":34115},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":1915014},\"end\":35022,\"start\":34834},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":12639289},\"end\":35581,\"start\":35024},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":988348},\"end\":35895,\"start\":35583},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":9672033},\"end\":36441,\"start\":35897},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":15119437},\"end\":36869,\"start\":36443},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2658285},\"end\":37476,\"start\":36871},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":10577922},\"end\":37756,\"start\":37478},{\"attributes\":{\"doi\":\"arXiv:1511.03683\",\"id\":\"b14\"},\"end\":38095,\"start\":37758},{\"attributes\":{\"id\":\"b15\"},\"end\":38302,\"start\":38097},{\"attributes\":{\"id\":\"b16\"},\"end\":38945,\"start\":38304},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":11815268},\"end\":39544,\"start\":38947},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":9396978},\"end\":40149,\"start\":39546},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1354459},\"end\":41002,\"start\":40151},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":11080756},\"end\":41662,\"start\":41004},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":18162341},\"end\":42322,\"start\":41664},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":14650762},\"end\":42756,\"start\":42324},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":18690358},\"end\":43440,\"start\":42758},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":7961699},\"end\":43975,\"start\":43442},{\"attributes\":{\"id\":\"b25\"},\"end\":44240,\"start\":43977},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":4228546},\"end\":44673,\"start\":44242},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":1169492},\"end\":45031,\"start\":44675},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":14223},\"end\":45595,\"start\":45033},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1055111},\"end\":46377,\"start\":45597},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":7577075},\"end\":46730,\"start\":46379},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":17719760},\"end\":47034,\"start\":46732}]", "bib_title": "[{\"end\":31543,\"start\":31474},{\"end\":32120,\"start\":32039},{\"end\":32614,\"start\":32568},{\"end\":33247,\"start\":33148},{\"end\":33784,\"start\":33722},{\"end\":34206,\"start\":34115},{\"end\":34856,\"start\":34834},{\"end\":35063,\"start\":35024},{\"end\":35631,\"start\":35583},{\"end\":35954,\"start\":35897},{\"end\":36508,\"start\":36443},{\"end\":36925,\"start\":36871},{\"end\":37523,\"start\":37478},{\"end\":38369,\"start\":38304},{\"end\":38995,\"start\":38947},{\"end\":39608,\"start\":39546},{\"end\":40241,\"start\":40151},{\"end\":41066,\"start\":41004},{\"end\":41720,\"start\":41664},{\"end\":42379,\"start\":42324},{\"end\":42832,\"start\":42758},{\"end\":43492,\"start\":43442},{\"end\":44277,\"start\":44242},{\"end\":44722,\"start\":44675},{\"end\":45062,\"start\":45033},{\"end\":45673,\"start\":45597},{\"end\":46447,\"start\":46379},{\"end\":46771,\"start\":46732}]", "bib_author": "[{\"end\":31563,\"start\":31545},{\"end\":31578,\"start\":31563},{\"end\":31593,\"start\":31578},{\"end\":31892,\"start\":31879},{\"end\":31904,\"start\":31892},{\"end\":31918,\"start\":31904},{\"end\":32133,\"start\":32122},{\"end\":32148,\"start\":32133},{\"end\":32162,\"start\":32148},{\"end\":32174,\"start\":32162},{\"end\":32189,\"start\":32174},{\"end\":32200,\"start\":32189},{\"end\":32210,\"start\":32200},{\"end\":32625,\"start\":32616},{\"end\":32641,\"start\":32625},{\"end\":33258,\"start\":33249},{\"end\":33268,\"start\":33258},{\"end\":33279,\"start\":33268},{\"end\":33286,\"start\":33279},{\"end\":33801,\"start\":33786},{\"end\":33819,\"start\":33801},{\"end\":33827,\"start\":33819},{\"end\":34219,\"start\":34208},{\"end\":34231,\"start\":34219},{\"end\":34875,\"start\":34858},{\"end\":34895,\"start\":34875},{\"end\":35083,\"start\":35065},{\"end\":35097,\"start\":35083},{\"end\":35650,\"start\":35633},{\"end\":35666,\"start\":35650},{\"end\":35678,\"start\":35666},{\"end\":35966,\"start\":35956},{\"end\":36525,\"start\":36510},{\"end\":36944,\"start\":36927},{\"end\":36960,\"start\":36944},{\"end\":37542,\"start\":37525},{\"end\":37558,\"start\":37542},{\"end\":37858,\"start\":37840},{\"end\":37873,\"start\":37858},{\"end\":37889,\"start\":37873},{\"end\":38107,\"start\":38097},{\"end\":38389,\"start\":38371},{\"end\":38400,\"start\":38389},{\"end\":38423,\"start\":38400},{\"end\":39010,\"start\":38997},{\"end\":39626,\"start\":39610},{\"end\":39640,\"start\":39626},{\"end\":39655,\"start\":39640},{\"end\":40257,\"start\":40243},{\"end\":40271,\"start\":40257},{\"end\":40289,\"start\":40271},{\"end\":41086,\"start\":41068},{\"end\":41100,\"start\":41086},{\"end\":41111,\"start\":41100},{\"end\":41125,\"start\":41111},{\"end\":41746,\"start\":41722},{\"end\":41762,\"start\":41746},{\"end\":41774,\"start\":41762},{\"end\":41779,\"start\":41774},{\"end\":42397,\"start\":42381},{\"end\":42412,\"start\":42397},{\"end\":42427,\"start\":42412},{\"end\":42850,\"start\":42834},{\"end\":42864,\"start\":42850},{\"end\":42873,\"start\":42864},{\"end\":42884,\"start\":42873},{\"end\":42899,\"start\":42884},{\"end\":43510,\"start\":43494},{\"end\":43525,\"start\":43510},{\"end\":43536,\"start\":43525},{\"end\":44076,\"start\":44064},{\"end\":44086,\"start\":44076},{\"end\":44303,\"start\":44279},{\"end\":44320,\"start\":44303},{\"end\":44337,\"start\":44320},{\"end\":44353,\"start\":44337},{\"end\":44369,\"start\":44353},{\"end\":44382,\"start\":44369},{\"end\":44735,\"start\":44724},{\"end\":44745,\"start\":44735},{\"end\":44755,\"start\":44745},{\"end\":44764,\"start\":44755},{\"end\":45079,\"start\":45064},{\"end\":45094,\"start\":45079},{\"end\":45105,\"start\":45094},{\"end\":45118,\"start\":45105},{\"end\":45134,\"start\":45118},{\"end\":45151,\"start\":45134},{\"end\":45686,\"start\":45675},{\"end\":45696,\"start\":45686},{\"end\":45708,\"start\":45696},{\"end\":45723,\"start\":45708},{\"end\":45740,\"start\":45723},{\"end\":45761,\"start\":45740},{\"end\":45773,\"start\":45761},{\"end\":45788,\"start\":45773},{\"end\":46462,\"start\":46449},{\"end\":46474,\"start\":46462},{\"end\":46487,\"start\":46474},{\"end\":46500,\"start\":46487},{\"end\":46791,\"start\":46773},{\"end\":46807,\"start\":46791},{\"end\":46822,\"start\":46807}]", "bib_venue": "[{\"end\":31645,\"start\":31593},{\"end\":31877,\"start\":31838},{\"end\":32280,\"start\":32210},{\"end\":32728,\"start\":32641},{\"end\":33370,\"start\":33286},{\"end\":33897,\"start\":33827},{\"end\":34331,\"start\":34231},{\"end\":34913,\"start\":34895},{\"end\":35183,\"start\":35097},{\"end\":35730,\"start\":35678},{\"end\":36060,\"start\":35966},{\"end\":36550,\"start\":36525},{\"end\":37047,\"start\":36960},{\"end\":37601,\"start\":37558},{\"end\":37838,\"start\":37758},{\"end\":38168,\"start\":38107},{\"end\":38509,\"start\":38423},{\"end\":39122,\"start\":39010},{\"end\":39762,\"start\":39655},{\"end\":40431,\"start\":40289},{\"end\":41208,\"start\":41125},{\"end\":41901,\"start\":41779},{\"end\":42495,\"start\":42427},{\"end\":42987,\"start\":42899},{\"end\":43585,\"start\":43536},{\"end\":44062,\"start\":43977},{\"end\":44441,\"start\":44382},{\"end\":44834,\"start\":44764},{\"end\":45200,\"start\":45151},{\"end\":45866,\"start\":45788},{\"end\":46538,\"start\":46500},{\"end\":46874,\"start\":46822},{\"end\":32817,\"start\":32730},{\"end\":33441,\"start\":33372},{\"end\":34446,\"start\":34361},{\"end\":35280,\"start\":35185},{\"end\":36152,\"start\":36062},{\"end\":36601,\"start\":36575},{\"end\":37139,\"start\":37049},{\"end\":38598,\"start\":38511},{\"end\":39237,\"start\":39124},{\"end\":39873,\"start\":39764},{\"end\":40581,\"start\":40433},{\"end\":41309,\"start\":41210},{\"end\":42027,\"start\":41903},{\"end\":42550,\"start\":42497},{\"end\":43110,\"start\":43020},{\"end\":45958,\"start\":45895}]"}}}, "year": 2023, "month": 12, "day": 17}