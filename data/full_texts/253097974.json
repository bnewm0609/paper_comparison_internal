{"id": 253097974, "updated": "2023-10-05 09:34:01.872", "metadata": {"title": "Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation", "authors": "[{\"first\":\"Zeyun\",\"last\":\"Zhong\",\"middle\":[]},{\"first\":\"David\",\"last\":\"Schneider\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Voit\",\"middle\":[]},{\"first\":\"Rainer\",\"last\":\"Stiefelhagen\",\"middle\":[]},{\"first\":\"Jurgen\",\"last\":\"Beyerer\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Although human action anticipation is a task which is inherently multi-modal, state-of-the-art methods on well known action anticipation datasets leverage this data by applying ensemble methods and averaging scores of unimodal anticipation networks. In this work we introduce transformer based modality fusion techniques, which unify multi-modal data at an early stage. Our Anticipative Feature Fusion Transformer (AFFT) proves to be superior to popular score fusion approaches and presents state-of-the-art results outperforming previous methods on EpicKitchens-100 and EGTEA Gaze+. Our model is easily extensible and allows for adding new modalities without architectural changes. Consequently, we extracted audio features on EpicKitchens-100 which we add to the set of commonly used features in the community.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2210.12649", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/wacv/ZhongSVSB23", "doi": "10.1109/wacv56688.2023.00601"}}, "content": {"source": {"pdf_hash": "7015acc77c00bccd14a7dda428909d2e248dcd1f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2210.12649v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "ba1c177e750856d7ced4652e637c56540691de5c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/7015acc77c00bccd14a7dda428909d2e248dcd1f.txt", "contents": "\nAnticipative Feature Fusion Transformer for Multi-Modal Action Anticipation\n\n\nZeyun Zhong \nFraunhofer IOSB\nKarlsruhe\n\nKarlsruhe Institute of Technology (KIT)\n\n\nDavid Schneider \nKarlsruhe Institute of Technology (KIT)\n\n\nMichael Voit \nFraunhofer IOSB\nKarlsruhe\n\nRainer Stiefelhagen \nKarlsruhe Institute of Technology (KIT)\n\n\nJ\u00fcrgen Beyerer \nFraunhofer IOSB\nKarlsruhe\n\nKarlsruhe Institute of Technology (KIT)\n\n\nAnticipative Feature Fusion Transformer for Multi-Modal Action Anticipation\n\nAlthough human action anticipation is a task which is inherently multi-modal, state-of-the-art methods on well known action anticipation datasets leverage this data by applying ensemble methods and averaging scores of unimodal anticipation networks. In this work we introduce transformer based modality fusion techniques, which unify multi-modal data at an early stage. Our Anticipative Feature Fusion Transformer (AFFT) proves to be superior to popular score fusion approaches and presents state-of-the-art results outperforming previous methods on EpicKitchens-100 and EGTEA Gaze+. Our model is easily extensible and allows for adding new modalities without architectural changes. Consequently, we extracted audio features on EpicKitchens-100 which we add to the set of commonly used features in the community. 1\n\nIntroduction\n\nBeyond human action recognition, anticipating possible future actions, as displayed in Figure 1, is one of the most important tasks for human machine cooperation and robotic assistance, e.g. to offer a hand at the right time or to generate proactive dialog to provide more natural interactions. As the anticipation results are just assumptions, this tends to be significantly more challenging than traditional action recognition, which performs well with today's well-honed discriminative models [13,35]. As modeling long temporal context is often crucial for anticipation [16,42,20], many such methods were proposed in recent years, including clustering [21,36], attention [42] and recurrence [16]. While vision based systems are the de-facto standard for action anticipation [16,20,48], additionally using other supporting modalities like optical flow features [47,7,28]   knowledge about objects in the scene [15] have shown to be beneficial. In recent work [28,27,37], audio has been explored and shown to be complementary with appearance for action recognition in first-person vision. Consistent with most multi-modal action recognition models [47,7], anticipation models typically use score fusion (i.e., averaging predictions computed based on each single modality) to fuse different modalities. While averaging using fixed weights, including simple averaging [42] and weighted averaging [20], shows already superior results over the unimodal baseline, Furnari et al. [16] show that assigning each modality with dynamical importance for the final prediction is particularly beneficial for anticipating egocentric actions. Inspired by the classical view of multisensory integration, i.e., information across the senses gets merged after the initial sensory processing is completed [6,45], we take the mid-level fusion strategy in this work. We present a transformer-based feature fusion model, Anticipative Feature Fusion Transformer (AFFT), which successfully combines multi-modal features in a mid-level fusion process where features are first fused and the fused representations are utilized to anticipate next actions, different from all late and score fusion methods mentioned above. Our method is based on features and does not require end-to-end training of feature extractors. We see this as a major advantage since recent state-of-the-art results on various tasks have been driven by large foundation models which are difficult and resource intensive to train. By combining strong feature extractors like OMNIVORE [22] with mid-level feature fusion, we achieve state-of-the art results on common action anticipation datasets without the need for fine-tuning them.\n\nIn summary, our main contributions are:\n\n\u2022 The Anticipative Feature Fusion Transformer (AFFT), which successfully performs mid-level fusion on extracted features, improves significantly over score fusion based approaches and provides state-of-the-art performance on EpicKitchens-100 action anticipation and competing results on EGTEA Gaze+;\n\n\u2022 A comparison of multiple self-attention and crossattention based feature fusion strategies as well as detailed hyper parameter ablations for our final model;\n\n\u2022 Extracted audio and OMNIVORE-based RGB features of EpicKitchen-100 which we provide to the community and an analysis of temporal and modality-wise performance contributions and model attention values.\n\n\nRelated Work\n\nAction anticipation aims to predict future actions given a video clip of the past and present. While many approaches investigated different forms of action and activity anticipation from third person video [17,12,29,23], the firstperson (egocentric) vision has recently gained popularity along with development of multiple challenge benchmarks to support it [8,9,32]. To model the temporal progression of past actions, [16] proposed using an LSTM to summarize the past and another LSTM for future prediction. [42] made use of long-range past information and used an adapted version of the attention mechanism to aggregate short-term ('recent') and long-term ('spanning') features. To maintain the sequential temporal evolution while addressing the problem of modeling long-range temporal dependencies of recurrent architectures, a variation of GPT-2 [40] has been recently proposed in [20]. We propose a transformer based feature fusion model to effectively fuse multiple modalities, and follow [20] to use a generative language model for future action prediction.\n\nMulti-modal fusion for action anticipation. The modalities typically used in prior work for egocentric vision are RGB, objects and optical flow [16,42,49,50,20]. To fuse information contained in different modalities, anticipation models typically utilize a late fusion strategy, similar to many multi-modal action recognition models [47,7,28]. These fusion methods can be broadly divided into score fusion and feature fusion. While in score fusion, the predicted future action scores of each modality are combined using either fixed weights, in form of simple averaging [42,49] or weighted averaging [20], or dynamic weights based on the scene [16], the feature fusion combines the predicted future action feature and an additional feed-forward layer is utilized to generate the action score [50]. Different from the late fusion strategy, we take the mid-level fusion strategy inspired by the classical view of multisensory integration [6,45]. Specifically, we adopt the multi-head attention mechanism [46] to combine different modalities at each timestamp and utilize the variation of GPT-2 following [20] to analyze the temporal evolution of the fused past features and predict future action features. Finally, a feed-forward layer is used to predict the future action class.\n\nAudio-visual learning. Recent work used audio for an array of video understanding tasks, including selfsupervised representation learning [5,3,30], audio-visual source separation [38,2,11], localizing sounds in video frames [4,43], generating sounds from video [39,52,18], leveraging audio for efficient action recognition [31,19], and utilizing audio to improve classification performance of action recognition [28,27,37]. Different from all the work above, we focus on making use of audio as a complementary source of information for action anticipation.\n\n\nMethodology\n\nOur architecture which is displayed in Figure 2 consists of three exchangeable components: Modality specific feature extractors f mj \u03a0 , j \u2208 {1, . . . , M }, a cross-modal fusion module g \u03a6 and an anticipation module a \u2126 . Since this work analyzes multi-modal fusion on frozen features, we assume all f \u03a0 to have pretrained frozen weights and therefore refer to Section 4.2 for more details on the specific feature sets used for our experiments. Our proposed fusion modules are presented in Section 3.2. We follow [20] and use a variation of the GPT-2 [40] model as feature anticipation module to predict\u1e91 i+1 = a \u2126 (z i ), i \u2208 {1, . . . , T }.\n\n\nProblem statement\n\nIn this work, we follow the anticipation setup defined in [8,9]. As illustrated in Figure 1, the action anticipation task aims to predict an action starting at time \u03c4 s by observing a video segment of length \u03c4 o . The observation segment is \u03c4 a seconds preceding the action, i.e., from time \u03c4 s \u2212 (\u03c4 a + \u03c4 o ) to \u03c4 s \u2212 \u03c4 a , where \u03c4 a denotes the \"anticipation time\", i.e., how many seconds in advance actions are to be anticipated. The anticipation time \u03c4 a is usually fixed for each dataset, whereas the length of the observation segment is typically dependent on the individual method. In\n\n\nFusion Module\n\n\u2026 < l a t e x i t s h a 1 _ b a s e 6 4 = \" 7 r q S n Z 0 t 3 c + 8 P w 9 H 6 F U X R h N w 5 M 0 = \" > A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L F b B U 0 m k q M e C F 4 8 V 7 A e 0 M W y 2 m 3 b p b h J 2 J 2 I N + S V e P C j i 1 Z / i z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u w X G + r Z X V t f W N z d J W e X t n d 6 9 i 7 x + 0 d Z w q y l o 0 F r H q B k Q z w S P W A g 6 C d R P F i A w E 6 w T j 6 6 n f e W B K 8 z i 6 g 0 n C P E m G E Q 8 5 J W A k 3 6 7 0 R w S y x 9 x 3 7 z P p u 7 l v V 5 2 a M w N e J m 5 B q q h A 0 7 e / + o O Y p p J F Q A X R u u c 6 C X g Z U c C p Y H m 5 n 2 q W E D o m Q 9 Y z N C K S a S + b H Z 7 j U 6 M M c B g r U x H g m f p 7 I i N S 6 4 k M T K c k M N K L 3 l T 8 z + u l E F 5 5 G Y + S F F h E 5 4 v C V G C I 8 T Q F P O C K U R A T Q w h V 3 N y K 6 Y g o Q s F k V T Y h u I s v L 5 P 2 e c 2 9 q N V v 6 9 X G S R F H C R 2 h Y 3 S G X H S J G u g G N V E L U Z S i Z / S K 3 q w n 6 8 V 6 t z 7 m r S t W M X O I / s D 6 / A H L 9 p M Y < / l a t e x i t >x m1 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" s T\nX 7 S v W Z C 7 m v s 3 B J B / 1 w X B J I s E Q = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k p S i n o s e P F Y w X 5 A G 8 N m u 2 2 X b j Z h d y L W k F / i x Y M i X v 0 p 3 v w 3 b t s c t P X B w O O 9 G W b m B b H g G\nh z n 2 y q s r W 9 s b h W 3 S z u 7 e / t l + + C w r a N E U d a i k Y h U N y C a C S 5 Z C z g I 1 o 0 V I 2 E g W C e Y X M / 8 z g N T m k f y D q Y x 8 0 I y k n z I K Q E j + X a 5 P y a Q P m Z + 7 T 4 N f T f z 7 Y p T d e b A q 8 T N S Q X l a P r 2 V 3 8 Q 0 S R k E q g g W v d c J w Y v J Q o 4 F S w r 9 R P N Y k I n Z M R 6 h k o S M u 2 l 8 8 M z f G a U A R 5 G y p Q E P F d / T 6 Q k 1 H o a B q Y z J D D W y 9 5 M / M / r J T C 8 8 l I u 4 w S Y p I t F w 0 R g i P A s B T z g i l E Q U 0 M I V d z c i u m Y K E L B Z F U y I b j L L 6 + S d q 3 q X l T r t / V K 4 z S P o 4 i O 0 Q k 6 R y 6 6 R A 1 0 g 5 q o h S h K 0 D N 6 R W / W k / V i v V s f i 9 a C l c 8 c o T + w P n 8 A z Y C T G Q = = < / l a t e x i t >x m1 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" q P g d 9 I c y z G\nD I j s o R 0 u A g R Q w f u A M = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k o i R T 0 W v H i s 0 C 9 o\nY 9 h s t + 3 S 3 S T s T s Q a 8 k u 8 e F D E q z / F m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B Z c g + N 8 W 4 W 1 9 Y 3 N r e J 2 a W d 3 b 7 9 s H x y 2 d Z Q o y l o 0 E p H q B k Q z w U P W A g 6 C d W P F i A w E 6 w S T m 5 n f e W B K 8 y h s w j R m n i S j k A 8 5 J W A k 3 y 7 3 x w T S x 8 x v 3 q f S d z P f r j h V Z w 6 8 S t y c V F C O h m 9 / 9 Q c R T S Q L g Q q i d c 9 1 Y v B S o o B T w b J S P 9 E s J n R C R q x n a E g k 0 1 4 6 P z z D Z 0 Y Z 4 G G k T I W A 5 + r v i Z R I r a c y M J 2 S w F g v e z P x P 6 + X w P D a S 3 k Y J 8 B C u l g 0 T A S G C M 9 S w A O u G A U x N Y R Q x c 2 t m I 6 J I h R M V i U T g r v 8 8 i p p X 1 T d y 2 r t r l a p n + Z x F N E x O k H n y E V X q I 5 u U Q O 1 E E U J e k a v 6 M 1 6 s l 6 s d + t j 0 V q w 8 p k j 9 A f W 5 w 8 B 4 5 M 7 < / l a t e x i t >x m1 T Feature Anticipation Module (GPT-2 based) \u2026 < l a t e x i t s h a 1 _ b a s e 6 4 = \" c m 8 u y A / W G 5 d H J X Z y 4 J h W y 1 7\nN / v U = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k p S i n o s e P F Y w X 5 A G 8 N m u 2 2 X b j Z h d y L W k F / i x Y M i X v 0 p 3 v w 3 b t s c t P X B w O O 9 G W b m B b H g G\nh z n 2 y q s r W 9 s b h W 3 S z u 7 e / t l + + C w r a N E U d a i k Y h U N y C a C S 5 Z C z g I 1 o 0 V I 2 E g W C e Y X M / 8 z g N T m k f y D q Y x 8 0 I y k n z I K Q E j + X a 5 P y a Q P m a + e 5 + G f i 3 z 7 Y p T d e b A q 8 T N S Q X l a P r 2 V 3 8 Q 0 S R k E q g g W v d c J w Y v J Q o 4 F S w r 9 R P N Y k I n Z M R 6 h k o S M u 2 l 8 8 M z f G a U A R 5 G y p Q E P F d / T 6 Q k 1 H o a B q Y z J D D W y 9 5 M / M / r J T C 8 8 l I u 4 w S Y p I t F w 0 R g i P A s B T z g i l E Q U 0 M I V d z c i u m Y K E L B Z F U y I b j L L 6 + S d q 3 q X l T r t / V K 4 z S P o 4 i O 0 Q k 6 R y 6 6 R A 1 0 g 5 q o h S h K 0 D N 6 R W / W k / V i v V s f i 9 a C l c 8 c o T + w P n 8 A z X u T G Q = = < / l a t e x i t >x m2 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" R b i x C j t 5 t P X x z t R g 9 3 M G 6 q 6 v k m 8 = \"\n> A A A B + H i c b V B N S 8 N A E J 3 U r 1 o / G v X o J V g F T y U p R T 0 W v H i s Y D + g j W G z 3 b Z L d z d h d y P W k F / i x Y M i X v 0 p 3 v w 3 b t s c t P X B w O O 9 G W b m h T G j S r v u t 1 V Y W 9 / Y 3 C p u l 3 Z 2 9 / b L 9 s F h W 0 W J x K S F I x b J b o g U Y V S Q l q a a k W 4 s C e I h I 5 1 w c j 3 z O w 9 E K h q J O z 2 N i c / R S N A h x U g b K b D L / T H S 6 W M W 1 O 5 T H t S y w K 6 4 V X c O Z 5 V 4 O a l A j m Z g f / U H E U 4 4 E R\no z p F T P c 2 P t p 0 h q i h n J S v 1 E k R j h C R q R n q E C c a L 8 d H 5 4 5 p w Z Z e A M I 2 l K a G e u / p 5 I E V d q y k P T y Z E e q 2 V v J v 7 n 9 R I 9 v P J T K u J E E 4 E X i 4 Y J c 3 T k z F J w B l Q S r N n U E I Q l N b c 6 e I w k w t p k V T I h e M s v r 5 J 2 r e p d V O u 3 9 U r j N I + j C M d w A u f g w S U 0 4 A a a 0 A I M C T z D K 7 x Z T 9 a L 9 W 5 9 L F o L V j 5 z B H 9 g f f 4 A z w W T G g = = < / l a t e x i t >x m2 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" 7 6  L E i k M u u 6 3 s 7 K 6 t r 6 x W d g q b u / s 7 u 2 X D g 6 b J k 4 1 4 w 0 W y 1 i 3 A 2 q 4 F I o 3 U K D k 7 U R z G g W S t 4 L R z d R v P X J t R K w e c J x w P 6 I D J U L B K F r p / q n n 9 U p l t + L O Q J a J l 5 M y 5 K j 3 S l / d f s z S i C t k k h r T 8 d w E / Y x q F E z y S b G b G p 5 Q N q I D 3 r F U 0 Y g b P 5 u d O i F n V u m T M N a 2 F J K Z + n s i o 5 E x 4 y i w n R H F o V n 0 p u J / X i f F 8 N r P h E p S 5 I r N F 4 W p J B i T 6 d + k L z R n K M e W U K a F v Z W w I d W U o U 2 n a E P w F l 9 e J s 2 L i n d Z q d 5 V y 7 X T P + x E d K B E K R t F K 9 0 + 9 S q 9 Y c s v u H G S V e B k p Q Y Z 6 r / j V 7 c c s j b h C J q k x H c 9 N 0 J 9 Q j Y J J P i 1 0 U 8 M T y k Z 0 w D u W K h p x 4 0 / m p 0 7 J u V X 6 J I y 1 L Y V k r v 6 e m N D I m H E U 2 M 6 I 4 t A s e z P x P 6 + T Y n j t T 4 R K U u S K L R a F q S Q Y k 9 n f p C 8 0 Z y j H l l C m h b 2 V s C H V l K F N p 2 B D 8 J Z f X i X N S t m 7 L F f v q q X a W R Z H H k 7 g F C 7 A g y u o w S 3 U o Q E M B v A M r / D m S O f F e X c + F q 0 5 J 5 s 5 h j 9 w P n 8 A C i i N j g = = < / l a t e x i t > z 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" E 3 u e + / H + p 4 j V M p c n q 4 A Q I o R l y 1 4 = \" > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S p 4 K o k U 9 V j w 4 r G i / Y A 2 l M 1 2 0 y 7 d b M L u R K i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 s 7 K 6 t r 6 x W d g q b u / s 7 u 2 X D g 6 b J k 4 1 4 w 0 W y 1 i 3 A 2 q 4 F I o 3 U K D k 7 U R z G g W S t 4 L R z d R v P X J t R K w e c J x w P 6 I D J U L B K F r p / q n n 9 U p l t + L O Q J a J l 5 M y 5 K j 3 S l / d f s z S i C t k k h r T 8 d w E / Y x q F E z y S b G b G p 5 Q N q I D 3 r F U 0 Y g b P 5 u d O i F n V u m T M N a 2 F J K Z + n s i o 5 E x 4 y i w n R H F o V n 0 p u J / X i f F 8 N r P h E p S 5 I r N F 4 W p J B i T 6 d + k L z R n K M e W U K a F v Z W w I d W U o U 2 n a E P w F l 9 e J s 2 L i n d Z q d 5 V y 7 X T P I 4 C H M M J n I M H V 1 C D W 6 h D A x g M 4 B l e 4 c 2 R z o v z 7 n z M W 1 e c f O Y I / s D 5 / A E I p I 2 N < / l a t e x i t > z 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" O 8 I z 3 K P U N K Y L x Y 5 / T U 5 h L r R X K N 4 = \" > A A A B 8 H i c b V D L T g J B E O z F F + I L 9 e h l I p p 4 I r u E q E c S L x 4 x k Y e B D Z k d B p g w O 7 u Z 6 T X B D V / h x Y P G e P V z v P k 3 D r A H B S v p p F L V n e 6 u I J b C o O t + O 7 m 1 9 Y 3 N r f x 2 Y W d 3 b / + g e H j U N F G i G W + w S E a 6 H V D D p V C 8 g Q I l b 8 e a 0 z C Q v B W M b 2 Z + 6 5 F r I y J 1 j 5 O Y + y E d K j E Q j K K V H r o j i u n T t F f p F U t u 2 Z 2 D r B I v I y X I U O 8 V v 7 r 9 i C U h V 8 g k N a b j u T H 6 K d U o m O T T Q j c x P K Z s T I e 8 Y 6 m i I T d + O j 9 4 S s 6 t 0 i e D S N t S S O b q 7 4 m U h s Z M w s B 2 h h R H Z t m b i f 9 5 n Q Q H 1 3 4 q V J w g V 2 y x a J B I g h G Z f U / 6 Q n O G c m I J Z V r Y W w k b U U 0 Z 2 o w K N g R v + e V V 0 q y U v c t y 9 a 5 a q p 1 l c e T h B E 7 h A j y 4 g h r c Q h 0 a w C C E Z 3 i F N 0 c 7 L 8 6 7 8 7 F o z T n Z z D H 8 g f P 5 A 9 l Y k F s = < / l a t e x i t >\u1e91 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" d 6 D d m N 9 / h 8 M u v e 3 l 8 A R J / n D 2 Q A U = \" > A A A B 8 H i c b V D L S g N B E O y N r x h f U Y 9 e B q P g K e x K U I 8 B L x 4 j 5 C X J E m Y n k 2 T I z O 4 y 0 y v E J V / h x Y M i X v 0 c b / 6 N k 2 Q P m l j Q U F R 1 0 9 0 V x F I Y d N 1 v J 7 e 2 v r G 5 l d 8 u 7 O z u 7 R 8 U D 4 + a J k o 0 4 w 0 W y U i 3 A 2 q 4 F C F v o E D J 2 7 H m V A W S t 4 L x 7 c x v P X J t R B T W c R J z X 9 F h K A a C U b T S Q 3 d E M X 2 a 9 u q 9 Y s k t u 3 O Q V e J l p A Q Z a r 3 i V 7 c f s U T x E J m k x n Q 8 N 0 Y / p R o F k 3 x a 6 C a G x 5 S N 6 Z B 3 L A 2 p 4 s Z P 5 w d P y b l V + m Q Q a V s h k r n 6 e y K l y p i J C m y n o j g y y 9 5 M / M / r J D i 4 8 V M R x g n y k C 0 W D R J J M C K z 7 0 l f a M 5 Q T i y h T A t 7 K 2 E j q i l D m 1 H B h u A t v 7 x K m p d l 7 6 p c u a + U q m d Z H H k 4 g V O 4 A A + u o Q p 3 U I M G M F D w D K / w 5 m j n x X l 3 P h a t O S e b O Y Y / c D 5 / A A z v k H 0 = < / l a t e x i t >\u1e91 T < l a t e x i t s h a 1 _ b a s e 6 4 = \" S 4 w O D / e P 1 3 L W C z / z b d T 9 b m M x g m A = \" > A A A B 9 H i c b V D L S g N B E O y N r x h f U Y 9 e B q M g C G F X g n o M e P E Y I S 9 I l j A 7 m S R D Z h / O 9 A b i s t / h x Y M i X v 0 Y b / 6 N k 2 Q P m l j Q U F R 1 0 9 3 l R V J o t O 1 v K 7 e 2 v r G 5 l d 8 u 7 O z u 7 R 8 U D 4 + a O o w V 4 w 0 W y l C 1 P a q 5 F A F v o E D J 2 5 H i 1 P c k b 3 n j u 5 n f m n C l R R j U c R p x 1 6 f D Q A w E o 2 g k t z u i m D y l v a R + 6 a S 9 Y s k u 2 3 O Q V e J k p A Q Z a r 3 i V 7 c f s t j n A T J J t e 4 4 d o R u Q h U K J n l a 6 M a a R 5 S N 6 Z B 3 D A 2 o z 7 W b z I 9 O y b l R + m Q Q K l M B k r n 6 e y K h v t Z T 3 z O d P s W R X v Z m 4 n 9 e J 8 b B r Z u I I I q R B 2 y x a B B L g i G Z J U D 6 Q n G G c m o I Z U q Y W w k b U U U Z m p w K J g R n + e V V 0 r w q O 9 f l y k O l V D 3 L 4 s j D C Z z C B T h w A 1 W 4 h x o 0 g M E j P M M r v F k T 6 8 V 6 t z 4 W r T k r m z m G P 7 A + f w C 1 U J H 5 < / l a t e x i t >\u1e91 T +1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" D i y a X K 3 Y W E 1 o 2 1 s s t 9 Q V / I a D u p w = \" > A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L F b B U 0 m k q M e C F 4 8 V m l p o Q 9 l s p + 3 S z S b s b o Q a + h u 8 e F D E q z / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 M B F c G 9 f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o p e N U M f R Z L G L V D q l G w S X 6 h h u B 7 U Q h j U K B D + H 4 d u Y / P K L S P J Z N M 0 k w i O h Q 8 g F n 1 F j J f + p l z W m v X H G r 7 h x k l X g 5 q U C O R q / 8 1 e 3 H L I 1 Q G i a o 1 h 3 P T U y Q U W U 4 E z g t d V O N C W V j O s S O p Z J G q I N s f u y U n F u l T w a x s i U N m a u / J z I a a T 2 J Q t s Z U T P S y 9 5 M / M / r p G Z w E 2 R c J q l B y R a L B q k g J i a z z 0 m f K 2 R G T C y h T H F 7 K 2 E j q i g z N p + S D c F b f n m V t C 6 r 3 l W 1 d l + r 1 M / y O I p w A q d w A R 5 c Q x 3 u o A E + M O D w D K / w 5 k j n x X l 3 P h a t B S e f O Y Y / c D 5 / A A J 8 j r w = < / l a t e x i t > z T \nh p h L 3 T V o 6 i v t d r C f t b A k Y a t X 8 = \" > A A A B + H i c b V B N S 8 N A E J 3 4 W e t H o x 6 9 L F b B U 0 l K U Y 8 F L x 4 r 9 A v a G D b b T b t 0 N w m 7 G 7 G G / h I v H h T x 6 k / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S D h T 2 n G + r b X 1 j c 2 t 7 c J O c X d v / 6 B k H x 6 1 V Z x K Q l\n\nCross-modal fusion\n\nTime-decoupled feature fusion In order to fuse the featuresx M i on each individual time-step separately, we apply L consecutive transformer encoder blocks as used in [10] with dimensionality d and k attention heads, this module is displayed on the left of Figure 3. We found that modalitywise positional embeddings do not yield an improvement of performance, presumably since the modality specific features are already easily separable in feature space. We do ablate the usage of a modality agnostic learnable tokenx \u039b , similar to the concept of a learnable class-token used in [10]. The module with the prepended learnable token x \u039b is referred to as Self-Attention Fuser (SA-Fuser). Without this learnable token we average the resulting output tokens z mj i . We consider the usage of the learnable token as default, experiments without token are marked as such.\n\nTemporal feature fusion The Temporal Self-Attention Fuser (T-SA-Fuser) which is displayed in the middle of Figure 3 follows the paradigm of the SA-Fuser, but instead of fusing multi-modal features per time step, all modality features for all time steps are used to provide all output features z = g(x M ) at once. A learnable positional embedding p i is used to encode the temporal positions for each modality and an attention mask enforces that an output feature at temporal position i only attends to previous or concurrent multi-modal features. Instead of a single modality agnostic token, we provide a learned token for each time step provided to the module. Learned positional embeddings are added to the tokens of each time step to allow the model to differentiate them.\n\nTemporal cross-attention feature fusion Our third fusion module, which is displayed on the right of Figure 3, is inspired by [26] and follows a different paradigm. Instead of providing all modalities at once, we iteratively enrich a main modality (RGB in our experiments) with information from other modalities. Instead of L transformer encoder blocks, (M \u2212 1) transformer decoder blocks [46] are used. Following the decoder architecture, the RGB featuresx RGB are provided as main input which provides the queries for the multi-head cross-attention and each block makes use of another modalityx mj as second decoder input which provides the keys and values. Positional embeddings are added to all modality features. We do not use additional tokens, but rather directly predict the fused features z. We refer to this module as Cross-Attention Fuser (CA-Fuser)\n\n\nFeature anticipation and classification\n\nAfter different modality features get fused by the fusion module, a variation of the GPT-2 [40] model is used to predict the future features\u1e91 i+1 = a \u2126 (z i ), i \u2208 {1, . . . , T }, following [20]. To encode the temporal ordering and obtain generative ability, learnable positional embeddings and a temporal attention mask are used. Based on the anticipated features\u1e91 we define a classification head h, a single linear layer followed by a softmax activation function. The anticipation result is based on the predicted future feature, so\u0177 i = h(\u1e91 i ) and the final anticipation result\ny T +1 = h(\u1e91 T +1 ).\n\nLoss functions\n\nOur loss functions follow the setting of [20]. We apply three losses L = L next + L cls + L feat . L next is defined on\u0177 T +1 and y T +1 according to the task of action anticipation. Since the network output does not only provide features\u1e91 T +1 for the anticipated next action but also for the preceding time steps i \u2208 {1, . . . , T }, L cls evaluates the action classification performance of these preceding features, so on\u0177 i = h(\u1e91 i ) and y i . Both are cross-entropy losses. L feat is the mean squared error between predicted and fused features\u1e91 i and z i .     \nLayerNorm MHSA LayerNorm MLP + + < l a t e x i t s h a 1 _ b a s e 6 4 = \" H g c J T f d Z w G A d y 7 0 H p i 9 o R p q Z p E 4 = \" > A A A B + n i c b V C 7 T s M w F H V 4 l v J K Y W S J q E B M V Y I q Y K z E w s B Q J P q Q m l A 5 j t N a d Z z I v g G q k E 9 h Y Q A h V r 6 E j b / B b T N A y 5 E s H Z 1 z j + 7 1 8 R P O F N j 2 t 7 G 0 v L K 6 t l 7 a K G 9 u b e / s m p W 9 t o p T S W i L x D y W X R 8 r y p m g L W D A a T e R F E c + p x 1 / d D n x O / d U K h a L W x g n 1 I v w Q L C Q E Q x a 6 p s V d 4 g h e 8 z v M v d a p w K c 9 8 2 q X b O n s B a J U 5 A q K t D s m 1 9 u E J M 0 o g I I x 0 r 1 H D s B L 8 M S G O E 0 L 7 u p o g k m I z y g P U 0 F j q j y s u n p u X W k l c A K Y 6 m f A G u q / k 5 k O F J q H P l 6 M s I w V P P e R P z P 6 6 U Q X n g Z E 0 k K V J D Z o j D l F s T W p A c r Y J I S 4 G N N M J F M 3 2 q R I Z a Y g G 6 r r E t w 5 r + 8 S N q n N e e s V r + p V x v H R R 0 l d I A O 0 Q l y 0 D l q o C v U R C 1 E 0 A N 6 R q / o z X g y X o x 3 4 2 M 2 u m Q U m X 3 0 B 8 b n D 8 D j l D 4 = < / l a t e x i t >x \u21e4 < l a t e x i t s h a 1 _ b a s e 6 4 = \" e w X i N p j P 3 6 y M d 3 V o p y p f g a X N p a Y = \" > A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L F b B U 0 m k q M e C F 4 8 V 7 A e 0 M W y 2 m 3 b p b h J 2 J 2 I N + S V e P C j i 1 Z / i z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u w X G + r Z X V t f W N z d J W e X t n d 6 9 i 7 x + 0 d Z w q y l o 0 F r H q B k Q z w S P W A g 6 C d R P F i A w E 6 w T j 6 6 n f e W B K 8 z i 6 g 0 n C P E m G E Q 8 5 J W A k 3 6 7 0 R w S y x 9 z n 9 5 n 0 3 d y 3 q 0 7 N m Q E v E 7 c g V V S g 6 d t f / U F M U 8 k i o I J o 3 X O d B L y M K O B U s L z c T z V L C B 2 T I e s Z G h H J t J f N D s / x q V E G O I y V q Q j w T P 0 9 k R G p 9 U Q G p l M S G O l F b y r + 5 / V S C K + 8 j E d J C i y i 8 0 V h K j D E e J o C H n D F K I i J I Y Q q b m 7 F d E Q U o W C y K p s Q 3 M W X l 0 n 7 v O Z e 1 O q 3 9 W r j p I i j h I 7 Q M T p D L r p E D X S D m q i F K E r R M 3 p F b 9 a T 9 W K 9 W x / z 1 h W r m D l E f 2 B 9 / g A i N Z N Q < / l a t e x i t >x m1 i < l a t e x i t s h a 1 _ b a s e 6 4 = \" t s b w 3 Q c M W g l 4 E a 0 t 3 s q O T G M x j 3 w = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k p S i n o s e P F Y w X 5 A G 8 N m u 2 2 X b j Z h d y L W k F / i x Y M i X v 0 p 3 v w 3 b t s c t P X B w O O 9 G W b m B b H g G h z n 2 y q s r W 9 s b h W 3 S z u 7 e / t l + + C w r a N E U d a i k Y h U N y C a C S 5 Z C z g I 1 o 0 V I 2 E g W C e Y X M / 8 z g N T m k f y D q Y x 8 0 I y k n z I K Q E j + X a 5 P y a Q P m Y + v 0 9 D v 5 b 5 d s W p O n P g V e L m p I J y N H 3 7 q z + I a B I y C V Q Q r X u u E 4 O X E g W c C p a V + o l m M a E T M m I 9 Q y U J m f b S + e E Z P j P K A A 8 j Z U o C n q u / J 1 I S a j 0 N A 9 M Z E h j r Z W 8 m / u f 1 E h h e e S m X c Q J M 0 s W i Y S I w R H i W A h 5 w x S i I q S G E K m 5 u x X R M F K F g s i q Z E N z l l 1 d J u 1 Z 1 L 6 r 1 2 3 q l c Z r H U U T H 6 A S d I x d d o g a 6 Q U 3 U Q h Q l 6 B m 9 o j f r y X q x 3 q 2 P R W v B y m e O 0 B 9 Y n z 8 j u p N R < / l a t e x i t >x m2 i \u2026 < l a t e x i t s h a 1 _ b a s e 6 4 = \" T 2 j W F 6 1 T v p v I v A X z + P 0 m Y v S a 5 C E = \" > A A A B 7 3 i c b V A 9 S w N B E J 3 z M 8 a v q K X N Y h S s w p 0 E t Q z Y W F h E M B + Q H G F v s 5 c s 2 d s 7 d + e E c O R P 2 F g o Y u v f s f P f u E m u 0 M Q H A 4 / 3 Z p i Z F y R S G H T d b 2 d l d W 1 9 Y 7 O w V d z e 2 d 3 b L x 0 c N k 2 c a s Y b L J a x b g f U c C k U b 6 B A y d u J 5 j Q K J G 8 F o 5 u p 3 3 r i 2 o h Y P e A 4 4 X 5 E B 0 q E g l G 0 U r u L I u K G 3 P V K Z b f i z k C W i Z e T M u S o 9 0 p f 3 X 7 M 0 o g r Z J I a 0 / H c B P 2 M a h R M 8 k m x m x q e U D a i A 9 6 x V F G 7 x s 9 m 9 0 7 I m V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z 2 M 6 G S F L l i 8 0 V h K g n G Z P o 8 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g j K t o Q v M W X l 0 n z o u J d V q r 3 1 X L t N I + j A M d w A u f g w R X U 4 B b q 0 A A G E p 7 h F d 6 c R + f F e X c ++ LayerNorm 1 2 T < l a t e x i t s h a 1 _ b a s e 6 4 = \" 7 r q S n Z 0 t 3 c + 8 P w 9 H 6 F U X R h N w 5 M 0 = \" > A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L F b B U 0 m k q M e C F 4 8 V 7 A e 0 M W y 2 m 3 b p b h J 2 J 2 I N + S V e P C j i 1 Z / i z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u w X G + r Z X V t f W N z d J W e X t n d 6 9 i 7 x + 0 d Z w q y l o 0 F r H q B k Q z w S P W A g 6 C d R P F i A w E 6 w T j 6 6 n f e W B K 8 z i 6 g 0 n C P E m G E Q 8 5 J W A k 3 6 7 0 R w S y x 9 x 3 7 z P p u 7 l v V 5 2 a M w N e J m 5 B q q h A 0 7 e / + o O Y p p J F Q A X R u u c 6 C X g Z U c C p Y H m 5 n 2 q W E D o m Q 9 Y z N C K S a S + b H Z 7 j U 6 M M c B g r U x H g m f p 7 I i N S 6 4 k M T K c k M N K L 3 l T 8 z + u l E F 5 5 G Y + S F F h E 5 4 v C V G C I 8 T Q F P O C K U R A T Q w h V 3 N y K 6 Y g o Q s F k V T Y h u I s v L 5 P 2 e c 2 9 q N V v 6 9 X G S R F H C R 2 h Y 3 S G X H S J G u g G N V E L U Z S i Z / S K 3 q w n 6 8 V 6 t z 7 m r S t W M X O I / s D 6 / A H L 9 p M Y < / l a t e x i t >x m1 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" s T X 7 S v W Z C 7 m v s 3 B J B / 1 w X B J I s E Q = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k p S i n o s e P F Y w X 5 A G 8 N m u 2 2 X b j Z h d y L W k F / i x Y M i X v 0 p 3 v w 3 b t s c t P X B w O O 9 G W b m B b H g G h z n 2 y q s r W 9 s b h W 3 S z u 7 e / t l + + C w r a N E U d a i k Y h U N y C a C S 5 Z C z g I 1 o 0 V I 2 E g W C e Y X M / 8 z g N T m k f y D q Y x 8 0 I y k n z I K Q E j + X a 5 P y a Q P m Z + 7 T 4 N f T f z 7 Y p T d e b A q 8 T N S Q X l a P r 2 V 3 8 Q 0 S R k E q g g W v d c J w Y v J Q o 4 F S w r 9 R P N Y k I n Z M R 6 h k o S M u 2 l 8 8 M z f G a U A R 5 G y p Q E P F d / T 6 Q k 1 H o a B q Y z J D D W y 9 5 M / M / r J T C 8 8 l I u 4 w S Y p I t F w 0 R g i P A s B T z g i l E Q U 0 M I V d z c i u m Y K E L B Z F U y I b j L L 6 + S d q 3 q X l T r t / V K 4 z S P o 4 i O 0 Q k 6 R y 6 6 R A 1 0 g 5 q o h S h K 0 D N 6 R W / W k / V i v V s f i 9 a C l c 8 c o T + w P n 8 A z Y C T G Q = = < / l a t e x i t >x m1 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" q P g d 9 I c y z G D I j s o R 0 u A g R Q w f u A M = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k o i R T 0 W v H i s 0 C 9 o Y 9 h s t + 3 S 3 S T s T s Q a 8 k u 8 e F D E q z / F m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B Z c g + N 8 W 4 W 1 9 Y 3 N r e J 2 a W d 3 b 7 9 s H x y 2 d Z Q o y l o 0 E p H q B k Q z w U P W A g 6 C d W P F i A w E 6 w S T m 5 n f e W B K 8 y h s w j R m n i S j k A 8 5 J W A k 3 y 7 3 x w T S x 8 x v 3 q f S d z P f r j h V Z w 6 8 S t y c V F C O h m 9 / 9 Q c R T S Q L g Q q i d c 9 1 Y v B S o o B T w b J S P 9 E s J n R C R q x n a E g k 0 1 4 6 P z z D Z 0 Y Z 4 G G k T I W A 5 + r v i Z R I r a c y M J 2 S w F g v e z P x P 6 + X w P D a S 3 k Y J 8 B C u l g 0 T A S G C M 9 S w A O u G A U x N Y R Q x c 2 t m I 6 J I h R M V i U T g r v 8 8 i p p X 1 T d y 2 r t r l a p n + Z x F N E x O k H n y E V X q I 5 u U Q O 1 E E U J e k a v 6 M 1 6 s l 6 s d + t j 0 V q w 8 p k j 9 A f W 5 w 8 B 4 5 M 7 < / l a t e x i t >x m1 T 1 2 T < l a t e x i t s h a 1 _ b a s e 6 4 = \" 9 M y R 6 Z 9 O J D s o V v 2 U q L e o E o y q s k U = \" > A A A B + H i c b V B N S 8 N A E J 3 U r 1 o / G v X o Z b E K n k o i R T 0 W v H i s Y D + g r W G z 3 b R r d 5 O w u x F r y C / x 4 k E R r / 4 U b / 4 b t 2 0 O 2 v p g 4 P H e D D P z / J g z p R 3 n 2 y q s r K 6 t b x Q 3 S 1 v b O 7 t l e 2 + / p a J E E t o k E Y 9 k x 8 e K c h b S p m a a 0 0 4 s K R Y + p 2 1 / f D X 1 2 w 9 U K h a F t 3 o S 0 7 7 A w 5 A F j G B t J M 8 u 9 0 Z Y p 4 + Z 5 9 6 l w r v P P L v i V J 0 Z 0 D J x c 1 K B H A 3 P / u o N I p I I G m r C s V J d 1 4 l 1 P 8 V S M 8 J p V u o l i s a Y j P G Q d g 0 N s a C q n 8 4 O z 9 C J U Q Y o i K S p U K O Z + n s i x U K p i f B N p 8 B 6 p B a 9 q f i f 1 0 1 0 c N l P W R g n m o Z k v i h I O N I R m q a A B k x S o v n E E E w k M 7 c i M s I S E 2 2 y K p k Q 3 M W X l 0 n r r O q e V 2 s 3 t U r 9 O I + j C I d w B K f g w g X U 4 R o a 0 A Q C C T z D K 7 x Z T 9 a L 9 W 5 9 z F s L V j 5 z A H 9 g f f 4 A I q K T U Q = = < / l a t e x i t >x mj 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" 1 o X l 6 B 6 M e d F l a w S y l q 5 F 2 B p Q E Y g = \" > A A A B + H i c b V D L S s N A F L 2 p r 1 o f j b p 0 M 1 g F V y W R o i 4 L b l x W s A 9 o Y 5 h M J + 3 Y y S T M T M Q a 8 i V u X C j i 1 k 9 x 5 9 8 4 f S y 0 9 c C F w z n 3 c u 8 9 Q c K Z 0 o 7 z b R V W V t f W N 4 q b p a 3 t n d 2 y v b f f U n E q C W 2 S m M e y E 2 B F O R O 0 q Z n m t J N I i q O A 0 3 Y w u p r 4 7 Q c q F Y v F r R 4 n 1 I v w Q L C Q E a y N 5 N v l 3 h D r 7 D H 3 z + 6 y y L / P f b v i V J 0 p 0 D J x 5 6 Q C c z R 8 + 6 v X j 0 k a U a E J x 0 p 1 X S f R X o a l Z o T T v N R L F U 0 w G e E B 7 R o q c E S V l 0 0 P z 9 G J U f o o j K U p o d F U / T 2 R 4 U i p c R S Y z g j r o V r 0 J u J / X j f V 4 a W X M Z G k m g o y W x S m H O k Y T V J A f S Y p 0 X x s C C a S m V s R G W K J i T Z Z l U w I 7 u L L y 6 R 1 V n X P q 7 W b W q V + P I + j C I d w B K f g w g X U 4 R o a 0 A Q C K T z D K 7 x Z T 9 a L 9 W 5 9 z F o L 1 n z m A P 7 A + v w B J C y T U g = = < / l a t e x i t >x mj 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" h h i 8 I h 6 q e s F B A z W D P f A d O u 9 4 K z 4 = \" > A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L F b B U 0 m k q M e C F 4 8 V + g V t D Z v t p l 2 7 m 4 T d i V h D f o k X D 4 p 4 9 a d 4 8 9 + 4 b X P Q 1 g c D j / d m m J n n x 4 J r c J x v a 2 V 1 b X 1 j s 7 B V 3 N 7 Z 3 S v Z + w c t H S W K s i a N R K Q 6 P t F M 8 J A 1 g Y N g n V g x I n 3 B 2 v 7 4 e u q 3 H 5 j S P A o b M I l Z X 5 J h y A N O C R j J s 0 u 9 E Y H 0 M f M a d 6 n 0 7 j P P L j s V Z w a 8 T N y c l F G O u m d / 9 Q Y R T S Q L g Q q i d d d 1 Y u i n R A G n g m X F X q J Z T O i Y D F n X 0 J B I p v v p 7 P A M n x p l g I N I m Q o B z 9 T f E y m R W k + k b z o l g Z F e 9 K b i f 1 4 3 g e C q n / I w T o C F d L 4 o S A S G C E 9 T w A O u G A U x M Y R Q x c 2 t m I 6 I I h R M V k U T g r v 4 8 j J p n V f c i 0 r 1 t l q u n e R x F N A R O k Z n y E W X q I Z u U B 0 1 E U U JC h k Q 0 a w N p J v l / t j r N P H z G f 3 q f B v M t + u O j V n D r R K 3 J x U I U f T t 7 / 6 g 4 g k g o a a c K x U z 3 V i 7 a V Y a k Y 4 z U r 9 R N E Y k w k e 0 Z 6 h I R Z U e e n 8 8 A y d G G W A h p E 0 F W o 0 V 3 9 P p F g o N R W B 6 R R Y j 9 W y N x P / 8 3 q J H l 5 6 K Q v j R N O Q L B Y N E 4 5 0 h G Y p o A G T l G g + N Q Q T y c y t i I y x x E S b r E o m B H f 5 5 V X S P q u 5 5 7 X 6 b b 3 a q O R x F O E Y K n A K L l x A A 6 6 h C S 0 g k M A z v M K b 9 W S 9 W O / W x 6 K 1 Y O U z R /\n\nT s M w F H X K q 5 R X o C O L R U F i q h J U A W M l F g a G I t G H 1 I T I c Z z W q u N E t o O I o v A r L A w g x M q H s P E 3 u G 0 G a D m S p a N z 7 t G 9 P n 7 C q F S W 9 W 1 U V l b X 1 j e q m 7 W t 7 Z 3 d P X P / o C f j V G D S x T G L x c B H k j D K S V d R x c g g E Q R F P i N 9 f 3 I 1 9 f s P R E g a 8 z u V J c S N 0 I j T k G K k t O S Z d W e M V P 5 Y e P Z 9 7 t z o X I A K z 2 x Y T W s G u E z s k j R A i Y 5 n f j l B j N O I c I U Z k n J o W 4 l y c y Q U x Y w U N S e V J E F 4 g k Z k q C l H E Z F u P j u + g C d a C W A Y C / 2 4 g j P 1 d y J H k Z R Z 5 O v J C K m x X P S m 4 n / e M F X h p Z t T n q S K c D x f F K Y M q h h O m 4 A B F Q Q r l m m C s K D 6 V o j H S C C s d F 8 1 X Y K 9 + O V l 0 j t r 2 u f N 1 m 2 r 0 T 4 u 6 6 i C Q 3 A E T o E N L k A b X I M O 6 A I M M v A M X s G b 8 W S 8 G O / G x 3 y 0 Y p S Z O v g D 4 / M H 8 P G U 4 A = = < / l a t e x i t >x\n\n\n\u21e4 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" 7 r q S n Z 0 t 3 c + 8 P w 9 H 6 F U X R h N w 5 M 0 = \" > A A A B + H i c b V B N S 8 N A E N 3 4 W e t H o x 6 9 L F b B U 0 m k q M e C F 4 8 V 7 A e 0 M W y 2 m 3 b p b h J 2 J 2 I N + S V e P C j i 1 Z / i z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u w X G + r Z X V t f W N z d J W e X t n d 6 9 i 7 x + 0 d Z w q y l o 0 F r H q B k Q z w S P W A g 6 C d R P F i A w E 6 w T j 6 6 n f e W B K 8 z i 6 g 0 n C P E m G E Q 8 5 J W A k 3 6 7 0 R w S y x 9 x 3 7 z P p u 7 l v V 5 2 a M w N e J m 5 B q q h A 0 7 e / + o O Y p p J F Q A X R u u c 6 C X g Z U c C p Y H m 5 n 2 q W E D o m Q 9 Y z N C K S a S + b H Z 7 j U 6 M M c B g r U x H g m f p 7 I i N S 6 4 k M T K c k M N K L 3 l T 8 z + u l E F 5 5 G Y + S F F h E 5 4 v C V G C I 8 T Q F P O C K U R A T Q w h V 3 N y K 6 Y g o Q s F k V T Y h u I s v L 5 P 2 e c 2 9 q N V v 6 9 X G S R F H C R 2 h Y 3 S G X H S J G u g G N V E L U Z S i Z / S K 3 q w n 6 8 V 6 t z 7 m r S t W M X O I / s D 6 / A H L 9 p M Y < / l a t e x i t >x m1 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" j l 2 T e y Q 0 Z f q Y E l e + + M M 7 H d h y M X c = \" > A A A B + H i c b V B N S 8 N A E J 3 U r 1 o / G v X o Z W k R P J V E i n o s e P E i V L A f 0 M a w 2 W 7 b p b t J 2 N 2 I N e S X e P G g i F d / i j f / j d s 2 B 2 1 9 M P B 4 b 4 a Z e U H M m d K O 8 2 0 V 1 t Y 3 N r e K 2 6 W d 3 b 3 9 s n 1 w 2 F Z R I g l t k Y h H s h t g R T k L a U s z z W k 3 l h S L g N N O M L m a + Z 0 H K h W L w j s 9 j a k n 8 C h k Q 0 a w N p J v l / t j r N P H z H f v U + H f Z L 5 d d W r O H G i V u D m p Q o 6 m b 3 / 1 B x F J B A 0 1 4 V i p n u v E 2 k u x 1 I x w m p X 6 i a I x J h M 8 o j 1 D Q y y o 8 t L 5 4 R k 6 M c o A D S N p K t R o r v 6 e S L F Q a i o C 0 y m w H q t l b y b + 5 / U S P b z 0 U h b G i a Y h W S w a J h z p C M 1 S Q A M m K d F 8 a g g m k p l b E R l j i Y k 2 W Z V M C O 7 y y 6 u k f V Z z z 2 v 1 2 3 q 1 U c n j K M I x V O A U X L i A B l x D E 1 p A I I F n e I U 3 6 8 l 6 s d 6 t j 0 V r w c p n j u A P r M 8 f 9 e i T M g = = < / l a t e x i t >x\nmM 1 \u2026 T T T <\n\nl a t e x i t s h a 1 _ b a s e 6 4 = \" z x t f 6 1 Z V A X C P 9 N / e Z Q t c U J p w L C U = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z W k R P J V E R D 0 W v H g R K v Q L 2 h g 2 2 2 2 7 d D c J u x O x h v w S L x 4 U 8 e p P 8 e a / c d v m o K 0 P B h 7 v z T A z L 4 g F 1 + A 4 3 1 Z h b X 1 j c 6 u 4 X d r Z 3 d s v 2 w e H b R 0 l i r I W j U S k u g H R T P C Q t Y C D Y N 1 Y M S I D w T r B 5 H r m d x 6 Y 0 j w K m z C N m S f J K O R D T g k Y y b f L / T G B 9 D H z m / e p 9 G 8 z 3 6 4 6 N W c O v E r c n F R R j o Z v f / U H E U 0 k C 4 E K o n X P d W L w U q K A U 8 G y U j / R L C Z 0 Q k a s Z 2 h I J N N e O j 8 8 w y d G G e B h p E y F g O f q 7 4 m U S K 2 n M j C d k s B Y L 3 s z 8 T + v l 8 D w y k t 5 G C f A Q r p Y N E w E h g j P U s A D r h g F M T W E U M X N r Z i O i S I U T F Y l E 4 K 7 / P I q a Z / V 3 I v a + d 1 5 t V 7 J 4 y i i Y 1 R B p 8 h F l 6 i O b l A D t R B F C X p G r + j N e r J e r H f r Y 9 F a s P K Z I / Q H 1 u c P K 9 W T V Q = = < / l a t e x i t >x mM T < l a t e x i t s h a 1 _ b a s e 6 4 = \" q P g d 9 I c y z G D I j s o R 0 u A g R Q w f u A M = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k o i R T 0 W v H i s 0 C 9 o Y 9 h s t + 3 S 3 S T s T s Q a 8 k u 8 e F D E q z / F m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I B Z c g + N 8 W 4 W 1 9 Y 3 N r e J 2 a W d 3 b 7 9 s H x y 2 d Z Q o y l o 0 E p H q B k Q z w U P W A g 6 C d W P F i A w E 6 w S T m 5 n f e W B K 8 y h s w j R m n i S j k A 8 5 J W A k 3 y 7 3 x w T S x 8 x v 3 q f S d z P f r j h V Z w 6 8 S t y c V F C O h m 9 / 9 Q c R T S Q L g Q q i d c 9 1 Y v B S o o B T w b J S P 9 E s J n R C R q x n a E g k 0 1 4 6 P z z D Z 0 Y Z 4 G G k T I W A 5 + r v i Z R I r a c y M J 2 S w F g v e z P x P 6 + X w P D a S 3 k Y J 8 B C u l g 0 T A S G C M 9 S w A O u G A U x N Y R Q x c 2 t m I 6 J I h R M V i U T g r v 8 8 i p p X 1 T d y 2 r t r l a p n + Z x F N E x O k H n y E V X q I 5 u U Q O 1 E E U J e k a v 6 M 1 6 s l 6 s d + t j 0 V q w 8 p k j 9 A f W 5 w 8 B 4 5 M 7 < / l a t e x i t >x\n\n\nm1 T < l a t e x i t s h a 1 _ b a s e 6 4 = \" I Q d r o 8 r E s J Y W 8 Q y S F 4 v h 8 H Q y N 5 U = \" > A A A B / H i c b V C 7 T s M w F H V 4 l v I K d G S x K E h M V Y I q Y K z E w s B Q p L 6 k J k S O 4 7 R W H S e y H U Q U h V 9 h Y Q A h V j 6 E j b / B b T N A y 5 E s H Z 1 z j + 7 1 8 R N G p b K s b 2 N l d W 1 9 Y 7 O y V d 3 e 2 d 3 b N w 8 O e z J O B S Z d H L N Y D H w k C a O c d B V V j A w S Q V D k M 9 L 3 J 9 d T v / 9 A h K Q x 7 6 g s I W 6 E R p y G F C O l J c + s O W O k 8 s f C 6 9 z n z q 3 O B a j w z L r V s G a A y 8 Q u S R 2 U a H v m l x P E O I 0 I V 5 g h K Y e 2 l S g 3 R 0 J R z E h R d V J J E o Q n a E S G m n I U E e n m s + M L e K q V A I a x 0 I 8 r O F N / J 3 I U S Z l F v p 6 M k B r L R W 8 q / u c N U x V e u T n l S a o I x / N F Y c q g i u G 0 C R h Q Q b B i m S Y I C 6 p v h X i M B M J K 9 1 X V J d i L X 1 4 m v f O G f d F o 3 j X r r Z O y j g o 4 A s f g D N j g E r T A D W i D L s A g A 8 / g F b w Z T 8 a L 8 W 5 8 z E d X j D J T A 3 9 g f P 4 A J 2 q V A w = = < / l a t e x i t >x\n\n\nl a t e x i t s h a 1 _ b a s e 6 4 = \" H g c J T f d Z w G A d y 7 0 H p i 9 o R p q Z p E 4 = \" > A A A B + n i c b V C 7 T s M w F H V 4 l v J K Y W S J q E B M V Y I q Y K z E w s B Q J P q Q m l A 5 j t N a d Z z I v g G q k E 9 h Y Q A h V r 6 E j b / B b T N A y 5 E s H Z 1 z j + 7 1 8 R P O F N j 2 t 7 G 0 v L K 6 t l 7 a K G 9 u b e / s m p W 9 t o p T S W i L x D y W X R 8 r y p m g L W D A a T e R F E c + p x 1 / d D n x O / d U K h a L W x g n 1 I v w Q L C Q E Q x a 6 p s V d 4 g h e 8 z v M v d a p w K c 9 8 2 q X b O n s B a J U 5 A q K t D s m 1 9 u E J M 0 o g I I x 0 r 1 H D s B L 8 M S G O E 0 L 7 u p o g k m I z y g P U 0 F j q j y s u n p u X W k l c A K Y 6 m f A G u q / k 5 k O F J q H P l 6 M s I w V P P e R P z P 6 6 U Q X n g Z E 0 k K V J D Z o j D l F s T W p A c r Y J I S 4 G N N M J F M 3 2 q R I Z a Y g G 6 r r E t w 5 r + 8 S N q n N e e s V r + p V x v H R R 0 l d I A O 0 Q l y 0 D l q o C v U R C 1 E 0 A N 6 R q / o z X g y X o x 3 4 2 M 2 u m Q U m X 3 0 B 8 b n D 8 D j l D 4 = < / l a t e x i t >x\n\n\n\u21e4 < l a t e x i t s h a 1 _ b a s e 6 4 = \" Q 2 v u 5 a I l C 0 9 A c q A j X I q G 3 4 1 O 0 T M = \" > A A A B + H i c b V B N S 8 N A E N 3 U r 1 o / G v X o Z b E K n k o i R T 0 W v H i s Y D + g r W G z 3 b R r d 5 O w O x F r y C / x 4 k E R r / 4 U b / 4 b t 2 0 O 2 v p g 4 P H e D D P z / F h w D Y 7 z b R V W V t f W N 4 q b p a 3 t n d 2 y v b f f 0 l G i K G v S S E S q 4 x P N B A 9 Z E z g I 1 o k V I 9 I X r O 2 P r 6 Z + + 4 E p z a P w F i Y x 6 0 s y D H n A K Q E j e X a 5 N y K Q P m Y e v 0 u l d 5 9 5 d s W p O j P g Z e L m p I J y N D z 7 q z e I a C J Z C F Q Q r b u u E 0 M / J Q o 4 F S w r 9 R L N Y k L H Z M i 6 h o Z E M t 1 P Z 4 d n + M Q o A x x E y l Q I e K b + n k i J 1 H o i f d M p C Y z 0 o j c V / / O 6 C Q S X / Z S H c Q I s p P N F Q S I w R H i a A h 5 w x S i I i S G E K m 5 u x X R E F K F g s i q Z E N z F l 5 d J 6 6 z q n l d r N 7 V K / T i P o 4 g O 0 R E 6 R S 6 6 Q H V 0 j R q o i S h K 0 D N 6 R W / W k / V i v V s f 8 9 a C l c 8 c o D + w P n 8 A e N K T i Q = = < / l a t e x i t >x mj i < l a t e x i t s h a 1 _ b a s e 6 4 = \" E K O B L K K Y r 1 I 3 y P p 8 i a 7 B x 0 o A u 3 4 = \" > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S p 4 K o k U 9 V j w 4 r G i / Y A 2 l M 1 2 0 y 7 d b M L u R K i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 s 7 K 6 t r 6 x W d g q b u / s 7 u 2 X D g 6 b J k 4 1 4 w 0 W y 1 i 3 A 2 q 4 F I o 3 U K D k 7 U R z G g W S t 4 L R z d R v P X J t R K w e c J x w P 6 I D J U L B K F r p / q k n e q W y W 3 F n I M v E y 0 k Z c t R 7 p a 9 u P 2 Z p x B U y S Y 3 p e G 6 C f k Y 1 C i b 5 p N h N D U 8 o G 9 E B 7 1 i q a M S N n 8 1 O n Z A z q / R J G G t b C s l M / T 2 R 0 c i Y c R T Y z o j i 0 C x 6 U / E / r 5 N i e O 1 n Q i U p c s X m i 8 J U E o z J 9 G / S F 5 o z l G N L K N P C 3 k r Y k G r K 0 K Z T t C F 4 i y 8 v k + Z F x b u s V O + q 5 d p p H k c B j u E E z s G D K 6 j B L d S h A Q w G 8 A y v 8 O Z I 5 8 V 5 d z 7 m r S t O P n M E f + B 8 / g B d h I 3 F < / l a t e x i t > z i < l a t e x i t s h a 1 _ b a s e 6 4 = \" q 2 k h a k N C q + n 1 E O 0 3 H Y y B z U D o + f k = \" > A A A B 8 H i c b V B N S w M x E J 3 1 s 9 a v q k c v w S p 4 K r t S 1 G P B i 8 c K 9 k P a d c m m 2 T Y 2 y S 5 J V q h L f 4 U X D 4 p 4 9 e d 4 8 9 + Y t n v Q 1 g c D j / d m m J k X J p x p 4 7 r f z t L y y u r a e m G j u L m 1 v b N b 2 t t v 6 j h V h D Z I z G P V D r G m n E n a M M x w 2 k 4 U x S L k t B U O r y Z + 6 5 E q z W J 5 a 0 Y J 9 Q X u S x Y x g o 2 V 7 p 4 C d p + J 4 G E c l M p u x Z 0 C L R I v J 2 X I U Q 9 K X 9 1 e T F J B p S E c a 9 3 x 3 M T 4 G V a G E U 7 H x W 6 q a Y L J E P d p x 1 K J B d V + N j 1 4 j E 6 s 0 k N R r G x J g 6 b q 7 4 k M C 6 1 H I r S d A p u B n v c m 4 n 9 e J z X R p Z 8 x m a S G S j J b F K U c m R h N v k c 9 p i g x f G Q J J o r Z W x E Z Y I W J s R k V b Q j e / M u L p H l W 8 c 4 r 1 Z t q u X a c x 1 G A Q z i C U / D g A m p w D X V o A A E B z /\n\n\nExperimental Setup\n\nIn order to investigate the influence of the different fusion strategies and evaluate the proposed method for the action anticipation task, we train and evaluate our methods on two different datasets (discussed in detail in Section 4.1). To allow a fair comparison with prior work, we first use pre-extracted TSN features [47] as input features for both datasets provided by [16]. To investigate the impact of the audio modality for action anticipation, we train a TSN audio action recognition model following [28] and extract its features for fusion with other modalities. In order to show the generalization of our proposed fusion method, we extract alternative RGB features from a recent state-of-theart visual model, OMNIVORE [22]. Information regarding feature extraction is discussed in detail in Section 4.2. All experiments follow the training procedure described in Section 4.3.\n\n\nDatasets and metrics\n\nWe perform experiments on two large-scale egocentric (first-person) video datasets: EpicKitchens-100 [9] and EGTEA Gaze+ [32]. EpicKitchens-100 consists of 700 long unscripted videos of cooking activities totalling 100 hours. It contains 90.0K action annotations, 97 verbs, and 300 nouns. We considered all unique (verb, noun) pairs in the public training set, obtaining 3,807 unique actions. We use the official train, val and test splits to report performance. The test evaluation is performed on a held-out set through a submission to the official challenge server. EGTEA Gaze+ is another popular egocentric action anticipation dataset. It contains 10.3K action annotations, 19 verbs, 51 nouns and 106 unique actions.\n\nWe report class mean top-5 recall [14] for EpicKitchens-100, a class-aware metric in which performance indicators obtained for each class are averaged to obtain the final score, accounting for the multi-modality in future predictions and class imbalance in a long-tail distribution. For EGTEA Gaze+, we report top-1/5 and class mean top-1. As some prior works report their results averaged across the official three splits, and some evaluate their methods on the first split only, we test our method using both recipes.\n\n\nUni-modal features\n\nRGB. We compare two types of RGB features, the commonly used TSN features [47] provided by [16] and Swin transformer [34] features which we extracted with OMNI-VORE [22] to represent more recent transformer based approaches. Both feature extractors are trained for action recognition. While TSN features are extracted by applying TSN on each frame, we extract Swin features by feeding 32 consecutive past frames totalling 1.067s video with a frame rate of 30fps to the OMNIVORE model for each timestamp.\n\nAudio. Following [28], We extract 1.28s of audio, convert it to single-channel, and resample it to 24kHz. We then convert it to a log-spectrogram representation using an STFT of window length 10ms, hop length 5ms and 256 frequency bands, resulting in a 2D spectrogram matrix of size 256\u00d7256, after which we compute the logarithm. Different from [28], we extract audio in an online manner, i.e., we extract the past audio segment for each timestamp, prohibiting the model to have access to the future, which is the prerequisite for the anticipation task. We feed such matrices to the TSN network, train it for the action recognition task and extract features for our work.\n\nObjects and optical flow. We use the existing object and optical flow features provided by [16]. Object representations are obtained by accumulating the confidence scores of all bounding boxes predicted by a Faster R-CNN [41] for each object class. Optical flow features are extracted by feeding 5 consecutive past frames of horizontal and vertical flow, forming a tensor with 10 channels, to a TSN model trained for action recognition.\n\n\nImplementation details\n\nArchitecture details. For our AFFT model we use the marked default hyper parameters from Table 2. For EGTEA Gaze+, we reduce the number of layers of the fuser and the future predictor to 2, since EGTEA Gaze+ is relatively small compared to EpicKitchens-100. We employ a linear projection layer for modality features that are not in alignment with the hidden size of the fuser. To match the hidden dimension used in the future predictor, another linear layer is employed to project the fused modality features.\n\nTraining & testing. We sample all modality features at 1 fps, resulting in a sequence of feature vectors whose length corresponds to observation time \u03c4 o . Default observation time is 10s, the other observation lengths are analyzed in Section 5.3. We train our models with SGD+momentum using 10 \u22126 weight decay and 10 \u22123 learning rate for 50 epochs, with 20 epochs warmup [24] and 30 epochs of cosine annealed decay, following [20]. We use mixup data augmentation [51] with \u03b1 = 0.1. Default settings for dropout and the stochastic depth regularization technique [25] are listed in Table 2. Following standard practice [16,20,48], our model is optimized to predict the action label during training and marginalize the output probabilities to obtain the verb and noun predictions in testing.\n\n\nFusion strategy\n\nAct. \n\n\nResults\n\nIn Section 5.1 we ablate the proposed fusion architectures. Continuing with the best architecture, we find optimized hyper parameters in Section 5.2 and the optimal temporal context in Section 5.3. In Section 5.4 we analyze the contribution of individual modalities to the final model performance and in Section 5.5 our models are compared against state-of-the-art feature based action anticipation models on EpicKitchens-100 and EGTEA Gaze+. The models trained with RGB-TSN and RGB-Swin features are referred to AFFT-TSN and AFFT-Swin respectively.\n\n\nFusion strategies\n\nWe evaluate the fusion architectures presented in Section 3.2 against score fusion based methods and evaluate which of our strategies proves best for multi-modal fusion. Table 1 lists all methods. In our comparison we include Modality Attention (MATT) [16], a learned score fusion weighting method, but find it to be lacking in our setting. For score averaging and weighted averaging, we choose the same setting as [20], verifying their results. Combining temporal and modality attention as done with T-SA-Fuser performs worst in our feature fusion models, which we assume to be caused by the complexity of this process. CA-Fuser introduces an inductive bias by introducing a new modality with each consecutive block, splitting the process of attention into separate smaller problems instead of presenting all temporal and modality tokens at once. Our best approach SA-Fuser on the other hand is even simpler, since it splits the problem along time-steps and only attends over the modality tokens. Temporal attention is then performed in a completely separate step with the GPT-2 based future predictor. We believe this reduced complexity to be the mechanism which leads to optimal performance of our final model. For further experiments we use the SA-Fuser as our default fusion module.  \n\n\nArchitecture ablations\n\nIn Table 2, we ablate different hyper parameters of our architecture. The default parameters are marked with grey table cells, the best values are typed in boldface.\n\nProjection layer and common dimensionality. The dimension of all multi-modal input features must coincide. This could be achieved using a simple linear layer, a linear layer with ReLU activation function [27,23] or a gated linear projection [36,44], listed in Table 2a. We add an additional variant sparse linear, meaning a linear layer is only applied for features which have a different dimension than the desired common dimension and show that it outperforms other projection methods. In Table 2b, we examine how the projection dimension influences performance. We find a dimensionality of 1024 to be optimal, a higher dimension presumably decreases performance due to the increased number of parameters and overfitting effects.\n\nAttention heads and encoder blocks. We compare the impact of different head numbers of the encoder multi-head attention in Table 2c, the number of encoder blocks is analyzed in Table 2d, we find eight heads and six consecutive encoder blocks to be best.\n\nEffect of regularization. We ablate using either no dropout and no stochastic depth [25] (i.e. no regularization) or using stochastic depth with maximal layer dropping probability of 0.1. Results in Table 2e show that both dropout and stochastic depth regularization are very beneficial.\n\n\nImpact of temporal context.\n\nTo study the ability of modeling sequences of long-range temporal interactions, we train and test the model with different lengths of temporal context, i.e., observation time \u03c4 o . As seen in Figure 4, as more frames of context are incorporated, the performance improves for both, AFFT-TSN and To further explore how the temporal context is utilized, following [20], we extract temporal attentions from the last layer of the feature anticipation module for all samples in the validation set of EpicKitchens-100, average them over heads and visualize them in Figure 6. The anticipation module learns to attend to visual features in the recent past, showing that the nearest past frames provide crucial keys for predicting future actions. This aligns with previous work [29,42] which reflects the importance of the recent past in designing anticipation models. However, while the median attention values of more distant past frames are smaller (close to 0.1), the attention distribution is significantly scattered, indicating that the model can choose to attend to important actions not only from the recent past, but also from the entire observation time, as illustrated in an example in Figure 8 Close bag Close bag Open fridge Put bag Close fridge Figure 8: Qualitative results on EpicKitchens-100. The horizontal and vertical axes indicate the index of past frames as well as the modality. The closer the color is to yellow, the higher the attention score. A video frame is highlighted with a yellow box when the attention score of the frame is highly activated.\n\n\nModality contributions\n\nAs shown in Table 3a, visual modalities, especially RGB, have higher performances than audio, also observable in Figure 7. Benefiting from a larger model capacity and better representative ability, RGB features extracted with an Omnivore-pre-trained Swin-Transformer perform significantly better than TSN features. Results in Table 3b show that the anticipation performance keeps increasing when additional modalities are introduced for both kinds of RGB features. In particular, AFFT-TSN and AFFT-Swin have gains of 3.6% and 1.9% over their uni-modal RGB performances in Table 3a, respectively. Per-class top-5 accuracies, for individual modalities as well as for our fusion model (AFFT-TSN) trained on all four modalities, can be seen in Figure 7. The fusion model outperforms uni-modal models for most classes, often by a significant margin. Results of AFFT-Swin are shown in the supplementary material. To analyze the contribution of our extracted audio features, we conduct experiments with the visual modalities (RGB+Obj+Flow) only and compare them with models  trained on all four modalities, which results in an increase of 0.6% (AFFT-TSN) and 0.4% (AFFT-Swin) in mean top-5 action anticipation accuracy as seen in Table 3b. To further validate the benefit of audio, we compute a confusion matrix with the utilization of audio for the largest-15 action classes, following [28], which we list in the supplementary. To better understand how the fusion module models relative importance of different modalities, we visualize the learned modality attentions of AFFT-Swin in Figure 5. Specifically, we use attention rollout [1] to aggregate attention over heads and layers. As shown in the figure, RGB has gained the most attention, indicating the modality which contributes the most for the anticipation task (as seen in Table 3a) will be automatically utilized most by the fusion module, as would be expected. Figure 5 also shows that the attention distributions of all modalities spread widely, showing that the model learns to adjust the relative importance of individual modalities based on each sample.   [16], except for MeMViT which uses RGB only. Tem-pAgg and the ones marked with + additionally use interacting hand-object bounding boxes and audio, respectively.\n\n\nComparison to the state-of-the-art\n\nOur final models follow the default hyper parameters from Table 2. On EpicKitchens-100, AFFT-TSN and AFFT-Swin use observations of 18s and 16s respectively, while the default observation time (10s) is used for EGTEA Gaze+. For the comparisons, we distinguish between training with frozen backbones (i.e., training on frozen features) and training with fine-tuned backbones (marked with gray font). In all tables in this section, the main metrics used to rank methods for these datasets are highlighted.\n\nIn Table 4, we compare our method with state-of-the-art methods on EpicKitchens-100. The table is divided into two compartments according to the validation and test splits. On the validation split, our AFFT-TSN outperforms other fusion methods with a large margin (14.8 \u2192 16.4 = 1.6 \u2191) with the exact same features provided by [16]. With the addition of audio, the performance is further improved by 0.6%. AFFT-Swin + which uses Omnivore features outperforms the current state-of-the-art model MeMViT by 0.8% mean top-5 ratio action anticipation performance on the val split without the need to fine-tune the backbone network. Consistent with the results on validation split, our method also outperforms prior fusion methods on the test set of EpicKitchens-100. As shown in bottom compartment in Table 4, we get the largest gains on tail classes, for which  Table 5: Comparison to the state-of-the-art methods on EGTEA Gaze+ with \u03c4 a = 0.5s. Results marked with \u22c6 are averaged across the three official splits, while others are based on split 1 only. We use the same input modalities as RULSTM. More details on the used modalities of each method can be found in the supplementary material.\n\nour method proves particularly effective. Note that Table 4 lists peer-reviewed results, only. In our supplementary we also list results of the EpicKitchens-Challenge, which holds many non-peer-reviewed results, often created with model ensembling of various methods.\n\nNext we evaluate our method on EGTEA Gaze+, shown in Table 5. Following prior works [33,20], we set the anticipation time \u03c4 a to 0.5s. As some prior works report the results averaged across the three official splits, while others test on split 1 only, we evaluate our methods using both recipes. Using fixed features, AFFT-TSN outperforms prior works using both recipes, especially for class mean top-1.\n\n\nConclusion and Future Work\n\nThis work presents Anticipative Feature Fusion Transformer (AFFT), an attention based multi-modal feature fusion method for action anticipation. Extensive ablations demonstrate the improved performance of our approach compared to basic score fusion or other multi-modal fusion methods and in state-of-the-art comparisons AFFT outperforms existing approaches on EpicKitchens-100 and EGTEA Gaze+. Our method can easily be combined with various feature extractors and is extensible to new modalities without architectural changes. Given this extensibility we hope to provide a framework for multi-modal action anticipation for other researchers and aim to experiment on additional modalities like body poses and object hand interactions ourselves, in the future.\n\n\nSupplementary Material\n\nIn this supplementary, we provide additional experiments and evaluations which did not fit in the main paper.\n\n\nA. Temporal and modality contributions\n\nIn Section 5.3, Figure 6 displays temporal attention values for AFFT-Swin. In Figure S10 we show the same evaluation for the extracted TSN features.\n\nLikewise, Figure 5 displays distributions of attention values over modalities using RGB-Swin features which is completed by Figure S9 which displays the the same results for RGB-TSN features. Figure S13 shows per-class top-5 accuracy for the 30 action classes with most samples in the EpicKitchens-100 validation set, based on RGB-Swin Features. A similar chart is displayed in Figure 7 for TSN features. Note, that for such high frequent classes, performance is significantly higher than in the overall dataset. Still, our method does not only perform well for high frequent classes, but also shows significantly improved results for tail classes, as can be seen in Table 4.\n\n\nB. Confusion Matrix\n\nWe follow the work of Kazakos et al. [28] and evaluate the contribution of the audio modality, specifically.  Table 3b, especially for Swin-Features, an increase of performance on the diagonal can be noted. \n\n\nC. Qualitative Results\n\nWe plot additional visualization results of modality and temporal attentions in Figure S12. The model used to generate such plots corresponds to the AFFT-Swin in Table 4. Each subfigure contains sampled frames showing temporal action evolution and modality and temporal attention map visualizations below. The frame receiving the most temporal attention is highlighted with a yellow box. From this experiment, we find that the proposed method attends dynamically to the multi-modalities and different past time steps to predict the future action, which demonstrates that our method successfully leverages long-term dependencies using multi-modal information for key frame detection and action anticipation.  D. EpicKitchens-100 challenge Table S6 lists results from the EpicKitchens-100 action anticipation challenge. This table relates to the test results in Table 4. Entries to the challenge typically significantly surpass single-method performances, since it is common to ensemble differently trained models or results from different methods. We list this table separately, since its ensem-    Figure S11: Confusion matrix for the largest-15 action classes in the validation set of EpicKitchens-100, with audio (left), as well as the difference to the confusion matrix without audio (right). From top to bottom, results of AFFT-TSN and AFFT-Swin are shown. An increase (blue) in confidence along the diagonal, especially obvious in the upper right figure, demonstrates the benefit of audio modality for egocentric action anticipation.\n\nbled results can not be directly compared and did not undergo peer review.\n\n\nE. Details of used modalities on EGTEA Gaze+\n\nWhile a single RGB modality is used for I3D-Res50, FHOI [33] adopts intentional hand movement as a feature representation, and jointly models and predicts the egocentric hand motion, interaction hotspots and future action. On the other hand, RULSTM [16] and ImagineRNN [49] make use of multiple modalities, i.e., RGB and optical flow, to further improve the anticipation performance of the next action. We note that the modalities used in AVT are ambiguous. We follow RULSTM and ImagineRNN and use RGB and optical flow as the input modalities for our method.  Figure S12: Qualitative results on EpicKitchens-100. The horizontal and vertical axes indicate the index of the past frames and the modality as well as temporal attention scores, respectively. The closer the color is to yellow, the higher the attention score. We highlight a video frame with a yellow box when the attention score of the frame is highly activated.\n\nFigure 1 :\n1The action anticipation task aims to use the observed video segment of length \u03c4 o to anticipate a future action \u03c4 a seconds before it happens.\n\nFigure 2 :\n2Architecture of AFFT. The feature encoders are omitted, we directly list the feature vectorsx M . A fusion module combines the modality specific feature vectors. The feature anticipation module then predicts the features of the next time step, followed by a linear classifier. our experiments we assume T temporally sequential input observations x mj i , i \u2208 {1, . . . , T }, j \u2208 {1, . . . , M } which describe the observation time \u03c4 o for each of the M available modalities. The anticipated action is defined to be at time step T + 1 without observation and label y T +1 . Depending on the dataset, the preceding observations might additionally be labelled with y i . Since this work is aimed at feature based modality fusion, we assume fixed feature extractors f \u03a0 and define the individual extracted features a\u015d x and the collection of all T \u00d7 M features for an input sample asx M .\n\nFigure 3 :\n3The SA-Fuser on the left applies Transformer Encoder blocks at individual time steps while the T-SA-Fuser in the middle and the transformer decoder based CA-Fuser on the right perform fusion on the whole temporal sequence at once.\n\nFigure 4 :Figure 5 :Figure 6 :\n456Impact of temporal context on the validation set of EpicKitchens-100. Our method leverages long-term dependencies to improve anticipation performance. Modality attentions of AFFT-Swin on the validation set of EK-100. Our method learns to pay more attention to RGB without any supervision. Temporal attentions of AFFT-Swin over all samples of the validation set of EK-100. Our method attends not only to the recent past, but also to the entire past frames.AFFT-Swin. The gains are especially pronounced when trained using RGB-Swin features (16.5 \u2192 18.5 = 2.0 \u2191) vs. RGB-TSN features (15.7 \u2192 17.0 = 1.3 \u2191).\n\nFigure 7 :\n7. Here the model attends to an early time step in the middle of the observation which shows the opening of a fridge in order to predict the the future action 'close fridge'. Results for AFFT-TSN are listed in the supplementary. Per-class top-5 accuracy of fusion (AFFT-TSN) and single modalities for the largest 25 actions in the validation set of EpicKitchens-100. The classes are presented in the order of number of samples per class, from left to right. For most classes the fusion method provides significantly better results over the single modalities.\n\n\nFigure S11 shows the confusion matrices for the 15 most frequent action classes on the left and displays the difference to the confusion matrix without the audio modality on the right. While this Figure reflects the limited contributions of audio which are also visible in\n\nFigure S9 :\nS9Modality attentions of AFFT-TSN on the validation set of EpicKitchens-100. This figure is the counterpart toFigure 5, which describes the same evaluation on Swin RGB features.\n\nFigure S10 :\nS10Temporal attentions of AFFT-TSN over all samples of the validation set of EpicKitchens-100. This figure describes a similar pattern and validates the evaluation on Swin features in figure 6.\n\nor *\norEqual contribution 1 Code: https://github.com/zeyun-zhong/AFFT? \n\nvisual \n\nacoustic \n\nTurn on \ntap \n\nRinse \nglass \n\nPut glass \ninto rack \n\nRinse \nspatula \n\nTake \nspatula \n\nPast Frames \nAnticipation \nTime \n\nFuture \nAction \n\nObserved \nUnobserved \n\n\n\nTable 2 :\n2Fuser architecture ablation on the validation set of EpicKitchens-100. Default settings are marked in gray .\n\n\nMod. Backbone Act.(b) Results of multiple modalities combined with RGB.RGB TSN \n13.2 \nRGB Swin \n16.1 \nObj F. R-CNN 9.9 \nAU TSN \n5.3 \nFlow TSN \n7.5 \n\n(a) Results of individual \nmodalities. \n\nRGB \nTSN Swin \n\nOther \nAct. Act. \n\nObj \n15.9 16.7 \nAU \n15.4 16.8 \nFlow \n15.2 16.5 \nObj+Flow \n16.2 17.6 \nObj+AU+Flow 16.8 18.0 \n\n\n\nTable 3 :\n3Impact of individual modalities on the validation set of EpicKitchens-100. Compared to other modalities, RGB performs significantly better, particularly on features extracted by Swin. The proposed fusion method benefits from multi-modal inputs. The more modalities are provided, the better the anticipation model performs.\n\n\nVerb Noun Act. Verb Noun Act. Verb Noun Act. MeMViT [48] 32.2 37.0 17.7 28.6 27.4 15.2 25.3 31.0 15.5 RULSTM [16] 27.8 30.8 14.0 28.8 27.2 14.2 19.8 22.0 11.1 TempAgg [42] 23.2 31.4 14.7 28.0 26.2 14.5 14.5 22.5 11.8 AVT+-TSN [20] 25.5 31.8 14.8 25.5 23.6 11.5 18.5 25.8 12.6Method \n\nOverall \nUnseen Kitchen \nTail Classes \n\nVal \n\nchance \n6.4 2.0 0.2 14.4 2.9 0.5 1.6 0.2 0.1 \nAVT+ [20] \n28.2 32.0 15.9 29.5 23.9 11.9 21.1 25.8 14.1 \nOurs-TSN \n21.3 32.7 16.4 24.1 25.5 13.6 13.2 25.8 14.3 \nOurs-TSN + \n22.3 31.5 17.0 23.8 25.3 14.0 14.6 23.6 15.0 \nOurs-Swin \n23.4 33.7 17.6 24.5 25.4 15.2 15.6 26.5 15.3 \nOurs-Swin + \n22.8 34.6 18.5 24.8 26.4 15.5 15.0 27.7 16.2 \n\nTest \n\nchance \n6.2 2.3 0.1 8.1 3.3 0.3 1.9 0.7 0.0 \nAVT+ [20] \n25.6 28.8 12.6 20.9 22.3 8.8 19.0 22.0 10.1 \n\nRULSTM [16] 25.3 26.7 11.2 19.4 26.9 9.7 17.6 16.0 7.9 \nTempAgg [42] 21.8 30.6 12.6 17.9 27.0 10.5 13.6 20.6 8.9 \nTCN-TSN [50] 20.4 26.6 10.9 17.9 26.9 11.1 11.7 15.2 7.0 \nTCN-TBN [50] 21.5 26.8 11.0 20.8 28.3 12.2 13.2 15.4 7.2 \nOurs-TSN + \n19.4 28.3 13.4 14.0 24.2 9.9 12.0 19.5 10.9 \nOurs-Swin + \n20.7 31.8 14.9 16.2 27.7 12.1 13.4 23.8 11.8 \n\n\n\nTable 4 :\n4Comparison of state-of-the-art methods on the validation and test set of EpicKitchens-100. Our models set a new state of the art. The numbers in bold-face indicate the highest score. All methods use all modalities provided by\n\n\nVerb Noun Act. Verb Noun Act. Act. TSN (Ours) 53.4 50.4 42.5 42.4 44.5 35.2 72.47 \u22c6Method \nTop-1 \nClass mean @1 Top-5 \n\nI3D-Res50 [7] \n48.0 42.1 34.8 31.3 30.0 23.2 \n-\nFHOI [33] \n49.0 45.5 36.6 32.5 32.7 25.3 \n-\nAVT [20] \n54.9 52.2 43.0 49.9 48.3 35.2 \n-\n\nRULSTM [16] \n-\n-\n-\n-\n-\n-71.84 \u22c6 \nImagineRNN [49] \n-\n-\n-\n-\n-\n-72.32 \u22c6 \nAVT (TSN) [20] 51.7 50.3 39.8 41.2 41.4 28.3 \n-\nAFFT-\n\n\nVerb Noun Act. Verb Noun Act. Verb Noun Act. NVIDIA-UNIBZ 29.7 38.5 19.6 23.5 35.2 16.4 23.5 31.1 16.6 SCUT 37.9 41.7 20.4 27.9 37.1 18.3 32.4 36.1 17.1Method \nOverall \nUnseen Kitchen \nTail Classes \n\nAVT++ [20] \n26.7 32.3 16.7 21.0 27.6 12.9 19.3 24.0 13.8 \nallenxuuu \n29.9 30.4 17.4 25.1 26.1 14.1 24.6 23.7 14.3 \nPCO-PSNRD \n30.9 41.3 18.7 25.7 35.4 16.3 25.0 35.4 16.1 \nICL-SJTU \n42.0 35.7 19.5 33.4 26.8 15.9 41.0 33.2 16.9 \n\n\nTable S6 :\nS6Current leaders in the EpicKitchens-100 action anticipation challenge. The numbers in bold-face indicate the highest score.\n\n\nWash knifeTake spoon Wash spoon Take plate Scrub plate (b) Future action: take milk.Take glass Take coffee Throw packaging Insert coffe Take sugar (c) Future action: take sugar.Put pan Take Tomato Take tomato Turn on tap Wash tomato (d) Future action: wash tomato.RGB \nObj \nAU \nFlow \nTemporal \n\n0 \n4 \n8 \n12 \n16 \n\n(a) Future action: scrub plate. \n\nRGB \nObj \nAU \nFlow \nTemporal \n\n0 \n4 \n8 \n12 \n16 \n\nClose drawer Put cloth \nTake spoon Open fridge \nTake milk \n\n190 take milk \n\nRGB \nObj \nAU \nFlow \nTemporal \n\n0 \n4 \n8 \n12 \n16 \n\nRGB \nObj \nAU \nFlow \nTemporal \n\n0 \n4 \n8 \n12 \n16 \n\n\nAcknowledgements This work was supported by the JuBot project which was made possible by funding from the Carl-Zeiss-Foundation. This work was performed on the HoreKa supercomputer funded by the Ministry of Science, Research and the Arts Baden-W\u00fcrttemberg and by the Federal Ministry of Education and Research.\nQuantifying attention flow in transformers. Samira Abnar, Willem Zuidema, ACL. Samira Abnar and Willem Zuidema. Quantifying attention flow in transformers. In ACL, 2020.\n\nJoon Son Chung, and Andrew Zisserman. The conversation: Deep audio-visual speech enhancement. Triantafyllos Afouras, In Interspeech. Triantafyllos Afouras, Joon Son Chung, and Andrew Zisser- man. The conversation: Deep audio-visual speech enhance- ment. In Interspeech, 2018.\n\nLook, Listen and Learn. Relja Arandjelovi\u0107, Andrew Zisserman, ICCV. Relja Arandjelovi\u0107 and Andrew Zisserman. Look, Listen and Learn. In ICCV, 2017.\n\nObjects that sound. Relja Arandjelovic, Andrew Zisserman, ECCV. Relja Arandjelovic and Andrew Zisserman. Objects that sound. In ECCV, pages 435-451, 2018.\n\nSoundnet: Learning sound representations from unlabeled video. Yusuf Aytar, Carl Vondrick, Antonio Torralba, NeurIPS. 29Yusuf Aytar, Carl Vondrick, and Antonio Torralba. Sound- net: Learning sound representations from unlabeled video. In NeurIPS, volume 29, 2016.\n\n. E Floyd, Arlyne Bloom, Laura Lazerson, Hofstadter, Freeman300New YorkFloyd E Bloom, Arlyne Lazerson, Laura Hofstadter, et al. Brain, mind, and behavior, volume 300. Freeman New York, 1988.\n\nQuo Vadis. Joao Carreira, Andrew Zisserman, arXiv:1705.07750Action Recognition? A New Model and the Kinetics Dataset. In CVPR. Joao Carreira and Andrew Zisserman. Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset. In CVPR, number arXiv:1705.07750, 2017.\n\nScaling egocentric vision: The epic-kitchens dataset. Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, ECCV. Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, et al. Scaling egocentric vision: The epic-kitchens dataset. In ECCV, pages 720-736, 2018.\n\nThe epic-kitchens dataset: Collection, challenges and baselines. Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, TPAMI43Dima Damen, Hazel Doughty, Giovanni Maria Farinella, Sanja Fidler, Antonino Furnari, Evangelos Kazakos, Davide Moltisanti, Jonathan Munro, Toby Perrett, Will Price, et al. The epic-kitchens dataset: Collection, challenges and base- lines. TPAMI, 43(11):4125-4141, 2020.\n\nSylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, ICLR. 2021Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. In ICLR, 2021.\n\n. Ariel Ephrat, Inbar Mosseri, Oran Lang, Tali Dekel, Kevin Wilson, Avinatan Hassidim, William T Freeman,Ariel Ephrat, Inbar Mosseri, Oran Lang, Tali Dekel, Kevin Wilson, Avinatan Hassidim, William T Freeman, and\n\nLooking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation. Michael Rubinstein, SIGGRAPH. Michael Rubinstein. Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech sepa- ration. In SIGGRAPH, 2018.\n\nWhen will you do what? -Anticipating Temporal Occurrences of Activities. Alexander Yazan Abu Farha, Juergen Richard, Gall, CVPR. Yazan Abu Farha, Alexander Richard, and Juergen Gall. When will you do what? -Anticipating Temporal Occur- rences of Activities. In CVPR, 2018.\n\nSlowfast networks for video recognition. Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, Kaiming He, ICCV. Christoph Feichtenhofer, Haoqi Fan, Jitendra Malik, and Kaiming He. Slowfast networks for video recognition. In ICCV, pages 6202-6211, 2019.\n\nLeveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation. Antonino Furnari, Sebastiano Battiato, Giovanni Maria Farinella, In ECCVW. Antonino Furnari, Sebastiano Battiato, and Giovanni Maria Farinella. Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipa- tion. In ECCVW, 2018.\n\nNext-active-object prediction from egocentric videos. Antonino Furnari, Sebastiano Battiato, Kristen Grauman, Giovanni Maria Farinella, Journal of Visual Communication and Image Representation. 49Antonino Furnari, Sebastiano Battiato, Kristen Grauman, and Giovanni Maria Farinella. Next-active-object prediction from egocentric videos. Journal of Visual Communication and Image Representation, 49:401-411, 2017.\n\nWhat Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention. Antonino Furnari, Giovanni Farinella, ICCV. Antonino Furnari and Giovanni Farinella. What Would You Expect? Anticipating Egocentric Actions With Rolling- Unrolling LSTMs and Modality Attention. In ICCV, 2019.\n\nRED: Reinforced Encoder-Decoder Networks for Action Anticipation. Jiyang Gao, Zhenheng Yang, Ram Nevatia, BMVC. Jiyang Gao, Zhenheng Yang, and Ram Nevatia. RED: Rein- forced Encoder-Decoder Networks for Action Anticipation. In BMVC, 2017.\n\n2.5 d visual sound. Ruohan Gao, Kristen Grauman, CVPR. Ruohan Gao and Kristen Grauman. 2.5 d visual sound. In CVPR, pages 324-333, 2019.\n\nListen to look: Action recognition by previewing audio. Ruohan Gao, Tae-Hyun Oh, Kristen Grauman, Lorenzo Torresani, CVPR. Ruohan Gao, Tae-Hyun Oh, Kristen Grauman, and Lorenzo Torresani. Listen to look: Action recognition by previewing audio. In CVPR, 2020.\n\nAnticipative Video Transformer. Rohit Girdhar, Kristen Grauman, ICCV. 2021Rohit Girdhar and Kristen Grauman. Anticipative Video Transformer. In ICCV, 2021.\n\nActionvlad: Learning spatio-temporal aggregation for action classification. Rohit Girdhar, Deva Ramanan, Abhinav Gupta, Josef Sivic, Bryan Russell, CVPR. Rohit Girdhar, Deva Ramanan, Abhinav Gupta, Josef Sivic, and Bryan Russell. Actionvlad: Learning spatio-temporal aggregation for action classification. In CVPR, pages 971- 980, 2017.\n\nOmnivore: A Single Model for Many Visual Modalities. Rohit Girdhar, Mannat Singh, Nikhila Ravi, Laurens Van Der Maaten, Armand Joulin, Ishan Misra, CVPR. 2022Rohit Girdhar, Mannat Singh, Nikhila Ravi, Laurens van der Maaten, Armand Joulin, and Ishan Misra. Omnivore: A Sin- gle Model for Many Visual Modalities. In CVPR, 2022.\n\nFuture Transformer for Long-term Action Anticipation. Dayoung Gong, Joonseok Lee, Manjin Kim, Seong Jong Ha, Minsu Cho, CVPR. 2022Dayoung Gong, Joonseok Lee, Manjin Kim, Seong Jong Ha, and Minsu Cho. Future Transformer for Long-term Action Anticipation. In CVPR, 2022.\n\nPriya Goyal, Piotr Doll\u00e1r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, arXiv:1706.02677Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprintPriya Goyal, Piotr Doll\u00e1r, Ross Girshick, Pieter Noord- huis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large mini- batch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.\n\nDeep networks with stochastic depth. Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Q Weinberger, ECCV. Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Q Weinberger. Deep networks with stochastic depth. In ECCV, pages 646-661, 2016.\n\nMultimodal transformer fusion for continuous emotion recognition. Jian Huang, Jianhua Tao, Bin Liu, Zheng Lian, Mingyue Niu, ICASSP. Jian Huang, Jianhua Tao, Bin Liu, Zheng Lian, and Mingyue Niu. Multimodal transformer fusion for continuous emotion recognition. In ICASSP, pages 3507-3511, 2020.\n\nWith a Little Help from my Temporal Context: Multimodal Egocentric Action Recognition. Evangelos Kazakos, Jaesung Huh, Arsha Nagrani, Andrew Zisserman, Dima Damen, BMVC. 2021Evangelos Kazakos, Jaesung Huh, Arsha Nagrani, Andrew Zisserman, and Dima Damen. With a Little Help from my Temporal Context: Multimodal Egocentric Action Recogni- tion. In BMVC, 2021.\n\nEPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition. Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, Dima Damen, ICCV. Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, and Dima Damen. EPIC-Fusion: Audio-Visual Temporal Bind- ing for Egocentric Action Recognition. In ICCV, 2019.\n\nTime-Conditioned Action Anticipation in One Shot. Qiuhong Ke, Mario Fritz, Bernt Schiele, CVPR. Qiuhong Ke, Mario Fritz, and Bernt Schiele. Time- Conditioned Action Anticipation in One Shot. In CVPR, June 2019.\n\nCooperative Learning of Audio and Video Models from Self-Supervised Synchronization. Bruno Korbar, Du Tran, Lorenzo Torresani, In NeurIPS. Bruno Korbar, Du Tran, and Lorenzo Torresani. Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization. In NeurIPS, 2018.\n\nSCSampler: Sampling Salient Clips From Video for Efficient Action Recognition. Bruno Korbar, Du Tran, Lorenzo Torresani, ICCV. Bruno Korbar, Du Tran, and Lorenzo Torresani. SCSam- pler: Sampling Salient Clips From Video for Efficient Action Recognition. In ICCV, 2019.\n\nIn the eye of beholder: Joint learning of gaze and actions in first person video. Yin Li, Miao Liu, James M Rehg, ECCV. Yin Li, Miao Liu, and James M Rehg. In the eye of beholder: Joint learning of gaze and actions in first person video. In ECCV, pages 619-635, 2018.\n\nForecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video. Miao Liu, Siyu Tang, Yin Li, James M Rehg, Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm2020Miao Liu, Siyu Tang, Yin Li, and James M. Rehg. Fore- casting Human-Object Interaction: Joint Prediction of Mo- tor Attention and Actions in First Person Video. In An- drea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors, ECCV, 2020.\n\nSwin transformer: Hierarchical vision transformer using shifted windows. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, Baining Guo, CVPR. Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In CVPR, pages 10012-10022, 2021.\n\nVideo swin transformer. Ze Liu, Jia Ning, Yue Cao, Yixuan Wei, Zheng Zhang, Stephen Lin, Han Hu, CVPR. Ze Liu, Jia Ning, Yue Cao, Yixuan Wei, Zheng Zhang, Stephen Lin, and Han Hu. Video swin transformer. In CVPR, pages 3202-3211, 2022.\n\nLearnable pooling with Context Gating for video classification. Antoine Miech, Ivan Laptev, Josef Sivic, CVPR Workshop. Antoine Miech, Ivan Laptev, and Josef Sivic. Learnable pooling with Context Gating for video classification. In CVPR Workshop, 2017.\n\nAttention Bottlenecks for Multimodal Fusion. Arsha Nagrani, Shan Yang, Anurag Arnab, Aren Jansen, Cordelia Schmid, Chen Sun, NeurIPS. 2021Arsha Nagrani, Shan Yang, Anurag Arnab, Aren Jansen, Cordelia Schmid, and Chen Sun. Attention Bottlenecks for Multimodal Fusion. In NeurIPS, 2021.\n\nAudio-Visual Scene Analysis with Self-Supervised Multisensory Features. Andrew Owens, Alexei A Efros, Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair WeissAndrew Owens and Alexei A. Efros. Audio-Visual Scene Analysis with Self-Supervised Multisensory Features. In Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, and Yair Weiss, editors, ECCV, 2018.\n\nVisually indicated sounds. Andrew Owens, Phillip Isola, Josh Mcdermott, Antonio Torralba, William T Edward H Adelson, Freeman, CVPR. Andrew Owens, Phillip Isola, Josh McDermott, Antonio Tor- ralba, Edward H Adelson, and William T Freeman. Visually indicated sounds. In CVPR, pages 2405-2413, 2016.\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 189Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsu- pervised multitask learners. OpenAI blog, 1(8):9, 2019.\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. Kaiming Shaoqing Ren, Ross He, Jian Girshick, Sun, NeurIPS. 28Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In NeurIPS, volume 28, 2015.\n\nTemporal Aggregate Representations for Long-Range Video Understanding. Fadime Sener, Dipika Singhania, Angela Yao, ECCV. Fadime Sener, Dipika Singhania, and Angela Yao. Tempo- ral Aggregate Representations for Long-Range Video Under- standing. In ECCV, 2020.\n\nMing-Hsuan Yang, and In So Kweon. Learning to localize sound sources in visual scenes: Analysis and applications. Arda Senocak, Tae-Hyun Oh, Junsik Kim, TPAMI. 435Arda Senocak, Tae-Hyun Oh, Junsik Kim, Ming-Hsuan Yang, and In So Kweon. Learning to localize sound sources in visual scenes: Analysis and applications. TPAMI, 43(5):1605-1619, 2019.\n\nEverything at Once -Multi-Modal Fusion Transformer for Video Retrieval. Nina Shvetsova, Brian Chen, Andrew Rouditchenko, Samuel Thomas, Brian Kingsbury, S Rogerio, David Feris, James Harwath, Hilde Glass, Kuehne, CVPR. 2022Nina Shvetsova, Brian Chen, Andrew Rouditchenko, Samuel Thomas, Brian Kingsbury, Rogerio S Feris, David Harwath, James Glass, and Hilde Kuehne. Everything at Once -Multi- Modal Fusion Transformer for Video Retrieval. In CVPR, 2022.\n\nPredictive coding and multisensory integration: an attentional account of the multisensory mind. Frontiers in Integrative Neuroscience. Durk Talsma, 919Durk Talsma. Predictive coding and multisensory integra- tion: an attentional account of the multisensory mind. Fron- tiers in Integrative Neuroscience, 9:19, 2015.\n\nAttention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, NeurIPS. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko- reit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is All you Need. In NeurIPS, 2017.\n\nTemporal Segment Networks: Towards Good Practices for Deep Action Recognition. Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, Luc Van Gool, ECCV. Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, and Luc Van Gool. Temporal Segment Networks: Towards Good Practices for Deep Action Recog- nition. In ECCV, 2016.\n\nMeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition. Chao-Yuan, Yanghao Wu, Karttikeya Li, Haoqi Mangalam, Bo Fan, Jitendra Xiong, Christoph Malik, Feichtenhofer, CVPR. 2022Chao-Yuan Wu, Yanghao Li, Karttikeya Mangalam, Haoqi Fan, Bo Xiong, Jitendra Malik, and Christoph Feichten- hofer. MeMViT: Memory-Augmented Multiscale Vision Transformer for Efficient Long-Term Video Recognition. In CVPR, 2022.\n\nLearning to Anticipate Egocentric Actions by Imagination. Yu Wu, Linchao Zhu, Xiaohan Wang, Yi Yang, Fei Wu, TIP. Yu Wu, Linchao Zhu, Xiaohan Wang, Yi Yang, and Fei Wu. Learning to Anticipate Egocentric Actions by Imagination. TIP, 2021.\n\nMulti-Modal Temporal Convolutional Network for Anticipating Actions in Egocentric Videos. Olga Zatsarynna, Yazan Abu Farha, Juergen Gall, CVPR Workshop. Olga Zatsarynna, Yazan Abu Farha, and Juergen Gall. Multi- Modal Temporal Convolutional Network for Anticipating Actions in Egocentric Videos. In CVPR Workshop, 2021.\n\nmixup: Beyond empirical risk minimization. Hongyi Zhang, Moustapha Cisse, David Yann N Dauphin, Lopez-Paz, In ICLR. Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimiza- tion. In ICLR, 2018.\n\nVisual to sound: Generating natural sound for videos in the wild. Yipin Zhou, Zhaowen Wang, Chen Fang, Trung Bui, Tamara L Berg, CVPR. Yipin Zhou, Zhaowen Wang, Chen Fang, Trung Bui, and Tamara L Berg. Visual to sound: Generating natural sound for videos in the wild. In CVPR, pages 3550-3558, 2018.\n", "annotations": {"author": "[{\"end\":160,\"start\":79},{\"end\":219,\"start\":161},{\"end\":260,\"start\":220},{\"end\":323,\"start\":261},{\"end\":408,\"start\":324}]", "publisher": null, "author_last_name": "[{\"end\":90,\"start\":85},{\"end\":176,\"start\":167},{\"end\":232,\"start\":228},{\"end\":280,\"start\":268},{\"end\":338,\"start\":331}]", "author_first_name": "[{\"end\":84,\"start\":79},{\"end\":166,\"start\":161},{\"end\":227,\"start\":220},{\"end\":267,\"start\":261},{\"end\":330,\"start\":324}]", "author_affiliation": "[{\"end\":117,\"start\":92},{\"end\":159,\"start\":119},{\"end\":218,\"start\":178},{\"end\":259,\"start\":234},{\"end\":322,\"start\":282},{\"end\":365,\"start\":340},{\"end\":407,\"start\":367}]", "title": "[{\"end\":76,\"start\":1},{\"end\":484,\"start\":409}]", "venue": null, "abstract": "[{\"end\":1300,\"start\":486}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":1816,\"start\":1812},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":1819,\"start\":1816},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":1893,\"start\":1889},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":1896,\"start\":1893},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":1899,\"start\":1896},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":1975,\"start\":1971},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":1978,\"start\":1975},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":1994,\"start\":1990},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2014,\"start\":2010},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2097,\"start\":2093},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2100,\"start\":2097},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2103,\"start\":2100},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":2183,\"start\":2179},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2185,\"start\":2183},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2188,\"start\":2185},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2232,\"start\":2228},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2281,\"start\":2277},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2284,\"start\":2281},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2287,\"start\":2284},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":2469,\"start\":2465},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2471,\"start\":2469},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2687,\"start\":2683},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2715,\"start\":2711},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2795,\"start\":2791},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3106,\"start\":3103},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3109,\"start\":3106},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3849,\"start\":3845},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4928,\"start\":4924},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4931,\"start\":4928},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4934,\"start\":4931},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4937,\"start\":4934},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5079,\"start\":5076},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5081,\"start\":5079},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5084,\"start\":5081},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5141,\"start\":5137},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5231,\"start\":5227},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5572,\"start\":5568},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5607,\"start\":5603},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5717,\"start\":5713},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5932,\"start\":5928},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5935,\"start\":5932},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5938,\"start\":5935},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":5941,\"start\":5938},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5944,\"start\":5941},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":6121,\"start\":6117},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6123,\"start\":6121},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6126,\"start\":6123},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":6358,\"start\":6354},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":6361,\"start\":6358},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6388,\"start\":6384},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6432,\"start\":6428},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":6580,\"start\":6576},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6723,\"start\":6720},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":6726,\"start\":6723},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":6790,\"start\":6786},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6890,\"start\":6886},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7204,\"start\":7201},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7206,\"start\":7204},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7209,\"start\":7206},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":7246,\"start\":7242},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7248,\"start\":7246},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7251,\"start\":7248},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7290,\"start\":7287},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7293,\"start\":7290},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7328,\"start\":7324},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":7331,\"start\":7328},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7334,\"start\":7331},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7390,\"start\":7386},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7393,\"start\":7390},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7479,\"start\":7475},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7482,\"start\":7479},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7485,\"start\":7482},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8153,\"start\":8149},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8191,\"start\":8187},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8362,\"start\":8359},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8364,\"start\":8362},{\"end\":14265,\"start\":14262},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21058,\"start\":21054},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21471,\"start\":21467},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":22662,\"start\":22658},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":22925,\"start\":22921},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":23531,\"start\":23527},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23631,\"start\":23627},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":24102,\"start\":24098},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":46161,\"start\":46157},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":46214,\"start\":46210},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":46349,\"start\":46345},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":46569,\"start\":46565},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":46851,\"start\":46848},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":46872,\"start\":46868},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":47507,\"start\":47503},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":48089,\"start\":48085},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":48106,\"start\":48102},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":48132,\"start\":48128},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":48180,\"start\":48176},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":48537,\"start\":48533},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":48865,\"start\":48861},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":49284,\"start\":49280},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":49414,\"start\":49410},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":50539,\"start\":50535},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":50594,\"start\":50590},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":50631,\"start\":50627},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":50729,\"start\":50725},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":50785,\"start\":50781},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":50788,\"start\":50785},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":50791,\"start\":50788},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":51816,\"start\":51812},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":51979,\"start\":51975},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":53251,\"start\":53247},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":53254,\"start\":53251},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":53288,\"start\":53284},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":53291,\"start\":53288},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":54119,\"start\":54115},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":54715,\"start\":54711},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":55122,\"start\":55118},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":55125,\"start\":55122},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":57325,\"start\":57321},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":57571,\"start\":57568},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":58059,\"start\":58055},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":59090,\"start\":59086},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":60307,\"start\":60303},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":60310,\"start\":60307},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":62481,\"start\":62477},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":64397,\"start\":64393},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":64590,\"start\":64586},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":64610,\"start\":64606}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":65416,\"start\":65261},{\"attributes\":{\"id\":\"fig_3\"},\"end\":66315,\"start\":65417},{\"attributes\":{\"id\":\"fig_8\"},\"end\":66559,\"start\":66316},{\"attributes\":{\"id\":\"fig_9\"},\"end\":67199,\"start\":66560},{\"attributes\":{\"id\":\"fig_10\"},\"end\":67770,\"start\":67200},{\"attributes\":{\"id\":\"fig_11\"},\"end\":68045,\"start\":67771},{\"attributes\":{\"id\":\"fig_12\"},\"end\":68236,\"start\":68046},{\"attributes\":{\"id\":\"fig_13\"},\"end\":68444,\"start\":68237},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":68699,\"start\":68445},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":68820,\"start\":68700},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":69141,\"start\":68821},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":69476,\"start\":69142},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":70599,\"start\":69477},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":70837,\"start\":70600},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":71219,\"start\":70838},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":71650,\"start\":71220},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":71788,\"start\":71651},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":72361,\"start\":71789}]", "paragraph": "[{\"end\":3994,\"start\":1316},{\"end\":4035,\"start\":3996},{\"end\":4336,\"start\":4037},{\"end\":4497,\"start\":4338},{\"end\":4701,\"start\":4499},{\"end\":5782,\"start\":4718},{\"end\":7061,\"start\":5784},{\"end\":7619,\"start\":7063},{\"end\":8279,\"start\":7635},{\"end\":8892,\"start\":8301},{\"end\":10005,\"start\":8910},{\"end\":11077,\"start\":10264},{\"end\":12195,\"start\":11214},{\"end\":13263,\"start\":12412},{\"end\":20541,\"start\":13750},{\"end\":21753,\"start\":20887},{\"end\":22531,\"start\":21755},{\"end\":23392,\"start\":22533},{\"end\":24018,\"start\":23436},{\"end\":24623,\"start\":24057},{\"end\":46722,\"start\":45835},{\"end\":47467,\"start\":46747},{\"end\":47988,\"start\":47469},{\"end\":48514,\"start\":48011},{\"end\":49187,\"start\":48516},{\"end\":49625,\"start\":49189},{\"end\":50161,\"start\":49652},{\"end\":50952,\"start\":50163},{\"end\":50977,\"start\":50972},{\"end\":51538,\"start\":50989},{\"end\":52849,\"start\":51560},{\"end\":53041,\"start\":52876},{\"end\":53774,\"start\":53043},{\"end\":54029,\"start\":53776},{\"end\":54318,\"start\":54031},{\"end\":55914,\"start\":54350},{\"end\":58216,\"start\":55941},{\"end\":58757,\"start\":58255},{\"end\":59948,\"start\":58759},{\"end\":60217,\"start\":59950},{\"end\":60622,\"start\":60219},{\"end\":61412,\"start\":60653},{\"end\":61548,\"start\":61439},{\"end\":61739,\"start\":61591},{\"end\":62416,\"start\":61741},{\"end\":62647,\"start\":62440},{\"end\":64212,\"start\":62674},{\"end\":64288,\"start\":64214},{\"end\":65260,\"start\":64337}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10263,\"start\":10006},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11213,\"start\":11078},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12411,\"start\":12196},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13749,\"start\":13264},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20865,\"start\":20542},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24039,\"start\":24019},{\"attributes\":{\"id\":\"formula_6\"},\"end\":28765,\"start\":24624},{\"attributes\":{\"id\":\"formula_7\"},\"end\":35002,\"start\":28765},{\"attributes\":{\"id\":\"formula_8\"},\"end\":35531,\"start\":35002},{\"attributes\":{\"id\":\"formula_9\"},\"end\":38585,\"start\":38571}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":49748,\"start\":49741},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":50751,\"start\":50744},{\"end\":51737,\"start\":51730},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":52886,\"start\":52879},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":53311,\"start\":53303},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":53542,\"start\":53534},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":53907,\"start\":53899},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":53961,\"start\":53953},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":54238,\"start\":54230},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":55961,\"start\":55953},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":56275,\"start\":56267},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":56521,\"start\":56513},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":57172,\"start\":57164},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":58320,\"start\":58313},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":58769,\"start\":58762},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":59562,\"start\":59555},{\"end\":59624,\"start\":59617},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":60009,\"start\":60002},{\"end\":60279,\"start\":60272},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":62415,\"start\":62408},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":62558,\"start\":62550},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":62843,\"start\":62836},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":63420,\"start\":63412},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":63541,\"start\":63534}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1314,\"start\":1302},{\"attributes\":{\"n\":\"2.\"},\"end\":4716,\"start\":4704},{\"attributes\":{\"n\":\"3.\"},\"end\":7633,\"start\":7622},{\"attributes\":{\"n\":\"3.1.\"},\"end\":8299,\"start\":8282},{\"end\":8908,\"start\":8895},{\"attributes\":{\"n\":\"3.2.\"},\"end\":20885,\"start\":20867},{\"attributes\":{\"n\":\"3.3.\"},\"end\":23434,\"start\":23395},{\"attributes\":{\"n\":\"3.4.\"},\"end\":24055,\"start\":24041},{\"end\":36465,\"start\":35533},{\"end\":38570,\"start\":36468},{\"end\":40683,\"start\":38587},{\"end\":41749,\"start\":40686},{\"end\":42800,\"start\":41752},{\"end\":45812,\"start\":42803},{\"attributes\":{\"n\":\"4.\"},\"end\":45833,\"start\":45815},{\"attributes\":{\"n\":\"4.1.\"},\"end\":46745,\"start\":46725},{\"attributes\":{\"n\":\"4.2.\"},\"end\":48009,\"start\":47991},{\"attributes\":{\"n\":\"4.3.\"},\"end\":49650,\"start\":49628},{\"end\":50970,\"start\":50955},{\"attributes\":{\"n\":\"5.\"},\"end\":50987,\"start\":50980},{\"attributes\":{\"n\":\"5.1.\"},\"end\":51558,\"start\":51541},{\"attributes\":{\"n\":\"5.2.\"},\"end\":52874,\"start\":52852},{\"attributes\":{\"n\":\"5.3.\"},\"end\":54348,\"start\":54321},{\"attributes\":{\"n\":\"5.4.\"},\"end\":55939,\"start\":55917},{\"attributes\":{\"n\":\"5.5.\"},\"end\":58253,\"start\":58219},{\"attributes\":{\"n\":\"6.\"},\"end\":60651,\"start\":60625},{\"end\":61437,\"start\":61415},{\"end\":61589,\"start\":61551},{\"end\":62438,\"start\":62419},{\"end\":62672,\"start\":62650},{\"end\":64335,\"start\":64291},{\"end\":65272,\"start\":65262},{\"end\":65428,\"start\":65418},{\"end\":66327,\"start\":66317},{\"end\":66591,\"start\":66561},{\"end\":67211,\"start\":67201},{\"end\":68058,\"start\":68047},{\"end\":68250,\"start\":68238},{\"end\":68450,\"start\":68446},{\"end\":68710,\"start\":68701},{\"end\":69152,\"start\":69143},{\"end\":70610,\"start\":70601},{\"end\":71662,\"start\":71652}]", "table": "[{\"end\":68699,\"start\":68515},{\"end\":69141,\"start\":68894},{\"end\":70599,\"start\":69754},{\"end\":71219,\"start\":70923},{\"end\":71650,\"start\":71374},{\"end\":72361,\"start\":72055}]", "figure_caption": "[{\"end\":65416,\"start\":65274},{\"end\":66315,\"start\":65430},{\"end\":66559,\"start\":66329},{\"end\":67199,\"start\":66595},{\"end\":67770,\"start\":67213},{\"end\":68045,\"start\":67773},{\"end\":68236,\"start\":68061},{\"end\":68444,\"start\":68254},{\"end\":68515,\"start\":68453},{\"end\":68820,\"start\":68712},{\"end\":68894,\"start\":68823},{\"end\":69476,\"start\":69154},{\"end\":69754,\"start\":69479},{\"end\":70837,\"start\":70612},{\"end\":70923,\"start\":70840},{\"end\":71374,\"start\":71222},{\"end\":71788,\"start\":71665},{\"end\":72055,\"start\":71791}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":1411,\"start\":1403},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":7682,\"start\":7674},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8392,\"start\":8384},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":21152,\"start\":21144},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":22641,\"start\":22633},{\"end\":54550,\"start\":54542},{\"end\":54916,\"start\":54908},{\"end\":55545,\"start\":55537},{\"end\":55607,\"start\":55599},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":56062,\"start\":56054},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":56689,\"start\":56681},{\"end\":57527,\"start\":57519},{\"end\":57864,\"start\":57856},{\"end\":61615,\"start\":61607},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":61679,\"start\":61669},{\"end\":61759,\"start\":61751},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":61874,\"start\":61865},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":61943,\"start\":61933},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":62127,\"start\":62119},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":62764,\"start\":62754},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":63782,\"start\":63772},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":64907,\"start\":64897}]", "bib_author_first_name": "[{\"end\":72723,\"start\":72717},{\"end\":72737,\"start\":72731},{\"end\":72951,\"start\":72938},{\"end\":73150,\"start\":73145},{\"end\":73171,\"start\":73165},{\"end\":73295,\"start\":73290},{\"end\":73316,\"start\":73310},{\"end\":73494,\"start\":73489},{\"end\":73506,\"start\":73502},{\"end\":73524,\"start\":73517},{\"end\":73694,\"start\":73693},{\"end\":73708,\"start\":73702},{\"end\":73721,\"start\":73716},{\"end\":73898,\"start\":73894},{\"end\":73915,\"start\":73909},{\"end\":74214,\"start\":74210},{\"end\":74227,\"start\":74222},{\"end\":74245,\"start\":74237},{\"end\":74251,\"start\":74246},{\"end\":74268,\"start\":74263},{\"end\":74285,\"start\":74277},{\"end\":74304,\"start\":74295},{\"end\":74320,\"start\":74314},{\"end\":74341,\"start\":74333},{\"end\":74353,\"start\":74349},{\"end\":74367,\"start\":74363},{\"end\":74707,\"start\":74703},{\"end\":74720,\"start\":74715},{\"end\":74738,\"start\":74730},{\"end\":74744,\"start\":74739},{\"end\":74761,\"start\":74756},{\"end\":74778,\"start\":74770},{\"end\":74797,\"start\":74788},{\"end\":74813,\"start\":74807},{\"end\":74834,\"start\":74826},{\"end\":74846,\"start\":74842},{\"end\":74860,\"start\":74856},{\"end\":75278,\"start\":75272},{\"end\":75297,\"start\":75292},{\"end\":75314,\"start\":75305},{\"end\":75331,\"start\":75327},{\"end\":75352,\"start\":75345},{\"end\":75365,\"start\":75359},{\"end\":75386,\"start\":75379},{\"end\":75405,\"start\":75397},{\"end\":75421,\"start\":75416},{\"end\":75751,\"start\":75746},{\"end\":75765,\"start\":75760},{\"end\":75779,\"start\":75775},{\"end\":75790,\"start\":75786},{\"end\":75803,\"start\":75798},{\"end\":76070,\"start\":76063},{\"end\":76322,\"start\":76313},{\"end\":76347,\"start\":76340},{\"end\":76564,\"start\":76555},{\"end\":76585,\"start\":76580},{\"end\":76599,\"start\":76591},{\"end\":76614,\"start\":76607},{\"end\":76884,\"start\":76876},{\"end\":76904,\"start\":76894},{\"end\":76923,\"start\":76915},{\"end\":76929,\"start\":76924},{\"end\":77210,\"start\":77202},{\"end\":77230,\"start\":77220},{\"end\":77248,\"start\":77241},{\"end\":77266,\"start\":77258},{\"end\":77272,\"start\":77267},{\"end\":77677,\"start\":77669},{\"end\":77695,\"start\":77687},{\"end\":77951,\"start\":77945},{\"end\":77965,\"start\":77957},{\"end\":77975,\"start\":77972},{\"end\":78145,\"start\":78139},{\"end\":78158,\"start\":78151},{\"end\":78319,\"start\":78313},{\"end\":78333,\"start\":78325},{\"end\":78345,\"start\":78338},{\"end\":78362,\"start\":78355},{\"end\":78554,\"start\":78549},{\"end\":78571,\"start\":78564},{\"end\":78755,\"start\":78750},{\"end\":78769,\"start\":78765},{\"end\":78786,\"start\":78779},{\"end\":78799,\"start\":78794},{\"end\":78812,\"start\":78807},{\"end\":79070,\"start\":79065},{\"end\":79086,\"start\":79080},{\"end\":79101,\"start\":79094},{\"end\":79115,\"start\":79108},{\"end\":79138,\"start\":79132},{\"end\":79152,\"start\":79147},{\"end\":79401,\"start\":79394},{\"end\":79416,\"start\":79408},{\"end\":79428,\"start\":79422},{\"end\":79444,\"start\":79434},{\"end\":79454,\"start\":79449},{\"end\":79615,\"start\":79610},{\"end\":79628,\"start\":79623},{\"end\":79641,\"start\":79637},{\"end\":79658,\"start\":79652},{\"end\":79676,\"start\":79670},{\"end\":79693,\"start\":79689},{\"end\":79708,\"start\":79702},{\"end\":80120,\"start\":80117},{\"end\":80130,\"start\":80128},{\"end\":80142,\"start\":80136},{\"end\":80154,\"start\":80148},{\"end\":80170,\"start\":80162},{\"end\":80397,\"start\":80393},{\"end\":80412,\"start\":80405},{\"end\":80421,\"start\":80418},{\"end\":80432,\"start\":80427},{\"end\":80446,\"start\":80439},{\"end\":80720,\"start\":80711},{\"end\":80737,\"start\":80730},{\"end\":80748,\"start\":80743},{\"end\":80764,\"start\":80758},{\"end\":80780,\"start\":80776},{\"end\":81071,\"start\":81062},{\"end\":81086,\"start\":81081},{\"end\":81102,\"start\":81096},{\"end\":81118,\"start\":81114},{\"end\":81353,\"start\":81346},{\"end\":81363,\"start\":81358},{\"end\":81376,\"start\":81371},{\"end\":81598,\"start\":81593},{\"end\":81609,\"start\":81607},{\"end\":81623,\"start\":81616},{\"end\":81881,\"start\":81876},{\"end\":81892,\"start\":81890},{\"end\":81906,\"start\":81899},{\"end\":82152,\"start\":82149},{\"end\":82161,\"start\":82157},{\"end\":82172,\"start\":82167},{\"end\":82174,\"start\":82173},{\"end\":82449,\"start\":82445},{\"end\":82459,\"start\":82455},{\"end\":82469,\"start\":82466},{\"end\":82479,\"start\":82474},{\"end\":82481,\"start\":82480},{\"end\":82887,\"start\":82885},{\"end\":82899,\"start\":82893},{\"end\":82908,\"start\":82905},{\"end\":82917,\"start\":82914},{\"end\":82928,\"start\":82922},{\"end\":82939,\"start\":82934},{\"end\":82954,\"start\":82947},{\"end\":82967,\"start\":82960},{\"end\":83205,\"start\":83203},{\"end\":83214,\"start\":83211},{\"end\":83224,\"start\":83221},{\"end\":83236,\"start\":83230},{\"end\":83247,\"start\":83242},{\"end\":83262,\"start\":83255},{\"end\":83271,\"start\":83268},{\"end\":83487,\"start\":83480},{\"end\":83499,\"start\":83495},{\"end\":83513,\"start\":83508},{\"end\":83720,\"start\":83715},{\"end\":83734,\"start\":83730},{\"end\":83747,\"start\":83741},{\"end\":83759,\"start\":83755},{\"end\":83776,\"start\":83768},{\"end\":83789,\"start\":83785},{\"end\":84034,\"start\":84028},{\"end\":84048,\"start\":84042},{\"end\":84050,\"start\":84049},{\"end\":84366,\"start\":84360},{\"end\":84381,\"start\":84374},{\"end\":84393,\"start\":84389},{\"end\":84412,\"start\":84405},{\"end\":84432,\"start\":84423},{\"end\":84689,\"start\":84685},{\"end\":84706,\"start\":84699},{\"end\":84716,\"start\":84711},{\"end\":84729,\"start\":84724},{\"end\":84741,\"start\":84736},{\"end\":84754,\"start\":84750},{\"end\":85040,\"start\":85033},{\"end\":85059,\"start\":85055},{\"end\":85068,\"start\":85064},{\"end\":85337,\"start\":85331},{\"end\":85351,\"start\":85345},{\"end\":85369,\"start\":85363},{\"end\":85638,\"start\":85634},{\"end\":85656,\"start\":85648},{\"end\":85667,\"start\":85661},{\"end\":85943,\"start\":85939},{\"end\":85960,\"start\":85955},{\"end\":85973,\"start\":85967},{\"end\":85994,\"start\":85988},{\"end\":86008,\"start\":86003},{\"end\":86021,\"start\":86020},{\"end\":86036,\"start\":86031},{\"end\":86049,\"start\":86044},{\"end\":86064,\"start\":86059},{\"end\":86463,\"start\":86459},{\"end\":86674,\"start\":86668},{\"end\":86688,\"start\":86684},{\"end\":86702,\"start\":86698},{\"end\":86716,\"start\":86711},{\"end\":86733,\"start\":86728},{\"end\":86746,\"start\":86741},{\"end\":86748,\"start\":86747},{\"end\":86762,\"start\":86756},{\"end\":86776,\"start\":86771},{\"end\":87055,\"start\":87050},{\"end\":87069,\"start\":87062},{\"end\":87080,\"start\":87077},{\"end\":87089,\"start\":87087},{\"end\":87101,\"start\":87096},{\"end\":87113,\"start\":87107},{\"end\":87123,\"start\":87120},{\"end\":87441,\"start\":87434},{\"end\":87456,\"start\":87446},{\"end\":87466,\"start\":87461},{\"end\":87479,\"start\":87477},{\"end\":87493,\"start\":87485},{\"end\":87510,\"start\":87501},{\"end\":87832,\"start\":87830},{\"end\":87844,\"start\":87837},{\"end\":87857,\"start\":87850},{\"end\":87866,\"start\":87864},{\"end\":87876,\"start\":87873},{\"end\":88105,\"start\":88101},{\"end\":88123,\"start\":88118},{\"end\":88142,\"start\":88135},{\"end\":88381,\"start\":88375},{\"end\":88398,\"start\":88389},{\"end\":88411,\"start\":88406},{\"end\":88648,\"start\":88643},{\"end\":88662,\"start\":88655},{\"end\":88673,\"start\":88669},{\"end\":88685,\"start\":88680},{\"end\":88697,\"start\":88691},{\"end\":88699,\"start\":88698}]", "bib_author_last_name": "[{\"end\":72729,\"start\":72724},{\"end\":72745,\"start\":72738},{\"end\":72959,\"start\":72952},{\"end\":73163,\"start\":73151},{\"end\":73181,\"start\":73172},{\"end\":73308,\"start\":73296},{\"end\":73326,\"start\":73317},{\"end\":73500,\"start\":73495},{\"end\":73515,\"start\":73507},{\"end\":73533,\"start\":73525},{\"end\":73700,\"start\":73695},{\"end\":73714,\"start\":73709},{\"end\":73730,\"start\":73722},{\"end\":73742,\"start\":73732},{\"end\":73907,\"start\":73899},{\"end\":73925,\"start\":73916},{\"end\":74220,\"start\":74215},{\"end\":74235,\"start\":74228},{\"end\":74261,\"start\":74252},{\"end\":74275,\"start\":74269},{\"end\":74293,\"start\":74286},{\"end\":74312,\"start\":74305},{\"end\":74331,\"start\":74321},{\"end\":74347,\"start\":74342},{\"end\":74361,\"start\":74354},{\"end\":74373,\"start\":74368},{\"end\":74713,\"start\":74708},{\"end\":74728,\"start\":74721},{\"end\":74754,\"start\":74745},{\"end\":74768,\"start\":74762},{\"end\":74786,\"start\":74779},{\"end\":74805,\"start\":74798},{\"end\":74824,\"start\":74814},{\"end\":74840,\"start\":74835},{\"end\":74854,\"start\":74847},{\"end\":74866,\"start\":74861},{\"end\":75290,\"start\":75279},{\"end\":75303,\"start\":75298},{\"end\":75325,\"start\":75315},{\"end\":75343,\"start\":75332},{\"end\":75357,\"start\":75353},{\"end\":75377,\"start\":75366},{\"end\":75395,\"start\":75387},{\"end\":75414,\"start\":75406},{\"end\":75429,\"start\":75422},{\"end\":75758,\"start\":75752},{\"end\":75773,\"start\":75766},{\"end\":75784,\"start\":75780},{\"end\":75796,\"start\":75791},{\"end\":75810,\"start\":75804},{\"end\":76081,\"start\":76071},{\"end\":76338,\"start\":76323},{\"end\":76355,\"start\":76348},{\"end\":76361,\"start\":76357},{\"end\":76578,\"start\":76565},{\"end\":76589,\"start\":76586},{\"end\":76605,\"start\":76600},{\"end\":76617,\"start\":76615},{\"end\":76892,\"start\":76885},{\"end\":76913,\"start\":76905},{\"end\":76939,\"start\":76930},{\"end\":77218,\"start\":77211},{\"end\":77239,\"start\":77231},{\"end\":77256,\"start\":77249},{\"end\":77282,\"start\":77273},{\"end\":77685,\"start\":77678},{\"end\":77705,\"start\":77696},{\"end\":77955,\"start\":77952},{\"end\":77970,\"start\":77966},{\"end\":77983,\"start\":77976},{\"end\":78149,\"start\":78146},{\"end\":78166,\"start\":78159},{\"end\":78323,\"start\":78320},{\"end\":78336,\"start\":78334},{\"end\":78353,\"start\":78346},{\"end\":78372,\"start\":78363},{\"end\":78562,\"start\":78555},{\"end\":78579,\"start\":78572},{\"end\":78763,\"start\":78756},{\"end\":78777,\"start\":78770},{\"end\":78792,\"start\":78787},{\"end\":78805,\"start\":78800},{\"end\":78820,\"start\":78813},{\"end\":79078,\"start\":79071},{\"end\":79092,\"start\":79087},{\"end\":79106,\"start\":79102},{\"end\":79130,\"start\":79116},{\"end\":79145,\"start\":79139},{\"end\":79158,\"start\":79153},{\"end\":79406,\"start\":79402},{\"end\":79420,\"start\":79417},{\"end\":79432,\"start\":79429},{\"end\":79447,\"start\":79445},{\"end\":79458,\"start\":79455},{\"end\":79621,\"start\":79616},{\"end\":79635,\"start\":79629},{\"end\":79650,\"start\":79642},{\"end\":79668,\"start\":79659},{\"end\":79687,\"start\":79677},{\"end\":79700,\"start\":79694},{\"end\":79716,\"start\":79709},{\"end\":80126,\"start\":80121},{\"end\":80134,\"start\":80131},{\"end\":80146,\"start\":80143},{\"end\":80160,\"start\":80155},{\"end\":80181,\"start\":80171},{\"end\":80403,\"start\":80398},{\"end\":80416,\"start\":80413},{\"end\":80425,\"start\":80422},{\"end\":80437,\"start\":80433},{\"end\":80450,\"start\":80447},{\"end\":80728,\"start\":80721},{\"end\":80741,\"start\":80738},{\"end\":80756,\"start\":80749},{\"end\":80774,\"start\":80765},{\"end\":80786,\"start\":80781},{\"end\":81079,\"start\":81072},{\"end\":81094,\"start\":81087},{\"end\":81112,\"start\":81103},{\"end\":81124,\"start\":81119},{\"end\":81356,\"start\":81354},{\"end\":81369,\"start\":81364},{\"end\":81384,\"start\":81377},{\"end\":81605,\"start\":81599},{\"end\":81614,\"start\":81610},{\"end\":81633,\"start\":81624},{\"end\":81888,\"start\":81882},{\"end\":81897,\"start\":81893},{\"end\":81916,\"start\":81907},{\"end\":82155,\"start\":82153},{\"end\":82165,\"start\":82162},{\"end\":82179,\"start\":82175},{\"end\":82453,\"start\":82450},{\"end\":82464,\"start\":82460},{\"end\":82472,\"start\":82470},{\"end\":82486,\"start\":82482},{\"end\":82891,\"start\":82888},{\"end\":82903,\"start\":82900},{\"end\":82912,\"start\":82909},{\"end\":82920,\"start\":82918},{\"end\":82932,\"start\":82929},{\"end\":82945,\"start\":82940},{\"end\":82958,\"start\":82955},{\"end\":82971,\"start\":82968},{\"end\":83209,\"start\":83206},{\"end\":83219,\"start\":83215},{\"end\":83228,\"start\":83225},{\"end\":83240,\"start\":83237},{\"end\":83253,\"start\":83248},{\"end\":83266,\"start\":83263},{\"end\":83274,\"start\":83272},{\"end\":83493,\"start\":83488},{\"end\":83506,\"start\":83500},{\"end\":83519,\"start\":83514},{\"end\":83728,\"start\":83721},{\"end\":83739,\"start\":83735},{\"end\":83753,\"start\":83748},{\"end\":83766,\"start\":83760},{\"end\":83783,\"start\":83777},{\"end\":83793,\"start\":83790},{\"end\":84040,\"start\":84035},{\"end\":84056,\"start\":84051},{\"end\":84372,\"start\":84367},{\"end\":84387,\"start\":84382},{\"end\":84403,\"start\":84394},{\"end\":84421,\"start\":84413},{\"end\":84449,\"start\":84433},{\"end\":84458,\"start\":84451},{\"end\":84697,\"start\":84690},{\"end\":84709,\"start\":84707},{\"end\":84722,\"start\":84717},{\"end\":84734,\"start\":84730},{\"end\":84748,\"start\":84742},{\"end\":84764,\"start\":84755},{\"end\":85053,\"start\":85041},{\"end\":85062,\"start\":85060},{\"end\":85077,\"start\":85069},{\"end\":85082,\"start\":85079},{\"end\":85343,\"start\":85338},{\"end\":85361,\"start\":85352},{\"end\":85373,\"start\":85370},{\"end\":85646,\"start\":85639},{\"end\":85659,\"start\":85657},{\"end\":85671,\"start\":85668},{\"end\":85953,\"start\":85944},{\"end\":85965,\"start\":85961},{\"end\":85986,\"start\":85974},{\"end\":86001,\"start\":85995},{\"end\":86018,\"start\":86009},{\"end\":86029,\"start\":86022},{\"end\":86042,\"start\":86037},{\"end\":86057,\"start\":86050},{\"end\":86070,\"start\":86065},{\"end\":86078,\"start\":86072},{\"end\":86470,\"start\":86464},{\"end\":86682,\"start\":86675},{\"end\":86696,\"start\":86689},{\"end\":86709,\"start\":86703},{\"end\":86726,\"start\":86717},{\"end\":86739,\"start\":86734},{\"end\":86754,\"start\":86749},{\"end\":86769,\"start\":86763},{\"end\":86787,\"start\":86777},{\"end\":87060,\"start\":87056},{\"end\":87075,\"start\":87070},{\"end\":87085,\"start\":87081},{\"end\":87094,\"start\":87090},{\"end\":87105,\"start\":87102},{\"end\":87118,\"start\":87114},{\"end\":87132,\"start\":87124},{\"end\":87432,\"start\":87423},{\"end\":87444,\"start\":87442},{\"end\":87459,\"start\":87457},{\"end\":87475,\"start\":87467},{\"end\":87483,\"start\":87480},{\"end\":87499,\"start\":87494},{\"end\":87516,\"start\":87511},{\"end\":87531,\"start\":87518},{\"end\":87835,\"start\":87833},{\"end\":87848,\"start\":87845},{\"end\":87862,\"start\":87858},{\"end\":87871,\"start\":87867},{\"end\":87879,\"start\":87877},{\"end\":88116,\"start\":88106},{\"end\":88133,\"start\":88124},{\"end\":88147,\"start\":88143},{\"end\":88387,\"start\":88382},{\"end\":88404,\"start\":88399},{\"end\":88426,\"start\":88412},{\"end\":88437,\"start\":88428},{\"end\":88653,\"start\":88649},{\"end\":88667,\"start\":88663},{\"end\":88678,\"start\":88674},{\"end\":88689,\"start\":88686},{\"end\":88704,\"start\":88700}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":218487351},\"end\":72842,\"start\":72673},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":4797928},\"end\":73119,\"start\":72844},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":10769575},\"end\":73268,\"start\":73121},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":36022762},\"end\":73424,\"start\":73270},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2915490},\"end\":73689,\"start\":73426},{\"attributes\":{\"id\":\"b5\"},\"end\":73881,\"start\":73691},{\"attributes\":{\"doi\":\"arXiv:1705.07750\",\"id\":\"b6\",\"matched_paper_id\":239933},\"end\":74154,\"start\":73883},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4710439},\"end\":74636,\"start\":74156},{\"attributes\":{\"id\":\"b8\"},\"end\":75144,\"start\":74638},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":225039882},\"end\":75742,\"start\":75146},{\"attributes\":{\"id\":\"b10\"},\"end\":75956,\"start\":75744},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":215808493},\"end\":76238,\"start\":75958},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":4570418},\"end\":76512,\"start\":76240},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":54463801},\"end\":76765,\"start\":76514},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":53373757},\"end\":77146,\"start\":76767},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":28883758},\"end\":77559,\"start\":77148},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":162168703},\"end\":77877,\"start\":77561},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":41037339},\"end\":78117,\"start\":77879},{\"attributes\":{\"id\":\"b18\"},\"end\":78255,\"start\":78119},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":209140244},\"end\":78515,\"start\":78257},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":235313631},\"end\":78672,\"start\":78517},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":16091693},\"end\":79010,\"start\":78674},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":246063865},\"end\":79338,\"start\":79012},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":249152215},\"end\":79608,\"start\":79340},{\"attributes\":{\"doi\":\"arXiv:1706.02677\",\"id\":\"b24\"},\"end\":80078,\"start\":79610},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":6773885},\"end\":80325,\"start\":80080},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":216361784},\"end\":80622,\"start\":80327},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":240353744},\"end\":80982,\"start\":80624},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":201306082},\"end\":81294,\"start\":80984},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":182212726},\"end\":81506,\"start\":81296},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":53280782},\"end\":81795,\"start\":81508},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":104292215},\"end\":82065,\"start\":81797},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":52233948},\"end\":82334,\"start\":82067},{\"attributes\":{\"id\":\"b33\"},\"end\":82810,\"start\":82336},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":232352874},\"end\":83177,\"start\":82812},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":235624247},\"end\":83414,\"start\":83179},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":36306843},\"end\":83668,\"start\":83416},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":235694621},\"end\":83954,\"start\":83670},{\"attributes\":{\"id\":\"b38\"},\"end\":84331,\"start\":83956},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":1697911},\"end\":84630,\"start\":84333},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":160025533},\"end\":84951,\"start\":84632},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":10328909},\"end\":85258,\"start\":84953},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":220919674},\"end\":85518,\"start\":85260},{\"attributes\":{\"id\":\"b43\"},\"end\":85865,\"start\":85520},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":244954552},\"end\":86321,\"start\":85867},{\"attributes\":{\"id\":\"b45\"},\"end\":86639,\"start\":86323},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":13756489},\"end\":86969,\"start\":86641},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":5711057},\"end\":87323,\"start\":86971},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":246064068},\"end\":87770,\"start\":87325},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":227282854},\"end\":88009,\"start\":87772},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":235702825},\"end\":88330,\"start\":88011},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":3162051},\"end\":88575,\"start\":88332},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":32701102},\"end\":88876,\"start\":88577}]", "bib_title": "[{\"end\":72715,\"start\":72673},{\"end\":72936,\"start\":72844},{\"end\":73143,\"start\":73121},{\"end\":73288,\"start\":73270},{\"end\":73487,\"start\":73426},{\"end\":73892,\"start\":73883},{\"end\":74208,\"start\":74156},{\"end\":75270,\"start\":75146},{\"end\":76061,\"start\":75958},{\"end\":76311,\"start\":76240},{\"end\":76553,\"start\":76514},{\"end\":76874,\"start\":76767},{\"end\":77200,\"start\":77148},{\"end\":77667,\"start\":77561},{\"end\":77943,\"start\":77879},{\"end\":78137,\"start\":78119},{\"end\":78311,\"start\":78257},{\"end\":78547,\"start\":78517},{\"end\":78748,\"start\":78674},{\"end\":79063,\"start\":79012},{\"end\":79392,\"start\":79340},{\"end\":80115,\"start\":80080},{\"end\":80391,\"start\":80327},{\"end\":80709,\"start\":80624},{\"end\":81060,\"start\":80984},{\"end\":81344,\"start\":81296},{\"end\":81591,\"start\":81508},{\"end\":81874,\"start\":81797},{\"end\":82147,\"start\":82067},{\"end\":82883,\"start\":82812},{\"end\":83201,\"start\":83179},{\"end\":83478,\"start\":83416},{\"end\":83713,\"start\":83670},{\"end\":84358,\"start\":84333},{\"end\":84683,\"start\":84632},{\"end\":85031,\"start\":84953},{\"end\":85329,\"start\":85260},{\"end\":85632,\"start\":85520},{\"end\":85937,\"start\":85867},{\"end\":86666,\"start\":86641},{\"end\":87048,\"start\":86971},{\"end\":87421,\"start\":87325},{\"end\":87828,\"start\":87772},{\"end\":88099,\"start\":88011},{\"end\":88373,\"start\":88332},{\"end\":88641,\"start\":88577}]", "bib_author": "[{\"end\":72731,\"start\":72717},{\"end\":72747,\"start\":72731},{\"end\":72961,\"start\":72938},{\"end\":73165,\"start\":73145},{\"end\":73183,\"start\":73165},{\"end\":73310,\"start\":73290},{\"end\":73328,\"start\":73310},{\"end\":73502,\"start\":73489},{\"end\":73517,\"start\":73502},{\"end\":73535,\"start\":73517},{\"end\":73702,\"start\":73693},{\"end\":73716,\"start\":73702},{\"end\":73732,\"start\":73716},{\"end\":73744,\"start\":73732},{\"end\":73909,\"start\":73894},{\"end\":73927,\"start\":73909},{\"end\":74222,\"start\":74210},{\"end\":74237,\"start\":74222},{\"end\":74263,\"start\":74237},{\"end\":74277,\"start\":74263},{\"end\":74295,\"start\":74277},{\"end\":74314,\"start\":74295},{\"end\":74333,\"start\":74314},{\"end\":74349,\"start\":74333},{\"end\":74363,\"start\":74349},{\"end\":74375,\"start\":74363},{\"end\":74715,\"start\":74703},{\"end\":74730,\"start\":74715},{\"end\":74756,\"start\":74730},{\"end\":74770,\"start\":74756},{\"end\":74788,\"start\":74770},{\"end\":74807,\"start\":74788},{\"end\":74826,\"start\":74807},{\"end\":74842,\"start\":74826},{\"end\":74856,\"start\":74842},{\"end\":74868,\"start\":74856},{\"end\":75292,\"start\":75272},{\"end\":75305,\"start\":75292},{\"end\":75327,\"start\":75305},{\"end\":75345,\"start\":75327},{\"end\":75359,\"start\":75345},{\"end\":75379,\"start\":75359},{\"end\":75397,\"start\":75379},{\"end\":75416,\"start\":75397},{\"end\":75431,\"start\":75416},{\"end\":75760,\"start\":75746},{\"end\":75775,\"start\":75760},{\"end\":75786,\"start\":75775},{\"end\":75798,\"start\":75786},{\"end\":75812,\"start\":75798},{\"end\":76083,\"start\":76063},{\"end\":76340,\"start\":76313},{\"end\":76357,\"start\":76340},{\"end\":76363,\"start\":76357},{\"end\":76580,\"start\":76555},{\"end\":76591,\"start\":76580},{\"end\":76607,\"start\":76591},{\"end\":76619,\"start\":76607},{\"end\":76894,\"start\":76876},{\"end\":76915,\"start\":76894},{\"end\":76941,\"start\":76915},{\"end\":77220,\"start\":77202},{\"end\":77241,\"start\":77220},{\"end\":77258,\"start\":77241},{\"end\":77284,\"start\":77258},{\"end\":77687,\"start\":77669},{\"end\":77707,\"start\":77687},{\"end\":77957,\"start\":77945},{\"end\":77972,\"start\":77957},{\"end\":77985,\"start\":77972},{\"end\":78151,\"start\":78139},{\"end\":78168,\"start\":78151},{\"end\":78325,\"start\":78313},{\"end\":78338,\"start\":78325},{\"end\":78355,\"start\":78338},{\"end\":78374,\"start\":78355},{\"end\":78564,\"start\":78549},{\"end\":78581,\"start\":78564},{\"end\":78765,\"start\":78750},{\"end\":78779,\"start\":78765},{\"end\":78794,\"start\":78779},{\"end\":78807,\"start\":78794},{\"end\":78822,\"start\":78807},{\"end\":79080,\"start\":79065},{\"end\":79094,\"start\":79080},{\"end\":79108,\"start\":79094},{\"end\":79132,\"start\":79108},{\"end\":79147,\"start\":79132},{\"end\":79160,\"start\":79147},{\"end\":79408,\"start\":79394},{\"end\":79422,\"start\":79408},{\"end\":79434,\"start\":79422},{\"end\":79449,\"start\":79434},{\"end\":79460,\"start\":79449},{\"end\":79623,\"start\":79610},{\"end\":79637,\"start\":79623},{\"end\":79652,\"start\":79637},{\"end\":79670,\"start\":79652},{\"end\":79689,\"start\":79670},{\"end\":79702,\"start\":79689},{\"end\":79718,\"start\":79702},{\"end\":80128,\"start\":80117},{\"end\":80136,\"start\":80128},{\"end\":80148,\"start\":80136},{\"end\":80162,\"start\":80148},{\"end\":80183,\"start\":80162},{\"end\":80405,\"start\":80393},{\"end\":80418,\"start\":80405},{\"end\":80427,\"start\":80418},{\"end\":80439,\"start\":80427},{\"end\":80452,\"start\":80439},{\"end\":80730,\"start\":80711},{\"end\":80743,\"start\":80730},{\"end\":80758,\"start\":80743},{\"end\":80776,\"start\":80758},{\"end\":80788,\"start\":80776},{\"end\":81081,\"start\":81062},{\"end\":81096,\"start\":81081},{\"end\":81114,\"start\":81096},{\"end\":81126,\"start\":81114},{\"end\":81358,\"start\":81346},{\"end\":81371,\"start\":81358},{\"end\":81386,\"start\":81371},{\"end\":81607,\"start\":81593},{\"end\":81616,\"start\":81607},{\"end\":81635,\"start\":81616},{\"end\":81890,\"start\":81876},{\"end\":81899,\"start\":81890},{\"end\":81918,\"start\":81899},{\"end\":82157,\"start\":82149},{\"end\":82167,\"start\":82157},{\"end\":82181,\"start\":82167},{\"end\":82455,\"start\":82445},{\"end\":82466,\"start\":82455},{\"end\":82474,\"start\":82466},{\"end\":82488,\"start\":82474},{\"end\":82893,\"start\":82885},{\"end\":82905,\"start\":82893},{\"end\":82914,\"start\":82905},{\"end\":82922,\"start\":82914},{\"end\":82934,\"start\":82922},{\"end\":82947,\"start\":82934},{\"end\":82960,\"start\":82947},{\"end\":82973,\"start\":82960},{\"end\":83211,\"start\":83203},{\"end\":83221,\"start\":83211},{\"end\":83230,\"start\":83221},{\"end\":83242,\"start\":83230},{\"end\":83255,\"start\":83242},{\"end\":83268,\"start\":83255},{\"end\":83276,\"start\":83268},{\"end\":83495,\"start\":83480},{\"end\":83508,\"start\":83495},{\"end\":83521,\"start\":83508},{\"end\":83730,\"start\":83715},{\"end\":83741,\"start\":83730},{\"end\":83755,\"start\":83741},{\"end\":83768,\"start\":83755},{\"end\":83785,\"start\":83768},{\"end\":83795,\"start\":83785},{\"end\":84042,\"start\":84028},{\"end\":84058,\"start\":84042},{\"end\":84374,\"start\":84360},{\"end\":84389,\"start\":84374},{\"end\":84405,\"start\":84389},{\"end\":84423,\"start\":84405},{\"end\":84451,\"start\":84423},{\"end\":84460,\"start\":84451},{\"end\":84699,\"start\":84685},{\"end\":84711,\"start\":84699},{\"end\":84724,\"start\":84711},{\"end\":84736,\"start\":84724},{\"end\":84750,\"start\":84736},{\"end\":84766,\"start\":84750},{\"end\":85055,\"start\":85033},{\"end\":85064,\"start\":85055},{\"end\":85079,\"start\":85064},{\"end\":85084,\"start\":85079},{\"end\":85345,\"start\":85331},{\"end\":85363,\"start\":85345},{\"end\":85375,\"start\":85363},{\"end\":85648,\"start\":85634},{\"end\":85661,\"start\":85648},{\"end\":85673,\"start\":85661},{\"end\":85955,\"start\":85939},{\"end\":85967,\"start\":85955},{\"end\":85988,\"start\":85967},{\"end\":86003,\"start\":85988},{\"end\":86020,\"start\":86003},{\"end\":86031,\"start\":86020},{\"end\":86044,\"start\":86031},{\"end\":86059,\"start\":86044},{\"end\":86072,\"start\":86059},{\"end\":86080,\"start\":86072},{\"end\":86472,\"start\":86459},{\"end\":86684,\"start\":86668},{\"end\":86698,\"start\":86684},{\"end\":86711,\"start\":86698},{\"end\":86728,\"start\":86711},{\"end\":86741,\"start\":86728},{\"end\":86756,\"start\":86741},{\"end\":86771,\"start\":86756},{\"end\":86789,\"start\":86771},{\"end\":87062,\"start\":87050},{\"end\":87077,\"start\":87062},{\"end\":87087,\"start\":87077},{\"end\":87096,\"start\":87087},{\"end\":87107,\"start\":87096},{\"end\":87120,\"start\":87107},{\"end\":87134,\"start\":87120},{\"end\":87434,\"start\":87423},{\"end\":87446,\"start\":87434},{\"end\":87461,\"start\":87446},{\"end\":87477,\"start\":87461},{\"end\":87485,\"start\":87477},{\"end\":87501,\"start\":87485},{\"end\":87518,\"start\":87501},{\"end\":87533,\"start\":87518},{\"end\":87837,\"start\":87830},{\"end\":87850,\"start\":87837},{\"end\":87864,\"start\":87850},{\"end\":87873,\"start\":87864},{\"end\":87881,\"start\":87873},{\"end\":88118,\"start\":88101},{\"end\":88135,\"start\":88118},{\"end\":88149,\"start\":88135},{\"end\":88389,\"start\":88375},{\"end\":88406,\"start\":88389},{\"end\":88428,\"start\":88406},{\"end\":88439,\"start\":88428},{\"end\":88655,\"start\":88643},{\"end\":88669,\"start\":88655},{\"end\":88680,\"start\":88669},{\"end\":88691,\"start\":88680},{\"end\":88706,\"start\":88691}]", "bib_venue": "[{\"end\":72750,\"start\":72747},{\"end\":72975,\"start\":72961},{\"end\":73187,\"start\":73183},{\"end\":73332,\"start\":73328},{\"end\":73542,\"start\":73535},{\"end\":74008,\"start\":73943},{\"end\":74379,\"start\":74375},{\"end\":74701,\"start\":74638},{\"end\":75435,\"start\":75431},{\"end\":76091,\"start\":76083},{\"end\":76367,\"start\":76363},{\"end\":76623,\"start\":76619},{\"end\":76949,\"start\":76941},{\"end\":77340,\"start\":77284},{\"end\":77711,\"start\":77707},{\"end\":77989,\"start\":77985},{\"end\":78172,\"start\":78168},{\"end\":78378,\"start\":78374},{\"end\":78585,\"start\":78581},{\"end\":78826,\"start\":78822},{\"end\":79164,\"start\":79160},{\"end\":79464,\"start\":79460},{\"end\":79822,\"start\":79734},{\"end\":80187,\"start\":80183},{\"end\":80458,\"start\":80452},{\"end\":80792,\"start\":80788},{\"end\":81130,\"start\":81126},{\"end\":81390,\"start\":81386},{\"end\":81645,\"start\":81635},{\"end\":81922,\"start\":81918},{\"end\":82185,\"start\":82181},{\"end\":82443,\"start\":82336},{\"end\":82977,\"start\":82973},{\"end\":83280,\"start\":83276},{\"end\":83534,\"start\":83521},{\"end\":83802,\"start\":83795},{\"end\":84026,\"start\":83956},{\"end\":84464,\"start\":84460},{\"end\":84777,\"start\":84766},{\"end\":85091,\"start\":85084},{\"end\":85379,\"start\":85375},{\"end\":85678,\"start\":85673},{\"end\":86084,\"start\":86080},{\"end\":86457,\"start\":86323},{\"end\":86796,\"start\":86789},{\"end\":87138,\"start\":87134},{\"end\":87537,\"start\":87533},{\"end\":87884,\"start\":87881},{\"end\":88162,\"start\":88149},{\"end\":88446,\"start\":88439},{\"end\":88710,\"start\":88706}]"}}}, "year": 2023, "month": 12, "day": 17}