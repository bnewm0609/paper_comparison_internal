{"id": 4331539, "updated": "2023-10-02 13:43:48.117", "metadata": {"title": "DeepJDOT: Deep Joint Distribution Optimal Transport for Unsupervised Domain Adaptation", "authors": "[{\"first\":\"Bharath\",\"last\":\"Damodaran\",\"middle\":[\"Bhushan\"]},{\"first\":\"Benjamin\",\"last\":\"Kellenberger\",\"middle\":[]},{\"first\":\"R'emi\",\"last\":\"Flamary\",\"middle\":[]},{\"first\":\"Devis\",\"last\":\"Tuia\",\"middle\":[]},{\"first\":\"Nicolas\",\"last\":\"Courty\",\"middle\":[]}]", "venue": "in Proceedings of European Conference on Computer Vision 2018 (ECCV-2018)", "journal": null, "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "In computer vision, one is often confronted with problems of domain shifts, which occur when one applies a classifier trained on a source dataset to target data sharing similar characteristics (e.g. same classes), but also different latent data structures (e.g. different acquisition conditions). In such a situation, the model will perform poorly on the new data, since the classifier is specialized to recognize visual cues specific to the source domain. In this work we explore a solution, named DeepJDOT, to tackle this problem: through a measure of discrepancy on joint deep representations/labels based on optimal transport, we not only learn new data representations aligned between the source and target domain, but also simultaneously preserve the discriminative information used by the classifier. We applied DeepJDOT to a series of visual recognition tasks, where it compares favorably against state-of-the-art deep domain adaptation methods.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1803.10081", "mag": "2963187488", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/eccv/DamodaranKFTC18", "doi": "10.1007/978-3-030-01225-0_28"}}, "content": {"source": {"pdf_hash": "ffbdf7c3861f88d309975647af61ddc36ed2bf2c", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1803.10081v3.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1803.10081", "status": "GREEN"}}, "grobid": {"id": "2a62aac093f58d6694d7e7ee164c985bcb159f9a", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/ffbdf7c3861f88d309975647af61ddc36ed2bf2c.txt", "contents": "\nDeepJDOT: Deep Joint Distribution Optimal Transport for Unsupervised Domain Adaptation\n\n\nBharath Bhushan Damodaran bharath-bhushan.damodaran@irisa.fr \nUMR 6074\nUniversit\u00e9 de Bretagne Sud\nIRISA\nCNRS\nFrance\n\nBenjamin Kellenberger benjamin.kellenberger@wur.nl \nWageningen University\nthe Netherlands\n\nR\u00e9mi Flamary \nUMR 7293\nLaboratoire Lagrange\nUniversit\u00e9 C\u00f4te d'Azur\nOCA\nCNRS\nFrance\n\nDevis Tuia \nWageningen University\nthe Netherlands\n\nNicolas Courty \nUMR 6074\nUniversit\u00e9 de Bretagne Sud\nIRISA\nCNRS\nFrance\n\nDeepJDOT: Deep Joint Distribution Optimal Transport for Unsupervised Domain Adaptation\nDeep Domain Adaptation, Optimal Transport\nIn computer vision, one is often confronted with problems of domain shifts, which occur when one applies a classifier trained on a source dataset to target data sharing similar characteristics (e.g. same classes), but also different latent data structures (e.g. different acquisition conditions). In such a situation, the model will perform poorly on the new data, since the classifier is specialized to recognize visual cues specific to the source domain. In this work we explore a solution, named DeepJDOT, to tackle this problem: through a measure of discrepancy on joint deep representations/labels based on optimal transport, we not only learn new data representations aligned between the source and target domain, but also simultaneously preserve the discriminative information used by the classifier. We applied DeepJDOT to a series of visual recognition tasks, where it compares favorably against state-of-the-art deep domain adaptation methods.\n\nIntroduction\n\nThe ability to generalize across datasets is one of the holy grails of computer vision. Designing models that can perform well on datasets sharing similar characteristics such as classes, but also presenting different underlying data structures (for instance different backgrounds, colorspaces, or acquired with different devices) is key in applications where labels are scarce or expensive to obtain. However, traditional learning machines struggle in performing well out of the datasets (or domains) they have been trained with. This is because models generally assume that both training (or source) and test (or target) data are issued from the same generating process. In vision problems, factors such as objects position, illumination, number of channels or seasonality break this assumption and call for adaptation strategies able to compensate for such shifts, or domain adaptation strategies [1]. In a first rough subdivision, domain adaptation strategies can be separated into unsupervised and semi-supervised domain adaptation: the former assumes that no labels are available in the target domain, while the latter assumes the presence of a few labeled instances in the target domain that can be used as reference points for the adaptation. In this paper, we propose a contribution for the former, more challenging case. Let x s \u2208 X S be the source domain examples with the associated labels y s \u2208 Y S . Similarly, let x t \u2208 X T be the target domain images, but with unknown labels. The goal of the unsupervised domain adaptation is to learn the classifier f in the target domain by leveraging the information from the source domain. To this end, we have access to a source domain dataset {x s i , y s } i=1,...,n s and a target domain dataset {x t i } i=1,...,n t with only observations and no labels.\n\nEarly unsupervised domain adaptation research tackled the problem as the one of finding a common representation between the domains, or a latent space, where a single classifier can be used independently from the datapoint's origin [2,3]. In [4], the authors propose to use discrete optimal transport to match the shifted marginal distributions of the two domains under constraints of class regularity in the source. In [5] a similar logic is used, but the joint distributions are aligned directly using a coupling accounting for the marginals and the classconditional distributions shift jointly. However, the method has two drawbacks, for which we propose solutions in this paper: 1) first, the JDOT method in [5] scales poorly, as it must solve a n 1 \u00d7 n 2 coupling, where n 1 and n 2 are the samples to be aligned; 2) secondly, the optimal transport coupling \u03b3 is computed between the input spaces (and using a 2 distance), which is a poor representation to be aligned, since we are interested in matching more semantic representations supposed to ease the work of the classifier using them to take decisions.\n\nWe solve the two problems above by a strategy based on deep learning. On the one hand, using deep learning algorithms for domain adaptation has found an increasing interest and has shown impressive results in recent computer vision literature [6][7][8][9]. On the other hand (and more importantly), a Convolutional Neural Network (CNN) offers the characteristics needed to solve our two problems: 1) by gradually adapting the optimal transport coupling along the CNN training, we obtain a scalable solution, an approximated and stochastic version of JDOT; 2) by learning the coupling in a deep layer of the CNN, we align the representation the classifier is using to take its decision, which is a more semantic representation of the classes. In summary, we learn jointly the embedding between the two domains and the classifier in a single CNN framework. We use a domain adaptation-tailored loss function based on optimal transport and therefore call our proposition Deep Joint Distribution Optimal Transportation (DeepJDOT).\n\nWe test DeepJDOT on a series of visual domain adaptation tasks and compare favorably against several recent state of the art competitors.\n\n\nRelated works\n\nUnsupervised domain adaptation. Unsupervised domain adaptation studies the situation where the source domain carries labeled instances, while the target domain is unlabeled, yet accessible during training [10]. Earlier approaches consider projections aligning data spaces to each other [2,11,12], thus trying to exploit shift-invariant information to match the domains in their original (input) space. Later works extended such logic to deep learning, typically by weight sharing [6]/reconstruction [13], by adding Maximum Mean Discrepancy (MMD) and association-based losses between source and target layers [14][15][16]. Other major developments focus on the inclusion of adversarial loss functions pushing the CNN to be unable to discriminate whether a sample comes from the source or the target domain [7,8,17]. Finally, the most recent works extend this adversarial logic to the use of GANs [18,19], for example using two GAN modules with shared weights [9], forcing image to image architectures to have similar activation distributions [20] or simply fooling a GAN's discriminator discerning between domains [21]. These adversarial image generation based methods [18][19][20] use a class-conditioning or cycle consistency term to learn the discriminative embedding, such that semantically similar images in both domains are projected closeby in the embedding space. Our proposed DeepJDOT uses the concept of a shared embedding for both domains [17] and is built on a similar logic as the MMD-based methods, yet adding a clear discriminative component to the alignment: the proposed DeepJDOT associates representation and discriminative learning, since the optimal transport coupling ensures that distributions are matched, while i) the JDOT class loss performs source label propagation to the target samples and ii) the fact of learning the coupling in deep layers of the CNN ensures discrimination power.\n\nOptimal transport in domain adaptation. Optimal transport [22][23][24] has been used in domain adaptation to learn the transformation between domains [4,25,26], with associated theoretical guarantees [27]. In those works, the coupling \u03b3 is used to transport (i.e. transform) the source data samples through an estimated mapping called barycentric mapping. Then, a new classifier is trained on the transported source data representation. But those different methods can only address problems of small to medium sizes because they rely on the exact solution of the OT problem on all samples. Very recently, Shen et al. [28] used the Wasserstein distance as a loss in a deep learning setting to promote similarities between embedded representations using the dual formulation of the problem exposed in [29]. However, none of those approaches considers an adaptation w.r.t. the discriminative content of the representation, as we propose in this paper.\n\n\nOptimal transport for domain adaptation\n\nOur proposal is based on optimal transport. After recalling the associated basic notions and its relation with domain adaptation, we detail the JDOT method [5], which is the starting point of our proposition.\n\n\nOptimal Transport\n\nOptimal transport [24] (OT) is a theory that allows to compare probability distributions in a geometrically sound manner. It permits to work on empirical distributions and to exploit the geometry of the data embedding space. Formally, OT searches a probabilistic coupling \u03b3 \u2208 \u03a0(\u00b5 1 , \u00b5 2 ) between two distributions \u00b5 1 and \u00b5 2 which yields a minimal displacement cost\nOT c (\u00b5 1 , \u00b5 2 ) = inf \u03b3\u2208\u03a0(\u00b51,\u00b52) R 2 c(x 1 , x 2 )d\u03b3(x 1 , x 2 )(1)\nw.r.t. a given cost function c(x 1 , x 2 ) measuring the dissimilarity between samples x 1 and x 2 . Here, \u03a0(\u00b5 1 , \u00b5 2 ) describes the space of joint probability distributions with marginals \u00b5 1 and \u00b5 2 . In a discrete setting (both distributions are empirical) this becomes:\nOT c (\u00b5 1 , \u00b5 2 ) = min \u03b3\u2208\u03a0(\u00b51,\u00b52) < \u03b3, C > F ,(2)\nwhere \u00b7, \u00b7 F is the Frobenius dot product, C \u2265 0 is a cost matrix \u2208 R n1\u00d7n2 representing the pairwise costs c(x i , x j ), and \u03b3 is a matrix of size n 1 \u00d7 n 2 with prescribed marginals. The minimum of this optimization problem can be used as a distance between distributions, and, whenever the cost c is a norm, it is referred to as the Wasserstein distance. Solving equation (2) is a simple linear programming problem with equality constraints, but scales super-quadratically with the size of the sample. Efficient computational schemes were proposed with entropic regularization [30] and/or stochastic versions using the dual formulation of the problem [31,29,32], allowing to tackle small to middle sized problems.\n\n\nJoint Distribution Optimal Transport\n\nCourty et al. [5] proposed the joint distribution optimal transport (JDOT) method to prevent the two-steps adaptation (i.e. first adapt the representation and then learn the classifier on the adapted features) by directly learning a classifier embedded in the cost function c. The underlying idea is to align the joint features/labels distribution instead of only considering the features distribution. Consequently, \u00b5 s and \u00b5 t are measures of the product space X \u00d7 Y. The generalized cost associated to this space is expressed as a weighted combination of costs in the feature and label spaces, reading\nd x s i , y s i ; x t j , y t j = \u03b1c(x s i , x t j ) + \u03bb t L(y s i , y t j )(3)\nfor the i-th source and j-th target element, and where c(\u00b7, \u00b7) is chosen as a 2 2 distance and L(\u00b7, \u00b7) is a classification loss (e.g. hinge or cross-entropy). Parameters \u03b1 and \u03bb t are two scalar values weighing the contributions of distance terms. Since target labels y t j are unknown, they are replaced by a surrogate version f (x t j ), which depends on a classifier f : X \u2192 Y. Accounting for the classification loss leads to the following minimization problem: where D f depends on f and gathers all the pairwise costs d(\u00b7, \u00b7). As a by-product of this optimization problem, samples that share a common representation and a common label (through classification) are matched, yielding better discrimination. Interestingly, it is proven in [5] that minimizing this quantity is equivalent to minimizing a learning bound on the domain adaptation problem. However, JDOT has two major drawbacks: i) on large datasets, solving for \u03b3 becomes intractable because \u03b3 scales quadratically in size to the number of samples; ii) the cost c(x s i , x t j ) is taken in the input space as the squared Euclidean norm on images and can be uninformative of the dissimilarity between two samples. Our proposed DeepJDOT solves those two issues by introducing a stochastic version computing only small couplings along the iterations of a CNN, and by the fact that the optimal transport is learned between the semantic representations in the deeper layers of the CNN, rather than in the image space.\nmin f,\u03b3\u2208\u03a0(\u00b5s,\u00b5t) < \u03b3, D f > F ,(4)\n\nProposed method\n\n\nDeep Joint Distribution Optimal Transport(DeepJDOT)\n\nThe DeepJDOT model, illustrated in Fig. 1, is composed of two parts: an embedding function g : x \u2192 z, where the input is mapped into the latent space Z, and the classifier f : z \u2192 y, which maps the latent space to the label space on the target domain. The latent space can be any feature layer provided by a model, as in our case the penultimate fully connected layer of a CNN. DeepJ-DOT optimizes jointly this feature space and the classifier to provide a method that performs well on the target domain. The solution to this problem can be achieved by minimizing the following objective function:\nmin \u03b3\u2208\u03a0(\u00b5s,\u00b5t),f,g i j \u03b3 ij d g(x s i ), y s i ; g(x t j ), f (g(x t j )) ,(5)where d g(x s i ), y s i ; g(x t j ), f (g(x t j ) = \u03b1 g(x s i ) \u2212 g(x t j ) 2 + \u03bb t L y s i , f (g(x t j ))\n, and \u03b1 and \u03bb t are the parameters controlling the tradeoff between the two terms, as in equation (3). Similarly to JDOT, the first term in the loss compares the compatibility of the embeddings for the source and target domain, while the second term considers the classifier f learned in the target domain and its regularity with respect to the labels available in the source. Despite similarities with the formulation of JDOT [5], our proposition comes with the notable difference that, in DeepJDOT, the Wasserstein distance is minimized between the joint (embedded space/label) distributions within the CNN, rather than between the original input spaces. As the deeper layers of a CNN encode both spatial and semantic information, we believe them to be more apt to describe the image content for both domains, rather than the original features that are affected by a number of factors such as illumination, pose or relative position of objects.\n\nOne can note that the formulation reported in equation (5) only depends on the classifier learned in the target domain. By doing so, one puts the emphasis on learning a good classifier for the target domain, and disregards the performance of the classifier when considering source samples. In recent literature, such a degradation in the source domain has been named as 'catastrophic forgetting' [33,34]. To avoid such forgetting, one can easily re-incorporate the loss on the source domain in (5), leading to the final DeepJDOT objective:\nmin \u03b3,f,g 1 n s i L s (y s i , f (g(x s i ))) + i,j \u03b3 ij \u03b1 g(x s i ) \u2212 g(x t j ) 2 + \u03bb t L t y s i , f (g(x t j )) .(6)\nThis last formulation is the optimization problem solved by DeepJDOT. However, for large sample sizes the constraint of computing a full \u03b3 yields a computationally infeasible problem, both in terms of memory and time complexity. In the next section, we propose an approximation method based on stochastic optimization.\n\n\nSolving the optimization problem with stochastic gradients\n\nIn this section, we describe the approximate optimization procedure for solving DeepJDOT. Equation (6) involves two groups of variables to be optimized: the OT matrix \u03b3 and the models f and g. This suggest the use of an alternative minimization approach (as proposed in the original JDOT). Indeed, when\u011d and f are fixed, solving equation (6) boils down to a standard OT problem with as-\nsociated cost matrix C ij = \u03b1 \u011d(x s i ) \u2212\u011d(x t j ) 2 + \u03bb t L t y s i ,f (\u011d(x t j )\n) . When fixin\u011d \u03b3, optimizing g and f is a classical deep learning problem. However, computing the optimal coupling with the classical OT solvers is not scalable to largescale datasets. Despite some recent development for large scale OT with general ground loss [31,32], the model does not scale sufficiently to meet requirements of recent computer vision tasks.\n\nTherefore, in this work we propose to solve the problem with a stochastic approximation using minibatches from both the source and target domains [35]. This approach has two major advantages: it is scalable to large datasets and can be easily integrated in modern deep learning frameworks. More specifically, the objective function (6) is approximated by sampling a mini-batch of size m, leading to the following optimization problem:\nmin f,g E 1 m m i=1 Ls (y s i , f (g(x s i )) + min \u03b3\u2208\u2206 m i,j \u03b3ij \u03b1 g(x s i ) \u2212 g(x t j ) 2 + \u03bbtLt y s i , f (g(x t j ))(7)\nwhere E is the expected value with respect to the randomly sampled minibatches drawn from both source and target domains. The classification loss functions for the source (L s ) and target (L t ) domains can be any general class of loss functions that are twice differentiable. We opted for a traditional cross-entropy loss in both cases. Note that, as discussed in [35], the expected value over the minibtaches does not converge to the true OT coupling between every pair of samples, which might then lead to the appearance of connections between samples that would not have been connected in the full coupling. However, this can also be seen as a regularization that will promote sharing of the mass between neighboring samples. Finally note that we did not use the regularized version of OT as in [35], since it introduces an additional regularization parameter that should be cross-validated, which can make the model calibration even more complex. Still, the extension of DeepJDOT to regularized OT is straightforward and could be beneficial for high-dimensional embeddings g.\n\nConsequently, we propose to obtain the stochastic update for Eq. (7) \n\u03b3 ij \u03b1 \u011d(x s i ) \u2212\u011d(x t j ) 2 + \u03bb t L t y s i ,f (g(x t j ))(8)\nusing the network simplex flow algorithm. 2. With fixed coupling\u03b3 obtained at the previous step, update the embedding function (g) and classifier (f ) with stochastic gradient update for the following loss on the minibatch:\n1 m m i=1 L s (y s i , f (g(x s i )))+ m i,j=1\u03b3 ij \u03b1 g(x s i ) \u2212 g(x t j ) 2 + \u03bb t L t y s i , f (g(x t j )\n) .\n\n(9) The domain alignment term aligns only the source and target samples with similar activation/labels and the sparse matrix\u03b3 will automatically perform label propagation between source and target samples. The classifier f is simultaneously learnt in both source and target domain.\n\n\nAlgorithm 1 DeepJDOT stochastic optimization\n\nRequire: x s : source domain samples, x t : target domain samples, y s : source domain labels 1: for each batch of source (x b s , y b s ) and target samples (x b t ) do 2:\n\nfix\u011d andf , solve for \u03b3 as in equation (8)  3: fix\u03b3, and update for g and f according to equation (9) 4: end for\n\n\nExperiments and Results\n\nWe evaluate DeepJDOT on three adaptation tasks: digits classification (Section 5.1), the OfficeHome dataset (Section 5.2), and the Visual Domain Adaptation challenge (visDA; Section 5.3). For each dataset, we first present the data, then detail the implementation and finally present and discuss the results.  Model For all digits adaptation experiments, our embedding function g is trained from scratch with six 3 \u00d7 3 convolutional layers containing 32, 32, 64, 64, 128 and 128 filters, and one fully-connected layer of 128 hidden units followed by a sigmoid nonlinearity respectively. Classifier f then consists of a fullyconnected layer, followed by a softmax to provide the class scores. The Adam optimizer (lr = 2e\u22124) is used to update our model using mini-batch sizes of m S = m T = 500 for the two domains (50 samples per class in the source minibatch). The hyper-parameters of DeepJDOT, \u03b1 = 0.001 and \u03bb t = 0.0001, are fixed experimentally.\n\nWe compare DeepJDOT with the following methods:\n\nnon-adversarial discrepancy methods: DeepCORAL [6], MMD [14], DRCN [40], DSN [41], AssocDA [16], Self-ensemble [42] 4 , adversarial discrepancy methods: DANN [8], ADDA [21], adversarial image generation methods: CoGAN [9], UNIT [18], GenToAdapt [19] and I2I Adapt [20].\n\nTo ensure fair comparison, we re-implemented the most relevant competitors (CORAL, MMD, DANN, and ADDA). For the other methods, the results are directly reported from the respective articles.\n\n\nResults\n\nThe performance of DeepJDOT on the four digits adaptation tasks is reported in Table 1. The first row (source only) shows the accuracies on target test data achieved with classifiers trained on source data without adaptation, and the row (target only) reports accuracies on the target test data achieved with classifiers trained on the target training data. This method is considered as an upper bound for our proposed method and can be seen as our gold standard.\n\nStochJDOT (stochastic adaptation of JDOT) refers to the accuracy of our proposed method, when the discrepancy between source and target domain is computed with an 2 distance in the original image space. Lastly, DeepJDOT-source indicates the source data accuracy, after adapting to the target domain, and can be considered a measure of catastrophic forgetting.\n\nThe experimental results show that DeepJDOT achieves accuracies comparable or higher to the current state-of-the-art methods. When the methods in the first block of Table 1 are considered, DeepJDOT outperforms the competitors by large margins, with the exception of DANN that have similar performance on the MNIST\u2192USPS task. In the more challenging adaptation settings (SVHN\u2192MNIST and MNIST\u2192MNIST-M), the state-of-the-art methods 5 were not able to adapt well to the target domain. Next, when the methods in the second block of Table 1 is considered, our method showed impressive performance, despite DeepJDOT not using any complex procedure for generating target images to perform the adaptation.\n\n\nt-SNE embeddings\n\nWe visualize the quality of the embeddings for the source and target domain learnt by DeepJDOT, StochJDOT and DANN using t-SNE embedding on the MNIST\u2192MNIST-M adaptation task ( Figure 3). As expected, in the source model the samples from the source domain are well clustered and target samples are more scattered. The t-SNE embeddings with the DANN were not able to align the distributions well, and this observation also holds for StochJDOT. It is noted that StochJDOT does not align the distributions, but learns the classifier in target domain directly. The poor embeddings of the target samples with StochJDOT shows the necessity of computing the ground metric (cost function) of optimal transport in the deep CNN layers. Finally, DeepJDOT perfectly aligns the source domain samples and target domain samples to each other, which explains the good numerical performances reported above. The \"tentacle\"-shaped and near-perfect separation of the classes in the embedding illustrate the fact that DeepJDOT finds an embedding that both aligns the source/target distribution, but also maximizes the margin between the classes. Table 2 reports the results obtained in the USPS\u2192MNIST and MNIST\u2192 MNIST-M cases for models using only parts of our proposed loss (equation (6)). When only the JDOT loss is considered (\u03b1d + L t case), the accuracy drops in both adaptation cases. This behavior might be due to overfitting of the target classifier to the noisy pseudo-(propagated) labels. However, the performance is comparable to non-adversarial discrepancy-based methods   reported in Table 1. On the contrary, when only the feature space distribution is included in Equation (6), i.e. the L s +\u03b1d experiment, the accuracy is close to our full model in USPS\u2192MNIST direction, but drops in the MNIST\u2192 MNIST-M one. Overall the accuracies are improved compared to the original JDOT model, which highlights the importance of including the information from the source domain. Moreover, this also highlights the importance of simultaneously updating the classifier both in the source and target domain. Summarizing, this ablation study showed that the individual components bring complimentary information to achieve the best classification results.\n\n\nAblation study\n\n\nOffice-Home\n\nDataset The Office-Home dataset [43] contains around 15 500 images in 65 categories from four different domains: artistic paintings, clipart, product and real-world images. Table 3. Performance of DeepJDOT on the Office-Home dataset. \"Ar\" = artistic paintings, \"Cl\" = clipart, \"Pr\" = product, \"Rw\" = real-world images. Performance figures of competitive methods are reported from [43]. Model In this case, we use a pre-trained VGG-16 model [44] with the last layer replaced, but perform no data augmentation. We use 3 250 samples per domain to compute the optimal couplings. We compared our model with following stateof-the-art methods: CORAL [45], JDA [46], DAN [47], DANN [8], and DAH [43].\n\nResults Table 3 lists the performance of DeepJDOT compared to a series of other adaptation methods. As can be seen, DeepJDOT outperforms all other models by a margin on all tasks, except for the adaptation from domain \"product\" to \"clipart\".\n\n\nVisDA-2017\n\nDataset The Visual Domain Adaptation classification challenge of 2017 (VisDA-2017; [48]) requires training a model on renderings of 3D models for each of the 12 classes and adapting to natural images sampled from MS-COCO [49] (validation set) and YouTube BoundingBoxes [50] (test set), respectively. The test set performances reported here were evaluated on the official server.\n\nModel Due to VisDA's strong adaptation complexity, we employ ResNet-50 [51] as a base model, replacing the last layer with two MLPs that map to 512 hidden an then to the 12 classes, respectively. We train a model on the source domain and then freeze it to calculate source feature vectors, adapting an intially identical copy to the target set. We use 4 096 samples per domain to calculate the couplings. Data augmentation follows the scheme of [42].\n\nResults DeepJDOT's performance on VisDA-2017 is reported in Table 4 along with the baselines (DeepCORAL, DAN) from the evaluation server 6 . Our entry in the evaluation server is mentioned as oatmil. We can see that our method achieved better accuracy than the distribution matching methods (DeepCORAL [6], DAN [47]) with all the classes, expect knife. We observe a negative transfer for the class car for DeepJDOT, however this phenomena is also valid with the most of the current methods (see the evaluation server results). For a fair comparison with the rest of the methods in the evaluation server, we also showed (values in bracket of Table 4) the accuracy difference between the source model and target model. Our method is ranked sixth when the mean accuracy is considered, and third when the difference between the source model and target model is considered at the time of publication. It is noted that the performance of our method depends on the capacity of the source model: if a larger CNN is used, the performance of our method could be improved further.\n\n\nConclusions\n\nIn this paper, we proposed the DeepJDOT model for unsupervised deep domain adaptation based on optimal transport. The proposed method aims at learning a common latent space for the source and target distributions, that conveys discriminant information for both domains. This is achieved by minimizing the discrepancy of joint deep feature/labels domain distributions by means of optimal transport. We propose an efficient stochastic algorithm that solves this problem, and despite being simple and easily integrable into modern deep learning frameworks, our method outperformed the state-of-the-art on cross domain digits and office-home adaptation, and provided satisfactory results on the VisDA-2017 adaptation. Future works will consider the evaluation of this method in multi-domains scenario, as well as more complicated cost functions taking into account similarities of the representations across the embedding layers and/or similarities of labels across different classifiers.\n\nFig. 1 .\n1Overview of the proposed DeepJDOT method. While the structure of the feature extractor g and the classifier f are shared by both domains, they are represented twice to distinguish between the two domains. Both the latent representations and labels are used to compute per batch a coupling matrix \u03b3 that is used in the global loss function.\n\n\nWith fixed CNN parameters (\u011d,f ) and for every randomly drawn minibatch (of m samples),\n\nDatasets\nWe consider four data sources (domains) from the digits classification field: MNIST[36], USPS[37], MNIST-M, and the Street View House Numbers (SVHN)[38] dataset. Each dataset involves a 10-class classification problem (retrieving numbers 0-9):-USPS. The USPS datasets contains 7'291 training and 2'007 test grayscale images of handwritten images, each one of size 16 \u00d7 16 pixels. -MNIST. The MNIST dataset contains 60'000 training and 10'000 testing grayscale images of size 28 \u00d7 28. -MNIST M. We generated the MNIST-M images by following the protocol in [8]. MNIST-M is a variation on MNIST, where the (black) background is replaced by random patches extracted from the Berkeley Segmentation Data Set (BSDS500) [39]. The number of training and testing samples are the same as the MNIST dataset discussed above. -SVHN. The SVHN dataset contains house numbers extracted from Google Street View images. We used the Format2 version of SVHN, where the images are cropped into 32 \u00d7 32 pixels. Multiple digits can appear in a single image, the objective is to detect the digit in the center of the image. This dataset contains 73'212 training images, and 26'032 testing images of size 32\u00d7 32\u00d73. The respective examples of the each dataset is shown inFigure 2.The three following experiments were run (the arrow direction corresponds to the sense of the domain adaptation):-USPS\u2194MNIST. The USPS images are zero-padded to reach the same size as MNIST dataset. The adaptation is considered in both directions: USPS \u2192 MNIST, and MNIST \u2192 USPS.\n\nFig. 2 .\n2Examples from the MNIST, USPS, SVHN and MNIST-M datasets. -SVHN\u2192MNIST. The single-channel MNIST images are replicated three times to form a gray 3 channels image, and resized to match the resolution of the SVHN images. Here, the adaptation is considered in only one direction: SVHN\u2192MNIST. Adapting SVHN images to MNIST is challenging due to the variations in the SVHN images [8] -MNIST\u2192MNIST-M. MNIST is considered as the source domain and MNIST-M as the target domain. The color MNIST-M images can be easily identified by a human, however it is challenging for the CNN trained on MNIST, which is only grayscale. Again, the gray scale MNIST images are replicated three times to match the color resolution of the MNIST-M images.\n\nFig. 3 .\n3t-SNE embeddings of 2'000 test samples for MNIST (source) and MNIST-M (target) for Source only classifier, DANN, StochJDOT and DeepJDOT. The left column shows domain comparisons, where colors represent the domain. The right column shows the ability of the methods to discriminate classes (samples are colored w.r.t. their classes).\n\n\narXiv:1803.10081v3 [cs.CV] 5 Sep 2018authors contributed equally \n\n\n\nTable 1 .\n1Classification accuracy on the target test datasets for the digit classification tasks. Source only and target only refer to training on the respective datasets without domain adaptation and evaluating on the target test dataset. The accuracies reported in the first block are our own implementations, while the second block reports performances from the respective articles. Bold and italic indicates the best and second best results. The last line reports the performance of DeepJDOT on the source domain.Method \nAdaptation:source\u2192target \nMNIST \u2192 USPS USPS \u2192 MNIST SVHN \u2192 MNIST MNIST \u2192 MNIST-M \nSource only \n94.8 \n59.6 \n60.7 \n60.8 \n\nDeepCORAL [6] \n89.33 \n91.5 \n59.6 \n66.5 \nMMD [14] \n88.5 \n73.5 \n64.8 \n72.5 \nDANN [8] \n95.7 \n90.0 \n70.8 \n75.4 \nADDA [21] \n92.4 \n93.8 \n76.0 5 \n78.8 \nAssocDA [16] \n-\n-\n95.7 \n89.5 \nSelf-ensemble 4 [42] \n88.14 \n92.35 \n93.33 \n-\nDRCN [40] \n91.8 \n73.6 \n81.9 \n-\nDSN [41] \n91.3 \n-\n82.7 \n83.2 \nCoGAN [9] \n91.2 \n89.1 \n-\n-\nUNIT [18] \n95.9 \n93.5 \n90.5 \n-\nGenToAdapt [19] \n95.3 \n90.8 \n92.4 \n-\nI2I Adapt [20] \n92.1 \n87.2 \n80.3 \n-\n\nStochJDOT \n93.6 \n90.5 \n67.6 \n66.7 \nDeepJDOT (ours) \n95.7 \n96.4 \n96.7 \n92.4 \n\ntarget only \n95.8 \n98.7 \n98.7 \n96.8 \nDeepJDOT-source \n98.5 \n94.9 \n75.7 \n97.8 \n\n\n\nTable 2 .\n2Ablation study of DeepJDOT.Method \nUSPS \u2192 MNIST MNIST \u2192 MNIST-M \nLs + (\u03b1d + Lt) \n96.4 \n92.4 \n\u03b1d + Lt \n86.41 \n73.6 \nLs + \u03b1d \n95.53 \n82.3 \n\n\n\n\nMethod Ar\u2192 Cl Ar\u2192 Pr Ar\u2192 Rw Cl\u2192 Ar Cl\u2192 Pr Cl\u2192 Rw Pr\u2192Ar Pr\u2192Cl Pr\u2192Rw Rw\u2192Ar Rw\u2192Cl Rw\u2192Pr Mean CORAL[45] 27.1036.16 \n44.32 \n26.08 \n40.03 \n40.33 \n27.77 30.54 \n50.61 \n38.48 \n36.36 \n57.11 \n37.91 \nJDA [46] \n25.34 \n35.98 \n42.94 \n24.52 \n40.19 \n40.90 \n25.96 32.72 \n49.25 \n35.10 \n35.35 \n55.35 \n36.97 \nDAN [47] \n30.66 \n42.17 \n54.13 \n32.83 \n47.59 \n49.58 \n29.07 34.05 \n56.70 \n43.58 \n38.25 \n62.73 \n43.46 \nDANN [8] \n33.33 \n42.96 \n54.42 \n32.26 \n49.13 \n49.76 \n30.44 38.14 \n56.76 \n44.71 \n42.66 \n64.65 \n44.94 \nDAH [43] \n31.64 \n40.75 \n51.73 \n34.69 \n51.93 \n52.79 \n29.91 39.63 60.71 \n44.99 \n45.13 \n62.54 \n45.54 \nDeepJDOT 39.73 50.41 \n62.49 \n39.52 54.35 \n53.15 36.72 39.24 63.55 52.29 45.43 70.45 50.67 \n\n\n\nTable 4 .\n4Performance of DeepJDOT on the VisDA 2017 classification challenge. The scores in the bracket indicate the accuracy difference between the source (unadapted) model and target (adapted) model. The respective values of CORAL and DAN are reported from the evaluation server 6 . plane bcycl bus car horse knife mcycl person plant sktbd train truck DeepCORAL [6] 62.5 21.7 66.3 64.6 31.1 36.7 54.2 24.9 73.8 29.9 43.4 34.2 45.3 (19.Method \n\nwe report a comparison against[42] by using minimal data augmentation (corresponding to MT+CT * inTable 1of[42]). We do not compare against their full model, as they use a much heavier data augmentation and different networks.\nFor ADDA[21] in the SVHN\u2192MNIST adaptation task the accuracy is reported from the paper, as we were not able to further improve the source only accuracy\nhttps://competitions.codalab.org/competitions/17052#results\nAcknowledgementThis work benefited from the support of Region Bretagne grant and OATMIL ANR-17-CE23-0012 project of the French National Research Agency (ANR). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research. The constructive comments and suggestions of anonymous reviewers are gratefully acknowledged.\nVisual domain adaptation: a survey of recent advances. V M Patel, R Gopalan, R Li, R Chellappa, IEEE SPM. 323Patel, V.M., Gopalan, R., Li, R., Chellappa, R.: Visual domain adaptation: a survey of recent advances. IEEE SPM 32(3) (2015) 53-69\n\nAdapting visual category models to new domains. K Saenko, B Kulis, M Fritz, T Darrell, ECCV. Saenko, K., Kulis, B., Fritz, M., Darrell, T.: Adapting visual category models to new domains. In: ECCV. (2010) 213-226\n\nDomain adaptation for object recognition: An unsupervised approach. R Gopalan, R Li, R Chellappa, ICCV.Gopalan, R., Li, R., Chellappa, R.: Domain adaptation for object recognition: An unsupervised approach. In: ICCV. (2011) 999-1006\n\nOptimal transport for domain adaptation. N Courty, R Flamary, D Tuia, A Rakotomamonjy, IEEE TPAMI. 399Courty, N., Flamary, R., Tuia, D., Rakotomamonjy, A.: Optimal transport for domain adaptation. IEEE TPAMI 39(9) (2017) 1853-1865\n\nJoint distribution optimal transportation for domain adaptation. N Courty, R Flamary, A Habrard, A Rakotomamonjy, Courty, N., Flamary, R., Habrard, A., Rakotomamonjy, A.: Joint distribution optimal transportation for domain adaptation. In: NIPS. (2017)\n\nDeep coral: Correlation alignment for deep domain adaptation. B Sun, K Saenko, ECCV workshops. Sun, B., Saenko, K.: Deep coral: Correlation alignment for deep domain adaptation. In: ECCV workshops. (2016) 443-450\n\nLabel efficient learning of transferable representations across domains and tasks. Z Luo, Y Zou, J Hoffman, L Fei-Fei, Luo, Z., Zou, Y., Hoffman, J., Fei-Fei, L.: Label efficient learning of transferable representations across domains and tasks. In: NIPS. (2017)\n\nDomain-adversarial training of neural networks. Y Ganin, E Ustinova, H Ajakan, P Germain, H Larochelle, F Laviolette, M Marchand, V Lempitsky, J. Mach. Learn. Res. 171Ganin, Y., Ustinova, E., Ajakan, H., Germain, P., Larochelle, H., Laviolette, F., Marchand, M., Lempitsky, V.: Domain-adversarial training of neural networks. J. Mach. Learn. Res. 17(1) (January 2016) 2096-2030\n\nCoupled generative adversarial networks. M Y Liu, O Tuzel, D D Lee, M Sugiyama, U V Luxburg, I Guyon, R Garnett, Liu, M.Y., Tuzel, O.: Coupled generative adversarial networks. In Lee, D.D., Sugiyama, M., Luxburg, U.V., Guyon, I., Garnett, R., eds.: NIPS. (2016) 469-477\n\nAnalysis of representations for domain adaptation. S Ben-David, J Blitzer, K Crammer, F Pereira, NIPS. Ben-David, S., Blitzer, J., Crammer, K., Pereira, F.: Analysis of representations for domain adaptation. In: NIPS. (2007) 137-144\n\nRobust visual domain adaptation with low-rank reconstruction. I H Jhuo, D Liu, D T Lee, S F Chang, CVPR. Jhuo, I.H., Liu, D., Lee, D.T., Chang, S.F.: Robust visual domain adaptation with low-rank reconstruction. In: CVPR. (2012) 2168-2175\n\nEfficient learning of domain-invariant image representations. J Hoffman, E Rodner, J Donahue, K Saenko, T Darrell, ICLR.Hoffman, J., Rodner, E., Donahue, J., Saenko, K., Darrell, T.: Efficient learning of domain-invariant image representations. In: ICLR. (2013)\n\nLightweight unsupervised domain adaptation by convolutional filter reconstruction. R Aljundi, T Tuytelaars, ECCV. Aljundi, R., Tuytelaars, T.: Lightweight unsupervised domain adaptation by con- volutional filter reconstruction. In: ECCV. (2016)\n\nLearning transferable features with deep adaptation networks. M Long, Y Cao, J Wang, M I Jordan, ICML. Long, M., Cao, Y., Wang, J., Jordan, M.I.: Learning transferable features with deep adaptation networks. In: ICML. (2015) 97-105\n\nUnsupervised domain adaptation with residual transfer networks. M Long, J Wang, M I Jordan, NIPS. Long, M., Wang, J., Jordan, M.I.: Unsupervised domain adaptation with residual transfer networks. In: NIPS. (2016)\n\nAssociative domain adaptation. P Haeusser, T Frerix, A Mordvintsev, D Cremers, Haeusser, P., Frerix, T., Mordvintsev, A., Cremers, D.: Associative domain adap- tation. In: ICCV. (2017)\n\nSimultaneous deep transfer across domains and tasks. E Tzeng, J Hoffman, T Darrell, K Saenko, ICCV.Tzeng, E., Hoffman, J., Darrell, T., Saenko, K.: Simultaneous deep transfer across domains and tasks. In: ICCV. (2015)\n\nUnsupervised image-to-image translation networks. M Y Liu, T Breuel, J ; Kautz, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, R Garnett, Guyon, I. Liu, M.Y., Breuel, T., Kautz, J.: Unsupervised image-to-image translation net- works. In Guyon, I., Luxburg, U.V., Bengio, S., Wallach, H., Fergus, R., Vish- wanathan, S., Garnett, R., eds.: NIPS. (2017) 700-708\n\nGenerate to adapt: Aligning domains using generative adversarial networks. S Sankaranarayanan, Y Balaji, C D Castillo, R Chellappa, CoRR abs/1704.01705Sankaranarayanan, S., Balaji, Y., Castillo, C.D., Chellappa, R.: Generate to adapt: Aligning domains using generative adversarial networks. CoRR abs/1704.01705 (2017)\n\nImage to Image Translation for Domain Adaptation. Z Murez, S Kolouri, D Kriegman, R Ramamoorthi, K Kim, ArXiv e-printsMurez, Z., Kolouri, S., Kriegman, D., Ramamoorthi, R., Kim, K.: Image to Image Translation for Domain Adaptation. ArXiv e-prints (December 2017)\n\nAdversarial discriminative domain adaptation. E Tzeng, J Hoffman, T Darrell, K Saenko, Tzeng, E., Hoffman, J., Darrell, T., Saenko, K.: Adversarial discriminative domain adaptation. In: CVPR. (2017)\n\nG Monge, M\u00e9moire sur la th\u00e9orie des d\u00e9blais et des remblais. De l'Imprimerie Royale. Monge, G.: M\u00e9moire sur la th\u00e9orie des d\u00e9blais et des remblais. De l'Imprimerie Royale (1781)\n\nOn the translocation of masses. L Kantorovich, C.R. (Doklady) Acad. Sci. URSS (N.S.). 37Kantorovich, L.: On the translocation of masses. C.R. (Doklady) Acad. Sci. URSS (N.S.) 37 (1942) 199-201\n\nOptimal transport: old and new. Grundlehren der mathematischen Wissenschaften. C Villani, SpringerVillani, C.: Optimal transport: old and new. Grundlehren der mathematischen Wissenschaften. Springer (2009)\n\nDomain adaptation with regularized optimal transport. N Courty, R Flamary, D Tuia, ECML. Courty, N., Flamary, R., Tuia, D.: Domain adaptation with regularized optimal transport. In: ECML. (2014)\n\nMapping estimation for discrete optimal transport. M Perrot, N Courty, R Flamary, A Habrard, NIPS. Perrot, M., Courty, N., Flamary, R., Habrard, A.: Mapping estimation for discrete optimal transport. In: NIPS. (2016) 4197-4205\n\nTheoretical analysis of domain adaptation with optimal transport. I Redko, A Habrard, M Sebban, ECML/PKDD. Redko, I., Habrard, A., Sebban, M.: Theoretical analysis of domain adaptation with optimal transport. In: ECML/PKDD. (2017) 737-753\n\nWasserstein distance guided representation learning for domain adaptation. J Shen, Y Qu, W Zhang, Y Yu, In: AAAI. Shen., J., Qu, Y., Zhang, W., Yu, Y.: Wasserstein distance guided representation learning for domain adaptation. In: AAAI. (2018)\n\nWasserstein generative adversarial networks. M Arjovsky, S Chintala, L Bottou, Arjovsky, M., Chintala, S., Bottou, L.: Wasserstein generative adversarial networks. In: ICML. (2017) 214-223\n\nSinkhorn distances: Lightspeed computation of optimal transportation. M Cuturi, In: NIPS. Cuturi, M.: Sinkhorn distances: Lightspeed computation of optimal transportation. In: NIPS. (2013) 2292-2300\n\nStochastic optimization for largescale optimal transport. A Genevay, M Cuturi, G Peyr\u00e9, F Bach, NIPS. Genevay, A., Cuturi, M., Peyr\u00e9, G., Bach, F.: Stochastic optimization for large- scale optimal transport. In: NIPS. (2016) 3432-3440\n\nLarge-scale optimal transport and mapping estimation. V Seguy, B Damodaran, B Flamary, R Courty, N Rolet, A Blondel, M , In: ICLR. Seguy, V., Damodaran, B, B., Flamary, R., Courty, N., Rolet, A., Blondel, M.: Large-scale optimal transport and mapping estimation. In: ICLR. (2018)\n\nIncremental learning of object detectors without catastrophic forgetting. K Shmelkov, C Schmid, K Alahari, ICCVVenice, ItalyShmelkov, K., Schmid, C., Alahari, K.: Incremental learning of object detectors without catastrophic forgetting. In: ICCV, Venice, Italy (2017)\n\nLearning without forgetting. Z Li, D Hoiem, IEEE TPAMI. in pressLi, Z., Hoiem, D.: Learning without forgetting. IEEE TPAMI (in press)\n\nA Genevay, G Peyr\u00e9, M Cuturi, arXiv:1706.00292Sinkhorn-autodiff: Tractable wasserstein learning of generative models. arXiv preprintGenevay, A., Peyr\u00e9, G., Cuturi, M.: Sinkhorn-autodiff: Tractable wasserstein learn- ing of generative models. arXiv preprint arXiv:1706.00292 (2017)\n\nGradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of the IEEE. 8611Lecun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11) (Nov 1998) 2278-2324\n\nA database for handwritten text recognition research. J J Hull, IEEE TPAMI. 165Hull, J.J.: A database for handwritten text recognition research. IEEE TPAMI 16(5) (May 1994) 550-554\n\nReading digits in natural images with unsupervised feature learning. Y Netzer, T Wang, A Coates, A Bissacco, B Wu, A Y Ng, NIPS worksophs. Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y.: Reading digits in natural images with unsupervised feature learning. In: NIPS worksophs. (2011)\n\nContour detection and hierarchical image segmentation. P Arbelaez, M Maire, C Fowlkes, J Malik, IEEE TPAMI. 335Arbelaez, P., Maire, M., Fowlkes, C., Malik, J.: Contour detection and hierarchical image segmentation. IEEE TPAMI 33(5) (May 2011) 898-916\n\nDeep reconstructionclassification networks for unsupervised domain adaptation. M Ghifary, W B Kleijn, M Zhang, D Balduzzi, W Li, ECCV.Ghifary, M., Kleijn, W.B., Zhang, M., Balduzzi, D., Li, W.: Deep reconstruction- classification networks for unsupervised domain adaptation. In: ECCV. (2016) 597-613\n\nDomain separation networks. K Bousmalis, G Trigeorgis, N Silberman, D Krishnan, D Erhan, NIPS. Bousmalis, K., Trigeorgis, G., Silberman, N., Krishnan, D., Erhan, D.: Domain separation networks. In: NIPS. (2016) 343-351\n\nSelf-ensembling for visual domain adaptation. G French, M Mackiewicz, M Fisher, International Conference on Learning Representations. French, G., Mackiewicz, M., Fisher, M.: Self-ensembling for visual domain adap- tation. In: International Conference on Learning Representations. (2018)\n\nDeep hashing network for unsupervised domain adaptation. H Venkateswara, J Eusebio, S Chakraborty, S Panchanathan, IEEE) Conference on Computer Vision and Pattern Recognition (CVPR. Venkateswara, H., Eusebio, J., Chakraborty, S., Panchanathan, S.: Deep hashing network for unsupervised domain adaptation. In: (IEEE) Conference on Computer Vision and Pattern Recognition (CVPR). (2017)\n\nK Simonyan, A Zisserman, arXiv:1409.1556Very deep convolutional networks for large-scale image recognition. arXiv preprintSimonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014)\n\nReturn of frustratingly easy domain adaptation. B Sun, J Feng, K Saenko, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. AAAI'16. the Thirtieth AAAI Conference on Artificial Intelligence. AAAI'16AAAI PressSun, B., Feng, J., Saenko, K.: Return of frustratingly easy domain adaptation. In: Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. AAAI'16, AAAI Press (2016) 2058-2065\n\nTransfer feature learning with joint distribution adaptation. M Long, J Wang, G Ding, J Sun, P S Yu, 2013 IEEE International Conference on Computer Vision. Long, M., Wang, J., Ding, G., Sun, J., Yu, P.S.: Transfer feature learning with joint distribution adaptation. In: 2013 IEEE International Conference on Computer Vision. (Dec 2013) 2200-2207\n\nLearning transferable features with deep adaptation networks. M Long, Y Cao, J Wang, M Jordan, PMLR (07-09Proceedings of the 32nd International Conference on Machine Learning. Bach, F., Blei, D.the 32nd International Conference on Machine LearningLille, France37Long, M., Cao, Y., Wang, J., Jordan, M.: Learning transferable features with deep adaptation networks. In Bach, F., Blei, D., eds.: Proceedings of the 32nd Inter- national Conference on Machine Learning. Volume 37 of Proceedings of Machine Learning Research., Lille, France, PMLR (07-09 Jul 2015) 97-105\n\nX Peng, B Usman, N Kaushik, J Hoffman, D Wang, K Saenko, Visda: The visual domain adaptation challenge. Peng, X., Usman, B., Kaushik, N., Hoffman, J., Wang, D., Saenko, K.: Visda: The visual domain adaptation challenge (2017)\n\nMicrosoft coco: Common objects in context. T Y Lin, M Maire, S Belongie, J Hays, P Perona, D Ramanan, P Doll\u00e1r, C L Zitnick, European conference on computer vision. SpringerLin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Doll\u00e1r, P., Zitnick, C.L.: Microsoft coco: Common objects in context. In: European conference on computer vision, Springer (2014) 740-755\n\nYoutubeboundingboxes: A large high-precision human-annotated data set for object detection in video. E Real, J Shlens, S Mazzocchi, X Pan, V Vanhoucke, Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference. Real, E., Shlens, J., Mazzocchi, S., Pan, X., Vanhoucke, V.: Youtube- boundingboxes: A large high-precision human-annotated data set for object de- tection in video. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, IEEE (2017) 7464-7473\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionHe, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. (2016) 770-778\n", "annotations": {"author": "[{\"end\":206,\"start\":90},{\"end\":297,\"start\":207},{\"end\":381,\"start\":298},{\"end\":432,\"start\":382},{\"end\":503,\"start\":433},{\"end\":206,\"start\":90},{\"end\":297,\"start\":207},{\"end\":381,\"start\":298},{\"end\":432,\"start\":382},{\"end\":503,\"start\":433}]", "publisher": null, "author_last_name": "[{\"end\":115,\"start\":106},{\"end\":228,\"start\":216},{\"end\":310,\"start\":303},{\"end\":392,\"start\":388},{\"end\":447,\"start\":441},{\"end\":115,\"start\":106},{\"end\":228,\"start\":216},{\"end\":310,\"start\":303},{\"end\":392,\"start\":388},{\"end\":447,\"start\":441}]", "author_first_name": "[{\"end\":97,\"start\":90},{\"end\":105,\"start\":98},{\"end\":215,\"start\":207},{\"end\":302,\"start\":298},{\"end\":387,\"start\":382},{\"end\":440,\"start\":433},{\"end\":97,\"start\":90},{\"end\":105,\"start\":98},{\"end\":215,\"start\":207},{\"end\":302,\"start\":298},{\"end\":387,\"start\":382},{\"end\":440,\"start\":433}]", "author_affiliation": "[{\"end\":205,\"start\":152},{\"end\":296,\"start\":259},{\"end\":380,\"start\":312},{\"end\":431,\"start\":394},{\"end\":502,\"start\":449},{\"end\":205,\"start\":152},{\"end\":296,\"start\":259},{\"end\":380,\"start\":312},{\"end\":431,\"start\":394},{\"end\":502,\"start\":449}]", "title": "[{\"end\":87,\"start\":1},{\"end\":590,\"start\":504},{\"end\":87,\"start\":1},{\"end\":590,\"start\":504}]", "venue": null, "abstract": "[{\"end\":1586,\"start\":633},{\"end\":1586,\"start\":633}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2505,\"start\":2502},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3651,\"start\":3648},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3653,\"start\":3651},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3661,\"start\":3658},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3839,\"start\":3836},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4131,\"start\":4128},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4777,\"start\":4774},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4780,\"start\":4777},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4783,\"start\":4780},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4786,\"start\":4783},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5922,\"start\":5918},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6002,\"start\":5999},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6005,\"start\":6002},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6008,\"start\":6005},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6196,\"start\":6193},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6216,\"start\":6212},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6325,\"start\":6321},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6329,\"start\":6325},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6333,\"start\":6329},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6521,\"start\":6518},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6523,\"start\":6521},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6526,\"start\":6523},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6612,\"start\":6608},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6615,\"start\":6612},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6674,\"start\":6671},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6758,\"start\":6754},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6830,\"start\":6826},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6885,\"start\":6881},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6889,\"start\":6885},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6893,\"start\":6889},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7166,\"start\":7162},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7687,\"start\":7683},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7691,\"start\":7687},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7695,\"start\":7691},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7778,\"start\":7775},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7781,\"start\":7778},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7784,\"start\":7781},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7829,\"start\":7825},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8246,\"start\":8242},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8428,\"start\":8424},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8776,\"start\":8773},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8869,\"start\":8865},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10198,\"start\":10194},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10272,\"start\":10268},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10275,\"start\":10272},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10278,\"start\":10275},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10388,\"start\":10385},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11800,\"start\":11797},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13858,\"start\":13855},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14776,\"start\":14772},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14779,\"start\":14776},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16153,\"start\":16149},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":16156,\"start\":16153},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":16401,\"start\":16397},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17180,\"start\":17176},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17614,\"start\":17610},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20057,\"start\":20054},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20067,\"start\":20063},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":20078,\"start\":20074},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":20088,\"start\":20084},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":20102,\"start\":20098},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":20122,\"start\":20118},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20168,\"start\":20165},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20179,\"start\":20175},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20228,\"start\":20225},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20239,\"start\":20235},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20256,\"start\":20252},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":20275,\"start\":20271},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24327,\"start\":24323},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24675,\"start\":24671},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":24735,\"start\":24731},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":24938,\"start\":24934},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24948,\"start\":24944},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":24958,\"start\":24954},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24968,\"start\":24965},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24982,\"start\":24978},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":25328,\"start\":25324},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":25466,\"start\":25462},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":25514,\"start\":25510},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":25696,\"start\":25692},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":26070,\"start\":26066},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":26378,\"start\":26375},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":26388,\"start\":26384},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":28681,\"start\":28677},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":28691,\"start\":28687},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":28746,\"start\":28742},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33811,\"start\":33807},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33888,\"start\":33884},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":34016,\"start\":34012},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2505,\"start\":2502},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3651,\"start\":3648},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3653,\"start\":3651},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3661,\"start\":3658},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3839,\"start\":3836},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4131,\"start\":4128},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4777,\"start\":4774},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4780,\"start\":4777},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4783,\"start\":4780},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4786,\"start\":4783},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5922,\"start\":5918},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6002,\"start\":5999},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6005,\"start\":6002},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6008,\"start\":6005},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6196,\"start\":6193},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6216,\"start\":6212},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6325,\"start\":6321},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6329,\"start\":6325},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6333,\"start\":6329},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6521,\"start\":6518},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6523,\"start\":6521},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6526,\"start\":6523},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6612,\"start\":6608},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6615,\"start\":6612},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6674,\"start\":6671},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6758,\"start\":6754},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6830,\"start\":6826},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6885,\"start\":6881},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6889,\"start\":6885},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6893,\"start\":6889},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7166,\"start\":7162},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7687,\"start\":7683},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7691,\"start\":7687},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7695,\"start\":7691},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7778,\"start\":7775},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7781,\"start\":7778},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7784,\"start\":7781},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7829,\"start\":7825},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8246,\"start\":8242},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8428,\"start\":8424},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8776,\"start\":8773},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8869,\"start\":8865},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10198,\"start\":10194},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10272,\"start\":10268},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10275,\"start\":10272},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10278,\"start\":10275},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10388,\"start\":10385},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11800,\"start\":11797},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13858,\"start\":13855},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14776,\"start\":14772},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14779,\"start\":14776},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16153,\"start\":16149},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":16156,\"start\":16153},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":16401,\"start\":16397},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17180,\"start\":17176},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17614,\"start\":17610},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20057,\"start\":20054},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20067,\"start\":20063},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":20078,\"start\":20074},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":20088,\"start\":20084},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":20102,\"start\":20098},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":20122,\"start\":20118},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20168,\"start\":20165},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20179,\"start\":20175},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20228,\"start\":20225},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20239,\"start\":20235},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20256,\"start\":20252},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":20275,\"start\":20271},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24327,\"start\":24323},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24675,\"start\":24671},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":24735,\"start\":24731},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":24938,\"start\":24934},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24948,\"start\":24944},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":24958,\"start\":24954},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24968,\"start\":24965},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24982,\"start\":24978},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":25328,\"start\":25324},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":25466,\"start\":25462},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":25514,\"start\":25510},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":25696,\"start\":25692},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":26070,\"start\":26066},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":26378,\"start\":26375},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":26388,\"start\":26384},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":28681,\"start\":28677},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":28691,\"start\":28687},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":28746,\"start\":28742},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33811,\"start\":33807},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33888,\"start\":33884},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":34016,\"start\":34012}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":28493,\"start\":28143},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28583,\"start\":28494},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30126,\"start\":28584},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30865,\"start\":30127},{\"attributes\":{\"id\":\"fig_4\"},\"end\":31208,\"start\":30866},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":31278,\"start\":31209},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":32495,\"start\":31279},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":32646,\"start\":32496},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":33328,\"start\":32647},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":33776,\"start\":33329},{\"attributes\":{\"id\":\"fig_0\"},\"end\":28493,\"start\":28143},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28583,\"start\":28494},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30126,\"start\":28584},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30865,\"start\":30127},{\"attributes\":{\"id\":\"fig_4\"},\"end\":31208,\"start\":30866},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":31278,\"start\":31209},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":32495,\"start\":31279},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":32646,\"start\":32496},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":33328,\"start\":32647},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":33776,\"start\":33329}]", "paragraph": "[{\"end\":3414,\"start\":1602},{\"end\":4529,\"start\":3416},{\"end\":5556,\"start\":4531},{\"end\":5695,\"start\":5558},{\"end\":7623,\"start\":5713},{\"end\":8573,\"start\":7625},{\"end\":8825,\"start\":8617},{\"end\":9215,\"start\":8847},{\"end\":9561,\"start\":9286},{\"end\":10330,\"start\":9613},{\"end\":10975,\"start\":10371},{\"end\":12535,\"start\":11056},{\"end\":13240,\"start\":12643},{\"end\":14374,\"start\":13428},{\"end\":14915,\"start\":14376},{\"end\":15354,\"start\":15036},{\"end\":15803,\"start\":15417},{\"end\":16249,\"start\":15887},{\"end\":16685,\"start\":16251},{\"end\":17891,\"start\":16810},{\"end\":17962,\"start\":17893},{\"end\":18250,\"start\":18027},{\"end\":18362,\"start\":18359},{\"end\":18645,\"start\":18364},{\"end\":18866,\"start\":18694},{\"end\":18980,\"start\":18868},{\"end\":19956,\"start\":19008},{\"end\":20005,\"start\":19958},{\"end\":20276,\"start\":20007},{\"end\":20469,\"start\":20278},{\"end\":20944,\"start\":20481},{\"end\":21305,\"start\":20946},{\"end\":22004,\"start\":21307},{\"end\":24258,\"start\":22025},{\"end\":24983,\"start\":24291},{\"end\":25226,\"start\":24985},{\"end\":25619,\"start\":25241},{\"end\":26071,\"start\":25621},{\"end\":27142,\"start\":26073},{\"end\":28142,\"start\":27158},{\"end\":3414,\"start\":1602},{\"end\":4529,\"start\":3416},{\"end\":5556,\"start\":4531},{\"end\":5695,\"start\":5558},{\"end\":7623,\"start\":5713},{\"end\":8573,\"start\":7625},{\"end\":8825,\"start\":8617},{\"end\":9215,\"start\":8847},{\"end\":9561,\"start\":9286},{\"end\":10330,\"start\":9613},{\"end\":10975,\"start\":10371},{\"end\":12535,\"start\":11056},{\"end\":13240,\"start\":12643},{\"end\":14374,\"start\":13428},{\"end\":14915,\"start\":14376},{\"end\":15354,\"start\":15036},{\"end\":15803,\"start\":15417},{\"end\":16249,\"start\":15887},{\"end\":16685,\"start\":16251},{\"end\":17891,\"start\":16810},{\"end\":17962,\"start\":17893},{\"end\":18250,\"start\":18027},{\"end\":18362,\"start\":18359},{\"end\":18645,\"start\":18364},{\"end\":18866,\"start\":18694},{\"end\":18980,\"start\":18868},{\"end\":19956,\"start\":19008},{\"end\":20005,\"start\":19958},{\"end\":20276,\"start\":20007},{\"end\":20469,\"start\":20278},{\"end\":20944,\"start\":20481},{\"end\":21305,\"start\":20946},{\"end\":22004,\"start\":21307},{\"end\":24258,\"start\":22025},{\"end\":24983,\"start\":24291},{\"end\":25226,\"start\":24985},{\"end\":25619,\"start\":25241},{\"end\":26071,\"start\":25621},{\"end\":27142,\"start\":26073},{\"end\":28142,\"start\":27158}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9285,\"start\":9216},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9612,\"start\":9562},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11055,\"start\":10976},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12570,\"start\":12536},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13319,\"start\":13241},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13427,\"start\":13319},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15035,\"start\":14916},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15886,\"start\":15804},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16809,\"start\":16686},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18026,\"start\":17963},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18358,\"start\":18251},{\"attributes\":{\"id\":\"formula_0\"},\"end\":9285,\"start\":9216},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9612,\"start\":9562},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11055,\"start\":10976},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12570,\"start\":12536},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13319,\"start\":13241},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13427,\"start\":13319},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15035,\"start\":14916},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15886,\"start\":15804},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16809,\"start\":16686},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18026,\"start\":17963},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18358,\"start\":18251}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20567,\"start\":20560},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21479,\"start\":21472},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21842,\"start\":21835},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23157,\"start\":23150},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":23608,\"start\":23601},{\"end\":24471,\"start\":24464},{\"end\":25000,\"start\":24993},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26140,\"start\":26133},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26721,\"start\":26714},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20567,\"start\":20560},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21479,\"start\":21472},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21842,\"start\":21835},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23157,\"start\":23150},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":23608,\"start\":23601},{\"end\":24471,\"start\":24464},{\"end\":25000,\"start\":24993},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26140,\"start\":26133},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26721,\"start\":26714}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1600,\"start\":1588},{\"attributes\":{\"n\":\"2\"},\"end\":5711,\"start\":5698},{\"attributes\":{\"n\":\"3\"},\"end\":8615,\"start\":8576},{\"attributes\":{\"n\":\"3.1\"},\"end\":8845,\"start\":8828},{\"attributes\":{\"n\":\"3.2\"},\"end\":10369,\"start\":10333},{\"attributes\":{\"n\":\"4\"},\"end\":12587,\"start\":12572},{\"attributes\":{\"n\":\"4.1\"},\"end\":12641,\"start\":12590},{\"attributes\":{\"n\":\"4.2\"},\"end\":15415,\"start\":15357},{\"end\":18692,\"start\":18648},{\"attributes\":{\"n\":\"5\"},\"end\":19006,\"start\":18983},{\"end\":20479,\"start\":20472},{\"end\":22023,\"start\":22007},{\"end\":24275,\"start\":24261},{\"attributes\":{\"n\":\"5.2\"},\"end\":24289,\"start\":24278},{\"attributes\":{\"n\":\"5.3\"},\"end\":25239,\"start\":25229},{\"attributes\":{\"n\":\"6\"},\"end\":27156,\"start\":27145},{\"end\":28152,\"start\":28144},{\"end\":28593,\"start\":28585},{\"end\":30136,\"start\":30128},{\"end\":30875,\"start\":30867},{\"end\":31289,\"start\":31280},{\"end\":32506,\"start\":32497},{\"end\":33339,\"start\":33330},{\"attributes\":{\"n\":\"1\"},\"end\":1600,\"start\":1588},{\"attributes\":{\"n\":\"2\"},\"end\":5711,\"start\":5698},{\"attributes\":{\"n\":\"3\"},\"end\":8615,\"start\":8576},{\"attributes\":{\"n\":\"3.1\"},\"end\":8845,\"start\":8828},{\"attributes\":{\"n\":\"3.2\"},\"end\":10369,\"start\":10333},{\"attributes\":{\"n\":\"4\"},\"end\":12587,\"start\":12572},{\"attributes\":{\"n\":\"4.1\"},\"end\":12641,\"start\":12590},{\"attributes\":{\"n\":\"4.2\"},\"end\":15415,\"start\":15357},{\"end\":18692,\"start\":18648},{\"attributes\":{\"n\":\"5\"},\"end\":19006,\"start\":18983},{\"end\":20479,\"start\":20472},{\"end\":22023,\"start\":22007},{\"end\":24275,\"start\":24261},{\"attributes\":{\"n\":\"5.2\"},\"end\":24289,\"start\":24278},{\"attributes\":{\"n\":\"5.3\"},\"end\":25239,\"start\":25229},{\"attributes\":{\"n\":\"6\"},\"end\":27156,\"start\":27145},{\"end\":28152,\"start\":28144},{\"end\":28593,\"start\":28585},{\"end\":30136,\"start\":30128},{\"end\":30875,\"start\":30867},{\"end\":31289,\"start\":31280},{\"end\":32506,\"start\":32497},{\"end\":33339,\"start\":33330}]", "table": "[{\"end\":31278,\"start\":31248},{\"end\":32495,\"start\":31798},{\"end\":32646,\"start\":32535},{\"end\":33328,\"start\":32754},{\"end\":33776,\"start\":33768},{\"end\":31278,\"start\":31248},{\"end\":32495,\"start\":31798},{\"end\":32646,\"start\":32535},{\"end\":33328,\"start\":32754},{\"end\":33776,\"start\":33768}]", "figure_caption": "[{\"end\":28493,\"start\":28154},{\"end\":28583,\"start\":28496},{\"end\":30126,\"start\":28594},{\"end\":30865,\"start\":30138},{\"end\":31208,\"start\":30877},{\"end\":31248,\"start\":31211},{\"end\":31798,\"start\":31291},{\"end\":32535,\"start\":32508},{\"end\":32754,\"start\":32649},{\"end\":33768,\"start\":33341},{\"end\":28493,\"start\":28154},{\"end\":28583,\"start\":28496},{\"end\":30126,\"start\":28594},{\"end\":30865,\"start\":30138},{\"end\":31208,\"start\":30877},{\"end\":31248,\"start\":31211},{\"end\":31798,\"start\":31291},{\"end\":32535,\"start\":32508},{\"end\":32754,\"start\":32649},{\"end\":33768,\"start\":33341}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12684,\"start\":12678},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22209,\"start\":22201},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12684,\"start\":12678},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22209,\"start\":22201}]", "bib_author_first_name": "[{\"end\":34647,\"start\":34646},{\"end\":34649,\"start\":34648},{\"end\":34658,\"start\":34657},{\"end\":34669,\"start\":34668},{\"end\":34675,\"start\":34674},{\"end\":34882,\"start\":34881},{\"end\":34892,\"start\":34891},{\"end\":34901,\"start\":34900},{\"end\":34910,\"start\":34909},{\"end\":35116,\"start\":35115},{\"end\":35127,\"start\":35126},{\"end\":35133,\"start\":35132},{\"end\":35323,\"start\":35322},{\"end\":35333,\"start\":35332},{\"end\":35344,\"start\":35343},{\"end\":35352,\"start\":35351},{\"end\":35579,\"start\":35578},{\"end\":35589,\"start\":35588},{\"end\":35600,\"start\":35599},{\"end\":35611,\"start\":35610},{\"end\":35830,\"start\":35829},{\"end\":35837,\"start\":35836},{\"end\":36065,\"start\":36064},{\"end\":36072,\"start\":36071},{\"end\":36079,\"start\":36078},{\"end\":36090,\"start\":36089},{\"end\":36294,\"start\":36293},{\"end\":36303,\"start\":36302},{\"end\":36315,\"start\":36314},{\"end\":36325,\"start\":36324},{\"end\":36336,\"start\":36335},{\"end\":36350,\"start\":36349},{\"end\":36364,\"start\":36363},{\"end\":36376,\"start\":36375},{\"end\":36666,\"start\":36665},{\"end\":36668,\"start\":36667},{\"end\":36675,\"start\":36674},{\"end\":36684,\"start\":36683},{\"end\":36686,\"start\":36685},{\"end\":36693,\"start\":36692},{\"end\":36705,\"start\":36704},{\"end\":36707,\"start\":36706},{\"end\":36718,\"start\":36717},{\"end\":36727,\"start\":36726},{\"end\":36947,\"start\":36946},{\"end\":36960,\"start\":36959},{\"end\":36971,\"start\":36970},{\"end\":36982,\"start\":36981},{\"end\":37192,\"start\":37191},{\"end\":37194,\"start\":37193},{\"end\":37202,\"start\":37201},{\"end\":37209,\"start\":37208},{\"end\":37211,\"start\":37210},{\"end\":37218,\"start\":37217},{\"end\":37220,\"start\":37219},{\"end\":37432,\"start\":37431},{\"end\":37443,\"start\":37442},{\"end\":37453,\"start\":37452},{\"end\":37464,\"start\":37463},{\"end\":37474,\"start\":37473},{\"end\":37716,\"start\":37715},{\"end\":37727,\"start\":37726},{\"end\":37941,\"start\":37940},{\"end\":37949,\"start\":37948},{\"end\":37956,\"start\":37955},{\"end\":37964,\"start\":37963},{\"end\":37966,\"start\":37965},{\"end\":38176,\"start\":38175},{\"end\":38184,\"start\":38183},{\"end\":38192,\"start\":38191},{\"end\":38194,\"start\":38193},{\"end\":38357,\"start\":38356},{\"end\":38369,\"start\":38368},{\"end\":38379,\"start\":38378},{\"end\":38394,\"start\":38393},{\"end\":38565,\"start\":38564},{\"end\":38574,\"start\":38573},{\"end\":38585,\"start\":38584},{\"end\":38596,\"start\":38595},{\"end\":38781,\"start\":38780},{\"end\":38783,\"start\":38782},{\"end\":38790,\"start\":38789},{\"end\":38800,\"start\":38799},{\"end\":38802,\"start\":38801},{\"end\":38811,\"start\":38810},{\"end\":38813,\"start\":38812},{\"end\":38824,\"start\":38823},{\"end\":38834,\"start\":38833},{\"end\":38845,\"start\":38844},{\"end\":38855,\"start\":38854},{\"end\":38871,\"start\":38870},{\"end\":39180,\"start\":39179},{\"end\":39200,\"start\":39199},{\"end\":39210,\"start\":39209},{\"end\":39212,\"start\":39211},{\"end\":39224,\"start\":39223},{\"end\":39474,\"start\":39473},{\"end\":39483,\"start\":39482},{\"end\":39494,\"start\":39493},{\"end\":39506,\"start\":39505},{\"end\":39521,\"start\":39520},{\"end\":39734,\"start\":39733},{\"end\":39743,\"start\":39742},{\"end\":39754,\"start\":39753},{\"end\":39765,\"start\":39764},{\"end\":39888,\"start\":39887},{\"end\":40099,\"start\":40098},{\"end\":40340,\"start\":40339},{\"end\":40522,\"start\":40521},{\"end\":40532,\"start\":40531},{\"end\":40543,\"start\":40542},{\"end\":40715,\"start\":40714},{\"end\":40725,\"start\":40724},{\"end\":40735,\"start\":40734},{\"end\":40746,\"start\":40745},{\"end\":40958,\"start\":40957},{\"end\":40967,\"start\":40966},{\"end\":40978,\"start\":40977},{\"end\":41207,\"start\":41206},{\"end\":41215,\"start\":41214},{\"end\":41221,\"start\":41220},{\"end\":41230,\"start\":41229},{\"end\":41422,\"start\":41421},{\"end\":41434,\"start\":41433},{\"end\":41446,\"start\":41445},{\"end\":41637,\"start\":41636},{\"end\":41825,\"start\":41824},{\"end\":41836,\"start\":41835},{\"end\":41846,\"start\":41845},{\"end\":41855,\"start\":41854},{\"end\":42057,\"start\":42056},{\"end\":42066,\"start\":42065},{\"end\":42079,\"start\":42078},{\"end\":42090,\"start\":42089},{\"end\":42100,\"start\":42099},{\"end\":42109,\"start\":42108},{\"end\":42120,\"start\":42119},{\"end\":42358,\"start\":42357},{\"end\":42370,\"start\":42369},{\"end\":42380,\"start\":42379},{\"end\":42582,\"start\":42581},{\"end\":42588,\"start\":42587},{\"end\":42688,\"start\":42687},{\"end\":42699,\"start\":42698},{\"end\":42708,\"start\":42707},{\"end\":43027,\"start\":43026},{\"end\":43036,\"start\":43035},{\"end\":43046,\"start\":43045},{\"end\":43056,\"start\":43055},{\"end\":43308,\"start\":43307},{\"end\":43310,\"start\":43309},{\"end\":43505,\"start\":43504},{\"end\":43515,\"start\":43514},{\"end\":43523,\"start\":43522},{\"end\":43533,\"start\":43532},{\"end\":43545,\"start\":43544},{\"end\":43551,\"start\":43550},{\"end\":43553,\"start\":43552},{\"end\":43793,\"start\":43792},{\"end\":43805,\"start\":43804},{\"end\":43814,\"start\":43813},{\"end\":43825,\"start\":43824},{\"end\":44069,\"start\":44068},{\"end\":44080,\"start\":44079},{\"end\":44082,\"start\":44081},{\"end\":44092,\"start\":44091},{\"end\":44101,\"start\":44100},{\"end\":44113,\"start\":44112},{\"end\":44319,\"start\":44318},{\"end\":44332,\"start\":44331},{\"end\":44346,\"start\":44345},{\"end\":44359,\"start\":44358},{\"end\":44371,\"start\":44370},{\"end\":44557,\"start\":44556},{\"end\":44567,\"start\":44566},{\"end\":44581,\"start\":44580},{\"end\":44856,\"start\":44855},{\"end\":44872,\"start\":44871},{\"end\":44883,\"start\":44882},{\"end\":44898,\"start\":44897},{\"end\":45185,\"start\":45184},{\"end\":45197,\"start\":45196},{\"end\":45491,\"start\":45490},{\"end\":45498,\"start\":45497},{\"end\":45506,\"start\":45505},{\"end\":45929,\"start\":45928},{\"end\":45937,\"start\":45936},{\"end\":45945,\"start\":45944},{\"end\":45953,\"start\":45952},{\"end\":45960,\"start\":45959},{\"end\":45962,\"start\":45961},{\"end\":46277,\"start\":46276},{\"end\":46285,\"start\":46284},{\"end\":46292,\"start\":46291},{\"end\":46300,\"start\":46299},{\"end\":46782,\"start\":46781},{\"end\":46790,\"start\":46789},{\"end\":46799,\"start\":46798},{\"end\":46810,\"start\":46809},{\"end\":46821,\"start\":46820},{\"end\":46829,\"start\":46828},{\"end\":47052,\"start\":47051},{\"end\":47054,\"start\":47053},{\"end\":47061,\"start\":47060},{\"end\":47070,\"start\":47069},{\"end\":47082,\"start\":47081},{\"end\":47090,\"start\":47089},{\"end\":47100,\"start\":47099},{\"end\":47111,\"start\":47110},{\"end\":47121,\"start\":47120},{\"end\":47123,\"start\":47122},{\"end\":47493,\"start\":47492},{\"end\":47501,\"start\":47500},{\"end\":47511,\"start\":47510},{\"end\":47524,\"start\":47523},{\"end\":47531,\"start\":47530},{\"end\":47926,\"start\":47925},{\"end\":47932,\"start\":47931},{\"end\":47941,\"start\":47940},{\"end\":47948,\"start\":47947},{\"end\":34647,\"start\":34646},{\"end\":34649,\"start\":34648},{\"end\":34658,\"start\":34657},{\"end\":34669,\"start\":34668},{\"end\":34675,\"start\":34674},{\"end\":34882,\"start\":34881},{\"end\":34892,\"start\":34891},{\"end\":34901,\"start\":34900},{\"end\":34910,\"start\":34909},{\"end\":35116,\"start\":35115},{\"end\":35127,\"start\":35126},{\"end\":35133,\"start\":35132},{\"end\":35323,\"start\":35322},{\"end\":35333,\"start\":35332},{\"end\":35344,\"start\":35343},{\"end\":35352,\"start\":35351},{\"end\":35579,\"start\":35578},{\"end\":35589,\"start\":35588},{\"end\":35600,\"start\":35599},{\"end\":35611,\"start\":35610},{\"end\":35830,\"start\":35829},{\"end\":35837,\"start\":35836},{\"end\":36065,\"start\":36064},{\"end\":36072,\"start\":36071},{\"end\":36079,\"start\":36078},{\"end\":36090,\"start\":36089},{\"end\":36294,\"start\":36293},{\"end\":36303,\"start\":36302},{\"end\":36315,\"start\":36314},{\"end\":36325,\"start\":36324},{\"end\":36336,\"start\":36335},{\"end\":36350,\"start\":36349},{\"end\":36364,\"start\":36363},{\"end\":36376,\"start\":36375},{\"end\":36666,\"start\":36665},{\"end\":36668,\"start\":36667},{\"end\":36675,\"start\":36674},{\"end\":36684,\"start\":36683},{\"end\":36686,\"start\":36685},{\"end\":36693,\"start\":36692},{\"end\":36705,\"start\":36704},{\"end\":36707,\"start\":36706},{\"end\":36718,\"start\":36717},{\"end\":36727,\"start\":36726},{\"end\":36947,\"start\":36946},{\"end\":36960,\"start\":36959},{\"end\":36971,\"start\":36970},{\"end\":36982,\"start\":36981},{\"end\":37192,\"start\":37191},{\"end\":37194,\"start\":37193},{\"end\":37202,\"start\":37201},{\"end\":37209,\"start\":37208},{\"end\":37211,\"start\":37210},{\"end\":37218,\"start\":37217},{\"end\":37220,\"start\":37219},{\"end\":37432,\"start\":37431},{\"end\":37443,\"start\":37442},{\"end\":37453,\"start\":37452},{\"end\":37464,\"start\":37463},{\"end\":37474,\"start\":37473},{\"end\":37716,\"start\":37715},{\"end\":37727,\"start\":37726},{\"end\":37941,\"start\":37940},{\"end\":37949,\"start\":37948},{\"end\":37956,\"start\":37955},{\"end\":37964,\"start\":37963},{\"end\":37966,\"start\":37965},{\"end\":38176,\"start\":38175},{\"end\":38184,\"start\":38183},{\"end\":38192,\"start\":38191},{\"end\":38194,\"start\":38193},{\"end\":38357,\"start\":38356},{\"end\":38369,\"start\":38368},{\"end\":38379,\"start\":38378},{\"end\":38394,\"start\":38393},{\"end\":38565,\"start\":38564},{\"end\":38574,\"start\":38573},{\"end\":38585,\"start\":38584},{\"end\":38596,\"start\":38595},{\"end\":38781,\"start\":38780},{\"end\":38783,\"start\":38782},{\"end\":38790,\"start\":38789},{\"end\":38800,\"start\":38799},{\"end\":38802,\"start\":38801},{\"end\":38811,\"start\":38810},{\"end\":38813,\"start\":38812},{\"end\":38824,\"start\":38823},{\"end\":38834,\"start\":38833},{\"end\":38845,\"start\":38844},{\"end\":38855,\"start\":38854},{\"end\":38871,\"start\":38870},{\"end\":39180,\"start\":39179},{\"end\":39200,\"start\":39199},{\"end\":39210,\"start\":39209},{\"end\":39212,\"start\":39211},{\"end\":39224,\"start\":39223},{\"end\":39474,\"start\":39473},{\"end\":39483,\"start\":39482},{\"end\":39494,\"start\":39493},{\"end\":39506,\"start\":39505},{\"end\":39521,\"start\":39520},{\"end\":39734,\"start\":39733},{\"end\":39743,\"start\":39742},{\"end\":39754,\"start\":39753},{\"end\":39765,\"start\":39764},{\"end\":39888,\"start\":39887},{\"end\":40099,\"start\":40098},{\"end\":40340,\"start\":40339},{\"end\":40522,\"start\":40521},{\"end\":40532,\"start\":40531},{\"end\":40543,\"start\":40542},{\"end\":40715,\"start\":40714},{\"end\":40725,\"start\":40724},{\"end\":40735,\"start\":40734},{\"end\":40746,\"start\":40745},{\"end\":40958,\"start\":40957},{\"end\":40967,\"start\":40966},{\"end\":40978,\"start\":40977},{\"end\":41207,\"start\":41206},{\"end\":41215,\"start\":41214},{\"end\":41221,\"start\":41220},{\"end\":41230,\"start\":41229},{\"end\":41422,\"start\":41421},{\"end\":41434,\"start\":41433},{\"end\":41446,\"start\":41445},{\"end\":41637,\"start\":41636},{\"end\":41825,\"start\":41824},{\"end\":41836,\"start\":41835},{\"end\":41846,\"start\":41845},{\"end\":41855,\"start\":41854},{\"end\":42057,\"start\":42056},{\"end\":42066,\"start\":42065},{\"end\":42079,\"start\":42078},{\"end\":42090,\"start\":42089},{\"end\":42100,\"start\":42099},{\"end\":42109,\"start\":42108},{\"end\":42120,\"start\":42119},{\"end\":42358,\"start\":42357},{\"end\":42370,\"start\":42369},{\"end\":42380,\"start\":42379},{\"end\":42582,\"start\":42581},{\"end\":42588,\"start\":42587},{\"end\":42688,\"start\":42687},{\"end\":42699,\"start\":42698},{\"end\":42708,\"start\":42707},{\"end\":43027,\"start\":43026},{\"end\":43036,\"start\":43035},{\"end\":43046,\"start\":43045},{\"end\":43056,\"start\":43055},{\"end\":43308,\"start\":43307},{\"end\":43310,\"start\":43309},{\"end\":43505,\"start\":43504},{\"end\":43515,\"start\":43514},{\"end\":43523,\"start\":43522},{\"end\":43533,\"start\":43532},{\"end\":43545,\"start\":43544},{\"end\":43551,\"start\":43550},{\"end\":43553,\"start\":43552},{\"end\":43793,\"start\":43792},{\"end\":43805,\"start\":43804},{\"end\":43814,\"start\":43813},{\"end\":43825,\"start\":43824},{\"end\":44069,\"start\":44068},{\"end\":44080,\"start\":44079},{\"end\":44082,\"start\":44081},{\"end\":44092,\"start\":44091},{\"end\":44101,\"start\":44100},{\"end\":44113,\"start\":44112},{\"end\":44319,\"start\":44318},{\"end\":44332,\"start\":44331},{\"end\":44346,\"start\":44345},{\"end\":44359,\"start\":44358},{\"end\":44371,\"start\":44370},{\"end\":44557,\"start\":44556},{\"end\":44567,\"start\":44566},{\"end\":44581,\"start\":44580},{\"end\":44856,\"start\":44855},{\"end\":44872,\"start\":44871},{\"end\":44883,\"start\":44882},{\"end\":44898,\"start\":44897},{\"end\":45185,\"start\":45184},{\"end\":45197,\"start\":45196},{\"end\":45491,\"start\":45490},{\"end\":45498,\"start\":45497},{\"end\":45506,\"start\":45505},{\"end\":45929,\"start\":45928},{\"end\":45937,\"start\":45936},{\"end\":45945,\"start\":45944},{\"end\":45953,\"start\":45952},{\"end\":45960,\"start\":45959},{\"end\":45962,\"start\":45961},{\"end\":46277,\"start\":46276},{\"end\":46285,\"start\":46284},{\"end\":46292,\"start\":46291},{\"end\":46300,\"start\":46299},{\"end\":46782,\"start\":46781},{\"end\":46790,\"start\":46789},{\"end\":46799,\"start\":46798},{\"end\":46810,\"start\":46809},{\"end\":46821,\"start\":46820},{\"end\":46829,\"start\":46828},{\"end\":47052,\"start\":47051},{\"end\":47054,\"start\":47053},{\"end\":47061,\"start\":47060},{\"end\":47070,\"start\":47069},{\"end\":47082,\"start\":47081},{\"end\":47090,\"start\":47089},{\"end\":47100,\"start\":47099},{\"end\":47111,\"start\":47110},{\"end\":47121,\"start\":47120},{\"end\":47123,\"start\":47122},{\"end\":47493,\"start\":47492},{\"end\":47501,\"start\":47500},{\"end\":47511,\"start\":47510},{\"end\":47524,\"start\":47523},{\"end\":47531,\"start\":47530},{\"end\":47926,\"start\":47925},{\"end\":47932,\"start\":47931},{\"end\":47941,\"start\":47940},{\"end\":47948,\"start\":47947}]", "bib_author_last_name": "[{\"end\":34655,\"start\":34650},{\"end\":34666,\"start\":34659},{\"end\":34672,\"start\":34670},{\"end\":34685,\"start\":34676},{\"end\":34889,\"start\":34883},{\"end\":34898,\"start\":34893},{\"end\":34907,\"start\":34902},{\"end\":34918,\"start\":34911},{\"end\":35124,\"start\":35117},{\"end\":35130,\"start\":35128},{\"end\":35143,\"start\":35134},{\"end\":35330,\"start\":35324},{\"end\":35341,\"start\":35334},{\"end\":35349,\"start\":35345},{\"end\":35366,\"start\":35353},{\"end\":35586,\"start\":35580},{\"end\":35597,\"start\":35590},{\"end\":35608,\"start\":35601},{\"end\":35625,\"start\":35612},{\"end\":35834,\"start\":35831},{\"end\":35844,\"start\":35838},{\"end\":36069,\"start\":36066},{\"end\":36076,\"start\":36073},{\"end\":36087,\"start\":36080},{\"end\":36098,\"start\":36091},{\"end\":36300,\"start\":36295},{\"end\":36312,\"start\":36304},{\"end\":36322,\"start\":36316},{\"end\":36333,\"start\":36326},{\"end\":36347,\"start\":36337},{\"end\":36361,\"start\":36351},{\"end\":36373,\"start\":36365},{\"end\":36386,\"start\":36377},{\"end\":36672,\"start\":36669},{\"end\":36681,\"start\":36676},{\"end\":36690,\"start\":36687},{\"end\":36702,\"start\":36694},{\"end\":36715,\"start\":36708},{\"end\":36724,\"start\":36719},{\"end\":36735,\"start\":36728},{\"end\":36957,\"start\":36948},{\"end\":36968,\"start\":36961},{\"end\":36979,\"start\":36972},{\"end\":36990,\"start\":36983},{\"end\":37199,\"start\":37195},{\"end\":37206,\"start\":37203},{\"end\":37215,\"start\":37212},{\"end\":37226,\"start\":37221},{\"end\":37440,\"start\":37433},{\"end\":37450,\"start\":37444},{\"end\":37461,\"start\":37454},{\"end\":37471,\"start\":37465},{\"end\":37482,\"start\":37475},{\"end\":37724,\"start\":37717},{\"end\":37738,\"start\":37728},{\"end\":37946,\"start\":37942},{\"end\":37953,\"start\":37950},{\"end\":37961,\"start\":37957},{\"end\":37973,\"start\":37967},{\"end\":38181,\"start\":38177},{\"end\":38189,\"start\":38185},{\"end\":38201,\"start\":38195},{\"end\":38366,\"start\":38358},{\"end\":38376,\"start\":38370},{\"end\":38391,\"start\":38380},{\"end\":38402,\"start\":38395},{\"end\":38571,\"start\":38566},{\"end\":38582,\"start\":38575},{\"end\":38593,\"start\":38586},{\"end\":38603,\"start\":38597},{\"end\":38787,\"start\":38784},{\"end\":38797,\"start\":38791},{\"end\":38808,\"start\":38803},{\"end\":38821,\"start\":38814},{\"end\":38831,\"start\":38825},{\"end\":38842,\"start\":38835},{\"end\":38852,\"start\":38846},{\"end\":38868,\"start\":38856},{\"end\":38879,\"start\":38872},{\"end\":39197,\"start\":39181},{\"end\":39207,\"start\":39201},{\"end\":39221,\"start\":39213},{\"end\":39234,\"start\":39225},{\"end\":39480,\"start\":39475},{\"end\":39491,\"start\":39484},{\"end\":39503,\"start\":39495},{\"end\":39518,\"start\":39507},{\"end\":39525,\"start\":39522},{\"end\":39740,\"start\":39735},{\"end\":39751,\"start\":39744},{\"end\":39762,\"start\":39755},{\"end\":39772,\"start\":39766},{\"end\":39894,\"start\":39889},{\"end\":40111,\"start\":40100},{\"end\":40348,\"start\":40341},{\"end\":40529,\"start\":40523},{\"end\":40540,\"start\":40533},{\"end\":40548,\"start\":40544},{\"end\":40722,\"start\":40716},{\"end\":40732,\"start\":40726},{\"end\":40743,\"start\":40736},{\"end\":40754,\"start\":40747},{\"end\":40964,\"start\":40959},{\"end\":40975,\"start\":40968},{\"end\":40985,\"start\":40979},{\"end\":41212,\"start\":41208},{\"end\":41218,\"start\":41216},{\"end\":41227,\"start\":41222},{\"end\":41233,\"start\":41231},{\"end\":41431,\"start\":41423},{\"end\":41443,\"start\":41435},{\"end\":41453,\"start\":41447},{\"end\":41644,\"start\":41638},{\"end\":41833,\"start\":41826},{\"end\":41843,\"start\":41837},{\"end\":41852,\"start\":41847},{\"end\":41860,\"start\":41856},{\"end\":42063,\"start\":42058},{\"end\":42076,\"start\":42067},{\"end\":42087,\"start\":42080},{\"end\":42097,\"start\":42091},{\"end\":42106,\"start\":42101},{\"end\":42117,\"start\":42110},{\"end\":42367,\"start\":42359},{\"end\":42377,\"start\":42371},{\"end\":42388,\"start\":42381},{\"end\":42585,\"start\":42583},{\"end\":42594,\"start\":42589},{\"end\":42696,\"start\":42689},{\"end\":42705,\"start\":42700},{\"end\":42715,\"start\":42709},{\"end\":43033,\"start\":43028},{\"end\":43043,\"start\":43037},{\"end\":43053,\"start\":43047},{\"end\":43064,\"start\":43057},{\"end\":43315,\"start\":43311},{\"end\":43512,\"start\":43506},{\"end\":43520,\"start\":43516},{\"end\":43530,\"start\":43524},{\"end\":43542,\"start\":43534},{\"end\":43548,\"start\":43546},{\"end\":43556,\"start\":43554},{\"end\":43802,\"start\":43794},{\"end\":43811,\"start\":43806},{\"end\":43822,\"start\":43815},{\"end\":43831,\"start\":43826},{\"end\":44077,\"start\":44070},{\"end\":44089,\"start\":44083},{\"end\":44098,\"start\":44093},{\"end\":44110,\"start\":44102},{\"end\":44116,\"start\":44114},{\"end\":44329,\"start\":44320},{\"end\":44343,\"start\":44333},{\"end\":44356,\"start\":44347},{\"end\":44368,\"start\":44360},{\"end\":44377,\"start\":44372},{\"end\":44564,\"start\":44558},{\"end\":44578,\"start\":44568},{\"end\":44588,\"start\":44582},{\"end\":44869,\"start\":44857},{\"end\":44880,\"start\":44873},{\"end\":44895,\"start\":44884},{\"end\":44911,\"start\":44899},{\"end\":45194,\"start\":45186},{\"end\":45207,\"start\":45198},{\"end\":45495,\"start\":45492},{\"end\":45503,\"start\":45499},{\"end\":45513,\"start\":45507},{\"end\":45934,\"start\":45930},{\"end\":45942,\"start\":45938},{\"end\":45950,\"start\":45946},{\"end\":45957,\"start\":45954},{\"end\":45965,\"start\":45963},{\"end\":46282,\"start\":46278},{\"end\":46289,\"start\":46286},{\"end\":46297,\"start\":46293},{\"end\":46307,\"start\":46301},{\"end\":46787,\"start\":46783},{\"end\":46796,\"start\":46791},{\"end\":46807,\"start\":46800},{\"end\":46818,\"start\":46811},{\"end\":46826,\"start\":46822},{\"end\":46836,\"start\":46830},{\"end\":47058,\"start\":47055},{\"end\":47067,\"start\":47062},{\"end\":47079,\"start\":47071},{\"end\":47087,\"start\":47083},{\"end\":47097,\"start\":47091},{\"end\":47108,\"start\":47101},{\"end\":47118,\"start\":47112},{\"end\":47131,\"start\":47124},{\"end\":47498,\"start\":47494},{\"end\":47508,\"start\":47502},{\"end\":47521,\"start\":47512},{\"end\":47528,\"start\":47525},{\"end\":47541,\"start\":47532},{\"end\":47929,\"start\":47927},{\"end\":47938,\"start\":47933},{\"end\":47945,\"start\":47942},{\"end\":47952,\"start\":47949},{\"end\":34655,\"start\":34650},{\"end\":34666,\"start\":34659},{\"end\":34672,\"start\":34670},{\"end\":34685,\"start\":34676},{\"end\":34889,\"start\":34883},{\"end\":34898,\"start\":34893},{\"end\":34907,\"start\":34902},{\"end\":34918,\"start\":34911},{\"end\":35124,\"start\":35117},{\"end\":35130,\"start\":35128},{\"end\":35143,\"start\":35134},{\"end\":35330,\"start\":35324},{\"end\":35341,\"start\":35334},{\"end\":35349,\"start\":35345},{\"end\":35366,\"start\":35353},{\"end\":35586,\"start\":35580},{\"end\":35597,\"start\":35590},{\"end\":35608,\"start\":35601},{\"end\":35625,\"start\":35612},{\"end\":35834,\"start\":35831},{\"end\":35844,\"start\":35838},{\"end\":36069,\"start\":36066},{\"end\":36076,\"start\":36073},{\"end\":36087,\"start\":36080},{\"end\":36098,\"start\":36091},{\"end\":36300,\"start\":36295},{\"end\":36312,\"start\":36304},{\"end\":36322,\"start\":36316},{\"end\":36333,\"start\":36326},{\"end\":36347,\"start\":36337},{\"end\":36361,\"start\":36351},{\"end\":36373,\"start\":36365},{\"end\":36386,\"start\":36377},{\"end\":36672,\"start\":36669},{\"end\":36681,\"start\":36676},{\"end\":36690,\"start\":36687},{\"end\":36702,\"start\":36694},{\"end\":36715,\"start\":36708},{\"end\":36724,\"start\":36719},{\"end\":36735,\"start\":36728},{\"end\":36957,\"start\":36948},{\"end\":36968,\"start\":36961},{\"end\":36979,\"start\":36972},{\"end\":36990,\"start\":36983},{\"end\":37199,\"start\":37195},{\"end\":37206,\"start\":37203},{\"end\":37215,\"start\":37212},{\"end\":37226,\"start\":37221},{\"end\":37440,\"start\":37433},{\"end\":37450,\"start\":37444},{\"end\":37461,\"start\":37454},{\"end\":37471,\"start\":37465},{\"end\":37482,\"start\":37475},{\"end\":37724,\"start\":37717},{\"end\":37738,\"start\":37728},{\"end\":37946,\"start\":37942},{\"end\":37953,\"start\":37950},{\"end\":37961,\"start\":37957},{\"end\":37973,\"start\":37967},{\"end\":38181,\"start\":38177},{\"end\":38189,\"start\":38185},{\"end\":38201,\"start\":38195},{\"end\":38366,\"start\":38358},{\"end\":38376,\"start\":38370},{\"end\":38391,\"start\":38380},{\"end\":38402,\"start\":38395},{\"end\":38571,\"start\":38566},{\"end\":38582,\"start\":38575},{\"end\":38593,\"start\":38586},{\"end\":38603,\"start\":38597},{\"end\":38787,\"start\":38784},{\"end\":38797,\"start\":38791},{\"end\":38808,\"start\":38803},{\"end\":38821,\"start\":38814},{\"end\":38831,\"start\":38825},{\"end\":38842,\"start\":38835},{\"end\":38852,\"start\":38846},{\"end\":38868,\"start\":38856},{\"end\":38879,\"start\":38872},{\"end\":39197,\"start\":39181},{\"end\":39207,\"start\":39201},{\"end\":39221,\"start\":39213},{\"end\":39234,\"start\":39225},{\"end\":39480,\"start\":39475},{\"end\":39491,\"start\":39484},{\"end\":39503,\"start\":39495},{\"end\":39518,\"start\":39507},{\"end\":39525,\"start\":39522},{\"end\":39740,\"start\":39735},{\"end\":39751,\"start\":39744},{\"end\":39762,\"start\":39755},{\"end\":39772,\"start\":39766},{\"end\":39894,\"start\":39889},{\"end\":40111,\"start\":40100},{\"end\":40348,\"start\":40341},{\"end\":40529,\"start\":40523},{\"end\":40540,\"start\":40533},{\"end\":40548,\"start\":40544},{\"end\":40722,\"start\":40716},{\"end\":40732,\"start\":40726},{\"end\":40743,\"start\":40736},{\"end\":40754,\"start\":40747},{\"end\":40964,\"start\":40959},{\"end\":40975,\"start\":40968},{\"end\":40985,\"start\":40979},{\"end\":41212,\"start\":41208},{\"end\":41218,\"start\":41216},{\"end\":41227,\"start\":41222},{\"end\":41233,\"start\":41231},{\"end\":41431,\"start\":41423},{\"end\":41443,\"start\":41435},{\"end\":41453,\"start\":41447},{\"end\":41644,\"start\":41638},{\"end\":41833,\"start\":41826},{\"end\":41843,\"start\":41837},{\"end\":41852,\"start\":41847},{\"end\":41860,\"start\":41856},{\"end\":42063,\"start\":42058},{\"end\":42076,\"start\":42067},{\"end\":42087,\"start\":42080},{\"end\":42097,\"start\":42091},{\"end\":42106,\"start\":42101},{\"end\":42117,\"start\":42110},{\"end\":42367,\"start\":42359},{\"end\":42377,\"start\":42371},{\"end\":42388,\"start\":42381},{\"end\":42585,\"start\":42583},{\"end\":42594,\"start\":42589},{\"end\":42696,\"start\":42689},{\"end\":42705,\"start\":42700},{\"end\":42715,\"start\":42709},{\"end\":43033,\"start\":43028},{\"end\":43043,\"start\":43037},{\"end\":43053,\"start\":43047},{\"end\":43064,\"start\":43057},{\"end\":43315,\"start\":43311},{\"end\":43512,\"start\":43506},{\"end\":43520,\"start\":43516},{\"end\":43530,\"start\":43524},{\"end\":43542,\"start\":43534},{\"end\":43548,\"start\":43546},{\"end\":43556,\"start\":43554},{\"end\":43802,\"start\":43794},{\"end\":43811,\"start\":43806},{\"end\":43822,\"start\":43815},{\"end\":43831,\"start\":43826},{\"end\":44077,\"start\":44070},{\"end\":44089,\"start\":44083},{\"end\":44098,\"start\":44093},{\"end\":44110,\"start\":44102},{\"end\":44116,\"start\":44114},{\"end\":44329,\"start\":44320},{\"end\":44343,\"start\":44333},{\"end\":44356,\"start\":44347},{\"end\":44368,\"start\":44360},{\"end\":44377,\"start\":44372},{\"end\":44564,\"start\":44558},{\"end\":44578,\"start\":44568},{\"end\":44588,\"start\":44582},{\"end\":44869,\"start\":44857},{\"end\":44880,\"start\":44873},{\"end\":44895,\"start\":44884},{\"end\":44911,\"start\":44899},{\"end\":45194,\"start\":45186},{\"end\":45207,\"start\":45198},{\"end\":45495,\"start\":45492},{\"end\":45503,\"start\":45499},{\"end\":45513,\"start\":45507},{\"end\":45934,\"start\":45930},{\"end\":45942,\"start\":45938},{\"end\":45950,\"start\":45946},{\"end\":45957,\"start\":45954},{\"end\":45965,\"start\":45963},{\"end\":46282,\"start\":46278},{\"end\":46289,\"start\":46286},{\"end\":46297,\"start\":46293},{\"end\":46307,\"start\":46301},{\"end\":46787,\"start\":46783},{\"end\":46796,\"start\":46791},{\"end\":46807,\"start\":46800},{\"end\":46818,\"start\":46811},{\"end\":46826,\"start\":46822},{\"end\":46836,\"start\":46830},{\"end\":47058,\"start\":47055},{\"end\":47067,\"start\":47062},{\"end\":47079,\"start\":47071},{\"end\":47087,\"start\":47083},{\"end\":47097,\"start\":47091},{\"end\":47108,\"start\":47101},{\"end\":47118,\"start\":47112},{\"end\":47131,\"start\":47124},{\"end\":47498,\"start\":47494},{\"end\":47508,\"start\":47502},{\"end\":47521,\"start\":47512},{\"end\":47528,\"start\":47525},{\"end\":47541,\"start\":47532},{\"end\":47929,\"start\":47927},{\"end\":47938,\"start\":47933},{\"end\":47945,\"start\":47942},{\"end\":47952,\"start\":47949}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":918513},\"end\":34831,\"start\":34591},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":7534823},\"end\":35045,\"start\":34833},{\"attributes\":{\"id\":\"b2\"},\"end\":35279,\"start\":35047},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":13347901},\"end\":35511,\"start\":35281},{\"attributes\":{\"id\":\"b4\"},\"end\":35765,\"start\":35513},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":12453047},\"end\":35979,\"start\":35767},{\"attributes\":{\"id\":\"b6\"},\"end\":36243,\"start\":35981},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":2871880},\"end\":36622,\"start\":36245},{\"attributes\":{\"id\":\"b8\"},\"end\":36893,\"start\":36624},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":10908021},\"end\":37127,\"start\":36895},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7176806},\"end\":37367,\"start\":37129},{\"attributes\":{\"id\":\"b11\"},\"end\":37630,\"start\":37369},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":18201210},\"end\":37876,\"start\":37632},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":556999},\"end\":38109,\"start\":37878},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":745350},\"end\":38323,\"start\":38111},{\"attributes\":{\"id\":\"b15\"},\"end\":38509,\"start\":38325},{\"attributes\":{\"id\":\"b16\"},\"end\":38728,\"start\":38511},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3783306},\"end\":39102,\"start\":38730},{\"attributes\":{\"doi\":\"CoRR abs/1704.01705\",\"id\":\"b18\"},\"end\":39421,\"start\":39104},{\"attributes\":{\"id\":\"b19\"},\"end\":39685,\"start\":39423},{\"attributes\":{\"id\":\"b20\"},\"end\":39885,\"start\":39687},{\"attributes\":{\"id\":\"b21\"},\"end\":40064,\"start\":39887},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":122853046},\"end\":40258,\"start\":40066},{\"attributes\":{\"id\":\"b23\"},\"end\":40465,\"start\":40260},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":18945224},\"end\":40661,\"start\":40467},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":11198605},\"end\":40889,\"start\":40663},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":5111106},\"end\":41129,\"start\":40891},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3861990},\"end\":41374,\"start\":41131},{\"attributes\":{\"id\":\"b28\"},\"end\":41564,\"start\":41376},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":61675022},\"end\":41764,\"start\":41566},{\"attributes\":{\"id\":\"b30\"},\"end\":42000,\"start\":41766},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":88522390},\"end\":42281,\"start\":42002},{\"attributes\":{\"id\":\"b32\"},\"end\":42550,\"start\":42283},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":4853851},\"end\":42685,\"start\":42552},{\"attributes\":{\"doi\":\"arXiv:1706.00292\",\"id\":\"b34\"},\"end\":42967,\"start\":42687},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":14542261},\"end\":43251,\"start\":42969},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":8148915},\"end\":43433,\"start\":43253},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":16852518},\"end\":43735,\"start\":43435},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":206764694},\"end\":43987,\"start\":43737},{\"attributes\":{\"id\":\"b39\"},\"end\":44288,\"start\":43989},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":2127515},\"end\":44508,\"start\":44290},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":3411732},\"end\":44796,\"start\":44510},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":2928248},\"end\":45182,\"start\":44798},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b43\"},\"end\":45440,\"start\":45184},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":16439870},\"end\":45864,\"start\":45442},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":13798326},\"end\":46212,\"start\":45866},{\"attributes\":{\"doi\":\"PMLR (07-09\",\"id\":\"b46\",\"matched_paper_id\":556999},\"end\":46779,\"start\":46214},{\"attributes\":{\"id\":\"b47\"},\"end\":47006,\"start\":46781},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":14113767},\"end\":47389,\"start\":47008},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":7705765},\"end\":47877,\"start\":47391},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":206594692},\"end\":48275,\"start\":47879},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":918513},\"end\":34831,\"start\":34591},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":7534823},\"end\":35045,\"start\":34833},{\"attributes\":{\"id\":\"b2\"},\"end\":35279,\"start\":35047},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":13347901},\"end\":35511,\"start\":35281},{\"attributes\":{\"id\":\"b4\"},\"end\":35765,\"start\":35513},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":12453047},\"end\":35979,\"start\":35767},{\"attributes\":{\"id\":\"b6\"},\"end\":36243,\"start\":35981},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":2871880},\"end\":36622,\"start\":36245},{\"attributes\":{\"id\":\"b8\"},\"end\":36893,\"start\":36624},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":10908021},\"end\":37127,\"start\":36895},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7176806},\"end\":37367,\"start\":37129},{\"attributes\":{\"id\":\"b11\"},\"end\":37630,\"start\":37369},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":18201210},\"end\":37876,\"start\":37632},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":556999},\"end\":38109,\"start\":37878},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":745350},\"end\":38323,\"start\":38111},{\"attributes\":{\"id\":\"b15\"},\"end\":38509,\"start\":38325},{\"attributes\":{\"id\":\"b16\"},\"end\":38728,\"start\":38511},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3783306},\"end\":39102,\"start\":38730},{\"attributes\":{\"doi\":\"CoRR abs/1704.01705\",\"id\":\"b18\"},\"end\":39421,\"start\":39104},{\"attributes\":{\"id\":\"b19\"},\"end\":39685,\"start\":39423},{\"attributes\":{\"id\":\"b20\"},\"end\":39885,\"start\":39687},{\"attributes\":{\"id\":\"b21\"},\"end\":40064,\"start\":39887},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":122853046},\"end\":40258,\"start\":40066},{\"attributes\":{\"id\":\"b23\"},\"end\":40465,\"start\":40260},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":18945224},\"end\":40661,\"start\":40467},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":11198605},\"end\":40889,\"start\":40663},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":5111106},\"end\":41129,\"start\":40891},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3861990},\"end\":41374,\"start\":41131},{\"attributes\":{\"id\":\"b28\"},\"end\":41564,\"start\":41376},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":61675022},\"end\":41764,\"start\":41566},{\"attributes\":{\"id\":\"b30\"},\"end\":42000,\"start\":41766},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":88522390},\"end\":42281,\"start\":42002},{\"attributes\":{\"id\":\"b32\"},\"end\":42550,\"start\":42283},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":4853851},\"end\":42685,\"start\":42552},{\"attributes\":{\"doi\":\"arXiv:1706.00292\",\"id\":\"b34\"},\"end\":42967,\"start\":42687},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":14542261},\"end\":43251,\"start\":42969},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":8148915},\"end\":43433,\"start\":43253},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":16852518},\"end\":43735,\"start\":43435},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":206764694},\"end\":43987,\"start\":43737},{\"attributes\":{\"id\":\"b39\"},\"end\":44288,\"start\":43989},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":2127515},\"end\":44508,\"start\":44290},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":3411732},\"end\":44796,\"start\":44510},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":2928248},\"end\":45182,\"start\":44798},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b43\"},\"end\":45440,\"start\":45184},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":16439870},\"end\":45864,\"start\":45442},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":13798326},\"end\":46212,\"start\":45866},{\"attributes\":{\"doi\":\"PMLR (07-09\",\"id\":\"b46\",\"matched_paper_id\":556999},\"end\":46779,\"start\":46214},{\"attributes\":{\"id\":\"b47\"},\"end\":47006,\"start\":46781},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":14113767},\"end\":47389,\"start\":47008},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":7705765},\"end\":47877,\"start\":47391},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":206594692},\"end\":48275,\"start\":47879}]", "bib_title": "[{\"end\":34644,\"start\":34591},{\"end\":34879,\"start\":34833},{\"end\":35320,\"start\":35281},{\"end\":35827,\"start\":35767},{\"end\":36291,\"start\":36245},{\"end\":36944,\"start\":36895},{\"end\":37189,\"start\":37129},{\"end\":37713,\"start\":37632},{\"end\":37938,\"start\":37878},{\"end\":38173,\"start\":38111},{\"end\":38778,\"start\":38730},{\"end\":40096,\"start\":40066},{\"end\":40519,\"start\":40467},{\"end\":40712,\"start\":40663},{\"end\":40955,\"start\":40891},{\"end\":41204,\"start\":41131},{\"end\":41634,\"start\":41566},{\"end\":41822,\"start\":41766},{\"end\":42054,\"start\":42002},{\"end\":42579,\"start\":42552},{\"end\":43024,\"start\":42969},{\"end\":43305,\"start\":43253},{\"end\":43502,\"start\":43435},{\"end\":43790,\"start\":43737},{\"end\":44316,\"start\":44290},{\"end\":44554,\"start\":44510},{\"end\":44853,\"start\":44798},{\"end\":45488,\"start\":45442},{\"end\":45926,\"start\":45866},{\"end\":46274,\"start\":46214},{\"end\":47049,\"start\":47008},{\"end\":47490,\"start\":47391},{\"end\":47923,\"start\":47879},{\"end\":34644,\"start\":34591},{\"end\":34879,\"start\":34833},{\"end\":35320,\"start\":35281},{\"end\":35827,\"start\":35767},{\"end\":36291,\"start\":36245},{\"end\":36944,\"start\":36895},{\"end\":37189,\"start\":37129},{\"end\":37713,\"start\":37632},{\"end\":37938,\"start\":37878},{\"end\":38173,\"start\":38111},{\"end\":38778,\"start\":38730},{\"end\":40096,\"start\":40066},{\"end\":40519,\"start\":40467},{\"end\":40712,\"start\":40663},{\"end\":40955,\"start\":40891},{\"end\":41204,\"start\":41131},{\"end\":41634,\"start\":41566},{\"end\":41822,\"start\":41766},{\"end\":42054,\"start\":42002},{\"end\":42579,\"start\":42552},{\"end\":43024,\"start\":42969},{\"end\":43305,\"start\":43253},{\"end\":43502,\"start\":43435},{\"end\":43790,\"start\":43737},{\"end\":44316,\"start\":44290},{\"end\":44554,\"start\":44510},{\"end\":44853,\"start\":44798},{\"end\":45488,\"start\":45442},{\"end\":45926,\"start\":45866},{\"end\":46274,\"start\":46214},{\"end\":47049,\"start\":47008},{\"end\":47490,\"start\":47391},{\"end\":47923,\"start\":47879}]", "bib_author": "[{\"end\":34657,\"start\":34646},{\"end\":34668,\"start\":34657},{\"end\":34674,\"start\":34668},{\"end\":34687,\"start\":34674},{\"end\":34891,\"start\":34881},{\"end\":34900,\"start\":34891},{\"end\":34909,\"start\":34900},{\"end\":34920,\"start\":34909},{\"end\":35126,\"start\":35115},{\"end\":35132,\"start\":35126},{\"end\":35145,\"start\":35132},{\"end\":35332,\"start\":35322},{\"end\":35343,\"start\":35332},{\"end\":35351,\"start\":35343},{\"end\":35368,\"start\":35351},{\"end\":35588,\"start\":35578},{\"end\":35599,\"start\":35588},{\"end\":35610,\"start\":35599},{\"end\":35627,\"start\":35610},{\"end\":35836,\"start\":35829},{\"end\":35846,\"start\":35836},{\"end\":36071,\"start\":36064},{\"end\":36078,\"start\":36071},{\"end\":36089,\"start\":36078},{\"end\":36100,\"start\":36089},{\"end\":36302,\"start\":36293},{\"end\":36314,\"start\":36302},{\"end\":36324,\"start\":36314},{\"end\":36335,\"start\":36324},{\"end\":36349,\"start\":36335},{\"end\":36363,\"start\":36349},{\"end\":36375,\"start\":36363},{\"end\":36388,\"start\":36375},{\"end\":36674,\"start\":36665},{\"end\":36683,\"start\":36674},{\"end\":36692,\"start\":36683},{\"end\":36704,\"start\":36692},{\"end\":36717,\"start\":36704},{\"end\":36726,\"start\":36717},{\"end\":36737,\"start\":36726},{\"end\":36959,\"start\":36946},{\"end\":36970,\"start\":36959},{\"end\":36981,\"start\":36970},{\"end\":36992,\"start\":36981},{\"end\":37201,\"start\":37191},{\"end\":37208,\"start\":37201},{\"end\":37217,\"start\":37208},{\"end\":37228,\"start\":37217},{\"end\":37442,\"start\":37431},{\"end\":37452,\"start\":37442},{\"end\":37463,\"start\":37452},{\"end\":37473,\"start\":37463},{\"end\":37484,\"start\":37473},{\"end\":37726,\"start\":37715},{\"end\":37740,\"start\":37726},{\"end\":37948,\"start\":37940},{\"end\":37955,\"start\":37948},{\"end\":37963,\"start\":37955},{\"end\":37975,\"start\":37963},{\"end\":38183,\"start\":38175},{\"end\":38191,\"start\":38183},{\"end\":38203,\"start\":38191},{\"end\":38368,\"start\":38356},{\"end\":38378,\"start\":38368},{\"end\":38393,\"start\":38378},{\"end\":38404,\"start\":38393},{\"end\":38573,\"start\":38564},{\"end\":38584,\"start\":38573},{\"end\":38595,\"start\":38584},{\"end\":38605,\"start\":38595},{\"end\":38789,\"start\":38780},{\"end\":38799,\"start\":38789},{\"end\":38810,\"start\":38799},{\"end\":38823,\"start\":38810},{\"end\":38833,\"start\":38823},{\"end\":38844,\"start\":38833},{\"end\":38854,\"start\":38844},{\"end\":38870,\"start\":38854},{\"end\":38881,\"start\":38870},{\"end\":39199,\"start\":39179},{\"end\":39209,\"start\":39199},{\"end\":39223,\"start\":39209},{\"end\":39236,\"start\":39223},{\"end\":39482,\"start\":39473},{\"end\":39493,\"start\":39482},{\"end\":39505,\"start\":39493},{\"end\":39520,\"start\":39505},{\"end\":39527,\"start\":39520},{\"end\":39742,\"start\":39733},{\"end\":39753,\"start\":39742},{\"end\":39764,\"start\":39753},{\"end\":39774,\"start\":39764},{\"end\":39896,\"start\":39887},{\"end\":40113,\"start\":40098},{\"end\":40350,\"start\":40339},{\"end\":40531,\"start\":40521},{\"end\":40542,\"start\":40531},{\"end\":40550,\"start\":40542},{\"end\":40724,\"start\":40714},{\"end\":40734,\"start\":40724},{\"end\":40745,\"start\":40734},{\"end\":40756,\"start\":40745},{\"end\":40966,\"start\":40957},{\"end\":40977,\"start\":40966},{\"end\":40987,\"start\":40977},{\"end\":41214,\"start\":41206},{\"end\":41220,\"start\":41214},{\"end\":41229,\"start\":41220},{\"end\":41235,\"start\":41229},{\"end\":41433,\"start\":41421},{\"end\":41445,\"start\":41433},{\"end\":41455,\"start\":41445},{\"end\":41646,\"start\":41636},{\"end\":41835,\"start\":41824},{\"end\":41845,\"start\":41835},{\"end\":41854,\"start\":41845},{\"end\":41862,\"start\":41854},{\"end\":42065,\"start\":42056},{\"end\":42078,\"start\":42065},{\"end\":42089,\"start\":42078},{\"end\":42099,\"start\":42089},{\"end\":42108,\"start\":42099},{\"end\":42119,\"start\":42108},{\"end\":42123,\"start\":42119},{\"end\":42369,\"start\":42357},{\"end\":42379,\"start\":42369},{\"end\":42390,\"start\":42379},{\"end\":42587,\"start\":42581},{\"end\":42596,\"start\":42587},{\"end\":42698,\"start\":42687},{\"end\":42707,\"start\":42698},{\"end\":42717,\"start\":42707},{\"end\":43035,\"start\":43026},{\"end\":43045,\"start\":43035},{\"end\":43055,\"start\":43045},{\"end\":43066,\"start\":43055},{\"end\":43317,\"start\":43307},{\"end\":43514,\"start\":43504},{\"end\":43522,\"start\":43514},{\"end\":43532,\"start\":43522},{\"end\":43544,\"start\":43532},{\"end\":43550,\"start\":43544},{\"end\":43558,\"start\":43550},{\"end\":43804,\"start\":43792},{\"end\":43813,\"start\":43804},{\"end\":43824,\"start\":43813},{\"end\":43833,\"start\":43824},{\"end\":44079,\"start\":44068},{\"end\":44091,\"start\":44079},{\"end\":44100,\"start\":44091},{\"end\":44112,\"start\":44100},{\"end\":44118,\"start\":44112},{\"end\":44331,\"start\":44318},{\"end\":44345,\"start\":44331},{\"end\":44358,\"start\":44345},{\"end\":44370,\"start\":44358},{\"end\":44379,\"start\":44370},{\"end\":44566,\"start\":44556},{\"end\":44580,\"start\":44566},{\"end\":44590,\"start\":44580},{\"end\":44871,\"start\":44855},{\"end\":44882,\"start\":44871},{\"end\":44897,\"start\":44882},{\"end\":44913,\"start\":44897},{\"end\":45196,\"start\":45184},{\"end\":45209,\"start\":45196},{\"end\":45497,\"start\":45490},{\"end\":45505,\"start\":45497},{\"end\":45515,\"start\":45505},{\"end\":45936,\"start\":45928},{\"end\":45944,\"start\":45936},{\"end\":45952,\"start\":45944},{\"end\":45959,\"start\":45952},{\"end\":45967,\"start\":45959},{\"end\":46284,\"start\":46276},{\"end\":46291,\"start\":46284},{\"end\":46299,\"start\":46291},{\"end\":46309,\"start\":46299},{\"end\":46789,\"start\":46781},{\"end\":46798,\"start\":46789},{\"end\":46809,\"start\":46798},{\"end\":46820,\"start\":46809},{\"end\":46828,\"start\":46820},{\"end\":46838,\"start\":46828},{\"end\":47060,\"start\":47051},{\"end\":47069,\"start\":47060},{\"end\":47081,\"start\":47069},{\"end\":47089,\"start\":47081},{\"end\":47099,\"start\":47089},{\"end\":47110,\"start\":47099},{\"end\":47120,\"start\":47110},{\"end\":47133,\"start\":47120},{\"end\":47500,\"start\":47492},{\"end\":47510,\"start\":47500},{\"end\":47523,\"start\":47510},{\"end\":47530,\"start\":47523},{\"end\":47543,\"start\":47530},{\"end\":47931,\"start\":47925},{\"end\":47940,\"start\":47931},{\"end\":47947,\"start\":47940},{\"end\":47954,\"start\":47947},{\"end\":34657,\"start\":34646},{\"end\":34668,\"start\":34657},{\"end\":34674,\"start\":34668},{\"end\":34687,\"start\":34674},{\"end\":34891,\"start\":34881},{\"end\":34900,\"start\":34891},{\"end\":34909,\"start\":34900},{\"end\":34920,\"start\":34909},{\"end\":35126,\"start\":35115},{\"end\":35132,\"start\":35126},{\"end\":35145,\"start\":35132},{\"end\":35332,\"start\":35322},{\"end\":35343,\"start\":35332},{\"end\":35351,\"start\":35343},{\"end\":35368,\"start\":35351},{\"end\":35588,\"start\":35578},{\"end\":35599,\"start\":35588},{\"end\":35610,\"start\":35599},{\"end\":35627,\"start\":35610},{\"end\":35836,\"start\":35829},{\"end\":35846,\"start\":35836},{\"end\":36071,\"start\":36064},{\"end\":36078,\"start\":36071},{\"end\":36089,\"start\":36078},{\"end\":36100,\"start\":36089},{\"end\":36302,\"start\":36293},{\"end\":36314,\"start\":36302},{\"end\":36324,\"start\":36314},{\"end\":36335,\"start\":36324},{\"end\":36349,\"start\":36335},{\"end\":36363,\"start\":36349},{\"end\":36375,\"start\":36363},{\"end\":36388,\"start\":36375},{\"end\":36674,\"start\":36665},{\"end\":36683,\"start\":36674},{\"end\":36692,\"start\":36683},{\"end\":36704,\"start\":36692},{\"end\":36717,\"start\":36704},{\"end\":36726,\"start\":36717},{\"end\":36737,\"start\":36726},{\"end\":36959,\"start\":36946},{\"end\":36970,\"start\":36959},{\"end\":36981,\"start\":36970},{\"end\":36992,\"start\":36981},{\"end\":37201,\"start\":37191},{\"end\":37208,\"start\":37201},{\"end\":37217,\"start\":37208},{\"end\":37228,\"start\":37217},{\"end\":37442,\"start\":37431},{\"end\":37452,\"start\":37442},{\"end\":37463,\"start\":37452},{\"end\":37473,\"start\":37463},{\"end\":37484,\"start\":37473},{\"end\":37726,\"start\":37715},{\"end\":37740,\"start\":37726},{\"end\":37948,\"start\":37940},{\"end\":37955,\"start\":37948},{\"end\":37963,\"start\":37955},{\"end\":37975,\"start\":37963},{\"end\":38183,\"start\":38175},{\"end\":38191,\"start\":38183},{\"end\":38203,\"start\":38191},{\"end\":38368,\"start\":38356},{\"end\":38378,\"start\":38368},{\"end\":38393,\"start\":38378},{\"end\":38404,\"start\":38393},{\"end\":38573,\"start\":38564},{\"end\":38584,\"start\":38573},{\"end\":38595,\"start\":38584},{\"end\":38605,\"start\":38595},{\"end\":38789,\"start\":38780},{\"end\":38799,\"start\":38789},{\"end\":38810,\"start\":38799},{\"end\":38823,\"start\":38810},{\"end\":38833,\"start\":38823},{\"end\":38844,\"start\":38833},{\"end\":38854,\"start\":38844},{\"end\":38870,\"start\":38854},{\"end\":38881,\"start\":38870},{\"end\":39199,\"start\":39179},{\"end\":39209,\"start\":39199},{\"end\":39223,\"start\":39209},{\"end\":39236,\"start\":39223},{\"end\":39482,\"start\":39473},{\"end\":39493,\"start\":39482},{\"end\":39505,\"start\":39493},{\"end\":39520,\"start\":39505},{\"end\":39527,\"start\":39520},{\"end\":39742,\"start\":39733},{\"end\":39753,\"start\":39742},{\"end\":39764,\"start\":39753},{\"end\":39774,\"start\":39764},{\"end\":39896,\"start\":39887},{\"end\":40113,\"start\":40098},{\"end\":40350,\"start\":40339},{\"end\":40531,\"start\":40521},{\"end\":40542,\"start\":40531},{\"end\":40550,\"start\":40542},{\"end\":40724,\"start\":40714},{\"end\":40734,\"start\":40724},{\"end\":40745,\"start\":40734},{\"end\":40756,\"start\":40745},{\"end\":40966,\"start\":40957},{\"end\":40977,\"start\":40966},{\"end\":40987,\"start\":40977},{\"end\":41214,\"start\":41206},{\"end\":41220,\"start\":41214},{\"end\":41229,\"start\":41220},{\"end\":41235,\"start\":41229},{\"end\":41433,\"start\":41421},{\"end\":41445,\"start\":41433},{\"end\":41455,\"start\":41445},{\"end\":41646,\"start\":41636},{\"end\":41835,\"start\":41824},{\"end\":41845,\"start\":41835},{\"end\":41854,\"start\":41845},{\"end\":41862,\"start\":41854},{\"end\":42065,\"start\":42056},{\"end\":42078,\"start\":42065},{\"end\":42089,\"start\":42078},{\"end\":42099,\"start\":42089},{\"end\":42108,\"start\":42099},{\"end\":42119,\"start\":42108},{\"end\":42123,\"start\":42119},{\"end\":42369,\"start\":42357},{\"end\":42379,\"start\":42369},{\"end\":42390,\"start\":42379},{\"end\":42587,\"start\":42581},{\"end\":42596,\"start\":42587},{\"end\":42698,\"start\":42687},{\"end\":42707,\"start\":42698},{\"end\":42717,\"start\":42707},{\"end\":43035,\"start\":43026},{\"end\":43045,\"start\":43035},{\"end\":43055,\"start\":43045},{\"end\":43066,\"start\":43055},{\"end\":43317,\"start\":43307},{\"end\":43514,\"start\":43504},{\"end\":43522,\"start\":43514},{\"end\":43532,\"start\":43522},{\"end\":43544,\"start\":43532},{\"end\":43550,\"start\":43544},{\"end\":43558,\"start\":43550},{\"end\":43804,\"start\":43792},{\"end\":43813,\"start\":43804},{\"end\":43824,\"start\":43813},{\"end\":43833,\"start\":43824},{\"end\":44079,\"start\":44068},{\"end\":44091,\"start\":44079},{\"end\":44100,\"start\":44091},{\"end\":44112,\"start\":44100},{\"end\":44118,\"start\":44112},{\"end\":44331,\"start\":44318},{\"end\":44345,\"start\":44331},{\"end\":44358,\"start\":44345},{\"end\":44370,\"start\":44358},{\"end\":44379,\"start\":44370},{\"end\":44566,\"start\":44556},{\"end\":44580,\"start\":44566},{\"end\":44590,\"start\":44580},{\"end\":44871,\"start\":44855},{\"end\":44882,\"start\":44871},{\"end\":44897,\"start\":44882},{\"end\":44913,\"start\":44897},{\"end\":45196,\"start\":45184},{\"end\":45209,\"start\":45196},{\"end\":45497,\"start\":45490},{\"end\":45505,\"start\":45497},{\"end\":45515,\"start\":45505},{\"end\":45936,\"start\":45928},{\"end\":45944,\"start\":45936},{\"end\":45952,\"start\":45944},{\"end\":45959,\"start\":45952},{\"end\":45967,\"start\":45959},{\"end\":46284,\"start\":46276},{\"end\":46291,\"start\":46284},{\"end\":46299,\"start\":46291},{\"end\":46309,\"start\":46299},{\"end\":46789,\"start\":46781},{\"end\":46798,\"start\":46789},{\"end\":46809,\"start\":46798},{\"end\":46820,\"start\":46809},{\"end\":46828,\"start\":46820},{\"end\":46838,\"start\":46828},{\"end\":47060,\"start\":47051},{\"end\":47069,\"start\":47060},{\"end\":47081,\"start\":47069},{\"end\":47089,\"start\":47081},{\"end\":47099,\"start\":47089},{\"end\":47110,\"start\":47099},{\"end\":47120,\"start\":47110},{\"end\":47133,\"start\":47120},{\"end\":47500,\"start\":47492},{\"end\":47510,\"start\":47500},{\"end\":47523,\"start\":47510},{\"end\":47530,\"start\":47523},{\"end\":47543,\"start\":47530},{\"end\":47931,\"start\":47925},{\"end\":47940,\"start\":47931},{\"end\":47947,\"start\":47940},{\"end\":47954,\"start\":47947}]", "bib_venue": "[{\"end\":34695,\"start\":34687},{\"end\":34924,\"start\":34920},{\"end\":35113,\"start\":35047},{\"end\":35378,\"start\":35368},{\"end\":35576,\"start\":35513},{\"end\":35860,\"start\":35846},{\"end\":36062,\"start\":35981},{\"end\":36407,\"start\":36388},{\"end\":36663,\"start\":36624},{\"end\":36996,\"start\":36992},{\"end\":37232,\"start\":37228},{\"end\":37429,\"start\":37369},{\"end\":37744,\"start\":37740},{\"end\":37979,\"start\":37975},{\"end\":38207,\"start\":38203},{\"end\":38354,\"start\":38325},{\"end\":38562,\"start\":38511},{\"end\":38889,\"start\":38881},{\"end\":39177,\"start\":39104},{\"end\":39471,\"start\":39423},{\"end\":39731,\"start\":39687},{\"end\":39970,\"start\":39896},{\"end\":40150,\"start\":40113},{\"end\":40337,\"start\":40260},{\"end\":40554,\"start\":40550},{\"end\":40760,\"start\":40756},{\"end\":40996,\"start\":40987},{\"end\":41243,\"start\":41235},{\"end\":41419,\"start\":41376},{\"end\":41654,\"start\":41646},{\"end\":41866,\"start\":41862},{\"end\":42131,\"start\":42123},{\"end\":42355,\"start\":42283},{\"end\":42606,\"start\":42596},{\"end\":42803,\"start\":42733},{\"end\":43089,\"start\":43066},{\"end\":43327,\"start\":43317},{\"end\":43572,\"start\":43558},{\"end\":43843,\"start\":43833},{\"end\":44066,\"start\":43989},{\"end\":44383,\"start\":44379},{\"end\":44642,\"start\":44590},{\"end\":44978,\"start\":44913},{\"end\":45290,\"start\":45224},{\"end\":45595,\"start\":45515},{\"end\":46020,\"start\":45967},{\"end\":46388,\"start\":46320},{\"end\":46883,\"start\":46838},{\"end\":47171,\"start\":47133},{\"end\":47611,\"start\":47543},{\"end\":48031,\"start\":47954},{\"end\":34695,\"start\":34687},{\"end\":34924,\"start\":34920},{\"end\":35113,\"start\":35047},{\"end\":35378,\"start\":35368},{\"end\":35576,\"start\":35513},{\"end\":35860,\"start\":35846},{\"end\":36062,\"start\":35981},{\"end\":36407,\"start\":36388},{\"end\":36663,\"start\":36624},{\"end\":36996,\"start\":36992},{\"end\":37232,\"start\":37228},{\"end\":37429,\"start\":37369},{\"end\":37744,\"start\":37740},{\"end\":37979,\"start\":37975},{\"end\":38207,\"start\":38203},{\"end\":38354,\"start\":38325},{\"end\":38562,\"start\":38511},{\"end\":38889,\"start\":38881},{\"end\":39177,\"start\":39104},{\"end\":39471,\"start\":39423},{\"end\":39731,\"start\":39687},{\"end\":39970,\"start\":39896},{\"end\":40150,\"start\":40113},{\"end\":40337,\"start\":40260},{\"end\":40554,\"start\":40550},{\"end\":40760,\"start\":40756},{\"end\":40996,\"start\":40987},{\"end\":41243,\"start\":41235},{\"end\":41419,\"start\":41376},{\"end\":41654,\"start\":41646},{\"end\":41866,\"start\":41862},{\"end\":42131,\"start\":42123},{\"end\":42355,\"start\":42283},{\"end\":42606,\"start\":42596},{\"end\":42803,\"start\":42733},{\"end\":43089,\"start\":43066},{\"end\":43327,\"start\":43317},{\"end\":43572,\"start\":43558},{\"end\":43843,\"start\":43833},{\"end\":44066,\"start\":43989},{\"end\":44383,\"start\":44379},{\"end\":44642,\"start\":44590},{\"end\":44978,\"start\":44913},{\"end\":45290,\"start\":45224},{\"end\":45595,\"start\":45515},{\"end\":46020,\"start\":45967},{\"end\":46388,\"start\":46320},{\"end\":46883,\"start\":46838},{\"end\":47171,\"start\":47133},{\"end\":47611,\"start\":47543},{\"end\":48031,\"start\":47954},{\"end\":45662,\"start\":45597},{\"end\":46474,\"start\":46408},{\"end\":48095,\"start\":48033},{\"end\":45662,\"start\":45597},{\"end\":46474,\"start\":46408},{\"end\":48095,\"start\":48033}]"}}}, "year": 2023, "month": 12, "day": 17}