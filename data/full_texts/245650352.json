{"id": 245650352, "updated": "2023-10-05 18:25:14.636", "metadata": {"title": "Zero-Shot Cost Models for Out-of-the-box Learned Cost Prediction", "authors": "[{\"first\":\"Benjamin\",\"last\":\"Hilprecht\",\"middle\":[]},{\"first\":\"Carsten\",\"last\":\"Binnig\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "In this paper, we introduce zero-shot cost models which enable learned cost estimation that generalizes to unseen databases. In contrast to state-of-the-art workload-driven approaches which require to execute a large set of training queries on every new database, zero-shot cost models thus allow to instantiate a learned cost model out-of-the-box without expensive training data collection. To enable such zero-shot cost models, we suggest a new learning paradigm based on pre-trained cost models. As core contributions to support the transfer of such a pre-trained cost model to unseen databases, we introduce a new model architecture and representation technique for encoding query workloads as input to those models. As we will show in our evaluation, zero-shot cost estimation can provide more accurate cost estimates than state-of-the-art models for a wide range of (real-world) databases without requiring any query executions on unseen databases. Furthermore, we show that zero-shot cost models can be used in a few-shot mode that further improves their quality by retraining them just with a small number of additional training queries on the unseen database.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2201.00561", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/pvldb/HilprechtB22", "doi": "10.14778/3551793.3551799"}}, "content": {"source": {"pdf_hash": "69ad3fb58b3d422b50583f7791554d4fe7720b88", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2201.00561v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "ce83ddf105f7a9dc42211b1385ee3be880d66b87", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/69ad3fb58b3d422b50583f7791554d4fe7720b88.txt", "contents": "\nZero-Shot Cost Models for Out-of-the-box Learned Cost Prediction\n\n\nBenjamin Hilprecht \nTU\nDarmstadt\n\nT U Darmstadt \nTU\nDarmstadt\n\nCarsten Binnig \nTU\nDarmstadt\n\nZero-Shot Cost Models for Out-of-the-box Learned Cost Prediction\n\nIn this paper, we introduce zero-shot cost models which enable learned cost estimation that generalizes to unseen databases. In contrast to state-of-the-art workload-driven approaches which require to execute a large set of training queries on every new database, zero-shot cost models thus allow to instantiate a learned cost model out-of-the-box without expensive training data collection. To enable such zero-shot cost models, we suggest a new learning paradigm based on pre-trained cost models. As core contributions to support the transfer of such a pre-trained cost model to unseen databases, we introduce a new model architecture and representation technique for encoding query workloads as input to those models. As we will show in our evaluation, zero-shot cost estimation can provide more accurate cost estimates than state-of-the-art models for a wide range of (real-world) databases without requiring any query executions on unseen databases. Furthermore, we show that zero-shot cost models can be used in a few-shot mode that further improves their quality by retraining them just with a small number of additional training queries on the unseen database.\n\nIntroduction\n\nMotivation. Accurate physical cost estimation (i.e., estimating query latencies) is crucial for query optimization in DBMSs. Classically, cost estimation is performed using models that make several simplifying assumptions. As a result, such models often over-or underestimate runtimes, leading to suboptimal planning decisions that degrade the overall query performance [15]. Recently, machine learning has thus been used for learned cost models that do not need to make such simplifying assumptions [28].\n\nWhile it was shown that the cost estimates of such learned cost models are significantly more accurate than those of the traditional cost models, the existing approaches rely on workload-driven learning where models have to observe thousands of queries on the same database 1 for which the cost prediction should be performed. This workload execution is required to gather the training data which can take hours (or days) since tens of thousands of queries need to be executed on potentially large databases.\n\nIn Figure 1, we show the cost estimation accuracy depending on how many hours we allow for gathering the training data for a workload-driven model. As we can see, even for a medium-sized database such as IMDB, it takes more than 5 hours of running queries on this database to gather enough training data such that the cost estimation model can provide a decent accuracy.\n\nUnfortunately, collecting training data by running queries is not a one-time effort. In fact, the training data collection has to be repeated for every new database a learned model should be deployed for. This is due to the fact that current model architectures While workload-driven approaches [28] require many hours of workload executions as training data, our zero-shot cost model supports the unseen IMDB database out-of-thebox and provides highly accurate cost estimates. If a workload is observed however, these queries can be used to finetune a zero-shot model resulting in few-shot models which further improve the performance.\n\nfor workload-driven learning tie a trained model to a particular database instance. Consequently, for every (new) unseen database we not only have to train a model from scratch but also gather training data in the form of queries. And even for the same database, in case of changed data characteristics due to updates, training data collection needs to be repeated. Overall, these repeated high costs for obtaining training data for unseen databases render workloaddriven learning unattractive for many practical deployments. Contributions. In this paper, we thus suggest a new learning paradigm for cost estimation called zero-shot cost models that reduces these high efforts. The general idea behind zero-shot cost models is motivated by recent advances in transfer learning of models. Similar to other approaches such as GPT-3 [3] which enable zero-shot learning for NLP, a zero-shot cost model is trained on a wide collection of different databases and workloads and can thus generalize out-of-the-box to a completely unseen database without the need to be trained particularly on that database. In fact as depicted in Figure 1, zero-shot cost models can provide a high accuracy and often even outperform existing workload-driven approaches that have been trained on large sets of training queries. Moreover, as we also show in Figure 1, zero-shot cost models can additionally be fine-tuned on the unseen database with just a few training queries and the resulting few-shot models further improve the accuracy.\n\nOne could now argue that it might be a significant effort to collect sufficient training data across databases for pre-training a zero-shot model. However, in contrast to workload-driven models which require training data for every unseen database, training data collection is a one-time effort; i.e., once trained the zero shot model can be used for any new unseen database. In fact, in our evaluation we show that zero-shot models can provide high accuracies for a wide-variety of real-world databases. Moreover, for historical traces can be used which eliminates the need to collect any training arXiv:2201.00561v1 [cs.DB] 3 Jan 2022 data. For example, cloud providers such as AWS, Microsoft, or Google, typically anyway keep logs of their customer workloads which could directly be used as training data for zero-shot learning without collecting any further training data.\n\nA key aspect to enable zero-shot learning is that a cost model can be transferred to new (unseen) databases, i.e., the models leverage observed query executions on a variety of different databases to predict runtimes on new (unseen) databases. However, state-ofthe-art model architectures used for workload-driven learning do not support this training and inference mode since they are tied to a particular database. As a core novel contribution for zero-shot cost models we thus devise a new model architecture based on a representation of queries that generalizes across databases using a transferable representation with features such as the tuple width that can be derived from any database. Moreover, zero-shot models separate concerns; i.e., data characteristics of a new database (e.g., rows of tables) are not implicitly learned as in classical workloaddriven learning (which hinders generalization), but are provided as input to the model.\n\nAnother core question for zero-shot models is at which point a sufficient amount of different training databases and workloads was observed to generalize robustly to unseen databases. To answer this question, as a second contribution in this paper we derive a method to estimate how accurate the runtime estimations of zeroshot models will be for unseen databases. We also discuss how to address cases of workload drifts where the zero-shot models are expected to generalize less robustly. Furthermore, we also show that zero-shot models are widely applicable beyond cost models for query optimizers for single-node DBMSs which is the main focus of this paper. For instance, we believe that zero-shot cost models can be naturally extended to to distributed DBMS or even other use cases such as providing cost estimates for design advisors where the goal is to automatically find a suitable database design (e.g., a set of indexes) for a given workload.\n\nFinally, in our extensive experimental evaluation, we verify that zero-shot cost models generalize robustly to unseen databases and workloads while providing cost estimates which are more accurate than those of workload-driven models. As part of this evaluation, we also provide a new benchmark (beyond JOB) which is necessary to evaluate cost estimation models more broadly on a variety of (real-world) databases. We will make this benchmark including query executions for training cost models publicly available and hope that it will benefit future research in learned cost estimation and potentially beyond.\n\nOutline In Section 2, we give an overview of our approach and describe the model architecture in more detail in Section 3. We then derive formal methods to recognize when sufficient training data is available for the model to generalize in Section 4 and then discuss our extensions to show the broader applicability of zero-shot cost models in Section 5. Before discussing the evaluation in Section 7, we describe the design decisions for our proposed benchmark to evaluate cost models. Finally, we present related work (Section 8) and conclude in Section 9.\n\n\nOverview\n\nIn this section, we introduce the problem of zero-shot cost estimation and then present an overview of our approach.\n\n\nProblem Statement\n\nThe overall goal of zero-shot cost estimation is to predict query latencies (i.e., runtimes) on an unseen database without having observed any query on this unseen database. Throughout this paper we use the term database to refer to a particular dataset (i.e., a set of tables with a given data distribution). Note that the problem of zero-shot cost estimation is thus in sharp contrast to the problem addressed by state-of-the-art workload-driven cost models which train a model per database. Finally, while we believe that zero-shot learning for DBMSs is more generally applicable, we restrict ourselves in this paper to cost estimations for relational DBMSs (both single-node and distributed). In particular, zero-shot cost models for other types of systems such as graph-databases or streaming systems are interesting avenues of future work.\n\n\nOur Approach\n\nA key challenge for developing zero-shot cost models is the question how to design a model that allows to generalize across databases. Here, we draw inspiration from the way classical cost models in DBMSs are designed. Typically, these consist of two models: a database-agnostic model to estimate the runtime cost and a databasedependent model (e.g., histograms) to capture data characteristics. When predicting the cost of a query, the estimated cardinalities and other characteristics (i.e., outputs of the database-dependent models) serve as input to the general database-agnostic cost model which captures the general system behavior (e.g., the costs of a sequential scan grows linearly w.r.t. the number of rows). While the classical models are lightweight, they often largely under-or overestimates the true costs of a query since models are too simple to capture complex interactions in the query plan and data.\n\nHence, in our approach, we also separate concerns but use a much richer learned model which similarly takes data characteristics of the unseen database as input to predict query runtimes in a database-agnostic manner. As depicted in Figure 2 (upper part), for training such a zero-shot cost model we provide different query plans along with the runtime as well as the data characteristics of the plan (such as tuple width as well as intermediate cardinalities) to the zero-shot cost model. Once trained, the model can be used on unseen databases to predict the query runtime as shown in Figure 2 (lower part).\n\nAs mentioned before, to predict the runtime of a query plan on a new (unseen) database, we feed the query plan together with its data characteristics into a zero-shot model. While data characteristics such as the tuple width can be derived from the database catalogs, other characteristics such as intermediate cardinalities require more complex techniques. To derive intermediate cardinalities of a query plan in our approach we thus make use of data-driven learning [10,32] that can provide exact estimates on a given database. Note that this does not contradict our main promise of zero-shot learning since data-driven models to capture data characteristics can be learned without queries as training data.  Figure 2: Overview of Zero-Shot Cost Estimation. The zeroshot cost model is trained once using a variety of queries and databases. At inference time, the model can then provide cost estimates for an unseen database and queries without requiring additional training queries. Enabling zero-shot cost estimation is based on two key ideas: (1) a new transferable query representation and model architecture is used to enable cost predictions on unseen databases and (2) we separate concerns, i.e., a zero-shot model learns a general database-agnostic cost model which takes database-specific characteristics as input.\n\nAnother core challenge of enabling zero-shot cost models that can estimate the runtime of a plan given its data characteristics is how to represent query plans which serve as input to the model. While along with workload-driven cost models, particular representation methods for query plans have already been proposed, those are not applicable for zero-shot learning. The reason is that the representations are not transferable across databases. For instance, literals in filter predicates are provided as input to the model (e.g., 2021 for the predicate movie.production_year=2021). However, the selectivity of literals will vary largely per database since the data distribution will likely be different (e.g., there might not even exist movies produced in 2021 in the test database).\n\nHence, as a second technique in this paper, we propose a new representation for queries that completely relies on features that can be derived from any database to allow the model to generalize to unseen databases. For example, predicates for filter operations in a query are encoded by the general predicate structure (e.g., which data types and comparison operators are used in a predicate) instead of encoding the literals. In addition, data characteristics of a filter operator (e.g., input and output cardinality to express the selectivity) are provided as additional input to a zero-shot model. That way, a zero-shot model can learn the runtime overhead of a filter operation based on database-agnostic characteristics. We present details of our query representation in Section 3.\n\nFinally, a last important aspect of zero-shot cost models is that they can easily be extended to few-shot learning. Hence, instead of using the zero-shot model out-of-the box (which already can provide good performance), one can fine-tune the model with only a few training queries on an unseen database.\n\n\nZero-Shot Cost Models\n\nAs mentioned in Section 2, a zero-shot cost model (once trained) is able to predict the runtime of a query on an entirely new database without retraining. A core building block needed to enable a zeroshot model is a new representation of queries that can generalize across databases. In the following, we thus first explain how we devised such a transferable query representation and then discuss how inference and training of a zero-shot model that uses this representation works.\n\n\nQuery Representation\n\nState-of-the-art workload-driven models [12,28] for cost estimation do not use transferable query representations and can thus only be used on the database they were trained on. To better understand why current query representations are not transferable, we first explain how they typically encode queries. 3.1.1 Query Representation for Workload-Driven Models. At the core, query representations used for workload-driven approaches hard-code the model against a single database. For example, attribute names (e.g., those used in filter predicates) are typically encoded using a one-hot encoding assigning each attribute present in the database a specific position in a feature vector. For instance, the attribute production_year of the IMDB dataset might be encoded using the vector (0, 1, 0) (assuming that there are only three attributes in total). If the same model should now be used to predict query costs for the SSB dataset, some attributes might not even exist or even worse they might exist but have very different data distributions or even a different data type. In fact, non-transferable feature encodings are not only used for attributes but in various places of the query representation such as encoding table names or literals in filter predicates. 3.1.2 Query Representation for Zero-Shot Cost Models. Hence, for zero-shot cost models we require a new query representation that is transferable across databases. The main idea of the transferable representation we suggest in this paper is shown in Figure 3. At the core, a query plan and the involved tables and attributes are represented using a graph where graph nodes use transferable features 1 (i.e., features that provide meaningful information to predict runtime on different databases). This representation then serves as input for the training and inference process of zero shot cost models 2 -4 that we explain in the subsequent sections. In the following, we discuss the graph encoding of the transferable featurization in detail.\n\nGraph Encoding of Query Plans. While graph-based representations have been already used to represent query operators of a query plan [28], our representation has significant differences. First, as shown in Figure 3 1 , our representation not only encodes physical plan operators as nodes (gray) in the graph as in previous work [28], but it also covers all query plan information more holistically using different nodes types for attributes (green), tables (blue) as well as predicate information (red). Second, as discussed before, previous approaches also covered such information, however, they used one-hot-encodings (which are non-transferable) while our representation captures the query complexity in a transferable way.\n\nFor instance, to encode filter predicates, different from previous approaches we encode the predicate structure as nodes (red)   without literals. In particular, we encode information such as data types of the attributes and operators used for comparisons. For example, the filter predicate company_type_id=2 for the query 0 in Figure 3, is encoded using an attribute node ( 5 ) with the comparison node = ( 7 ). As such, a zero-shot cost model provided with the transferable features (e.g., intermediate cardinalities which are given by the data-driven models) can infer the complexity of the predicates to estimate the query runtime.\n\nTransferable Featurization. While our graph representation allows to flexibly encode query plans across databases, we similarly have to make sure that the features used to represent nodes in the graph 1 (e.g., plan operators as shown in gray) are transferable. In particular, when used on different databases, features should not encode any implicit information that hinder the transfer of the model to a new unseen database. The set of such features used for the different node types in our query representation is depicted in Table 1. For instance, attribute nodes (green) use features such as the data type or the width in bytes. Similarly, for tables (blue nodes), we use other transferable features (e.g., the number of rows as well as the number of pages on disk). Importantly, transferable features can either characterize the query plan (e.g., operator types) or represent the data characteristics (e.g., intermediate cardinalities) and together allow a zero-shot cost model to generalize to an unseen database. For transferable features that represent data characteristics many can be derived from the metadata of a database (such as the the number of rows of a table node). However, some other features that represent data characteristics -e.g., the estimated output cardinality of an operator node -require more involved techniques. In Section 3.4, we discuss alternatives of how we provide estimated output cardinalities to zero-shot cost models.\n\n\nInference on Zero-Shot Models\n\nOnce a query graph with the transferable features on a unseen database is constructed for a query plan, it can be used as input for a (trained) zero-shot cost model to predict the runtime. Predicting the runtime of a new query plan with a zero-shot cost model is  executed in three steps which we depict as pseudocode in Algorithm 1: First, we compute a hidden state for every node of the query graph 2 given the node-wise input features. Second, the information of different graph nodes is combined using message passing 3 before a Multi-Layer-Perceptron (MLP) predicts the runtime of the query plan 4 . The same steps are also reflected in Figure 3 2 to 4 . In particular, in step 2 , the feature vectors of each graph node are encoded using a node-type specific MLP, i.e., nodes of the same type (e.g., all plan operators) use the same MLP to initialize their hidden state \u210e (line 5). For instance, in Figure 3, the hidden state \u210e 8 of the node representing the sequential scan on the movie_companies table is obtained by feeding the feature vector 8 (containing transferable features) into an MLP which is shared among all plan operators (gray nodes). Afterwards, in step 3 , a message passing scheme is applied which is prominently used in graph neural networks (GNNs) [6] to model the interactions between nodes in graphs (i.e., to capture interactions of query operators in the plan such as effects of a pipelined query execution). Different from message passing schemes for general graph encodings, for the message passing in zero-shot models we can exploit the fact that queries can be represented as directed acyclic graphs (DAGs) since query-plans are tree-structured. We thus use a novel bottom-up message passing \n\u210e \u2032 \u2190 \u2032 ( ) \u2208children(v) \u210e \u2032 \u2295 \u210e 8:\u02c6\u2190 est (\u210e \u2032 )\n\u22b2 Estimate costs using root node state 4 9: return\u015d cheme through the graph (i.e., in topological ordering) to obtain an updated hidden state \u210e \u2032 of a node that contains all information of the child nodes. During this pass, the updated hidden states \u210e \u2032 of the children are combined by summation [33] and concatenated with the initial hidden state \u210e of a node and fed into a node-typespecific MLP (line 7). For instance, in Figure 3, the updated hidden state \u210e \u2032 8 of the scan node is obtained by summing up the updated hidden states of the child nodes (representing the table and predicate operator of the scan) concatenated with the initial hidden state (capturing properties of the scan) which is then fed into an MLP which is again shared among all plan operators.\n\nFinally, as a result of step 3 the updated hidden state \u210e \u2032 of the root node of a query plan captures the properties of the entire query. For the cost prediction in step 4 , we thus feed this hidden state into a final estimation MLP to obtain the cost estimat\u00ea = est (\u210e ) (line 8). Hence, in Figure 3 4 , the updated hidden state \u210e \u2032 13 is fed into the final estimation MLP to obtain the cost estimate since it captures information of the entire plan.\n\n\nTraining Zero-Shot Models\n\nAs mentioned before, a zero-shot cost model is trained on several databases and queries to learn the runtime complexity of query plans given the input features. To be more precise, a zero-shot cost model is trained in a supervised fashion using pairs ( , ) that consists of a plan with the respective features and the actual runtime cost . Importantly, all steps described in the inference procedure (node encoding, message passing and finally runtime estimation) are differentiable, which allows us to train the model parameters of the MLPs used for all zero-shot model components jointly in an end-to-end fashion. As loss function to compare the actual costs of a featurized query plan with the estimated cost\u015d , we use the Q-error loss max(\u02c6,\u02c6) [12,28] since this worked best for zero-shot models compared to other alternatives.\n\n\nDeriving Data Characteristics\n\nAs discussed before, an important aspect of a zero-shot model is that the model is not tied to a particular data distribution of a single database. For enabling this, we provide data characteristics such as attribute widths in bytes, number of pages and tuples of tables but also output cardinalities of operators as input to those models.\n\nTo be more precise, given a particular query plan for which the runtime should be estimated, those features have to be annotated for each graph node in the query encoding.\n\nWhile the majority of those features can simply be derived from the database catalog, intermediate cardinalities in a query plan are notoriously hard to predict and simple statistics are known to be   Table 2). In the following, we discuss these aspects. First, a zero-shot cost model should be able to predict query runtimes on databases that were not seen before without relying on an observed workload on that database. Since workload-driven models for cardinality estimation require such queries as training data, they are not suited for our purpose of predicting cardinalities for zero-shot models. Second, traditional histogram-based approaches have the advantage that no additional efforts are required since the query optimizers anyway have built-in techniques. However, they are often imprecise. Third, data-driven models are more precise but also need to be trained. However, the training does not rely on query executions and is thus usually just in the order of minutes. Unfortunately, state-of-the-art data-driven cardinality estimators do not yet support the same variety of different queries as traditional approaches.\n\nDepending on whether the effort to train a data-driven model for an unseen database is acceptable and the workload is supported, one can either opt for traditional approaches or data-driven models. Hence, we propose to use zero-shot models with data-driven cardinality models if possible and use optimizer cardinality estimates only as a fallback. In our evaluation, we see that zero-shot models can still produce reasonable estimates even if only cardinalities estimates from traditional models are available.\n\n\nRobustness of Zero-Shot Models\n\nAn important question for zero-shot models is at which point a sufficient amount of different training databases (and workloads) was observed to generalize robustly to unseen databases. To answer this question, we first derive a method to estimate how robust the runtime estimates of zero-shot models will be for unseen databases. We then discuss a simple method to detect cases of workload drifts (i.e., the queries at runtime have substantially different characteristics than the training queries) as well as strategies how to tackle this problem.\n\n\nEstimating the Generalization Performance\n\nWe first formalize the problem, before we derive a method to estimate the generalization error. For training a zero-shot model, we have observed databases and workloads. In particular, for each of the databases we have access to training data in the form of query plans and their runtimes =\n{( 1 , 1 ), ( 2 , 2 ), . . . ( , )}.\nWe are now interested in how accurately the zero-shot cost model will predict the runtimes for plans * on some unseen database * . In particular, if the expected error is acceptable, we have observed a sufficient amount of databases and workloads. More formally, we will define some error metric ( ) with which we can compare the true runtimes and model predictions for some database . An example for such a metric could be the prominently used median Q-error. We are now interested in estimating this error metric for an unseen database ( * ), i.e., the expected generalization error.\n\nWe now make use of statistical techniques to estimate the generalization error. For instance, in ML it is standard practice to train the model on a subset of the data and then use the remaining samples to estimate the error for future unseen datasets. Analogously, we can train the zero-shot model on a subset of the training databases 1 , 2 , . . . , (i.e., for a subset of databases) and evaluate the trained model on the remaining databases +1 , . . . , . Similar to cross validation, we can repeat this procedure with different splits and average the test errors to estimate the generalization error ( * ), i.e., how accurate the model is expected to be on an unseen database. Interestingly, this is an unbiased estimator of the test error ( * ) under the independent identically distributed (i.i.d.) assumption which we will discuss shortly. Hence, using only the observed databases and queries, we can estimate how accurate the model predictions for unseen databases will be.\n\nIn order to now evaluate whether the model has observed a sufficient amount of databases and workloads, we can use two techniques. First, we can simply estimate the generalization error as described above and stop the training if it is sufficient. However, in this case we have to decide which generalization error is acceptable. A second technique (which we actually use in this paper) is to estimate if additional training databases will improve the generalization performance. For this, we train the model on subsets of all training databases. If the estimated generalization error ( * ) does not improve significantly for a larger number of training databases, we can conclude that additional databases will not improve the generalization capabilities of the zero-shot cost model and thus stop the training data collection.\n\n\nTackling Workload Drifts\n\nThe performance of zero-shot cost models will deteriorate if the new database and workload is significantly different from the training data. For instance, if there are significantly larger joins in the unseen database than for the training databases, the zero-shot model might not be able to predict the runtime with the same high accuracy. As we will show in our experimental evaluation, however, zero-shot cost models can often still generalize robustly in practice and can provide more accurate estimates than other baselines in case of workload drifts. In addition, we suggest a strategy to detect cases of workload drifts by monitoring the test error and propose to tackle workload-drifts using few-shot learning.\n\nNote that in cases of workload drifts the i.i.d. assumption does not hold and the Q-error on the unseen database is larger than implied by the generalization error. More technically, the i.i.d. assumption is a common assumption in ML that requires that the training datasets and test datasets are independent samples of some distribution D. Due to a workload drift, the samples are no longer independent and thus the generalization error ( * ) might be increased. A simple   yet effective strategy to recognize those cases is thus to monitor the error for unseen databases during inference. In cases where the error exceeds a certain threshold, one could decide to fine-tune the zero-shot model using the additional observed queries as training data (resulting in few-shot models). We will demonstrate in the experimental evaluation that zero-shot cost models fine-tuned on a small number of additional queries can significantly improve the accuracy on the unseen database in such cases.\n\n\nExtensions of Zero-Shot Cost Models\n\nWe now describe how zero-shot cost estimation can be extended in various directions.\n\n\nDistributed DBMSs\n\nWhile the zero-shot cost models we discussed so far are centered around single-node DBMSs, we argue that zero-shot models can also be adapted to other types of DBMS. An important class of DBMSs are distributed DBMSs that are often found in the cloud to support scalable data processing. To show the general feasibility, we now discuss some concrete extension of our approach to support a (commercial) cloud DBMS for OLAP . Overall, we think that this demonstrates the potential of our approach to be adapted to new domains with the zero-shot paradigm in mind. For supporting zero-shot cost estimates on the concrete cloud DBMS we used, two extensions were needed: First, as mentioned before, cloud DBMSs are typically distributed and thus frequently shuffle the data during query execution (e.g., for distributed join processing). Second, independent of the fact that the processing is distributed there are often other optimizations to reduce the query execution costs of reading large amounts of data such as using a column store layout instead of a row store layout.\n\nTo support these two aspects in zero-shot cost models, we extended the encoding of queries which serves as input to the zeroshot model as depicted in Figure 4. In particular, we included operator nodes for data shuffling as well as encode data formats (column or row) as a feature of the table node.\n\n\nPhysical Design Tuning\n\nAnother interesting direction is to use these models to estimate the runtime of query workloads for different (potential) physical designs. This is helpful to automate physical design tuning which needs to enumerate different alternative designs and estimate which design to pick based on cost estimates (representing the runtime of a workload on a unseen physical design).\n\nTo show that zero-shot cost models support this, we extended the zero-cost models to be able to predict the runtime for queries with and without certain indexes on an unseen database. For this, the query representation was extended such that the model can learn the trade-offs between different operations (e.g., how expensive a sequential scan is vs. an index scan). Moreover, when training a zero-shot cost model, the training databases should include tables with and without indexes such that the model can learn how the cost for these two cases differ based on data characteristics.\n\nIn our experimental evaluation, we show that the zero-shot cost models can thus generalize robustly to unseen physical designs (i.e., to estimate the cost of a query with and without an index). However, there is clearly more to be done. For example, it could be beneficial to also introduce additional (transferable) features to capture other aspects of a physical designs (such as the expected height of indexes) or even support other options of physical designs (e.g., materialized views) in zero-cost models.\n\n\nOther Directions\n\nWe believe that many more aspects such as hardware parameters (e.g., amount of available memory) and database knob configurations could be captured using zero-shot models. Since those features are naturally transferable, e.g., knobs such as buffer sizes carry the same semantics across databases, an extension of our models will be possible. That way zero-shot models could inform also automated knob tuning. However, while all these directions are interesting, they are beyond the scope of this paper and represent avenues of future work.\n\n\nA New Benchmark\n\nIn order to properly train and evaluate cost models, we require both a diverse set of databases and executed workloads on these databases. Since currently there is no suitable benchmark with such properties, we created a new benchmark (that includes existing benchmarks such as JOB) which we discuss in this section. Furthermore, we will make this benchmark publicly available to foster future research in this area.\n\n\nDesign Decisions\n\nFor many years, DBMS systems were evaluated using synthetic benchmarks such as TPC-H [1], TPC-DS [24] or SSB [25]. While such benchmarks allow to evaluate the general system performance and scalability, they are in isolation insufficient to evaluate cost prediction models since the predicted cardinalities of the query optimizer are significantly more accurate than in practice. The reason is that the data is synthetic and thus no interesting correlations have to be captured making cardinality estimation challenging in practice. Hence, Leis et al. [15] suggested the JOB-workload on the IMDB dataset that comes with challenging correlations and has become the standard method (along with the simplified JOB-light workload [12]) to evaluate learned cost and cardinality estimation approaches.\n\nWhile the IMDB benchmark is useful to evaluate workloaddriven cost estimators that need to work on a single database only, it cannot be used for the evaluation of zero-shot cost models since these have to be trained on a variety of different databases. Moreover, even for workload-driven cost estimators a benchmark that spans a more diverse set of databases would definitively be helpful to evaluate the prediction quality. Hence, we decided to create a new benchmark that covers established datasets such as IMDB but also additional datasets that have other characteristics.\n\n\nDatasets\n\nAs discussed before, it is insufficient to just add synthetic datasets since correlations hardly resemble data distributions found in the real-world. We thus decided to leverage publicly available realworld datasets [23] together with the datasets used in established benchmarks such as JOB. Since certain database were very small in size, we additionally scaled them to larger sizes to be interesting for cost estimation (s.t. a sample of queries takes a predefined threshold of time). In addition to the datasets mentioned before, we also included standard benchmarks such as SSB and TPC-H to the benchmark. As these benchmarks rely on synthetic data, this further increases the variety of data characteristics our benchmark covers for testing learned cardinality estimators. Overall, the benchmark comprises of 20 databases that vary largely in the number of tables, columns and foreign-key relationships.\n\n\nWorkloads and Traces\n\nFurthermore, for benchmarking learned cost models, workloads are required for training and testing. To simplify the comparison with prior work we first include predefined benchmark queries for databases that come with such workloads (e.g., JOB for IMDB). However, since for the majority of the databases mentioned before no workloads are available, we implemented a workload generator that generates different types of queries. For creating the workload, the generator supports three modes: a standard mode where Select-Project-Aggregate-Join (SPAJ) queries with conjunctive predicates on numeric and categorical columns similar to the ones used by Kipf et al. [12] are generated, a more complex mode which includes predicates involving disjunctions, string comparisons with regex predicates, IS (NOT) NULL comparisons and IN operators (resembling the complexity of the JOB-workload) and finally an index workload where random indexes (both foreign key and for predicate columns) are created throughout the execution of the standard workload which is challenging due to the varying physical designs. Since the benchmark will be publicly available it can be easily extended to support an even broader class of queries in the future.\n\nIn addition to the datasets and the workload generator, the benchmark comes with workload traces (e.g., executions of the queries and their runtime) for all 20 databases that can be used directly by other researchers as training / testing data (which we also used in our evaluation). To be more precise, we generated 15, 000 queries per database and executed those queries on a Postgres DBMS (v12) on c8220 nodes on the cloudlab platform. Overall, this also allows for a better reproducibility since this platform can be used by other researchers as well. To limit the already excessive resource consumption required to produce this trace, we excluded queries running longer than 30 seconds from the benchmark. In total, the execution of these more than 300k queries takes 10 days if executed on a single node. As part of the traces, we not only provide the Overall, zero-shot models are significantly more accurate than the scaled estimates of the optimizer cost model.\n\nruntime of the query but also the physical plan used to run the query along with actual cardinalities.\n\n\nExperimental Evaluation\n\nIn this Section, we evaluate zero-shot cost estimation with a set of different experiments:\n\n\u2022 Exp 1. Zero-Shot Accuracy. We evaluate how accurately zero-shot cost models can predict costs for unseen databases. \u2022 Exp 2. Zero-Shot vs. Workload-Driven. In addition, we compare the training overhead and accuracy with state-ofthe-art workload driven approaches. \u2022 Exp 3. Generalization. In this experiment, we study how our models generalize under workload drifts (i.e., under database updates and larger unseen joins). \u2022 Exp 4. Extensions. We then study the broad applicability of zero-shot cost models beyond single-node cost estimation (i.e., for distributed DBMSs and different physical designs). \u2022 Exp 5. Training and Inference Performance. Furthermore, we evaluate the training and inference performance of zero-shot cost models and compare training efforts to workload-driven models. \u2022 Exp 6. Ablation Study. Finally, we show the effects of different design alternatives of zero-shot models as well as a study where we determine how many database are sufficient for zero-shot cost models to generalize. For all experiments, we use the traces of the benchmark discussed before (for training and testing).\n\n\nExp 1: Zero-Shot Accuracy\n\nFirst, in order to evaluate the accuracy of zero-shot cost models, we trained a zero-shot model using workloads on 19 out of the 20 datasets of the benchmark as training data and evaluated the model on the workload of the unseen (remaining) database. In particular, we use the trained model to predict the runtimes of the queries on the unseen database and report the median Q-error. In the first experiment, we focus on the standard workloads and defer the results of the complex and index workloads of our benchmark to follow-up experiments. For this experiment, we repeat the cost estimation for every unseen database with three runs using different seeds\n\nFor showing the performance of zero-shot cost models on unseen databases, we used two variants of providing intermediate cardinalities -we either used predictions of learned cardinality estimators or the actual cardinalities which are not available in practice prior to execution but serve as an interesting upper baseline for zero-shot learning (i.e., how accurate the predictions become with perfect cardinality estimates). For the data-driven cardinality estimator, we trained DeepDB [10] models, which worked best in preliminary experiments.\n\nTo the best of our knowledge, we are the first to propose zeroshot cost estimation and thus no other learned approaches are included as a direct baseline in this first experiment where we aim to analyze the accuracy on unseen databases. For instance, workload-driven approaches would need query executions on the unseen database which we do not provide in the zero-shot setting. However, we compare our approach with workload-driven models in Section 7.2.\n\nAs a sanity check that zero-shot models provide better performance than classical cost estimation models that rely on simple (non-learned) techniques (and as such could also count as zero-shot cost models), we use cost estimates coming from the Postgres query optimizer as a baseline similar to previous work [28]. Moreover, for the distributed setup we later on also employ the cost estimates of a commercial cloud DBMS. Since Postgres cost estimates are provided as abstract cost units, we use a simple linear model on top of Postgres estimates (and hence the results are called Scaled Optimizer) which provides actual query runtimes. Different from [28] which directly take the cost units as runtime (in ms), using a linear model on top results in a much lower Q-error for Postgres. For training the simple linear model we are using the same training data from the other 19 databases as for zero-shot models to be fair.\n\nThe results can be seen in Figure 5. In general, the zero-shot models offer robust performances for all of the databases despite the varying complexity. In fact, all median Q-errors are below 1.54 for the version using DeepDB cardinality estimates (vs. 8.62 in the worst case for the Scaled Optimizer cost). Finally, we can see that zero-shot cost models using DeepDB cardinalities are almost matching the performance with perfect cardinalities. This suggests that the models can cope with partially inaccurate cardinalities. Indeed, as we will see in a follow-up experiment, this even holds when we use potentially inaccurate cardinality estimates coming from a classical the optimizer instead.\n\nOverall, we can see that the zero-shot cost models are significantly more accurate than the scaled optimizer estimates outperforming these on 18 out of 19 datasets and being on par for the last remaining dataset (Airline). The reason is that zero-shot cost models capture subtleties in operator performance and interactions of operators in the plan more accurately than simplistic cost models. The results are just on par for the remaining database since the optimizer costs are relatively accurate because it is merely a star schema, i.e., a relatively simple schema structure.\n\n\nExp 2: Zero-Shot vs. Workload-Driven\n\nIn the following, we contrast the performance of zero-shot cost models with workload-driven approaches. Even the most accurate workload-driven model (E2E) requires approximately 50k query executions on an unseen database for a comparable performance with zero-shot models which is roughly equivalent to 66 hours of executed workload. Since zero-shot models do not require any additional queries it is significantly cheaper to deploy them for a new database. However, zero-shot models can be fine-tuned to obtain few-shot models which further improve the accuracy.\n\n\nTraining\n\nOverhead. An interesting question is how many training queries are required for workload-driven learning on an unseen database to match the performance of zero-shot learning which we will study next. In particular, in this experiment we evaluate the Qerrors for the standard workloads (scale, synthetic, and JOB-light) on the IMDB database. As before zero-shot models are not trained on IMDB at all (but on the other 19 databases) while workloaddriven models are trained on a varying number of training queries on IMDB.\n\nFor the workload-driven approaches we use the E2E model proposed by Sun and Li [28] as well as the MSCN model by Kipf et al. [12]. The idea of the E2E models is to featurize the physical query plans and feed them into a neural model to predict the runtime. However, in contrast to zero-shot cost models the query plan representation is not transferable and thus the train and test databases have to be identical. The MSCN model which was initially developed for cardinality estimation uses a more high level representation and encodes the sets of joins, predicates and tables of a query which are then fed into a neural architecture which is thus oblivious of the physical plans used. Both models are trained on a varying number of training queries which are generated for the IMDB dataset similar to the original training setup used by Sun and Li [28]. Furthermore, as a last baseline, we again employ the scaled costs of the Postgres query optimizer.\n\nIn Figure 6, we depict the median Q-error of comparing our zero-shot performance to the baselines as discussed before for the IMDB benchmark workloads for a varying number of training queries. As we can see the zero-shot cost models can estimate the runtimes accurately even though queries on the IMDB dataset   Figure 7: JOB-Full Workload. Zero-shot models are significantly more accurate than the workload-driven model (E2E) and the scaled optimizer estimates even for the complex JOB benchmark. Again few-shot learning can further improve the performance of zero-shot models.\n\nwere not observed in the training data. In particular, E2E requires about 50k training queries on the IMDB database to be on-par with zero-shot cost models. As we can see in the lower right plot in Figure 6 this amount of queries takes approximately 66 hours to run which is a significant effort given that it has to be repeated for every new database. Another interesting comparison is to use the training queries also to fine-tune the zero-shot models on the IMDB database; i.e., we use zero-shot models in the few-shot mode discussed in the paper. As we can see, few-shot cost models that are fine-tuned on the IMDB database can further improve the cost estimation accuracy of zero-shot models. It is thus beneficial to also leverage fine-tuning in case training queries for the unseen database are available. Finally, we can see that the MSCN models are not equally accurate which is likely due to the fact that they do not consider the physical plan that was run to execute a given query. Still, all learned approaches are more accurate than the scaled optimizer in the median after only a few queries. Furthermore, we can observe that zero-shot and few-shot cost models not only outperform workloaddriven models in the median but also in the tail performance, i.e., on the 95th percentile Q-error. We can observe similar effects for the maximum Q-error.\n\nComplex Queries. In this experiment, we next focus on the performance for complex queries. For this, we again train on 19 datasets and test on the IMDB database (this time using the complex benchmark queries) using the JOB-Full benchmark which (different from the other workloads on IMDB) contains also queries with a higher number of joins and more complex predicates including patternmatching queries on strings. Note that data-driven models do not support complex predicates and we thus resort to the cardinality estimates of the query optimizer (Postgres) to inform the zero-shot model. As baselines, we again compare to the scaled optimizer costs and E2E which in contrast to MSCN supports complex predicates. To be fair, we use training queries with complex predicates on IMDB for the workload-driven models. In addition, we also report the accuracy of zero-shot models fine-tuned on the IMDB database using the few-shot learning.\n\nAs we can see in Figure 7, again zero-shot models outperform the other approaches. In particular, even the version using just optimizer cardinality estimates is more accurate than E2E using 50 queries which emphasizes that zero-shot cost models are robust w.r.t. imprecise cardinality estimates. The E2E models in this case need 50 queries just to match the performance of the scaled optimizer costs which is inferior to the previous experiment with a \n\n\nQ-Errors\n\nTrain on 0-3 Way/ Test on 4+ Way Joins Figure 9: Zero-shot cost models generalize robustly to larger Joins. Compared to zero-shot models trained also on larger joins (Full), the zero-shot models trained only on smaller joins (Small Joins) have only minor regressions in accuracy. In addition, fine-tuning the zero-shot cost models on a low number of additional queries with larger joins (resulting in few-shot models) further improves the performance.\n\nlower query complexity. The reason is that the E2E model has to learn the data distribution of strings as well and support complex predicates including wildcards while only observing queries. We hope that in future, data-driven models support string predicates and disjunctions as well to be used in conjunction with zero-shot cost models also for complex queries. Similar to the previous experiment, few-shot learning can further improve the accuracy.\n\n\nExp 3: Generalization\n\nIn this experiment, we investigate how robustly zero-shot cost models react to changes in the data characteristics and workload.\n\nGeneralization to Updates. For the first aspect, we analyze the effects of updates on the accuracy of cost estimation. For this, we only train on a fraction of the full data and then update the database (without retraining the prediction models). After the update of the database, we then predicted the query runtimes using zero-shot cost models as well as the other baselines (workload-driven models and the scaled optimizer). Note, that workload-driven models are expected to result in inferior performance for a higher fraction of updates since they cannot capture database updates without collecting new training data. This is very different from zero-shot models that get informed by data-driven models that can thus adjust to data updates without the need to retrain. In particular, the datadriven models from DeepDB [10] as well as classical statistics such as histograms that are compatible with zero-shot cost models are directly updateable with low overhead and hence can provide also accurate estimates after the update.\n\nWe depicted the results in Figure 8. As we can see, there is almost no performance degradation for the zero-shot cost models  Table 3: Q-errors for IMDB benchmarks on a commercial distributed cloud data warehouse.\n\nwith a higher update fraction. Note that we did not retrain the zero-shot cost models at all to achieve the performance but simply relied on the ability to generalize to different data characteristics. In contrast, for workload-driven models we observe a performance degradation since those models would require additional training queries on the updated database to be adapted. The reason is that the models also internalize the data distribution (i.e., table sizes and correlations) implicitly during the training and can only be informed about changes by observing additional query runtimes. This is especially problematic for more update-heavy workloads were frequently additional training queries have to be run to update the models. Note that the scaled optimizer costs do not experience such a degradation but are again less accurate than zero-shot models. Generalization to Workload Drifts. In this experiment, we investigate how zero-shot models react to workload drifts, in particular to larger joins that appear after training a cost prediction model. To this end, we trained the zero-shot models using only queries with up to 2 or 3-way joins on the 19 training datasets and evaluate the model using 3-way or 4-way joins (or larger) on the IMDB dataset, respectively. Since we suggest to address workload-drifts using few-shot learning, we also introduce variants that are fine-tuned on a small amount of large joins on the IMDB database. As we can see in Figure 9, the performance of the model with a training set constrained to small joins does not degrade heavily compared to the model that was also trained on larger joins on the remaining 19 datasets (Full) indicating a robust generalization to larger joins. In addition, few-shot models fine-tuned on a small amount of larger joins (\u2248 50) observed on the IMDB dataset is sufficient to achieve the same median Q-error. An even larger amount of retraining queries allows to outperform the original zero-shot model which is consistent with previous experiments showing that few-shot learning further improves the accuracy.\n\n\nExp 4: Extensions\n\nWe now investigate how zero-shot models can be extended to support distributed DBMSs and different physical designs.\n\nDistributed DBMSs. In this experiment, we executed the standard queries on a commercial cloud DBMS and use the models to predict query runtimes of the IMDB benchmarks on this system. To this end, we adapted our zero-shot model architecture as described in Section 5.1 and compare it with the scaled cost estimates of the internal query optimizer of the system. To the best of our knowledge, workload-driven approaches for cost estimation do not support distributed DBMSs as of today which is why we could not employ them as a baseline. The results are given in Table 3. As we can see, zero-shot cost models are already able to outperform the cost estimates of the internal query optimizer of the DBMS. We believe that with more targeted features, the performance could even be improved further.\n\nPhysical Designs. Second, we investigate how robustly zero-shot cost models generalize to unseen physical designs -in particular 5 10 15 20 Number of Databases \n\n\nExp 5: Efficiency of Training and Inference\n\nIn this experiment, we evaluate the efficiency of training and inference of zero-shot models compared to workload-driven models.\n\nTraining Overhead. In a first experiment, we compare the number of training queries required for zero-shot models as well as for workload-driven models. Importantly, workload-driven models need to be trained on every single database while zero-shot models can (once trained) be applied to many different databases out-of-the-box. For showing this effect we analyze how many training queries would be required for supporting a varying number of unseen databases for which new cost estimates are required The results are shown in Figure 10a. As we can see since workload execution is a one-time effort for zero-shot models (since they generalize across databases) this quickly amortizes compared to workload-driven learning since for workload-driven models, we need to collect training data for every new database.\n\nTraining and Inference Throughput. In a second experiment, we compare the training and inference throughput of zero-shot cost models with state-of-the-art workload-driven approaches. In this experiment, we aim to show that zero-shot models are not imposing higher overhead for training and inference and thus can be used efficiently in real DBMSs. As we can see in Figure 10b, zero-shot models achieve a comparable throughput and thus do not impose higher overhead comapred to workload-driven models. As we can see, the MSCN models achieve higher throughput compared to all other models (zero-shot and E2E). The reason is that these models  Figure 11: Ablation Study. Using a flattened representation of the plans instead of our graph-based encoding yields less accurate models. Zero-shot models using the cardinality estimates of the query optimizer are still reasonably accurate. 5 Figure 12: Zero-Shot Generalization by Number of Training Databases. If we use more than 15 training databases we start to see diminishing returns in accuracy suggesting that the variety of databases in the benchmark is sufficient.\n\nfeaturize the physical query plan resulting in larger graphs compared to MSCN models which only encode the joins, tables and predicates in a query. However, this comes at the cost of an inferior predictive performance as shown before.\n\n\nExp. 6: Ablation Study\n\nIn this experiment, we present the results of our ablation study showing the effects of the different design choices as well as the efficiency of our estimator to determine how many different databases are needed for training a zero-shot model.\n\nZero-Shot Design Space. We first explore the different design space options of zero-shot cost estimation. In particular, we focus on the questions how different cardinality estimation techniques impact the model accuracy and whether our new model architecture using graph encodings is actually required or a simpler architecture suffices.\n\nTo address the latter question, we implemented a different version of zero-shot cost estimation that represents a single query plan as a flat vector (instead of using a graph). In particular, the chosen representation is similar to Ganapathi et al. [5] that represents a query plan using a vector where each physical operator corresponds to two entries in the vector: one that counts how often the operator appears in the plan and one that sums up the cardinality estimates for that operator. For instance, if we only had sequential scans and nested loop joins in the query plans and one plan would scan two relations of 1M tuples each and join them resulting in 1M tuples, the vector representing the query plan could be (2, 2 , 1, 1 ). Given this representation, we train a state-of-the-art regression model [11] to predict the runtime given a vector. Similar to the zero-shot models, we train on the remaining 19 datasets and evaluate the performance on the IMDB benchmarks.\n\nAs we can see in Figure 11, the flattened version of zero-shot cost models is significantly less accurate than our proposed transferable graph-based representation. The reason is that the interactions of physical operators in the plan can only be modeled approximately if represented as a vector while our graph-based encoding allows the neural model to capture such interactions more accurately. Second, regarding cardinality estimates, we can see that data-driven cardinality estimates improve the accuracy of zero-shot cost models compared to models using optimizer cardinality estimates. However, the estimates are still very accurate even if cardinality estimates are annotated from simple cardinality estimation models that are used in DBMSs today. This is especially useful for query types that datadriven models do not support as of today and where the optimizer cardinality estimates hence serve as a fallback.\n\nNumber of Training Databases. As described in Section 4.1, in order to assess whether a zero-shot cost model has seen a sufficient number of training databases and workloads, we estimate the expected generalization error for a varying number of training databases. The generalization error is estimated by computing the test error on an unseen holdout database. If the model performance plateaus for a certain number of training databases, we can conclude that the number of training databases is sufficient.\n\nIn this experiment, we show how the generalization error develops for a growing number of training databases (i.e., from just using one up to all 19 databases). For estimating the generalization error, we use the standard benchmark queries as defined on the IMDB dataset (i.e., we use the synthetic, scale and JOB-light [12] workloads). As we can observe in Figure 12, as expected the generalization errors reduce with a growing number of databases. This is the case because with an increased number of databases the model can observe a larger variety of different data characteristics and can thus more robustly predict the runtimes for an unseen database, i.e., IMDB in this case. Interestingly, we can already achieve a reasonably small generalization error after just five different databases indicating that a moderate number of databases can be sufficient for zero-shot learning. Moreover, we clearly observe diminishing returns between 15 to 19 databases.\n\nWe can thus conclude that the number of training datasets from the benchmark is indeed sufficient to allow a zero-shot model to generalize robustly to unseen databases from the benchmark and that further datasets will likely not improve the model performance.\n\n\nRelated Work\n\nLearned Cost Estimation. Closest to our work are workloaddriven approaches for cost estimation. Neural predictions models [22,28] have been proposed for cost estimation by featurizing the physical query plan as a tree. However, the models are workload-driven and thus require thousands of query executions for an unseen database. Recently, a framework has been proposed to efficiently gather this training data [30]. In contrast, zero-shot learning completely alleviates the need to run a representative workload for new databases. Moreover, workload-driven models were extended by improving inference and training performance [35] and to concurrent query latency prediction [36]. These ideas are orthogonal and could potentially be applied to zero-shot learning as well. An alternative to reduce the required training queries for cost estimation is DBMS fitting [8] where the idea is to model the operator complexity and adjust this basic model by fitting the parameters using differentiable programming. However, the operator complexity has to be modeled explicitly which can be impossible for complex queries.\n\nEarlier work proposes to use statistical methods to predict the costs of queries. For instance, it was proposed to learn models at a per-operator level [2,16] to predict the overall query runtime. However, since interactions of operators cannot be learned and the models are thus too simplistic, the performance is inferior to workload-driven approaches [22]. An alternative idea is to represent query plans as flat vectors [5] to treat cost estimation using supervised regression which we have shown to be less accurate than zero-shot cost estimation (cf. Section 7.1).\n\nIn addition, it was suggested to leverage query executions on smaller data samples or different hardware instantiations [4,29] or queries sharing common subexpressions [27,31] to more accurately predict the costs. In both cases, the test workload needs to closely resemble the train workload for the models to be effective again limiting the applicability. In contrast, we have shown that zero-shot models generalize to a diverse set of workloads.\n\nLearned DBMS components and Design Advisors Machine learning has been applied more broadly to optimize DBMS systems by replacing traditional approaches for tasks such as query optimization [13,[19][20][21] or query scheduling [18,26]. In addition, it was applied to knob tuning [34], materialized view selection [7,17], index selection [14] or partitioning [9]. Note that all these approaches are workload-driven since query executions on the test database are required to train the models. We believe that zero-shot cost estimation could be used to support a variety of these tasks since they crucially depend on accurate cost estimates.\n\n\nConclusion and Future Work\n\nIn this paper, we have demonstrated that it is possible to accurately and robustly predict query runtimes on entirely unseen databases, i.e., in a zero-shot setting. In addition, fine-tuning the zero-shot models to obtain few-shot models can further improve the performance if training queries are available on the new database. We enabled this by deriving a transferable representation of queries that generalizes across databases and a specialized model architecture.\n\nAs a future direction, we argue that zero-shot learning has even a much broader applicability and could be applied to a large set of learned DBMS components including design advisors etc. Furthermore, we believe that the underlying principles can be applied to an even broader set of data systems (e.g., data streaming systems).\n\n\nAcknowledgments\n\nThis research and development project is funded by the German Federal Ministry of Education and Research (BMBF) within the \"The Future of Value Creation -Research on Production, Services and Work\" program and managed by the Project Management Agency Karlsruhe (PTKA). The author is responsible for the content of this publication. In addition, the research was partly funded by the Hochtief project AICO (AI in Construction), the HMWK cluster project 3AI (The Third Wave of AI), as well as the DFG Collaborative Research Center 1053 (MAKI). Finally, we want to thank the Amazon Redshift team for valuable discussions.\n\nFigure 1 :\n1Cost Estimation Errors on the IMDB database.\n\nFigure 3 :\n3Using Zero-Shot Models for Cost Estimation (i.e., for Inference) on a unseen Database. (1) A query is represented as a graph with different node types (to represent plan operators, predicates, tables, attributes etc.) and nodes are annotated with transferable features which generalize across databases. (2) Afterwards, the resulting feature vectors of the nodes are fed into node-type-specific Multi-Layer-Perceptrons (MLPs) to obtain a hidden state which is (3) propagated through the query-tree using bottom-up message passing to account for interactions among connected nodes. (4) Finally, the hidden state of the root node (encoding the entire graph) is fed into a final model -the estimation MLP -which predicts the query runtime.\n\nFigure 4 :\n4Extension of Zero-shot Models to Distributed Cloud Data Warehouses. The columnar storage is accounted for by adding only nodes representing scanned columns to the graph whereas network shuffle operations (such as broadcast, partition by key etc.) required for distributed join execution are represented as physical plan nodes.\n\nFigure 5 :\n5Zero-Shot Generalization across Databases. The zero-shot models are trained using workloads on 19/20 databases and tested on the remaining unseen database.\n\nFigure 6 :\n6Estimation Errors of Workload-Driven Models for a varying Number of Training Queries compared with Zero-Shot Cost Models.\n\nFigure 8 :\n8Zero-Shot Models are robust w.r.t. Updates. Without any retraining we do not see regressions in cost estimation accuracy even for massive update rates. In contrast, workload-driven models require additional training queries.\n\nTable Table\nTableAttribute \n\nMIN(...) \n\n= \n\nAttribute Attribute Attribute \n\nSELECT MIN(t.production_year) FROM title t, movie_companies mc WHERE t.id=mc.movie_id AND mc.company_type_id=2; \n\nGraph Encoding with Transferable Features \n\n2100ms \n\nMessage Passing \n\nInput Query \n\n1 \n3 \n4 \n\nNode Encoding \n\n2 \n\nRuntime Prediction \n\nEstimation MLP \n\nInitialize Hidden \nStates using MLP \nper Node Type \n\n= \n\nfeatures x8 \nopname: scan \ncard out : 550k* \n\nwidth: 4 \n\n*Input from Data-\nDriven Model \n\nfeatures x 1 \nrelpages: 21 \n\nfeatures x 5 \ndata_type: integer \n\nfeatures x 7 \noperator: = \n\nh 13 \nh 11 \n\nh 8 \u2192h' 8 \n\nh 10 \n\nh 9 \n\nh' 0 \nh' 1 \n\nh' 2 \n\nh 12 \n\nh' 6 \n\nh' 3 \nh' 4 \nh' 5 \n\nh' 7 \n\nCombine Child Hidden \nStates and propagate up e.g., \nh' 8 =MLP' operator (h 8 \u2295(h' 1 +h' 7 )) \n\nBottom-Up \nMessage Passing \n\ntitle \nmovie_companies \n\n0 \n\ne.g., h 8 =MLP operator (x 8 ) \n=MLP operator ([0 1 550 4]), \nwhere opname=scan is \nencoded as [0 1] \n\nInput: Hidden State of Root \nNode (Captures entire Plan) \n\nJoin Predicates \nTable Node with Transf. \nFeatures instead of One-\nHot-Encoding \n\n\n\nTable 1 :\n1Zero-Shot Features. All features are transferable and have the same semantics for different databases.\n\n\nAlgorithm 1 Inference on Zero-Shot Models 1: Input: Query graph encoding with nodes and input features 2: Output: Cost estimate3 : 4: for \u2208 graph encoding do\u22b2 Compute hidden state per node 2 \n\n5: \n\n\u210e \u2190 MLP ( ) ( ) \n\n6: for \u2208 in topological ordering do \n\n\u22b2 Bottom-up pass in graph 3 \n\n7: \n\n\n\nTable 2 :\n2Trade-offs of different Cardinality estimators used with Zero-shot Models. Data-driven models are a promising choice offering low overhead and high accuracy.often imprecise[15]. Hence, learned approaches to tackle cardinality estimation have been proposed to derive accurate intermediate cardinalities. While in principle such learned approaches can be used to predict intermediate cardinalities which are then used as input for the zero-shot models, there are important trade-offs when choosing which techniques are suitable for zero-shot learning (cf.\n\nTable Table .\nTable..Operator Nodes: \nrepresent Network \nDistribution \n\nScanned Column \n\nScanned Column \nNodes: account for \nColumnar Storage \n\nScanned Column \n\n\n\n\nFigure 10: Training and Inference and Performance. Even though zero-shot models generalize across databases they almost match the inference and training throughput of the most accurate workload-driven alternative (E2E) and quickly amortize in terms of required training queries.using an unseen set of indexes. We again train the zero-shot cost model on 19 databases and evaluate it using the IMDB database where this time indexes are created during the execution of the training workload. For training, we use index workloads of our benchmark that involves query executions using indexes on the other 19 databases. On the IMDB database with different indexes, we observed median Q-errors of 1.21, 1.28 and 1.34 using the zero-shot variants using exact, DeepDB-estimated and cardinalities estimated by the Postgres optimizer, respectively which is comparable to the Q-errors reported before without indexes.250k \n\n500k \n\n750k \n\n1M \n\nTraining \nQueries \n\nE2E (Workload-Driven) \nZero-Shot \n\n(a) Required Training Queries. \n\nTraining \nInference \n0 \n\n1000 \n\nThroughput \n(Plans/sec) \n\nMSCN (Workload-Driven) \n\nE2E (Workload-Driven) \nZero-Shot \n(DeepDB Est. Cardinalities) \nZero-Shot \n(Exact Cardinalities) \n\n(b) Train and Test Throughput. \n\n\n\n\nScale Synthetic JOB-lightMedian Q-ErrorWorkload \n\n1.0 \n\n1.5 \n\nFlattened Plans \nZero-Shot \n(Est. Cardinalities) \nZero-Shot \n(DeepDB Est. Cardinalities) \nZero-Shot \n(Exact Cardinalities) \n\n\n\n\n10 15    Number of \nTraining Datasets \n\n1.25 \n\n1.50 \n\n1.75 \n\nMedian Q-Error \n\nScale \n\n5 10 15 \n\nNumber of \nTraining Datasets \n\n1.5 \n\n2.0 \n\nSynthetic \n\n5 10 15 \n\nNumber of \nTraining Datasets \n\n1.25 \n\n1.50 \n\n1.75 \n\nJOB-light \n\nZero-Shot \n(DeepDB Est. Cardinalities) \n\nZero-Shot \n(Exact Cardinalities) \n\n\nThroughout this paper, we use the term database to refer to a particular dataset with certain data characteristics.\n\n. Tpc-H Benchmark, TPC-H benchmark. http://www.tpc.org/tpch/.\n\nLearning-based Query Performance Modeling and Prediction. Mert Akdere, Ugur \u00c7etintemel, Matteo Riondato, Eli Upfal, Stanley B Zdonik, 10.1109/ICDE.2012.642012 IEEE 28th International Conference on Data Engineering. Mert Akdere, Ugur \u00c7etintemel, Matteo Riondato, Eli Upfal, and Stanley B. Zdonik. 2012. Learning-based Query Performance Modeling and Prediction. In 2012 IEEE 28th International Conference on Data Engineering. 390-401. https://doi.org/10. 1109/ICDE.2012.64\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. LinScott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec RadfordCurran Associates, Inc33Advances in Neural Information Processing SystemsTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Pra- fulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural In- formation Processing Systems, H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates, Inc., 1877-1901. https://proceedings. neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf\n\nJockey: Guaranteed Job Latency in Data Parallel Clusters. Andrew D Ferguson, Peter Bodik, Srikanth Kandula, Eric Boutin, Rodrigo Fonseca, 10.1145/2168836.2168847Proceedings of the 7th ACM European Conference on Computer Systems. the 7th ACM European Conference on Computer SystemsBern, Switzerland; New York, NY, USAAssociation for Computing MachineryEuroSys '12)Andrew D. Ferguson, Peter Bodik, Srikanth Kandula, Eric Boutin, and Rodrigo Fonseca. 2012. Jockey: Guaranteed Job Latency in Data Parallel Clusters. In Proceedings of the 7th ACM European Conference on Computer Systems (Bern, Switzerland) (EuroSys '12). Association for Computing Machinery, New York, NY, USA, 99-112. https://doi.org/10.1145/2168836.2168847\n\nPredicting Multiple Metrics for Queries: Better Decisions Enabled by Machine Learning. Archana Ganapathi, Harumi Kuno, Umeshwar Dayal, Janet L Wiener, Armando Fox, Michael Jordan, David Patterson, 10.1109/ICDE.2009.130IEEE 25th International Conference on Data Engineering. Archana Ganapathi, Harumi Kuno, Umeshwar Dayal, Janet L. Wiener, Armando Fox, Michael Jordan, and David Patterson. 2009. Predicting Multiple Metrics for Queries: Better Decisions Enabled by Machine Learning. In 2009 IEEE 25th International Conference on Data Engineering. 592-603. https://doi.org/10.1109/ ICDE.2009.130\n\nNeural Message Passing for Quantum Chemistry. Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, George E Dahl, Proceedings of the 34th International Conference on Machine Learning (Proceedings of Machine Learning Research. Doina Precup and Yee Whye Tehthe 34th International Conference on Machine Learning ( Machine Learning ResearchSydney, AustraliaPMLR, International Convention Centre70Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. 2017. Neural Message Passing for Quantum Chemistry. In Proceed- ings of the 34th International Conference on Machine Learning (Proceedings of Machine Learning Research), Doina Precup and Yee Whye Teh (Eds.), Vol. 70. PMLR, International Convention Centre, Sydney, Australia, 1263-1272. http: //proceedings.mlr.press/v70/gilmer17a.html\n\nAn autonomous materialized view management system with deep reinforcement learning. Yue Han, Guoliang Li, Haitao Yuan, Ji Sun, 2021 IEEE 37th International Conference on Data Engineering (ICDE). IEEEYue Han, Guoliang Li, Haitao Yuan, and Ji Sun. 2021. An autonomous materialized view management system with deep reinforcement learning. In 2021 IEEE 37th International Conference on Data Engineering (ICDE). IEEE, 2159-2164.\n\nDBMS Fitting: Why should we learn what we already know. Benjamin Hilprecht, Tiemo Bang, ; Carsten, Muhammad ; Binnig, Benjamin El-Hindi, Aditya H\u00e4ttasch, Khanna, Uwe Robin; Rehrmann, Andreas R\u00f6hm, Lasse Schmidt, Tobias Thostrup, Ziegler, CIDR 2020. Amsterdam, Netherlands43.22.03; LK 01Benjamin Hilprecht, Tiemo Bang, Carsten; Binnig, Muhammad; El-Hindi, Ben- jamin H\u00e4ttasch, Aditya Khanna, Robin; Rehrmann, Uwe R\u00f6hm, Andreas Schmidt, Lasse Thostrup, and Tobias Ziegler. 2020. DBMS Fitting: Why should we learn what we already know. In CIDR 2020, January 12-15, 2020 Amsterdam, Netherlands. 43.22.03; LK 01.\n\nLearning a Partitioning Advisor for Cloud Databases. Benjamin Hilprecht, Carsten Binnig, Uwe R\u00f6hm, 10.1145/3318464.3389704Proceedings of the 2020 ACM SIG-MOD International Conference on Management of Data. the 2020 ACM SIG-MOD International Conference on Management of DataPortland, OR, USA; New York, NY, USAAssociation for Computing MachinerySIG-MOD '20)Benjamin Hilprecht, Carsten Binnig, and Uwe R\u00f6hm. 2020. Learning a Par- titioning Advisor for Cloud Databases. In Proceedings of the 2020 ACM SIG- MOD International Conference on Management of Data (Portland, OR, USA) (SIG- MOD '20). Association for Computing Machinery, New York, NY, USA, 143-157. https://doi.org/10.1145/3318464.3389704\n\nBenjamin Hilprecht, Andreas Schmidt, Moritz Kulessa, Alejandro Molina, 10.14778/3384345.3384349Kristian Kersting, and Carsten Binnig. 2020. DeepDB: Learn from Data, Not from Queries! Proc. VLDB Endow. 13Benjamin Hilprecht, Andreas Schmidt, Moritz Kulessa, Alejandro Molina, Kris- tian Kersting, and Carsten Binnig. 2020. DeepDB: Learn from Data, Not from Queries! Proc. VLDB Endow. 13, 7 (March 2020), 992-1005. https://doi.org/10. 14778/3384345.3384349\n\nLightGBM: A Highly Efficient Gradient Boosting Decision Tree. Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu, Advances in Neural Information Processing Systems. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. GarnettCurran Associates, Inc30Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. 2017. LightGBM: A Highly Efficient Gradient Boosting Decision Tree. In Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/paper/ 2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf\n\nLearned Cardinalities: Estimating Correlated Joins with Deep Learning. Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter A Boncz, Alfons Kemper, CIDR 2019, 9th Biennial Conference on Innovative Data Systems Research. Asilomar, CA, USAOnline ProceedingsAndreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter A. Boncz, and Alfons Kemper. 2019. Learned Cardinalities: Estimating Correlated Joins with Deep Learning. In CIDR 2019, 9th Biennial Conference on Innovative Data Systems Research, Asilomar, CA, USA, January 13-16, 2019, Online Proceedings.\n\nLearning to Optimize Join Queries With Deep Reinforcement Learning. S Krishnan, Z Yang, Ken Goldberg, J Hellerstein, I Stoica, ArXiv abs/1808.03196S. Krishnan, Z. Yang, Ken Goldberg, J. Hellerstein, and I. Stoica. 2018. Learning to Optimize Join Queries With Deep Reinforcement Learning. ArXiv abs/1808.03196 (2018).\n\nAn Index Advisor Using Deep Reinforcement Learning (CIKM '20). Hai Lan, Zhifeng Bao, Yuwei Peng, 10.1145/3340531.3412106Association for Computing MachineryNew York, NY, USAHai Lan, Zhifeng Bao, and Yuwei Peng. 2020. An Index Advisor Using Deep Reinforcement Learning (CIKM '20). Association for Computing Machinery, New York, NY, USA, 2105-2108. https://doi.org/10.1145/3340531.3412106\n\nQuery Optimization through the Looking Glass, and What We Found Running the Join Order Benchmark. Viktor Leis, Bernhard Radke, Andrey Gubichev, Atanas Mirchev, Peter Boncz, Alfons Kemper, Thomas Neumann, 10.1007/s00778-017-0480-7The VLDB Journal. 27Viktor Leis, Bernhard Radke, Andrey Gubichev, Atanas Mirchev, Peter Boncz, Alfons Kemper, and Thomas Neumann. 2018. Query Optimization through the Looking Glass, and What We Found Running the Join Order Benchmark. The VLDB Journal 27, 5 (Oct. 2018), 643-668. https://doi.org/10.1007/s00778-017- 0480-7\n\nRobust Estimation of Resource Consumption for SQL Queries Using Statistical Techniques. Jiexing Li, Arnd Christian K\u00f6nig, Vivek Narasayya, Surajit Chaudhuri, 10.14778/2350229.2350269Proc. VLDB Endow. VLDB Endow5Jiexing Li, Arnd Christian K\u00f6nig, Vivek Narasayya, and Surajit Chaudhuri. 2012. Robust Estimation of Resource Consumption for SQL Queries Using Statistical Techniques. Proc. VLDB Endow. 5, 11 (July 2012), 1555-1566. https://doi.org/10. 14778/2350229.2350269\n\nOpportunistic View Materialization with Deep Reinforcement Learning. Xi Liang, Aaron J Elmore, Sanjay Krishnan, arXiv:1903.01363Xi Liang, Aaron J. Elmore, and Sanjay Krishnan. 2019. Opportunistic View Materialization with Deep Reinforcement Learning. CoRR abs/1903.01363 (2019). arXiv:1903.01363 http://arxiv.org/abs/1903.01363\n\nLearning Scheduling Algorithms for Data Processing Clusters. Hongzi Mao, Malte Schwarzkopf, Zili Shaileshh Bojja Venkatakrishnan, Mohammad Meng, Alizadeh, 10.1145/3341302.3342080SIGCOMM '19). Beijing, China; New York, NY, USAAssociation for Computing MachineryHongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng, and Mohammad Alizadeh. 2019. Learning Scheduling Algorithms for Data Pro- cessing Clusters. In Proceedings of the ACM Special Interest Group on Data Commu- nication (Beijing, China) (SIGCOMM '19). Association for Computing Machinery, New York, NY, USA, 270-288. https://doi.org/10.1145/3341302.3342080\n\nBao: Making Learned Query Optimization Practical. Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Alizadeh, Tim Kraska, 10.1145/3448016.3452838Proceedings of the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21). the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21)New York, NY, USAAssociation for Computing MachineryRyan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Al- izadeh, and Tim Kraska. 2021. Bao: Making Learned Query Optimization Practical. In Proceedings of the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21). Association for Computing Machinery, New York, NY, USA, 1275-1288. https://doi.org/10.1145/3448016.3452838\n\nNeo: A Learned Query Optimizer. Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh, Tim Kraska, Olga Papaemmanouil, Nesime Tatbul, 10.14778/3342263.3342644Proc. VLDB Endow. 1211Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh, Tim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: A Learned Query Optimizer. Proc. VLDB Endow. 12, 11 (July 2019), 1705-1718. https: //doi.org/10.14778/3342263.3342644\n\nDeep Reinforcement Learning for Join Order Enumeration. Ryan Marcus, Olga Papaemmanouil, 10.1145/3211954.3211957Proceedings of the First International Workshop on Exploiting Artificial Intelligence Techniques for Data Management. the First International Workshop on Exploiting Artificial Intelligence Techniques for Data ManagementHouston, TX, USA; New York, NY, USA, ArticleAssociation for Computing Machinery) (aiDM'18)Ryan Marcus and Olga Papaemmanouil. 2018. Deep Reinforcement Learning for Join Order Enumeration. In Proceedings of the First International Workshop on Exploiting Artificial Intelligence Techniques for Data Management (Houston, TX, USA) (aiDM'18). Association for Computing Machinery, New York, NY, USA, Article 3, 4 pages. https://doi.org/10.1145/3211954.3211957\n\nPlan-Structured Deep Neural Network Models for Query Performance Prediction. Ryan Marcus, Olga Papaemmanouil, 10.14778/3342263.3342646Proc. VLDB Endow. 1211Ryan Marcus and Olga Papaemmanouil. 2019. Plan-Structured Deep Neural Network Models for Query Performance Prediction. Proc. VLDB Endow. 12, 11 (July 2019), 1733-1746. https://doi.org/10.14778/3342263.3342646\n\nThe CTU Prague Relational Learning Repository. Jan Motl, Oliver Schulte, arXiv:1511.03086Jan Motl and Oliver Schulte. 2015. The CTU Prague Relational Learning Reposi- tory. CoRR abs/1511.03086 (2015). arXiv:1511.03086 http://arxiv.org/abs/1511. 03086\n\nThe Making of TPC-DS. Meikel Raghunath Othayoth Nambiar, Poess, Proceedings of the 32nd International Conference on Very Large Data Bases. the 32nd International Conference on Very Large Data BasesSeoul, KoreaVLDB '06). VLDB EndowmentRaghunath Othayoth Nambiar and Meikel Poess. 2006. The Making of TPC-DS. In Proceedings of the 32nd International Conference on Very Large Data Bases (Seoul, Korea) (VLDB '06). VLDB Endowment, 1049-1058.\n\nThe star schema benchmark and augmented fact table indexing. O&apos; Patrick, Elizabeth O Neil, Xuedong Neil, Stephen Chen, Revilak, Technology Conference on Performance Evaluation and Benchmarking. SpringerPatrick O'Neil, Elizabeth O'Neil, Xuedong Chen, and Stephen Revilak. 2009. The star schema benchmark and augmented fact table indexing. In Technology Conference on Performance Evaluation and Benchmarking. Springer, 237-252.\n\nScheduling OLTP transactions via learned abort prediction. Yangjun Sheng, Anthony Tomasic, Tieying Zhang, Andrew Pavlo, Proceedings of the Second International Workshop on Exploiting Artificial Intelligence Techniques for Data Management. the Second International Workshop on Exploiting Artificial Intelligence Techniques for Data ManagementAmsterdam, The Netherlands1Yangjun Sheng, Anthony Tomasic, Tieying Zhang, and Andrew Pavlo. 2019. Scheduling OLTP transactions via learned abort prediction. In Proceedings of the Second International Workshop on Exploiting Artificial Intelligence Techniques for Data Management, aiDM@SIGMOD 2019, Amsterdam, The Netherlands, July 5, 2019. 1:1-1:8.\n\nCost Models for Big Data Query Processing: Learning, Retrofitting, and Our Findings. Tarique Siddiqui, Alekh Jindal, Shi Qiao, Hiren Patel, Wangchao Le, 10.1145/3318464.3380584Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data. the 2020 ACM SIGMOD International Conference on Management of DataPortland, OR, USA; New York, NY, USAAssociation for Computing MachinerySIGMOD '20)Tarique Siddiqui, Alekh Jindal, Shi Qiao, Hiren Patel, and Wangchao Le. 2020. Cost Models for Big Data Query Processing: Learning, Retrofitting, and Our Findings. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data (Portland, OR, USA) (SIGMOD '20). Association for Computing Machinery, New York, NY, USA, 99-113. https://doi.org/10.1145/3318464.3380584\n\nAn End-to-End Learning-Based Cost Estimator. Ji Sun, Guoliang Li, 10.14778/3368289.3368296Proc. VLDB Endow. VLDB Endow13Ji Sun and Guoliang Li. 2019. An End-to-End Learning-Based Cost Estimator. Proc. VLDB Endow. 13, 3 (Nov. 2019), 307-319. https://doi.org/10.14778/3368289. 3368296\n\nErnest: Efficient Performance Prediction for Large-Scale Advanced Analytics. Shivaram Venkataraman, Zongheng Yang, Michael Franklin, Benjamin Recht, Ion Stoica, Proceedings of the 13th Usenix Conference on Networked Systems Design and Implementation. the 13th Usenix Conference on Networked Systems Design and ImplementationSanta Clara, CA; USANSDI'16). USENIX AssociationShivaram Venkataraman, Zongheng Yang, Michael Franklin, Benjamin Recht, and Ion Stoica. 2016. Ernest: Efficient Performance Prediction for Large-Scale Advanced Analytics. In Proceedings of the 13th Usenix Conference on Networked Systems Design and Implementation (Santa Clara, CA) (NSDI'16). USENIX Associ- ation, USA, 363-378.\n\nExpand Your Training Limits! Generating Training Data for ML-Based Data Management. Francesco Ventura, Zoi Kaoudi, Jorge Arnulfo Quian\u00e9-Ruiz, Volker Markl, 10.1145/3448016.3457286Proceedings of the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21). the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21)New York, NY, USAAssociation for Computing MachineryFrancesco Ventura, Zoi Kaoudi, Jorge Arnulfo Quian\u00e9-Ruiz, and Volker Markl. 2021. Expand Your Training Limits! Generating Training Data for ML-Based Data Management. In Proceedings of the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21). Association for Computing Machinery, New York, NY, USA, 1865-1878. https://doi.org/10.1145/3448016. 3457286\n\nTowards a Learning Optimizer for Shared Clouds. Chenggang Wu, Alekh Jindal, Saeed Amizadeh, Hiren Patel, Wangchao Le, Shi Qiao, Sriram Rao, 10.14778/3291264.3291267Proc. VLDB Endow. 12Chenggang Wu, Alekh Jindal, Saeed Amizadeh, Hiren Patel, Wangchao Le, Shi Qiao, and Sriram Rao. 2018. Towards a Learning Optimizer for Shared Clouds. Proc. VLDB Endow. 12, 3 (Nov. 2018), 210-222. https://doi.org/10.14778/3291264. 3291267\n\nNeuroCard: One Cardinality Estimator for All Tables. Zongheng Yang, Amog Kamsetty, Sifei Luan, Eric Liang, Yan Duan, 10.14778/3421424.3421432Proc. VLDB Endow. VLDB Endow14Xi Chen, and Ion StoicaZongheng Yang, Amog Kamsetty, Sifei Luan, Eric Liang, Yan Duan, Xi Chen, and Ion Stoica. 2020. NeuroCard: One Cardinality Estimator for All Tables. Proc. VLDB Endow. 14, 1 (Sept. 2020), 61-73. https://doi.org/10.14778/3421424.3421432\n\nDeep Sets. Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, R Russ, Alexander J Salakhutdinov, Smola, Advances in Neural Information Processing Systems. I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. GarnettCurran Associates, Inc30Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and Alexander J Smola. 2017. Deep Sets. In Advances in Neural Information Processing Systems, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Cur- ran Associates, Inc., 3391-3401. https://proceedings.neurips.cc/paper/2017/file/ f22e4747da1aa27e363d86d40ff442fe-Paper.pdf\n\nAn End-to-End Automatic Cloud Database Tuning System Using Deep Reinforcement Learning. Ji Zhang, Yu Liu, Ke Zhou, Guoliang Li, Zhili Xiao, Bin Cheng, Jiashu Xing, Yangtao Wang, Tianheng Cheng, Li Liu, Minwei Ran, Zekang Li, 10.1145/3299869.3300085Proceedings of the 2019 International Conference on Management of Data. the 2019 International Conference on Management of DataAmsterdam, Netherlands; New York, NY, USASIGMOD '19). Association for Computing MachineryJi Zhang, Yu Liu, Ke Zhou, Guoliang Li, Zhili Xiao, Bin Cheng, Jiashu Xing, Yangtao Wang, Tianheng Cheng, Li Liu, Minwei Ran, and Zekang Li. 2019. An End-to-End Automatic Cloud Database Tuning System Using Deep Reinforce- ment Learning. In Proceedings of the 2019 International Conference on Management of Data (Amsterdam, Netherlands) (SIGMOD '19). Association for Computing Ma- chinery, New York, NY, USA, 415-432. https://doi.org/10.1145/3299869.3300085\n\nEfficient Deep Learning Pipelines for Accurate Cost Estimations Over Large Scale Query Workload. Johan Kok, Zhi Kang, Sien Gaurav, Feng Yi Tan, Shixuan Cheng, Bingsheng Sun, He, 10.1145/3448016.3457546Proceedings of the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21). the 2021 International Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21)New York, NY, USAAssociation for Computing MachineryJohan Kok Zhi Kang, Gaurav, Sien Yi Tan, Feng Cheng, Shixuan Sun, and Bing- sheng He. 2021. Efficient Deep Learning Pipelines for Accurate Cost Estima- tions Over Large Scale Query Workload. In Proceedings of the 2021 Interna- tional Conference on Management of Data (Virtual Event, China) (SIGMOD/PODS '21). Association for Computing Machinery, New York, NY, USA, 1014-1022. https://doi.org/10.1145/3448016.3457546\n\nQuery Performance Prediction for Concurrent Queries Using Graph Embedding. Xuanhe Zhou, Ji Sun, Guoliang Li, Jianhua Feng, 10.14778/3397230.3397238Proc. VLDB Endow. VLDB Endow13Xuanhe Zhou, Ji Sun, Guoliang Li, and Jianhua Feng. 2020. Query Performance Prediction for Concurrent Queries Using Graph Embedding. Proc. VLDB Endow. 13, 9 (May 2020), 1416-1428. https://doi.org/10.14778/3397230.3397238\n", "annotations": {"author": "[{\"end\":101,\"start\":68},{\"end\":130,\"start\":102},{\"end\":160,\"start\":131}]", "publisher": null, "author_last_name": "[{\"end\":86,\"start\":77},{\"end\":115,\"start\":106},{\"end\":145,\"start\":139}]", "author_first_name": "[{\"end\":76,\"start\":68},{\"end\":103,\"start\":102},{\"end\":105,\"start\":104},{\"end\":138,\"start\":131}]", "author_affiliation": "[{\"end\":100,\"start\":88},{\"end\":129,\"start\":117},{\"end\":159,\"start\":147}]", "title": "[{\"end\":65,\"start\":1},{\"end\":225,\"start\":161}]", "venue": null, "abstract": "[{\"end\":1395,\"start\":227}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b14\"},\"end\":1785,\"start\":1781},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":1915,\"start\":1911},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2193,\"start\":2192},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3099,\"start\":3095},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4271,\"start\":4268},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11922,\"start\":11918},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":11925,\"start\":11922},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":15231,\"start\":15227},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":15234,\"start\":15231},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17334,\"start\":17330},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17529,\"start\":17525},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21108,\"start\":21107},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21332,\"start\":21329},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22131,\"start\":22127},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23834,\"start\":23830},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":23837,\"start\":23834},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":35320,\"start\":35317},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":35333,\"start\":35329},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":35345,\"start\":35341},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":35788,\"start\":35784},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":35962,\"start\":35958},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":36838,\"start\":36834},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":38216,\"start\":38212},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":42274,\"start\":42270},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":43100,\"start\":43096},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":43443,\"start\":43439},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":46207,\"start\":46203},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":46253,\"start\":46249},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":46976,\"start\":46972},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":52310,\"start\":52306},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":55885,\"start\":55884},{\"end\":55894,\"start\":55889},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":57790,\"start\":57789},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":59123,\"start\":59120},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":59685,\"start\":59681},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":61605,\"start\":61601},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":62647,\"start\":62643},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":62650,\"start\":62647},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":62936,\"start\":62932},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":63152,\"start\":63148},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":63200,\"start\":63196},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":63387,\"start\":63384},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":63790,\"start\":63787},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":63793,\"start\":63790},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":63993,\"start\":63989},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":64062,\"start\":64059},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":64330,\"start\":64327},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":64333,\"start\":64330},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":64379,\"start\":64375},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":64382,\"start\":64379},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":64849,\"start\":64845},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":64853,\"start\":64849},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":64857,\"start\":64853},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":64861,\"start\":64857},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":64886,\"start\":64882},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":64889,\"start\":64886},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":64938,\"start\":64934},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":64971,\"start\":64968},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":64974,\"start\":64971},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":64996,\"start\":64992},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":65016,\"start\":65013},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":70127,\"start\":70123}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":66819,\"start\":66762},{\"attributes\":{\"id\":\"fig_2\"},\"end\":67569,\"start\":66820},{\"attributes\":{\"id\":\"fig_4\"},\"end\":67909,\"start\":67570},{\"attributes\":{\"id\":\"fig_5\"},\"end\":68078,\"start\":67910},{\"attributes\":{\"id\":\"fig_6\"},\"end\":68213,\"start\":68079},{\"attributes\":{\"id\":\"fig_8\"},\"end\":68451,\"start\":68214},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":69531,\"start\":68452},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":69646,\"start\":69532},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":69938,\"start\":69647},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":70504,\"start\":69939},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":70667,\"start\":70505},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":71904,\"start\":70668},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":72094,\"start\":71905},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":72398,\"start\":72095}]", "paragraph": "[{\"end\":1916,\"start\":1411},{\"end\":2426,\"start\":1918},{\"end\":2798,\"start\":2428},{\"end\":3436,\"start\":2800},{\"end\":4952,\"start\":3438},{\"end\":5830,\"start\":4954},{\"end\":6780,\"start\":5832},{\"end\":7734,\"start\":6782},{\"end\":8346,\"start\":7736},{\"end\":8906,\"start\":8348},{\"end\":9035,\"start\":8919},{\"end\":9902,\"start\":9057},{\"end\":10837,\"start\":9919},{\"end\":11448,\"start\":10839},{\"end\":12774,\"start\":11450},{\"end\":13561,\"start\":12776},{\"end\":14349,\"start\":13563},{\"end\":14655,\"start\":14351},{\"end\":15162,\"start\":14681},{\"end\":17195,\"start\":15187},{\"end\":17924,\"start\":17197},{\"end\":18561,\"start\":17926},{\"end\":20021,\"start\":18563},{\"end\":21781,\"start\":20055},{\"end\":22599,\"start\":21831},{\"end\":23052,\"start\":22601},{\"end\":23913,\"start\":23082},{\"end\":24286,\"start\":23947},{\"end\":24459,\"start\":24288},{\"end\":25594,\"start\":24461},{\"end\":26106,\"start\":25596},{\"end\":26690,\"start\":26141},{\"end\":27026,\"start\":26736},{\"end\":27649,\"start\":27064},{\"end\":28632,\"start\":27651},{\"end\":29461,\"start\":28634},{\"end\":30209,\"start\":29490},{\"end\":31198,\"start\":30211},{\"end\":31322,\"start\":31238},{\"end\":32413,\"start\":31344},{\"end\":32714,\"start\":32415},{\"end\":33114,\"start\":32741},{\"end\":33702,\"start\":33116},{\"end\":34215,\"start\":33704},{\"end\":34775,\"start\":34236},{\"end\":35211,\"start\":34795},{\"end\":36027,\"start\":35232},{\"end\":36605,\"start\":36029},{\"end\":37526,\"start\":36618},{\"end\":38782,\"start\":37551},{\"end\":39754,\"start\":38784},{\"end\":39858,\"start\":39756},{\"end\":39977,\"start\":39886},{\"end\":41093,\"start\":39979},{\"end\":41781,\"start\":41123},{\"end\":42328,\"start\":41783},{\"end\":42785,\"start\":42330},{\"end\":43709,\"start\":42787},{\"end\":44406,\"start\":43711},{\"end\":44986,\"start\":44408},{\"end\":45590,\"start\":45027},{\"end\":46122,\"start\":45603},{\"end\":47076,\"start\":46124},{\"end\":47656,\"start\":47078},{\"end\":49017,\"start\":47658},{\"end\":49955,\"start\":49019},{\"end\":50409,\"start\":49957},{\"end\":50873,\"start\":50422},{\"end\":51327,\"start\":50875},{\"end\":51481,\"start\":51353},{\"end\":52514,\"start\":51483},{\"end\":52729,\"start\":52516},{\"end\":54819,\"start\":52731},{\"end\":54957,\"start\":54841},{\"end\":55753,\"start\":54959},{\"end\":55915,\"start\":55755},{\"end\":56091,\"start\":55963},{\"end\":56905,\"start\":56093},{\"end\":58022,\"start\":56907},{\"end\":58258,\"start\":58024},{\"end\":58529,\"start\":58285},{\"end\":58869,\"start\":58531},{\"end\":59848,\"start\":58871},{\"end\":60769,\"start\":59850},{\"end\":61279,\"start\":60771},{\"end\":62243,\"start\":61281},{\"end\":62504,\"start\":62245},{\"end\":63633,\"start\":62521},{\"end\":64205,\"start\":63635},{\"end\":64654,\"start\":64207},{\"end\":65294,\"start\":64656},{\"end\":65794,\"start\":65325},{\"end\":66124,\"start\":65796},{\"end\":66761,\"start\":66144}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":21830,\"start\":21782},{\"attributes\":{\"id\":\"formula_1\"},\"end\":27063,\"start\":27027}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":19098,\"start\":19091},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24669,\"start\":24662},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":52649,\"start\":52642},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":55527,\"start\":55520}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1409,\"start\":1397},{\"attributes\":{\"n\":\"2\"},\"end\":8917,\"start\":8909},{\"attributes\":{\"n\":\"2.1\"},\"end\":9055,\"start\":9038},{\"attributes\":{\"n\":\"2.2\"},\"end\":9917,\"start\":9905},{\"attributes\":{\"n\":\"3\"},\"end\":14679,\"start\":14658},{\"attributes\":{\"n\":\"3.1\"},\"end\":15185,\"start\":15165},{\"attributes\":{\"n\":\"3.2\"},\"end\":20053,\"start\":20024},{\"attributes\":{\"n\":\"3.3\"},\"end\":23080,\"start\":23055},{\"attributes\":{\"n\":\"3.4\"},\"end\":23945,\"start\":23916},{\"attributes\":{\"n\":\"4\"},\"end\":26139,\"start\":26109},{\"attributes\":{\"n\":\"4.1\"},\"end\":26734,\"start\":26693},{\"attributes\":{\"n\":\"4.2\"},\"end\":29488,\"start\":29464},{\"attributes\":{\"n\":\"5\"},\"end\":31236,\"start\":31201},{\"attributes\":{\"n\":\"5.1\"},\"end\":31342,\"start\":31325},{\"attributes\":{\"n\":\"5.2\"},\"end\":32739,\"start\":32717},{\"attributes\":{\"n\":\"5.3\"},\"end\":34234,\"start\":34218},{\"attributes\":{\"n\":\"6\"},\"end\":34793,\"start\":34778},{\"attributes\":{\"n\":\"6.1\"},\"end\":35230,\"start\":35214},{\"attributes\":{\"n\":\"6.2\"},\"end\":36616,\"start\":36608},{\"attributes\":{\"n\":\"6.3\"},\"end\":37549,\"start\":37529},{\"attributes\":{\"n\":\"7\"},\"end\":39884,\"start\":39861},{\"attributes\":{\"n\":\"7.1\"},\"end\":41121,\"start\":41096},{\"attributes\":{\"n\":\"7.2\"},\"end\":45025,\"start\":44989},{\"end\":45601,\"start\":45593},{\"end\":50420,\"start\":50412},{\"attributes\":{\"n\":\"7.3\"},\"end\":51351,\"start\":51330},{\"attributes\":{\"n\":\"7.4\"},\"end\":54839,\"start\":54822},{\"attributes\":{\"n\":\"7.5\"},\"end\":55961,\"start\":55918},{\"attributes\":{\"n\":\"7.6\"},\"end\":58283,\"start\":58261},{\"attributes\":{\"n\":\"8\"},\"end\":62519,\"start\":62507},{\"attributes\":{\"n\":\"9\"},\"end\":65323,\"start\":65297},{\"attributes\":{\"n\":\"10\"},\"end\":66142,\"start\":66127},{\"end\":66773,\"start\":66763},{\"end\":66831,\"start\":66821},{\"end\":67581,\"start\":67571},{\"end\":67921,\"start\":67911},{\"end\":68090,\"start\":68080},{\"end\":68225,\"start\":68215},{\"end\":68464,\"start\":68453},{\"end\":69542,\"start\":69533},{\"end\":69949,\"start\":69940},{\"end\":70519,\"start\":70506}]", "table": "[{\"end\":69531,\"start\":68470},{\"end\":69938,\"start\":69806},{\"end\":70667,\"start\":70527},{\"end\":71904,\"start\":71576},{\"end\":72094,\"start\":71946},{\"end\":72398,\"start\":72106}]", "figure_caption": "[{\"end\":66819,\"start\":66775},{\"end\":67569,\"start\":66833},{\"end\":67909,\"start\":67583},{\"end\":68078,\"start\":67923},{\"end\":68213,\"start\":68092},{\"end\":68451,\"start\":68227},{\"end\":69646,\"start\":69544},{\"end\":69806,\"start\":69649},{\"end\":70504,\"start\":69951},{\"end\":70527,\"start\":70525},{\"end\":71576,\"start\":70670},{\"end\":71946,\"start\":71907},{\"end\":72106,\"start\":72097}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2439,\"start\":2431},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4569,\"start\":4561},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4778,\"start\":4770},{\"end\":11080,\"start\":11072},{\"end\":11434,\"start\":11426},{\"end\":12169,\"start\":12161},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16710,\"start\":16702},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17411,\"start\":17403},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18262,\"start\":18254},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20705,\"start\":20697},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20968,\"start\":20960},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22263,\"start\":22255},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22901,\"start\":22893},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":32573,\"start\":32565},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":43746,\"start\":43738},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":47089,\"start\":47081},{\"end\":47398,\"start\":47390},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":47864,\"start\":47856},{\"end\":49982,\"start\":49974},{\"end\":50469,\"start\":50461},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":52551,\"start\":52543},{\"end\":54207,\"start\":54199},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":56631,\"start\":56621},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57282,\"start\":57272},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57557,\"start\":57548},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57800,\"start\":57791},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":59876,\"start\":59867},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":61648,\"start\":61639}]", "bib_author_first_name": "[{\"end\":72641,\"start\":72637},{\"end\":72654,\"start\":72650},{\"end\":72673,\"start\":72667},{\"end\":72687,\"start\":72684},{\"end\":72702,\"start\":72695},{\"end\":72704,\"start\":72703},{\"end\":73054,\"start\":73051},{\"end\":73070,\"start\":73062},{\"end\":73081,\"start\":73077},{\"end\":73096,\"start\":73089},{\"end\":73111,\"start\":73106},{\"end\":73113,\"start\":73112},{\"end\":73130,\"start\":73122},{\"end\":73147,\"start\":73141},{\"end\":73167,\"start\":73161},{\"end\":73181,\"start\":73175},{\"end\":73196,\"start\":73190},{\"end\":73213,\"start\":73205},{\"end\":73228,\"start\":73223},{\"end\":73251,\"start\":73243},{\"end\":73264,\"start\":73261},{\"end\":73280,\"start\":73275},{\"end\":73294,\"start\":73288},{\"end\":73309,\"start\":73303},{\"end\":73326,\"start\":73319},{\"end\":73338,\"start\":73331},{\"end\":73352,\"start\":73347},{\"end\":73364,\"start\":73360},{\"end\":73375,\"start\":73371},{\"end\":73391,\"start\":73384},{\"end\":74552,\"start\":74546},{\"end\":74554,\"start\":74553},{\"end\":74570,\"start\":74565},{\"end\":74586,\"start\":74578},{\"end\":74600,\"start\":74596},{\"end\":74616,\"start\":74609},{\"end\":75304,\"start\":75297},{\"end\":75322,\"start\":75316},{\"end\":75337,\"start\":75329},{\"end\":75350,\"start\":75345},{\"end\":75352,\"start\":75351},{\"end\":75368,\"start\":75361},{\"end\":75381,\"start\":75374},{\"end\":75395,\"start\":75390},{\"end\":75857,\"start\":75851},{\"end\":75872,\"start\":75866},{\"end\":75874,\"start\":75873},{\"end\":75894,\"start\":75887},{\"end\":75896,\"start\":75895},{\"end\":75909,\"start\":75904},{\"end\":75925,\"start\":75919},{\"end\":75927,\"start\":75926},{\"end\":76725,\"start\":76722},{\"end\":76739,\"start\":76731},{\"end\":76750,\"start\":76744},{\"end\":76759,\"start\":76757},{\"end\":77127,\"start\":77119},{\"end\":77144,\"start\":77139},{\"end\":77152,\"start\":77151},{\"end\":77170,\"start\":77162},{\"end\":77172,\"start\":77171},{\"end\":77189,\"start\":77181},{\"end\":77206,\"start\":77200},{\"end\":77228,\"start\":77225},{\"end\":77253,\"start\":77246},{\"end\":77265,\"start\":77260},{\"end\":77281,\"start\":77275},{\"end\":77733,\"start\":77725},{\"end\":77752,\"start\":77745},{\"end\":77764,\"start\":77761},{\"end\":78376,\"start\":78368},{\"end\":78395,\"start\":78388},{\"end\":78411,\"start\":78405},{\"end\":78430,\"start\":78421},{\"end\":78891,\"start\":78885},{\"end\":78898,\"start\":78896},{\"end\":78911,\"start\":78905},{\"end\":78927,\"start\":78920},{\"end\":78937,\"start\":78934},{\"end\":78951,\"start\":78944},{\"end\":78961,\"start\":78956},{\"end\":78973,\"start\":78966},{\"end\":79666,\"start\":79659},{\"end\":79679,\"start\":79673},{\"end\":79694,\"start\":79686},{\"end\":79708,\"start\":79702},{\"end\":79720,\"start\":79715},{\"end\":79722,\"start\":79721},{\"end\":79736,\"start\":79730},{\"end\":80225,\"start\":80224},{\"end\":80237,\"start\":80236},{\"end\":80247,\"start\":80244},{\"end\":80259,\"start\":80258},{\"end\":80274,\"start\":80273},{\"end\":80540,\"start\":80537},{\"end\":80553,\"start\":80546},{\"end\":80564,\"start\":80559},{\"end\":80965,\"start\":80959},{\"end\":80980,\"start\":80972},{\"end\":80994,\"start\":80988},{\"end\":81011,\"start\":81005},{\"end\":81026,\"start\":81021},{\"end\":81040,\"start\":81034},{\"end\":81055,\"start\":81049},{\"end\":81508,\"start\":81501},{\"end\":81517,\"start\":81513},{\"end\":81540,\"start\":81535},{\"end\":81559,\"start\":81552},{\"end\":81954,\"start\":81952},{\"end\":81967,\"start\":81962},{\"end\":81969,\"start\":81968},{\"end\":81984,\"start\":81978},{\"end\":82279,\"start\":82273},{\"end\":82290,\"start\":82285},{\"end\":82308,\"start\":82304},{\"end\":82350,\"start\":82342},{\"end\":82904,\"start\":82900},{\"end\":82923,\"start\":82913},{\"end\":82936,\"start\":82930},{\"end\":82948,\"start\":82942},{\"end\":82965,\"start\":82957},{\"end\":82979,\"start\":82976},{\"end\":83682,\"start\":83678},{\"end\":83701,\"start\":83691},{\"end\":83714,\"start\":83708},{\"end\":83723,\"start\":83720},{\"end\":83739,\"start\":83731},{\"end\":83753,\"start\":83750},{\"end\":83766,\"start\":83762},{\"end\":83788,\"start\":83782},{\"end\":84156,\"start\":84152},{\"end\":84169,\"start\":84165},{\"end\":84963,\"start\":84959},{\"end\":84976,\"start\":84972},{\"end\":85298,\"start\":85295},{\"end\":85311,\"start\":85305},{\"end\":85528,\"start\":85522},{\"end\":86007,\"start\":86000},{\"end\":86026,\"start\":86017},{\"end\":86028,\"start\":86027},{\"end\":86042,\"start\":86035},{\"end\":86056,\"start\":86049},{\"end\":86437,\"start\":86430},{\"end\":86452,\"start\":86445},{\"end\":86469,\"start\":86462},{\"end\":86483,\"start\":86477},{\"end\":87153,\"start\":87146},{\"end\":87169,\"start\":87164},{\"end\":87181,\"start\":87178},{\"end\":87193,\"start\":87188},{\"end\":87209,\"start\":87201},{\"end\":87902,\"start\":87900},{\"end\":87916,\"start\":87908},{\"end\":88224,\"start\":88216},{\"end\":88247,\"start\":88239},{\"end\":88261,\"start\":88254},{\"end\":88280,\"start\":88272},{\"end\":88291,\"start\":88288},{\"end\":88933,\"start\":88924},{\"end\":88946,\"start\":88943},{\"end\":88960,\"start\":88955},{\"end\":88968,\"start\":88961},{\"end\":88988,\"start\":88982},{\"end\":89728,\"start\":89719},{\"end\":89738,\"start\":89733},{\"end\":89752,\"start\":89747},{\"end\":89768,\"start\":89763},{\"end\":89784,\"start\":89776},{\"end\":89792,\"start\":89789},{\"end\":89805,\"start\":89799},{\"end\":90155,\"start\":90147},{\"end\":90166,\"start\":90162},{\"end\":90182,\"start\":90177},{\"end\":90193,\"start\":90189},{\"end\":90204,\"start\":90201},{\"end\":90540,\"start\":90534},{\"end\":90555,\"start\":90549},{\"end\":90570,\"start\":90564},{\"end\":90592,\"start\":90584},{\"end\":90602,\"start\":90601},{\"end\":90618,\"start\":90609},{\"end\":90620,\"start\":90619},{\"end\":91319,\"start\":91317},{\"end\":91329,\"start\":91327},{\"end\":91337,\"start\":91335},{\"end\":91352,\"start\":91344},{\"end\":91362,\"start\":91357},{\"end\":91372,\"start\":91369},{\"end\":91386,\"start\":91380},{\"end\":91400,\"start\":91393},{\"end\":91415,\"start\":91407},{\"end\":91425,\"start\":91423},{\"end\":91437,\"start\":91431},{\"end\":91449,\"start\":91443},{\"end\":92253,\"start\":92248},{\"end\":92262,\"start\":92259},{\"end\":92273,\"start\":92269},{\"end\":92286,\"start\":92282},{\"end\":92302,\"start\":92295},{\"end\":92319,\"start\":92310},{\"end\":93111,\"start\":93105},{\"end\":93120,\"start\":93118},{\"end\":93134,\"start\":93126},{\"end\":93146,\"start\":93139}]", "bib_author_last_name": "[{\"end\":72533,\"start\":72518},{\"end\":72648,\"start\":72642},{\"end\":72665,\"start\":72655},{\"end\":72682,\"start\":72674},{\"end\":72693,\"start\":72688},{\"end\":72711,\"start\":72705},{\"end\":73060,\"start\":73055},{\"end\":73075,\"start\":73071},{\"end\":73087,\"start\":73082},{\"end\":73104,\"start\":73097},{\"end\":73120,\"start\":73114},{\"end\":73139,\"start\":73131},{\"end\":73159,\"start\":73148},{\"end\":73173,\"start\":73168},{\"end\":73188,\"start\":73182},{\"end\":73203,\"start\":73197},{\"end\":73221,\"start\":73214},{\"end\":73241,\"start\":73229},{\"end\":73259,\"start\":73252},{\"end\":73273,\"start\":73265},{\"end\":73286,\"start\":73281},{\"end\":73301,\"start\":73295},{\"end\":73317,\"start\":73310},{\"end\":73329,\"start\":73327},{\"end\":73345,\"start\":73339},{\"end\":73358,\"start\":73353},{\"end\":73369,\"start\":73365},{\"end\":73382,\"start\":73376},{\"end\":73398,\"start\":73392},{\"end\":74563,\"start\":74555},{\"end\":74576,\"start\":74571},{\"end\":74594,\"start\":74587},{\"end\":74607,\"start\":74601},{\"end\":74624,\"start\":74617},{\"end\":75314,\"start\":75305},{\"end\":75327,\"start\":75323},{\"end\":75343,\"start\":75338},{\"end\":75359,\"start\":75353},{\"end\":75372,\"start\":75369},{\"end\":75388,\"start\":75382},{\"end\":75405,\"start\":75396},{\"end\":75864,\"start\":75858},{\"end\":75885,\"start\":75875},{\"end\":75902,\"start\":75897},{\"end\":75917,\"start\":75910},{\"end\":75932,\"start\":75928},{\"end\":76729,\"start\":76726},{\"end\":76742,\"start\":76740},{\"end\":76755,\"start\":76751},{\"end\":76763,\"start\":76760},{\"end\":77137,\"start\":77128},{\"end\":77149,\"start\":77145},{\"end\":77160,\"start\":77153},{\"end\":77179,\"start\":77173},{\"end\":77198,\"start\":77190},{\"end\":77215,\"start\":77207},{\"end\":77223,\"start\":77217},{\"end\":77244,\"start\":77229},{\"end\":77258,\"start\":77254},{\"end\":77273,\"start\":77266},{\"end\":77290,\"start\":77282},{\"end\":77299,\"start\":77292},{\"end\":77743,\"start\":77734},{\"end\":77759,\"start\":77753},{\"end\":77769,\"start\":77765},{\"end\":78386,\"start\":78377},{\"end\":78403,\"start\":78396},{\"end\":78419,\"start\":78412},{\"end\":78437,\"start\":78431},{\"end\":78894,\"start\":78892},{\"end\":78903,\"start\":78899},{\"end\":78918,\"start\":78912},{\"end\":78932,\"start\":78928},{\"end\":78942,\"start\":78938},{\"end\":78954,\"start\":78952},{\"end\":78964,\"start\":78962},{\"end\":78977,\"start\":78974},{\"end\":79671,\"start\":79667},{\"end\":79684,\"start\":79680},{\"end\":79700,\"start\":79695},{\"end\":79713,\"start\":79709},{\"end\":79728,\"start\":79723},{\"end\":79743,\"start\":79737},{\"end\":80234,\"start\":80226},{\"end\":80242,\"start\":80238},{\"end\":80256,\"start\":80248},{\"end\":80271,\"start\":80260},{\"end\":80281,\"start\":80275},{\"end\":80544,\"start\":80541},{\"end\":80557,\"start\":80554},{\"end\":80569,\"start\":80565},{\"end\":80970,\"start\":80966},{\"end\":80986,\"start\":80981},{\"end\":81003,\"start\":80995},{\"end\":81019,\"start\":81012},{\"end\":81032,\"start\":81027},{\"end\":81047,\"start\":81041},{\"end\":81063,\"start\":81056},{\"end\":81511,\"start\":81509},{\"end\":81533,\"start\":81518},{\"end\":81550,\"start\":81541},{\"end\":81569,\"start\":81560},{\"end\":81960,\"start\":81955},{\"end\":81976,\"start\":81970},{\"end\":81993,\"start\":81985},{\"end\":82283,\"start\":82280},{\"end\":82302,\"start\":82291},{\"end\":82340,\"start\":82309},{\"end\":82355,\"start\":82351},{\"end\":82365,\"start\":82357},{\"end\":82911,\"start\":82905},{\"end\":82928,\"start\":82924},{\"end\":82940,\"start\":82937},{\"end\":82955,\"start\":82949},{\"end\":82974,\"start\":82966},{\"end\":82986,\"start\":82980},{\"end\":83689,\"start\":83683},{\"end\":83706,\"start\":83702},{\"end\":83718,\"start\":83715},{\"end\":83729,\"start\":83724},{\"end\":83748,\"start\":83740},{\"end\":83760,\"start\":83754},{\"end\":83780,\"start\":83767},{\"end\":83795,\"start\":83789},{\"end\":84163,\"start\":84157},{\"end\":84183,\"start\":84170},{\"end\":84970,\"start\":84964},{\"end\":84990,\"start\":84977},{\"end\":85303,\"start\":85299},{\"end\":85319,\"start\":85312},{\"end\":85555,\"start\":85529},{\"end\":85562,\"start\":85557},{\"end\":86015,\"start\":86008},{\"end\":86033,\"start\":86029},{\"end\":86047,\"start\":86043},{\"end\":86061,\"start\":86057},{\"end\":86070,\"start\":86063},{\"end\":86443,\"start\":86438},{\"end\":86460,\"start\":86453},{\"end\":86475,\"start\":86470},{\"end\":86489,\"start\":86484},{\"end\":87162,\"start\":87154},{\"end\":87176,\"start\":87170},{\"end\":87186,\"start\":87182},{\"end\":87199,\"start\":87194},{\"end\":87212,\"start\":87210},{\"end\":87906,\"start\":87903},{\"end\":87919,\"start\":87917},{\"end\":88237,\"start\":88225},{\"end\":88252,\"start\":88248},{\"end\":88270,\"start\":88262},{\"end\":88286,\"start\":88281},{\"end\":88298,\"start\":88292},{\"end\":88941,\"start\":88934},{\"end\":88953,\"start\":88947},{\"end\":88980,\"start\":88969},{\"end\":88994,\"start\":88989},{\"end\":89731,\"start\":89729},{\"end\":89745,\"start\":89739},{\"end\":89761,\"start\":89753},{\"end\":89774,\"start\":89769},{\"end\":89787,\"start\":89785},{\"end\":89797,\"start\":89793},{\"end\":89809,\"start\":89806},{\"end\":90160,\"start\":90156},{\"end\":90175,\"start\":90167},{\"end\":90187,\"start\":90183},{\"end\":90199,\"start\":90194},{\"end\":90209,\"start\":90205},{\"end\":90547,\"start\":90541},{\"end\":90562,\"start\":90556},{\"end\":90582,\"start\":90571},{\"end\":90599,\"start\":90593},{\"end\":90607,\"start\":90603},{\"end\":90634,\"start\":90621},{\"end\":90641,\"start\":90636},{\"end\":91325,\"start\":91320},{\"end\":91333,\"start\":91330},{\"end\":91342,\"start\":91338},{\"end\":91355,\"start\":91353},{\"end\":91367,\"start\":91363},{\"end\":91378,\"start\":91373},{\"end\":91391,\"start\":91387},{\"end\":91405,\"start\":91401},{\"end\":91421,\"start\":91416},{\"end\":91429,\"start\":91426},{\"end\":91441,\"start\":91438},{\"end\":91452,\"start\":91450},{\"end\":92257,\"start\":92254},{\"end\":92267,\"start\":92263},{\"end\":92280,\"start\":92274},{\"end\":92293,\"start\":92287},{\"end\":92308,\"start\":92303},{\"end\":92323,\"start\":92320},{\"end\":92327,\"start\":92325},{\"end\":93116,\"start\":93112},{\"end\":93124,\"start\":93121},{\"end\":93137,\"start\":93135},{\"end\":93151,\"start\":93147}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":72577,\"start\":72516},{\"attributes\":{\"doi\":\"10.1109/ICDE.2012.64\",\"id\":\"b1\",\"matched_paper_id\":1914773},\"end\":73049,\"start\":72579},{\"attributes\":{\"id\":\"b2\"},\"end\":74486,\"start\":73051},{\"attributes\":{\"doi\":\"10.1145/2168836.2168847\",\"id\":\"b3\",\"matched_paper_id\":207193689},\"end\":75208,\"start\":74488},{\"attributes\":{\"doi\":\"10.1109/ICDE.2009.130\",\"id\":\"b4\",\"matched_paper_id\":8609713},\"end\":75803,\"start\":75210},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":9665943},\"end\":76636,\"start\":75805},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":235618862},\"end\":77061,\"start\":76638},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":211015954},\"end\":77670,\"start\":77063},{\"attributes\":{\"doi\":\"10.1145/3318464.3389704\",\"id\":\"b8\",\"matched_paper_id\":218982590},\"end\":78366,\"start\":77672},{\"attributes\":{\"doi\":\"10.14778/3384345.3384349\",\"id\":\"b9\"},\"end\":78821,\"start\":78368},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3815895},\"end\":79586,\"start\":78823},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":52154172},\"end\":80154,\"start\":79588},{\"attributes\":{\"doi\":\"ArXiv abs/1808.03196\",\"id\":\"b12\"},\"end\":80472,\"start\":80156},{\"attributes\":{\"doi\":\"10.1145/3340531.3412106\",\"id\":\"b13\"},\"end\":80859,\"start\":80474},{\"attributes\":{\"doi\":\"10.1007/s00778-017-0480-7\",\"id\":\"b14\",\"matched_paper_id\":4570668},\"end\":81411,\"start\":80861},{\"attributes\":{\"doi\":\"10.14778/2350229.2350269\",\"id\":\"b15\",\"matched_paper_id\":51970952},\"end\":81881,\"start\":81413},{\"attributes\":{\"doi\":\"arXiv:1903.01363\",\"id\":\"b16\"},\"end\":82210,\"start\":81883},{\"attributes\":{\"doi\":\"10.1145/3341302.3342080\",\"id\":\"b17\",\"matched_paper_id\":52918846},\"end\":82848,\"start\":82212},{\"attributes\":{\"doi\":\"10.1145/3448016.3452838\",\"id\":\"b18\",\"matched_paper_id\":235474469},\"end\":83644,\"start\":82850},{\"attributes\":{\"doi\":\"10.14778/3342263.3342644\",\"id\":\"b19\",\"matched_paper_id\":102352007},\"end\":84094,\"start\":83646},{\"attributes\":{\"doi\":\"10.1145/3211954.3211957\",\"id\":\"b20\",\"matched_paper_id\":3854187},\"end\":84880,\"start\":84096},{\"attributes\":{\"doi\":\"10.14778/3342263.3342646\",\"id\":\"b21\",\"matched_paper_id\":59553521},\"end\":85246,\"start\":84882},{\"attributes\":{\"doi\":\"arXiv:1511.03086\",\"id\":\"b22\"},\"end\":85498,\"start\":85248},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":5590663},\"end\":85937,\"start\":85500},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":26282610},\"end\":86369,\"start\":85939},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":167204311},\"end\":87059,\"start\":86371},{\"attributes\":{\"doi\":\"10.1145/3318464.3380584\",\"id\":\"b26\",\"matched_paper_id\":211572502},\"end\":87853,\"start\":87061},{\"attributes\":{\"doi\":\"10.14778/3368289.3368296\",\"id\":\"b27\",\"matched_paper_id\":174802790},\"end\":88137,\"start\":87855},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":14366444},\"end\":88838,\"start\":88139},{\"attributes\":{\"doi\":\"10.1145/3448016.3457286\",\"id\":\"b29\",\"matched_paper_id\":235473953},\"end\":89669,\"start\":88840},{\"attributes\":{\"doi\":\"10.14778/3291264.3291267\",\"id\":\"b30\",\"matched_paper_id\":58015526},\"end\":90092,\"start\":89671},{\"attributes\":{\"doi\":\"10.14778/3421424.3421432\",\"id\":\"b31\",\"matched_paper_id\":219687533},\"end\":90521,\"start\":90094},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":4870287},\"end\":91227,\"start\":90523},{\"attributes\":{\"doi\":\"10.1145/3299869.3300085\",\"id\":\"b33\",\"matched_paper_id\":195259215},\"end\":92149,\"start\":91229},{\"attributes\":{\"doi\":\"10.1145/3448016.3457546\",\"id\":\"b34\",\"matched_paper_id\":232320409},\"end\":93028,\"start\":92151},{\"attributes\":{\"doi\":\"10.14778/3397230.3397238\",\"id\":\"b35\",\"matched_paper_id\":219557876},\"end\":93427,\"start\":93030}]", "bib_title": "[{\"end\":72635,\"start\":72579},{\"end\":74544,\"start\":74488},{\"end\":75295,\"start\":75210},{\"end\":75849,\"start\":75805},{\"end\":76720,\"start\":76638},{\"end\":77117,\"start\":77063},{\"end\":77723,\"start\":77672},{\"end\":78883,\"start\":78823},{\"end\":79657,\"start\":79588},{\"end\":80957,\"start\":80861},{\"end\":81499,\"start\":81413},{\"end\":82271,\"start\":82212},{\"end\":82898,\"start\":82850},{\"end\":83676,\"start\":83646},{\"end\":84150,\"start\":84096},{\"end\":84957,\"start\":84882},{\"end\":85520,\"start\":85500},{\"end\":85998,\"start\":85939},{\"end\":86428,\"start\":86371},{\"end\":87144,\"start\":87061},{\"end\":87898,\"start\":87855},{\"end\":88214,\"start\":88139},{\"end\":88922,\"start\":88840},{\"end\":89717,\"start\":89671},{\"end\":90145,\"start\":90094},{\"end\":90532,\"start\":90523},{\"end\":91315,\"start\":91229},{\"end\":92246,\"start\":92151},{\"end\":93103,\"start\":93030}]", "bib_author": "[{\"end\":72535,\"start\":72518},{\"end\":72650,\"start\":72637},{\"end\":72667,\"start\":72650},{\"end\":72684,\"start\":72667},{\"end\":72695,\"start\":72684},{\"end\":72713,\"start\":72695},{\"end\":73062,\"start\":73051},{\"end\":73077,\"start\":73062},{\"end\":73089,\"start\":73077},{\"end\":73106,\"start\":73089},{\"end\":73122,\"start\":73106},{\"end\":73141,\"start\":73122},{\"end\":73161,\"start\":73141},{\"end\":73175,\"start\":73161},{\"end\":73190,\"start\":73175},{\"end\":73205,\"start\":73190},{\"end\":73223,\"start\":73205},{\"end\":73243,\"start\":73223},{\"end\":73261,\"start\":73243},{\"end\":73275,\"start\":73261},{\"end\":73288,\"start\":73275},{\"end\":73303,\"start\":73288},{\"end\":73319,\"start\":73303},{\"end\":73331,\"start\":73319},{\"end\":73347,\"start\":73331},{\"end\":73360,\"start\":73347},{\"end\":73371,\"start\":73360},{\"end\":73384,\"start\":73371},{\"end\":73400,\"start\":73384},{\"end\":74565,\"start\":74546},{\"end\":74578,\"start\":74565},{\"end\":74596,\"start\":74578},{\"end\":74609,\"start\":74596},{\"end\":74626,\"start\":74609},{\"end\":75316,\"start\":75297},{\"end\":75329,\"start\":75316},{\"end\":75345,\"start\":75329},{\"end\":75361,\"start\":75345},{\"end\":75374,\"start\":75361},{\"end\":75390,\"start\":75374},{\"end\":75407,\"start\":75390},{\"end\":75866,\"start\":75851},{\"end\":75887,\"start\":75866},{\"end\":75904,\"start\":75887},{\"end\":75919,\"start\":75904},{\"end\":75934,\"start\":75919},{\"end\":76731,\"start\":76722},{\"end\":76744,\"start\":76731},{\"end\":76757,\"start\":76744},{\"end\":76765,\"start\":76757},{\"end\":77139,\"start\":77119},{\"end\":77151,\"start\":77139},{\"end\":77162,\"start\":77151},{\"end\":77181,\"start\":77162},{\"end\":77200,\"start\":77181},{\"end\":77217,\"start\":77200},{\"end\":77225,\"start\":77217},{\"end\":77246,\"start\":77225},{\"end\":77260,\"start\":77246},{\"end\":77275,\"start\":77260},{\"end\":77292,\"start\":77275},{\"end\":77301,\"start\":77292},{\"end\":77745,\"start\":77725},{\"end\":77761,\"start\":77745},{\"end\":77771,\"start\":77761},{\"end\":78388,\"start\":78368},{\"end\":78405,\"start\":78388},{\"end\":78421,\"start\":78405},{\"end\":78439,\"start\":78421},{\"end\":78896,\"start\":78885},{\"end\":78905,\"start\":78896},{\"end\":78920,\"start\":78905},{\"end\":78934,\"start\":78920},{\"end\":78944,\"start\":78934},{\"end\":78956,\"start\":78944},{\"end\":78966,\"start\":78956},{\"end\":78979,\"start\":78966},{\"end\":79673,\"start\":79659},{\"end\":79686,\"start\":79673},{\"end\":79702,\"start\":79686},{\"end\":79715,\"start\":79702},{\"end\":79730,\"start\":79715},{\"end\":79745,\"start\":79730},{\"end\":80236,\"start\":80224},{\"end\":80244,\"start\":80236},{\"end\":80258,\"start\":80244},{\"end\":80273,\"start\":80258},{\"end\":80283,\"start\":80273},{\"end\":80546,\"start\":80537},{\"end\":80559,\"start\":80546},{\"end\":80571,\"start\":80559},{\"end\":80972,\"start\":80959},{\"end\":80988,\"start\":80972},{\"end\":81005,\"start\":80988},{\"end\":81021,\"start\":81005},{\"end\":81034,\"start\":81021},{\"end\":81049,\"start\":81034},{\"end\":81065,\"start\":81049},{\"end\":81513,\"start\":81501},{\"end\":81535,\"start\":81513},{\"end\":81552,\"start\":81535},{\"end\":81571,\"start\":81552},{\"end\":81962,\"start\":81952},{\"end\":81978,\"start\":81962},{\"end\":81995,\"start\":81978},{\"end\":82285,\"start\":82273},{\"end\":82304,\"start\":82285},{\"end\":82342,\"start\":82304},{\"end\":82357,\"start\":82342},{\"end\":82367,\"start\":82357},{\"end\":82913,\"start\":82900},{\"end\":82930,\"start\":82913},{\"end\":82942,\"start\":82930},{\"end\":82957,\"start\":82942},{\"end\":82976,\"start\":82957},{\"end\":82988,\"start\":82976},{\"end\":83691,\"start\":83678},{\"end\":83708,\"start\":83691},{\"end\":83720,\"start\":83708},{\"end\":83731,\"start\":83720},{\"end\":83750,\"start\":83731},{\"end\":83762,\"start\":83750},{\"end\":83782,\"start\":83762},{\"end\":83797,\"start\":83782},{\"end\":84165,\"start\":84152},{\"end\":84185,\"start\":84165},{\"end\":84972,\"start\":84959},{\"end\":84992,\"start\":84972},{\"end\":85305,\"start\":85295},{\"end\":85321,\"start\":85305},{\"end\":85557,\"start\":85522},{\"end\":85564,\"start\":85557},{\"end\":86017,\"start\":86000},{\"end\":86035,\"start\":86017},{\"end\":86049,\"start\":86035},{\"end\":86063,\"start\":86049},{\"end\":86072,\"start\":86063},{\"end\":86445,\"start\":86430},{\"end\":86462,\"start\":86445},{\"end\":86477,\"start\":86462},{\"end\":86491,\"start\":86477},{\"end\":87164,\"start\":87146},{\"end\":87178,\"start\":87164},{\"end\":87188,\"start\":87178},{\"end\":87201,\"start\":87188},{\"end\":87214,\"start\":87201},{\"end\":87908,\"start\":87900},{\"end\":87921,\"start\":87908},{\"end\":88239,\"start\":88216},{\"end\":88254,\"start\":88239},{\"end\":88272,\"start\":88254},{\"end\":88288,\"start\":88272},{\"end\":88300,\"start\":88288},{\"end\":88943,\"start\":88924},{\"end\":88955,\"start\":88943},{\"end\":88982,\"start\":88955},{\"end\":88996,\"start\":88982},{\"end\":89733,\"start\":89719},{\"end\":89747,\"start\":89733},{\"end\":89763,\"start\":89747},{\"end\":89776,\"start\":89763},{\"end\":89789,\"start\":89776},{\"end\":89799,\"start\":89789},{\"end\":89811,\"start\":89799},{\"end\":90162,\"start\":90147},{\"end\":90177,\"start\":90162},{\"end\":90189,\"start\":90177},{\"end\":90201,\"start\":90189},{\"end\":90211,\"start\":90201},{\"end\":90549,\"start\":90534},{\"end\":90564,\"start\":90549},{\"end\":90584,\"start\":90564},{\"end\":90601,\"start\":90584},{\"end\":90609,\"start\":90601},{\"end\":90636,\"start\":90609},{\"end\":90643,\"start\":90636},{\"end\":91327,\"start\":91317},{\"end\":91335,\"start\":91327},{\"end\":91344,\"start\":91335},{\"end\":91357,\"start\":91344},{\"end\":91369,\"start\":91357},{\"end\":91380,\"start\":91369},{\"end\":91393,\"start\":91380},{\"end\":91407,\"start\":91393},{\"end\":91423,\"start\":91407},{\"end\":91431,\"start\":91423},{\"end\":91443,\"start\":91431},{\"end\":91454,\"start\":91443},{\"end\":92259,\"start\":92248},{\"end\":92269,\"start\":92259},{\"end\":92282,\"start\":92269},{\"end\":92295,\"start\":92282},{\"end\":92310,\"start\":92295},{\"end\":92325,\"start\":92310},{\"end\":92329,\"start\":92325},{\"end\":93118,\"start\":93105},{\"end\":93126,\"start\":93118},{\"end\":93139,\"start\":93126},{\"end\":93153,\"start\":93139}]", "bib_venue": "[{\"end\":72792,\"start\":72733},{\"end\":73477,\"start\":73400},{\"end\":74715,\"start\":74649},{\"end\":75482,\"start\":75428},{\"end\":76044,\"start\":75934},{\"end\":76831,\"start\":76765},{\"end\":77310,\"start\":77301},{\"end\":77876,\"start\":77794},{\"end\":78567,\"start\":78463},{\"end\":79028,\"start\":78979},{\"end\":79815,\"start\":79745},{\"end\":80222,\"start\":80156},{\"end\":80535,\"start\":80474},{\"end\":81106,\"start\":81090},{\"end\":81611,\"start\":81595},{\"end\":81950,\"start\":81883},{\"end\":82402,\"start\":82390},{\"end\":83122,\"start\":83011},{\"end\":83837,\"start\":83821},{\"end\":84324,\"start\":84208},{\"end\":85032,\"start\":85016},{\"end\":85293,\"start\":85248},{\"end\":85637,\"start\":85564},{\"end\":86136,\"start\":86072},{\"end\":86608,\"start\":86491},{\"end\":87318,\"start\":87237},{\"end\":87961,\"start\":87945},{\"end\":88388,\"start\":88300},{\"end\":89130,\"start\":89019},{\"end\":89851,\"start\":89835},{\"end\":90251,\"start\":90235},{\"end\":90692,\"start\":90643},{\"end\":91547,\"start\":91477},{\"end\":92463,\"start\":92352},{\"end\":93193,\"start\":93177},{\"end\":73630,\"start\":73542},{\"end\":74804,\"start\":74717},{\"end\":76173,\"start\":76075},{\"end\":77334,\"start\":77312},{\"end\":77981,\"start\":77878},{\"end\":79834,\"start\":79817},{\"end\":81623,\"start\":81613},{\"end\":82437,\"start\":82404},{\"end\":83237,\"start\":83124},{\"end\":84471,\"start\":84326},{\"end\":85709,\"start\":85639},{\"end\":86738,\"start\":86610},{\"end\":87422,\"start\":87320},{\"end\":87973,\"start\":87963},{\"end\":88483,\"start\":88390},{\"end\":89245,\"start\":89132},{\"end\":90263,\"start\":90253},{\"end\":91645,\"start\":91549},{\"end\":92578,\"start\":92465},{\"end\":93205,\"start\":93195}]"}}}, "year": 2023, "month": 12, "day": 17}