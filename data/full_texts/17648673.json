{"id": 17648673, "updated": "2023-09-29 02:36:12.443", "metadata": {"title": "Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs", "authors": "[{\"first\":\"Martin\",\"last\":\"Simonovsky\",\"middle\":[]},{\"first\":\"Nikos\",\"last\":\"Komodakis\",\"middle\":[]}]", "venue": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2017, "month": 4, "day": 10}, "abstract": "A number of problems can be formulated as prediction on graph-structured data. In this work, we generalize the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity. To move beyond a simple diffusion, filter weights are conditioned on the specific edge labels in the neighborhood of a vertex. Together with the proper choice of graph coarsening, we explore constructing deep neural networks for graph classification. In particular, we demonstrate the generality of our formulation in point cloud classification, where we set the new state of the art, and on a graph classification dataset, where we outperform other deep learning approaches. The source code is available at https://github.com/mys007/ecc", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1704.02901", "mag": "2949455170", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/SimonovskyK17", "doi": "10.1109/cvpr.2017.11"}}, "content": {"source": {"pdf_hash": "1d0e5eaf6833c254a7ad389a6c84ef424d6fa65b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1704.02901v3.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1704.02901", "status": "GREEN"}}, "grobid": {"id": "8ab447c781600382452c70bc96f604eeec79939c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1d0e5eaf6833c254a7ad389a6c84ef424d6fa65b.txt", "contents": "\nDynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\n\n\nMartin Simonovsky martin.simonovsky@enpc.fr \nUniversit\u00e9 Paris Est\n\u00c9cole des Ponts ParisTech\n\nNikos Komodakis nikos.komodakis@enpc.fr \nUniversit\u00e9 Paris Est\n\u00c9cole des Ponts ParisTech\n\nDynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\n\nA number of problems can be formulated as prediction on graph-structured data. In this work, we generalize the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity. To move beyond a simple diffusion, filter weights are conditioned on the specific edge labels in the neighborhood of a vertex. Together with the proper choice of graph coarsening, we explore constructing deep neural networks for graph classification. In particular, we demonstrate the generality of our formulation in point cloud classification, where we set the new state of the art, and on a graph classification dataset, where we outperform other deep learning approaches. The source code is available at\n\nIntroduction\n\nConvolutional Neural Networks (CNNs) have gained massive popularity in tasks where the underlying data representation has a grid structure, such as in speech processing and natural language understanding (1D, temporal convolutions), in image classification and segmentation (2D, spatial convolutions), or in video parsing (3D, volumetric convolutions) [22].\n\nOn the other hand, in many other tasks the data naturally lie on irregular or generally non-Euclidean domains, which can be structured as graphs in many cases. These include problems in 3D modeling, computational chemistry and biology, geospatial analysis, social networks, or natural language semantics and knowledge bases, to name a few. Assuming that the locality, stationarity, and composionality principles of representation hold to at least some level in the data, it is meaningful to consider a hierarchical CNN-like architecture for processing it.\n\nHowever, a generalization of CNNs from grids to general graphs is not straightforward and has recently become a topic of increased interest. We identify that the current formulations of graph convolution do not exploit edge la-bels, which results in an overly homogeneous view of local graph neighborhoods, with an effect similar to enforcing rotational invariance of filters in regular convolutions on images. Hence, in this work we propose a convolution operation which can make use of this information channel and show that it leads to an improved graph classification performance.\n\nThis novel formulation also opens up a broader range of applications; we concentrate here on point clouds specifically. Point clouds have been mostly ignored by deep learning so far, their voxelization being the only trend to the best of our knowledge [26,19]. To offer a competitive alternative with a different set of advantages and disadvantages, we construct graphs in Euclidean space from point clouds in this work and demonstrate state of the art performance on Sydney dataset of LiDAR scans [9].\n\nOur contributions are as follows:\n\n\u2022 We formulate a convolution-like operation on graph signals performed in the spatial domain where filter weights are conditioned on edge labels (discrete or continuous) and dynamically generated for each specific input sample. Our networks work on graphs with arbitrary varying structure throughout a dataset.\n\n\u2022 We are the first to apply graph convolutions to point cloud classification. Our method outperforms volumetric approaches and attains the new state of the art performance on Sydney dataset, with the benefit of preserving sparsity and presumably fine details.\n\n\u2022 We reach a competitive level of performance on graph classification benchmark NCI1 [39], outperforming other approaches based on deep learning there.\n\n\nRelated Work\n\nThe first formulation of a convolutional network analogy for irregular domains modeled with graphs has been introduced by Bruna et al. [6], who looked into both the spatial and the spectral domain of representation for performing localized filtering. Figure 1. Illustration of edge-conditioned convolution on a directed subgraph. The feature X l (1) on vertex 1 in the l-th network layer is computed as a weighted sum of features X l\u22121 (.) on the set of its predecessor vertices, assuming self-loops. The particular weight matrices are dynamically generated by filter-generating network F l based on the corresponding edge labels L(.), visualized as colors.\n\nSpectral Methods. A mathematically sound definition of convolution operator makes use of the spectral analysis theory, where it corresponds to multiplication of the signal on vertices transformed into the spectral domain by graph Fourier transform. The spatial locality of filters is then given by smoothness of the spectral filters, in case of [6] modeled as B-splines. The transform involves very expensive multiplications with the eigenvector matrix. However, by a parameterization of filters as Chebyshev polynomials of eigenvalues and their approximate evaluation, computationally efficient and localized filtering has been recently achieved by Defferrard et al. [11]. Nevertheless, the filters are still learned in the context of the spectrum of graph Laplacian, which therefore has to be the same for all graphs in a dataset. This means that the graph structure is fixed and only the signal defined on the vertices may differ. This precludes applications on problems where the graph structure varies in the dataset, such as meshes, point clouds, or diverse biochemical datasets.\n\nTo cover these important cases, we formulate our filtering approach in the spatial domain, where the limited complexity of evaluation and the localization property is provided by construction. The main challenge here is dealing with weight sharing among local neighborhoods [6], as the number of vertices adjacent to a particular vertex varies and their ordering is often not well definable.\n\nSpatial Methods. Bruna et al. [6] assumed fixed graph structure and did not share any weights among neighborhoods. Several works have independently dealt with this problem. Duvenaud et al. [14] sum the signal over neighboring vertices followed by a weight matrix multiplication, effectively sharing the same weights among all edges. Atwood and Towsley [2] share weights based on the number of hops between two vertices. Kipf and Welling [21] further approximate the spectral method of [11] and weaken the dependency on the Laplacian, but ultimately arrive at center-surround weighting of neighborhoods. None of these methods captures finer structure of the neighborhood and thus does not generalize the standard convolution on grids. In contrast, our method can make use of possible edge labels and is shown to generalize regular convolution (Section 3.2).\n\nThe approach of Niepert et al. [28] introduces a heuristic for linearizing selected graph neighborhoods so that a conventional 1D CNN can be used. We share their goal of capturing structure in neighborhoods but approach it in a different way. Finally, Graph neural networks [34,24] propagate features across a graph until (near) convergence and exploit edge labels as one of the sources of information as we do. However, their system is quite different from the current multilayer feed-forward architectures, making the reuse of today's common building blocks not straightforward.\n\nCNNs on Point Clouds and Meshes. There has been little work on deep learning on point clouds or meshes. Masci et al. [25] define convolution over patch descriptors around every vertex of a 3D mesh using geodesic distances, formulated in a deep learning architecture. The only way of processing point clouds using deep learning has been to first voxelize them before feeding them to a 3D CNN, be it for classification [26] or segmentation [19] purposes. Instead, we regard point cloud as graphs in Euclidean space in this work.\n\n\nMethod\n\nWe propose a method for performing convolutions over local graph neighborhoods exploiting edge labels (Section 3.1) and show it to generalize regular convolutions (Section 3.2). Afterwards, we present deep networks with our convolution operator (Section 3.3) in the case of point clouds (Section 3.4) and general graphs (Section 3.5).\n\n\nEdge-Conditioned Convolution\n\nLet us consider a directed or undirected graph G = (V, E), where V is a finite set of vertices with |V | = n and E \u2286 V \u00d7 V is a set of edges with |E| = m. Let l \u2208 {0, .., l max } be the layer index in a feed-forward neural network. We assume the graph is both vertex-and edgelabeled, i.e. there exists function X l : V \u2192 R d l assigning labels (also called signals or features) to each vertex and L : E \u2192 R s assigning labels (also called attributes) to each edge. These functions can be regarded as matrices X l \u2208 R n\u00d7d l and L \u2208 R m\u00d7s , X 0 then being the input signal. A neighborhood N (i) = {j; (j, i) \u2208 E} \u222a {i} of vertex i is defined to contain all adjacent vertices (predecessors in directed graphs) including i itself (self-loop).\n\nOur approach computes the filtered signal X l (i) \u2208 R d l at vertex i as a weighted sum of signals X l\u22121 (j) \u2208 R d l\u22121 in its neighborhood, j \u2208 N (i). While such a commutative aggregation solves the problem of undefined vertex ordering and varying neighborhood sizes, it also smooths out any structural information. To retain it, we propose to condition each filtering weight on the respective edge label. To this end, we borrow the idea from Dynamic filter networks [5] and define a filter-generating network F l : R s \u2192 R d l \u00d7d l\u22121 which given edge label L(j, i) outputs edge-specific weight matrix \u0398 l ji \u2208 R d l \u00d7d l\u22121 , see Figure 1. The convolution operation, coined Edge-Conditioned Convolution (ECC), is formalized as follows:\nX l (i) = 1 |N (i)| j\u2208N (i) F l (L(j, i); w l )X l\u22121 (j) + b l = 1 |N (i)| j\u2208N (i) \u0398 l ji X l\u22121 (j) + b l(1)\nwhere b l \u2208 R d l is a learnable bias and F l is parameterized by learnable network weights w l . For clarity, w l and b l are model parameters updated only during training and \u0398 l ji are dynamically generated parameters for an edge label in a particular input graph. The filter-generating network F l can be implemented with any differentiable architecture; we use multi-layer perceptrons in our applications.\n\nComplexity. Computing X l for all vertices requires at most 1 m evaluations of F l and m + n or 2m + n matrixvector multiplications for directed, resp. undirected graphs. Both operations can be carried out efficiently on the GPU in batch-mode.\n\n\nRelationship to Existing Formulations\n\nOur formulation of convolution on graph neighborhoods retains the key properties of the standard convolution on regular grids that are useful in the context of CNNs: weight sharing and locality.\n\nThe weights in ECC are tied by edge label, which is in contrast to tying them by hop distance from a vertex [2], according to a neighborhood linearization heuristic [28], by being the central vertex or not [21], indiscriminately [14], or not at all [6].\n\nIn fact, our definition reduces to that of Duvenaud et al. [14] (up to scaling) in the case of uninformative edge labels:\nj\u2208N (i) \u0398 l ji X l\u22121 (j) = \u0398 l j\u2208N (i) X l\u22121 (j) if \u0398 l ji = \u0398 l \u2200(j, i) \u2208 E.\nMore importantly, the standard discrete convolution on grids is a special case of ECC, which we demonstrate in 1D for clarity. Consider an ordered set of vertices V forming a path graph (chain). To obtain convolution with a centered kernel of size s, we form E so that each vertex is connected to its s spatially nearest neighbors including self by a directed edge labeled with one-hot encoding of the neighbor's discrete offset \u03b4, see Figure 2. Taking F l as a singlelayer perceptron without bias, we have F l (L(j, i); w l ) = w l (\u03b4), where w l (\u03b4) denotes the respective reshaped column of the parameter matrix w l \u2208 R (d l \u00d7d l\u22121 )\u00d7s . With a slight abuse of notation, we arrive at the equivalence to the standard convolution:\nX l (i) = j\u2208N (i) \u0398 l ji X l\u22121 (j) = \u03b4 w l (\u03b4)X l\u22121 (i \u2212 \u03b4)\n, ignoring the normalization factor of 1/|N (i)| playing a role only at grid boundaries.\n\nThis shows that ECC can retain the same number of parameteres and computational complexity of the regular convolution in the case of grids. Note that such equivalence is not possible with none of [2,21,14] due to their way of weight tying.\n\n\nDeep Networks with ECC\n\nWhile ECC is in principle applicable to both vertex classification and graph classification tasks, in this paper we restrict ourselves only to the latter one, i.e. predicting a class for the whole input graph. Hence, we follow the common architectural pattern for feed-forward networks of in- Figure 2. Construction of a directed graph with one-hot edge labeling where the proposed edge-conditioned convolution is equivalent to the regular 1D convolution with a centered filter of size s = 3.\n\nterlaced convolutions and poolings topped by global pooling and fully-connected layers, see Figure 3 for an illustration. This way, information from the local neighborhoods gets combined over successive layers to gain context (enlarge receptive field). While edge labels are fixed for a particular graph, their (learned) interpretation by the means of filter generating networks may change from layer to layer (weights of F l are not shared among layers). Therefore, the restriction of ECC to 1-hop neighborhoods N (i) is not a constraint, akin to using small 3\u00d73 filters in normal CNNs in exchange for deeper networks, which is known to be beneficial [17].\n\nWe use batch normalization [20] after each convolution, which was necessary for the learning to converge. Interestingly, we had no success with other feature normalization techniques such as data-dependent initialization [27] or layer normalization [3].\n\nPooling. While (non-strided) convolutional layers and all point-wise layers do not change the underlying graph and only evolve the signal on vertices, pooling layers are defined to output aggregated signal on the vertices of a new, coarsened graph. Therefore, a pyramid of h max progressively coarser graphs has to be constructed for each input graph. Let us extend here our notation with an additional superscript h \u2208 {0, .., h max } to distinguish among different graphs G (h) = (V (h) , E (h) ) in the pyramid when necessary. Each G (h) has also its associated labels L (h) and signal X (h),l . A coarsening typically consists of three steps: subsampling or merging vertices, creating the new edge structure E (h) and labeling L (h) (so-called reduction), and mapping the vertices in the original graph to those in the coarsened one with M (h) :\nV (h\u22121) \u2192 V (h) .\nWe use a different algorithm depending on whether we work with general graphs or graphs in Euclidean space, therefore we postpone discussing the details to the applications. Finally, the pooling layer with index l h aggregates X (h\u22121),l h \u22121 into a lower dimensional X (h),l h based on M (h) . See Figure 3 for an example of using the introduced notation.\n\nDuring coarsening, a small graph may be reduced to several disconnected vertices in its lower resolutions without problems as self-edges are always present. Since the architecture is designed to process graphs with variable n, m, we deal with varying vertex count n (hmax) in the lowest graph resolution by global average/max pooling.\n\n\nApplication in Point Clouds\n\nPoint clouds are an important 3D data modality arising from many acquisition techniques, such as laser scanning (LiDAR) or multi-view reconstruction. Due to their natural irregularity and sparsity, so far the only way of processing point clouds using deep learning has been to first voxelize them before feeding them to a 3D CNN, be it for classification [26] or segmentation [19] purposes. Such a dense representation is very hardware friendly and simple to handle with the current deep learning frameworks.\n\nOn the other hand, there are several disadvantages too. First, voxel representation tends to be much more expensive in terms of memory than usually sparse point clouds (we are not aware of any GPU implementation of convolutions on sparse tensors). Second, the necessity to fit them into a fixed size 3D grid brings about discretization artifacts and the loss of metric scale and possibly of details. With this work, we would like to offer a competitive alternative to the mainstream by performing deep learning on point clouds directly. As far as we know, we are the first to demonstrate such a result.\n\nGraph Construction. Given a point cloud P with its point features X P (such as laser return intensity or color) we build a directed graph G = (V, E) and set up its labels X 0 and L as follows. First, we create vertex i \u2208 V for every point p \u2208 P and assign the respective signal to it by X 0 (i) = X P (p) (or 0 if there are no features X P (p)). Then we connect each vertex i to all vertices j in its spatial neighborhood by a directed edge (j, i). In our experiments with neighborhoods, fixed metric radius \u03c1 worked better than a fixed number of neighbors. The offset \u03b4 = p j \u2212 p i between the points corresponding to vertices j, i is represented in Cartesian and spherical coordinates as 6D edge label vector L(j, i) = (\u03b4 x , \u03b4 y , \u03b4 z , ||\u03b4||, arccos \u03b4 z /||\u03b4||, arctan \u03b4 y /\u03b4 x ).\n\nGraph Coarsening. For a single input point cloud P , a pyramid of downsampled point clouds P (h) is obtained by the VoxelGrid algorithm [31], which overlays a grid of resolution r (h) over the point cloud and replaces all points within a voxel with their centroid (and thus maintains subvoxel accuracy). Each of the resulting point clouds P (h) is then independently converted into a graph G (h) and labeling L (h) with neighborhood radius \u03c1 (h) as described above. The pooling map M (h) is defined so that each point in P (h\u22121) is assigned to its spatially nearest point in the subsampled point cloud P (h) . Data Augmentation. In order to reduce overfitting on small datasets, we perform online data augmentation. In particular, we randomly rotate point clouds about their upaxis, jitter their scale, perform mirroring, or delete random points.\n\n\nApplication in General Graphs\n\nMany problems can be modeled directly as graphs. In such cases the graph dataset is already given and only the appropriate graph coarsening scheme needs to be chosen. This is by no means trivial and there exists a large body of literature on this problem [32]. Without any concept of spatial localization of vertices, we resort to established graph coarsening algorithms and utilize the multiresolution framework of Shuman et al. [36,29], which works by repeated downsampling and graph reduction of the input graph. The downsampling step is based on splitting the graph into two components by the sign of the largest eigenvector of the Laplacian. This is followed by Kron reduction [13], which also defines the new edge labeling, enhanced with spectral sparsification of edges [37]. Note that the algorithm regards graphs as unweighted for the purpose of coarsening.\n\nThis method is attractive for us because of two reasons. Each downsampling step removes approximately half of the vertices, guaranteeing a certain level of pooling strength, and the sparsification step is randomized. The latter property is exploited as a useful data augmentation technique since several different graph pyramids can be generated from a single input graph. This is in spirit similar to the effect of fractional max-pooling [16]. We do not perform any other data augmentation.\n\n\nExperiments\n\nThe proposed method is evaluated in point cloud classification (real-world data in Section 4.1 and synthetic in 4.2) and on a standard graph classification benchmark (Section 4.3). In addition, we validate our method and study its properties on MNIST (Section 4.4).\n\n\nSydney Urban Objects\n\nThis point cloud dataset [9] consists of 588 objects in 14 categories (vehicles, pedestrians, signs, and trees) manually extracted from 360 \u2022 LiDAR scans, see Figure 4. It demonstrates non-ideal sensing conditions with occlusions (holes) and a large variability in viewpoint (single viewpoint). This makes object classification a challenging task.\n\nFollowing the protocol employed by the dataset authors, we report the mean F1 score weighted by class frequency, as the dataset is imbalanced. This score is further aggregated over four standard training/testing splits.\n\nNetwork Configuration. Our ECC-network has 7 parametric layers and 4 levels of graph resolution. Its configuration can be described as C (16) Triangle+SVM [9] 67.1 GFH+SVM [7] 71.0 VoxNet [26] 73.0 ORION [1] 77  Results. In the same table, we also study the dependence on convolution radii \u03c1: increasing them 1.5\u00d7 or 2\u00d7 in all convolutional layers leads to a drop in performance, which would correspond to a preference of using smaller filters in regular CNNs. The average neighborhood size is roughly 10 vertices for our best-performing network. We hypothesize that larger radii smooth out the information in the central vertex. To investigate this, we increased the importance of the self-loop by adding an identity skip-connection (see Appendix E) and retrained the networks. We achieved 77.0, 79.5 (the new state of the art), and 77.4 mean F1 for ECC, ECC 1.5\u03c1, and ECC 2\u03c1, respectively. Stronger identity connection allowed for successful integration of a larger context, up to some limit, which indeed suggests that information should be aggregated neither too much nor too little.  Results. Table 2 compares our result to several recent works, based either on volumetric [40,26,1,30] or rendered image representation [38]. Test sets were expanded to include 12 orientations (ECC). We also evaluate voting over orientations (ECC 12 votes), which slightly improves the results likely due to the rotational variance of VoxelGrid algorithm. While not fully reaching the state of the art, we believe our method remains very competitive (90.8%, resp. 87.4% mean instance accuracy). For a fairer comparison, a leading volumetric method should be retrained on voxelized synthetic point clouds.\n\n\nModelNet\n\n\nGraph Classification\n\nWe evaluate on a graph classification benchmark frequently used in the community, consisting of five datasets: NCI1, NCI109, MUTAG, ENZYMES, and D&D. Their properties can be found in Table 3, indicating the variability in dataset sizes, in graph sizes, and in the availability of labels. Following [35], we perform 10-fold cross-validation  Table 2. Mean class accuracy (resp. mean instance accuracy) on ModelNets [40]. Only the best models of each baseline are listed.\n\nwith 9 folds for training and 1 for testing and report the average prediction accuracy. NCI1 and NCI109 [39] consist of graph representations of chemical compounds screened for activity against nonsmall cell lung cancer and ovarian cancer cell lines, respectively. MUTAG [10] is a dataset of nitro compounds labeled according to whether or not they have a mutagenic effect on a bacterium. ENZYMES [4] contains representations of tertiary structure of 6 classes of enzymes. D&D [12] is a database of protein structures (vertices are amino acids, edges indicate spatial closeness) classified as enzymes and non-enzymes.\n\nNetwork Configuration. Our ECC-network for NCI1 has 8 parametric layers and 3 levels of graph resolution. Its configuration can be described as C (48) (2), where C(c) denotes ECC with c output channels followed by affine batch normalization, ReLU activation and dropout (probability 0.05), MP stands for max-pooling onto a coarser graph, GAP is global average pooling, FC(c) is fullyconnected layer with c output channels, and D(p) is dropout with probability p. The filter-generating networks F l have configuration FC(64)-FC(d l d l\u22121 ) with orthogonal weight initialization [33] and ReLU in between. Labels are encoded as one-hot vectors (d 0 = 37 and s = 4 due to an extra label for self-connections). Networks are trained with SGD and cross-entropy loss for 50 epochs with batch size 64 and learning rate 0.1 step-wise decreasing after 25, 35, and 45 epochs. The dataset is expanded five times by randomized sparsification (Section 3.5). Small deviations from this description for the other four datasets are mentioned in the supplementary.\n\nBaselines. We compare our method (ECC) to the state of the art Weisfeiler-Lehman graph kernel et al. [35] and to four approaches using deep learning as at least one of their components [2,28,41,8] or votes (ECC-5-votes) are averaged over 5 runs. To judge the influence of edge labels, we run our method with uniform labels and F l being a single layer FC(d l d l\u22121 ) without bias 2 (ECC no edge labels).\n\nResults. Table 4 conveys that while there is no clear winning algorithm, our method performs at the level of state of the art for edge-labeled datasets (NCI1, NCI109, MU-TAG). The results demonstrate the importance of exploiting edge labels for convolution-based methods, as the performance of DCNN [2] and ECC without edge labels is distinctly worse, justifying the motivation behind this paper. Averaging over random sparsifications at test time improves accuracy by a small amount. Our results on datasets without edge labels (ENZYMES, D&D) are somewhat below the state of the art but still at a reasonable level, though improvement in this case was not the aim of this work. This indicates that further research is needed into the adaptation of CNNs to general graphs. A more detailed discussion for each dataset is available in the supplementary.\n\n\nMNIST\n\nTo further validate our method, we applied it to the MNIST classification problem [23], a dataset of 70k greyscale images of handwritten digits represented on a 2D grid of size 28\u00d728. We regard each image I as point cloud P with points p i = (x, y, 0) and signal X 0 (i) = I(x, y) representing each pixel, x, y \u2208 {0, .., 27}. Edge labeling and graph coarsening is performed as explained in Section 3.4. We are mainly interested in two questions: Is ECC able to reach the standard performance on this classic baseline? What kind of representation does it learn?\n\nNetwork Configuration. Our ECC-network has 5 parametric layers with configuration C(16)-MP(2,3.4)-C(32)-MP(4,6.8)-C(64)-MP(8,30)-C(128)-D(0.5)-FC(10); the notation and filter-generating network being as in Section 4.1.\n\nThe last convolution has a stride of 30 and thus maps all 4 \u00d7 4 points to only a single point. Input graphs are created with r 0 = 1 and \u03c1 0 = 2.9. This model exactly corresponds to a regular CNN with three convolutions with filters of size 5\u00d75, 3\u00d73, and 3\u00d73 interlaced with max-poolings of size 2\u00d72, finished with two fully connected layers. Networks are trained with SGD and cross-entropy loss for 20 epochs with batch size 64 and learning rate 0.01 step-wise decreasing after 10 and 15 epochs.\n\nResults. Table 5 proves that our ECC network can achieve the level of quality comparable to the good standard in the community (99.14). This is exactly the same accuracy as reported by Defferrard et al. [11] and better than what is offered by other spectral-based approaches (98.2 [6], 94.96 [15]). Note that we are not aiming at becoming the state of the art on MNIST by this work.\n\nNext, we investigate the effect of regular grid and irregular mesh. To this end, we discard all black points (X 0 (i) = 0) from the point clouds, corresponding to 80.9% of data, and retrain the network (ECC sparse input). Exactly the same test performance is obtained (99.14), indicating that our method is very stable with respect to graph structure changing from sample to sample. Furthermore, we check the quality of the learned filter generating networks F l . We compare with ECC configured to mimic regular convolution using single-layer filter networks and one-hot encoding of offsets (ECC one-hot), as described in Section 3.2. This configuration reaches 99.37 accuracy, or 0.23 more than ECC, implying that F l are not perfect but still perform very well in learning the proper partitioning of edge labels.\n\nLast, we explore the generated filters visually for the case of the sparse input ECC. As filters \u0398 1 \u2208 R 16\u00d71 are a continuous function of an edge label, we can visualize the change of values in each dimension in 16 images by sampling labels over grids of two resolutions. The coarser one in Figure 5 has integer steps corresponding to the offsets \u03b4 x , \u03b4 y \u2208 {\u22122, .., 2}. It shows filters exhibiting the structured patterns typically found in the first layer of CNNs. The finer resolution in Figure 5 (sub-pixel steps of 0.1) reveals that the filters are in fact smooth and do not contain  Table 5. Accuracy on MNIST dataset [23]. any discontinuities apart from the angular artifact due to the 2\u03c0 periodicity of azimuth. Interestingly, the artifact is not distinct in all filters, suggesting the network may learn to overcome it if necessary.\n\n\nConclusion\n\nWe have introduced edge-conditioned convolution (ECC), an operation on graph signal performed in the spatial domain where filter weights are conditioned on edge labels and dynamically generated for each specific input sample. We have shown that our formulation generalizes the standard convolution on graphs if edge labels are chosen properly and experimentally validated this assertion on MNIST. We applied our approach to point cloud classification in a novel way, setting a new state of the art performance on Sydney dataset. Furthermore, we have outperformed other deep learning-based approaches on graph classification dataset NCI1. The source code is available at https://github.com/mys007/ecc.\n\nIn feature work we would like to treat meshes as graphs rather than point clouds. Moreover, we plan to address the currently higher level of GPU memory consumption in case of large graphs with continuous edge labels, for example by randomized clustering, which could also serve as additional regularization through data augmentation.\n\nIn the first part, the appendix provides further discussion of the graph classification results (Section B) and investigates robustness of point cloud classification to noise (Section C). In the second part, we explore several extensions of our ECC formulation, specifically with different edge labeling for point clouds (Section D), with identity connections (Section E), with degree labels (Section F), and with a learned normalization factor (Section G).\n\n\nB. Details on Graph Classification Benchmark\n\nIn this section we describe the differences in our network architecture to the one introduced for NCI1 in the main paper and discuss evaluation results for each dataset in detail.\n\nNCI1. ECC (83.80%) performs distinctly better than convolution methods that are not able to use edge labels (DCNN [2] 62.61%, PSCN [28] 78.59%). Methods not approaching the problem as convolutions on graphs but rather combining deep learning with other techniques are stronger (Deep WL [41] 80.31%, structure2vec [8] 83.72%) but are still outperformed by ECC. While the Weisfeiler-Lehman graph kernel remains the strongest method (WL [35] 84.55%), it is fair to conclude that ECC, structure2vec, and WL perform at the same level.\n\nNCI109. We use the same ECC-network configuration and training details as described in Section 4.3 for NCI1, since both datasets are similar. ECC (82.14%) performs distinctly better than DCNN [2] (62.86%), which is not able to use edge labels, and is on par with non-convolutional approaches (Deep WL [41] 80.32%, structure2vec [8] 82.16%, WL [35] 84.49%).\n\nMUTAG. As MUTAG is a tiny dataset of small graphs, we trained a downsized ECC-network to combat overfitting. Using the notation from Section 4.3, its configuration is C(16)-C(32)-C(48)-MP-C(64)-MP-GAP-FC(64)-D(0.2)-FC (2), all other details are as with NCI1. While by numbers ECC (89.44%) outperforms all other approaches except of PSCN [28] (92.63%), we note that all four leading methods (Deep WL [41] 87.44%, structure2vec [8] 88.28%, ECC, PSCN) can be seen to perform equally well due to fluctuations caused by the dataset size. We account the tiny decrease in performance with test-time randomization (88.33%) to the same reason.\n\nENZYMES. Due to higher complexity of this task we use a wider ECC-network configured as C(64)-C(64)-C(96)-MP-C(96)-C(128)-MP-C(128)-C(160)-MP-C(160)-GAP-FC(192)-D(0.2)-FC(6) using the notation and other details in Section 4.3. As this dataset is not edge-labeled, we do not expect to obtain the best performance. Indeed, our method (53.50%) performs at the level of Deep WL [41] (53.43%) and is overperformed by WL [35] (59.05%) and structure2vec [8] (61.10%). Note that the gap to the other convolution-based method DCNN [2] (18.10%) is huge and there is an improvement of more than 4 percentage points due to edge labels in coarser graph resolutions from Kron reduction.\n\nD&D. Due to large graphs in this dataset we designed a ECC-network with more pooling configured as C (48) 2)-FC(2) using the notation and other details in Section 4.3. As this dataset is not edge-labeled, we do not expect to obtain the best performance. Our method (74.10%) is overperformed by the others who evaluated on this dataset (PSCN [28] 77.12%, WL [35] 79.78%, structure2vec [8] 82.22%), though the margin is not very large.\n\n\nC. Robustness to Noise\n\nReal-world point clouds contain several kinds of artifacts, such as holes due to occlusions and Gaussian noise due to measurement uncertainty. Figure 6 shows that ECC is highly robust to point removal and can be made robust to additive Gaussian noise by a proper training data augmentation.\n\n\nD. Edge Labels for Point Clouds\n\nIn Section 3.4 we defined edge labels L(j, i) as the offset \u03b4 = p j \u2212 p i in Cartesian and spherical coordinates, L(j, i) = (\u03b4 x , \u03b4 y , \u03b4 z , ||\u03b4||, arccos \u03b4 z /||\u03b4||, arctan \u03b4 y /\u03b4 x ). Here, we explore the importance of individual elements in the proposed edge labeling and further evaluate labels invariant to rotation about objects' vertical axis z (IRz). Table 6 conveys that models with isotropic (60.7) or no labels (38.9) perform poorly as expected, while either of the coordinate systems is important. IRz labeling performs comparably or even slightly better than our proposed one. However, we believe this is a property of the specific dataset and may not necessarily generalize, an example being MNIST, Label L(j, i) Mean F1\n\n(\u03b4 x , \u03b4 y , \u03b4 z , ||\u03b4||, arccos \u03b4 z /||\u03b4||, arctan \u03b4 y /\u03b4 x ) 78.4 (\u03b4 x , \u03b4 y , \u03b4 z ) 76.1 (||\u03b4||, arccos \u03b4 z /||\u03b4||, arctan \u03b4 y /\u03b4 x ) 77.3\n\n(||\u03b4 xy ||, \u03b4 z , ||\u03b4||, arccos \u03b4 z /||\u03b4||) 75.8 (||\u03b4 xy ||, \u03b4 z ) 78.2 (||\u03b4||, arccos \u03b4 z /||\u03b4||) 78.7\n\n(||\u03b4||) 60.7 (0) 38.9 where IRz is equivalent to full isotropy and decreases accuracy to 89.9%.\n\n\nE. Identity Connections\n\nThe formulation of ECC in Equation 1 does not treat self-loop edges in a special way. However, the success of residual networks [18] is a strong motivation to consider adding identity skip-connections to our model and encouraging ECC in residual learning. We thus formulate ECCresnet as follows:  Table 7. The effect of adding identity connections (improvements in italics). Performance metrics vary and are specific to each dataset, as introduced in the main paper.\n\nX l (i) = 1 |N (i)| j\u2208N (i) \u0398 l ji X l\u22121 (j) + b l + id(X l\u22121 (i))\n\n(2) where id() is an identity mapping if d l = d l\u22121 and a linear mapping otherwise.\n\nThe results listed in Table 7 show that with two exceptions (NCI109 and ENZYMES) ECC does not benefit from identity connections in the specific network configurations. The trend may be different for other configurations, e.g. ECC 1.5\u03c1 improved from 76.9 to 79.5 mean F1 score on Sydney due to identity connections as mentioned in Section 4.1.\n\n\nF. Vertex Degrees in Edge Labels\n\nIn the task of graph classification, we used categorical labels (if present) encoded as one-hot vectors for edges in the input graph and scalars computed by Kron reduction for edges in all coarsened graphs.\n\nHere we investigate making the edge labels more informative by including the degrees of the pair of vertices forming an edge. The degree information is implicitly used by spectral convolution methods, as the degree information is contained in the graph Laplacian, and also appears in the explicit propagation rules [21,2].\n\nOur model can be easily extended to make use of this information by simply appending it to the existing edge label vectors. We consider four variants of providing additional degree labels L deg (j) and L deg (i) about a directed edge (j, i): L deg (i) = 1/ deg(i), L deg (i) = 1/deg(i), L deg (i) = deg(i), and L deg (i) = deg(i), where deg(i) = |N (i)| is the degree of vertex i \u2208 V . We use these additional labels in all graph resolutions. Table 8 reveals that degree information can improve the results considerably, especially for datasets without given edge labels (by up to 5 percentage points for ENZYMES and up to 2.14 percentage points for D&D). However, no variant of L deg (i) can guarantee consistent improvement over all datasets.\n\n\nG. Vertex Degrees in Normalization\n\nThe formulation of ECC in Equation 1 performs normalization by the neighborhood size. Here we explore learning an additional multiplicative factor, conditioned on the  Table 9. The effect of adding a learned normalization factor (improvements in italics). Performance metrics vary and are specific to each dataset, as introduced in the main paper.\n\nneighborhood size 1/|N (i)|. To this end, we again make use of Dynamic filter networks [5] and design a factorgenerating network Z l : R \u2192 R which given vertex degree deg(i) = |N (i)| outputs a vertex-specific normalization factor. We formulate ECC-Z as follows:\nX l (i) = Z l (|N (i)|; w l ) |N (i)| j\u2208N (i) \u0398 l ji X l\u22121 (j) + b l(3)\nIn our experiments, the factor-generating networks Z l have configuration FC(32)-FC(1) with orthogonal weight initialization [33] and ReLUs in between.\n\nThe results in Table 9 show that while being helpful on some datasets (NCI109, ENZYMES, ModelNet10), ECC-Z harms the performance on the other ones. Embedding vertex information in labels instead seems to achieve higher performance (Section F).\n\nFigure 3 .\n3Illustration of a deep network with three edge-conditioned convolutions (first, fourth, and eight network layer) and one pooling (seventh layer). The last convolution is executed on a structurally different graph G(1) , which is related to the input graph G (0) by coarsening and signal aggregation in the max pooling step according to mapping M(1) . See Section 3.3 for more details.\n\n\n64)-D(0.2)-FC(14), where C(c) denotes ECC with c output channels followed by affine batch normalization and ReLU activation, MP(r,\u03c1) stands for max-pooling down to grid resolution of r meters and neighborhood radius of Model Mean F1\n\n\u03c1\nmeters, GAP is global average pooling, FC(c) is fullyconnected layer with c output channels, and D(p) is dropout with probability p. The filter-generating networks F l have configuration FC(16)-FC(32)-FC(d l d l\u22121 ) with orthogonal weight initialization[33] and ReLUs in between. Input graphs are created with r 0 = 0.1 and \u03c1 0 = 0.2 meters to break overly dense point clusters. Networks are trained with SGD and cross-entropy loss for 250 epochs with batch size 32 and learning rate 0.1 step-wise decreasing after 200 and 245 epochs. Vertex signal X 0 is scalar laser return intensity (0-255), representing depth.\n\n\nModelNet [40] is a large scale collection of object meshes. We evaluate classification performance on its subsets ModelNet10 (3991/908 train/test examples in 10 categories) and ModelNet40 (9843/2468 train/test examples in 40 categories). Synthetic point clouds are created from\n\nFigure 4 .\n4Illustrative samples of the majority of classes in Sydney Urban Objects dataset, reproduced from[9]. meshes by uniformly sampling 1000 points on mesh faces according to face area (a simulation of acquisition from multiple viewpoints) and rescaled into a unit sphere.Network Configuration. Our ECC-network for Model-Net10 has 7 parametric layers and 3 levels of graph resolution with configuration C(16)-C(32)-MP(2.5/32,7.5/32)-C(32)-C(32)-MP(7.5/32,22.5/32)-C(64)-GMP-FC(64)-D(0.2)-FC(10), GMP being global max pooling. Other definitions and filter-generating networks F l are as in Section 4.1. Input graphs are created with r 0 = 1/32 and \u03c1 0 = 2/32 units, mimicking the typical grid resolution of 32 3 in voxel-based methods. The network is trained with SGD and cross-entropy loss for 175 epochs with batch size 64 and learning rate 0.1 step-wise decreasing after every 50 epochs. There is no vertex signal, i.e. X 0 are zero. For ModelNet40, the network is wider (C(24), C(48), C(48), C(48), C(96), FC(64), FC(40)) and is trained for 100 epochs with learning rate decreasing after each 30 epochs.\n\n\n-C(48)-C(48)-MP-C(48)-C(64)-MP-C(64)-GAP-FC(64)-D(0.1)-FC\n\nFigure 5 .\n5Convolutional filters learned on MNIST in the first layer for sparse input ECC, sampled in two different resolutions. See Section 4.4 for details.\n\n\n-C(48)-C(48)-MP-C(48)-MP-C(64)-MP-C(64)-MP-C(64)-MP-C(64)-MP-GAP-FC(64)-D(0.\n\nFigure 6 .\n6Robustness to point removal and Gaussian noise.\n\nTable 1\n1compares our result (ECC, 78.4) against \ntwo methods based on volumetric CNNs evaluated on vox-\nelized occupancy grids of size 32x32x32 (VoxNet [26] 73.0 \nand ORION [1] 77.8), which we outperform by a small mar-\ngin and set the new state of the art result on this dataset. \n\n\n\n. Randomized sparsification used during training time can also be exploited at test time, when the network prediction scores (ECC-5-scores)NCI1 NCI109 MUTAG ENZYMES D&D \n\n# graphs \n4110 4127 \n188 \n600 \n1178 \nmean |V | \n29.87 29.68 \n17.93 \n32.63 \n284.32 \nmean |E| \n32.3 32.13 \n19.79 \n62.14 \n715.66 \n# classes \n2 \n2 \n2 \n6 \n2 \n# vertex labels 37 \n38 \n7 \n3 \n82 \n# edge labels \n3 \n3 \n11 \n-\n-\n\nTable 3. Characteristics of the graph benchmark datasets, ex-\ntended from [8]. Both edge and vertex labels are categorical. \n\nModel \nNCI1 NCI109 MUTAG ENZYMES D&D \n\nDCNN [2] \n62.61 62.86 \n66.98 \n18.10 \n-\nPSCN [28] \n78.59 \n-\n92.63 \n-\n77.12 \nDeep WL [41] \n80.31 80.32 \n87.44 \n53.43 \n-\nstructure2vec [8] 83.72 82.16 \n88.28 \n61.10 \n82.22 \nWL [35] \n84.55 84.49 \n83.78 \n59.05 \n79.78 \n\nECC (no edge labels) 76.82 75.03 \n76.11 \n45.67 \n72.54 \nECC \n83.80 81.87 \n89.44 \n50.00 \n73.65 \nECC (5 votes) \n83.63 82.04 \n88.33 \n53.50 \n73.68 \nECC (5 scores) \n83.80 82.14 \n88.33 \n52.67 \n74.10 \n\nTable 4. Mean accuracy (10 folds) on graph classification datasets. \nOnly the best-performing models of each baseline are listed. \n\n\n\nTable 6 .\n6ECC on Sydney with varied edge label definition.\n\n\nNCI1 NCI109 MUTAG ENZYMES D&D Sydney ModelNet10ECC-resnet 83.24 \n81.97 \n85.56 \n51.83 \n70.48 \n77.0 \n88.5 (89.3) \nECC \n83.80 \n81.87 \n89.44 \n50.00 \n73.65 \n78.4 \n89.3 (90.0) \n\n\n\nTable 8 .\n8NCI1 NCI109 MUTAG ENZYMES D&DL deg (i) = 1/ deg(i) 82.99   The effect in mean classification accuracy of adding vertex degrees to edge labels (improvements in italics).81.94 \n87.78 \n53.67 \n73.65 \nL deg (i) = 1/deg(i) \n83.60 \n82.40 \n88.89 \n52.67 \n71.77 \nL deg (i) = deg(i) \n83.58 \n82.28 \n86.67 \n55.00 \n75.79 \nL deg (i) = deg(i) \n83.16 \n83.03 \n86.67 \n52.83 \n73.74 \n\nECC without L deg (i) 83.80 \n81.87 \n89.44 \n50.00 \n73.65 \n\nNCI1 NCI109 MUTAG ENZYMES D&D Sydney ModelNet10 \n\nECC-Z 83.48 \n82.57 \n86.67 \n52.50 \n72.03 \n75.5 \n89.9 (90.6) \nECC \n83.80 \n81.87 \n89.44 \n50.00 \n73.65 \n78.4 \n89.3 (90.0) \n\n\nIf edge labels are represented by s discrete values in a particular graph and s < m, F l can be evaluated only s-times.\nAlso possible for unlabeled ENZYMES and D&D, since our method uses labels from Kron reduction for all coarsened graphs by default.\nAcknowledgments.We gratefully acknowledge NVIDIA Corporation for the donated GPU used in this research. We are thankful to anonymous reviewers for their feedback.AppendixA. Overview\nOrientation-boosted voxel nets for 3d object recognition. N S Alvar, M Zolfaghari, T Brox, abs/1604.03351CoRR67N. S. Alvar, M. Zolfaghari, and T. Brox. Orientation-boosted voxel nets for 3d object recognition. CoRR, abs/1604.03351, 2016. 6, 7\n\nDiffusion-convolutional neural networks. J Atwood, D Towsley, NIPS. 11J. Atwood and D. Towsley. Diffusion-convolutional neural networks. In NIPS, 2016. 2, 3, 7, 10, 11\n\nLayer normalization. CoRR. L J Ba, R Kiros, G E Hinton, abs/1607.06450L. J. Ba, R. Kiros, and G. E. Hinton. Layer normalization. CoRR, abs/1607.06450, 2016. 4\n\nShortest-path kernels on graphs. K M Borgwardt, H Kriegel, Proceedings of the 5th IEEE International Conference on Data Mining (ICDM 2005). the 5th IEEE International Conference on Data Mining (ICDM 2005)Houston, Texas, USAK. M. Borgwardt and H. Kriegel. Shortest-path kernels on graphs. In Proceedings of the 5th IEEE International Confer- ence on Data Mining (ICDM 2005), 27-30 November 2005, Houston, Texas, USA, pages 74-81, 2005. 7\n\nDynamic filter networks. B D Brabandere, X Jia, T Tuytelaars, L V Gool, NIPS. 312B. D. Brabandere, X. Jia, T. Tuytelaars, and L. V. Gool. Dy- namic filter networks. In NIPS, 2016. 3, 12\n\n. J Bruna, W Zaremba, A Szlam, Y Lecun, abs/1312.6203J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks on graphs. CoRR, abs/1312.6203, 2013. 1, 2, 3, 8\n\nPerformance of global descriptors for velodyne-based urban object recognition. T Chen, B Dai, D Liu, J Song, 2014 IEEE Intelligent Vehicles Symposium Proceedings. Dearborn, MI, USAT. Chen, B. Dai, D. Liu, and J. Song. Performance of global descriptors for velodyne-based urban object recogni- tion. In 2014 IEEE Intelligent Vehicles Symposium Proceed- ings, Dearborn, MI, USA, June 8-11, 2014, pages 667-673, 2014. 6\n\nDiscriminative embeddings of latent variable models for structured data. H Dai, B Dai, L Song, ICML. 710H. Dai, B. Dai, and L. Song. Discriminative embeddings of latent variable models for structured data. In ICML, 2016. 7, 10\n\nUnsupervised feature learning for classification of outdoor 3d scans. M De Deuge, A Quadros, C Hung, B Douillard, Australasian Conference on Robitics and Automation. 26M. De Deuge, A. Quadros, C. Hung, and B. Douillard. Un- supervised feature learning for classification of outdoor 3d scans. In Australasian Conference on Robitics and Automa- tion, volume 2, 2013. 1, 5, 6\n\nStructure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity. A K Debnath, R L Lopez De Compadre, G Debnath, A J Shusterman, C Hansch, Journal of medicinal chemistry. 342A. K. Debnath, R. L. Lopez de Compadre, G. Debnath, A. J. Shusterman, and C. Hansch. Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobic- ity. Journal of medicinal chemistry, 34(2):786-797, 1991. 7\n\nConvolutional neural networks on graphs with fast localized spectral filtering. M Defferrard, X Bresson, P Vandergheynst, NIPS. 2M. Defferrard, X. Bresson, and P. Vandergheynst. Convolu- tional neural networks on graphs with fast localized spectral filtering. In NIPS, 2016. 2, 8\n\nDistinguishing enzyme structures from non-enzymes without alignments. P D Dobson, A J Doig, Journal of molecular biology. 3304P. D. Dobson and A. J. Doig. Distinguishing enzyme struc- tures from non-enzymes without alignments. Journal of molecular biology, 330(4):771-783, 2003. 7\n\nKron reduction of graphs with applications to electrical networks. F D\u00f6rfler, F Bullo, IEEE Trans. on Circuits and Systems. 1F. D\u00f6rfler and F. Bullo. Kron reduction of graphs with appli- cations to electrical networks. IEEE Trans. on Circuits and Systems, 60-I(1):150-163, 2013. 5\n\nConvolutional networks on graphs for learning molecular fingerprints. D K Duvenaud, D Maclaurin, J Aguilera-Iparraguirre, R Bombarell, T Hirzel, A Aspuru-Guzik, R P Adams, NIPS. 23D. K. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. Bombarell, T. Hirzel, A. Aspuru-Guzik, and R. P. Adams. Convolutional networks on graphs for learning molecular fingerprints. In NIPS, 2015. 2, 3\n\nGraph based convolutional neural network. M Edwards, X Xie, BMVC. M. Edwards and X. Xie. Graph based convolutional neural network. In BMVC, 2016. 8\n\nFractional max-pooling. CoRR, abs/1412.6071. B Graham, B. Graham. Fractional max-pooling. CoRR, abs/1412.6071, 2014. 5\n\nConvolutional neural networks at constrained time cost. K He, J Sun, CVPR. K. He and J. Sun. Convolutional neural networks at con- strained time cost. In CVPR, 2015. 4\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, CVPR. 11K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016. 11\n\nPoint cloud labeling using 3d convolutional neural network. J Huang, S You, ICPR. 14J. Huang and S. You. Point cloud labeling using 3d convolu- tional neural network. In ICPR, 2016. 1, 3, 4\n\nBatch normalization: Accelerating deep network training by reducing internal covariate shift. S Ioffe, C Szegedy, ICML. [20] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015. 4\n\nSemi-supervised classification with graph convolutional networks. T N Kipf, M Welling, abs/1609.02907CoRR211T. N. Kipf and M. Welling. Semi-supervised classification with graph convolutional networks. CoRR, abs/1609.02907, 2016. 2, 3, 11\n\nDeep learning. Y Lecun, Y Bengio, G Hinton, Nature. 5217553Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. Nature, 521(7553):436-444, 2015. 1\n\nGradientbased learning applied to document recognition. Proceedings of the IEEE. Y Lecun, L Bottou, Y Bengio, P Haffner, 86Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient- based learning applied to document recognition. Proceed- ings of the IEEE, 86(11):2278-2324, 1998. 7, 8\n\nGated graph sequence neural networks. Y Li, D Tarlow, M Brockschmidt, R S Zemel, ICLR. Y. Li, D. Tarlow, M. Brockschmidt, and R. S. Zemel. Gated graph sequence neural networks. In ICLR, 2016. 2\n\nJ Masci, D Boscaini, M M Bronstein, P Vandergheynst, Geodesic convolutional neural networks on riemannian manifolds. J. Masci, D. Boscaini, M. M. Bronstein, and P. Van- dergheynst. Geodesic convolutional neural networks on rie- mannian manifolds. pages 37-45, 2015. 2\n\nVoxnet: A 3d convolutional neural network for real-time object recognition. D Maturana, S Scherer, IROS. 67D. Maturana and S. Scherer. Voxnet: A 3d convolutional neural network for real-time object recognition. In IROS, 2015. 1, 3, 4, 6, 7\n\nAll you need is a good init. D Mishkin, J Matas, ICLR. D. Mishkin and J. Matas. All you need is a good init. In ICLR, 2016. 4\n\nLearning convolutional neural networks for graphs. M Niepert, M Ahmed, K Kutzkov, ICML. 710M. Niepert, M. Ahmed, and K. Kutzkov. Learning convolu- tional neural networks for graphs. In ICML, 2016. 2, 3, 7, 10\n\nGSPBOX: A toolbox for signal processing on graphs. N Perraudin, J Paratte, D I Shuman, V Kalofolias, P Vandergheynst, D K Hammond, abs/1408.5781N. Perraudin, J. Paratte, D. I. Shuman, V. Kalofolias, P. Van- dergheynst, and D. K. Hammond. GSPBOX: A toolbox for signal processing on graphs. CoRR, abs/1408.5781, 2014. 5\n\nVolumetric and multi-view cnns for object classification on 3d data. C R Qi, H Su, M Nie\u00dfner, A Dai, M Yan, L J Guibas, CVPR. 67C. R. Qi, H. Su, M. Nie\u00dfner, A. Dai, M. Yan, and L. J. Guibas. Volumetric and multi-view cnns for object classi- fication on 3d data. In CVPR, 2016. 6, 7\n\n3d is here: Point cloud library (pcl). R B Rusu, S Cousins, Robotics and Automation (ICRA), 2011 IEEE International Conference on. IEEER. B. Rusu and S. Cousins. 3d is here: Point cloud library (pcl). In Robotics and Automation (ICRA), 2011 IEEE Inter- national Conference on, pages 1-4. IEEE, 2011. 4\n\nAdvanced coarsening schemes for graph partitioning. I Safro, P Sanders, C Schulz, ACM Journal of Experimental Algorithmics. 191I. Safro, P. Sanders, and C. Schulz. Advanced coarsening schemes for graph partitioning. ACM Journal of Experimen- tal Algorithmics, 19(1), 2014. 5\n\nExact solutions to the nonlinear dynamics of learning in deep linear neural networks. A M Saxe, J L Mcclelland, S Ganguli, ICLR. 712A. M. Saxe, J. L. McClelland, and S. Ganguli. Exact so- lutions to the nonlinear dynamics of learning in deep linear neural networks. In ICLR, 2014. 6, 7, 12\n\nThe graph neural network model. F Scarselli, M Gori, A C Tsoi, M Hagenbuchner, G Monfardini, IEEE Trans. Neural Networks. 201F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural network model. IEEE Trans. Neural Networks, 20(1):61-80, 2009. 2\n\nWeisfeiler-lehman graph kernels. N Shervashidze, P Schweitzer, E J Van Leeuwen, K Mehlhorn, K M Borgwardt, Journal of Machine Learning Research. 12610N. Shervashidze, P. Schweitzer, E. J. van Leeuwen, K. Mehlhorn, and K. M. Borgwardt. Weisfeiler-lehman graph kernels. Journal of Machine Learning Research, 12:2539-2561, 2011. 6, 7, 10\n\nA multiscale pyramid transform for graph signals. D I Shuman, M J Faraji, P Vandergheynst, IEEE Trans. Signal Processing. 648D. I. Shuman, M. J. Faraji, and P. Vandergheynst. A mul- tiscale pyramid transform for graph signals. IEEE Trans. Signal Processing, 64(8):2119-2134, 2016. 5\n\nGraph sparsification by effective resistances. D A Spielman, N Srivastava, SIAM Journal on Computing. 406D. A. Spielman and N. Srivastava. Graph sparsification by effective resistances. SIAM Journal on Computing, 40(6):1913-1926, 2011. 5\n\nLearned-Miller. Multi-view convolutional neural networks for 3d shape recognition. H Su, S Maji, E Kalogerakis, E , ICCV. 67H. Su, S. Maji, E. Kalogerakis, and E. G. Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition. In ICCV, 2015. 6, 7\n\nComparison of descriptor spaces for chemical compound retrieval and classification. N Wale, I A Watson, G Karypis, Knowledge and Information Systems. 1437N. Wale, I. A. Watson, and G. Karypis. Comparison of de- scriptor spaces for chemical compound retrieval and classifi- cation. Knowledge and Information Systems, 14(3):347-375, 2008. 1, 7\n\n3d shapenets for 2.5d object recognition and next-best-view prediction. Z Wu, S Song, A Khosla, X Tang, J Xiao, CVPR. 67Z. Wu, S. Song, A. Khosla, X. Tang, and J. Xiao. 3d shapenets for 2.5d object recognition and next-best-view pre- diction. In CVPR, 2015. 6, 7\n\nDeep graph kernels. P Yanardag, S V N Vishwanathan, SIGKDD. 710P. Yanardag and S. V. N. Vishwanathan. Deep graph kernels. In SIGKDD, 2015. 7, 10\n", "annotations": {"author": "[{\"end\":171,\"start\":79},{\"end\":260,\"start\":172}]", "publisher": null, "author_last_name": "[{\"end\":96,\"start\":86},{\"end\":187,\"start\":178}]", "author_first_name": "[{\"end\":85,\"start\":79},{\"end\":177,\"start\":172}]", "author_affiliation": "[{\"end\":170,\"start\":124},{\"end\":259,\"start\":213}]", "title": "[{\"end\":76,\"start\":1},{\"end\":336,\"start\":261}]", "venue": null, "abstract": "[{\"end\":1119,\"start\":338}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b21\"},\"end\":1491,\"start\":1487},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2893,\"start\":2889},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2896,\"start\":2893},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3138,\"start\":3135},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3838,\"start\":3834},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4055,\"start\":4052},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4924,\"start\":4921},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5248,\"start\":5244},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5940,\"start\":5937},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6089,\"start\":6086},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6249,\"start\":6245},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6411,\"start\":6408},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6497,\"start\":6493},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6545,\"start\":6541},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6949,\"start\":6945},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7192,\"start\":7188},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7195,\"start\":7192},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7617,\"start\":7613},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7917,\"start\":7913},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7938,\"start\":7934},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9610,\"start\":9607},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10989,\"start\":10986},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11047,\"start\":11043},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11088,\"start\":11084},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11111,\"start\":11107},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11130,\"start\":11127},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11196,\"start\":11192},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12414,\"start\":12411},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12417,\"start\":12414},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12420,\"start\":12417},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13631,\"start\":13627},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13859,\"start\":13855},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13886,\"start\":13883},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15838,\"start\":15834},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15859,\"start\":15855},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":17519,\"start\":17515},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":18518,\"start\":18514},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":18693,\"start\":18689},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":18696,\"start\":18693},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18945,\"start\":18941},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":19040,\"start\":19036},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":19570,\"start\":19566},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19952,\"start\":19949},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20652,\"start\":20649},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20669,\"start\":20666},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":20686,\"start\":20682},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":20701,\"start\":20698},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":21676,\"start\":21672},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21679,\"start\":21676},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21681,\"start\":21679},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21684,\"start\":21681},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":21722,\"start\":21718},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":22524,\"start\":22520},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":22640,\"start\":22636},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":22801,\"start\":22797},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22968,\"start\":22964},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":23093,\"start\":23090},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23174,\"start\":23170},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":23893,\"start\":23889},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":24464,\"start\":24460},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":24547,\"start\":24544},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":24550,\"start\":24547},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24553,\"start\":24550},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24555,\"start\":24553},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":25066,\"start\":25063},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25711,\"start\":25707},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27112,\"start\":27108},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27189,\"start\":27186},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":27201,\"start\":27197},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":28736,\"start\":28732},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30805,\"start\":30802},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":30823,\"start\":30819},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30978,\"start\":30974},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":31004,\"start\":31001},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":31126,\"start\":31122},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":31414,\"start\":31411},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":31524,\"start\":31520},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":31550,\"start\":31547},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":31566,\"start\":31562},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":31798,\"start\":31795},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":31918,\"start\":31914},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":31980,\"start\":31976},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32006,\"start\":32003},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":32591,\"start\":32587},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":32632,\"start\":32628},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32663,\"start\":32660},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":32738,\"start\":32735},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":33232,\"start\":33228},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":33248,\"start\":33244},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33274,\"start\":33271},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":34914,\"start\":34910},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":36310,\"start\":36306},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36312,\"start\":36310},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":37537,\"start\":37534},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":37911,\"start\":37907},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":38409,\"start\":38406},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":38540,\"start\":38537},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":38596,\"start\":38592},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":39072,\"start\":39068},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":39822,\"start\":39819}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":38576,\"start\":38179},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38811,\"start\":38577},{\"attributes\":{\"id\":\"fig_2\"},\"end\":39429,\"start\":38812},{\"attributes\":{\"id\":\"fig_3\"},\"end\":39709,\"start\":39430},{\"attributes\":{\"id\":\"fig_4\"},\"end\":40823,\"start\":39710},{\"attributes\":{\"id\":\"fig_5\"},\"end\":40883,\"start\":40824},{\"attributes\":{\"id\":\"fig_6\"},\"end\":41043,\"start\":40884},{\"attributes\":{\"id\":\"fig_7\"},\"end\":41122,\"start\":41044},{\"attributes\":{\"id\":\"fig_8\"},\"end\":41183,\"start\":41123},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":41468,\"start\":41184},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":42564,\"start\":41469},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42625,\"start\":42565},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":42800,\"start\":42626},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":43405,\"start\":42801}]", "paragraph": "[{\"end\":1492,\"start\":1135},{\"end\":2049,\"start\":1494},{\"end\":2635,\"start\":2051},{\"end\":3139,\"start\":2637},{\"end\":3174,\"start\":3141},{\"end\":3486,\"start\":3176},{\"end\":3747,\"start\":3488},{\"end\":3900,\"start\":3749},{\"end\":4574,\"start\":3917},{\"end\":5661,\"start\":4576},{\"end\":6054,\"start\":5663},{\"end\":6912,\"start\":6056},{\"end\":7494,\"start\":6914},{\"end\":8022,\"start\":7496},{\"end\":8367,\"start\":8033},{\"end\":9138,\"start\":8400},{\"end\":9875,\"start\":9140},{\"end\":10395,\"start\":9985},{\"end\":10640,\"start\":10397},{\"end\":10876,\"start\":10682},{\"end\":11131,\"start\":10878},{\"end\":11254,\"start\":11133},{\"end\":12064,\"start\":11333},{\"end\":12213,\"start\":12125},{\"end\":12454,\"start\":12215},{\"end\":12973,\"start\":12481},{\"end\":13632,\"start\":12975},{\"end\":13887,\"start\":13634},{\"end\":14737,\"start\":13889},{\"end\":15111,\"start\":14756},{\"end\":15447,\"start\":15113},{\"end\":15987,\"start\":15479},{\"end\":16591,\"start\":15989},{\"end\":17377,\"start\":16593},{\"end\":18225,\"start\":17379},{\"end\":19125,\"start\":18259},{\"end\":19618,\"start\":19127},{\"end\":19899,\"start\":19634},{\"end\":20271,\"start\":19924},{\"end\":20492,\"start\":20273},{\"end\":22186,\"start\":20494},{\"end\":22691,\"start\":22222},{\"end\":23310,\"start\":22693},{\"end\":24357,\"start\":23312},{\"end\":24762,\"start\":24359},{\"end\":25615,\"start\":24764},{\"end\":26185,\"start\":25625},{\"end\":26405,\"start\":26187},{\"end\":26903,\"start\":26407},{\"end\":27287,\"start\":26905},{\"end\":28104,\"start\":27289},{\"end\":28949,\"start\":28106},{\"end\":29664,\"start\":28964},{\"end\":29999,\"start\":29666},{\"end\":30458,\"start\":30001},{\"end\":30686,\"start\":30507},{\"end\":31217,\"start\":30688},{\"end\":31575,\"start\":31219},{\"end\":32211,\"start\":31577},{\"end\":32885,\"start\":32213},{\"end\":33320,\"start\":32887},{\"end\":33637,\"start\":33347},{\"end\":34409,\"start\":33673},{\"end\":34552,\"start\":34411},{\"end\":34657,\"start\":34554},{\"end\":34754,\"start\":34659},{\"end\":35248,\"start\":34782},{\"end\":35316,\"start\":35250},{\"end\":35402,\"start\":35318},{\"end\":35746,\"start\":35404},{\"end\":35989,\"start\":35783},{\"end\":36313,\"start\":35991},{\"end\":37059,\"start\":36315},{\"end\":37445,\"start\":37098},{\"end\":37709,\"start\":37447},{\"end\":37933,\"start\":37782},{\"end\":38178,\"start\":37935}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9984,\"start\":9876},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11332,\"start\":11255},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12124,\"start\":12065},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14755,\"start\":14738},{\"attributes\":{\"id\":\"formula_4\"},\"end\":37781,\"start\":37710}]", "table_ref": "[{\"end\":21599,\"start\":21592},{\"end\":22412,\"start\":22405},{\"end\":22570,\"start\":22563},{\"end\":24780,\"start\":24773},{\"end\":26921,\"start\":26914},{\"end\":28704,\"start\":28697},{\"end\":35086,\"start\":35079},{\"end\":35433,\"start\":35426},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":36765,\"start\":36758},{\"end\":37273,\"start\":37266},{\"end\":37957,\"start\":37950}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1133,\"start\":1121},{\"attributes\":{\"n\":\"2.\"},\"end\":3915,\"start\":3903},{\"attributes\":{\"n\":\"3.\"},\"end\":8031,\"start\":8025},{\"attributes\":{\"n\":\"3.1.\"},\"end\":8398,\"start\":8370},{\"attributes\":{\"n\":\"3.2.\"},\"end\":10680,\"start\":10643},{\"attributes\":{\"n\":\"3.3.\"},\"end\":12479,\"start\":12457},{\"attributes\":{\"n\":\"3.4.\"},\"end\":15477,\"start\":15450},{\"attributes\":{\"n\":\"3.5.\"},\"end\":18257,\"start\":18228},{\"attributes\":{\"n\":\"4.\"},\"end\":19632,\"start\":19621},{\"attributes\":{\"n\":\"4.1.\"},\"end\":19922,\"start\":19902},{\"attributes\":{\"n\":\"4.2.\"},\"end\":22197,\"start\":22189},{\"attributes\":{\"n\":\"4.3.\"},\"end\":22220,\"start\":22200},{\"attributes\":{\"n\":\"4.4.\"},\"end\":25623,\"start\":25618},{\"attributes\":{\"n\":\"5.\"},\"end\":28962,\"start\":28952},{\"end\":30505,\"start\":30461},{\"end\":33345,\"start\":33323},{\"end\":33671,\"start\":33640},{\"end\":34780,\"start\":34757},{\"end\":35781,\"start\":35749},{\"end\":37096,\"start\":37062},{\"end\":38190,\"start\":38180},{\"end\":38814,\"start\":38813},{\"end\":39721,\"start\":39711},{\"end\":40895,\"start\":40885},{\"end\":41134,\"start\":41124},{\"end\":41192,\"start\":41185},{\"end\":42575,\"start\":42566},{\"end\":42811,\"start\":42802}]", "table": "[{\"end\":41468,\"start\":41194},{\"end\":42564,\"start\":41610},{\"end\":42800,\"start\":42675},{\"end\":43405,\"start\":42981}]", "figure_caption": "[{\"end\":38576,\"start\":38192},{\"end\":38811,\"start\":38579},{\"end\":39429,\"start\":38815},{\"end\":39709,\"start\":39432},{\"end\":40823,\"start\":39723},{\"end\":40883,\"start\":40826},{\"end\":41043,\"start\":40897},{\"end\":41122,\"start\":41046},{\"end\":41183,\"start\":41136},{\"end\":41610,\"start\":41471},{\"end\":42625,\"start\":42577},{\"end\":42675,\"start\":42628},{\"end\":42981,\"start\":42813}]", "figure_ref": "[{\"end\":4176,\"start\":4168},{\"end\":9778,\"start\":9770},{\"end\":11777,\"start\":11769},{\"end\":12782,\"start\":12774},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13075,\"start\":13067},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15062,\"start\":15054},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20091,\"start\":20083},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":28406,\"start\":28398},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":28607,\"start\":28599},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":33498,\"start\":33490}]", "bib_author_first_name": "[{\"end\":43898,\"start\":43897},{\"end\":43900,\"start\":43899},{\"end\":43909,\"start\":43908},{\"end\":43923,\"start\":43922},{\"end\":44125,\"start\":44124},{\"end\":44135,\"start\":44134},{\"end\":44280,\"start\":44279},{\"end\":44282,\"start\":44281},{\"end\":44288,\"start\":44287},{\"end\":44297,\"start\":44296},{\"end\":44299,\"start\":44298},{\"end\":44446,\"start\":44445},{\"end\":44448,\"start\":44447},{\"end\":44461,\"start\":44460},{\"end\":44876,\"start\":44875},{\"end\":44878,\"start\":44877},{\"end\":44892,\"start\":44891},{\"end\":44899,\"start\":44898},{\"end\":44913,\"start\":44912},{\"end\":44915,\"start\":44914},{\"end\":45040,\"start\":45039},{\"end\":45049,\"start\":45048},{\"end\":45060,\"start\":45059},{\"end\":45069,\"start\":45068},{\"end\":45315,\"start\":45314},{\"end\":45323,\"start\":45322},{\"end\":45330,\"start\":45329},{\"end\":45337,\"start\":45336},{\"end\":45727,\"start\":45726},{\"end\":45734,\"start\":45733},{\"end\":45741,\"start\":45740},{\"end\":45952,\"start\":45951},{\"end\":45964,\"start\":45963},{\"end\":45975,\"start\":45974},{\"end\":45983,\"start\":45982},{\"end\":46410,\"start\":46409},{\"end\":46412,\"start\":46411},{\"end\":46423,\"start\":46422},{\"end\":46425,\"start\":46424},{\"end\":46446,\"start\":46445},{\"end\":46457,\"start\":46456},{\"end\":46459,\"start\":46458},{\"end\":46473,\"start\":46472},{\"end\":46895,\"start\":46894},{\"end\":46909,\"start\":46908},{\"end\":46920,\"start\":46919},{\"end\":47166,\"start\":47165},{\"end\":47168,\"start\":47167},{\"end\":47178,\"start\":47177},{\"end\":47180,\"start\":47179},{\"end\":47445,\"start\":47444},{\"end\":47456,\"start\":47455},{\"end\":47730,\"start\":47729},{\"end\":47732,\"start\":47731},{\"end\":47744,\"start\":47743},{\"end\":47757,\"start\":47756},{\"end\":47782,\"start\":47781},{\"end\":47795,\"start\":47794},{\"end\":47805,\"start\":47804},{\"end\":47821,\"start\":47820},{\"end\":47823,\"start\":47822},{\"end\":48088,\"start\":48087},{\"end\":48099,\"start\":48098},{\"end\":48240,\"start\":48239},{\"end\":48371,\"start\":48370},{\"end\":48377,\"start\":48376},{\"end\":48530,\"start\":48529},{\"end\":48536,\"start\":48535},{\"end\":48545,\"start\":48544},{\"end\":48552,\"start\":48551},{\"end\":48729,\"start\":48728},{\"end\":48738,\"start\":48737},{\"end\":48954,\"start\":48953},{\"end\":48963,\"start\":48962},{\"end\":49188,\"start\":49187},{\"end\":49190,\"start\":49189},{\"end\":49198,\"start\":49197},{\"end\":49376,\"start\":49375},{\"end\":49385,\"start\":49384},{\"end\":49395,\"start\":49394},{\"end\":49588,\"start\":49587},{\"end\":49597,\"start\":49596},{\"end\":49607,\"start\":49606},{\"end\":49617,\"start\":49616},{\"end\":49831,\"start\":49830},{\"end\":49837,\"start\":49836},{\"end\":49847,\"start\":49846},{\"end\":49863,\"start\":49862},{\"end\":49865,\"start\":49864},{\"end\":49988,\"start\":49987},{\"end\":49997,\"start\":49996},{\"end\":50009,\"start\":50008},{\"end\":50011,\"start\":50010},{\"end\":50024,\"start\":50023},{\"end\":50333,\"start\":50332},{\"end\":50345,\"start\":50344},{\"end\":50527,\"start\":50526},{\"end\":50538,\"start\":50537},{\"end\":50676,\"start\":50675},{\"end\":50687,\"start\":50686},{\"end\":50696,\"start\":50695},{\"end\":50886,\"start\":50885},{\"end\":50899,\"start\":50898},{\"end\":50910,\"start\":50909},{\"end\":50912,\"start\":50911},{\"end\":50922,\"start\":50921},{\"end\":50936,\"start\":50935},{\"end\":50953,\"start\":50952},{\"end\":50955,\"start\":50954},{\"end\":51223,\"start\":51222},{\"end\":51225,\"start\":51224},{\"end\":51231,\"start\":51230},{\"end\":51237,\"start\":51236},{\"end\":51248,\"start\":51247},{\"end\":51255,\"start\":51254},{\"end\":51262,\"start\":51261},{\"end\":51264,\"start\":51263},{\"end\":51476,\"start\":51475},{\"end\":51478,\"start\":51477},{\"end\":51486,\"start\":51485},{\"end\":51792,\"start\":51791},{\"end\":51801,\"start\":51800},{\"end\":51812,\"start\":51811},{\"end\":52102,\"start\":52101},{\"end\":52104,\"start\":52103},{\"end\":52112,\"start\":52111},{\"end\":52114,\"start\":52113},{\"end\":52128,\"start\":52127},{\"end\":52339,\"start\":52338},{\"end\":52352,\"start\":52351},{\"end\":52360,\"start\":52359},{\"end\":52362,\"start\":52361},{\"end\":52370,\"start\":52369},{\"end\":52386,\"start\":52385},{\"end\":52619,\"start\":52618},{\"end\":52635,\"start\":52634},{\"end\":52649,\"start\":52648},{\"end\":52651,\"start\":52650},{\"end\":52666,\"start\":52665},{\"end\":52678,\"start\":52677},{\"end\":52680,\"start\":52679},{\"end\":52972,\"start\":52971},{\"end\":52974,\"start\":52973},{\"end\":52984,\"start\":52983},{\"end\":52986,\"start\":52985},{\"end\":52996,\"start\":52995},{\"end\":53253,\"start\":53252},{\"end\":53255,\"start\":53254},{\"end\":53267,\"start\":53266},{\"end\":53528,\"start\":53527},{\"end\":53534,\"start\":53533},{\"end\":53542,\"start\":53541},{\"end\":53557,\"start\":53556},{\"end\":53799,\"start\":53798},{\"end\":53807,\"start\":53806},{\"end\":53809,\"start\":53808},{\"end\":53819,\"start\":53818},{\"end\":54130,\"start\":54129},{\"end\":54136,\"start\":54135},{\"end\":54144,\"start\":54143},{\"end\":54154,\"start\":54153},{\"end\":54162,\"start\":54161},{\"end\":54342,\"start\":54341},{\"end\":54354,\"start\":54353},{\"end\":54358,\"start\":54355}]", "bib_author_last_name": "[{\"end\":43906,\"start\":43901},{\"end\":43920,\"start\":43910},{\"end\":43928,\"start\":43924},{\"end\":44132,\"start\":44126},{\"end\":44143,\"start\":44136},{\"end\":44285,\"start\":44283},{\"end\":44294,\"start\":44289},{\"end\":44306,\"start\":44300},{\"end\":44458,\"start\":44449},{\"end\":44469,\"start\":44462},{\"end\":44889,\"start\":44879},{\"end\":44896,\"start\":44893},{\"end\":44910,\"start\":44900},{\"end\":44920,\"start\":44916},{\"end\":45046,\"start\":45041},{\"end\":45057,\"start\":45050},{\"end\":45066,\"start\":45061},{\"end\":45075,\"start\":45070},{\"end\":45320,\"start\":45316},{\"end\":45327,\"start\":45324},{\"end\":45334,\"start\":45331},{\"end\":45342,\"start\":45338},{\"end\":45731,\"start\":45728},{\"end\":45738,\"start\":45735},{\"end\":45746,\"start\":45742},{\"end\":45961,\"start\":45953},{\"end\":45972,\"start\":45965},{\"end\":45980,\"start\":45976},{\"end\":45993,\"start\":45984},{\"end\":46420,\"start\":46413},{\"end\":46443,\"start\":46426},{\"end\":46454,\"start\":46447},{\"end\":46470,\"start\":46460},{\"end\":46480,\"start\":46474},{\"end\":46906,\"start\":46896},{\"end\":46917,\"start\":46910},{\"end\":46934,\"start\":46921},{\"end\":47175,\"start\":47169},{\"end\":47185,\"start\":47181},{\"end\":47453,\"start\":47446},{\"end\":47462,\"start\":47457},{\"end\":47741,\"start\":47733},{\"end\":47754,\"start\":47745},{\"end\":47779,\"start\":47758},{\"end\":47792,\"start\":47783},{\"end\":47802,\"start\":47796},{\"end\":47818,\"start\":47806},{\"end\":47829,\"start\":47824},{\"end\":48096,\"start\":48089},{\"end\":48103,\"start\":48100},{\"end\":48247,\"start\":48241},{\"end\":48374,\"start\":48372},{\"end\":48381,\"start\":48378},{\"end\":48533,\"start\":48531},{\"end\":48542,\"start\":48537},{\"end\":48549,\"start\":48546},{\"end\":48556,\"start\":48553},{\"end\":48735,\"start\":48730},{\"end\":48742,\"start\":48739},{\"end\":48960,\"start\":48955},{\"end\":48971,\"start\":48964},{\"end\":49195,\"start\":49191},{\"end\":49206,\"start\":49199},{\"end\":49382,\"start\":49377},{\"end\":49392,\"start\":49386},{\"end\":49402,\"start\":49396},{\"end\":49594,\"start\":49589},{\"end\":49604,\"start\":49598},{\"end\":49614,\"start\":49608},{\"end\":49625,\"start\":49618},{\"end\":49834,\"start\":49832},{\"end\":49844,\"start\":49838},{\"end\":49860,\"start\":49848},{\"end\":49871,\"start\":49866},{\"end\":49994,\"start\":49989},{\"end\":50006,\"start\":49998},{\"end\":50021,\"start\":50012},{\"end\":50038,\"start\":50025},{\"end\":50342,\"start\":50334},{\"end\":50353,\"start\":50346},{\"end\":50535,\"start\":50528},{\"end\":50544,\"start\":50539},{\"end\":50684,\"start\":50677},{\"end\":50693,\"start\":50688},{\"end\":50704,\"start\":50697},{\"end\":50896,\"start\":50887},{\"end\":50907,\"start\":50900},{\"end\":50919,\"start\":50913},{\"end\":50933,\"start\":50923},{\"end\":50950,\"start\":50937},{\"end\":50963,\"start\":50956},{\"end\":51228,\"start\":51226},{\"end\":51234,\"start\":51232},{\"end\":51245,\"start\":51238},{\"end\":51252,\"start\":51249},{\"end\":51259,\"start\":51256},{\"end\":51271,\"start\":51265},{\"end\":51483,\"start\":51479},{\"end\":51494,\"start\":51487},{\"end\":51798,\"start\":51793},{\"end\":51809,\"start\":51802},{\"end\":51819,\"start\":51813},{\"end\":52109,\"start\":52105},{\"end\":52125,\"start\":52115},{\"end\":52136,\"start\":52129},{\"end\":52349,\"start\":52340},{\"end\":52357,\"start\":52353},{\"end\":52367,\"start\":52363},{\"end\":52383,\"start\":52371},{\"end\":52397,\"start\":52387},{\"end\":52632,\"start\":52620},{\"end\":52646,\"start\":52636},{\"end\":52663,\"start\":52652},{\"end\":52675,\"start\":52667},{\"end\":52690,\"start\":52681},{\"end\":52981,\"start\":52975},{\"end\":52993,\"start\":52987},{\"end\":53010,\"start\":52997},{\"end\":53264,\"start\":53256},{\"end\":53278,\"start\":53268},{\"end\":53531,\"start\":53529},{\"end\":53539,\"start\":53535},{\"end\":53554,\"start\":53543},{\"end\":53804,\"start\":53800},{\"end\":53816,\"start\":53810},{\"end\":53827,\"start\":53820},{\"end\":54133,\"start\":54131},{\"end\":54141,\"start\":54137},{\"end\":54151,\"start\":54145},{\"end\":54159,\"start\":54155},{\"end\":54167,\"start\":54163},{\"end\":54351,\"start\":54343},{\"end\":54371,\"start\":54359}]", "bib_entry": "[{\"attributes\":{\"doi\":\"abs/1604.03351\",\"id\":\"b0\"},\"end\":44081,\"start\":43839},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":15483870},\"end\":44250,\"start\":44083},{\"attributes\":{\"doi\":\"abs/1607.06450\",\"id\":\"b2\"},\"end\":44410,\"start\":44252},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":1550330},\"end\":44848,\"start\":44412},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2097418},\"end\":45035,\"start\":44850},{\"attributes\":{\"doi\":\"abs/1312.6203\",\"id\":\"b5\"},\"end\":45233,\"start\":45037},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":15308333},\"end\":45651,\"start\":45235},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":2708270},\"end\":45879,\"start\":45653},{\"attributes\":{\"id\":\"b8\"},\"end\":46253,\"start\":45881},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":19990980},\"end\":46812,\"start\":46255},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3016223},\"end\":47093,\"start\":46814},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":5719990},\"end\":47375,\"start\":47095},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":10743012},\"end\":47657,\"start\":47377},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1690180},\"end\":48043,\"start\":47659},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3251509},\"end\":48192,\"start\":48045},{\"attributes\":{\"id\":\"b15\"},\"end\":48312,\"start\":48194},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":2141952},\"end\":48481,\"start\":48314},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":206594692},\"end\":48666,\"start\":48483},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":2884555},\"end\":48857,\"start\":48668},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":5808102},\"end\":49119,\"start\":48859},{\"attributes\":{\"doi\":\"abs/1609.02907\",\"id\":\"b20\"},\"end\":49358,\"start\":49121},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1779661},\"end\":49504,\"start\":49360},{\"attributes\":{\"id\":\"b22\"},\"end\":49790,\"start\":49506},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":8393918},\"end\":49985,\"start\":49792},{\"attributes\":{\"id\":\"b24\"},\"end\":50254,\"start\":49987},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":14620252},\"end\":50495,\"start\":50256},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":2780493},\"end\":50622,\"start\":50497},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":1430801},\"end\":50832,\"start\":50624},{\"attributes\":{\"doi\":\"abs/1408.5781\",\"id\":\"b28\"},\"end\":51151,\"start\":50834},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1009127},\"end\":51434,\"start\":51153},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":206849822},\"end\":51737,\"start\":51436},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":1953992},\"end\":52013,\"start\":51739},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":17272965},\"end\":52304,\"start\":52015},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":206756462},\"end\":52583,\"start\":52306},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":1797579},\"end\":52919,\"start\":52585},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":842003},\"end\":53203,\"start\":52921},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":8001711},\"end\":53442,\"start\":53205},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":2407217},\"end\":53712,\"start\":53444},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":2596211},\"end\":54055,\"start\":53714},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":31088232},\"end\":54319,\"start\":54057},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":207227372},\"end\":54465,\"start\":54321}]", "bib_title": "[{\"end\":44122,\"start\":44083},{\"end\":44443,\"start\":44412},{\"end\":44873,\"start\":44850},{\"end\":45312,\"start\":45235},{\"end\":45724,\"start\":45653},{\"end\":45949,\"start\":45881},{\"end\":46407,\"start\":46255},{\"end\":46892,\"start\":46814},{\"end\":47163,\"start\":47095},{\"end\":47442,\"start\":47377},{\"end\":47727,\"start\":47659},{\"end\":48085,\"start\":48045},{\"end\":48368,\"start\":48314},{\"end\":48527,\"start\":48483},{\"end\":48726,\"start\":48668},{\"end\":48951,\"start\":48859},{\"end\":49373,\"start\":49360},{\"end\":49828,\"start\":49792},{\"end\":50330,\"start\":50256},{\"end\":50524,\"start\":50497},{\"end\":50673,\"start\":50624},{\"end\":51220,\"start\":51153},{\"end\":51473,\"start\":51436},{\"end\":51789,\"start\":51739},{\"end\":52099,\"start\":52015},{\"end\":52336,\"start\":52306},{\"end\":52616,\"start\":52585},{\"end\":52969,\"start\":52921},{\"end\":53250,\"start\":53205},{\"end\":53525,\"start\":53444},{\"end\":53796,\"start\":53714},{\"end\":54127,\"start\":54057},{\"end\":54339,\"start\":54321}]", "bib_author": "[{\"end\":43908,\"start\":43897},{\"end\":43922,\"start\":43908},{\"end\":43930,\"start\":43922},{\"end\":44134,\"start\":44124},{\"end\":44145,\"start\":44134},{\"end\":44287,\"start\":44279},{\"end\":44296,\"start\":44287},{\"end\":44308,\"start\":44296},{\"end\":44460,\"start\":44445},{\"end\":44471,\"start\":44460},{\"end\":44891,\"start\":44875},{\"end\":44898,\"start\":44891},{\"end\":44912,\"start\":44898},{\"end\":44922,\"start\":44912},{\"end\":45048,\"start\":45039},{\"end\":45059,\"start\":45048},{\"end\":45068,\"start\":45059},{\"end\":45077,\"start\":45068},{\"end\":45322,\"start\":45314},{\"end\":45329,\"start\":45322},{\"end\":45336,\"start\":45329},{\"end\":45344,\"start\":45336},{\"end\":45733,\"start\":45726},{\"end\":45740,\"start\":45733},{\"end\":45748,\"start\":45740},{\"end\":45963,\"start\":45951},{\"end\":45974,\"start\":45963},{\"end\":45982,\"start\":45974},{\"end\":45995,\"start\":45982},{\"end\":46422,\"start\":46409},{\"end\":46445,\"start\":46422},{\"end\":46456,\"start\":46445},{\"end\":46472,\"start\":46456},{\"end\":46482,\"start\":46472},{\"end\":46908,\"start\":46894},{\"end\":46919,\"start\":46908},{\"end\":46936,\"start\":46919},{\"end\":47177,\"start\":47165},{\"end\":47187,\"start\":47177},{\"end\":47455,\"start\":47444},{\"end\":47464,\"start\":47455},{\"end\":47743,\"start\":47729},{\"end\":47756,\"start\":47743},{\"end\":47781,\"start\":47756},{\"end\":47794,\"start\":47781},{\"end\":47804,\"start\":47794},{\"end\":47820,\"start\":47804},{\"end\":47831,\"start\":47820},{\"end\":48098,\"start\":48087},{\"end\":48105,\"start\":48098},{\"end\":48249,\"start\":48239},{\"end\":48376,\"start\":48370},{\"end\":48383,\"start\":48376},{\"end\":48535,\"start\":48529},{\"end\":48544,\"start\":48535},{\"end\":48551,\"start\":48544},{\"end\":48558,\"start\":48551},{\"end\":48737,\"start\":48728},{\"end\":48744,\"start\":48737},{\"end\":48962,\"start\":48953},{\"end\":48973,\"start\":48962},{\"end\":49197,\"start\":49187},{\"end\":49208,\"start\":49197},{\"end\":49384,\"start\":49375},{\"end\":49394,\"start\":49384},{\"end\":49404,\"start\":49394},{\"end\":49596,\"start\":49587},{\"end\":49606,\"start\":49596},{\"end\":49616,\"start\":49606},{\"end\":49627,\"start\":49616},{\"end\":49836,\"start\":49830},{\"end\":49846,\"start\":49836},{\"end\":49862,\"start\":49846},{\"end\":49873,\"start\":49862},{\"end\":49996,\"start\":49987},{\"end\":50008,\"start\":49996},{\"end\":50023,\"start\":50008},{\"end\":50040,\"start\":50023},{\"end\":50344,\"start\":50332},{\"end\":50355,\"start\":50344},{\"end\":50537,\"start\":50526},{\"end\":50546,\"start\":50537},{\"end\":50686,\"start\":50675},{\"end\":50695,\"start\":50686},{\"end\":50706,\"start\":50695},{\"end\":50898,\"start\":50885},{\"end\":50909,\"start\":50898},{\"end\":50921,\"start\":50909},{\"end\":50935,\"start\":50921},{\"end\":50952,\"start\":50935},{\"end\":50965,\"start\":50952},{\"end\":51230,\"start\":51222},{\"end\":51236,\"start\":51230},{\"end\":51247,\"start\":51236},{\"end\":51254,\"start\":51247},{\"end\":51261,\"start\":51254},{\"end\":51273,\"start\":51261},{\"end\":51485,\"start\":51475},{\"end\":51496,\"start\":51485},{\"end\":51800,\"start\":51791},{\"end\":51811,\"start\":51800},{\"end\":51821,\"start\":51811},{\"end\":52111,\"start\":52101},{\"end\":52127,\"start\":52111},{\"end\":52138,\"start\":52127},{\"end\":52351,\"start\":52338},{\"end\":52359,\"start\":52351},{\"end\":52369,\"start\":52359},{\"end\":52385,\"start\":52369},{\"end\":52399,\"start\":52385},{\"end\":52634,\"start\":52618},{\"end\":52648,\"start\":52634},{\"end\":52665,\"start\":52648},{\"end\":52677,\"start\":52665},{\"end\":52692,\"start\":52677},{\"end\":52983,\"start\":52971},{\"end\":52995,\"start\":52983},{\"end\":53012,\"start\":52995},{\"end\":53266,\"start\":53252},{\"end\":53280,\"start\":53266},{\"end\":53533,\"start\":53527},{\"end\":53541,\"start\":53533},{\"end\":53556,\"start\":53541},{\"end\":53560,\"start\":53556},{\"end\":53806,\"start\":53798},{\"end\":53818,\"start\":53806},{\"end\":53829,\"start\":53818},{\"end\":54135,\"start\":54129},{\"end\":54143,\"start\":54135},{\"end\":54153,\"start\":54143},{\"end\":54161,\"start\":54153},{\"end\":54169,\"start\":54161},{\"end\":54353,\"start\":54341},{\"end\":54373,\"start\":54353}]", "bib_venue": "[{\"end\":44635,\"start\":44552},{\"end\":45415,\"start\":45398},{\"end\":43895,\"start\":43839},{\"end\":44149,\"start\":44145},{\"end\":44277,\"start\":44252},{\"end\":44550,\"start\":44471},{\"end\":44926,\"start\":44922},{\"end\":45396,\"start\":45344},{\"end\":45752,\"start\":45748},{\"end\":46045,\"start\":45995},{\"end\":46512,\"start\":46482},{\"end\":46940,\"start\":46936},{\"end\":47215,\"start\":47187},{\"end\":47499,\"start\":47464},{\"end\":47835,\"start\":47831},{\"end\":48109,\"start\":48105},{\"end\":48237,\"start\":48194},{\"end\":48387,\"start\":48383},{\"end\":48562,\"start\":48558},{\"end\":48748,\"start\":48744},{\"end\":48977,\"start\":48973},{\"end\":49185,\"start\":49121},{\"end\":49410,\"start\":49404},{\"end\":49585,\"start\":49506},{\"end\":49877,\"start\":49873},{\"end\":50102,\"start\":50040},{\"end\":50359,\"start\":50355},{\"end\":50550,\"start\":50546},{\"end\":50710,\"start\":50706},{\"end\":50883,\"start\":50834},{\"end\":51277,\"start\":51273},{\"end\":51565,\"start\":51496},{\"end\":51861,\"start\":51821},{\"end\":52142,\"start\":52138},{\"end\":52426,\"start\":52399},{\"end\":52728,\"start\":52692},{\"end\":53041,\"start\":53012},{\"end\":53305,\"start\":53280},{\"end\":53564,\"start\":53560},{\"end\":53862,\"start\":53829},{\"end\":54173,\"start\":54169},{\"end\":54379,\"start\":54373}]"}}}, "year": 2023, "month": 12, "day": 17}