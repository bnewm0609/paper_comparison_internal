{"id": 119181611, "updated": "2023-10-01 14:48:40.926", "metadata": {"title": "BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer", "authors": "[{\"first\":\"Fei\",\"last\":\"Sun\",\"middle\":[]},{\"first\":\"Jun\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Jian\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Changhua\",\"last\":\"Pei\",\"middle\":[]},{\"first\":\"Xiao\",\"last\":\"Lin\",\"middle\":[]},{\"first\":\"Wenwu\",\"last\":\"Ou\",\"middle\":[]},{\"first\":\"Peng\",\"last\":\"Jiang\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 28th ACM International Conference on Information and Knowledge Management", "publication_date": {"year": 2019, "month": 4, "day": 14}, "abstract": "Modeling users' dynamic and evolving preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks (e.g., Recurrent Neural Network) to encode users' historical interactions from left to right into hidden representations for making recommendations. Although these methods achieve satisfactory results, they often assume a rigidly ordered sequence which is not always practical. We argue that such left-to-right unidirectional architectures restrict the power of the historical sequence representations. For this purpose, we introduce a Bidirectional Encoder Representations from Transformers for sequential Recommendation (BERT4Rec). However, jointly conditioning on both left and right context in deep bidirectional model would make the training become trivial since each item can indirectly ``see the target item''. To address this problem, we train the bidirectional model using the Cloze task, predicting the masked items in the sequence by jointly conditioning on their left and right context. Comparing with predicting the next item at each position in a sequence, the Cloze task can produce more samples to train a more powerful bidirectional model. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1904.06690", "mag": "2984100107", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cikm/SunLWPLOJ19", "doi": "10.1145/3357384.3357895"}}, "content": {"source": {"pdf_hash": "eb14da36c668b58a76a2cb83f41e1225e94321ee", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1904.06690v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "28c2d2b155a11db00167ca43db461956aa77fa3c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/eb14da36c668b58a76a2cb83f41e1225e94321ee.txt", "contents": "\nBERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer\n\n\nFei Sun \nAlibaba Group\nBeijingChina\n\nJun Liu \nAlibaba Group\nBeijingChina\n\nJian Wu \nAlibaba Group\nBeijingChina\n\nChanghua Pei changhua.pch@alibaba-inc.com \nAlibaba Group\nBeijingChina\n\nXiao Lin \nAlibaba Group\nBeijingChina\n\nWenwu Ou \nAlibaba Group\nBeijingChina\n\nPeng Jiang jiangpeng.jp@alibaba-inc.com \nAlibaba Group\nBeijingChina\n\nFei Sun \nAlibaba Group\nBeijingChina\n\nJun Liu \nAlibaba Group\nBeijingChina\n\nJian Wu \nAlibaba Group\nBeijingChina\n\nChanghua Pei \nAlibaba Group\nBeijingChina\n\nXiao Lin \nAlibaba Group\nBeijingChina\n\nWenwu Ou \nAlibaba Group\nBeijingChina\n\nPeng Jiang \nAlibaba Group\nBeijingChina\n\nBERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer\nACM Reference Format:. 2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. In Proceedings of ACM Wood-stock (WOODSTOCK'19). ACM, New York, NY, USA, Article 4, 11 pages.Sequential RecommendationBidirectional Sequential ModelCloze\nModeling users' dynamic and evolving preferences from their historical behaviors is challenging and crucial for recommendation systems. Previous methods employ sequential neural networks (e.g., Recurrent Neural Network) to encode users' historical interactions from left to right into hidden representations for making recommendations. Although these methods achieve satisfactory results, they often assume a rigidly ordered sequence which is not always practical. We argue that such left-to-right unidirectional architectures restrict the power of the historical sequence representations. For this purpose, we introduce a Bidirectional Encoder Representations from Transformers for sequential Recommendation (BERT4Rec). However, jointly conditioning on both left and right context in deep bidirectional model would make the training become trivial since each item can indirectly \"see the target item\". To address this problem, we train the bidirectional model using the Cloze task, predicting the masked items in the sequence jointly conditioning on their left and right context. Comparing with predicting the next item at each position in a sequence, the Cloze task can produce more samples to train a more powerful bidirectional model. Extensive experiments on four benchmark datasets show that our model outperforms various state-of-the-art sequential models consistently.CCS CONCEPTS\u2022 Information systems \u2192 Recommender systems.\n\nINTRODUCTION\n\nAccurately characterizing users' interests lives at the heart of an effective recommendation system. However, in many real-world applications, users' current interests are intrinsically dynamic and evolving, influenced by their historical behaviors. For example, Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s).  one may purchase accessories (e.g., Joy-Con controllers) soon after buying a Nintendo Switch, though she/he will not buy console accessories under normal circumstances.\n\nTo model such sequential dynamics in user behaviors, various methods have been proposed to make sequential recommendations based on user historical interactions [15,22,40]. They aim to predict the successive item(s) that a user is likely to interact with given her/his past interactions.\n\nEarly works usually adopt Markov chains (MCs) to model users' behavior sequences for predicting their next behaviors [11,40,45]. Such methods usually make a strong simplified assumption, combining previous items independently which often hurts the recommendation accuracy [49]. Recently, a surge of works employ sequential neural networks, e.g., Recurrent Neural Network (RNN), for sequential recommendation and obtain promising results [7,14,15,56,58]. The basic paradigm of previous work is to encode a user's historical interactions into a vector (i.e., representation of user's preference) using a left-to-right sequential model and make recommendations base on this hidden representation.\n\nIn this paper, we argue that such left-to-right unidirectional architectures restrict the power of the historical sequence representations. Both MCs and RNN based models are originally introduced for sequential data with a natural order, e.g., text and time series data. They often assume a rigidly ordered sequence over data which is not always true for user behaviors in real-world applications. The choices of items in a user's historical interactions may not follow a rigid order assumption [18,54]. For example in Figure 1, the order in which three lipsticks (B, C, and D) are clicked makes no difference for recommendation systems. Moreover, user behaviors on websites like YouTube or Amazon are often noisy due to a variety of unobservable external factors [5]. Thus, we argue that bidirectional model is a more reasonable choice for modeling user behavior sequences. Furthermore, even on data with rigid order like text, deep bidirectional self-attention model BERT [6] has significantly outperformed other state-of-the-art unidirectional models (e.g., OpenAI GPT [38]) on eleven tasks of General Language Understanding Evaluation (GLUE) benchmark 1 .\n\nInspired by the success of BERT in language understanding, we seek to apply the deep bidirectional self-attention model for sequential recommendation. However, it is not straightforward and intuitive to apply the bidirectional model for sequential recommendation. As shown in Figure 2, jointly conditioning on both left and right context in deep bidirectional model would cause information leakage, i.e., allowing each item to indirectly \"see the target item\". This could make predicting the future become trivial and the network would not learn anything useful. To address this problem, we introduce the Cloze task [50] to take the place of the objective in unidirectional models (i.e., sequentially predicting the next item). Specifically, we randomly mask some items in the input sequences, and then predict only those masked items based on their surrounding context. In this way, we learn a bidirectional model by allowing the representations of each position in the input sequence to fuse their left and right context. In addition to training a bidirectional model, another advantage of the Cloze objective is that it can produce more samples to train a more powerful model. However, a downside of the Cloze objective is that it creates a mismatch between the training and the final task (i.e., sequential recommendation). To fix this, we append a special token ([mask]) at the end of the input sequence to indicate the item that we need to predict during test, and then make recommendations base on its final hidden vector. Extensive experiments on four datasets show that our model outperforms various state-of-the-art baselines consistently.\n\nThe contributions of our paper are as follows:\n\n\u2022 We propose to model user behavior sequences with bidirectional self-attention network through Cloze task. To the best of our knowledge, this is the first study to introduce deep bidirectional sequential model and Cloze objective into the field of recommendation systems. \u2022 We compare our model with state-of-the-art methods and demonstrate the effectiveness of both bidirectional architecture and the Cloze objective through quantitative analysis on four benchmark datasets. \u2022 We conduct a comprehensive ablation study to analyze the contribution of key components in the proposed model.\n\n\nRELATED WORK\n\nIn this section, we will briefly review several line of works closely related to ours, including general recommendation, sequential recommendation, and attention mechanism.\n\n\nGeneral Recommendation\n\nEarly works on recommendation systems typically use Collaborative Filtering (CF) to model users' preferences based on their interaction histories [26,43]. Among various CF methods, Matrix Factorization (MF) is the most popular one, which projects users and items into a shared vector space and estimate a user's preference on an item by the inner product between their vectors [26,27,41]. Another line of work is item-based neighborhood methods [20,25,31,43]. They estimate a user's preference on an 1 https://gluebenchmark.com item via measuring its similarities with the items in her/his interaction history using a precomputed item-to-item similarity matrix. Recently, deep learning has been revolutionizing the recommendation systems dramatically. The early pioneer work is a two-layer Restricted Boltzmann Machines (RBM) for collaborative filtering, proposed by Salakhutdinov et al. [42] in Netflix Prize 2 .\n\nOne line of deep learning based recommendation algorithms seeks to use neural networks to learn distributed item representations from auxiliary information, e.g., text [23,53], images [21,55], and acoustic features [51]. These representations are then integrated with CF models to improve the recommendation performance. Another line of work seeks to take the place of conventional matrix factorization. For example, Neural Collaborative Filtering (NCF) [12] estimates user preferences via Multi-Layer Perceptions (MLP) instead of inner product, while AutoRec [44] and CDAE [57] predict users' ratings using Auto-encoder framework.\n\n\nSequential Recommendation\n\nUnfortunately, none of above methods is for sequential recommendation since they all ignore the order in users' behaviors.\n\nEarly works on sequential recommendation usually capture sequential patterns from user historical interactions using Markov chains (MCs). For example, Shani et al. [45] formalized recommendation generation as a sequential optimization problem and employ Markov Decision Processes (MDPs) to address it. Later, Rendle et al. [40] combine the power of MCs and MF to model both sequential behaviors and general interests by Factorizing Personalized Markov Chains (FPMC). Besides the first-order MCs, high-order MCs are also adopted to consider more previous items [10,11].\n\nRecently, RNN and its variants, Gated Recurrent Unit (GRU) [4] and Long Short-Term Memory (LSTM) [17], are becoming more and more popular for modeling user behavior sequences [7,14,15,28,37,56,58]. The basic idea of these methods is to encode user's previous records into a vector (i.e., representation of user's preference which is used to make predictions) with various recurrent architectures and loss functions, including session-based GRU with ranking loss (GRU4Rec) [15], Dynamic REcurrent bAsket Model (DREAM) [58], user-based GRU [7], attention-based GRU (NARM) [28], and improved GRU4Rec with new loss function (i.e., BPR-max and TOP1-max) and an improved sampling strategy [14].\n\nOther than recurrent neural networks, various deep learning models are also introduced for sequential recommendation [3,22,33,49]. For example, Tang and Wang [49] propose a Convolutional Sequence Model (Caser) to learn sequential patterns using both horizontal and vertical convolutional filters. Chen et al. [3] and Huang et al. [19] employ Memory Network to improve sequential recommendation. STAMP captures both users' general interests and current interests using a MLP network with attention [33].\n\n\nAttention Mechanism\n\nAttention mechanism has shown promising potential in modeling sequential data, e.g., machine translation [2,52] and sentence representation learning [6]. Recently, some works try to employ the attention mechanism to improve recommendation performances and interpretability [28,33]. For example, Li et al. [28] incorporate an attention mechanism into GRU to capture both the user's sequential behavior and main purpose in session-based recommendation.\n\nThe attention mechanism mentioned in above is basically an additional component to the original models. In contrast, Transformer [52] and BERT [6] model the text sequence relying entirely on multi-head self-attention and achieve state-of-the-art results on tasks like machine translation and sentence classification. Recently, there is a rising enthusiasm for applying purely attention-based neural networks to model sequential data for their effectiveness and efficiency [30,32,38,46]. For sequential recommendation, Kang and McAuley [22] introduce a two-layer Transformer decoder (i.e., Transformer language model) called SASRec to capture user's sequential behaviors and achieve state-of-the-art results on several public datasets. SASRec is closely related to our work. However, it is still a unidirectional model using a casual attention mask. While our proposed model learns to encode users' historical records from both directions with the help of Cloze task.\n\n\nBERT4REC\n\nBefore going into the details of our proposed model, we first introduce the research problem, the basic concepts, and the notations used throughout this paper.\n\n\nProblem Statement\n\nIn sequential recommendation, let U={u 1 , u 2 , . . . , u | U | } denote a set of users, V={v 1 , v 2 , . . . , v | V | } be a set of items, and list\nS u =[v (u) 1 , . . . , v (u) t , . . . , v (u)\nn u ] denote the interaction sequence in chronological order for user u \u2208 U, where v (u) t \u2208 V is the item that u has interacted with at time step 3 t and n u is the the length of interaction sequence for user u. Given the interaction history S u , sequential recommendation aims to predict the item that user u will interact with at time step n u + 1. It can be formalized as modeling the probability:\n\np v (u) n u +1 = v | S u over all possible items for user u at time step n u + 1.\n\n\nModel Architecture\n\nIn this paper, we introduce a new sequential recommendation model called BERT4Rec, which stands for Bidirectional Encoder Representations from Transformers for sequential Recommendation. It is built upon the popular self-attention layer, also referred to as \"Transformer layer\".\n\nAs illustrated in Figure 2b, BERT4Rec is stacked by L bidirectional Transformer layers. At each layer, it iteratively revises the representation of every position by exchanging information across all positions at the previous layer in parallel with the Transformer layer. Instead of learning to pass relevant information forward step by step as RNN based methods did in Figure 2d, self-attention mechanism endows BERT4Rec with the capability to directly capture the dependencies in any distances. This mechanism results in a global receptive field, while CNN based methods like Caser usually have a limited receptive field. In addition, in contrast to RNN based methods, self-attention is straightforward to parallelize.\n\nComparing Figure 2b, 2c, and 2d, the most noticeable difference is that SASRec and RNN based methods are all left-to-right unidirectional architecture, while our BERT4Rec uses bidirectional self-attention to jointly combine both left and right context. In this way, our proposed model can alleviate the limitation of previous methods, a rigid order assumption.\n\n\nTransformer Layer\n\nAs illustrated in Figure 2b, given an input sequence of length t, we iteratively compute hidden representations h l i at each layer l for each position i simultaneously by applying the Transformer layer from [52]. Here, we stack h l i \u2208 R d together into matrix H l \u2208R t \u00d7d since we compute attention function on all positions simultaneously in practice. As shown in Figure 2a, the Transformer layer Trm contains two sub-layers, a Multi-Head Self-Attention sub-layer and a Position-wise Feed-Forward network.\n\nMulti-Head Self-Attention. Attention mechanisms have become an integral part of sequence modeling in a variety of tasks, allowing modeling the dependencies between representation pairs without regard to their distance in the sequences. Previous work has shown that it is beneficial to jointly attend to information from different representation subspaces at different positions [6,29,52]. Thus, we adopt the multi-head self-attention instead of performing a single attention function in this work. Specifically, multi-head attention first linearly projects H l into h subspaces, with different, learnable linear projections, and then apply h attention functions in parallel to produce the output representations which are concatenated and once again projected:\nMH(H l ) = [head 1 ; head 2 ; . . . ; head h ]W O head i = Attention H l W Q i , H l W K i , H l W V i (1)\nwhere the projections matrices for each headW\nQ i \u2208 R d \u00d7d /h ,W K i \u2208 R d \u00d7d /h , W V i \u2208 R d \u00d7d /h , and W O i \u2208 R d \u00d7d are learnable parameters.\nHere, we omit the layer subscript l for the sake of simplicity. In fact, these projection parameters are not shared across the layers. Here, the Attention function is Scaled Dot-Product Attention:\nAttention(Q, K, V ) = softmax QK \u22a4 d/h V(2)\nwhere query Q, key K, and value V are projected from the same matrix H l with different learned projection matrices as in Equation 1.\n\nThe temperature d/h is introduced to produce a softer attention distribution for avoiding extremely small gradients [16,52].\n\nPosition-wise Feed-Forward Network. As described above, the self-attention sub-layer is mainly based on linear projections. To endow the model with nonlinearity and interactions between different dimensions, we apply a Position-wise Feed-Forward Network to the outputs of the self-attention sub-layer, separately and identically at each position. It consists of two affine transformations with a Gaussian Error Linear Unit (GELU) activation in between:\nPFFN(H l ) = FFN(h l 1 ) \u22a4 ; . . . ; FFN(h l t ) \u22a4 \u22a4 FFN(x) = GELU xW (1) + b (1) W (2) + b (2) GELU(x) = x\u03a6(x)(3)\nwhere \u03a6(x) is the cumulative distribution function of the standard gaussian distribution,\nW (1) \u2208 R d \u00d74d , W (2) \u2208 R 4d \u00d7d , b (1) \u2208 R 4d v 1 \u00b7 \u00b7 \u00b7 v t \u22121 v [mask] v 1 \u00b7 \u00b7 \u00b7 [mask] v t \u22121 Trm . . . Trm + Trm . . . Trm + Trm . . . Trm + L\u00d7 p 1 \u00b7 \u00b7 \u00b7 p t \u22121 p t Projection h L 1 h L t \u22121 v t h L t Embedding Layer \u00b7 \u00b7 \u00b7 . . . \u00b7 \u00b7 \u00b7 Multi-Head Attention Dropout Add & Norm Position-wise Feed-Forward Dropout Add & Norm input Trm (b) BERT4Rec model architecture. (a) Transformer Layer. \u00b7 \u00b7 \u00b7 v 1 . . . v t v t \u22121 GRU GRU GRU . . . v 2 . . . v t v t +1 (d) RNN based sequential recommendation methods. Trm Trm Trm Trm Trm Trm v 1 v t \u22121 v t . . . . . . . . . . . . v 2 v t v t +1\n(c) SASRec model architecture. and b (2) \u2208 R d are learnable parameters and shared across all positions. We omit the layer subscript l for convenience. In fact, these parameters are different from layer to layer. In this work, following OpenAI GPT [38] and BERT [6], we use a smoother GELU [13] activation rather than the standard ReLu activation. Stacking Transformer Layer. As elaborated above, we can easily capture item-item interactions across the entire user behavior sequence using self-attention mechanism. Nevertheless, it is usually beneficial to learn more complex item transition patterns by stacking the self-attention layers. However, the network becomes more difficult to train as it goes deeper. Therefore, we employ a residual connection [9] around each of the two sublayers as in Figure 2a, followed by layer normalization [1]. Moreover, we also apply dropout [47] to the output of each sub-layer, before it is normalized. That is, the output of each sub-layer is LN(x + Dropout(sublayer(x))), where sublayer(\u00b7) is the function implemented by the sub-layer itself, LN is the layer normalization function defined as:\nLN(x) = \u03b3 \u2299 x \u2212 \u00b5 \u221a \u03c3 2 + \u03f5 + \u03b2\nwhere \u00b5 and \u03c3 are mean and variance of x correspondingly, \u2299 is element-wise multiplication, \u03b3 is the learnable scale factors, \u03b2 is the bias terms, \u03f5 is a small float number to avoid dividing by 0. We use LN to normalize the inputs over all the hidden units in the same layer for stabilizing and accelerating the network training. In summary, BERT4Rec refines the hidden representations of each layer as follows:\nH l = Trm H l \u22121 , \u2200i \u2208 [1, . . . , L](4)Trm(H l \u22121 ) = LN A l \u22121 + Dropout PFFN(A l \u22121 ) (5) A l \u22121 = LN H l \u22121 + Dropout MH(H l \u22121 )(6)\n\nEmbedding Layer\n\nAs elaborated above, without any recurrence or convolution module, the Transformer layer Trm is not aware of the order of the input sequence. In order to make use of the sequential information of the input, we inject Positional Embeddings into the input item embeddings at the bottoms of the Transformer layer stacks. For a given item v i , its input representation h 0 i is constructed by summing the corresponding item and positional embedding:\nh 0 i = v i + p i where v i \u2208E is the d\u2212dimensional embedding for item v i , p i \u2208P is the d\u2212dimensional positional embedding for position index i.\nIn this work, we use the learnable positional embeddings instead of the fixed sinusoid embeddings in [52] for better performances. The positional embedding matrix P \u2208 R N \u00d7d allows our model to identify which portion of the input it is dealing with but also imposes a restriction on the maximum sentence length N that our model can handle. Thus, we need to truncate the the input sequence\n[v 1 , . . . , v t ] to the last N items [v u t \u2212N +1 , . . . , v t ] if t > N .\n\nOutput Layer\n\nAfter L layers that hierarchically exchange information across all positions in the previous layer, we get the final output H L for all items of the input sequence. Unlike traditional sequential recommendation model predicting the next t + 1 item given the first t items, we predict the masked items v t base on h L t as shown in Figure 2b. Specifically, assuming that we mask the item v t at time step t, we apply a two layer feed-forward network with GELU activation in between to produce an output distribution over target items:\nP(v) = softmax GELU(h L t W P + b P )E \u22a4 + b O(7)\nwhere W P is the learnable projection matrix, b P , and b O are bias terms, E \u2208 R |V |\u00d7d is the embedding matrix for the item set V. We use the shared item embedding matrix in the input and output layer for alleviating overfitting and reducing model size.\n\n\nModel Learning\n\nTraining. Unidirectional models usually train the model by predicting the next item for each position in the input sequence as illustrated in Figure 2c and 2d. Specifically, the target of the input\nsequence [v 1 , . . . , v t ] is a shifted version [v 2 , . . . , v t +1 ]\n. However, as shown in Figure 2b, jointly conditioning on both left and right context in a bidirectional model would cause the final output representation of each item contain the information of the target item. This makes predicting the future become trivial and the network would not learn anything useful.\n\nIn order to train a deep bidirectional sequential model, we introduce a new objective: Cloze task [50] (also known as \"Masked Language Model\" in [6]). It is a test consisting of a portion of language with some words removed, where the participant is asked to fill the missing words. In our case, for each training step, we randomly mask \u03c1 proportion of all items in the input sequence (i.e., replace with special token \"[mask]\"), and then predict the original ids of the masked items based solely on its left and right context. For example:\nInput: [v 1 , v 2 , v 3 , v 4 , v 5 ] [v 1 , [mask] 1 , v 3 , [mask] 2 , v 5 ] Labels: [mask] 1 = v 2 , [mask] 2 = v 4 randomly mask\nThe final hidden vectors corresponding to \"[mask]\" are fed into an output softmax over the item set, as in conventional sequential recommendation. Eventually, we define the loss for each masked input S \u2032 u as the negative log likelihood of the masked targets:\nL = 1 |S m u | v m \u2208S m u \u2212 log P(v m = v * m |S \u2032 u )(8)\nwhere S \u2032 u is the masked version for user behavior history S u , S m u is the random masked items in it, v * m is the true item for the masked item v m , and the probability P(\u00b7) is defined in Equation 7.\n\nAn additional advantage for Cloze task is that it can generate more samples to train the model. Assuming a sequence of length n, conventional sequential predictions in Figure 2c and 2d produce n unique samples for training, while our BERT4Rec can obtain n k samples (if we randomly mask k items). This allows us to learn a more powerful bidirectional representation model.\n\nTest. As described above, we create a mismatch between the training and the final sequential recommendation task since the Cloze objective is to predict the current masked items while sequential recommendation aims to predict the future. To address this, we append the special token \"[mask]\" to the end of user's behavior sequence, and then predict the next item based on the final hidden representation of this token. To better match the sequential recommendation task (i.e., predict the last item), we also produce samples that only mask the last item in the input sequences during training. It works like fine-tuning for sequential recommendation and can further improve the recommendation performances.\n\n\nDiscussion\n\nHere, we discuss the relation of our model with previous related work.\n\nSASRec. Obviously, SASRec is a left-to-right unidirectional version of our BERT4Rec with a single head attention and causal attention mask. Different architectures lead to different training methods. SASRec predicts the next item for each position in a sequence, while BERT4Rec predicts the masked positions in the sequence. CBOW. Another very similar work is Continuous Bag-of-Words (CBOW) model [35]. CBOW predicts a target word using the average of all the word vectors in its context (both left and right). It can be seen as a simplified case of BERT4Rec, if we replace the L-layer Transformer layer in BERT4Rec with uniform attention weights on items, use unshared item embeddings, remove the positional embedding, and only mask the central item. CBOW uses a simple aggregator to model word sequences since its goal is to learn good word representations, not sentence representations. On the contrary, we use a deep self-attention architecture to model the context since our goal is to learn a powerful sequence representation model for making recommendations.\n\nSG. Similar to CBOW, Skip-Gram (SG) [36] can also be seen as a simplified case of BERT4Rec following the similar reduction operations. The difference is that we mask all items except only one for SG. From this point of view, Cloze is a general form for the objective of CBOW and SG.\n\n\nEXPERIMENTS\n\nIn this section, we first introduce our experimental setup, then report and analyze the experimental results.\n\n\nDatasets\n\nWe evaluate the proposed model on four real-world representative datasets which vary significantly in domains and sparsity.\n\n\u2022 Amazon Beauty 4 : This is a series of product review datasets crawled from Amazon.com by McAuley et al. [34]. They split the data into separate datasets according to the toplevel product categories on Amazon. In this work, we adopt the \"Beauty\" category. \u2022 Steam 5 : This is a dataset collected from Steam, a large online video game distribution platform, by Kang and McAuley [22]. \u2022 MovieLens [8]: This is a popular benchmark dataset for evaluating recommendation algorithms. In this work, we adopt two well-established versions, MovieLens 1m (ML-1m) 6 and MovieLens 20m (ML-20m) 7 .\n\nFor dataset preprocessing, we follow the common practice from [22,40,49]. For all datasets, we convert all numeric ratings or the presence of a review to implicit feedback of 1 (i.e., the user interacted with the item). After that, we group the interaction records by users, and build the interaction sequence for each user by sorting these interaction records according to the timestamps. Following the common practice [12,22,40,49], we also discard cold-start users with less than 5 feedbacks, as dealing with coldstart recommendation is not the goal of this work. The statistics of the processed datasets are summarized in Table 1.\n\n\nTask Settings & Evaluation Metrics\n\nTo evaluate the performance of the sequential recommendation models, we adopted the leave-one-out evaluation (i.e., next item recommendation) task, which has been widely used in literature [12,22,49]. Specifically, given an interaction sequence\nS u = [v (u) 1 , . . . , v (u) n u ]\nfor user u, we use item v u n u for test, v u n u \u22121 for hyper-parameter tuning, and [v (u)\n1 , . . . , v (u)\nn u \u22122 ] for training. Note that, during testing, we use the first n u \u2212 1 items (i.e., including validation set) to predict the last item v u n u in the test set. For easy and fair evaluation, we follow the common strategy in [12,22,49], pairing each ground truth item in the test set with 100 randomly sampled negative items that the user has not interacted with. To make the sampling reliable and representative, these 100 negative items are sampled according to their popularity. Hence, the task becomes to rank these negative items with the ground truth item for each user.\n\nEvaluation Metrics. To evaluate the ranking list of all the models, we employ a variety of evaluation metrics, including Hit Ratio (HR), Normalized Discounted Cumulative Gain (NDCG), and Mean Reciprocal Rank (MRR).\n\nHR@k measures the proportion of cases that the desired item is among the top-k items in all test cases. It is computed as:\nHR@k = 1 |U| u \u2208U 1(R u,\u0434 u \u2264 k)\nwhere, \u0434 u is the ground truth item for user u, R u,\u0434 u is the rank generated by the model for item \u0434 u and user u, and 1 is an indicator function. HR@k does not consider the actual rank of \u0434 u as long as it is among the top-k.\n\nNDCG@k is a position-aware metric which assigns larger weights on higher ranks. For next item recommendation, it is calculated as :\nNDCG@k = 1 |U| u \u2208U 2 1(R u,\u0434u \u2264k ) \u2212 1 log 2 (R u,\u0434 u + 1)\nMRR is the average of reciprocal ranks of the ground truth R u,\u0434 u :\nMRR = 1 |U| u \u2208U 1 R u,\u0434 u\nConsidering we only have one ground truth item for each user, HR@k is equivalent to Recall@k and proportional to Precision@k; MRR is equivalent to Mean Average Precision (MAP). In this work, we report HR and NDCG with k = 1, 5, 10. For all these metrics, the higher the value, the better the performance.\n\n\nBaselines & Implementation Details\n\nTo verify the effectiveness of our method, we compare it with the following representative baselines:\n\n\u2022 POP: It is the simplest baseline that ranks items according to their popularity judged by the number of interactions. \u2022 BPR-MF [39]: It optimizes the matrix factorization with implicit feedback using a pairwise ranking loss. \u2022 NCF [12]: It models user\u00e2\u0102\u015eitem interactions with a MLP instead of the inner product in matrix factorization.\n\n\u2022 FPMC [40]: It captures users' general taste as well as their sequential behaviors by combing MF with first-order MCs. \u2022 GRU4Rec [15]: It uses GRU with ranking based loss to model user sequences for session based recommendation. \u2022 GRU4Rec + [14]: It is an improved version of GRU4Rec with a new class of loss functions and sampling strategy. \u2022 Caser [49]: It employs CNN in both horizontal and vertical way to model high-order MCs for sequential recommendation. \u2022 SASRec [22]: It uses a left-to-right Transformer language model to capture users' sequential behaviors, and achieves state-of-the-art performance on sequential recommendation.\n\nFor NCF 8 , GRU4Rec 9 , GRU4Rec +9 , Caser 10 , and SASRec 11 , we use code provided by the corresponding authors. For BPR-MF and FPMC, we implement them using TensorFlow. For common hyperparameters in all models, we consider the hidden dimension size d from {16, 32, 64, 128, 256}, the \u2113 2 regularizer from {1, 0.1, 0.01, 0.001, 0.0001}, and dropout rate from {0, 0.1, 0.2, \u00b7 \u00b7 \u00b7 , 0.9}. All other hyper-parameters (e.g., Markov order in Caser) and initialization strategies are either followed the suggestion from the methods' authors or tuned on the validation sets. We report the results of each baseline under its optimal hyper-parameter settings.\n\nWe implement BERT4Rec 12 with TensorFlow 13 . All parameters are initialized using truncated normal distribution in the range [\u22120.02, 0.02]. We train the model using Adam [24] with learning rate of 1e-4, \u03b2 1 = 0.9, \u03b2 2 = 0.999, \u2113 2 weight decay of 0.01, and linear decay of the learning rate. The gradient is clipped when its \u2113 2 norm exceeds a threshold of 5. For fair comparison, we set the layer number L = 2 and head number h = 2 and use the same maximum sequence length as in [22], N = 200 for ML-1m and ML-20m, N = 50 for Beauty and Steam datasets. For head setting, we empirically set the dimensionality of each head as 32 (single head if d < 32). We tune the mask proportion \u03c1 using the validation set, resulting in \u03c1 = 0.6 for Beauty, \u03c1 = 0.4 for Steam, and \u03c1 = 0.2 for ML-1m and ML-20m. All the models are trained from scratch without any pre-training on a single NVIDIA GeForce GTX 1080 Ti GPU with a batch size of 256. The effects of hyper-parameters on the final performances are examined below. Table 2 summarized the best results of all baselines and our model on four benchmark datasets. The last column is the improvements of BERT4Rec relative to the best baseline. We omit the NDCG@1 results since it is equal to HR@1 in our experiments. It can be observed that:\n\n\nOverall Performance Comparison\n\nThe non-personalized POP method gives the worst performance on all datasets since it does not model user's personalized preference using the historical records. Among all the baseline methods, sequential methods (e.g., FPMC and GRU4Rec + ) outperforms non-sequential methods (e.g., BPR-MF and NCF) on all datasets consistently. Compared with BPR-MF, the main improvement of FPMC is that it models users' historical records in a sequential way. This observation verifies that considering sequential information is beneficial for improving performances in recommendation systems. Among sequential recommendation baselines, Caser outperforms FPMC on all datasets especially for the dense dataset ML-1m, suggesting that high-order MCs is beneficial for sequential recommendation. However, high-order MCs usually use very small order L since they do not scale well with the order L. This causes Caser to perform worse than GRU4Rec + and SASRec, especially on sparse datasets. Furthermore, SASRec performs distinctly better than GRU4Rec and GRU4Rec + , suggesting that self-attention mechanism is a more powerful tool for sequential recommendation.\n\nAccording to the results, it is obvious that our proposed BERT4Rec achieves the best performances among all methods on four datasets in terms of all evaluation metrics. It gains 7.24% HR@10, 11.03% NDCG@10, and 11.46% MRR improvements (on average) against the strongest baseline.\n\nHere comes a question: do the gains come from the bidirectional self-attention model or from the Cloze objective?\n\nIn order to answer this question, we try to isolate the effects of these two factors by constraining the Cloze task to mask only one item at a time. In this way, the main difference between our BERT4Rec (with 1 mask) and SASRec is that BERT4Rec predicts the target item jointly conditioning on both left and right context. We report the results on Beauty and ML-1m with d = 256 in Table 3 due to the space limitation. The results show that BERT4Rec with 1 mask significantly outperforms SASRec on all metrics. This demonstrates the importance of bidirectional representations for sequential recommendation. Besides, the last two rows indicate that the Cloze objective also improves the recommendation performances. Detailed analysis of the mask proportion \u03c1 in Cloze task can be found in \u00a7 4.6\n\nIn the following studies, we examine the impact of the hyperparameters, including the hidden dimensionality d, the mask proportion \u03c1, and the maximum sequence length N . we analyze one hyper-parameter at a time by fixing the remaining hyper-parameters at their optimal settings. Due to space limitations, we only report NDCG@10 and HR@10 for the follow-up experiments.\n\n\nImpact of Hidden Dimensionality d\n\nWe now study how the hidden dimensionality d affects the recommendation performance. Figure 3 shows NDCG@10 and HR@10 for neural sequential methods with the hidden dimensionality d varying from 16 to 256 while keeping other optimal hyper-parameters unchanged. We make some observations from this figure.\n\nThe most obvious observation from these sub-figures is that the performance of each model tends to converge as the dimensionality increases. A larger hidden dimensionality does not necessarily lead to better model performance, especially on sparse datasets like Beauty and Steam. This is probably caused by overfitting. In terms of details, Caser performs unstably on four datasets, which 16 Figure 3: Effect of the hidden dimensionality d on Hit@10 and NDCG@10 for neural sequential models. \n\n\nImpact of Mask Proportion \u03c1\n\nAs described in \u00a7 3.6, mask proportion \u03c1 is a key factor in model training, which directly affects the loss function Equation 8. Obviously, mask proportion \u03c1 should not be too small or it is not enough to learn a strong model. Meanwhile, it should not be too large, otherwise it would be hard to train since there are too many items to guess based on a few contexts in such case. To examine this, we study how mask proportion \u03c1 affects the recommendation performances on different datasets. Table 4 shows the results with varying mask proportion \u03c1 from 0.1 to 0.9. Considering the results with \u03c1 > 0.6 on all datasets, a general pattern emerges, the performances decreasing as \u03c1 increases. From the results of the first two columns, it is easy to see that \u03c1 = 0.2 performs much better than \u03c1 = 0.1 on all datasets.\n\nThese results verify what we claimed above.\n\nIn addition, we observe that optimal mask proportion \u03c1 is highly dependent on the sequence length of the dataset. For the datasets with short sequence length (e.g., Beauty and Steam), the best performances are achieved at \u03c1=0.6 (Beauty) and \u03c1=0.4 (Steam), while the datasets with long sequence length (e.g., ML-1m and ML-20m) prefer a small \u03c1=0.2. This is reasonable since, comparing with short sequence datasets, a large \u03c1 in long sequence datasets means much more items that need to be predicted. Take ML-1m and Beauty as example, \u03c1=0.6 means we need to predict 98=\u230a163.5\u00d70.5\u230b items on average per sequence for ML-1m, while it is only 5=\u230a8.8\u00d70.6\u230b items for Beauty. The former is too hard for model training.\n\nBesides the recommendation performances, mask proportion \u03c1 also affects the efficiency of the model since it directly determines the number of masked items in Equation 8. Figure 4 shows the training speed (the number of masked samples per second) of various mask proportion \u03c1. It is easy to see that BERT4Rec scales linearly with a small coefficient roughly.  \n\n\nImpact of Maximum Sequence Length N\n\nWe also investigate the effect of the maximum sequence length N on model's recommendation performances and efficiency. Table 5 shows recommendation performances and training speed with different maximum length N on Beauty and ML-1m. We observe that the proper maximum length N is also highly dependent on the average sequence length of the dataset. Beauty prefers a smaller N = 20, while ML-1m achieves the best performances on N = 200. This indicates that user's behavior is affected by more recent items on short sequence datasets, and less recent items for long sequence datasets. The model does not consistently benefit from a larger N since a larger N tends to introduce both extra information and more noise. However, our model performs very stably as the length N becomes larger. This indicates that our model can attend to the informative items from the noisy historical records.\n\nA scalability concern about BERT4Rec is that its computational complexity per layer is O(n 2 d), quadratic with the length. Fortunately, the results in Table 5 shows that the self-attention layer can be effectively parallelized using GPUs.\n\n\nAblation Study\n\nFinally, we perform ablation experiments over a number of key components of BERT4Rec in order to better understand their impacts, including positional embedding (PE), position-wise feed-forward network (PFFN), layer normalization (LN), residual connection (RC), dropout, the layer number L of self-attention, and the number of heads h in multi-head attention. Table 6 shows the results of our default version (L = 2, h = 2) and its eleven variants on all four datasets with dimensionality d = 64 while keeping other hyperparameters (e.g. \u03c1) at their optimal settings. We introduce the variants and analyze their effects respectively:\n\n(1) Positional embedding. The results show that removing positional embeddings causes BERT4Rec's performances decreasing dramatically on long sequence datasets (i.e., ML-1m and ML-20m). Without the positional embeddings, the hidden representation H L i for each item v i depends only on item embeddings. In this situation, we predict different target items using the same hidden representation of \"[mask]\". This makes the model illposed. This issue is more serious on long sequence datasets since they have more masked items to predict.\n\n(2) Position-wise Feed-Forward Network. The results show that long sequence datasets (e.g., ML-20m) benefit more from PFFN. This is reasonable since a purpose of PFFN is to integrate information from many heads which is preferred by long sequence datasets as discussed in the analysis about head number h in (5). (3) Layer Normalization, Residual Connection, and Dropout.\n\nThese three components are introduced mainly to alleviate overfitting. Not surprisingly, they are more effective on small datasets like Beauty. To verify their effectiveness on large datasets, we conduct an experiment on ML-20m with layer L = 4. The results\n\nshow that NDCG@10 decreases about 10% without RC. (4) Number of layers L. The results show that stacking Transformer layer can boost performances especially on large datasets (e.g, ML-20m). This verifies that it is helpful to learn more complex item transition patterns via deep self-attention architecture. The decline in Beauty with L = 4 is largely due to overfitting. (5) Head number h. We observe that long sequence datasets (e.g., ML-20m) benefit from a larger h while short sequence datasets (e.g., Beauty) prefer a smaller h. This phenomenon is consistent with the findings in [48] that large h in multi-head attention is essential for modeling long distance dependencies.\n\n\nCONCLUSION AND FUTURE WORK\n\nDeep bidirectional self-attention architecture has achieved tremendous success in language understanding. In this paper, we introduce a deep bidirectional sequential model called BERT4Rec for sequential recommendation. For model training, we introduce the Cloze task which predicts the masked items using both left and right context. Extensive experimental results on four real-world datasets show that our model outperforms state-of-the-art baselines. Several directions remain to be explored. A valuable direction is to incorporate rich item features (e.g., category and price for products, cast for movies) into BERT4Rec instead of just modeling item ids. Another interesting direction for the future work would be introducing user component into the model for explicit user modeling when the users have multiple sessions.\n\n\nWOODSTOCK'19, July 2019, El Paso, Texas USA \u00a9 2019 Copyright held by the owner/author(s). ACM ISBN 123-4567-24-567/08/06. https://doi.org/10.475\n\nFigure 1 :\n1An example of anonymous user click records on a popular E-commerce platform. Although user behaviors exhibit sequential dependencies over long time scales (e.g., from A to [B,C,D]), a user's actions in a short period are often random (e.g., the order in [B,C,D]).\n\nFigure 2 :\n2Differences in sequential recommendation model architectures. BERT4Rec learns a bidirectional model via Cloze task, while SASRec and RNN based methods are all left-to-right unidirectional model which predicts next item sequentially.\n\nFigure 4 :\n4Training speed with different mask proportion \u03c1.\n\nTable 1 :\n1Statistics of datasets.Datasets \n#users #items #actions Avg. length Density \n\nBeauty \n40,226 54,542 \n0.35m \n8.8 \n0.02% \nSteam \n281,428 13,044 \n3.5m \n12.4 \n0.10% \nML-1m \n6040 \n3416 \n1.0m \n163.5 \n4.79% \nML-20m 138,493 26,744 \n20m \n144.4 \n0.54% \n\n\n\nTable 2 :\n2Performance comparison of different methods on next-item prediction. Bold scores are the best in each row, while underlined scores are the second best. Improvements over baselines are statistically significant with p < 0.01.Datasets Metric \nPOP \nBPR-MF \nNCF \nFPMC GRU4Rec GRU4Rec + \nCaser \nSASRec BERT4Rec Improv. \n\nBeauty \n\nHR@1 \n0.0077 \n0.0415 \n0.0407 0.0435 \n0.0402 \n0.0551 \n0.0475 \n0.0906 \n0.0953 \n5.19% \nHR@5 \n0.0392 \n0.1209 \n0.1305 0.1387 \n0.1315 \n0.1781 \n0.1625 \n0.1934 \n0.2207 \n14.12% \nHR@10 \n0.0762 \n0.1992 \n0.2142 0.2401 \n0.2343 \n0.2654 \n0.2590 \n0.2653 \n0.3025 \n14.02% \nNDCG@5 \n0.0230 \n0.0814 \n0.0855 0.0902 \n0.0812 \n0.1172 \n0.1050 \n0.1436 \n0.1599 \n11.35% \nNDCG@10 0.0349 \n0.1064 \n0.1124 0.1211 \n0.1074 \n0.1453 \n0.1360 \n0.1633 \n0.1862 \n14.02% \nMRR \n0.0437 \n0.1006 \n0.1043 0.1056 \n0.1023 \n0.1299 \n0.1205 \n0.1536 \n0.1701 \n10.74% \n\nSteam \n\nHR@1 \n0.0159 \n0.0314 \n0.0246 0.0358 \n0.0574 \n0.0812 \n0.0495 \n0.0885 \n0.0957 \n8.14% \nHR@5 \n0.0805 \n0.1177 \n0.1203 0.1517 \n0.2171 \n0.2391 \n0.1766 \n0.2559 \n0.2710 \n5.90% \nHR@10 \n0.1389 \n0.1993 \n0.2169 0.2551 \n0.3313 \n0.3594 \n0.2870 \n0.3783 \n0.4013 \n6.08% \nNDCG@5 \n0.0477 \n0.0744 \n0.0717 0.0945 \n0.1370 \n0.1613 \n0.1131 \n0.1727 \n0.1842 \n6.66% \nNDCG@10 0.0665 \n0.1005 \n0.1026 0.1283 \n0.1802 \n0.2053 \n0.1484 \n0.2147 \n0.2261 \n5.31% \nMRR \n0.0669 \n0.0942 \n0.0932 0.1139 \n0.1420 \n0.1757 \n0.1305 \n0.1874 \n0.1949 \n4.00% \n\nML-1m \n\nHR@1 \n0.0141 \n0.0914 \n0.0397 0.1386 \n0.1583 \n0.2092 \n0.2194 \n0.2351 \n0.2863 \n21.78% \nHR@5 \n0.0715 \n0.2866 \n0.1932 0.4297 \n0.4673 \n0.5103 \n0.5353 \n0.5434 \n0.5876 \n8.13% \nHR@10 \n0.1358 \n0.4301 \n0.3477 0.5946 \n0.6207 \n0.6351 \n0.6692 \n0.6629 \n0.6970 \n4.15% \nNDCG@5 \n0.0416 \n0.1903 \n0.1146 0.2885 \n0.3196 \n0.3705 \n0.3832 \n0.3980 \n0.4454 \n11.91% \nNDCG@10 0.0621 \n0.2365 \n0.1640 0.3439 \n0.3627 \n0.4064 \n0.4268 \n0.4368 \n0.4818 \n10.32% \nMRR \n0.0627 \n0.2009 \n0.1358 0.2891 \n0.3041 \n0.3462 \n0.3648 \n0.3790 \n0.4254 \n12.24% \n\nML-20m \n\nHR@1 \n0.0221 \n0.0553 \n0.0231 0.1079 \n0.1459 \n0.2021 \n0.1232 \n0.2544 \n0.3440 \n35.22% \nHR@5 \n0.0805 \n0.2128 \n0.1358 0.3601 \n0.4657 \n0.5118 \n0.3804 \n0.5727 \n0.6323 \n10.41% \nHR@10 \n0.1378 \n0.3538 \n0.2922 0.5201 \n0.5844 \n0.6524 \n0.5427 \n0.7136 \n0.7473 \n4.72% \nNDCG@5 \n0.0511 \n0.1332 \n0.0771 0.2239 \n0.3090 \n0.3630 \n0.2538 \n0.4208 \n0.4967 \n18.04% \nNDCG@10 0.0695 \n0.1786 \n0.1271 0.2895 \n0.3637 \n0.4087 \n0.3062 \n0.4665 \n0.5340 \n14.47% \nMRR \n0.0709 \n0.1503 \n0.1072 0.2273 \n0.2967 \n0.3476 \n0.2529 \n0.4026 \n0.4785 \n18.85% \n\n\n\nTable 3 :\n3Analysis on bidirection and Cloze with d = 256Model \nBeauty \nML-1m \n\nHR@10 NDCG@10 MRR HR@10 NDCG@10 MRR \n\nSASRec \n0.2653 \n0.1633 \n0.1536 0.6629 \n0.4368 \n0.3790 \nBERT4Rec (1 mask) 0.2940 \n0.1769 \n0.1618 0.6869 \n0.4696 \n0.4127 \nBERT4Rec \n0.3025 \n0.1862 \n0.1701 0.6970 \n0.4818 \n0.4254 \n\n\n\nTable 4 :\n4Performance with different mask proportion \u03c1 on d = 64. our model consistently outperforms all other baselines on all datasets even with a relatively small hidden dimensionality. Considering that our model achieves satisfactory performance with d \u2265 64, we only report the results with d = 64 in the following analysis experiments.Dataset \nMetrics \nMask Proportion \u03c1 \n\n0.1 \n0.2 \n0.3 \n0.4 \n0.5 \n0.6 \n0.7 \n0.8 \n0.9 \n\nBeauty \nHR@10 \n0.2797 \n0.2869 0.2952 \n0.2996 0.3028 0.3047 0.3009 0.2968 0.2265 \nNDCG@10 0.1626 \n0.1693 0.1744 \n0.1799 0.1809 0.1832 0.1772 0.1749 0.1264 \n\nSteam \nHR@10 \n0.3831 \n0.3962 0.3985 0.4007 0.3961 \n0.3911 0.3884 0.3802 0.3569 \nNDCG@10 0.2123 \n0.2206 0.2226 0.2241 0.2207 \n0.2190 0.2149 0.2096 0.1909 \n\nML-1m \nHR@10 \n0.6877 0.6955 0.6937 \n0.6875 0.6844 \n0.6794 0.6745 0.6511 0.6293 \nNDCG@10 0.4673 0.4759 0.4743 \n0.4688 0.4650 \n0.4587 0.4506 0.4250 0.3942 \n\nML-20m \nHR@10 \n0.6781 0.6879 0.6825 \n0.6822 0.6810 \n0.6791 0.6667 0.6462 0.6167 \nNDCG@10 0.4444 0.4513 0.4487 \n0.4471 0.4452 \n0.4434 0.4292 0.4049 0.3741 \n\nmight limit its usefulness. Self-attention based methods (i.e., SAS-\nRec and BERT4Rec) achieve superior performances on all datasets. \nFinally, \n\nTable 5 :\n5Performance with different maximum length N .10 \n20 \n30 \n40 \n50 \n\nBeauty \n\n#samples/s \n5504 \n3256 \n2284 \n1776 \n1441 \nHR@10 \n0.3006 0.3061 0.3057 0.3054 0.3047 \nNDCG@10 0.1826 0.1875 0.1837 0.1833 0.1832 \n\n10 \n50 \n100 \n200 \n400 \n\nML-1m \n\n#samples/s 14255 \n8890 \n5711 \n2918 \n1213 \nHR@10 \n0.6788 0.6854 0.6947 0.6955 0.6898 \nNDCG@10 0.4631 0.4743 0.4758 0.4759 0.4715 \n\n\n\nTable 6 :\n6Ablation analysis (NDCG@10) on four datasets. Bold score indicates performance better than the default version, while \u2193 indicates performance drop more than 10%.Architecture \nDataset \n\nBeauty \nSteam \nML-1m \nML-20m \n\nL = 2, h = 2 \n0.1832 \n0.2241 \n0.4759 \n0.4513 \n\nw/o PE \n0.1741 \n0.2060 0.2155\u2193 \n0.2867\u2193 \nw/o PFFN \n0.1803 \n0.2137 \n0.4544 \n0.4296 \n\nw/o LN \n0.1642\u2193 \n0.2058 \n0.4334 \n0.4186 \nw/o RC \n0.1619\u2193 \n0.2193 \n0.4643 \n0.4483 \nw/o Dropout \n0.1658 \n0.2185 \n0.4553 \n0.4471 \n\n1 layer (L = 1) \n0.1782 \n0.2122 \n0.4412 \n0.4238 \n3 layers (L = 3) \n0.1859 0.2262 \n0.4864 \n0.4661 \n4 layers (L = 4) \n0.1834 0.2279 \n0.4898 \n0.4732 \n\n1 head (h = 1) \n0.1853 \n0.2187 \n0.4568 \n0.4402 \n4 heads (h = 4) \n0.1830 0.2245 \n0.4770 \n0.4520 \n8 heads (h = 8) \n0.1823 0.2248 \n0.4743 \n0.4550 \n\n\nhttps://www.netflixprize.com\nHere, following[22,40], we use the relative time index instead of absolute time index for numbering interaction records.\nhttp://jmcauley.ucsd.edu/data/amazon/ 5 https://cseweb.ucsd.edu/~jmcauley/datasets.html#steam_data 6 http://grouplens.org/datasets/movielens/1m/ 7 https://grouplens.org/datasets/movielens/20m/\nhttps://github.com/hexiangnan/neural_collaborative_filtering 9 https://github.com/hidasib/GRU4Rec 10 https://github.com/graytowne/caser_pytorch 11 https://github.com/kang205/SASRec12 The source code will be released soon.13 https://www.tensorflow.org\n\nLayer Normalization. Jimmy Lei, Ryan Ba, Geoffrey E Kiros, Hinton, CoRR abs/1607.06450Lei Jimmy Ba, Ryan Kiros, and Geoffrey E. Hinton. 2016. Layer Normalization. CoRR abs/1607.06450 (2016).\n\nNeural Machine Translation by Jointly Learning to Align and Translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Proceedings of ICLR. ICLRDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In Proceedings of ICLR.\n\nSequential Recommendation with User Memory Networks. Xu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Proceedings of WSDM. WSDMNew York, NY, USAACMYixin Cao, Zheng Qin, and Hongyuan ZhaXu Chen, Hongteng Xu, Yongfeng Zhang, Jiaxi Tang, Yixin Cao, Zheng Qin, and Hongyuan Zha. 2018. Sequential Recommendation with User Memory Networks. In Proceedings of WSDM. ACM, New York, NY, USA, 108-116.\n\nLearning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. Kyunghyun Cho, Caglar Bart Van Merrienboer, Dzmitry Gulcehre, Fethi Bahdanau, Holger Bougares, Yoshua Schwenk, Bengio, Proceedings of EMNLP. EMNLPAssociation for Computational LinguisticsKyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. In Proceedings of EMNLP. Association for Computational Linguistics, 1724-1734.\n\nDeep Neural Networks for YouTube Recommendations. Paul Covington, Jay Adams, Emre Sargin, Proceedings of RecSys. RecSysNew York, NY, USAACMPaul Covington, Jay Adams, and Emre Sargin. 2016. Deep Neural Networks for YouTube Recommendations. In Proceedings of RecSys. ACM, New York, NY, USA, 191-198.\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, CoRR abs/1810.04805Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. CoRR abs/1810.04805 (2018).\n\nSequential User-based Recurrent Neural Network Recommendations. Tim Donkers, Benedikt Loepp, J\u00fcrgen Ziegler, Proceedings of RecSys. RecSysNew York, NY, USAACMTim Donkers, Benedikt Loepp, and J\u00fcrgen Ziegler. 2017. Sequential User-based Recurrent Neural Network Recommendations. In Proceedings of RecSys. ACM, New York, NY, USA, 152-160.\n\nThe MovieLens Datasets: History and Context. F , Maxwell Harper, Joseph A Konstan, ACM Trans. Interact. Intell. Syst. 519F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Trans. Interact. Intell. Syst. 5, 4, Article 19 (Dec. 2015), 19 pages.\n\nDeep Residual Learning for Image Recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of CVPR. CVPRKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep Residual Learning for Image Recognition. In Proceedings of CVPR. 770-778.\n\nTranslation-based Recommendation. Ruining He, Wang-Cheng Kang, Julian Mcauley, Proceedings of RecSys. RecSysNew York, NY, USAACMRuining He, Wang-Cheng Kang, and Julian McAuley. 2017. Translation-based Recommendation. In Proceedings of RecSys. ACM, New York, NY, USA, 161-169.\n\nFusing Similarity Models with Markov Chains for Sparse Sequential Recommendation. Ruining He, Julian Mcauley, Proceedings of ICDM. ICDMRuining He and Julian McAuley. 2016. Fusing Similarity Models with Markov Chains for Sparse Sequential Recommendation. In Proceedings of ICDM. 191-200.\n\nNeural Collaborative Filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proceedings of WWW. WWWXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of WWW. 173-182.\n\nBridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units. Dan Hendrycks, Kevin Gimpel, CoRR abs/1606.08415Dan Hendrycks and Kevin Gimpel. 2016. Bridging Nonlinearities and Stochastic Regularizers with Gaussian Error Linear Units. CoRR abs/1606.08415 (2016).\n\nRecurrent Neural Networks with Top-k Gains for Session-based Recommendations. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Proceedings of CIKM. CIKMNew York, NY, USAACMBal\u00e1zs Hidasi and Alexandros Karatzoglou. 2018. Recurrent Neural Networks with Top-k Gains for Session-based Recommendations. In Proceedings of CIKM. ACM, New York, NY, USA, 843-852.\n\nSession-based Recommendations with Recurrent Neural Networks. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, Proceedings of ICLR. ICLRLinas Baltrunas, and Domonkos TikkBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In Proceedings of ICLR.\n\nDistilling the knowledge in a neural network. Geoffrey Hinton, Oriol Vinyals, Jeff Dean, Deep Learning and Representation Learning Workshop. Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2015. Distilling the knowledge in a neural network. In Deep Learning and Representation Learning Workshop.\n\nLong Short-Term Memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural Computation. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9, 8 (Nov. 1997), 1735-1780.\n\nDiversifying Personalized Recommendation with User-session Context. Liang Hu, Longbing Cao, Shoujin Wang, Guandong Xu, Jian Cao, Zhiping Gu, Proceedings of IJCAI. IJCAILiang Hu, Longbing Cao, Shoujin Wang, Guandong Xu, Jian Cao, and Zhiping Gu. 2017. Diversifying Personalized Recommendation with User-session Context. In Proceedings of IJCAI. 1858-1864.\n\nImproving Sequential Recommendation with Knowledge-Enhanced Memory Networks. Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, Edward Y Chang, Proceedings of SIGIR. SIGIRNew York, NY, USAACMJin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, and Edward Y. Chang. 2018. Improving Sequential Recommendation with Knowledge-Enhanced Mem- ory Networks. In Proceedings of SIGIR. ACM, New York, NY, USA, 505-514.\n\nFISM: Factored Item Similarity Models for top-N Recommender Systems. Santosh Kabbur, Xia Ning, George Karypis, Proceedings of KDD. KDDNew York, NY, USAACMSantosh Kabbur, Xia Ning, and George Karypis. 2013. FISM: Factored Item Similarity Models for top-N Recommender Systems. In Proceedings of KDD. ACM, New York, NY, USA, 659-667.\n\nVisually-Aware Fashion Recommendation and Design with Generative Image Models. Wang-Cheng Kang, Chen Fang, Zhaowen Wang, Julian Mcauley, Proceedings of ICDM. ICDMIEEE Computer SocietyWang-Cheng Kang, Chen Fang, Zhaowen Wang, and Julian McAuley. 2017. Visually-Aware Fashion Recommendation and Design with Generative Image Models. In Proceedings of ICDM. IEEE Computer Society, 207-216.\n\nSelf-Attentive Sequential Recommendation. Wang-Cheng Kang, Julian Mcauley, Proceedings of ICDM. ICDMn. d.Wang-Cheng Kang and Julian McAuley. [n. d.]. Self-Attentive Sequential Recom- mendation. In Proceedings of ICDM. 197-206.\n\nConvolutional Matrix Factorization for Document Context-Aware Recommendation. Donghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, Hwanjo Yu, Proceedings of RecSys. RecSysNew York, NY, USAACMDonghyun Kim, Chanyoung Park, Jinoh Oh, Sungyoung Lee, and Hwanjo Yu. 2016. Convolutional Matrix Factorization for Document Context-Aware Recom- mendation. In Proceedings of RecSys. ACM, New York, NY, USA, 233-240.\n\nAdam: A Method for Stochastic Optimization. P Diederik, Jimmy Kingma, Ba, Proceedings of ICLR. ICLRDiederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti- mization. In Proceedings of ICLR.\n\nFactorization Meets the Neighborhood: A Multifaceted Collaborative Filtering Model. Yehuda Koren, Proceedings of KDD. ACM. KDD. ACMYehuda Koren. 2008. Factorization Meets the Neighborhood: A Multifaceted Collaborative Filtering Model. In Proceedings of KDD. ACM, 426-434.\n\nAdvances in Collaborative Filtering. Yehuda Koren, Robert Bell, Recommender Systems Handbook. Boston, MASpringer USYehuda Koren and Robert Bell. 2011. Advances in Collaborative Filtering. In Recommender Systems Handbook. Springer US, Boston, MA, 145-186.\n\nMatrix Factorization Techniques for Recommender Systems. Yehuda Koren, Robert Bell, Chris Volinsky, Computer. 42Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Tech- niques for Recommender Systems. Computer 42, 8 (Aug. 2009), 30-37.\n\nNeural Attentive Session-based Recommendation. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, Jun Ma, Proceedings of CIKM. CIKMNew York, NY, USAACMJing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural Attentive Session-based Recommendation. In Proceedings of CIKM. ACM, New York, NY, USA, 1419-1428.\n\nMulti-Head Attention with Disagreement Regularization. Jian Li, Zhaopeng Tu, Baosong Yang, Michael R Lyu, Tong Zhang, Proceedings of tEMNLP. tEMNLPJian Li, Zhaopeng Tu, Baosong Yang, Michael R. Lyu, and Tong Zhang. 2018. Multi- Head Attention with Disagreement Regularization. In Proceedings of tEMNLP. 2897-2903.\n\nA Structured Self-attentive Sentence Embedding. Zhouhan Lin, Minwei Feng, C\u00edcero Nogueira, Mo Santos, Bing Yu, Bowen Xiang, Yoshua Zhou, Bengio, Proceedings of ICLR. ICLRZhouhan Lin, Minwei Feng, C\u00edcero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, and Yoshua Bengio. 2017. A Structured Self-attentive Sentence Embedding. In Proceedings of ICLR.\n\nAmazon.Com Recommendations: Item-to-Item Collaborative Filtering. Greg Linden, Brent Smith, Jeremy York, IEEE Internet Computing. 71Greg Linden, Brent Smith, and Jeremy York. 2003. Amazon.Com Recommenda- tions: Item-to-Item Collaborative Filtering. IEEE Internet Computing 7, 1 (Jan. 2003), 76-80.\n\nGenerating Wikipedia by Summarizing Long Sequences. J Peter, Mohammad Liu, Etienne Saleh, Ben Pot, Ryan Goodrich, Lukasz Sepassi, Noam Kaiser, Shazeer, Proceedings of ICLR. ICLRPeter J. Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 2018. Generating Wikipedia by Summarizing Long Sequences. In Proceedings of ICLR.\n\nSTAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation. Qiao Liu, Yifu Zeng, Refuoe Mokhosi, Haibin Zhang, Proceedings of KDD. KDDNew York, NY, USAACMQiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: Short- Term Attention/Memory Priority Model for Session-based Recommendation. In Proceedings of KDD. ACM, New York, NY, USA, 1831-1839.\n\nImage-Based Recommendations on Styles and Substitutes. Julian Mcauley, Christopher Targett, Proceedings of SIGIR. SIGIRNew York, NY, USAACMQinfeng Shi, and Anton van den HengelJulian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel. 2015. Image-Based Recommendations on Styles and Substitutes. In Proceedings of SIGIR. ACM, New York, NY, USA, 43-52.\n\nEfficient Estimation of Word Representations in Vector Space. Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean, CoRR abs/1301.3781Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient Estimation of Word Representations in Vector Space. CoRR abs/1301.3781 (2013).\n\nDistributed Representations of Words and Phrases and Their Compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean, Proceedings of NIPS. NIPSUSACurran Associates IncTomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Distributed Representations of Words and Phrases and Their Compositionality. In Proceedings of NIPS. Curran Associates Inc., USA, 3111-3119.\n\nPersonalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks. Massimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, Paolo Cremonesi, Proceedings of RecSys. RecSysNew York, NY, USAACMMassimo Quadrana, Alexandros Karatzoglou, Bal\u00e1zs Hidasi, and Paolo Cremonesi. 2017. Personalizing Session-based Recommendations with Hierarchical Recurrent Neural Networks. In Proceedings of RecSys. ACM, New York, NY, USA, 130-137.\n\nImproving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, OpenAI Technical report. Tim Salimans, and Ilya SutskeverAlec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Im- proving language understanding by generative pre-training. In OpenAI Technical report.\n\nBPR: Bayesian Personalized Ranking from Implicit Feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, Proceedings of UAI. UAIArlington, Virginia, United StatesAUAI PressSteffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In Proceedings of UAI. AUAI Press, Arlington, Virginia, United States, 452-461.\n\nFactorizing Personalized Markov Chains for Next-basket Recommendation. Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme, Proceedings of WWW. WWWNew York, NY, USAACMSteffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factoriz- ing Personalized Markov Chains for Next-basket Recommendation. In Proceedings of WWW. ACM, New York, NY, USA, 811-820.\n\nProbabilistic Matrix Factorization. Ruslan Salakhutdinov, Andriy Mnih, Proceedings of NIPS. NIPSUSACurran Associates IncRuslan Salakhutdinov and Andriy Mnih. 2007. Probabilistic Matrix Factorization. In Proceedings of NIPS. Curran Associates Inc., USA, 1257-1264.\n\nRestricted Boltzmann Machines for Collaborative Filtering. Ruslan Salakhutdinov, Andriy Mnih, Geoffrey Hinton, Proceedings of ICML. ICMLRuslan Salakhutdinov, Andriy Mnih, and Geoffrey Hinton. 2007. Restricted Boltzmann Machines for Collaborative Filtering. In Proceedings of ICML. 791- 798.\n\nItem-based Collaborative Filtering Recommendation Algorithms. Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl, Proceedings of WWW. WWWNew York, NY, USAACMBadrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based Collaborative Filtering Recommendation Algorithms. In Proceedings of WWW. ACM, New York, NY, USA, 285-295.\n\nAutoRec: Autoencoders Meet Collaborative Filtering. Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, Lexing Xie, Proceedings of WWW. WWWNew York, NY, USAACMSuvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015. AutoRec: Autoencoders Meet Collaborative Filtering. In Proceedings of WWW. ACM, New York, NY, USA, 111-112.\n\nAn MDP-Based Recommender System. Guy Shani, David Heckerman, Ronen I Brafman, J. Mach. Learn. Res. 6Guy Shani, David Heckerman, and Ronen I. Brafman. 2005. An MDP-Based Recommender System. J. Mach. Learn. Res. 6 (Dec. 2005), 1265-1295.\n\nSelf-Attention with Relative Position Representations. Peter Shaw, Jakob Uszkoreit, Ashish Vaswani, Proceedings of NAACL. Association for Computational Linguistics. NAACL. Association for Computational LinguisticsPeter Shaw, Jakob Uszkoreit, and Ashish Vaswani. 2018. Self-Attention with Relative Position Representations. In Proceedings of NAACL. Association for Computational Linguistics, 464-468.\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov, J. Mach. Learn. Res. 15Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. J. Mach. Learn. Res. 15, 1 (Jan. 2014), 1929-1958.\n\nWhy Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures. Gongbo Tang, Mathias M\u00fcller, Annette Rios, Rico Sennrich, Proceedings of EMNLP. EMNLPGongbo Tang, Mathias M\u00fcller, Annette Rios, and Rico Sennrich. 2018. Why Self- Attention? A Targeted Evaluation of Neural Machine Translation Architectures. In Proceedings of EMNLP. 4263-4272.\n\nPersonalized Top-N Sequential Recommendation via Convolutional Sequence Embedding. Jiaxi Tang, Ke Wang, Proceedings of WSDM. WSDMJiaxi Tang and Ke Wang. 2018. Personalized Top-N Sequential Recommendation via Convolutional Sequence Embedding. In Proceedings of WSDM. 565-573.\n\nWilson L Taylor, \u00e2\u0102\u0132Cloze Procedure\u00e2\u0102\u0130: A New Tool for Measuring Readability. 30Wilson L. Taylor. 1953. \u00e2\u0102\u0132Cloze Procedure\u00e2\u0102\u0130: A New Tool for Measuring Readability. Journalism Bulletin 30, 4 (1953), 415-433.\n\nDeep content-based music recommendation. Aaron Van Den Oord, Sander Dieleman, Benjamin Schrauwen, Proceedings of NIPS. NIPSAaron van den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. In Proceedings of NIPS. 2643-2651.\n\nAttention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, NIPS. Curran Associates, IncAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In NIPS. Curran Associates, Inc., 5998-6008.\n\nCollaborative Deep Learning for Recommender Systems. Hao Wang, Naiyan Wang, Dit-Yan Yeung, Proceedings of KDD. KDDNew York, NY, USAACMHao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative Deep Learning for Recommender Systems. In Proceedings of KDD. ACM, New York, NY, USA, 1235-1244.\n\nAttention-Based Transactional Context Embedding for Next-Item Recommendation. Shoujin Wang, Liang Hu, Longbing Cao, Xiaoshui Huang, Defu Lian, Wei Liu, Shoujin Wang, Liang Hu, Longbing Cao, Xiaoshui Huang, Defu Lian, and Wei Liu. 2018. Attention-Based Transactional Context Embedding for Next-Item Recommendation. , 2532-2539 pages.\n\nWhat Your Images Reveal: Exploiting Visual Contents for Point-of-Interest Recommendation. Suhang Wang, Yilin Wang, Jiliang Tang, Kai Shu, Suhas Ranganath, Huan Liu, Proceedings of WWW. WWWSuhang Wang, Yilin Wang, Jiliang Tang, Kai Shu, Suhas Ranganath, and Huan Liu. 2017. What Your Images Reveal: Exploiting Visual Contents for Point-of-Interest Recommendation. In Proceedings of WWW. 391-400.\n\nRecurrent Recommender Networks. Chao-Yuan, Amr Wu, Alex Ahmed, Alexander J Beutel, How Smola, Jing, Proceedings of WSDM. WSDMNew York, NY, USAACMChao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J. Smola, and How Jing. 2017. Recurrent Recommender Networks. In Proceedings of WSDM. ACM, New York, NY, USA, 495-503.\n\nCollaborative Denoising Auto-Encoders for Top-N Recommender Systems. Yao Wu, Christopher Dubois, Alice X Zheng, Martin Ester, Proceedings of WSDM. WSDMNew York, NY, USAACMYao Wu, Christopher DuBois, Alice X. Zheng, and Martin Ester. 2016. Collabora- tive Denoising Auto-Encoders for Top-N Recommender Systems. In Proceedings of WSDM. ACM, New York, NY, USA, 153-162.\n\nA Dynamic Recurrent Model for Next Basket Recommendation. Feng Yu, Qiang Liu, Shu Wu, Liang Wang, Tieniu Tan, Proceedings of SIGIR. SIGIRNew York, NY, USAACMFeng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. A Dynamic Recurrent Model for Next Basket Recommendation. In Proceedings of SIGIR. ACM, New York, NY, USA, 729-732.\n", "annotations": {"author": "[{\"end\":135,\"start\":99},{\"end\":172,\"start\":136},{\"end\":209,\"start\":173},{\"end\":280,\"start\":210},{\"end\":318,\"start\":281},{\"end\":356,\"start\":319},{\"end\":425,\"start\":357},{\"end\":462,\"start\":426},{\"end\":499,\"start\":463},{\"end\":536,\"start\":500},{\"end\":578,\"start\":537},{\"end\":616,\"start\":579},{\"end\":654,\"start\":617},{\"end\":694,\"start\":655}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":103},{\"end\":143,\"start\":140},{\"end\":180,\"start\":178},{\"end\":222,\"start\":219},{\"end\":289,\"start\":286},{\"end\":327,\"start\":325},{\"end\":367,\"start\":362},{\"end\":433,\"start\":430},{\"end\":470,\"start\":467},{\"end\":507,\"start\":505},{\"end\":549,\"start\":546},{\"end\":587,\"start\":584},{\"end\":625,\"start\":623},{\"end\":665,\"start\":660}]", "author_first_name": "[{\"end\":102,\"start\":99},{\"end\":139,\"start\":136},{\"end\":177,\"start\":173},{\"end\":218,\"start\":210},{\"end\":285,\"start\":281},{\"end\":324,\"start\":319},{\"end\":361,\"start\":357},{\"end\":429,\"start\":426},{\"end\":466,\"start\":463},{\"end\":504,\"start\":500},{\"end\":545,\"start\":537},{\"end\":583,\"start\":579},{\"end\":622,\"start\":617},{\"end\":659,\"start\":655}]", "author_affiliation": "[{\"end\":134,\"start\":108},{\"end\":171,\"start\":145},{\"end\":208,\"start\":182},{\"end\":279,\"start\":253},{\"end\":317,\"start\":291},{\"end\":355,\"start\":329},{\"end\":424,\"start\":398},{\"end\":461,\"start\":435},{\"end\":498,\"start\":472},{\"end\":535,\"start\":509},{\"end\":577,\"start\":551},{\"end\":615,\"start\":589},{\"end\":653,\"start\":627},{\"end\":693,\"start\":667}]", "title": "[{\"end\":96,\"start\":1},{\"end\":790,\"start\":695}]", "venue": null, "abstract": "[{\"end\":2503,\"start\":1071}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3516,\"start\":3512},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3519,\"start\":3516},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3522,\"start\":3519},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3761,\"start\":3757},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3764,\"start\":3761},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3767,\"start\":3764},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3916,\"start\":3912},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4080,\"start\":4077},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4083,\"start\":4080},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4086,\"start\":4083},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4089,\"start\":4086},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":4092,\"start\":4089},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4834,\"start\":4830},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":4837,\"start\":4834},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5102,\"start\":5099},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5312,\"start\":5309},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5411,\"start\":5407},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":6116,\"start\":6112},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8150,\"start\":8146},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8153,\"start\":8150},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8381,\"start\":8377},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8384,\"start\":8381},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8387,\"start\":8384},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8449,\"start\":8445},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8452,\"start\":8449},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8455,\"start\":8452},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8458,\"start\":8455},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8892,\"start\":8888},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9087,\"start\":9083},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9090,\"start\":9087},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9103,\"start\":9099},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":9106,\"start\":9103},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":9134,\"start\":9130},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9373,\"start\":9369},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":9479,\"start\":9475},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":9493,\"start\":9489},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9868,\"start\":9864},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10027,\"start\":10023},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10264,\"start\":10260},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10267,\"start\":10264},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10332,\"start\":10329},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10371,\"start\":10367},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10448,\"start\":10445},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10451,\"start\":10448},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10454,\"start\":10451},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10457,\"start\":10454},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10460,\"start\":10457},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":10463,\"start\":10460},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":10466,\"start\":10463},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10746,\"start\":10742},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":10791,\"start\":10787},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10811,\"start\":10808},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10844,\"start\":10840},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10957,\"start\":10953},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11080,\"start\":11077},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11083,\"start\":11080},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":11086,\"start\":11083},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":11089,\"start\":11086},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":11122,\"start\":11118},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11272,\"start\":11269},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11294,\"start\":11290},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":11461,\"start\":11457},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11594,\"start\":11591},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":11597,\"start\":11594},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11638,\"start\":11635},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11763,\"start\":11759},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":11766,\"start\":11763},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11795,\"start\":11791},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":12071,\"start\":12067},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12084,\"start\":12081},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12414,\"start\":12410},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12417,\"start\":12414},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":12420,\"start\":12417},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":12423,\"start\":12420},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12477,\"start\":12473},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":15401,\"start\":15397},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16080,\"start\":16077},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":16083,\"start\":16080},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":16086,\"start\":16083},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17211,\"start\":17207},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":17214,\"start\":17211},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18713,\"start\":18709},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18726,\"start\":18723},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18755,\"start\":18751},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19219,\"start\":19216},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":19305,\"start\":19302},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":19343,\"start\":19339},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":20895,\"start\":20891},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":22817,\"start\":22813},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22863,\"start\":22860},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":25482,\"start\":25478},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":26188,\"start\":26184},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26803,\"start\":26799},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27075,\"start\":27071},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27092,\"start\":27089},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27248,\"start\":27247},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":27277,\"start\":27276},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27347,\"start\":27343},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":27350,\"start\":27347},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27353,\"start\":27350},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":27705,\"start\":27701},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27708,\"start\":27705},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":27711,\"start\":27708},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27714,\"start\":27711},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":28147,\"start\":28143},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28150,\"start\":28147},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28153,\"start\":28150},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":28577,\"start\":28573},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28580,\"start\":28577},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28583,\"start\":28580},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":30394,\"start\":30390},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":30498,\"start\":30494},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":30612,\"start\":30608},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":30735,\"start\":30731},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30847,\"start\":30843},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30956,\"start\":30952},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":31077,\"start\":31073},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32072,\"start\":32068},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":32382,\"start\":32378},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":36649,\"start\":36647},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38523,\"start\":38522},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":42295,\"start\":42291},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":49345,\"start\":49341},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":49348,\"start\":49345},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":49822,\"start\":49820},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":49863,\"start\":49861}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":43389,\"start\":43243},{\"attributes\":{\"id\":\"fig_1\"},\"end\":43666,\"start\":43390},{\"attributes\":{\"id\":\"fig_2\"},\"end\":43912,\"start\":43667},{\"attributes\":{\"id\":\"fig_3\"},\"end\":43974,\"start\":43913},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":44231,\"start\":43975},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":46644,\"start\":44232},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":46942,\"start\":46645},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":48135,\"start\":46943},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":48515,\"start\":48136},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":49296,\"start\":48516}]", "paragraph": "[{\"end\":3349,\"start\":2519},{\"end\":3638,\"start\":3351},{\"end\":4333,\"start\":3640},{\"end\":5494,\"start\":4335},{\"end\":7145,\"start\":5496},{\"end\":7193,\"start\":7147},{\"end\":7784,\"start\":7195},{\"end\":7973,\"start\":7801},{\"end\":8913,\"start\":8000},{\"end\":9546,\"start\":8915},{\"end\":9698,\"start\":9576},{\"end\":10268,\"start\":9700},{\"end\":10958,\"start\":10270},{\"end\":11462,\"start\":10960},{\"end\":11936,\"start\":11486},{\"end\":12904,\"start\":11938},{\"end\":13076,\"start\":12917},{\"end\":13248,\"start\":13098},{\"end\":13699,\"start\":13297},{\"end\":13782,\"start\":13701},{\"end\":14083,\"start\":13805},{\"end\":14805,\"start\":14085},{\"end\":15167,\"start\":14807},{\"end\":15697,\"start\":15189},{\"end\":16459,\"start\":15699},{\"end\":16612,\"start\":16567},{\"end\":16911,\"start\":16715},{\"end\":17089,\"start\":16956},{\"end\":17215,\"start\":17091},{\"end\":17669,\"start\":17217},{\"end\":17874,\"start\":17785},{\"end\":19594,\"start\":18461},{\"end\":20038,\"start\":19627},{\"end\":20641,\"start\":20195},{\"end\":21178,\"start\":20790},{\"end\":21807,\"start\":21275},{\"end\":22113,\"start\":21858},{\"end\":22329,\"start\":22132},{\"end\":22713,\"start\":22405},{\"end\":23255,\"start\":22715},{\"end\":23648,\"start\":23389},{\"end\":23912,\"start\":23707},{\"end\":24286,\"start\":23914},{\"end\":24994,\"start\":24288},{\"end\":25079,\"start\":25009},{\"end\":26146,\"start\":25081},{\"end\":26430,\"start\":26148},{\"end\":26555,\"start\":26446},{\"end\":26691,\"start\":26568},{\"end\":27279,\"start\":26693},{\"end\":27915,\"start\":27281},{\"end\":28198,\"start\":27954},{\"end\":28327,\"start\":28236},{\"end\":28924,\"start\":28346},{\"end\":29140,\"start\":28926},{\"end\":29264,\"start\":29142},{\"end\":29525,\"start\":29298},{\"end\":29658,\"start\":29527},{\"end\":29787,\"start\":29719},{\"end\":30119,\"start\":29815},{\"end\":30259,\"start\":30158},{\"end\":30599,\"start\":30261},{\"end\":31241,\"start\":30601},{\"end\":31895,\"start\":31243},{\"end\":33177,\"start\":31897},{\"end\":34354,\"start\":33212},{\"end\":34635,\"start\":34356},{\"end\":34750,\"start\":34637},{\"end\":35545,\"start\":34752},{\"end\":35915,\"start\":35547},{\"end\":36256,\"start\":35953},{\"end\":36750,\"start\":36258},{\"end\":37596,\"start\":36782},{\"end\":37641,\"start\":37598},{\"end\":38352,\"start\":37643},{\"end\":38714,\"start\":38354},{\"end\":39641,\"start\":38754},{\"end\":39882,\"start\":39643},{\"end\":40534,\"start\":39901},{\"end\":41072,\"start\":40536},{\"end\":41445,\"start\":41074},{\"end\":41704,\"start\":41447},{\"end\":42386,\"start\":41706},{\"end\":43242,\"start\":42417}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13296,\"start\":13249},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16566,\"start\":16460},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16714,\"start\":16613},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16955,\"start\":16912},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17784,\"start\":17670},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18460,\"start\":17875},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19626,\"start\":19595},{\"attributes\":{\"id\":\"formula_7\"},\"end\":20080,\"start\":20039},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20176,\"start\":20080},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20789,\"start\":20642},{\"attributes\":{\"id\":\"formula_10\"},\"end\":21259,\"start\":21179},{\"attributes\":{\"id\":\"formula_11\"},\"end\":21857,\"start\":21808},{\"attributes\":{\"id\":\"formula_12\"},\"end\":22404,\"start\":22330},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23388,\"start\":23256},{\"attributes\":{\"id\":\"formula_14\"},\"end\":23706,\"start\":23649},{\"attributes\":{\"id\":\"formula_15\"},\"end\":28235,\"start\":28199},{\"attributes\":{\"id\":\"formula_16\"},\"end\":28345,\"start\":28328},{\"attributes\":{\"id\":\"formula_17\"},\"end\":29297,\"start\":29265},{\"attributes\":{\"id\":\"formula_18\"},\"end\":29718,\"start\":29659},{\"attributes\":{\"id\":\"formula_19\"},\"end\":29814,\"start\":29788}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27914,\"start\":27907},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":32913,\"start\":32906},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":37280,\"start\":37273},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":38880,\"start\":38873},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":39802,\"start\":39795},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":40268,\"start\":40261}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2517,\"start\":2505},{\"attributes\":{\"n\":\"2\"},\"end\":7799,\"start\":7787},{\"attributes\":{\"n\":\"2.1\"},\"end\":7998,\"start\":7976},{\"attributes\":{\"n\":\"2.2\"},\"end\":9574,\"start\":9549},{\"attributes\":{\"n\":\"2.3\"},\"end\":11484,\"start\":11465},{\"attributes\":{\"n\":\"3\"},\"end\":12915,\"start\":12907},{\"attributes\":{\"n\":\"3.1\"},\"end\":13096,\"start\":13079},{\"attributes\":{\"n\":\"3.2\"},\"end\":13803,\"start\":13785},{\"attributes\":{\"n\":\"3.3\"},\"end\":15187,\"start\":15170},{\"attributes\":{\"n\":\"3.4\"},\"end\":20193,\"start\":20178},{\"attributes\":{\"n\":\"3.5\"},\"end\":21273,\"start\":21261},{\"attributes\":{\"n\":\"3.6\"},\"end\":22130,\"start\":22116},{\"attributes\":{\"n\":\"3.7\"},\"end\":25007,\"start\":24997},{\"attributes\":{\"n\":\"4\"},\"end\":26444,\"start\":26433},{\"attributes\":{\"n\":\"4.1\"},\"end\":26566,\"start\":26558},{\"attributes\":{\"n\":\"4.2\"},\"end\":27952,\"start\":27918},{\"attributes\":{\"n\":\"4.3\"},\"end\":30156,\"start\":30122},{\"attributes\":{\"n\":\"4.4\"},\"end\":33210,\"start\":33180},{\"attributes\":{\"n\":\"4.5\"},\"end\":35951,\"start\":35918},{\"attributes\":{\"n\":\"4.6\"},\"end\":36780,\"start\":36753},{\"attributes\":{\"n\":\"4.7\"},\"end\":38752,\"start\":38717},{\"attributes\":{\"n\":\"4.8\"},\"end\":39899,\"start\":39885},{\"attributes\":{\"n\":\"5\"},\"end\":42415,\"start\":42389},{\"end\":43401,\"start\":43391},{\"end\":43678,\"start\":43668},{\"end\":43924,\"start\":43914},{\"end\":43985,\"start\":43976},{\"end\":44242,\"start\":44233},{\"end\":46655,\"start\":46646},{\"end\":46953,\"start\":46944},{\"end\":48146,\"start\":48137},{\"end\":48526,\"start\":48517}]", "table": "[{\"end\":44231,\"start\":44010},{\"end\":46644,\"start\":44468},{\"end\":46942,\"start\":46703},{\"end\":48135,\"start\":47285},{\"end\":48515,\"start\":48193},{\"end\":49296,\"start\":48689}]", "figure_caption": "[{\"end\":43389,\"start\":43245},{\"end\":43666,\"start\":43403},{\"end\":43912,\"start\":43680},{\"end\":43974,\"start\":43926},{\"end\":44010,\"start\":43987},{\"end\":44468,\"start\":44244},{\"end\":46703,\"start\":46657},{\"end\":47285,\"start\":46955},{\"end\":48193,\"start\":48148},{\"end\":48689,\"start\":48528}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":4862,\"start\":4854},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":5780,\"start\":5772},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14112,\"start\":14103},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14464,\"start\":14455},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14826,\"start\":14817},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15216,\"start\":15207},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15565,\"start\":15556},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19268,\"start\":19259},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21614,\"start\":21605},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22283,\"start\":22274},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22437,\"start\":22428},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":24091,\"start\":24082},{\"end\":36046,\"start\":36038},{\"end\":36658,\"start\":36650},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":38533,\"start\":38525}]", "bib_author_first_name": "[{\"end\":49918,\"start\":49913},{\"end\":49928,\"start\":49924},{\"end\":49941,\"start\":49933},{\"end\":49943,\"start\":49942},{\"end\":50162,\"start\":50155},{\"end\":50182,\"start\":50173},{\"end\":50194,\"start\":50188},{\"end\":50437,\"start\":50435},{\"end\":50452,\"start\":50444},{\"end\":50465,\"start\":50457},{\"end\":50478,\"start\":50473},{\"end\":50879,\"start\":50870},{\"end\":50891,\"start\":50885},{\"end\":50921,\"start\":50914},{\"end\":50937,\"start\":50932},{\"end\":50954,\"start\":50948},{\"end\":50971,\"start\":50965},{\"end\":51415,\"start\":51411},{\"end\":51430,\"start\":51427},{\"end\":51442,\"start\":51438},{\"end\":51747,\"start\":51742},{\"end\":51764,\"start\":51756},{\"end\":51778,\"start\":51772},{\"end\":51792,\"start\":51784},{\"end\":52073,\"start\":52070},{\"end\":52091,\"start\":52083},{\"end\":52105,\"start\":52099},{\"end\":52389,\"start\":52388},{\"end\":52399,\"start\":52392},{\"end\":52414,\"start\":52408},{\"end\":52416,\"start\":52415},{\"end\":52685,\"start\":52678},{\"end\":52697,\"start\":52690},{\"end\":52713,\"start\":52705},{\"end\":52723,\"start\":52719},{\"end\":52936,\"start\":52929},{\"end\":52951,\"start\":52941},{\"end\":52964,\"start\":52958},{\"end\":53261,\"start\":53254},{\"end\":53272,\"start\":53266},{\"end\":53500,\"start\":53492},{\"end\":53509,\"start\":53505},{\"end\":53523,\"start\":53516},{\"end\":53538,\"start\":53531},{\"end\":53547,\"start\":53544},{\"end\":53560,\"start\":53552},{\"end\":53829,\"start\":53826},{\"end\":53846,\"start\":53841},{\"end\":54111,\"start\":54105},{\"end\":54130,\"start\":54120},{\"end\":54441,\"start\":54435},{\"end\":54460,\"start\":54450},{\"end\":54755,\"start\":54747},{\"end\":54769,\"start\":54764},{\"end\":54783,\"start\":54779},{\"end\":55025,\"start\":55021},{\"end\":55044,\"start\":55038},{\"end\":55271,\"start\":55266},{\"end\":55284,\"start\":55276},{\"end\":55297,\"start\":55290},{\"end\":55312,\"start\":55304},{\"end\":55321,\"start\":55317},{\"end\":55334,\"start\":55327},{\"end\":55634,\"start\":55631},{\"end\":55647,\"start\":55642},{\"end\":55651,\"start\":55648},{\"end\":55666,\"start\":55658},{\"end\":55679,\"start\":55672},{\"end\":55691,\"start\":55685},{\"end\":55693,\"start\":55692},{\"end\":56043,\"start\":56036},{\"end\":56055,\"start\":56052},{\"end\":56068,\"start\":56062},{\"end\":56388,\"start\":56378},{\"end\":56399,\"start\":56395},{\"end\":56413,\"start\":56406},{\"end\":56426,\"start\":56420},{\"end\":56738,\"start\":56728},{\"end\":56751,\"start\":56745},{\"end\":57000,\"start\":56992},{\"end\":57015,\"start\":57006},{\"end\":57027,\"start\":57022},{\"end\":57041,\"start\":57032},{\"end\":57053,\"start\":57047},{\"end\":57368,\"start\":57367},{\"end\":57384,\"start\":57379},{\"end\":57622,\"start\":57616},{\"end\":57848,\"start\":57842},{\"end\":57862,\"start\":57856},{\"end\":58124,\"start\":58118},{\"end\":58138,\"start\":58132},{\"end\":58150,\"start\":58145},{\"end\":58372,\"start\":58368},{\"end\":58384,\"start\":58377},{\"end\":58396,\"start\":58390},{\"end\":58411,\"start\":58403},{\"end\":58420,\"start\":58417},{\"end\":58430,\"start\":58427},{\"end\":58723,\"start\":58719},{\"end\":58736,\"start\":58728},{\"end\":58748,\"start\":58741},{\"end\":58762,\"start\":58755},{\"end\":58764,\"start\":58763},{\"end\":58774,\"start\":58770},{\"end\":59034,\"start\":59027},{\"end\":59046,\"start\":59040},{\"end\":59059,\"start\":59053},{\"end\":59072,\"start\":59070},{\"end\":59085,\"start\":59081},{\"end\":59095,\"start\":59090},{\"end\":59109,\"start\":59103},{\"end\":59402,\"start\":59398},{\"end\":59416,\"start\":59411},{\"end\":59430,\"start\":59424},{\"end\":59684,\"start\":59683},{\"end\":59700,\"start\":59692},{\"end\":59713,\"start\":59706},{\"end\":59724,\"start\":59721},{\"end\":59734,\"start\":59730},{\"end\":59751,\"start\":59745},{\"end\":59765,\"start\":59761},{\"end\":60083,\"start\":60079},{\"end\":60093,\"start\":60089},{\"end\":60106,\"start\":60100},{\"end\":60122,\"start\":60116},{\"end\":60439,\"start\":60433},{\"end\":60460,\"start\":60449},{\"end\":60815,\"start\":60810},{\"end\":60828,\"start\":60825},{\"end\":60839,\"start\":60835},{\"end\":60856,\"start\":60849},{\"end\":61116,\"start\":61111},{\"end\":61130,\"start\":61126},{\"end\":61145,\"start\":61142},{\"end\":61156,\"start\":61152},{\"end\":61173,\"start\":61166},{\"end\":61546,\"start\":61539},{\"end\":61567,\"start\":61557},{\"end\":61587,\"start\":61581},{\"end\":61601,\"start\":61596},{\"end\":61960,\"start\":61956},{\"end\":61977,\"start\":61970},{\"end\":62279,\"start\":62272},{\"end\":62297,\"start\":62288},{\"end\":62317,\"start\":62313},{\"end\":62331,\"start\":62327},{\"end\":62719,\"start\":62712},{\"end\":62737,\"start\":62728},{\"end\":62757,\"start\":62753},{\"end\":63061,\"start\":63055},{\"end\":63083,\"start\":63077},{\"end\":63349,\"start\":63343},{\"end\":63371,\"start\":63365},{\"end\":63386,\"start\":63378},{\"end\":63644,\"start\":63638},{\"end\":63659,\"start\":63653},{\"end\":63675,\"start\":63669},{\"end\":63689,\"start\":63685},{\"end\":63986,\"start\":63980},{\"end\":64002,\"start\":63996},{\"end\":64010,\"start\":64003},{\"end\":64023,\"start\":64018},{\"end\":64038,\"start\":64032},{\"end\":64306,\"start\":64303},{\"end\":64319,\"start\":64314},{\"end\":64336,\"start\":64331},{\"end\":64338,\"start\":64337},{\"end\":64567,\"start\":64562},{\"end\":64579,\"start\":64574},{\"end\":64597,\"start\":64591},{\"end\":64981,\"start\":64975},{\"end\":65002,\"start\":64994},{\"end\":65015,\"start\":65011},{\"end\":65032,\"start\":65028},{\"end\":65050,\"start\":65044},{\"end\":65402,\"start\":65396},{\"end\":65416,\"start\":65409},{\"end\":65432,\"start\":65425},{\"end\":65443,\"start\":65439},{\"end\":65762,\"start\":65757},{\"end\":65771,\"start\":65769},{\"end\":65956,\"start\":65950},{\"end\":65958,\"start\":65957},{\"end\":66205,\"start\":66200},{\"end\":66226,\"start\":66220},{\"end\":66245,\"start\":66237},{\"end\":66459,\"start\":66453},{\"end\":66473,\"start\":66469},{\"end\":66487,\"start\":66483},{\"end\":66501,\"start\":66496},{\"end\":66518,\"start\":66513},{\"end\":66531,\"start\":66526},{\"end\":66533,\"start\":66532},{\"end\":66547,\"start\":66541},{\"end\":66561,\"start\":66556},{\"end\":66863,\"start\":66860},{\"end\":66876,\"start\":66870},{\"end\":66890,\"start\":66883},{\"end\":67186,\"start\":67179},{\"end\":67198,\"start\":67193},{\"end\":67211,\"start\":67203},{\"end\":67225,\"start\":67217},{\"end\":67237,\"start\":67233},{\"end\":67247,\"start\":67244},{\"end\":67531,\"start\":67525},{\"end\":67543,\"start\":67538},{\"end\":67557,\"start\":67550},{\"end\":67567,\"start\":67564},{\"end\":67578,\"start\":67573},{\"end\":67594,\"start\":67590},{\"end\":67877,\"start\":67874},{\"end\":67886,\"start\":67882},{\"end\":67903,\"start\":67894},{\"end\":67905,\"start\":67904},{\"end\":67917,\"start\":67914},{\"end\":68216,\"start\":68213},{\"end\":68232,\"start\":68221},{\"end\":68246,\"start\":68241},{\"end\":68248,\"start\":68247},{\"end\":68262,\"start\":68256},{\"end\":68574,\"start\":68570},{\"end\":68584,\"start\":68579},{\"end\":68593,\"start\":68590},{\"end\":68603,\"start\":68598},{\"end\":68616,\"start\":68610}]", "bib_author_last_name": "[{\"end\":49922,\"start\":49919},{\"end\":49931,\"start\":49929},{\"end\":49949,\"start\":49944},{\"end\":49957,\"start\":49951},{\"end\":50171,\"start\":50163},{\"end\":50186,\"start\":50183},{\"end\":50201,\"start\":50195},{\"end\":50442,\"start\":50438},{\"end\":50455,\"start\":50453},{\"end\":50471,\"start\":50466},{\"end\":50483,\"start\":50479},{\"end\":50883,\"start\":50880},{\"end\":50912,\"start\":50892},{\"end\":50930,\"start\":50922},{\"end\":50946,\"start\":50938},{\"end\":50963,\"start\":50955},{\"end\":50979,\"start\":50972},{\"end\":50987,\"start\":50981},{\"end\":51425,\"start\":51416},{\"end\":51436,\"start\":51431},{\"end\":51449,\"start\":51443},{\"end\":51754,\"start\":51748},{\"end\":51770,\"start\":51765},{\"end\":51782,\"start\":51779},{\"end\":51802,\"start\":51793},{\"end\":52081,\"start\":52074},{\"end\":52097,\"start\":52092},{\"end\":52113,\"start\":52106},{\"end\":52406,\"start\":52400},{\"end\":52424,\"start\":52417},{\"end\":52688,\"start\":52686},{\"end\":52703,\"start\":52698},{\"end\":52717,\"start\":52714},{\"end\":52727,\"start\":52724},{\"end\":52939,\"start\":52937},{\"end\":52956,\"start\":52952},{\"end\":52972,\"start\":52965},{\"end\":53264,\"start\":53262},{\"end\":53280,\"start\":53273},{\"end\":53503,\"start\":53501},{\"end\":53514,\"start\":53510},{\"end\":53529,\"start\":53524},{\"end\":53542,\"start\":53539},{\"end\":53550,\"start\":53548},{\"end\":53565,\"start\":53561},{\"end\":53839,\"start\":53830},{\"end\":53853,\"start\":53847},{\"end\":54118,\"start\":54112},{\"end\":54142,\"start\":54131},{\"end\":54448,\"start\":54442},{\"end\":54472,\"start\":54461},{\"end\":54762,\"start\":54756},{\"end\":54777,\"start\":54770},{\"end\":54788,\"start\":54784},{\"end\":55036,\"start\":55026},{\"end\":55056,\"start\":55045},{\"end\":55274,\"start\":55272},{\"end\":55288,\"start\":55285},{\"end\":55302,\"start\":55298},{\"end\":55315,\"start\":55313},{\"end\":55325,\"start\":55322},{\"end\":55337,\"start\":55335},{\"end\":55640,\"start\":55635},{\"end\":55656,\"start\":55652},{\"end\":55670,\"start\":55667},{\"end\":55683,\"start\":55680},{\"end\":55699,\"start\":55694},{\"end\":56050,\"start\":56044},{\"end\":56060,\"start\":56056},{\"end\":56076,\"start\":56069},{\"end\":56393,\"start\":56389},{\"end\":56404,\"start\":56400},{\"end\":56418,\"start\":56414},{\"end\":56434,\"start\":56427},{\"end\":56743,\"start\":56739},{\"end\":56759,\"start\":56752},{\"end\":57004,\"start\":57001},{\"end\":57020,\"start\":57016},{\"end\":57030,\"start\":57028},{\"end\":57045,\"start\":57042},{\"end\":57056,\"start\":57054},{\"end\":57377,\"start\":57369},{\"end\":57391,\"start\":57385},{\"end\":57395,\"start\":57393},{\"end\":57628,\"start\":57623},{\"end\":57854,\"start\":57849},{\"end\":57867,\"start\":57863},{\"end\":58130,\"start\":58125},{\"end\":58143,\"start\":58139},{\"end\":58159,\"start\":58151},{\"end\":58375,\"start\":58373},{\"end\":58388,\"start\":58385},{\"end\":58401,\"start\":58397},{\"end\":58415,\"start\":58412},{\"end\":58425,\"start\":58421},{\"end\":58433,\"start\":58431},{\"end\":58726,\"start\":58724},{\"end\":58739,\"start\":58737},{\"end\":58753,\"start\":58749},{\"end\":58768,\"start\":58765},{\"end\":58780,\"start\":58775},{\"end\":59038,\"start\":59035},{\"end\":59051,\"start\":59047},{\"end\":59068,\"start\":59060},{\"end\":59079,\"start\":59073},{\"end\":59088,\"start\":59086},{\"end\":59101,\"start\":59096},{\"end\":59114,\"start\":59110},{\"end\":59122,\"start\":59116},{\"end\":59409,\"start\":59403},{\"end\":59422,\"start\":59417},{\"end\":59435,\"start\":59431},{\"end\":59690,\"start\":59685},{\"end\":59704,\"start\":59701},{\"end\":59719,\"start\":59714},{\"end\":59728,\"start\":59725},{\"end\":59743,\"start\":59735},{\"end\":59759,\"start\":59752},{\"end\":59772,\"start\":59766},{\"end\":59781,\"start\":59774},{\"end\":60087,\"start\":60084},{\"end\":60098,\"start\":60094},{\"end\":60114,\"start\":60107},{\"end\":60128,\"start\":60123},{\"end\":60447,\"start\":60440},{\"end\":60468,\"start\":60461},{\"end\":60823,\"start\":60816},{\"end\":60833,\"start\":60829},{\"end\":60847,\"start\":60840},{\"end\":60861,\"start\":60857},{\"end\":61124,\"start\":61117},{\"end\":61140,\"start\":61131},{\"end\":61150,\"start\":61146},{\"end\":61164,\"start\":61157},{\"end\":61178,\"start\":61174},{\"end\":61555,\"start\":61547},{\"end\":61579,\"start\":61568},{\"end\":61594,\"start\":61588},{\"end\":61611,\"start\":61602},{\"end\":61968,\"start\":61961},{\"end\":61988,\"start\":61978},{\"end\":62286,\"start\":62280},{\"end\":62311,\"start\":62298},{\"end\":62325,\"start\":62318},{\"end\":62346,\"start\":62332},{\"end\":62726,\"start\":62720},{\"end\":62751,\"start\":62738},{\"end\":62772,\"start\":62758},{\"end\":63075,\"start\":63062},{\"end\":63088,\"start\":63084},{\"end\":63363,\"start\":63350},{\"end\":63376,\"start\":63372},{\"end\":63393,\"start\":63387},{\"end\":63651,\"start\":63645},{\"end\":63667,\"start\":63660},{\"end\":63683,\"start\":63676},{\"end\":63695,\"start\":63690},{\"end\":63994,\"start\":63987},{\"end\":64016,\"start\":64011},{\"end\":64030,\"start\":64024},{\"end\":64042,\"start\":64039},{\"end\":64312,\"start\":64307},{\"end\":64329,\"start\":64320},{\"end\":64346,\"start\":64339},{\"end\":64572,\"start\":64568},{\"end\":64589,\"start\":64580},{\"end\":64605,\"start\":64598},{\"end\":64992,\"start\":64982},{\"end\":65009,\"start\":65003},{\"end\":65026,\"start\":65016},{\"end\":65042,\"start\":65033},{\"end\":65064,\"start\":65051},{\"end\":65407,\"start\":65403},{\"end\":65423,\"start\":65417},{\"end\":65437,\"start\":65433},{\"end\":65452,\"start\":65444},{\"end\":65767,\"start\":65763},{\"end\":65776,\"start\":65772},{\"end\":65965,\"start\":65959},{\"end\":66218,\"start\":66206},{\"end\":66235,\"start\":66227},{\"end\":66255,\"start\":66246},{\"end\":66467,\"start\":66460},{\"end\":66481,\"start\":66474},{\"end\":66494,\"start\":66488},{\"end\":66511,\"start\":66502},{\"end\":66524,\"start\":66519},{\"end\":66539,\"start\":66534},{\"end\":66554,\"start\":66548},{\"end\":66572,\"start\":66562},{\"end\":66868,\"start\":66864},{\"end\":66881,\"start\":66877},{\"end\":66896,\"start\":66891},{\"end\":67191,\"start\":67187},{\"end\":67201,\"start\":67199},{\"end\":67215,\"start\":67212},{\"end\":67231,\"start\":67226},{\"end\":67242,\"start\":67238},{\"end\":67251,\"start\":67248},{\"end\":67536,\"start\":67532},{\"end\":67548,\"start\":67544},{\"end\":67562,\"start\":67558},{\"end\":67571,\"start\":67568},{\"end\":67588,\"start\":67579},{\"end\":67598,\"start\":67595},{\"end\":67872,\"start\":67863},{\"end\":67880,\"start\":67878},{\"end\":67892,\"start\":67887},{\"end\":67912,\"start\":67906},{\"end\":67923,\"start\":67918},{\"end\":67929,\"start\":67925},{\"end\":68219,\"start\":68217},{\"end\":68239,\"start\":68233},{\"end\":68254,\"start\":68249},{\"end\":68268,\"start\":68263},{\"end\":68577,\"start\":68575},{\"end\":68588,\"start\":68585},{\"end\":68596,\"start\":68594},{\"end\":68608,\"start\":68604},{\"end\":68620,\"start\":68617}]", "bib_entry": "[{\"attributes\":{\"doi\":\"CoRR abs/1607.06450\",\"id\":\"b0\"},\"end\":50082,\"start\":49892},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11212020},\"end\":50380,\"start\":50084},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":207562781},\"end\":50773,\"start\":50382},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":5590763},\"end\":51359,\"start\":50775},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":207240067},\"end\":51658,\"start\":51361},{\"attributes\":{\"doi\":\"CoRR abs/1810.04805\",\"id\":\"b5\"},\"end\":52004,\"start\":51660},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":38116062},\"end\":52341,\"start\":52006},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":16619709},\"end\":52630,\"start\":52343},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":206594692},\"end\":52893,\"start\":52632},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":10246046},\"end\":53170,\"start\":52895},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":9124261},\"end\":53458,\"start\":53172},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":13907106},\"end\":53738,\"start\":53460},{\"attributes\":{\"doi\":\"CoRR abs/1606.08415\",\"id\":\"b12\"},\"end\":54025,\"start\":53740},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1159769},\"end\":54371,\"start\":54027},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":11810482},\"end\":54699,\"start\":54373},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":7200347},\"end\":54995,\"start\":54701},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":1915014},\"end\":55196,\"start\":54997},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":8527315},\"end\":55552,\"start\":55198},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":49644765},\"end\":55965,\"start\":55554},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":207204749},\"end\":56297,\"start\":55967},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":23787675},\"end\":56684,\"start\":56299},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":52127932},\"end\":56912,\"start\":56686},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":207239982},\"end\":57321,\"start\":56914},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":6628106},\"end\":57530,\"start\":57323},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":207168823},\"end\":57803,\"start\":57532},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":14698210},\"end\":58059,\"start\":57805},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":58370896},\"end\":58319,\"start\":58061},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":21066930},\"end\":58662,\"start\":58321},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":53081097},\"end\":58977,\"start\":58664},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":15280949},\"end\":59330,\"start\":58979},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":14604122},\"end\":59629,\"start\":59332},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":3608234},\"end\":59993,\"start\":59631},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":50775765},\"end\":60376,\"start\":59995},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":1012652},\"end\":60746,\"start\":60378},{\"attributes\":{\"doi\":\"CoRR abs/1301.3781\",\"id\":\"b34\"},\"end\":61032,\"start\":60748},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":16447573},\"end\":61448,\"start\":61034},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":10174110},\"end\":61893,\"start\":61450},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":49313245},\"end\":62211,\"start\":61895},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":10795036},\"end\":62639,\"start\":62213},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":207178809},\"end\":63017,\"start\":62641},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":467086},\"end\":63282,\"start\":63019},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":7285098},\"end\":63574,\"start\":63284},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":8047550},\"end\":63926,\"start\":63576},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":16274986},\"end\":64268,\"start\":63928},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":875571},\"end\":64505,\"start\":64270},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":3725815},\"end\":64906,\"start\":64507},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":6844431},\"end\":65307,\"start\":64908},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":52100282},\"end\":65672,\"start\":65309},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":39847715},\"end\":65948,\"start\":65674},{\"attributes\":{\"id\":\"b49\"},\"end\":66157,\"start\":65950},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":7118498},\"end\":66424,\"start\":66159},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":13756489},\"end\":66805,\"start\":66426},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":4833213},\"end\":67099,\"start\":66807},{\"attributes\":{\"id\":\"b53\"},\"end\":67433,\"start\":67101},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":14152303},\"end\":67829,\"start\":67435},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":5362246},\"end\":68142,\"start\":67831},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":6392154},\"end\":68510,\"start\":68144},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":2023817},\"end\":68846,\"start\":68512}]", "bib_title": "[{\"end\":50153,\"start\":50084},{\"end\":50433,\"start\":50382},{\"end\":50868,\"start\":50775},{\"end\":51409,\"start\":51361},{\"end\":52068,\"start\":52006},{\"end\":52386,\"start\":52343},{\"end\":52676,\"start\":52632},{\"end\":52927,\"start\":52895},{\"end\":53252,\"start\":53172},{\"end\":53490,\"start\":53460},{\"end\":54103,\"start\":54027},{\"end\":54433,\"start\":54373},{\"end\":54745,\"start\":54701},{\"end\":55019,\"start\":54997},{\"end\":55264,\"start\":55198},{\"end\":55629,\"start\":55554},{\"end\":56034,\"start\":55967},{\"end\":56376,\"start\":56299},{\"end\":56726,\"start\":56686},{\"end\":56990,\"start\":56914},{\"end\":57365,\"start\":57323},{\"end\":57614,\"start\":57532},{\"end\":57840,\"start\":57805},{\"end\":58116,\"start\":58061},{\"end\":58366,\"start\":58321},{\"end\":58717,\"start\":58664},{\"end\":59025,\"start\":58979},{\"end\":59396,\"start\":59332},{\"end\":59681,\"start\":59631},{\"end\":60077,\"start\":59995},{\"end\":60431,\"start\":60378},{\"end\":61109,\"start\":61034},{\"end\":61537,\"start\":61450},{\"end\":61954,\"start\":61895},{\"end\":62270,\"start\":62213},{\"end\":62710,\"start\":62641},{\"end\":63053,\"start\":63019},{\"end\":63341,\"start\":63284},{\"end\":63636,\"start\":63576},{\"end\":63978,\"start\":63928},{\"end\":64301,\"start\":64270},{\"end\":64560,\"start\":64507},{\"end\":64973,\"start\":64908},{\"end\":65394,\"start\":65309},{\"end\":65755,\"start\":65674},{\"end\":66198,\"start\":66159},{\"end\":66451,\"start\":66426},{\"end\":66858,\"start\":66807},{\"end\":67523,\"start\":67435},{\"end\":67861,\"start\":67831},{\"end\":68211,\"start\":68144},{\"end\":68568,\"start\":68512}]", "bib_author": "[{\"end\":49924,\"start\":49913},{\"end\":49933,\"start\":49924},{\"end\":49951,\"start\":49933},{\"end\":49959,\"start\":49951},{\"end\":50173,\"start\":50155},{\"end\":50188,\"start\":50173},{\"end\":50203,\"start\":50188},{\"end\":50444,\"start\":50435},{\"end\":50457,\"start\":50444},{\"end\":50473,\"start\":50457},{\"end\":50485,\"start\":50473},{\"end\":50885,\"start\":50870},{\"end\":50914,\"start\":50885},{\"end\":50932,\"start\":50914},{\"end\":50948,\"start\":50932},{\"end\":50965,\"start\":50948},{\"end\":50981,\"start\":50965},{\"end\":50989,\"start\":50981},{\"end\":51427,\"start\":51411},{\"end\":51438,\"start\":51427},{\"end\":51451,\"start\":51438},{\"end\":51756,\"start\":51742},{\"end\":51772,\"start\":51756},{\"end\":51784,\"start\":51772},{\"end\":51804,\"start\":51784},{\"end\":52083,\"start\":52070},{\"end\":52099,\"start\":52083},{\"end\":52115,\"start\":52099},{\"end\":52392,\"start\":52388},{\"end\":52408,\"start\":52392},{\"end\":52426,\"start\":52408},{\"end\":52690,\"start\":52678},{\"end\":52705,\"start\":52690},{\"end\":52719,\"start\":52705},{\"end\":52729,\"start\":52719},{\"end\":52941,\"start\":52929},{\"end\":52958,\"start\":52941},{\"end\":52974,\"start\":52958},{\"end\":53266,\"start\":53254},{\"end\":53282,\"start\":53266},{\"end\":53505,\"start\":53492},{\"end\":53516,\"start\":53505},{\"end\":53531,\"start\":53516},{\"end\":53544,\"start\":53531},{\"end\":53552,\"start\":53544},{\"end\":53567,\"start\":53552},{\"end\":53841,\"start\":53826},{\"end\":53855,\"start\":53841},{\"end\":54120,\"start\":54105},{\"end\":54144,\"start\":54120},{\"end\":54450,\"start\":54435},{\"end\":54474,\"start\":54450},{\"end\":54764,\"start\":54747},{\"end\":54779,\"start\":54764},{\"end\":54790,\"start\":54779},{\"end\":55038,\"start\":55021},{\"end\":55058,\"start\":55038},{\"end\":55276,\"start\":55266},{\"end\":55290,\"start\":55276},{\"end\":55304,\"start\":55290},{\"end\":55317,\"start\":55304},{\"end\":55327,\"start\":55317},{\"end\":55339,\"start\":55327},{\"end\":55642,\"start\":55631},{\"end\":55658,\"start\":55642},{\"end\":55672,\"start\":55658},{\"end\":55685,\"start\":55672},{\"end\":55701,\"start\":55685},{\"end\":56052,\"start\":56036},{\"end\":56062,\"start\":56052},{\"end\":56078,\"start\":56062},{\"end\":56395,\"start\":56378},{\"end\":56406,\"start\":56395},{\"end\":56420,\"start\":56406},{\"end\":56436,\"start\":56420},{\"end\":56745,\"start\":56728},{\"end\":56761,\"start\":56745},{\"end\":57006,\"start\":56992},{\"end\":57022,\"start\":57006},{\"end\":57032,\"start\":57022},{\"end\":57047,\"start\":57032},{\"end\":57058,\"start\":57047},{\"end\":57379,\"start\":57367},{\"end\":57393,\"start\":57379},{\"end\":57397,\"start\":57393},{\"end\":57630,\"start\":57616},{\"end\":57856,\"start\":57842},{\"end\":57869,\"start\":57856},{\"end\":58132,\"start\":58118},{\"end\":58145,\"start\":58132},{\"end\":58161,\"start\":58145},{\"end\":58377,\"start\":58368},{\"end\":58390,\"start\":58377},{\"end\":58403,\"start\":58390},{\"end\":58417,\"start\":58403},{\"end\":58427,\"start\":58417},{\"end\":58435,\"start\":58427},{\"end\":58728,\"start\":58719},{\"end\":58741,\"start\":58728},{\"end\":58755,\"start\":58741},{\"end\":58770,\"start\":58755},{\"end\":58782,\"start\":58770},{\"end\":59040,\"start\":59027},{\"end\":59053,\"start\":59040},{\"end\":59070,\"start\":59053},{\"end\":59081,\"start\":59070},{\"end\":59090,\"start\":59081},{\"end\":59103,\"start\":59090},{\"end\":59116,\"start\":59103},{\"end\":59124,\"start\":59116},{\"end\":59411,\"start\":59398},{\"end\":59424,\"start\":59411},{\"end\":59437,\"start\":59424},{\"end\":59692,\"start\":59683},{\"end\":59706,\"start\":59692},{\"end\":59721,\"start\":59706},{\"end\":59730,\"start\":59721},{\"end\":59745,\"start\":59730},{\"end\":59761,\"start\":59745},{\"end\":59774,\"start\":59761},{\"end\":59783,\"start\":59774},{\"end\":60089,\"start\":60079},{\"end\":60100,\"start\":60089},{\"end\":60116,\"start\":60100},{\"end\":60130,\"start\":60116},{\"end\":60449,\"start\":60433},{\"end\":60470,\"start\":60449},{\"end\":60825,\"start\":60810},{\"end\":60835,\"start\":60825},{\"end\":60849,\"start\":60835},{\"end\":60863,\"start\":60849},{\"end\":61126,\"start\":61111},{\"end\":61142,\"start\":61126},{\"end\":61152,\"start\":61142},{\"end\":61166,\"start\":61152},{\"end\":61180,\"start\":61166},{\"end\":61557,\"start\":61539},{\"end\":61581,\"start\":61557},{\"end\":61596,\"start\":61581},{\"end\":61613,\"start\":61596},{\"end\":61970,\"start\":61956},{\"end\":61990,\"start\":61970},{\"end\":62288,\"start\":62272},{\"end\":62313,\"start\":62288},{\"end\":62327,\"start\":62313},{\"end\":62348,\"start\":62327},{\"end\":62728,\"start\":62712},{\"end\":62753,\"start\":62728},{\"end\":62774,\"start\":62753},{\"end\":63077,\"start\":63055},{\"end\":63090,\"start\":63077},{\"end\":63365,\"start\":63343},{\"end\":63378,\"start\":63365},{\"end\":63395,\"start\":63378},{\"end\":63653,\"start\":63638},{\"end\":63669,\"start\":63653},{\"end\":63685,\"start\":63669},{\"end\":63697,\"start\":63685},{\"end\":63996,\"start\":63980},{\"end\":64018,\"start\":63996},{\"end\":64032,\"start\":64018},{\"end\":64044,\"start\":64032},{\"end\":64314,\"start\":64303},{\"end\":64331,\"start\":64314},{\"end\":64348,\"start\":64331},{\"end\":64574,\"start\":64562},{\"end\":64591,\"start\":64574},{\"end\":64607,\"start\":64591},{\"end\":64994,\"start\":64975},{\"end\":65011,\"start\":64994},{\"end\":65028,\"start\":65011},{\"end\":65044,\"start\":65028},{\"end\":65066,\"start\":65044},{\"end\":65409,\"start\":65396},{\"end\":65425,\"start\":65409},{\"end\":65439,\"start\":65425},{\"end\":65454,\"start\":65439},{\"end\":65769,\"start\":65757},{\"end\":65778,\"start\":65769},{\"end\":65967,\"start\":65950},{\"end\":66220,\"start\":66200},{\"end\":66237,\"start\":66220},{\"end\":66257,\"start\":66237},{\"end\":66469,\"start\":66453},{\"end\":66483,\"start\":66469},{\"end\":66496,\"start\":66483},{\"end\":66513,\"start\":66496},{\"end\":66526,\"start\":66513},{\"end\":66541,\"start\":66526},{\"end\":66556,\"start\":66541},{\"end\":66574,\"start\":66556},{\"end\":66870,\"start\":66860},{\"end\":66883,\"start\":66870},{\"end\":66898,\"start\":66883},{\"end\":67193,\"start\":67179},{\"end\":67203,\"start\":67193},{\"end\":67217,\"start\":67203},{\"end\":67233,\"start\":67217},{\"end\":67244,\"start\":67233},{\"end\":67253,\"start\":67244},{\"end\":67538,\"start\":67525},{\"end\":67550,\"start\":67538},{\"end\":67564,\"start\":67550},{\"end\":67573,\"start\":67564},{\"end\":67590,\"start\":67573},{\"end\":67600,\"start\":67590},{\"end\":67874,\"start\":67863},{\"end\":67882,\"start\":67874},{\"end\":67894,\"start\":67882},{\"end\":67914,\"start\":67894},{\"end\":67925,\"start\":67914},{\"end\":67931,\"start\":67925},{\"end\":68221,\"start\":68213},{\"end\":68241,\"start\":68221},{\"end\":68256,\"start\":68241},{\"end\":68270,\"start\":68256},{\"end\":68579,\"start\":68570},{\"end\":68590,\"start\":68579},{\"end\":68598,\"start\":68590},{\"end\":68610,\"start\":68598},{\"end\":68622,\"start\":68610}]", "bib_venue": "[{\"end\":50228,\"start\":50224},{\"end\":50527,\"start\":50506},{\"end\":51016,\"start\":51011},{\"end\":51497,\"start\":51474},{\"end\":52161,\"start\":52138},{\"end\":52754,\"start\":52750},{\"end\":53020,\"start\":52997},{\"end\":53307,\"start\":53303},{\"end\":53590,\"start\":53587},{\"end\":54186,\"start\":54165},{\"end\":54499,\"start\":54495},{\"end\":55366,\"start\":55361},{\"end\":55745,\"start\":55723},{\"end\":56118,\"start\":56098},{\"end\":56461,\"start\":56457},{\"end\":56786,\"start\":56782},{\"end\":57104,\"start\":57081},{\"end\":57422,\"start\":57418},{\"end\":57663,\"start\":57655},{\"end\":57909,\"start\":57899},{\"end\":58477,\"start\":58456},{\"end\":58811,\"start\":58805},{\"end\":59149,\"start\":59145},{\"end\":59808,\"start\":59804},{\"end\":60170,\"start\":60150},{\"end\":60514,\"start\":60492},{\"end\":61208,\"start\":61201},{\"end\":61659,\"start\":61636},{\"end\":62405,\"start\":62368},{\"end\":62814,\"start\":62794},{\"end\":63118,\"start\":63111},{\"end\":63420,\"start\":63416},{\"end\":63737,\"start\":63717},{\"end\":64084,\"start\":64064},{\"end\":64720,\"start\":64672},{\"end\":65481,\"start\":65476},{\"end\":65803,\"start\":65799},{\"end\":66282,\"start\":66278},{\"end\":66938,\"start\":66918},{\"end\":67623,\"start\":67620},{\"end\":67973,\"start\":67952},{\"end\":68312,\"start\":68291},{\"end\":68666,\"start\":68644},{\"end\":49911,\"start\":49892},{\"end\":50222,\"start\":50203},{\"end\":50504,\"start\":50485},{\"end\":51009,\"start\":50989},{\"end\":51472,\"start\":51451},{\"end\":51740,\"start\":51660},{\"end\":52136,\"start\":52115},{\"end\":52459,\"start\":52426},{\"end\":52748,\"start\":52729},{\"end\":52995,\"start\":52974},{\"end\":53301,\"start\":53282},{\"end\":53585,\"start\":53567},{\"end\":53824,\"start\":53740},{\"end\":54163,\"start\":54144},{\"end\":54493,\"start\":54474},{\"end\":54840,\"start\":54790},{\"end\":55076,\"start\":55058},{\"end\":55359,\"start\":55339},{\"end\":55721,\"start\":55701},{\"end\":56096,\"start\":56078},{\"end\":56455,\"start\":56436},{\"end\":56780,\"start\":56761},{\"end\":57079,\"start\":57058},{\"end\":57416,\"start\":57397},{\"end\":57653,\"start\":57630},{\"end\":57897,\"start\":57869},{\"end\":58169,\"start\":58161},{\"end\":58454,\"start\":58435},{\"end\":58803,\"start\":58782},{\"end\":59143,\"start\":59124},{\"end\":59460,\"start\":59437},{\"end\":59802,\"start\":59783},{\"end\":60148,\"start\":60130},{\"end\":60490,\"start\":60470},{\"end\":60808,\"start\":60748},{\"end\":61199,\"start\":61180},{\"end\":61634,\"start\":61613},{\"end\":62013,\"start\":61990},{\"end\":62366,\"start\":62348},{\"end\":62792,\"start\":62774},{\"end\":63109,\"start\":63090},{\"end\":63414,\"start\":63395},{\"end\":63715,\"start\":63697},{\"end\":64062,\"start\":64044},{\"end\":64367,\"start\":64348},{\"end\":64670,\"start\":64607},{\"end\":65085,\"start\":65066},{\"end\":65474,\"start\":65454},{\"end\":65797,\"start\":65778},{\"end\":66026,\"start\":65967},{\"end\":66276,\"start\":66257},{\"end\":66578,\"start\":66574},{\"end\":66916,\"start\":66898},{\"end\":67177,\"start\":67101},{\"end\":67618,\"start\":67600},{\"end\":67950,\"start\":67931},{\"end\":68289,\"start\":68270},{\"end\":68642,\"start\":68622}]"}}}, "year": 2023, "month": 12, "day": 17}