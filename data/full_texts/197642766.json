{"id": 197642766, "updated": "2022-02-06 00:48:44.823", "metadata": {"title": "A Framework for Collaborative Learning in Secure High-Dimensional Space", "authors": "[{\"middle\":[],\"last\":\"Imani\",\"first\":\"Mohsen\"},{\"middle\":[],\"last\":\"Kim\",\"first\":\"Yeseong\"},{\"middle\":[],\"last\":\"Riazi\",\"first\":\"Sadegh\"},{\"middle\":[],\"last\":\"Messerly\",\"first\":\"John\"},{\"middle\":[],\"last\":\"Liu\",\"first\":\"Patric\"},{\"middle\":[],\"last\":\"Koushanfar\",\"first\":\"Farinaz\"},{\"middle\":[],\"last\":\"Rosing\",\"first\":\"Tajana\"}]", "venue": "2019 IEEE 12th International Conference on Cloud Computing (CLOUD)", "journal": "2019 IEEE 12th International Conference on Cloud Computing (CLOUD)", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "As the amount of data generated by the Internet of the Things (IoT) devices keeps increasing, many applications need to offload computation to the cloud. However, it often entails risks due to security and privacy issues. Encryption and decryption methods add to an already significant computational burden. In this paper, we propose a novel framework, called SecureHD, which provides a secure learning solution based on the idea of high-dimensional (HD) computing. We encode original data into secure, high-dimensional vectors. The training is performed with the encoded vectors. Thus, applications can send their data to the cloud with no security concerns, while the cloud can perform the offloaded tasks without additional decryption steps. In particular, we propose a novel HD-based classification algorithm which is suitable to handle a large amount of data that the cloud typically processes. In addition, we also show how SecureHD can recover the encoded data in a lossless manner. In our evaluation, we show that the proposed SecureHD framework can perform the encoding and decoding tasks 145.6\u00d7 and 6.8\u00d7 faster than a state-of-the-art encryption/decryption library running on the contemporary CPU. In addition, our learning method achieves high accuracy of 95% on average for diverse practical classification tasks including cloud-scale datasets.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2970402754", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/IEEEcloud/ImaniKRMLKR19", "doi": "10.1109/cloud.2019.00076"}}, "content": {"source": {"pdf_hash": "c546daa9afd0e62aa157ca059d1b975524376157", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "d5a8abd2755ae41b5edc241e2ae1f2ac7f2e9c8a", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c546daa9afd0e62aa157ca059d1b975524376157.txt", "contents": "\nA Framework for Collaborative Learning in Secure High-Dimensional Space\n\n\nMohsen Imani moimani@ucsd.edu \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nYeseong Kim \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nM Sadegh Riazi mriazi@ucsd.edu \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nJohn Messerly jmesserl@ucsd.edu \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nPatric Liu ptliu@ucsd.edu \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nFarinaz Koushanfar fkoushanfar@ucsd.edu \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nTajana Rosing tajana@ucsd.edu \nUniversity of California San Diego\nLa Jolla92093CAUSA\n\nA Framework for Collaborative Learning in Secure High-Dimensional Space\n10.1109/CLOUD.2019.00076Machine learningSecure learningBrain-inspired computingHyperdimensional computingDistributed learning\nAs the amount of data generated by the Internet of the Things (IoT) devices keeps increasing, many applications need to offload computation to the cloud. However, it often entails risks due to security and privacy issues. Encryption and decryption methods add to an already significant computational burden. In this paper, we propose a novel framework, called SecureHD, which provides a secure learning solution based on the idea of high-dimensional (HD) computing. We encode original data into secure, high-dimensional vectors. The training is performed with the encoded vectors. Thus, applications can send their data to the cloud with no security concerns, while the cloud can perform the offloaded tasks without additional decryption steps. In particular, we propose a novel HD-based classification algorithm which is suitable to handle a large amount of data that the cloud typically processes. In addition, we also show how SecureHD can recover the encoded data in a lossless manner. In our evaluation, we show that the proposed SecureHD framework can perform the encoding and decoding tasks 145.6\u00d7 and 6.8\u00d7 faster than a state-of-the-art encryption/decryption library running on the contemporary CPU. In addition, our learning method achieves high accuracy of 95% on average for diverse practical classification tasks including cloud-scale datasets.\n\nI. INTRODUCTION\n\nInternet of Things (IoT) applications often analyze collected data using machine learning algorithms. As the amount of the data keeps increasing, many applications send the data to powerful systems, e.g., data centers, to run the learning algorithms [1], [2], [3]. On the one hand, sending the original data is not desirable due to privacy and security concerns [4], [5], [6], [7]. On the other hand, many machine learning models require unencrypted (plaintext) data, e.g., original images, to train models and perform inference. When offloading the computation tasks, sensitive information is exposed to the untrustworthy cloud system which is susceptible to internal and external attacks [8], [9], [10] . In many IoT systems, the learning procedure should be performed with the data that is held by a large number of user devices at the edge of the Internet. These users may be unwilling to share the original data with the cloud and other users [11], [12], [13], [14].\n\nAn existing strategy applicable to this scenario is exploiting Homomorphic Encryption (HE). HE enables encrypting the * Mohsen Imani and Yeseong Kim contributed equally to this research. raw data and allowing certain operations to be performed directly on the ciphertext without decryption [15]. However, this approach significantly increases computation burden in addition to the costly learning procedures. For example, in our evaluation, with Microsoft SEAL, a state-of-the-art homomorphic encryption library [16], it takes around 14 days to encrypt all of the 28x28 pixel images in the entire MNIST dataset, and increases the data size by 28 times. More recently, Google presented a protocol for secure aggregation of highdimensional data that can be used in federated learning [17]. This approach enables training Deep Neural Networks (DNN) when data is distributed over different users. In this technique, the users' devices need to perform the DNN training task locally to update the global model. However, IoT edge devices often do not have enough computation resources to perform complex DNN training.\n\nThis paper proposes a novel secure technique that enables efficient, scalable, and secure collaborative learning in highdimensional space. Instead of using conventional machine learning algorithms, we exploit High-Dimensional (HD) computing [18] to perform the learning tasks in a secure domain. HD computing does not require complete knowledge for the original data that the conventional learning algorithms need -it runs with a mapping function that encodes a given data to a high-dimensional space that mimics massive numbers of neurons and synapses in brains. The original data cannot be reconstructed from the mapped data without knowing the mapping function, since a single value can be represented with extremely huge possibilities in the highdimensional space.\n\nAlong with the attractive properties for secure learning, HD computing also offers additional benefits. HD provides an efficient learning strategy without complex computations such as back propagation in neural networks. In addition, the HDbased learning models are extremely robust in the presence of hardware failures due to the independence of dimensions in the computation. Prior work shows that HD computing can be applied to many cognitive tasks such as analogybased reasoning [19], latent semantic analysis [20], language recognition [21], [22], and speech/object recognition [23], [24].\n\nWe address several technical challenges to enable HDbased trustworthy, collaborative learning. For example, to map the original data into high-dimensional vectors, called hypervectors, it exploits a set of base hypervectors which are randomly generated. Since the base hypervectors can be used to estimate the original data, every user has to have different base hypervectors to ensure the confidentiality of the data. However, in this case, the HD computation cannot be performed with the data provided by different users. The other challenge is that the existing HD learning methods do not scale with the size of data. This highly limits the applicability to HD-based computing on cloud-scale services.\n\nIn this paper, we design a novel framework, called SecureHD, which fills the gap between the existing HD computing and trustworthy, collaborative learning. We present the following contributions: i) We design a novel secure collaborative learning protocol that securely generates and distributes public and secret keys. SecureHD utilizes Multi-Party Computation (MPC) techniques which are proven to be secure when each party is untrusted [25]. With the generated keys, the user data are not revealed to the cloud server, while the server can still learn a model based on the data encoded by users. Since MPC is an expensive protocol, we carefully optimize it by replacing a part of tasks with two-party computation. In addition, our design leverages MPC only for a one-time key generation operation. The rest of the operations such as encoding, decoding, and learning are performed without using MPC. ii) We propose a new encoding method that maps the original data with the secret key assigned to each user. Our encoding method significantly improves classification accuracy as compared to the state-of-the-art HD work [22], [26]. Unlike existing HD encoding functions, the proposed method encodes both the data and the metadata, e.g., data types and color depths, in a recover-friendly manner. Since the secret key of each user is not disclosed to anyone, although one may know encoded data of other users, they cannot be decoded. iii) SecureHD provides a robust decoding method for the authorized user who has the secret key. We show that the cosine similarity metric widely used in HD computing is not suitable to recover the original data. We propose a new decoding method which recovers the encoded data in a lossless manner through an iterative procedure. iv) We present scalable HD-based classification methods for many practical learning problems which need the collaboration of many users, e.g., human activity and face image recognition. We propose two collaborative learning approaches, cloud-centric learning for the case that end-node devices do not have enough computing capability, and edgebased learning that all the user devices participate in secure distributed learning. v) We also show a hardware accelerator design that significantly minimizes the costs paid for security. This enables secure HD computing on less-powerful edge devices, e.g., gateways, which are responsible for data encryption/deception. We design and implement the proposed SecureHD framework on diverse computing devices in IoT systems, including a gateway-level device, a high-performance system, and our proposed hardware accelerator. In our evaluations, we show that the proposed framework can perform the encoding and decoding tasks 145.6\u00d7 and 6.8\u00d7 faster than a state-of-the-art homomorphic encryption library when both are running on the Intel i7-8700K. The hardware accelerator further improves the performance efficiency by 35.5\u00d7 and 20.4\u00d7 as compared to the CPU-based encoding and decoding of SecureHD. In addition, our classification method presents high accuracy and scalability for diverse practical problems. It successfully performs learning tasks with 95% average accuracy for six real-world workloads, ranging from datasets collected in a small IoT network, e.g., human activity recognition, to a large dataset which includes hundreds of thousands of images for the face recognition task. Our decoding method also provides high quality in the data recovery. For example, SecureHD can recover the encoded data in a lossless manner, where the size of the encoded data is 4 times smaller than the one encrypted by the state-of-the-art homomorphic encryption library [27]. Figure 1 shows the scenario that we focus in this paper. The clients, e.g., user devices, send either their sensitive data or partially trained models in an encrypted form to the cloud. The cloud performs a learning task by collecting the encrypted information received from multiple clients. In our security model, we assume that a client cannot trust the cloud as well as other clients. When requested by the user, the cloud sends back the encrypted data to clients. The client then decrypts the data with its private key.\n\n\nII. MOTIVATION AND BACKGROUND A. Motivational Scenario\n\nAs an existing solution, homomorphic encryption enables processing on the encrypted version of data [15]. Figure 2 shows the execution time of a state-of-the-art homomorphic encryption library, Microsoft SEAL [16], for MNIST training dataset, which includes 60000 images of 28\u00d728 pixels. We execute the library on two platforms that a client in IoT systems may use, a high-performance computer (Intel i7-8700K) and a Raspberry Pi 3 (ARM Cortex A53). The result shows that, even with the simple dataset of 47 MBytes, it takes significantly large execution time, e.g., more than 13 days on ARM to encrypt. Another approach is to utilize secure Multi-Party Computation (MPC) techniques [25], [28]. In theory, any function, which can be represented as a Boolean circuit with inputs from multiple parties, can be evaluated securely without disclosing each party's to anyone else. For example, by describing the machine learning algorithm as a Boolean circuit with learning data as inputs to the circuit, one can securely learn the model. However, such solutions are very costly in practice and are computation and communication intensive. In SecureHD, we only use MPC to securely generate and distribute users' private keys which is orders of magnitude less costly than performing the complete learning task using MPC. The key generation step is a one-time operation so the small cost associated with it is quickly amortized over time for future tasks.\n\n\nB. Background: HD Computing\n\nBrain-inspired high-dimensional (HD) computing performs cognitive tasks using ultra-wide words -that is, with very high-dimensional vectors, also known as hypervectors [18], [29]. Hypervectors are holographic and (pseudo)random with independent identically distributed (i.i.d.) components. A hypervector may contain multiple values by spreading them across its components in full holistic representation. In this case, no component in a hypervector is more responsible for storing any piece of information than others. These unique features make hypervectors robust against errors in their components.\n\nHypervectors are implemented with high-dimensional operations, such as binding that forms a new hypervector which associates two hypervectors, and bundling that combines hypervectors into a single composite hypervector. (i) The binding of two hypervectors A and B is denoted as A * B. The result of the operation is a new hypervector that is dissimilar to its constituent vectors. For bipolar hypervectors ({\u22121, +1} D ), the component-wise multiplication performs the binding operation. For example, let us consider two hypervectors randomly generated, i.e., each component has either -1 or +1 with 50:50 chance. Since they are nearorthogonal, their binding has approximately zero similarity each other, i.e., \u03b4 (A * B, A) \u2248 0 where \u03b4 is a function that computes the cosine similarity. (ii) Bundling operation is denoted as A B and preserves similarity to its component hypervectors. The component-wise addition implements the Many learning tasks can be implemented in the HD domain. To implement a simple classification algorithm, a data point in a given training dataset is first converted into a hypervector. This step is often referred to as encoding. The encoding exploits a set of orthogonal hypervectors, called base hypervectors, to map each data point into the HD space. Then, it bundles the encoded hypervectors for each class. The reasoning (inference) can be performed by choosing the class whose bundled hypervector presents the highest similarity to an unseen hypervector [18].\n\n\nIII. SECURE LEARNING IN HD SPACE A. Security Model\n\nIn SecureHD, we consider the server and other clients to be untrusted. More precisely, we consider Honest-but-Curious (HbC) adversary model where each party, server or a client, is untrusted but follows the protocol. Both the server and other clients are not able to extract any information based on the data that they receive and send during the secure computation protocol. For the task of key generation and distribution, we utilize a secure MPC protocol which is proven to be secure in the HbC adversary model [25]. We also use two-party Yao's Garbled Circuits (GC) protocol which is also to be secure in the HbC adversary model as well [30]. The intermediate results are stored as additive unique shares of PKey by each client and the server.\n\n\nB. Proposed Framework\n\nIn this section, we describe the proposed SecureHD framework which enables trustworthy, collaborate HD computing. Figure 3 illustrates the overview of SecureHD. The first step is to create different keys for each user and cloudbased on an MPC protocol. As discussed in Section II-B, to perform a HD learning task, the data are encoded with a set of base hypervectors. The MPC protocol creates the base hypervectors for the learning application, called global keys (GKeys). Instead of sharing the original GKeys with clients, the server distributes permutations of each GKey, i.e., a hypervector whose dimensions are randomly shuffled. Since each user has different permutations of GKeys, called personal keys (PKeys), no one can decode encoded data of others. The cloud has dimension indexes used in the GKey shuffling, called shuffling keys (SKeys). Since the cloud does After the key generation, each client can encode their data with its PKeys. SecureHD securely injects a small amount of information into the encoded data. We exploit this technique to store the metadata, e.g., data types, which are important to recover the entire original data. Once the encoded data is sent to the cloud, the cloud reshuffles the encoded data with the SKeys for the client. This allows the cloud to perform the learning task with no need for accessing GKeys and PKeys. With the SecureHD framework, the client can also decode the data from the encoded hypervectors. For example, once a client fetches the encoded data from the cloud storage service, it can exploit the framework to recover the original data using its own PKeys. Each client may also utilize the specialized hardware to accelerate both the encoding and decoding procedures. Figure 4 illustrates how our protocol securely create the key hypervectors. The protocol runs two phases: Phase 1 that all clients and the cloud participate, and Phase 2 that two parties, a single client and cloud, participate. Recall that in order for the cloud server to be able to learn the model, all have to be projected based on the same base hypervectors. Given the base hypervector and the encoded result, one can reconstruct the plaintext data. Therefore, all clients have to use the same key without anyone having access to the base hypervectors. We realize these two constraints at the same time with a novel hybrid secure computation solution.\n\n\nC. Secure Key Generation and Distribution\n\nIn the first phase, we generate the base hypervectors, which we denote by GKey. The main idea is that the base hypervectors are generated collaboratively inside the secure Multi-Party Computation (MPC) protocol. At the beginning of the first phase, each party i inputs two sets of random strings called S i and S * i . Each stream length is D, where D is the dimension size of a hypervector. The MPC protocol computes element-wise XOR (\u2295) of all the provided bitstreams, and the substream of D elements represent the global base hypervector, i.e., GKey. Then, it performs XOR for the GKeys again with S * i provided by each client. At the end of the first MPC protocol phase, the cloud receives S * i \u2295 GKey corresponding to each user i and stores these secret keys. Note that since S i and S * i are inputs from each user to the MPC protocol, it is not revealed to any other party during the joint computation. It can be seen that the server has a unique XOR-share of the global key GKey for each user. This, in turn, enables the server and each party to continue their computation in a point-to-point manner without involving other parties during the second phase.\n\nOur approach has a strong property that even if all other clients are dishonest and provide zero vectors as their share to generate the Gkey, the security of our system is not hindered. The reason is that the Gkey is generated with XOR of S i for all clients. That is, if one generates its seed randomly, the global key will have a uniform random distribution. In addition, the server only receives an XOR-share of the global key. The XOR-sharing technique is equivalent to One-Time Pad encryption and is information-theoretic secure which is superior to the security against computationally-bounded adversaries in standard encryption schemes such as Advanced Encryption Standard (AES). We only use XOR gates in MPC which are considerably less costly than non-XOR gates [31].\n\nIn the second phase, the protocol distributes the secret key for each user. Each party engages in a two-party secure computation using the GC protocol. Server's inputs are SKey i and S * i \u2295 GKey, while the client's input is S * i . The global key GKey is securely reconstructed inside the GC protocol by XOR of the two shares:\nGKey = S * i \u2295 (S * i \u2295 GKey).\nThe global key is then shuffled based on the unique permutation bits held by the server (SKey i ). In order to avoid costly random accesses inside the GC protocol, we use the Waksman permutation network with SKey i being the permutation bits [32]. The shuffled global key is sent back to the user, and we perform a single rotational shift for the GKey to generate the next base hypervector. We repeat this n times where n is the required number of base hypervectors, e.g., the feature size. The permuted base hypervectors serve as user's personal keys, called PKey, for the projection. Once a user performs the projection with PKey, she can send the result to the server, and the server permutes back based on the SKey i for the learning process. Figure 5 shows how the SecureHD framework performs the encoding and decoding of a client with the generated PKeys. Once the encoded data is received from the cloud, Se-cureHD can also decode them back to the original domain. This is useful for other cloud services, e.g., cloud storage. This procedure starts with identifying the injected metadata ( \u2022 C ). Based on the injected metadata, it figures out the base hyperevectors that will be used in the decoding. Then, it reconstructs the original data from the decoded data ( \u2022 D ).\n\n\nIV. SECUREHD ENCODING AND DECODING\n\nThe key of the data recovery procedure is the value extraction algorithm, which retrieves both metadata and data. A. Encoding in HD Space 1) Data Encoding: The first step of SecureHD is to encode input data into hypervector, where an original data point has n features. We associate each feature with a hypervector. The features can have discrete value (e.g., alphabets in the text), in which we perform a straight mapping to hypervectors, or they can have a continuous range, in which case the values can be quantized and then mapped similar to discrete features. Our goal is to encode each feature vector to a hypervector that has D dimensions, e.g. D = 10, 000.\n\nTo differentiate each feature, we exploit a PKey for each feature value, i.e., {B 1 , B 2 ,..., B n }, where n is the feature size of an original data point. Since the PKeys are generated from the random bit streams, the similarity of different base hypervectors are nearly orthogonal [29]:\n\u03b4 (B i , B j ) 0 (0 < i, j \u2264 n, i = j).\nThe orthogonality of feature hypervectors is ensured as long as the hypervector dimension, D, is large enough compared to the number of features (D >> n) in the original data. Different features are combined by multiplying feature values with the corresponding base hypervector, B i \u2208 {\u22121, +1} D and adding them for all the features. For example, where f i is a feature value, the following equation represents the encoded hypervector, H: 1 The scalar multiplication, denoted by *, can make a hypervector that has integer elements, i.e., H \u2208 N D . If two original feature values are similar, their encoded hypervectors are also similar, thus providing the learning capability for the cloud without any knowledge for the PKeys. Please note that, with this encoding scheme, although an attacker intercepts sufficient hypervectors, the upper bound of the information leakage is the distribution of the data. It is because the hypervector does not preserve any information of the feature order, e.g., pixel positions in an image, and there are extremely large combinations of values in hypervector elements which exponentially grow as n increases. In the case that n is small, e.g., n < 20, we can simply add extra features drawn from a uniform random distribution, and it does not affect the data recovery accuracy and HD computation results.\n1 H = f 1 * B 1 + f 2 * B 2 + ... + f n * B n .\n2) Metadata Injection: A client may receive an encoded hypervector where SecureHD processes multiple data types. In this case, to identify base hypervectors used in the prior encoding, it needs to embed additional information of the data identifier and metadata, such as data type (e.g., image or text) and color depth. One naive way is to store this metadata as attached bits to the original hypervector. However, this does not keep the metadata secure.\n\nTo embed the additional metadata into hypervectors, we exploit the fact that HD computing is robust to small modification of hypervector elements. Let us consider a data hypervector as a concatenation of several partial vectors. For example, a single hypervector with the D dimension can be viewed as the concatenation of different d-dimensional vectors, A 1 ,..., A N :\nH = A 1 A 2 \u00b7\u00b7\u00b7 A N where D = N \u00d7 d, and each A i vector is called as a segment.\nWe inject the metadata in a minimal number of segments. Figure 5 shows the concatenation of a hypervector to N = 200 segments with d = 50 dimensions. We first generate a random d dimensional vector with bipolar values, M i , i.e., metavector. A metavector corresponds to a metadata type. For example, M 1 and M 2 can correspond to the image and text types, while M 3 , M 4 , and M 5 correspond to each color depth, e.g., 2-bit, 8-bit, and 32-bit. Our design injects each M i into one of the segments in the data hypervector. We add the metavector multiple times to better distinguish it against the values already stored in the segment. For example, if we inject the metavector in the first segment, the following equation denotes the metadata injection procedure:  Figure 6a shows an example of the cosine similarity for each B i when f 1 = 50, f 2 = 26 and f 3 = 77 and m changes from 1 to 120. The result shows that the similarity decreases as subtracting more instances of B 1 from H. For example, the similarity is zero when m is close to f i as expected, and it gets negative values for further subtractions, since H has the term of \u2212B 1 . Regardless of the initial similarity of H with B, the cosine similarity is around zero when m is close to each feature value f i .\nA 1 = A 1 + C * M 1 + C * M 2 + ... + C * M k where C is\nHowever, there are two main issues in the cosine similaritybased value search. First, finding the feature values in this way needs iterative procedures, slowing down the runtime of data recovery. In addition, it is more challenging when feature values are represented in floating points. Second, the cosine similarity metric may not give accurate results in the recovery. In our earlier example, the similarity of each f i is zero, when m i is 49, 29 and 78 respectively.\n\nTo efficiently estimate f i values, we exploit another approach that utilizes the random distribution of the hypervector elements. Let us consider the following equation:\nH \u00b7 B i = f i * (B i \u00b7 B i ) + \u2211 j,\u2200 j =i f j * (B i \u00b7 B j ).\nB i \u00b7 B i is D since each element of the base hypervector is Figure 7. Iterative error correction procedure either 1 or -1, while B i \u00b7 B j is almost zero due to their nearorthogonal relationship. Thus, we can estimate f i with the following equation, called value discovery metric:\nf i H \u00b7 B i /D.\nThis metric yields an initial estimate of all feature values,\nsay F 1 = { f 1 1 ,..., f 1 n }.\nStarting with the initial estimation, SecureHD minimizes the error through an iterative procedure. Figure 7 shows the iterative error correction mechanism. We encode the estimated feature vector, F 1 , into the high dimensional space, H 1 = {h 1 1 , ..., h 1 D }. We then compute \u0394H 1 = H \u2212 H 1 , and apply the value extraction metric for \u0394H 1 . Since this yields the estimated error, E 1 , in the original domain, we add it to the estimated feature vector for the better estimate of the actual features, i.e., F 2 = F 1 + E 1 . We repeat this procedure until the estimated error converges. To determine the termination condition, we compute the variance of the error hypervector, \u0394H i , at the end of each iteration. Figure 6b shows the variance changes when decoding four example hypervectors. For this experiment, we used two feature vectors whose size is either n = 1200 or 1000, where the feature values are uniform-randomly generated. We encoded each feature vector to two hypervectors with either D = 7, 000 or D = 10, 000. As shown in the results, the iterations required for accurate recovery depends on both the number of features in the original domain and hypervector dimensions. In the rest of the paper, we use the ratio of the hypervector dimension to the number of features in the original domain, i.e., R = D/n, to evaluate the quality of the data recovery for different feature sizes. The larger R ratio, the larger the retraining iterations are expected to sufficiently recover the data.\n\n2) Metadata Recovery: We utilize the value extraction method to recover the metadata. We calculate how many times each metavector {M 1 ,...,M k } presents in a segment. If the extracted instances of metavector are similar to the actual C value that we injected, such metavector is considered to be in the segment. However, since the metavector has a small number of elements, i.e., d << D dimensions, it might have a large error in finding the exact C value. Let's assume that, when injecting a metavector C times, the value extraction method identifies a value, C, in a range of [C min ,C max ]. The range also includes C. If the metavector does not exist, the C Figure 8. Relationship between the number of metavector injections and segment size value C will be approximately zero, i.e., a range of [\u2212\u03b5, \u03b5]. The amount of \u03b5 depends on the other information stored in the segment. Figure 8a shows the distribution of extracted values, C, when injecting 5 metadata 10 times (C = 10) into a single segment of a hypervector. These distributions are reported using a Monte Carlo simulation with 1500 randomly generated metavectors. The results show that the distributions of the existing and non-existing cases are overlapped, making the estimation difficult. However, as shown in Figure 8b, when using C = 128, there is a clear margin between these two distributions which identify the existence of a metadata. Figure 8c shows the distributions when we inject 8 metadata into a single segment with C = 128. In that case, two distributions overlap, i.e., there are a few cases when we cannot fully recover the metadata.\n\nWe determine C so that the distance between C min and \u03b5 is larger than 0. We define the distance as the noise margin, NM = C min \u2212 \u03b5. Figure 8d shows how many metavectors can be injected for different C values. The results show that the number of meta vectors that we can inject saturates for larger C values. Since the large number of C and segment size, d, also have a higher chance to influence on the accuracy of the data recovery, we choose C = 128 and d = 50 for our evaluation. In Section VI-E, we present a detailed evaluation for different settings of the metavector injection.\n\n3) Data Recovery: After recovering the metadata, Se-cureHD can recognize the data types and choose the base hypervectors for decoding. We subtract the metadata from the encoded hypervector and start decoding the main data. SecureHD utilizes the same value extraction method to identify the values for each base hypervector. The quality of data recovery depends on the dimension of hypervectors in the encoded domain (D) and the number of features in the original space (n), i.e., R = D/n defined in Section IV-B1. Intuitively, with the larger the R value, we can achieve a higher accuracy during the data recovery at the expense of the size of encoded data. For instance, when storing an Figure 9. Illustration of the classification in SecureHD image with n = 1000 pixels in a hypervector with D = 10, 000 dimensions (R = 10), it is expected to achieve high accuracy for the data recovery. In our evaluation, we observed that, with R = 7, it is enough to ensure lossless data recovery in the worst case. In Section VI-D, we explore more detailed discussion about how R impacts on the accuracy of the recovery procedure.\n\nV. LEARNING IN HD SPACE A. Secure Collaborative Learning Figure 9 shows the HD-based collaborative learning in the high-dimensional space. In this paper, we show two training approaches, centralized and federated training, which performs classification learning with a large amount of data provided by many clients. The cloud can perform the training procedures using the encoded hypervectors without explicit decoding. It only needs to permute the encoded data using the SKey of each client. Note that the permutation aligns the encoded data on the same GKey base, even though the cloud does not have the GKeys. It reduces the cost of the learning procedure, and the data can be securely classified even on the untrustworthy cloud. The training procedure creates multiple hypervectors as the trained model, where each hypervector represents the pattern of data points in one class. We refer them to class hypervectors. 1) Approach 1: Centralized Training: In this approach, the clients send the encoded hypervectors to the cloud. The cloud permutes them with the SKeys, and a trainer module combines the permuted hypervectors. The training is performed with the following sub-procedures. (i) Initial training: At the initial stage, it creates the class hypervectors for each class. As an example, for a face recognition problem, SecureHD creates two hypervectors representing \"face\" and \"non-face\". These hypervectors are generated with element-wise addition for all encoded inputs which belong to the same class, i.e., one for \"face\" and the other one for \"non-face\". (ii) Multivector expansion: After training the initial HD model, we expand the initial model with cross-validation, so that each class has multiple hypervectors of the size of \u03c1. The key idea is that, when training with larger data, it may need to capture more distinct patterns with different hypervectors. To this end, we first check cosine similarity for each encoded hypervector again to the trained model. If an encoded data does not correctly match with its corresponding class, it means that the encoded hypervector has a distinct pattern as compared to the majority of all the inputs in the class. For each class, we create a set that includes such mismatched hypervectors and the original model. We then choose two hypervectors, whose similarity is the highest among all pairs in the set, and update the set by adding the selected two into a new hypervector. This is repeated until the set includes only \u03c1 hypervectors. (iii) Retraining: As the last step, we iteratively adjust the HD model over the same dataset to give higher weights for misclassified samples that may often happen in a large dataset. We check the similarity for each encoded hypervector again with all existing classes. Let us assume that C p k is one of the class hypervectors belonging to k th class, where p is the index of multiple hypervectors in the class. If an encoded hypervector Q belonging to i th class is incorrectly classified to C miss j , we update the model by\nC miss j = C miss j \u2212 \u03b1Q and C \u03c4 i = C \u03c4 i + \u03b1Q where \u03c4 = argmax t \u03b4 (C t i , Q)\nand \u03b1 is a learning rate in a range of [0.0, 1.0]. In other words, in the case of misclassification, we subtract the encoded hypervector from the class which it is incorrectly classified to, while adding it to the class hypervector which has the highest similarity in the correct class. This procedure is repeated for predefined iterations, and the final class hypervectors are used for the future inference.\n\n2) Approach 2: Federated Training: The clients may not have enough network bandwidth to send every encoded hypervector. To address this issue, we present the second approach, called federated training, as an edge computing. In this approach, the clients individually train initial models, i.e., one hypervector for each class, only using their own encoded hypervectors. Once the cloud receives the initial models of all the clients, it permutes the models with the SKeys and performs element-wise additions to create a global model, C k , for each k th class.\n\nSince the cloud only knows the initial models for each client, the multivector expansion procedure is not performed in this approach, but we can still execute the retraining procedure explained in Section V-A1. To this end, the cloud re-permutes the global model and sends it back to each client. With the global model, each client performs the same retraining procedure. Let us assume that C i k is the retrained model by the i th client. After the cloud aggregates allC i k with the permutation, it updates the global models by\nC k = \u2211 i C i k \u2212 (n \u2212 1) * C k .\nThis is repeated for the predefined iterations. This approach allows the clients to send the trained class hypervectors only for each retraining iteration, thus significantly reducing the network usage.\n\n\nB. HD Model-Based Inference\n\nWith the class hypervectors generated by either approach, we can perform the inference in any device including the cloud and clients. For example, the cloud can receive an encoded hypervector from a client, and permute the dimension with the SKey in the same way to the training procedure. Then, it checks cosine similarity of the permuted hypervector to all trained class hypervectors to label with the corresponding class to the most similar class hypervector. In the case of the client-based inference, once the cloud sends re-permuted class hypervectors to a client, the client can perform the inference for its encoded hypervector with the same similarity check.\n\n\nVI. EVALUATION A. Experimental Setup\n\nWe have implemented the SecureHD framework including encoding, decoding, and learning in high-dimensional space using C++. We evaluated the system on three different platforms: Intel i7 7600 CPU with 16GB memory, Raspberry Pi 3, and Kintex-7 FPGA KC705. We also exploit a network simulator, NS-3 [33], for large-scale simulation. We verify the FPGA timing and the functionality of the encoding and decoding by synthesizing Verilog using Xilinx Vivado Design Suite [34]. The synthesis code has been implemented on the Kintex-7 FPGA KC705 Evaluation Kit. We compare the efficiency of the proposed SecureHD with SEAL, the stateof-the-art C++ implementation of a homomorphic library, Microsoft SEAL [27]. For SEAL, we used the default parameters: polynomial modulus of n = 2048, coefficient modulus of q = 128 \u2212 bit, plain modulus of t = 1 << 8, noise standard deviation of 3.9, and decomposition bit count of 16. We evaluate the proposed SecureHD framework with real-world datasets including human activity recognition, phone position identification, and image classification. Table I summarizes the evaluated datasets. The tested benchmarks range from relatively small datasets collected in a small IoT network, e.g., PAMAP2, to a large dataset which includes hundreds of thousands of images of facial and non-facial data. We also compare the classification accuracy of SecureHD for the datasets with the state-of-the-art learning models shown in the table.\n\n\nB. Encoding and Decoding Performance\n\nAs explained in Section III-C, SecureHD performs a onetime key generation to distribute the PKeys to each user using the MPC and GC protocols. Table II listed the number of required logic gates evaluated in the protocol and the amount of required communication between clients. This overhead comes mostly from the first phase of the protocol, since the second phase has been simplified with the twoparty GC protocol. The cost of the protocol is dominated by network communication. In our simulation conducted under our in-house network of 100 Mbps, it takes around 9 minutes to create D = 10, 000 keys for 100 participants. Note that the runtime overhead is negligible since the key generation happens only once before all future computation.\n\nWe have also evaluated the encoding and decoding procedure running on each client. We compare the efficiency of SecureHD with the Microsoft SEAL [27]. We run both the SecureHD framework and homomorphic library on ARM Cortex 53 and Intel i7 processors. Figure 10 shows the   C. Evaluation of SecureHD Learning 1) Learning Accuracy: Based on the proposed SecureHD, clients can share the information with the cloud in a secure way, such that the cloud cannot understand the original data while still performing the learning tasks. Along with the proposed two learning approaches, we also evaluate the stateof-the-art HD classification approach, called one-shot HD model, which trains the model using a single hypervector per class with no retraining [22], [26]. For the centralized training, we trained two models, one that has 64 class hypervectors for each class and the other one that has 16 for each class. We call them as Centralized-64 and Centralized-16. The retraining procedure was performed for 100 times with \u03b1 = 0.05, since the classification accuracy was converged with this configuration for all the benchmarks. Figure 11 shows the classification accuracy of the Se-cureHD for the different benchmarks. The results show that the centralized training approach achieves high classification accuracy comparable to the state-of-the-art learning methods such as DNN models. We also observed that, by training more hypervectors per class, it can provide higher classification accuracy. For example, for the federated training approach, which does not use multivectors, the classification accuracy is 90% on average, which is 5% lower than the Centralized-64. As compared to the state-of-the-art one-shot HD model which does not retrain models, Centralized-64 achieves 15.4% higher classification accuracy on average.\n\n2) Scalability of SecureHD Learning: As discussed in Section V-A, the proposed learning method is designed to effectively handle a large amount of data. To understand the scalability of the proposed learning method, we evaluate how the accuracy is changed when the training data are come from different numbers of clients, with simulation on NS-3 [33]. In this experiment, we exploit three datasets, PAMAP2, EXTRA, and FACE, which include information of where data points are originated. For example, PAMAP2 and EXTRA are gathered from 7 and 56 individual users. Similarly, the FACE dataset includes 100 clients that have different facial images with each other. Figure 12a and b show the accuracy changes for the centralized and federated training approaches. The result shows that increasing the number of clients improves classification accuracy by training with more data. Furthermore, as compared to the one-shot HD model, the two proposed approaches show better scalability in terms of accuracy. For example, the accuracy difference between the proposed approach and the one-shot model grows as more clients engage in the training. Considering the centralized training, the accuracy difference for the FACE dataset is 5% when trained with one client, while it is 14.7% for the 60-client case. This means that the multivector expansion and retraining techniques are effective to learn with a large amount of data.\n\nWe also verify how the SecureHD learning methods work with constrained network conditions that often happen in IoT systems. In our network simulation, we assume the worstcase network condition, i.e., all clients share the bandwidth of a standard WiFi 802.11 network. Note that it is a worstcase scenario and in practice, each embedded device may not share the same network. Figure 12c shows that the network bandwidth limits the number of hypervectors that can be sent for each second as multiple clients involve the learning task. For example, a network with 100 clients can send the lower number of hypervectors by 23.6\u00d7 than a single-client case. As discussed before, the federated learning can be exploited to overcome the limited network bandwidth at the expense of the accuracy loss. Another solution is to use a reduced dimension in the centralized learning. As shown in Figure 12c, when D = 1, 000, clients can send the data to the cloud with 353 samples per second, which is 10 times higher than the case of D = 10, 000. Figure 12d shows how learning accuracy changes for different dimension settings. The results show that reducing the hypervector dimensions to 4000 and 1000 dimensions has less than 1.4% and 5.3% impact on the classification accuracy. This strategy gives another choice of the trade-off between accuracy and network communication cost.\n\n\nD. Data Recovery Trade-offs\n\nAs discussed in Section IV-B3, the proposed SecureHD framework provides a decoding method for the authorized user that has the original Pkeys used in the encoding. Figure 13a shows the data recovery rate on images with different pixel sizes. To verify the proposed recovery method in the worst case scenario, we created 1000 images whose pixel values are randomly chosen, and report the average error when we map the 1000 images to D = 10, 000 dimension. The x-axis shows the ratio R, i.e., D/n where the number of hypervector dimension (D) to the number of pixels (n) in an image. The data recovery rate depends on the precision of the pixel values. Using high-resolution images, SecureHD requires a larger R value to ensure 100% accuracy. For instance, for images with 32-bit pixel resolution, SecureHD can achieve 100% data recovery using R = 7, while lower resolution images (e.g., 16 and 8-bits) requires R = 6 to ensure 100% data recovery. Our evaluation shows that our method can decode any input image with 100% data recovery rate using R = 7. This means that we can securely encode data with 4\u00d7 smaller size compared to the homomorphic encryption library which increases the data size by 28 times through the encryption.\n\nWe also evaluate the SecureHD framework with a text dataset written in three different European languages [43]. Figure 13b shows the accuracy of data recovery for the three languages. The x-axis is the ratio between the length of hypervectors to the number of characters in the text when D = 10, 000. Our method assigns a single value to each alphabet letter and encodes the texts with the hypervectors. Since the number of characters in these languages is less than 49, we require at most 6 bits to represent each alphabet. In terms of the data recovery, it is equal to encoding the same size image with the 6-bit pixel resolution. Our evaluation shows that SecureHD can provide 100% data recovery rate with R = 6. Figure 14 shows the quality of the data recovery for two example images. The Lena and MNIST image have 100\u00d7100 pixels and 28 \u00d7 28 pixels, respectively. Our encoding maps the input data to hypervectors with different dimensions. For example, the Lena image with R = 6 means that the image has been encoded with D = 60, 000 dimensions. Our evaluation shows that SecureHD can achieve lossless data recovery on Lena photo when R \u2265 6, while using R = 5 and R = 4 the data recovery rates are 93% and 68%. Similarly, R = 5 and R = 4 provide 96% and 56% data recovery for the MNIST images.\n\n\nE. Metadata Recovery Trade-offs\n\nAs discussed in Section IV-B2, the metadata injection method needs to be performed such that it ensures 100% metadata recovery and it has minimal impacts on the original hypervector for the learning and data recovery. The solid line in Figure 15a shows the noise margin when injecting multiple metavectors into a single segment of hypervector when the number of elements in the segment is chosen by 50(= d). We report the results based on the worst case for  Figure 15. Data recovery rate for different settings of metavector injection 5000 Monte Carlo simulation. The results show that each segment can store 6 metavectors at most to take a positive noise margin that ensures 100% metadata recovery. The dotted line shows the data recovery error rate for different numbers of metavectors injected into a single segment. Our evaluation shows that adding 6 metavectors has less than 0.005% impact on the data recovery rate.\n\nSince the number of metavectors which can be injected in one segment is limited, we may need to distribute the metadata in different segments. Figure 15b presents the impact of the metadata injection on the data recovery error rate. When we inject 6 metadata into each of all 200 segments, i.e., 1200 metavectors in total, the impact on the recovery accuracy is still minimal, i.e., less than 0.12%.\n\nVII. RELATED WORK Secure Learning Privacy-preserving deep learning and classification has been an active research area in recent years [17], [44], [45], [46], [47], [48], [49]. Shokri and Shmatikov [45] have proposed a solution for collaborative deep learning where the training data is distributed among many parties. Each party locally trains her model and sends the parameter updates to the server. However, it has been shown that Generative Adversarial Networks (GANs) can be used to attack this method [50].\n\nSecureML [47] is a framework for secure training of machine learning models. All of the computation of Se-cureML is performed by the two servers using MPC protocols, whereas, SecureHD only relies on the MPC protocol for secure key generation and distribution. Chameleon [44] is a privacy-preserving machine learning framework that utilizes different cryptographic protocols for different operations within the machine learning task. In contrast to SecureML and Chameleon, our solution does not require two non-colluding servers and only involves one server.\n\nGoogle has also proposed a federated learning approach [17] for collaborative learning. In their approach, each client needs to learn the local model based on the private training data to update the central model in the cloud. However, our solution is more light-weight to be run on less-powerful IoT devices and also applicable to other cloudoriented tasks, e.g., data storage services. Hyperdimensional Computing Since the Finnish computational neuroscientist P. Kanerva introduced the field of hyperdimensional computing [18], prior research have applied the idea into diverse cognitive tasks, such as analogybased reasoning [19], latent semantic analysis [20], language recognition [21], speech/object recognition [23], [24], activity recognition [51], [52], and clustering [53] . However, most of the existing works assume that the HD learning tasks are performed on a single system. To the best of our knowledge, this paper is the first work that securely performs the HD learning tasks on a cloud scale. In addition, we also focus on how to accurately recover the encoded data in the HD space.\n\nSome existing works have presented the hardware accelerator design to efficiently perform HD tasks [26], [54], [55]. Work in [56] proposed a framework for enabling model sparsity in HD computing. Several works showed new memory architectures that perform the HD operations inside the memory array [26], [57], [58]. Our design is orthogonal in this view that it can exploit any of these hardware for hardware acceleration.\n\nVIII. CONCLUSION In this paper, we propose a novel framework, called SecureHD, which provides secure data encoding and learning solution based on HD computing. With our framework, clients can securely send their data to untrustworthy clouds, while the cloud can perform the learning tasks without the knowledge of the original data. Our proof-of-concept implementation demonstrates that the proposed SecureHD framework successfully performs the encoding and decoding tasks with high efficiency, e.g., 145.6\u00d7 and 6.8\u00d7 faster than the state-of-the-art encryption/decryption library. Our learning method achieves accuracy of 95% on average for diverse practical learning tasks. In addition, SecureHD provides lossless data recovery with 4\u00d7 reduction in the data size compared to the existing encryption solution.\n\nFigure 1 .\n1Motivational scenario\n\nFigure 2 .\n2Execution time of homomorphic encryption and decryption over MNIST dataset\n\nFigure 3 .\n3Overview of SecureHD bundling for bipolar hypervectors. For example, the bundling of two random hypervectors keeps the information, i.e., \u03b4 (A B, A) \u2248 cos(\u03c0/4).\n\nFigure 4 .\n4MPC-based key generation not have the GKeys, it cannot decrypt the encoded data of clients. This MPC-based key generation runs only once.\n\nFigure 5 .\n5The example has been shown for an image input data with n pixel values, { f 1 ,..., f n }. Our design encodes each input data into a high-dimensional vector from the feature values ( \u2022 A ). It exploits the PKeys, i.e., a set of the base hypervectors for the client, where 0 and 1 in the PKeys correspond to -1 and 1 to form a bipolar hypervector ({\u22121, +1} D ). We denote them by PKeys = {B 1 ,..., B n }. To store the metadata with negligible impact on the encoded hypervector, we devise a method which injects several metadata to small segments of an encoded hypervector. This method exploits another set of base vectors, {M 1 ,..., M k } ( \u2022 B ). We call them as Illustration of SecureHD encoding and decoding procedures metavector. The encoded data are sent to the cloud to perform HD learning.\n\n\nthe number of injections for each metavector.B. Decoding in HD Space 1) Value Extraction: In many of today's applications, the clouds are used as a storage, so the clients should be able to recover the original data from encoded ones. The key component of the decoding procedure is a new data recovery method that extracts the feature values stored in the encoded hypervectors. Let us consider an example ofH = f 1 * B 1 + f 2 * B 2 + f 3 * B 3 ,where B i is a base hypervector with D dimensions and f i is a feature value. The goal of the decoding procedure is to find a f i for a given B i and H. A possible way is to exploit the cosine similarity metric, \u03b4 . For example, if we measure the cosine similarity of H and B 1 hypervectors, \u03b4 (H, B 1 ), the higher \u03b4 value represents higher chance of the existence of B 1 in H. Thus, one method may iteratively subtracts one instance of B 1 from H to check when the cosine similarity is zero, i.e., \u03b4 (H , B 1 ) where H = H \u2212 m * B 1 .\n\nFigure 10 .\n10Comparison of SecureHD efficiency to homomorphic algorithm in encoding and decoding\n\nFigure 11 .Figure 12 .\n1112SecureHD Scalability of SecureHD classification\n\nFigure 14 .\n14Example of image recovery\n\nTable I\nIDATASETS (n: FEATURE SIZE, K: NUMBER OF CLASSES)n \nK \n\nData \nSize \n\nTrain \nSize \n\nTest \nSize \nDescription/State-of-the-art Model \n\nMNIST \n784 \n10 \n220MB \n60,000 \n10,000 \nHandwritten Recognition/DNN [35], [36] \nISOLET \n617 \n26 \n19MB \n6,238 \n1,559 \nVoice Recognition/DNN [37], [38] \nUCIHAR \n561 \n12 \n10MB \n6,213 \n1,554 \nActivity recognition(Mobile)/DNN [38], [39] \nPAMAP2 \n75 \n5 \n240MB \n611,142 \n101,582 \nActivity recognition(IMU)/DNN [40] \nEXTRA \n225 \n4 \n140MB \n146,869 \n16,343 \nPhone position recognition/AdaBoost [41] \nFACE \n608 \n2 \n1.3GB \n522,441 \n2,494 \nFace recognition/Adaboost [42] \n\n\n\nTable II OVERHEAD\nIIFOR KEY GENERATION AND DISTRIBUTIONPhases \nPhase 1 \nPhase 2 \n# of Clients \n10 \n50 \n100 \n\nD=1000 \n# of Gates \n11K \n51K \n101K \n8.9K \nCommunication \n7.1MB \n160MB \n650MB \n284MB \n\nD=5000 \n# of Gates \n55K \n255K \n505K \n56.4K \nCommunication \n35MB \n813MB \n3.24GB \n1.8MB \n\nD=10,000 \n# of Gates \n110K \n510K \n101K \n122.9K \nCommunication \n70.34MB \n1.64GB \n6.46GB \n3.93MB \n\nexecution time of the SecureHD and homomorphic library to \nprocess a single data point. For SecureHD, we used R = 7 to \nensure 100% data recovery rate for all benchmark datasets. \nOur evaluation shows that SecureHD achieves on average \n133\u00d7 and 14.7\u00d7 (145.6\u00d7 and 6.8\u00d7) speedup for the encoding \nand decoding, respectively, as compared to the homomorphic \ntechnique running on the ARM architecture (Intel i7). The \nencoding of SecureHD running on embedded devices (ARM) \nis still 8.1\u00d7 faster than the homomorphic encryption running \non the high-performance client (Intel i7). We also compare \nthe SecureHD efficiency on the FPGA implementation. We \nobserve that the encoding and decoding of SecureHD achieve \n626.2\u00d7 and 389.4\u00d7 (35.5\u00d7 and 20.4\u00d7) faster execution as \ncompared to the SecureHD execution on the ARM (Intel i7). \nFor example, the proposed FPGA implementation is able to \nencode 2,600 data points and decode 1,335 for the MNIST \nimages in a second. \n\n\nAuthorized licensed use limited to: Univ of Calif San Diego. Downloaded on May 11,2020 at 08:37:28 UTC from IEEE Xplore. Restrictions apply.\nACKNOWLEDGEMENTSThis work was partially supported by CRISP, one of six centers in JUMP, an SRC program sponsored by DARPA, Office of Naval Research (N00014-17-1-2500), MURI (FA9550-14-1-0351), Semiconductor Research Corporation (2016-TS-2690), and also NSF grants #1730158, #1527034, and #1619261. Authors would like to thank Kazim Ergun from UCSD for his help on the network simulation.\nScaling distributed machine learning with the parameter server. M Li, D G Andersen, J W Park, A J Smola, A Ahmed, V Josifovski, J Long, E J Shekita, B.-Y. Su, OSDI. 14M. Li, D. G. Andersen, J. W. Park, A. J. Smola, A. Ahmed, V. Josifovski, J. Long, E. J. Shekita, and B.-Y. Su, \"Scaling distributed machine learning with the parameter server.\" in OSDI, vol. 14, 2014.\n\nArguing to learn: Confronting cognitions in computer-supported collaborative learning environments. J Andriessen, M Baker, D D Suthers, Springer Science & Business Media1J. Andriessen, M. Baker, and D. D. Suthers, Arguing to learn: Confronting cognitions in computer-supported collaborative learning environments. Springer Science & Business Media, 2013, vol. 1.\n\nBig data analytics over encrypted datasets with seabed. A Papadimitriou, R Bhagwan, N Chandran, R Ramjee, A Haeberlen, H Singh, A Modi, S Badrinarayanan, OSDI. A. Papadimitriou, R. Bhagwan, N. Chandran, R. Ramjee, A. Haeberlen, H. Singh, A. Modi, and S. Badrinarayanan, \"Big data analytics over encrypted datasets with seabed.\" in OSDI, 2016.\n\nBig data classification: Problems and challenges in network intrusion prediction with machine learning. S Suthaharan, ACM SIGMETRICS Performance Evaluation Review. 41S. Suthaharan, \"Big data classification: Problems and challenges in network intrusion prediction with machine learning,\" ACM SIGMETRICS Perfor- mance Evaluation Review, vol. 41, 2014.\n\nA survey of data mining and machine learning methods for cyber security intrusion detection. A L Buczak, E Guven, IEEE Communications Surveys & Tutorials. 18A. L. Buczak and E. Guven, \"A survey of data mining and machine learning methods for cyber security intrusion detection,\" IEEE Communications Surveys & Tutorials, vol. 18, 2016.\n\nTowards the science of security and privacy in machine learning. N Papernot, P Mcdaniel, A Sinha, M Wellman, arXiv:1611.03814arXiv preprintN. Papernot, P. McDaniel, A. Sinha, and M. Wellman, \"Towards the science of security and privacy in machine learning,\" arXiv preprint arXiv:1611.03814, 2016.\n\nMachine learning: Trends, perspectives, and prospects. M I Jordan, T M Mitchell, Science. 349M. I. Jordan and T. M. Mitchell, \"Machine learning: Trends, perspectives, and prospects,\" Science, vol. 349, 2015.\n\nHey, you, get off of my cloud: exploring information leakage in third-party compute clouds. T Ristenpart, E Tromer, H Shacham, S Savage, Proceedings of the 16th ACM conference on Computer and communications security. the 16th ACM conference on Computer and communications securityACMT. Ristenpart, E. Tromer, H. Shacham, and S. Savage, \"Hey, you, get off of my cloud: exploring information leakage in third-party compute clouds,\" in Proceedings of the 16th ACM conference on Computer and communications security. ACM, 2009.\n\nContext-sensitive fencing: Securing speculative execution via microcode customization. M Taram, A Venkat, D Tullsen, International Conference on Architectural Support for Programming Languages and Operating Systems. ACMM. Taram, A. Venkat, and D. Tullsen, \"Context-sensitive fencing: Secur- ing speculative execution via microcode customization,\" in International Conference on Architectural Support for Programming Languages and Operating Systems. ACM, 2019.\n\nMobilizing the micro-ops: Exploiting context sensitive decoding for security and energy efficiency. M Taram, A Venkat, D Tullsen, 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA. IEEEM. Taram, A. Venkat, and D. Tullsen, \"Mobilizing the micro-ops: Ex- ploiting context sensitive decoding for security and energy efficiency,\" in 2018 ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA). IEEE, 2018.\n\nShielding applications from an untrusted cloud with haven. A Baumann, M Peinado, G Hunt, ACM Transactions on Computer Systems (TOCS). 33A. Baumann, M. Peinado, and G. Hunt, \"Shielding applications from an untrusted cloud with haven,\" ACM Transactions on Computer Systems (TOCS), vol. 33, 2015.\n\nTrusted data sharing over untrusted cloud storage providers. G Zhao, C Rong, J Li, F Zhang, Y Tang, Cloud Computing Technology and Science (CloudCom). IEEEIEEE Second International Conference onG. Zhao, C. Rong, J. Li, F. Zhang, and Y. Tang, \"Trusted data sharing over untrusted cloud storage providers,\" in Cloud Computing Technology and Science (CloudCom), 2010 IEEE Second International Conference on. IEEE, 2010.\n\nSporc: Group collaboration using untrusted cloud resources. A J Feldman, W P Zeller, M J Freedman, E W Felten, OSDI. 10A. J. Feldman, W. P. Zeller, M. J. Freedman, and E. W. Felten, \"Sporc: Group collaboration using untrusted cloud resources.\" in OSDI, vol. 10, 2010.\n\nSecure knn query processing in untrusted cloud environments. S Choi, G Ghinita, H.-S Lim, E Bertino, IEEE Transactions on Knowledge and Data Engineering. 26S. Choi, G. Ghinita, H.-S. Lim, and E. Bertino, \"Secure knn query process- ing in untrusted cloud environments,\" IEEE Transactions on Knowledge and Data Engineering, vol. 26, 2014.\n\nFully homomorphic encryption over the integers. M Van Dijk, C Gentry, S Halevi, V Vaikuntanathan, Annual International Conference on the Theory and Applications of Cryptographic Techniques. SpringerM. Van Dijk, C. Gentry, S. Halevi, and V. Vaikuntanathan, \"Fully homo- morphic encryption over the integers,\" in Annual International Conference on the Theory and Applications of Cryptographic Techniques. Springer, 2010.\n\n. H Chen, K Han, Z Huang, A Jalali, K Laine, Simple encrypted arithmetic library v2.3.0,\" in MicrosoftH. Chen, K. Han, Z. Huang, A. Jalali, and K. Laine, \"Simple encrypted arithmetic library v2.3.0,\" in Microsoft, 2017.\n\nPractical secure aggregation for privacy-preserving machine learning. K Bonawitz, V Ivanov, B Kreuter, A Marcedone, H B Mcmahan, S Patel, D Ramage, A Segal, K Seth, CCS. ACMK. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel, D. Ramage, A. Segal, and K. Seth, \"Practical secure aggregation for privacy-preserving machine learning,\" in CCS. ACM, 2017.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive Computation. 1P. Kanerva, \"Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors,\" Cog- nitive Computation, vol. 1, 2009.\n\nWhat we mean when we say \"whats the dollar of mexico?\": Prototypes and mapping in concept space. P Kanerva, AAAI Fall Symposium: Quantum Informatics for Cognitive, Social, and Semantic Processes. P. Kanerva, \"What we mean when we say \"whats the dollar of mexico?\": Prototypes and mapping in concept space,\" in AAAI Fall Symposium: Quantum Informatics for Cognitive, Social, and Semantic Processes, 2010.\n\nRandom indexing of text samples for latent semantic analysis. P Kanerva, J Kristofersson, A Holst, Proceedings of the 22nd annual conference of the cognitive science society. the 22nd annual conference of the cognitive science societyCiteseer1036P. Kanerva, J. Kristofersson, and A. Holst, \"Random indexing of text samples for latent semantic analysis,\" in Proceedings of the 22nd annual conference of the cognitive science society, vol. 1036. Citeseer, 2000.\n\nLow-power sparse hyperdimensional encoder for language recognition. M Imani, J Hwang, T Rosing, A Rahimi, J M Rabaey, IEEE Design & Test. 34M. Imani, J. Hwang, T. Rosing, A. Rahimi, and J. M. Rabaey, \"Low-power sparse hyperdimensional encoder for language recognition,\" IEEE Design & Test, vol. 34, 2017.\n\nA robust and energy-efficient classifier using brain-inspired hyperdimensional computing. A Rahimi, P Kanerva, J M Rabaey, Proceedings of the 2016 International Symposium on Low Power Electronics and Design. the 2016 International Symposium on Low Power Electronics and DesignACMA. Rahimi, P. Kanerva, and J. M. Rabaey, \"A robust and energy-efficient classifier using brain-inspired hyperdimensional computing,\" in Proceed- ings of the 2016 International Symposium on Low Power Electronics and Design. ACM, 2016.\n\nHierarchical hyperdimensional computing for energy efficient classification. M Imani, C Huang, D Kong, T Rosing, 2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC). IEEEM. Imani, C. Huang, D. Kong, and T. Rosing, \"Hierarchical hyperdi- mensional computing for energy efficient classification,\" in 2018 55th ACM/ESDA/IEEE Design Automation Conference (DAC). IEEE, 2018.\n\nVoicehd: Hyperdimensional computing for efficient speech recognition. M Imani, D Kong, A Rahimi, T Rosing, IEEE. in Rebooting Computing (ICRCM. Imani, D. Kong, A. Rahimi, and T. Rosing, \"Voicehd: Hyperdimen- sional computing for efficient speech recognition,\" in Rebooting Computing (ICRC), 2017 IEEE International Conference on. IEEE, 2017.\n\nOptimizing semi-honest secure multiparty computation for the internet. A Ben-Efraim, Y Lindell, E Omri, Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS). the ACM SIGSAC Conference on Computer and Communications Security (CCS)A. Ben-Efraim, Y. Lindell, and E. Omri, \"Optimizing semi-honest secure multiparty computation for the internet,\" in Proceedings of the ACM SIGSAC Conference on Computer and Communications Security (CCS).\n\nExploring hyperdimensional associative memory. M Imani, A Rahimi, D Kong, T Rosing, J M Rabaey, High Performance Computer Architecture (HPCA. IEEE2017 IEEE International Symposium onM. Imani, A. Rahimi, D. Kong, T. Rosing, and J. M. Rabaey, \"Exploring hyperdimensional associative memory,\" in High Performance Computer Architecture (HPCA), 2017 IEEE International Symposium on. IEEE, 2017.\n\nSimple encrypted arithmetic libraryseal v2. 1. H Chen, K Laine, R Player, International Conference on Financial Cryptography and Data Security. SpringerH. Chen, K. Laine, and R. Player, \"Simple encrypted arithmetic library- seal v2. 1,\" in International Conference on Financial Cryptography and Data Security. Springer, 2017.\n\nSecure multi-party computation problems and their applications: a review and open problems. W Du, M J Atallah, Proceedings of the 2001 workshop on New security paradigms. the 2001 workshop on New security paradigmsACMW. Du and M. J. Atallah, \"Secure multi-party computation problems and their applications: a review and open problems,\" in Proceedings of the 2001 workshop on New security paradigms. ACM, 2001.\n\nRandom indexing of text samples for latent semantic analysis. P Kanerva, J Kristofersson, A Holst, Proceedings of the 22nd annual conference of the cognitive science society. the 22nd annual conference of the cognitive science societyCiteseer1036P. Kanerva, J. Kristofersson, and A. Holst, \"Random indexing of text samples for latent semantic analysis,\" in Proceedings of the 22nd annual conference of the cognitive science society, vol. 1036. Citeseer, 2000.\n\nHow to generate and exchange secrets. A C , -C Yao, Foundations of Computer Science. IEEE27th Annual Symposium onA. C.-C. Yao, \"How to generate and exchange secrets,\" in Foundations of Computer Science, 1986., 27th Annual Symposium on. IEEE, 1986.\n\nImproved garbled circuit: Free XOR gates and applications. V Kolesnikov, T Schneider, Automata, Languages and Programming. SpringerV. Kolesnikov and T. Schneider, \"Improved garbled circuit: Free XOR gates and applications,\" in Automata, Languages and Programming. Springer, 2008.\n\nGradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of the IEEE. 86Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \"Gradient-based learning applied to document recognition,\" Proceedings of the IEEE, vol. 86, 1998.\n\nA permutation network. A Waksman, Journal of the ACM (JACM). 15A. Waksman, \"A permutation network,\" Journal of the ACM (JACM), vol. 15, 1968.\n\nNetwork simulations with the ns-3 simulator. T R Henderson, M Lacage, G F Riley, C Dowell, J Kopena, SIGCOMM demonstration. 14T. R. Henderson, M. Lacage, G. F. Riley, C. Dowell, and J. Kopena, \"Network simulations with the ns-3 simulator,\" SIGCOMM demonstration, vol. 14, 2008.\n\nVivado design suite. T Feist, White Paper. 5T. Feist, \"Vivado design suite,\" White Paper, vol. 5, 2012.\n\nMulti-column deep neural networks for image classification. D Ciregan, U Meier, J Schmidhuber, Computer vision and pattern recognition (CVPR). IEEED. Ciregan, U. Meier, and J. Schmidhuber, \"Multi-column deep neural net- works for image classification,\" in Computer vision and pattern recognition (CVPR), 2012 IEEE conference on. IEEE, 2012.\n\nUci machine learning repository. \"Uci machine learning repository,\" http://archive.ics.uci.edu/ml/datasets/ ISOLET.\n\nLooknn: Neural network with no multiplication. M S Razlighi, M Imani, F Koushanfar, T Rosing, 2017 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEEM. S. Razlighi, M. Imani, F. Koushanfar, and T. Rosing, \"Looknn: Neural network with no multiplication,\" in 2017 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEE, 2017.\n\nHuman activity recognition on smartphones using a multiclass hardware-friendly support vector machine. D Anguita, A Ghio, L Oneto, X Parra, J L Reyes-Ortiz, International workshop on ambient assisted living. SpringerD. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz, \"Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine,\" in International workshop on ambient assisted living. Springer, 2012.\n\nIntroducing a new benchmarked dataset for activity monitoring. A Reiss, D Stricker, Wearable Computers (ISWC), 2012 16th International Symposium on. IEEEA. Reiss and D. Stricker, \"Introducing a new benchmarked dataset for activ- ity monitoring,\" in Wearable Computers (ISWC), 2012 16th International Symposium on. IEEE, 2012.\n\nRecognizing detailed human context in the wild from smartphones and smartwatches. Y Vaizman, K Ellis, G Lanckriet, IEEE Pervasive Computing. 16Y. Vaizman, K. Ellis, and G. Lanckriet, \"Recognizing detailed human context in the wild from smartphones and smartwatches,\" IEEE Pervasive Computing, vol. 16, 2017.\n\nOrchard: Visual object recognition accelerator based on approximate in-memory processing. Y Kim, M Imani, T Rosing, Computer-Aided Design (ICCAD. Y. Kim, M. Imani, and T. Rosing, \"Orchard: Visual object recognition accelerator based on approximate in-memory processing,\" in Computer- Aided Design (ICCAD), 2017 IEEE/ACM International Conference on. IEEE, 2017.\n\nCorpus portal for search in monolingual corpora. U Quasthoff, M Richter, C Biemann, Proceedings of the fifth international conference on language resources and evaluation. the fifth international conference on language resources and evaluation17991802U. Quasthoff, M. Richter, and C. Biemann, \"Corpus portal for search in monolingual corpora,\" in Proceedings of the fifth international conference on language resources and evaluation, vol. 17991802, 2006.\n\nChameleon: A hybrid secure computation framework for machine learning applications. M S Riazi, C Weinert, O Tkachenko, E M Songhori, T Schneider, F Koushanfar, ASIACCS. ACMM. S. Riazi, C. Weinert, O. Tkachenko, E. M. Songhori, T. Schneider, and F. Koushanfar, \"Chameleon: A hybrid secure computation framework for machine learning applications,\" in ASIACCS. ACM, 2018.\n\nPrivacy-preserving deep learning. R Shokri, V Shmatikov, CCS. ACMR. Shokri and V. Shmatikov, \"Privacy-preserving deep learning,\" in CCS. ACM, 2015.\n\nPrivacy-preserving deep learning and inference. M S Riazi, F Koushanfar, Proceedings of the International Conference on Computer-Aided Design. the International Conference on Computer-Aided DesignACMM. S. Riazi and F. Koushanfar, \"Privacy-preserving deep learning and inference,\" in Proceedings of the International Conference on Computer- Aided Design. ACM, 2018.\n\nSecureML: A system for scalable privacypreserving machine learning. P Mohassel, Y Zhang, IEEE S&P. P. Mohassel and Y. Zhang, \"SecureML: A system for scalable privacy- preserving machine learning.\" in IEEE S&P, 2017.\n\nDeep learning on private data. M S Riazi, B D Rouhani, F Koushanfar, IEEE Security and Privacy Magazine. IEEEM. S. Riazi, B. D. Rouhani, and F. Koushanfar, \"Deep learning on private data,\" in IEEE Security and Privacy Magazine. IEEE, 2019.\n\nXONN: XNOR-based oblivious deep neural network inference. M S Riazi, M Samragh, H Chen, K Laine, K Lauter, F Koushanfar, USENIX SecurityM. S. Riazi, M. Samragh, H. Chen, K. Laine, K. Lauter, and F. Koushanfar, \"XONN: XNOR-based oblivious deep neural network inference,\" USENIX Security, 2019.\n\nDeep models under the GAN: information leakage from collaborative deep learning. B Hitaj, G Ateniese, F P\u00e9rez-Cruz, CCS. ACMB. Hitaj, G. Ateniese, and F. P\u00e9rez-Cruz, \"Deep models under the GAN: information leakage from collaborative deep learning,\" in CCS. ACM, 2017.\n\nA binary learning framework for hyperdimensional computing. M Imani, J Messerly, F Wu, W Pi, T Rosing, Design Automation and Test in Europe Conference (DATE). IEEE/ACM. M. Imani, J. Messerly, F. Wu, W. Pi, and T. Rosing, \"A binary learning framework for hyperdimensional computing,\" in Design Automation and Test in Europe Conference (DATE). IEEE/ACM, 2019.\n\nLocality-based encoding for energy-efficient braininspired hyperdimensional computing. M Imani, ACM/ESDA/IEEE Design Automation Conference (DAC). IEEEM. Imani et al., \"Locality-based encoding for energy-efficient brain- inspired hyperdimensional computing,\" in ACM/ESDA/IEEE Design Au- tomation Conference (DAC). IEEE, 2019.\n\nHdcluster: An accurate clustering using brain-inspired high-dimensional computing. M Imani, Y Kim, T Worley, S Gupta, T Rosing, Design Automation and Test in Europe Conference (DATE). IEEE/ACM. M. Imani, Y. Kim, T. Worley, S. Gupta, and T. Rosing, \"Hdcluster: An accurate clustering using brain-inspired high-dimensional computing,\" in Design Automation and Test in Europe Conference (DATE). IEEE/ACM, 2019.\n\nF5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing. S Salamat, M Imani, B Khaleghi, T Rosing, International Symposium on Field-Programmable Gate Arrays (FPGA). S. Salamat, M. Imani, B. Khaleghi, and T. Rosing, \"F5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing,\" in International Symposium on Field-Programmable Gate Arrays (FPGA).\n\n. Acm/ Sigda, ACM/SIGDA, 2019.\n\nFach: Fpga-based acceleration of hyperdimensional computing by reducing computational complexity. M Imani, ASP-DAC. IEEEM. Imani et al., \"Fach: Fpga-based acceleration of hyperdimensional computing by reducing computational complexity,\" in ASP-DAC. IEEE, 2019.\n\nSparsehd: Algorithm-hardware co-optimization for efficient high-dimensional computing. M Imani, IEEE FCCM. IEEE. M. Imani et al., \"Sparsehd: Algorithm-hardware co-optimization for effi- cient high-dimensional computing,\" in IEEE FCCM. IEEE, 2019.\n\nBrain-inspired computing exploiting carbon nanotube fets and resistive ram: Hyperdimensional computing case study. T Wu, P Huang, A Rahimi, H Li, J Rabaey, P Wong, S Mitra, IEEE Intl. Solid-State Circuits Conference (ISSCC). IEEET. Wu, P. Huang, A. Rahimi, H. Li, J. Rabaey, P. Wong, and S. Mitra, \"Brain-inspired computing exploiting carbon nanotube fets and resistive ram: Hyperdimensional computing case study,\" in IEEE Intl. Solid-State Circuits Conference (ISSCC). IEEE, 2018.\n\nHyperdimensional computing with 3d vrram in-memory kernels: Device-architecture co-design for energyefficient, error-resilient language recognition. H Li, T F Wu, A Rahimi, K.-S Li, M Rusch, C.-H Lin, J.-L Hsu, M M Sabry, S B Eryilmaz, J Sohn, Electron Devices Meeting (IEDM). H. Li, T. F. Wu, A. Rahimi, K.-S. Li, M. Rusch, C.-H. Lin, J.-L. Hsu, M. M. Sabry, S. B. Eryilmaz, J. Sohn et al., \"Hyperdimensional computing with 3d vrram in-memory kernels: Device-architecture co-design for energy- efficient, error-resilient language recognition,\" in Electron Devices Meeting (IEDM), 2016 IEEE International. IEEE, 2016.\n", "annotations": {"author": "[{\"start\":\"75\",\"end\":\"160\"},{\"start\":\"161\",\"end\":\"228\"},{\"start\":\"229\",\"end\":\"315\"},{\"start\":\"316\",\"end\":\"403\"},{\"start\":\"404\",\"end\":\"485\"},{\"start\":\"486\",\"end\":\"581\"},{\"start\":\"582\",\"end\":\"667\"}]", "publisher": null, "author_last_name": "[{\"start\":\"82\",\"end\":\"87\"},{\"start\":\"169\",\"end\":\"172\"},{\"start\":\"238\",\"end\":\"243\"},{\"start\":\"321\",\"end\":\"329\"},{\"start\":\"411\",\"end\":\"414\"},{\"start\":\"494\",\"end\":\"504\"},{\"start\":\"589\",\"end\":\"595\"}]", "author_first_name": "[{\"start\":\"75\",\"end\":\"81\"},{\"start\":\"161\",\"end\":\"168\"},{\"start\":\"229\",\"end\":\"230\"},{\"start\":\"231\",\"end\":\"237\"},{\"start\":\"316\",\"end\":\"320\"},{\"start\":\"404\",\"end\":\"410\"},{\"start\":\"486\",\"end\":\"493\"},{\"start\":\"582\",\"end\":\"588\"}]", "author_affiliation": "[{\"start\":\"106\",\"end\":\"159\"},{\"start\":\"174\",\"end\":\"227\"},{\"start\":\"261\",\"end\":\"314\"},{\"start\":\"349\",\"end\":\"402\"},{\"start\":\"431\",\"end\":\"484\"},{\"start\":\"527\",\"end\":\"580\"},{\"start\":\"613\",\"end\":\"666\"}]", "title": "[{\"start\":\"1\",\"end\":\"72\"},{\"start\":\"668\",\"end\":\"739\"}]", "venue": null, "abstract": "[{\"start\":\"866\",\"end\":\"2222\"}]", "bib_ref": "[{\"start\":\"2491\",\"end\":\"2494\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"2496\",\"end\":\"2499\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"2501\",\"end\":\"2504\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"2603\",\"end\":\"2606\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"2608\",\"end\":\"2611\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"2613\",\"end\":\"2616\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"2618\",\"end\":\"2621\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"2931\",\"end\":\"2934\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"2936\",\"end\":\"2939\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"2941\",\"end\":\"2945\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"3189\",\"end\":\"3193\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"3195\",\"end\":\"3199\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"3201\",\"end\":\"3205\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"3207\",\"end\":\"3211\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"3504\",\"end\":\"3508\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"3726\",\"end\":\"3730\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"3996\",\"end\":\"4000\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"4567\",\"end\":\"4571\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"5579\",\"end\":\"5583\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"5610\",\"end\":\"5614\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"5637\",\"end\":\"5641\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"5643\",\"end\":\"5647\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"5679\",\"end\":\"5683\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"5685\",\"end\":\"5689\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"6836\",\"end\":\"6840\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"7518\",\"end\":\"7522\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"7524\",\"end\":\"7528\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"10069\",\"end\":\"10073\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"10758\",\"end\":\"10762\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"10867\",\"end\":\"10871\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"11341\",\"end\":\"11345\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"11347\",\"end\":\"11351\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"12305\",\"end\":\"12309\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"12311\",\"end\":\"12315\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"14226\",\"end\":\"14230\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"14800\",\"end\":\"14804\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"14927\",\"end\":\"14931\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"19427\",\"end\":\"19431\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"20035\",\"end\":\"20039\",\"attributes\":{\"ref_id\":\"b32\"}},{\"start\":\"22062\",\"end\":\"22066\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"22547\",\"end\":\"22548\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"27082\",\"end\":\"27083\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"37554\",\"end\":\"37558\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"37722\",\"end\":\"37726\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"37953\",\"end\":\"37957\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"39643\",\"end\":\"39647\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"40245\",\"end\":\"40249\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"40251\",\"end\":\"40255\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"41668\",\"end\":\"41672\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"45474\",\"end\":\"45478\",\"attributes\":{\"ref_id\":\"b42\"}},{\"start\":\"48161\",\"end\":\"48165\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"48167\",\"end\":\"48171\",\"attributes\":{\"ref_id\":\"b43\"}},{\"start\":\"48173\",\"end\":\"48177\",\"attributes\":{\"ref_id\":\"b44\"}},{\"start\":\"48179\",\"end\":\"48183\",\"attributes\":{\"ref_id\":\"b45\"}},{\"start\":\"48185\",\"end\":\"48189\",\"attributes\":{\"ref_id\":\"b46\"}},{\"start\":\"48191\",\"end\":\"48195\",\"attributes\":{\"ref_id\":\"b47\"}},{\"start\":\"48197\",\"end\":\"48201\",\"attributes\":{\"ref_id\":\"b48\"}},{\"start\":\"48224\",\"end\":\"48228\",\"attributes\":{\"ref_id\":\"b44\"}},{\"start\":\"48533\",\"end\":\"48537\",\"attributes\":{\"ref_id\":\"b49\"}},{\"start\":\"48549\",\"end\":\"48553\",\"attributes\":{\"ref_id\":\"b46\"}},{\"start\":\"48810\",\"end\":\"48814\",\"attributes\":{\"ref_id\":\"b43\"}},{\"start\":\"49154\",\"end\":\"49158\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"49623\",\"end\":\"49627\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"49727\",\"end\":\"49731\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"49758\",\"end\":\"49762\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"49785\",\"end\":\"49789\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"49817\",\"end\":\"49821\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"49823\",\"end\":\"49827\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"49850\",\"end\":\"49854\",\"attributes\":{\"ref_id\":\"b50\"}},{\"start\":\"49856\",\"end\":\"49860\",\"attributes\":{\"ref_id\":\"b51\"}},{\"start\":\"49877\",\"end\":\"49881\",\"attributes\":{\"ref_id\":\"b52\"}},{\"start\":\"50300\",\"end\":\"50304\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"50306\",\"end\":\"50310\",\"attributes\":{\"ref_id\":\"b53\"}},{\"start\":\"50312\",\"end\":\"50316\",\"attributes\":{\"ref_id\":\"b55\"}},{\"start\":\"50326\",\"end\":\"50330\",\"attributes\":{\"ref_id\":\"b56\"}},{\"start\":\"50498\",\"end\":\"50502\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"50504\",\"end\":\"50508\",\"attributes\":{\"ref_id\":\"b57\"}},{\"start\":\"50510\",\"end\":\"50514\",\"attributes\":{\"ref_id\":\"b58\"}}]", "figure": "[{\"start\":\"51434\",\"end\":\"51468\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"51469\",\"end\":\"51556\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"51557\",\"end\":\"51730\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"51731\",\"end\":\"51881\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"51882\",\"end\":\"52692\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"52693\",\"end\":\"53677\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"53678\",\"end\":\"53776\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"53777\",\"end\":\"53852\",\"attributes\":{\"id\":\"fig_8\"}},{\"start\":\"53853\",\"end\":\"53893\",\"attributes\":{\"id\":\"fig_9\"}},{\"start\":\"53894\",\"end\":\"54494\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"54495\",\"end\":\"55837\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"2241\",\"end\":\"3212\"},{\"start\":\"3214\",\"end\":\"4324\"},{\"start\":\"4326\",\"end\":\"5094\"},{\"start\":\"5096\",\"end\":\"5690\"},{\"start\":\"5692\",\"end\":\"6396\"},{\"start\":\"6398\",\"end\":\"10599\"},{\"start\":\"10658\",\"end\":\"12105\"},{\"start\":\"12137\",\"end\":\"12738\"},{\"start\":\"12740\",\"end\":\"14231\"},{\"start\":\"14286\",\"end\":\"15033\"},{\"start\":\"15059\",\"end\":\"17443\"},{\"start\":\"17489\",\"end\":\"18655\"},{\"start\":\"18657\",\"end\":\"19432\"},{\"start\":\"19434\",\"end\":\"19761\"},{\"start\":\"19793\",\"end\":\"21072\"},{\"start\":\"21111\",\"end\":\"21775\"},{\"start\":\"21777\",\"end\":\"22067\"},{\"start\":\"22108\",\"end\":\"23447\"},{\"start\":\"23496\",\"end\":\"23950\"},{\"start\":\"23952\",\"end\":\"24322\"},{\"start\":\"24404\",\"end\":\"25680\"},{\"start\":\"25738\",\"end\":\"26209\"},{\"start\":\"26211\",\"end\":\"26381\"},{\"start\":\"26444\",\"end\":\"26726\"},{\"start\":\"26743\",\"end\":\"26804\"},{\"start\":\"26838\",\"end\":\"28344\"},{\"start\":\"28346\",\"end\":\"29962\"},{\"start\":\"29964\",\"end\":\"30550\"},{\"start\":\"30552\",\"end\":\"31671\"},{\"start\":\"31673\",\"end\":\"34699\"},{\"start\":\"34781\",\"end\":\"35189\"},{\"start\":\"35191\",\"end\":\"35750\"},{\"start\":\"35752\",\"end\":\"36281\"},{\"start\":\"36316\",\"end\":\"36518\"},{\"start\":\"36550\",\"end\":\"37217\"},{\"start\":\"37258\",\"end\":\"38713\"},{\"start\":\"38754\",\"end\":\"39496\"},{\"start\":\"39498\",\"end\":\"41319\"},{\"start\":\"41321\",\"end\":\"42739\"},{\"start\":\"42741\",\"end\":\"44105\"},{\"start\":\"44137\",\"end\":\"45366\"},{\"start\":\"45368\",\"end\":\"46665\"},{\"start\":\"46701\",\"end\":\"47623\"},{\"start\":\"47625\",\"end\":\"48024\"},{\"start\":\"48026\",\"end\":\"48538\"},{\"start\":\"48540\",\"end\":\"49097\"},{\"start\":\"49099\",\"end\":\"50199\"},{\"start\":\"50201\",\"end\":\"50622\"},{\"start\":\"50624\",\"end\":\"51433\"}]", "formula": "[{\"start\":\"19762\",\"end\":\"19792\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"22068\",\"end\":\"22107\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"23448\",\"end\":\"23495\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"24323\",\"end\":\"24403\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"25681\",\"end\":\"25737\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"26382\",\"end\":\"26443\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"26727\",\"end\":\"26742\",\"attributes\":{\"id\":\"formula_6\"}},{\"start\":\"26805\",\"end\":\"26837\",\"attributes\":{\"id\":\"formula_7\"}},{\"start\":\"34700\",\"end\":\"34780\",\"attributes\":{\"id\":\"formula_8\"}},{\"start\":\"36282\",\"end\":\"36315\",\"attributes\":{\"id\":\"formula_9\"}}]", "table_ref": "[{\"start\":\"38332\",\"end\":\"38339\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"38897\",\"end\":\"38905\",\"attributes\":{\"ref_id\":\"tab_0\"}}]", "section_header": "[{\"start\":\"2224\",\"end\":\"2239\"},{\"start\":\"10602\",\"end\":\"10656\"},{\"start\":\"12108\",\"end\":\"12135\"},{\"start\":\"14234\",\"end\":\"14284\"},{\"start\":\"15036\",\"end\":\"15057\"},{\"start\":\"17446\",\"end\":\"17487\"},{\"start\":\"21075\",\"end\":\"21109\"},{\"start\":\"36521\",\"end\":\"36548\"},{\"start\":\"37220\",\"end\":\"37256\"},{\"start\":\"38716\",\"end\":\"38752\"},{\"start\":\"44108\",\"end\":\"44135\"},{\"start\":\"46668\",\"end\":\"46699\"},{\"start\":\"51435\",\"end\":\"51445\"},{\"start\":\"51470\",\"end\":\"51480\"},{\"start\":\"51558\",\"end\":\"51568\"},{\"start\":\"51732\",\"end\":\"51742\"},{\"start\":\"51883\",\"end\":\"51893\"},{\"start\":\"53679\",\"end\":\"53690\"},{\"start\":\"53778\",\"end\":\"53800\"},{\"start\":\"53854\",\"end\":\"53865\"},{\"start\":\"53895\",\"end\":\"53902\"},{\"start\":\"54496\",\"end\":\"54513\"}]", "table": "[{\"start\":\"53952\",\"end\":\"54494\"},{\"start\":\"54551\",\"end\":\"55837\"}]", "figure_caption": "[{\"start\":\"51447\",\"end\":\"51468\"},{\"start\":\"51482\",\"end\":\"51556\"},{\"start\":\"51570\",\"end\":\"51730\"},{\"start\":\"51744\",\"end\":\"51881\"},{\"start\":\"51895\",\"end\":\"52692\"},{\"start\":\"52695\",\"end\":\"53677\"},{\"start\":\"53693\",\"end\":\"53776\"},{\"start\":\"53805\",\"end\":\"53852\"},{\"start\":\"53868\",\"end\":\"53893\"},{\"start\":\"53904\",\"end\":\"53952\"},{\"start\":\"54516\",\"end\":\"54551\"}]", "figure_ref": "[{\"start\":\"10075\",\"end\":\"10083\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"10764\",\"end\":\"10772\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"15173\",\"end\":\"15181\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"16788\",\"end\":\"16796\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"20540\",\"end\":\"20548\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"24460\",\"end\":\"24468\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"25170\",\"end\":\"25179\"},{\"start\":\"26505\",\"end\":\"26513\"},{\"start\":\"26937\",\"end\":\"26945\"},{\"start\":\"27556\",\"end\":\"27565\"},{\"start\":\"29010\",\"end\":\"29018\"},{\"start\":\"29228\",\"end\":\"29237\"},{\"start\":\"29624\",\"end\":\"29633\"},{\"start\":\"29755\",\"end\":\"29764\"},{\"start\":\"30098\",\"end\":\"30107\"},{\"start\":\"31240\",\"end\":\"31248\"},{\"start\":\"31730\",\"end\":\"31738\"},{\"start\":\"39750\",\"end\":\"39759\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"40621\",\"end\":\"40630\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"41984\",\"end\":\"41994\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"43115\",\"end\":\"43125\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"43619\",\"end\":\"43629\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"43771\",\"end\":\"43781\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"44301\",\"end\":\"44311\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"45480\",\"end\":\"45490\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"46084\",\"end\":\"46093\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"46937\",\"end\":\"46947\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"47160\",\"end\":\"47169\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"47768\",\"end\":\"47778\",\"attributes\":{\"ref_id\":\"fig_0\"}}]", "bib_author_first_name": "[{\"start\":\"56431\",\"end\":\"56432\"},{\"start\":\"56437\",\"end\":\"56438\"},{\"start\":\"56439\",\"end\":\"56440\"},{\"start\":\"56451\",\"end\":\"56452\"},{\"start\":\"56453\",\"end\":\"56454\"},{\"start\":\"56461\",\"end\":\"56462\"},{\"start\":\"56463\",\"end\":\"56464\"},{\"start\":\"56472\",\"end\":\"56473\"},{\"start\":\"56481\",\"end\":\"56482\"},{\"start\":\"56495\",\"end\":\"56496\"},{\"start\":\"56503\",\"end\":\"56504\"},{\"start\":\"56505\",\"end\":\"56506\"},{\"start\":\"56516\",\"end\":\"56521\"},{\"start\":\"56836\",\"end\":\"56837\"},{\"start\":\"56850\",\"end\":\"56851\"},{\"start\":\"56859\",\"end\":\"56860\"},{\"start\":\"56861\",\"end\":\"56862\"},{\"start\":\"57156\",\"end\":\"57157\"},{\"start\":\"57173\",\"end\":\"57174\"},{\"start\":\"57184\",\"end\":\"57185\"},{\"start\":\"57196\",\"end\":\"57197\"},{\"start\":\"57206\",\"end\":\"57207\"},{\"start\":\"57219\",\"end\":\"57220\"},{\"start\":\"57228\",\"end\":\"57229\"},{\"start\":\"57236\",\"end\":\"57237\"},{\"start\":\"57548\",\"end\":\"57549\"},{\"start\":\"57888\",\"end\":\"57889\"},{\"start\":\"57890\",\"end\":\"57891\"},{\"start\":\"57900\",\"end\":\"57901\"},{\"start\":\"58196\",\"end\":\"58197\"},{\"start\":\"58208\",\"end\":\"58209\"},{\"start\":\"58220\",\"end\":\"58221\"},{\"start\":\"58229\",\"end\":\"58230\"},{\"start\":\"58484\",\"end\":\"58485\"},{\"start\":\"58486\",\"end\":\"58487\"},{\"start\":\"58496\",\"end\":\"58497\"},{\"start\":\"58498\",\"end\":\"58499\"},{\"start\":\"58730\",\"end\":\"58731\"},{\"start\":\"58744\",\"end\":\"58745\"},{\"start\":\"58754\",\"end\":\"58755\"},{\"start\":\"58765\",\"end\":\"58766\"},{\"start\":\"59250\",\"end\":\"59251\"},{\"start\":\"59259\",\"end\":\"59260\"},{\"start\":\"59269\",\"end\":\"59270\"},{\"start\":\"59724\",\"end\":\"59725\"},{\"start\":\"59733\",\"end\":\"59734\"},{\"start\":\"59743\",\"end\":\"59744\"},{\"start\":\"60139\",\"end\":\"60140\"},{\"start\":\"60150\",\"end\":\"60151\"},{\"start\":\"60161\",\"end\":\"60162\"},{\"start\":\"60436\",\"end\":\"60437\"},{\"start\":\"60444\",\"end\":\"60445\"},{\"start\":\"60452\",\"end\":\"60453\"},{\"start\":\"60458\",\"end\":\"60459\"},{\"start\":\"60467\",\"end\":\"60468\"},{\"start\":\"60853\",\"end\":\"60854\"},{\"start\":\"60855\",\"end\":\"60856\"},{\"start\":\"60866\",\"end\":\"60867\"},{\"start\":\"60868\",\"end\":\"60869\"},{\"start\":\"60878\",\"end\":\"60879\"},{\"start\":\"60880\",\"end\":\"60881\"},{\"start\":\"60892\",\"end\":\"60893\"},{\"start\":\"60894\",\"end\":\"60895\"},{\"start\":\"61123\",\"end\":\"61124\"},{\"start\":\"61131\",\"end\":\"61132\"},{\"start\":\"61142\",\"end\":\"61146\"},{\"start\":\"61152\",\"end\":\"61153\"},{\"start\":\"61448\",\"end\":\"61449\"},{\"start\":\"61460\",\"end\":\"61461\"},{\"start\":\"61470\",\"end\":\"61471\"},{\"start\":\"61480\",\"end\":\"61481\"},{\"start\":\"61822\",\"end\":\"61823\"},{\"start\":\"61830\",\"end\":\"61831\"},{\"start\":\"61837\",\"end\":\"61838\"},{\"start\":\"61846\",\"end\":\"61847\"},{\"start\":\"61856\",\"end\":\"61857\"},{\"start\":\"62111\",\"end\":\"62112\"},{\"start\":\"62123\",\"end\":\"62124\"},{\"start\":\"62133\",\"end\":\"62134\"},{\"start\":\"62144\",\"end\":\"62145\"},{\"start\":\"62157\",\"end\":\"62158\"},{\"start\":\"62159\",\"end\":\"62160\"},{\"start\":\"62170\",\"end\":\"62171\"},{\"start\":\"62179\",\"end\":\"62180\"},{\"start\":\"62189\",\"end\":\"62190\"},{\"start\":\"62198\",\"end\":\"62199\"},{\"start\":\"62540\",\"end\":\"62541\"},{\"start\":\"62851\",\"end\":\"62852\"},{\"start\":\"63221\",\"end\":\"63222\"},{\"start\":\"63232\",\"end\":\"63233\"},{\"start\":\"63249\",\"end\":\"63250\"},{\"start\":\"63688\",\"end\":\"63689\"},{\"start\":\"63697\",\"end\":\"63698\"},{\"start\":\"63706\",\"end\":\"63707\"},{\"start\":\"63716\",\"end\":\"63717\"},{\"start\":\"63726\",\"end\":\"63727\"},{\"start\":\"63728\",\"end\":\"63729\"},{\"start\":\"64016\",\"end\":\"64017\"},{\"start\":\"64026\",\"end\":\"64027\"},{\"start\":\"64037\",\"end\":\"64038\"},{\"start\":\"64039\",\"end\":\"64040\"},{\"start\":\"64517\",\"end\":\"64518\"},{\"start\":\"64526\",\"end\":\"64527\"},{\"start\":\"64535\",\"end\":\"64536\"},{\"start\":\"64543\",\"end\":\"64544\"},{\"start\":\"64888\",\"end\":\"64889\"},{\"start\":\"64897\",\"end\":\"64898\"},{\"start\":\"64905\",\"end\":\"64906\"},{\"start\":\"64915\",\"end\":\"64916\"},{\"start\":\"65232\",\"end\":\"65233\"},{\"start\":\"65246\",\"end\":\"65247\"},{\"start\":\"65257\",\"end\":\"65258\"},{\"start\":\"65676\",\"end\":\"65677\"},{\"start\":\"65685\",\"end\":\"65686\"},{\"start\":\"65695\",\"end\":\"65696\"},{\"start\":\"65703\",\"end\":\"65704\"},{\"start\":\"65713\",\"end\":\"65714\"},{\"start\":\"65715\",\"end\":\"65716\"},{\"start\":\"66067\",\"end\":\"66068\"},{\"start\":\"66075\",\"end\":\"66076\"},{\"start\":\"66084\",\"end\":\"66085\"},{\"start\":\"66439\",\"end\":\"66440\"},{\"start\":\"66445\",\"end\":\"66446\"},{\"start\":\"66447\",\"end\":\"66448\"},{\"start\":\"66820\",\"end\":\"66821\"},{\"start\":\"66831\",\"end\":\"66832\"},{\"start\":\"66848\",\"end\":\"66849\"},{\"start\":\"67257\",\"end\":\"67258\"},{\"start\":\"67259\",\"end\":\"67260\"},{\"start\":\"67263\",\"end\":\"67265\"},{\"start\":\"67527\",\"end\":\"67528\"},{\"start\":\"67541\",\"end\":\"67542\"},{\"start\":\"67806\",\"end\":\"67807\"},{\"start\":\"67815\",\"end\":\"67816\"},{\"start\":\"67825\",\"end\":\"67826\"},{\"start\":\"67835\",\"end\":\"67836\"},{\"start\":\"68044\",\"end\":\"68045\"},{\"start\":\"68209\",\"end\":\"68210\"},{\"start\":\"68211\",\"end\":\"68212\"},{\"start\":\"68224\",\"end\":\"68225\"},{\"start\":\"68234\",\"end\":\"68235\"},{\"start\":\"68236\",\"end\":\"68237\"},{\"start\":\"68245\",\"end\":\"68246\"},{\"start\":\"68255\",\"end\":\"68256\"},{\"start\":\"68464\",\"end\":\"68465\"},{\"start\":\"68608\",\"end\":\"68609\"},{\"start\":\"68619\",\"end\":\"68620\"},{\"start\":\"68628\",\"end\":\"68629\"},{\"start\":\"69054\",\"end\":\"69055\"},{\"start\":\"69056\",\"end\":\"69057\"},{\"start\":\"69068\",\"end\":\"69069\"},{\"start\":\"69077\",\"end\":\"69078\"},{\"start\":\"69091\",\"end\":\"69092\"},{\"start\":\"69475\",\"end\":\"69476\"},{\"start\":\"69486\",\"end\":\"69487\"},{\"start\":\"69494\",\"end\":\"69495\"},{\"start\":\"69503\",\"end\":\"69504\"},{\"start\":\"69512\",\"end\":\"69513\"},{\"start\":\"69514\",\"end\":\"69515\"},{\"start\":\"69891\",\"end\":\"69892\"},{\"start\":\"69900\",\"end\":\"69901\"},{\"start\":\"70237\",\"end\":\"70238\"},{\"start\":\"70248\",\"end\":\"70249\"},{\"start\":\"70257\",\"end\":\"70258\"},{\"start\":\"70554\",\"end\":\"70555\"},{\"start\":\"70561\",\"end\":\"70562\"},{\"start\":\"70570\",\"end\":\"70571\"},{\"start\":\"70875\",\"end\":\"70876\"},{\"start\":\"70888\",\"end\":\"70889\"},{\"start\":\"70899\",\"end\":\"70900\"},{\"start\":\"71367\",\"end\":\"71368\"},{\"start\":\"71369\",\"end\":\"71370\"},{\"start\":\"71378\",\"end\":\"71379\"},{\"start\":\"71389\",\"end\":\"71390\"},{\"start\":\"71402\",\"end\":\"71403\"},{\"start\":\"71404\",\"end\":\"71405\"},{\"start\":\"71416\",\"end\":\"71417\"},{\"start\":\"71429\",\"end\":\"71430\"},{\"start\":\"71687\",\"end\":\"71688\"},{\"start\":\"71697\",\"end\":\"71698\"},{\"start\":\"71850\",\"end\":\"71851\"},{\"start\":\"71852\",\"end\":\"71853\"},{\"start\":\"71861\",\"end\":\"71862\"},{\"start\":\"72236\",\"end\":\"72237\"},{\"start\":\"72248\",\"end\":\"72249\"},{\"start\":\"72416\",\"end\":\"72417\"},{\"start\":\"72418\",\"end\":\"72419\"},{\"start\":\"72427\",\"end\":\"72428\"},{\"start\":\"72429\",\"end\":\"72430\"},{\"start\":\"72440\",\"end\":\"72441\"},{\"start\":\"72684\",\"end\":\"72685\"},{\"start\":\"72686\",\"end\":\"72687\"},{\"start\":\"72695\",\"end\":\"72696\"},{\"start\":\"72706\",\"end\":\"72707\"},{\"start\":\"72714\",\"end\":\"72715\"},{\"start\":\"72723\",\"end\":\"72724\"},{\"start\":\"72733\",\"end\":\"72734\"},{\"start\":\"73001\",\"end\":\"73002\"},{\"start\":\"73010\",\"end\":\"73011\"},{\"start\":\"73022\",\"end\":\"73023\"},{\"start\":\"73249\",\"end\":\"73250\"},{\"start\":\"73258\",\"end\":\"73259\"},{\"start\":\"73270\",\"end\":\"73271\"},{\"start\":\"73276\",\"end\":\"73277\"},{\"start\":\"73282\",\"end\":\"73283\"},{\"start\":\"73635\",\"end\":\"73636\"},{\"start\":\"73957\",\"end\":\"73958\"},{\"start\":\"73966\",\"end\":\"73967\"},{\"start\":\"73973\",\"end\":\"73974\"},{\"start\":\"73983\",\"end\":\"73984\"},{\"start\":\"73992\",\"end\":\"73993\"},{\"start\":\"74368\",\"end\":\"74369\"},{\"start\":\"74379\",\"end\":\"74380\"},{\"start\":\"74388\",\"end\":\"74389\"},{\"start\":\"74400\",\"end\":\"74401\"},{\"start\":\"74685\",\"end\":\"74689\"},{\"start\":\"74813\",\"end\":\"74814\"},{\"start\":\"75064\",\"end\":\"75065\"},{\"start\":\"75340\",\"end\":\"75341\"},{\"start\":\"75346\",\"end\":\"75347\"},{\"start\":\"75355\",\"end\":\"75356\"},{\"start\":\"75365\",\"end\":\"75366\"},{\"start\":\"75371\",\"end\":\"75372\"},{\"start\":\"75381\",\"end\":\"75382\"},{\"start\":\"75389\",\"end\":\"75390\"},{\"start\":\"75857\",\"end\":\"75858\"},{\"start\":\"75863\",\"end\":\"75864\"},{\"start\":\"75865\",\"end\":\"75866\"},{\"start\":\"75871\",\"end\":\"75872\"},{\"start\":\"75881\",\"end\":\"75885\"},{\"start\":\"75890\",\"end\":\"75891\"},{\"start\":\"75899\",\"end\":\"75903\"},{\"start\":\"75909\",\"end\":\"75913\"},{\"start\":\"75919\",\"end\":\"75920\"},{\"start\":\"75921\",\"end\":\"75922\"},{\"start\":\"75930\",\"end\":\"75931\"},{\"start\":\"75932\",\"end\":\"75933\"},{\"start\":\"75944\",\"end\":\"75945\"}]", "bib_author_last_name": "[{\"start\":\"56433\",\"end\":\"56435\"},{\"start\":\"56441\",\"end\":\"56449\"},{\"start\":\"56455\",\"end\":\"56459\"},{\"start\":\"56465\",\"end\":\"56470\"},{\"start\":\"56474\",\"end\":\"56479\"},{\"start\":\"56483\",\"end\":\"56493\"},{\"start\":\"56497\",\"end\":\"56501\"},{\"start\":\"56507\",\"end\":\"56514\"},{\"start\":\"56522\",\"end\":\"56524\"},{\"start\":\"56838\",\"end\":\"56848\"},{\"start\":\"56852\",\"end\":\"56857\"},{\"start\":\"56863\",\"end\":\"56870\"},{\"start\":\"57158\",\"end\":\"57171\"},{\"start\":\"57175\",\"end\":\"57182\"},{\"start\":\"57186\",\"end\":\"57194\"},{\"start\":\"57198\",\"end\":\"57204\"},{\"start\":\"57208\",\"end\":\"57217\"},{\"start\":\"57221\",\"end\":\"57226\"},{\"start\":\"57230\",\"end\":\"57234\"},{\"start\":\"57238\",\"end\":\"57252\"},{\"start\":\"57550\",\"end\":\"57560\"},{\"start\":\"57892\",\"end\":\"57898\"},{\"start\":\"57902\",\"end\":\"57907\"},{\"start\":\"58198\",\"end\":\"58206\"},{\"start\":\"58210\",\"end\":\"58218\"},{\"start\":\"58222\",\"end\":\"58227\"},{\"start\":\"58231\",\"end\":\"58238\"},{\"start\":\"58488\",\"end\":\"58494\"},{\"start\":\"58500\",\"end\":\"58508\"},{\"start\":\"58732\",\"end\":\"58742\"},{\"start\":\"58746\",\"end\":\"58752\"},{\"start\":\"58756\",\"end\":\"58763\"},{\"start\":\"58767\",\"end\":\"58773\"},{\"start\":\"59252\",\"end\":\"59257\"},{\"start\":\"59261\",\"end\":\"59267\"},{\"start\":\"59271\",\"end\":\"59278\"},{\"start\":\"59726\",\"end\":\"59731\"},{\"start\":\"59735\",\"end\":\"59741\"},{\"start\":\"59745\",\"end\":\"59752\"},{\"start\":\"60141\",\"end\":\"60148\"},{\"start\":\"60152\",\"end\":\"60159\"},{\"start\":\"60163\",\"end\":\"60167\"},{\"start\":\"60438\",\"end\":\"60442\"},{\"start\":\"60446\",\"end\":\"60450\"},{\"start\":\"60454\",\"end\":\"60456\"},{\"start\":\"60460\",\"end\":\"60465\"},{\"start\":\"60469\",\"end\":\"60473\"},{\"start\":\"60857\",\"end\":\"60864\"},{\"start\":\"60870\",\"end\":\"60876\"},{\"start\":\"60882\",\"end\":\"60890\"},{\"start\":\"60896\",\"end\":\"60902\"},{\"start\":\"61125\",\"end\":\"61129\"},{\"start\":\"61133\",\"end\":\"61140\"},{\"start\":\"61147\",\"end\":\"61150\"},{\"start\":\"61154\",\"end\":\"61161\"},{\"start\":\"61450\",\"end\":\"61458\"},{\"start\":\"61462\",\"end\":\"61468\"},{\"start\":\"61472\",\"end\":\"61478\"},{\"start\":\"61482\",\"end\":\"61496\"},{\"start\":\"61824\",\"end\":\"61828\"},{\"start\":\"61832\",\"end\":\"61835\"},{\"start\":\"61839\",\"end\":\"61844\"},{\"start\":\"61848\",\"end\":\"61854\"},{\"start\":\"61858\",\"end\":\"61863\"},{\"start\":\"62113\",\"end\":\"62121\"},{\"start\":\"62125\",\"end\":\"62131\"},{\"start\":\"62135\",\"end\":\"62142\"},{\"start\":\"62146\",\"end\":\"62155\"},{\"start\":\"62161\",\"end\":\"62168\"},{\"start\":\"62172\",\"end\":\"62177\"},{\"start\":\"62181\",\"end\":\"62187\"},{\"start\":\"62191\",\"end\":\"62196\"},{\"start\":\"62200\",\"end\":\"62204\"},{\"start\":\"62542\",\"end\":\"62549\"},{\"start\":\"62853\",\"end\":\"62860\"},{\"start\":\"63223\",\"end\":\"63230\"},{\"start\":\"63234\",\"end\":\"63247\"},{\"start\":\"63251\",\"end\":\"63256\"},{\"start\":\"63690\",\"end\":\"63695\"},{\"start\":\"63699\",\"end\":\"63704\"},{\"start\":\"63708\",\"end\":\"63714\"},{\"start\":\"63718\",\"end\":\"63724\"},{\"start\":\"63730\",\"end\":\"63736\"},{\"start\":\"64018\",\"end\":\"64024\"},{\"start\":\"64028\",\"end\":\"64035\"},{\"start\":\"64041\",\"end\":\"64047\"},{\"start\":\"64519\",\"end\":\"64524\"},{\"start\":\"64528\",\"end\":\"64533\"},{\"start\":\"64537\",\"end\":\"64541\"},{\"start\":\"64545\",\"end\":\"64551\"},{\"start\":\"64890\",\"end\":\"64895\"},{\"start\":\"64899\",\"end\":\"64903\"},{\"start\":\"64907\",\"end\":\"64913\"},{\"start\":\"64917\",\"end\":\"64923\"},{\"start\":\"65234\",\"end\":\"65244\"},{\"start\":\"65248\",\"end\":\"65255\"},{\"start\":\"65259\",\"end\":\"65263\"},{\"start\":\"65678\",\"end\":\"65683\"},{\"start\":\"65687\",\"end\":\"65693\"},{\"start\":\"65697\",\"end\":\"65701\"},{\"start\":\"65705\",\"end\":\"65711\"},{\"start\":\"65717\",\"end\":\"65723\"},{\"start\":\"66069\",\"end\":\"66073\"},{\"start\":\"66077\",\"end\":\"66082\"},{\"start\":\"66086\",\"end\":\"66092\"},{\"start\":\"66441\",\"end\":\"66443\"},{\"start\":\"66449\",\"end\":\"66456\"},{\"start\":\"66822\",\"end\":\"66829\"},{\"start\":\"66833\",\"end\":\"66846\"},{\"start\":\"66850\",\"end\":\"66855\"},{\"start\":\"67266\",\"end\":\"67269\"},{\"start\":\"67529\",\"end\":\"67539\"},{\"start\":\"67543\",\"end\":\"67552\"},{\"start\":\"67808\",\"end\":\"67813\"},{\"start\":\"67817\",\"end\":\"67823\"},{\"start\":\"67827\",\"end\":\"67833\"},{\"start\":\"67837\",\"end\":\"67844\"},{\"start\":\"68046\",\"end\":\"68053\"},{\"start\":\"68213\",\"end\":\"68222\"},{\"start\":\"68226\",\"end\":\"68232\"},{\"start\":\"68238\",\"end\":\"68243\"},{\"start\":\"68247\",\"end\":\"68253\"},{\"start\":\"68257\",\"end\":\"68263\"},{\"start\":\"68466\",\"end\":\"68471\"},{\"start\":\"68610\",\"end\":\"68617\"},{\"start\":\"68621\",\"end\":\"68626\"},{\"start\":\"68630\",\"end\":\"68641\"},{\"start\":\"69058\",\"end\":\"69066\"},{\"start\":\"69070\",\"end\":\"69075\"},{\"start\":\"69079\",\"end\":\"69089\"},{\"start\":\"69093\",\"end\":\"69099\"},{\"start\":\"69477\",\"end\":\"69484\"},{\"start\":\"69488\",\"end\":\"69492\"},{\"start\":\"69496\",\"end\":\"69501\"},{\"start\":\"69505\",\"end\":\"69510\"},{\"start\":\"69516\",\"end\":\"69527\"},{\"start\":\"69893\",\"end\":\"69898\"},{\"start\":\"69902\",\"end\":\"69910\"},{\"start\":\"70239\",\"end\":\"70246\"},{\"start\":\"70250\",\"end\":\"70255\"},{\"start\":\"70259\",\"end\":\"70268\"},{\"start\":\"70556\",\"end\":\"70559\"},{\"start\":\"70563\",\"end\":\"70568\"},{\"start\":\"70572\",\"end\":\"70578\"},{\"start\":\"70877\",\"end\":\"70886\"},{\"start\":\"70890\",\"end\":\"70897\"},{\"start\":\"70901\",\"end\":\"70908\"},{\"start\":\"71371\",\"end\":\"71376\"},{\"start\":\"71380\",\"end\":\"71387\"},{\"start\":\"71391\",\"end\":\"71400\"},{\"start\":\"71406\",\"end\":\"71414\"},{\"start\":\"71418\",\"end\":\"71427\"},{\"start\":\"71431\",\"end\":\"71441\"},{\"start\":\"71689\",\"end\":\"71695\"},{\"start\":\"71699\",\"end\":\"71708\"},{\"start\":\"71854\",\"end\":\"71859\"},{\"start\":\"71863\",\"end\":\"71873\"},{\"start\":\"72238\",\"end\":\"72246\"},{\"start\":\"72250\",\"end\":\"72255\"},{\"start\":\"72420\",\"end\":\"72425\"},{\"start\":\"72431\",\"end\":\"72438\"},{\"start\":\"72442\",\"end\":\"72452\"},{\"start\":\"72688\",\"end\":\"72693\"},{\"start\":\"72697\",\"end\":\"72704\"},{\"start\":\"72708\",\"end\":\"72712\"},{\"start\":\"72716\",\"end\":\"72721\"},{\"start\":\"72725\",\"end\":\"72731\"},{\"start\":\"72735\",\"end\":\"72745\"},{\"start\":\"73003\",\"end\":\"73008\"},{\"start\":\"73012\",\"end\":\"73020\"},{\"start\":\"73024\",\"end\":\"73034\"},{\"start\":\"73251\",\"end\":\"73256\"},{\"start\":\"73260\",\"end\":\"73268\"},{\"start\":\"73272\",\"end\":\"73274\"},{\"start\":\"73278\",\"end\":\"73280\"},{\"start\":\"73284\",\"end\":\"73290\"},{\"start\":\"73637\",\"end\":\"73642\"},{\"start\":\"73959\",\"end\":\"73964\"},{\"start\":\"73968\",\"end\":\"73971\"},{\"start\":\"73975\",\"end\":\"73981\"},{\"start\":\"73985\",\"end\":\"73990\"},{\"start\":\"73994\",\"end\":\"74000\"},{\"start\":\"74370\",\"end\":\"74377\"},{\"start\":\"74381\",\"end\":\"74386\"},{\"start\":\"74390\",\"end\":\"74398\"},{\"start\":\"74402\",\"end\":\"74408\"},{\"start\":\"74690\",\"end\":\"74695\"},{\"start\":\"74815\",\"end\":\"74820\"},{\"start\":\"75066\",\"end\":\"75071\"},{\"start\":\"75342\",\"end\":\"75344\"},{\"start\":\"75348\",\"end\":\"75353\"},{\"start\":\"75357\",\"end\":\"75363\"},{\"start\":\"75367\",\"end\":\"75369\"},{\"start\":\"75373\",\"end\":\"75379\"},{\"start\":\"75383\",\"end\":\"75387\"},{\"start\":\"75391\",\"end\":\"75396\"},{\"start\":\"75859\",\"end\":\"75861\"},{\"start\":\"75867\",\"end\":\"75869\"},{\"start\":\"75873\",\"end\":\"75879\"},{\"start\":\"75886\",\"end\":\"75888\"},{\"start\":\"75892\",\"end\":\"75897\"},{\"start\":\"75904\",\"end\":\"75907\"},{\"start\":\"75914\",\"end\":\"75917\"},{\"start\":\"75923\",\"end\":\"75928\"},{\"start\":\"75934\",\"end\":\"75942\"},{\"start\":\"75946\",\"end\":\"75950\"}]", "bib_entry": "[{\"start\":\"56367\",\"end\":\"56734\",\"attributes\":{\"matched_paper_id\":\"4614646\",\"id\":\"b0\"}},{\"start\":\"56736\",\"end\":\"57098\",\"attributes\":{\"id\":\"b1\"}},{\"start\":\"57100\",\"end\":\"57442\",\"attributes\":{\"matched_paper_id\":\"2593828\",\"id\":\"b2\"}},{\"start\":\"57444\",\"end\":\"57793\",\"attributes\":{\"matched_paper_id\":\"916066\",\"id\":\"b3\"}},{\"start\":\"57795\",\"end\":\"58129\",\"attributes\":{\"matched_paper_id\":\"44606951\",\"id\":\"b4\"}},{\"start\":\"58131\",\"end\":\"58427\",\"attributes\":{\"id\":\"b5\",\"doi\":\"arXiv:1611.03814\"}},{\"start\":\"58429\",\"end\":\"58636\",\"attributes\":{\"matched_paper_id\":\"677218\",\"id\":\"b6\"}},{\"start\":\"58638\",\"end\":\"59161\",\"attributes\":{\"matched_paper_id\":\"1276493\",\"id\":\"b7\"}},{\"start\":\"59163\",\"end\":\"59622\",\"attributes\":{\"matched_paper_id\":\"53657225\",\"id\":\"b8\"}},{\"start\":\"59624\",\"end\":\"60078\",\"attributes\":{\"matched_paper_id\":\"4939154\",\"id\":\"b9\"}},{\"start\":\"60080\",\"end\":\"60373\",\"attributes\":{\"matched_paper_id\":\"11437341\",\"id\":\"b10\"}},{\"start\":\"60375\",\"end\":\"60791\",\"attributes\":{\"matched_paper_id\":\"15405085\",\"id\":\"b11\"}},{\"start\":\"60793\",\"end\":\"61060\",\"attributes\":{\"matched_paper_id\":\"13930531\",\"id\":\"b12\"}},{\"start\":\"61062\",\"end\":\"61398\",\"attributes\":{\"matched_paper_id\":\"15566914\",\"id\":\"b13\"}},{\"start\":\"61400\",\"end\":\"61818\",\"attributes\":{\"matched_paper_id\":\"5627147\",\"id\":\"b14\"}},{\"start\":\"61820\",\"end\":\"62039\",\"attributes\":{\"id\":\"b15\"}},{\"start\":\"62041\",\"end\":\"62413\",\"attributes\":{\"matched_paper_id\":\"3833774\",\"id\":\"b16\"}},{\"start\":\"62415\",\"end\":\"62752\",\"attributes\":{\"matched_paper_id\":\"733980\",\"id\":\"b17\"}},{\"start\":\"62754\",\"end\":\"63157\",\"attributes\":{\"matched_paper_id\":\"7149851\",\"id\":\"b18\"}},{\"start\":\"63159\",\"end\":\"63618\",\"attributes\":{\"matched_paper_id\":\"60571601\",\"id\":\"b19\"}},{\"start\":\"63620\",\"end\":\"63924\",\"attributes\":{\"matched_paper_id\":\"8038292\",\"id\":\"b20\"}},{\"start\":\"63926\",\"end\":\"64438\",\"attributes\":{\"matched_paper_id\":\"9812826\",\"id\":\"b21\"}},{\"start\":\"64440\",\"end\":\"64816\",\"attributes\":{\"matched_paper_id\":\"49301394\",\"id\":\"b22\"}},{\"start\":\"64818\",\"end\":\"65159\",\"attributes\":{\"matched_paper_id\":\"21351739\",\"id\":\"b23\"}},{\"start\":\"65161\",\"end\":\"65627\",\"attributes\":{\"matched_paper_id\":\"6050547\",\"id\":\"b24\"}},{\"start\":\"65629\",\"end\":\"66018\",\"attributes\":{\"matched_paper_id\":\"1677864\",\"id\":\"b25\"}},{\"start\":\"66020\",\"end\":\"66345\",\"attributes\":{\"matched_paper_id\":\"3606950\",\"id\":\"b26\"}},{\"start\":\"66347\",\"end\":\"66756\",\"attributes\":{\"matched_paper_id\":\"5505223\",\"id\":\"b27\"}},{\"start\":\"66758\",\"end\":\"67217\",\"attributes\":{\"matched_paper_id\":\"60571601\",\"id\":\"b28\"}},{\"start\":\"67219\",\"end\":\"67466\",\"attributes\":{\"matched_paper_id\":\"296057\",\"id\":\"b29\"}},{\"start\":\"67468\",\"end\":\"67747\",\"attributes\":{\"matched_paper_id\":\"7746167\",\"id\":\"b30\"}},{\"start\":\"67749\",\"end\":\"68019\",\"attributes\":{\"matched_paper_id\":\"14542261\",\"id\":\"b31\"}},{\"start\":\"68021\",\"end\":\"68162\",\"attributes\":{\"matched_paper_id\":\"1380247\",\"id\":\"b32\"}},{\"start\":\"68164\",\"end\":\"68441\",\"attributes\":{\"matched_paper_id\":\"18689058\",\"id\":\"b33\"}},{\"start\":\"68443\",\"end\":\"68546\",\"attributes\":{\"matched_paper_id\":\"110511037\",\"id\":\"b34\"}},{\"start\":\"68548\",\"end\":\"68888\",\"attributes\":{\"matched_paper_id\":\"2161592\",\"id\":\"b35\"}},{\"start\":\"68890\",\"end\":\"69005\",\"attributes\":{\"id\":\"b36\"}},{\"start\":\"69007\",\"end\":\"69370\",\"attributes\":{\"matched_paper_id\":\"34011320\",\"id\":\"b37\"}},{\"start\":\"69372\",\"end\":\"69826\",\"attributes\":{\"matched_paper_id\":\"13178535\",\"id\":\"b38\"}},{\"start\":\"69828\",\"end\":\"70153\",\"attributes\":{\"matched_paper_id\":\"10337279\",\"id\":\"b39\"}},{\"start\":\"70155\",\"end\":\"70462\",\"attributes\":{\"matched_paper_id\":\"8728742\",\"id\":\"b40\"}},{\"start\":\"70464\",\"end\":\"70824\",\"attributes\":{\"matched_paper_id\":\"4701912\",\"id\":\"b41\"}},{\"start\":\"70826\",\"end\":\"71281\",\"attributes\":{\"matched_paper_id\":\"17089484\",\"id\":\"b42\"}},{\"start\":\"71283\",\"end\":\"71651\",\"attributes\":{\"matched_paper_id\":\"3638420\",\"id\":\"b43\"}},{\"start\":\"71653\",\"end\":\"71800\",\"attributes\":{\"matched_paper_id\":\"20714\",\"id\":\"b44\"}},{\"start\":\"71802\",\"end\":\"72166\",\"attributes\":{\"matched_paper_id\":\"53238079\",\"id\":\"b45\"}},{\"start\":\"72168\",\"end\":\"72383\",\"attributes\":{\"matched_paper_id\":\"11605311\",\"id\":\"b46\"}},{\"start\":\"72385\",\"end\":\"72624\",\"attributes\":{\"matched_paper_id\":\"199459168\",\"id\":\"b47\"}},{\"start\":\"72626\",\"end\":\"72918\",\"attributes\":{\"id\":\"b48\"}},{\"start\":\"72920\",\"end\":\"73187\",\"attributes\":{\"matched_paper_id\":\"5051282\",\"id\":\"b49\"}},{\"start\":\"73189\",\"end\":\"73546\",\"attributes\":{\"matched_paper_id\":\"155109576\",\"id\":\"b50\"}},{\"start\":\"73548\",\"end\":\"73872\",\"attributes\":{\"id\":\"b51\"}},{\"start\":\"73874\",\"end\":\"74281\",\"attributes\":{\"matched_paper_id\":\"155106744\",\"id\":\"b52\"}},{\"start\":\"74283\",\"end\":\"74681\",\"attributes\":{\"matched_paper_id\":\"67872077\",\"id\":\"b53\"}},{\"start\":\"74683\",\"end\":\"74713\",\"attributes\":{\"id\":\"b54\"}},{\"start\":\"74715\",\"end\":\"74975\",\"attributes\":{\"matched_paper_id\":\"58027670\",\"id\":\"b55\"}},{\"start\":\"74977\",\"end\":\"75223\",\"attributes\":{\"matched_paper_id\":\"189824904\",\"id\":\"b56\"}},{\"start\":\"75225\",\"end\":\"75706\",\"attributes\":{\"matched_paper_id\":\"3869844\",\"id\":\"b57\"}},{\"start\":\"75708\",\"end\":\"76325\",\"attributes\":{\"matched_paper_id\":\"25209638\",\"id\":\"b58\"}}]", "bib_title": "[{\"start\":\"56367\",\"end\":\"56429\"},{\"start\":\"57100\",\"end\":\"57154\"},{\"start\":\"57444\",\"end\":\"57546\"},{\"start\":\"57795\",\"end\":\"57886\"},{\"start\":\"58429\",\"end\":\"58482\"},{\"start\":\"58638\",\"end\":\"58728\"},{\"start\":\"59163\",\"end\":\"59248\"},{\"start\":\"59624\",\"end\":\"59722\"},{\"start\":\"60080\",\"end\":\"60137\"},{\"start\":\"60375\",\"end\":\"60434\"},{\"start\":\"60793\",\"end\":\"60851\"},{\"start\":\"61062\",\"end\":\"61121\"},{\"start\":\"61400\",\"end\":\"61446\"},{\"start\":\"62041\",\"end\":\"62109\"},{\"start\":\"62415\",\"end\":\"62538\"},{\"start\":\"62754\",\"end\":\"62849\"},{\"start\":\"63159\",\"end\":\"63219\"},{\"start\":\"63620\",\"end\":\"63686\"},{\"start\":\"63926\",\"end\":\"64014\"},{\"start\":\"64440\",\"end\":\"64515\"},{\"start\":\"64818\",\"end\":\"64886\"},{\"start\":\"65161\",\"end\":\"65230\"},{\"start\":\"65629\",\"end\":\"65674\"},{\"start\":\"66020\",\"end\":\"66065\"},{\"start\":\"66347\",\"end\":\"66437\"},{\"start\":\"66758\",\"end\":\"66818\"},{\"start\":\"67219\",\"end\":\"67255\"},{\"start\":\"67468\",\"end\":\"67525\"},{\"start\":\"67749\",\"end\":\"67804\"},{\"start\":\"68021\",\"end\":\"68042\"},{\"start\":\"68164\",\"end\":\"68207\"},{\"start\":\"68443\",\"end\":\"68462\"},{\"start\":\"68548\",\"end\":\"68606\"},{\"start\":\"69007\",\"end\":\"69052\"},{\"start\":\"69372\",\"end\":\"69473\"},{\"start\":\"69828\",\"end\":\"69889\"},{\"start\":\"70155\",\"end\":\"70235\"},{\"start\":\"70464\",\"end\":\"70552\"},{\"start\":\"70826\",\"end\":\"70873\"},{\"start\":\"71283\",\"end\":\"71365\"},{\"start\":\"71653\",\"end\":\"71685\"},{\"start\":\"71802\",\"end\":\"71848\"},{\"start\":\"72168\",\"end\":\"72234\"},{\"start\":\"72385\",\"end\":\"72414\"},{\"start\":\"72920\",\"end\":\"72999\"},{\"start\":\"73189\",\"end\":\"73247\"},{\"start\":\"73548\",\"end\":\"73633\"},{\"start\":\"73874\",\"end\":\"73955\"},{\"start\":\"74283\",\"end\":\"74366\"},{\"start\":\"74715\",\"end\":\"74811\"},{\"start\":\"74977\",\"end\":\"75062\"},{\"start\":\"75225\",\"end\":\"75338\"},{\"start\":\"75708\",\"end\":\"75855\"}]", "bib_author": "[{\"start\":\"56431\",\"end\":\"56437\"},{\"start\":\"56437\",\"end\":\"56451\"},{\"start\":\"56451\",\"end\":\"56461\"},{\"start\":\"56461\",\"end\":\"56472\"},{\"start\":\"56472\",\"end\":\"56481\"},{\"start\":\"56481\",\"end\":\"56495\"},{\"start\":\"56495\",\"end\":\"56503\"},{\"start\":\"56503\",\"end\":\"56516\"},{\"start\":\"56516\",\"end\":\"56526\"},{\"start\":\"56836\",\"end\":\"56850\"},{\"start\":\"56850\",\"end\":\"56859\"},{\"start\":\"56859\",\"end\":\"56872\"},{\"start\":\"57156\",\"end\":\"57173\"},{\"start\":\"57173\",\"end\":\"57184\"},{\"start\":\"57184\",\"end\":\"57196\"},{\"start\":\"57196\",\"end\":\"57206\"},{\"start\":\"57206\",\"end\":\"57219\"},{\"start\":\"57219\",\"end\":\"57228\"},{\"start\":\"57228\",\"end\":\"57236\"},{\"start\":\"57236\",\"end\":\"57254\"},{\"start\":\"57548\",\"end\":\"57562\"},{\"start\":\"57888\",\"end\":\"57900\"},{\"start\":\"57900\",\"end\":\"57909\"},{\"start\":\"58196\",\"end\":\"58208\"},{\"start\":\"58208\",\"end\":\"58220\"},{\"start\":\"58220\",\"end\":\"58229\"},{\"start\":\"58229\",\"end\":\"58240\"},{\"start\":\"58484\",\"end\":\"58496\"},{\"start\":\"58496\",\"end\":\"58510\"},{\"start\":\"58730\",\"end\":\"58744\"},{\"start\":\"58744\",\"end\":\"58754\"},{\"start\":\"58754\",\"end\":\"58765\"},{\"start\":\"58765\",\"end\":\"58775\"},{\"start\":\"59250\",\"end\":\"59259\"},{\"start\":\"59259\",\"end\":\"59269\"},{\"start\":\"59269\",\"end\":\"59280\"},{\"start\":\"59724\",\"end\":\"59733\"},{\"start\":\"59733\",\"end\":\"59743\"},{\"start\":\"59743\",\"end\":\"59754\"},{\"start\":\"60139\",\"end\":\"60150\"},{\"start\":\"60150\",\"end\":\"60161\"},{\"start\":\"60161\",\"end\":\"60169\"},{\"start\":\"60436\",\"end\":\"60444\"},{\"start\":\"60444\",\"end\":\"60452\"},{\"start\":\"60452\",\"end\":\"60458\"},{\"start\":\"60458\",\"end\":\"60467\"},{\"start\":\"60467\",\"end\":\"60475\"},{\"start\":\"60853\",\"end\":\"60866\"},{\"start\":\"60866\",\"end\":\"60878\"},{\"start\":\"60878\",\"end\":\"60892\"},{\"start\":\"60892\",\"end\":\"60904\"},{\"start\":\"61123\",\"end\":\"61131\"},{\"start\":\"61131\",\"end\":\"61142\"},{\"start\":\"61142\",\"end\":\"61152\"},{\"start\":\"61152\",\"end\":\"61163\"},{\"start\":\"61448\",\"end\":\"61460\"},{\"start\":\"61460\",\"end\":\"61470\"},{\"start\":\"61470\",\"end\":\"61480\"},{\"start\":\"61480\",\"end\":\"61498\"},{\"start\":\"61822\",\"end\":\"61830\"},{\"start\":\"61830\",\"end\":\"61837\"},{\"start\":\"61837\",\"end\":\"61846\"},{\"start\":\"61846\",\"end\":\"61856\"},{\"start\":\"61856\",\"end\":\"61865\"},{\"start\":\"62111\",\"end\":\"62123\"},{\"start\":\"62123\",\"end\":\"62133\"},{\"start\":\"62133\",\"end\":\"62144\"},{\"start\":\"62144\",\"end\":\"62157\"},{\"start\":\"62157\",\"end\":\"62170\"},{\"start\":\"62170\",\"end\":\"62179\"},{\"start\":\"62179\",\"end\":\"62189\"},{\"start\":\"62189\",\"end\":\"62198\"},{\"start\":\"62198\",\"end\":\"62206\"},{\"start\":\"62540\",\"end\":\"62551\"},{\"start\":\"62851\",\"end\":\"62862\"},{\"start\":\"63221\",\"end\":\"63232\"},{\"start\":\"63232\",\"end\":\"63249\"},{\"start\":\"63249\",\"end\":\"63258\"},{\"start\":\"63688\",\"end\":\"63697\"},{\"start\":\"63697\",\"end\":\"63706\"},{\"start\":\"63706\",\"end\":\"63716\"},{\"start\":\"63716\",\"end\":\"63726\"},{\"start\":\"63726\",\"end\":\"63738\"},{\"start\":\"64016\",\"end\":\"64026\"},{\"start\":\"64026\",\"end\":\"64037\"},{\"start\":\"64037\",\"end\":\"64049\"},{\"start\":\"64517\",\"end\":\"64526\"},{\"start\":\"64526\",\"end\":\"64535\"},{\"start\":\"64535\",\"end\":\"64543\"},{\"start\":\"64543\",\"end\":\"64553\"},{\"start\":\"64888\",\"end\":\"64897\"},{\"start\":\"64897\",\"end\":\"64905\"},{\"start\":\"64905\",\"end\":\"64915\"},{\"start\":\"64915\",\"end\":\"64925\"},{\"start\":\"65232\",\"end\":\"65246\"},{\"start\":\"65246\",\"end\":\"65257\"},{\"start\":\"65257\",\"end\":\"65265\"},{\"start\":\"65676\",\"end\":\"65685\"},{\"start\":\"65685\",\"end\":\"65695\"},{\"start\":\"65695\",\"end\":\"65703\"},{\"start\":\"65703\",\"end\":\"65713\"},{\"start\":\"65713\",\"end\":\"65725\"},{\"start\":\"66067\",\"end\":\"66075\"},{\"start\":\"66075\",\"end\":\"66084\"},{\"start\":\"66084\",\"end\":\"66094\"},{\"start\":\"66439\",\"end\":\"66445\"},{\"start\":\"66445\",\"end\":\"66458\"},{\"start\":\"66820\",\"end\":\"66831\"},{\"start\":\"66831\",\"end\":\"66848\"},{\"start\":\"66848\",\"end\":\"66857\"},{\"start\":\"67257\",\"end\":\"67263\"},{\"start\":\"67263\",\"end\":\"67271\"},{\"start\":\"67527\",\"end\":\"67541\"},{\"start\":\"67541\",\"end\":\"67554\"},{\"start\":\"67806\",\"end\":\"67815\"},{\"start\":\"67815\",\"end\":\"67825\"},{\"start\":\"67825\",\"end\":\"67835\"},{\"start\":\"67835\",\"end\":\"67846\"},{\"start\":\"68044\",\"end\":\"68055\"},{\"start\":\"68209\",\"end\":\"68224\"},{\"start\":\"68224\",\"end\":\"68234\"},{\"start\":\"68234\",\"end\":\"68245\"},{\"start\":\"68245\",\"end\":\"68255\"},{\"start\":\"68255\",\"end\":\"68265\"},{\"start\":\"68464\",\"end\":\"68473\"},{\"start\":\"68608\",\"end\":\"68619\"},{\"start\":\"68619\",\"end\":\"68628\"},{\"start\":\"68628\",\"end\":\"68643\"},{\"start\":\"69054\",\"end\":\"69068\"},{\"start\":\"69068\",\"end\":\"69077\"},{\"start\":\"69077\",\"end\":\"69091\"},{\"start\":\"69091\",\"end\":\"69101\"},{\"start\":\"69475\",\"end\":\"69486\"},{\"start\":\"69486\",\"end\":\"69494\"},{\"start\":\"69494\",\"end\":\"69503\"},{\"start\":\"69503\",\"end\":\"69512\"},{\"start\":\"69512\",\"end\":\"69529\"},{\"start\":\"69891\",\"end\":\"69900\"},{\"start\":\"69900\",\"end\":\"69912\"},{\"start\":\"70237\",\"end\":\"70248\"},{\"start\":\"70248\",\"end\":\"70257\"},{\"start\":\"70257\",\"end\":\"70270\"},{\"start\":\"70554\",\"end\":\"70561\"},{\"start\":\"70561\",\"end\":\"70570\"},{\"start\":\"70570\",\"end\":\"70580\"},{\"start\":\"70875\",\"end\":\"70888\"},{\"start\":\"70888\",\"end\":\"70899\"},{\"start\":\"70899\",\"end\":\"70910\"},{\"start\":\"71367\",\"end\":\"71378\"},{\"start\":\"71378\",\"end\":\"71389\"},{\"start\":\"71389\",\"end\":\"71402\"},{\"start\":\"71402\",\"end\":\"71416\"},{\"start\":\"71416\",\"end\":\"71429\"},{\"start\":\"71429\",\"end\":\"71443\"},{\"start\":\"71687\",\"end\":\"71697\"},{\"start\":\"71697\",\"end\":\"71710\"},{\"start\":\"71850\",\"end\":\"71861\"},{\"start\":\"71861\",\"end\":\"71875\"},{\"start\":\"72236\",\"end\":\"72248\"},{\"start\":\"72248\",\"end\":\"72257\"},{\"start\":\"72416\",\"end\":\"72427\"},{\"start\":\"72427\",\"end\":\"72440\"},{\"start\":\"72440\",\"end\":\"72454\"},{\"start\":\"72684\",\"end\":\"72695\"},{\"start\":\"72695\",\"end\":\"72706\"},{\"start\":\"72706\",\"end\":\"72714\"},{\"start\":\"72714\",\"end\":\"72723\"},{\"start\":\"72723\",\"end\":\"72733\"},{\"start\":\"72733\",\"end\":\"72747\"},{\"start\":\"73001\",\"end\":\"73010\"},{\"start\":\"73010\",\"end\":\"73022\"},{\"start\":\"73022\",\"end\":\"73036\"},{\"start\":\"73249\",\"end\":\"73258\"},{\"start\":\"73258\",\"end\":\"73270\"},{\"start\":\"73270\",\"end\":\"73276\"},{\"start\":\"73276\",\"end\":\"73282\"},{\"start\":\"73282\",\"end\":\"73292\"},{\"start\":\"73635\",\"end\":\"73644\"},{\"start\":\"73957\",\"end\":\"73966\"},{\"start\":\"73966\",\"end\":\"73973\"},{\"start\":\"73973\",\"end\":\"73983\"},{\"start\":\"73983\",\"end\":\"73992\"},{\"start\":\"73992\",\"end\":\"74002\"},{\"start\":\"74368\",\"end\":\"74379\"},{\"start\":\"74379\",\"end\":\"74388\"},{\"start\":\"74388\",\"end\":\"74400\"},{\"start\":\"74400\",\"end\":\"74410\"},{\"start\":\"74685\",\"end\":\"74697\"},{\"start\":\"74813\",\"end\":\"74822\"},{\"start\":\"75064\",\"end\":\"75073\"},{\"start\":\"75340\",\"end\":\"75346\"},{\"start\":\"75346\",\"end\":\"75355\"},{\"start\":\"75355\",\"end\":\"75365\"},{\"start\":\"75365\",\"end\":\"75371\"},{\"start\":\"75371\",\"end\":\"75381\"},{\"start\":\"75381\",\"end\":\"75389\"},{\"start\":\"75389\",\"end\":\"75398\"},{\"start\":\"75857\",\"end\":\"75863\"},{\"start\":\"75863\",\"end\":\"75871\"},{\"start\":\"75871\",\"end\":\"75881\"},{\"start\":\"75881\",\"end\":\"75890\"},{\"start\":\"75890\",\"end\":\"75899\"},{\"start\":\"75899\",\"end\":\"75909\"},{\"start\":\"75909\",\"end\":\"75919\"},{\"start\":\"75919\",\"end\":\"75930\"},{\"start\":\"75930\",\"end\":\"75944\"},{\"start\":\"75944\",\"end\":\"75952\"}]", "bib_venue": "[{\"start\":\"56526\",\"end\":\"56530\"},{\"start\":\"56736\",\"end\":\"56834\"},{\"start\":\"57254\",\"end\":\"57258\"},{\"start\":\"57562\",\"end\":\"57606\"},{\"start\":\"57909\",\"end\":\"57948\"},{\"start\":\"58131\",\"end\":\"58194\"},{\"start\":\"58510\",\"end\":\"58517\"},{\"start\":\"58775\",\"end\":\"58853\"},{\"start\":\"59280\",\"end\":\"59377\"},{\"start\":\"59754\",\"end\":\"59834\"},{\"start\":\"60169\",\"end\":\"60212\"},{\"start\":\"60475\",\"end\":\"60524\"},{\"start\":\"60904\",\"end\":\"60908\"},{\"start\":\"61163\",\"end\":\"61214\"},{\"start\":\"61498\",\"end\":\"61588\"},{\"start\":\"62206\",\"end\":\"62209\"},{\"start\":\"62551\",\"end\":\"62572\"},{\"start\":\"62862\",\"end\":\"62948\"},{\"start\":\"63258\",\"end\":\"63332\"},{\"start\":\"63738\",\"end\":\"63756\"},{\"start\":\"64049\",\"end\":\"64132\"},{\"start\":\"64553\",\"end\":\"64611\"},{\"start\":\"64925\",\"end\":\"64929\"},{\"start\":\"65265\",\"end\":\"65351\"},{\"start\":\"65725\",\"end\":\"65769\"},{\"start\":\"66094\",\"end\":\"66162\"},{\"start\":\"66458\",\"end\":\"66516\"},{\"start\":\"66857\",\"end\":\"66931\"},{\"start\":\"67271\",\"end\":\"67302\"},{\"start\":\"67554\",\"end\":\"67589\"},{\"start\":\"67846\",\"end\":\"67869\"},{\"start\":\"68055\",\"end\":\"68080\"},{\"start\":\"68265\",\"end\":\"68286\"},{\"start\":\"68473\",\"end\":\"68484\"},{\"start\":\"68643\",\"end\":\"68689\"},{\"start\":\"68890\",\"end\":\"68921\"},{\"start\":\"69101\",\"end\":\"69172\"},{\"start\":\"69529\",\"end\":\"69578\"},{\"start\":\"69912\",\"end\":\"69975\"},{\"start\":\"70270\",\"end\":\"70294\"},{\"start\":\"70580\",\"end\":\"70608\"},{\"start\":\"70910\",\"end\":\"70996\"},{\"start\":\"71443\",\"end\":\"71450\"},{\"start\":\"71710\",\"end\":\"71713\"},{\"start\":\"71875\",\"end\":\"71943\"},{\"start\":\"72257\",\"end\":\"72265\"},{\"start\":\"72454\",\"end\":\"72488\"},{\"start\":\"72626\",\"end\":\"72682\"},{\"start\":\"73036\",\"end\":\"73039\"},{\"start\":\"73292\",\"end\":\"73356\"},{\"start\":\"73644\",\"end\":\"73692\"},{\"start\":\"74002\",\"end\":\"74066\"},{\"start\":\"74410\",\"end\":\"74474\"},{\"start\":\"74822\",\"end\":\"74829\"},{\"start\":\"75073\",\"end\":\"75088\"},{\"start\":\"75398\",\"end\":\"75448\"},{\"start\":\"75952\",\"end\":\"75983\"},{\"start\":\"58855\",\"end\":\"58918\"},{\"start\":\"63334\",\"end\":\"63393\"},{\"start\":\"64134\",\"end\":\"64202\"},{\"start\":\"65353\",\"end\":\"65424\"},{\"start\":\"66518\",\"end\":\"66561\"},{\"start\":\"66933\",\"end\":\"66992\"},{\"start\":\"70998\",\"end\":\"71069\"},{\"start\":\"71945\",\"end\":\"71998\"}]"}}}, "year": 2023, "month": 12, "day": 17}