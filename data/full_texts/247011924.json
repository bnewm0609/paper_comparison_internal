{"id": 247011924, "updated": "2023-10-05 16:42:11.157", "metadata": {"title": "Cross-Task Knowledge Distillation in Multi-Task Recommendation", "authors": "[{\"first\":\"Chenxiao\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Junwei\",\"last\":\"Pan\",\"middle\":[]},{\"first\":\"Xiaofeng\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Tingyu\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Dapeng\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Guihai\",\"last\":\"Chen\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Multi-task learning (MTL) has been widely used in recommender systems, wherein predicting each type of user feedback on items (e.g, click, purchase) are treated as individual tasks and jointly trained with a unified model. Our key observation is that the prediction results of each task may contain task-specific knowledge about user's fine-grained preference towards items. While such knowledge could be transferred to benefit other tasks, it is being overlooked under the current MTL paradigm. This paper, instead, proposes a Cross-Task Knowledge Distillation framework that attempts to leverage prediction results of one task as supervised signals to teach another task. However, integrating MTL and KD in a proper manner is non-trivial due to several challenges including task conflicts, inconsistent magnitude and requirement of synchronous optimization. As countermeasures, we 1) introduce auxiliary tasks with quadruplet loss functions to capture cross-task fine-grained ranking information and avoid task conflicts, 2) design a calibrated distillation approach to align and distill knowledge from auxiliary tasks, and 3) propose a novel error correction mechanism to enable and facilitate synchronous training of teacher and student models. Comprehensive experiments are conducted to verify the effectiveness of our framework in real-world datasets.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2202.09852", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aaai/YangP0JLC22", "doi": "10.1609/aaai.v36i4.20352"}}, "content": {"source": {"pdf_hash": "6bc729a25797ae1c4e08b832daa708f699c6669d", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2202.09852v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "01a7b96623cf2b6f20020bda78e31e70b44d6c38", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6bc729a25797ae1c4e08b832daa708f699c6669d.txt", "contents": "\nCross-Task Knowledge Distillation in Multi-Task Recommendation\n\n\nChenxiao Yang \nDepartment of Computer Science and Engineering\nShanghai Jiao Tong University\n\n\nJunwei Pan \nTencent Inc\n\n\nXiaofeng Gao gao-xf@cs.sjtu.edu.cn \nDepartment of Computer Science and Engineering\nShanghai Jiao Tong University\n\n\nTingyu Jiang \nTencent Inc\n\n\nDapeng Liu \nTencent Inc\n\n\nGuihai Chen gchen@cs.sjtu.edu.cn \nDepartment of Computer Science and Engineering\nShanghai Jiao Tong University\n\n\nCross-Task Knowledge Distillation in Multi-Task Recommendation\n\nMulti-task learning (MTL) has been widely used in recommender systems, wherein predicting each type of user feedback on items (e.g, click, purchase) are treated as individual tasks and jointly trained with a unified model. Our key observation is that the prediction results of each task may contain task-specific knowledge about user's fine-grained preference towards items. While such knowledge could be transferred to benefit other tasks, it is being overlooked under the current MTL paradigm. This paper, instead, proposes a Cross-Task Knowledge Distillation framework that attempts to leverage prediction results of one task as supervised signals to teach another task. However, integrating MTL and KD in a proper manner is non-trivial due to several challenges including task conflicts, inconsistent magnitude and requirement of synchronous optimization. As countermeasures, we 1) introduce auxiliary tasks with quadruplet loss functions to capture cross-task fine-grained ranking information and avoid task conflicts, 2) design a calibrated distillation approach to align and distill knowledge from auxiliary tasks, and 3) propose a novel error correction mechanism to enable and facilitate synchronous training of teacher and student models. Comprehensive experiments are conducted to verify the effectiveness of our framework in real-world datasets.\n\nIntroduction\n\nOnline recommender systems often involve predicting various types of user feedback such as clicking and purchasing. Multi-Task Learning (MTL) (Caruana 1997) has emerged in this context as a powerful tool to explore the connection of tasks for improving user interest modeling (Ma et al. 2018b;Lu, Dong, and Smyth 2018;Wang et al. 2018).\n\nCommon MTL models consist of low-level shared network and several high-level individual networks, as shown in Fig. 1(a), in the hope that the shared network could transfer the knowledge about \"how to encode the input features\" by sharing or enforcing similarity on parameters of different tasks (Ruder 2017). Most prior works (Ma et al. 2018a;Tang et al. 2020a;Ma et al. 2019) put efforts on designing different shared network architectures with ad-hoc parametersharing mechanisms such as branching and gating. In these models, each task is trained under the supervision of its own Copyright \u00a9 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. binary ground-truth label (1 or 0), attempting to rank positive items above negative ones. However, using such binary labels as training signals, the task may fail to accurately capture user's preference for items with the same label, despite that learning the auxiliary knowledge about these items' relations may benefit the overall ranking performance.\n\nTo address this limitation, we observe that the predictions of other tasks may contain useful information about how to rank same-labeled items. For example, given two tasks predicting 'Buy' and 'Like', and two items labeled as 'Buy:0, Like:1' and 'Buy:0, Like:0', the task 'Buy' may not accurately distinguish their relative ranking since both of their labels are 0. In contrast, another task 'Like' will identity the former item as positive with larger probability (e.g. 0.7), the latter with smaller probability (e.g. 0.1). Based on the fact that a user is more likely to purchase the item she likes 1 , we could somehow take advantage of these predictions from other tasks as a means to transfer ranking knowledge.\n\nKnowledge Distillation (KD) (Hinton, Vinyals, and Dean 2015) is a teacher-student learning framework where the student is trained using the predictions of the teacher. As revealed by theoretical analysis in previous studies (Tang et al. 2020b;Phuong and Lampert 2019), the predictions of the teacher, also known as soft labels, are usually seen as more informative training signals than binary hard labels, since they could reflect 'whether the sample is true positive (negative)'. On the perspective of backward gradient, KD can adaptively re-scale student model's training dynamics based on the values of soft labels. Specially, in the above example, we could incorporate predictions 0.7 and 0.1 in the training signals for task 'Buy'. Consequently, the gradients w.r.t the sample labeled 'Buy:0 & Like:0' in the example will be larger, indicating it is a more confident negative sample. Through this process, the task 'Buy' could hopefully give accurate rankings of same-labeled items. Motivated by these above observations, we proceed to design a new knowledge transfer paradigm on the optimization level of MTL models by leveraging KD. It is non-trivial due to three critical and fundamental challenges:\n\n\u2022 How to address the task conflict problem during distillation? Not all knowledge from other tasks is use-  ful (Yu et al. 2020). Specially, in online recommendation, the target task may believe that a user prefers item A since she bought item A instead of item B , while another task may reversely presume she prefers item B since she puts it in the collection rather than item A . Such conflicting ranking knowledge may be harmful for the target task and could empirically cause significant performance drop.\n\n\u2022 How to align the magnitude of predictions for different tasks? Distinct from vanilla KD where teacher and student models have the same prediction target, different tasks may have different magnitude of positive ratio. Directly using another task's predictions as training signals without alignment could mislead the target task to yield biased predictions (Zhou et al. 2021). \u2022 How to enhance training when teacher and student are synchronously optimized? The vanilla KD adopts asynchronous training where the teacher model is welltrained beforehand. However, MTL inherently requires synchronous training, where each task is jointly learned from scratch. This indicates the teacher may be poorlytrained and provide inaccurate or even erroneous training signals, causing slow convergence and local optima (Wen, Lai, and Qian 2019;Xu et al. 2020).\n\nIn this paper, we propose a novel framework named as Cross-Task Knowledge Distillation (CrossDistil). Different from prior MTL models where knowledge transfer is achieved by sharing representations in bottom layers, Cross-Distil also facilitates transferring ranking knowledge on the top layers, as shown in Fig. 1(b). To solve the aforementioned challenges: First, we introduce augmented tasks to learn the knowledge of the ranking orders of four types of samples as shown in Fig. 1(c). New tasks are trained based on a quadruplet loss function, and could fundamentally avoid conflicts by only preserving the useful knowledge and discarding the harmful one, as shown in Fig. 1(d). Second, we consider a calibration process that is seamlessly integrated in the KD procedure to align predictions of different tasks, which is accompanied with a bi-level training algorithm to optimize parameters for prediction and calibration respectively. Third, teachers and students are trained in an end-to-end manner with a novel error correction mechanism to speed up model training and further enhance knowledge quality. We conduct comprehensive experiments on a largescale public dataset and a real-world production dataset that is collected from our platform. The results demonstrate that CrossDistil achieves state-of-the-art performance. The ablation studies also thoroughly dissect the effectiveness of its modules.\n\n\nPreliminaries and Related Works\n\nKnowledge Distillation (Hinton, Vinyals, and Dean 2015) is a teacher-student learning framework where the student model is trained by mimicking outputs of the teacher model. For binary classification, the distillation loss function is formulated as\nL KD = CE(\u03c3(r T /\u03c4 ), \u03c3(r S /\u03c4 )),(1)\nwhere CE(y,\u0177) = y log(\u0177) + (1 \u2212 y) log(1 \u2212\u0177) is binary cross-entropy, r T and r S denote logits of the teacher and student model, and \u03c4 is the temperature hyper-parameter. Recent advances (Tang et al. 2020b;Yuan et al. 2020) show that KD performs instance-specific label smoothing regularization that re-scales backward gradient in logits space, and thus could hint to the student model about the confidence of the ground-truth, which explain the efficacy of KD for wider applications apart from traditional model compression (Kim et al. 2021;Yuan et al. 2020). Existing works in recommender systems adopt KD for its original purpose, i.e., distilling knowledge from a cumbersome teacher model into a lightweight student model targeting the same task (Tang and Wang 2018;Xu et al. 2020;Zhu et al. 2020). Distinct from theirs or other KD works in other fields, this paper leverages KD to transfer knowledge across different tasks, which is non-trivial due to the aforementioned three major challenges.\n\nMulti-Task Learning (Zhang and Yang 2021) is a machine learning framework that learns task-invariant representations by a shared bottom network, and yields predictions for each individual task by task-specific networks. It has received increasing interests in recommender systems (Ma et al. 2018b;Lu, Dong, and Smyth 2018;Wang et al. 2018;Pan et al. 2019) for modeling user interests by predicting different types of user feedback. A series of works seek for improvements by designing different shared network architectures, such as adding constraints on taskspecific parameters (Duong et al. 2015;Misra et al. 2016;Yang and Hospedales 2016) and separating shared and taskspecific parameters (Ma et al. 2018a;Tang et al. 2020a;Ma et al. 2019). Different from theirs, we resort to KD to transfer ranking knowledge across tasks on top of task-specific networks. Notably, our model is a general framework and could be leveraged as an extension of off-the-shelf MTL models.\n\n\nProposed Model\n\n\nTask Augmentation for Ranking\n\nThis paper focuses on multi-task learning for predicting different user feedback (e.g. click, like, purchase, lookthrough), and considers two tasks denoted as task A and task B to simplify illustration. As shown in the left panel of Fig. 2, we first split the set of training samples into multiple subsets according to combinations of tasks' labels:\nD +\u2212 = {(x i , y A i , y B i ) \u2208 D | y A i = 1, y B i = 0}, D \u2212+ = {(x i , y A i , y B i ) \u2208 D | y A i = 0, y B i = 1}, D \u2212\u00b7 = D \u2212\u2212 \u222a D \u2212+ , D +\u00b7 = D +\u2212 \u222a D ++ , D \u00b7\u2212 = D \u2212\u2212 \u222a D +\u2212 , D \u00b7+ = D \u2212+ \u222a D ++ ,(2)\nwhere x is an input feature vector, y A and y B denote hard labels for task A and task B respectively. The goal is to rank positive samples before negative ones, which can be expressed a bipartite order x +\u00b7 x \u2212\u00b7 for task A and x \u00b7+ x \u00b7\u2212 for task B, where x +\u00b7 \u2208 D +\u00b7 and so forth. Note that these bipartite orders may be contradictory among different tasks, e.g., x +\u2212 x \u2212+ for task A while x +\u2212 \u227a x \u2212+ for task B. Due to the existence of such conflicts, directly conducting KD by treating one task as teacher and another task as student may cause inconsistent training signals and is empirically harmful for the overall ranking performance.\n\nTo enable knowledge transfer across tasks via KD, we introduce auxiliary ranking-based tasks that could essentially avoid task conflicts while preserving useful ranking knowledge. In specific, we consider a quadruplet (x ++ , x +\u2212 , x \u2212+ , x \u2212\u2212 ) and the corresponding multipartite\norder x ++ x +\u2212 x \u2212+ x \u2212\u2212 for task A.\nIn contrast with the original bipartite order, the multipartite order reveals additional information about the ranking of samples, i.e., x ++\n\nx +\u2212 and x \u2212+ x \u2212\u2212 without introducing contradictions. Therefore, we refer such order as fine-grained ranking. Based on this, we introduce a new ranking-based task called augmented task A+ for enhancing knowledge transfer by additionally maximizing\nln p(\u0398| ) = ln p(x ++ x +\u2212 |\u0398) \u00b7 p(x \u2212+ x \u2212\u2212 |\u0398) \u00b7 p(\u0398) = (x ++ ,x +\u2212 , x \u2212+ ,x \u2212\u2212 ) ln \u03c3(r ++ +\u2212 ) + ln \u03c3(r \u2212+ \u2212\u2212 ) \u2212 Reg(\u0398),(3)\nwhere r is the logit value before activation in the last layer, r ++ +\u2212 =r ++ \u2212r +\u2212 , and sigmoid function \u03c3(x) = 1/(1 + exp(\u2212x)). The loss function for augmented task A+ is\nL A+ = (x ++ ,x +\u2212 , x \u2212+ ,x \u2212\u2212 ) \u2212\u03b2 A 1 ln \u03c3(r ++ +\u2212 ) \u2212 \u03b2 A 2 ln \u03c3(r \u2212+ \u2212\u2212 ) + (x +\u00b7 ,x \u2212\u00b7 ) \u2212 ln \u03c3(r +\u00b7 \u2212\u00b7 ),(4)\nwhich consists of three terms that respectively correspond to three pair-wise ranking relations of samples, where coefficients \u03b2 1 , \u03b2 2 balance their importance. The loss function for augmented task B+ could be defined in a similar spirit. These augmented ranking-based tasks are jointly trained with original regression-based tasks in MTL framework as shown in the second panel of Fig. 2. The original regression-based loss function is formulated as:\nL A =CE(y A ,\u0177 A ), L B = CE(y B ,\u0177 B ), CE(y,\u0177) = xi\u2208D \u2212y i ln\u0177 i \u2212 (1 \u2212 y i ) ln(1 \u2212\u0177 i ),(5)\nwhere\u0177 = \u03c3(r) is the predicted probability. The introduced auxiliary ranking-based tasks could avoid task conflicts and act as prerequisites for knowledge transfer through KD. Besides, the task augmentation approach itself is beneficial for the generalizability of main tasks (Hsieh and Tseng 2021) by introducing more related tasks that may provide hints about what shall be learned and transferred in shared layers.\n\n\nCalibrated Knowledge Distillation\n\nWe next design a cross-task knowledge distillation approach that can transfer fine-grained ranking knowledge for MTL. Since the prediction results of another task may contain the information about unseen rankings between samples of the same label, a straightforward approach is to use soft labels of another task to teach the current task by the vanilla hint loss (i.e. distillation loss) as in Eqn. (1). Unfortunately, such naive approach may be problematic and even imposes negative effects in practice. This is because the labels of different tasks may have contradictory ranking information that would harm the learning of other tasks as mentioned previously. To avoid such conflicts, we instead treat augmented ranking-based tasks as teachers, original regression-based tasks as students, and adopt the following distillation loss functions:\nL A\u2212KD = CE(\u03c3(r A+ /\u03c4 ), \u03c3(r A /\u03c4 )), L B\u2212KD = CE(\u03c3(r B+ /\u03c4 ), \u03c3(r B /\u03c4 )).(6)\nNote that soft labels\u0177 A+ = \u03c3(r A+ /\u03c4 ) and\u0177 B+ = \u03c3(r B+ /\u03c4 ) are invariant when training the student model, and hence the student will not mislead the teacher. The loss functions for students are formulated as\nL A\u2212Stu = (1 \u2212 \u03b1 A )L A + \u03b1 A L A\u2212KD , L B\u2212Stu = (1 \u2212 \u03b1 B )L B + \u03b1 B L B\u2212KD ,(7)\nwhere \u03b1 A \u2208 [0, 1] is the hyper-parameter to balance two losses. The soft labels output by augmented ranking-based tasks are more informative training signals than hard labels. As an example, for samples x ++ , x +\u2212 , x \u2212+ , x \u2212\u2212 , the teacher model for augmented task A+ may give predictions 0.9, 0.8, 0.2, 0.1 which intrinsically contains auxiliary ranking orders x ++ x +\u2212 and x \u2212+ x \u2212\u2212 that are not revealed in hard labels. Such knowledge is then explicitly transferred through the distillation loss and can meanwhile regularize task-specific layers from over-fitting the hard labels. However, an issue of the aforementioned approach is that augmented tasks are optimized with pair-wise loss functions and thus are not predicting a probability, i.e., the prediction \u03c3(r A+ ) does not agree with the actual probability that the input sample is a positive one. Directly using the soft labels of teachers may mislead students and cause performance deterioration. To solve this problem, we propose to calibrate the predictions so as to provide numerically sound and unbiased soft labels . Platt Scaling (Niculescu-Mizil and Caruana 2005;Platt et al. 1999) is a classic probability calibration method. We adopt it for calibration in this work. Still, one can replace it with any other more complex methods in practice. Formally, to get calibrated probabilities, we transform the logit values of teacher models through the following equation:\n\nr A+ = P A \u00b7r A+ + Q A ,\u1ef9 A+ = 1 1 + expr A+ (8) wherer and\u1ef9 are the logit value and probability after calibration, respectively. The same process is also used for task B+. P , Q are learnable parameters specific to each task. They are trained by optimizing the calibration loss\nL Cal = L A\u2212Cal +L B\u2212Cal = CE(y A ,\u1ef9 A+ )+CE(y B ,\u1ef9 B+ ).\n(9) We fix MTL model parameters when optimizing L Cal as shown in the third panel of Fig. 2. Note that, since the calibrated outputs of the teacher model are linear projections of the original outputs, the ranking result is unaffected so that the latent fine-grained ranking knowledge in soft labels is preserved during the calibration process. Distillation losses in Eqn. (6) are then revised by replacingr A+ ,r B+ withr A+ ,r B+ . \nx ++ , x +\u2212 , x \u2212+ , x \u2212\u2212 uniformly at random from D ++ , D +\u2212 , D \u2212+ , D \u2212\u2212 respectively; 5 Sample x +\u00b7 , x \u2212\u00b7 , x \u00b7+ , x \u00b7\u2212 uniformly at random from D +\u00b7 , D \u2212\u00b7 , D \u00b7+ , D \u00b7\u2212 respectively; 6\nModel parameter \u0398 optimization: \n7 Calculate L A+ (x +\u00b7 , x \u2212\u00b7 , x ++ , x +\u2212 , x \u2212+ , x \u2212\u2212 ; \u0398); 8 Calculate L B+ (x \u00b7+ , x \u00b7\u2212 , x ++ , x +\u2212 , x \u2212+ , x \u2212\u2212 ; \u0398); 9 Calculate L A\u2212Stu (x; \u0398), L B\u2212Stu (x; \u0398); 10 L M odel \u2190 wightedSum(L A+ , L B+ , L A\u2212Stu , L B\u2212Stu ); 11 \u0398 \u2190 \u0398 \u2212 \u03b31\u2207\u0398L M\n\nModel Training\n\nConventional KD adopts a two-stage training process where the teacher model is trained in advance and its parameters are fixed when training the student model (Hinton, Vinyals, and Dean 2015). However, such asynchronous training procedure is not favorable for industrial applications such as online advertising. Instead, due to simplicity and easy maintenance, synchronous training procedure where teacher and student models are trained in an end-to-end manner is more desirable as done in (Xu et al. 2020;Anil et al. 2018;Zhou et al. 2018). In our framework, there are two sets of parameters for optimization, namely, parameters in MTL backbone for prediction (denoted as \u0398) and parameters for calibration including P A , P B , Q A and Q B (denoted as \u2126). To jointly optimize prediction parameters and calibration parameters, we propose a bi-level training procedure where \u0398 and \u2126 are optimized in turn for each iteration as shown in the training algorithm. For sampling, it is impractical to enumerate every combination of samples as in Eqn. (4). Instead, We adopt bootstrap sampling strategy as used in (Rendle et al. 2012; Shan, Lin, and Sun 2018) as unbiased approximation.\n\n\nError Correction Mechanism\n\nIn KD-based methods, the student model is trained according to predictions of the teacher model, without considering if they are accurate or not. However, inaccurate predictions of the teacher model that is contradictory with the hard label could harm the student model's performance in two aspects. First, at early stage of training when the teacher model is not well-trained, frequent errors in soft labels may distract the training process of the student model, causing slow convergence (Xu et al. 2020). Second, even at later stage of training when the teacher model is relatively well-trained, it is still likely that the teacher model would occasionally provide mistaken predictions that may cause performance deterioration (Wen, Lai, and Qian 2019). A previous work (Xu et al. 2020) adopts a warm-up scheme by removing distillation loss in the earliest k steps of training. However, it is not clear how to choose an appropriate hyper-parameter k, and it cannot prevent errors after k steps.\n\nIn this work, we propose to adjust predictions of the teacher model\u1ef9 to align with the hard label y. Specifically, we clamp logit values for the teacher model (if the prediction is inconsistent with the ground truth) as follows: (10) where r T eacher could ber A+ orr B+ , 1[y] is an indicator function that returns 1 is y = 1 else returns \u22121, and m is the error correction margin, a hyper-parameter. This procedure could accelerate convergence by eliminating inaccurate predictions at the early stage of training, and further enhance knowledge quality at the later stage to improve student model's performance. The proposed error correction mechanism has the following properties: 1) It does not affect the predictions of the teacher model if they are sufficiently correct (that predicts the true label with at least probability \u03c3(m)); 2) It does not affect training of the teacher model since the computation of distillation loss has no backward gradient for teachers as shown in Fig. 2. \nr T eacher (x) \u2190 1[y] \u00b7 M ax 1[y] \u00b7 r T eacher (x), m\n\nExperiments\n\nWe conduct experiments on real-world datasets to answer the following research questions: RQ1: How do CrossDistil performs compared with the state-of-the-art multi-task learning frameworks; RQ2: Are the proposed modules in CrossDistil effective for improving the performance; RQ3: Does error correction mechanism help to accelerate convergence and enhance knowledge quality; RQ4: Does the student model really benefit from auxiliary ranking knowledge; RQ5: How do the hyper-parameters influence the performance?\n\n\nDatasets\n\nWe conduct experiments on a publicly accessible dataset TikTok 2 and our WechatMoments dataset. Tiktok dataset is collected from a short-video app with two types of user feedback, i.e., 'Finish watching' and 'Like'. WechatMoments dataset is collected through sampling user logs during 5 consecutive days with two types of user feedback, i.e., 'Not interested' and 'Click'. For Tiktok, we randomly choose 80% samples as training set, 10% as validation set and the rest as test set. For WechatMoments, we split the data according to days and use the data of the first four days for training and the last day for validation and test. The statistics of datasets are given in Table 1.\n\n\nEvaluation Metrics\n\nWe use two widely adopted metrics, i.e., AUC and Multi-AUC, for evaluation. AUC indicates the bipartite ranking 2 https://www.biendata.xyz/competition/icmechallenge2019/data/ (i.e., x + x \u2212 ) performance of the model.\nAUC = 1 N + N \u2212 xi\u2208D + xj \u2208D \u2212 (I(p(x i ) > p(x j ))) (11)\nwhere p(x) is the predicted probability of x being a positive sample and I(\u00b7) is the indicator function.\n\n\nMulti-Class Area Under ROC Curve (Multi-AUC)\n\nThe vanilla formulation of AUC only measures the performance of bipartite ranking where a data point is labeled either as a positive sample or a negative one. However, we are also interested in multipartite ranking performance since samples have multiple classes with an order x ++\n\nx +\u2212 x \u2212+ x \u2212\u2212 (for task A). Therefore, following (Shan, Lin, and Sun 2018;Shan et al. 2017), we adopt Multi-AUC to evaluate multipartite ranking performance on test set. Note that we use the weighted version which considers the class imbalance problem (Hand and Till 2001) and is defined as:\nMulti-AUC = 2 c(c \u2212 1) c j=1 c k>j p(j \u222ak)\u00b7AU C(k, j), (12)\nwhere c is the number of classes, p() is the prevalenceweighting function as described in (Ferri, Hern\u00e1ndez-Orallo, and Modroiu 2009), AU C(k, j) is the AUC score with class k as the positive class and j as the negative class.\n\n\nBaseline Methods\n\nWe choose the following MTL models with different shared network architectures for comparison: Shared-Bottom (Caruana 1997), Cross-Stitch (Misra et al. 2016), MMoE (Ma et al. 2018a), PLE (Tang et al. 2020a). We use two variants of our method: TAUG incorporates augmented tasks on top of MTL models, and CrossDistil extends TAUG by conducting calibrated knowledge distillation. Despite that Both TAUG and CrossDistil could be implemented on most state-of-the-art MTL models, we choose the best competitor (i.e. PLE) as the backbone. Table 2 and 3 show the experiment results of our methods versus other competitors on WechatMoments and Tik-Tok datasets respectively. The bold value marks the best one in one column, while the underlined value corresponds to the best one among all the baselines. To show improvements over the single-task counterpart, we report results of Single-Model which uses a separate network for learning each task. As is shown in the tables, the proposed CrossDistil achieves the best performance improvements over Single-Model in terms of AUC and Multi-AUC 3 . These results manifest that       CrossDistil could indeed better leverage the knowledge from other tasks to improve both bipartite and multipartite ranking abilities on all tasks. Also, TAUG model alone, without calibrated KD, achieves better performance compared with the backbone model PLE, which validates the effectiveness of task augmentation. Besides, there are several observations in comparison tables. First, Single-Model on augmented ranking-based tasks (teacher) achieves better results in Multi-AUC compared with Single-Model on original regression-based task (student). It verifies that the proposed augmented tasks are capable of capturing task-specific fine-grained ranking information. Second, the student model exceeds the teacher model both in AUC and Multi-AUC performance in most cases, which is not strange since the student benefits from additional training signals that could act as label smoothing regularization and the teacher does not have such advantage. The same phenomenon is observed in many other works (Yuan et al. 2020;Tang et al. 2020b;Zhang and Sabuncu 2020) \n\n\nRQ1: Performance Comparison\n\n\nRQ2,3,4: Ablation Study\n\nWe design a series of ablation studies to investigate the effectiveness of some key components. Four variants are considered to simplify CrossDistil by: i) removing BPR losses for learning auxiliary ranking relations, ii) directly employing the teacher model outputs for knowledge distillation without any calibration, iii) not applying the error correction mechanism, vi) using regression-based teacher models that learn the same task as students and using the vanilla knowledge distillation that is similar with (Zhou et al. 2018), v) directly using the predictions of another task for distillation. Table 4 and 5 show the results for these variants on TikTok dataset and performance drops compared with the baseline (i.e. CrossDistil).\n\nFor the first variant, teacher loss function degrades to traditional BPR loss with no auxiliary ranking information. Such auxiliary ranking information that contains cross-task knowledge is a key factor for good performance in AUC and Multi-AUC. The second variant without calibration may produce unreliable soft labels and result in performance deterioration. Also, it is worth mentioning that the calibration process could significantly improve the performance of LogLoss, which is a widely used regression-based metric. Concretely, LogLoss reduces from 0.5832 to 0.5703 for task A, and 0.0623 to 0.0337 for task B by using calibration. The results of the third variant indicate that the error correction mechanism can also bring up improvements for AUC and Multi-AUC. Another benefit of error correction is to accelerate model training, which will be further discussed. For the fourth variant, we can see that the proposed CrossDistil is better than the vanilla KD since it transfers fine-grained ranking knowledge across tasks. For the last variant, directly conducting KD could cause performance drop because of    the ranking conflicts of tasks.\n\n\nRQ3: Does Error Correction Mechanism Help to Accelerate Convergence and Enhance Knowledge Quality?\n\nTo answer this question, we plot the learning curves of test loss with (blue line) and without (red line) error correction in Fig. 4. As we can see, for both tasks, the test loss of Cross-Distil with error correction significantly goes down faster at the beginning of the training process when the teacher is not well-trained. Plus, at later stage of training when the teacher becomes well-trained, the test loss of CrossDistil with error correction slowly keeps going down and achieves better optimal results compared with the variant, indicating that the proposed error correction mechanism could indeed help to improve knowledge quality.\n\nRQ4: Does the Student Model Really Benefit from Auxiliary Ranking Knowledge from Other Tasks? To answer this question, we conduct the following experiment: For a target task A, we randomly choose a certain ratio of positive samples of task B, and then exchange their task B's label with the same number of randomly selected negative samples, to create a corrupted training set. Note that such data corruption process only has negative effects on the reliability of the auxiliary ranking information, so that we can investigate its impact on the student model's performance. Figure 5 shows the results of performance change when increasing the ratio from 10% to 90%. The results indicate that flawed auxiliary information has considerable negative effects on the overall performance, which again verifies Cross-Distil could effectively transfer knowledge across tasks.\n\n\nRQ5: Hyper-parameter Study\n\nThis subsection studies the performance variation of Cross-Distil w.r.t. some key hyper-parameters (i.e. error correction margin m, auxiliary ranking loss coefficient \u03b2 1 and \u03b2 2 , distillation loss weight \u03b1). Figure 3(a) shows the Multi-AUC performance with error correction margin ranges from \u22124 to 4. As we can see, the model performance first increases and then decreases. This is because extremely small m is equivalent to not conducting error correction, while extremely large m makes the soft labels degrade to hard labels. The results in Fig. 3(b) and Fig. 3(c) indicate a proper setting for \u03b2 can help to capture the correct underlying fine-grained ranking information. The results in Fig. 3(d) reveal that a proper \u03b1 from 0 to 1 can bring the best performance, which is reasonable since the distillation loss plays the role of label smoothing regularization and could not replace hard labels.\n\n\nConclusion\n\nIn this paper, we propose a cross-task knowledge distillation framework for multi-task recommendation. First, augmented ranking-based tasks are designed to capture finegrained ranking knowledge, which could avoid conflicted information to alleviate negative transfer problem and prepare for subsequent knowledge distillation. Second, calibrated knowledge distillation is adopted to transfer knowledge from augmented tasks (teacher) to original tasks (student). Third, an additional error correction method is proposed to speed up the convergence and improve knowledge quality in the synchronous training process. CrossDistil could be incorporated in most off-the-shelf multi-task learning models, and is easy to be extended or modified for industrial applications such as online advertising. The core idea of CrossDistil could inspire a new paradigm for solving domain-specific task conflict problem and enhancing knowledge transfer in broader areas of data mining and machine learning.\n\nFigure 1 :\n1Illustration of the motivation of CrossDistil.\n\nFigure 2 :\n2Illustration of computational graph for CrossDistil.\n\n\nTraining dataset D, learning rate \u03b31 and \u03b32, initial parameters \u0398 and \u2126. 1 Construct set D ++ , D +\u2212 , D \u2212+ , D \u2212\u2212 , D +\u00b7 , D \u2212\u00b7 , D \u00b7+ , D \u00b7\u2212 ;\n\n\n7625 (+0.0097) 0.6394 (+0.0124) 0.7607 (+0.0010) 0.6240 (+0.0216) 7632 (+0.0104) 0.6432 (+0.0162) 0.7612 (+0.0015) 0.6394 (+0.0370) 0.7625 (+0.0090) 0.6853 (+0.0145) 0.7608 (+0.0004) 0.6768 (+0.0063) CrossDistil 0.7644 (+0.0116) 0.6879 (+0.0609) 0.7618 (+0.0021) 0.6861 (+0.0837) 0.7618 (+0.0083) 0.6910 (+0.0202) 0.7609 (+0.0005) 0.6850 (+0.0145)\n\n\n7491 (+0.0035) 0.6743 (+0.0408) 0.9498 (+0.0007) 0.8081 (+0.0115) 0.7485 (+0.0032) 0.7408 (+0.0268) 0.9501 (+0.0020) 0.8335 (+0.0038) CrossDistil 0.7494 (+0.0038) 0.7411 (+0.1076) 0.9513 (+0.0022) 0.8341 (+0.0375) 0.7487 (+0.0034) 0.7403 (+0.0263) 0.9502 (+0.0021) 0.8324 (+0.0027)\n\nFigure 4 :\n4Learning curves of CrossDistil with and without error correction mechanism on TikTok dataset.\n\nFigure 5 :\n5Impact of corrupted auxiliary ranking information on the student model performance for TikTok dataset.\n\n\nBuy & Not Like > Not Buy & Not Like Buy & Not Like > Not Buy & Like Buy & Like > Not Buy & Not Like Buy & Like ? Not Buy & Like Buy & Not Like ? Not Buy & Not Like Buy & Not Like < Not Buy & Like Buy & Like > Not Buy & Not Like> \n\n> \n> \n\nFGR (Buy) \n\nUser \nFeature \n\nItem \nFeature \n\nContext \nFeature \n\nShared Layers \n\nBuy ? \nLike ? \n\n(c) Fine-Grained Ranking (FGR) \n\n(a) Existing MTL framework \n\nUser Features \nItem Features \nContext Features \n\nBuy ? \nLike ? \n\nFGR (Like) \n\nKD \nKD \n\nShared Layers \n\n(b) Our framework \n\nFC Layer \nFC Layer \n\nFC Layer \nFC Layer \nFC Layer \nFC Layer \n\nBuy ? \n\nLike ? \n\nSample 1 Sample 2 Sample 3 Sample 4 \n\nAuxiliary Ranking Auxiliary Ranking \n\nKnowledge Transfer \n\n*NO* \nKnowledge Transfer \n\nBuy & Like > Not Buy & Like \n\n(Teacher) \n\nBuy ? \n\n( Student ) \n\nLike ? \n\n(d) Explicitly transfer useful (green) knowledge \n\nKnowledge Transfer in both layers \n\n\n\n\nodel ;12 \n\nCalibration parameter \u2126 optimization: \n\n13 \n\nCalculate L Cal (x; \u2126); \n\n14 \n\n\u2126 \u2190 \u2126 \u2212 \u03b32\u2207\u2126L Cal ; \n15 end \n\n\n\nTable 1 :\n1Statistics of two datasets.Datasets \n#Samples #Fields #Features Density(A) Density(B) \n\nWechatMoments 9,381,820 \n10 \n447,002 \n1.510% \n9.975% \nTikTok \n19,622,340 \n9 \n4,691,483 37.994% \n1.101% \n\n\n\nTable 2 :\n2Experiment results of CrossDistil and competitors on WechatMoments dataset.Methods \nTaskA-Student \nTaskB-Student \nTaskA-Teacher \nTaskB-Teacher \n\nAUC \nMulti-AUC \nAUC \nMulti-AUC \nAUC \nMulti-AUC \nAUC \nMulti-AUC \n\nSingle-Model \n0.7528 \n0.6270 \n0.7597 \n0.6024 \n0.7535 \n0.6708 \n0.7604 \n0.6705 \nShared-Bottom 0.7540 (+0.0012) \n\nTable 3 :\n3Experiment results of CrossDistil and competitors on TikTok dataset.Methods \nTaskA-Student \nTaskB-Student \nTaskA-Teacher \nTaskB-Teacher \n\n\n\nTable 4 :\n4Ablation analysis for Task A on TikTok dataset.Variants \nAUC \nMulti-AUC \n\nw/o AuxiliaryRank \n0.7488 (\u22120.0006) \n0.6510 (\u22120.0901) \nw/o Calibration \n0.7478 (\u22120.0016) \n0.7396 (\u22120.0015) \nw/o Correction \n0.7486 (\u22120.0008) \n0.7399 (\u22120.0012) \nKD (same task) \n0.7489 (\u22120.0005) \n0.6901 (\u22120.0510) \nKD (cross task) \n0.7269 (\u22120.0225) \n0.6120 (\u22120.1291) \n\nBaseline \n0.7494 \n0.7411 \n\n\n\nTable 5 :\n5Ablation analysis for Task B on TikTok dataset.\n\n\nMulti-AUC for Task B(d) Distillation loss weight \u03b1Figure 3: Multi-AUC performance on TikTok dataset for TaskA and Task B w.r.t. different hyper-parameters.-4 \n\n-2 \n-1 \n0 \n1 \n2 \n4 \n\n0.734 \n\n0.736 \n\n0.738 \n\n0.740 \n\nMulti-AUC for Task A \n\n0.832 \n\n0.834 \n\n0.836 \n\n0.838 \n\nMulti-AUC for Task B \n\n(a) Error correction margin m \n\n0 \n0.1 \n0.2 \n0.3 \n0.4 \n0.5 \n\n0.736 \n\n0.738 \n\n0.740 \n\n0.742 \n\nMulti-AUC for Task A \n\n0.832 0.834 0.836 0.838 0.840 \n\nMulti-AUC for Task B \n\n(b) Coefficient \u03b21 \n\n0 \n0.1 \n0.2 \n0.3 \n0.4 \n0.5 \n\n0.738 \n\n0.740 \n\n0.742 \n\nMulti-AUC for Task A \n\n0.830 \n\n0.832 \n\n0.834 \n\n0.836 \n\nMulti-AUC for Task B \n\n(c) Coefficient \u03b22 \n\n0 \n0.2 \n0.4 \n0.6 \n0.8 \n1.0 \n\n0.738 \n\n0.740 \n\nMulti-AUC for Task A \n\n0.828 0.830 0.832 0.834 0.836 \n\n0 \n2000 \n4000 \n6000 \n8000 \n10000 \nSteps \n\n0.58 \n\n0.60 \n\n0.62 \n\n0.64 \n\n0.66 \n\n0.68 \n\nTest Loss \n\nw/o Error Correction \nwith Error Correction \n\n\nThe same applies to other types of user feedback, e.g., click, collect, forward.\nFor large-scale datasets in online advertisement, the improvements of AUC in the table is considerable because of its hardness.\n\nR Anil, G Pereyra, A Passos, R Ormandi, G E Dahl, G E Hinton, arXiv:1804.03235Large scale distributed neural network training through online distillation. arXiv preprintAnil, R.; Pereyra, G.; Passos, A.; Ormandi, R.; Dahl, G. E.; and Hinton, G. E. 2018. Large scale distributed neural net- work training through online distillation. arXiv preprint arXiv:1804.03235.\n\nMultitask learning. R Caruana, Machine learning. 281Caruana, R. 1997. Multitask learning. Machine learning, 28(1): 41-75.\n\nLow resource dependency parsing: Cross-lingual parameter sharing in a neural network parser. L Duong, T Cohn, S Bird, P Cook, ACL. Duong, L.; Cohn, T.; Bird, S.; and Cook, P. 2015. Low re- source dependency parsing: Cross-lingual parameter sharing in a neural network parser. In ACL, 845-850.\n\nAn experimental comparison of performance measures for classification. C Ferri, J Hern\u00e1ndez-Orallo, R Modroiu, PRL. 301Ferri, C.; Hern\u00e1ndez-Orallo, J.; and Modroiu, R. 2009. An experimental comparison of performance measures for clas- sification. PRL, 30(1): 27-38.\n\nA simple generalisation of the area under the ROC curve for multiple class classification problems. D J Hand, R J Till, Machine Learning. 45Hand, D. J.; and Till, R. J. 2001. A simple generalisation of the area under the ROC curve for multiple class classifica- tion problems. Machine Learning, 45(2): 171-186.\n\nG Hinton, O Vinyals, J Dean, arXiv:1503.02531Distilling the knowledge in a neural network. arXiv preprintHinton, G.; Vinyals, O.; and Dean, J. 2015. Distill- ing the knowledge in a neural network. arXiv preprint arXiv:1503.02531.\n\nBoosting Multi-task Learning Through Combination of Task Labels-with Applications in ECG Phenotyping. M.-E Hsieh, V Tseng, AAAI. 35Hsieh, M.-E.; and Tseng, V. 2021. Boosting Multi-task Learning Through Combination of Task Labels-with Appli- cations in ECG Phenotyping. In AAAI, volume 35, 7771- 7779.\n\nSelfknowledge distillation with progressive refinement of targets. K Kim, B Ji, D Yoon, S Hwang, ICCV. Kim, K.; Ji, B.; Yoon, D.; and Hwang, S. 2021. Self- knowledge distillation with progressive refinement of tar- gets. In ICCV, 6567-6576.\n\nWhy I like it: multitask learning for recommendation and explanation. Y Lu, R Dong, B Smyth, Rec-Sys. Lu, Y.; Dong, R.; and Smyth, B. 2018. Why I like it: multi- task learning for recommendation and explanation. In Rec- Sys, 4-12.\n\nSnr: Sub-network routing for flexible parameter sharing in multi-task learning. J Ma, Z Zhao, J Chen, A Li, L Hong, E H Chi, AAAI. 33Ma, J.; Zhao, Z.; Chen, J.; Li, A.; Hong, L.; and Chi, E. H. 2019. Snr: Sub-network routing for flexible parameter shar- ing in multi-task learning. In AAAI, volume 33, 216-223.\n\nModeling task relationships in multi-task learning with multi-gate mixture-of-experts. J Ma, Z Zhao, X Yi, J Chen, L Hong, E H Chi, SIGKDD. Ma, J.; Zhao, Z.; Yi, X.; Chen, J.; Hong, L.; and Chi, E. H. 2018a. Modeling task relationships in multi-task learn- ing with multi-gate mixture-of-experts. In SIGKDD, 1930- 1939.\n\nEntire space multi-task model: An effective approach for estimating post-click conversion rate. X Ma, L Zhao, G Huang, Z Wang, Z Hu, X Zhu, K Gai, SIGIR. Ma, X.; Zhao, L.; Huang, G.; Wang, Z.; Hu, Z.; Zhu, X.; and Gai, K. 2018b. Entire space multi-task model: An ef- fective approach for estimating post-click conversion rate. In SIGIR, 1137-1140.\n\nCross-stitch networks for multi-task learning. I Misra, A Shrivastava, A Gupta, M Hebert, CVPR. Misra, I.; Shrivastava, A.; Gupta, A.; and Hebert, M. 2016. Cross-stitch networks for multi-task learning. In CVPR, 3994-4003.\n\nPredicting good probabilities with supervised learning. A Niculescu-Mizil, R Caruana, ICML. Niculescu-Mizil, A.; and Caruana, R. 2005. Predicting good probabilities with supervised learning. In ICML, 625-632.\n\nPredicting different types of conversions with multi-task learning in online advertising. J Pan, Y Mao, A L Ruiz, Y Sun, A Flores, SIGKDD. Pan, J.; Mao, Y.; Ruiz, A. L.; Sun, Y.; and Flores, A. 2019. Predicting different types of conversions with multi-task learning in online advertising. In SIGKDD, 2689-2697.\n\nTowards understanding knowledge distillation. M Phuong, C Lampert, ICML. Phuong, M.; and Lampert, C. 2019. Towards understanding knowledge distillation. In ICML, 5142-5151.\n\nProbabilistic outputs for support vector machines and comparisons to regularized likelihood methods. J Platt, Advances in Large Margin Classifiers. 103Platt, J.; et al. 1999. Probabilistic outputs for support vector machines and comparisons to regularized likelihood meth- ods. Advances in Large Margin Classifiers, 10(3): 61-74.\n\nS Rendle, C Freudenthaler, Z Gantner, L Schmidt-Thieme, arXiv:1205.2618arXiv:1706.05098Ruder, S. 2017. An overview of multi-task learning in deep neural networks. arXiv preprintBPR: Bayesian personalized ranking from implicit feedbackRendle, S.; Freudenthaler, C.; Gantner, Z.; and Schmidt- Thieme, L. 2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint arXiv:1205.2618. Ruder, S. 2017. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098.\n\nCombined regression and tripletwise learning for conversion rate prediction in real-time bidding advertising. L Shan, L Lin, C Sun, SIGIR. Shan, L.; Lin, L.; and Sun, C. 2018. Combined regres- sion and tripletwise learning for conversion rate prediction in real-time bidding advertising. In SIGIR, 115-123.\n\nOptimizing ranking for response prediction via triplet-wise learning from historical feedback. L Shan, L Lin, C Sun, X Wang, B Liu, International Journal of Machine Learning and Cybernetics. 86Shan, L.; Lin, L.; Sun, C.; Wang, X.; and Liu, B. 2017. Optimizing ranking for response prediction via triplet-wise learning from historical feedback. International Journal of Machine Learning and Cybernetics, 8(6): 1777-1793.\n\nProgressive layered extraction (PLE): A novel multi-task learning model for personalized recommendations. H Tang, J Liu, M Zhao, X Gong, RecSys. Tang, H.; Liu, J.; Zhao, M.; and Gong, X. 2020a. Progressive layered extraction (PLE): A novel multi-task learning model for personalized recommendations. In RecSys, 269-278.\n\nRanking distillation: Learning compact ranking models with high performance for recommender system. J Tang, R Shivanna, Z Zhao, D Lin, A Singh, E H Chi, S Jain, J Tang, K Wang, arXiv:2002.03532SIGKDD. arXiv preprintUnderstanding and improving knowledge distillationTang, J.; Shivanna, R.; Zhao, Z.; Lin, D.; Singh, A.; Chi, E. H.; and Jain, S. 2020b. Understanding and improving knowledge distillation. arXiv preprint arXiv:2002.03532. Tang, J.; and Wang, K. 2018. Ranking distillation: Learning compact ranking models with high performance for recom- mender system. In SIGKDD, 2289-2298.\n\nExplainable recommendation via multi-task learning in opinionated text data. N Wang, H Wang, Y Jia, Y Yin, SIGIR. Wang, N.; Wang, H.; Jia, Y.; and Yin, Y. 2018. Explainable recommendation via multi-task learning in opinionated text data. In SIGIR, 165-174.\n\nPreparing lessons: Improve knowledge distillation with better supervision. T Wen, S Lai, X Qian, arXiv:1911.07471arXiv preprintWen, T.; Lai, S.; and Qian, X. 2019. Preparing lessons: Im- prove knowledge distillation with better supervision. arXiv preprint arXiv:1911.07471.\n\nPrivileged features distillation at Taobao recommendations. C Xu, Q Li, J Ge, J Gao, X Yang, C Pei, F Sun, J Wu, H Sun, W Ou, SIGKDD. Xu, C.; Li, Q.; Ge, J.; Gao, J.; Yang, X.; Pei, C.; Sun, F.; Wu, J.; Sun, H.; and Ou, W. 2020. Privileged features distillation at Taobao recommendations. In SIGKDD, 2590-2598.\n\nDeep multi-task representation learning: A tensor factorisation approach. Y Yang, T Hospedales, arXiv:1605.06391arXiv preprintYang, Y.; and Hospedales, T. 2016. Deep multi-task repre- sentation learning: A tensor factorisation approach. arXiv preprint arXiv:1605.06391.\n\nGradient surgery for multi-task learning. T Yu, S Kumar, A Gupta, S Levine, K Hausman, C Finn, NeurIPSYu, T.; Kumar, S.; Gupta, A.; Levine, S.; Hausman, K.; and Finn, C. 2020. Gradient surgery for multi-task learning. NeurIPS.\n\nRevisiting knowledge distillation via label smoothing regularization. L Yuan, F E Tay, G Li, T Wang, J Feng, CVPR. Yuan, L.; Tay, F. E.; Li, G.; Wang, T.; and Feng, J. 2020. Revisiting knowledge distillation via label smoothing regu- larization. In CVPR, 3903-3911.\n\nA survey on multi-task learning. Y Zhang, Yang , Q , TKDEZhang, Y.; and Yang, Q. 2021. A survey on multi-task learn- ing. TKDE.\n\nSelf-distillation as instance-specific label smoothing. Z Zhang, M R Sabuncu, arXiv:2006.05065arXiv preprintZhang, Z.; and Sabuncu, M. R. 2020. Self-distillation as instance-specific label smoothing. arXiv preprint arXiv:2006.05065.\n\nRocket launching: A universal and efficient framework for training well-performing light net. G Zhou, Y Fan, R Cui, W Bian, X Zhu, K Gai, In AAAI. 32Zhou, G.; Fan, Y.; Cui, R.; Bian, W.; Zhu, X.; and Gai, K. 2018. Rocket launching: A universal and efficient frame- work for training well-performing light net. In AAAI, vol- ume 32.\n\nRethinking soft labels for knowledge distillation: A bias-variance tradeoff perspective. H Zhou, L Song, J Chen, Y Zhou, G Wang, J Yuan, Q Zhang, ICLRZhou, H.; Song, L.; Chen, J.; Zhou, Y.; Wang, G.; Yuan, J.; and Zhang, Q. 2021. Rethinking soft labels for knowledge distillation: A bias-variance tradeoff perspective. ICLR.\n\nEnsembled CTR prediction via knowledge distillation. J Zhu, J Liu, W Li, J Lai, X He, L Chen, Z Zheng, CIKM. Zhu, J.; Liu, J.; Li, W.; Lai, J.; He, X.; Chen, L.; and Zheng, Z. 2020. Ensembled CTR prediction via knowledge distilla- tion. In CIKM, 2941-2958.\n", "annotations": {"author": "[{\"end\":159,\"start\":66},{\"end\":185,\"start\":160},{\"end\":300,\"start\":186},{\"end\":328,\"start\":301},{\"end\":354,\"start\":329},{\"end\":467,\"start\":355}]", "publisher": null, "author_last_name": "[{\"end\":79,\"start\":75},{\"end\":170,\"start\":167},{\"end\":198,\"start\":195},{\"end\":313,\"start\":308},{\"end\":339,\"start\":336},{\"end\":366,\"start\":362}]", "author_first_name": "[{\"end\":74,\"start\":66},{\"end\":166,\"start\":160},{\"end\":194,\"start\":186},{\"end\":307,\"start\":301},{\"end\":335,\"start\":329},{\"end\":361,\"start\":355}]", "author_affiliation": "[{\"end\":158,\"start\":81},{\"end\":184,\"start\":172},{\"end\":299,\"start\":222},{\"end\":327,\"start\":315},{\"end\":353,\"start\":341},{\"end\":466,\"start\":389}]", "title": "[{\"end\":63,\"start\":1},{\"end\":530,\"start\":468}]", "venue": null, "abstract": "[{\"end\":1889,\"start\":532}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2061,\"start\":2047},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2198,\"start\":2181},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2223,\"start\":2198},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2240,\"start\":2223},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2586,\"start\":2569},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2604,\"start\":2586},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2618,\"start\":2604},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4074,\"start\":4042},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4257,\"start\":4238},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4281,\"start\":4257},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5352,\"start\":5336},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6111,\"start\":6094},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6567,\"start\":6542},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6582,\"start\":6567},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8085,\"start\":8053},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8524,\"start\":8505},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8541,\"start\":8524},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8860,\"start\":8843},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8877,\"start\":8860},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9088,\"start\":9068},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9103,\"start\":9088},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9119,\"start\":9103},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9616,\"start\":9599},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9641,\"start\":9616},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9658,\"start\":9641},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9673,\"start\":9658},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9917,\"start\":9898},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9935,\"start\":9917},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9960,\"start\":9935},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10028,\"start\":10011},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10046,\"start\":10028},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10061,\"start\":10046},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13519,\"start\":13497},{\"end\":16031,\"start\":15981},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":16048,\"start\":16031},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17793,\"start\":17761},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":18108,\"start\":18092},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":18125,\"start\":18108},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18141,\"start\":18125},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":18727,\"start\":18708},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":19316,\"start\":19301},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":19566,\"start\":19541},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":19599,\"start\":19584},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":22883,\"start\":22858},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22900,\"start\":22883},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23081,\"start\":23061},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":23293,\"start\":23251},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":23531,\"start\":23517},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":23564,\"start\":23546},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":23589,\"start\":23572},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":23614,\"start\":23595},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":25547,\"start\":25529},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":25565,\"start\":25547},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":25588,\"start\":25565},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26179,\"start\":26161}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":31144,\"start\":31085},{\"attributes\":{\"id\":\"fig_1\"},\"end\":31210,\"start\":31145},{\"attributes\":{\"id\":\"fig_2\"},\"end\":31357,\"start\":31211},{\"attributes\":{\"id\":\"fig_3\"},\"end\":31707,\"start\":31358},{\"attributes\":{\"id\":\"fig_4\"},\"end\":31991,\"start\":31708},{\"attributes\":{\"id\":\"fig_7\"},\"end\":32098,\"start\":31992},{\"attributes\":{\"id\":\"fig_8\"},\"end\":32214,\"start\":32099},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33098,\"start\":32215},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":33218,\"start\":33099},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33424,\"start\":33219},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":33756,\"start\":33425},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":33907,\"start\":33757},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":34287,\"start\":33908},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":34347,\"start\":34288},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":35227,\"start\":34348}]", "paragraph": "[{\"end\":2241,\"start\":1905},{\"end\":3293,\"start\":2243},{\"end\":4012,\"start\":3295},{\"end\":5222,\"start\":4014},{\"end\":5734,\"start\":5224},{\"end\":6583,\"start\":5736},{\"end\":7994,\"start\":6585},{\"end\":8278,\"start\":8030},{\"end\":9317,\"start\":8317},{\"end\":10288,\"start\":9319},{\"end\":10688,\"start\":10339},{\"end\":11538,\"start\":10896},{\"end\":11821,\"start\":11540},{\"end\":12001,\"start\":11860},{\"end\":12251,\"start\":12003},{\"end\":12555,\"start\":12382},{\"end\":13124,\"start\":12672},{\"end\":13638,\"start\":13221},{\"end\":14522,\"start\":13676},{\"end\":14812,\"start\":14602},{\"end\":16334,\"start\":14894},{\"end\":16614,\"start\":16336},{\"end\":17107,\"start\":16673},{\"end\":17333,\"start\":17301},{\"end\":18780,\"start\":17602},{\"end\":19808,\"start\":18811},{\"end\":20800,\"start\":19810},{\"end\":21380,\"start\":20869},{\"end\":22072,\"start\":21393},{\"end\":22312,\"start\":22095},{\"end\":22476,\"start\":22372},{\"end\":22806,\"start\":22525},{\"end\":23100,\"start\":22808},{\"end\":23387,\"start\":23161},{\"end\":25589,\"start\":23408},{\"end\":26385,\"start\":25647},{\"end\":27538,\"start\":26387},{\"end\":28281,\"start\":27641},{\"end\":29150,\"start\":28283},{\"end\":30083,\"start\":29181},{\"end\":31084,\"start\":30098}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8316,\"start\":8279},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10895,\"start\":10689},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11859,\"start\":11822},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12381,\"start\":12252},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12671,\"start\":12556},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13220,\"start\":13125},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14601,\"start\":14523},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14893,\"start\":14813},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16672,\"start\":16615},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17300,\"start\":17108},{\"attributes\":{\"id\":\"formula_10\"},\"end\":17584,\"start\":17334},{\"attributes\":{\"id\":\"formula_11\"},\"end\":20854,\"start\":20801},{\"attributes\":{\"id\":\"formula_12\"},\"end\":22371,\"start\":22313},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23160,\"start\":23101}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22071,\"start\":22064},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23947,\"start\":23940},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":26256,\"start\":26249}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1903,\"start\":1891},{\"attributes\":{\"n\":\"2\"},\"end\":8028,\"start\":7997},{\"attributes\":{\"n\":\"3\"},\"end\":10305,\"start\":10291},{\"attributes\":{\"n\":\"3.1\"},\"end\":10337,\"start\":10308},{\"attributes\":{\"n\":\"3.2\"},\"end\":13674,\"start\":13641},{\"attributes\":{\"n\":\"3.3\"},\"end\":17600,\"start\":17586},{\"attributes\":{\"n\":\"3.4\"},\"end\":18809,\"start\":18783},{\"attributes\":{\"n\":\"4\"},\"end\":20867,\"start\":20856},{\"attributes\":{\"n\":\"4.1\"},\"end\":21391,\"start\":21383},{\"attributes\":{\"n\":\"4.2\"},\"end\":22093,\"start\":22075},{\"end\":22523,\"start\":22479},{\"attributes\":{\"n\":\"4.3\"},\"end\":23406,\"start\":23390},{\"attributes\":{\"n\":\"4.4\"},\"end\":25619,\"start\":25592},{\"attributes\":{\"n\":\"4.5\"},\"end\":25645,\"start\":25622},{\"end\":27639,\"start\":27541},{\"attributes\":{\"n\":\"4.6\"},\"end\":29179,\"start\":29153},{\"attributes\":{\"n\":\"5\"},\"end\":30096,\"start\":30086},{\"end\":31096,\"start\":31086},{\"end\":31156,\"start\":31146},{\"end\":32003,\"start\":31993},{\"end\":32110,\"start\":32100},{\"end\":33229,\"start\":33220},{\"end\":33435,\"start\":33426},{\"end\":33767,\"start\":33758},{\"end\":33918,\"start\":33909},{\"end\":34298,\"start\":34289}]", "table": "[{\"end\":33098,\"start\":32444},{\"end\":33218,\"start\":33107},{\"end\":33424,\"start\":33258},{\"end\":33756,\"start\":33512},{\"end\":33907,\"start\":33837},{\"end\":34287,\"start\":33967},{\"end\":35227,\"start\":34505}]", "figure_caption": "[{\"end\":31144,\"start\":31098},{\"end\":31210,\"start\":31158},{\"end\":31357,\"start\":31213},{\"end\":31707,\"start\":31360},{\"end\":31991,\"start\":31710},{\"end\":32098,\"start\":32005},{\"end\":32214,\"start\":32112},{\"end\":32444,\"start\":32217},{\"end\":33107,\"start\":33101},{\"end\":33258,\"start\":33231},{\"end\":33512,\"start\":33437},{\"end\":33837,\"start\":33769},{\"end\":33967,\"start\":33920},{\"end\":34347,\"start\":34300},{\"end\":34505,\"start\":34350}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2362,\"start\":2353},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6902,\"start\":6893},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7071,\"start\":7062},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7265,\"start\":7256},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10578,\"start\":10572},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13061,\"start\":13055},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16764,\"start\":16758},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20799,\"start\":20792},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":27773,\"start\":27767},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":28865,\"start\":28857},{\"end\":29402,\"start\":29391},{\"end\":29733,\"start\":29727},{\"end\":29747,\"start\":29741},{\"end\":29881,\"start\":29875}]", "bib_author_first_name": "[{\"end\":35439,\"start\":35438},{\"end\":35447,\"start\":35446},{\"end\":35458,\"start\":35457},{\"end\":35468,\"start\":35467},{\"end\":35479,\"start\":35478},{\"end\":35481,\"start\":35480},{\"end\":35489,\"start\":35488},{\"end\":35491,\"start\":35490},{\"end\":35826,\"start\":35825},{\"end\":36022,\"start\":36021},{\"end\":36031,\"start\":36030},{\"end\":36039,\"start\":36038},{\"end\":36047,\"start\":36046},{\"end\":36294,\"start\":36293},{\"end\":36303,\"start\":36302},{\"end\":36323,\"start\":36322},{\"end\":36590,\"start\":36589},{\"end\":36592,\"start\":36591},{\"end\":36600,\"start\":36599},{\"end\":36602,\"start\":36601},{\"end\":36802,\"start\":36801},{\"end\":36812,\"start\":36811},{\"end\":36823,\"start\":36822},{\"end\":37138,\"start\":37134},{\"end\":37147,\"start\":37146},{\"end\":37402,\"start\":37401},{\"end\":37409,\"start\":37408},{\"end\":37415,\"start\":37414},{\"end\":37423,\"start\":37422},{\"end\":37647,\"start\":37646},{\"end\":37653,\"start\":37652},{\"end\":37661,\"start\":37660},{\"end\":37889,\"start\":37888},{\"end\":37895,\"start\":37894},{\"end\":37903,\"start\":37902},{\"end\":37911,\"start\":37910},{\"end\":37917,\"start\":37916},{\"end\":37925,\"start\":37924},{\"end\":37927,\"start\":37926},{\"end\":38208,\"start\":38207},{\"end\":38214,\"start\":38213},{\"end\":38222,\"start\":38221},{\"end\":38228,\"start\":38227},{\"end\":38236,\"start\":38235},{\"end\":38244,\"start\":38243},{\"end\":38246,\"start\":38245},{\"end\":38538,\"start\":38537},{\"end\":38544,\"start\":38543},{\"end\":38552,\"start\":38551},{\"end\":38561,\"start\":38560},{\"end\":38569,\"start\":38568},{\"end\":38575,\"start\":38574},{\"end\":38582,\"start\":38581},{\"end\":38838,\"start\":38837},{\"end\":38847,\"start\":38846},{\"end\":38862,\"start\":38861},{\"end\":38871,\"start\":38870},{\"end\":39071,\"start\":39070},{\"end\":39090,\"start\":39089},{\"end\":39315,\"start\":39314},{\"end\":39322,\"start\":39321},{\"end\":39329,\"start\":39328},{\"end\":39331,\"start\":39330},{\"end\":39339,\"start\":39338},{\"end\":39346,\"start\":39345},{\"end\":39584,\"start\":39583},{\"end\":39594,\"start\":39593},{\"end\":39813,\"start\":39812},{\"end\":40043,\"start\":40042},{\"end\":40053,\"start\":40052},{\"end\":40070,\"start\":40069},{\"end\":40081,\"start\":40080},{\"end\":40662,\"start\":40661},{\"end\":40670,\"start\":40669},{\"end\":40677,\"start\":40676},{\"end\":40955,\"start\":40954},{\"end\":40963,\"start\":40962},{\"end\":40970,\"start\":40969},{\"end\":40977,\"start\":40976},{\"end\":40985,\"start\":40984},{\"end\":41387,\"start\":41386},{\"end\":41395,\"start\":41394},{\"end\":41402,\"start\":41401},{\"end\":41410,\"start\":41409},{\"end\":41702,\"start\":41701},{\"end\":41710,\"start\":41709},{\"end\":41722,\"start\":41721},{\"end\":41730,\"start\":41729},{\"end\":41737,\"start\":41736},{\"end\":41746,\"start\":41745},{\"end\":41748,\"start\":41747},{\"end\":41755,\"start\":41754},{\"end\":41763,\"start\":41762},{\"end\":41771,\"start\":41770},{\"end\":42269,\"start\":42268},{\"end\":42277,\"start\":42276},{\"end\":42285,\"start\":42284},{\"end\":42292,\"start\":42291},{\"end\":42525,\"start\":42524},{\"end\":42532,\"start\":42531},{\"end\":42539,\"start\":42538},{\"end\":42785,\"start\":42784},{\"end\":42791,\"start\":42790},{\"end\":42797,\"start\":42796},{\"end\":42803,\"start\":42802},{\"end\":42810,\"start\":42809},{\"end\":42818,\"start\":42817},{\"end\":42825,\"start\":42824},{\"end\":42832,\"start\":42831},{\"end\":42838,\"start\":42837},{\"end\":42845,\"start\":42844},{\"end\":43111,\"start\":43110},{\"end\":43119,\"start\":43118},{\"end\":43350,\"start\":43349},{\"end\":43356,\"start\":43355},{\"end\":43365,\"start\":43364},{\"end\":43374,\"start\":43373},{\"end\":43384,\"start\":43383},{\"end\":43395,\"start\":43394},{\"end\":43606,\"start\":43605},{\"end\":43614,\"start\":43613},{\"end\":43616,\"start\":43615},{\"end\":43623,\"start\":43622},{\"end\":43629,\"start\":43628},{\"end\":43637,\"start\":43636},{\"end\":43836,\"start\":43835},{\"end\":43848,\"start\":43844},{\"end\":43852,\"start\":43851},{\"end\":43988,\"start\":43987},{\"end\":43997,\"start\":43996},{\"end\":43999,\"start\":43998},{\"end\":44260,\"start\":44259},{\"end\":44268,\"start\":44267},{\"end\":44275,\"start\":44274},{\"end\":44282,\"start\":44281},{\"end\":44290,\"start\":44289},{\"end\":44297,\"start\":44296},{\"end\":44588,\"start\":44587},{\"end\":44596,\"start\":44595},{\"end\":44604,\"start\":44603},{\"end\":44612,\"start\":44611},{\"end\":44620,\"start\":44619},{\"end\":44628,\"start\":44627},{\"end\":44636,\"start\":44635},{\"end\":44878,\"start\":44877},{\"end\":44885,\"start\":44884},{\"end\":44892,\"start\":44891},{\"end\":44898,\"start\":44897},{\"end\":44905,\"start\":44904},{\"end\":44911,\"start\":44910},{\"end\":44919,\"start\":44918}]", "bib_author_last_name": "[{\"end\":35444,\"start\":35440},{\"end\":35455,\"start\":35448},{\"end\":35465,\"start\":35459},{\"end\":35476,\"start\":35469},{\"end\":35486,\"start\":35482},{\"end\":35498,\"start\":35492},{\"end\":35834,\"start\":35827},{\"end\":36028,\"start\":36023},{\"end\":36036,\"start\":36032},{\"end\":36044,\"start\":36040},{\"end\":36052,\"start\":36048},{\"end\":36300,\"start\":36295},{\"end\":36320,\"start\":36304},{\"end\":36331,\"start\":36324},{\"end\":36597,\"start\":36593},{\"end\":36607,\"start\":36603},{\"end\":36809,\"start\":36803},{\"end\":36820,\"start\":36813},{\"end\":36828,\"start\":36824},{\"end\":37144,\"start\":37139},{\"end\":37153,\"start\":37148},{\"end\":37406,\"start\":37403},{\"end\":37412,\"start\":37410},{\"end\":37420,\"start\":37416},{\"end\":37429,\"start\":37424},{\"end\":37650,\"start\":37648},{\"end\":37658,\"start\":37654},{\"end\":37667,\"start\":37662},{\"end\":37892,\"start\":37890},{\"end\":37900,\"start\":37896},{\"end\":37908,\"start\":37904},{\"end\":37914,\"start\":37912},{\"end\":37922,\"start\":37918},{\"end\":37931,\"start\":37928},{\"end\":38211,\"start\":38209},{\"end\":38219,\"start\":38215},{\"end\":38225,\"start\":38223},{\"end\":38233,\"start\":38229},{\"end\":38241,\"start\":38237},{\"end\":38250,\"start\":38247},{\"end\":38541,\"start\":38539},{\"end\":38549,\"start\":38545},{\"end\":38558,\"start\":38553},{\"end\":38566,\"start\":38562},{\"end\":38572,\"start\":38570},{\"end\":38579,\"start\":38576},{\"end\":38586,\"start\":38583},{\"end\":38844,\"start\":38839},{\"end\":38859,\"start\":38848},{\"end\":38868,\"start\":38863},{\"end\":38878,\"start\":38872},{\"end\":39087,\"start\":39072},{\"end\":39098,\"start\":39091},{\"end\":39319,\"start\":39316},{\"end\":39326,\"start\":39323},{\"end\":39336,\"start\":39332},{\"end\":39343,\"start\":39340},{\"end\":39353,\"start\":39347},{\"end\":39591,\"start\":39585},{\"end\":39602,\"start\":39595},{\"end\":39819,\"start\":39814},{\"end\":40050,\"start\":40044},{\"end\":40067,\"start\":40054},{\"end\":40078,\"start\":40071},{\"end\":40096,\"start\":40082},{\"end\":40667,\"start\":40663},{\"end\":40674,\"start\":40671},{\"end\":40681,\"start\":40678},{\"end\":40960,\"start\":40956},{\"end\":40967,\"start\":40964},{\"end\":40974,\"start\":40971},{\"end\":40982,\"start\":40978},{\"end\":40989,\"start\":40986},{\"end\":41392,\"start\":41388},{\"end\":41399,\"start\":41396},{\"end\":41407,\"start\":41403},{\"end\":41415,\"start\":41411},{\"end\":41707,\"start\":41703},{\"end\":41719,\"start\":41711},{\"end\":41727,\"start\":41723},{\"end\":41734,\"start\":41731},{\"end\":41743,\"start\":41738},{\"end\":41752,\"start\":41749},{\"end\":41760,\"start\":41756},{\"end\":41768,\"start\":41764},{\"end\":41776,\"start\":41772},{\"end\":42274,\"start\":42270},{\"end\":42282,\"start\":42278},{\"end\":42289,\"start\":42286},{\"end\":42296,\"start\":42293},{\"end\":42529,\"start\":42526},{\"end\":42536,\"start\":42533},{\"end\":42544,\"start\":42540},{\"end\":42788,\"start\":42786},{\"end\":42794,\"start\":42792},{\"end\":42800,\"start\":42798},{\"end\":42807,\"start\":42804},{\"end\":42815,\"start\":42811},{\"end\":42822,\"start\":42819},{\"end\":42829,\"start\":42826},{\"end\":42835,\"start\":42833},{\"end\":42842,\"start\":42839},{\"end\":42848,\"start\":42846},{\"end\":43116,\"start\":43112},{\"end\":43130,\"start\":43120},{\"end\":43353,\"start\":43351},{\"end\":43362,\"start\":43357},{\"end\":43371,\"start\":43366},{\"end\":43381,\"start\":43375},{\"end\":43392,\"start\":43385},{\"end\":43400,\"start\":43396},{\"end\":43611,\"start\":43607},{\"end\":43620,\"start\":43617},{\"end\":43626,\"start\":43624},{\"end\":43634,\"start\":43630},{\"end\":43642,\"start\":43638},{\"end\":43842,\"start\":43837},{\"end\":43994,\"start\":43989},{\"end\":44007,\"start\":44000},{\"end\":44265,\"start\":44261},{\"end\":44272,\"start\":44269},{\"end\":44279,\"start\":44276},{\"end\":44287,\"start\":44283},{\"end\":44294,\"start\":44291},{\"end\":44301,\"start\":44298},{\"end\":44593,\"start\":44589},{\"end\":44601,\"start\":44597},{\"end\":44609,\"start\":44605},{\"end\":44617,\"start\":44613},{\"end\":44625,\"start\":44621},{\"end\":44633,\"start\":44629},{\"end\":44642,\"start\":44637},{\"end\":44882,\"start\":44879},{\"end\":44889,\"start\":44886},{\"end\":44895,\"start\":44893},{\"end\":44902,\"start\":44899},{\"end\":44908,\"start\":44906},{\"end\":44916,\"start\":44912},{\"end\":44925,\"start\":44920}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1804.03235\",\"id\":\"b0\"},\"end\":35803,\"start\":35438},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":45998148},\"end\":35926,\"start\":35805},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":17263016},\"end\":36220,\"start\":35928},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2026934},\"end\":36487,\"start\":36222},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":43144161},\"end\":36799,\"start\":36489},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b5\"},\"end\":37030,\"start\":36801},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":235306648},\"end\":37332,\"start\":37032},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":233714221},\"end\":37574,\"start\":37334},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":52902832},\"end\":37806,\"start\":37576},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":58145688},\"end\":38118,\"start\":37808},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":50770252},\"end\":38439,\"start\":38120},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":5067648},\"end\":38788,\"start\":38441},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":1923223},\"end\":39012,\"start\":38790},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":207158152},\"end\":39222,\"start\":39014},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":196181435},\"end\":39535,\"start\":39224},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":174800711},\"end\":39709,\"start\":39537},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":56563878},\"end\":40040,\"start\":39711},{\"attributes\":{\"doi\":\"arXiv:1205.2618\",\"id\":\"b17\"},\"end\":40549,\"start\":40042},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":195351654},\"end\":40857,\"start\":40551},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":29229939},\"end\":41278,\"start\":40859},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":221784966},\"end\":41599,\"start\":41280},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":50778760},\"end\":42189,\"start\":41601},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":47019137},\"end\":42447,\"start\":42191},{\"attributes\":{\"id\":\"b23\"},\"end\":42722,\"start\":42449},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":213981455},\"end\":43034,\"start\":42724},{\"attributes\":{\"id\":\"b25\"},\"end\":43305,\"start\":43036},{\"attributes\":{\"id\":\"b26\"},\"end\":43533,\"start\":43307},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":219962714},\"end\":43800,\"start\":43535},{\"attributes\":{\"id\":\"b28\"},\"end\":43929,\"start\":43802},{\"attributes\":{\"id\":\"b29\"},\"end\":44163,\"start\":43931},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":3913636},\"end\":44496,\"start\":44165},{\"attributes\":{\"id\":\"b31\"},\"end\":44822,\"start\":44498},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":224282886},\"end\":45080,\"start\":44824}]", "bib_title": "[{\"end\":35823,\"start\":35805},{\"end\":36019,\"start\":35928},{\"end\":36291,\"start\":36222},{\"end\":36587,\"start\":36489},{\"end\":37132,\"start\":37032},{\"end\":37399,\"start\":37334},{\"end\":37644,\"start\":37576},{\"end\":37886,\"start\":37808},{\"end\":38205,\"start\":38120},{\"end\":38535,\"start\":38441},{\"end\":38835,\"start\":38790},{\"end\":39068,\"start\":39014},{\"end\":39312,\"start\":39224},{\"end\":39581,\"start\":39537},{\"end\":39810,\"start\":39711},{\"end\":40659,\"start\":40551},{\"end\":40952,\"start\":40859},{\"end\":41384,\"start\":41280},{\"end\":41699,\"start\":41601},{\"end\":42266,\"start\":42191},{\"end\":42782,\"start\":42724},{\"end\":43603,\"start\":43535},{\"end\":44257,\"start\":44165},{\"end\":44875,\"start\":44824}]", "bib_author": "[{\"end\":35446,\"start\":35438},{\"end\":35457,\"start\":35446},{\"end\":35467,\"start\":35457},{\"end\":35478,\"start\":35467},{\"end\":35488,\"start\":35478},{\"end\":35500,\"start\":35488},{\"end\":35836,\"start\":35825},{\"end\":36030,\"start\":36021},{\"end\":36038,\"start\":36030},{\"end\":36046,\"start\":36038},{\"end\":36054,\"start\":36046},{\"end\":36302,\"start\":36293},{\"end\":36322,\"start\":36302},{\"end\":36333,\"start\":36322},{\"end\":36599,\"start\":36589},{\"end\":36609,\"start\":36599},{\"end\":36811,\"start\":36801},{\"end\":36822,\"start\":36811},{\"end\":36830,\"start\":36822},{\"end\":37146,\"start\":37134},{\"end\":37155,\"start\":37146},{\"end\":37408,\"start\":37401},{\"end\":37414,\"start\":37408},{\"end\":37422,\"start\":37414},{\"end\":37431,\"start\":37422},{\"end\":37652,\"start\":37646},{\"end\":37660,\"start\":37652},{\"end\":37669,\"start\":37660},{\"end\":37894,\"start\":37888},{\"end\":37902,\"start\":37894},{\"end\":37910,\"start\":37902},{\"end\":37916,\"start\":37910},{\"end\":37924,\"start\":37916},{\"end\":37933,\"start\":37924},{\"end\":38213,\"start\":38207},{\"end\":38221,\"start\":38213},{\"end\":38227,\"start\":38221},{\"end\":38235,\"start\":38227},{\"end\":38243,\"start\":38235},{\"end\":38252,\"start\":38243},{\"end\":38543,\"start\":38537},{\"end\":38551,\"start\":38543},{\"end\":38560,\"start\":38551},{\"end\":38568,\"start\":38560},{\"end\":38574,\"start\":38568},{\"end\":38581,\"start\":38574},{\"end\":38588,\"start\":38581},{\"end\":38846,\"start\":38837},{\"end\":38861,\"start\":38846},{\"end\":38870,\"start\":38861},{\"end\":38880,\"start\":38870},{\"end\":39089,\"start\":39070},{\"end\":39100,\"start\":39089},{\"end\":39321,\"start\":39314},{\"end\":39328,\"start\":39321},{\"end\":39338,\"start\":39328},{\"end\":39345,\"start\":39338},{\"end\":39355,\"start\":39345},{\"end\":39593,\"start\":39583},{\"end\":39604,\"start\":39593},{\"end\":39821,\"start\":39812},{\"end\":40052,\"start\":40042},{\"end\":40069,\"start\":40052},{\"end\":40080,\"start\":40069},{\"end\":40098,\"start\":40080},{\"end\":40669,\"start\":40661},{\"end\":40676,\"start\":40669},{\"end\":40683,\"start\":40676},{\"end\":40962,\"start\":40954},{\"end\":40969,\"start\":40962},{\"end\":40976,\"start\":40969},{\"end\":40984,\"start\":40976},{\"end\":40991,\"start\":40984},{\"end\":41394,\"start\":41386},{\"end\":41401,\"start\":41394},{\"end\":41409,\"start\":41401},{\"end\":41417,\"start\":41409},{\"end\":41709,\"start\":41701},{\"end\":41721,\"start\":41709},{\"end\":41729,\"start\":41721},{\"end\":41736,\"start\":41729},{\"end\":41745,\"start\":41736},{\"end\":41754,\"start\":41745},{\"end\":41762,\"start\":41754},{\"end\":41770,\"start\":41762},{\"end\":41778,\"start\":41770},{\"end\":42276,\"start\":42268},{\"end\":42284,\"start\":42276},{\"end\":42291,\"start\":42284},{\"end\":42298,\"start\":42291},{\"end\":42531,\"start\":42524},{\"end\":42538,\"start\":42531},{\"end\":42546,\"start\":42538},{\"end\":42790,\"start\":42784},{\"end\":42796,\"start\":42790},{\"end\":42802,\"start\":42796},{\"end\":42809,\"start\":42802},{\"end\":42817,\"start\":42809},{\"end\":42824,\"start\":42817},{\"end\":42831,\"start\":42824},{\"end\":42837,\"start\":42831},{\"end\":42844,\"start\":42837},{\"end\":42850,\"start\":42844},{\"end\":43118,\"start\":43110},{\"end\":43132,\"start\":43118},{\"end\":43355,\"start\":43349},{\"end\":43364,\"start\":43355},{\"end\":43373,\"start\":43364},{\"end\":43383,\"start\":43373},{\"end\":43394,\"start\":43383},{\"end\":43402,\"start\":43394},{\"end\":43613,\"start\":43605},{\"end\":43622,\"start\":43613},{\"end\":43628,\"start\":43622},{\"end\":43636,\"start\":43628},{\"end\":43644,\"start\":43636},{\"end\":43844,\"start\":43835},{\"end\":43851,\"start\":43844},{\"end\":43855,\"start\":43851},{\"end\":43996,\"start\":43987},{\"end\":44009,\"start\":43996},{\"end\":44267,\"start\":44259},{\"end\":44274,\"start\":44267},{\"end\":44281,\"start\":44274},{\"end\":44289,\"start\":44281},{\"end\":44296,\"start\":44289},{\"end\":44303,\"start\":44296},{\"end\":44595,\"start\":44587},{\"end\":44603,\"start\":44595},{\"end\":44611,\"start\":44603},{\"end\":44619,\"start\":44611},{\"end\":44627,\"start\":44619},{\"end\":44635,\"start\":44627},{\"end\":44644,\"start\":44635},{\"end\":44884,\"start\":44877},{\"end\":44891,\"start\":44884},{\"end\":44897,\"start\":44891},{\"end\":44904,\"start\":44897},{\"end\":44910,\"start\":44904},{\"end\":44918,\"start\":44910},{\"end\":44927,\"start\":44918}]", "bib_venue": "[{\"end\":35591,\"start\":35516},{\"end\":35852,\"start\":35836},{\"end\":36057,\"start\":36054},{\"end\":36336,\"start\":36333},{\"end\":36625,\"start\":36609},{\"end\":36890,\"start\":36846},{\"end\":37159,\"start\":37155},{\"end\":37435,\"start\":37431},{\"end\":37676,\"start\":37669},{\"end\":37937,\"start\":37933},{\"end\":38258,\"start\":38252},{\"end\":38593,\"start\":38588},{\"end\":38884,\"start\":38880},{\"end\":39104,\"start\":39100},{\"end\":39361,\"start\":39355},{\"end\":39608,\"start\":39604},{\"end\":39857,\"start\":39821},{\"end\":40203,\"start\":40129},{\"end\":40688,\"start\":40683},{\"end\":41048,\"start\":40991},{\"end\":41423,\"start\":41417},{\"end\":41800,\"start\":41794},{\"end\":42303,\"start\":42298},{\"end\":42522,\"start\":42449},{\"end\":42856,\"start\":42850},{\"end\":43108,\"start\":43036},{\"end\":43347,\"start\":43307},{\"end\":43648,\"start\":43644},{\"end\":43833,\"start\":43802},{\"end\":43985,\"start\":43931},{\"end\":44310,\"start\":44303},{\"end\":44585,\"start\":44498},{\"end\":44931,\"start\":44927}]"}}}, "year": 2023, "month": 12, "day": 17}