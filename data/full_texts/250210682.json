{"id": 250210682, "updated": "2022-10-06 14:24:20.989", "metadata": {"title": "Learn from Others and Be Yourself in Heterogeneous Federated Learning", "authors": "[{\"first\":\"Wenke\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Mang\",\"last\":\"Ye\",\"middle\":[]},{\"first\":\"Bo\",\"last\":\"Du\",\"middle\":[]}]", "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Federated learning has emerged as an important distributed learning paradigm, which normally involves collaborative updating with others and local updating on private data. However, heterogeneity problem and catastrophic forgetting bring distinctive challenges. First, due to non-i.i.d (identically and independently distributed) data and heterogeneous architectures, models suffer performance degradation on other domains and communication barrier with participants models. Second, in local updating, model is separately optimized on private data, which is prone to overfit current data distribution and forgets previously acquired knowledge, resulting in catastrophic forgetting. In this work, we propose FCCL (Federated CrossCorrelation and Continual Learning). For heterogeneity problem, FCCL leverages unlabeled public data for communication and construct cross-correlation matrix to learn a generalizable representation under domain shift. Mean- while, for catastrophic forgetting, FCCL utilizes knowledge distillation in local updating, providing inter and intra domain information without leaking privacy. Empirical results on various image classification tasks demonstrate the effectiveness of our method and the efficiency of modules.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/HuangY022", "doi": "10.1109/cvpr52688.2022.00990"}}, "content": {"source": {"pdf_hash": "6388e78c8546aa83fc4096b9c0ee1dc3fb22257b", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "6897e062e77b981abfcc15d479ee6ddaeb34bdc5", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6388e78c8546aa83fc4096b9c0ee1dc3fb22257b.txt", "contents": "\nLearn from Others and Be Yourself in Heterogeneous Federated Learning\n\n\nWenke Huang \nNational Engineering Research Center for Multimedia Software\nInstitute of Artificial Intelligence\nSchool of Computer Science\nHubei Key Laboratory of Multimedia and Network Communication Engineering\nWuhan University\nWuhanChina\n\nMang Ye \nNational Engineering Research Center for Multimedia Software\nInstitute of Artificial Intelligence\nSchool of Computer Science\nHubei Key Laboratory of Multimedia and Network Communication Engineering\nWuhan University\nWuhanChina\n\nHubei Luojia Laboratory\nWuhanChina\n\nBo Du \nNational Engineering Research Center for Multimedia Software\nInstitute of Artificial Intelligence\nSchool of Computer Science\nHubei Key Laboratory of Multimedia and Network Communication Engineering\nWuhan University\nWuhanChina\n\nHubei Luojia Laboratory\nWuhanChina\n\nLearn from Others and Be Yourself in Heterogeneous Federated Learning\n10.1109/CVPR52688.2022.00990\nFederated learning has emerged as an important distributed learning paradigm, which normally involves collaborative updating with others and local updating on private data. However, heterogeneity problem and catastrophic forgetting bring distinctive challenges. First, due to non-i.i.d (identically and independently distributed) data and heterogeneous architectures, models suffer performance degradation on other domains and communication barrier with participants models. Second, in local updating, model is separately optimized on private data, which is prone to overfit current data distribution and forgets previously acquired knowledge, resulting in catastrophic forgetting. In this work, we propose FCCL (Federated Cross-Correlation and Continual Learning). For heterogeneity problem, FCCL leverages unlabeled public data for communication and construct cross-correlation matrix to learn a generalizable representation under domain shift. Meanwhile, for catastrophic forgetting, FCCL utilizes knowledge distillation in local updating, providing inter and intra domain information without leaking privacy. Empirical results on various image classification tasks demonstrate the effectiveness of our method and the efficiency of modules.\n\nIntroduction\n\nDeep learning algorithms have achieved remarkable progress, owing to the availability of large-scale data [8,51,69]. However, in the real world, data are commonly dispersed over different participants (e.g., mobile devices, organizations). Due to growing privacy concerns and strict data protection regulations [84], participants cannot integrate data together to train a model. Driven by such realistic issues, federated learning [33,34,58,59,89] provides a privacy-preserving paradigm, where participants collabo- Figure 1. Problem illustration of heterogeneous federated learning. (a) In collaborative updating, how to handle communication problem of heterogeneous models and learn a generalizable representation under heterogeneous data (domain shift)? (b) In local updating, how to alleviate catastrophic forgetting to present stable and satisfactory performance in both inter and intra domains? ratively learn a model without leaking private data. It has been an active and challenging research topic and shows promising results in real-world setting [17,19,29,52,54].\n\nAlong with its pilot progress, researches on federated learning are baffled by some key challenges [30,42]. An inevitable and practical challenge is heterogeneity problem. On the one hand, distributed data might be non-i.i.d (identically and independently distributed), leading to data heterogeneity [30,39,95]. A myriad of methods [43,46,73,77] incorporate extra proximal terms to handle the data in label distribution skew (prior probability shift) [30], neglecting the fact that there exists domain shift (same label, different features) [60,64,66]. In particular, private model suffers severe performance degradation on other domains with no-ticeably different distribution. As a result, learning a generalizable representation under domain shift is technically challenging. On the other hand, due to different design criteria, distinct hardware capabilities [20,86] and intellectual property rights [56], participants require to customize models, which poses a practical challenge: model heterogeneity. Preceding methods are developed under the assumption that local models share parameters or gradients, which cannot work on heterogeneous models. In order to solve this problem, a main stream of subsequent effort leverages knowledge transfer through labeled data [38,74], shared model [48,72,92] or group operation [21,50]. But these methods have different limitations. Specifically, labeled data require server to collect data with similar distributions to private data, which causes costly human efforts and needs special domain expertise. For shared model, it raises computational cost and necessitates additional model structure in participant side. Group operation leverages unlabeled public data to measure distribution divergence. However, these methods mainly focus on label distribution skew and consider the performance on one domain. Simultaneously considering data and model heterogeneity, an essential issue has long been overlooked: (a) How to learn a generalizable representation in heterogeneous federated learning?\n\nBesides heterogeneity problem, another impediment for federated learning steams from its paradigm. Generally, federated learning could be viewed as a two-step cyclic process: collaborative updating and local updating [58,89]. In collaborative updating, participants learn from others. In local updating, model is optimized on private data, which is prone to overfit current knowledge and forget previous knowledge, resulting in catastrophic forgetting [57]. To tackle this challenge, one type of methods typically performs fine-tuning for several rounds [38,50,58,74,88]. However, carefully configuring hyper-parameters to achieve satisfactory performance is time-consuming and cannot tackle this problem systematically. Current popular solutions [41,43,73,77] focus on calculating parameter stiffness to regulate models, which can not explicitly depict the degree of effect from different participants. Consequently, a natural question arises: (b) How to balance multiple knowledge to reduce catastrophic forgetting? We further explain heterogeneity problem and catastrophic forgetting in Fig. 1.\n\nFor the heterogeneity problem, we take inspiration from the self-supervised learning [5,6,11,13,18,25,49,91,94]. In particular, self-supervised learning aims to learn a generalizable representation through rich and diverse data for downstream tasks and unseen classes. Intuitively, we expect that the models would present similar logits output for the same classes in different domains. This motivates us to leverage unlabeled public data for Federated Cross-Correlation Learning, which is diverse and easy to obtain. Specifically, we try to maximize the similarity between log-its output and minimize the redundancy within logits output on unlabeled public data. Through correlating same dimensions and decorrelating different dimensions on logits output, models would learn class invariance and encourage the diversity of different classes. Thus, our method handles the communication problem in heterogeneous models and learns a generalizable representation under domain shift.\n\nTo handle catastrophic forgetting, we develop Federated Continual Learning via knowledge distillation [2,24] in local updating to continually learn from inter and intra domains. To avoid forgetting inter domain information in local updating stage, we propose to distill the knowledge of intradomain (local) model learned in previous rounds, where it captured the inter domain information after communication with other participants. In addition, for intra domain forgetting problem, we leverage the initially pretrained local model (without knowledge learned from others) to constrain the later local updating for each participant. Therefore, balancing knowledge through distillation with these two models is reasonable to handle the catastrophic forgetting.\n\nIn this work, we propose a novel federated learning method, dubbed FCCL (Federated Cross-Correlation and Continual Learning). The overview of FCCL is illustrated in Fig. 2. In a nutshell, our contributions are three-fold:\n\n\u2022 We formulate a simple and effective method for heterogeneous federated learning. Through leveraging unlabeled public data and adopting self-supervised learning, heterogeneous models achieve communication and learn a generalizable representation.\n\n\u2022 We explore to alleviate catastrophic forgetting in federated learning. Through inter and intra domain knowledge distillation with updated and pretrained models, it balances knowledge from others and itself.\n\n\u2022 We conduct extensive experiments on two image classification tasks (e.g., Digits [27,37,62,68] and Office-Home [82]) with unlabeled public data [35,69,87]. FCCL achieves superior inter and intra domain performance over related methods. Ablation study on core module validates its efficacy and indispensability.\n\n\nRelated Work\n\nFederated with Data Heterogeneity. A pioneering work proposed the currently most widely used algorithm, FedAVG [58]. But it suffers performance deterioration on non-i.i.d data (data heterogeneity). Shortly after, a large body methods [12,41,43,73,77] research on non-i.i.d data. These methods mainly focus on label distribution skew, where non-i.i.d data [30] are formed by partitioning existing data based on label space with limited domain shift. However, when private data sampled from different data domains, these works do not consider inter domain performance but only focus on learning an internal model. Latest researches have studied related problems of unsupervised domain adaptation for target domain [45,65] and domain generalization on unseen domains [52]. However, collecting data in the target domain can be time-consuming and impractical. Meanwhile, considering the performance on unknown domains is an idealistic setting. For more realistic settings, participants are probably more interested in the performance on other domains, which could directly improve economic benefits. In this work, we focus on improving inter domain performance under domain shift.\n\nFederated with Model Heterogeneity. With the demand for unique models, federated learning with model heterogeneity has been an active area of research. FedMD [38], CRONUS [4] and CFD [71] operate on labeled public data (with similar distribution) via knowledge distillation [2,24]. Therefore, these approaches heavily rely on the quality of labeled public data, which may not always be available on the server. Latest works (e.g.,FedDF [50], FedKT [40] and FEDGEN [75]) have proven the feasibility to do distillation on unlabeled public data or synthetic data. However, these methods leverage unlabeled public data to reach semantic information consistency through various measuring metrics [9,36], which are not suitable to learn a generalizable representation and and thus lead to a bad inter domain performance. Another direction is introducing shared extra model such as FML [72] and LG-FEDAVG [48]. However, these techniques may not be applicable when considering the additional computing overhead and expensive communication cost. In this paper, based on unlabeled public data, we correlate same dimensions and decorrelate different dimensions to learn a generalizable representation in heterogeneous federated learning.\n\nSelf-Supervised Learning. Self-supervised Learning has emerged as a powerful method for learning useful representation without supervision from labels, largely reducing the performance gap between supervised models on various downstream vision tasks. Many related methods rely on contrastive learning (e.g., SimCLR [5], MoCO [7,22]), which contrast positive pairs against negative pairs and minimizes difference between positive pairs for avoiding collapsing solutions [79,90]. Recently, another line of works (e.g., BYOL [15], SimSiam [6]) employs asymmetry of the learning update (stop-gradient operation) to avoid trivial solutions. Besides, some methods (e.g., W-MSE [3], Barlow Twins [91] )) investigate the possibility of feature decorrelation based on Cholesky Decomposition [83] and Information Bottleneck [80]. There are several works that consider federated learning with self-supervised learning (e.g., FURL [93], MOON [41]). They focus on the unsupervised learning setting and label distribution skew with model homogeneity respectively. The key difference between FCCL and above self-supervised learning methods is that ours is designed for federated setting rather centralized setting. Inspired by self-supervised learning, FCCL constructs the comparison between different models in federated learning.\n\nCatastrophic Forgetting. Catastrophic forgetting has been an essential problem in continual learning when models continuously learn from a stream data, with the goal of gradually extending acquired knowledge and using it for future learning [14,57]. The challenge lies in the continuously changing class distributions of each task [63,81]. Existing continual learning works on tackling catastrophic forgetting can be broadly divided into three branches [10]: replay methods [1,67], regularization-based methods [32,47,53,85] and parameter isolation methods [55,61,70]. As for federated learning, data are distributed rather than sequential like continual learning. But these differences aside, both continual learning and federated learning share a common challenge -how to balance the knowledge from different data distribution. Unlike continual learning methods, we focus on alleviate catastrophic forgetting in distributed data rather than time series data. In particular, we expect to balance and boost both inter and intra domain performance.\n\n\nMethod\n\nProblem Setup and Notations. Following the standard federated learning setup, there are K participants (indexed by i). Each participant has a local model \u03b8 i and private\ndata D i = {(X i , Y i )|X i \u2208 R Ni\u00d7D , Y i \u2208 R Ni\u00d7C },\nwhere N i denotes the number of private data, D represents input size and C is defined as the number of classes for classification. Meanwhile, the private data distribution is denoted as P i (X, Y ) and rewritten as P i (X|Y )P i (Y ). Furthermore, in heterogeneous federated learning, data heterogeneity and model heterogeneity are defined as following:\n\n\u2022 Data heterogeneity: P i (X|Y ) = P j (X|Y ). There exists domain shift among private data, i.e., conditional distribution P (X|Y ) of private data vary across participants even if P (Y ) is shared. Specifically, same label Y has distinctive feature X in different domains.\n\n\u2022 Model heterogeneity:\nShape(\u03b8 i ) = Shape(\u03b8 j ).\nParticipants customize models independently, i.e., for classification task, the selected backbones (e.g., ResNet [23], EfficientNet [78] and MobileNet [26]) are different with differential classifier models.\n\nWe leverage unlabeled public data D 0 = {X 0 |X 0 \u2208 R N0\u00d7D } to realize communication. The public data are relatively easy to access in real scenarios, e.g., existing datasets [8,51,69] and web images [44]. The goal for i th participant is to reach communication and learn a model \u03b8 i with generalizable representation. In addition, considering catastrophic problem, \u03b8 k is required to present both higher and stabler inter and intra domain performance.\n\nOverview of Framework. The framework of our method is illustrated in Fig. 2. Specifically, in collaborative updating, we measure cross-correlation matrix between logits output on unlabeled public data to make similarity and reduce redundancy. Meanwhile, in local updating, ours continually balances multi domains information through knowledge distillation. Next, we will first describe Federated Cross-Correlation Learning \u00a7 3.1. Then we introduce Federated Continual Learning \u00a7 3.2.\n\n\nFederated Cross-Correlation Learning\n\nMotivation of Dimension-Level Operation. Motivated by the success of self-supervised learning via Information Bottleneck [80,91], a generalizable representation should be as informative as possible about image, while being as invariant as possible to the specific domain distortions that are applied to this sample. In our work, domain shift results in distinctive feature X for the same label Y in different domains. Therefore, the distribution of logits output along the batch dimension on different domains is not identical. Moreover, different dimensions of logits output are corresponding to distinct classes. Thus, we need to encourages the invariance of same dimensions and the diversity of different dimensions. Private data carries specific domain information and is under privacy protection, which is not suitable and feasible to do self-supervised learning. Therefore, we leverage the unlabeled public data, which are normally generated and collected from multi domains and is easy to obtain. We optimize private models through requiring logits output invariant to domain distortion and decorrelating different dimensions of logits output on unlabeled public data.\n\nConstruction of Cross-Correlation Matrix. Specifically, we get the logits output for i th participant:\nZ i = f (\u03b8 i , X 0 ) \u2208 R N0\u00d7C .\nFor i th and j th participant, the logits output on unlabeled public data is Z i and Z j . Notably, considering the computing burden on the server side, we calculate average logits output: Z = 1 K i Z i . Then, we compute cross-correlation matrix, M i for i th participant with average logits output as:\nM uv i b ||Z b,u i || ||Z b,v || b ||Z b,u i || 2 b ||Z b,v || 2 .(1)\nwhere b indexes batch samples, u, v index the dimension of logits output and || \u00b7 || is the normalization operation along the batch dimension. M i is a square matrix with size of output dimensionality, C and values comprised between -1 (i.e., dissimilarity) and 1 (i.e., similarity). Then, collaborative loss for i th participant is defined as:\nL Col i u (1 \u2212 M uu i ) 2 + \u03bb Col u v =u (1 + M uv i ) 2 ,(2)\nwhere \u03bb Col is a positive constant trading off the importance of the first and second terms of loss. Naturally, when ondiagonal terms of the cross-correlation matrix take the value +1, it encourages the logits output from different participants to be similar; when off-diagonal terms of the crosscorrelation matrix take value \u22121, it encourages the diversity of logits output, since different dimensions of these logits output will be uncorrelated to each other.\n\nComparison with Analogous Methods. FedMD [38] relies on minimizing mean square error on annotated data. FedDF [50] reaches logits output distribution consistency on unlabeled public data. However, in our work, we expect [50] [50] calculates the distribution divergence where instance-wise normalized logits output is compared inside a batch. to achieve correlation of same dimensions but decorrelation of different dimensions on unlabeled public data. Besides, we do operation along the batch dimension, which means that we view unlabeled public data as ensemble rather than individual sample. It is advantageous to eliminate anomalous sample disturbance. We further illustrate the conceptual comparison between FCCL and FedDF in Fig. 3.\n\n\nFederated Continual Learning\n\nTypical Supervision Loss. For local updating in federated learning, current methods [38,50,58,74] typically cast this process as a supervised classification problem. Specifically, at t th communication round, after the collaborative updating, the i th private model is defined as \u03b8 t,im i . Then, optimize \u03b8 t,im i on private data D i (X i , Y i ) for fixed epochs. Given the logits output Z t,im i,pvt = f (\u03b8 t,im i , X i ) for private data X i w.r.t its ground truth label Y i , the cross-entropy loss is optimized with softmax:\nL CE i = \u22121 Yi log(softmax(Z t,im i,pvt ),(3)\nwhere 1 Yi denotes the one-hot encoding of Y i and\nsoftmax(Z t,im i,pvt ) = exp(Z t,im i,pvt ) C c =1 exp(Z t,im,c i,pvt )\n. Such training objective design would suffer catastrophic forgetting mainly due to the following two limitations: 1) In local updating, without supervision from other participants, models easily overfit current data distribution and present poor inter domain performance. 2) Besides, it only penalizes the prediction independently with prior probabilities, which provides limited and hard intra domain information [24]. Dual-Domain Knowledge Distillation Loss. In this work, we develop a federated continual learning method to address both 1) and 2) through regularizing the objective from model-wise aspect. Specifically, at the end of t \u2212 1 th round, the updated model, \u03b8 t\u22121 i involves the knowledge learned from other participants. We calculate the logits output on private data: domain knowledge distillation loss is defined as:\nZ t\u22121 i,pvt = f (\u03b8 t\u22121 i , X i ). The inter M \u2192 M M \u2192 M M \u2192 U M \u2192 U (a) CE (b) OursL Inter i = \u03c3(Z t\u22121 i,pvt ) log \u03c3(Z t\u22121 i,pvt ) \u03c3(Z t,im i,pvt ) ,(4)\nwhere \u03c3 denote softmax function. As Eq. (4), the purpose is to continually learn from others while preserving privacy, so as to guarantee inter domain performance and handle catastrophic forgetting in federated learning. Besides, for the i th participant, it is feasible to pretrain a model, \u03b8 * i on private data. We measure the logits output on private data:\nZ * i,pvt = f (\u03b8 * i , X i ).\nThe intra domain knowledge distillation loss can be given as :\nL Intra i = \u03c3(Z * i,pvt ) log \u03c3(Z * i,pvt ) \u03c3(Z t,im i,pvt ) .(5)\nKnowledge distillation with pretrained model provides soft and rich intra domain information. Further, it cooperates with the former typical supervision loss (i.e., cross-entropy loss) in Eq. (3) to provide soft and hard intra domain information to ensure intra domain performance. To some extent, above two models (i.e. updated model \u03b8 t\u22121 i and pretrained model \u03b8 * i ) respectively represent inter and intra 'teacher' model. Through knowledge distillation, balancing knowledge from others and itself simultaneously boosts both inter and intra domain performance. The dual-domain knowledge distillation is calculated by Average logits output:\nL Dual i = L Inter i + L Intra i .(6)Z = 1 K i Zi for i = 1, 2, ..., K in parallel do \u03b8 t,im i \u2190 Federated Cross-Correlation Learning (Zi,Z, \u03b8 t\u22121 i ) \u03b8 t i \u2190 Federate Continual Learning (\u03b8 * i ,\u03b8 t\u22121 i , \u03b8 t,im i ) return \u03b8 T i Federated Cross-Correlation Learning (Zi,Z, \u03b8 t\u22121 i ) Mi \u2190 (Zi, Z) by Eq. (1) L Col i \u2190 (Mi, \u03bb Col ) through Eq. (2) \u03b8 t,im i \u2190 \u03b8 t\u22121 i \u2212 \u03b7\u2207L Col i return \u03b8 t,im i to i th participant Federated Continual Learning (\u03b8 * i ,\u03b8 t\u22121 i , \u03b8 i,im i ): for e = 1, 2, ..., E do Z t,im i,pvt = f (\u03b8 t,im i , Xi) L CE i \u2190 CE(Z t,im i,pvt , Yi) in Eq. (3) L Inter i \u2190 KL(Z t,im i,pvt , f(\u03b8 t\u22121 i , Xi)) in Eq. (4) L Intra i \u2190 KL(Z t,im i,pvt , f(\u03b8 * i , Xi)) in Eq. (5) L Dual i = L Inter i + L Intra i L Loc i = L CE i + \u03bbLoc L Dual i \u03b8 t,im i \u2190 \u03b8 t,im i \u2212 \u03b7\u2207L Loc i \u03b8 t i \u2190 \u03b8 t,im i return \u03b8 t i to i th participant\nThe typical supervision loss in Eq. (3) and dual-domain knowledge distillation loss in Eq. (6) are complementary to each other. The former requires models to learn a discriminative representation that is meaningful for classification tasks, while the latter helps to regularize the model with soft and rich information in both intra and inter domain. Thus, the overall training target is:\nL Loc i = L CE i + \u03bb Loc L Dual i ,(7)\nwhere \u03bb Loc > 0 is a coefficient. As shown in Fig. 4, the features learned by L Dual i is more compact and separated in both intra and inter domain by enjoying the advantage of both typical supervision loss and dual-domain knowledge distillation loss, models show better discriminative features, producing promising intra and inter domain performance.\n\n\nDiscussion and Limitation\n\nWe describe FCCL in Alg. 1. FCCL constructs crosscorrelation matrix with the average logits output. Therefore, FCCL is applicable when there are a large size of partici-pants in federated learning, attributed to that the computation complexity for server side is O(K). Besides, Federated Cross-Correlation Learning does operation on logits output regardless of the specific model structure. Thus, when participants share same model structure (model homogeneity), FCCL is still capable. Assuming that there is no data heterogeneity among distributed data, the first term of L Col i in Eq. (1) would be close to zero, but the second term still disassociates different dimensions on logits output. On this basis, FCCL is model agnostic method and able to handle different degree of domain shift. However, we also note limitation on the requirement of task consistency. For multi-task setting, logits output may not only have distinct dimensions, but also contain different meanings for same dimension. This limitation is also shared by related methods [38,50,74,91].\n\n\nExperiments\n\nData and Model. We extensively evaluate our method on two classification tasks (e.g., Digits [27,37,62,68] and Office-Home [82]) with three public data (e.g., Cifar-100 [35], ImageNet [69] and Fashion-MNIST [87]). Specifically, Digits task includes four domains (i.e., MNIST (M ), USPS (U ), SVHN (SV ) and SYN (SY )) with 10 categories. The Office-Home task also have four domains (i.e., Art (A ), Clipart (C ), Product (P ) and Real World (R )). Note that for both tasks, data acquired from different domains present domain shift (data heterogeneity).\n\nFor these two classification tasks, participants customize models that can be differ from differentiated backbones and classifiers (model heterogeneity). For experiments, we set the model as ResNet [23], EfficientNet [78], MobileNet [26] and GoogLeNet [76] for these four domains.\n\nComparison Methods. We compare our method, FCCL with state-of-the-art approaches including FedDF [50], FML [72], FedMD [38], RCFL [16] and FedMatch [28]. We also compare SOLO, where participant trains a model on private data without federated learning. Since specific experimental settings are not totally consistent, we retain key features of methods for comparison.\n\nEvaluation Metrics. We report the standard metrics to measure the quality of methods: accuracy, which is defined as the number of samples that are paired divided by the number of samples. Specifically, for evaluation intra and inter domain performance, we define as following:  adopt the average accuracy as metric. Besides, for these two classification tasks, Digits and Office-Home respectively contain 10 and 65 categories. Top-1 and Top-5 accuracy are adopted for these two tasks. Implementation Details. In federated learning process, all participants adopt the same hyper-parameter setting (i.e., \u03bb Col = 0.0051 like [91] and \u03bb Loc = 1). Models are trained using Adam optimizer [31] with batch size of 512 and learning rate as 0.001 in both collaborative updating and local updating for all approaches. In terms of data scale, in Digits task, MNIST, USPS, SVHN and SYN are assigned to four participants. The size of corresponding private data is set to 150, 80, 5000 and 1800 respectively. As for Office-Home task, each participant is individually assigned with Art, Clipart, Product and Real World, and the corresponding private data size is 1400, 2000, 2500, 2000. The number of unlabeled public data is 5000 for these two tasks. For pre-processing, we resize all input images into 32 \u00d7 32 with three channels for compatibility. We do communication for T = 40 rounds, where all approaches have little or no accuracy gain with more communications rounds. Besides, for SOLO, models are trained on private data for 50 epochs, which are also initial models for federated learning process.\nA Intra i = (argMax(f (\u03b8 i , X T est i )) == Y T est i ) |D T est i | ,(8)A Inter i = j =i (argMax(f (\u03b8 i , X T est j )) == Y T est j ) (K \u2212 1) \u00d7 |D T est j | .(9)\n\nComparison with State-of-the-Art Methods\n\nWe provide comparison results with state-of-the-art methods on two image classification tasks (i.e., Digits and Office-Home) with three public data (i.e., Cifar-100 , Ima-geNet and Fashion-MNIST ).\n\nInter Domain Analysis. We report the inter domain performance with state-of-the-art methods on Tab. 1. It clearly depict that under domain shift, SOLO present worst in these two tasks, demonstrating the benefits of federated learning. We observe that FCCL significantly outperforms better than counterparts. The Fig. 5 presents that FCCL achieves similar logits output between participants and redundancy within the logits output, confirming that FCCL successfully enforces the correlation of same dimensions and decorrelation of different dimensions on both public and private data.\n\nIntra Domain Analysis. To compare the effectiveness of alleviating catastrophic forgetting, we show the intra domain performance in Tab. 2. Take the results of Digits task with Cifar-100 as an example, our method outperforms the strong compared method, RCFL , by 2.30%. Besides, the intra domain accuracy via increasing communication rounds in Fig. 6a and optimization objective value in Fig. 6b present that FCCL suffers less periodic performance shock and is not prone to overfitting to current data distribution (L Loc = 0.0225), illustrating that FCCL is cable of balancing multiple knowledge, alleviating catastrophic forgetting.\n\nModel Homogeneity Analysis. We further compare FCCL with other methods under model homogeneity. We set the shared model as ResNet-18 and add the averaging parameters operation between collaborative updating and local updating. The Tab. 3 presents both inter and intra domain performance on Office-Home task with Cifar-100 .  Table 2. Comparison of intra domain performance with stateof-the-art methods on these two tasks with Cifar-100. The metric is evaluated on respective testing data in Eq. (8).\n\n(a) Average Intra Domain Accuracy (b) L Loc Figure 6. Comparison of intra domain performance and optimization objective value in local updating via increasing communication rounds on Digits task with Cifar-100.  Table 3. Comparison with state-of-the-art methods under model homogeneity on Office-Home task with Cifar-100.\n\n\nInter Domain Intra Domain Methods\nA \u2192 C \u2192 P \u2192 R \u2192 A C P R SOLO\n\nDiagnostic Experiments\n\nTo demonstrate how each component in FCCL contributes to overall performance, a series of ablation experiments are conducted. The proposed method, FCCL is comprised of two components: Federated Cross-Correlation Learning and Federated Continual learning.\n\nFederated Cross-Correlation Learning. To prove its robustness and stability, we evaluate the performance on different public data without label (i.e., Cifar-100 , Ima-geNet and Fashion-MNIST ). The results in Fig. 7 suggest that Federated Cross-Correlation Learning achieves consistent performance in each domain. Moreover, it can be seen that it is more effective by the use of public data with rich categories (ImageNet) or simple detail (Fashion-MNIST ).\n\nFederated Continual Learning. We investigate the effectiveness of our core idea in handling catastrophic forgetting. As shown in Fig. 8 tial inter domain performance gain (i.e., 6.38% on Digits task with Cifar-100 ), compared with w/o CON (optimization objective in local updating is only cross-entropy loss, L Ce i in Eq. (3)). In addition, the Fig. 8 illustrates that it also boosts the intra performance (i.e., 3.88% with Ima-geNet). The Fig. 4 visualizes features in intra and inter domain cases. As seen, the proposed Federated Continual Learning begets a well discriminative feature space. This suggests that exploiting extra restriction signals in local updating is beneficial for alleviating catastrophic forgetting. \n\n\nConclusion\n\nThis paper proposes a simple and effective method of FCCL for federated learning. FCCL is capable of handling heterogeneity problem and alleviating catastrophic forgetting. In particular, we construct cross-correlation matrix in collaborative updating to learn a generalizable representation. Meanwhile, we introduce knowledge distillation with inter and intra domain information in local updating, boosting inter and intra domain performance. Experimental results on classification tasks show that our method performs favorably in comparison with state-of-the-art methods.\n\nFigure 2 .\n2Illustration of FCCL . (a) Simplified schematization of our method that solves heterogeneity problem and catastrophic forgetting via Federated Cross-Correlation Learning and Federated Continual Learning. (b) Federated Cross-Correlation Learning \u00a7 3.1: Construct cross-correlation matrix Mi to target matrix, MT = 2 \u00d7 eye(C) \u2212 ones(C), where on-diagonal is 1, off-diagonal is \u22121. (c) Federated Continual Learning \u00a7 3.2: Distillation with updated and pretrained models offers inter and intra domain knowledge without privacy leaking. The gradient color proportion reflects the degree of influence by other participants. Best viewed in color. Zoom in for details.\n\nFigure 3 .\n3Conceptual comparison. The unlabeled public data X0 with batch size B and input size D are fed into different models. The logits output has C dimensions. (a) FCCL learns invariance in same dimensions and decorrelates pairs of different dimensions on the batch-wise normalized logits output in Eq. (1). (b) FedDF\n\nFigure 4 .\n4Visualization of features learned with (left) typical supervision loss (i.e., cross-entropy loss, L CE in Eq. (3) and (right) optimization objective based on dual-domain knowledge distillation (i.e., L Dual in Eq. (6)) on intra (top) and inter (bottom) domain. M and U represent MNIST and USPS respectively. Features are colored based on class labels.\n\nFigure 5 .\n5Cross-correlation matrix visualization for different domains on Digits task with Cifar-100 . We visualize the cross-correlation matrix (Eq.(1)) with other models on public data (left) and private data (right) respectively. The left and right figure in each subfigure represent the cross-correlation matrix with other models on public data (i.e., Cifar-100 ) and private data respectively. The matrix is 10\u00d710. The darker the color, the closer the M uv i (Eq. (1)) is to 1.\n\n\nAs for the method overall performance evaluation, weDigits \n\nOffice-Home \nMethods \nM \u2192 \nU \u2192 \nSV \u2192 \nSY \u2192 \nAVG \nA \u2192 \nC \u2192 \nP \u2192 \nR \u2192 \nAVG \n\nSOLO \n15.29 \n13.91 \n39.24 \n34.30 \n25.68 \n18.89 \n19.36 \n21.97 \n21.02 \n20.31 \nFedMD [38] \n8.97 \n12.61 \n40.89 \n43.03 \n26.38 \n16.85 \n23.13 \n28.78 \n25.01 \n23.44 \nFML [72] \n17.11 \n16.00 \n45.19 \n46.26 \n31.14 \n18.97 \n24.41 \n29.75 \n24.91 \n24.51 \nRCFL [16] \n10.21 \n16.10 \n48.85 \n37.96 \n28.28 \n15.16 \n22.01 \n27.98 \n23.95 \n22.28 \nFedDF [50] \n13.23 \n19.29 \n45.25 \n43.95 \n30.43 \n17.38 \n21.76 \n25.17 \n22.97 \n21.82 \nFedMatch [28] \n9.22 \n14.76 \n46.28 \n36.05 \n26.58 \n19.05 \n25.24 \n28.73 \n24.35 \n24.34 \nFCCL \n20.74 \n20.60 \n44.68 \n48.02 \n33.51 \n25.55 26.41 \n30.14 \n29.41 \n27.88 \n\nTable 1. Comparison of inter domain performance with state-of-the-art methods. M \u2192 means that private data is MNIST and \nrespective model is tested on other domains in Eq. (9). AVG denotes average accuracy calculated from each domain. (The best average \naccuracy is marked in bold. The best entries in each domain are underlined. These notes are the same to others.) \n\n\n\n\nSOLO 70.20 74.19 74.57 73.60 65.27 60.50 74.68 54.28 FedMD [38] 77.30 80.05 77.73 87.72 66.17 60.63 76.35 56.60 FML [72] 80.66 79.75 78.58 88.87 81.46 65.58 79.82 65.07 RCFL [16] 82.59 81.05 78.79 91.40 65.13 61.33 76.44 55.78 FedDF [50] 82.95 78.84 78.46 91.30 66.10 60.44 75.70 55.98 FedMatch [28] 82.69 78.31 79.79 89.23 81.50 65.40 79.81 65.06 FCCL 88.84 84.42 78.55 91.23 81.51 65.42 79.84 65.16Digits \n\nOffice-Home \nMethods M \nU \nSV \nSY \nA \nC \nP \nR \n\n\n\n\n18.89 22.58 22.33 27.26 65.27 61.51 74.84 57.65 FedAVG [58] 57.85 54.05 55.72 60.18 66.71 60.90 74.29 57.49 FedMD [38] 61.03 62.41 62.45 62.55 66.50 61.75 73.63 58.10 FedMatch [28] 51.60 47.77 42.33 55.35 80.35 65.05 78.99 64.55 FCCL 64.48 62.33 63.26 64.86 81.38 65.47 79.40 65.19FML [72] 39.56 36.94 32.73 42.00 74.87 60.73 77.19 60.71 \nRCFL [16] 61.52 59.56 57.56 63.59 67.16 61.39 73.33 58.58 \nFedDF [50] 61.10 57.92 62.19 60.41 66.69 60.69 74.12 57.69 \n\n\n\n, additionally considering dualdomain knowledge distillation ( \u00a7 3.2) leads to a substan-Figure 7. Ablation study on Federated Cross-Correlation Learning \u00a7 3.1 with different public data for inter domain performance on each domain performance (left) and overall performance (right) in Digits task.20.74 \n20.6 \n\n44.68 \n48.02 \n\n21.62 \n21.12 \n\n47.73 \n\n52.34 \n\n21.12 \n24.07 \n\n51.97 \n50.13 \n\nMNIST \nUSPS \nSVHN \nSYN \n\nCifar-100 \nImageNet \nFashion-MNIST \n\nPublic Data \nAVG \n\nCifar-100 \n33.51 \n\nImageNet \n35.70 \n\nFashion-MNIST \n36.82 \n\n\n\n\nAblation study on Federated Continual Learning \u00a7 3.2 for inter (left) and intra (right) domain performance on Digits task. w/o CON means that loss function is L CE i in Eq. (3).33.51 \n\n35.7 \n\n36.82 \n\n27.13 \n\n30.26 \n\n32.42 \n\nCifar-100 \nImageNet \nFashion-MNIST \n\nFCCL w/o CON \n\nMethods \nAVG \n\nCifar-100 \nFCCL \n85.76 \nw/o CON \n82.07 \n\nImageNet \nFCCL \n86.09 \nw/o CON \n82.21 \n\nFashion-MNIST \nFCCL \n85.77 \nw/o CON \n83.29 \nFigure 8. \n\nRainbow memory: Continual learning with a memory of diverse samples. Jihwan Bang, Heesu Kim, Youngjoon Yoo, Jung-Woo Ha, Jonghyun Choi, CVPR. Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha, and Jonghyun Choi. Rainbow memory: Continual learning with a memory of diverse samples. In CVPR, pages 8218- 8227, 2021. 3\n\nModel compression. Cristian Bucilu\u01ce, Rich Caruana, Alexandru Niculescu-Mizil, KDD. 23Cristian Bucilu\u01ce, Rich Caruana, and Alexandru Niculescu- Mizil. Model compression. In KDD, pages 535-541, 2006. 2, 3\n\nParametric instance classification for unsupervised visual feature learning. Yue Cao, Zhenda Xie, Bin Liu, Yutong Lin, Zheng Zhang, Han Hu, NeurIPS. 2020Yue Cao, Zhenda Xie, Bin Liu, Yutong Lin, Zheng Zhang, and Han Hu. Parametric instance classification for unsu- pervised visual feature learning. In NeurIPS, pages 15614- 15624, 2020. 3\n\nCronus: Robust and heterogeneous collaborative learning with black-box knowledge transfer. Hongyan Chang, Virat Shejwalkar, Reza Shokri, Amir Houmansadr, arXiv:1912.11279arXiv preprintHongyan Chang, Virat Shejwalkar, Reza Shokri, and Amir Houmansadr. Cronus: Robust and heterogeneous collab- orative learning with black-box knowledge transfer. arXiv preprint arXiv:1912.11279, 2019. 3\n\nA simple framework for contrastive learning of visual representations. Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, ICML. 23Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge- offrey Hinton. A simple framework for contrastive learning of visual representations. In ICML, pages 1597-1607, 2020. 2, 3\n\nExploring simple siamese representation learning. Xinlei Chen, Kaiming He, CVPR. 23Xinlei Chen and Kaiming He. Exploring simple siamese rep- resentation learning. In CVPR, pages 15750-15758, 2021. 2, 3\n\nAn empirical study of training self-supervised vision transformers. Xinlei Chen, * , Saining Xie, * , Kaiming He, ICCV. Xinlei Chen*, Saining Xie*, and Kaiming He. An empiri- cal study of training self-supervised vision transformers. In ICCV, 2021. 3\n\nThe cityscapes dataset for semantic urban scene understanding. Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, Bernt Schiele, CVPR. 13Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic urban scene understanding. In CVPR, 2016. 1, 3\n\nA tutorial on the cross-entropy method. Pieter-Tjerk De Boer, Dirk P Kroese, Shie Mannor, Reuven Y Rubinstein, Annals of Operations Research. 3Pieter-Tjerk De Boer, Dirk P Kroese, Shie Mannor, and Reuven Y Rubinstein. A tutorial on the cross-entropy method. Annals of Operations Research, pages 19-67, 2005. 3\n\nAles Leonardis, Greg Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, IEEE TPAMI. 3Matthias Delange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ales Leonardis, Greg Slabaugh, and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEE TPAMI, pages 1-1, 2021. 3\n\nUnsupervised visual representation learning by context prediction. Carl Doersch, Abhinav Gupta, Alexei A Efros, ICCV. Carl Doersch, Abhinav Gupta, and Alexei A Efros. Unsuper- vised visual representation learning by context prediction. In ICCV, pages 1422-1430, 2015. 2\n\nRobust federated learning with noisy and heterogeneous clients. Xiuwen Fang, Mang Ye, CVPR. 2022Xiuwen Fang and Mang Ye. Robust federated learning with noisy and heterogeneous clients. In CVPR, 2022. 2\n\nLearning representations by predicting bags of visual words. Spyros Gidaris, Andrei Bursuc, Gilles Puy, Nikos Komodakis, Matthieu Cord, Patrick P\u00e9rez, CVPR. Spyros Gidaris, Andrei Bursuc, Gilles Puy, Nikos Ko- modakis, Matthieu Cord, and Patrick P\u00e9rez. Learning rep- resentations by predicting bags of visual words. In CVPR, 2021. 2\n\nAn empirical investigation of catastrophic forgetting in gradient-based neural networks. J Ian, Mehdi Goodfellow, Da Mirza, Aaron Xiao, Yoshua Courville, Bengio, arXiv:1312.6211arXiv preprintIan J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. An empirical investigation of catas- trophic forgetting in gradient-based neural networks. arXiv preprint arXiv:1312.6211, 2013. 3\n\nBootstrap your own latent -a new approach to self-supervised learning. Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, H Pierre, Elena Richemond, Carl Buchatskaya, Bernardo Doersch, Zhaohan Daniel Avila Pires, Mohammad Gheshlaghi Guo, Azar, NeurIPS. Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre H Richemond, Elena Buchatskaya, Carl Do- ersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Moham- mad Gheshlaghi Azar, et al. Bootstrap your own latent -a new approach to self-supervised learning. In NeurIPS, pages 21271-21284, 2020. 3\n\nResource-constrained federated learning with heterogeneous labels and models. Bala Gautham Krishna Gudur, Shyamala Balaji, K Satheesh, Perepu, ACM SIGKDD Workshop, 2020. 6. 7Gautham Krishna Gudur, Bala Shyamala Balaji, and Satheesh K Perepu. Resource-constrained federated learn- ing with heterogeneous labels and models. In ACM SIGKDD Workshop, 2020. 6, 7, 8\n\nFederated learning with diversified preference for humor recognition. Xu Guo, Pengwei Xing, Siwei Feng, Boyang Li, Chunyan Miao, IJCAI Workshop. 2020Xu Guo, Pengwei Xing, Siwei Feng, Boyang Li, and Chun- yan Miao. Federated learning with diversified preference for humor recognition. In IJCAI Workshop, 2020. 1\n\nDimensionality reduction by learning an invariant mapping. Raia Hadsell, Sumit Chopra, Yann Lecun, CVPR. Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimension- ality reduction by learning an invariant mapping. In CVPR, pages 1735-1742, 2006. 2\n\nFederated learning for mobile keyboard prediction. Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Fran\u00e7oise Beaufays, Sean Augenstein, Hubert Eichner, Chlo\u00e9 Kiddon, Daniel Ramage, arXiv:1811.03604arXiv preprintAndrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ra- maswamy, Fran\u00e7oise Beaufays, Sean Augenstein, Hubert Eichner, Chlo\u00e9 Kiddon, and Daniel Ramage. Federated learning for mobile keyboard prediction. arXiv preprint arXiv:1811.03604, 2018. 1\n\nFednas: Federated deep learning via neural architecture search. Chaoyang He, Murali Annavaram, Salman Avestimehr, arXiv:2004.08546arXiv preprintChaoyang He, Murali Annavaram, and Salman Avestimehr. Fednas: Federated deep learning via neural architecture search. arXiv preprint arXiv:2004.08546, 2020. 2\n\nGroup knowledge transfer: Federated learning of large cnns at the edge. Chaoyang He, Murali Annavaram, Salman Avestimehr, NeurIPS. 2020Chaoyang He, Murali Annavaram, and Salman Avestimehr. Group knowledge transfer: Federated learning of large cnns at the edge. In NeurIPS, pages 14068-14080, 2020. 2\n\nMomentum contrast for unsupervised visual representation learning. Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Ross Girshick, CVPR. 2020Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual rep- resentation learning. In CVPR, pages 9729-9738, 2020. 3\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR. 36Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, pages 770-778, 2016. 3, 6\n\nGeoffrey Hinton, Oriol Vinyals, Jeff Dean, arXiv:1503.02531Distilling the knowledge in a neural network. 25arXiv preprintGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distill- ing the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015. 2, 3, 5\n\nUnsupervised learning: foundations of neural computation. Terrence Joseph Geoffrey E Hinton, Sejnowski, MIT pressGeoffrey E Hinton, Terrence Joseph Sejnowski, et al. Unsu- pervised learning: foundations of neural computation. MIT press, 1999. 2\n\nG Andrew, Menglong Howard, Bo Zhu, Dmitry Chen, Weijun Kalenichenko, Tobias Wang, Marco Weyand, Hartwig Andreetto, Adam, arXiv:1704.04861Mobilenets: Efficient convolutional neural networks for mobile vision applications. 36arXiv preprintAndrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco An- dreetto, and Hartwig Adam. Mobilenets: Efficient convolu- tional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. 3, 6\n\nA database for handwritten text recognition research. Jonathan J Hull, IEEE TPAMI. 26Jonathan J. Hull. A database for handwritten text recognition research. IEEE TPAMI, pages 550-554, 1994. 2, 6\n\nFederated semi-supervised learning with inter-client consistency & disjoint learning. Wonyong Jeong, Jaehong Yoon, Eunho Yang, Sung Ju Hwang, ICLR, 2021. 6. 7Wonyong Jeong, Jaehong Yoon, Eunho Yang, and Sung Ju Hwang. Federated semi-supervised learning with inter-client consistency & disjoint learning. In ICLR, 2021. 6, 7, 8\n\nPrivacy-preserving technology to help millions of people: Federated prediction model for stroke prevention. Ce Ju, Ruihui Zhao, Jichao Sun, Xiguang Wei, Bo Zhao, Yang Liu, Hongshan Li, Tianjian Chen, Xinwei Zhang, Dashan Gao, arXiv:2006.10517arXiv preprintCe Ju, Ruihui Zhao, Jichao Sun, Xiguang Wei, Bo Zhao, Yang Liu, Hongshan Li, Tianjian Chen, Xinwei Zhang, Dashan Gao, et al. Privacy-preserving technology to help millions of people: Federated prediction model for stroke prevention. arXiv preprint arXiv:2006.10517, 2020. 1\n\nPeter Kairouz, Brendan Mcmahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, arXiv:1912.04977Rachel Cummings, et al. Advances and open problems in federated learning. 1arXiv preprintPeter Kairouz, H Brendan McMahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cum- mings, et al. Advances and open problems in federated learn- ing. arXiv preprint arXiv:1912.04977, 2019. 1, 2\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 7\n\nAgnieszka Grabska-Barwinska, et al. Overcoming catastrophic forgetting in neural networks. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, PNASJames Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska- Barwinska, et al. Overcoming catastrophic forgetting in neu- ral networks. PNAS, pages 3521-3526, 2017. 3\n\nFederated optimization: Distributed machine learning for on-device intelligence. Jakub Kone\u010dn\u1ef3, Brendan Mcmahan, Daniel Ramage, Peter Richt\u00e1rik, arXiv:1610.02527arXiv preprintJakub Kone\u010dn\u1ef3, H Brendan McMahan, Daniel Ramage, and Peter Richt\u00e1rik. Federated optimization: Distributed ma- chine learning for on-device intelligence. arXiv preprint arXiv:1610.02527, 2016. 1\n\nFederated learning: Strategies for improving communication efficiency. Jakub Kone\u010dn\u1ef3, Brendan Mcmahan, X Felix, Peter Yu, Ananda Richt\u00e1rik, Dave Theertha Suresh, Bacon, arXiv:1610.05492arXiv preprintJakub Kone\u010dn\u1ef3, H Brendan McMahan, Felix X Yu, Peter Richt\u00e1rik, Ananda Theertha Suresh, and Dave Bacon. Fed- erated learning: Strategies for improving communication ef- ficiency. arXiv preprint arXiv:1610.05492, 2016. 1\n\nLearning multiple layers of features from tiny images. A Krizhevsky, G Hinton, 26Department of Computer Science, University of TorontoMaster's thesisA. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master's thesis, Department of Computer Science, University of Toronto, 2009. 2, 6\n\nOn information and sufficiency. Solomon Kullback, A Richard, Leibler, Annals of Mathematical Statistics. 3Solomon Kullback and Richard A Leibler. On information and sufficiency. Annals of Mathematical Statistics, pages 79- 86, 1951. 3\n\nGradient-based learning applied to document recognition. Yann Lecun, L\u00e9on Bottou, Yoshua Bengio, Patrick Haffner, Proceedings of the IEEE. the IEEE26Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recog- nition. Proceedings of the IEEE, pages 2278-2324, 1998. 2, 6\n\nFedmd: Heterogenous federated learning via model distillation. Daliang Li, Junpu Wang, NeurIPS Workshop. 7Daliang Li and Junpu Wang. Fedmd: Heterogenous feder- ated learning via model distillation. In NeurIPS Workshop, 2019. 2, 3, 4, 5, 6, 7, 8\n\nFederated learning on non-iid data silos: An experimental study. Qinbin Li, Yiqun Diao, Quan Chen, Bingsheng He, arXiv:2102.02079arXiv preprintQinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He. Fed- erated learning on non-iid data silos: An experimental study. arXiv preprint arXiv:2102.02079, 2021. 1\n\nModel-agnostic round-optimal federated learning via knowledge transfer. Qinbin Li, Bingsheng He, Dawn Song, arXiv:2010.01017arXiv preprintQinbin Li, Bingsheng He, and Dawn Song. Model-agnostic round-optimal federated learning via knowledge transfer. arXiv preprint arXiv:2010.01017, 2020. 3\n\nModelcontrastive federated learning. Qinbin Li, Bingsheng He, Dawn Song, CVPR. 23Qinbin Li, Bingsheng He, and Dawn Song. Model- contrastive federated learning. In CVPR, pages 10713- 10722, 2021. 2, 3\n\nFederated learning: Challenges, methods, and future directions. Tian Li, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith, IEEE SPM. 1Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods, and future directions. IEEE SPM, pages 50-60, 2020. 1\n\nFederated optimization in heterogeneous networks. Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, Virginia Smith, arXiv:1812.061271arXiv preprintTian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar San- jabi, Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127, 2018. 1, 2\n\nWen Li, Limin Wang, Wei Li, Eirikur Agustsson, Luc Van Gool, arXiv:1708.02862Webvision database: Visual learning and understanding from web data. arXiv preprintWen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database: Visual learning and under- standing from web data. arXiv preprint arXiv:1708.02862, 2017. 3\n\nMulti-site fmri analysis using privacy-preserving federated learning and domain adaptation: Abide results. Xiaoxiao Li, Yufeng Gu, Nicha Dvornek, H Lawrence, Pamela Staib, James S Ventola, Duncan, 101765MedIAXiaoxiao Li, Yufeng Gu, Nicha Dvornek, Lawrence H Staib, Pamela Ventola, and James S Duncan. Multi-site fmri anal- ysis using privacy-preserving federated learning and domain adaptation: Abide results. MedIA, page 101765, 2020. 3\n\nFed{bn}: Federated learning on non-{iid} features via local batch normalization. Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, Qi Dou, ICLR. Xiaoxiao Li, Meirui Jiang, Xiaofei Zhang, Michael Kamp, and Qi Dou. Fed{bn}: Federated learning on non-{iid} fea- tures via local batch normalization. In ICLR, 2021. 1\n\nLearning without forgetting. Zhizhong Li, Derek Hoiem, IEEE TPAMI. 3Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE TPAMI, pages 2935-2947, 2017. 3\n\nThink locally, act globally: Federated learning with local and global representations. Terrance Paul Pu Liang, Liu Liu, Ziyin, Randy P Nicholas B Allen, David Auerbach, Ruslan Brent, Louis-Philippe Salakhutdinov, Morency, NeurIPS Workshop, 2020. 23Paul Pu Liang, Terrance Liu, Liu Ziyin, Nicholas B Allen, Randy P Auerbach, David Brent, Ruslan Salakhutdinov, and Louis-Philippe Morency. Think locally, act globally: Fed- erated learning with local and global representations. In NeurIPS Workshop, 2020. 2, 3\n\nLearning deep parsimonious representations. Renjie Liao, Alexander Schwing, S Richard, Raquel Zemel, Urtasun, NeurIPS. Renjie Liao, Alexander Schwing, Richard S Zemel, and Raquel Urtasun. Learning deep parsimonious representa- tions. In NeurIPS, pages 5083-5091, 2016. 2\n\nEnsemble distillation for robust model fusion in federated learning. Tao Lin, Lingjing Kong, U Sebastian, Martin Stich, Jaggi, NeurIPS. 7Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi. Ensemble distillation for robust model fusion in fed- erated learning. In NeurIPS, pages 2351-2363, 2020. 2, 3, 4, 5, 6, 7, 8\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, ECCV. 13Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV, pages 740-755, 2014. 1, 3\n\nFeddg: Federated domain generalization on medical image segmentation via episodic learning in continuous frequency space. Quande Liu, Cheng Chen, Jing Qin, Qi Dou, Pheng-Ann Heng, CVPR. 13Quande Liu, Cheng Chen, Jing Qin, Qi Dou, and Pheng-Ann Heng. Feddg: Federated domain generalization on medical image segmentation via episodic learning in continuous fre- quency space. In CVPR, pages 1013-1023, 2021. 1, 3\n\nRotate your networks: Better weight consolidation and less catastrophic forgetting. Xialei Liu, Marc Masana, Luis Herranz, Joost Van De, Antonio M Weijer, Andrew D Lopez, Bagdanov, ICPR. Xialei Liu, Marc Masana, Luis Herranz, Joost Van de Weijer, Antonio M Lopez, and Andrew D Bagdanov. Rotate your networks: Better weight consolidation and less catastrophic forgetting. In ICPR, pages 2262-2268, 2018. 3\n\nFedvision: An online visual object detection platform powered by federated learning. Yang Liu, Anbu Huang, Yun Luo, He Huang, Youzhi Liu, Yuanyuan Chen, Lican Feng, Tianjian Chen, Han Yu, Qiang Yang, AAAI. Yang Liu, Anbu Huang, Yun Luo, He Huang, Youzhi Liu, Yuanyuan Chen, Lican Feng, Tianjian Chen, Han Yu, and Qiang Yang. Fedvision: An online visual object detection platform powered by federated learning. In AAAI, pages 13172-13179, 2020. 1\n\nPacknet: Adding multiple tasks to a single network by iterative pruning. Arun Mallya, Svetlana Lazebnik, CVPR. Arun Mallya and Svetlana Lazebnik. Packnet: Adding mul- tiple tasks to a single network by iterative pruning. In CVPR, pages 7765-7773, 2018. 3\n\nIntellectual property rights: A critical history. Lynne Rienner Publishers Boulder. Christopher May, K Susan, Sell, Christopher May and Susan K Sell. Intellectual property rights: A critical history. Lynne Rienner Publishers Boul- der, 2006. 2\n\nCatastrophic interference in connectionist networks: The sequential learning problem. Michael Mccloskey, J Neal, Cohen, Psychology of Learning and Motivation. Elsevier23Michael McCloskey and Neal J Cohen. Catastrophic inter- ference in connectionist networks: The sequential learning problem. In Psychology of Learning and Motivation, pages 109-165. Elsevier, 1989. 2, 3\n\nCommunicationefficient learning of deep networks from decentralized data. Brendan Mcmahan, Eider Moore, Daniel Ramage, Seth Hampson, Blaise Aguera Y Arcas, Artificial Intelligence and Statistics. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication- efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pages 1273-1282, 2017. 1, 2, 5, 8\n\nSecureml: A system for scalable privacy-preserving machine learning. Payman Mohassel, Yupeng Zhang, IEEE SSP. Payman Mohassel and Yupeng Zhang. Secureml: A system for scalable privacy-preserving machine learning. In IEEE SSP, pages 19-38, 2017. 1\n\nA unifying view on dataset shift in classification. G Jose, Troy Moreno-Torres, Roc\u00edo Raeder, Alaiz-Rodr\u00edguez, V Nitesh, Francisco Chawla, Herrera, PRJose G Moreno-Torres, Troy Raeder, Roc\u00edo Alaiz- Rodr\u00edguez, Nitesh V Chawla, and Francisco Herrera. A uni- fying view on dataset shift in classification. PR, pages 521- 530, 2012. 1\n\nNettailor: Tuning the architecture, not just the weights. Pedro Morgado, Nuno Vasconcelos, CVPR. Pedro Morgado and Nuno Vasconcelos. Nettailor: Tuning the architecture, not just the weights. In CVPR, pages 3044- 3054, 2019. 3\n\nReading digits in natural images with unsupervised feature learning. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y Ng, NeurIPS Workshop. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis- sacco, Bo Wu, and Andrew Y Ng. Reading digits in natu- ral images with unsupervised feature learning. In NeurIPS Workshop, 2011. 2, 6\n\nToward understanding catastrophic forgetting in continual learning. Alessandro Cuong V Nguyen, Michael Achille, Tal Lam, Vijay Hassner, Stefano Mahadevan, Soatto, arXiv:1908.01091arXiv preprintCuong V Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay Mahadevan, and Stefano Soatto. Toward understanding catastrophic forgetting in continual learning. arXiv preprint arXiv:1908.01091, 2019. 3\n\nA survey on transfer learning. Qiang Sinno Jialin Pan, Yang, IEEE TKDE. 1Sinno Jialin Pan and Qiang Yang. A survey on transfer learn- ing. IEEE TKDE, pages 1345-1359, 2009. 1\n\nFederated adversarial domain adaptation. Xingchao Peng, Zijun Huang, Yizhe Zhu, Kate Saenko, ICLR. 2020Xingchao Peng, Zijun Huang, Yizhe Zhu, and Kate Saenko. Federated adversarial domain adaptation. In ICLR, 2020. 3\n\nDataset Shift in Machine Learning. Joaquin Qui\u00f1onero-Candela, Masashi Sugiyama, D Neil, Anton Lawrence, Schwaighofer, Mit PressJoaquin Qui\u00f1onero-Candela, Masashi Sugiyama, Neil D Lawrence, and Anton Schwaighofer. Dataset Shift in Ma- chine Learning. Mit Press, 2009. 1\n\nicarl: Incremental classifier and representation learning. Alexander Sylvestre-Alvise Rebuffi, Georg Kolesnikov, Christoph H Sperl, Lampert, CVPR. Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl: Incremental classi- fier and representation learning. In CVPR, pages 2001-2010, 2017. 3\n\nPrasun Roy, Subhankar Ghosh, arXiv:1807.10108Saumik Bhattacharya, and Umapada Pal. Effects of degradations on deep neural network architectures. 26arXiv preprintPrasun Roy, Subhankar Ghosh, Saumik Bhattacharya, and Umapada Pal. Effects of degradations on deep neural net- work architectures. arXiv preprint arXiv:1807.10108, 2018. 2, 6\n\n. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C Berg, Li Fei-Fei, 6Imagenet large scale visual recognition challenge. IJCVOlga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San- jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large scale visual recognition challenge. IJCV, pages 211-252, 2015. 1, 2, 3, 6\n\nA Andrei, Rusu, C Neil, Guillaume Rabinowitz, Hubert Desjardins, James Soyer, Koray Kirkpatrick, Kavukcuoglu, arXiv:1606.04671Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprintAndrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray Kavukcuoglu, Raz- van Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint arXiv:1606.04671, 2016. 3\n\n. Felix Sattler, Arturo Marban, Roman Rischke, Wojciech Samek, arXiv:2012.00632Communication-efficient federated distillation. arXiv preprintFelix Sattler, Arturo Marban, Roman Rischke, and Woj- ciech Samek. Communication-efficient federated distilla- tion. arXiv preprint arXiv:2012.00632, 2020. 3\n\nFederated mutual learning. Tao Shen, Jie Zhang, Xinkang Jia, Fengda Zhang, Gang Huang, Pan Zhou, Kun Kuang, Fei Wu, Chao Wu, arXiv:2006.167657arXiv preprintTao Shen, Jie Zhang, Xinkang Jia, Fengda Zhang, Gang Huang, Pan Zhou, Kun Kuang, Fei Wu, and Chao Wu. Fed- erated mutual learning. arXiv preprint arXiv:2006.16765, 2020. 2, 3, 6, 7, 8\n\nOvercoming forgetting in federated learning on non-iid data. NeurIPS Workshop. Neta Shoham, Tomer Avidor, Aviv Keren, Nadav Israel, Daniel Benditkis, Liron Mor-Yosef, and Itai Zeitak1Neta Shoham, Tomer Avidor, Aviv Keren, Nadav Israel, Daniel Benditkis, Liron Mor-Yosef, and Itai Zeitak. Over- coming forgetting in federated learning on non-iid data. In NeurIPS Workshop, 2019. 1, 2\n\nFederated model distillation with noise-free differential privacy. Lichao Sun, Lingjuan Lyu, arXiv:2009.055376arXiv preprintLichao Sun and Lingjuan Lyu. Federated model distil- lation with noise-free differential privacy. arXiv preprint arXiv:2009.05537, 2020. 2, 5, 6\n\nData-free knowledge distillation for heterogeneous federated learning. Lichao Sun, Lingjuan Lyu, ICML. Lichao Sun and Lingjuan Lyu. Data-free knowledge distil- lation for heterogeneous federated learning. In ICML, 2021. 3\n\nGoing deeper with convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In CVPR, pages 1-9, 2015. 6\n\nPersonalized federated learning with moreau envelopes. T Canh, Nguyen Dinh, Josh Tran, Nguyen, NeurIPS. 1Canh T. Dinh, Nguyen Tran, and Josh Nguyen. Personal- ized federated learning with moreau envelopes. In NeurIPS, pages 21394-21405, 2020. 1, 2\n\nEfficientnet: Rethinking model scaling for convolutional neural networks. Mingxing Tan, Quoc Le, ICML. 36Mingxing Tan and Quoc Le. Efficientnet: Rethinking model scaling for convolutional neural networks. In ICML, pages 6105-6114, 2019. 3, 6\n\nUnderstanding self-supervised learning dynamics without contrastive pairs. Yuandong Tian, Xinlei Chen, Surya Ganguli, ICML. Yuandong Tian, Xinlei Chen, and Surya Ganguli. Un- derstanding self-supervised learning dynamics without con- trastive pairs. In ICML, 2021. 3\n\nNaftali Tishby, C Fernando, William Pereira, Bialek, The information bottleneck method. arXiv preprint physics/0004057. 34Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottleneck method. arXiv preprint physics/0004057, 2000. 3, 4\n\nThree scenarios for continual learning. M Gido, Andreas S Van De Ven, Tolias, arXiv:1904.07734arXiv preprintGido M Van de Ven and Andreas S Tolias. Three scenar- ios for continual learning. arXiv preprint arXiv:1904.07734, 2019. 3\n\nDeep hashing network for unsupervised domain adaptation. Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, Sethuraman Panchanathan, CVPR. 26Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, pages 5018- 5027, 2017. 2, 6\n\nNumerical Recipes: Example Book C (The Art of Scientific Computing). T William, Vetterling, H William, Press, A Saul, Brian P Teukolsky, Flannery, Press Syndicate of the University of CambridgeWilliam T Vetterling, William H Press, Saul A Teukolsky, and Brian P Flannery. Numerical Recipes: Example Book C (The Art of Scientific Computing). Press Syndicate of the University of Cambridge, 1992. 3\n\nThe eu general data protection regulation (gdpr). Paul Voigt, Axel Von, Bussche, Springer International Publishing3152676ChamA Practical Guide. 1st EdPaul Voigt and Axel Von dem Bussche. The eu general data protection regulation (gdpr). A Practical Guide, 1st Ed., Cham: Springer International Publishing, page 3152676, 2017. 1\n\nTraining networks in null space of feature covariance for continual learning. Shipeng Wang, Xiaorong Li, Jian Sun, Zongben Xu, CVPR. Shipeng Wang, Xiaorong Li, Jian Sun, and Zongben Xu. Training networks in null space of feature covariance for continual learning. In CVPR, pages 184-193, 2021. 3\n\nFbnet: Hardware-aware efficient convnet design via differentiable neural architecture search. Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, Kurt Keutzer, CVPR. Bichen Wu, Xiaoliang Dai, Peizhao Zhang, Yanghan Wang, Fei Sun, Yiming Wu, Yuandong Tian, Peter Vajda, Yangqing Jia, and Kurt Keutzer. Fbnet: Hardware-aware efficient con- vnet design via differentiable neural architecture search. In CVPR, pages 10734-10742, 2019. 2\n\nFashionmnist: A novel image dataset for benchmarking machine learning algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf, arXiv:1708.0774726arXiv preprintHan Xiao, Kashif Rasul, and Roland Vollgraf. Fashion- mnist: A novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017. 2, 6\n\n. Ming Xie, Guodong Long, Tao Shen, Tianyi Zhou, Xianzhi Wang, Jing Jiang, Chengqi Zhang, arXiv:2108.08647Multi-center federated learning. arXiv preprintMing Xie, Guodong Long, Tao Shen, Tianyi Zhou, Xianzhi Wang, Jing Jiang, and Chengqi Zhang. Multi-center feder- ated learning. arXiv preprint arXiv:2108.08647, 2021. 2\n\nFederated machine learning: Concept and applications. Qiang Yang, Yang Liu, Tianjian Chen, Yongxin Tong, ACM TIST. 1Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and applications. ACM TIST, pages 1-19, 2019. 1, 2\n\nUnsupervised embedding learning via invariant and spreading instance feature. Mang Ye, Xu Zhang, C Pong, Shih-Fu Yuen, Chang, CVPR. Mang Ye, Xu Zhang, Pong C Yuen, and Shih-Fu Chang. Un- supervised embedding learning via invariant and spreading instance feature. In CVPR, pages 6210-6219, 2019. 3\n\nBarlow twins: Self-supervised learning via redundancy reduction. Jure Zbontar, Li Jing, Ishan Misra, Yann Lecun, St\u00e9phane Deny, ICML. 67Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and St\u00e9phane Deny. Barlow twins: Self-supervised learning via redundancy reduction. In ICML, 2021. 2, 3, 4, 6, 7\n\nSpecialized federated learning using mixture of experts. John Edvin Listo Zec, Olof Martinsson, Leon Ren\u00e9 Mogren, Daniel S\u00fctfeld, Gillblad, arXiv:2010.02056arXiv preprintEdvin Listo Zec, John Martinsson, Olof Mogren, Leon Ren\u00e9 S\u00fctfeld, and Daniel Gillblad. Specialized federated learning using mixture of experts. arXiv preprint arXiv:2010.02056, 2020. 2\n\nFederated unsupervised representation learning. Fengda Zhang, Kun Kuang, Zhaoyang You, Tao Shen, Jun Xiao, Yin Zhang, Chao Wu, Yueting Zhuang, Xiaolin Li, arXiv:2010.08982arXiv preprintFengda Zhang, Kun Kuang, Zhaoyang You, Tao Shen, Jun Xiao, Yin Zhang, Chao Wu, Yueting Zhuang, and Xiaolin Li. Federated unsupervised representation learning. arXiv preprint arXiv:2010.08982, 2020. 3\n\nWhat makes instance discrimination good for transfer learning. Nanxuan Zhao, Zhirong Wu, W H Rynson, Stephen Lau, Lin, ICLR, 2021. Nanxuan Zhao, Zhirong Wu, Rynson WH Lau, and Stephen Lin. What makes instance discrimination good for transfer learning? In ICLR, 2021. 2\n\nFederated learning with non-iid data. Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, Vikas Chandra, arXiv:1806.00582arXiv preprintYue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582, 2018. 1\n", "annotations": {"author": "[{\"end\":312,\"start\":73},{\"end\":584,\"start\":313},{\"end\":854,\"start\":585}]", "publisher": null, "author_last_name": "[{\"end\":84,\"start\":79},{\"end\":320,\"start\":318},{\"end\":590,\"start\":588}]", "author_first_name": "[{\"end\":78,\"start\":73},{\"end\":317,\"start\":313},{\"end\":587,\"start\":585}]", "author_affiliation": "[{\"end\":311,\"start\":86},{\"end\":547,\"start\":322},{\"end\":583,\"start\":549},{\"end\":817,\"start\":592},{\"end\":853,\"start\":819}]", "title": "[{\"end\":70,\"start\":1},{\"end\":924,\"start\":855}]", "venue": null, "abstract": "[{\"end\":2197,\"start\":954}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2322,\"start\":2319},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":2325,\"start\":2322},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":2328,\"start\":2325},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":2528,\"start\":2524},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2648,\"start\":2644},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2651,\"start\":2648},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":2654,\"start\":2651},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":2657,\"start\":2654},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":2660,\"start\":2657},{\"end\":2737,\"start\":2729},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3274,\"start\":3270},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3277,\"start\":3274},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3280,\"start\":3277},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":3283,\"start\":3280},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":3286,\"start\":3283},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3392,\"start\":3388},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3395,\"start\":3392},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3593,\"start\":3589},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3596,\"start\":3593},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":3599,\"start\":3596},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3625,\"start\":3621},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3628,\"start\":3625},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":3631,\"start\":3628},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":3634,\"start\":3631},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3744,\"start\":3740},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":3834,\"start\":3830},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":3837,\"start\":3834},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":3840,\"start\":3837},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4156,\"start\":4152},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":4159,\"start\":4156},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4197,\"start\":4193},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4563,\"start\":4559},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":4566,\"start\":4563},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":4585,\"start\":4581},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":4588,\"start\":4585},{\"attributes\":{\"ref_id\":\"b91\"},\"end\":4591,\"start\":4588},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4615,\"start\":4611},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":4618,\"start\":4615},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":5550,\"start\":5546},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":5553,\"start\":5550},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":5785,\"start\":5781},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5887,\"start\":5883},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5890,\"start\":5887},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":5893,\"start\":5890},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":5896,\"start\":5893},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":5899,\"start\":5896},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6080,\"start\":6076},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":6083,\"start\":6080},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":6086,\"start\":6083},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":6089,\"start\":6086},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6516,\"start\":6513},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6518,\"start\":6516},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6521,\"start\":6518},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6524,\"start\":6521},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6527,\"start\":6524},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6530,\"start\":6527},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":6533,\"start\":6530},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":6536,\"start\":6533},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":6539,\"start\":6536},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7514,\"start\":7511},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7517,\"start\":7514},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8938,\"start\":8934},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":8941,\"start\":8938},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":8944,\"start\":8941},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":8947,\"start\":8944},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":8968,\"start\":8964},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9001,\"start\":8997},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":9004,\"start\":9001},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":9007,\"start\":9004},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":9295,\"start\":9291},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9418,\"start\":9414},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9421,\"start\":9418},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9424,\"start\":9421},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":9427,\"start\":9424},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":9430,\"start\":9427},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9539,\"start\":9535},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9896,\"start\":9892},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":9899,\"start\":9896},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9948,\"start\":9944},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10519,\"start\":10515},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10531,\"start\":10528},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":10544,\"start\":10540},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10634,\"start\":10631},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10637,\"start\":10634},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":10797,\"start\":10793},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10809,\"start\":10805},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":10825,\"start\":10821},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11051,\"start\":11048},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11054,\"start\":11051},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":11240,\"start\":11236},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":11259,\"start\":11255},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11903,\"start\":11900},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11913,\"start\":11910},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11916,\"start\":11913},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":12058,\"start\":12054},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":12061,\"start\":12058},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12111,\"start\":12107},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12124,\"start\":12121},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12259,\"start\":12256},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":12278,\"start\":12274},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":12371,\"start\":12367},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":12403,\"start\":12399},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":12508,\"start\":12504},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12519,\"start\":12515},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13148,\"start\":13144},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":13151,\"start\":13148},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":13238,\"start\":13234},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":13241,\"start\":13238},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13360,\"start\":13356},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13380,\"start\":13377},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":13383,\"start\":13380},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13418,\"start\":13414},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":13421,\"start\":13418},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":13424,\"start\":13421},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":13427,\"start\":13424},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":13464,\"start\":13460},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":13467,\"start\":13464},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":13470,\"start\":13467},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14986,\"start\":14982},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":15005,\"start\":15001},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15024,\"start\":15020},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15257,\"start\":15254},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":15260,\"start\":15257},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":15263,\"start\":15260},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":15283,\"start\":15279},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":16182,\"start\":16178},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":16185,\"start\":16182},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18658,\"start\":18654},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":18727,\"start\":18723},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":18837,\"start\":18833},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":18842,\"start\":18838},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":19471,\"start\":19467},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":19474,\"start\":19471},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":19477,\"start\":19474},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":19480,\"start\":19477},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20502,\"start\":20498},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24931,\"start\":24927},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":24934,\"start\":24931},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":24937,\"start\":24934},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":24940,\"start\":24937},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":25054,\"start\":25050},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":25057,\"start\":25054},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":25060,\"start\":25057},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":25063,\"start\":25060},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":25084,\"start\":25080},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":25130,\"start\":25126},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":25145,\"start\":25141},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":25168,\"start\":25164},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25714,\"start\":25710},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":25733,\"start\":25729},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25749,\"start\":25745},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":25768,\"start\":25764},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":25895,\"start\":25891},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":25905,\"start\":25901},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":25917,\"start\":25913},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":25928,\"start\":25924},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":25946,\"start\":25942},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":26790,\"start\":26786},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26851,\"start\":26847}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":32998,\"start\":32325},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33323,\"start\":32999},{\"attributes\":{\"id\":\"fig_2\"},\"end\":33688,\"start\":33324},{\"attributes\":{\"id\":\"fig_3\"},\"end\":34174,\"start\":33689},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":35242,\"start\":34175},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":35702,\"start\":35243},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36163,\"start\":35703},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":36694,\"start\":36164},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":37123,\"start\":36695}]", "paragraph": "[{\"end\":3287,\"start\":2213},{\"end\":5327,\"start\":3289},{\"end\":6426,\"start\":5329},{\"end\":7407,\"start\":6428},{\"end\":8167,\"start\":7409},{\"end\":8390,\"start\":8169},{\"end\":8639,\"start\":8392},{\"end\":8849,\"start\":8641},{\"end\":9163,\"start\":8851},{\"end\":10355,\"start\":9180},{\"end\":11583,\"start\":10357},{\"end\":12901,\"start\":11585},{\"end\":13950,\"start\":12903},{\"end\":14130,\"start\":13961},{\"end\":14541,\"start\":14187},{\"end\":14817,\"start\":14543},{\"end\":14841,\"start\":14819},{\"end\":15076,\"start\":14869},{\"end\":15531,\"start\":15078},{\"end\":16016,\"start\":15533},{\"end\":17232,\"start\":16057},{\"end\":17336,\"start\":17234},{\"end\":17672,\"start\":17369},{\"end\":18087,\"start\":17743},{\"end\":18611,\"start\":18150},{\"end\":19350,\"start\":18613},{\"end\":19913,\"start\":19383},{\"end\":20010,\"start\":19960},{\"end\":20917,\"start\":20083},{\"end\":21431,\"start\":21071},{\"end\":21524,\"start\":21462},{\"end\":22235,\"start\":21591},{\"end\":23457,\"start\":23069},{\"end\":23848,\"start\":23497},{\"end\":24941,\"start\":23878},{\"end\":25510,\"start\":24957},{\"end\":25792,\"start\":25512},{\"end\":26161,\"start\":25794},{\"end\":27755,\"start\":26163},{\"end\":28160,\"start\":27963},{\"end\":28745,\"start\":28162},{\"end\":29381,\"start\":28747},{\"end\":29882,\"start\":29383},{\"end\":30205,\"start\":29884},{\"end\":30550,\"start\":30296},{\"end\":31009,\"start\":30552},{\"end\":31736,\"start\":31011},{\"end\":32324,\"start\":31751}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14186,\"start\":14131},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14868,\"start\":14842},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17368,\"start\":17337},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17742,\"start\":17673},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18149,\"start\":18088},{\"attributes\":{\"id\":\"formula_5\"},\"end\":19959,\"start\":19914},{\"attributes\":{\"id\":\"formula_6\"},\"end\":20082,\"start\":20011},{\"attributes\":{\"id\":\"formula_7\"},\"end\":21001,\"start\":20918},{\"attributes\":{\"id\":\"formula_8\"},\"end\":21070,\"start\":21001},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21461,\"start\":21432},{\"attributes\":{\"id\":\"formula_10\"},\"end\":21590,\"start\":21525},{\"attributes\":{\"id\":\"formula_11\"},\"end\":22273,\"start\":22236},{\"attributes\":{\"id\":\"formula_12\"},\"end\":23068,\"start\":22273},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23496,\"start\":23458},{\"attributes\":{\"id\":\"formula_14\"},\"end\":27830,\"start\":27756},{\"attributes\":{\"id\":\"formula_15\"},\"end\":27919,\"start\":27830},{\"attributes\":{\"id\":\"formula_16\"},\"end\":30270,\"start\":30242}]", "table_ref": "[{\"end\":29715,\"start\":29708},{\"end\":30103,\"start\":30096}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2211,\"start\":2199},{\"attributes\":{\"n\":\"2.\"},\"end\":9178,\"start\":9166},{\"attributes\":{\"n\":\"3.\"},\"end\":13959,\"start\":13953},{\"attributes\":{\"n\":\"3.1.\"},\"end\":16055,\"start\":16019},{\"attributes\":{\"n\":\"3.2.\"},\"end\":19381,\"start\":19353},{\"attributes\":{\"n\":\"3.3.\"},\"end\":23876,\"start\":23851},{\"attributes\":{\"n\":\"4.\"},\"end\":24955,\"start\":24944},{\"attributes\":{\"n\":\"4.1.\"},\"end\":27961,\"start\":27921},{\"end\":30241,\"start\":30208},{\"attributes\":{\"n\":\"4.2.\"},\"end\":30294,\"start\":30272},{\"attributes\":{\"n\":\"5.\"},\"end\":31749,\"start\":31739},{\"end\":32336,\"start\":32326},{\"end\":33010,\"start\":33000},{\"end\":33335,\"start\":33325},{\"end\":33700,\"start\":33690}]", "table": "[{\"end\":35242,\"start\":34229},{\"end\":35702,\"start\":35645},{\"end\":36163,\"start\":35986},{\"end\":36694,\"start\":36463},{\"end\":37123,\"start\":36874}]", "figure_caption": "[{\"end\":32998,\"start\":32338},{\"end\":33323,\"start\":33012},{\"end\":33688,\"start\":33337},{\"end\":34174,\"start\":33702},{\"end\":34229,\"start\":34177},{\"end\":35645,\"start\":35245},{\"end\":35986,\"start\":35705},{\"end\":36463,\"start\":36166},{\"end\":36874,\"start\":36697}]", "figure_ref": "[{\"end\":6425,\"start\":6419},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8340,\"start\":8334},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15608,\"start\":15602},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19349,\"start\":19343},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23549,\"start\":23543},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":28480,\"start\":28474},{\"end\":29098,\"start\":29091},{\"end\":29142,\"start\":29135},{\"end\":29936,\"start\":29928},{\"end\":30767,\"start\":30761},{\"end\":31146,\"start\":31140},{\"end\":31363,\"start\":31357},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":31458,\"start\":31452}]", "bib_author_first_name": "[{\"end\":37200,\"start\":37194},{\"end\":37212,\"start\":37207},{\"end\":37227,\"start\":37218},{\"end\":37241,\"start\":37233},{\"end\":37254,\"start\":37246},{\"end\":37470,\"start\":37462},{\"end\":37484,\"start\":37480},{\"end\":37503,\"start\":37494},{\"end\":37726,\"start\":37723},{\"end\":37738,\"start\":37732},{\"end\":37747,\"start\":37744},{\"end\":37759,\"start\":37753},{\"end\":37770,\"start\":37765},{\"end\":37781,\"start\":37778},{\"end\":38084,\"start\":38077},{\"end\":38097,\"start\":38092},{\"end\":38114,\"start\":38110},{\"end\":38127,\"start\":38123},{\"end\":38447,\"start\":38443},{\"end\":38459,\"start\":38454},{\"end\":38479,\"start\":38471},{\"end\":38497,\"start\":38489},{\"end\":38748,\"start\":38742},{\"end\":38762,\"start\":38755},{\"end\":38969,\"start\":38963},{\"end\":38977,\"start\":38976},{\"end\":38987,\"start\":38980},{\"end\":38994,\"start\":38993},{\"end\":39004,\"start\":38997},{\"end\":39216,\"start\":39210},{\"end\":39232,\"start\":39225},{\"end\":39249,\"start\":39240},{\"end\":39261,\"start\":39257},{\"end\":39277,\"start\":39271},{\"end\":39296,\"start\":39289},{\"end\":39310,\"start\":39307},{\"end\":39325,\"start\":39319},{\"end\":39337,\"start\":39332},{\"end\":39635,\"start\":39620},{\"end\":39646,\"start\":39642},{\"end\":39648,\"start\":39647},{\"end\":39661,\"start\":39657},{\"end\":39676,\"start\":39670},{\"end\":39678,\"start\":39677},{\"end\":40025,\"start\":40017},{\"end\":40040,\"start\":40035},{\"end\":40054,\"start\":40050},{\"end\":40068,\"start\":40063},{\"end\":40080,\"start\":40078},{\"end\":40397,\"start\":40393},{\"end\":40414,\"start\":40407},{\"end\":40428,\"start\":40422},{\"end\":40430,\"start\":40429},{\"end\":40667,\"start\":40661},{\"end\":40678,\"start\":40674},{\"end\":40867,\"start\":40861},{\"end\":40883,\"start\":40877},{\"end\":40898,\"start\":40892},{\"end\":40909,\"start\":40904},{\"end\":40929,\"start\":40921},{\"end\":40943,\"start\":40936},{\"end\":41224,\"start\":41223},{\"end\":41235,\"start\":41230},{\"end\":41250,\"start\":41248},{\"end\":41263,\"start\":41258},{\"end\":41276,\"start\":41270},{\"end\":41616,\"start\":41604},{\"end\":41631,\"start\":41624},{\"end\":41646,\"start\":41639},{\"end\":41663,\"start\":41655},{\"end\":41673,\"start\":41672},{\"end\":41687,\"start\":41682},{\"end\":41703,\"start\":41699},{\"end\":41725,\"start\":41717},{\"end\":41742,\"start\":41735},{\"end\":41749,\"start\":41743},{\"end\":41771,\"start\":41763},{\"end\":41782,\"start\":41772},{\"end\":42196,\"start\":42192},{\"end\":42238,\"start\":42237},{\"end\":42547,\"start\":42545},{\"end\":42560,\"start\":42553},{\"end\":42572,\"start\":42567},{\"end\":42585,\"start\":42579},{\"end\":42597,\"start\":42590},{\"end\":42850,\"start\":42846},{\"end\":42865,\"start\":42860},{\"end\":42878,\"start\":42874},{\"end\":43089,\"start\":43083},{\"end\":43104,\"start\":43096},{\"end\":43115,\"start\":43110},{\"end\":43132,\"start\":43125},{\"end\":43153,\"start\":43144},{\"end\":43168,\"start\":43164},{\"end\":43187,\"start\":43181},{\"end\":43202,\"start\":43197},{\"end\":43217,\"start\":43211},{\"end\":43570,\"start\":43562},{\"end\":43581,\"start\":43575},{\"end\":43599,\"start\":43593},{\"end\":43882,\"start\":43874},{\"end\":43893,\"start\":43887},{\"end\":43911,\"start\":43905},{\"end\":44177,\"start\":44170},{\"end\":44187,\"start\":44182},{\"end\":44198,\"start\":44193},{\"end\":44210,\"start\":44203},{\"end\":44220,\"start\":44216},{\"end\":44463,\"start\":44456},{\"end\":44475,\"start\":44468},{\"end\":44491,\"start\":44483},{\"end\":44501,\"start\":44497},{\"end\":44660,\"start\":44652},{\"end\":44674,\"start\":44669},{\"end\":44688,\"start\":44684},{\"end\":44982,\"start\":44974},{\"end\":44989,\"start\":44983},{\"end\":45163,\"start\":45162},{\"end\":45180,\"start\":45172},{\"end\":45191,\"start\":45189},{\"end\":45203,\"start\":45197},{\"end\":45216,\"start\":45210},{\"end\":45237,\"start\":45231},{\"end\":45249,\"start\":45244},{\"end\":45265,\"start\":45258},{\"end\":45718,\"start\":45710},{\"end\":45720,\"start\":45719},{\"end\":45945,\"start\":45938},{\"end\":45960,\"start\":45953},{\"end\":45972,\"start\":45967},{\"end\":45983,\"start\":45979},{\"end\":45986,\"start\":45984},{\"end\":46290,\"start\":46288},{\"end\":46301,\"start\":46295},{\"end\":46314,\"start\":46308},{\"end\":46327,\"start\":46320},{\"end\":46335,\"start\":46333},{\"end\":46346,\"start\":46342},{\"end\":46360,\"start\":46352},{\"end\":46373,\"start\":46365},{\"end\":46386,\"start\":46380},{\"end\":46400,\"start\":46394},{\"end\":46716,\"start\":46711},{\"end\":46733,\"start\":46726},{\"end\":46750,\"start\":46743},{\"end\":46766,\"start\":46758},{\"end\":46780,\"start\":46775},{\"end\":46794,\"start\":46789},{\"end\":46800,\"start\":46795},{\"end\":46818,\"start\":46810},{\"end\":46836,\"start\":46829},{\"end\":46852,\"start\":46846},{\"end\":47288,\"start\":47287},{\"end\":47304,\"start\":47299},{\"end\":47559,\"start\":47554},{\"end\":47579,\"start\":47573},{\"end\":47593,\"start\":47589},{\"end\":47610,\"start\":47606},{\"end\":47628,\"start\":47619},{\"end\":47647,\"start\":47641},{\"end\":47649,\"start\":47648},{\"end\":47662,\"start\":47656},{\"end\":47674,\"start\":47670},{\"end\":47686,\"start\":47681},{\"end\":48054,\"start\":48049},{\"end\":48071,\"start\":48064},{\"end\":48087,\"start\":48081},{\"end\":48101,\"start\":48096},{\"end\":48414,\"start\":48409},{\"end\":48431,\"start\":48424},{\"end\":48442,\"start\":48441},{\"end\":48455,\"start\":48450},{\"end\":48466,\"start\":48460},{\"end\":48482,\"start\":48478},{\"end\":48813,\"start\":48812},{\"end\":48827,\"start\":48826},{\"end\":49113,\"start\":49106},{\"end\":49125,\"start\":49124},{\"end\":49371,\"start\":49367},{\"end\":49383,\"start\":49379},{\"end\":49398,\"start\":49392},{\"end\":49414,\"start\":49407},{\"end\":49703,\"start\":49696},{\"end\":49713,\"start\":49708},{\"end\":49950,\"start\":49944},{\"end\":49960,\"start\":49955},{\"end\":49971,\"start\":49967},{\"end\":49987,\"start\":49978},{\"end\":50261,\"start\":50255},{\"end\":50275,\"start\":50266},{\"end\":50284,\"start\":50280},{\"end\":50518,\"start\":50512},{\"end\":50532,\"start\":50523},{\"end\":50541,\"start\":50537},{\"end\":50744,\"start\":50740},{\"end\":50753,\"start\":50749},{\"end\":50771,\"start\":50766},{\"end\":50791,\"start\":50783},{\"end\":51023,\"start\":51019},{\"end\":51032,\"start\":51028},{\"end\":51051,\"start\":51045},{\"end\":51066,\"start\":51060},{\"end\":51081,\"start\":51076},{\"end\":51101,\"start\":51093},{\"end\":51334,\"start\":51331},{\"end\":51344,\"start\":51339},{\"end\":51354,\"start\":51351},{\"end\":51366,\"start\":51359},{\"end\":51381,\"start\":51378},{\"end\":51784,\"start\":51776},{\"end\":51795,\"start\":51789},{\"end\":51805,\"start\":51800},{\"end\":51816,\"start\":51815},{\"end\":51833,\"start\":51827},{\"end\":51848,\"start\":51841},{\"end\":52197,\"start\":52189},{\"end\":52208,\"start\":52202},{\"end\":52223,\"start\":52216},{\"end\":52238,\"start\":52231},{\"end\":52247,\"start\":52245},{\"end\":52465,\"start\":52457},{\"end\":52475,\"start\":52470},{\"end\":52687,\"start\":52679},{\"end\":52706,\"start\":52703},{\"end\":52724,\"start\":52719},{\"end\":52726,\"start\":52725},{\"end\":52750,\"start\":52745},{\"end\":52767,\"start\":52761},{\"end\":52789,\"start\":52775},{\"end\":53151,\"start\":53145},{\"end\":53167,\"start\":53158},{\"end\":53178,\"start\":53177},{\"end\":53194,\"start\":53188},{\"end\":53445,\"start\":53442},{\"end\":53459,\"start\":53451},{\"end\":53467,\"start\":53466},{\"end\":53485,\"start\":53479},{\"end\":53749,\"start\":53741},{\"end\":53762,\"start\":53755},{\"end\":53775,\"start\":53770},{\"end\":53791,\"start\":53786},{\"end\":53804,\"start\":53798},{\"end\":53817,\"start\":53813},{\"end\":53832,\"start\":53827},{\"end\":53851,\"start\":53841},{\"end\":54200,\"start\":54194},{\"end\":54211,\"start\":54206},{\"end\":54222,\"start\":54218},{\"end\":54230,\"start\":54228},{\"end\":54245,\"start\":54236},{\"end\":54574,\"start\":54568},{\"end\":54584,\"start\":54580},{\"end\":54597,\"start\":54593},{\"end\":54612,\"start\":54607},{\"end\":54628,\"start\":54621},{\"end\":54630,\"start\":54629},{\"end\":54645,\"start\":54639},{\"end\":54647,\"start\":54646},{\"end\":54979,\"start\":54975},{\"end\":54989,\"start\":54985},{\"end\":55000,\"start\":54997},{\"end\":55008,\"start\":55006},{\"end\":55022,\"start\":55016},{\"end\":55036,\"start\":55028},{\"end\":55048,\"start\":55043},{\"end\":55063,\"start\":55055},{\"end\":55073,\"start\":55070},{\"end\":55083,\"start\":55078},{\"end\":55414,\"start\":55410},{\"end\":55431,\"start\":55423},{\"end\":55688,\"start\":55677},{\"end\":55695,\"start\":55694},{\"end\":55931,\"start\":55924},{\"end\":55944,\"start\":55943},{\"end\":56291,\"start\":56284},{\"end\":56306,\"start\":56301},{\"end\":56320,\"start\":56314},{\"end\":56333,\"start\":56329},{\"end\":56349,\"start\":56343},{\"end\":56721,\"start\":56715},{\"end\":56738,\"start\":56732},{\"end\":56947,\"start\":56946},{\"end\":56958,\"start\":56954},{\"end\":56979,\"start\":56974},{\"end\":57006,\"start\":57005},{\"end\":57024,\"start\":57015},{\"end\":57289,\"start\":57284},{\"end\":57303,\"start\":57299},{\"end\":57527,\"start\":57522},{\"end\":57539,\"start\":57536},{\"end\":57550,\"start\":57546},{\"end\":57569,\"start\":57559},{\"end\":57582,\"start\":57580},{\"end\":57595,\"start\":57587},{\"end\":57884,\"start\":57874},{\"end\":57908,\"start\":57901},{\"end\":57921,\"start\":57918},{\"end\":57932,\"start\":57927},{\"end\":57949,\"start\":57942},{\"end\":58244,\"start\":58239},{\"end\":58433,\"start\":58425},{\"end\":58445,\"start\":58440},{\"end\":58458,\"start\":58453},{\"end\":58468,\"start\":58464},{\"end\":58644,\"start\":58637},{\"end\":58671,\"start\":58664},{\"end\":58683,\"start\":58682},{\"end\":58695,\"start\":58690},{\"end\":58940,\"start\":58931},{\"end\":58972,\"start\":58967},{\"end\":58994,\"start\":58985},{\"end\":58996,\"start\":58995},{\"end\":59207,\"start\":59201},{\"end\":59222,\"start\":59213},{\"end\":59544,\"start\":59540},{\"end\":59561,\"start\":59558},{\"end\":59571,\"start\":59568},{\"end\":59584,\"start\":59576},{\"end\":59600,\"start\":59593},{\"end\":59615,\"start\":59611},{\"end\":59627,\"start\":59620},{\"end\":59641,\"start\":59635},{\"end\":59658,\"start\":59652},{\"end\":59674,\"start\":59667},{\"end\":59695,\"start\":59686},{\"end\":59697,\"start\":59696},{\"end\":59706,\"start\":59704},{\"end\":60046,\"start\":60045},{\"end\":60062,\"start\":60061},{\"end\":60078,\"start\":60069},{\"end\":60097,\"start\":60091},{\"end\":60115,\"start\":60110},{\"end\":60128,\"start\":60123},{\"end\":60470,\"start\":60465},{\"end\":60486,\"start\":60480},{\"end\":60500,\"start\":60495},{\"end\":60518,\"start\":60510},{\"end\":60793,\"start\":60790},{\"end\":60803,\"start\":60800},{\"end\":60818,\"start\":60811},{\"end\":60830,\"start\":60824},{\"end\":60842,\"start\":60838},{\"end\":60853,\"start\":60850},{\"end\":60863,\"start\":60860},{\"end\":60874,\"start\":60871},{\"end\":60883,\"start\":60879},{\"end\":61561,\"start\":61555},{\"end\":61575,\"start\":61567},{\"end\":61835,\"start\":61829},{\"end\":61849,\"start\":61841},{\"end\":62022,\"start\":62013},{\"end\":62035,\"start\":62032},{\"end\":62049,\"start\":62041},{\"end\":62061,\"start\":62055},{\"end\":62077,\"start\":62072},{\"end\":62092,\"start\":62084},{\"end\":62110,\"start\":62103},{\"end\":62125,\"start\":62118},{\"end\":62143,\"start\":62137},{\"end\":62426,\"start\":62425},{\"end\":62439,\"start\":62433},{\"end\":62450,\"start\":62446},{\"end\":62701,\"start\":62693},{\"end\":62711,\"start\":62707},{\"end\":62945,\"start\":62937},{\"end\":62958,\"start\":62952},{\"end\":62970,\"start\":62965},{\"end\":63137,\"start\":63130},{\"end\":63147,\"start\":63146},{\"end\":63165,\"start\":63158},{\"end\":63428,\"start\":63427},{\"end\":63442,\"start\":63435},{\"end\":63444,\"start\":63443},{\"end\":63683,\"start\":63676},{\"end\":63702,\"start\":63698},{\"end\":63718,\"start\":63712},{\"end\":63742,\"start\":63732},{\"end\":64016,\"start\":64015},{\"end\":64039,\"start\":64038},{\"end\":64057,\"start\":64056},{\"end\":64069,\"start\":64064},{\"end\":64071,\"start\":64070},{\"end\":64398,\"start\":64394},{\"end\":64410,\"start\":64406},{\"end\":64758,\"start\":64751},{\"end\":64773,\"start\":64765},{\"end\":64782,\"start\":64778},{\"end\":64795,\"start\":64788},{\"end\":65070,\"start\":65064},{\"end\":65084,\"start\":65075},{\"end\":65097,\"start\":65090},{\"end\":65112,\"start\":65105},{\"end\":65122,\"start\":65119},{\"end\":65134,\"start\":65128},{\"end\":65147,\"start\":65139},{\"end\":65159,\"start\":65154},{\"end\":65175,\"start\":65167},{\"end\":65185,\"start\":65181},{\"end\":65554,\"start\":65551},{\"end\":65567,\"start\":65561},{\"end\":65581,\"start\":65575},{\"end\":65804,\"start\":65800},{\"end\":65817,\"start\":65810},{\"end\":65827,\"start\":65824},{\"end\":65840,\"start\":65834},{\"end\":65854,\"start\":65847},{\"end\":65865,\"start\":65861},{\"end\":65880,\"start\":65873},{\"end\":66179,\"start\":66174},{\"end\":66190,\"start\":66186},{\"end\":66204,\"start\":66196},{\"end\":66218,\"start\":66211},{\"end\":66461,\"start\":66457},{\"end\":66468,\"start\":66466},{\"end\":66477,\"start\":66476},{\"end\":66491,\"start\":66484},{\"end\":66746,\"start\":66742},{\"end\":66758,\"start\":66756},{\"end\":66770,\"start\":66765},{\"end\":66782,\"start\":66778},{\"end\":66798,\"start\":66790},{\"end\":67036,\"start\":67032},{\"end\":67058,\"start\":67054},{\"end\":67075,\"start\":67071},{\"end\":67080,\"start\":67076},{\"end\":67095,\"start\":67089},{\"end\":67385,\"start\":67379},{\"end\":67396,\"start\":67393},{\"end\":67412,\"start\":67404},{\"end\":67421,\"start\":67418},{\"end\":67431,\"start\":67428},{\"end\":67441,\"start\":67438},{\"end\":67453,\"start\":67449},{\"end\":67465,\"start\":67458},{\"end\":67481,\"start\":67474},{\"end\":67787,\"start\":67780},{\"end\":67801,\"start\":67794},{\"end\":67807,\"start\":67806},{\"end\":67809,\"start\":67808},{\"end\":67825,\"start\":67818},{\"end\":68028,\"start\":68025},{\"end\":68039,\"start\":68035},{\"end\":68053,\"start\":68044},{\"end\":68065,\"start\":68059},{\"end\":68077,\"start\":68072},{\"end\":68090,\"start\":68085}]", "bib_author_last_name": "[{\"end\":37205,\"start\":37201},{\"end\":37216,\"start\":37213},{\"end\":37231,\"start\":37228},{\"end\":37244,\"start\":37242},{\"end\":37259,\"start\":37255},{\"end\":37478,\"start\":37471},{\"end\":37492,\"start\":37485},{\"end\":37519,\"start\":37504},{\"end\":37730,\"start\":37727},{\"end\":37742,\"start\":37739},{\"end\":37751,\"start\":37748},{\"end\":37763,\"start\":37760},{\"end\":37776,\"start\":37771},{\"end\":37784,\"start\":37782},{\"end\":38090,\"start\":38085},{\"end\":38108,\"start\":38098},{\"end\":38121,\"start\":38115},{\"end\":38138,\"start\":38128},{\"end\":38452,\"start\":38448},{\"end\":38469,\"start\":38460},{\"end\":38487,\"start\":38480},{\"end\":38504,\"start\":38498},{\"end\":38753,\"start\":38749},{\"end\":38765,\"start\":38763},{\"end\":38974,\"start\":38970},{\"end\":38991,\"start\":38988},{\"end\":39007,\"start\":39005},{\"end\":39223,\"start\":39217},{\"end\":39238,\"start\":39233},{\"end\":39255,\"start\":39250},{\"end\":39269,\"start\":39262},{\"end\":39287,\"start\":39278},{\"end\":39305,\"start\":39297},{\"end\":39317,\"start\":39311},{\"end\":39330,\"start\":39326},{\"end\":39345,\"start\":39338},{\"end\":39640,\"start\":39636},{\"end\":39655,\"start\":39649},{\"end\":39668,\"start\":39662},{\"end\":39689,\"start\":39679},{\"end\":40033,\"start\":40026},{\"end\":40048,\"start\":40041},{\"end\":40061,\"start\":40055},{\"end\":40076,\"start\":40069},{\"end\":40084,\"start\":40081},{\"end\":40405,\"start\":40398},{\"end\":40420,\"start\":40415},{\"end\":40436,\"start\":40431},{\"end\":40672,\"start\":40668},{\"end\":40681,\"start\":40679},{\"end\":40875,\"start\":40868},{\"end\":40890,\"start\":40884},{\"end\":40902,\"start\":40899},{\"end\":40919,\"start\":40910},{\"end\":40934,\"start\":40930},{\"end\":40949,\"start\":40944},{\"end\":41228,\"start\":41225},{\"end\":41246,\"start\":41236},{\"end\":41256,\"start\":41251},{\"end\":41268,\"start\":41264},{\"end\":41286,\"start\":41277},{\"end\":41294,\"start\":41288},{\"end\":41622,\"start\":41617},{\"end\":41637,\"start\":41632},{\"end\":41653,\"start\":41647},{\"end\":41670,\"start\":41664},{\"end\":41680,\"start\":41674},{\"end\":41697,\"start\":41688},{\"end\":41715,\"start\":41704},{\"end\":41733,\"start\":41726},{\"end\":41761,\"start\":41750},{\"end\":41786,\"start\":41783},{\"end\":41792,\"start\":41788},{\"end\":42218,\"start\":42197},{\"end\":42235,\"start\":42220},{\"end\":42247,\"start\":42239},{\"end\":42255,\"start\":42249},{\"end\":42551,\"start\":42548},{\"end\":42565,\"start\":42561},{\"end\":42577,\"start\":42573},{\"end\":42588,\"start\":42586},{\"end\":42602,\"start\":42598},{\"end\":42858,\"start\":42851},{\"end\":42872,\"start\":42866},{\"end\":42884,\"start\":42879},{\"end\":43094,\"start\":43090},{\"end\":43108,\"start\":43105},{\"end\":43123,\"start\":43116},{\"end\":43142,\"start\":43133},{\"end\":43162,\"start\":43154},{\"end\":43179,\"start\":43169},{\"end\":43195,\"start\":43188},{\"end\":43209,\"start\":43203},{\"end\":43224,\"start\":43218},{\"end\":43573,\"start\":43571},{\"end\":43591,\"start\":43582},{\"end\":43610,\"start\":43600},{\"end\":43885,\"start\":43883},{\"end\":43903,\"start\":43894},{\"end\":43922,\"start\":43912},{\"end\":44180,\"start\":44178},{\"end\":44191,\"start\":44188},{\"end\":44201,\"start\":44199},{\"end\":44214,\"start\":44211},{\"end\":44229,\"start\":44221},{\"end\":44466,\"start\":44464},{\"end\":44481,\"start\":44476},{\"end\":44495,\"start\":44492},{\"end\":44505,\"start\":44502},{\"end\":44667,\"start\":44661},{\"end\":44682,\"start\":44675},{\"end\":44693,\"start\":44689},{\"end\":45007,\"start\":44990},{\"end\":45018,\"start\":45009},{\"end\":45170,\"start\":45164},{\"end\":45187,\"start\":45181},{\"end\":45195,\"start\":45192},{\"end\":45208,\"start\":45204},{\"end\":45229,\"start\":45217},{\"end\":45242,\"start\":45238},{\"end\":45256,\"start\":45250},{\"end\":45275,\"start\":45266},{\"end\":45281,\"start\":45277},{\"end\":45725,\"start\":45721},{\"end\":45951,\"start\":45946},{\"end\":45965,\"start\":45961},{\"end\":45977,\"start\":45973},{\"end\":45992,\"start\":45987},{\"end\":46293,\"start\":46291},{\"end\":46306,\"start\":46302},{\"end\":46318,\"start\":46315},{\"end\":46331,\"start\":46328},{\"end\":46340,\"start\":46336},{\"end\":46350,\"start\":46347},{\"end\":46363,\"start\":46361},{\"end\":46378,\"start\":46374},{\"end\":46392,\"start\":46387},{\"end\":46404,\"start\":46401},{\"end\":46724,\"start\":46717},{\"end\":46741,\"start\":46734},{\"end\":46756,\"start\":46751},{\"end\":46773,\"start\":46767},{\"end\":46787,\"start\":46781},{\"end\":46808,\"start\":46801},{\"end\":46827,\"start\":46819},{\"end\":46844,\"start\":46837},{\"end\":46860,\"start\":46853},{\"end\":47297,\"start\":47289},{\"end\":47311,\"start\":47305},{\"end\":47315,\"start\":47313},{\"end\":47571,\"start\":47560},{\"end\":47587,\"start\":47580},{\"end\":47604,\"start\":47594},{\"end\":47617,\"start\":47611},{\"end\":47639,\"start\":47629},{\"end\":47654,\"start\":47650},{\"end\":47668,\"start\":47663},{\"end\":47679,\"start\":47675},{\"end\":47694,\"start\":47687},{\"end\":48062,\"start\":48055},{\"end\":48079,\"start\":48072},{\"end\":48094,\"start\":48088},{\"end\":48111,\"start\":48102},{\"end\":48422,\"start\":48415},{\"end\":48439,\"start\":48432},{\"end\":48448,\"start\":48443},{\"end\":48458,\"start\":48456},{\"end\":48476,\"start\":48467},{\"end\":48498,\"start\":48483},{\"end\":48505,\"start\":48500},{\"end\":48824,\"start\":48814},{\"end\":48834,\"start\":48828},{\"end\":49122,\"start\":49114},{\"end\":49133,\"start\":49126},{\"end\":49142,\"start\":49135},{\"end\":49377,\"start\":49372},{\"end\":49390,\"start\":49384},{\"end\":49405,\"start\":49399},{\"end\":49422,\"start\":49415},{\"end\":49706,\"start\":49704},{\"end\":49718,\"start\":49714},{\"end\":49953,\"start\":49951},{\"end\":49965,\"start\":49961},{\"end\":49976,\"start\":49972},{\"end\":49990,\"start\":49988},{\"end\":50264,\"start\":50262},{\"end\":50278,\"start\":50276},{\"end\":50289,\"start\":50285},{\"end\":50521,\"start\":50519},{\"end\":50535,\"start\":50533},{\"end\":50546,\"start\":50542},{\"end\":50747,\"start\":50745},{\"end\":50764,\"start\":50754},{\"end\":50781,\"start\":50772},{\"end\":50797,\"start\":50792},{\"end\":51026,\"start\":51024},{\"end\":51043,\"start\":51033},{\"end\":51058,\"start\":51052},{\"end\":51074,\"start\":51067},{\"end\":51091,\"start\":51082},{\"end\":51107,\"start\":51102},{\"end\":51337,\"start\":51335},{\"end\":51349,\"start\":51345},{\"end\":51357,\"start\":51355},{\"end\":51376,\"start\":51367},{\"end\":51390,\"start\":51382},{\"end\":51787,\"start\":51785},{\"end\":51798,\"start\":51796},{\"end\":51813,\"start\":51806},{\"end\":51825,\"start\":51817},{\"end\":51839,\"start\":51834},{\"end\":51856,\"start\":51849},{\"end\":51864,\"start\":51858},{\"end\":52200,\"start\":52198},{\"end\":52214,\"start\":52209},{\"end\":52229,\"start\":52224},{\"end\":52243,\"start\":52239},{\"end\":52251,\"start\":52248},{\"end\":52468,\"start\":52466},{\"end\":52481,\"start\":52476},{\"end\":52701,\"start\":52688},{\"end\":52710,\"start\":52707},{\"end\":52717,\"start\":52712},{\"end\":52743,\"start\":52727},{\"end\":52759,\"start\":52751},{\"end\":52773,\"start\":52768},{\"end\":52803,\"start\":52790},{\"end\":52812,\"start\":52805},{\"end\":53156,\"start\":53152},{\"end\":53175,\"start\":53168},{\"end\":53186,\"start\":53179},{\"end\":53200,\"start\":53195},{\"end\":53209,\"start\":53202},{\"end\":53449,\"start\":53446},{\"end\":53464,\"start\":53460},{\"end\":53477,\"start\":53468},{\"end\":53491,\"start\":53486},{\"end\":53498,\"start\":53493},{\"end\":53753,\"start\":53750},{\"end\":53768,\"start\":53763},{\"end\":53784,\"start\":53776},{\"end\":53796,\"start\":53792},{\"end\":53811,\"start\":53805},{\"end\":53825,\"start\":53818},{\"end\":53839,\"start\":53833},{\"end\":53859,\"start\":53852},{\"end\":54204,\"start\":54201},{\"end\":54216,\"start\":54212},{\"end\":54226,\"start\":54223},{\"end\":54234,\"start\":54231},{\"end\":54250,\"start\":54246},{\"end\":54578,\"start\":54575},{\"end\":54591,\"start\":54585},{\"end\":54605,\"start\":54598},{\"end\":54619,\"start\":54613},{\"end\":54637,\"start\":54631},{\"end\":54653,\"start\":54648},{\"end\":54663,\"start\":54655},{\"end\":54983,\"start\":54980},{\"end\":54995,\"start\":54990},{\"end\":55004,\"start\":55001},{\"end\":55014,\"start\":55009},{\"end\":55026,\"start\":55023},{\"end\":55041,\"start\":55037},{\"end\":55053,\"start\":55049},{\"end\":55068,\"start\":55064},{\"end\":55076,\"start\":55074},{\"end\":55088,\"start\":55084},{\"end\":55421,\"start\":55415},{\"end\":55440,\"start\":55432},{\"end\":55692,\"start\":55689},{\"end\":55701,\"start\":55696},{\"end\":55707,\"start\":55703},{\"end\":55941,\"start\":55932},{\"end\":55949,\"start\":55945},{\"end\":55956,\"start\":55951},{\"end\":56299,\"start\":56292},{\"end\":56312,\"start\":56307},{\"end\":56327,\"start\":56321},{\"end\":56341,\"start\":56334},{\"end\":56364,\"start\":56350},{\"end\":56730,\"start\":56722},{\"end\":56744,\"start\":56739},{\"end\":56952,\"start\":56948},{\"end\":56972,\"start\":56959},{\"end\":56986,\"start\":56980},{\"end\":57003,\"start\":56988},{\"end\":57013,\"start\":57007},{\"end\":57031,\"start\":57025},{\"end\":57040,\"start\":57033},{\"end\":57297,\"start\":57290},{\"end\":57315,\"start\":57304},{\"end\":57534,\"start\":57528},{\"end\":57544,\"start\":57540},{\"end\":57557,\"start\":57551},{\"end\":57578,\"start\":57570},{\"end\":57585,\"start\":57583},{\"end\":57598,\"start\":57596},{\"end\":57899,\"start\":57885},{\"end\":57916,\"start\":57909},{\"end\":57925,\"start\":57922},{\"end\":57940,\"start\":57933},{\"end\":57959,\"start\":57950},{\"end\":57967,\"start\":57961},{\"end\":58261,\"start\":58245},{\"end\":58267,\"start\":58263},{\"end\":58438,\"start\":58434},{\"end\":58451,\"start\":58446},{\"end\":58462,\"start\":58459},{\"end\":58475,\"start\":58469},{\"end\":58662,\"start\":58645},{\"end\":58680,\"start\":58672},{\"end\":58688,\"start\":58684},{\"end\":58704,\"start\":58696},{\"end\":58718,\"start\":58706},{\"end\":58965,\"start\":58941},{\"end\":58983,\"start\":58973},{\"end\":59002,\"start\":58997},{\"end\":59011,\"start\":59004},{\"end\":59211,\"start\":59208},{\"end\":59228,\"start\":59223},{\"end\":59556,\"start\":59545},{\"end\":59566,\"start\":59562},{\"end\":59574,\"start\":59572},{\"end\":59591,\"start\":59585},{\"end\":59609,\"start\":59601},{\"end\":59618,\"start\":59616},{\"end\":59633,\"start\":59628},{\"end\":59650,\"start\":59642},{\"end\":59665,\"start\":59659},{\"end\":59684,\"start\":59675},{\"end\":59702,\"start\":59698},{\"end\":59714,\"start\":59707},{\"end\":60053,\"start\":60047},{\"end\":60059,\"start\":60055},{\"end\":60067,\"start\":60063},{\"end\":60089,\"start\":60079},{\"end\":60108,\"start\":60098},{\"end\":60121,\"start\":60116},{\"end\":60140,\"start\":60129},{\"end\":60153,\"start\":60142},{\"end\":60478,\"start\":60471},{\"end\":60493,\"start\":60487},{\"end\":60508,\"start\":60501},{\"end\":60524,\"start\":60519},{\"end\":60798,\"start\":60794},{\"end\":60809,\"start\":60804},{\"end\":60822,\"start\":60819},{\"end\":60836,\"start\":60831},{\"end\":60848,\"start\":60843},{\"end\":60858,\"start\":60854},{\"end\":60869,\"start\":60864},{\"end\":60877,\"start\":60875},{\"end\":60886,\"start\":60884},{\"end\":61565,\"start\":61562},{\"end\":61579,\"start\":61576},{\"end\":61839,\"start\":61836},{\"end\":61853,\"start\":61850},{\"end\":62030,\"start\":62023},{\"end\":62039,\"start\":62036},{\"end\":62053,\"start\":62050},{\"end\":62070,\"start\":62062},{\"end\":62082,\"start\":62078},{\"end\":62101,\"start\":62093},{\"end\":62116,\"start\":62111},{\"end\":62135,\"start\":62126},{\"end\":62154,\"start\":62144},{\"end\":62431,\"start\":62427},{\"end\":62444,\"start\":62440},{\"end\":62455,\"start\":62451},{\"end\":62463,\"start\":62457},{\"end\":62705,\"start\":62702},{\"end\":62714,\"start\":62712},{\"end\":62950,\"start\":62946},{\"end\":62963,\"start\":62959},{\"end\":62978,\"start\":62971},{\"end\":63144,\"start\":63138},{\"end\":63156,\"start\":63148},{\"end\":63173,\"start\":63166},{\"end\":63181,\"start\":63175},{\"end\":63433,\"start\":63429},{\"end\":63455,\"start\":63445},{\"end\":63463,\"start\":63457},{\"end\":63696,\"start\":63684},{\"end\":63710,\"start\":63703},{\"end\":63730,\"start\":63719},{\"end\":63755,\"start\":63743},{\"end\":64024,\"start\":64017},{\"end\":64036,\"start\":64026},{\"end\":64047,\"start\":64040},{\"end\":64054,\"start\":64049},{\"end\":64062,\"start\":64058},{\"end\":64081,\"start\":64072},{\"end\":64091,\"start\":64083},{\"end\":64404,\"start\":64399},{\"end\":64414,\"start\":64411},{\"end\":64423,\"start\":64416},{\"end\":64763,\"start\":64759},{\"end\":64776,\"start\":64774},{\"end\":64786,\"start\":64783},{\"end\":64798,\"start\":64796},{\"end\":65073,\"start\":65071},{\"end\":65088,\"start\":65085},{\"end\":65103,\"start\":65098},{\"end\":65117,\"start\":65113},{\"end\":65126,\"start\":65123},{\"end\":65137,\"start\":65135},{\"end\":65152,\"start\":65148},{\"end\":65165,\"start\":65160},{\"end\":65179,\"start\":65176},{\"end\":65193,\"start\":65186},{\"end\":65559,\"start\":65555},{\"end\":65573,\"start\":65568},{\"end\":65590,\"start\":65582},{\"end\":65808,\"start\":65805},{\"end\":65822,\"start\":65818},{\"end\":65832,\"start\":65828},{\"end\":65845,\"start\":65841},{\"end\":65859,\"start\":65855},{\"end\":65871,\"start\":65866},{\"end\":65886,\"start\":65881},{\"end\":66184,\"start\":66180},{\"end\":66194,\"start\":66191},{\"end\":66209,\"start\":66205},{\"end\":66223,\"start\":66219},{\"end\":66464,\"start\":66462},{\"end\":66474,\"start\":66469},{\"end\":66482,\"start\":66478},{\"end\":66496,\"start\":66492},{\"end\":66503,\"start\":66498},{\"end\":66754,\"start\":66747},{\"end\":66763,\"start\":66759},{\"end\":66776,\"start\":66771},{\"end\":66788,\"start\":66783},{\"end\":66803,\"start\":66799},{\"end\":67052,\"start\":67037},{\"end\":67069,\"start\":67059},{\"end\":67087,\"start\":67081},{\"end\":67103,\"start\":67096},{\"end\":67113,\"start\":67105},{\"end\":67391,\"start\":67386},{\"end\":67402,\"start\":67397},{\"end\":67416,\"start\":67413},{\"end\":67426,\"start\":67422},{\"end\":67436,\"start\":67432},{\"end\":67447,\"start\":67442},{\"end\":67456,\"start\":67454},{\"end\":67472,\"start\":67466},{\"end\":67484,\"start\":67482},{\"end\":67792,\"start\":67788},{\"end\":67804,\"start\":67802},{\"end\":67816,\"start\":67810},{\"end\":67829,\"start\":67826},{\"end\":67834,\"start\":67831},{\"end\":68033,\"start\":68029},{\"end\":68042,\"start\":68040},{\"end\":68057,\"start\":68054},{\"end\":68070,\"start\":68066},{\"end\":68083,\"start\":68078},{\"end\":68098,\"start\":68091}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":232427874},\"end\":37441,\"start\":37125},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11253972},\"end\":37644,\"start\":37443},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":220055846},\"end\":37984,\"start\":37646},{\"attributes\":{\"doi\":\"arXiv:1912.11279\",\"id\":\"b3\"},\"end\":38370,\"start\":37986},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":211096730},\"end\":38690,\"start\":38372},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":227118869},\"end\":38893,\"start\":38692},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":233024948},\"end\":39145,\"start\":38895},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":502946},\"end\":39578,\"start\":39147},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":110510},\"end\":39889,\"start\":39580},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":218889912},\"end\":40324,\"start\":39891},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":9062671},\"end\":40595,\"start\":40326},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":249980023},\"end\":40798,\"start\":40597},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":211532737},\"end\":41132,\"start\":40800},{\"attributes\":{\"doi\":\"arXiv:1312.6211\",\"id\":\"b13\"},\"end\":41531,\"start\":41134},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":219687798},\"end\":42112,\"start\":41533},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":226277993},\"end\":42473,\"start\":42114},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":227254137},\"end\":42785,\"start\":42475},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":8281592},\"end\":43030,\"start\":42787},{\"attributes\":{\"doi\":\"arXiv:1811.03604\",\"id\":\"b18\"},\"end\":43496,\"start\":43032},{\"attributes\":{\"doi\":\"arXiv:2004.08546\",\"id\":\"b19\"},\"end\":43800,\"start\":43498},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":225091697},\"end\":44101,\"start\":43802},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":207930212},\"end\":44408,\"start\":44103},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":206594692},\"end\":44650,\"start\":44410},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b23\"},\"end\":44914,\"start\":44652},{\"attributes\":{\"id\":\"b24\"},\"end\":45160,\"start\":44916},{\"attributes\":{\"doi\":\"arXiv:1704.04861\",\"id\":\"b25\"},\"end\":45654,\"start\":45162},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":8148915},\"end\":45850,\"start\":45656},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":219966488},\"end\":46178,\"start\":45852},{\"attributes\":{\"doi\":\"arXiv:2006.10517\",\"id\":\"b28\"},\"end\":46709,\"start\":46180},{\"attributes\":{\"doi\":\"arXiv:1912.04977\",\"id\":\"b29\"},\"end\":47241,\"start\":46711},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b30\"},\"end\":47461,\"start\":47243},{\"attributes\":{\"id\":\"b31\"},\"end\":47966,\"start\":47463},{\"attributes\":{\"doi\":\"arXiv:1610.02527\",\"id\":\"b32\"},\"end\":48336,\"start\":47968},{\"attributes\":{\"doi\":\"arXiv:1610.05492\",\"id\":\"b33\"},\"end\":48755,\"start\":48338},{\"attributes\":{\"id\":\"b34\"},\"end\":49072,\"start\":48757},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":116908168},\"end\":49308,\"start\":49074},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":14542261},\"end\":49631,\"start\":49310},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":203951869},\"end\":49877,\"start\":49633},{\"attributes\":{\"doi\":\"arXiv:2102.02079\",\"id\":\"b38\"},\"end\":50181,\"start\":49879},{\"attributes\":{\"doi\":\"arXiv:2010.01017\",\"id\":\"b39\"},\"end\":50473,\"start\":50183},{\"attributes\":{\"id\":\"b40\"},\"end\":50674,\"start\":50475},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":201126242},\"end\":50967,\"start\":50676},{\"attributes\":{\"doi\":\"arXiv:1812.06127\",\"id\":\"b42\"},\"end\":51329,\"start\":50969},{\"attributes\":{\"doi\":\"arXiv:1708.02862\",\"id\":\"b43\"},\"end\":51667,\"start\":51331},{\"attributes\":{\"id\":\"b44\"},\"end\":52106,\"start\":51669},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":231924480},\"end\":52426,\"start\":52108},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":4853851},\"end\":52590,\"start\":52428},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":207985657},\"end\":53099,\"start\":52592},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":14889902},\"end\":53371,\"start\":53101},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":219636007},\"end\":53696,\"start\":53373},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":14113767},\"end\":54070,\"start\":53698},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":232170551},\"end\":54482,\"start\":54072},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":44868747},\"end\":54888,\"start\":54484},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":210714181},\"end\":55335,\"start\":54890},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":35249701},\"end\":55591,\"start\":55337},{\"attributes\":{\"id\":\"b55\"},\"end\":55836,\"start\":55593},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":61019113},\"end\":56208,\"start\":55838},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":14955348},\"end\":56644,\"start\":56210},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":11605311},\"end\":56892,\"start\":56646},{\"attributes\":{\"id\":\"b59\"},\"end\":57224,\"start\":56894},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":195767066},\"end\":57451,\"start\":57226},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":16852518},\"end\":57804,\"start\":57453},{\"attributes\":{\"doi\":\"arXiv:1908.01091\",\"id\":\"b62\"},\"end\":58206,\"start\":57806},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":740063},\"end\":58382,\"start\":58208},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":207880633},\"end\":58600,\"start\":58384},{\"attributes\":{\"id\":\"b65\"},\"end\":58870,\"start\":58602},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":206596260},\"end\":59199,\"start\":58872},{\"attributes\":{\"doi\":\"arXiv:1807.10108\",\"id\":\"b67\"},\"end\":59536,\"start\":59201},{\"attributes\":{\"id\":\"b68\"},\"end\":60043,\"start\":59538},{\"attributes\":{\"doi\":\"arXiv:1606.04671\",\"id\":\"b69\"},\"end\":60461,\"start\":60045},{\"attributes\":{\"doi\":\"arXiv:2012.00632\",\"id\":\"b70\"},\"end\":60761,\"start\":60463},{\"attributes\":{\"doi\":\"arXiv:2006.16765\",\"id\":\"b71\"},\"end\":61102,\"start\":60763},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":204743727},\"end\":61486,\"start\":61104},{\"attributes\":{\"doi\":\"arXiv:2009.05537\",\"id\":\"b73\"},\"end\":61756,\"start\":61488},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":235125689},\"end\":61979,\"start\":61758},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":206592484},\"end\":62368,\"start\":61981},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":219708331},\"end\":62617,\"start\":62370},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":167217261},\"end\":62860,\"start\":62619},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":231924910},\"end\":63128,\"start\":62862},{\"attributes\":{\"id\":\"b79\"},\"end\":63385,\"start\":63130},{\"attributes\":{\"doi\":\"arXiv:1904.07734\",\"id\":\"b80\"},\"end\":63617,\"start\":63387},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":2928248},\"end\":63944,\"start\":63619},{\"attributes\":{\"id\":\"b82\"},\"end\":64342,\"start\":63946},{\"attributes\":{\"id\":\"b83\"},\"end\":64671,\"start\":64344},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":232257263},\"end\":64968,\"start\":64673},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":54461508},\"end\":65467,\"start\":64970},{\"attributes\":{\"doi\":\"arXiv:1708.07747\",\"id\":\"b86\"},\"end\":65796,\"start\":65469},{\"attributes\":{\"doi\":\"arXiv:2108.08647\",\"id\":\"b87\"},\"end\":66118,\"start\":65798},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":219878182},\"end\":66377,\"start\":66120},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":102350974},\"end\":66675,\"start\":66379},{\"attributes\":{\"id\":\"b90\",\"matched_paper_id\":232110471},\"end\":66973,\"start\":66677},{\"attributes\":{\"doi\":\"arXiv:2010.02056\",\"id\":\"b91\"},\"end\":67329,\"start\":66975},{\"attributes\":{\"doi\":\"arXiv:2010.08982\",\"id\":\"b92\"},\"end\":67715,\"start\":67331},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":219573568},\"end\":67985,\"start\":67717},{\"attributes\":{\"doi\":\"arXiv:1806.00582\",\"id\":\"b94\"},\"end\":68287,\"start\":67987}]", "bib_title": "[{\"end\":37192,\"start\":37125},{\"end\":37460,\"start\":37443},{\"end\":37721,\"start\":37646},{\"end\":38441,\"start\":38372},{\"end\":38740,\"start\":38692},{\"end\":38961,\"start\":38895},{\"end\":39208,\"start\":39147},{\"end\":39618,\"start\":39580},{\"end\":40015,\"start\":39891},{\"end\":40391,\"start\":40326},{\"end\":40659,\"start\":40597},{\"end\":40859,\"start\":40800},{\"end\":41602,\"start\":41533},{\"end\":42190,\"start\":42114},{\"end\":42543,\"start\":42475},{\"end\":42844,\"start\":42787},{\"end\":43872,\"start\":43802},{\"end\":44168,\"start\":44103},{\"end\":44454,\"start\":44410},{\"end\":45708,\"start\":45656},{\"end\":45936,\"start\":45852},{\"end\":49104,\"start\":49074},{\"end\":49365,\"start\":49310},{\"end\":49694,\"start\":49633},{\"end\":50510,\"start\":50475},{\"end\":50738,\"start\":50676},{\"end\":52187,\"start\":52108},{\"end\":52455,\"start\":52428},{\"end\":52677,\"start\":52592},{\"end\":53143,\"start\":53101},{\"end\":53440,\"start\":53373},{\"end\":53739,\"start\":53698},{\"end\":54192,\"start\":54072},{\"end\":54566,\"start\":54484},{\"end\":54973,\"start\":54890},{\"end\":55408,\"start\":55337},{\"end\":55922,\"start\":55838},{\"end\":56282,\"start\":56210},{\"end\":56713,\"start\":56646},{\"end\":57282,\"start\":57226},{\"end\":57520,\"start\":57453},{\"end\":58237,\"start\":58208},{\"end\":58423,\"start\":58384},{\"end\":58929,\"start\":58872},{\"end\":61163,\"start\":61104},{\"end\":61827,\"start\":61758},{\"end\":62011,\"start\":61981},{\"end\":62423,\"start\":62370},{\"end\":62691,\"start\":62619},{\"end\":62935,\"start\":62862},{\"end\":63674,\"start\":63619},{\"end\":64749,\"start\":64673},{\"end\":65062,\"start\":64970},{\"end\":66172,\"start\":66120},{\"end\":66455,\"start\":66379},{\"end\":66740,\"start\":66677},{\"end\":67778,\"start\":67717}]", "bib_author": "[{\"end\":37207,\"start\":37194},{\"end\":37218,\"start\":37207},{\"end\":37233,\"start\":37218},{\"end\":37246,\"start\":37233},{\"end\":37261,\"start\":37246},{\"end\":37480,\"start\":37462},{\"end\":37494,\"start\":37480},{\"end\":37521,\"start\":37494},{\"end\":37732,\"start\":37723},{\"end\":37744,\"start\":37732},{\"end\":37753,\"start\":37744},{\"end\":37765,\"start\":37753},{\"end\":37778,\"start\":37765},{\"end\":37786,\"start\":37778},{\"end\":38092,\"start\":38077},{\"end\":38110,\"start\":38092},{\"end\":38123,\"start\":38110},{\"end\":38140,\"start\":38123},{\"end\":38454,\"start\":38443},{\"end\":38471,\"start\":38454},{\"end\":38489,\"start\":38471},{\"end\":38506,\"start\":38489},{\"end\":38755,\"start\":38742},{\"end\":38767,\"start\":38755},{\"end\":38976,\"start\":38963},{\"end\":38980,\"start\":38976},{\"end\":38993,\"start\":38980},{\"end\":38997,\"start\":38993},{\"end\":39009,\"start\":38997},{\"end\":39225,\"start\":39210},{\"end\":39240,\"start\":39225},{\"end\":39257,\"start\":39240},{\"end\":39271,\"start\":39257},{\"end\":39289,\"start\":39271},{\"end\":39307,\"start\":39289},{\"end\":39319,\"start\":39307},{\"end\":39332,\"start\":39319},{\"end\":39347,\"start\":39332},{\"end\":39642,\"start\":39620},{\"end\":39657,\"start\":39642},{\"end\":39670,\"start\":39657},{\"end\":39691,\"start\":39670},{\"end\":40035,\"start\":40017},{\"end\":40050,\"start\":40035},{\"end\":40063,\"start\":40050},{\"end\":40078,\"start\":40063},{\"end\":40086,\"start\":40078},{\"end\":40407,\"start\":40393},{\"end\":40422,\"start\":40407},{\"end\":40438,\"start\":40422},{\"end\":40674,\"start\":40661},{\"end\":40683,\"start\":40674},{\"end\":40877,\"start\":40861},{\"end\":40892,\"start\":40877},{\"end\":40904,\"start\":40892},{\"end\":40921,\"start\":40904},{\"end\":40936,\"start\":40921},{\"end\":40951,\"start\":40936},{\"end\":41230,\"start\":41223},{\"end\":41248,\"start\":41230},{\"end\":41258,\"start\":41248},{\"end\":41270,\"start\":41258},{\"end\":41288,\"start\":41270},{\"end\":41296,\"start\":41288},{\"end\":41624,\"start\":41604},{\"end\":41639,\"start\":41624},{\"end\":41655,\"start\":41639},{\"end\":41672,\"start\":41655},{\"end\":41682,\"start\":41672},{\"end\":41699,\"start\":41682},{\"end\":41717,\"start\":41699},{\"end\":41735,\"start\":41717},{\"end\":41763,\"start\":41735},{\"end\":41788,\"start\":41763},{\"end\":41794,\"start\":41788},{\"end\":42220,\"start\":42192},{\"end\":42237,\"start\":42220},{\"end\":42249,\"start\":42237},{\"end\":42257,\"start\":42249},{\"end\":42553,\"start\":42545},{\"end\":42567,\"start\":42553},{\"end\":42579,\"start\":42567},{\"end\":42590,\"start\":42579},{\"end\":42604,\"start\":42590},{\"end\":42860,\"start\":42846},{\"end\":42874,\"start\":42860},{\"end\":42886,\"start\":42874},{\"end\":43096,\"start\":43083},{\"end\":43110,\"start\":43096},{\"end\":43125,\"start\":43110},{\"end\":43144,\"start\":43125},{\"end\":43164,\"start\":43144},{\"end\":43181,\"start\":43164},{\"end\":43197,\"start\":43181},{\"end\":43211,\"start\":43197},{\"end\":43226,\"start\":43211},{\"end\":43575,\"start\":43562},{\"end\":43593,\"start\":43575},{\"end\":43612,\"start\":43593},{\"end\":43887,\"start\":43874},{\"end\":43905,\"start\":43887},{\"end\":43924,\"start\":43905},{\"end\":44182,\"start\":44170},{\"end\":44193,\"start\":44182},{\"end\":44203,\"start\":44193},{\"end\":44216,\"start\":44203},{\"end\":44231,\"start\":44216},{\"end\":44468,\"start\":44456},{\"end\":44483,\"start\":44468},{\"end\":44497,\"start\":44483},{\"end\":44507,\"start\":44497},{\"end\":44669,\"start\":44652},{\"end\":44684,\"start\":44669},{\"end\":44695,\"start\":44684},{\"end\":45009,\"start\":44974},{\"end\":45020,\"start\":45009},{\"end\":45172,\"start\":45162},{\"end\":45189,\"start\":45172},{\"end\":45197,\"start\":45189},{\"end\":45210,\"start\":45197},{\"end\":45231,\"start\":45210},{\"end\":45244,\"start\":45231},{\"end\":45258,\"start\":45244},{\"end\":45277,\"start\":45258},{\"end\":45283,\"start\":45277},{\"end\":45727,\"start\":45710},{\"end\":45953,\"start\":45938},{\"end\":45967,\"start\":45953},{\"end\":45979,\"start\":45967},{\"end\":45994,\"start\":45979},{\"end\":46295,\"start\":46288},{\"end\":46308,\"start\":46295},{\"end\":46320,\"start\":46308},{\"end\":46333,\"start\":46320},{\"end\":46342,\"start\":46333},{\"end\":46352,\"start\":46342},{\"end\":46365,\"start\":46352},{\"end\":46380,\"start\":46365},{\"end\":46394,\"start\":46380},{\"end\":46406,\"start\":46394},{\"end\":46726,\"start\":46711},{\"end\":46743,\"start\":46726},{\"end\":46758,\"start\":46743},{\"end\":46775,\"start\":46758},{\"end\":46789,\"start\":46775},{\"end\":46810,\"start\":46789},{\"end\":46829,\"start\":46810},{\"end\":46846,\"start\":46829},{\"end\":46862,\"start\":46846},{\"end\":47299,\"start\":47287},{\"end\":47313,\"start\":47299},{\"end\":47317,\"start\":47313},{\"end\":47573,\"start\":47554},{\"end\":47589,\"start\":47573},{\"end\":47606,\"start\":47589},{\"end\":47619,\"start\":47606},{\"end\":47641,\"start\":47619},{\"end\":47656,\"start\":47641},{\"end\":47670,\"start\":47656},{\"end\":47681,\"start\":47670},{\"end\":47696,\"start\":47681},{\"end\":48064,\"start\":48049},{\"end\":48081,\"start\":48064},{\"end\":48096,\"start\":48081},{\"end\":48113,\"start\":48096},{\"end\":48424,\"start\":48409},{\"end\":48441,\"start\":48424},{\"end\":48450,\"start\":48441},{\"end\":48460,\"start\":48450},{\"end\":48478,\"start\":48460},{\"end\":48500,\"start\":48478},{\"end\":48507,\"start\":48500},{\"end\":48826,\"start\":48812},{\"end\":48836,\"start\":48826},{\"end\":49124,\"start\":49106},{\"end\":49135,\"start\":49124},{\"end\":49144,\"start\":49135},{\"end\":49379,\"start\":49367},{\"end\":49392,\"start\":49379},{\"end\":49407,\"start\":49392},{\"end\":49424,\"start\":49407},{\"end\":49708,\"start\":49696},{\"end\":49720,\"start\":49708},{\"end\":49955,\"start\":49944},{\"end\":49967,\"start\":49955},{\"end\":49978,\"start\":49967},{\"end\":49992,\"start\":49978},{\"end\":50266,\"start\":50255},{\"end\":50280,\"start\":50266},{\"end\":50291,\"start\":50280},{\"end\":50523,\"start\":50512},{\"end\":50537,\"start\":50523},{\"end\":50548,\"start\":50537},{\"end\":50749,\"start\":50740},{\"end\":50766,\"start\":50749},{\"end\":50783,\"start\":50766},{\"end\":50799,\"start\":50783},{\"end\":51028,\"start\":51019},{\"end\":51045,\"start\":51028},{\"end\":51060,\"start\":51045},{\"end\":51076,\"start\":51060},{\"end\":51093,\"start\":51076},{\"end\":51109,\"start\":51093},{\"end\":51339,\"start\":51331},{\"end\":51351,\"start\":51339},{\"end\":51359,\"start\":51351},{\"end\":51378,\"start\":51359},{\"end\":51392,\"start\":51378},{\"end\":51789,\"start\":51776},{\"end\":51800,\"start\":51789},{\"end\":51815,\"start\":51800},{\"end\":51827,\"start\":51815},{\"end\":51841,\"start\":51827},{\"end\":51858,\"start\":51841},{\"end\":51866,\"start\":51858},{\"end\":52202,\"start\":52189},{\"end\":52216,\"start\":52202},{\"end\":52231,\"start\":52216},{\"end\":52245,\"start\":52231},{\"end\":52253,\"start\":52245},{\"end\":52470,\"start\":52457},{\"end\":52483,\"start\":52470},{\"end\":52703,\"start\":52679},{\"end\":52712,\"start\":52703},{\"end\":52719,\"start\":52712},{\"end\":52745,\"start\":52719},{\"end\":52761,\"start\":52745},{\"end\":52775,\"start\":52761},{\"end\":52805,\"start\":52775},{\"end\":52814,\"start\":52805},{\"end\":53158,\"start\":53145},{\"end\":53177,\"start\":53158},{\"end\":53188,\"start\":53177},{\"end\":53202,\"start\":53188},{\"end\":53211,\"start\":53202},{\"end\":53451,\"start\":53442},{\"end\":53466,\"start\":53451},{\"end\":53479,\"start\":53466},{\"end\":53493,\"start\":53479},{\"end\":53500,\"start\":53493},{\"end\":53755,\"start\":53741},{\"end\":53770,\"start\":53755},{\"end\":53786,\"start\":53770},{\"end\":53798,\"start\":53786},{\"end\":53813,\"start\":53798},{\"end\":53827,\"start\":53813},{\"end\":53841,\"start\":53827},{\"end\":53861,\"start\":53841},{\"end\":54206,\"start\":54194},{\"end\":54218,\"start\":54206},{\"end\":54228,\"start\":54218},{\"end\":54236,\"start\":54228},{\"end\":54252,\"start\":54236},{\"end\":54580,\"start\":54568},{\"end\":54593,\"start\":54580},{\"end\":54607,\"start\":54593},{\"end\":54621,\"start\":54607},{\"end\":54639,\"start\":54621},{\"end\":54655,\"start\":54639},{\"end\":54665,\"start\":54655},{\"end\":54985,\"start\":54975},{\"end\":54997,\"start\":54985},{\"end\":55006,\"start\":54997},{\"end\":55016,\"start\":55006},{\"end\":55028,\"start\":55016},{\"end\":55043,\"start\":55028},{\"end\":55055,\"start\":55043},{\"end\":55070,\"start\":55055},{\"end\":55078,\"start\":55070},{\"end\":55090,\"start\":55078},{\"end\":55423,\"start\":55410},{\"end\":55442,\"start\":55423},{\"end\":55694,\"start\":55677},{\"end\":55703,\"start\":55694},{\"end\":55709,\"start\":55703},{\"end\":55943,\"start\":55924},{\"end\":55951,\"start\":55943},{\"end\":55958,\"start\":55951},{\"end\":56301,\"start\":56284},{\"end\":56314,\"start\":56301},{\"end\":56329,\"start\":56314},{\"end\":56343,\"start\":56329},{\"end\":56366,\"start\":56343},{\"end\":56732,\"start\":56715},{\"end\":56746,\"start\":56732},{\"end\":56954,\"start\":56946},{\"end\":56974,\"start\":56954},{\"end\":56988,\"start\":56974},{\"end\":57005,\"start\":56988},{\"end\":57015,\"start\":57005},{\"end\":57033,\"start\":57015},{\"end\":57042,\"start\":57033},{\"end\":57299,\"start\":57284},{\"end\":57317,\"start\":57299},{\"end\":57536,\"start\":57522},{\"end\":57546,\"start\":57536},{\"end\":57559,\"start\":57546},{\"end\":57580,\"start\":57559},{\"end\":57587,\"start\":57580},{\"end\":57600,\"start\":57587},{\"end\":57901,\"start\":57874},{\"end\":57918,\"start\":57901},{\"end\":57927,\"start\":57918},{\"end\":57942,\"start\":57927},{\"end\":57961,\"start\":57942},{\"end\":57969,\"start\":57961},{\"end\":58263,\"start\":58239},{\"end\":58269,\"start\":58263},{\"end\":58440,\"start\":58425},{\"end\":58453,\"start\":58440},{\"end\":58464,\"start\":58453},{\"end\":58477,\"start\":58464},{\"end\":58664,\"start\":58637},{\"end\":58682,\"start\":58664},{\"end\":58690,\"start\":58682},{\"end\":58706,\"start\":58690},{\"end\":58720,\"start\":58706},{\"end\":58967,\"start\":58931},{\"end\":58985,\"start\":58967},{\"end\":59004,\"start\":58985},{\"end\":59013,\"start\":59004},{\"end\":59213,\"start\":59201},{\"end\":59230,\"start\":59213},{\"end\":59558,\"start\":59540},{\"end\":59568,\"start\":59558},{\"end\":59576,\"start\":59568},{\"end\":59593,\"start\":59576},{\"end\":59611,\"start\":59593},{\"end\":59620,\"start\":59611},{\"end\":59635,\"start\":59620},{\"end\":59652,\"start\":59635},{\"end\":59667,\"start\":59652},{\"end\":59686,\"start\":59667},{\"end\":59704,\"start\":59686},{\"end\":59716,\"start\":59704},{\"end\":60055,\"start\":60045},{\"end\":60061,\"start\":60055},{\"end\":60069,\"start\":60061},{\"end\":60091,\"start\":60069},{\"end\":60110,\"start\":60091},{\"end\":60123,\"start\":60110},{\"end\":60142,\"start\":60123},{\"end\":60155,\"start\":60142},{\"end\":60480,\"start\":60465},{\"end\":60495,\"start\":60480},{\"end\":60510,\"start\":60495},{\"end\":60526,\"start\":60510},{\"end\":60800,\"start\":60790},{\"end\":60811,\"start\":60800},{\"end\":60824,\"start\":60811},{\"end\":60838,\"start\":60824},{\"end\":60850,\"start\":60838},{\"end\":60860,\"start\":60850},{\"end\":60871,\"start\":60860},{\"end\":60879,\"start\":60871},{\"end\":60888,\"start\":60879},{\"end\":61567,\"start\":61555},{\"end\":61581,\"start\":61567},{\"end\":61841,\"start\":61829},{\"end\":61855,\"start\":61841},{\"end\":62032,\"start\":62013},{\"end\":62041,\"start\":62032},{\"end\":62055,\"start\":62041},{\"end\":62072,\"start\":62055},{\"end\":62084,\"start\":62072},{\"end\":62103,\"start\":62084},{\"end\":62118,\"start\":62103},{\"end\":62137,\"start\":62118},{\"end\":62156,\"start\":62137},{\"end\":62433,\"start\":62425},{\"end\":62446,\"start\":62433},{\"end\":62457,\"start\":62446},{\"end\":62465,\"start\":62457},{\"end\":62707,\"start\":62693},{\"end\":62716,\"start\":62707},{\"end\":62952,\"start\":62937},{\"end\":62965,\"start\":62952},{\"end\":62980,\"start\":62965},{\"end\":63146,\"start\":63130},{\"end\":63158,\"start\":63146},{\"end\":63175,\"start\":63158},{\"end\":63183,\"start\":63175},{\"end\":63435,\"start\":63427},{\"end\":63457,\"start\":63435},{\"end\":63465,\"start\":63457},{\"end\":63698,\"start\":63676},{\"end\":63712,\"start\":63698},{\"end\":63732,\"start\":63712},{\"end\":63757,\"start\":63732},{\"end\":64026,\"start\":64015},{\"end\":64038,\"start\":64026},{\"end\":64049,\"start\":64038},{\"end\":64056,\"start\":64049},{\"end\":64064,\"start\":64056},{\"end\":64083,\"start\":64064},{\"end\":64093,\"start\":64083},{\"end\":64406,\"start\":64394},{\"end\":64416,\"start\":64406},{\"end\":64425,\"start\":64416},{\"end\":64765,\"start\":64751},{\"end\":64778,\"start\":64765},{\"end\":64788,\"start\":64778},{\"end\":64800,\"start\":64788},{\"end\":65075,\"start\":65064},{\"end\":65090,\"start\":65075},{\"end\":65105,\"start\":65090},{\"end\":65119,\"start\":65105},{\"end\":65128,\"start\":65119},{\"end\":65139,\"start\":65128},{\"end\":65154,\"start\":65139},{\"end\":65167,\"start\":65154},{\"end\":65181,\"start\":65167},{\"end\":65195,\"start\":65181},{\"end\":65561,\"start\":65551},{\"end\":65575,\"start\":65561},{\"end\":65592,\"start\":65575},{\"end\":65810,\"start\":65800},{\"end\":65824,\"start\":65810},{\"end\":65834,\"start\":65824},{\"end\":65847,\"start\":65834},{\"end\":65861,\"start\":65847},{\"end\":65873,\"start\":65861},{\"end\":65888,\"start\":65873},{\"end\":66186,\"start\":66174},{\"end\":66196,\"start\":66186},{\"end\":66211,\"start\":66196},{\"end\":66225,\"start\":66211},{\"end\":66466,\"start\":66457},{\"end\":66476,\"start\":66466},{\"end\":66484,\"start\":66476},{\"end\":66498,\"start\":66484},{\"end\":66505,\"start\":66498},{\"end\":66756,\"start\":66742},{\"end\":66765,\"start\":66756},{\"end\":66778,\"start\":66765},{\"end\":66790,\"start\":66778},{\"end\":66805,\"start\":66790},{\"end\":67054,\"start\":67032},{\"end\":67071,\"start\":67054},{\"end\":67089,\"start\":67071},{\"end\":67105,\"start\":67089},{\"end\":67115,\"start\":67105},{\"end\":67393,\"start\":67379},{\"end\":67404,\"start\":67393},{\"end\":67418,\"start\":67404},{\"end\":67428,\"start\":67418},{\"end\":67438,\"start\":67428},{\"end\":67449,\"start\":67438},{\"end\":67458,\"start\":67449},{\"end\":67474,\"start\":67458},{\"end\":67486,\"start\":67474},{\"end\":67794,\"start\":67780},{\"end\":67806,\"start\":67794},{\"end\":67818,\"start\":67806},{\"end\":67831,\"start\":67818},{\"end\":67836,\"start\":67831},{\"end\":68035,\"start\":68025},{\"end\":68044,\"start\":68035},{\"end\":68059,\"start\":68044},{\"end\":68072,\"start\":68059},{\"end\":68085,\"start\":68072},{\"end\":68100,\"start\":68085}]", "bib_venue": "[{\"end\":37265,\"start\":37261},{\"end\":37524,\"start\":37521},{\"end\":37793,\"start\":37786},{\"end\":38075,\"start\":37986},{\"end\":38510,\"start\":38506},{\"end\":38771,\"start\":38767},{\"end\":39013,\"start\":39009},{\"end\":39351,\"start\":39347},{\"end\":39720,\"start\":39691},{\"end\":40096,\"start\":40086},{\"end\":40442,\"start\":40438},{\"end\":40687,\"start\":40683},{\"end\":40955,\"start\":40951},{\"end\":41221,\"start\":41134},{\"end\":41801,\"start\":41794},{\"end\":42285,\"start\":42257},{\"end\":42618,\"start\":42604},{\"end\":42890,\"start\":42886},{\"end\":43081,\"start\":43032},{\"end\":43560,\"start\":43498},{\"end\":43931,\"start\":43924},{\"end\":44235,\"start\":44231},{\"end\":44511,\"start\":44507},{\"end\":44755,\"start\":44711},{\"end\":44972,\"start\":44916},{\"end\":45381,\"start\":45299},{\"end\":45737,\"start\":45727},{\"end\":46007,\"start\":45994},{\"end\":46286,\"start\":46180},{\"end\":46950,\"start\":46878},{\"end\":47285,\"start\":47243},{\"end\":47552,\"start\":47463},{\"end\":48047,\"start\":47968},{\"end\":48407,\"start\":48338},{\"end\":48810,\"start\":48757},{\"end\":49177,\"start\":49144},{\"end\":49447,\"start\":49424},{\"end\":49736,\"start\":49720},{\"end\":49942,\"start\":49879},{\"end\":50253,\"start\":50183},{\"end\":50552,\"start\":50548},{\"end\":50807,\"start\":50799},{\"end\":51017,\"start\":50969},{\"end\":51475,\"start\":51408},{\"end\":51774,\"start\":51669},{\"end\":52257,\"start\":52253},{\"end\":52493,\"start\":52483},{\"end\":52836,\"start\":52814},{\"end\":53218,\"start\":53211},{\"end\":53507,\"start\":53500},{\"end\":53865,\"start\":53861},{\"end\":54256,\"start\":54252},{\"end\":54669,\"start\":54665},{\"end\":55094,\"start\":55090},{\"end\":55446,\"start\":55442},{\"end\":55675,\"start\":55593},{\"end\":55995,\"start\":55958},{\"end\":56404,\"start\":56366},{\"end\":56754,\"start\":56746},{\"end\":56944,\"start\":56894},{\"end\":57321,\"start\":57317},{\"end\":57616,\"start\":57600},{\"end\":57872,\"start\":57806},{\"end\":58278,\"start\":58269},{\"end\":58481,\"start\":58477},{\"end\":58635,\"start\":58602},{\"end\":59017,\"start\":59013},{\"end\":59344,\"start\":59246},{\"end\":60232,\"start\":60171},{\"end\":60788,\"start\":60763},{\"end\":61181,\"start\":61165},{\"end\":61553,\"start\":61488},{\"end\":61859,\"start\":61855},{\"end\":62160,\"start\":62156},{\"end\":62472,\"start\":62465},{\"end\":62720,\"start\":62716},{\"end\":62984,\"start\":62980},{\"end\":63248,\"start\":63183},{\"end\":63425,\"start\":63387},{\"end\":63761,\"start\":63757},{\"end\":64013,\"start\":63946},{\"end\":64392,\"start\":64344},{\"end\":64804,\"start\":64800},{\"end\":65199,\"start\":65195},{\"end\":65549,\"start\":65469},{\"end\":66233,\"start\":66225},{\"end\":66509,\"start\":66505},{\"end\":66809,\"start\":66805},{\"end\":67030,\"start\":66975},{\"end\":67377,\"start\":67331},{\"end\":67846,\"start\":67836},{\"end\":68023,\"start\":67987},{\"end\":49457,\"start\":49449}]"}}}, "year": 2023, "month": 12, "day": 17}