{"id": 196622289, "updated": "2023-10-07 00:58:16.762", "metadata": {"title": "Random Khatri-Rao-Product Codes for Numerically-Stable Distributed Matrix Multiplication", "authors": "[{\"first\":\"Adarsh\",\"last\":\"Subramaniam\",\"middle\":[\"M.\"]},{\"first\":\"Anoosheh\",\"last\":\"Heidarzadeh\",\"middle\":[]},{\"first\":\"Krishna\",\"last\":\"Narayanan\",\"middle\":[\"R.\"]}]", "venue": "2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)", "journal": "2019 57th Annual Allerton Conference on Communication, Control, and Computing (Allerton)", "publication_date": {"year": 2019, "month": 7, "day": 12}, "abstract": "We propose a class of codes called random Khatri-Rao-Product (RKRP) codes for distributed matrix multiplication in the presence of stragglers. The main advantage of the proposed codes is that decoding of RKRP codes is highly numerically stable in comparison to decoding of Polynomial codes and decoding of the recently proposed OrthoPoly codes. We show that RKRP codes are maximum distance separable with probability 1. The communication cost and encoding complexity for RKRP codes are identical to that of OrthoPoly codes and Polynomial codes and the average decoding complexity of RKRP codes is lower than that of OrthoPoly codes. Numerical results show that the average relative $L_2$-norm of the reconstruction error for RKRP codes is substantially better than that of OrthoPoly codes.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1907.05965", "mag": "2993649261", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/allerton/SubramaniamHN19", "doi": "10.1109/allerton.2019.8919859"}}, "content": {"source": {"pdf_hash": "c3a34e0bf506b8935b2048d9cbd537390ab326c2", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1907.05965v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1907.05965", "status": "GREEN"}}, "grobid": {"id": "d55caaa6ed67420766c4a5556ae0db5a4f61c79b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c3a34e0bf506b8935b2048d9cbd537390ab326c2.txt", "contents": "\nRandom Khatri-Rao-Product Codes for Numerically-Stable Distributed Matrix Multiplication\n12 Jul 2019\n\nAdarsh M Subramaniam \nDepartment of Electrical and Computer Engineering\nTexas A&M University\n\n\nAnoosheh Heidarzadeh \nDepartment of Electrical and Computer Engineering\nTexas A&M University\n\n\nKrishna R Narayanan \nDepartment of Electrical and Computer Engineering\nTexas A&M University\n\n\nRandom Khatri-Rao-Product Codes for Numerically-Stable Distributed Matrix Multiplication\n12 Jul 2019arXiv:1907.05965v1 [cs.IT] 1\nWe propose a class of codes called random Khatri-Rao-Product (RKRP) codes for distributed matrix multiplication in the presence of stragglers. The main advantage of the proposed codes is that decoding of RKRP codes is highly numerically stable in comparison to decoding of Polynomial codes [1] and decoding of the recently proposed OrthoPoly codes[2]. We show that RKRP codes are maximum distance separable with probability 1. The communication cost and encoding complexity for RKRP codes are identical to that of OrthoPoly codes and Polynomial codes and the average decoding complexity of RKRP codes is lower than that of OrthoPoly codes. Numerical results show that the average relative L 2 -norm of the reconstruction error for RKRP codes is substantially better than that of OrthoPoly codes.\n\nI. INTRODUCTION AND MAIN RESULTS\n\nWe consider the problem of computing A T B for two matrices A \u2208 R N2\u00d7N1 and B \u2208 R N2\u00d7N3 in a distributed fashion using a coded matrix multiplication scheme with N worker nodes [1], [3]- [12]. In [1], Yu, Maddah-Ali and Avestimehr proposed an elegant encoding scheme called Polynomial codes in which the matrices A T and B are each split into m and n sub-matrices, respectively, the sub-matrices are encoded using a polynomial code and the computations are distributed to N worker nodes. This scheme is shown to have optimal recovery threshold, i.e., the matrix product A T B can be computed (recovered) using the results of computation from any subset of worker nodes of cardinality K = mn. In the language of coding theory, Polynomial codes are generalized Reed-Solomon codes, their generator matrices have Vandermonde structures, and they are maximum distance separable (MDS) codes.\n\nJuly 16, 2019 DRAFT One important drawback of Polynomial codes is that the process of recovering A T B from the results of the worker nodes (the decoding process) involves explicitly or implicitly inverting a Vandermonde matrix, which is well known to be highly numerically unstable even for moderate values of K = mn.\n\nVery recently, Fahim and Cadambe [2] proposed a very interesting polynomial code called OrthoPoly code which uses an orthogonal polynomial basis resulting in a Chebyshev-Vandermonde structure for the generator matrix. OrthoPoly codes are also MDS codes, i.e., have optimal recovery threshold; however, they afford better numerical stability than Polynomial codes. In particular, when there are S stragglers among N nodes, i.e., N = K + S, the condition number of the matrix that needs to be inverted grows only polynomially in N . However, the main drawback of OrthoPoly codes is that the condition number still grows exponentially in S making it unsuitable even for moderately large values of S.\n\nIn this paper, we propose a coding scheme for the distributed matrix multiplication problem which we call Random Khatri-Rao-Product (RKRP) codes which exhibits substantially better numerical stability than Polynomial codes [1] and OrthoPoly codes [2]. The proposed coding scheme is not based on polynomial interpolation; rather, it is designed in the spirit of random codes in information theory.\n\nRKRP codes split both A T and B into sub-matrices and encode them by forming random linear combinations of the sub-matrices. The proposed RKRP codes have several desirable features: (i) RKRP codes have the same thresholds, encoding complexity and communication cost as that of Polynomial codes and OrthoPoly codes; (ii) Decoding process of RKRP codes is substantially more numerically stable than that of Polynomial and OrthoPoly codes, and decoding can be implemented even for fairly large values of K, S, N (e.g., K = 1000 and any S, N ); and (iii) decoding complexity of RKRP codes is lower than that of OrthoPoly codes. To the best of our knowledge, the RKRP code construction and the analysis of their MDS property are new.\n\nWe present two ensembles of generator matrices for RKRP codes called the non-systematic RKRP ensemble and the systematic RKRP ensemble. Codes from these ensembles will be referred to as non-systematic RKRP codes and systematic RKRP codes 1 , respectively. Systematic RKRP codes have better average decoding complexity and better numerical stability. Hence, systematic RKRP codes would be preferred over non-systematic RKRP codes for most applications. However, we present both nonsystematic and systematic ensembles in this paper for the following reasons. Since Polynomial and\n\nOrthoPoly codes are presented with non-systematic encoding, non-systematic RKRP codes allow for 1 The terminology of associating the words systematic and non-systematic with the code, rather than with the encoder is not standard in coding theory. While it is possible to find a systematic encoder for a non-systematic RKRP code, the resulting code would not belong to the systematic RKRP ensemble and hence, should be treated as a non-systematic RKRP code. the submatrix of A corresponding to the rows from S 1 and columns from S 2 is given by [A] S1,S2 . We denote the set of integers from i to j, inclusive of i and j by i : j and we denote the set of integers from\n1 to i by [i]\n. For a vector v, we denote the part of vector v between indices i and j as v i:j . We will assume that vectors without transposes are column vectors unless stated otherwise. Random variables will be denoted by capital letters and their realizations will be denoted by lower case letters.\n\n\nIII. SYSTEM MODEL AND PRELIMINARIES\n\nWe consider a system with one master node which has access to matrices A T and B and N worker nodes which can perform multiplication of sub-matrices of A T and B. At the master node, the matrix A T is split into m sub-matrices row-wise and B is split into n sub-matrices column-wise as shown below.\nA T = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 A T 1 A T 2 . . . A T m \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb , B = B 1 B 2 \u00b7 \u00b7 \u00b7 B n(1)\nIn order to compute the matrix product A T B, we need to compute the matrix products A T j B l for j = 1, . . . , m and l = 1, . . . , n. The main idea in distributed coded computation is to first encode\nA T 1 , . . . , A T m and B 1 , . . . , B n into N pairs of matrices U T i , V i , i = 1, . . . , N . 2\nThe ith worker node is then tasked with computing the matrix product X i = U T i V i . It is assumed that K out of the N workers return the result of their computation; these worker nodes are called non-stragglers. Without loss of generality we assume that the non-stragglers are worker nodes 1, . . . , K. \nX i = U T i V i .\nDefinition 3. The row-wise Khatri-Rao product of two matrices P \u2208 R K\u00d7m and Q \u2208 R K\u00d7n denoted by P \u2299 Q is given by the matrix M whose ith row is the Kronecker product of the ith row of P and the ith row of Q, i.e.,\n[M] i,: = [P i,: ] \u2297 [Q i,: ](2)\nwhere \u2297 refers to the Kronecker product.\n\n\nIV. NON-SYSTEMATICALLY ENCODED RANDOM KHATRI-RAO-PRODUCT CODES\n\n\nA. Encoding:\n\nOur proposed non-systematic RKRP codes are encoded as follows. For i = 1, . . . , N , the master node\ncomputes U T i = m j=1 p i,j A T j ,(3)V i = n l=1 q i,l B l(4)\nwhere p i,j , q i,l are realizations of independent identically distributed random variables P i,j and Q i,l , respectively. Both P i,j and Q i,l are assumed to be continuous random variables with a probability density function f \u2200i, j, l, i.e., their distribution is absolutely continuous with respect to the Lebesgue measure.\n\nU i and V i are then transmitted to the ith worker node which is tasked with computing X i = U T i V i . We first note that X i can be written as\nX i = m j=1 p i,j A T j n l=1 q i,l B l = m j=1 n l=1 p i,j q i,l A T j B l .(5)\nSince the matrix X i is a linear combination of the desired matrix products A T j B l , the (s, t)th entry of X i , namely [X i ] s,t , is a linear combination of the (s, t)th entries of the matrix products A T j B l , namely\n[A T j B l ] s,t .\nDuring the decoding process, we attempt to recover\n[A T j B l ] s,t from [X 1 ] st , . . . , [X K ] s,t for each pair of s, t separately.\nTo keep the discussions clear, we focus on the recovery of the (1, 1)th entry of A T j B l , namely [A T j B l ] 1,1 . The same idea extends to the recovery of other indices as well. Let y i = [X i ] 1,1 denote the (1, 1)th entry in the matrix product computed by the ith non-straggler worker node, and let\nz j,l = [A T j B l ] 1,1 .\nThe vector of computed values can be written as a linear combination of matrix products given by \uf8ee\n\uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 y 1 y 2 . . . y i . . . y N \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 p 1,1 q 1,1 p 1,1 q 1,2 . . . p 1,1 q 1,n . . . p 1,m q 1,n p 2,1 q 2,1 p 2,1 q 2,2 . . . p 2,1 q 2,n . . . p 2,m q 2,n . . . p i,1 q i,1 p i,1 q i,2 . . . p i,1 q i,n . . . p i,m q i,n . . . p N,1 q N,1 p N,1 q N,2 . . . p N,1 q N,n . . . p N,m q N,n \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 z 1,1 z 1,2 . . . z 1,n . . . z m,n \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb(6)\nIt will be more convenient to express (6) in a slightly different form. For j \u2208 {1, . . . , mn}, let j \u2032 = \u2308j/n\u2309 and j \u2032\u2032 = (j \u2212 1) mod n + 1, and let w j = z j \u2032 ,j \u2032\u2032 . Without loss of generality, let us assume that the worker nodes which return their computation are worker nodes 1, 2, . . . , K. The computed values y i 's are related to the unknown values w j 's according to \uf8ee\n\uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 y 1 y 2 . . . y i . . . y K \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 p 1,1 q 1,1 p 1,1 q 1,2 .\n. . p 1,1 q 1,n . . . p 1,m q 1,n p 2,1 q 2,1 p 2,1 q 2,2 . . . p 2,1 q 2,n . . . p 2,m q 2,n . . .\np i,1 q i,1 p i,1 q i,2 . . . p i,1 q i,n . . . p i,m q i,n . . . p K,1 q K,1 p K,1 q K,2 . . . p K,1 q K,n . . . p K,m q K,n \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w 1 w 2 . . . w j . . . w K \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb(7)\nor, more succinctly as\ny = G w (8) where y = [y 1 , y 2 , . . . , y K ] T , w = [w 1 , w 2 , . . . , w mn ] T , and G is an N \u00d7 mn generator matrix for a code with [G] i,j = p i,j \u2032 q i,j \u2032\u2032 .\nLet P and Q be two matrices whose entries are given by\n[P] i,j \u2032 = p i,j \u2032 and [Q] i,j \u2032\u2032 = q i,j \u2032\u2032 .\nIt can be seen that\nG = P \u2299 Q,(9)\ni.e., G is the row-wise Khatri-Rao product of two matrices P and Q. Hence, we call these codes as Random Khatri-Rao-Product codes.\n\nExample 4. In order to clarify the main idea, consider an example with m = 2 and n = 3 and N > 6. Without loss of generality, assume that the worker nodes 1, 2, . . . , 6 return the results of their computations, namely, X 1 , . . . , X 6 . In this case, the set of computations returned by the worker nodes is related to the matrix products that we need to compute according to \uf8ee\n\uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 y 1 y 2 y 3 y 4 y 5 y 6 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 p 1,1 q 1,1 p 1,1 q 1,2 p 1,1 q 1,3 p 1,2 q 1,1 p 1,2 q 1,2 p 1,2 q 1,3 p 2,1 q 2,1 p 2,1 q 2,2 p 2,1 q 2,3 p 2,2 q 2,1 p 2,2 q 2,2 p 2,2 q 2,3 p 3,1 q 3,1 p 3,1 q 3,2 p 3,1 q 3,3 p 3,2 q 3,1 p 3,2 q 3,2 p 3,2 q 3,3\np 4,1 q 4,1 p 4,1 q 4,2 p 4,1 q 4,3 p 4,2 q 4,1 p 4,2 q 4,2 p 4,2 q 4,3 p 5,1 q 5,1 p 5,1 q 5,2 p 5,1 q 5,3 p 5,2 q 5,1 p 5,2 q 5,2 p 5,2 q 5,3 p 6,1 q 6,1 p 6,1 q 6,2 p 6,1 q 6,3 p 6,2 q 6,1 p 6,2 q 6,2 p 6,2 q 6,3\n\uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w 1 w 2 w 3 w 4 w 5 w 6 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb(10)\nDefinition 5. The ensemble of N \u00d7K generator matrices obtained by choosing the generator matrix G as in (9) where p i,j , q i,j are realizations of random variables P i,j , Q i,j such that {P 1,1 , . . . , P N,m , Q 1,1 , . . . , Q N,n } is a set of independent random variables with probability density function f will be referred to as the non-systematic random Khatri-Rao-product generator matrix ensemble G non\u2212sys (N, K, f ).\n\n\nB. Decoding:\n\nDuring decoding, an estimate of w, namely\u0175, is obtained as follow\u015d\nw = G \u22121 y.(11)\nIn the absence of numerical round-off errors, if G is invertible, then\u0175 = w. However, when performing computation with finite bits of precision, there will be numerical errors in the computation. Let e = w \u2212\u0175 be the error, and define the relative error as\n\u03b7 := ||e|| 2 ||w|| 2 .(12)\nV. NON-SYSTEMATIC RKRP CODES ARE MDS CODES WITH PROBABILITY 1\n\nOur first main result in this paper is that if a generator matrix is randomly chosen from the nonsystematic RKRP ensemble G non\u2212sys (N, K, f ), the encoding scheme defined in (4) results in an MDS code with probability 1. Proof. This lemma is proved in [13, Lemma 1] for the complex field C. The proof for the real field can be obtained by following the same steps and replacing C with R.\n\nTheorem 7. Non-systematic RKRP codes are MDS codes with probability 1.\n\nProof. To prove the theorem, we need to prove that the matrix G obtained when K = mn in (7) is a full rank matrix with probability 1. Let p i,j be a realization of the random variable P i,j and let q i,j be a realization of the random variable Q i,j . The generator matrix in (7) \n\u0393 = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 P 1,1 Q 1,1 P 1,1 Q 1,2 . . . P 1,1 Q 1,n . . . P 1m Q 1,n P 2,1 Q 2,1 P 2,1 Q 2,2 . . . P 2,1 Q 2,n . . . P 2m Q 2,n . . . P i,1 Q i,1 P i,1 Q i2 . . . P i,1 Q in . . . P i,m Q in . . . P K,1 Q K,1 P K,1 Q K,2 . . . P K,1 Q K,n . . . P K,m Q K,n \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb(13)\nWe will show that Pr(rank(\u0393) = mn) = 0. The determinant of \u0393 is a polynomial in the variables \n\nWe first show that there exists at least one P 1,1 , . . . , P K,m , Q 1,1 , . . . , Q K,n for which h(P 1,1 , . . . , P K,m , Q 1,1 , . . . , Q K,n ) = 0.\n\nFor j \u2208 [mn], let j \u2032 = \u2308j/n\u2309 and j \u2032\u2032 = ((j \u2212 1) mod n) + 1. Let P j,j \u2032 = 1, Q j,j \u2032\u2032 = 1, \u2200j \u2208 [mn], P j,l = 0, \u2200j \u2208 [mn], l = j \u2032 , and Q j,l = 0, \u2200j \u2208 [mn], l = j \u2032\u2032 . For this choice of P 1,1 , . . . , P K,m , Q 1,1 , . . . , Q K,n , it can be seen that the matrix \u0393 reduces to an identity matrix, and hence h(P 1,1 , . . . , P K,m , Q 1,1 , . . . , Q K,n ) = 1 ( = 0). From Lemma 6, we then see that the zero set of h has measure zero, and hence, Pr(rank(\u0393) = mn) = 0.\n\n\nVI. SYSTEMATIC KHATRI-RAO-PRODUCT CODES\n\nIn this section, we introduce a systematic construction of random Khatri-Rao-Product codes which reduces the average encoding and decoding complexities compared to its non-systematic counterpart.\n\n\nA. Encoding:\n\nIn systematic encoding, the first K worker nodes are simply given the submatrices A T j and B l without encoding and the other N \u2212 K worker nodes are given encoded versions as in the non-systematic version.\n\nFor i \u2208 {1, . . . , K = mn}, let i \u2032 = \u2308i/n\u2309 and i \u2032\u2032 = ((i \u2212 1) mod n) + 1. The encoding process can be described as below\nU T i = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 A T i \u2032 , i \u2208 [K], m j=1 p i\u2212K,j A T j , K + 1 \u2264 i \u2264 N,(15)V i = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 B i \u2032\u2032 , i \u2208 [K], n l=1 q i\u2212K,l B l , K + 1 \u2264 i \u2264 N,(16)\nwhere p i,j , q i,j are realizations of P i,j , Q i,j which are absolutely continuous random variables with respect to the Lebesgue measure. U i and V i are then transmitted to the ith worker node which is tasked with\ncomputing X i = U T i V i .\nWe will refer to worker nodes 1, 2, . . . , K as systematic worker nodes and we will refer to worker nodes K + 1, . . . , N as parity worker nodes.\n\nAs in the case of non-systematic encoding, we focus on the recovery of the (1, 1)th entry of A T j B l , namely [A T j B l ] 1,1 . The same idea extends to the recovery of other indices as well. Let y i = [X i ] 1,1 denote the (1, 1)th entry in the matrix product computed by the ith non-straggler worker node and let\nz j,l = [A T j B l ] 1,1 . For j \u2208 [mn]\n, let j \u2032 = \u2308j/n\u2309 and j \u2032\u2032 = ((j \u2212 1) mod n) + 1 and let w j = z j \u2032 ,j \u2032\u2032 . The computed values y i 's are related to the unknown values w j 's according to \n\uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 y 1 y 2 . . . y K y K+1 . . . y N \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 1 0 . . . 0 . . . 0 0 1 . . . 0 . . . 0 . . .\uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w 1 w 2 . . . w j . . . w K \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb ,(17)\nwhere S = N \u2212 K.\n\nThe generator matrix in (17) can be written as [I K\u00d7K F T ] T where F is an N \u2212 K \u00d7 K matrix whose ith row is given by p i \u2299 q i , i.e., 1 q 1,1 p 1,1 q 1 (17) where P i,j , Q i,j \u223c f will be referred to as the systematic random Khatri-Rao-product generator matrix ensemble G sys (N, K, f ).\nF = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 p 1,\n\nB. Decoding\n\nWe consider the case when there are S 1 stragglers among the systematic worker nodes and S 2 = S \u2212S 1 stragglers among the parity worker nodes. Without loss of generality we assume that the stragglers are the worker nodes 1, 2, . . . , S 1 and K+S 1 +1, . . . , N . This implies that the master nodes obtains y S1+1 , . . . , y K and since the encoding is systematic, the master node can trivially recover w S1+1 , . . . , w K by setting w i = y i for i = S 1 + 1, . . . , S K . We can recover w 1 , . . . , w S1 from y K+1 , . . . , y K+S1 as follows. Notice\nthat \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 y K+1 y K+2 . . . y K+S1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = [F] K+1:K+S1,1:S1 \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w 1 w 2 . . . w S1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb (19) + [F] K+1:K+S1,S1+1:K \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w S1+1 w S1+2 . . . w K \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb ,(20)\nwhich in turn implies that \uf8ee\n\uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 y K+1 y K+2 . . . y K+S1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \u2212 [F] K+1:K+S1,S1+1:K \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w S1+1 w S1+2 . . . w K \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb y (21) = [F] K+1:K+S1,1:S1 Gsys \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w 1 w 2 . . . w S1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb w ,\nor more succinctly,\ny = G sys w.(22)\nWe can obtain an estimate of w, namely\u0175, a\u015d\nw = G \u22121 sys y.(23)\nNote that in the above description it is assumed that the stragglers were worker nodes 1, 2, . . . , S and K + S 1 + 1, . . . , N . However, the same ideas can be used for arbitrary sets of stragglers. The following example will clarify this.\n\nExample 9. Consider an example with m = 2, n = 3, K = 6 with N = 10 worker nodes. Let the straggler nodes be the worker nodes 2,4,5, and 8. In this case, we first recover w 1 , w 3 , w 6 by setting w 1 = y 1 , w 3 = y 3 and w 6 = y 6 . Then, we recover w 2 , w 4 , and w 5 from w 1 , w 3 , w 6 , y 7 , y 9 , y 10 using \uf8ee\n\uf8ef \uf8ef \uf8ef \uf8f0 y 7 y 9 y 10 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb \u2212 [F] {7,8,9},{1,3,6} \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 w 1 w 3 w 6 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb = [F] {7,8,9},{2,4,5} \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 w 2 w 4 w 5 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb .(24)\nWe show that if a generator matrix is chosen at random from the systematic RKRP ensemble G sys (N, K, f ), the encoding scheme in (17) result in an MDS code with probability 1.\n\nTheorem 10. Systematic RKRP codes are MDS codes with probability 1.\n\nProof. To prove the theorem, we need to prove that G sys is full rank with probability 1. The proof follows along the same lines as the proof of Theorem 7.\n\n\nVII. REVIEW OF ORTHOPOLY CODES\n\nIn this section, we will briefly review OrthoPoly codes for the sake of completeness. Details can be found in [2]. The encoding scheme consists of the master node dividing the matrices A and B as in Section III and subsequently computing\nu T i = m\u22121 j=1 T j (x i )A T j , v i = n\u22121 j=1 T jm (x i )B j\nwhere T r (x) = cos(r(cos \u22121 (x))) and x i = cos( (2i\u22121)\u03c0 2N ), and sending u T i and v i to the ith worker node. The ith worker node computes u T i v i and sends the result back the master node for decoding. Let us assume that worker nodes i = 1, . . . , K (K is defined as K mn) return their outputs. As before, we focus on the recovery of\n[A T i B j ] 1,1 . If y i = [u T i v i ] 1,1 , then \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 y 1 y 2 . . . y i . . . y K \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb y = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 T 0 (x 1 ) \u00b7 \u00b7 \u00b7 T K\u22121 (x 1 ) . . . . . . . . . T 0 (x K ) \u00b7 \u00b7 \u00b7 T K\u22121 (x K ) \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb GO H \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 w 1 w 2 . . . w j . . . w K \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb w(25)\nwhere H is a K \u00d7 K matrix such that\nH (r,(i\u22121)+(j\u22121)m+1) = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 1, r = (i \u2212 1) + (j \u2212 1)m + 1, i = 1, j \u2208 [n] 1 2 , r = (i \u2212 1) + (j \u2212 1)m + 1, i = 1, i \u2208 [m], j \u2208 [n] 1 2 , r = |(i \u2212 1) \u2212 (j \u2212 1)m| + 1, i = 1, i \u2208 [m], j \u2208 [n] 0, otherwise.\nAn estimate of w ( w i = [A j B l ] 1,1 such that i = r + lm + 1, for 0 \u2264 r \u2264 m \u2212 1 and 0 \u2264 l \u2264 n \u2212 1) is then obtained according to\u0175 Hence, the decoding complexity of OrthoPoly codes involves inverting a K \u00d7K matrix followed by N1N3 mn multiplication of a K \u00d7 K matrix and a K \u00d7 1 vector. The overall complexity is hence O(K 3 + K 2 N1N3 mn ). Since S 1 \u2264 K, the average decoding complexity for systematic RKRP codes is lower than that of OrthoPoly codes and the worst-case complexities (when S 1 = K) are identical.\n= H \u22121 G \u22121 O y.(26)\n\nIX. SIMULATION RESULTS\n\nWe now present simulation results to demonstrate the superior numerical stability of RKRP codes. We performed Monte Carlo simulations of the encoding and decoding process by choosing the entries of A and B to be realizations of i.i.d Gaussian random variables with zero mean and unit variance. For the presented results, we have considered the recovery of the (1, 1)th entry of A T j B l . The corresponding vector w is then a realization of the vector-valued random variable W . Then, we computed y using (8), (17), and (25) for non-systematic RKRP codes, systematic RKRP codes, and OrthoPoly codes, respectively. We randomly chose a subset of N \u2212 K worker nodes to be stragglers. Then, we computed w using (11), (23), (26) for non-systematic RKRP codes, systematic RKRP codes, and OrthoPoly codes, respectively. For each of these codes, we define the average relative error to be \u03b7 ave := E ||W \u2212\u0174 || 2 ||W || 2 and we estimate \u03b7 ave from Monte Carlo simulations.\n\n\nA. MDS property\n\nFirstly, in several million simulations, we never observed any instance where the generator matrix G in (8) or G sys in (21) was singular, which provides empirical evidence to our claim that non-systematic and systematic RKRP codes are MDS codes with probability 1.\n\n\nB. Average relative error\n\nIn Fig. 1, we plot the average relative error as a function of N when the total number of worker nodes is set to be N = \u2308K/(1 \u2212 \u03b1)\u2309 or K = \u230aN (1 \u2212 \u03b1)\u230b. This model is meaningful when we consider practical scenarios where each worker node fails with a fixed probability. In the plots in Fig. 1, \u03b1 is fixed and K and N are varied. The results are shown for \u03b1 = 0.1 and for OrthoPoly codes, non-systematic RKRP codes, and systematic RKRP codes. It can be seen that the average relative error is several orders of magnitude lower for RKRP codes when N is about 100. OrthoPoly codes. It should also be noted that the average relative error remains largely independent of \u03b1 for RKRP codes whereas they grow rapidly with \u03b1 for OrthoPoly codes.\n\nIn Figure 3, we plot the average relative error versus the number of straggler nodes S for a fixed K when N = K + S. It can be seen that the proposed RKRP codes provide excellent robustness even as the number of stragglers increases.\n\n\nC. Average log condition number\n\nThe expected value of the logarithm of the condition number of a random matrix is a measure of loss in precision in computing the inverse of the determinant of the matrix, when the matrix is chosen from an underlying ensemble [14]. We computed the expected value of the logarithm of the condition number of we chose G sys from the G sys (N, K, f ) ensemble, and for OrthoPoly codes, we randomly chose K \u00d7 K submatrices of G O and multiplied the matrix by H. In Figure 4, we plot the average of the log of the condition number as a function of \u03b1 for the three ensembles. We fix K and let N = K(1 + \u03b1).\n\nIt can be seen that the average of the log of the condition number is substantially lower for RKRP codes than for Orthopoly codes showing that the number of bits of precision lost is substantially lower for RKRP codes. We proposed a new class of codes called random Khatri-Rao-product (RKRP) codes for which the generator matrix is the row-wise Khatri-Rao product of two random matrices. We proposed two random ensembles of generator matrices and corresponding codes called non-systematic RKRP codes and systematic RKRP codes. We showed that RKRP codes are maximum distance separable with probability 1 and that their decoding is substantially more numerically stable than Polynomial codes and OrthoPoly codes. The average decoding complexity of RKRP codes is lower than that of OrthoPoly codes.\n\nDefinition 1 .\n1An encoding scheme is a mapping from (A T 1 , . . . ,A T m , B 1 , . . . , B n ) to {(X i = U T i , V i )} for i = 1, . . . , N . A codeword is a vector of matrices X = [X 1 , X 2 , . . . , X N ]. Acode is the set of possible codewords {X}. Definition 2. An encoding scheme is said to result in a maximum distance separable (MDS) code, or the corresponding code is said to be MDS, if the set of matrix products {A T i B j } for i = 1, . . . , m and j = 1, . . . , n can be computed (recovered) from any subset of {X 1 , X 2 , . . . , X N } of size mn, where\n\nLemma 6 .\n6Consider an analytic function h(x) of several real variables x = [x 1 , x 2 , \u00b7 \u00b7 \u00b7 , x n ] \u2208 \u00ca n . If h(x) is nontrivial in the sense that there exists x 0 \u2208 \u00ca n such that h(x 0 ) = 0 then the zero set of h(x),Z = {x \u2208 \u00ca n | h(x) = 0}July 16, 2019 DRAFT is of measure (Lebesgue measure in \u00ca n ) zero.\n\n\n{P i,j } i\u2208[K],j\u2208[m] and {Q i,j } i\u2208[K],j\u2208[n] with degree 2mn. Let det(\u0393) = h(P 1,1 , . . . , P K,m , Q 1,1 , . . . , Q K,n )\n\n\n1,1 p 1,1 q 1,2 . . . p 1,1 q 1,n . . . p 1m q 1,n p 2,1 q 2,1 p 2,1 q 2,2 . . . p 2,1 q 2,n . . . p 2m q 2,n . . . p S,1 q S,1 p S,1 q S,2 . . . p S,1 q S,n . . . p S,m q S,n\n\n. 1 ,Fig. 1 :\n11OrthoPoly codes \u03b1 = 0.1, Non-systematic RKP codes \u03b1 = 0.1, Systematic RKP codes Plot of average relative error as a function of N for a fixed \u03b1; N = \u2308K/(1 \u2212 \u03b1)\u2309 In Figure 2, we plot the average relative error versus \u03b1 = N \u2212K N for a fixed K. Again, it can be seen that the proposed RKRP codes are very robust to numerical precision errors and substantially outperform\n\nFig. 2 :KFig. 3 :\n23OrthoPoly codes K = 49, Non-systematic RKP codes K = 49, Systematic RKP codes Plot of average relative error versus fraction of straggler nodes (\u03b1) for K = 49; \u03b1 = = 49, OrthoPoly codes K = 49, Non-systematic RKP codes K = 49, Systematic RKP codes Plot of average relative error versus number of stragglers (S) for K = 49; N = K + S matrices from three ensembles. For non-systematic RKRP codes, we chose G from the G non\u2212sys (N, K, f ) ensemble where f is a Gaussian density with zero mean and unit variance. For systematic RKRP codes,\n\nFig. 4 :\n4OrthoPoly codes K = 49, Non-systematic RKP codes K = 49, Systematic RKP codes Plot of E[log(condition number)] of inverted matrix versus fraction of straggler nodes (\n\n\na fair comparison with Polynomial and OrthoPoly codes. The proofs are also easier to follow when presented for the non-systematic ensemble first and then extended to the systematic ensemble. Finally, non-systematically RKRP codes provide privacy which systematic RKRP codes do not, although this issue is not studied further in this paper.II. NOTATIONWe use boldface capital letters for matrices and underlined variables to represent vectors. We denote the i, jth element of the matrix A by [A] i,j . The ith row and ith column of matrix A will be represented by [A] i,: and [A] :,i , respectively. If S 1 \u2282 Z + and S 2 \u2282 Z + are two subsets of positive integers, then\n\n\n,2 . . . p 1,1 q 1,n . . . p 1m q 1,np 2,1 q 2,1 p 2,1 q 2,2 . . . p 2,1 q 2,n . . . p 2m q 2,n \n. . . \n\np S,1 q S,1 p S,1 q S,2 . . . p S,1 q S,n . . . p S,m q S,n \n\n\uf8f9 \n\n\uf8fa \n\uf8fa \n\uf8fa \n\uf8fa \n\uf8fa \n\uf8fa \n\uf8fb \n\n. \n(18) \n\nDefinition 8. The ensemble of N \u00d7 K generator matrices obtained by choosing the generator matrix G \n\nas in \n\n\nVIII. DECODING COMPLEXITIESIn this section, we briefly discuss the decoding complexity of systematic RKRP codes and OrthoPoly codes. Decoding of systematic RKRP codes involves two steps. It involves inversion of the S 1 \u00d7 S 1 OrthoPoly codes cannot be easily implemented in systematic form because of the multiplication by H.matrix G sys in (22) whose complexity is O(S 3 \n1 ). To retrieve every entry of [A T \nj B l ], we need to multiply \nG \u22121 \nsys and y which requires O(S 2 \n1 ) operations. This step needs to be repeated for each of the N1N3 \nmn entries \nof [A T \nj B l ] and hence, the overall decoding complexity is O(S 3 \n1 + S 2 \n\n1 \nN1N3 \n\nmn ). \n\nThis is not the most general form of encoding but many of the existing encoding schemes in the literature as well as the proposed scheme can be represented in this way.July 16, 2019 DRAFT\nJuly 16, 2019 DRAFT\n\nPolynomial codes: an optimal design for high-dimensional coded matrix multiplication. Q Yu, M A Maddah-Ali, A S Avestimehr, arXiv:1705.10464Q. Yu, M. A. Maddah-Ali, and A. S. Avestimehr, \"Polynomial codes: an optimal design for high-dimensional coded matrix multiplication,\" arXiv:1705.10464, 2018.\n\nNumerically stable polynomially coded computing. M Fahim, V Cadambe, of the International Symposium on Information Theory. in to appear in proceedingsM. Fahim and V. Cadambe, \"Numerically stable polynomially coded computing,\" in to appear in proceedings of the International Symposium on Information Theory, 2019.\n\nStraggler mitigation in distributed matrix multiplication: Fundamental limits and optimal coding. Q Yu, M A Maddah-Ali, A S Avestimehr, arXiv:1801.07487Q. Yu, M. A. Maddah-Ali, and A. S. Avestimehr, \"Straggler mitigation in distributed matrix multiplication: Fundamental limits and optimal coding,\" arXiv:1801.07487, 2018.\n\nA unified coded deep neural network training strategy based on generalized polydot codes for matrix multiplication. S Dutta, Z Bai, H Jeong, T M Low, P Grover, arXiv:1811.10751S. Dutta, Z. Bai, H. Jeong, T. M. Low, and P. Grover, \"A unified coded deep neural network training strategy based on generalized polydot codes for matrix multiplication,\" arXiv:1811.10751, 2018.\n\nUniversally decodable matrices for distributed matrix-vector multiplication. A Ramamoorthy, L Tang, P O Vontobel, arXiv:1901.10674A. Ramamoorthy, L. Tang, and P. O. Vontobel, \"Universally decodable matrices for distributed matrix-vector multiplication,\" arXiv:1901.10674, 2019.\n\nLagrange coded computing: Optimal design for resiliency, security and privacy. Q Yu, N Raviv, J So, A S Avestimehr, arXiv:1806.00939Q. Yu, N. Raviv, J. So, and A. S. Avestimehr, \"Lagrange coded computing: Optimal design for resiliency, security and privacy,\" arXiv:1806.00939, 2018.\n\nSpeeding up distributed machine learning using codes. K Lee, M Lam, R Pedarsani, D S Papailiopoulos, K Ramchandran, arXiv:1512.02673K. Lee, M. Lam, R. Pedarsani, D. S. Papailiopoulos, and K. Ramchandran, \"Speeding up distributed machine learning using codes,\" arXiv:1512.02673, 2015.\n\n. S Dutta, V R Cadambe, P Grover, arXiv:1704.05181short-dot\": Computing large linear transforms distributedly using coded short dot productsS. Dutta, V. R. Cadambe, and P. Grover, \"\"short-dot\": Computing large linear transforms distributedly using coded short dot products,\" arXiv:1704.05181, 2017.\n\nA unified coding framework for distributed computing with straggling servers. S Li, M A Maddah-Ali, A S Avestimehr, 2016 IEEE Globecom Workshops. S. Li, M. A. Maddah-Ali, and A. S. Avestimehr, \"A unified coding framework for distributed computing with straggling servers,\" in 2016 IEEE Globecom Workshops, Dec 2016, pp. 1-6.\n\nHigh-dimensional coded matrix multiplication. K Lee, C Suh, K Ramchandran, 2017 IEEE International Symposium on Information Theory (ISIT). K. Lee, C. Suh, and K. Ramchandran, \"High-dimensional coded matrix multiplication,\" in 2017 IEEE International Symposium on Information Theory (ISIT), June 2017, pp. 2418-2422.\n\nCoded distributed computing: Straggling servers and multistage dataflows. S Li, M A Maddah-Ali, A S Avestimehr, 2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton). S. Li, M. A. Maddah-Ali, and A. S. Avestimehr, \"Coded distributed computing: Straggling servers and multistage dataflows,\" in 2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton), Sep. 2016, pp. 164-171.\n\nCoded distributed computing for inverse problems. Y Yang, P Grover, S Kar, Advances in Neural Information Processing Systems. 30Y. Yang, P. Grover, and S. Kar, \"Coded distributed computing for inverse problems,\" in Advances in Neural Information Processing Systems 30, 2017, pp. 709-719.\n\nAlmost-sure identifiability of multidimensional harmonic retrieval. T Jiang, N D Sidiropoulos, J M Berge, IEEE Transactions on Signal Processing. 499T. Jiang, N. D. Sidiropoulos, and J. M. ten Berge, \"Almost-sure identifiability of multidimensional harmonic retrieval,\" IEEE Transactions on Signal Processing, vol. 49, no. 9, pp. 1849-1859, 2001.\n\nEigenvalues and condition numbers of random matrices. A Edelman, SIAM Journal on Matrix Analysis and Applications. 94A. Edelman, \"Eigenvalues and condition numbers of random matrices,\" SIAM Journal on Matrix Analysis and Applications, vol. 9, no. 4, pp. 543-560, 1988.\n", "annotations": {"author": "[{\"end\":197,\"start\":103},{\"end\":292,\"start\":198},{\"end\":386,\"start\":293}]", "publisher": null, "author_last_name": "[{\"end\":123,\"start\":112},{\"end\":218,\"start\":207},{\"end\":312,\"start\":303}]", "author_first_name": "[{\"end\":109,\"start\":103},{\"end\":111,\"start\":110},{\"end\":206,\"start\":198},{\"end\":300,\"start\":293},{\"end\":302,\"start\":301}]", "author_affiliation": "[{\"end\":196,\"start\":125},{\"end\":291,\"start\":220},{\"end\":385,\"start\":314}]", "title": "[{\"end\":89,\"start\":1},{\"end\":475,\"start\":387}]", "venue": null, "abstract": "[{\"end\":1311,\"start\":516}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1526,\"start\":1523},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1531,\"start\":1528},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1537,\"start\":1533},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1545,\"start\":1542},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2589,\"start\":2586},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3477,\"start\":3474},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3501,\"start\":3498},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5055,\"start\":5054},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":19110,\"start\":19107},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21365,\"start\":21362},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21948,\"start\":21945},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":23372,\"start\":23368}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":25114,\"start\":24540},{\"attributes\":{\"id\":\"fig_1\"},\"end\":25428,\"start\":25115},{\"attributes\":{\"id\":\"fig_2\"},\"end\":25556,\"start\":25429},{\"attributes\":{\"id\":\"fig_3\"},\"end\":25734,\"start\":25557},{\"attributes\":{\"id\":\"fig_4\"},\"end\":26119,\"start\":25735},{\"attributes\":{\"id\":\"fig_5\"},\"end\":26676,\"start\":26120},{\"attributes\":{\"id\":\"fig_6\"},\"end\":26854,\"start\":26677},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":27525,\"start\":26855},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":27838,\"start\":27526},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":28498,\"start\":27839}]", "paragraph": "[{\"end\":2231,\"start\":1347},{\"end\":2551,\"start\":2233},{\"end\":3249,\"start\":2553},{\"end\":3647,\"start\":3251},{\"end\":4377,\"start\":3649},{\"end\":4956,\"start\":4379},{\"end\":5625,\"start\":4958},{\"end\":5928,\"start\":5640},{\"end\":6266,\"start\":5968},{\"end\":6559,\"start\":6356},{\"end\":6971,\"start\":6664},{\"end\":7204,\"start\":6990},{\"end\":7278,\"start\":7238},{\"end\":7461,\"start\":7360},{\"end\":7853,\"start\":7526},{\"end\":8000,\"start\":7855},{\"end\":8307,\"start\":8082},{\"end\":8377,\"start\":8327},{\"end\":8771,\"start\":8465},{\"end\":8897,\"start\":8799},{\"end\":9767,\"start\":9385},{\"end\":10005,\"start\":9906},{\"end\":10269,\"start\":10247},{\"end\":10494,\"start\":10440},{\"end\":10562,\"start\":10543},{\"end\":10707,\"start\":10577},{\"end\":11089,\"start\":10709},{\"end\":11629,\"start\":11414},{\"end\":12172,\"start\":11742},{\"end\":12255,\"start\":12189},{\"end\":12527,\"start\":12272},{\"end\":12616,\"start\":12555},{\"end\":13006,\"start\":12618},{\"end\":13078,\"start\":13008},{\"end\":13360,\"start\":13080},{\"end\":13766,\"start\":13672},{\"end\":13923,\"start\":13768},{\"end\":14400,\"start\":13925},{\"end\":14639,\"start\":14444},{\"end\":14862,\"start\":14656},{\"end\":14987,\"start\":14864},{\"end\":15355,\"start\":15138},{\"end\":15531,\"start\":15384},{\"end\":15850,\"start\":15533},{\"end\":16049,\"start\":15891},{\"end\":16385,\"start\":16369},{\"end\":16678,\"start\":16387},{\"end\":17277,\"start\":16718},{\"end\":17528,\"start\":17500},{\"end\":17768,\"start\":17749},{\"end\":17829,\"start\":17786},{\"end\":18092,\"start\":17850},{\"end\":18414,\"start\":18094},{\"end\":18736,\"start\":18560},{\"end\":18805,\"start\":18738},{\"end\":18962,\"start\":18807},{\"end\":19234,\"start\":18997},{\"end\":19639,\"start\":19298},{\"end\":20008,\"start\":19973},{\"end\":20809,\"start\":20292},{\"end\":21821,\"start\":20856},{\"end\":22106,\"start\":21841},{\"end\":22871,\"start\":22136},{\"end\":23106,\"start\":22873},{\"end\":23742,\"start\":23142},{\"end\":24539,\"start\":23744}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5639,\"start\":5626},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6355,\"start\":6267},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6663,\"start\":6560},{\"attributes\":{\"id\":\"formula_3\"},\"end\":6989,\"start\":6972},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7237,\"start\":7205},{\"attributes\":{\"id\":\"formula_5\"},\"end\":7501,\"start\":7462},{\"attributes\":{\"id\":\"formula_6\"},\"end\":7525,\"start\":7501},{\"attributes\":{\"id\":\"formula_7\"},\"end\":8081,\"start\":8001},{\"attributes\":{\"id\":\"formula_8\"},\"end\":8326,\"start\":8308},{\"attributes\":{\"id\":\"formula_9\"},\"end\":8464,\"start\":8378},{\"attributes\":{\"id\":\"formula_10\"},\"end\":8798,\"start\":8772},{\"attributes\":{\"id\":\"formula_11\"},\"end\":9384,\"start\":8898},{\"attributes\":{\"id\":\"formula_12\"},\"end\":9905,\"start\":9768},{\"attributes\":{\"id\":\"formula_13\"},\"end\":10246,\"start\":10006},{\"attributes\":{\"id\":\"formula_14\"},\"end\":10439,\"start\":10270},{\"attributes\":{\"id\":\"formula_15\"},\"end\":10542,\"start\":10495},{\"attributes\":{\"id\":\"formula_16\"},\"end\":10576,\"start\":10563},{\"attributes\":{\"id\":\"formula_17\"},\"end\":11413,\"start\":11090},{\"attributes\":{\"id\":\"formula_18\"},\"end\":11741,\"start\":11630},{\"attributes\":{\"id\":\"formula_19\"},\"end\":12271,\"start\":12256},{\"attributes\":{\"id\":\"formula_20\"},\"end\":12554,\"start\":12528},{\"attributes\":{\"id\":\"formula_21\"},\"end\":13671,\"start\":13361},{\"attributes\":{\"id\":\"formula_23\"},\"end\":15065,\"start\":14988},{\"attributes\":{\"id\":\"formula_24\"},\"end\":15137,\"start\":15065},{\"attributes\":{\"id\":\"formula_25\"},\"end\":15383,\"start\":15356},{\"attributes\":{\"id\":\"formula_26\"},\"end\":15890,\"start\":15851},{\"attributes\":{\"id\":\"formula_27\"},\"end\":16239,\"start\":16050},{\"attributes\":{\"id\":\"formula_28\"},\"end\":16368,\"start\":16239},{\"attributes\":{\"id\":\"formula_29\"},\"end\":16703,\"start\":16679},{\"attributes\":{\"id\":\"formula_30\"},\"end\":17499,\"start\":17278},{\"attributes\":{\"id\":\"formula_31\"},\"end\":17748,\"start\":17529},{\"attributes\":{\"id\":\"formula_32\"},\"end\":17785,\"start\":17769},{\"attributes\":{\"id\":\"formula_33\"},\"end\":17849,\"start\":17830},{\"attributes\":{\"id\":\"formula_34\"},\"end\":18559,\"start\":18415},{\"attributes\":{\"id\":\"formula_35\"},\"end\":19297,\"start\":19235},{\"attributes\":{\"id\":\"formula_36\"},\"end\":19972,\"start\":19640},{\"attributes\":{\"id\":\"formula_37\"},\"end\":20291,\"start\":20009},{\"attributes\":{\"id\":\"formula_38\"},\"end\":20830,\"start\":20810}]", "table_ref": null, "section_header": "[{\"end\":1345,\"start\":1313},{\"end\":5966,\"start\":5931},{\"end\":7343,\"start\":7281},{\"end\":7358,\"start\":7346},{\"end\":12187,\"start\":12175},{\"end\":14442,\"start\":14403},{\"end\":14654,\"start\":14642},{\"end\":16716,\"start\":16705},{\"end\":18995,\"start\":18965},{\"end\":20854,\"start\":20832},{\"end\":21839,\"start\":21824},{\"end\":22134,\"start\":22109},{\"end\":23140,\"start\":23109},{\"end\":24555,\"start\":24541},{\"end\":25125,\"start\":25116},{\"end\":25749,\"start\":25736},{\"end\":26138,\"start\":26121},{\"end\":26686,\"start\":26678}]", "table": "[{\"end\":27838,\"start\":27565},{\"end\":28498,\"start\":28166}]", "figure_caption": "[{\"end\":25114,\"start\":24557},{\"end\":25428,\"start\":25127},{\"end\":25556,\"start\":25431},{\"end\":25734,\"start\":25559},{\"end\":26119,\"start\":25752},{\"end\":26676,\"start\":26141},{\"end\":26854,\"start\":26688},{\"end\":27525,\"start\":26857},{\"end\":27565,\"start\":27528},{\"end\":28166,\"start\":27841}]", "figure_ref": "[{\"end\":12171,\"start\":12161},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16541,\"start\":16524},{\"end\":16677,\"start\":16667},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22145,\"start\":22139},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22427,\"start\":22421},{\"end\":22884,\"start\":22876},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":23611,\"start\":23603}]", "bib_author_first_name": "[{\"end\":28795,\"start\":28794},{\"end\":28801,\"start\":28800},{\"end\":28803,\"start\":28802},{\"end\":28817,\"start\":28816},{\"end\":28819,\"start\":28818},{\"end\":29058,\"start\":29057},{\"end\":29067,\"start\":29066},{\"end\":29422,\"start\":29421},{\"end\":29428,\"start\":29427},{\"end\":29430,\"start\":29429},{\"end\":29444,\"start\":29443},{\"end\":29446,\"start\":29445},{\"end\":29764,\"start\":29763},{\"end\":29773,\"start\":29772},{\"end\":29780,\"start\":29779},{\"end\":29789,\"start\":29788},{\"end\":29791,\"start\":29790},{\"end\":29798,\"start\":29797},{\"end\":30098,\"start\":30097},{\"end\":30113,\"start\":30112},{\"end\":30121,\"start\":30120},{\"end\":30123,\"start\":30122},{\"end\":30379,\"start\":30378},{\"end\":30385,\"start\":30384},{\"end\":30394,\"start\":30393},{\"end\":30400,\"start\":30399},{\"end\":30402,\"start\":30401},{\"end\":30638,\"start\":30637},{\"end\":30645,\"start\":30644},{\"end\":30652,\"start\":30651},{\"end\":30665,\"start\":30664},{\"end\":30667,\"start\":30666},{\"end\":30685,\"start\":30684},{\"end\":30871,\"start\":30870},{\"end\":30880,\"start\":30879},{\"end\":30882,\"start\":30881},{\"end\":30893,\"start\":30892},{\"end\":31247,\"start\":31246},{\"end\":31253,\"start\":31252},{\"end\":31255,\"start\":31254},{\"end\":31269,\"start\":31268},{\"end\":31271,\"start\":31270},{\"end\":31541,\"start\":31540},{\"end\":31548,\"start\":31547},{\"end\":31555,\"start\":31554},{\"end\":31886,\"start\":31885},{\"end\":31892,\"start\":31891},{\"end\":31894,\"start\":31893},{\"end\":31908,\"start\":31907},{\"end\":31910,\"start\":31909},{\"end\":32305,\"start\":32304},{\"end\":32313,\"start\":32312},{\"end\":32323,\"start\":32322},{\"end\":32612,\"start\":32611},{\"end\":32621,\"start\":32620},{\"end\":32623,\"start\":32622},{\"end\":32639,\"start\":32638},{\"end\":32641,\"start\":32640},{\"end\":32946,\"start\":32945}]", "bib_author_last_name": "[{\"end\":28798,\"start\":28796},{\"end\":28814,\"start\":28804},{\"end\":28830,\"start\":28820},{\"end\":29064,\"start\":29059},{\"end\":29075,\"start\":29068},{\"end\":29425,\"start\":29423},{\"end\":29441,\"start\":29431},{\"end\":29457,\"start\":29447},{\"end\":29770,\"start\":29765},{\"end\":29777,\"start\":29774},{\"end\":29786,\"start\":29781},{\"end\":29795,\"start\":29792},{\"end\":29805,\"start\":29799},{\"end\":30110,\"start\":30099},{\"end\":30118,\"start\":30114},{\"end\":30132,\"start\":30124},{\"end\":30382,\"start\":30380},{\"end\":30391,\"start\":30386},{\"end\":30397,\"start\":30395},{\"end\":30413,\"start\":30403},{\"end\":30642,\"start\":30639},{\"end\":30649,\"start\":30646},{\"end\":30662,\"start\":30653},{\"end\":30682,\"start\":30668},{\"end\":30697,\"start\":30686},{\"end\":30877,\"start\":30872},{\"end\":30890,\"start\":30883},{\"end\":30900,\"start\":30894},{\"end\":31250,\"start\":31248},{\"end\":31266,\"start\":31256},{\"end\":31282,\"start\":31272},{\"end\":31545,\"start\":31542},{\"end\":31552,\"start\":31549},{\"end\":31567,\"start\":31556},{\"end\":31889,\"start\":31887},{\"end\":31905,\"start\":31895},{\"end\":31921,\"start\":31911},{\"end\":32310,\"start\":32306},{\"end\":32320,\"start\":32314},{\"end\":32327,\"start\":32324},{\"end\":32618,\"start\":32613},{\"end\":32636,\"start\":32624},{\"end\":32647,\"start\":32642},{\"end\":32954,\"start\":32947}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1705.10464\",\"id\":\"b0\"},\"end\":29006,\"start\":28708},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":84187068},\"end\":29321,\"start\":29008},{\"attributes\":{\"doi\":\"arXiv:1801.07487\",\"id\":\"b2\"},\"end\":29645,\"start\":29323},{\"attributes\":{\"doi\":\"arXiv:1811.10751\",\"id\":\"b3\"},\"end\":30018,\"start\":29647},{\"attributes\":{\"doi\":\"arXiv:1901.10674\",\"id\":\"b4\"},\"end\":30297,\"start\":30020},{\"attributes\":{\"doi\":\"arXiv:1806.00939\",\"id\":\"b5\"},\"end\":30581,\"start\":30299},{\"attributes\":{\"doi\":\"arXiv:1512.02673\",\"id\":\"b6\"},\"end\":30866,\"start\":30583},{\"attributes\":{\"doi\":\"arXiv:1704.05181\",\"id\":\"b7\"},\"end\":31166,\"start\":30868},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":12990675},\"end\":31492,\"start\":31168},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6938356},\"end\":31809,\"start\":31494},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":14254924},\"end\":32252,\"start\":31811},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":8562588},\"end\":32541,\"start\":32254},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":16093880},\"end\":32889,\"start\":32543},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":120665672},\"end\":33159,\"start\":32891}]", "bib_title": "[{\"end\":29055,\"start\":29008},{\"end\":31244,\"start\":31168},{\"end\":31538,\"start\":31494},{\"end\":31883,\"start\":31811},{\"end\":32302,\"start\":32254},{\"end\":32609,\"start\":32543},{\"end\":32943,\"start\":32891}]", "bib_author": "[{\"end\":28800,\"start\":28794},{\"end\":28816,\"start\":28800},{\"end\":28832,\"start\":28816},{\"end\":29066,\"start\":29057},{\"end\":29077,\"start\":29066},{\"end\":29427,\"start\":29421},{\"end\":29443,\"start\":29427},{\"end\":29459,\"start\":29443},{\"end\":29772,\"start\":29763},{\"end\":29779,\"start\":29772},{\"end\":29788,\"start\":29779},{\"end\":29797,\"start\":29788},{\"end\":29807,\"start\":29797},{\"end\":30112,\"start\":30097},{\"end\":30120,\"start\":30112},{\"end\":30134,\"start\":30120},{\"end\":30384,\"start\":30378},{\"end\":30393,\"start\":30384},{\"end\":30399,\"start\":30393},{\"end\":30415,\"start\":30399},{\"end\":30644,\"start\":30637},{\"end\":30651,\"start\":30644},{\"end\":30664,\"start\":30651},{\"end\":30684,\"start\":30664},{\"end\":30699,\"start\":30684},{\"end\":30879,\"start\":30870},{\"end\":30892,\"start\":30879},{\"end\":30902,\"start\":30892},{\"end\":31252,\"start\":31246},{\"end\":31268,\"start\":31252},{\"end\":31284,\"start\":31268},{\"end\":31547,\"start\":31540},{\"end\":31554,\"start\":31547},{\"end\":31569,\"start\":31554},{\"end\":31891,\"start\":31885},{\"end\":31907,\"start\":31891},{\"end\":31923,\"start\":31907},{\"end\":32312,\"start\":32304},{\"end\":32322,\"start\":32312},{\"end\":32329,\"start\":32322},{\"end\":32620,\"start\":32611},{\"end\":32638,\"start\":32620},{\"end\":32649,\"start\":32638},{\"end\":32956,\"start\":32945}]", "bib_venue": "[{\"end\":28792,\"start\":28708},{\"end\":29129,\"start\":29077},{\"end\":29419,\"start\":29323},{\"end\":29761,\"start\":29647},{\"end\":30095,\"start\":30020},{\"end\":30376,\"start\":30299},{\"end\":30635,\"start\":30583},{\"end\":31312,\"start\":31284},{\"end\":31631,\"start\":31569},{\"end\":32011,\"start\":31923},{\"end\":32378,\"start\":32329},{\"end\":32687,\"start\":32649},{\"end\":33004,\"start\":32956}]"}}}, "year": 2023, "month": 12, "day": 17}