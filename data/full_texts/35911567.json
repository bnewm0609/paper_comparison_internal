{"id": 35911567, "updated": "2023-09-28 11:54:45.96", "metadata": {"title": "Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models", "authors": "[{\"first\":\"Gabriel\",\"last\":\"Guimaraes\",\"middle\":[\"Lima\"]},{\"first\":\"Benjamin\",\"last\":\"Sanchez-Lengeling\",\"middle\":[]},{\"first\":\"Pedro\",\"last\":\"Farias\",\"middle\":[\"Luis\",\"Cunha\"]},{\"first\":\"Al'an\",\"last\":\"Aspuru-Guzik\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2017, "month": 5, "day": 30}, "abstract": "In unsupervised data generation tasks, besides the generation of a sample based on previous observations, one would often like to give hints to the model in order to bias the generation towards desirable metrics. We propose a method that combines Generative Adversarial Networks (GANs) and reinforcement learning (RL) in order to accomplish exactly that. While RL biases the data generation process towards arbitrary metrics, the GAN component of the reward function ensures that the model still remembers information learned from data. We build upon previous results that incorporated GANs and RL in order to generate sequence data and test this model in several settings for the generation of molecules encoded as text sequences (SMILES) and in the context of music generation, showing for each case that we can effectively bias the generation process towards desired metrics.", "fields_of_study": "[\"Mathematics\",\"Computer Science\"]", "external_ids": {"arxiv": "1705.10843", "mag": "2618625858", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/GuimaraesSFA17", "doi": null}}, "content": {"source": {"pdf_hash": "e8573813a0d45e1e82747ff8e5517578aa6eaf14", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1705.10843v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "a3191f3d305c87d5f04c3825a88c22f614c05991", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e8573813a0d45e1e82747ff8e5517578aa6eaf14.txt", "contents": "\nObjective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models\n\n\nGabriel L Guimaraes gabrielguimaraes@college.harvard.edu \nHarvard University\nHarvard University\nHarvard University\nHarvard University\n\n\nBenjamin Sanchez-Lengeling bsanchezlengeling@g.harvard.edu \nHarvard University\nHarvard University\nHarvard University\nHarvard University\n\n\nPedro Luis \nHarvard University\nHarvard University\nHarvard University\nHarvard University\n\n\nCunha Farias pfarias@college.harvard.edu \nHarvard University\nHarvard University\nHarvard University\nHarvard University\n\n\nAl\u00e1n Aspuru-Guzik \nHarvard University\nHarvard University\nHarvard University\nHarvard University\n\n\nObjective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models\n\nIn unsupervised data generation tasks, besides the generation of a sample based on previous observations, one would often like to give hints to the model in order to bias the generation towards desirable metrics. We propose a method that combines Generative Adversarial Networks (GANs) [8] and reinforcement learning (RL) in order to accomplish exactly that. While RL biases the data generation process towards arbitrary metrics, the GAN component of the reward function ensures that the model still remembers information learned from data. We build upon previous results that incorporated GANs and RL in order to generate sequence data[20]and test this model in several settings for the generation of molecules encoded as text sequences (SMILES [12]) and in the context of music generation, showing for each case that we can effectively bias the generation process towards desired metrics.\n\nIntroduction\n\nThe unsupervised generation of data is a dynamic area of machine learning and an active research frontier. Besides generating a desired distribution, one often wants to guide the generative model towards certain desired criterion. For example, when generating music one might wish to reward the model for choosing certain melodic patterns. In the case of molecular design, besides generating valid molecules [7], one may want to optimize molecular properties to screen for their potential in solar cells [9] or batteries [17] or OLEDS [6]. One way to impose arbitrary objectives to generative models is via naive reinforcement learning (RL), where we define hard coded rewards and treat the model as a player taking actions in a game-like setting. Unfortunately, depending on the objective, this approach may lead to unphysical or uninteresting samples.\n\nFollowing the chemistry example, compounds can be represented as SMILES strings -text sequences that encode the connectivity graph of arbitrary molecules [12]. SMILES have grammar rules based on chemical bonding, which can lead to valid expressions such as \"N#Cc1cc[nH]n1\" or invalid such as \"[C[[[N\", encoding a non-plausible molecule. In this setting a simple objective fucntion such as \"molecules should be valid\" might skew our model to create monotonous repetitions of valid characters and generate strings such as \"CCCN\", \"CCCCN\", \"CCCCCN\", which are valid but not very interesting molecules in terms of chemical diversity.\n\nPrevious work has relied on specific modifications of the objective function to reach the desired properties. For example, in order to increase the number of generated valid molecules, Ranzato et al [13] added penalties for molecules with unrealistically large carbon rings (size larger than 6), molecules shorter than any training set sample, or molecules with less carbons than any molecule in the training set.Without penalty or reward terms, RL can easily get stuck around local maxima which can be very far from the global maximum reward.\n\nThis type of reward optimization depends highly on experimentation as well as domain specific knowledge. In the Objective-Reinforced Generative Adversarial Network (ORGAN) introduced in this work, we explore the addition of an adversarial approach to the reinforcement learning setting using generative adversarial networks (GANs) to bias the generative process. GANs are a family of generative models proposed by Goodfellow et al [8] which are able to generate compelling results in a number of image-related tasks [19]. The proposed ORGAN model adds a GAN discriminator term to the reinforcement learning reward function. The generator is trained to maximize a weighted average of two rewards: the \"objective,\" which is hard coded and unchanging, and the discriminator, which is dynamically trained along with the generator in an adversarial fashion. While the objective component of the reward function ensures that the model selects for traits that maximize the specified heuristic, the changing discriminator part does not let the model lock on certain modes and therefore to generate uninteresting or repetitive data.\n\nIn order to implement the above idea, we build on SeqGAN, a recent work that successfully combines GANs and RL in order to apply the GAN framework to sequential data [20]. While our implementation uses recurrent neural networks (RNNs) to generate sequential data, in theory our model can be adapted to generate any type of data, as long as the GAN is trained via RL. We implement our model in the context of molecules and music generation, optimizing several different metrics. Our results show that ORGAN achieves better objective scores than maximum likelihood estimate (MLE) and SeqGAN, without sacrificing the diversity of generated data 1 .\n\n\nModel\n\nAs illustrated in Figure 1, the informal idea of ORGAN is that the generator is trained via policy gradient to maximize two rewards at the same time: one that improves the hard-coded objective and another that tries to fool the discriminator in a GAN setting. More formally, the discriminator D \u03c6 is a Convolutional Neural Network (CNN) parameterized by \u03c6. We feed both real and generated data to it and update D \u03c6 like we would any classifier\nmin \u03c6 E Y \u223cpdata(Y ) [log D(Y )] + E Y \u223cp G \u03b8 (Y ) [log(1 \u2212 D(Y ))](1)\nThe generator G \u03b8 is an RNN parameterized by \u03b8 using Long Short Term Memory (LSTM) cells [10] that generates T length sequences Y 1:T = (y 1 , ..., y T ). Let R(Y 1:T ) be the reward function defined for full length sequences. We will define it later in this section.\n\nWe treat G as an agent in an reinforcement learning context. Its state s t is the currently produced sequence of tokens Y 1:t and its action a is the next token y t+1 to select. The agent's stochastic policy is given by G \u03b8 (y t |Y 1:t\u22121 ) and we wish to maximize its expected long term reward\nJ(\u03b8) = E[R(Y 1:T )|s 0 , \u03b8] = y1\u2208Y G \u03b8 (y 1 |s 0 ) \u00b7 Q(s 0 , y 1 )(2)\nwhere s 0 is a fixed initial state. Q(s, a) is our action-value function that represents the expected reward at state s of taking action a and following our current policy G \u03b8 to complete the rest of the sequence. For any full sequence Y 1:T , we have Q(s = Y 1:T \u22121 , a = y T ) = R(Y 1:T ) but we also wish to calculate Q for partial sequences at intermediate timesteps, considering the expected future reward when the sequence is completed. In order to do so, we perform N -time Monte Carlo search with the canonical rollout policy G \u03b8 represented as\nMC G \u03b8 (Y 1:t ; N ) = {Y 1 1:T , ..., Y N 1:T } (3)\nwhere Y n 1:t = Y 1:t and Y n t+1:T is stochastically sampled via the policy G \u03b8 . Now Q becomes\nQ(s = Y 1:t\u22121 , a = y t ) = \uf8f1 \uf8f2 \uf8f3 1 N n=1,...,N R(Y n 1:T ), Y n 1:T \u2208 MC G \u03b8 (Y 1:t ; N ), if t < T . R(Y 1:T ), if t = T .(4)\nFollowing the original SeqGAN work, in order to apply reinforcement learning to an RNN, an unbiased estimation of the gradient of J(\u03b8) can be derived as\n\u2207 \u03b8 J(\u03b8) 1 T t=1,...,T E yt\u223cG \u03b8 (yt|Y1:t\u22121) [\u2207 \u03b8 log G \u03b8 (y t |Y 1:t\u22121 ) \u00b7 Q(Y 1:t\u22121 , y t )](5)\nFinally in ORGAN we simply define the reward function for a particular sequence Y 1:t as\nR(Y 1:T ) = \u03bb \u00b7 D \u03c6 (Y 1:T ) + (1 \u2212 \u03bb) \u00b7 O(Y 1:T )(6)\nwhere D \u03c6 is the discriminator and O is the objective representing any heuristic that we like. When \u03bb = 0 the model ignores D and becomes a naive RL, whereas when \u03bb = 1 it is simply a SeqGAN model.\n\nAlgorithm 1 shows pseudocode for the proposed model. Highlighted in blue are the specific differences between SeqGAN and our model. All the gradient descent steps are done using the Adam algorithm [14]. Note that our implementation on top of SeqGAN is merely because we are working with sequential data. In theory, the ORGAN model can be used with most types of GAN.\nAlgorithm 1: Objective-Reinforced Generative Adversarial Networks (ORGAN) require :Generator G \u03b8 ; Discriminator D \u03c6 ; dataset S = {Y 1:T }; objective O : Y \u2192 (0, 1) Initialize G \u03b8 , D \u03c6 with random weights \u03b8, \u03c6;\nPre-train G \u03b8 using MLE on S; Generate negative samples using G \u03b8 for training D \u03c6 ; Pre-train D \u03c6 by minimizing the cross entropy; repeat for g-steps do Generate a sequence Y 1: \nT = (y 1 , ..., y T ) \u223c G \u03b8 ; for t in 1 : T do Compute Q(s = Y 1:t\u22121 , a = y t ) by\n\nExperiments\n\nWe compare ORGAN with three other methods of training RNNs: SeqGAN, Naive RL, and Maximum Likelihood Estimate (MLE). Each of the four methods is used to train the same architecture. All training methods involve a pre-training step of 240 epochs of MLE. The MLE baseline simply stops right after pre-training, while the other methods proceed to further train the model using the different approaches.\n\nFor each dataset, we first build a dictionary mapping the vocabulary -the set of all characters present in the dataset -to integers. Then we preprocess the dataset by transforming each sequence into a fixed sized integer sequence of length N where N is the maximum length of a string present in the dataset along with around 10% more characters increase flexibility. Every string with length smaller than N is padded with \"_\" characters. Thus the input to our model becomes a list of fixed sized integer sequences.\n\n\nMolecules\n\nIn this work, we used three different chemistry datasets consisting of SMILES strings representing molecules in pharmaceutical contexts:\n\n\u2022 Drug-like -A random subset of 15k drug-like molecules from ZINC database of 35 million commercially-available compounds for virtual screening, typically used for drug discovery [11]. The maximum sequence length is 121 and the alphabet size is 37.\n\n\u2022 Small mols -A random subset of 15k molecules from the set of 134 thousand stable small molecules [18]. This is a subset of all molecules with up to nine heavy atoms (CONF) out of the GDB-17 universe of 166 billion organic molecules [18]. The maximum sequence length is 31 and the alphabet size is 25.\n\n\u2022 Tiny mols -A smaller subset of the Small mols dataset containing all molecules with less than 12 atoms. The maximum sequence length is 29 while the alphabet size is 22.\n\nWhen choosing reward metrics we picked qualities that are normally desired for drug discovery:\n\n\u2022 Novelty: A function that will return a value of 1 if a SMILES encoded is a valid molecule that is outside of the training set. It will return 0.3 if it is only valid, and 0 if not. Each plot is optimized for a particular objective (bold line). Visibly these rewards present the most growth in each case signifying the generated data is indeed receiving bias from the metric.\n\n\u2022 Diversity: A function from 0 to 1 that measures the average similarity of a molecule with respect to a random subset of molecules for a training set. The closer to 0, the less diverse this molecule is. \u2022 Solubility (Log(P)): A function that measures the solubility of a molecule in water normalized to the range 0 to 1 based on experimental data. The value is computed via RDKit's LogP function [15]. \u2022 Synthetizability: A normalized version of the synthetic accessibility score [4] as implemented in RDKit, a measure based on molecular complexity and fragment contributions that estimates how hard (0) or how easy (1) it is to make a given molecule.   Figure 3 shows some of the generated molecules.\n\nIn Figure 2 we can observe that indeed the reward is inducing a bias in the generated data since each particular reward is growing the fastest before plateauing to a maxima. We also find that some metrics will improve after time along with the reward. This behavior is expected since many of the rewards are not independent. We can also observe that novelty presents the same pattern. This is again not Naive RL Table 2: SMILES strings for the molecules illustrated in 3, each column is from a different training algorithm. Upon a glance, the naive RL molecules seem much less interesting than the SeqGAN and ORGAN ones because they are not as diverse and posses repetitive substructures.\" surprising, since novelty is essentially counting valid sequences which are necessary for all other rewards.\nORGAN (\u03bb = 0.8) SeqGAN Cc1ccccc1OCCCCCCCCCOCCCCOCCCCOc1ccccc1 OCC(CC)C CC(C)S(=O)(=O)c1c(Br)cccc1NS(=O)(=O)c1ccccc1C CCCCCCCCOCCCOCCCOCc1ccccc1 CSCC(=O)N1CCCC1 COCCN1CC(O)CC(C(C)C)CCC1 CCCOCCCCCOCCC COC(=O)n1ccc(F)c1F CNC(=O)c1ccc(Sc2nnn(C(C)C)c2C=O)cc1 CCCOCCCOCCCCCCCCOc1ccccc1 OCCC(=O)Nc1ccc(F)c(F)c1 COc1cccc(OC)c1S(=O)(=O)C(C)C(=O)NCc1ccc(OC)c(-n2cccc2)c1 OCCCCCCOCCCCOCCOCc1ccccc1 CC(=O)Nc1ccc(F)c(F)c1OC CCOc1ccc(NCc2ccccc2OC)cc1O OCCCCCCCOCCCOCCCOCCCOc1ccccc1 OCCCC(=O)N O=S1C(C)CC(NC2=O)CC1CS(=O)(=O)c1nc3ccccc3nc12 CCOCCCOCCOCCCc1ccccc1 CCCC(=S)NC(=O)NCC1CCC1 Nc1cc(F)ccc1NC(=O)c1ccc2c(Cl)cccc2c1 CCOCCCCOc1ccccc1OCCCOc1ccccc1 CCC(=O)OCC(=O)[O-] O=C(c1cccc(N2CCCC2)c1)c1cccc(C)n1 CCOCCCCCOCCCCCOCCOCc1ccccc1 CCCCC(=O)C1CCCC1 CCc1nc(C)nc(C)c1[N+](=O)[O-] OCCOCCOCCCCCOCCCCCOc1ccccc1OC CCCC(=CO)c1ccc(F)cc1F CCN(C(=O)NCC1N(C2CCCC2)C1)C(=O)c1ccccn1\nMeanwhile, Figure 3 illustrates the role that \u03bb plays in the generative process. While the maximum of the reward druglikeliness lies in the RL setting we can see that the generated molecules are quite simple. By increasing \u03bb we are end up with a lower (but still high) druglikeness while generating more acceptable molecules. This pattern is perceived in almost all metrics, sometimes the maxima will also be in the intermediate regime.\n\nIn our experiments we also noted that naive RL has different failure scenarios. For instance, when trained on the Small mols dataset, it learned to generate longer sequences with monotonous patterns like \"CCCCCCCCCCCCCCCCC\" or \"CCCCOCCCCCOCCCCCC\". When trained on the drug-like dataset, however, the naive RL model learned to generate sequences significantly shorter than those in the training set such as the single atom molecule \"N.\" The GAN component can easily prevent any of these failure scenarios since the discriminator can learn to penalize string batches that do not look like the training set (in this case they do not have the same average length) as seen in average lengths of sequences generated by each of the models in Table 1.\n\n\nMusic\n\nTo further demonstrate the applicability of ORGAN, we extended its application to music. We used ABC notation, which allows music to be expressed in a text format, and facilitates reading the dataset  and analyzing its contents. In this work we use the Nottingham [1] dataset, filtering out sequences longer than 80 notes. We generate songs optimizing three different metrics:\n\n\u2022 Tonality: This measures how many perfect fifths are in the music that is generated. A perfect fifth is defined as a musical interval whose frequencies have a ratio of approximately 3:2. These provide what is generally considered pleasant note sequences due to their high consonance. \u2022 Melodicity:In order of decreasing consonance, we have the following intervals: perfect fifth, perfect fourth, major sixth, major third, minor third, minor sixth, major second, minor seventh, and minor second [16]. We decided that, for an interval to be considered melodic, it must be one of the top three in the above list. Note that tonality is a subset of melodicity, as maximizing tonality also helps maximize melodicity. \u2022 Ratio of Steps: A step is an interval between two consecutive notes of a scale. An interval from C to D, for example, is a step. A skip, on the other hand, is a longer interval. An interval from C to G, for example, is a skip. By maximizing the ratio of steps in our music, we are adhering to conjunct melodic motion [3], Our rationale here is that by increasing the number of steps in our songs we make our melodic leaps rarer and more memorable [5].\n\nMoreover we calculate diversity as the average pairwise edit distance of the generated data following the approach of Habrard et al [2]. We do not attempt to maximize this metric explicitly but we keep track of it to shed light on the trade-off between metric optimization and sample diversity in the ORGAN framework. Table 3 shows quantitative results comparing ORGAN to other baseline methods optimizing for three different metrics. ORGAN outperforms SeqGAN and MLE in all of the three metrics. Naive RL achieves a higher score than ORGAN for the Ratio of Steps metric, but it underperforms in terms of diversity, as Naive RL would likely generate very simple rather than diverse songs. In this sense, similar to the molecule case, although the Naive RL ratio of steps score is higher than ORGAN's, the actual generated songs can be deemed much less interesting. By tweaking \u03bb, the ORGAN approach allows one to explore the trade-off between maximizing the desired objective and maintaining diversity or \"interestingness.\"\n\nBesides the expected correlation between Tonality and Melodicity, we also noticed an inverse relationship between Ratio of Steps and any of the other two. This is because two consecutive notes, what qualifies as a step, do not have the frequency ratios of perfect fifths, perfect fourths, or major sixths, which are responsible for increasing Melodicity. Figure 4 shows the distribution of the tonality of data sampled from ORGAN and from the training set. As \u03bb increases, the curves become more smooth since the discriminator forces the model to approach the structure of the training set. Without the discriminator component, naive RL (\u03bb = 0) Figure 4: Tonality distributions of the sampled data from ORGAN with different values of \u03bb as well as from the training set. The x axis represents the tonality metric while the y axis represents the frequency of that particular tonality in the sampled data.\n\ncreates a distribution that does not seem very realistic because of its lack of diversity. In all cases, however, the RL component of ORGAN successfully skews the model towards data with higher values of tonality.\n\n\nConclusion and Future Work\n\nIn this work, we have presented a general framework which builds on the recent advances of Generative Adversarial Networks to optimize an arbitrary objective in a sequence generation task.\n\nWe have shown that ORGAN improves desired metrics achieving better results than RNNs trained via either MLE or SeqGAN. More importantly, we are able to tune the data generation towards a particular reward function while using the adversarial setting to keep data non-repetitious. Moreover, ORGAN is much easier to use as a black box than similar objective optimization models, since one does not need to introduce multiple domain-specific penalties to the reward function: many times a simple objective \"hint\" will suffice.\n\nFuture work should attempt to formalize ORGANs from a theoretical standpoint in order to understand when and how they converge. It is crucial to understand when GANs converge in general, which is still an open question. Future work should also do more to understand the influence of the choice of heuristic on the performance of the model.\n\nFinally, future work should extend ORGANs to work with data that is not sequential, such as images. This requires framing the GAN setup as a reinforcement learning problem in order to add an arbitrary (not necessarily differentiable) objective function. We believe this extension to be quite promising since real valued GANs are currently better understood than sequence data GANs.\n\nFigure 1 :\n1Illustration of ORGAN. Left: D is trained as a classifier receiving as input a mix of the real data and the generated data by G. Right: G is trained by RL where the reward is a combination of D and the objective, and is passed back to the policy function via Monte Carlo sampling.\n\nFigure 2 :\n2Plots showing the rewards for the Tiny dataset across training epochs using \u03bb = 0.2.\n\n\u2022\nDruglikeness: A heuristic that estimates how likely a molecule could be used as a drug for humans. Composed of a linear combination of Novelty, Diversity, Solubility and Synthetizability (positive reward if it falls within the range of -0.4 and 5.6).\n\nFigure 3 :\n3of \u03bb on druglikeness for small mols Molecules generated from a random subset of 10 SMILES for three different values of \u03bb, optimizing for Druglikeness. The Naive RL molecules are constructed via simple repetition of characters, the SeqGan are much more complex but are structures highly improbable to be found in nature, the \u03bb = 0.8 setting lies between both regimes.\n\n\nEq. 4 using D \u03c6 and O to calculate rewards per Eq. 6 end Update generator parameters \u03b8 via policy gradient by Eq 5.; end for d-steps do Use G \u03b8 to generate negative examples and combine with given positive examples S; Train discriminator D \u03c6 for k epochs by Eq. 1; end until model converges;\n\n\nEvaluation of different training methods on different datasets, optimizing for solubility. Each measure was taken over a set of 6400 generated molecules.Table 1 shows quantitative results comparing ORGAN to other baseline methods in different datasets. The table includes values for some of the metrics utilized in the objective. WhileDataset \nAlgorithm \nNovelty Diversity Solubility Synth. Drug. \nTiny mols \nNaive RL \n0.94 \n0.69 \n0.40 \n0.73 \n0.90 \nORGAN (\u03bb = 0.2) \n0.92 \n0.51 \n0.38 \n0.73 \n0.90 \nSeqGAN \n0.22 \n0.41 \n0.21 \n0.30 \n0.59 \nMLE \n0.52 \n0.24 \n0.12 \n0.16 \n0.42 \n\nSmall mols \nNaive RL \n0.96 \n0.69 \n0.70 \n0.83 \n0.93 \nORGAN (\u03bb = 0.8) \n0.23 \n0.41 \n0.22 \n0.30 \n0.6 \nSeqGAN \n0.32 \n0.11 \n0.20 \n0.17 \n0.28 \nMLE \n0.38 \n0.14 \n0.24 \n0.24 \n0.38 \n\nDrug-like \nNaive RL \n0.95 \n0.64 \n0.41 \n0.82 \n0.91 \nORGAN (\u03bb = 0.8) \n0.97 \n0.56 \n0.78 \n0.81 \n0.92 \nSeqGAN \n0.24 \n0.09 \n0.13 \n0.12 \n0.19 \nMLE \n0.32 \n0.13 \n0.20 \n0.20 \n0.29 \nTable 1: \n\nTable 3 :\n3Results of ORGAN optimizing different metrics. Each measure was taken over a set of 6400 \ngenerated songs. Bolded entries represent the optimized metric as well as the diversity achieved by \nORGAN in each experiment. \n\n\nImplementation of this code is available online at https://github.com/gablg1/ORGAN\nAcknowledgmentsWe thank Dr. Anders Fr\u00f6seth for his generous support for this work. We thank Harvard Research Computing for their support on using the Oddysey cluster. To Jaime Lobato Cardoso and Anna Huang on discussion about music metrics.\nABC version of the Nottingham Music Database. J Allwright, J. Allwright. ABC version of the Nottingham Music Database. URL http://abc. sourceforge.net/NMD/.\n\nMelody recognition with learned edit distances. Structural, Syntactic, and Statistical Pattern Recognition. J.-M I Habrard, M S David Rizo, doi: 10.1007/ 978-3-540-89689-0_13J.-M. I. Amaury Habrard and M. S. David Rizo. Melody recognition with learned edit distances. Structural, Syntactic, and Statistical Pattern Recognition, 2008. doi: 10.1007/ 978-3-540-89689-0_13.\n\nA History of Music in Western Culture. M E Bonds, M. E. Bonds. A History of Music in Western Culture. page 123, 2006.\n\nEstimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions. P Ertl, A Schuffenhauer, 10.1186/1758-2946-1-8Journal of Cheminformatics. 1P. Ertl and A. Schuffenhauer. Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions. Journal of Cheminformatics, 1, 2009. doi: 10.1186/1758-2946-1-8.\n\nThe Power of the Melodic Leap. G Ewer, G. Ewer. The Power of the Melodic Leap. 2013. URL http://www.secretsofsongwriting. com/2013/01/16/the-power-of-the-melodic-leap/.\n\nDesign of efficient molecular organic light-emitting diodes by a high-throughput virtual screening and experimental approach. R G\u00f3mez-Bombarelli, J Aguilera-Iparraguirre, T D Hirzel, D Duvenaud, D Maclaurin, M A Blood-Forsythe, H S Chae, M Einzinger, D.-G Ha, G M Wu, S Jeon, H Kang, H Miyazaki, M Numata, S Kim, W Huang, S I Hong, M Baldo, R P Adams, A Aspuru-Guzik, 10.1038/nmat4717Nature Materials. 1510R. G\u00f3mez-Bombarelli, J. Aguilera-Iparraguirre, T. D. Hirzel, D. Duvenaud, D. Maclaurin, M. A. Blood-Forsythe, H. S. Chae, M. Einzinger, D.-G. Ha, G. M. Tony Wu, S. Jeon, H. Kang, H. Miyazaki, M. Numata, S. Kim, W. Huang, S. I. Hong, M. Baldo, R. P. Adams, and A. Aspuru- Guzik. Design of efficient molecular organic light-emitting diodes by a high-throughput virtual screening and experimental approach. Nature Materials, 15(10):1120-1127, aug 2016. doi: 10.1038/nmat4717.\n\nAutomatic chemical design using a data-driven continuous representation of molecules. R G\u00f3mez-Bombarelli, D Duvenaud, J M Hern\u00e1ndez-Lobato, J Aguilera-Iparraguirre, T D Hirzel, R P Adams, A Aspuru-Guzik, arXiv:1610.02415cs.LGR. G\u00f3mez-Bombarelli, D. Duvenaud, J. M. Hern\u00e1ndez-Lobato, J. Aguilera-Iparraguirre, T. D. Hirzel, R. P. Adams, and A. Aspuru-Guzik. Automatic chemical design using a data-driven continuous representation of molecules. 2016. arXiv:1610.02415 [cs.LG].\n\nI Goodfellow, J Pouget-Abadie, M Mirza, arXiv:1406.2661Generative Adversarial Networks. stat.MLI. Goodfellow, J. Pouget-Abadie, and M. Mirza. Generative Adversarial Networks. 2014. arXiv:1406.2661 [stat.ML].\n\nLead candidates for high-performance organic photovoltaics from high-throughput quantum chemistry -the harvard clean energy project. J Hachmann, R Olivares-Amaya, A Jinich, A L Appleton, M A Blood-Forsythe, L R Seress, C Rom\u00e1n-Salgado, K Trepte, S Atahan-Evrenk, S Er, S Shrestha, R Mondal, A Sokolov, Z Bao, A Aspuru-Guzik, 10.1039/c3ee42756kEnergy Environ. Sci. 72J. Hachmann, R. Olivares-Amaya, A. Jinich, A. L. Appleton, M. A. Blood-Forsythe, L. R. Seress, C. Rom\u00e1n-Salgado, K. Trepte, S. Atahan-Evrenk, S. Er, S. Shrestha, R. Mondal, A. Sokolov, Z. Bao, and A. Aspuru-Guzik. Lead candidates for high-performance organic photovoltaics from high-throughput quantum chemistry -the harvard clean energy project. Energy Environ. Sci., 7(2):698-704, 2014. doi: 10.1039/c3ee42756k.\n\n. J Hochreiter, Sepp, Urgen Schmidhuber, arxiv:1206.2944Long Short Term Memory. Memory. 9J. Hochreiter, Sepp and Schmidhuber and Urgen. Long Short Term Memory. Memory, 9(1993): 1-28, 1996. arxiv:1206.2944.\n\nZINC -A Free Database of Commercially Available Compounds for Virtual Screening. J J Irwin, B K Shoichet, J Chem Inf Model. J. J. Irwin and B. K. Shoichet. ZINC -A Free Database of Commercially Available Compounds for Virtual Screening. J Chem Inf Model, 2006.\n\nOpenSMILES specification. C A James, R Apodaca, N O&apos;boyle, A Dalke, J Van Drie, P Ertl, G Hutchison, G Landrum, C Morley, E Willighagen, H D Winter, T Vandermeersch, J May, C. A. James, R. Apodaca, N. O'Boyle, A. Dalke, J. van Drie, P. Ertl, G. Hutchison, G. Landrum, C. Morley, E. Willighagen, H. D. Winter, T. Vandermeersch, and J. May. OpenSMILES specification. 2016. URL http://opensmiles.org/.\n\nSequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control. N Jaques, S Gu, D Bahdanau, J Miguel, H Lobato, R E Turner, D Eck, arXiv:1611.02796cs.LGN. Jaques, S. Gu, D. Bahdanau, J. Miguel, H. Lobato, R. E. Turner, and D. Eck. Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control. 2017. arXiv:1611.02796 [cs.LG].\n\nAdam: A Method for Stochastic Optimization. ICLR. D P Kingma, J Ba, arXiv:1412.6980cs.LGD. P. Kingma and J. Ba. Adam: A Method for Stochastic Optimization. ICLR, 2014. arXiv:1412.6980 [cs.LG].\n\nRdkit: Open-source cheminformatics. G Landrum, G. Landrum. Rdkit: Open-source cheminformatics. URL http://www.rdkit.org.\n\nDensity Degree of Intervals and Chords. O Legname, O. Legname. Density Degree of Intervals and Chords. 1998. URL http://www.oneonta. edu/faculty/legnamo/theorist/density/density.html.\n\nA redox-flow battery with an alloxazine-based organic electrolyte. K Lin, R G\u00f3mez-Bombarelli, E S Beh, L Tong, Q Chen, A Valle, A Aspuru-Guzik, M J Aziz, R G Gordon, 10.1038/nenergy.2016.102Nature Energy. 1916102K. Lin, R. G\u00f3mez-Bombarelli, E. S. Beh, L. Tong, Q. Chen, A. Valle, A. Aspuru-Guzik, M. J. Aziz, and R. G. Gordon. A redox-flow battery with an alloxazine-based organic electrolyte. Nature Energy, 1(9):16102, jul 2016. doi: 10.1038/nenergy.2016.102.\n\nQuantum chemistry structures and properties of 134 kilo molecules. Scientific Data. R Ramakrishnan, P Dral, M Rupp, A Von Lilienfeld, 10.1038/sdata.2014.22R. Ramakrishnan, P. Dral, M. Rupp, and A. von Lilienfeld. Quantum chemistry structures and properties of 134 kilo molecules. Scientific Data, 2014. doi: 10.1038/sdata.2014.22.\n\nT Salimans, I Goodfellow, W Zaremba, V Cheung, A Radford, X Chen, arXiv:1606.03498Improved Techniques for Training GANs. NIPS. cs.LGT. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen. Improved Techniques for Training GANs. NIPS, 2016. arXiv:1606.03498 [cs.LG].\n\nSeqGAN: Sequence Generative Adversarial Nets with Policy Gradient. L Yu, W Zhang, J Wang, Y Yu, arXiv:1609.05473cs.LGL. Yu, W. Zhang, J. Wang, and Y. Yu. SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient. 2016. arXiv:1609.05473 [cs.LG].\n", "annotations": {"author": "[{\"end\":230,\"start\":95},{\"end\":368,\"start\":231},{\"end\":458,\"start\":369},{\"end\":578,\"start\":459},{\"end\":675,\"start\":579}]", "publisher": null, "author_last_name": "[{\"end\":114,\"start\":105},{\"end\":257,\"start\":240},{\"end\":379,\"start\":375},{\"end\":471,\"start\":465},{\"end\":596,\"start\":584}]", "author_first_name": "[{\"end\":102,\"start\":95},{\"end\":104,\"start\":103},{\"end\":239,\"start\":231},{\"end\":374,\"start\":369},{\"end\":464,\"start\":459},{\"end\":583,\"start\":579}]", "author_affiliation": "[{\"end\":229,\"start\":153},{\"end\":367,\"start\":291},{\"end\":457,\"start\":381},{\"end\":577,\"start\":501},{\"end\":674,\"start\":598}]", "title": "[{\"end\":92,\"start\":1},{\"end\":767,\"start\":676}]", "venue": null, "abstract": "[{\"end\":1659,\"start\":769}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2086,\"start\":2083},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2182,\"start\":2179},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2200,\"start\":2196},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2213,\"start\":2210},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2688,\"start\":2684},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3364,\"start\":3360},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4140,\"start\":4137},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4226,\"start\":4222},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5001,\"start\":4997},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6094,\"start\":6090},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8257,\"start\":8253},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10165,\"start\":10161},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10335,\"start\":10331},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10470,\"start\":10466},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11583,\"start\":11579},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11666,\"start\":11663},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14999,\"start\":14996},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15609,\"start\":15605},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16144,\"start\":16141},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16274,\"start\":16271},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":16412,\"start\":16409}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":20181,\"start\":19888},{\"attributes\":{\"id\":\"fig_1\"},\"end\":20279,\"start\":20182},{\"attributes\":{\"id\":\"fig_2\"},\"end\":20533,\"start\":20280},{\"attributes\":{\"id\":\"fig_3\"},\"end\":20914,\"start\":20534},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":21208,\"start\":20915},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":22133,\"start\":21209},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":22365,\"start\":22134}]", "paragraph": "[{\"end\":2528,\"start\":1675},{\"end\":3159,\"start\":2530},{\"end\":3704,\"start\":3161},{\"end\":4829,\"start\":3706},{\"end\":5476,\"start\":4831},{\"end\":5929,\"start\":5486},{\"end\":6268,\"start\":6001},{\"end\":6563,\"start\":6270},{\"end\":7186,\"start\":6634},{\"end\":7335,\"start\":7239},{\"end\":7616,\"start\":7464},{\"end\":7802,\"start\":7714},{\"end\":8054,\"start\":7857},{\"end\":8422,\"start\":8056},{\"end\":8815,\"start\":8636},{\"end\":9314,\"start\":8915},{\"end\":9830,\"start\":9316},{\"end\":9980,\"start\":9844},{\"end\":10230,\"start\":9982},{\"end\":10534,\"start\":10232},{\"end\":10706,\"start\":10536},{\"end\":10802,\"start\":10708},{\"end\":11180,\"start\":10804},{\"end\":11884,\"start\":11182},{\"end\":12684,\"start\":11886},{\"end\":13977,\"start\":13541},{\"end\":14722,\"start\":13979},{\"end\":15108,\"start\":14732},{\"end\":16275,\"start\":15110},{\"end\":17300,\"start\":16277},{\"end\":18204,\"start\":17302},{\"end\":18419,\"start\":18206},{\"end\":18638,\"start\":18450},{\"end\":19163,\"start\":18640},{\"end\":19504,\"start\":19165},{\"end\":19887,\"start\":19506}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6000,\"start\":5930},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6633,\"start\":6564},{\"attributes\":{\"id\":\"formula_2\"},\"end\":7238,\"start\":7187},{\"attributes\":{\"id\":\"formula_3\"},\"end\":7463,\"start\":7336},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7713,\"start\":7617},{\"attributes\":{\"id\":\"formula_5\"},\"end\":7856,\"start\":7803},{\"attributes\":{\"id\":\"formula_6\"},\"end\":8635,\"start\":8423},{\"attributes\":{\"id\":\"formula_7\"},\"end\":8900,\"start\":8816},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13540,\"start\":12685}]", "table_ref": "[{\"end\":12305,\"start\":12298},{\"end\":14721,\"start\":14714},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":16602,\"start\":16595}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1673,\"start\":1661},{\"attributes\":{\"n\":\"2\"},\"end\":5484,\"start\":5479},{\"attributes\":{\"n\":\"3\"},\"end\":8913,\"start\":8902},{\"end\":9842,\"start\":9833},{\"end\":14730,\"start\":14725},{\"attributes\":{\"n\":\"4\"},\"end\":18448,\"start\":18422},{\"end\":19899,\"start\":19889},{\"end\":20193,\"start\":20183},{\"end\":20282,\"start\":20281},{\"end\":20545,\"start\":20535},{\"end\":22144,\"start\":22135}]", "table": "[{\"end\":22133,\"start\":21546},{\"end\":22365,\"start\":22146}]", "figure_caption": "[{\"end\":20181,\"start\":19901},{\"end\":20279,\"start\":20195},{\"end\":20533,\"start\":20283},{\"end\":20914,\"start\":20547},{\"end\":21208,\"start\":20917},{\"end\":21546,\"start\":21211}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5512,\"start\":5504},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":11845,\"start\":11837},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11897,\"start\":11889},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":13560,\"start\":13552},{\"end\":17665,\"start\":17657},{\"end\":17955,\"start\":17947}]", "bib_author_first_name": "[{\"end\":22737,\"start\":22736},{\"end\":22960,\"start\":22956},{\"end\":22962,\"start\":22961},{\"end\":22973,\"start\":22972},{\"end\":22975,\"start\":22974},{\"end\":23259,\"start\":23258},{\"end\":23261,\"start\":23260},{\"end\":23464,\"start\":23463},{\"end\":23472,\"start\":23471},{\"end\":23791,\"start\":23790},{\"end\":24056,\"start\":24055},{\"end\":24076,\"start\":24075},{\"end\":24101,\"start\":24100},{\"end\":24103,\"start\":24102},{\"end\":24113,\"start\":24112},{\"end\":24125,\"start\":24124},{\"end\":24138,\"start\":24137},{\"end\":24140,\"start\":24139},{\"end\":24158,\"start\":24157},{\"end\":24160,\"start\":24159},{\"end\":24168,\"start\":24167},{\"end\":24184,\"start\":24180},{\"end\":24190,\"start\":24189},{\"end\":24192,\"start\":24191},{\"end\":24198,\"start\":24197},{\"end\":24206,\"start\":24205},{\"end\":24214,\"start\":24213},{\"end\":24226,\"start\":24225},{\"end\":24236,\"start\":24235},{\"end\":24243,\"start\":24242},{\"end\":24252,\"start\":24251},{\"end\":24254,\"start\":24253},{\"end\":24262,\"start\":24261},{\"end\":24271,\"start\":24270},{\"end\":24273,\"start\":24272},{\"end\":24282,\"start\":24281},{\"end\":24896,\"start\":24895},{\"end\":24916,\"start\":24915},{\"end\":24928,\"start\":24927},{\"end\":24930,\"start\":24929},{\"end\":24950,\"start\":24949},{\"end\":24975,\"start\":24974},{\"end\":24977,\"start\":24976},{\"end\":24987,\"start\":24986},{\"end\":24989,\"start\":24988},{\"end\":24998,\"start\":24997},{\"end\":25286,\"start\":25285},{\"end\":25300,\"start\":25299},{\"end\":25317,\"start\":25316},{\"end\":25628,\"start\":25627},{\"end\":25640,\"start\":25639},{\"end\":25658,\"start\":25657},{\"end\":25668,\"start\":25667},{\"end\":25670,\"start\":25669},{\"end\":25682,\"start\":25681},{\"end\":25684,\"start\":25683},{\"end\":25702,\"start\":25701},{\"end\":25704,\"start\":25703},{\"end\":25714,\"start\":25713},{\"end\":25731,\"start\":25730},{\"end\":25741,\"start\":25740},{\"end\":25758,\"start\":25757},{\"end\":25764,\"start\":25763},{\"end\":25776,\"start\":25775},{\"end\":25786,\"start\":25785},{\"end\":25797,\"start\":25796},{\"end\":25804,\"start\":25803},{\"end\":26278,\"start\":26277},{\"end\":26302,\"start\":26297},{\"end\":26564,\"start\":26563},{\"end\":26566,\"start\":26565},{\"end\":26575,\"start\":26574},{\"end\":26577,\"start\":26576},{\"end\":26771,\"start\":26770},{\"end\":26773,\"start\":26772},{\"end\":26782,\"start\":26781},{\"end\":26793,\"start\":26792},{\"end\":26809,\"start\":26808},{\"end\":26818,\"start\":26817},{\"end\":26830,\"start\":26829},{\"end\":26838,\"start\":26837},{\"end\":26851,\"start\":26850},{\"end\":26862,\"start\":26861},{\"end\":26872,\"start\":26871},{\"end\":26887,\"start\":26886},{\"end\":26889,\"start\":26888},{\"end\":26899,\"start\":26898},{\"end\":26916,\"start\":26915},{\"end\":27238,\"start\":27237},{\"end\":27248,\"start\":27247},{\"end\":27254,\"start\":27253},{\"end\":27266,\"start\":27265},{\"end\":27276,\"start\":27275},{\"end\":27286,\"start\":27285},{\"end\":27288,\"start\":27287},{\"end\":27298,\"start\":27297},{\"end\":27576,\"start\":27575},{\"end\":27578,\"start\":27577},{\"end\":27588,\"start\":27587},{\"end\":27756,\"start\":27755},{\"end\":27882,\"start\":27881},{\"end\":28094,\"start\":28093},{\"end\":28101,\"start\":28100},{\"end\":28121,\"start\":28120},{\"end\":28123,\"start\":28122},{\"end\":28130,\"start\":28129},{\"end\":28138,\"start\":28137},{\"end\":28146,\"start\":28145},{\"end\":28155,\"start\":28154},{\"end\":28171,\"start\":28170},{\"end\":28173,\"start\":28172},{\"end\":28181,\"start\":28180},{\"end\":28183,\"start\":28182},{\"end\":28574,\"start\":28573},{\"end\":28590,\"start\":28589},{\"end\":28598,\"start\":28597},{\"end\":28606,\"start\":28605},{\"end\":28822,\"start\":28821},{\"end\":28834,\"start\":28833},{\"end\":28848,\"start\":28847},{\"end\":28859,\"start\":28858},{\"end\":28869,\"start\":28868},{\"end\":28880,\"start\":28879},{\"end\":29175,\"start\":29174},{\"end\":29181,\"start\":29180},{\"end\":29190,\"start\":29189},{\"end\":29198,\"start\":29197}]", "bib_author_last_name": "[{\"end\":22747,\"start\":22738},{\"end\":22970,\"start\":22963},{\"end\":22986,\"start\":22976},{\"end\":23267,\"start\":23262},{\"end\":23469,\"start\":23465},{\"end\":23486,\"start\":23473},{\"end\":23796,\"start\":23792},{\"end\":24073,\"start\":24057},{\"end\":24098,\"start\":24077},{\"end\":24110,\"start\":24104},{\"end\":24122,\"start\":24114},{\"end\":24135,\"start\":24126},{\"end\":24155,\"start\":24141},{\"end\":24165,\"start\":24161},{\"end\":24178,\"start\":24169},{\"end\":24187,\"start\":24185},{\"end\":24195,\"start\":24193},{\"end\":24203,\"start\":24199},{\"end\":24211,\"start\":24207},{\"end\":24223,\"start\":24215},{\"end\":24233,\"start\":24227},{\"end\":24240,\"start\":24237},{\"end\":24249,\"start\":24244},{\"end\":24259,\"start\":24255},{\"end\":24268,\"start\":24263},{\"end\":24279,\"start\":24274},{\"end\":24295,\"start\":24283},{\"end\":24913,\"start\":24897},{\"end\":24925,\"start\":24917},{\"end\":24947,\"start\":24931},{\"end\":24972,\"start\":24951},{\"end\":24984,\"start\":24978},{\"end\":24995,\"start\":24990},{\"end\":25011,\"start\":24999},{\"end\":25297,\"start\":25287},{\"end\":25314,\"start\":25301},{\"end\":25323,\"start\":25318},{\"end\":25637,\"start\":25629},{\"end\":25655,\"start\":25641},{\"end\":25665,\"start\":25659},{\"end\":25679,\"start\":25671},{\"end\":25699,\"start\":25685},{\"end\":25711,\"start\":25705},{\"end\":25728,\"start\":25715},{\"end\":25738,\"start\":25732},{\"end\":25755,\"start\":25742},{\"end\":25761,\"start\":25759},{\"end\":25773,\"start\":25765},{\"end\":25783,\"start\":25777},{\"end\":25794,\"start\":25787},{\"end\":25801,\"start\":25798},{\"end\":25817,\"start\":25805},{\"end\":26289,\"start\":26279},{\"end\":26295,\"start\":26291},{\"end\":26314,\"start\":26303},{\"end\":26572,\"start\":26567},{\"end\":26586,\"start\":26578},{\"end\":26779,\"start\":26774},{\"end\":26790,\"start\":26783},{\"end\":26806,\"start\":26794},{\"end\":26815,\"start\":26810},{\"end\":26827,\"start\":26819},{\"end\":26835,\"start\":26831},{\"end\":26848,\"start\":26839},{\"end\":26859,\"start\":26852},{\"end\":26869,\"start\":26863},{\"end\":26884,\"start\":26873},{\"end\":26896,\"start\":26890},{\"end\":26913,\"start\":26900},{\"end\":26920,\"start\":26917},{\"end\":27245,\"start\":27239},{\"end\":27251,\"start\":27249},{\"end\":27263,\"start\":27255},{\"end\":27273,\"start\":27267},{\"end\":27283,\"start\":27277},{\"end\":27295,\"start\":27289},{\"end\":27302,\"start\":27299},{\"end\":27585,\"start\":27579},{\"end\":27591,\"start\":27589},{\"end\":27764,\"start\":27757},{\"end\":27890,\"start\":27883},{\"end\":28098,\"start\":28095},{\"end\":28118,\"start\":28102},{\"end\":28127,\"start\":28124},{\"end\":28135,\"start\":28131},{\"end\":28143,\"start\":28139},{\"end\":28152,\"start\":28147},{\"end\":28168,\"start\":28156},{\"end\":28178,\"start\":28174},{\"end\":28190,\"start\":28184},{\"end\":28587,\"start\":28575},{\"end\":28595,\"start\":28591},{\"end\":28603,\"start\":28599},{\"end\":28621,\"start\":28607},{\"end\":28831,\"start\":28823},{\"end\":28845,\"start\":28835},{\"end\":28856,\"start\":28849},{\"end\":28866,\"start\":28860},{\"end\":28877,\"start\":28870},{\"end\":28885,\"start\":28881},{\"end\":29178,\"start\":29176},{\"end\":29187,\"start\":29182},{\"end\":29195,\"start\":29191},{\"end\":29201,\"start\":29199}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":22846,\"start\":22690},{\"attributes\":{\"doi\":\"doi: 10.1007/ 978-3-540-89689-0_13\",\"id\":\"b1\"},\"end\":23217,\"start\":22848},{\"attributes\":{\"id\":\"b2\"},\"end\":23336,\"start\":23219},{\"attributes\":{\"doi\":\"10.1186/1758-2946-1-8\",\"id\":\"b3\",\"matched_paper_id\":7423230},\"end\":23757,\"start\":23338},{\"attributes\":{\"id\":\"b4\"},\"end\":23927,\"start\":23759},{\"attributes\":{\"doi\":\"10.1038/nmat4717\",\"id\":\"b5\",\"matched_paper_id\":9855489},\"end\":24807,\"start\":23929},{\"attributes\":{\"doi\":\"arXiv:1610.02415\",\"id\":\"b6\"},\"end\":25283,\"start\":24809},{\"attributes\":{\"doi\":\"arXiv:1406.2661\",\"id\":\"b7\"},\"end\":25492,\"start\":25285},{\"attributes\":{\"doi\":\"10.1039/c3ee42756k\",\"id\":\"b8\",\"matched_paper_id\":38634275},\"end\":26273,\"start\":25494},{\"attributes\":{\"doi\":\"arxiv:1206.2944\",\"id\":\"b9\"},\"end\":26480,\"start\":26275},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":10801901},\"end\":26742,\"start\":26482},{\"attributes\":{\"id\":\"b11\"},\"end\":27147,\"start\":26744},{\"attributes\":{\"doi\":\"arXiv:1611.02796\",\"id\":\"b12\"},\"end\":27523,\"start\":27149},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b13\"},\"end\":27717,\"start\":27525},{\"attributes\":{\"id\":\"b14\"},\"end\":27839,\"start\":27719},{\"attributes\":{\"id\":\"b15\"},\"end\":28024,\"start\":27841},{\"attributes\":{\"doi\":\"10.1038/nenergy.2016.102\",\"id\":\"b16\",\"matched_paper_id\":32906098},\"end\":28487,\"start\":28026},{\"attributes\":{\"doi\":\"10.1038/sdata.2014.22\",\"id\":\"b17\"},\"end\":28819,\"start\":28489},{\"attributes\":{\"doi\":\"arXiv:1606.03498\",\"id\":\"b18\"},\"end\":29105,\"start\":28821},{\"attributes\":{\"doi\":\"arXiv:1609.05473\",\"id\":\"b19\"},\"end\":29359,\"start\":29107}]", "bib_title": "[{\"end\":23461,\"start\":23338},{\"end\":24053,\"start\":23929},{\"end\":25625,\"start\":25494},{\"end\":26561,\"start\":26482},{\"end\":28091,\"start\":28026}]", "bib_author": "[{\"end\":22749,\"start\":22736},{\"end\":22972,\"start\":22956},{\"end\":22988,\"start\":22972},{\"end\":23269,\"start\":23258},{\"end\":23471,\"start\":23463},{\"end\":23488,\"start\":23471},{\"end\":23798,\"start\":23790},{\"end\":24075,\"start\":24055},{\"end\":24100,\"start\":24075},{\"end\":24112,\"start\":24100},{\"end\":24124,\"start\":24112},{\"end\":24137,\"start\":24124},{\"end\":24157,\"start\":24137},{\"end\":24167,\"start\":24157},{\"end\":24180,\"start\":24167},{\"end\":24189,\"start\":24180},{\"end\":24197,\"start\":24189},{\"end\":24205,\"start\":24197},{\"end\":24213,\"start\":24205},{\"end\":24225,\"start\":24213},{\"end\":24235,\"start\":24225},{\"end\":24242,\"start\":24235},{\"end\":24251,\"start\":24242},{\"end\":24261,\"start\":24251},{\"end\":24270,\"start\":24261},{\"end\":24281,\"start\":24270},{\"end\":24297,\"start\":24281},{\"end\":24915,\"start\":24895},{\"end\":24927,\"start\":24915},{\"end\":24949,\"start\":24927},{\"end\":24974,\"start\":24949},{\"end\":24986,\"start\":24974},{\"end\":24997,\"start\":24986},{\"end\":25013,\"start\":24997},{\"end\":25299,\"start\":25285},{\"end\":25316,\"start\":25299},{\"end\":25325,\"start\":25316},{\"end\":25639,\"start\":25627},{\"end\":25657,\"start\":25639},{\"end\":25667,\"start\":25657},{\"end\":25681,\"start\":25667},{\"end\":25701,\"start\":25681},{\"end\":25713,\"start\":25701},{\"end\":25730,\"start\":25713},{\"end\":25740,\"start\":25730},{\"end\":25757,\"start\":25740},{\"end\":25763,\"start\":25757},{\"end\":25775,\"start\":25763},{\"end\":25785,\"start\":25775},{\"end\":25796,\"start\":25785},{\"end\":25803,\"start\":25796},{\"end\":25819,\"start\":25803},{\"end\":26291,\"start\":26277},{\"end\":26297,\"start\":26291},{\"end\":26316,\"start\":26297},{\"end\":26574,\"start\":26563},{\"end\":26588,\"start\":26574},{\"end\":26781,\"start\":26770},{\"end\":26792,\"start\":26781},{\"end\":26808,\"start\":26792},{\"end\":26817,\"start\":26808},{\"end\":26829,\"start\":26817},{\"end\":26837,\"start\":26829},{\"end\":26850,\"start\":26837},{\"end\":26861,\"start\":26850},{\"end\":26871,\"start\":26861},{\"end\":26886,\"start\":26871},{\"end\":26898,\"start\":26886},{\"end\":26915,\"start\":26898},{\"end\":26922,\"start\":26915},{\"end\":27247,\"start\":27237},{\"end\":27253,\"start\":27247},{\"end\":27265,\"start\":27253},{\"end\":27275,\"start\":27265},{\"end\":27285,\"start\":27275},{\"end\":27297,\"start\":27285},{\"end\":27304,\"start\":27297},{\"end\":27587,\"start\":27575},{\"end\":27593,\"start\":27587},{\"end\":27766,\"start\":27755},{\"end\":27892,\"start\":27881},{\"end\":28100,\"start\":28093},{\"end\":28120,\"start\":28100},{\"end\":28129,\"start\":28120},{\"end\":28137,\"start\":28129},{\"end\":28145,\"start\":28137},{\"end\":28154,\"start\":28145},{\"end\":28170,\"start\":28154},{\"end\":28180,\"start\":28170},{\"end\":28192,\"start\":28180},{\"end\":28589,\"start\":28573},{\"end\":28597,\"start\":28589},{\"end\":28605,\"start\":28597},{\"end\":28623,\"start\":28605},{\"end\":28833,\"start\":28821},{\"end\":28847,\"start\":28833},{\"end\":28858,\"start\":28847},{\"end\":28868,\"start\":28858},{\"end\":28879,\"start\":28868},{\"end\":28887,\"start\":28879},{\"end\":29180,\"start\":29174},{\"end\":29189,\"start\":29180},{\"end\":29197,\"start\":29189},{\"end\":29203,\"start\":29197}]", "bib_venue": "[{\"end\":22734,\"start\":22690},{\"end\":22954,\"start\":22848},{\"end\":23256,\"start\":23219},{\"end\":23535,\"start\":23509},{\"end\":23788,\"start\":23759},{\"end\":24329,\"start\":24313},{\"end\":24893,\"start\":24809},{\"end\":25371,\"start\":25340},{\"end\":25856,\"start\":25837},{\"end\":26361,\"start\":26331},{\"end\":26604,\"start\":26588},{\"end\":26768,\"start\":26744},{\"end\":27235,\"start\":27149},{\"end\":27573,\"start\":27525},{\"end\":27753,\"start\":27719},{\"end\":27879,\"start\":27841},{\"end\":28229,\"start\":28216},{\"end\":28571,\"start\":28489},{\"end\":28946,\"start\":28903},{\"end\":29172,\"start\":29107}]"}}}, "year": 2023, "month": 12, "day": 17}