{"id": 8953884, "updated": "2023-11-08 15:10:33.25", "metadata": {"title": "Variational Reasoning for Question Answering with Knowledge Graph", "authors": "[{\"first\":\"Yuyu\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Hanjun\",\"last\":\"Dai\",\"middle\":[]},{\"first\":\"Zornitsa\",\"last\":\"Kozareva\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Smola\",\"middle\":[\"J.\"]},{\"first\":\"Le\",\"last\":\"Song\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2017, "month": 9, "day": 12}, "abstract": "Knowledge graph (KG) is known to be helpful for the task of question answering (QA), since it provides well-structured relational information between entities, and allows one to further infer indirect facts. However, it is challenging to build QA systems which can learn to reason over knowledge graphs based on question-answer pairs alone. First, when people ask questions, their expressions are noisy (for example, typos in texts, or variations in pronunciations), which is non-trivial for the QA system to match those mentioned entities to the knowledge graph. Second, many questions require multi-hop logic reasoning over the knowledge graph to retrieve the answers. To address these challenges, we propose a novel and unified deep learning architecture, and an end-to-end variational learning algorithm which can handle noise in questions, and learn multi-hop reasoning simultaneously. Our method achieves state-of-the-art performance on a recent benchmark dataset in the literature. We also derive a series of new benchmark datasets, including questions for multi-hop reasoning, questions paraphrased by neural translation model, and questions in human voice. Our method yields very promising results on all these challenging datasets.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1709.04071", "mag": "2963068946", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aaai/ZhangDKSS18", "doi": "10.1609/aaai.v32i1.12057"}}, "content": {"source": {"pdf_hash": "375519c167cb62e77190c2195d6e180fa4e6a5ca", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1709.04071v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "054862ce62add962e4902fea40a9d1834456ed03", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/375519c167cb62e77190c2195d6e180fa4e6a5ca.txt", "contents": "\nVariational Reasoning for Question Answering with Knowledge Graph\n\n\nYuyu Zhang 1yuyu.zhang@cc.gatech.edu \nCollege of Computing\nGeorgia Institute of Technology\n\n\nHanjun Dai hanjun.dai@cc.gatech.edu \nCollege of Computing\nGeorgia Institute of Technology\n\n\nZornitsa Kozareva 2kozareva@amazon.com \nAmazon Web Services\n\n\nAlexander J Smola smola@amazon.com \nAmazon Web Services\n\n\nLe Song lsong@cc.gatech.edu \nCollege of Computing\nGeorgia Institute of Technology\n\n\nVariational Reasoning for Question Answering with Knowledge Graph\n\nKnowledge graph (KG) is known to be helpful for the task of question answering (QA), since it provides well-structured relational information between entities, and allows one to further infer indirect facts. However, it is challenging to build QA systems which can learn to reason over knowledge graphs based on question-answer pairs alone. First, when people ask questions, their expressions are noisy (for example, typos in texts, or variations in pronunciations), which is nontrivial for the QA system to match those mentioned entities to the knowledge graph. Second, many questions require multi-hop logic reasoning over the knowledge graph to retrieve the answers. To address these challenges, we propose a novel and unified deep learning architecture, and an end-to-end variational learning algorithm which can handle noise in questions, and learn multi-hop reasoning simultaneously. Our method achieves state-of-the-art performance on a recent benchmark dataset in the literature. We also derive a series of new benchmark datasets, including questions for multi-hop reasoning, questions paraphrased by neural translation model, and questions in human voice. Our method yields very promising results on all these challenging datasets.\n\nIntroduction\n\nQuestion answering (QA) has been a long-standing research problem in Machine Learning and Artificial Intelligence. Thanks to the creation of large-scale knowledge graphs such as DBPedia [1] and Freebase [2], QA systems can be armed with well-structured knowledge on specific and open domains. Many traditional approaches for KG-powered QA are based on semantic parsers [3,4,5,6], which first map a question to formal meaning representation (e.g. logical form) and then translate it to a KG query. The answer to the question can be retrieved by executing the query. One of the disadvantages of these approaches is that the model is not trained end-to-end and errors may be cascaded.\n\nWith the recent success of deep learning, some end-to-end solutions based on neural networks have been proposed and show very promising performance on benchmark datasets, such as Memory Networks [7], Key-Value Memory Networks [8] and Gated Graph Sequence Neural Networks [9]. However, these neural approaches treat the KG as a flattened big table of itemized knowledge records, making it hard to exploit the structure information in the graph and thus weak on logic reasoning. When the answer is not a direct neighbor of the topic entity in question (i.e. there are multiple hops between question and answer entities in the KG), which requires logic reasoning over the KG, the neural approaches usually perform poorly. For instance, it is easy to handle single-hop questions like \"Who wrote the paper titled ...? \" by querying itemized knowledge records in triples (paper title, authored by, author name). However, logic reasoning on the KG is required for multihop questions such as \"Who have co-authored papers with ...? \". With the KG, we start from the mentioned author, and follow author authored \u2212\u2212\u2212\u2212\u2212\u2192 paper authored by \u2212 \u2212\u2212\u2212\u2212\u2212\u2212 \u2192 author to find answers. A common remedy is the so-called knowledge graph completion: create new relations for non-neighbor entity pairs in the KG [10,11,12]. However, multi-hop reasoning is combinatorial in nature, i.e. the number of multi-hop relations grow explosively with the increase of hops. For example, if we create new relation types like friend-of-friend and friend-of-friend-of-friend , the number of edges in the KG will explode, which is intractable for both storage and computation.\n\nAnother key challenge is how to locate topic entities in the KG. Most existing works assume that the topic entity in question can be located by simple string matching [8,13,9,5], which is often not true. When people ask questions, either in text or speech, various noise can be introduced in the expressions. For example, people are likely to make typos or name ambiguity in question. In even harder case, audio questions, people may pronounce the same entity differently in different questions, even for the same person. Due to these noises, it is hard to do exact matching to locate topic entities. For text questions, broad matching techniques (e.g. hand-craft rules, regular expressions, edit distance, etc.) are widely used for entity recognition [14]. However, they require domain experts and lots of human effort. For speech questions, it is even harder to match topic entities directly. Most existing QA systems first do speech recognition, converting the audio to text, and then match entities in text. Unfortunately, the error rate is typically high for speech recognition system to recognize entities in voice, such as human names or street addresses. Since it is not end-to-end, the error of the speech recognition system may cascade to affect the downstream QA system. Typically, the training data for QA system is provided as question-answer pairs, where finegrained annotation of these pairs are not available, or only available for a few. More specifically, there are very few explicit annotations of the exact entity present in the question, the type of the questions, and the exact logic reasoning steps along the knowledge graph leading to the answer. Thus it is challenging to simultaneously learn to locate the topic KG entity in the question, and figure out the unknown reasoning steps pointing to the answer based on training question-answer pairs alone.\n\nTo address the challenges mentioned above, we propose an end-to-end learning framework for question answering with knowledge graph named variational reasoning network (VRN), which have the following new features:\n\n\u2022 We build a probabilistic modeling framework for end-to-end QA system, which can simultaneously handle uncertain topic entity and multi-hop reasoning.\n\n\u2022 We propose a novel propagation-like deep learning architecture over the knowledge graph to perform logic inference in the probabilistic model.\n\n\u2022 We apply the REINFORCE algorithm with variance reduction technique to make the system end-to-end trainable.\n\n\u2022 We derive a series of new challenging benchmark datasets MetaQA 1 (MoviE Text Audio QA) intended for research on question-answering systems. These datasets contain over 400K questions for both single-and multi-hop reasoning. To test QA systems in more realistic (and more difficult) scenarios, MetaQA also provides neural-translation-model-paraphrased datasets, and text-to-speech-based audio datasets.\n\nExtensive experiments show that our method achieves state-of-the-art performance on both single-and multi-hop datasets, demonstrating the capability of multi-hop reasoning. Moreover, we obtain promising results on the challenging audio QA datasets, showing the effectiveness of endto-end learning framework. With the rise of virtual assistant tools (e.g. Alexa, Cortana, Google Assistant and Siri), QA systems are now even closer to our daily life. This paper is one step towards more realistic QA systems, which can handle noisy question input in both text and speech, and learn from examples to reason over the knowledge graph.\n\n\nRelated Work\n\nQA with semantic parser: Most traditional approaches for KG-powered QA are based on semantic parsers, which map the question to a certain meaning representation or logical form [3,4,15,5,6], or directly map the question to an executable program [16]. These approaches require domain-specific grammars, rules, or fine-grained annotations. Also, they are not designed to handle noisy questions, and do not support end-to-end training since they use separate stages for question parsing and logic reasoning. Neural approaches for QA: The family of memory networks achieves state-of-the-art performance in various kinds of QA tasks. Some of them are able to do reasoning within local context [17,18] using attention mechanism [19]. For QA with KG, Miller et al. [8] achieves state-ofthe-art performance, outperforming previous works [20,7] on benchmark datasets. Recent work [21] uses neural programmer model for QA with single knowledge table. However, the multi-hop reasoning capability of these approaches depends on recurrent attentions and there is no explicit traversal over the KG. Graph embedding: Recently, researchers have built deep architectures to embed structured data, such as trees [22,23,24] or graphs [25,26,27]. Also some works [9,28] extend it to sequential case like multi-step reasoning. However, these approaches only work on small instances like sentences or molecules. Instead, our work embeds the reasoning-graph from source entity to every target entity in large-scale knowledge graph. Multi-hop reasoning: There are some other works on knowledge graph completion with traversal, which requires path sampling [12,29] or dynamic programming [30]. Our work can handle QA with natural language or human speech, and the reasoning-graph embeddings can represent complicated reasoning rules.\n\nIn summary, most of the existing approaches have separate stages for entity locating, such as keyword matching, frequency-based method, and domain-specific methods [31]. Since they are not jointly trained with the reasoning part, the errors in entity locating (e.g. incorrectly recognized name entity from speech recognition system) will be cascaded to the downstream QA system.  Figure 1: End-to-end architecture of the variational reasoning network (VRN) for question-answering with knowledge graph. The model consists of two probabilistic modules for topic entity recognition (P (y|q)) and logic reasoning over knowledge graph (P (a|y, q)) respectively. Inside the knowledge base plate, the scope of entity Lost Christmas (colored red) is illustrated, and each colored ellipsoid plate corresponds to the reasoning graph leading to a potential answer colored in yellow. The reasoning graphs are efficiently embedded and scored against the question embeddings to retrieve the best answer. During training, to handle the non-differentiable sampling operation y \u223c P (y|q), we use variational posterior with the REINFORCE algorithm.\n\n\nModel\n\n\nProblem definition\n\nKnowledge base/graph (KG): A knowledge graph is a directed graph where the entities and their relations are represented by nodes and edges, respectively, i.e. G = (V (G), E(G)). Furthermore, each edge from E(G) is a triplet (a 1 i , r i , a 2 i ), representing a directed relation r i between subject entity a 1 i and object entity a 2 i both from the node set V (G). Each entity in the knowledge graph can also contain additional information such as type and text description. For instance, entity a 1 i is described as actor Jennifer Lawrence, and entity a 2 i is movie Passengers. Then a relation in the knowledge graph can be (Jennifer Lawrence, acted in, Passengers), where the corresponding r i is acted in. In this work, we assume that the knowledge graph is given. Question answering with KG: Given a question q, the algorithm is asked to output an entity in the knowledge graph which properly answers the question. For example, q can be a question like \"who acted in the movie Passengers?\", and one possible answer is Jennifer Lawrence, which is an entity in the KG. In a more challenging setting, q can even be an audio segment reading the same question. The training set\nD train = {(q i , a i )} N i=1\ncontains N pairs of question and answers. Note that fine-grained annotation is not present, such as the exact entity present in the question, question type, or the exact logic reasoning steps along the knowledge graph leading to the answer. Thus, a QA system with KG should be able to handle noisy entity in questions and learn multi-hop reasoning directly from question-answer pairs.\n\n\nOverall formulation\n\nTo address both key challenges in a unified probabilistic framework, we propose the variational reasoning network (VRN). The overall architecture is shown in Fig 1. VRN consists of two probabilistic modules, as described below. Module for topic entity recognition: Recognizing the topic entity y (or the entity mentioned in the question) is the first step in performing logic reasoning over the knowledge graph 2 . For example, the topic entity mentioned in Sec 3.1 is the movie Passenger. We denote such entity as y, and model the compatibility of this entity with the question q as a probabilistic model P \u03b8 1 (y|q), which shows the probability of the KG entity y being mentioned in the question q. Depending on the question form (text or audio), the parameterization of P \u03b8 1 (y|q) may be different and details can be found in Sec 3.3. Module for logic reasoning over knowledge graph: Given the topic entity y, one need to reason over the knowledge graph to find out the answer a. As described in Sec 3.1, the algorithm should learn to use the reasoning rule (y, acted by, a) for that question. Since there is no annotations for such reasoning step, the QA system has to learn it only from question-answer pairs. Thus we model the likelihood of an answer a being correct given entity y and question q as P \u03b8 2 (a|y, q). The parameterization of P \u03b8 2 (a|y, q) need to capture traversal or reasoning over knowledge graph, which is explained in detail in Sec 3.4.\n\nSince the topic entity in question is not annotated, it is natural to formulate the problem by treating the topic entity y as a latent variable. With the two probabilistic components above, we model the probability of answer a being correct given question q as y\u2208V (G) P \u03b8 1 (y|q i )P \u03b8 2 (a i |y, q i ), which sums out all possibilities of the latent variable. Given a training set D train of N questionanswer pairs, the set of parameters \u03b8 1 and \u03b8 2 can be estimated by maximizing the log-likelihood of this latent variable model:\nmax \u03b8 1 ,\u03b8 2 1 N N i=1 log \uf8eb \uf8ed y\u2208V (G) P \u03b8 1 (y|q i )P \u03b8 2 (a i |y, q i ) \uf8f6 \uf8f8 .\n(1)\n\nNext we will describe our parametrization of P \u03b8 1 (y|q) and P \u03b8 2 (a|y, q), and the algorithms for learning and inference based on that.\n\n\nProbabilistic module for topic entity recognition\n\nMost existing QA approaches assume that topic entities are annotated, or can be simply found via string matching. However, for more realistic questions or even audio questions, a more general approach is to build a recognizer that can be trained jointly with the logic reasoning engine.\n\nTo handle unlabeled topic entities, we notice that the full context of the question can be helpful. For example, Michael could either be the name of a movie or an actor. It is hard to tell which one relates to the question by merely looking at this entity name. However, we should be able to resolve the unique entity by checking the surrounding words in the question. Similarly, in the knowledge graph there could be multiple entities with the same name, but the connected edges (relations) of the entity nodes are different, which helps to resolve the unique entity. For example, as a movie name, Michael may be connected with a directed by edge pointing to an entity of director; while as an actor name, Michael may be connected with birthday and height edges.\n\nSpecifically, we use a neural network f ent (\u00b7) : q \u2192 R d which can represent the question q in a d dimensional vector. Depending on the question form (text or audio), this neural network can be a simple embedding network mapping bag-of-words to a vector, or a recurrent neural network to embed sentences, or a convolution neural network to embed audio questions. Thus the probability of having y in q is\nP \u03b8 1 (y|q) = softmax W y f ent (q) (2) = exp(W y f ent (q)) y \u2208V (G) exp(W y f ent (q)) ,(3)\nwhere W y \u2208 R d , \u2200y \u2208 V (G) are the weights in the last classification layer. This parameterization avoids heuristic keyword matching for the entity as is done in previous work [8,20], and makes the entity recognition process differentiable and end-to-end trainable.\n\n\nProbabilistic module for logic reasoning over knowledge graph\n\nAlgorithm 1 Joint training of VRN 1: Initialize \u03b8 1 , \u03b8 2 , \u03c6 with small labeled set 2: for i = 1 to n do 3:\n\nSample (q i , a i ) from the training data 4:\n\nSample {y j } M j=1 using (8) 5:\nSmoothing\u03bc,\u03c3 with {A(y j , a i , q i )} M j=1 6:\nUpdate the baseline b(a, q) using least square 7: \u03c8 \u2190 \u03c8 \u2212 \u03b7\u2207 \u03c8 L using (10) 8:\n\u03b8 1 \u2190 \u03b8 1 \u2212 \u03b7\u2207 \u03b8 1 L, \u03b8 2 \u2190 \u03b8 2 \u2212 \u03b7\u2207 \u03b8 2 L 9: end for\nParameterizing the reasoning model P \u03b8 2 (a|y, q) is challenging, since 1) the knowledge graph can be very large; 2) the required logic reasoning is unknown and can be multi-step. In other words, retrieving the answer requires multi-step traversal over a gigantic graph. Thus in this paper, we propose a reasoning-graph embedding architecture, where all the inference rules and their complex combinations are represented as nonlinear embeddings in vector space and will be learned. Scope of y. More specifically, we assume the maximum number of steps (or hops), T , of the logic reasoning is known to the algorithm. Starting from a topic entity y, we perform topological sort (ignoring the original edge direction) for all entities within T hops according to the knowledge graph. After that, we get an ordered list of entities a 1 , a 2 , . . . , a m and their relations from the knowledge graph. We call this subgraph G y with ordered nodes as the scope of y. Fig 2 shows an example of a 2-hop scope, where entities are labeled with their topological distance to the source entity.\n\nReasoning graph to a. Given a potential answer a in the scope G y , we denote G y\u2192a to be the minimum subgraph that contains all the paths from y to a in G y . The actual logic reasoning leading to answer a for question q is unknown but hidden in the reasoning graph. Thus we will learn a vector representation (or embedding) for G y\u2192a , denoted as g(G y\u2192a ) \u2208 R d , for scoring the compatibility of the question type and the hidden path in the reasoning graph.\n\nMore specifically, suppose the question is embedded using a neural network f qt (\u00b7) : q \u2192 R d , which captures the question type and implies the type of logic reasoning we need to perform over knowledge graph. Then the compatibility (or likelihood) of answer a being correct can be computed using the embedded reasoning graph G y\u2192a and the scope G y as\nP \u03b8 2 (a|y, q) = softmax f qt (q) g(G y\u2192a ) (4) = exp(f qt (q) g(G y\u2192a )) a \u2208V (Gy) exp(f qt (q) g(G y\u2192a )) .(5)\nWe note that the normalization in the likelihood requires the embedding of the reasoning graphs for all entities a in the scope G y . This may involve thousands of or even more reasoning graphs depending on the KG and the number of hops. Computing these embeddings separately can be very computationally expensive. Instead, we develop a neural architecture which can compute these embeddings jointly and share intermediate computations.\n\nJoint embedding reasoning graphs. More specifically, we propose a \"forward graph embedding\" architecture, which is analogous to forward filtering in Hidden Markov Model or Bayesian Network. The embedding of the reasoning graph for a is computed recursively using its parents' embeddings:\ng(G y\u2192a ) = 1 #Parent(a)\na j \u2208Parent(a),(a j ,r,a) or (a,r,a j )\u2208Gy\n\u03c3(V \u00d7 [g(G y\u2192a j ), e r ]),(6)\nwhere e r is the one-hot encoding of relation type r \u2208 R, V \u2208 R d\u00d7(d+|R|) are the model parameters, \u03c3(\u00b7) is a nonlinear function such as ReLU, and #Parent(a) counts the number of parents of a in G y . The only boundary case is g(G y\u2192y ) = 0 when y = a. Overall, computing the embedding g(G y\u2192a ) for all a takes O(|V (G y )| + |E(G y )|) time, which is proportional to the number of nodes and edges in the scope G y . This formulation is able to capture various reasoning rules. Take Fig 2 as an example: the embedding of the entity Killing Them Softly sums up the two embeddings propagated from its parents. Thus it tends to match the reasoning paths from the parent entities. Note that this formulation is significantly different from the work in [25,26,27], where embedding is computed for each small molecular graph separately. Furthermore, those graph embedding methods often contain iterative processes which visit each nodes multiple times.\n\n\nEnd-to-end Learning\n\nIn this section, we describe the algorithm for learning the parameters in P \u03b8 1 (y|q) and P \u03b8 2 (a|y, q). The overall learning algorithm is described in Algorithm 1.\n\n\nVariational method with inverse reasoning-graph embedding\n\nEM algorithm is often used to learn latent variable models. However, performing exact EM updates for the objective in (1) is intractable since the posterior cannot be computed in closed form. Instead, we use variational inference and optimize the negative Helmholtz variational free energy:\nmax \u03c8,\u03b8 1 ,\u03b8 2 L(\u03c8, \u03b8 1 , \u03b8 2 ) = 1 N N i=1 E Q \u03c8 (y|q i ,a i ) [ log P \u03b8 1 (y|q i ) + log P \u03b8 2 (a i |y, q i ) \u2212 log Q \u03c8 (y|q i , a i )],(7)\nwhere the variational posterior Q \u03c8 (y|q, a) is jointly learned with the model. Note that (7) is essentially optimizing the lower bound of (1). Thus to reduce the approximation error, a powerful set of posterior distributions is necessary. Variational posterior. Q \u03c8 computes the likelihood of the topic entity y for a question q, with additional information of answer a. Thus besides the direct text or acoustic compatibility of y and q, we can also introduce logic match with the help of a. Similar to the forward propagation architecture used in Sec 3.4, here we can define the scope G a for answer a, the inverse reasoning graph G a\u2192y , and the inverse embedding architecture to efficiently compute the embeddingg(G a\u2192y ). Finally, the variational posterior consists of two parts:\nQ \u03c8 (y|q, a) \u221d exp W yf ent (q) +f qt (q) g(G a\u2192y ) ,(8)\nwhere the normalization is done over all entities y in the scope G a . Furthermore, the embedding operatorsf ent ,f qt and parameters {W y } y\u2208V (G) are defined in the same way as (4) and (6) but with different set of parameters. One can also share the parameter to obtain a more compact model.\n\n\nREINFORCE with variance reduction\n\nSince the latent variable y in the variational objective (7) takes discrete values, which is not differentiable with respect to \u03c8, we use the REINFORCE algorithm [32] with variance reduction [33] to tackle this problem. First, using the likelihood ratio trick, the gradient of L with respect to posterior parameters \u03c8 can be computed as (for simplicity of notation, we assume that there is only one training instance, i.e. N = 1): where A(y, a, q) = log P \u03b8 1 (y|q) + log P \u03b8 2 (a|y, q) \u2212 log Q \u03c8 (y|q, a) can be treated as the learning signal in policy gradient. Second, to reduce the variance of gradient, we center and normalize the signal A(y, a, q) and also subtract a baseline function b(a, q) [33]. Finally, the gradient in (9) can be approximated by the Monte Carlo method using K samples of the latent variable from Q \u03c8 :\n\u2207 \u03c8 L = E Q \u03c8 (y|a,q) \u2207 \u03c8 log Q \u03c8 (y|a, q) A(y, a, q) ,(9)\u2207 \u03c8 L \u2248 1 K K j=1 \u2207 \u03c8 log Q \u03c8 (y j |a, q) (A(y j ,a,q)\u2212\u03bc) \u03c3 \u2212 b(a, q) ,(10)\nwhere\u03bc and\u03c3 estimate the mean and standard deviation of A(y j , a, q) with moving average. b(a, q) is another neural network that fits the expected normalized learning signal. In our experiments, we simply build a two-layer perceptron with concatenated one-hot answer and question features. Here b(a, q) tries to fit\u00c3(y j , a, q) = (A(y j ,a,q)\u2212\u03bc) \u03c3 by minimizing the square loss. For other parameters \u03b8 1 and \u03b8 2 in P \u03b8 1 (y|q) and P (\u03b8 2 ) (a|y, q) respectively, the gradients are computed in the normal way.\n\n\nInference\n\nDuring inference, we are only given the question q, and ideally we want to find the answer by computing arg max y,a log (P \u03b8 1 (y|q)P \u03b8 2 (a|y, q)). However, this computation is quadratic in the number of entities and thus too expensive. Alternatively, we can approximate it via beam search. So we select k candidate entities y 1 , y 2 , . . . , y k with top scores from P \u03b8 1 (y|q), and then the answer is given by a * = argmax a\u2208Gy,y\u2208{y 1 ,y 2 ,...,y k } log P \u03b8 2 (a|y, q).\n\nIn our experiments, we found that k = 1 (equivalent as greedy inference) can already achieve good performance.\n\n\nExperiments\n\n\nThe MetaQA benchmark\n\nThere is an existing public QA dataset named WikiMovies 3 , which consists of question-answer pairs in the domain of movies and provides a medium-sized knowledge graph [8]. However, it has  ; 2) there is no noise on the topic entity in question, so it can be easily located in the knowledge graph; 3) it is generated from very limited number of text templates, which is easy to be exploited by models and of limited practical value. Some small datasets like WebQuestions [5] are mostly for single-hop questions; while WikiTableQuestions [34] involves tiny knowledge table for each question, instead of one large-scale knowledge graph shared among all questions. Thus in this paper, we introduce a new challenging question-answer benchmark: MetaQA (MoviE Text Audio QA). It contains more than 400K questions for both single and multi-hop reasoning, and provides more realistic text and audio versions. MetaQA serves as a comprehensive extension of WikiMovies. Due to the page limit, we briefly list the datasets included in MetaQA below, and put more details in Appendix A. \u2022 NTM: Thanks to the recent breakthrough in neural translation models (NTM), we can introduce more variations over the Vanilla datasets. We use a NTM trained by dual learning techniques [35] to paraphrase question by first translating it from English to French, and then sample translations back to English with beam search. The questions in the NTM dataset have different wordings but keep the same meaning. This dataset also contains 1-hop, 2-hop and 3-hop categories.\n\n\u2022 Audio: To make it even more practical and challenging, we generate audio datasets with the help of text-to-speech (TTS) system. We use Google TTS service to read all the questions in Vanilla. We also provide extracted MFCC features for each question. The Audio dataset also contains 1-hop, 2-hop and 3-hop categories. Note that although the audio is machinegenerated, it is still much less regulated compared to text-template-generated data, and have a lot of variations in waveforms. For example, even for the same word, the TTS system can have different intonations depending on the word position in question and other context words. Visualization of the audio data can be found in Appendix C. \n\n\nVanilla-EU NTM-EU\n\nPerformance improvement of entity recognizer 5% init joint train Figure 3: Improvement of the entity recognizer.\n\n\nCompetitor methods\n\nWe have three competitor methods: 1) as discussed in Sec 2, Miller et al. [8] proposed Key-Value Memory Networks (KV-MemNN), and reported state-of-the-art results at that time on WikiMovies; 2) Bordes et al. [20]'s QA system also tries to embed the inference subgraph for reasoning, but the representation is simply an unordered bag-of-relationships and neighbor entities; 3) the \"supervised embedding\" is considered as yet another baseline method, which is a simple approach but often works surprisingly well as reported in Dodge et al. [13]. We implement baseline methods with Tensorflow [36]. Our results on Vanilla 1-hop are consistent with the reported performance in [8]. We take whichever higher and report it in Table 1. For example, our KV-MemNN obtains 95.8% test accuracy, while the original paper reports 93.9% on the same dataset, so we just report 95.8% in table.\n\nWhen training KV-MemNN, we use the same number of \"internal hops\" as the hop number of that dataset. We also try to use more \"internal hops\" than the dataset hop number, but it is not helpful. Also, we insert knowledge items within 3 hops of the located topic entity to the memory slots, which ensures that if the topic entity is correctly matched, the answer is existing somewhere in the memory array.\n\n\nExperimental settings\n\nWe use all the datasets in MetaQA for experiments. We follow the same split of train/validation/test for all datasets. The number of questions in each part is listed in Appendix (Table 3). We tune hyperparameters on validation set for all methods. In both Vanilla and NTM, we use bag-of-words representation for entity name to parameterize W y in (3).\n\nFor Vanilla, we have two different settings: 1) provide the entity labels in all questions, so that we can compare with KV-MemNN under the same setting of Miller et al. [8] on Vanilla 1-hop dataset; 2) only provide 5% entity labels among all questions, named as Vanilla-EU (EU stands for topic entity unlabeled). We make all the methods use bag-of-words representation of the question, and avoid hard entity matching. This setting is more of a sanity check of how much the method is dependent on labeled topic entities. In practice, hard matching can always be an option on text data, but it is not feasible for audio data.\n\nTo make task more realistic and challenging, we experiment with EU setting for NTM and Audio datasets. For NTM-EU, only 5% topic entity labels among all questions are provided. For Audio-EU, a higher labeled ratio 20% since it is much more difficult than text data. To handle the variant length of audio questions, we use a simple convolutional neural network (CNN) with three convolutional layers and three max-pooling layers to embed the audio questions into fixed-dimension vectors. We put more details about CNN embedding in Appendix D.\n\nFor all the EU setting above, the small set of entity labeled questions are used to initialize a topic entity recognizer. After that, all methods train on entire dataset but without the entity labels. For VRN, we show that this pretrained recognizer will also get improved with variational joint training; for other baselines, the entity recognizer will be fixed.\n\n\nResults and discussions\n\nThe experimental results are listed in Table 1 and Table 2. Vanilla: Since all the topic entities are labeled, Vanilla mainly evaluates the ability of logic reasoning. Note that Vanilla 1-hop is the same as WikiMovies, which is included for sanity check. All the baseline methods achieve similar performance as reported in the original papers [8,20], while our method performs the best. It is clear to see that 2-and 3-hop questions are harder, leading to significant accuracy drop on all methods. Nevertheless, our method still achieves promising results and lead competitors by a large margin. We notice that KV-MemNN is not performing well on multi-hop reasoning, perhaps due to explosion of relevant knowledge items. Vanilla-EU: Without topic entity labels, all reasoning-based methods are getting worse on multihop questions. However, supervised embedding gets better in this case, since it just learns to remember the pair of question and answer entities. According to the statistics in Appendix (Table 4), a big portion of questions can be answered by just memorizing the pairs in training data. That explains why supervised embedding behaves differently on this dataset. NTM-EU: The questions in this dataset are paraphrased by neural translation model, which increases the variety of wordings, and makes the task harder. It is reasonable that all methods are getting slightly worse results compared to Vanilla-EU. The same explanation applies to supervised embedding, which is not reasoning but memorizing all the pairs. This is indeed weak generalization and it takes advantage of the nature of this dataset, but it is not likely to perform well on new entity pairs. Audio-EU: This audio dataset is the most challenging one. As mentioned in Sec 6.1, even the same word can be pronounced in a variety of intonations. It is hard to recognize the entity in audio data, also hard to tell the question type. It is not surprising that all methods perform worse compared to text data. Our method achieves 37% on 1-hop audio questions, which is very promising. For 2-hop and 3-hop questions, our method still outperforms other methods. Clearly, there is large room for improvement on audio QA. We leave it as future work, and hopefully the MetaQA benchmark can facilitate more researchers working on QA systems.\n\n\nModel ablation\n\nSince our framework uses variational method to jointly learn the entity recognizer and reasoning graph embedding, we here do the model ablation to answer the following two questions: 1) is the reasoning graph embedding approach necessary for inference? 2) is the variational method helpful for joint training? Importance of reasoning graph embedding: As the results shown in Table 1, our proposed VRN outperforms all the other baselines, especially in 3-hop setting. Since this experiment only compares the reasoning ability, it clearly shows that simply representing the inference rule as linear combination of reasoning graph entities is not enough. Improvement of entity recognition with joint training: In Fig 3 we show that using our joint training framework with variance reduction REINFORCE, we can improve the entity recognition performance further without the corresponding topic entity label supervision. For 1-hop and 2-hop questions, our model can improve greatly. While for 3-hop, since the inference task is much harder, we can only marginally improve the performance. For audio data, we've improved by 10% in 1-hop case, and it is hard to improve further for multi hops. In Table 1 the baselines perform much worse in the EU setting, due to the absence of joint training.\n\n\nInspection of learning and inference\n\nWe study the convergence of our learning algorithm in Appendix E.1. It shows variance reduction technique helps the convergence significantly, while simpler tasks converge better. Also we present an example inference path with highest score in the reasoning graph in Appendix E.2. To answer \"What are the main languages in David Mandel films? \", the model learns to find the movie EuroTrip first through directed or wrote relationships, then follow in language to get the correct answer German.    \n\n\nC Visualization of audio data\n\nWe visualize the MFCC features of two questions sharing the same entity, as in Fig 6. It is clear that the entity part (highlighted by red dotted lines) is similar but not exactly the same. This shows the difficulty of handling the audio questions.\n\n\nD Details of CNN embedding\n\nTo answer audio questions, we need information of both the topic entity in question, and the question type, i.e. what is asking about that entity. So we train two CNNs with different objectives: one is to predict the topic entity, and the other is to predict the question type. We use the same input (MFCC features of audio questions) for both CNNs, and only use training data to fit them. We treat the activations of the second last layer (before softmax layer) as the embeddings of audio questions.\n\n\nE More experiment results\n\n\nE.1 Convergence of VRN\n\nWe visualize the training loss in Fig 4 to get an idea of how it converges. We can see using the variance reduction technique, the training converges very fast. Also as expected, for simpler tasks involving fewer inference steps, they can converge to a better solution.\n\n\nE.2 Visualization of the learned reasoning rule\n\nTo check what the reasoning graph have learned, we visualize the inference path with highest score in the reasoning-graph. Specifically, for 1-hop answers, we simply check the compatibility between  edge type and question embedding; for answers with multi-hop, we traverse from answer to topic entity, and take the edge whose embedding has maximum compatibility with the question. We show one 2-hop inference result in Fig 5. To answer the NTM question correctly, one need to use either directed or wrote relation to find the movie EuroTrip first, then follow in language to get the correct answer German.\n\nFigure 2 :\n2A question like \"movie sharing same genre and director \" would require two reasoning paths y \u2192 Crime \u2192 a and y \u2192 Andrew Dominik \u2192 a. The vector representation should encode the information of the entire reasoning-graph, which can be computed recursively. Thus the embedding of Andrew Dominik can be reused by The assassination and Killing Them Softly.\n\n\u2022\nVanilla: We have the original WikiMovies as the Vanilla 1-hop dataset. For multi-hop reasoning, we design 21 types of 2-hop questions and 15 types of 3-hop questions, and generate them by random sampling from a text template pool. Details and question examples are in Appendix B.\n\nFigure 4 :\n4Convergence of our VRN on different text datasets. Here X-axis represents # mini-batch, and Y-axis reports the total loss for learning \u03b8 1 , \u03b8 2 , \u03c8 and baseline b(q, a).Vanilla: What are the primary languages in the movies directed by David Mandel? NTM: What are the main languages in David Mandel films?\n\nFigure 5 :\n5Example of the learned 2-hop inference.\n\n\n) MFCC features of the shared entity in both questions: Dolly Parton.\n\nFigure 6 :\n6Visualization of the MFCC features of two questions sharing the same entity. The red dotted box highlights the entity parts.\n\nTable 1 :\n1Test results (% hits@1) on Vanilla and Vanilla-EU datasets. EU stands for entity unlabeled.Vanilla \n1-hop \n\nVanilla \n2-hop \n\nVanilla \n3-hop \n\nVanilla-EU \n1-hop \n\nVanilla-EU \n2-hop \n\nVanilla-EU \n3-hop \n\nVRN \n97.5 \n89.9 \n62.5 \n82.0 \n75.6 \n38.3 \nBordes et al. [20]'s QA system \n95.7 \n81.8 \n28.4 \n39.5 \n38.3 \n26.9 \nKV-MemNN \n95.8 \n25.1 \n10.1 \n35.8 \n10.3 \n10.5 \nSupervised embedding \n54.4 \n29.1 \n28.9 \n18.1 \n23.2 \n25.3 \n\n\n\nTable 2 :\n2Test results (% hits@1) on NTM-EU and Audio-EU datasets. EU stands for entity unlabeled.NTM-EU \n1-hop \n\nNTM-EU \n2-hop \n\nNTM-EU \n3-hop \n\nAudio-EU \n1-hop \n\nAudio-EU \n2-hop \n\nAudio-EU \n3-hop \n\nVRN \n81.3 \n69.7 \n38.0 \n37.0 \n24.6 \n21.1 \nBordes et al. [20]'s QA system \n32.5 \n32.3 \n25.3 \n18.5 \n19.3 \n15.3 \nKV-MemNN \n33.9 \n8.7 \n10.2 \n4.3 \n7.0 \n15.3 \nSupervised embedding \n16.1 \n22.8 \n24.2 \n4.1 \n6.1 \n12.1 \n\nseveral limitations: 1) all questions in it are single-hop, thus it is not able to evaluate the ability \nof reasoning\n\nTable 3 :\n3Statistics of the datasets in the MetaQA benchmark.# of Questions \n\n1-hop \n2-hop \n3-hop \n\nTrain \n96,106 118,980 114,196 \nValidation \n9,992 \n14,872 \n14,274 \nTest \n9,947 \n14,872 \n14,274 \n\n\n\nTable 4 :\n4Ratios of new entities and new entity pairs in each dataset.1-hop 2-hop 3-hop \n\n\nOur new benchmark dataset collections MetaQA are publicly available at https://goo.gl/f3AmcY.\nIn this paper, we consider the case with single topic entity in each question.\nIt is available at https://research.fb.com/downloads/babi.\nWe use the API from https://github.com/pndurette/gTTS.\nAppendix A Details of the MetaQA benchmarkVanilla 1-hop dataset: Our Vanilla 1-hop dataset is derived from the WikiMovies dataset. Following the settings in[8], we use the wiki entities branch of WikiMovies. To make it easier to use, we apply an automatic entity labeling on the dataset. Specifically, we parse each question with left-to-right largest consumption of entity names and then normal words, and highlight the entity in question with a pair of square brackets. A few entity names are identical to normal words, which will lead to \"fake entities\" to be labeled in the question. For simplicity, we just remove those ambiguous questions, which makes our Vanilla 1-hop text dataset slightly smaller than WikiMovies. We also provide corresponding question type identifier files for train / validation/ test sets.Table 5 and Table 6.Year 8,752When did the films release whose screenwriters also wrote Crash?\nDbpedia: A nucleus for a web of open data. The semantic web. S\u00f6ren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, Zachary Ives, S\u00f6ren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. Dbpedia: A nucleus for a web of open data. The semantic web, 2007.\n\nFreebase: a collaboratively created graph database for structuring human knowledge. Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, Jamie Taylor, Proceedings of the 2008 ACM SIGMOD international conference on Management of data. the 2008 ACM SIGMOD international conference on Management of dataKurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, 2008.\n\nDriving semantic parsing from the world's response. James Clarke, Dan Goldwasser, Ming-Wei Chang, Dan Roth, Proceedings of the fourteenth conference on computational natural language learning. the fourteenth conference on computational natural language learningJames Clarke, Dan Goldwasser, Ming-Wei Chang, and Dan Roth. Driving semantic parsing from the world's response. In Proceedings of the fourteenth conference on computational natural language learning, 2010.\n\nLearning dependency-based compositional semantics. Percy Liang, Dan Michael I Jordan, Klein, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies1Percy Liang, Michael I Jordan, and Dan Klein. Learning dependency-based compositional semantics. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, 2011.\n\nSemantic parsing on freebase from question-answer pairs. Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Proceedings of the Conference on Empirical Methods in Natural Language Processing. the Conference on Empirical Methods in Natural Language ProcessingJonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. Semantic parsing on freebase from question-answer pairs. In In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2013.\n\nSemantic parsing via staged query graph generation: Question answering with knowledge base. Ming-Wei Wen-Tau Yih, Xiaodong Chang, Jianfeng He, Gao, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics. the 53rd Annual Meeting of the Association for Computational LinguisticsWen-tau Yih, Ming-Wei Chang, Xiaodong He, and Jianfeng Gao. Semantic parsing via staged query graph generation: Question answering with knowledge base. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, 2015.\n\n. Jason Weston, Sumit Chopra, Antoine Bordes, arXiv:1410.3916Memory networks. arXiv preprintJason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. arXiv preprint arXiv:1410.3916, 2014.\n\nAlexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein, Antoine Karimi, Jason Bordes, Weston, arXiv:1606.03126Key-value memory networks for directly reading documents. arXiv preprintAlexander Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Ja- son Weston. Key-value memory networks for directly reading documents. arXiv preprint arXiv:1606.03126, 2016.\n\nGated graph sequence neural networks. Yujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel, arXiv:1511.05493arXiv preprintYujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015.\n\nReasoning with neural tensor networks for knowledge base completion. Richard Socher, Danqi Chen, D Christopher, Andrew Manning, Ng, Advances in Neural Information Processing Systems. Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, pages 926-934, 2013.\n\nKnowledge vault: A web-scale approach to probabilistic knowledge fusion. Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, Wei Zhang, SIGKDD. Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. Knowledge vault: A web-scale approach to proba- bilistic knowledge fusion. In SIGKDD, 2014.\n\nTraversing knowledge graphs in vector space. Kelvin Guu, John Miller, Percy Liang, arXiv:1506.01094arXiv preprintKelvin Guu, John Miller, and Percy Liang. Traversing knowledge graphs in vector space. arXiv preprint arXiv:1506.01094, 2015.\n\nEvaluating prerequisite qualities for learning end-to-end dialog systems. Jesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Szlam, Jason Weston, arXiv:1511.06931arXiv preprintJesse Dodge, Andreea Gane, Xiang Zhang, Antoine Bordes, Sumit Chopra, Alexander Miller, Arthur Szlam, and Jason Weston. Evaluating prerequisite qualities for learning end-to-end dialog systems. arXiv preprint arXiv:1511.06931, 2015.\n\nEntity linking: Finding extracted entities in a knowledge base. Delip Rao, Paul Mcnamee, Mark Dredze, Multi-source, multilingual information extraction and summarization. SpringerDelip Rao, Paul McNamee, and Mark Dredze. Entity linking: Finding extracted entities in a knowledge base. In Multi-source, multilingual information extraction and summarization, pages 93-115. Springer, 2013.\n\nScaling semantic parsers with on-the-fly ontology matching. Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, Luke Zettlemoyer, EMNLP. Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer. Scaling semantic parsers with on-the-fly ontology matching. In EMNLP, 2013.\n\nNeural symbolic machines: Learning semantic parsers on freebase with weak supervision. Chen Liang, Jonathan Berant, Quoc Le, D Kenneth, Ni Forbus, Lao, arXiv:1611.00020arXiv preprintChen Liang, Jonathan Berant, Quoc Le, Kenneth D Forbus, and Ni Lao. Neural symbolic machines: Learning semantic parsers on freebase with weak supervision. arXiv preprint arXiv:1611.00020, 2016.\n\nAsk me anything: Dynamic memory networks for natural language processing. Ankit Kumar, Ozan Irsoy, Jonathan Su, James Bradbury, Robert English, Brian Pierce, Peter Ondruska, Ishaan Gulrajani, Richard Socher, arXiv:1506.07285arXiv preprintAnkit Kumar, Ozan Irsoy, Jonathan Su, James Bradbury, Robert English, Brian Pierce, Pe- ter Ondruska, Ishaan Gulrajani, and Richard Socher. Ask me anything: Dynamic memory networks for natural language processing. arXiv preprint arXiv:1506.07285, 2015.\n\nEnd-to-end memory networks. Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, Advances in neural information processing systems. Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end memory networks. In Advances in neural information processing systems, pages 2440-2448, 2015.\n\nStacked attention networks for image question answering. Z Yang, X He, J Gao, L Deng, A J Smola, arXiv:1511.02274arXiv preprintZ. Yang, X. He, J. Gao, L. Deng, and A.J. Smola. Stacked attention networks for image question answering. arXiv preprint arXiv:1511.02274, 2015.\n\nQuestion answering with subgraph embeddings. Antoine Bordes, Sumit Chopra, Jason Weston, arXiv:1406.3676arXiv preprintAntoine Bordes, Sumit Chopra, and Jason Weston. Question answering with subgraph em- beddings. arXiv preprint arXiv:1406.3676, 2014.\n\nLearning a natural language interface with neural programmer. Arvind Neelakantan, V Quoc, Martin Le, Andrew Abadi, Dario Mccallum, Amodei, arXiv:1611.08945arXiv preprintArvind Neelakantan, Quoc V Le, Martin Abadi, Andrew McCallum, and Dario Amodei. Learn- ing a natural language interface with neural programmer. arXiv preprint arXiv:1611.08945, 2016.\n\nRecursive deep models for semantic compositionality over a sentiment treebank. Richard Socher, Alex Perelygin, Y Jean, Jason Wu, Chuang, D Christopher, Manning, Y Andrew, Christopher Ng, Potts, EMNLP. Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, An- drew Y Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP, 2013.\n\nDeep recursive neural networks for compositionality in language. Ozan Irsoy, Claire Cardie, Advances in Neural Information Processing Systems. Ozan Irsoy and Claire Cardie. Deep recursive neural networks for compositionality in language. In Advances in Neural Information Processing Systems, pages 2096-2104, 2014.\n\nConvolutional neural networks over tree structures for programming language processing. Lili Mou, Ge Li, Lu Zhang, Tao Wang, Zhi Jin, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. the Thirtieth AAAI Conference on Artificial IntelligenceLili Mou, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. Convolutional neural networks over tree structures for programming language processing. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, 2016.\n\nConvolutional networks on graphs for learning molecular fingerprints. Dougal David K Duvenaud, Jorge Maclaurin, Rafael Iparraguirre, Timothy Bombarell, Al\u00e1n Hirzel, Ryan P Aspuru-Guzik, Adams, Advances in Neural Information Processing Systems. David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Al\u00e1n Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. In Advances in Neural Information Processing Systems, pages 2215- 2223, 2015.\n\nDiscriminative embeddings of latent variable models for structured data. Hanjun Dai, Bo Dai, Le Song, ICML. Hanjun Dai, Bo Dai, and Le Song. Discriminative embeddings of latent variable models for structured data. In ICML, 2016.\n\nDiffusion-convolutional neural networks. James Atwood, Don Towsley, Advances in Neural Information Processing Systems. James Atwood and Don Towsley. Diffusion-convolutional neural networks. In Advances in Neural Information Processing Systems, pages 1993-2001, 2016.\n\nLearning graphical state transitions. Daniel D Johnson, Proceedings of the 5th International Conference on Learning Representations, ICLR'17. the 5th International Conference on Learning Representations, ICLR'17Daniel D. Johnson. Learning graphical state transitions. In Proceedings of the 5th International Conference on Learning Representations, ICLR'17, 2017.\n\nCompositional vector space models for knowledge base completion. Arvind Neelakantan, Benjamin Roth, Andrew Mccallum, arXiv:1504.06662arXiv preprintArvind Neelakantan, Benjamin Roth, and Andrew McCallum. Compositional vector space models for knowledge base completion. arXiv preprint arXiv:1504.06662, 2015.\n\nCompositional learning of embeddings for relation paths in knowledge bases and text. Kristina Toutanova, Victoria Xi, Wen-Tau Lin, Hoifung Yih, Chris Poon, Quirk, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational Linguistics1Kristina Toutanova, Xi Victoria Lin, Wen-tau Yih, Hoifung Poon, and Chris Quirk. Compo- sitional learning of embeddings for relation paths in knowledge bases and text. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, volume 1, pages 1434-1444, 2016.\n\nYi Yang, Ming-Wei Chang, S-Mart, arXiv:1609.08075Novel tree-based structured learning algorithms applied to tweet entity linking. arXiv preprintYi Yang and Ming-Wei Chang. S-mart: Novel tree-based structured learning algorithms ap- plied to tweet entity linking. arXiv preprint arXiv:1609.08075, 2016.\n\nSimple statistical gradient-following algorithms for connectionist reinforcement learning. Ronald J Williams, Machine Learning. 8Ronald J. Williams. Simple statistical gradient-following algorithms for connectionist rein- forcement learning. Machine Learning, 8:229-256, 1992.\n\nAndriy Mnih, Karol Gregor, arXiv:1402.0030Neural variational inference and learning in belief networks. arXiv preprintAndriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. arXiv preprint arXiv:1402.0030, 2014.\n\nCompositional semantic parsing on semi-structured tables. Panupong Pasupat, Percy Liang, arXiv:1508.00305arXiv preprintPanupong Pasupat and Percy Liang. Compositional semantic parsing on semi-structured ta- bles. arXiv preprint arXiv:1508.00305, 2015.\n\nDual learning for machine translation. Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tieyan Liu, Wei-Ying Ma, Advances in Neural Information Processing Systems. Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tieyan Liu, and Wei-Ying Ma. Dual learning for machine translation. In Advances in Neural Information Processing Systems, pages 820-828, 2016.\n\nTensorflow: Largescale machine learning on heterogeneous systems. Abadi Mart\u0131n, Ashish Agarwal, Paul Barham, Eugene Brevdo, Abadi Mart\u0131n, Ashish Agarwal, Paul Barham, Eugene Brevdo, and et. al. Tensorflow: Large- scale machine learning on heterogeneous systems. 2015.\n", "annotations": {"author": "[{\"end\":161,\"start\":69},{\"end\":253,\"start\":162},{\"end\":315,\"start\":254},{\"end\":373,\"start\":316},{\"end\":457,\"start\":374}]", "publisher": null, "author_last_name": "[{\"end\":79,\"start\":74},{\"end\":172,\"start\":169},{\"end\":271,\"start\":263},{\"end\":333,\"start\":328},{\"end\":381,\"start\":377}]", "author_first_name": "[{\"end\":73,\"start\":69},{\"end\":168,\"start\":162},{\"end\":262,\"start\":254},{\"end\":325,\"start\":316},{\"end\":327,\"start\":326},{\"end\":376,\"start\":374}]", "author_affiliation": "[{\"end\":160,\"start\":107},{\"end\":252,\"start\":199},{\"end\":314,\"start\":294},{\"end\":372,\"start\":352},{\"end\":456,\"start\":403}]", "title": "[{\"end\":66,\"start\":1},{\"end\":523,\"start\":458}]", "venue": null, "abstract": "[{\"end\":1765,\"start\":525}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1970,\"start\":1967},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1987,\"start\":1984},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2153,\"start\":2150},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2155,\"start\":2153},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2157,\"start\":2155},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2159,\"start\":2157},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2662,\"start\":2659},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2693,\"start\":2690},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2738,\"start\":2735},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3752,\"start\":3748},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3755,\"start\":3752},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3758,\"start\":3755},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4270,\"start\":4267},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4273,\"start\":4270},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4275,\"start\":4273},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4277,\"start\":4275},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4856,\"start\":4852},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7835,\"start\":7832},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7837,\"start\":7835},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7840,\"start\":7837},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7842,\"start\":7840},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7844,\"start\":7842},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7904,\"start\":7900},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8347,\"start\":8343},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8350,\"start\":8347},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8381,\"start\":8377},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8416,\"start\":8413},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8488,\"start\":8484},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8490,\"start\":8488},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8530,\"start\":8526},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8853,\"start\":8849},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8856,\"start\":8853},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8859,\"start\":8856},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8874,\"start\":8870},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8877,\"start\":8874},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8880,\"start\":8877},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8901,\"start\":8898},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8904,\"start\":8901},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9291,\"start\":9287},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9294,\"start\":9291},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9322,\"start\":9318},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9633,\"start\":9629},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16254,\"start\":16251},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":16257,\"start\":16254},{\"end\":16694,\"start\":16692},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":20369,\"start\":20365},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":20372,\"start\":20369},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20375,\"start\":20372},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22587,\"start\":22583},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22616,\"start\":22612},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":23125,\"start\":23121},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23155,\"start\":23152},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24708,\"start\":24705},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25011,\"start\":25008},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25078,\"start\":25074},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":25800,\"start\":25796},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27014,\"start\":27011},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":27149,\"start\":27145},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":27479,\"start\":27475},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":27531,\"start\":27527},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27613,\"start\":27610},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":28594,\"start\":28591},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":28769,\"start\":28766},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":30501,\"start\":30498},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":30504,\"start\":30501}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":36471,\"start\":36107},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36754,\"start\":36472},{\"attributes\":{\"id\":\"fig_4\"},\"end\":37073,\"start\":36755},{\"attributes\":{\"id\":\"fig_5\"},\"end\":37126,\"start\":37074},{\"attributes\":{\"id\":\"fig_6\"},\"end\":37198,\"start\":37127},{\"attributes\":{\"id\":\"fig_7\"},\"end\":37336,\"start\":37199},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":37765,\"start\":37337},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":38294,\"start\":37766},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":38493,\"start\":38295},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38586,\"start\":38494}]", "paragraph": "[{\"end\":2462,\"start\":1781},{\"end\":4098,\"start\":2464},{\"end\":5977,\"start\":4100},{\"end\":6191,\"start\":5979},{\"end\":6344,\"start\":6193},{\"end\":6490,\"start\":6346},{\"end\":6601,\"start\":6492},{\"end\":7007,\"start\":6603},{\"end\":7638,\"start\":7009},{\"end\":9463,\"start\":7655},{\"end\":10595,\"start\":9465},{\"end\":11807,\"start\":10626},{\"end\":12223,\"start\":11839},{\"end\":13710,\"start\":12247},{\"end\":14244,\"start\":13712},{\"end\":14328,\"start\":14325},{\"end\":14467,\"start\":14330},{\"end\":14807,\"start\":14521},{\"end\":15572,\"start\":14809},{\"end\":15978,\"start\":15574},{\"end\":16340,\"start\":16073},{\"end\":16514,\"start\":16406},{\"end\":16561,\"start\":16516},{\"end\":16595,\"start\":16563},{\"end\":16723,\"start\":16645},{\"end\":17860,\"start\":16778},{\"end\":18323,\"start\":17862},{\"end\":18677,\"start\":18325},{\"end\":19227,\"start\":18791},{\"end\":19516,\"start\":19229},{\"end\":19584,\"start\":19542},{\"end\":20563,\"start\":19616},{\"end\":20752,\"start\":20587},{\"end\":21104,\"start\":20814},{\"end\":22031,\"start\":21247},{\"end\":22383,\"start\":22089},{\"end\":23251,\"start\":22421},{\"end\":23896,\"start\":23386},{\"end\":24386,\"start\":23910},{\"end\":24498,\"start\":24388},{\"end\":26080,\"start\":24537},{\"end\":26780,\"start\":26082},{\"end\":26914,\"start\":26802},{\"end\":27814,\"start\":26937},{\"end\":28218,\"start\":27816},{\"end\":28595,\"start\":28244},{\"end\":29220,\"start\":28597},{\"end\":29762,\"start\":29222},{\"end\":30127,\"start\":29764},{\"end\":32468,\"start\":30155},{\"end\":33773,\"start\":32487},{\"end\":34312,\"start\":33814},{\"end\":34594,\"start\":34346},{\"end\":35125,\"start\":34625},{\"end\":35449,\"start\":35180},{\"end\":36106,\"start\":35501}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11838,\"start\":11808},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14324,\"start\":14245},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16072,\"start\":15979},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16644,\"start\":16596},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16777,\"start\":16724},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18790,\"start\":18678},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19541,\"start\":19517},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19615,\"start\":19585},{\"attributes\":{\"id\":\"formula_8\"},\"end\":21246,\"start\":21105},{\"attributes\":{\"id\":\"formula_9\"},\"end\":22088,\"start\":22032},{\"attributes\":{\"id\":\"formula_10\"},\"end\":23310,\"start\":23252},{\"attributes\":{\"id\":\"formula_11\"},\"end\":23385,\"start\":23310}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":27664,\"start\":27657},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":28431,\"start\":28422},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":30213,\"start\":30194},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":32869,\"start\":32862},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":33683,\"start\":33676}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1779,\"start\":1767},{\"attributes\":{\"n\":\"2\"},\"end\":7653,\"start\":7641},{\"attributes\":{\"n\":\"3\"},\"end\":10603,\"start\":10598},{\"attributes\":{\"n\":\"3.1\"},\"end\":10624,\"start\":10606},{\"attributes\":{\"n\":\"3.2\"},\"end\":12245,\"start\":12226},{\"attributes\":{\"n\":\"3.3\"},\"end\":14519,\"start\":14470},{\"attributes\":{\"n\":\"3.4\"},\"end\":16404,\"start\":16343},{\"attributes\":{\"n\":\"4\"},\"end\":20585,\"start\":20566},{\"attributes\":{\"n\":\"4.1\"},\"end\":20812,\"start\":20755},{\"attributes\":{\"n\":\"4.2\"},\"end\":22419,\"start\":22386},{\"attributes\":{\"n\":\"5\"},\"end\":23908,\"start\":23899},{\"attributes\":{\"n\":\"6\"},\"end\":24512,\"start\":24501},{\"attributes\":{\"n\":\"6.1\"},\"end\":24535,\"start\":24515},{\"end\":26800,\"start\":26783},{\"attributes\":{\"n\":\"6.2\"},\"end\":26935,\"start\":26917},{\"attributes\":{\"n\":\"6.3\"},\"end\":28242,\"start\":28221},{\"attributes\":{\"n\":\"6.4\"},\"end\":30153,\"start\":30130},{\"attributes\":{\"n\":\"6.5\"},\"end\":32485,\"start\":32471},{\"attributes\":{\"n\":\"6.6\"},\"end\":33812,\"start\":33776},{\"end\":34344,\"start\":34315},{\"end\":34623,\"start\":34597},{\"end\":35153,\"start\":35128},{\"end\":35178,\"start\":35156},{\"end\":35499,\"start\":35452},{\"end\":36118,\"start\":36108},{\"end\":36474,\"start\":36473},{\"end\":36766,\"start\":36756},{\"end\":37085,\"start\":37075},{\"end\":37210,\"start\":37200},{\"end\":37347,\"start\":37338},{\"end\":37776,\"start\":37767},{\"end\":38305,\"start\":38296},{\"end\":38504,\"start\":38495}]", "table": "[{\"end\":37765,\"start\":37440},{\"end\":38294,\"start\":37866},{\"end\":38493,\"start\":38358},{\"end\":38586,\"start\":38566}]", "figure_caption": "[{\"end\":36471,\"start\":36120},{\"end\":36754,\"start\":36475},{\"end\":37073,\"start\":36768},{\"end\":37126,\"start\":37087},{\"end\":37198,\"start\":37129},{\"end\":37336,\"start\":37212},{\"end\":37440,\"start\":37349},{\"end\":37866,\"start\":37778},{\"end\":38358,\"start\":38307},{\"end\":38566,\"start\":38506}]", "figure_ref": "[{\"end\":9853,\"start\":9845},{\"end\":12411,\"start\":12405},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17750,\"start\":17739},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20108,\"start\":20095},{\"end\":26875,\"start\":26867},{\"end\":33205,\"start\":33194},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":34431,\"start\":34425},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":35222,\"start\":35214},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":35926,\"start\":35920}]", "bib_author_first_name": "[{\"end\":39853,\"start\":39848},{\"end\":39869,\"start\":39860},{\"end\":39883,\"start\":39877},{\"end\":39899,\"start\":39895},{\"end\":39916,\"start\":39909},{\"end\":39934,\"start\":39927},{\"end\":40194,\"start\":40190},{\"end\":40211,\"start\":40206},{\"end\":40226,\"start\":40219},{\"end\":40240,\"start\":40237},{\"end\":40254,\"start\":40249},{\"end\":40723,\"start\":40718},{\"end\":40735,\"start\":40732},{\"end\":40756,\"start\":40748},{\"end\":40767,\"start\":40764},{\"end\":41190,\"start\":41185},{\"end\":41201,\"start\":41198},{\"end\":41746,\"start\":41738},{\"end\":41761,\"start\":41755},{\"end\":41771,\"start\":41768},{\"end\":41786,\"start\":41781},{\"end\":42256,\"start\":42248},{\"end\":42278,\"start\":42270},{\"end\":42294,\"start\":42286},{\"end\":42723,\"start\":42718},{\"end\":42737,\"start\":42732},{\"end\":42753,\"start\":42746},{\"end\":42921,\"start\":42912},{\"end\":42934,\"start\":42930},{\"end\":42947,\"start\":42942},{\"end\":42976,\"start\":42969},{\"end\":42990,\"start\":42985},{\"end\":43336,\"start\":43331},{\"end\":43347,\"start\":43341},{\"end\":43360,\"start\":43356},{\"end\":43382,\"start\":43375},{\"end\":43637,\"start\":43630},{\"end\":43651,\"start\":43646},{\"end\":43659,\"start\":43658},{\"end\":43679,\"start\":43673},{\"end\":44031,\"start\":44028},{\"end\":44045,\"start\":44038},{\"end\":44065,\"start\":44059},{\"end\":44078,\"start\":44073},{\"end\":44087,\"start\":44085},{\"end\":44098,\"start\":44093},{\"end\":44113,\"start\":44107},{\"end\":44132,\"start\":44125},{\"end\":44141,\"start\":44138},{\"end\":44426,\"start\":44420},{\"end\":44436,\"start\":44432},{\"end\":44450,\"start\":44445},{\"end\":44694,\"start\":44689},{\"end\":44709,\"start\":44702},{\"end\":44721,\"start\":44716},{\"end\":44736,\"start\":44729},{\"end\":44750,\"start\":44745},{\"end\":44768,\"start\":44759},{\"end\":44783,\"start\":44777},{\"end\":44796,\"start\":44791},{\"end\":45138,\"start\":45133},{\"end\":45148,\"start\":45144},{\"end\":45162,\"start\":45158},{\"end\":45520,\"start\":45517},{\"end\":45540,\"start\":45534},{\"end\":45551,\"start\":45547},{\"end\":45563,\"start\":45559},{\"end\":45816,\"start\":45812},{\"end\":45832,\"start\":45824},{\"end\":45845,\"start\":45841},{\"end\":45851,\"start\":45850},{\"end\":45863,\"start\":45861},{\"end\":46181,\"start\":46176},{\"end\":46193,\"start\":46189},{\"end\":46209,\"start\":46201},{\"end\":46219,\"start\":46214},{\"end\":46236,\"start\":46230},{\"end\":46251,\"start\":46246},{\"end\":46265,\"start\":46260},{\"end\":46282,\"start\":46276},{\"end\":46301,\"start\":46294},{\"end\":46631,\"start\":46622},{\"end\":46649,\"start\":46644},{\"end\":46661,\"start\":46658},{\"end\":46940,\"start\":46939},{\"end\":46948,\"start\":46947},{\"end\":46954,\"start\":46953},{\"end\":46961,\"start\":46960},{\"end\":46969,\"start\":46968},{\"end\":46971,\"start\":46970},{\"end\":47207,\"start\":47200},{\"end\":47221,\"start\":47216},{\"end\":47235,\"start\":47230},{\"end\":47475,\"start\":47469},{\"end\":47490,\"start\":47489},{\"end\":47503,\"start\":47497},{\"end\":47514,\"start\":47508},{\"end\":47527,\"start\":47522},{\"end\":47846,\"start\":47839},{\"end\":47859,\"start\":47855},{\"end\":47872,\"start\":47871},{\"end\":47884,\"start\":47879},{\"end\":47898,\"start\":47897},{\"end\":47922,\"start\":47921},{\"end\":47942,\"start\":47931},{\"end\":48244,\"start\":48240},{\"end\":48258,\"start\":48252},{\"end\":48583,\"start\":48579},{\"end\":48591,\"start\":48589},{\"end\":48598,\"start\":48596},{\"end\":48609,\"start\":48606},{\"end\":48619,\"start\":48616},{\"end\":49051,\"start\":49045},{\"end\":49075,\"start\":49070},{\"end\":49093,\"start\":49087},{\"end\":49115,\"start\":49108},{\"end\":49131,\"start\":49127},{\"end\":49146,\"start\":49140},{\"end\":49574,\"start\":49568},{\"end\":49582,\"start\":49580},{\"end\":49590,\"start\":49588},{\"end\":49771,\"start\":49766},{\"end\":49783,\"start\":49780},{\"end\":50037,\"start\":50031},{\"end\":50039,\"start\":50038},{\"end\":50428,\"start\":50422},{\"end\":50450,\"start\":50442},{\"end\":50463,\"start\":50457},{\"end\":50758,\"start\":50750},{\"end\":50778,\"start\":50770},{\"end\":50790,\"start\":50783},{\"end\":50803,\"start\":50796},{\"end\":50814,\"start\":50809},{\"end\":51286,\"start\":51284},{\"end\":51301,\"start\":51293},{\"end\":51684,\"start\":51678},{\"end\":51686,\"start\":51685},{\"end\":51871,\"start\":51865},{\"end\":51883,\"start\":51878},{\"end\":52180,\"start\":52172},{\"end\":52195,\"start\":52190},{\"end\":52408,\"start\":52406},{\"end\":52419,\"start\":52413},{\"end\":52428,\"start\":52425},{\"end\":52439,\"start\":52434},{\"end\":52453,\"start\":52446},{\"end\":52464,\"start\":52458},{\"end\":52478,\"start\":52470},{\"end\":52801,\"start\":52796},{\"end\":52816,\"start\":52810},{\"end\":52830,\"start\":52826},{\"end\":52845,\"start\":52839}]", "bib_author_last_name": "[{\"end\":39858,\"start\":39854},{\"end\":39875,\"start\":39870},{\"end\":39893,\"start\":39884},{\"end\":39907,\"start\":39900},{\"end\":39925,\"start\":39917},{\"end\":39939,\"start\":39935},{\"end\":40204,\"start\":40195},{\"end\":40217,\"start\":40212},{\"end\":40235,\"start\":40227},{\"end\":40247,\"start\":40241},{\"end\":40261,\"start\":40255},{\"end\":40730,\"start\":40724},{\"end\":40746,\"start\":40736},{\"end\":40762,\"start\":40757},{\"end\":40772,\"start\":40768},{\"end\":41196,\"start\":41191},{\"end\":41218,\"start\":41202},{\"end\":41225,\"start\":41220},{\"end\":41753,\"start\":41747},{\"end\":41766,\"start\":41762},{\"end\":41779,\"start\":41772},{\"end\":41792,\"start\":41787},{\"end\":42268,\"start\":42257},{\"end\":42284,\"start\":42279},{\"end\":42297,\"start\":42295},{\"end\":42302,\"start\":42299},{\"end\":42730,\"start\":42724},{\"end\":42744,\"start\":42738},{\"end\":42760,\"start\":42754},{\"end\":42928,\"start\":42922},{\"end\":42940,\"start\":42935},{\"end\":42953,\"start\":42948},{\"end\":42967,\"start\":42955},{\"end\":42983,\"start\":42977},{\"end\":42997,\"start\":42991},{\"end\":43005,\"start\":42999},{\"end\":43339,\"start\":43337},{\"end\":43354,\"start\":43348},{\"end\":43373,\"start\":43361},{\"end\":43388,\"start\":43383},{\"end\":43644,\"start\":43638},{\"end\":43656,\"start\":43652},{\"end\":43671,\"start\":43660},{\"end\":43687,\"start\":43680},{\"end\":43691,\"start\":43689},{\"end\":44036,\"start\":44032},{\"end\":44057,\"start\":44046},{\"end\":44071,\"start\":44066},{\"end\":44083,\"start\":44079},{\"end\":44091,\"start\":44088},{\"end\":44105,\"start\":44099},{\"end\":44123,\"start\":44114},{\"end\":44136,\"start\":44133},{\"end\":44147,\"start\":44142},{\"end\":44430,\"start\":44427},{\"end\":44443,\"start\":44437},{\"end\":44456,\"start\":44451},{\"end\":44700,\"start\":44695},{\"end\":44714,\"start\":44710},{\"end\":44727,\"start\":44722},{\"end\":44743,\"start\":44737},{\"end\":44757,\"start\":44751},{\"end\":44775,\"start\":44769},{\"end\":44789,\"start\":44784},{\"end\":44803,\"start\":44797},{\"end\":45142,\"start\":45139},{\"end\":45156,\"start\":45149},{\"end\":45169,\"start\":45163},{\"end\":45532,\"start\":45521},{\"end\":45545,\"start\":45541},{\"end\":45557,\"start\":45552},{\"end\":45575,\"start\":45564},{\"end\":45822,\"start\":45817},{\"end\":45839,\"start\":45833},{\"end\":45848,\"start\":45846},{\"end\":45859,\"start\":45852},{\"end\":45870,\"start\":45864},{\"end\":45875,\"start\":45872},{\"end\":46187,\"start\":46182},{\"end\":46199,\"start\":46194},{\"end\":46212,\"start\":46210},{\"end\":46228,\"start\":46220},{\"end\":46244,\"start\":46237},{\"end\":46258,\"start\":46252},{\"end\":46274,\"start\":46266},{\"end\":46292,\"start\":46283},{\"end\":46308,\"start\":46302},{\"end\":46642,\"start\":46632},{\"end\":46656,\"start\":46650},{\"end\":46668,\"start\":46662},{\"end\":46945,\"start\":46941},{\"end\":46951,\"start\":46949},{\"end\":46958,\"start\":46955},{\"end\":46966,\"start\":46962},{\"end\":46977,\"start\":46972},{\"end\":47214,\"start\":47208},{\"end\":47228,\"start\":47222},{\"end\":47242,\"start\":47236},{\"end\":47487,\"start\":47476},{\"end\":47495,\"start\":47491},{\"end\":47506,\"start\":47504},{\"end\":47520,\"start\":47515},{\"end\":47536,\"start\":47528},{\"end\":47544,\"start\":47538},{\"end\":47853,\"start\":47847},{\"end\":47869,\"start\":47860},{\"end\":47877,\"start\":47873},{\"end\":47887,\"start\":47885},{\"end\":47895,\"start\":47889},{\"end\":47910,\"start\":47899},{\"end\":47919,\"start\":47912},{\"end\":47929,\"start\":47923},{\"end\":47945,\"start\":47943},{\"end\":47952,\"start\":47947},{\"end\":48250,\"start\":48245},{\"end\":48265,\"start\":48259},{\"end\":48587,\"start\":48584},{\"end\":48594,\"start\":48592},{\"end\":48604,\"start\":48599},{\"end\":48614,\"start\":48610},{\"end\":48623,\"start\":48620},{\"end\":49068,\"start\":49052},{\"end\":49085,\"start\":49076},{\"end\":49106,\"start\":49094},{\"end\":49125,\"start\":49116},{\"end\":49138,\"start\":49132},{\"end\":49159,\"start\":49147},{\"end\":49166,\"start\":49161},{\"end\":49578,\"start\":49575},{\"end\":49586,\"start\":49583},{\"end\":49595,\"start\":49591},{\"end\":49778,\"start\":49772},{\"end\":49791,\"start\":49784},{\"end\":50047,\"start\":50040},{\"end\":50440,\"start\":50429},{\"end\":50455,\"start\":50451},{\"end\":50472,\"start\":50464},{\"end\":50768,\"start\":50759},{\"end\":50781,\"start\":50779},{\"end\":50794,\"start\":50791},{\"end\":50807,\"start\":50804},{\"end\":50819,\"start\":50815},{\"end\":50826,\"start\":50821},{\"end\":51291,\"start\":51287},{\"end\":51307,\"start\":51302},{\"end\":51315,\"start\":51309},{\"end\":51695,\"start\":51687},{\"end\":51876,\"start\":51872},{\"end\":51890,\"start\":51884},{\"end\":52188,\"start\":52181},{\"end\":52201,\"start\":52196},{\"end\":52411,\"start\":52409},{\"end\":52423,\"start\":52420},{\"end\":52432,\"start\":52429},{\"end\":52444,\"start\":52440},{\"end\":52456,\"start\":52454},{\"end\":52468,\"start\":52465},{\"end\":52481,\"start\":52479},{\"end\":52808,\"start\":52802},{\"end\":52824,\"start\":52817},{\"end\":52837,\"start\":52831},{\"end\":52852,\"start\":52846}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":40104,\"start\":39787},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":207167677},\"end\":40664,\"start\":40106},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":5667590},\"end\":41132,\"start\":40666},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":340852},\"end\":41679,\"start\":41134},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":6401679},\"end\":42154,\"start\":41681},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":18309765},\"end\":42714,\"start\":42156},{\"attributes\":{\"doi\":\"arXiv:1410.3916\",\"id\":\"b6\"},\"end\":42910,\"start\":42716},{\"attributes\":{\"doi\":\"arXiv:1606.03126\",\"id\":\"b7\"},\"end\":43291,\"start\":42912},{\"attributes\":{\"doi\":\"arXiv:1511.05493\",\"id\":\"b8\"},\"end\":43559,\"start\":43293},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":8429835},\"end\":43953,\"start\":43561},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":4557963},\"end\":44373,\"start\":43955},{\"attributes\":{\"doi\":\"arXiv:1506.01094\",\"id\":\"b11\"},\"end\":44613,\"start\":44375},{\"attributes\":{\"doi\":\"arXiv:1511.06931\",\"id\":\"b12\"},\"end\":45067,\"start\":44615},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":6420241},\"end\":45455,\"start\":45069},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":14341841},\"end\":45723,\"start\":45457},{\"attributes\":{\"doi\":\"arXiv:1611.00020\",\"id\":\"b15\"},\"end\":46100,\"start\":45725},{\"attributes\":{\"doi\":\"arXiv:1506.07285\",\"id\":\"b16\"},\"end\":46592,\"start\":46102},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1399322},\"end\":46880,\"start\":46594},{\"attributes\":{\"doi\":\"arXiv:1511.02274\",\"id\":\"b18\"},\"end\":47153,\"start\":46882},{\"attributes\":{\"doi\":\"arXiv:1406.3676\",\"id\":\"b19\"},\"end\":47405,\"start\":47155},{\"attributes\":{\"doi\":\"arXiv:1611.08945\",\"id\":\"b20\"},\"end\":47758,\"start\":47407},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":990233},\"end\":48173,\"start\":47760},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":9792203},\"end\":48489,\"start\":48175},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1914494},\"end\":48973,\"start\":48491},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1690180},\"end\":49493,\"start\":48975},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2708270},\"end\":49723,\"start\":49495},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":15483870},\"end\":49991,\"start\":49725},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":29504454},\"end\":50355,\"start\":49993},{\"attributes\":{\"doi\":\"arXiv:1504.06662\",\"id\":\"b28\"},\"end\":50663,\"start\":50357},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":13621654},\"end\":51282,\"start\":50665},{\"attributes\":{\"doi\":\"arXiv:1609.08075\",\"id\":\"b30\"},\"end\":51585,\"start\":51284},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":2332513},\"end\":51863,\"start\":51587},{\"attributes\":{\"doi\":\"arXiv:1402.0030\",\"id\":\"b32\"},\"end\":52112,\"start\":51865},{\"attributes\":{\"doi\":\"arXiv:1508.00305\",\"id\":\"b33\"},\"end\":52365,\"start\":52114},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":5758868},\"end\":52728,\"start\":52367},{\"attributes\":{\"id\":\"b35\"},\"end\":52997,\"start\":52730}]", "bib_title": "[{\"end\":40188,\"start\":40106},{\"end\":40716,\"start\":40666},{\"end\":41183,\"start\":41134},{\"end\":41736,\"start\":41681},{\"end\":42246,\"start\":42156},{\"end\":43628,\"start\":43561},{\"end\":44026,\"start\":43955},{\"end\":45131,\"start\":45069},{\"end\":45515,\"start\":45457},{\"end\":46620,\"start\":46594},{\"end\":47837,\"start\":47760},{\"end\":48238,\"start\":48175},{\"end\":48577,\"start\":48491},{\"end\":49043,\"start\":48975},{\"end\":49566,\"start\":49495},{\"end\":49764,\"start\":49725},{\"end\":50029,\"start\":49993},{\"end\":50748,\"start\":50665},{\"end\":51676,\"start\":51587},{\"end\":52404,\"start\":52367}]", "bib_author": "[{\"end\":39860,\"start\":39848},{\"end\":39877,\"start\":39860},{\"end\":39895,\"start\":39877},{\"end\":39909,\"start\":39895},{\"end\":39927,\"start\":39909},{\"end\":39941,\"start\":39927},{\"end\":40206,\"start\":40190},{\"end\":40219,\"start\":40206},{\"end\":40237,\"start\":40219},{\"end\":40249,\"start\":40237},{\"end\":40263,\"start\":40249},{\"end\":40732,\"start\":40718},{\"end\":40748,\"start\":40732},{\"end\":40764,\"start\":40748},{\"end\":40774,\"start\":40764},{\"end\":41198,\"start\":41185},{\"end\":41220,\"start\":41198},{\"end\":41227,\"start\":41220},{\"end\":41755,\"start\":41738},{\"end\":41768,\"start\":41755},{\"end\":41781,\"start\":41768},{\"end\":41794,\"start\":41781},{\"end\":42270,\"start\":42248},{\"end\":42286,\"start\":42270},{\"end\":42299,\"start\":42286},{\"end\":42304,\"start\":42299},{\"end\":42732,\"start\":42718},{\"end\":42746,\"start\":42732},{\"end\":42762,\"start\":42746},{\"end\":42930,\"start\":42912},{\"end\":42942,\"start\":42930},{\"end\":42955,\"start\":42942},{\"end\":42969,\"start\":42955},{\"end\":42985,\"start\":42969},{\"end\":42999,\"start\":42985},{\"end\":43007,\"start\":42999},{\"end\":43341,\"start\":43331},{\"end\":43356,\"start\":43341},{\"end\":43375,\"start\":43356},{\"end\":43390,\"start\":43375},{\"end\":43646,\"start\":43630},{\"end\":43658,\"start\":43646},{\"end\":43673,\"start\":43658},{\"end\":43689,\"start\":43673},{\"end\":43693,\"start\":43689},{\"end\":44038,\"start\":44028},{\"end\":44059,\"start\":44038},{\"end\":44073,\"start\":44059},{\"end\":44085,\"start\":44073},{\"end\":44093,\"start\":44085},{\"end\":44107,\"start\":44093},{\"end\":44125,\"start\":44107},{\"end\":44138,\"start\":44125},{\"end\":44149,\"start\":44138},{\"end\":44432,\"start\":44420},{\"end\":44445,\"start\":44432},{\"end\":44458,\"start\":44445},{\"end\":44702,\"start\":44689},{\"end\":44716,\"start\":44702},{\"end\":44729,\"start\":44716},{\"end\":44745,\"start\":44729},{\"end\":44759,\"start\":44745},{\"end\":44777,\"start\":44759},{\"end\":44791,\"start\":44777},{\"end\":44805,\"start\":44791},{\"end\":45144,\"start\":45133},{\"end\":45158,\"start\":45144},{\"end\":45171,\"start\":45158},{\"end\":45534,\"start\":45517},{\"end\":45547,\"start\":45534},{\"end\":45559,\"start\":45547},{\"end\":45577,\"start\":45559},{\"end\":45824,\"start\":45812},{\"end\":45841,\"start\":45824},{\"end\":45850,\"start\":45841},{\"end\":45861,\"start\":45850},{\"end\":45872,\"start\":45861},{\"end\":45877,\"start\":45872},{\"end\":46189,\"start\":46176},{\"end\":46201,\"start\":46189},{\"end\":46214,\"start\":46201},{\"end\":46230,\"start\":46214},{\"end\":46246,\"start\":46230},{\"end\":46260,\"start\":46246},{\"end\":46276,\"start\":46260},{\"end\":46294,\"start\":46276},{\"end\":46310,\"start\":46294},{\"end\":46644,\"start\":46622},{\"end\":46658,\"start\":46644},{\"end\":46670,\"start\":46658},{\"end\":46947,\"start\":46939},{\"end\":46953,\"start\":46947},{\"end\":46960,\"start\":46953},{\"end\":46968,\"start\":46960},{\"end\":46979,\"start\":46968},{\"end\":47216,\"start\":47200},{\"end\":47230,\"start\":47216},{\"end\":47244,\"start\":47230},{\"end\":47489,\"start\":47469},{\"end\":47497,\"start\":47489},{\"end\":47508,\"start\":47497},{\"end\":47522,\"start\":47508},{\"end\":47538,\"start\":47522},{\"end\":47546,\"start\":47538},{\"end\":47855,\"start\":47839},{\"end\":47871,\"start\":47855},{\"end\":47879,\"start\":47871},{\"end\":47889,\"start\":47879},{\"end\":47897,\"start\":47889},{\"end\":47912,\"start\":47897},{\"end\":47921,\"start\":47912},{\"end\":47931,\"start\":47921},{\"end\":47947,\"start\":47931},{\"end\":47954,\"start\":47947},{\"end\":48252,\"start\":48240},{\"end\":48267,\"start\":48252},{\"end\":48589,\"start\":48579},{\"end\":48596,\"start\":48589},{\"end\":48606,\"start\":48596},{\"end\":48616,\"start\":48606},{\"end\":48625,\"start\":48616},{\"end\":49070,\"start\":49045},{\"end\":49087,\"start\":49070},{\"end\":49108,\"start\":49087},{\"end\":49127,\"start\":49108},{\"end\":49140,\"start\":49127},{\"end\":49161,\"start\":49140},{\"end\":49168,\"start\":49161},{\"end\":49580,\"start\":49568},{\"end\":49588,\"start\":49580},{\"end\":49597,\"start\":49588},{\"end\":49780,\"start\":49766},{\"end\":49793,\"start\":49780},{\"end\":50049,\"start\":50031},{\"end\":50442,\"start\":50422},{\"end\":50457,\"start\":50442},{\"end\":50474,\"start\":50457},{\"end\":50770,\"start\":50750},{\"end\":50783,\"start\":50770},{\"end\":50796,\"start\":50783},{\"end\":50809,\"start\":50796},{\"end\":50821,\"start\":50809},{\"end\":50828,\"start\":50821},{\"end\":51293,\"start\":51284},{\"end\":51309,\"start\":51293},{\"end\":51317,\"start\":51309},{\"end\":51697,\"start\":51678},{\"end\":51878,\"start\":51865},{\"end\":51892,\"start\":51878},{\"end\":52190,\"start\":52172},{\"end\":52203,\"start\":52190},{\"end\":52413,\"start\":52406},{\"end\":52425,\"start\":52413},{\"end\":52434,\"start\":52425},{\"end\":52446,\"start\":52434},{\"end\":52458,\"start\":52446},{\"end\":52470,\"start\":52458},{\"end\":52483,\"start\":52470},{\"end\":52810,\"start\":52796},{\"end\":52826,\"start\":52810},{\"end\":52839,\"start\":52826},{\"end\":52854,\"start\":52839}]", "bib_venue": "[{\"end\":40412,\"start\":40346},{\"end\":40927,\"start\":40859},{\"end\":41446,\"start\":41345},{\"end\":41943,\"start\":41877},{\"end\":42465,\"start\":42393},{\"end\":48754,\"start\":48698},{\"end\":50204,\"start\":50135},{\"end\":50989,\"start\":50917},{\"end\":39846,\"start\":39787},{\"end\":40344,\"start\":40263},{\"end\":40857,\"start\":40774},{\"end\":41343,\"start\":41227},{\"end\":41875,\"start\":41794},{\"end\":42391,\"start\":42304},{\"end\":43079,\"start\":43023},{\"end\":43329,\"start\":43293},{\"end\":43742,\"start\":43693},{\"end\":44155,\"start\":44149},{\"end\":44418,\"start\":44375},{\"end\":44687,\"start\":44615},{\"end\":45238,\"start\":45171},{\"end\":45582,\"start\":45577},{\"end\":45810,\"start\":45725},{\"end\":46174,\"start\":46102},{\"end\":46719,\"start\":46670},{\"end\":46937,\"start\":46882},{\"end\":47198,\"start\":47155},{\"end\":47467,\"start\":47407},{\"end\":47959,\"start\":47954},{\"end\":48316,\"start\":48267},{\"end\":48696,\"start\":48625},{\"end\":49217,\"start\":49168},{\"end\":49601,\"start\":49597},{\"end\":49842,\"start\":49793},{\"end\":50133,\"start\":50049},{\"end\":50420,\"start\":50357},{\"end\":50915,\"start\":50828},{\"end\":51412,\"start\":51333},{\"end\":51713,\"start\":51697},{\"end\":51967,\"start\":51907},{\"end\":52170,\"start\":52114},{\"end\":52532,\"start\":52483},{\"end\":52794,\"start\":52730}]"}}}, "year": 2023, "month": 12, "day": 17}