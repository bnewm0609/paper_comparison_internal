{"id": 233407785, "updated": "2023-10-06 04:35:42.45", "metadata": {"title": "Extractive and Abstractive Explanations for Fact-Checking and Evaluation of News", "authors": "[{\"first\":\"Ashkan\",\"last\":\"Kazemi\",\"middle\":[]},{\"first\":\"Zehua\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Ver\u00f3nica\",\"last\":\"P\u00e9rez-Rosas\",\"middle\":[]},{\"first\":\"Rada\",\"last\":\"Mihalcea\",\"middle\":[]}]", "venue": "NLP4IF", "journal": "Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "In this paper, we explore the construction of natural language explanations for news claims, with the goal of assisting fact-checking and news evaluation applications. We experiment with two methods: (1) an extractive method based on Biased TextRank \u2013 a resource-effective unsupervised graph-based algorithm for content extraction; and (2) an abstractive method based on the GPT-2 language model. We perform comparative evaluations on two misinformation datasets in the political and health news domains, and find that the extractive method shows the most promise.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2104.12918", "mag": "3169962312", "acl": "2021.nlp4if-1.7", "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2104-12918", "doi": "10.18653/v1/2021.nlp4if-1.7"}}, "content": {"source": {"pdf_hash": "d2019a971cb501137ed65eb773a8ce2667721e8d", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/2021.nlp4if-1.7.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/2021.nlp4if-1.7.pdf", "status": "HYBRID"}}, "grobid": {"id": "91fa1f43b3f5710198a873896fbf20bf1ea20e31", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d2019a971cb501137ed65eb773a8ce2667721e8d.txt", "contents": "\nExtractive and Abstractive Explanations for Fact-Checking and Evaluation of News\nJune 6, 2021\n\nAshkan Kazemi ashkank@umich.edu \nZehua Li \nVer\u00f3nica Per\u00e9z-Rosas \nRada Mihalcea mihalcea@umich.edu \nExtractive and Abstractive Explanations for Fact-Checking and Evaluation of News\n\nProceedings of the 4th NLP4IF Workshop on NLP for Internet Freedom\nthe 4th NLP4IF Workshop on NLP for Internet FreedomJune 6, 202145 University of Michigan, Ann Arbor\nIn this paper, we explore the construction of natural language explanations for news claims, with the goal of assisting fact-checking and news evaluation applications. We experiment with two methods: (1) an extractive method based on Biased TextRank -a resource-effective unsupervised graph-based algorithm for content extraction; and (2) an abstractive method based on the GPT-2 language model. We perform comparative evaluations on two misinformation datasets in the political and health news domains, and find that the extractive method shows the most promise.\n\nIntroduction\n\nNavigating the media landscape is becoming increasingly challenging given the abundance of misinformation, which reinforces the importance of keeping our news consumption focused and informed. While fake news and misinformation have been a recent focus of research studies (P\u00e9rez-Rosas et al., 2018;Thorne and Vlachos, 2018;Lu and Li, 2020), the majority of this work aims to categorize claims, rather than generate explanations that support or deny them. This is a challenging problem that has been mainly tackled by expert journalists who manually verify the information surrounding a given claim and provide a detailed verdict based on supporting or refuting evidence. More recently, there has been a growing interest in creating computational tools able to assist during this process by providing supporting explanations for a given claim based on the news content and context (Atanasova et al., 2020;Fan et al., 2020). While a true or false veracity label does not provide enough information and a detailed fact-checking report or news article might take long to read, bitesized explanations can bridge this gap and improve the transparency of automated news evaluation systems.\n\nTo contribute to this line of work, our paper explores two approaches to generate supporting explanations to assist with the evaluation of news. First, we investigate how an extractive method based on Biased TextRank (Kazemi et al., 2020) can be used to generate explanations. Second, we explore an abstractive method based on GPT-2, a large generative language model (Radford et al., 2019).\n\nOur methods take as input a news article and a claim and generate a claim-focused explanation by extracting or generating relevant information to the original article in relation to the claim. We evaluate our proposed methods on the health care and political domains, where misinformation is abundant. As current news on the COVID-19 pandemic and the elections are overloading social media outlets, we find these domains to be of timely importance. Through comparative experiments, we find that both methods are effective at generating explanations for news claims, with the extractive approach showing the most promise for this task.\n\n\nRelated Work\n\nWhile explainability in AI has been a central subject of research in recent years (Poursabzi-Sangdeh et al., 2018;Lundberg and Lee, 2017;Core et al., 2006), the generation of natural language explanations is still relatively understudied. Camburu et al. (2018) propose e-SNLI, a natural language (NL) inference dataset augmented with human-annotated NL explanations. In their paper, Camburu et al. generated NL explanations for premise and hypothesis pairs for an inference task using the In-ferSent (Conneau et al., 2017) architecture. Kumar and Talukdar (2020) propose the task of generating \"faithful\" (i.e., aligned with the model's internal decision making) NL explanations and propose NILE, a method that jointly produces NLI labels and faithful NL explanations.\n\nGenerating explanations in the context of news and fact-checking is a timely and novel topic in the Claim: nearly half of Oregon's children are poor. Fact-Check Report: ...Jim Francesconi...said...\"Nearly half of Oregon's children are poor.\" He said the information came from a 2012 report...According to that report, \"nearly 50% of children are either poor or lowincome.\" Francesconi almost immediately realized his mistake. \"In retrospect, I wish I would have said poor or low income.\"...there is a distinction between poor and low income as far as the U.S. government is concerned.\" ... If you check the...Census information, you'll find that...23 percent of children in Oregon live in...below...poverty level while another 21 percent live in low-income families. As far as the U.S. government is concerned, about a quarter of the state's children are poor, not half... (redacted) Supporting Explanation (Ground Truth): So where does this leave us? Francesconi said in an opinion piece that \"nearly half of Oregon's children are poor.\" In fact, if you use federal definitions for poverty, about a quarter are poor and another quarter are low-income. But experts tell us that families that are described as low-income still struggle to meet their basic needs and, for all intents and purposes, qualify as poor. Be that as it may, Francesconi was referencing a report that used the federal definitions. Biased TextRank (Extractive): \"Nearly half of Oregon's children are poor.\" According to that report, \"nearly 50% of children are either poor or low-income.\" Low income refers to families between 100 and 200 percent of the federal poverty level. As far as the U.S. government is concerned, about a quarter of the state's children are poor, not half. GPT-2 Based (Abstractive):\" That's still below the federal poverty level. But that's not half. About 47 percent of Oregon's children are not poor, according to the Census data. So the percentage of children in the state who are poor is not half yet. It's actually closer to half. NLP community (Atanasova et al., 2020;Fan et al., 2020;Kotonya and Toni, 2020). In (Atanasova et al., 2020) the authors proposed a supervised BERT (Devlin et al., 2019) based model for jointly predicting the veracity of a claim by extracting supporting explanations from fact-checked claims in the LIAR-PLUS (Alhindi et al., 2018) dataset. Kotonya and Toni (2020) constructed a dataset for a similar task in the public health domain and provided baseline models for explainable fact verification using this dataset. Fan et al. (2020) used explanations about a claim to assist fact-checkers and showed that explanations improved both the efficiency and the accuracy of the fact-checking process.\n\n\nMethods\n\nWe explore two methods for producing natural language explanations: an extractive unsupervised method based on Biased TextRank, and an abstractive method based on GPT-2.\n\n\nExtractive: Biased TextRank\n\nIntroduced by Kazemi et al. (2020) and based on the TextRank algorithm (Mihalcea and Tarau, 2004), Biased TextRank is a targeted content extraction algorithm with a range of applications in keyword and sentence extraction. The TextRank algorithm ranks text segments for their importance by running a random walk algorithm on a graph built by including a node for each text segment (e.g., sentence), and drawing weighted edges by linking the text segment using a measure of similarity.\n\nThe Biased TextRank algorithm takes an extra \"bias\" input and ranks the input text segments considering both their own importance and their relevance to the bias term. The bias query is embedded into Biased TextRank using a similar idea introduced by Haveliwala (2002) for topic-sensitive PageRank. The similarity between the text segments that form the graph and the \"bias\" is used to set the restart probabilities of the random walker in a run of PageRank over the text graph. That means the more similar each text segment is to the bias query, the more likely it is for that node to be visited in each restart and therefore, it has a better chance of ranking higher than the less similar nodes to the bias query. During our experiments, we use SBERT (Reimers and Gurevych, 2019) contextual embeddings to transform text into sentence vectors and cosine similarity as similarity measure.\n\n\nAbstractive: GPT-2 Based\n\nWe implement an abstractive explanation generation method based on GPT-2, a transformer-based language model introduced in Radford et al. (2019) and trained on 8 million web pages containing 40 GBs of text.\n\nAside from success in language generation tasks (Budzianowski and Vuli\u0107, 2019;Ham et al., 2020), the pretrained GPT-2 model enables us to generate abstractive explanations for a relatively small dataset through transfer learning.\n\nIn order to generate explanations that are closer in domain and style to the reference explanation, we conduct an initial fine-tuning step. While fine tuning, we provide the news article, the claim, and its corresponding explanation as an input to the model and explicitly mark the beginning and the end of each input argument with bespoke tokens. At test time, we provide the article and query inputs in similar format but leave the explanation field to be completed by the model. We use top-k sampling to generate explanations. We stop the generation after the model outputs the explicit end of the text token introduced in the fine-tuning process.\n\nOverall, this fine-tuning strategy is able to generate explanations that follow a style similar to the reference explanation. However, we identify cases where the model generates gibberish and/or repetitive text, which are problems previously reported in the literature while using GPT-2 (Holtzman et al., 2019;Welleck et al., 2020). To address these issues, we devise a strategy to remove unimportant sentences that could introduce noise to the generation process. We first use Biased TextRank to rank the importance of the article sentences towards the question/claim. Then, we repeatedly remove the least important sentence (up to 5 times) and input the modified text into the GPT-2 generator. This approach keeps the text generation time complexity in the same order of magnitude as before and reduces the generation noise rate to close to zero.\n\n\nEvaluation\n\n\nExperimental Setup\n\nWe use a medium (355M hyper parameters) GPT-2 model (Radford et al., 2019) as implemented in the Huggingface transformers (Wolf et al., 2019) library. We use ROUGE (Lin, 2004), a common measure for language generation assessment as our main evaluation metric for the generated explanations and report the F score on three variations of ROUGE: ROUGE-1, ROUGE-2 and ROUGE-L.\n\nWe compare our methods against two baselines. The first is an explanation obtained by applying TextRank on the input text. The second, called \"embedding similarity\", ranks the input sentences by their embedding cosine similarity to the question and takes the top five sentences as an explanation.\n\n\nDatasets\n\nLIAR-PLUS. The LIAR-PLUS (Alhindi et al., 2018) dataset contains 10,146 train, 1,278 validation and 1,255 test data points collected from Poli-tiFact.com, a political fact-checking website in the U.S. A datapoint in this dataset contains a claim, its verdict, a news-length fact-check report justifying the verdict and a short explanation called \"Our ruling\" that summarizes the fact-check report and the verdict on the claim. General statistics on this dataset are presented in Table 2.\n\nHealth News Reviews (HNR). We collect health news reviews along with ratings and expla-   nations from healthnewsreview.org, a website dedicated to evaluating healthcare journalism in the US. 1 The news articles are rated with a 1 to 5 star scale and the explanations, which justify the news' rating, consist of short answers for 10 evaluative questions on the quality of information reported in the article. The questions cover informative aspects that should be included in the news such as intervention costs, treatment benefits, discussion of harms and benefits, clinical evidence, and availability of treatment among others. Answers to these questions are further evaluated as either satisfactory, non-satisfactory or non-applicable to the given news item. For our experiments, we select 1,650 reviews that include both the original article and the accompanying metadata as well as explanations.\n\nExplanations' statistics are presented in Table 2.\n\nTo further study explanations in this dataset, we randomly select 50 articles along with their corresponding questions and explanations. We then manually label sentences in the original article that are relevant to the quality aspect being measured. 2 During this process we only include explanations that are deemed as \"satisfactory,\" which means that relevant information is included in the original article.\n\n\nProducing Explanations\n\nWe use the Biased TextRank and the GPT-2 based models to automatically generate explanations for each dataset. With LIAR-PLUS, we seek to generate the explanation provided in the \"Our ruling\" section. For HNR we aim to generate the explanation provided for the different evaluative questions described in section 4.2. We use the provided train-   ing, validation and test splits for the LIAR-PLUS dataset. For HNR, we use 20% of the data as the test set and we study the first nine questions for each article only and exclude question #10 as answering it requires information beyond the news article. We use explanations and question-related article sentences as our references in ROUGE evaluations over the HNR dataset, and the section labeled \"Our ruling\" as ground truth for LIAR-PLUS.\n\nExtractive Explanations. To generate extractive explanations for the LIAR dataset, we apply Biased TextRank on the original article and its corresponding claim and pick the top 5 ranked sentences as the explanation (based on the average length of explanations in the dataset). To generate explanations on the HNR dataset, we apply Biased TextRank on each news article and question pair for 9 of the evaluative questions and select the top 5 ranked sentences as the extracted explanation (matching the dataset average explanation length).\n\nAbstractive Explanations. We apply the GPT-2 based model to generate abstractive explanations for each dataset using the original article and the corresponding claim or question as an input. We apply this method directly on the LIAR-PLUS dataset. On the HNT dataset, since we have several questions, we train separate GPT-2 based models per question. In addition, each model is trained using the articles corresponding to questions labeled as \"satisfactory\" only as the \"unsatisfactory\" or \"not applicable\" questions do not contain information within the scope of the original article.\n\n\nDownstream Evaluation\n\nWe also conduct a set of experiments to evaluate to what extent we can answer the evaluation questions in the HNR dataset with the generated explanations. For each question, we assign binary labels to the articles (1 for satisfactory answers, 0 for not satisfactory and NA answers) and train individual classifiers aiming to discriminate between these two labels. During these experiments each classifier is trained and evaluated ten times on the test set and the results are averaged over the ten runs.\n\n\nExperimental Results\n\nAs results in Table 3 suggest, while our abstractive GPT-2 based model fails to surpass extractive baselines on the LIAR-PLUS dataset, Biased TextRank outperforms the unsupervised TextRank baseline. Biased TextRank's improvements over TextRank suggest that a claim-focused summary of the article is better at generating supporting explanations than a regular summary produced by TextRank. Note that the current state-of-the-art results for this dataset, presented in (Atanasova et al., 2020) achieve 35.70, 13.51 and 31.58 in ROUGE-1, 2 and L scores respectively. However, a direct comparison with their method would not be accurate as it is a method that is supervised (versus the unsupervised Biased TextRank) and extractive (versus the abstractive GPT-2 based model). Table 4 presents results on automatic evaluation of generated explanations for the HNR dataset, showing that the GPT-2 based model outperforms Biased TextRank when evaluated against actual explanations and Biased TextRank beats GPT-2 against the extractive baseline. This indicates the GPT-2 based method is more effective in this dataset and performs comparably with Biased Tex-tRank. Results for the downstream task using both methods are shown in Table 5. As observed, results are significantly different and demonstrate that Biased TextRank significantly outperforms (ttest p = 0.05) the GPT-2-based abstractive method, thus suggesting that Biased TextRank generates good quality explanations for the HNR dataset.\n\nOur evaluations indicate that Biased TextRank shows the most promise, while the GPT-2 based model mostly follows in performance. Keeping in mind that the GPT-2 based model is solving the harder problem of generating language, it is worth noting the little supervision it receives on both datasets, especially on the HNR dataset where the average size of the training data is 849.\n\nIn terms of resource efficiency and speed, Biased TextRank is faster and lighter than the GPT-2 based model. Excluding the time needed to fine-tune the GPT-2 model, it takes approximately 60 seconds on a GPU to generate a coherent abstractive explanation on average on the LIAR-PLUS dataset, while Biased TextRank extracts explanations in the order of milliseconds and can even do it without a GPU in a few seconds. We find Biased TextRank's efficiency as another advantage of the unsupervised algorithm over the GPT-2 based model.\n\n\nConclusion\n\nIn this paper, we presented extractive and abstractive methods for generating supporting explanations for more convenient and transparent human consumption of news. We evaluated our methods on two domains and found promising results for producing explanations. In particular, Biased Text-Rank (an extractive method) outperformed the unsupervised baselines on the LIAR-PLUS dataset and performed reasonably close to the extractive ground-truth on the HNR dataset.\n\nFor future work, we believe generating abstractive explanations should be a priority, since intuitively an increase in the readability and coherence of the supporting explanations will result in improvements in the delivery and perception of news.\n\nTable 1 :\n1An example data point from the LIAR-PLUS dataset, with ground truth explanations, and explanations generated by our methods.\n\nTable 2 :\n2Dataset statistics for explanations; total count, average words and sentences per explanation.Model \nROUGE-1 ROUGE-2 ROUGE-L \nTextRank \n27.74 \n7.42 \n23.24 \nGPT-2 Based \n24.01 \n5.78 \n21.15 \nBiased TextRank \n30.90 \n10.39 \n26.22 \n\n\n\nTable 3 :\n3ROUGE-N scores of generated explanations on the LIAR-PLUS dataset.\n\nTable 4 :\n4ROUGE evaluation on the HNR dataset. Left columns under \"Explanations\" have the actual explanations as reference and the columns on the right provide results for comparison against question-relevant sentences.Model \nAcc. \nF1 (+) \nF1 (-) \nGPT-2 Based \n64.40% 49.04% 54.67% \nBiased TextRank 65.70% 56.69% 57.96% \n\n\n\nTable 5 :\n5Downstream evaluation results on the HNR dataset, averaged over 10 runs and 9 questions.\nWe followed the restrictions in the site's robots.txt file. 2 The annotation was conducted by two annotators, with a Pearson's correlation score of 0.62 and a Jaccard similarity of 0.75.\nAcknowledgmentsWe are grateful to Dr. Stacy Loeb, Professor of Urology and Population Health at New York University, for her expert feedback, which was instrumental for this work. This material is based in part upon work supported by the Precision Health initiative at the University of Michigan, by the National Science Foundation (grant #1815291), and by the John Templeton Foundation (grant #61156). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the Precision Health initiative, the National Science Foundation, or John Templeton Foundation.\nWhere is your evidence: Improving factchecking by justification modeling. Savvas Tariq Alhindi, Smaranda Petridis, Muresan, 10.18653/v1/W18-5513Proceedings of the First Workshop on Fact Extraction and VERification (FEVER). the First Workshop on Fact Extraction and VERification (FEVER)Brussels, BelgiumAssociation for Computational LinguisticsTariq Alhindi, Savvas Petridis, and Smaranda Mure- san. 2018. Where is your evidence: Improving fact- checking by justification modeling. In Proceedings of the First Workshop on Fact Extraction and VER- ification (FEVER), pages 85-90, Brussels, Belgium. Association for Computational Linguistics.\n\nGenerating fact checking explanations. Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, Isabelle Augenstein, 10.18653/v1/2020.acl-main.656Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational LinguisticsPepa Atanasova, Jakob Grue Simonsen, Christina Li- oma, and Isabelle Augenstein. 2020. Generating fact checking explanations. In Proceedings of the 58th Annual Meeting of the Association for Compu- tational Linguistics, pages 7352-7364, Online. As- sociation for Computational Linguistics.\n\nHello, it's GPT-2 -how can I help you? towards the use of pretrained language models for task-oriented dialogue systems. Pawe\u0142 Budzianowski, Ivan Vuli\u0107, 10.18653/v1/D19-5602Proceedings of the 3rd Workshop on Neural Generation and Translation. the 3rd Workshop on Neural Generation and TranslationHong KongAssociation for Computational LinguisticsPawe\u0142 Budzianowski and Ivan Vuli\u0107. 2019. Hello, it's GPT-2 -how can I help you? towards the use of pre- trained language models for task-oriented dialogue systems. In Proceedings of the 3rd Workshop on Neural Generation and Translation, pages 15-22, Hong Kong. Association for Computational Linguis- tics.\n\ne-snli: Natural language inference with natural language explanations. Oana-Maria Camburu, Tim Rockt\u00e4schel, Thomas Lukasiewicz, Phil Blunsom, Advances in Neural Information Processing Systems. S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. GarnettCurran Associates, Inc31Oana-Maria Camburu, Tim Rockt\u00e4schel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-snli: Nat- ural language inference with natural language expla- nations. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, ed- itors, Advances in Neural Information Processing Systems 31, pages 9539-9549. Curran Associates, Inc.\n\nSupervised learning of universal sentence representations from natural language inference data. Alexis Conneau, Douwe Kiela, Holger Schwenk, Lo\u00efc Barrault, Antoine Bordes, 10.18653/v1/D17-1070Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsAlexis Conneau, Douwe Kiela, Holger Schwenk, Lo\u00efc Barrault, and Antoine Bordes. 2017. Supervised learning of universal sentence representations from natural language inference data. In Proceedings of the 2017 Conference on Empirical Methods in Nat- ural Language Processing, pages 670-680, Copen- hagen, Denmark. Association for Computational Linguistics.\n\nBuilding explainable artificial intelligence systems. Chad Mark G Core, Michael Lane, Dave Van Lent, Gomboc, AAAI. Steve Solomon, and Milton RosenbergMark G Core, H Chad Lane, Michael Van Lent, Dave Gomboc, Steve Solomon, and Milton Rosenberg. 2006. Building explainable artificial intelligence systems. In AAAI, pages 1766-1773.\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaLong and Short Papers1Association for Computational LinguisticsJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.\n\nGenerating fact checking briefs. Angela Fan, Aleksandra Piktus, Fabio Petroni, Guillaume Wenzek, Marzieh Saeidi, Andreas Vlachos, Antoine Bordes, Sebastian Riedel, 10.18653/v1/2020.emnlp-main.580Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational LinguisticsAngela Fan, Aleksandra Piktus, Fabio Petroni, Guil- laume Wenzek, Marzieh Saeidi, Andreas Vlachos, Antoine Bordes, and Sebastian Riedel. 2020. Gen- erating fact checking briefs. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 7147-7161, Online. Association for Computational Linguistics.\n\nEnd-to-end neural pipeline for goal-oriented dialogue systems using GPT-2. Donghoon Ham, Jeong-Gwan Lee, Youngsoo Jang, Kee-Eung Kim, 10.18653/v1/2020.acl-main.54Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsDonghoon Ham, Jeong-Gwan Lee, Youngsoo Jang, and Kee-Eung Kim. 2020. End-to-end neural pipeline for goal-oriented dialogue systems using GPT-2. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguis- tics, pages 583-592, Online. Association for Com- putational Linguistics.\n\nTopic-sensitive pagerank. H Taher, Haveliwala, Proceedings of the 11th international conference on World Wide Web. the 11th international conference on World Wide WebACMTaher H Haveliwala. 2002. Topic-sensitive pagerank. In Proceedings of the 11th international conference on World Wide Web, pages 517-526. ACM.\n\nThe curious case of neural text degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, International Conference on Learning Representations. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text de- generation. In International Conference on Learn- ing Representations.\n\nBiased TextRank: Unsupervised graph-based content extraction. Ashkan Kazemi, Ver\u00f3nica P\u00e9rez-Rosas, Rada Mihalcea, 10.18653/v1/2020.coling-main.144Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational LinguisticsBarcelona, SpainInternational Committee on Computational LinguisticsAshkan Kazemi, Ver\u00f3nica P\u00e9rez-Rosas, and Rada Mi- halcea. 2020. Biased TextRank: Unsupervised graph-based content extraction. In Proceedings of the 28th International Conference on Compu- tational Linguistics, pages 1642-1652, Barcelona, Spain (Online). International Committee on Compu- tational Linguistics.\n\nExplainable automated fact-checking for public health claims. Neema Kotonya, Francesca Toni, 10.18653/v1/2020.emnlp-main.623Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational LinguisticsNeema Kotonya and Francesca Toni. 2020. Ex- plainable automated fact-checking for public health claims. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 7740-7754, Online. Associa- tion for Computational Linguistics.\n\nNILE : Natural language inference with faithful natural language explanations. Sawan Kumar, Partha Talukdar, 10.18653/v1/2020.acl-main.771Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational LinguisticsSawan Kumar and Partha Talukdar. 2020. NILE : Natu- ral language inference with faithful natural language explanations. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, pages 8730-8742, Online. Association for Computational Linguistics.\n\nROUGE: A package for automatic evaluation of summaries. Chin-Yew Lin, Text Summarization Branches Out. Barcelona, SpainAssociation for Computational LinguisticsChin-Yew Lin. 2004. ROUGE: A package for auto- matic evaluation of summaries. In Text Summariza- tion Branches Out, pages 74-81, Barcelona, Spain. Association for Computational Linguistics.\n\nGCAN: Graph-aware co-attention networks for explainable fake news detection on social media. Yi-Ju Lu, Cheng-Te Li, 10.18653/v1/2020.acl-main.48Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational LinguisticsYi-Ju Lu and Cheng-Te Li. 2020. GCAN: Graph-aware co-attention networks for explainable fake news de- tection on social media. In Proceedings of the 58th Annual Meeting of the Association for Computa- tional Linguistics, pages 505-514, Online. Associ- ation for Computational Linguistics.\n\nA unified approach to interpreting model predictions. M Scott, Su-In Lundberg, Lee, Advances in Neural Information Processing Systems. Scott M Lundberg and Su-In Lee. 2017. A unified approach to interpreting model predictions. In Ad- vances in Neural Information Processing Systems, pages 4765-4774.\n\nTextrank: Bringing order into text. Rada Mihalcea, Paul Tarau, Proceedings of the 2004 conference on empirical methods in natural language processing. the 2004 conference on empirical methods in natural language processingRada Mihalcea and Paul Tarau. 2004. Textrank: Bring- ing order into text. In Proceedings of the 2004 con- ference on empirical methods in natural language processing, pages 404-411.\n\nAutomatic detection of fake news. Ver\u00f3nica P\u00e9rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, Rada Mihalcea, Proceedings of the 27th International Conference on Computational Linguistics. the 27th International Conference on Computational LinguisticsSanta Fe, New Mexico, USAAssociation for Computational LinguisticsVer\u00f3nica P\u00e9rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, and Rada Mihalcea. 2018. Automatic de- tection of fake news. In Proceedings of the 27th International Conference on Computational Linguis- tics, pages 3391-3401, Santa Fe, New Mexico, USA. Association for Computational Linguistics.\n\nManipulating and measuring model interpretability. Forough Poursabzi-Sangdeh, G Daniel, Jake M Goldstein, Jennifer Wortman Hofman, Hanna Vaughan, Wallach, arXiv:1802.07810arXiv preprintForough Poursabzi-Sangdeh, Daniel G Goldstein, Jake M Hofman, Jennifer Wortman Vaughan, and Hanna Wallach. 2018. Manipulating and mea- suring model interpretability. arXiv preprint arXiv:1802.07810.\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI Blog. 189Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners. OpenAI Blog, 1(8):9.\n\nSentence-BERT: Sentence embeddings using Siamese BERTnetworks. Nils Reimers, Iryna Gurevych, 10.18653/v1/D19-1410Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsNils Reimers and Iryna Gurevych. 2019. Sentence- BERT: Sentence embeddings using Siamese BERT- networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu- ral Language Processing (EMNLP-IJCNLP), pages 3982-3992, Hong Kong, China. Association for Computational Linguistics.\n\nAutomated fact checking: Task formulations, methods and future directions. James Thorne, Andreas Vlachos, Proceedings of the 27th International Conference on Computational Linguistics. the 27th International Conference on Computational LinguisticsSanta Fe, New Mexico, USAAssociation for Computational LinguisticsJames Thorne and Andreas Vlachos. 2018. Automated fact checking: Task formulations, methods and fu- ture directions. In Proceedings of the 27th Inter- national Conference on Computational Linguistics, pages 3346-3359, Santa Fe, New Mexico, USA. As- sociation for Computational Linguistics.\n\nSean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, Kyunghyun Cho, arXiv:2002.02492Consistency of a recurrent language model with respect to incomplete decoding. arXiv preprintSean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang, and Kyunghyun Cho. 2020. Consistency of a recurrent language model with respect to incomplete decoding. arXiv preprint arXiv:2002.02492.\n\nHuggingface's transformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R&apos;emi Louf, Morgan Funtowicz, Jamie Brew, abs/1910.03771ArXiv. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, R'emi Louf, Morgan Funtow- icz, and Jamie Brew. 2019. Huggingface's trans- formers: State-of-the-art natural language process- ing. ArXiv, abs/1910.03771.\n", "annotations": {"author": "[{\"end\":128,\"start\":96},{\"end\":138,\"start\":129},{\"end\":160,\"start\":139},{\"end\":194,\"start\":161}]", "publisher": null, "author_last_name": "[{\"end\":109,\"start\":103},{\"end\":137,\"start\":135},{\"end\":159,\"start\":148},{\"end\":174,\"start\":166}]", "author_first_name": "[{\"end\":102,\"start\":96},{\"end\":134,\"start\":129},{\"end\":147,\"start\":139},{\"end\":165,\"start\":161}]", "author_affiliation": null, "title": "[{\"end\":81,\"start\":1},{\"end\":275,\"start\":195}]", "venue": "[{\"end\":343,\"start\":277}]", "abstract": "[{\"end\":1007,\"start\":444}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b18\"},\"end\":1322,\"start\":1296},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1347,\"start\":1322},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":1363,\"start\":1347},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1928,\"start\":1904},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1945,\"start\":1928},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2446,\"start\":2425},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2598,\"start\":2576},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3366,\"start\":3334},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3389,\"start\":3366},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3407,\"start\":3389},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3512,\"start\":3491},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3774,\"start\":3752},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3814,\"start\":3789},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6093,\"start\":6069},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6110,\"start\":6093},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6133,\"start\":6110},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6162,\"start\":6138},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6223,\"start\":6202},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6588,\"start\":6571},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6996,\"start\":6976},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7059,\"start\":7033},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8509,\"start\":8488},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8651,\"start\":8621},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8668,\"start\":8651},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9767,\"start\":9744},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9788,\"start\":9767},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10415,\"start\":10393},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10482,\"start\":10463},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10516,\"start\":10505},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":15863,\"start\":15839}]", "figure": "[{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":18637,\"start\":18501},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":18878,\"start\":18638},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":18957,\"start\":18879},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":19282,\"start\":18958},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":19383,\"start\":19283}]", "paragraph": "[{\"end\":2206,\"start\":1023},{\"end\":2599,\"start\":2208},{\"end\":3235,\"start\":2601},{\"end\":4020,\"start\":3252},{\"end\":6749,\"start\":4022},{\"end\":6930,\"start\":6761},{\"end\":7446,\"start\":6962},{\"end\":8336,\"start\":7448},{\"end\":8571,\"start\":8365},{\"end\":8802,\"start\":8573},{\"end\":9454,\"start\":8804},{\"end\":10305,\"start\":9456},{\"end\":10713,\"start\":10341},{\"end\":11011,\"start\":10715},{\"end\":11511,\"start\":11024},{\"end\":12413,\"start\":11513},{\"end\":12465,\"start\":12415},{\"end\":12877,\"start\":12467},{\"end\":13692,\"start\":12904},{\"end\":14231,\"start\":13694},{\"end\":14818,\"start\":14233},{\"end\":15347,\"start\":14844},{\"end\":16860,\"start\":15372},{\"end\":17241,\"start\":16862},{\"end\":17774,\"start\":17243},{\"end\":18251,\"start\":17789},{\"end\":18500,\"start\":18253}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":11510,\"start\":11503},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":12464,\"start\":12457},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":15393,\"start\":15386},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":16150,\"start\":16143},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":16600,\"start\":16593}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1021,\"start\":1009},{\"attributes\":{\"n\":\"2\"},\"end\":3250,\"start\":3238},{\"attributes\":{\"n\":\"3\"},\"end\":6759,\"start\":6752},{\"attributes\":{\"n\":\"3.1\"},\"end\":6960,\"start\":6933},{\"attributes\":{\"n\":\"3.2\"},\"end\":8363,\"start\":8339},{\"attributes\":{\"n\":\"4\"},\"end\":10318,\"start\":10308},{\"attributes\":{\"n\":\"4.1\"},\"end\":10339,\"start\":10321},{\"attributes\":{\"n\":\"4.2\"},\"end\":11022,\"start\":11014},{\"attributes\":{\"n\":\"4.3\"},\"end\":12902,\"start\":12880},{\"attributes\":{\"n\":\"4.4\"},\"end\":14842,\"start\":14821},{\"attributes\":{\"n\":\"5\"},\"end\":15370,\"start\":15350},{\"attributes\":{\"n\":\"7\"},\"end\":17787,\"start\":17777},{\"end\":18511,\"start\":18502},{\"end\":18648,\"start\":18639},{\"end\":18889,\"start\":18880},{\"end\":18968,\"start\":18959},{\"end\":19293,\"start\":19284}]", "table": "[{\"end\":18878,\"start\":18744},{\"end\":19282,\"start\":19179}]", "figure_caption": "[{\"end\":18637,\"start\":18513},{\"end\":18744,\"start\":18650},{\"end\":18957,\"start\":18891},{\"end\":19179,\"start\":18970},{\"end\":19383,\"start\":19295}]", "figure_ref": null, "bib_author_first_name": "[{\"end\":20304,\"start\":20298},{\"end\":20328,\"start\":20320},{\"end\":20908,\"start\":20904},{\"end\":20925,\"start\":20920},{\"end\":20930,\"start\":20926},{\"end\":20950,\"start\":20941},{\"end\":20966,\"start\":20958},{\"end\":21635,\"start\":21630},{\"end\":21654,\"start\":21650},{\"end\":22243,\"start\":22233},{\"end\":22256,\"start\":22253},{\"end\":22276,\"start\":22270},{\"end\":22294,\"start\":22290},{\"end\":22911,\"start\":22905},{\"end\":22926,\"start\":22921},{\"end\":22940,\"start\":22934},{\"end\":22954,\"start\":22950},{\"end\":22972,\"start\":22965},{\"end\":23635,\"start\":23631},{\"end\":23656,\"start\":23649},{\"end\":23667,\"start\":23663},{\"end\":23995,\"start\":23990},{\"end\":24012,\"start\":24004},{\"end\":24026,\"start\":24020},{\"end\":24040,\"start\":24032},{\"end\":24891,\"start\":24885},{\"end\":24907,\"start\":24897},{\"end\":24921,\"start\":24916},{\"end\":24940,\"start\":24931},{\"end\":24956,\"start\":24949},{\"end\":24972,\"start\":24965},{\"end\":24989,\"start\":24982},{\"end\":25007,\"start\":24998},{\"end\":25700,\"start\":25692},{\"end\":25716,\"start\":25706},{\"end\":25730,\"start\":25722},{\"end\":25745,\"start\":25737},{\"end\":26276,\"start\":26275},{\"end\":26611,\"start\":26608},{\"end\":26625,\"start\":26622},{\"end\":26634,\"start\":26632},{\"end\":26646,\"start\":26639},{\"end\":26660,\"start\":26655},{\"end\":26966,\"start\":26960},{\"end\":26983,\"start\":26975},{\"end\":27001,\"start\":26997},{\"end\":27631,\"start\":27626},{\"end\":27650,\"start\":27641},{\"end\":28272,\"start\":28267},{\"end\":28286,\"start\":28280},{\"end\":28883,\"start\":28875},{\"end\":29268,\"start\":29263},{\"end\":29281,\"start\":29273},{\"end\":29869,\"start\":29868},{\"end\":29882,\"start\":29877},{\"end\":30155,\"start\":30151},{\"end\":30170,\"start\":30166},{\"end\":30562,\"start\":30554},{\"end\":30583,\"start\":30576},{\"end\":30604,\"start\":30595},{\"end\":30618,\"start\":30614},{\"end\":31187,\"start\":31180},{\"end\":31208,\"start\":31207},{\"end\":31221,\"start\":31217},{\"end\":31223,\"start\":31222},{\"end\":31243,\"start\":31235},{\"end\":31251,\"start\":31244},{\"end\":31265,\"start\":31260},{\"end\":31571,\"start\":31567},{\"end\":31588,\"start\":31581},{\"end\":31598,\"start\":31593},{\"end\":31611,\"start\":31606},{\"end\":31623,\"start\":31618},{\"end\":31636,\"start\":31632},{\"end\":31897,\"start\":31893},{\"end\":31912,\"start\":31907},{\"end\":32783,\"start\":32778},{\"end\":32799,\"start\":32792},{\"end\":33311,\"start\":33307},{\"end\":33325,\"start\":33321},{\"end\":33342,\"start\":33335},{\"end\":33355,\"start\":33348},{\"end\":33363,\"start\":33356},{\"end\":33379,\"start\":33370},{\"end\":33775,\"start\":33769},{\"end\":33790,\"start\":33782},{\"end\":33804,\"start\":33798},{\"end\":33817,\"start\":33811},{\"end\":33835,\"start\":33828},{\"end\":33853,\"start\":33846},{\"end\":33866,\"start\":33859},{\"end\":33878,\"start\":33875},{\"end\":33896,\"start\":33886},{\"end\":33909,\"start\":33903},{\"end\":33926,\"start\":33921}]", "bib_author_last_name": "[{\"end\":20318,\"start\":20305},{\"end\":20337,\"start\":20329},{\"end\":20346,\"start\":20339},{\"end\":20918,\"start\":20909},{\"end\":20939,\"start\":20931},{\"end\":20956,\"start\":20951},{\"end\":20977,\"start\":20967},{\"end\":21648,\"start\":21636},{\"end\":21660,\"start\":21655},{\"end\":22251,\"start\":22244},{\"end\":22268,\"start\":22257},{\"end\":22288,\"start\":22277},{\"end\":22302,\"start\":22295},{\"end\":22919,\"start\":22912},{\"end\":22932,\"start\":22927},{\"end\":22948,\"start\":22941},{\"end\":22963,\"start\":22955},{\"end\":22979,\"start\":22973},{\"end\":23647,\"start\":23636},{\"end\":23661,\"start\":23657},{\"end\":23676,\"start\":23668},{\"end\":23684,\"start\":23678},{\"end\":24002,\"start\":23996},{\"end\":24018,\"start\":24013},{\"end\":24030,\"start\":24027},{\"end\":24050,\"start\":24041},{\"end\":24895,\"start\":24892},{\"end\":24914,\"start\":24908},{\"end\":24929,\"start\":24922},{\"end\":24947,\"start\":24941},{\"end\":24963,\"start\":24957},{\"end\":24980,\"start\":24973},{\"end\":24996,\"start\":24990},{\"end\":25014,\"start\":25008},{\"end\":25704,\"start\":25701},{\"end\":25720,\"start\":25717},{\"end\":25735,\"start\":25731},{\"end\":25749,\"start\":25746},{\"end\":26282,\"start\":26277},{\"end\":26294,\"start\":26284},{\"end\":26620,\"start\":26612},{\"end\":26630,\"start\":26626},{\"end\":26637,\"start\":26635},{\"end\":26653,\"start\":26647},{\"end\":26665,\"start\":26661},{\"end\":26973,\"start\":26967},{\"end\":26995,\"start\":26984},{\"end\":27010,\"start\":27002},{\"end\":27639,\"start\":27632},{\"end\":27655,\"start\":27651},{\"end\":28278,\"start\":28273},{\"end\":28295,\"start\":28287},{\"end\":28887,\"start\":28884},{\"end\":29271,\"start\":29269},{\"end\":29284,\"start\":29282},{\"end\":29875,\"start\":29870},{\"end\":29891,\"start\":29883},{\"end\":29896,\"start\":29893},{\"end\":30164,\"start\":30156},{\"end\":30176,\"start\":30171},{\"end\":30574,\"start\":30563},{\"end\":30593,\"start\":30584},{\"end\":30612,\"start\":30605},{\"end\":30627,\"start\":30619},{\"end\":31205,\"start\":31188},{\"end\":31215,\"start\":31209},{\"end\":31233,\"start\":31224},{\"end\":31258,\"start\":31252},{\"end\":31273,\"start\":31266},{\"end\":31282,\"start\":31275},{\"end\":31579,\"start\":31572},{\"end\":31591,\"start\":31589},{\"end\":31604,\"start\":31599},{\"end\":31616,\"start\":31612},{\"end\":31630,\"start\":31624},{\"end\":31646,\"start\":31637},{\"end\":31905,\"start\":31898},{\"end\":31921,\"start\":31913},{\"end\":32790,\"start\":32784},{\"end\":32807,\"start\":32800},{\"end\":33319,\"start\":33312},{\"end\":33333,\"start\":33326},{\"end\":33346,\"start\":33343},{\"end\":33368,\"start\":33364},{\"end\":33383,\"start\":33380},{\"end\":33780,\"start\":33776},{\"end\":33796,\"start\":33791},{\"end\":33809,\"start\":33805},{\"end\":33826,\"start\":33818},{\"end\":33844,\"start\":33836},{\"end\":33857,\"start\":33854},{\"end\":33873,\"start\":33867},{\"end\":33884,\"start\":33879},{\"end\":33901,\"start\":33897},{\"end\":33919,\"start\":33910},{\"end\":33931,\"start\":33927}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/W18-5513\",\"id\":\"b0\",\"matched_paper_id\":53640239},\"end\":20863,\"start\":20224},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.656\",\"id\":\"b1\",\"matched_paper_id\":215744944},\"end\":21507,\"start\":20865},{\"attributes\":{\"doi\":\"10.18653/v1/D19-5602\",\"id\":\"b2\",\"matched_paper_id\":196471188},\"end\":22160,\"start\":21509},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":54040953},\"end\":22807,\"start\":22162},{\"attributes\":{\"doi\":\"10.18653/v1/D17-1070\",\"id\":\"b4\",\"matched_paper_id\":28971531},\"end\":23575,\"start\":22809},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2733167},\"end\":23906,\"start\":23577},{\"attributes\":{\"doi\":\"10.18653/v1/N19-1423\",\"id\":\"b6\",\"matched_paper_id\":52967399},\"end\":24850,\"start\":23908},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.580\",\"id\":\"b7\",\"matched_paper_id\":226262339},\"end\":25615,\"start\":24852},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.54\",\"id\":\"b8\",\"matched_paper_id\":219719687},\"end\":26247,\"start\":25617},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":129431},\"end\":26560,\"start\":26249},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":127986954},\"end\":26896,\"start\":26562},{\"attributes\":{\"doi\":\"10.18653/v1/2020.coling-main.144\",\"id\":\"b11\",\"matched_paper_id\":226236800},\"end\":27562,\"start\":26898},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.623\",\"id\":\"b12\",\"matched_paper_id\":224802782},\"end\":28186,\"start\":27564},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.771\",\"id\":\"b13\",\"matched_paper_id\":218869840},\"end\":28817,\"start\":28188},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":964287},\"end\":29168,\"start\":28819},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.48\",\"id\":\"b15\",\"matched_paper_id\":216144503},\"end\":29812,\"start\":29170},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":21889700},\"end\":30113,\"start\":29814},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":577937},\"end\":30518,\"start\":30115},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":27274148},\"end\":31127,\"start\":30520},{\"attributes\":{\"doi\":\"arXiv:1802.07810\",\"id\":\"b19\"},\"end\":31512,\"start\":31129},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":160025533},\"end\":31828,\"start\":31514},{\"attributes\":{\"doi\":\"10.18653/v1/D19-1410\",\"id\":\"b21\",\"matched_paper_id\":201646309},\"end\":32701,\"start\":31830},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":49320819},\"end\":33305,\"start\":32703},{\"attributes\":{\"doi\":\"arXiv:2002.02492\",\"id\":\"b23\"},\"end\":33693,\"start\":33307},{\"attributes\":{\"doi\":\"abs/1910.03771\",\"id\":\"b24\",\"matched_paper_id\":204509627},\"end\":34227,\"start\":33695}]", "bib_title": "[{\"end\":20296,\"start\":20224},{\"end\":20902,\"start\":20865},{\"end\":21628,\"start\":21509},{\"end\":22231,\"start\":22162},{\"end\":22903,\"start\":22809},{\"end\":23629,\"start\":23577},{\"end\":23988,\"start\":23908},{\"end\":24883,\"start\":24852},{\"end\":25690,\"start\":25617},{\"end\":26273,\"start\":26249},{\"end\":26606,\"start\":26562},{\"end\":26958,\"start\":26898},{\"end\":27624,\"start\":27564},{\"end\":28265,\"start\":28188},{\"end\":28873,\"start\":28819},{\"end\":29261,\"start\":29170},{\"end\":29866,\"start\":29814},{\"end\":30149,\"start\":30115},{\"end\":30552,\"start\":30520},{\"end\":31565,\"start\":31514},{\"end\":31891,\"start\":31830},{\"end\":32776,\"start\":32703},{\"end\":33767,\"start\":33695}]", "bib_author": "[{\"end\":20320,\"start\":20298},{\"end\":20339,\"start\":20320},{\"end\":20348,\"start\":20339},{\"end\":20920,\"start\":20904},{\"end\":20941,\"start\":20920},{\"end\":20958,\"start\":20941},{\"end\":20979,\"start\":20958},{\"end\":21650,\"start\":21630},{\"end\":21662,\"start\":21650},{\"end\":22253,\"start\":22233},{\"end\":22270,\"start\":22253},{\"end\":22290,\"start\":22270},{\"end\":22304,\"start\":22290},{\"end\":22921,\"start\":22905},{\"end\":22934,\"start\":22921},{\"end\":22950,\"start\":22934},{\"end\":22965,\"start\":22950},{\"end\":22981,\"start\":22965},{\"end\":23649,\"start\":23631},{\"end\":23663,\"start\":23649},{\"end\":23678,\"start\":23663},{\"end\":23686,\"start\":23678},{\"end\":24004,\"start\":23990},{\"end\":24020,\"start\":24004},{\"end\":24032,\"start\":24020},{\"end\":24052,\"start\":24032},{\"end\":24897,\"start\":24885},{\"end\":24916,\"start\":24897},{\"end\":24931,\"start\":24916},{\"end\":24949,\"start\":24931},{\"end\":24965,\"start\":24949},{\"end\":24982,\"start\":24965},{\"end\":24998,\"start\":24982},{\"end\":25016,\"start\":24998},{\"end\":25706,\"start\":25692},{\"end\":25722,\"start\":25706},{\"end\":25737,\"start\":25722},{\"end\":25751,\"start\":25737},{\"end\":26284,\"start\":26275},{\"end\":26296,\"start\":26284},{\"end\":26622,\"start\":26608},{\"end\":26632,\"start\":26622},{\"end\":26639,\"start\":26632},{\"end\":26655,\"start\":26639},{\"end\":26667,\"start\":26655},{\"end\":26975,\"start\":26960},{\"end\":26997,\"start\":26975},{\"end\":27012,\"start\":26997},{\"end\":27641,\"start\":27626},{\"end\":27657,\"start\":27641},{\"end\":28280,\"start\":28267},{\"end\":28297,\"start\":28280},{\"end\":28889,\"start\":28875},{\"end\":29273,\"start\":29263},{\"end\":29286,\"start\":29273},{\"end\":29877,\"start\":29868},{\"end\":29893,\"start\":29877},{\"end\":29898,\"start\":29893},{\"end\":30166,\"start\":30151},{\"end\":30178,\"start\":30166},{\"end\":30576,\"start\":30554},{\"end\":30595,\"start\":30576},{\"end\":30614,\"start\":30595},{\"end\":30629,\"start\":30614},{\"end\":31207,\"start\":31180},{\"end\":31217,\"start\":31207},{\"end\":31235,\"start\":31217},{\"end\":31260,\"start\":31235},{\"end\":31275,\"start\":31260},{\"end\":31284,\"start\":31275},{\"end\":31581,\"start\":31567},{\"end\":31593,\"start\":31581},{\"end\":31606,\"start\":31593},{\"end\":31618,\"start\":31606},{\"end\":31632,\"start\":31618},{\"end\":31648,\"start\":31632},{\"end\":31907,\"start\":31893},{\"end\":31923,\"start\":31907},{\"end\":32792,\"start\":32778},{\"end\":32809,\"start\":32792},{\"end\":33321,\"start\":33307},{\"end\":33335,\"start\":33321},{\"end\":33348,\"start\":33335},{\"end\":33370,\"start\":33348},{\"end\":33385,\"start\":33370},{\"end\":33782,\"start\":33769},{\"end\":33798,\"start\":33782},{\"end\":33811,\"start\":33798},{\"end\":33828,\"start\":33811},{\"end\":33846,\"start\":33828},{\"end\":33859,\"start\":33846},{\"end\":33875,\"start\":33859},{\"end\":33886,\"start\":33875},{\"end\":33903,\"start\":33886},{\"end\":33921,\"start\":33903},{\"end\":33933,\"start\":33921}]", "bib_venue": "[{\"end\":20526,\"start\":20447},{\"end\":21169,\"start\":21097},{\"end\":21814,\"start\":21752},{\"end\":23179,\"start\":23089},{\"end\":23727,\"start\":23692},{\"end\":24365,\"start\":24216},{\"end\":25222,\"start\":25143},{\"end\":25940,\"start\":25868},{\"end\":26415,\"start\":26364},{\"end\":27201,\"start\":27123},{\"end\":27863,\"start\":27784},{\"end\":28487,\"start\":28415},{\"end\":28938,\"start\":28922},{\"end\":29475,\"start\":29403},{\"end\":30337,\"start\":30266},{\"end\":30795,\"start\":30708},{\"end\":32296,\"start\":32120},{\"end\":32975,\"start\":32888},{\"end\":20445,\"start\":20368},{\"end\":21095,\"start\":21008},{\"end\":21750,\"start\":21682},{\"end\":22353,\"start\":22304},{\"end\":23087,\"start\":23001},{\"end\":23690,\"start\":23686},{\"end\":24214,\"start\":24072},{\"end\":25141,\"start\":25047},{\"end\":25866,\"start\":25779},{\"end\":26362,\"start\":26296},{\"end\":26719,\"start\":26667},{\"end\":27121,\"start\":27044},{\"end\":27782,\"start\":27688},{\"end\":28413,\"start\":28326},{\"end\":28920,\"start\":28889},{\"end\":29401,\"start\":29314},{\"end\":29947,\"start\":29898},{\"end\":30264,\"start\":30178},{\"end\":30706,\"start\":30629},{\"end\":31178,\"start\":31129},{\"end\":31659,\"start\":31648},{\"end\":32118,\"start\":31943},{\"end\":32886,\"start\":32809},{\"end\":33478,\"start\":33401},{\"end\":33952,\"start\":33947}]"}}}, "year": 2023, "month": 12, "day": 17}