{"id": 251744205, "updated": "2022-10-31 15:42:21.849", "metadata": {"title": "GENERIC: highly efficient learning engine on edge using hyperdimensional computing", "authors": "[{\"first\":\"Behnam\",\"last\":\"Khaleghi\",\"middle\":[]},{\"first\":\"Jaeyoung\",\"last\":\"Kang\",\"middle\":[]},{\"first\":\"Hanyang\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Justin\",\"last\":\"Morris\",\"middle\":[]},{\"first\":\"Tajana\",\"last\":\"Rosing\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 59th ACM/IEEE Design Automation Conference", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Hyperdimensional Computing (HDC) mimics the brain's basic principles in performing cognitive tasks by encoding the data to high-dimensional vectors and employing non-complex learning techniques. Conventional processing platforms such as CPUs and GPUs are incapable of taking full advantage of the highly-parallel bit-level operations of HDC. On the other hand, existing HDC encoding techniques do not cover a broad range of applications to make a custom design plausible. In this paper, we first propose a novel encoding that achieves high accuracy for diverse applications. Thereafter, we leverage the proposed encoding and design a highly efficient and flexible ASIC accelerator, dubbed GENERIC, suited for the edge domain. GENERIC supports both classification (train and inference) and clustering for unsupervised learning on edge. Our design is flexible in the input size (hence it can run various applications) and hypervectors dimensionality, allowing it to trade off the accuracy and energy/performance on-demand. We augment GENERIC with application-opportunistic power-gating and voltage over-scaling (thanks to the notable error resiliency of HDC) for further energy reduction. GENERIC encoding improves the prediction accuracy over previous HDC and ML techniques by 3.5% and 6.5%, respectively. At 14 nm technology node, GENERIC occupies an area of 0.30 mm2, and consumes 0.09 mW static and 1.97 mW active power. Compared to the previous inference-only accelerator, GENERIC reduces the energy consumption by 4.1\u00d7.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/dac/Khaleghi0XMR22", "doi": "10.1145/3489517.3530669"}}, "content": {"source": {"pdf_hash": "b2b3775722c5bce373a6dfae64695fc2b05a253a", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "8972eb1ca843a5d509624a24695e4ff023399a2d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/b2b3775722c5bce373a6dfae64695fc2b05a253a.txt", "contents": "\nGENERIC: Highly Efficient Learning Engine on Edge using Hy-perdimensional Computing\nJuly 10-14, 2022\n\nBehnam Khaleghi bkhaleghi@ucsd.edu \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nJaeyoung Kang j5kang@ucsd.edu \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nHanyang Xu \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nJustin Morris j1morris@ucsd.edu \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nTajana Rosing tajana@ucsd.edu \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nBehnam Khaleghi \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nJaeyoung Kang \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nHanyang Xu \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nJustin Morris \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nTajana Ros \nDepartment of Computer Science and Engineering\nUC San Diego\nLa Jolla92093CA\n\nGENERIC: Highly Efficient Learning Engine on Edge using Hy-perdimensional Computing\n\nProceedings of the 59th ACM/IEEE Design Automation Conference (DAC) (DAC '22)\nthe 59th ACM/IEEE Design Automation Conference (DAC) (DAC '22)San Francisco, CAJuly 10-14, 2022ACM Reference Format: USA. ACM, New York, NY, USA, 6 pages. https://doi.org/10.1145/3489517. 3530669\nHyperdimensional Computing (HDC) mimics the brain's basic principles in performing cognitive tasks by encoding the data to high-dimensional vectors and employing non-complex learning techniques. Conventional processing platforms such as CPUs and GPUs are incapable of taking full advantage of the highly-parallel bit-level operations of HDC. On the other hand, existing HDC encoding techniques do not cover a broad range of applications to make a custom design plausible. In this paper, we first propose a novel encoding that achieves high accuracy for diverse applications. Thereafter, we leverage the proposed encoding and design a highly efficient and flexible ASIC accelerator, dubbed GENERIC, suited for the edge domain. GENERIC supports both classification (train and inference) and clustering for unsupervised learning on edge. Our design is flexible in the input size (hence it can run various applications) and hypervectors dimensionality, allowing it to trade off the accuracy and energy/performance on-demand. We augment GENERIC with application-opportunistic power-gating and voltage over-scaling (thanks to the notable error resiliency of HDC) for further energy reduction. GENERIC encoding improves the prediction accuracy over previous HDC and ML techniques by 3.5% and 6.5%, respectively. At 14 nm technology node, GENERIC occupies an area of 0.30 mm 2 , and consumes 0.09 mW static and 1.97 mW active power. Compared to the previous inference-only accelerator, GENERIC reduces the energy consumption by 4.1\u00d7.\n\nIntroduction\n\nHyperdimensional Computing (HDC) is a novel brain-inspired learning paradigm based on the observation that brains perform cognitive tasks by mapping sensory inputs to high-dimensional neural representation [1][2][3]. It enables the brain to carry out simple, low-power, error-resilient, and parallelizable operations all in the hyperspace. Such characteristics of HDC make it appealing for a wide variety of applications such as IoT domain that generates an increasing amount of data with tight resource and energy constraints [4,5].\n\nPermission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). DAC '22, July 10-14, 2022 HDC uses specific algorithms to encode raw inputs to a highdimensional representation of hypervectors with D \u210e \u22482\u22125 dimensions. The encoding takes place by deterministically associating each element of an input with a binary or bipolar (\u00b11) hypervector and bundling (element-wise addition) the hypervectors of all elements to create the encoded hypervector. Training is straightforward and involves bundling all encoded hypervectors of the same category. For inference, the query input is encoded to a hypervector in the same fashion and compared with all class hypervectors using a simple similarity metric such as cosine.\n\nThe bit-level massively parallel operations of HDC do not accord well with conventional CPUs/GPUs due to, e.g., memory latency and data movement of large vectors and the fact that these devices are over-provisioned for majorly binary operations of HDC. Previous works on custom HDC accelerators support a limited range of applications or achieve low accuracy. The authors of [6] and [7] propose custom HDC inference designs that are limited to a specific application. More flexible HDC inference ASICs are proposed in [8] and [9], but as we quantify in Section 3.2, the utilized encoding techniques achieve poor accuracy for particular applications such as time-series. The authors of [10] propose a trainable HDC accelerator, which yields 9% lower accuracy than baseline ML algorithms. An HDC-tailored processor is proposed in [11], but it consumes \u223c1\u22122 orders of magnitude more energy than ASIC counterparts. The in-memory HDC platform of [12] uses low-leakage PCM cells to store hypervectors, but its CMOS peripherals throttle the overall efficiency.\n\nIn this paper, we propose GENERIC (highly efficient learning engine on edge using hyperdimensional computing) for highly efficient and accurate trainable classification and clustering. Our primary goal is to make GENERIC compact and low-power to meet year-long battery-powered operation, yet fast enough during training and burst inference, e.g., when it serves as an IoT gateway. To this end, we make the following contributions.\n\n(1) We propose a novel HDC encoding that yields high accuracy in various benchmarks. Such a generic encoding is fundamental to develop a custom yet flexible circuit.\n\n(2) We perform a detailed comparison of HDC and various ML techniques on conventional devices and point out the failure of these devices in unleashing HDC advantages.\n\n(3) We propose the GENERIC flexible architecture that implements accurate HDC-based trainable classification and clustering. (4) GENERIC benefits from extreme energy reduction techniques such as application-opportunistic power gating, on-demand dimension reduction, and error-resilient voltage over-scaling. (5) Comparison of GENERIC with the state-of-the-art HDC implementations reveals GENERIC improves the classification accuracy by 3.5% over previous HDC techniques and 6.5% over ML techniques. GENERIC improves energy consumption by 4.1\u00d7 and 15.7\u00d7 compared to previous HDC accelerators [8] and [10], respectively.  2 Hyperdimensional Computing 2.1 Learning with HDC Figure 1 demonstrates the HDC training and inference. During training, each input X is encoded to a hypervector H (X) and added up to its class hypervector. In the inference, the query is likewise encoded and compared with class hypervectors. The class index with the highest similarity score is returned as the prediction result. We use cosine distance of the query and class hypervectors as the similarity metric. The accuracy of an HDC model can be improved by retraining iterations where the encoded train data are compared with the HDC model, and in case of misprediction, the model is updated by subtracting the encoded hypervector from the mispredicted class and adding it to the correct class.\n\nThe similarity of hypervectors indicates their proximity [1], which can be used to cluster data in the hyperspace [13]. Initially, encoded hypervectors are selected as clusters centroids. At each iteration, all encoded inputs are compared with the centroids and added to the closest (highest score) centroid hypervector. In classification, the model is updated right away. However, in clustering, the model is fixed and used for finding the similarities, and a new model is created from scratch, which replaces the current model in the next iteration.\n\n\nEncoding\n\nEncoding is the major step of HDC; hence, previous works have proposed several encoding techniques to map the inputs to highdimensional space. Most encodings associate hypervectors with the raw input features (elements), called level hypervector (see Figure 2(a)), which are hyperspace representative of scalar elements. Usually, inputs are quantized into bins to limit the number of levels. If there is a meaningful distance between the input elements (as in the values of white and black pixels), this distance is also preserved when generating the levels.\n\nEncoding of an input is accomplished by aggregation the level hypervectors of its elements. To handle the positional order of elements, which is essential in most datasets such as image or voice, HDC uses variants of binding. The permutation encoding of Figure  2(b) carries out binding by circular shift of the level hypervectors; the level hypervector of th feature is permuted by indexes. Some other encodings such as random projection (RP), shown in Figure 2(c), or level-id use id hypervectors for binding. In these encodings, each input index has a random (but constant) binary id, which is multiplied (XOR in the binary domain) with its level, and the result vector is aggregated with that of other indexes.\n\n\nProposed HDC Encoding 3.1 GENERIC Encoding\n\nThe encoding techniques discussed in Section 2.2 achieve low accuracy for certain datasets such as language identification which generally need extracting local subsequences of consecutive features, without considering the global order of these subsequences (see subsection 3.2). Previous studies use ngram encoding for such datasets [6,7,14]. Ngram encoding extracts all subsequences of length (usually \u2208{3\u22125}) in a given input, encodes all these subsequences and aggregates them to produce the encoded hypervector. However, ngram encoding achieves very low accuracy for datasets such as images or voices in which the spatio-temporal information of should be taken into account.\n\nWe propose a new encoding, dubbed GENERIC, to cover a more versatile set of applications. As shown in Figure 2(d), our encoding processes sliding windows of length by applying the permutation encoding. That is, for every window consisting of elements { , +1 , +2 } (for =3), three level hypervectors are selected, where \u2113 ( ), \u2113 ( +1 ), and \u2113 ( +2 ) are permuted by 0, 1, and 2 indexes, respectively. The permuted hypervectors are XORed elementwise to create the window hypervector. The permutation accounts for positional information within a window, e.g., to distinguish \"abc\" and \"bca\". To account for global order of features, we associate a random but constant id hypervector with each window, which is XORed with the window hypervector to perform binding. To skip the global binding in certain applications, id hypervectors are set to {0} D \u210e . Equation (1) formalizes our encoding, where ( ) indicates permutation by indexes, multiplies (XOR in binary) the levels of th window, applies the binding , and adds up the window hypervector for all windows of elements.\nH (X) = \u2212 +1 =1 \u00b7 \u22121 =0 ( ) \u2113 ( + )(1)\nWe use =3 as it achieved the highest accuracy (on average) for our examined benchmarks (see subsection 3.2), however, GENERIC architecture can adjust the value of for every application.\n\n\nAccuracy Comparison\n\nWe compiled eleven datasets from different domains, consisting of the benchmarks described in [10], seizure detection by skull surface EEG signals, and user activity recognition by motion sensors (PAMAP2) [15]. We implemented the HDC algorithms using an optimized Python implementation that leverages SIMD operations. For ML techniques, we used Python scikit-learn library [16]. We discarded the results of logistic regression and -nearest neighbors as they achieved lower accuracy. For DNN models of benchmarks, we used AutoKeras library [17] for automated model exploration. Table 1 summarizes the accuracy results (RP: random projection, MLP: multi-layer perceptron, SVM: support vector machine, RF: random forest). The proposed GENERIC encoding achieves 3.5% higher accuracy than the best baseline HDC (level-id), 6.5% higher than best baseline ML (SVM), and 1.0% higher than DNN. The  RP encoding fails in time-series datasets that require temporal information (e.g., EEG). As explained in subsection 3.1, the ngram encoding [6,14] do not capture the global relation of the features, so it fails in datasets such as speech (ISOLET) and image recognition (MNIST). Except for the ngram and the proposed GENERIC, other HDC techniques fail in the LANG (text classification) as they enforce capturing sequential information and ignore subsequences.\n\n\nEfficiency on Conventional Hardware\n\nHDC's operations are simple and highly parallelizable, however, conventional processors are not optimized for binary operations such as one-bit accumulation. Also, the size of hypervectors in most settings becomes larger than the cache size of low-end edge processors, which may impose significant performance overhead. For a detailed comparison, we implemented the HDC and ML algorithms on the datasets of subsection 3.2 on a Raspberry Pi 3 embedded processor and NVIDIA Jetson TX2 low-power edge GPU, and also a desktop CPU (Intel Core i7-8700 at 3.2 GHz) with a larger cache. We used Hioki 3334 power meter to measure the power of the Raspberry Pi. Figure 3 compares the training and inference (a) energy consumption and (b) execution time of the algorithms, reported as the geometric mean of all benchmarks (for eGPU, we omitted the results of conventional ML as it performed worse than CPU for a variety of libraries we examined). We can observe that (i) conventional ML algorithms, including DNN, unanimously consume smaller energy than HDC on all devices, (ii) GENERIC encoding, due to processing multiple hypervectors per window, is less efficient than other HDC techniques, and (iii) our eGPU implementation, by data packing (for parallel XOR) and memory reuse, significantly improves the HDC execution time and energy consumption. For instance, eGPU improves the energy usage and execution time of GENERIC inference by 134\u00d7 and 252\u00d7 over running on low-end Raspberry Pi (70\u00d7 and 30\u00d7 over CPU). However, GENERIC running on eGPU still consumes 12\u00d7 (3\u00d7) more inference (train) energy,  with 27\u00d7 (111\u00d7) higher execution time than the most efficient baseline (random forest). Nonetheless, eGPU numbers imply substantial energy and runtime reduction potential for HDC by effectively taking advantage of low-precision operations (achieved by bit-packing in eGPU) and high parallelism. Figure 4 shows the main components of GENERIC architecture. The main inputs include (i) input port to read an input (including the label in case of training) from the serial interface element by element and store in the input memory before starting the encoding, (ii) config port to load the level, , and class hypervectors (in case of offline training), and (iii) spec port to provide the application characteristics to the controller, such as D \u210e dimensionality, elements per input, length of window, number of classes or centroids, effective bit-width, and mode (training, inference, or clustering). Output port returns the labels of inference or clustering.\n\n\nGENERIC Architecture\n\n\nOverview\n\nThe controller, by using spec data, handles the programmability of GENERIC and orchestrates the operations. For instance, the encoder generates =16 (architectural constant) partial dimensions after each iteration over the stored input, where the variable D \u210e signals the end of encoding to finalize the search result, denotes the number of input memory rows to be proceeded to fetch features (i.e., the exit condition for counter), indicates the number of class memory rows that need to be read for dot-product and so on. The class memory layout of GENERIC also allows trade off between the hypervectors length \u210e and supported classes . By default, GENERIC class memories can store \u210e =4K for up to =32 classes. For an application with less than 32 classes, higher number of dimensions can be used (e.g., 8K dimensions for 16 classes). We further discuss it in subsection 4.3. These application-specific input parameters enable GENERIC the flexibility to implement various applications without requiring a complex instruction set or reconfigurable logic.\n\n\nClassification and Clustering\n\n\nEncoding and Inference:\n\nFeatures are fetched one by one from the input memory and quantized to obtain the level bin, and accordingly, (16) bits of the proper level hypervector are read. The levels are stored as -bit rows in the level memory. The stacked registers (reg to 1) facilitate storing and on-the-fly sliding of level hypervectors of a window. Each pass over the input features generates encoding dimensions, which are used for dot-product with the classes. The class hypervectors are distributed into memories (CM 1 to CM ) to enable reading consecutive dimensions at once. The dot-product of partial encoding with each class is summed up in the pipelined adder \u2022 6 , and accumulated with the dot-product result of previous/next dimensions in the score memory \u2022 7 .\n\nAfter D \u210e iterations, all dimensions are generated, and the dotproduct scores are finalized. We use cosine similarity metric between the encoding vector H and class C : = H\u00b7 C H 2 \u00d7 C 2 ; hence, we need to normalize the dot-product result with L2 norms. The H 2 can be removed from the denominator as it is a constant and does not affect the rank of classes. In addition, to eliminate the square root of C 2 , we modify the metric to = (H\u00b7 C ) 2 C 2 2 without affecting the predictions. The norm2 memory of Figure 4 \u2022 8 stores the squared L2 norms of classes, and similarly, the squared score is passed to the divider \u2022 9 . We use an approximate log-based division [18].\n\n\nTraining and Retraining:\n\nIn the first round of training, i.e., model initialization, encoded inputs of the same class/label are accumulated. It is done through the adder \u2022 4 and mux \u2022 3 of all class memories. The controller uses the input label and the iteration counter to activate the proper memory row. In the next retraining epochs, the model is examined and updated in case of misprediction (see Figure 1). Thus, during retraining, meanwhile performing inference on the training data, the encoded hypervector is stored in temporary rows of the class memories (through the second input of mux \u2022 3 ). If updating a class is required, the class rows are read and latched in the adder \u2022 4 , followed by reading the corresponding encoded dimensions from the temporary rows and writing the new class dimensions back to the memory. Hence, each update takes 3\u00d7 D \u210e cycles. Training also requires calculating the squared L2 norm of classes in the norm2 memory \u2022 8 . As it can be seen in Figure 4, the class memories are able to pass the output into both ports of the multipliers (one direct and another through the mux) to calculate and then accumulate the squared elements.\n\n\n4.2.3\n\nClustering: GENERIC selects the first encoded inputs as the initial cluster centroids and initializes centroids in the class memories. It allocates two sets of memory rows for temporary data; one for the incoming encoding generated in the encoding module and another for the copy centroids (as mentioned in Section 2.1, clustering generates a new copy instead of direct update). Similarity checking of the encoding dimensions with the centroids is done pipelined similar to inference, but the encoded dimensions are stored to be added to the copy centroid after finalizing the similarity checking. After finding the most similar centroid, the copy centroid is updated by adding the stored hypervector (similar to retraining). The copy centroids serve as the new centroids in the next epoch.\n\n\nEnergy Reduction\n\nWe take advantage of the properties of GENERIC architecture and HDC for utmost energy efficiency. The following elaborates energy-saving techniques that benefit GENERIC. These techniques can also be applied to other HDC accelerators.\n\n\nid Memory Compression:\n\nThe memory naturally needs 1K\u00d74K=512 KB (for up to to 1K features per input, and D \u210e =4K dimensions) which occupies a large area and consumes huge power. However, GENERIC generates s on-the-fly using a seed vector, where th is generated by permuting the seed by indexes. Therefore, the memory shrinks to 4 Kbit, i.e., 1024\u00d7 reduction. Permutation preserves the orthogonality. It is implemented by the tmp register in Figure 4 \u2022 2 , by which, for a new window, the reg id is right-shifted and one bit of tmp is shifted in. The tmp register helps to avoid frequent access to the memory by reading (16) bits at once and feeding in the next cycles.\n\n\nApplication-opportunistic Power Gating:\n\nFor an application with classes and using D \u210e dimensions, GENERIC stripes the dimensions 1 to (16) of its 1 st class vector in the 1 st row of class memories, the 2 nd class vector in the 2 nd row, and so on (see Figure 4). The next dimensions of the 1 st class vector are therefore written into + 1 th row, followed by the other classes. Thus, GENERIC always uses the first \u00d7D \u210e 32\u00d74K portion of class memories. The applications of Section 3.2, on average, fill 28% of the class memories (minimum 6% for EEG/FACE, and maximum 81% for ISO-LET) using D \u210e =4K dimensions. Accordingly, GENERIC partitions each class memory into four banks and power gates the unused banks. With four banks, 1.6 out of four banks are activated on average, leading to 59% power saving. With more fine-grained eight banks, 2.7 banks (out of eight) become active, saving 66% power. However, eight banks impose 55% area overhead compared to 20% of four banks (see Section 5.1 for setup). We concluded that the fourbank configuration yields the minimum area\u00d7power cost. Since the power gating is static (permanent) for an application, no wake-up latency or energy is involved.\n\n\nOn-demand Dimension Reduction:\n\nGENERIC can trade the energy consumption and performance with accuracy. Recall that GENERIC generates dimensions of the encoding per iteration over the features. By feeding a new D \u210e value as input, GENERIC can seamlessly use the new dimension count by updating the counter exit condition, so smaller hypervectors of the encoding and class hypervectors will be used. Nevertheless, GENERIC stores the squared L2 norms of the whole classes for similarity metric ( =\n(H\u00b7 C ) 2 C 2 2 )\nwhile for arbitrary reduced encoding dimensions, only the corresponding elements (and their L2 norms) of the classes are needed. As Figure 5 shows, using the old (Constant) L2 values causes significant accuracy loss compared to using the recomputed (Updated) L2 norm of sub-hypervectors. The difference is up to 20.1% for EEG and 8.5% for ISOLET. To address this issue, when calculating the squared L2 norms during the training, GENERIC stores the L2 norms of every 128 th -dimension sub-class in a different row of the norm2 memory \u2022 8 .Thus, dimensions can be reduced with a granularity of 128 while keeping the norm2 memory small (2 KB for 32 classes).\n\n\n4.3.4\n\nVoltage Over-scaling: GENERIC has to use 16-bit class dimensions to support training. As a result, the large class memories consume \u223c80% of the total power. HDC exhibits notable tolerance to the bit-flip of vectors [19], which can be leveraged to over-scale the memory voltage without performance loss. Figure 6 shows the accuracy of select benchmarks (ISOLET and FACE) with respect to the class memory error. The static (s) and dynamic (dyn) power saving as a result of corresponding voltage scaling (without reducing clock cycle) is also shown in the right axis (based on the measured data of [20]). The figure shows the result of the HDC models with different bit-width ( input parameter of GENERIC)\n\nof classes by loading a quantized HDC model (the mask unit \u2022 5 in the architecture masks out the unused bits). As it can be seen, error tolerance not only depends on application but also on the bit-width.\n\n1-bit FACE model shows a high degree of error tolerance (hence, power saving) by up to 7% bit-flip error rate, while ISOLET provides acceptable accuracy by up to 4% bit-flip using a 4-bit model. Quantized elements also reduce the dynamic power of dot-product. Voltage over-scaling also depends on the application's sensitivity to dimension reduction and its workload. For instance, FACE has a higher tolerance to voltage scaling than dimension reduction (see Figure 5). On the other hand, ISOLET is more sensitive to voltage reduction but achieves good accuracy down to 1K dimensions ( Figure  5), which means 4\u00d7 energy reduction compared to 4K dimensions. Thus, voltage over-scaling for ISOLET is only preferred in workloads with a higher idle time where the static power dominates (voltage scaling reduces the static power more significantly).\n\n\nResults\n\n\nSetup\n\nWe implemented GENERIC at the RTL level in SystemVerilog and verified the functionality in Modelsim. We used Synopsys Design Compiler to synthesize GENERIC targeting 500 MHz clock with 14 nm Standard Cell Library of GlobalFoundries. We used Artisan memory compiler to generate the SRAM memories. The level memory has a total size of 64\u00d74K = 32KB for 64 bins, the feature memory is 1024\u00d78b, and class memories are 8K\u00d716b (16 KB each). We obtained the power consumption using Synopsys Power Compiler. GENERIC occupies an area of 0.30 mm 2 and consumes a worst-case static power of 0.25 mW when all memory banks are active. For datasets of Section 3.2, GENERIC consumes a static and dynamic power of 0.09 mW, and 1.79 mW, respectively (without voltage scaling). Figure 7 shows the area and power breakdown. Note that the level memory contributes to less than 10% of area and power. Hence, using more levels does not considerably affect the area or power.\n\n\nClassification Evaluation\n\n\nTraining:\n\nSince previous HDC ASICs have not reported training energy and performance, we compare the per-input energy and execution time of GENERIC training with RF (random forest, most efficient baseline) and SVM (most accurate conventional ML) on CPU, and DNN and HDC on eGPU. Figure 8 shows the average energy and execution time for the datasets of Section 3.2. GENERIC improves the energy consumption by 528\u00d7 over RF, 1257\u00d7 over DNN, and 694\u00d7 over HDC on eGPU (which, as discussed in Section 3.3, is the most efficient baseline device for HDC). GENERIC consumes an average 2.06 mW of training power. It also has 11\u00d7 faster train time than DNN and 3.7\u00d7 than HDC on eGPU. RF has 12\u00d7 smaller train time than GENERIC, but as we mentioned, the overall energy consumption of GENERIC is significantly (528\u00d7) smaller than RF. Also, we used constant 20 epochs for GENERIC training while the accuracy of most datasets saturates after a few epochs.\n\n\nInference:\n\nWe compare the energy consumption of GENERIC inference with previous HDC platforms from Datta et al. [10], and tiny-HD [8]. We scale their report numbers to 14 nm according to [21] for a fair comparison. We also include the RF (most efficient ML), SVM (most-accurate ML) and DNN on HDC on eGPU (mostefficient HDC baseline). Figure 9 compares the energy consumption  of GENERIC and aforementioned baselines. Since GENERIC achieves significantly higher accuracy than previous work (e.g., 10.3% over [10]), GENERIC\u2212LP applies the low-power techniques of Section 4.3 to leverage this accuracy benefit. GENERIC\u2212LP improves the baseline GENERIC energy by 15.5\u00d7 through dimension reduction and voltage over-scaling. GENERIC\u2212LP consumes 15.7\u00d7 and 4.1\u00d7 less energy compared to [10] and tiny-HD [8], respectively. Note that despite tiny-HD [8], GENERIC supports training which makes it to use larger memories. GENERIC is is 1593\u00d7 and 8796\u00d7 more energy-efficient than the most-efficient ML (RF) and eGPU-HDC, respectively. Table 2 compares the normalized mutual information score of the K-means and HDC for the FCPS [22] benchmarks and the Iris flower dataset. On average, K-means achieves slightly (0.031) higher score, but for datasets with more features, the proposed GENERIC can better benefit from using windows (windows become less effective in a smaller number of features). Figure 10 compares the per-input energy consumption of GENERIC with K-means clustering running on CPU and Raspberry Pi. GENERIC consumes only 0.068 J per input, which is 17,523\u00d7 and 61,400\u00d7 more efficient than K-means on Raspberry Pi and CPU. The average per-input execution time of Raspberry Pi and CPU is, respectively, 394 Sec and 248 Sec, while GENERIC achieves 9.6 Sec (41\u00d7 and 26\u00d7 faster than R-Pi and CPU, respectively).\n\n\nClustering Evaluation\n\n\nConclusion\n\nWe proposed GENERIC, a highly-efficient HDC accelerator that supports classification (inference and training) and clustering using a novel encoding technique that achieves 3.5% (6.5%) better accuracy compared to other HDC (ML) algorithms. GENERIC benefits from power-gating, voltage over-scaling, and dimension reduction for utmost energy saving. Our results showed that GENERIC improves the classification energy by 15.1\u00d7 over a previous trainable HDC accelerator, and 4.1\u00d7 over an inference-only accelerator. GENERIC HDC-based clustering consumes 17,523\u00d7 lower energy with 41\u00d7 higher performance than Raspberry Pi running K-means with similar accuracy, facilitating ultra-efficient continuous learning on edge. \n\nFigure 1 :\n1(a) HDC model training (initialization), (b) inference, and (c) retraining.\n\nFigure 2 :\n2(a) Level hypervectors, (b) permutation encoding, (c) random projection encoding, (d) proposed GENERIC encoding.\n\nFigure 3 :\n3(a) Energy consumption and (b) execution time of HDC and ML algorithms on different devices.\n\nFigure 4 :\n4Overview of GENERIC architecture.\n\nFigure 5 :\n5Accuracy with constant and updated L2 norm.\n\nFigure 6 :Figure 7 :\n67Accuracy and power reduction wrt memory error. Accuracy and power reduction wrt memory error.\n\nFigure 8 :Figure 9 :\n89Training energy and execution time. Inference energy of GENERIC vs baselines.\n\nFigure 10 :\n10GENERIC and K-means energy comparison.\n\n\n, San Francisco, CA, USA \u00a9 2022 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-9142-9/22/07. https://doi.org/10.1145/3489517.3530669\n\nTable 1 :\n1Accuracy of HDC and ML algorithms.Dataset \nHDC Algorithms \nML Algorithms \nRP \nlevel-id ngram permute GENERIC MLP SVM RF \nDNN \nCARDIO \nDNA \nEEG \nEMG \nFACE \nISOLET \nLANG \n\n2 8 \n3 \n\nMNIST \nPAGE \nPAMAP2 \nUCIHAR \n\nMean \n3 \nSTDV \n2 4 \n4 \n\n\n\nTable 2 :\n2Mutual information score of K-means and HDC.Hepta Tetra TwoDiamonds WingNut Iris \nK-means 1.0 \n0.637 1.0 \n0.774 \n0.758 \nHDC \n0.904 0.589 0.981 \n0.781 \n0.760 \n\n\nAcknowledgementsThis work was supported in part by CRISP, one of six centers in JUMP (an SRC program sponsored by DARPA), SRC Global Research Collaboration (GRC) grant, and NSF grants #1911095, #1826967, #2100237, and #2112167. We would like to thank Amin Kalantar and Onat Gungor for helping in Raspberry Pi experiments.\nTheoretical foundations of hyperdimensional computing. A Thomas, S Dasgupta, T Rosing, Journal of Artificial Intelligence Research. 72A. Thomas, S. Dasgupta, and T. Rosing, \"Theoretical foundations of hyperdimen- sional computing, \" Journal of Artificial Intelligence Research, vol. 72, pp. 215-249, 2021.\n\nClassification using hyperdimensional computing: A review. L Ge, K K Parhi, IEEE Circuits and Systems Magazine. 202L. Ge and K. K. Parhi, \"Classification using hyperdimensional computing: A review, \" IEEE Circuits and Systems Magazine, vol. 20, no. 2, pp. 30-47, 2020.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors,\" Cognitive computation, vol. 1, no. 2, pp. 139-159, 2009.\n\nDevice and technology implications of the internet of things. R Aitken, V Chandra, J Myers, B Sandhu, L Shifren, G Yeric, 2014 symposium on VLSI technology (VLSI-technology): digest of technical papers. IEEER. Aitken, V. Chandra, J. Myers, B. Sandhu, L. Shifren, and G. Yeric, \"Device and technology implications of the internet of things,\" in 2014 symposium on VLSI technology (VLSI-technology): digest of technical papers, pp. 1-4, IEEE, 2014.\n\nReliability-driven deployment in energy-harvesting sensor networks. X Yu, X Song, L Cherkasova, T \u0160 Rosing, 2020 16th International Conference on Network and Service Management (CNSM). IEEEX. Yu, X. Song, L. Cherkasova, and T. \u0160. Rosing, \"Reliability-driven deployment in energy-harvesting sensor networks, \" in 2020 16th International Conference on Network and Service Management (CNSM), pp. 1-9, IEEE, 2020.\n\nA robust and energy-efficient classifier using braininspired hyperdimensional computing. A Rahimi, P Kanerva, International Symposium on Low Power Electronics and Design. A. Rahimi, P. Kanerva, et al., \"A robust and energy-efficient classifier using brain- inspired hyperdimensional computing, \" in International Symposium on Low Power Electronics and Design, pp. 64-69, 2016.\n\nA wearable biosensing system with in-sensor adaptive machine learning for hand gesture recognition. A Moin, A Zhou, A Rahimi, A Menon, S Benatti, G Alexandrov, S Tamakloe, Nature Electronics. 41A. Moin, A. Zhou, A. Rahimi, A. Menon, S. Benatti, G. Alexandrov, S. Tamakloe, et al., \"A wearable biosensing system with in-sensor adaptive machine learning for hand gesture recognition, \" Nature Electronics, vol. 4, no. 1, pp. 54-63, 2021.\n\ntiny-hd: Ultra-efficient hyperdimensional computing engine for iot applications. B Khaleghi, H Xu, J Morris, T \u0160 Rosing, 2021 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEE2021B. Khaleghi, H. Xu, J. Morris, and T. \u0160. Rosing, \"tiny-hd: Ultra-efficient hyperdi- mensional computing engine for iot applications, \" in 2021 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 408-413, IEEE, 2021.\n\nA 5 w standard cell memory-based configurable hyperdimensional computing accelerator for always-on smart sensing. M Eggimann, A Rahimi, L Benini, arXiv:2102.02758arXiv preprintM. Eggimann, A. Rahimi, and L. Benini, \"A 5 w standard cell memory-based con- figurable hyperdimensional computing accelerator for always-on smart sensing, \" arXiv preprint arXiv:2102.02758, 2021.\n\nA programmable hyper-dimensional processor architecture for human-centric iot. S Datta, IEEE Journal on Emerging and Selected Topics in Circuits and Systems. 93S. Datta et al., \"A programmable hyper-dimensional processor architecture for human-centric iot, \" IEEE Journal on Emerging and Selected Topics in Circuits and Systems, vol. 9, no. 3, pp. 439-452, 2019.\n\nPulp-hd: Accelerating brain-inspired high-dimensional computing on a parallel ultra-low power platform. F Montagna, A Rahimi, S Benatti, D Rossi, L Benini, 55th Design Automation Conference (DAC). IEEEF. Montagna, A. Rahimi, S. Benatti, D. Rossi, and L. Benini, \"Pulp-hd: Accelerat- ing brain-inspired high-dimensional computing on a parallel ultra-low power platform, \" in 55th Design Automation Conference (DAC), pp. 1-6, IEEE, 2018.\n\nIn-memory hyperdimensional computing. G Karunaratne, M Le Gallo, G Cherubini, L Benini, Nature Electronics. G. Karunaratne, M. Le Gallo, G. Cherubini, L. Benini, et al., \"In-memory hyperdi- mensional computing, \" Nature Electronics, pp. 1-11, 2020.\n\nHdcluster: An accurate clustering using brain-inspired high-dimensional computing. M Imani, Y Kim, Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEEM. Imani, Y. Kim, et al., \"Hdcluster: An accurate clustering using brain-inspired high-dimensional computing, \" in Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. 1591-1594, IEEE, 2019.\n\nHyperembed: Tradeoffs between resources and performance in nlp tasks with hyperdimensional computing enabled embedding of n-gram statistics. P Alonso, International Joint Conference on Neural Networks. IEEE2021P. Alonso et al., \"Hyperembed: Tradeoffs between resources and performance in nlp tasks with hyperdimensional computing enabled embedding of n-gram statistics, \" in International Joint Conference on Neural Networks, IEEE, 2021.\n\nUci machine learning repository. \"Uci machine learning repository. \" https://archive.ics.uci.edu/ml/datasets/.\n\nScikit-learn: Machine learning in python. F Pedregosa, the Journal of machine Learning research. 12F. Pedregosa et al., \"Scikit-learn: Machine learning in python,\" the Journal of machine Learning research, vol. 12, pp. 2825-2830, 2011.\n\nAuto-keras: An efficient neural architecture search system. H Jin, Q Song, X Hu, 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. H. Jin, Q. Song, and X. Hu, \"Auto-keras: An efficient neural architecture search system, \" in 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 1946-1956, 2019.\n\nComputer multiplication and division using binary logarithms. J N Mitchell, IRE Transactions on Electronic Computers. 4J. N. Mitchell, \"Computer multiplication and division using binary logarithms, \" IRE Transactions on Electronic Computers, no. 4, pp. 512-517, 1962.\n\nExploring hyperdimensional associative memory. M Imani, A Rahimi, D Kong, T Rosing, International Symposium on High Performance Computer Architecture (HPCA). IEEEM. Imani, A. Rahimi, D. Kong, T. Rosing, et al., \"Exploring hyperdimensional associative memory, \" in International Symposium on High Performance Computer Architecture (HPCA), pp. 445-456, IEEE, 2017.\n\nSram voltage scaling for energy-efficient convolutional neural networks. L Yang, B Murmann, International Symposium on Quality Electronic Design (ISQED). IEEEL. Yang and B. Murmann, \"Sram voltage scaling for energy-efficient convolu- tional neural networks, \" in International Symposium on Quality Electronic Design (ISQED), pp. 7-12, IEEE, 2017.\n\nScaling equations for the accurate prediction of cmos device performance from 180 nm to 7 nm. A Stillmaker, B Baas, Integration. 58A. Stillmaker and B. Baas, \"Scaling equations for the accurate prediction of cmos device performance from 180 nm to 7 nm, \" Integration, vol. 58, pp. 74-81, 2017.\n\nClustering with som: U\u02c6* c. A Ultsch, Proceedings of the workshop on selforganizing maps. the workshop on selforganizing mapsA. Ultsch, \"Clustering with som: U\u02c6* c,\" in Proceedings of the workshop on self- organizing maps, 2005, 2005.\n", "annotations": {"author": "[{\"end\":215,\"start\":103},{\"end\":323,\"start\":216},{\"end\":412,\"start\":324},{\"end\":522,\"start\":413},{\"end\":630,\"start\":523},{\"end\":724,\"start\":631},{\"end\":816,\"start\":725},{\"end\":905,\"start\":817},{\"end\":997,\"start\":906},{\"end\":1086,\"start\":998}]", "publisher": null, "author_last_name": "[{\"end\":118,\"start\":110},{\"end\":229,\"start\":225},{\"end\":334,\"start\":332},{\"end\":426,\"start\":420},{\"end\":536,\"start\":530},{\"end\":646,\"start\":638},{\"end\":738,\"start\":734},{\"end\":827,\"start\":825},{\"end\":919,\"start\":913},{\"end\":1008,\"start\":1005}]", "author_first_name": "[{\"end\":109,\"start\":103},{\"end\":224,\"start\":216},{\"end\":331,\"start\":324},{\"end\":419,\"start\":413},{\"end\":529,\"start\":523},{\"end\":637,\"start\":631},{\"end\":733,\"start\":725},{\"end\":824,\"start\":817},{\"end\":912,\"start\":906},{\"end\":1004,\"start\":998}]", "author_affiliation": "[{\"end\":214,\"start\":139},{\"end\":322,\"start\":247},{\"end\":411,\"start\":336},{\"end\":521,\"start\":446},{\"end\":629,\"start\":554},{\"end\":723,\"start\":648},{\"end\":815,\"start\":740},{\"end\":904,\"start\":829},{\"end\":996,\"start\":921},{\"end\":1085,\"start\":1010}]", "title": "[{\"end\":84,\"start\":1},{\"end\":1170,\"start\":1087}]", "venue": "[{\"end\":1249,\"start\":1172}]", "abstract": "[{\"end\":2971,\"start\":1446}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3196,\"start\":3193},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3199,\"start\":3196},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3202,\"start\":3199},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3517,\"start\":3514},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3519,\"start\":3517},{\"end\":3945,\"start\":3924},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4949,\"start\":4946},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4957,\"start\":4954},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5092,\"start\":5089},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5100,\"start\":5097},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5260,\"start\":5256},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5403,\"start\":5399},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5516,\"start\":5512},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6987,\"start\":6984},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6996,\"start\":6992},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7827,\"start\":7824},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7885,\"start\":7881},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9989,\"start\":9986},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9991,\"start\":9989},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9994,\"start\":9991},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11750,\"start\":11746},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11861,\"start\":11857},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12029,\"start\":12025},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12195,\"start\":12191},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12685,\"start\":12682},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12688,\"start\":12685},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":18159,\"start\":18155},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23654,\"start\":23650},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24034,\"start\":24030},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27254,\"start\":27250},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27271,\"start\":27268},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":27329,\"start\":27325},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27650,\"start\":27646},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27921,\"start\":27917},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27937,\"start\":27934},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27982,\"start\":27979},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28258,\"start\":28254}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":29788,\"start\":29700},{\"attributes\":{\"id\":\"fig_1\"},\"end\":29914,\"start\":29789},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30020,\"start\":29915},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30067,\"start\":30021},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30124,\"start\":30068},{\"attributes\":{\"id\":\"fig_5\"},\"end\":30242,\"start\":30125},{\"attributes\":{\"id\":\"fig_6\"},\"end\":30344,\"start\":30243},{\"attributes\":{\"id\":\"fig_7\"},\"end\":30398,\"start\":30345},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30545,\"start\":30399},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":30791,\"start\":30546},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":30963,\"start\":30792}]", "paragraph": "[{\"end\":3520,\"start\":2987},{\"end\":4569,\"start\":3522},{\"end\":5624,\"start\":4571},{\"end\":6056,\"start\":5626},{\"end\":6223,\"start\":6058},{\"end\":6391,\"start\":6225},{\"end\":7765,\"start\":6393},{\"end\":8318,\"start\":7767},{\"end\":8889,\"start\":8331},{\"end\":9605,\"start\":8891},{\"end\":10331,\"start\":9652},{\"end\":11403,\"start\":10333},{\"end\":11628,\"start\":11443},{\"end\":13000,\"start\":11652},{\"end\":15589,\"start\":13040},{\"end\":16678,\"start\":15625},{\"end\":17488,\"start\":16738},{\"end\":18160,\"start\":17490},{\"end\":19334,\"start\":18189},{\"end\":20134,\"start\":19344},{\"end\":20388,\"start\":20155},{\"end\":21059,\"start\":20415},{\"end\":22253,\"start\":21103},{\"end\":22751,\"start\":22288},{\"end\":23425,\"start\":22770},{\"end\":24137,\"start\":23435},{\"end\":24343,\"start\":24139},{\"end\":25190,\"start\":24345},{\"end\":26161,\"start\":25210},{\"end\":27134,\"start\":26203},{\"end\":28947,\"start\":27149},{\"end\":29699,\"start\":28986}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11442,\"start\":11404},{\"attributes\":{\"id\":\"formula_1\"},\"end\":22769,\"start\":22752}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":12236,\"start\":12229},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":28168,\"start\":28161}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2985,\"start\":2973},{\"attributes\":{\"n\":\"2.2\"},\"end\":8329,\"start\":8321},{\"attributes\":{\"n\":\"3\"},\"end\":9650,\"start\":9608},{\"attributes\":{\"n\":\"3.2\"},\"end\":11650,\"start\":11631},{\"attributes\":{\"n\":\"3.3\"},\"end\":13038,\"start\":13003},{\"attributes\":{\"n\":\"4\"},\"end\":15612,\"start\":15592},{\"attributes\":{\"n\":\"4.1\"},\"end\":15623,\"start\":15615},{\"attributes\":{\"n\":\"4.2\"},\"end\":16710,\"start\":16681},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":16736,\"start\":16713},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":18187,\"start\":18163},{\"end\":19342,\"start\":19337},{\"attributes\":{\"n\":\"4.3\"},\"end\":20153,\"start\":20137},{\"attributes\":{\"n\":\"4.3.1\"},\"end\":20413,\"start\":20391},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":21101,\"start\":21062},{\"attributes\":{\"n\":\"4.3.3\"},\"end\":22286,\"start\":22256},{\"end\":23433,\"start\":23428},{\"attributes\":{\"n\":\"5\"},\"end\":25200,\"start\":25193},{\"attributes\":{\"n\":\"5.1\"},\"end\":25208,\"start\":25203},{\"attributes\":{\"n\":\"5.2\"},\"end\":26189,\"start\":26164},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":26201,\"start\":26192},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":27147,\"start\":27137},{\"attributes\":{\"n\":\"5.3\"},\"end\":28971,\"start\":28950},{\"attributes\":{\"n\":\"6\"},\"end\":28984,\"start\":28974},{\"end\":29711,\"start\":29701},{\"end\":29800,\"start\":29790},{\"end\":29926,\"start\":29916},{\"end\":30032,\"start\":30022},{\"end\":30079,\"start\":30069},{\"end\":30146,\"start\":30126},{\"end\":30264,\"start\":30244},{\"end\":30357,\"start\":30346},{\"end\":30556,\"start\":30547},{\"end\":30802,\"start\":30793}]", "table": "[{\"end\":30791,\"start\":30592},{\"end\":30963,\"start\":30848}]", "figure_caption": "[{\"end\":29788,\"start\":29713},{\"end\":29914,\"start\":29802},{\"end\":30020,\"start\":29928},{\"end\":30067,\"start\":30034},{\"end\":30124,\"start\":30081},{\"end\":30242,\"start\":30149},{\"end\":30344,\"start\":30267},{\"end\":30398,\"start\":30360},{\"end\":30545,\"start\":30401},{\"end\":30592,\"start\":30558},{\"end\":30848,\"start\":30804}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7072,\"start\":7064},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":8590,\"start\":8582},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9154,\"start\":9145},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9356,\"start\":9345},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10443,\"start\":10435},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13700,\"start\":13692},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14936,\"start\":14928},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18005,\"start\":17997},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18573,\"start\":18565},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19155,\"start\":19147},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20840,\"start\":20832},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21324,\"start\":21316},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22910,\"start\":22902},{\"end\":23746,\"start\":23738},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24812,\"start\":24804},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24940,\"start\":24931},{\"end\":25977,\"start\":25969},{\"end\":26480,\"start\":26472},{\"end\":27481,\"start\":27473},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":28529,\"start\":28520}]", "bib_author_first_name": "[{\"end\":31342,\"start\":31341},{\"end\":31352,\"start\":31351},{\"end\":31364,\"start\":31363},{\"end\":31653,\"start\":31652},{\"end\":31659,\"start\":31658},{\"end\":31661,\"start\":31660},{\"end\":31989,\"start\":31988},{\"end\":32284,\"start\":32283},{\"end\":32294,\"start\":32293},{\"end\":32305,\"start\":32304},{\"end\":32314,\"start\":32313},{\"end\":32324,\"start\":32323},{\"end\":32335,\"start\":32334},{\"end\":32737,\"start\":32736},{\"end\":32743,\"start\":32742},{\"end\":32751,\"start\":32750},{\"end\":32765,\"start\":32764},{\"end\":32767,\"start\":32766},{\"end\":33169,\"start\":33168},{\"end\":33179,\"start\":33178},{\"end\":33558,\"start\":33557},{\"end\":33566,\"start\":33565},{\"end\":33574,\"start\":33573},{\"end\":33584,\"start\":33583},{\"end\":33593,\"start\":33592},{\"end\":33604,\"start\":33603},{\"end\":33618,\"start\":33617},{\"end\":33976,\"start\":33975},{\"end\":33988,\"start\":33987},{\"end\":33994,\"start\":33993},{\"end\":34004,\"start\":34003},{\"end\":34006,\"start\":34005},{\"end\":34448,\"start\":34447},{\"end\":34460,\"start\":34459},{\"end\":34470,\"start\":34469},{\"end\":34787,\"start\":34786},{\"end\":35176,\"start\":35175},{\"end\":35188,\"start\":35187},{\"end\":35198,\"start\":35197},{\"end\":35209,\"start\":35208},{\"end\":35218,\"start\":35217},{\"end\":35547,\"start\":35546},{\"end\":35562,\"start\":35561},{\"end\":35565,\"start\":35563},{\"end\":35574,\"start\":35573},{\"end\":35587,\"start\":35586},{\"end\":35842,\"start\":35841},{\"end\":35851,\"start\":35850},{\"end\":36282,\"start\":36281},{\"end\":36734,\"start\":36733},{\"end\":36989,\"start\":36988},{\"end\":36996,\"start\":36995},{\"end\":37004,\"start\":37003},{\"end\":37346,\"start\":37345},{\"end\":37348,\"start\":37347},{\"end\":37600,\"start\":37599},{\"end\":37609,\"start\":37608},{\"end\":37619,\"start\":37618},{\"end\":37627,\"start\":37626},{\"end\":37990,\"start\":37989},{\"end\":37998,\"start\":37997},{\"end\":38359,\"start\":38358},{\"end\":38373,\"start\":38372},{\"end\":38588,\"start\":38587}]", "bib_author_last_name": "[{\"end\":31349,\"start\":31343},{\"end\":31361,\"start\":31353},{\"end\":31371,\"start\":31365},{\"end\":31656,\"start\":31654},{\"end\":31667,\"start\":31662},{\"end\":31997,\"start\":31990},{\"end\":32291,\"start\":32285},{\"end\":32302,\"start\":32295},{\"end\":32311,\"start\":32306},{\"end\":32321,\"start\":32315},{\"end\":32332,\"start\":32325},{\"end\":32341,\"start\":32336},{\"end\":32740,\"start\":32738},{\"end\":32748,\"start\":32744},{\"end\":32762,\"start\":32752},{\"end\":32774,\"start\":32768},{\"end\":33176,\"start\":33170},{\"end\":33187,\"start\":33180},{\"end\":33563,\"start\":33559},{\"end\":33571,\"start\":33567},{\"end\":33581,\"start\":33575},{\"end\":33590,\"start\":33585},{\"end\":33601,\"start\":33594},{\"end\":33615,\"start\":33605},{\"end\":33627,\"start\":33619},{\"end\":33985,\"start\":33977},{\"end\":33991,\"start\":33989},{\"end\":34001,\"start\":33995},{\"end\":34013,\"start\":34007},{\"end\":34457,\"start\":34449},{\"end\":34467,\"start\":34461},{\"end\":34477,\"start\":34471},{\"end\":34793,\"start\":34788},{\"end\":35185,\"start\":35177},{\"end\":35195,\"start\":35189},{\"end\":35206,\"start\":35199},{\"end\":35215,\"start\":35210},{\"end\":35225,\"start\":35219},{\"end\":35559,\"start\":35548},{\"end\":35571,\"start\":35566},{\"end\":35584,\"start\":35575},{\"end\":35594,\"start\":35588},{\"end\":35848,\"start\":35843},{\"end\":35855,\"start\":35852},{\"end\":36289,\"start\":36283},{\"end\":36744,\"start\":36735},{\"end\":36993,\"start\":36990},{\"end\":37001,\"start\":36997},{\"end\":37007,\"start\":37005},{\"end\":37357,\"start\":37349},{\"end\":37606,\"start\":37601},{\"end\":37616,\"start\":37610},{\"end\":37624,\"start\":37620},{\"end\":37634,\"start\":37628},{\"end\":37995,\"start\":37991},{\"end\":38006,\"start\":37999},{\"end\":38370,\"start\":38360},{\"end\":38378,\"start\":38374},{\"end\":38595,\"start\":38589}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":222378549},\"end\":31591,\"start\":31286},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":216080530},\"end\":31861,\"start\":31593},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":733980},\"end\":32219,\"start\":31863},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":25902720},\"end\":32666,\"start\":32221},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":222304313},\"end\":33077,\"start\":32668},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":9812826},\"end\":33455,\"start\":33079},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":231705788},\"end\":33892,\"start\":33457},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":236150314},\"end\":34331,\"start\":33894},{\"attributes\":{\"doi\":\"arXiv:2102.02758\",\"id\":\"b8\"},\"end\":34705,\"start\":34333},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":201900134},\"end\":35069,\"start\":34707},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":49291228},\"end\":35506,\"start\":35071},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":174797921},\"end\":35756,\"start\":35508},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":155106744},\"end\":36138,\"start\":35758},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":211990327},\"end\":36577,\"start\":36140},{\"attributes\":{\"id\":\"b14\"},\"end\":36689,\"start\":36579},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":10659969},\"end\":36926,\"start\":36691},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":85517610},\"end\":37281,\"start\":36928},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":27294397},\"end\":37550,\"start\":37283},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":1677864},\"end\":37914,\"start\":37552},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":23804502},\"end\":38262,\"start\":37916},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":205666078},\"end\":38557,\"start\":38264},{\"attributes\":{\"id\":\"b21\"},\"end\":38793,\"start\":38559}]", "bib_title": "[{\"end\":31339,\"start\":31286},{\"end\":31650,\"start\":31593},{\"end\":31986,\"start\":31863},{\"end\":32281,\"start\":32221},{\"end\":32734,\"start\":32668},{\"end\":33166,\"start\":33079},{\"end\":33555,\"start\":33457},{\"end\":33973,\"start\":33894},{\"end\":34784,\"start\":34707},{\"end\":35173,\"start\":35071},{\"end\":35544,\"start\":35508},{\"end\":35839,\"start\":35758},{\"end\":36279,\"start\":36140},{\"end\":36731,\"start\":36691},{\"end\":36986,\"start\":36928},{\"end\":37343,\"start\":37283},{\"end\":37597,\"start\":37552},{\"end\":37987,\"start\":37916},{\"end\":38356,\"start\":38264},{\"end\":38585,\"start\":38559}]", "bib_author": "[{\"end\":31351,\"start\":31341},{\"end\":31363,\"start\":31351},{\"end\":31373,\"start\":31363},{\"end\":31658,\"start\":31652},{\"end\":31669,\"start\":31658},{\"end\":31999,\"start\":31988},{\"end\":32293,\"start\":32283},{\"end\":32304,\"start\":32293},{\"end\":32313,\"start\":32304},{\"end\":32323,\"start\":32313},{\"end\":32334,\"start\":32323},{\"end\":32343,\"start\":32334},{\"end\":32742,\"start\":32736},{\"end\":32750,\"start\":32742},{\"end\":32764,\"start\":32750},{\"end\":32776,\"start\":32764},{\"end\":33178,\"start\":33168},{\"end\":33189,\"start\":33178},{\"end\":33565,\"start\":33557},{\"end\":33573,\"start\":33565},{\"end\":33583,\"start\":33573},{\"end\":33592,\"start\":33583},{\"end\":33603,\"start\":33592},{\"end\":33617,\"start\":33603},{\"end\":33629,\"start\":33617},{\"end\":33987,\"start\":33975},{\"end\":33993,\"start\":33987},{\"end\":34003,\"start\":33993},{\"end\":34015,\"start\":34003},{\"end\":34459,\"start\":34447},{\"end\":34469,\"start\":34459},{\"end\":34479,\"start\":34469},{\"end\":34795,\"start\":34786},{\"end\":35187,\"start\":35175},{\"end\":35197,\"start\":35187},{\"end\":35208,\"start\":35197},{\"end\":35217,\"start\":35208},{\"end\":35227,\"start\":35217},{\"end\":35561,\"start\":35546},{\"end\":35573,\"start\":35561},{\"end\":35586,\"start\":35573},{\"end\":35596,\"start\":35586},{\"end\":35850,\"start\":35841},{\"end\":35857,\"start\":35850},{\"end\":36291,\"start\":36281},{\"end\":36746,\"start\":36733},{\"end\":36995,\"start\":36988},{\"end\":37003,\"start\":36995},{\"end\":37009,\"start\":37003},{\"end\":37359,\"start\":37345},{\"end\":37608,\"start\":37599},{\"end\":37618,\"start\":37608},{\"end\":37626,\"start\":37618},{\"end\":37636,\"start\":37626},{\"end\":37997,\"start\":37989},{\"end\":38008,\"start\":37997},{\"end\":38372,\"start\":38358},{\"end\":38380,\"start\":38372},{\"end\":38597,\"start\":38587}]", "bib_venue": "[{\"end\":31416,\"start\":31373},{\"end\":31703,\"start\":31669},{\"end\":32020,\"start\":31999},{\"end\":32422,\"start\":32343},{\"end\":32851,\"start\":32776},{\"end\":33248,\"start\":33189},{\"end\":33647,\"start\":33629},{\"end\":34086,\"start\":34015},{\"end\":34445,\"start\":34333},{\"end\":34863,\"start\":34795},{\"end\":35266,\"start\":35227},{\"end\":35614,\"start\":35596},{\"end\":35923,\"start\":35857},{\"end\":36340,\"start\":36291},{\"end\":36610,\"start\":36579},{\"end\":36786,\"start\":36746},{\"end\":37086,\"start\":37009},{\"end\":37399,\"start\":37359},{\"end\":37708,\"start\":37636},{\"end\":38068,\"start\":38008},{\"end\":38391,\"start\":38380},{\"end\":38647,\"start\":38597},{\"end\":38684,\"start\":38649}]"}}}, "year": 2023, "month": 12, "day": 17}