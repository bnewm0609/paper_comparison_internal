{"id": 233289667, "updated": "2023-10-06 04:39:15.483", "metadata": {"title": "Quantum Architecture Search via Deep Reinforcement Learning", "authors": "[{\"first\":\"En-Jui\",\"last\":\"Kuo\",\"middle\":[]},{\"first\":\"Yao-Lung\",\"last\":\"Fang\",\"middle\":[\"L.\"]},{\"first\":\"Samuel\",\"last\":\"Chen\",\"middle\":[\"Yen-Chi\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": 4, "day": 15}, "abstract": "Recent advances in quantum computing have drawn considerable attention to building realistic application for and using quantum computers. However, designing a suitable quantum circuit architecture requires expert knowledge. For example, it is non-trivial to design a quantum gate sequence for generating a particular quantum state with as fewer gates as possible. We propose a quantum architecture search framework with the power of deep reinforcement learning (DRL) to address this challenge. In the proposed framework, the DRL agent can only access the Pauli-$X$, $Y$, $Z$ expectation values and a predefined set of quantum operations for learning the target quantum state, and is optimized by the advantage actor-critic (A2C) and proximal policy optimization (PPO) algorithms. We demonstrate a successful generation of quantum gate sequences for multi-qubit GHZ states without encoding any knowledge of quantum physics in the agent. The design of our framework is rather general and can be employed with other DRL architectures or optimization methods to study gate synthesis and compilation for many quantum states.", "fields_of_study": "[\"Physics\",\"Computer Science\"]", "external_ids": {"arxiv": "2104.07715", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2104-07715", "doi": null}}, "content": {"source": {"pdf_hash": "4817ccfe1f4059c37a919ee30d49ae3eae95bd73", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2104.07715v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "ede325c98edcb577b06c400c2228107ee079bd4c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4817ccfe1f4059c37a919ee30d49ae3eae95bd73.txt", "contents": "\nQuantum Architecture Search via Deep Reinforcement Learning\n\n\nEn-Jui Kuo \nDepartment of Physics\nUniversity of Maryland\n20742College ParkMDUSA\n\nJoint Quantum Institute\nNIST/University of Maryland\n20742College ParkMDUSA\n\nYao-Lung L Fang \nComputational Science Initiative\nBrookhaven National Laboratory\nUpton11973NYUSA\n\nSamuel \nYen-Chi Chen \nComputational Science Initiative\nBrookhaven National Laboratory\nUpton11973NYUSA\n\nQuantum Architecture Search via Deep Reinforcement Learning\n(Dated: April 19, 2021)BNL-UMD\nRecent advances in quantum computing have drawn considerable attention to building realistic application for and using quantum computers. However, designing a suitable quantum circuit architecture requires expert knowledge. For example, it is non-trivial to design a quantum gate sequence for generating a particular quantum state with as fewer gates as possible. We propose a quantum architecture search framework with the power of deep reinforcement learning (DRL) to address this challenge. In the proposed framework, the DRL agent can only access the Pauli-X, Y ,Z expectation values and a predefined set of quantum operations for learning the target quantum state, and is optimized by the advantage actor-critic (A2C) and proximal policy optimization (PPO) algorithms. We demonstrate a successful generation of quantum gate sequences for multiqubit GHZ states without encoding any knowledge of quantum physics in the agent. The design of our framework is rather general and can be employed with other DRL architectures or optimization methods to study gate synthesis and compilation for many quantum states. * kuoenjui@umd.edu \u2020 leofang@bnl.gov \u2021 ychen@bnl.gov arXiv:2104.07715v1 [quant-ph] 15 Apr 2021 Define the maximum steps in a single episode S Define the update timestep U Define the update epoch number K Define the epsilon clip C Initialise trajectory buffer T Initialise timestep counter t Initialize two sets of model parameters \u03b8 and \u03b8 old for episode = 1, 2, . . . , M do Reset the testing environment and initialise state s 1 for step = 1, 2, . . . , S do Update the timestep t = t + 1Select the action a t from the policy \u03c0 (a t | s t ; \u03b8 old ) Execute action a t in emulator and observe reward r t and next state s t+1Record the transition (s t , a t , log \u03c0 (a t | s t ; \u03b8 old ) , r t ) in T if t = U then Calculate the discounted rewards R t for each state s t in the trajectory buffer T for k = 1, 2, . . . , K do Calculate the log probability log \u03c0 (a t | s t ; \u03b8), state values V (s t , \u03b8) and entropy H t .Calculate the ratio q t = exp (log \u03c0 (a t | s t ; \u03b8) \u2212 log \u03c0 (a t | s t ; \u03b8 old )) Calculate the advantage A t = R t \u2212 V (s t , \u03b8)Update the agent policy parameters \u03b8 with gradient descent on the loss L end forUpdate the \u03b8 old to \u03b8 Reset the trajectory buffer T Reset the timestep counter t = 0 end if end for end for\n\nI. INTRODUCTION\n\nRecently, reinforcement learning (RL) [1] has found tremendous success and demonstrated a human-or superhuman-level of capabilities in a wide range of tasks, such as mastering video games [2][3][4][5] and even the game of Go [6,7]. With such success, it is natural to consider applying such techniques to scientific areas that require sophisticated control capabilities.\n\nIndeed, RL has been used to study quantum control [8][9][10][11][12][13][14], quantum error correction [15][16][17][18][19] and the optimization of variational quantum algorithms [20][21][22][23].\n\nRL has also been applied to automatically building a deep learning architecture for a given task. This is the so-called neural architecture search [24] and has been proven possible in a wide variety of machine learning (ML) tasks [25][26][27][28][29][30][31]. The core idea is to train an RL agent to sequentially put in different deep learning components (e.g., convolutional operations, residual connections, pooling and so on) and then evaluate the model performance. Although the concept is simple, several recent studies have reported reaching a state-of-the-art performance [32] and beating the best human-crafted DL models.\n\nQuantum computing has promised exponential speedups for several hard computational problems otherwise intractable on a classical computer [33,34], such as factorizing large integers [35] and unstructured database search [36]. Recent studies in variational quantum algorithms (VQA) have applied quantum computing to many scientific domains, including molecular dynamical studies [37], quantum optimization [38,39] and various quantum machine learning (QML) applications such as regression [40][41][42], classification [41,[43][44][45][46][47][48][49][50][51][52][53][54][55][56][57], generative modeling [58][59][60][61][62], deep reinforcement learning [63][64][65][66][67][68][69], sequence modeling [40,70,71], speech recognition [72], metric and embedding learning [73,74], transfer learning [47] and federated learning [75]. However, designing a quantum circuit to solve a specific task is non-trivial, as it demands domain knowledge and sometimes extraordinary insights.\n\nIn this study, we investigate the potential of training an RL agent to search for a quantum circuit architecture for generating a desired quantum state. In this work, we present a new quantum architecture search framework powered by deep reinforcement learning (DRL). As shown in Figure1, the proposed framework includes an RL agent interacting with a quantum computer or quantum simulator. The RL agent will sequentially generate an output action, which is a candidate of the quantum gate or operation placed on the circuit. The built circuit is evaluated against certain metrics, such as the fidelity, to check if it actually reaches the goal. The reward is calculated based on the fidelity and sent back to the RL agent. The procedure is carried out iteratively to train the RL agent.\n\nOur contributions are the following:\n\n\u2022 Provide a framework for the study of quantum architecture search.\n\n\u2022 Demonstrate building a quantum circuit step-by-step via deep reinforcement learning without any knowledge in physics.\n\nThe paper is organized as follows. In Section II, we introduce the RL background knowledge used in this work. In Section III we introduce the quantum architectures that our agent will search. In Section IV, we describe the experimental procedures and results in details.\n\nFinally we discuss the results in Section V and conclude in Section VI. proposed quantum architecture search framework consists of two major components. First is a quantum computer or quantum simulator. In this work, we use a quantum simulator with and without noise. Second is an RL agent interacting with the quantum computer. In each time step, the RL agent will generate an action for the quantum computer. The action specifies a quantum operation to be added to the system. Then the fidelity of the quantum circuit is evaluated to determine the reward to be sent back to the agent. In addition, Pauli-X, Y and Z expectation values are also fed back to the agent. The RL agent will then be updated based on these information.\n\n\nDeep RL for AutoQuantum\n\n\nII. REINFORCEMENT LEARNING\n\nReinforcement learning (RL) is a machine learning paradigm in which an agent learns how to make decisions via interacting with the environments [1]. Concretely speaking, the agent interacts with an environment E over a number of discrete time steps. At each time step t, the agent receives a state or observation s t from the environment E and then chooses an action a t from a set of possible actions A according to its policy \u03c0. The policy \u03c0 is a function which maps the state or observation s t to action a t . In general, the policy can be stochastic, meaning that given a state s, the action output can be a probability distribution \u03c0(a t |s t ) conditioned on s t . After executing the action a t , the agent receives the state of the next time step s t+1 and a scalar reward r t . The process continues until the agent reaches the terminal state or a pre-defined stopping criteria (e.g. the maximum steps allowed). An episode is defined as an agent starting from a randomly selected initial state and following the aforementioned process all the way through the terminal state or reaching a stopping criteria.\n\nWe define the total discounted return from time step t as R t = T t =t \u03b3 t \u2212t r t , where \u03b3 is the discount factor that lies in (0, 1]. In principle, \u03b3 is provided by the investigator to control how future rewards are weighted to the decision making function. When a large \u03b3 is considered, the agent weighs the future reward more heavily. On the other hand, with a small \u03b3, future rewards are quickly ignored and immediate reward will be weighted more.\n\nThe goal of the agent is to maximize the expected return from each state s t in the training process. The action-value function or Q-value function Q \u03c0 (s, a) = E[R t |s t = s, a] is the expected return for selecting an action a in state s based on policy \u03c0. The optimal action value function Q * (s, a) = max \u03c0 Q \u03c0 (s, a) gives a maximal action-value across all possible policies. The value of state s under policy \u03c0, V \u03c0 (s) = E [R t |s t = s], is the agent's expected return by following policy \u03c0 from the state s. Various RL algorithms are designed to find the policy which can maximize the value function. The RL algorithms which maximize the value function are called value-based RL.\n\n\nA. Policy Gradient\n\nIn contrast to the value-based RL, which learns the value function and use it as the reference to generate the decision on each time-step, there is another kind of RL method called policy gradient. In this method, the policy function \u03c0(a|s; \u03b8) is parameterized with the parameters \u03b8. The \u03b8 will then be subject to the optimization procedure which is gradient ascent on the expected total return E[R t ]. One of the classic examples of policy gradient algorithm is the REINFORCE algorithm [76]. In the standard REINFORCE algorithm, the parameters \u03b8 are updated along the direction \u2207 \u03b8 log \u03c0 (a t |s t ; \u03b8) R t , which is the unbiased\nestimate of \u2207 \u03b8 E [R t ].\nHowever, the policy gradient method suffers from large variance of the \u2207 \u03b8 E [R t ], making the training very hard. To reduce the variance of this estimate and keep it unbiased, one can subtract a learned function of the state b t (s t ), which is known as the baseline, from the return. The result is therefore \u2207 \u03b8 log \u03c0 (a t |s t ; \u03b8) (R t \u2212 b t (s t )).\n\n\nB. Advantage Actor-Critic (A2C)\n\nA learned estimate of the value function is a common choice for the baseline b t (s t ) \u2248 V \u03c0 (s t ). This choice usually leads to a much lower variance estimate of the policy gradient.\n\nWhen one uses the approximate value function as the baseline, the quantity R t \u2212 b t = Q(s t , a t ) \u2212 V (s t ) can be seen as the advantage A(s t , a t ) of the action a t at the state s t .\n\nIntuitively, one can see this advantage as \"how good or bad the action a t compared to the average value at this state V (s t ).\" For example, if the Q(s t , a t ) equals to 10 at a given time-step t, it is not clear whether a t is a good action or not. However, if we also know that the V (s t ) equals to, say 2 here, then we can imply that a t may not be bad. Conversely, if the V (s t ) equals to 15, then the advantage is 10 \u2212 15 = \u22125, meaning that the Q value for this action a t is well below the average V (s t ) and therefore that action is not good. This approach is called advantage actor-critic (A2C) method where the policy \u03c0 is the actor and the baseline which is the value function V is the critic [1].\n\n\nC. Proximal Policy Optimization (PPO)\n\nIn the policy gradients method, we optimize the policy according to the policy loss L policy (\u03b8) = E t [\u2212 log \u03c0 (a t | st; \u03b8)] via gradient descent. However, the training itself may suf-fer from instabilities. If the step size of policy update is too small, the training process would be too slow. On the other hand, if the step size is too high, there will be a high variance in the training. The proximal policy optimization (PPO) [77] fixes this problem by limiting the policy update step size at each training step. The PPO introduces the loss function called clipped surrogate loss function that will constraint the policy change a a small range with the help of a clip. Consider the ratio between the probability of action a t under current policy and the probability under previous policy q t (\u03b8) = \u03c0(at|st;\u03b8) \u03c0(at|st;\u03b8 old ) . If q t (\u03b8) > 1, it means the action a t is with higher probability in the current policy than in the old one. And if 0 < q t (\u03b8) < 1, it means that the action a t is less probable in the current policy than in the old one. Our new loss function can then be defined as\nL policy (\u03b8) = E t [q t (\u03b8)A t ] = E t [ \u03c0(at|st;\u03b8) \u03c0(at|st;\u03b8 old ) A t ], where A t = R t \u2212 V (s t ; \u03b8)\nis the advantage function. However, if the action under current policy is much more probable than in the previous policy, the ratio q t may be large, leading to a large policy update step. To circumvent this problem, the original PPO algorithm [77] adds a constraint on the ratio, which can only be in the range 0.8 to 1.2. The modified loss function is\nnow L policy (\u03b8) = E t [\u2212min(q t A t , clip(q t , 1\u2212C, 1+C)A t )]\nwhere the C is the clip hyperparameter (common choice is 0.2). Finally, the value loss and entropy bonus are added into the total loss function as usual:\nL(\u03b8) = L policy + c 1 L value \u2212 c 2 H where L value = E t [ R t \u2212 V (s t ; \u03b8) 2 ] is the value loss and H = E t [H t ] = E t [\u2212 j \u03c0 (a j | s t ; \u03b8) log(\u03c0 (a j | s t ; \u03b8))]\nis the entropy bonus which is to encourage exploration.\n\n\nIII. PROBLEM SETUP\n\nBelow we describe in detail the problem we aim to solve using DRL. Given an initial state |0 \u00b7 \u00b7 \u00b7 0 and the target state, the goal is to produce a quantum circuit which transforms the initial state to the target state within certain error tolerance. We use the Pauli measurements as observations, a natural choice in quantum mechanics. We then use various RL algorithms to achieve our goal. The overall scheme is shown in Figure 1. Specifically, the environment E is the quantum computer or quantum simulator. In this work, we use a quantum simulator since currently it is not yet practical to train tens of thousands of episodes on a cloudbased quantum device. The RL agent, hosted on a classical computer, interacts with the environment E. In each time step, the RL agent chooses an action a from the possible set of actions A, which consists of different quantum operations (one-and two-qubit gates).\n\nAfter the RL agent updates the quantum circuit with the chosen action, the environment E executes the new circuit and calculates the fidelity to the given target state. If the fidelity reaches a pre-defined threshold, the episode ends and a large positive reward is given to the RL agent. Otherwise, the RL agent receives a small negative reward. The states or observations which the environment E returns to the RL agent are Pauli measurements on each qubit, so for an n-qubit system the dimension of the observations is 3n. The procedure continues until the agent reaches either the desired threshold or the maximum allowed steps.\n\nRL algorithms like A2C and PPO are employed to optimize the agent. Next, we discuss in detail the mathematical setting of our problem.\n\n\nA. Mathematical formulation of the problem\n\nSuppose we are given the number of qubits n \u2208 N, the initial quantum state |0 \u2297 n , the target state |\u03c8 , the tolerance error \u2265 0, and a set of gates G. Our goal is to find a quantum circuit C : |0 \u2297 n \u2192 |\u03c8 so that our DRL architecture serves as a function F:\nF : (|0 \u2297 n , |\u03c8 , , G) \u2192 C(1)\nsuch that 1 \u2265 D(|\u03c8 , C(|0 \u2297 n )) \u2265 1 \u2212 , where C is composed of gates g \u2208 G and D is a distance metric between two quantum states (larger is better). In this paper, we use the fidelity [78] to be our distance D. Given two density operators \u03c1 and \u03c3 (see also Sec. IV A 3), the fidelity is generally defined as the quantity F (\u03c1, \u03c3) = tr \u221a \u03c1\u03c3 \u221a \u03c1 2 . In the special case where \u03c1 and \u03c3 represent pure quantum states, namely, \u03c1 = |\u03c8 \u03c1 \u03c8 \u03c1 | and \u03c3 = |\u03c8 \u03c3 \u03c8 \u03c3 |, the definition becomes the inner product of two states: F (\u03c1, \u03c3) = | \u03c8 \u03c1 |\u03c8 \u03c3 | 2 .\n\n\nB. Multi-qubit entangled states as target\n\nTo validate that the proposed DRL pipeline can be applied to quantum architecture search, it is best to check if multi-qubit entanglement can be generated as expected. To this end, we target the generation of two kinds of quantum states: Bell state and Greenberger-Horne-Zeilinger (GHZ) state.\n\nA Bell state reaches maximal two-qubit entanglement,\n|Bell = |0 \u22972 + |1 \u22972 \u221a 2 = |00 + |11 \u221a 2 .(2)\nTo generate a Bell state, we pick the observation to be the expectation values of Pauli\nmatrices on each qubits { \u03c3 i j | i \u2208 {0, 1}, j \u2208 {x, y, z}}. The action set G is G = n i=1 U i (\u03c0/4) , X i , Y i , Z i , H i , CN OT i,(i+1)(mod2) ,(3)\nwhere n = 2 (for two qubits),\nU i (\u03b8) = 1 0 0 exp(i\u03b8)\nis the single qubit rotation about the Z-axis applied to qubit i, X i \u2261 \u03c3 i x is the Pauli-X gate and likewise for Y i and Z i , H i is the Hadamard gate, and CN OT i,j is the CNOT gate with the i-th qubit as control and j-th qubit as target, so we have 12 actions in total. A textbook example for creating a Bell state is shown in Fig. 2. A GHZ state is a multi-qubit generalization of the Bell state, in which an equal superposition between the lowest and the highest energy states is created. For 3 qubits it is given by\n|GHZ = |0 \u22973 + |1 \u22973 \u221a 2 = |000 + |111 \u221a 2(4)\nTo generate the 3-qubit GHZ state, we again use the expectation values of individual qubit's Pauli matrices, leading to 9 observables in total. For the actions, we pick the same singlequbit gates as in Eq. (3), and six CN OT gates as two-qubit gates, so total we have 21\n\nactions. In this fashion, for general n-qubit cases there will be 5n + n(n \u2212 1) = \u2126(n 2 ) actions, increasing only quadratically instead of exponentially in n. An example for creating a 3-qubit GHZ state is shown in Fig. 3. \n\n\nIV. EXPERIMENTS AND RESULTS\n\nA. Experimental Settings\n\n\nOptimizer\n\nWe apply the gradient-descent method to optimize the RL policy. There are a wide variety of gradient-descent methods which are demonstrated highly successful [79][80][81]. In this work,\n\nwe use the Adam [81] optimizer for training the RL agent in both the A2C and PPO cases.\n\nAdam is one of the gradient-descent methods which computes the adaptive learning rates for each parameter. In addition, Adam stores both the exponentially decaying average of gradients g t and its square g 2 t ,\nm t = \u03b2 1 m t\u22121 + (1 \u2212 \u03b2 1 ) g t (5a) v t = \u03b2 2 v t\u22121 + (1 \u2212 \u03b2 2 ) g 2 t (5b)\nwhere \u03b2 1 and \u03b2 2 are hyperparameters. We use \u03b2 1 = 0.9 and \u03b2 2 = 0.999 in this work. The m t and v t are adjusted according to the following formula to counteract the biases towards\n0,m t = m t 1 \u2212 \u03b2 t 1 (6a) v t = v t 1 \u2212 \u03b2 t 2 (6b)\nThe parameters \u03b8 t in the RL model in the time step t are then updated according to the following formula,\n\u03b8 t+1 = \u03b8 t \u2212 \u03b7 \u221av t + m t(7)\nWe use the Adam optimizer provided in the Python package PyTorch [82] to perform the optimization procedures.\n\n\nQuantum Noise in Quantum Simulator\n\nHere we introduce the error schemes we use in this study. We consider two forms of errors, gate errors and measurement errors. The gate error refers to the imperfection in any quantum operation we perform, whereas the measurement error refers to the error that occurs during quantum measurement. For the gate error, we consider the depolarizing noise which replaces the state of any qubit with a random state of probability p gate . For the measurement error, we consider a random flip between 0 and 1 with probability p meas immediately before the actual measurement. We use the following noise configuration in the simulation software to test our deep RL agents:\n\n\u2022 error rate (both p gate and p meas ) = 0.001\n\n\u2022 error rate (both p gate and p meas ) = 0.005\n\nFor the simulation of quantum circuits in both noise-free and noisy environments, we use the software package Qiskit from IBM [83].\n\n\nDensity Matrix of Quantum States\n\nThe general form of a density matrix \u03c1 of a quantum state under the basis {|\u03c8 i } is,\n\u03c1 = j p j |\u03c8 j \u03c8 j |(8)\nwhere p j represents the probability that the quantum system is in the pure state |\u03c8 j such that j p j = 1. For example, the density matrix of the Bell state considered in this study is |Bell = (|00 + |11 ) / \u221a 2. Its corresponding density matrix \u03c1 is then given by\n|Bell Bell| = 1 2 (|00 00| + |00 11| + |11 00| + |11 11|)(9)\nThe density matrix is used in calculating the state fidelity F as mentioned earlier.\n\n\nQuantum State Tomography\n\nQuantum state tomography is a procedure to reconstruct the density matrix associated \n\n\nCustomized OpenAI Gym Environment\n\nWe build a customized OpenAI Gym [84] environment to facilitate the development and testing of this work. In this package, users can set the target quantum state, threshold of fidelity and the quantum computing backend (real device or simulator software). In addition, it is also possible to customize the noise pattern. We construct the testing environments with the following settings:\n\n\u2022 Observation: As mentioned the agent receives Pauli-X, Y Z expectation values on each qubit. For general n-qubit systems, the number of observations will be 3 \u00d7 n.\n\n\u2022 Action: The RL agent is expected to select a quantum gate operating on the specific qubit as given in Eq. (3).\n\n\u2022 Reward: For each step before successfully reaching the goal, the agent will receive a \u22120.01 reward to encourage the shortest path. When reaching the goal, the agent will receive a reward of value (F \u2212 0.01).\n\n\nHyperparameters\n\nIn this work, we employ the neural network models (shown in Table I) as our DRL agents:\n\nWe consider two DRL algorithms in this work, their hyperparameters are:\n\n\u2022 A2C: learning rate \u03b7 = 10 \u22124 , discount factor \u03b3 = 0.99  \n\n\n3-qubit GHZ state\n\nHere we consider the application of DRL to generate the 3-qubit GHZ state from scratch under the noise-free environment. The result is in the Figure 7. We can observe that both A2C and PPO methods can successfully train the DRL agent to synthesize the GHZ state. It is demonstrated that, with the same neural network architecture, the PPO method reaches optimal results faster and the result is more stable compared to the A2C method. Notably, the advantage of PPO over A2C is much more significant compared to the 2-qubit case. In Figure 6 we provide the quantum circuit for GHZ state generated by the DRL agent. The gray area in the right panels of the figure represents the standard deviation of reward in each training episode. We observe that, given the same neural network architecture, PPO performs better than the A2C in terms of the convergence speed and the stability.\n\n\nC. Results: Noisy Environments\n\nIn the previous section, we observe that the RL training based on PPO algorithm converges faster. In the noisy scenario, we only use the PPO and not the vanilla A2C since  that the noisy environment is considered harder than the noise-free one. Here we study the case of applying DRL agent to synthesize the 2-qubit Bell state under noisy environment.\n\nThe first case we consider is with single-qubit error rate = 0.001 and the fidelity threshold = 0.95. Similar to the previous noise-free 2-qubit experiments, the agent gets a negative reward \u22120.01 at each step to encourage the shortest path. The maximum steps an agent can try in an episode is still 20. If the agent can reach fidelity beyond the threshold 0.95, then the agent will receive a positive reward (fidelity\u22120.01). Otherwise it will only receive reward = \u22120.01 when the episode ends. The result is shown in Figure 8a. Compared to the setting with the same single-qubit error rate and fidelity threshold = 0.99 (shown in Figure 8b), we observe that the one with fidelity threshold = 0.95 performs better, with much more stable score (smaller standard deviation).\n\nHere we need to point out that the fidelity threshold is to define whether the agent reaches a minimum goal. The agent is still trained to maximize the overall return, and the final fidelity which the agent can achieve is not limited to this threshold. A potential explanation is that, under the setting of fidelity threshold = 0.95, the agent would receive more guidance in the training phase. If the threshold is high, say 0.99, then the agent will stop after the maximum attempts and get no information about the fidelity in many of the training episodes. On the other hand, if the fidelity threshold is lower, the agent would receive positive reward in more training episode, which will in turn help the agent to adjust its model parameters.\n\nFinally we compare the performance between single-qubit error rate = 0.001 and 0.005, both with the fidelity threshold = 0.95. We observe that both cases (shown in Figure 8a and architecture search based on the heuristic search methods [85]. Recent works focus on the application of machine learning techniques [86][87][88][89][90]. Our methods differ from these. For example, in the work [87,89], the authors proposed frameworks to optimize the existing quantum circuit, reducing the number of quantum gates. In our method, there is no existing quantum circuit to be optimized. The quantum circuit is to be generated from scratch.\n\nOur method is also different from [88] as we do not directly sample from a distribution of quantum circuits. Our method is also different from [86] as we are not to generate a batch of circuits in each time step nor using random search, instead, we would let the circuit grow incrementally. Recent work on optimizing parameterized quantum structures [91] indicates potential direction of extending AI/ML method to a more general setting (e.g. optimizing the quantum circuit architecture and its parameters simultaneously).\n\n\nB. More Complex Problems\n\nOne may wonder how efficient this approach can be extended to large quantum circuits.\n\nIn general, this should be very difficult and the complexity scales exponentially in N , the number of qubits. However, given a universal set of one and two-qubit quantum gates, in principle to approximate any quantum state (up to an error tolerance) it only requires a finite number of gates. So our approach is still valid for arbitrary large qubit size but computationally hard. There is no free lunch we can get. But our method is still useful to construct the general density matrix. It is interesting to see the difficulty in the training related to the complexity of the target density matrix. There are various ways to define the complexity of the density matrices [92,93], the connection to which we leave as future work.\n\n\nC. Noisy Environments\n\nIn this work we investigate the potential of applying deep reinforcement learning in the quantum gate search under simple noisy configurations. Our proposed software toolkit and framework is possible to be extended into other more complex noise models. Therefore, the results of this work is a good choice of testbed for a variety of future studies concerning different noise or error schemes. For example, recent works suggest that ML models can be used to learn the quantum circuit architecture under the noise effects [94]. We expect our framework can be incorporated with such techniques. In addition, real quantum computers have different hardware topologies and these indeed have influences on the circuit design, we leave these topology-aware quantum architecture search as future work.\n\n\nD. Real Quantum Computers\n\nIt is interesting to ask whether one can use real quantum computers to realize our algorithms. Our platform is based on Qiskit. Therefore, one can easily connect our module by connecting the real IBM quantum computer. Thousand of training episodes are required in our experiment, however, real quantum computers do not have so much resource to do. So it is interesting to investigate this problem when quantum computing resources are more accessible. We leave it as future work.\n\n\nE. Other Quantum States\n\nIn this work, we consider the cases of two-qubit Bell state and three-qubit GHZ state for demonstration. However, the framework of the testing environment and RL agents are rather general. It is possible to investigate the quantum architecture search problem with other target quantum states and different noise configurations. In addition, it is also very convenient to test the performance of different reinforcement learning algorithms on quantum architecture search via the standard OpenAI Gym interface.\n\n\nF. Extension of the Environment\n\nIn this work, we pre-defined a set of gates or operations which can be used to generate a desired quantum state. This is not a limitation of our framework. The testing environment itself can be extended or modified to fit the quantum computing devices that are of interest. For example, it is interesting to build customized training environments with available operations from a specific quantum hardware.\n\n\nG. Circuit Optimization\n\nOne relevant question is that once we give a circuit C to produce a particular quantum state. Can one optimize this circuit getting a new circuit C by reducing its depth and circuit\n\ncomplexity? The answer is yes, recently, there is a paper using reinforcement learning for given a circuit representation [95] and optimize the circuit depth. So [95] can be viewed as the next step or the useful tool to optimize our circuits. However, we are building quantum circuit from scratch. So our goal is different from theirs. One can easily see from the complexity point of view, solving our task efficiently does not imply solving their task efficiently and vice versa. One can indeed combine our work and their work to form a pipeline to solve the following: given a target state \u03c8 and then try to find an efficient circuit C such that using C to create the target state. There is another related paper [96] using reinforcement learning and variational quantum circuit to find the ground state.\n\n\nVI. CONCLUSION\n\nIn this work, we demonstrate the application of deep reinforcement learning (DRL) to automatically generate the quantum gates sequence from the density matrix only. Our results suggest that with the currently available deep reinforcement learning algorithms, it is possible to discover the near-optimal quantum gate sequence with very limited physics knowledge encoded into the RL agents. We also present the customized OpenAI Gym environment for the experiments, which is a valuable tool for exploring other related quantum computing problems. Calculate the entropy term H = t H t = t \u2212 j \u03c0 (a j | s t ; \u03b8 \u03c0 ) log(\u03c0 (a j | s t ; \u03b8 \u03c0 ))\n\nCalculate the advantage A t = R t \u2212 V (s t , \u03b8 v )\n\nCalculate the policy loss L policy = E t [\u2212 log \u03c0 (a t | s t ; \u03b8 \u03c0 ) A t ] Total loss L = L value + L policy \u2212 0.001 \u00d7 H Update the agent policy parameters \u03b8 \u03c0 and \u03b8 v with gradient descent on the loss L where we import relevant packages and set the target of the quantum state that we want the RL agent to learn. The target is used to initialize the gym environment. Consider the case of noisy two-qubit system, the OpenAI Gym environment setting is as follows, where we import relevant packages and set the target of the quantum state that we want the RL agent to learn. In addition, we use functions from Qiskit package to define the noise model and the quantum simulation backend. The target and backend setting are then used to initialize the gym environment. We adopt the code for generating noise model from IBM qiskit textbook [97].\n\nFIG. 1 :\n1Reward: (a) -0.01 for each step. (b) +0.99 when reaching fidelity > 0.99. Observation: Pauli-X,Y,Z expectation values. Overview of DRL for our quantum architecture search framework. The\n\nFIG. 2 :\n2Quantum circuit for the Bell state.\n\nFIG. 3 :\n3Quantum circuit for the GHZ state.\n\n4\nwith a quantum state from a set of complete measurements. Expanding the density matrix in the Pauli basis of N qubits, N \u2212 1 linearly independent projective operators can uniquely determine the density matrix, for which Eq. 10 is a special case with the projectors being the Pauli operators. As a result, the number of measurements grows exponentially in the qubit number N , posing a significant challenge in verifying multi-qubit quantum states in any experiments, and with a finite number of shots the expectation values for {\u03c1 i 1 ,\u00b7\u00b7\u00b7 ,i N } can only be measured within certain accuracy. For the purpose of this work, however, we perform the quantum state tomography simulations using IBM's Qiskit software package[83].\n\n\nPPO for noise-free two-qubit system.FIG. 5: Deep Reinforcement Learning for Two-Qubit system. In the synthesis of the Bell state with noise-free simulation environment, we set the total number of training episodes to be 5000. The left panels of the figure show the raw scores of the DRL agents.\n\nFIG. 6 :\n6Quantum circuit for the GHZ state generated by the DRL(PPO) agent. PPO for noise-free three-qubit system.\n\nFIG. 7 :\n7Deep Reinforcement Learning for Three-Qubit system. In the synthesis of the GHZ state with noise-free simulation environment, we set the total number of training episodes to be 10000. We observe that, given the same neural network architecture, PPO performs significantly better than the A2C in terms of the convergence speed and the stability. The result is consistent with the 2-qubit case.\n\nFigure 8c )\n8cconverge quickly. However, the final converged fidelity in the case with higher error rate is a bit lower. reinforcement learning techniques have been applied in the investigation of quantum computing technologies. There are three main categories: quantum error correction, quantum optimal control and quantum architecture search. Early works on the PPO for noisy two-qubit system with single-qubit error rate 0.PPO for noisy two-qubit system with single-qubit error rate 0.PPO for noisy two-qubit system with single-qubit error rate 0.005 and fidelity threshold 0.95.FIG. 8: Deep Reinforcement for Noisy Two-Qubit system. Synthesis of the Bell state.\n\nAlgorithm 1\n1Advantage Actor-Critic (A2C) for quantum architecture search Define the number of total episode M Define the maximum steps in a single episode S for episode = 1, 2, . . . , M do Reset the testing environment and initialise state s 1 Initialise trajectory buffer T Initialise the counter t Initialise episode reward R E = 0 for step = 1, 2, . . . , S do Select the action a t from the policy \u03c0 (a t | s t ; \u03b8 \u03c0 ) Execute action a t in emulator and observe reward r t and next state s t+1 Record the transition (s t , a t , r t , s t+1 ) in T Episode reward R E \u2190 R E + 1 if reaching terminal state or reaching maximum steps M then Calculate the value targets R t for each state s t in the trajectory buffer T Calculate the values V (s t , \u03b8 v ) of each state s t from the model V (s t , \u03b8 v ) Calculate the value loss L value = E t V (s t , \u03b8 v ) \u2212 R t 2\n\n\ngym.make('BasicTwoQubit-v0', target = target)\n\n\n.providers.aer.noise import NoiseModel 4 from qiskit.providers.aer.noise.errors import pauli_errorqubit gate error is applied to x gates15 noise_model.add_all_qubit_quantum_error(error_gate1, [\"x\"])16 # two qubit gate error is applied to cx gates17 noise_model.add_all_qubit_quantum_error(error_gate2, [\"cx\"\n\nTABLE I :\nIThe neural network for A2C and PPO. The structure is the same for both the actor and critic. The only difference is that in the actor, there is a softmax at the end of the network.Here we consider the application of DRL to generate the 2-qubit Bell state from scratch under the noise-free environment. The result is in theFigure 5. We can observe that both A2C and PPO methods can successfully train the DRL agent to synthesize the Bell state. It is demonstrated that, with the same neural network architecture, the PPO method reaches optimal results faster and the result is more stable compared to the A2C method. In Figure4 we provide the quantum circuit for Bell state generated by the DRL agent.FIG. 4: Quantum circuit for the Bell state generated by the DRL(PPO) agent.B. Results: Noise-Free Environments \n\n1. 2-qubit Bell state \n\n|0 \n\n|0 \nH \n\u2022 \n\n\ni 1 ,\u00b7\u00b7\u00b7 ,i N =0 \u03c1 i i ,\u00b7\u00b7\u00b7 ,i N \u03c3 i 1 \u2297 \u00b7 \u00b7 \u00b7 \u2297 \u03c3 i N ,(10)it can be seen that to fully determine \u03c1 requires 4 N \u2212 1 measurement operations (minus one due to the conservation of probability, Tr(\u03c1) = 1). More generally, measurements with\nAppendix A: RL AlgorithmsHere we provide the details of the RL algorithms used in this work.Appendix B: Code samples\nReinforcement learning: An introduction. R S Sutton, A G Barto, MIT pressR. S. Sutton and A. G. Barto, Reinforcement learning: An introduction. MIT press, 2018.\n\nHuman-level control through deep reinforcement learning. V Mnih, K Kavukcuoglu, D Silver, A A Rusu, J Veness, M G Bellemare, A Graves, M Riedmiller, A K Fidjeland, G Ostrovski, S Petersen, C Beattie, A Sadik, I Antonoglou, H King, D Kumaran, D Wierstra, S Legg, D Hassabis, Nature. 518V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, S. Petersen, C. Beattie, A. Sadik, I. Antonoglou, H. King, D. Kumaran, D. Wierstra, S. Legg, and D. Hassabis, \"Human-level control through deep reinforcement learning,\" Nature, vol. 518, pp. 529-533, 2 2015.\n\nMastering atari, go, chess and shogi by planning with a learned model. J Schrittwieser, I Antonoglou, T Hubert, K Simonyan, L Sifre, S Schmitt, A Guez, E Lockhart, D Hassabis, T Graepel, arXiv:1911.08265arXiv preprintJ. Schrittwieser, I. Antonoglou, T. Hubert, K. Simonyan, L. Sifre, S. Schmitt, A. Guez, E. Lockhart, D. Hassabis, T. Graepel, et al., \"Mastering atari, go, chess and shogi by planning with a learned model,\" arXiv preprint arXiv:1911.08265, 2019.\n\nAgent57: Outperforming the atari human benchmark. A P Badia, B Piot, S Kapturowski, P Sprechmann, A Vitvitskyi, D Guo, C Blundell, arXiv:2003.13350arXiv preprintA. P. Badia, B. Piot, S. Kapturowski, P. Sprechmann, A. Vitvitskyi, D. Guo, and C. Blundell, \"Agent57: Outperforming the atari human benchmark,\" arXiv preprint arXiv:2003.13350, 2020.\n\nRecurrent experience replay in distributed reinforcement learning. S Kapturowski, G Ostrovski, J Quan, R Munos, W Dabney, International conference on learning representations. S. Kapturowski, G. Ostrovski, J. Quan, R. Munos, and W. Dabney, \"Recurrent experience replay in distributed reinforcement learning,\" in International conference on learning repre- sentations, 2018.\n\nMastering the game of go with deep neural networks and tree search. D Silver, A Huang, C J Maddison, A Guez, L Sifre, G Van Den Driessche, J Schrittwieser, I Antonoglou, V Panneershelvam, M Lanctot, nature. 5297587D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, et al., \"Mastering the game of go with deep neural networks and tree search,\" nature, vol. 529, no. 7587, pp. 484-489, 2016.\n\nMastering the game of go without human knowledge. D Silver, J Schrittwieser, K Simonyan, I Antonoglou, A Huang, A Guez, T Hubert, L Baker, M Lai, A Bolton, nature. 5507676D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, et al., \"Mastering the game of go without human knowledge,\" nature, vol. 550, no. 7676, pp. 354-359, 2017.\n\nReinforcement learning in different phases of quantum control. M Bukov, A G Day, D Sels, P Weinberg, A Polkovnikov, P Mehta, Physical Review X. 8331086M. Bukov, A. G. Day, D. Sels, P. Weinberg, A. Polkovnikov, and P. Mehta, \"Reinforcement learning in different phases of quantum control,\" Physical Review X, vol. 8, no. 3, p. 031086, 2018.\n\nReinforcement learning with neural networks for quantum feedback. T F\u00f6sel, P Tighineanu, T Weiss, F Marquardt, Physical Review X. 8331084T. F\u00f6sel, P. Tighineanu, T. Weiss, and F. Marquardt, \"Reinforcement learning with neural networks for quantum feedback,\" Physical Review X, vol. 8, no. 3, p. 031084, 2018.\n\nUniversal quantum control through deep reinforcement learning. M Y Niu, S Boixo, V N Smelyanskiy, H Neven, npj Quantum Information. 5M. Y. Niu, S. Boixo, V. N. Smelyanskiy, and H. Neven, \"Universal quantum control through deep reinforcement learning,\" npj Quantum Information, vol. 5, no. 1, pp. 1-8, 2019.\n\nDeep reinforcement learning for quantum gate control. Z An, D Zhou, EPL (Europhysics Letters). 126660002Z. An and D. Zhou, \"Deep reinforcement learning for quantum gate control,\" EPL (Euro- physics Letters), vol. 126, no. 6, p. 60002, 2019.\n\nWhen does reinforcement learning stand out in quantum control? a comparative study on state preparation. X.-M Zhang, Z Wei, R Asad, X.-C Yang, X Wang, npj Quantum Information. 5X.-M. Zhang, Z. Wei, R. Asad, X.-C. Yang, and X. Wang, \"When does reinforcement learning stand out in quantum control? a comparative study on state preparation,\" npj Quantum Information, vol. 5, no. 1, pp. 1-7, 2019.\n\nLearning in quantum control: High-dimensional global optimization for noisy quantum dynamics. P Palittapongarnpim, P Wittek, E Zahedinejad, S Vedaie, B C Sanders, Neurocomputing. 268P. Palittapongarnpim, P. Wittek, E. Zahedinejad, S. Vedaie, and B. C. Sanders, \"Learning in quantum control: High-dimensional global optimization for noisy quantum dynamics,\" Neurocomputing, vol. 268, pp. 116-126, 2017.\n\nGeneralizable control for quantum parameter estimation through reinforcement learning. H Xu, J Li, L Liu, Y Wang, H Yuan, X Wang, npj Quantum Information. 5H. Xu, J. Li, L. Liu, Y. Wang, H. Yuan, and X. Wang, \"Generalizable control for quantum pa- rameter estimation through reinforcement learning,\" npj Quantum Information, vol. 5, no. 1, pp. 1-8, 2019.\n\nQuantum error correction for the toric code using deep reinforcement learning. P Andreasson, J Johansson, S Liljestrand, M Granath, 3183QuantumP. Andreasson, J. Johansson, S. Liljestrand, and M. Granath, \"Quantum error correction for the toric code using deep reinforcement learning,\" Quantum, vol. 3, p. 183, 2019.\n\nDeep q-learning decoder for depolarizing noise on the toric code. D Fitzek, M Eliasson, A F Kockum, M Granath, Physical Review Research. 2223230D. Fitzek, M. Eliasson, A. F. Kockum, and M. Granath, \"Deep q-learning decoder for depo- larizing noise on the toric code,\" Physical Review Research, vol. 2, no. 2, p. 023230, 2020.\n\nDistributed training for deep reinforcement learning decoders on the toric code. A Olsson, G Lindeby, A. Olsson and G. Lindeby, \"Distributed training for deep reinforcement learning decoders on the toric code,\" 2020.\n\nOptimizing quantum error correction codes with reinforcement learning. H P Nautrup, N Delfosse, V Dunjko, H J Briegel, N Friis, 3215QuantumH. P. Nautrup, N. Delfosse, V. Dunjko, H. J. Briegel, and N. Friis, \"Optimizing quantum error correction codes with reinforcement learning,\" Quantum, vol. 3, p. 215, 2019.\n\nReinforcement learning for optimal error correction of toric codes. L D Colomer, M Skotiniotis, R Mu\u00f1oz-Tapia, Physics Letters A. 38417126353L. D. Colomer, M. Skotiniotis, and R. Mu\u00f1oz-Tapia, \"Reinforcement learning for optimal error correction of toric codes,\" Physics Letters A, vol. 384, no. 17, p. 126353, 2020.\n\nReinforcement learning assisted quantum optimization. M M Wauters, E Panizon, G B Mbeng, G E Santoro, arXiv:2004.12323arXiv preprintM. M. Wauters, E. Panizon, G. B. Mbeng, and G. E. Santoro, \"Reinforcement learning assisted quantum optimization,\" arXiv preprint arXiv:2004.12323, 2020.\n\nPolicy gradient based quantum approximate optimization algorithm. J Yao, M Bukov, L Lin, arXiv:2002.01068arXiv preprintJ. Yao, M. Bukov, and L. Lin, \"Policy gradient based quantum approximate optimization algorithm,\" arXiv preprint arXiv:2002.01068, 2020.\n\nLearning to learn with quantum neural networks via classical neural networks. G Verdon, M Broughton, J R Mcclean, K J Sung, R Babbush, Z Jiang, H Neven, M Mohseni, arXiv:1907.05415arXiv preprintG. Verdon, M. Broughton, J. R. McClean, K. J. Sung, R. Babbush, Z. Jiang, H. Neven, and M. Mohseni, \"Learning to learn with quantum neural networks via classical neural networks,\" arXiv preprint arXiv:1907.05415, 2019.\n\nOptimizing quantum heuristics with meta-learning. M Wilson, S Stromswold, F Wudarski, S Hadfield, N M Tubman, E Rieffel, arXiv:1908.03185arXiv preprintM. Wilson, S. Stromswold, F. Wudarski, S. Hadfield, N. M. Tubman, and E. Rieffel, \"Opti- mizing quantum heuristics with meta-learning,\" arXiv preprint arXiv:1908.03185, 2019.\n\nNeural architecture search with reinforcement learning. B Zoph, Q V Le, arXiv:1611.01578arXiv preprintB. Zoph and Q. V. Le, \"Neural architecture search with reinforcement learning,\" arXiv preprint arXiv:1611.01578, 2016.\n\nDesigning neural network architectures using reinforcement learning. B Baker, O Gupta, N Naik, R Raskar, arXiv:1611.02167arXiv preprintB. Baker, O. Gupta, N. Naik, and R. Raskar, \"Designing neural network architectures using reinforcement learning,\" arXiv preprint arXiv:1611.02167, 2016.\n\nEfficient architecture search by network transformation. H Cai, T Chen, W Zhang, Y Yu, J Wang, arXiv:1707.04873arXiv preprintH. Cai, T. Chen, W. Zhang, Y. Yu, and J. Wang, \"Efficient architecture search by network transformation,\" arXiv preprint arXiv:1707.04873, 2017.\n\nLearning transferable architectures for scalable image recognition. B Zoph, V Vasudevan, J Shlens, Q V Le, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionB. Zoph, V. Vasudevan, J. Shlens, and Q. V. Le, \"Learning transferable architectures for scalable image recognition,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 8697-8710, 2018.\n\nPractical block-wise neural network architecture generation. Z Zhong, J Yan, W Wu, J Shao, C.-L Liu, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionZ. Zhong, J. Yan, W. Wu, J. Shao, and C.-L. Liu, \"Practical block-wise neural network ar- chitecture generation,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2423-2432, 2018.\n\nA flexible approach to automated rnn architecture generation. M Schrimpf, S Merity, J Bradbury, R Socher, arXiv:1712.07316arXiv preprintM. Schrimpf, S. Merity, J. Bradbury, and R. Socher, \"A flexible approach to automated rnn architecture generation,\" arXiv preprint arXiv:1712.07316, 2017.\n\nEfficient neural architecture search via parameter sharing. H Pham, M Y Guan, B Zoph, Q V Le, J Dean, arXiv:1802.03268arXiv preprintH. Pham, M. Y. Guan, B. Zoph, Q. V. Le, and J. Dean, \"Efficient neural architecture search via parameter sharing,\" arXiv preprint arXiv:1802.03268, 2018.\n\nPath-level network transformation for efficient architecture search. H Cai, J Yang, W Zhang, S Han, Y Yu, arXiv:1806.02639arXiv preprintH. Cai, J. Yang, W. Zhang, S. Han, and Y. Yu, \"Path-level network transformation for efficient architecture search,\" arXiv preprint arXiv:1806.02639, 2018.\n\nNeural architecture search: A survey. T Elsken, J H Metzen, F Hutter, J. Mach. Learn. Res. 2055T. Elsken, J. H. Metzen, F. Hutter, et al., \"Neural architecture search: A survey.,\" J. Mach. Learn. Res., vol. 20, no. 55, pp. 1-21, 2019.\n\nQuantum computational supremacy. A W Harrow, A Montanaro, Nature. 5497671A. W. Harrow and A. Montanaro, \"Quantum computational supremacy,\" Nature, vol. 549, no. 7671, pp. 203-209, 2017.\n\nQuantum supremacy using a programmable superconducting processor. F Arute, K Arya, R Babbush, D Bacon, J C Bardin, R Barends, R Biswas, S Boixo, F G Brandao, D A Buell, Nature. 5747779F. Arute, K. Arya, R. Babbush, D. Bacon, J. C. Bardin, R. Barends, R. Biswas, S. Boixo, F. G. Brandao, D. A. Buell, et al., \"Quantum supremacy using a programmable superconducting processor,\" Nature, vol. 574, no. 7779, pp. 505-510, 2019.\n\nPolynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer. P W Shor, SIAM review. 412P. W. Shor, \"Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer,\" SIAM review, vol. 41, no. 2, pp. 303-332, 1999.\n\nQuantum mechanics helps in searching for a needle in a haystack. L K Grover, Physical review letters. 792325L. K. Grover, \"Quantum mechanics helps in searching for a needle in a haystack,\" Physical review letters, vol. 79, no. 2, p. 325, 1997.\n\nA variational eigenvalue solver on a photonic quantum processor. A Peruzzo, J Mcclean, P Shadbolt, M.-H Yung, X.-Q Zhou, P J Love, A Aspuru-Guzik, J L O&apos;brien, Nature communications. 54213A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q. Zhou, P. J. Love, A. Aspuru-Guzik, and J. L. O'brien, \"A variational eigenvalue solver on a photonic quantum processor,\" Nature communications, vol. 5, p. 4213, 2014.\n\nQuantum approximate optimization algorithm: performance, mechanism, and implementation on near-term devices. L Zhou, S.-T Wang, S Choi, H Pichler, M D Lukin, arXiv:1812.01041arXiv preprintL. Zhou, S.-T. Wang, S. Choi, H. Pichler, and M. D. Lukin, \"Quantum approximate optimiza- tion algorithm: performance, mechanism, and implementation on near-term devices,\" arXiv preprint arXiv:1812.01041, 2018.\n\nA quantum approximate optimization algorithm. E Farhi, J Goldstone, S Gutmann, arXiv:1411.4028arXiv preprintE. Farhi, J. Goldstone, and S. Gutmann, \"A quantum approximate optimization algorithm,\" arXiv preprint arXiv:1411.4028, 2014.\n\nQuantum long short-term memory. S Y Chen, S Yoo, Y.-L L Fang, arXiv:2009.01783arXiv preprintS. Y.-C. Chen, S. Yoo, and Y.-L. L. Fang, \"Quantum long short-term memory,\" arXiv preprint arXiv:2009.01783, 2020.\n\nQuantum circuit learning. K Mitarai, M Negoro, M Kitagawa, K Fujii, Physical Review A. 98332309K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii, \"Quantum circuit learning,\" Physical Review A, vol. 98, no. 3, p. 032309, 2018.\n\nSolving nonlinear differential equations with differentiable quantum circuits. O Kyriienko, A E Paine, V E Elfving, arXiv:2011.10395arXiv preprintO. Kyriienko, A. E. Paine, and V. E. Elfving, \"Solving nonlinear differential equations with differentiable quantum circuits,\" arXiv preprint arXiv:2011.10395, 2020.\n\nCircuit-centric quantum classifiers. M Schuld, A Bocharov, K Svore, N Wiebe, arXiv:1804.00633arXiv preprintM. Schuld, A. Bocharov, K. Svore, and N. Wiebe, \"Circuit-centric quantum classifiers,\" arXiv preprint arXiv:1804.00633, 2018.\n\nSupervised learning with quantum-enhanced feature spaces. V Havl\u00ed\u010dek, A D C\u00f3rcoles, K Temme, A W Harrow, A Kandala, J M Chow, J M Gambetta, Nature. 5677747V. Havl\u00ed\u010dek, A. D. C\u00f3rcoles, K. Temme, A. W. Harrow, A. Kandala, J. M. Chow, and J. M. Gambetta, \"Supervised learning with quantum-enhanced feature spaces,\" Nature, vol. 567, no. 7747, pp. 209-212, 2019.\n\nE Farhi, H Neven, arXiv:1802.06002Classification with quantum neural networks on near term processors. arXiv preprintE. Farhi and H. Neven, \"Classification with quantum neural networks on near term proces- sors,\" arXiv preprint arXiv:1802.06002, 2018.\n\nParameterized quantum circuits as machine learning models. M Benedetti, E Lloyd, S Sack, M Fiorentini, Quantum Science and Technology. 4443001M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, \"Parameterized quantum circuits as machine learning models,\" Quantum Science and Technology, vol. 4, no. 4, p. 043001, 2019.\n\nTransfer learning in hybrid classical-quantum neural networks. A Mari, T R Bromley, J Izaac, M Schuld, N Killoran, arXiv:1912.08278arXiv preprintA. Mari, T. R. Bromley, J. Izaac, M. Schuld, and N. Killoran, \"Transfer learning in hybrid classical-quantum neural networks,\" arXiv preprint arXiv:1912.08278, 2019.\n\nClassification with quantum machine learning: A survey. Z Abohashima, M Elhosen, E H Houssein, W M Mohamed, arXiv:2006.12270arXiv preprintZ. Abohashima, M. Elhosen, E. H. Houssein, and W. M. Mohamed, \"Classification with quantum machine learning: A survey,\" arXiv preprint arXiv:2006.12270, 2020.\n\nTowards building a facial identification system using quantum machine learning techniques. P Easom-Mccaldin, A Bouridane, A Belatreche, R Jiang, arXiv:2008.12616arXiv preprintP. Easom-McCaldin, A. Bouridane, A. Belatreche, and R. Jiang, \"Towards building a facial identification system using quantum machine learning techniques,\" arXiv preprint arXiv:2008.12616, 2020.\n\nQuantum unsupervised and supervised learning on superconducting processors. A Sarma, R Chatterjee, K Gili, T Yu, arXiv:1909.04226arXiv preprintA. Sarma, R. Chatterjee, K. Gili, and T. Yu, \"Quantum unsupervised and supervised learning on superconducting processors,\" arXiv preprint arXiv:1909.04226, 2019.\n\nA hybrid system for learning classical data in quantum states. S A Stein, B Baheri, R M Tischio, Y Chen, Y Mao, Q Guan, A Li, B Fang, arXiv:2012.00256arXiv preprintS. A. Stein, B. Baheri, R. M. Tischio, Y. Chen, Y. Mao, Q. Guan, A. Li, and B. Fang, \"A hybrid system for learning classical data in quantum states,\" arXiv preprint arXiv:2012.00256, 2020.\n\nHybrid quantum-classical classifier based on tensor network and variational quantum circuit. S Y Chen, C.-M Huang, C.-W Hsing, Y.-J Kao, arXiv:2011.14651arXiv preprintS. Y.-C. Chen, C.-M. Huang, C.-W. Hsing, and Y.-J. Kao, \"Hybrid quantum-classical classifier based on tensor network and variational quantum circuit,\" arXiv preprint arXiv:2011.14651, 2020.\n\nQuantum convolutional neural networks for high energy physics data analysis. S Y Chen, T.-C Wei, C Zhang, H Yu, S Yoo, arXiv:2012.12177arXiv preprintS. Y.-C. Chen, T.-C. Wei, C. Zhang, H. Yu, and S. Yoo, \"Quantum convolutional neural networks for high energy physics data analysis,\" arXiv preprint arXiv:2012.12177, 2020.\n\nApplication of quantum machine learning using the quantum variational classifier method to high energy physics analysis at the lhc on ibm quantum computer simulator and hardware with 10 qubits. S L Wu, J Chan, W Guan, S Sun, A Wang, C Zhou, M Livny, F Carminati, A Di Meglio, A C Li, arXiv:2012.11560arXiv preprintS. L. Wu, J. Chan, W. Guan, S. Sun, A. Wang, C. Zhou, M. Livny, F. Carminati, A. Di Meglio, A. C. Li, et al., \"Application of quantum machine learning using the quantum variational clas- sifier method to high energy physics analysis at the lhc on ibm quantum computer simulator and hardware with 10 qubits,\" arXiv preprint arXiv:2012.11560, 2020.\n\nQuclassi: A hybrid deep neural network architecture based on quantum state fidelity. S A Stein, Y Mao, B Baheri, Q Guan, A Li, D Chen, S Xu, C Ding, arXiv:2103.11307arXiv preprintS. A. Stein, Y. Mao, B. Baheri, Q. Guan, A. Li, D. Chen, S. Xu, and C. Ding, \"Quclassi: A hybrid deep neural network architecture based on quantum state fidelity,\" arXiv preprint arXiv:2103.11307, 2021.\n\nHybrid quantum-classical graph convolutional network. S Y Chen, T.-C Wei, C Zhang, H Yu, S Yoo, arXiv:2101.06189arXiv preprintS. Y.-C. Chen, T.-C. Wei, C. Zhang, H. Yu, and S. Yoo, \"Hybrid quantum-classical graph convolutional network,\" arXiv preprint arXiv:2101.06189, 2021.\n\nQuantum self-supervised learning. B Jaderberg, L W Anderson, W Xie, S Albanie, M Kiffner, D Jaksch, arXiv:2103.14653arXiv preprintB. Jaderberg, L. W. Anderson, W. Xie, S. Albanie, M. Kiffner, and D. Jaksch, \"Quantum self-supervised learning,\" arXiv preprint arXiv:2103.14653, 2021.\n\nQuantum generative adversarial networks. P.-L Dallaire-Demers, N Killoran, Physical Review A. 98112324P.-L. Dallaire-Demers and N. Killoran, \"Quantum generative adversarial networks,\" Physical Review A, vol. 98, no. 1, p. 012324, 2018.\n\nQugan: A generative adversarial network through quantum states. S A Stein, B Baheri, R M Tischio, Y Mao, Q Guan, A Li, B Fang, S Xu, arXiv:2010.09036arXiv preprintS. A. Stein, B. Baheri, R. M. Tischio, Y. Mao, Q. Guan, A. Li, B. Fang, and S. Xu, \"Qugan: A generative adversarial network through quantum states,\" arXiv preprint arXiv:2010.09036, 2020.\n\nQuantum generative adversarial networks for learning and loading random distributions. C Zoufal, A Lucchi, S Woerner, npj Quantum Information. 5C. Zoufal, A. Lucchi, and S. Woerner, \"Quantum generative adversarial networks for learning and loading random distributions,\" npj Quantum Information, vol. 5, no. 1, pp. 1-9, 2019.\n\nQuantum generative adversarial network for generating discrete data. H Situ, Z He, L Li, S Zheng, arXiv:1807.01235arXiv preprintH. Situ, Z. He, L. Li, and S. Zheng, \"Quantum generative adversarial network for generating discrete data,\" arXiv preprint arXiv:1807.01235, 2018.\n\nQuantum semi-supervised generative adversarial network for enhanced data classification. K Nakaji, N Yamamoto, arXiv:2010.13727arXiv preprintK. Nakaji and N. Yamamoto, \"Quantum semi-supervised generative adversarial network for enhanced data classification,\" arXiv preprint arXiv:2010.13727, 2020.\n\nVariational quantum circuits for deep reinforcement learning. S Y Chen, C.-H H Yang, J Qi, P.-Y Chen, X Ma, H.-S Goan, IEEE Access. 8S. Y.-C. Chen, C.-H. H. Yang, J. Qi, P.-Y. Chen, X. Ma, and H.-S. Goan, \"Variational quantum circuits for deep reinforcement learning,\" IEEE Access, vol. 8, pp. 141007-141024, 2020.\n\nReinforcement learning with quantum variational circuit. O Lockwood, M Si, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment. the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment16O. Lockwood and M. Si, \"Reinforcement learning with quantum variational circuit,\" in Pro- ceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertain- ment, vol. 16, pp. 245-251, 2020.\n\nQuantum enhancements for deep reinforcement learning in large spaces. S Jerbi, L M Trenkwalder, H P Nautrup, H J Briegel, V Dunjko, PRX Quantum. 2110328S. Jerbi, L. M. Trenkwalder, H. P. Nautrup, H. J. Briegel, and V. Dunjko, \"Quantum en- hancements for deep reinforcement learning in large spaces,\" PRX Quantum, vol. 2, no. 1, p. 010328, 2021.\n\nHybrid quantum-classical ulam-von neumann linear solver-based quantum dynamic programing algorithm. C.-C Chen, K Shiba, M Sogabe, K Sakamoto, T Sogabe, Proceedings of the Annual Conference of JSAI. the Annual Conference of JSAI2020C.-C. CHEN, K. SHIBA, M. SOGABE, K. SAKAMOTO, and T. SOGABE, \"Hybrid quantum-classical ulam-von neumann linear solver-based quantum dynamic programing al- gorithm,\" Proceedings of the Annual Conference of JSAI, vol. JSAI2020, pp. 2K6ES203- 2K6ES203, 2020.\n\nQuantum reinforcement learning in continuous action space. S Wu, S Jin, D Wen, X Wang, arXiv:2012.10711arXiv preprintS. Wu, S. Jin, D. Wen, and X. Wang, \"Quantum reinforcement learning in continuous action space,\" arXiv preprint arXiv:2012.10711, 2020.\n\nQuantum agents in the gym: a variational quantum algorithm for deep q-learning. A Skolik, S Jerbi, V Dunjko, arXiv:2103.15084arXiv preprintA. Skolik, S. Jerbi, and V. Dunjko, \"Quantum agents in the gym: a variational quantum algorithm for deep q-learning,\" arXiv preprint arXiv:2103.15084, 2021.\n\nVariational quantum policies for reinforcement learning. S Jerbi, C Gyurik, S Marshall, H J Briegel, V Dunjko, arXiv:2103.05577arXiv preprintS. Jerbi, C. Gyurik, S. Marshall, H. J. Briegel, and V. Dunjko, \"Variational quantum policies for reinforcement learning,\" arXiv preprint arXiv:2103.05577, 2021.\n\nJ Bausch, arXiv:2006.14619Recurrent quantum neural networks. arXiv preprintJ. Bausch, \"Recurrent quantum neural networks,\" arXiv preprint arXiv:2006.14619, 2020.\n\nLearning temporal data with variational quantum recurrent neural network. Y Takaki, K Mitarai, M Negoro, K Fujii, M Kitagawa, arXiv:2012.11242arXiv preprintY. Takaki, K. Mitarai, M. Negoro, K. Fujii, and M. Kitagawa, \"Learning temporal data with variational quantum recurrent neural network,\" arXiv preprint arXiv:2012.11242, 2020.\n\nDecentralizing feature extraction with quantum convolutional neural network for automatic speech recognition. C.-H H Yang, J Qi, S Y Chen, P.-Y Chen, S M Siniscalchi, X Ma, C.-H Lee, arXiv:2010.13309arXiv preprintC.-H. H. Yang, J. Qi, S. Y.-C. Chen, P.-Y. Chen, S. M. Siniscalchi, X. Ma, and C.-H. Lee, \"Decentralizing feature extraction with quantum convolutional neural network for automatic speech recognition,\" arXiv preprint arXiv:2010.13309, 2020.\n\nQuantum embeddings for machine learning. S Lloyd, M Schuld, A Ijaz, J Izaac, N Killoran, arXiv:2001.03622arXiv preprintS. Lloyd, M. Schuld, A. Ijaz, J. Izaac, and N. Killoran, \"Quantum embeddings for machine learning,\" arXiv preprint arXiv:2001.03622, 2020.\n\nA unified classification framework with quantum metric learning. N A Nghiem, S Y C Chen, T.-C Wei, arXiv:2010.13186arXiv preprintN. A. Nghiem, S. Y.-C. Chen, and T.-C. Wei, \"A unified classification framework with quan- tum metric learning,\" arXiv preprint arXiv:2010.13186, 2020.\n\nFederated quantum machine learning. S Y , -C Chen, S Yoo, arXiv:2103.12010arXiv preprintS. Y.-C. Chen and S. Yoo, \"Federated quantum machine learning,\" arXiv preprint arXiv:2103.12010, 2021.\n\nSimple statistical gradient-following algorithms for connectionist reinforcement learning. R J Williams, Machine learning. 83-4R. J. Williams, \"Simple statistical gradient-following algorithms for connectionist reinforce- ment learning,\" Machine learning, vol. 8, no. 3-4, pp. 229-256, 1992.\n\nProximal policy optimization algorithms. J Schulman, F Wolski, P Dhariwal, A Radford, O Klimov, arXiv:1707.06347arXiv preprintJ. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov, \"Proximal policy optimiza- tion algorithms,\" arXiv preprint arXiv:1707.06347, 2017.\n\nQuantum computation and quantum information. M A Nielsen, I Chuang, M. A. Nielsen and I. Chuang, \"Quantum computation and quantum information,\" 2002.\n\nAn overview of gradient descent optimization algorithms. S Ruder, arXiv:1609.04747arXiv preprintS. Ruder, \"An overview of gradient descent optimization algorithms,\" arXiv preprint arXiv:1609.04747, 2016.\n\nLecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude. T Tieleman, G Hinton, COURSERA: Neural Networks for Machine Learning. T. Tieleman and G. Hinton, \"Lecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude.\" COURSERA: Neural Networks for Machine Learning, 2012.\n\nAdam: A method for stochastic optimization. D P Kingma, J Ba, arXiv:1412.6980arXiv preprintD. P. Kingma and J. Ba, \"Adam: A method for stochastic optimization,\" arXiv preprint arXiv:1412.6980, 2014.\n\nPyTorch: An Imperative Style, High-Performance Deep Learning Library. A Paszke, S Gross, F Massa, A Lerer, J Bradbury, G Chanan, T Killeen, Z Lin, N Gimelshein, L Antiga, A Desmaison, A Kopf, E Yang, Z Devito, M Raison, A Tejani, S Chilamkurthy, B Steiner, L Fang, J Bai, S Chintala, Advances in Neural Information Processing Systems. H. Wallach and H. Larochelle and A. Beygelzimer and F. d'Alch\u00e9-Buc and E. Fox and R. GarnettCurran Associates, Inc32A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Te- jani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S. Chintala, \"PyTorch: An Imperative Style, High-Performance Deep Learning Library,\" in Advances in Neural Information Process- ing Systems 32 (H. Wallach and H. Larochelle and A. Beygelzimer and F. d'Alch\u00e9-Buc and E. Fox and R. Garnett, ed.), pp. 8024-8035, Curran Associates, Inc., 2019.\n\nThe ibm q experience and qiskit open-source quantum computing software. A Cross, APS Meeting Abstracts. A. Cross, \"The ibm q experience and qiskit open-source quantum computing software,\" in APS Meeting Abstracts, 2018.\n\nOpenai gym. G Brockman, V Cheung, L Pettersson, J Schneider, J Schulman, J Tang, W Zaremba, arXiv:1606.01540arXiv preprintG. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba, \"Openai gym,\" arXiv preprint arXiv:1606.01540, 2016.\n\nAutomated design of quantum circuits. C P Williams, A G Gray, NASA International Conference on Quantum Computing and Quantum Communications. SpringerC. P. Williams and A. G. Gray, \"Automated design of quantum circuits,\" in NASA Inter- national Conference on Quantum Computing and Quantum Communications, pp. 113-125, Springer, 1998.\n\nQuantum circuit design search. M Pirhooshyaran, T Terlaky, arXiv:2012.04046arXiv preprintM. Pirhooshyaran and T. Terlaky, \"Quantum circuit design search,\" arXiv preprint arXiv:2012.04046, 2020.\n\nQuantum circuit architecture search: error mitigation and trainability enhancement for variational quantum solvers. Y Du, T Huang, S You, M.-H Hsieh, D Tao, arXiv:2010.10217arXiv preprintY. Du, T. Huang, S. You, M.-H. Hsieh, and D. Tao, \"Quantum circuit architecture search: error mitigation and trainability enhancement for variational quantum solvers,\" arXiv preprint arXiv:2010.10217, 2020.\n\nDifferentiable quantum architecture search. S.-X Zhang, C.-Y Hsieh, S Zhang, H Yao, arXiv:2010.08561arXiv preprintS.-X. Zhang, C.-Y. Hsieh, S. Zhang, and H. Yao, \"Differentiable quantum architecture search,\" arXiv preprint arXiv:2010.08561, 2020.\n\nOptimizing noisy-intermediate scale quantum circuits: A block-based synthesis. X.-C Wu, M G Davis, F T Chong, C Iancu, arXiv:2012.09835arXiv preprintX.-C. Wu, M. G. Davis, F. T. Chong, and C. Iancu, \"Optimizing noisy-intermediate scale quantum circuits: A block-based synthesis,\" arXiv preprint arXiv:2012.09835, 2020.\n\nNeural predictor based quantum architecture search. S.-X Zhang, C.-Y Hsieh, S Zhang, H Yao, arXiv:2103.06524arXiv preprintS.-X. Zhang, C.-Y. Hsieh, S. Zhang, and H. Yao, \"Neural predictor based quantum architecture search,\" arXiv preprint arXiv:2103.06524, 2021.\n\nStructure optimization for parameterized quantum circuits. M Ostaszewski, E Grant, M Benedetti, 5391QuantumM. Ostaszewski, E. Grant, and M. Benedetti, \"Structure optimization for parameterized quan- tum circuits,\" Quantum, vol. 5, p. 391, 2021.\n\nLogarithmic negativity: a full entanglement monotone that is not convex. M B Plenio, Physical review letters. 95990503M. B. Plenio, \"Logarithmic negativity: a full entanglement monotone that is not convex,\" Physical review letters, vol. 95, no. 9, p. 090503, 2005.\n\nComputable measure of entanglement. G Vidal, R F Werner, Physical Review A. 65332314G. Vidal and R. F. Werner, \"Computable measure of entanglement,\" Physical Review A, vol. 65, no. 3, p. 032314, 2002.\n\nMachine learning of noise-resilient quantum circuits. L Cincio, K Rudinger, M Sarovar, P J Coles, PRX Quantum. 2110324L. Cincio, K. Rudinger, M. Sarovar, and P. J. Coles, \"Machine learning of noise-resilient quantum circuits,\" PRX Quantum, vol. 2, no. 1, p. 010324, 2021.\n\nQuantum circuit optimization with deep reinforcement learning. T F\u00f6sel, M Y Niu, F Marquardt, L Li, arXiv:2103.07585arXiv preprintT. F\u00f6sel, M. Y. Niu, F. Marquardt, and L. Li, \"Quantum circuit optimization with deep reinforcement learning,\" arXiv preprint arXiv:2103.07585, 2021.\n\nReinforcement learning for optimization of variational quantum circuit architectures. M Ostaszewski, L M Trenkwalder, W Masarczyk, E Scerri, V Dunjko, arXiv:2103.16089arXiv preprintM. Ostaszewski, L. M. Trenkwalder, W. Masarczyk, E. Scerri, and V. Dunjko, \"Reinforce- ment learning for optimization of variational quantum circuit architectures,\" arXiv preprint arXiv:2103.16089, 2021.\n\nLearn Quantum Computation using Qiskit. \"Learn Quantum Computation using Qiskit.\" https://qiskit.org/textbook/ ch-quantum-hardware/error-correction-repetition-code.html, 2020.\n", "annotations": {"author": "[{\"end\":219,\"start\":63},{\"end\":317,\"start\":220},{\"end\":325,\"start\":318},{\"end\":420,\"start\":326}]", "publisher": null, "author_last_name": "[{\"end\":73,\"start\":70},{\"end\":235,\"start\":231},{\"end\":338,\"start\":334}]", "author_first_name": "[{\"end\":69,\"start\":63},{\"end\":228,\"start\":220},{\"end\":230,\"start\":229},{\"end\":324,\"start\":318},{\"end\":333,\"start\":326}]", "author_affiliation": "[{\"end\":142,\"start\":75},{\"end\":218,\"start\":144},{\"end\":316,\"start\":237},{\"end\":419,\"start\":340}]", "title": "[{\"end\":60,\"start\":1},{\"end\":480,\"start\":421}]", "venue": null, "abstract": "[{\"end\":2861,\"start\":512}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2921,\"start\":2918},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3071,\"start\":3068},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3074,\"start\":3071},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3077,\"start\":3074},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3080,\"start\":3077},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3108,\"start\":3105},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3110,\"start\":3108},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3305,\"start\":3302},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3308,\"start\":3305},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3312,\"start\":3308},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3316,\"start\":3312},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3320,\"start\":3316},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3324,\"start\":3320},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3328,\"start\":3324},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3359,\"start\":3355},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3363,\"start\":3359},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3367,\"start\":3363},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3371,\"start\":3367},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3375,\"start\":3371},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3435,\"start\":3431},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3439,\"start\":3435},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3443,\"start\":3439},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3447,\"start\":3443},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3601,\"start\":3597},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3684,\"start\":3680},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3688,\"start\":3684},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3692,\"start\":3688},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3696,\"start\":3692},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3700,\"start\":3696},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3704,\"start\":3700},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3708,\"start\":3704},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4034,\"start\":4030},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4224,\"start\":4220},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":4227,\"start\":4224},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":4268,\"start\":4264},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":4306,\"start\":4302},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":4464,\"start\":4460},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4491,\"start\":4487},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":4494,\"start\":4491},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":4574,\"start\":4570},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":4578,\"start\":4574},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4582,\"start\":4578},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":4603,\"start\":4599},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":4607,\"start\":4603},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":4611,\"start\":4607},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4615,\"start\":4611},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":4619,\"start\":4615},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":4623,\"start\":4619},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":4627,\"start\":4623},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":4631,\"start\":4627},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":4635,\"start\":4631},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":4639,\"start\":4635},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":4643,\"start\":4639},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":4647,\"start\":4643},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":4651,\"start\":4647},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":4655,\"start\":4651},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":4659,\"start\":4655},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":4663,\"start\":4659},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":4689,\"start\":4685},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":4693,\"start\":4689},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":4697,\"start\":4693},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":4701,\"start\":4697},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":4705,\"start\":4701},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":4739,\"start\":4735},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":4743,\"start\":4739},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":4747,\"start\":4743},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":4751,\"start\":4747},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":4755,\"start\":4751},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":4759,\"start\":4755},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":4763,\"start\":4759},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":4787,\"start\":4783},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":4790,\"start\":4787},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":4793,\"start\":4790},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":4818,\"start\":4814},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":4854,\"start\":4850},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":4857,\"start\":4854},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":4881,\"start\":4877},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":4909,\"start\":4905},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7281,\"start\":7278},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":9910,\"start\":9906},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11565,\"start\":11562},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":12045,\"start\":12041},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":13064,\"start\":13060},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":15841,\"start\":15837},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":18226,\"start\":18222},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":18230,\"start\":18226},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":18234,\"start\":18230},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":18271,\"start\":18267},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":19071,\"start\":19067},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":20042,\"start\":20038},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":20790,\"start\":20786},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":24921,\"start\":24917},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":24996,\"start\":24992},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":25000,\"start\":24996},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":25004,\"start\":25000},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":25008,\"start\":25004},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":25012,\"start\":25008},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":25074,\"start\":25070},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":25077,\"start\":25074},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":25352,\"start\":25348},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":25461,\"start\":25457},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":25668,\"start\":25664},{\"attributes\":{\"ref_id\":\"b91\"},\"end\":26629,\"start\":26625},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":26632,\"start\":26629},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":27233,\"start\":27229},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":29324,\"start\":29320},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":29364,\"start\":29360},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":29917,\"start\":29913},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":31552,\"start\":31548},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":32570,\"start\":32566},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":35113,\"start\":35111},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":35175,\"start\":35173},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":35223,\"start\":35221}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":31750,\"start\":31554},{\"attributes\":{\"id\":\"fig_1\"},\"end\":31797,\"start\":31751},{\"attributes\":{\"id\":\"fig_2\"},\"end\":31843,\"start\":31798},{\"attributes\":{\"id\":\"fig_3\"},\"end\":32571,\"start\":31844},{\"attributes\":{\"id\":\"fig_4\"},\"end\":32868,\"start\":32572},{\"attributes\":{\"id\":\"fig_5\"},\"end\":32985,\"start\":32869},{\"attributes\":{\"id\":\"fig_6\"},\"end\":33389,\"start\":32986},{\"attributes\":{\"id\":\"fig_7\"},\"end\":34056,\"start\":33390},{\"attributes\":{\"id\":\"fig_8\"},\"end\":34924,\"start\":34057},{\"attributes\":{\"id\":\"fig_9\"},\"end\":34972,\"start\":34925},{\"attributes\":{\"id\":\"fig_10\"},\"end\":35282,\"start\":34973},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":36148,\"start\":35283}]", "paragraph": "[{\"end\":3250,\"start\":2880},{\"end\":3448,\"start\":3252},{\"end\":4080,\"start\":3450},{\"end\":5057,\"start\":4082},{\"end\":5846,\"start\":5059},{\"end\":5884,\"start\":5848},{\"end\":5953,\"start\":5886},{\"end\":6074,\"start\":5955},{\"end\":6346,\"start\":6076},{\"end\":7077,\"start\":6348},{\"end\":8250,\"start\":7134},{\"end\":8704,\"start\":8252},{\"end\":9395,\"start\":8706},{\"end\":10050,\"start\":9418},{\"end\":10433,\"start\":10077},{\"end\":10654,\"start\":10469},{\"end\":10847,\"start\":10656},{\"end\":11566,\"start\":10849},{\"end\":12710,\"start\":11608},{\"end\":13169,\"start\":12816},{\"end\":13389,\"start\":13236},{\"end\":13617,\"start\":13562},{\"end\":14544,\"start\":13640},{\"end\":15178,\"start\":14546},{\"end\":15314,\"start\":15180},{\"end\":15620,\"start\":15361},{\"end\":16192,\"start\":15652},{\"end\":16531,\"start\":16238},{\"end\":16585,\"start\":16533},{\"end\":16720,\"start\":16633},{\"end\":16903,\"start\":16874},{\"end\":17451,\"start\":16928},{\"end\":17768,\"start\":17498},{\"end\":17994,\"start\":17770},{\"end\":18050,\"start\":18026},{\"end\":18249,\"start\":18064},{\"end\":18338,\"start\":18251},{\"end\":18551,\"start\":18340},{\"end\":18812,\"start\":18630},{\"end\":18971,\"start\":18865},{\"end\":19111,\"start\":19002},{\"end\":19814,\"start\":19150},{\"end\":19862,\"start\":19816},{\"end\":19910,\"start\":19864},{\"end\":20043,\"start\":19912},{\"end\":20165,\"start\":20080},{\"end\":20455,\"start\":20190},{\"end\":20601,\"start\":20517},{\"end\":20715,\"start\":20630},{\"end\":21140,\"start\":20753},{\"end\":21306,\"start\":21142},{\"end\":21420,\"start\":21308},{\"end\":21631,\"start\":21422},{\"end\":21738,\"start\":21651},{\"end\":21811,\"start\":21740},{\"end\":21872,\"start\":21813},{\"end\":22772,\"start\":21894},{\"end\":23158,\"start\":22807},{\"end\":23932,\"start\":23160},{\"end\":24679,\"start\":23934},{\"end\":25312,\"start\":24681},{\"end\":25836,\"start\":25314},{\"end\":25950,\"start\":25865},{\"end\":26682,\"start\":25952},{\"end\":27501,\"start\":26708},{\"end\":28009,\"start\":27531},{\"end\":28545,\"start\":28037},{\"end\":28987,\"start\":28581},{\"end\":29196,\"start\":29015},{\"end\":30004,\"start\":29198},{\"end\":30659,\"start\":30023},{\"end\":30711,\"start\":30661},{\"end\":31553,\"start\":30713}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10076,\"start\":10051},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12815,\"start\":12711},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13235,\"start\":13170},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13561,\"start\":13390},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15651,\"start\":15621},{\"attributes\":{\"id\":\"formula_5\"},\"end\":16632,\"start\":16586},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16873,\"start\":16721},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16927,\"start\":16904},{\"attributes\":{\"id\":\"formula_8\"},\"end\":17497,\"start\":17452},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18629,\"start\":18552},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18864,\"start\":18813},{\"attributes\":{\"id\":\"formula_11\"},\"end\":19001,\"start\":18972},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20189,\"start\":20166},{\"attributes\":{\"id\":\"formula_13\"},\"end\":20516,\"start\":20456}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21718,\"start\":21711}]", "section_header": "[{\"end\":2878,\"start\":2863},{\"end\":7103,\"start\":7080},{\"end\":7132,\"start\":7106},{\"end\":9416,\"start\":9398},{\"end\":10467,\"start\":10436},{\"end\":11606,\"start\":11569},{\"end\":13638,\"start\":13620},{\"end\":15359,\"start\":15317},{\"end\":16236,\"start\":16195},{\"end\":18024,\"start\":17997},{\"attributes\":{\"n\":\"1.\"},\"end\":18062,\"start\":18053},{\"attributes\":{\"n\":\"2.\"},\"end\":19148,\"start\":19114},{\"attributes\":{\"n\":\"3.\"},\"end\":20078,\"start\":20046},{\"attributes\":{\"n\":\"4.\"},\"end\":20628,\"start\":20604},{\"attributes\":{\"n\":\"5.\"},\"end\":20751,\"start\":20718},{\"attributes\":{\"n\":\"6.\"},\"end\":21649,\"start\":21634},{\"attributes\":{\"n\":\"2.\"},\"end\":21892,\"start\":21875},{\"end\":22805,\"start\":22775},{\"end\":25863,\"start\":25839},{\"end\":26706,\"start\":26685},{\"end\":27529,\"start\":27504},{\"end\":28035,\"start\":28012},{\"end\":28579,\"start\":28548},{\"end\":29013,\"start\":28990},{\"end\":30021,\"start\":30007},{\"end\":31563,\"start\":31555},{\"end\":31760,\"start\":31752},{\"end\":31807,\"start\":31799},{\"end\":31846,\"start\":31845},{\"end\":32878,\"start\":32870},{\"end\":32995,\"start\":32987},{\"end\":33402,\"start\":33391},{\"end\":34069,\"start\":34058},{\"end\":35293,\"start\":35284}]", "table": "[{\"end\":36148,\"start\":36070}]", "figure_caption": "[{\"end\":31750,\"start\":31565},{\"end\":31797,\"start\":31762},{\"end\":31843,\"start\":31809},{\"end\":32571,\"start\":31847},{\"end\":32868,\"start\":32574},{\"end\":32985,\"start\":32880},{\"end\":33389,\"start\":32997},{\"end\":34056,\"start\":33405},{\"end\":34924,\"start\":34071},{\"end\":34972,\"start\":34927},{\"end\":35282,\"start\":34975},{\"end\":36070,\"start\":35295}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14071,\"start\":14063},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17266,\"start\":17260},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17992,\"start\":17986},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":22044,\"start\":22036},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":22434,\"start\":22426},{\"end\":23687,\"start\":23678},{\"end\":23800,\"start\":23791},{\"end\":24854,\"start\":24845}]", "bib_author_first_name": "[{\"end\":36546,\"start\":36545},{\"end\":36548,\"start\":36547},{\"end\":36558,\"start\":36557},{\"end\":36560,\"start\":36559},{\"end\":36724,\"start\":36723},{\"end\":36732,\"start\":36731},{\"end\":36747,\"start\":36746},{\"end\":36757,\"start\":36756},{\"end\":36759,\"start\":36758},{\"end\":36767,\"start\":36766},{\"end\":36777,\"start\":36776},{\"end\":36779,\"start\":36778},{\"end\":36792,\"start\":36791},{\"end\":36802,\"start\":36801},{\"end\":36816,\"start\":36815},{\"end\":36818,\"start\":36817},{\"end\":36831,\"start\":36830},{\"end\":36844,\"start\":36843},{\"end\":36856,\"start\":36855},{\"end\":36867,\"start\":36866},{\"end\":36876,\"start\":36875},{\"end\":36890,\"start\":36889},{\"end\":36898,\"start\":36897},{\"end\":36909,\"start\":36908},{\"end\":36921,\"start\":36920},{\"end\":36929,\"start\":36928},{\"end\":37365,\"start\":37364},{\"end\":37382,\"start\":37381},{\"end\":37396,\"start\":37395},{\"end\":37406,\"start\":37405},{\"end\":37418,\"start\":37417},{\"end\":37427,\"start\":37426},{\"end\":37438,\"start\":37437},{\"end\":37446,\"start\":37445},{\"end\":37458,\"start\":37457},{\"end\":37470,\"start\":37469},{\"end\":37808,\"start\":37807},{\"end\":37810,\"start\":37809},{\"end\":37819,\"start\":37818},{\"end\":37827,\"start\":37826},{\"end\":37842,\"start\":37841},{\"end\":37856,\"start\":37855},{\"end\":37870,\"start\":37869},{\"end\":37877,\"start\":37876},{\"end\":38171,\"start\":38170},{\"end\":38186,\"start\":38185},{\"end\":38199,\"start\":38198},{\"end\":38207,\"start\":38206},{\"end\":38216,\"start\":38215},{\"end\":38547,\"start\":38546},{\"end\":38557,\"start\":38556},{\"end\":38566,\"start\":38565},{\"end\":38568,\"start\":38567},{\"end\":38580,\"start\":38579},{\"end\":38588,\"start\":38587},{\"end\":38597,\"start\":38596},{\"end\":38618,\"start\":38617},{\"end\":38635,\"start\":38634},{\"end\":38649,\"start\":38648},{\"end\":38667,\"start\":38666},{\"end\":39011,\"start\":39010},{\"end\":39021,\"start\":39020},{\"end\":39038,\"start\":39037},{\"end\":39050,\"start\":39049},{\"end\":39064,\"start\":39063},{\"end\":39073,\"start\":39072},{\"end\":39081,\"start\":39080},{\"end\":39091,\"start\":39090},{\"end\":39100,\"start\":39099},{\"end\":39107,\"start\":39106},{\"end\":39419,\"start\":39418},{\"end\":39428,\"start\":39427},{\"end\":39430,\"start\":39429},{\"end\":39437,\"start\":39436},{\"end\":39445,\"start\":39444},{\"end\":39457,\"start\":39456},{\"end\":39472,\"start\":39471},{\"end\":39763,\"start\":39762},{\"end\":39772,\"start\":39771},{\"end\":39786,\"start\":39785},{\"end\":39795,\"start\":39794},{\"end\":40070,\"start\":40069},{\"end\":40072,\"start\":40071},{\"end\":40079,\"start\":40078},{\"end\":40088,\"start\":40087},{\"end\":40090,\"start\":40089},{\"end\":40105,\"start\":40104},{\"end\":40369,\"start\":40368},{\"end\":40375,\"start\":40374},{\"end\":40665,\"start\":40661},{\"end\":40674,\"start\":40673},{\"end\":40681,\"start\":40680},{\"end\":40692,\"start\":40688},{\"end\":40700,\"start\":40699},{\"end\":41046,\"start\":41045},{\"end\":41067,\"start\":41066},{\"end\":41077,\"start\":41076},{\"end\":41092,\"start\":41091},{\"end\":41102,\"start\":41101},{\"end\":41104,\"start\":41103},{\"end\":41442,\"start\":41441},{\"end\":41448,\"start\":41447},{\"end\":41454,\"start\":41453},{\"end\":41461,\"start\":41460},{\"end\":41469,\"start\":41468},{\"end\":41477,\"start\":41476},{\"end\":41790,\"start\":41789},{\"end\":41804,\"start\":41803},{\"end\":41817,\"start\":41816},{\"end\":41832,\"start\":41831},{\"end\":42094,\"start\":42093},{\"end\":42104,\"start\":42103},{\"end\":42116,\"start\":42115},{\"end\":42118,\"start\":42117},{\"end\":42128,\"start\":42127},{\"end\":42436,\"start\":42435},{\"end\":42446,\"start\":42445},{\"end\":42644,\"start\":42643},{\"end\":42646,\"start\":42645},{\"end\":42657,\"start\":42656},{\"end\":42669,\"start\":42668},{\"end\":42679,\"start\":42678},{\"end\":42681,\"start\":42680},{\"end\":42692,\"start\":42691},{\"end\":42953,\"start\":42952},{\"end\":42955,\"start\":42954},{\"end\":42966,\"start\":42965},{\"end\":42981,\"start\":42980},{\"end\":43256,\"start\":43255},{\"end\":43258,\"start\":43257},{\"end\":43269,\"start\":43268},{\"end\":43280,\"start\":43279},{\"end\":43282,\"start\":43281},{\"end\":43291,\"start\":43290},{\"end\":43293,\"start\":43292},{\"end\":43555,\"start\":43554},{\"end\":43562,\"start\":43561},{\"end\":43571,\"start\":43570},{\"end\":43824,\"start\":43823},{\"end\":43834,\"start\":43833},{\"end\":43847,\"start\":43846},{\"end\":43849,\"start\":43848},{\"end\":43860,\"start\":43859},{\"end\":43862,\"start\":43861},{\"end\":43870,\"start\":43869},{\"end\":43881,\"start\":43880},{\"end\":43890,\"start\":43889},{\"end\":43899,\"start\":43898},{\"end\":44210,\"start\":44209},{\"end\":44220,\"start\":44219},{\"end\":44234,\"start\":44233},{\"end\":44246,\"start\":44245},{\"end\":44258,\"start\":44257},{\"end\":44260,\"start\":44259},{\"end\":44270,\"start\":44269},{\"end\":44543,\"start\":44542},{\"end\":44551,\"start\":44550},{\"end\":44553,\"start\":44552},{\"end\":44778,\"start\":44777},{\"end\":44787,\"start\":44786},{\"end\":44796,\"start\":44795},{\"end\":44804,\"start\":44803},{\"end\":45056,\"start\":45055},{\"end\":45063,\"start\":45062},{\"end\":45071,\"start\":45070},{\"end\":45080,\"start\":45079},{\"end\":45086,\"start\":45085},{\"end\":45338,\"start\":45337},{\"end\":45346,\"start\":45345},{\"end\":45359,\"start\":45358},{\"end\":45369,\"start\":45368},{\"end\":45371,\"start\":45370},{\"end\":45801,\"start\":45800},{\"end\":45810,\"start\":45809},{\"end\":45817,\"start\":45816},{\"end\":45823,\"start\":45822},{\"end\":45834,\"start\":45830},{\"end\":46262,\"start\":46261},{\"end\":46274,\"start\":46273},{\"end\":46284,\"start\":46283},{\"end\":46296,\"start\":46295},{\"end\":46552,\"start\":46551},{\"end\":46560,\"start\":46559},{\"end\":46562,\"start\":46561},{\"end\":46570,\"start\":46569},{\"end\":46578,\"start\":46577},{\"end\":46580,\"start\":46579},{\"end\":46586,\"start\":46585},{\"end\":46848,\"start\":46847},{\"end\":46855,\"start\":46854},{\"end\":46863,\"start\":46862},{\"end\":46872,\"start\":46871},{\"end\":46879,\"start\":46878},{\"end\":47110,\"start\":47109},{\"end\":47120,\"start\":47119},{\"end\":47122,\"start\":47121},{\"end\":47132,\"start\":47131},{\"end\":47341,\"start\":47340},{\"end\":47343,\"start\":47342},{\"end\":47353,\"start\":47352},{\"end\":47561,\"start\":47560},{\"end\":47570,\"start\":47569},{\"end\":47578,\"start\":47577},{\"end\":47589,\"start\":47588},{\"end\":47598,\"start\":47597},{\"end\":47600,\"start\":47599},{\"end\":47610,\"start\":47609},{\"end\":47621,\"start\":47620},{\"end\":47631,\"start\":47630},{\"end\":47640,\"start\":47639},{\"end\":47642,\"start\":47641},{\"end\":47653,\"start\":47652},{\"end\":47655,\"start\":47654},{\"end\":48017,\"start\":48016},{\"end\":48019,\"start\":48018},{\"end\":48269,\"start\":48268},{\"end\":48271,\"start\":48270},{\"end\":48514,\"start\":48513},{\"end\":48525,\"start\":48524},{\"end\":48536,\"start\":48535},{\"end\":48551,\"start\":48547},{\"end\":48562,\"start\":48558},{\"end\":48570,\"start\":48569},{\"end\":48572,\"start\":48571},{\"end\":48580,\"start\":48579},{\"end\":48596,\"start\":48595},{\"end\":48598,\"start\":48597},{\"end\":48974,\"start\":48973},{\"end\":48985,\"start\":48981},{\"end\":48993,\"start\":48992},{\"end\":49001,\"start\":49000},{\"end\":49012,\"start\":49011},{\"end\":49014,\"start\":49013},{\"end\":49311,\"start\":49310},{\"end\":49320,\"start\":49319},{\"end\":49333,\"start\":49332},{\"end\":49532,\"start\":49531},{\"end\":49534,\"start\":49533},{\"end\":49542,\"start\":49541},{\"end\":49552,\"start\":49548},{\"end\":49554,\"start\":49553},{\"end\":49734,\"start\":49733},{\"end\":49745,\"start\":49744},{\"end\":49755,\"start\":49754},{\"end\":49767,\"start\":49766},{\"end\":50013,\"start\":50012},{\"end\":50026,\"start\":50025},{\"end\":50028,\"start\":50027},{\"end\":50037,\"start\":50036},{\"end\":50039,\"start\":50038},{\"end\":50284,\"start\":50283},{\"end\":50294,\"start\":50293},{\"end\":50306,\"start\":50305},{\"end\":50315,\"start\":50314},{\"end\":50539,\"start\":50538},{\"end\":50551,\"start\":50550},{\"end\":50553,\"start\":50552},{\"end\":50565,\"start\":50564},{\"end\":50574,\"start\":50573},{\"end\":50576,\"start\":50575},{\"end\":50586,\"start\":50585},{\"end\":50597,\"start\":50596},{\"end\":50599,\"start\":50598},{\"end\":50607,\"start\":50606},{\"end\":50609,\"start\":50608},{\"end\":50841,\"start\":50840},{\"end\":50850,\"start\":50849},{\"end\":51153,\"start\":51152},{\"end\":51166,\"start\":51165},{\"end\":51175,\"start\":51174},{\"end\":51183,\"start\":51182},{\"end\":51477,\"start\":51476},{\"end\":51485,\"start\":51484},{\"end\":51487,\"start\":51486},{\"end\":51498,\"start\":51497},{\"end\":51507,\"start\":51506},{\"end\":51517,\"start\":51516},{\"end\":51782,\"start\":51781},{\"end\":51796,\"start\":51795},{\"end\":51807,\"start\":51806},{\"end\":51809,\"start\":51808},{\"end\":51821,\"start\":51820},{\"end\":51823,\"start\":51822},{\"end\":52115,\"start\":52114},{\"end\":52133,\"start\":52132},{\"end\":52146,\"start\":52145},{\"end\":52160,\"start\":52159},{\"end\":52470,\"start\":52469},{\"end\":52479,\"start\":52478},{\"end\":52493,\"start\":52492},{\"end\":52501,\"start\":52500},{\"end\":52763,\"start\":52762},{\"end\":52765,\"start\":52764},{\"end\":52774,\"start\":52773},{\"end\":52784,\"start\":52783},{\"end\":52786,\"start\":52785},{\"end\":52797,\"start\":52796},{\"end\":52805,\"start\":52804},{\"end\":52812,\"start\":52811},{\"end\":52820,\"start\":52819},{\"end\":52826,\"start\":52825},{\"end\":53147,\"start\":53146},{\"end\":53149,\"start\":53148},{\"end\":53160,\"start\":53156},{\"end\":53172,\"start\":53168},{\"end\":53184,\"start\":53180},{\"end\":53489,\"start\":53488},{\"end\":53491,\"start\":53490},{\"end\":53502,\"start\":53498},{\"end\":53509,\"start\":53508},{\"end\":53518,\"start\":53517},{\"end\":53524,\"start\":53523},{\"end\":53929,\"start\":53928},{\"end\":53931,\"start\":53930},{\"end\":53937,\"start\":53936},{\"end\":53945,\"start\":53944},{\"end\":53953,\"start\":53952},{\"end\":53960,\"start\":53959},{\"end\":53968,\"start\":53967},{\"end\":53976,\"start\":53975},{\"end\":53985,\"start\":53984},{\"end\":53998,\"start\":53997},{\"end\":54001,\"start\":53999},{\"end\":54011,\"start\":54010},{\"end\":54013,\"start\":54012},{\"end\":54482,\"start\":54481},{\"end\":54484,\"start\":54483},{\"end\":54493,\"start\":54492},{\"end\":54500,\"start\":54499},{\"end\":54510,\"start\":54509},{\"end\":54518,\"start\":54517},{\"end\":54524,\"start\":54523},{\"end\":54532,\"start\":54531},{\"end\":54538,\"start\":54537},{\"end\":54834,\"start\":54833},{\"end\":54836,\"start\":54835},{\"end\":54847,\"start\":54843},{\"end\":54854,\"start\":54853},{\"end\":54863,\"start\":54862},{\"end\":54869,\"start\":54868},{\"end\":55091,\"start\":55090},{\"end\":55104,\"start\":55103},{\"end\":55106,\"start\":55105},{\"end\":55118,\"start\":55117},{\"end\":55125,\"start\":55124},{\"end\":55136,\"start\":55135},{\"end\":55147,\"start\":55146},{\"end\":55384,\"start\":55380},{\"end\":55403,\"start\":55402},{\"end\":55641,\"start\":55640},{\"end\":55643,\"start\":55642},{\"end\":55652,\"start\":55651},{\"end\":55662,\"start\":55661},{\"end\":55664,\"start\":55663},{\"end\":55675,\"start\":55674},{\"end\":55682,\"start\":55681},{\"end\":55690,\"start\":55689},{\"end\":55696,\"start\":55695},{\"end\":55704,\"start\":55703},{\"end\":56016,\"start\":56015},{\"end\":56026,\"start\":56025},{\"end\":56036,\"start\":56035},{\"end\":56325,\"start\":56324},{\"end\":56333,\"start\":56332},{\"end\":56339,\"start\":56338},{\"end\":56345,\"start\":56344},{\"end\":56621,\"start\":56620},{\"end\":56631,\"start\":56630},{\"end\":56893,\"start\":56892},{\"end\":56895,\"start\":56894},{\"end\":56906,\"start\":56902},{\"end\":56908,\"start\":56907},{\"end\":56916,\"start\":56915},{\"end\":56925,\"start\":56921},{\"end\":56933,\"start\":56932},{\"end\":56942,\"start\":56938},{\"end\":57204,\"start\":57203},{\"end\":57216,\"start\":57215},{\"end\":57698,\"start\":57697},{\"end\":57707,\"start\":57706},{\"end\":57709,\"start\":57708},{\"end\":57724,\"start\":57723},{\"end\":57726,\"start\":57725},{\"end\":57737,\"start\":57736},{\"end\":57739,\"start\":57738},{\"end\":57750,\"start\":57749},{\"end\":58077,\"start\":58073},{\"end\":58085,\"start\":58084},{\"end\":58094,\"start\":58093},{\"end\":58104,\"start\":58103},{\"end\":58116,\"start\":58115},{\"end\":58521,\"start\":58520},{\"end\":58527,\"start\":58526},{\"end\":58534,\"start\":58533},{\"end\":58541,\"start\":58540},{\"end\":58796,\"start\":58795},{\"end\":58806,\"start\":58805},{\"end\":58815,\"start\":58814},{\"end\":59070,\"start\":59069},{\"end\":59079,\"start\":59078},{\"end\":59089,\"start\":59088},{\"end\":59101,\"start\":59100},{\"end\":59103,\"start\":59102},{\"end\":59114,\"start\":59113},{\"end\":59317,\"start\":59316},{\"end\":59554,\"start\":59553},{\"end\":59564,\"start\":59563},{\"end\":59575,\"start\":59574},{\"end\":59585,\"start\":59584},{\"end\":59594,\"start\":59593},{\"end\":59926,\"start\":59922},{\"end\":59928,\"start\":59927},{\"end\":59936,\"start\":59935},{\"end\":59942,\"start\":59941},{\"end\":59944,\"start\":59943},{\"end\":59955,\"start\":59951},{\"end\":59963,\"start\":59962},{\"end\":59965,\"start\":59964},{\"end\":59980,\"start\":59979},{\"end\":59989,\"start\":59985},{\"end\":60309,\"start\":60308},{\"end\":60318,\"start\":60317},{\"end\":60328,\"start\":60327},{\"end\":60336,\"start\":60335},{\"end\":60345,\"start\":60344},{\"end\":60592,\"start\":60591},{\"end\":60594,\"start\":60593},{\"end\":60604,\"start\":60603},{\"end\":60608,\"start\":60605},{\"end\":60619,\"start\":60615},{\"end\":60845,\"start\":60844},{\"end\":60847,\"start\":60846},{\"end\":60852,\"start\":60850},{\"end\":60860,\"start\":60859},{\"end\":61092,\"start\":61091},{\"end\":61094,\"start\":61093},{\"end\":61335,\"start\":61334},{\"end\":61347,\"start\":61346},{\"end\":61357,\"start\":61356},{\"end\":61369,\"start\":61368},{\"end\":61380,\"start\":61379},{\"end\":61614,\"start\":61613},{\"end\":61616,\"start\":61615},{\"end\":61627,\"start\":61626},{\"end\":61777,\"start\":61776},{\"end\":62012,\"start\":62011},{\"end\":62024,\"start\":62023},{\"end\":62297,\"start\":62296},{\"end\":62299,\"start\":62298},{\"end\":62309,\"start\":62308},{\"end\":62523,\"start\":62522},{\"end\":62533,\"start\":62532},{\"end\":62542,\"start\":62541},{\"end\":62551,\"start\":62550},{\"end\":62560,\"start\":62559},{\"end\":62572,\"start\":62571},{\"end\":62582,\"start\":62581},{\"end\":62593,\"start\":62592},{\"end\":62600,\"start\":62599},{\"end\":62614,\"start\":62613},{\"end\":62624,\"start\":62623},{\"end\":62637,\"start\":62636},{\"end\":62645,\"start\":62644},{\"end\":62653,\"start\":62652},{\"end\":62663,\"start\":62662},{\"end\":62673,\"start\":62672},{\"end\":62683,\"start\":62682},{\"end\":62699,\"start\":62698},{\"end\":62710,\"start\":62709},{\"end\":62718,\"start\":62717},{\"end\":62725,\"start\":62724},{\"end\":63495,\"start\":63494},{\"end\":63656,\"start\":63655},{\"end\":63668,\"start\":63667},{\"end\":63678,\"start\":63677},{\"end\":63692,\"start\":63691},{\"end\":63705,\"start\":63704},{\"end\":63717,\"start\":63716},{\"end\":63725,\"start\":63724},{\"end\":63949,\"start\":63948},{\"end\":63951,\"start\":63950},{\"end\":63963,\"start\":63962},{\"end\":63965,\"start\":63964},{\"end\":64276,\"start\":64275},{\"end\":64293,\"start\":64292},{\"end\":64556,\"start\":64555},{\"end\":64562,\"start\":64561},{\"end\":64571,\"start\":64570},{\"end\":64581,\"start\":64577},{\"end\":64590,\"start\":64589},{\"end\":64882,\"start\":64878},{\"end\":64894,\"start\":64890},{\"end\":64903,\"start\":64902},{\"end\":64912,\"start\":64911},{\"end\":65165,\"start\":65161},{\"end\":65171,\"start\":65170},{\"end\":65173,\"start\":65172},{\"end\":65182,\"start\":65181},{\"end\":65184,\"start\":65183},{\"end\":65193,\"start\":65192},{\"end\":65458,\"start\":65454},{\"end\":65470,\"start\":65466},{\"end\":65479,\"start\":65478},{\"end\":65488,\"start\":65487},{\"end\":65726,\"start\":65725},{\"end\":65741,\"start\":65740},{\"end\":65750,\"start\":65749},{\"end\":65986,\"start\":65985},{\"end\":65988,\"start\":65987},{\"end\":66215,\"start\":66214},{\"end\":66224,\"start\":66223},{\"end\":66226,\"start\":66225},{\"end\":66435,\"start\":66434},{\"end\":66445,\"start\":66444},{\"end\":66457,\"start\":66456},{\"end\":66468,\"start\":66467},{\"end\":66470,\"start\":66469},{\"end\":66717,\"start\":66716},{\"end\":66726,\"start\":66725},{\"end\":66728,\"start\":66727},{\"end\":66735,\"start\":66734},{\"end\":66748,\"start\":66747},{\"end\":67021,\"start\":67020},{\"end\":67036,\"start\":67035},{\"end\":67038,\"start\":67037},{\"end\":67053,\"start\":67052},{\"end\":67066,\"start\":67065},{\"end\":67076,\"start\":67075}]", "bib_author_last_name": "[{\"end\":36555,\"start\":36549},{\"end\":36566,\"start\":36561},{\"end\":36729,\"start\":36725},{\"end\":36744,\"start\":36733},{\"end\":36754,\"start\":36748},{\"end\":36764,\"start\":36760},{\"end\":36774,\"start\":36768},{\"end\":36789,\"start\":36780},{\"end\":36799,\"start\":36793},{\"end\":36813,\"start\":36803},{\"end\":36828,\"start\":36819},{\"end\":36841,\"start\":36832},{\"end\":36853,\"start\":36845},{\"end\":36864,\"start\":36857},{\"end\":36873,\"start\":36868},{\"end\":36887,\"start\":36877},{\"end\":36895,\"start\":36891},{\"end\":36906,\"start\":36899},{\"end\":36918,\"start\":36910},{\"end\":36926,\"start\":36922},{\"end\":36938,\"start\":36930},{\"end\":37379,\"start\":37366},{\"end\":37393,\"start\":37383},{\"end\":37403,\"start\":37397},{\"end\":37415,\"start\":37407},{\"end\":37424,\"start\":37419},{\"end\":37435,\"start\":37428},{\"end\":37443,\"start\":37439},{\"end\":37455,\"start\":37447},{\"end\":37467,\"start\":37459},{\"end\":37478,\"start\":37471},{\"end\":37816,\"start\":37811},{\"end\":37824,\"start\":37820},{\"end\":37839,\"start\":37828},{\"end\":37853,\"start\":37843},{\"end\":37867,\"start\":37857},{\"end\":37874,\"start\":37871},{\"end\":37886,\"start\":37878},{\"end\":38183,\"start\":38172},{\"end\":38196,\"start\":38187},{\"end\":38204,\"start\":38200},{\"end\":38213,\"start\":38208},{\"end\":38223,\"start\":38217},{\"end\":38554,\"start\":38548},{\"end\":38563,\"start\":38558},{\"end\":38577,\"start\":38569},{\"end\":38585,\"start\":38581},{\"end\":38594,\"start\":38589},{\"end\":38615,\"start\":38598},{\"end\":38632,\"start\":38619},{\"end\":38646,\"start\":38636},{\"end\":38664,\"start\":38650},{\"end\":38675,\"start\":38668},{\"end\":39018,\"start\":39012},{\"end\":39035,\"start\":39022},{\"end\":39047,\"start\":39039},{\"end\":39061,\"start\":39051},{\"end\":39070,\"start\":39065},{\"end\":39078,\"start\":39074},{\"end\":39088,\"start\":39082},{\"end\":39097,\"start\":39092},{\"end\":39104,\"start\":39101},{\"end\":39114,\"start\":39108},{\"end\":39425,\"start\":39420},{\"end\":39434,\"start\":39431},{\"end\":39442,\"start\":39438},{\"end\":39454,\"start\":39446},{\"end\":39469,\"start\":39458},{\"end\":39478,\"start\":39473},{\"end\":39769,\"start\":39764},{\"end\":39783,\"start\":39773},{\"end\":39792,\"start\":39787},{\"end\":39805,\"start\":39796},{\"end\":40076,\"start\":40073},{\"end\":40085,\"start\":40080},{\"end\":40102,\"start\":40091},{\"end\":40111,\"start\":40106},{\"end\":40372,\"start\":40370},{\"end\":40380,\"start\":40376},{\"end\":40671,\"start\":40666},{\"end\":40678,\"start\":40675},{\"end\":40686,\"start\":40682},{\"end\":40697,\"start\":40693},{\"end\":40705,\"start\":40701},{\"end\":41064,\"start\":41047},{\"end\":41074,\"start\":41068},{\"end\":41089,\"start\":41078},{\"end\":41099,\"start\":41093},{\"end\":41112,\"start\":41105},{\"end\":41445,\"start\":41443},{\"end\":41451,\"start\":41449},{\"end\":41458,\"start\":41455},{\"end\":41466,\"start\":41462},{\"end\":41474,\"start\":41470},{\"end\":41482,\"start\":41478},{\"end\":41801,\"start\":41791},{\"end\":41814,\"start\":41805},{\"end\":41829,\"start\":41818},{\"end\":41840,\"start\":41833},{\"end\":42101,\"start\":42095},{\"end\":42113,\"start\":42105},{\"end\":42125,\"start\":42119},{\"end\":42136,\"start\":42129},{\"end\":42443,\"start\":42437},{\"end\":42454,\"start\":42447},{\"end\":42654,\"start\":42647},{\"end\":42666,\"start\":42658},{\"end\":42676,\"start\":42670},{\"end\":42689,\"start\":42682},{\"end\":42698,\"start\":42693},{\"end\":42963,\"start\":42956},{\"end\":42978,\"start\":42967},{\"end\":42993,\"start\":42982},{\"end\":43266,\"start\":43259},{\"end\":43277,\"start\":43270},{\"end\":43288,\"start\":43283},{\"end\":43301,\"start\":43294},{\"end\":43559,\"start\":43556},{\"end\":43568,\"start\":43563},{\"end\":43575,\"start\":43572},{\"end\":43831,\"start\":43825},{\"end\":43844,\"start\":43835},{\"end\":43857,\"start\":43850},{\"end\":43867,\"start\":43863},{\"end\":43878,\"start\":43871},{\"end\":43887,\"start\":43882},{\"end\":43896,\"start\":43891},{\"end\":43907,\"start\":43900},{\"end\":44217,\"start\":44211},{\"end\":44231,\"start\":44221},{\"end\":44243,\"start\":44235},{\"end\":44255,\"start\":44247},{\"end\":44267,\"start\":44261},{\"end\":44278,\"start\":44271},{\"end\":44548,\"start\":44544},{\"end\":44556,\"start\":44554},{\"end\":44784,\"start\":44779},{\"end\":44793,\"start\":44788},{\"end\":44801,\"start\":44797},{\"end\":44811,\"start\":44805},{\"end\":45060,\"start\":45057},{\"end\":45068,\"start\":45064},{\"end\":45077,\"start\":45072},{\"end\":45083,\"start\":45081},{\"end\":45091,\"start\":45087},{\"end\":45343,\"start\":45339},{\"end\":45356,\"start\":45347},{\"end\":45366,\"start\":45360},{\"end\":45374,\"start\":45372},{\"end\":45807,\"start\":45802},{\"end\":45814,\"start\":45811},{\"end\":45820,\"start\":45818},{\"end\":45828,\"start\":45824},{\"end\":45838,\"start\":45835},{\"end\":46271,\"start\":46263},{\"end\":46281,\"start\":46275},{\"end\":46293,\"start\":46285},{\"end\":46303,\"start\":46297},{\"end\":46557,\"start\":46553},{\"end\":46567,\"start\":46563},{\"end\":46575,\"start\":46571},{\"end\":46583,\"start\":46581},{\"end\":46591,\"start\":46587},{\"end\":46852,\"start\":46849},{\"end\":46860,\"start\":46856},{\"end\":46869,\"start\":46864},{\"end\":46876,\"start\":46873},{\"end\":46882,\"start\":46880},{\"end\":47117,\"start\":47111},{\"end\":47129,\"start\":47123},{\"end\":47139,\"start\":47133},{\"end\":47350,\"start\":47344},{\"end\":47363,\"start\":47354},{\"end\":47567,\"start\":47562},{\"end\":47575,\"start\":47571},{\"end\":47586,\"start\":47579},{\"end\":47595,\"start\":47590},{\"end\":47607,\"start\":47601},{\"end\":47618,\"start\":47611},{\"end\":47628,\"start\":47622},{\"end\":47637,\"start\":47632},{\"end\":47650,\"start\":47643},{\"end\":47661,\"start\":47656},{\"end\":48024,\"start\":48020},{\"end\":48278,\"start\":48272},{\"end\":48522,\"start\":48515},{\"end\":48533,\"start\":48526},{\"end\":48545,\"start\":48537},{\"end\":48556,\"start\":48552},{\"end\":48567,\"start\":48563},{\"end\":48577,\"start\":48573},{\"end\":48593,\"start\":48581},{\"end\":48611,\"start\":48599},{\"end\":48979,\"start\":48975},{\"end\":48990,\"start\":48986},{\"end\":48998,\"start\":48994},{\"end\":49009,\"start\":49002},{\"end\":49020,\"start\":49015},{\"end\":49317,\"start\":49312},{\"end\":49330,\"start\":49321},{\"end\":49341,\"start\":49334},{\"end\":49539,\"start\":49535},{\"end\":49546,\"start\":49543},{\"end\":49559,\"start\":49555},{\"end\":49742,\"start\":49735},{\"end\":49752,\"start\":49746},{\"end\":49764,\"start\":49756},{\"end\":49773,\"start\":49768},{\"end\":50023,\"start\":50014},{\"end\":50034,\"start\":50029},{\"end\":50047,\"start\":50040},{\"end\":50291,\"start\":50285},{\"end\":50303,\"start\":50295},{\"end\":50312,\"start\":50307},{\"end\":50321,\"start\":50316},{\"end\":50548,\"start\":50540},{\"end\":50562,\"start\":50554},{\"end\":50571,\"start\":50566},{\"end\":50583,\"start\":50577},{\"end\":50594,\"start\":50587},{\"end\":50604,\"start\":50600},{\"end\":50618,\"start\":50610},{\"end\":50847,\"start\":50842},{\"end\":50856,\"start\":50851},{\"end\":51163,\"start\":51154},{\"end\":51172,\"start\":51167},{\"end\":51180,\"start\":51176},{\"end\":51194,\"start\":51184},{\"end\":51482,\"start\":51478},{\"end\":51495,\"start\":51488},{\"end\":51504,\"start\":51499},{\"end\":51514,\"start\":51508},{\"end\":51526,\"start\":51518},{\"end\":51793,\"start\":51783},{\"end\":51804,\"start\":51797},{\"end\":51818,\"start\":51810},{\"end\":51831,\"start\":51824},{\"end\":52130,\"start\":52116},{\"end\":52143,\"start\":52134},{\"end\":52157,\"start\":52147},{\"end\":52166,\"start\":52161},{\"end\":52476,\"start\":52471},{\"end\":52490,\"start\":52480},{\"end\":52498,\"start\":52494},{\"end\":52504,\"start\":52502},{\"end\":52771,\"start\":52766},{\"end\":52781,\"start\":52775},{\"end\":52794,\"start\":52787},{\"end\":52802,\"start\":52798},{\"end\":52809,\"start\":52806},{\"end\":52817,\"start\":52813},{\"end\":52823,\"start\":52821},{\"end\":52831,\"start\":52827},{\"end\":53154,\"start\":53150},{\"end\":53166,\"start\":53161},{\"end\":53178,\"start\":53173},{\"end\":53188,\"start\":53185},{\"end\":53496,\"start\":53492},{\"end\":53506,\"start\":53503},{\"end\":53515,\"start\":53510},{\"end\":53521,\"start\":53519},{\"end\":53528,\"start\":53525},{\"end\":53934,\"start\":53932},{\"end\":53942,\"start\":53938},{\"end\":53950,\"start\":53946},{\"end\":53957,\"start\":53954},{\"end\":53965,\"start\":53961},{\"end\":53973,\"start\":53969},{\"end\":53982,\"start\":53977},{\"end\":53995,\"start\":53986},{\"end\":54008,\"start\":54002},{\"end\":54016,\"start\":54014},{\"end\":54490,\"start\":54485},{\"end\":54497,\"start\":54494},{\"end\":54507,\"start\":54501},{\"end\":54515,\"start\":54511},{\"end\":54521,\"start\":54519},{\"end\":54529,\"start\":54525},{\"end\":54535,\"start\":54533},{\"end\":54543,\"start\":54539},{\"end\":54841,\"start\":54837},{\"end\":54851,\"start\":54848},{\"end\":54860,\"start\":54855},{\"end\":54866,\"start\":54864},{\"end\":54873,\"start\":54870},{\"end\":55101,\"start\":55092},{\"end\":55115,\"start\":55107},{\"end\":55122,\"start\":55119},{\"end\":55133,\"start\":55126},{\"end\":55144,\"start\":55137},{\"end\":55154,\"start\":55148},{\"end\":55400,\"start\":55385},{\"end\":55412,\"start\":55404},{\"end\":55649,\"start\":55644},{\"end\":55659,\"start\":55653},{\"end\":55672,\"start\":55665},{\"end\":55679,\"start\":55676},{\"end\":55687,\"start\":55683},{\"end\":55693,\"start\":55691},{\"end\":55701,\"start\":55697},{\"end\":55707,\"start\":55705},{\"end\":56023,\"start\":56017},{\"end\":56033,\"start\":56027},{\"end\":56044,\"start\":56037},{\"end\":56330,\"start\":56326},{\"end\":56336,\"start\":56334},{\"end\":56342,\"start\":56340},{\"end\":56351,\"start\":56346},{\"end\":56628,\"start\":56622},{\"end\":56640,\"start\":56632},{\"end\":56900,\"start\":56896},{\"end\":56913,\"start\":56909},{\"end\":56919,\"start\":56917},{\"end\":56930,\"start\":56926},{\"end\":56936,\"start\":56934},{\"end\":56947,\"start\":56943},{\"end\":57213,\"start\":57205},{\"end\":57219,\"start\":57217},{\"end\":57704,\"start\":57699},{\"end\":57721,\"start\":57710},{\"end\":57734,\"start\":57727},{\"end\":57747,\"start\":57740},{\"end\":57757,\"start\":57751},{\"end\":58082,\"start\":58078},{\"end\":58091,\"start\":58086},{\"end\":58101,\"start\":58095},{\"end\":58113,\"start\":58105},{\"end\":58123,\"start\":58117},{\"end\":58524,\"start\":58522},{\"end\":58531,\"start\":58528},{\"end\":58538,\"start\":58535},{\"end\":58546,\"start\":58542},{\"end\":58803,\"start\":58797},{\"end\":58812,\"start\":58807},{\"end\":58822,\"start\":58816},{\"end\":59076,\"start\":59071},{\"end\":59086,\"start\":59080},{\"end\":59098,\"start\":59090},{\"end\":59111,\"start\":59104},{\"end\":59121,\"start\":59115},{\"end\":59324,\"start\":59318},{\"end\":59561,\"start\":59555},{\"end\":59572,\"start\":59565},{\"end\":59582,\"start\":59576},{\"end\":59591,\"start\":59586},{\"end\":59603,\"start\":59595},{\"end\":59933,\"start\":59929},{\"end\":59939,\"start\":59937},{\"end\":59949,\"start\":59945},{\"end\":59960,\"start\":59956},{\"end\":59977,\"start\":59966},{\"end\":59983,\"start\":59981},{\"end\":59993,\"start\":59990},{\"end\":60315,\"start\":60310},{\"end\":60325,\"start\":60319},{\"end\":60333,\"start\":60329},{\"end\":60342,\"start\":60337},{\"end\":60354,\"start\":60346},{\"end\":60601,\"start\":60595},{\"end\":60613,\"start\":60609},{\"end\":60623,\"start\":60620},{\"end\":60857,\"start\":60853},{\"end\":60864,\"start\":60861},{\"end\":61103,\"start\":61095},{\"end\":61344,\"start\":61336},{\"end\":61354,\"start\":61348},{\"end\":61366,\"start\":61358},{\"end\":61377,\"start\":61370},{\"end\":61387,\"start\":61381},{\"end\":61624,\"start\":61617},{\"end\":61634,\"start\":61628},{\"end\":61783,\"start\":61778},{\"end\":62021,\"start\":62013},{\"end\":62031,\"start\":62025},{\"end\":62306,\"start\":62300},{\"end\":62312,\"start\":62310},{\"end\":62530,\"start\":62524},{\"end\":62539,\"start\":62534},{\"end\":62548,\"start\":62543},{\"end\":62557,\"start\":62552},{\"end\":62569,\"start\":62561},{\"end\":62579,\"start\":62573},{\"end\":62590,\"start\":62583},{\"end\":62597,\"start\":62594},{\"end\":62611,\"start\":62601},{\"end\":62621,\"start\":62615},{\"end\":62634,\"start\":62625},{\"end\":62642,\"start\":62638},{\"end\":62650,\"start\":62646},{\"end\":62660,\"start\":62654},{\"end\":62670,\"start\":62664},{\"end\":62680,\"start\":62674},{\"end\":62696,\"start\":62684},{\"end\":62707,\"start\":62700},{\"end\":62715,\"start\":62711},{\"end\":62722,\"start\":62719},{\"end\":62734,\"start\":62726},{\"end\":63501,\"start\":63496},{\"end\":63665,\"start\":63657},{\"end\":63675,\"start\":63669},{\"end\":63689,\"start\":63679},{\"end\":63702,\"start\":63693},{\"end\":63714,\"start\":63706},{\"end\":63722,\"start\":63718},{\"end\":63733,\"start\":63726},{\"end\":63960,\"start\":63952},{\"end\":63970,\"start\":63966},{\"end\":64290,\"start\":64277},{\"end\":64301,\"start\":64294},{\"end\":64559,\"start\":64557},{\"end\":64568,\"start\":64563},{\"end\":64575,\"start\":64572},{\"end\":64587,\"start\":64582},{\"end\":64594,\"start\":64591},{\"end\":64888,\"start\":64883},{\"end\":64900,\"start\":64895},{\"end\":64909,\"start\":64904},{\"end\":64916,\"start\":64913},{\"end\":65168,\"start\":65166},{\"end\":65179,\"start\":65174},{\"end\":65190,\"start\":65185},{\"end\":65199,\"start\":65194},{\"end\":65464,\"start\":65459},{\"end\":65476,\"start\":65471},{\"end\":65485,\"start\":65480},{\"end\":65492,\"start\":65489},{\"end\":65738,\"start\":65727},{\"end\":65747,\"start\":65742},{\"end\":65760,\"start\":65751},{\"end\":65995,\"start\":65989},{\"end\":66221,\"start\":66216},{\"end\":66233,\"start\":66227},{\"end\":66442,\"start\":66436},{\"end\":66454,\"start\":66446},{\"end\":66465,\"start\":66458},{\"end\":66476,\"start\":66471},{\"end\":66723,\"start\":66718},{\"end\":66732,\"start\":66729},{\"end\":66745,\"start\":66736},{\"end\":66751,\"start\":66749},{\"end\":67033,\"start\":67022},{\"end\":67050,\"start\":67039},{\"end\":67063,\"start\":67054},{\"end\":67073,\"start\":67067},{\"end\":67083,\"start\":67077}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":36664,\"start\":36504},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":205242740},\"end\":37291,\"start\":36666},{\"attributes\":{\"doi\":\"arXiv:1911.08265\",\"id\":\"b2\"},\"end\":37755,\"start\":37293},{\"attributes\":{\"doi\":\"arXiv:2003.13350\",\"id\":\"b3\"},\"end\":38101,\"start\":37757},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":59345798},\"end\":38476,\"start\":38103},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":515925},\"end\":38958,\"start\":38478},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":205261034},\"end\":39353,\"start\":38960},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":55212377},\"end\":39694,\"start\":39355},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":54085699},\"end\":40004,\"start\":39696},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":86443261},\"end\":40312,\"start\":40006},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":119529393},\"end\":40554,\"start\":40314},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":119397375},\"end\":40949,\"start\":40556},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2233303},\"end\":41352,\"start\":40951},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":131777047},\"end\":41708,\"start\":41354},{\"attributes\":{\"id\":\"b14\"},\"end\":42025,\"start\":41710},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":209516030},\"end\":42352,\"start\":42027},{\"attributes\":{\"id\":\"b16\"},\"end\":42570,\"start\":42354},{\"attributes\":{\"id\":\"b17\"},\"end\":42882,\"start\":42572},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":207773869},\"end\":43199,\"start\":42884},{\"attributes\":{\"doi\":\"arXiv:2004.12323\",\"id\":\"b19\"},\"end\":43486,\"start\":43201},{\"attributes\":{\"doi\":\"arXiv:2002.01068\",\"id\":\"b20\"},\"end\":43743,\"start\":43488},{\"attributes\":{\"doi\":\"arXiv:1907.05415\",\"id\":\"b21\"},\"end\":44157,\"start\":43745},{\"attributes\":{\"doi\":\"arXiv:1908.03185\",\"id\":\"b22\"},\"end\":44484,\"start\":44159},{\"attributes\":{\"doi\":\"arXiv:1611.01578\",\"id\":\"b23\"},\"end\":44706,\"start\":44486},{\"attributes\":{\"doi\":\"arXiv:1611.02167\",\"id\":\"b24\"},\"end\":44996,\"start\":44708},{\"attributes\":{\"doi\":\"arXiv:1707.04873\",\"id\":\"b25\"},\"end\":45267,\"start\":44998},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":12227989},\"end\":45737,\"start\":45269},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3866935},\"end\":46197,\"start\":45739},{\"attributes\":{\"doi\":\"arXiv:1712.07316\",\"id\":\"b28\"},\"end\":46489,\"start\":46199},{\"attributes\":{\"doi\":\"arXiv:1802.03268\",\"id\":\"b29\"},\"end\":46776,\"start\":46491},{\"attributes\":{\"doi\":\"arXiv:1806.02639\",\"id\":\"b30\"},\"end\":47069,\"start\":46778},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":52016139},\"end\":47305,\"start\":47071},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":2514901},\"end\":47492,\"start\":47307},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":204836822},\"end\":47916,\"start\":47494},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":2337707},\"end\":48201,\"start\":47918},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":1621022},\"end\":48446,\"start\":48203},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":3908336},\"end\":48862,\"start\":48448},{\"attributes\":{\"doi\":\"arXiv:1812.01041\",\"id\":\"b37\"},\"end\":49262,\"start\":48864},{\"attributes\":{\"doi\":\"arXiv:1411.4028\",\"id\":\"b38\"},\"end\":49497,\"start\":49264},{\"attributes\":{\"doi\":\"arXiv:2009.01783\",\"id\":\"b39\"},\"end\":49705,\"start\":49499},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":117542570},\"end\":49931,\"start\":49707},{\"attributes\":{\"doi\":\"arXiv:2011.10395\",\"id\":\"b41\"},\"end\":50244,\"start\":49933},{\"attributes\":{\"doi\":\"arXiv:1804.00633\",\"id\":\"b42\"},\"end\":50478,\"start\":50246},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":51680972},\"end\":50838,\"start\":50480},{\"attributes\":{\"doi\":\"arXiv:1802.06002\",\"id\":\"b44\"},\"end\":51091,\"start\":50840},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":189999815},\"end\":51411,\"start\":51093},{\"attributes\":{\"doi\":\"arXiv:1912.08278\",\"id\":\"b46\"},\"end\":51723,\"start\":51413},{\"attributes\":{\"doi\":\"arXiv:2006.12270\",\"id\":\"b47\"},\"end\":52021,\"start\":51725},{\"attributes\":{\"doi\":\"arXiv:2008.12616\",\"id\":\"b48\"},\"end\":52391,\"start\":52023},{\"attributes\":{\"doi\":\"arXiv:1909.04226\",\"id\":\"b49\"},\"end\":52697,\"start\":52393},{\"attributes\":{\"doi\":\"arXiv:2012.00256\",\"id\":\"b50\"},\"end\":53051,\"start\":52699},{\"attributes\":{\"doi\":\"arXiv:2011.14651\",\"id\":\"b51\"},\"end\":53409,\"start\":53053},{\"attributes\":{\"doi\":\"arXiv:2012.12177\",\"id\":\"b52\"},\"end\":53732,\"start\":53411},{\"attributes\":{\"doi\":\"arXiv:2012.11560\",\"id\":\"b53\"},\"end\":54394,\"start\":53734},{\"attributes\":{\"doi\":\"arXiv:2103.11307\",\"id\":\"b54\"},\"end\":54777,\"start\":54396},{\"attributes\":{\"doi\":\"arXiv:2101.06189\",\"id\":\"b55\"},\"end\":55054,\"start\":54779},{\"attributes\":{\"doi\":\"arXiv:2103.14653\",\"id\":\"b56\"},\"end\":55337,\"start\":55056},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":13739672},\"end\":55574,\"start\":55339},{\"attributes\":{\"doi\":\"arXiv:2010.09036\",\"id\":\"b58\"},\"end\":55926,\"start\":55576},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":90233075},\"end\":56253,\"start\":55928},{\"attributes\":{\"doi\":\"arXiv:1807.01235\",\"id\":\"b60\"},\"end\":56529,\"start\":56255},{\"attributes\":{\"doi\":\"arXiv:2010.13727\",\"id\":\"b61\"},\"end\":56828,\"start\":56531},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":195767325},\"end\":57144,\"start\":56830},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":221150441},\"end\":57625,\"start\":57146},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":221848910},\"end\":57971,\"start\":57627},{\"attributes\":{\"id\":\"b65\"},\"end\":58459,\"start\":57973},{\"attributes\":{\"doi\":\"arXiv:2012.10711\",\"id\":\"b66\"},\"end\":58713,\"start\":58461},{\"attributes\":{\"doi\":\"arXiv:2103.15084\",\"id\":\"b67\"},\"end\":59010,\"start\":58715},{\"attributes\":{\"doi\":\"arXiv:2103.05577\",\"id\":\"b68\"},\"end\":59314,\"start\":59012},{\"attributes\":{\"doi\":\"arXiv:2006.14619\",\"id\":\"b69\"},\"end\":59477,\"start\":59316},{\"attributes\":{\"doi\":\"arXiv:2012.11242\",\"id\":\"b70\"},\"end\":59810,\"start\":59479},{\"attributes\":{\"doi\":\"arXiv:2010.13309\",\"id\":\"b71\"},\"end\":60265,\"start\":59812},{\"attributes\":{\"doi\":\"arXiv:2001.03622\",\"id\":\"b72\"},\"end\":60524,\"start\":60267},{\"attributes\":{\"doi\":\"arXiv:2010.13186\",\"id\":\"b73\"},\"end\":60806,\"start\":60526},{\"attributes\":{\"doi\":\"arXiv:2103.12010\",\"id\":\"b74\"},\"end\":60998,\"start\":60808},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":2332513},\"end\":61291,\"start\":61000},{\"attributes\":{\"doi\":\"arXiv:1707.06347\",\"id\":\"b76\"},\"end\":61566,\"start\":61293},{\"attributes\":{\"id\":\"b77\"},\"end\":61717,\"start\":61568},{\"attributes\":{\"doi\":\"arXiv:1609.04747\",\"id\":\"b78\"},\"end\":61922,\"start\":61719},{\"attributes\":{\"id\":\"b79\"},\"end\":62250,\"start\":61924},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b80\"},\"end\":62450,\"start\":62252},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":202786778},\"end\":63420,\"start\":62452},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":67150463},\"end\":63641,\"start\":63422},{\"attributes\":{\"doi\":\"arXiv:1606.01540\",\"id\":\"b83\"},\"end\":63908,\"start\":63643},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":14819346},\"end\":64242,\"start\":63910},{\"attributes\":{\"doi\":\"arXiv:2012.04046\",\"id\":\"b85\"},\"end\":64437,\"start\":64244},{\"attributes\":{\"doi\":\"arXiv:2010.10217\",\"id\":\"b86\"},\"end\":64832,\"start\":64439},{\"attributes\":{\"doi\":\"arXiv:2010.08561\",\"id\":\"b87\"},\"end\":65080,\"start\":64834},{\"attributes\":{\"doi\":\"arXiv:2012.09835\",\"id\":\"b88\"},\"end\":65400,\"start\":65082},{\"attributes\":{\"doi\":\"arXiv:2103.06524\",\"id\":\"b89\"},\"end\":65664,\"start\":65402},{\"attributes\":{\"id\":\"b90\"},\"end\":65910,\"start\":65666},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":20691213},\"end\":66176,\"start\":65912},{\"attributes\":{\"id\":\"b92\",\"matched_paper_id\":32356668},\"end\":66378,\"start\":66178},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":220301669},\"end\":66651,\"start\":66380},{\"attributes\":{\"doi\":\"arXiv:2103.07585\",\"id\":\"b94\"},\"end\":66932,\"start\":66653},{\"attributes\":{\"doi\":\"arXiv:2103.16089\",\"id\":\"b95\"},\"end\":67318,\"start\":66934},{\"attributes\":{\"id\":\"b96\"},\"end\":67495,\"start\":67320}]", "bib_title": "[{\"end\":36721,\"start\":36666},{\"end\":38168,\"start\":38103},{\"end\":38544,\"start\":38478},{\"end\":39008,\"start\":38960},{\"end\":39416,\"start\":39355},{\"end\":39760,\"start\":39696},{\"end\":40067,\"start\":40006},{\"end\":40366,\"start\":40314},{\"end\":40659,\"start\":40556},{\"end\":41043,\"start\":40951},{\"end\":41439,\"start\":41354},{\"end\":42091,\"start\":42027},{\"end\":42950,\"start\":42884},{\"end\":45335,\"start\":45269},{\"end\":45798,\"start\":45739},{\"end\":47107,\"start\":47071},{\"end\":47338,\"start\":47307},{\"end\":47558,\"start\":47494},{\"end\":48014,\"start\":47918},{\"end\":48266,\"start\":48203},{\"end\":48511,\"start\":48448},{\"end\":49731,\"start\":49707},{\"end\":50536,\"start\":50480},{\"end\":51150,\"start\":51093},{\"end\":55378,\"start\":55339},{\"end\":56013,\"start\":55928},{\"end\":56890,\"start\":56830},{\"end\":57201,\"start\":57146},{\"end\":57695,\"start\":57627},{\"end\":58071,\"start\":57973},{\"end\":61089,\"start\":61000},{\"end\":62009,\"start\":61924},{\"end\":62520,\"start\":62452},{\"end\":63492,\"start\":63422},{\"end\":63946,\"start\":63910},{\"end\":65983,\"start\":65912},{\"end\":66212,\"start\":66178},{\"end\":66432,\"start\":66380}]", "bib_author": "[{\"end\":36557,\"start\":36545},{\"end\":36568,\"start\":36557},{\"end\":36731,\"start\":36723},{\"end\":36746,\"start\":36731},{\"end\":36756,\"start\":36746},{\"end\":36766,\"start\":36756},{\"end\":36776,\"start\":36766},{\"end\":36791,\"start\":36776},{\"end\":36801,\"start\":36791},{\"end\":36815,\"start\":36801},{\"end\":36830,\"start\":36815},{\"end\":36843,\"start\":36830},{\"end\":36855,\"start\":36843},{\"end\":36866,\"start\":36855},{\"end\":36875,\"start\":36866},{\"end\":36889,\"start\":36875},{\"end\":36897,\"start\":36889},{\"end\":36908,\"start\":36897},{\"end\":36920,\"start\":36908},{\"end\":36928,\"start\":36920},{\"end\":36940,\"start\":36928},{\"end\":37381,\"start\":37364},{\"end\":37395,\"start\":37381},{\"end\":37405,\"start\":37395},{\"end\":37417,\"start\":37405},{\"end\":37426,\"start\":37417},{\"end\":37437,\"start\":37426},{\"end\":37445,\"start\":37437},{\"end\":37457,\"start\":37445},{\"end\":37469,\"start\":37457},{\"end\":37480,\"start\":37469},{\"end\":37818,\"start\":37807},{\"end\":37826,\"start\":37818},{\"end\":37841,\"start\":37826},{\"end\":37855,\"start\":37841},{\"end\":37869,\"start\":37855},{\"end\":37876,\"start\":37869},{\"end\":37888,\"start\":37876},{\"end\":38185,\"start\":38170},{\"end\":38198,\"start\":38185},{\"end\":38206,\"start\":38198},{\"end\":38215,\"start\":38206},{\"end\":38225,\"start\":38215},{\"end\":38556,\"start\":38546},{\"end\":38565,\"start\":38556},{\"end\":38579,\"start\":38565},{\"end\":38587,\"start\":38579},{\"end\":38596,\"start\":38587},{\"end\":38617,\"start\":38596},{\"end\":38634,\"start\":38617},{\"end\":38648,\"start\":38634},{\"end\":38666,\"start\":38648},{\"end\":38677,\"start\":38666},{\"end\":39020,\"start\":39010},{\"end\":39037,\"start\":39020},{\"end\":39049,\"start\":39037},{\"end\":39063,\"start\":39049},{\"end\":39072,\"start\":39063},{\"end\":39080,\"start\":39072},{\"end\":39090,\"start\":39080},{\"end\":39099,\"start\":39090},{\"end\":39106,\"start\":39099},{\"end\":39116,\"start\":39106},{\"end\":39427,\"start\":39418},{\"end\":39436,\"start\":39427},{\"end\":39444,\"start\":39436},{\"end\":39456,\"start\":39444},{\"end\":39471,\"start\":39456},{\"end\":39480,\"start\":39471},{\"end\":39771,\"start\":39762},{\"end\":39785,\"start\":39771},{\"end\":39794,\"start\":39785},{\"end\":39807,\"start\":39794},{\"end\":40078,\"start\":40069},{\"end\":40087,\"start\":40078},{\"end\":40104,\"start\":40087},{\"end\":40113,\"start\":40104},{\"end\":40374,\"start\":40368},{\"end\":40382,\"start\":40374},{\"end\":40673,\"start\":40661},{\"end\":40680,\"start\":40673},{\"end\":40688,\"start\":40680},{\"end\":40699,\"start\":40688},{\"end\":40707,\"start\":40699},{\"end\":41066,\"start\":41045},{\"end\":41076,\"start\":41066},{\"end\":41091,\"start\":41076},{\"end\":41101,\"start\":41091},{\"end\":41114,\"start\":41101},{\"end\":41447,\"start\":41441},{\"end\":41453,\"start\":41447},{\"end\":41460,\"start\":41453},{\"end\":41468,\"start\":41460},{\"end\":41476,\"start\":41468},{\"end\":41484,\"start\":41476},{\"end\":41803,\"start\":41789},{\"end\":41816,\"start\":41803},{\"end\":41831,\"start\":41816},{\"end\":41842,\"start\":41831},{\"end\":42103,\"start\":42093},{\"end\":42115,\"start\":42103},{\"end\":42127,\"start\":42115},{\"end\":42138,\"start\":42127},{\"end\":42445,\"start\":42435},{\"end\":42456,\"start\":42445},{\"end\":42656,\"start\":42643},{\"end\":42668,\"start\":42656},{\"end\":42678,\"start\":42668},{\"end\":42691,\"start\":42678},{\"end\":42700,\"start\":42691},{\"end\":42965,\"start\":42952},{\"end\":42980,\"start\":42965},{\"end\":42995,\"start\":42980},{\"end\":43268,\"start\":43255},{\"end\":43279,\"start\":43268},{\"end\":43290,\"start\":43279},{\"end\":43303,\"start\":43290},{\"end\":43561,\"start\":43554},{\"end\":43570,\"start\":43561},{\"end\":43577,\"start\":43570},{\"end\":43833,\"start\":43823},{\"end\":43846,\"start\":43833},{\"end\":43859,\"start\":43846},{\"end\":43869,\"start\":43859},{\"end\":43880,\"start\":43869},{\"end\":43889,\"start\":43880},{\"end\":43898,\"start\":43889},{\"end\":43909,\"start\":43898},{\"end\":44219,\"start\":44209},{\"end\":44233,\"start\":44219},{\"end\":44245,\"start\":44233},{\"end\":44257,\"start\":44245},{\"end\":44269,\"start\":44257},{\"end\":44280,\"start\":44269},{\"end\":44550,\"start\":44542},{\"end\":44558,\"start\":44550},{\"end\":44786,\"start\":44777},{\"end\":44795,\"start\":44786},{\"end\":44803,\"start\":44795},{\"end\":44813,\"start\":44803},{\"end\":45062,\"start\":45055},{\"end\":45070,\"start\":45062},{\"end\":45079,\"start\":45070},{\"end\":45085,\"start\":45079},{\"end\":45093,\"start\":45085},{\"end\":45345,\"start\":45337},{\"end\":45358,\"start\":45345},{\"end\":45368,\"start\":45358},{\"end\":45376,\"start\":45368},{\"end\":45809,\"start\":45800},{\"end\":45816,\"start\":45809},{\"end\":45822,\"start\":45816},{\"end\":45830,\"start\":45822},{\"end\":45840,\"start\":45830},{\"end\":46273,\"start\":46261},{\"end\":46283,\"start\":46273},{\"end\":46295,\"start\":46283},{\"end\":46305,\"start\":46295},{\"end\":46559,\"start\":46551},{\"end\":46569,\"start\":46559},{\"end\":46577,\"start\":46569},{\"end\":46585,\"start\":46577},{\"end\":46593,\"start\":46585},{\"end\":46854,\"start\":46847},{\"end\":46862,\"start\":46854},{\"end\":46871,\"start\":46862},{\"end\":46878,\"start\":46871},{\"end\":46884,\"start\":46878},{\"end\":47119,\"start\":47109},{\"end\":47131,\"start\":47119},{\"end\":47141,\"start\":47131},{\"end\":47352,\"start\":47340},{\"end\":47365,\"start\":47352},{\"end\":47569,\"start\":47560},{\"end\":47577,\"start\":47569},{\"end\":47588,\"start\":47577},{\"end\":47597,\"start\":47588},{\"end\":47609,\"start\":47597},{\"end\":47620,\"start\":47609},{\"end\":47630,\"start\":47620},{\"end\":47639,\"start\":47630},{\"end\":47652,\"start\":47639},{\"end\":47663,\"start\":47652},{\"end\":48026,\"start\":48016},{\"end\":48280,\"start\":48268},{\"end\":48524,\"start\":48513},{\"end\":48535,\"start\":48524},{\"end\":48547,\"start\":48535},{\"end\":48558,\"start\":48547},{\"end\":48569,\"start\":48558},{\"end\":48579,\"start\":48569},{\"end\":48595,\"start\":48579},{\"end\":48613,\"start\":48595},{\"end\":48981,\"start\":48973},{\"end\":48992,\"start\":48981},{\"end\":49000,\"start\":48992},{\"end\":49011,\"start\":49000},{\"end\":49022,\"start\":49011},{\"end\":49319,\"start\":49310},{\"end\":49332,\"start\":49319},{\"end\":49343,\"start\":49332},{\"end\":49541,\"start\":49531},{\"end\":49548,\"start\":49541},{\"end\":49561,\"start\":49548},{\"end\":49744,\"start\":49733},{\"end\":49754,\"start\":49744},{\"end\":49766,\"start\":49754},{\"end\":49775,\"start\":49766},{\"end\":50025,\"start\":50012},{\"end\":50036,\"start\":50025},{\"end\":50049,\"start\":50036},{\"end\":50293,\"start\":50283},{\"end\":50305,\"start\":50293},{\"end\":50314,\"start\":50305},{\"end\":50323,\"start\":50314},{\"end\":50550,\"start\":50538},{\"end\":50564,\"start\":50550},{\"end\":50573,\"start\":50564},{\"end\":50585,\"start\":50573},{\"end\":50596,\"start\":50585},{\"end\":50606,\"start\":50596},{\"end\":50620,\"start\":50606},{\"end\":50849,\"start\":50840},{\"end\":50858,\"start\":50849},{\"end\":51165,\"start\":51152},{\"end\":51174,\"start\":51165},{\"end\":51182,\"start\":51174},{\"end\":51196,\"start\":51182},{\"end\":51484,\"start\":51476},{\"end\":51497,\"start\":51484},{\"end\":51506,\"start\":51497},{\"end\":51516,\"start\":51506},{\"end\":51528,\"start\":51516},{\"end\":51795,\"start\":51781},{\"end\":51806,\"start\":51795},{\"end\":51820,\"start\":51806},{\"end\":51833,\"start\":51820},{\"end\":52132,\"start\":52114},{\"end\":52145,\"start\":52132},{\"end\":52159,\"start\":52145},{\"end\":52168,\"start\":52159},{\"end\":52478,\"start\":52469},{\"end\":52492,\"start\":52478},{\"end\":52500,\"start\":52492},{\"end\":52506,\"start\":52500},{\"end\":52773,\"start\":52762},{\"end\":52783,\"start\":52773},{\"end\":52796,\"start\":52783},{\"end\":52804,\"start\":52796},{\"end\":52811,\"start\":52804},{\"end\":52819,\"start\":52811},{\"end\":52825,\"start\":52819},{\"end\":52833,\"start\":52825},{\"end\":53156,\"start\":53146},{\"end\":53168,\"start\":53156},{\"end\":53180,\"start\":53168},{\"end\":53190,\"start\":53180},{\"end\":53498,\"start\":53488},{\"end\":53508,\"start\":53498},{\"end\":53517,\"start\":53508},{\"end\":53523,\"start\":53517},{\"end\":53530,\"start\":53523},{\"end\":53936,\"start\":53928},{\"end\":53944,\"start\":53936},{\"end\":53952,\"start\":53944},{\"end\":53959,\"start\":53952},{\"end\":53967,\"start\":53959},{\"end\":53975,\"start\":53967},{\"end\":53984,\"start\":53975},{\"end\":53997,\"start\":53984},{\"end\":54010,\"start\":53997},{\"end\":54018,\"start\":54010},{\"end\":54492,\"start\":54481},{\"end\":54499,\"start\":54492},{\"end\":54509,\"start\":54499},{\"end\":54517,\"start\":54509},{\"end\":54523,\"start\":54517},{\"end\":54531,\"start\":54523},{\"end\":54537,\"start\":54531},{\"end\":54545,\"start\":54537},{\"end\":54843,\"start\":54833},{\"end\":54853,\"start\":54843},{\"end\":54862,\"start\":54853},{\"end\":54868,\"start\":54862},{\"end\":54875,\"start\":54868},{\"end\":55103,\"start\":55090},{\"end\":55117,\"start\":55103},{\"end\":55124,\"start\":55117},{\"end\":55135,\"start\":55124},{\"end\":55146,\"start\":55135},{\"end\":55156,\"start\":55146},{\"end\":55402,\"start\":55380},{\"end\":55414,\"start\":55402},{\"end\":55651,\"start\":55640},{\"end\":55661,\"start\":55651},{\"end\":55674,\"start\":55661},{\"end\":55681,\"start\":55674},{\"end\":55689,\"start\":55681},{\"end\":55695,\"start\":55689},{\"end\":55703,\"start\":55695},{\"end\":55709,\"start\":55703},{\"end\":56025,\"start\":56015},{\"end\":56035,\"start\":56025},{\"end\":56046,\"start\":56035},{\"end\":56332,\"start\":56324},{\"end\":56338,\"start\":56332},{\"end\":56344,\"start\":56338},{\"end\":56353,\"start\":56344},{\"end\":56630,\"start\":56620},{\"end\":56642,\"start\":56630},{\"end\":56902,\"start\":56892},{\"end\":56915,\"start\":56902},{\"end\":56921,\"start\":56915},{\"end\":56932,\"start\":56921},{\"end\":56938,\"start\":56932},{\"end\":56949,\"start\":56938},{\"end\":57215,\"start\":57203},{\"end\":57221,\"start\":57215},{\"end\":57706,\"start\":57697},{\"end\":57723,\"start\":57706},{\"end\":57736,\"start\":57723},{\"end\":57749,\"start\":57736},{\"end\":57759,\"start\":57749},{\"end\":58084,\"start\":58073},{\"end\":58093,\"start\":58084},{\"end\":58103,\"start\":58093},{\"end\":58115,\"start\":58103},{\"end\":58125,\"start\":58115},{\"end\":58526,\"start\":58520},{\"end\":58533,\"start\":58526},{\"end\":58540,\"start\":58533},{\"end\":58548,\"start\":58540},{\"end\":58805,\"start\":58795},{\"end\":58814,\"start\":58805},{\"end\":58824,\"start\":58814},{\"end\":59078,\"start\":59069},{\"end\":59088,\"start\":59078},{\"end\":59100,\"start\":59088},{\"end\":59113,\"start\":59100},{\"end\":59123,\"start\":59113},{\"end\":59326,\"start\":59316},{\"end\":59563,\"start\":59553},{\"end\":59574,\"start\":59563},{\"end\":59584,\"start\":59574},{\"end\":59593,\"start\":59584},{\"end\":59605,\"start\":59593},{\"end\":59935,\"start\":59922},{\"end\":59941,\"start\":59935},{\"end\":59951,\"start\":59941},{\"end\":59962,\"start\":59951},{\"end\":59979,\"start\":59962},{\"end\":59985,\"start\":59979},{\"end\":59995,\"start\":59985},{\"end\":60317,\"start\":60308},{\"end\":60327,\"start\":60317},{\"end\":60335,\"start\":60327},{\"end\":60344,\"start\":60335},{\"end\":60356,\"start\":60344},{\"end\":60603,\"start\":60591},{\"end\":60615,\"start\":60603},{\"end\":60625,\"start\":60615},{\"end\":60850,\"start\":60844},{\"end\":60859,\"start\":60850},{\"end\":60866,\"start\":60859},{\"end\":61105,\"start\":61091},{\"end\":61346,\"start\":61334},{\"end\":61356,\"start\":61346},{\"end\":61368,\"start\":61356},{\"end\":61379,\"start\":61368},{\"end\":61389,\"start\":61379},{\"end\":61626,\"start\":61613},{\"end\":61636,\"start\":61626},{\"end\":61785,\"start\":61776},{\"end\":62023,\"start\":62011},{\"end\":62033,\"start\":62023},{\"end\":62308,\"start\":62296},{\"end\":62314,\"start\":62308},{\"end\":62532,\"start\":62522},{\"end\":62541,\"start\":62532},{\"end\":62550,\"start\":62541},{\"end\":62559,\"start\":62550},{\"end\":62571,\"start\":62559},{\"end\":62581,\"start\":62571},{\"end\":62592,\"start\":62581},{\"end\":62599,\"start\":62592},{\"end\":62613,\"start\":62599},{\"end\":62623,\"start\":62613},{\"end\":62636,\"start\":62623},{\"end\":62644,\"start\":62636},{\"end\":62652,\"start\":62644},{\"end\":62662,\"start\":62652},{\"end\":62672,\"start\":62662},{\"end\":62682,\"start\":62672},{\"end\":62698,\"start\":62682},{\"end\":62709,\"start\":62698},{\"end\":62717,\"start\":62709},{\"end\":62724,\"start\":62717},{\"end\":62736,\"start\":62724},{\"end\":63503,\"start\":63494},{\"end\":63667,\"start\":63655},{\"end\":63677,\"start\":63667},{\"end\":63691,\"start\":63677},{\"end\":63704,\"start\":63691},{\"end\":63716,\"start\":63704},{\"end\":63724,\"start\":63716},{\"end\":63735,\"start\":63724},{\"end\":63962,\"start\":63948},{\"end\":63972,\"start\":63962},{\"end\":64292,\"start\":64275},{\"end\":64303,\"start\":64292},{\"end\":64561,\"start\":64555},{\"end\":64570,\"start\":64561},{\"end\":64577,\"start\":64570},{\"end\":64589,\"start\":64577},{\"end\":64596,\"start\":64589},{\"end\":64890,\"start\":64878},{\"end\":64902,\"start\":64890},{\"end\":64911,\"start\":64902},{\"end\":64918,\"start\":64911},{\"end\":65170,\"start\":65161},{\"end\":65181,\"start\":65170},{\"end\":65192,\"start\":65181},{\"end\":65201,\"start\":65192},{\"end\":65466,\"start\":65454},{\"end\":65478,\"start\":65466},{\"end\":65487,\"start\":65478},{\"end\":65494,\"start\":65487},{\"end\":65740,\"start\":65725},{\"end\":65749,\"start\":65740},{\"end\":65762,\"start\":65749},{\"end\":65997,\"start\":65985},{\"end\":66223,\"start\":66214},{\"end\":66235,\"start\":66223},{\"end\":66444,\"start\":66434},{\"end\":66456,\"start\":66444},{\"end\":66467,\"start\":66456},{\"end\":66478,\"start\":66467},{\"end\":66725,\"start\":66716},{\"end\":66734,\"start\":66725},{\"end\":66747,\"start\":66734},{\"end\":66753,\"start\":66747},{\"end\":67035,\"start\":67020},{\"end\":67052,\"start\":67035},{\"end\":67065,\"start\":67052},{\"end\":67075,\"start\":67065},{\"end\":67085,\"start\":67075}]", "bib_venue": "[{\"end\":45517,\"start\":45455},{\"end\":45981,\"start\":45919},{\"end\":57406,\"start\":57322},{\"end\":58200,\"start\":58171},{\"end\":36543,\"start\":36504},{\"end\":36946,\"start\":36940},{\"end\":37362,\"start\":37293},{\"end\":37805,\"start\":37757},{\"end\":38277,\"start\":38225},{\"end\":38683,\"start\":38677},{\"end\":39122,\"start\":39116},{\"end\":39497,\"start\":39480},{\"end\":39824,\"start\":39807},{\"end\":40136,\"start\":40113},{\"end\":40407,\"start\":40382},{\"end\":40730,\"start\":40707},{\"end\":41128,\"start\":41114},{\"end\":41507,\"start\":41484},{\"end\":41787,\"start\":41710},{\"end\":42162,\"start\":42138},{\"end\":42433,\"start\":42354},{\"end\":42641,\"start\":42572},{\"end\":43012,\"start\":42995},{\"end\":43253,\"start\":43201},{\"end\":43552,\"start\":43488},{\"end\":43821,\"start\":43745},{\"end\":44207,\"start\":44159},{\"end\":44540,\"start\":44486},{\"end\":44775,\"start\":44708},{\"end\":45053,\"start\":44998},{\"end\":45453,\"start\":45376},{\"end\":45917,\"start\":45840},{\"end\":46259,\"start\":46199},{\"end\":46549,\"start\":46491},{\"end\":46845,\"start\":46778},{\"end\":47160,\"start\":47141},{\"end\":47371,\"start\":47365},{\"end\":47669,\"start\":47663},{\"end\":48037,\"start\":48026},{\"end\":48303,\"start\":48280},{\"end\":48634,\"start\":48613},{\"end\":48971,\"start\":48864},{\"end\":49308,\"start\":49264},{\"end\":49529,\"start\":49499},{\"end\":49792,\"start\":49775},{\"end\":50010,\"start\":49933},{\"end\":50281,\"start\":50246},{\"end\":50626,\"start\":50620},{\"end\":50941,\"start\":50874},{\"end\":51226,\"start\":51196},{\"end\":51474,\"start\":51413},{\"end\":51779,\"start\":51725},{\"end\":52112,\"start\":52023},{\"end\":52467,\"start\":52393},{\"end\":52760,\"start\":52699},{\"end\":53144,\"start\":53053},{\"end\":53486,\"start\":53411},{\"end\":53926,\"start\":53734},{\"end\":54479,\"start\":54396},{\"end\":54831,\"start\":54779},{\"end\":55088,\"start\":55056},{\"end\":55431,\"start\":55414},{\"end\":55638,\"start\":55576},{\"end\":56069,\"start\":56046},{\"end\":56322,\"start\":56255},{\"end\":56618,\"start\":56531},{\"end\":56960,\"start\":56949},{\"end\":57320,\"start\":57221},{\"end\":57770,\"start\":57759},{\"end\":58169,\"start\":58125},{\"end\":58518,\"start\":58461},{\"end\":58793,\"start\":58715},{\"end\":59067,\"start\":59012},{\"end\":59375,\"start\":59342},{\"end\":59551,\"start\":59479},{\"end\":59920,\"start\":59812},{\"end\":60306,\"start\":60267},{\"end\":60589,\"start\":60526},{\"end\":60842,\"start\":60808},{\"end\":61121,\"start\":61105},{\"end\":61332,\"start\":61293},{\"end\":61611,\"start\":61568},{\"end\":61774,\"start\":61719},{\"end\":62079,\"start\":62033},{\"end\":62294,\"start\":62252},{\"end\":62785,\"start\":62736},{\"end\":63524,\"start\":63503},{\"end\":63653,\"start\":63643},{\"end\":64049,\"start\":63972},{\"end\":64273,\"start\":64244},{\"end\":64553,\"start\":64439},{\"end\":64876,\"start\":64834},{\"end\":65159,\"start\":65082},{\"end\":65452,\"start\":65402},{\"end\":65723,\"start\":65666},{\"end\":66020,\"start\":65997},{\"end\":66252,\"start\":66235},{\"end\":66489,\"start\":66478},{\"end\":66714,\"start\":66653},{\"end\":67018,\"start\":66934},{\"end\":67358,\"start\":67320}]"}}}, "year": 2023, "month": 12, "day": 17}