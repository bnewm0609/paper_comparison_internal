{"id": 252216587, "updated": "2023-02-21 14:36:24.676", "metadata": {"title": "Global and Personalized Graphs for Heterogeneous Sequential Recommendation by Learning Behavior Transitions and User Intentions", "authors": "[{\"first\":\"Weixin\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Mingkai\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Yongxin\",\"last\":\"Ni\",\"middle\":[]},{\"first\":\"Weike\",\"last\":\"Pan\",\"middle\":[]},{\"first\":\"Li\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Zhong\",\"last\":\"Ming\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 16th ACM Conference on Recommender Systems", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Heterogeneous sequential recommendation (HSR) is a very important recommendation problem, which aims to predict a user\u2019s next interacted item under a target behavior type (e.g., purchase in e-commerce sites) based on his/her historical interactions with different behaviors. Though existing sequential methods have achieved advanced performance by considering the varied impacts of interactions with sequential information, a large body of them still have two major shortcomings. Firstly, they usually model different behaviors separately without considering the correlations between them. The transitions from item to item under diverse behaviors indicate some users\u2019 potential behavior manner. Secondly, though the behavior information contains a user\u2019s fine-grained interests, the insufficient consideration of the local context information limits them from well understanding user intentions. Utilizing the adjacent interactions to better understand a user\u2019s behavior could improve the certainty of prediction. To address these two issues, we propose a novel solution utilizing global and personalized graphs for HSR (GPG4HSR) to learn behavior transitions and user intentions. Specifically, our GPG4HSR consists of two graphs, i.e., a global graph to capture the transitions between different behaviors, and a personalized graph to model items with behaviors by further considering the distinct user intentions of the adjacent contextually relevant nodes. Extensive experiments on four public datasets with the state-of-the-art baselines demonstrate the effectiveness and general applicability of our method GPG4HSR.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/recsys/ChenHNPC022", "doi": "10.1145/3523227.3546761"}}, "content": {"source": {"pdf_hash": "f18d768b62198e6c7421b4422f69374b354f3e0b", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "942641dcd669aeb28716c8360b13cb68c51041ce", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f18d768b62198e6c7421b4422f69374b354f3e0b.txt", "contents": "\nGlobal and Personalized Graphs for Heterogeneous Sequential Recommendation by Learning Behavior Transitions and User Intentions\nSeptember 18-23, 2022. September 18-23, 2022\n\nWeixin Chen \nMingkai He mingkai_he@163.com \nYongxin Ni niyongxin@u.nus.edu \nWeike Pan panweike@szu.edu.cn \nZhong Ming mingz@szu.edu.cn \nLi Chen lichen@comp.hkbu.edu.hk \nWeixin Chen \nMingkai He \nYongxin Ni \nWeike Pan \nZhong Ming \nLi \nChen \n\nShenzhen University Shenzhen\nChina\n\n\nShenzhen University Shenzhen\nChina\n\n\nNational University of Singapore Queenstown\nSingapore\n\n\nShenzhen University Shenzhen\nChina\n\n\nShenzhen University Shenzhen\nChina\n\n\nHong Kong Baptist University Hong Kong\nChina\n\nGlobal and Personalized Graphs for Heterogeneous Sequential Recommendation by Learning Behavior Transitions and User Intentions\n\nSixteenth ACM Conference on Recommender Systems (RecSys '22)\nSeattle, WA, USA 2022; Seattle, W22September 18-23, 2022. September 18-23, 202210.1145/3523227.3546761ACM ISBN 978-1-4503-9278-5/22/09. . . $15.00 A, USA. ACM, New York, NY, USA, 10 pages. https: //Sequential RecommendationGraph Neural NetworkBehavior TransitionUser Intention * co-corresponding authors\nHeterogeneous sequential recommendation (HSR) is a very important recommendation problem, which aims to predict a user's next interacted item under a target behavior type (e.g., purchase in ecommerce sites) based on his/her historical interactions with different behaviors. Though existing sequential methods have achieved advanced performance by considering the varied impacts of interactions with sequential information, a large body of them still have two major shortcomings. Firstly, they usually model different behaviors separately without considering the correlations between them. The transitions from item to item under diverse behaviors indicate some users' potential behavior manner. Secondly, though the behavior information contains a user's fine-grained interests, the insufficient consideration of the local context information limits them from well understanding user intentions. Utilizing the adjacent interactions to better understand a user's behavior could improve the certainty of prediction. To address these two issues, we propose a novel solution utilizing global and personalized graphs for HSR (GPG4HSR) to learn behavior transitions and user intentions. Specifically, our GPG4HSR consists of two graphs, i.e., a global graph to capture the transitions between different behaviors, and a personalized graph to model items with behaviors by further considering the distinct user intentions of the adjacent contextually relevant nodes. Extensive experiments on four public datasets with the state-of-the-art baselines demonstrate the effectiveness and general applicability of our method GPG4HSR.\n\nINTRODUCTION\n\nIn lots of scenes including e-commerce sites, recommender systems have played a crucial booster role. Through learning from the historical (user, item) interactions, it is able to generate the digital scores or a ranked list for the uninteracted items, and recommend some appropriate items for each user to alleviate the information overload problem. As a user's preferences widely exist in the form of sequence and the way he/she interacted with items, how to model the user's sequential and heterogeneous behaviors becomes a research hotspot recently.\n\nAlthough existing methods model the sequential and behavior information in an effective way, they usually suffer from the following two issues. Firstly, they often ignore the correlations of different behaviors. Specifically, the different transitions according to their behavior types indicate importance to a different extent, but modeling behaviors separately, i.e., splitting an interaction sequence into multiple subsequences according to the behavior types, cannot learn the potential correlations well as the connection between different types of behaviors is broken. Secondly, they usually model behaviors without utilizing the local context information. Even though the behavior information could capture different levels of user intentions, the context information is able to further enhance the certainty and decrease the randomness. For example, if a user Alice performed a sequence of browsing item A, adding item A to the cart, and purchasing item A, and another user Bob also performed an interaction sequence but with a slight difference, i.e., browsing item A, adding item A to the cart, and browsing item B. The behavior of adding item A to the cart exists in both sequences, which indicates a high probability of purchasing item A. However, the subsequent interactions are quite different, and are also very useful to obtain an enhanced understanding of \"adding item A to the cart\" for each user, i.e., Alice would purchase items in cart with higher certainty, but there is more randomness for Bob to do so.\n\nMost of traditional recommendation algorithms [9,18] fill a rating matrix of (user, item) pairs to deal with general recommendation, without utilizing the sequential and behavior information. Compared with general recommendation, early works for sequential recommendation [8,10,21,29] obtain better performance since they capture more accurate preferences by learning the sequential patterns. For instance, GRU4Rec [8] utilizes gated recurrent units (GRUs), a variant of recurrent neural networks (RNNs), to transmit the previous information to subsequent units for learning the sequential patterns inherently. With the increasing amount of e-commerce users and items, the information overload problem becomes crucial, while the increasing behavior data offers more detailed information to gain a deeper understanding of a user's intentions. This actually raises an emerging and valuable topic, i.e., heterogeneous sequential recommendation (HSR). For example, TransRec++ [31] adapts TransRec [5] to strengthen its ability of capturing the behavior transitions of users, which considers the correlations between different behaviors but lacks consideration of distinguishing those behaviors. RIB [32] concatenates the item and behavior embeddings as the input embedding to consider the influences of different behaviors, and adopts an RNN layer to learn the sequential patterns. However, concatenation of two embeddings could only learn the distinct importance of behaviors but not the relations between them. MGNN-SPred [23] constructs two itemto-item graphs by incorporating the context information between items under the same behavior in order to learn the transitions, but ignores the transitions under different behaviors.\n\nTo overcome these issues, we propose a novel solution called global and personalized graphs for heterogeneous sequential recommendation (GPG4HSR). Firstly, we introduce a global graph layer, equipped with a global graph (GG) of items and behavior transitions to capture the transitions between all behaviors, which addresses the aforementioned first issue. Secondly, to learn user intentions by distinguishing the varied effects of the same interaction with different context information and address the second issue, we utilize a personalized graph layer with a personalized graph (PG) of interaction sequence to model heterogeneous feedback with the influence of adjacent interactions. In addition, to balance these two modules (i.e., the global and personalized graph layers) and take a further step in learning the sequential patterns, we apply an effective fusion layer and an attention layer. Finally, we introduce a prediction layer in order to predict the next likely-to-purchase item. Note that we group all behaviors into examinations and purchases as their two representative behavior types, and the exploratory study in Section 6.2 indicates that our GPG4HSR is applicable to scenes with more types of behaviors.\n\nWe summarize our main contributions as follows: (i) We propose a novel model called GPG4HSR to address two fundamental issues in HSR by considering the correlations of all behaviors via a global graph (GG) and enhancing the interaction representation with the context information via a personalized graph (PG). (ii) We develop a global graph layer and a personalized graph layer to model GG and PG, respectively, in which the former weighs the transitions between different behaviors and the latter incorporates the representations of a local behavior and its adjacent contextually relevant interactions. (iii) We study the recommendation performance of our GPG4HSR and eight competitive baselines on four datasets, and find that our GPG4HSR performs the best in most cases. Moreover, further studies, including exploratory studies with more than two different types of behaviors, ablation studies of the major components, framework studies with different backbone models and sensitivity analysis of the hyperparameter, show the effectiveness of our solution.\n\n\nRELATED WORK 2.1 General Recommendation\n\nBayesian personalized ranking (BPR) [18] factorizes an implicit feedback matrix with a pairwise preference assumption that users prefer interacted items to uninteracted ones. Fusing item similarity model (FISM) [9] integrates an item similarity model into matrix factorization by replacing a user-specific latent vector with an aggregated latent vector of his/her interacted items. Recently, due to the superior performance of deep learning (DL)-based methods, more works are developed by taking advantage of their merits. Among them, a large amount of graph neural network (GNN)-based recommendation algorithms [1,7,15,24,30] make use of (user, item) bipartite graphs to capture the collaborative information. For example, PinSage [30] combines random walk and GraphSage [3] to successfully apply GNN to commercial recommender systems. GHCF [1] captures heterogeneous relations with high-hop structure of (user, item) interactions based on graph convolutional network (GCN). NGCF [24] explicitly learns node embeddings with the collaborative filtering signals through the graph structure. By removing the nonlinear part in NGCF, LightGCN [7] obtains a simple but effective model. Ultra-GCN [15] derives a compact model from the ultimate limit form of LightGCN, which thus avoids some critical problems such as oversmoothing caused by stacked graph networks. Most recently, some studies [26,28] learn multi-behavior information by meta learning. For instance, CML [26] distills transferable knowledge across different behavior types through a multi-behavior contrastive learning framework. However, all these methods do not utilize the sequential information, which is very important in learning users' preferences.\n\n\nSequential Recommendation\n\nCompared with the general recommendation methods, sequential recommendation methods predict the next likely-to-interact item through exploiting the extra position information of the interactions that provides more accurate real-time interests and intentions of the users. We classify sequential recommendation methods into two branches according to the number of behavior types exploited.\n\n\nHomogeneous Sequential Recommendation.\n\nEarly works on sequential recommendation only tackle one single type of behavior on items such as one-class or homogeneous implicit feedback, and learn the sequential patterns relying on Markov chains or deep neural networks (DNNs). Methods based on Markov chains [6] model user preferences with transitions of sequential items where the current state of an individual taste is only affected by the last state and the current interacted item. FPMC [19] extends matrix factorization with Markov chains to learn both the long-term and short-term preferences with consecutive items for each user. Fossil [6] further adopts higher-order Markov chains to address the sparsity issue. Translation-based recommendation (TransRec) [5] applies a translation-based structure in which it regards the items as space and users as transition vectors. DNN-based methods learn the sequential patterns through different structures of networks such as RNN [8], CNN [21], attention [10] and GNN [23,25,27,29]. The RNN-based method GRU4Rec [8] inherently utilizes the sequential information by updating the state recurrently but facing the notorious gradient vanishing problem. CNN-based methods [21] slide elaborately designed convolution filters over an embedding matrix to extract low dimensional features. Attention-based methods [10] add position embeddings and item embeddings to learn features of items with the position information and pay the calculated attention according to some designated rules to them. GNN-based methods [25,27,29] usually construct graphs in diverse forms to capture deep relations between users and/or items, especially some item-to-item graphs that capture complicated transitions of items efficiently. Based on SR-GNN [27], GC-SAN [29] uses a self-attention mechanism to better capture the contextual information between the historical items. GCE-GNN [25] constructs a session graph and a global graph for learning session-level item representations and global-level item representations, respectively, which is similar to our work. However, it lacks consideration of the effects caused by different user behaviors. All these works only model homogeneous behaviors and ignore that the heterogeneous feedback can better reflect the preferences of users in different degrees.\n\n\nHeterogeneous Sequential Recommendation.\n\nThere are few works modeling both sequential and multi-behaviors information, and most of them are DL-based methods. As one of the few matrix factorization (MF)-based methods, TransRec++ [31] extends Tran-sRec [5] with behavior transition vectors to learn the dynamics of users' heterogeneous behaviors. Compared with the MF-based methods, DL-based methods are more powerful in processing sequences and heterogeneous behaviors. RIB [32] concatenates a behavior embedding with an item embedding to introduce behaviorspecific influences, along with an RNN layer and an attention layer to capture the sequential patterns and distinguish the varied effects of interactions, respectively. BINN [11] uses w-item2vec to obtain a unified representation of each item and takes the behavior information as an auxiliary input of the bidirectional RNN modules. MKM-SR [16] learns an item embedding and a behavior embedding via gated GNN (GGNN) and GRU, respectively, and concatenates them as an interaction embedding. MGNN-SPred [23] is a closely related work to ours that captures the sequential information and distinguishes the impact of different behaviors via GNN. Similarly, MBGNN [17] and MGCNet [20] learn the transition patterns considering only the same types of behaviors. They split one sequence into multiple subsequences according to the behavior types on items, assuming that each type of behavior is independent of each other and ignoring the correlations between different behaviors.\n\nWe can see that recommendation with users' sequential and heterogeneous feedback or behaviors has the potential to learn the users' preferences more accurately, but the existing few works can not exploit the global correlations of the users' behaviors and the local context in each user's sequence well. This motivates us to design a novel solution for modeling users' sequential and heterogeneous feedback in recommender systems. \n\n\nPRELIMINARIES 3.1 Problem Definition\n\nIn this paper, we aim to address the problem of heterogeneous sequential recommendation (HSR) in which the prediction of the next likely-to-purchase item is based on an interaction sequence of items with two or more different types of behaviors. Note that different from session-based recommendation, users are not anonymous in sequential recommendation. With the goal to model the behaviors in a more general and common way, we categorize all the behaviors into two major types, i.e., examination e and purchase p, where the former denotes all relatively positive non-target behaviors such as clicks, adds-to-cart and favorites in e-commerce sites, and the latter represents the target behavior.\n\nTo be specific, we have an interaction sequence\nS u = {(i 1 , b 1 ), (i 2 , b 2 ), . . . , (i t , b t ), . . . , (i |S u | , b |S u | )} for each user u, where (i t , b t )\ndenotes the (item, behavior) pair of the t-th interaction in sequence S u . Depending on the historical data above, our goal is to recommend the next likely-to-purchase item for each user u more accurately. We illustrate the studied HSR problem in Figure 1.\n\n\nChallenges\n\nThe heterogeneous feedback provides more detailed information of a user's interactions but also brings the following challenges to be addressed. Firstly, how to model heterogeneous behaviors in sequential recommendation. Different behaviors which represent different levels of users' interests should be distinguished when modeling the interactions in a sequence. There are rife solutions for sequential recommendation, e.g., Caser [21], GRU4Rec [8] and SASRec [10], which could model the item sequences adequately from different classic deep-learning perspectives, but they do not consider the heterogeneity of the users' feedback. Secondly, how to capture the global relationship between items with different types of behaviors more accurately when the user behavior data is sparse. Since the interactions between a certain user and the items are often very rare, some GNN-based methods like MKM-SR [16] and MGNN-SPred [23] turn to capture the relationship between items via some global graphs. However, they both underrate the correlations of different behaviors because they split an interaction sequence as separated ones w.r.t. the behavior types and ignore the correlations between different behaviors.\n\n\nOverview of Our Solution\n\nTo address the aforementioned challenges, we propose a novel solution called GPG4HSR shown in Figure 2, which mainly consists of two types of graphs, i.e., a global graph (GG) G \u0434 of items and behavior transitions for all users and a personalized graph (PG) G u p of interaction sequence for each user u.\n\nIn order to capture the relationship between items with heterogeneous behaviors, we construct a global item graph\nG \u0434 = (V \u0434 , E \u0434 ),\nwhere G \u0434 takes all the items as nodes V \u0434 and defines four basic edge types in the global edge set E \u0434 , i.e., from examination to examination (e2e), from purchase to purchase (p2p), from examination to purchase (e2p) and from purchase to examination (p2e). To better leverage the importance of heterogeneous behaviors, we assign a learnable weight to each basic edge type by an edge gating network. For further distinguishing the order of two items on behavior transitions e2p and p2e and identifying the behavior on an item, we extend each one of them to two sub directed edge types with suffixes '+' and '\u2212', where '+' and '\u2212' mean an inward direction and an outward direction, respectively. For example, a directed edge of type e2p\u2212 on node pair (v, v\u2032) (or a corresponding edge of type e2p+ on node pair (v\u2032, v)) denotes that a user examines the item of node v and subsequently purchases the item of node v\u2032. These two sub edge types will share half the assigned weight of their parent edge type, i.e., e2p.\n\nThough the structure information of one single sequence may not be sufficient to improve the representations of the involved interactions, there is still some potentially valuable information from the contextually relevant interactions worth discovering since they could contribute to capturing the corresponding intentions of a target user. Hence, we also construct a user-specific graph\nG u p = (V u p , E u p )\nto enhance the understanding of each user u's personalized interests by taking the items with specific behaviors as nodes. Different from fusing the behavior information into the edges on G \u0434 , we combine the items and their associated behavior information into the nodes in the personalized graph G u p , and also consider two edge types + and \u2212 which are identical to that in G \u0434 . For the goal of distinguishing the importance of different transitions, we also consider the frequency f of each edge in both the global and personalized graphs. The construction of G \u0434 and G u p is very efficient. Specifically, we just need to traverse all the interactions in the form of each user's sequence which indicates the algorithmic complexity of our graph construction is O(|R|), where R is the whole set of observed (user, item, behavior) tuples.\n\nWe also introduce a global personalized fusion (GPF) to balance and combine the global and personalized graph representations in order to acquire the final graph representation of a sequence. Subsequently, we apply an attention layer from SASRec [10] which stacks multiple self-attention blocks followed by GPF to weigh the sequential items within the final graph representation efficiently. Then a prediction layer is placed at the end to score and rank all the candidate items for top-N recommendation.\n\n\nOUR SOLUTION 4.1 The Input and Embedding Layer\n\nFor each sequence S u , we truncate the latest L (item, behavior) pairs, i.e, S u = {(i 1 , b 1 ), (i 2 , b 2 ), . . . , (i L , b L )}, for which our goal is to predict the next item i L+1 under the behavior type b L+1 . For each interaction pair (i t , b t ), we have three one-hot indicator vectors\nx i \u2208 R m\u00d71 , x b \u2208 R 2\u00d71 and x t \u2208 R L\u00d71 corresponding to the item i t ,\nthe behavior type b t and the position t, respectively. And we obtain the corresponding latent feature vectors\nv i t \u2208 R d \u00d71 , b b t \u2208 R d \u00d71 and p t \u2208 R d \u00d71 by multiplying their embedding matrices W I \u2208 R d \u00d7m , W B \u2208 R d \u00d72 and W P \u2208 R d \u00d7L : v i t = W I x i t , b b t = W B x b t , p t = W P x t(1)\n\nThe Global Graph Layer\n\nIn order to study the behavior transitions, we utilize the proposed global graph (G \u0434 ) which captures the transitions between the items with behaviors to learn the diversified effects of each specific transition type. For each item i t in a sequence S u , we first feed its global node v i t and all the edges linked to it in G \u0434 into a global graph layer. For brevity, we remove the subscript symbol i t of the node v i t and denote it as v. We classify the neighbour groups w.r.t. the node v by six edge types, i.e., e2e, p2p, e2p+, e2p\u2212, p2e+ and p2e\u2212, to distinguish a specific transition of behaviors. Taking e2p+ as an example, we generate its neighbour groups and the corresponding update vectors as follows:\nA e2p+ (v) = {(v\u2032, f ) | (v, v\u2032, f , e2p+) \u2208 E \u0434 } (2) h e2p+ v = (v \u2032, f )\u2208A e 2p+ (v ) f \u00d7 v v \u2032 (v \u2032, f )\u2208A e 2p+ (v ) f(3)\nwhere v\u2032 denotes a node that links to v, f \u2208 R denotes the frequency of the corresponding edge, and v v \u2032 \u2208 R d \u00d71 denotes the feature vector of item i\u2032 w.r.t. the node v\u2032. For example, (v, v\u2032, f , e2p+) represents an edge from an examined item v\u2032 to a purchased item v with a frequency f . In particular, we take the mean of the sub update vectors h \nh e2p v = 1 2 (h e2p+ v + h e2p\u2212 v ), h p2e v = 1 2 (h p2e+ v + h p2e\u2212 v )(4)\nWe also design a gating network inside the global layer to weigh different item-to-item relationship:\nw \u0434 = W \u0434 [h e2e v ; h p2p v ; h e2p+ v ; h e2p\u2212 v ; h p2e+ v ; h p2e\u2212 v ](5)\nwhere W \u0434 \u2208 R 4\u00d76d is a transition matrix used to calculate the weights of the edge types, and w \u0434 = [w e2e , w p2p , w e2p , w p2e ] \u2208 R 4\u00d71 denotes the learned weights of the four basic transition types. Finally, we can obtain the node v's global graph representation h\n\u0434 v \u2208 R d \u00d71 in G \u0434 : h \u0434 v = v v + w e2e h e2e v + w p2p h p2p v + w e2p h e2p v + w p2e h p2e v(6)\nwhere v v \u2208 R d \u00d71 denotes the feature vector of the item w.r.t. the node v.\n\n\nThe Personalized Graph Layer\n\nThe structure information of one sequence is normally not as significant as that in G \u0434 since the interaction data of one user is only a tiny part of the whole data. We thus fuse the behavior information into the nodes in G u p instead of into the edges in G \u0434 to differentiate the varied importance of multiple behaviors. After that, we further learn the local context information by considering the node linked by inward and outward edges to learn the intentions of a user's Ranking candidate items by scores interaction. Different from the global graph layer, we take the summation of the item and behavior feature vectors, i.e., (v v + b v ), as the representation of the node v, and feed it into a personalized graph layer. The neighbour groups of the node v classified by the local edge type in E u p , i.e., classified by identifying whether it is an inward (+) or an outward (-) edge, are also fed simultaneously. For each node v, we have its neighbour groups A u + (v) and A u \u2212 (v) as below:\nA u + (v) = {(v\u2032, f ) | (v, v\u2032, f , +) \u2208 E u p } A u \u2212 (v) = {(v\u2032, f ) | (v, v\u2032, f , \u2212) \u2208 E u p }(7)\nThen we can further obtain the inward update vector h + v \u2208 R d \u00d71 and the outward update vector h \u2212 v \u2208 R d \u00d71 :\nh + v = (v \u2032,f )\u2208A u + (v ) f (v v \u2032 + b v \u2032 ) (v \u2032 , f )\u2208A u + (v ) f h \u2212 v = (v \u2032, f )\u2208A u \u2212 (v ) f (v v \u2032 + b v \u2032 ) (v \u2032 , f )\u2208A u \u2212 (v ) f(8)\nwhere v v \u2032 and b v \u2032 denote the item feature vector and the behavior feature vector w.r.t. the node v\u2032, respectively. With these representations, the output of the personalized graph layer w.r.t. the node v can then be calculated as below:\nh u v = v v + b v + h + v + h \u2212 v(9)\nwhere v v and b v again denote the item embedding and the behavior embedding of the node v, respectively.\n\n\nGlobal Personalized Fusion Layer\n\nTo integrate the outputs of the global and personalized layers, i.e., h \u0434 v in Eq.(6) and h u v in Eq. (9), and learn the final graph representation h v , we apply this global personalized fusion layer GPF (\u00b7, \u00b7) to assign weights to the global and personalized representations h \u0434 v and h u v . We form GPF (\u00b7, \u00b7) as follows:\n\u03b3 u = GPF (h \u0434 v , h u v ) = \u03c3 (W \u0434p [h \u0434 v ; h u v ])(10)\nwhere W \u0434p \u2208 R 1\u00d72d is a transition vector to calculate the weight of the global graph representation, i.e., \u03b3 u \u2208 R, and \u03c3 is the sigmoid function \u03c3 (\u03be ) = 1/(1 + e \u2212\u03be ). Based on the learned gating factor, we further linearly combine the outputs of the global and personalized layers:\nh v = \u03b3 u h \u0434 v + (1 \u2212 \u03b3 u )h u v(11)\nwhere h v is the final graph representation w.r.t. the node v, i.e., item i t in G \u0434 and interaction pair (i t , b t ) in G u p . By projecting each interaction pair (i t , b t ) in a sequence S u into the graph layer, we can obtain the final graph representation of the sequence S u , i.e., H u = {h 1 , h 2 , . . . , h L }.\n\n\nThe Attention Layer\n\nAt the beginning of this attention layer, a dropout layer is placed after the global personalized fusion layer. The dropout technique is typically useful for successful recommendation, and its ratio is especially highly dependent on a specific dataset which will also be investigated in Section 6.5.\n\nTo learn the inner sequential patterns, we apply stacking selfattention blocks as the attention layer to weigh and summarize each interaction in a sequence following [10]. Specifically, we first inject a learnable position embedding p t \u2208 R 1\u00d7d into the graph representation h t for each interaction (i t , b t ) in the sequence S u to capture the influence of the relative position t and obtain the input matrix X (0) = [x 1 ; x 2 ; . . . ; x L ] \u2208 R L\u00d7d of the first block:\nX (0) = h 1 + p 1 ; h 2 + p 2 ; . . . ; h L + p L(12)\nTo distinguish the different importance of each input, we then define the self-attention layer SA(\u00b7) and the pointwise feed-forward network F F N (\u00b7) as below [10]:\nSA(X) = softmax( QK T \u221a d )V (13) F F N (X) = ReLU(XW 1 + b 1 )W 2 + b 2(14)\nwhere W 1 , W 2 \u2208 R d \u00d7d and b 1 , b 2 \u2208 R d \u00d71 are the weight matrices and bias vectors. Same as [22] and [10], we define the self-attention block by combining SA(\u00b7) and F F N (\u00b7), and stack the self-attention blocks to capture deeper relationship:\nSAB(X) = F F N (SA(X))(15)X (bl ) = SAB (bl ) (X (bl \u22121) ), \u2200bl \u2208 {1, 2, . . . , BL}(16)\nwhere bl denotes the current block and BL is the number of stacking blocks. We take the last output vector x (BL) L \u2208 R d \u00d71 as the final representation of the interaction sequence.\n\n\nThe Prediction Layer\n\nTo learn how likely each candidate item would be the next interacted item under a specific behavior, we apply a prediction layer and calculate the predicted probabilities of the candidate items as below:\ny = softmax(W o [x (BL) L ; b b L+1 ] + bias o )(17)\nwhere W o \u2208 R m\u00d72d and bias o \u2208 R m\u00d71 are the weight and bias for the output, and y = [y 1 , y 2 , ..., y m ] \u2208 R m\u00d71 represents the predicted scores of all the candidate items. We then adopt the cross-entropy loss function for model training:\nL = \u2212 m i=1 Y i log(y i ) + (1 \u2212 Y i ) log(1 \u2212 y i )(18)\nwhere Y i = 1 if i is the next item and Y i = 0 otherwise, and y i is the ranking score for item i at (L + 1)-th position.\n\n\nEXPERIMENTAL SETTING 5.1 Datasets\n\nWe conduct experiments on four public datasets including Movie-Lens 1M (ML1M), Rec15, User Behavior (UB) and Tmall, and define the examinations and purchases based on their contained behaviors legitimately following [4].   11) and in the past six months before. To make the comparison fairer, we remove the data on the \"Double 11\" day to avoid the various promotion activities' influence. We split each dataset into three parts, i.e., the last interactions in sequences as the test data, the penultimate ones as the validation data and the rest as the training data [4]. The statistics of the preprocessed datasets are shown in Table 1. \n\n\nEvaluation Metrics\n\nWe evaluate the top-N recommendation performance via two common metrics, i.e., hit ratio (HR@N) and normalized discounted cumulative gain (NDCG@N), where N is the number of recommended items, HR@N represents the ratio of the number of top-N accurately predicted items, and NDCG@N further considers the ranking orders. We set N=10 in the experiments, and recommend items from all the uninteracted ones (instead of some randomly sampled ones) of each user to avoid the situation that the metrics collapse to AUC [2].\n\n\nBaselines\n\nTo demonstrate the superiority of our GPG4HSR, we choose the following state-of-the-art methods. Fossil [6]. A well-known method combining FISM [9] and FMPC [19], where the former is designed to learn the global preferences and the latter intends to capture the dynamic interests. It also balances these two components by some global and personalized factors. TransRec++ [31]. A novel MF-based model for HSR as an extended version of TransRec [5]. It applies some behavior transition vectors in an item transition space to learn the dynamics of users' heterogeneous behaviors.\n\nGRU4Rec [8]. An RNN-based model which first introduces RNN from NLP to sequential recommendation. It applies GRU on items in sequences to recurrently learn a user's preferences at each time step.\n\nCaser [21]. A CNN-based model which applies some horizontal and vertical convolution filters to a sequence of recent item embeddings to capture a user's short-term preferences. SASRec [10]. An efficient sequential model with an advanced selfattention mechanism. It stacks self-attention networks to capture deep relationship of the input and predicts the next interacted item. We use its core component, i.e., the hierarchical self-attention network, as our attention layer to learn the sequential patterns. Following [10], we predict the target item without using the target behavior, which is thus different from that of the proposed GPG4HSR.\n\nRIB [32]. An RNN-based model for HSR which incorporates the behavior embedding and the item embedding learned by a modified version of item2vec. It then adopts an RNN layer to model the sequence and an attention layer to distinguish the interactions' varied effects. SR-GNN [27]. A GNN-based sequential method which models sequences as a graph structured data to capture the items' transitions. It also learns the long-term and short-term preferences of the users using an attention network. MGNN-SPred [23]. A GNN-based model for HSR which constructs a multi-relational item graph (MRIG), splits a sequence w.r.t. different types of behaviors, and then learns the correlations of the items with a same behavior. It balances the effects of different behaviors via an efficient gating network, which is also adopted by our model to leverage the global and user-specific graph sequence representations.\n\n\nImplementation Details\n\nFollowing [10], we set the sequence length L to 50, the hidden size d to 64, the batch size to 128, and the learning rate to 0.001 for all methods. We construct a training set by a sliding window, where one single training sample contains a sequence of (item, behavior) pairs and a target behavior used to predict the target item. We also pad the items at the left if the training sequence is shorter than 50 [13]. In particular, we set the sequence length L to 10 for MGNN-SPred on ML1M since it performs poorly using the default setting. The dropout ratio is set to 0.2 for ML1M and 0.5 for the other datasets [10]. We use a single-head attention layer and set the number of blocks to 2 [13]. We set the recurrent unit size to 64 for GRU4Rec and RIB to align with the hidden size. The numbers of the vertical and horizontal filters are 4 and 16, respectively, and the height of the horizontal filters is chosen from {2, 3, 4} for Caser following [13]. For the other hyperparameters, we reference the original papers or tune them on the validation data of each dataset. The related code and scripts of GPG4HSR 5 used in our experiments are made publicly available for reproducibility. 5 https://csse.szu.edu.cn/staff/panwk/publications/GPG4HSR\n\n\nRESULTS\n\n\nMain results\n\nWe report the main results in Table 2. We re-implemented most methods in [4] and achieved very similar results, and for consistency, we used the results of MF-based methods (i.e., Fossil and TransRec++) from [31] and the results of some DL-based methods (i.e., GRU4Rec, Caser, SASRec, RIB and SR-GNN) from [4] for direct comparison. The best result in each column of each dataset is marked in bold, and the second-best one is marked with an underline.\n\nWe have the following observations from Table 2: i) Our GPG4HSR outperforms two MF-based methods, four non-GNN DL-based methods and one GNN-based method (i.e., MGNN-SPred) on all the four datasets. Besides, our GPG4HSR beats the other GNN-based method (i.e., SR-GNN) on three of the four datasets (i.e., ML1M, UB and Tmall), and achieves the second-best performance on HR@10 on Rec15 in which case its indicator score is very close to the best. The reason why GPG4HSR performs slightly worse than SR-GNN may be because of insufficient correlations between different behaviors as there are more continuous interactions with a same behavior type in Rec15 than in other datasets. 6 Hence, the results clearly demonstrate the superior performance of our GPG4HSR. ii) Compared with SASRec, our GPG4HSR surpasses it on all the four datasets, which means that the input embedding learned by our graph layers captures more correlations of the behaviors and is capable of distinguishing the user intentions of a same behavior with different context information. iii) SASRec achieves the second best on average, which demonstrates the effectiveness and superiority of the attention mechanism for sequential recommendation. Such a result indicates that the current GNN-based methods are more suitable for anonymous and short sessions but may not be very competitive for sequential recommendation with multiple behaviors probably because they ignore the correlations of different behaviors. iv) The results of the DL-based methods exceed the MFbased methods in almost all cases, which shows the advantage of modeling sequences using deep neural networks. v) TransRec++ performs better than Fossil on three of the four datasets, which indicates the potential information of the correlations (i.e., transitions) of different behaviors is useful for the next likely-to-purchase item prediction. vi) For the DL-based methods, the two GNN-based methods only defeat the non-GNN methods on Rec15, which means that the existing GNN-based models learn the sequential patterns insufficiently and their performances are better when the average length of sequences is shorter. To be specific, the average length of Rec15 is 18.41, which is much shorter than 150.96 of ML1M, 29.10 of UB and 62.29 of Tmall.\n\n\nExploration with More Types of Behaviors\n\nTo explore the capability of our GPG4HSR dealing with more types of behaviors, we conduct an exploration study and report the results in Figure 3. Note that the label on the horizontal axis with suffix '_click' means that we only take the clicking behaviors as the examinations, and the label with suffix '_mul' means that we  take all non-purchase positive feedback, i.e., clicks, adds-to-cart and favorites as the examinations. We also show the results of SAS-Rec because it performs the second best in most cases as shown in Table 2 and is also an important module of our GPG4HSR. From Figure 3 we can see that SASRec and our GPG4HSR both perform better when using more types of behaviors and our GPG4HSR beats SASRec in both scenes showing the general applicability of our GPG4HSR.\n\n\nAblation Study\n\nIn order to figure out the effectiveness of different components of our GPG4HSR, we conduct an ablation study and report the results in Table 3. Note that we only report the results on HR@10 because of the limited space and its consistent tendency with NDCG@10.\n\nWe study the performance of our GPG4HSR without the global personalized fusion layer (i.e., h v = h \u0434 v + h u v , denoted as 'w/o GPF'), without the global graph GG (i.e., h v = h u v , denoted as 'w/o GPF, GG'), without the personalized graph PG (i.e., h v = h \u0434 v , denoted as 'w/o GPF, PG'), and without GG, PG and target behavior information in the prediction layer, (i.e., our GPG4HSR reduces to SASRec, denoted as 'w/o GPF, GG, PG'). The best and the secondbest results are marked in bold and underlined, respectively. We could have the following observations from Table 3:\n\n\u2022 GPG4HSR vs. others. Our GPG4HSR with all the components achieves the best performance on average, which shows that each component in GPG4HSR contributes to learning the graph representation because the performance drops gradually as more components are removed in most cases.  Figure 4: Recommendation performance (HR@10) of each sequential recommendation method (i.e., SASRec, Caser or GRU4Rec) and that of adding our GPG as a generic behavior-aware framework to it, denoted as \"Benchmark\" and \"Bench-mark+GPG\", respectively. And the first one (i.e., without the global graph GG) slightly exceeds the second one (i.e., without the personalized graph PG), indicating the distinct user intentions of the behaviors with the local context information which offers more learnable information than their correlations in GG.\n\nAccording to Table 3 and the corresponding observations, we can see that our GPG4HSR again achieves the best on average, which indicates that each component is useful. In particular, the personalized graph PG captures the distinct user intentions of different behaviors and the global graph GG learns the correlations of behaviors from their transitions, and the fusion layer combines these two complementary components.\n\n\nFramework Study\n\nAs described in Section 4.5, we adopt the advanced attention technique to learn the sequential patterns in our GPG4HSR. In this subsection, we explore whether our global and personalized graphs (GPG) would work well with other sequential models. For this purpose, we conduct exploratory experiments with some other sequential recommendation methods.\n\nSpecifically, we replace the attention layer in our GPG4HSR shown in Figure 2 with the convolution component in Caser [21] and GRU in GRU4Rec [8], which are denoted as 'Caser+GPG' and 'GRU+GPG', respectively. Note that our GPG4HSR can be considered as 'SASRec+GPG' since its attention layer is designed using the same technology with that in SASRec [10]. With GPG being integrated, we investigate whether the three effective sequential models will be boosted and report the results of this framework study in Figure 4, where the blue bars represent the backbone models and the orange bars represent the ones with GPG as the behavior-aware framework. Similarly, due to space limitation and similar observations on two metrics, we also report the results on HR@10 only.\n\nThrough the results in Figure 4, we witness that each sequential model with GPG as a behavior-aware framework outperforms the corresponding original model on all the four datasets, which demonstrates the ability of our GPG to capture the rich behavior information including their transitions and their representations learned with the varied influences of adjacent nodes.\n\n\nImpact of the Dropout Ratio\n\nWe adjust the dropout ratio \u2208 {0.0, 0.1, 0.2, . . . , 0.9} for SASRec and our GPG4HSR on four datasets and show the performance in Figure 5. We use HR@10 and NDCG@10 as the labels on the vertical axis for consistency with the main results. We can see that there is a similar tendency of the results with the change of the values of the dropout ratio for both methods, and our GPG4HSR performs better than SASRec in almost all cases. This again indicates the effectiveness of our GBG. Moreover, the dropout ratios to achieve the best performance on different datasets are different and there is a sharp drop at a turning point with a large value of the dropout ratio, e.g., 0.8 to 0.9 on ML1M, and 0.7 to 0.8 on UB and Tmall. The results in Figure 5 also provide us some guidance on configuring the dropout ratio on a certain dataset, i.e., a low value is more suitable for datasets with low sparsity, and a medium value is better for datasets with high sparsity.\n\n\nCONCLUSIONS AND FUTURE WORK\n\nIn this paper, we address two limitations of existing works for heterogeneous sequential recommendation (HSR), i.e., modeling different behaviors separately, and learning the user interests beneath behaviors without considering the local context information. To address these two issues, we propose a novel solution called GPG4HSR, which captures the transitions of behaviors via a global graph (GG), and learns the user intentions of different feedback with adjacent interactions via a personalized graph (PG). Extensive empirical studies on four public datasets demonstrate that our GPG4HSR achieves the state-of-the-art performance compared with several competitive baselines. Ablation studies also show that the design of PG, GG and GPF in our GPG4HSR is reasonable.\n\nFor future works, we will take the users' privacy [12,14] into consideration and design some GNN-and federated learning-based methods for the studied problem. Moreover, we are interested in exploiting some textual information such as the users' reviews and the items' attributes to further improve our model.\n\nFigure 1 :\n1Illustration of the heterogeneous sequential recommendation (HSR) problem, where each number denotes an item ID.\n\n\nbalance the importance of the inward and outward relations:\n\nFigure 2 :\n2Illustration of our Global and Personalized Graphs for Heterogeneous Sequential Recommendation (GPG4HSR).\n\nFigure 3 :\n3Recommendation performance in scenes with two (marked with '_click') and more than two (marked with '_mul') types of behaviors on UB and Tmall. Note that there are only two types of behaviors in Rec15, which is thus not included in this study.\n\nFigure 5 :\n5Recommendation performance of SASRec and our GPG4HSR with different values of dropout ratios. \u2022 GPG4HSR vs. 'w/o GPF'. The results show that our GPG4HSR with complete structure outperforms GPG4HSR without the fusion layer on ML1M, Rec15 and Tmall, and there is a very small gap between them on Rec15. These results show that the fusion component is effective in balancing the two different graph representations. \u2022 'w/o GPF, GG', 'w/o GPF, PG' vs. 'w/o GPF, GG, PG' . The former two outperform the last one on all the four datasets, demonstrating the effectiveness of PG and GG as each single component for improving the recommendation performance.\n\nTable 1 :\n1Statistics of the preprocessed data used in the experiments.Dataset #Users #Items #Examinations #Purchases Density \nML1M 5,645 2,357 \n628,892 \n223,305 \n6.41% \nRec15 36,917 9,621 \n446,442 \n233,263 \n0.45% \nUB \n20,858 30,793 \n470,731 \n136,250 \n0.09% \nTmall 17,209 16,176 \n831,117 \n240,901 \n0.38% \n\n\n\nTable 2 :\n2Recommendation performance of two MF-based methods, four non-GNN DL-based methods, two GNN-based methods and our GPG4HSR on four datasets. The results except MGNN-SPred and our GPG4HSR are copied from[31] and[4] for direct comparison.Methods \nML1M \nRec15 \nUB \nTmall \nHR@10 NDCG@10 \nHR@10 NDCG@10 \nHR@10 NDCG@10 \nHR@10 NDCG@10 \nFossil \n0.1114 \n0.0528 \n0.3736 \n0.2029 \n0.0508 \n0.0270 \n0.0437 \n0.0241 \nTransRec++ \n0.1088 \n0.0508 \n0.4064 \n0.2209 \n0.0661 \n0.0413 \n0.0593 \n0.0377 \nGRU4Rec \n0.1249 \n0.0600 \n0.3588 \n0.1921 \n0.0571 \n0.0320 \n0.0744 \n0.0431 \nCaser \n0.1215 \n0.0608 \n0.3985 \n0.2042 \n0.0562 \n0.0289 \n0.0390 \n0.0207 \nSASRec \n0.1350 \n0.0651 \n0.3615 \n0.1889 \n0.0744 \n0.0412 \n0.0862 \n0.0521 \nRIB \n0.1302 \n0.0646 \n0.3668 \n0.1921 \n0.0660 \n0.0370 \n0.0776 \n0.0454 \nSR-GNN \n0.1267 \n0.0614 \n0.4211 \n0.2291 \n0.0575 \n0.0307 \n0.0707 \n0.0419 \nMGNN-SPred 0.1134 \n0.0548 \n0.4164 \n0.2108 \n0.0727 \n0.0386 \n0.0449 \n0.0236 \nGPG4HSR \n0.1460 \n0.0737 \n0.4198 \n0.2160 \n0.0830 \n0.0462 \n0.0944 \n0.0548 \n\nUB_click \nUB_mul \nTmall_click \nTmall_mul \nDataset \n\n0.02 \n\n0.03 \n\n0.04 \n\n0.05 \n\n0.06 \n\n0.07 \n\n0.08 \n\n0.09 \n\n0.10 \n\n0.11 \n\nIndicator score \n\nSASRec HR@10 \nGPG4HSR HR@10 \nSASRec NDCG@10 \nGPG4HSR NDCG@10 \n\n\n\nTable 3 :\n3Recommendation performance (HR@10) of our GPG4HSR with different architectures for ablation study.Architectures \nML1M Rec15 \nUB \nTmall \nw/o GPF \n0.1454 0.4122 0.0840 0.0901 \nw/o GPF, GG \n0.1456 0.4104 0.0815 0.0899 \nw/o GPF, PG \n0.1422 0.3785 0.0769 0.0870 \nw/o GPF, GG, PG 0.1350 0.3615 0.0744 0.0862 \nGPG4HSR \n0.1460 0.4198 0.0830 0.0944 \n\n\nhttps://grouplens.org/datasets/movielens/1m\nhttps://recsys.acm.org/recsys15/challenge 3 https://tianchi.aliyun.com/dataset/dataDetail?dataId=649 4 https://tianchi.aliyun.com/dataset/dataDetail?dataId=42\n91.6% sequences in Rec15 exist a continuous sub-sequence of clicks (i.e., examinations) which takes 60% length of its parent sequence.\nACKNOWLEDGMENTSWe thank the support of National Natural Science Foundation of China Nos. 62172283 and 61836005.\nGraph Heterogeneous Multi-Relational Recommendation. Chong Chen, Weizhi Ma, Min Zhang, Zhaowei Wang, Xiuqiang He, Chenyang Wang, Yiqun Liu, Shaoping Ma, AAAI'21. Chong Chen, Weizhi Ma, Min Zhang, Zhaowei Wang, Xiuqiang He, Chenyang Wang, Yiqun Liu, and Shaoping Ma. 2021. Graph Heterogeneous Multi-Relational Recommendation. In AAAI'21. 3958-3966.\n\nA Case Study on Sampling Strategies for Evaluating Neural Sequential Item Recommendation Models. Alexander Dallmann, Daniel Zoller, Andreas Hotho, RecSys'21. Alexander Dallmann, Daniel Zoller, and Andreas Hotho. 2021. A Case Study on Sampling Strategies for Evaluating Neural Sequential Item Recommendation Models. In RecSys'21. 505-514.\n\nInductive Representation Learning on Large Graphs. William L Hamilton, Zhitao Ying, Jure Leskovec, NeurIPS'17. William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Represen- tation Learning on Large Graphs. In NeurIPS'17. 1024-1034.\n\nBAR: Behavior-Aware Recommendation for Sequential Heterogeneous One-Class Collaborative Filtering. Mingkai He, Weike Pan, Zhong Ming, Information Sciences. 608Mingkai He, Weike Pan, and Zhong Ming. 2022. BAR: Behavior-Aware Rec- ommendation for Sequential Heterogeneous One-Class Collaborative Filtering. Information Sciences 608 (2022), 881-899.\n\nTranslation-based recommendation. Ruining He, Wang-Cheng Kang, Julian Mcauley, RecSys'17. Ruining He, Wang-Cheng Kang, and Julian McAuley. 2017. Translation-based recommendation. In RecSys'17. 161-169.\n\nFusing similarity models with Markov chains for sparse sequential recommendation. Ruining He, Julian Mcauley, ICDM'16. Ruining He and Julian McAuley. 2016. Fusing similarity models with Markov chains for sparse sequential recommendation. In ICDM'16. 191-200.\n\nLightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yong-Dong Zhang, Meng Wang, SIGIR'20. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yong-Dong Zhang, and Meng Wang. 2020. LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. In SIGIR'20. 639-648.\n\nSession-based Recommendations with Recurrent Neural Networks. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, ICLR'16. Linas Baltrunas, and Domonkos TikkBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In ICLR'16.\n\nFISM: Factored Item Similarity Models for top-N Recommender Systems. Santosh Kabbur, Xia Ning, George Karypis, KDD'13. Santosh Kabbur, Xia Ning, and George Karypis. 2013. FISM: Factored Item Similarity Models for top-N Recommender Systems. In KDD'13. 659-667.\n\nSelf-Attentive Sequential Recommendation. Wang-Cheng Kang, Julian J Mcauley, ICDM'18. Wang-Cheng Kang and Julian J. McAuley. 2018. Self-Attentive Sequential Rec- ommendation. In ICDM'18. 197-206.\n\nLearning from History and Present: Next-Item Recommendation via Discriminatively Exploiting User Behaviors. Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, Enhong Chen, KDD'18. Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, and Enhong Chen. 2018. Learning from History and Present: Next-Item Recommendation via Discrimina- tively Exploiting User Behaviors. In KDD'18. 1734-1743.\n\nSurvey of Recommender Systems Based on Federated Learning (in Chinese). Feng Liang, Enyue Yang, Weike Pan, Qiang Yang, Zhong Ming, SCIENTIA SINICA Informationis. 525Feng Liang, Enyue Yang, Weike Pan, Qiang Yang, and Zhong Ming. 2022. Survey of Recommender Systems Based on Federated Learning (in Chinese). SCIENTIA SINICA Informationis 52(5) (2022), 713-741.\n\nFISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation. Jing Lin, Weike Pan, Zhong Ming, RecSys'20. Jing Lin, Weike Pan, and Zhong Ming. 2020. FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation. In RecSys'20. 130- 139.\n\nRecommendation Framework via Fake Marks and Secret Sharing. Zhaohao Lin, Weike Pan, Qiang Yang, Zhong Ming, ACM Transactions on Information Systems. Zhaohao Lin, Weike Pan, Qiang Yang, and Zhong Ming. 2022. Recommendation Framework via Fake Marks and Secret Sharing. ACM Transactions on Information Systems (2022).\n\nUltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation. Kelong Mao, Jieming Zhu, Xi Xiao, Biao Lu, Zhaowei Wang, Xiuqiang He, CIKM'21. Kelong Mao, Jieming Zhu, Xi Xiao, Biao Lu, Zhaowei Wang, and Xiuqiang He. 2017. UltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation. In CIKM'21. 1253-1262.\n\nIncorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation. Wenjing Meng, Deqing Yang, Yanghua Xiao, SIGIR'20. Wenjing Meng, Deqing Yang, and Yanghua Xiao. 2020. Incorporating User Micro-behaviors and Item Knowledge into Multi-task Learning for Session-based Recommendation. In SIGIR'20. 1091-1100.\n\nMulti-behavior Graph Neural Networks for Session-based Recommendation (MLDBBI'21). Wenhao Pan, Kai Yang, Wenhao Pan and Kai Yang. 2021. Multi-behavior Graph Neural Networks for Session-based Recommendation (MLDBBI'21). 756-761.\n\nBPR: Bayesian Personalized Ranking from Implicit Feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, UAI'09. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In UAI'09. 452-461.\n\nFactorizing personalized Markov chains for next-basket recommendation. Steffen Rendle, Christoph Freudenthaler, Lars Schmidt-Thieme, WWW'10. Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor- izing personalized Markov chains for next-basket recommendation. In WWW'10. 811-820.\n\nMulti-behavior Graph Contextual Aware Network for Session-based Recommendation. Qi Shen, Lingfei Wu, Yitong Pang, Yiming Zhang, Zhihua Wei, Fangli Xu, Bo Long, CoRR abs/2109.11903Qi Shen, Lingfei Wu, Yitong Pang, Yiming Zhang, Zhihua Wei, Fangli Xu, and Bo Long. 2021. Multi-behavior Graph Contextual Aware Network for Session-based Recommendation. CoRR abs/2109.11903 (2021).\n\nPersonalized top-N Sequential Recommendation via Convolutional Sequence Embedding. Jiaxi Tang, Ke Wang, WSDM'18. Jiaxi Tang and Ke Wang. 2018. Personalized top-N Sequential Recommendation via Convolutional Sequence Embedding. In WSDM'18. 565-573.\n\nAttention is All You Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, NeurIPS'17. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All You Need. In NeurIPS'17. 6000-6010.\n\nBeyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction. Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, Hongyuan Zha, WWW'20. Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and Hongyuan Zha. 2020. Beyond Clicks: Modeling Multi-Relational Item Graph for Session- Based Target Behavior Prediction. In WWW'20. 3056-3062.\n\nNeural Graph Collaborative Filtering. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, Tat-Seng Chua, SIGIR'19. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. In SIGIR'19. 165-174.\n\nGlobal Context Enhanced Graph Neural Networks for Session-based Recommendation. Ziyang Wang, Wei Wei, Gao Cong, Xiao-Li Li, Xianling Mao, Minghui Qiu, SIGIR'20. Ziyang Wang, Wei Wei, Gao Cong, Xiao-Li Li, Xianling Mao, and Minghui Qiu. 2020. Global Context Enhanced Graph Neural Networks for Session-based Rec- ommendation. In SIGIR'20. 169-178.\n\nContrastive Meta Learning with Behavior Multiplicity for Recommendation. Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, Dawei Yin, WSDM'22. Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022. Contrastive Meta Learning with Behavior Multiplicity for Recommendation. In WSDM'22. 1120-1128.\n\nSession-based Recommendation with Graph Neural Networks. Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan, AAAI'19. Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. 2019. Session-based Recommendation with Graph Neural Networks. In AAAI'19. 346-353.\n\nGraph Meta Network for Multi-Behavior Recommendation. Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, Liefeng Bo, SIGIR'21. Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, and Liefeng Bo. 2021. Graph Meta Network for Multi-Behavior Recommendation. In SIGIR'21. 757-766.\n\nGraph Contextualized Self-Attention Network for Session-based Recommendation. Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, S Victor, Jiajie Sheng, Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. IJCAI'19Chengfeng Xu, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Fuzhen Zhuang, Junhua Fang, and Xiaofang Zhou. 2019. Graph Contextualized Self- Attention Network for Session-based Recommendation. In IJCAI'19. 3940-3946.\n\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, Jure Leskovec, KDD'18. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In KDD'18. 974-983.\n\nTransRec++: Translation-based Sequential Recommendation with Heterogeneous Feedback. Zhuoxin Zhan, Mingkai He, Weike Pan, Zhong Ming, fcs/EN/10.1007/s11704-022-1184-8FCS. 162162615Zhuoxin Zhan, Mingkai He, Weike Pan, and Zhong Ming. 16(2):162615, 2022. TransRec++: Translation-based Sequential Recommendation with Heterogeneous Feedback. FCS (16(2):162615, 2022). https://doi.org/fcs/EN/10.1007/s11704-022- 1184-8\n\nMicro Behaviors: A New Perspective in E-commerce Recommender Systems. Meizi Zhou, Zhouye Ding, Jiliang Tang, Dawei Yin, WSDM'18. Meizi Zhou, Zhouye Ding, Jiliang Tang, and Dawei Yin. 2018. Micro Behaviors: A New Perspective in E-commerce Recommender Systems. In WSDM'18. 727-735.\n", "annotations": {"author": "[{\"end\":187,\"start\":175},{\"end\":218,\"start\":188},{\"end\":250,\"start\":219},{\"end\":281,\"start\":251},{\"end\":310,\"start\":282},{\"end\":343,\"start\":311},{\"end\":356,\"start\":344},{\"end\":368,\"start\":357},{\"end\":380,\"start\":369},{\"end\":391,\"start\":381},{\"end\":403,\"start\":392},{\"end\":407,\"start\":404},{\"end\":413,\"start\":408},{\"end\":450,\"start\":414},{\"end\":487,\"start\":451},{\"end\":543,\"start\":488},{\"end\":580,\"start\":544},{\"end\":617,\"start\":581},{\"end\":664,\"start\":618}]", "publisher": null, "author_last_name": "[{\"end\":186,\"start\":182},{\"end\":198,\"start\":196},{\"end\":229,\"start\":227},{\"end\":260,\"start\":257},{\"end\":292,\"start\":288},{\"end\":318,\"start\":314},{\"end\":355,\"start\":351},{\"end\":367,\"start\":365},{\"end\":379,\"start\":377},{\"end\":390,\"start\":387},{\"end\":402,\"start\":398}]", "author_first_name": "[{\"end\":181,\"start\":175},{\"end\":195,\"start\":188},{\"end\":226,\"start\":219},{\"end\":256,\"start\":251},{\"end\":287,\"start\":282},{\"end\":313,\"start\":311},{\"end\":350,\"start\":344},{\"end\":364,\"start\":357},{\"end\":376,\"start\":369},{\"end\":386,\"start\":381},{\"end\":397,\"start\":392},{\"end\":406,\"start\":404},{\"end\":412,\"start\":408}]", "author_affiliation": "[{\"end\":449,\"start\":415},{\"end\":486,\"start\":452},{\"end\":542,\"start\":489},{\"end\":579,\"start\":545},{\"end\":616,\"start\":582},{\"end\":663,\"start\":619}]", "title": "[{\"end\":128,\"start\":1},{\"end\":792,\"start\":665}]", "venue": "[{\"end\":854,\"start\":794}]", "abstract": "[{\"end\":2779,\"start\":1159}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4927,\"start\":4924},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4930,\"start\":4927},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5153,\"start\":5150},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5156,\"start\":5153},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5159,\"start\":5156},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5162,\"start\":5159},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5296,\"start\":5293},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5854,\"start\":5850},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5874,\"start\":5871},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6077,\"start\":6073},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6402,\"start\":6398},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8976,\"start\":8972},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9150,\"start\":9147},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9551,\"start\":9548},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9553,\"start\":9551},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9556,\"start\":9553},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9559,\"start\":9556},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9562,\"start\":9559},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9672,\"start\":9668},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9711,\"start\":9708},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9781,\"start\":9778},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9921,\"start\":9917},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10078,\"start\":10075},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10131,\"start\":10127},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10327,\"start\":10323},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10330,\"start\":10327},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10404,\"start\":10400},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11379,\"start\":11376},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11564,\"start\":11560},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11716,\"start\":11713},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11837,\"start\":11834},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12052,\"start\":12049},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12062,\"start\":12058},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12078,\"start\":12074},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12091,\"start\":12087},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12094,\"start\":12091},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12097,\"start\":12094},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12100,\"start\":12097},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12134,\"start\":12131},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12291,\"start\":12287},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12429,\"start\":12425},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12630,\"start\":12626},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12633,\"start\":12630},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12636,\"start\":12633},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12848,\"start\":12844},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12861,\"start\":12857},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12981,\"start\":12977},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13635,\"start\":13631},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13657,\"start\":13654},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13880,\"start\":13876},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14137,\"start\":14133},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14304,\"start\":14300},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14465,\"start\":14461},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14623,\"start\":14619},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14639,\"start\":14635},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16985,\"start\":16981},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16998,\"start\":16995},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17014,\"start\":17010},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17454,\"start\":17450},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":17474,\"start\":17470},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20750,\"start\":20746},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":25584,\"start\":25581},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27009,\"start\":27005},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27532,\"start\":27528},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27713,\"start\":27709},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27722,\"start\":27718},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":29093,\"start\":29090},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":29443,\"start\":29440},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30047,\"start\":30044},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30169,\"start\":30166},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30209,\"start\":30206},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":30223,\"start\":30219},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":30437,\"start\":30433},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30508,\"start\":30505},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":30651,\"start\":30648},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":30847,\"start\":30843},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":31025,\"start\":31021},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":31359,\"start\":31355},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31491,\"start\":31487},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31761,\"start\":31757},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31990,\"start\":31986},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":32424,\"start\":32420},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":32823,\"start\":32819},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33026,\"start\":33022},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":33103,\"start\":33099},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":33362,\"start\":33358},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":33597,\"start\":33596},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33757,\"start\":33754},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":33893,\"start\":33889},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33990,\"start\":33987},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":34812,\"start\":34811},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":39843,\"start\":39839},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":39866,\"start\":39863},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":40074,\"start\":40070},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":42713,\"start\":42709},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":42716,\"start\":42713},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":44718,\"start\":44714},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":44725,\"start\":44722}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":43093,\"start\":42968},{\"attributes\":{\"id\":\"fig_1\"},\"end\":43155,\"start\":43094},{\"attributes\":{\"id\":\"fig_3\"},\"end\":43274,\"start\":43156},{\"attributes\":{\"id\":\"fig_5\"},\"end\":43531,\"start\":43275},{\"attributes\":{\"id\":\"fig_6\"},\"end\":44193,\"start\":43532},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":44501,\"start\":44194},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":45698,\"start\":44502},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":46053,\"start\":45699}]", "paragraph": "[{\"end\":3348,\"start\":2795},{\"end\":4876,\"start\":3350},{\"end\":6605,\"start\":4878},{\"end\":7831,\"start\":6607},{\"end\":8892,\"start\":7833},{\"end\":10651,\"start\":8936},{\"end\":11069,\"start\":10681},{\"end\":13399,\"start\":11112},{\"end\":14932,\"start\":13444},{\"end\":15365,\"start\":14934},{\"end\":16102,\"start\":15406},{\"end\":16151,\"start\":16104},{\"end\":16534,\"start\":16277},{\"end\":17758,\"start\":16549},{\"end\":18091,\"start\":17787},{\"end\":18206,\"start\":18093},{\"end\":19240,\"start\":18227},{\"end\":19630,\"start\":19242},{\"end\":20498,\"start\":19656},{\"end\":21004,\"start\":20500},{\"end\":21355,\"start\":21055},{\"end\":21540,\"start\":21430},{\"end\":22475,\"start\":21759},{\"end\":22954,\"start\":22603},{\"end\":23134,\"start\":23033},{\"end\":23484,\"start\":23213},{\"end\":23662,\"start\":23586},{\"end\":24696,\"start\":23695},{\"end\":24911,\"start\":24798},{\"end\":25298,\"start\":25058},{\"end\":25441,\"start\":25336},{\"end\":25804,\"start\":25478},{\"end\":26150,\"start\":25864},{\"end\":26514,\"start\":26189},{\"end\":26837,\"start\":26538},{\"end\":27314,\"start\":26839},{\"end\":27533,\"start\":27369},{\"end\":27860,\"start\":27611},{\"end\":28131,\"start\":27950},{\"end\":28359,\"start\":28156},{\"end\":28656,\"start\":28413},{\"end\":28836,\"start\":28714},{\"end\":29511,\"start\":28874},{\"end\":30048,\"start\":29534},{\"end\":30638,\"start\":30062},{\"end\":30835,\"start\":30640},{\"end\":31481,\"start\":30837},{\"end\":32383,\"start\":31483},{\"end\":33654,\"start\":32410},{\"end\":34132,\"start\":33681},{\"end\":36415,\"start\":34134},{\"end\":37245,\"start\":36460},{\"end\":37525,\"start\":37264},{\"end\":38106,\"start\":37527},{\"end\":38928,\"start\":38108},{\"end\":39350,\"start\":38930},{\"end\":39719,\"start\":39370},{\"end\":40488,\"start\":39721},{\"end\":40861,\"start\":40490},{\"end\":41855,\"start\":40893},{\"end\":42657,\"start\":41887},{\"end\":42967,\"start\":42659}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16276,\"start\":16152},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18226,\"start\":18207},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19655,\"start\":19631},{\"attributes\":{\"id\":\"formula_3\"},\"end\":21429,\"start\":21356},{\"attributes\":{\"id\":\"formula_4\"},\"end\":21733,\"start\":21541},{\"attributes\":{\"id\":\"formula_5\"},\"end\":22602,\"start\":22476},{\"attributes\":{\"id\":\"formula_6\"},\"end\":23032,\"start\":22955},{\"attributes\":{\"id\":\"formula_7\"},\"end\":23212,\"start\":23135},{\"attributes\":{\"id\":\"formula_8\"},\"end\":23585,\"start\":23485},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24797,\"start\":24697},{\"attributes\":{\"id\":\"formula_10\"},\"end\":25057,\"start\":24912},{\"attributes\":{\"id\":\"formula_11\"},\"end\":25335,\"start\":25299},{\"attributes\":{\"id\":\"formula_12\"},\"end\":25863,\"start\":25805},{\"attributes\":{\"id\":\"formula_13\"},\"end\":26188,\"start\":26151},{\"attributes\":{\"id\":\"formula_14\"},\"end\":27368,\"start\":27315},{\"attributes\":{\"id\":\"formula_15\"},\"end\":27610,\"start\":27534},{\"attributes\":{\"id\":\"formula_16\"},\"end\":27887,\"start\":27861},{\"attributes\":{\"id\":\"formula_17\"},\"end\":27949,\"start\":27887},{\"attributes\":{\"id\":\"formula_18\"},\"end\":28412,\"start\":28360},{\"attributes\":{\"id\":\"formula_19\"},\"end\":28713,\"start\":28657}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":29509,\"start\":29502},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":33718,\"start\":33711},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":34181,\"start\":34174},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36995,\"start\":36988},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":37407,\"start\":37400},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":38105,\"start\":38098},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":38950,\"start\":38943}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2793,\"start\":2781},{\"attributes\":{\"n\":\"2\"},\"end\":8934,\"start\":8895},{\"attributes\":{\"n\":\"2.2\"},\"end\":10679,\"start\":10654},{\"attributes\":{\"n\":\"2.2.1\"},\"end\":11110,\"start\":11072},{\"attributes\":{\"n\":\"2.2.2\"},\"end\":13442,\"start\":13402},{\"attributes\":{\"n\":\"3\"},\"end\":15404,\"start\":15368},{\"attributes\":{\"n\":\"3.2\"},\"end\":16547,\"start\":16537},{\"attributes\":{\"n\":\"3.3\"},\"end\":17785,\"start\":17761},{\"attributes\":{\"n\":\"4\"},\"end\":21053,\"start\":21007},{\"attributes\":{\"n\":\"4.2\"},\"end\":21757,\"start\":21735},{\"attributes\":{\"n\":\"4.3\"},\"end\":23693,\"start\":23665},{\"attributes\":{\"n\":\"4.4\"},\"end\":25476,\"start\":25444},{\"attributes\":{\"n\":\"4.5\"},\"end\":26536,\"start\":26517},{\"attributes\":{\"n\":\"4.6\"},\"end\":28154,\"start\":28134},{\"attributes\":{\"n\":\"5\"},\"end\":28872,\"start\":28839},{\"attributes\":{\"n\":\"5.2\"},\"end\":29532,\"start\":29514},{\"attributes\":{\"n\":\"5.3\"},\"end\":30060,\"start\":30051},{\"attributes\":{\"n\":\"5.4\"},\"end\":32408,\"start\":32386},{\"attributes\":{\"n\":\"6\"},\"end\":33664,\"start\":33657},{\"attributes\":{\"n\":\"6.1\"},\"end\":33679,\"start\":33667},{\"attributes\":{\"n\":\"6.2\"},\"end\":36458,\"start\":36418},{\"attributes\":{\"n\":\"6.3\"},\"end\":37262,\"start\":37248},{\"attributes\":{\"n\":\"6.4\"},\"end\":39368,\"start\":39353},{\"attributes\":{\"n\":\"6.5\"},\"end\":40891,\"start\":40864},{\"attributes\":{\"n\":\"7\"},\"end\":41885,\"start\":41858},{\"end\":42979,\"start\":42969},{\"end\":43167,\"start\":43157},{\"end\":43286,\"start\":43276},{\"end\":43543,\"start\":43533},{\"end\":44204,\"start\":44195},{\"end\":44512,\"start\":44503},{\"end\":45709,\"start\":45700}]", "table": "[{\"end\":44501,\"start\":44266},{\"end\":45698,\"start\":44748},{\"end\":46053,\"start\":45809}]", "figure_caption": "[{\"end\":43093,\"start\":42981},{\"end\":43155,\"start\":43096},{\"end\":43274,\"start\":43169},{\"end\":43531,\"start\":43288},{\"end\":44193,\"start\":43545},{\"end\":44266,\"start\":44206},{\"end\":44748,\"start\":44514},{\"end\":45809,\"start\":45711}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16533,\"start\":16525},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17889,\"start\":17881},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":29099,\"start\":29097},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":36605,\"start\":36597},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":37057,\"start\":37049},{\"end\":38395,\"start\":38387},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":39798,\"start\":39790},{\"end\":40238,\"start\":40230},{\"end\":40521,\"start\":40513},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":41032,\"start\":41024},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":41641,\"start\":41633}]", "bib_author_first_name": "[{\"end\":46562,\"start\":46557},{\"end\":46575,\"start\":46569},{\"end\":46583,\"start\":46580},{\"end\":46598,\"start\":46591},{\"end\":46613,\"start\":46605},{\"end\":46626,\"start\":46618},{\"end\":46638,\"start\":46633},{\"end\":46652,\"start\":46644},{\"end\":46959,\"start\":46950},{\"end\":46976,\"start\":46970},{\"end\":46992,\"start\":46985},{\"end\":47250,\"start\":47243},{\"end\":47252,\"start\":47251},{\"end\":47269,\"start\":47263},{\"end\":47280,\"start\":47276},{\"end\":47548,\"start\":47541},{\"end\":47558,\"start\":47553},{\"end\":47569,\"start\":47564},{\"end\":47831,\"start\":47824},{\"end\":47846,\"start\":47836},{\"end\":47859,\"start\":47853},{\"end\":48082,\"start\":48075},{\"end\":48093,\"start\":48087},{\"end\":48342,\"start\":48334},{\"end\":48351,\"start\":48347},{\"end\":48363,\"start\":48358},{\"end\":48373,\"start\":48370},{\"end\":48387,\"start\":48378},{\"end\":48399,\"start\":48395},{\"end\":48670,\"start\":48664},{\"end\":48689,\"start\":48679},{\"end\":48978,\"start\":48971},{\"end\":48990,\"start\":48987},{\"end\":49003,\"start\":48997},{\"end\":49215,\"start\":49205},{\"end\":49228,\"start\":49222},{\"end\":49230,\"start\":49229},{\"end\":49471,\"start\":49468},{\"end\":49482,\"start\":49476},{\"end\":49491,\"start\":49489},{\"end\":49503,\"start\":49497},{\"end\":49514,\"start\":49511},{\"end\":49526,\"start\":49520},{\"end\":49825,\"start\":49821},{\"end\":49838,\"start\":49833},{\"end\":49850,\"start\":49845},{\"end\":49861,\"start\":49856},{\"end\":49873,\"start\":49868},{\"end\":50210,\"start\":50206},{\"end\":50221,\"start\":50216},{\"end\":50232,\"start\":50227},{\"end\":50482,\"start\":50475},{\"end\":50493,\"start\":50488},{\"end\":50504,\"start\":50499},{\"end\":50516,\"start\":50511},{\"end\":50820,\"start\":50814},{\"end\":50833,\"start\":50826},{\"end\":50841,\"start\":50839},{\"end\":50852,\"start\":50848},{\"end\":50864,\"start\":50857},{\"end\":50879,\"start\":50871},{\"end\":51200,\"start\":51193},{\"end\":51213,\"start\":51207},{\"end\":51227,\"start\":51220},{\"end\":51522,\"start\":51516},{\"end\":51531,\"start\":51528},{\"end\":51728,\"start\":51721},{\"end\":51746,\"start\":51737},{\"end\":51766,\"start\":51762},{\"end\":51780,\"start\":51776},{\"end\":52049,\"start\":52042},{\"end\":52067,\"start\":52058},{\"end\":52087,\"start\":52083},{\"end\":52360,\"start\":52358},{\"end\":52374,\"start\":52367},{\"end\":52385,\"start\":52379},{\"end\":52398,\"start\":52392},{\"end\":52412,\"start\":52406},{\"end\":52424,\"start\":52418},{\"end\":52431,\"start\":52429},{\"end\":52744,\"start\":52739},{\"end\":52753,\"start\":52751},{\"end\":52937,\"start\":52931},{\"end\":52951,\"start\":52947},{\"end\":52965,\"start\":52961},{\"end\":52979,\"start\":52974},{\"end\":52996,\"start\":52991},{\"end\":53009,\"start\":53004},{\"end\":53011,\"start\":53010},{\"end\":53025,\"start\":53019},{\"end\":53039,\"start\":53034},{\"end\":53351,\"start\":53348},{\"end\":53361,\"start\":53358},{\"end\":53375,\"start\":53369},{\"end\":53383,\"start\":53381},{\"end\":53391,\"start\":53389},{\"end\":53403,\"start\":53399},{\"end\":53417,\"start\":53409},{\"end\":53681,\"start\":53676},{\"end\":53696,\"start\":53688},{\"end\":53705,\"start\":53701},{\"end\":53716,\"start\":53712},{\"end\":53731,\"start\":53723},{\"end\":53967,\"start\":53961},{\"end\":53977,\"start\":53974},{\"end\":53986,\"start\":53983},{\"end\":54000,\"start\":53993},{\"end\":54013,\"start\":54005},{\"end\":54026,\"start\":54019},{\"end\":54304,\"start\":54301},{\"end\":54314,\"start\":54310},{\"end\":54330,\"start\":54322},{\"end\":54340,\"start\":54336},{\"end\":54351,\"start\":54345},{\"end\":54363,\"start\":54358},{\"end\":54613,\"start\":54610},{\"end\":54624,\"start\":54618},{\"end\":54638,\"start\":54631},{\"end\":54649,\"start\":54644},{\"end\":54660,\"start\":54656},{\"end\":54672,\"start\":54666},{\"end\":54906,\"start\":54898},{\"end\":54916,\"start\":54912},{\"end\":54925,\"start\":54921},{\"end\":54937,\"start\":54933},{\"end\":54950,\"start\":54943},{\"end\":55196,\"start\":55187},{\"end\":55209,\"start\":55201},{\"end\":55222,\"start\":55216},{\"end\":55229,\"start\":55228},{\"end\":55244,\"start\":55238},{\"end\":55610,\"start\":55607},{\"end\":55624,\"start\":55617},{\"end\":55636,\"start\":55629},{\"end\":55647,\"start\":55643},{\"end\":55669,\"start\":55662},{\"end\":55671,\"start\":55670},{\"end\":55686,\"start\":55682},{\"end\":55990,\"start\":55983},{\"end\":56004,\"start\":55997},{\"end\":56014,\"start\":56009},{\"end\":56025,\"start\":56020},{\"end\":56388,\"start\":56383},{\"end\":56401,\"start\":56395},{\"end\":56415,\"start\":56408},{\"end\":56427,\"start\":56422}]", "bib_author_last_name": "[{\"end\":46567,\"start\":46563},{\"end\":46578,\"start\":46576},{\"end\":46589,\"start\":46584},{\"end\":46603,\"start\":46599},{\"end\":46616,\"start\":46614},{\"end\":46631,\"start\":46627},{\"end\":46642,\"start\":46639},{\"end\":46655,\"start\":46653},{\"end\":46968,\"start\":46960},{\"end\":46983,\"start\":46977},{\"end\":46998,\"start\":46993},{\"end\":47261,\"start\":47253},{\"end\":47274,\"start\":47270},{\"end\":47289,\"start\":47281},{\"end\":47551,\"start\":47549},{\"end\":47562,\"start\":47559},{\"end\":47574,\"start\":47570},{\"end\":47834,\"start\":47832},{\"end\":47851,\"start\":47847},{\"end\":47867,\"start\":47860},{\"end\":48085,\"start\":48083},{\"end\":48101,\"start\":48094},{\"end\":48345,\"start\":48343},{\"end\":48356,\"start\":48352},{\"end\":48368,\"start\":48364},{\"end\":48376,\"start\":48374},{\"end\":48393,\"start\":48388},{\"end\":48404,\"start\":48400},{\"end\":48677,\"start\":48671},{\"end\":48701,\"start\":48690},{\"end\":48985,\"start\":48979},{\"end\":48995,\"start\":48991},{\"end\":49011,\"start\":49004},{\"end\":49220,\"start\":49216},{\"end\":49238,\"start\":49231},{\"end\":49474,\"start\":49472},{\"end\":49487,\"start\":49483},{\"end\":49495,\"start\":49492},{\"end\":49509,\"start\":49504},{\"end\":49518,\"start\":49515},{\"end\":49531,\"start\":49527},{\"end\":49831,\"start\":49826},{\"end\":49843,\"start\":49839},{\"end\":49854,\"start\":49851},{\"end\":49866,\"start\":49862},{\"end\":49878,\"start\":49874},{\"end\":50214,\"start\":50211},{\"end\":50225,\"start\":50222},{\"end\":50237,\"start\":50233},{\"end\":50486,\"start\":50483},{\"end\":50497,\"start\":50494},{\"end\":50509,\"start\":50505},{\"end\":50521,\"start\":50517},{\"end\":50824,\"start\":50821},{\"end\":50837,\"start\":50834},{\"end\":50846,\"start\":50842},{\"end\":50855,\"start\":50853},{\"end\":50869,\"start\":50865},{\"end\":50882,\"start\":50880},{\"end\":51205,\"start\":51201},{\"end\":51218,\"start\":51214},{\"end\":51232,\"start\":51228},{\"end\":51526,\"start\":51523},{\"end\":51536,\"start\":51532},{\"end\":51735,\"start\":51729},{\"end\":51760,\"start\":51747},{\"end\":51774,\"start\":51767},{\"end\":51795,\"start\":51781},{\"end\":52056,\"start\":52050},{\"end\":52081,\"start\":52068},{\"end\":52102,\"start\":52088},{\"end\":52365,\"start\":52361},{\"end\":52377,\"start\":52375},{\"end\":52390,\"start\":52386},{\"end\":52404,\"start\":52399},{\"end\":52416,\"start\":52413},{\"end\":52427,\"start\":52425},{\"end\":52436,\"start\":52432},{\"end\":52749,\"start\":52745},{\"end\":52758,\"start\":52754},{\"end\":52945,\"start\":52938},{\"end\":52959,\"start\":52952},{\"end\":52972,\"start\":52966},{\"end\":52989,\"start\":52980},{\"end\":53002,\"start\":52997},{\"end\":53017,\"start\":53012},{\"end\":53032,\"start\":53026},{\"end\":53050,\"start\":53040},{\"end\":53356,\"start\":53352},{\"end\":53367,\"start\":53362},{\"end\":53379,\"start\":53376},{\"end\":53387,\"start\":53384},{\"end\":53397,\"start\":53392},{\"end\":53407,\"start\":53404},{\"end\":53421,\"start\":53418},{\"end\":53686,\"start\":53682},{\"end\":53699,\"start\":53697},{\"end\":53710,\"start\":53706},{\"end\":53721,\"start\":53717},{\"end\":53736,\"start\":53732},{\"end\":53972,\"start\":53968},{\"end\":53981,\"start\":53978},{\"end\":53991,\"start\":53987},{\"end\":54003,\"start\":54001},{\"end\":54017,\"start\":54014},{\"end\":54030,\"start\":54027},{\"end\":54308,\"start\":54305},{\"end\":54320,\"start\":54315},{\"end\":54334,\"start\":54331},{\"end\":54343,\"start\":54341},{\"end\":54356,\"start\":54352},{\"end\":54367,\"start\":54364},{\"end\":54616,\"start\":54614},{\"end\":54629,\"start\":54625},{\"end\":54642,\"start\":54639},{\"end\":54654,\"start\":54650},{\"end\":54664,\"start\":54661},{\"end\":54676,\"start\":54673},{\"end\":54910,\"start\":54907},{\"end\":54919,\"start\":54917},{\"end\":54931,\"start\":54926},{\"end\":54941,\"start\":54938},{\"end\":54953,\"start\":54951},{\"end\":55199,\"start\":55197},{\"end\":55214,\"start\":55210},{\"end\":55226,\"start\":55223},{\"end\":55236,\"start\":55230},{\"end\":55250,\"start\":55245},{\"end\":55254,\"start\":55252},{\"end\":55615,\"start\":55611},{\"end\":55627,\"start\":55625},{\"end\":55641,\"start\":55637},{\"end\":55660,\"start\":55648},{\"end\":55680,\"start\":55672},{\"end\":55695,\"start\":55687},{\"end\":55995,\"start\":55991},{\"end\":56007,\"start\":56005},{\"end\":56018,\"start\":56015},{\"end\":56030,\"start\":56026},{\"end\":56393,\"start\":56389},{\"end\":56406,\"start\":56402},{\"end\":56420,\"start\":56416},{\"end\":56431,\"start\":56428}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":235306102},\"end\":46851,\"start\":46504},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":236469059},\"end\":47190,\"start\":46853},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":4755450},\"end\":47440,\"start\":47192},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":250205160},\"end\":47788,\"start\":47442},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":10246046},\"end\":47991,\"start\":47790},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":9124261},\"end\":48251,\"start\":47993},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":211043589},\"end\":48600,\"start\":48253},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11810482},\"end\":48900,\"start\":48602},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":207204749},\"end\":49161,\"start\":48902},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":52127932},\"end\":49358,\"start\":49163},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":50768534},\"end\":49747,\"start\":49360},{\"attributes\":{\"id\":\"b11\"},\"end\":50107,\"start\":49749},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":221784706},\"end\":50413,\"start\":50109},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":250410419},\"end\":50729,\"start\":50415},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":240070722},\"end\":51078,\"start\":50731},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":219636253},\"end\":51431,\"start\":51080},{\"attributes\":{\"id\":\"b16\"},\"end\":51660,\"start\":51433},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":10795036},\"end\":51969,\"start\":51662},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":207178809},\"end\":52276,\"start\":51971},{\"attributes\":{\"doi\":\"CoRR abs/2109.11903\",\"id\":\"b19\"},\"end\":52654,\"start\":52278},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":39847715},\"end\":52902,\"start\":52656},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":13756489},\"end\":53248,\"start\":52904},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":211171550},\"end\":53636,\"start\":53250},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":150380651},\"end\":53879,\"start\":53638},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":220730170},\"end\":54226,\"start\":53881},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":246828747},\"end\":54551,\"start\":54228},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":53219431},\"end\":54842,\"start\":54553},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":235792434},\"end\":55107,\"start\":54844},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":199465865},\"end\":55534,\"start\":55109},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":46949657},\"end\":55896,\"start\":55536},{\"attributes\":{\"doi\":\"fcs/EN/10.1007/s11704-022-1184-8\",\"id\":\"b30\",\"matched_paper_id\":247208886},\"end\":56311,\"start\":55898},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":32370905},\"end\":56592,\"start\":56313}]", "bib_title": "[{\"end\":46555,\"start\":46504},{\"end\":46948,\"start\":46853},{\"end\":47241,\"start\":47192},{\"end\":47539,\"start\":47442},{\"end\":47822,\"start\":47790},{\"end\":48073,\"start\":47993},{\"end\":48332,\"start\":48253},{\"end\":48662,\"start\":48602},{\"end\":48969,\"start\":48902},{\"end\":49203,\"start\":49163},{\"end\":49466,\"start\":49360},{\"end\":49819,\"start\":49749},{\"end\":50204,\"start\":50109},{\"end\":50473,\"start\":50415},{\"end\":50812,\"start\":50731},{\"end\":51191,\"start\":51080},{\"end\":51719,\"start\":51662},{\"end\":52040,\"start\":51971},{\"end\":52737,\"start\":52656},{\"end\":52929,\"start\":52904},{\"end\":53346,\"start\":53250},{\"end\":53674,\"start\":53638},{\"end\":53959,\"start\":53881},{\"end\":54299,\"start\":54228},{\"end\":54608,\"start\":54553},{\"end\":54896,\"start\":54844},{\"end\":55185,\"start\":55109},{\"end\":55605,\"start\":55536},{\"end\":55981,\"start\":55898},{\"end\":56381,\"start\":56313}]", "bib_author": "[{\"end\":46569,\"start\":46557},{\"end\":46580,\"start\":46569},{\"end\":46591,\"start\":46580},{\"end\":46605,\"start\":46591},{\"end\":46618,\"start\":46605},{\"end\":46633,\"start\":46618},{\"end\":46644,\"start\":46633},{\"end\":46657,\"start\":46644},{\"end\":46970,\"start\":46950},{\"end\":46985,\"start\":46970},{\"end\":47000,\"start\":46985},{\"end\":47263,\"start\":47243},{\"end\":47276,\"start\":47263},{\"end\":47291,\"start\":47276},{\"end\":47553,\"start\":47541},{\"end\":47564,\"start\":47553},{\"end\":47576,\"start\":47564},{\"end\":47836,\"start\":47824},{\"end\":47853,\"start\":47836},{\"end\":47869,\"start\":47853},{\"end\":48087,\"start\":48075},{\"end\":48103,\"start\":48087},{\"end\":48347,\"start\":48334},{\"end\":48358,\"start\":48347},{\"end\":48370,\"start\":48358},{\"end\":48378,\"start\":48370},{\"end\":48395,\"start\":48378},{\"end\":48406,\"start\":48395},{\"end\":48679,\"start\":48664},{\"end\":48703,\"start\":48679},{\"end\":48987,\"start\":48971},{\"end\":48997,\"start\":48987},{\"end\":49013,\"start\":48997},{\"end\":49222,\"start\":49205},{\"end\":49240,\"start\":49222},{\"end\":49476,\"start\":49468},{\"end\":49489,\"start\":49476},{\"end\":49497,\"start\":49489},{\"end\":49511,\"start\":49497},{\"end\":49520,\"start\":49511},{\"end\":49533,\"start\":49520},{\"end\":49833,\"start\":49821},{\"end\":49845,\"start\":49833},{\"end\":49856,\"start\":49845},{\"end\":49868,\"start\":49856},{\"end\":49880,\"start\":49868},{\"end\":50216,\"start\":50206},{\"end\":50227,\"start\":50216},{\"end\":50239,\"start\":50227},{\"end\":50488,\"start\":50475},{\"end\":50499,\"start\":50488},{\"end\":50511,\"start\":50499},{\"end\":50523,\"start\":50511},{\"end\":50826,\"start\":50814},{\"end\":50839,\"start\":50826},{\"end\":50848,\"start\":50839},{\"end\":50857,\"start\":50848},{\"end\":50871,\"start\":50857},{\"end\":50884,\"start\":50871},{\"end\":51207,\"start\":51193},{\"end\":51220,\"start\":51207},{\"end\":51234,\"start\":51220},{\"end\":51528,\"start\":51516},{\"end\":51538,\"start\":51528},{\"end\":51737,\"start\":51721},{\"end\":51762,\"start\":51737},{\"end\":51776,\"start\":51762},{\"end\":51797,\"start\":51776},{\"end\":52058,\"start\":52042},{\"end\":52083,\"start\":52058},{\"end\":52104,\"start\":52083},{\"end\":52367,\"start\":52358},{\"end\":52379,\"start\":52367},{\"end\":52392,\"start\":52379},{\"end\":52406,\"start\":52392},{\"end\":52418,\"start\":52406},{\"end\":52429,\"start\":52418},{\"end\":52438,\"start\":52429},{\"end\":52751,\"start\":52739},{\"end\":52760,\"start\":52751},{\"end\":52947,\"start\":52931},{\"end\":52961,\"start\":52947},{\"end\":52974,\"start\":52961},{\"end\":52991,\"start\":52974},{\"end\":53004,\"start\":52991},{\"end\":53019,\"start\":53004},{\"end\":53034,\"start\":53019},{\"end\":53052,\"start\":53034},{\"end\":53358,\"start\":53348},{\"end\":53369,\"start\":53358},{\"end\":53381,\"start\":53369},{\"end\":53389,\"start\":53381},{\"end\":53399,\"start\":53389},{\"end\":53409,\"start\":53399},{\"end\":53423,\"start\":53409},{\"end\":53688,\"start\":53676},{\"end\":53701,\"start\":53688},{\"end\":53712,\"start\":53701},{\"end\":53723,\"start\":53712},{\"end\":53738,\"start\":53723},{\"end\":53974,\"start\":53961},{\"end\":53983,\"start\":53974},{\"end\":53993,\"start\":53983},{\"end\":54005,\"start\":53993},{\"end\":54019,\"start\":54005},{\"end\":54032,\"start\":54019},{\"end\":54310,\"start\":54301},{\"end\":54322,\"start\":54310},{\"end\":54336,\"start\":54322},{\"end\":54345,\"start\":54336},{\"end\":54358,\"start\":54345},{\"end\":54369,\"start\":54358},{\"end\":54618,\"start\":54610},{\"end\":54631,\"start\":54618},{\"end\":54644,\"start\":54631},{\"end\":54656,\"start\":54644},{\"end\":54666,\"start\":54656},{\"end\":54678,\"start\":54666},{\"end\":54912,\"start\":54898},{\"end\":54921,\"start\":54912},{\"end\":54933,\"start\":54921},{\"end\":54943,\"start\":54933},{\"end\":54955,\"start\":54943},{\"end\":55201,\"start\":55187},{\"end\":55216,\"start\":55201},{\"end\":55228,\"start\":55216},{\"end\":55238,\"start\":55228},{\"end\":55252,\"start\":55238},{\"end\":55256,\"start\":55252},{\"end\":55617,\"start\":55607},{\"end\":55629,\"start\":55617},{\"end\":55643,\"start\":55629},{\"end\":55662,\"start\":55643},{\"end\":55682,\"start\":55662},{\"end\":55697,\"start\":55682},{\"end\":55997,\"start\":55983},{\"end\":56009,\"start\":55997},{\"end\":56020,\"start\":56009},{\"end\":56032,\"start\":56020},{\"end\":56395,\"start\":56383},{\"end\":56408,\"start\":56395},{\"end\":56422,\"start\":56408},{\"end\":56433,\"start\":56422}]", "bib_venue": "[{\"end\":46664,\"start\":46657},{\"end\":47009,\"start\":47000},{\"end\":47301,\"start\":47291},{\"end\":47596,\"start\":47576},{\"end\":47878,\"start\":47869},{\"end\":48110,\"start\":48103},{\"end\":48414,\"start\":48406},{\"end\":48710,\"start\":48703},{\"end\":49019,\"start\":49013},{\"end\":49247,\"start\":49240},{\"end\":49539,\"start\":49533},{\"end\":49909,\"start\":49880},{\"end\":50248,\"start\":50239},{\"end\":50562,\"start\":50523},{\"end\":50891,\"start\":50884},{\"end\":51242,\"start\":51234},{\"end\":51514,\"start\":51433},{\"end\":51803,\"start\":51797},{\"end\":52110,\"start\":52104},{\"end\":52356,\"start\":52278},{\"end\":52767,\"start\":52760},{\"end\":53062,\"start\":53052},{\"end\":53429,\"start\":53423},{\"end\":53746,\"start\":53738},{\"end\":54040,\"start\":54032},{\"end\":54376,\"start\":54369},{\"end\":54685,\"start\":54678},{\"end\":54963,\"start\":54955},{\"end\":55301,\"start\":55256},{\"end\":55703,\"start\":55697},{\"end\":56067,\"start\":56064},{\"end\":56440,\"start\":56433}]"}}}, "year": 2023, "month": 12, "day": 17}