{"id": 214802082, "updated": "2023-10-06 16:51:23.393", "metadata": {"title": "Improved Code Summarization via a Graph Neural Network", "authors": "[{\"first\":\"Alexander\",\"last\":\"LeClair\",\"middle\":[]},{\"first\":\"Sakib\",\"last\":\"Haque\",\"middle\":[]},{\"first\":\"Lingfei\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Collin\",\"last\":\"McMillan\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 28th International Conference on Program Comprehension", "publication_date": {"year": 2020, "month": 4, "day": 6}, "abstract": "Automatic source code summarization is the task of generating natural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as the community has taken greater advantage of advances in neural network and AI technologies. In general, source code summarization techniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that using structural information as input leads to improved performance. The first approaches to use structural information flattened the AST into a sequence. Recently, more complex approaches based on random AST paths or graph neural networks have improved on the models using flattened ASTs. However, the literature still does not describe the using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, we present an approach that uses a graph-based neural architecture that better matches the default structure of the AST to generate these summaries. We evaluate our technique using a data set of 2.1 million Java method-comment pairs and show improvement over four baseline techniques, two from the software engineering literature, and two from machine learning literature.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2004.02843", "mag": "3086449553", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iwpc/LeClairHWM20", "doi": "10.1145/3387904.3389268"}}, "content": {"source": {"pdf_hash": "c345b74be9f98cca9592cc376465118df5c9f2da", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2004.02843v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2004.02843", "status": "GREEN"}}, "grobid": {"id": "ff99679b5d03271bd959b86486d317163618e856", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c345b74be9f98cca9592cc376465118df5c9f2da.txt", "contents": "\nImproved Code Summarization via a Graph Neural Network\n2016. July 2017\n\nAlexander Leclair aleclair@nd.edu \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nSakib Haque shaque@nd.edu \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nLingfei Wu \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nCollin Mcmillan \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nAlexander Leclair \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nSakib Haque \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nLingfei Wu \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nCollin Mcmillan \nACM Reference format\nIBM Research Yorktown Heights\n10598NY\n\nImproved Code Summarization via a Graph Neural Network\n\nProceed-ings of ACM Conference\need-ings of ACM ConferenceWashington, DC, USA122016. July 201710.1145/nnnnnnn.nnnnnnnUniversity of Notre Dame South Bend, IN 46556 University of Notre Dame South Bend, IN 46556 University of Notre Dame South Bend, IN 46556Automatic documentationneural networksdeep learningarti cial intelligence\nAutomatic source code summarization is the task of generating natural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as the community has taken greater advantage of advances in neural network and AI technologies. In general, source code summarization techniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that using structural information as input leads to improved performance. e rst approaches to use structural information a ened the AST into a sequence. Recently, more complex approaches based on random AST paths or graph neural networks have improved on the models using a ened ASTs. However, the literature still does not describe the using a graph neural network together with source code sequence as separate inputs to a model. erefore, in this paper, we present an approach that uses a graph-based neural architecture that be er matches the default structure of the AST to generate these summaries. We evaluate our technique using a data set of 2.1 million Java method-comment pairs and show improvement over four baseline techniques, two from the so ware engineering literature, and two from machine learning literature.\n\nINTRODUCTION\n\nSource code summarization is the task of writing brief natural language descriptions of code [15,19,29,37]. ese descriptions Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permi ed. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. Request permissions from permissions@acm.org. Conference'17, Washington, DC, USA \u00a9 2016 ACM. 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 DOI: 10.1145/nnnnnnn.nnnnnnn have long been the backbone of developer documentation such as JavaDocs [27]. e idea is that a short description allows a programmer to understand what a section of code does and that code's purpose in the overall program, without requiring the programmer to read the code itself. Summaries like \"uploads log les to the backup server\" or \"formats decimal values as scienti c notation\" can give programmers a clear picture of what code does, saving them time from comprehending the details of that code.\n\nAutomatic code summarization is a rapidly expanding research area. Programmers are notorious for neglecting the manual e ort of writing summaries themselves [12,26,45,48], and automation has long been cited as a desirable alternative [17]. e term \"source code summarization\" was coined around ten years ago [19] and since that time the eld has proliferated. At rst, the dominant strategy was based on sentence templates and heuristics derived from empirical studies [15,36,40,44,50,51]. Starting around 2016, data-driven strategies based on neural networks came to the forefront, leveraging gains from both the AI/NLP and mining so ware repositories research communities [3,23,25,29]. ese data-driven approaches were inspired by neural machine translation (NMT) from natural language processing. In NMT, a sentence in one language e.g. English is translated into another language e.g. Spanish. A dataset of millions of examples of English sentences paired with Spanish translations is required. A neural architecture based on the encoder-decoder model is used to learn the mapping between words and even the correct grammatical structure from one language to the other based on these examples. is works well because both input and output languages are sequences of roughly equal length, and mappings of words tend to exist across languages. e metaphor in code summarization is to treat source code as one language input and summaries as another. So code would be input to the same models' encoder, and summaries to the decoder. Advances in repository mining made it possible to gather large datasets of paired examples [33].\n\nBut evidence is accumulating that the metaphor to NMT has major limits [21]. Source code has far fewer words that map directly to summaries than the NMT use case [30]. Source code tends not to be of equal length to summaries; it is much longer [15,39]. And crucially, source code is not merely a sequence of words. Code is a complex web of interacting components, with di erent classes, routines, statements, and identi ers connected via di erent relationships. So ware engineering researchers have long recognized that code is much more suited to graph or tree representations that tease out the nuances of these relationships [6,42]. Yet, the typical application of NMT to code summarization treats code as a sequence to be fed into a recurrent neural network (RNN) or similar structure designed for sequential information. e literature is beginning to recognize the limits to sequential representations of code for code summarization. Hu et al. [23] annotate the sequence with clues from the abstract syntax tree (AST). LeClair et al. [29] expand on this idea by separating the code and AST into two di erent inputs. Alon et al. [3] extract paths from the AST to aid summarization. Meanwhile, Allamanis et al. [2] propose using graph neural networks (GNNs) to learn representations of code (though for the problem of code generation, not summarization). ese approaches all show how neural networks can be e ective in extracting information from source code be er in a graph or tree form than in a sequence of tokens, and using that information for downstream tasks such as summarization.\n\nWhat is missing from the literature is a thorough examination of how graph neural networks improve representations of code based on the AST. ere is evidence that GNN-based representations improve performance, but the degree of that improvement for code summarization has not been explored thoroughly, and the reasons for the improvement are not well understood.\n\nIn this paper, we present an approach for improving source code summarization using GNNs. Speci cally, we target the problem of summarizing program subroutines. Our approach is based on the graph2seq model presented by Xu et al. [58], though with a few modi cations to customize the model to a so ware engineering context. In short, we use the GNN-based encoder of graph2seq to model the AST of each subroutine, combined with the RNN-based encoder used by LeClair et al. [29] to model the subroutine as a sequence. We demonstrate a 4.6% BLEU score improvement for a large, published dataset [30] as compared to recent baselines. In an experiment, we use techniques from the literature on explainable AI to propose explanations for why the approach performs be er and in which cases. We seek to provide insights to guide future researchers. We make all our data, implementations, and experimental framework available via our online appendix (Section 9).\n\n\nPROBLEM, SIGNIFICANCE, SCOPE\n\nWe target the problem of automatically generating summaries of program subroutines. To be clear, the input is the source code of a subroutine, and the output is a short, natural language description of that subroutine. ese summaries have several advantages when put into documentation such as decreased time to understand code [17], improved code comprehension [11,54], and to making code more searchable [22]. Programmers are notorious for consuming high quality documentation for themselves, while neglecting to write and update it themselves [17]. erefore, recent research has focused on automating the documentation process. Current research has had success generating summaries for a subset of methods that are generally shorter and use simpler language in both the code and reference comment (e.g. se ers and ge ers), but have had a problem with methods that have more complex structures or language [29]. A similar situation for other SE research problems has been helped by various graph representations of code [2,16], but using graph representations is only starting to be accepted for code summarization [3,16]. Graph representations have the potential to improve code summarization because, instead of using only a sequence of code tokens as input, the model can access a rich variety of relationships among tokens.\n\nAutomatic documentation has a large potential impact on how so ware is developed and maintained. Not only would automatic documentation reduce the time and energy programmers spend reading and writing so ware, having a high level summary available has been shown to improve results in other SE tasks such as code categorization and code search [22,28].\n\n\nBACKGROUND AND RELATED WORK\n\nis section discusses some of the previous work relevant to this work and source code summarization.\n\n\nSource Code Summarization\n\nSource code summarization research can be broadly categorized as either 1) heuristic/template-driven approaches or 2) more recent AI/Data-driven approaches. Heuristic-based approaches for source code summarization started to gain popularity in 2010 with work done by Haiduc et al. [20]. In their work, text retrieval techniques and latent semantic indexing (LSI) were used to pick important keywords out of source code, then those words are considered the summary. Early work done by Haiduc et al. and others have helped inspire other work using extractive summarization techniques based on TF-IDF, LSI, and LDA to create a summary. Heuristic-based approaches are less related to this work than datadriven approaches, so due to space limitations we direct readers to surveys by Song et al. [49] and Nazar et al. [41] for additional background on the topic. is paper builds on the current work done with data-driven approaches in source code summarization which have dominated NLP and SE literature since around 2015. In Table 1, we divide recent work into two groups by their use of the AST as an input to the model. en we further divide related work by the following six a ributes:\n\n(1) Src Code -A model uses the source code sequence as input, not as part of the AST. (2) AST -A model uses the AST as input.\n\n(3) API -A model uses API information. (4) FlatAST -Using a a ened version of the AST as model input. (5) GNN -e model uses a form of graph neural network for node/edge embedding. (6) Paths -Using a path through the AST as input to the model.\n\nA brief history of the related data-driven work starts with Iyer et al [25]. In their work they used stack over ow questions and responses where the title of the post was considered the high level summary, and the source code in the top rated response was used as the input. e model they developed was an a ention based sequence to sequence model similar to those used in neural machine translation tasks [53]. To expand on this idea, Hu et al. [24] added API information as an additional input into the model. ey found that the model was able to generate be er responses if it had access to information provided by API calls in the source code.\n\nLater, Hu et al. [23] developed a structure based traversal (SBT) method for a ening the AST into a sequence that keeps words in the code associated with their node type. e SBT sequence is a combination of source code tokens and AST structure which was then input into an o the shelf encoder/decoder model. LeClair Src Code AST API FlatAST GNN Paths 2016 Iyer et al. [25] x 2017 Loyola et al. [34] x 2017 Lu et al. [35] x x 2018 Hu et al. [24] x x 2018 Liang et al. [31] x x 2018 Hu et al. [23] x x x 2018 Wan et al. [56] x x 2019 LeClair et al. [29] x x x 2019 Alon et al. [3] x x x 2019 Fernandes et al. [16] x x et al. [29] built upon this work by creating a multi-input model that used the SBT sequence with all identi ers removed as the rst input, and the source code tokens as the second. ey found that if you decouple the structure of the code form the code itself that the model improved its ability to learn that structure.\n\nMore recently, Alon et al. [3] in 2018 proposed a source code summarization technique that would encode each pairwise path between nodes in the AST. ey would then randomly select a subset of these paths for each iteration in training. ese paths were then encoded and used as input to a standard encoder/decoder model. ey found that encoding the AST paths allowed the model to generalize to unseen methods more easily, as well as providing a level of regularization by randomly selecting a subset of paths each training iteration. en in 2019 Fernandes et al. [16] developed a GNN based model that uses three graph representations of source code as input 1) next token, 2) AST, and 3) last lexical use. To represent these three graphs they used a shared node setup where each graph represented a di erent set of edges between source code tokens. Using this approach they observed a be er \"global\" view of the method and had success with maintaining the central named entity from the method. Fernandes' observation is an important clue that there is additional information embedded in the source code beyond the sequence of tokens, this motivates the use of a GNN for the AST as a separate input in our work.\n\n\nNeural Machine Translation\n\nFor the last six years work in neural machine translation (NMT) has been dominated by the encoder-decoder model architecture developed by Bahdanau et al. [5]. e encoder-decoder architecture can be thought of as two separate models, one to encode the input (e.g. English words) into a vector representation, and one to decode that representation into the desired output (e.g. German tokens).\n\nCommonly, encoder-decoder models use a recurrent layer (RNN, GRU, LSTM, etc.) in both the encoder and decoder. Recurrent layers are e ective at learning sequence information because for each token in a sequence, information is propagated through the layer [52]. is allows each token to a ect the following tokens in the sequence. Some of the common recurrent layers such as the GRU and LSTM also can return state information at each time step of the input sequence. e state information output from the encoder is commonly used to seed the initial state of the decoder improving translation results [53].\n\nAnother more recent addition to many encoder-decoder models is the a ention mechanism. e intuition behind a ention is that not all tokens in a sequence are of equal importance to the nal output prediction. What a ention tries to do is to learn what words are important and map input tokens to output tokens. It does this by taking the input sequence at every time step and the predicted sequence at a time step and tries to determine which time step in the input will be most useful to predict the next token in the output.\n\n\nGraph Neural Networks\n\nGraph Neural Networks are another key background technology to this paper. A recent survey by Wu et al. [57] categorizes GNNs into four groups:\n\n(1) Recurrent Graph Neural Networks (RecGNNs) (2) Convolutional Graph Neural Networks (ConvGNNs) (3) Graph Autoencoders (GAEs) (4) Spatial-temporal Graph Neural Networks (STGNNs) We will focus on ConvGNNs in this section because they are well suited for this task, and it is what we use in this paper. ConvGNNs were developed a er RecGNNs and were designed with the same idea of message passing between nodes. ey have also been shown to encode spatial information be er than RecGNNs and are able to be stacked, improving the ability to propagate information across nodes [57]. ConvGNNs take graph data and learn representations of nodes based on the initial node vector and its neighbors in the graph. e process of combining the information from neighboring nodes is called \"aggregation.\" By aggregating information from neighboring nodes a model can learn representations based on arbitrary relationships. ese relationships could be the hidden structures of a sentence, the parts of speech [8], dependency parsing trees [59], or the sequence of tokens [7]. ConvGNNs have been used for similar tasks before, such as in graph2seq for semantic parsing [58] and natural question generation [8].\n\nConvGNNs also allow nodes to get information from other nodes that are further than just a single edge or \"hop\" away. In the gure below we show an example partial AST and what 1, 2, and 3 hops look like for the token 'function'. Each time a hop is performed, the node gets information from its neighboring nodes. So, on the rst hop the token 'function' aggregates information from the nodes 'block', 'speci er', 'name', 'type', and 'parameter list'. In the next hop that occurs, the 'function' node will still only combine information from its neighbors, but now each of those nodes will have aggregate information from their children. For example, the node 'block' will contain information from the 'expr stmt' node. en when the 'function' node aggregates the 'block' node, it has information from both 'block' and 'expr stmt'.\n\nere are several aggregation strategies which have been shown to have di erent performance for di erent tasks [16,57]. A common aggregation strategy is to sum a node vector with its neighbors and then apply an activation on that node, but there are many schemes that can be used to combine node information. Some other approaches to this are pooling, min, max, and mean. Xu et al. discuss di erent node and edge aggregation methods in their paper on creating sequences from graphs. ey found that in most cases a mean aggregator out performed other types of aggregators, including one using an LSTM.\n\n\nAPPROACH\n\nis section provides the details of our approach. Our model is based o the neural model proposed by LeClair et al. [29] and builds on that work by using ConvGNNs discussed in the previous section. In a nutshell, our approach works in 5 steps:\n\n(1) Embed the source code sequence and the AST node tokens.\n\n(2) Encode the embedding output with a recurrent layer for the source code token sequence and a ConvGNN for the AST nodes and edges. (3) Use an a ention mechanism to learn important tokens in the source code and AST. (4) Decode the encoder outputs. (5) Predict the next token in the sequence.\n\n\nModel Overview\n\nAn overview of our model is in Figure 1. In a nutshell, what we did was modify the model on the multi-input encoder-decoder proposed by LeClair et al. to use a ConvGNN instead of a a ened AST. Notice in area A of Figure 1 that our model has four inputs 1) the sequence of source code tokens, 2) the nodes of the AST, 3) the edges of the AST, 4) the predicted sequence up to this point. Next, in area B, we embed the inputs using standard embedding layers. e source sequence and AST nodes share an embedding due to a large overlap in vocabulary. en in area C of Figure 1 the AST nodes are input into the ConvGNN layers, the number of layers here depends on the hop size of the model, and then input into a GRU. e source code sequence goes into a GRU a er the embedding in area D. For the decoder in area H, we have an embedding layer feeding into a GRU. We then do two a ention mechanisms seen in area E, one between the source code and summary, and the other between the AST and summary. en in areas F and G we combine the outputs of our a ention creating a context vector which is a ened and used to predict the next token in the sequence.\n\nKey Novel Component. e key novel component of this paper is in processing the AST using a ConvGNN and combining the output of the ConvGNN encoder with the output of the source code token encoder. In our approach, the ConvGNN allows the nodes of the AST to learn representations based on their neighboring nodes.\n\nTeaching the model information about the structure of the code, and how it relates to the tokens found in the source code sequence. Both the source and and AST encodings are input into separate a ention mechanisms with the decoder and are then concatenated.\n\nis creates a context vector which we then use in a dense layer to predict the next token in the sequence.\n\nBasically, what we do is combine the structure of the sequence (the AST) with the sequence itself (the source code). Combining the structure of a sequence and the sequence itself into a model has been shown to improve the quality of generated summaries in both SE and NLP literature [23,29]. In this paper we aim to show that using a neural network architecture that is more suited to the structure of the data (graph vs sequence) we can further improve the models ability to learn complex relationships in the source code.\n\n\nModel Details\n\nIn this section we will discuss speci c model implementation details that we used for our best performing model to encourage reproducibility. We developed our proposed model using Keras [9] and Tensor ow [1]. We also provide our source code and data as an online appendix (details can be found in Section 9).\n\nFirst, as mentioned in the previous section, our model is based on the encoder-decoder architecture and has four inputs 1) the source code sequence, 2/3) the AST as a collection of nodes along with an adjacency matrix with edge information and 4) the comment generated up to this point which is the input to the decoder. As seen in Figure 1, we use two embedding layers one for the source code and AST and one for the decoder. We use a single embedding layer for both the source code and AST node inputs because they have such a large overlap in vocabulary. e shared embedding layer has a vocabulary size of 10908 and an embedding size of 100. e decoder embedding layer has a vocabulary size of 10000 and an embedding size of 100. So far, this follows the model proposed by LeClair et al. [29]. Next, the model has two encoders, one for the source code sequence and another for the AST. e source code sequence encoder is a single GRU layer with an output length of 256. We have the source code GRU return its hidden states to use as the initial state for the decoder GRU. e second encoder, the AST encoder, is a collection of ConvGNN layers followed by a GRU of length 256. e number of ConvGNN layers depends on the number of hops used, for our best model this was 2-hops as seen in Figure 1.\n\ne ConvGNN that we use for the AST node embeddings takes the AST embedding layer output and the AST edge data as inputs.\n\nen, for each node in the input it sums the current node vector with each of it's neighbors and multiplies that by a set of trainable weights and adds a trainable bias. In our best performing implementation we use a ConvGNN layer for each hop in the model as seen in Figure 1. We also test our model with di erent numbers of hops, which slightly changes the architecture of the AST encoder of the model by adding additional ConvGNN layers.\n\nNext, we have two a ention mechanisms 1) an a ention between the decoder and the source code, and 2) between the decoder and the AST. ese a ention mechanisms learn which tokens from the source code/AST are important to the prediction of the next token in the decoder sequence given the current predicted sequence generated up to this point. e a ention mechanisms are then concatenated together with the decoder to create a nal context vector.\n\nen, we apply a dense layer to each vector in our nal context vector, which we then a en and use to predict the next token in the sequence.\n\n\nData Preparation\n\ne data set that we used for this project was provided by LeClair et al. in a paper on recommendations for source code summarization datasets [30]. LeClair et al. describe best practices for developing a dataset for source code summarization and also provide a dataset of 2.1 million Java method comment pairs. ey provide their dataset in two versions, 1) a ltered version with the raw, unprocessed version of the methods and comments and 2) the tokenized version where text processing has already been applied. For our baseline comparisons, we use the tokenized version of the dataset provided by LeClair et al. allowing us to directly compare results with their work in source code summarization. e dataset did not include ASTs that were already parsed, so we use the SrcML library [10] to generate the associated ASTs from the raw source code.\n\n\nHardware Details\n\nFor training, validating, testing of our models we used a workstation with Xeon E1430v4 CPUs, 110GB RAM, a Titan RTX GPU, and a adro P5000 GPU. So ware used include the following:\n\nUbuntu 18.04 Python 3.6 CUDA 10 Tensor ow 1.14 Keras 2.2 CuDNN 7\n\n\nEXPERIMENT DESIGN\n\nIn this section we discuss the design of our experiments and discuss the methodology, baselines, and metrics used to obtain our results.\n\n\nResearch estions\n\nOur research objective is to determine if our proposed approach of using the source code sequence along with a graph based AST and ConvGNN outperform current baselines. We also want to determine why our proposed model may outperform current baselines based on the use of the AST graph and ConvGNN. We ask the following Research estions (RQs) to explore these situations: RQ 1 What is the performance of our approach compared to the baselines in Section 5.4 in terms of the metrics in Section 5.3? RQ 2 What is the degree of di erence in performance caused by the number of graph hops in terms of the metrics in Section 5.3? RQ 3 Is there evidence that the performance di erences are due to use of the ConvGNN? e rationale for RQ 1 is to compare our approach with other approaches that use the AST as input. Previous work has already shown that the inclusion of the AST as an input to the model outperforms previous models where no AST information was provided [3,16,24,29]. Some previous work provides the AST as a tree or graph [3,16], but the source code sequence was not provided to the model. Our proposed model is a logical next step in source code summarization literature and we ask RQ 1 to evaluate our model against previous models. e rationale for RQ 2 is to determine what a ect (if any) the number of hops has on the generated summaries (a description of ConvGNN hops can be found in Section 3.3). Xu et al. [58] discuss the impact of hop size on their work with generating SQL queries. ey found that for their test models, the number of hops did not a ect model convergence. To test this they generate random directed graphs of sizes 100 and 1000 and trained a model to nd the shortest path between nodes, but did not evaluate how hop size a ects the task of source code summarization. Since ConvGNNs create a layer for each hop, it becomes computationally expensive to train models with an arbitrarily large number of hops. With RQ 2 we hope to build an intuition into how the number of hops a ects ConvGNN learning speci cally for source code summarization. e rationale for RQ 3 is that discovering why a model learned to generate certain summaries can be just as important as evaluation metrics [4,13,14,38,47,55]. Doshie et al. [14] discuss what interpretability means and o ers guidelines to researchers on what they can do to make their models more explainable, while Roscher et al. state that \"\u2026explainability is a prerequisite to ensure the scienti c value of the outcome\" [46]. As models are developed many factors change, and it is o en times not an easy task to determine which factors had the greatest impact on performance. In their work on explainable AI, Arras et al. and Samek et al. show how you can use visualizations to aid in the process of explainability for text based modeling tasks [4,47]. With RQ 3 we aim to explain what impact the inclusion of the AST as a graph and ConvGNN had on generated summaries.\n\n\nMethodology\n\nTo answer RQ 1 , we follow established methodology and evaluation metrics that have become standard in both source code summarization work and neural machine translation from NLP [32,43]. To start, we use a large well-documented data set from the literature to allow us to easily compare results and baselines. We use the data handling guidelines outlined in LeClair et al. [30] so that we do not have data leakage between our training, validation, and testing sets.  Table 2: BLEU and ROUGE-LCS scores for the baselines and our proposed models\n\nNext, we train our models for ten epochs and choose the model with the highest validation accuracy score for our comparisons. Choosing the model with the best validation performance out of ten epochs is a training strategy that has been successfully used in other related work [29]. For RQ 1 we evaluate the best performing model using automated evaluation techniques to compare against our baselines and report in this paper. For RQ 2 we train ve ConvGNN models with all hyper-parameters frozen except for hop size. We test our model using hop sizes of 1,2,3,5, and 10 in line with other related work [58]. We used the model con guration outlined in Section 4 that uses the source code and AST input, as well as a GRU layer directly a er the ConvGNN layers. We chose this model because of its performance and its faster training speed compared with the BiLSTM model. To report our results we use the same \"best of ten\" technique that we use to answer RQ 1 , that is, we train each model for ten epochs and report the results on the model with the highest validation accuracy.\n\nFor RQ 3 we use a combination of automated tools and metrics such as BLEU [43], ROUGE [32], and visualizations from model weights. Visualizing model weights and parameters has become a popular way to help explain what deep learning models are doing, and possibly give insight into why they generate the output that they do. To help us answer RQ 3 we use concepts similar to those outlined in Samek et al. [47] for model visualizations.\n\n\nMetrics\n\nFor our quantitative metrics we use both BLEU [43] and ROUGE [32] to evaluate our model performance. BLEU scores are a standard evaluation metric in the source code summarization literature [24,25,29]. BLEU is a text similarity metric that compares overlapping n-grams between two given texts. While BLEU can be thought of as a precision score: how much of the generated text appears in the reference text. In contrast, ROUGE can be thought of as a recall score: how much of the reference appears in the generated text.\n\nROUGE is used primarily in text summarization tasks in the NLP literature due to the score allowing multiple references since there may be multiple correct summaries of a text [32]. In our work we do not have multiple reference texts per method, but ROUGE gives us additional information about the performance of our models that BLEU scores alone do not provide. In this paper we report a composite BLEU score, BLEU 1 through BLEU 4 (n-grams of length 1 to length 4), and ROUGE-LCS (longest common sub-sequence) to have a well rounded set of automated evaluation metrics.\n\n\nBaselines\n\nWe compare our model against four baselines. ese baselines are all from recent work that is directly relevant to this paper. We chose these baselines because they provide comparison for three categories in source code summarization using the AST: 1) a ened AST, 2) using paths through the AST, and 3) using a graph neural network to encode the AST.\n\nEach of these baselines uses AST information as input to the model with di erent schemes. ey also cover a variety of model architectures and con gurations. Due to space limitations we do not list all relevant details for each model, but have a more in depth overview in Section 3.1 and in Table 1.\n\n\u2022 ast-attendgru: In this model LeClair et al. [29] use a standard encoder-decoder model and add an additional encoder for the AST. ey a en the AST using the SBT technique outline in Hu et al. [23]. en both the source code tokens and the a ened AST are provided as input into the model. For encoding these inputs they use recurrent layers and then use a decoder with a recurrent layer to generate the predictions. is approach is representative of other approaches that a en the AST into a sequence. \u2022 graph2seq: Xu et al. [58] developed a general graph to sequence neural model that generates both node and graph embeddings. In their work they use an SQL query and generate a natural language query based on the SQL. eir implementation propagates both forward and backwards over the graph, and includes node level a ention. ey achieved state of the art results on an SQL-\u00bfnatural language task using BLEU-4 as a metric. ey also evaluate how the number of hops a ected the performance of the model nding that any number of hops still converged to similar results, but speci c models could perform just as well with less hops lowering the amount of computation needed.\n\n\u2022 code2seq: Alon et al [3] use random pairwise paths through the AST as model input which we discuss more in depth in Section 3.1. ey used C# code to generate summaries, while we use Java. ey had a variety of con gurations that they test, due to this we did a good-faith re-implementation of their base model in an a empt to capture the major contributions of their approach.\n\n\u2022 BILSTM+GNN: Fernandes et al. [16] proposed a model using a BILSTM and GNN trained with a C# data set for code summarization. We reproduced a model using the information outlined in their paper. We trained the model using the Java data set from LeClair et al. to create a comparison for our work. In their paper they report results on a variety of model architectures and setups, we include comparison results with a model based on their best performing con guration.\n\nese baselines are not an exhaustive list of relevant work, but they cover recent techniques used for source code summarization. Some other work that we chose not to use for baselines include Hu et al. [23], and Wan et al. [56]. We chose not to include Hu et al. in our baselines because the work done by LeClair et al. built upon their work and was shows to have higher performance, and is much closer to our proposed work in this paper. In our proposed model we use the technique outlined in LeClair et al. of separating the source code sequence tokens from the AST.\n\nWan et al. [56] is another potential baseline, but we found it unsuitable for comparison in this paper for three reasons: 1) the approach combines an AST+code encoding with Reinforcement Learning (RL), and the RL component adds many experimental variables with e ects di cult to distinguish from the AST+code component, 2) the AST+code encoding technique has now been superceded by other techniques which we already use as baselines, and 3) we were unable to reproduce the results in the paper. An interesting question for future work is to study the e ects of the RL component in a separate experiment: the RL component of Wan et al. is supportive of, rather than a competitor with, the AST+code encoding. We also do not compare against heuristic based approaches. Most data-driven approaches outperform heuristic based approaches in all of the automated metrics, and previous work has already reported the comparisons.\n\n\nreats to Validity\n\ne primary threat to validity for this paper is that the automated metrics we use to score and rate out models may not be representative of human judgement. BLEU and ROUGE metrics can give us a good indication how our model performs compared to the reference text and other models, but there are instances where the model may generate a valid summary that does not align with the reference text. On the other hand, there is no evaluation as to whether a reference comment for a given method is a good summary. e bene t of these automated metrics is that they are fast and have wide use among the source code summarization community. To mitigate the potential pitfalls that using automated metrics may involve, we include an in depth discussion and evaluation of speci c examples from our model to help interpret what our model has learned when compared to baselines. e dataset we use is also another potential threat to validity. While other data sets do exist with other programming languages, for example C# or Python, many of these data sets lack the size and scope of the data set provided by LeClair et al.. For example the C# dataset used Fernandes et al. has 23 projects, with 55,635 methods having associated documentation. Another common pitfall of datasets described in LeClair et al. is that many datasets split data on the function level instead of the project level. is means that functions from the same project can appear in both the training and testing sets causing potential data leakage. Using Java is bene cial due to its widespread use in many di erent types of programs and its adoption in industry. Java also has a well de ned commenting standard with JavaDocs that creates easily parsable documentation.\n\nOne other threat to validity is that we were unable to perform extensive hyper-parameter optimizations on our models due to hardware limitations. It could be the case that some of our models or baselines outlined in Table 2 could be heavily impacted by certain hyper-parameters (e.g., input sequence length, learning rate, and vocabulary size), giving di erent scores and rankings.\n\nis is a common issue with deep learning projects, and this a ects nearly all similar types of experiments. We try to mitigate the impact of this issue by being consistent with our hyper-parameter values. We also take great care when reproducing work for our baselines, making sure the experimental set ups are reasonable and match them as closely as we can to their descriptions.\n\n\nEXPERIMENT RESULTS\n\nis section provides the experiment results for the research questions we ask in Section 5.1. To answer RQ 1 we use a combination of automated metrics and discuss its performance compared to other models in the context of these metrics. For RQ 2 we test a series of models with di erent hop sizes and compare them to our model as well as our baselines. To answer RQ 3 we provide a set of examples comparing our model using the graph AST and ConvGNN with a a ened AST model and show how the addition of the ConvGNN contributes to the overall summary.\n\n\nRQ 1 : antitative Evaluation\n\nFor our experimental results we tested three model con gurations.\n\nIn labeling our models we use code+gnn to represent the models that use an encoder for the source code tokens, a ConvGNN encoder for the AST, and then we use a +{layer name} format to show the layer that was used on the output of the ConvGNN. We found that model code+gnn+BiLSTM was the highest performing approach obtaining a BLEU-A score of 19.93 and ROUGE-LCS score of 56.08, as seen in Table 2. e code+gnn+BiLSTM model outperformed the nearest graph-based baseline by 4.6% BLEU-A and 0.06% ROUGE-LCS. e code+gnn+BiLSTM model also outperformed the a ened AST baseline by 5.7% BLEU-A and 12.72% ROUGE-LCS. We a ribute this increase in performance to the use of the ConvGNN as an encoding for the AST. Adding the ConvGNN allows the model to learn be er AST node representations than it can with only a sequence model. We go into more depth into how the ConvGNN may be boosting performance in Section 6.3. We a ribute our performance improvement over other graph-based approaches to the use of the source code token sequence as a separate additional encoder. We found that using both the source code sequence and the AST allows the model to learn when to copy tokens directly from the source code, serving a purpose similar to a 'copy mechanism' as described by Gu et al. [18]. Copy mechanisms are used to copy words directly from the input text to the output, primarily used to improve performance with rare or unknown tokens. In this case, the model has learned to copy tokens directly from the source code. is works well for source code summarization because of the large overlap in source code and summary vocabulary (over 94%). In Section 6.3 example 1 we show how models that use both source code and AST input utilize the source code a ention like a copy mechanism.\n\nWe also see a noticeable e ect on model performance based on the recurrent layer a er the ConvGNNs. LeClair et al. achieved 18.69 BLEU-A using only a recurrent layer to encode the a ened AST sequence, and without a recurrent layer the code+gnn+dense model achieves a 19.46 BLEU-A. In an e ort to see how di erent recurrent layers a ect the models performance, we trained a two hop model using GRU and another model using a BiLSTM as shown in Table 2. We found that code+gnn+BiLSTM outperformed code+gnn+GRU by 0.05 BLEU-A and 0.3 ROUGE-LCS. e improved score of the BiLSTM layer is likely due to the increased complexity of the layer over the GRU. We nd in many cases that the BiLSTM architecture outperforms other recurrent layers, but at a signi cantly increased computational cost. For this reason, and because the code+gnn+BiLSTM model only outperformed the code+gnn+GRU model by 0.05 BLEU-A (0.2%), we chose to conduct our other tests using the code+gnn+GRU architecture.\n\n\nRQ 2 : Hop size analysis\n\nIn Table 2 we compare the number of hops in the ConvGNN layers and how it a ects the performance of the model. We found that for the AST two hops had the best overall performance. With having two hops, a node will get information from nodes up to two edges away. As outlined in Section 4, our model implementation creates a separate ConvGNN layer for each hop in series. One explanation for why two hops had the best performance is that, because we are generating summaries at the method level, the ASTs in the dataset are not very deep. Another possibility could be that the other nodes most important to a speci c node are its neighbors, and dealing with smaller clusters of node data is su cient for learning. Lastly, even though the number of hops directly in uences how far and quickly information will propagate through the ConvGNN, every iteration the neighboring nodes are now an aggregate of their neighbors n hops away. In other words, a er one iteration with two hops, a nodes neighbor is now an aggregate of nodes three hops away, so a er enough iterations each node should be a ected by every other node, with closer nodes having a larger e ect.\n\nWhile using two hops reported the best BLEU score for the code+gnn+GRU models, it only performed 1.5% be er than using three hops and 2.8% be er than using 10. Also notice that using ve hops outperformed three and ten hops, this could be due to the random initialization or other minor factors. Because the di erence in overall BLEU score is relatively small between hop sizes, we believe that the number of hops is less important than other hyperparameters. It could be that the number of hops will be more important when summarizing larger selections of code where nodes are farther apart. For example, if the task were to summarize an entire program it may be bene cial to have more hops in your encoder to allow information to propagate farther.\n\n\nRQ 3 : Graph AST Contribution\n\nWe provide three in-depth examples of the GNN's contribution to our model. In these examples we also compare directly with the ast-a endgru model proposed by LeClair et al. [29]. We chose to compare with ast-a endgru because it represents a collection of  Example 1: Visualization of source code and AST attention for code+gnn+gru and ast-attendgru work using a ened ASTs to summarize source code as well as having separate encoders for the source code sequence and AST. We feel that comparing against this model allows us to isolate the contribution that the ConvGNN is making to the generated summaries. It should be noted however that these two models process the AST di erently, they both use SrcML [10] to generate ASTs, but ast-a endgru takes another step and additionally processes the AST using the SBT technique developed by Hu et al.. More details about how LeClair et al. process the AST can be found in Section 5.4.\n\nOur rst example visualized in Example 1 shows an instance where the reference summary contains tokens that also appear in the source code. We use this example to showcase how the source code and AST a entions work together as a copy mechanism to generate summaries. e visualizations in Example 1 are a snapshot of the a ention outputs for both the source code and AST when the models are predicting the rst token in the sequence, which is 'sends' in the reference. We can see in Example 1 (a) that the code+gnn+GRU model and (c) the ast-a endgru model a end to the third token in the input source code sequence (column 2), which in this case is the token 'send'. Where these two models di er, however, is what their respective ASTs are a ending to (seen in (b) and (d)). In the case of code+gnn+GRU (b), the model is a ending to the token 'send' in column eight and the token 'status' in column thirty-eight. On the other hand, e ast-a endgru (d) model is a ending to column thirty-seven, which is the token 'sexpr stmt'.\n\nOne explanation for this is that code+gnn+GRU is able to combine structural and code elements be er than models that don't utilize a ConvGNN. In the context of this example what this means is that the AST token 'send' in the code+gnn+GRU is a learned combination of the 'send' node and its neighbors, which in the AST are nodes 'name', 'status', 'bar', and 'info'. e ast-a endgru model only sees the AST as a sequence of tokens, so when it a ends to the token 'sexpr stmt', its neighboring tokens are 'sblock' and 'sexpr'. Another observation from Example 1 (d) is that, generally, the ast-a endgru model activates more on the AST sequence than it does on the source code sequence, while code+gnn+GRU activates similarly on both a entions and focuses more on speci c tokens. is could be due to the ConvGNN learning more speci c structure information from the AST.\n\nWe also found that because the AST a ention is more ne grained than the ast-a endgru a ention, it learns whether to copy words directly from the source code be er than the other model. In this case, because both the source code and AST a ention focus on the same token, 'send', it determined that 'send' or a word very close to it (in this case 'sends') should be the predicted token. If the source code and AST a ention di er then the model will o en times predict tokens that are not in the source code or AST.\n\nIf we look at later tokens in the predicted sequence, we see that code+gnn+GRU predicts the correct tokens until the last one. For the nal token the reference token is 'server' and code+gnn+GRU predicted 'socket'. What is also interesting here is that ast-a endgru predicted the token 'guess' which is in the reference summary and source code sequence. If we look at Example 2 we see the output of the AST a ention mechanisms for both the code+gnn+GRU and ast-a endgru models during their prediction of the nal token in the sequence. What this means is that code+gnn+GRU has the input sequence [sends, a, guess, to, the] and predicts 'socket' and ast-a endgru has the sequence [a empts, to, initiate, a, \u00a1UNK\u00bf] and predicts 'guess'. We do not include the source code visualization here because they were very similar to the visualizations in Example 1 (a) and (c). So, in the source code a ention both models a end to the tokens 'send' and 'guess', but as we can see in the AST visualization, code+gnn+GRU is a ending to the token in column forty-six -'querying'; and ast-a endgru is a ending to a large, nonspeci c area in the structure of the AST. e code+gnn+GRU model has learned that the combination of the tokens 'send', 'guess', and the AST token 'querying' lead to the prediction of the token 'socket'. While this prediction was incorrect, the token 'socket' is closely related to the term 'server' in this context. Notice that the token 'querying' is also in the source code, but neither model a ends to it. As stated above, the source code a ention is acting more as a copy mechanism and is a ending to tokens that it believes should be the next predicted token, then it relies on the AST a ention to add additional information for the nal prediction.\n\nExample 3 is a case where the code+gnn+GRU model correctly predicts the sixth token in the sequence, ' rst', but ast-a endgru predicts the token 'speci ed'. For this prediction both models have the same predicted token sequence input to the decoder. If we look at Example 3, we can see the the a ention visualizations for our models for their prediction of the sixth token in the sequence. In Example 3 (a) in the sixth row, the code+gnn+GRU model is a ending to the h column, which is the token 'o'. In this piece of code 'o' is the identi er for the input parameter for the method. e ast-a endgru model source a ention (Example 3 (c)) is a ending to columns seventeen and thirty-four which are both the token 'game'. Looking at the code+gnn+GRU AST a ention (Example 3 (b)), we see that it is a ending to column sixty-three, which is also the token 'game'. So, in this example the ast-a engru model's source a ention is a ending to 'game' and the code+gnn+GRU model's a ention is also a ending to the token 'game' in the AST.\n\nis is important because it shows both models have learned that this token is important to the prediction, but in di erent contexts. Looking at the visualizations, we see again that the code+gnn+GRU model is able to focus on speci c, important tokens in both the source code and the AST, while the ast-a endgru model a ends to larger portions of the AST.\n\n\nDISCUSSION AND FUTURE WORK\n\ne major take-aways from the work outlined in this paper are:\n\n\u2022 Using the AST as a graph with ConvGNN layers outperforms a a ened version of the AST \u2022 Including the source code sequence as a separate encoder allows the model to learn to use the source code and AST as a copy mechanism. \u2022 e improved node embeddings from the ConvGNN allow the model to learn be er token representations where representation of tokens in the AST are a combination of structure elements.\n\ne three examples that we show are situations where the addition of the ConvGNN allowed the model to learn be er node representations than using a a ened sequence for the AST. When both the source code a ention and the AST a ention align on a speci c token, the model treats this like a copy mechanism, directly copying the input source token to the output. When the source and AST a ention do not agree, we see the model relying more on the AST to predict the next token in the sequence. When we compare this to a model with a a ened AST input, we see a large di erence in how the AST is being a ended to, generally the a ened AST model looks at larger structure areas instead of speci c tokens.\n\nAs an avenue for future work, models such as these have been shown to improve performance when ensembled. LeClair et al. showed that a model without AST information outperformed a model using AST information on speci c types of summaries [29].\n\nis could lead to interesting results, potentially showing that bringing in di erent features from the source code allows the models to learn to generate be er summaries for speci c types of methods.\n\n\nCONCLUSION\n\nIn this work we have presented a new neural model architecture that utilizes a sequence of source code tokens along with Con-vGNNs to encode the AST of a Java method and generate natural language summaries. We provide background and insights into why using a graph based neural network to encode the AST improves performance, along with providing a comparison of our results against relevant baselines. We conclude that the combination of source code tokens along with the AST and ConvGNNs allows the model to be er learn when to directly copy tokens from the source code, as well as create be er representations of tokens in the AST. We show that that the use of the ConvGNN to encode the AST improves aggregate BLEU scores (BLEU-A) by over 4.6% over other graph-based approaches and 5.7% improvement over a ened AST approaches. We also provide an in dept analysis of how the ConvGNN layers a ribute to this increase in performance, and speculate on how these insights can be used for future work.\n\n\nREPODUCIBILITY\n\nAll of our models, source code, and data used in this work can be found in our online repository at h ps://go.aws/2tPXV2R. \n\n\nACKNOWLEDGMENTS\n\nis work is supported in part by NSF CCF-1452959 and CCF-1717607. Any opinions, ndings, and conclusions expressed herein are the authors and do not necessarily re ect those of the sponsors.\n\nFigure 1 :\n1High level diagram of model architecture for 2-hop model\n\n\n(b) code+gnn+GRU : Source attention (c) code+gnn+GRU : AST attention (d) ast-a endgru: Source attention (e) ast-a endgru: AST attention\n\n\na) code+gnn+GRU : AST attention (b) ast-a endgru: AST attention Example 2: Visualization of AST attention mechanisms for code+gnn+gru and ast-attendgru when predicting the nal token in the sequence.\n\n\nreturns the index of the rst occurrence of the speci ed element code+gnn+GRU returns the index of the rst occurrence of the speci ed element ast-a endgru returns the index of the speci ed object in the list ) code+gnn+GRU : AST attention (d) ast-a endgru: Source attention (e) ast-a endgru: AST attention Example 3: Visualization of source code and AST attention for code+gnn+GRU and ast-attendgru\n\nTable 1 :\n1Comparison of recent data-driven Source Code Sum-\nmarization research categorized by the data, architectures, \nand approaches used. \ne approaches in the upper table \nuse only the source code sequence as input to their models, \nwhile the bottom table approaches use the AST or a combi-\nnation of AST and source code. \n\n\n\nMart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado, Andy Davis, Je Rey Dean, Ma Hieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geo Rey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\u00e9gas, Oriol Vinyals, Pete Warden, Martin Wa enberg, Martin Wicke, Yuan Yu, and Xiaoqiang ZhengDandelion Man\u00e9, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya SutskeverMart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Je rey Dean, Ma hieu Devin, San- jay Ghemawat, Ian Goodfellow, Andrew Harp, Geo rey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Man\u00e9, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi\u00e9gas, Oriol Vinyals, Pete Warden, Martin Wa enberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. 2015. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. h ps://www.tensor ow.org/ So ware available from tensor ow.org.\n\nLearning to represent programs with graphs. Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi, International Conference on Learning Representations. Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. 2018. Learn- ing to represent programs with graphs. International Conference on Learning Representations (2018).\n\nUri Alon, Shaked Brody, Omer Levy, Eran Yahav, Generating sequences from structured representations of code. International Conference on Learning Representations. 2Uri Alon, Shaked Brody, Omer Levy, and Eran Yahav. 2019. code2seq: Generating sequences from structured representations of code. International Conference on Learning Representations (2019).\n\nWhat is relevant in a text document? : An interpretable machine learning approach. Leila Arras, Franziska Horn, Grgoire Montavon, Klaus-Robert Mller, Wojciech Samek, 10.1371/journal.pone.0181142PLOS ONE. 12Leila Arras, Franziska Horn, Grgoire Montavon, Klaus-Robert Mller, and Wo- jciech Samek. 2017. What is relevant in a text document? : An inter- pretable machine learning approach. PLOS ONE 12, 8 (Aug 2017), e0181142. h ps://doi.org/10.1371/journal.pone.0181142\n\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, arXiv:1409.0473arXiv preprintDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural ma- chine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).\n\nSource code analysis: A road map. David Binkley, Future of So ware Engineering. IEEE Computer Society. David Binkley. 2007. Source code analysis: A road map. In 2007 Future of So ware Engineering. IEEE Computer Society, 104-119.\n\nImproved Neural Machine Translation with a Syntax-Aware Encoder and Decoder. Huadong Chen, Shujian Huang, David Chiang, Jiajun Chen, 10.18653/v1/P17-1177Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics1Long Papers)Huadong Chen, Shujian Huang, David Chiang, and Jiajun Chen. 2017. Improved Neural Machine Translation with a Syntax-Aware Encoder and Decoder. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Vancouver, Canada, 1936-1945. h ps://doi.org/10.18653/v1/P17-1177\n\nReinforcement learning based graph-to-sequence model for natural question generation. Yu Chen, Lingfei Wu, Mohammed J Zaki, International Conference on Learning Representations. Yu Chen, Lingfei Wu, and Mohammed J Zaki. 2020. Reinforcement learning based graph-to-sequence model for natural question generation. International Conference on Learning Representations (2020).\n\n. Fran\u00e7ois Chollet, Fran\u00e7ois Chollet et al. 2015. Keras. h ps://github.com/fchollet/keras.\n\nLightweight transformation and fact extraction with the srcML toolkit. L Michael, Collard, J Michael, Jonathan I Decker, Maletic, 11th IEEE International Working Conference on. IEEE. Source Code Analysis and Manipulation (SCAM)Michael L Collard, Michael J Decker, and Jonathan I Maletic. 2011. Lightweight transformation and fact extraction with the srcML toolkit. In Source Code Analysis and Manipulation (SCAM), 2011 11th IEEE International Working Conference on. IEEE, 173-184.\n\nA systematic survey of program comprehension through dynamic analysis. Andy Bas Cornelissen, Arie Zaidman, Leon Van Deursen, Rainer Moonen, Koschke, IEEE Transactions on So ware Engineering. 35Bas Cornelissen, Andy Zaidman, Arie Van Deursen, Leon Moonen, and Rainer Koschke. 2009. A systematic survey of program comprehension through dynamic analysis. IEEE Transactions on So ware Engineering 35, 5 (2009), 684-702.\n\nA study of the documentation essential to so ware maintenance. Sergio Cozze I B. De, Nicolas Souza, K\u00e1thia M Anquetil, De Oliveira, 10.1145/1085313.1085331Proceedings of the 23rd annual international conference on Design of communication: documenting & designing for pervasive information (SIGDOC '05). the 23rd annual international conference on Design of communication: documenting & designing for pervasive information (SIGDOC '05)New York, NY, USAACMSergio Cozze i B. de Souza, Nicolas Anquetil, and K\u00e1thia M. de Oliveira. 2005. A study of the documentation essential to so ware maintenance. In Proceedings of the 23rd annual international conference on Design of communication: documenting & designing for pervasive information (SIGDOC '05). ACM, New York, NY, USA, 68-75. h ps://doi.org/10.1145/1085313.1085331\n\nWhat Does Explainable AI Really Mean? A New Conceptualization of Perspectives. Derek Doran, Sarah Schulz, Tarek R Besold, arXiv:1710.00794org/abs/1710.00794Derek Doran, Sarah Schulz, and Tarek R. Besold. 2017. What Does Explainable AI Really Mean? A New Conceptualization of Perspectives. CoRR abs/1710.00794 (2017). arXiv:1710.00794 h p://arxiv.org/abs/1710.00794\n\nFinale Doshi, - Velez, Been Kim, arXiv:1702.08608arXiv:stat.ML/1702.08608Towards A Rigorous Science of Interpretable Machine Learning. arXiv e-prints. Finale Doshi-Velez and Been Kim. 2017. Towards A Rigorous Science of Inter- pretable Machine Learning. arXiv e-prints, Article arXiv:1702.08608 (Feb 2017), arXiv:1702.08608 pages. arXiv:stat.ML/1702.08608\n\nEvaluating source code summarization techniques: Replication and expansion. P Brian, Eddy, Nicholas A Robinson, Je Rey C Kra, Carver, IEEE 21st International Conference on. IEEE. Program Comprehension (ICPC)Brian P Eddy, Je rey A Robinson, Nicholas A Kra , and Je rey C Carver. 2013. Evaluating source code summarization techniques: Replication and expansion. In Program Comprehension (ICPC), 2013 IEEE 21st International Conference on. IEEE, 13-22.\n\nStructured Neural Summarization. Patrick Fernandes, Miltiadis Allamanis, Marc Brockschmidt, arXiv:1811.01824org/abs/1811.01824Patrick Fernandes, Miltiadis Allamanis, and Marc Brockschmidt. 2018. Structured Neural Summarization. CoRR abs/1811.01824 (2018). arXiv:1811.01824 h p: //arxiv.org/abs/1811.01824\n\ne relevance of so ware documentation, tools and technologies: a survey. Andrew Forward, Timothy C Lethbridge, 10.1145/585058.585065Proceedings of the 2002 ACM symposium on Document engineering (DocEng '02). the 2002 ACM symposium on Document engineering (DocEng '02)New York, NY, USAACMAndrew Forward and Timothy C. Lethbridge. 2002. e relevance of so ware documentation, tools and technologies: a survey. In Proceedings of the 2002 ACM symposium on Document engineering (DocEng '02). ACM, New York, NY, USA, 26-33. h ps://doi.org/10.1145/585058.585065\n\nIncorporating Copying Mechanism in Sequence-to-Sequence Learning. Jiatao Gu, Zhengdong Lu, Hang Li, O K Victor, Li, Proceedings of the 54th. the 54thJiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li. 2016. Incorporating Copying Mechanism in Sequence-to-Sequence Learning. Proceedings of the 54th\n\n10.18653/v1/p16-1154Annual Meeting of the Association for Computational Linguistics. Long Papers1Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2016). h ps://doi.org/10.18653/v1/p16-1154\n\nOn the use of automated text summarization techniques for summarizing source code. Sonia Haiduc, Jairo Aponte, Laura Moreno, Andrian Marcus, Sonia Haiduc, Jairo Aponte, Laura Moreno, and Andrian Marcus. 2010. On the use of automated text summarization techniques for summarizing source code.\n\nReverse Engineering (WCRE), 2010 17th Working Conference on. IEEE. In Reverse Engineering (WCRE), 2010 17th Working Conference on. IEEE, 35-44.\n\nOn the Use of Domain Terms in Source Code. S Haiduc, A Marcus, 16th IEEE International Conference on Program Comprehension (ICPC'08). Amsterdam, e Netherlands. S. Haiduc and A. Marcus. 2008. On the Use of Domain Terms in Source Code. In 16th IEEE International Conference on Program Comprehension (ICPC'08). Amster- dam, e Netherlands, 113-122.\n\nAre deep neural networks the best choice for modeling source code. J Vincent, Premkumar Hellendoorn, Devanbu, Proceedings of the 2017 11th Joint Meeting on Foundations of So ware Engineering. the 2017 11th Joint Meeting on Foundations of So ware EngineeringACMVincent J Hellendoorn and Premkumar Devanbu. 2017. Are deep neural networks the best choice for modeling source code?. In Proceedings of the 2017 11th Joint Meeting on Foundations of So ware Engineering. ACM, 763-773.\n\nAutomatically mining so ware-based, semantically-similar words from comment-code mappings. M J Howard, S Gupta, L Pollock, K Vijay-Shanker, 10.1109/MSR.2013.662405210th Working Conference on Mining So ware Repositories (MSR). M. J. Howard, S. Gupta, L. Pollock, and K. Vijay-Shanker. 2013. Automatically mining so ware-based, semantically-similar words from comment-code map- pings. In 2013 10th Working Conference on Mining So ware Repositories (MSR). 377-386. h ps://doi.org/10.1109/MSR.2013.6624052\n\nDeep code comment generation. Xing Hu, Ge Li, Xin Xia, David Lo, Zhi Jin, Proceedings of the 26th International Conference on Program Comprehension. the 26th International Conference on Program ComprehensionACMXing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep code comment generation. In Proceedings of the 26th International Conference on Program Com- prehension. ACM, 200-210.\n\nSummarizing Source Code with Transferred API Knowledge. Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, Zhi Jin, IJCAI. Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, and Zhi Jin. 2018. Summarizing Source Code with Transferred API Knowledge.. In IJCAI. 2269-2275.\n\nSummarizing source code using a neural a ention model. Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Luke Ze Lemoyer, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational Linguistics1Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Ze lemoyer. 2016. Summarizing source code using a neural a ention model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Vol. 1. 2073-2083.\n\nA Survey of Documentation Practice within Corrective Maintenance. Mira Kajko-Ma Sson, 10.1023/B:LIDA.0000048322.42751.caEmpirical So w. Engg. 10Mira Kajko-Ma sson. 2005. A Survey of Documentation Practice within Cor- rective Maintenance. Empirical So w. Engg. 10, 1 (Jan. 2005), 31-55. h ps: //doi.org/10.1023/B:LIDA.0000048322.42751.ca\n\nAPI documentation from source code comments: a case study of Javadoc. Douglas Kramer, Proceedings of the 17th annual international conference on Computer documentation. the 17th annual international conference on Computer documentationACMDouglas Kramer. 1999. API documentation from source code comments: a case study of Javadoc. In Proceedings of the 17th annual international conference on Computer documentation. ACM, 147-153.\n\nAdapting Neural Text Classi cation for Improved So ware Categorization. A Leclair, Z Eberhart, C Mcmillan, 10.1109/ICSME.2018.000562018 IEEE International Conference on So ware Maintenance and Evolution (ICSME). A. LeClair, Z. Eberhart, and C. McMillan. 2018. Adapting Neural Text Clas- si cation for Improved So ware Categorization. In 2018 IEEE International Conference on So ware Maintenance and Evolution (ICSME). 461-472. h ps: //doi.org/10.1109/ICSME.2018.00056\n\nA neural model for generating natural language summaries of program subroutines. Alexander Leclair, Siyuan Jiang, Collin Mcmillan, Proceedings of the 41st International Conference on So ware Engineering. the 41st International Conference on So ware EngineeringIEEE PressAlexander LeClair, Siyuan Jiang, and Collin McMillan. 2019. A neural model for generating natural language summaries of program subroutines. In Proceedings of the 41st International Conference on So ware Engineering. IEEE Press, 795-806.\n\nRecommendations for Datasets for Source Code Summarization. Alexander Leclair, Collin Mcmillan, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesLong and Short Papers1Alexander LeClair and Collin McMillan. 2019. Recommendations for Datasets for Source Code Summarization. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers). 3931-3937.\n\nAutomatic Generation of Text Descriptive Comments for Code Blocks. Yuding Liang, Kenny Q Zhu, arXiv:1808.06880org/abs/1808.06880Yuding Liang and Kenny Q. Zhu. 2018. Automatic Generation of Text Descriptive Comments for Code Blocks. CoRR abs/1808.06880 (2018). arXiv:1808.06880 h p://arxiv.org/abs/1808.06880\n\nRouge: A package for automatic evaluation of summaries. Chin-Yew Lin, Text Summarization Branches Out. Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. Text Summarization Branches Out (2004).\n\nUCI Source Code Data Sets. C Lopes, S Bajracharya, J Ossher, P Baldi, C. Lopes, S. Bajracharya, J. Ossher, and P. Baldi. 2010. UCI Source Code Data Sets. h p://www.ics.uci.edu/$\\sim$lopes/datasets/\n\nA Neural Architecture for Generating Natural Language Descriptions from Source Code Changes. Pablo Loyola, Edison Marrese-Taylor, Yutaka Matsuo, ACL. Pablo Loyola, Edison Marrese-Taylor, and Yutaka Matsuo. 2017. A Neural Ar- chitecture for Generating Natural Language Descriptions from Source Code Changes. In ACL.\n\nLearning to Generate Comments for API-Based Code Snippets. Yangyang Lu, Zelong Zhao, Ge Li, Zhi Jin, So ware Engineering and Methodology for Emerging Domains. Zheng Li, He Jiang, Ge Li, Minghui Zhou, and Ming LiSingapore; SingaporeSpringerYangyang Lu, Zelong Zhao, Ge Li, and Zhi Jin. 2019. Learning to Generate Com- ments for API-Based Code Snippets. In So ware Engineering and Methodology for Emerging Domains, Zheng Li, He Jiang, Ge Li, Minghui Zhou, and Ming Li (Eds.). Springer Singapore, Singapore, 3-14.\n\nAutomated feature discovery via sentence selection and source code summarization. W Paul, Cheng Mcburney, Collin Liu, Mcmillan, Journal of So ware: Evolution and Process. 28Paul W McBurney, Cheng Liu, and Collin McMillan. 2016. Automated feature discovery via sentence selection and source code summarization. Journal of So ware: Evolution and Process 28, 2 (2016), 120-145.\n\nAutomatic source code summarization of context for java methods. W Paul, Collin Mcburney, Mcmillan, IEEE Transactions on So ware Engineering. 42Paul W McBurney and Collin McMillan. 2016. Automatic source code summa- rization of context for java methods. IEEE Transactions on So ware Engineering 42, 2 (2016), 103-119.\n\nExplanation in arti cial intelligence: Insights from the social sciences. Tim Miller, 10.1016/j.artint.2018.07.00707.007Arti cial Intelligence. 267Tim Miller. 2019. Explanation in arti cial intelligence: Insights from the social sciences. Arti cial Intelligence 267 (2019), 1 -38. h ps://doi.org/10.1016/j.artint. 2018.07.007\n\nOn the analysis of human and automatic summaries of source code. Laura Moreno, Jairo Aponte, CLEI Electronic Journal. 15Laura Moreno and Jairo Aponte. 2012. On the analysis of human and automatic summaries of source code. CLEI Electronic Journal 15, 2 (2012), 2-2.\n\nAutomatic generation of natural language summaries for java classes. Laura Moreno, Jairo Aponte, Giriprasad Sridhara, Andrian Marcus, Lori Pollock, K Vijay-Shanker, IEEE 21st International Conference on. IEEE. Program Comprehension (ICPC)Laura Moreno, Jairo Aponte, Giriprasad Sridhara, Andrian Marcus, Lori Pollock, and K Vijay-Shanker. 2013. Automatic generation of natural language summaries for java classes. In Program Comprehension (ICPC), 2013 IEEE 21st International Conference on. IEEE, 23-32.\n\nSummarizing so ware artifacts: A literature review. Najam Nazar, Yan Hu, He Jiang, Journal of Computer Science and Technology. 31Najam Nazar, Yan Hu, and He Jiang. 2016. Summarizing so ware artifacts: A literature review. Journal of Computer Science and Technology 31, 5 (2016), 883-909.\n\ne program dependence graph in a so ware development environment. J Karl, Linda M O O Enstein, Enstein, ACM SIGSOFT So ware Engineering Notes. 9Karl J O enstein and Linda M O enstein. 1984. e program dependence graph in a so ware development environment. ACM SIGSOFT So ware Engineering Notes 9, 3 (1984), 177-184.\n\nBLEU: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting on association for computational linguistics. the 40th annual meeting on association for computational linguisticsAssociation for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 311-318.\n\nAn eye-tracking study of java programmers and application to source code summarization. Paige Rodeghero, Cheng Liu, W Paul, Collin Mcburney, Mcmillan, IEEE Transactions on So ware Engineering. 41Paige Rodeghero, Cheng Liu, Paul W McBurney, and Collin McMillan. 2015. An eye-tracking study of java programmers and application to source code summarization. IEEE Transactions on So ware Engineering 41, 11 (2015), 1038- 1054.\n\nHow do professional developers comprehend so ware. Tobias Roehm, Rebecca Tiarks, Rainer Koschke, Walid Maalej, Proceedings of the 2012 International Conference on So ware Engineering (ICSE 2012. the 2012 International Conference on So ware Engineering (ICSE 2012Piscataway, NJ, USAIEEE PressTobias Roehm, Rebecca Tiarks, Rainer Koschke, and Walid Maalej. 2012. How do professional developers comprehend so ware?. In Proceedings of the 2012 Inter- national Conference on So ware Engineering (ICSE 2012). IEEE Press, Piscataway, NJ, USA, 255-265. h p://dl.acm.org/citation.cfm?id=2337223.2337254\n\nRibana Roscher, Bastian Bohn, Marco F Duarte, Jochen Garcke, arXiv:cs.LG/1905.08883Explainable Machine Learning for Scienti c Insights and Discoveries. Ribana Roscher, Bastian Bohn, Marco F. Duarte, and Jochen Garcke. 2019. Explainable Machine Learning for Scienti c Insights and Discoveries. arXiv:cs.LG/1905.08883\n\nExplainable arti cial intelligence: Understanding, visualizing and interpreting deep learning models. Wojciech Samek, Klaus-Robert Wiegand, M\u00fcller, arXiv:1708.08296arXiv preprintWojciech Samek, omas Wiegand, and Klaus-Robert M\u00fcller. 2017. Explainable arti cial intelligence: Understanding, visualizing and interpreting deep learning models. arXiv preprint arXiv:1708.08296 (2017).\n\nAn empirical study on evolution of API documentation. Lin Shi, Hao Zhong, Tao Xie, Mingshu Li, Proceedings of the 14th international conference on Fundamental approaches to so ware engineering: part of the joint European conferences on theory and practice of so ware (FASE'11/ETAPS'11). the 14th international conference on Fundamental approaches to so ware engineering: part of the joint European conferences on theory and practice of so ware (FASE'11/ETAPS'11)Berlin, HeidelbergSpringer-VerlagLin Shi, Hao Zhong, Tao Xie, and Mingshu Li. 2011. An empirical study on evolution of API documentation. In Proceedings of the 14th international conference on Fundamental approaches to so ware engineering: part of the joint European conferences on theory and practice of so ware (FASE'11/ETAPS'11). Springer-Verlag, Berlin, Heidelberg, 416-431. h p://dl.acm.org/citation.cfm?id=1987434.1987473\n\nA Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques. Xiaotao Song, Hailong Sun, Xu Wang, Jiafei Yan, IEEE AccessXiaotao Song, Hailong Sun, Xu Wang, and Jiafei Yan. 2019. A Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques. IEEE Access (2019).\n\nTowards automatically generating summary comments for java methods. Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, Vijay-Shanker, Proceedings of the IEEE/ACM international conference on Automated so ware engineering. the IEEE/ACM international conference on Automated so ware engineeringACMGiriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, and K Vijay- Shanker. 2010. Towards automatically generating summary comments for java methods. In Proceedings of the IEEE/ACM international conference on Automated so ware engineering. ACM, 43-52.\n\nAutomatically detecting and describing high level actions within methods. Giriprasad Sridhara, Lori Pollock, K Vijay-Shanker, Proceedings of the 33rd International Conference on So ware Engineering. the 33rd International Conference on So ware EngineeringACMGiriprasad Sridhara, Lori Pollock, and K Vijay-Shanker. 2011. Automatically detecting and describing high level actions within methods. In Proceedings of the 33rd International Conference on So ware Engineering. ACM, 101-110.\n\nGenerating text with recurrent neural networks. Ilya Sutskever, James Martens, Geo Rey E Hinton, Proceedings of the 28th International Conference on Machine Learning. the 28th International Conference on Machine LearningIlya Sutskever, James Martens, and Geo rey E Hinton. 2011. Generating text with recurrent neural networks. In Proceedings of the 28th International Conference on Machine Learning (ICML-11). 1017-1024.\n\nSequence to sequence learning with neural networks. Ilya Sutskever, Oriol Vinyals, Le, Advances in neural information processing systems. Ilya Sutskever, Oriol Vinyals, and oc V Le. 2014. Sequence to sequence learning with neural networks. In Advances in neural information processing systems. 3104-3112.\n\nProgram comprehension during so ware maintenance and evolution. Anneliese Von Mayrhauser, Marie Vans, Computer. 8Anneliese Von Mayrhauser and A Marie Vans. 1995. Program comprehension during so ware maintenance and evolution. Computer 8 (1995), 44-55.\n\nSebastian Laura Von Rueden, Jochen Mayer, Christian Garcke, Jannis Bauckhage, Schuecker, arXiv:stat.ML/1903.12394Informed Machine Learning -Towards a Taxonomy of Explicit Integration of Knowledge into Machine Learning. Laura von Rueden, Sebastian Mayer, Jochen Garcke, Christian Bauckhage, and Jannis Schuecker. 2019. Informed Machine Learning -Towards a Taxonomy of Ex- plicit Integration of Knowledge into Machine Learning. arXiv:stat.ML/1903.12394\n\nImproving Automatic Source Code Summarization via Deep Reinforcement Learning. Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, Philip S Yu, 10.1145/3238147.3238206Proceedings of the 33rd ACM/IEEE International Conference on Automated So ware Engineering. the 33rd ACM/IEEE International Conference on Automated So ware EngineeringNew York, NY, USA397407Association for Computing MachineryYao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S. Yu. 2018. Improving Automatic Source Code Summarization via Deep Reinforcement Learning. In Proceedings of the 33rd ACM/IEEE In- ternational Conference on Automated So ware Engineering (ASE 2018). Asso- ciation for Computing Machinery, New York, NY, USA, 397 407. h ps: //doi.org/10.1145/3238147.3238206\n\nA Comprehensive Survey on Graph Neural Networks. Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S Yu, arXiv:1901.00596org/abs/1901.00596Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. 2019. A Comprehensive Survey on Graph Neural Networks. CoRR abs/1901.00596 (2019). arXiv:1901.00596 h p://arxiv.org/abs/1901.00596\n\nGraph2seq: Graph to sequence learning with a ention-based neural networks. Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, Vadim Sheinin, arXiv:1804.00823arXiv preprintKun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, and Vadim Sheinin. 2018. Graph2seq: Graph to sequence learning with a ention-based neural networks. arXiv preprint arXiv:1804.00823 (2018).\n\nExploiting rich syntactic information for semantic parsing with graph-tosequence model. Kun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, Vadim Sheinin, Conference on Empirical Methods in Natural Language Processing. Kun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, and Vadim Sheinin. 2018. Exploiting rich syntactic information for semantic parsing with graph-to- sequence model. Conference on Empirical Methods in Natural Language Processing (2018).\n", "annotations": {"author": "[{\"end\":167,\"start\":73},{\"end\":254,\"start\":168},{\"end\":326,\"start\":255},{\"end\":403,\"start\":327},{\"end\":482,\"start\":404},{\"end\":555,\"start\":483},{\"end\":627,\"start\":556},{\"end\":704,\"start\":628}]", "publisher": null, "author_last_name": "[{\"end\":90,\"start\":83},{\"end\":179,\"start\":174},{\"end\":265,\"start\":263},{\"end\":342,\"start\":334},{\"end\":421,\"start\":414},{\"end\":494,\"start\":489},{\"end\":566,\"start\":564},{\"end\":643,\"start\":635}]", "author_first_name": "[{\"end\":82,\"start\":73},{\"end\":173,\"start\":168},{\"end\":262,\"start\":255},{\"end\":333,\"start\":327},{\"end\":413,\"start\":404},{\"end\":488,\"start\":483},{\"end\":563,\"start\":556},{\"end\":634,\"start\":628}]", "author_affiliation": "[{\"end\":166,\"start\":108},{\"end\":253,\"start\":195},{\"end\":325,\"start\":267},{\"end\":402,\"start\":344},{\"end\":481,\"start\":423},{\"end\":554,\"start\":496},{\"end\":626,\"start\":568},{\"end\":703,\"start\":645}]", "title": "[{\"end\":55,\"start\":1},{\"end\":759,\"start\":705}]", "venue": "[{\"end\":791,\"start\":761}]", "abstract": "[{\"end\":2356,\"start\":1088}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2469,\"start\":2465},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2472,\"start\":2469},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2475,\"start\":2472},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2478,\"start\":2475},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3158,\"start\":3156},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3256,\"start\":3252},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3845,\"start\":3841},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3848,\"start\":3845},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3851,\"start\":3848},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3854,\"start\":3851},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3922,\"start\":3918},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3995,\"start\":3991},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4154,\"start\":4150},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4157,\"start\":4154},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4160,\"start\":4157},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":4163,\"start\":4160},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":4166,\"start\":4163},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":4169,\"start\":4166},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4358,\"start\":4355},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4361,\"start\":4358},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4364,\"start\":4361},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4367,\"start\":4364},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":5307,\"start\":5303},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5385,\"start\":5381},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5476,\"start\":5472},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5558,\"start\":5554},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5561,\"start\":5558},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5941,\"start\":5938},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":5944,\"start\":5941},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6262,\"start\":6258},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6352,\"start\":6348},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6445,\"start\":6442},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6526,\"start\":6523},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":7498,\"start\":7494},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7740,\"start\":7736},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7860,\"start\":7856},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8581,\"start\":8577},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8615,\"start\":8611},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":8618,\"start\":8615},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8659,\"start\":8655},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8799,\"start\":8795},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9160,\"start\":9156},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9273,\"start\":9270},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9276,\"start\":9273},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9368,\"start\":9365},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9371,\"start\":9368},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9927,\"start\":9923},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9930,\"start\":9927},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10377,\"start\":10373},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":10886,\"start\":10882},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10908,\"start\":10904},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11722,\"start\":11718},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":12056,\"start\":12052},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12096,\"start\":12092},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12315,\"start\":12311},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12665,\"start\":12661},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12691,\"start\":12687},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12713,\"start\":12709},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12737,\"start\":12733},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":12764,\"start\":12760},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12788,\"start\":12784},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":12815,\"start\":12811},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12844,\"start\":12840},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12871,\"start\":12868},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12904,\"start\":12900},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12920,\"start\":12916},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13258,\"start\":13255},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13790,\"start\":13786},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14621,\"start\":14618},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":15116,\"start\":15112},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":15458,\"start\":15454},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":16118,\"start\":16114},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":16730,\"start\":16726},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17149,\"start\":17146},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":17180,\"start\":17176},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17211,\"start\":17208},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":17309,\"start\":17305},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17345,\"start\":17342},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18291,\"start\":18287},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":18294,\"start\":18291},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18906,\"start\":18902},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":21511,\"start\":21507},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21514,\"start\":21511},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21954,\"start\":21951},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21972,\"start\":21969},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":22868,\"start\":22864},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":24678,\"start\":24674},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25320,\"start\":25316},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":26786,\"start\":26783},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26789,\"start\":26786},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26792,\"start\":26789},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26795,\"start\":26792},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":26855,\"start\":26852},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26858,\"start\":26855},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":27247,\"start\":27243},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":28037,\"start\":28034},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":28040,\"start\":28037},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28043,\"start\":28040},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":28046,\"start\":28043},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28049,\"start\":28046},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":28052,\"start\":28049},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28072,\"start\":28068},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":28321,\"start\":28317},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":28645,\"start\":28642},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28648,\"start\":28645},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":28964,\"start\":28960},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":28967,\"start\":28964},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":29159,\"start\":29155},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":29608,\"start\":29604},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":29933,\"start\":29929},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":30413,\"start\":30412},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":30483,\"start\":30479},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30495,\"start\":30491},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":30814,\"start\":30810},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":30902,\"start\":30898},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30917,\"start\":30913},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":31046,\"start\":31042},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31049,\"start\":31046},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":31052,\"start\":31049},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":31553,\"start\":31549},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":32657,\"start\":32653},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":32803,\"start\":32799},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":33132,\"start\":33128},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":33800,\"start\":33797},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":34186,\"start\":34182},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":34826,\"start\":34822},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":34847,\"start\":34843},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":35205,\"start\":35201},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":40569,\"start\":40565},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":44191,\"start\":44187},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":44721,\"start\":44717},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":51928,\"start\":51924}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":53562,\"start\":53493},{\"attributes\":{\"id\":\"fig_1\"},\"end\":53700,\"start\":53563},{\"attributes\":{\"id\":\"fig_2\"},\"end\":53901,\"start\":53701},{\"attributes\":{\"id\":\"fig_3\"},\"end\":54301,\"start\":53902},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":54632,\"start\":54302}]", "paragraph": "[{\"end\":3682,\"start\":2372},{\"end\":5308,\"start\":3684},{\"end\":6900,\"start\":5310},{\"end\":7263,\"start\":6902},{\"end\":8217,\"start\":7265},{\"end\":9577,\"start\":8250},{\"end\":9931,\"start\":9579},{\"end\":10062,\"start\":9963},{\"end\":11274,\"start\":10092},{\"end\":11401,\"start\":11276},{\"end\":11645,\"start\":11403},{\"end\":12292,\"start\":11647},{\"end\":13226,\"start\":12294},{\"end\":14433,\"start\":13228},{\"end\":14854,\"start\":14464},{\"end\":15459,\"start\":14856},{\"end\":15984,\"start\":15461},{\"end\":16153,\"start\":16010},{\"end\":17346,\"start\":16155},{\"end\":18176,\"start\":17348},{\"end\":18775,\"start\":18178},{\"end\":19029,\"start\":18788},{\"end\":19090,\"start\":19031},{\"end\":19384,\"start\":19092},{\"end\":20543,\"start\":19403},{\"end\":20856,\"start\":20545},{\"end\":21115,\"start\":20858},{\"end\":21222,\"start\":21117},{\"end\":21747,\"start\":21224},{\"end\":22073,\"start\":21765},{\"end\":23367,\"start\":22075},{\"end\":23488,\"start\":23369},{\"end\":23928,\"start\":23490},{\"end\":24372,\"start\":23930},{\"end\":24512,\"start\":24374},{\"end\":25378,\"start\":24533},{\"end\":25578,\"start\":25399},{\"end\":25644,\"start\":25580},{\"end\":25802,\"start\":25666},{\"end\":28765,\"start\":25823},{\"end\":29325,\"start\":28781},{\"end\":30403,\"start\":29327},{\"end\":30840,\"start\":30405},{\"end\":31371,\"start\":30852},{\"end\":31944,\"start\":31373},{\"end\":32306,\"start\":31958},{\"end\":32605,\"start\":32308},{\"end\":33772,\"start\":32607},{\"end\":34149,\"start\":33774},{\"end\":34619,\"start\":34151},{\"end\":35188,\"start\":34621},{\"end\":36110,\"start\":35190},{\"end\":37858,\"start\":36132},{\"end\":38241,\"start\":37860},{\"end\":38622,\"start\":38243},{\"end\":39193,\"start\":38645},{\"end\":39291,\"start\":39226},{\"end\":41065,\"start\":39293},{\"end\":42042,\"start\":41067},{\"end\":43229,\"start\":42071},{\"end\":43980,\"start\":43231},{\"end\":44941,\"start\":44014},{\"end\":45964,\"start\":44943},{\"end\":46829,\"start\":45966},{\"end\":47343,\"start\":46831},{\"end\":49105,\"start\":47345},{\"end\":50134,\"start\":49107},{\"end\":50489,\"start\":50136},{\"end\":50580,\"start\":50520},{\"end\":50987,\"start\":50582},{\"end\":51684,\"start\":50989},{\"end\":51929,\"start\":51686},{\"end\":52129,\"start\":51931},{\"end\":53142,\"start\":52144},{\"end\":53284,\"start\":53161},{\"end\":53492,\"start\":53304}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":11119,\"start\":11112},{\"end\":29256,\"start\":29249},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":32604,\"start\":32597},{\"end\":38083,\"start\":38076},{\"end\":39690,\"start\":39683},{\"end\":41516,\"start\":41509},{\"end\":42081,\"start\":42074}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2370,\"start\":2358},{\"attributes\":{\"n\":\"2\"},\"end\":8248,\"start\":8220},{\"attributes\":{\"n\":\"3\"},\"end\":9961,\"start\":9934},{\"attributes\":{\"n\":\"3.1\"},\"end\":10090,\"start\":10065},{\"attributes\":{\"n\":\"3.2\"},\"end\":14462,\"start\":14436},{\"attributes\":{\"n\":\"3.3\"},\"end\":16008,\"start\":15987},{\"attributes\":{\"n\":\"4\"},\"end\":18786,\"start\":18778},{\"attributes\":{\"n\":\"4.1\"},\"end\":19401,\"start\":19387},{\"attributes\":{\"n\":\"4.2\"},\"end\":21763,\"start\":21750},{\"attributes\":{\"n\":\"4.3\"},\"end\":24531,\"start\":24515},{\"attributes\":{\"n\":\"4.4\"},\"end\":25397,\"start\":25381},{\"attributes\":{\"n\":\"5\"},\"end\":25664,\"start\":25647},{\"attributes\":{\"n\":\"5.1\"},\"end\":25821,\"start\":25805},{\"attributes\":{\"n\":\"5.2\"},\"end\":28779,\"start\":28768},{\"attributes\":{\"n\":\"5.3\"},\"end\":30850,\"start\":30843},{\"attributes\":{\"n\":\"5.4\"},\"end\":31956,\"start\":31947},{\"attributes\":{\"n\":\"5.5\"},\"end\":36130,\"start\":36113},{\"attributes\":{\"n\":\"6\"},\"end\":38643,\"start\":38625},{\"attributes\":{\"n\":\"6.1\"},\"end\":39224,\"start\":39196},{\"attributes\":{\"n\":\"6.2\"},\"end\":42069,\"start\":42045},{\"attributes\":{\"n\":\"6.3\"},\"end\":44012,\"start\":43983},{\"attributes\":{\"n\":\"7\"},\"end\":50518,\"start\":50492},{\"attributes\":{\"n\":\"8\"},\"end\":52142,\"start\":52132},{\"attributes\":{\"n\":\"9\"},\"end\":53159,\"start\":53145},{\"attributes\":{\"n\":\"10\"},\"end\":53302,\"start\":53287},{\"end\":53504,\"start\":53494},{\"end\":54312,\"start\":54303}]", "table": "[{\"end\":54632,\"start\":54314}]", "figure_caption": "[{\"end\":53562,\"start\":53506},{\"end\":53700,\"start\":53565},{\"end\":53901,\"start\":53703},{\"end\":54301,\"start\":53904}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19442,\"start\":19434},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19624,\"start\":19616},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19972,\"start\":19964},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22415,\"start\":22407},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":23366,\"start\":23358},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":23764,\"start\":23756}]", "bib_author_first_name": "[{\"end\":54640,\"start\":54634},{\"end\":54654,\"start\":54648},{\"end\":54668,\"start\":54664},{\"end\":54683,\"start\":54677},{\"end\":54699,\"start\":54692},{\"end\":54711,\"start\":54706},{\"end\":54723,\"start\":54719},{\"end\":54725,\"start\":54724},{\"end\":54739,\"start\":54735},{\"end\":54749,\"start\":54747},{\"end\":54762,\"start\":54760},{\"end\":54781,\"start\":54775},{\"end\":54795,\"start\":54792},{\"end\":54814,\"start\":54808},{\"end\":54824,\"start\":54821},{\"end\":54828,\"start\":54825},{\"end\":54844,\"start\":54837},{\"end\":54860,\"start\":54852},{\"end\":54871,\"start\":54866},{\"end\":54890,\"start\":54884},{\"end\":54908,\"start\":54899},{\"end\":54921,\"start\":54917},{\"end\":56095,\"start\":56086},{\"end\":56111,\"start\":56107},{\"end\":56133,\"start\":56126},{\"end\":56375,\"start\":56372},{\"end\":56388,\"start\":56382},{\"end\":56400,\"start\":56396},{\"end\":56411,\"start\":56407},{\"end\":56815,\"start\":56810},{\"end\":56832,\"start\":56823},{\"end\":56846,\"start\":56839},{\"end\":56869,\"start\":56857},{\"end\":56885,\"start\":56877},{\"end\":57273,\"start\":57266},{\"end\":57293,\"start\":57284},{\"end\":57305,\"start\":57299},{\"end\":57553,\"start\":57548},{\"end\":57828,\"start\":57821},{\"end\":57842,\"start\":57835},{\"end\":57855,\"start\":57850},{\"end\":57870,\"start\":57864},{\"end\":58586,\"start\":58584},{\"end\":58600,\"start\":58593},{\"end\":58613,\"start\":58605},{\"end\":58615,\"start\":58614},{\"end\":58882,\"start\":58874},{\"end\":59036,\"start\":59035},{\"end\":59056,\"start\":59055},{\"end\":59074,\"start\":59066},{\"end\":59076,\"start\":59075},{\"end\":59521,\"start\":59517},{\"end\":59543,\"start\":59539},{\"end\":59557,\"start\":59553},{\"end\":59577,\"start\":59571},{\"end\":59955,\"start\":59948},{\"end\":59969,\"start\":59963},{\"end\":59971,\"start\":59970},{\"end\":60765,\"start\":60760},{\"end\":60778,\"start\":60773},{\"end\":60792,\"start\":60787},{\"end\":60794,\"start\":60793},{\"end\":61053,\"start\":61047},{\"end\":61062,\"start\":61061},{\"end\":61074,\"start\":61070},{\"end\":61481,\"start\":61480},{\"end\":61503,\"start\":61495},{\"end\":61505,\"start\":61504},{\"end\":61524,\"start\":61516},{\"end\":61895,\"start\":61888},{\"end\":61916,\"start\":61907},{\"end\":61932,\"start\":61928},{\"end\":62239,\"start\":62233},{\"end\":62256,\"start\":62249},{\"end\":62258,\"start\":62257},{\"end\":62787,\"start\":62781},{\"end\":62801,\"start\":62792},{\"end\":62810,\"start\":62806},{\"end\":62816,\"start\":62815},{\"end\":62818,\"start\":62817},{\"end\":63333,\"start\":63328},{\"end\":63347,\"start\":63342},{\"end\":63361,\"start\":63356},{\"end\":63377,\"start\":63370},{\"end\":63727,\"start\":63726},{\"end\":63737,\"start\":63736},{\"end\":64097,\"start\":64096},{\"end\":64116,\"start\":64107},{\"end\":64600,\"start\":64599},{\"end\":64602,\"start\":64601},{\"end\":64612,\"start\":64611},{\"end\":64621,\"start\":64620},{\"end\":64632,\"start\":64631},{\"end\":65045,\"start\":65041},{\"end\":65052,\"start\":65050},{\"end\":65060,\"start\":65057},{\"end\":65071,\"start\":65066},{\"end\":65079,\"start\":65076},{\"end\":65460,\"start\":65456},{\"end\":65467,\"start\":65465},{\"end\":65475,\"start\":65472},{\"end\":65486,\"start\":65481},{\"end\":65496,\"start\":65491},{\"end\":65504,\"start\":65501},{\"end\":65725,\"start\":65715},{\"end\":65739,\"start\":65732},{\"end\":65754,\"start\":65749},{\"end\":65770,\"start\":65763},{\"end\":66278,\"start\":66274},{\"end\":66623,\"start\":66616},{\"end\":67050,\"start\":67049},{\"end\":67061,\"start\":67060},{\"end\":67073,\"start\":67072},{\"end\":67536,\"start\":67527},{\"end\":67552,\"start\":67546},{\"end\":67566,\"start\":67560},{\"end\":68024,\"start\":68015},{\"end\":68040,\"start\":68034},{\"end\":68715,\"start\":68709},{\"end\":68728,\"start\":68723},{\"end\":68730,\"start\":68729},{\"end\":69015,\"start\":69007},{\"end\":69199,\"start\":69198},{\"end\":69208,\"start\":69207},{\"end\":69223,\"start\":69222},{\"end\":69233,\"start\":69232},{\"end\":69468,\"start\":69463},{\"end\":69483,\"start\":69477},{\"end\":69506,\"start\":69500},{\"end\":69753,\"start\":69745},{\"end\":69764,\"start\":69758},{\"end\":69773,\"start\":69771},{\"end\":69781,\"start\":69778},{\"end\":70281,\"start\":70280},{\"end\":70293,\"start\":70288},{\"end\":70310,\"start\":70304},{\"end\":70640,\"start\":70639},{\"end\":70653,\"start\":70647},{\"end\":70970,\"start\":70967},{\"end\":71290,\"start\":71285},{\"end\":71304,\"start\":71299},{\"end\":71560,\"start\":71555},{\"end\":71574,\"start\":71569},{\"end\":71593,\"start\":71583},{\"end\":71611,\"start\":71604},{\"end\":71624,\"start\":71620},{\"end\":71635,\"start\":71634},{\"end\":72047,\"start\":72042},{\"end\":72058,\"start\":72055},{\"end\":72065,\"start\":72063},{\"end\":72345,\"start\":72344},{\"end\":72361,\"start\":72352},{\"end\":72665,\"start\":72658},{\"end\":72681,\"start\":72676},{\"end\":72694,\"start\":72690},{\"end\":72709,\"start\":72701},{\"end\":73274,\"start\":73269},{\"end\":73291,\"start\":73286},{\"end\":73298,\"start\":73297},{\"end\":73311,\"start\":73305},{\"end\":73662,\"start\":73656},{\"end\":73677,\"start\":73670},{\"end\":73692,\"start\":73686},{\"end\":73707,\"start\":73702},{\"end\":74206,\"start\":74200},{\"end\":74223,\"start\":74216},{\"end\":74235,\"start\":74230},{\"end\":74237,\"start\":74236},{\"end\":74252,\"start\":74246},{\"end\":74627,\"start\":74619},{\"end\":74647,\"start\":74635},{\"end\":74956,\"start\":74953},{\"end\":74965,\"start\":74962},{\"end\":74976,\"start\":74973},{\"end\":74989,\"start\":74982},{\"end\":75882,\"start\":75875},{\"end\":75896,\"start\":75889},{\"end\":75904,\"start\":75902},{\"end\":75917,\"start\":75911},{\"end\":76176,\"start\":76166},{\"end\":76192,\"start\":76187},{\"end\":76204,\"start\":76199},{\"end\":76220,\"start\":76216},{\"end\":76752,\"start\":76742},{\"end\":76767,\"start\":76763},{\"end\":76778,\"start\":76777},{\"end\":77205,\"start\":77201},{\"end\":77222,\"start\":77217},{\"end\":77241,\"start\":77232},{\"end\":77631,\"start\":77627},{\"end\":77648,\"start\":77643},{\"end\":77954,\"start\":77945},{\"end\":77976,\"start\":77971},{\"end\":78143,\"start\":78134},{\"end\":78168,\"start\":78162},{\"end\":78185,\"start\":78176},{\"end\":78200,\"start\":78194},{\"end\":78668,\"start\":78665},{\"end\":78678,\"start\":78674},{\"end\":78688,\"start\":78685},{\"end\":78703,\"start\":78695},{\"end\":78715,\"start\":78708},{\"end\":78726,\"start\":78722},{\"end\":78737,\"start\":78731},{\"end\":78739,\"start\":78738},{\"end\":79433,\"start\":79426},{\"end\":79444,\"start\":79438},{\"end\":79457,\"start\":79450},{\"end\":79471,\"start\":79464},{\"end\":79485,\"start\":79478},{\"end\":79499,\"start\":79493},{\"end\":79501,\"start\":79500},{\"end\":79835,\"start\":79832},{\"end\":79847,\"start\":79840},{\"end\":79858,\"start\":79852},{\"end\":79872,\"start\":79865},{\"end\":79886,\"start\":79879},{\"end\":79902,\"start\":79897},{\"end\":80239,\"start\":80236},{\"end\":80251,\"start\":80244},{\"end\":80262,\"start\":80256},{\"end\":80271,\"start\":80269},{\"end\":80281,\"start\":80276},{\"end\":80293,\"start\":80288}]", "bib_author_last_name": "[{\"end\":54646,\"start\":54641},{\"end\":54662,\"start\":54655},{\"end\":54675,\"start\":54669},{\"end\":54690,\"start\":54684},{\"end\":54704,\"start\":54700},{\"end\":54717,\"start\":54712},{\"end\":54733,\"start\":54726},{\"end\":54745,\"start\":54740},{\"end\":54758,\"start\":54750},{\"end\":54773,\"start\":54763},{\"end\":54790,\"start\":54782},{\"end\":54806,\"start\":54796},{\"end\":54819,\"start\":54815},{\"end\":54835,\"start\":54829},{\"end\":54850,\"start\":54845},{\"end\":54864,\"start\":54861},{\"end\":54882,\"start\":54872},{\"end\":54897,\"start\":54891},{\"end\":54915,\"start\":54909},{\"end\":54931,\"start\":54922},{\"end\":56105,\"start\":56096},{\"end\":56124,\"start\":56112},{\"end\":56141,\"start\":56134},{\"end\":56380,\"start\":56376},{\"end\":56394,\"start\":56389},{\"end\":56405,\"start\":56401},{\"end\":56417,\"start\":56412},{\"end\":56821,\"start\":56816},{\"end\":56837,\"start\":56833},{\"end\":56855,\"start\":56847},{\"end\":56875,\"start\":56870},{\"end\":56891,\"start\":56886},{\"end\":57282,\"start\":57274},{\"end\":57297,\"start\":57294},{\"end\":57312,\"start\":57306},{\"end\":57561,\"start\":57554},{\"end\":57833,\"start\":57829},{\"end\":57848,\"start\":57843},{\"end\":57862,\"start\":57856},{\"end\":57875,\"start\":57871},{\"end\":58591,\"start\":58587},{\"end\":58603,\"start\":58601},{\"end\":58620,\"start\":58616},{\"end\":58890,\"start\":58883},{\"end\":59044,\"start\":59037},{\"end\":59053,\"start\":59046},{\"end\":59064,\"start\":59057},{\"end\":59083,\"start\":59077},{\"end\":59092,\"start\":59085},{\"end\":59537,\"start\":59522},{\"end\":59551,\"start\":59544},{\"end\":59569,\"start\":59558},{\"end\":59584,\"start\":59578},{\"end\":59593,\"start\":59586},{\"end\":59946,\"start\":59926},{\"end\":59961,\"start\":59956},{\"end\":59980,\"start\":59972},{\"end\":59993,\"start\":59982},{\"end\":60771,\"start\":60766},{\"end\":60785,\"start\":60779},{\"end\":60801,\"start\":60795},{\"end\":61059,\"start\":61054},{\"end\":61068,\"start\":61063},{\"end\":61078,\"start\":61075},{\"end\":61487,\"start\":61482},{\"end\":61493,\"start\":61489},{\"end\":61514,\"start\":61506},{\"end\":61528,\"start\":61525},{\"end\":61536,\"start\":61530},{\"end\":61905,\"start\":61896},{\"end\":61926,\"start\":61917},{\"end\":61945,\"start\":61933},{\"end\":62247,\"start\":62240},{\"end\":62269,\"start\":62259},{\"end\":62790,\"start\":62788},{\"end\":62804,\"start\":62802},{\"end\":62813,\"start\":62811},{\"end\":62825,\"start\":62819},{\"end\":62829,\"start\":62827},{\"end\":63340,\"start\":63334},{\"end\":63354,\"start\":63348},{\"end\":63368,\"start\":63362},{\"end\":63384,\"start\":63378},{\"end\":63734,\"start\":63728},{\"end\":63744,\"start\":63738},{\"end\":64105,\"start\":64098},{\"end\":64128,\"start\":64117},{\"end\":64137,\"start\":64130},{\"end\":64609,\"start\":64603},{\"end\":64618,\"start\":64613},{\"end\":64629,\"start\":64622},{\"end\":64646,\"start\":64633},{\"end\":65048,\"start\":65046},{\"end\":65055,\"start\":65053},{\"end\":65064,\"start\":65061},{\"end\":65074,\"start\":65072},{\"end\":65083,\"start\":65080},{\"end\":65463,\"start\":65461},{\"end\":65470,\"start\":65468},{\"end\":65479,\"start\":65476},{\"end\":65489,\"start\":65487},{\"end\":65499,\"start\":65497},{\"end\":65508,\"start\":65505},{\"end\":65730,\"start\":65726},{\"end\":65747,\"start\":65740},{\"end\":65761,\"start\":65755},{\"end\":65778,\"start\":65771},{\"end\":66292,\"start\":66279},{\"end\":66630,\"start\":66624},{\"end\":67058,\"start\":67051},{\"end\":67070,\"start\":67062},{\"end\":67082,\"start\":67074},{\"end\":67544,\"start\":67537},{\"end\":67558,\"start\":67553},{\"end\":67575,\"start\":67567},{\"end\":68032,\"start\":68025},{\"end\":68049,\"start\":68041},{\"end\":68721,\"start\":68716},{\"end\":68734,\"start\":68731},{\"end\":69019,\"start\":69016},{\"end\":69205,\"start\":69200},{\"end\":69220,\"start\":69209},{\"end\":69230,\"start\":69224},{\"end\":69239,\"start\":69234},{\"end\":69475,\"start\":69469},{\"end\":69498,\"start\":69484},{\"end\":69513,\"start\":69507},{\"end\":69756,\"start\":69754},{\"end\":69769,\"start\":69765},{\"end\":69776,\"start\":69774},{\"end\":69785,\"start\":69782},{\"end\":70286,\"start\":70282},{\"end\":70302,\"start\":70294},{\"end\":70314,\"start\":70311},{\"end\":70324,\"start\":70316},{\"end\":70645,\"start\":70641},{\"end\":70662,\"start\":70654},{\"end\":70672,\"start\":70664},{\"end\":70977,\"start\":70971},{\"end\":71297,\"start\":71291},{\"end\":71311,\"start\":71305},{\"end\":71567,\"start\":71561},{\"end\":71581,\"start\":71575},{\"end\":71602,\"start\":71594},{\"end\":71618,\"start\":71612},{\"end\":71632,\"start\":71625},{\"end\":71649,\"start\":71636},{\"end\":72053,\"start\":72048},{\"end\":72061,\"start\":72059},{\"end\":72071,\"start\":72066},{\"end\":72350,\"start\":72346},{\"end\":72371,\"start\":72362},{\"end\":72380,\"start\":72373},{\"end\":72674,\"start\":72666},{\"end\":72688,\"start\":72682},{\"end\":72699,\"start\":72695},{\"end\":72713,\"start\":72710},{\"end\":73284,\"start\":73275},{\"end\":73295,\"start\":73292},{\"end\":73303,\"start\":73299},{\"end\":73320,\"start\":73312},{\"end\":73330,\"start\":73322},{\"end\":73668,\"start\":73663},{\"end\":73684,\"start\":73678},{\"end\":73700,\"start\":73693},{\"end\":73714,\"start\":73708},{\"end\":74214,\"start\":74207},{\"end\":74228,\"start\":74224},{\"end\":74244,\"start\":74238},{\"end\":74259,\"start\":74253},{\"end\":74633,\"start\":74628},{\"end\":74655,\"start\":74648},{\"end\":74663,\"start\":74657},{\"end\":74960,\"start\":74957},{\"end\":74971,\"start\":74966},{\"end\":74980,\"start\":74977},{\"end\":74992,\"start\":74990},{\"end\":75887,\"start\":75883},{\"end\":75900,\"start\":75897},{\"end\":75909,\"start\":75905},{\"end\":75921,\"start\":75918},{\"end\":76185,\"start\":76177},{\"end\":76197,\"start\":76193},{\"end\":76214,\"start\":76205},{\"end\":76228,\"start\":76221},{\"end\":76243,\"start\":76230},{\"end\":76761,\"start\":76753},{\"end\":76775,\"start\":76768},{\"end\":76792,\"start\":76779},{\"end\":77215,\"start\":77206},{\"end\":77230,\"start\":77223},{\"end\":77248,\"start\":77242},{\"end\":77641,\"start\":77632},{\"end\":77656,\"start\":77649},{\"end\":77660,\"start\":77658},{\"end\":77969,\"start\":77955},{\"end\":77981,\"start\":77977},{\"end\":78160,\"start\":78144},{\"end\":78174,\"start\":78169},{\"end\":78192,\"start\":78186},{\"end\":78210,\"start\":78201},{\"end\":78221,\"start\":78212},{\"end\":78672,\"start\":78669},{\"end\":78683,\"start\":78679},{\"end\":78693,\"start\":78689},{\"end\":78706,\"start\":78704},{\"end\":78720,\"start\":78716},{\"end\":78729,\"start\":78727},{\"end\":78742,\"start\":78740},{\"end\":79436,\"start\":79434},{\"end\":79448,\"start\":79445},{\"end\":79462,\"start\":79458},{\"end\":79476,\"start\":79472},{\"end\":79491,\"start\":79486},{\"end\":79504,\"start\":79502},{\"end\":79838,\"start\":79836},{\"end\":79850,\"start\":79848},{\"end\":79863,\"start\":79859},{\"end\":79877,\"start\":79873},{\"end\":79895,\"start\":79887},{\"end\":79910,\"start\":79903},{\"end\":80242,\"start\":80240},{\"end\":80254,\"start\":80252},{\"end\":80267,\"start\":80263},{\"end\":80274,\"start\":80272},{\"end\":80286,\"start\":80282},{\"end\":80301,\"start\":80294}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":56040,\"start\":54634},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":3495200},\"end\":56370,\"start\":56042},{\"attributes\":{\"id\":\"b2\"},\"end\":56725,\"start\":56372},{\"attributes\":{\"doi\":\"10.1371/journal.pone.0181142\",\"id\":\"b3\",\"matched_paper_id\":2479906},\"end\":57193,\"start\":56727},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b4\"},\"end\":57512,\"start\":57195},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":3720634},\"end\":57742,\"start\":57514},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1177\",\"id\":\"b6\",\"matched_paper_id\":3504277},\"end\":58496,\"start\":57744},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":199577786},\"end\":58870,\"start\":58498},{\"attributes\":{\"id\":\"b8\"},\"end\":58962,\"start\":58872},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":9459633},\"end\":59444,\"start\":58964},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":16125167},\"end\":59861,\"start\":59446},{\"attributes\":{\"doi\":\"10.1145/1085313.1085331\",\"id\":\"b11\",\"matched_paper_id\":9333486},\"end\":60679,\"start\":59863},{\"attributes\":{\"doi\":\"arXiv:1710.00794\",\"id\":\"b12\"},\"end\":61045,\"start\":60681},{\"attributes\":{\"id\":\"b13\"},\"end\":61402,\"start\":61047},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":12442030},\"end\":61853,\"start\":61404},{\"attributes\":{\"id\":\"b15\"},\"end\":62159,\"start\":61855},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":8033761},\"end\":62713,\"start\":62161},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":8174613},\"end\":63013,\"start\":62715},{\"attributes\":{\"id\":\"b18\"},\"end\":63243,\"start\":63015},{\"attributes\":{\"id\":\"b19\"},\"end\":63536,\"start\":63245},{\"attributes\":{\"id\":\"b20\"},\"end\":63681,\"start\":63538},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":2242673},\"end\":64027,\"start\":63683},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":21164835},\"end\":64506,\"start\":64029},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":12839714},\"end\":65009,\"start\":64508},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":49584534},\"end\":65398,\"start\":65011},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":49584957},\"end\":65658,\"start\":65400},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":8820379},\"end\":66206,\"start\":65660},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":14585311},\"end\":66544,\"start\":66208},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":30353027},\"end\":66975,\"start\":66546},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":46939411},\"end\":67444,\"start\":66977},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":59606259},\"end\":67953,\"start\":67446},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":102354583},\"end\":68640,\"start\":67955},{\"attributes\":{\"id\":\"b32\"},\"end\":68949,\"start\":68642},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":964287},\"end\":69169,\"start\":68951},{\"attributes\":{\"id\":\"b34\"},\"end\":69368,\"start\":69171},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":17355},\"end\":69684,\"start\":69370},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":203186110},\"end\":70196,\"start\":69686},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":18292711},\"end\":70572,\"start\":70198},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":17406565},\"end\":70891,\"start\":70574},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":36024272},\"end\":71218,\"start\":70893},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":4861489},\"end\":71484,\"start\":71220},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":1129667},\"end\":71988,\"start\":71486},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":7418692},\"end\":72277,\"start\":71990},{\"attributes\":{\"id\":\"b43\"},\"end\":72592,\"start\":72279},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":11080756},\"end\":73179,\"start\":72594},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":13109013},\"end\":73603,\"start\":73181},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":9956794},\"end\":74198,\"start\":73605},{\"attributes\":{\"id\":\"b47\"},\"end\":74515,\"start\":74200},{\"attributes\":{\"id\":\"b48\"},\"end\":74897,\"start\":74517},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":16916939},\"end\":75788,\"start\":74899},{\"attributes\":{\"id\":\"b50\"},\"end\":76096,\"start\":75790},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":9790585},\"end\":76666,\"start\":76098},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":11106352},\"end\":77151,\"start\":76668},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":8843166},\"end\":77573,\"start\":77153},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":7961699},\"end\":77879,\"start\":77575},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":1682648},\"end\":78132,\"start\":77881},{\"attributes\":{\"id\":\"b56\"},\"end\":78584,\"start\":78134},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":52069701},\"end\":79375,\"start\":78586},{\"attributes\":{\"id\":\"b58\"},\"end\":79755,\"start\":79377},{\"attributes\":{\"id\":\"b59\"},\"end\":80146,\"start\":79757},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":52074926},\"end\":80604,\"start\":80148}]", "bib_title": "[{\"end\":56084,\"start\":56042},{\"end\":56808,\"start\":56727},{\"end\":57546,\"start\":57514},{\"end\":57819,\"start\":57744},{\"end\":58582,\"start\":58498},{\"end\":59033,\"start\":58964},{\"end\":59515,\"start\":59446},{\"end\":59924,\"start\":59863},{\"end\":61478,\"start\":61404},{\"end\":62231,\"start\":62161},{\"end\":62779,\"start\":62715},{\"end\":63724,\"start\":63683},{\"end\":64094,\"start\":64029},{\"end\":64597,\"start\":64508},{\"end\":65039,\"start\":65011},{\"end\":65454,\"start\":65400},{\"end\":65713,\"start\":65660},{\"end\":66272,\"start\":66208},{\"end\":66614,\"start\":66546},{\"end\":67047,\"start\":66977},{\"end\":67525,\"start\":67446},{\"end\":68013,\"start\":67955},{\"end\":69005,\"start\":68951},{\"end\":69461,\"start\":69370},{\"end\":69743,\"start\":69686},{\"end\":70278,\"start\":70198},{\"end\":70637,\"start\":70574},{\"end\":70965,\"start\":70893},{\"end\":71283,\"start\":71220},{\"end\":71553,\"start\":71486},{\"end\":72040,\"start\":71990},{\"end\":72342,\"start\":72279},{\"end\":72656,\"start\":72594},{\"end\":73267,\"start\":73181},{\"end\":73654,\"start\":73605},{\"end\":74951,\"start\":74899},{\"end\":76164,\"start\":76098},{\"end\":76740,\"start\":76668},{\"end\":77199,\"start\":77153},{\"end\":77625,\"start\":77575},{\"end\":77943,\"start\":77881},{\"end\":78663,\"start\":78586},{\"end\":80234,\"start\":80148}]", "bib_author": "[{\"end\":54648,\"start\":54634},{\"end\":54664,\"start\":54648},{\"end\":54677,\"start\":54664},{\"end\":54692,\"start\":54677},{\"end\":54706,\"start\":54692},{\"end\":54719,\"start\":54706},{\"end\":54735,\"start\":54719},{\"end\":54747,\"start\":54735},{\"end\":54760,\"start\":54747},{\"end\":54775,\"start\":54760},{\"end\":54792,\"start\":54775},{\"end\":54808,\"start\":54792},{\"end\":54821,\"start\":54808},{\"end\":54837,\"start\":54821},{\"end\":54852,\"start\":54837},{\"end\":54866,\"start\":54852},{\"end\":54884,\"start\":54866},{\"end\":54899,\"start\":54884},{\"end\":54917,\"start\":54899},{\"end\":54933,\"start\":54917},{\"end\":56107,\"start\":56086},{\"end\":56126,\"start\":56107},{\"end\":56143,\"start\":56126},{\"end\":56382,\"start\":56372},{\"end\":56396,\"start\":56382},{\"end\":56407,\"start\":56396},{\"end\":56419,\"start\":56407},{\"end\":56823,\"start\":56810},{\"end\":56839,\"start\":56823},{\"end\":56857,\"start\":56839},{\"end\":56877,\"start\":56857},{\"end\":56893,\"start\":56877},{\"end\":57284,\"start\":57266},{\"end\":57299,\"start\":57284},{\"end\":57314,\"start\":57299},{\"end\":57563,\"start\":57548},{\"end\":57835,\"start\":57821},{\"end\":57850,\"start\":57835},{\"end\":57864,\"start\":57850},{\"end\":57877,\"start\":57864},{\"end\":58593,\"start\":58584},{\"end\":58605,\"start\":58593},{\"end\":58622,\"start\":58605},{\"end\":58892,\"start\":58874},{\"end\":59046,\"start\":59035},{\"end\":59055,\"start\":59046},{\"end\":59066,\"start\":59055},{\"end\":59085,\"start\":59066},{\"end\":59094,\"start\":59085},{\"end\":59539,\"start\":59517},{\"end\":59553,\"start\":59539},{\"end\":59571,\"start\":59553},{\"end\":59586,\"start\":59571},{\"end\":59595,\"start\":59586},{\"end\":59948,\"start\":59926},{\"end\":59963,\"start\":59948},{\"end\":59982,\"start\":59963},{\"end\":59995,\"start\":59982},{\"end\":60773,\"start\":60760},{\"end\":60787,\"start\":60773},{\"end\":60803,\"start\":60787},{\"end\":61061,\"start\":61047},{\"end\":61070,\"start\":61061},{\"end\":61080,\"start\":61070},{\"end\":61489,\"start\":61480},{\"end\":61495,\"start\":61489},{\"end\":61516,\"start\":61495},{\"end\":61530,\"start\":61516},{\"end\":61538,\"start\":61530},{\"end\":61907,\"start\":61888},{\"end\":61928,\"start\":61907},{\"end\":61947,\"start\":61928},{\"end\":62249,\"start\":62233},{\"end\":62271,\"start\":62249},{\"end\":62792,\"start\":62781},{\"end\":62806,\"start\":62792},{\"end\":62815,\"start\":62806},{\"end\":62827,\"start\":62815},{\"end\":62831,\"start\":62827},{\"end\":63342,\"start\":63328},{\"end\":63356,\"start\":63342},{\"end\":63370,\"start\":63356},{\"end\":63386,\"start\":63370},{\"end\":63736,\"start\":63726},{\"end\":63746,\"start\":63736},{\"end\":64107,\"start\":64096},{\"end\":64130,\"start\":64107},{\"end\":64139,\"start\":64130},{\"end\":64611,\"start\":64599},{\"end\":64620,\"start\":64611},{\"end\":64631,\"start\":64620},{\"end\":64648,\"start\":64631},{\"end\":65050,\"start\":65041},{\"end\":65057,\"start\":65050},{\"end\":65066,\"start\":65057},{\"end\":65076,\"start\":65066},{\"end\":65085,\"start\":65076},{\"end\":65465,\"start\":65456},{\"end\":65472,\"start\":65465},{\"end\":65481,\"start\":65472},{\"end\":65491,\"start\":65481},{\"end\":65501,\"start\":65491},{\"end\":65510,\"start\":65501},{\"end\":65732,\"start\":65715},{\"end\":65749,\"start\":65732},{\"end\":65763,\"start\":65749},{\"end\":65780,\"start\":65763},{\"end\":66294,\"start\":66274},{\"end\":66632,\"start\":66616},{\"end\":67060,\"start\":67049},{\"end\":67072,\"start\":67060},{\"end\":67084,\"start\":67072},{\"end\":67546,\"start\":67527},{\"end\":67560,\"start\":67546},{\"end\":67577,\"start\":67560},{\"end\":68034,\"start\":68015},{\"end\":68051,\"start\":68034},{\"end\":68723,\"start\":68709},{\"end\":68736,\"start\":68723},{\"end\":69021,\"start\":69007},{\"end\":69207,\"start\":69198},{\"end\":69222,\"start\":69207},{\"end\":69232,\"start\":69222},{\"end\":69241,\"start\":69232},{\"end\":69477,\"start\":69463},{\"end\":69500,\"start\":69477},{\"end\":69515,\"start\":69500},{\"end\":69758,\"start\":69745},{\"end\":69771,\"start\":69758},{\"end\":69778,\"start\":69771},{\"end\":69787,\"start\":69778},{\"end\":70288,\"start\":70280},{\"end\":70304,\"start\":70288},{\"end\":70316,\"start\":70304},{\"end\":70326,\"start\":70316},{\"end\":70647,\"start\":70639},{\"end\":70664,\"start\":70647},{\"end\":70674,\"start\":70664},{\"end\":70979,\"start\":70967},{\"end\":71299,\"start\":71285},{\"end\":71313,\"start\":71299},{\"end\":71569,\"start\":71555},{\"end\":71583,\"start\":71569},{\"end\":71604,\"start\":71583},{\"end\":71620,\"start\":71604},{\"end\":71634,\"start\":71620},{\"end\":71651,\"start\":71634},{\"end\":72055,\"start\":72042},{\"end\":72063,\"start\":72055},{\"end\":72073,\"start\":72063},{\"end\":72352,\"start\":72344},{\"end\":72373,\"start\":72352},{\"end\":72382,\"start\":72373},{\"end\":72676,\"start\":72658},{\"end\":72690,\"start\":72676},{\"end\":72701,\"start\":72690},{\"end\":72715,\"start\":72701},{\"end\":73286,\"start\":73269},{\"end\":73297,\"start\":73286},{\"end\":73305,\"start\":73297},{\"end\":73322,\"start\":73305},{\"end\":73332,\"start\":73322},{\"end\":73670,\"start\":73656},{\"end\":73686,\"start\":73670},{\"end\":73702,\"start\":73686},{\"end\":73716,\"start\":73702},{\"end\":74216,\"start\":74200},{\"end\":74230,\"start\":74216},{\"end\":74246,\"start\":74230},{\"end\":74261,\"start\":74246},{\"end\":74635,\"start\":74619},{\"end\":74657,\"start\":74635},{\"end\":74665,\"start\":74657},{\"end\":74962,\"start\":74953},{\"end\":74973,\"start\":74962},{\"end\":74982,\"start\":74973},{\"end\":74994,\"start\":74982},{\"end\":75889,\"start\":75875},{\"end\":75902,\"start\":75889},{\"end\":75911,\"start\":75902},{\"end\":75923,\"start\":75911},{\"end\":76187,\"start\":76166},{\"end\":76199,\"start\":76187},{\"end\":76216,\"start\":76199},{\"end\":76230,\"start\":76216},{\"end\":76245,\"start\":76230},{\"end\":76763,\"start\":76742},{\"end\":76777,\"start\":76763},{\"end\":76794,\"start\":76777},{\"end\":77217,\"start\":77201},{\"end\":77232,\"start\":77217},{\"end\":77250,\"start\":77232},{\"end\":77643,\"start\":77627},{\"end\":77658,\"start\":77643},{\"end\":77662,\"start\":77658},{\"end\":77971,\"start\":77945},{\"end\":77983,\"start\":77971},{\"end\":78162,\"start\":78134},{\"end\":78176,\"start\":78162},{\"end\":78194,\"start\":78176},{\"end\":78212,\"start\":78194},{\"end\":78223,\"start\":78212},{\"end\":78674,\"start\":78665},{\"end\":78685,\"start\":78674},{\"end\":78695,\"start\":78685},{\"end\":78708,\"start\":78695},{\"end\":78722,\"start\":78708},{\"end\":78731,\"start\":78722},{\"end\":78744,\"start\":78731},{\"end\":79438,\"start\":79426},{\"end\":79450,\"start\":79438},{\"end\":79464,\"start\":79450},{\"end\":79478,\"start\":79464},{\"end\":79493,\"start\":79478},{\"end\":79506,\"start\":79493},{\"end\":79840,\"start\":79832},{\"end\":79852,\"start\":79840},{\"end\":79865,\"start\":79852},{\"end\":79879,\"start\":79865},{\"end\":79897,\"start\":79879},{\"end\":79912,\"start\":79897},{\"end\":80244,\"start\":80236},{\"end\":80256,\"start\":80244},{\"end\":80269,\"start\":80256},{\"end\":80276,\"start\":80269},{\"end\":80288,\"start\":80276},{\"end\":80303,\"start\":80288}]", "bib_venue": "[{\"end\":55299,\"start\":55168},{\"end\":58075,\"start\":57986},{\"end\":60314,\"start\":60166},{\"end\":62444,\"start\":62368},{\"end\":62864,\"start\":62856},{\"end\":64286,\"start\":64221},{\"end\":65218,\"start\":65160},{\"end\":65941,\"start\":65869},{\"end\":66781,\"start\":66715},{\"end\":67706,\"start\":67650},{\"end\":68322,\"start\":68195},{\"end\":69917,\"start\":69897},{\"end\":72868,\"start\":72800},{\"end\":73886,\"start\":73800},{\"end\":75379,\"start\":75186},{\"end\":76402,\"start\":76332},{\"end\":76923,\"start\":76867},{\"end\":77373,\"start\":77320},{\"end\":78951,\"start\":78859},{\"end\":54998,\"start\":54933},{\"end\":56195,\"start\":56143},{\"end\":56533,\"start\":56419},{\"end\":56929,\"start\":56921},{\"end\":57264,\"start\":57195},{\"end\":57615,\"start\":57563},{\"end\":57984,\"start\":57897},{\"end\":58674,\"start\":58622},{\"end\":59145,\"start\":59094},{\"end\":59635,\"start\":59595},{\"end\":60164,\"start\":60018},{\"end\":60758,\"start\":60681},{\"end\":61196,\"start\":61120},{\"end\":61581,\"start\":61538},{\"end\":61886,\"start\":61855},{\"end\":62366,\"start\":62292},{\"end\":62854,\"start\":62831},{\"end\":63098,\"start\":63035},{\"end\":63326,\"start\":63245},{\"end\":63603,\"start\":63538},{\"end\":63841,\"start\":63746},{\"end\":64219,\"start\":64139},{\"end\":64732,\"start\":64672},{\"end\":65158,\"start\":65085},{\"end\":65515,\"start\":65510},{\"end\":65867,\"start\":65780},{\"end\":66348,\"start\":66328},{\"end\":66713,\"start\":66632},{\"end\":67187,\"start\":67108},{\"end\":67648,\"start\":67577},{\"end\":68193,\"start\":68051},{\"end\":68707,\"start\":68642},{\"end\":69052,\"start\":69021},{\"end\":69196,\"start\":69171},{\"end\":69518,\"start\":69515},{\"end\":69843,\"start\":69787},{\"end\":70367,\"start\":70326},{\"end\":70714,\"start\":70674},{\"end\":71035,\"start\":71013},{\"end\":71336,\"start\":71313},{\"end\":71694,\"start\":71651},{\"end\":72115,\"start\":72073},{\"end\":72419,\"start\":72382},{\"end\":72798,\"start\":72715},{\"end\":73372,\"start\":73332},{\"end\":73798,\"start\":73716},{\"end\":74350,\"start\":74283},{\"end\":74617,\"start\":74517},{\"end\":75184,\"start\":74994},{\"end\":75873,\"start\":75790},{\"end\":76330,\"start\":76245},{\"end\":76865,\"start\":76794},{\"end\":77318,\"start\":77250},{\"end\":77711,\"start\":77662},{\"end\":77991,\"start\":77983},{\"end\":78351,\"start\":78247},{\"end\":78857,\"start\":78767},{\"end\":79424,\"start\":79377},{\"end\":79830,\"start\":79757},{\"end\":80365,\"start\":80303}]"}}}, "year": 2023, "month": 12, "day": 17}