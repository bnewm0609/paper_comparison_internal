{"id": 244270763, "updated": "2023-10-05 19:56:30.545", "metadata": {"title": "Differentially Private Federated Learning on Heterogeneous Data", "authors": "[{\"first\":\"Maxence\",\"last\":\"Noble\",\"middle\":[]},{\"first\":\"Aur'elien\",\"last\":\"Bellet\",\"middle\":[]},{\"first\":\"Aymeric\",\"last\":\"Dieuleveut\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Federated Learning (FL) is a paradigm for large-scale distributed learning which faces two key challenges: (i) efficient training from highly heterogeneous user data, and (ii) protecting the privacy of participating users. In this work, we propose a novel FL approach (DP-SCAFFOLD) to tackle these two challenges together by incorporating Differential Privacy (DP) constraints into the popular SCAFFOLD algorithm. We focus on the challenging setting where users communicate with a\"honest-but-curious\"server without any trusted intermediary, which requires to ensure privacy not only towards a third-party with access to the final model but also towards the server who observes all user communications. Using advanced results from DP theory, we establish the convergence of our algorithm for convex and non-convex objectives. Our analysis clearly highlights the privacy-utility trade-off under data heterogeneity, and demonstrates the superiority of DP-SCAFFOLD over the state-of-the-art algorithm DP-FedAvg when the number of local updates and the level of heterogeneity grow. Our numerical results confirm our analysis and show that DP-SCAFFOLD provides significant gains in practice.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2111.09278", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aistats/NobleBD22", "doi": null}}, "content": {"source": {"pdf_hash": "55b5afd8bdea06dc3512ce2ee73d2e83565ca4d6", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2111.09278v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "760f38c3f6891627c01a19a8aea601b1f27f6c53", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/55b5afd8bdea06dc3512ce2ee73d2e83565ca4d6.txt", "contents": "\nDifferentially Private Federated Learning on Heterogeneous Data\n\n\nMaxence Noble \nAur\u00e9lien Bellet \n\nAymeric Dieuleveut Centre de Math\u00e9matiques Appliqu\u00e9es Ecole Polytechnique\nInstitut Polytechnique de Paris Univ. Lille\nInriaFrance\n\n\nCentre de Math\u00e9matiques Appliqu\u00e9es Ecole Polytechnique\nCNRS\nCentrale Lille\nUMR 9189 -CRIStALF-59000LilleFrance, France\n\n\nInstitut Polytechnique de Paris\n\n\nDifferentially Private Federated Learning on Heterogeneous Data\n\nFederated Learning (FL) is a paradigm for large-scale distributed learning which faces two key challenges: (i) training efficiently from highly heterogeneous user data, and (ii) protecting the privacy of participating users. In this work, we propose a novel FL approach (DP-SCAFFOLD) to tackle these two challenges together by incorporating Differential Privacy (DP) constraints into the popular SCAFFOLD algorithm. We focus on the challenging setting where users communicate with a \"honest-but-curious\" server without any trusted intermediary, which requires to ensure privacy not only towards a third party observing the final model but also towards the server itself. Using advanced results from DP theory and optimization, we establish the convergence of our algorithm for convex and non-convex objectives. Our paper clearly highlights the trade-off between utility and privacy and demonstrates the superiority of DP-SCAFFOLD over the state-ofthe-art algorithm DP-FedAvg when the number of local updates and the level of heterogeneity grows. Our numerical results confirm our analysis and show that DP-SCAFFOLD provides significant gains in practice.Definition 2.1 (Differential Privacy, Dwork and Roth, 2014). Let , \u03b4 > 0. A randomized algorithm A : X n \u2192 Y is ( , \u03b4)-DP if for all pairs of neighboring datasets D, D and every subset S \u2282 Y, we have:The privacy level is controlled by the parameters and \u03b4 (the lower, the more private). A standard building block to design DP algorithms is the Gaussian mech-The complete pseudo-code is given in Algorithm 1. Subsampling steps, which amplify privacy (Kasiviswanathan et al., 2011), are highlighted in red, and steps specifically related to DP are highlighted in yellow. Setting \u03c3 g = 0 and C = \u221e recovers the classical SCAFFOLD algorithm, and removing control variates (i.e., setting c t i to 0 for all t \u2208 [T ], i \u2208 [M ]) recovers DP-FedAvg, which we describe in Appendix A (Algorithm 2) for completeness.Intuition for control variates. In SCAFFOLD, the local control variate c i converges to the local gradient \u2207f i (x * ) at the optimal, while c approximates 1 M M i=1 c i (Karimireddy et al., 2020b, Appendix E). Therefore, adding (c \u2212 c i ) in the update balances the local stochastic gradient and limits user-drift. Warm-start version of DP-SCAFFOLD. We adapt the warm-start strategy from Karimireddy et al. (2020b, Maxence Noble, Aur\u00e9lien Bellet, Aymeric DieuleveutAppendix E) to accommodate DP constraints, leading to DP-SCAFFOLD-warm. The first few rounds of communication are saved to set 2 the initial values of the control variates tok i (x 0 ) (perturbed by DP-noise), without updating the global model. Note that as we leverage user sampling in the privacy analysis, the server cannot communicate with all users at a single round and the users have to be randomly picked to ensure privacy. We prove the convergence of DP-SCAFFOLD-warm in Section 4.2 (assuming that every user participated to the warm-start phase). Our experiments in Section 5 are conducted with this version of DP-SCAFFOLD.User-level privacy. Our framework can easily be adapted to user-level privacy, by setting S = 2C/s.THEORETICAL ANALYSISWe first provide the analysis of the privacy level in Section 4.1, then analyze utility in Section 4.2.PrivacyWe first establish that the setting of our algorithms DP-SCAFFOLD and DP-FedAvg enables a fair comparison in terms of privacy.Claim 4.1. For a given noise scale \u03c3 g > 0, x t has the same level of privacy at any round t \u2208 [T ] in DP-SCAFFOLD(-warm) and DP-FedAvg after the server aggregation. lected Areas in Information Theory, 2(1): 464-478,  2021b. federated learning with differential privacy. IEEE Internet of Things Journal, 7(10):9530-9539, 2020.\n\nINTRODUCTION\n\n\n2021\n\n). Compared to machine learning in the cloud, the promise of FL is to avoid the costs of moving data and to mitigate privacy concerns. Yet, this promise can only be fulfilled if two key challenges are addressed. First, FL algorithms must be able to efficiently deal with the high heterogeneity of data across users, which stems from the fact that each local dataset reflects the usage and production patterns specific to a given user. Heterogeneous data may prevent FL algorithms from converging unless they use a large number of communication rounds between the users and the server, which is often considered as a bottleneck in FL (Khaled et al., 2020;Karimireddy et al., 2020b). Second, when training data contains sensitive or confidential information, FL algorithms must provide rigorous privacy guarantees to ensure that the server (or a third party) cannot accurately reconstruct this information from model updates shared by users (Geiping et al., 2020). The widely recognized way to quantify such guarantees is Differential Privacy (DP) (Dwork and Roth, 2014).\n\nSince the seminal FedAvg algorithm proposed by McMahan et al. (2017), a lot of effort has gone into addressing these two challenges separately. FL algorithms like SCAFFOLD (Karimireddy et al., 2020b) and FedProx (Li et al., 2020a) can better deal with heterogeneous data, while versions of FedAvg with Differential Privacy (DP) guarantees have been proposed based on the addition of random noise to the model updates (McMahan et al., 2018;Geyer et al., 2017;Triastcyn and Faltings, 2019). Yet, we are not aware of any approach designed to tackle data heterogeneity while ensuring differential privacy, or of any work studying the associated trade-offs. This appears to be a challenging problem: on the one hand, data heterogeneity can hurt the privacy-utility trade-off of DP-FL algorithms (by requiring more communication rounds and thus more noise). On the other hand, it is not clear how to extend existing heterogeneous FL algorithms to satisfy DP and what the resulting privacyutility trade-off would be in theory and in practice.\n\nOur work precisely aims to tackle the issue of data heterogeneity in the context of FL under DP constraints. We aim to protect the privacy of any user's data against a honest-but-curious server observing all user updates, and against a third party observing only the final model. We present DP-SCAFFOLD, a novel differential private FL algorithm for training a global model from heterogeneous data based on SCAFFOLD (Karimireddy et al., 2020b) augmented with the addition of noise in the local model updates. Our convergence analysis leverages a particular initialization of the algorithm, and controls a different set of quantities than in the original proof.\n\nRelying on recent tools for tightly keeping track of the privacy loss of the subsampled Gaussian mechanism (Wang et al., 2020) under R\u00e9nyi Differential Privacy (RDP) (Mironov, 2017), we formally characterize the privacy-utility trade-off of DP-FedAvg, considered as the state-of-the-art DP-FL algorithm (Geyer et al., 2017), and DP-SCAFFOLD in convex and nonconvex regimes. Our results show the superiority of DP-SCAFFOLD over DP-FedAvg when the number of local updates is large and/or the level of heterogeneity is high. Finally, we provide experiments on simulated and real-world data which confirm our theoretical findings and show that the gains achieved by DP-SCAFFOLD are significant in practice.\n\nThe rest of the paper is organized as follows. Section 2 reviews some background and related work on FL, data heterogeneity and privacy. Section 3 describes the problem setting and introduces DP-SCAFFOLD. In Section 4, we provide theoretical guarantees on both privacy and utility for DP-SCAFFOLD and DP-FedAvg. Finally, Section 5 presents the results of our experiments and we conclude with some perspectives for future work in Section 6.\n\n\nRELATED WORK\n\nFederated learning & heterogeneity. The baseline FL algorithm FedAvg (McMahan et al., 2017) is known to suffer from instability and convergence issues in heterogeneous settings, related to device variability or non-identically distributed data (Khaled et al., 2020). In the last case, these issues stem from a userdrift in the local updates, which occurs even if all users are available or full-batch gradients are used (Karimireddy et al., 2020b). Several FL algorithms have been proposed to better tackle heterogeneity. FedProx (Li et al., 2020a) features a proximal term in the objective function of local updates. However, it is often numerically outperformed by SCAFFOLD (Karimireddy et al., 2020b), which relies on variance reduction through control variates. In a nutshell, the update direction of the global model at the server (c) and the update direction of each user i's local model (c i ) are estimated and combined in local Stochastic Gradient Descent (SGD) steps (c \u2212 c i ) to correct the user-drift (see Section 3.3 for more details). MIME (Karimireddy et al., 2020a) also focuses on client heterogeneity and improves on SCAFFOLD by using the stochastic gradient evaluated on the global model as the local variate c i and the synchronized full-batch gradient as the global control variate c. However, computing full-batch gradients is very costly in practice. Similarly, incorporating DP noise into FedDyn (Acar et al., 2021), which is based on the exact minimization of a proxy function, is not straightforward. On the other hand, the adaptation of SCAFFOLD to DP-SCAFFOLD is more natural as control variates only depend on stochastic gradients and thus do not degrade the privacy level throughout the iterations (see details in Section 4.1).\n\nExtension to other optimization schemes: While Fed-Opt (Reddi et al., 2020) generalizes FedAvg by using different optimization methods locally (e.g., Adam (Kingma and Ba, 2014), AdaGrad (Duchi et al., 2011), etc., instead of vanilla local SGD steps) or a different aggregation on the central server, these methods may also suffer from user-drift. Their main objective is to improve the convergence rate (Wang et al., 2021) without focusing on heterogeneity. We thus choose to focus on the simplest algorithm to highlight the impact of DP and heterogeneity. Federated learning & differential privacy. Even if datasets remain decentralized in FL, the privacy of users may still be compromised by the fact that the server (which may be \"honest-but-curious\") or a third party has access to model parameters that are exchanged during or after training (Fredrikson et al., 2015;Shokri et al., 2017;Geiping et al., 2020). Differential Privacy (DP) (Dwork and Roth, 2014) provides a robust mathematical way to quantify the information that an algorithm A leaks about its input data. DP relies on a notion of neighboring datasets, which in the context of FL may refer to pairs of datasets differing by one user (user-level DP) or by one data point of one user (record-level DP).\n\nanism (Dwork and Roth, 2014), which adds Gaussian noise to the output of a non-private computation. The variance of the noise is calibrated to the sensitivity of the computation, i.e., the worst-case change (measured in 2 norm) in its output on two neighboring datasets. The design of private ML algorithms heavily relies on the Gaussian mechanism to randomize intermediate data-dependent computations (e.g. gradients). The privacy guarantees of the overall procedure are then obtained via composition (Dwork et al., 2010;Kairouz et al., 2015). Recent theoretical tools like R\u00e9nyi Differential Privacy (Mironov, 2017) (see Appendix B) allow to obtain tighter privacy bounds for the Gaussian mechanism under composition and data subsampling (Wang et al., 2020).\n\nIn the context of FL, the output of an algorithm A in the sense of Definition 2.1 contains all information observed by the party we aim to protect against. Some work considered a trusted server and thus only protect against a third party who observes the final model. In this setting, McMahan et al. (2018) introduced DP-FedAvg and DP-FedSGD (i.e., DP-FedAvg with a single local update), which was also proposed independently by Geyer et al. (2017). These algorithms extend FedAvg and FedSGD by having the server add Gaussian noise to the aggregated user updates. Triastcyn and Faltings (2019) used a relaxation of DP known as Bayesian DP to provide sharper privacy loss bounds. However, these papers do not discuss the theoretical trade-off between utility and privacy. Some recent work by Wei et al. (2020) has formally examined this trade-off for DP-FedSGD, providing a utility guarantee for strongly convex loss functions. However, they do not consider multiple local updates. Some papers also considered the setting with a \"honest-but-curious\" server, where users must randomize their updates locally before sharing them. This corresponds to a stronger version of DP, referred to as Local Differential Privacy (LDP) (Duchi et al., 2013;Zhao et al., 2021;Duchi et al., 2018). DP-FedAvg and DP-FedSGD can be easily adapted to this setting by pushing the Gaussian noise addition to the users, which induces a cost in utility. Zhao et al. (2021) consider DP-FedSGD in this setting but do not provide any utility analysis. Girgis et al. (2021b) provide utility and compression guarantees for variants of DP-FedSGD in an intermediate model where a trusted shuffler between the server and the users randomly permutes the user contributions, which is known to amplify privacy (Balle et al., 2019;Cheu et al., 2019;Ghazi et al., 2019;Erlingsson et al., 2019). However, both of these studies do not consider multiple local updates, which is key to reduce the number of communication rounds. Li et al. (2020b) consider the server as \"honest-but-curious\" but does not ensure end-to-end privacy to the users. Finally, Hu et al. (2020) present a personalized DP-FL approach as a way to tackle data heterogeneity, but it is limited to linear models.\n\nSummary. To the best of our knowledge, there exists no FL approach designed to tackle data heterogeneity under DP constraints, or any study of existing DP-FL algorithms capturing the impact of data heterogeneity on the privacy-utility trade-off.\n\n\nDP-SCAFFOLD\n\nIn this section, we first describe the framework that we consider for FL and DP, before giving a detailed description of DP-SCAFFOLD. A table summarizing all notations is provided in Appendix A.\n\n\nFederated Learning Framework\n\nWe consider a setting with a central server and M users. Each user i \u2208 [M ], holds a private local dataset\nD i = {d i 1 , ..., d i R } \u2282 X R , composed of R observations living in a space X .\nWe denote by D := D 1 ... D M the disjoint union of all user datasets. Each dataset D i is supposed to be independently sampled from distinct distributions. The objective is to solve the following empirical risk minimization problem over parameter x:\nmin x\u2208R d F (x) := 1 M M i=1 F i (x), where F i (x) := 1 R R j=1 f i (x, d i j )\nis the empirical risk on user i, and for all x \u2208 R d and d \u2208 X , f i (x, d) is the loss of the model x on observation d. We denote by \u2207f i (x, d i j ) the gradient of the loss f i computed on a sample d i j \u2208 D i , and by extension, for any\nS i \u2282 D i , \u2207f i (x, S i ) := 1 |Si| j\u2208Si \u2207f i (x, d i j )\nis the averaged mini-batch gradient. We note that our results can easily be adapted to optimize any weighted average of the loss functions and to imbalanced local datasets.\n\n\nPrivacy Model\n\nWe aim at controlling the information leakage from individual datasets D i in the updates shared by the users. For simplicity, our analysis focuses on recordlevel DP with respect to (w.r.t) the joint dataset D. We thus consider the following notion of neighborhood: D, D \u2208 X M R are neighboring datasets (denoted ||D \u2212 D || \u2264 1) if they differ by at most one record, that is if there exists at most one i \u2208 [M ] such that D i and D i differ by one record. We want to ensure privacy (or quantify privacy level) (i) towards a third party observing the final model and (ii) towards an honest-but-curious server. Our DP budget is set in advance and denoted by ( , \u03b4), and corresponds to the This claim can be proved by induction, see Appendix B. Consequently, the analysis of privacy is similar for DP-FedAvg or DP-SCAFFOLD. Theorem 4.1 gives the order of magnitude of \u03c3 g (same for DP-FedAvg and DP-SCAFFOLD) to ensure DP towards the server or any third party. Similar to previous work (see e.g., Girgis et al., 2021b), the results presented below consider the following regime, as it allows to obtain simple closed forms for the privacy guarantees in Theorem 4.1.\n\nAssumption 1. We consider a noise level \u03c3 g , a privacy budget > 0 and a data-subsampling ratio s s.t.: (i) s = o(1), (ii) < 1 and (iii) \u03c3 g = \u2126(s K/ log(2T l/\u03b4)) (high privacy regime).\n\nNote that our analysis does not require Assumption 1, but the resulting expressions and the dependency on the key parameters are then difficult to interpret. This assumption is actually not used in our experiments, where we compute the privacy loss numerically using the complete formulas from our proof. Under Assumption 1, set \u03c3 g = \u2126 s lT K log(2T l/\u03b4) log(2/\u03b4)/ \u221a M . Then, for DP-SCAFFOLD(-warm) and DP-FedAvg, x T is (1) O( ), \u03b4 -DP towards a third party, (2) O( s ), \u03b4 s -DP towards the server, where s = M/l and \u03b4 s = \u03b4 2 ( 1 l + 1).\n\nSketch of proof. We here summarize the main steps of the proof. Let \u03c3 g be a given DP noise level. Our proof stands for the privacy analysis over a query function of sensitivity 1 (since calibration is made with constant S in Section 3.2). We denote GM(\u03c3 g ) the corresponding Gaussian mechanism. We first provide the result for any third party.\n\nWe combine the following steps:\n\n\u2022 Data-subsampling with R\u00e9nyi DP. Let t \u2208 [T ] be an arbitrary round. We first estimate an upper DP bound a (w.r.t. D) of the privacy loss after the aggregation by the server of lM individual contributions (Step 21 in Alg. 1). Those are private w.r.t. to the corresponding local datasets, say (\u03b1, i )-RDP w.r.t. D i where i \u2208 C t stands for the i-th user, each one being the result of the composition of K adaptative ssubsampled GM(\u03c3 g ). For any \u03b1 > 1, we know that GM(\u03c3 g ) is (\u03b1, \u03b1/2\u03c3 2 g )-RDP (Mironov, 2017). Wang et al. (2020) proves that the s-subsampled GM(\u03c3 g ) is (\u03b1, O(s 2 \u03b1/\u03c3 2 g ))-RDP under Assumption 1-(i). By the RDP composition rule over the K local iterations, we have i (\u03b1) \u2264 O(Ks 2 \u03b1/\u03c3 2 g ). Therefore, the aggregation over all users considered in C t is private w.r.t. D with a corresponding Gaussian noise of variance S 2 \u03c3 2 a where \u03c3 2 a = 1 lM \u03c3 2 g Ks 2 (mean of independent Gaussian noises). Yet, making the whole aggregation private w.r.t. D only requires a l 2 calibration equal to S = S/lM (by triangle inequality) which means we can quantify the gain of privacy as (\u03b1, O(Ks 2 \u03b1/lM \u03c3 2 g ))-RDP. After converting this result into a DP bound (Mironov, 2017), we get that for any \u03b4 > 0, the whole mechanism is ( a (\u03b1, \u03b4 ), \u03b4 )-DP where\na (\u03b1, \u03b4 ) = O Ks 2 \u03b1 lM \u03c3 2 g + log(1/\u03b4 ) \u03b1\u22121 .\n\u2022 User-subsampling with DP. In order to get explicit bounds (that may not be optimal), we then use classical DP tools to estimate an upper DP bound T after T rounds. By combining amplification by subsampling results (Kasiviswanathan et al., 2011) over users andstrong composition (Kairouz et al., 2015) (with Assumption 1-(ii)) over communication rounds, we finally get that, for any \u03b4 > 0, x T is ( T (\u03b1, \u03b4 , \u03b4 ), T l\u03b4 +\u03b4 )-DP where T (\u03b1, \u03b4 , \u03b4 ) = O(l a (\u03b1, \u03b4 ) T log(1/\u03b4 )).\n\n\u2022 Fixing parameters. Considering our final privacy budget \u03b4 for any third party, we fix \u03b4 := \u03b4/2T l and \u03b4 := \u03b4/2. Following the method of the Moments Accountant (Abadi et al., 2016), we minimize the bound on T w.r.t. \u03b1 > 1, which gives that T = O(\u02dc ) wher\u1ebd = l T log(2/\u03b4) s K log(2T l/\u03b4)\n\u03c3 g \u221a lM + Ks 2 lM \u03c3 2 g .\nFinally, under Assumption 1-(iii), the second term is bounded by the first one. We then invert the formula of this upper bound of\u02dc to express \u03c3 g as a function of a given privacy budget , proving the first statement.\n\nTo prove the second statement, we recall that the server has access to individual contributions before aggregation (which prevents a reduction by a factor lM of the variance) and that it knows the selected users at each round, which cancels the user-sampling effect (factor l). We refer to Appendix B for the full proof as well as the non-asymptotic (tighter) formulas.\n\nRemarks on privacy accounting. The RDP analysis conducted to handle data subsampling allows to limit the impact of K in the expression of \u03c3 g . A standard analysis would require a noise level increased by an extra factor O( log(T Kls/\u03b4)). On the other hand, we tracked the privacy loss over the communication rounds using standard strong composition (Dwork et al., 2010), which gives a closed-form expression but is often sub-optimal in practice. In our experiments, we use RDP upper bounds to calibrate \u03c3 g more tightly.\n\nWe refer to Appendix B for more details.\n\nExtension to other frameworks. Instead of the Gaussian mechanism, other randomizers could be applied, possibly to the per-example gradients. The privacy analysis would be then similar to ours as long as a tight RDP bound on the subsampling of this mechanism is provided (see the work of Wang et al., 2020, for more details). Otherwise, classic DP results for composition and subsampling must be used instead. Besides this, our analysis could be extended to the use of a shuffler between the users and the server to amplify privacy guarantees. For instance, one could use a recent RDP result for shuffled subsampled pure DP mechanisms (Girgis et al., 2021a, Theorem 1).\n\n\nUtility\n\nWe denote by \u00b7 the Euclidean 2 -norm. We assume that F is bounded from below by F * = F (x * ), for an x * \u2208 R d . Furthermore, we make standard assumptions on the functions (F i ) i\u2208 [M ] .\n\nAssumption 2. For all i \u2208 [M ], F i is differentiable and \u03bd-smooth (i.e., \u2207F i is \u03bd-Lipschitz).\n\nWe also make the following assumption on the stochastic gradients and data sampling. \nAssumption 3. For any iteration t \u2208 [T ], k \u2208 [K], 1. the stochastic gradient \u2207f i (y k\u22121 i , d i j ) is condi- tionally unbiased, i.e., E d i j [\u2207f i (y k\u22121 i , d i j )|y k\u22121 i ] = \u2207F i (y k\u22121 i\u2208 R d , E d i j [ \u2207f i (y, d i j ) \u2212 \u2207F i (y) 2 ] \u2264 \u03c2 2 . 3. there exists a clipping constant C independent of i, j such that \u2207f i (y k\u22121 i , d i j ) \u2264 C.\nThe first condition is naturally satisfied when d i j is uniformly sampled in [R]. The second condition is classical in the literature, and can be relaxed to only assume that the noise is bounded at the optimal point x * (Gower et al., 2019). Remark that consequently, the variance of a mini-batch of size sR uniformly sampled over D i is upper bounded by \u03c2 2 /sR. Finally, the third point ensures that we can safely ignore the impact of gradient clipping.\n\nLastly, to obtain a convergence guarantee for DP-FedAvg (but not for DP-SCAFFOLD), we use Assumption 4 on the data-heterogeneity, which bounds gradients \u2207f i towards \u2207f . Assumption 4 (Bounded Gradient dissimilarity). There exist constants G \u2265 0 and B \u2265 1 such that:\n\u2200x \u2208 R d , 1 M M i=1 ||\u2207F i (x)|| 2 \u2264 G 2 + B 2 ||\u2207F (x)|| 2 .\nQuantifying the heterogeneity between users by controlling the difference between the local gradients and the global one is classical in federated optimization (e.g. Kairouz et al., 2021). We can now state a utility result in the convex case, by considering \u03c3 * g := s lT K log(2T l/\u03b4) log(2/\u03b4)/ \u221a M (order of magnitude of noise scale to approximately ensure endto-end ( , \u03b4)-DP w.r.t. D according to Theorem 4.1). This result is extended to the strongly convex and nonconvex cases in Appendix C. Theorem 4.2 (Utility result -convex case). Assume that for all i \u2208 [M ], F i is convex. Let x 0 \u2208 R d and denote D 0 := ||x 0 \u2212 x * ||. Under Assumptions 2 and 3, we consider the sequence of iterates (x t ) t\u22650 of Algorithm 1 (DP-SCAFFOLD) and Algorithm 2 (DP-FedAvg), starting from x 0 , and with DP noise \u03c3 g := \u03c3 * g . Then there exist step-sizes (\u03b7 g , \u03b7 l ) and weights (w t ) t\u2208 [T ] such that the expected excess of loss\nE[F (x T )] \u2212 F * , where x T = T t=1 w t x t , is bounded by: \u2022 For DP-FedAvg, under Assumption 4: O D0C d log(T l/\u03b4) log(1/\u03b4) M R privacy bound + \u03c2D0 \u221a sRlM KT + B 2 \u03bdD 2 0 T + GD0 \u221a 1 \u2212 l \u221a lM T + D 4/3 0 \u03bd 1/3 G 2/3 T 2/3 optimization bound .\n\u2022 For DP-SCAFFOLD-warm:\nO D0C d log(T l/\u03b4) log(1/\u03b4) M R privacy bound + \u03c2D0 \u221a sRlM KT + \u03bdD 2 0 l 2/3 T optimization bound .\nThe two bounds given in Theorem 4.2 consist of three and two terms respectively: 1. A classical convergence rate resulting from (nonprivate) first order optimization, highlighted in green.\n\nThe dominant part, as T \u2192 \u221e, is \u03c2D0 \u221a sRlM KT . This term is inversely proportional to the square root of the total number of iterations T K times the average number of gradients computed per iteration lM \u00d7 sR, and increases proportionally to the stochastic gradients' standard deviation \u03c2 and the initial distance to the optimal point D 0 .\n\n2. An extra term, in blue, showing that heterogeneity hinders the convergence of DP-FedAvg, for which Assumption 4 is required. Here, as T \u2192 \u221e, the dominant term in it is GD0 \u221a 1\u2212l \u221a lM T , except if the user sampling ratio l = 1, then the dominating term becomes\nD 4/3 0 \u03bd 1/3 G 2/3 T 2/3\n. Both these terms do not decrease with the number of local iterations K, and increase with heterogeneity constant G. This extra term for DP-FedAvg highlights the superiority of DP-SCAFFOLD over DP-FedAvg under data heterogeneity. 3. Lastly, an additional term showing the impact of DP appears. This term is diverging with the number of iterations T , which results in the privacy-utility trade-off on T . Moreover, this term decreases proportionally to the whole number of data records M R. It also outlines the cost of DP since it sublinearly grows with the size of the model d and dramatically increases inversely to the DP budget .\n\nTake-away messages. Our analysis highlights that: (i) DP-SCAFFOLD improves on DP-FedAvg in the presence of heterogeneity; and (ii) increasing the number of local updates K is very profitable to DP-SCAFFOLD, as it improves the dominating optimization bound without degrading the privacy bound. These aspects are numerically confirmed in Section 5.\n\nSketch of proof and originality. To establish Theorem 4.2, we adapt the proof of Theorems V and VII in Karimireddy et al. (2020b). However, we consider a weakened assumption on stochastic gradients due the addition of Gaussian noise in the local updates. Consequently, in order to limit the impact of this additional noise, we change the quantity (Lyapunov function) that is controlled during the proof: we combine the squared distance to the optimal point x t \u2212 x * 2 to a control of the lag at iteration t, 1\nKM K k=1 M i=1 E \u03b1 t i,k\u22121 \u2212 x t 2 ;\nwhere we ensure that our control variates (c t i ) i\u2208 [M ] at iteration t correspond to noisy stochastic gradients measured at points (\u03b1 t i,k\u22121 ) i\u2208 [M ] , that is,\nc t i = 1 K K k=1H k i \u03b1 t i,k\u22121 . 3 This proof is detailed in Appendix C.\nRelying directly on the result in Karimireddy et al. (2020b) would require to devote a large fraction (e.g., half) of the privacy budget to the initialization phase to obtain a reasonable bound. Such a strategy did not perform well in experiments.\n\nOn the warm-start strategy. To obtain the utility result, we have to ensure that initial users' controls c 0 i are set as follows:\nc 0 i = 1 K K k=1H k i (x 0 ) (notations of Alg. 1).\nOur theoretical result thus only holds for the DP-SCAFFOLD-warm version. However, we observed in our experiments that DP-SCAFFOLD (which uses initial user control variates equal to 0) led to the same results as DP-SCAFFOLD-warm.\n\nExtension to other local randomizers. Our utility analysis would easily extend to any unbiased mechanism with explicit variance (see Appendix C).\n\n\nEXPERIMENTS\n\nExperimental setup. In our experiments, 4 we perform federated classification with two models: (i) logistic regression (LogReg) for synthetic and real-world data, and (ii) a deep neural network with one hidden layer (DNN ) (see Appendix D.1 for the precise architecture) on real-world data. We fix the global step-size \u03b7 g = 1, local step-size \u03b7 l = \u03b7 0 /sK where \u03b7 0 is carefully tuned (see Appendix D.1), and use a 2 -regularization parameter set to 5.10 \u22123 . Regarding privacy, we fix \u03b4 = 1/M R in all experiments. Then, for each setting, once the parameters related to sampling and number of iterations are fixed, we calculate the corresponding privacy bound by using non-asymptotic upper bounds from RDP theory (see Section 4.1). Details on the clipping heuristic are given in Appendix D.1. We report average results over 3 random runs.\n\nDatasets. For synthetic data, we follow the data generation setup of Li et al. (2020a), which enables to control heterogeneity between users' local models and between users' data distributions, respectively with parameters \u03b1 and \u03b2 (the higher, the more heterogeneous). Note that the setting (\u03b1, \u03b2) = (0, 0) still creates heterogeneity and does not lead to i.i.d. data across users. Our data is generated from a logistic regression design with 10 classes, with input dimension d = 40. We consider M = 100 users, each holding 3 In contrast, the proof in the convex case in Karimireddy et al. (2020b) \ncontrols 1 M M i=1 E c t i \u2212 \u2207fi(x * ) 2 . 4 Code available on Github.\nR = 5000 samples. We compare three levels of heterogeneity: (\u03b1, \u03b2) \u2208 {(0, 0), (1, 1), (5, 5)}. Details on data generation are given in Appendix D.2.\n\nWe also conduct experiments on the EMNIST-'balanced' dataset (Cohen et al., 2017), which consists of 47 balanced classes (letters and digits) containing all together 131, 600 samples. The dataset is divided into M = 40 users, who each have R = 2500 data records. Heterogeneity is controlled by parameter \u03b3. For \u03b3% similar data, we allocate to each user \u03b3% i.i.d. data and the remaining (100 \u2212 \u03b3)% by sorting according to the label (Hsu et al., 2019), which corresponds to 'FEMNIST' (Federated EMNIST ). For experiments involving DNN, we rather use the seminal MNIST dataset, which features 60, 000 samples labeled by one of the 10 balanced classes. All of the samples are allocated between M = 60 users (thus R = 1000). For both datasets, we consider heterogeneity levels \u03b3 \u2208 {0%, 10%, 100%}.\n\nWe split each dataset in train/test sets with proportion 80%/20%. Features are first standardized, then each data point is normalized to have unit L2 norm.\n\nSuperiority of DP-SCAFFOLD. We first study the performance of different algorithms under varying levels of data heterogeneity and number of local updates. We set subsampling parameters to l = 0.2 and s = 0.2 for all of the datasets and fix the noise level \u03c3 g = 60 for synthetic data, and \u03c3 g = 30 for real-world data. We compare 6 algorithms: FedAvg, FedSGD (FedAvg with Ks = 1), SCAFFOLD(-warm), with and without DP. The results for LogReg (convex objective) with T = 400 are shown in Figure 1 for synthetic data and Figure 2 (top row) for FEMNIST. Figure 2 (bottom row) shows results for DNN (non-convex objective) with T = 100 on MNIST data. We report in the figure caption the corresponding privacy bound for the last iterate with respect to a third party.\n\nIn both convex and non-convex settings, DP-SCAFFOLD clearly outperforms DP-FedAvg and DP-FedSGD under data heterogeneity. The performance gap also increases with the number K of local updates, see Figure 1. These results confirm our theoretical results: they show that the control variates of DP-SCAFFOLD are robust to noise, and allow to overcome the limitations of DP-FedAvg under high heterogeneity and many local updates.\n\nTrade-offs between parameters. In DP-SCAFFOLD, a fixed guarantee can be achieved by different combinations of values for K, T and \u03c3 g , as shown in Theorem 4.2). We propose to empirically observe these trade-offs on synthetic data under a high privacy regime ( = 3). The sampling parameters are fixed to l = 0.05, s = 0.2. Given \u03c3 g and K, we calculate the maximal value of T such that the privacy bound is still maintained after T communication rounds. Table 1 shows the test accuracy obtained after these iterations for a high heterogeneity setting (\u03b1, \u03b2) = (5, 5).\n\nOur results highlight the trade-off between T and K (which relates to hardware and communication constraints in real deployments) to achieve some given performance. Indeed, if K is too large, T has to be chosen very low to ensure the desired privacy, leading to poor accuracy. For instance, with K = 40, T cannot exceed 90, and the resulting accuracy thus barely reaches 22%, even with low private noise. On the other hand, if we set K too low, DP-SCAFFOLD does not converge despite a high value of T , since it does not take advantage of the local updates. Moreover, we can observe another dimension of the trade-off involving \u03c3 g . It seems that better performance can be achieved by setting \u03c3 g relatively low, although it implies to choose a smaller T . This trade-off is evidenced by the fact that the accuracy achieved in the first two rows (\u03c3 g = 10 and \u03c3 g = 20) is quite similar, showing that \u03c3 g and T compensate each other.\n\nOther results. Appendix D.3 shows results with other metrics and heterogeneity levels, higher privacy regimes, and presents additional experiments on the effect of sampling parameters l and s (and the tradeoff with T ) on privacy and convergence.\n\n\nCONCLUSION\n\nOur paper introduced a novel FL algorithm, DP-SCAFFOLD, to tackle data heterogeneity under DP constraints, and showed that it improves over the baseline DP-FedAvg from both the theoretical and empirical point of view. In particular, our theoretical analysis highlights an interesting trade-off between the parameters of the problem, involving a term of heterogeneity in DP-FedAvg which does not appear in the rate of DP-SCAFFOLD. As future work, we aim at providing additional experiments with deep learning models and various sizes of local datasets across users, for more realistic use-cases. Besides, our paper opens other perspectives. DP-SCAFFOLD may be improved by incorporating other ML techniques such as momentum. On the experimental side, a larger number of samples and a more precise tuning of the trade-off between T , K and subsampling parameters may dramatically improve the utility for real-world cases under a given privacy budget. From a theoretical perspective, investigating an adaptation of our approach to a personalized FL setting (Fallah et al., 2020;Sattler et al., 2020;Marfoq et al., 2021), where formal privacy guarantees have seldom been studied (at the exception of Bellet et al., 2018; Hu et al., 2020), is a direction of interest. Table 1: Test Accuracy (%) For DP-SCAFFOLD on Synthetic Data, With = 3, l = 0.05, s = 0.2, (\u03b1, \u03b2) = (5, 5).   \n\u03c3 g K = 1 K = 5 K = 10 K = 20 K =\n\nAcknowledgments\n\nWe thank Baptiste Goujaud and Constantin Philippenko for interesting discussions. We thank anonymous reviewers for their constructive feedback. The work of A. Dieuleveut is partially supported by ANR-19-CHIA-0002-01 /chaire SCAI, and Hi! Paris. The work of A. Bellet is supported by grants ANR-16-CE23-0016 (Project PAMELA) and ANR-20-CE23-0015 (Project PRIDE). \n\n\nReferences\n\n\nORGANIZATION OF THE APPENDIX\n\nThis appendix is organized as follows. Appendix A summarizes the main notations and provides the detailed DP-FedAvg algorithm for completeness. Appendix B provides details on our privacy analysis. Appendix C gives the full proofs of our utility results for the convex, strongly convex and non-convex cases. Finally, Appendix D provides more details on the experiments of Section 5, as well as additional results.\n\n\nA ADDITIONAL INFORMATION\n\nA.1 Table of Notations   Table 2 summarizes the main notations used throughout the paper.  \nD i D joint dataset ( M i=1 D i ) f i (x, d)\nloss of the i-th user for model x on data record d F i local empirical risk function of the i-th user ( 1\nR R j=1 f i (\u00b7, d i j )) F global objective function ( 1 M M i=1 F i ) x t \u2208 R d\nserver model after round t y k i \u2208 R d model of i-th user after local update k c t \u2208 R d server control variate after round t c t i \u2208 R d control variate of the i-th user after round t l \u2208 (0, 1) user sampling ratio s \u2208 (0, 1) data sampling ratio , \u03b4 differential privacy parameters \u03c3 g standard deviation of Gaussian noise added for privacy C gradient clipping threshold \u03bd\n\nLipschitz-smoothness constant \u00b5 strong convexity parameter \u03c2 2 variance of stochastic gradients\n\n\nA.2 DP-FedAvg Algorithm\n\nThe code of DP-FedAvg is given in Algorithm 2.\n\nAlgorithm 2: DP-FedAvg(T, K, l, s, \u03c3 g , C)\n\nServer Input: initial x 0 Output: x T 1 for t = 1, ..., T do 2 User subsampling by the server:\nC t \u2282 [M ] of size lM 3 Server communicates x t\u22121 to users i \u2208 C t 4 for user i \u2208 C t do 5 Initialize model: y 0 i \u2190 x t 6 for k = 1, ..., K do 7\nData subsampling by user:\nS k i \u2282 D i of size sR 8 for sample j \u2208 S k i do 9 Compute gradient: g ij \u2190 \u2207f i (y k\u22121 i , d i j ) 10\nClip gradient:g ij \u2190 g ij / max 1, ||g ij || 2 /C 11 Add DP noise to local gradients:\nH k i \u2190 1 sR j\u2208S k ig ij + 2C sR N (0, \u03c3 2 g ) 12 y k i \u2190 y k\u22121 i \u2212 \u03b7 lH k i 13 \u2206y t i \u2190 y K i \u2212 x t\u22121 14\nUser i communicates to server: \u2206y t i 15 Server aggregates:\n\u2206x t \u2190 1 lM i\u2208C t \u2206y t i 16 x t \u2190 x t\u22121 + \u03b7 g \u2206x t\n\nB DETAILS ON PRIVACY ANALYSIS\n\nIn this section, we provide the proof of our privacy results. We start by recalling standard differential privacy results on composition and amplification by subsampling in Section B.1. Section B.2 reviews recent results in R\u00e9nyi Differential Privacy (RDP) which allow to obtain tighter privacy bounds. We then formally state and prove Claim 4.1 in Section B.3. Finally, we provide the proof of our main result (Theorem 4.1) in Section B.4.\n\n\nB.1 Reminders on Differential Privacy\n\nIn the following, we denote by D \u2208 X n to a dataset of size n. Two datasets D, D \u2208 X n are said to be neighboring (denoted by ||D \u2212 D || \u2264 1) if they differ by at most one element.\n\nComposition. Let M 1 (\u00b7; A 1 ), ..., M T (\u00b7; A T ) be a sequence of T adaptive DP mechanisms where A t stands for the auxiliary input to the t-th mechanism, which may depend on the outputs of previous mechanisms (M t ) t <t . The ability to choose the sequences of mechanisms adaptively is crucial for the design of iterative machine learning algorithms. DP allows to keep track of the privacy guarantees when such a sequence of private mechanisms is run on the same dataset D. Remark. When stating theoretical results, is typically approximated by O( T log(1/\u03b4 )) when << 1.\n\nPrivacy amplification by subsampling. A key result in DP is that applying a private algorithm on a random subsample of the dataset amplifies privacy guarantees (Kasiviswanathan et al., 2011). In this work, we are interested in subsampling without replacement. Definition B.1 (Subsampling without replacement). The subsampling procedure Samp n,m : X n \u2192 X m (where m \u2208 N, with m \u2264 n) takes D as input and chooses uniformly among its elements a subset D of m elements. We may also denote Samp n,m as Samp q where q = m/n in the rest of the paper.\n\nLemma B.2 quantifies the associated privacy amplification effect.\n\nLemma B.2 (Amplification by subsampling, Kasiviswanathan et al., 2011). Let M : X m \u2192 Y be a ( , \u03b4)-DP mechanism w.r.t. a given dataset D \u2208 X m . Then, mechanism M : X n \u2192 Y defined as M := M \u2022 Samp n,m is ( , \u03b4 )-DP w.r.t. to any dataset D \u2208 X n such that D = Samp n,m (D), where:\n\n= log(1 + q(e \u2212 1)), \u03b4 = q\u03b4, q = m/n.\n\n\nRemark.\n\nIn theoretical results, is often approximated by O(q ) when << 1. \n\n\nB.2 R\u00e9nyi Differential Privacy\n\nThe interpretation of this quantity is easy to understand: ( , \u03b4)-DP ensures that the absolute value of the privacy loss is bounded by with probability at least (1 \u2212 \u03b4) for all pairs of neighboring datasets D and D (Dwork and Roth, 2014, Lemma 3.17).\n\nWe will reason on the Cumulant Generating Function (CGF) of the privacy loss, denoted K M , rather than on the privacy loss L M itself. This CGF is expressed as follows for any \u03bb > 0:\nK M (D, D , \u03bb) := E \u03b8\u223cM (D) e \u03bbL M D,D (\u03b8) = E \u03b8\u223cM (D) M (D)(\u03b8) M (D )(\u03b8) \u03bb ,\nwhich is also equivalent to:\nK M (D, D , \u03bb) = E \u03b8\u223cM (D ) M (D)(\u03b8) M (D )(\u03b8) \u03bb+1 .(3)\nBy the property of the moment generating function, K M (D, D , \u00b7) fully determines the distribution of the privacy loss random variable L M D,D . We also define K M (\u03bb) := sup ||D\u2212D ||\u22641 K M (D, D , \u03bb), which is the upper bound on the CGF for any pair of neighboring datasets.\n\nWe can now introduce R\u00e9nyi Differential Privacy (RDP), which generalizes DP using the R\u00e9nyi divergence D \u03b1 .\n\nDefinition B.2 (R\u00e9nyi Differential Privacy, Mironov, 2017). For any \u03b1 \u2208 (1, \u221e) and any > 0, a mechanism M : X n \u2192 Y is said to be (\u03b1, )-RDP, if for all neighboring datasets D and D ,\nD \u03b1 (M (D)||M (D )) := 1 \u03b1 \u2212 1 log E \u03b8\u223cM (D ) M (D)(\u03b8) M (D )(\u03b8) \u03b1 \u2264 .(4)\nGiven a mechanism M and a RDP parameter \u03b1, we can thus determine from Definition B.2 the lowest value of the -RDP bound, denoted M (\u03b1), such that M is (\u03b1, M (\u03b1))-RDP. Indeed, M (\u03b1) is such that:\nM (\u03b1) = inf \u2208\u03b5(M ) where \u03b5(M ) := { > 0 : sup ||D\u2212D ||\u22641 D \u03b1 (M (D)||M (D )) \u2264 }.\nThe obvious similarity between Eq. (3) and Eq. (4) shows the link between the CGF and the notion of RDP. Indeed, for any \u03b1 \u2208 (1, \u221e), it is easy to see that (\u03b1 \u2212 1) M (\u03b1) is equal to K M (\u03bb) where \u03bb + 1 = \u03b1 (restated in Lemma B.3).\nLemma B.3 (Equivalence RDP-CGF). Any mechanism M is (\u03bb + 1, K M (\u03bb)/\u03bb)-RDP for all \u03bb > 0.\nWe now recall how we can convert RDP guarantees into standard DP guarantees.\n\nLemma B.4 (RDP to DP conversion, Mironov, 2017). If M is ( , \u03b1)-RDP, then M is ( +log(1/\u03b4)/(\u03b1\u22121), \u03b4)-DP for any 0 < \u03b4 < 1.\n\nGiven Lemma B.4 and Lemma B.3, it is possible to find the smallest from some fixed parameter \u03b4 or the smallest \u03b4 from some fixed parameter so as to achieve ( , \u03b4)-DP:\n(\u03b4) = min \u03bb>0 log(1/\u03b4) + K M (\u03bb) \u03bb ,(5)\u03b4( ) = min \u03bb>0 e K M (\u03bb)\u2212\u03bb .(6)\nMoreover, \u03bb \u2192 K M (\u03bb)/\u03bb is monotonous (Van Erven and Harremos, 2014, Theorem 3) and \u03bb \u2192 K M (\u03bb) is convex (Van Erven and Harremos, 2014, Theorem 11). This last property enables to bound K M by a linear interpolation between the values of K M evaluated at integers, as stated below:\n\u2200\u03bb > 0, K M (\u03bb) \u2264 (1 \u2212 \u03bb + \u03bb )K M ( \u03bb ) + (\u03bb \u2212 \u03bb )K M ( \u03bb ).(7)\nTherefore, Problem (5) is quasi-convex and Problem (6) is log-convex, and both can be solved if we know the expression of K M (\u03bb) for any \u03bb > 0.\n\nWe provide below other useful results from RDP theory, which we will use in our privacy analysis.\n\nLemma B.5 (RDP Composition, Mironov, 2017). Let \u03b1 \u2208 (1, \u221e). Let M 1 and M 2 be two mechanisms such that M 1 is (\u03b1, 1 )-RDP and M 2 , which takes the output of M 1 as auxiliary input, is (\u03b1, 2 )-RDP. Then the composed mechanism M 2 \u2022 M 1 is (\u03b1, 1 + 2 )-RDP.\n\nLemma B.6 (RDP Gaussian mechanism, Mironov, 2017). If f : X n \u2192 R d has 2 -sensitivity 1, then the Gaussian mechanism G f (\u00b7) := f (\u00b7) + N (0, \u03c3 2 g I d ) is (\u03b1, \u03b1/2\u03c3 2 g )-RDP for any \u03b1 > 1. Lemma B.7 (RDP for subsampled Gaussian mechanism, Wang et al., 2020). Let \u03b1 \u2208 N with \u03b1 \u2265 2 and 0 < q < 1 be a subsampling ratio. Suppose f : X n \u2192 R d has 2 -sensitivity equal to 1. Let G f (\u00b7) := G f \u2022 Samp q (\u00b7) be a subsampled Gaussian mechanism. Then G f is (\u03b1, (\u03b1, \u03c3 2 g ))-RDP where (\u03b1, \u03c3 2 g ) \u2264 1 \u03b1 \u2212 1 log 1 + 2q 2 \u03b1 2 min{2(e 1/\u03c3 2 g \u2212 1), e 1/\u03c3 2 g } + \u03b1 j=3 2q j \u03b1 j e j(j\u22121)/2\u03c3 2 g .\n\nRemark. By considering q = o(1), the dominant term in the upper bound of (\u03b1, \u03c3 2 g ) comes from the term of the sum of the order of q 2 . In particular, when \u03c3 2 g is large (i.e. high privacy regime), the term min{2(e 1/\u03c3 2 g \u22121), e 1/\u03c3 2 g } simplifies to 2(e 1/\u03c3 2 g \u2212 1) \u2264 4/\u03c3 2 g . This thus simplifies the whole upper bound to O(\u03b1q 2 /\u03c3 2 g ).\n\n\nB.3 Proof of Claim 4.1\n\nWe restate below a more formal version of Claim 4.1 along with its proof. For any t \u2208 [T ], we define subversions of algorithms DP-SCAFFOLD (Alg. 1) and DP-FedAvg (Alg. 2), which stop at round t and reveal an output, either to the server or to a third party:\n\n\u2022 To the server. We assume that the sampling of users C t is known by the server. Formally, we define A t DP-SCAFFOLD , which outputs (reveals) {y t i , c t i } i\u2208C t , and A t DP-FedAvg , which outputs {y t i } i\u2208C t (those quantities being private w.r.t. {D i } i\u2208C t ).\n\n\u2022 To a third party. We define\u00c3 t DP-SCAFFOLD , which outputs (x t , c t ) and\u00c3 t DP-FedAvg , which outputs x t (those quantities being private w.r.t. D).\n\nIn both privacy models, DP-SCAFFOLD and DP-FedAvg can be seen as T adaptive compositions of these subalgorithms.\n\nClaim B.1 (Formal version of Claim 4.1). For any t \u2208 [T ], the following holds:\n\n\u2022 A t DP-SCAFFOLD and A t DP-FedAvg have the same level of privacy (towards the server),\n\n\u2022\u00c3 t DP-SCAFFOLD and\u00c3 t DP-FedAvg have the same level of privacy (towards a third party).\n\nProof. We prove the claim by reasoning by induction on the number of communication rounds t. We only give the proof for the first statement (including the DP-SCAFFOLD-warm version). The second one can be proved in a similar manner.\n\nFirst, consider t = 1. For any i \u2208 C t , control variates c 0 i are either all set to 0 (DP-SCAFFOLD), or c 0 i are at least as private as y 1 i (DP-SCAFFOLD-warm). The level of privacy for A 1 DP-SCAFFOLD is thus fully determined by the level of privacy of {y 1 i } i\u2208C t , which is the same as A 1 DP-FedAvg . Therefore the claim is true for t = 1. Then, let t \u2208 [T ] and suppose that the claim is verified for all t < t. Let i \u2208 C t and first consider A t DP-SCAFFOLD . The update of the i-th user model (see Eq. 1) at round t shows that an additional information leakage may come from the correction (c t\u22121 \u2212 c t\u22121 i ), or more precisely from c t\u22121 i since c t\u22121 is known by the server. By assumption of induction, c t\u22121 i is also known by the server. Therefore, using the post-processing property of DP, the y t i as updated in DP-SCAFFOLD is as private w.r.t. D i as the y t i as updated in DP-FedAvg. Besides this, the update of the i-th control variate fully depends on the local updates of y t i through the average of the DP-noised stochastic gradients calculated over the local iterations. Therefore, considering all the contributions from C t , A t\n\n\nDP-FedAvg\n\nand A t DP-SCAFFOLD have the same level of privacy.\n\n\nB.4 Proof of Theorem 4.1\n\nPreliminaries. Lemma B.7 only gives an upper bound of the RDP privacy for a subsampled Gaussian mechanism when \u03b1 \u2208 N with \u03b1 \u2265 2. However we will need to optimize our privacy bound w.r.t. \u03b1 \u2208 R with \u03b1 > 1. We thus use Lemma B.3 and the convexity of the CGF (see Eq. 7) to generalize this upper bound to the following result.\n\nLet \u03b1 \u2208 R with \u03b1 > 1. Under the same assumptions as in Lemma B.7, G f is (\u03b1, (\u03b1, \u03c3 2 g ))-RDP with\n(\u03b1, \u03c3 2 g ) \u2264 (1 \u2212 \u03b1 + \u03b1 ) \u03b1 \u2212 1 \u03b1 \u2212 1 ( \u03b1 , \u03c3 2 g ) + (\u03b1 \u2212 \u03b1 ) \u03b1 \u2212 1 \u03b1 \u2212 1 ( \u03b1 , \u03c3 2 g ),(8)\nwhere (\u00b7, \u03c3 2 g ) admits the upper bound given in Lemma B.7.\n\nDetails of the proof. Our privacy analysis assumes that the query function has sensitivity 1, since the calibration of the Gaussian noise is locally adjusted in our algorithms with the constant S = 2C/sR (see Section 3.2). We simply denote by G the Gaussian mechanism with variance \u03c3 2 g , which is (\u03b1, \u03b1/2\u03c3 2 g )-RDP (Lemma B.6). Below, we first prove privacy guarantees towards a third party observing only the final result, and then deduce the guarantees towards the honest-but-curious server.\n\nStep 1: data subsampling. Let t \u2208 [T ] be an arbitrary round. We first provide an upper bound a for the privacy loss after the aggregation by the server of the lM individual contributions (line 20 in Alg. 1), thanks to the local addition of noise.\n\nLet i \u2208 C t , \u03b1 > 1. We denote by i (\u03b1) the \u03b1-RDP budget (w.r.t. D i ) used to \"hide\" the individual contribution of the i-th user from the server. This contribution is the result of the composition of K adaptative s-subsampled mechanisms G:\n\n\u2022 We first obtain an upper RDP bound for the s-subsampled mechanism with Lemma B.7. Suppose first \u03b1 \u2208 N and \u03b1 \u2265 2, which is the case covered by Lemma B.7. Under Assumption 1-(i) and Assumption 1-(iii), the resulting mechanism is (\u03b1, O(s 2 \u03b1/\u03c3 2 g ))-RDP. To extend this result to \u03b1 > 1, we use the result provided in (8): by factoring by s 2 /\u03c3 2 g in the upper bound of (\u03b1, \u03c3 2 g ), and bounding the rest of the inequality (a convex combination between \u03b1 ( \u03b1 \u2212 1)/(\u03b1 \u2212 1) and \u03b1 ( \u03b1 \u2212 1)/(\u03b1 \u2212 1)) by \u03b1 + 1, we also obtain that this mechanism is (\u03b1, O(s 2 (\u03b1 + 1)/\u03c3 2 g ))-RDP.\n\n\u2022 We then use the result of Lemma B.5 for the RDP composition rule over the K local iterations, which gives that i (\u03b1) \u2264 O(Ks 2 (\u03b1 + 1)/\u03c3 2 g ).\n\nWe now consider the aggregation step. Taking into account all the contributions of the users from C t , we get a Gaussian noise of variance S 2 \u03c3 2 a where \u03c3 2 a = 1 lM \u03c3 2 g . Note that the sensitivity of the aggregation (w.r.t. the joint dataset D) is lM times smaller than when considering an individual contribution. Therefore, with the previous approximation, the aggregated contributions satisfy (\u03b1, O(Ks 2 (\u03b1 + 1)/lM \u03c3 2 g ))-RDP w.r.t. D. After converting this result into a DP bound (Lemma B.4), we get that for any 0 < \u03b4 < 1, the aggregation at line 20 in Alg. 1 is ( a (\u03b1, \u03b4 )\n, \u03b4 )-DP w.r.t. D where a (\u03b1, \u03b4 ) = O Ks 2 (\u03b1+1) lM \u03c3 2 g + log(1/\u03b4 ) \u03b1\u22121 .\nWithout approximation: we would obtain at this step an exact upper bound a (\u03b1, \u03b4 ) = K (\u03b1, lM \u03c3 2 g ) + log(1/\u03b4 ) \u03b1\u22121 .\n\nStep 2: user subsampling. In order to get explicit bounds, we then use classical DP tools to estimate an upper DP bound after T rounds taking into account the amplification by subsampling from the set of users.\n\nRemark that these tools are however sub-optimal for practical implementations (Abadi et al., 2016, Section 5.1.).\n\n\u2022 Using Lemma B.2, the subsampling of users enables a gain of privacy of the order of l, which gives O(l a (\u03b1, \u03b4 )), l\u03b4 -DP.\n\n\u2022 Using Lemma B.1, we compose this mechanism over T iterations, which under Assumption 1-(ii) gives for any \u03b4 > 0, O( T log(1/\u03b4 )l a (\u03b1, \u03b4 )), T l\u03b4 + \u03b4 -DP.\n\nWithout approximation: the mechanism is * (\u03b1, \u03b4 ) 2T log(1/\u03b4 ) + T * (\u03b1, \u03b4 )(e * (\u03b1,\u03b4 ) \u2212 1), T l\u03b4 + \u03b4 where * (\u03b1, \u03b4 ) = log(1 + l(e a (\u03b1,\u03b4 ) \u2212 1)).\n\nStep 3: setting parameters. We denote T (\u03b1, \u03b4 , \u03b4 ) = l T log(1/\u03b4 ) Ks 2 (\u03b1+1)\nlM \u03c3 2 g + log(1/\u03b4 ) \u03b1\u22121 .\nGiven what is stated above, the final output of the algorithm is (O( T ), T l\u03b4 + \u03b4 )-DP.\n\nConsidering our final privacy budget \u03b4, we arbitrarily fix \u03b4 := \u03b4/2T l and \u03b4 := \u03b4/2. We now aim to find an expression of \u03c3 g such that the privacy bound is minimized. By considering the approximated bound, this gives the following minimization problem: min \u03b1>1 T (\u03b1) := l T log(2/\u03b4)\nKs 2 (\u03b1 + 1) lM \u03c3 2 g + log(2T l/\u03b4) \u03b1 \u2212 1 .\nUsing DP rather than RDP enables to solve this minimization problem pretty easily since only the second factor in T (\u03b1) depends on \u03b1, that is:\nmin \u03b1>1\u02dc T (\u03b1) := Ks 2 (\u03b1 + 1) lM \u03c3 2 g + log(2T l/\u03b4) \u03b1 \u2212 1 .\nBy omitting constants, we obtain the expression for the minimum value of T (\u03b1):\n= l T log(2/\u03b4) s K log(2T l/\u03b4) \u03c3 g \u221a lM + Ks 2 lM \u03c3 2 g .\nUnder Assumption 1-(iii), we can bound the second term by the first one, which gives:\n= O s lT K log(2/\u03b4) log(2T l/\u03b4) \u03c3 g \u221a M .\nWe then invert the formula of this upper bound of\u02dc to express \u03c3 g as a function of a given privacy budget :\n\u03c3 g = \u2126 s lT K log(2T l/\u03b4) log(2/\u03b4)/ \u221a M ,\nwhich proves that the algorithm is (O( ), \u03b4)-DP towards a third party observing its final output.\n\nWithout approximation: the minimization problem is much more complex and has to be solved numerically min \u03b1>1,\u03b4 >0,\u03b4 >0 * (\u03b1, \u03b4 ) 2T log(1/\u03b4 ) + T * (\u03b1, \u03b4 )(e * (\u03b1,\u03b4 ) \u2212 1) s.t. \u03b4 = T l\u03b4 + \u03b4 , or: min \u03b1>1,x\u2208(0,1) * (\u03b1, x\u03b4/T l) 2T log(1/(1 \u2212 x)\u03b4) + T * (\u03b1, x\u03b4/T l)(e * (\u03b1,x\u03b4/T l) \u2212 1).\n\nExtension to privacy towards the server. The crucial difference with the third party case is that the server observes individual contributions and knows which users are subsampled at each step. Removing the privacy amplification effect of the l-subsampling of users and the aggregation step, the minimization problem becomes min \u03b1>1 T (\u03b1) := T log(2/\u03b4)\nKs 2 \u03b1 \u03c3 2 g + log(2T /\u03b4) \u03b1 \u2212 1 ,\nwhere the minimizing value can be approximated by:\n= T log(2/\u03b4) s K log(2T /\u03b4) \u03c3 g + Ks 2 \u03c3 2 g .\nUnder Assumption 1-(iii), we can bound the second term by the first one:\n= O s T K log(2/\u03b4) log(2T /\u03b4) \u03c3 g ,\nwhich proves that we obtain (O( s ), \u03b4 s )-DP towards the server where s = M l and \u03b4 s = \u03b4 2 ( 1 l + 1).\n\nFiner results for amplification by subsampling. To establish privacy towards a third party, it is actually possible to combine the subsampling ratios (user and data) to determine a bound upon the subsampling of data directly from D and thus to quantify a more precise gain in privacy (Girgis et al., 2021b). The difficulty in this setup is that this combined subsampling is not uniform overall, which requires extending the proof of Lemma B.2 as done by Girgis et al. (2021b) in the case of classical differential privacy.\n\nImplementation. In practice, we determine a RDP upper bound at Step 2, by using the theorem proved by Wang et al. (2020) (which is not restricted to Gaussian mechanisms) with the exact RDP bound obtained at Step 1 and sampling parameter l. This result being accurate only for \u03b1 \u2208 N \\ {0, 1}, we obtain an natural extension of the bound for any \u03b1 > 1 with Eq (7). Then, we invoke Lemma B.5 to obtain the final RDP bound after T communication rounds, for any \u03b1 > 1. Under fixed privacy parameter \u03b4 (chosen as 1/M R in our experiments), we finally obtain the minimal value for w.r.t. \u03b1 \u2208 (1, \u221e), which is determined by Eq (5). The last step is done by using a fine grid search over parameter \u03b1.\n\n\nC PROOF OF UTILITY\n\nIn this section, we provide the proof of our utility results. We first establish in Section C.1 some preliminary results about the impact of DP noise over stochastic gradients. In Section C.2, we provide the complete version of our utility result for DP-SCAFFOLD-warm (Theorem C.1), from which Theorem 4.2 is an immediate corollary. We prove this theorem for convex local loss functions in Section C.3 and non-convex loss functions in Section C.4. We finally state in Section C.5 our complete result for DP-FedAvg (Theorem C.2).\n\nFor any C, \u03c3 g > 0, we define \u03a3 g (C) := 2C \u221a 2d\u03c3 g /sR. We recall that we assume that F is bounded from below by F * = F (x * ), for an x * \u2208 R d .\n\n\nC.1 Preliminaries\n\nProperties of DP-noised stochastic gradients. Let i \u2208 [M ], x \u2208 R d , S i \u2282 D i and C, \u03c3 g > 0. Suppose Assumptions 2 and 3.3 are verified (the last assumption ensures that the clipping on per-example local gradients with threshold C is not effective).\n\nWe recall below the expression ofH i (x) from Section 3.3, which is the noised version of the local gradient H i (x) of the i-th user over S i evaluated at x (omitting index k):\nH i (x) := H i (x) + 2C sR N (0, \u03c3 2 g ), where H i (x) := 1 sR d i j \u2208Si \u2207f i (x, d i j ).\nWe recall that the 2 -sensitivity of H i (x) w.r.t. S i is upper bounded by 2C/sR, which explains the scaling of the Gaussian noise in the expression ofH i (x). Since the variance of N (0, I d ) is 2d, the following statement holds directly:\nE H i (x) = H i (x) and E ||H i (x) \u2212 H i (x)|| 2 \u2264 8C 2 d\u03c3 2 g s 2 R 2 = \u03a3 g (C) 2 .\nBy combining our utility assumptions with the result stated above, we can deduce the following lemma.\n\nLemma C.1 (Regularity of DP-noised stochastic gradients). Under Assumptions 2 and 3, for any iteration\nt \u2208 [T ], k \u2208 [K], 1. E H k i (y k\u22121 i )|y k\u22121 i = \u2207F i (y k\u22121 i ), 2. E ||H k i (y k\u22121 i ) \u2212 \u2207F i (y k\u22121 i )|| 2 |y k\u22121 i \u2264 \u03c2 2 sR + \u03a3 2 g (C).\nThe proof of Lemma C.1 is easily obtained by conditioning on the two sources of randomness (i.e., mini-batch sampling and Gaussian noise) which are independent, thus the variance is additive. This result can be seen as a degraded version of Assumption 3 due to the local injection DP noise, a fact that we will strongly leverage to derive convergence rates.\n\nWe now enumerate several statements that will be used in the utility proof. First, Lemma C.2 enables to control ||\u2207F || 2 using the assumption of smoothness over the local loss functions. Second, Lemma C.3 provides separation inequalities of mean and variance (Karimireddy et al., 2020b, Lemma 4), which enables to state a result on quantities of interest in Corollary C.1.\n\nLemma C.2 (Nesterov inequality). Suppose Assumption 2 is verified and assume that for all i \u2208 [M ], F i is convex. Then,  \n\u2200x \u2208 R d , ||\u2207F (x)|| 2 \u2264 2\u03bd(F (x) \u2212 F * ). Proof. Let x \u2208 R d . ||\u2207F (x)|| 2 = ||\u2207F (x) \u2212 \u2207F (x * )|| 2 = || 1 M M i=1 \u2207F i (x) \u2212 \u2207F i (x * )|| 2 \u2264 1 M M i=1 ||\u2207F i (x) \u2212 \u2207F i (x * )|| 2 (Jensen inequality) \u2264 2\u03bd(F (x) \u2212 F * ) (E n i=1 A i 2 \u2264 n i=1 a i 2 + n 2 \u03c3 2 A .\n\nSuppose that their conditional mean is E[A\nE n i=1 A i 2 \u2264 2 n i=1 a i 2 + 2n\u03c3 2 A .\nCorollary C.1. Let t \u2208 [T ]. In the following statements, the expectation is taken w.r.t. the randomness from their local data sampling and from the Gaussian DP noise, conditionally to the users' sampling C t and initial value of variables y i , that is y 0 = x t\u22121 (same for all users). We have:\n\u2022 E \uf8ee \uf8f0 1 KlM i\u2208C t k\u2208[K] (H k i (y k\u22121 i ) \u2212 \u2207F i (y k\u22121 i )) 2 C t , y 0 \uf8f9 \uf8fb \u2264 \u03a3 2 g (C) + \u03c2 2 /sR KlM , \u2022 E 1 lM i\u2208C t c t i \u2212 E[c t i ] 2 |C t , y 0 \u2264 \u03a3 2 g (C) + \u03c2 2 /sR KlM , \u2022 E c t \u2212 E[c t ] 2 |y 0 \u2264 \u03a3 2 g (C) + \u03c2 2 /sR KlM .\nProof. First inequality. We define a random variable A such as A := 1\nKlM i\u2208C t k\u2208[K] A i,k , with A i,k := H k i (y k\u22121 i ). From Lemma C.1, we have that for all i \u2208 C t , k \u2208 [K]: E[A i,k |y k\u22121 i ] = E[H k i (y k\u22121 i )|y k\u22121 i ] = \u2207F i (y k\u22121 i ). Furthermore, by Lemma C.1, E ||H k i (y k\u22121 i ) \u2212 \u2207F i (y k\u22121 i )|| 2 |y k\u22121 i \u2264 \u03a3 2 g (C) + \u03c2 2 /sR. Furthermore, (a) for i, j \u2208 C t , k\u2208[K] A i,k \u2212 \u2207F i (y k\u22121 i ) and k\u2208[K] A j,k \u2212 \u2207F j (y k\u22121 j ) are independent con- ditionally to y 0 ; (b) for any i \u2208 C t , (A i,k \u2212 \u2207F i (y k\u22121 i )) k\u2208[K] is a martingale increment, i.e., E[A i,k \u2212 \u2207F i (y k\u22121 i )|\u03c3({y k i } k \u2208[k\u22121] )] = 0. Consequently: E \uf8ee \uf8f0 1 KlM i\u2208C t k\u2208[K] A i,k \u2212 \u2207Fi(y k\u22121 i ) 2 C t , y 0 \uf8f9 \uf8fb (a) = 1 (KlM ) 2 i\u2208C t E \uf8ee \uf8f0 k\u2208[K] A i,k \u2212 \u2207Fi(y k\u22121 i ) 2 y 0 \uf8f9 \uf8fb (b) = 1 (KlM ) 2 i\u2208C t k\u2208[K] E \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 E A i,k \u2212 \u2207Fi(y k\u22121 i ) 2 \u03c3 {y k i } k \u2208[k] \u2264\u03a3 2 g (C)+\u03c2 2 /sR y 0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \u2264 \u03a3 2 g (C) + \u03c2 2 /sR KlM .\nTo prove the second equality, we need to \"iteratively\" expand the squared norm and take the conditional expectation w.r.t. \u03c3 {y k i } k \u2208[k] for k = K, K \u2212 1, . . . , 1 and use the martingale property to obtain that the scalar products are equal to 0.\n\nSecond inequality. We recall that for any i \u2208 C t , c t i = 1 K K k=1H k i (y k\u22121 i ). Thus 1 lM i\u2208C t c t i = A and we can directly use the results from the first inequality.\n\nThird inequality. We recall that c t = 1 M M i=1 c t i (even if local control variates are not updated). Therefore, we can use the previous results and take the expectation over C t , which gives:\nE c t \u2212 E[c t ] 2 |y 0 \u2264 \u03c2 2 /sR + \u03a3 2 g (C) KM \u2264 \u03c2 2 /sR + \u03a3 2 g (C) KlM . E||\u2207F (x T )|| 2 \u2264 O \u03c2/ \u221a sR + \u03a3 g (C) \u221a T KlM F 0 + \u03bd l 2 3 T F 0 , where D 0 = ||x 0 \u2212 x * || and F 0 := F (x 0 ) \u2212 F * .\nWe recover the result of Theorem 4.2 for DP-SCAFFOLD-warm where F i are convex by setting \u03c3 g = \u03c3 * g where \u03c3 * g := s lT K log(2T l/\u03b4) log(2/\u03b4)/ \u221a M , which gives \u03a3 g (C) = 2Cd 2lT K log(2T l/\u03b4) log(2/\u03b4)/ R \u221a M (with numerical constants omitted for the asymptotic bound).\n\n\nC.3 Proof of Theorem C.1 (Convex case)\n\nIn this section, we give a detailed proof of convergence of DP-SCAFFOLD-warm with convex local loss functions. Our analysis is adapted from the proof given by Karimireddy et al. (2020b) without DP noise, but requires original modifications (see below). Throughout this part, we re-use the notations from Section 3.3.\n\nSummary of the main steps. Let t \u2208 [T ] be an arbitrary communication round of the algorithm. We detail below the updates that occur at this round.\n\n\u2022 Let i \u2208 C t . Starting from y 0 i = x t\u22121 , the random variable y i is updated at local step k \u2208 [K] such that\ny k i := y k\u22121 i \u2212 \u03b7 l v t i,k where v t i,k =H k i (y k\u22121 i ) \u2212 c t\u22121 i + c t\u22121 .\n\u2022 Then we define the local control variatec t i for this user by:\nc t i := c t\u22121 \u2212 c t\u22121 i + 1 K\u03b7 l (x t\u22121 \u2212 y K i ) = 1 K K k=1H k i (y k\u22121 i ).\n\u2022 For any i \u2208 [M ], we update the control variate c t i such that:\n-c t i :=c t i if i \u2208 C t , i := c t\u22121 i otherwise.\n\u2022 Finally, the global update is computed as:\nx t = x t\u22121 + \u03b7 g lM i\u2208C t (y K i \u2212 x t\u22121 ) and c t = 1 M i\u2208C t c t i + i / \u2208C t c t\u22121 i .\nTo keep track of the lag in the update of c t i , we introduce \u03b1 t i,k\u22121 defined for any i \u2208 [M ], any t \u2208 [T ] and any k \u2208 [K] by:\n\u03b1 t i,k\u22121 = y k\u22121 i if i \u2208 C t \u03b1 t\u22121 i,k\u22121 otherwise with \u03b1 0 i,k\u22121 = x 0 .\nWe hence have the following property for any i \u2208 [M ] and any t \u2208 [T ]:\nc t i = 1 K K k=1H k i (\u03b1 t i,k\u22121 ). Additional definitions. \u2022 Model gap: \u2206x t := x t \u2212 x t\u22121 ,\n\u2022 Global step-size:\u03b7 := K\u03b7 l \u03b7 g which gives \u2206x t = \u2212\u03b7 KlM\nk\u2208[K],i\u2208C tH k i (y k\u22121 i ) + c t\u22121 \u2212 c t\u22121 i , \u2022 User-drift: E t := 1 KM K k=1 M i=1 E||y k i \u2212 x t\u22121 || 2 , \u2022 Control lag: F t := 1 KM K k=1 M i=1 E||\u03b1 t i,k\u22121 \u2212 x t || 2 with F 0 = 0.\nOriginality of the proof. The proof substantially differs form the proof by Karimireddy et al. (2020b) in the convex case. Indeed, Karimireddy et al. (2020b) control a combination of the quadratic distance to the optimum and a control of the deviation between the controls and the gradients at the optimal point c t i \u2212 \u2207F i (x * ) . Leveraging such a quantity in our proof would result in a worse upper bound on the utility than the one we get, as either the noise added to ensure DP (if c 0 i is defined w.r.t. a noised gradient) or the heterogeneity (if c 0 i = 0) would also appear in the initial condition c t i \u2212 \u2207F i (x * ) . On the other hand, in our approach, we combine the quadratic distance to the optimum to a control of the lag and user-drift. In some sense this resembles some aspects of the proof in the non-convex regime in (Karimireddy et al., 2020b), in which the excess risk (F (x t )\u2212F * ) is combined with the lag. Nevertheless, our result (in the convex case), strongly leverages the convexity of the function in the proof.\n\nDetails of the proof. The idea of the proof is to find a contraction inequality involving\n||x t \u2212x * || 2 , E[F (x t\u22121 )]\u2212 F (x * ), F t and \u03c2/ \u221a sR + \u03a3 g (C)\n. To do so, we will first bound the variance of the server's update. Then we will see how the control lag evolves through the communication rounds. We will also bound the user drift. To make the proof more readable, the index t may be omitted on random variables when the only communication round that is considered is the t-th one.\n\nLemma C.4 (Variance of the server's update). \u2200\u03b7 \u2208 [0, 1/\u03bd]\nE||x t \u2212 x t\u22121 || 2 \u2264 4\u03b7 2 \u03bd 2 E t + 8\u03bd 2\u03b72 F t\u22121 + 8\u03bd\u03b7 2 E F (x t\u22121 ) \u2212 F (x * ) + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)).\nProof. We consider the model gap \u2206x t = x t \u2212 x t\u22121 .\nE||\u2206x t || 2 =\u03b7 2 E 1 KlM k\u2208[K],i\u2208C tH i (y k\u22121 i ) A1 + c t\u22121 A2 \u2212 1 lM i\u2208C t c t\u22121 i A3\nWe combine Lemma C.3-1 on A 1 , A 2 , A 3 with Corollary C.1 which controls their individual variance (conditionally to the users' sampling and the local parameters) by \u03c2 2 /sR+\u03a3 2 g (C) KlM . We first get rid of the terms related to the variance of the data sampling and the DP noise, before bounding the quantities of interest. It leads to:\nE||\u2206x t || 2 =\u03b7 2 E \uf8ee \uf8f0 E \uf8ee \uf8f0 1 KlM k\u2208[K],i\u2208C tH i (y k\u22121 i ) + c t\u22121 \u2212 1 lM i\u2208C t c t\u22121 i 2 C t , y 0 \uf8f9 \uf8fb \uf8f9 \uf8fb \u2264\u03b7 2 E \uf8ee \uf8f0 1 KlM k\u2208[K],i\u2208C t E[H i (y k\u22121 i )|y 0 ] + E[c t\u22121 |y 0 ] \u2212 E[c t\u22121 i |y 0 ] 2 \uf8f9 \uf8fb + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)),\nwhere the inequality is given by Lemma C.3-1.\nFor any i \u2208 C t , k \u2208 [K], we have E[H i (y k\u22121 i )|y 0 ] = E E[H i (y k\u22121 i )|y k\u22121 i ] y 0 = E \u2207F i (y k\u22121 i )|y 0 = \u2207F i (y k\u22121 i ). Then, E||\u2206x t || 2 \u2264\u03b7 2 E \uf8ee \uf8f0 1 KlM k\u2208[K],i\u2208C t \u2207F i (y k\u22121 i ) + E[c t\u22121 |y 0 ] \u2212 E[c t\u22121 i |y 0 ] 2 \uf8f9 \uf8fb + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)) (convexity of ||.|| 2 ) =\u03b7 2 1 KM k\u2208[K],i\u2208[M ] E \u2207F i (y k\u22121 i ) + E[c t\u22121 |y 0 ] \u2212 E[c t\u22121 i |y 0 ] \u2207Fi(y k\u22121 i )\u2212\u2207Fi(x t\u22121 ) +E[c t\u22121 |y 0 ]\u2212\u2207F (x t\u22121 ) \u2212E[c t\u22121 i |y 0 ]+\u2207Fi(x t\u22121 ) +\u2207F (x t\u22121 ) 2 + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)) (definition of C t ) =\u03b7 2 1 KM k\u2208[K],i\u2208[M ] E E \u2207F i (y k\u22121 i ) \u2212 \u2207F i (x t\u22121 ) + c t\u22121 \u2212 \u2207F (x t\u22121 ) \u2212 c t\u22121 i + \u2207F i (x t\u22121 ) + \u2207F (x t\u22121 ) y 0 2 + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)\n) (all variables are measurable wrt y 0 )\n\u2264\u03b7 2 1 KM k\u2208[K],i\u2208[M ] E E \u2207F i (y k\u22121 i ) \u2212 \u2207F i (x t\u22121 ) + c t\u22121 \u2212 \u2207F (x t\u22121 ) \u2212 c t\u22121 i + \u2207F i (x t\u22121 ) + \u2207F (x t\u22121 ) 2 y 0 + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)) (Jensen inequality) \u2264 4\u03b7 2 KM k\u2208[K],i\u2208[M ] E \u2207F i (y k\u22121 i ) \u2212 \u2207F i (x t\u22121 ) 2 + 8\u03b7 2 KM k\u2208[K],i\u2208[M ] E \u2207F i (\u03b1 t\u22121 i,k\u22121 ) \u2212 \u2207F i (x t\u22121 ) 2 + 4\u03b7 2 E \u2207F (x t\u22121 ) 2 + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)).\nThe last inequality is obtained by definition of c and c i and by applying Jensen inequality. With Lemma C.2, this leads to the result.\n\nLemma C.5 (Lag in the control variate). \u2200\u03b1 \u2208 [1/2, 1], \u2200\u03b7 \u2264 1 24\u03bd l \u03b1 ,\nF t \u2264 1 \u2212 17 36 l F t\u22121 + 1 24\u03bd l 2\u03b1\u22121 E F (x t\u22121 ) \u2212 F (x * ) + 97 48 l 2\u03b1\u22121 E t + l \u03bd 2 \u03c2 2 /sR + \u03a3 2 g (C) 32KlM .\nProof. We adapt the original proof made in the non-convex case (Karimireddy et al., 2020b, Lemma 16) and use Lemma C.1 and Lemma C.2.\n\nLemma C.6 (Bounding the user drift). \u2200\u03b7 g \u2265 1, \u2200\u03b7 l \u2264 1/24\u03bdK\u03b7 g ,\n9 2 \u03bd 2\u03b7 E t \u2264 9 2 \u03bd 3\u03b72 F t\u22121 + 9 40\u03b7 \u03bd \u03b7 2 g E F (x t\u22121 ) \u2212 F (x * ) + 27 40\u03b7 2 \u03bd K\u03b7 2 g \u03c2 2 /sR + \u03a3 2 g (C) .\nProof. We once again adapt the original proof made in the non-convex case (Karimireddy et al., 2020b, Lemma 17), use Lemma C.2 and multiply on each side of the inequality by 9 2 \u03bd 2\u03b7 . \nE||x t \u2212 x * || 2 + 27\u03bd 2\u03b72 1 l F t \u2264 1 \u2212 \u00b5\u03b7 2 E||x t\u22121 \u2212 x * || 2 + 27\u03bd 2\u03b72 1 l F t\u22121 \u2212\u03b7 2 E F (x t\u22121 ) \u2212 F (x * ) + 10\u03b7 2 KlM 1 + lM \u03b7 2 g (\u03c2 2 /sR + \u03a3 2 g (C)).\nProof. We recall that \u2206x t = \u2212\u03b7 KlM\nk\u2208[K],i\u2208C tH k i (y k\u22121 i ) + c t\u22121 \u2212 c t\u22121 i . Then, E[\u2206x t |y 0 ] = E[\u2206x t |x t\u22121 ] = \u2212\u03b7E[c t\u22121 |y 0 ] = \u2212\u03b7 KM k\u2208[K],i\u2208[M ] E[\u2207F i (y k\u22121 i )|y 0 ].(9)\nWe denote E t\u22121 [.] as the expectation conditioned on randomness generated (strictly) prior to round t, i.e. conditionally to \u03c3(x \u03c4 , \u03c4 \u2264 t \u2212 1). We first bound the quantity\nE t\u22121 ||x t \u2212 x * || 2 = E t\u22121 ||x t\u22121 + \u2206x t \u2212 x * || 2 , Et\u22121||x t \u2212 x * || 2 = Et\u22121||x t\u22121 \u2212 x * || 2 + Et\u22121||\u2206x t || 2 + 2 Et\u22121[\u2206x t |y0], x t\u22121 \u2212 x * = ||x t\u22121 \u2212 x * || 2 + Et\u22121||\u2206x t || 2 + 2 \u2212\u03b7 KM k\u2208[K],i\u2208[M ] E[\u2207Fi(y k\u22121 i )|y0] by (9) , x t\u22121 \u2212 x * \u2264 Et\u22121||x t\u22121 \u2212 x * || 2 + 4\u03b7 2 \u03bd 2 Et + 8\u03bd 2\u03b72 Ft\u22121 + 8\u03bd\u03b7 2 F (x t\u22121 ) \u2212 F (x * ) + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)) + 2\u03b7 KM Et\u22121 \uf8ee \uf8f0 k\u2208[K],i\u2208[M ] \u2207Fi(y k\u22121 i ), x * \u2212 x t\u22121 \uf8f9 \uf8fb A , (Lemma C.4) where E[A] \u2264 2\u03b7 KM E \uf8eb \uf8ed k\u2208[K],i\u2208[M ] F i (x * ) \u2212 F i (x t\u22121 ) + \u03bd||y k\u22121 i \u2212 x t\u22121 || 2 \u2212 \u00b5 4 ||x t\u22121 \u2212 x * || 2 \uf8f6 \uf8f8 = \u22122\u03b7 E(F (x t\u22121 )) \u2212 F (x * ) + \u00b5 4 E||x t\u22121 \u2212 x * || + 2\u03bd\u03b7E t ,\nwhere the inequality comes from the convexity and \u03bd-smoothness property.\n\nHence, by taking the expectation:\nE||x t \u2212 x * || 2 \u2264 E||x t\u22121 \u2212 x * || 2 \u2212 2\u03b7 E(F (x t\u22121 )) \u2212 F (x * ) + \u00b5 4 E||x t\u22121 \u2212 x * || 2 + 2\u03bd\u03b7E t + 4\u03b7 2 \u03bd 2 E t + 8\u03bd 2\u03b72 F t\u22121 + 8\u03bd\u03b7 2 E F (x t\u22121 ) \u2212 F (x * ) + 9\u03b7 2 KlM (\u03c2 2 /sR + \u03a3 2 g (C)).\nBy combining all terms and multiplying by \u03bd on each side of the inequality, it comes:\n\u03bdE||x t \u2212 x * || 2 \u2264 1 \u2212 \u00b5\u03b7 2 \u03bdE||x t\u22121 \u2212 x * || 2 + (8\u03bd 2\u03b72 \u2212 2\u03b7\u03bd) E(F (x t\u22121 )) \u2212 F (x * )(10)\n+ 9\u03b7 2 \u03bd KlM (\u03c2 2 /sR + \u03a3 2 g (C)) + (2\u03bd 2\u03b7 + 4\u03bd 3\u03b72 )E t + 8\u03bd 3\u03b72 F t\u22121 .\n\nWe now consider \u03b1 \u2208 [1/2, 1], \u03b7 l \u2264 1 24K\u03bd\u03b7g l \u03b1 and \u03b7 g \u2265 1. We use the result of Lemma C.5 where each side is multiplied by 27\u03bd 3\u03b72 1 l to obtain:\n\n\n2.\n\nLet us now prove the result of Lemma C.8 for the convex case. Let \u03b7 g \u2265 1,\u03b7 l = min l 2 3 24\u03bdK\u03b7g ,\nD0 \u221a KlM K\u03b7g \u221a T (1+lM/\u03b7 2 g )(\u03c2 2 /sR+\u03a3g(C) 2 )\nand T \u2265 1. By averaging over t in Lemma C.7 with \u00b5 = 0, we have for any \u03b7 l \u2264\u03b7 l (recalling that\u03b7 = K\u03b7 g \u03b7 l )\n1 T T t=1 E F (x t\u22121 ) \u2212 F (x * ) \u2264 2 \u03b7T {D 2 0 + 27\u03bd 2\u03b72 1 l F 0 } + 20\u03b7 KlM 1 + lM \u03b7 2 g (\u03c2 2 /sR + \u03a3 2 g (C)) \u2264 48\u03bd l 2 3 T D 2 0 + 22D 0 \u03c2/ \u221a sR + \u03a3 g (C) \u221a T KlM 1 + lM \u03b7 2 g ,\nusing that F 0 = 0 and \u03c2 2 /sR + \u03a3 2 g (C) \u2264 (\u03c2/ \u221a sR + \u03a3 g (C)) 2 . The result of Lemma C.8 is thus straightforward by using the convexity of F and considering w t = 1/T .\n\n\nConclusion.\n\nWe obtain the result of Theorem C.1 for the convex case with Lemma C.8 and \u03b7 g := \u221a lM \u2265 1.\n\n\nC.4 Proof of Theorem C.1 (Non-Convex case)\n\nTo state this result, we adapt the original proof in the case with a larger variance for DP-noised stochastic gradients (see Lemma C.1), which gives the following result.\n\nLemma C.9 (Convergence of DP-SCAFFOLD-warm with non-convex loss functions). If f i are non-convex, \u03b7 g \u2265 1,\u03b7 l = l 2 3 24\u03bdK\u03b7g and T \u2265 1, then there exist weights {w t } and local step-sizes \u03b7 l \u2264\u03b7 l such that\nx T = t\u2208[T ] w t x t and E||\u2207F (x T )|| 2 \u2264 O F 0 \u03c2/ \u221a sR + \u03a3 g (C) \u221a T KlM 1 + lM \u03b7 2 g + \u03bd T F 0 1 l 2 3 , where F 0 := F (x 0 ) \u2212 F (x * ).\nConclusion. We obtain the result of Theorem C.1 with Lemma C.9 and \u03b7 g := \u221a lM \u2265 1.\n\n\nC.5 Theorem of Convergence for DP-FedAvg\n\nTheorem C.2 (Utility rates of DP-FedAvg(T, K, l, s, \u03c3 g , C), \u03c3 g chosen arbitrarily). Let \u03c3 g , C > 0, x 0 \u2208 R d . Suppose we run DP-FedAvg(T, K, l, s, \u03c3 g , C) (see Algorithm 2). Under Assumptions 2 and 3, we consider the sequence of iterates (x t ) t\u22650 of the algorithm, starting from x 0 .\n\n1. If F i are \u00b5-strongly convex (\u00b5 > 0), \u03b7 g = \u221a lM ,\u03b7 l = 1 8(1+B 2 )\u03bdK\u03b7g and T \u2265 8(1+b 2 )\u03bd \u00b5 , then there exist weights {w t } t\u2208[T ] and local step-sizes \u03b7 l \u2264\u03b7 l such that the averaged output of DP-FedAvg(T, K, l, s, \u03c3 g , C), defined by x T = t\u2208[T ] w t x t , has expected excess of loss such that:\nE[F (x T )] \u2212 F (x * ) \u2264 O \u03c2 2 /sR + \u03a3 2 g (C) \u00b5T KlM + (1 \u2212 l) G 2 \u00b5T lM + \u03bdG 2 \u00b5 2 T 2 + \u00b5D 2 0 exp \u2212 \u00b5 16(1 + B 2 )\u03bd T ,\n2. If F i are convex, \u03b7 g = \u221a lM ,\u03b7 l = 1 8(1+B 2 )\u03bdK\u03b7g and T \u2265 1, then there exist weights {w t } t\u2208[T ] and local step-sizes \u03b7 l \u2264\u03b7 l such that the averaged output of DP-FedAvg(T, K, l, s, \u03c3 g , C), defined by x T = t\u2208[T ] w t x t , has expected excess of loss such that:\nE[F (x T )] \u2212 F (x * ) \u2264 O D 0 \u03c2/ \u221a sR + \u03a3 g (C) \u221a T KlM + GD 0 \u221a 1 \u2212 l \u221a T lM + D 4/3 0 \u03bd 1/3 G 2/3 T 2/3 + B 2 \u03bdD 2 0 T ,\n3. If F i are non-convex, \u03b7 g = \u221a lM ,\u03b7 l = 1 8(1+B 2 )\u03bdK\u03b7g and T \u2265 1, then there exist weights {w t } t\u2208[T ] and local step-sizes \u03b7 l \u2264\u03b7 l such that the randomized output of DP-SCAFFOLD-warm(T, K, l, s, \u03c3 g , C), defined by {x T = x t with probability w t for all t}, has expected squared gradient of the loss such that:\nE||\u2207F (x T )|| 2 \u2264 O \u03bd \u221a F \u03c2/ \u221a sR + \u03a3 g (C) \u221a T KlM + \u03bdG F (1 \u2212 l) \u221a T lM + F 2/3 \u03bd 1/3 G 2/3 T 2/3 + B 2 \u03bdF T , where D 0 := ||x 0 \u2212 x * || and F := F (x 0 ) \u2212 F (x * ).\nProof. To state the result of Theorem C.2, we combine the original result (Karimireddy et al., 2020b, Theorem V) provided for any type of loss functions with the result of Lemma C.1.\n\n\nD ADDITIONAL EXPERIMENTS DETAILS AND RESULTS\n\nIn this section, we give additional details on our experimental setup (Section D.1) and synthetic data generation process (Section D.2), and provide additional results (Section D.3). All results are summarized in Table 3.  Hyperparameter tuning. We tuned the step-size hyperparameter \u03b7 0 for each dataset, each algorithm and each version (with or without DP) over a grid of 10 values with the lowest level of heterogeneity (5-fold cross validation conducted on the training set). We then kept the same \u03b7 0 for experiments with higher heterogeneity.\n\nClipping heuristic. Setting a good clipping threshold C while preserving accuracy can be difficult (McMahan et al., 2018). Indeed, if C is too small, the clipped gradients may become biased, thereby affecting the convergence rate. On the other hand, if C is too large, we have to add more noise to stochastic gradients to ensure differential privacy (since the variance of the Gaussian noise is proportional to C 2 ). In practice, we follow the strategy proposed by Abadi et al. (2016), which consists in setting C as the median of the norms of the unclipped gradients over each stage of local training. Throughout the iterations, C will then decrease. However, we are aware that locally setting C may leak information to the server about the magnitude of stochastic gradients. We here consider this leak as minor and neglect its impact on privacy guarantees. Adaptive clipping (Andrew et al., 2021) could be used to mitigate these concerns.\n\nDeep neural network. To prove the advantage of DP-SCAFFOLD with non-convex objectives, we perform experiments on MNIST data with a deep neural network. Its architecture is inspired by the network used by Abadi et al. (2016) for DP-SGD. We use a feedforward neural network with ReLU units and softmax of 10 classes (corresponding to the 10 digits of MNIST) with cross-entropy loss. Our network combines a 60-dimensional Principal Component Analysis (PCA) projection layer and a hidden layer with 200 hidden units. Since the error bound for DP-FL algorithms grows linearly with the dimension of the parameters for non-convex objectives (see Theorems C.1,C.2), the PCA layer is actually necessary to prevent the curse of dimensionality due to the addition of noise for privacy. Note that neural networks with more layers would also suffer from the curse of dimensionality in the DP-FL context. Using a batch size of 500, we can reach a test accuracy higher than 98% with this architecture in 100 epochs under the centralized setting. This result is consistent with what can be achieved with a vanilla neural network (LeCun et al., 1998). In our framework, the PCA procedure is applied as preprocessing to all the samples without differential privacy. To avoid privacy leakage at this step, it would need to include a private mechanism, whose privacy loss should be added to that of the training phase (see the discussion in Abadi et al., 2016, Section 4).\n\n\nD.2 Synthetic Data Generation\n\nEach ground-truth model for user i consists in weights W i \u2208 R d \u00d710 and bias b i \u2208 R 10 , which are sampled from the following distributions: ). The labels are obtained by independently changing the labels given by the ground truth model with probability 0.05.\nW i |u i \u223c N d \u00d710 (u i , Id) and b i |u i \u223c N 10 (u i , Id) where u i \u223c N d \u00d710 (0, \u03b1Id) and u i \u223c N 10 (0, \u03b1Id). The data matrix X i of user i is sampled according to X i |v i \u223c N d (v i , \u03a3) where \u03a3 is the covariance matrix defined by its diagonal \u03a3 j,j = j \u22121.2 and v i |B i \u223c N d (B i , Id) where B i \u223c N d (0, \u03bdId\n\nD.3 Additional Experimental Results\n\nWe provide below more results on the experiments described in Section 5, including additional metrics and more extensive choices of heterogeneity levels. We also present additional experiments with higher privacy, including a study on the effect of sampling parameters l and s (and the trade-off with T ) on privacy and convergence.\n\nMetrics. To measure the convergence and performance of the algorithms at any communication round t \u2208 [T ], we consider the following metrics:\n\n\u2022 Accuracy(t): the average test accuracy of the model over all users,\n\n\u2022 Train Loss(t)= log 10 (F (x t ) \u2212 F (x * )): the log-gap between the objective function evaluated at parameter x t and its minimum,\n\u2022 Train Gradient Dissimilarity(t)= 1 M M i=1 ||\u2207F i (x t )|| 2 \u2212 ||\u2207F (x t )|| 2 ,\nand similarly the Train Gradient Log-\nDissimilarity(t)= log 1 M M i=1 ||\u2207F i (x t )|| 2 \u2212 log ||\u2207F (x t )|| 2 ,\nwhich measure how the local gradients differ from the global gradient (i.e., the average across users) when evaluated at x t , and hence quantify the user-drift over the rounds of communication.\n\n\nD.3.1 Results with other metrics and different heterogeneity levels\n\nWe provide below some additional results which complement those provided in Section 5.\n\n\u2022 Synthetic data. We plot in Fig. 3 the evolution of the accuracy over the rounds, which is consistent with the evolution of the train loss in Fig. 1. While the variance of the accuracy for DP-FedAvg grows with the heterogeneity, the results of DP-SCAFFOLD-warm are not affected. We can observe an average difference of 10% in the accuracy for these two algorithms over the various heterogeneity settings. We provide in Fig. 4 the evolution of the gradient dissimilarity for the same settings as in Fig. 1 and Fig. 3, which once again shows a better convergence of DP-SCAFFOLD-warm compared to DP-FedAvg for the same privacy level. We also provide the evolution of the train loss when varying a single heterogeneity parameter: either \u03b1 (which controls model heterogeneity across users) in Fig. 5 or \u03b2 (which controls data heterogeneity across users) in Fig. 6. In both of these settings, DP-SCAFFOLD-warm performs consistently better.\n\n\u2022 FEMNIST data. In Fig. 7, we put in perspective the accuracy observed with K = 50 (see Fig. 2, first row) with the one observed with K = 100. We also show the evolution of the gradient dissimilarity in Fig. 8. These results on real data again show the superior performance of DP-SCAFFOLD-warm, consistently with our observations on synthetic data.       In Section 5 of the main text, we presented these trade-offs for DP-SCAFFOLD under a high level of heterogeneity (see Table 1). We provide below the results of these trade-offs for DP-SCAFFOLD with a lower level of heterogeneity (\u03b1, \u03b2) = (0, 0) (see Table 4). We consider again synthetic data with = 3 towards any third party. To report the test accuracy which is obtained at the end of the iterations, we proceed in two steps: (i) we compute the average test accuracy over the last 10% of the iterations for each random run, (ii) we calculate the mean and the standard deviation over the 3 runs and report them in the tables. We highlight in bold for each row (i.e., for each value of \u03c3 g ) in Tables 1,4 the best accuracy score obtained over all values of K.\n\nWe observe the same trends as the ones described for Table 1 in the main text. Indeed, our results clearly show a trade-off between T and K for DP-SCAFFOLD under a fixed privacy budget. If K is set too low or too large, the performance of the algorithm is sub-optimal either because T has to be chosen too low or because control variates are inefficient under few local updates.\n\nMoreover, we observe that setting \u03c3 g to a high value does not necessarily improve the gain in the number of communication rounds. In particular, for high values of \u03c3 g , the calculation of the privacy bound does not allow to obtain a large increase in T (T does not change between \u03c3 g = 40 and \u03c3 g = 160 for any value of K), which thus leads to poor performance. This can be explained by the fact that the upper bound for the subsampled Gaussian mechanism given in Lemma B.7 does not converge to 0 when \u03c3 g is very large. Indeed, given a subsampling ratio q < 1, we can observe that this bound in the asymptotic regime becomes 1 \u03b1\u22121 log(1 + 2 \u03b1 j=3 q j \u03b1 j ), which is positive. Hence, by increasing the value of \u03c3 g , we cannot hope to inconditionally increase the number of compositions of the mechanism under a fixed privacy budget, if q is taken too large. This artefact thus proves how small subsampling ratios have to be chosen to compute differential privacy in practice. In our experiments, we can clearly notice that this asymptotic regime is reached as soon as \u03c3 g is greater than 80. One would have to consider lower subsampling ratios (for instance l = 10 \u22124 , s = 10 \u22124 ), to obtain different values for T when \u03c3 g = 80 and \u03c3 g = 160. We investigate such trade-offs in the next section.\n\n\nD.3.3 Experiments under higher privacy regime and role of sampling parameters\n\nIn Section 5 of the main text, given private parameter \u03c3 g , we conducted experiments for (i) convex objective on FEMNIST (\u03c3 g = 30) and synthetic data (\u03c3 g = 60) and (ii) non-convex objective on MNIST data (\u03c3 g = 30). Considering the sampling parameters we used (l = 0.2, s = 0.2), this setting allows to reach, towards any third party, (11.4, \u03b4)-DP for FEMNIST data and (13, \u03b4)-DP for synthetic data. In the case of MNIST data, we obtain (7.2, \u03b4)-DP towards any third party for (K, T ) = (50, 100). Although these experiments only allow \"low privacy\", stronger DP guarantees can be obtained by simply decreasing the subsampling ratios (thus amplifying the privacy). For instance, setting l = l/4 = 0.05 in case of synthetic data would provide (4.2, \u03b4)-DP for (K, T ) = (50, 400). We present below some results on numerical trade-offs under a higher privacy regime.\n\nAs observed in the experiments of the main text and consistently with previous work (Karimireddy et al., 2020b), we observe the superiority of SCAFFOLD over FedAvg and FedSGD under heterogeneous data, but most importantly our results show that this hierarchy is preserved in our DP-FL framework with privacy constraints: this is especially clear with growing heterogeneity and with growing number K of local updates. Besides this, the results provided for logistic regression in the privacy regime numerically demonstrate that DP-SCAFFOLD sometimes even outperforms (non-private) FedAvg despite the local injection of Gaussian noise, see for instance Fig. 1-10 and Fig. 2 (bottom row), and to a lesser extent Fig. 9. Therefore, our results are quite promising with respect to obtaining efficient DP-FL algorithms under heterogeneous data for higher privacy regimes.\n\nTrade-offs between l and T . In this section, we compare the robustness of DP-FedAvg and DP-SCAFFOLD w.r.t. user sampling ratio l, under a fixed privacy bound towards a third party. We fix parameters s = 0.2, K = 10 and report in Figure 9 the evolution of the test accuracy of these algorithms for l \u2208 {0.08, 0.1, 0.12} over the communication rounds. For each value of l, the number of communication rounds T l is determined to be maximal w.r.t. to the privacy bound, so that the desired privacy level is achieved for the output after T l rounds. These values of T l are represented on Figure 9 with red vertical lines (note that the higher l, the lower T l ). We conduct this experiment on the following datasets: synthetic data with = 5 (Fig 9, first row), FEMNIST data with LogReg model, = 5 (Fig 9, second row) and MNIST data with DNN model, = 3 (Fig 9, third row).\n\nOur results first show that DP-SCAFFOLD achieves much better performance than DP-FedAvg in these high privacy regimes. The superiority of DP-SCAFFOLD towards DP-FedAvg is especially strong under high heterogeneity: we notice a gap of 20% in the accuracy score with synthetic data for (\u03b1, \u03b2) = (5, 5) and FEMNIST data for \u03b3 = 0% with logistic regression model, a gap of 10% in the accuracy score for MNIST data with \u03b3 = 0% and DNN. Furthermore, DP-SCAFFOLD is robust to a low value of user sampling parameter l. We observe that we obtain the best performance by choosing l = 0.08 (the lowest value considered), which allows to set T l to a high value. Note that the evolution of the accuracy is similar for all values of l. Therefore, setting a low l provides an effective way to achieve good accuracy with higher privacy. Trade-offs between s and T . In this section, we compare the behavior of DP-FedAvg and DP-SCAFFOLD w.r.t. data sampling ratio s under a fixed privacy bound towards a third party. We fix parameters l = 0.1, K = 10 and report in Figure 10 the evolution of the test accuracy of these algorithms for s \u2208 {0.05, 0.1, 0.2} over the communication rounds. For each value of s, the number of communication rounds T s is determined to be maximal w.r.t. to the privacy bound, so that the desired privacy level is achieved for the output after T s rounds. These values of T s are represented on Figure 10 with red vertical lines (note that the higher s, the lower T ). We conduct this experiment for the following datasets: synthetic data with = 5 (Fig 10, first row), FEMNIST data with LogReg model, = 5 (Fig 10, second row) and MNIST data with DNN model, = 3 (Fig 10, third row).\n\nOur results confirm that DP-SCAFFOLD leads to better performance than DP-FedAvg with any value of s \u2208 {0.2, 0.1, 0.05} under heterogeneity (as expected, we obtain very similar accuracy scores for these two algorithms with \u03b3 = 100% for FEMNIST and MNIST data). However, this superiority decreases as s decreases. Consider for instance FEMNIST data with 10% similarity: the gap in accuracy drops from 30% with s = 0.2, to less than 20% with s = 0.1. Our results seem to show that we obtain better performance with a high value of s, although it implies to set T s to a lower value. This is contrast to the effect of l shown in  \n\nFederated\nLearning (FL) enables a set of users with local datasets to collaboratively train a machine learning model without centralizing data (Kairouz et al., Proceedings of the 25 th International Conference on Artificial Intelligence and Statistics (AISTATS) 2022, Valencia, Spain. PMLR: Volume 151. Copyright 2022 by the author(s).\n\nFigure 1 :\n1Train Loss On Synthetic Data ( = 13). First Row: K = 50; Second Row: K = 100.\n\nFigure 2 :\n2Test Accuracy With K = 50. First Row: FEMNIST (LogReg), = 11.4; Second Row: MNIST (DNN), = 7.2.\n\n\n{1, 2, ..., n} for any n \u2208 N M , i \u2208 [M ] number and index of users T , t \u2208 [T ] number and index of communication rounds K, k \u2208 [K] number and index of local updates (for each user) D i local dataset held by the i-th user, composed of points d i 1 , . . . , d i R R size of any local dataset\n\n\nSimple composition (Dwork et al., 2010, Theorem III.1.) states that the privacy parameters grow linearly with T . Dwork et al. (2010) provide a strong composition result where the parameter grows sublinearly with T . This result is recalled in Lemma B.1. Lemma B.1 (Strong adaptive composition, Dwork et al., 2010). Let M 1 , ..., M T be T adaptive ( , \u03b4)-DP mechanisms. Then, for any \u03b4 > 0, the mechanism M = (M 1 , ..., M T ) is ( , \u03b4)-DP where: =2T log(1/\u03b4 ) + T (e \u2212 1) and \u03b4 = T \u03b4 + \u03b4 .\n\n\nAbadi et al. (2016)  demonstrated in practice that the privacy bounds provided by standard ( , \u03b4)-DP theory (see Section B.1) often overestimate the actual privacy loss. In order to better express inequalities on the tails of the output distributions of private algorithms, we introduce the privacy loss random variable(Dwork and Roth, 2014; Abadi et al., 2016; Wang et al., 2020). Given a random mechanism M , let M (D) and M (D ) be the distributions of the output when M is run on D and D respectively. The privacy loss L M D,D is defined as: L M D,D (\u03b8) := log M (D)(\u03b8) M (D )(\u03b8) where \u03b8 \u223c M (D).\n\n\nof DP-SCAFFOLD over DP-FedAvg MNIST DNN Fig 2 (second row) Superiority of DP-SCAFFOLD over DP-FedAvg Synthetic LogReg Tables 1,4 Tradeoffs between K, T and \u03c3 g under fixed Synthetic, FEMNIST LogReg Fig 9 (first, second rows) Tradeoffs between T and l under fixed MNIST DNN Fig 9 (third row) Tradeoffs between T and l under fixed Synthetic, FEMNIST LogReg Fig 10 (first, second rows) Tradeoffs between T and s under fixed MNIST DNN Fig 10 (third row) Tradeoffs between T and s under fixed D.1 Algorithms Setup\n\nFigure 3 :\n3Test Accuracy On Synthetic Data ( = 13). First Row: K = 50; Second Row: K = 100.\n\nFigure 4 :\n4Train Gradient Dissimilarity On Synthetic Data ( = 13). First Row: K = 50; Second Row: K = 100.\n\nFigure 5 :\n5Model Heterogeneity (Varying \u03b1): Train Loss On Synthetic Data ( = 13). First Row: K = 50; Second Row: K = 100.\n\nFigure 6 :\n6Data Heterogeneity Varying \u03b2): Train Loss On Synthetic Data ( = 13). First Row: K = 50; Second Row: K = 100.\n\nFigure 7 :\n7Test Accuracy On FEMNIST Data (LogReg) with = 11.5. First Row: K = 50; Second Row: K = 100.\n\nFigure 8 :\n8Train Gradient Dissimilarity On FEMNIST Data (LogReg) with = 11.5. First Row: K = 50; Second Row: K = 100.\n\nFigure 9 :\n9Test Accuracy With Various Values For l Under Fixed Privacy Budget. First Row: Synthetic data ( = 5); Second Row: FEMNIST data (LogReg, = 5); Third Row: MNIST (DNN, = 3).\n\n\nFig 9.\n\nFigure 10 :\n10Test Accuracy With Various Values For s Under Fixed Privacy Budget. First Row: Synthetic Data ( = 5); Second Row: FEMNIST Data (LogReg, = 5); Third Row: MNIST Data (DNN, = 3).\n\n\n\u00b12.62 T = 546 24.41 \u00b10.81 T = 506 27.33 \u00b10.37 T = 458 19.42 \u00b10.51 T = 362 14.08 \u00b10.14 T = 87 160 13.97 \u00b11.70 T = 546 15.99 \u00b10.30 T = 506 19.27 \u00b11.65 T = 458 14.86 \u00b10.75 T = 362 14.17 \u00b10.06 T = 8740 \n\n10 27.41 \u00b10.71 T = 542 45.53 \u00b10.99 T = 488 43.52 \u00b11.52 T = 428 42.51 \u00b10.80 T = 324 21.80 \u00b13.28 T = 72 \n20 27.34 \u00b11.31 T = 545 44.39 \u00b10.46 T = 502 43.47 \u00b11.74 T = 451 42.33 \u00b10.77 T = 352 20.14 \u00b12.67 T = 83 \n40 21.05 \u00b12.27 T = 546 34.50 \u00b10.65 T = 505 36.85 \u00b10.85 T = 457 33.24 \u00b10.41 T = 360 14.85 \u00b10.95 T = 86 \n80 17.61 \n\n\nMartin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In Durmus Alp Emre Acar, Yue Zhao, Ramon Matas, Matthew Mattina, Paul Whatmough, and Venkatesh Saligrama. Federated learning based on dynamic regularization. In International Conference on Learning Representations, 2021. Galen Andrew, Om Thakkar, H. Brendan McMahan, and Swaroop Ramaswamy. Differentially private learning with adaptive clipping. Advances in Neural Information Processing Systems, 34, 2021. Borja Balle, James Bell, Adri\u00e0 Gasc\u00f3n, and Kobbi Nissim. The privacy blanket of the shuffle model. In Annual International Cryptology Conference, pages 638-667. Springer, 2019. Aur\u00e9lien Bellet, Rachid Guerraoui, Mahsa Taziki, and Marc Tommasi. Personalized and private peer-topeer machine learning. In International Conference on Artificial Intelligence and Statistics, pages 473-481. PMLR, 2018. Albert Cheu, Adam Smith, Jonathan Ullman, David Zeber, and Maxim Zhilyaev. Distributed differential privacy via shuffling. In Annual International Conference on the Theory and Applications of Cryptographic Techniques, pages 375-403. Springer, 2019. Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik. Emnist: Extending mnist to handwritten letters. In 2017 international joint conference on neural networks (IJCNN), pages 2921-2926. IEEE, 2017. John C. Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(7), 2011. John C. Duchi, Michael I. Jordan, and Martin J. Wainwright. Local privacy and statistical minimax rates. In 2013 IEEE 54th Annual Symposium on Foundations of Computer Science, pages 429-438. IEEE, 2013. John C. Duchi, Michael I. Jordan, and Martin J. Wainwright. Minimax optimal procedures for locally private estimation. Journal of the American Statistical Association, 113(521):182-201, 2018. From local to central differential privacy via anonymity. In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 2468-2479. SIAM, 2019. Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with theoretical guarantees: A model-agnostic metalearning approach. Advances in Neural Information Processing Systems, 33:3557-3568, 2020. Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. Model inversion attacks that exploit confidence information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC conference on computer and communications security, pages 1322-1333, 2015. Jonas Geiping, Hartmut Bauermeister, Hannah Dr\u00f6ge, and Michael Moeller. Inverting gradients-how easy is it to break privacy in federated learning? Advances in Neural Information Processing Systems, 33:16937-16947, 2020. Robin C. Geyer, Tassilo Klein, and Moin Nabi. Differentially private federated learning: A client level perspective. arXiv preprint arXiv:1712.07557, 2017. Badih Ghazi, Rasmus Pagh, and Ameya Velingker. Scalable and differentially private distributed aggregation in the shuffled model. arXiv preprint arXiv:1906.08320, 2019. Antonious M. Girgis, Deepesh Data, and Suhas Diggavi. Renyi differential privacy of the subsampled shuffle model in distributed learning. Advances in Neural Information Processing Systems, 34, 2021a. Antonious M. Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and Ananda Theertha Suresh. Shuffled model of federated learning: Privacy, accuracy and communication trade-offs. IEEE Journal on Se-Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri, Sashank J. Reddi, Sebastian U. Stich, and Ananda Theertha Suresh. Mime: Mimicking centralized stochastic algorithms in federated learning. arXiv preprint arXiv:2008.03606, 2020a. Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International Conference on Machine Learning, pages 5132-5143. PMLR, 2020b. Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. What can we learn privately? SIAM Journal on Computing, 40(3):793-826, 2011. Ahmed Khaled, Konstantin Mishchenko, and Peter Richt\u00e1rik. Tighter theory for local sgd on identical and heterogeneous data. In International Conference on Artificial Intelligence and Statistics, pages 4519-4529. PMLR, 2020. Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated optimization in heterogeneous networks. Proceedings of Machine Learning and Systems, 2:429-450, 2020a. Yiwei Li, Tsung-Hui Chang, and Chong-Yung Chi. Secure federated averaging algorithm with differential privacy. In 2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP), pages 1-6. IEEE, 2020b. Othmane Marfoq, Giovanni Neglia, Aur\u00e9lien Bellet, Laetitia Kameni, and Richard Vidal. Federated multi-task learning under a mixture of distributions. Advances in Neural Information Processing Systems, 34, 2021. H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273-1282. PMLR, 2017. H. Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning differentially private recurrent language models. In International Conference on Learning Representations, 2018. Yurii Nesterov et al. Lectures on convex optimization, volume 137. Springer, 2004. Sashank J. Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Kone\u010dn\u1ef3, Sanjiv Kumar, and H. Brendan McMahan. Adaptive federated optimization. In International Conference on Learning Representations, 2020. agnostic distributed multitask optimization under privacy constraints. IEEE Transactions on Neural Networks and Learning Systems, 2020.Proceedings of the 2016 ACM SIGSAC conference \non computer and communications security, pages \n308-318, 2016. \n\nCynthia Dwork and Aaron Roth. The algorithmic \nfoundations of differential privacy. Foundations and \nTrends\u00ae in Theoretical Computer Science, 9(3-4): \n211-407, 2014. \n\nCynthia Dwork, Guy N. Rothblum, and Salil Vadhan. \nBoosting and differential privacy. In 2010 IEEE \n51st Annual Symposium on Foundations of Com-\nputer Science, pages 51-60. IEEE, 2010. \n\nUlfar Erlingsson, Vitaly Feldman, Ilya Mironov, \nAnanth Raghunathan, Kunal Talwar, and \nAbhradeep Thakurta. \nAmplification by shuf-\nfling: Diederik P. Kingma and Jimmy Ba. Adam: A \nmethod for stochastic optimization. arXiv preprint \narXiv:1412.6980, 2014. \n\nYann LeCun, L\u00e9on Bottou, Yoshua Bengio, and \nPatrick Haffner. Gradient-based learning applied to \ndocument recognition. Proceedings of the IEEE, 86 \n(11):2278-2324, 1998. \n\nIlya Mironov. R\u00e9nyi differential privacy. In 2017 \nIEEE 30th computer security foundations sympo-\nsium (CSF), pages 263-275. IEEE, 2017. \n\nFelix Sattler, Klaus-Robert M\u00fcller, and Wojciech \nSamek. \nClustered federated learning: Model-\nReza Shokri, Marco Stronati, Congzheng Song, and \nVitaly Shmatikov. Membership inference attacks \nagainst machine learning models. In 2017 IEEE \nSymposium on Security and Privacy (SP), pages 3-\n18. IEEE, 2017. \n\nAleksei Triastcyn and Boi Faltings. Federated learning \nwith bayesian differential privacy. In 2019 IEEE \nInternational Conference on Big Data (Big Data), \npages 2587-2596. IEEE, 2019. \n\nTim Van Erven and Peter Harremos. R\u00e9nyi divergence \nand kullback-leibler divergence. IEEE Transactions \non Information Theory, 60(7):3797-3820, 2014. \n\nJianyu Wang, Zachary Charles, Zheng Xu, Gauri \nJoshi, H. Brendan McMahan, Maruan Al-Shedivat, \nGalen Andrew, Salman Avestimehr, Katharine \nDaly, Deepesh Data, et al. A field guide to federated \noptimization. arXiv preprint arXiv:2107.06917, \n2021. \n\nYu-Xiang Wang, Borja Balle, and Shiva Ka-\nsiviswanathan. Subsampled R\u00e9nyi Differential Pri-\nvacy and Analytical Moments Accountant. Journal \nof Privacy and Confidentiality, 10(2), 2020. \n\nKang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H. \nYang, Farhad Farokhi, Shi Jin, Tony Q. S. Quek, \nand H. Vincent Poor. Federated learning with dif-\nferential privacy: Algorithms and performance anal-\nysis. IEEE Transactions on Information Forensics \nand Security, 15:3454-3469, 2020. \n\nYang Zhao, Jun Zhao, Mengmeng Yang, Teng Wang, \nNing Wang, Lingjuan Lyu, Dusit Niyato, and Kwok-\nYan Lam. Local Differential Privacy based Feder-\nated Learning for Internet of Things. IEEE Internet \nof Things Journal, 8(11):8836-8853, 2021. \nSupplementary Material: \nDifferentially Private Federated Learning on Heterogeneous Data \n\n\n\nTable 2 :\n2Summary of the main notations.Symbol \nDescription \n\n\n\nTable 3 :\n3Summary of the experiments of the paper. Superiority of DP-SCAFFOLD over DP-FedAvgDataset \nModel Reference \nTake-away message \nSynthetic \nLogReg Figs 1,3-6 \n\n\nTable 4 :\n4Test Accuracy (%) For DP-SCAFFOLD On Synthetic Data ( = 3, l = 0.05, s = 0.2, (\u03b1, \u03b2) = (0, 0)). \u00b10.50 T = 542 44.37 \u00b10.15 T = 488 44.17 \u00b10.56 T = 428 41.71 \u00b10.36 T = 324 25.92 \u00b10.90 T = 72 20 28.31 \u00b11.15 T = 545 41.97 \u00b10.77 T = 502 43.27 \u00b10.90 T = 451 41.13 \u00b10.55 T = 352 28.20 \u00b12.23 T = 83 40 21.07 \u00b10.41 T = 546 33.01 \u00b11.20 T = 505 35.96 \u00b10.84 T = 457 32.82 \u00b11.11 T = 360 23.49 \u00b11.70 T = 86 80 17.09 \u00b11.31 T = 546 21.84 \u00b10.96 T = 506 25.92 \u00b10.59 T = 458 24.02 \u00b11.27 T = 362 17.95 \u00b11.14 T = 87 160 15.24 \u00b11.63 T = 546 15.37 \u00b10.28 T = 506 20.09 \u00b11.51 T = 458 18.09 \u00b11.86 T = 362 15.38 \u00b10.87 T = 87 D.3.2 Additional results on the trade-offs between K, T and \u03c3 g\u03c3 g \nK = 1 \nK = 5 \nK = 10 \nK = 20 \nK = 40 \n\n10 31.29 \nThis happens with high probability: typically, after 4/l where l = o(1), all users have been selected at least once with probability 1 \u2212 e \u22124 \u2248 0.98.\n3 24\u03bdK\u03b7g and T \u2265 1, then there exist weights {w t } t\u2208[T ] and local step-sizes \u03b7 l \u2264\u03b7 l such that the randomized output of DP-SCAFFOLD-warm(T, K, l, s, \u03c3 g , C), defined by {x T = x t with probability w t for all t}, has expected squared gradient of the loss such that:\nTheorem C.1 (Utility rates for DP-SCAFFOLD-warm, \u03c3 g chosen arbitrarily). Let \u03c3 g , C > 0, x 0 \u2208 R d . Suppose we run DP-SCAFFOLD-warm(T, K, l, s, \u03c3 g , C) with initial local controls such that c 0 i = 1 K K k=1H k i (x 0 ) for any i \u2208[M ]. Under Assumptions 2 and 3, we consider the sequence of iterates (x t ) t\u22650 of the algorithm, starting from x 0 .1. If F i are \u00b5-strongly convex (\u00b5 > 0), \u03b7 g = \u221a lM ,\u03b7 l = minthen there exist weights {w t } t\u2208[T ] and local step-sizes \u03b7 l \u2264\u03b7 l such that the averaged output of DP-SCAFFOLD-warm(T, K, l, s, \u03c3 g , C), defined by x T = t\u2208[T ]w t x t , has expected excess of loss such that:and T \u2265 1, then there exist weights {w t } t\u2208[T ] and local step-sizes \u03b7 l \u2264\u03b7 l such that the averaged output of DP-SCAFFOLD-warm(T, K, l, s, \u03c3 g , C), defined by x T = t\u2208[T ] w t x t , has expected excess of loss such that:Since we have \u03b7 l \u2264 1 24K\u03bd\u03b7g , we recall the result from Lemma C.6:By summing inequalities(10),(11),(12), we obtain:We now consider \u03b7 l \u2264 l/54\u00b5K\u03b7 g . Then\u03b7 \u2264 l/54\u00b5 and we recall that \u03bd\u03b7 \u2264 1/24. We fix \u03b1 = 2/3 (then 2\u22122\u03b1 = \u03b1).In this part, we aim at simplifying the terms on the right side of the last inequality.Simplifying(13):Simplifying(14):Simplifying (15):Since l 2\u03b1\u22122 \u03bd\u03b7 = \u03bd\u03b7 1 l 2/3 \u2264 1/24, We then obtain the final result by dividing by \u03bd on each side of the inequality.Lemma C.8 (Convergence of DP-SCAFFOLD-warm with convex loss functions).If f i are \u00b5-strongly convex (\u00b5 > 0), \u03b7 g \u2265 1,\u03b7 l = minand T \u2265 1, then there exist weights {w t } and local step-sizes \u03b7 l \u2264\u03b7 l such thatProof. We denote D 0 := ||x 0 \u2212 x * ||.1. Let us first prove the result of Lemma C.8 for the strongly convex case. We start by unrolling the contraction inequality obtained in Lemma C.7. Let \u03b7 g \u2265 1 and\u03b7 l = min l 2 3 24\u03bdK\u03b7g , l 54\u00b5K\u03b7g . We define\u03b7 max = K\u03b7 g\u03b7l . In particular, we have\u03b7 max \u2208 (0, 2/\u00b5]. For any\u03b7 \u2264\u03b7 max and any t \u2265 1, we have by Lemma C.7where A t = 2E||x t \u2212 x * || 2 + 54\u03bd 2\u03b72 1 l F t and C = 20). We invoke a technical contraction result used in the original proof (Karimireddy et al., 2020b, Lemma 1) to obtain that there exist weights {w t } and local step-sizes \u03b7 l \u2264\u03b7 l such thatrecalling that\u03b7 = K\u03b7 g \u03b7 l . We now define x T = t\u2208[T ]w t x t , and directly obtain the result of Lemma C.8 using the convexity of F and the last bound,", "annotations": {"author": "[{\"end\":81,\"start\":67},{\"end\":98,\"start\":82},{\"end\":230,\"start\":99},{\"end\":351,\"start\":231},{\"end\":386,\"start\":352}]", "publisher": null, "author_last_name": "[{\"end\":80,\"start\":75},{\"end\":97,\"start\":91}]", "author_first_name": "[{\"end\":74,\"start\":67},{\"end\":90,\"start\":82}]", "author_affiliation": "[{\"end\":229,\"start\":100},{\"end\":350,\"start\":232},{\"end\":385,\"start\":353}]", "title": "[{\"end\":64,\"start\":1},{\"end\":450,\"start\":387}]", "venue": null, "abstract": "[{\"end\":4191,\"start\":452}]", "bib_ref": "[{\"end\":4868,\"start\":4847},{\"end\":4894,\"start\":4868},{\"end\":5175,\"start\":5153},{\"end\":5282,\"start\":5260},{\"end\":5353,\"start\":5332},{\"end\":5484,\"start\":5448},{\"end\":5515,\"start\":5489},{\"end\":5724,\"start\":5702},{\"end\":5743,\"start\":5724},{\"end\":5771,\"start\":5743},{\"end\":6765,\"start\":6738},{\"end\":7110,\"start\":7091},{\"end\":7165,\"start\":7150},{\"end\":7307,\"start\":7287},{\"end\":8235,\"start\":8206},{\"end\":8409,\"start\":8388},{\"end\":8591,\"start\":8564},{\"end\":8847,\"start\":8811},{\"end\":9226,\"start\":9194},{\"end\":9584,\"start\":9565},{\"end\":9979,\"start\":9959},{\"end\":10080,\"start\":10054},{\"end\":10110,\"start\":10082},{\"end\":10326,\"start\":10307},{\"end\":10776,\"start\":10751},{\"end\":10796,\"start\":10776},{\"end\":10817,\"start\":10796},{\"end\":11121,\"start\":11106},{\"end\":11203,\"start\":11181},{\"end\":11697,\"start\":11677},{\"end\":11718,\"start\":11697},{\"end\":11934,\"start\":11915},{\"end\":12243,\"start\":12222},{\"end\":12385,\"start\":12366},{\"end\":12745,\"start\":12728},{\"end\":13178,\"start\":13158},{\"end\":13196,\"start\":13178},{\"end\":13215,\"start\":13196},{\"end\":13481,\"start\":13460},{\"end\":13730,\"start\":13710},{\"end\":13748,\"start\":13730},{\"end\":13767,\"start\":13748},{\"end\":13791,\"start\":13767},{\"end\":13940,\"start\":13923},{\"end\":16695,\"start\":16674},{\"end\":18466,\"start\":18451},{\"end\":18486,\"start\":18468},{\"end\":19142,\"start\":19127},{\"end\":19529,\"start\":19484},{\"end\":19570,\"start\":19529},{\"end\":21021,\"start\":21001},{\"end\":22084,\"start\":22080},{\"end\":22702,\"start\":22699},{\"end\":22862,\"start\":22842},{\"end\":23596,\"start\":23575},{\"end\":24295,\"start\":24291},{\"end\":26642,\"start\":26616},{\"end\":27119,\"start\":27115},{\"end\":27215,\"start\":27211},{\"end\":27362,\"start\":27336},{\"end\":29055,\"start\":29038},{\"end\":29566,\"start\":29540},{\"end\":29870,\"start\":29850},{\"end\":34770,\"start\":34749},{\"end\":34791,\"start\":34770},{\"end\":34811,\"start\":34791},{\"end\":39021,\"start\":38991},{\"end\":39514,\"start\":39485},{\"end\":52901,\"start\":52879},{\"end\":53070,\"start\":53049},{\"end\":59733,\"start\":59707},{\"end\":61336,\"start\":61310},{\"end\":62102,\"start\":62075},{\"end\":65238,\"start\":65201},{\"end\":65563,\"start\":65526},{\"end\":71462,\"start\":71440},{\"end\":71826,\"start\":71807},{\"end\":72507,\"start\":72488},{\"end\":73417,\"start\":73397}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":84698,\"start\":84362},{\"attributes\":{\"id\":\"fig_1\"},\"end\":84789,\"start\":84699},{\"attributes\":{\"id\":\"fig_2\"},\"end\":84898,\"start\":84790},{\"attributes\":{\"id\":\"fig_3\"},\"end\":85193,\"start\":84899},{\"attributes\":{\"id\":\"fig_4\"},\"end\":85687,\"start\":85194},{\"attributes\":{\"id\":\"fig_5\"},\"end\":86290,\"start\":85688},{\"attributes\":{\"id\":\"fig_7\"},\"end\":86801,\"start\":86291},{\"attributes\":{\"id\":\"fig_8\"},\"end\":86895,\"start\":86802},{\"attributes\":{\"id\":\"fig_9\"},\"end\":87004,\"start\":86896},{\"attributes\":{\"id\":\"fig_10\"},\"end\":87128,\"start\":87005},{\"attributes\":{\"id\":\"fig_11\"},\"end\":87250,\"start\":87129},{\"attributes\":{\"id\":\"fig_12\"},\"end\":87355,\"start\":87251},{\"attributes\":{\"id\":\"fig_13\"},\"end\":87475,\"start\":87356},{\"attributes\":{\"id\":\"fig_14\"},\"end\":87659,\"start\":87476},{\"attributes\":{\"id\":\"fig_15\"},\"end\":87668,\"start\":87660},{\"attributes\":{\"id\":\"fig_16\"},\"end\":87859,\"start\":87669},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":88380,\"start\":87860},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":97101,\"start\":88381},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":97166,\"start\":97102},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":97336,\"start\":97167},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":98063,\"start\":97337}]", "paragraph": "[{\"end\":5283,\"start\":4214},{\"end\":6320,\"start\":5285},{\"end\":6982,\"start\":6322},{\"end\":7686,\"start\":6984},{\"end\":8127,\"start\":7688},{\"end\":9902,\"start\":8144},{\"end\":11173,\"start\":9904},{\"end\":11935,\"start\":11175},{\"end\":14176,\"start\":11937},{\"end\":14423,\"start\":14178},{\"end\":14633,\"start\":14439},{\"end\":14772,\"start\":14666},{\"end\":15108,\"start\":14858},{\"end\":15430,\"start\":15190},{\"end\":15662,\"start\":15490},{\"end\":16841,\"start\":15680},{\"end\":17028,\"start\":16843},{\"end\":17571,\"start\":17030},{\"end\":17918,\"start\":17573},{\"end\":17951,\"start\":17920},{\"end\":19219,\"start\":17953},{\"end\":19745,\"start\":19268},{\"end\":20034,\"start\":19747},{\"end\":20278,\"start\":20062},{\"end\":20649,\"start\":20280},{\"end\":21172,\"start\":20651},{\"end\":21214,\"start\":21174},{\"end\":21884,\"start\":21216},{\"end\":22086,\"start\":21896},{\"end\":22183,\"start\":22088},{\"end\":22270,\"start\":22185},{\"end\":23077,\"start\":22621},{\"end\":23345,\"start\":23079},{\"end\":24333,\"start\":23409},{\"end\":24604,\"start\":24581},{\"end\":24893,\"start\":24705},{\"end\":25236,\"start\":24895},{\"end\":25501,\"start\":25238},{\"end\":26163,\"start\":25528},{\"end\":26511,\"start\":26165},{\"end\":27023,\"start\":26513},{\"end\":27226,\"start\":27061},{\"end\":27549,\"start\":27302},{\"end\":27681,\"start\":27551},{\"end\":27963,\"start\":27735},{\"end\":28110,\"start\":27965},{\"end\":28967,\"start\":28126},{\"end\":29567,\"start\":28969},{\"end\":29787,\"start\":29639},{\"end\":30581,\"start\":29789},{\"end\":30738,\"start\":30583},{\"end\":31501,\"start\":30740},{\"end\":31928,\"start\":31503},{\"end\":32497,\"start\":31930},{\"end\":33433,\"start\":32499},{\"end\":33681,\"start\":33435},{\"end\":35068,\"start\":33696},{\"end\":35483,\"start\":35121},{\"end\":35941,\"start\":35529},{\"end\":36061,\"start\":35970},{\"end\":36212,\"start\":36107},{\"end\":36667,\"start\":36294},{\"end\":36764,\"start\":36669},{\"end\":36838,\"start\":36792},{\"end\":36883,\"start\":36840},{\"end\":36979,\"start\":36885},{\"end\":37151,\"start\":37126},{\"end\":37340,\"start\":37255},{\"end\":37506,\"start\":37447},{\"end\":38030,\"start\":37590},{\"end\":38252,\"start\":38072},{\"end\":38829,\"start\":38254},{\"end\":39375,\"start\":38831},{\"end\":39442,\"start\":39377},{\"end\":39725,\"start\":39444},{\"end\":39764,\"start\":39727},{\"end\":39842,\"start\":39776},{\"end\":40127,\"start\":39877},{\"end\":40312,\"start\":40129},{\"end\":40419,\"start\":40391},{\"end\":40752,\"start\":40476},{\"end\":40862,\"start\":40754},{\"end\":41046,\"start\":40864},{\"end\":41315,\"start\":41121},{\"end\":41628,\"start\":41398},{\"end\":41795,\"start\":41719},{\"end\":41919,\"start\":41797},{\"end\":42087,\"start\":41921},{\"end\":42440,\"start\":42159},{\"end\":42649,\"start\":42505},{\"end\":42748,\"start\":42651},{\"end\":43006,\"start\":42750},{\"end\":43596,\"start\":43008},{\"end\":43946,\"start\":43598},{\"end\":44231,\"start\":43973},{\"end\":44505,\"start\":44233},{\"end\":44660,\"start\":44507},{\"end\":44774,\"start\":44662},{\"end\":44855,\"start\":44776},{\"end\":44945,\"start\":44857},{\"end\":45036,\"start\":44947},{\"end\":45269,\"start\":45038},{\"end\":46431,\"start\":45271},{\"end\":46496,\"start\":46445},{\"end\":46848,\"start\":46525},{\"end\":46948,\"start\":46850},{\"end\":47103,\"start\":47043},{\"end\":47601,\"start\":47105},{\"end\":47850,\"start\":47603},{\"end\":48093,\"start\":47852},{\"end\":48671,\"start\":48095},{\"end\":48817,\"start\":48673},{\"end\":49406,\"start\":48819},{\"end\":49602,\"start\":49483},{\"end\":49814,\"start\":49604},{\"end\":49929,\"start\":49816},{\"end\":50055,\"start\":49931},{\"end\":50213,\"start\":50057},{\"end\":50363,\"start\":50215},{\"end\":50443,\"start\":50365},{\"end\":50559,\"start\":50471},{\"end\":50843,\"start\":50561},{\"end\":51030,\"start\":50888},{\"end\":51172,\"start\":51093},{\"end\":51316,\"start\":51231},{\"end\":51466,\"start\":51359},{\"end\":51607,\"start\":51510},{\"end\":51893,\"start\":51609},{\"end\":52247,\"start\":51895},{\"end\":52332,\"start\":52282},{\"end\":52452,\"start\":52380},{\"end\":52593,\"start\":52489},{\"end\":53117,\"start\":52595},{\"end\":53810,\"start\":53119},{\"end\":54361,\"start\":53833},{\"end\":54511,\"start\":54363},{\"end\":54785,\"start\":54533},{\"end\":54964,\"start\":54787},{\"end\":55298,\"start\":55057},{\"end\":55486,\"start\":55385},{\"end\":55590,\"start\":55488},{\"end\":56093,\"start\":55736},{\"end\":56468,\"start\":56095},{\"end\":56592,\"start\":56470},{\"end\":57245,\"start\":56949},{\"end\":57549,\"start\":57480},{\"end\":58657,\"start\":58406},{\"end\":58834,\"start\":58659},{\"end\":59032,\"start\":58836},{\"end\":59505,\"start\":59233},{\"end\":59864,\"start\":59548},{\"end\":60013,\"start\":59866},{\"end\":60127,\"start\":60015},{\"end\":60276,\"start\":60211},{\"end\":60423,\"start\":60357},{\"end\":60520,\"start\":60476},{\"end\":60743,\"start\":60612},{\"end\":60891,\"start\":60820},{\"end\":61046,\"start\":60988},{\"end\":62280,\"start\":61234},{\"end\":62371,\"start\":62282},{\"end\":62773,\"start\":62441},{\"end\":62833,\"start\":62775},{\"end\":63003,\"start\":62950},{\"end\":63436,\"start\":63094},{\"end\":63721,\"start\":63676},{\"end\":64451,\"start\":64410},{\"end\":64946,\"start\":64811},{\"end\":65019,\"start\":64948},{\"end\":65271,\"start\":65138},{\"end\":65338,\"start\":65273},{\"end\":65637,\"start\":65452},{\"end\":65837,\"start\":65802},{\"end\":66165,\"start\":65992},{\"end\":66874,\"start\":66802},{\"end\":66909,\"start\":66876},{\"end\":67196,\"start\":67111},{\"end\":67368,\"start\":67294},{\"end\":67518,\"start\":67370},{\"end\":67623,\"start\":67525},{\"end\":67783,\"start\":67673},{\"end\":68138,\"start\":67966},{\"end\":68245,\"start\":68154},{\"end\":68462,\"start\":68292},{\"end\":68672,\"start\":68464},{\"end\":68899,\"start\":68816},{\"end\":69237,\"start\":68944},{\"end\":69543,\"start\":69239},{\"end\":69941,\"start\":69668},{\"end\":70387,\"start\":70066},{\"end\":70742,\"start\":70560},{\"end\":71339,\"start\":70791},{\"end\":72282,\"start\":71341},{\"end\":73736,\"start\":72284},{\"end\":74031,\"start\":73770},{\"end\":74722,\"start\":74390},{\"end\":74865,\"start\":74724},{\"end\":74936,\"start\":74867},{\"end\":75071,\"start\":74938},{\"end\":75192,\"start\":75155},{\"end\":75461,\"start\":75267},{\"end\":75619,\"start\":75533},{\"end\":76555,\"start\":75621},{\"end\":77672,\"start\":76557},{\"end\":78052,\"start\":77674},{\"end\":79354,\"start\":78054},{\"end\":80302,\"start\":79436},{\"end\":81169,\"start\":80304},{\"end\":82040,\"start\":81171},{\"end\":83733,\"start\":82042},{\"end\":84361,\"start\":83735}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14857,\"start\":14773},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15189,\"start\":15109},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15489,\"start\":15431},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19267,\"start\":19220},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20061,\"start\":20035},{\"attributes\":{\"id\":\"formula_5\"},\"end\":22466,\"start\":22271},{\"attributes\":{\"id\":\"formula_6\"},\"end\":22620,\"start\":22466},{\"attributes\":{\"id\":\"formula_7\"},\"end\":23408,\"start\":23346},{\"attributes\":{\"id\":\"formula_8\"},\"end\":24580,\"start\":24334},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24704,\"start\":24605},{\"attributes\":{\"id\":\"formula_10\"},\"end\":25527,\"start\":25502},{\"attributes\":{\"id\":\"formula_11\"},\"end\":27060,\"start\":27024},{\"attributes\":{\"id\":\"formula_12\"},\"end\":27301,\"start\":27227},{\"attributes\":{\"id\":\"formula_13\"},\"end\":27734,\"start\":27682},{\"attributes\":{\"id\":\"formula_14\"},\"end\":29638,\"start\":29568},{\"attributes\":{\"id\":\"formula_15\"},\"end\":35102,\"start\":35069},{\"attributes\":{\"id\":\"formula_16\"},\"end\":36106,\"start\":36062},{\"attributes\":{\"id\":\"formula_17\"},\"end\":36293,\"start\":36213},{\"attributes\":{\"id\":\"formula_18\"},\"end\":37125,\"start\":36980},{\"attributes\":{\"id\":\"formula_19\"},\"end\":37254,\"start\":37152},{\"attributes\":{\"id\":\"formula_20\"},\"end\":37446,\"start\":37341},{\"attributes\":{\"id\":\"formula_21\"},\"end\":37557,\"start\":37507},{\"attributes\":{\"id\":\"formula_23\"},\"end\":40390,\"start\":40313},{\"attributes\":{\"id\":\"formula_24\"},\"end\":40475,\"start\":40420},{\"attributes\":{\"id\":\"formula_25\"},\"end\":41120,\"start\":41047},{\"attributes\":{\"id\":\"formula_26\"},\"end\":41397,\"start\":41316},{\"attributes\":{\"id\":\"formula_27\"},\"end\":41718,\"start\":41629},{\"attributes\":{\"id\":\"formula_28\"},\"end\":42127,\"start\":42088},{\"attributes\":{\"id\":\"formula_29\"},\"end\":42158,\"start\":42127},{\"attributes\":{\"id\":\"formula_30\"},\"end\":42504,\"start\":42441},{\"attributes\":{\"id\":\"formula_31\"},\"end\":47042,\"start\":46949},{\"attributes\":{\"id\":\"formula_32\"},\"end\":49482,\"start\":49407},{\"attributes\":{\"id\":\"formula_33\"},\"end\":50470,\"start\":50444},{\"attributes\":{\"id\":\"formula_34\"},\"end\":50887,\"start\":50844},{\"attributes\":{\"id\":\"formula_35\"},\"end\":51092,\"start\":51031},{\"attributes\":{\"id\":\"formula_36\"},\"end\":51230,\"start\":51173},{\"attributes\":{\"id\":\"formula_37\"},\"end\":51358,\"start\":51317},{\"attributes\":{\"id\":\"formula_38\"},\"end\":51509,\"start\":51467},{\"attributes\":{\"id\":\"formula_39\"},\"end\":52281,\"start\":52248},{\"attributes\":{\"id\":\"formula_40\"},\"end\":52379,\"start\":52333},{\"attributes\":{\"id\":\"formula_41\"},\"end\":52488,\"start\":52453},{\"attributes\":{\"id\":\"formula_42\"},\"end\":55056,\"start\":54965},{\"attributes\":{\"id\":\"formula_43\"},\"end\":55384,\"start\":55299},{\"attributes\":{\"id\":\"formula_44\"},\"end\":55735,\"start\":55591},{\"attributes\":{\"id\":\"formula_45\"},\"end\":56821,\"start\":56593},{\"attributes\":{\"id\":\"formula_46\"},\"end\":56862,\"start\":56821},{\"attributes\":{\"id\":\"formula_47\"},\"end\":56948,\"start\":56907},{\"attributes\":{\"id\":\"formula_48\"},\"end\":57479,\"start\":57246},{\"attributes\":{\"id\":\"formula_49\"},\"end\":58405,\"start\":57550},{\"attributes\":{\"id\":\"formula_50\"},\"end\":59232,\"start\":59033},{\"attributes\":{\"id\":\"formula_51\"},\"end\":60210,\"start\":60128},{\"attributes\":{\"id\":\"formula_52\"},\"end\":60356,\"start\":60277},{\"attributes\":{\"id\":\"formula_53\"},\"end\":60475,\"start\":60424},{\"attributes\":{\"id\":\"formula_54\"},\"end\":60611,\"start\":60521},{\"attributes\":{\"id\":\"formula_55\"},\"end\":60819,\"start\":60744},{\"attributes\":{\"id\":\"formula_56\"},\"end\":60987,\"start\":60892},{\"attributes\":{\"id\":\"formula_57\"},\"end\":61233,\"start\":61047},{\"attributes\":{\"id\":\"formula_58\"},\"end\":62440,\"start\":62372},{\"attributes\":{\"id\":\"formula_59\"},\"end\":62949,\"start\":62834},{\"attributes\":{\"id\":\"formula_60\"},\"end\":63093,\"start\":63004},{\"attributes\":{\"id\":\"formula_61\"},\"end\":63675,\"start\":63437},{\"attributes\":{\"id\":\"formula_62\"},\"end\":64409,\"start\":63722},{\"attributes\":{\"id\":\"formula_63\"},\"end\":64810,\"start\":64452},{\"attributes\":{\"id\":\"formula_64\"},\"end\":65137,\"start\":65020},{\"attributes\":{\"id\":\"formula_65\"},\"end\":65451,\"start\":65339},{\"attributes\":{\"id\":\"formula_66\"},\"end\":65801,\"start\":65638},{\"attributes\":{\"id\":\"formula_67\"},\"end\":65991,\"start\":65838},{\"attributes\":{\"id\":\"formula_68\"},\"end\":66801,\"start\":66166},{\"attributes\":{\"id\":\"formula_69\"},\"end\":67110,\"start\":66910},{\"attributes\":{\"id\":\"formula_70\"},\"end\":67293,\"start\":67197},{\"attributes\":{\"id\":\"formula_71\"},\"end\":67672,\"start\":67624},{\"attributes\":{\"id\":\"formula_72\"},\"end\":67965,\"start\":67784},{\"attributes\":{\"id\":\"formula_73\"},\"end\":68815,\"start\":68673},{\"attributes\":{\"id\":\"formula_74\"},\"end\":69667,\"start\":69544},{\"attributes\":{\"id\":\"formula_75\"},\"end\":70065,\"start\":69942},{\"attributes\":{\"id\":\"formula_76\"},\"end\":70559,\"start\":70388},{\"attributes\":{\"id\":\"formula_77\"},\"end\":74351,\"start\":74032},{\"attributes\":{\"id\":\"formula_78\"},\"end\":75154,\"start\":75072},{\"attributes\":{\"id\":\"formula_79\"},\"end\":75266,\"start\":75193}]", "table_ref": "[{\"end\":32391,\"start\":32384},{\"end\":34965,\"start\":34958},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":36002,\"start\":35974},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":71011,\"start\":71004},{\"end\":77037,\"start\":77030},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":77169,\"start\":77162},{\"end\":77734,\"start\":77727}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":4205,\"start\":4193},{\"end\":4212,\"start\":4208},{\"attributes\":{\"n\":\"2\"},\"end\":8142,\"start\":8130},{\"attributes\":{\"n\":\"3\"},\"end\":14437,\"start\":14426},{\"attributes\":{\"n\":\"3.1\"},\"end\":14664,\"start\":14636},{\"attributes\":{\"n\":\"3.2\"},\"end\":15678,\"start\":15665},{\"attributes\":{\"n\":\"4.2\"},\"end\":21894,\"start\":21887},{\"attributes\":{\"n\":\"5\"},\"end\":28124,\"start\":28113},{\"attributes\":{\"n\":\"6\"},\"end\":33694,\"start\":33684},{\"end\":35119,\"start\":35104},{\"end\":35496,\"start\":35486},{\"end\":35527,\"start\":35499},{\"end\":35968,\"start\":35944},{\"end\":36790,\"start\":36767},{\"end\":37588,\"start\":37559},{\"end\":38070,\"start\":38033},{\"end\":39774,\"start\":39767},{\"end\":39875,\"start\":39845},{\"end\":43971,\"start\":43949},{\"end\":46443,\"start\":46434},{\"end\":46523,\"start\":46499},{\"end\":53831,\"start\":53813},{\"end\":54531,\"start\":54514},{\"attributes\":{\"n\":\"2.\"},\"end\":56906,\"start\":56864},{\"end\":59546,\"start\":59508},{\"end\":67523,\"start\":67521},{\"end\":68152,\"start\":68141},{\"end\":68290,\"start\":68248},{\"end\":68942,\"start\":68902},{\"end\":70789,\"start\":70745},{\"end\":73768,\"start\":73739},{\"end\":74388,\"start\":74353},{\"end\":75531,\"start\":75464},{\"end\":79434,\"start\":79357},{\"end\":84372,\"start\":84363},{\"end\":84710,\"start\":84700},{\"end\":84801,\"start\":84791},{\"end\":86813,\"start\":86803},{\"end\":86907,\"start\":86897},{\"end\":87016,\"start\":87006},{\"end\":87140,\"start\":87130},{\"end\":87262,\"start\":87252},{\"end\":87367,\"start\":87357},{\"end\":87487,\"start\":87477},{\"end\":87681,\"start\":87670},{\"end\":97112,\"start\":97103},{\"end\":97177,\"start\":97168},{\"end\":97347,\"start\":97338}]", "table": "[{\"end\":88380,\"start\":88057},{\"end\":97101,\"start\":94360},{\"end\":97166,\"start\":97144},{\"end\":97336,\"start\":97261},{\"end\":98063,\"start\":98010}]", "figure_caption": "[{\"end\":84698,\"start\":84373},{\"end\":84789,\"start\":84712},{\"end\":84898,\"start\":84803},{\"end\":85193,\"start\":84901},{\"end\":85687,\"start\":85196},{\"end\":86290,\"start\":85690},{\"end\":86801,\"start\":86293},{\"end\":86895,\"start\":86815},{\"end\":87004,\"start\":86909},{\"end\":87128,\"start\":87018},{\"end\":87250,\"start\":87142},{\"end\":87355,\"start\":87264},{\"end\":87475,\"start\":87369},{\"end\":87659,\"start\":87489},{\"end\":87668,\"start\":87662},{\"end\":87859,\"start\":87684},{\"end\":88057,\"start\":87862},{\"end\":94360,\"start\":88383},{\"end\":97144,\"start\":97114},{\"end\":97261,\"start\":97179},{\"end\":98010,\"start\":97349}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31235,\"start\":31227},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":31267,\"start\":31259},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":31299,\"start\":31291},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":49406,\"start\":49385},{\"end\":73914,\"start\":73913},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":75656,\"start\":75650},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":75770,\"start\":75764},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":76047,\"start\":76041},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":76137,\"start\":76120},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":76416,\"start\":76410},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":76480,\"start\":76474},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":76582,\"start\":76576},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":76651,\"start\":76645},{\"attributes\":{\"ref_id\":\"fig_13\"},\"end\":76766,\"start\":76760},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":80964,\"start\":80955},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":80975,\"start\":80969},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":81019,\"start\":81013},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":81409,\"start\":81401},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":81765,\"start\":81757},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":81928,\"start\":81910},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":81985,\"start\":81966},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":82039,\"start\":82021},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":83100,\"start\":83091},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":83456,\"start\":83447},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":83619,\"start\":83600},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":83677,\"start\":83657},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":83732,\"start\":83713}]", "bib_author_first_name": null, "bib_author_last_name": null, "bib_entry": null, "bib_title": null, "bib_author": null, "bib_venue": null}}}, "year": 2023, "month": 12, "day": 17}