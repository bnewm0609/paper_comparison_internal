{"id": 238634824, "updated": "2023-09-28 00:38:22.597", "metadata": {"title": "Private Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses", "authors": "[{\"first\":\"Andrew\",\"last\":\"Lowy\",\"middle\":[]},{\"first\":\"Meisam\",\"last\":\"Razaviyayn\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "This paper studies the problem of federated learning (FL) in the absence of a trustworthy server/clients. In this setting, each client needs to ensure the privacy of its own data without relying on the server or other clients. We study local di\ufb00erential privacy (LDP) and provide tight upper and lower bounds that establish the minimax optimal rates (up to logarithms) for LDP convex/strongly convex federated stochastic optimization. Our rates match the optimal statistical rates in certain practical parameter regimes (\u201cprivacy for free\u201d). Second, we develop an accelerated distributed noisy SGD algorithm, leading to the \ufb01rst non-trivial LDP risk bounds for FL with non-i.i.d. clients. Third, we consider the special case where each client\u2019s loss function is empirical and use a variation of our accelerated LDP FL algorithm to improve communication complexity compared to existing works. We also provide matching lower bounds, establishing the optimality of our algorithm for convex/strongly convex settings. Fourth, with a secure shu\ufb04er to anonymize client reports (but without a trusted server), our algorithm attains the optimal central DP rates for stochastic convex/strongly convex optimization, thereby achieving optimality in the local and central models simultaneously . Our upper bounds quantify the role of network communication reliability in performance.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2106.09779", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iclr/LowyR23", "doi": null}}, "content": {"source": {"pdf_hash": "be9dce9d6857b867dc2fc05e5630ae8dd41ad194", "pdf_src": "ScienceParsePlus", "pdf_uri": "[\"https://export.arxiv.org/pdf/2106.09779v7.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "ce5623c0e0df2f6b4324692affe9deb16c52ac1e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/be9dce9d6857b867dc2fc05e5630ae8dd41ad194.txt", "contents": "\nPrivate Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses\n\n\nAndrew Lowy lowya@usc.edu \nMeisam Razaviyayn\nUniversity of Southern\nCalifornia\n\nPrivate Federated Learning Without a Trusted Server: Optimal Algorithms for Convex Losses\n\nThis paper studies the problem of federated learning (FL) in the absence of a trustworthy server/clients. In this setting, each client needs to ensure the privacy of its own data without relying on the server or other clients. We study local differential privacy (LDP) and provide tight upper and lower bounds that establish the minimax optimal rates (up to logarithms) for LDP convex/strongly convex federated stochastic optimization. Our rates match the optimal statistical rates in certain practical parameter regimes (\"privacy for free\"). Second, we develop an accelerated distributed noisy SGD algorithm, leading to the first non-trivial LDP risk bounds for FL with non-i.i.d. clients. Third, we consider the special case where each client's loss function is empirical and use a variation of our accelerated LDP FL algorithm to improve communication complexity compared to existing works. We also provide matching lower bounds, establishing the optimality of our algorithm for convex/strongly convex settings. Fourth, with a secure shuffler to anonymize client reports (but without a trusted server), our algorithm attains the optimal central DP rates for stochastic convex/strongly convex optimization, thereby achieving optimality in the local and central models simultaneously. Our upper bounds quantify the role of network communication reliability in performance.\n\nIntroduction\n\nContemporary machine learning problems often involve vast amounts of data coming from many sources (e.g. cell-phone users or organizations such as hospitals) containing sensitive information (e.g. location or health records). In federated learning, each \"client\" (e.g. cell-phone users or organizations such as hospitals) stores its data locally and a central server coordinates updates to achieve the global learning objective [KMA`19]. Federated learning (FL) has been deployed across application domains such as the internet of things [NDP`21] . One of the primary reasons for the introduction of FL was to offer greater privacy for sensitive user data [MMR`17]. Unfortunately, merely storing data locally is not sufficient to prevent data leakage, as model parameters or updates can still reveal sensitive information [FJR15, HZL19, SWZ`20, ZH20]. These leaks can occur when clients send updates to the server, which an adversary may be able to access, or (in decentralized/peer-to-peer FL) directly to other clients. Therefore, it is important to develop privacy-preserving mechanisms for FL that do not rely on the server or other clients to implement.\n\nConsider a FL setting with N clients, each containing a local data set with n i samples: X i \" px i,1 ,\u00a8\u00a8\u00a8, x i,ni q for i P rN s. Assume X i is independent of X j for all i \u2030 j. In each round of communication r, a uniformly random subset S r of M r P rN s clients is able to participate, where tM r u R r\"1 are i.i.d. random variables. For all i, let D i be a probability distribution on a set X i , which contains data, and denote X :\" \u0164 N i\"1 X i . Given a convex (in w) loss function f : W\u02c6X \u00d1 R, define client i's local objective as F i pwq :\" E xi\"Di rf pw, x i qs,\n\nwhere W \u0102 R d is closed, convex, and }w} 2 \u010f D, @w P W. At times, we will focus on empirical risk minimization (ERM), where p F i pwq :\" 1 ni \u0159 ni j\"1 f pw, x i,j q. Our goal is to solve min wPW # F pwq :\"\nN \u00ff i\"1 p i F i pwq + ,(2)\nor, in the ERM case, min wPW p F pwq :\" \u0159 N i\"1 p i p F i pwq, while maintaining the privacy of each client. Here p i \u011b 0 and \u0159 i p i \" 1. We assume WLOG (see Appendix B) that p i \" 1 N , @i P rN s. We say problem (2) is \"i.i.d.\" if X i \" X and D i \" D @i. When F i takes the general form (1) (not necessarily ERM), we refer to the problem as \"SCO\" (stochastic convex optimization) for emphasis.\n\nPopular algorithms for FL include Local SGD/Federated Averaging [MRTZ18] and Minibatch SGD. Both of these are fully interactive algorithms, meaning they can adaptively query each client multiple times. A subset of fully interactive algorithms is the set of sequentially interactive algorithms, which can query clients adaptively in sequence, but cannot query any one client more than once. Non-interactive algorithms are non-adaptive sequentially interactive algorithms: they query each client once, independently of other clients' reports. See [JMNR19] for further discussion.\n\nNotions of Privacy for FL: Given the practical importance of maintaining the privacy of user data during the FL process, numerous different definitions of private FL have been proposed. Some of these have used secure multi-party computation (MPC) [CRT18, MZCS18], but this approach leaves users vulnerable to inference attacks on the trained model. This is in contrast to differential privacy (DP), which by now has been widely accepted as the gold standard of rigorous data privacy notions. DP is defined with respect to a database space X and a measure of distance \u03c1 : X 2 \u00d1 r0, 8q between databases. We say two databases X, X 1 P X are \u03c1-adjacent if \u03c1pX, X 1 q \u010f 1.\n\nDefinition 1. (Differential Privacy) Let \u011b 0, \u03b4 P r0, 1q. A randomized algorithm A : X \u00d1 W is p , \u03b4qdifferentially private (DP) if for all \u03c1-adjacent data sets X, X 1 P X and all measurable subsets S \u0102 W, we have PpApXq P Sq \u010f e PpApX 1 q P Sq`\u03b4.\n\nIf (3) holds for all measurable subsets S, then we denote this property by ApXq \u00bb p ,\u03b4q ApX 1 q. For FL, we will fix X :\" X n1 1\u02c6\u00a8\u00a8\u00a8\u02c6X n N N so that databases X in our FL setting consist of N client datasets X \" pX 1 ,\u00a8\u00a8\u00a8X N q. Definition 1 says that an algorithm is DP if with high probability, an adversary cannot distinguish between the outputs of the algorithm when it is run on adjacent databases. Depending on the choice of \u03c1, we can get different variations of DP. For example, in the classical notion of central differential privacy (CDP) (often simply referred to as \"differential privacy\") [Dwo06], \u03c1pX, X 1 q :\" \u0159 N i\"1 \u0159 ni j\"1 1 xi,j \u2030x 1 i,j is the hamming distance and adjacent databases are those differing in a single sample. 1 In the context of FL, a major problem with CDP is that it does not preclude the untrusted server from accessing non-private updates (which may leak clients' data).\n\nClient-level DP (also called user-level DP) has been proposed as an alternative to CDP where a single person may contribute many samples to the database (e.g. language modeling) [MRTZ18, GKN17, JW18, GV18, WLD`20a, ZT20, LSA`21]. It is defined by taking \u03c1pX, X 1 q \" \u0159 N i\"1 1 Xi\u2030X 1 i . Client-level DP shares the same drawback as CDP: it allows sensitive data to be leaked to the untrusted server. In contrast to the centralized models of CDP and client-level DP, this work imposes the stronger requirement that client updates be private before they are sent to the untrusted server (or other clients) for aggregation.\n\nFirst, we consider local differential privacy (LDP), a generalization of the the classic notion with the same name [KLN`11] to FL. An R-round fully interactive randomized algorithm A : X \u00d1 Z R\u02c6N for FL is characterized in every round r P rRs by N local client functions called randomizers R piq r : Z pr\u00b41q\u02c6N\u02c6X ni i \u00d1 Z (i P rN s) and an aggregation mechanism. The randomizers send messages Z piq r :\" R piq r pZ 1:r\u00b41 , X i q (which may depend on client data X i and the outputs Z 1:r\u00b41 :\" tZ pjq t u jPrN s,tPrr\u00b41s of clients' randomizers in prior rounds) to the server or (in peer-to-peer FL) other clients. 2 Then, the server (or clients, for peer-to-peer FL) updates the global model. Algorithm A is tp i , \u03b4 i qu N i\"1 -LDP if for all i P rN s, the full transcript of client i's communications, i.e. the collection of all R messages tZ piq r u rPrRs , is p i , \u03b4 i q-DP, conditional on the messages and data of all other clients. See Fig. 1. 3 More precisely:\n\nDefinition 2. (Local Differential Privacy) A randomized algorithm A : X n1 1\u02c6\u00a8\u00a8\u00a8\u02c6X n N N \u00d1 Z R\u02c6N is tp i , \u03b4 i qu N i\"1 -LDP if for all i P rN s and all \u03c1 i -adjacent X i , X 1 i P X ni i , we have where for all r the distribution of R piq r pZ 1:r\u00b41 , X i q is conditional on the transcripts Z pj\u2030iq 1:r\u00b41 of all other clients in all previous rounds. Here \u03c1 i : X 2 i \u00d1 r0, 8q is given by \u03c1 i pX i , X 1 i q \" \u0159 ni j\"1 1 xi,j \u2030x 1 i,j . client's data regardless of whether the server or other clients are trustworthy and regardless of the network topology (e.g. peer-to-peer or server-orchestrated). The messages Z piq 1:R of client i are DP, ensuring that client i's data cannot be leaked, even if the server or other clients are curious or leak data themselves.\n\nWe sometimes assume for simplicity that privacy parameters are the same across clients and denote these common parameters by p 0 , \u03b4 0 q. Note that LDP is stronger than CDP : p 0 , \u03b4 0 q-LDP implies p 0 , \u03b4 0 q-CDP but the converse is false. Moreover, LDP is stronger than client-level DP in the following sense: p 0 , \u03b4 0 q-LDP implies pn , ne pn\u00b41q \u03b4q client-level DP, but p , \u03b4q-client-level DP does not imply p 1 , \u03b4 1 q-LDP for any 1 , \u03b4 1 . See Appendix C.\n\nIt is also illuminating to compare Definition 2 with classical item-level LDP [KLN`11, DJW13], which requires each individual person (rather than client) to randomize their own data. When n \" 1, so that each client has just one person's data, classical LDP is equivalent to Definition 2. But if n \u0105 1, then classical LDP would require each person (e.g. patient) to randomize her reports (e.g. medical test results) before sending them to the data collector (doctors/researchers) within the client (hospital). Since we assume in FL that clients can be trusted with their own data, this intra-client randomization is practically unnecessary. Thus, Definition 2 is more practically relevant for FL than classical item-level LDP, and it results in higher accuracy models. An intermediate trust model between the low-trust local model and the high-trust central/client-level model is the shuffle model [BEM`17, CSU`19, EFM`20a, EFM`20b, FMT20, LCC`20, GDD`21] where clients have access to a secure shuffler (also known as a mixnet) that receives randomized reports from the clients and randomly permutes them (effectively anonymizing them), before the reports are sent to the untrusted server/other clients. 4\n\nDefinition 3. (Shuffle Differential Privacy) A randomized algorithm A : X n1 1\u02c6\u00a8\u00a8\u00a8\u02c6X n N N \u00d1 Z N\u02c6R is p , \u03b4q-shuffle DP (SDP) if for all \u03c1-adjacent databases X, X 1 P X n1 1\u02c6\u00a8\u00a8\u00a8\u02c6X n N N and all measurable subsets S, the collection of all uniformly randomly permuted messages that are sent by the shuffler satisfies (3), with \u03c1pX, X 1 q :\" \u0159 N i\"1 \u0159 ni j\"1 1 xi,j \u2030x 1 i,j . That is, SDP uses the same notion of adjacency \u03c1 as CDP, but prohibits the server from viewing non-private functions of clients' data, instead restricting clients to randomize their own data and use shuffling. Since p 0 , \u03b4 0 q-LDP implies p 0 , \u03b4 0 q-CDP and shuffling can be seen as post-processing, it follows that p 0 , \u03b4 0 q-LDP implies p 0 , \u03b4 0 q-SDP. 2 We assume that R piq r pZ 1:r\u00b41 , X i q is conditionally independent of X j (j \u2030 i) given Z 1:r\u00b41 and X i . That is, the randomizers of i cannot \"eavesdrop\" on another client's data (consistent with the local data principle of FL). We allow for Z piq t to be empty/zero if client i does not output anything to the server in round t. 3 Ultimately, the algorithm A may output some p w P W that is a function of the client transcripts pZ 1 ,\u00a8\u00a8\u00a8, Z R q. By the post-processing property of DP [DR14, Proposition 2.1], the privacy of p w will be guaranteed if the client transcripts are DP. Thus, here we simply consider the output of A to be the client transcripts.\n\n4 Assume that client reports can be decrypted by the server, but not by the shuffler [EFM`20a, FMT20].\n\nNotation and Assumptions: Denote by }\u00a8} the Euclidean norm. A differentiable function g :\nW \u00d1 R (W \u010e R d ) is \u00b5-strongly convex (\u00b5 \u011b 0) if gpwq \u011b gpw 1 q`x\u2207gpw 1 q, w\u00b4w 1 y`\u00b5 2 }w\u00b4w 1 } 2 @ w, w 1 P W. If \u00b5 \" 0, we say g is convex. A function h : W \u00d1 R m is L-Lipschitz if }hpwq\u00b4hpw 1 q} \u010f L}w\u00b4w 1 } for all w, w 1 P W. h is \u03b2-smooth if its derivative \u2207h is \u03b2-Lipschitz.\nDenote w\u02daP argmin wPW F pwq. We write a \u00c0 b if DC \u0105 0 such that a \u010f Cb. We write a \" r Opbq if a \u00c0 logp\u03b8qb for some parameters \u03b8. We assume the following throughout this work:\n\nAssumption 1. f p\u00a8, xq is L i -Lipschitz and \u00b5-strongly convex (with \u00b5 \" 0 for convex) @x P X i .\n\nAssumption 2. In each round r, a uniformly random subset S r of M r P rN s distinct clients can communicate with the server, where tM r u r\u011b0 are i.i.d. random variables with 1 M :\" Ep 1 Mr q and 1\nM 1 :\" Ep 1 M 2 r q.\nAssumption 2 is more realistic and general than existing FL works, which usually assume M r \" M is deterministic [KMA`19]. M r is determined by the network and is not a design parameter: M r is the number of clients that are able to contribute to global updates in each round, which is not the same as the number of clients that a given algorithm queries in each round. For example, the one-pass sequential algorithms of [DJW13, STU17] query just Op1q clients in each round, but require M r \" N to implement since they dictate exactly which client(s) must communicate with the server in every round and do not allow any client to contribute more than one report. \n\n\nRelated\nD i \" D)\nFL problem with n \" 1 and M \" N , establishing minimax risk bounds for the class of sequentially interactive LDP algorithms and convex, Lipschitz loss functions. We consider the ( 0 , \u03b4 0 )-LDP i.i.d. FL problem in a more general setting where each client has an arbitrary number of samples (n \u011b 1) and establish tight minimax risk bounds for two Lipschitz function classes-strongly convex and convex. Crucially, our minimax risk bounds hold with respect to a wider class of algorithms than that considered by [DJW13] and [STU17]; in addition to sequentially interactive algorithms, our algorithm class also includes a broad subset of fully interactive algorithms. These risk bounds match (up to logarithms) the respective non-private rates if d 2 0 \u00c0 n (\"privacy for free\").  (2), which we refer to as LDP Federated ERM, has been extensively studied in recent years [TLC`20, HHG`20, HG20, WFSK19, WLD`20b, DPZ`20, ZZY`20, ABK`19, STL20, GDD`21], but only one of these works, [GDD`21], provides an algorithm that achieves a tight upper bound. [GDD`21] focuses primarily on the shuffled model of DP, but we observe that their algorithm also yields an p 0 , \u03b4 0 q-LDP empirical risk bound for convex loss. We employ a variation of our accelerated LDP algorithm-combined with Nesterov smoothing [Nes05] in the non-smooth case-to achieve the same risk bound as [GDD`21] in fewer rounds of server communication. We also address strongly convex ERM. Further, we provide matching lower bounds, implying that our algorithm is optimal among a subclass of fully interactive LDP algorithms. 4. Achieving the optimal CDP i.i.d. SCO rates without a trusted curator (Theorem 4.1): [GDD`21, EFM`20a] showed that the optimal CDP convex federated ERM rate [BST14] can be attained in the lower trust (relative to the central model) shuffle model of DP. The concurrent work [CJMP21, Theorem 4.9] shows that when all M \" N clients can communicate in every round and each client has just n \" 1 sample, the optimal CDP SCO rate can be attained with an SDP algorithm. We show, more generally, that our algorithm (with shuffling) attains the optimal CDP SCO rates for clients with any number n \u011b 1 of samples. Therefore, with shuffling, our algorithm is simultaneously optimal in both the local and central models of DP for i.i.d. FL. We also provide upper bounds when M \u0103 N clients can communicate in each round.\n\nIn non-private distributed optimization, [LO10, TG15, NOS17] provide convergence results with random connectivity graphs. Our upper bounds describe the effect of the mean/variance of 1{M r on DP FL. Tight lower bounds for DP FL when M \u0103 N is an open problem stemming from our work.\n\n\nUpper Bounds for LDP FL\n\nIn this section, we give LDP excess risk and communication complexity upper bounds for the FL problem (2). To simplify the presentation of our results, we will assume that n i \" n, i \" 0 , \u03b4 i \" \u03b4 0 , and L i \" L for all i. This assumption implies that the simplified upper bounds will not depend on the second moment 1{M 1 . Appendix D contains the general versions of these upper bounds and their proofs.\n\nNoisy Minibatch SGD for i.i.d. clients: Consider the case of i.i.d. clients: X i \" X , D i \" D for all i. We derive tight loss bounds via Algorithm 1, an LDP version of distributed minibatch SGD (MB-SGD). In each round r, all M r available clients send noisy stochastic gradients to the server: r g i r :\" 1\nK \u0159 K j\"1 \u2207f pw r , x r i,j q`u i , where u i \" N p0, \u03c3 2\ni I d q and x i,j are drawn uniformly with replacement from X i . The server averages these M r reports, updates w r`1 :\" \u03a0 W rw r\u00b4\u03b7 r Mr \u0159 iPSr r g i r s and reports w r`1 to all N clients.\n\nAlgorithm 1 Noisy MB-SGD Require: Number of clients N P N, dimension d P N of data, noise parameters t\u03c3 i u iPrN s , data sets X i P X ni i for i P rN s, convex loss function f pw, xq, number of communication rounds R P N, number tKu N i\"1 \u0102 N of local samples drawn per round, step sizes t\u03b7 r u rPrRs and weights t\u03b3 r u rPrRs . 1: Initialize w 0 \" 0. 2: for r P t0, 1,\u00a8\u00a8\u00a8, R\u00b41u do 3:\n\nfor i P S r do in parallel 4:\n\nClients draw K i samples x r i,j (uniformly with replacement) from X i (for j P rK i s) and noise u i \" N p0, \u03c3 2 i I d q.\n\n\n5:\n\nClient computes r g i r :\" 1 Ki \u0159 Ki j\"1 \u2207f pw r , x r i,j q`u i . Server aggregates r g r :\" 1 Mr \u0159 iPSr r g i r for subset S r of M r P rN s (distinct) active clients.\n\n\n8:\n\nServer updates w r`1 :\" \u03a0 W rw r\u00b4\u03b7r r g r s and reports update back to all N clients. 9: end for 10: return p\nw R \" 1 \u0393 R \u0159 R\u00b41 r\"0 \u03b3 r w r , where \u0393 R :\" \u0159 R\u00b41 r\"0 \u03b3 r .\nAlgorithm 1 can also be seen as a distributed version of [BFTT19, Algorithm 1]. We now give privacy and excess population loss guarantees for Algorithm 1, run with \u03c3 2 i :\" 256L 2 R lnp2.5R{\u03b40q lnp2{\u03b40q\nn 2 2 0 : Theorem 2.1. [Informal] Let f : W\u02c6X \u00d1 R d be \u03b2-smooth in w for all x P X . Assume 0 \u010f lnp2{\u03b4 0 q and choose K \u011b 0n 4 ? 2R lnp2{\u03b40q\n. Then Algorithm 1 is p 0 , \u03b4 0 q-LDP. Moreover, there exist choices of \u03b7 r \" \u03b7 and t\u03b3 r u R\u00b41 r\"0 such that the output p w R \" \u0159 R\u00b41 r\"0 \u03b3 r w r of Algorithm 1 achieves the following excess loss:\n1. If f p\u00a8, xq is convex, then setting R \" max\u00b4\u03b2 D ? M L min ! ? n, 0 n ? d ) , min ! n, 2 0 n 2 d ) {K\u00afyields EF p p w R q\u00b4F pw\u02daq \" r O\u02dcL D ? M\u02dc1 ? n`a d lnp2{\u03b4 0 q 0 n\u00b8\u00b8.(4)\n2. If f p\u00a8, xq is \u00b5-strongly convex, then setting R \" max\u00b48 \u03b2 \u00b5 ln\u00b4\u03b2\nD 2 \u00b5M 2 0 n 2 dL 2\u00af, min ! n, 2 0 n 2 d ) {K\u00afyields EF p p w R q\u00b4F pw\u02daq \" r O\u02c6L 2 \u00b5M\u02c61 n`d lnp2{\u03b4 0 q 2 0 n 2\u02d9\u02d9.(5)\nThe r O notation hides a logarithmic factor depending on problem parameters other than \u03b4 0 .\n\nThe first terms in each of (4) and (5) (LD{ ? M n for convex and L 2 {\u00b5M n for strongly convex) are upper bounds on the uniform stability [BE02] of Algorithm 1, which we use to bound its generalization error, similar to how [BFTT19] proceeded for the case N \" 1. The second terms in each of (4) and (5)  . We use the slightly larger noise specified in Theorem 2.1 because it allows for slightly more flexible local minibatch size K and we find the privacy proof to be simpler. This remark applies verbatim to the rest of the upper bounds in this paper with the exception of those in Theorem 2.3.\n\nWe get rid of the restriction on \u03b2 that appears in [BFTT19, Theorem 3.2] for N \" 1, non-strongly convex loss by using a different (smaller, when N \" 1) step size. This allows us to extend our convex upper bound to non-smooth functions in the distributed setting via Nesterov smoothing [Nes05], like [BFTT19] did for N \" 1:\nTheorem 2.2. [Informal] Let 0 \u010f lnp2{\u03b4 0 q and choose K \u011b 0n 4 ? 2R lnp2{\u03b40q\n. Then Algorithm 1 is p 0 , \u03b4 0 q-LDP. Further, there exists \u03b2 \u0105 0 such that running Algorithm 1 on f \u03b2 pw, xq :\" min vPW\u00b4f pv, xq`\u03b2 2 }w\u00b4v} 2\u0233 ields:\n1. If f p\u00a8, xq is convex, then setting R \" M min ! n, 2 0 n 2 d ) yields EF p p w R q\u00b4F pw\u02daq \" r O\u02dcL D ? M\u02dc1 ? n`a d lnp2{\u03b4 0 q 0 n\u00b8\u00b8.(6)\n2. If f p\u00a8, xq is \u00b5-strongly convex, then setting R \" M min (7)\n\nThe r O notation hides logarithmic factors depending on problem parameters other than \u03b4 0 .\n\nWe will see (Theorem 3.1) that these upper bounds are tight up to logarithmic factors when M \" N , implying that Algorithm 1 is optimal among a large class of fully interactive LDP algorithms. Theorem 3.1 also implies that the minimax rate for convex/strongly convex LDP i.i.d. FL is the same for smooth and non-smooth functions, which mirrors the story for CDP ERM and SCO [BST14, BFTT19, FMT20]. The cost of non-smoothness is higher communication complexity (larger R) and computational effort needed to compute the Moreau envelope f \u03b2 . However, [BFTT19] present a computationally efficient implementation using approximate prox operators that could be used to reduce the computational cost of Algorithm 1 in the non-smooth setting. Lastly, if M \" N and d 2 0 \u00c0 n, then both of these upper bounds match (up to logarithms) the respective non-private lower bounds for SCO (\"privacy for free\") [NY83, ABRW12, HK14].\n\nOne-pass Accelerated Noisy Distributed SGD for non-i.i.d. clients: Consider the general non-i.i.d. FL problem, where F i pwq takes the general form (1) for some unknown distributions D i on X i (i P rN s). The uniform stability approach that we used to obtain our i.i.d. upper bounds does not work in this setting. 5 Instead, we directly minimize F by modifying Algorithm 1 as follows: 1. We draw K :\" 1 local samples without replacement and set R :\" n. Thus, each sample is used at most one time during the algorithm, so that the bounds we obtain apply to F. 2. We use acceleration to increase the convergence rate. 3. To provide LDP, we use Gaussian noise with larger variance \u03c3 2 \" 8L 2 lnp1.25{\u03b40q 2 0 . We call this algorithm One-pass Accelerated Noisy Distributed SGD. It is an instantiation of Accelerated Noisy MB-SGD, described in Algorithm 2 (Appendix D.4). Algorithm 2 is a noisy LDP version of the accelerated MB-SGD of [GL12], which was analyzed in the distributed setting by [WPS20b].\n\nInstead of appealing to the advanced composition theorem or moments accountant, we prove the privacy of our algorithm via parallel composition [McS09] since the local data points used in each round are distinct. That is, sampling without replacement allows us to view the privacy-preserving component of our algorithm as a sequence of R \" n parallel Gaussian mechanisms operating on distinct samples in each client. Crucially, the domains of the n local Gaussian mechanisms must be disjoint for parallel composition to apply, which implies that privacy amplification by subsampling doesn't apply. Consequently, we need to increase the variance of the noise to ensure LDP. See Appendix D.5 for details.\n\nTheorem 2.3. Let f p\u00a8, xq be \u03b2-smooth for all x P X . Assume 0 \u010f 1. Then One-pass Accelerated Noisy Distributed SGD is p 0 , \u03b4 0 q-LDP. Moreover:\n1. If f p\u00a8, xq is convex, then EF p p w R q\u00b4F pw\u02daq \" O\u02dc\u03b2 D 2 n 2`L D a d lnp1{\u03b4 0 q 0 ? M n\u00b8.(8)\n2. If f p\u00a8, xq is \u00b5-strongly convex, then . Then Algorithm 2 is p 0 , \u03b4 0 q-LDP. Further, there is \u03b2 \u0105 0 such that running Algorithm 2 on f \u03b2 pwq :\" min vPW\u00b4f pvq`\u03b2 2 }w\u00b4v} 2\u0233 ields the following bounds on the excess empirical loss (w.r.t. f ):\nEF p p w R q\u00b4F pw\u02daq \" O\u02c6LD exp\u02c6\u00b4c \u00b5 \u03b2 n\u02d9`L 2 \u00b5 d lnp1{\u03b4 0 q 2 0 M n\u02d9.(9)\n1. If f p\u00a8, xq is convex, then setting R \" max\u02dc? M 0n\n? d , 2 0 n 2 d # 1 K if M = N 1 otherwise\u00b8y ields E p F p p w R q\u00b4p F pw\u02daq \" r O\u02dcLD\u02dca d lnp2{\u03b4 0 q 0 n ? M\u00b8\u00b8.(10)\n2. If f p\u00a8, xq is \u00b5-strongly convex, then setting R \" max\u02dc? M 0n\n? d ln\u00b4D \u00b5M 2 0 n 2 Ld\u00af, 2 0 n 2 d # 1 K if M = N 1 otherwise\u00b8y ields E p F p p w R q\u00b4p F pw\u02daq \" r O\u02c6L 2 \u00b5\u02c6d lnp2{\u03b4 0 q 2 0 n 2 M\u02d9\u02d9.(11)\nThe r O notation hides a logarithmic factor depending on problem parameters other than \u03b4 0 . \n\n\nLower Bounds for LDP FL\n\nWe provide tight lower bounds on the excess population/empirical loss of LDP algorithms for the federated SCO/ERM problems when M \" N . As a consequence, Algorithm 1 and Algorithm 2 are minimax optimal for i.i.d. SCO and ERM respectively, for two function classes: F L,D :\" tf : W\u02c6X \u00d1 R d | @x P X f p\u00a8, xq is convex, L-Lipschitz, and W \u010e B 2 p0, Dqu; and G \u00b5,L,D :\" tf P F L,D | @x P X f p\u00a8, xq is \u00b5-strongly convexu. For SCO, the p 0 , \u03b4 0 q-LDP algorithm class A p 0,\u03b40q \" A that we consider contains all sequentially interactive algorithms, as well as fully interactive algorithms that are compositional (c.f. [JMNR19]):\n\nDefinition 4. Let A be an R-round p 0 , \u03b4 0 q-LDP FL algorithm with data domain X . Let tp 0 r , \u03b4 0 r qu R r\"1 denote the minimal (non-negative) parameters of the local randomizers R piq r selected at round r (r P rRs) such that R piq r pZ p1:r\u00b41q ,\u00a8q : X n \u00d1 Z is p 0 r , \u03b4 0 r q-DP for all i P rN s and all Z p1:r\u00b41q P Z pr\u00b41qN . For an absolute constant\nC \u0105 0, we say that A is C-compositional if b \u0159 rPrRs p r 0 q 2 \u010f C 0 .\nIf such a C exists, we simply say A is compositional.\n\nAny p 0 , \u03b4 0 q-LDP A has r 0 \u010f 0 . The vast majority of p 0 , \u03b4 0 q-LDP algorithms studied in the literature satisfy Definition 4. For example, any algorithm that uses the strong composition theorems of [DR14, Thm. 3.20] or [KOV15] for its privacy analysis is 1-compositional. In particular, the three algorithms presented in Section 2 are 1-compositional, hence they are in A. One might suspect that all LDP algorithms are compositional, but this is not the case. A simple modification of [JMNR19, Example 2.2] shows that for any C \u0105 0, there is an p 0 , \u03b4 0 q-LDP algorithm A and a data domain X such that A fails to be C-compositional. See Appendix E.1.\n\nTheorem 3.1. Let n, d, N, R P N, 0 P p0, ? N s, \u03b4 0 P p0, 1q and A P A p 0,\u03b40q such that in every round r P rRs, the local randomizers R piq r pZ p1:r\u00b41q ,\u00a8q : X n \u00d1 Z are p r 0 , \u03b4 r 0 q-DP for all i P rN s, Z p1:r\u00b41q P Z r\u00b41\u02c6N , with r 0 \u010f 1 n , and N \u011b 16 lnp2{\u03b4 min 0 nq, where \u03b4 min 0 :\" min r \u03b4 r 0 . If A is if A is sequentially interactive, assume \u03b4 0 \" op1{n 2 N 2 q; if A is compositional, assume \u0159 r \u03b4 r 0 \" op1{n 2 N 2 q instead. Then there exists a \u03b2-smooth (@\u03b2 \u011b 0) loss f P F L,D and a distribution D on a set X such that if the local data sets are drawn i.i.d. X i \" D n , then:\nEF pApXqq\u00b4F pw\u02daq \" r \u2126\u02dcLD\u02dc1 ? N n`m in # 1, ? d 0 n ? N +\u00b8\u00b8.(12)\nFurthermore, there exists another (\u00b5-smooth) f P G \u00b5,L,D and distribution D such that\nEF pApXqq\u00b4F pw\u02daq \" r \u2126\u02c6L 2 \u00b5nN`L D min \" 1, d 2 0 n 2 N *\u02d9.(13)\nThese lower bounds are essentially tight 7 by Theorem 2.2. The first term in each of the lower bounds is the optimal non-private rate; the second parts of the bounds are what we prove in Appendix E.2.\n\nTheorem 3.1 is more generally applicable than the lower bounds in [DJW13, Proposition 3] (for the L 2 setting) and [STU17, Theorem 31], which only apply to sequentially interactive LDP algorithms and databases with n \" 1 sample per client. A corollary of Theorem 3.1 is that setting n \" 1 in (13) gives a lower bound for classical LDP i.i.d. SCO with strongly convex loss, which-to the best of our knowledge-was not previously known; [DJW13, STU17] only provide lower bounds for convex loss. As in [DJW13] and [STU17], 7 Up to logarithms, and for strongly convex case-a factor of \u00b5D{L. If d \u0105 2 0 n 2 N , then the trivial algorithm attains the matching upper bound OpLDq. our lower bounds hold for sufficiently private LDP algorithms-those for which the privacy loss on each client in each round r 0 \u00c0 1{n 8 . For n \" 1, 0 \u010f 1{n \" 1 is required in [DJW13, Proposition 3] and [STU17, Claim 29]; this implies r 0 \u010f 1{n. Also, the assumptions on \u03b4 0 , \u03b4 r 0 are not very restrictive in practice; see Remark E.1. To prove Theorem 3.1, we first analyze the central privacy guarantees of A P A p 0 ,\u03b40q when client data sets X 1 ,\u00a8\u00a8\u00a8, X N are shuffled each round before the randomizers are applied, showing that privacy amplifies to \" r Op 0\n\n? N q (Theorem E.1 in the Appendix). This is an extension of [FMT20, Theorem 3.8] to n \u0105 1 and fully interactive compositional algorithm. The second step is to apply the CDP lower bounds of [BFTT19, Appendix C] to A s , the \"shuffled\" version of A. 9 This implies that the shuffled algorithm A s has excess population loss that is lower bounded as in Theorem 3.1. The final step in the proof is to observe that the i.i.d. assumption implies that A s and A have the same expected population loss.\n\nFor federated ERM, we proceed similarly and prove a tight lower bound in Theorem E.4, establishing the optimality of Algorithm 2 for an algorithm class B \u0102 A. Loosely speaking, B consists of algorithms in A that are symmetric with respect to each of the N clients (such as Algorithm 2).\n\n\nOptimal Algorithm for Shuffle DP FL\n\nAssume access to a secure shuffler. In each round r, the shuffler receives the reports pZ p1q r ,\u00a8\u00a8\u00a8Z pN q r q from clients, draws a uniformly random permutation of rN s, \u03c0, and then sends pZ p\u03c0p1qq r ,\u00a8\u00a8\u00a8, Z p\u03c0pN qq r q to the server for aggregation. We first show that this \"shuffled version\" of Algorithm 1 achieves the optimal convex/strongly convex CDP bounds for i.i.d. SCO ([BFTT19, FMT20]) when M \" N , even with the weaker trust assumptions of the shuffle model:\nTheorem 4.1. Let f : W\u02c6X \u00d1 R d be \u03b2-smooth, \u010f lnp2{\u03b4q, \u03b4 P p0, 1q, and M \u011b 16 lnp18RM 2 {N \u03b4q for R specified below. Then DC \u0105 0 such that \u03c3 2 i :\" CL 2 RM lnpRM 2 {N \u03b4q lnpR{\u03b4q lnp1{\u03b4q n 2 N 2 2\nensures that the shuffled Algorithm 1 is p , \u03b4q-CDP. Further:\n\n1. If f p\u00a8, xq is convex, then setting R :\" max\u00b4n\n2 N 2 2 M , N M , min ! n, 2 n 2 N 2 dM ) , \u03b2D L min ! ? nM , nN ? d )\u00afy ields EF p p w R q\u00b4F pw\u02daq \" r O\u02dcLD\u02dc1 ? nM`a d lnp1{\u03b4q nN\u00b8\u00b8.(14)\n2. If f p\u00a8, xq is \u00b5-strongly convex, then setting R :\" max\u00b4n\n2 N 2 2 M , N M , 8\u03b2 \u00b5 ln\u00b4\u03b2 D 2 \u00b5 2 n 2 N 2 dL 2\u00af, min ! n, 2 n 2 N 2 dM )\u0233 ields EF p p w R q\u00b4F pw\u02daq \" r O\u02c6L 2 \u00b5\u02c61 nM`d lnp1{\u03b4q 2 n 2 N 2\u02d9\u02d9.(15)\nThe r O notation hides logarithmic factors depending on problem parameters other than \u03b4.\n\nTogether with our LDP results, Theorem 4.1 implies that, with shuffling, Algorithm 1 is simultaneously optimal for i.i.d. FL in the local and central models of DP if M \" N . 10 Nesterov smoothing can be used to obtain the same bounds without the \u03b2-smoothness assumption, similar to how we proceeded for Theorem 2.2. We omit the details here.\n\nObserve that less noise (smaller \u03c3 2 i q is needed to achieve SDP compared to LDP, which results in smaller excess loss. This is because of the differing notions of adjacency (\u03c1) between LDP and SDP, and because shuffling amplifies privacy in the central model (see [FMT20, Theorem 3.8] and Theorem E.2). If M \u0103 N , then client subsampling amplifies privacy further. The proof of Theorem 4.1 (Appendix F) shows that the first term of each excess risk bound above is an upper bound on the uniform stability, hence generalization 8 If there are N \" Op1q clients, then existing CDP lower bounds [BFTT19] apply and match our LDP upper bounds as long as 0 \u00c0 1; thus, this restriction on r 0 disappears if N \" Op1q. 9 While [BFTT19] does not explicitly prove lower bounds for strongly convex CDP SCO, their proof technique easily extends to strongly convex loss, implying that EF p p w R q\u00b4F pw\u02daq \" r \u2126\u00b4L 2 \u00b5nN`L D d 2 n 2 N 2\u00aff or p , \u03b4q CDP algorithms with \u03b4 \" op1{nN q, by [BST14, Theorem 5.5].\n\n10 See Theorem E.3 for a re-statement of the known CDP SCO lower bounds.\n\nerror, of Algorithm 1, whereas the second terms are upper bounds on the empirical loss of Algorithm 1. In particular, for convex federated ERM, the first term in (14) vanishes and we recover the upper bound of [GDD`21, Theorem 1]. These convex/strongly convex ERM bounds are also tight by [BST14], even when M \u0103 N . The requirement that M \" N is only needed to achieve optimality for SCO because the uniform stability (generalization error) scales with M .\n\n\nDiscussion and Directions for Future Work\n\nIn this paper, we considered the problem of conducting federated learning privately without a trusted server. We proposed LDP and SDP as strong, practical privacy notions in this context, and discussed the merits of these privacy notions compared to central notions of DP (CDP and client-level DP). Our goal was to understand the best possible performance that any LDP/SDP algorithm could achieve in various convex/strongly convex problem settings (non-i.i.d., i.i.d., or ERM clients). Below, we discuss our results and point to possible directions for future work. nN\u00af. On the other hand, in the more restrictive notion of classical LDP, which assumes clients are untrusted and requires intra-client randomization, the rate is\n\u0398\u00b4? d ? nN\u00af[ DJW13, STU17]\n. Thus, our \"trusted clients, untrusted server\" LDP rate sits between the \"full trust\" CDP and \"no trust, even in clients\" classical LDP rates. Also, the bounds we established for LDP are only tight when M \" N , leading to the open question of what the optimal minimax rate is with unreliable communication (M \u0103 N ). We suspect our upper bounds are tight for all M \u010f N ; proving tight lower bounds when M \u0103 N is an interesting direction for future work.\n\nSecond, we developed an accelerated LDP algorithm (One-pass Accelerated Distributed SGD) that achieved the first non-trivial excess risk bound for non-i.i.d. FL. It is interesting to compare the bound in (8) to the optimal classical LDP, i.i.d. SCO rate of LD ?\nd{ 0 ? nN for M \" N [DJW13, STU17]\n, where clients are untrusted (so individuals must randomize their intra-client reports) but identically distributed. 11\nWhen n \u00c1\u00b4N d \u03b2 2 D 2 L 2\u00af1 {3\nand M \" N , (8) matches this rate, showing that private convex FL with trusted, heterogeneous clients (and untrusted server) is no harder than learning with untrusted, homogeneous clients (and untrusted server). Similarly, for strongly convex loss, if M \" N and n \u00c1 a \u03b2{\u00b5 lnpnN 2 0 {dq, then EF p p w R q\u00b4F pw\u02daq \u00c0 L 2 ? d{\u00b5 2 0 N n nearly matches the classical LDP i.i.d. rate (see Theorem 3.1 and the discussion that follows). We leave the following question to future work: can the bound in Theorem 2.3 be improved or is our algorithm optimal for non-i.i.d. LDP FL?\n\nFor federated ERM, we proposed a communication-efficient accelerated algorithm (Algorithm 2) and provided excess risk lower bounds to show that our algorithm is optimal. We proved these lower bounds for a subset B of the algorithm class A for which our i.i.d. SCO lower bounds hold-can these lower bounds be extended to the full class A? Also, what is the optimal LDP rate when M \u0103 N ?\n\nLast, we showed that the optimal i.i.d. SCO (and ERM) rates for CDP FL can be attained without a trusted server, via shuffling. It could be worth exploring other problem settings where a similar phenomenon holds. Finally, another direction for future work is understanding the problems studied in this paper when the loss function is non-convex.\n\n[ABRW12] Alekh Agarwal, Peter L. Bartlett [Exc] Math Stack Exchange. Total variation distance of two random vectors whose components are independent.\n\nhttps://math.stackexchange.com/questions/1558845/ total-variation-distance-of-two-random-vectors-whose-components-are-independent.\n\n[fed19]\n\nWebank and swiss re signed cooperation mou. Fed AI Ecosystem, Nov 2019.\n\n[  f or \u00b5-strongly convex, \u03b2-smooth f with condition number \u03ba \" \u03b2{\u00b5, r N \" \u0159 N i\"1 n i , and 1{ 2 is an average of 1{ 2 i . The additive term is clearly problematic: e.g. if \" 1, then the bound becomes trivial. Ignoring this term, the first term in their bound is still looser than the bound that we provide in Theorem 2.4. Namely, our bound in part 2 of Theorem D.1 is tighter by a factor of O\u00b4l np1{\u03b4q \u03ban\u00af. Additionally, the bounds in [WFSK19] require R \"large enough\" and do not come with communication complexity guarantees. In the convex case, the LDP ERM bound reported in [WFSK19, Theorem 3] is not interpretable because the unspecified \"constants\" in the upper bound on E p F p p w R q\u00b4p F pw\u02daq are said to be allowed to depend on R. [WLD`20b, Theorems 2 and 3] provide convergence rates for smooth PL convex LDP ERM, which are complicated non-monotonic functions of R. Since they do not prescribe a choice of R, it is unclear what excess risk and communication complexity bounds are attainable with their algorithm. In particular, they do not prove any excess risk bounds.\n\n[ Ri gnoring smoothness and strong convexity factors, where \u0398 is a parameter that they only provide an upper bound for in special cases (e.g. quadratic objective). Thus, their bounds are not complete for general strongly convex loss functions. Even in the special cases where they do provide a bound for \u0398, our bounds are much tighter. Assuming that \u0398 \" 1 and (for simplicity of exposition) that parameters are the same across clients, their Theorem 3.1 implies taking \u03c3 2 \" 1{ 2 to ensure p , 0q-LDP. The resulting convergence rate is then OpM { 2 q, which does not scale with n i and is increasing with M. Also, the dependence of their rate on the dimension d is unclear, as it does not appear explicitly in their theorem. 12 Ignoring this issue, their bound (particularly the dependence on M and n i ) is clearly much looser than all of the excess risk bounds we give in the present work.\n\n[ZZY`20] and [ABK`19] apply the LDP FL framework to Internet of Things, and [STL20] uses noisy (deterministic) GD for LDP wireless channels in the FL (smooth strongly convex) ERM setting. Their bounds do not scale with the number of data points n i , however (only with the number of clients N ). Therefore, our bounds are much tighter, and apply to general convex FL problems besides wireless channels. B Assumption that p i \" 1{N for all i P rN s\n\nThe assumption that p i \" 1 N for all i P rN s in (2) is without loss of generality by considering the transformation\nr F i pwq :\" p i N F i pwq. Then F pwq \" \u0159 N i\"1 p i F i pwq \" 1 N \u0159 N i\"1\nr F i pwq, so our results for p i \" 1{N apply for general p i with L i replaced by \u0102 L i :\" p i N L i , \u00b5 i replaced by r \u00b5 i :\" p i N \u00b5 i , and \u03b2 i gets replaced by r \u03b2 i :\" p i N \u03b2 i . In particular, if X i \" X for all i, then L gets replaced with r L \" max iPrN s p i N L, \u00b5 gets replaced with r \u00b5 \" max iPrN s p i N \u00b5, \u03b2 gets replaced with r \u03b2 \" max iPrN s p i N \u03b2.\n\n\nC Relationships between notions of DP\n\n\nC.1 LDP is stronger than CDP\n\nAssume A is p 0 , \u03b4 0 q-LDP. Let X, X 1 be adjacent databases in the CDP sense; i.e. there exists a unique i P rN s, j P rn i s such that x i,j \u2030 x 1 i,j . Then for all r P rRs, l \u2030 i, X l \" X 1 l , so the conditional distributions of R plq r pZ 1:r\u00b41 , X l q and R plq r pZ 1 1:r\u00b41 , X 1 l q given Z pl 1 \u2030lq 1:r\u00b41 \" z pl 1 \u2030lq 1:r\u00b41 are identical for all z pl 1 \u2030lq 1:r\u00b41 P Z r\u00b41\u02c6N\u00b41 . Integrating both sides of this equality with respect to the joint density of Z pl 1 \u2030lq 1:r\u00b41 shows that R plq r pZ 1:r\u00b41 , X l q \" R plq r pZ 1 1:r\u00b41 , X 1 l q (unconditional equality of distributions). Hence the full transcript of client l is (unconditionally) p0, 0q-CDP for all l \u2030 i. A similar argument (using the inequality (3) instead of equality) shows that client i's full transcript is unconditionally p 0 , \u03b4 0 q-CDP. Therefore, by the basic composition theorem for DP [DR14], the full combined transcript of all N clients is p 0 , \u03b4 0 q-CDP, which implies that A is p 0 , \u03b4 0 q-CDP.\n\nConversely, p , \u03b4q-CDP does not imply p 1 , \u03b4 1 q-LDP for any 1 , \u03b4 1 . This is because a CDP algorithm may send non-private updates to the server and rely on the server to randomize, completely violating the requirement of LDP.\n\nC.2 LDP is \"stronger\" than client-level DP Precisely, we claim that if A is p 0 , \u03b4 0 q-LDP then A is pn , ne pn\u00b41q \u03b4q client-level DP; but conversely p , \u03b4qclient-level DP does not imply p 1 , \u03b4 1 q-LDP for any 1 , \u03b4 1 . The first part of the claim is due to group privacy [Kam20, Theorem 10] (and the argument used above in Appendix C.1 to get rid of the \"conditional\"). The second part of the claim is true because a client-level DP algorithm may send non-private updates to the server and rely on the server to randomize, completely violating the requirement of LDP.\n\n\nD Complete Versions and Proofs of Upper Bounds for LDP FL\n\n\nD.1 Notation and assumptions for stating the complete versions of our upper bounds\n\nIn addition to Assumption 2 and the notation introduced in the main body of the paper, we will also require the following notations and assumptions to state the complete, general forms of our upper bound theorems.\n\nAssumption 3. For all i P rN s :\n\n1. E xi\"Di }\u2207f pw, x i q\u00b4\u2207F i pwq} 2 \u010f p\u03c6 i q 2 for all w P W, or:\n\n2. E xi\"Di }\u2207f pw\u02da, x i q\u00b4\u2207F i pw\u02daq} 2 \u010f p\u03c6i q 2 for any w\u02daP argmin wPW F pwq. \n\u011a \u03c6 2 M :\" 1 M M \u00ff i\"1 \u03c6 2 piq ,\nwhere \u03c6 p1q :\" \u03c6 max :\" max iPrN s \u03c6 i \u011b \u03c6 p2q \u011b\u00a8\u00a8\u00a8\u011b \u03c6 pN q :\" \u03c6 min :\" min iPrN s \u03c6 i , and define \u011e p\u03c6M q 2 similarly. More generally, whenever a bar and M subscript are appended to a parameter in this paper, it denotes the average of the M largest values. Also, define\n\u03a6 2 :\" b Erp \u011a \u03c6 2 M1 q 2 s and \u03a3 2 :\" b Ep \u011a \u03c3 2 M1 q 2\nfor any t\u03c3 2 i u N i\"1 \u010e r0, 8q. Next, define the heterogeneity parameters ]. If the data is homogeneous, then all F i share the same minimizers, so \u03c5 2 \" 0, but the converse is false. Also, \u03c5 2 \" 0 iff F i \" F`a i for constants a i P R, i P rN s (homogeneous up to translation). Denote\n\u03a5 2 :\" #\u00b41\u00b4M\u00b41 N\u00b41\u00af\u03c5 2 if N \u0105 1 0 otherwise\nand its counterpart \u03a5 2 , defined similarly but with \u03c5 2 . Also, we denote K :\" min iPrN s K i . Lastly, for given parameters, denote\n\u03c8 i :\"\u02c6L i n i i\u02d92 lnp2.5R{\u03b4 i q lnp2{\u03b4 i q for i P rN s, \u03a8 :\" g f f e E M1\u02dc1 M 1 M1 \u00ff i\"1 \u03c8 piq\u00b82 , \u03be i :\" \u03c8 i {L 2 i , and \u039e :\" g f f e E M1\u02dc1 M 1 M1 \u00ff i\"1 \u03be piq\u00b82 .\nIn the case of balanced data and same parameters across clients, \u03c8 i \" \u03c8 \" L 2 lnp2.5R{\u03b4q lnp2\u03b4q{n 2 2 \" \u03a8 for all i and similarly \u03be i \" \u03be \" \u039e for all i. In the general case, we have \u03c8 min \u010f \u03a8 \u010f \u03c8 max and \u03be min \u010f \u039e \u010f \u03be max .\n\n\nD.2 Complete statement and proof of Theorem 2.1\n\nWe first state the fully general version of Theorem 2.1 for arbitrary n i , i , \u03b4 i . Theorem 2.1 [Complete Version] Let f : W\u02c6X \u00d1 R be convex, L-Lipschitz, and \u03b2-smooth in w for all x P X , where W is a closed convex set in R d s.t. }w} \u010f D for all w P W. Let D be an arbitrary probability distribution on X . For each client i P rN s, draw a local i.i.d. data set X i \" D ni . Run Algorithm 1 and\n\u03c3 2 i \" 256L 2 R lnp 2.5R \u03b4 i q lnp2{\u03b4iq n 2 i 2 i\n. Then the algorithm is tp i , \u03b4 i qu iPrN s -LDP for any i P p0, lnp 2 \u03b4i qs and \u03b4 i P p0, 1q,\nprovided K i \u011b in 4 ? 2R lnp2{\u03b4iq\n. Moreover, we get the following excess population loss bounds:\n1. (Convex): Choose \u03b3 r \" 1 R and constant step-size \u03b7 \" min t1{4\u03b2, r \u03b7u, where r \u03b7 \" D ? \u0102 M LR min \" ? n min , L ? d r \u03a8 * , where \u0102 M :\" # ? M 1 if \u03a8 M 1 \u010f \u03c8max M ?\nM otherwise and r \u03a8 :\"\n# \u03a8 if \u03a8 M 1 \u010f \u03c8max M \u03c8 max otherwise . Similarly, denote r \u039e :\" r \u03a8{L 2 . Then, EF p p w R q\u00b4F pw\u02daq \u010f 272 LD a \u0102 M max \" 1 ? n min , a d r \u039e * in R :\" R max\u02c6\u03b2 D ? \u0102 M L min \" ? n min , 1 ? d r \u039e * , min ! n min , 1 d r \u039e )\n{K\u02d9V rounds of communication.\n\n\n(Strongly Convex)\n\nAssume additionally that f p\u00a8, xq is \u00b5-strongly convex for all x P X . Choose the following constant step-size and averaging weights:\n\u03b7 r \" \u03b7 \" min $ ' ' ' ' ' ' & ' ' ' ' ' ' % 1 4\u03b2 , ln\u00a8max $ & % 2, \u00b5 2 D 2 R 2 2\u02c64 L 2 M K`d min \" \u03a3 2 M 1 , \u03c3 2 max M *\u02d9, . -\u201a \u00b5R , / / / / / / . / / / / / / - , \u03b3 r \" p1\u00b4\u00b5\u03b7q\u00b4p r`1q . Then choosing R \" \u00bb - - - $ & % max ! 8\u03b2 \u00b5 ln\u00b4\u03b2 D 2 \u00b5M 1 d\u03a8\u00af, L 2 d\u03a8 ) if \u03a8 M 1 \u010f \u03c8max M max ! 8\u03b2 \u00b5 ln\u00b4\u03b2 D 2 \u00b5M d\u03c8max\u00af, L 2 d\u03c8max ) otherwise fi ffi ffi ffi implies EF p p w R q\u00b4F pw\u02daq \" r O\u02c6L 2 \u00b5\u02c61 M n min`d min \" \u039e M 1 , \u03be max M *\u02d9\u02d9.(16)\nRemark D.1. Note that 1{M 1 \u011b 1{M by Cauchy-Schwartz. Both of the upper bounds in the complete version of Theorem 2.1 involve minima of the terms \u039e{M 1 and \u03be max {M, which trade off the unbalancedness of client data and privacy needs with the variance of 1{M r . In particular, if the variance of 1{M r is small enough that \u039e M 1 \u010f \u03bemax M , then the communication complexity and excess risk bounds in the complete version of Theorem 2.1 depend on averages of the parameters across clients, rather than maximums. In FL problems with unbalanced/heterogeneous data and disparate privacy needs across a large number of clients, the difference between \"average\" and \"max\" can be substantial. On the other hand, if data is balanced and privacy needs are the same across clients, then \u03be i \" \u03be max \" \u039e \" lnp2.5R{\u03b4 0 q lnp2{\u03b4 0 q{n 2 2 0 for all i and \u039e M 1 \u011b \u03bemax M , so we recover the informal version of Theorem 2.1 stated in the main body, with dependence only on the mean 1{M of 1{M r and not the second moment 1{M 1 . Similar remarks apply to the rest of the upper bounds presented in this Appendix.\n\nWe will require some preliminaries before we move to the proof of Theorem 2.1. We begin with the following definition from [BE02]:\n\nDefinition 5. (Uniform Stability) A randomized algorithm A : W\u02c6X \u0102 N is said to be \u03b1-uniformly stable (w.r.t. loss function f : W\u02c6X ) if for any pair of adjacent data sets X, X 1 P X \u0102 N , |X\u2206X 1 | \u010f 2, we have sup xPX E A rf pApXq, xq\u00b4f pApX 1 q, xqs \u010f \u03b1.\n\nThe following lemma, which is well-known, allows us to easily pass from empirical risk to population loss when the algorithm in question is uniformly stable:\n\nLemma D.1. Let A : X \u0102 N \u00d1 W be \u03b1-uniformly stable w.r.t. convex loss function f : W\u02c6X \u00d1 R. Let D be any distribution over X and let X \" D \u0102 N . Then the excess population loss is upper bounded by the excess expected empirical loss plus \u03b1:\nErF pApXq, Dq\u00b4F\u02das \u010f \u03b1`Er p F pApXq, Xq\u00b4min wPW p F pw, Xqs,\nwhere the expectations are over both the randomness in A and the sampling of X \" D \u0102 N . Here we denote the empirical loss by p F pw, Xq and the population loss by F pw, Dq for additional clarity, and F\u02da:\" min wPW F pw, Dq \" min wPW F pwq.\n\n\nProof. By [HRS16, Theorem 2.2],\n\nErF pApXq, Dq\u00b4p F pApXq, Xqs \u010f \u03b1.\n\n\nHence\n\nErF pApXq, Dq\u00b4F\u02das \" ErF pApXq, Dq\u00b4p F pApXq, Xq`p F pApXq, Xq\nmin wPW p F pw, Xq`min wPW p F pw, Xq\u00b4F\u02das \u010f \u03b1`Er p F pApXq, Xq\u00b4min wPW p F pw, Xqs, since E X\"D N min wPW p F pw, Xq \u010f min wPW E \" p F pw, Xq \u0131 \" min wPW F pw, Dq \" F\u02da.\nThe next step is to bound the uniform stability of Algorithm 1:\n\nLemma D.2. Let f p\u00a8, xq be convex, L-Lipschitz, and \u03b2-smooth loss for all x P X . Then under Assumption 2, Algorithm 1 with constant stepsize \u03b7 \u010f 1 \u03b2 is \u03b1-uniformly stable with respect to f for \u03b1 \" 2L 2 R\u03b7 nminM , where n min \" min iPrN s n i . If, in addition f p\u00a8, xq is \u00b5-strongly convex, for all x P X , then under Assumption 2, Algorithm 1 with constant step size \u03b7 r \" \u03b7 \u010f 1 \u03b2 and any averaging weights \u03b3 r is \u03b1-uniformly stable with respect to f for \u03b1 \" . For simplicity, assume K i \" K for all i: it will be clear from the proof that K i does not affect the result. For now, fix the randomness of tM r u r\u011b0 . Let X, X 1 P X \u0102 N be two data sets, denoted X \" pX 1 ,\u00a8\u00a8\u00a8, X N q for X i P X ni for all i P rN s and similarly for X 1 , and assume |X\u2206X 1 | \" 2. Then there is a unique a P rN s and b P rn i s such that x a,b \u2030 x 1 a,b . For t P t0, 1,\u00a8\u00a8\u00a8, Ru, denote the t-th iterates of Algorithm 1 on these two data sets by w t \" w t pXq and w 1 t \" w t pX 1 q respectively. We claim that\nE \" }w t\u00b4w 1 t } |t M r u 0\u010fr\u010ft \u2030 \u010f 2L\u03b7 n min t \u00ff r\"0 1 M r(17)\nfor all t. We prove the claim by induction. It is trivially true when t \" 0. Suppose (17) holds for all t \u010f \u03c4. Denote the samples in each local mini-batch at iteration \u03c4 by tx i,j u iPrN s,jPrKs (dropping the \u03c4 for brevity). First condition on the randomness due to minibatch sampling and due to the Gaussian noise. That is, assume that the averages of the Gaussian vectors u i , u 1 i added to the stochastic gradients at iteration \u03c4 of the algorithm run on X and X 1 respectively are fixed (non-random) vectors: s u :\" 1 M\u03c4 \u0159 iPS\u03c4 u i and s u 1 :\" 1 M\u03c4 \u0159 iPS\u03c4 u 1 i . Assume WLOG that S \u03c4 \" rM \u03c4 s. Observe that the function r Gpwq \" gpwq`} s u} 2 2 whose gradient equals \u2207gpwq`s u is still convex and \u03b2-smooth if g is. Apply this observation to the convex \u03b2-smooth function gpwq \" 1\n\n\nM\u03c4 K\n\n\u0159 iPrM\u03c4 s f pw \u03c4 , x i,j q. Denote r g \u03c4 \"\u00b41 M\u03c4 K \u0159 iPrM\u03c4 s,jPrKs \u2207f pw \u03c4 , x i,j q\u00af`s u and r g 1 \u03c4 \"\u00b41 M\u03c4 K \u0159 iPrM\u03c4 s,jPrKs \u2207f pw \u03c4 , x 1 i,j q\u00af`s u 1 . Then by non-expansiveness of projection, we have\n}w \u03c4`1\u00b4w 1 \u03c4`1 } \" \u203a \u203a \u03a0 W pw \u03c4\u00b4\u03b7\u03c4 r g \u03c4 q\u00b4\u03a0 W`w 1 \u03c4\u00b4\u03b7\u03c4 r g 1 \u03c4\u02d8\u203a \u203a \u010f \u203a \u203a pw \u03c4\u00b4\u03b7\u03c4 r g \u03c4 q\u00b4pw 1 \u03c4\u00b4\u03b7\u03c4 r g 1 \u03c4 q \u203a \u203a \u010f\u02c7\u02c7\u02c7\u02c7\u02c7\u02c7\u02c7\u02c7w r\u00b4\u03b7r\u02dc\u02dc1 M r K \u00ff pi,jq\u2030pa,bq \u2207f pw r , x i,j q\u00b8`s uw 1 r\u00b4\u03b7r\u02dc\u02dc1 M r K \u00ff pi,jq\u2030pa,bq \u2207f pw 1 r , x i,j q\u00b8`s u 1\u00b8\u00b8\u02c7q \u03c4 \u03b7 \u03c4 M \u03c4 K \u203a \u203a \u2207f pw \u03c4 , x a,b q\u00b4\u2207f pw 1 \u03c4 , x 1 a,b q \u203a \u203a \u010f}w \u03c4\u00b4w 1 \u03c4 }`q \u03c4 \u03b7 \u03c4 M \u03c4 K \u203a \u203a \u2207f pw \u03c4 , x a,b q\u00b4\u2207f pw 1 \u03c4 , x 1 a,b q \u203a \u203a ,\nwhere q \u03c4 P t0, 1,\u00a8\u00a8\u00a8, Ku is a realization of the random variable Q \u03c4 that counts the number of times index b occurs in worker a's local minibatch at iteration \u03c4, and we used non-expansiveness of the gradient descent step [HRS16, Lemma 3.7] for \u03b7 \u010f 2 \u03b2 (and the observation above about translating a smooth convex function by s u) in the last inequality. (Recall that we sample uniformly with replacement.) Now Q \u03c4 is a sum of K independent Bernoulli( 1 na q random variables, hence EQ \u03c4 \" K na . Then using the inductive hypothesis and taking expected value over the randomness of the Gaussian noise and the minibatch sampling proves the claim. (Note that in the worst case, we would have a P argmin iPrN s n i .) Next, taking expectation with respect to the randomness of tM r u rPrts implies\nE}w t\u00b4w 1 t } \u010f 2Lt n min M ,\nsince the M r are i.i.d. with Ep 1 M1 q \" 1 M . Then Jensen's inequality and Lipschitz continuity of f p\u00a8, xq imply that for any x P X ,\nErf p \u010e w R , xq\u00b4f p \u010e w 1 R , x 1 qs \u010f LE} \u010e w R\u00b4\u010e w 1 R } \u010f L R R\u00b41 \u00ff t\"0 E}w t\u00b4w 1 t } \u010f 2L 2 \u03b7 RM n min RpR`1q 2 \" L 2 \u03b7pR`1q M n min ,\ncompleting the proof of the convex case.\n\nNext suppose f is \u00b5-strongly convex. The proof begins identically to the convex case. We condition on M r , u i , and S r as before and (keeping the same notation used there) get for any r \u011b 0\n}w r`1\u00b4w 1 r`1 } \u010f\u02c7\u02c7\u02c7\u02c7\u02c7\u02c7\u02c7\u02c7w r\u00b4\u03b7r\u02dc\u02dc1 M r K \u00ff pi,jq\u2030pa,bq \u2207f pw r , x i,j q\u00b8`s uw 1 r\u00b4\u03b7r\u02dc\u02dc1 M r K \u00ff pi,jq\u2030pa,bq \u2207f pw 1 r , x i,j q\u00b8`s u 1\u00b8\u00b8\u02c7q r \u03b7 r M r K \u203a \u203a \u2207f pw r , x a,b q\u00b4\u2207f pw 1 r , x 1 a,b q \u203a \u203a .\nWe will need the following tighter estimate of the non-expansiveness of the gradient updates to bound the first term on the right-hand side of the inequality above: Note that G r pw r q :\" 1 MrK \u0159 pi,jq\u2030pa,bq,pi,jqPrMrs\u02c6rKs f pw r , x r i,j q is p1\u00b4q r MrK q\u03b2-smooth and p1\u00b4q r MrK q\u00b5-strongly convex and hence so is G r pw r q`s u. Therefore, invoking Lemma D.3 and the assumption \u03b7 r \" \u03b7 \u010f 1 \u03b2 , as well as Lipschitzness of f p\u00a8, xq@x P X , yields\n}w r`1\u00b4w 1 r`1 } \u010f\u02dc1\u00b4\u03b7 \u00b5p1\u00b4q r MrK q 2\u00b8} w r\u00b4w 1 r }`2 q r \u03b7L M r K .\nNext, taking expectations over the M r (with mean Ep 1 Mr q \" 1 M ), the minibatch sampling (recall Eq r \" K na ), and the Gaussian noise implies\nE}w r`1\u00b4w 1 r`1 } \u010f\u02dc1\u00b4\u03b7 \u00b5p1\u00b41 naM q 2\u00b8E }w r\u00b4w 1 r }`2 \u03b7L n a M .\nOne can then prove the following claim by an inductive argument very similar to the one used in the proof of the convex part of Lemma D.2: for all t \u011b 0,\nE}w t\u00b4w 1 t } \u010f 2\u03b7L n a M t \u00ff r\"0 p1\u00b4bq r , where b :\" \u00b5\u03b7 2\u00b4n a M\u00b41\nnaM\u00af\u0103 1. The above claim implies that\nE}w t\u00b4w 1 t } \u010f 2\u03b7L n a M\u02c61\u00b4p 1\u00b4bq t`1 b\u010f 4L \u00b5pn a M\u00b41q \u010f 4L \u00b5pn min M\u00b41q .\nFinally, using the above bound together with Lipschitz continuity of f and Jensen's inequality, we obtain that for any x P X ,\nErf p p w R , xq\u00b4f p p w 1 R , xqs \u010f LE} p w R\u00b4p w 1 R } \" LE \u203a \u203a \u203a \u203a \u203a 1 \u0393 R R\u00b41 \u00ff r\"0 \u03b3 r pw r\u00b4w 1 r q \u203a \u203a \u203a \u203a \u203a \u010f LE \u00ab 1 \u0393 R R\u00b41 \u00ff r\"0 \u03b3 r }w r\u00b4w 1 r } ff \u010f L \u00ab 1 \u0393 R R\u00b41 \u00ff r\"0 \u03b3 r\u02c64 L \u00b5pn min M\u00b41q\u02d9ff \" 4L 2 \u00b5pn min M\u00b41q ,\nwhich completes the proof of Lemma D.2.\n\nFinally, we bound the empirical loss of Algorithm 1:\n\nLemma D.4. Let f : W\u02c6X \u00d1 R be \u00b5-strongly convex (with \u00b5 \" 0 for convex case), L-Lipschitz, and \u03b2-smooth in w for all x P X , where W is a closed convex set in R d s.t. }w} \u010f D for all w P W. Let X P X n1\u02c6\u00a8\u00a8\u00a8X n N . Then Algorithm 1 with \u03c3 2 i \"\n256L 2 R lnp 2.5R \u03b4 i q lnp2{\u03b4iq n 2 i 2 i\nattains the following empirical loss bounds: 1. (Convex) For any \u03b7 \u010f 1{4\u03b2 and R P N, \u03b3 r :\" 1{R, we have\nE p F p p w R q\u00b4p F pw\u02daq \u010f D 2 \u03b7R`2 \u03b7 \" min \" \u03a6 2 M 1 K , p\u03c6m ax q 2 M K *`\u03a5 2 M`d 2 min \" \u03a3 2 M 1 , \u03c3 2 max M *\uf6be .\n2. (Strongly Convex) Choose the following constant step-size and averaging weights:\n\u03b7 r \" \u03b7 \" min $ ' ' ' ' ' ' & ' ' ' ' ' ' % 1 4\u03b2 , ln\u00a8max $ & % 2, \u00b5 2 D 2 R 2 2\u02c6min \" s L 2 M 1 , L 2 max M *`d min \" \u03a3 2 M 1 , \u03c3 2 max M *\u02d9, .\n-\u201a \u00b5R\n, / / / / / / . / / / / / / - , \u03b3 r \" p1\u00b4\u00b5\u03b7q\u00b4p r`1q . Then choosing R \" $ & % max ! 8\u03b2 \u00b5 ln\u00b4\u03b2 D 2 \u00b5M 1 d\u03a8\u00af, L 2 d\u03a8 ) if \u03a8 M 1 \u010f \u03c8max M max ! 8\u03b2 \u00b5 ln\u00b4\u03b2 D 2 \u00b5M d\u03c8max\u00af, L 2 d\u03c8max )\notherwise (and assuming R \u011b 1) implies\nE p F p p w R q\u00b4p F pw\u02daq \" r O\u02c6L 2 \u00b5 d min \" \u039e M 1 , \u03be max M *\u02d9.(18)\nThe proof of Lemma D.4 will require some additional lemmas (some of which will come in handy for later results too): First, observe that if we assume that the subset S r of M r P rN s active clients is drawn uniformly (i.e. Assumption 2), then the stochastic gradients r g r in line 7 of Algorithm 1 are unbiased estimates of \u2207F pw r q. Furthermore, their variance is upper bounded as follows:\n\nLemma D.5. Suppose Assumption 2 holds. Let f : W\u02c6X \u00d1 R be a convex loss function and let r g r :\" 1 Mr \u0159 iPSr 1 Ki \u0159 jPrKis p\u2207f pw r , x r i,j q`u i q, where px r i,j q jPrKs are sampled (with replacement) from X i and u i \" N p0, \u03c3 2 i I d q is independent of \u2207f pw r , x r i,j q for all i P rN s, j P rK i s. Denote K :\" min iPrN s K i . Assume N \u0105 1. If f satisfies the first part of Assumption 3, then E} r g r\u00b4\u2207 F pw r q} 2 \u010f min\n\" \u03a6 2 M 1 K , \u03c6 2 max M K *`\u02c61\u00b4M\u00b41 N\u00b41\u02d9\u03c5 2 M`d min \" \u03a3 2 M 1 , \u03c3 2 max M * , where \u03a6 2 :\" b Ep \u011a \u03c6 2 M1 q 2 , and \u03a3 2 \" b Ep \u011a \u03c3 2 M1 q 2 .\nIf instead f satisfies the second part of Assumption 3, then for r g r evaluated at w r \" w\u02daP argmin wPW F pwq, we have\nE} r g r } 2 \u010f min \" \u03a6 2 M 1 K , p\u03c6m ax q 2 M K *`\u02c61\u00b4M\u00b41 N\u00b41\u02d9\u03c5 2 M`d min \" \u03a3 2 M 1 , \u03c3 2 max M * , where \u03a6 2 :\" b\nEr \u011e p\u03c6M 1 q 2 s 2 . If N \" 1, then the second (middle) term on the right-hand side of each inequality above vanishes.\n\nThe three terms on the right-hand side of each inequality correspond (from left to right) to the variances of: local minibatch sampling within each client, the draw of the client set S r of size M r under Assumption 2, and the Gaussian noise. Also, note that M \u011b M 1 by Cauchy-Schwartz. Each minimum on the right-hand side is attained by the first term if 1{M r has small variance (so that 1{M 1 \u00ab 1{M ) and/or if the clients are fairly heterogeneous, so that parameters measuring averages (e.g. \u03a3 2 ) are much smaller than the corresponding maxima (e.g. \u03c3 2 max ). In the complementary case, the minima are attained by the second terms. We now turn to the proof of Lemma D.5.\n\nProof of Lemma D.5. Assume f satisfies the first part of Assumption 3. First, fix the randomness due to the size of the client set M r . Now r g r \" g r`s u r , where s u r \" 1 Mr \u0159 Mr i\"1 u i \" N p0, \u03c3 2 Mr I d q for some \u03c3 2 \u010f \u011a \u03c3 2 Mr \" 1 Mr \u0159 Mr i\"1 \u03c3 2 piq and s u r is independent of g r :\" 1 Mr \u0159 iPSr 1 Ki \u0159 jPrKis \u2207f pw r , x r i,j q. Hence, Er} r g r\u00b4\u2207 F pw r q} 2 |M r s \" Er}g r\u00b4\u2207 F pw r q} 2 |M r s`Er}s u} 2 |M r s \u010f Er}g r\u00b4\u2207 F pw r q} 2 |M r s`d\n\u011a \u03c3 2 Mr M r .\nLet us drop the r subscripts for brevity (denoting g \" g r , w \" w r , S \" S r , and M r \" M 1 since they have the same distribution) and denote h i :\" 1 Ki \u0159 Ki j\"1 \u2207f pw, x i,j q. Now, we have (conditionally on M 1 )\nEr}g\u00b4\u2207F pwq} 2 |M 1 s \" E \u00bb - \u203a \u203a \u203a \u203a \u203a 1 M 1 \u00ff iPS 1 K i Ki \u00ff j\"1 \u2207f pw, x i,j q\u00b4\u2207F pwq \u203a \u203a \u203a \u203a \u203a 2\u02c7M 1 fi fl \" E \u00bb - \u203a \u203a \u203a \u203a \u203a 1 M 1 \u00ff iPS p\u2207h i\u00b4\u2207 F i pwqq`1 M 1 \u00ff iPS \u2207F i pwq\u00b4\u2207F pwq \u203a \u203a \u203a \u203a \u203a 2\u02c7M 1 fi fl \" 1 M 2 1 E \u00ab } \u00ff iPS h i pwq\u00b4\u2207F i pwq} 2\u02c7M 1 ff l jh n a \u25cb 1 M 2 1 E \u00ab } \u00ff iPS \u2207F i pwq\u00b4\u2207F pwq} 2\u02c7M 1 ff l jh n b \u25cb ,\nsince, conditional on S, the cross-terms vanish by (conditional) independence of h i and the non-random \u0159 i 1 PS \u2207F i 1 pwq\u00b4\u2207F pwq for all i P S. Now we bound a \u25cb:\na \u25cb \" E S \u00ab E hi } \u00ff iPS h i pwq\u00b4\u2207F i pwq} 2\u02c7S , M 1 ff \" E S \u00ab \u00ff iPS E hi }h i pwq\u00b4\u2207F i pwq} 2\u02c7S , M 1 ff \u010f E S \u00ab \u00ff iPS \u03c6 2 i K i ff \u010f E S \u00ab M 1 \u011a \u03c6 2 M1 K ff ,\nby conditional independence of h i\u00b4\u2207 F i and h i 1\u00b4\u2207F i 1 given S. Hence\n1 M 2 1 E \u00ab } \u00ff iPS h i pwq\u00b4\u2207F i pwq} 2\u02c7M 1 ff \u010f \u011a \u03c6 2 M1 M 1 K .\nNext we bound b \u25cb. Fix any w P W and denote y i :\" \u2207F i pwq and s y :\n\" 1 N \u0159 N i\"1 y i \" \u2207F pwq. We claim b \u25cb = E \" } \u0159 iPS y i\u00b4s y} 2\u02c7M 1 \uf6be \u010f M 1\u00b4N\u00b4M 1N\u00b41\u00af\u03c5\n2 . Assume WLOG that s y \" 0 (otherwise, consider y 1 i \" y i\u00b4s y, which has mean 0). Also, we omit the \"conditional on M 1 \" notation (but continue to condition on M 1 ) in the below and denote by \u2126 the collection of all`N M1\u02d8s ubsets of rN s of size M 1 . Now,\nb \u25cb \" 1 N M1\u02d8\u00ff SP\u2126 \u203a \u203a \u203a \u203a \u203a \u00ff iPS y i \u203a \u203a \u203a \u203a \u203a 2 \" 1 N M1\u02d8\u00ff SP\u2126\u02dc\u00ff iPS }y i } 2`2 \u00ff i,i 1 PS,i\u0103i 1 xy i , y i 1 y\" 1 N M1\u02d8\u02dc\u02c6N\u00b41 M 1\u00b41\u02d9N \u00ff i\"1 }y i } 2`2\u02c6N\u00b42 M 1\u00b42\u02d9\u00ff 1\u010fi\u0103i 1 \u010fN xy i , y i 1 y\" M 1 N N \u00ff i\"1 }y i } 2`2 M 1 pM 1\u00b41 q N pN\u00b41q \u00ff 1\u010fi\u0103i 1 \u010fN xy i , y i 1 y \" M 1 N\u02c6M 1\u00b41 N\u00b41`N\u00b4M 1 N\u00b41\u02d9N \u00ff i\"1 }y i } 2`2 M 1 pM 1\u00b41 q N pN\u00b41q \u00ff 1\u010fi\u0103i 1 \u010fN xy i , y i 1 y \" M 1 N M 1\u00b41 N\u00b41 \u203a \u203a \u203a \u203a \u203a N \u00ff i\"1 y i \u203a \u203a \u203a \u203a \u203a 2`M 1 N N\u00b4M 1 N\u00b41 N \u00ff i\"1 }y i } 2 \" M 1 N N\u00b4M 1 N\u00b41 N \u00ff i\"1 }y i } 2 \u010f M 1\u02c6N\u00b4M 1 N\u00b41\u02d9\n.\nHence 1 M 2 1 E \" } \u0159 iPS \u2207F i pwq\u00b4\u2207F pwq} 2\u02c7M 1 \uf6be \u010f N\u00b4M1 N\u00b41 \u03c5 2 M1\n. Finally, we take expectation over the randomness in M 1 to get\nE}r g r\u00b4\u2207 F pw r q} 2 \u010f E \u00ab \u011a \u03c6 2 M1 M 1 K`\u02c61\u00b4M 1\u00b41 N\u00b41\u02d9\u03c5 2 M 1 ff`d E \u011a \u03c3 2 M1 M 1 \u010f min \" \u03a6 2 M 1 K , \u03c6 2 max M K *`\u02c61\u00b4M\u00b41 N\u00b41\u02d9\u03c5 2 M`d min \" \u03a3 2 M 1 , \u03c3 2 max M * ,\nwhere, in each minima, the first respective term was obtained using Cauchy-Schwartz and the second term by bounding the numerator by the deterministic \"max,\" which can be pulled outside the expectation. The second statement in the lemma is proved in a nearly identical manner. The statement when N \" 1 follows from the first part of the proof alone, since the b \u25cb term is zero when there is no variance in client sampling (which is the case when N \" 1).\n\nWe will also need the following lemmas for the proof of Lemma D.4 (and hence Theorem 2.1):\n\nLemma D.6. (Projection lemma) Let W \u0102 R d be a closed convex set. Then }\u03a0 W paq\u00b4b} 2 \u010f }a\u00b4b} 2 for any a P R d , b P W.\n\nLemma D.6 is well-known. 13 We also recall a standard property of smooth convex functions for convenience:\n\nLemma D.7. (Co-coercivity of the gradient) For any convex, \u03b2-smooth function F : W \u00d1 R and any w, w 1 P W, we have }\u2207F pwq\u00b4\u2207F pw 1 q} 2 \u010f \u03b2x\u2207F pwq\u00b4\u2207F pw 1 q, w\u00b4w 1 y, and }\u2207F pwq\u00b4\u2207F pw 1 q} 2 \u010f 2\u03b2pF pwq\u00b4F pw 1 q\u00b4x\u2207F pw 1 q, w\u00b4w 1 yq.\n\nLastly, we need the following lemmas to optimize the step-sizes for our strongly convex excess risk bounds:\n\nLemma D.8. [Sti19, Lemma 2] Let b \u0105 0, let a, c \u011b 0, and t\u03b7 t u t\u011b0 be non-negative step-sizes such that \u03b7 t \u010f 1 g for all t \u011b 0 for some parameter g \u011b a. Let tr t u t\u011b0 and ts t u t\u011b0 be two non-negative sequences of real numbers which satisfy r t`1 \u010f p1\u00b4a\u03b7 t qr t\u00b4b \u03b7 t s t`c \u03b7 2 t for all t \u011b 0. Then there exist particular choices of step-sizes \u03b7 t \u010f 1 g and averaging weights \u03b3 t \u011b 0 such that\nb \u0393 T T \u00ff t\"0 s t \u03b3 t`a r T`1 \" r O\u02c6gr 0 exp\u02c6\u00b4a T g\u02d9`c aT\u02d9,\nwhere \u0393 T :\" \u0159 T t\"0 \u03b3 t . In fact, we can choose \u03b7 t and \u03b3 t as follows:\n\u03b7 t \" \u03b7 \" min # 1 g , ln`max 2, a 2 r 0 T 2 {c (\u0203 T + , \u03b3 t \" p1\u00b4a\u03b7q\u00b4p t`1q .\nFinally, we are ready to prove Lemma D.4:\n\nProof of Lemma D.4. We essentially follow the proof of the excess risk bound for the non-private version of Algorithm 1 given in [WPS20b, Theorem 1] (adapted for possibly constrained W \u2030 R d using projection), but accounting for the added Gaussian noise and random M r . First, condition on the random M r and consider M r as fixed. Let w\u02daP argmin wPW p F pwq be any minimizer of p F with norm less than or equal to D, and denote the average of the i.i.d. Gaussian noises across all clients in one round by s u r :\" 1\nMr \u0159 iPSr u i . Note that s u r \" N\u02c60, \u0118 \u03c3 2\n\nMr\n\nMr I d\u02d9b y independence of the tu i u iPrN s and hence E}s u r } 2 \" d \u0118 \u03c3 2\n\n\nMr\n\nMr . Then for any r \u011b 0, conditional on M r , we have that\nE \" }w r`1\u00b4w\u02da} 2\u02c7M r \uf6be \"E \u00bb - \u203a \u203a \u203a \u203a \u203a \u03a0 W \u00ab w r\u00b4\u03b7r\u02dc1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw r , x r i,j q\u00b4u i\u00b8ff\u00b4w\u02da\u203a \u203a \u203a \u203a \u203a 2\u02c7M r fi fl \u010fE \u00bb - \u203a \u203a \u203a \u203a \u203a w r\u00b4\u03b7r\u02dc1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw r , x r i,j q\u00b4u i\u00b8\u00b4w\u02da\u203a \u203a \u203a \u203a \u203a 2\u02c7M r fi fl \"E \" }w r\u00b4w\u02da} 2\u02c7M r \uf6be\u00b42 \u03b7 r E \" x\u2207 p F pw r q`s u r , w r\u00b4w\u02day\u02c7Mr \uf6be \u03b7 2 r E \u00bb - \u203a \u203a \u203a \u203a \u203a s u r`1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw r , x r i,j q \u203a \u203a \u203a \u203a \u203a 2\u02c7M r fi fl \u010fp1\u00b4\u00b5\u03b7 r qE \" }w r\u00b4w\u02da} 2\u02c7M r \uf6be\u00b42 \u03b7 r Er p F pw r q\u00b4p F\u02da|M r s \u03b7 2 r E \u00bb - \u203a \u203a \u203a \u203a \u203a s u r`1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw r , x r i,j q \u203a \u203a \u203a \u203a \u203a 2\u02c7M r fi fl ,(19)\nwhere we used Lemma D.6 in the first inequality, and \u00b5-strong convexity of p F (for \u00b5 \u011b 0) and the fact that s u r is independent of the gradient estimate and mean zero in the last inequality. Now, omitting the \"conditional on M r \" notation for brevity (but still conditioning on M r ), we can bound the last term by\nE \u203a \u203a \u203a \u203a \u203a s u r`1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw r , x r i,j q \u203a \u203a \u203a \u203a \u203a 2 \"E \u203a \u203a \u203a \u203a \u203a 1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw r , x r i,j q\u00b4\u2207f pw\u02da, x r i,j q`\u2207f pw\u02da, x r i,j q \u203a \u203a \u203a \u203a \u203a 2`d \u011a \u03c3 2 Mr M r \u010f2E \u203a \u203a \u203a \u203a \u203a 1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw r , x r i,j q\u00b4\u2207f pw\u02da, x r i,j q \u203a \u203a \u203a \u203a \u203a 2 2E \u203a \u203a \u203a \u203a \u203a 1 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 \u2207f pw\u02da, x r i,j q \u203a \u203a \u203a \u203a \u203a 2`d \u011a \u03c3 2 Mr M r \u010f 2 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 E \u203a \u203a \u2207f pw r , x r i,j q\u00b4\u2207f pw\u02da, x r i,j q \u203a \u203a 2 2 M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r\u00b8`d \u011a \u03c3 2 Mr M r \u010f 4\u03b2 M r \u00ff iPSr 1 K i Ki \u00ff j\"1 E \" f pw r , x r i,j q\u00b4f pw\u02da, x r i,j q\u00b4x\u2207f pw\u02da, x r i,j q, w r\u00b4w\u02day \u2030 2 M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r\u00b8`d \u011a \u03c3 2 Mr M r \u010f 4\u03b2Er p F pw r q\u00b4p F\u02das`2 M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r\u00b8`d \u011a \u03c3 2 Mr M r where we denote \u03a5 2 r :\" #\u00b41\u00b4M r\u00b41\nN\u00b41\u00af\u03c5 2 if N \u0105 1 0 otherwise. Above, we used the \"relaxed triangle inequality\" (see e.g. [KKM`20, Lemma 3]) in the first inequality, Lemma D.5 (with M r considered fixed/non-random due to conditioning and replacing r g r by the noiseless minibatch gradient) in the second inequality, Lemma D.7 in the third inequality, and the first-order optimality conditions for constrained optimization in the final inequality. The first equality is due to independence of the Gaussian noise and the stochastic gradients. Next, plugging this estimate back into Equation 19 and noting that \u03b7 r \u010f 1 4\u03b2 for all r \u011b 0, we obtain\nE \" }w r`1\u00b4w\u02da} 2\u02c7M r \uf6be \u010f p1\u00b4\u00b5\u03b7 r qE \" }w r\u00b4w\u02da} 2\u02c7M r \uf6be\u00b42 \u03b7 r p1\u00b42\u03b2\u03b7 r qEr p F pw r q\u00b4p F\u02da|M r s (20) 2\u03b7 2 r M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r\u00b8`\u03b7 2 r d \u011a \u03c3 2 Mr M r \u010f p1\u00b4\u00b5\u03b7 r qEr}w r\u00b4w\u02da} 2 |M r s\u00b4\u03b7 r Er p F pw r q\u00b4p F\u02da|M r s 2\u03b7 2 r M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r\u00b8`\u03b7 2 r d \u011a \u03c3 2 Mr M r ,(21)\nwhich implies\n\nEr p F pw r q\u00b4p F\u02da|M r s \u010f\u02c61 \u03b7 r\u00b4\u00b5\u02d9E r}w r\u00b4w\u02da} 2 |M r s\u00b41 \u03b7 r Er}w r`1\u00b4w\u02da} 2 |M r s\n2\u03b7 r M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r\u00b8`\u03b7r d \u011a \u03c3 2 Mr M r .(22)\nNow we consider the convex (\u00b5 \" 0) and strongly convex (\u00b5 \u0105 0) cases separately.\n\nConvex (\u00b5 \" 0) case: By our choice of \u03b7 r \" \u03b7 and (22), the average iterate x w R satisfies:\nEr p F p x w R q\u00b4p F\u02da|tM r u r\u010fR s \u010f 1 R R\u00b41 \u00ff r\"0 Er p F pw r q\u00b4p F\u02da|M r s \u010f 1 R R\u00b41 \u00ff r\"0 1 \u03b7 pEr}w r\u00b4w\u02da} 2\u00b4} w r`1\u00b4w\u02da} |M r sq 1 R R\u00b41 \u00ff r\"0 2\u03b7 M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r`d \u011a \u03c3 2 Mr {2\u1e11 }w 0\u00b4w\u02da} 2 \u03b7R`1 R R\u00b41 \u00ff r\"0 2\u03b7 M r\u02dc\u011e p\u03c6M r q 2 K`\u03a5 2 r`d \u011a \u03c3 2 Mr {2\u00b8.\nThen taking expectation over the randomness in M r , we get by Assumption 2 that\nE p F p p w R q\u00b4p F pw\u02daq \u010f D 2 \u03b7R`2 \u03b7 \" min \" \u03a6 2 M 1 K , p\u03c6m ax q 2 M K *`\u02c61\u00b4M\u00b41 N\u00b41\u02d9\u03c5 2 M`d 2 min \" \u03a3 2 M 1 , \u03c3 2 max M *\uf6be(23)\nif N \u0105 1; and if N \" 1, then the term involving \u03c5 2 vanishes. Above we used Cauchy-Schwartz to get the first term in each of the minima and upper bounded the numerator by the non-random \"max\" quantity (and invoked linearity of expectation) for the second. Strongly convex (\u00b5 \u0105 0) case: Recall from (21) that\nEr}w t`1\u00b4w\u02da} 2 |M t s \u010f p1\u00b4\u00b5\u03b7 t qEr}w t\u00b4w\u02da} 2 |M t s\u00b4\u03b7 r Er p F pw t q\u00b4p F\u02da|M t s 2\u03b7 2 t M t\u02dc\u011e p\u03c6M t q 2 K`\u03a5 2 t`d \u011a \u03c3 2 Mt {2\u00b8(24)\nfor all t \u011b 0. Taking expectation over M t gives\nE}w t`1\u00b4w\u02da} 2 \u010f p1\u00b4\u00b5\u03b7 t qE}w t\u00b4w\u02da} 2\u00b4\u03b7 t Er p F pw t q\u00b4p F\u02das (25) 2\u03b7 2 t \" 4L 2 M K`\u03a5 2 M`d 2 min \" \u03a3 2 M 1 , \u03c3 2 max M *\uf6be ,(26)\nwhich satisfies the conditions for Lemma D.8, with sequences r t \" E}w t\u00b4w\u02da} 2 , s t \" Er p F pw t q\u00b4p F\u02das and parameters\na \" \u00b5, b \" 1, c \" 2\u02c64 L 2 M K`\u03a5 2 M\u02d9`d min \" \u03a3 2 M 1 , \u03c3 2 max M * , g \" 4\u03b2, T \" R.\nThen applying Lemma D.8 and Jensen's inequality completes the proof.\n\nAt last, we are prepared to prove Theorem 2.1.\n\nProof of Theorem 2.1. Privacy: By independence of the Gaussian noise across clients, it suffices to show that transcript of client i's interactions with the server is DP for all i P rN s (conditional on the transcripts of all other clients). WLOG consider i \" 1 and denote client 1's privacy parameters by and \u03b4 and batch size by K. (we used the assumption \u010f lnp2{\u03b4q here) and r \u03b4 \" \u03b4 2R . First, condition on the randomness due to local sampling of the local data point x r 1,1 (line 4 of Algorithm 1). Now, the L 2 sensitivity of each local step of SGD is bounded by \u2206 :\" sup |X1\u2206X 1 1 |\u010f2,wPW } 1 K \u0159 K j\"1 \u2207f pw, x 1,j q\u00b4\u2207f pw, x 1 1,j q} \u010f 2L{K, by L-Lipschitzness of f. Thus, the standard privacy guarantee of the Gaussian mechanism [DR14, Theorem A.1] implies that (conditional on the randomness due to sampling) taking \u03c3 2 1 \u011b 8L 2 lnp1.25{ r \u03b4q r 2 K 2 suffices to ensure that round r (in isolation) is pr , r \u03b4q-LDP. Now we invoke the randomness due to sampling: [Ull17, Problem 1b] implies that round r (in isolation) is p 2r K n1 , r \u03b4q-LDP. The assumption on K i ensures that 1 :\" n1\n2K 2 ? 2R lnp2{\u03b4q\n\u010f 1, so that the privacy guarantees of the Gaussian mechanism and amplification by subsampling stated above indeed hold. Therefore, with sampling, it suffices to take \u03c3 2 1 \u011b 32L 2 lnp1.25{ r \u03b4q n 2 1 r 2 \" 256L 2 R lnp2.5R{\u03b4q lnp2{\u03b4q n 2 1 2 to ensure that round r (in isolation) is pr , r \u03b4q-LDP for all r and hence that the full algorithm (R rounds) is p , \u03b4q-LDP. Excess loss: First suppose f is merely convex (\u00b5 \" 0). By Lemma D.2, Lemma D.1, and Lemma D.4 (and noting \u03c6m ax \u010f 4L 2 and \u03c5 2 \" 0 since client data is i.i.d.), we have:\nEF p p w R q\u00b4F pw\u02daq \u010f \u03b1`E p F p p w R q\u00b4p F pw\u02daq (27) \u010f 2L 2 R\u03b7 n min M`D 2 \u03b7R (28) 2\u03b7 \" min \" \u03a6 2 M 1 K , p\u03c6m ax q 2 M K *`\u02c61\u00b4M\u00b41 N\u00b41\u02d9\u03c5 2 M`d 2 min \" \u03a3 2 M 1 , \u03c3 2 max M *\uf6be (29) \u010f 2L 2 R\u03b7 n min M`D 2 \u03b7R`2 \u03b7 \" 4Rd min \" \u03a8 M 1 , \u03c8 max M *`4 L 2 M K \uf6be (30) \u010f \u03b7L 2 \" R\u02c62 M n min`2 56d min \" \u039e M 1 , \u03be max M *\u02d9`8 M K \uf6be`D 2 \u03b7R(31)\nfor any \u03b7 \u010f 1 4\u03b2 . Then one can verify that the prescribed choice of \u03b7 and R yields the desired bound. Now suppose f is \u00b5-strongly convex. The prescribed choice of \u03b7 and R imply that D.3 Complete statement and proof of Theorem 2.2\nE p F p p w R q\u00b4p F pw\u02daq \" r O\u02c6d \u00b5 min \" \u03a8 M 1 ,\nUsing the same notation as in the complete version of Theorem 2.1, we have: Theorem 2.2 [Complete Version] Let f : W\u02c6X \u00d1 R be \u00b5-strongly convex (with \u00b5 \" 0 for convex case) and L-Lipschitz, in w for all x P X , where W is a closed convex set in R d s.t. }w} \u010f D for all w P W. Let D be an arbitrary probability distribution on X . For each client i P rN s, draw a local i.i.d. data set X i \" D ni .\n\nRunning Algorithm 1 on f \u03b2 pw, xq :\" min vPW\u00b4f pv, xq`\u03b2 2 }w\u00b4v} 2\u00afw ith \u03b2 as prescribed below and the same \u03c3 2 i , \u03b7 r \" \u03b7 and t\u03b3 r u \nQ \u0102 M min ! n min , 1 d r \u039e )U yields EF p p w R q\u00b4F pw\u02daq \u010f 545 LD a \u0102 M max \" 1 ? n min , a d r \u039e * .\n\n(Strongly convex) Setting\n\u03b2 :\" \u00b5 \u0102 M min ! n min , 1 d r \u039e )\nand R :\"\nQ max ! 8 \u0102 M min ! n min , 1 d r \u039e ) ln\u00b4\u03b2 D 2 \u00b5M 1 dL 2 r \u039e\u00af, 1 d r \u039e )U yields EF p p w R q\u00b4F pw\u02daq \" r O\u02c6L 2 \u00b5\u02c61 M n min`d min \" \u039e M 1 , \u03be max M *\u02d9\u02d9.\nThe proof follows from applying Theorem 2.1 to the \u03b2-smooth, Lipschitz, convex loss F \u03b2 to upper bound EF \u03b2 p p w R q\u00b4F\u03b2 and then relating this quantity to EF p p w R q\u00b4F pw\u02daq by using: Proof of Theorem 2.2. We have EF p p w R q\u00b4F pw\u02daq \u010f EF \u03b2 p p w R q\u00b4F\u03b2`L 2 2\u03b2 , by part 2 of Lemma D.9. Then plugging in \u03b2 and combining part 1 of Lemma D.9 with Theorem 2.1 completes the proof.\n\n\nD.4 Noisy Accelerated MB-SGD Algorithm and the statement and proof of smooth federated ERM upper bounds\n\nThe Noisy Accelerated MB-SGD algorithm is formally described in Algorithm 2. We first state the informal guarantee of Algorithm 2 for smooth losses:\n\nTheorem D.1.\n\n[Informal] Let f : W\u02c6X \u00d1 R d be L-Lipschitz, \u03b2-smooth, and \u00b5-strongly convex (with \u00b5 \" 0 for convex case). Then, Algorithm 2 with \u03c3 2 i :\" 256L 2 R lnp2.5R{\u03b40q lnp2{\u03b40q\nn 2 2 0 and K i \" K \u011b 0 n 4 ? 2R lnp2{\u03b40q\nis p 0 , \u03b4 0 q-LDP. Moreover, for any X P X n\u02c6N , its output p w R satisfies:\n1. (Convex) Setting R \" max\u02dc\u00b4\u03b2 D ? M 0 n L ? d\u00af1 {2 , 2 0 n 2 d # 1 K if M = N 1 otherwise\u00b8y ields E p F p p w R q\u00b4p F pw\u02daq \" O\u02dcLD\u02dca d lnp2.5R{\u03b4 0 q lnp2{\u03b4 0 q 0 n ? M\u00b8\u00b8.(32)\n2. (Strongly convex) Setting R \" max\u02dcb \u03b2 \u00b5 ln\u00b4D\n\u00b5M 2 0 n 2 Ld\u00af, 2 0 n 2 d # 1 K if M = N 1 otherwise\u00b8y ields E p F p p w R q\u00b4p F pw\u02daq \" O\u02c6L 2 \u00b5\u02c6d\nlnp2.5R{\u03b4 0 q lnp2{\u03b4 0 q 2 0 n 2 M\u02d9\u02d9.\n\n\n(33)\n\nAlgorithm 2 Noisy Accelerated MB-SGD Require: Number of clients N P N, dimension d P N of data, noise parameters t\u03c3 i u iPrN s , closed convex set W \u0102 R d , data sets X i P X ni i for i P rN s, loss function f pw, xq, number of communication rounds R P N, number K i P N of local samples drawn per round, step size parameters t\u03b7 r u rPrRs , t\u03b1 r u rPrRs such that \u03b1 1 \" 1, \u03b1 r P p0, 1q for all r \u011b 2 and \u03b7 r \u0105 0 for all r \u011b 1, norm D of some optimum w\u02daof F. 1: Set initial point w ag 0 \" w 0 P W and r \" 1. Client draws K i samples x r i,j from X i (for j P rK i s) and noise u i \" N p0, \u03c3 2 i I d q.\n\n\n6:\n\nClient computes r g i r :\" 1 Ki \u0159 Ki j\"1 \u2207f pw md r , x r i,j q`u i .\n\n\n7:\n\nend for 8:\n\nServer aggregates r g r :\" 1 M \u0159 M i\"1 r g i r .\n\n\n9:\n\nServer updates and broadcasts: 10: w r :\" argmin wPW \u03b1 r \" xr g r , wy`\u00b5 2 }w md r\u00b4w } 2 \u2030`\" p1\u00b4\u03b1 r q \u00b5 2`\u03b7 r 2 \u2030 }w r\u00b41\u00b4w } 2 ( .\n\n\n11:\n\nServer updates and broadcasts w ag r \" \u03b1 r w r`p 1\u00b4\u03b1 r qw ag r\u00b41 . 12: end for 13: return w ag R .\n\nNext, we state the complete version of Theorem D.1:\nTheorem D.1 [Complete Version] Let X P X n1 1\u02c6\u00a8\u00a8\u00a8X n N\nN . Suppose f p\u00a8, x i q is L i -Lipschitz and convex on W for all x i P X i , i P rN s, p F p\u00a8, Xq :\" p F p\u00a8q is s \u03b2-smooth, Assumption 3 part 1 and Assumption 2 hold. Set\n\u03c3 2 i \" 256L 2 i R lnp 2.5R \u03b4 i q lnp2{\u03b4iq n 2 i 2 i . Denote \u03a5 2 \" #\u00b41\u00b4M\u00b41 N\u00b41\u00af\u03c5 2 if N \u0105 1 0 otherwise and V 2 :\" min \" \u03a6 2 M 1 K , \u03c6 2 max M K *`d min \" \u03a3 2 M 1 , \u03c3 2 max M *`\u03a5 2 M ,\nwhere K :\" min iPrN s K i . Then Algorithm 2 is tp i , \u03b4 i qu iPrN s -LDP for any i P p0, lnp 2 \u03b4i qs and \u03b4 i P p0, 1q,\nprovided K i \u011b in 4 ? 2R lnp2{\u03b4iq\n. Moreover:\n\n1. Running Algorithm 2 on r F pwq :\" p F pwq`\u03bb 2 }w} 2 with \u03bb :\" V 2D ?\n\nR for R rounds yields (for some choice of stepsizes)\nE p F pw ag R q\u00b4p F pw\u02daq \u00c0 s \u03b2D 2 R 2`D \u00ab min #c p\u03a6 2 {KRq`d\u03a8 M 1 , c p\u03c6 2 max {KRq`d\u03c8 max M +`c \u03a5 2 M R ff .(34)\nIn particular, setting R \"\n$ ' ' & ' ' % max \"\u00b4s \u03b2D ? M 1 ? d\u03a8\u00af1 {2 , \u03a6 2 {K`\u03a5 2 d\u03a8 * if \u03a8 M 1 \u010f \u03c8max M max \"\u00b4s \u03b2D ? M ? d\u03c8max\u00af1 {2 , \u03c6 2 max {K`\u03a5 2 d\u03c8max * otherwise implies E p F pw ag R q\u00b4p F pw\u02daq \u00c0 D ? d min # ? \u03a8 ? M 1 , ? \u03c8 max ? M + ,(35)\nassuming R \u011b 1.\n\n2. If, in addition, p F is s \u00b5-strongly convex, then running a multi-stage implementation of Algorithm 2 directly on p F with the same choices of \u03c3 2 i and K yields\nE p F pw ag R q\u00b4p F pw\u02daq \u00c0 \u2206 exp\u02c6\u00b4c s \u00b5 s \u03b2 R1 s \u00b5 \" min \" p\u03a6 2 {KRq`d\u03a8 M 1 , p\u03c6 2 max {KRq`d\u03c8 max M *`\u03a5 2 M R \uf6be ,(36)\nwhere F pw 0 q\u00b4F\u02da\u010f \u2206.\n\nIn particular, choosing R \"\n$ ' ' & ' ' % max \" b s \u03b2 s \u00b5 ln\u00b4\u2206 s \u00b5M 1 d\u03a8\u00af, \u03a6 2 {K`\u03a5 2 d\u03a8 * if \u03a8 M 1 \u010f \u03c8max M max \" b s \u03b2 s \u00b5 ln\u00b4\u2206 s \u00b5M d\u03c8max\u00af, \u03c6 2 max {K`\u03a5 2 d\u03c8max * otherwise implies E p F pw ag R q\u00b4p F pw\u02daq \u00c0 d s \u00b5 min \" \u03a8 M 1 , \u03c8 max M * ,(37)\nprovided R \u011b 1.\n\nProof of Theorem D.1. LDP of Algorithm 1 follows from LDP of Algorithm 1 (see Theorem 2.1) and the postprocessing property of DP [DR14, Proposition 2.1]. Namely, since the choice of noise given in Theorem D.1 ensures that clients' local stochastic minibatch gradients are LDP and the iterates in Algorithm 2 are functions of these private noisy gradients, it follows that the iterates themselves are LDP. For convergence, we begin with the convex (s \u00b5 \" 0) part. We will need the following lemma:\n\nLemma D.10. [WPS20b, Lemma 4] Let F : W \u00d1 R d be convex and \u03b2-smooth, and suppose that the unbiased stochastic gradients r gpw t q at each iteration have bounded variance E}r gpwq\u00b4\u2207F pwq} 2 \u010f V 2 . If p w ag is computed by T steps of AC-SA on the regularized objective r F pwq \" F pwq`V 2}w0\u00b4w\u02da}\n\n?\nT }w\u00b4w 0 } 2 , then EF p p w ag q\u00b4F\u02da\u00c0 \u03b2}w 0\u00b4w\u02da} 2 T 2`V }w 0\u00b4w\u02da} ? T .\nCombining Lemma D.10 with the estimates of the variance of the stochastic gradients from Lemma D.5 (and replacing \u03b2 by s \u03b2) proves the first (convex) part of Theorem D.1.\n\nFor the second (strongly convex) part, we follow [GL13, WPS20b] and use the following multi-stage implementation of Algorithm 2 to further accelerate convergence: Let F p0q\u00b4F\u02da\u010f \u2206 and q 0 \" 0. Then for k P rU s, do the following:\n\n1. Run R k rounds of Algorithm 2 using w 0 \" q k\u00b41 , t\u03b1 r u r\u011b1 and t\u03b7 r u r\u011b1 , where\nR k \" S max # 4 d 2\u03b2 \u00b5 , 128V 2 3\u00b5\u22062\u00b4p k`1q +W , \u03b1 r \" 2 r`1 , \u03b7 r \" 4\u03c5 k rpr`1q , \u03c5 k \" max # 2\u03b2, \" \u00b5V 2 3\u22062\u00b4p k\u00b41q R k pR k`1 qpR k`2 q \uf6be 1{2 + 2. Set q k \" w ag R k ,\nwhere w ag R k is the output of Step 1 above. Then update k \u00d0 k`1 and return to Step 1. We then have the following risk bound for the multi-stage protocol:\n\nLemma D.11. [GL13, Proposition 7] Let F : W \u00d1 R d be \u00b5-strongly convex and \u03b2-smooth, and suppose that the unbiased stochastic gradients r gpw t q at each iteration have bounded variance E}r gpwq\u00b4\u2207F pwq} 2 \u010f V 2 . If p w ag is computed by T steps of the multi-stage AC-SA, then\nEF p p w ag q\u00b4F\u02da\u00c0 \u2206 exp\u02c6\u00b4c \u00b5 \u03b2 T\u02d9`V 2 \u00b5T ,\nwhere \u2206 \" F pw 0 q\u00b4F\u02da.\n\nIn our notation, T \" R and F is replaced by p F , which is s \u00b5-strongly convex and s \u03b2-smooth by assumption. If U is chosen so that \u0159 U k\"1 R k \u010f R total rounds of Algorithm 2, then the full algorithm, run with noise \u03c3 2 i specified in Theorem D.1 [Complete Version], is LDP. Applying Lemma D.11 with , where \u2206 2 \" sup w,x }\u2207f pw, xq\u00b4\u2207f pw, x 1 q} \u010f 2L is the L 2 sensitivity of the non-private gradient update in line 6 of Algorithm 2. Therefore, conditional on the private transcript of all other clients, we see that client i's transcript is p 0 , \u03b4 0 q-DP for all i P rN s, which means that One-Pas Noisy Accelerated Distributed SGD is p 0 , \u03b4 0 q-LDP.\nV 2 \" min \" \u03a6 2 M 1 K , \u03c6 2 max M K *`\u03a5 2 M`d min \" \u03a3 2 M 1 ,\n\nExcess loss:\n\nFor the convex case, we plug the estimate for the variance of the noisy stochastic gradients from Lemma D.5 for V 2 in Lemma D.10 and set T \" n. Note that L-Lipschitzness implies that\nV 2 \u010f \u03c6 2 M`\u03c5 2 M`d \u03c3 2 M \u010f 5L 2`d \u03c3 2 M .\nSimilarly, for strongly convex loss, we plug the same estimate for V 2 into Lemma D.11 with T \" n (using the multi-stage implementation of Algorithm 2, described in the previous subsection of this appendix). This completes the proof.\n\n\nD.6 Complete version and proof of Theorem 2.4\n\nTheorem 2.4 [Complete Version] Suppose f p\u00a8, x i q is L i -Lipschitz and convex on W for all x i P X i , i P rN s, Assumption 3 part 1 and Assumption 2 hold. Assume L i \" L for all i. Set \u03c3 2 i \"\n256L 2 R lnp 2.5R \u03b4 i q lnp2{\u03b4iq n 2 i 2 i . Denote \u03a5 2 \" #\u00b41\u00b4M\u00b41 N\u00b41\u00af\u03c5 2 if N \u0105 1 0 otherwise and V 2 :\" min \" \u03a6 2 M 1 K , \u03c6 2 max M K *`d min \" \u03a3 2 M 1 , \u03c3 2 max M *`\u03a5 2 M , where K :\" min iPrN s K i . Also denote \u0102 M :\" # ? M 1 if \u03a8 M 1 \u010f \u03c8max M ?\nM otherwise and r \u03a8 :\" \n# \u03a8 if \u03a8 M 1 \u010f \u03c8max M \u03c8 max otherwise . Fix any X P X n1E p F pw ag R q\u00b4p F pw\u02daq \u00c0 L 2 D a \u0102 M R 2 a d r \u03a8`D \u00ab min #c p\u03a6 2 {KRq`d\u03a8 M 1 , c p\u03c6 2 max {KRq`d\u03c8 max M +`c \u03a5 2 M R f D ? d min # ? \u03a8 ? M 1 , ? \u03c8 max ? M + .\nIn particular, setting R \"\n$ & % max !\u00b4L ? M 1 ? d\u03a8\u00af, \u03a6 2 {K`\u03a5 2 d\u03a8 ) if \u03a8 M 1 \u010f \u03c8max M max !\u00b4L ? M ? d\u03c8max\u00af, \u03c6 2 max {K`\u03a5 2 d\u03c8max ) otherwise implies E p F pw ag R q\u00b4p F pw\u02daq \u00c0 D ? d min # ? \u03a8 ? M 1 , ? \u03c8 max ? M + ,(38)\nassuming R \u011b 1.\n\n2. If, in addition, p F is s \u00b5-strongly convex, then running a multi-stage implementation of Algorithm 2 on p F \u03b2\nwith \u03b2 :\" s \u00b5 \u0102 M L 2 d r \u03a8 yields E p F pw ag R q\u00b4p F pw\u02daq \u00c0 \u2206 exp\u00a8\u00b4R d d r \u03a8 \u0102 M L 2\u201a 1 s \u00b5 \" min \" p\u03a6 2 {KRq`d\u03a8 M 1 , p\u03c6 2 max {KRq`d\u03c8 max M *`\u03a5 2 M R \uf6be ,(39)\nwhere F pw 0 q\u00b4F\u02da\u010f \u2206 \u010f LD.\n\nIn particular, choosing R \"\n$ ' & ' % max \" b M 1 L 2 d\u03a8 ln\u00b4\u2206 s \u00b5M 1 d\u03a8\u00af, \u03a6 2 {K`\u03a5 2 d\u03a8 * if \u03a8 M 1 \u010f \u03c8max M max !b M L 2 d\u03c8max ln\u00b4\u2206 s \u00b5M d\u03c8max\u00af, \u03c6 2 max {K`\u03a5 2 d\u03c8max ) otherwise implies E p F pw ag R q\u00b4p F pw\u02daq \u00c0 d s \u00b5 min \" \u03a8 M 1 , \u03c8 max M * ,(40)\nprovided R \u011b 1.\n\nProof. The proof is very similar to the proof of Theorem 2.2. We apply Theorem D.1 to the \u03b2-smooth objective r F \u03b2 (for convex case) or p F \u03b2 (for strongly convex) and use Lemma D.9. This ensures that excess risk with respect to p F increases by at most L 2 {\u03b2, which is bounded by the smooth convex (or strongly convex, respectively) excess risk bound by our choice of \u03b2.\n\n\nE Lower Bounds for LDP FL\n\n\nE.1 Example of LDP Algorithm that is Not Compositional\n\nThis example is a simple modification of [JMNR19, Example 2.2] (adapted to our definition of compositionality for \u03b4 0 \u0105 0). Given any C \u0105 0, set d :\" 2C 2 and let X \" te 1 ,\u00a8\u00a8\u00a8e d u \u0102 t0, 1u d be the standard basis for R d . Let n \" 1 and X \" px 1 ,\u00a8\u00a8\u00a8, x N q P X N . For all i P rN s let Q piq : X \u00d1 X be the randomized response mechanism that outputs Q piq px i q \" x i with probability e 0 e 0`d\u00b41 and otherwise outputs a uniformly random element of X ztx i u. Note that Q piq is 0 -DP, hence p 0 , \u03b4 0 q-DP for any \u03b4 0 \u0105 0. Consider the d-round algorithm A : Since each client's data is only referenced once and Q piq is 0 -DP, we have r 0 \" 0 and A is p 0 , \u03b4 0 q-DP.\nX N \u00d1 Z d\u02c6N in Algorithm 3, where Z \" R dHowever, b \u0159 d r\"1 p r 0 q 2 \" a d 2 0 \" ? 2C 0 \u0105 C 0 , so that A is not C-compositional.\n\nE.2 Proof of Theorem 3.1\n\nBefore we proceed to the proof of Theorem 3.1, we recall the simpler characterization of LDP for sequentially interactive algorithms. A sequentially interactive algorithm A with randomizers tR piq u N i\"1 is p 0 , \u03b4 0 q-LDP if and only if R piq p\u00a8, Z p1:i\u00b41q q : X n i\u02c6Z is p 0 , \u03b4 0 q-DP for all Z p1:i\u00b41q P Z i\u00b41 . In what follows, we will fix X i \" X for all i. We now turn to the proof.\n\nStep 1: Privacy amplification by shuffling. We begin by stating and proving the amplification by shuffling result that we will leverage to obtain Theorem 3.1:\n\nTheorem E.1. Let A P A p 0,\u03b40q such that 0 P p0, ? N s and \u03b4 0 P p0, 1q. Assume that in each round, the local randomizers R piq r pZ p1:r\u00b41q ,\u00a8q : X n \u00d1 Z are p r 0 , \u03b4 r 0 q-DP for all i P rN s, r P rRs, Z p1:r\u00b41q P Z r\u00b41\u02c6N with r 0 \u010f 1 n . If A is compositional, then assume \u03b4 r 0 P r 2e\u00b4N {16 N n , 1 14nN R s and denote \u03b4 :\" 14N n \u0159 R r\"1 \u03b4 r 0 ; if instead A is sequentially interactive, then assume \u03b4 0 \" \u03b4 r 0 P r 2e\u00b4N {16 N n , 1 7N n s and denote \u03b4 :\" 7N n\u03b4 0 . Let A s : X \u00d1 W be the same algorithm as A except that in each round r, A s draws a random permutation \u03c0 r of rN s and applies R piq r to X \u03c0rpiq instead of X i . Then, A s is p , \u03b4q-CDP, where \" O\u02c6 0 lnp1{nN \u03b4 min 0 q ? N\u02d9, and \u03b4 min 0 :\" min rPrRs \u03b4 r 0 . Note that for sequentially interactive A, \u03b4 min 0 \" \u03b4 0 .\n\nTo the best of our knowledge, the restriction on r 0 is needed to obtain \" r Op 0 { ? N q in all works that have analyzed privacy amplification by shuffling [EFM`20b, FMT20, BBGN19, CSU`19, BKM`20], but these works focus on the sequentially interactive case with n \" 1, so the restriction amounts to 0 \u00c0 1 (or 0 \" r Op1qq. The fully interactive compositional part of Theorem E.1 will follow as a corollary (Corollary E.1 ) of the following result which analyzes the privacy amplification in each round:\n\nTheorem E.2 (Single round privacy amplification by shuffling). Let r 0 \u010f ln\u00b4N 16 lnp2{\u03b4 r q\u00af{ n, r P N and let R piq r pZ,\u00a8q : X n \u00d1 Z be an p r 0 , \u03b4 r 0 q-DP local randomizer for all Z \" Z p1:N q p1:r\u00b41q P Z pr\u00b41q\u02c6N and i P rN s, where X is an arbitrary set. Given a distributed data set X \" pX 1 ,\u00a8\u00a8\u00a8, X N q P X N\u02c6n and Z \" Z p1:N q p1:r\u00b41q , consider the shuffled algorithm A r s : X n\u02c6N\u02c6Z pr\u00b41q\u02c6N \u00d1 Z N that first samples a random permutation \u03c0 of rN s and then computes Z r \" pZ \n\nand r \u03b4 r :\" \u03b4 r`2 N ne pn\u00b41q r 0 \u03b4 r 0 . In particular, if r 0 \" O`1 n\u02d8, then\nr \" O\u02dc r 0 a lnp1{\u03b4 r q ? N\u00b8.(42)\nFurther, if r 0 \u010f 1{n, then setting \u03b4 r :\" N n\u03b4 r 0 implies that\nr \" O\u02dc r 0 a lnp1{nN \u03b4 r 0 q ? N\u00b8( 43)\nand r \u03b4 r \u010f 7N n\u03b4 r 0 , which is in p0, 1q if we assume \u03b4 r 0 P p0, 1 7N n s.\n\nWe sometimes refer to the algorithm A r s as the \"shuffled algorithm derived from the randomizers tR piq r u.\" From Theorem E.2, we obtain: Corollary E.1 (R-round privacy amplification for compositional algorithms). Let A : X n\u02c6N \u00d1 Z R\u02c6N be an R-round p 0 , \u03b4 0 q-LDP and C-compositional algorithm such that 0 P p0, ? N s and \u03b4 0 P p0, 1q, where X is an arbitrary set. Assume that in each round, the local randomizers R piq r pZ p1:r\u00b41q ,\u00a8q : X n \u00d1 Z are p r 0 , \u03b4 r 0 q-DP for i P rN s, r P rRs, where r 0 \u010f 1 n , and \u03b4 r 0 P r 2e\u00b4N {16 N n , 1 14nN R s. Then, the shuffled algorithm A s : X n\u02c6N \u00d1 Z R\u02c6N derived from tR Proof. Let \u03b4 1 :\" \u0159 r N n\u03b4 r 0 and \u03b4 r :\" N n\u03b4 r 0 . Then the (central) privacy loss of the full R-round shuffled algorithm is bounded as \u010f 2 \u00ff r p r q 2`c 2 \u00ff r p r q 2 lnp1{\u03b4 1 q \" O\u02dc\u00ff r\u02c6p r 0 q 2 lnp1{\u03b4 r q N\u02d9`d \u00ff r p r 0 q 2 lnp1{\u03b4 r q lnp1{\u03b4 1 q N\"\nO\u02c6 0 lnp1{nN \u03b4 min 0 q ? N\u02d9,\nwhere the three (in)equalities follow in order from the Advanced Composition Theorem [DR14], (43) in Theorem E.2, and C-compositionality of A combined with the assumption 0 \u00c0 ? N . Also, \u03b4 \" \u03b4 1`\u0159 r r \u03b4 r by the Advanced Composition Theorem, where r \u03b4 r \u010f 7N n\u03b4 r 0 by Theorem E.2. Hence \u03b4 \u010f 14N n \u0159 r \u03b4 r 0 .\n\nRemark E.1. The upper bounds assumed on \u03b4 r 0 and \u03b4 r in Theorem 3.1 ensure that \u03b4 P p0, 1q and that the lower bounds of [BST14] apply (see Theorem E.3). These assumptions are not very restrictive in practice, since \u03b4 r 0 , \u03b4 0 ! 1 is needed for meaningful privacy guarantees (see e.g. [DR14, Chapter 2]) and R must be polynomial for the algorithm to run. To quote [DR14, p. 18], \"typically we are interested in values of \u03b4 that are less than the inverse of any polynomial in the size of the database.\" For larger \u03b4 (e.g. \u03b4 \" \u2126p1{nq), there are examples of algorithms that satisfy the definition of DP but clearly violate any reasonable notion of privacy. For instance, an algorithm that outputs \u03b4 0 n random samples from each client's data set is p0, \u03b4 0 q-LDP, but completely violates the privacy of at least one person in each client if \u03b4 \u011b 1{n. Also, since N \" 1 is the regime of interest (otherwise if N \" r Op1q, the CDP lower bounds of [BFTT19] already match our upper bounds up to logarithms), the requirement that N be larger than 16 lnp2{\u03b4 min 0 nq is unimportant. 14 The sequentially interactive part of Theorem E.1 will be clear directly from the proof of Theorem E.2. We now turn to the proof of Theorem E.2, which uses the techniques from [FMT20]. First, we'll need some more notation. The privacy relation in (3) between random variables P and Q can be characterized by the hockey-stick divergence: D e pP }Qq :\" \u015f maxt0, ppxq\u00b4e qpxqudx, where p and q denote the probability density or mass functions of P and Q respectively. Then P \u00bb p ,\u03b4q Proof. By group privacy (see e.g. [Kam20, Theorem 10]), and the assumption that R is p , \u03b4q-DP, it follows that RpXq and RpX 1 q are pn , ne pn\u00b41q \u03b4q indistinguishable for all X, X 1 P X n . In particular, taking X 1 :\" X 0 completes the proof. Lemma E.3. Let R piq : X n \u00d1 Z be randomized algorithms (i P rN s) and let A s : X n\u02c6N \u00d1 Z N be the shuffled algorithm A s pXq :\" pR p1q pX \u03c0p1q q,\u00a8\u00a8\u00a8R pN q pX \u03c0pN q qq derived from tR piq u iPrN s for X \" pX 1 ,\u00a8\u00a8\u00a8, X N q, where \u03c0 is a uniformly random permutation of rN s. Let X 0 \" pX 0 1 , X 2 ,\u00a8\u00a8\u00a8, X N q and X 1 \" pX 1 1 , X 2 ,\u00a8\u00a8\u00a8, X N q, \u03b4 P p0, 1q and p P r 16 lnp2{\u03b4q N , 1s. Suppose that for all i P rN s, X P X n ztX 1 1 , X 0 1 u, there exists a distribution LO piq pXq such that R piq pXq \" p 2 R piq pX 0 1 q`p 2 R piq pX 1 1 q`p1\u00b4pqLO piq pXq.\nThen A s pX 0 q \u00bb p ,\u03b4q A s pX 1 q, where \u010f ln\u02dc1`8 a lnp4{\u03b4q ? pN`8 pN\u00b8.\nProof. The proof mirrors the proof of [FMT20, Lemma 3.3] closely, replacing their notation with ours.\n\nObserve that the DP assumption in [FMT20, Lemma 3.3] is not actually needed in the proof.\n\nLemma E.4. Let R : X n \u00d1 Z be p , \u03b4q deletion group DP for groups of size n with reference distribution \u03c1.\n\nThen there exists a randomizer R 1 : X n \u00d1 Z such that: (i) R 1 is p , 0q deletion group DP for groups of size n with reference distribution \u03c1; and (ii) T V pRpXq, R 1 pXqq \u010f \u03b4.\n\nIn particular, R 1 is p2 , p1`e q\u03b4q group DP for groups of size n (by i).\n\nProof. The proof is nearly identical to the proof of [FMT20, Lemma 3.7].\n\nWe also need the following stronger version of [FMT20, Lemma 3.7]:\n\nLemma E.5. If RpX 0 1 q \u00bb p 0,\u03b40 q RpX 1 1 q, then there exists a randomizer R 1 : X n \u00d1 Z such that R 1 pX 1 1 q \u00bb p 0,0q\n\nRpX 0 1 q and T V pR 1 pX 1 1 q, RpX 1 1 qq \u010f \u03b4 0 .\n\nProof. The proof follows the same techniques as [FMT20, Lemma 3.7], noting that the weaker hypothesis in Lemma E.5 is sufficient for all the steps to go through and that the assumption of n \" 1 in [FMT20] is not needed in the proof.\n\nLemma E.6 ([DR14], Lemma 3.17). Given random variables P, Q, P 1 and Q 1 , if D e pP 1 , Q 1 q \u010f \u03b4, T V pP, P 1 q \u010f \u03b4 1 , and T V pQ, Q 1 q \u010f \u03b4 1 , then D e pP, Qq \u010f \u03b4`pe `1q\u03b4 1 .\n\nLemma E.7 ([FMT20], Lemma 2.3). Let P and Q be distributions satisfying P \" p1\u00b4qqP 0`q P 1 and Q \" p1\u00b4qqP 0`q Q 1 for some q P r0, 1s. Then for any \u0105 0, if 1 \" logp1`qpe \u00b41qq, then D e 1 pP ||Qq \u010f q maxtD e pP 1 ||P 0 q, D e pP 0 ||Q 1 qu \u010f qD e pP 1 ||Q 1 q.\n\nWe are now ready to prove Theorem E.2:\n\nProof of Theorem E.2. Let X 0 , X 1 P X n\u02c6N be adjacent (in the CDP sense) distributed data sets (i.e. |X 0 \u2206X 1 | \u010f 1). Assume WLOG that X 0 \" pX 0 1 , X 2 ,\u00a8\u00a8\u00a8, X N q and X 1 \" pX 1 1 , X 2 ,\u00a8\u00a8\u00a8, X N q, where X 0 1 \" px 1,0 , x 1,2 ,\u00a8\u00a8\u00a8, x 1,n q \u2030 px 1,1 , x 1,2 ,\u00a8\u00a8\u00a8, x 1,n q. We can also assume WLOG that X j R tX 0 1 , X 1 1 u for all j P t2,\u00a8\u00a8\u00a8, N u by re-defining X and R piq r if necessary. Fix i P rN s, r P rRs, Z \" Z 1:r\u00b41 \" Z p1:N q p1:r\u00b41q P Z pr\u00b41q\u02c6N , denote RpXq :\" R piq r pZ, Xq for X P X n , and A s pXq :\" A r s pZ 1:r\u00b41 , Xq. Draw \u03c0 uniformly from the set of permutations of rN s. Now, since R is p 0 , \u03b4 0 q-DP, RpX 1 1 q \u00bb p r 0 ,\u03b4 r 0 q RpX 0 1 q, so by Lemma E.5, there exists a local randomizer R 1 such that R 1 pX 1 1 q \u00bb p r 0 ,0q\n\nRpX 0 1 q and T V pR 1 pX 1 1 q, RpX 1 1 qq \u010f \u03b4 r 0 .\n\nHence, by Lemma E.1, there exist distributions U pX 0 1 q and U pX 1 1 q such that\nRpX 0 1 q \" e r 0 e r 0`1 U pX 0 1 q`1 e r 0`1 U pX 1 1 q(44)\nand\nR 1 pX 1 1 q \" 1 e r 0`1 U pX 0 1 q`e r 0 e r 0`1 U pX 1 1 q.(45)\nDenote r 0 :\" n r 0 and r \u03b4 0 :\" ne pn\u00b41q r 0 \u03b4 r 0 . By convexity of hockey-stick divergence and the hypothesis that R is p r 0 , \u03b4 r 0 q-DP (hence RpXq \u00bb p\u0102 0, \u0102 \u03b40q\n\nRpX 0 1 q, RpX 1 1 q for all X by Lemma E.2), we have RpXq \u00bb p\u0102 0, \u0102 \u03b40q 1 2 pRpX 0 1 q`RpX 1 1 qq :\" \u03c1 for all X P X n . That is, R is p r 0 , r \u03b4 0 q deletion group DP for groups of size n with reference distribution \u03c1. Thus, Lemma E.4 implies that there exists a local randomizer R 2 such that R 2 pXq and \u03c1 are p r 0 , 0q indistinguishable and T V pR 2 pXq, RpXqq \u010f r \u03b4 0 for all X. Then by the definition of p r 0 , 0q indistinguishability, for all X there exists a \"left-over\" distribution LOpXq such that R 2 pXq \" 1 e \u0102 0 \u03c1`p1\u00b41{e \u0102 0 qLOpXq \" 1 2e \u0102 0 pRpX 0 1 q`RpX 1 1 qq`p1\u00b41{e \u0102 0 qLOpXq. Now, define a randomizer L by LpX 0 1 q :\" RpX 0 1 q, LpX 1 1 q :\" R 1 pX 1 1 q, and\nLpXq :\" 1 2e \u0102 0 RpX 0 1 q`1 2e \u0102 0 R 1 pX 1 1 q`p1\u00b41{e \u0102 0 qLOpXq \" 1 2e \u0102 0 U pX 0 1 q`1 2e \u0102 0 U pX 1 1 q`p1\u00b41{e \u0102 0 qLOpXq(46)\nfor all X P X n ztX 0 1 , X 1 1 u. (The equality follows from (44) and (45).) Note that T V pRpX 0 1 q, LpX 0 1 qq \" 0, T V pRpX 1 1 q, LpX 1 1 qq \u010f \u03b4 r 0 , and for all X P X n ztX 0 1 , X 1 1 u, T V pRpXq, LpXqq \u010f T V pRpXq, R 2 pXqqT V pR 2 pXq, LpXqq \u010f r \u03b4 0`1 2e \u0102 0 T V pR 1 pX 1 1 q, RpX 1 1 qq \" pne pn\u00b41q r 0`1 2e n r 0 q\u03b4 r 0 \u010f p2ne pn\u00b41q r 0 q\u03b4 r 0 \" 2 r \u03b4 0 . Keeping r fixed (omitting r scripts everywhere), for any i P rN s and Z :\" Z 1:r\u00b41 P Z pr\u00b41q\u02c6N , let L piq pZ,\u00a8q, U piq pZ,\u00a8q, and LO piq pZ,\u00a8q denote the randomizers resulting from the process described above. Let A L : X n\u02c6N \u00d1 Z N be defined exactly the same way as A r s :\" A s (same \u03c0) but with the randomizers R piq replaced by L piq . Since A s applies each randomizer R piq exactly once and R p1q pZ, X \u03c0p1q ,\u00a8\u00a8\u00a8R pN q pZ, X \u03c0pN q q are independent (conditional on Z \" Z 1:r\u00b41 ) 15 , we have T V pA s pX 0 q, A L pX 0 q \u010f N p2ne pn\u00b41q r 0 q\u03b4 r 0 and T V pA s pX 1 q, A L pX 1 q \u010f N p2ne pn\u00b41q r 0 q\u03b4 r 0 (see [Exc]). Now we claim that A L pX 0 q and A L pX 1 q are p r , \u03b4 r q indistinguishable for any \u03b4 r \u011b 2e\u00b4N e\u00b4n r 0 {16 . Observe that this claim implies that A s pX 0 q and A s pX 1 q are p r , r \u03b4 r q indistinguishable by Lemma E.6 (with P 1 :\" A L pX 0 q, Q 1 :\" A L pX 1 q, P :\" A s pX 0 q, Q :\" A s pX 1 q.) Therefore, it remains to prove the claim, i.e. to show that D e r pA L pX 0 q, A L pX 1 q \u010f \u03b4 r for any \u03b4 r \u011b 2e\u00b4N e\u00b4n . For any inputs Z, X, let A U pZ, Xq be defined exactly the same as A s pZ, Xq (same \u03c0) but with the randomizers R piq replaced by L \n\nThen by (46), for any X P X n ztX 0 1 , X 1 1 u and any Z \" Z 1:r\u00b41 P Z pr\u00b41q\u02c6N , we have L piq U pZ, Xq \" 1 2e \u0102 0 L piq U pZ, X 0 1 q`1 2e \u0102 0 L piq U pZ, X 1 1 q`p1\u00b4e\u00b4\u0102 0 qLO piq pZ, Xq. Hence, Lemma E.3 (with p :\" e\u00b4\u0102 0 \" e\u00b4n r 0\n\nimplies that A U pX 0 q and A U pX 1 q) ar\u1ebd log\u02dc1`8 a e \u0102 0 lnp4{\u03b4 r q ? N`8 e \u0102 0 N\u00b8, \u03b4 r1\n\nindistinguishable for any \u03b4 r \u011b 2e\u00b4N e\u00b4n r 0 {16 . Applying Lemma E.7 with P :\" A L pX 0 q, Q \" A L pX 1 q,\n\nq \" e r 0\u00b41 e r 0`1 , P 1 \" A U pX 0 q, Q 1 \" A U pX 1 q, and P 0 \" 1 2 pP 1`Q1 q yields that A L pX 0 q and A L pX 1 q are p r , \u03b4 r q indistinguishable, as desired. This proves the claim and hence (by Lemma E.6, as described earlier) the theorem.\n\nRemark E.2. Notice that if A is sequentially interactive, then the proof of Theorem E.2 above almost immediately implies the sequentially interactive part of Theorem E.1. Essentially, just change notation: replace Z 1:r\u00b41 by Z p1:i\u00b41q , the collection of (single) reports sent by the first i\u00b41 clients; note that r 0 \" 0 , \u03b4 r 0 \" \u03b4 0 ; and view the N reports as being sent in order instead of simultaneously. Alternatively, plug our techniques for n \u0105 1 into the proof of [FMT20, Theorem 3.8], which is for sequentially interactive algorithms.\n\nStep 2: Combine Theorem E.1 with the following CDP SCO lower bounds which follow from [BST14, 2. There exists a \u00b5-strongly convex, \u00b5-smooth, L-Lipschitz loss f : W\u02c6X \u00d1 R and a distribution D on X such that the expected loss of A is lower bounded as EF p p w R q\u00b4F pw\u02daq \" r \u2126\u02c6L 2 \u00b5nN`L D min \" 1, d 2 n 2 N 2 *\u02d9.\n\nNamely, if A is p 0 , \u03b4 0 q-LDP, then (under the hypotheses of Theorem 3.1) A s is p , \u03b4q-CDP for \" r Op 0 { ? N q, so Theorem E.3 implies that the excess loss of A s is lower bounded as in Theorem E.3 with replaced by 0 { ? N .\n\nStep 3: We simply observe that when the expectation is taken over the randomness in sampling X \" D n\u02c6N , the expected excess population loss of A s is identical to that of A since XX i and XX \u03c0piq have the same distribution for all i, \u03c0 by the i.i.d. assumption. This completes the proof of Theorem 3.1.\n\n\nE.3 Lower bounds for LDP Federated ERM\n\nFormally, define the algorithm class B 0,\u03b40 :\" B to consist of those algorithms A P A 0,\u03b40 \" A such that for any X P X, f P F L,D , the expected empirical loss of the shuffled algorithm A s derived from A is upper bounded by the expected loss of A: E A,t\u03c0rur p F pA s pXqq \u00c0 E A p F pApXqq. Here A s denotes the algorithm that applies the randomizer R piq r to X \u03c0rpiq for all i, r, but otherwise behaves exactly like A. This is not a very constructive definition but we will describe examples of algorithms in B. B includes all compositional or sequentially interactive LDP algorithms that are symmetric with respect to each of the N clients, meaning that the aggregation functions g r are symmetric (i.e. g r pZ 1 ,\u00a8\u00a8\u00a8, Z N q \" g r pZ \u03c0p1q ,\u00a8\u00a8\u00a8Z \u03c0pN q q for all permutations \u03c0) and in each round r the randomizers R piq r \" R r are the same for all clients i P rN s. (R piq r can still change with r though.) For example, the three algorithms presented in Section 2 are all in B. This is because the aggregation functions used in each round are simple averages of the M \" N noisy gradients received from all clients (and they are compositional) and the randomizers in round r are identical when i \" 0 , \u03b4 i \" \u03b4 0 , n i \" n, X i \" X : each adds the same gaussian noise to the stochastic gradients. B also 16 Part 2 of Theorem E.3 follows from the alternate rescaling of [BST14]'s hard instance in which gpw, xq \" 1 2 }w\u00b4x} 2 on B 2 p0, 1q\u02c6X is scaled to f pw, xq \" \u00b5gpw, xq on W\u02c6X given in Theorem E.3. Then f is \u00b5D-Lipschitz, \u00b5-smooth, \u00b5-strongly convex, and the excess empirical risk in [BST14, Theorem 5.5] is scaled by \u00b5D 2 \" LD. See also [LR21, Proposition 2.7] and its proof.\n\nincludes sequentially interactive algorithms that choose the order in which clients are processed uniformly at random. This is because the distributions of the updates of A and A s are both averages over all permutations of rN s of the conditional (on \u03c0) distributions of the randomizers applied to the \u03c0-permuted database.\n\nTheorem E.4. Let n, d, N, R P N, 0 P p0, ? N s, \u03b4 0 P p0, 1q and A P B p 0,\u03b40 q such that in every round r P rRs, the local randomizers R piq r pZ p1:r\u00b41q ,\u00a8q : X n \u00d1 Z are p r 0 , \u03b4 r 0 q-DP for all i P rN s, Z p1:r\u00b41q P Z r\u00b41\u02c6N , with r 0 \u010f 1 n , and \u03b4 r 0 \u011b 2e\u00b4N {16 N n . Assume moreover that \u0159 r \u03b4 r 0 \" op1{n 2 N 2 q if A is compositional; if A is sequentially interactive, assume instead that \u03b4 0 \" op1{n 2 N 2 q. Then there exists a (linear, hence \u03b2-smooth @\u03b2 \u011b 0) loss function f P F L,D and a database X P X nN for some X such that the excess empirical loss of A is lower bounded as:\nE p F p p w R q\u00b4p F pw\u02daq \" r \u2126\u02dcLD min # 1, ? d 0 n ? N +\u00b8.\nFurthermore, there exists another (\u00b5-smooth) f P G \u00b5,L,D such that\nE p F p p w R q\u00b4p F pw\u02daq \" r \u2126\u02c6LD min \" 1, d 2 0 n 2 N *\u02d9.\nHere, the r \u2126 notation hides logarithmic factors depending on \u03b4 r 0 , n, and N . Proof.\n\nStep 1 is identical to Step 1 of the proof of Theorem E.4.\n\nStep 2 is very similar, but uses Theorem E.5 (below) instead of Theorem E.3 to lower bound the excess empirical loss of A s . Finally, the definition of B implies that the excess risk of A is the same as that of A s , hence the lower bound also applies to A.\n\nTheorem E.5.\n\n[BST14] Let \u00b5, D, \u0105 0, L \u011b \u00b5D, and \u03b4 \" op1{nN q. Consider X :\" t\u00b4D ? d , D\n\n? d u d \u0102 R d and W :\" B 2 p0, Dq \u0102 R d . Let A : X nN \u00d1 W be any p , \u03b4q-CDP algorithm. Then: 1. There exists a (\u00b5 \" 0) convex, linear (\u03b2-smooth for any \u03b2), L-Lipschitz loss f : W\u02c6X \u00d1 R and a database X P X nN such that the expected empirical loss of A is lower bounded as E p F p p w R q\u00b4p F pw\u02daq \" r \u2126\u02dcLD min # 1,\n\n? d nN +\u00b8.\n\n2. There exists a \u00b5-strongly convex, \u00b5-smooth, L-Lipschitz loss f : W\u02c6X \u00d1 R and a database X P X nN such that the expected empirical loss of A is lower bounded as E p F p p w R q\u00b4p F pw\u02daq \" r \u2126\u02c6LD min \" 1, d 2 n 2 N 2 *\u02d9.\n\n\nF Proof of Theorem 4.1\n\nFor this result, we will just prove the stated version with balanced data and same privacy needs across clients, and non-random M r \" M \u010f N (same setup as [GDD`21] considered for ERM). Theorem 4.1 Let f : W\u02c6X \u00d1 R d be \u03b2-smooth, L-Lipschitz, and \u00b5-strongly convex (with \u00b5 \" 0 for convex case). Assume \u010f lnp2{\u03b4q, \u03b4 P p0, 1q, and M \u011b 16 lnp18RM 2 {N \u03b4q for R specified below. Then, there is a constant C \u0105 0 such that setting \u03c3 2 i :\" CL 2 RM lnpRM 2 {N \u03b4q lnpR{\u03b4q lnp1{\u03b4q n 2 N 2 2 ensures that the shuffled version of Algorithm 1 is p , \u03b4q-CDP. Moreover, there exist \u03b7 r \" \u03b7 and t\u03b3 r u R\u00b41 r\"0 such that the shuffled version of Algorithm 1 achieves the following upper bounds on excess loss: \n\nFigure 1 :\n1LDP protects the privacy of each\n\n\nabsence of differential privacy constraints, federated learning has received a lot of attention from researchers in recent years. Among these, the most relevant works to us are [KLB`20, LHY`20, KKM`20, WPS`20a, WPS20b, YM20], which have proved bounds on the convergence rate of federated learning algorithms. From an algorithmic standpoint, all of these works propose and analyze either Minibatch SGD (MB-SGD), FedAvg/Local SGD [MMR`17], or an extension or accelerated/variance-reduced variation of one of these. Notably, [WPS20b] proves tight upper and lower bounds that establish the near optimality of accelerated MB-SGD for the heterogeneous SCO problem with non-random M r \" M \" N in a fairly wide parameter regime.More recently, there have been many proposed attempts to ensure the privacy of individuals' data during and after the federated learning process. Some of these have used secure multi-party computation (MPC) [CRT18, MZCS18], but this approach leaves users vulnerable to inference attacks on the trained model and does not provide the rigorous guarantee of DP. Others [MRTZ18, GKN17, JW18, GV18, WLD`20a, ZT20] have used client-level DP or global DP (CDP), which rely on a trusted third party, or hybrid DP/MPC approaches [JW18, TBA`19]. The work of [JW18] is particularly relevant in that they prove CDP empirical risk bounds and high probability guarantees on the population loss when the data is i.i.d. across clients. However they do not address LDP, non-i.i.d. FL, or provide expected excess loss bounds for i.i.d. FL. It is also worth mentioning that [GKN17] considers random M r but does not prove any bounds.Despite this progress, prior to our present work, far less was known about the convergence rate and excess risk potential of LDP FL algorithms. The only exceptions are in the two extreme corner cases of N \" 1 and n \" 1. When N \" 1, LDP and CDP are essentially equivalent; tight ERM [BST14] and i.i.d. SCO [BFTT19, FKT20] bounds are known for this case. In addition, for the special case of pure LDP i.i.d. SCO when n \" 1 and M r \" N is fixed, [DJW13] establishes the minimax optimal rate for the class of sequentially interactive algorithms and convex loss functions. To the best of our knowledge, all works examining the general LDP FL problem with arbitrary n, M, N \u011b 1 either focus on ERM and/or do not provide excess risk bounds that scale with both M and n i . Furthermore, none provide communication/gradient complexity guarantees, lower bounds, or bounds for random M r . We discuss each of these works in turn below:[TLC`20] gives an LDP FL algorithm but no risk bounds.[HHG`20] and [HG20] use LDP ADMM algorithms for smooth convex Federated ERM. However, their utility bounds are stated in terms of an average of the client functions evaluated at different points, so it is not clear how to relate their result to the standard performance measure for learning (which we consider in this paper): expected excess risk at the point p w output by the algorithm. [WFSK19, Theorem 2] provides an tp i , 0qu N i\"1 -LDP ERM bound for fixed M r \" M \" N of O\u00b4\u03ba L\n\n\n}\u2207F i pwq\u00b4\u2207F pwq} 2 ,which have appeared in [KKM`20, KMR19, KLB`20, WPS20b\n\n\n(assuming mintM, n min u \u0105 1). Proof of Lemma D.2. The proof of the convex case is similar to proofs of [HRS16, Theorem 3.8], [FV19, Lemma 4.3], and [BFTT19, Lemma 3.4]\n\n\nThen the proof begins along similar lines as the proof of [BST14, Theorem 2.1]. By the advanced composition theorem [DR14, Theorem 3.20], it suffices to show that each of the R rounds of the algorithm is pr , r \u03b4q-LDP, where r \"\n\n\nD.4. Then the result follows from Lemma D.1 and Lemma D.2.\n\nR\u00b41 r\" 0\n0in Theorem 2.1[Complete Version] results in the following upper bounds on the excess loss (w.r.t.\n\n\nf : W \u00d1 R d be convex and L-Lipschitz and let \u03b2 \u0105 0. Then the \u03b2-Moreau envelope f \u03b2 pwq :\" min vPW\u00b4f pvq`\u03b2 2 }w\u00b4v} 2\u00afs atisfies: 1. f \u03b2 is convex, 2L-Lipschitz, and \u03b2-smooth.2. @w, f \u03b2 pwq \u010f f pwq \u010f f \u03b2\n\n\nD.5 proves the strongly convex portion of Theorem D.1.D.5 Proof of Theorem 2.3Proof of Theorem 2.3. 1. Privacy: By post-processing, it suffices to show that the R \" n noisy gradients computed in line 6 of Algorithm 2 are p 0 , \u03b4 0 q-LDP. Further, since the points sampled locally are disjoint/distinct (because we sample locally without replacement), parallel composition [McS09] implies that if each update in line 6 is p 0 , \u03b4 0 q-LDP, then the full algorithm is p 0 , \u03b4 0 q-LDP. Now recall that the Gaussian mechanism [DR14, Appendix A.1] provides p 0 , \u03b4 0 q-DP if \u03c3 2 \u011b\n\n\nf \u03b2 pw, x i,j q, with f \u03b2 defined earlier (see complete version of Theorem 2.2). Then Algorithm 2 is tp i , \u03b4 i qu N i\"1 -LDP provided K i \u011b lnp2{\u03b4 i q. Further: 1. Running Algorithm 2 on r F \u03b2 pwq :\" p F \u03b2 pwq`\u03bb 2 }w} 2 with \u03bb :\" V 2D ?R and \u03b2 :\"\n\n\ni q :\" Q piq px i q. 9: end for 10: return tR piq r px i qu iPrN s,rPrds .\n\n\npZ, X \u03c0piq q. Then, A r s is p r , r \u03b4 r q-CDP, where\n\n\npiq r pZ p1:r\u00b41q,\u00a8q u iPrN s,rPrRs (i.e. A s is the composition of the R shuffled algorithms A r s defined in Theorem E.2) is p , \u03b4q-CDP, where \u03b4 \u010f 14N n\n\nL\npiq pZ, Xq otherwise.\n\nAA\nU pX 1 q and A L pX 1 q \" U pX 1 q.\n\n\nTheorems 5.3/5.5], [BFTT19, Appendix C], and the non-private SCO lower bounds (see [NY83, ABRW12]) 16 :Theorem E.3. [BFTT19, BST14] Let \u00b5, D, \u0105 0, L \u011b \u00b5D, and \u03b4 \" op1{nN q. Consider X :\" t\u00b4D ? d , D ? d u d \u0102 R d and W :\" B 2 p0, Dq \u0102 R d .Let A : X nN \u00d1 W be any p , \u03b4q-CDP algorithm. Then: 1. There exists a (\u00b5 \" 0) convex, linear (\u03b2-smooth for any \u03b2), L-Lipschitz loss f : W\u02c6X \u00d1 R and a distribution D on X such that the expected loss of A is lower bounded as EF p p w R q\u00b4F pw\u02daq \" r \u2126\u02dcLD\u02dc1 ?\n\n\n, wireless communication [MRTZ18], medicine [CMM`19], finance [fed19], and by companies such as Google [Pic19] and Apple [App19]\n\n\nWork and Our Contributions: Below we discuss the most relevant related work and describe our main contributions. See Appendix A for additional discussion of related work. 1. Tight minimax risk bounds for LDP Federated SCO with i.i.d. clients and reliable communication (Theorem 2.1, Theorem 2.2, and Theorem 3.1): [DJW13] and [STU17] studied a special case of the i.i.d. (\n\n2 .\n2The first non-trivial upper bound for LDP SCO with non-i.i.d. clients (Theorem 2.3): For the challenging problem of LDP FL (SCO) with non-i.i.d. client distributions, we develop an accelerated distributed noisy SGD algorithm based on [GL12], which runs in linear time and obtains the first non-trivial risk bound for smooth convex/strongly convex loss. Unsurprisingly, our non-i.i.d. bound does not match the i.i.d. minimax rate, leading to the open question of what the minimax rate is for non-i.i.d. LDP FL. However, for sufficiently large n, our bound does match the optimal i.i.d. rate for classical LDP, where clients are not trusted. 3. Improved communication complexity for LDP Federated ERM, plus matching lower bounds for a subset of LDP algorithms (Theorem D.1, Theorem 2.4, Section 3 and Theorem E.4): The special case of problem\n\n\nare upper bounds on the empirical risk of Algorithm 1. See Appendix D.2 for the detailed proof. The dependence of our communication complexity bounds in Theorem 2.1 on the number of active clients M is favorable: in the convex case, we have a ? M dependence and for strongly convex, it is logarithmic (yet excess risk decreases linearly in M ). This is an attractive feature of Algorithm 1 for large-scale FL problems. LDP of our algorithm, proved in Appendix D.2, follows from the privacy guarantees of the Gaussian mechanism [DR14, Theorem A.1], L-Lipschitzness of the loss (which implies bounded sensitivity), privacy amplification by subsampling [Ull17], and the advanced composition theorem [DR14, Theorem 3.20]. The alternative form of noise in [ACG`16] with \u03c3 2 \" 8L 2 R lnp1{\u03b40qn 2 2 \n\n0 \n\ncan be used to eliminate the hidden logarithmic \n\nfactor in the upper bounds in Theorem 2.1, provided K \u011b n \na \n4R (c.f. [BFTT19, Algorithm 1])\n\n\nThis upper bound is looser than the optimal i.i.d. bounds of Theorem 2.1 (yet the tightest known bound for non-i.i.d. LDP FL), leaving open the question of what the minimax optimal rate is for non-i.i.d. LDP FL.Accelerated Noisy MB-SGD for Federated ERM: With non-random M r \" M , [GDD`21] provides an \nupper bound for convex LDP ERM that nearly matches the one we provide below. 6 We use our accelerated \nLDP algorithm, Algorithm 2, to achieve the upper bounds for convex and strongly convex loss in fewer rounds \nof communications than [GDD`21]. Unlike the one-pass version of Algorithm 2 used for non-i.i.d. FL, for \nERM we sample local minibatches from each client with replacement to get tighter (in fact, optimal) bounds. \nHere we present just the non-smooth result, which we use Nesterov smoothing to obtain: \n\nTheorem 2.4. [Informal] Assume 0 \u010f lnp2{\u03b4 0 q and choose K \u011b \n\n0 n \n4 \n\n? \n\n2R lnp2{\u03b40q \n\n\n\n\nachievable excess risk of LDP FL algorithms with i.i.d. clients and M \" N . For the convex case, the minimax rate scales roughly as \u0398\u00b4? dOur first main result (Theorem 2.1, Theorem 2.2, and Theorem 3.1) was tight upper and lower bounds \non the n \n? \nN`1 \n? \n\nnN\u00af. Since LDP is stronger than CDP, it is not surprising \nthat the CDP rate [BFTT19] is tighter: \u0398\u00b4? d \n\nnN`1 \n? \n\n\n\n\n, Pradeep Ravikumar, and Martin J. Wainwright. Informationtheoretic lower bounds on the oracle complexity of stochastic convex optimization. Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Thakurta. Private stochastic convex optimization with optimal rates. In Advances in Neural Information Processing Systems, 2019. Cynthia Dwork and Aaron Roth. The Algorithmic Foundations of Differential Privacy. 2014. [Dwo06] Cynthia Dwork. Differential privacy. In International Colloquium on Automata, Languages, and Programming, pages 1-12. Springer, 2006. [EFM`20a] \u00dalfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Shuang Song, Kunal Talwar, and Abhradeep Thakurta. Encode, shuffle, analyze privacy revisited: Formalizations and empirical evaluation. arXiv preprint arXiv:2001.03618, 2020. [EFM`20b] Ulfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Abhradeep Thakurta. Amplification by shuffling: From local to central differential privacy via anonymity, 2020.IEEE \nTransactions on Information Theory, 58(5):3235-3249, 2012. \n\n[ACG`16] Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, \nand Li Zhang. Deep learning with differential privacy. Proceedings of the 2016 ACM SIGSAC \nConference on Computer and Communications Security, Oct 2016. \n\n[App19] \nApple. Private federated learning. NeurIPS 2019 Expo Talk Abstract, 2019. \n\n[BBGN19] Borja Balle, James Bell, Adria Gasc\u00f3n, and Kobbi Nissim. The privacy blanket of the shuffle \nmodel. In Annual International Cryptology Conference, pages 638-667. Springer, 2019. \n\n[BE02] \nOlivier Bousquet and Andr\u00e9 Elisseeff. Stability and generalization. The Journal of Machine \nLearning Research, 2:499-526, 2002. \n\n[BEM`17] Andrea Bittau, Ulfar Erlingsson, Petros Maniatis, Ilya Mironov, Ananth Raghunathan, David \nLie, Mitch Rudominer, Ushasree Kode, Julien Tinnes, and Bernhard Seefeld. Prochlo: Strong \nprivacy for analytics in the crowd. In Proceedings of the Symposium on Operating Systems \nPrinciples (SOSP), pages 441-459, 2017. \n\n[BFTT19] [BKM`20] Borja Balle, Peter Kairouz, Brendan McMahan, Om Dipakbhai Thakkar, and Abhradeep \nThakurta. Privacy amplification via random check-ins. 33, 2020. \n\n[BS16] \nMark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, \nand lower bounds. In Proceedings, Part I, of the 14th International Conference on Theory of \nCryptography -Volume 9985, page 635-658, Berlin, Heidelberg, 2016. Springer-Verlag. \n\n[BST14] \nRaef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimization: Effi-\ncient algorithms and tight error bounds. In 2014 IEEE 55th Annual Symposium on Foundations \nof Computer Science, pages 464-473. IEEE, 2014. \n\n[CJMP21] Albert Cheu, Matthew Joseph, Jieming Mao, and Binghui Peng. Shuffle private stochastic \nconvex optimization. arXiv preprint arXiv:2106.09805, 2021. \n\n[CMM`19] Pierre Courtiol, Charles Maussion, Matahi Moarii, Elodie Pronier, Samuel Pilcer, Meriem Sefta, \nPierre Manceron, Sylvain Toldo, Mikhail Zaslavskiy, and Nolwenn Le Stang. Deep learning-based \nclassification of mesothelioma improves prediction of patient outcome. Nature Medicine, page \n1-7, 2019. \n\n[CRT18] \nYi-Ruei Chen, Amir Rezapour, and Wen-Guey Tzeng. Privacy-preserving ridge regression on \ndistributed data. Information Sciences, 451:34-49, 2018. \n\n[CSU`19] Albert Cheu, Adam Smith, Jonathan Ullman, David Zeber, and Maxim Zhilyaev. Distributed \ndifferential privacy via shuffling. In Annual International Conference on the Theory and \nApplications of Cryptographic Techniques, pages 375-403. Springer, 2019. \n\n[DJW13] \nJohn C. Duchi, Michael I. Jordan, and Martin J. Wainwright. Local privacy and statistical \nminimax rates. In 2013 IEEE 54th Annual Symposium on Foundations of Computer Science, \npages 429-438, 2013. \n[DPZ`20] Roel Dobbe, Ye Pu, Jingge Zhu, Kannan Ramchandran, and Claire Tomlin. Customized local \ndifferential privacy for multi-agent distributed optimization, 2020. \n\n[DR14] \n\n\n\nFJR15] Matt Fredrikson, Somesh Jha, and Thomas Ristenpart. Model inversion attacks that exploit confidence information and basic countermeasures. In Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, pages 1322-1333, 2015.[FKT20]Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, pages 439-449, 2020.[FMT20] Vitaly Feldman, Audra McMillan, and Kunal Talwar. Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling, 2020.[FV19] Vitaly Feldman and Jan Vondrak. High probability generalization bounds for uniformly stable algorithms with nearly optimal rate. InAlinaBeygelzimer and Daniel Hsu, editors, Proceedings of the Thirty-Second Conference on Learning Theory, volume 99 of Proceedings of Machine Learning Research, pages 1270-1279, Phoenix, USA, 25-28 Jun 2019. PMLR. [GDD`21] Antonious Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and Ananda Theertha Suresh. Shuffled model of differential privacy in federated learning. In Arindam Banerjee and Kenji Fukumizu, editors, Proceedings of The 24th International Conference on Artificial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pages 2521-2529. PMLR, 13-15 Apr 2021. [GKN17] Robin C. Geyer, Tassilo Klein, and Moin Nabi. Differentially private federated learning: A client level perspective. CoRR, abs/1712.07557, 2017. [GL12] Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework. SIAM Journal on Optimization, 22(4):1469-1492, 2012. [GL13] Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, ii: Shrinking procedures and optimal algorithms. Shripad Gade and Nitin H Vaidya. Privacy-preserving distributed learning via obfuscated stochastic gradients. In 2018 IEEE Conference on Decision and Control (CDC), pages 184-191. IEEE, 2018. Zonghao Huang and Yanmin Gong. Differentially private ADMM for convex distributed learning: Improved accuracy via multi-step approximation. arXiv preprint:2005.07890, 2020. [HHG`20] Zonghao Huang, Rui Hu, Yuanxiong Guo, Eric Chan-Tin, and Yanmin Gong. DP-ADMM: ADMM-based distributed learning with differential privacy. IEEE Transactions on Information Forensics and Security, 15:1002-1012, 2020. [HK14] Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization. The Journal of Machine Learning Research, 15Ben Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic gradient descent. In Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pages 1225-1234, New York, New York, USA, 20-22 Jun 2016. PMLR. [HZL19] Zecheng He, Tianwei Zhang, and Ruby B Lee. Model inversion attacks against collaborative inference. In Proceedings of the 35th Annual Computer Security Applications Conference, pages 148-162, 2019. [JMNR19] Matthew Joseph, Jieming Mao, Seth Neel, and Aaron Roth. The role of interactivity in local differential privacy. In 2019 IEEE 60th Annual Symposium on Foundations of Computer Science (FOCS), pages 94-105. IEEE, 2019. [JW18] Bargav Jayaraman and Lingxiao Wang. Distributed learning without distress: Privacy-preserving empirical risk minimization. Advances in Neural Information Processing Systems, 2018. [Kam20] Gautam Kamath. Cs 860: Algorithms for private data analysis, 2020. http://www. gautamkamath.com/CS860notes/lec5.pdf. [KKM`20] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. SCAFFOLD: Stochastic controlled averaging for federated learning. In Hal Daum\u00e9 III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 5132-5143. PMLR, 13-18 Jul 2020. Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy, 2015. [LCC`20] Ruixuan Liu, Yang Cao, Hong Chen, Ruoyang Guo, and Masatoshi Yoshikawa. Flame: Differentially private federated learning in the shuffle model. In AAAI, 2020. [LHY`20] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of FedAvg on non-iid data. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020, 2020. [LO10] Ilan Lobel and Asuman Ozdaglar. Distributed subgradient methods for convex optimization over random networks. IEEE Transactions on Automatic Control, 56(6):1291-1306, 2010. [LR21] Andrew Lowy and Meisam Razaviyayn. Output perturbation for differentially private convex optimization with improved population loss bounds, runtimes and applications to private adversarial training. arXiv preprint:2102.04704, 2021. [LSA`21] Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza, Mehryar Mohri, and Ananda Theertha Suresh. Learning with user-level privacy. arXiv preprint arXiv:2102.11845, 2021. [McS09] Frank D McSherry. Privacy integrated queries: an extensible platform for privacy-preserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, pages 19-30, 2009. [MMR`17] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pages 1273-1282. PMLR, 2017. [MRTZ18] Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning differentially private recurrent language models. In International Conference on Learning Representations (ICLR), 2018. [MV16] Jack Murtagh and Salil Vadhan. The complexity of computing the optimal composition of differential privacy. In Theory of Cryptography Conference, pages 157-175. Springer, 2016. [MZCS18] Xu Ma, Fangguo Zhang, Xiaofeng Chen, and Jian Shen. Privacy preserving multi-party computation delegation for deep learning in cloud computing. Information Sciences, 459:103-116, 2018. [NDP`21] Dinh C. Nguyen, Ming Ding, Pubudu N. Pathirana, Aruna Seneviratne, Jun Li, and H. Vincent Poor. Federated learning for internet of things: A comprehensive survey. IEEE Communications Surveys and Tutorials, page 1-1, 2021. Alex Olshevsky, and Wei Shi. Achieving geometric convergence for distributed optimization over time-varying graphs. SIAM Journal on Optimization, 27(4):2597-2633, 2017. [NY83] Arkadii Semenovich Nemirovskii and David Borisovich Yudin. Problem Complexity and Method Efficiency in Optimization. 1983. [Pic19] Sundar Pichai. Google's Sundar Pichai: Privacy should not be a luxury good. The New York Times, May 2019. Mohamed Seif, Ravi Tandon, and Ming Li. Wireless federated learning with local differential privacy. In 2020 IEEE International Symposium on Information Theory (ISIT), pages 2604-2609, 2020. [STU17] Adam Smith, Abhradeep Thakurta, and Jalaj Upadhyay. Is interaction necessary for distributed private learning? In 2017 IEEE Symposium on Security and Privacy (SP), pages 58-77, 2017. [SWZ`20] Mengkai Song, Zhibo Wang, Zhifei Zhang, Yang Song, Qian Wang, Ju Ren, and Hairong Qi. Analyzing user-level privacy attack against federated learning. IEEE Journal on Selected Areas in Communications, 38(10):2430-2444, 2020. [TBA`19] Stacey Truex, Nathalie Baracaldo, Ali Anwar, Thomas Steinke, Heiko Ludwig, Rui Zhang, and Yi Zhou. A hybrid approach to privacy-preserving federated learning. In Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security, pages 1-11, 2019. [TG15] Behrouz Touri and Bahman Gharesifard. Continuous-time distributed convex optimization on time-varying directed networks. In 2015 54th IEEE Conference on Decision and Control (CDC), pages 724-729, 2015. [TLC`20] Stacey Truex, Ling Liu, Ka-Ho Chow, Mehmet Emre Gursoy, and Wenqi Wei. LDP-Fed: federated learning with local differential privacy. In Proceedings of the Third ACM International Workshop on Edge Systems, Analytics and Networking, page 61-66. Association for Computing Machinery, 2020. [Ull17] Jonathan Ullman. CS7880: rigorous approaches to data privacy, 2017. http://www.ccs.neu. edu/home/jullman/cs7880s17/HW1sol.pdf. [WFSK19] Nan Wu, Farhad Farokhi, David Smith, and Mohamed Ali Kaafar. The value of collaboration in convex machine learning with differential privacy, 2019. [WLD`20a] Kang Wei, Jun Li, Ming Ding, Chuan Ma, Hang Su, Bo Zhang, and H Vincent Poor. Userlevel privacy-preserving federated learning: Analysis and performance optimization. arXiv preprint:2003.00229, 2020. [WLD`20b] Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin, Tony QS Quek, and H Vincent Poor. Federated learning with differential privacy: Algorithms and performance analysis. IEEE Transactions on Information Forensics and Security, 15:3454-3469, 2020. [WPS`20a] Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan Mcmahan, Ohad Shamir, and Nathan Srebro. Is local SGD better than minibatch SGD? In International Conference on Machine Learning, pages 10334-10343. PMLR, 2020.SIAM Journal on Optimization, 23(4):2061-2089, 2013. \n\n[GV18] \n[HG20] \n\n(1):2489-\n2512, 2014. \n\n[HRS16] \nMoritz Hardt, [KOV15] \n\n[Nes05] \nYurii Nesterov. Smooth minimization of non-smooth functions. Mathematical programming, \n103(1):127-152, 2005. \n\n[NOS17] \nAngelia Nedic, [Sti19] \nSebastian U. Stich. Unified optimal analysis of the (stochastic) gradient method. arXiv \npreprint:1907.04232, 2019. \n[STL20] \n\n[WPS20b] Blake E Woodworth, Kumar Kshitij Patel, and Nati Srebro. Minibatch vs local sgd for \nheterogeneous distributed learning. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, \nand H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages \n6281-6292. Curran Associates, Inc., 2020. \n\n[YM20] \nHonglin Yuan and Tengyu Ma. Federated accelerated stochastic gradient descent. In H. Larochelle, \nM. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information \nProcessing Systems, volume 33, pages 5332-5344. Curran Associates, Inc., 2020. \n\n[ZH20] \nLigeng Zhu and Song Han. Deep leakage from gradients. In Federated learning, pages 17-31. \nSpringer, 2020. \n\n[ZT20] \nYaqin Zhou and Shaojie Tang. Differentially private distributed learning. INFORMS Journal \non Computing, 32(3):779-789, 2020. \n\n[ZZY`20] Yang Zhao, Jun Zhao, Mengmeng Yang, Teng Wang, Ning Wang, Lingjuan Lyu, Dusit Niyato, \nand Kwok-Yan Lam. Local differential privacy based federated learning for internet of things. \nIEEE Internet of Things Journal, 2020. \n\n\n\nLemma D.3. [HRS16, Lemma 3.7.3] Let G : W \u00d1 R d be \u00b5-strongly convex and \u03b2-smooth. Assume \u03b7 \u010f 2\u03b2`\u00b5 \n\nThen for any w, v P W, we have \n\n}pw\u00b4\u03b7\u2207Gpwqq\u00b4pv\u00b4\u03b7\u2207Gpvqq} \u010f\u02c61\u00b4\u03b7 \n\u03b2\u00b5 \n\u03b2`\u00b5\u02d9} \nv\u00b4w} \u010f\u00b41\u00b4\u03b7 \n\u00b5 \n2\u00af} \nv\u00b4w}. \n\n\n\n\n1. (Convex) Setting R :\" max\u00b4n lnpRM 2 {N \u03b4q lnpR{\u03b4q lnp1{\u03b4q 2 n 2 N 2\u02d9\u02d9.2 N 2 2 \nM \n\n, N \nM , min \n\n! \nn, \n\n2 n 2 N 2 \ndM \n\n) \n, \u03b2D \nL min \n\n! ? \nnM , nN \n\n? \nd \n\n)\u00afy \nields \n\nEF p p \nw R q\u00b4F pw\u02daq \" O\u02dcLD\u02dc1 ? \nnM`a \n\nd lnpRM 2 {N \u03b4q lnpR{\u03b4q lnp1{\u03b4q \nnN\u00b8\u00b8. \n(48) \n\n2. (Strongly convex) R :\" max\u00b4n \n\n2 N 2 2 \nM \n\n, N \nM , 8\u03b2 \n\u00b5 ln\u00b4\u03b2 D 2 \u00b5 2 n 2 N 2 \ndL 2\u00af, min \n\n! \nn, \n\n2 n 2 N 2 \ndM \n\n)\u00afy \nields \n\nEF p p \nw R q\u00b4F pw\u02daq \" r \nO\u02c6L \n\n2 \n\n\u00b5\u02c61 nM`d \n\n\nWe abbreviate central differential privacy by CDP for convenience, but note that this is a different notion of DP from concentrated differential privacy [BS16], for which the same abbreviation is sometimes used.\nSpecifically, Lemma D.1 in the Appendix does not apply without the i.i.d. assumption.\nThe bound in [GDD`21] is looser than the bound in (32) by logarithmic factor.\nThe rate established in [DJW13, STU17] is for sequentially interactive algorithm, but plugging n \" 1 into Theorem 3.1 (and replacing the number of clients N by nN ) shows that the same lower bound holds for fully interactive classical LDP algorithms.\nNote that in order for their result to be correct, by [BST14, Theorem 5.4] when N \" M \" 1, their bound must scale at least as d 2 { 2 n 2 , unless their bound is trivial (\u011b LD).\nIt can be proved by expanding both sides and applying [LR21, Lemma B.4] multiple times.\nTechnically, this assumption on N is needed to ensure that the condition on r 0 in Theorem E.2 is satisfied; it is inherited from [FMT20, Theorem 3.8], as we borrow their techniques, and a similar assumption appears in their result too.\nThis follows from the assumption given in the lead up to Definition 2 that R piq pZ 1:r\u00b41 , Xq is conditionally independent of X 1 given Z 1:r\u00b41 for all Z 1:r\u00b41 and X \u2030 X 1 .\nAcknowledgementsWe would like to thank Tianjian Huang, Dmitrii Ostrovskii, and Adam Smith for helpful comments and conversations.Q iff maxtD e pP }Qq, D e pQ}P qu \u010f \u03b4. Second, recall the total variation distance between P and Q is given by T V pP, Qq \" 1 2 \u015f R |ppxq\u00b4qpxq|dx. Third, we recall the notion of group privacy:Definition 6 (Group DP). A randomized algorithm A : X N \u00d1 Z is p , \u03b4q group DP for groups of size N if ApXq \u00bb p ,\u03b4q ApX 1 q for all X, X 1 P X N .We'll also need the following stronger version of a decomposition from [KOV15] and [MV16, Lemma 3.2].Lemma E.1 ([KOV15]). Let R 0 , R 1 : X n \u00d1 Z be local randomizers such that R 0 pX 0 q and R 1 pX 1 q are p , 0q indistinguishable. Then, there exists a randomized algorithm U : tX 0 , X 1 u \u00d1 Z such that R 0 pX 0 q \" e e `1 U pX 0 q`1 e `1 U pX 1 q and R 1 pX 1 q \" 1 e `1 U pX 0 q`e e `1 U pX 1 q. Lemma E.1 follows from the proof of [MV16, Lemma 3.2], noting that the weaker hypothesis assumed in Lemma E.1 sufficient for all steps to go through.Definition 7 (Deletion Group DP). Algorithm R : X n \u00d1 Z is p , \u03b4q deletion group DP for groups of size n if there exists a reference distribution \u03c1 such that RpXq \u00bb p ,\u03b4q \u03c1 for all X P X n .It's easy to show that if R is deletion group DP for groups of size n, then R is p2 , p1`e q\u03b4q group DP for groups of size n. In addition, we have the following result:Lemma E.2. Let X 0 P X n . If R : X n \u00d1 Z is an p , \u03b4q-DP local randomizer, then R is pn , ne pn\u00b41q \u03b4q deletion group DP for groups of size n with reference distribution RpX 0 q (i.e. RpXq \u00bb pr , r \u03b4q RpX 0 q for all X P X n , where r \" n and r \u03b4 \" ne pn\u00b41q \u03b4).Proof of Theorem 4.1. We fix K \" 1 for simplicity, but note that K \u0105 1 can also be used (see [GDD`21, Lemma 3] for details), which would improve the communication complexity of our algorithm by a factor of K in some parameter regimes. Privacy: The privacy proof is similar to the proof of [GDD`21, Theorem 1], except we replace their use of [BBGN19] (for pure DP randomizers) with [FMT20, Theorem 3.8] for our approximate DP randomizer (gaussian mechanism). Observe that in each round r, the model updates of the shuffled algorithm A r s can be viewed as post-processing of the composition M r pXq \" S M\u02dds amp M,N pZ p1q r ,\u00a8\u00a8\u00a8, Z pN q r q, where S M uniformly randomly shuffles the M received reports, samp M,N is the mechanism that chooses M reports uniformly at random from N , and Z piq rRpx 1 q,\u00a8\u00a8\u00a8, p Rpx n qq and r R M : X nM \u00d1 Z M is given by X \u00de \u00d1 p r RpX 1 q,\u00a8\u00a8\u00a8r RpX M qq for any X \" pX 1 ,\u00a8\u00a8\u00a8, X M q P X nM . This is because we are applying the same randomizer (same additive Gaussian noise) across clients and the operators S M and r R M commute. (Also, applying a randomizer to all N clients and then randomly choosing M reports is equivalent to randomly choosing M clients and then applying the same randomizer to all M of these clients.) Therefore, conditional on the random subsampling of M out of N clients (denoted pX 1 ,\u00a8\u00a8\u00a8, X M q for convenience), [FMT20, Theorem 3.8] implies that for some C \u0105 0 and p \u03b4 0 \" nN \u03b4 18RM 2 , we see that \u03c3 2 \" O\u00b4L 2 lnpRM 2 {N \u03b4q lnpR{\u03b4q lnp1{\u03b4qqRM n 2 N 2 2\u00afe nsures that A s is p , \u03b4q-CDP, i.e. that A is p , \u03b4q-SDP. Note that our choices of R in the theorem (specifically R \u011b N {M and R \u011b n 2 N 2 2 M ) ensure that p \u03b4 0 , \u03b4 \u010f 1 and p 0 \u00c0 1, so that [FMT20, Theorem 3.8] indeed gives us the amplification by shuffling result used above.Excess risk: The proof is very similar to the proof of Theorem 2.1, except \u03c3 2 is now smaller. Convex case: Set \u03b3 r \" \u03b3 \" 1{R for all r. Now (23), Lemma D.2, and Lemma D.1 together imply for any \u03b7 \u010f 1{4\u03b2 thatThen one can verify that plugging in the prescribed R yields the stated excess population loss bound. \u00b5-strongly convex case: Let X P X nN and denote the empirical risk minimizer by r w. Then for any \u03b7 t \u010f 1{4\u03b2, by (20) and the i.i.d assumption (so \u03a5 2 \" 0), we have (for all t) E}w t`1\u00b4r w} 2 \u010f p1\u00b4\u00b5\u03b7 t qE}w t\u00b4r w} 2\u00b4\u03b7Then by Lemma D.8 with a \" \u00b5, b \" 1, c \" 2\u00b44 L 2 M`d CL 2 R lnpRM 2 {N \u03b4q lnpR{\u03b4q lnp1{\u03b4q 2 n 2 N 2\u00af, g \" 4\u03b2, and T \" R, there exists a constant stepsize r \u03b7 and averaging weights \u03b3 r such that E p F p p w R q\u00b4p F pw\u02daq \" r O\u02c6\u03b2D 2 exp\u02c6\u00b4\u00b5 R 4\u03b2\u02d9`L Then one verifies that the prescribed R is large enough to achieve the stated excess population loss bound.\nSeyit Camtepe, and Mohammed Atiquzzaman. Local differential privacy for deep learning. Peter Pathum Chamikara Mahawaga Arachchige, Ibrahim Bertok, Dongxi Khalil, Liu, IEEE Internet of Things Journal. 77Pathum Chamikara Mahawaga Arachchige, Peter Bertok, Ibrahim Khalil, Dongxi Liu, Seyit Camtepe, and Mohammed Atiquzzaman. Local differential privacy for deep learning. IEEE Internet of Things Journal, 7(7):5827-5842, 2019.\n\nA unified theory of decentralized SGD with changing topology and local updates. Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, Sebastian Stich, PMLRProceedings of the 37th International Conference on Machine Learning. Hal Daum\u00e9 III and Aarti Singhthe 37th International Conference on Machine Learning119Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A unified theory of decentralized SGD with changing topology and local updates. In Hal Daum\u00e9 III and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 5381-5393. PMLR, 13-18 Jul 2020.\n\nWhat can we learn privately?. Shiva Prasad Kasiviswanathan, K Homin, Kobbi Lee, Sofya Nissim, Adam Raskhodnikova, Smith, SIAM Journal on Computing. 403KLN`11[KLN`11] Shiva Prasad Kasiviswanathan, Homin K Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. What can we learn privately? SIAM Journal on Computing, 40(3):793-826, 2011.\n\nH Brendan Peter Kairouz, Brendan Mcmahan, Aur\u00e9lien Avent, Mehdi Bellet, Arjun Nitin Bennis, Keith Bhagoji, Zachary Bonawitz, Graham Charles, Rachel Cormode, Cummings, G L Rafael, Salim El Oliveira, David Rouayheb, Josh Evans, Zachary Gardner, Adri\u00e0 Garrett, Badih Gasc\u00f3n, Phillip B Ghazi, Marco Gibbons, Zaid Gruteser, Chaoyang Harchaoui, Lie He, Zhouyuan He, Ben Huo, Justin Hutchinson, Martin Hsu, Tara Jaggi, Gauri Javidi, Mikhail Joshi, Jakub Khodak, Aleksandra Kone\u010dn\u00fd, Farinaz Korolova, Sanmi Koushanfar, Tancr\u00e8de Koyejo, Yang Lepoint, Prateek Liu, Mehryar Mittal, Richard Mohri, ; Jianyu Nock, Li Wang, Zheng Xiong, Qiang Xu, Felix X Yang, Han Yu, Sen Yu, Zhao, Praneeth Vepakomma. Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tram\u00e8rAyfer \u00d6zg\u00fcrAdvances and open problems in federated learning. arXiv preprint:1912.04977Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aur\u00e9lien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G. L. D'Oliveira, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adri\u00e0 Gasc\u00f3n, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Kone\u010dn\u00fd, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancr\u00e8de Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer \u00d6zg\u00fcr, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tram\u00e8r, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances and open problems in federated learning. arXiv preprint:1912.04977, 2019.\n\nBetter communication complexity for local SGD. Ahmed Khaled, Konstantin Mishchenko, Peter Richt\u00e1rik, arXiv preprintAhmed Khaled, Konstantin Mishchenko, and Peter Richt\u00e1rik. Better communication complexity for local SGD. arXiv preprint, 2019.\n", "annotations": {"author": "[{\"end\":172,\"start\":93},{\"end\":172,\"start\":93}]", "publisher": null, "author_last_name": "[{\"end\":104,\"start\":100},{\"end\":104,\"start\":100}]", "author_first_name": "[{\"end\":99,\"start\":93},{\"end\":99,\"start\":93}]", "author_affiliation": "[{\"end\":171,\"start\":120},{\"end\":171,\"start\":120}]", "title": "[{\"end\":90,\"start\":1},{\"end\":262,\"start\":173},{\"end\":90,\"start\":1},{\"end\":262,\"start\":173}]", "venue": null, "abstract": "[{\"end\":1637,\"start\":264},{\"end\":1637,\"start\":264}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2089,\"start\":2081},{\"end\":2199,\"start\":2191},{\"end\":2317,\"start\":2309},{\"end\":11182,\"start\":11181},{\"end\":11517,\"start\":11516},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12936,\"start\":12928},{\"end\":14482,\"start\":14474},{\"end\":14863,\"start\":14855},{\"end\":22412,\"start\":22404},{\"end\":35141,\"start\":35133},{\"end\":58282,\"start\":58280},{\"end\":88377,\"start\":88372},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2089,\"start\":2081},{\"end\":2199,\"start\":2191},{\"end\":2317,\"start\":2309},{\"end\":11182,\"start\":11181},{\"end\":11517,\"start\":11516},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12936,\"start\":12928},{\"end\":14482,\"start\":14474},{\"end\":14863,\"start\":14855},{\"end\":22412,\"start\":22404},{\"end\":35141,\"start\":35133},{\"end\":58282,\"start\":58280},{\"end\":88377,\"start\":88372}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":95660,\"start\":95615},{\"attributes\":{\"id\":\"fig_4\"},\"end\":98758,\"start\":95661},{\"attributes\":{\"id\":\"fig_5\"},\"end\":98835,\"start\":98759},{\"attributes\":{\"id\":\"fig_6\"},\"end\":99006,\"start\":98836},{\"attributes\":{\"id\":\"fig_7\"},\"end\":99237,\"start\":99007},{\"attributes\":{\"id\":\"fig_8\"},\"end\":99298,\"start\":99238},{\"attributes\":{\"id\":\"fig_9\"},\"end\":99407,\"start\":99299},{\"attributes\":{\"id\":\"fig_10\"},\"end\":99612,\"start\":99408},{\"attributes\":{\"id\":\"fig_12\"},\"end\":100189,\"start\":99613},{\"attributes\":{\"id\":\"fig_13\"},\"end\":100439,\"start\":100190},{\"attributes\":{\"id\":\"fig_14\"},\"end\":100516,\"start\":100440},{\"attributes\":{\"id\":\"fig_15\"},\"end\":100572,\"start\":100517},{\"attributes\":{\"id\":\"fig_16\"},\"end\":100728,\"start\":100573},{\"attributes\":{\"id\":\"fig_17\"},\"end\":100753,\"start\":100729},{\"attributes\":{\"id\":\"fig_18\"},\"end\":100793,\"start\":100754},{\"attributes\":{\"id\":\"fig_19\"},\"end\":101291,\"start\":100794},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":101422,\"start\":101292},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":101797,\"start\":101423},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":102644,\"start\":101798},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":103588,\"start\":102645},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":104499,\"start\":103589},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":104877,\"start\":104500},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":108915,\"start\":104878},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":119870,\"start\":108916},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":120077,\"start\":119871},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":120525,\"start\":120078},{\"attributes\":{\"id\":\"fig_1\"},\"end\":95660,\"start\":95615},{\"attributes\":{\"id\":\"fig_4\"},\"end\":98758,\"start\":95661},{\"attributes\":{\"id\":\"fig_5\"},\"end\":98835,\"start\":98759},{\"attributes\":{\"id\":\"fig_6\"},\"end\":99006,\"start\":98836},{\"attributes\":{\"id\":\"fig_7\"},\"end\":99237,\"start\":99007},{\"attributes\":{\"id\":\"fig_8\"},\"end\":99298,\"start\":99238},{\"attributes\":{\"id\":\"fig_9\"},\"end\":99407,\"start\":99299},{\"attributes\":{\"id\":\"fig_10\"},\"end\":99612,\"start\":99408},{\"attributes\":{\"id\":\"fig_12\"},\"end\":100189,\"start\":99613},{\"attributes\":{\"id\":\"fig_13\"},\"end\":100439,\"start\":100190},{\"attributes\":{\"id\":\"fig_14\"},\"end\":100516,\"start\":100440},{\"attributes\":{\"id\":\"fig_15\"},\"end\":100572,\"start\":100517},{\"attributes\":{\"id\":\"fig_16\"},\"end\":100728,\"start\":100573},{\"attributes\":{\"id\":\"fig_17\"},\"end\":100753,\"start\":100729},{\"attributes\":{\"id\":\"fig_18\"},\"end\":100793,\"start\":100754},{\"attributes\":{\"id\":\"fig_19\"},\"end\":101291,\"start\":100794},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":101422,\"start\":101292},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":101797,\"start\":101423},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":102644,\"start\":101798},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":103588,\"start\":102645},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":104499,\"start\":103589},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":104877,\"start\":104500},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":108915,\"start\":104878},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":119870,\"start\":108916},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":120077,\"start\":119871},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":120525,\"start\":120078}]", "paragraph": "[{\"end\":2811,\"start\":1653},{\"end\":3384,\"start\":2813},{\"end\":3591,\"start\":3386},{\"end\":4014,\"start\":3619},{\"end\":4593,\"start\":4016},{\"end\":5263,\"start\":4595},{\"end\":5511,\"start\":5265},{\"end\":6421,\"start\":5513},{\"end\":7043,\"start\":6423},{\"end\":8010,\"start\":7045},{\"end\":8776,\"start\":8012},{\"end\":9240,\"start\":8778},{\"end\":10446,\"start\":9242},{\"end\":11843,\"start\":10448},{\"end\":11947,\"start\":11845},{\"end\":12038,\"start\":11949},{\"end\":12495,\"start\":12320},{\"end\":12594,\"start\":12497},{\"end\":12793,\"start\":12596},{\"end\":13478,\"start\":12815},{\"end\":15887,\"start\":13498},{\"end\":16170,\"start\":15889},{\"end\":16604,\"start\":16198},{\"end\":16913,\"start\":16606},{\"end\":17162,\"start\":16972},{\"end\":17548,\"start\":17164},{\"end\":17579,\"start\":17550},{\"end\":17703,\"start\":17581},{\"end\":17879,\"start\":17710},{\"end\":17995,\"start\":17886},{\"end\":18259,\"start\":18057},{\"end\":18597,\"start\":18401},{\"end\":18842,\"start\":18774},{\"end\":19052,\"start\":18960},{\"end\":19649,\"start\":19054},{\"end\":19973,\"start\":19651},{\"end\":20201,\"start\":20051},{\"end\":20403,\"start\":20340},{\"end\":20496,\"start\":20405},{\"end\":21413,\"start\":20498},{\"end\":22413,\"start\":21415},{\"end\":23116,\"start\":22415},{\"end\":23263,\"start\":23118},{\"end\":23605,\"start\":23361},{\"end\":23732,\"start\":23679},{\"end\":23912,\"start\":23848},{\"end\":24143,\"start\":24050},{\"end\":24795,\"start\":24171},{\"end\":25154,\"start\":24797},{\"end\":25279,\"start\":25226},{\"end\":25938,\"start\":25281},{\"end\":26534,\"start\":25940},{\"end\":26685,\"start\":26600},{\"end\":26950,\"start\":26750},{\"end\":28187,\"start\":26952},{\"end\":28684,\"start\":28189},{\"end\":28972,\"start\":28686},{\"end\":29483,\"start\":29012},{\"end\":29741,\"start\":29680},{\"end\":29792,\"start\":29743},{\"end\":29990,\"start\":29930},{\"end\":30225,\"start\":30137},{\"end\":30568,\"start\":30227},{\"end\":31561,\"start\":30570},{\"end\":31635,\"start\":31563},{\"end\":32093,\"start\":31637},{\"end\":32866,\"start\":32139},{\"end\":33347,\"start\":32894},{\"end\":33610,\"start\":33349},{\"end\":33766,\"start\":33646},{\"end\":34364,\"start\":33797},{\"end\":34751,\"start\":34366},{\"end\":35098,\"start\":34753},{\"end\":35249,\"start\":35100},{\"end\":35381,\"start\":35251},{\"end\":35390,\"start\":35383},{\"end\":35463,\"start\":35392},{\"end\":36546,\"start\":35465},{\"end\":37439,\"start\":36548},{\"end\":37889,\"start\":37441},{\"end\":38008,\"start\":37891},{\"end\":38453,\"start\":38084},{\"end\":39508,\"start\":38526},{\"end\":39738,\"start\":39510},{\"end\":40310,\"start\":39740},{\"end\":40670,\"start\":40457},{\"end\":40704,\"start\":40672},{\"end\":40772,\"start\":40706},{\"end\":40853,\"start\":40774},{\"end\":41158,\"start\":40887},{\"end\":41502,\"start\":41216},{\"end\":41680,\"start\":41547},{\"end\":42073,\"start\":41849},{\"end\":42523,\"start\":42125},{\"end\":42670,\"start\":42575},{\"end\":42768,\"start\":42705},{\"end\":42959,\"start\":42937},{\"end\":43213,\"start\":43184},{\"end\":43368,\"start\":43235},{\"end\":44890,\"start\":43794},{\"end\":45022,\"start\":44892},{\"end\":45280,\"start\":45024},{\"end\":45439,\"start\":45282},{\"end\":45680,\"start\":45441},{\"end\":45980,\"start\":45741},{\"end\":46049,\"start\":46016},{\"end\":46120,\"start\":46059},{\"end\":46353,\"start\":46290},{\"end\":47348,\"start\":46355},{\"end\":48198,\"start\":47413},{\"end\":48410,\"start\":48207},{\"end\":49581,\"start\":48787},{\"end\":49748,\"start\":49612},{\"end\":49929,\"start\":49889},{\"end\":50123,\"start\":49931},{\"end\":50776,\"start\":50327},{\"end\":50992,\"start\":50847},{\"end\":51212,\"start\":51059},{\"end\":51318,\"start\":51281},{\"end\":51521,\"start\":51395},{\"end\":51787,\"start\":51748},{\"end\":51841,\"start\":51789},{\"end\":52087,\"start\":51843},{\"end\":52235,\"start\":52131},{\"end\":52435,\"start\":52352},{\"end\":52586,\"start\":52581},{\"end\":52803,\"start\":52765},{\"end\":53266,\"start\":52873},{\"end\":53702,\"start\":53268},{\"end\":53962,\"start\":53843},{\"end\":54195,\"start\":54077},{\"end\":54873,\"start\":54197},{\"end\":55335,\"start\":54875},{\"end\":55569,\"start\":55351},{\"end\":56060,\"start\":55897},{\"end\":56295,\"start\":56223},{\"end\":56431,\"start\":56362},{\"end\":56783,\"start\":56521},{\"end\":57285,\"start\":57284},{\"end\":57419,\"start\":57355},{\"end\":58040,\"start\":57587},{\"end\":58132,\"start\":58042},{\"end\":58253,\"start\":58134},{\"end\":58361,\"start\":58255},{\"end\":58596,\"start\":58363},{\"end\":58705,\"start\":58598},{\"end\":59105,\"start\":58707},{\"end\":59239,\"start\":59166},{\"end\":59359,\"start\":59318},{\"end\":59878,\"start\":59361},{\"end\":60005,\"start\":59929},{\"end\":60070,\"start\":60012},{\"end\":60952,\"start\":60635},{\"end\":62310,\"start\":61699},{\"end\":62597,\"start\":62584},{\"end\":62682,\"start\":62599},{\"end\":62817,\"start\":62737},{\"end\":62911,\"start\":62819},{\"end\":63249,\"start\":63169},{\"end\":63686,\"start\":63379},{\"end\":63867,\"start\":63819},{\"end\":64118,\"start\":63997},{\"end\":64271,\"start\":64203},{\"end\":64319,\"start\":64273},{\"end\":65417,\"start\":64321},{\"end\":65973,\"start\":65436},{\"end\":66530,\"start\":66300},{\"end\":66978,\"start\":66580},{\"end\":67114,\"start\":66980},{\"end\":67288,\"start\":67280},{\"end\":67820,\"start\":67441},{\"end\":68076,\"start\":67928},{\"end\":68090,\"start\":68078},{\"end\":68260,\"start\":68092},{\"end\":68380,\"start\":68303},{\"end\":68603,\"start\":68556},{\"end\":68739,\"start\":68702},{\"end\":69348,\"start\":68748},{\"end\":69424,\"start\":69355},{\"end\":69441,\"start\":69431},{\"end\":69491,\"start\":69443},{\"end\":69628,\"start\":69498},{\"end\":69734,\"start\":69636},{\"end\":69787,\"start\":69736},{\"end\":70014,\"start\":69843},{\"end\":70320,\"start\":70201},{\"end\":70366,\"start\":70355},{\"end\":70439,\"start\":70368},{\"end\":70493,\"start\":70441},{\"end\":70634,\"start\":70608},{\"end\":70869,\"start\":70854},{\"end\":71035,\"start\":70871},{\"end\":71176,\"start\":71155},{\"end\":71205,\"start\":71178},{\"end\":71440,\"start\":71425},{\"end\":71938,\"start\":71442},{\"end\":72235,\"start\":71940},{\"end\":72238,\"start\":72237},{\"end\":72480,\"start\":72310},{\"end\":72710,\"start\":72482},{\"end\":72798,\"start\":72712},{\"end\":73124,\"start\":72969},{\"end\":73402,\"start\":73126},{\"end\":73468,\"start\":73446},{\"end\":74126,\"start\":73470},{\"end\":74387,\"start\":74204},{\"end\":74664,\"start\":74431},{\"end\":74909,\"start\":74714},{\"end\":75184,\"start\":75161},{\"end\":75427,\"start\":75401},{\"end\":75638,\"start\":75623},{\"end\":75753,\"start\":75640},{\"end\":75942,\"start\":75916},{\"end\":75971,\"start\":75944},{\"end\":76208,\"start\":76193},{\"end\":76582,\"start\":76210},{\"end\":77341,\"start\":76669},{\"end\":77890,\"start\":77500},{\"end\":78050,\"start\":77892},{\"end\":78838,\"start\":78052},{\"end\":79342,\"start\":78840},{\"end\":79829,\"start\":79344},{\"end\":79909,\"start\":79831},{\"end\":80008,\"start\":79944},{\"end\":80125,\"start\":80048},{\"end\":81001,\"start\":80127},{\"end\":81340,\"start\":81031},{\"end\":83702,\"start\":81342},{\"end\":83877,\"start\":83776},{\"end\":83968,\"start\":83879},{\"end\":84076,\"start\":83970},{\"end\":84255,\"start\":84078},{\"end\":84330,\"start\":84257},{\"end\":84404,\"start\":84332},{\"end\":84472,\"start\":84406},{\"end\":84596,\"start\":84474},{\"end\":84649,\"start\":84598},{\"end\":84883,\"start\":84651},{\"end\":85064,\"start\":84885},{\"end\":85325,\"start\":85066},{\"end\":85365,\"start\":85327},{\"end\":86126,\"start\":85367},{\"end\":86181,\"start\":86128},{\"end\":86265,\"start\":86183},{\"end\":86331,\"start\":86328},{\"end\":86565,\"start\":86398},{\"end\":87253,\"start\":86567},{\"end\":88935,\"start\":87385},{\"end\":89170,\"start\":88937},{\"end\":89263,\"start\":89172},{\"end\":89372,\"start\":89265},{\"end\":89622,\"start\":89374},{\"end\":90168,\"start\":89624},{\"end\":90481,\"start\":90170},{\"end\":90711,\"start\":90483},{\"end\":91016,\"start\":90713},{\"end\":92741,\"start\":91059},{\"end\":93066,\"start\":92743},{\"end\":93661,\"start\":93068},{\"end\":93787,\"start\":93721},{\"end\":93934,\"start\":93847},{\"end\":93994,\"start\":93936},{\"end\":94254,\"start\":93996},{\"end\":94268,\"start\":94256},{\"end\":94344,\"start\":94270},{\"end\":94661,\"start\":94346},{\"end\":94673,\"start\":94663},{\"end\":94896,\"start\":94675},{\"end\":95614,\"start\":94923},{\"end\":2811,\"start\":1653},{\"end\":3384,\"start\":2813},{\"end\":3591,\"start\":3386},{\"end\":4014,\"start\":3619},{\"end\":4593,\"start\":4016},{\"end\":5263,\"start\":4595},{\"end\":5511,\"start\":5265},{\"end\":6421,\"start\":5513},{\"end\":7043,\"start\":6423},{\"end\":8010,\"start\":7045},{\"end\":8776,\"start\":8012},{\"end\":9240,\"start\":8778},{\"end\":10446,\"start\":9242},{\"end\":11843,\"start\":10448},{\"end\":11947,\"start\":11845},{\"end\":12038,\"start\":11949},{\"end\":12495,\"start\":12320},{\"end\":12594,\"start\":12497},{\"end\":12793,\"start\":12596},{\"end\":13478,\"start\":12815},{\"end\":15887,\"start\":13498},{\"end\":16170,\"start\":15889},{\"end\":16604,\"start\":16198},{\"end\":16913,\"start\":16606},{\"end\":17162,\"start\":16972},{\"end\":17548,\"start\":17164},{\"end\":17579,\"start\":17550},{\"end\":17703,\"start\":17581},{\"end\":17879,\"start\":17710},{\"end\":17995,\"start\":17886},{\"end\":18259,\"start\":18057},{\"end\":18597,\"start\":18401},{\"end\":18842,\"start\":18774},{\"end\":19052,\"start\":18960},{\"end\":19649,\"start\":19054},{\"end\":19973,\"start\":19651},{\"end\":20201,\"start\":20051},{\"end\":20403,\"start\":20340},{\"end\":20496,\"start\":20405},{\"end\":21413,\"start\":20498},{\"end\":22413,\"start\":21415},{\"end\":23116,\"start\":22415},{\"end\":23263,\"start\":23118},{\"end\":23605,\"start\":23361},{\"end\":23732,\"start\":23679},{\"end\":23912,\"start\":23848},{\"end\":24143,\"start\":24050},{\"end\":24795,\"start\":24171},{\"end\":25154,\"start\":24797},{\"end\":25279,\"start\":25226},{\"end\":25938,\"start\":25281},{\"end\":26534,\"start\":25940},{\"end\":26685,\"start\":26600},{\"end\":26950,\"start\":26750},{\"end\":28187,\"start\":26952},{\"end\":28684,\"start\":28189},{\"end\":28972,\"start\":28686},{\"end\":29483,\"start\":29012},{\"end\":29741,\"start\":29680},{\"end\":29792,\"start\":29743},{\"end\":29990,\"start\":29930},{\"end\":30225,\"start\":30137},{\"end\":30568,\"start\":30227},{\"end\":31561,\"start\":30570},{\"end\":31635,\"start\":31563},{\"end\":32093,\"start\":31637},{\"end\":32866,\"start\":32139},{\"end\":33347,\"start\":32894},{\"end\":33610,\"start\":33349},{\"end\":33766,\"start\":33646},{\"end\":34364,\"start\":33797},{\"end\":34751,\"start\":34366},{\"end\":35098,\"start\":34753},{\"end\":35249,\"start\":35100},{\"end\":35381,\"start\":35251},{\"end\":35390,\"start\":35383},{\"end\":35463,\"start\":35392},{\"end\":36546,\"start\":35465},{\"end\":37439,\"start\":36548},{\"end\":37889,\"start\":37441},{\"end\":38008,\"start\":37891},{\"end\":38453,\"start\":38084},{\"end\":39508,\"start\":38526},{\"end\":39738,\"start\":39510},{\"end\":40310,\"start\":39740},{\"end\":40670,\"start\":40457},{\"end\":40704,\"start\":40672},{\"end\":40772,\"start\":40706},{\"end\":40853,\"start\":40774},{\"end\":41158,\"start\":40887},{\"end\":41502,\"start\":41216},{\"end\":41680,\"start\":41547},{\"end\":42073,\"start\":41849},{\"end\":42523,\"start\":42125},{\"end\":42670,\"start\":42575},{\"end\":42768,\"start\":42705},{\"end\":42959,\"start\":42937},{\"end\":43213,\"start\":43184},{\"end\":43368,\"start\":43235},{\"end\":44890,\"start\":43794},{\"end\":45022,\"start\":44892},{\"end\":45280,\"start\":45024},{\"end\":45439,\"start\":45282},{\"end\":45680,\"start\":45441},{\"end\":45980,\"start\":45741},{\"end\":46049,\"start\":46016},{\"end\":46120,\"start\":46059},{\"end\":46353,\"start\":46290},{\"end\":47348,\"start\":46355},{\"end\":48198,\"start\":47413},{\"end\":48410,\"start\":48207},{\"end\":49581,\"start\":48787},{\"end\":49748,\"start\":49612},{\"end\":49929,\"start\":49889},{\"end\":50123,\"start\":49931},{\"end\":50776,\"start\":50327},{\"end\":50992,\"start\":50847},{\"end\":51212,\"start\":51059},{\"end\":51318,\"start\":51281},{\"end\":51521,\"start\":51395},{\"end\":51787,\"start\":51748},{\"end\":51841,\"start\":51789},{\"end\":52087,\"start\":51843},{\"end\":52235,\"start\":52131},{\"end\":52435,\"start\":52352},{\"end\":52586,\"start\":52581},{\"end\":52803,\"start\":52765},{\"end\":53266,\"start\":52873},{\"end\":53702,\"start\":53268},{\"end\":53962,\"start\":53843},{\"end\":54195,\"start\":54077},{\"end\":54873,\"start\":54197},{\"end\":55335,\"start\":54875},{\"end\":55569,\"start\":55351},{\"end\":56060,\"start\":55897},{\"end\":56295,\"start\":56223},{\"end\":56431,\"start\":56362},{\"end\":56783,\"start\":56521},{\"end\":57285,\"start\":57284},{\"end\":57419,\"start\":57355},{\"end\":58040,\"start\":57587},{\"end\":58132,\"start\":58042},{\"end\":58253,\"start\":58134},{\"end\":58361,\"start\":58255},{\"end\":58596,\"start\":58363},{\"end\":58705,\"start\":58598},{\"end\":59105,\"start\":58707},{\"end\":59239,\"start\":59166},{\"end\":59359,\"start\":59318},{\"end\":59878,\"start\":59361},{\"end\":60005,\"start\":59929},{\"end\":60070,\"start\":60012},{\"end\":60952,\"start\":60635},{\"end\":62310,\"start\":61699},{\"end\":62597,\"start\":62584},{\"end\":62682,\"start\":62599},{\"end\":62817,\"start\":62737},{\"end\":62911,\"start\":62819},{\"end\":63249,\"start\":63169},{\"end\":63686,\"start\":63379},{\"end\":63867,\"start\":63819},{\"end\":64118,\"start\":63997},{\"end\":64271,\"start\":64203},{\"end\":64319,\"start\":64273},{\"end\":65417,\"start\":64321},{\"end\":65973,\"start\":65436},{\"end\":66530,\"start\":66300},{\"end\":66978,\"start\":66580},{\"end\":67114,\"start\":66980},{\"end\":67288,\"start\":67280},{\"end\":67820,\"start\":67441},{\"end\":68076,\"start\":67928},{\"end\":68090,\"start\":68078},{\"end\":68260,\"start\":68092},{\"end\":68380,\"start\":68303},{\"end\":68603,\"start\":68556},{\"end\":68739,\"start\":68702},{\"end\":69348,\"start\":68748},{\"end\":69424,\"start\":69355},{\"end\":69441,\"start\":69431},{\"end\":69491,\"start\":69443},{\"end\":69628,\"start\":69498},{\"end\":69734,\"start\":69636},{\"end\":69787,\"start\":69736},{\"end\":70014,\"start\":69843},{\"end\":70320,\"start\":70201},{\"end\":70366,\"start\":70355},{\"end\":70439,\"start\":70368},{\"end\":70493,\"start\":70441},{\"end\":70634,\"start\":70608},{\"end\":70869,\"start\":70854},{\"end\":71035,\"start\":70871},{\"end\":71176,\"start\":71155},{\"end\":71205,\"start\":71178},{\"end\":71440,\"start\":71425},{\"end\":71938,\"start\":71442},{\"end\":72235,\"start\":71940},{\"end\":72238,\"start\":72237},{\"end\":72480,\"start\":72310},{\"end\":72710,\"start\":72482},{\"end\":72798,\"start\":72712},{\"end\":73124,\"start\":72969},{\"end\":73402,\"start\":73126},{\"end\":73468,\"start\":73446},{\"end\":74126,\"start\":73470},{\"end\":74387,\"start\":74204},{\"end\":74664,\"start\":74431},{\"end\":74909,\"start\":74714},{\"end\":75184,\"start\":75161},{\"end\":75427,\"start\":75401},{\"end\":75638,\"start\":75623},{\"end\":75753,\"start\":75640},{\"end\":75942,\"start\":75916},{\"end\":75971,\"start\":75944},{\"end\":76208,\"start\":76193},{\"end\":76582,\"start\":76210},{\"end\":77341,\"start\":76669},{\"end\":77890,\"start\":77500},{\"end\":78050,\"start\":77892},{\"end\":78838,\"start\":78052},{\"end\":79342,\"start\":78840},{\"end\":79829,\"start\":79344},{\"end\":79909,\"start\":79831},{\"end\":80008,\"start\":79944},{\"end\":80125,\"start\":80048},{\"end\":81001,\"start\":80127},{\"end\":81340,\"start\":81031},{\"end\":83702,\"start\":81342},{\"end\":83877,\"start\":83776},{\"end\":83968,\"start\":83879},{\"end\":84076,\"start\":83970},{\"end\":84255,\"start\":84078},{\"end\":84330,\"start\":84257},{\"end\":84404,\"start\":84332},{\"end\":84472,\"start\":84406},{\"end\":84596,\"start\":84474},{\"end\":84649,\"start\":84598},{\"end\":84883,\"start\":84651},{\"end\":85064,\"start\":84885},{\"end\":85325,\"start\":85066},{\"end\":85365,\"start\":85327},{\"end\":86126,\"start\":85367},{\"end\":86181,\"start\":86128},{\"end\":86265,\"start\":86183},{\"end\":86331,\"start\":86328},{\"end\":86565,\"start\":86398},{\"end\":87253,\"start\":86567},{\"end\":88935,\"start\":87385},{\"end\":89170,\"start\":88937},{\"end\":89263,\"start\":89172},{\"end\":89372,\"start\":89265},{\"end\":89622,\"start\":89374},{\"end\":90168,\"start\":89624},{\"end\":90481,\"start\":90170},{\"end\":90711,\"start\":90483},{\"end\":91016,\"start\":90713},{\"end\":92741,\"start\":91059},{\"end\":93066,\"start\":92743},{\"end\":93661,\"start\":93068},{\"end\":93787,\"start\":93721},{\"end\":93934,\"start\":93847},{\"end\":93994,\"start\":93936},{\"end\":94254,\"start\":93996},{\"end\":94268,\"start\":94256},{\"end\":94344,\"start\":94270},{\"end\":94661,\"start\":94346},{\"end\":94673,\"start\":94663},{\"end\":94896,\"start\":94675},{\"end\":95614,\"start\":94923}]", "formula": "[{\"attributes\":{\"id\":\"formula_1\"},\"end\":3618,\"start\":3592},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12319,\"start\":12039},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12814,\"start\":12794},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13497,\"start\":13489},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16971,\"start\":16914},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18056,\"start\":17996},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18400,\"start\":18260},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18773,\"start\":18598},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18959,\"start\":18843},{\"attributes\":{\"id\":\"formula_11\"},\"end\":20050,\"start\":19974},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20339,\"start\":20202},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23360,\"start\":23264},{\"attributes\":{\"id\":\"formula_14\"},\"end\":23678,\"start\":23606},{\"attributes\":{\"id\":\"formula_15\"},\"end\":23847,\"start\":23733},{\"attributes\":{\"id\":\"formula_16\"},\"end\":24049,\"start\":23913},{\"attributes\":{\"id\":\"formula_17\"},\"end\":25225,\"start\":25155},{\"attributes\":{\"id\":\"formula_18\"},\"end\":26599,\"start\":26535},{\"attributes\":{\"id\":\"formula_19\"},\"end\":26749,\"start\":26686},{\"attributes\":{\"id\":\"formula_20\"},\"end\":29679,\"start\":29484},{\"attributes\":{\"id\":\"formula_21\"},\"end\":29929,\"start\":29793},{\"attributes\":{\"id\":\"formula_22\"},\"end\":30136,\"start\":29991},{\"attributes\":{\"id\":\"formula_23\"},\"end\":32893,\"start\":32867},{\"attributes\":{\"id\":\"formula_24\"},\"end\":33645,\"start\":33611},{\"attributes\":{\"id\":\"formula_25\"},\"end\":33796,\"start\":33767},{\"attributes\":{\"id\":\"formula_26\"},\"end\":38083,\"start\":38009},{\"attributes\":{\"id\":\"formula_27\"},\"end\":40886,\"start\":40854},{\"attributes\":{\"id\":\"formula_28\"},\"end\":41215,\"start\":41159},{\"attributes\":{\"id\":\"formula_29\"},\"end\":41546,\"start\":41503},{\"attributes\":{\"id\":\"formula_30\"},\"end\":41848,\"start\":41681},{\"attributes\":{\"id\":\"formula_31\"},\"end\":42574,\"start\":42524},{\"attributes\":{\"id\":\"formula_32\"},\"end\":42704,\"start\":42671},{\"attributes\":{\"id\":\"formula_33\"},\"end\":42936,\"start\":42769},{\"attributes\":{\"id\":\"formula_34\"},\"end\":43183,\"start\":42960},{\"attributes\":{\"id\":\"formula_35\"},\"end\":43793,\"start\":43369},{\"attributes\":{\"id\":\"formula_36\"},\"end\":45740,\"start\":45681},{\"attributes\":{\"id\":\"formula_37\"},\"end\":46289,\"start\":46121},{\"attributes\":{\"id\":\"formula_38\"},\"end\":47412,\"start\":47349},{\"attributes\":{\"id\":\"formula_39\"},\"end\":48786,\"start\":48411},{\"attributes\":{\"id\":\"formula_40\"},\"end\":49611,\"start\":49582},{\"attributes\":{\"id\":\"formula_41\"},\"end\":49888,\"start\":49749},{\"attributes\":{\"id\":\"formula_42\"},\"end\":50326,\"start\":50124},{\"attributes\":{\"id\":\"formula_43\"},\"end\":50846,\"start\":50777},{\"attributes\":{\"id\":\"formula_44\"},\"end\":51058,\"start\":50993},{\"attributes\":{\"id\":\"formula_45\"},\"end\":51280,\"start\":51213},{\"attributes\":{\"id\":\"formula_46\"},\"end\":51394,\"start\":51319},{\"attributes\":{\"id\":\"formula_47\"},\"end\":51747,\"start\":51522},{\"attributes\":{\"id\":\"formula_48\"},\"end\":52130,\"start\":52088},{\"attributes\":{\"id\":\"formula_49\"},\"end\":52351,\"start\":52236},{\"attributes\":{\"id\":\"formula_50\"},\"end\":52580,\"start\":52436},{\"attributes\":{\"id\":\"formula_51\"},\"end\":52764,\"start\":52587},{\"attributes\":{\"id\":\"formula_52\"},\"end\":52872,\"start\":52804},{\"attributes\":{\"id\":\"formula_53\"},\"end\":53842,\"start\":53703},{\"attributes\":{\"id\":\"formula_54\"},\"end\":54076,\"start\":53963},{\"attributes\":{\"id\":\"formula_55\"},\"end\":55350,\"start\":55336},{\"attributes\":{\"id\":\"formula_56\"},\"end\":55896,\"start\":55570},{\"attributes\":{\"id\":\"formula_57\"},\"end\":56222,\"start\":56061},{\"attributes\":{\"id\":\"formula_58\"},\"end\":56361,\"start\":56296},{\"attributes\":{\"id\":\"formula_59\"},\"end\":56520,\"start\":56432},{\"attributes\":{\"id\":\"formula_60\"},\"end\":57283,\"start\":56784},{\"attributes\":{\"id\":\"formula_61\"},\"end\":57354,\"start\":57286},{\"attributes\":{\"id\":\"formula_62\"},\"end\":57586,\"start\":57420},{\"attributes\":{\"id\":\"formula_63\"},\"end\":59165,\"start\":59106},{\"attributes\":{\"id\":\"formula_64\"},\"end\":59317,\"start\":59240},{\"attributes\":{\"id\":\"formula_65\"},\"end\":59923,\"start\":59879},{\"attributes\":{\"id\":\"formula_66\"},\"end\":60634,\"start\":60071},{\"attributes\":{\"id\":\"formula_67\"},\"end\":61698,\"start\":60953},{\"attributes\":{\"id\":\"formula_68\"},\"end\":62583,\"start\":62311},{\"attributes\":{\"id\":\"formula_69\"},\"end\":62736,\"start\":62683},{\"attributes\":{\"id\":\"formula_70\"},\"end\":63168,\"start\":62912},{\"attributes\":{\"id\":\"formula_71\"},\"end\":63378,\"start\":63250},{\"attributes\":{\"id\":\"formula_72\"},\"end\":63818,\"start\":63687},{\"attributes\":{\"id\":\"formula_73\"},\"end\":63996,\"start\":63868},{\"attributes\":{\"id\":\"formula_74\"},\"end\":64202,\"start\":64119},{\"attributes\":{\"id\":\"formula_75\"},\"end\":65435,\"start\":65418},{\"attributes\":{\"id\":\"formula_76\"},\"end\":66299,\"start\":65974},{\"attributes\":{\"id\":\"formula_77\"},\"end\":66579,\"start\":66531},{\"attributes\":{\"id\":\"formula_78\"},\"end\":67217,\"start\":67115},{\"attributes\":{\"id\":\"formula_79\"},\"end\":67279,\"start\":67245},{\"attributes\":{\"id\":\"formula_80\"},\"end\":67440,\"start\":67289},{\"attributes\":{\"id\":\"formula_81\"},\"end\":68302,\"start\":68261},{\"attributes\":{\"id\":\"formula_82\"},\"end\":68555,\"start\":68381},{\"attributes\":{\"id\":\"formula_83\"},\"end\":68701,\"start\":68604},{\"attributes\":{\"id\":\"formula_84\"},\"end\":69842,\"start\":69788},{\"attributes\":{\"id\":\"formula_85\"},\"end\":70200,\"start\":70015},{\"attributes\":{\"id\":\"formula_86\"},\"end\":70354,\"start\":70321},{\"attributes\":{\"id\":\"formula_87\"},\"end\":70607,\"start\":70494},{\"attributes\":{\"id\":\"formula_88\"},\"end\":70853,\"start\":70635},{\"attributes\":{\"id\":\"formula_89\"},\"end\":71154,\"start\":71036},{\"attributes\":{\"id\":\"formula_90\"},\"end\":71424,\"start\":71206},{\"attributes\":{\"id\":\"formula_91\"},\"end\":72309,\"start\":72239},{\"attributes\":{\"id\":\"formula_92\"},\"end\":72968,\"start\":72799},{\"attributes\":{\"id\":\"formula_93\"},\"end\":73445,\"start\":73403},{\"attributes\":{\"id\":\"formula_94\"},\"end\":74188,\"start\":74127},{\"attributes\":{\"id\":\"formula_95\"},\"end\":74430,\"start\":74388},{\"attributes\":{\"id\":\"formula_96\"},\"end\":75160,\"start\":74910},{\"attributes\":{\"id\":\"formula_97\"},\"end\":75241,\"start\":75185},{\"attributes\":{\"id\":\"formula_98\"},\"end\":75400,\"start\":75241},{\"attributes\":{\"id\":\"formula_99\"},\"end\":75622,\"start\":75428},{\"attributes\":{\"id\":\"formula_100\"},\"end\":75915,\"start\":75754},{\"attributes\":{\"id\":\"formula_101\"},\"end\":76192,\"start\":75972},{\"attributes\":{\"id\":\"formula_102\"},\"end\":77383,\"start\":77342},{\"attributes\":{\"id\":\"formula_103\"},\"end\":77472,\"start\":77383},{\"attributes\":{\"id\":\"formula_105\"},\"end\":79943,\"start\":79910},{\"attributes\":{\"id\":\"formula_106\"},\"end\":80047,\"start\":80009},{\"attributes\":{\"id\":\"formula_107\"},\"end\":81030,\"start\":81002},{\"attributes\":{\"id\":\"formula_108\"},\"end\":83775,\"start\":83703},{\"attributes\":{\"id\":\"formula_109\"},\"end\":86327,\"start\":86266},{\"attributes\":{\"id\":\"formula_110\"},\"end\":86397,\"start\":86332},{\"attributes\":{\"id\":\"formula_111\"},\"end\":87384,\"start\":87254},{\"attributes\":{\"id\":\"formula_113\"},\"end\":93720,\"start\":93662},{\"attributes\":{\"id\":\"formula_114\"},\"end\":93846,\"start\":93788},{\"attributes\":{\"id\":\"formula_1\"},\"end\":3618,\"start\":3592},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12319,\"start\":12039},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12814,\"start\":12794},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13497,\"start\":13489},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16971,\"start\":16914},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18056,\"start\":17996},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18400,\"start\":18260},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18773,\"start\":18598},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18959,\"start\":18843},{\"attributes\":{\"id\":\"formula_11\"},\"end\":20050,\"start\":19974},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20339,\"start\":20202},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23360,\"start\":23264},{\"attributes\":{\"id\":\"formula_14\"},\"end\":23678,\"start\":23606},{\"attributes\":{\"id\":\"formula_15\"},\"end\":23847,\"start\":23733},{\"attributes\":{\"id\":\"formula_16\"},\"end\":24049,\"start\":23913},{\"attributes\":{\"id\":\"formula_17\"},\"end\":25225,\"start\":25155},{\"attributes\":{\"id\":\"formula_18\"},\"end\":26599,\"start\":26535},{\"attributes\":{\"id\":\"formula_19\"},\"end\":26749,\"start\":26686},{\"attributes\":{\"id\":\"formula_20\"},\"end\":29679,\"start\":29484},{\"attributes\":{\"id\":\"formula_21\"},\"end\":29929,\"start\":29793},{\"attributes\":{\"id\":\"formula_22\"},\"end\":30136,\"start\":29991},{\"attributes\":{\"id\":\"formula_23\"},\"end\":32893,\"start\":32867},{\"attributes\":{\"id\":\"formula_24\"},\"end\":33645,\"start\":33611},{\"attributes\":{\"id\":\"formula_25\"},\"end\":33796,\"start\":33767},{\"attributes\":{\"id\":\"formula_26\"},\"end\":38083,\"start\":38009},{\"attributes\":{\"id\":\"formula_27\"},\"end\":40886,\"start\":40854},{\"attributes\":{\"id\":\"formula_28\"},\"end\":41215,\"start\":41159},{\"attributes\":{\"id\":\"formula_29\"},\"end\":41546,\"start\":41503},{\"attributes\":{\"id\":\"formula_30\"},\"end\":41848,\"start\":41681},{\"attributes\":{\"id\":\"formula_31\"},\"end\":42574,\"start\":42524},{\"attributes\":{\"id\":\"formula_32\"},\"end\":42704,\"start\":42671},{\"attributes\":{\"id\":\"formula_33\"},\"end\":42936,\"start\":42769},{\"attributes\":{\"id\":\"formula_34\"},\"end\":43183,\"start\":42960},{\"attributes\":{\"id\":\"formula_35\"},\"end\":43793,\"start\":43369},{\"attributes\":{\"id\":\"formula_36\"},\"end\":45740,\"start\":45681},{\"attributes\":{\"id\":\"formula_37\"},\"end\":46289,\"start\":46121},{\"attributes\":{\"id\":\"formula_38\"},\"end\":47412,\"start\":47349},{\"attributes\":{\"id\":\"formula_39\"},\"end\":48786,\"start\":48411},{\"attributes\":{\"id\":\"formula_40\"},\"end\":49611,\"start\":49582},{\"attributes\":{\"id\":\"formula_41\"},\"end\":49888,\"start\":49749},{\"attributes\":{\"id\":\"formula_42\"},\"end\":50326,\"start\":50124},{\"attributes\":{\"id\":\"formula_43\"},\"end\":50846,\"start\":50777},{\"attributes\":{\"id\":\"formula_44\"},\"end\":51058,\"start\":50993},{\"attributes\":{\"id\":\"formula_45\"},\"end\":51280,\"start\":51213},{\"attributes\":{\"id\":\"formula_46\"},\"end\":51394,\"start\":51319},{\"attributes\":{\"id\":\"formula_47\"},\"end\":51747,\"start\":51522},{\"attributes\":{\"id\":\"formula_48\"},\"end\":52130,\"start\":52088},{\"attributes\":{\"id\":\"formula_49\"},\"end\":52351,\"start\":52236},{\"attributes\":{\"id\":\"formula_50\"},\"end\":52580,\"start\":52436},{\"attributes\":{\"id\":\"formula_51\"},\"end\":52764,\"start\":52587},{\"attributes\":{\"id\":\"formula_52\"},\"end\":52872,\"start\":52804},{\"attributes\":{\"id\":\"formula_53\"},\"end\":53842,\"start\":53703},{\"attributes\":{\"id\":\"formula_54\"},\"end\":54076,\"start\":53963},{\"attributes\":{\"id\":\"formula_55\"},\"end\":55350,\"start\":55336},{\"attributes\":{\"id\":\"formula_56\"},\"end\":55896,\"start\":55570},{\"attributes\":{\"id\":\"formula_57\"},\"end\":56222,\"start\":56061},{\"attributes\":{\"id\":\"formula_58\"},\"end\":56361,\"start\":56296},{\"attributes\":{\"id\":\"formula_59\"},\"end\":56520,\"start\":56432},{\"attributes\":{\"id\":\"formula_60\"},\"end\":57283,\"start\":56784},{\"attributes\":{\"id\":\"formula_61\"},\"end\":57354,\"start\":57286},{\"attributes\":{\"id\":\"formula_62\"},\"end\":57586,\"start\":57420},{\"attributes\":{\"id\":\"formula_63\"},\"end\":59165,\"start\":59106},{\"attributes\":{\"id\":\"formula_64\"},\"end\":59317,\"start\":59240},{\"attributes\":{\"id\":\"formula_65\"},\"end\":59923,\"start\":59879},{\"attributes\":{\"id\":\"formula_66\"},\"end\":60634,\"start\":60071},{\"attributes\":{\"id\":\"formula_67\"},\"end\":61698,\"start\":60953},{\"attributes\":{\"id\":\"formula_68\"},\"end\":62583,\"start\":62311},{\"attributes\":{\"id\":\"formula_69\"},\"end\":62736,\"start\":62683},{\"attributes\":{\"id\":\"formula_70\"},\"end\":63168,\"start\":62912},{\"attributes\":{\"id\":\"formula_71\"},\"end\":63378,\"start\":63250},{\"attributes\":{\"id\":\"formula_72\"},\"end\":63818,\"start\":63687},{\"attributes\":{\"id\":\"formula_73\"},\"end\":63996,\"start\":63868},{\"attributes\":{\"id\":\"formula_74\"},\"end\":64202,\"start\":64119},{\"attributes\":{\"id\":\"formula_75\"},\"end\":65435,\"start\":65418},{\"attributes\":{\"id\":\"formula_76\"},\"end\":66299,\"start\":65974},{\"attributes\":{\"id\":\"formula_77\"},\"end\":66579,\"start\":66531},{\"attributes\":{\"id\":\"formula_78\"},\"end\":67217,\"start\":67115},{\"attributes\":{\"id\":\"formula_79\"},\"end\":67279,\"start\":67245},{\"attributes\":{\"id\":\"formula_80\"},\"end\":67440,\"start\":67289},{\"attributes\":{\"id\":\"formula_81\"},\"end\":68302,\"start\":68261},{\"attributes\":{\"id\":\"formula_82\"},\"end\":68555,\"start\":68381},{\"attributes\":{\"id\":\"formula_83\"},\"end\":68701,\"start\":68604},{\"attributes\":{\"id\":\"formula_84\"},\"end\":69842,\"start\":69788},{\"attributes\":{\"id\":\"formula_85\"},\"end\":70200,\"start\":70015},{\"attributes\":{\"id\":\"formula_86\"},\"end\":70354,\"start\":70321},{\"attributes\":{\"id\":\"formula_87\"},\"end\":70607,\"start\":70494},{\"attributes\":{\"id\":\"formula_88\"},\"end\":70853,\"start\":70635},{\"attributes\":{\"id\":\"formula_89\"},\"end\":71154,\"start\":71036},{\"attributes\":{\"id\":\"formula_90\"},\"end\":71424,\"start\":71206},{\"attributes\":{\"id\":\"formula_91\"},\"end\":72309,\"start\":72239},{\"attributes\":{\"id\":\"formula_92\"},\"end\":72968,\"start\":72799},{\"attributes\":{\"id\":\"formula_93\"},\"end\":73445,\"start\":73403},{\"attributes\":{\"id\":\"formula_94\"},\"end\":74188,\"start\":74127},{\"attributes\":{\"id\":\"formula_95\"},\"end\":74430,\"start\":74388},{\"attributes\":{\"id\":\"formula_96\"},\"end\":75160,\"start\":74910},{\"attributes\":{\"id\":\"formula_97\"},\"end\":75241,\"start\":75185},{\"attributes\":{\"id\":\"formula_98\"},\"end\":75400,\"start\":75241},{\"attributes\":{\"id\":\"formula_99\"},\"end\":75622,\"start\":75428},{\"attributes\":{\"id\":\"formula_100\"},\"end\":75915,\"start\":75754},{\"attributes\":{\"id\":\"formula_101\"},\"end\":76192,\"start\":75972},{\"attributes\":{\"id\":\"formula_102\"},\"end\":77383,\"start\":77342},{\"attributes\":{\"id\":\"formula_103\"},\"end\":77472,\"start\":77383},{\"attributes\":{\"id\":\"formula_105\"},\"end\":79943,\"start\":79910},{\"attributes\":{\"id\":\"formula_106\"},\"end\":80047,\"start\":80009},{\"attributes\":{\"id\":\"formula_107\"},\"end\":81030,\"start\":81002},{\"attributes\":{\"id\":\"formula_108\"},\"end\":83775,\"start\":83703},{\"attributes\":{\"id\":\"formula_109\"},\"end\":86327,\"start\":86266},{\"attributes\":{\"id\":\"formula_110\"},\"end\":86397,\"start\":86332},{\"attributes\":{\"id\":\"formula_111\"},\"end\":87384,\"start\":87254},{\"attributes\":{\"id\":\"formula_113\"},\"end\":93720,\"start\":93662},{\"attributes\":{\"id\":\"formula_114\"},\"end\":93846,\"start\":93788}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1651,\"start\":1639},{\"end\":13488,\"start\":13481},{\"attributes\":{\"n\":\"2\"},\"end\":16196,\"start\":16173},{\"end\":17708,\"start\":17706},{\"end\":17884,\"start\":17882},{\"attributes\":{\"n\":\"3\"},\"end\":24169,\"start\":24146},{\"attributes\":{\"n\":\"4\"},\"end\":29010,\"start\":28975},{\"attributes\":{\"n\":\"5\"},\"end\":32137,\"start\":32096},{\"end\":38493,\"start\":38456},{\"end\":38524,\"start\":38496},{\"end\":40370,\"start\":40313},{\"end\":40455,\"start\":40373},{\"end\":42123,\"start\":42076},{\"attributes\":{\"n\":\"2.\"},\"end\":43233,\"start\":43216},{\"end\":46014,\"start\":45983},{\"end\":46057,\"start\":46052},{\"end\":48205,\"start\":48201},{\"end\":59927,\"start\":59925},{\"end\":60010,\"start\":60008},{\"attributes\":{\"n\":\"2.\"},\"end\":67244,\"start\":67219},{\"end\":67926,\"start\":67823},{\"end\":68746,\"start\":68742},{\"end\":69353,\"start\":69351},{\"end\":69429,\"start\":69427},{\"end\":69496,\"start\":69494},{\"end\":69634,\"start\":69631},{\"attributes\":{\"n\":\"2.\"},\"end\":74202,\"start\":74190},{\"end\":74712,\"start\":74667},{\"end\":76610,\"start\":76585},{\"end\":76667,\"start\":76613},{\"end\":77498,\"start\":77474},{\"end\":91057,\"start\":91019},{\"end\":94921,\"start\":94899},{\"end\":95626,\"start\":95616},{\"end\":99308,\"start\":99300},{\"end\":100731,\"start\":100730},{\"end\":100757,\"start\":100755},{\"end\":101802,\"start\":101799},{\"attributes\":{\"n\":\"1\"},\"end\":1651,\"start\":1639},{\"end\":13488,\"start\":13481},{\"attributes\":{\"n\":\"2\"},\"end\":16196,\"start\":16173},{\"end\":17708,\"start\":17706},{\"end\":17884,\"start\":17882},{\"attributes\":{\"n\":\"3\"},\"end\":24169,\"start\":24146},{\"attributes\":{\"n\":\"4\"},\"end\":29010,\"start\":28975},{\"attributes\":{\"n\":\"5\"},\"end\":32137,\"start\":32096},{\"end\":38493,\"start\":38456},{\"end\":38524,\"start\":38496},{\"end\":40370,\"start\":40313},{\"end\":40455,\"start\":40373},{\"end\":42123,\"start\":42076},{\"attributes\":{\"n\":\"2.\"},\"end\":43233,\"start\":43216},{\"end\":46014,\"start\":45983},{\"end\":46057,\"start\":46052},{\"end\":48205,\"start\":48201},{\"end\":59927,\"start\":59925},{\"end\":60010,\"start\":60008},{\"attributes\":{\"n\":\"2.\"},\"end\":67244,\"start\":67219},{\"end\":67926,\"start\":67823},{\"end\":68746,\"start\":68742},{\"end\":69353,\"start\":69351},{\"end\":69429,\"start\":69427},{\"end\":69496,\"start\":69494},{\"end\":69634,\"start\":69631},{\"attributes\":{\"n\":\"2.\"},\"end\":74202,\"start\":74190},{\"end\":74712,\"start\":74667},{\"end\":76610,\"start\":76585},{\"end\":76667,\"start\":76613},{\"end\":77498,\"start\":77474},{\"end\":91057,\"start\":91019},{\"end\":94921,\"start\":94899},{\"end\":95626,\"start\":95616},{\"end\":99308,\"start\":99300},{\"end\":100731,\"start\":100730},{\"end\":100757,\"start\":100755},{\"end\":101802,\"start\":101799}]", "table": "[{\"end\":103588,\"start\":103433},{\"end\":104499,\"start\":103802},{\"end\":104877,\"start\":104639},{\"end\":108915,\"start\":105899},{\"end\":119870,\"start\":118377},{\"end\":120077,\"start\":119968},{\"end\":120525,\"start\":120153},{\"end\":103588,\"start\":103433},{\"end\":104499,\"start\":103802},{\"end\":104877,\"start\":104639},{\"end\":108915,\"start\":105899},{\"end\":119870,\"start\":118377},{\"end\":120077,\"start\":119968},{\"end\":120525,\"start\":120153}]", "figure_caption": "[{\"end\":95660,\"start\":95628},{\"end\":98758,\"start\":95663},{\"end\":98835,\"start\":98761},{\"end\":99006,\"start\":98838},{\"end\":99237,\"start\":99009},{\"end\":99298,\"start\":99240},{\"end\":99407,\"start\":99310},{\"end\":99612,\"start\":99410},{\"end\":100189,\"start\":99615},{\"end\":100439,\"start\":100192},{\"end\":100516,\"start\":100442},{\"end\":100572,\"start\":100519},{\"end\":100728,\"start\":100575},{\"end\":100753,\"start\":100732},{\"end\":100793,\"start\":100758},{\"end\":101291,\"start\":100796},{\"end\":101422,\"start\":101294},{\"end\":101797,\"start\":101425},{\"end\":102644,\"start\":101804},{\"end\":103433,\"start\":102647},{\"end\":103802,\"start\":103591},{\"end\":104639,\"start\":104502},{\"end\":105899,\"start\":104880},{\"end\":118377,\"start\":108918},{\"end\":119968,\"start\":119873},{\"end\":120153,\"start\":120080},{\"end\":95660,\"start\":95628},{\"end\":98758,\"start\":95663},{\"end\":98835,\"start\":98761},{\"end\":99006,\"start\":98838},{\"end\":99237,\"start\":99009},{\"end\":99298,\"start\":99240},{\"end\":99407,\"start\":99310},{\"end\":99612,\"start\":99410},{\"end\":100189,\"start\":99615},{\"end\":100439,\"start\":100192},{\"end\":100516,\"start\":100442},{\"end\":100572,\"start\":100519},{\"end\":100728,\"start\":100575},{\"end\":100753,\"start\":100732},{\"end\":100793,\"start\":100758},{\"end\":101291,\"start\":100796},{\"end\":101422,\"start\":101294},{\"end\":101797,\"start\":101425},{\"end\":102644,\"start\":101804},{\"end\":103433,\"start\":102647},{\"end\":103802,\"start\":103591},{\"end\":104639,\"start\":104502},{\"end\":105899,\"start\":104880},{\"end\":118377,\"start\":108918},{\"end\":119968,\"start\":119873},{\"end\":120153,\"start\":120080}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":7991,\"start\":7985},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":7991,\"start\":7985}]", "bib_author_first_name": "[{\"end\":126230,\"start\":126225},{\"end\":126276,\"start\":126269},{\"end\":126291,\"start\":126285},{\"end\":126652,\"start\":126643},{\"end\":126671,\"start\":126664},{\"end\":126685,\"start\":126680},{\"end\":126701,\"start\":126695},{\"end\":126718,\"start\":126709},{\"end\":127322,\"start\":127321},{\"end\":127335,\"start\":127330},{\"end\":127346,\"start\":127341},{\"end\":127359,\"start\":127355},{\"end\":127600,\"start\":127599},{\"end\":127608,\"start\":127601},{\"end\":127631,\"start\":127624},{\"end\":127649,\"start\":127641},{\"end\":127662,\"start\":127657},{\"end\":127676,\"start\":127671},{\"end\":127682,\"start\":127677},{\"end\":127696,\"start\":127691},{\"end\":127713,\"start\":127706},{\"end\":127730,\"start\":127724},{\"end\":127746,\"start\":127740},{\"end\":127767,\"start\":127766},{\"end\":127769,\"start\":127768},{\"end\":127783,\"start\":127778},{\"end\":127786,\"start\":127784},{\"end\":127802,\"start\":127797},{\"end\":127817,\"start\":127813},{\"end\":127832,\"start\":127825},{\"end\":127847,\"start\":127842},{\"end\":127862,\"start\":127857},{\"end\":127878,\"start\":127871},{\"end\":127880,\"start\":127879},{\"end\":127893,\"start\":127888},{\"end\":127907,\"start\":127903},{\"end\":127926,\"start\":127918},{\"end\":127941,\"start\":127938},{\"end\":127954,\"start\":127946},{\"end\":127962,\"start\":127959},{\"end\":127974,\"start\":127968},{\"end\":127993,\"start\":127987},{\"end\":128003,\"start\":127999},{\"end\":128016,\"start\":128011},{\"end\":128032,\"start\":128025},{\"end\":128045,\"start\":128040},{\"end\":128064,\"start\":128054},{\"end\":128081,\"start\":128074},{\"end\":128097,\"start\":128092},{\"end\":128118,\"start\":128110},{\"end\":128131,\"start\":128127},{\"end\":128148,\"start\":128141},{\"end\":128161,\"start\":128154},{\"end\":128177,\"start\":128170},{\"end\":128193,\"start\":128185},{\"end\":128202,\"start\":128200},{\"end\":128214,\"start\":128209},{\"end\":128227,\"start\":128222},{\"end\":128237,\"start\":128232},{\"end\":128239,\"start\":128238},{\"end\":128249,\"start\":128246},{\"end\":128257,\"start\":128254},{\"end\":129550,\"start\":129545},{\"end\":129569,\"start\":129559},{\"end\":129587,\"start\":129582},{\"end\":126230,\"start\":126225},{\"end\":126276,\"start\":126269},{\"end\":126291,\"start\":126285},{\"end\":126652,\"start\":126643},{\"end\":126671,\"start\":126664},{\"end\":126685,\"start\":126680},{\"end\":126701,\"start\":126695},{\"end\":126718,\"start\":126709},{\"end\":127322,\"start\":127321},{\"end\":127335,\"start\":127330},{\"end\":127346,\"start\":127341},{\"end\":127359,\"start\":127355},{\"end\":127600,\"start\":127599},{\"end\":127608,\"start\":127601},{\"end\":127631,\"start\":127624},{\"end\":127649,\"start\":127641},{\"end\":127662,\"start\":127657},{\"end\":127676,\"start\":127671},{\"end\":127682,\"start\":127677},{\"end\":127696,\"start\":127691},{\"end\":127713,\"start\":127706},{\"end\":127730,\"start\":127724},{\"end\":127746,\"start\":127740},{\"end\":127767,\"start\":127766},{\"end\":127769,\"start\":127768},{\"end\":127783,\"start\":127778},{\"end\":127786,\"start\":127784},{\"end\":127802,\"start\":127797},{\"end\":127817,\"start\":127813},{\"end\":127832,\"start\":127825},{\"end\":127847,\"start\":127842},{\"end\":127862,\"start\":127857},{\"end\":127878,\"start\":127871},{\"end\":127880,\"start\":127879},{\"end\":127893,\"start\":127888},{\"end\":127907,\"start\":127903},{\"end\":127926,\"start\":127918},{\"end\":127941,\"start\":127938},{\"end\":127954,\"start\":127946},{\"end\":127962,\"start\":127959},{\"end\":127974,\"start\":127968},{\"end\":127993,\"start\":127987},{\"end\":128003,\"start\":127999},{\"end\":128016,\"start\":128011},{\"end\":128032,\"start\":128025},{\"end\":128045,\"start\":128040},{\"end\":128064,\"start\":128054},{\"end\":128081,\"start\":128074},{\"end\":128097,\"start\":128092},{\"end\":128118,\"start\":128110},{\"end\":128131,\"start\":128127},{\"end\":128148,\"start\":128141},{\"end\":128161,\"start\":128154},{\"end\":128177,\"start\":128170},{\"end\":128193,\"start\":128185},{\"end\":128202,\"start\":128200},{\"end\":128214,\"start\":128209},{\"end\":128227,\"start\":128222},{\"end\":128237,\"start\":128232},{\"end\":128239,\"start\":128238},{\"end\":128249,\"start\":128246},{\"end\":128257,\"start\":128254},{\"end\":129550,\"start\":129545},{\"end\":129569,\"start\":129559},{\"end\":129587,\"start\":129582}]", "bib_author_last_name": "[{\"end\":126267,\"start\":126231},{\"end\":126283,\"start\":126277},{\"end\":126298,\"start\":126292},{\"end\":126303,\"start\":126300},{\"end\":126662,\"start\":126653},{\"end\":126678,\"start\":126672},{\"end\":126693,\"start\":126686},{\"end\":126707,\"start\":126702},{\"end\":126724,\"start\":126719},{\"end\":127319,\"start\":127291},{\"end\":127328,\"start\":127323},{\"end\":127339,\"start\":127336},{\"end\":127353,\"start\":127347},{\"end\":127373,\"start\":127360},{\"end\":127380,\"start\":127375},{\"end\":127622,\"start\":127609},{\"end\":127639,\"start\":127632},{\"end\":127655,\"start\":127650},{\"end\":127669,\"start\":127663},{\"end\":127689,\"start\":127683},{\"end\":127704,\"start\":127697},{\"end\":127722,\"start\":127714},{\"end\":127738,\"start\":127731},{\"end\":127754,\"start\":127747},{\"end\":127764,\"start\":127756},{\"end\":127776,\"start\":127770},{\"end\":127795,\"start\":127787},{\"end\":127811,\"start\":127803},{\"end\":127823,\"start\":127818},{\"end\":127840,\"start\":127833},{\"end\":127855,\"start\":127848},{\"end\":127869,\"start\":127863},{\"end\":127886,\"start\":127881},{\"end\":127901,\"start\":127894},{\"end\":127916,\"start\":127908},{\"end\":127936,\"start\":127927},{\"end\":127944,\"start\":127942},{\"end\":127957,\"start\":127955},{\"end\":127966,\"start\":127963},{\"end\":127985,\"start\":127975},{\"end\":127997,\"start\":127994},{\"end\":128009,\"start\":128004},{\"end\":128023,\"start\":128017},{\"end\":128038,\"start\":128033},{\"end\":128052,\"start\":128046},{\"end\":128072,\"start\":128065},{\"end\":128090,\"start\":128082},{\"end\":128108,\"start\":128098},{\"end\":128125,\"start\":128119},{\"end\":128139,\"start\":128132},{\"end\":128152,\"start\":128149},{\"end\":128168,\"start\":128162},{\"end\":128183,\"start\":128178},{\"end\":128198,\"start\":128194},{\"end\":128207,\"start\":128203},{\"end\":128220,\"start\":128215},{\"end\":128230,\"start\":128228},{\"end\":128244,\"start\":128240},{\"end\":128252,\"start\":128250},{\"end\":128260,\"start\":128258},{\"end\":128266,\"start\":128262},{\"end\":129557,\"start\":129551},{\"end\":129580,\"start\":129570},{\"end\":129597,\"start\":129588},{\"end\":126267,\"start\":126231},{\"end\":126283,\"start\":126277},{\"end\":126298,\"start\":126292},{\"end\":126303,\"start\":126300},{\"end\":126662,\"start\":126653},{\"end\":126678,\"start\":126672},{\"end\":126693,\"start\":126686},{\"end\":126707,\"start\":126702},{\"end\":126724,\"start\":126719},{\"end\":127319,\"start\":127291},{\"end\":127328,\"start\":127323},{\"end\":127339,\"start\":127336},{\"end\":127353,\"start\":127347},{\"end\":127373,\"start\":127360},{\"end\":127380,\"start\":127375},{\"end\":127622,\"start\":127609},{\"end\":127639,\"start\":127632},{\"end\":127655,\"start\":127650},{\"end\":127669,\"start\":127663},{\"end\":127689,\"start\":127683},{\"end\":127704,\"start\":127697},{\"end\":127722,\"start\":127714},{\"end\":127738,\"start\":127731},{\"end\":127754,\"start\":127747},{\"end\":127764,\"start\":127756},{\"end\":127776,\"start\":127770},{\"end\":127795,\"start\":127787},{\"end\":127811,\"start\":127803},{\"end\":127823,\"start\":127818},{\"end\":127840,\"start\":127833},{\"end\":127855,\"start\":127848},{\"end\":127869,\"start\":127863},{\"end\":127886,\"start\":127881},{\"end\":127901,\"start\":127894},{\"end\":127916,\"start\":127908},{\"end\":127936,\"start\":127927},{\"end\":127944,\"start\":127942},{\"end\":127957,\"start\":127955},{\"end\":127966,\"start\":127963},{\"end\":127985,\"start\":127975},{\"end\":127997,\"start\":127994},{\"end\":128009,\"start\":128004},{\"end\":128023,\"start\":128017},{\"end\":128038,\"start\":128033},{\"end\":128052,\"start\":128046},{\"end\":128072,\"start\":128065},{\"end\":128090,\"start\":128082},{\"end\":128108,\"start\":128098},{\"end\":128125,\"start\":128119},{\"end\":128139,\"start\":128132},{\"end\":128152,\"start\":128149},{\"end\":128168,\"start\":128162},{\"end\":128183,\"start\":128178},{\"end\":128198,\"start\":128194},{\"end\":128207,\"start\":128203},{\"end\":128220,\"start\":128215},{\"end\":128230,\"start\":128228},{\"end\":128244,\"start\":128240},{\"end\":128252,\"start\":128250},{\"end\":128260,\"start\":128258},{\"end\":128266,\"start\":128262},{\"end\":129557,\"start\":129551},{\"end\":129580,\"start\":129570},{\"end\":129597,\"start\":129588}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":199501779},\"end\":126561,\"start\":126138},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b1\",\"matched_paper_id\":214612476},\"end\":127259,\"start\":126563},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":1935},\"end\":127597,\"start\":127261},{\"attributes\":{\"id\":\"b3\"},\"end\":129496,\"start\":127599},{\"attributes\":{\"id\":\"b4\"},\"end\":129739,\"start\":129498},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":199501779},\"end\":126561,\"start\":126138},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b1\",\"matched_paper_id\":214612476},\"end\":127259,\"start\":126563},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":1935},\"end\":127597,\"start\":127261},{\"attributes\":{\"id\":\"b3\"},\"end\":129496,\"start\":127599},{\"attributes\":{\"id\":\"b4\"},\"end\":129739,\"start\":129498}]", "bib_title": "[{\"end\":126223,\"start\":126138},{\"end\":126641,\"start\":126563},{\"end\":127289,\"start\":127261},{\"end\":126223,\"start\":126138},{\"end\":126641,\"start\":126563},{\"end\":127289,\"start\":127261}]", "bib_author": "[{\"end\":126269,\"start\":126225},{\"end\":126285,\"start\":126269},{\"end\":126300,\"start\":126285},{\"end\":126305,\"start\":126300},{\"end\":126664,\"start\":126643},{\"end\":126680,\"start\":126664},{\"end\":126695,\"start\":126680},{\"end\":126709,\"start\":126695},{\"end\":126726,\"start\":126709},{\"end\":127321,\"start\":127291},{\"end\":127330,\"start\":127321},{\"end\":127341,\"start\":127330},{\"end\":127355,\"start\":127341},{\"end\":127375,\"start\":127355},{\"end\":127382,\"start\":127375},{\"end\":127624,\"start\":127599},{\"end\":127641,\"start\":127624},{\"end\":127657,\"start\":127641},{\"end\":127671,\"start\":127657},{\"end\":127691,\"start\":127671},{\"end\":127706,\"start\":127691},{\"end\":127724,\"start\":127706},{\"end\":127740,\"start\":127724},{\"end\":127756,\"start\":127740},{\"end\":127766,\"start\":127756},{\"end\":127778,\"start\":127766},{\"end\":127797,\"start\":127778},{\"end\":127813,\"start\":127797},{\"end\":127825,\"start\":127813},{\"end\":127842,\"start\":127825},{\"end\":127857,\"start\":127842},{\"end\":127871,\"start\":127857},{\"end\":127888,\"start\":127871},{\"end\":127903,\"start\":127888},{\"end\":127918,\"start\":127903},{\"end\":127938,\"start\":127918},{\"end\":127946,\"start\":127938},{\"end\":127959,\"start\":127946},{\"end\":127968,\"start\":127959},{\"end\":127987,\"start\":127968},{\"end\":127999,\"start\":127987},{\"end\":128011,\"start\":127999},{\"end\":128025,\"start\":128011},{\"end\":128040,\"start\":128025},{\"end\":128054,\"start\":128040},{\"end\":128074,\"start\":128054},{\"end\":128092,\"start\":128074},{\"end\":128110,\"start\":128092},{\"end\":128127,\"start\":128110},{\"end\":128141,\"start\":128127},{\"end\":128154,\"start\":128141},{\"end\":128170,\"start\":128154},{\"end\":128185,\"start\":128170},{\"end\":128200,\"start\":128185},{\"end\":128209,\"start\":128200},{\"end\":128222,\"start\":128209},{\"end\":128232,\"start\":128222},{\"end\":128246,\"start\":128232},{\"end\":128254,\"start\":128246},{\"end\":128262,\"start\":128254},{\"end\":128268,\"start\":128262},{\"end\":129559,\"start\":129545},{\"end\":129582,\"start\":129559},{\"end\":129599,\"start\":129582},{\"end\":126269,\"start\":126225},{\"end\":126285,\"start\":126269},{\"end\":126300,\"start\":126285},{\"end\":126305,\"start\":126300},{\"end\":126664,\"start\":126643},{\"end\":126680,\"start\":126664},{\"end\":126695,\"start\":126680},{\"end\":126709,\"start\":126695},{\"end\":126726,\"start\":126709},{\"end\":127321,\"start\":127291},{\"end\":127330,\"start\":127321},{\"end\":127341,\"start\":127330},{\"end\":127355,\"start\":127341},{\"end\":127375,\"start\":127355},{\"end\":127382,\"start\":127375},{\"end\":127624,\"start\":127599},{\"end\":127641,\"start\":127624},{\"end\":127657,\"start\":127641},{\"end\":127671,\"start\":127657},{\"end\":127691,\"start\":127671},{\"end\":127706,\"start\":127691},{\"end\":127724,\"start\":127706},{\"end\":127740,\"start\":127724},{\"end\":127756,\"start\":127740},{\"end\":127766,\"start\":127756},{\"end\":127778,\"start\":127766},{\"end\":127797,\"start\":127778},{\"end\":127813,\"start\":127797},{\"end\":127825,\"start\":127813},{\"end\":127842,\"start\":127825},{\"end\":127857,\"start\":127842},{\"end\":127871,\"start\":127857},{\"end\":127888,\"start\":127871},{\"end\":127903,\"start\":127888},{\"end\":127918,\"start\":127903},{\"end\":127938,\"start\":127918},{\"end\":127946,\"start\":127938},{\"end\":127959,\"start\":127946},{\"end\":127968,\"start\":127959},{\"end\":127987,\"start\":127968},{\"end\":127999,\"start\":127987},{\"end\":128011,\"start\":127999},{\"end\":128025,\"start\":128011},{\"end\":128040,\"start\":128025},{\"end\":128054,\"start\":128040},{\"end\":128074,\"start\":128054},{\"end\":128092,\"start\":128074},{\"end\":128110,\"start\":128092},{\"end\":128127,\"start\":128110},{\"end\":128141,\"start\":128127},{\"end\":128154,\"start\":128141},{\"end\":128170,\"start\":128154},{\"end\":128185,\"start\":128170},{\"end\":128200,\"start\":128185},{\"end\":128209,\"start\":128200},{\"end\":128222,\"start\":128209},{\"end\":128232,\"start\":128222},{\"end\":128246,\"start\":128232},{\"end\":128254,\"start\":128246},{\"end\":128262,\"start\":128254},{\"end\":128268,\"start\":128262},{\"end\":129559,\"start\":129545},{\"end\":129582,\"start\":129559},{\"end\":129599,\"start\":129582}]", "bib_venue": "[{\"end\":126336,\"start\":126305},{\"end\":126798,\"start\":126730},{\"end\":127407,\"start\":127382},{\"end\":128286,\"start\":128268},{\"end\":129543,\"start\":129498},{\"end\":126336,\"start\":126305},{\"end\":126798,\"start\":126730},{\"end\":127407,\"start\":127382},{\"end\":128286,\"start\":128268},{\"end\":129543,\"start\":129498},{\"end\":126882,\"start\":126829},{\"end\":126882,\"start\":126829}]"}}}, "year": 2023, "month": 12, "day": 17}