{"id": 255894127, "updated": "2023-02-01 14:33:59.425", "metadata": {"title": "BGNN: Behavior-aware graph neural network for heterogeneous session-based recommendation", "authors": "[{\"first\":\"Jinwei\",\"last\":\"Luo\",\"middle\":[]},{\"first\":\"Mingkai\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Weike\",\"last\":\"Pan\",\"middle\":[]},{\"first\":\"Zhong\",\"last\":\"Ming\",\"middle\":[]}]", "venue": "Frontiers of Computer Science", "journal": "Frontiers of Computer Science", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Session-based recommendation (SBR) and multi-behavior recommendation (MBR) are both important problems and have attracted the attention of many researchers and practitioners. Different from SBR that solely uses one single type of behavior sequences and MBR that neglects sequential dynamics, heterogeneous SBR (HSBR) that exploits different types of behavioral information (e.g., examinations like clicks or browses, purchases, adds-to-carts and adds-to-favorites) in sequences is more consistent with real-world recommendation scenarios, but it is rarely studied. Early efforts towards HSBR focus on distinguishing different types of behaviors or exploiting homogeneous behavior transitions in a sequence with the same type of behaviors. However, all the existing solutions for HSBR do not exploit the rich heterogeneous behavior transitions in an explicit way and thus may fail to capture the semantic relations between different types of behaviors. However, all the existing solutions for HSBR do not model the rich heterogeneous behavior transitions in the form of graphs and thus may fail to capture the semantic relations between different types of behaviors. The limitation hinders the development of HSBR and results in unsatisfactory performance. As a response, we propose a novel behavior-aware graph neural network (BGNN) for HSBR. Our BGNN adopts a dual-channel learning strategy for differentiated modeling of two different types of behavior sequences in a session. Moreover, our BGNN integrates the information of both homogeneous behavior transitions and heterogeneous behavior transitions in a unified way. We then conduct extensive empirical studies on three real-world datasets, and find that our BGNN outperforms the best baseline by 21.87%, 18.49%, and 37.16% on average correspondingly. A series of further experiments and visualization studies demonstrate the rationality and effectiveness of our BGNN. An exploratory study on extending our BGNN to handle more than two types of behaviors show that our BGNN can easily and effectively be extended to multi-behavior scenarios.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/fcsc/LuoHPM23", "doi": "10.1007/s11704-022-2100-y"}}, "content": {"source": {"pdf_hash": "eb661d48c44f5ae103dc74e103a7f160922e44e9", "pdf_src": "Springer", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "84a548ff56c47b0fa7c074f1c6d8c90f57ccffc4", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/eb661d48c44f5ae103dc74e103a7f160922e44e9.txt", "contents": "\nBGNN: Behavior-aware graph neural network for heterogeneous session-based recommendation\n\n\nJinwei Luo \nCollege of Computer Science and Software Engineering\nShenzhen University\n518060ShenzhenChina\n\nNational Engineering Laboratory for Big Data System Computing Technology\nShenzhen University\n518060ShenzhenChina\n\nMingkai He \nCollege of Computer Science and Software Engineering\nShenzhen University\n518060ShenzhenChina\n\nNational Engineering Laboratory for Big Data System Computing Technology\nShenzhen University\n518060ShenzhenChina\n\nWeike Pan \nCollege of Computer Science and Software Engineering\nShenzhen University\n518060ShenzhenChina\n\nNational Engineering Laboratory for Big Data System Computing Technology\nShenzhen University\n518060ShenzhenChina\n\nZhong Ming \nCollege of Computer Science and Software Engineering\nShenzhen University\n518060ShenzhenChina\n\nNational Engineering Laboratory for Big Data System Computing Technology\nShenzhen University\n518060ShenzhenChina\n\nBGNN: Behavior-aware graph neural network for heterogeneous session-based recommendation\n10.1007/s11704-022-2100-yHigher Education Press 2023session-based recommendationgraph neural networkheterogeneous behaviors\nSession-based recommendation (SBR) and multibehavior recommendation (MBR) are both important problems and have attracted the attention of many researchers and practitioners. Different from SBR that solely uses one single type of behavior sequences and MBR that neglects sequential dynamics, heterogeneous SBR (HSBR) that exploits different types of behavioral information (e.g., examinations like clicks or browses, purchases, adds-to-carts and adds-to-favorites) in sequences is more consistent with real-world recommendation scenarios, but it is rarely studied. Early efforts towards HSBR focus on distinguishing different types of behaviors or exploiting homogeneous behavior transitions in a sequence with the same type of behaviors. However, all the existing solutions for HSBR do not exploit the rich heterogeneous behavior transitions in an explicit way and thus may fail to capture the semantic relations between different types of behaviors. However, all the existing solutions for HSBR do not model the rich heterogeneous behavior transitions in the form of graphs and thus may fail to capture the semantic relations between different types of behaviors. The limitation hinders the development of HSBR and results in unsatisfactory performance. As a response, we propose a novel behavior-aware graph neural network (BGNN) for HSBR. Our BGNN adopts a dual-channel learning strategy for differentiated modeling of two different types of behavior sequences in a session. Moreover, our BGNN integrates the information of both homogeneous behavior transitions and heterogeneous behavior transitions in a unified way. We then conduct extensive empirical studies on three real-world datasets, and find that our BGNN outperforms the best baseline by 21.87%, 18.49%, and 37.16% on average correspondingly. A series of further experiments and visualization studies demonstrate the rationality and effectiveness of our BGNN. An exploratory study on extending our BGNN to handle more than two types of behaviors show that our BGNN can easily and effectively be extended to multibehavior scenarios.\n\nIntroduction\n\nIntelligent recommendation is a technology to alleviate the problem of information overload in this era of information explosion [1,2]. Session-based recommendation aims to recommend the next possible interacted item to a user based on the user's behavior sequence in the session, which has recently been a research hotspot [3,4].\n\nHowever, session-based recommendation solely uses a single type of behavior sequence of the user and often faces the problem of data sparsity, especially when the behavior is naturally sparse [5]. For example, in an e-commerce scenario, the company's ultimate goal is to guide users to purchase items for profit while the data of purchases is very rare. Using only purchase sequences for session-based recommendation would lead to unsatisfactory recommendation performance since users' interests are diverse while the data is sparse [5,6]. For instance, a user may purchase certain items for certain occasions (such as birthday and festivals), or purchase items for his/her family members, which are both not related to their recent purchases [7].\n\nFortunately, the behavior sequence of a session in a realworld e-commerce platform is often heterogeneous and composed of more than one type of behaviors, e.g., purchases and examinations, in which examinations can be clicks or browses. Therefore, we can exploit the more abundant information in the heterogeneous behavior sequence to improve the recommendation performance of predicting the target behaviors, i.e., purchases. We name this type of research problem as heterogeneous session-based recommendation (HSBR) and name the traditional session-based recommendation as homogeneous session-based recommendation in this paper. Although the researches on HSBR are relatively few, we argue that HSBR is more consistent with the setting of real-world scenarios and deserves more attention from the community.\n\nExisting works for HSBR can be classified into two categories, i.e., methods based on recurrent neural network (RNN) [8][9][10] and methods based on graph neural network (GNN) [5,6]. In addition, some researchers have used Transformer-based methods in modeling of multi-behavior sequences in CTR and CVR tasks [11,12]. For example, the RNN-based method RIB [10] uses the behavior embedding to distinguish the different types of behaviors in a heterogeneous session, and takes the concatenation of the item embedding and the behavior embedding as the input of a gate recurrent unit (GRU) layer. The GNN-based method M-SR [5] proposes to treat a heterogeneous behavior sequence as an item sequence and an operation (behavior type) sequence for separate modeling. Specifically, M-SR uses a GNN method to model the complex item transitions in the item sequence and uses a GRU layer to model the operation sequence, supposing that there are sequential dependencies between different behavior types. The other GNN-based method MGNN-SPred [6] constructs a global multi-relational item graph based on two types of homogeneous behavior sequences, i.e., examination sequences and purchase sequences, over all sessions, and uses a GNN method to enhance the learning of item representations. Although MGNN-SPred strengthens the learning of item representations by exploiting the homogeneous behavior transition information, its modeling of different types of behavior sequences is the same, resulting in examining and purchasing an item will get the same representation in the feature space (see the details in Section 5.2.4), which may limit the capability of the model.\n\nMore importantly, most of the existing methods for HSBR focus on either distinguishing different types of behaviors or exploiting homogeneous behavior transitions intra each type of behavior sequences, while ignoring the useful information of heterogeneous behavior transitions inter different types of behavior sequences. For example, a user usually examines items for comparison before making a purchase decision, where the transition between examinations like clicks or browses indicates similarity and the transition from examination to purchase may indicate a progressive relationship [3]. Therefore, exploiting the heterogeneous behavior transitions is essential for learning the semantic connections between different types of behaviors and achieving accurate recommendation.\n\nTo fill this gap in HSBR, we propose to construct two different global graphs, i.e., homogeneous behavior transition graph (HoBTG) and heterogeneous behavior transition graph (HeBTG), based on all sessions to exploit the behavior transition information from two aspects, i.e., homogeneous and heterogeneous behavior transitions, respectively. We further propose a novel method named behavior-aware graph neural network (BGNN) to fully leverage the knowledge in the two graphs, in which a dual-channel learning strategy is designed to focus more on the modeling of the auxiliary behavior sequences, i.e., the examination sequences in this paper. To be more specific, we regard HoBTG as a common graph for learning high-quality item representations for both the purchases and the examinations, and utilize HeBTG for modeling of the examinations, aiming to explicitly utilize the purchase-oriented semantic connections implicit in HeBTG. In our BGNN, we introduce a personalized item neighbor aggregator (PING), which personalizes the messages passing in HeBTG by considering the users' purchase preference when aggregating neighboring nodes. And we also design a representation gating (RNG) module to balance the two views of item representations of the examination sequence learned from the two graphs. Moreover, BGNN learns the two types of behavior sequence representations through a parallel softattention mechanism, and finally fuses them into the session representation.\n\nThe main contributions of our work are summarized as follows.\n\n\u2022 We propose to construct two kinds of graphs, i.e., HoBTG and HeBTG, to capture the information of homogeneous behavior transitions and heterogeneous behavior transitions, respectively. \u2022 We propose a novel solution named behavior-aware graph neural network (BGNN) based on a dual-channel learning strategy, in which the use of HeBTG in the auxiliary channel makes the contribution of the auxiliary sequences to the target sequences more clear. \u2022 We design a personalized item neighbor aggregator (PING) to personalize the messages passing in HeBTG when aggregating neighboring nodes. And we also introduce a representation gating (RNG) module to endow our BGNN with the capability of balancing the two views of item representations well. \u2022 The experimental results on three real-world datasets show that our BGNN outperforms the best baseline by a large margin, demonstrating the superiority of our method. The visualization studies further verify the rationality and significance of exploiting heterogeneous behavior transitions in our BGNN. We also conduct an exploratory study of extending our BGNN to deal with more than two types of behaviors, where the results indicate that our BGNN can be easily and effectively extended to multi-behavior scenarios.\n\n\nRelated work\n\n\nHomogeneous session-based recommendation\n\nThere are many types of methods for session-based recommendation to model users' interest and produce personalized recommendation. Neighborhood-based methods [13,14] are a kind of simple but effective type of approaches to generate personalized recommendation. Item-KNN [13] recommends the most similar items to the interacted items in users' current sessions. Compared with neighborhood-based methods, factorization-based methods have better generalization ability. Matrix factorization (MF) [15] regards the inner product of a user-specific latent vector and an itemspecific latent vector as the user's preference towards the item. FPMC [16] models the first-order Markov chains (MCs) on the basis of MF, which can capture the evolution of users' interests. Fossil [17] uses the items that a user has interacted with to represent the user, and also considers the most recent items to capture the short-term preference.\n\nWith the development of deep learning, recurrent neural network (RNN), as a neural structure that is good at capturing sequential patterns, has become a suitable choice for modeling sessions [18,19]. GRU4Rec [20] applies a gate recurrent unit (GRU) structure for session-based recommendation, which models users' preference step by step to capture the sequential patterns. DREAM [21] aggregates the items in each session through the pooling operation, and uses a recurrent architecture to model the dynamic representation of a user. However, the RNN-based methods do not emphasize users' main purposes in the current sessions. An attention-based method NARM [22] uses GRU to obtain the hidden state of each step and aggregates the representations of each step by an attention mechanism to obtain users' main purposes. STAMP [23] regards the most recent examination as users' local interest, and considers the relationship between the historical examinations and the most recent examination, so as to obtain users' overall interest. DIN [24] takes each candidate item as a query to give a history item different attention to extract the interest embedding that suits the current candidate item.\n\nRecently, more researchers focus on applying graph neural network (GNN) to session-based recommendation, because the data of session-based recommendation can be expressed in the form of a graph [25][26][27]. SR-GNN [25] uses a gated GNN (GGNN) to aggregate neighbor information to obtain graphbased item representations in the session graph, and then obtain the session representation by aggregating the item representations with an attention mechanism. FGNN [27] proposes a weighted graph attention layer to perform more effective information propagation on the weighted session graphs, which takes the weight of edges into consideration when aggregating neighbors. DHCN [28] and SHARE [29] propose to model a session as a hypergraph to capture beyondpairwise relations. There are also some works that incorporate other sessions into consideration when modeling the current session [30,31]. For example, GCE-GNN [31] constructs a local session graph and a global graph to learn two levels of item transitions, and then enrich the item representations through the GNN method.\n\nBesides, various deep learning techniques are also applied to sequential recommendation, where the difference between session-based recommendation and sequential recommendation is that the data of the former is from anonymous users and the sequences are relatively short [3]. For instance, convolutional neural network (CNN)-based methods such as Caser [32] and NextItNet [33] have been proposed to consider skip connections and transitions at union-level. Owing to the success of Transformer and the self-attention mechanism, SASRec [34] makes use of some self-attention modules to encode the sequential patterns in each sequence. BERT4Rec [35] borrows the idea of the cloze task in NLP and trains the model in a bidirectional manner. S3Rec [36] further proposes a series of pretext tasks to pretrain the model in a selfsupervised manner. Recently, some researchers also propose to leverage graph neural network in sequential recommendation [37,38].\n\n\nHeterogeneous session-based recommendation\n\nThe above homogeneous session-based recommendation methods solely use one single type of behavior sequences and may not match a real application scenario well. Although many researchers have conducted studies on heterogeneous recommendation without considering the sequential information [39][40][41][42][43][44][45][46], few of them pay attention to heterogeneous session-based recommendation.\n\nAs far as we know, there are only a few heterogeneous session-based recommendation methods, including RNNbased methods RLBL [8], RIB [10], BINN [9] and graphbased methods MKM-SR [5] and MGNN-SPred [6]. RLBL [8] uses a behavior-aware log bilinear (LBL) module and an RNN layer to obtain the session representation. RIB [10] concatenates a behavior embedding and an item embedding in the input layer to distinguish different types of behaviors, and uses a GRU to model the entire heterogeneous session. BINN [9] proposes a contextual long short-term memory (CLSTM) structure, which makes the model more suitable for heterogeneous session recommendation. However, methods based on recurrent neural network strictly follow the chronological order of behavior sequences to mine sequential patterns, and lack the ability to model the complex item transition patterns. In contrast, the graph neural network can aggregate the neighbor information through an aggregator to represent the nodes in a graph, and can also explore the high-order connectivity information by repeating the aggregation operation. MKM-SR [5] constructs a session graph from the item sequence of a session and obtains the item representations through a GGNN. In addition, it uses a GRU layer to model the operation (behavior type) sequence of a session to obtain the operation representation at each step. MKM-SR further introduces a multi-task learning framework to incorporate the rich item knowledge from a knowledge graph. MGNN-SPred [6] introduces a multi-relational item graph (MRIG) based on the examination sequences and purchase sequences in all sessions, to capture the global item-to-item relationships, and then obtains the representations of the examination sequences and purchase sequences by the learned embeddings of the nodes in the graph.\n\nAnother series of works utilize some Transformer-based methods to model heterogeneous behavior sequences in clickthrough rate (CTR) and conversion rate (CVR) prediction tasks in a multi-task learning paradigm [11,12]. DMT [11] proposes a deep interest Transformer to model each behaviorspecific sequence of items separately, where the decoder takes the target item as a query to extract the user's diverse interests. DMT also includes a multi-gate mixture of experts (MMoE) to jointly optimize multiple objectives and uses a bias deep neural network to reduce the bias. Taking both explicit and implicit feedback into consideration, DFN [12] proposes to interactively learn users' unbiased preferences for recommendation. The explicit feedback includes dislike sequences, and the implicit feedback includes click sequences and unclick sequences. By taking touch-interactive behaviors (e.g., taps and swips in the screen) into consideration, DIPN [47] proposes a hierarchical attention mechanism to fuse all the interactive behaviors.\n\nAmong the aforementioned HSBR methods, they model the relationship between different behaviors from two different perspectives. The first one is to directly model the behavior type sequences. For example, RIB [9] takes each behavior type embedding of each step as a part of the input of GRU and MKM-SR [5] directly uses a GRU layer to model the whole behavior type sequence. The advantage of this type of methods is that they can explicitly distinguish different behavior types, while the disadvantage is that they can only implicitly capture the transitions between different behaviors. The other is to divide a heterogeneous session into some behavior-specific item sub-sequences such as MGNN-SPred [6] and DMT [11]. For example, DMT [11] and MGNN-SPred [6] both learn the interests of different behavior-specific sequences and capture the relationship between different behaviors at the fusion layer, i.e., a gating module in MGNN-SPred and an MLP network in DMT. The merit of this type of methods is that they can explicitly learn the homogeneous behavior transitions intra each behavior-specific sequence while the disadvantage is that they only capture the relationship between behaviors in a coarse manner through an MLP structure with two behavior interest embedding and lose the fine-grained item-level information in sequences. As the most related method to ours, the representation of examining an item in MGNN-SPred is the same as that of purchasing the item, which may limit the capability of the model (see more details in Section 5.2.4). Notice that our BGNN falls into the second category of modeling the relationship between different behaviors. Notice that, we fill the gap by modeling both homogeneous and heterogeneous behavior transitions in the form of a graph and put them into use in the early itemlevel representation learning before the latter sequence-level fusion layer. Moreover, the visualization results show that our BGNN can learn the semantic relationships between different types of behaviors well.\n\nWe can see that there are relatively few heterogeneous session-based recommendation methods, although it is more in line with the real applications. In this paper, we further focus on the graph-based heterogeneous session recommendation problem and propose a novel solution called behavior-aware graph neural network (BGNN). As far as we know, we are the first to model heterogeneous behavior transitions in the form of a graph.\n\n\nPreliminaries\n\nIn this section, we formally define the studied problem, and then give the introduction of two types of behavior transition graphs.\n\n\nProblem definition\nS = {s}, s \u2208 {1, 2, . . . , |S|} s S V = {v}, v \u2208 {1, 2, . . . , |V|}\n\nGiven a set of sessions\n\n, where each session consists of a sequence of behaviors in chronological order. The behavior sequence of a session in a real-world ecommerce platform is often heterogeneous including both examinations and purchases, for which the studied problem is called heterogeneous session-based recommendation (HSBR). Our goal is to exploit the behavioral information in and recommend some likely-to-purchase items from the item set for each session. Notice that we regard the purchases as the target behaviors according to the recommendation goal and take the examinations as the auxiliary behaviors, in which examinations can be clicks or browses. We use two types of behavior sequences in the following model introduction section to align with MGNN-SPred [6], the most relevant work of our BGNN, and leave the extension of coping with more than two types of behavior sequences to Section 5.2.8.\n\n\nGraph construction\nE s = {e s 1 , e s 2 , . . . , e s |E s | } P s = { p s 1 , p s 2 , . . . , p s |P s | } e s i , p s i \u2208 V\nWe first divide each heterogeneous behavior session into two parts, including an examination sequence and a purchase sequence , where . Moreover, we propose to explore the behavior transition information from two different perspectives, i.e., intra homogeneous behavior sequence and inter heterogeneous behavior sequences. Specifically, we construct two different graphs, including a homogeneous behavior transition graph (HoBTG) and a heterogeneous behavior transition graph (HeBTG). HoBTG captures the information of homogeneous behavior transitions such as from examination to examination in an examination sequence and from purchase to purchase in a purchase sequence, and HeBTG captures the information of heterogeneous behavior transitions, i.e., a transition from examination to purchase in a session.\nG = (V, E) V E V e2e p2p p2p v 2 v 4 1 p2p v 2 v 4 (v, e2e, v \u2032 ) (v, p2p, v \u2032 ) (v, e2e, v \u2032 ) v \u2032 v (v, p2p, v \u2032 ) v \u2032 v\nInspired by [6], we construct an HoBTG , where is a set of nodes and denotes the edges of homogeneous behavior transitions. Specifically, we include the items of all sessions in the node set and construct the edges between two consecutive items with homogeneous behavior transitions, i.e., from examination to examination ( ) or from purchase to purchase ( ). We illustrate the graph construction process of HoBTG in Fig. 1(a). For example, we can see a transition from to in the purchase sequence of session , so we include a edge linking from node to node in HoBTG. In the end, HoBTG consists of two types of edges, i.e., and . Specifically, an edge means that a user examines item after examining item , and means that a user purchases item after purchasing item .G\n= (V,\u1ebc) (v, e2p, v \u2032 ) v \u2032 v e2p v 1 v 4 e2p 2\nAlthough HoBTG collects rich information about homogeneous behavior transitions, it ignores the information about heterogeneous behavior transitions between the examination sequence and the purchase sequence of the same session, which is crucial for discovering the complex semantic relations between different types of behaviors. To address this issue, we propose to construct a HeBTG and the graph construction process of HeBTG is illustrated in Fig. 1(b). Specifically, we construct the edges between two consecutive items with directional behavior transitions from examination to purchase. We denote an edge in HeBTG as , which means that a user purchases item after examining item . For example, we include an edge linking form node to node because there is an behavior transition between them in session . Notice that the reason we focus on the directional relation from examination to purchase instead of the versa is that we want to model the transitions from auxiliary behaviors to target behaviors, which is more in line with our goal of predicting purchase behaviors (i.e., recommend some likely-to-purchase items) and can make the p2e contribution of the auxiliary sequences to the target sequences more clear. We leave the extension of our BGNN that considering another heterogeneous behavior transition, i.e., , to Section 5.2.6 for discussion.\n\ne2p By restricting the two ends of a directed edge to be different types of behaviors, HeBTG can also be regarded as a pseudo-bipartite graph, in which each item node plays two roles, i.e., an examination and a purchase, to pass the different messages. In the end, HeBTG can be seen as a behavior-aware graph, which builds a bridge from the auxiliary behaviors to the target behaviors directly.\n\nFor each edge in HoBTG or HeBTG, we take the frequency of its occurrences in all sessions as its edge weight. Moreover, for each edge type of each node in HoBTG or HeBTG, we only keep a certain number of edges with the highest edge weight, which can greatly reduce the computational overhead and avoid the noise caused by the uninformative neighboring nodes.\n\n\nBehavior-aware graph neural network\n\nIn this section, we first give an overview of the proposed behavior-aware graph neural network (BGNN) which exploits both homogeneous and heterogeneous behavior transition information, and then describe each module of our BGNN in detail.\n\n\nOverview\n\nThe pipeline of our BGNN is illustrated in Fig. 2. In general, our BGNN adopts a dual-channel learning strategy for differentiated modeling of two different types of behavior sequences and pays more attention to the modeling of the auxiliary channel. Notice that each input session includes an examination sequence and a purchase sequence. We leave the extension of our BGNN dealing with more than two types of behaviors to Section 5.2.8.\n\nAdopting a dual-channel learning strategy, we feed the purchase sequence into the target channel (in the bottom left corner of Fig. 2) and feed the examination sequence into the auxiliary channel (in the upper left corner of Fig. 2). In the target channel, the purchase sequence is encoded into a sequence of item representations by a multi-layer GNN in HoBTG. While in the auxiliary channel, in addition to using the same method as that in the target channel to get the item representations of examinations, we further design a personalized multi-layer GNN that considers a user's purchase preference (green dotted line of Fig. 2) to learn a purchaseoriented (i.e., target-oriented) view of the item representations in HeBTG. We feed these two views of item representations into our representation gating module to obtain the final item representations of examinations. In the session representation learning part, a parallel soft-attention mechanism is employed to obtain the sequence representations of two types of behavior sequences. The final session representation is then generated by fusing the two sequence representations.\n\n\nTarget channel\n\nIn the target channel, we aim to propagate the information in HoBTG to learn high-quality item representations of the purchase sequence.\nv e2e p2p N out e2e (v) = {v \u2032 | (v, e2e, v \u2032 ) \u2208 E} N in e2e (v) = {v \u2032 | (v \u2032 , e2e, v) \u2208 E} N out p2p (v) = {v \u2032 | (v, p2p, v \u2032 ) \u2208 E} N in p2p (v) = {v \u2032 | (v \u2032 , p2p, v) \u2208 E}\nInspired by [6], we use graphSAGE with mean-aggregator [48] to learn the item representations due to its efficiency in our setting. There are four sets of homogeneous neighboring nodes for each node w.r.t. the outgoing/incoming neighboring nodes of / homogeneous behavior transitions, including , ,\n\n, and .\n\n\nv k\n\nFirstly, we separately aggregate four groups of neighboring nodes of node to obtain its four -order neighbor group representations via mean pooling as follows,\nh out e2e (v, k) = \u2211 v \u2032 \u2208N out e2e (v) h(v \u2032 , k \u2212 1) |N out e2e (v)| ,(1)h in e2e (v, k) = \u2211 v \u2032 \u2208N in e2e (v) h(v \u2032 , k \u2212 1) |N in e2e (v)| ,(2)h out p2p (v, k) = \u2211 v \u2032 \u2208N out p2p (v) h(v \u2032 , k \u2212 1) |N out p2p (v)| ,(3)h in p2p (v, k) = \u2211 v \u2032 \u2208N in p2p (v) h(v \u2032 , k \u2212 1) |N in p2p (v)| ,(4)h(v \u2032 , k \u2212 1) \u2208 R d\u00d71 (k \u2212 1) v \u2032 k v h(v, k) \u2208 R d\u00d71\nwhere denotes the -order representation of node . Secondly, the -order representation of target node , i.e., , is recursively updated as follows,\nh(v, k) =h(v, k \u2212 1) + h out e2e (v, k) + h in e2e (v, k) + h out p2p (v, k) + h in p2p (v, k),(5)\ne2e e2p p2p Fig. 1 Illustration of the graph construction process of homogeneous behavior transition graph (HoBTG) and heterogeneous BTG (HeBTG) from sessions with examinations and purchases. Notice that an examination behavior (or an examined item) in a session is marked in brown and a purchase behavior is marked in green, and , and denote transitions from examination to examination, from examination to purchase, and from purchase to purchase, respectively. (a) HoBTG;\n(b) HeBTG k h(v, 0) = m v \u2208 R d\u00d71 v\nwhere is the depth of GNN, and , i.e., the initial node representation is set as the embedding vector of item .\nP = {p 1 , p 2 , p 3 , . . . , p |P| } H p = [h k p 1 , h k p 2 , h k p 3 , . . . , h k p |P| ] \u2208 R d\u00d7|P| h k p i = h(p i , k) i = 1, 2, 3, . . . , |P|\nFinally, for a purchase sequence 1) , we can then obtain its representations , where , .\n\n\nAuxiliary channel\n\nIn the auxiliary channel, we have three parts, i.e., representation learning in HoBTG, representation learning in HeBTG and representation gating, for learning the final item representations of the examination sequence.\nE = {e 1 , e 2 , e 3 , . . . , e |E| } H e = [h k e 1 , h k e 2 , h k e 3 , . . . , h k e |E| ] \u2208 R d\u00d7|E| h k e i = h(e i , k) i = 1, 2, 3, . . . , |E|\nRepresentation learning in HoBTG. By exploiting homogeneous behavior transitions in HoBTG as that in the target channel, for an examination sequence in the auxiliary channel, we have , where , . H e Representation learning in HeBTG. Although the item representations of the examination sequence has already comprised of rich homogeneous behavior transition information from HoBTG, we argue that it is not appropriate and is also insufficient. On one hand, the representations learned in HoBTG are behavior agnostic. For example, given two identical item sequences with exchanges between examinations and purchases, HoBTG would pass exactly the same messages into the item nodes and then return exactly the same item representations, which is unreasonable, indicating that HoBTG cannot distinguish different types of behaviors. On the other hand, the representations learned in HoBTG neglect the semantic connections with the target behaviors, and thus may not capture the intention of a user well, which is also observed in our visualization studies (see Section 5.2.4). Therefore, we propose to learn purchase-oriented (i.e., targetoriented) item representations in HeBTG for an examination sequence.G\n= (V,\u1ebc) v e2p\nFirstly, according to HeBTG , we define two sets of behavior-aware neighboring nodes for each item node w.r.t. the outgoing/incoming nodes through the behavior transitions,\nN out e2p (v) = {v \u2032 | (v, e2p, v \u2032 ) \u2208\u1ebc},(6)N in e2p (v) = {v \u2032 | (v \u2032 , e2p, v) \u2208\u1ebc},(7)N out e2p (v) v N in e2p (v) v v\nwhere is the neighboring node set of node when it plays the role as an examination, and is the neighboring node set of node when it plays the role as a purchase. We can see that in our HeBTG a node with an examination behavior only connects nodes with a purchase behavior and vice versa.\n\nv Secondly, in order to personalize the information propagation in HeBTG, we propose a personalized item neighbor aggregator (PING) to adaptively adjust the contribution of different neighbors by considering a user's purchase preference captured in the purchase sequence representation. For example, given two sessions in which the examination sequences are identical while the purchase sequences are completely different (like the example in Fig. 1), our PING would adjust the contribution of different neighboring nodes and thus generate different item representations for these two identical examination sequences, which is helpful in representation learning. Specifically, we recursively aggregate and update the representation of a node with an examination  Fig. 2 The pipeline of our proposed behavior-aware graph neural network (BGNN). Firstly, an examination sequence and a purchase sequence are extracted from a session , which are then fed into the auxiliary channel and the target channel to learn the item representations of each sequence, respectively. Specifically, in the auxiliary channel, two views of item representations of the examination sequence, i.e., and , are learned in two different graphs, which are then integrated as the final item representations . Secondly, the two sequences of item representations are used to generate the representation of the examination sequence and the representation of the purchase sequence , respectively. Finally, the two sequence representations are fused to generate the session representation , which is then used for prediction 6 Front. Comput. Sci., 2023, 17 (5): 175336 s 1) Notice that we omit the superscript for brevity.\n\nbehavior in HeBTG as follows,\n\u03b1 k\u22121 v,v \u2032 =softmax(q \u22a4 0 \u03c3(W 1he (v, k \u2212 1) + W 2hp (v \u2032 , k \u2212 1) + W 3 p s )),(8)h e (v, k) =h e (v, k \u2212 1) + \u2211 v \u2032 \u2208N out e2p (v) \u03b1 k\u22121 v,v \u2032hp(v \u2032 , k \u2212 1),(9)h e (v, k) \u2208 R d\u00d71 k vh p (v \u2032 , k \u2212 1) \u2208 R d\u00d71 k \u2212 1 v \u2032 h e (v, 0) = m vhp (v, 0) = m v v \u03b1 k\u22121 v,v \u2032 v \u2032 v k \u2212 1 p s \u2208 R d\u00d71 s q 0 \u2208 R d\u00d71 W 1 , W 2 , W 3 \u2208 R d\u00d7d \u03c3(\u00b7)\nwhere denotes the -order representation of node with an examination behavior, denotes the ( )-order representation of node with a purchase behavior. Notice that , , i.e., the initial node representation is set as the embedding vector of item . And is an attention value representing the contribution of a neighboring node for a target node at the ( )th layer, denotes the purchase sequence representation of session (see the details in Section 4.4), , are projection matrices, and is the sigmoid function.\n\u03b1 k\u22121 v,v \u2032 s p s\nIn this way, the calculation of an attention value takes the purchase sequence representation of the current session , i.e., , into consideration, which enables personalizing the aggregation of the neighboring nodes in HeBTG.\n\nv Similarly, we aggregate and update the representation of node with a purchase behavior in HeBTG as follows,\n\u03b2 k\u22121 v,v \u2032 =softmax(q \u22a4 0 \u03c3(W 1hp (v, k \u2212 1) + W 2he (v \u2032 , k \u2212 1) + W 3 p s )),(10)h p (v, k) =h p (v, k \u2212 1) + \u2211 v \u2032 \u2208N in e2p (v) \u03b2 k\u22121 v,v \u2032he(v \u2032 , k \u2212 1),(11)\u03b2 k\u22121 v,v \u2032he (v, 0) = m vhp (v, 0) = m v e2p\nwhere is an attention value, and . Notice that when the messages are passed in HeBTG composed of edges, the node that acts as a purchase collects messages from the nodes that act as an examination (refer to Eqs. (10)\u2212(11)), and vice versa (refer to Eqs. (8)\u2212(9)). \nk E = {e 1 , e 2 , e3 ,\u03b3 e = \u03c3 \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed q \u22a4 1 \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \u2211 |E| i=1 h k e i |E| , \u2211 |E| i=1h k e i |E| \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 ,(12)Z e = \u03b3 e \u00b7 H e + (1 \u2212 \u03b3 e ) \u00b7H e ,(13)[\u00b7, \u00b7] \u03c3(\u00b7) \u03b3 e q 1 \u2208 R 2d\u00d71 Z e \u2208 R d\u00d7|E|\nwhere denotes the concatenation operation, is the sigmoid function, denotes the balance scalar of two representation matrices of an examination sequence, is a trainable parameter, and is the fused representation matrix of an examination sequence. Instead of directly operating on two representation matrices like mean-pooling or max-pooling, our RNG uses the mean vector of two matrices to calculate the weights of two representation matrices, and takes the corresponding weighted sum of two representation matrices as the final representations of items.\n\n\nSession representation learning\nH p \u2208 R d\u00d7|P| Z e \u2208 R d\u00d7|E|\nThrough the target channel and the auxiliary channel, we can obtain two item representation matrices of a purchase sequence and an examination sequence, i.e., and , respectively. In this subsection, we describe how we learn the final session representation.\ns p s \u2208 R d\u00d71\nInspired by [23], we use a parallel soft-attention mechanism to calculate the examination sequence representation and purchase sequence representation in the same way but with different parameters. Specifically, we calculate the purchase sequence representation of session , i.e., , as follows,\natt i = softmax(q \u22a4 a \u03c3(W 4 h k p i + W 5 h k p |P| + W 6hp )),(14)p s = |P| \u2211 i=1 att i h k p i ,(15)h p = \u2211 |P| i=1 h k p i |P| H p q a \u2208 R d\u00d71 W 4 , W 5 W 6 \u2208 R d\u00d7d \u03c3(\u00b7)\nwhere is the mean vector of , ,\n\n, are trainable projection matrices and is again the sigmoid function. Similarly, given the item representations of an examination sequence , we have the examination sequence representation of session , i.e.,\n\n. We then employ a gating function to obtain the final representation of session as follows,\nr s = g \u00b7 e s + (1 \u2212 g) \u00b7 p s ,(16)g = \u03c3(q \u22a4 [e s , p s ]) q \u2208 R 2d\u00d71 where\n, and is a trainable parameter.\n\n\nPrediction i\n\nIn the end, the final prediction of item is calculated as follows,\n\u0177 i = softmax(r T s Wm i ),(17)W \u2208 R d\u00d7d m i i\nwhere is a trainable parameter, and is the item embedding of item . We then adopt the cross-entropy loss function to train the model,\nL(\u0177) = \u2212 |V| \u2211 i=1 y i log(\u0177 i ) + (1 \u2212 y i ) log(1 \u2212\u0177 i ),(18)y i \u2208 {0, 1}\ni where denotes the ground truth label of item .\n\n\nExperiments\n\nIn this section, we present the experimental settings and results to answer the following research questions (RQs).\n\n\u2022 RQ1) Does our BGNN achieve the state-of-the-art performance for the studied problem (i.e., HSBR)? \u2022 RQ2) What is the impact of the different components in our BGNN? In HSBR, we treat examinations as the auxiliary behaviors and regard purchases as the target behaviors, and preprocess these datasets as follows: 1) for the Tmall and UB datasets, due to the consideration of data volume, we retain the data of the first two months, and discard cold-start items that have fewer than 5 interactions; 2) for the Yoochoose dataset, we do not perform the above preprocessing in order to be consistent with [6]; 3) given a session with a purchase sequence and an examination sequence , we use a sliding window [23,25]  ); and 4) we take the corresponding examinations that occur before the label as the input of the examination sequence. If the examination sequence involves the label (i.e., item), then we only preserve the examination sequence until the label in order to predict new items [6].\n\nFor the Tmall and UB datasets, we use the first 1/3 of the last week's data as the validation data, the other 2/3 as the test data, and use the remaining data for training. While for the Yoochoose dataset, we use the first 6/7 of the dataset as the training data, 1/3 of the remaining data as the validation data and the rest as the test data [6]. The statistics of the processed datasets are shown in Table 1. The data, code and scripts used in the experiments are publicly available 3) for reproducibility and further extension.\n\n\nEvaluation metrics\n\nWe evaluate the recommendation performance via three commonly used ranking-oriented metrics, i.e., hit ratio (H@20), mean reciprocal rank (M@20) and normalized discounted cumulative gain (N@20). H@20 means the hit ratio of the target item in the top-20 recommendation list, while the M@20 and N@20 pay attention to the ranked positions of the items in each recommendation list.\n\n\nBaselines\n\nWe compare our BGNN with the following baselines, including some traditional, RNN-based, attention-based, Transformer-based, and GNN-based methods for both homogeneous and heterogeneous session-based recommendation.\n\n\u2022 POP is a basic method that always recommends the most popular items according to the popularity calculated in the training set. \u2022 ItemKNN [13] is a KNN-based method that recommends the most similar items in the current session. \u2022 GRU4Rec [20] is a pioneering method that applies recurrent neural network for session-based recommendation, which uses a GRU layer to encode the sequential information. \u2022 NARM [22] is a method that that uses GRU as the sequence encoder and uses an attention-based method to capture a user's local preference. \u2022 STAMP [23] is a method that uses an attention mechanism to learn the long-term and short-term preference of a user. \u2022 SR-GNN [25] is a pioneering method that models each individual sequence as a session graph and then learn the item representations through a gated GNN (GGNN) in the session graph. \u2022 GCE-GNN [31] is a state-of-the-art session-based recommendation method that constructs both a globallevel graph and a session-level graph to learn two levels of item transitions, and then enriches the item representation through a GNN method. \u2022 RIB [10] is an RNN-based method that takes the concatenation of the behavior embedding and the item embedding as the input of a GRU layer to encode the sequential information. 2) See tianchi.aliyun website 3) We will make all the data, code and scripts used in the experiments publicly available once the paper has been accepted.\n\n\u2022 M-SR [5] is a GNN-based method that uses a GGNN to model the sequences of items and uses a GRU layer to model the sequential patterns in the sequences of behaviors. Notice that M-SR is a reduced version of MKM-SR by removing the knowledge graph from the model. \u2022 DMT-trans [11] is a Transformer-based method that uses multiple deep interest Transformers to model different types of behavior sequences. Notice that DMT-trans is a reduced version of DMT where the MMoE part and bias deep neural network are removed. \u2022 MGNN-SPred [6] is a state-of-the-art method that builds a global multi-relational item graph based on two types of homogeneous behavior sequences, and further introduces a GNN method to enhance the representations of the items. \u2022 MGNN-SPred-W is an enhanced version of MGNN-SPred [6] provided by us, where MGNN-SPred-W changes the neighbor sampling method to only retain a certain number of edges with the highest weight.\n\n\nImplementation details\n\nWe implement all the baselines and our BGNN in TensorFlow and our BGNN is implemented based on the code of MGNN-SPred [6]. 4) For a fair comparison of all methods, we fix the embedding dimensionality to 64 and use the Xavier initialization [49] to initialize all the parameters. We optimize all the models with the Adam optimizer, use negative sampling with 20 negative samples during the training phase according to the released code of [6], set the batch size to 64 on Yoochoose and Tmall, and 256 on UB. We set the maximum number of epochs to 100 and adopt an early stopping strategy with a patience of 30, i.e., we stop training if the performance on H@20 on the validation data does not increase for 30 successive epochs. Moreover, we follow [6] and adopt the average length of the purchase sequences on different datasets (see Table 1) as the corresponding maximum\nL L = 3 L = 5 L = 7 {0.1, 0.2, ..., 0.9} {1, 2, 3} {1, 2, 3}\nlength of both types of behavior sequences [6], i.e., for Yoochoose, for Tmall and for UB. For homogeneous session-based recommendation methods, we follow [6] and use the original methods twice to model the purchase sequences and the examination sequences respectively, and finally use a gate function to fuse the two forms of sequence information to predict the next item. For example, in our implementation of GCE-GNN, we use the examination sequences and the purchase sequences to construct a global examination graph and a global purchase graph, respectively. For fair comparison, the hyper-parameters are tuned on the validation data following the suggestions from the original papers. For methods with dropout technique, we tune the dropout rate in range according to the original papers [11,20,22]. For GNN-based methods, we select the number of GNN layers from and report the best results [5,6,25]. Similarly for our BGNN, we fix the GNN depth in HoBTG to 2, and select the GNN depth in HeBTG from [5,6,25]. Moreover, following the suggestions from the original papers [6,31], for methods with global graphs, i.e., GCE-GNN, MGNN-SPred and our BGNN, we set the numbers of neighbors of each node w.r.t. each type of edge to 12, 5 and 5, respectively. For all the GNN-based methods, every item node's initial representation is set as the corresponding item embedding following the suggestions in the original papers [5,6,25,31].\n\n\nResults\n\n\nPerformance comparison (RQ1)\n\nWe report the experimental results of twelve baselines and our BGNN in Table 2, in which the best result of each column is marked in bold and the second best result is underlined.\n\nFor the two traditional methods, POP has the worst performance because it only recommends the most popular items for all users. By considering the similarities between items, ItemKNN performs better than POP.\n\nAmong the methods for homogeneous session-based 4) See GitHub website recommendation, we can see that: 1) GRU4Rec performs well on two short-sequence datasets, i.e., Yoochoose and Tmall, but performs poorly on the long-sequence dataset UB, indicating that GRU cannot effectively model relatively long sequences [25]. 2) NARM and STAMP beat GRU4Rec in most cases, which shows that the attention mechanism in them can help capture the user's main intention in session. 3) SR-GNN performs better than NARM and STAMP on Yoochoose and Tmall. By modeling each sequence as a graph, SR-GNN can capture more complicated item transitions. 4) Compared with other homogeneous session-based methods, GCE-GNN consistently performs the best on all the three datasets. This result indicates the effectiveness of constructing global graphs to exploit the information from other sessions to enhance the representation of items in the current session.\n\n\ne2e p2p\n\nAmong the methods for HSBR, we can observe that: 1) Although M-SR and RIB both use behavior embedding and RNN to distinguish different types of behaviors in a session, M-SR outperforms RIB, indicating that GGNN adopted in M-SR can leverage the rich item transition information. 2) DMT-trans performs better than M-SR on Yoochoose, showing that using the deep interest Transformers with the target item as the query to extract the user's diverse interest benefits the recommendation. 3) MGNN-SPred outperforms M-SR to a large extent, which shows that learning the homogeneous behavior transition information (i.e., and ) through a global graph can effectively enhance the item representations. It is worth mentioning that in our implementation of GCE-GNN, we use the examination sequences and the purchase sequences to construct a global examination graph and a global purchase graph, respectively, and thus it can capture the homogeneous behavior transition information. 4) MGNN-SPred-W surpasses MGNN-SPred in most cases, showcasing that our frequency-based sampling method of edges can avoid sampling some uninformative neighboring nodes.\n\nOur BGNN consistently achieves the best performance on all the three datasets compared with all the twelve baselines, which clearly demonstrates the superiority of our BGNN. Compared with the most competitive baseline MGNN-SPred-W, our method has an average improvement of 27.21%, 29.02%, and 23.67% in terms of H@20, M@20 and N@20 over the three datasets. Different from all the existing HSBR methods, our BGNN adopts a dual-channel learning strategy for differentiated modeling of different types of behavior sequences, and integrates the information of homogeneous behavior transitions, i.e., intra homogeneous behavior sequence, and the information of heterogeneous behavior transitions, i.e., inter heterogeneous behavior sequences, leading to consistently better performance.\n\n\nAblation study (RQ2)\n\nIn order to understand the contribution of different components to the performance of our BGNN, we conduct an ablation study and report the results in Table 3. We have the following observations. (i) By replacing the soft-attention module in our BGNN with a mean-pooling layer and removing all the modules that rely on HeBTG, i.e., BGNN (w/o s&HeBTG), our BGNN reduces to MGNN-SPred-W, i.e., the enhanced version of MGNN-SPred [6] provided by us. The improvement of BGNN (w/o s) over BGNN (w/o s&HeBTG), especially on Yoochoose there is a 15.6% improvement, indicates that constructing HeBTG to exploit the heterogeneous behavior transitions from auxiliary behaviors to target behaviors can benefit the recommendation performance. (ii) Comparing BGNN (w/o s&HeBTG) with BGNN (w/o HeBTG), we find that the scale of improvements on three datasets are data dependent. Specifically, the biggest improvement comes from the UB dataset with the longest sequences, while the smallest improvement from the Yoochoose dataset with the shortest sequences. These results show that the soft-attention mechanism is useful for our BGNN to capture users' local and global preference, especially when coping with long sequences. (iii) Comparing our BGNN with its variant BGNN (w/o RNG), i.e., the version of BGNN that replaces the RNG module with a mean-pooling layer, the performance decrease (especially with an 3.12% drop on Tmall) in most cases shows the usefulness of our RNG module in balancing two views of item representation matrices. (iv) Comparing BGNN (w/o PING) and BGNN, we find that BGNN without PING performs worse (especially with an 8.8% drop on Yoochoose) on all datasets, indicating that considering users' purchase preference when aggregating information in HeBTG can improve the performance of our BGNN. (v) Our BGNN performs the best compared with all of its variants on the Tmall and UB dataset, which clearly demonstrates the positive complementary effect of all the designed components in our BGNN.\n\n\nQuantitative study (RQ3) d K\n\nWe investigate the impact of two hyper-parameters in our BGNN, i.e., the embedding dimensionality and the number of GNN layers in HeBTG.\nd \u2208 {32, 64, 128} d = 128\nImpact of the embedding dimensionality. Specifically, we fix the number of GNN layers in HeBTG as 1, and consider the model with different embedding dimensionality . Notice that the results on M@20 and N@20 are similar and are not included due to space limitation. As shown in Fig. 3, with the increase of the embedding dimensionality, the performance of MGNN-SPred-W and our BGNN both improves overall. This is because the increase in the embedding dimensionality improves the representation capacity. For the Yoochoose dataset, we can see that when , the recommendation performance of MGNN-SPred-W improves while that of our BGNN decreases, which is likely caused by over-fitting of our BGNN since it is more complex in modeling of the heterogeneity of behaviors. We will study how to copy with this issue in the future. To sum up, our BGNN consistently outperforms MGNN-SPred-W with different values of the embedding dimensionality.\nK = 2\nImpact of the depth of GNN in HeBTG. By stacking different numbers of GNN layers, we investigate how the depth of GNN in HeBTG affects the performance of our BGNN. As shown in Fig. 4, we can see that on the UB and Yoochoose datasets, one GNN layer is sufficient for BGNN to perform well. While on the Tmall dataset, BGNN performs better when the number of layers is , indicating that learning the high-order connectivity of heterogeneous behavior transitions in HeBTG can further improve the performance.\n\n\nVisualization of item representations (RQ4)\n\ne2e p2p e2p\n\nWe visualize the representations of purchasing and examining an item to show the influence of utilizing heterogeneous behavior transitions. Specifically, we randomly select an item, i.e., 27260 in Yoochoose, and then use the trained MGNN-SPred-W and our BGNN to get the representation of examining the item and purchasing the item respectively, which are visualized in the Fig. 5. We can see that for MGNN-SPred-W, the representation of examining the item is the same as the representation of purchasing the item, which may limit the capability of the model. Notice that the results of MGNN-SPred is consistent across all items of all datasets and the reason is that MGNN-SPred models different types of behavior sequences in a same way, i.e., both examinations and purchases aggregate the same neighbor information from both the and edges. For our BGNN, we can see that examining and purchasing an item will get different representations in the feature space, showing that utilizing the heterogeneous behavior transitions in the modeling of examination sequence can help the model to distinguish different types of behaviors.\n\nMoreover, we visualize the representations of examinations and purchases to show whether our BGNN learns the semantic information of different types of behaviors. Specifically, we randomly select a target item in each dataset and retrieve the sessions that use the item as the label, and finally visualize the representations of examinations and purchases in these sessions, as well as that of the target item. Notice that the dimensionality of representations is 64, and thus we use the T-SNE [50] for visualization. For comparison, we also show the visualization of MGNN-SPred-W, which is the best baseline in our experiments. In the visualization for MGNN-SPred-W, we do not observe obvious patterns, and at the same time, we can again see that there are some overlaps between the representations of purchases and examinations. As shown in Fig. 6, we can find that for our BGNN: 1) the representations of examinations are gradually aggregated into the target item, which is reasonable since user's examinations before purchasing an item are more relevant; and 2) compared with the relatively tight distribution of the learned representations of examinations, the representations of purchases present a more dispersed state, which reflects the semantic difference between examinations and purchases.\n\n\nEfficiency (RQ5)\n\nWe evaluate the efficiency of our BGNN compared with some GNN-based methods. To make a fair comparision, we set the depth of GNNs to 1 and the embedding dimensionality as 64 for all the methods. All experiments are conducted on a single Tesla P100 GPU and in the same environment. We report the average training time per epoch in Table 4.\n\nFrom Table 4, we can observe that the running time of GCE-GNN is the longest, which is reasonable because it uses two more session-level graphs than MGNN-SPred and our BGNN, and the construction of session-level graphs is not completed in advance in the implementation of GCE-GNN [31]. Moreover, MGNN-SPred and our BGNN are much faster than GCE-GNN on all the three datasets since these two methods do not need session-level graphs and the global graphs are constructed and stored in advance. Comparing our  Previously, we model the target-oriented heterogeneous behavior transitions in our BGNN since exploiting makes the contribution of the auxiliary sequences to the target sequences more clear. However, the heterogeneous behavior transitions are also important for HSBR. For example, the purchase of an IPhone might indicate that we should not recommend similar items in the next step. In this subsection, we discuss the impact of adding to our BGNN and do some exploration of the behavior transitions. To introduce the transitions, we only need to make some modifications on the basis of our BGNN. Specifically, we need to build the edges from purchase to examination in the graph construction process of HeBTG, and then in the target channel, we need to add the representation learning in HeBTG and the representation gating for purchase sequences, which are in the same form as in the auxiliary channel but exploiting the transitions. We conduct the experiments on the three datasets and report the results in Table 5   p2e   p2e   e2p  p2e  e2p  p2e p2e\nd K = 1\nAs shown in Table 5, with the introduction of the transitions, BGNN++ improves BGNN on Tmall and UB, while the performance decreases on Yoochoose. The performance improvement of BGNN++ on Tmall and UB illustrates the effectiveness of mining heterogeneous behavior transitions . However, the performance degradation on Yoochoose is obvious and we observe that in UB and Tmall, the number of edges of and the number of edges of are close, while in Yoochoose, the number of edges of is 3.4 times the number of edges of . Therefore, we believe that the relative scarcity of the number of edges leads to the performance decrease of BGNN++ on Yoochoose.\n\n\nDiscussion\ne2e p2p e2p p2e\nIn heterogeneous sessions, different types of behavior transitions indicate different information. In this section, we explore and discuss the characteristics of both the homogeneous behavior transitions (i.e., and ) and the heterogeneous behavior transitions in HeBTG (i.e., and ). Specifically, for each type of transition edge, we count the total number of such edges and the number of edges whose end nodes (items) belong to the same category, and show the in-category ratio of the four types of behavior transitions on Tmall and UB in Fig. 7. It is worth mentioning that we do not explore Yoochoose because it does not contain well-defined category information. Moreover, the number of categories on Tmall is 1137, while that on UB is only 73.\n\nIt can be seen that in these two datasets, the in-category ratio e2e e2e p2p e2p p2e\n\nof the transitions is the highest among the four types of behavior transitions, indicating that the transitions largely represent a similar relationship between the two nodes. This is also in line with our intuition about user behavior patterns since a user usually examines some similar items for comparison before making a final purchase decision. In the Tmall dataset, only 20% of the transitions are transitions intra the same category, because users' purchase interests are diverse and can change sharply after their purchase demand is met [51]. As for the behavior transitions and , we can not get an obvious conclusion from the in-category ratio. This also shows that the complexity of the heterogeneous behavior transitions relative to the other two types of homogeneous behavior transitions. We can thus see that exploring the complex semantic relationship hidden in them is important for the heterogeneous session-based recommendation.\n\n\nExploratory study (RQ7)\n\nIn the following, we present how to extend our BGNN to scenarios with more than two types of behaviors, and study the effectiveness of our BGNN. We reprocessed the Tmall dataset so as to conduct the extended studies. Tmall dataset has two other auxiliary behaviors, i.e., adds-to-cart and adds-to-favorite, which are denoted as and for short, respectively. Our BGNN can elegantly adapt to the sessions with multiple types of behaviors by stacking the auxiliary channels. Specifically, for HoBTG that is shared in each channel, we construct the homogeneous behavior transition edges, i.e., , , , , within all the behavior sequences. Furthermore, we construct the unique HeBTG of each auxiliary channel to take advantage of the heterogeneous behavior transitions that are directed to the target behaviors, i.e., , and . Different from MGNN-SPred that solely utilizes a single GNN on a common global graph to enrich the item representations of different types of behavior sequences, our BGNN differs in modeling different auxiliary behaviors and target behaviors, presenting an architecture in which different types of auxiliary behaviors direct to the same type of target behavior. We report the relevant results in Table 6. We can see that our BGNN surpasses MGNN-SPred-W on H@20, M@20 and N@20 by 11.82%, 25.78%, and 19.38%, respectively, which clearly demonstrates the superiority of our BGNN in dealing with multi-behavior sessions.\n\n\nConclusions and future work\n\nIn this work, we study the problem of heterogeneous sessionbased recommendation (HSBR) that exploits different behavioral information in sessions, which is different from session-based recommendation (SBR) that solely uses one single type of behavior sequences and multi-behavior recommendation (MBR) that neglects sequential dynamics. In order to fully make use of the rich information in behavior transitions, we construct a new heterogeneous behavior transition graph (HeBTG) besides the homogeneous behavior transition graph (HoBTG). We then further propose a novel behavior-aware graph neural network (BGNN) that can integrate the information of the homogeneous and heterogeneous behavior transitions when modeling examination sequences (auxiliary sequences) by utilizing GNN methods to learn two views of item representations in HoBTG and HeBTG. Moreover, we conduct extensive experiments on three realword datasets, where the results clearly demonstrate the superiority of our BGNN and the benefit of exploiting heterogeneous behavior transitions. The visualization studies demonstrate the rationality of our BGNN and the exploratory study also shows the effectiveness of our BGNN when coping with more than two types of behaviors in HSBR. For future works, we are interested in studying personalized heterogeneous behavior transitions in fine-grained sessionlevel graphs. We also plan to construct time-evolving behavior transition graphs in order to learn users' short-term preference more accurately.  papers in AIJ, TBD, TIIS, TIST, TKDE,  TOIS, AAAI, CIKM, IJCAI, RecSys, SDM, SIGIR, WSDM, etc. Zhong Ming received the PhD degree in Computer Science and Technology from the Sun Yat-Sen University, China in 2003. He is currently a professor with the College of Computer Science and Software Engineering, Shenzhen University, China. His research interests include software engineering and artificial intelligence. He has published more than 200 refereed international conference and journal papers (including 40+ ACM/IEEE Transactions papers). He was the recipient of the ACM TiiS 2016 Best Paper Award and some other best paper awards. 16 Front. Comput. Sci., 2023, 17(5): 175336\n\n\nto generate the inputs of purchase sequences and labels, i.e., ([ ], ), ([ ], ),...,([ ,..., ],\n\nFig. 3 Fig. 4\n34Recommendation performance (H@20(%)) of MGNN-SPred-W and our BGNN with different values of on Tmall, Yoochoose and UB ( Recommendation performance (H@20(%)) of our BGNN with different numbers of GNN layers, i.e., , on Tmall, Yoochoose and UB BGNN with MGNN-SPred, we can see that the average training time of our BGNN is about 1.4 times of that of MGNN-SPred. This level of increase in training time is acceptable considering the performance improvement.\n\nFig. 5\n5Visualization of the representations of purchasing and examining item 27260 in Yoochoose produced by MGNN-SPred-W and our BGNN Fig. 6 Visualization of the representations of examinations and purchases in the sessions with the same target item produced by MGNN-SPred-W and our BGNN on Tmall, Yoochoose and UB. (a) Tmall(MGNN-SPred-W); (b) Yoochoose(MGNN-SPred-W); (c) UB(MGNN-SPred-W); (d) Tmall(BGNN); (e) Yoochoose(BGNN); (f) UB(\n\n\nRepresentation gating. So far, for an examination sequence, we have item representations learned in both HoBTG and HeBTG. We can further balance these two views of item representations using our proposed representation gating (RNG) module as follows,. . . , e \n|E| }H \ne = [h k \n\ne \n\n1 ,h k \n\ne \n\n2 , \nh k \n\ne \n\n3 , . . . ,h k \n\ne \n\n|E| ] \u2208 R d\u00d7|E|hk \ne i =h e (e i , k) i = 1, 2, 3, . . . , |E| \n\nAfter extending our PING in HeBTG to layers, for an \nexamination sequence \n, we can obtain a \npurchase-oriented view of item representations \n, where \n, \n. \n\n\n\u2022 RQ3 )\nRQ3How do the dimensionality of embedding and the depth of GNN in HeBTG affect the performance of our BGNN? \u2022 RQ4) What are the rationality of our BGNN compared to MGNN-SPred? \u2022 RQ5) What is the efficiency of our BGNN compared with the relevant methods?p2e \n\n\u2022 RQ6) What is the impact of another heterogeneous \nbehavior transition, i.e., \n? \n\u2022 RQ7) How does our BGNN perform in scenarios with \nmore than two types of behaviors? \n\n5.1 Settings \n5.1.1 Datasets \nWe conduct experiments on three public real-world datasets in \ne-commerce scenarios, i.e., Tmall 2) , Yoochoose and User \nBehavior (UB) 2) . The Tmall dataset is an e-commerce dataset \nreleased at the IJCAI Competition 2015, the Yoochoose \ndataset comes from the RecSys'15 Challenge and the UB \ndataset comes from the IJCAI Competition 2016. These are all \ndatasets with heterogeneous behaviors, i.e., examinations and \npurchases. \n\nP = {p \n1 , p \n2 , p \n3 , . . . , p |P| }, |P| \u2a7e 2 \nE = {e \n1 , e \n2 , e \n3 , . . . , e \n|E| }, |E| \u2a7e 5 \n\np \n1 p \n\n2 \n\np \n1 , p \n2 p \n\n3 \n\np \n1 , p \n\n2 \n\np \n|P|\u22121 p \n\n|P| \n\n\n\nTable 1\n1Statistics of the processed datasets The specific year when the dataset was collected is not released.Tmall \nYoochoose \nUser Behavior \n\n\nTable 2\n2Recommendation performance of our BGNN and twelve baselines, including two traditional methods POP and ItemKNN, five homogeneous session-\nbased methods GRU4Rec, NARM, STAMP, SR-GNN and GCE-GNN, and five heterogeneous session-based methods RIB, M-SR, DMT-trans, MGNN-SPred \nand MGNN-SPred-W, on Tmall, Yoochoose and UB. Notice that the best results are marked in bold and the second best results are underlined \n\nMethod \nTmall \nYoochoose \nUser behavior \n\nH@20/% \nM@20/% \nN@20/% \nH@20/% \nM@20/% \nN@20/% \nH@20/% \nM@20/% \nN@20/% \nPOP \n0.917 \n0.462 \n0.560 \n0.708 \n0.139 \n0.266 \n1.508 \n1.263 \n1.314 \nItemKNN \n1.965 \n0.3393 \n0.682 \n8.748 \n2.374 \n3.767 \n2.309 \n0.5991 \n0.9626 \nGRU4Rec \n2.429 \n0.698 \n1.071 \n12.616 \n2.925 \n5.019 \n2.828 \n1.414 \n1.718 \nNARM \n2.541 \n0.736 \n1.124 \n12.110 \n2.806 \n4.808 \n3.591 \n1.518 \n1.967 \nSTAMP \n2.656 \n0.897 \n1.289 \n12.662 \n3.287 \n5.327 \n3.044 \n1.462 \n1.807 \nSR-GNN \n2.998 \n1.045 \n1.482 \n12.959 \n3.588 \n5.6341 \n2.941 \n1.502 \n1.817 \nGCE-GNN \n6.453 \n1.634 \n2.725 \n18.376 \n3.611 \n6.834 \n5.829 \n1.415 \n2.379 \nRIB \n2.421 \n0.641 \n1.024 \n12.203 \n2.751 \n4.779 \n2.511 \n1.464 \n1.689 \nM-SR \n3.419 \n1.171 \n1.669 \n11.485 \n3.399 \n5.169 \n4.708 \n1.462 \n2.168 \nDMT-trans \n3.153 \n1.024 \n1.489 \n13.534 \n3.309 \n5.523 \n3.802 \n1.249 \n1.803 \nMGNN-SPred \n5.701 \n1.789 \n2.655 \n14.417 \n3.406 \n5.79 \n5.206 \n1.775 \n2.517 \nMGNN-SPred-W \n6.175 \n2.028 \n3.945 \n16.111 \n4.166 \n6.771 \n5.638 \n1.843 \n2.668 \nBGNN \n8.691 \n2.918 \n4.205 \n19.167 \n5.267 \n8.322 \n8.952 \n2.913 \n4.235 \n\n\n\nTable 3\n3Recommendation performance (H@20(%)) of our BGNN with different architectures on Tmall, Yoochoose and UBArchitecture \nDataset \nTmall \nYoochoose \nUB \nBGNN (w/o s&HeBTG) \n6.175 \n16.111 \n5.638 \nBGNN (w/o s) \n6.858 \n18.631 \n5.965 \nBGNN (w/o HeBTG) \n8.368 \n17.974 \n8.799 \nBGNN (w/o PING) \n8.428 \n18.977 \n8.823 \nBGNN (w/o RNG) \n8.194 \n17.469 \n8.966 \nBGNN \n8.691 \n19.167 \n8.952 \n\n\n\nTable 4\n4Training time cost per epoch of GCE-GNN, MGNN-SPred and our BGNN on Tmall, Yoochoose and UB Recommendation performance of our BGNN and its variant BGNN++ that considers the behavior transitions . Notice that / represents the ratio of the number of edges of these two typesMethod \nTmall/s \nYoochoose/s \nUB/s \nGCE-GNN \n43 \n42 \n108 \nMGNN-SPred \n9 \n9 \n23 \nBGNN \n14 \n14 \n28 \n\n\n\n\nMingkai He received the MS degree in Software Engineering from Shenzhen University, China in 2022. He is currently an Engineer at Baidu, Shenzhen, China. His research interests include recommender systems and deep learning. He has published papers in FCS, TIST, INS, KDD, CIKM, and RecSys. Weike Pan received the PhD degree in Computer Science and Engineering from the Hong Kong University of Science and Technology, China in 2012. He is currently an associate professor with the College of Computer Science and Software Engineering, Shenzhen University, China. His research interests include transfer learning, federated learning, recommender systems and machine learning. He has published research\nFront. Comput. Sci., 2023, 17(5): 175336\nJinwei LUO et al. BGNN: Behavior-aware graph neural network for heterogeneous session-based recommendation\nFront. Comput. Sci., 2023, 17(5): 175336\nAcknowledgementsWe thank the support of the National Natural Science Foundation of China (Grant Nos. 62172283 and 61836005).ReferencesHu Y, Koren Y, Volinsky C. Collaborative filtering for implicit feedback datasets. In: Proceedings of the 8th IEEE International Conference on Data Mining. 2008, 263-272\nX He, L Liao, H Zhang, L Nie, X Hu, T S Chua, Proceedings of the 26th International Conference on World Wide Web. the 26th International Conference on World Wide WebHe X, Liao L, Zhang H, Nie L, Hu X, Chua T S. Neural collaborative filtering. In: Proceedings of the 26th International Conference on World Wide Web. 2017, 173-182\n\nA survey on session-based recommender systems. S Wang, L Cao, Y Wang, Q Z Sheng, M A Orgun, D Lian, ACM Computing Surveys. 20227154Wang S, Cao L, Wang Y, Sheng Q Z, Orgun M A, Lian D. A survey on session-based recommender systems. ACM Computing Surveys, 2022, 54(7): 154\n\nMulti-interest diversification for end-to-end sequential recommendation. W Chen, P Ren, F Cai, F Sun, M De Rijke, ACM Transactions on 4. Information System. 40120Chen W, Ren P, Cai F, Sun F, De Rijke M. Multi-interest diversification for end-to-end sequential recommendation. ACM Transactions on 4. Information System, 2021, 40(1): 20\n\nIncorporating user micro-behaviors and item knowledge into multi-task learning for session-based recommendation. W Meng, D Yang, Y Xiao, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020Meng W, Yang D, Xiao Y. Incorporating user micro-behaviors and item knowledge into multi-task learning for session-based recommendation. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020, 1091-1100\n\nBeyond clicks: modeling multi-relational item graph for session-based target behavior prediction. W Wen, W Zhang, S Liu, Q Liu, B Zhang, L Lin, H Zha, Proceedings of the Web Conference 2020. 2020. the Web Conference 2020. 2020Wen W, Zhang W, Liu S, Liu Q, Zhang B, Lin L, Zha H. Beyond clicks: modeling multi-relational item graph for session-based target behavior prediction. In: Proceedings of the Web Conference 2020. 2020, 3056-3062\n\nTime to shop for valentine's day: shopping occasions and sequential recommendation in E-commerce. J Wang, R Louca, D Hu, C Cellier, J Caverlee, L Hong, Proceedings of the 13th International Conference on Web Search and Data Mining. 2020. the 13th International Conference on Web Search and Data Mining. 2020Wang J, Louca R, Hu D, Cellier C, Caverlee J, Hong L. Time to shop for valentine's day: shopping occasions and sequential recommendation in E-commerce. In: Proceedings of the 13th International Conference on Web Search and Data Mining. 2020, 645-653\n\nMulti-behavioral sequential prediction with recurrent log-bilinear model. Q Liu, S Wu, L Wang, IEEE Transactions on Knowledge and Data Engineering. 296Liu Q, Wu S, Wang L. Multi-behavioral sequential prediction with recurrent log-bilinear model. IEEE Transactions on Knowledge and Data Engineering, 2017, 29(6): 1254-1267\n\nLearning from history and present: next-item recommendation via discriminatively exploiting user behaviors. Z Li, H Zhao, Q Liu, Z Huang, T Mei, E Chen, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningLi Z, Zhao H, Liu Q, Huang Z, Mei T, Chen E. Learning from history and present: next-item recommendation via discriminatively exploiting user behaviors. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2018, 1734-1743\n\nMicro behaviors: a new perspective in E-commerce recommender systems. M Zhou, Z Ding, J Tang, D Yin, Proceedings of the 11th ACM International Conference on Web Search and Data Mining. the 11th ACM International Conference on Web Search and Data MiningZhou M, Ding Z, Tang J, Yin D. Micro behaviors: a new perspective in E-commerce recommender systems. In: Proceedings of the 11th ACM International Conference on Web Search and Data Mining. 2018, 727-735\n\nDeep multifaceted transformers for multi-objective ranking in large-scale E-commerce recommender systems. Y Gu, Z Ding, S Wang, L Zou, Y Liu, D Yin, Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2020. the 29th ACM International Conference on Information & Knowledge Management. 2020Gu Y, Ding Z, Wang S, Zou L, Liu Y, Yin D. Deep multifaceted transformers for multi-objective ranking in large-scale E-commerce recommender systems. In: Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2020, 2493-2500\n\nDeep feedback network for recommendation. R Xie, C Ling, Y Wang, R Wang, F Xia, L Lin, Proceedings of the 29th International Joint Conference on Artificial Intelligence. the 29th International Joint Conference on Artificial Intelligence2020Xie R, Ling C, Wang Y, Wang R, Xia F, Lin L. Deep feedback network for recommendation. In: Proceedings of the 29th International Joint Conference on Artificial Intelligence. 2020, 2519-2525\n\nItem-based collaborative filtering recommendation algorithms. B Sarwar, G Karypis, J Konstan, J Riedl, Proceedings of the 10th International Conference on World Wide Web. the 10th International Conference on World Wide WebSarwar B, Karypis G, Konstan J, Riedl J. Item-based collaborative filtering recommendation algorithms. In: Proceedings of the 10th International Conference on World Wide Web. 2001, 285-295\n\nWhen recurrent neural networks meet the neighborhood for session-based recommendation. D Jannach, M Ludewig, Proceedings of the 11th ACM Conference on Recommender Systems. the 11th ACM Conference on Recommender SystemsJannach D, Ludewig M. When recurrent neural networks meet the neighborhood for session-based recommendation. In: Proceedings of the 11th ACM Conference on Recommender Systems. 2017, 306-310\n\nBayesian personalized ranking from implicit feedback. S Rendle, C Freudenthaler, Z Gantner, L Schmidt-Thieme, Bpr, Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence. the 25th Conference on Uncertainty in Artificial IntelligenceRendle S, Freudenthaler C, Gantner Z, Schmidt-Thieme L. BPR: Bayesian personalized ranking from implicit feedback. In: Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence. 2009, 452-461\n\nFactorizing personalized markov chains for next-basket recommendation. S Rendle, C Freudenthaler, L Schmidt-Thieme, Proceedings of the 19th International Conference on World Wide Web. the 19th International Conference on World Wide WebRendle S, Freudenthaler C, Schmidt-Thieme L. Factorizing personalized markov chains for next-basket recommendation. In: Proceedings of the 19th International Conference on World Wide Web. 2010, 811-820\n\nFusing similarity models with Markov chains for sparse sequential recommendation. R He, J Mcauley, Proceedings of the 16th IEEE International Conference on Data Mining. the 16th IEEE International Conference on Data MiningHe R, McAuley J. Fusing similarity models with Markov chains for sparse sequential recommendation. In: Proceedings of the 16th IEEE International Conference on Data Mining. 2016, 191-200\n\nSequential user-based recurrent neural network recommendations. T Donkers, B Loepp, J Ziegler, Proceedings of the 11th ACM Conference on Recommender Systems. the 11th ACM Conference on Recommender SystemsDonkers T, Loepp B, Ziegler J. Sequential user-based recurrent neural network recommendations. In: Proceedings of the 11th ACM Conference on Recommender Systems. 2017, 152-160\n\nPersonalizing session-based recommendations with hierarchical recurrent neural networks. M Quadrana, A Karatzoglou, B Hidasi, P Cremonesi, Proceedings of the 11th ACM Conference on Recommender Systems. the 11th ACM Conference on Recommender SystemsQuadrana M, Karatzoglou A, Hidasi B, Cremonesi P. Personalizing session-based recommendations with hierarchical recurrent neural networks. In: Proceedings of the 11th ACM Conference on Recommender Systems. 2017, 130-137\n\nSession-based recommendations with recurrent neural networks. B Hidasi, A Karatzoglou, L Baltrunas, D Tikk, Proceedings of the 4th International Conference on Learning Representations. the 4th International Conference on Learning RepresentationsHidasi B, Karatzoglou A, Baltrunas L, Tikk D. Session-based recommendations with recurrent neural networks. In: Proceedings of the 4th International Conference on Learning Representations. 2016\n\nA dynamic recurrent model for next basket recommendation. F Yu, Q Liu, S Wu, L Wang, T Tan, Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information 21. the 39th International ACM SIGIR Conference on Research and Development in Information 21Yu F, Liu Q, Wu S, Wang L, Tan T. A dynamic recurrent model for next basket recommendation. In: Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information 21.\n\nThe ratio of the two nodes of each type of edge that belong to the same category on Tmall and UB. (a) Tmall. Fig. 7 The ratio of the two nodes of each type of edge that belong to the same category on Tmall and UB. (a) Tmall;\n\n. Front. Comput. Sci. 20235175336Front. Comput. Sci., 2023, 17(5): 175336\n\nNeural attentive sessionbased recommendation. J Li, P Ren, Z Chen, Z Ren, T Lian, J Ma, Proceedings of 2017 ACM on Conference on Information and Knowledge Management. 2017 ACM on Conference on Information and Knowledge ManagementLi J, Ren P, Chen Z, Ren Z, Lian T, Ma J. Neural attentive session- based recommendation. In: Proceedings of 2017 ACM on Conference on Information and Knowledge Management. 2017, 1419-1428\n\nSTAMP: short-term attention/memory priority model for session-based recommendation. Q Liu, Y Zeng, R Mokhosi, H Zhang, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningLiu Q, Zeng Y, Mokhosi R, Zhang H. STAMP: short-term attention/memory priority model for session-based recommendation. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2018, 1831-1839\n\nDeep interest network for click-through rate prediction. G Zhou, X Zhu, C Song, Y Fan, H Zhu, X Ma, Y Yan, Jin J Li, H Gai, K , Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningZhou G, Zhu X, Song C, Fan Y, Zhu H, Ma X, Yan Y, Jin J Li H, Gai K. Deep interest network for click-through rate prediction. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2018, 1059-1068\n\nSession-based recommendation with graph neural networks. S Wu, Y Tang, Y Zhu, L Wang, X Xie, T Tan, Proceedings of the 33rd AAAI Conference on Artificial Intelligence. the 33rd AAAI Conference on Artificial Intelligence2019Wu S, Tang Y, Zhu Y, Wang L, Xie X, Tan T. Session-based recommendation with graph neural networks. In: Proceedings of the 33rd AAAI Conference on Artificial Intelligence. 2019, 346-353\n\nGraph contextualized self-attention network for session-based recommendation. C Xu, P Zhao, Y Liu, V S Sheng, J Xu, F Zhuang, J Fang, X Zhou, Proceedings of the 28th International Joint Conference on Artificial Intelligence. the 28th International Joint Conference on Artificial Intelligence2019Xu C, Zhao P, Liu Y, Sheng V S, Xu J, Zhuang F, Fang J, Zhou X. Graph contextualized self-attention network for session-based recommendation. In: Proceedings of the 28th International Joint Conference on Artificial Intelligence. 2019, 3940-3946\n\nRethinking the item order in session-based recommendation with graph neural networks. R Qiu, J Li, Z Huang, H Yin, Proceedings of the 28th ACM International Conference on Information and Knowledge Management. the 28th ACM International Conference on Information and Knowledge ManagementQiu R, Li J, Huang Z, Yin H. Rethinking the item order in session-based recommendation with graph neural networks. In: Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 2019, 579-588\n\nSelf-supervised hypergraph convolutional networks for session-based recommendation. X Xia, H Yin, J Yu, Q Wang, L Cui, X Zhang, Proceedings of the 35th AAAI Conference on Artificial Intelligence. the 35th AAAI Conference on Artificial Intelligence2021Xia X, Yin H, Yu J, Wang Q, Cui L, Zhang X. Self-supervised hypergraph convolutional networks for session-based recommendation. In: Proceedings of the 35th AAAI Conference on Artificial Intelligence. 2021, 4503-4518\n\nSession-based recommendation with hypergraph attention networks. J Wang, K Ding, Z Zhu, J Caverlee, Proceedings of 2021 SIAM International Conference on Data Mining. 2021 SIAM International Conference on Data MiningWang J, Ding K, Zhu Z, Caverlee J. Session-based recommendation with hypergraph attention networks. In: Proceedings of 2021 SIAM International Conference on Data Mining. 2021, 82-90\n\nGraph-enhanced multi-task learning of multi-level transition dynamics for session-based recommendation. C Huang, J Chen, L Xia, Y Xu, P Dai, Y Chen, L Bo, J Zhao, J Huang, Proceedings of the 35th AAAI Conference on Artificial Intelligence. the 35th AAAI Conference on Artificial Intelligence2021Huang C, Chen J, Xia L, Xu Y, Dai P, Chen Y, Bo L, Zhao J, Huang J X. Graph-enhanced multi-task learning of multi-level transition dynamics for session-based recommendation. In: Proceedings of the 35th AAAI Conference on Artificial Intelligence. 2021, 4123-4130\n\nGlobal context enhanced graph neural networks for session-based recommendation. Z Wang, W Wei, G Cong, X L Li, X L Mao, M Qiu, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020Wang Z, Wei W, Cong G, Li X L, Mao X L, Qiu M. Global context enhanced graph neural networks for session-based recommendation. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020, 169-178\n\nPersonalized top-N sequential recommendation via convolutional sequence embedding. J Tang, K Wang, Proceedings of the 11th ACM International Conference on Web Search and Data Mining. the 11th ACM International Conference on Web Search and Data MiningTang J, Wang K. Personalized top-N sequential recommendation via convolutional sequence embedding. In: Proceedings of the 11th ACM International Conference on Web Search and Data Mining. 2018, 565-573\n\nA simple convolutional generative network for next item recommendation. F Yuan, A Karatzoglou, I Arapakis, J M Jose, X He, Proceedings of the 12th ACM International Conference on Web Search and Data Mining. the 12th ACM International Conference on Web Search and Data MiningYuan F, Karatzoglou A, Arapakis I, Jose J M, He X. A simple convolutional generative network for next item recommendation. In: Proceedings of the 12th ACM International Conference on Web Search and Data Mining. 2019, 582-590\n\nSelf-attentive sequential recommendation. C K Wang, J Mcauley, Proceedings of 2018 IEEE International Conference on Data Mining. 2018 IEEE International Conference on Data MiningWang C K, McAuley J. Self-attentive sequential recommendation. In: Proceedings of 2018 IEEE International Conference on Data Mining. 2018, 197-206\n\nBERT4Rec: sequential recommendation with bidirectional encoder representations from transformer. F Sun, J Liu, J Wu, C Pei, X Lin, W Ou, P Jiang, Proceedings of the 28th ACM International Conference on Information and Knowledge Management. the 28th ACM International Conference on Information and Knowledge ManagementSun F, Liu J, Wu J, Pei C, Lin X, Ou W, Jiang P. BERT4Rec: sequential recommendation with bidirectional encoder representations from transformer. In: Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 2019, 1441-1450\n\nS3-Rec: self-supervised learning for sequential recommendation with mutual information maximization. K Zhou, H Wang, W X Zhao, Y Zhu, S Wang, F Zhang, Z Wang, J Wen, Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2020. the 29th ACM International Conference on Information & Knowledge Management. 2020Zhou K, Wang H, Zhao W X, Zhu Y, Wang S, Zhang F, Wang Z, Wen J R. S3-Rec: self-supervised learning for sequential recommendation with mutual information maximization. In: Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2020, 1893-1902\n\nMemory augmented graph neural networks for sequential recommendation. C Ma, L Ma, Y Zhang, J Sun, X Liu, M Coates, Proceedings of the 34th AAAI Conference on Artificial Intelligence. the 34th AAAI Conference on Artificial Intelligence2020Ma C, Ma L, Zhang Y, Sun J, Liu X, Coates M. Memory augmented graph neural networks for sequential recommendation. In: Proceedings of the 34th AAAI Conference on Artificial Intelligence. 2020, 5045-5052\n\nSequential recommendation with graph neural networks. J Chang, C Gao, Y Zheng, Y Hui, Y Niu, Y Song, Jin D Li, Y , Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2021. the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2021Chang J, Gao C, Zheng Y, Hui Y, Niu Y, Song Y, Jin D, Li Y. Sequential recommendation with graph neural networks. In: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2021, 378-387\n\nA survey on heterogeneous one-class collaborative filtering. X Chen, L Li, W Pan, Ming Z , ACM Transactions on Information Systems. 2020435Chen X, Li L, Pan W, Ming Z. A survey on heterogeneous one-class collaborative filtering. ACM Transactions on Information Systems, 2020, 38(4): 35\n\nBayesian personalized ranking with multi-channel user feedback. B Loni, R Pagano, M Larson, A Hanjalic, Proceedings of the 10th ACM Conference on Recommender Systems. the 10th ACM Conference on Recommender SystemsLoni B, Pagano R, Larson M, Hanjalic A. Bayesian personalized ranking with multi-channel user feedback. In: Proceedings of the 10th ACM Conference on Recommender Systems. 2016, 361-364\n\nNeural multi-task recommendation from multi-behavior data. C Gao, X He, D Gan, X Chen, F Feng, Y Li, T S Chua, Jin D , Proceedings of the 35th IEEE International Conference on Data Engineering. the 35th IEEE International Conference on Data EngineeringGao C, He X, Gan D, Chen X, Feng F, Li Y, Chua T S, Jin D. Neural multi-task recommendation from multi-behavior data. In: Proceedings of the 35th IEEE International Conference on Data Engineering. 2019, 1554-1557\n\nMulti-behavior recommendation with graph convolutional networks. B Jin, C Gao, X He, Jin D Li, Y , Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020Jin B, Gao C, He X, Jin D, Li Y. Multi-behavior recommendation with graph convolutional networks. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020, 659-668\n\nMultiplex behavioral relation learning for recommendation via memory augmented transformer network. L Xia, C Huang, Y Xu, P Dai, B Zhang, L Bo, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020Xia L, Huang C, Xu Y, Dai P, Zhang B, Bo L. Multiplex behavioral relation learning for recommendation via memory augmented transformer network. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020, 2397-2406\n\nEfficient heterogeneous collaborative filtering without negative sampling for recommendation. C Chen, M Zhang, Y Zhang, W Ma, Y Liu, S Ma, Proceedings of the 34th AAAI Conference on Artificial Intelligence. the 34th AAAI Conference on Artificial Intelligence2020Chen C, Zhang M, Zhang Y, Ma W, Liu Y, Ma S. Efficient heterogeneous collaborative filtering without negative sampling for recommendation. In: Proceedings of the 34th AAAI Conference on Artificial Intelligence. 2020, 19-26\n\nKnowledge-enhanced hierarchical graph transformer network for multibehavior recommendation. L Xia, C Huang, Y Xu, P Dai, X Zhang, H Yang, Pei J Bo, L , Proceedings of the 35th AAAI Conference on Artificial Intelligence. the 35th AAAI Conference on Artificial Intelligence2021Xia L, Huang C, Xu Y, Dai P, Zhang X, Yang H, Pei J, Bo L. Knowledge-enhanced hierarchical graph transformer network for multi- behavior recommendation. In: Proceedings of the 35th AAAI Conference on Artificial Intelligence. 2021, 4486-4493\n\nGraph heterogeneous multi-relational recommendation. C Chen, W Ma, M Zhang, Z Wang, X He, C Wang, Y Liu, S Ma, Proceedings of the 35th AAAI Conference on Artificial Intelligence. the 35th AAAI Conference on Artificial Intelligence2021Chen C, Ma W, Zhang M, Wang Z, He X, Wang C, Liu Y, Ma S. Graph heterogeneous multi-relational recommendation. In: Proceedings of the 35th AAAI Conference on Artificial Intelligence. 2021, 3958-3966\n\nBuying or browsing?: predicting real-time purchasing intent using attention-based deep network with multiple behavior. L Guo, L Hua, R Jia, B Zhao, X Wang, B Cui, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningGuo L, Hua L, Jia R, Zhao B, Wang X, Cui B. Buying or browsing?: predicting real-time purchasing intent using attention-based deep network with multiple behavior. In: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2019, 1984-1992\n\nInductive representation learning on large graphs. W L Hamilton, Ying R Leskovec, J , Proceedings of the 31st International Conference on Neural Information Processing Systems. the 31st International Conference on Neural Information Processing SystemsHamilton W L, Ying R, Leskovec J. Inductive representation learning on large graphs. In: Proceedings of the 31st International Conference on Neural Information Processing Systems. 2017, 1025-1035\n\nUnderstanding the difficulty of training deep feedforward neural networks. X Glorot, Y Bengio, Proceedings of the 13th International Conference on Artificial Intelligence and Statistics. the 13th International Conference on Artificial Intelligence and StatisticsGlorot X, Bengio Y. Understanding the difficulty of training deep feedforward neural networks. In: Proceedings of the 13th International Conference on Artificial Intelligence and Statistics. 2010, 249-256\n\nVisualizing data using t-SNE. L Van Der Maaten, G Hinton, Journal of Machine Learning Research. 986van der Maaten L, Hinton G. Visualizing data using t-SNE. Journal of Machine Learning Research, 2008, 9(86): 2579-2605\n\nToward dynamic user intention: temporal evolutionary effects of item relations in sequential recommendation. C Wang, W Ma, M Zhang, C Chen, Y Liu, S Ma, ACM Transactions on Information Systems. 39216Wang C, Ma W, Zhang M, Chen C, Liu Y, Ma S. Toward dynamic user intention: temporal evolutionary effects of item relations in sequential recommendation. ACM Transactions on Information Systems, 2021, 39(2): 16\n\nHis research interests include recommender systems and deep learning. Tkde Joca, Kdd Tist, Cikm , China in 2020. He is currently pursuing the MS degree with the College of Computer Science and Software Engineering. Shenzhen University, ChinaJinwei Luo received the BS degree in College of Mechatronics and Control Engineering from Shenzhen UniversityJinwei Luo received the BS degree in College of Mechatronics and Control Engineering from Shenzhen University, China in 2020. He is currently pursuing the MS degree with the College of Computer Science and Software Engineering, Shenzhen University, China. His research interests include recommender systems and deep learning. He has published papers in JOCA, TKDE, TIST, KDD, and CIKM.\n\nBGNN: Behavior-aware graph neural network for heterogeneous session-based recommendation. Luo Jinwei, Jinwei LUO et al. BGNN: Behavior-aware graph neural network for heterogeneous session-based recommendation\n", "annotations": {"author": "[{\"end\":311,\"start\":92},{\"end\":531,\"start\":312},{\"end\":750,\"start\":532},{\"end\":970,\"start\":751}]", "publisher": null, "author_last_name": "[{\"end\":102,\"start\":99},{\"end\":322,\"start\":320},{\"end\":541,\"start\":538},{\"end\":761,\"start\":757}]", "author_first_name": "[{\"end\":98,\"start\":92},{\"end\":319,\"start\":312},{\"end\":537,\"start\":532},{\"end\":756,\"start\":751}]", "author_affiliation": "[{\"end\":196,\"start\":104},{\"end\":310,\"start\":198},{\"end\":416,\"start\":324},{\"end\":530,\"start\":418},{\"end\":635,\"start\":543},{\"end\":749,\"start\":637},{\"end\":855,\"start\":763},{\"end\":969,\"start\":857}]", "title": "[{\"end\":89,\"start\":1},{\"end\":1059,\"start\":971}]", "venue": null, "abstract": "[{\"end\":3279,\"start\":1184}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3427,\"start\":3424},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3429,\"start\":3427},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3622,\"start\":3619},{\"end\":3624,\"start\":3622},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3822,\"start\":3819},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4163,\"start\":4160},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4165,\"start\":4163},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4373,\"start\":4370},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5307,\"start\":5304},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5310,\"start\":5307},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5314,\"start\":5310},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5366,\"start\":5363},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5368,\"start\":5366},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5501,\"start\":5497},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5504,\"start\":5501},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5548,\"start\":5544},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5810,\"start\":5807},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6222,\"start\":6219},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7441,\"start\":7438},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10652,\"start\":10648},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10655,\"start\":10652},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10764,\"start\":10760},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10987,\"start\":10983},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11133,\"start\":11129},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11261,\"start\":11257},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11607,\"start\":11603},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11610,\"start\":11607},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11624,\"start\":11620},{\"end\":11795,\"start\":11791},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":12074,\"start\":12070},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12240,\"start\":12236},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12452,\"start\":12448},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12805,\"start\":12801},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12809,\"start\":12805},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12813,\"start\":12809},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12826,\"start\":12822},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":13070,\"start\":13066},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":13283,\"start\":13279},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13298,\"start\":13294},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13494,\"start\":13490},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":13497,\"start\":13494},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":13524,\"start\":13520},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13958,\"start\":13955},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14041,\"start\":14037},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":14060,\"start\":14056},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":14222,\"start\":14218},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":14329,\"start\":14325},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":14430,\"start\":14426},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14630,\"start\":14626},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":14633,\"start\":14630},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":14973,\"start\":14969},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":14977,\"start\":14973},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":14981,\"start\":14977},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":14985,\"start\":14981},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":14989,\"start\":14985},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":14993,\"start\":14989},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":14997,\"start\":14993},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":15001,\"start\":14997},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15204,\"start\":15201},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15214,\"start\":15210},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":15224,\"start\":15221},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15258,\"start\":15255},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15277,\"start\":15274},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15287,\"start\":15284},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15399,\"start\":15395},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":15586,\"start\":15583},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16184,\"start\":16181},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16583,\"start\":16580},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17113,\"start\":17109},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17116,\"start\":17113},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17126,\"start\":17122},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17541,\"start\":17537},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":17850,\"start\":17846},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18147,\"start\":18144},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18240,\"start\":18237},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18639,\"start\":18636},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18652,\"start\":18648},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18675,\"start\":18671},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18694,\"start\":18691},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21416,\"start\":21413},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22628,\"start\":22625},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27757,\"start\":27754},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":27801,\"start\":27797},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":29620,\"start\":29618},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":33460,\"start\":33459},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":36398,\"start\":36394},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38419,\"start\":38416},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":38523,\"start\":38519},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":38526,\"start\":38523},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":38804,\"start\":38801},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":39153,\"start\":39150},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":39294,\"start\":39292},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":40112,\"start\":40108},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":40212,\"start\":40208},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":40380,\"start\":40376},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":40521,\"start\":40517},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":40640,\"start\":40636},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":40823,\"start\":40819},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":41064,\"start\":41060},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":41264,\"start\":41262},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":41397,\"start\":41394},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41666,\"start\":41662},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":41919,\"start\":41916},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":42188,\"start\":42185},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":42474,\"start\":42471},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":42597,\"start\":42593},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":42794,\"start\":42791},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43103,\"start\":43100},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43331,\"start\":43328},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":43443,\"start\":43440},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":44083,\"start\":44079},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":44086,\"start\":44083},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":44089,\"start\":44086},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":44185,\"start\":44182},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":44187,\"start\":44185},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":44190,\"start\":44187},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":44294,\"start\":44291},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":44296,\"start\":44294},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":44299,\"start\":44296},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":44365,\"start\":44362},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":44368,\"start\":44365},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":44709,\"start\":44706},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":44711,\"start\":44709},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":44714,\"start\":44711},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":44717,\"start\":44714},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":45467,\"start\":45463},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":48474,\"start\":48471},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":53379,\"start\":53375},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":54827,\"start\":54823},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":58176,\"start\":58172},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":62216,\"start\":62214}]", "figure": "[{\"attributes\":{\"id\":\"fig_2\"},\"end\":62355,\"start\":62258},{\"attributes\":{\"id\":\"fig_3\"},\"end\":62827,\"start\":62356},{\"attributes\":{\"id\":\"fig_5\"},\"end\":63267,\"start\":62828},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":63825,\"start\":63268},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":64901,\"start\":63826},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":65047,\"start\":64902},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":66525,\"start\":65048},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":66909,\"start\":66526},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":67291,\"start\":66910},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":67993,\"start\":67292}]", "paragraph": "[{\"end\":3625,\"start\":3295},{\"end\":4374,\"start\":3627},{\"end\":5185,\"start\":4376},{\"end\":6846,\"start\":5187},{\"end\":7630,\"start\":6848},{\"end\":9106,\"start\":7632},{\"end\":9169,\"start\":9108},{\"end\":10430,\"start\":9171},{\"end\":11410,\"start\":10490},{\"end\":12605,\"start\":11412},{\"end\":13682,\"start\":12607},{\"end\":14634,\"start\":13684},{\"end\":15075,\"start\":14681},{\"end\":16898,\"start\":15077},{\"end\":17933,\"start\":16900},{\"end\":19968,\"start\":17935},{\"end\":20398,\"start\":19970},{\"end\":20547,\"start\":20416},{\"end\":21552,\"start\":20665},{\"end\":22489,\"start\":21681},{\"end\":23381,\"start\":22613},{\"end\":24787,\"start\":23429},{\"end\":25183,\"start\":24789},{\"end\":25543,\"start\":25185},{\"end\":25820,\"start\":25583},{\"end\":26271,\"start\":25833},{\"end\":27406,\"start\":26273},{\"end\":27561,\"start\":27425},{\"end\":28040,\"start\":27742},{\"end\":28049,\"start\":28042},{\"end\":28216,\"start\":28057},{\"end\":28711,\"start\":28566},{\"end\":29284,\"start\":28811},{\"end\":29432,\"start\":29321},{\"end\":29673,\"start\":29585},{\"end\":29914,\"start\":29695},{\"end\":31269,\"start\":30067},{\"end\":31456,\"start\":31284},{\"end\":31866,\"start\":31579},{\"end\":33556,\"start\":31868},{\"end\":33587,\"start\":33558},{\"end\":34428,\"start\":33923},{\"end\":34672,\"start\":34447},{\"end\":34783,\"start\":34674},{\"end\":35259,\"start\":34995},{\"end\":36047,\"start\":35493},{\"end\":36367,\"start\":36110},{\"end\":36676,\"start\":36382},{\"end\":36881,\"start\":36850},{\"end\":37091,\"start\":36883},{\"end\":37185,\"start\":37093},{\"end\":37293,\"start\":37262},{\"end\":37376,\"start\":37310},{\"end\":37557,\"start\":37424},{\"end\":37682,\"start\":37634},{\"end\":37813,\"start\":37698},{\"end\":38805,\"start\":37815},{\"end\":39337,\"start\":38807},{\"end\":39737,\"start\":39360},{\"end\":39966,\"start\":39751},{\"end\":41385,\"start\":39968},{\"end\":42326,\"start\":41387},{\"end\":43223,\"start\":42353},{\"end\":44718,\"start\":43285},{\"end\":44940,\"start\":44761},{\"end\":45150,\"start\":44942},{\"end\":46084,\"start\":45152},{\"end\":47236,\"start\":46096},{\"end\":48019,\"start\":47238},{\"end\":50050,\"start\":48044},{\"end\":50219,\"start\":50083},{\"end\":51181,\"start\":50246},{\"end\":51692,\"start\":51188},{\"end\":51751,\"start\":51740},{\"end\":52879,\"start\":51753},{\"end\":54182,\"start\":52881},{\"end\":54541,\"start\":54203},{\"end\":56105,\"start\":54543},{\"end\":56761,\"start\":56114},{\"end\":57539,\"start\":56791},{\"end\":57625,\"start\":57541},{\"end\":58572,\"start\":57627},{\"end\":60034,\"start\":58600},{\"end\":62257,\"start\":60066}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":20638,\"start\":20569},{\"attributes\":{\"id\":\"formula_1\"},\"end\":21680,\"start\":21574},{\"attributes\":{\"id\":\"formula_2\"},\"end\":22612,\"start\":22490},{\"attributes\":{\"id\":\"formula_3\"},\"end\":23428,\"start\":23382},{\"attributes\":{\"id\":\"formula_4\"},\"end\":27741,\"start\":27562},{\"attributes\":{\"id\":\"formula_5\"},\"end\":28292,\"start\":28217},{\"attributes\":{\"id\":\"formula_6\"},\"end\":28364,\"start\":28292},{\"attributes\":{\"id\":\"formula_7\"},\"end\":28439,\"start\":28364},{\"attributes\":{\"id\":\"formula_8\"},\"end\":28511,\"start\":28439},{\"attributes\":{\"id\":\"formula_9\"},\"end\":28565,\"start\":28511},{\"attributes\":{\"id\":\"formula_10\"},\"end\":28810,\"start\":28712},{\"attributes\":{\"id\":\"formula_11\"},\"end\":29320,\"start\":29285},{\"attributes\":{\"id\":\"formula_12\"},\"end\":29584,\"start\":29433},{\"attributes\":{\"id\":\"formula_13\"},\"end\":30066,\"start\":29915},{\"attributes\":{\"id\":\"formula_14\"},\"end\":31283,\"start\":31270},{\"attributes\":{\"id\":\"formula_15\"},\"end\":31502,\"start\":31457},{\"attributes\":{\"id\":\"formula_16\"},\"end\":31546,\"start\":31502},{\"attributes\":{\"id\":\"formula_17\"},\"end\":31578,\"start\":31546},{\"attributes\":{\"id\":\"formula_18\"},\"end\":33672,\"start\":33588},{\"attributes\":{\"id\":\"formula_19\"},\"end\":33752,\"start\":33672},{\"attributes\":{\"id\":\"formula_20\"},\"end\":33922,\"start\":33752},{\"attributes\":{\"id\":\"formula_21\"},\"end\":34446,\"start\":34429},{\"attributes\":{\"id\":\"formula_22\"},\"end\":34869,\"start\":34784},{\"attributes\":{\"id\":\"formula_23\"},\"end\":34949,\"start\":34869},{\"attributes\":{\"id\":\"formula_24\"},\"end\":34994,\"start\":34949},{\"attributes\":{\"id\":\"formula_25\"},\"end\":35283,\"start\":35260},{\"attributes\":{\"id\":\"formula_26\"},\"end\":35411,\"start\":35283},{\"attributes\":{\"id\":\"formula_27\"},\"end\":35450,\"start\":35411},{\"attributes\":{\"id\":\"formula_28\"},\"end\":35492,\"start\":35450},{\"attributes\":{\"id\":\"formula_29\"},\"end\":36109,\"start\":36082},{\"attributes\":{\"id\":\"formula_30\"},\"end\":36381,\"start\":36368},{\"attributes\":{\"id\":\"formula_31\"},\"end\":36744,\"start\":36677},{\"attributes\":{\"id\":\"formula_32\"},\"end\":36779,\"start\":36744},{\"attributes\":{\"id\":\"formula_33\"},\"end\":36849,\"start\":36779},{\"attributes\":{\"id\":\"formula_34\"},\"end\":37221,\"start\":37186},{\"attributes\":{\"id\":\"formula_35\"},\"end\":37261,\"start\":37221},{\"attributes\":{\"id\":\"formula_36\"},\"end\":37408,\"start\":37377},{\"attributes\":{\"id\":\"formula_37\"},\"end\":37423,\"start\":37408},{\"attributes\":{\"id\":\"formula_38\"},\"end\":37621,\"start\":37558},{\"attributes\":{\"id\":\"formula_39\"},\"end\":37633,\"start\":37621},{\"attributes\":{\"id\":\"formula_40\"},\"end\":43284,\"start\":43224},{\"attributes\":{\"id\":\"formula_41\"},\"end\":50245,\"start\":50220},{\"attributes\":{\"id\":\"formula_42\"},\"end\":51187,\"start\":51182},{\"attributes\":{\"id\":\"formula_43\"},\"end\":56113,\"start\":56106},{\"attributes\":{\"id\":\"formula_44\"},\"end\":56790,\"start\":56775}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":39216,\"start\":39209},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":43193,\"start\":43186},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":44839,\"start\":44832},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":48202,\"start\":48195},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":54540,\"start\":54533},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":54555,\"start\":54548},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":56101,\"start\":56061},{\"end\":56133,\"start\":56126},{\"end\":59821,\"start\":59814},{\"end\":61672,\"start\":61578}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3293,\"start\":3281},{\"attributes\":{\"n\":\"2\"},\"end\":10445,\"start\":10433},{\"attributes\":{\"n\":\"2.1\"},\"end\":10488,\"start\":10448},{\"attributes\":{\"n\":\"2.2\"},\"end\":14679,\"start\":14637},{\"attributes\":{\"n\":\"3\"},\"end\":20414,\"start\":20401},{\"attributes\":{\"n\":\"3.1\"},\"end\":20568,\"start\":20550},{\"end\":20663,\"start\":20640},{\"attributes\":{\"n\":\"3.2\"},\"end\":21573,\"start\":21555},{\"attributes\":{\"n\":\"4\"},\"end\":25581,\"start\":25546},{\"attributes\":{\"n\":\"4.1\"},\"end\":25831,\"start\":25823},{\"attributes\":{\"n\":\"4.2\"},\"end\":27423,\"start\":27409},{\"end\":28055,\"start\":28052},{\"attributes\":{\"n\":\"4.3\"},\"end\":29693,\"start\":29676},{\"attributes\":{\"n\":\"4.4\"},\"end\":36081,\"start\":36050},{\"attributes\":{\"n\":\"4.5\"},\"end\":37308,\"start\":37296},{\"attributes\":{\"n\":\"5\"},\"end\":37696,\"start\":37685},{\"attributes\":{\"n\":\"5.1.2\"},\"end\":39358,\"start\":39340},{\"attributes\":{\"n\":\"5.1.3\"},\"end\":39749,\"start\":39740},{\"attributes\":{\"n\":\"5.1.4\"},\"end\":42351,\"start\":42329},{\"attributes\":{\"n\":\"5.2\"},\"end\":44728,\"start\":44721},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":44759,\"start\":44731},{\"end\":46094,\"start\":46087},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":48042,\"start\":48022},{\"attributes\":{\"n\":\"5.2.3\"},\"end\":50081,\"start\":50053},{\"attributes\":{\"n\":\"5.2.4\"},\"end\":51738,\"start\":51695},{\"attributes\":{\"n\":\"5.2.5\"},\"end\":54201,\"start\":54185},{\"attributes\":{\"n\":\"5.2.7\"},\"end\":56774,\"start\":56764},{\"attributes\":{\"n\":\"5.2.8\"},\"end\":58598,\"start\":58575},{\"attributes\":{\"n\":\"6\"},\"end\":60064,\"start\":60037},{\"end\":62370,\"start\":62357},{\"end\":62835,\"start\":62829},{\"end\":63834,\"start\":63827},{\"end\":64910,\"start\":64903},{\"end\":65056,\"start\":65049},{\"end\":66534,\"start\":66527},{\"end\":66918,\"start\":66911}]", "table": "[{\"end\":63825,\"start\":63520},{\"end\":64901,\"start\":64088},{\"end\":65047,\"start\":65014},{\"end\":66525,\"start\":65058},{\"end\":66909,\"start\":66640},{\"end\":67291,\"start\":67192}]", "figure_caption": "[{\"end\":62355,\"start\":62260},{\"end\":62827,\"start\":62373},{\"end\":63267,\"start\":62837},{\"end\":63520,\"start\":63270},{\"end\":64088,\"start\":63838},{\"end\":65014,\"start\":64912},{\"end\":66640,\"start\":66536},{\"end\":67192,\"start\":66920},{\"end\":67993,\"start\":67294}]", "figure_ref": "[{\"end\":23039,\"start\":23030},{\"end\":23886,\"start\":23877},{\"end\":25882,\"start\":25876},{\"end\":26406,\"start\":26400},{\"end\":26504,\"start\":26498},{\"end\":26904,\"start\":26897},{\"end\":28829,\"start\":28823},{\"end\":32317,\"start\":32311},{\"end\":32637,\"start\":32631},{\"end\":50529,\"start\":50523},{\"end\":51370,\"start\":51364},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":52132,\"start\":52126},{\"end\":53730,\"start\":53724},{\"end\":57337,\"start\":57331}]", "bib_author_first_name": "[{\"end\":68488,\"start\":68487},{\"end\":68494,\"start\":68493},{\"end\":68502,\"start\":68501},{\"end\":68511,\"start\":68510},{\"end\":68518,\"start\":68517},{\"end\":68524,\"start\":68523},{\"end\":68526,\"start\":68525},{\"end\":68865,\"start\":68864},{\"end\":68873,\"start\":68872},{\"end\":68880,\"start\":68879},{\"end\":68890,\"start\":68887},{\"end\":68901,\"start\":68898},{\"end\":68910,\"start\":68909},{\"end\":69163,\"start\":69162},{\"end\":69171,\"start\":69170},{\"end\":69178,\"start\":69177},{\"end\":69185,\"start\":69184},{\"end\":69192,\"start\":69191},{\"end\":69539,\"start\":69538},{\"end\":69547,\"start\":69546},{\"end\":69555,\"start\":69554},{\"end\":70153,\"start\":70152},{\"end\":70160,\"start\":70159},{\"end\":70169,\"start\":70168},{\"end\":70176,\"start\":70175},{\"end\":70183,\"start\":70182},{\"end\":70192,\"start\":70191},{\"end\":70199,\"start\":70198},{\"end\":70591,\"start\":70590},{\"end\":70599,\"start\":70598},{\"end\":70608,\"start\":70607},{\"end\":70614,\"start\":70613},{\"end\":70625,\"start\":70624},{\"end\":70637,\"start\":70636},{\"end\":71125,\"start\":71124},{\"end\":71132,\"start\":71131},{\"end\":71138,\"start\":71137},{\"end\":71482,\"start\":71481},{\"end\":71488,\"start\":71487},{\"end\":71496,\"start\":71495},{\"end\":71503,\"start\":71502},{\"end\":71512,\"start\":71511},{\"end\":71519,\"start\":71518},{\"end\":72048,\"start\":72047},{\"end\":72056,\"start\":72055},{\"end\":72064,\"start\":72063},{\"end\":72072,\"start\":72071},{\"end\":72540,\"start\":72539},{\"end\":72546,\"start\":72545},{\"end\":72554,\"start\":72553},{\"end\":72562,\"start\":72561},{\"end\":72569,\"start\":72568},{\"end\":72576,\"start\":72575},{\"end\":73066,\"start\":73065},{\"end\":73073,\"start\":73072},{\"end\":73081,\"start\":73080},{\"end\":73089,\"start\":73088},{\"end\":73097,\"start\":73096},{\"end\":73104,\"start\":73103},{\"end\":73517,\"start\":73516},{\"end\":73527,\"start\":73526},{\"end\":73538,\"start\":73537},{\"end\":73549,\"start\":73548},{\"end\":73954,\"start\":73953},{\"end\":73965,\"start\":73964},{\"end\":74330,\"start\":74329},{\"end\":74340,\"start\":74339},{\"end\":74357,\"start\":74356},{\"end\":74368,\"start\":74367},{\"end\":74813,\"start\":74812},{\"end\":74823,\"start\":74822},{\"end\":74840,\"start\":74839},{\"end\":75262,\"start\":75261},{\"end\":75268,\"start\":75267},{\"end\":75654,\"start\":75653},{\"end\":75665,\"start\":75664},{\"end\":75674,\"start\":75673},{\"end\":76060,\"start\":76059},{\"end\":76072,\"start\":76071},{\"end\":76087,\"start\":76086},{\"end\":76097,\"start\":76096},{\"end\":76502,\"start\":76501},{\"end\":76512,\"start\":76511},{\"end\":76527,\"start\":76526},{\"end\":76540,\"start\":76539},{\"end\":76938,\"start\":76937},{\"end\":76944,\"start\":76943},{\"end\":76951,\"start\":76950},{\"end\":76957,\"start\":76956},{\"end\":76965,\"start\":76964},{\"end\":77717,\"start\":77716},{\"end\":77723,\"start\":77722},{\"end\":77730,\"start\":77729},{\"end\":77738,\"start\":77737},{\"end\":77745,\"start\":77744},{\"end\":77753,\"start\":77752},{\"end\":78174,\"start\":78173},{\"end\":78181,\"start\":78180},{\"end\":78189,\"start\":78188},{\"end\":78200,\"start\":78199},{\"end\":78683,\"start\":78682},{\"end\":78691,\"start\":78690},{\"end\":78698,\"start\":78697},{\"end\":78706,\"start\":78705},{\"end\":78713,\"start\":78712},{\"end\":78720,\"start\":78719},{\"end\":78726,\"start\":78725},{\"end\":78735,\"start\":78732},{\"end\":78737,\"start\":78736},{\"end\":78743,\"start\":78742},{\"end\":78750,\"start\":78749},{\"end\":79235,\"start\":79234},{\"end\":79241,\"start\":79240},{\"end\":79249,\"start\":79248},{\"end\":79256,\"start\":79255},{\"end\":79264,\"start\":79263},{\"end\":79271,\"start\":79270},{\"end\":79666,\"start\":79665},{\"end\":79672,\"start\":79671},{\"end\":79680,\"start\":79679},{\"end\":79689,\"start\":79686},{\"end\":79698,\"start\":79697},{\"end\":79704,\"start\":79703},{\"end\":79714,\"start\":79713},{\"end\":79722,\"start\":79721},{\"end\":80215,\"start\":80214},{\"end\":80222,\"start\":80221},{\"end\":80228,\"start\":80227},{\"end\":80237,\"start\":80236},{\"end\":80727,\"start\":80726},{\"end\":80734,\"start\":80733},{\"end\":80741,\"start\":80740},{\"end\":80747,\"start\":80746},{\"end\":80755,\"start\":80754},{\"end\":80762,\"start\":80761},{\"end\":81176,\"start\":81175},{\"end\":81184,\"start\":81183},{\"end\":81192,\"start\":81191},{\"end\":81199,\"start\":81198},{\"end\":81613,\"start\":81612},{\"end\":81622,\"start\":81621},{\"end\":81630,\"start\":81629},{\"end\":81637,\"start\":81636},{\"end\":81643,\"start\":81642},{\"end\":81650,\"start\":81649},{\"end\":81658,\"start\":81657},{\"end\":81664,\"start\":81663},{\"end\":81672,\"start\":81671},{\"end\":82147,\"start\":82146},{\"end\":82155,\"start\":82154},{\"end\":82162,\"start\":82161},{\"end\":82172,\"start\":82169},{\"end\":82180,\"start\":82177},{\"end\":82187,\"start\":82186},{\"end\":82757,\"start\":82756},{\"end\":82765,\"start\":82764},{\"end\":83198,\"start\":83197},{\"end\":83206,\"start\":83205},{\"end\":83221,\"start\":83220},{\"end\":83235,\"start\":83232},{\"end\":83243,\"start\":83242},{\"end\":83670,\"start\":83667},{\"end\":83678,\"start\":83677},{\"end\":84049,\"start\":84048},{\"end\":84056,\"start\":84055},{\"end\":84063,\"start\":84062},{\"end\":84069,\"start\":84068},{\"end\":84076,\"start\":84075},{\"end\":84083,\"start\":84082},{\"end\":84089,\"start\":84088},{\"end\":84631,\"start\":84630},{\"end\":84639,\"start\":84638},{\"end\":84649,\"start\":84646},{\"end\":84657,\"start\":84656},{\"end\":84664,\"start\":84663},{\"end\":84672,\"start\":84671},{\"end\":84681,\"start\":84680},{\"end\":84689,\"start\":84688},{\"end\":85226,\"start\":85225},{\"end\":85232,\"start\":85231},{\"end\":85238,\"start\":85237},{\"end\":85247,\"start\":85246},{\"end\":85254,\"start\":85253},{\"end\":85261,\"start\":85260},{\"end\":85652,\"start\":85651},{\"end\":85661,\"start\":85660},{\"end\":85668,\"start\":85667},{\"end\":85677,\"start\":85676},{\"end\":85684,\"start\":85683},{\"end\":85691,\"start\":85690},{\"end\":85701,\"start\":85698},{\"end\":85703,\"start\":85702},{\"end\":85709,\"start\":85708},{\"end\":86241,\"start\":86240},{\"end\":86249,\"start\":86248},{\"end\":86255,\"start\":86254},{\"end\":86265,\"start\":86261},{\"end\":86267,\"start\":86266},{\"end\":86531,\"start\":86530},{\"end\":86539,\"start\":86538},{\"end\":86549,\"start\":86548},{\"end\":86559,\"start\":86558},{\"end\":86925,\"start\":86924},{\"end\":86932,\"start\":86931},{\"end\":86938,\"start\":86937},{\"end\":86945,\"start\":86944},{\"end\":86953,\"start\":86952},{\"end\":86961,\"start\":86960},{\"end\":86969,\"start\":86966},{\"end\":86979,\"start\":86976},{\"end\":86981,\"start\":86980},{\"end\":87397,\"start\":87396},{\"end\":87404,\"start\":87403},{\"end\":87411,\"start\":87410},{\"end\":87419,\"start\":87416},{\"end\":87421,\"start\":87420},{\"end\":87427,\"start\":87426},{\"end\":87982,\"start\":87981},{\"end\":87989,\"start\":87988},{\"end\":87998,\"start\":87997},{\"end\":88004,\"start\":88003},{\"end\":88011,\"start\":88010},{\"end\":88020,\"start\":88019},{\"end\":88619,\"start\":88618},{\"end\":88627,\"start\":88626},{\"end\":88636,\"start\":88635},{\"end\":88645,\"start\":88644},{\"end\":88651,\"start\":88650},{\"end\":88658,\"start\":88657},{\"end\":89103,\"start\":89102},{\"end\":89110,\"start\":89109},{\"end\":89119,\"start\":89118},{\"end\":89125,\"start\":89124},{\"end\":89132,\"start\":89131},{\"end\":89141,\"start\":89140},{\"end\":89151,\"start\":89148},{\"end\":89153,\"start\":89152},{\"end\":89159,\"start\":89158},{\"end\":89581,\"start\":89580},{\"end\":89589,\"start\":89588},{\"end\":89595,\"start\":89594},{\"end\":89604,\"start\":89603},{\"end\":89612,\"start\":89611},{\"end\":89618,\"start\":89617},{\"end\":89626,\"start\":89625},{\"end\":89633,\"start\":89632},{\"end\":90081,\"start\":90080},{\"end\":90088,\"start\":90087},{\"end\":90095,\"start\":90094},{\"end\":90102,\"start\":90101},{\"end\":90110,\"start\":90109},{\"end\":90118,\"start\":90117},{\"end\":90639,\"start\":90636},{\"end\":90654,\"start\":90650},{\"end\":90656,\"start\":90655},{\"end\":90668,\"start\":90667},{\"end\":91109,\"start\":91108},{\"end\":91119,\"start\":91118},{\"end\":91532,\"start\":91531},{\"end\":91550,\"start\":91549},{\"end\":91830,\"start\":91829},{\"end\":91838,\"start\":91837},{\"end\":91844,\"start\":91843},{\"end\":91853,\"start\":91852},{\"end\":91861,\"start\":91860},{\"end\":91868,\"start\":91867},{\"end\":92204,\"start\":92200},{\"end\":92214,\"start\":92211},{\"end\":92225,\"start\":92221},{\"end\":92960,\"start\":92957}]", "bib_author_last_name": "[{\"end\":68491,\"start\":68489},{\"end\":68499,\"start\":68495},{\"end\":68508,\"start\":68503},{\"end\":68515,\"start\":68512},{\"end\":68521,\"start\":68519},{\"end\":68531,\"start\":68527},{\"end\":68870,\"start\":68866},{\"end\":68877,\"start\":68874},{\"end\":68885,\"start\":68881},{\"end\":68896,\"start\":68891},{\"end\":68907,\"start\":68902},{\"end\":68915,\"start\":68911},{\"end\":69168,\"start\":69164},{\"end\":69175,\"start\":69172},{\"end\":69182,\"start\":69179},{\"end\":69189,\"start\":69186},{\"end\":69201,\"start\":69193},{\"end\":69544,\"start\":69540},{\"end\":69552,\"start\":69548},{\"end\":69560,\"start\":69556},{\"end\":70157,\"start\":70154},{\"end\":70166,\"start\":70161},{\"end\":70173,\"start\":70170},{\"end\":70180,\"start\":70177},{\"end\":70189,\"start\":70184},{\"end\":70196,\"start\":70193},{\"end\":70203,\"start\":70200},{\"end\":70596,\"start\":70592},{\"end\":70605,\"start\":70600},{\"end\":70611,\"start\":70609},{\"end\":70622,\"start\":70615},{\"end\":70634,\"start\":70626},{\"end\":70642,\"start\":70638},{\"end\":71129,\"start\":71126},{\"end\":71135,\"start\":71133},{\"end\":71143,\"start\":71139},{\"end\":71485,\"start\":71483},{\"end\":71493,\"start\":71489},{\"end\":71500,\"start\":71497},{\"end\":71509,\"start\":71504},{\"end\":71516,\"start\":71513},{\"end\":71524,\"start\":71520},{\"end\":72053,\"start\":72049},{\"end\":72061,\"start\":72057},{\"end\":72069,\"start\":72065},{\"end\":72076,\"start\":72073},{\"end\":72543,\"start\":72541},{\"end\":72551,\"start\":72547},{\"end\":72559,\"start\":72555},{\"end\":72566,\"start\":72563},{\"end\":72573,\"start\":72570},{\"end\":72580,\"start\":72577},{\"end\":73070,\"start\":73067},{\"end\":73078,\"start\":73074},{\"end\":73086,\"start\":73082},{\"end\":73094,\"start\":73090},{\"end\":73101,\"start\":73098},{\"end\":73108,\"start\":73105},{\"end\":73524,\"start\":73518},{\"end\":73535,\"start\":73528},{\"end\":73546,\"start\":73539},{\"end\":73555,\"start\":73550},{\"end\":73962,\"start\":73955},{\"end\":73973,\"start\":73966},{\"end\":74337,\"start\":74331},{\"end\":74354,\"start\":74341},{\"end\":74365,\"start\":74358},{\"end\":74383,\"start\":74369},{\"end\":74388,\"start\":74385},{\"end\":74820,\"start\":74814},{\"end\":74837,\"start\":74824},{\"end\":74855,\"start\":74841},{\"end\":75265,\"start\":75263},{\"end\":75276,\"start\":75269},{\"end\":75662,\"start\":75655},{\"end\":75671,\"start\":75666},{\"end\":75682,\"start\":75675},{\"end\":76069,\"start\":76061},{\"end\":76084,\"start\":76073},{\"end\":76094,\"start\":76088},{\"end\":76107,\"start\":76098},{\"end\":76509,\"start\":76503},{\"end\":76524,\"start\":76513},{\"end\":76537,\"start\":76528},{\"end\":76545,\"start\":76541},{\"end\":76941,\"start\":76939},{\"end\":76948,\"start\":76945},{\"end\":76954,\"start\":76952},{\"end\":76962,\"start\":76958},{\"end\":76969,\"start\":76966},{\"end\":77720,\"start\":77718},{\"end\":77727,\"start\":77724},{\"end\":77735,\"start\":77731},{\"end\":77742,\"start\":77739},{\"end\":77750,\"start\":77746},{\"end\":77756,\"start\":77754},{\"end\":78178,\"start\":78175},{\"end\":78186,\"start\":78182},{\"end\":78197,\"start\":78190},{\"end\":78206,\"start\":78201},{\"end\":78688,\"start\":78684},{\"end\":78695,\"start\":78692},{\"end\":78703,\"start\":78699},{\"end\":78710,\"start\":78707},{\"end\":78717,\"start\":78714},{\"end\":78723,\"start\":78721},{\"end\":78730,\"start\":78727},{\"end\":78740,\"start\":78738},{\"end\":78747,\"start\":78744},{\"end\":79238,\"start\":79236},{\"end\":79246,\"start\":79242},{\"end\":79253,\"start\":79250},{\"end\":79261,\"start\":79257},{\"end\":79268,\"start\":79265},{\"end\":79275,\"start\":79272},{\"end\":79669,\"start\":79667},{\"end\":79677,\"start\":79673},{\"end\":79684,\"start\":79681},{\"end\":79695,\"start\":79690},{\"end\":79701,\"start\":79699},{\"end\":79711,\"start\":79705},{\"end\":79719,\"start\":79715},{\"end\":79727,\"start\":79723},{\"end\":80219,\"start\":80216},{\"end\":80225,\"start\":80223},{\"end\":80234,\"start\":80229},{\"end\":80241,\"start\":80238},{\"end\":80731,\"start\":80728},{\"end\":80738,\"start\":80735},{\"end\":80744,\"start\":80742},{\"end\":80752,\"start\":80748},{\"end\":80759,\"start\":80756},{\"end\":80768,\"start\":80763},{\"end\":81181,\"start\":81177},{\"end\":81189,\"start\":81185},{\"end\":81196,\"start\":81193},{\"end\":81208,\"start\":81200},{\"end\":81619,\"start\":81614},{\"end\":81627,\"start\":81623},{\"end\":81634,\"start\":81631},{\"end\":81640,\"start\":81638},{\"end\":81647,\"start\":81644},{\"end\":81655,\"start\":81651},{\"end\":81661,\"start\":81659},{\"end\":81669,\"start\":81665},{\"end\":81678,\"start\":81673},{\"end\":82152,\"start\":82148},{\"end\":82159,\"start\":82156},{\"end\":82167,\"start\":82163},{\"end\":82175,\"start\":82173},{\"end\":82184,\"start\":82181},{\"end\":82191,\"start\":82188},{\"end\":82762,\"start\":82758},{\"end\":82770,\"start\":82766},{\"end\":83203,\"start\":83199},{\"end\":83218,\"start\":83207},{\"end\":83230,\"start\":83222},{\"end\":83240,\"start\":83236},{\"end\":83246,\"start\":83244},{\"end\":83675,\"start\":83671},{\"end\":83686,\"start\":83679},{\"end\":84053,\"start\":84050},{\"end\":84060,\"start\":84057},{\"end\":84066,\"start\":84064},{\"end\":84073,\"start\":84070},{\"end\":84080,\"start\":84077},{\"end\":84086,\"start\":84084},{\"end\":84095,\"start\":84090},{\"end\":84636,\"start\":84632},{\"end\":84644,\"start\":84640},{\"end\":84654,\"start\":84650},{\"end\":84661,\"start\":84658},{\"end\":84669,\"start\":84665},{\"end\":84678,\"start\":84673},{\"end\":84686,\"start\":84682},{\"end\":84693,\"start\":84690},{\"end\":85229,\"start\":85227},{\"end\":85235,\"start\":85233},{\"end\":85244,\"start\":85239},{\"end\":85251,\"start\":85248},{\"end\":85258,\"start\":85255},{\"end\":85268,\"start\":85262},{\"end\":85658,\"start\":85653},{\"end\":85665,\"start\":85662},{\"end\":85674,\"start\":85669},{\"end\":85681,\"start\":85678},{\"end\":85688,\"start\":85685},{\"end\":85696,\"start\":85692},{\"end\":85706,\"start\":85704},{\"end\":86246,\"start\":86242},{\"end\":86252,\"start\":86250},{\"end\":86259,\"start\":86256},{\"end\":86536,\"start\":86532},{\"end\":86546,\"start\":86540},{\"end\":86556,\"start\":86550},{\"end\":86568,\"start\":86560},{\"end\":86929,\"start\":86926},{\"end\":86935,\"start\":86933},{\"end\":86942,\"start\":86939},{\"end\":86950,\"start\":86946},{\"end\":86958,\"start\":86954},{\"end\":86964,\"start\":86962},{\"end\":86974,\"start\":86970},{\"end\":87401,\"start\":87398},{\"end\":87408,\"start\":87405},{\"end\":87414,\"start\":87412},{\"end\":87424,\"start\":87422},{\"end\":87986,\"start\":87983},{\"end\":87995,\"start\":87990},{\"end\":88001,\"start\":87999},{\"end\":88008,\"start\":88005},{\"end\":88017,\"start\":88012},{\"end\":88023,\"start\":88021},{\"end\":88624,\"start\":88620},{\"end\":88633,\"start\":88628},{\"end\":88642,\"start\":88637},{\"end\":88648,\"start\":88646},{\"end\":88655,\"start\":88652},{\"end\":88661,\"start\":88659},{\"end\":89107,\"start\":89104},{\"end\":89116,\"start\":89111},{\"end\":89122,\"start\":89120},{\"end\":89129,\"start\":89126},{\"end\":89138,\"start\":89133},{\"end\":89146,\"start\":89142},{\"end\":89156,\"start\":89154},{\"end\":89586,\"start\":89582},{\"end\":89592,\"start\":89590},{\"end\":89601,\"start\":89596},{\"end\":89609,\"start\":89605},{\"end\":89615,\"start\":89613},{\"end\":89623,\"start\":89619},{\"end\":89630,\"start\":89627},{\"end\":89636,\"start\":89634},{\"end\":90085,\"start\":90082},{\"end\":90092,\"start\":90089},{\"end\":90099,\"start\":90096},{\"end\":90107,\"start\":90103},{\"end\":90115,\"start\":90111},{\"end\":90122,\"start\":90119},{\"end\":90648,\"start\":90640},{\"end\":90665,\"start\":90657},{\"end\":91116,\"start\":91110},{\"end\":91126,\"start\":91120},{\"end\":91547,\"start\":91533},{\"end\":91557,\"start\":91551},{\"end\":91835,\"start\":91831},{\"end\":91841,\"start\":91839},{\"end\":91850,\"start\":91845},{\"end\":91858,\"start\":91854},{\"end\":91865,\"start\":91862},{\"end\":91871,\"start\":91869},{\"end\":92209,\"start\":92205},{\"end\":92219,\"start\":92215},{\"end\":92967,\"start\":92961}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":68815,\"start\":68487},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":61153541},\"end\":69087,\"start\":68817},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":237558256},\"end\":69423,\"start\":69089},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":219636253},\"end\":70052,\"start\":69425},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":211171550},\"end\":70490,\"start\":70054},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":208540056},\"end\":71048,\"start\":70492},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14093453},\"end\":71371,\"start\":71050},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":50768534},\"end\":71975,\"start\":71373},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":32370905},\"end\":72431,\"start\":71977},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":224282883},\"end\":73021,\"start\":72433},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":220484640},\"end\":73452,\"start\":73023},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":8047550},\"end\":73864,\"start\":73454},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":31923308},\"end\":74273,\"start\":73866},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":49695599},\"end\":74739,\"start\":74275},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":207178809},\"end\":75177,\"start\":74741},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":9124261},\"end\":75587,\"start\":75179},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":38116062},\"end\":75968,\"start\":75589},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":10174110},\"end\":76437,\"start\":75970},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":11810482},\"end\":76877,\"start\":76439},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":2023817},\"end\":77367,\"start\":76879},{\"attributes\":{\"id\":\"b20\"},\"end\":77593,\"start\":77369},{\"attributes\":{\"id\":\"b21\"},\"end\":77668,\"start\":77595},{\"attributes\":{\"id\":\"b22\"},\"end\":78087,\"start\":77670},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":50775765},\"end\":78623,\"start\":78089},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1637394},\"end\":79175,\"start\":78625},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":53219431},\"end\":79585,\"start\":79177},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":199465865},\"end\":80126,\"start\":79587},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":207758412},\"end\":80640,\"start\":80128},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":229156813},\"end\":81108,\"start\":80642},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":232073844},\"end\":81506,\"start\":81110},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":235306079},\"end\":82064,\"start\":81508},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":220730170},\"end\":82671,\"start\":82066},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":39847715},\"end\":83123,\"start\":82673},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":53977298},\"end\":83623,\"start\":83125},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":52127932},\"end\":83949,\"start\":83625},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":119181611},\"end\":84527,\"start\":83951},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":221150341},\"end\":85153,\"start\":84529},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":209501162},\"end\":85595,\"start\":85155},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":235658226},\"end\":86177,\"start\":85597},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":222296312},\"end\":86464,\"start\":86179},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":757461},\"end\":86863,\"start\":86466},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":160030052},\"end\":87329,\"start\":86865},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":220730113},\"end\":87879,\"start\":87331},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":220730199},\"end\":88522,\"start\":87881},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":208284469},\"end\":89008,\"start\":88524},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":235306149},\"end\":89525,\"start\":89010},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":235306102},\"end\":89959,\"start\":89527},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":196171043},\"end\":90583,\"start\":89961},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":4755450},\"end\":91031,\"start\":90585},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":5575601},\"end\":91499,\"start\":91033},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":5855042},\"end\":91718,\"start\":91501},{\"attributes\":{\"id\":\"b51\"},\"end\":92128,\"start\":91720},{\"attributes\":{\"id\":\"b52\"},\"end\":92865,\"start\":92130},{\"attributes\":{\"id\":\"b53\"},\"end\":93075,\"start\":92867}]", "bib_title": "[{\"end\":68862,\"start\":68817},{\"end\":69160,\"start\":69089},{\"end\":69536,\"start\":69425},{\"end\":70150,\"start\":70054},{\"end\":70588,\"start\":70492},{\"end\":71122,\"start\":71050},{\"end\":71479,\"start\":71373},{\"end\":72045,\"start\":71977},{\"end\":72537,\"start\":72433},{\"end\":73063,\"start\":73023},{\"end\":73514,\"start\":73454},{\"end\":73951,\"start\":73866},{\"end\":74327,\"start\":74275},{\"end\":74810,\"start\":74741},{\"end\":75259,\"start\":75179},{\"end\":75651,\"start\":75589},{\"end\":76057,\"start\":75970},{\"end\":76499,\"start\":76439},{\"end\":76935,\"start\":76879},{\"end\":77714,\"start\":77670},{\"end\":78171,\"start\":78089},{\"end\":78680,\"start\":78625},{\"end\":79232,\"start\":79177},{\"end\":79663,\"start\":79587},{\"end\":80212,\"start\":80128},{\"end\":80724,\"start\":80642},{\"end\":81173,\"start\":81110},{\"end\":81610,\"start\":81508},{\"end\":82144,\"start\":82066},{\"end\":82754,\"start\":82673},{\"end\":83195,\"start\":83125},{\"end\":83665,\"start\":83625},{\"end\":84046,\"start\":83951},{\"end\":84628,\"start\":84529},{\"end\":85223,\"start\":85155},{\"end\":85649,\"start\":85597},{\"end\":86238,\"start\":86179},{\"end\":86528,\"start\":86466},{\"end\":86922,\"start\":86865},{\"end\":87394,\"start\":87331},{\"end\":87979,\"start\":87881},{\"end\":88616,\"start\":88524},{\"end\":89100,\"start\":89010},{\"end\":89578,\"start\":89527},{\"end\":90078,\"start\":89961},{\"end\":90634,\"start\":90585},{\"end\":91106,\"start\":91033},{\"end\":91529,\"start\":91501},{\"end\":91827,\"start\":91720},{\"end\":92198,\"start\":92130}]", "bib_author": "[{\"end\":68493,\"start\":68487},{\"end\":68501,\"start\":68493},{\"end\":68510,\"start\":68501},{\"end\":68517,\"start\":68510},{\"end\":68523,\"start\":68517},{\"end\":68533,\"start\":68523},{\"end\":68872,\"start\":68864},{\"end\":68879,\"start\":68872},{\"end\":68887,\"start\":68879},{\"end\":68898,\"start\":68887},{\"end\":68909,\"start\":68898},{\"end\":68917,\"start\":68909},{\"end\":69170,\"start\":69162},{\"end\":69177,\"start\":69170},{\"end\":69184,\"start\":69177},{\"end\":69191,\"start\":69184},{\"end\":69203,\"start\":69191},{\"end\":69546,\"start\":69538},{\"end\":69554,\"start\":69546},{\"end\":69562,\"start\":69554},{\"end\":70159,\"start\":70152},{\"end\":70168,\"start\":70159},{\"end\":70175,\"start\":70168},{\"end\":70182,\"start\":70175},{\"end\":70191,\"start\":70182},{\"end\":70198,\"start\":70191},{\"end\":70205,\"start\":70198},{\"end\":70598,\"start\":70590},{\"end\":70607,\"start\":70598},{\"end\":70613,\"start\":70607},{\"end\":70624,\"start\":70613},{\"end\":70636,\"start\":70624},{\"end\":70644,\"start\":70636},{\"end\":71131,\"start\":71124},{\"end\":71137,\"start\":71131},{\"end\":71145,\"start\":71137},{\"end\":71487,\"start\":71481},{\"end\":71495,\"start\":71487},{\"end\":71502,\"start\":71495},{\"end\":71511,\"start\":71502},{\"end\":71518,\"start\":71511},{\"end\":71526,\"start\":71518},{\"end\":72055,\"start\":72047},{\"end\":72063,\"start\":72055},{\"end\":72071,\"start\":72063},{\"end\":72078,\"start\":72071},{\"end\":72545,\"start\":72539},{\"end\":72553,\"start\":72545},{\"end\":72561,\"start\":72553},{\"end\":72568,\"start\":72561},{\"end\":72575,\"start\":72568},{\"end\":72582,\"start\":72575},{\"end\":73072,\"start\":73065},{\"end\":73080,\"start\":73072},{\"end\":73088,\"start\":73080},{\"end\":73096,\"start\":73088},{\"end\":73103,\"start\":73096},{\"end\":73110,\"start\":73103},{\"end\":73526,\"start\":73516},{\"end\":73537,\"start\":73526},{\"end\":73548,\"start\":73537},{\"end\":73557,\"start\":73548},{\"end\":73964,\"start\":73953},{\"end\":73975,\"start\":73964},{\"end\":74339,\"start\":74329},{\"end\":74356,\"start\":74339},{\"end\":74367,\"start\":74356},{\"end\":74385,\"start\":74367},{\"end\":74390,\"start\":74385},{\"end\":74822,\"start\":74812},{\"end\":74839,\"start\":74822},{\"end\":74857,\"start\":74839},{\"end\":75267,\"start\":75261},{\"end\":75278,\"start\":75267},{\"end\":75664,\"start\":75653},{\"end\":75673,\"start\":75664},{\"end\":75684,\"start\":75673},{\"end\":76071,\"start\":76059},{\"end\":76086,\"start\":76071},{\"end\":76096,\"start\":76086},{\"end\":76109,\"start\":76096},{\"end\":76511,\"start\":76501},{\"end\":76526,\"start\":76511},{\"end\":76539,\"start\":76526},{\"end\":76547,\"start\":76539},{\"end\":76943,\"start\":76937},{\"end\":76950,\"start\":76943},{\"end\":76956,\"start\":76950},{\"end\":76964,\"start\":76956},{\"end\":76971,\"start\":76964},{\"end\":77722,\"start\":77716},{\"end\":77729,\"start\":77722},{\"end\":77737,\"start\":77729},{\"end\":77744,\"start\":77737},{\"end\":77752,\"start\":77744},{\"end\":77758,\"start\":77752},{\"end\":78180,\"start\":78173},{\"end\":78188,\"start\":78180},{\"end\":78199,\"start\":78188},{\"end\":78208,\"start\":78199},{\"end\":78690,\"start\":78682},{\"end\":78697,\"start\":78690},{\"end\":78705,\"start\":78697},{\"end\":78712,\"start\":78705},{\"end\":78719,\"start\":78712},{\"end\":78725,\"start\":78719},{\"end\":78732,\"start\":78725},{\"end\":78742,\"start\":78732},{\"end\":78749,\"start\":78742},{\"end\":78753,\"start\":78749},{\"end\":79240,\"start\":79234},{\"end\":79248,\"start\":79240},{\"end\":79255,\"start\":79248},{\"end\":79263,\"start\":79255},{\"end\":79270,\"start\":79263},{\"end\":79277,\"start\":79270},{\"end\":79671,\"start\":79665},{\"end\":79679,\"start\":79671},{\"end\":79686,\"start\":79679},{\"end\":79697,\"start\":79686},{\"end\":79703,\"start\":79697},{\"end\":79713,\"start\":79703},{\"end\":79721,\"start\":79713},{\"end\":79729,\"start\":79721},{\"end\":80221,\"start\":80214},{\"end\":80227,\"start\":80221},{\"end\":80236,\"start\":80227},{\"end\":80243,\"start\":80236},{\"end\":80733,\"start\":80726},{\"end\":80740,\"start\":80733},{\"end\":80746,\"start\":80740},{\"end\":80754,\"start\":80746},{\"end\":80761,\"start\":80754},{\"end\":80770,\"start\":80761},{\"end\":81183,\"start\":81175},{\"end\":81191,\"start\":81183},{\"end\":81198,\"start\":81191},{\"end\":81210,\"start\":81198},{\"end\":81621,\"start\":81612},{\"end\":81629,\"start\":81621},{\"end\":81636,\"start\":81629},{\"end\":81642,\"start\":81636},{\"end\":81649,\"start\":81642},{\"end\":81657,\"start\":81649},{\"end\":81663,\"start\":81657},{\"end\":81671,\"start\":81663},{\"end\":81680,\"start\":81671},{\"end\":82154,\"start\":82146},{\"end\":82161,\"start\":82154},{\"end\":82169,\"start\":82161},{\"end\":82177,\"start\":82169},{\"end\":82186,\"start\":82177},{\"end\":82193,\"start\":82186},{\"end\":82764,\"start\":82756},{\"end\":82772,\"start\":82764},{\"end\":83205,\"start\":83197},{\"end\":83220,\"start\":83205},{\"end\":83232,\"start\":83220},{\"end\":83242,\"start\":83232},{\"end\":83248,\"start\":83242},{\"end\":83677,\"start\":83667},{\"end\":83688,\"start\":83677},{\"end\":84055,\"start\":84048},{\"end\":84062,\"start\":84055},{\"end\":84068,\"start\":84062},{\"end\":84075,\"start\":84068},{\"end\":84082,\"start\":84075},{\"end\":84088,\"start\":84082},{\"end\":84097,\"start\":84088},{\"end\":84638,\"start\":84630},{\"end\":84646,\"start\":84638},{\"end\":84656,\"start\":84646},{\"end\":84663,\"start\":84656},{\"end\":84671,\"start\":84663},{\"end\":84680,\"start\":84671},{\"end\":84688,\"start\":84680},{\"end\":84695,\"start\":84688},{\"end\":85231,\"start\":85225},{\"end\":85237,\"start\":85231},{\"end\":85246,\"start\":85237},{\"end\":85253,\"start\":85246},{\"end\":85260,\"start\":85253},{\"end\":85270,\"start\":85260},{\"end\":85660,\"start\":85651},{\"end\":85667,\"start\":85660},{\"end\":85676,\"start\":85667},{\"end\":85683,\"start\":85676},{\"end\":85690,\"start\":85683},{\"end\":85698,\"start\":85690},{\"end\":85708,\"start\":85698},{\"end\":85712,\"start\":85708},{\"end\":86248,\"start\":86240},{\"end\":86254,\"start\":86248},{\"end\":86261,\"start\":86254},{\"end\":86270,\"start\":86261},{\"end\":86538,\"start\":86530},{\"end\":86548,\"start\":86538},{\"end\":86558,\"start\":86548},{\"end\":86570,\"start\":86558},{\"end\":86931,\"start\":86924},{\"end\":86937,\"start\":86931},{\"end\":86944,\"start\":86937},{\"end\":86952,\"start\":86944},{\"end\":86960,\"start\":86952},{\"end\":86966,\"start\":86960},{\"end\":86976,\"start\":86966},{\"end\":86984,\"start\":86976},{\"end\":87403,\"start\":87396},{\"end\":87410,\"start\":87403},{\"end\":87416,\"start\":87410},{\"end\":87426,\"start\":87416},{\"end\":87430,\"start\":87426},{\"end\":87988,\"start\":87981},{\"end\":87997,\"start\":87988},{\"end\":88003,\"start\":87997},{\"end\":88010,\"start\":88003},{\"end\":88019,\"start\":88010},{\"end\":88025,\"start\":88019},{\"end\":88626,\"start\":88618},{\"end\":88635,\"start\":88626},{\"end\":88644,\"start\":88635},{\"end\":88650,\"start\":88644},{\"end\":88657,\"start\":88650},{\"end\":88663,\"start\":88657},{\"end\":89109,\"start\":89102},{\"end\":89118,\"start\":89109},{\"end\":89124,\"start\":89118},{\"end\":89131,\"start\":89124},{\"end\":89140,\"start\":89131},{\"end\":89148,\"start\":89140},{\"end\":89158,\"start\":89148},{\"end\":89162,\"start\":89158},{\"end\":89588,\"start\":89580},{\"end\":89594,\"start\":89588},{\"end\":89603,\"start\":89594},{\"end\":89611,\"start\":89603},{\"end\":89617,\"start\":89611},{\"end\":89625,\"start\":89617},{\"end\":89632,\"start\":89625},{\"end\":89638,\"start\":89632},{\"end\":90087,\"start\":90080},{\"end\":90094,\"start\":90087},{\"end\":90101,\"start\":90094},{\"end\":90109,\"start\":90101},{\"end\":90117,\"start\":90109},{\"end\":90124,\"start\":90117},{\"end\":90650,\"start\":90636},{\"end\":90667,\"start\":90650},{\"end\":90671,\"start\":90667},{\"end\":91118,\"start\":91108},{\"end\":91128,\"start\":91118},{\"end\":91549,\"start\":91531},{\"end\":91559,\"start\":91549},{\"end\":91837,\"start\":91829},{\"end\":91843,\"start\":91837},{\"end\":91852,\"start\":91843},{\"end\":91860,\"start\":91852},{\"end\":91867,\"start\":91860},{\"end\":91873,\"start\":91867},{\"end\":92211,\"start\":92200},{\"end\":92221,\"start\":92211},{\"end\":92228,\"start\":92221},{\"end\":92969,\"start\":92957}]", "bib_venue": "[{\"end\":68652,\"start\":68601},{\"end\":69783,\"start\":69681},{\"end\":70280,\"start\":70251},{\"end\":70799,\"start\":70730},{\"end\":71705,\"start\":71624},{\"end\":72229,\"start\":72162},{\"end\":72761,\"start\":72680},{\"end\":73259,\"start\":73193},{\"end\":73676,\"start\":73625},{\"end\":74084,\"start\":74038},{\"end\":74529,\"start\":74468},{\"end\":74976,\"start\":74925},{\"end\":75401,\"start\":75348},{\"end\":75793,\"start\":75747},{\"end\":76218,\"start\":76172},{\"end\":76684,\"start\":76624},{\"end\":77166,\"start\":77077},{\"end\":77899,\"start\":77837},{\"end\":78387,\"start\":78306},{\"end\":78932,\"start\":78851},{\"end\":79396,\"start\":79345},{\"end\":79878,\"start\":79812},{\"end\":80414,\"start\":80337},{\"end\":80889,\"start\":80838},{\"end\":81325,\"start\":81276},{\"end\":81799,\"start\":81748},{\"end\":82414,\"start\":82312},{\"end\":82923,\"start\":82856},{\"end\":83399,\"start\":83332},{\"end\":83803,\"start\":83754},{\"end\":84268,\"start\":84191},{\"end\":84874,\"start\":84793},{\"end\":85389,\"start\":85338},{\"end\":85933,\"start\":85831},{\"end\":86679,\"start\":86633},{\"end\":87117,\"start\":87059},{\"end\":87651,\"start\":87549},{\"end\":88246,\"start\":88144},{\"end\":88782,\"start\":88731},{\"end\":89281,\"start\":89230},{\"end\":89757,\"start\":89706},{\"end\":90303,\"start\":90222},{\"end\":90836,\"start\":90762},{\"end\":91295,\"start\":91220},{\"end\":92371,\"start\":92345},{\"end\":68599,\"start\":68533},{\"end\":68938,\"start\":68917},{\"end\":69244,\"start\":69203},{\"end\":69679,\"start\":69562},{\"end\":70249,\"start\":70205},{\"end\":70728,\"start\":70644},{\"end\":71196,\"start\":71145},{\"end\":71622,\"start\":71526},{\"end\":72160,\"start\":72078},{\"end\":72678,\"start\":72582},{\"end\":73191,\"start\":73110},{\"end\":73623,\"start\":73557},{\"end\":74036,\"start\":73975},{\"end\":74466,\"start\":74390},{\"end\":74923,\"start\":74857},{\"end\":75346,\"start\":75278},{\"end\":75745,\"start\":75684},{\"end\":76170,\"start\":76109},{\"end\":76622,\"start\":76547},{\"end\":77075,\"start\":76971},{\"end\":77476,\"start\":77369},{\"end\":77615,\"start\":77597},{\"end\":77835,\"start\":77758},{\"end\":78304,\"start\":78208},{\"end\":78849,\"start\":78753},{\"end\":79343,\"start\":79277},{\"end\":79810,\"start\":79729},{\"end\":80335,\"start\":80243},{\"end\":80836,\"start\":80770},{\"end\":81274,\"start\":81210},{\"end\":81746,\"start\":81680},{\"end\":82310,\"start\":82193},{\"end\":82854,\"start\":82772},{\"end\":83330,\"start\":83248},{\"end\":83752,\"start\":83688},{\"end\":84189,\"start\":84097},{\"end\":84791,\"start\":84695},{\"end\":85336,\"start\":85270},{\"end\":85829,\"start\":85712},{\"end\":86309,\"start\":86270},{\"end\":86631,\"start\":86570},{\"end\":87057,\"start\":86984},{\"end\":87547,\"start\":87430},{\"end\":88142,\"start\":88025},{\"end\":88729,\"start\":88663},{\"end\":89228,\"start\":89162},{\"end\":89704,\"start\":89638},{\"end\":90220,\"start\":90124},{\"end\":90760,\"start\":90671},{\"end\":91218,\"start\":91128},{\"end\":91595,\"start\":91559},{\"end\":91912,\"start\":91873},{\"end\":92343,\"start\":92228},{\"end\":92955,\"start\":92867}]"}}}, "year": 2023, "month": 12, "day": 17}