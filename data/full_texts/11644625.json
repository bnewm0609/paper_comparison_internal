{"id": 11644625, "updated": "2023-07-19 15:53:18.702", "metadata": {"title": "The United Nations Parallel Corpus v1.0", "authors": "[{\"first\":\"Micha\u0142\",\"last\":\"Ziemski\",\"middle\":[]},{\"first\":\"Marcin\",\"last\":\"Junczys-Dowmunt\",\"middle\":[]},{\"first\":\"Bruno\",\"last\":\"Pouliquen\",\"middle\":[]}]", "venue": "LREC", "journal": "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16)", "publication_date": {"year": 2016, "month": null, "day": null}, "abstract": "This paper describes the creation process and statistics of the official United Nations Parallel Corpus, the first parallel corpus composed from United Nations documents published by the original data creator. The parallel corpus presented consists of manually translated UN documents from the last 25 years (1990 to 2014) for the six official UN languages, Arabic, Chinese, English, French, Russian, and Spanish. The corpus is freely available for download under a liberal license. Apart from the pairwise aligned documents, a fully aligned subcorpus for the six official UN languages is distributed. We provide baseline BLEU scores of our Moses-based SMT systems trained with the full data of language pairs involving English and for all possible translation directions of the six-way subcorpus.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2572474373", "acl": "L16-1561", "pubmed": null, "pubmedcentral": null, "dblp": "conf/lrec/ZiemskiJP16", "doi": null}}, "content": {"source": {"pdf_hash": "800366078f063a637e6a4880c0c49c217c7905ea", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/L16-1561.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4fce620be406f544cadbd7f039fa3477fb1b6ba8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/800366078f063a637e6a4880c0c49c217c7905ea.txt", "contents": "\nThe United Nations Parallel Corpus v1.0\n\n\nMicha\u0142 Ziemski mziemski@unog.ch \nMarcin Junczys-Dowmunt \nAdam Mickiewicz University\nPozna\u0144Poland\n\nWorld Intellectual Property Organization\nGenevaSwitzerland\n\nBruno Pouliquen bruno.pouliquen@wipo.int \nWorld Intellectual Property Organization\nGenevaSwitzerland\n\nThe United Nations Parallel Corpus v1.0\nUnited Nations, DGACM, New York, United States of AmericaUnited Nationsparallel corpusstatistical machine translation\nThis paper describes the creation process and statistics of the official United Nations Parallel Corpus, the first parallel corpus composed from United Nations documents published by the original data creator. The parallel corpus presented consists of manually translated UN documents from the last 25 years (1990 to 2014) for the six official UN languages, Arabic, Chinese, English, French, Russian, and Spanish. The corpus is freely available for download under a liberal license. Apart from the pairwise aligned documents, a fully aligned subcorpus for the six official UN languages is distributed. We provide baseline BLEU scores of our Moses-based SMT systems trained with the full data of language pairs involving English and for all possible translation directions of the six-way subcorpus.\n\nMotivation\n\nThe United Nations 1 (UN) is mandated to publish documents in six official languages and built up a considerable archive of parallel documents from its own translation operations. Multilingualism is a strategic priority for the United Nations, as an essential factor in harmonious communication among peoples. The official publication of this corpus is a reaction to the growing importance of statistical machine translation (SMT) within the UN Department for General Assembly and Conference Management (DGACM) translation services. In 2011, a research project -in cooperation with the World Intellectual Property Organization (WIPO) -to explore a prototype SMT system based on the TAPTA system used at WIPO (Pouliquen et al., 2011) for the language pair English-Spanish (Pouliquen et al., 2012) was spearheaded by the Spanish Translation Service (STS) in New York and quickly noticed by other United Nations language services. Further development underlined the good performance of the SMT approach and its applicability to UN translation services. The system was expanded (Pouliquen et al., 2013) to a total of 10 language pairs, resulting in a productiongrade cloud-based SMT service called TAPTA4UN. Especially since its integration with the in-house computer assisted translation (CAT) tool eLUNa, TAPTA4UN has become a critical global tool in the UN translation toolkit. DGACM publishes documents in the six official UN languages and additionally in German 2 and is running major translation operations in various locations. The global DGACM translation output for 2014 alone was 231 million words. The translated documents are hosted on the Official Document System 3 (ODS) and are publicly available. Historically, this parallel data has been a major re-source for SMT and NLP research, and has resulted in various (unofficial) corpora, most of them incomplete due to resorting to scraping ODS (Rafalovitch and Dale, 2009;Eisele and Chen, 2010;Chen and Eisele, 2012). Other resources are also available from the Linguistic Data Consortium (LDC) 4 . Depending on the language pair, the present corpus is between two (e.g. en-fr) to four times (e.g. en-ru) larger than data published by (Chen and Eisele, 2012); half of the documents are available for all six languages. The scope of documents used for the SMT models has continuously expanded as additional United Nations documents have become available. The present corpus is the result of this going collection process. The sharing of technology, expertise, and data has proven to be a crucial factor in enabling the adoption of machine translation (MT) at the UN. In the past, DGACM has successfully shared its translation models with other organizations such as WIPO, IMO (Pouliquen et al., 2015), FAO and ILO. Consequently, in order to facilitate research into and the adoption and development of SMT, DGACM is making available a more complete corpus of its parallel documents in a reusable format, including sentence level alignments.\n\n\nLicense and Availability\n\nThe UN parallel corpus is composed of official records and other parliamentary documents of the United Nations that are in the public domain. The UN corpus will be made available for download at http:// conferences.unite.un.org/UNCorpus. The following disclaimer 5 , an integral part of the corpus, shall be respected with regard to the United Nations Parallel Corpus v1.0 (no other restrictions apply):\n\n\u2022 The UN corpus is made available without warranty of any kind, explicit or implied. The United Nations <TEI.2> <teiHeader> <fileDesc> <publicationStmt> <date>20100713</date> <idno type=\"symbol\">CD/1890</idno> <idno type=\"jobno\">G1061646</idno> [...] <keywords> <term>ARMS RACE</term> <term>OUTER SPACE</term> <term>INTERNATIONAL SECURITY</term> </keywords> [...] </teiHeader> <text> <body> <p id=\"1\"> <s id=\"1:1\" lang=\"en\">CD/1890</s> </p> [...] <p id=\"6\"> <s id=\"6:1\" lang=\"en\">The permanent Mission of C <s id=\"6:2\" lang=\"en\">The conference took place (a) English sample document (some elements were omitted) <linkGrp fromDoc=\"Xml/fr/2010/cd/1890.xml\" toDoc=\"Xml/en /2010/cd/1890.xml\" score=\"0.352899\"> <link type=\"1-1\" xtargets=\"1:1;1:1\" score=\"1\"/> <link type=\"1-1\" xtargets=\"2:1;2:1\" score=\"1\"/> <link type=\"1-1\" xtargets=\"3:1;3:1\" score=\"1\"/> <link type=\"0-1\" xtargets=\";4:1\" score=\"0\"/> <link type=\"1-1\" xtargets=\"4:1;5:1\" score=\"0.733075\"/> <link type=\"1-1\" xtargets=\"5:1;6:1\" score=\"0.613475\"/> <link type=\"1-1\" xtargets=\"6:1;7:1\" score=\"0.648559\"/> <link type=\"1-1\" xtargets=\"6:2;7:2\" score=\"0.662173\"/> <link type=\"1-1\" xtargets=\"7:1;8:1\" score=\"0.416193\"/> <link type=\"1-1\" xtargets=\"8:1;9:1\" score=\"0.428882\"/> <link type=\"1-1\" xtargets=\"9:1;10:1\" score=\"1\"/> <link type=\"1-1\" xtargets=\"10:1;11:1\" score=\"1\"/> <link type=\"1-1\" xtargets=\"11:1;12:1\" score=\"0.738796\"/> <link type=\"0-1\" xtargets=\";13:1\" score=\"0\"/> <link type=\"1-1\" xtargets=\"12:1;14:1\" score=\"0.638055\"/> <link type=\"1-1\" xtargets=\"13:1;15:1\" score=\"0.317246\"/> <link type=\"1-1\" xtargets=\"13:2;15:2\" score=\"0.565939\"/> <link type=\"1-1\" xtargets=\"14:1;16:1\" score=\"0.164868\"/> <link type=\"1-1\" xtargets=\"14:2;16:2\" score=\"0.35008\"/> <link type=\"1-1\" xtargets=\"14:2;16:2\" score=\"0.35008\" /> <link type=\"1-1\" xtargets=\"14:3;16:3\" score=\"0.285692\" / <link type=\"1-1\" xtargets=\"14:4;16:4\" score=\"0.41574\" /> (b) Sentence alignment information for two documents Figure 1: TEI-based XML format of raw corpus files specifically makes no warranties or representations as to the accuracy or completeness of the information contained in the UN corpus.\n\n\u2022 Under no circumstances shall the United Nations be liable for any loss, liability, injury or damage incurred or suffered that is claimed to have resulted from the use of the UN corpus. The use of the UN corpus is at the user's sole risk. The user specifically acknowledges and agrees that the United Nations is not liable for any conduct of any user. If the user is dissatisfied with any of the material provided in the UN corpus, the user's sole and exclusive remedy is to discontinue using the UN corpus.\n\n\u2022 When using the UN corpus, the user must acknowledge the United Nations as the source of the information. For references, please use this very publication.\n\n\u2022 Nothing herein shall constitute or be considered to be a limitation upon or waiver, express or implied, of the privileges and immunities of the United Nations, which are specifically reserved.\n\n\nFile Organization and Format\n\nAll documents are organized into folders by language, publication year, and publication symbols. Corresponding documents are placed in parallel folder structures, and a document's translation in any of the official languages (if it exists) can be found by inspecting the same file path in the required language subfolder. For individual documents, it was decided to follow the TEI-based format of the JRC-Aquis parallel corpus (Steinberger et al., 2006). Documents retain the original paragraph structure and sentence splits have been added automatically (see Figure 1a; details on the processing steps are given in Section 5.). Documents for which multiple language versions exist have corresponding link files (Figure 1b) for each of the maximum 15 language pairs. They contain information about the alignment link type, ids of linked sentences (xtargets) and the alignment quality score.\n\nWe also make available plain-text bitexts that span all documents for a specific language pair and can be used more readily with SMT training pipelines.\n\n\nDocument Meta-Information\n\nEvery document in XML file format has embedded metainformation:\n\nSymbol Each UN document has a unique symbol 6 which is common for all language versions.\n\nTranslation job number A unique language-specific document identifier.\n\nPublication date The original publication date for a document by symbol, which applies to all language versions. This date does not necessarily correspond to the release date of each individual document.\n\nProcessing place Possible locations are New York, Geneva and Vienna.\n\nKeywords Any number of subjects covered by the document, according to the ODS subject lexicon, which is based on the UNBIS Thesaurus 7 .\n\n\nCreating the Parallel Corpus\n\nDuring processing, we differentiate between primary and secondary language pairs. Primary language pairs consist of one non-English language and English. Secondary language pairs are formed from non-English language pairs. Figure 2 illustrates all the processing steps for creating the sentence alignment link file from two parallel documents 6 A detailed description of these symbols can be found at  for a primary language pair, here English-French. The dependency graph featured is modeled very closely after our pipeline based on GNU Make. After converting binary formats (MS Word, WordPerfect) to the presented TEI-XML format, sentence splitting 8 is applied to the XML file, retaining the original paragraph structure as shown in Figure 1a.\n\nTo ensure a high-quality sentence alignment, we rely on a two-step approach similar to Sennrich and Volk (2011 domly select a subset of 10,000 document pairs and align them using Hunalign (Varga et al., 2005), selecting only 1-1 alignments that are themselves surrounded by 1-1 alignments. This small lower-quality parallel corpus is used to train an SMT system with Moses (Koehn et al., 2007). Following Sennrich and Volk (2011) we use significance pruning (Johnson et al., 2007) to filter out noise resulting from alignment errors. Next, our monolingual sentence aligner BLEU-Champ 9 is applied. BLEU-Champ relies on smoothed sentence level BLEU-2 as a similarity metric between sentences and uses the Champollion algorithm (Ma, 2006) with that metric. In order to avoid computational bottlenecks for long documents, first a path consisting only of 0-1, 1-0, 1-1 alignments is calculated. In a second step, the search is restricted to a 10-sentence-wide corridor around the best path allowing for all alignment combinations up to 4-4 alignments. This procedure avoids search errors and is fast enough to use the Champollion algorithm with documents consisting of thousands of sentences. Given the English tokenized text and the translated French text, BLEU-Champ produces a ladder file (Hunalign's numeric alignment format) which eventually is combined with the two TEI documents to form the final TEI sentence alignment file (see Figure 1b). The XML and link files in Figure 2 are distributed as part of the corpus. Since the link files contain pointers to the original XML documents, any set of link files can be used to produce plain-text parallel corpora.\n\nIn the case of secondary language pairs, the same steps are followed, except that both documents are translated into English and sentence alignment is performed on the English translation results of both files.\n\n\nStatistics\n\nStatistics for all language pairs are presented in Table 1a.\n\nWe also make available a fully aligned subcorpus ( Table 1c). This subcorpus consists of sentences that are consistently aligned across all languages with the English primary documents. We believe this might be one of the largest resources of this kind and of particular value for comparative linguistic research.\n\n\nTest and Development Data\n\nDocuments released in 2015 (excluded from the current corpus) were used to create official development and test sets for machine translation tasks. Development data was randomly selected from documents that were released in the first quarter of 2015 and test data was selected from the second quarter. To avoid repetitions, we only chose translation tuples for which the English sentence was unique. We also skewed the distribution of sentence lengths slightly by requiring that half of the sentences not be chosen if their length was below 50 characters and not imposing any restrictions on the other half. This was done to reduce the occurrence of formulaic and less informative sentences. Both sets comprise 4,000 sentences that are 1-1 alignments across all official languages. As in the case of the fully aligned subcorpus, any translation direction can be evaluated (see Table 2b).  -92,337 491,166,055 569,888,234 513,100,827 557,143,420 16,038,721 zh 387,968,412 425,562,909 493,338,256 498,007,502 417,366,738 -387,931,939 381,371,583 382,052,741 377,884,885 392,372,764 (a) Statistics for pair-wise aligned documents. Cells above the diagonal contain the number of documents and lines per language pair. Cells below the diagonal contain tokens numbers in a language pair -the upper number refers to the language in the column title, the lower to the language in the row title. Tokens were counted after processing with the Moses tokenizer. For Chinese, Jieba was used before applying the Moses tokenizer with default settings.  \n\n\nMachine Translation Baselines\n\nBased on the described test sets we also provide baseline results for our in-house Moses (Koehn et al., 2007) systems that were trained on the described data. Sentences longer than 100 words were discarded. To speed up the word alignment procedure, we split the training corpora into four equally sized parts that are aligned with MGIZA++ (Gao and Vogel, 2008), running 5 iterations of Model 1 and the HMM model on each part. 10 We use a 5gram language model trained from the target parallel data, with 3-grams or higher order being pruned if they occur only once. Apart from the default configuration with a lexical reordering model, we add a 5-gram operation sequence model (Durrani et al., 2013) (all n-grams pruned if they occur only once) and a 9-gram word-class language model with word-classes produced by word2vec (Mikolov et al., 2013) (3-grams and 4-grams are pruned if they occur only once, 5-grams and 6-grams if they occur only twice, etc.), both trained using KenLM (Heafield et al., 2013). To reduce the phrase-table size, we apply significance pruning (Johnson et al., 2007) and use the compact phrase-  Fully aligned Subcorpus In Table 2b, we provide BLEU scores for the entire translation matrix for all official languages from the fully aligned subcorpus. These systems are not used as in-house translation systems and were produced as an academic exercise. The results do not differ significantly for common translation directions in both settings despite the differences in absolute data sizes. We speculate that this may be caused by the fact that the fully aligned corpus covers 80-90% of the documents even if sometimes only 50% of the segments are present. Optimizer instability during parameter tuning or a certain degree of saturation might be other factors.\n\n\nConclusions\n\nThe publication of the United Nations Parallel Corpus v1.0 makes a more complete resource of UN documents available to the general public. It is the result of the continuous effort and dedication to multilingualism. The alignment links provided allow for experiments with language pairs, for instance Arabic-Chinese, that have not been widely investigated. Our baselines and test sets can serve as reference data for future publications and we would like researchers to explore machine translation techniques beyond the phrase-based approach that was used to produce them. The fully aligned subcorpus in particular may prove a valuable resource for studying pivoting techniques and multi-source or multi-target approaches. The metainformation and preserved document structure provided can help to advance recent work in document-level translation.\n\nWe are keen to test the most promising results in our own systems.\n\nIn the future, we hope to publish updated versions of the presented parallel corpus, expanding forward and backwards in time.\n\nFigure 2 :\n2Sentence alignment dependency graph\n\nTable 1 :\n1Statistics for the United Nations Corpus v1.0 (1990 -2014)    \n\n\ntable and reordering data structures(Junczys-Dowmunt, 2012). During decoding, we use the cube-pruning algorithm with stack size and cube-pruning pop limits of 1,000. All scores are provided for lowercased data; the data was tokenized with the Moses tokenizer. For Chinese segmentation we used Jieba 11 before applying the Moses tokenizer. Full Data into and from English At DGACM, translation is mainly done between English and the remaining lan-10  We confirmed that there seemed to be no quality loss due to splitting and limiting the iterations to simpler alignment models.11 https://github.com/fxsjy/jieba ar es fr ru zh en\u2192 42.04 61.35 50.33 43.89 37.68 en\u2190 54.01 60.38 52.58 53.53 43.68 (a) BLEU scores from and into English for all available data (b) BLEU scores matrix of the fully aligned subcorpus\u2192 \nar \nen \nes \nfr \nru \nzh \nar \n-\n53.07 49.77 42.80 36.00 31.58 \nen 41.96 \n-\n61.26 50.09 43.25 37.84 \nes 38.13 59.89 \n-\n49.76 39.69 31.27 \nfr 34.43 52.22 52.44 \n-\n36.48 29.98 \nru 34.43 52.59 49.61 43.37 \n-\n32.63 \nzh 28.02 42.97 39.64 34.42 29.57 \n-\n\n\n\nTable 2 :\n2BLEU scores for baseline systems guages. Hence, we have in-house translation systems for these language pairs that are being used in production 12 .Table 2acontains the most recent results for these systems trained with all the available data for a language pair.\nReferring to the Department for General Assembly and Conference Management which is responsible for the document processing chain, including translation, of the UN Secretariat 2 Only some documents are translated by the German Translation Section in New York.3 http://ods.un.org\nSee e.g.Franz, Alex, Shankar Kumar, and Thorsten Brants.  1993 United Nations Parallel Text LDC2013T06. Web  Download. Philadelphia: Linguistic Data Consortium, 2013 Drafted with the advice of the General Legal Division, Office of Legal Affairs, United Nations.\nhttps://github/emjotde/bleu-champ\nThe data collection efforts for this publication also resulted in a considerably larger set of training data for our own systems.\nAcknowledgementsThe authors wish to thank Ms Catherine Pollard, Under-Secretary-General for General Assembly Affairs and Conference Management, and Ms Cecilia Elizalde, Director, Documentation Division, DGACM, for making the publication of the UN parallel corpus possible. The authors further wish to thank Mr Michael Rudolph Ten-Pow, Senior Adviser on Multilingualism, Michelle Keating, Chief, Languages Service, UNOG, and Ms Danielle Henripin, UNHQ, for all their support.\nMultiUN v2: UN documents with multilingual alignments. Y Chen, A Eisele, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12). Nicoletta Calzolarithe Eight International Conference on Language Resources and Evaluation (LREC'12)Istanbul, Turkey, MayEuropean Language Resources Association (ELRAChen, Y. and Eisele, A. (2012). MultiUN v2: UN docu- ments with multilingual alignments. In Nicoletta Calzo- lari (Conference Chair), et al., editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC'12), Istanbul, Turkey, May. Eu- ropean Language Resources Association (ELRA).\n\nCan Markov models over minimal translation units help phrase-based SMT?. N Durrani, A Fraser, H Schmid, H Hoang, P Koehn, ACL. The Association for Computer LinguisticsDurrani, N., Fraser, A., Schmid, H., Hoang, H., and Koehn, P. (2013). Can Markov models over minimal translation units help phrase-based SMT? In ACL, pages 399-405. The Association for Computer Linguistics.\n\nMultiUN: A multilingual corpus from United Nation documents. A Eisele, Y Chen, Language Resources and Evaluation. Eisele, A. and Chen, Y. (2010). MultiUN: A multilingual corpus from United Nation documents. In Language Re- sources and Evaluation.\n\nParallel implementations of word alignment tool. Q Gao, S Vogel, Software Engineering, Testing, and Quality Assurance for Natural Language Processing. ACLGao, Q. and Vogel, S. (2008). Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Process- ing, pages 49-57. ACL.\n\nF Grali\u0144ski, K Jassem, M Junczys-Dowmunt, PSI-Toolkit: Natural Language Processing Pipeline. Computational Linguistics -Applications. Grali\u0144ski, F., Jassem, K., and Junczys-Dowmunt, M. (2012). PSI-Toolkit: Natural Language Processing Pipeline. Computational Linguistics -Applications, pages 27-39.\n\nScalable modified Kneser-Ney language model estimation. K Heafield, I Pouzyrevsky, J H Clark, P Koehn, Proceedings of the 51st Annual Meeting of the ACL. the 51st Annual Meeting of the ACLHeafield, K., Pouzyrevsky, I., Clark, J. H., and Koehn, P. (2013). Scalable modified Kneser-Ney language model estimation. In Proceedings of the 51st Annual Meeting of the ACL, pages 690-696.\n\nImproving translation quality by discarding most of the phrasetable. J H Johnson, J Martin, G Forst, R Kuhn, Proceedings of EMNLP-CoNLL'07. EMNLP-CoNLL'07Johnson, J. H., Martin, J., Forst, G., and Kuhn, R. (2007). Improving translation quality by discarding most of the phrasetable. In Proceedings of EMNLP-CoNLL'07, pages 967-975.\n\nPhrasal Rank-Encoding: Exploiting phrase redundancy and translational relations for phrase table compression. M Junczys-Dowmunt, Prague Bull. Math. Linguistics. 98Junczys-Dowmunt, M. (2012). Phrasal Rank-Encoding: Exploiting phrase redundancy and translational relations for phrase table compression. Prague Bull. Math. Lin- guistics, 98:63-74.\n\nMoses: Open source toolkit for statistical machine translation. P Koehn, H Hoang, A Birch, C Callison-Burch, M Federico, N Bertoldi, B Cowan, W Shen, C Moran, R Zens, C Dyer, O Bojar, A Constantin, E Herbst, Proceedings of the 45th Annual Meeting of the ACL. the 45th Annual Meeting of the ACLACLKoehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed- erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and Herbst, E. (2007). Moses: Open source toolkit for sta- tistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL, pages 177-180. ACL.\n\nChampollion: A robust parallel text sentence aligner. X Ma, Proceedings of LREC-2006. LREC-2006Ma, X. (2006). Champollion: A robust parallel text sen- tence aligner. In Proceedings of LREC-2006.\n\nEfficient estimation of word representations in vector space. T Mikolov, K Chen, G Corrado, J Dean, abs/1301.3781CoRR. Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Efficient estimation of word representations in vector space. CoRR, abs/1301.3781.\n\nTAPTA: A user-driven translation system for patent documents based on domain-aware statistical machine translation. B Pouliquen, C Mazenc, A Iorio, Proceedings of the 15th Annual Conference of the EAMT. the 15th Annual Conference of the EAMTTrento, ItalyPouliquen, B., Mazenc, C., and Iorio, A. (2011). TAPTA: A user-driven translation system for patent documents based on domain-aware statistical machine translation. In Proceedings of the 15th Annual Conference of the EAMT, pages 5-12, Trento, Italy.\n\nLarge-scale multiple language translation accelerator at the United Nations. B Pouliquen, C Mazenc, C Elizalde, J Garcia-Verdugo, B Pouliquen, C Elizalde, M Junczys-Dowmunt, C Mazenc, J Garc\u00eda-Verdugo, 16th Annual Conference of the European Association for Machine Translation. Trento, ItalyMT-Summit XIVPouliquen, B., Mazenc, C., Elizalde, C., and Garcia- Verdugo, J. (2012). Statistical machine translation pro- totype using UN parallel documents. In 16th Annual Conference of the European Association for Machine Translation (EAMT 2012), pages 12-19, Trento, Italy. Pouliquen, B., Elizalde, C., Junczys-Dowmunt, M., Mazenc, C., and Garc\u00eda-Verdugo, J. (2013). Large-scale multiple language translation accelerator at the United Nations. In MT-Summit XIV, pages 345-352.\n\nSMT at the International Maritime Organization: experiences with combining in-house corpora with out-of-domain corpora. B Pouliquen, M Junczys-Dowmunt, B Pinero, M Ziemski, Proceedings of the 18th Annual Conference of the European Association for Machine Translation. Rafalovitch, A. and Dale, R.the 18th Annual Conference of the European Association for Machine TranslationAntalya, TurkeyMT Summit XII. International Association of Machine TranslationPouliquen, B., Junczys-Dowmunt, M., Pinero, B., and Ziemski, M. (2015). SMT at the International Maritime Organization: experiences with combining in-house cor- pora with out-of-domain corpora. In Proceedings of the 18th Annual Conference of the European Association for Machine Translation, pages 202-205, Antalya, Turkey. Rafalovitch, A. and Dale, R. (2009). United Nations gen- eral assembly resolutions: A six-language parallel cor- pus. In MT Summit XII, pages 292-299. International Association of Machine Translation.\n\nIterative, MT-based sentence alignment of parallel texts. 18th Nordic Conference of Computational Linguistics. R Sennrich, M Volk, NODALIDASennrich, R. and Volk, M. (2011). Iterative, MT-based sen- tence alignment of parallel texts. 18th Nordic Confer- ence of Computational Linguistics, NODALIDA.\n\nThe JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages. R Steinberger, B Pouliquen, A Widiger, C Ignat, T Erjavec, D Tufi\u015f, Proceedings of the 5th International Conference on Language Resources and Evaluation. the 5th International Conference on Language Resources and EvaluationSteinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Er- javec, T., and Tufi\u015f, D. (2006). The JRC-Acquis: A mul- tilingual aligned parallel corpus with 20+ languages. In Proceedings of the 5th International Conference on Lan- guage Resources and Evaluation, pages 2142-2147.\n\nParallel corpora for medium density languages. D Varga, L N\u00e9meth, P Hal\u00e1csy, A Kornai, V Tr\u00f3n, V Nagy, Recent Advances in Natural Language Processing. RANLP 2005Varga, D., N\u00e9meth, L., Hal\u00e1csy, P., Kornai, A., Tr\u00f3n, V., and Nagy, V. (2005). Parallel corpora for medium den- sity languages. In Recent Advances in Natural Language Processing (RANLP 2005), pages 590-596.\n", "annotations": {"author": "[{\"end\":75,\"start\":43},{\"end\":200,\"start\":76},{\"end\":302,\"start\":201}]", "publisher": null, "author_last_name": "[{\"end\":57,\"start\":50},{\"end\":98,\"start\":83},{\"end\":216,\"start\":207}]", "author_first_name": "[{\"end\":49,\"start\":43},{\"end\":82,\"start\":76},{\"end\":206,\"start\":201}]", "author_affiliation": "[{\"end\":139,\"start\":100},{\"end\":199,\"start\":141},{\"end\":301,\"start\":243}]", "title": "[{\"end\":40,\"start\":1},{\"end\":342,\"start\":303}]", "venue": null, "abstract": "[{\"end\":1258,\"start\":461}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2004,\"start\":1980},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2067,\"start\":2043},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2370,\"start\":2346},{\"end\":3202,\"start\":3174},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3224,\"start\":3202},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3246,\"start\":3224},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3488,\"start\":3465},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4029,\"start\":4005},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8172,\"start\":8146},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10322,\"start\":10299},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10420,\"start\":10400},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10605,\"start\":10585},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10692,\"start\":10670},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10948,\"start\":10938},{\"end\":13584,\"start\":13394},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14186,\"start\":14166},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14437,\"start\":14416},{\"end\":14505,\"start\":14503},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14774,\"start\":14753},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14921,\"start\":14899},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15080,\"start\":15057},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15167,\"start\":15145},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17106,\"start\":17083}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":16969,\"start\":16921},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":17044,\"start\":16970},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":18103,\"start\":17045},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":18379,\"start\":18104}]", "paragraph": "[{\"end\":4269,\"start\":1272},{\"end\":4701,\"start\":4298},{\"end\":6822,\"start\":4703},{\"end\":7332,\"start\":6824},{\"end\":7490,\"start\":7334},{\"end\":7686,\"start\":7492},{\"end\":8609,\"start\":7719},{\"end\":8763,\"start\":8611},{\"end\":8856,\"start\":8793},{\"end\":8946,\"start\":8858},{\"end\":9018,\"start\":8948},{\"end\":9223,\"start\":9020},{\"end\":9293,\"start\":9225},{\"end\":9431,\"start\":9295},{\"end\":10210,\"start\":9464},{\"end\":11873,\"start\":10212},{\"end\":12085,\"start\":11875},{\"end\":12160,\"start\":12100},{\"end\":12475,\"start\":12162},{\"end\":14043,\"start\":12505},{\"end\":15862,\"start\":14077},{\"end\":16725,\"start\":15878},{\"end\":16793,\"start\":16727},{\"end\":16920,\"start\":16795}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":12159,\"start\":12151},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":12221,\"start\":12213},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":13390,\"start\":13382},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":15232,\"start\":15224}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1270,\"start\":1260},{\"attributes\":{\"n\":\"2.\"},\"end\":4296,\"start\":4272},{\"attributes\":{\"n\":\"3.\"},\"end\":7717,\"start\":7689},{\"attributes\":{\"n\":\"4.\"},\"end\":8791,\"start\":8766},{\"attributes\":{\"n\":\"5.\"},\"end\":9462,\"start\":9434},{\"attributes\":{\"n\":\"6.\"},\"end\":12098,\"start\":12088},{\"attributes\":{\"n\":\"7.\"},\"end\":12503,\"start\":12478},{\"attributes\":{\"n\":\"8.\"},\"end\":14075,\"start\":14046},{\"attributes\":{\"n\":\"9.\"},\"end\":15876,\"start\":15865},{\"end\":16932,\"start\":16922},{\"end\":16980,\"start\":16971},{\"end\":18114,\"start\":18105}]", "table": "[{\"end\":18103,\"start\":17854}]", "figure_caption": "[{\"end\":16969,\"start\":16934},{\"end\":17044,\"start\":16982},{\"end\":17854,\"start\":17047},{\"end\":18379,\"start\":18116}]", "figure_ref": "[{\"end\":6646,\"start\":6638},{\"end\":8288,\"start\":8279},{\"end\":8442,\"start\":8431},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9695,\"start\":9687},{\"end\":10209,\"start\":10200},{\"end\":11655,\"start\":11645},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11691,\"start\":11683}]", "bib_author_first_name": "[{\"end\":19616,\"start\":19615},{\"end\":19624,\"start\":19623},{\"end\":20294,\"start\":20293},{\"end\":20305,\"start\":20304},{\"end\":20315,\"start\":20314},{\"end\":20325,\"start\":20324},{\"end\":20334,\"start\":20333},{\"end\":20657,\"start\":20656},{\"end\":20667,\"start\":20666},{\"end\":20893,\"start\":20892},{\"end\":20900,\"start\":20899},{\"end\":21187,\"start\":21186},{\"end\":21200,\"start\":21199},{\"end\":21210,\"start\":21209},{\"end\":21542,\"start\":21541},{\"end\":21554,\"start\":21553},{\"end\":21569,\"start\":21568},{\"end\":21571,\"start\":21570},{\"end\":21580,\"start\":21579},{\"end\":21936,\"start\":21935},{\"end\":21938,\"start\":21937},{\"end\":21949,\"start\":21948},{\"end\":21959,\"start\":21958},{\"end\":21968,\"start\":21967},{\"end\":22310,\"start\":22309},{\"end\":22610,\"start\":22609},{\"end\":22619,\"start\":22618},{\"end\":22628,\"start\":22627},{\"end\":22637,\"start\":22636},{\"end\":22655,\"start\":22654},{\"end\":22667,\"start\":22666},{\"end\":22679,\"start\":22678},{\"end\":22688,\"start\":22687},{\"end\":22696,\"start\":22695},{\"end\":22705,\"start\":22704},{\"end\":22713,\"start\":22712},{\"end\":22721,\"start\":22720},{\"end\":22730,\"start\":22729},{\"end\":22744,\"start\":22743},{\"end\":23222,\"start\":23221},{\"end\":23426,\"start\":23425},{\"end\":23437,\"start\":23436},{\"end\":23445,\"start\":23444},{\"end\":23456,\"start\":23455},{\"end\":23740,\"start\":23739},{\"end\":23753,\"start\":23752},{\"end\":23763,\"start\":23762},{\"end\":24206,\"start\":24205},{\"end\":24219,\"start\":24218},{\"end\":24229,\"start\":24228},{\"end\":24241,\"start\":24240},{\"end\":24259,\"start\":24258},{\"end\":24272,\"start\":24271},{\"end\":24284,\"start\":24283},{\"end\":24303,\"start\":24302},{\"end\":24313,\"start\":24312},{\"end\":25022,\"start\":25021},{\"end\":25035,\"start\":25034},{\"end\":25054,\"start\":25053},{\"end\":25064,\"start\":25063},{\"end\":25991,\"start\":25990},{\"end\":26003,\"start\":26002},{\"end\":26254,\"start\":26253},{\"end\":26269,\"start\":26268},{\"end\":26282,\"start\":26281},{\"end\":26293,\"start\":26292},{\"end\":26302,\"start\":26301},{\"end\":26313,\"start\":26312},{\"end\":26803,\"start\":26802},{\"end\":26812,\"start\":26811},{\"end\":26822,\"start\":26821},{\"end\":26833,\"start\":26832},{\"end\":26843,\"start\":26842},{\"end\":26851,\"start\":26850}]", "bib_author_last_name": "[{\"end\":19621,\"start\":19617},{\"end\":19631,\"start\":19625},{\"end\":20302,\"start\":20295},{\"end\":20312,\"start\":20306},{\"end\":20322,\"start\":20316},{\"end\":20331,\"start\":20326},{\"end\":20340,\"start\":20335},{\"end\":20664,\"start\":20658},{\"end\":20672,\"start\":20668},{\"end\":20897,\"start\":20894},{\"end\":20906,\"start\":20901},{\"end\":21197,\"start\":21188},{\"end\":21207,\"start\":21201},{\"end\":21226,\"start\":21211},{\"end\":21551,\"start\":21543},{\"end\":21566,\"start\":21555},{\"end\":21577,\"start\":21572},{\"end\":21586,\"start\":21581},{\"end\":21946,\"start\":21939},{\"end\":21956,\"start\":21950},{\"end\":21965,\"start\":21960},{\"end\":21973,\"start\":21969},{\"end\":22326,\"start\":22311},{\"end\":22616,\"start\":22611},{\"end\":22625,\"start\":22620},{\"end\":22634,\"start\":22629},{\"end\":22652,\"start\":22638},{\"end\":22664,\"start\":22656},{\"end\":22676,\"start\":22668},{\"end\":22685,\"start\":22680},{\"end\":22693,\"start\":22689},{\"end\":22702,\"start\":22697},{\"end\":22710,\"start\":22706},{\"end\":22718,\"start\":22714},{\"end\":22727,\"start\":22722},{\"end\":22741,\"start\":22731},{\"end\":22751,\"start\":22745},{\"end\":23225,\"start\":23223},{\"end\":23434,\"start\":23427},{\"end\":23442,\"start\":23438},{\"end\":23453,\"start\":23446},{\"end\":23461,\"start\":23457},{\"end\":23750,\"start\":23741},{\"end\":23760,\"start\":23754},{\"end\":23769,\"start\":23764},{\"end\":24216,\"start\":24207},{\"end\":24226,\"start\":24220},{\"end\":24238,\"start\":24230},{\"end\":24256,\"start\":24242},{\"end\":24269,\"start\":24260},{\"end\":24281,\"start\":24273},{\"end\":24300,\"start\":24285},{\"end\":24310,\"start\":24304},{\"end\":24328,\"start\":24314},{\"end\":25032,\"start\":25023},{\"end\":25051,\"start\":25036},{\"end\":25061,\"start\":25055},{\"end\":25072,\"start\":25065},{\"end\":26000,\"start\":25992},{\"end\":26008,\"start\":26004},{\"end\":26266,\"start\":26255},{\"end\":26279,\"start\":26270},{\"end\":26290,\"start\":26283},{\"end\":26299,\"start\":26294},{\"end\":26310,\"start\":26303},{\"end\":26319,\"start\":26314},{\"end\":26809,\"start\":26804},{\"end\":26819,\"start\":26813},{\"end\":26830,\"start\":26823},{\"end\":26840,\"start\":26834},{\"end\":26848,\"start\":26844},{\"end\":26856,\"start\":26852}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":10005952},\"end\":20218,\"start\":19560},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":5907276},\"end\":20593,\"start\":20220},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":13222584},\"end\":20841,\"start\":20595},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4895939},\"end\":21184,\"start\":20843},{\"attributes\":{\"id\":\"b4\"},\"end\":21483,\"start\":21186},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2561041},\"end\":21864,\"start\":21485},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":12131372},\"end\":22197,\"start\":21866},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":9842047},\"end\":22543,\"start\":22199},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":794019},\"end\":23165,\"start\":22545},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":751375},\"end\":23361,\"start\":23167},{\"attributes\":{\"doi\":\"abs/1301.3781\",\"id\":\"b10\",\"matched_paper_id\":5959482},\"end\":23621,\"start\":23363},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":22434442},\"end\":24126,\"start\":23623},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":43274683},\"end\":24899,\"start\":24128},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":15238400},\"end\":25877,\"start\":24901},{\"attributes\":{\"id\":\"b14\"},\"end\":26176,\"start\":25879},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":26124282},\"end\":26753,\"start\":26178},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":13133927},\"end\":27122,\"start\":26755}]", "bib_title": "[{\"end\":19613,\"start\":19560},{\"end\":20291,\"start\":20220},{\"end\":20654,\"start\":20595},{\"end\":20890,\"start\":20843},{\"end\":21539,\"start\":21485},{\"end\":21933,\"start\":21866},{\"end\":22307,\"start\":22199},{\"end\":22607,\"start\":22545},{\"end\":23219,\"start\":23167},{\"end\":23423,\"start\":23363},{\"end\":23737,\"start\":23623},{\"end\":24203,\"start\":24128},{\"end\":25019,\"start\":24901},{\"end\":26251,\"start\":26178},{\"end\":26800,\"start\":26755}]", "bib_author": "[{\"end\":19623,\"start\":19615},{\"end\":19633,\"start\":19623},{\"end\":20304,\"start\":20293},{\"end\":20314,\"start\":20304},{\"end\":20324,\"start\":20314},{\"end\":20333,\"start\":20324},{\"end\":20342,\"start\":20333},{\"end\":20666,\"start\":20656},{\"end\":20674,\"start\":20666},{\"end\":20899,\"start\":20892},{\"end\":20908,\"start\":20899},{\"end\":21199,\"start\":21186},{\"end\":21209,\"start\":21199},{\"end\":21228,\"start\":21209},{\"end\":21553,\"start\":21541},{\"end\":21568,\"start\":21553},{\"end\":21579,\"start\":21568},{\"end\":21588,\"start\":21579},{\"end\":21948,\"start\":21935},{\"end\":21958,\"start\":21948},{\"end\":21967,\"start\":21958},{\"end\":21975,\"start\":21967},{\"end\":22328,\"start\":22309},{\"end\":22618,\"start\":22609},{\"end\":22627,\"start\":22618},{\"end\":22636,\"start\":22627},{\"end\":22654,\"start\":22636},{\"end\":22666,\"start\":22654},{\"end\":22678,\"start\":22666},{\"end\":22687,\"start\":22678},{\"end\":22695,\"start\":22687},{\"end\":22704,\"start\":22695},{\"end\":22712,\"start\":22704},{\"end\":22720,\"start\":22712},{\"end\":22729,\"start\":22720},{\"end\":22743,\"start\":22729},{\"end\":22753,\"start\":22743},{\"end\":23227,\"start\":23221},{\"end\":23436,\"start\":23425},{\"end\":23444,\"start\":23436},{\"end\":23455,\"start\":23444},{\"end\":23463,\"start\":23455},{\"end\":23752,\"start\":23739},{\"end\":23762,\"start\":23752},{\"end\":23771,\"start\":23762},{\"end\":24218,\"start\":24205},{\"end\":24228,\"start\":24218},{\"end\":24240,\"start\":24228},{\"end\":24258,\"start\":24240},{\"end\":24271,\"start\":24258},{\"end\":24283,\"start\":24271},{\"end\":24302,\"start\":24283},{\"end\":24312,\"start\":24302},{\"end\":24330,\"start\":24312},{\"end\":25034,\"start\":25021},{\"end\":25053,\"start\":25034},{\"end\":25063,\"start\":25053},{\"end\":25074,\"start\":25063},{\"end\":26002,\"start\":25990},{\"end\":26010,\"start\":26002},{\"end\":26268,\"start\":26253},{\"end\":26281,\"start\":26268},{\"end\":26292,\"start\":26281},{\"end\":26301,\"start\":26292},{\"end\":26312,\"start\":26301},{\"end\":26321,\"start\":26312},{\"end\":26811,\"start\":26802},{\"end\":26821,\"start\":26811},{\"end\":26832,\"start\":26821},{\"end\":26842,\"start\":26832},{\"end\":26850,\"start\":26842},{\"end\":26858,\"start\":26850}]", "bib_venue": "[{\"end\":19729,\"start\":19633},{\"end\":20345,\"start\":20342},{\"end\":20707,\"start\":20674},{\"end\":20992,\"start\":20908},{\"end\":21318,\"start\":21228},{\"end\":21637,\"start\":21588},{\"end\":22004,\"start\":21975},{\"end\":22358,\"start\":22328},{\"end\":22802,\"start\":22753},{\"end\":23251,\"start\":23227},{\"end\":23480,\"start\":23476},{\"end\":23824,\"start\":23771},{\"end\":24404,\"start\":24330},{\"end\":25167,\"start\":25074},{\"end\":25988,\"start\":25879},{\"end\":26405,\"start\":26321},{\"end\":26904,\"start\":26858},{\"end\":19852,\"start\":19750},{\"end\":21673,\"start\":21639},{\"end\":22020,\"start\":22006},{\"end\":22838,\"start\":22804},{\"end\":23262,\"start\":23253},{\"end\":23877,\"start\":23826},{\"end\":24419,\"start\":24406},{\"end\":25290,\"start\":25197},{\"end\":26476,\"start\":26407}]"}}}, "year": 2023, "month": 12, "day": 17}