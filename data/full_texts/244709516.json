{"id": 244709516, "updated": "2023-10-13 05:43:49.813", "metadata": {"title": "Transferability Estimation using Bhattacharyya Class Separability", "authors": "[{\"first\":\"Michal\",\"last\":\"P'andy\",\"middle\":[]},{\"first\":\"Andrea\",\"last\":\"Agostinelli\",\"middle\":[]},{\"first\":\"Jasper\",\"last\":\"Uijlings\",\"middle\":[]},{\"first\":\"Vittorio\",\"last\":\"Ferrari\",\"middle\":[]},{\"first\":\"Thomas\",\"last\":\"Mensink\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Transfer learning has become a popular method for leveraging pre-trained models in computer vision. However, without performing computationally expensive fine-tuning, it is difficult to quantify which pre-trained source models are suitable for a specific target task, or, conversely, to which tasks a pre-trained source model can be easily adapted to. In this work, we propose Gaussian Bhattacharyya Coefficient (GBC), a novel method for quantifying transferability between a source model and a target dataset. In a first step we embed all target images in the feature space defined by the source model, and represent them with per-class Gaussians. Then, we estimate their pairwise class separability using the Bhattacharyya coefficient, yielding a simple and effective measure of how well the source model transfers to the target task. We evaluate GBC on image classification tasks in the context of dataset and architecture selection. Further, we also perform experiments on the more complex semantic segmentation transferability estimation task. We demonstrate that GBC outperforms state-of-the-art transferability metrics on most evaluation criteria in the semantic segmentation settings, matches the performance of top methods for dataset transferability in image classification, and performs best on architecture selection problems for image classification.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2111.12780", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/PandyAUFM22", "doi": "10.1109/cvpr52688.2022.00896"}}, "content": {"source": {"pdf_hash": "4fa282f35dacd5f390c5001af964adea9f44bb8b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.12780v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "6a8147a422577ae75c564186e4c8a619a83b95fb", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4fa282f35dacd5f390c5001af964adea9f44bb8b.txt", "contents": "\nTransferability Estimation using Bhattacharyya Class Separability\n\n\nMichal P\u00e1ndy michalpandy@google.com \nGoogle Research\n\n\nAndrea Agostinelli agostinelli@google.com \nGoogle Research\n\n\nJasper Uijlings \nGoogle Research\n\n\nVittorio Ferrari vittoferrari@google.com \nGoogle Research\n\n\nThomas Mensink mensink@google.com \nGoogle Research\n\n\nTransferability Estimation using Bhattacharyya Class Separability\n\nTransfer learning has become a popular method for leveraging pre-trained models in computer vision. However, without performing computationally expensive finetuning, it is difficult to quantify which pre-trained source models are suitable for a specific target task, or, conversely, to which tasks a pre-trained source model can be easily adapted to. In this work, we propose Gaussian Bhattacharyya Coefficient (GBC), a novel method for quantifying transferability between a source model and a target dataset. In a first step we embed all target images in the feature space defined by the source model, and represent them with per-class Gaussians. Then, we estimate their pairwise class separability using the Bhattacharyya coefficient, yielding a simple and effective measure of how well the source model transfers to the target task. We evaluate GBC on image classification tasks in the context of dataset and architecture selection. Further, we also perform experiments on the more complex semantic segmentation transferability estimation task. We demonstrate that GBC outperforms state-of-the-art transferability metrics on most evaluation criteria in the semantic segmentation settings, matches the performance of top methods for dataset transferability in image classification, and performs best on architecture selection problems for image classification.\n\nIntroduction\n\nThe goal of transfer learning is to reuse knowledge learned on a source task to help train a model for a target task. Currently, the most common form of transfer learning in computer vision is to pre-train a source model on the ILSVRC'12 dataset [55] and then fine-tune it on the target dataset [3,14,23,24,30,35,57,75]. However, each target task may benefit from a different source model architecture [12,25,45,53] or different source dataset [42,46,71]. The challenge then becomes to determine which (pre-* Currently at Waymo.\n\n\nSource models\n\nTarget data embedded in source feature space GBC overlap ranking Target data Figure 1. This figure illustrates the high-level overview of our approach. On the left, we use the pre-trained source models to embed data into the source models' feature space. On the right, we use GBC to rank these methods based on how much classes overlap in corresponding embedding spaces. trained) source model is most suitable for a particular target task, or to which target task a specific model can be easily adapted. Determining this by fine-tuning all combinations of source models and target datasets is computationally prohibitive.\n\nTo address this problem, several recent works introduced transferability metrics [4,38,47,60,61,72], which aim at predicting how well a source model transfers to a given target dataset. A good transferability metric is computationally efficient, and its predictions correlate well with the final performance of a model after fine-tuning on the target dataset. Typically a transferability metric is estimated by applying the source model to the target dataset to extract embeddings or predictions, which are then combined with the target ground-truth labels to measure transferability. This paper proposes a novel transferability metric: the Gaussian Bhattacharyya Coefficient (GBC). The main idea is to measure the amount of overlap between target classes in the feature space of the source model (Fig. 1). If this overlap is small, the target classes are easily separated which means the knowledge in the source model is useful for the target task and the source model should transfer well. Conversely, if the overlap is large, the target classes are difficult to separate and the source model transfers badly to this target task. In order to estimate the amount of overlap, we apply the feature extractor of the source model to the target dataset and model each target class as a Gaussian distribution in this space. Importantly, we carefully apply regularization techniques to ensure that the Gaussian model can accurately represent each class. Then, we measure the sum of the overlaps between each pair of target classes using the Bhattacharyya coefficient. The Bhattacharyya coefficient has a closed-form solution when applied on Gaussian distributions. We use this overlap as our transferability metric.\n\nWe perform extensive experiments on two tasks. First we consider image classification, the primary focus of previous works on transferability metrics [4,38,47,60,61,72]. Additionally, we consider a realistic transfer learning scenario for the task of semantic segmentation by considering transfer across a large variety of datasets from different image domains. Our experiments demonstrate that GBC outperforms several state-of-the-art transferability metrics: LEEP [47], LogME [72], H-score [4]. Furthermore, we demonstrate that our method is computationally efficient.\n\nIn summary, our paper makes the following contributions: 1) We introduce GBC, a new transferability metric which measures the amount of overlap between target classes in the source feature space. Since we model the target samples with per-class Gaussians, the GBC can be estimated in closed form; 2) We lift transferability experiments to a realistic transfer learning scenario for semantic segmentation; 3) We experimentally demonstrate that our GBC method outperforms other transferability metrics, including LEEP [47], LogME [72], and H-score [4].\n\n\nRelated work\n\nWhile our work falls into the broad domain of transfer learning [50,67], and relates to model selection [19,52], and domain adaption [6,18,49], in this section we discuss the most relevant related work in estimating transferability metrics. We structure these along four general paradigms.\n\n\nTask relatedness.\n\nPioneering works in task relatedness [7,33,41] introduce symmetric measures between source and target tasks or domains. The intuition is that related tasks could be learned together more efficiently [7]. While intuitively task relatedness should correlate with transferability, these particular measures are generally hard to estimate. Moreover, the relatedness measures are symmetric, while transfer is asymmetrical: ImageNet is probably a very good source dataset for CIFAR-10, while the reverse is likely not true [42,47].\n\nLabel comparison-based methods.\n\nLEEP [47] and NCE [61] use the labels of the source domain and the tar-get domain to construct transferability metrics. In NCE by Tran et al. [61], they assume that the images of a source and target task are identical, but their labels differ. Then, they use the negative conditional entropy between the target labels and the source labels as a tranferability metric. Nguyen et al. propose LEEP [47], where the source model is applied to the target dataset. The resulting label predictions are utilised for computing a log-likelihood between the target labels and the source model predictions. An assumption in label comparison-based models is their dependence on the source output label space. Specifically, two source models with an identical feature extractor yet different classification heads will produce different transferability scores. In contrast source embedding-based methods rely purely on the underlying feature extractor.\n\nSource embedding-based methods. Source embeddingbased methods utilize the embeddings of target samples obtained via a pre-trained source model. Target embeddings are used together with their labels to compute various distance metrics. Cui et al. [16] propose to compute the Earth Mover's Distances between the class conditioned means of the embeddings. In H-score by Bao et al. [4], high transferability estimates are assigned to sources, where the embeddings display low feature redundancy and high inter-class variance. Li et al. [38] introduce N LEEP, an extension to LEEP where the authors fit a Gaussian Mixture Model of the target data in the embedding space and use this in place of the source model's classification head to compute the LEEP score. Finally, You et al. [72] propose the stateof-the-art LogME score which treats each target label as a linear model with Gaussian noise, and then optimise the parameters of the prior distribution to find the average maximum (log) evidence of labels given the target sample embeddings. Our work also falls into the source embeddingbased methods, but we directly consider the separability of class conditioned target embeddings.\n\n\nOptimal transport.\n\nThere have been several works proposing transferability estimation based on optimal transport (OT), including [2,60]. The underlying assumption is that when in the source model's embedding space the source and target datasets have similar geometrical structures, and hence have a low OT-distance, the given source model is a suitable for the given target dataset. With [2], we share the idea to model classes as Gaussian distributions in the embeddeding space. However, OT based approaches have some serious drawbacks: (1) The method in [60] relies on parameter tuning based on ground-truth transferability scores; (2) These methods require access to the source training set; and (3) Computing the (regularized) OT distance scales quadratically in the number of data samples, which makes it practically infeasible to compute transferability scores for large datasets (including ImageNet).\n\n\nMethod\n\n\nFormal description\n\nBefore we describe our method, we first provide a more formal description of the problem at hand. The goal is to estimate the transferability score S s\u2192t of a source model m s for a particular target task t. The target task t is described by a training set D t containing images and ground truth label pairs (x t , y t ).\n\nA good transferability metric S s\u2192t correlates with the accuracy A s\u2192t of the target model m s\u2192t . The accuracy A s\u2192t is measured by evaluating m s\u2192t on the (unseen) test set of the target task D test t . To create the target model m s\u2192t , it is initialized using the weights of the source model m s , after which it is fully fine-tuned on the target task t using the target training set D t . However, since fully finetuning m s\u2192t is computationally expensive, instead we want to predict how it will transfer using a computational efficient transferability metric S s\u2192t .\n\nThe source model m s is defined by (a) the network architecture, such as ResNet50 [25] or VGG16 [58]; and (b) the training dataset used to train the source network, such as supervised classification on ImageNet [55].\n\nFor our method, we assume that we have access to the image embedding function of the source model f s (x), which returns a feature vector representation of image x. Our method only relies on the feature extractor f s (x), similar to H-score [4] and LogME [72]. In contrast, optimal transport based methods require access to the source (training) dataset D s [2,60], and LEEP requires the per target example predictions in the source label space [47].\n\n\nEvaluating transferability.\n\nWe evaluate the performance of the transferability metrics by evaluating the correlation between S s\u2192t and A s\u2192t , as measured by the weighted Kendall tau rank correlation \u03c4 w , as proposed by [72].\n\nIn contrast to the Pearson r correlation coefficient which measures a linear relation between S and A, the Kendall rank correlation allows for highly non-linear relations, since it correlates rankings. The weighted Kendall correlation \u03c4 w places higher weights on the models with the highest accuracies. This incorporates the rationale that it is more important to have the top few models correctly ranked, than the models with lower accuracies. For a more elaborate discussion on the appropriateness of the weighted Kendall tau, we refer the reader to You et al. [72].\n\nWe evaluate \u03c4 w for different kinds of transferability scenarios, either fixing the target task to find the most suitable source model, or by correlating a fixed source model with different target tasks. Figure 2. Illustration of the intuition: when images of the target classes overlap less in the embedding space of a source model, then it is a more suitable source to transfer from (left: a poor source; right: a better one). We use the Bhattacharyya coefficient to estimate the overlap between classes, each modeled as a Gaussian.\n\n\nClass separability\n\nThe key idea behind our method is that if the target images are class-wise separable in the source model feature space f s (\u00b7), then this source model allows for good classification for the target task. This intuition is shown in Fig. 2, where we show two embeddings of 4 target classes. We argue that the left dataset is more difficult to transfer to than the right dataset because the amount of class overlap is higher. We posit that the class overlap is proportional to the error of a sufficiently expressive fine-tuned classifier on the target dataset, and hence is proportional with the transferability of the source model to the target data. Our approach measures the amount of class separability of the target dataset in the source model feature space and uses that as transferability score S s\u2192t .\n\n\nBhattacharyya coefficient.\n\nThe Bhattacharyya coefficient [8] (BC) is a measure of the amount of overlap between two distributions; in our case we want to measure the overlap between the probability densities of two target classes p ci , p cj :\nBC(p ci , p cj ) = p ci (x) p cj (x) dx (1)\n\nPer-class Gaussian distributions.\n\nIn order to compute the Bhattacharyya coefficient, we need to define the probabilistic model p c for the target classes. We chose to model each class distribution with a Gaussian in the source embedding space: p c = N (\u00b5 c , \u03a3 c ), with:\n\u00b5 c = 1 N c i [[y i = c]] f s (x i ) \u03a3 c = 1 N c \u2212 1 i [[y i = c]] (f s (x i ) \u2212 \u00b5 c ) (f s (x i ) \u2212 \u00b5 c ) where N c = i [[y i = c]]\n, the number of images in this class. \n\n\nResNet50\n\nResNet152 While we do not suggest that per-class distributions are necessarily (multivariate) Gaussians, the advantage of using this model is that the Bhattacharyya coefficient can be computed in closed form from the class means and covariance matrices, using the Bhattacharyya distance D B :\nMobileNetV2 MobileNet DenseNet202 DenseNet169 DenseNet121 ResNet50v2 ResNet101D B (c i , c j ) = 1 8 (\u00b5 ci \u2212 \u00b5 cj ) \u03a3 \u22121 (\u00b5 ci \u2212 \u00b5 cj ) + 1 2 ln |\u03a3| |\u03a3 ci ||\u03a3 cj | (2) where \u03a3 = 1 2 (\u03a3 ci + \u03a3 cj ), the Bhattacharyya coefficient is then BC(\u00b7, \u00b7) = exp \u2212D B (\u00b7, \u00b7).\nGaussian Bhattacharyya coefficient. Our final transferability score estimates the overlap of all classes by taking the sum of the pairwise coefficients:\nGBC s\u2192t = \u2212 i,j [[i = j]] BC(c i , c j )(3)\nThe final score uses the negative sum, because higher Bhattacharyya coefficients correspond to more overlap between the classes and therefore less transferability.\n\nTheoretical guarantee. A nice property of GBC is that it provides some theoretical guarantee: when a classification head is fine-tuned on top of a fixed feature backbone and the per-class Gaussian assumption holds, then GBC is equivalent to an upper-bound on the optimal Bayes classification error [21,40]. However, when the full model is fine-tuned, it is difficult to draw such a strong guarantee, as for all transferability metrics. For this, we rely on strong empirical results to demonstrate that GBC works well also in this general case.\n\n\nPractical considerations\n\nPCA dimensionality reduction.\n\nIn practice, we transform the source embedding using the PCA projection into a fixed dimensional feature space of 64 dimensions. The reason for doing so is that different source architectures produce features with different number of dimensions and the Bhattacharyya coefficient is affected by the dimensionality due to its use of the determinant of the covariance matrix (Eq. (2)), which would make GBC scores difficult to compare. Moreover, reducing the number of dimensions allows to better estimate the Gaussian model.\n\n\nCovariance estimation.\n\nTo compute GBC, we need to estimate the per-class covariance matrices for all target classes. However, estimating the full covariance is infeasible, since the number of samples in a class can be very low, for example in the Caltech-USCD Birds [63]  Time complexity.\n\nIn order to compute GBC, we first extract source model features f x (\u00b7) for all images in the target data, the corresponding complexity if O(N F ), for N images, and where F denotes the complexity of extracting features. First, for PCA estimation using SVD, it costs O(N D 2 ) to obtain the projection matrix. Then, to project samples and obtain their per-class means and covariance estimates in the reduced d-dimensional space is O(N Dd) and O(N Dd 2 ), respectively. Finally, computing the Bhattacharyya distance (2) between two classes in the reduced space with diagonal covariance matrices costs O(d), so estimating our transferability metric (3) is O(C 2 d). In practice, the total run time largely depends on the cost of extracting features for the target dataset: O(N F ).\n\n\nExperiments\n\nIn this section, we evaluate our proposed GBC transferability metric. We consider various transfer learning tasks to compare our proposed method against related work.\n\n\nClassification: architecture transferability\n\nExperimental setup.\n\nWe consider several different source model architectures pre-trained on ImageNet. We want to identify which architecture would perform best on a given target dataset. To this end, we follow the experimental setup in [72] and evaluate our method using 8 different target datasets and 9 commonly utilized network architectures. Concretely, we fix the target dataset and we compute A s\u2192t and S s\u2192t for each architecture. Then, we measure weighted Kendall rank correlation \u03c4 w (as proposed by You et al. [72]) between the reference A s\u2192t and predicted S s\u2192t across all the architectures, and report the results. We repeat this experiment for every target dataset.\n\nWe use the following target datasets: CIFAR-10 & 100 [36], Imagenette [28], Oxford IIIT Pets [51], Caltech-USCD Birds 2011 (CUB'11) [63], Stanford Dogs [32], Oxford Flowers 102 [48], and SUN-397 [70].\n\nAs source architectures we use ResNet-50, ResNet-101 & ResNet-152 [25], ResNetV2-50 [26], DenseNet-101, DenseNet-169 & DenseNet-201 [29], MobileNet [27], and MobileNetV2 [56] from the Keras library [13]. Before After Before After The target accuracy A s\u2192t is computed by evaluating the target model after fine-tuning each architecture on each target dataset for 100 epochs (with SGD with Momentum, using a batch size of 64 and learning rate of 10 \u22124 ).\n\nWe compare our method to three competitive baselines: H-score [4], LEEP [47] and LogME [72] 1 .\n\nMain results and comparisons. We present the results of the full source architecture transferability experiment in Tab. 1 (see more results in App. D). Notably, GBC achieves the highest average rank correlation \u03c4 w of .47 over all the target datasets. Moreover, GBC is the only method to exhibit positive rank correlations for all target datasets. GBC determines the single best performing architecture for 3 target datasets, while LEEP and H-score for 2, and LogME for none. Furthermore, the best architecture is among the top-3 suggested models by GBC in 7 datasets, while only in 6 for LEEP, in 3 for H-score, and in 1 for LogME. Fig. 3 presents the scatter plots of the accuracies A and estimated transferability scores S obtained by each method on each dataset. GBC showcases increasing trends across all datasets. These results demonstrate that GBC outperforms previous work for source architecture selection. Fig. 4 shows the feature distributions before and after fine-tuning for two models with different GBC transferabil-ity scores (DenseNet and MobilNet). Each row shows a separate experiment on a different target dataset (CIFAR-10, CUB'11). In both cases, MobileNet has lower GBC scores than DenseNet and also results in lower accuracy after finetuning, demonstrating that our method works as intended.\n\nInfluence of regularization. We evaluated the influence of GBC's regularization parameters (Sect. 3.3). We used CIFAR-10 as the target dataset and transferred from the 9 source architectures listed above. For PCA we considered {16,32,64,128}-dimensional projections, and for the covariance estimation the regularization variants: {full, diagonal, spherical}. From the results we conclude that spherical regularization with 64-dimensional PCA projections delivers the best performance. Please see App. B for full details. Hence, in all classification experiments we use these settings (Sect. 4.1 & Sect. 4.2).\n\nWe want to highlight that using these settings the covariance estimation is robust, even in a low data regime: (1) On the smallest dataset we consider (CUB'11, 29 samples per class), GBC outperforms all previous methods in Tab. 1 and is on-par with the best in Tab. 2; (2) We computed the Pearson correlation (\u03c1) between GBC's performance and the number of samples per class. They are essentially uncorrelated (\u03c1 = \u22120.048), suggesting that GBC does not perform worse with fewer samples per class.\n\nComputational cost. To provide an indicative reference, we compare here the run times of several transferability metrics on CIFAR-100 (on a single CPU). After the feature extraction stage (shared by all metrics), GBC runs in 7.8s, vs 12.0s for LogME, 6.1s for H-score, and 0.2s for LEEP.\n\n\nClassification: dataset transferability Experimental setup.\n\nGood transferability metrics should correlate with a model's performance on target test data, as mentioned in Sect. 3.1. To evaluate this, we follow the setup from [47]: Given a fixed source model, the goal is to rank target datasets according to the actual performance of the source model after fine-tuning it on the target training set.\n\nFor this set of experiments all our source models have a ResNet-50 [25] architecture. Our first source model is trained on ImageNet [55]. This ImageNet [55] source model also acts as initialisation for the other 5 source models, trained on the following datasets: CIFAR-10 & CIFAR-100 [36], Fashion-MNIST [69], SUN397 [70] and Caltech-USCD Birds2011 [63]. This results in 6 source models. We use the same datasets as targets except for ImageNet, resulting in 5 target datasets. This results in 25 source-target pairs used as experiments.\n\nFor each of these 25 experiments, we use a single source model and a single main target dataset. Following [47], we construct a set of 100 subsampled target datasets from this main target dataset. Each subsampled target dataset is obtained by sampling uniformly between 2% and a 100% of the target classes and using all available images for these classes. For example, when the CIFAR-100 dataset is used as main target dataset, 100 subsampled datasets are created, each containing the CIFAR-100 images for 2-100 (randomly selected) classes. For each of these subsampled target datasets, the trans- Figure 5. This figure illustrates the scatter plots of LEEP, LogME, H-score, and GBC for CIFAR-100 and CUB'11 as target datasets. In each figure, the transferability score Ss\u2192t of the method is on the X-axis, with the corresponding As\u2192t of each fine-tuned model on the Y-axis. From the plots we observe that while LogME and H-score tend to struggle to differentiate between target datasets, both GBC and LEEP showcase increasing trends.\n\nferability score of the source model is estimated. To obtain the target model m s\u2192t , we fully fine-tuned the source model for each subsampled target dataset, for 100 epochs (using SGD with Momentum, with a batch size of 10 and learning rate of 10 \u22123 , these hyper-parameters are the same as in LEEP [47]).\n\nEvaluation. The accuracy A s\u2192t is obtained by evaluating the final target models on the target test set (removing labels not sampled for this particular target task). We measure correlation between the transferability metric S s\u2192t and the accuracy A s\u2192t using the weighted Kendall rank correlation \u03c4 w . The baselines we use are H-score, LogME, and LEEP. For fair comparisons, each method is evaluated on the same set of 100 random target datasets in all experiments.\n\nResults. We present the quantitative results in Tab. 2 (and more results in App. D). We observe that our proposed GBC has the top performance on 15 (out of 25) experiments, LEEP has the top performance on 19 experiments, LogME has the top performance in 5 cases, and H-score has the top performance in 1 case, where we include ties in our counting. GBC and LEEP achieve an average \u03c4 w score of .82, much higher than H-score (.66) and LogME (.40). Further, both GBC and LEEP consistently showcased high \u03c4 w values (\u2265 .67) across all experiments, while both H-score (.12) and LogME underperform for certain target datasets (e.g. CUB'11 for LogME). These results confirm that the proposed GBC method outperforms LogME and H-score, and is on par with LEEP in this setting. We illustrate the correlation between A s\u2192t and S s\u2192t on CIFAR-100 (top) and CUB'11 (bottom) in Fig. 5. We observe that LogME and H-score fail to distinguish well between certain target datasets, i.e. assign near identical transferability scores despite the differences in target accuracies. On the other hand, both LEEP and the proposed GBC distinguish between the target datasets well, with persistent monotonically increasing trends.\n\n\nSegmentation: dataset transferability\n\nExperimental setup.\n\nWe now turn to a transfer learning scenario for semantic segmentation, following the setup of [42]: 17 datasets spanning very different image domains (consumer photos, autonomous driving, aerial imagery, underwater, indoor scenes, synthetic, close-ups) containing 6-150 classes each: ADE20K [74], BDD [73], CamVid [9], CityScapes [15], COCO [11,34,39], IDD [62], iSAID [65,68], ISPRS [54], KITTI [1], Mappilary [44], Pascal Context [43], Pascal VOC [20], ScanNet [17], SUIM [31], SUN RGB-D [59], vGallery [66], and vKITTI2 [10,22]. While [42] used their setup to investigate what factors are important for good transfer learning, they did not aim to predict transferability. Nevertheless, we interpret one of their measurements as a transferability metric.\n\nWe use the low-shot target training regime of [42], which is arguably the most interesting scenario for transfer learning. The target training set is limited to 150 images for all datasets, except COCO and ADE20k, where the limit is set to 1000 images since they contain a large number of classes.\n\nWe use a HRNetV2-W48 backbone [64] with a linear classifier on top. This model offers excellent performance for semantic segmentation [64] and was also used in [37,42]. We train a source model on each dataset.\n\nWe consider all 17 \u00d7 16 = 272 valid source model, target dataset pairs (for each target dataset we do not consider its corresponding source model trained on the full training set). For each pair, we compute the transferability metrics. We also compute the actual mean Intersection-over-Union performance by fine-tuning the source model on the target training set, and then evaluate on the target test set.\n\nWe evaluate in two scenarios like before: (1) given a fixed source model, we rank all valid target datasets; and (2) given a fixed target dataset, we rank all valid source models. For each scenario we measure the correlation with \u03c4 w and also the top-1 selection accuracy: for scenario (1) the percentage of targets where the source with the highest predicted transferability score also has the highest actual performance, and for scenario (2) the same, however with the role of source and target reversed.\n\n\nGBC estimation.\n\nFor semantic segmentation, instead of one label per image, we have predictions at the pixel level. To estimate the transferability metrics, we consider each pixel x i and its ground truth label y i as a separate observation. Since using all observations for all metrics is too computationally expensive, we subsample 1000 pixels as observations per training image. We subsample using a class-balanced sampling strategy (i.e. sample inverseproportionally to the label frequency), which we found to improve results for all metrics. To make the comparison completely fair, we always use the exact same subsampled pixels for each image to calculate all transferability metrics.\n\nFor semantic segmentation, even after subsampling, we have generally many more observations than for image classification. Therefore, instead of modelling spherical Gaussians, we model Gaussians with a diagonal covariance matrix, which offer a greater modeling capacity. This improved results for our method.\n\n\nImage Domain Similarity.\n\nIn [42] Table 3. Overview of results for transferability estimation for semantic segmentation. GBC outperforms all transferability methods in terms of top-1 accuracy, which is the most important measure in a practical transfer learning application.\n\nthat transfer learning performance was reasonably correlated with image domain similarity (IDS) between the source and target dataset. In this paper we interpret IDS as a transferability metric. IDS was established as follows [42]: First a multi-task model (trained on multiple sources) was applied to 1000 randomly sampled images of each dataset, resulting in a single embedding vector per image. Then each target image embedding was matched to its closest source image embedding. Finally, IDS is the average euclidean distance between these matched embeddings. We obtained all IDS metrics from the authors in personal correspondence.\n\nResults. Tab. 3 presents the results (see App. C for more details). For scenario (1), when choosing a source model for a fixed target dataset, our method has the highest top-1 accuracy: it outperforms all other methods in choosing the best source, which is the main goal in a practical application. When looking at the weighted Kendall \u03c4 w , which measures overall ranking correctness, LogME is best, and our method is second. In scenario (2), determining for a fixed source model to which target dataset it transfers best, LogME completely fails. While IDS and LEEP perform better, they are still significantly below our method in both top-1 accuracy and \u03c4 w . We conclude that our proposed GBC transferability metric is the overall best transferability metric for semantic segmentation.\n\n\nConclusion\n\nIn this paper, we introduce the Gaussian Bhattacharyya coefficient (GBC), a novel transferability metric which measures the amount of overlap between target classes (each modelled as a Gaussian) in the source feature space. The societal impact is that it reduces the need for heavy training procedures in transfer learning by selecting good models to transfer from in an efficient manner. We compare our method against state-of-the-art transferability metrics: LogME [72], LEEP [47], and H-score [5] and show that GBC outperforms them (or is on par) on most evaluation criteria. A key limitation of GBC is that it is designed for classification tasks only (not regression).\n\n\nA. Limitations and Future work\n\nHere we reflect on some of the key limitations of the proposed GBC method.\n\nNetwork Architectures. Firstly, the selected source architectures play a key role in evaluating the proposed method. It is plausible that different architectures yield different class distributions in the embedding space, which could impact the per-class Gaussian approximation of GBC. Further, all the architectures are sensitive to training hyperparameter choices, which introduces further complications in estimating ground truth transferability scores. To allow for fair comparison, we have used the same network architectures as in [72] as much as possible, and verified that our networks are trained until convergence. However, a different set of used architectures may influence the results.\n\nClassification networks. GBC measures pairwise class overlap and hence is suitable for transfer in a classification setting. However, many interesting transfer learning problems are in regression, or even unsupervised learning and reinforcement learning. In terms of regression, it would be useful to extend GBC, for example by binning the regression variable and replace the class overlap with an overlap between the used bins. We believe all of these directions present promising avenues for future work.\n\n\nB. Empirical analysis of design choices\n\nIn this experiment, we evaluate the influence of GBC's design choices introduced in our method section. We use CIFAR10 as a target dataset and transfer from the 9 source architectures pre-trained on ImageNet as described in our experiments.\n\nEffects of regularization strategies We compare three Gaussian covariance regularization strategies: none, diagonal, and spherical. As we can observe in Fig. 6, adding regularization improves our results, with the best \u03c4 w in the case of spherical regularization.\n\nEffects of PCA dimensions In this experiment, we compare the performance of GBC across multiple PCA dimensions: 16, 32, 64, and 128. We discover performance improvements up to 64 dimensions (see Fig. 7), after which we observe a decline in \u03c4 w . Hence, it can be beneficial to carefully select the appropriate PCA dimensions for the given use case.\n\n\nC. Detailed Results for Semantic Segmentation\n\nHere we provide additional results for semantic segmentation. In particular Tab. 4 shows per-target results for the  source selection task (ranking source datasets for a particular fixed target dataset), while Tab. 5 shows per-source results for the target selection task (ranking target datasets for a fixed source dataset). For each table we provide the Weighted Kendall Tau correlation metric for every dataset, and we indicate whether a transferability metric correctly predicts the top-1 source (in source selection) or the top-1 target (in target selection).\n\n\nD. Additional Results for Image Classification\n\nIn this section we provide additional experimental results for the image classification experiments. \u2022 Moreover, we provide scatter plots for all target datasets used in Fig. 8, extending Figure 4 in the main paper.    In each plane, the transferability score Ss\u2192t of the method is on the X-axis, with the corresponding As\u2192t of each fine-tuned model on the Y-axis. From the plots we observe that while LogME and H-score tend to struggle to differentiate between some of the target datasets, both GBC and LEEP showcase increasing trends.\n\nFigure 3 .\n3Overview of source selection experiments. For eight different target datasets we show the correlation between the accuracy of the model (A, Y-axis) and the transferability scores (S,X-axis) of LEEP, H-score, LogMe and GBC. See text for details.\n\n\n: .68 gbc : \u2212419 acc : .45\n\nFigure 4 .\n4Feature distribution of CIFAR-10 (top) and 10 (randomly selected) classes of CUB'11 (bottom), visualized with UMAP.\n\nFigure 6 .\n6This figure demonstrates the superiority of spherical regularization with respect to other strategies in terms of weighted Kendall's rank correlation.\n\nFigure 7 .\n7This figure demonstrates the sensitivity of GBC to PCA dimensionality on Cifar10 in terms of weighted Kendall's rank correlation.\n\nFigure 8 .\n8This figure illustrates the scatter plots of LEEP, LogME, H-score, and GBC for all datasets used in the dataset transferability experiment (see Section 4.2 and Fig 4 of the main paper).\n\n\ndataset, on average there are only 30 samples per class. Therefore, we experiment with both diagonal covariance matrices and spherical ones.Pets Imagenette CIFAR-10 CUB'11 Dogs Flowers102 SUN CIFAR-100 AverageTable 1. Overview of results for transferability for source selection in image classification. We depict for eight different target datasets the weighted Kendall \u03c4w between the accuracy of the fine-tuned model and the transferability scores from LEEP, LogMe, H-score and the proposed GBC. Our proposed method obtains the highest average \u03c4w across the different datasets.LogMe -0.06 \n0.58 \n0.25 \n0.2 \n0.08 \n0.00 \n-0.19 \n0.34 \n0.15 \nH-score 0.06 \n0.59 \n0.45 \n0.16 \n-0.01 \n0.09 \n0.09 \n0.34 \n0.22 \nLEEP \n0.63 \n0.65 \n0.52 \n0.25 \n0.59 \n-0.46 \n0.40 \n0.55 \n0.39 \nGBC \n0.55 \n0.63 \n0.46 \n0.43 \n0.80 \n0.23 \n0.32 \n0.35 \n0.47 \n\n\n\n\n\u2022 For the source selection experiments (Sect. 4.1 / Tab. 1), we include different correlation metrics: Weighted Kendall Tau (Tab. 6a, also in the main paper), Kendall Tau (Tab. 6b), and Pearson's r coefficient (Tab. 6c). \u2022 For the dataset transferability experiments (Sect. 4.2 / Tab. 2), we include also the Weighted Kendall Tau (Tab. 7a, used in the main paper), Kendall Tau (Tab. 7b), and Pearson's r coefficient (Tab. 7c).\n\n\nTable 4. Per-target results for segmentation source selection.Table 5. Per-source results for segmentation target selection. Pets Imagenette CIFAR-10 CUB'11 Dogs Flowers102 SUN CIFAR-100 Average Pets Imagenette CIFAR-10 CUB'11 Dogs Flowers102 SUN CIFAR-100 Average Pets Imagenette CIFAR-10 CUB'11 Dogs Flowers102 SUN CIFAR-100 Average\u03c4 w \n\nTop-1 \nTarget Dataset \nIDS LEEP LogME GBC \nIDS LEEP LogME GBC \n[42] \n[47] \n[72] \nOurs \n[42] \n[47] \n[72] \nOurs \n\nPascal Context [43] \n0.48 \n0.64 \n0.82 \n0.73 \n-\nPascal VOC [20] \n0.25 \n0.29 \n0.52 \n0.44 \n-\n-\nADE20K [74] \n0.21 \n0.42 \n0.43 \n0.41 \nCOCO [11, 34, 39] \n-0.12 -0.15 \n0.20 \n-0.14 \n-\n-\n-\n-\nKITTI [1] \n0.64 \n0.77 \n0.82 \n0.84 \n-\n-\n-\n-\nCamVid [9] \n0.62 \n0.76 \n0.75 \n0.73 \nCityScapes [15] \n0.62 \n0.88 \n0.92 \n0.93 \n-\nIDD [62] \n0.57 \n0.80 \n0.87 \n0.90 \nBDD [73] \n0.77 \n0.85 \n0.93 \n0.90 \nMVD [44] \n0.58 \n0.65 \n0.72 \n0.66 \n-\n-\n-\n-\nISPRS [54] \n0.26 \n0.08 \n0.52 \n0.66 \n-\n-\niSAID [65, 68] \n0.35 \n0.36 \n0.13 \n0.27 \n-\n-\nSUN RGB-D [59] \n0.53 \n0.52 \n0.61 \n0.57 \n-\n-\n-\nScanNet [17] \n0.43 \n0.71 \n0.65 \n0.61 \n-\n-\n-\nSUIM [31] \n0.39 \n0.27 \n0.64 \n0.58 \n-\nvKITTI2 [10, 22] \n0.70 \n0.65 \n0.73 \n0.64 \n-\nvGallery [66] \n0.40 \n0.44 \n0.50 \n0.27 \n-\n-\n-\n-\nAverage \n0.45 \n0.53 \n0.63 \n0.59 \n0.41 0.47 \n0.59 \n0.65 \n\n\u03c4 w \nTop-1 \nSource Dataset \nIDS LEEP LogME GBC \nIDS LEEP LogME GBC \n[42] \n[47] \n[72] \nOurs \n[42] \n[47] \n[72] \nOurs \n\nPascal Context [43] \n0.53 \n0.78 \n0.01 \n0.72 \n-\n-\n-\nPascal VOC [20] \n0.34 \n0.52 \n0.06 \n0.69 \n-\n-\nADE20K [74] \n0.48 \n0.74 \n0.01 \n0.69 \n-\n-\nCOCO [11, 34, 39] \n0.12 \n0.66 \n0.15 \n0.73 \n-\n-\n-\n-\nKITTI [1] \n0.48 \n0.60 \n0.09 \n0.70 \n-\n-\n-\nCamVid [9] \n0.61 \n0.57 \n0.01 \n0.72 \n-\n-\n-\nCityScapes [15] \n0.38 \n0.57 \n0.17 \n0.74 \n-\n-\n-\nIDD [62] \n0.48 \n0.59 \n0.24 \n0.70 \n-\n-\n-\nBDD [73] \n0.55 \n0.69 \n0.12 \n0.74 \n-\n-\nMVD [44] \n0.58 \n0.63 \n0.21 \n0.68 \n-\n-\n-\n-\nISPRS [54] \n-0.10 0.59 \n0.09 \n0.69 \n-\n-\n-\niSAID [65, 68] \n0.30 \n0.73 \n0.02 \n0.79 \n-\nSUN RGB-D [59] \n0.40 \n0.54 \n0.06 \n0.62 \n-\nScanNet [17] \n0.40 \n0.59 \n0.05 \n0.60 \n-\nSUIM [31] \n0.32 \n0.61 \n0.11 \n0.72 \n-\n-\n-\nvKITTI2 [10, 22] \n0.61 \n0.62 \n0.17 \n0.71 \n-\n-\nvGallery [66] \n-0.01 0.52 \n-0.19 \n0.51 \n-\n-\n-\n-\nAverage \n0.36 \n0.62 \n0.08 \n0.69 \n0.41 0.24 \n0.00 \n0.76 \n\nLogMe -0.06 \n0.58 \n0.25 \n0.2 \n0.08 \n0.00 \n-0.19 \n0.34 \n0.15 \nH-score 0.06 \n0.59 \n0.45 \n0.16 \n-0.01 \n0.09 \n0.09 \n0.34 \n0.22 \nLEEP \n0.63 \n0.65 \n0.52 \n0.25 \n0.59 \n-0.46 \n0.40 \n0.55 \n0.39 \nGBC \n0.55 \n0.63 \n0.46 \n0.43 \n0.80 \n0.23 \n0.32 \n0.35 \n0.47 \n\n(a) Metric: Weighted Kendall Tau (\u03c4w) \n\nLogME -0.06 \n0.56 \n0.44 \n0.28 \n0.17 \n0.0 \n-0.17 \n0.50 \n0.22 \nH-score 0.17 \n0.54 \n0.56 \n0.28 \n0.06 \n0.13 \n0.0 \n0.50 \n0.28 \nLEEP \n0.5 \n0.5 \n0.56 \n0.28 \n0.39 \n-0.28 \n0.28 \n0.56 \n0.35 \nGBC \n0.44 \n0.39 \n0.50 \n0.22 \n0.67 \n0.17 \n0.17 \n0.39 \n0.37 \n\n(b) Metric: Kendall Tau (\u03c4 ) \n\nLogME 0.33 \n0.58 \n0.62 \n0.45 \n0.28 \n0.37 \n-0.14 \n0.54 \n0.38 \nH-score 0.37 \n0.52 \n0.83 \n0.35 \n0.25 \n-0.0 \n-0.01 \n0.78 \n0.39 \nLEEP \n0.28 \n0.12 \n0.81 \n0.03 \n0.48 \n-0.2 \n0.21 \n0.75 \n0.31 \nGBC \n0.40 \n0.45 \n0.81 \n0.49 \n0.44 \n0.57 \n0.27 \n0.77 \n0.52 \n\n(c) Metric: Pearson correlation coefficient (\u03c1) \n\n\n\nTable 6 .\n6Overview of results for transferability for source selection in image classification.Source \nLEEP LogME H-score GBC \n[47] \n[72] \n[4] \nOurs \n\nCIFAR-10 \nCUB'11 \n0.68 \n0.71 \n0.69 \n0.72 \nCIFAR-100 \n0.75 \n0.75 \n0.73 \n0.69 \nF-MNIST \n0.68 \n0.70 \n0.72 \n0.68 \nSUN \n0.73 \n0.75 \n0.72 \n0.67 \nImageNet \n0.68 \n0.68 \n0.69 \n0.71 \n\nCIFAR-100 \nCUB'11 \n0.90 \n0.29 \n0.59 \n0.90 \nCIFAR-10 \n0.92 \n0.29 \n0.88 \n0.92 \nF-MNIST \n0.88 \n0.24 \n0.26 \n0.88 \nSUN \n0.90 \n0.30 \n0.88 \n0.90 \nImageNet \n0.91 \n0.25 \n0.88 \n0.92 \n\nFashion-MNIST \nCUB'11 \n0.72 \n0.71 \n0.71 \n0.71 \nCIFAR-10 \n0.72 \n0.73 \n0.69 \n0.69 \nCIFAR-100 \n0.71 \n0.71 \n0.70 \n0.69 \nSUN \n0.71 \n0.71 \n0.69 \n0.71 \nImageNet \n0.72 \n0.71 \n0.69 \n0.70 \n\nCaltech-USCD Birds 2011 \nCIFAR-10 \n0.87 \n-0.59 \n0.83 \n0.86 \nCIFAR-100 \n0.87 \n-0.58 \n0.80 \n0.87 \nF-MNIST \n0.70 \n-0.50 \n0.51 \n0.69 \nSUN \n0.88 \n-0.60 \n0.80 \n0.88 \nImageNet \n0.89 \n-0.59 \n0.73 \n0.88 \n\nSUN-397 \nCUB'11 \n0.95 \n0.87 \n0.54 \n0.95 \nCIFAR-10 \n0.95 \n0.87 \n0.12 \n0.95 \nCIFAR-100 \n0.95 \n0.88 \n0.51 \n0.95 \nF-MNIST \n0.95 \n0.86 \n0.54 \n0.95 \nImageNet \n0.96 \n0.87 \n0.55 \n0.96 \n\nAverage \n0.82 \n0.40 \n0.66 \n0.82 \n\n(a) Weighted Kendall Tau (\u03c4w) \n\nLEEP LogME H-score GBC \n[47] \n[72] \n[4] \nOurs \n\nCIFAR-10 \n0.51 \n0.53 \n0.54 \n0.55 \n0.58 \n0.57 \n0.56 \n0.55 \n0.49 \n0.48 \n0.50 \n0.49 \n0.53 \n0.55 \n0.56 \n0.56 \n0.53 \n0.53 \n0.50 \n0.49 \n\nCIFAR-100 \n0.84 \n0.74 \n0.65 \n0.84 \n0.85 \n0.74 \n0.73 \n0.85 \n0.81 \n0.69 \n0.66 \n0.81 \n0.83 \n0.72 \n0.74 \n0.82 \n0.86 \n0.74 \n0.77 \n0.86 \n\nFashion-MNIST \n0.48 \n0.46 \n0.49 \n0.48 \n0.47 \n0.49 \n0.46 \n0.46 \n0.47 \n0.48 \n0.46 \n0.46 \n0.49 \n0.47 \n0.47 \n0.47 \n0.49 \n0.48 \n0.47 \n0.50 \n\nCaltech-USCD Birds 2011 \n0.79 \n-0.04 \n0.69 \n0.79 \n0.79 \n-0.02 \n0.67 \n0.80 \n0.33 \n-0.03 \n0.29 \n0.33 \n0.79 \n-0.04 \n0.67 \n0.78 \n0.82 \n-0.02 \n0.65 \n0.82 \n\nSUN-397 \n0.92 \n0.91 \n0.27 \n0.92 \n0.92 \n0.90 \n0.22 \n0.91 \n0.90 \n0.89 \n0.28 \n0.90 \n0.91 \n0.90 \n0.26 \n0.91 \n0.92 \n0.91 \n0.26 \n0.92 \n\n0.69 \n0.52 \n0.51 \n0.69 \n\n(b) Kendall Tau (\u03c4 ) \n\nLEEP LogME H-score GBC \n[47] \n[72] \n[4] \nOurs \n\nCIFAR-10 \n0.69 \n0.70 \n0.65 \n0.70 \n0.75 \n0.77 \n0.70 \n0.77 \n0.63 \n0.65 \n0.58 \n0.66 \n0.71 \n0.73 \n0.66 \n0.72 \n0.69 \n0.71 \n0.64 \n0.70 \n\nCIFAR-100 \n0.94 \n0.29 \n0.56 \n0.87 \n0.95 \n0.29 \n0.61 \n0.86 \n0.92 \n0.21 \n-0.29 \n0.85 \n0.95 \n0.19 \n0.56 \n0.87 \n0.95 \n0.25 \n0.58 \n0.82 \n\nFashion-MNIST \n0.63 \n0.64 \n0.60 \n0.61 \n0.61 \n0.62 \n0.57 \n0.59 \n0.61 \n0.62 \n0.56 \n0.59 \n0.63 \n0.63 \n0.59 \n0.60 \n0.62 \n0.63 \n0.59 \n0.60 \n\nCaltech-USCD Birds 2011 \n0.94 \n-0.75 \n0.87 \n0.77 \n0.94 \n-0.77 \n0.81 \n0.76 \n0.66 \n-0.68 \n0.24 \n0.43 \n0.95 \n-0.72 \n0.56 \n0.83 \n0.94 \n-0.77 \n0.76 \n0.75 \n\nSUN-397 \n0.92 \n0.91 \n0.27 \n0.92 \n0.92 \n0.90 \n0.22 \n0.91 \n0.90 \n0.89 \n0.28 \n0.90 \n0.91 \n0.90 \n0.26 \n0.91 \n0.92 \n0.91 \n0.26 \n0.92 \n\n0.82 \n0.36 \n0.54 \n0.75 \n\n(c) Pearson correlation coefficient (\u03c1) \n\n\n\nTable 7 .\n7Overview of results for transferability for target dataset transferability.\nLEEP & LogMe: github.com/thuml/LogME; H-score: git.io/J1WOr\n\nAugmented reality meets computer vision : Efficient data generation for urban driving scenes. Hassan Alhaija, Siva Mustikovela, Lars Mescheder, Andreas Geiger, Carsten Rother, International Journal of Computer Vision. 810Hassan Alhaija, Siva Mustikovela, Lars Mescheder, Andreas Geiger, and Carsten Rother. Augmented reality meets com- puter vision : Efficient data generation for urban driving scenes. International Journal of Computer Vision, 2018. 8, 10\n\nGeometric dataset distances via optimal transport. David Alvarez, -Melis , Nicolo Fusi, NeurIPS. 23David Alvarez-Melis and Nicolo Fusi. Geometric dataset distances via optimal transport. In NeurIPS, pages 21428- 21439, 2020. 2, 3\n\nFactors of transferability for a generic convnet representation. Hossein Azizpour, Ali Sharif Razavian, Josephine Sullivan, Atsuto Maki, Stefan Carlsson, TPAMI. 1Hossein Azizpour, Ali Sharif Razavian, Josephine Sullivan, Atsuto Maki, and Stefan Carlsson. Factors of transferability for a generic convnet representation. TPAMI, 2015. 1\n\nAn informationtheoretic approach to transferability in task transfer learning. Yajie Bao, Yang Li, Shao-Lun, Lin Huang, Lizhong Zhang, Amir Zheng, Leonidas Zamir, Guibas, IEEE Int. Conf. on Image Processing. 611Yajie Bao, Yang Li, Shao-Lun Huang, Lin Zhang, Lizhong Zheng, Amir Zamir, and Leonidas Guibas. An information- theoretic approach to transferability in task transfer learning. In IEEE Int. Conf. on Image Processing, pages 2309-2313, 2019. 1, 2, 3, 5, 6, 11\n\nAn informationtheoretic approach to transferability in task transfer learning. Yajie Bao, Yang Li, Shao-Lun, Lin Huang, Lizhong Zhang, Amir Zheng, Leonidas Zamir, Guibas, IEEE Int. Conf. on Image Processing. Yajie Bao, Yang Li, Shao-Lun Huang, Lin Zhang, Lizhong Zheng, Amir Zamir, and Leonidas Guibas. An information- theoretic approach to transferability in task transfer learning. In IEEE Int. Conf. on Image Processing, 2019. 8\n\nAnalysis of representations for domain adaptation. Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, NeurIPS. 2Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain adaptation. NeurIPS, 2007. 2\n\nAnalysis of representations for domain adaptation. Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, NeurIPS. Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations for domain adaptation. In NeurIPS, 2007. 2\n\nOn a measure of divergence between two multinomial populations. Anil Bhattacharyya, Indian Journal of Statistics. 3Anil Bhattacharyya. On a measure of divergence between two multinomial populations. Indian Journal of Statistics, 1946. 3\n\nSemantic object classes in video: A high-definition ground truth database. G J Brostow, J Fauqueur, R Cipolla, Patt. Rec. Letters. 30210G. J. Brostow, J. Fauqueur, and R. Cipolla. Semantic object classes in video: A high-definition ground truth database. Patt. Rec. Letters, 30(2):88-97, 2009. 7, 10\n\nVirtual kitti 2. arXiv. Yohann Cabon, Naila Murray, Martin Humenberger, 810Yohann Cabon, Naila Murray, and Martin Humenberger. Vir- tual kitti 2. arXiv, 2020. 8, 10\n\nCOCO-Stuff: Thing and stuff classes in context. Holger Caesar, Jasper Uijlings, Vittorio Ferrari, CVPR. 810Holger Caesar, Jasper Uijlings, and Vittorio Ferrari. COCO- Stuff: Thing and stuff classes in context. In CVPR, 2018. 8, 10\n\nDeeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. L-C Chen, G Papandreou, I Kokkinos, K Murphy, A L Yuille, TPAMI. 1L-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A.L. Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully con- nected crfs. TPAMI, 2018. 1\n\n. Fran\u00e7ois Chollet, Fran\u00e7ois Chollet et al. Keras. https://keras.io/ api/applications/, 2015. 5\n\nBest practices for fine-tuning visual classifiers to new domains. Brian Chu, Vashisht Madhavan, Oscar Beijbom, Judy Hoffman, Trevor Darrell, ECCV. Brian Chu, Vashisht Madhavan, Oscar Beijbom, Judy Hoff- man, and Trevor Darrell. Best practices for fine-tuning visual classifiers to new domains. In ECCV, 2016. 1\n\nThe cityscapes dataset for semantic urban scene understanding. M Cordts, M Omran, S Ramos, T Rehfeld, M Enzweiler, R Benenson, U Franke, S Roth, B Schiele, CVPR. 810M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele. The cityscapes dataset for semantic urban scene understanding. In CVPR, 2016. 8, 10\n\nLarge scale fine-grained categorization and domain-specific transfer learning. Yin Cui, Yang Song, Chen Sun, Andrew Howard, Serge Belongie, CVPR. Yin Cui, Yang Song, Chen Sun, Andrew Howard, and Serge Belongie. Large scale fine-grained categorization and domain-specific transfer learning. In CVPR, 2018. 2\n\nScanNet: Richly-annotated 3d reconstructions of indoor scenes. Angela Dai, Angel X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, Matthias Nie\u00dfner, CVPR. 810Angela Dai, Angel X. Chang, Manolis Savva, Maciej Hal- ber, Thomas Funkhouser, and Matthias Nie\u00dfner. ScanNet: Richly-annotated 3d reconstructions of indoor scenes. In CVPR, 2017. 8, 10\n\nFrustratingly easy domain adaptation. Hal Daum\u00e9, Iii , ACL. Hal Daum\u00e9 III. Frustratingly easy domain adaptation. In ACL, 2009. 2\n\nModel selection techniques: An overview. Jie Ding, Vahid Tarokh, Yuhong Yang, IEEE SPM. 2Jie Ding, Vahid Tarokh, and Yuhong Yang. Model selection techniques: An overview. IEEE SPM, 2018. 2\n\nThe PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results. M Everingham, L Van Gool, C K I Williams, J Winn, A Zisserman, 810M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object Classes Chal- lenge 2012 (VOC2012) Results, 2012. 8, 10\n\nIntroduction to statistical pattern recognition. Keinosuke Fukunaga, ElsevierKeinosuke Fukunaga. Introduction to statistical pattern recognition. Elsevier, 2013. 4\n\nYohann Cabon, and Eleonora Vig. Virtual worlds as proxy for multi-object tracking analysis. Adrien Gaidon, Qiao Wang, CVPR. 810Adrien Gaidon, Qiao Wang, Yohann Cabon, and Eleonora Vig. Virtual worlds as proxy for multi-object tracking anal- ysis. In CVPR, 2016. 8, 10\n\nFast R-CNN. R Girshick, ICCV. R. Girshick. Fast R-CNN. In ICCV, 2015. 1\n\nPiotr Doll\u00e1r, and Ross Girshick. Mask R-CNN. Kaiming He, Georgia Gkioxari, ICCV. Kaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Gir- shick. Mask R-CNN. In ICCV, 2017. 1\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR. 56Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 3, 5, 6\n\nIdentity mappings in deep residual networks. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, ECCV. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In ECCV, 2016. 5\n\nMobilenets: Efficient convolutional neural networks for mobile vision applications. G Andrew, Menglong Howard, Bo Zhu, Dmitry Chen, Weijun Kalenichenko, Tobias Wang, Marco Weyand, Hartwig Andreetto, Adam, Technical reportAndrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco An- dreetto, and Hartwig Adam. Mobilenets: Efficient convolu- tional neural networks for mobile vision applications. Tech- nical report, arXiv, 2017. 5\n\n. J Howard, J. Howard. Imagenette. github.com/fastai/imagenette/. 5\n\nLaurens Van Der Maaten, and Kilian Q. Weinberger. Densely connected convolutional networks. Gao Huang, Zhuang Liu, CVPR. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil- ian Q. Weinberger. Densely connected convolutional net- works. In CVPR, 2017. 5\n\nWhat makes imagenet good for transfer learning?. M Huh, P Agrawal, A A Efros, NeurIPS LSCVS workshop. M. Huh, P. Agrawal, and A.A. Efros. What makes imagenet good for transfer learning? In NeurIPS LSCVS workshop, 2016. 1\n\nSadman Sakib Enan, and Junaed Sattar. Semantic Segmentation of Underwater Imagery: Dataset and Benchmark. Md Jahidul Islam, Chelsey Edge, Yuyang Xiao, Peigen Luo, Muntaqim Mehtaz, Christopher Morse, IROS. 810Md Jahidul Islam, Chelsey Edge, Yuyang Xiao, Peigen Luo, Muntaqim Mehtaz, Christopher Morse, Sadman Sakib Enan, and Junaed Sattar. Semantic Segmentation of Underwater Imagery: Dataset and Benchmark. In IROS, 2020. 8, 10\n\nNovel dataset for fine-grained image categorization. Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, Li Fei-Fei, CVPR Workshops. Aditya Khosla, Nityananda Jayadevaprakash, Bangpeng Yao, and Li Fei-Fei. Novel dataset for fine-grained image categorization. In CVPR Workshops, 2011. 5\n\nDetecting change in data streams. Daniel Kifer, Shai Ben-David, Johannes Gehrke, VLDB. Daniel Kifer, Shai Ben-David, and Johannes Gehrke. Detect- ing change in data streams. In VLDB, 2004. 2\n\nPanoptic segmentation. A Kirillov, K He, R Girshick, C Rother, P Doll\u00e1r, CVPR. 810A. Kirillov, K. He, R. Girshick, C. Rother, and P. Doll\u00e1r. Panoptic segmentation. In CVPR, 2019. 8, 10\n\nDo better imagenet models transfer better. Simon Kornblith, Jonathon Shlens, Quoc V Le, CVPR. Simon Kornblith, Jonathon Shlens, and Quoc V Le. Do bet- ter imagenet models transfer better? In CVPR, 2019. 1\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, 56University of TorontoTechnical reportAlex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009. 5, 6\n\nMSeg: A composite dataset for multidomain semantic segmentation. John Lambert, Zhuang Liu, Ozan Sener, James Hays, Vladlen Koltun, CVPR. John Lambert, Zhuang Liu, Ozan Sener, James Hays, and Vladlen Koltun. MSeg: A composite dataset for multi- domain semantic segmentation. In CVPR, 2020. 8\n\nYandong Li, Xuhui Jia, Ruoxin Sang, Yukun Zhu, Bradley Green, Liqiang Wang, and Boqing Gong. Ranking neural checkpoints. In CVPR. 1Yandong Li, Xuhui Jia, Ruoxin Sang, Yukun Zhu, Bradley Green, Liqiang Wang, and Boqing Gong. Ranking neural checkpoints. In CVPR, pages 2663-2673, 2021. 1, 2\n\nMicrosoft COCO: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C Lawrence Zitnick, Piotr Doll\u00e1r, ECCV. 810Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Doll\u00e1r. Microsoft COCO: Common objects in context. In ECCV, 2014. 8, 10\n\nPhone clustering using the bhattacharyya distance. Brian Mak, Etienne Barnard, Proceeding of Fourth International Conference on Spoken Language Processing. IC-SLP'96. eeding of Fourth International Conference on Spoken Language essing. IC-SLP'96IEEE4Brian Mak and Etienne Barnard. Phone clustering using the bhattacharyya distance. In Proceeding of Fourth Inter- national Conference on Spoken Language Processing. IC- SLP'96, volume 4, pages 2005-2008. IEEE, 1996. 4\n\nDomain adaptation: Learning bounds and algorithms. Yishay Mansour, Mehryar Mohri, Afshin Rostamizadeh, COLT. Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds and algorithms. In COLT, 2009. 2\n\nFactors of influence for transfer learning across diverse appearance domains and task types. arXiv. Thomas Mensink, Jasper Uijlings, Alina Kuznetsova, Michael Gygli, Vittorio Ferrari, 10Thomas Mensink, Jasper Uijlings, Alina Kuznetsova, Michael Gygli, and Vittorio Ferrari. Factors of influence for transfer learning across diverse appearance domains and task types. arXiv, 2021. 1, 2, 7, 8, 10\n\nThe role of context for object detection and semantic segmentation in the wild. R Mottaghi, X Chen, X Liu, N.-G Cho, S.-W Lee, S Fidler, R Urtasun, A Yuille, CVPR. 810R. Mottaghi, X. Chen, X. Liu, N.-G. Cho, S.-W. Lee, S. Fi- dler, R. Urtasun, and A. Yuille. The role of context for object detection and semantic segmentation in the wild. In CVPR, 2014. 8, 10\n\nThe mapillary vistas dataset for semantic understanding of street scenes. Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bul\u00f2, Peter Kontschieder, ICCV. 810Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bul\u00f2, and Peter Kontschieder. The mapillary vistas dataset for semantic understanding of street scenes. In ICCV, 2017. 8, 10\n\nStacked hourglass networks for human pose estimation. Alejandro Newell, Kaiyu Yang, Jia Deng, ECCV. Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hour- glass networks for human pose estimation. In ECCV, 2016. 1\n\nDomain adaptive transfer learning with specialist models. Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith, Quoc V Le, Ruoming Pang, arXivJiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Korn- blith, Quoc V. Le, and Ruoming Pang. Domain adaptive transfer learning with specialist models. Technical report, arXiv, 2018. 1\n\nLEEP: A new measure to evaluate transferability of learned representations. Cuong Nguyen, Tal Hassner, Matthias Seeger, Cedric Archambeau, ICML. 1011Cuong Nguyen, Tal Hassner, Matthias Seeger, and Cedric Archambeau. LEEP: A new measure to evaluate transfer- ability of learned representations. In ICML, 2020. 1, 2, 3, 5, 6, 7, 8, 10, 11\n\nAutomated flower classification over a large number of classes. Maria-Elena Nilsback, Andrew Zisserman, Indian Conf. on CVGIP. Maria-Elena Nilsback and Andrew Zisserman. Automated flower classification over a large number of classes. In Indian Conf. on CVGIP, 2008. 5\n\nDomain adaptation via transfer component analysis. Ivor W Sinno Jialin Pan, James T Tsang, Qiang Kwok, Yang, IEEE Trans. on Neural Networks. 2Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang. Domain adaptation via transfer component analysis. IEEE Trans. on Neural Networks, pages 199-210, 2010. 2\n\nA survey on transfer learning. Qiang Sinno Jialin Pan, Yang, IEEE Trans. KDE. 2Sinno Jialin Pan and Qiang Yang. A survey on transfer learn- ing. IEEE Trans. KDE, 2009. 2\n\nCats and dogs. O M Parkhi, A Vedaldi, A Zisserman, C V Jawahar, CVPR. O. M. Parkhi, A. Vedaldi, A. Zisserman, and CV Jawahar. Cats and dogs. In CVPR, 2012. 5\n\nModel evaluation, model selection, and algorithm selection in machine learning. Sebastian Raschka, arXiv. 2Technical reportSebastian Raschka. Model evaluation, model selection, and algorithm selection in machine learning. Technical report, arXiv, 2018. 2\n\nU-Net: Convolutional networks for biomedical image segmentation. O Ronneberger, P Fischer, T Brox, MIC-CAIO. Ronneberger, P. Fischer, and T. Brox. U-Net: Convolu- tional networks for biomedical image segmentation. In MIC- CAI, 2015. 1\n\nResults of the ISPRS benchmark on urban object detection and 3d building reconstruction. Franz Rottensteiner, Gunho Sohn, Markus Gerke, Jan Dirk Wegner, Uwe Breitkopf, Jaewook Jung, ISPRS Journal of Photogrammetry and Remote Sensing. 810Franz Rottensteiner, Gunho Sohn, Markus Gerke, Jan Dirk Wegner, Uwe Breitkopf, and Jaewook Jung. Results of the ISPRS benchmark on urban object detection and 3d build- ing reconstruction. ISPRS Journal of Photogrammetry and Remote Sensing, 2014. 8, 10\n\n. O Russakovsky, J Deng, H Su, J Krause, S Satheesh, S Ma, Z Huang, A Karpathy, A Khosla, M Bernstein, A Berg, L Fei-Fei, ImageNet large scale visual recognition challenge. IJCV, 2015. 1, 3, 6O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. Berg, and L. Fei-Fei. ImageNet large scale visual recognition challenge. IJCV, 2015. 1, 3, 6\n\nMark Sandler, Andrew G Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen, Mobilenetv2: Inverted residuals and linear bottleneck. Mark Sandler, Andrew G. Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottleneck. In CVPR, 2018. 5\n\nFully convolutional networks for semantic segmentation. E Shelhamer, J Long, T Darrell, TPAMI. 1E. Shelhamer, J. Long, and T. Darrell. Fully convolutional networks for semantic segmentation. TPAMI, 2016. 1\n\nVery deep convolutional networks for large-scale image recognition. K Simonyan, A Zisserman, ICLR. K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015. 3\n\nSUN RGB-D: A RGB-D scene understanding benchmark suite. S Song, S Lichtenberg, J Xiao, CVPR. 810S. Song, S. Lichtenberg, and J. Xiao. SUN RGB-D: A RGB- D scene understanding benchmark suite. In CVPR, 2015. 8, 10\n\nOtce: A transferability metric for cross-domain cross-task representations. Yang Tan, Yang Li, Shao-Lun Huang, CVPR, 2021. 1. 23Yang Tan, Yang Li, and Shao-Lun Huang. Otce: A transfer- ability metric for cross-domain cross-task representations. In CVPR, 2021. 1, 2, 3\n\nTransferability and hardness of supervised classification tasks. Anh T Tran, V Cuong, Tal Nguyen, Hassner, ICCV. 1Anh T Tran, Cuong V Nguyen, and Tal Hassner. Transfer- ability and hardness of supervised classification tasks. In ICCV, 2019. 1, 2\n\nIdd: A dataset for exploring problems of autonomous navigation in unconstrained environments. Girish Varma, Anbumani Subramanian, Anoop Namboodiri, Manmohan Chandraker, C V Jawahar, Proc. WACV. WACV810Girish Varma, Anbumani Subramanian, Anoop Namboodiri, Manmohan Chandraker, and C.V. Jawahar. Idd: A dataset for exploring problems of autonomous navigation in uncon- strained environments. In Proc. WACV, 2019. 8, 10\n\nThe Caltech-UCSD Birds-200-2011 Dataset. C Wah, S Branson, P Welinder, P Perona, S Belongie, CNS-TR-2011-00146California Institute of TechnologyTechnical ReportC. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The Caltech-UCSD Birds-200-2011 Dataset. Technical Re- port CNS-TR-2011-001, California Institute of Technology, 2011. 4, 5, 6\n\nDeep high-resolution representation learning for visual recognition. TPAMI. J Wang, K Sun, T Cheng, B Jiang, C Deng, Y Zhao, D Liu, Y Mu, M Tan, X Wang, W Liu, B Xiao, J. Wang, K. Sun, T. Cheng, B. Jiang, C. Deng, Y. Zhao, D. Liu, Y. Mu, M. Tan, X. Wang, W. Liu, and B. Xiao. Deep high-resolution representation learning for visual recogni- tion. TPAMI, 2020. 8\n\nGui-Song Xia, and Xiang Bai. isaid: A large-scale dataset for instance segmentation in aerial images. Aditya Syed Waqas Zamir, Akshita Arora, Salman Gupta, Guolei Khan, Sun, Fan Fahad Shahbaz Khan, Ling Zhu, Shao, CVPR Workshops. 810Syed Waqas Zamir, Aditya Arora, Akshita Gupta, Salman Khan, Guolei Sun, Fahad Shahbaz Khan, Fan Zhu, Ling Shao, Gui-Song Xia, and Xiang Bai. isaid: A large-scale dataset for instance segmentation in aerial images. In CVPR Workshops, 2019. 8, 10\n\nVisual localization by learning objects-of-interest dense match regression. Philippe Weinzaepfel, Gabriela Csurka, Yohann Cabon, Martin Humenberger, CVPR. 810Philippe Weinzaepfel, Gabriela Csurka, Yohann Cabon, and Martin Humenberger. Visual localization by learning objects-of-interest dense match regression. In CVPR, 2019. 8, 10\n\nA survey of transfer learning. Karl Weiss, M Taghi, Dingding Khoshgoftaar, Wang, Journal of Big data. 31Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. A survey of transfer learning. Journal of Big data, 3(1):1-40, 2016. 2\n\nDOTA: A large-scale dataset for object detection in aerial images. Gui-Song Xia, Xiang Bai, Jian Ding, Zhen Zhu, Serge Belongie, Jiebo Luo, Mihai Datcu, Marcello Pelillo, Liangpei Zhang, In CVPR. 810Gui-Song Xia, Xiang Bai, Jian Ding, Zhen Zhu, Serge Be- longie, Jiebo Luo, Mihai Datcu, Marcello Pelillo, and Liang- pei Zhang. DOTA: A large-scale dataset for object detection in aerial images. In CVPR, 2018. 8, 10\n\nFashionmnist: a novel image dataset for benchmarking machine learning algorithms. Han Xiao, Kashif Rasul, Roland Vollgraf, Technical reportHan Xiao, Kashif Rasul, and Roland Vollgraf. Fashion- mnist: a novel image dataset for benchmarking machine learning algorithms. Technical report, ArXiV, 2017. 6\n\nSUN database: Large-scale scene recognition from Abbey to Zoo. J Xiao, J Hays, K Ehinger, A Oliva, A Torralba, CVPR. 56J. Xiao, J. Hays, K. Ehinger, A. Oliva, and A. Torralba. SUN database: Large-scale scene recognition from Abbey to Zoo. In CVPR, 2010. 5, 6\n\nNeural data server: A large-scale search engine for transfer learning data. Xi Yan, David Acuna, Sanja Fidler, CVPR. 2020Xi Yan, David Acuna, and Sanja Fidler. Neural data server: A large-scale search engine for transfer learning data. In CVPR, 2020. 1\n\nLogME: Practical assessment of pre-trained models for transfer learning. Kaichao You, Yong Liu, Jianmin Wang, Mingsheng Long, ICML. 1011Kaichao You, Yong Liu, Jianmin Wang, and Mingsheng Long. LogME: Practical assessment of pre-trained models for transfer learning. In ICML, 2021. 1, 2, 3, 5, 6, 8, 9, 10, 11\n\nVashisht Madhavan, and Trevor Darrell. Bdd100k: A diverse driving dataset for heterogeneous multitask learning. Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, CVPR, 2020. 710Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, Vashisht Madhavan, and Trevor Dar- rell. Bdd100k: A diverse driving dataset for heterogeneous multitask learning. In CVPR, 2020. 7, 10\n\nScene parsing through ADE20K dataset. B Zhou, H Zhao, X Puig, S Fidler, A Barriuso, A Torralba, CVPR. 710B. Zhou, H. Zhao, X. Puig, S. Fidler, A. Barriuso, and A. Torralba. Scene parsing through ADE20K dataset. In CVPR, 2017. 7, 10\n\nObjects as points. Xingyi Zhou, Dequan Wang, Philipp Kr\u00e4henb\u00fchl, arXiv. Xingyi Zhou, Dequan Wang, and Philipp Kr\u00e4henb\u00fchl. Ob- jects as points. In arXiv, 2019. 1\n", "annotations": {"author": "[{\"end\":123,\"start\":69},{\"end\":184,\"start\":124},{\"end\":219,\"start\":185},{\"end\":279,\"start\":220},{\"end\":332,\"start\":280}]", "publisher": null, "author_last_name": "[{\"end\":81,\"start\":76},{\"end\":142,\"start\":131},{\"end\":200,\"start\":192},{\"end\":236,\"start\":229},{\"end\":294,\"start\":287}]", "author_first_name": "[{\"end\":75,\"start\":69},{\"end\":130,\"start\":124},{\"end\":191,\"start\":185},{\"end\":228,\"start\":220},{\"end\":286,\"start\":280}]", "author_affiliation": "[{\"end\":122,\"start\":106},{\"end\":183,\"start\":167},{\"end\":218,\"start\":202},{\"end\":278,\"start\":262},{\"end\":331,\"start\":315}]", "title": "[{\"end\":66,\"start\":1},{\"end\":398,\"start\":333}]", "venue": null, "abstract": "[{\"end\":1762,\"start\":400}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b54\"},\"end\":2028,\"start\":2024},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2076,\"start\":2073},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2079,\"start\":2076},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2082,\"start\":2079},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2085,\"start\":2082},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2088,\"start\":2085},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2091,\"start\":2088},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":2094,\"start\":2091},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":2097,\"start\":2094},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2184,\"start\":2180},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2187,\"start\":2184},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2190,\"start\":2187},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":2193,\"start\":2190},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2226,\"start\":2222},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":2229,\"start\":2226},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":2232,\"start\":2229},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3031,\"start\":3028},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3034,\"start\":3031},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3037,\"start\":3034},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":3040,\"start\":3037},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":3043,\"start\":3040},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":3046,\"start\":3043},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4811,\"start\":4808},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":4814,\"start\":4811},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":4817,\"start\":4814},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":4820,\"start\":4817},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":4823,\"start\":4820},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":4826,\"start\":4823},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":5128,\"start\":5124},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":5140,\"start\":5136},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5153,\"start\":5150},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":5750,\"start\":5746},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":5762,\"start\":5758},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5779,\"start\":5776},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5865,\"start\":5861},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":5868,\"start\":5865},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5905,\"start\":5901},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":5908,\"start\":5905},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5933,\"start\":5930},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5936,\"start\":5933},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":5939,\"start\":5936},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6148,\"start\":6145},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6151,\"start\":6148},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6154,\"start\":6151},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6310,\"start\":6307},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6629,\"start\":6625},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":6632,\"start\":6629},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":6677,\"start\":6673},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":6690,\"start\":6686},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":6814,\"start\":6810},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":7067,\"start\":7063},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7856,\"start\":7852},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7987,\"start\":7984},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":8142,\"start\":8138},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":8386,\"start\":8382},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8922,\"start\":8919},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":8925,\"start\":8922},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9181,\"start\":9178},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":9350,\"start\":9346},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10712,\"start\":10708},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":10726,\"start\":10722},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":10841,\"start\":10837},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11088,\"start\":11085},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":11103,\"start\":11099},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11205,\"start\":11202},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":11208,\"start\":11205},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":11293,\"start\":11289},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":11523,\"start\":11519},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":12094,\"start\":12090},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13523,\"start\":13520},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15430,\"start\":15426},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":15433,\"start\":15430},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":16527,\"start\":16523},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":17798,\"start\":17794},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":18082,\"start\":18078},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":18296,\"start\":18292},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":18313,\"start\":18309},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":18336,\"start\":18332},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":18375,\"start\":18371},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":18395,\"start\":18391},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":18420,\"start\":18416},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":18438,\"start\":18434},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":18511,\"start\":18507},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":18529,\"start\":18525},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":18577,\"start\":18573},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":18593,\"start\":18589},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":18615,\"start\":18611},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18643,\"start\":18639},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18960,\"start\":18957},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18971,\"start\":18967},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":18986,\"start\":18982},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":21936,\"start\":21932},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":22179,\"start\":22175},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":22244,\"start\":22240},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":22264,\"start\":22260},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":22397,\"start\":22393},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":22417,\"start\":22413},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":22430,\"start\":22426},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":22462,\"start\":22458},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":22758,\"start\":22754},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":23987,\"start\":23983},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":25826,\"start\":25822},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":26023,\"start\":26019},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":26033,\"start\":26029},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26045,\"start\":26042},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":26062,\"start\":26058},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":26073,\"start\":26069},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26076,\"start\":26073},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":26079,\"start\":26076},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":26089,\"start\":26085},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":26101,\"start\":26097},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":26104,\"start\":26101},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":26116,\"start\":26112},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":26127,\"start\":26124},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":26143,\"start\":26139},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":26164,\"start\":26160},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26181,\"start\":26177},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26195,\"start\":26191},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26206,\"start\":26202},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":26222,\"start\":26218},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":26237,\"start\":26233},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26255,\"start\":26251},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":26258,\"start\":26255},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":26270,\"start\":26266},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":26536,\"start\":26532},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":26819,\"start\":26815},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":26923,\"start\":26919},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":26949,\"start\":26945},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":26952,\"start\":26949},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":28948,\"start\":28944},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":29421,\"start\":29417},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":31102,\"start\":31098},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":31113,\"start\":31109},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31130,\"start\":31127},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":31956,\"start\":31952}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":34979,\"start\":34722},{\"attributes\":{\"id\":\"fig_2\"},\"end\":35008,\"start\":34980},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35137,\"start\":35009},{\"attributes\":{\"id\":\"fig_4\"},\"end\":35301,\"start\":35138},{\"attributes\":{\"id\":\"fig_5\"},\"end\":35444,\"start\":35302},{\"attributes\":{\"id\":\"fig_6\"},\"end\":35643,\"start\":35445},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":36470,\"start\":35644},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36899,\"start\":36471},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":39891,\"start\":36900},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42585,\"start\":39892},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":42673,\"start\":42586}]", "paragraph": "[{\"end\":2306,\"start\":1778},{\"end\":2945,\"start\":2324},{\"end\":4656,\"start\":2947},{\"end\":5228,\"start\":4658},{\"end\":5780,\"start\":5230},{\"end\":6086,\"start\":5797},{\"end\":6633,\"start\":6108},{\"end\":6666,\"start\":6635},{\"end\":7604,\"start\":6668},{\"end\":8786,\"start\":7606},{\"end\":9697,\"start\":8809},{\"end\":10050,\"start\":9729},{\"end\":10624,\"start\":10052},{\"end\":10842,\"start\":10626},{\"end\":11294,\"start\":10844},{\"end\":11524,\"start\":11326},{\"end\":12095,\"start\":11526},{\"end\":12631,\"start\":12097},{\"end\":13459,\"start\":12654},{\"end\":13706,\"start\":13490},{\"end\":14024,\"start\":13787},{\"end\":14196,\"start\":14158},{\"end\":14501,\"start\":14209},{\"end\":14918,\"start\":14766},{\"end\":15126,\"start\":14963},{\"end\":15671,\"start\":15128},{\"end\":15729,\"start\":15700},{\"end\":16253,\"start\":15731},{\"end\":16545,\"start\":16280},{\"end\":17326,\"start\":16547},{\"end\":17508,\"start\":17342},{\"end\":17576,\"start\":17557},{\"end\":18237,\"start\":17578},{\"end\":18439,\"start\":18239},{\"end\":18893,\"start\":18441},{\"end\":18990,\"start\":18895},{\"end\":20307,\"start\":18992},{\"end\":20917,\"start\":20309},{\"end\":21415,\"start\":20919},{\"end\":21704,\"start\":21417},{\"end\":22106,\"start\":21768},{\"end\":22645,\"start\":22108},{\"end\":23681,\"start\":22647},{\"end\":23989,\"start\":23683},{\"end\":24458,\"start\":23991},{\"end\":25665,\"start\":24460},{\"end\":25726,\"start\":25707},{\"end\":26484,\"start\":25728},{\"end\":26783,\"start\":26486},{\"end\":26994,\"start\":26785},{\"end\":27401,\"start\":26996},{\"end\":27909,\"start\":27403},{\"end\":28602,\"start\":27929},{\"end\":28912,\"start\":28604},{\"end\":29189,\"start\":28941},{\"end\":29826,\"start\":29191},{\"end\":30616,\"start\":29828},{\"end\":31304,\"start\":30631},{\"end\":31413,\"start\":31339},{\"end\":32113,\"start\":31415},{\"end\":32621,\"start\":32115},{\"end\":32905,\"start\":32665},{\"end\":33170,\"start\":32907},{\"end\":33520,\"start\":33172},{\"end\":34134,\"start\":33570},{\"end\":34721,\"start\":34185}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13750,\"start\":13707},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14157,\"start\":14025},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14580,\"start\":14502},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14765,\"start\":14580},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14962,\"start\":14919}]", "table_ref": "[{\"end\":28956,\"start\":28949}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1776,\"start\":1764},{\"end\":2322,\"start\":2309},{\"attributes\":{\"n\":\"2.\"},\"end\":5795,\"start\":5783},{\"end\":6106,\"start\":6089},{\"end\":8807,\"start\":8789},{\"attributes\":{\"n\":\"3.\"},\"end\":9706,\"start\":9700},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9727,\"start\":9709},{\"end\":11324,\"start\":11297},{\"attributes\":{\"n\":\"3.2.\"},\"end\":12652,\"start\":12634},{\"end\":13488,\"start\":13462},{\"end\":13785,\"start\":13752},{\"end\":14207,\"start\":14199},{\"attributes\":{\"n\":\"3.3.\"},\"end\":15698,\"start\":15674},{\"end\":16278,\"start\":16256},{\"attributes\":{\"n\":\"4.\"},\"end\":17340,\"start\":17329},{\"attributes\":{\"n\":\"4.1.\"},\"end\":17555,\"start\":17511},{\"attributes\":{\"n\":\"4.2.\"},\"end\":21766,\"start\":21707},{\"attributes\":{\"n\":\"4.3.\"},\"end\":25705,\"start\":25668},{\"end\":27927,\"start\":27912},{\"end\":28939,\"start\":28915},{\"attributes\":{\"n\":\"5.\"},\"end\":30629,\"start\":30619},{\"end\":31337,\"start\":31307},{\"end\":32663,\"start\":32624},{\"end\":33568,\"start\":33523},{\"end\":34183,\"start\":34137},{\"end\":34733,\"start\":34723},{\"end\":35020,\"start\":35010},{\"end\":35149,\"start\":35139},{\"end\":35313,\"start\":35303},{\"end\":35456,\"start\":35446},{\"end\":39902,\"start\":39893},{\"end\":42596,\"start\":42587}]", "table": "[{\"end\":36470,\"start\":36225},{\"end\":39891,\"start\":37236},{\"end\":42585,\"start\":39989}]", "figure_caption": "[{\"end\":34979,\"start\":34735},{\"end\":35008,\"start\":34982},{\"end\":35137,\"start\":35022},{\"end\":35301,\"start\":35151},{\"end\":35444,\"start\":35315},{\"end\":35643,\"start\":35458},{\"end\":36225,\"start\":35646},{\"end\":36899,\"start\":36473},{\"end\":37236,\"start\":36902},{\"end\":39989,\"start\":39904},{\"end\":42673,\"start\":42598}]", "figure_ref": "[{\"end\":2409,\"start\":2401},{\"end\":3752,\"start\":3744},{\"end\":12309,\"start\":12301},{\"end\":12890,\"start\":12884},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19631,\"start\":19625},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19914,\"start\":19908},{\"end\":23253,\"start\":23245},{\"end\":25331,\"start\":25325},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":33066,\"start\":33060},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":33373,\"start\":33367},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":34361,\"start\":34355},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":34381,\"start\":34373}]", "bib_author_first_name": "[{\"end\":42835,\"start\":42829},{\"end\":42849,\"start\":42845},{\"end\":42867,\"start\":42863},{\"end\":42886,\"start\":42879},{\"end\":42902,\"start\":42895},{\"end\":43249,\"start\":43244},{\"end\":43265,\"start\":43259},{\"end\":43274,\"start\":43268},{\"end\":43496,\"start\":43489},{\"end\":43510,\"start\":43507},{\"end\":43537,\"start\":43528},{\"end\":43554,\"start\":43548},{\"end\":43567,\"start\":43561},{\"end\":43844,\"start\":43839},{\"end\":43854,\"start\":43850},{\"end\":43872,\"start\":43869},{\"end\":43887,\"start\":43880},{\"end\":43899,\"start\":43895},{\"end\":43915,\"start\":43907},{\"end\":44313,\"start\":44308},{\"end\":44323,\"start\":44319},{\"end\":44341,\"start\":44338},{\"end\":44356,\"start\":44349},{\"end\":44368,\"start\":44364},{\"end\":44384,\"start\":44376},{\"end\":44717,\"start\":44713},{\"end\":44733,\"start\":44729},{\"end\":44747,\"start\":44743},{\"end\":44765,\"start\":44757},{\"end\":44975,\"start\":44971},{\"end\":44991,\"start\":44987},{\"end\":45005,\"start\":45001},{\"end\":45023,\"start\":45015},{\"end\":45248,\"start\":45244},{\"end\":45494,\"start\":45493},{\"end\":45496,\"start\":45495},{\"end\":45507,\"start\":45506},{\"end\":45519,\"start\":45518},{\"end\":45749,\"start\":45743},{\"end\":45762,\"start\":45757},{\"end\":45777,\"start\":45771},{\"end\":45939,\"start\":45933},{\"end\":45954,\"start\":45948},{\"end\":45973,\"start\":45965},{\"end\":46233,\"start\":46230},{\"end\":46241,\"start\":46240},{\"end\":46255,\"start\":46254},{\"end\":46267,\"start\":46266},{\"end\":46277,\"start\":46276},{\"end\":46279,\"start\":46278},{\"end\":46504,\"start\":46496},{\"end\":46662,\"start\":46657},{\"end\":46676,\"start\":46668},{\"end\":46692,\"start\":46687},{\"end\":46706,\"start\":46702},{\"end\":46722,\"start\":46716},{\"end\":46967,\"start\":46966},{\"end\":46977,\"start\":46976},{\"end\":46986,\"start\":46985},{\"end\":46995,\"start\":46994},{\"end\":47006,\"start\":47005},{\"end\":47019,\"start\":47018},{\"end\":47031,\"start\":47030},{\"end\":47041,\"start\":47040},{\"end\":47049,\"start\":47048},{\"end\":47341,\"start\":47338},{\"end\":47351,\"start\":47347},{\"end\":47362,\"start\":47358},{\"end\":47374,\"start\":47368},{\"end\":47388,\"start\":47383},{\"end\":47636,\"start\":47630},{\"end\":47647,\"start\":47642},{\"end\":47649,\"start\":47648},{\"end\":47664,\"start\":47657},{\"end\":47678,\"start\":47672},{\"end\":47693,\"start\":47687},{\"end\":47714,\"start\":47706},{\"end\":47960,\"start\":47957},{\"end\":47971,\"start\":47968},{\"end\":48093,\"start\":48090},{\"end\":48105,\"start\":48100},{\"end\":48120,\"start\":48114},{\"end\":48307,\"start\":48306},{\"end\":48321,\"start\":48320},{\"end\":48333,\"start\":48332},{\"end\":48337,\"start\":48334},{\"end\":48349,\"start\":48348},{\"end\":48357,\"start\":48356},{\"end\":48586,\"start\":48577},{\"end\":48791,\"start\":48785},{\"end\":48804,\"start\":48800},{\"end\":48975,\"start\":48974},{\"end\":49087,\"start\":49080},{\"end\":49099,\"start\":49092},{\"end\":49264,\"start\":49257},{\"end\":49276,\"start\":49269},{\"end\":49292,\"start\":49284},{\"end\":49302,\"start\":49298},{\"end\":49496,\"start\":49489},{\"end\":49508,\"start\":49501},{\"end\":49524,\"start\":49516},{\"end\":49534,\"start\":49530},{\"end\":49749,\"start\":49748},{\"end\":49766,\"start\":49758},{\"end\":49777,\"start\":49775},{\"end\":49789,\"start\":49783},{\"end\":49802,\"start\":49796},{\"end\":49823,\"start\":49817},{\"end\":49835,\"start\":49830},{\"end\":49851,\"start\":49844},{\"end\":50136,\"start\":50135},{\"end\":50297,\"start\":50294},{\"end\":50311,\"start\":50305},{\"end\":50510,\"start\":50509},{\"end\":50517,\"start\":50516},{\"end\":50528,\"start\":50527},{\"end\":50530,\"start\":50529},{\"end\":50798,\"start\":50788},{\"end\":50813,\"start\":50806},{\"end\":50826,\"start\":50820},{\"end\":50839,\"start\":50833},{\"end\":50853,\"start\":50845},{\"end\":50873,\"start\":50862},{\"end\":51170,\"start\":51164},{\"end\":51189,\"start\":51179},{\"end\":51215,\"start\":51207},{\"end\":51223,\"start\":51221},{\"end\":51443,\"start\":51437},{\"end\":51455,\"start\":51451},{\"end\":51475,\"start\":51467},{\"end\":51619,\"start\":51618},{\"end\":51631,\"start\":51630},{\"end\":51637,\"start\":51636},{\"end\":51649,\"start\":51648},{\"end\":51659,\"start\":51658},{\"end\":51829,\"start\":51824},{\"end\":51849,\"start\":51841},{\"end\":51864,\"start\":51858},{\"end\":52046,\"start\":52042},{\"end\":52292,\"start\":52288},{\"end\":52308,\"start\":52302},{\"end\":52318,\"start\":52314},{\"end\":52331,\"start\":52326},{\"end\":52345,\"start\":52338},{\"end\":52522,\"start\":52515},{\"end\":52532,\"start\":52527},{\"end\":52544,\"start\":52538},{\"end\":52556,\"start\":52551},{\"end\":52569,\"start\":52562},{\"end\":52856,\"start\":52848},{\"end\":52869,\"start\":52862},{\"end\":52882,\"start\":52877},{\"end\":52900,\"start\":52893},{\"end\":52914,\"start\":52910},{\"end\":52930,\"start\":52925},{\"end\":52943,\"start\":52937},{\"end\":52956,\"start\":52952},{\"end\":52967,\"start\":52966},{\"end\":52976,\"start\":52968},{\"end\":52991,\"start\":52986},{\"end\":53287,\"start\":53282},{\"end\":53300,\"start\":53293},{\"end\":53756,\"start\":53750},{\"end\":53773,\"start\":53766},{\"end\":53787,\"start\":53781},{\"end\":54039,\"start\":54033},{\"end\":54055,\"start\":54049},{\"end\":54071,\"start\":54066},{\"end\":54091,\"start\":54084},{\"end\":54107,\"start\":54099},{\"end\":54410,\"start\":54409},{\"end\":54422,\"start\":54421},{\"end\":54430,\"start\":54429},{\"end\":54440,\"start\":54436},{\"end\":54450,\"start\":54446},{\"end\":54457,\"start\":54456},{\"end\":54467,\"start\":54466},{\"end\":54478,\"start\":54477},{\"end\":54771,\"start\":54764},{\"end\":54787,\"start\":54781},{\"end\":54803,\"start\":54797},{\"end\":54808,\"start\":54804},{\"end\":54820,\"start\":54815},{\"end\":55078,\"start\":55069},{\"end\":55092,\"start\":55087},{\"end\":55102,\"start\":55099},{\"end\":55297,\"start\":55291},{\"end\":55310,\"start\":55305},{\"end\":55322,\"start\":55317},{\"end\":55339,\"start\":55334},{\"end\":55355,\"start\":55351},{\"end\":55357,\"start\":55356},{\"end\":55369,\"start\":55362},{\"end\":55646,\"start\":55641},{\"end\":55658,\"start\":55655},{\"end\":55676,\"start\":55668},{\"end\":55691,\"start\":55685},{\"end\":55978,\"start\":55967},{\"end\":55995,\"start\":55989},{\"end\":56227,\"start\":56223},{\"end\":56229,\"start\":56228},{\"end\":56253,\"start\":56248},{\"end\":56255,\"start\":56254},{\"end\":56268,\"start\":56263},{\"end\":56519,\"start\":56514},{\"end\":56670,\"start\":56669},{\"end\":56672,\"start\":56671},{\"end\":56682,\"start\":56681},{\"end\":56693,\"start\":56692},{\"end\":56706,\"start\":56705},{\"end\":56708,\"start\":56707},{\"end\":56902,\"start\":56893},{\"end\":57135,\"start\":57134},{\"end\":57150,\"start\":57149},{\"end\":57161,\"start\":57160},{\"end\":57399,\"start\":57394},{\"end\":57420,\"start\":57415},{\"end\":57433,\"start\":57427},{\"end\":57444,\"start\":57441},{\"end\":57449,\"start\":57445},{\"end\":57461,\"start\":57458},{\"end\":57480,\"start\":57473},{\"end\":57798,\"start\":57797},{\"end\":57813,\"start\":57812},{\"end\":57821,\"start\":57820},{\"end\":57827,\"start\":57826},{\"end\":57837,\"start\":57836},{\"end\":57849,\"start\":57848},{\"end\":57855,\"start\":57854},{\"end\":57864,\"start\":57863},{\"end\":57876,\"start\":57875},{\"end\":57886,\"start\":57885},{\"end\":57899,\"start\":57898},{\"end\":57907,\"start\":57906},{\"end\":58199,\"start\":58195},{\"end\":58215,\"start\":58209},{\"end\":58217,\"start\":58216},{\"end\":58234,\"start\":58226},{\"end\":58246,\"start\":58240},{\"end\":58269,\"start\":58258},{\"end\":58547,\"start\":58546},{\"end\":58560,\"start\":58559},{\"end\":58568,\"start\":58567},{\"end\":58766,\"start\":58765},{\"end\":58778,\"start\":58777},{\"end\":58969,\"start\":58968},{\"end\":58977,\"start\":58976},{\"end\":58992,\"start\":58991},{\"end\":59205,\"start\":59201},{\"end\":59215,\"start\":59211},{\"end\":59228,\"start\":59220},{\"end\":59472,\"start\":59471},{\"end\":59483,\"start\":59480},{\"end\":59741,\"start\":59735},{\"end\":59757,\"start\":59749},{\"end\":59776,\"start\":59771},{\"end\":59797,\"start\":59789},{\"end\":59811,\"start\":59810},{\"end\":59813,\"start\":59812},{\"end\":60101,\"start\":60100},{\"end\":60108,\"start\":60107},{\"end\":60119,\"start\":60118},{\"end\":60131,\"start\":60130},{\"end\":60141,\"start\":60140},{\"end\":60485,\"start\":60484},{\"end\":60493,\"start\":60492},{\"end\":60500,\"start\":60499},{\"end\":60509,\"start\":60508},{\"end\":60518,\"start\":60517},{\"end\":60526,\"start\":60525},{\"end\":60534,\"start\":60533},{\"end\":60541,\"start\":60540},{\"end\":60547,\"start\":60546},{\"end\":60554,\"start\":60553},{\"end\":60562,\"start\":60561},{\"end\":60569,\"start\":60568},{\"end\":60879,\"start\":60873},{\"end\":60905,\"start\":60898},{\"end\":60919,\"start\":60913},{\"end\":60933,\"start\":60927},{\"end\":60948,\"start\":60945},{\"end\":60973,\"start\":60969},{\"end\":61334,\"start\":61326},{\"end\":61356,\"start\":61348},{\"end\":61371,\"start\":61365},{\"end\":61385,\"start\":61379},{\"end\":61618,\"start\":61614},{\"end\":61627,\"start\":61626},{\"end\":61643,\"start\":61635},{\"end\":61887,\"start\":61879},{\"end\":61898,\"start\":61893},{\"end\":61908,\"start\":61904},{\"end\":61919,\"start\":61915},{\"end\":61930,\"start\":61925},{\"end\":61946,\"start\":61941},{\"end\":61957,\"start\":61952},{\"end\":61973,\"start\":61965},{\"end\":61991,\"start\":61983},{\"end\":62313,\"start\":62310},{\"end\":62326,\"start\":62320},{\"end\":62340,\"start\":62334},{\"end\":62594,\"start\":62593},{\"end\":62602,\"start\":62601},{\"end\":62610,\"start\":62609},{\"end\":62621,\"start\":62620},{\"end\":62630,\"start\":62629},{\"end\":62868,\"start\":62866},{\"end\":62879,\"start\":62874},{\"end\":62892,\"start\":62887},{\"end\":63124,\"start\":63117},{\"end\":63134,\"start\":63130},{\"end\":63147,\"start\":63140},{\"end\":63163,\"start\":63154},{\"end\":63472,\"start\":63466},{\"end\":63484,\"start\":63477},{\"end\":63494,\"start\":63491},{\"end\":63506,\"start\":63501},{\"end\":63521,\"start\":63513},{\"end\":63536,\"start\":63528},{\"end\":63808,\"start\":63807},{\"end\":63816,\"start\":63815},{\"end\":63824,\"start\":63823},{\"end\":63832,\"start\":63831},{\"end\":63842,\"start\":63841},{\"end\":63854,\"start\":63853},{\"end\":64027,\"start\":64021},{\"end\":64040,\"start\":64034},{\"end\":64054,\"start\":64047}]", "bib_author_last_name": "[{\"end\":42843,\"start\":42836},{\"end\":42861,\"start\":42850},{\"end\":42877,\"start\":42868},{\"end\":42893,\"start\":42887},{\"end\":42909,\"start\":42903},{\"end\":43257,\"start\":43250},{\"end\":43279,\"start\":43275},{\"end\":43505,\"start\":43497},{\"end\":43526,\"start\":43511},{\"end\":43546,\"start\":43538},{\"end\":43559,\"start\":43555},{\"end\":43576,\"start\":43568},{\"end\":43848,\"start\":43845},{\"end\":43857,\"start\":43855},{\"end\":43867,\"start\":43859},{\"end\":43878,\"start\":43873},{\"end\":43893,\"start\":43888},{\"end\":43905,\"start\":43900},{\"end\":43921,\"start\":43916},{\"end\":43929,\"start\":43923},{\"end\":44317,\"start\":44314},{\"end\":44326,\"start\":44324},{\"end\":44336,\"start\":44328},{\"end\":44347,\"start\":44342},{\"end\":44362,\"start\":44357},{\"end\":44374,\"start\":44369},{\"end\":44390,\"start\":44385},{\"end\":44398,\"start\":44392},{\"end\":44727,\"start\":44718},{\"end\":44741,\"start\":44734},{\"end\":44755,\"start\":44748},{\"end\":44773,\"start\":44766},{\"end\":44985,\"start\":44976},{\"end\":44999,\"start\":44992},{\"end\":45013,\"start\":45006},{\"end\":45031,\"start\":45024},{\"end\":45262,\"start\":45249},{\"end\":45504,\"start\":45497},{\"end\":45516,\"start\":45508},{\"end\":45527,\"start\":45520},{\"end\":45755,\"start\":45750},{\"end\":45769,\"start\":45763},{\"end\":45789,\"start\":45778},{\"end\":45946,\"start\":45940},{\"end\":45963,\"start\":45955},{\"end\":45981,\"start\":45974},{\"end\":46238,\"start\":46234},{\"end\":46252,\"start\":46242},{\"end\":46264,\"start\":46256},{\"end\":46274,\"start\":46268},{\"end\":46286,\"start\":46280},{\"end\":46512,\"start\":46505},{\"end\":46666,\"start\":46663},{\"end\":46685,\"start\":46677},{\"end\":46700,\"start\":46693},{\"end\":46714,\"start\":46707},{\"end\":46730,\"start\":46723},{\"end\":46974,\"start\":46968},{\"end\":46983,\"start\":46978},{\"end\":46992,\"start\":46987},{\"end\":47003,\"start\":46996},{\"end\":47016,\"start\":47007},{\"end\":47028,\"start\":47020},{\"end\":47038,\"start\":47032},{\"end\":47046,\"start\":47042},{\"end\":47057,\"start\":47050},{\"end\":47345,\"start\":47342},{\"end\":47356,\"start\":47352},{\"end\":47366,\"start\":47363},{\"end\":47381,\"start\":47375},{\"end\":47397,\"start\":47389},{\"end\":47640,\"start\":47637},{\"end\":47655,\"start\":47650},{\"end\":47670,\"start\":47665},{\"end\":47685,\"start\":47679},{\"end\":47704,\"start\":47694},{\"end\":47722,\"start\":47715},{\"end\":47966,\"start\":47961},{\"end\":48098,\"start\":48094},{\"end\":48112,\"start\":48106},{\"end\":48125,\"start\":48121},{\"end\":48318,\"start\":48308},{\"end\":48330,\"start\":48322},{\"end\":48346,\"start\":48338},{\"end\":48354,\"start\":48350},{\"end\":48367,\"start\":48358},{\"end\":48595,\"start\":48587},{\"end\":48798,\"start\":48792},{\"end\":48809,\"start\":48805},{\"end\":48984,\"start\":48976},{\"end\":49090,\"start\":49088},{\"end\":49108,\"start\":49100},{\"end\":49267,\"start\":49265},{\"end\":49282,\"start\":49277},{\"end\":49296,\"start\":49293},{\"end\":49306,\"start\":49303},{\"end\":49499,\"start\":49497},{\"end\":49514,\"start\":49509},{\"end\":49528,\"start\":49525},{\"end\":49538,\"start\":49535},{\"end\":49756,\"start\":49750},{\"end\":49773,\"start\":49767},{\"end\":49781,\"start\":49778},{\"end\":49794,\"start\":49790},{\"end\":49815,\"start\":49803},{\"end\":49828,\"start\":49824},{\"end\":49842,\"start\":49836},{\"end\":49861,\"start\":49852},{\"end\":49867,\"start\":49863},{\"end\":50143,\"start\":50137},{\"end\":50303,\"start\":50298},{\"end\":50315,\"start\":50312},{\"end\":50514,\"start\":50511},{\"end\":50525,\"start\":50518},{\"end\":50536,\"start\":50531},{\"end\":50804,\"start\":50799},{\"end\":50818,\"start\":50814},{\"end\":50831,\"start\":50827},{\"end\":50843,\"start\":50840},{\"end\":50860,\"start\":50854},{\"end\":50879,\"start\":50874},{\"end\":51177,\"start\":51171},{\"end\":51205,\"start\":51190},{\"end\":51219,\"start\":51216},{\"end\":51231,\"start\":51224},{\"end\":51449,\"start\":51444},{\"end\":51465,\"start\":51456},{\"end\":51482,\"start\":51476},{\"end\":51628,\"start\":51620},{\"end\":51634,\"start\":51632},{\"end\":51646,\"start\":51638},{\"end\":51656,\"start\":51650},{\"end\":51666,\"start\":51660},{\"end\":51839,\"start\":51830},{\"end\":51856,\"start\":51850},{\"end\":51867,\"start\":51865},{\"end\":52057,\"start\":52047},{\"end\":52300,\"start\":52293},{\"end\":52312,\"start\":52309},{\"end\":52324,\"start\":52319},{\"end\":52336,\"start\":52332},{\"end\":52352,\"start\":52346},{\"end\":52525,\"start\":52523},{\"end\":52536,\"start\":52533},{\"end\":52549,\"start\":52545},{\"end\":52560,\"start\":52557},{\"end\":52575,\"start\":52570},{\"end\":52860,\"start\":52857},{\"end\":52875,\"start\":52870},{\"end\":52891,\"start\":52883},{\"end\":52908,\"start\":52901},{\"end\":52923,\"start\":52915},{\"end\":52935,\"start\":52931},{\"end\":52950,\"start\":52944},{\"end\":52964,\"start\":52957},{\"end\":52984,\"start\":52977},{\"end\":52998,\"start\":52992},{\"end\":53291,\"start\":53288},{\"end\":53308,\"start\":53301},{\"end\":53764,\"start\":53757},{\"end\":53779,\"start\":53774},{\"end\":53800,\"start\":53788},{\"end\":54047,\"start\":54040},{\"end\":54064,\"start\":54056},{\"end\":54082,\"start\":54072},{\"end\":54097,\"start\":54092},{\"end\":54115,\"start\":54108},{\"end\":54419,\"start\":54411},{\"end\":54427,\"start\":54423},{\"end\":54434,\"start\":54431},{\"end\":54444,\"start\":54441},{\"end\":54454,\"start\":54451},{\"end\":54464,\"start\":54458},{\"end\":54475,\"start\":54468},{\"end\":54485,\"start\":54479},{\"end\":54779,\"start\":54772},{\"end\":54795,\"start\":54788},{\"end\":54813,\"start\":54809},{\"end\":54833,\"start\":54821},{\"end\":55085,\"start\":55079},{\"end\":55097,\"start\":55093},{\"end\":55107,\"start\":55103},{\"end\":55303,\"start\":55298},{\"end\":55315,\"start\":55311},{\"end\":55332,\"start\":55323},{\"end\":55349,\"start\":55340},{\"end\":55360,\"start\":55358},{\"end\":55374,\"start\":55370},{\"end\":55653,\"start\":55647},{\"end\":55666,\"start\":55659},{\"end\":55683,\"start\":55677},{\"end\":55702,\"start\":55692},{\"end\":55987,\"start\":55979},{\"end\":56005,\"start\":55996},{\"end\":56246,\"start\":56230},{\"end\":56261,\"start\":56256},{\"end\":56273,\"start\":56269},{\"end\":56279,\"start\":56275},{\"end\":56536,\"start\":56520},{\"end\":56542,\"start\":56538},{\"end\":56679,\"start\":56673},{\"end\":56690,\"start\":56683},{\"end\":56703,\"start\":56694},{\"end\":56716,\"start\":56709},{\"end\":56910,\"start\":56903},{\"end\":57147,\"start\":57136},{\"end\":57158,\"start\":57151},{\"end\":57166,\"start\":57162},{\"end\":57413,\"start\":57400},{\"end\":57425,\"start\":57421},{\"end\":57439,\"start\":57434},{\"end\":57456,\"start\":57450},{\"end\":57471,\"start\":57462},{\"end\":57485,\"start\":57481},{\"end\":57810,\"start\":57799},{\"end\":57818,\"start\":57814},{\"end\":57824,\"start\":57822},{\"end\":57834,\"start\":57828},{\"end\":57846,\"start\":57838},{\"end\":57852,\"start\":57850},{\"end\":57861,\"start\":57856},{\"end\":57873,\"start\":57865},{\"end\":57883,\"start\":57877},{\"end\":57896,\"start\":57887},{\"end\":57904,\"start\":57900},{\"end\":57915,\"start\":57908},{\"end\":58207,\"start\":58200},{\"end\":58224,\"start\":58218},{\"end\":58238,\"start\":58235},{\"end\":58256,\"start\":58247},{\"end\":58274,\"start\":58270},{\"end\":58557,\"start\":58548},{\"end\":58565,\"start\":58561},{\"end\":58576,\"start\":58569},{\"end\":58775,\"start\":58767},{\"end\":58788,\"start\":58779},{\"end\":58974,\"start\":58970},{\"end\":58989,\"start\":58978},{\"end\":58997,\"start\":58993},{\"end\":59209,\"start\":59206},{\"end\":59218,\"start\":59216},{\"end\":59234,\"start\":59229},{\"end\":59469,\"start\":59459},{\"end\":59478,\"start\":59473},{\"end\":59490,\"start\":59484},{\"end\":59499,\"start\":59492},{\"end\":59747,\"start\":59742},{\"end\":59769,\"start\":59758},{\"end\":59787,\"start\":59777},{\"end\":59808,\"start\":59798},{\"end\":59821,\"start\":59814},{\"end\":60105,\"start\":60102},{\"end\":60116,\"start\":60109},{\"end\":60128,\"start\":60120},{\"end\":60138,\"start\":60132},{\"end\":60150,\"start\":60142},{\"end\":60490,\"start\":60486},{\"end\":60497,\"start\":60494},{\"end\":60506,\"start\":60501},{\"end\":60515,\"start\":60510},{\"end\":60523,\"start\":60519},{\"end\":60531,\"start\":60527},{\"end\":60538,\"start\":60535},{\"end\":60544,\"start\":60542},{\"end\":60551,\"start\":60548},{\"end\":60559,\"start\":60555},{\"end\":60566,\"start\":60563},{\"end\":60574,\"start\":60570},{\"end\":60896,\"start\":60880},{\"end\":60911,\"start\":60906},{\"end\":60925,\"start\":60920},{\"end\":60938,\"start\":60934},{\"end\":60943,\"start\":60940},{\"end\":60967,\"start\":60949},{\"end\":60977,\"start\":60974},{\"end\":60983,\"start\":60979},{\"end\":61346,\"start\":61335},{\"end\":61363,\"start\":61357},{\"end\":61377,\"start\":61372},{\"end\":61397,\"start\":61386},{\"end\":61624,\"start\":61619},{\"end\":61633,\"start\":61628},{\"end\":61656,\"start\":61644},{\"end\":61662,\"start\":61658},{\"end\":61891,\"start\":61888},{\"end\":61902,\"start\":61899},{\"end\":61913,\"start\":61909},{\"end\":61923,\"start\":61920},{\"end\":61939,\"start\":61931},{\"end\":61950,\"start\":61947},{\"end\":61963,\"start\":61958},{\"end\":61981,\"start\":61974},{\"end\":61997,\"start\":61992},{\"end\":62318,\"start\":62314},{\"end\":62332,\"start\":62327},{\"end\":62349,\"start\":62341},{\"end\":62599,\"start\":62595},{\"end\":62607,\"start\":62603},{\"end\":62618,\"start\":62611},{\"end\":62627,\"start\":62622},{\"end\":62639,\"start\":62631},{\"end\":62872,\"start\":62869},{\"end\":62885,\"start\":62880},{\"end\":62899,\"start\":62893},{\"end\":63128,\"start\":63125},{\"end\":63138,\"start\":63135},{\"end\":63152,\"start\":63148},{\"end\":63168,\"start\":63164},{\"end\":63475,\"start\":63473},{\"end\":63489,\"start\":63485},{\"end\":63499,\"start\":63495},{\"end\":63511,\"start\":63507},{\"end\":63526,\"start\":63522},{\"end\":63540,\"start\":63537},{\"end\":63813,\"start\":63809},{\"end\":63821,\"start\":63817},{\"end\":63829,\"start\":63825},{\"end\":63839,\"start\":63833},{\"end\":63851,\"start\":63843},{\"end\":63863,\"start\":63855},{\"end\":64032,\"start\":64028},{\"end\":64045,\"start\":64041},{\"end\":64065,\"start\":64055}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":3731652},\"end\":43191,\"start\":42735},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":211066128},\"end\":43422,\"start\":43193},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":1846738},\"end\":43758,\"start\":43424},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":202782600},\"end\":44227,\"start\":43760},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":202782600},\"end\":44660,\"start\":44229},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":10908021},\"end\":44918,\"start\":44662},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":10908021},\"end\":45178,\"start\":44920},{\"attributes\":{\"id\":\"b7\"},\"end\":45416,\"start\":45180},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":10759568},\"end\":45717,\"start\":45418},{\"attributes\":{\"id\":\"b9\"},\"end\":45883,\"start\":45719},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":4396518},\"end\":46115,\"start\":45885},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":3429309},\"end\":46492,\"start\":46117},{\"attributes\":{\"id\":\"b12\"},\"end\":46589,\"start\":46494},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":10247639},\"end\":46901,\"start\":46591},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":502946},\"end\":47257,\"start\":46903},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":43993788},\"end\":47565,\"start\":47259},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":7684883},\"end\":47917,\"start\":47567},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":5360764},\"end\":48047,\"start\":47919},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":53035396},\"end\":48237,\"start\":48049},{\"attributes\":{\"id\":\"b19\"},\"end\":48526,\"start\":48239},{\"attributes\":{\"id\":\"b20\"},\"end\":48691,\"start\":48528},{\"attributes\":{\"id\":\"b21\"},\"end\":48960,\"start\":48693},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":206770307},\"end\":49033,\"start\":48962},{\"attributes\":{\"id\":\"b23\"},\"end\":49209,\"start\":49035},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":206594692},\"end\":49442,\"start\":49211},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":6447277},\"end\":49662,\"start\":49444},{\"attributes\":{\"id\":\"b26\"},\"end\":50131,\"start\":49664},{\"attributes\":{\"id\":\"b27\"},\"end\":50200,\"start\":50133},{\"attributes\":{\"id\":\"b28\"},\"end\":50458,\"start\":50202},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":7824159},\"end\":50680,\"start\":50460},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":214795113},\"end\":51109,\"start\":50682},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":3181866},\"end\":51401,\"start\":51111},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":52800392},\"end\":51593,\"start\":51403},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":4853375},\"end\":51779,\"start\":51595},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":43928547},\"end\":51985,\"start\":51781},{\"attributes\":{\"id\":\"b35\"},\"end\":52221,\"start\":51987},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":215541815},\"end\":52513,\"start\":52223},{\"attributes\":{\"id\":\"b37\"},\"end\":52803,\"start\":52515},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":14113767},\"end\":53229,\"start\":52805},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":177951},\"end\":53697,\"start\":53231},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":6178817},\"end\":53931,\"start\":53699},{\"attributes\":{\"id\":\"b41\"},\"end\":54327,\"start\":53933},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":6529084},\"end\":54688,\"start\":54329},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":5753855},\"end\":55013,\"start\":54690},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":13613792},\"end\":55231,\"start\":55015},{\"attributes\":{\"id\":\"b45\"},\"end\":55563,\"start\":55233},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":211572839},\"end\":55901,\"start\":55565},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":15193013},\"end\":56170,\"start\":55903},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":788838},\"end\":56481,\"start\":56172},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":740063},\"end\":56652,\"start\":56483},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":383200},\"end\":56811,\"start\":56654},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":49529756},\"end\":57067,\"start\":56813},{\"attributes\":{\"id\":\"b52\"},\"end\":57303,\"start\":57069},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":108438562},\"end\":57793,\"start\":57305},{\"attributes\":{\"id\":\"b54\"},\"end\":58193,\"start\":57795},{\"attributes\":{\"id\":\"b55\"},\"end\":58488,\"start\":58195},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":1629541},\"end\":58695,\"start\":58490},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":14124313},\"end\":58910,\"start\":58697},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":6242669},\"end\":59123,\"start\":58912},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":232352783},\"end\":59392,\"start\":59125},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":201303557},\"end\":59639,\"start\":59394},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":53759579},\"end\":60057,\"start\":59641},{\"attributes\":{\"doi\":\"CNS-TR-2011-001\",\"id\":\"b62\"},\"end\":60406,\"start\":60059},{\"attributes\":{\"id\":\"b63\"},\"end\":60769,\"start\":60408},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":170079084},\"end\":61248,\"start\":60771},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":195442998},\"end\":61581,\"start\":61250},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":740063},\"end\":61810,\"start\":61583},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":32378562},\"end\":62226,\"start\":61812},{\"attributes\":{\"id\":\"b68\"},\"end\":62528,\"start\":62228},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":1309931},\"end\":62788,\"start\":62530},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":210116785},\"end\":63042,\"start\":62790},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":231985863},\"end\":63352,\"start\":63044},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":215415900},\"end\":63767,\"start\":63354},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":5636055},\"end\":64000,\"start\":63769},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":118714035},\"end\":64162,\"start\":64002}]", "bib_title": "[{\"end\":42827,\"start\":42735},{\"end\":43242,\"start\":43193},{\"end\":43487,\"start\":43424},{\"end\":43837,\"start\":43760},{\"end\":44306,\"start\":44229},{\"end\":44711,\"start\":44662},{\"end\":44969,\"start\":44920},{\"end\":45242,\"start\":45180},{\"end\":45491,\"start\":45418},{\"end\":45931,\"start\":45885},{\"end\":46228,\"start\":46117},{\"end\":46655,\"start\":46591},{\"end\":46964,\"start\":46903},{\"end\":47336,\"start\":47259},{\"end\":47628,\"start\":47567},{\"end\":47955,\"start\":47919},{\"end\":48088,\"start\":48049},{\"end\":48783,\"start\":48693},{\"end\":48972,\"start\":48962},{\"end\":49078,\"start\":49035},{\"end\":49255,\"start\":49211},{\"end\":49487,\"start\":49444},{\"end\":50292,\"start\":50202},{\"end\":50507,\"start\":50460},{\"end\":50786,\"start\":50682},{\"end\":51162,\"start\":51111},{\"end\":51435,\"start\":51403},{\"end\":51616,\"start\":51595},{\"end\":51822,\"start\":51781},{\"end\":52286,\"start\":52223},{\"end\":52846,\"start\":52805},{\"end\":53280,\"start\":53231},{\"end\":53748,\"start\":53699},{\"end\":54407,\"start\":54329},{\"end\":54762,\"start\":54690},{\"end\":55067,\"start\":55015},{\"end\":55639,\"start\":55565},{\"end\":55965,\"start\":55903},{\"end\":56221,\"start\":56172},{\"end\":56512,\"start\":56483},{\"end\":56667,\"start\":56654},{\"end\":56891,\"start\":56813},{\"end\":57392,\"start\":57305},{\"end\":58544,\"start\":58490},{\"end\":58763,\"start\":58697},{\"end\":58966,\"start\":58912},{\"end\":59199,\"start\":59125},{\"end\":59457,\"start\":59394},{\"end\":59733,\"start\":59641},{\"end\":60871,\"start\":60771},{\"end\":61324,\"start\":61250},{\"end\":61612,\"start\":61583},{\"end\":61877,\"start\":61812},{\"end\":62591,\"start\":62530},{\"end\":62864,\"start\":62790},{\"end\":63115,\"start\":63044},{\"end\":63464,\"start\":63354},{\"end\":63805,\"start\":63769},{\"end\":64019,\"start\":64002}]", "bib_author": "[{\"end\":42845,\"start\":42829},{\"end\":42863,\"start\":42845},{\"end\":42879,\"start\":42863},{\"end\":42895,\"start\":42879},{\"end\":42911,\"start\":42895},{\"end\":43259,\"start\":43244},{\"end\":43268,\"start\":43259},{\"end\":43281,\"start\":43268},{\"end\":43507,\"start\":43489},{\"end\":43528,\"start\":43507},{\"end\":43548,\"start\":43528},{\"end\":43561,\"start\":43548},{\"end\":43578,\"start\":43561},{\"end\":43850,\"start\":43839},{\"end\":43859,\"start\":43850},{\"end\":43869,\"start\":43859},{\"end\":43880,\"start\":43869},{\"end\":43895,\"start\":43880},{\"end\":43907,\"start\":43895},{\"end\":43923,\"start\":43907},{\"end\":43931,\"start\":43923},{\"end\":44319,\"start\":44308},{\"end\":44328,\"start\":44319},{\"end\":44338,\"start\":44328},{\"end\":44349,\"start\":44338},{\"end\":44364,\"start\":44349},{\"end\":44376,\"start\":44364},{\"end\":44392,\"start\":44376},{\"end\":44400,\"start\":44392},{\"end\":44729,\"start\":44713},{\"end\":44743,\"start\":44729},{\"end\":44757,\"start\":44743},{\"end\":44775,\"start\":44757},{\"end\":44987,\"start\":44971},{\"end\":45001,\"start\":44987},{\"end\":45015,\"start\":45001},{\"end\":45033,\"start\":45015},{\"end\":45264,\"start\":45244},{\"end\":45506,\"start\":45493},{\"end\":45518,\"start\":45506},{\"end\":45529,\"start\":45518},{\"end\":45757,\"start\":45743},{\"end\":45771,\"start\":45757},{\"end\":45791,\"start\":45771},{\"end\":45948,\"start\":45933},{\"end\":45965,\"start\":45948},{\"end\":45983,\"start\":45965},{\"end\":46240,\"start\":46230},{\"end\":46254,\"start\":46240},{\"end\":46266,\"start\":46254},{\"end\":46276,\"start\":46266},{\"end\":46288,\"start\":46276},{\"end\":46514,\"start\":46496},{\"end\":46668,\"start\":46657},{\"end\":46687,\"start\":46668},{\"end\":46702,\"start\":46687},{\"end\":46716,\"start\":46702},{\"end\":46732,\"start\":46716},{\"end\":46976,\"start\":46966},{\"end\":46985,\"start\":46976},{\"end\":46994,\"start\":46985},{\"end\":47005,\"start\":46994},{\"end\":47018,\"start\":47005},{\"end\":47030,\"start\":47018},{\"end\":47040,\"start\":47030},{\"end\":47048,\"start\":47040},{\"end\":47059,\"start\":47048},{\"end\":47347,\"start\":47338},{\"end\":47358,\"start\":47347},{\"end\":47368,\"start\":47358},{\"end\":47383,\"start\":47368},{\"end\":47399,\"start\":47383},{\"end\":47642,\"start\":47630},{\"end\":47657,\"start\":47642},{\"end\":47672,\"start\":47657},{\"end\":47687,\"start\":47672},{\"end\":47706,\"start\":47687},{\"end\":47724,\"start\":47706},{\"end\":47968,\"start\":47957},{\"end\":47974,\"start\":47968},{\"end\":48100,\"start\":48090},{\"end\":48114,\"start\":48100},{\"end\":48127,\"start\":48114},{\"end\":48320,\"start\":48306},{\"end\":48332,\"start\":48320},{\"end\":48348,\"start\":48332},{\"end\":48356,\"start\":48348},{\"end\":48369,\"start\":48356},{\"end\":48597,\"start\":48577},{\"end\":48800,\"start\":48785},{\"end\":48811,\"start\":48800},{\"end\":48986,\"start\":48974},{\"end\":49092,\"start\":49080},{\"end\":49110,\"start\":49092},{\"end\":49269,\"start\":49257},{\"end\":49284,\"start\":49269},{\"end\":49298,\"start\":49284},{\"end\":49308,\"start\":49298},{\"end\":49501,\"start\":49489},{\"end\":49516,\"start\":49501},{\"end\":49530,\"start\":49516},{\"end\":49540,\"start\":49530},{\"end\":49758,\"start\":49748},{\"end\":49775,\"start\":49758},{\"end\":49783,\"start\":49775},{\"end\":49796,\"start\":49783},{\"end\":49817,\"start\":49796},{\"end\":49830,\"start\":49817},{\"end\":49844,\"start\":49830},{\"end\":49863,\"start\":49844},{\"end\":49869,\"start\":49863},{\"end\":50145,\"start\":50135},{\"end\":50305,\"start\":50294},{\"end\":50317,\"start\":50305},{\"end\":50516,\"start\":50509},{\"end\":50527,\"start\":50516},{\"end\":50538,\"start\":50527},{\"end\":50806,\"start\":50788},{\"end\":50820,\"start\":50806},{\"end\":50833,\"start\":50820},{\"end\":50845,\"start\":50833},{\"end\":50862,\"start\":50845},{\"end\":50881,\"start\":50862},{\"end\":51179,\"start\":51164},{\"end\":51207,\"start\":51179},{\"end\":51221,\"start\":51207},{\"end\":51233,\"start\":51221},{\"end\":51451,\"start\":51437},{\"end\":51467,\"start\":51451},{\"end\":51484,\"start\":51467},{\"end\":51630,\"start\":51618},{\"end\":51636,\"start\":51630},{\"end\":51648,\"start\":51636},{\"end\":51658,\"start\":51648},{\"end\":51668,\"start\":51658},{\"end\":51841,\"start\":51824},{\"end\":51858,\"start\":51841},{\"end\":51869,\"start\":51858},{\"end\":52059,\"start\":52042},{\"end\":52302,\"start\":52288},{\"end\":52314,\"start\":52302},{\"end\":52326,\"start\":52314},{\"end\":52338,\"start\":52326},{\"end\":52354,\"start\":52338},{\"end\":52527,\"start\":52515},{\"end\":52538,\"start\":52527},{\"end\":52551,\"start\":52538},{\"end\":52562,\"start\":52551},{\"end\":52577,\"start\":52562},{\"end\":52862,\"start\":52848},{\"end\":52877,\"start\":52862},{\"end\":52893,\"start\":52877},{\"end\":52910,\"start\":52893},{\"end\":52925,\"start\":52910},{\"end\":52937,\"start\":52925},{\"end\":52952,\"start\":52937},{\"end\":52966,\"start\":52952},{\"end\":52986,\"start\":52966},{\"end\":53000,\"start\":52986},{\"end\":53293,\"start\":53282},{\"end\":53310,\"start\":53293},{\"end\":53766,\"start\":53750},{\"end\":53781,\"start\":53766},{\"end\":53802,\"start\":53781},{\"end\":54049,\"start\":54033},{\"end\":54066,\"start\":54049},{\"end\":54084,\"start\":54066},{\"end\":54099,\"start\":54084},{\"end\":54117,\"start\":54099},{\"end\":54421,\"start\":54409},{\"end\":54429,\"start\":54421},{\"end\":54436,\"start\":54429},{\"end\":54446,\"start\":54436},{\"end\":54456,\"start\":54446},{\"end\":54466,\"start\":54456},{\"end\":54477,\"start\":54466},{\"end\":54487,\"start\":54477},{\"end\":54781,\"start\":54764},{\"end\":54797,\"start\":54781},{\"end\":54815,\"start\":54797},{\"end\":54835,\"start\":54815},{\"end\":55087,\"start\":55069},{\"end\":55099,\"start\":55087},{\"end\":55109,\"start\":55099},{\"end\":55305,\"start\":55291},{\"end\":55317,\"start\":55305},{\"end\":55334,\"start\":55317},{\"end\":55351,\"start\":55334},{\"end\":55362,\"start\":55351},{\"end\":55376,\"start\":55362},{\"end\":55655,\"start\":55641},{\"end\":55668,\"start\":55655},{\"end\":55685,\"start\":55668},{\"end\":55704,\"start\":55685},{\"end\":55989,\"start\":55967},{\"end\":56007,\"start\":55989},{\"end\":56248,\"start\":56223},{\"end\":56263,\"start\":56248},{\"end\":56275,\"start\":56263},{\"end\":56281,\"start\":56275},{\"end\":56538,\"start\":56514},{\"end\":56544,\"start\":56538},{\"end\":56681,\"start\":56669},{\"end\":56692,\"start\":56681},{\"end\":56705,\"start\":56692},{\"end\":56718,\"start\":56705},{\"end\":56912,\"start\":56893},{\"end\":57149,\"start\":57134},{\"end\":57160,\"start\":57149},{\"end\":57168,\"start\":57160},{\"end\":57415,\"start\":57394},{\"end\":57427,\"start\":57415},{\"end\":57441,\"start\":57427},{\"end\":57458,\"start\":57441},{\"end\":57473,\"start\":57458},{\"end\":57487,\"start\":57473},{\"end\":57812,\"start\":57797},{\"end\":57820,\"start\":57812},{\"end\":57826,\"start\":57820},{\"end\":57836,\"start\":57826},{\"end\":57848,\"start\":57836},{\"end\":57854,\"start\":57848},{\"end\":57863,\"start\":57854},{\"end\":57875,\"start\":57863},{\"end\":57885,\"start\":57875},{\"end\":57898,\"start\":57885},{\"end\":57906,\"start\":57898},{\"end\":57917,\"start\":57906},{\"end\":58209,\"start\":58195},{\"end\":58226,\"start\":58209},{\"end\":58240,\"start\":58226},{\"end\":58258,\"start\":58240},{\"end\":58276,\"start\":58258},{\"end\":58559,\"start\":58546},{\"end\":58567,\"start\":58559},{\"end\":58578,\"start\":58567},{\"end\":58777,\"start\":58765},{\"end\":58790,\"start\":58777},{\"end\":58976,\"start\":58968},{\"end\":58991,\"start\":58976},{\"end\":58999,\"start\":58991},{\"end\":59211,\"start\":59201},{\"end\":59220,\"start\":59211},{\"end\":59236,\"start\":59220},{\"end\":59471,\"start\":59459},{\"end\":59480,\"start\":59471},{\"end\":59492,\"start\":59480},{\"end\":59501,\"start\":59492},{\"end\":59749,\"start\":59735},{\"end\":59771,\"start\":59749},{\"end\":59789,\"start\":59771},{\"end\":59810,\"start\":59789},{\"end\":59823,\"start\":59810},{\"end\":60107,\"start\":60100},{\"end\":60118,\"start\":60107},{\"end\":60130,\"start\":60118},{\"end\":60140,\"start\":60130},{\"end\":60152,\"start\":60140},{\"end\":60492,\"start\":60484},{\"end\":60499,\"start\":60492},{\"end\":60508,\"start\":60499},{\"end\":60517,\"start\":60508},{\"end\":60525,\"start\":60517},{\"end\":60533,\"start\":60525},{\"end\":60540,\"start\":60533},{\"end\":60546,\"start\":60540},{\"end\":60553,\"start\":60546},{\"end\":60561,\"start\":60553},{\"end\":60568,\"start\":60561},{\"end\":60576,\"start\":60568},{\"end\":60898,\"start\":60873},{\"end\":60913,\"start\":60898},{\"end\":60927,\"start\":60913},{\"end\":60940,\"start\":60927},{\"end\":60945,\"start\":60940},{\"end\":60969,\"start\":60945},{\"end\":60979,\"start\":60969},{\"end\":60985,\"start\":60979},{\"end\":61348,\"start\":61326},{\"end\":61365,\"start\":61348},{\"end\":61379,\"start\":61365},{\"end\":61399,\"start\":61379},{\"end\":61626,\"start\":61614},{\"end\":61635,\"start\":61626},{\"end\":61658,\"start\":61635},{\"end\":61664,\"start\":61658},{\"end\":61893,\"start\":61879},{\"end\":61904,\"start\":61893},{\"end\":61915,\"start\":61904},{\"end\":61925,\"start\":61915},{\"end\":61941,\"start\":61925},{\"end\":61952,\"start\":61941},{\"end\":61965,\"start\":61952},{\"end\":61983,\"start\":61965},{\"end\":61999,\"start\":61983},{\"end\":62320,\"start\":62310},{\"end\":62334,\"start\":62320},{\"end\":62351,\"start\":62334},{\"end\":62601,\"start\":62593},{\"end\":62609,\"start\":62601},{\"end\":62620,\"start\":62609},{\"end\":62629,\"start\":62620},{\"end\":62641,\"start\":62629},{\"end\":62874,\"start\":62866},{\"end\":62887,\"start\":62874},{\"end\":62901,\"start\":62887},{\"end\":63130,\"start\":63117},{\"end\":63140,\"start\":63130},{\"end\":63154,\"start\":63140},{\"end\":63170,\"start\":63154},{\"end\":63477,\"start\":63466},{\"end\":63491,\"start\":63477},{\"end\":63501,\"start\":63491},{\"end\":63513,\"start\":63501},{\"end\":63528,\"start\":63513},{\"end\":63542,\"start\":63528},{\"end\":63815,\"start\":63807},{\"end\":63823,\"start\":63815},{\"end\":63831,\"start\":63823},{\"end\":63841,\"start\":63831},{\"end\":63853,\"start\":63841},{\"end\":63865,\"start\":63853},{\"end\":64034,\"start\":64021},{\"end\":64047,\"start\":64034},{\"end\":64067,\"start\":64047}]", "bib_venue": "[{\"end\":42951,\"start\":42911},{\"end\":43288,\"start\":43281},{\"end\":43583,\"start\":43578},{\"end\":43966,\"start\":43931},{\"end\":44435,\"start\":44400},{\"end\":44782,\"start\":44775},{\"end\":45040,\"start\":45033},{\"end\":45292,\"start\":45264},{\"end\":45547,\"start\":45529},{\"end\":45741,\"start\":45719},{\"end\":45987,\"start\":45983},{\"end\":46293,\"start\":46288},{\"end\":46736,\"start\":46732},{\"end\":47063,\"start\":47059},{\"end\":47403,\"start\":47399},{\"end\":47728,\"start\":47724},{\"end\":47977,\"start\":47974},{\"end\":48135,\"start\":48127},{\"end\":48304,\"start\":48239},{\"end\":48575,\"start\":48528},{\"end\":48815,\"start\":48811},{\"end\":48990,\"start\":48986},{\"end\":49114,\"start\":49110},{\"end\":49312,\"start\":49308},{\"end\":49544,\"start\":49540},{\"end\":49746,\"start\":49664},{\"end\":50321,\"start\":50317},{\"end\":50560,\"start\":50538},{\"end\":50885,\"start\":50881},{\"end\":51247,\"start\":51233},{\"end\":51488,\"start\":51484},{\"end\":51672,\"start\":51668},{\"end\":51873,\"start\":51869},{\"end\":52040,\"start\":51987},{\"end\":52358,\"start\":52354},{\"end\":52643,\"start\":52577},{\"end\":53004,\"start\":53000},{\"end\":53396,\"start\":53310},{\"end\":53806,\"start\":53802},{\"end\":54031,\"start\":53933},{\"end\":54491,\"start\":54487},{\"end\":54839,\"start\":54835},{\"end\":55113,\"start\":55109},{\"end\":55289,\"start\":55233},{\"end\":55708,\"start\":55704},{\"end\":56028,\"start\":56007},{\"end\":56311,\"start\":56281},{\"end\":56559,\"start\":56544},{\"end\":56722,\"start\":56718},{\"end\":56917,\"start\":56912},{\"end\":57132,\"start\":57069},{\"end\":57537,\"start\":57487},{\"end\":58329,\"start\":58276},{\"end\":58583,\"start\":58578},{\"end\":58794,\"start\":58790},{\"end\":59003,\"start\":58999},{\"end\":59249,\"start\":59236},{\"end\":59505,\"start\":59501},{\"end\":59833,\"start\":59823},{\"end\":60098,\"start\":60059},{\"end\":60482,\"start\":60408},{\"end\":60999,\"start\":60985},{\"end\":61403,\"start\":61399},{\"end\":61683,\"start\":61664},{\"end\":62006,\"start\":61999},{\"end\":62308,\"start\":62228},{\"end\":62645,\"start\":62641},{\"end\":62905,\"start\":62901},{\"end\":63174,\"start\":63170},{\"end\":63552,\"start\":63542},{\"end\":63869,\"start\":63865},{\"end\":64072,\"start\":64067},{\"end\":53476,\"start\":53398},{\"end\":59839,\"start\":59835}]"}}}, "year": 2023, "month": 12, "day": 17}