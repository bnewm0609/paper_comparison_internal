{"id": 244117791, "updated": "2023-10-05 19:44:38.956", "metadata": {"title": "Finding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks", "authors": "[{\"first\":\"Chen\",\"last\":\"Ma\",\"middle\":[]},{\"first\":\"Xiangyu\",\"last\":\"Guo\",\"middle\":[]},{\"first\":\"Li\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Jun-Hai\",\"last\":\"Yong\",\"middle\":[]},{\"first\":\"Yisen\",\"last\":\"Wang\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "One major problem in black-box adversarial attacks is the high query complexity in the hard-label attack setting, where only the top-1 predicted label is available. In this paper, we propose a novel geometric-based approach called Tangent Attack (TA), which identifies an optimal tangent point of a virtual hemisphere located on the decision boundary to reduce the distortion of the attack. Assuming the decision boundary is locally flat, we theoretically prove that the minimum $\\ell_2$ distortion can be obtained by reaching the decision boundary along the tangent line passing through such tangent point in each iteration. To improve the robustness of our method, we further propose a generalized method which replaces the hemisphere with a semi-ellipsoid to adapt to curved decision boundaries. Our approach is free of pre-training. Extensive experiments conducted on the ImageNet and CIFAR-10 datasets demonstrate that our approach can consume only a small number of queries to achieve the low-magnitude distortion. The implementation source code is released online at https://github.com/machanic/TangentAttack.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2111.07492", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/MaGCYW21", "doi": null}}, "content": {"source": {"pdf_hash": "08fc0e1b0c8f6b4b84ae896169e2199229f27bec", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.07492v5.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "a9689fdb2d88696f7ab10ce694d62af873ef0291", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/08fc0e1b0c8f6b4b84ae896169e2199229f27bec.txt", "contents": "\nFinding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks\n\n\nChen Ma \nSchool of Software\nTsinghua University\nBNRist, BeijingChina\n\nXiangyu Guo xiangyug@buffalo.edu \nDepartment of Computer Science and Engineering\nUniversity at Buffalo\nBuffalo, NYUSA\n\nLi Chen \nSchool of Software\nTsinghua University\nBNRist, BeijingChina\n\nJun-Hai Yong yongjh@tsinghua.edu.cn \nSchool of Software\nTsinghua University\nBNRist, BeijingChina\n\nYisen Wang yisen.wang@pku.edu.cn \nKey Lab. of Machine Perception\nSchool of Artificial Intelligence\nPeking University\nBeijingChina\n\nInstitute for Artificial Intelligence\nPeking University\nBeijingChina\n\nFinding Optimal Tangent Points for Reducing Distortions of Hard-label Attacks\n\nOne major problem in black-box adversarial attacks is the high query complexity in the hard-label attack setting, where only the top-1 predicted label is available. In this paper, we propose a novel geometric-based approach called Tangent Attack (TA), which identifies an optimal tangent point of a virtual hemisphere located on the decision boundary to reduce the distortion of the attack. Assuming the decision boundary is locally flat, we theoretically prove that the minimum 2 distortion can be obtained by reaching the decision boundary along the tangent line passing through such tangent point in each iteration. To improve the robustness of our method, we further propose a generalized method which replaces the hemisphere with a semi-ellipsoid to adapt to curved decision boundaries. Our approach is free of pre-training. Extensive experiments conducted on the ImageNet and CIFAR-10 datasets demonstrate that our approach can consume only a small number of queries to achieve the low-magnitude distortion. The implementation source code is released online at https://github.com/machanic/TangentAttack.\n\nIntroduction\n\nAdversarial attacks cause deep neural networks (DNNs) to make incorrect predictions by slightly perturbing benign images during the test time. They can be divided into two main categories on the basis of the amount of information exposed by the target model, namely white-box and black-box attacks. Many white-box attacks [6,30,33] have been proposed, and they can compute the gradients w.r.t. the target model's input images to generate adversarial examples with the first-order optimization techniques. In contrast, black-box attacks are more practical because they craft adversarial examples without requiring the target model's gradients.\n\nOver the past years, the community has made considerable efforts in developing black-box attacks, and the proposed methods can be divided into transfer-and query-based attacks. Transfer-based attacks [26,40,41] generate adversarial examples by using a white-box attack method against a surrogate model to fool the target model. Although there is no need to query the target model in these attacks, the attack success rate can not be guaranteed, especially in the case of targeted attacks. To achieve satisfactory attack success rates, the query-based attacks use elaborate queries to obtain the feedback of the target model for crafting adversarial examples. In the score-based setting, the query-based attacks [2,12,22,29] estimate approximate gradients by querying the predicted scores of the target model at multiple points. However, in most real-world scenarios, the score-based setting  Figure 1: Simplified two-dimensional illustration of our motivation. H is the decision boundary, and x t\u22121 is the current adversarial example mapped onto the decision boundary at the (t \u2212 1)-th iteration. HSJA updates x t\u22121 along the gradient direction to reach g and then maps it to H at x g along the line through x and g. However, the optimal update should be the tangent point k because it can be mapped onto H at x t that has the shortest distance to the original image x.\n\nis not applicable because the public service returns only the top-1 predicted label (i.e., the hard label) rather than the predicted score. In this case, since the feedback information is limited and the objective function is discontinuous, the attack requires solving a high-dimensional combinatorial optimization problem, which is often challenging.\n\nTo reformulate the attack as a real-valued continuous optimization problem, OPT [10], Sign-OPT [11], and RayS [8] focus on minimizing an objective function g(\u03b8), which is defined as the distance from the original image to the nearest adversarial example along the direction \u03b8. However, when attacking complex models, it may be difficult to find a suitable direction \u03b8 along which adversarial examples exist.\n\nBoundary Attack (BA) [4], HopSkipJumpAttack (HSJA) [7], QEBA [25], qFool [27], and Policy Driven Attack (PDA) [43] eliminate the search of the direction \u03b8. Instead, they start from a large adversarial perturbation and then reduce its distortion while staying in the adversarial region. Because the output labels of the target model flip only near the decision boundary, these attacks restrict their explorations to the regions near the decision boundary. However, they do not thoroughly investigate the geometric properties of the decision boundary to accelerate the attack. For example, PDA uses a reinforcement learning framework to train a policy network to predict search directions, which are not geometrically optimal. In addition, the prediction accuracy of the policy network decreases significantly in the later stages of the iterations, resulting in worse performance of these iterations. HSJA and qFool simply use the gradient u estimated at the decision boundary as the direction of each update, while ignoring a geometrically critical issue, i.e., u is not the optimal direction to be followed ( Fig. 1). We could explore better search directions at each attack iteration.\n\nTo find the optimal search direction for minimizing the distortions of attack, we propose a new geometric-based approach whose motivation is illustrated in Fig. 1. We construct a virtual semicircle B centered at x t\u22121 to indicate all possible locations that x t\u22121 can reach along different directions, and the radius of B limits the range of updates for successful attacks. It is easy to observe that moving along the tangent line can reach the nearest location of the decision boundary to the original image x, thereby producing the adversarial example with the minimum distortion. In real attack scenarios, the image data reside in a high-dimensional space, and the semicircle becomes a hemisphere. In this case, the benefit of using tangent points still exists, and we provide the detailed description and the formal proof in Section 3 and appendix.\n\nTo summarize, the main contributions of this study are as follows.\n\n1. We cast the problem of minimizing the distortion in hard-label attacks into a geometric problem.\n\nWe discover that the minimum distortion can be obtained by searching the optimal tangent point of a virtual hemisphere around the adversarial example at each iteration. 2. We propose a novel geometric-based method to obtain a closed-form solution of the optimal tangent point. We provide an intuitive explanation of our approach, as well as a formal proof of its correctness. 3. To improve robustness, we further propose a generalized method that replaces the hemisphere with a semi-ellipsoid to adapt to the target models with curved decision boundaries. 4. Extensive experiments conducted on the CIFAR-10 [24] and ImageNet [14] datasets demonstrate the effectiveness of our approach.\n\n\nRelated Work\n\nQuery-based black-box attacks can be divided into score-and decision-based attack (a.k.a. the hard-label attack). Score-based attacks [1,2,3,9,12,22,29,32] use the predicted probability score to craft adversarial examples, which is not always available in most real-world systems. Hard-label attacks are more useful, but obviously more challenging, because only the top-1 predicted label can be obtained. The hard-label attacks usually fall into three categories.\n\nThe first category starts from the original image x 0 and attempts to find a optimal direction \u03b8 to reach the adversarial example. OPT [10] searches an optimal \u03b8 to minimize the distance from x 0 to the nearest adversarial example. Sign-OPT [11] improves the query efficiency of OPT by using a single query to estimate the sign of the directional derivative. RayS [8] eliminates the gradient estimation and proposes a fast check step to efficiently find the direction \u03b8. However, RayS is only applicable to the untargeted attack under the \u221e norm because it is difficult to find a suitable direction to reach the region of the target class in a targeted attack, especially in the case of a large number of classes.\n\nThe second category starts from a large perturbation or an image of the target class, and then reduces its distortion while staying in adversarial region, thereby gradually making it closer to the original image. BA [4] and NES [1] are two representative methods, but they have high query complexity. Biased BA [5] reinterprets BA as a biased sampling framework and incorporates different biases to improve the query efficiency. HSJA [7] utilizes the gradient estimation and the binary search to outperform BA. HSJA can be used as the baseline of hard-label attacks. QEBA [25] improves HSJA by using dimension reduction techniques. SurFree [31] and GeoDA [34] improve the performance of HSJA by exploiting geometric properties of DNNs. However, the geometric features of DNNs have not been fully explored, and they do not support the targeted attack. PDA [43] uses a reinforcement learning framework to train a policy network to predict promising directions. However, PDA requires a high-cost pre-training, which is not always available in all tasks.\n\nThe third category uses a random sampling technique to improve query efficiency. Customized Adversarial Boundary (CAB) attack [37] uses the current noise to select the sensitive area of images and customize sampling distribution. Evolutionary [16] improves the query efficiency by reducing the dimension of the search space with the stochastic coordinate selection.\n\nThe issue of RayS and GeoDA is that they only support untargeted attacks. Because moving the original image far enough in any direction can always make it escape the non-adversarial region in untargeted attacks. However, in targeted attacks, it is difficult to find a suitable direction along which the target class's region exists. In contrast, our approach supports all types of attacks, and we exploit the geometric characteristics of the decision boundaries of DNNs to boost the attack.\n\n\nThe Proposed Approach\n\n\nThe Goal of Hard-label Attacks\n\nGiven a target model f : R d \u2192 R k and a benign image x \u2208 [0, 1] d that is correctly classified using f , the goal of the adversary is to slightly perturb x into x adv , such that f (x adv ) outputs incorrect prediction. In the hard-label attack, the adversary can only observe the top-1 predicted label of f , denoted as\u0177 = arg max i f (x adv ) i . We define an indicator function \u03c6(\u00b7) of a successful attack:\n\u03c6(x adv ) := \uf8f1 \uf8f2 \uf8f3 1 if\u0177 = y adv in the targeted attack, or\u0177 = y in the untargeted attack, 0 otherwise,(1)\nwhere y \u2208 R is the true label of x and y adv \u2208 R is a predefined target class label. In this study, we focus on generating an adversarial example x adv that satisfies \u03c6(x adv ) = 1, such that the distortion d(x adv , x) := x adv \u2212 x p is minimized. This goal can be formulated as the optimization problem: min\nxadv d(x adv , x) s.t. \u03c6(x adv ) = 1.(2)\n\nMotivation\n\nMost recent attacks belong to the second category (Section 2) follow a common procedure: it starts from an adversarial image yet not close enough to the benign one, then it iteratively searches for a closer adversarial image. Let us take a typical attack HSJA [7] for example ( Fig. 1). First, the attack initializes the adversarial example by using an image of the target class (in a targeted attack) or a noisy version of the original image (in an untargeted attack). Next, it performs the binary search to map the initial sample onto the decision boundary H, denoted as x t\u22121 . Then, the algorithm iteratively performs three steps to update x t\u22121 : estimating gradient u at H by sampling many probes around x t\u22121 ; jumping to the point g along the direction u with the step size determined by the geometric progression; and mapping g onto H at x g by performing the binary search along the line passing through g and the original image x. However, geometrically speaking, the estimated gradient u is not the optimal search direction, and we can find a better boundary point x t by connecting x to a certain point on the semicircle B and then taking the intersection point on H. Fig. 1 shows that the tangent point k is the optimum update because it leads to the minimum distortion of the attack. Figure 2: Geometrical explanation of Theorem 1. All points on H that are closer to x than x t are within a red disk, which is the intersection of H and the red cone whose vertex is x. Clearly k is the only intersection point of the cone and the hemisphere B. Thus, of all the lines intersecting B, only the intersection of the tangent line and H is closest to x.\n\n\nDefinition of Optimal Tangent Points\nx y z H B x t\u22121 x t u x k\nThere is some experimental evidence that the decision boundaries of DNNs are smooth surfaces with the low curvature [17,34]. Based on this observation, we approximate the local decision boundary with a hyperplane H. Fig. 3 illustrates our problem in three-dimensional space. We will derive our algorithm from R 3 and show that it can be directly extended to higher-dimensional spaces. Lastly, we address the case of curved decision boundaries.\n\nAs described in Section 3.2, x t\u22121 denotes the boundary sample that already lies on the decision boundary. We create a virtual hemisphere B centered at x t\u22121 with a radius R, which is an estimation of the safe region where we can search for adversarial examples. In the targeted attack, B represents the current estimation of the target class region around x t\u22121 . Ideally, B is small enough to be fully contained in the target class's region, i.e., \u03c6(x ) = 1 for \u2200x \u2208 B. Then, we need to find a point on B which would produce the minimum distortion when mapped to H. In two-dimensional case, this point is the tangent point. However, in n-dimensional space where n \u2265 3, there are infinitely many tangent lines of B passing through x which create infinitely many tangent points on B, shown as the red points in Figs. 2 and 3. Still, we will show that exactly one tangent point can lead to the minimum distortion when mapping it onto H along the tangent line.\n\nFormally, let k be any point on the surface of B, u be the approximate gradient of H estimated at x t\u22121 , and x t be the intersection of H and the line passing through x and k, we have the following theorem. Theorem 1. Let H, u, k, x, and x t\u22121 be defined above, then the distance x \u2212 x t is minimized if k is the optimal solution of the following constrained optimization problem:\narg max k k \u2212 x t\u22121 , u(3)s.t. k \u2212 x t\u22121 , x \u2212 k = 0, (4) k \u2212 x t\u22121 = R, (5) k \u2212 x t\u22121 , u \u2265 0.(6)\nIn particular, the optimal k is in the plane spanned by u and x \u2212 x t\u22121 .\n\nThe objective function of Eq. (3) is to maximize the projection of the vector k \u2212 x t\u22121 onto u, which is equivalent to finding k that is farthest away from H. The first constraint ensures that k is a tangent point. The second constraint indicates k is on the surface of B. The last constraint states that k cannot appear on the same side of H as x, which is always satisfied if \u03a0 H (x \u2212 x t\u22121 ) \u2265 R, where the notation \u03a0 H : R n \u2192 H denotes the orthogonal projection from R n onto the hyperplane H. If there is no feasible solution, then our algorithm (Algorithm 1) reduces the radius R to guarantee that the last constraint is always satisfied. The formal proof of Theorem 1 is presented in the appendix. Here, \nx z x H V B x t\u22121 x t k R k x h u \u03b3 \u03b2 \u03b1\n\nClosed-Form Solution of the Optimal Tangent Point\n\nThe main intuition of the derivation is illustrated in Fig. 3, which shows an example in R 3 . For ease of presentation, we move x t\u22121 to 0. The known variables are x, x t\u22121 , the unit normal vector u of hyperplane H, and the radius R. We need to solve for the unknown k. Let V = span({x, u}) be the plane spanned by x and u. According to Theorem 1, we know k \u2208 V . Let us denote the angle between x and H as \u03b1, the angle between x and k as \u03b2, and the angle between k and H as \u03b3. Then, \u03b2 = \u03b1 + \u03b3 because all three points x, k, and x t\u22121 are on the same plane V . Because the angle between x and u is \u03c0 / 2 + \u03b1, we have\nx, u = x \u00b7 u \u00b7 cos( \u03c0 2 + \u03b1) = x \u00b7 u \u00b7 (\u2212 sin \u03b1) .(7)\nThen we have sin \u03b1 = \u2212 x,u x \u00b7 u and cos \u03b1 = 1 \u2212 sin 2 \u03b1 =\n\u221a x 2 \u00b7 u 2 \u2212 x,u 2 x \u00b7 u\n. By the constraint (4), x \u2212 k is orthogonal to k. Thus, we have cos \u03b2 = R / x and sin \u03b2 = 1 \u2212 cos 2 \u03b2 = x 2 \u2212 R 2 / x . Then sin \u03b3 and cos \u03b3 can be derived as functions of \u03b1 and \u03b2 from basic facts of trigonometric functions: sin \u03b3 = sin(\u03b2 \u2212 \u03b1) = sin \u03b2 cos \u03b1 \u2212 cos \u03b2 sin \u03b1, cos \u03b3 = cos(\u03b2 \u2212 \u03b1) = cos \u03b2 cos \u03b1 + sin \u03b2 sin \u03b1.\n\nNow, let k \u2208 H be the orthogonal projection of k onto the plane H. The distance between k and k is denoted as h (Fig. 3). Then h = R \u00b7 sin \u03b3 = R \u00b7 (sin \u03b2 cos \u03b1 \u2212 cos \u03b2 sin \u03b1).\n\nTo derive k , let us denote x as the orthogonal projection of x onto z axis. So we have x = x, \u2212u \u00b7 (\u2212u) / u 2 = x, u \u00b7 u / u 2 . Then, because k and x \u2212 x are on the same direction, we have\nk k = x \u2212 x x \u2212 x .(9)\nNow, k = R \u00b7 cos \u03b3 and x = x, u \u00b7 u / u 2 are plugged into Eq. (9), and k is obtained as\nk = x \u2212 x x \u2212 x \u00b7 k = x \u2212 x, u \u00b7 u / u 2 x \u2212 x, u \u00b7 u / u 2 \u00b7 R \u00b7 cos \u03b3.(10)\nTherefore, k can be derived as\nk = k + h \u00b7 u = x \u2212 x, u \u00b7 u / u 2 x \u2212 x, u \u00b7 u / u 2 \u00b7 R \u00b7 cos \u03b3 + h \u00b7 u.(11)\nx z  Finally, because x t\u22121 has been moved to the origin, we need to move k back by adding x t\u22121 .\nx t\u22121 h S L V x k \u03b8 H (a) 3D view of Generalized Tangent Attack v x(x 0 , z 0 ) u k(x k , z k ) k (x k , z k ) L S \u03b8 (b) 2D plane V\nWe remark that although the above derivation is illustrated in R 3 , it can be directly applied to higher dimensions. The reason is Theorem 1, which essentially reduces any dimension space to R 2 : to find the optimal k, we only need to focus on the plane V spanned by u and x \u2212 x t\u22121 .\n\n\nGeneralized Tangent Attack\n\nWhen the local decision boundary is not flat enough, the boundary point obtained via the tangent line may not be the optimal, as shown in Fig. 4a. A simple solution is to simply continue halving the radius R of the hemisphere: as long as R becomes small enough, the local flatness can always be obtained. However, too small a radius will reduce the convergence rate of our algorithm, because the distance between x t and x t\u22121 is proportional to R. Therefore, when the classification decision boundary is a curved surface, the attack algorithm should change the shape of hemisphere rather than simply reducing R. Based on this idea, we propose the Generalized Tangent Attack (G-TA).\n\nFirst, although the shape of the decision boundary can be very complex in a high-dimensional space, the important thing for our algorithm is only the situation in the two-dimensional plane spanned by x and u. In particular, if the decision boundary is \"downward\" curved (as opposed to the example in Fig. 4a), then searching along the tangent line is still a better approach than HSJA's solution. Thus, the only \"bad case\" we have to deal with is when the decision boundary is \"upward\" curved and has a large curvature, as shown in Fig. 4a.\n\nAccording to Theorem 1, we only need to focus on the plane V spanned by x and u, as shown in Fig. 4b. Now, u and v :\n= (x \u2212 x, u \u00b7 u / u 2 ) / x \u2212 x, u \u00b7 u / u 2 form an orthogonal basis of the plane V , then x can be identified with coordinates (x 0 , z 0 ), i.e., x = x 0 v + z 0 u.\nLet \u03b8 denote the angle between the vector x and the vector \u2212u, i.e., \u03b8 = arccos x,\u2212u\nx \u00b7 u . Then (x 0 , z 0 ) = ( x \u00b7 sin \u03b8, \u2212 x \u00b7 cos \u03b8)\n. Consider the projection of the ellipsoid on V (which is an ellipse), we denote L as its radius along the direction of u, and S as its radius along the direction of v. Because the optimal tangent point k lies in the plane V , k can also be identified as k = x k v + z k u, and we only need to solve for the unknown (x k , z k ).\n\nThe ellipse is characterized by the equation x 2 / S 2 + z 2 / L 2 = 1, thus the tangent point k satisfies x 2 k / S 2 + z 2 k / L 2 = 1. Now we view z as a function of x, and take the derivative w.r.t. x at both sides of the equation to get the following formula:\n2x k S 2 + 2z k L 2 \u00b7 dz dx x=x k = 0.(12)\nThus, we have the slope of tangent line at k be dz\ndx x=x k = \u2212 x k L 2 z k S 2 .\nTherefore, the tangent line can be written as\nz \u2212 z k = \u2212 x k L 2 z k S 2 (x \u2212 x k ).\nSince the tangent line passes through x, we know\nz 0 \u2212 z k = \u2212 x k L 2 z k S 2 (x 0 \u2212 x k ).\nIn summary, we can obtain the following system of equations:\n\uf8f1 \uf8f2 \uf8f3 L 2 x 2 k + S 2 z 2 k \u2212 x k x 0 L 2 \u2212 z 0 z k S 2 = 0, x 2 k S 2 + z 2 k L 2 = 1.(13)\nIn Eq. (13), the known variables are L, S, x 0 and z 0 , and the unknown variables that we need to solve for are x k and z k . In general, there are two solutions for Eq. (13), i.e., k and k depicted in Fig. 4b. Apparently, the solution of the optimal tangent point should satisfy z k > 0, so the one of two solutions in which z k > 0 should be picked:\n\uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 x k = S 2 L 2 \u2212 z 0 \u00b7 L 2 S 2 z0+L 2 x0 \u221a \u2212L 2 S 2 +L 2 x 2 0 +S 2 z 2 0 L 2 x 2 0 +S 2 z 2 0 L 2 \u00b7 x 0 , z k = L 2 S 2 z 0 + L 2 x 0 \u2212L 2 S 2 + L 2 x 2 0 + S 2 z 2 0 L 2 x 2 0 + S 2 z 2 0 .(14)\nFinally, the optimal tangent point k is obtained via\nk = |x k | \u00b7 x\u2212 x,u \u00b7u/ u 2 x\u2212 x,u \u00b7u/ u 2 + z k \u00b7 u.\nIn the implementation, the value of L is determined in the same way as the radius R in TA (the hemisphere version). So we fix L = R, and use a hyperparameter r = L/S to control the value of S. Imagine that in the case of R 3 , the semi-ellipsoid becomes \"slender\" by setting r > 1, thereby adapting to the decision boundary of curved surface while preserving a relatively large step size.\n\n\nThe Complete Algorithm\n\nTA (the hemisphere version) and G-TA (the semi-ellipsoid version) can be combined into one algorithm process, which is shown in Algorithm 1. It first performs a binary search to map the initial samplex 0 to the decision boundary. Note that the binary search step always maps any x adv to the adversarial side of H that satisfies \u03c6(x adv ) = 1, hence the attack success rate is always 100%. Then, it performs a for loop of T iterations to find the adversarial example that is close to x. In the first iteration, we sample B 0 probes around the boundary sample to estimate the gradient, which is increased to B 0 \u221a t at the t-th iteration. This is because the error of gradient estimation in the later iterations has a greater impact on the attack performance, so using more samples can reduce the estimation error. Then, a while loop is performed to determine a reasonable radius R by repeatedly halving the radius until the tangent point k is in the adversarial region. Finally, Algorithm 1 uses the binary search method to map k back to the classification decision boundary to end this iteration.\n\n\nAlgorithm 1 Tangent Attack\n\nInput: benign image x, attack success indicator function \u03c6(\u00b7) defined in Eq. (1), initial batch size B 0 , iteration T , mode m \u2208 {semi-ellipsoid, hemisphere}, radius ratio r.\nInitializex 0 that satisfies \u03c6(x 0 ) = 1; x 0 \u2190 BinarySearch(x 0 , x, \u03c6); boundary search d 0 = x 0 \u2212 x ; for t in 1, . . . , T do Sample B t \u2190 B 0 \u221a t random vectors to estimate the gradient u; Initialize R \u2190 d t\u22121 / \u221a t; the initial radius while true do\nCompute the optimal tangent point k based on Eq. (11) if m = hemisphere else Eq. (14);\nR \u2190 R 2 ;\nsearch the radius, and we set\nL = R, S = L r if m = semi-ellipsoid if \u03c6(k) = 1 then break; end if end while k \u2190 Clip(k, 0, 1); x t \u2190 BinarySearch(k, x, \u03c6); boundary search d t = x t \u2212 x ; end for 4 Experiment\n\nExperimental Setting\n\nDatasets. TA and G-TA are evaluated on two datasets, namely CIFAR-10 and ImageNet with the image resolutions of 32 \u00d7 32 \u00d7 3 and 299 \u00d7 299 \u00d7 3, respectively. We randomly select 1,000 correctly classified images from their validation sets for experiments.\n\nMethod Setting. The initial batch size B 0 is set to 100, which means the algorithm samples 100 probes for estimating a gradient at the first iteration. The threshold \u03b3 that controls the termination of the binary search is set to 1.0 in the CIFAR-10 dataset and 1,000 in the ImageNet dataset. The radius ratio r is set to 1.5 in the CIFAR-10 dataset and 1.1 in the ImageNet dataset. Besides, we also set r to 1.5 when attacking defense models. In targeted attacks, the target class label is set to y adv = (y + 1) mod C, where y is the true label, and C is the number of classes.\n\nCompared Methods. The advantage of our method is that it supports all types of attacks, including both untargeted and targeted attacks under 2 norm and \u221e norm constraints. Therefore, for complete and fair comparisons, we select the compared methods that support both untargeted and targeted attacks with state-of-the-art performance, including Boundary Attack (BA) [4], Sign-OPT [11], SVM-OPT [11], and HopSkipJumpAttack (HSJA) [7]. HSJA is adopted as the baseline, whose hyperparameters are set to be the same with ours (e.g, the same initial batch size B 0 and threshold \u03b3).\n\nIn addition, QEBA [25] is a HSJA-based method which has three variants: QEBA-I, QEBA-S and QEBA-F. We select QEBA-S in the additional experiment to verify whether the proposed method can improve attack performance of other HSJA-based method. For the consistency of experiments, we translate the implementations of Sign-OPT, SVM-OPT and HSJA from the official NumPy version into the PyTorch version by replacing each NumPy function with the corresponding PyTorch function. Thus, the two versions behave exactly the same. In the targeted attack, we randomly select an image from the target class of the validation set to be the initial sample of HSJA, BA, TA and G-TA. For fair comparison, we set the initial direction \u03b8 0 of Sign-OPT and SVM-OPT to the direction of a randomly selected image of the target class. The detailed settings are presented in the appendix.\n\nTarget Models. In the CIFAR-10 dataset, we select four target models implemented using the PyTorch framework 2 : (1) a 272-layer PyramidNet+ShakeDrop network (PyramidNet-272) [19,42] trained using AutoAugment [13] ; (2) a model obtained through a neural architecture search called GDAS [15]; (3) \n\n\nComparisons with State-of-the-Art Methods\n\nResults of Attacks against Undefended Models. Tables 1 and 2 show the experimental results on the ImageNet and CIFAR-10 datasets. We derive two conclusions based on the results:\n\n(1) We found that the experiments of CIFAR-10 requires a larger radius ratio r than that of ImageNet to achieve the satisfactory performance of G-TA. We speculate that the reason is that the target models of ImageNet have relatively flat decision boundaries.\n\n(2) TA is more effective in targeted attacks, while the G-TA performs better in untargeted ones. This is because the adversarial region of the target class is narrower and more scattered, making the local classification decision boundary smoother, so that Theorem 1 holds and TA performs better.\n\nIn addition, one unique benefit of our approach is that it can be used as a performance enhanced plug-in when combining it with other HSJA-based approaches (e.g., QEBA-S). Specifically, the method is to change the jump directions of boundary samples of QEBA-S to the directions of the optimal tangent points. We present that \"QEBA-S + TA\" can further improve the performance of QEBA-S, as shown in Table 3.   Results of Attacks against Defense Models. We conduct the experiments of untargeted attacks on defense models. Fig. 5 shows the experimental results on the CIFAR-10 dataset. We select 4 defense models: (1) a model obtained through adversarial training, abbreviated as AT [30]; (2)  improved AT that optimizes a regularized surrogate loss, named as TRADES [46]; (3) an imagetransformation-based defense called JPEG [18]; and (4) a DNN-oriented compression defense called Feature Distillation [28]. All defense models adopt ResNet-50 as the backbone. Previous studies [47] have shown that AT and TRADES have the issue of robust overfitting, which leads to a significant increase in the curvature of the classification decision boundary. Figs. 5a and 5b show that G-TA outperforms TA when attacking AT and TRADES. This advantage is also demonstrated in attacking other defenses (e.g., Figs. 5d and 5c), proving the effectiveness of G-TA in attacking defense models.\n\n\nComprehensive Understanding of Tangent Attack\n\nIn the ablation studies, we conduct the experiments of the targeted attacks on the ImageNet dataset to understand our approach in depth, and the target model is ResNet-50. The results are shown in Fig. 6.\n\nInitialization. Our algorithm starts with an imagex 0 selected from the target class, and we study three selection strategies: (1) a randomly selected image, (2) the image with the shortest distance to the original image, and (3) the image with the longest distance to the original image. Fig. 6a shows that the strategy of (2) achieves the best performance.\n\nRadius Ratio. Fig. 6b shows that the performance of G-TA is not sensitive to the radius ratio r.\n\nJump Direction. Fig. 6c shows the effects of different jump directions. RandomHSJA is a variant of HSJA which adopts a random vector r that satisfies r, u > 0 as the jump direction. Fig. 6c verifies the benefit of jumping to the optimal tangent point.\n\nInitial Batch Size. In general, Fig. 6d shows that a smaller B 0 performs better since it saves queries. But B 0 = 5 performs worse than B 0 = 30 because it uses too few samples for gradient estimation. \n\n\nConclusion\n\nIn this paper, we propose a new geometric-based method for query-efficient hard-label black-box attacks. Our method relies on the observation that the minimum 2 distortion can be obtained by searching a boundary point along a tangent line of a virtual hemisphere. We offer a closed-form solution for computing the optimal tangent point and provide a formal proof of its correctness. We further propose a generalized method that replaces the hemisphere with a semi-ellipsoid to adapt to the target models with curved decision boundaries. Lastly, we evaluate our approach through extensive experiments and show its superior performance compared with baseline methods. \n\n\nA Potential Negative Societal Impacts\n\nThe adversarial attack is a major security concern in the real-world machine learning system, because the generated adversarial perturbation could be used for the malicious purpose. Our study relies only on the top-1 predicted label to craft the adversarial examples which is applicable to most real-world systems, making it more useful and practical. Although the experiments in this paper are about attacking the image classifier, this method can be used in other settings, such as the object detection, the recommender system, the facial recognition system, and the autonomous driving. In summary, this study could be used in harmful ways by malicious users.\n\nIn a broader perspective, the adversarial example is not restricted to malicious applications, and it can be used in the positive side, e.g., the generation of CAPTCHA and the privacy protection. In particular, the study of adversarial attacks can promote the defense techniques. In recent years, many proposed defenses are broken by the latest attacks, which stimulates the development of defenses.\n\nOur results also point to the potential defense techniques against hard-label attacks. For example, the defense can prohibit queries near the decision boundary, then the approximate gradient cannot be estimated, making Tangent Attack ineffective. Another possible defense is to add random perturbations to the input image to prevent effective gradient estimation, or predict random classification labels for samples near the classification decision boundary.\n\n\nB Proof of Theorem 1 B.1 Notations and Assumption\n\nBefore we formally prove Theorem 1, let us first define the notations that will be used in the proof. Let x denote the original image, and w.l.o.g. we assume the boundary sample x t\u22121 = 0 be the origin of the coordinate axis. Let B denote a n-dimensional ball centered at x t\u22121 with the radius of R, and its surface is denoted as S := \u2202B. Note that B denotes a complete ball in this proof. However, B denotes the hemisphere in the main text of the paper. Theorem 1 assumes that the classification decision boundary of the target model is the hyperplane H, which is defined by its unit normal vector u. Then, the hyperplane H divides R n into two half-spaces:\nH \u22650 = {v \u2208 R n | v, u \u2265 0}, H \u22640 = {v \u2208 R n | v, u \u2264 0}.(15)\nIn the attack, H \u22650 mainly contains the adversarial region, and H \u22640 represents the non-adversarial region. In Fig. 7, we visually represent the hyperplane H and two half-spaces in R 3 .\n\nx y Figure 7: Illustration of the entities defined in the proof, where C is a convex cone whose boundary intersects with the circle formed by all the tangent points from x to the ball B.\nz H \u22650 H \u22640 f (k) H V B \u03a0 H (x) R x Cone C y k * x k * x t\u22121 u\nSuppose x \u2208 H \u22640 \\ B is a fixed point outside B such that x, u < 0. Now, let us define the cosine function cos(a, b) := a,b a b to represent the cosine of the angle between two vectors, then we can define the convex cone C with x t\u22121 as its vertex, as shown below:\nC := v \u2208 R n | cos(v, x) \u2265 R x . (16) Fig. 7 demonstrates the convex cone C in R 3 . For v \u2208 S \u2229 C that satisfies cos(v, x) = R / x , the equation v \u2212 x 2 = x 2 \u2212 v 2 holds, i.e.\n, v is the tangent point of the tangent line from x to the surface of B.\n\nTo make the feasible region of the optimization problem (3) in Theorem 1 nonempty, we need to make an assumption about the positional relationship between x and the ball B. Let \u03a0 H : R n \u2192 H denote the orthogonal projection from R n onto the hyperplane H, we make the following assumption:\nAssumption B.1. \u03a0 H (x) \u2208 C\nNote that Assumption B.1 is not really an \"assumption\": it essentially means that there is a tangent point on S \u2229 H \u22650 , which is in the adversarial region. Assumption B.1 means the feasible region of the optimization problem (3) is a nonempty set. By repeatedly reducing the radius R, the algorithm guarantees that the optimal tangent point is in the adversarial region, thereby making Assumption B.1 always hold. In addition, according to Assumption B.1, \u03a0 H (x) \u2265 R holds.\n\nIn Theorem 1, k is an arbitrary point on the surface of the hemisphere B \u2229 H \u22650 , so this proof mainly focuses on points in this region. In the following text, the hemisphere is denoted as B := B \u2229 H \u22650 , and its surface is denoted as S := S \u2229 H \u22650 for brevity. Now, let us pick up any k \u2208 S 4 , and then the intersection point between the hyperplane H and the line passing through x and k is denoted as y k . Then, (y k , \u03bb) is the unique solution of the following equation system:\ny k = \u03bbk + (1 \u2212 \u03bb)x, y k , u = 0, 0 \u2264 \u03bb \u2264 1.(17)\nBecause the position of k determines the distance between y k and x, we can define the function f (k) := y k \u2212 x to represent the distance between x and y k .\n\n\nB.2 Proof\n\nTo prove Theorem 1, we turn to prove the following lemma, which is equivalent to Theorem 1. Lemma 1. Let S , f be defined as above, then minimizing f over the feasible region S is equivalent to finding the point k from the set S \u2229 C that is farthest away from H, i.e.,\n\narg min\nk\u2208S f (k) = arg max k\u2208(S \u2229C) k, u .(18)\nIn addition, we can replace S with B in the above equation, and the optimal solution of f (k) does not change. In other words, when the feasible region is B , the optimal solution can be always obtained at the surface of B . Thus, the following equation holds:\n\narg min \n\nProof. By simplifying the original problem to a two-dimensional plane, the proof of Lemma 1 will be readily apparent. Let V := span({x, u}) be the plane spanned by x and u. It is easy to observe B, S, C, B , and S are symmetrical about the plane V . Next, we will show that for any k \u2208 B , there must exist a point k * \u2208 S \u2229 V such that f (k * ) \u2264 f (k). To find the k * that satisfies the condition, we introduce the notation \u03a0 V : R n \u2192 V to denote the projection from R n to V . Now, take any k \u2208 B , and use k to denote the mirror point of k with respect to V , as shown in Fig. 8. The projection point \u03a0 V (k) is the midpoint of the line between k and k , i.e., k = 2\u03a0 V (k) \u2212 k.\n\nx y z f (k) Note that if k \u2208 V , then k, k and k coincide. Since B is symmetrical about the plane V , we have k \u2208 B . Now since B is the intersection of two convex sets B and H \u22650 , we know that B is also a convex set. Notice that \u03a0 V (k) = 1 2 \u00b7 (k + k ) is a convex combination of k and k , and B is a convex set, thus we conclude \u03a0 V (k) \u2208 B . Now, we will show that we can ignore any point outside of V , thus restricting the problem to the two-dimensional plane V . Formally, the following inequality holds for any k:\nH V B k k R x y k x t\u22121 k * k uf (\u03a0 V (k)) \u2264 f (k).(20)\nThe above inequality is easy to prove. Because\nx \u2208 V , we have \u03a0 V (y k \u2212 x) = \u03a0 V (y k ) \u2212 x . Therefore, f (\u03a0 V (k)) = \u03a0 V (y k ) \u2212 x = \u03a0 V (y k \u2212 x) \u2264 y k \u2212 x = f (k).(21)\nNow, we can focus on the plane V and find the optimal k * on it such that f (k * ) \u2264 f (\u03a0 V (k)). Let us define C 0 to denote the convex cone with the point x as the vertex, and its boundary is formed by all tangent lines from x to B:\nC 0 := v \u2208 R n | cos(v \u2212 x, \u2212x) \u2265 1 \u2212 R 2 x 2 .(22)\nLet k := \u03a0 V (k) be the projection point of k onto the plane V (see Fig. 9). Because k \u2208 B and k \u2208 V , we have k \u2208 \u03a0 V (B ). Now, we define k * \u2208 S \u2229 C 0 \u2229 V to be the tangent point from x to the semicircle \u03a0 V (B ). We claim k * is the optimal one that attains the minimum f (k ) among all k in \u03a0 V (B ). We denote the angle between \u2212x and u as \u03b8 1 , i.e., \u03b8 1 := arccos (cos (\u2212x, u)).\n\nThe angle between \u2212x and k \u2212 x is denoted as \u03b8 2 , i.e., \u03b8 2 := arccos (cos(\u2212x, k \u2212 x)). Based on the position of k in \u03a0 V (B ), there are two possible cases for the angle \u03b8 2 , as shown in Fig. 9a and Fig. 9b, respectively. We discuss them separately below.\n\nIn the first case (Fig. 9a), y k and \u03a0 H (x) are on the same side of x t\u22121 . By Assumption B.1, we know that\n\u03a0 H (x) \u2265 R, so cos(\u2212x, u) = 1 \u2212 \u03a0 H (x) 2 / x 2 \u2264 1 \u2212 R 2 / x 2 .\nAccording to the definition of the convex cone C 0 , u is outside C 0 . Notice that x \u2208 C 0 and k \u2208 \u03a0 V (B ), hence k \u2212 x is in the convex cone \u03a0 V (C 0 ). Therefore, based on the positions of the two vectors u and k \u2212 x with respect to the cone \u03a0 V (C 0 ), we conclude that \u03b8 1 \u2265 \u03b8 2 . In such case, the distance function is f (k ) = y k \u2212 x = | x, u | / cos(\u03b8 1 \u2212 \u03b8 2 ), as shown in Fig. 9a. Because both x and u are fixed, the value of \u03b8 1 is fixed. Therefore, the only way to minimize f (k ) is to maximize \u03b8 2 . Among all possible choices of k in \u03a0 V (B ), the k that maximizes the angle \u03b8 2 appears on\nH \u03a0 H (x) | x, u | | x, u | u k * k \u03a0 V (B) R \u03b8 1 \u03b8 2 Cone \u03a0 V (C 0 ) y k x t\u22121\nx (a) y k and \u03a0H (x) are on the same side of xt\u22121.\n\nH  In the second case (Fig. 9b), y k and \u03a0 H (x) are on different sides of x t\u22121 . In this case, \u03b8 2 \u2265 0. In particular, when \u03b8 2 = 0, y k and x t\u22121 coincide. According to Assumption B.1, \u03b8 1 > 0. The distance function can be defined as f (k ) = y k \u2212 x = | x, u | / cos(\u03b8 1 + \u03b8 2 ) in this case. Because \u03b8 1 > 0 and \u03b8 2 \u2265 0, the following inequality holds:\n\u03a0 H (x) | x, u | | x, u | u k * k \u03a0 V (B) R \u03b8 1 \u03b8 2 Cone \u03a0 V (C 0 ) x x t\u22121 y k (bf (k ) = | x, u | cos(\u03b8 1 + \u03b8 2 ) \u2265 | x, u | cos(\u03b8 1 ) \u2265 | x, u | cos(\u03b8 1 \u2212 \u03b8 2 ) .(23)\nAccording to the above inequality, the distance obtained from the second case is greater than or equal to the distance in the first case, and the distances in both cases are equal only if \u03b8 2 = 0. Therefore, we can still conclude that f (k ) \u2265 f (k * ), i.e., arg min k\u2208B f (k) = k * .\n\nFinally, we need to prove arg max k\u2208(B \u2229C) k, u = k * , so that Eq. (19) holds. The overall proof process is similar to the above proof, except that all f (k) in the above proof need to be replaced by k, u . Correspondingly, Eq. (20) needs to be changed to the following formula:\nk * , u \u2265 \u03a0 V (k), u = k, u .(24)\nFirstly, let us prove the equality part of Eq. (24): when projecting any k \u2208 (B \u2229 C) onto the plane V , the value of k, u does not change. Thus, we have \u03a0 V (k), u = k, u . Secondly, we prove the inequality part of Eq. (24): k * , u \u2265 \u03a0 V (k), u . Now the problem is reduced to the plane V again.\nBecause \u03a0 V (k) \u2208 (B \u2229 C \u2229 V )\n, only the first case mentioned above can happen (Fig. 9a). By a similar argument, we conclude that arg max k\u2208(B \u2229C) k, u = k * holds, which proves Lemma 1. Consequently, Theorem 1 holds.\n\n\nC Experimental Settings\n\nIn this section, we provide the hyperparameter settings of the compared methods, i.e., HSJA [7], BA [4], Sign-OPT [11], and SVM-OPT [11].\n\nExperimental Equipment. The experiments of all compared methods are conducted by using PyTorch 1.7.1 framework on a NVIDIA 1080Ti GPU.\n\nHSJA. Hyperparameters of HSJA [7] are listed in Table 4. We translate the implementation code into the PyTorch version for the experiments. In the experiments of targeted attacks, we randomly select an image from the target class as the initial adversarial example. For fair comparison, we set \u03b3, threshold of the binary search 1.0 B0, the initial batch size for gradient estimation 100 Bmax, the maximum batch size for gradient estimation 10,000 the search method for step size geometric progression number of iterations 64\n\nImageNet \u03b3, threshold of the binary search 1,000.0 B0, the initial batch size for gradient estimation 100 Bmax, the maximum batch size for gradient estimation 10,000 the search method for step size geometric progression number of iterations 64    Hyperparameter Value k, number of queries for estimating gradients 100 \u03b1, the step size of the gradient descent of \u03b8 0.2 \u03b2, used for the gradient estimation of \u03b8 and determining the stopping threshold of binary search 0.001 the number of iterations 1,000 the binary search's stopping threshold of the CIFAR-10 dataset \u03b2 500 the binary search's stopping threshold of the ImageNet dataset 1 \u00d7 10 \u22124 the hyperparameters of TA and G-TA to be the same with HSJA, i.e., the same initial batch size B 0 and the same \u03b3.\n\nBA. Hyperparameters of BA [4] are listed in Table 5. In the experiments, we directly use the implementation of BA from Foolbox 2.0 [35,36], and adopt a randomly selected image from the target class as the initialization in the targeted attack.\n\nSign-OPT and SVM-OPT. Hyperparameters of Sign-OPT [11] and SVM-OPT [11] are listed in Tables 6 and 7. We translate the implementation code into the PyTorch version for the experiments.\n\nIn the experiments of targeted attacks, we set the initial direction \u03b8 0 of Sign-OPT and SVM-OPT to the direction of a randomly selected image of the target class.\n\n\nD Experimental Results\n\n\nD.1 Limitation of Tangent Attack\n\nThe proposed approach supports all types of attacks, including both untargeted and targeted attacks under the both 2 and \u221e norm constraints. This is the strength of the proposed approach. However, in the \u221e norm attack, TA and G-TA obtain the similar performance to the baseline method HSJA. Because under the definition of the \u221e norm distance: D \u221e (x, y) := max i (|x i \u2212 y i |), i \u2208 {1, . . . , d} (d is the image dimension), the intersection of the tangent line and the decision boundary may not be the one with the shortest \u221e norm distance to the original image. Therefore, searching the boundary sample along the tangent line cannot always outperform HSJA in the \u221e norm attack.\n\nTables 8 and 9 demonstrate the experimental results of attacking against undefended models on the CIFAR-10 and ImageNet datasets. Untargeted Attack @300 @1K @2K @5K @8K @10K @300 @1K @2K @5K @8K @10K\n\n\nInception-v3\n\nSign-OPT [11] Table 9: Mean \u221e distortions of different query budgets on the CIFAR-10 dataset, where the radius ratio r is set to 1.5 in G-TA. BA is not applicable to the \u221e norm attack, and thus it is not listed.\n\nTarget Model Method Targeted Attack Untargeted Attack @300 @1K @2K @5K @8K @10K @300 @1K @2K @5K @8K @10K\n\n\nPyramidNet-272\n\nSign-OPT [11]  The results of Tables 8 and 9 show that HSJA, TA and G-TA obtain the similar average \u221e distortions. Therefore, although the proposed approach is applicable to \u221e norm attack, the performance is similar to that of the baseline method HSJA.\n\n\nD.2 Experimental Results of Attacks against Defense Models\n\nWe also conduct experiments by using \u221e norm attacks to break five defense models, and the experimental results are shown in Table 10. The conclusion drawn from this table is the same as that in Tables 8 and 9: TA and G-TA obtain the similar performance with HSJA in \u221e norm attacks. Next, we conduct experiments by using 2 norm attack to break different defense models on the CIFAR-10 and ImageNet datasets. In the CIFAR-10 dataset, we select six types of defense models:\n\n\u2022 Adversarial Training (AT) [30]: the most effective defense method, which uses adversarial examples as the training data to obtain the robust classifier.\n\n\u2022 TRADES [46]: an improved AT that optimizes a regularized surrogate loss.\n\n\u2022 JPEG [18]: a standard image compression algorithm based on the discrete cosine transform, which can remove the adversarial perturbations, thereby providing some degree of defense.\n\n\u2022 Feature Distillation [28]: a defense method based on the improved JPEG image compression. Its defense mechanism is divided into two steps. Firstly, it filters out adversarial perturbations by using a semi-analytical method. Secondly, it restores the classification accuracy of benign images by using a DNN-oriented quantization process.\n\n\u2022 Feature Scatter [45]: a feature scattering-based AT method, which is an unsupervised approach for generating adversarial examples during the training.\n\n\u2022 ComDefend [23]: a defense model that consists of a compression CNN and a reconstruction CNN to transform the adversarial image into its clean version to defend against attacks.\n\nIn the ImageNet dataset, we directly use the publicly available AT models for experiments, all of which use the ResNet-50 networks as their backbones. The pre-trained weights can be downloaded from https://github.com/MadryLab/robustness. In the experiments, we set the radius ratio r of G-TA to 1.5, and the experimental results are shown in Fig. 10. In untargeted attacks (Figs. 10a,  10b, 10c), the G-TA (the semi-ellipsoid version) outperforms the TA (the hemisphere version), and the baseline method HSJA outperforms TA and G-TA. We conjecture that it is because the classification decision boundaries of the AT models on the ImageNet dataset are extremely curved in untargeted attacks, resulting in the better performance of HSJA. In targeted attacks (Figs. 10d, 10e, 10f), both TA and G-TA outperform HSJA in the attacks of different AT models. These results indicate that TA and G-TA are more suitable for the targeted attack. Another interesting finding is that SVM-OPT    (Figs. 10a, 10b, 10c) shows the results of untargeted attacks, and the second row (Figs. 10d, 10e, 10f) shows the results of targeted attacks. performs better in untargeted attacks while Sign-OPT performs better in targeted attacks. We will explore the reasons for these results in the future work.\n\nFigs. 11 and 12 show the experimental results of untargeted and targeted attacks on the CIFAR-10 dataset, respectively. In the results of untargeted attacks (Fig. 11), G-TA outperforms HSJA and TA in the attacks of ComDefend, JPEG and Feature Distillation. When the target models are AT, Feature Scatter and TRADES, the performance of G-TA is similar to that of the baseline attack method HSJA.\n\nIn addition, in the experimental results of targeted attacks (Fig. 12), the performance of G-TA is similar to that of TA when attacking different defense models.\n\n\nD.3 Distributions of Distortions across Different Adversarial Examples\n\nSo far, all the experimental results only show the average 2 distortion of 1,000 adversarial examples.\n\nTo check the distortion of each adversarial example in more detail, we extract the 2 distortions of 20 samples from HSJA, TA and G-TA. These samples are selected from 1,000 images in the following way: from the 1st image to the 1,000th image, we select one image for every 50 images. Fig. 13 shows the distributions of 2 distortions across 20 adversarial examples on the ImageNet dataset, where the 1st image's \"image number index\" is 0. The results indicate that the 2 distortions obtained by TA and G-TA are uniformly better than that of the baseline method HSJA. Thus, our approach can obtain better 2 distortions on different adversarial examples, not just on specific samples.\n\n\nD.4 Experimental Results of Median Distortions\n\nIn this section, we report the median 2 distortions of different query budgets on the CIFAR-10 and ImageNet datasets. Tables 11 and 12 show the experimental results. We can draw the following conclusions based on the results.\n\n(1) TA and G-TA perform better in attacking high-resolution images, i.e., the images of the ImageNet dataset. The median 2 distortions of Table 11 are larger than that of Table 12, because the highresolution images of the ImageNet dataset lead to larger 2 distortions.\n\n(2) TA is more effective in the targeted attacks. We speculate that it is because the adversarial region of the target class is narrower and more scattered in the targeted attack, resulting in a smoother decision boundary. Thus, TA is more suitable for targeted attacks.  distortions of different query budgets on the ImageNet dataset. \"-\" denotes no adversarial example is found in this query budget.\n\n\nTarget Model\n\nMethod Targeted Attack Untargeted Attack @300 @1K @2K @5K @8K @10K @300 @1K @2K @5K @8K @10K\n\nFigure 3 :\n3The illustration of the optimal tangent point k for the flat decision boundary. The tangent point k is on the surface of a virtual hemisphere B with a radius R centered at the adversarial example x t\u22121 . x is the original image, x t is the intersection point of the tangent line and the decision hyperplane H, k and x are the orthogonal projections of k and x onto H and z axis, respectively.we refer the readers toFig. 2for an intuitive geometrical explanation. Eq.(3)is computationally expensive to solve in the high-dimensional space. Fortunately, we show there actually exists a closed-form solution.\n\n\nspanned by x and u.\n\nFigure 4 :\n4Illustration of the derivation of Generalized Tangent Attack, which replaces the hemisphere B with a semi-ellipsoid to increase the height of k to adapt to curved decision boundaries.\n\n\na wide residual network with 28 layers and 10 times width expansion (WRN-28) [44]; and (4) a wide residual network with 40 layers (WRN-40) [44]. In the ImageNet dataset, we select four target models from an off-the-shelf library containing pre-trained weights 3 : (1) Inception-v3 [39], (2) Inception-v4 [38], (3) ResNet-101 [20], and (4) SENet-154 [21]. Evaluation Metric. Following previous studies [43], we report the mean 2 distortions as 1 |X| x\u2208X ( x adv \u2212 x ) under different query budgets, where X is the test set.\n\nFigure 5 :\n5Experimental results of the attacks against defense models with the backbone of ResNet-50.\n\nFigure 6 :\n6Experimental results of ablation studies.\n\nFigure 8 :\n8Illustration of the points used in proving Lemma 1, where k is the mirror point of k with respect to the plane V , and k is the projection of k onto the plane V .\n\n\n) y k and \u03a0H (x) are on different sides of xt\u22121.\n\nFigure 9 :\n9Illustration of the problem reduced to the plane V . the boundary of \u03a0 V (C 0 ) \u2229 H \u22650 . The only point that satisfies this condition is the tangent point k * . Therefore, in the first case, arg min k\u2208B f (k) = k * .\n\n\nk, number of queries for estimating an approximate gradient 200 \u03b1, the update step size of the direction \u03b8 0.2 \u03b2, used for the gradient estimation of \u03b8 and determining the stopping threshold of binary search 0.001 the number of iterations 1,000 the binary search's stopping threshold of the CIFAR-10 dataset \u03b2 500 the binary search's stopping threshold of the ImageNet dataset 1 \u00d7 10 \u22124\n\n\n0.194 0.110 0.072 0.032 0.022 0.019 0.082 0.029 0.020 0.012 0.010 0.009\n\nFigure 10 :\n10Experimental results of 2 norm attacks against adversarial trained ResNet-50 networks on the ImageNet dataset, where the first row\n\nFigure 11 :\n11Experimental results of the 2 norm untargeted attacks against defense models on the CIFAR-10 dataset, where all defense models adopt the backbone of ResNet-50 network.\n\nFigure 12 :\n12Experimental results of the 2 norm targeted attacks against defense models on the CIFAR-10 dataset, where all defense models adopt the backbone of ResNet-50 network.\n\nFigure 13 :\n13Comparisons of 2 distortions across 20 adversarial examples in targeted attacks of the ImageNet dataset.\n\nTable 1 :\n1Mean 2 distortions of different query budgets on the ImageNet dataset, where r = 1.1. OPT [11] 103.939 87.706 71.291 46.744 34.640 29.414 121.085 79.158 43.642 16.625 10.557 8.680 SVM-OPT [11] 101.630 82.950 67.965 46.275 35.694 31.106 121.135 66.027 36.763 15.736 10.501 8.789 OPT [11] 101.620 85.731 69.719 46.416 34.957 30.004 132.991 86.431 48.292 18.678 11.567 9.262 SVM-OPT [11] 99.856 81.342 66.982 45.667 35.477 31.152 132.227 72.920 41.095 17.611 11.OPT [11] 75.722 62.876 49.191 30.155 21.333 17.672 70.035 47.705 27.314 10.890 6.643 5.245 SVM-OPT [11] 75.680 58.932 47.073 30.348 22.553 19.312 69.854 40.291 23.692 10.Target Model \nMethod \nTargeted Attack \nUntargeted Attack \n@300 \n@1K \n@2K \n@5K @8K @10K @300 \n@1K \n@2K \n@5K @8K @10K \n\nInception-v3 \n\nBA [4] \n111.798 108.044 106.283 102.715 86.931 78.326 \n-\n107.558 102.309 95.776 78.668 60.296 \nSign-HSJA [7] \n111.562 95.295 82.111 52.544 37.395 30.425 103.605 57.295 37.185 15.484 9.989 7.967 \nTA \n103.781 80.327 66.708 42.121 30.846 25.566 94.752 52.523 35.229 15.040 9.748 7.793 \nG-TA \n103.724 81.089 67.168 42.434 31.011 25.587 94.972 52.278 34.734 14.850 9.673 7.757 \n\nInception-v4 \n\nBA [4] \n110.343 106.616 104.586 100.321 84.058 75.507 \n-\n116.075 111.474 104.451 86.572 66.283 \nSign-418 9.372 \nHSJA [7] \n109.670 93.916 80.937 52.358 37.773 30.958 110.727 63.731 42.290 17.936 11.367 8.911 \nTA \n101.666 78.683 65.304 41.629 30.993 25.958 101.207 58.616 40.314 17.639 11.304 8.907 \nG-TA \n101.495 79.210 65.888 42.002 30.965 25.847 101.324 58.718 40.106 17.296 11.032 8.691 \n\nSENet-154 \n\nBA [4] \n81.090 77.723 76.122 71.967 55.953 47.652 \n-\n75.998 71.671 66.983 53.917 40.725 \nSign-494 6.666 5.409 \nHSJA [7] \n77.035 63.488 51.802 30.138 19.680 16.261 71.248 38.035 24.895 10.218 5.855 4.842 \nTA \n70.739 55.256 43.694 24.961 16.756 13.876 65.589 35.689 24.037 10.039 5.774 4.766 \nG-TA \n70.591 55.224 44.047 25.041 16.854 14.047 65.846 35.601 23.730 9.902 5.720 4.738 \n\nResNet-101 \n\nBA [4] \n81.565 77.903 76.366 72.392 58.746 51.679 \n-\n64.007 60.389 56.544 44.175 31.371 \nSign-OPT [11] 76.732 63.939 51.231 32.439 23.160 19.248 56.244 38.282 21.985 10.048 7.050 6.050 \nSVM-OPT [11] 77.031 61.417 49.842 32.806 24.553 20.964 55.894 32.638 19.409 9.830 7.185 6.281 \nHSJA [7] \n76.121 63.091 52.301 31.018 20.472 16.911 56.264 27.443 17.717 7.649 4.723 4.019 \nTA \n72.434 57.969 47.142 27.699 18.788 15.414 53.197 26.777 17.651 7.730 4.822 4.107 \nG-TA \n72.459 58.320 47.297 27.905 19.045 15.633 53.142 26.597 17.345 7.568 4.712 4.021 \n\n\n\nTable 2 :\n2Mean 2 distortions with different query budgets on the CIFAR-10 dataset, where r = 1.5.Target Model \nMethod \nTargeted Attack \nUntargeted Attack \n@300 @1K @2K @5K @8K @10K @300 @1K @2K @5K @8K @10K \n\nPyramidNet-272 \n\nBA [4] \n8.651 8.073 8.013 6.387 4.189 3.333 \n-\n5.636 4.725 4.414 2.750 1.696 \nSign-OPT [11] 8.279 6.331 4.250 1.718 0.960 0.718 4.387 2.334 1.178 0.403 0.267 0.226 \nSVM-OPT [11] 9.207 6.801 4.530 2.010 1.207 0.947 4.481 2.318 1.093 0.414 0.276 0.236 \nHSJA [7] \n7.917 4.329 2.523 0.793 0.489 0.397 4.505 1.279 0.713 0.333 0.255 0.227 \nTA \n7.943 4.267 2.488 0.809 0.503 0.406 4.256 1.275 0.710 0.329 0.253 0.226 \nG-TA \n7.816 4.277 2.469 0.803 0.505 0.412 4.432 1.270 0.702 0.329 0.252 0.225 \n\nGDAS \n\nBA [4] \n8.487 7.885 7.821 6.034 3.632 2.703 \n-\n2.717 2.514 2.373 1.642 1.106 \nSign-OPT [11] 8.372 6.514 4.351 1.827 0.987 0.711 4.917 4.159 3.260 1.352 0.452 0.250 \nSVM-OPT [11] 9.529 7.243 5.092 2.347 1.317 0.958 4.909 3.950 2.736 1.082 0.371 0.234 \nHSJA [7] \n7.714 3.566 1.966 0.591 0.365 0.301 2.188 0.756 0.483 0.261 0.208 0.189 \nTA \n7.674 3.529 1.946 0.585 0.366 0.302 2.190 0.774 0.485 0.257 0.206 0.187 \nG-TA \n7.697 3.558 1.959 0.583 0.361 0.298 2.161 0.745 0.476 0.255 0.204 0.185 \n\nWRN-28 \n\nBA [4] \n8.688 8.046 7.984 5.786 2.486 1.555 \n-\n4.425 3.648 3.435 1.543 0.832 \nSign-OPT [11] 8.258 5.576 3.260 1.087 0.593 0.459 3.093 1.494 0.828 0.319 0.239 0.213 \nSVM-OPT [11] 9.516 5.968 3.744 1.367 0.728 0.553 2.977 1.466 0.723 0.325 0.245 0.221 \nHSJA [7] \n6.810 2.603 1.326 0.518 0.389 0.347 3.052 0.797 0.508 0.299 0.250 0.232 \nTA \n6.802 2.556 1.311 0.519 0.394 0.353 2.974 0.785 0.496 0.293 0.249 0.233 \nG-TA \n6.755 2.543 1.281 0.513 0.387 0.345 2.995 0.782 0.502 0.298 0.250 0.232 \n\nWRN-40 \n\nBA [4] \n8.658 8.014 7.953 5.738 2.484 1.566 \n-\n4.377 3.586 3.367 1.487 0.821 \nSign-OPT [11] 8.156 5.579 3.300 1.186 0.646 0.501 4.754 3.239 1.885 0.311 0.226 0.201 \nSVM-OPT [11] 9.339 6.061 3.840 1.445 0.800 0.605 4.457 2.756 0.739 0.310 0.229 0.206 \nHSJA [7] \n6.909 2.648 1.330 0.528 0.400 0.357 2.992 0.777 0.498 0.290 0.242 0.225 \nTA \n6.944 2.579 1.295 0.523 0.398 0.358 2.926 0.770 0.490 0.288 0.243 0.227 \nG-TA \n6.783 2.605 1.320 0.535 0.403 0.361 2.952 0.772 0.492 0.288 0.241 0.223 \n\n\n\nTable 3 :\n3Experimental results of the combined method of QEBA-S and TA.Target Model \nMethod \nTargeted Attack \n@300 \n@1K \n@2K \n@5K \n@8K \n@10K \n\nInception-v3 \nQEBA-S [25] \n100.295 79.604 63.621 35.194 22.773 18.414 \nQEBA-S + TA 104.490 75.622 59.836 33.112 22.329 17.799 \n\nInception-v4 \nQEBA-S [25] \n97.772 \n77.347 62.451 35.275 23.204 19.002 \nQEBA-S + TA 101.845 73.838 58.554 33.288 23.160 18.736 \n\nSENet-154 \nQEBA-S [25] \n72.831 \n55.367 42.674 21.988 13.888 11.210 \nQEBA-S + TA \n76.547 \n52.269 39.740 20.608 13.873 11.016 \n\nResNet-101 \nQEBA-S [25] \n75.567 \n57.929 44.983 23.209 14.402 11.467 \nQEBA-S + TA \n78.709 \n53.917 41.245 21.198 13.856 10.773 \n\n\n\n[ 38 ]\n38Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alexander Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. In AAAI Conference on Artificial Intelligence, page 4278-4284, 2017. [39] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In IEEE Conference on Computer Vision and Pattern Haichao Zhang and Jianyu Wang. Defense against adversarial attacks using feature scattering-based adversarial training. In Advances in Neural Information Processing Systems, pages 1829-1839, 2019. [46] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan. Theoretically principled trade-off between robustness and accuracy. In International Conference on Machine Learning, pages 7472-7482, 2019. [47] Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, and Mohan Kankanhalli. Geometryaware instance-reweighted adversarial training. In International Conference on Learning Representations, pages 1-29, 2021.Recognition, pages 2818-2826, 2016. \n\n[40] Xin Wang, Jie Ren, Shuyun Lin, Xiangming Zhu, Yisen Wang, and Quanshi Zhang. A unified ap-\nproach to interpreting and boosting adversarial transferability. In International Conference on Learning \nRepresentations, pages 1-35, 2021. \n\n[41] Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, and Xingjun Ma. Skip connections matter: on the \ntransferability of adversarial examples generated with ResNets. In International Conference on Learning \nRepresentations, pages 1-15, 2020. \n\n[42] Yoshihiro Yamada, Masakazu Iwamura, Takuya Akiba, and Koichi Kise. Shakedrop regularization for \ndeep residual learning. IEEE Access, 7:186126-186136, 2019. \n\n[43] Ziang Yan, Yiwen Guo, Jian Liang, and Changshui Zhang. Policy-driven attack: learning to query for \nhard-label black-box adversarial examples. In International Conference on Learning Representations, \npages 1-15, 2021. \n\n[44] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In British Machine Vision Conference, \npages 87.1-87.12, 2016. \n\n[45] \n\nTable 4 :\n4The hyperparameters of HSJA.Dataset \nHyperparameter \nValue \n\nCIFAR-10 \n\n\n\nTable 5 :\n5The hyperparameters of BA.Hyperparameter \nValue \n\nmaximum number of trials per iteration \n25 \nnumber of iterations \n1,200 \nspherical step size \n0.01 \nsource step size \n0.01 \nstep size adaptation multiplier \n1.5 \ndisable automatic batch size tuning \nFalse \ngenerate candidates and random numbers without using multithreading \nFalse \n\n\n\nTable 6 :\n6The hyperparameters of Sign-OPT.Hyperparameter \nValue \n\n\n\nTable 7 :\n7The hyperparameters of SVM-OPT.\n\nTable 8 :\n8Mean \u221e distortions of different query budgets on the ImageNet dataset, where the radius ratio r is set to 1.1 in G-TA. BA is not applicable to the \u221e norm attack, hence it is not listed.Target Model \nMethod \nTargeted Attack \n\n\nTable 10 :\n10The experimental results of performing \u221e norm attacks against the defense models on the CIFAR-10 dataset, where the radius ratio r is set to 1.5 in G-TA.Target Model \nMethod \nUntargeted Attack \n@300 @1K @2K @5K @8K @10K \n\nAT [30] \n\nSign-OPT [11] 0.731 0.519 0.395 0.288 0.255 0.243 \nSVM-OPT [11] 0.719 0.498 0.382 0.287 0.261 0.251 \nHSJA [7] \n0.181 0.145 0.121 0.090 0.080 0.075 \nTA \n0.184 0.147 0.121 0.090 0.079 0.075 \nG-TA \n0.181 0.145 0.121 0.090 0.080 0.075 \n\nTRADES [46] \n\nSign-OPT [11] 0.748 0.562 0.419 0.304 0.269 0.257 \nSVM-OPT [11] 0.743 0.534 0.409 0.308 0.281 0.271 \nHSJA [7] \n0.194 0.162 0.137 0.106 0.095 0.090 \nTA \n0.195 0.163 0.138 0.107 0.095 0.090 \nG-TA \n0.194 0.163 0.138 0.107 0.095 0.090 \n\nJPEG [18] \n\nSign-OPT [11] 0.301 0.292 0.281 0.262 0.250 0.245 \nSVM-OPT [11] 0.301 0.288 0.275 0.256 0.249 0.246 \nHSJA [7] \n0.094 0.086 0.078 0.066 0.061 0.058 \nTA \n0.093 0.087 0.080 0.067 0.061 0.058 \nG-TA \n0.097 0.091 0.081 0.068 0.062 0.059 \n\nFeature Distillation [28] \n\nSign-OPT [11] 0.344 0.330 0.317 0.290 0.273 0.266 \nSVM-OPT [11] 0.354 0.338 0.323 0.297 0.284 0.279 \nHSJA [7] \n0.090 0.087 0.080 0.069 0.064 0.061 \nTA \n0.089 0.086 0.079 0.070 0.063 0.060 \nG-TA \n0.090 0.086 0.079 0.067 0.062 0.059 \n\nFeature Scatter [45] \n\nSign-OPT [11] 0.561 0.380 0.246 0.135 0.110 0.101 \nSVM-OPT [11] 0.550 0.344 0.222 0.137 0.116 0.110 \nHSJA [7] \n0.202 0.137 0.104 0.062 0.048 0.042 \nTA \n0.202 0.137 0.104 0.062 0.048 0.042 \nG-TA \n0.205 0.139 0.105 0.062 0.048 0.042 \n\n\n\n\n0 2K 4K 6K 8K 10K 12K 14K 16K 18K 20K (d) AT ( 2 norm = 3.0) 0 2K 4K 6K 8K 10K 12K 14K 16K 18K 20K (e) AT ( \u221e norm = 4/255) 0 2K 4K 6K 8K 10K 12K 14K 16K 18K 20KNumber of Queries \n\n0 \n5 \n10 \n15 \n20 \n25 \n30 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n70 \n75 \n80 \n85 \n90 \n\nMean \u2113 \n2 Distortion \n\nG-TA \nTA \nHSJA \nBA \nSVM-OPT \nSign-OPT \n\nNumber of Queries \n\n0 \n5 \n10 \n15 \n20 \n25 \n30 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n70 \n75 \n80 \n85 \n90 \n\nMean \u2113 \n2 Distortion \n\nG-TA \nTA \nHSJA \nBA \nSVM-OPT \nSign-OPT \n\nNumber of Queries \n\n0 \n5 \n10 \n15 \n20 \n25 \n30 \n35 \n40 \n45 \n50 \n55 \n60 \n65 \n70 \n75 \n80 \n85 \n90 \n\nMean \u2113 \n2 Distortion \n\nG-TA \nTA \nHSJA \nBA \nSVM-OPT \nSign-OPT \n\n\n\nTable 11 :\n11Median 2\nPre-trained weights: https://github.com/machanic/SimulatorAttack 3 Pre-trained weights: https://github.com/Cadene/pretrained-models.pytorch\nNote that k defined here may not be a tangent point on the ball.\nAcknowledgmentsThis research is partially supported by the National Key R&D Program of China (2019YFB1405703) and TC190A4DA/3, the National Natural Science Foundation of China (Grant Nos. 62021002, 61972221). Yisen Wang is partially supported by the National Natural Science Foundation of China under Grant 62006153, and Project 2020BD006 supported by PKU-Baidu Fund.Appendix\nBlack-box adversarial attacks with limited queries and information. Ilyas Andrew, Engstrom Logan, Athalye Anish, Lin Jessy, International Conference on Machine Learning. Ilyas Andrew, Engstrom Logan, Athalye Anish, and Lin Jessy. Black-box adversarial attacks with limited queries and information. In International Conference on Machine Learning, pages 2142-2151, 2018.\n\nImproving query efficiency of black-box adversarial attack. Yang Bai, Yuyuan Zeng, Yong Jiang, Yisen Wang, Shu-Tao Xia, Weiwei Guo, European Conference on Computer Vision. Yang Bai, Yuyuan Zeng, Yong Jiang, Yisen Wang, Shu-Tao Xia, and Weiwei Guo. Improving query efficiency of black-box adversarial attack. In European Conference on Computer Vision, pages 101-116, 2020.\n\nPractical black-box attacks on deep neural networks using efficient query mechanisms. Arjun Nitin, Warren Bhagoji, Bo He, Dawn Li, Song, European Conference on Computer Vision. Arjun Nitin Bhagoji, Warren He, Bo Li, and Dawn Song. Practical black-box attacks on deep neural networks using efficient query mechanisms. In European Conference on Computer Vision, pages 158-174, 2018.\n\nDecision-based adversarial attacks: reliable attacks against black-box machine learning models. Wieland Brendel, Jonas Rauber, Matthias Bethge, International Conference on Learning Representations. Wieland Brendel, Jonas Rauber, and Matthias Bethge. Decision-based adversarial attacks: reliable attacks against black-box machine learning models. In International Conference on Learning Representations, pages 1-12, 2018.\n\nGuessing smart: biased sampling for efficient black-box adversarial attacks. T Brunner, F Diehl, M T Le, A Knoll, IEEE/CVF International Conference on Computer Vision. T. Brunner, F. Diehl, M. T. Le, and A. Knoll. Guessing smart: biased sampling for efficient black-box adversarial attacks. In IEEE/CVF International Conference on Computer Vision, pages 4957-4965, 2019.\n\nTowards evaluating the robustness of neural networks. Nicholas Carlini, David A Wagner, IEEE Symposium on Security and Privacy. Nicholas Carlini and David A. Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium on Security and Privacy, pages 39-57, 2017.\n\nHopSkipJumpAttack: a query-efficient decisionbased adversarial attack. Jianbo Chen, Jordan Michael, I , Wainwright Martin, J , IEEE Symposium on Security and Privacy. Jianbo Chen, Jordan Michael I., and Wainwright Martin J. HopSkipJumpAttack: a query-efficient decision- based adversarial attack. In IEEE Symposium on Security and Privacy, pages 1277-1294, 2020.\n\nRayS: a ray searching method for hard-label adversarial attack. Jinghui Chen, Quanquan Gu, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. Jinghui Chen and Quanquan Gu. RayS: a ray searching method for hard-label adversarial attack. In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, page 1739-1747, 2020.\n\nZOO: zeroth order optimization based black-box attacks to deep neural networks without training substitute models. Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, Cho-Jui Hsieh, In ACM Workshop on Artificial Intelligence and Security. Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. ZOO: zeroth order optimization based black-box attacks to deep neural networks without training substitute models. In ACM Workshop on Artificial Intelligence and Security, pages 15-26, 2017.\n\nQuery-efficient hard-label black-box attack: an optimization-based approach. Minhao Cheng, Thong Le, Pin-Yu Chen, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, International Conference on Learning Representations. Minhao Cheng, Thong Le, Pin-Yu Chen, Huan Zhang, JinFeng Yi, and Cho-Jui Hsieh. Query-efficient hard-label black-box attack: an optimization-based approach. In International Conference on Learning Representations, pages 1-14, 2019.\n\nSign-OPT: a query-efficient hard-label adversarial attack. Minhao Cheng, Simranjit Singh, Pin-Yu Chen, Sijia Liu, Cho-Jui Hsieh, International Conference on Learning Representations. Minhao Cheng, Simranjit Singh, Pin-Yu Chen, Sijia Liu, and Cho-Jui Hsieh. Sign-OPT: a query-efficient hard-label adversarial attack. In International Conference on Learning Representations, pages 1-16, 2020.\n\nImproving black-box adversarial attacks with a transfer-based prior. Shuyu Cheng, Yinpeng Dong, Advances in Neural Information Processing Systems. Tianyu Pang, Hang Su, and Jun ZhuShuyu Cheng, Yinpeng Dong, Tianyu Pang, Hang Su, and Jun Zhu. Improving black-box adversarial attacks with a transfer-based prior. In Advances in Neural Information Processing Systems, pages 10934-10944, 2019.\n\nAutoAugment: learning augmentation strategies from data. Barret Ekin D Cubuk, Dandelion Zoph, Vijay Mane, Quoc V Vasudevan, Le, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. AutoAugment: learning augmentation strategies from data. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 113-123, 2019.\n\nImageNet: a large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, IEEE Conference on Computer Vision and Pattern Recognition. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: a large-scale hierarchical image database. In IEEE Conference on Computer Vision and Pattern Recognition, pages 248-255, 2009.\n\nSearching for a robust neural architecture in four GPU hours. Xuanyi Dong, Yi Yang, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Xuanyi Dong and Yi Yang. Searching for a robust neural architecture in four GPU hours. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1761-1770, 2019.\n\nEfficient decisionbased black-box adversarial attacks on face recognition. Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, Jun Zhu, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, and Jun Zhu. Efficient decision- based black-box adversarial attacks on face recognition. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7714-7722, 2019.\n\nRobustness of classifiers: from adversarial to random noise. Alhussein Fawzi, Pascal Seyed-Mohsen Moosavi-Dezfooli, Frossard, Advances in Neural Information Processing Systems. Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. Robustness of classifiers: from adversarial to random noise. In Advances in Neural Information Processing Systems, page 1632-1640, 2016.\n\nCountering adversarial images using input transformations. Chuan Guo, Mayank Rana, Moustapha Cisse, Laurens Van Der Maaten, International Conference on Learning Representations. Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van der Maaten. Countering adversarial images using input transformations. In International Conference on Learning Representations, pages 1-12, 2018.\n\nDeep pyramidal residual networks. Dongyoon Han, Jiwhan Kim, Junmo Kim, IEEE Conference on Computer Vision and Pattern Recognition. Dongyoon Han, Jiwhan Kim, and Junmo Kim. Deep pyramidal residual networks. In IEEE Conference on Computer Vision and Pattern Recognition, pages 5927-5935, 2017.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, IEEE Conference on Computer Vision and Pattern Recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition, pages 770-778, 2016.\n\nSqueeze-and-excitation networks. Jie Hu, Li Shen, Gang Sun, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7132-7141, 2018.\n\nPrior convictions: black-box adversarial attacks with bandits and priors. Andrew Ilyas, Logan Engstrom, Aleksander Madry, International Conference on Learning Representations. Andrew Ilyas, Logan Engstrom, and Aleksander Madry. Prior convictions: black-box adversarial attacks with bandits and priors. In International Conference on Learning Representations, pages 1-25, 2019.\n\nComDefend: an efficient image compression model to defend adversarial examples. Xiaojun Jia, Xingxing Wei, Xiaochun Cao, Hassan Foroosh, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Xiaojun Jia, Xingxing Wei, Xiaochun Cao, and Hassan Foroosh. ComDefend: an efficient image compres- sion model to defend adversarial examples. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6084-6092, 2019.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Alex Krizhevsky. Learning multiple layers of features from tiny images. pages 1-60, 2009.\n\nQEBA: Query-efficient boundary-based blackbox attack. Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, and Bo Li. QEBA: Query-efficient boundary-based blackbox attack. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1221-1230, 2020.\n\nDelving into transferable adversarial examples and black-box attacks. Yanpei Liu, Xinyun Chen, Chang Liu, Dawn Song, International Conference on Learning Representations. Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn Song. Delving into transferable adversarial examples and black-box attacks. In International Conference on Learning Representations, pages 1-24, 2017.\n\nA geometry-inspired decision-based attack. Yujia Liu, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, IEEE/CVF International Conference on Computer Vision. Yujia Liu, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. A geometry-inspired decision-based attack. In IEEE/CVF International Conference on Computer Vision, pages 4889-4897, 2019.\n\nFeature distillation: DNNoriented jpeg compression against adversarial examples. Zihao Liu, Qi Liu, Tao Liu, Nuo Xu, Xue Lin, Yanzhi Wang, Wujie Wen, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Zihao Liu, Qi Liu, Tao Liu, Nuo Xu, Xue Lin, Yanzhi Wang, and Wujie Wen. Feature distillation: DNN- oriented jpeg compression against adversarial examples. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 860-868, 2019.\n\nSimulating unknown target models for query-efficient black-box attacks. Chen Ma, Li Chen, Jun-Hai Yong, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Chen Ma, Li Chen, and Jun-Hai Yong. Simulating unknown target models for query-efficient black-box attacks. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11835-11844, 2021.\n\nTowards deep learning models resistant to adversarial attacks. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu, International Conference on Learning Representations. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. To- wards deep learning models resistant to adversarial attacks. In International Conference on Learning Representations, pages 1-28, 2018.\n\nSurFree: a fast surrogate-free black-box attack. Thibault Maho, Teddy Furon, Erwan Le Merrer, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Thibault Maho, Teddy Furon, and Erwan Le Merrer. SurFree: a fast surrogate-free black-box attack. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10430-10439, 2021.\n\nParsimonious black-box adversarial attacks via efficient combinatorial optimization. Seungyong Moon, Gaon An, Hyun Oh Song, International Conference on Machine Learning. Seungyong Moon, Gaon An, and Hyun Oh Song. Parsimonious black-box adversarial attacks via efficient combinatorial optimization. In International Conference on Machine Learning, pages 4636-4645, 2019.\n\nDeepFool: a simple and accurate method to fool deep neural networks. Alhussein Seyed-Mohsen Moosavi-Dezfooli, Pascal Fawzi, Frossard, IEEE Conference on Computer Vision and Pattern Recognition. Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. DeepFool: a simple and accurate method to fool deep neural networks. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2574-2582, 2016.\n\nGeoDA: a geometric framework for black-box adversarial attacks. Ali Rahmati, Pascal Seyed-Mohsen Moosavi-Dezfooli, Huaiyu Frossard, Dai, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, and Huaiyu Dai. GeoDA: a geometric framework for black-box adversarial attacks. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8446-8455, 2020.\n\nFoolbox: a Python toolbox to benchmark the robustness of machine learning models. Jonas Rauber, Wieland Brendel, Matthias Bethge, Reliable Machine Learning in the Wild Workshop of International Conference on Machine Learning. Jonas Rauber, Wieland Brendel, and Matthias Bethge. Foolbox: a Python toolbox to benchmark the robustness of machine learning models. In Reliable Machine Learning in the Wild Workshop of International Conference on Machine Learning, pages 1-6, 2017.\n\nFoolbox Native: fast adversarial attacks to benchmark the robustness of machine learning models in PyTorch, TensorFlow, and JAX. Jonas Rauber, Roland Zimmermann, Matthias Bethge, Wieland Brendel, Journal of Open Source Software. 5532607Jonas Rauber, Roland Zimmermann, Matthias Bethge, and Wieland Brendel. Foolbox Native: fast adversarial attacks to benchmark the robustness of machine learning models in PyTorch, TensorFlow, and JAX. Journal of Open Source Software, 5(53):2607, 2020.\n\nPolishing decision-based adversarial noise with a customized sampling. Yucheng Shi, Yahong Han, Qi Tian, IEEE/CVF Conference on Computer Vision and Pattern Recognition. Inception-v3Yucheng Shi, Yahong Han, and Qi Tian. Polishing decision-based adversarial noise with a customized sampling. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1030-1038, 2020. Inception-v3\n\n. G-Ta , 97.449 75.499 62.484 38.886 26.004 20.091 96.410 50.985 31.176 11.861 7.549 6.087G-TA 97.449 75.499 62.484 38.886 26.004 20.091 96.410 50.985 31.176 11.861 7.549 6.087\n\nInception-v4. Inception-v4\n\n. G-Ta , 95.563 75.889 62.404 38.457 26.495 21.069 101.186 57.672 36.743 13.999 8.694 6.856G-TA 95.563 75.889 62.404 38.457 26.495 21.069 101.186 57.672 36.743 13.999 8.694 6.856\n\nSENet-154. SENet-154\n\n. G-Ta , 66.077 51.852 41.065 21.946 13.461 10.899 65.122 33.841 21.823 7.772 4.231 3.489G-TA 66.077 51.852 41.065 21.946 13.461 10.899 65.122 33.841 21.823 7.772 4.231 3.489\n\n. G-Ta , 69.117 56.275 44.315 24.316 15.133 11.946 51.883 24.403 14.643 5.842 3.703 3.191G-TA 69.117 56.275 44.315 24.316 15.133 11.946 51.883 24.403 14.643 5.842 3.703 3.191\n\nMedian 2 distortions of different query budgets on the CIFAR-10 dataset. Target Model Method Targeted Attack Untargeted Attack -300 @1K @2K @5K @8K @10K 300 @1K @2K @5K @8K @10K. Table. 12Table 12: Median 2 distortions of different query budgets on the CIFAR-10 dataset. Target Model Method Targeted Attack Untargeted Attack - 300 @1K @2K @5K @8K @10K 300 @1K @2K @5K @8K @10K\n", "annotations": {"author": "[{\"end\":150,\"start\":81},{\"end\":269,\"start\":151},{\"end\":339,\"start\":270},{\"end\":437,\"start\":340},{\"end\":638,\"start\":438}]", "publisher": null, "author_last_name": "[{\"end\":88,\"start\":86},{\"end\":162,\"start\":159},{\"end\":277,\"start\":273},{\"end\":352,\"start\":348},{\"end\":448,\"start\":444}]", "author_first_name": "[{\"end\":85,\"start\":81},{\"end\":158,\"start\":151},{\"end\":272,\"start\":270},{\"end\":347,\"start\":340},{\"end\":443,\"start\":438}]", "author_affiliation": "[{\"end\":149,\"start\":90},{\"end\":268,\"start\":185},{\"end\":338,\"start\":279},{\"end\":436,\"start\":377},{\"end\":567,\"start\":472},{\"end\":637,\"start\":569}]", "title": "[{\"end\":78,\"start\":1},{\"end\":716,\"start\":639}]", "venue": null, "abstract": "[{\"end\":1827,\"start\":718}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2168,\"start\":2165},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2171,\"start\":2168},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2174,\"start\":2171},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2691,\"start\":2687},{\"end\":2694,\"start\":2691},{\"end\":2697,\"start\":2694},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3201,\"start\":3198},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3204,\"start\":3201},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3207,\"start\":3204},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3210,\"start\":3207},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4295,\"start\":4291},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4310,\"start\":4306},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4324,\"start\":4321},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4644,\"start\":4641},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4674,\"start\":4671},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4685,\"start\":4681},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4697,\"start\":4693},{\"end\":4734,\"start\":4730},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7387,\"start\":7386},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7441,\"start\":7437},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7459,\"start\":7455},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7669,\"start\":7666},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7671,\"start\":7669},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7673,\"start\":7671},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7675,\"start\":7673},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7678,\"start\":7675},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7681,\"start\":7678},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7684,\"start\":7681},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7687,\"start\":7684},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8136,\"start\":8132},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8242,\"start\":8238},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8364,\"start\":8361},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8931,\"start\":8928},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8943,\"start\":8940},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9026,\"start\":9023},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9149,\"start\":9146},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9288,\"start\":9284},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9356,\"start\":9352},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9371,\"start\":9367},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9894,\"start\":9890},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10011,\"start\":10007},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11825,\"start\":11822},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13409,\"start\":13405},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":13412,\"start\":13409},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17593,\"start\":17590},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":25243,\"start\":25240},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25258,\"start\":25254},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25272,\"start\":25268},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25306,\"start\":25303},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":25475,\"start\":25471},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":26498,\"start\":26494},{\"end\":26501,\"start\":26498},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":26532,\"start\":26528},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":26609,\"start\":26605},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":28081,\"start\":28077},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28224,\"start\":28220},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28301,\"start\":28297},{\"end\":28376,\"start\":28372},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":40181,\"start\":40177},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":41061,\"start\":41058},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":41069,\"start\":41066},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41084,\"start\":41080},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41102,\"start\":41098},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":41274,\"start\":41271},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":42556,\"start\":42553},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":42662,\"start\":42658},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":42665,\"start\":42662},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":42826,\"start\":42822},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":42843,\"start\":42839},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":44095,\"start\":44091},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":44432,\"start\":44428},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":45238,\"start\":45234},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":45449,\"start\":45445},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":45648,\"start\":45644},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":46131,\"start\":46127}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":50669,\"start\":50052},{\"attributes\":{\"id\":\"fig_2\"},\"end\":50691,\"start\":50670},{\"attributes\":{\"id\":\"fig_3\"},\"end\":50888,\"start\":50692},{\"attributes\":{\"id\":\"fig_4\"},\"end\":51413,\"start\":50889},{\"attributes\":{\"id\":\"fig_5\"},\"end\":51517,\"start\":51414},{\"attributes\":{\"id\":\"fig_6\"},\"end\":51572,\"start\":51518},{\"attributes\":{\"id\":\"fig_8\"},\"end\":51748,\"start\":51573},{\"attributes\":{\"id\":\"fig_9\"},\"end\":51799,\"start\":51749},{\"attributes\":{\"id\":\"fig_10\"},\"end\":52029,\"start\":51800},{\"attributes\":{\"id\":\"fig_11\"},\"end\":52418,\"start\":52030},{\"attributes\":{\"id\":\"fig_13\"},\"end\":52492,\"start\":52419},{\"attributes\":{\"id\":\"fig_15\"},\"end\":52638,\"start\":52493},{\"attributes\":{\"id\":\"fig_16\"},\"end\":52821,\"start\":52639},{\"attributes\":{\"id\":\"fig_17\"},\"end\":53002,\"start\":52822},{\"attributes\":{\"id\":\"fig_18\"},\"end\":53122,\"start\":53003},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":55630,\"start\":53123},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":57848,\"start\":55631},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":58503,\"start\":57849},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":60646,\"start\":58504},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":60731,\"start\":60647},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":61077,\"start\":60732},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":61146,\"start\":61078},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":61190,\"start\":61147},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":61427,\"start\":61191},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":62916,\"start\":61428},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":63554,\"start\":62917},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":63577,\"start\":63555}]", "paragraph": "[{\"end\":2485,\"start\":1843},{\"end\":3856,\"start\":2487},{\"end\":4209,\"start\":3858},{\"end\":4618,\"start\":4211},{\"end\":5805,\"start\":4620},{\"end\":6659,\"start\":5807},{\"end\":6727,\"start\":6661},{\"end\":6828,\"start\":6729},{\"end\":7515,\"start\":6830},{\"end\":7995,\"start\":7532},{\"end\":8710,\"start\":7997},{\"end\":9762,\"start\":8712},{\"end\":10129,\"start\":9764},{\"end\":10621,\"start\":10131},{\"end\":11090,\"start\":10680},{\"end\":11507,\"start\":11198},{\"end\":13223,\"start\":11562},{\"end\":13732,\"start\":13289},{\"end\":14692,\"start\":13734},{\"end\":15075,\"start\":14694},{\"end\":15248,\"start\":15175},{\"end\":15962,\"start\":15250},{\"end\":16673,\"start\":16055},{\"end\":16786,\"start\":16728},{\"end\":17134,\"start\":16813},{\"end\":17311,\"start\":17136},{\"end\":17503,\"start\":17313},{\"end\":17615,\"start\":17527},{\"end\":17723,\"start\":17693},{\"end\":17901,\"start\":17803},{\"end\":18320,\"start\":18034},{\"end\":19033,\"start\":18351},{\"end\":19575,\"start\":19035},{\"end\":19693,\"start\":19577},{\"end\":19946,\"start\":19862},{\"end\":20330,\"start\":20001},{\"end\":20596,\"start\":20332},{\"end\":20690,\"start\":20640},{\"end\":20767,\"start\":20722},{\"end\":20856,\"start\":20808},{\"end\":20961,\"start\":20901},{\"end\":21406,\"start\":21054},{\"end\":21680,\"start\":21628},{\"end\":22123,\"start\":21735},{\"end\":23247,\"start\":22150},{\"end\":23453,\"start\":23278},{\"end\":23796,\"start\":23710},{\"end\":23836,\"start\":23807},{\"end\":24292,\"start\":24039},{\"end\":24873,\"start\":24294},{\"end\":25451,\"start\":24875},{\"end\":26317,\"start\":25453},{\"end\":26615,\"start\":26319},{\"end\":26838,\"start\":26661},{\"end\":27098,\"start\":26840},{\"end\":27395,\"start\":27100},{\"end\":28768,\"start\":27397},{\"end\":29022,\"start\":28818},{\"end\":29382,\"start\":29024},{\"end\":29480,\"start\":29384},{\"end\":29733,\"start\":29482},{\"end\":29938,\"start\":29735},{\"end\":30619,\"start\":29953},{\"end\":31322,\"start\":30661},{\"end\":31723,\"start\":31324},{\"end\":32183,\"start\":31725},{\"end\":32895,\"start\":32237},{\"end\":33144,\"start\":32958},{\"end\":33332,\"start\":33146},{\"end\":33660,\"start\":33396},{\"end\":33912,\"start\":33840},{\"end\":34203,\"start\":33914},{\"end\":34707,\"start\":34232},{\"end\":35191,\"start\":34709},{\"end\":35399,\"start\":35241},{\"end\":35681,\"start\":35413},{\"end\":35690,\"start\":35683},{\"end\":35991,\"start\":35731},{\"end\":36001,\"start\":35993},{\"end\":36687,\"start\":36003},{\"end\":37211,\"start\":36689},{\"end\":37314,\"start\":37268},{\"end\":37677,\"start\":37443},{\"end\":38116,\"start\":37730},{\"end\":38376,\"start\":38118},{\"end\":38486,\"start\":38378},{\"end\":39161,\"start\":38554},{\"end\":39292,\"start\":39242},{\"end\":39651,\"start\":39294},{\"end\":40107,\"start\":39822},{\"end\":40388,\"start\":40109},{\"end\":40719,\"start\":40423},{\"end\":40938,\"start\":40751},{\"end\":41103,\"start\":40966},{\"end\":41239,\"start\":41105},{\"end\":41765,\"start\":41241},{\"end\":42525,\"start\":41767},{\"end\":42770,\"start\":42527},{\"end\":42956,\"start\":42772},{\"end\":43121,\"start\":42958},{\"end\":43864,\"start\":43183},{\"end\":44065,\"start\":43866},{\"end\":44293,\"start\":44082},{\"end\":44400,\"start\":44295},{\"end\":44671,\"start\":44419},{\"end\":45204,\"start\":44734},{\"end\":45360,\"start\":45206},{\"end\":45436,\"start\":45362},{\"end\":45619,\"start\":45438},{\"end\":45959,\"start\":45621},{\"end\":46113,\"start\":45961},{\"end\":46293,\"start\":46115},{\"end\":47574,\"start\":46295},{\"end\":47970,\"start\":47576},{\"end\":48133,\"start\":47972},{\"end\":48310,\"start\":48208},{\"end\":48993,\"start\":48312},{\"end\":49269,\"start\":49044},{\"end\":49539,\"start\":49271},{\"end\":49942,\"start\":49541},{\"end\":50051,\"start\":49959}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11197,\"start\":11091},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11548,\"start\":11508},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13288,\"start\":13263},{\"attributes\":{\"id\":\"formula_3\"},\"end\":15102,\"start\":15076},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15174,\"start\":15102},{\"attributes\":{\"id\":\"formula_5\"},\"end\":16002,\"start\":15963},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16727,\"start\":16674},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16812,\"start\":16787},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17526,\"start\":17504},{\"attributes\":{\"id\":\"formula_10\"},\"end\":17692,\"start\":17616},{\"attributes\":{\"id\":\"formula_11\"},\"end\":17802,\"start\":17724},{\"attributes\":{\"id\":\"formula_12\"},\"end\":18033,\"start\":17902},{\"attributes\":{\"id\":\"formula_13\"},\"end\":19861,\"start\":19694},{\"attributes\":{\"id\":\"formula_14\"},\"end\":20000,\"start\":19947},{\"attributes\":{\"id\":\"formula_15\"},\"end\":20639,\"start\":20597},{\"attributes\":{\"id\":\"formula_16\"},\"end\":20721,\"start\":20691},{\"attributes\":{\"id\":\"formula_17\"},\"end\":20807,\"start\":20768},{\"attributes\":{\"id\":\"formula_18\"},\"end\":20900,\"start\":20857},{\"attributes\":{\"id\":\"formula_19\"},\"end\":21053,\"start\":20962},{\"attributes\":{\"id\":\"formula_20\"},\"end\":21627,\"start\":21407},{\"attributes\":{\"id\":\"formula_21\"},\"end\":21734,\"start\":21681},{\"attributes\":{\"id\":\"formula_22\"},\"end\":23709,\"start\":23454},{\"attributes\":{\"id\":\"formula_23\"},\"end\":23806,\"start\":23797},{\"attributes\":{\"id\":\"formula_24\"},\"end\":24015,\"start\":23837},{\"attributes\":{\"id\":\"formula_25\"},\"end\":32957,\"start\":32896},{\"attributes\":{\"id\":\"formula_26\"},\"end\":33395,\"start\":33333},{\"attributes\":{\"id\":\"formula_27\"},\"end\":33839,\"start\":33661},{\"attributes\":{\"id\":\"formula_28\"},\"end\":34231,\"start\":34204},{\"attributes\":{\"id\":\"formula_29\"},\"end\":35240,\"start\":35192},{\"attributes\":{\"id\":\"formula_30\"},\"end\":35730,\"start\":35691},{\"attributes\":{\"id\":\"formula_32\"},\"end\":37243,\"start\":37212},{\"attributes\":{\"id\":\"formula_33\"},\"end\":37267,\"start\":37243},{\"attributes\":{\"id\":\"formula_34\"},\"end\":37442,\"start\":37315},{\"attributes\":{\"id\":\"formula_35\"},\"end\":37729,\"start\":37678},{\"attributes\":{\"id\":\"formula_36\"},\"end\":38553,\"start\":38487},{\"attributes\":{\"id\":\"formula_37\"},\"end\":39241,\"start\":39162},{\"attributes\":{\"id\":\"formula_38\"},\"end\":39734,\"start\":39652},{\"attributes\":{\"id\":\"formula_39\"},\"end\":39821,\"start\":39734},{\"attributes\":{\"id\":\"formula_40\"},\"end\":40422,\"start\":40389},{\"attributes\":{\"id\":\"formula_41\"},\"end\":40750,\"start\":40720}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":26721,\"start\":26707},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":27802,\"start\":27795},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":41296,\"start\":41289},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":42578,\"start\":42571},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":42872,\"start\":42858},{\"end\":44103,\"start\":44096},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":44463,\"start\":44449},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":44866,\"start\":44858},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":44942,\"start\":44928},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":49178,\"start\":49162},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":49417,\"start\":49409},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":49450,\"start\":49442}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1841,\"start\":1829},{\"attributes\":{\"n\":\"2\"},\"end\":7530,\"start\":7518},{\"attributes\":{\"n\":\"3\"},\"end\":10645,\"start\":10624},{\"attributes\":{\"n\":\"3.1\"},\"end\":10678,\"start\":10648},{\"attributes\":{\"n\":\"3.2\"},\"end\":11560,\"start\":11550},{\"attributes\":{\"n\":\"3.3\"},\"end\":13262,\"start\":13226},{\"attributes\":{\"n\":\"3.4\"},\"end\":16053,\"start\":16004},{\"attributes\":{\"n\":\"3.5\"},\"end\":18349,\"start\":18323},{\"attributes\":{\"n\":\"3.6\"},\"end\":22148,\"start\":22126},{\"end\":23276,\"start\":23250},{\"attributes\":{\"n\":\"4.1\"},\"end\":24037,\"start\":24017},{\"attributes\":{\"n\":\"4.2\"},\"end\":26659,\"start\":26618},{\"attributes\":{\"n\":\"4.3\"},\"end\":28816,\"start\":28771},{\"attributes\":{\"n\":\"5\"},\"end\":29951,\"start\":29941},{\"end\":30659,\"start\":30622},{\"end\":32235,\"start\":32186},{\"end\":35411,\"start\":35402},{\"end\":40964,\"start\":40941},{\"end\":43146,\"start\":43124},{\"end\":43181,\"start\":43149},{\"end\":44080,\"start\":44068},{\"end\":44417,\"start\":44403},{\"end\":44732,\"start\":44674},{\"end\":48206,\"start\":48136},{\"end\":49042,\"start\":48996},{\"end\":49957,\"start\":49945},{\"end\":50063,\"start\":50053},{\"end\":50703,\"start\":50693},{\"end\":51425,\"start\":51415},{\"end\":51529,\"start\":51519},{\"end\":51584,\"start\":51574},{\"end\":51811,\"start\":51801},{\"end\":52505,\"start\":52494},{\"end\":52651,\"start\":52640},{\"end\":52834,\"start\":52823},{\"end\":53015,\"start\":53004},{\"end\":53133,\"start\":53124},{\"end\":55641,\"start\":55632},{\"end\":57859,\"start\":57850},{\"end\":58511,\"start\":58505},{\"end\":60657,\"start\":60648},{\"end\":60742,\"start\":60733},{\"end\":61088,\"start\":61079},{\"end\":61157,\"start\":61148},{\"end\":61201,\"start\":61192},{\"end\":61439,\"start\":61429},{\"end\":63566,\"start\":63556}]", "table": "[{\"end\":55630,\"start\":53764},{\"end\":57848,\"start\":55730},{\"end\":58503,\"start\":57922},{\"end\":60646,\"start\":59594},{\"end\":60731,\"start\":60687},{\"end\":61077,\"start\":60770},{\"end\":61146,\"start\":61122},{\"end\":61427,\"start\":61388},{\"end\":62916,\"start\":61595},{\"end\":63554,\"start\":63080}]", "figure_caption": "[{\"end\":50669,\"start\":50065},{\"end\":50691,\"start\":50672},{\"end\":50888,\"start\":50705},{\"end\":51413,\"start\":50891},{\"end\":51517,\"start\":51427},{\"end\":51572,\"start\":51531},{\"end\":51748,\"start\":51586},{\"end\":51799,\"start\":51751},{\"end\":52029,\"start\":51813},{\"end\":52418,\"start\":52032},{\"end\":52492,\"start\":52421},{\"end\":52638,\"start\":52508},{\"end\":52821,\"start\":52654},{\"end\":53002,\"start\":52837},{\"end\":53122,\"start\":53018},{\"end\":53764,\"start\":53135},{\"end\":55730,\"start\":55643},{\"end\":57922,\"start\":57861},{\"end\":59594,\"start\":58514},{\"end\":60687,\"start\":60659},{\"end\":60770,\"start\":60744},{\"end\":61122,\"start\":61090},{\"end\":61190,\"start\":61159},{\"end\":61388,\"start\":61203},{\"end\":61595,\"start\":61442},{\"end\":63080,\"start\":62919},{\"end\":63577,\"start\":63569}]", "figure_ref": "[{\"end\":3387,\"start\":3379},{\"end\":5736,\"start\":5729},{\"end\":5969,\"start\":5963},{\"end\":11847,\"start\":11840},{\"end\":12749,\"start\":12743},{\"end\":12869,\"start\":12861},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13511,\"start\":13505},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16116,\"start\":16110},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17256,\"start\":17248},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18496,\"start\":18489},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19342,\"start\":19335},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19574,\"start\":19567},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19677,\"start\":19670},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21264,\"start\":21257},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27923,\"start\":27917},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":28556,\"start\":28541},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29021,\"start\":29015},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29320,\"start\":29313},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29405,\"start\":29398},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29505,\"start\":29498},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29671,\"start\":29664},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29774,\"start\":29767},{\"end\":33075,\"start\":33069},{\"end\":33158,\"start\":33150},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":36587,\"start\":36581},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":37804,\"start\":37798},{\"end\":38114,\"start\":38107},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":38315,\"start\":38308},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":38327,\"start\":38320},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":38405,\"start\":38396},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":38946,\"start\":38939},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":39325,\"start\":39316},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":40809,\"start\":40800},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":46644,\"start\":46637},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":46690,\"start\":46668},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":47072,\"start\":47051},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":47297,\"start\":47276},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":47379,\"start\":47358},{\"attributes\":{\"ref_id\":\"fig_16\"},\"end\":47742,\"start\":47733},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":48042,\"start\":48033},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":48603,\"start\":48596}]", "bib_author_first_name": "[{\"end\":64232,\"start\":64227},{\"end\":64249,\"start\":64241},{\"end\":64264,\"start\":64257},{\"end\":64275,\"start\":64272},{\"end\":64594,\"start\":64590},{\"end\":64606,\"start\":64600},{\"end\":64617,\"start\":64613},{\"end\":64630,\"start\":64625},{\"end\":64644,\"start\":64637},{\"end\":64656,\"start\":64650},{\"end\":65008,\"start\":65002},{\"end\":65020,\"start\":65018},{\"end\":65029,\"start\":65025},{\"end\":65388,\"start\":65381},{\"end\":65403,\"start\":65398},{\"end\":65420,\"start\":65412},{\"end\":65785,\"start\":65784},{\"end\":65796,\"start\":65795},{\"end\":65805,\"start\":65804},{\"end\":65807,\"start\":65806},{\"end\":65813,\"start\":65812},{\"end\":66141,\"start\":66133},{\"end\":66156,\"start\":66151},{\"end\":66158,\"start\":66157},{\"end\":66439,\"start\":66433},{\"end\":66452,\"start\":66446},{\"end\":66463,\"start\":66462},{\"end\":66476,\"start\":66466},{\"end\":66486,\"start\":66485},{\"end\":66797,\"start\":66790},{\"end\":66812,\"start\":66804},{\"end\":67210,\"start\":67204},{\"end\":67221,\"start\":67217},{\"end\":67233,\"start\":67229},{\"end\":67249,\"start\":67242},{\"end\":67261,\"start\":67254},{\"end\":67670,\"start\":67664},{\"end\":67683,\"start\":67678},{\"end\":67694,\"start\":67688},{\"end\":67705,\"start\":67701},{\"end\":67720,\"start\":67713},{\"end\":67732,\"start\":67725},{\"end\":68092,\"start\":68086},{\"end\":68109,\"start\":68100},{\"end\":68123,\"start\":68117},{\"end\":68135,\"start\":68130},{\"end\":68148,\"start\":68141},{\"end\":68493,\"start\":68488},{\"end\":68508,\"start\":68501},{\"end\":68873,\"start\":68867},{\"end\":68897,\"start\":68888},{\"end\":68909,\"start\":68904},{\"end\":68922,\"start\":68916},{\"end\":69279,\"start\":69276},{\"end\":69289,\"start\":69286},{\"end\":69303,\"start\":69296},{\"end\":69318,\"start\":69312},{\"end\":69326,\"start\":69323},{\"end\":69333,\"start\":69331},{\"end\":69680,\"start\":69674},{\"end\":69689,\"start\":69687},{\"end\":70020,\"start\":70013},{\"end\":70031,\"start\":70027},{\"end\":70043,\"start\":70036},{\"end\":70055,\"start\":70048},{\"end\":70063,\"start\":70060},{\"end\":70073,\"start\":70069},{\"end\":70084,\"start\":70081},{\"end\":70473,\"start\":70464},{\"end\":70487,\"start\":70481},{\"end\":70851,\"start\":70846},{\"end\":70863,\"start\":70857},{\"end\":70879,\"start\":70870},{\"end\":70894,\"start\":70887},{\"end\":71211,\"start\":71203},{\"end\":71223,\"start\":71217},{\"end\":71234,\"start\":71229},{\"end\":71515,\"start\":71508},{\"end\":71527,\"start\":71520},{\"end\":71543,\"start\":71535},{\"end\":71553,\"start\":71549},{\"end\":71841,\"start\":71838},{\"end\":71848,\"start\":71846},{\"end\":71859,\"start\":71855},{\"end\":72164,\"start\":72158},{\"end\":72177,\"start\":72172},{\"end\":72198,\"start\":72188},{\"end\":72549,\"start\":72542},{\"end\":72563,\"start\":72555},{\"end\":72577,\"start\":72569},{\"end\":72589,\"start\":72583},{\"end\":72956,\"start\":72952},{\"end\":73121,\"start\":73114},{\"end\":73133,\"start\":73126},{\"end\":73144,\"start\":73138},{\"end\":73158,\"start\":73152},{\"end\":73167,\"start\":73165},{\"end\":73519,\"start\":73513},{\"end\":73531,\"start\":73525},{\"end\":73543,\"start\":73538},{\"end\":73553,\"start\":73549},{\"end\":73859,\"start\":73854},{\"end\":73877,\"start\":73865},{\"end\":73902,\"start\":73896},{\"end\":74240,\"start\":74235},{\"end\":74248,\"start\":74246},{\"end\":74257,\"start\":74254},{\"end\":74266,\"start\":74263},{\"end\":74274,\"start\":74271},{\"end\":74286,\"start\":74280},{\"end\":74298,\"start\":74293},{\"end\":74689,\"start\":74685},{\"end\":74696,\"start\":74694},{\"end\":74710,\"start\":74703},{\"end\":75055,\"start\":75045},{\"end\":75073,\"start\":75063},{\"end\":75089,\"start\":75083},{\"end\":75107,\"start\":75099},{\"end\":75123,\"start\":75117},{\"end\":75473,\"start\":75465},{\"end\":75485,\"start\":75480},{\"end\":75501,\"start\":75493},{\"end\":75859,\"start\":75850},{\"end\":75870,\"start\":75866},{\"end\":75882,\"start\":75875},{\"end\":76214,\"start\":76205},{\"end\":76252,\"start\":76246},{\"end\":76622,\"start\":76619},{\"end\":76638,\"start\":76632},{\"end\":76676,\"start\":76670},{\"end\":77075,\"start\":77070},{\"end\":77091,\"start\":77084},{\"end\":77109,\"start\":77101},{\"end\":77599,\"start\":77594},{\"end\":77614,\"start\":77608},{\"end\":77635,\"start\":77627},{\"end\":77651,\"start\":77644},{\"end\":78031,\"start\":78024},{\"end\":78043,\"start\":78037},{\"end\":78051,\"start\":78049},{\"end\":78353,\"start\":78349},{\"end\":78559,\"start\":78555},{\"end\":78761,\"start\":78757},{\"end\":78937,\"start\":78933}]", "bib_author_last_name": "[{\"end\":64239,\"start\":64233},{\"end\":64255,\"start\":64250},{\"end\":64270,\"start\":64265},{\"end\":64281,\"start\":64276},{\"end\":64598,\"start\":64595},{\"end\":64611,\"start\":64607},{\"end\":64623,\"start\":64618},{\"end\":64635,\"start\":64631},{\"end\":64648,\"start\":64645},{\"end\":64660,\"start\":64657},{\"end\":65000,\"start\":64989},{\"end\":65016,\"start\":65009},{\"end\":65023,\"start\":65021},{\"end\":65032,\"start\":65030},{\"end\":65038,\"start\":65034},{\"end\":65396,\"start\":65389},{\"end\":65410,\"start\":65404},{\"end\":65427,\"start\":65421},{\"end\":65793,\"start\":65786},{\"end\":65802,\"start\":65797},{\"end\":65810,\"start\":65808},{\"end\":65819,\"start\":65814},{\"end\":66149,\"start\":66142},{\"end\":66165,\"start\":66159},{\"end\":66444,\"start\":66440},{\"end\":66460,\"start\":66453},{\"end\":66483,\"start\":66477},{\"end\":66802,\"start\":66798},{\"end\":66815,\"start\":66813},{\"end\":67215,\"start\":67211},{\"end\":67227,\"start\":67222},{\"end\":67240,\"start\":67234},{\"end\":67252,\"start\":67250},{\"end\":67267,\"start\":67262},{\"end\":67676,\"start\":67671},{\"end\":67686,\"start\":67684},{\"end\":67699,\"start\":67695},{\"end\":67711,\"start\":67706},{\"end\":67723,\"start\":67721},{\"end\":67738,\"start\":67733},{\"end\":68098,\"start\":68093},{\"end\":68115,\"start\":68110},{\"end\":68128,\"start\":68124},{\"end\":68139,\"start\":68136},{\"end\":68154,\"start\":68149},{\"end\":68499,\"start\":68494},{\"end\":68513,\"start\":68509},{\"end\":68886,\"start\":68874},{\"end\":68902,\"start\":68898},{\"end\":68914,\"start\":68910},{\"end\":68932,\"start\":68923},{\"end\":68936,\"start\":68934},{\"end\":69284,\"start\":69280},{\"end\":69294,\"start\":69290},{\"end\":69310,\"start\":69304},{\"end\":69321,\"start\":69319},{\"end\":69329,\"start\":69327},{\"end\":69341,\"start\":69334},{\"end\":69685,\"start\":69681},{\"end\":69694,\"start\":69690},{\"end\":70025,\"start\":70021},{\"end\":70034,\"start\":70032},{\"end\":70046,\"start\":70044},{\"end\":70058,\"start\":70056},{\"end\":70067,\"start\":70064},{\"end\":70079,\"start\":70074},{\"end\":70088,\"start\":70085},{\"end\":70479,\"start\":70474},{\"end\":70517,\"start\":70488},{\"end\":70527,\"start\":70519},{\"end\":70855,\"start\":70852},{\"end\":70868,\"start\":70864},{\"end\":70885,\"start\":70880},{\"end\":70909,\"start\":70895},{\"end\":71215,\"start\":71212},{\"end\":71227,\"start\":71224},{\"end\":71238,\"start\":71235},{\"end\":71518,\"start\":71516},{\"end\":71533,\"start\":71528},{\"end\":71547,\"start\":71544},{\"end\":71557,\"start\":71554},{\"end\":71844,\"start\":71842},{\"end\":71853,\"start\":71849},{\"end\":71863,\"start\":71860},{\"end\":72170,\"start\":72165},{\"end\":72186,\"start\":72178},{\"end\":72204,\"start\":72199},{\"end\":72553,\"start\":72550},{\"end\":72567,\"start\":72564},{\"end\":72581,\"start\":72578},{\"end\":72597,\"start\":72590},{\"end\":72967,\"start\":72957},{\"end\":73124,\"start\":73122},{\"end\":73136,\"start\":73134},{\"end\":73150,\"start\":73145},{\"end\":73163,\"start\":73159},{\"end\":73170,\"start\":73168},{\"end\":73523,\"start\":73520},{\"end\":73536,\"start\":73532},{\"end\":73547,\"start\":73544},{\"end\":73558,\"start\":73554},{\"end\":73863,\"start\":73860},{\"end\":73894,\"start\":73878},{\"end\":73911,\"start\":73903},{\"end\":74244,\"start\":74241},{\"end\":74252,\"start\":74249},{\"end\":74261,\"start\":74258},{\"end\":74269,\"start\":74267},{\"end\":74278,\"start\":74275},{\"end\":74291,\"start\":74287},{\"end\":74302,\"start\":74299},{\"end\":74692,\"start\":74690},{\"end\":74701,\"start\":74697},{\"end\":74715,\"start\":74711},{\"end\":75061,\"start\":75056},{\"end\":75081,\"start\":75074},{\"end\":75097,\"start\":75090},{\"end\":75115,\"start\":75108},{\"end\":75129,\"start\":75124},{\"end\":75478,\"start\":75474},{\"end\":75491,\"start\":75486},{\"end\":75508,\"start\":75502},{\"end\":75864,\"start\":75860},{\"end\":75873,\"start\":75871},{\"end\":75887,\"start\":75883},{\"end\":76244,\"start\":76215},{\"end\":76258,\"start\":76253},{\"end\":76268,\"start\":76260},{\"end\":76630,\"start\":76623},{\"end\":76668,\"start\":76639},{\"end\":76685,\"start\":76677},{\"end\":76690,\"start\":76687},{\"end\":77082,\"start\":77076},{\"end\":77099,\"start\":77092},{\"end\":77116,\"start\":77110},{\"end\":77606,\"start\":77600},{\"end\":77625,\"start\":77615},{\"end\":77642,\"start\":77636},{\"end\":77659,\"start\":77652},{\"end\":78035,\"start\":78032},{\"end\":78047,\"start\":78044},{\"end\":78056,\"start\":78052}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":5046541},\"end\":64528,\"start\":64159},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":221878860},\"end\":64901,\"start\":64530},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":52951839},\"end\":65283,\"start\":64903},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2410333},\"end\":65705,\"start\":65285},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":56895282},\"end\":66077,\"start\":65707},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2893830},\"end\":66360,\"start\":66079},{\"attributes\":{\"id\":\"b6\"},\"end\":66724,\"start\":66362},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":219981888},\"end\":67087,\"start\":66726},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":2179389},\"end\":67585,\"start\":67089},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":49672236},\"end\":68025,\"start\":67587},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":202734646},\"end\":68417,\"start\":68027},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":189928401},\"end\":68808,\"start\":68419},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":196208260},\"end\":69221,\"start\":68810},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":57246310},\"end\":69610,\"start\":69223},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":198903996},\"end\":69936,\"start\":69612},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":104291897},\"end\":70401,\"start\":69938},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":13451211},\"end\":70785,\"start\":70403},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":12308095},\"end\":71167,\"start\":70787},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":5398883},\"end\":71460,\"start\":71169},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":206594692},\"end\":71803,\"start\":71462},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":140309863},\"end\":72082,\"start\":71805},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":49907212},\"end\":72460,\"start\":72084},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":54434655},\"end\":72895,\"start\":72462},{\"attributes\":{\"id\":\"b23\"},\"end\":73058,\"start\":72897},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":218972155},\"end\":73441,\"start\":73060},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":17707860},\"end\":73809,\"start\":73443},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":85518037},\"end\":74152,\"start\":73811},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3863554},\"end\":74611,\"start\":74154},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":221445735},\"end\":74980,\"start\":74613},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":3488815},\"end\":75414,\"start\":74982},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":227162679},\"end\":75763,\"start\":75416},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":155100229},\"end\":76134,\"start\":75765},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":12387176},\"end\":76553,\"start\":76136},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":212725250},\"end\":76986,\"start\":76555},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3995611},\"end\":77463,\"start\":76988},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":224901284},\"end\":77951,\"start\":77465},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":219619122},\"end\":78345,\"start\":77953},{\"attributes\":{\"doi\":\"97.449 75.499 62.484 38.886 26.004 20.091 96.410 50.985 31.176 11.861 7.549 6.087\",\"id\":\"b37\"},\"end\":78523,\"start\":78347},{\"attributes\":{\"id\":\"b38\"},\"end\":78551,\"start\":78525},{\"attributes\":{\"doi\":\"95.563 75.889 62.404 38.457 26.495 21.069 101.186 57.672 36.743 13.999 8.694 6.856\",\"id\":\"b39\"},\"end\":78731,\"start\":78553},{\"attributes\":{\"id\":\"b40\"},\"end\":78753,\"start\":78733},{\"attributes\":{\"doi\":\"66.077 51.852 41.065 21.946 13.461 10.899 65.122 33.841 21.823 7.772 4.231 3.489\",\"id\":\"b41\"},\"end\":78929,\"start\":78755},{\"attributes\":{\"doi\":\"69.117 56.275 44.315 24.316 15.133 11.946 51.883 24.403 14.643 5.842 3.703 3.191\",\"id\":\"b42\"},\"end\":79105,\"start\":78931},{\"attributes\":{\"id\":\"b43\"},\"end\":79483,\"start\":79107}]", "bib_title": "[{\"end\":64225,\"start\":64159},{\"end\":64588,\"start\":64530},{\"end\":64987,\"start\":64903},{\"end\":65379,\"start\":65285},{\"end\":65782,\"start\":65707},{\"end\":66131,\"start\":66079},{\"end\":66431,\"start\":66362},{\"end\":66788,\"start\":66726},{\"end\":67202,\"start\":67089},{\"end\":67662,\"start\":67587},{\"end\":68084,\"start\":68027},{\"end\":68486,\"start\":68419},{\"end\":68865,\"start\":68810},{\"end\":69274,\"start\":69223},{\"end\":69672,\"start\":69612},{\"end\":70011,\"start\":69938},{\"end\":70462,\"start\":70403},{\"end\":70844,\"start\":70787},{\"end\":71201,\"start\":71169},{\"end\":71506,\"start\":71462},{\"end\":71836,\"start\":71805},{\"end\":72156,\"start\":72084},{\"end\":72540,\"start\":72462},{\"end\":73112,\"start\":73060},{\"end\":73511,\"start\":73443},{\"end\":73852,\"start\":73811},{\"end\":74233,\"start\":74154},{\"end\":74683,\"start\":74613},{\"end\":75043,\"start\":74982},{\"end\":75463,\"start\":75416},{\"end\":75848,\"start\":75765},{\"end\":76203,\"start\":76136},{\"end\":76617,\"start\":76555},{\"end\":77068,\"start\":76988},{\"end\":77592,\"start\":77465},{\"end\":78022,\"start\":77953},{\"end\":79284,\"start\":79107}]", "bib_author": "[{\"end\":64241,\"start\":64227},{\"end\":64257,\"start\":64241},{\"end\":64272,\"start\":64257},{\"end\":64283,\"start\":64272},{\"end\":64600,\"start\":64590},{\"end\":64613,\"start\":64600},{\"end\":64625,\"start\":64613},{\"end\":64637,\"start\":64625},{\"end\":64650,\"start\":64637},{\"end\":64662,\"start\":64650},{\"end\":65002,\"start\":64989},{\"end\":65018,\"start\":65002},{\"end\":65025,\"start\":65018},{\"end\":65034,\"start\":65025},{\"end\":65040,\"start\":65034},{\"end\":65398,\"start\":65381},{\"end\":65412,\"start\":65398},{\"end\":65429,\"start\":65412},{\"end\":65795,\"start\":65784},{\"end\":65804,\"start\":65795},{\"end\":65812,\"start\":65804},{\"end\":65821,\"start\":65812},{\"end\":66151,\"start\":66133},{\"end\":66167,\"start\":66151},{\"end\":66446,\"start\":66433},{\"end\":66462,\"start\":66446},{\"end\":66466,\"start\":66462},{\"end\":66485,\"start\":66466},{\"end\":66489,\"start\":66485},{\"end\":66804,\"start\":66790},{\"end\":66817,\"start\":66804},{\"end\":67217,\"start\":67204},{\"end\":67229,\"start\":67217},{\"end\":67242,\"start\":67229},{\"end\":67254,\"start\":67242},{\"end\":67269,\"start\":67254},{\"end\":67678,\"start\":67664},{\"end\":67688,\"start\":67678},{\"end\":67701,\"start\":67688},{\"end\":67713,\"start\":67701},{\"end\":67725,\"start\":67713},{\"end\":67740,\"start\":67725},{\"end\":68100,\"start\":68086},{\"end\":68117,\"start\":68100},{\"end\":68130,\"start\":68117},{\"end\":68141,\"start\":68130},{\"end\":68156,\"start\":68141},{\"end\":68501,\"start\":68488},{\"end\":68515,\"start\":68501},{\"end\":68888,\"start\":68867},{\"end\":68904,\"start\":68888},{\"end\":68916,\"start\":68904},{\"end\":68934,\"start\":68916},{\"end\":68938,\"start\":68934},{\"end\":69286,\"start\":69276},{\"end\":69296,\"start\":69286},{\"end\":69312,\"start\":69296},{\"end\":69323,\"start\":69312},{\"end\":69331,\"start\":69323},{\"end\":69343,\"start\":69331},{\"end\":69687,\"start\":69674},{\"end\":69696,\"start\":69687},{\"end\":70027,\"start\":70013},{\"end\":70036,\"start\":70027},{\"end\":70048,\"start\":70036},{\"end\":70060,\"start\":70048},{\"end\":70069,\"start\":70060},{\"end\":70081,\"start\":70069},{\"end\":70090,\"start\":70081},{\"end\":70481,\"start\":70464},{\"end\":70519,\"start\":70481},{\"end\":70529,\"start\":70519},{\"end\":70857,\"start\":70846},{\"end\":70870,\"start\":70857},{\"end\":70887,\"start\":70870},{\"end\":70911,\"start\":70887},{\"end\":71217,\"start\":71203},{\"end\":71229,\"start\":71217},{\"end\":71240,\"start\":71229},{\"end\":71520,\"start\":71508},{\"end\":71535,\"start\":71520},{\"end\":71549,\"start\":71535},{\"end\":71559,\"start\":71549},{\"end\":71846,\"start\":71838},{\"end\":71855,\"start\":71846},{\"end\":71865,\"start\":71855},{\"end\":72172,\"start\":72158},{\"end\":72188,\"start\":72172},{\"end\":72206,\"start\":72188},{\"end\":72555,\"start\":72542},{\"end\":72569,\"start\":72555},{\"end\":72583,\"start\":72569},{\"end\":72599,\"start\":72583},{\"end\":72969,\"start\":72952},{\"end\":73126,\"start\":73114},{\"end\":73138,\"start\":73126},{\"end\":73152,\"start\":73138},{\"end\":73165,\"start\":73152},{\"end\":73172,\"start\":73165},{\"end\":73525,\"start\":73513},{\"end\":73538,\"start\":73525},{\"end\":73549,\"start\":73538},{\"end\":73560,\"start\":73549},{\"end\":73865,\"start\":73854},{\"end\":73896,\"start\":73865},{\"end\":73913,\"start\":73896},{\"end\":74246,\"start\":74235},{\"end\":74254,\"start\":74246},{\"end\":74263,\"start\":74254},{\"end\":74271,\"start\":74263},{\"end\":74280,\"start\":74271},{\"end\":74293,\"start\":74280},{\"end\":74304,\"start\":74293},{\"end\":74694,\"start\":74685},{\"end\":74703,\"start\":74694},{\"end\":74717,\"start\":74703},{\"end\":75063,\"start\":75045},{\"end\":75083,\"start\":75063},{\"end\":75099,\"start\":75083},{\"end\":75117,\"start\":75099},{\"end\":75131,\"start\":75117},{\"end\":75480,\"start\":75465},{\"end\":75493,\"start\":75480},{\"end\":75510,\"start\":75493},{\"end\":75866,\"start\":75850},{\"end\":75875,\"start\":75866},{\"end\":75889,\"start\":75875},{\"end\":76246,\"start\":76205},{\"end\":76260,\"start\":76246},{\"end\":76270,\"start\":76260},{\"end\":76632,\"start\":76619},{\"end\":76670,\"start\":76632},{\"end\":76687,\"start\":76670},{\"end\":76692,\"start\":76687},{\"end\":77084,\"start\":77070},{\"end\":77101,\"start\":77084},{\"end\":77118,\"start\":77101},{\"end\":77608,\"start\":77594},{\"end\":77627,\"start\":77608},{\"end\":77644,\"start\":77627},{\"end\":77661,\"start\":77644},{\"end\":78037,\"start\":78024},{\"end\":78049,\"start\":78037},{\"end\":78058,\"start\":78049},{\"end\":78356,\"start\":78349},{\"end\":78562,\"start\":78555},{\"end\":78764,\"start\":78757},{\"end\":78940,\"start\":78933}]", "bib_venue": "[{\"end\":64327,\"start\":64283},{\"end\":64700,\"start\":64662},{\"end\":65078,\"start\":65040},{\"end\":65481,\"start\":65429},{\"end\":65873,\"start\":65821},{\"end\":66205,\"start\":66167},{\"end\":66527,\"start\":66489},{\"end\":66891,\"start\":66817},{\"end\":67324,\"start\":67269},{\"end\":67792,\"start\":67740},{\"end\":68208,\"start\":68156},{\"end\":68564,\"start\":68515},{\"end\":69000,\"start\":68938},{\"end\":69401,\"start\":69343},{\"end\":69758,\"start\":69696},{\"end\":70152,\"start\":70090},{\"end\":70578,\"start\":70529},{\"end\":70963,\"start\":70911},{\"end\":71298,\"start\":71240},{\"end\":71617,\"start\":71559},{\"end\":71927,\"start\":71865},{\"end\":72258,\"start\":72206},{\"end\":72661,\"start\":72599},{\"end\":72950,\"start\":72897},{\"end\":73234,\"start\":73172},{\"end\":73612,\"start\":73560},{\"end\":73965,\"start\":73913},{\"end\":74366,\"start\":74304},{\"end\":74779,\"start\":74717},{\"end\":75183,\"start\":75131},{\"end\":75572,\"start\":75510},{\"end\":75933,\"start\":75889},{\"end\":76328,\"start\":76270},{\"end\":76754,\"start\":76692},{\"end\":77212,\"start\":77118},{\"end\":77692,\"start\":77661},{\"end\":78120,\"start\":78058},{\"end\":78537,\"start\":78525},{\"end\":78742,\"start\":78733},{\"end\":79291,\"start\":79286}]"}}}, "year": 2023, "month": 12, "day": 17}