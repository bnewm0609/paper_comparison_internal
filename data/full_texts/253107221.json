{"id": 253107221, "updated": "2023-10-05 09:17:04.588", "metadata": {"title": "Practical Program Repair in the Era of Large Pre-trained Language Models", "authors": "[{\"first\":\"Chunqiu\",\"last\":\"Xia\",\"middle\":[\"Steven\"]},{\"first\":\"Yuxiang\",\"last\":\"Wei\",\"middle\":[]},{\"first\":\"Lingming\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Automated Program Repair (APR) aims to help developers automatically patch software bugs. However, current state-of-the-art traditional and learning-based APR techniques face the problem of limited patch variety, failing to fix complicated bugs. This is mainly due to the reliance on bug-fixing datasets to craft fix templates or directly predict potential patches. Large Pre-Trained Language Models (PLMs), trained using billions of text/code tokens, can potentially help avoid this issue. Very recently, researchers have directly leveraged PLMs for APR without relying on any bug-fixing datasets. Meanwhile, such existing work either failed to include state-of-the-art PLMs or was not evaluated on realistic datasets. In this work, we perform the first extensive study on directly applying PLMs for APR. We select 9 recent state-of-the-art PLMs, including both generative and infilling models, ranging from 125M to 20B in size. We designed 3 different repair settings to evaluate the different ways we can use PLMs to generate patches. We apply the PLMs under these repair settings on 5 datasets across 3 different languages and compare different PLMs in the number of bugs fixed, generation speed and compilation rate. Our study demonstrates that directly applying state-of-the-art PLMs can already substantially outperform all existing APR techniques on all our datasets. Among the studied PLMs, the scaling effect exists for APR where larger models tend to achieve better performance. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the PLMs consider correct patches to be more natural than other ones, and can even be leveraged for effective patch ranking or patch correctness checking.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2210.14179", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2210-14179", "doi": "10.48550/arxiv.2210.14179"}}, "content": {"source": {"pdf_hash": "f031ba42cf82f106200bb03fbb91dd5671a59b9c", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2210.14179v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c25689e06210fa4b4ede595bc6908b951dd9db20", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f031ba42cf82f106200bb03fbb91dd5671a59b9c.txt", "contents": "\nPractical Program Repair in the Era of Large Pre-trained Language Models\n\n\nChunqiu Steven Xia chunqiu2@illinois.edu \nUniversity of Illinois at Urbana-Champaign\nUniversity of Illinois at Urbana-Champaign\nUniversity of Illinois at Urbana-Champaign\n\n\nYuxiang Wei \nUniversity of Illinois at Urbana-Champaign\nUniversity of Illinois at Urbana-Champaign\nUniversity of Illinois at Urbana-Champaign\n\n\nLingming Zhang lingming@illinois.edu \nUniversity of Illinois at Urbana-Champaign\nUniversity of Illinois at Urbana-Champaign\nUniversity of Illinois at Urbana-Champaign\n\n\nPractical Program Repair in the Era of Large Pre-trained Language Models\n\nAutomated Program Repair (APR) aims to help developers automatically patch software bugs. However, current state-of-the-art traditional and learning-based APR techniques face the problem of limited patch variety, failing to fix complicated bugs. This is mainly due to the reliance on bug-fixing datasets to craft fix templates (traditional) or directly predict potential patches (learning-based). Large Pre-Trained Language Models (PLMs), trained using billions of text/code tokens, can potentially help avoid this issue. Very recently, researchers have directly leveraged PLMs for APR without relying on any bugfixing datasets. Meanwhile, such existing work either failed to include state-of-the-art PLMs or was not evaluated on realistic datasets. Thus, the true power of modern PLMs on the important APR problem is yet to be revealed.In this work, we perform the first extensive study on directly applying PLMs for APR. We select 9 recent state-of-the-art PLMs, including both generative and infilling models, ranging from 125M to 20B in size. We designed 3 different repair settings to evaluate the different ways we can use PLMs to generate patches: 1) generate the entire patch function, 2) fill in a chunk of code given the prefix and suffix 3) output a single line fix. We apply the PLMs under these repair settings on 5 datasets across 3 different languages and compare different PLMs in the number of bugs fixed, generation speed and compilation rate. We also compare the PLMs against recent state-of-the-art APR tools. Our study demonstrates that directly applying state-ofthe-art PLMs can already substantially outperform all existing APR techniques on all our datasets. Among the studied PLMs, the scaling effect exists for APR where larger models tend to achieve better performance. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the PLMs consider correct patches to be more natural than other ones, and can even be leveraged for effective patch ranking or patch correctness checking. Lastly, we show that PLM-based APR can be further substantially boosted via: 1) increasing the sample size, and 2) incorporating fix template information.\n\nI. INTRODUCTION\n\nAs software programs and systems become more and more ubiquitous in everyday life, so do software bugs. Due to the wide-ranging adoption of software systems in fields from healthcare [1] to transportation [2], these bugs can potentially cause dangerous safety issues [3] and financial losses [4]. As such, developers often need to spend a significant amount of time and effort to fix software bugs [5]. In order to help developers reduce this manual effort, Automated Program Repair (APR) tools have been built to automatically generate potential patches given the original buggy program [6].\n\nAmong traditional APR techniques [7]- [16], template-based APR has been widely recognized as the state of the art [17], [18]. These techniques leverage fix templates, often designed by human experts, to fix specific types of bugs in the source code. As a result, these APR tools are constrained by the underlying fix templates in the types of bugs that can be fixed. To combat this, researchers have proposed learningbased APR tools [19]- [22], which typically model program repair as a Neural Machine Translation (NMT) problem [23], where the goal is to translate a buggy program into a fixed program. The core component of these learning-based APR tools is an encoder and decoder pair, where the model aims to capture the buggy context via the encoder and then autoregressively generate the patch using the decoder. As such, these learning-based APR tools require supervised training datasets containing pairs of buggy and patched code, usually obtained by mining historical bug fixes from open-source repositories. While learning-based APR tools have shown improvements in both the number and variety of bugs that can be fixed [19], [20], they are still restricted by their training data which only contain a limited amount of bug fix types and may not generalize to unseen bug types [24].\n\nRecent developments in building Large Pre-Trained Language Models (PLMs) offer an alternative solution that can be applied for program repair without relying on historical bug fixes. While PLMs are usually general-purpose tools for NLP tasks (e.g., GPT3 [25]), they have also been used for programming languages by finetuning on code (e.g., Codex [26]). Unlike the specifically designed learning-based APR models, PLMs are trained in an unsupervised fashion using up to billions of text/code tokens and can be used in a variety of code tasks. Recently, AlphaRepair [24] proposes to leverage CodeBERT [27], a large code model pre-trained on millions of code snippets, directly for APR. The key insight from AlphaRepair is instead of learning transformations to go from buggy code to fixed code, we can directly use the model to predict what the correct code should look like given its surrounding context (including both prefix and suffix), i.e., infilling-style APR. Using this idea, AlphaRepair demonstrated state-of-the-art repair results without finetuning on bug fixing dataset. While AlphaRepair has shown improvements over previous learning-based APR, the model (125M parameters) it uses is far smaller than the current state-of-the-art PLMs (Codex: 12B parameters and GPT-3: 175B parameters). Beside AlphaRepair, researchers have also directly leveraged Codex for generative APR [28], [29], i.e., generating the fixes based on the context before bugs (i.e., prefix only). However, these studies mostly focus on Codex and are only evaluated on a small dataset with 40 bugs on simple programming tasks.\n\nCurrent state-of-the-art PLMs such as Codex [26] and INCODER [30] have also included evaluation for code related tasks such as code completion, docstring generation and variable/type prediction. However, these evaluations still mainly focus on NLP metrics such as BLEU score [31] which do not accurately measure the functional or semantic correctness of the generated code. Furthermore, the datasets consist of handcurated code problems which do not accurately reflect the type of projects developers work on in the real world.\n\nOur Work. We present the first extensive evaluation of recent PLMs for fixing real-world projects. We designed 3 different APR experimental settings: 1) complete function generation 2) correct code infilling and 3) single line generation to showcase the different ways PLMs can be applied for APR. In our study, we include both popular types of PLM architectures (generative and infilling models) to show the advantages and flaws of using each type for APR. We include models with a wide range of different parameter sizes, spanning from 125 million to 20 billion. We evaluate not only the improvement in repair effectiveness but also the trade-off with respect to speed when increasing the model size. In total, we use 5 different repair datasets containing real open-source bugs and developer written tests across 3 programming languages to evaluate APR under realistic settings. Compared with existing applications of PLMs for APR [24], [28], [29], our study is the first to include state-of-the-art PLMs for both infilling-style and generative APR on various datasets and programming languages. To summarize, this paper makes the following contributions.\n\nDimension. This paper bridges the gap between the recent advances in PLMs and a crucial software engineering problem -APR. This paper not only demonstrates the potential and future for directly leveraging PLMs for solving the important APR problem, but also provides a realistic evaluation scenario for the recent PLMs, which were mainly evaluated on simple/synthetic coding problems rather than real-world systems as studied in the APR area. Study. We conduct extensive evaluations using 9 different recent PLMs on 5 different repair datasets across 3 different programming languages (Java, Python, and C). We compare the PLMs against each other using the 3 repair settings we designed. Using the popular repair datasets, we further compare the PLMs with state-of-the-art APR tools.\n\nPractical Guidelines. Our study shows for the first time that directly applying state-of-the-art PLMs can already substantially outperform all existing APR tools on the widely studied Defects4J 1.2 dataset (and other ones), e.g., Codex can fix 32 more bugs than the existing best APR technique.\n\nAmong the studied PLMs, the scaling effect exists for APR where larger models tend to deliver stronger APR results. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the PLMs consider correct patches to be more natural than other ones, and can even be used for effective patch ranking or correctness checking. Lastly, we show that PLM-based APR can be further substantially improved via: 1) increasing the sample size, and 2) incorporating fix template information.\n\n\nII. BACKGROUND AND RELATED WORK A. Large Pre-Trained Language Model\n\nLarge Pre-Trained Language Models (PLMs) have become ubiquitous in the domain of NLP, achieving impressive performance in many tasks such as machine translation [23], text summarization [32] and classification [33]. PLMs follow the Transformer architecture [34] -an encoder to capture input representation and a decoder to generate output tokens. These PLMs are first pre-trained in an unsupervised manner, on large amounts of text data and then finetuned for downstream tasks. However, certain tasks may not have an abundance of finetuned data available. As such, researchers have evaluated the ability for PLMs to perform on downstream tasks without finetuning. This is achieved via prompt engineering [35] providing the model with natural language descriptions and demonstrations of the task it is trying to solve before giving the model the target input. This works by leveraging the generalpurpose setup of PLMs where the unsupervised pretraining dataset already encompasses many domains of problems/tasks. Using this idea and the exponential growth in PLM size [36], impressive performance in many tasks can be achieved even without any finetuning [25].\n\nPLMs can be classified into encoder-only, decoder-only and encoder-decoder models based on their architectures. Encoderonly models (such as BERT [37]) contain only the encoder component of a Transformer. They are typically designed to learn data representations and are trained using the Masked Language Modeling (MLM) objective -a small percentage (e.g., 15%) of tokens in the training data will be replaced by masked tokens, and then the models are trained to predict the original values of the masked tokens based on the bidirectional contexts. Decoder-only models (such as GPT-3 [25] and GPT-Neo [38]) are large generative models that use the decoder to predict the next token output given all previous tokens (i.e., left context or prefix only). To combine the usage of both encoder and decoder, encoder-decoder models (such as T5 [39] and BART [40]) have also been proposed for sequence-to-sequence tasks where the training objective aims to recover the correct output sequence given the original input (e.g., corrupted to uncorrupted). One such training objective is span prediction tasks, where random spans (multiple tokens) are replaced with artificial span tokens and the model is tasked with recovering the original tokens. For inferencing, one can use the encoderdecoder models to infill text by also adding the artificial span token in place. Recently, researchers have also combined MLM with generative models to perform both bidirectional and autoregressive text generation or infilling [41]. In our APR scenario, all types of PLMs can potentially be leveraged for generative or infilling-style APR, and we select 9 state-of-theart PLMs for our study (detailed in Section III-A).\n\n\nB. Automated Program Repair\n\nAutomated Program Repair (APR) tools are used to generate patched code given the original code and the corresponding buggy location. Each patch generated by the APR tool is validated against the test suite. Plausible patches are ones which pass the entire suite. Correct patches are plausible patches which correctly fix the underlying bug.\n\nTraditional APR tools can be classified as heuristicbased [7]- [9], constraint-based [10]- [12] and templatebased [13]- [17]. Traditionally, template-based APR tools achieve the best performance, where each template is handcrafted by human experts designed to provide a fix for a specific type of bug. However, these template-based APR tools can only fix the bug types that are part of the templates. As a result, researchers employed learning-based APR tools to generate more expressive patches. Learning-based APR tools such as Recoder [19], RewardRepair [21], and CURE [20] are based on NMT techniques [23] which require specific bug fixing data to train the NMT model to generate a fix line given the buggy line. Due to this reliance on the bug-fixing data, these learning-based tools are still limited in terms of the type of fixes it can apply. Recent work of AlphaRepair [24] addresses this by performing APR under a zero-shot setting by directly using the CodeBERT model for repair. AlphaRepair fills the original buggy line with masked tokens and uses CodeBERT to replace the masked tokens with correct code tokens to generate repair, i.e., infilling-style (also called clozestyle) APR. While AlphaRepair is able to achieve state-of-theart results, CodeBERT is considerably smaller than the newest PLMs. Additionally, AlphaRepair is only tested on a single setting where the correct location of the buggy line is known.\n\nRecent work [28], [29] has also looked into directly applying PLMs for APR. Prenner et al. [29] conducted a smallscale evaluation for the Codex model on a simple dataset containing both Java and Python versions of buggy algorithm implementations. Codex is given the buggy function and by using prompt engineering, are then asked to generate a complete fixed function. The results show that Codex is competitive with state-of-the-art learning-based APR tools in Python but worse in Java. In contrast, we show that by using our practical repair settings, PLMs are able to outperform state-of-the-art APR tools on both Java and Python. Kolak et al. [28] also used Codex along with 2 smaller PLMs and evaluated their ability to generate the correct patch line when given the code prefix on the same dataset as the previous work [29]. The evaluation demonstrated the scaling effect of PLMs where the repair results can be improved by using larger models. Interestingly, the study leverages sum entropy for patch ranking while AlphaRepair leverages mean entropy (i.e., both favors more natural [42] patches). Thus, we also perform a study of leveraging various recent PLMs for computing both entropies for patch ranking on real-world systems. Overall, the 2 prior studies [28], [29] are done on a small dataset with synthetic bugs using only a small number of PLMs. Moreover, the input and repair setting being used in the studies are also limited, e.g., only considered generative APR. In this paper, we present an extensive study of applying various state-of-the-art PLMs for both infilling-style and generative APR on diverse repair datasets across programming languages.\n\n\nIII. APPROACH\n\nIn this section we describe the PLMs selected for evaluation and introduce 3 different APR generation settings we use to evaluate each PLM. These settings are designed to showcase the different practical ways we can directly use PLMs for APR and highlight advantages and differences of the studied PLM types. Also, we detail the patch ranking strategy of using entropy to prioritize patches that are more likely to be correct.\n\n\nA. Models\n\nWe begin by describing the different PLMs we use for evaluation. Our selection process starts with the list of popular models hosted on the Hugging Face [43] -an open-source platform to host and deploy large models. We sort the list of models based on popularity (#downloads this month) and select the PLMs which contain code as training data. Furthermore, we also pick models from different organizations and types (described below) to obtain a diverse set of models.\n\nAlong with the open-source models, we also use the closedsource Codex model [26] (accessible only via API) since it has shown to achieve impressive performance on code related tasks. In total, we use 9 different PLMs for our experiment.\n\nOur chosen PLMs range from 125M to 20B in parameter size. Table I presents the PLM overview. Column Model is the model name, #Parameters presents the number of model parameters, Training Dataset indicates the dataset used for pre-training (N.R. is not released), and Type refers to the type of APR the model can perform (infilling or generative).\n\n1) Generative Models:\n\n\u2022 GPT-Neo [38], GPT-J [44], GPT-NeoX [45] All three models are open-source implementations of the GPT-3 transformer architecture [25]. In our experiments, we use GPT-Neo models with 125M, 1.3B and 2.7B parameters. GPT-J and GPT-NeoX are even larger models with 6.7B and 20B parameters. These models were trained on The Pile [46], \n+ - #\n\nB. PLM-based Patch Generation\n\nIn our study, we designed three settings for APR: 1) Complete function generation -the input is a buggy function and the goal is to output the patched function.\n\n2) Correct code infilling -the buggy location is known and the goal is to generate the correct replacement code given the prefix and suffix of the buggy function.\n\n3) Single line generation -the bug location is provided and the bug is fixed by a single line change. Single line generation uses a subset of bugs in correct code infilling. We separate this case since many fault-localization methods provides a ranking in the granularity of individual code lines [51], [52]. More importantly, both infilling and generative PLMs can be applied for this setting, enabling direct comparison of the two. We now describe the different inputs for each setting. 1) Complete function generation: For this setting, the initial input is the original buggy function. We aim to use a generative model to autoregressively generate the entire patched version of the buggy function. However, naively feeding the PLMs the buggy function will not work since each PLM is not pre-trained for APR (i.e., they do not know that the goal is to generate a patched function). Therefore, to facilitate the direct usage of PLMs for APR, we use specific prompts to enable the models to perform few-shot learning. This allows the PLMs to recognize the task and generate a patched function by completing the input provided. We note here that the task of complete function generation makes no assumption of 1) the location of the bug and 2) the type of bug or fix required. Therefore, the PLM needs to figure out why the function is buggy and provide a patch to fix the bug. Figure 1 shows the input which is made up of two example bug fixes (one crafted by us and one from the same project/dataset the target bug is from) in order to demonstrate the task and the expected format of the output. To start off, we follow the prior study [29] and begin with a description of the task: # Provide a fix for the buggy function. This describes in natural language the task we want the PLM to perform. This is a Python example and we use the Python comment format of # as a prefix for this description (we use other comment prefixes depending on the language of the buggy code). We then provide an example bug and patch pair. In Figure 1, this example is a function which computes the Fibonacci number. We prefix the example buggy and fixed function with # Buggy Function and # Fixed Function to provide additional context for the model. For our second example, we follow the same prompting style and pick a buggy and patched function pair from the same project that the bug is from. This way we can provide the model with some examples of the coding style used in the project. Finally, we finish the prompt by adding the bug we want to fix.\n\n2) Correct code infilling: Unlike complete function generation, where the buggy location within the function is not known. For correct code infilling, the input is the prefix and suffix after removing the buggy code hunk. In order to fill in the correct code, both the prefix and suffix can provide useful information. As a result, generative models are not suitable for this task since the generation process conditions only on the context to the left (prefix). Therefore, for correct code infilling, we only use infilling models which perform generation by conditioning on both left (prefix) and right (suffix) code. Figure 2 shows an example input for the infilling task. We start with the target buggy function we want to fix and remove the buggy code hunk. This gives us the prefix and suffix code which are still correct. We then place an infilling token between the prefix and suffix. This infilling token (e.g., <INFILL>) indicates to the model that this is the location where we want the new code to be generated at. The model then generates only the code to fill in the missing chunk and we obtain a patch by combining the model output with the prefix and suffix code snippets.\n\n3) Single line generation: In single line generation, the buggy location is provided and the bug requires only a single line change. Figure 3a shows a similar setup to correct code infilling where we provide both the prefix and suffix code and use infilling models to generate a replacement line. Different from correct code infilling, we can also use generative models by providing only the prefix. Figure 3b demonstrates the setup to use generative models for this task. Since we know the bug requires only a single line change, we can stop the generation after the model has provided us with one line. We cannot apply the same strategy using generative models for correct code infilling since those bugs may need multiple lines to fix and we do not know when we can stop the generation [28]. Additionally, when using generative models for single line generation, we cannot provide the models with the suffix code due to the causal nature of the generative models. We contrast this with infilling models on the same task to demonstrate the effect of including the suffix context for APR.\n\n\nC. Patch Ranking and Validation\n\nFor all 3 repair tasks, the patch generation process is similar -we provide the PLMs with the constructed input and use sampling to generate multiple patches per bug. We use nucleus sampling [53] with a sampling temperature. A lower temperature means the model is likely to pick tokens with higher likelihood, resulting in samples that are more similar (temperature of 0 gives deterministic result by picking the most likely token at each generation step). A higher temperature gives more probability for the model to pick a token with a lower likelihood, leading to more unique and interesting samples. How to pick an optimal temperature value is not obvious for a problem such as APR. For certain bugs, one may prefer a lower temperature value in order to quickly arrive at a reasonable patch. For harder bugs, a higher temperature value can be useful to generate more unique patches in an attempt to provide a fix. For our experiments, we use the default setting used in previous work [26], [30].\n\nIn addition to generating patches, we also record the entropy value of each patch. Entropy captures how natural [42] the generated sample is according to the model and can be calculated as the negative log probability of each generated token. Let t 1 , t 2 , ..., t n be the list of tokens generated and p ti be the model probability of generating token t i given the previous context and generated tokens. Entropy is defined as:\nmean entropy = \u2212 n i=1 log(p ti ) n (1) sum entropy = \u2212 n i=1 log(p ti )(2)\nMean entropy averages entropies of all tokens generated whereas sum entropy computes the total entropy of the sequence. For patch ranking, we prioritize patches with lower entropy first. In this way, patches that are more natural [42] can be ranked higher. Previous work on leveraging PLMs for APR either used mean entropy [24] or sum entropy [28] without thorough evaluation, and mainly focused on patch ranking. In contrast, in this work, we empirically compare both entropy computations, and have further applied them for both patch ranking and patch correctness checking [54]. Finally, for each patch generated, we filter out any patches with syntactic or semantic errors and validate the rest against the test suites to identify patches which pass all the tests.\n\n\nIV. EXPERIMENTAL SETUP\n\n\nA. Research Questions\n\nWe study the following research questions: \n\n\nB. Implementation\n\nWe implement the generation pipeline in Python using PyTorch [55] versions of each PLM. We use the Hugging Face [43] library to load the model weights and generate outputs. For Codex, we use API access provided by OpenAI to query the model [56] with code-davinci-002 engine. To use Codex for correct code infilling, we append the API request with an additional suffix parameter [50] with the extracted suffix from the bug. For all our experiments, we directly reuse  [26], [28], [30].\n\nPatches are generated on a 32-Core workstation with Ryzen Threadripper PRO 3975WX CPU, 256 GB RAM and NVIDIA RTX A6000 GPU, running Ubuntu 20.04.4 LTS.\n\n\nC. Subject Systems\n\nFor evaluation, we use 5 APR benchmarks spanning across 3 programming languages. We focus on bugs where the fix is within a single function, which is also the focus of most recent APR work [19], [20], [22], [57]. To this end, we filter these benchmarks to find bugs that fit our designed repair settings. Table II presents the details of each repair dataset. Column Dataset is the dataset name, #Bugs is the total number of bugs, #SF, #SH, #SL shows the number of bugs which the reference fix is within a single function, single hunk (consecutive lines) and single line. Source refers to where the bugs are collected from, Language is the programming language of the bugs. We next discuss the detailed dataset information:\n\n1) Defects4J 1.2 and 2.0 [58]: The most widely studied APR benchmark with a collection of bugs gathered from open-source projects in Java containing pairs of buggy and patch versions of the source project. Since Defects4J has been updated to include more bugs from additional projects, we consider 2 different versions of Defects4J. Defects4J 1.2 contains 391 bugs (removing the 4 depreciated bugs) from 6 open-source Java projects. Defects4J 2.0 contains 438 new bugs from 9 additional projects. Each bug in Defects4J also contains developer tests exposing the bug.\n\n2) QuixBugs-Python and -Java [59]: A multi-lingual repair benchmark with 40 classic programming problems. QuixBugs benchmark is constructed from a programming challenge where programmers were asked to fix a small buggy function. QuixBugs was originally in Python but has been translated to Java, with both versions having the same 40 bugs. Each bug is accompanied with multiple test inputs and expected outputs.\n\n3) ManyBugs [60]: A C repair dataset consisting of 185 bugs gathered from 9 open-source projects with developer written tests. Each bug is manually verified and classified into a bug type. However, we were not able to reproduce all bugs from the dataset (i.e., builds successfully and reference patches can pass all provided tests). As such we only use the 91 bugs where the results were reproducible by us.  \n\n\nD. Compared Techniques\n\nWe compare against the state-of-the-art APR baselines with both learning-based and traditional APR tools. We choose 8 recent learning-based APR tools: AlphaRepair [24], Re-wardRepair [21], Recoder [19], DeepDebug [61], CURE [20], CoCoNuT [22], DLFix [62] and SequenceR [63]. Apart from AlphaRepair, these learning-based APR baselines are based on the NMT models. AlphaRepair combines a PLM (CodeBERT) with simple templates to generate patches under a zeroshot setting. Furthermore, we also choose 12 traditional APR tools: TBar [17], PraPR [18], AVATAR [16], SimFix [64], FixMiner [15], CapGen [9], JAID [65], SketchFix [13], NOPOL [12], jGenProg [66], jMutRepair [14], and jKali [14]. In total, we evaluate against 20 different APR tools. We compare against the baseline results on Defects4J 1.2, 2.0, QuixBugs-Python and Java on perfect fault localization -the ground-truth fix location is known to the repair tool. This is the preferred comparison setting as it eliminates the impact of differences in fault localization have on the result [19], [20], [22], [67]. Due to the lack of recent APR tools that are evaluated on ManyBugs, we only use it for RQ1. We follow prior work [17]- [20] and directly use the correct patch results from previous studies [17], [18], [24].\n\n\nE. Evaluation Metrics\n\nTo evaluate the repair performance, we use the standard metrics of plausible patches -passing the all test cases, and correct patches -syntactically or semantically equivalent to the reference patches. To determine correct patches, we follow the standard practice in APR research and manually inspect each plausible patch for semantic equivalency.\n\n\nV. RESULT\n\nA. RQ1: Comparison of Different PLMs 1) Repair effectiveness: We first compare PLMs against each other in generating plausible and correct patches. Table III shows the results of 6 generative models under complete function generation setting. The two integers in each cell represent the number of correct and plausible patches. We first observe that similar to previous studies in NLP [36], there is a scaling effect on the repair effectiveness. As we increase the size of the model, we also increase in the number of correct and plausible patches generated. Directly looking at the group of GPT models trained on the same dataset, we see that the performance consistently increases as we use larger models across all repair datasets. However, we see that the Codex model (12B) outperforms the biggest model (GPT-NeoX (20B)). We hypothesize that this is because Codex is designed and finetuned for code generation; on the other hand, while the training dataset of GPT-NeoX is partially made up of code, it is designed for general purpose text generation.\n\nTables IV and V show the results on the correct code infilling and single line generation repair tasks. Similar to the previous result, we again see the scaling effect of increased performance as model size increases. Compared to complete function generation, we observe that each model using correct code infilling and single line generation is able to produce a higher ratio of correct fixes to the total number of bugs. Furthermore, we also observe that the ratio of correct patches to plausible patches is higher in the latter 2 settings as well. This signals that patches produced using code infilling and single line generation is more likely to be the correct fix. The improved performance is because for complete function generation the model needs to understand the prompt given (III-B1), localize the bug and provide the correct fix. On the other hand, when we provide the model with the buggy location information in correct code infilling and single line generation, it only needs to fill in or complete the partial code, leading to more correct patches. This comparison is more direct when evaluating the Codex model, the only model that can perform both code infilling and function generation. We see that when performing correct code infilling, Codex is able to fix 40% (62/154) of the total bugs whereas when asked to generate the entire function, it drops to 28% (63/225). Table V, we included both generative and infilling models. However, for generative models we are not able to provide it with suffix code snippets since their generation is dependent only on the previous context. We compare this with infilling models, which can perform infilling conditioned on both the context before and after. We observe that infilling models perform better than their generative counterparts. Additionally, since we are able to use both the generative and infilling versions of Codex, we can directly compare the repair ability of the model when given only the prefix versus both prefix and suffix context. We see that when using the suffix information from the original buggy function, the Codex model is able to improve the number of correct and plausible fixes across all repair datasets. This shows that for repair, successfully utilizing the code after the buggy lines is important for fixing bugs.  2) Speed: Next we look at the speed of patch generation using PLMs. We already saw from the previous result analysis that as we increase the size of the model, we obtain an increase in repair performance. However, such performance increase does not come for free as larger models require longer time for inferencing. Table VI shows the samples generated per minute for different PLMs on Defects4J 1.2 and QuixBugs-Python with the 3 repair generation settings (Columns CF, CI, SL refer to complete function, correct infilling and single line generation, respectively). We only include models that we run locally on the same hardware (i.e., excluding Codex since it is only accessible through API access). We first observe that as we increase model size, the patch generation speed drastically slows down (71x slower on GPT-NeoX than GPT-Neo 125M on complete function generation). This demonstrates the tradeoff between repair effectiveness and time cost when using large models. Additionally, we see that compared to single line generation and correct code infilling, complete function generation takes significantly more time, since generating an entire function is much more time consuming than generating a single line or hunk. This shows that when the buggy location is known, we can use infilling and single line generation settings to achieve faster repair.\n\n\nFor single line generation results in\n\n3) Compilation rate: We evaluate the compilation rate of the patches generated by each PLM. Figure 4 shows the syntactic and semantic error rates of all studied PLMs using the three repair settings on Defects4J 1.2. We first observe that the overall error rate (syntactic + semantic) of the generated patches goes down as we increase the size of the model. This reaffirms the previously discussed scaling effect of PLMs and show that the patches generated by larger models contain less errors. Next we see that all generative models using single line generation produced a high number of syntactic errors. Recall that single line generation when using generative models only provides the prefix in the buggy function. As a result, the generated line can easily introduce some syntax errors (e.g., adding an if statement with an opening bracket) since the model does not know what the suffix code context is. On the other hand, the amount of syntax errors produced in the two other settings are much lower. For complete function generation, PLMs can effectively retain the syntax of the language during training and generate syntactically correct functions. For correct code infilling, not only do we get low syntactic errors but also achieve the lowest semantic errors.\n\nHaving both the prefix and suffix provides the model with sufficient context which leads to higher compilable patch rate.\n\nB. RQ2: Comparison against State-of-the-art APR tools 1) Defects4J 1.2 results: We first compare the results of directly using PLMs for repair against both traditional and learning-based APR tools on Defects4J 1.2. Table VII shows the number of correct bug fixes of the top baseline tools and also the PLMs in our evaluation. The last 3 columns present the number of correct patches generated when using each of the three APR settings. We then combine all patches generated for each of the models together (Column 2) to demonstrate the total number of fixes that can be obtained for the 255 single function bugs in Defects4J 1.2. Note that this is still a fair comparison -prior APR techniques typically use a timeout of 5h for each bug [19], [20], [24], while generating 200 patches for each of the 3 settings (i.e., at most 600 patches in total) costs no more than 2.5 hours for each model.\n\nWe observe that some of the models are able to achieve comparable performances compared to some of the recent state-of-the-art APR tools. Additionally, this result is obtained while generating only up to 600 samples per bug whereas prior approaches, especially learning-based tools, can generate up to 5000 patches per bug [20], [22], [24]. While the most effective model (Codex) can already outperform all existing techniques (e.g., fixing 99 single-function bugs), by combining the patches generated by all models (Total), we can achieve 109 correct fixes on single function bugs! The surprising results show that by directly applying PLMs for APR without any specific change/finetuning, we can already achieve the highest number of correct fixes compared to existing baselines. Figure 5 presents the Venn diagram of unique fixes that can be generated using PLMs compared to the 3 best performing baselines on all the single function bugs in Defects4J 1.2. We also combine all fixes from other baselines together into the \"Others\" category in the Venn diagram. We observe that by combining all the models together, we can generate a significant amount of unique bug fixes (36) that no other tools have fixed so far. Due to the potential data leakage issue (discussed in detail in Section VI), we further investigate whether PLMs can generate correct patches that are not exactly the same as developer patches. Figure 5b shows the unique bug fixes on Defects4J 1.2 compared to the baselines when we remove all fixes which are exactly the same as the developer patch. We observe that combining all PLMs together would still achieve the highest number of bug fixes (93) with 31 unique bug fixes.\n\nTo demonstrate the ability of these PLMs, we show some unique fixes produced by them. Figure 6a is a correct patch produced by the INCODER 6.7B model under correct code infilling task. We see here that the function is called areEqual and the bug is caused by missing a specific case of comparing if the two inputs have the same reference. Using both the prefix (name of the function) and suffix (other comparison statements with return values), the model figures out the correct code to  Figure 6b shows a patch of the Math-69 bug generated by Codex. The function here calculates a matrix of p-values of a 2-sided, 2-sample t-test. The bug is caused by precision error when the function call is extremely close to 1. Here the model generates an alternative way of calculating the p-value which is much more stable than before. This is a hard bug to fix since the change is quite subtle however it does not fit any of the common templates used in traditional APR. To generate the correct fix, the model needs to understand the goal of the function (p-value calculation) and use statistical formulas. Both of which is in Codex as it is trained not only on code but also on general text, which contains many descriptions and examples of t-test p-value calculations. This unique fix shows the benefit of using PLMs for program repair where domain knowledge of the project can be utilized as well.\n\n2) Additional results: In addition to comparing against state-of-the-art baselines on Defects4J 1.2, we also compare the performance of PLMs on other datasets widely used to evaluate previous APR tools. Table VIII shows the results on Defects4J 2.0, QuixBugs-Java and -Python where we also combine the correct bug fixes of the 3 generation strategies together. Similar to the Defects4J 1.2 results, we observe that many models can achieve similar (or even better) performance with carefully designed APR tools. More surprisingly, all 9 studied PLMs can outperform TBar, state-of-the-art templatebased APR tool, and are competitive compared with the recent Recoder technique on the Defects4J 2.0 dataset. Furthermore, unlike many baselines which can only be used on a single language (specifically designed for a particular language or requiring additional finetuning on another language), the PLMs can be directly applied for multi-lingual repair.\n\nC. RQ3: Patch Ranking and Correctness Checking Analysis 1) Entropy: As we are using PLMs for patch generation, this allows us to compute the entropy of each patch. Entropy calculates how natural the generated sample is (Equation 1). Table IX shows the mean entropy values for correct (C), plausible (P) and non-plausible patches (NP). Each row shows the results of a PLM on a repair scenario containing bugs for which the PLM can produce a correct patch. We observe that average entropy value of correct and plausible patches for all models are less than non-plausible patches. Although not shown in the table, we observe the same finding when comparing patches using sum entropy. In other words, the studied PLMs consider correct patches which correctly fix the underlying bugs to be more nature than other patches. Additionally, while the entropy difference between correct and plausible patches are not as drastic as compared to nonplausible patches, we also find that correct patches are in general less entropic than plausible ones. Recent work [54] has shown that existing solutions for patch-correctness checking (i.e., identifying correct patches from plausible patches) can suffer from dataset overfitting and performance drops when applied on more complicated patches. We demonstrate for the first time that entropy computation via PLMs can help distinguish correct patches from plausible patches, indicating a promising future of directly leveraging the PLM entropy metric for patch-correctness checking.\n\n2) Patch ranking: Using the entropy values of each generated patch, we perform ranking to validate patches with higher rank (lower entropy) first. We pick 5 PLMs with the highest number of correct patches to perform this analysis. Figure 7 shows the number of bugs fixed for the Defects4J 1.2 dataset using different patch ranking strategies as we increase the number of patches to validate. We see that compared to randomly picking patches to validate (blue line), when using entropy rankings (orange and green line), we can validate the correct patches faster. This shows that entropy can be an effective measure used to rank the potential patches to  prioritize lower entropy patches for validation under tighter time constraints. Furthermore, we observe that sum entropy performs slightly better compared to mean entropy. We hypothesize that this is because sum entropy calculates the entire sequence entropy regardless of the length of the generated sequence. As such, shorter sequences tend to have lower sum entropy compared to longer sequences; interestingly, this is consistent with traditional APR or patch correctness checking techniques [11], [72], [73], which favor simple patches over complicated ones.\n\n\nD. RQ4: Improvements on Direct PLM APR\n\nIn previous RQs, we showed that by directly applying PLMs for APR we can already achieve comparable performance with previous APR tools. We further explore the possibilities to boost the ability of PLMs for APR. For this experimental setup, we choose the best performing model (apart from Codex, which already outperforms existing APR techniques without any further extension) -INCODER 6.7B and run the model longer (2000 samples per bug) combined with repair templates. We evaluate on all bugs in Defects4J 1.2 by adjusting our repair settings to generate patches for every location which is changed by the reference patch instead of only on a single change location. This setup is similar to previous learning-based repair tools [19], [24] and allows us to compare on the full Defects4J 1.2 dataset. Furthermore, following prior work [24], we include evaluation on Defects4J 2.0 single line bugs and QuixBugs-Python. We observe that if we apply the model longer and generate more samples, we can drastically improve the number of correct bugs fixed in all three datasets and achieve very close result to that obtained by the best baseline. Moreover, we can obtain further improvements by using simple repair templates and achieve the highest number of correctly fixed bugs on all datasets, e.g., fixing 78 bugs on Defects4J 1.2 with 15 unique bug fixes that no other baseline tools have fixed before. This finding shows that not only can PLMs be effective when directly used for program repair, we can combine them with more domain specific techniques such as simple repair templates to further improve their performance.\n\n\nVI. THREATS TO VALIDITY\n\nInternal. One internal threat to validity comes from our manual validation of plausible patches to determine semantically correct patches. To address this, we carefully performed the analysis and released the correct patches and code used to perform the experiments for public evaluation [74].\n\nAnother internal threat comes from the potential data leakage of real developer patched functions being part of the original training data. To address this, we examine the patches PLMs generated for Defects4J 1.2 since this is the most widely studied dataset for APR and we mainly compared with stateof-the-art APR tools on this dataset. We first check if the bugs fixed by each PLM contain correct patches different than the reference developer patches. Out of the 354 individual bug fixes by all models on Defects4J 1.2, 234 fixes (66%) contain a patch that is different than the developer patch. We also found that due to the simplicity of single line patches, majority of the correct patches generated for single line bugs are the same as the developer patch. If we exclude single line bugs, the percentage increases to 77% (196/255). Out of the 109 bugs that can be fixed by combining all correct patches generated by all PLMs together (Total row in Table VII), 93 bugs (85%) are fixed by at least one correct patch that is different than the original developer patch, e.g., as shown in Figure 5b, removing PLM fixes that are exactly the same as the developer patches can still fix 31 bugs that prior tools cannot fix.\n\nSince we only have access to the training data used in CodeT5, GPT-Neo, GPT-J and GPT-NeoX models, we further check if the fixed function is within the training datasets when the correct patch is equivalent to the developer fix for these models. We found that while 38% (48/128) of bugs fixes contain only the same fix as the developer patch, only 15% (20/128) of those patches are also found in the original training data, showing that the majority of correct bug fixes provided by these PLMs are not simply from memorizing the training data. Moreover, our RQ4 shows that improvements can be further made by combining repair templates with PLMs, which is orthogonal to the data leakage issue. Additionally, We observe that PLMs are able to achieve the state-of-the-art results on QuixBugs dataset which is not part of the training data as it has low number of stars on GitHub and contains synthetic bugs and patches that are not part of any larger real-world projects. Further reducing the data leakage issue would require retraining the PLMs, which could be extremely costly. External. We evaluate PLMs on 5 repair datasets across 3 programming languages, making our evaluation one of the most comprehensive studies in APR. However, our findings may still not generalize to other datasets or languages.\n\n\nVII. CONCLUSION\n\nWe present an extensive evaluation on PLMs for direct program repair. We use 9 state-of-the-art PLMs with 5 different repair datasets and design different practical repair settings to compare and contrast the repair effectiveness of different PLMs. In our evaluation, we shed light on the scaling effect that increasing model size has on various important factors in APR such as the number of bugs fixed, the speed of patch generation, and the compilation rate. Also, we compare the performance of PLMs against state-of-the-art APR tools and highlight the unique fixes and advantages of using PLMs for APR. Furthermore, we evaluated the ability for PLMs to perform patch ranking in order to prioritize correct patches for faster validation. Lastly, we demonstrate the possibilities (i.e., increasing the sample size and combining PLMs with repair templates) to further boost the performance of PLMs for APR. The results from our study demonstrate promising future of adopting PLMs for APR.\n\nFig. 3 :\n3APR input for single line generation\n\nFig. 4 :\n4Syntactic and semantic error rates on Defects4J 1.2\n\nFig. 6 :\n6Unique bug fixes generated by PLMs\n\nFig. 7 :\n7Number of bugs fixes when using different patch ranking strategies on Defects4J 1.2\n\nTABLE I :\nIEvaluation PLM overviewModel \n#Parameters Training Dataset \nType \n\nGPT-Neo \n125M/1.3B/2.7B \nThe Pile \nGenerative \nGPT-J \n6.7B \nThe Pile \nGenerative \nGPT-NeoX \n20B \nThe Pile \nGenerative \n\nCodex \n12B \nN.R. \nGenerative \n& Infilling \n\nCodeT5 \n220M \nCodeSearchNet \n& BigQuery \nInfilling \n\nINCODER \n1.3B/6.7B \nN.R. \nInfilling \n\n\n\n\nCodex In addition to using Codex as a generative model, we use the recently added suffix feature[50] to perform code infilling. Since Codex is not open-sourced, we do not know how the model performs the infilling.Provide a fix for the buggy function \n# Buggy Function \ndef fibonacci(n): \nif n == 0: \nreturn 0 \nelif n == 1 or n == 2: \nreturn 1 \nelse: \nreturn fibonacci(n-1) -fibonacci(n-2) \n# Fixed Function \ndef fibonacci(n): \nif n == 0: \nreturn 0 \nelif n == 1 or n == 2: \nreturn 1 \nelse: \nreturn fibonacci(n-1) + fibonacci(n-2) \n\n# Provide a fix for the buggy function \n# Buggy Function \n{ example_bug } \n# Fixed Function \n{ example_fix } \n\n# Provide a fix for the buggy function \n# Buggy Function \n{ bug } \n# Fixed Function \n\nBuggy \nProject \n\nPrevious Bug \nand Fix \n\nTarget Bug \n\nBug Fix \nExample \n\nExample Bug \n\nExample Fix \n\nExample \u2460 \n\nExample \u2461 \n\nFig. 1: APR input for complete function generation \n\nan 800GB dataset combining 22 diverse text-based datasets \nwith 7.6% containing open-source Github code. \n\u2022 Codex [26] A 12B parameter GPT-3 based model designed \nfor code generation. Codex is initialized with GPT-3 weights \ntrained on natural language corpus and then finetuned on a \nlarge corpus of 159GB code files. \n2) Infilling Models: \n\n\u2022 CodeT5 [47] A 220M parameter model based on T5 [39] ar-\nchitecture designed for code related tasks. CodeT5 is trained \nusing span prediction objective on 8.35 million functions \nacross 8 different programming languages by combining \nCodeSearchNet [48] with C/C# dataset from BigQuery [49]. \n\u2022 INCODER [30] A model designed for code infilling by \nadopting a causal masking objective [41]. INCODER is \ntrained on both open-source Github/GitLab code (159 GB) \nand StackOverFlow questions and answers (57 GB). We use \nboth the 1.3B and 6.7B parameter version. \n\u2022 \n\n\u2022 RQ1 :\nRQ1How do different types of PLMs perform for different APR settings? We study the effectiveness of different PLMs on different repair datasets, across different languages and on different APR tasks. Furthermore, we evaluate the scaling behavior of PLMs when increasing model size with respect to APR ability, computation time and compilation rates to holistically evaluate each PLM. \u2022 RQ2: How does directly applying PLMs for APR compare against state-of-the-art APR tools? We compare the results using PLMs against state-of-the-art baselines. We study the unique bugs fixed by PLMs and highlight the advantages of directly applying PLMs for APR. \u2022 RQ3: Can PLMs be directly used for patch ranking and correctness checking? We use the built-in naturalness metric of PLMs (entropy) to evaluate if PLMs considers patched functions to be more natural than buggy functions and if entropy can directly rank the patches for patch ranking and correctness checking.\u2022 RQ4: Can we further improve the performance of \nPLMs? We explore two directions for further improving \nPLMs' performance for APR: 1) increasing the number of \nsamples, and 2) combining PLMs with templates. \n\n\n\nTABLE II :\nIIEvaluation dataset statisticsDataset \n#Bugs #SF #SH #SL \nSource \nLanguage \n\nDefects4J 1.2 \n391 \n255 \n154 \n80 \nreal-world \nJava \nDefects4J 2.0 \n438 \n228 \n159 \n78 \nreal-world \nJava \nQuixBugs-\nJava \n40 \n40 \n37 \n36 \ncoding \nproblems \nJava \n\nQuixBugs-\nPython \n40 \n40 \n40 \n40 \ncoding \nproblems \nPython \n\nManyBugs \n185 \n39 \n23 \n12 \nreal-world \nC \nTotal \n1094 \n572 \n413 \n246 \n\nthe weights of each model. Our default setting for generation \nuses nucleus sampling [53] with top p = 0.95, temperature \n= 0.8 and 200 samples per bug. This generation setting is \nconsistent with previous studies on PLMs \n\nTABLE III :\nIIIComplete function APRDataset \nGPT-Neo \n125M \n\nGPT-Neo \n1.3B \n\nGPT-Neo \n2.7B \nGPT-J \nGPT-\nNeoX \nCodex \n\nDefects4J 1.2 \n6 / 8 \n7 / 16 \n10 / 24 14 / 31 18 / 36 63 / 102 \nDefects4J 2.0 \n2 / 17 \n4 / 18 \n6 / 20 11 / 33 15 / 36 49 / 93 \nQuixBugs-Java 1 / 3 \n4 / 5 \n3 / 5 \n3 / 5 8 / 9 32 / 35 \nQuixBugs-Py \n1 / 3 \n4 / 6 \n4 / 6 13 / 17 19 / 22 37 / 37 \nManyBugs \n0 / 2 \n1 / 4 \n2 / 4 \n3 / 6 4 / 12 7 / 15 \n\n\n\nTABLE IV :\nIVCorrect code infilling APRDataset \nCodeT5 \nINCODER 1.3B \nINCODER 6.7B \nCodex \nDefects4J 1.2 \n6 / 13 \n32 / 51 \n37 / 53 \n62 / 77 \nDefects4J 2.0 \n12 / 19 \n31 / 56 \n37 / 61 \n56 / 85 \nQuixBugs-Java \n10 / 10 \n21 / 26 \n26 / 29 \n34 / 36 \nQuixBugs-Py \n7 / 8 \n25 / 26 \n27 / 28 \n39 / 39 \nManyBugs \n2 / 5 \n8 / 12 \n9 / 13 \n12 / 15 \n\n\n\nTABLE V :\nVSingle line APRDataset \nGPT-Neo \n125M \n\nGPT-Neo \n1.3B \n\nGPT-Neo \n2.7B \nGPT-J \nGPT-NeoX CodeT5 \nINCODER \n1.3B \n\nINCODER \n6.7B \n\nCodex \nsingle-line \n\nCodex \nsuffix \nDefects4J 1.2 \n5 / 10 \n12 / 20 \n13 / 21 \n16 / 26 \n21 / 31 \n5 / 12 \n21 / 36 \n26 / 38 \n32 / 37 \n39 / 47 \nDefects4J 2.0 \n8 / 17 \n10 / 26 \n16 / 28 \n12 / 26 \n19 / 36 \n9 / 15 \n15 / 32 \n21 / 37 \n26 / 38 \n31 / 45 \nQuixBugs-Java \n8 / 9 \n19 / 20 \n16 / 17 \n20 / 21 \n20 / 21 \n10 / 10 \n21 / 26 \n26 / 29 \n30 / 31 \n34 / 36 \nQuixBugs-Python \n9 / 10 \n14 / 14 \n22 / 23 \n26 / 27 \n28 / 28 \n7 / 8 \n25 / 26 \n27 / 28 \n36 / 36 \n39 / 39 \nManyBugs \n2 / 4 \n2 / 5 \n3 / 5 \n6 / 7 \n6 / 9 \n2 / 4 \n8 / 11 \n9 / 11 \n8 / 10 \n10 / 11 \n\n\n\nTABLE VI :\nVIPatch generation speed (#patch/min)Models \nDefects4J 1.2 \nQuixBugs-Python \nCF \nCI \nSL \nCF \nCI \nSL \n\nGPT-Neo 125M 139 \n-1080 369 \n-1061 \nGPT-Neo 1.3B \n31 \n-\n543 127 \n-\n814 \nGPT-Neo 2.7B \n27 \n-\n489 \n85 \n-\n625 \nGPT-J \n15 \n-\n227 \n39 \n-\n354 \nGPT-NeoX \n2 \n-\n47 \n6 \n-\n73 \nCodeT5 \n-969 \n-\n-1991 \n-\nINCODER 1.3B \n-535 \n-\n-1083 \n-\nINCODER 6.7B \n-288 \n-\n-\n419 \n-\n\n\n\nTABLE VII :\nVIIDefects4J 1.2 baseline comparison \n\nTools / Models \nSingle func. \n(255 bugs) \n\nPatch \nfunc. \n\nCorrect \nhunk \n\nSingle \nline \n\nAlphaRepair \n67 \nRewardRepair \n48 \nRecoder \n61 \nTBar \n54 \nCURE \n52 \nGPT-Neo 125M \n9 \n6 \n-\n5 \nGPT-Neo 1.3B \n18 \n7 \n-\n12 \nGPT-Neo 2.7B \n20 \n10 \n-\n13 \nGPT-J \n28 \n14 \n-\n16 \nGPT-NeoX \n34 \n18 \n-\n21 \nCodeT5 \n6 \n-\n6 \n-\nINCODER 1.3B \n32 \n-\n32 \n-\nINCODER 6.7B \n37 \n-\n37 \n-\nCodex \n99 \n63 \n62 \n32 \nTotal \n109 \n69 \n74 \n40 \n\n\n\nTABLE VIII :\nVIIIAdditional baseline comparisonTools / Models \nDefects4J 2.0 \n(78 bugs) \n\nQuixBugs-Java \n(40 bugs) \n\nQuixBugs-Python \n(40 bugs) \n\nAlphaRepair \n35 \n28 \n27 \nRewardRepair \n25 \n20 \n-\nDeepDebug \n-\n-\n21 \nRecoder \n11 \n17 \n-\nCURE \n-\n21 \n-\nTBar \n8 \n-\n-\nCoCoNuT \n-\n13 \n19 \nGPT-Neo 125M \n10 \n8 \n9 \nGPT-Neo 1.3B \n11 \n20 \n17 \nGPT-Neo 2.7B \n19 \n18 \n24 \nGPT-J \n16 \n22 \n29 \nGPT-NeoX \n24 \n21 \n31 \nCodeT5 \n9 \n10 \n7 \nINCODER 1.3B \n15 \n21 \n25 \nINCODER 6.7B \n21 \n26 \n27 \nCodex \n45 \n38 \n40 \nTotal \n52 \n38 \n40 \n\nbe insert here (first checking if the references are the same \nbefore proceeding). Such code is commonly found in open-\nsource projects which uses similar comparison functions where \nthe PLMs can learn from. In fact, we found several similar \ncomparison functions (checking if the objects have the same \nreference) [68]-[71] in different projects as a part of The \nPile dataset [46] that some of the PLMs were trained on. \nFurthermore, unlike traditional APR tools which often work \non a single line, PLMs can generate multiple lines of code in \norder to provide the correct fixes. \n\n\nTABLE IX :\nIXMean entropy of generated patchesModels \nDefects4J 1.2 \nQuixBugs-Python \nC \nP \nNP \nC \nP \nNP \n\nFunction Gen. \n\nGPT-Neo 125M 0.08 0.13 0.23 0.10 0.10 \n0.20 \nGPT-Neo 1.3B \n0.12 0.12 0.19 0.06 0.05 \n0.09 \nGPT-Neo 2.7B \n0.09 0.13 0.17 0.05 0.06 \n0.08 \nGPT-J \n0.07 0.10 0.12 0.04 0.05 \n0.08 \nGPT-NeoX \n0.08 0.11 0.13 0.05 0.07 \n0.10 \nCodex \n0.04 0.05 0.08 0.11 0.13 \n0.16 \n\nInfilling \nCodeT5 \n0.50 0.51 0.54 0.51 0.50 \n0.59 \nINCODER 1.3B \n0.49 0.58 0.65 0.54 0.56 \n0.65 \nINCODER 6.7B \n0.45 0.50 0.61 0.61 0.60 \n0.65 \nCodex \n0.43 0.43 0.50 0.32 0.33 \n0.42 \n\nLine Gen. \n\nGPT-Neo 125M 0.38 0.42 0.58 0.41 0.45 \n0.61 \nGPT-Neo 1.3B \n0.32 0.38 0.58 0.25 0.27 \n0.47 \nGPT-Neo 2.7B \n0.28 0.32 0.55 0.21 0.26 \n0.40 \nGPT-J \n0.29 0.33 0.54 0.20 0.22 \n0.38 \nGPT-NeoX \n0.39 0.42 0.71 0.26 0.28 \n0.55 \nCodex \n0.19 0.28 0.57 0.18 0.23 \n0.60 \n\n\n\nTABLE X :\nXBaseline comparison with PLM improvementsTools / Models \nDefects4J \n1.2 All \n\nDefects4J 2.0 \nSingle Line \n\nQuixBugs-\nPython \n\nAlphaRepair \n74 \n35 \n27 \nRewardRepair \n45 \n25 \n-\nDeepDebug \n-\n-\n21 \nRecoder \n65 \n11 \n-\nTBar \n68 \n8 \n-\nINCODER (200) \n37 \n21 \n27 \nINCODER (2000) \n64 \n25 \n32 \nINCODER w/ template (2000) \n78 \n39 \n37 \n\n\n\nTable X\nXshows the baseline tools along with our model setups. INCODER (200) is our default setup from previous evaluation that generates 200 samples per bug. INCODER (2000) shows the results when we increase the number of samples to 2000. INCODER w/ template (2000) contains the results when combining repair template with the INCODER model. Using similar design as the AlphaRepair baseline, we apply different repair templates by using the original buggy line. Such templates include: keeping parts of the prefix or suffix, replacing method calls or parameters, and changing/adding new boolean conditions or operators to the buggy line. These repair templates make use of the original buggy line and provide important starting code for the model.\n\nSoftware for the healthcare industry: what is it and why it's worth using?\" neoteric. K Luzniak, K. Luzniak, \"Software for the healthcare industry: what is it and why it's worth using?\" neoteric, 2022, https://neoteric.eu/blog/ software-for-the-healthcare-industry-what-is-it-and-why-its-worth-using.\n\nData driving new approaches to transportation. N Mayersohn, The New York Times. N. Mayersohn, \"Data driving new approaches to transportation,\" The New York Times, 2022, https://www.nytimes.com/2020/02/05/ technology/data-micromobility-electric-scooters-mds.html.\n\nSoftware's dangerous aspect. E Richards, The Washington Post. E. Richards, \"Software's dangerous aspect,\" The Washington Post, 1990, https://www.washingtonpost.com/archive/politics/1990/12/09/ softwares-dangerous-aspect/9b2e9243-8deb-4ac7-9e8f-968de0806e5e/.\n\nReport: Software failure caused $1.7 trillion in financial losses in 2017. S Matteson, TechRepublicS. Matteson, \"Report: Software failure caused $1.7 trillion in financial losses in 2017,\" TechRe- public, 2018, https://www.techrepublic.com/article/ report-software-failure-caused-1-7-trillion-in-financial-losses-in-2017/.\n\nThe debugging mindset. D H O&apos;dell, D. H. O'Dell, \"The debugging mindset,\" acmqueue, 2017, https://queue. acm.org/detail.cfm?id=3068754/.\n\nAutomatic software repair: A survey. L Gazzola, D Micucci, L Mariani, IEEE Transactions on Software Engineering. 451L. Gazzola, D. Micucci, and L. Mariani, \"Automatic software repair: A survey,\" IEEE Transactions on Software Engineering, vol. 45, no. 1, pp. 34-67, 2019.\n\nGenprog: A generic method for automatic software repair. C Le Goues, T Nguyen, S Forrest, W Weimer, IEEE Transactions on Software Engineering. 381C. Le Goues, T. Nguyen, S. Forrest, and W. Weimer, \"Genprog: A generic method for automatic software repair,\" IEEE Transactions on Software Engineering, vol. 38, no. 1, pp. 54-72, 2012.\n\nHistory driven program repair. X B D Le, D Lo, C Le Goues, 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER). 1X. B. D. Le, D. Lo, and C. Le Goues, \"History driven program repair,\" in 2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER), vol. 1, 2016, pp. 213-224.\n\nContext-aware patch generation for better automated program repair. M Wen, J Chen, R Wu, D Hao, S.-C Cheung, Proceedings of the 40th International Conference on Software Engineering, ser. ICSE '18. the 40th International Conference on Software Engineering, ser. ICSE '18M. Wen, J. Chen, R. Wu, D. Hao, and S.-C. Cheung, \"Context-aware patch generation for better automated program repair,\" in Proceedings of the 40th International Conference on Software Engineering, ser. ICSE '18, 2018, p. 1-11.\n\nAngelix: Scalable multiline program patch synthesis via symbolic analysis. S Mechtaev, J Yi, A Roychoudhury, Proceedings of the 38th International Conference on Software Engineering, ser. ICSE '16. the 38th International Conference on Software Engineering, ser. ICSE '16S. Mechtaev, J. Yi, and A. Roychoudhury, \"Angelix: Scalable multiline program patch synthesis via symbolic analysis,\" in Proceedings of the 38th International Conference on Software Engineering, ser. ICSE '16, 2016, p. 691-701.\n\nS3: syntaxand semantic-guided repair synthesis via programming by examples. X.-B D Le, D.-H Chu, D Lo, C Le Goues, W Visser, Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering. the 2017 11th Joint Meeting on Foundations of Software EngineeringX.-B. D. Le, D.-H. Chu, D. Lo, C. Le Goues, and W. Visser, \"S3: syntax- and semantic-guided repair synthesis via programming by examples,\" in Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, 2017, pp. 593-604.\n\nAutomatic repair of buggy if conditions and missing preconditions with smt. F Demarco, J Xuan, D Le Berre, M Monperrus, Proceedings of the 6th International Workshop on Constraints in Software Testing, Verification, and Analysis, ser. CSTVA. the 6th International Workshop on Constraints in Software Testing, Verification, and Analysis, ser. CSTVAF. DeMarco, J. Xuan, D. Le Berre, and M. Monperrus, \"Automatic repair of buggy if conditions and missing preconditions with smt,\" in Proceedings of the 6th International Workshop on Constraints in Software Testing, Verification, and Analysis, ser. CSTVA 2014, 2014, p. 30-39.\n\nSketchfix: A tool for automated program repair approach using lazy candidate generation. J Hua, M Zhang, K Wang, S Khurshid, Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ser. ESEC/FSE. the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ser. ESEC/FSEACMJ. Hua, M. Zhang, K. Wang, and S. Khurshid, \"Sketchfix: A tool for automated program repair approach using lazy candidate generation,\" in Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ser. ESEC/FSE 2018. ACM, 2018, p. 888-891.\n\nAstor: A program repair library for java (demo). M Martinez, M Monperrus, Proceedings of the 25th International Symposium on Software Testing and Analysis, ser. ISSTA 2016. the 25th International Symposium on Software Testing and Analysis, ser. ISSTA 2016New York, NY, USAAssociation for Computing MachineryM. Martinez and M. Monperrus, \"Astor: A program repair library for java (demo),\" in Proceedings of the 25th International Symposium on Software Testing and Analysis, ser. ISSTA 2016. New York, NY, USA: Association for Computing Machinery, 2016, p. 441-444.\n\nFixminer: Mining relevant fix patterns for automated program repair. A Koyuncu, K Liu, T F Bissyand\u00e9, D Kim, J Klein, M Monperrus, Y L Traon, Empir. Softw. Eng. 253A. Koyuncu, K. Liu, T. F. Bissyand\u00e9, D. Kim, J. Klein, M. Monperrus, and Y. L. Traon, \"Fixminer: Mining relevant fix patterns for automated program repair,\" Empir. Softw. Eng., vol. 25, no. 3, pp. 1980-2024, 2020.\n\nAVATAR: fixing semantic bugs with fix patterns of static analysis violations. K Liu, A Koyuncu, D Kim, T F Bissyand\u00e9, Proceedings of the 26th IEEE International Conference on Software Analysis, Evolution, and Reengineering. the 26th IEEE International Conference on Software Analysis, Evolution, and ReengineeringIEEEK. Liu, A. Koyuncu, D. Kim, and T. F. Bissyand\u00e9, \"AVATAR: fixing semantic bugs with fix patterns of static analysis violations,\" in Proceed- ings of the 26th IEEE International Conference on Software Analysis, Evolution, and Reengineering. IEEE, 2019, pp. 456-467.\n\nTbar: Revisiting template-based automated program repair. K Liu, A Koyuncu, D Kim, T F Bissyand\u00e9, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2019. the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2019New York, NY, USAACMK. Liu, A. Koyuncu, D. Kim, and T. F. Bissyand\u00e9, \"Tbar: Revisiting template-based automated program repair,\" in Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2019. New York, NY, USA: ACM, 2019, p. 31-42.\n\nPractical program repair via bytecode mutation. A Ghanbari, S Benton, L Zhang, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2019. the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2019ACMA. Ghanbari, S. Benton, and L. Zhang, \"Practical program repair via bytecode mutation,\" in Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2019. ACM, 2019, pp. 19-30.\n\nA syntax-guided edit decoder for neural program repair. Q Zhu, Z Sun, Y Xiao, W Zhang, K Yuan, Y Xiong, L Zhang, Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringNew York, NY, USAACMQ. Zhu, Z. Sun, Y.-a. Xiao, W. Zhang, K. Yuan, Y. Xiong, and L. Zhang, \"A syntax-guided edit decoder for neural program repair,\" in Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. New York, NY, USA: ACM, 2021, p. 341-353.\n\nCure: Code-aware neural machine translation for automatic program repair. N Jiang, T Lutellier, L Tan, 2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE). N. Jiang, T. Lutellier, and L. Tan, \"Cure: Code-aware neural machine translation for automatic program repair,\" 2021 IEEE/ACM 43rd Inter- national Conference on Software Engineering (ICSE), May 2021.\n\nNeural program repair with execution-based backpropagation. H Ye, M Martinez, M Monperrus, 2022 IEEE/ACM 44th International Conference on Software Engineering (ICSE). H. Ye, M. Martinez, and M. Monperrus, \"Neural program repair with execution-based backpropagation,\" in 2022 IEEE/ACM 44th Interna- tional Conference on Software Engineering (ICSE), 2022, pp. 1506- 1518.\n\nCoconut: Combining context-aware neural translation models using ensemble for program repair. T Lutellier, H V Pham, L Pang, Y Li, M Wei, L Tan, Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2020. the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, ser. ISSTA 2020New York, NY, USAAssociation for Computing MachineryT. Lutellier, H. V. Pham, L. Pang, Y. Li, M. Wei, and L. Tan, \"Coconut: Combining context-aware neural translation models using ensemble for program repair,\" in Proceedings of the 29th ACM SIGSOFT Interna- tional Symposium on Software Testing and Analysis, ser. ISSTA 2020. New York, NY, USA: Association for Computing Machinery, 2020, p. 101-114.\n\nSequence to sequence learning with neural networks. I Sutskever, O Vinyals, Q V Le, arXiv:1409.3215I. Sutskever, O. Vinyals, and Q. V. Le, \"Sequence to sequence learning with neural networks,\" 2014, arXiv:1409.3215.\n\nLess training, more repairing please: Revisiting automated program repair via zero-shot learning. C S Xia, L Zhang, arXiv:2207.082812022C. S. Xia and L. Zhang, \"Less training, more repairing please: Revisiting automated program repair via zero-shot learning,\" 2022, arXiv:2207.08281.\n\nLanguage models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, arXiv:2005.141652020T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhari- wal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei, \"Language models are few-shot learners,\" 2020, arXiv:2005.14165.\n\n. M Chen, J Tworek, H Jun, Q Yuan, H P De Oliveira Pinto, J Kaplan, H Edwards, Y Burda, N Joseph, G Brockman, A Ray, R Puri, M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri,\n\n. G Krueger, M Petrov, H Khlaaf, G Sastry, P Mishkin, B Chan, S Gray, N Ryder, M Pavlov, A Power, L Kaiser, M Bavarian, C Winter, P Tillet, F P Such, D Cummings, M Plappert, F Chantzis, E Barnes, A Herbert-Voss, W H Guss, A Nichol, A Paino, N Tezak, J Tang, I Babuschkin, S Balaji, S Jain, W Saunders, C Hesse, A N Carr, J Leike, J Achiam, V Misra, E Morikawa, A Radford, M Knight, M Brundage, M Murati, K Mayer, P Welinder, B Mcgrew, D Amodei, S Mccandlish, I Sutskever, W Zaremba, arXiv:2107.033742021Evaluating large language models trained on codeG. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and W. Zaremba, \"Evaluating large language models trained on code,\" 2021, arXiv:2107.03374.\n\nCodebert: A pre-trained model for programming and natural languages. Z Feng, D Guo, D Tang, N Duan, X Feng, M Gong, L Shou, B Qin, T Liu, D Jiang, M Zhou, arXiv:2002.081552020Z. Feng, D. Guo, D. Tang, N. Duan, X. Feng, M. Gong, L. Shou, B. Qin, T. Liu, D. Jiang, and M. Zhou, \"Codebert: A pre-trained model for programming and natural languages,\" 2020, arXiv:2002.08155.\n\nPatch generation with language models: Feasibility and scaling behavior. S D Kolak, R Martins, C L Goues, V J Hellendoorn, Deep Learning for Code Workshop. S. D. Kolak, R. Martins, C. L. Goues, and V. J. Hellendoorn, \"Patch generation with language models: Feasibility and scaling behavior,\" in Deep Learning for Code Workshop, 2022.\n\nCan openai's codex fix bugs?: An evaluation on quixbugs. J A Prenner, H Babii, R Robbes, IEEE/ACM International Workshop on Automated Program Repair. APRJ. A. Prenner, H. Babii, and R. Robbes, \"Can openai's codex fix bugs?: An evaluation on quixbugs,\" in 2022 IEEE/ACM International Workshop on Automated Program Repair (APR), 2022, pp. 69-75.\n\nIncoder: A generative model for code infilling and synthesis. D Fried, A Aghajanyan, J Lin, S Wang, E Wallace, F Shi, R Zhong, W Yih, L Zettlemoyer, M Lewis, arXiv:2204.059992022D. Fried, A. Aghajanyan, J. Lin, S. Wang, E. Wallace, F. Shi, R. Zhong, W.-t. Yih, L. Zettlemoyer, and M. Lewis, \"Incoder: A generative model for code infilling and synthesis,\" 2022, arXiv:2204.05999.\n\nBleu: A method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W.-J Zhu, Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL '02. the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL '02K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, \"Bleu: A method for automatic evaluation of machine translation,\" in Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ser. ACL '02, 2002, p. 311-318.\n\nFine-tune bert for extractive summarization. Y Liu, arXiv:1903.10318Y. Liu, \"Fine-tune bert for extractive summarization,\" 2019, arXiv:1903.10318.\n\nXlnet: Generalized autoregressive pretraining for language understanding. Z Yang, Z Dai, Y Yang, J Carbonell, R Salakhutdinov, Q V Le, arXiv:1906.082372020Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. Salakhutdinov, and Q. V. Le, \"Xlnet: Generalized autoregressive pretraining for language understand- ing,\" 2020, arXiv:1906.08237.\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, arXiv:1706.03762A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, \"Attention is all you need,\" 2017, arXiv:1706.03762.\n\nPrompt programming for large language models: Beyond the few-shot paradigm. L Reynolds, K Mcdonell, arXiv:2102.073502021L. Reynolds and K. McDonell, \"Prompt programming for large language models: Beyond the few-shot paradigm,\" 2021, arXiv:2102.07350.\n\nScaling laws for neural language models. J Kaplan, S Mccandlish, T Henighan, T B Brown, B Chess, R Child, S Gray, A Radford, J Wu, D Amodei, arXiv:2001.083612020J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, \"Scaling laws for neural language models,\" 2020, arXiv:2001.08361.\n\nBert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, arXiv:1810.04805J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \"Bert: Pre-training of deep bidirectional transformers for language understanding,\" 2018, arXiv:1810.04805.\n\nGPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow. S Black, L Gao, P Wang, C Leahy, S Biderman, 10.5281/zenodo.5297715S. Black, L. Gao, P. Wang, C. Leahy, and S. Biderman, \"GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow,\" Mar. 2021. [Online]. Available: https://doi.org/10.5281/zenodo.5297715\n\nExploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, J. Mach. Learn. Res. C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, \"Exploring the limits of transfer learning with a unified text-to-text transformer,\" J. Mach. Learn. Res., jan 2020.\n\nBart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. M Lewis, Y Liu, N Goyal, M Ghazvininejad, A Mohamed, O Levy, V Stoyanov, L Zettlemoyer, arXiv:1910.13461M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer, \"Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehen- sion,\" 2019, arXiv:1910.13461.\n\nCm3: A causal masked multimodal model of the internet. A Aghajanyan, B Huang, C Ross, V Karpukhin, H Xu, N Goyal, D Okhonko, M Joshi, G Ghosh, M Lewis, L Zettlemoyer, arXiv:2201.07520A. Aghajanyan, B. Huang, C. Ross, V. Karpukhin, H. Xu, N. Goyal, D. Okhonko, M. Joshi, G. Ghosh, M. Lewis, and L. Zettlemoyer, \"Cm3: A causal masked multimodal model of the internet,\" 2022, arXiv:2201.07520.\n\nOn the naturalness of software. A Hindle, E T Barr, Z Su, M Gabel, P Devanbu, Proceedings of the 34th International Conference on Software Engineering, ser. ICSE '12. the 34th International Conference on Software Engineering, ser. ICSE '12A. Hindle, E. T. Barr, Z. Su, M. Gabel, and P. Devanbu, \"On the naturalness of software,\" in Proceedings of the 34th International Conference on Software Engineering, ser. ICSE '12, 2012, p. 837-847.\n\nHugging face. \"Hugging face,\" 2022, https://huggingface.co.\n\nGPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. B Wang, A Komatsuzaki, B. Wang and A. Komatsuzaki, \"GPT-J-6B: A 6 Billion Param- eter Autoregressive Language Model,\" https://github.com/kingoflolz/ mesh-transformer-jax, May 2021.\n\nGPT-NeoX-20B: An open-source autoregressive language model. S Black, S Biderman, E Hallahan, Q Anthony, L Gao, L Golding, H He, C Leahy, K Mcdonell, J Phang, M Pieler, U S Prashanth, S Purohit, L Reynolds, J Tow, B Wang, S Weinbach, arXiv:2204.06745Proceedings of the ACL Workshop on Challenges & Perspectives in Creating Large Language Models. the ACL Workshop on Challenges & Perspectives in Creating Large Language Models2022S. Black, S. Biderman, E. Hallahan, Q. Anthony, L. Gao, L. Golding, H. He, C. Leahy, K. McDonell, J. Phang, M. Pieler, U. S. Prashanth, S. Purohit, L. Reynolds, J. Tow, B. Wang, and S. Weinbach, \"GPT-NeoX- 20B: An open-source autoregressive language model,\" in Proceedings of the ACL Workshop on Challenges & Perspectives in Creating Large Language Models, 2022, arXiv:2204.06745.\n\nThe pile: An 800gb dataset of diverse text for language modeling. L Gao, S Biderman, S Black, L Golding, T Hoppe, C Foster, J Phang, H He, A Thite, N Nabeshima, arXiv:2101.000272020L. Gao, S. Biderman, S. Black, L. Golding, T. Hoppe, C. Foster, J. Phang, H. He, A. Thite, N. Nabeshima et al., \"The pile: An 800gb dataset of diverse text for language modeling,\" 2020, arXiv:2101.00027.\n\nCodet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. S J Yue Wang, Weishi Wang, S C Hoi, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language Processing2021S. J. Yue Wang, Weishi Wang and S. C. Hoi, \"Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation,\" in Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, 2021.\n\nCodesearchnet challenge: Evaluating the state of semantic code search. H Husain, H.-H Wu, T Gazit, M Allamanis, M Brockschmidt, arXiv:1909.094362020H. Husain, H.-H. Wu, T. Gazit, M. Allamanis, and M. Brockschmidt, \"Codesearchnet challenge: Evaluating the state of semantic code search,\" 2020, arXiv:1909.09436.\n\nBigquery github repos. \"Bigquery github repos,\" 2022, https://console.cloud.google.com/ marketplace/details/github/github-repos.\n\nCodex suffix api. \"Codex suffix api,\" https://beta.openai.com/docs/api-reference/ completions/create#completions/create-suffix, 2022.\n\nOn the accuracy of spectrum-based fault localization. R Abreu, P Zoeteweij, A J Van Gemund, Testing: Academic and Industrial Conference Practice and Research Techniques -MUTATION. TAICPART-MUTATIONR. Abreu, P. Zoeteweij, and A. J. van Gemund, \"On the accuracy of spectrum-based fault localization,\" in Testing: Academic and In- dustrial Conference Practice and Research Techniques -MUTATION (TAICPART-MUTATION 2007), 2007, pp. 89-98.\n\nInjecting mechanical faults to localize developer faults for evolving software. L Zhang, L Zhang, S Khurshid, ACM SIGPLAN Notices. 4810L. Zhang, L. Zhang, and S. Khurshid, \"Injecting mechanical faults to localize developer faults for evolving software,\" ACM SIGPLAN Notices, vol. 48, no. 10, pp. 765-784, 2013.\n\nThe curious case of neural text degeneration. A Holtzman, J Buys, L Du, M Forbes, Y Choi, arXiv:1904.09751A. Holtzman, J. Buys, L. Du, M. Forbes, and Y. Choi, \"The curious case of neural text degeneration,\" 2019, arXiv:1904.09751.\n\nAttention: Not just another dataset for patch-correctness checking. Y Wang, J Yang, Y Lou, M Wen, L Zhang, arXiv:2207.065902022Y. Wang, J. Yang, Y. Lou, M. Wen, and L. Zhang, \"Atten- tion: Not just another dataset for patch-correctness checking,\" 2022, arXiv:2207.06590.\n\nPytorch. \"Pytorch,\" 2022, http://pytorch.org.\n\n. Openai, \"Openai api,\" 2022, https://openai.com/api.\n\nCompetitionlevel code generation with alphacode. Y Li, D Choi, J Chung, N Kushman, J Schrittwieser, R Leblond, T Eccles, J Keeling, F Gimeno, A D Lago, T Hubert, P Choy, C D . M. D&apos;autume, I Babuschkin, X Chen, P.-S Huang, J Welbl, S Gowal, A Cherepanov, J Molloy, D J Mankowitz, E S Robson, P Kohli, N Freitas, K Kavukcuoglu, O Vinyals, arXiv:2203.078142022Y. Li, D. Choi, J. Chung, N. Kushman, J. Schrittwieser, R. Leblond, T. Eccles, J. Keeling, F. Gimeno, A. D. Lago, T. Hubert, P. Choy, C. d. M. d'Autume, I. Babuschkin, X. Chen, P.-S. Huang, J. Welbl, S. Gowal, A. Cherepanov, J. Molloy, D. J. Mankowitz, E. S. Robson, P. Kohli, N. de Freitas, K. Kavukcuoglu, and O. Vinyals, \"Competition- level code generation with alphacode,\" 2022, arXiv:2203.07814.\n\nDefects4j: A database of existing faults to enable controlled testing studies for java programs. R Just, D Jalali, M D Ernst, Association for Computing MachineryNew York, NY, USAR. Just, D. Jalali, and M. D. Ernst, \"Defects4j: A database of existing faults to enable controlled testing studies for java programs,\" ser. ISSTA 2014. New York, NY, USA: Association for Computing Machinery, 2014, p. 437-440.\n\nQuixbugs: A multilingual program repair benchmark set based on the quixey challenge,\" ser. SPLASH Companion. D Lin, J Koppel, A Chen, A Solar-Lezama, Association for Computing MachineryNew York, NY, USAD. Lin, J. Koppel, A. Chen, and A. Solar-Lezama, \"Quixbugs: A multi- lingual program repair benchmark set based on the quixey challenge,\" ser. SPLASH Companion 2017. New York, NY, USA: Association for Computing Machinery, 2017, p. 55-56.\n\nThe manybugs and introclass benchmarks for automated repair of c programs. C Le Goues, N Holtschulte, E K Smith, Y Brun, P Devanbu, S Forrest, W Weimer, IEEE Transactions on Software Engineering. 4112C. Le Goues, N. Holtschulte, E. K. Smith, Y. Brun, P. Devanbu, S. Forrest, and W. Weimer, \"The manybugs and introclass benchmarks for automated repair of c programs,\" IEEE Transactions on Software Engineering, vol. 41, no. 12, pp. 1236-1256, 2015.\n\nDeepdebug: Fixing python bugs using stack traces, backtranslation, and code skeletons. D Drain, C B Clement, G Serrato, N Sundaresan, arXiv:2105.093522021D. Drain, C. B. Clement, G. Serrato, and N. Sundaresan, \"Deepdebug: Fixing python bugs using stack traces, backtranslation, and code skele- tons,\" 2021, arXiv:2105.09352.\n\nDlfix: Context-based code transformation learning for automated program repair. Y Li, S Wang, T N Nguyen, Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, ser. ICSE '20. the ACM/IEEE 42nd International Conference on Software Engineering, ser. ICSE '20New York, NY, USAAssociation for Computing MachineryY. Li, S. Wang, and T. N. Nguyen, \"Dlfix: Context-based code transfor- mation learning for automated program repair,\" in Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering, ser. ICSE '20. New York, NY, USA: Association for Computing Machinery, 2020, p. 602-614.\n\nSequencer: Sequence-to-sequence learning for end-toend program repair. Z Chen, S Kommrusch, M Tufano, L.-N Pouchet, D Poshyvanyk, M Monperrus, IEEE Transaction on Software Engineering. Z. Chen, S. Kommrusch, M. Tufano, L.-N. Pouchet, D. Poshyvanyk, and M. Monperrus, \"Sequencer: Sequence-to-sequence learning for end-to- end program repair,\" IEEE Transaction on Software Engineering, 2019.\n\nShaping program repair space with existing patches and similar code. J Jiang, Y Xiong, H Zhang, Q Gao, X Chen, Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis. F. Tip and E. Boddenthe 27th ACM SIGSOFT International Symposium on Software Testing and AnalysisAmsterdam, The NetherlandsACMJ. Jiang, Y. Xiong, H. Zhang, Q. Gao, and X. Chen, \"Shaping program repair space with existing patches and similar code,\" in Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2018, Amsterdam, The Netherlands, July 16-21, 2018, F. Tip and E. Bodden, Eds. ACM, 2018, pp. 298-309.\n\nContract-based program repair without the contracts. L Chen, Y Pei, C A Furia, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE. L. Chen, Y. Pei, and C. A. Furia, \"Contract-based program repair without the contracts,\" in 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE), 2017, pp. 637-647.\n\nAutomatic repair of real bugs: An experience report on the defects4j dataset. M Martinez, T Durieux, J Xuan, R Sommerard, M Monperrus, arXiv:1505.07002M. Martinez, T. Durieux, J. Xuan, R. Sommerard, and M. Monperrus, \"Automatic repair of real bugs: An experience report on the defects4j dataset,\" 2015, arXiv:1505.07002.\n\nAn empirical investigation into learning bug-fixing patches in the wild via neural machine translation. M Tufano, C Watson, G Bavota, M Di Penta, M White, D Poshyvanyk, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. the 33rd ACM/IEEE International Conference on Automated Software EngineeringM. Tufano, C. Watson, G. Bavota, M. Di Penta, M. White, and D. Poshyvanyk, \"An empirical investigation into learning bug-fixing patches in the wild via neural machine translation,\" in Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, 2018, p. 832-837.\n\nGroza object comparison code. teiid object comparison code,\" 2022\"teiid object comparison code,\" 2022, https://github.com/teiid/teiid/blob/ 21c93a6fd4be2528f95224f99905d74479862d1b/federate-common-core/ src/main/java/com/metamatrix/core/util/EquivalenceUtil.java#L49-L57. [71] \"Groza object comparison code,\" 2022, https://github.com/IoT-Technology/Groza/blob/ fbafceef53d646025046990ffbd89bf701c56b45/dao/src/main/java/ com/sanshengshui/server/dao/util/mapping/JsonTypeDescriptor.java# L49-L58.\n\nImpact analysis of syntactic and semantic similarities on patch prioritization in automated program repair. M Asad, K K Ganguly, K Sakib, 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME). M. Asad, K. K. Ganguly, and K. Sakib, \"Impact analysis of syntactic and semantic similarities on patch prioritization in automated program re- pair,\" in 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME), 2019, pp. 328-332.\n\nLeveraging syntax-related code for automated program repair. Q Xin, S P Reiss, 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEEQ. Xin and S. P. Reiss, \"Leveraging syntax-related code for automated program repair,\" in 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2017, pp. 660-670.\n\nDataset. \"Dataset,\" 2022, https://figshare.com/s/temp.\n", "annotations": {"author": "[{\"end\":248,\"start\":76},{\"end\":392,\"start\":249},{\"end\":561,\"start\":393}]", "publisher": null, "author_last_name": "[{\"end\":94,\"start\":91},{\"end\":260,\"start\":257},{\"end\":407,\"start\":402}]", "author_first_name": "[{\"end\":83,\"start\":76},{\"end\":90,\"start\":84},{\"end\":256,\"start\":249},{\"end\":401,\"start\":393}]", "author_affiliation": "[{\"end\":247,\"start\":118},{\"end\":391,\"start\":262},{\"end\":560,\"start\":431}]", "title": "[{\"end\":73,\"start\":1},{\"end\":634,\"start\":562}]", "venue": null, "abstract": "[{\"end\":2966,\"start\":636}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3171,\"start\":3168},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3193,\"start\":3190},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3255,\"start\":3252},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3280,\"start\":3277},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3386,\"start\":3383},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3576,\"start\":3573},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3615,\"start\":3612},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3621,\"start\":3617},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3697,\"start\":3693},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3703,\"start\":3699},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4016,\"start\":4012},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4022,\"start\":4018},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4111,\"start\":4107},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4713,\"start\":4709},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4719,\"start\":4715},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4870,\"start\":4866},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5131,\"start\":5127},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5224,\"start\":5220},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5442,\"start\":5438},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5477,\"start\":5473},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6263,\"start\":6259},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6269,\"start\":6265},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6530,\"start\":6526},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6547,\"start\":6543},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6761,\"start\":6757},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7949,\"start\":7945},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7955,\"start\":7951},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7961,\"start\":7957},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10128,\"start\":10124},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10153,\"start\":10149},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10177,\"start\":10173},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10224,\"start\":10220},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10671,\"start\":10667},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11034,\"start\":11030},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11121,\"start\":11117},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11273,\"start\":11269},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11711,\"start\":11707},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11728,\"start\":11724},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":11964,\"start\":11960},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11978,\"start\":11974},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":12631,\"start\":12627},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13254,\"start\":13251},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13259,\"start\":13256},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":13288,\"start\":13284},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13311,\"start\":13307},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13317,\"start\":13313},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13735,\"start\":13731},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13754,\"start\":13750},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13769,\"start\":13765},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13802,\"start\":13798},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14075,\"start\":14071},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14639,\"start\":14635},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14645,\"start\":14641},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14718,\"start\":14714},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15273,\"start\":15269},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":15451,\"start\":15447},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":15715,\"start\":15711},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15893,\"start\":15889},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":15899,\"start\":15895},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":16906,\"start\":16902},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":17299,\"start\":17295},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":17842,\"start\":17838},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":17854,\"start\":17850},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":17869,\"start\":17865},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":17961,\"start\":17957},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18156,\"start\":18152},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":18824,\"start\":18820},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":18830,\"start\":18826},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":20165,\"start\":20161},{\"end\":21990,\"start\":21981},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":23043,\"start\":23039},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":23570,\"start\":23566},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24367,\"start\":24363},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24373,\"start\":24369},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24492,\"start\":24488},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":25116,\"start\":25112},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":25209,\"start\":25205},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":25229,\"start\":25225},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":25461,\"start\":25457},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":25830,\"start\":25826},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":25881,\"start\":25877},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":26009,\"start\":26005},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":26147,\"start\":26143},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26236,\"start\":26232},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":26242,\"start\":26238},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26248,\"start\":26244},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":26618,\"start\":26614},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26624,\"start\":26620},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":26630,\"start\":26626},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":26636,\"start\":26632},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":27178,\"start\":27174},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":27750,\"start\":27746},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":28146,\"start\":28142},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":28733,\"start\":28729},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":28753,\"start\":28749},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":28767,\"start\":28763},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":28783,\"start\":28779},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":28794,\"start\":28790},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28808,\"start\":28804},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":28820,\"start\":28816},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":28839,\"start\":28835},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29098,\"start\":29094},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29110,\"start\":29106},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":29123,\"start\":29119},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":29136,\"start\":29132},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":29151,\"start\":29147},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29163,\"start\":29160},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":29174,\"start\":29170},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":29190,\"start\":29186},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":29202,\"start\":29198},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":29217,\"start\":29213},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29234,\"start\":29230},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29250,\"start\":29246},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":29613,\"start\":29609},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":29619,\"start\":29615},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":29625,\"start\":29621},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":29631,\"start\":29627},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29750,\"start\":29746},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":29756,\"start\":29752},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29826,\"start\":29822},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29832,\"start\":29828},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":29838,\"start\":29834},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":30615,\"start\":30611},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":37136,\"start\":37132},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37142,\"start\":37138},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":37148,\"start\":37144},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37616,\"start\":37612},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":37622,\"start\":37618},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":37628,\"start\":37624},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":38467,\"start\":38463},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":42382,\"start\":42378},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":43998,\"start\":43994},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":44004,\"start\":44000},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":44010,\"start\":44006},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":44839,\"start\":44835},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":44845,\"start\":44841},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":44944,\"start\":44940},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":46047,\"start\":46043},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":50278,\"start\":50274}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":49636,\"start\":49589},{\"attributes\":{\"id\":\"fig_1\"},\"end\":49699,\"start\":49637},{\"attributes\":{\"id\":\"fig_2\"},\"end\":49745,\"start\":49700},{\"attributes\":{\"id\":\"fig_3\"},\"end\":49840,\"start\":49746},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":50175,\"start\":49841},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":51988,\"start\":50176},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":53166,\"start\":51989},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":53772,\"start\":53167},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":54186,\"start\":53773},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":54521,\"start\":54187},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":55196,\"start\":54522},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":55564,\"start\":55197},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":56017,\"start\":55565},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":57107,\"start\":56018},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":57943,\"start\":57108},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":58280,\"start\":57944},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":59030,\"start\":58281}]", "paragraph": "[{\"end\":3577,\"start\":2985},{\"end\":4871,\"start\":3579},{\"end\":6480,\"start\":4873},{\"end\":7009,\"start\":6482},{\"end\":8169,\"start\":7011},{\"end\":8954,\"start\":8171},{\"end\":9250,\"start\":8956},{\"end\":9891,\"start\":9252},{\"end\":11122,\"start\":9963},{\"end\":12819,\"start\":11124},{\"end\":13191,\"start\":12851},{\"end\":14621,\"start\":13193},{\"end\":16291,\"start\":14623},{\"end\":16735,\"start\":16309},{\"end\":17217,\"start\":16749},{\"end\":17455,\"start\":17219},{\"end\":17803,\"start\":17457},{\"end\":17826,\"start\":17805},{\"end\":18158,\"start\":17828},{\"end\":18357,\"start\":18197},{\"end\":18521,\"start\":18359},{\"end\":21059,\"start\":18523},{\"end\":22248,\"start\":21061},{\"end\":23339,\"start\":22250},{\"end\":24374,\"start\":23375},{\"end\":24805,\"start\":24376},{\"end\":25649,\"start\":24882},{\"end\":25743,\"start\":25700},{\"end\":26249,\"start\":25765},{\"end\":26402,\"start\":26251},{\"end\":27147,\"start\":26425},{\"end\":27715,\"start\":27149},{\"end\":28128,\"start\":27717},{\"end\":28539,\"start\":28130},{\"end\":29839,\"start\":28566},{\"end\":30212,\"start\":29865},{\"end\":31280,\"start\":30226},{\"end\":34959,\"start\":31282},{\"end\":36270,\"start\":35001},{\"end\":36393,\"start\":36272},{\"end\":37287,\"start\":36395},{\"end\":38983,\"start\":37289},{\"end\":40377,\"start\":38985},{\"end\":41326,\"start\":40379},{\"end\":42843,\"start\":41328},{\"end\":44061,\"start\":42845},{\"end\":45727,\"start\":44104},{\"end\":46048,\"start\":45755},{\"end\":47273,\"start\":46050},{\"end\":48579,\"start\":47275},{\"end\":49588,\"start\":48599}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18164,\"start\":18159},{\"attributes\":{\"id\":\"formula_1\"},\"end\":24881,\"start\":24806}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":17522,\"start\":17515},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":26738,\"start\":26730},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":32679,\"start\":32672},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":33922,\"start\":33914},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":36619,\"start\":36610},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":40592,\"start\":40582},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":41569,\"start\":41561},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":47015,\"start\":47005}]", "section_header": "[{\"end\":2983,\"start\":2968},{\"end\":9961,\"start\":9894},{\"end\":12849,\"start\":12822},{\"end\":16307,\"start\":16294},{\"end\":16747,\"start\":16738},{\"end\":18195,\"start\":18166},{\"end\":23373,\"start\":23342},{\"end\":25674,\"start\":25652},{\"end\":25698,\"start\":25677},{\"end\":25763,\"start\":25746},{\"end\":26423,\"start\":26405},{\"end\":28564,\"start\":28542},{\"end\":29863,\"start\":29842},{\"end\":30224,\"start\":30215},{\"end\":34999,\"start\":34962},{\"end\":44102,\"start\":44064},{\"end\":45753,\"start\":45730},{\"end\":48597,\"start\":48582},{\"end\":49598,\"start\":49590},{\"end\":49646,\"start\":49638},{\"end\":49709,\"start\":49701},{\"end\":49755,\"start\":49747},{\"end\":49851,\"start\":49842},{\"end\":51997,\"start\":51990},{\"end\":53178,\"start\":53168},{\"end\":53785,\"start\":53774},{\"end\":54198,\"start\":54188},{\"end\":54532,\"start\":54523},{\"end\":55208,\"start\":55198},{\"end\":55577,\"start\":55566},{\"end\":56031,\"start\":56019},{\"end\":57119,\"start\":57109},{\"end\":57954,\"start\":57945},{\"end\":58289,\"start\":58282}]", "table": "[{\"end\":50175,\"start\":49876},{\"end\":51988,\"start\":50391},{\"end\":53166,\"start\":52956},{\"end\":53772,\"start\":53210},{\"end\":54186,\"start\":53810},{\"end\":54521,\"start\":54227},{\"end\":55196,\"start\":54549},{\"end\":55564,\"start\":55246},{\"end\":56017,\"start\":55581},{\"end\":57107,\"start\":56066},{\"end\":57943,\"start\":57155},{\"end\":58280,\"start\":57997}]", "figure_caption": "[{\"end\":49636,\"start\":49600},{\"end\":49699,\"start\":49648},{\"end\":49745,\"start\":49711},{\"end\":49840,\"start\":49757},{\"end\":49876,\"start\":49853},{\"end\":50391,\"start\":50178},{\"end\":52956,\"start\":52001},{\"end\":53210,\"start\":53181},{\"end\":53810,\"start\":53789},{\"end\":54227,\"start\":54201},{\"end\":54549,\"start\":54534},{\"end\":55246,\"start\":55211},{\"end\":56066,\"start\":56036},{\"end\":57155,\"start\":57122},{\"end\":57997,\"start\":57956},{\"end\":59030,\"start\":58291}]", "figure_ref": "[{\"end\":19909,\"start\":19901},{\"end\":20555,\"start\":20547},{\"end\":21688,\"start\":21680},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22392,\"start\":22383},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22659,\"start\":22650},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":35101,\"start\":35093},{\"end\":38078,\"start\":38070},{\"end\":38710,\"start\":38701},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39080,\"start\":39071},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39482,\"start\":39473},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":43084,\"start\":43076},{\"end\":47151,\"start\":47142}]", "bib_author_first_name": "[{\"end\":59119,\"start\":59118},{\"end\":59382,\"start\":59381},{\"end\":59628,\"start\":59627},{\"end\":59934,\"start\":59933},{\"end\":60206,\"start\":60205},{\"end\":60208,\"start\":60207},{\"end\":60363,\"start\":60362},{\"end\":60374,\"start\":60373},{\"end\":60385,\"start\":60384},{\"end\":60655,\"start\":60654},{\"end\":60658,\"start\":60656},{\"end\":60667,\"start\":60666},{\"end\":60677,\"start\":60676},{\"end\":60688,\"start\":60687},{\"end\":60962,\"start\":60961},{\"end\":60966,\"start\":60963},{\"end\":60972,\"start\":60971},{\"end\":60978,\"start\":60977},{\"end\":60981,\"start\":60979},{\"end\":61360,\"start\":61359},{\"end\":61367,\"start\":61366},{\"end\":61375,\"start\":61374},{\"end\":61381,\"start\":61380},{\"end\":61391,\"start\":61387},{\"end\":61865,\"start\":61864},{\"end\":61877,\"start\":61876},{\"end\":61883,\"start\":61882},{\"end\":62368,\"start\":62364},{\"end\":62370,\"start\":62369},{\"end\":62379,\"start\":62375},{\"end\":62386,\"start\":62385},{\"end\":62392,\"start\":62391},{\"end\":62395,\"start\":62393},{\"end\":62404,\"start\":62403},{\"end\":62884,\"start\":62883},{\"end\":62895,\"start\":62894},{\"end\":62903,\"start\":62902},{\"end\":62906,\"start\":62904},{\"end\":62915,\"start\":62914},{\"end\":63521,\"start\":63520},{\"end\":63528,\"start\":63527},{\"end\":63537,\"start\":63536},{\"end\":63545,\"start\":63544},{\"end\":64251,\"start\":64250},{\"end\":64263,\"start\":64262},{\"end\":64836,\"start\":64835},{\"end\":64847,\"start\":64846},{\"end\":64854,\"start\":64853},{\"end\":64856,\"start\":64855},{\"end\":64869,\"start\":64868},{\"end\":64876,\"start\":64875},{\"end\":64885,\"start\":64884},{\"end\":64898,\"start\":64897},{\"end\":64900,\"start\":64899},{\"end\":65224,\"start\":65223},{\"end\":65231,\"start\":65230},{\"end\":65242,\"start\":65241},{\"end\":65249,\"start\":65248},{\"end\":65251,\"start\":65250},{\"end\":65787,\"start\":65786},{\"end\":65794,\"start\":65793},{\"end\":65805,\"start\":65804},{\"end\":65812,\"start\":65811},{\"end\":65814,\"start\":65813},{\"end\":66364,\"start\":66363},{\"end\":66376,\"start\":66375},{\"end\":66386,\"start\":66385},{\"end\":66884,\"start\":66883},{\"end\":66891,\"start\":66890},{\"end\":66898,\"start\":66897},{\"end\":66906,\"start\":66905},{\"end\":66915,\"start\":66914},{\"end\":66923,\"start\":66922},{\"end\":66932,\"start\":66931},{\"end\":67625,\"start\":67624},{\"end\":67634,\"start\":67633},{\"end\":67647,\"start\":67646},{\"end\":67991,\"start\":67990},{\"end\":67997,\"start\":67996},{\"end\":68009,\"start\":68008},{\"end\":68396,\"start\":68395},{\"end\":68409,\"start\":68408},{\"end\":68411,\"start\":68410},{\"end\":68419,\"start\":68418},{\"end\":68427,\"start\":68426},{\"end\":68433,\"start\":68432},{\"end\":68440,\"start\":68439},{\"end\":69105,\"start\":69104},{\"end\":69118,\"start\":69117},{\"end\":69129,\"start\":69128},{\"end\":69131,\"start\":69130},{\"end\":69368,\"start\":69367},{\"end\":69370,\"start\":69369},{\"end\":69377,\"start\":69376},{\"end\":69594,\"start\":69593},{\"end\":69596,\"start\":69595},{\"end\":69605,\"start\":69604},{\"end\":69613,\"start\":69612},{\"end\":69622,\"start\":69621},{\"end\":69633,\"start\":69632},{\"end\":69643,\"start\":69642},{\"end\":69655,\"start\":69654},{\"end\":69670,\"start\":69669},{\"end\":69679,\"start\":69678},{\"end\":69689,\"start\":69688},{\"end\":69699,\"start\":69698},{\"end\":69710,\"start\":69709},{\"end\":69726,\"start\":69725},{\"end\":69737,\"start\":69736},{\"end\":69749,\"start\":69748},{\"end\":69758,\"start\":69757},{\"end\":69768,\"start\":69767},{\"end\":69770,\"start\":69769},{\"end\":69781,\"start\":69780},{\"end\":69787,\"start\":69786},{\"end\":69797,\"start\":69796},{\"end\":69806,\"start\":69805},{\"end\":69814,\"start\":69813},{\"end\":69824,\"start\":69823},{\"end\":69834,\"start\":69833},{\"end\":69842,\"start\":69841},{\"end\":69851,\"start\":69850},{\"end\":69860,\"start\":69859},{\"end\":69870,\"start\":69869},{\"end\":69884,\"start\":69883},{\"end\":69895,\"start\":69894},{\"end\":69908,\"start\":69907},{\"end\":70369,\"start\":70368},{\"end\":70377,\"start\":70376},{\"end\":70387,\"start\":70386},{\"end\":70394,\"start\":70393},{\"end\":70402,\"start\":70401},{\"end\":70404,\"start\":70403},{\"end\":70425,\"start\":70424},{\"end\":70435,\"start\":70434},{\"end\":70446,\"start\":70445},{\"end\":70455,\"start\":70454},{\"end\":70465,\"start\":70464},{\"end\":70477,\"start\":70476},{\"end\":70484,\"start\":70483},{\"end\":70631,\"start\":70630},{\"end\":70642,\"start\":70641},{\"end\":70652,\"start\":70651},{\"end\":70662,\"start\":70661},{\"end\":70672,\"start\":70671},{\"end\":70683,\"start\":70682},{\"end\":70691,\"start\":70690},{\"end\":70699,\"start\":70698},{\"end\":70708,\"start\":70707},{\"end\":70718,\"start\":70717},{\"end\":70727,\"start\":70726},{\"end\":70737,\"start\":70736},{\"end\":70749,\"start\":70748},{\"end\":70759,\"start\":70758},{\"end\":70769,\"start\":70768},{\"end\":70771,\"start\":70770},{\"end\":70779,\"start\":70778},{\"end\":70791,\"start\":70790},{\"end\":70803,\"start\":70802},{\"end\":70815,\"start\":70814},{\"end\":70825,\"start\":70824},{\"end\":70841,\"start\":70840},{\"end\":70843,\"start\":70842},{\"end\":70851,\"start\":70850},{\"end\":70861,\"start\":70860},{\"end\":70870,\"start\":70869},{\"end\":70879,\"start\":70878},{\"end\":70887,\"start\":70886},{\"end\":70901,\"start\":70900},{\"end\":70911,\"start\":70910},{\"end\":70919,\"start\":70918},{\"end\":70931,\"start\":70930},{\"end\":70940,\"start\":70939},{\"end\":70942,\"start\":70941},{\"end\":70950,\"start\":70949},{\"end\":70959,\"start\":70958},{\"end\":70969,\"start\":70968},{\"end\":70978,\"start\":70977},{\"end\":70990,\"start\":70989},{\"end\":71001,\"start\":71000},{\"end\":71011,\"start\":71010},{\"end\":71023,\"start\":71022},{\"end\":71033,\"start\":71032},{\"end\":71042,\"start\":71041},{\"end\":71054,\"start\":71053},{\"end\":71064,\"start\":71063},{\"end\":71074,\"start\":71073},{\"end\":71088,\"start\":71087},{\"end\":71101,\"start\":71100},{\"end\":71860,\"start\":71859},{\"end\":71868,\"start\":71867},{\"end\":71875,\"start\":71874},{\"end\":71883,\"start\":71882},{\"end\":71891,\"start\":71890},{\"end\":71899,\"start\":71898},{\"end\":71907,\"start\":71906},{\"end\":71915,\"start\":71914},{\"end\":71922,\"start\":71921},{\"end\":71929,\"start\":71928},{\"end\":71938,\"start\":71937},{\"end\":72236,\"start\":72235},{\"end\":72238,\"start\":72237},{\"end\":72247,\"start\":72246},{\"end\":72258,\"start\":72257},{\"end\":72260,\"start\":72259},{\"end\":72269,\"start\":72268},{\"end\":72271,\"start\":72270},{\"end\":72555,\"start\":72554},{\"end\":72557,\"start\":72556},{\"end\":72568,\"start\":72567},{\"end\":72577,\"start\":72576},{\"end\":72905,\"start\":72904},{\"end\":72914,\"start\":72913},{\"end\":72928,\"start\":72927},{\"end\":72935,\"start\":72934},{\"end\":72943,\"start\":72942},{\"end\":72954,\"start\":72953},{\"end\":72961,\"start\":72960},{\"end\":72970,\"start\":72969},{\"end\":72977,\"start\":72976},{\"end\":72992,\"start\":72991},{\"end\":73287,\"start\":73286},{\"end\":73299,\"start\":73298},{\"end\":73309,\"start\":73308},{\"end\":73320,\"start\":73316},{\"end\":73788,\"start\":73787},{\"end\":73965,\"start\":73964},{\"end\":73973,\"start\":73972},{\"end\":73980,\"start\":73979},{\"end\":73988,\"start\":73987},{\"end\":74001,\"start\":74000},{\"end\":74018,\"start\":74017},{\"end\":74020,\"start\":74019},{\"end\":74248,\"start\":74247},{\"end\":74259,\"start\":74258},{\"end\":74270,\"start\":74269},{\"end\":74280,\"start\":74279},{\"end\":74293,\"start\":74292},{\"end\":74302,\"start\":74301},{\"end\":74304,\"start\":74303},{\"end\":74313,\"start\":74312},{\"end\":74323,\"start\":74322},{\"end\":74585,\"start\":74584},{\"end\":74597,\"start\":74596},{\"end\":74802,\"start\":74801},{\"end\":74812,\"start\":74811},{\"end\":74826,\"start\":74825},{\"end\":74838,\"start\":74837},{\"end\":74840,\"start\":74839},{\"end\":74849,\"start\":74848},{\"end\":74858,\"start\":74857},{\"end\":74867,\"start\":74866},{\"end\":74875,\"start\":74874},{\"end\":74886,\"start\":74885},{\"end\":74892,\"start\":74891},{\"end\":75187,\"start\":75186},{\"end\":75200,\"start\":75196},{\"end\":75209,\"start\":75208},{\"end\":75216,\"start\":75215},{\"end\":75480,\"start\":75479},{\"end\":75489,\"start\":75488},{\"end\":75496,\"start\":75495},{\"end\":75504,\"start\":75503},{\"end\":75513,\"start\":75512},{\"end\":75834,\"start\":75833},{\"end\":75844,\"start\":75843},{\"end\":75855,\"start\":75854},{\"end\":75866,\"start\":75865},{\"end\":75873,\"start\":75872},{\"end\":75883,\"start\":75882},{\"end\":75893,\"start\":75892},{\"end\":75901,\"start\":75900},{\"end\":75907,\"start\":75906},{\"end\":75909,\"start\":75908},{\"end\":76266,\"start\":76265},{\"end\":76275,\"start\":76274},{\"end\":76282,\"start\":76281},{\"end\":76291,\"start\":76290},{\"end\":76308,\"start\":76307},{\"end\":76319,\"start\":76318},{\"end\":76327,\"start\":76326},{\"end\":76339,\"start\":76338},{\"end\":76669,\"start\":76668},{\"end\":76683,\"start\":76682},{\"end\":76692,\"start\":76691},{\"end\":76700,\"start\":76699},{\"end\":76713,\"start\":76712},{\"end\":76719,\"start\":76718},{\"end\":76728,\"start\":76727},{\"end\":76739,\"start\":76738},{\"end\":76748,\"start\":76747},{\"end\":76757,\"start\":76756},{\"end\":76766,\"start\":76765},{\"end\":77038,\"start\":77037},{\"end\":77048,\"start\":77047},{\"end\":77050,\"start\":77049},{\"end\":77058,\"start\":77057},{\"end\":77064,\"start\":77063},{\"end\":77073,\"start\":77072},{\"end\":77570,\"start\":77569},{\"end\":77578,\"start\":77577},{\"end\":77812,\"start\":77811},{\"end\":77821,\"start\":77820},{\"end\":77833,\"start\":77832},{\"end\":77845,\"start\":77844},{\"end\":77856,\"start\":77855},{\"end\":77863,\"start\":77862},{\"end\":77874,\"start\":77873},{\"end\":77880,\"start\":77879},{\"end\":77889,\"start\":77888},{\"end\":77901,\"start\":77900},{\"end\":77910,\"start\":77909},{\"end\":77920,\"start\":77919},{\"end\":77922,\"start\":77921},{\"end\":77935,\"start\":77934},{\"end\":77946,\"start\":77945},{\"end\":77958,\"start\":77957},{\"end\":77965,\"start\":77964},{\"end\":77973,\"start\":77972},{\"end\":78628,\"start\":78627},{\"end\":78635,\"start\":78634},{\"end\":78647,\"start\":78646},{\"end\":78656,\"start\":78655},{\"end\":78667,\"start\":78666},{\"end\":78676,\"start\":78675},{\"end\":78686,\"start\":78685},{\"end\":78695,\"start\":78694},{\"end\":78701,\"start\":78700},{\"end\":78710,\"start\":78709},{\"end\":79055,\"start\":79054},{\"end\":79057,\"start\":79056},{\"end\":79074,\"start\":79068},{\"end\":79082,\"start\":79081},{\"end\":79084,\"start\":79083},{\"end\":79587,\"start\":79586},{\"end\":79600,\"start\":79596},{\"end\":79606,\"start\":79605},{\"end\":79615,\"start\":79614},{\"end\":79628,\"start\":79627},{\"end\":80147,\"start\":80146},{\"end\":80156,\"start\":80155},{\"end\":80169,\"start\":80168},{\"end\":80171,\"start\":80170},{\"end\":80608,\"start\":80607},{\"end\":80617,\"start\":80616},{\"end\":80626,\"start\":80625},{\"end\":80886,\"start\":80885},{\"end\":80898,\"start\":80897},{\"end\":80906,\"start\":80905},{\"end\":80912,\"start\":80911},{\"end\":80922,\"start\":80921},{\"end\":81140,\"start\":81139},{\"end\":81148,\"start\":81147},{\"end\":81156,\"start\":81155},{\"end\":81163,\"start\":81162},{\"end\":81170,\"start\":81169},{\"end\":81495,\"start\":81494},{\"end\":81501,\"start\":81500},{\"end\":81509,\"start\":81508},{\"end\":81518,\"start\":81517},{\"end\":81529,\"start\":81528},{\"end\":81546,\"start\":81545},{\"end\":81557,\"start\":81556},{\"end\":81567,\"start\":81566},{\"end\":81578,\"start\":81577},{\"end\":81588,\"start\":81587},{\"end\":81590,\"start\":81589},{\"end\":81598,\"start\":81597},{\"end\":81608,\"start\":81607},{\"end\":81616,\"start\":81615},{\"end\":81618,\"start\":81617},{\"end\":81640,\"start\":81639},{\"end\":81654,\"start\":81653},{\"end\":81665,\"start\":81661},{\"end\":81674,\"start\":81673},{\"end\":81683,\"start\":81682},{\"end\":81692,\"start\":81691},{\"end\":81706,\"start\":81705},{\"end\":81716,\"start\":81715},{\"end\":81718,\"start\":81717},{\"end\":81731,\"start\":81730},{\"end\":81733,\"start\":81732},{\"end\":81743,\"start\":81742},{\"end\":81752,\"start\":81751},{\"end\":81763,\"start\":81762},{\"end\":81778,\"start\":81777},{\"end\":82308,\"start\":82307},{\"end\":82316,\"start\":82315},{\"end\":82326,\"start\":82325},{\"end\":82328,\"start\":82327},{\"end\":82726,\"start\":82725},{\"end\":82733,\"start\":82732},{\"end\":82743,\"start\":82742},{\"end\":82751,\"start\":82750},{\"end\":83133,\"start\":83132},{\"end\":83136,\"start\":83134},{\"end\":83145,\"start\":83144},{\"end\":83160,\"start\":83159},{\"end\":83162,\"start\":83161},{\"end\":83171,\"start\":83170},{\"end\":83179,\"start\":83178},{\"end\":83190,\"start\":83189},{\"end\":83201,\"start\":83200},{\"end\":83594,\"start\":83593},{\"end\":83603,\"start\":83602},{\"end\":83605,\"start\":83604},{\"end\":83616,\"start\":83615},{\"end\":83627,\"start\":83626},{\"end\":83913,\"start\":83912},{\"end\":83919,\"start\":83918},{\"end\":83927,\"start\":83926},{\"end\":83929,\"start\":83928},{\"end\":84535,\"start\":84534},{\"end\":84543,\"start\":84542},{\"end\":84556,\"start\":84555},{\"end\":84569,\"start\":84565},{\"end\":84580,\"start\":84579},{\"end\":84594,\"start\":84593},{\"end\":84924,\"start\":84923},{\"end\":84933,\"start\":84932},{\"end\":84942,\"start\":84941},{\"end\":84951,\"start\":84950},{\"end\":84958,\"start\":84957},{\"end\":85568,\"start\":85567},{\"end\":85576,\"start\":85575},{\"end\":85583,\"start\":85582},{\"end\":85585,\"start\":85584},{\"end\":85953,\"start\":85952},{\"end\":85965,\"start\":85964},{\"end\":85976,\"start\":85975},{\"end\":85984,\"start\":85983},{\"end\":85997,\"start\":85996},{\"end\":86301,\"start\":86300},{\"end\":86311,\"start\":86310},{\"end\":86321,\"start\":86320},{\"end\":86331,\"start\":86330},{\"end\":86334,\"start\":86332},{\"end\":86343,\"start\":86342},{\"end\":86352,\"start\":86351},{\"end\":87436,\"start\":87435},{\"end\":87444,\"start\":87443},{\"end\":87446,\"start\":87445},{\"end\":87457,\"start\":87456},{\"end\":87864,\"start\":87863},{\"end\":87871,\"start\":87870},{\"end\":87873,\"start\":87872}]", "bib_author_last_name": "[{\"end\":59127,\"start\":59120},{\"end\":59392,\"start\":59383},{\"end\":59637,\"start\":59629},{\"end\":59943,\"start\":59935},{\"end\":60220,\"start\":60209},{\"end\":60371,\"start\":60364},{\"end\":60382,\"start\":60375},{\"end\":60393,\"start\":60386},{\"end\":60664,\"start\":60659},{\"end\":60674,\"start\":60668},{\"end\":60685,\"start\":60678},{\"end\":60695,\"start\":60689},{\"end\":60969,\"start\":60967},{\"end\":60975,\"start\":60973},{\"end\":60987,\"start\":60982},{\"end\":61364,\"start\":61361},{\"end\":61372,\"start\":61368},{\"end\":61378,\"start\":61376},{\"end\":61385,\"start\":61382},{\"end\":61398,\"start\":61392},{\"end\":61874,\"start\":61866},{\"end\":61880,\"start\":61878},{\"end\":61896,\"start\":61884},{\"end\":62373,\"start\":62371},{\"end\":62383,\"start\":62380},{\"end\":62389,\"start\":62387},{\"end\":62401,\"start\":62396},{\"end\":62411,\"start\":62405},{\"end\":62892,\"start\":62885},{\"end\":62900,\"start\":62896},{\"end\":62912,\"start\":62907},{\"end\":62925,\"start\":62916},{\"end\":63525,\"start\":63522},{\"end\":63534,\"start\":63529},{\"end\":63542,\"start\":63538},{\"end\":63554,\"start\":63546},{\"end\":64260,\"start\":64252},{\"end\":64273,\"start\":64264},{\"end\":64844,\"start\":64837},{\"end\":64851,\"start\":64848},{\"end\":64866,\"start\":64857},{\"end\":64873,\"start\":64870},{\"end\":64882,\"start\":64877},{\"end\":64895,\"start\":64886},{\"end\":64906,\"start\":64901},{\"end\":65228,\"start\":65225},{\"end\":65239,\"start\":65232},{\"end\":65246,\"start\":65243},{\"end\":65261,\"start\":65252},{\"end\":65791,\"start\":65788},{\"end\":65802,\"start\":65795},{\"end\":65809,\"start\":65806},{\"end\":65824,\"start\":65815},{\"end\":66373,\"start\":66365},{\"end\":66383,\"start\":66377},{\"end\":66392,\"start\":66387},{\"end\":66888,\"start\":66885},{\"end\":66895,\"start\":66892},{\"end\":66903,\"start\":66899},{\"end\":66912,\"start\":66907},{\"end\":66920,\"start\":66916},{\"end\":66929,\"start\":66924},{\"end\":66938,\"start\":66933},{\"end\":67631,\"start\":67626},{\"end\":67644,\"start\":67635},{\"end\":67651,\"start\":67648},{\"end\":67994,\"start\":67992},{\"end\":68006,\"start\":67998},{\"end\":68019,\"start\":68010},{\"end\":68406,\"start\":68397},{\"end\":68416,\"start\":68412},{\"end\":68424,\"start\":68420},{\"end\":68430,\"start\":68428},{\"end\":68437,\"start\":68434},{\"end\":68444,\"start\":68441},{\"end\":69115,\"start\":69106},{\"end\":69126,\"start\":69119},{\"end\":69134,\"start\":69132},{\"end\":69374,\"start\":69371},{\"end\":69383,\"start\":69378},{\"end\":69602,\"start\":69597},{\"end\":69610,\"start\":69606},{\"end\":69619,\"start\":69614},{\"end\":69630,\"start\":69623},{\"end\":69640,\"start\":69634},{\"end\":69652,\"start\":69644},{\"end\":69667,\"start\":69656},{\"end\":69676,\"start\":69671},{\"end\":69686,\"start\":69680},{\"end\":69696,\"start\":69690},{\"end\":69707,\"start\":69700},{\"end\":69723,\"start\":69711},{\"end\":69734,\"start\":69727},{\"end\":69746,\"start\":69738},{\"end\":69755,\"start\":69750},{\"end\":69765,\"start\":69759},{\"end\":69778,\"start\":69771},{\"end\":69784,\"start\":69782},{\"end\":69794,\"start\":69788},{\"end\":69803,\"start\":69798},{\"end\":69811,\"start\":69807},{\"end\":69821,\"start\":69815},{\"end\":69831,\"start\":69825},{\"end\":69839,\"start\":69835},{\"end\":69848,\"start\":69843},{\"end\":69857,\"start\":69852},{\"end\":69867,\"start\":69861},{\"end\":69881,\"start\":69871},{\"end\":69892,\"start\":69885},{\"end\":69905,\"start\":69896},{\"end\":69915,\"start\":69909},{\"end\":70374,\"start\":70370},{\"end\":70384,\"start\":70378},{\"end\":70391,\"start\":70388},{\"end\":70399,\"start\":70395},{\"end\":70422,\"start\":70405},{\"end\":70432,\"start\":70426},{\"end\":70443,\"start\":70436},{\"end\":70452,\"start\":70447},{\"end\":70462,\"start\":70456},{\"end\":70474,\"start\":70466},{\"end\":70481,\"start\":70478},{\"end\":70489,\"start\":70485},{\"end\":70639,\"start\":70632},{\"end\":70649,\"start\":70643},{\"end\":70659,\"start\":70653},{\"end\":70669,\"start\":70663},{\"end\":70680,\"start\":70673},{\"end\":70688,\"start\":70684},{\"end\":70696,\"start\":70692},{\"end\":70705,\"start\":70700},{\"end\":70715,\"start\":70709},{\"end\":70724,\"start\":70719},{\"end\":70734,\"start\":70728},{\"end\":70746,\"start\":70738},{\"end\":70756,\"start\":70750},{\"end\":70766,\"start\":70760},{\"end\":70776,\"start\":70772},{\"end\":70788,\"start\":70780},{\"end\":70800,\"start\":70792},{\"end\":70812,\"start\":70804},{\"end\":70822,\"start\":70816},{\"end\":70838,\"start\":70826},{\"end\":70848,\"start\":70844},{\"end\":70858,\"start\":70852},{\"end\":70867,\"start\":70862},{\"end\":70876,\"start\":70871},{\"end\":70884,\"start\":70880},{\"end\":70898,\"start\":70888},{\"end\":70908,\"start\":70902},{\"end\":70916,\"start\":70912},{\"end\":70928,\"start\":70920},{\"end\":70937,\"start\":70932},{\"end\":70947,\"start\":70943},{\"end\":70956,\"start\":70951},{\"end\":70966,\"start\":70960},{\"end\":70975,\"start\":70970},{\"end\":70987,\"start\":70979},{\"end\":70998,\"start\":70991},{\"end\":71008,\"start\":71002},{\"end\":71020,\"start\":71012},{\"end\":71030,\"start\":71024},{\"end\":71039,\"start\":71034},{\"end\":71051,\"start\":71043},{\"end\":71061,\"start\":71055},{\"end\":71071,\"start\":71065},{\"end\":71085,\"start\":71075},{\"end\":71098,\"start\":71089},{\"end\":71109,\"start\":71102},{\"end\":71865,\"start\":71861},{\"end\":71872,\"start\":71869},{\"end\":71880,\"start\":71876},{\"end\":71888,\"start\":71884},{\"end\":71896,\"start\":71892},{\"end\":71904,\"start\":71900},{\"end\":71912,\"start\":71908},{\"end\":71919,\"start\":71916},{\"end\":71926,\"start\":71923},{\"end\":71935,\"start\":71930},{\"end\":71943,\"start\":71939},{\"end\":72244,\"start\":72239},{\"end\":72255,\"start\":72248},{\"end\":72266,\"start\":72261},{\"end\":72283,\"start\":72272},{\"end\":72565,\"start\":72558},{\"end\":72574,\"start\":72569},{\"end\":72584,\"start\":72578},{\"end\":72911,\"start\":72906},{\"end\":72925,\"start\":72915},{\"end\":72932,\"start\":72929},{\"end\":72940,\"start\":72936},{\"end\":72951,\"start\":72944},{\"end\":72958,\"start\":72955},{\"end\":72967,\"start\":72962},{\"end\":72974,\"start\":72971},{\"end\":72989,\"start\":72978},{\"end\":72998,\"start\":72993},{\"end\":73296,\"start\":73288},{\"end\":73306,\"start\":73300},{\"end\":73314,\"start\":73310},{\"end\":73324,\"start\":73321},{\"end\":73792,\"start\":73789},{\"end\":73970,\"start\":73966},{\"end\":73977,\"start\":73974},{\"end\":73985,\"start\":73981},{\"end\":73998,\"start\":73989},{\"end\":74015,\"start\":74002},{\"end\":74023,\"start\":74021},{\"end\":74256,\"start\":74249},{\"end\":74267,\"start\":74260},{\"end\":74277,\"start\":74271},{\"end\":74290,\"start\":74281},{\"end\":74299,\"start\":74294},{\"end\":74310,\"start\":74305},{\"end\":74320,\"start\":74314},{\"end\":74334,\"start\":74324},{\"end\":74594,\"start\":74586},{\"end\":74606,\"start\":74598},{\"end\":74809,\"start\":74803},{\"end\":74823,\"start\":74813},{\"end\":74835,\"start\":74827},{\"end\":74846,\"start\":74841},{\"end\":74855,\"start\":74850},{\"end\":74864,\"start\":74859},{\"end\":74872,\"start\":74868},{\"end\":74883,\"start\":74876},{\"end\":74889,\"start\":74887},{\"end\":74899,\"start\":74893},{\"end\":75194,\"start\":75188},{\"end\":75206,\"start\":75201},{\"end\":75213,\"start\":75210},{\"end\":75226,\"start\":75217},{\"end\":75486,\"start\":75481},{\"end\":75493,\"start\":75490},{\"end\":75501,\"start\":75497},{\"end\":75510,\"start\":75505},{\"end\":75522,\"start\":75514},{\"end\":75841,\"start\":75835},{\"end\":75852,\"start\":75845},{\"end\":75863,\"start\":75856},{\"end\":75870,\"start\":75867},{\"end\":75880,\"start\":75874},{\"end\":75890,\"start\":75884},{\"end\":75898,\"start\":75894},{\"end\":75904,\"start\":75902},{\"end\":75913,\"start\":75910},{\"end\":76272,\"start\":76267},{\"end\":76279,\"start\":76276},{\"end\":76288,\"start\":76283},{\"end\":76305,\"start\":76292},{\"end\":76316,\"start\":76309},{\"end\":76324,\"start\":76320},{\"end\":76336,\"start\":76328},{\"end\":76351,\"start\":76340},{\"end\":76680,\"start\":76670},{\"end\":76689,\"start\":76684},{\"end\":76697,\"start\":76693},{\"end\":76710,\"start\":76701},{\"end\":76716,\"start\":76714},{\"end\":76725,\"start\":76720},{\"end\":76736,\"start\":76729},{\"end\":76745,\"start\":76740},{\"end\":76754,\"start\":76749},{\"end\":76763,\"start\":76758},{\"end\":76778,\"start\":76767},{\"end\":77045,\"start\":77039},{\"end\":77055,\"start\":77051},{\"end\":77061,\"start\":77059},{\"end\":77070,\"start\":77065},{\"end\":77081,\"start\":77074},{\"end\":77575,\"start\":77571},{\"end\":77590,\"start\":77579},{\"end\":77818,\"start\":77813},{\"end\":77830,\"start\":77822},{\"end\":77842,\"start\":77834},{\"end\":77853,\"start\":77846},{\"end\":77860,\"start\":77857},{\"end\":77871,\"start\":77864},{\"end\":77877,\"start\":77875},{\"end\":77886,\"start\":77881},{\"end\":77898,\"start\":77890},{\"end\":77907,\"start\":77902},{\"end\":77917,\"start\":77911},{\"end\":77932,\"start\":77923},{\"end\":77943,\"start\":77936},{\"end\":77955,\"start\":77947},{\"end\":77962,\"start\":77959},{\"end\":77970,\"start\":77966},{\"end\":77982,\"start\":77974},{\"end\":78632,\"start\":78629},{\"end\":78644,\"start\":78636},{\"end\":78653,\"start\":78648},{\"end\":78664,\"start\":78657},{\"end\":78673,\"start\":78668},{\"end\":78683,\"start\":78677},{\"end\":78692,\"start\":78687},{\"end\":78698,\"start\":78696},{\"end\":78707,\"start\":78702},{\"end\":78720,\"start\":78711},{\"end\":79066,\"start\":79058},{\"end\":79079,\"start\":79075},{\"end\":79088,\"start\":79085},{\"end\":79594,\"start\":79588},{\"end\":79603,\"start\":79601},{\"end\":79612,\"start\":79607},{\"end\":79625,\"start\":79616},{\"end\":79641,\"start\":79629},{\"end\":80153,\"start\":80148},{\"end\":80166,\"start\":80157},{\"end\":80182,\"start\":80172},{\"end\":80614,\"start\":80609},{\"end\":80623,\"start\":80618},{\"end\":80635,\"start\":80627},{\"end\":80895,\"start\":80887},{\"end\":80903,\"start\":80899},{\"end\":80909,\"start\":80907},{\"end\":80919,\"start\":80913},{\"end\":80927,\"start\":80923},{\"end\":81145,\"start\":81141},{\"end\":81153,\"start\":81149},{\"end\":81160,\"start\":81157},{\"end\":81167,\"start\":81164},{\"end\":81176,\"start\":81171},{\"end\":81398,\"start\":81392},{\"end\":81498,\"start\":81496},{\"end\":81506,\"start\":81502},{\"end\":81515,\"start\":81510},{\"end\":81526,\"start\":81519},{\"end\":81543,\"start\":81530},{\"end\":81554,\"start\":81547},{\"end\":81564,\"start\":81558},{\"end\":81575,\"start\":81568},{\"end\":81585,\"start\":81579},{\"end\":81595,\"start\":81591},{\"end\":81605,\"start\":81599},{\"end\":81613,\"start\":81609},{\"end\":81637,\"start\":81619},{\"end\":81651,\"start\":81641},{\"end\":81659,\"start\":81655},{\"end\":81671,\"start\":81666},{\"end\":81680,\"start\":81675},{\"end\":81689,\"start\":81684},{\"end\":81703,\"start\":81693},{\"end\":81713,\"start\":81707},{\"end\":81728,\"start\":81719},{\"end\":81740,\"start\":81734},{\"end\":81749,\"start\":81744},{\"end\":81760,\"start\":81753},{\"end\":81775,\"start\":81764},{\"end\":81786,\"start\":81779},{\"end\":82313,\"start\":82309},{\"end\":82323,\"start\":82317},{\"end\":82334,\"start\":82329},{\"end\":82730,\"start\":82727},{\"end\":82740,\"start\":82734},{\"end\":82748,\"start\":82744},{\"end\":82764,\"start\":82752},{\"end\":83142,\"start\":83137},{\"end\":83157,\"start\":83146},{\"end\":83168,\"start\":83163},{\"end\":83176,\"start\":83172},{\"end\":83187,\"start\":83180},{\"end\":83198,\"start\":83191},{\"end\":83208,\"start\":83202},{\"end\":83600,\"start\":83595},{\"end\":83613,\"start\":83606},{\"end\":83624,\"start\":83617},{\"end\":83638,\"start\":83628},{\"end\":83916,\"start\":83914},{\"end\":83924,\"start\":83920},{\"end\":83936,\"start\":83930},{\"end\":84540,\"start\":84536},{\"end\":84553,\"start\":84544},{\"end\":84563,\"start\":84557},{\"end\":84577,\"start\":84570},{\"end\":84591,\"start\":84581},{\"end\":84604,\"start\":84595},{\"end\":84930,\"start\":84925},{\"end\":84939,\"start\":84934},{\"end\":84948,\"start\":84943},{\"end\":84955,\"start\":84952},{\"end\":84963,\"start\":84959},{\"end\":85573,\"start\":85569},{\"end\":85580,\"start\":85577},{\"end\":85591,\"start\":85586},{\"end\":85962,\"start\":85954},{\"end\":85973,\"start\":85966},{\"end\":85981,\"start\":85977},{\"end\":85994,\"start\":85985},{\"end\":86007,\"start\":85998},{\"end\":86308,\"start\":86302},{\"end\":86318,\"start\":86312},{\"end\":86328,\"start\":86322},{\"end\":86340,\"start\":86335},{\"end\":86349,\"start\":86344},{\"end\":86363,\"start\":86353},{\"end\":87441,\"start\":87437},{\"end\":87454,\"start\":87447},{\"end\":87463,\"start\":87458},{\"end\":87868,\"start\":87865},{\"end\":87879,\"start\":87874}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":59332,\"start\":59032},{\"attributes\":{\"id\":\"b1\"},\"end\":59596,\"start\":59334},{\"attributes\":{\"id\":\"b2\"},\"end\":59856,\"start\":59598},{\"attributes\":{\"id\":\"b3\"},\"end\":60180,\"start\":59858},{\"attributes\":{\"id\":\"b4\"},\"end\":60323,\"start\":60182},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":47017778},\"end\":60595,\"start\":60325},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":4111307},\"end\":60928,\"start\":60597},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":8844190},\"end\":61289,\"start\":60930},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":3374770},\"end\":61787,\"start\":61291},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":11431040},\"end\":62286,\"start\":61789},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1503790},\"end\":62805,\"start\":62288},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":506586},\"end\":63429,\"start\":62807},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":53080867},\"end\":64199,\"start\":63431},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":7322935},\"end\":64764,\"start\":64201},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":52915728},\"end\":65143,\"start\":64766},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":56173188},\"end\":65726,\"start\":65145},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":84186411},\"end\":66313,\"start\":65728},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":49671483},\"end\":66825,\"start\":66315},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":235435998},\"end\":67548,\"start\":66827},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":232076119},\"end\":67928,\"start\":67550},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":234340063},\"end\":68299,\"start\":67930},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":218979651},\"end\":69050,\"start\":68301},{\"attributes\":{\"doi\":\"arXiv:1409.3215\",\"id\":\"b22\"},\"end\":69267,\"start\":69052},{\"attributes\":{\"doi\":\"arXiv:2207.08281\",\"id\":\"b23\"},\"end\":69552,\"start\":69269},{\"attributes\":{\"doi\":\"arXiv:2005.14165\",\"id\":\"b24\"},\"end\":70364,\"start\":69554},{\"attributes\":{\"id\":\"b25\"},\"end\":70626,\"start\":70366},{\"attributes\":{\"doi\":\"arXiv:2107.03374\",\"id\":\"b26\"},\"end\":71788,\"start\":70628},{\"attributes\":{\"doi\":\"arXiv:2002.08155\",\"id\":\"b27\"},\"end\":72160,\"start\":71790},{\"attributes\":{\"id\":\"b28\"},\"end\":72495,\"start\":72162},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":250318108},\"end\":72840,\"start\":72497},{\"attributes\":{\"doi\":\"arXiv:2204.05999\",\"id\":\"b30\"},\"end\":73220,\"start\":72842},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":11080756},\"end\":73740,\"start\":73222},{\"attributes\":{\"doi\":\"arXiv:1903.10318\",\"id\":\"b32\"},\"end\":73888,\"start\":73742},{\"attributes\":{\"doi\":\"arXiv:1906.08237\",\"id\":\"b33\"},\"end\":74218,\"start\":73890},{\"attributes\":{\"doi\":\"arXiv:1706.03762\",\"id\":\"b34\"},\"end\":74506,\"start\":74220},{\"attributes\":{\"doi\":\"arXiv:2102.07350\",\"id\":\"b35\"},\"end\":74758,\"start\":74508},{\"attributes\":{\"doi\":\"arXiv:2001.08361\",\"id\":\"b36\"},\"end\":75102,\"start\":74760},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b37\"},\"end\":75401,\"start\":75104},{\"attributes\":{\"doi\":\"10.5281/zenodo.5297715\",\"id\":\"b38\"},\"end\":75748,\"start\":75403},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":204838007},\"end\":76148,\"start\":75750},{\"attributes\":{\"doi\":\"arXiv:1910.13461\",\"id\":\"b40\"},\"end\":76611,\"start\":76150},{\"attributes\":{\"doi\":\"arXiv:2201.07520\",\"id\":\"b41\"},\"end\":77003,\"start\":76613},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":2846066},\"end\":77443,\"start\":77005},{\"attributes\":{\"id\":\"b43\"},\"end\":77504,\"start\":77445},{\"attributes\":{\"id\":\"b44\"},\"end\":77749,\"start\":77506},{\"attributes\":{\"doi\":\"arXiv:2204.06745\",\"id\":\"b45\",\"matched_paper_id\":248177957},\"end\":78559,\"start\":77751},{\"attributes\":{\"doi\":\"arXiv:2101.00027\",\"id\":\"b46\"},\"end\":78945,\"start\":78561},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":237386541},\"end\":79513,\"start\":78947},{\"attributes\":{\"doi\":\"arXiv:1909.09436\",\"id\":\"b48\"},\"end\":79825,\"start\":79515},{\"attributes\":{\"id\":\"b49\"},\"end\":79955,\"start\":79827},{\"attributes\":{\"id\":\"b50\"},\"end\":80090,\"start\":79957},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":8923739},\"end\":80525,\"start\":80092},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":14538824},\"end\":80837,\"start\":80527},{\"attributes\":{\"doi\":\"arXiv:1904.09751\",\"id\":\"b53\"},\"end\":81069,\"start\":80839},{\"attributes\":{\"doi\":\"arXiv:2207.06590\",\"id\":\"b54\"},\"end\":81341,\"start\":81071},{\"attributes\":{\"id\":\"b55\"},\"end\":81388,\"start\":81343},{\"attributes\":{\"id\":\"b56\"},\"end\":81443,\"start\":81390},{\"attributes\":{\"doi\":\"arXiv:2203.07814\",\"id\":\"b57\"},\"end\":82208,\"start\":81445},{\"attributes\":{\"id\":\"b58\"},\"end\":82614,\"start\":82210},{\"attributes\":{\"id\":\"b59\"},\"end\":83055,\"start\":82616},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":1766669},\"end\":83504,\"start\":83057},{\"attributes\":{\"doi\":\"arXiv:2105.09352\",\"id\":\"b61\"},\"end\":83830,\"start\":83506},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":222080996},\"end\":84461,\"start\":83832},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":57573711},\"end\":84852,\"start\":84463},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":49269943},\"end\":85512,\"start\":84854},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":24005510},\"end\":85872,\"start\":85514},{\"attributes\":{\"doi\":\"arXiv:1505.07002\",\"id\":\"b66\"},\"end\":86194,\"start\":85874},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":51991430},\"end\":86828,\"start\":86196},{\"attributes\":{\"id\":\"b68\"},\"end\":87325,\"start\":86830},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":208882197},\"end\":87800,\"start\":87327},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":33145039},\"end\":88169,\"start\":87802},{\"attributes\":{\"id\":\"b71\"},\"end\":88225,\"start\":88171}]", "bib_title": "[{\"end\":59379,\"start\":59334},{\"end\":59625,\"start\":59598},{\"end\":60360,\"start\":60325},{\"end\":60652,\"start\":60597},{\"end\":60959,\"start\":60930},{\"end\":61357,\"start\":61291},{\"end\":61862,\"start\":61789},{\"end\":62362,\"start\":62288},{\"end\":62881,\"start\":62807},{\"end\":63518,\"start\":63431},{\"end\":64248,\"start\":64201},{\"end\":64833,\"start\":64766},{\"end\":65221,\"start\":65145},{\"end\":65784,\"start\":65728},{\"end\":66361,\"start\":66315},{\"end\":66881,\"start\":66827},{\"end\":67622,\"start\":67550},{\"end\":67988,\"start\":67930},{\"end\":68393,\"start\":68301},{\"end\":72233,\"start\":72162},{\"end\":72552,\"start\":72497},{\"end\":73284,\"start\":73222},{\"end\":75831,\"start\":75750},{\"end\":77035,\"start\":77005},{\"end\":77809,\"start\":77751},{\"end\":79052,\"start\":78947},{\"end\":80144,\"start\":80092},{\"end\":80605,\"start\":80527},{\"end\":83130,\"start\":83057},{\"end\":83910,\"start\":83832},{\"end\":84532,\"start\":84463},{\"end\":84921,\"start\":84854},{\"end\":85565,\"start\":85514},{\"end\":86298,\"start\":86196},{\"end\":87433,\"start\":87327},{\"end\":87861,\"start\":87802}]", "bib_author": "[{\"end\":59129,\"start\":59118},{\"end\":59394,\"start\":59381},{\"end\":59639,\"start\":59627},{\"end\":59945,\"start\":59933},{\"end\":60222,\"start\":60205},{\"end\":60373,\"start\":60362},{\"end\":60384,\"start\":60373},{\"end\":60395,\"start\":60384},{\"end\":60666,\"start\":60654},{\"end\":60676,\"start\":60666},{\"end\":60687,\"start\":60676},{\"end\":60697,\"start\":60687},{\"end\":60971,\"start\":60961},{\"end\":60977,\"start\":60971},{\"end\":60989,\"start\":60977},{\"end\":61366,\"start\":61359},{\"end\":61374,\"start\":61366},{\"end\":61380,\"start\":61374},{\"end\":61387,\"start\":61380},{\"end\":61400,\"start\":61387},{\"end\":61876,\"start\":61864},{\"end\":61882,\"start\":61876},{\"end\":61898,\"start\":61882},{\"end\":62375,\"start\":62364},{\"end\":62385,\"start\":62375},{\"end\":62391,\"start\":62385},{\"end\":62403,\"start\":62391},{\"end\":62413,\"start\":62403},{\"end\":62894,\"start\":62883},{\"end\":62902,\"start\":62894},{\"end\":62914,\"start\":62902},{\"end\":62927,\"start\":62914},{\"end\":63527,\"start\":63520},{\"end\":63536,\"start\":63527},{\"end\":63544,\"start\":63536},{\"end\":63556,\"start\":63544},{\"end\":64262,\"start\":64250},{\"end\":64275,\"start\":64262},{\"end\":64846,\"start\":64835},{\"end\":64853,\"start\":64846},{\"end\":64868,\"start\":64853},{\"end\":64875,\"start\":64868},{\"end\":64884,\"start\":64875},{\"end\":64897,\"start\":64884},{\"end\":64908,\"start\":64897},{\"end\":65230,\"start\":65223},{\"end\":65241,\"start\":65230},{\"end\":65248,\"start\":65241},{\"end\":65263,\"start\":65248},{\"end\":65793,\"start\":65786},{\"end\":65804,\"start\":65793},{\"end\":65811,\"start\":65804},{\"end\":65826,\"start\":65811},{\"end\":66375,\"start\":66363},{\"end\":66385,\"start\":66375},{\"end\":66394,\"start\":66385},{\"end\":66890,\"start\":66883},{\"end\":66897,\"start\":66890},{\"end\":66905,\"start\":66897},{\"end\":66914,\"start\":66905},{\"end\":66922,\"start\":66914},{\"end\":66931,\"start\":66922},{\"end\":66940,\"start\":66931},{\"end\":67633,\"start\":67624},{\"end\":67646,\"start\":67633},{\"end\":67653,\"start\":67646},{\"end\":67996,\"start\":67990},{\"end\":68008,\"start\":67996},{\"end\":68021,\"start\":68008},{\"end\":68408,\"start\":68395},{\"end\":68418,\"start\":68408},{\"end\":68426,\"start\":68418},{\"end\":68432,\"start\":68426},{\"end\":68439,\"start\":68432},{\"end\":68446,\"start\":68439},{\"end\":69117,\"start\":69104},{\"end\":69128,\"start\":69117},{\"end\":69136,\"start\":69128},{\"end\":69376,\"start\":69367},{\"end\":69385,\"start\":69376},{\"end\":69604,\"start\":69593},{\"end\":69612,\"start\":69604},{\"end\":69621,\"start\":69612},{\"end\":69632,\"start\":69621},{\"end\":69642,\"start\":69632},{\"end\":69654,\"start\":69642},{\"end\":69669,\"start\":69654},{\"end\":69678,\"start\":69669},{\"end\":69688,\"start\":69678},{\"end\":69698,\"start\":69688},{\"end\":69709,\"start\":69698},{\"end\":69725,\"start\":69709},{\"end\":69736,\"start\":69725},{\"end\":69748,\"start\":69736},{\"end\":69757,\"start\":69748},{\"end\":69767,\"start\":69757},{\"end\":69780,\"start\":69767},{\"end\":69786,\"start\":69780},{\"end\":69796,\"start\":69786},{\"end\":69805,\"start\":69796},{\"end\":69813,\"start\":69805},{\"end\":69823,\"start\":69813},{\"end\":69833,\"start\":69823},{\"end\":69841,\"start\":69833},{\"end\":69850,\"start\":69841},{\"end\":69859,\"start\":69850},{\"end\":69869,\"start\":69859},{\"end\":69883,\"start\":69869},{\"end\":69894,\"start\":69883},{\"end\":69907,\"start\":69894},{\"end\":69917,\"start\":69907},{\"end\":70376,\"start\":70368},{\"end\":70386,\"start\":70376},{\"end\":70393,\"start\":70386},{\"end\":70401,\"start\":70393},{\"end\":70424,\"start\":70401},{\"end\":70434,\"start\":70424},{\"end\":70445,\"start\":70434},{\"end\":70454,\"start\":70445},{\"end\":70464,\"start\":70454},{\"end\":70476,\"start\":70464},{\"end\":70483,\"start\":70476},{\"end\":70491,\"start\":70483},{\"end\":70641,\"start\":70630},{\"end\":70651,\"start\":70641},{\"end\":70661,\"start\":70651},{\"end\":70671,\"start\":70661},{\"end\":70682,\"start\":70671},{\"end\":70690,\"start\":70682},{\"end\":70698,\"start\":70690},{\"end\":70707,\"start\":70698},{\"end\":70717,\"start\":70707},{\"end\":70726,\"start\":70717},{\"end\":70736,\"start\":70726},{\"end\":70748,\"start\":70736},{\"end\":70758,\"start\":70748},{\"end\":70768,\"start\":70758},{\"end\":70778,\"start\":70768},{\"end\":70790,\"start\":70778},{\"end\":70802,\"start\":70790},{\"end\":70814,\"start\":70802},{\"end\":70824,\"start\":70814},{\"end\":70840,\"start\":70824},{\"end\":70850,\"start\":70840},{\"end\":70860,\"start\":70850},{\"end\":70869,\"start\":70860},{\"end\":70878,\"start\":70869},{\"end\":70886,\"start\":70878},{\"end\":70900,\"start\":70886},{\"end\":70910,\"start\":70900},{\"end\":70918,\"start\":70910},{\"end\":70930,\"start\":70918},{\"end\":70939,\"start\":70930},{\"end\":70949,\"start\":70939},{\"end\":70958,\"start\":70949},{\"end\":70968,\"start\":70958},{\"end\":70977,\"start\":70968},{\"end\":70989,\"start\":70977},{\"end\":71000,\"start\":70989},{\"end\":71010,\"start\":71000},{\"end\":71022,\"start\":71010},{\"end\":71032,\"start\":71022},{\"end\":71041,\"start\":71032},{\"end\":71053,\"start\":71041},{\"end\":71063,\"start\":71053},{\"end\":71073,\"start\":71063},{\"end\":71087,\"start\":71073},{\"end\":71100,\"start\":71087},{\"end\":71111,\"start\":71100},{\"end\":71867,\"start\":71859},{\"end\":71874,\"start\":71867},{\"end\":71882,\"start\":71874},{\"end\":71890,\"start\":71882},{\"end\":71898,\"start\":71890},{\"end\":71906,\"start\":71898},{\"end\":71914,\"start\":71906},{\"end\":71921,\"start\":71914},{\"end\":71928,\"start\":71921},{\"end\":71937,\"start\":71928},{\"end\":71945,\"start\":71937},{\"end\":72246,\"start\":72235},{\"end\":72257,\"start\":72246},{\"end\":72268,\"start\":72257},{\"end\":72285,\"start\":72268},{\"end\":72567,\"start\":72554},{\"end\":72576,\"start\":72567},{\"end\":72586,\"start\":72576},{\"end\":72913,\"start\":72904},{\"end\":72927,\"start\":72913},{\"end\":72934,\"start\":72927},{\"end\":72942,\"start\":72934},{\"end\":72953,\"start\":72942},{\"end\":72960,\"start\":72953},{\"end\":72969,\"start\":72960},{\"end\":72976,\"start\":72969},{\"end\":72991,\"start\":72976},{\"end\":73000,\"start\":72991},{\"end\":73298,\"start\":73286},{\"end\":73308,\"start\":73298},{\"end\":73316,\"start\":73308},{\"end\":73326,\"start\":73316},{\"end\":73794,\"start\":73787},{\"end\":73972,\"start\":73964},{\"end\":73979,\"start\":73972},{\"end\":73987,\"start\":73979},{\"end\":74000,\"start\":73987},{\"end\":74017,\"start\":74000},{\"end\":74025,\"start\":74017},{\"end\":74258,\"start\":74247},{\"end\":74269,\"start\":74258},{\"end\":74279,\"start\":74269},{\"end\":74292,\"start\":74279},{\"end\":74301,\"start\":74292},{\"end\":74312,\"start\":74301},{\"end\":74322,\"start\":74312},{\"end\":74336,\"start\":74322},{\"end\":74596,\"start\":74584},{\"end\":74608,\"start\":74596},{\"end\":74811,\"start\":74801},{\"end\":74825,\"start\":74811},{\"end\":74837,\"start\":74825},{\"end\":74848,\"start\":74837},{\"end\":74857,\"start\":74848},{\"end\":74866,\"start\":74857},{\"end\":74874,\"start\":74866},{\"end\":74885,\"start\":74874},{\"end\":74891,\"start\":74885},{\"end\":74901,\"start\":74891},{\"end\":75196,\"start\":75186},{\"end\":75208,\"start\":75196},{\"end\":75215,\"start\":75208},{\"end\":75228,\"start\":75215},{\"end\":75488,\"start\":75479},{\"end\":75495,\"start\":75488},{\"end\":75503,\"start\":75495},{\"end\":75512,\"start\":75503},{\"end\":75524,\"start\":75512},{\"end\":75843,\"start\":75833},{\"end\":75854,\"start\":75843},{\"end\":75865,\"start\":75854},{\"end\":75872,\"start\":75865},{\"end\":75882,\"start\":75872},{\"end\":75892,\"start\":75882},{\"end\":75900,\"start\":75892},{\"end\":75906,\"start\":75900},{\"end\":75915,\"start\":75906},{\"end\":76274,\"start\":76265},{\"end\":76281,\"start\":76274},{\"end\":76290,\"start\":76281},{\"end\":76307,\"start\":76290},{\"end\":76318,\"start\":76307},{\"end\":76326,\"start\":76318},{\"end\":76338,\"start\":76326},{\"end\":76353,\"start\":76338},{\"end\":76682,\"start\":76668},{\"end\":76691,\"start\":76682},{\"end\":76699,\"start\":76691},{\"end\":76712,\"start\":76699},{\"end\":76718,\"start\":76712},{\"end\":76727,\"start\":76718},{\"end\":76738,\"start\":76727},{\"end\":76747,\"start\":76738},{\"end\":76756,\"start\":76747},{\"end\":76765,\"start\":76756},{\"end\":76780,\"start\":76765},{\"end\":77047,\"start\":77037},{\"end\":77057,\"start\":77047},{\"end\":77063,\"start\":77057},{\"end\":77072,\"start\":77063},{\"end\":77083,\"start\":77072},{\"end\":77577,\"start\":77569},{\"end\":77592,\"start\":77577},{\"end\":77820,\"start\":77811},{\"end\":77832,\"start\":77820},{\"end\":77844,\"start\":77832},{\"end\":77855,\"start\":77844},{\"end\":77862,\"start\":77855},{\"end\":77873,\"start\":77862},{\"end\":77879,\"start\":77873},{\"end\":77888,\"start\":77879},{\"end\":77900,\"start\":77888},{\"end\":77909,\"start\":77900},{\"end\":77919,\"start\":77909},{\"end\":77934,\"start\":77919},{\"end\":77945,\"start\":77934},{\"end\":77957,\"start\":77945},{\"end\":77964,\"start\":77957},{\"end\":77972,\"start\":77964},{\"end\":77984,\"start\":77972},{\"end\":78634,\"start\":78627},{\"end\":78646,\"start\":78634},{\"end\":78655,\"start\":78646},{\"end\":78666,\"start\":78655},{\"end\":78675,\"start\":78666},{\"end\":78685,\"start\":78675},{\"end\":78694,\"start\":78685},{\"end\":78700,\"start\":78694},{\"end\":78709,\"start\":78700},{\"end\":78722,\"start\":78709},{\"end\":79068,\"start\":79054},{\"end\":79081,\"start\":79068},{\"end\":79090,\"start\":79081},{\"end\":79596,\"start\":79586},{\"end\":79605,\"start\":79596},{\"end\":79614,\"start\":79605},{\"end\":79627,\"start\":79614},{\"end\":79643,\"start\":79627},{\"end\":80155,\"start\":80146},{\"end\":80168,\"start\":80155},{\"end\":80184,\"start\":80168},{\"end\":80616,\"start\":80607},{\"end\":80625,\"start\":80616},{\"end\":80637,\"start\":80625},{\"end\":80897,\"start\":80885},{\"end\":80905,\"start\":80897},{\"end\":80911,\"start\":80905},{\"end\":80921,\"start\":80911},{\"end\":80929,\"start\":80921},{\"end\":81147,\"start\":81139},{\"end\":81155,\"start\":81147},{\"end\":81162,\"start\":81155},{\"end\":81169,\"start\":81162},{\"end\":81178,\"start\":81169},{\"end\":81400,\"start\":81392},{\"end\":81500,\"start\":81494},{\"end\":81508,\"start\":81500},{\"end\":81517,\"start\":81508},{\"end\":81528,\"start\":81517},{\"end\":81545,\"start\":81528},{\"end\":81556,\"start\":81545},{\"end\":81566,\"start\":81556},{\"end\":81577,\"start\":81566},{\"end\":81587,\"start\":81577},{\"end\":81597,\"start\":81587},{\"end\":81607,\"start\":81597},{\"end\":81615,\"start\":81607},{\"end\":81639,\"start\":81615},{\"end\":81653,\"start\":81639},{\"end\":81661,\"start\":81653},{\"end\":81673,\"start\":81661},{\"end\":81682,\"start\":81673},{\"end\":81691,\"start\":81682},{\"end\":81705,\"start\":81691},{\"end\":81715,\"start\":81705},{\"end\":81730,\"start\":81715},{\"end\":81742,\"start\":81730},{\"end\":81751,\"start\":81742},{\"end\":81762,\"start\":81751},{\"end\":81777,\"start\":81762},{\"end\":81788,\"start\":81777},{\"end\":82315,\"start\":82307},{\"end\":82325,\"start\":82315},{\"end\":82336,\"start\":82325},{\"end\":82732,\"start\":82725},{\"end\":82742,\"start\":82732},{\"end\":82750,\"start\":82742},{\"end\":82766,\"start\":82750},{\"end\":83144,\"start\":83132},{\"end\":83159,\"start\":83144},{\"end\":83170,\"start\":83159},{\"end\":83178,\"start\":83170},{\"end\":83189,\"start\":83178},{\"end\":83200,\"start\":83189},{\"end\":83210,\"start\":83200},{\"end\":83602,\"start\":83593},{\"end\":83615,\"start\":83602},{\"end\":83626,\"start\":83615},{\"end\":83640,\"start\":83626},{\"end\":83918,\"start\":83912},{\"end\":83926,\"start\":83918},{\"end\":83938,\"start\":83926},{\"end\":84542,\"start\":84534},{\"end\":84555,\"start\":84542},{\"end\":84565,\"start\":84555},{\"end\":84579,\"start\":84565},{\"end\":84593,\"start\":84579},{\"end\":84606,\"start\":84593},{\"end\":84932,\"start\":84923},{\"end\":84941,\"start\":84932},{\"end\":84950,\"start\":84941},{\"end\":84957,\"start\":84950},{\"end\":84965,\"start\":84957},{\"end\":85575,\"start\":85567},{\"end\":85582,\"start\":85575},{\"end\":85593,\"start\":85582},{\"end\":85964,\"start\":85952},{\"end\":85975,\"start\":85964},{\"end\":85983,\"start\":85975},{\"end\":85996,\"start\":85983},{\"end\":86009,\"start\":85996},{\"end\":86310,\"start\":86300},{\"end\":86320,\"start\":86310},{\"end\":86330,\"start\":86320},{\"end\":86342,\"start\":86330},{\"end\":86351,\"start\":86342},{\"end\":86365,\"start\":86351},{\"end\":87443,\"start\":87435},{\"end\":87456,\"start\":87443},{\"end\":87465,\"start\":87456},{\"end\":87870,\"start\":87863},{\"end\":87881,\"start\":87870}]", "bib_venue": "[{\"end\":59116,\"start\":59032},{\"end\":59412,\"start\":59394},{\"end\":59658,\"start\":59639},{\"end\":59931,\"start\":59858},{\"end\":60203,\"start\":60182},{\"end\":60436,\"start\":60395},{\"end\":60738,\"start\":60697},{\"end\":61087,\"start\":60989},{\"end\":61487,\"start\":61400},{\"end\":61985,\"start\":61898},{\"end\":62494,\"start\":62413},{\"end\":63047,\"start\":62927},{\"end\":63718,\"start\":63556},{\"end\":64372,\"start\":64275},{\"end\":64925,\"start\":64908},{\"end\":65367,\"start\":65263},{\"end\":65935,\"start\":65826},{\"end\":66503,\"start\":66394},{\"end\":67082,\"start\":66940},{\"end\":67727,\"start\":67653},{\"end\":68095,\"start\":68021},{\"end\":68555,\"start\":68446},{\"end\":69102,\"start\":69052},{\"end\":69365,\"start\":69269},{\"end\":69591,\"start\":69554},{\"end\":71857,\"start\":71790},{\"end\":72316,\"start\":72285},{\"end\":72645,\"start\":72586},{\"end\":72902,\"start\":72842},{\"end\":73423,\"start\":73326},{\"end\":73785,\"start\":73742},{\"end\":73962,\"start\":73890},{\"end\":74245,\"start\":74220},{\"end\":74582,\"start\":74508},{\"end\":74799,\"start\":74760},{\"end\":75184,\"start\":75104},{\"end\":75477,\"start\":75403},{\"end\":75934,\"start\":75915},{\"end\":76263,\"start\":76150},{\"end\":76666,\"start\":76613},{\"end\":77170,\"start\":77083},{\"end\":77457,\"start\":77445},{\"end\":77567,\"start\":77506},{\"end\":78094,\"start\":78000},{\"end\":78625,\"start\":78561},{\"end\":79176,\"start\":79090},{\"end\":79584,\"start\":79515},{\"end\":79848,\"start\":79827},{\"end\":79973,\"start\":79957},{\"end\":80270,\"start\":80184},{\"end\":80656,\"start\":80637},{\"end\":80883,\"start\":80839},{\"end\":81137,\"start\":81071},{\"end\":81350,\"start\":81343},{\"end\":81492,\"start\":81445},{\"end\":82305,\"start\":82210},{\"end\":82723,\"start\":82616},{\"end\":83251,\"start\":83210},{\"end\":83591,\"start\":83506},{\"end\":84034,\"start\":83938},{\"end\":84646,\"start\":84606},{\"end\":85057,\"start\":84965},{\"end\":85675,\"start\":85593},{\"end\":85950,\"start\":85874},{\"end\":86456,\"start\":86365},{\"end\":86858,\"start\":86830},{\"end\":87545,\"start\":87465},{\"end\":87964,\"start\":87881},{\"end\":88178,\"start\":88171},{\"end\":61561,\"start\":61489},{\"end\":62059,\"start\":61987},{\"end\":62562,\"start\":62496},{\"end\":63154,\"start\":63049},{\"end\":63867,\"start\":63720},{\"end\":64473,\"start\":64374},{\"end\":65458,\"start\":65369},{\"end\":66048,\"start\":65937},{\"end\":66599,\"start\":66505},{\"end\":67228,\"start\":67084},{\"end\":68668,\"start\":68557},{\"end\":73507,\"start\":73425},{\"end\":77244,\"start\":77172},{\"end\":78175,\"start\":78096},{\"end\":79249,\"start\":79178},{\"end\":84134,\"start\":84036},{\"end\":85182,\"start\":85079},{\"end\":86534,\"start\":86458}]"}}}, "year": 2023, "month": 12, "day": 17}