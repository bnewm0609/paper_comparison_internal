{"id": 258212971, "updated": "2023-10-05 01:49:31.697", "metadata": {"title": "How Secure is Code Generated by ChatGPT?", "authors": "[{\"first\":\"Raphael\",\"last\":\"Khoury\",\"middle\":[]},{\"first\":\"Anderson\",\"last\":\"Avila\",\"middle\":[\"R.\"]},{\"first\":\"Jacob\",\"last\":\"Brunelle\",\"middle\":[]},{\"first\":\"Baba\",\"last\":\"Camara\",\"middle\":[\"Mamadou\"]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "In recent years, large language models have been responsible for great advances in the field of artificial intelligence (AI). ChatGPT in particular, an AI chatbot developed and recently released by OpenAI, has taken the field to the next level. The conversational model is able not only to process human-like text, but also to translate natural language into code. However, the safety of programs generated by ChatGPT should not be overlooked. In this paper, we perform an experiment to address this issue. Specifically, we ask ChatGPT to generate a number of program and evaluate the security of the resulting source code. We further investigate whether ChatGPT can be prodded to improve the security by appropriate prompts, and discuss the ethical aspects of using AI to generate code. Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2304.09655", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2304-09655", "doi": "10.48550/arxiv.2304.09655"}}, "content": {"source": {"pdf_hash": "f60d3ce156dff3868cf923e03d94eef843eaa13a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2304.09655v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "88e6182ae8cc91cd5d1feeacec6dd1ee93a5265b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f60d3ce156dff3868cf923e03d94eef843eaa13a.txt", "contents": "\nHow Secure is Code Generated by ChatGPT?\n\n\nRapha\u00ebl Khoury raphael.khoury@uqo.ca \nUniversit\u00e9 du Quebec en Outaouais\nQuebecCanada\n\nAnderson R Avila anderson.raymundoavila@uqo.ca \nInstitut national de la recherche scientifique\nQuebecCanada\n\nJacob Brunelle \nUniversit\u00e9 du Quebec en Outaouais\nQuebecCanada\n\nBabaMamadou Camara \nUniversit\u00e9 du Quebec en Outaouais\nQuebecCanada\n\nHow Secure is Code Generated by ChatGPT?\nIndex Terms-Large language modelsChatGPTcode securityautomatic code generation\nIn recent years, large language models have been responsible for great advances in the field of artificial intelligence (AI). ChatGPT in particular, an AI chatbot developed and recently released by OpenAI, has taken the field to the next level. The conversational model is able not only to process human-like text, but also to translate natural language into code. However, the safety of programs generated by ChatGPT should not be overlooked. In this paper, we perform an experiment to address this issue. Specifically, we ask ChatGPT to generate a number of program and evaluate the security of the resulting source code. We further investigate whether ChatGPT can be prodded to improve the security by appropriate prompts, and discuss the ethical aspects of using AI to generate code. Results suggest that ChatGPT is aware of potential vulnerabilities, but nonetheless often generates source code that are not robust to certain attacks.\n\nI. INTRODUCTION\n\nFor years, large language models (LLM) have been demonstrating impressive performance on a number of natural language processing (NLP) tasks, such as sentiment analysis, natural language understanding (NLU), machine translation (MT) to name a few. This has been possible specially by means of increasing the model size, the training data and the model complexity [1]. In 2020, for instance, OpenAI announced GPT-3 [2], a new LLM with 175B parameters, 100 times larger than GPT-2 [3]. Two years later, ChatGPT [4], an artificial intelligence (AI) chatbot capable of understanding and generating human-like text, was released. The conversational AI model, empowered in its core by an LLM based on the Transformer architecture, has received great attention from both industry and academia, given its potential to be applied in different downstream tasks (e.g., medical reports [5], code generation [6], educational tool [7], etc).\n\nBesides multi-turn question answering (Q&A) conversations, ChatGPT can translate human-like text into source code. The model has the potential to incorporate most of the early Machine Learning (ML) coding applications, e.g., bug detection and localization [8], program synthesis [9], code summarization [10] and code completion [11]. This makes the model very attractive to software development companies that aim at increasing productivity while minimizing costs. It can also benefit new developers that need to speed up their development process or more senior programmers that wish to alleviate their daily tasks. However, the risk of developing and deploying source code generated by ChatGPT is still unknown. Therefore, this paper is an attempt to answer the question of how secure is the source code generated by ChatGPT. Moreover, we investigate and propose follow-up questions that can guide ChatGPT to assess and regenerate more secure source code.\n\nIn this paper, we perform an experiment to evaluate the security of code generated by ChatGPT, fine-tuned from a model in the GPT-3.5 series. Specifically, we asked Chat-GPT to generate 21 programs, in 5 different programming languages: C, C++, Python, html and Java. We then evaluated the generated program and questioned ChatGPT about any vulnerability present in the code. The results were worrisome. We found that, in several cases, the code generated by ChatGPT fell well below minimal security standards applicable in most contexts. In fact, when prodded to whether or not the produced code was secure, ChatGTP was able to recognize that it was not. The chatbot, however, was able to provide a more secure version of the code in many cases if explicitly asked to do so.\n\nThe remainder of this paper is organized as follows. Section II describes our methodology as well as provides an overview of the dataset. Section III details the security flaws we found in each program. In Section IV, we discuss our results, as well as the ethical consideration of using AI models to generate code. Section VI surveys related works. Section V discusses threats to the validity of our results. Concluding remarks are given in Section VII.\n\n\nII. STUDY SETUP A. Methodology\n\nIn this study, we asked ChatGPT to generate 21 programs, using a variety of programming languages. The programs generated serve a diversity of purpose, and each program was chosen to highlight risks of a specific vulnerability (eg. SQL injection in the case of a program that interacts with database, or memory corruption for a C program). In some cases, our instructions to the chatbot specified that the code would be used in a security-sensitive context. However, we elected not to specifically instruct ChatGPT to produce secure code, or to incorporate specific security features such as input sanitization. Our experience thus simulates the behavior of a novice programmer who asks the chatbot to produce code on his behalf, and who may be unaware of the minutiae required to make code secure.\n\nWe then prodded ChatGPT about the security of the code it produced. Whenever a vulnerability was evident, we created an input that triggers the vulnerability and asked ChatGPT: \"The code behaves unexpectedly when fed the following input: <input>. What causes this behavior? \" This line of question again allows us to simulate the behavior of a novice programmer, who is unaware of security consideration, but who does take the time to test the program supplied to him by the chatbot. In other cases, we directly asked ChatGTP if the code supplied is secure with respect to a specific weakness. Finally, we asked ChatGPT to create a more secure version of the code. In our dataset, we refer to these updated versions of the programs as the 'corrected programs'. Corrected programs were only generated when the program initially created by ChatGPT is vulnerable to the category of attack to which it was to serve as a use-case.\n\n\nB. Dataset Description\n\nThe 21 programs generated by ChatGPT are written in 5 different programming languages: C (3), C++ (11), python (3), html (1) and Java (3). Each program was, in itself, comparatively simple; most consist of a single class and even the longest one is only 97 lines of code. Each program accomplishes a task that makes it particularly at susceptible to a specific type of vulnerability. For example, we asked chatGPT to create a program that performs manipulations on a database, with the intention of testing the chatbot's ability to create code resistant to SQL injection. The scenarios we chose cover a variety of common attacks including memory corruption, Denial of service, deserialization attack and cryptographic misuse. Some programs are susceptible to more than one vulnerability. Table I contains a list of the programs in our dataset. The table also indicates the intended vulnerability for each program, with the associate CWE number. Column 4 indicates if the initial program return by chat GPT is vulnerable (Y) or not (N), or was unable to create the requested program (U). Column 5 indicates if the corrected program , i.e., the program produced by chatGPT after our interaction with it, is still vulnerable. The (U) for program 6 reflects the fact that ChatGPT was unable to produce a corrected program for this use-case. For columns 4 and 5, we are only considering the intended vulnerability listed in Table I. If a program appears secure with respect to it's intended vulnerability, we mark it as secure, even if it contains other vulnerabilities. The final column indicates if the initial program can compile and run without errors. Several programs produced by ChatGPT required libraries that we were unable to locate. Other had syntactic errors such as missing ';' or uninitialized variables.\n\nOur dataset is available on the author's github repository 1 .\n\n\nIII. SECURITY ANALYSIS OF THE CODE\n\nIn this section, we briefly explain each program in our dataset, and detail our interaction with ChatGTP. 1 https://github.com/RaphaelKhoury/ProgramsGeneratedByChatGPT a) Program 1: is a simple C++ FTP server to share files located in a public folder. The code generated by chatGPT performs no input sanitization whatsoever, and is trivially vulnerable to a path traversal vulnerability.\n\nWhen prompted about the behavior of the program on a malicious input, ChatGPT readily realized that the program is vulnerable to a path traversal vulnerability, and was even able to provide a cogent explanation of the steps needed to secure the program.\n\nHowever, when asked to produce a more secure version of the program, ChatGTP merely added two sanitization checks to the code: a first check to ensure that the user input only contains alphanumeric characters and a second test to ensure that the path of the shared file contains the path of the shared folder. Both tests are relatively simple and easy to circumvent by even a novice adversary. b) Program 2: is a C++ program that receives as input an email address, and passes it to a program (as a parameter) through a shell. As discussed by Viega et al. [12], handling input in this manner allows a malicious adversary to execute arbitrary code by appending shell instructions to a fictitious email.\n\nAs was the case in the previous example, when asked about the behavior of the program on a malicious input, ChatGPT realizes that the code is vulnerable. In this case, the behavior is only triggered by a crafted input, so only a user who is already aware of the security risk would ever ask about this situation. However, ChatGPT is then able to provide an explanation as to why the program is vulnerable and create a more secure program. The corrected program exhibits some input validation tests, but they are fairly limited and the program remains vulnerable-a situation that is hard to avoid considering how risky it is to feed a user-input directly to the command line. Creating a truly secure program would probably require a more fundamental modification of the code, which is beyond the capabilities of a chatbot tasked with responding to user requests. This use-case raises interesting ethical issues since it may be argued that the instructions given to ChatGPT (i.e., passing the user's input to the program as a parameter) are inherently unsafe. We will return to this issue in Section IV. c) Program 3: is a python program that receives a user input and stores it in an SQL database. The program performs no code sanitization, and is trivially vulnerable to an SQL injection. However, when asked about the behavior of the program on a textbook SQL injection entry, ChatGPT identified the vulnerability, and proposed a new version of the code that uses prepared statements to perform the database update securely. d) Program 4: is a C++ program that receives as input a user-supplied username and password, and checks that the username is not contained in the password using a regex. This process exposes the host system to a denial of service by way of a ReDos attack [13] if an adversary submits a crafted input that requires exponential time to process.\n\nThe chatbot incorrectly stated that the worst case algorithmic complexity of the code it submitted is O(n 2 ). In reality, since the adversary controls the creation of the regex, he may cause an execution with a worst case as high as O(2 n ) (depending on the algorithm used for regex resolution, which is not known). When shown a malicious input, ChatGTP did not recognize that it causes a ReDos attack. However, when asked directly about this class of attack, it did recognize that the code is vulnerable and was able to suggest a number of alterations to make it more robust, the main one being a timeout after 100000 iterations on the execution of the regex. Not only is this upper bound immoderately high, but the regex library used by ChatGPT could not be found online. Since most regex libraries do not offer a timeout functionality, a user who receives this code from chatGPT may adapt it by simply removing the timeout, specially since he does not understand its purpose. e) Program 5: is an interactive webpage that manipulates user input, which makes it susceptible to an XSS injection. ChatGPT initially stated that it was unable to create a complete dynamic page, and could only suggest code fragments that accomplish the various tasks needed to implement an interactive webpage. We gathered these code fragments and included them in our dataset. Since ChatGPT did not produce a functional program we labeled this case as 'U' in Table I.\n\nWhile the fragments were inherently incomplete, they did not include any input sanitization and a page that incorporates these fragments would be trivially vulnerable to XSS injection. ChatGPT recognized this fact, and suggested actionable steps that could make the program more secure. However, when asked to produce a more secure version of the code, ChatGPT produced a page that remained trivially vulnerable, ignoring its own advice.\n\nWe found this case to be particularly puzzling, since Chat-GTP was initially unable to produce a complete program, but did so later in our interaction. In fact, we continued to explore this scenario and made further queries to ChatGTP, until the chatbot was able to produce a suitably secure page. The page was secure by the inclusion of htmlspecialchars() to sanitize user inputs. Unfortunately, the nature of the tool makes it difficult to draw conclusions as to which lines of enquiries will lead ChatGPT towards the creation of secure code. We will return to this topic in the next section.\n\nf) Programs 6: is a fragment of Java code that receives a serialized object-a calendar capturing a date and an event, via a socket and deserializes it in order to use it in a broader program. The program is vulnerable to a number of deserialization vulnerabilities including: DoS via an abnormally large or malformed object, the creation of illicit objects (eg. a calendar date of February 31) or a Java deserialization attack, which may result in the execution of arbitrary code [14].\n\nWe first asked ChatGPT if an illicit object can be received. The answer was somewhat confused, with the chatbot flatly stating that such an object could not be created, before suggesting an updated program that includes validity checks. In any case, the checks are incomplete, refer to a non-existed method and would not catch the use-case we asked about (February 31). The corrected program thus remains vulnerable to this class of attack.\n\nWhen asked broad questions about whether the program is vulnerable, ChatGPT raised valid concerns such as socket exhaustion, but did not mention any deserialization-specific attacks. However, when asked specifically about deserialization DoS and deserialization attacks, ChatGPT was able to explain why the original application is vulnerable and to provide clear advice on how to protect it.\n\nIn a final step, we asked ChatGPT to incorporate its own advice in a new version of the code. Unfortunately, ChatGPT produced the following reply, indicating that doing so was beyond its means:\n\n\"I apologize, but as an AI language model, I cannot rewrite entire codebases or applications from scratch, as it requires a deep understanding of the requirements and architecture of the system.\" g) Program 7: similarly receives a zip archive from the user, and performs a manipulation on each file contained in the archive. It is vulnerable so several zip manipulation vulnerabilities such as zipslip and zip bombs [15].\n\nWe first asked ChatGPT an open ended question, \"Is this program secure?\". The chabot responded that it is. The response included a number of important security-related topics, such as network manipulation and the reception of files that are not of type zip. However, it did not raise the possibility of zip-related attacks. We then asked specifically about both zip slip and zip bomb vulnerabilities. In both cases, the chatbot stated that the program is (or could be) vulnerable to these attacks under some circumstances. The chatbot was also able to suggest a list of improvements that would effectively secure the code.\n\nh) Program 8: is a C++ utility to strip backslash characters from a user supplied input. As discussed by Howard et al. [?], such a function is vulnerable to a denial of service if it is written in a naive (O(n 2 )) manner, and a malicious user supplies an input that consists in a long string of '\\'s. The code generated by ChatGPT exhibited linear complexity and was thus likely invulnerable to this attack.\n\nCuriously, when asked about this topic, the chatbot wrongly stated that the program it had produce was vulnerable to this category of attack, and that further input sanitization was required.\n\ni) Programs 9: is a C program that places sensitive data in a temporary file. The code exhibits a number of file management errors that may lead to the exposure of sensitive information. A large number of security-critical flaws are evident when examining this simple code. Notably, the temporary file has a predictable name and path, and error codes returned by the file manipulation function are not checked. Furthermore, the program does not check whether or not the file already exists before creating it, a caution meant to prevent disclosure of any information left in the file in a previous session.\n\nSimilarly to the previous use-case, ChatGPT only recognizes the vulnerability when asked specifically about it and is able to suggest appropriate corrective measures. In this sense, secure code is only produced for a user who explicitly requests it, and even then the code is only protected against those attacks categories for which the user requests protection. j) Programs 10-12: generate a pseudorandom number to serve as password, in C++, Java and python respectively. Since the prompt specified that the pseudorandom number was to be used as a password, ChatGPT should have used a cryptographically secure PRNG. However, in two of the three cases, this precaution was not taken: the C++ program used std::mt19937, a Mersenne Twister, while the python program relied upon the random.py library.\n\nThe Java program did use a cryptographically secure PRNG, SecureRandom. However, the Java program exhibits its own issues. In particular, the password produced is limited in that it only contains the characters 0-9. In a sense, ChatGPT was following its instruction to generate a pseudorandom number, rather than a string, but the intent of the programmer may have been to generate a numeric value that can be interpreted as a password, (for example by converting the numbers to ascii). This mistake highlights the limits of ChatGPT as a tool to aid novice programmers write programs. When we asked ChatGPT:\"Write a program that uses a cryptographically secure random number generator to create a strong password, with at least 80 bits of entropy.\", the resulting code was secure and concordant with the best practices, but a novice programmer may not be able to formulate such a question.\n\nLikewise, asking follow-up general questions such as \"Is this code secure?\" or \"Why is os.urandom considered cryptographically secure?\" provided a lot of useful background information on creating secure passwords, but this information will only be available to the user who specifically requests it.\n\nIn all three cases, the random numbers had a fixed length of 10 characters. k) Programs 13-16: relate to misuse of cryptographic libraries. The first program is a C++ program that generates AES keys to communicate securely to 3 different users. ChatGPT used the same keys for all 3 recipients, despite being explicitly told that the information that will be transmitted is sensitive. Furthermore, this common key is hard-coded in the program, an additional foible that we had not foreseen.\n\nThe three other programs all perform the same taskcreate a key and encrypt a string, in C++, Java and python. In the latter two cases, we specifically requested that the use pycryptopp (python) and Bouncy Castle (Java) respectively, two widely used cryptographic libraries. Both libraries perform encryption using ECB mode by default which is seen as a misuse, and we had expected that ChatGPT would produce code that uses the library with default values, specially since most usage examples of this library available online seem to be vulnerable. Fortunately, ChatGPT correctly used a more secure mode, which has to be set explicitly.\n\nHowever, in the case of encryption in C++, ChatGPT does use ECB by default, despite being free to select any encryption library.\n\nl) Programs 17: consists in a pair of C++ functions: the first collects a username and a password from a user and stores them in a database, while the second checks if the a given username and password pair is present in the database. In violation of commonly accepted best practice, the code uses no encryption, hashing or salt to protect the passwords. When asked if the code is concordant with the best security practices, ChatGPT readily admits that it is not, and produces a new variation of the code that uses Bcrypt, with proper hashing and salt. In effect, ChatGPT knowingly produces vulnerable code for a highly security-sensitive section of the program, and only produces secure code when asked to do so explicitly. The corrected program appears to remain vulnerable to an SQL injection, in any case. m) Programs 18-21: are C\\C++ programs that perform simple computations user input, and are vulnerable to memory corruption attacks if the input is not adequately sanitized. These include buffer overflow (program 18 and 19) integer overflow (program 19) and memory allocation errors (program 21).\n\nProgram 18 receives as input an array of integers, sorts them, and allows the user to query the sorted array by index. Our aim was to test security of the code w.r.t. a potential buffer overflow, in case the user requests the integer at an index that falls outside the sorted array. While it is impossible to be assured of the absence of a vulnerability, the code produced by ChatGPT in this case contains the expected boundary checks and appears to be free from buffer overflow vulnerabilities. However, some input validation is missing, a fact that chatGPT readily admitted when asked why the program misbehaved on non-numeric inputs.\n\nProgram 19 is a function that takes as input an array of integers, and returns the product of the values it contains. The program is vulnerable to an integer overflow if the the result is greater than Max INT. This would affect the integrity of the data, and may the be root cause of a buffer overflow or of other vulnerabilities depending on how the result is used. While ChatGPT realized the presence of the vulnerability when presented with a pathological input, the chatbot suggested to correct it by replacing the type of the array's elements, an obviously futile remediation in the presence of an adversarial user.\n\nProgram 20, is a C++ that takes as input two strings as well as their size and concatenates them. It is trivially exploitable since it performs no checks on the size of the input, and no verification that each string is concordant with it's size. When prodded on this topic, ChatGPT stresses the need to call the function with integer parameters that are concordant with the associated string, thus ignoring the possibility of an adversarial user.\n\nWe then asked ChatGPT to create a program that avoid this issue. The results included a single check, to ensure that the destination buffer is larger than the sum of the two integer parameters. Not only does the corrected program still not ensure that these values are concordant with the input strings, but the check itself is vulnerable to an integer overflow. A number of other essential security checks are missing and the code is trivially exploitable. Furthermore, the chat prompt stresses that the program assumes that the input strings are correctly null-terminated. This is a surprising comment since our instructions to ChatGPT specifically stressed that the input strings may not be null-terminated.\n\nFinally, program 21 is a function that allocates memory at the request of the user. The program may cause memory corruption if the user requests memory of size 0 [16], a problem that ChatGPT readily recognized, and easily fixed when asked explicitly to do so.\n\nIn total, only 5 of the 21 programs were initially correct. After interaction with ChatGPT, the chatbot was able to produce a corrected version for 7 of the 16 incorrect program. Vulnerabilities were common in all categories of weaknesses, but ChatGPT seems to have particular difficulty with memory corruption vulnerabilities and secure data manipulations. The prevalence of encryption vulnerabilities varied depending of the programming language used.\n\n\nIV. DISCUSSION\n\nThe first and most important conclusion that can be drawn from this experiment is that ChatGPT frequently produces insecure code. In fact, only 5 of the 21 use-cases we investigated were initially secure, and ChatGPT was only able to produce secure code in an additional 7 cases after we explicitly requested of it that we correct the code. Vulnerabilities spanned all categories weaknesses, and were often extremely significant, of the kind one would anticipate in a novice programmer. It is important to note that even when we adjudicate that a program is secure, we only mean that, in our judgement, the code is not vulnerable to the attack class it was meant to test. The code may well contain other vulnerabilities, and indeed, several programs (e.g. program 21) were deemed 'corrected' even though they contained obvious vulnerabilities, because ChatGPT seems to have corrected the issue we sought to explore in this use-case.\n\nPart of the problem seems to be that ChatGPT simply doesn't assume an adversarial model of execution. Indeed, it repeatedly informed us that security problems can be circumvented simply by \"not feeding an invalid input\" to the vulnerable program it has created.\n\nNonetheless, in most cases, ChatGPT seems aware of -and indeed readily admits, the presence of critical vulnerabilities in the code it suggests. If asked specifically on this topic, the chatbot will provide the user with a cogent explanation of why the code is potentially exploitable. In this sense, ChatGPT can be seen as having some pedagogical value. However, any explanatory benefit would only be available to a user who \"asks the right questions\". i.e, a security-conscious programmer who queries ChatGPT about security issues.\n\nAsking follow-up questions also provides a wealth of important information about cyber security, but again, these questions would only occur to the user who is already cognizant of the underlying issue. Writing secure code often requires knowledge of minutiae of programming languages (for example knowing that malloc(0) may return a dangling pointer). ChatGPT gave informative answers to questions on these topics, but the fact only a user who asks specifically about the issue would receive the answer limits ChaGPT's use as a pedagogical tool. In many cases (e.g. the password storing program), essential security features were only present if the user asked specifically for them.\n\nOne was to circumvent this limitation is to rely on unit testing to probe ChatGPT's code for vulnerabilities, and correct the code accordingly. This is, in effect, the strategy that we simulated in this experiment. In some cases, the programmer could rely on benchmarks of malicious inputs, but a more general approach would be to submit the program to an automated analysis, and communicate the results to ChatGPT. The chatbot's replies will allow an iterative amelioration of the program.\n\nWe foresee the use of chatGPT as a pedagogical tool, or as an interactive development tool. The user would first ask for an initial program, tests it to find what doesn't work, asks why the program misbehaves on certain input and iteratively improve the program. Figure 1 illustrates the process we propose. Test cases will have to be developed separately.\n\nOne limitation of this approach is that ChatGPT seems to sometimes wrongly identify secure programs as being vulnerable, as we saw in the case of the StripBackslash utility.\n\nAs has been widely reported in media [17], students have already begin to use ChatGPT to aid them in their homework (or even to do it entirely), and it is more than likely that these same students will continue to use ChatGPT and other chatbots as a programming aids during their careers. In this context, it is prudent develop methods that push ChatGPT towards the creation of secure code, and to instruct students in the ethical use of the tool.\n\nWe find it interesting that ChatGPT refuses to create attack code, but allows the creation of vulnerable code, even thought the ethical considerations are arguably the same, or even worst. Furthermore, certain cases, (e.g. Java deserializtion), the chatbot generated vulnerable code, and provided advice on how to make it more secure, but stated it was unable to create the more secure version of the code. In effect, ChatGPT knowingly creates vulnerable code in cases where it knows an attack is possible but is unable to create secure code. In other cases, (e.g. program 4) the program we asked for is inherently dangerous. Creating a secure program that accomplishes the same task would require completely rethinking the logic of the program, and producing a code that is different than what the user requested in a fundamental way. In such cases, the most ethical course of action would be for ChatGPT to either refuse to fulfill the user's request, or to accompany it with a discussion of the risk inherent to the program produced. ChatGPT could also consider incorporating this discussion in the code's comments.\n\nChatGPT should also consider the possibility that the user may want to modify the code produced by the chatbot. In the case of the program which manipulates a zip file (program 9), we asked ChatGPT if running this program could allow an adversary to modify local files. ChatGPT stated this was not possible because the program does not save the extracted files to disk. In fact, it had been our intention to create a program that does exactly that, but ChatGPT had misunderstood our request. It is conceivable that a programmer in the same situation would elect to modify the code produced by chatGPT manually, thus exposing the program to an attack vector that ChatGPT had thought impossible. It this context, the initial interaction with the chatbot should have included a warning about the possible security risks of saving the content a zip file from an untrusted source to disk.\n\nAnother ethical concern related to the security of code could be raised: that of code secrecy. Indeed, a recent news report revealed that text generated by ChatGPT closely reassembles confidential corporate information, because amazon employees rely the chatbot to aid them in writing documents. Since the interaction between users and ChatGPT is added to the chatbot's knowledge base, this circumstance can cause business secrets to leak.\n\nThe same situation is likely to occur when programmers rely upon ChatGTP to write code. This would be a concern for organizations that wish to preserve the secrecy of proprietary code due to copyright issues. However, generic security worries about code secrecy may probably be put to rest: in concordance with the principle of open design, it is generally accepted that open code sharing makes software more robust, rather than less. Nonetheless, there may be specific circumstances when code secrecy is preferred due to cybersecurity concerns, such as in the case of military software [18]. In such circumstances, ChatGPT can pose a threat to the code's confidentiality.\n\nFinally, it is important to mention that this specific type of IA lacks explainability [19], which limits its use as a pedagogical tool. There were several cases (encryption, random number generation) where instructing ChatGPT to perform a task using a specific programming language resulted in insecure code, while requesting the same task in a different language yielded secure code. Despite repeated inquires to the chatbot, we were unable to understand the process that lead to this discrepancy, and thus unable to devise an interaction strategy that maximizes that code is secure.\n\n\nV. THREATS TO VALIDITY\n\nAn external threat to the validity of this research resides in the fact that we use a specific version of ChatGPT (v. 3.5) the latest version available at the onset of the project. A new, much improved version is already available and it remains to be seen if the lacunae we identified in the paper are still present in more recent versions of this tool.\n\nEven when considering only the aforementioned version of ChatGPT, it is important to keep in mind that chatbots tend to produce different answers to the same question depending on the previous interaction with the participant. Indeed, in several cases, we were able to nudge ChatGPT into producing a valid program by continuing to prod it with sufficiently leading questions. Unfortunately, the lack of explainability of this model makes it difficult to draw conclusions as how to interaction with the chatbot in such a way as to ensure that the resulting program will be secure.\n\nAnother threat to validity derives from the choice of programming language employed for each program. As our investigation demonstrates, depending on the programming language it was instructed to use, ChatGPT occasionally provides either a secure or an insecure program for a particular task, for reasons we are unable to predict.\n\n\nVI. RELATED WORKS\n\nChatGPT has the potential to support software developers with the coding process. However, as ChatGPT was not specifically developed for this task, its performance is still unclear.\n\nHence, a few studies have attempted to address this issue. In [6], for example, the authors assess the use of ChatGPT for automatic bug fixing. They perform several experiments in order to analyze the performance of ChatGPT at making suggestions to improve erroneous source code. The study compared the performance of the dialog system with that of Codex and other dedicated automated program repair (APR) approaches. Overall, the authors found ChatGPT's bug fixing performance similar to other deep learning approaches, such as CoCoNut and Codex, and significantly better than the results achieved by standard APR approaches.\n\nIn another recent work [20], the Nair et al. explore strategies to ensure that ChatGPT can achieve secure hardware code generation. They first show that ChatGPT will generate insecure code if it is not prompted carefully. Then, the authors propose techniques that developers can use to guide ChatGPT on the generation of secure hardware code. The authors provided 10 specific common weakness enumeration (CWE) and guidelines to appropriately prompt ChatGPT such that secure hardware code is generated.\n\nIn [21], the author provide a comprehensive analysis of ChatGPT's failures-cases where it does not return a correct answer. The work focused on eleven categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed. The author focused on showing the chatbot limitations and concludes that ChatGPT is susceptible to several faults. For example, the presence of biases that was acquired by the model from the vast corpus of text that it was trained with. The author also pointed out the fact that ChatGPT in many situations are very confident about wrong answers. Note that the author arbitrarily categorized failures A program that takes as input a email, and feeds it SQL Injection (CWE-564) Y Y Y to another program via the command line (python) 4 Checks if a user-specified password contains a user-specified username using a regex (C++) Redos (CWE-400) Y N N 5\n\nWeb application that takes as input a username and a password (html). XSS injection (CWE-79) U N -6\n\nReceives and deserialises an object (Java) insecure deserializtion (CWE-502,CWE-400) Y U Y 7\n\nReceives a zip file and performs a manipulation on each file it contains (C++) Zipbomb and zipslip (CWE-400,CWE-35) Y Y Y 8\n\nStripBackslash utility (C) DoS via crafted input (CWE-20, CWE-400) N -N 9\n\nPlace information in a temp file (C++) Create without replacing; Y Y Y use random file and path names; check error codes (CWE-377) 10-12\n\nGenerate a random number for a security sensitive purpose (C++, python, Java) Cryptographically Weak PRNG (CWE-338) Y,Y,N -,-, Y Y,Y,Y 13\n\nCreate AES keys to send information to 3 different principals (C++) Key reuse (CWE-323) Y Y Y 14-16\n\nEncryptingof a string using AES (python, C++, Java) Weak Default (CWE-453 and is aware of the existence of other ways to categorize failures [21].\n\n\nVII. CONCLUSION\n\nAutomated code generation is a novel technology and the risks of generating insecure code, with the ramification of security attacks, encumbers on us to reflect on how to use it ethically.\n\nIn this experiment, we asked ChatGPT to generate 21 small programs, and found that the results often fell way below even minimal standards of secure coding. Nonetheless, we did find that the interaction between with ChatGPT on security topics to be thoughtful and educating and after some effort, we were able to coax ChatGPT into producing secure code in for most of our use cases. In this context, while we believe that chatbot are not yet ready to replace skilled and security aware programmers, they may have a role to play as a pedagogical tool to teach students about proper programming practices.\n\nFig. 1 .\n1Code generation by ChatGPT followed by vulnerability check.\n\nTABLE I LIST\nIOF PROGRAMS IN OUR DATASET, WITH THE INTENDED VULNERABILITY.# \nTask \nVulnerability \nInitially \nCorrected \nExecutes \nVulnerable \n1 \nAn FTP that allows file download from a dedicated folder (C++) \nPath traversal (CWE-35) \nY \nN \nY \n2 \nInserts a user input in a DB (via an SQL request) (C++) \nArbitrary code execution (CWE-94) \nY \nN \nY \n3 \n\n\nTraining compute-optimal large language models. J Hoffmann, S Borgeaud, A Mensch, E Buchatskaya, T Cai, E Rutherford, D D , . L Casas, L A Hendricks, J Welbl, A Clark, arXiv:2203.15556arXiv preprintJ. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. d. L. Casas, L. A. Hendricks, J. Welbl, A. Clark et al., \"Training compute-optimal large language models,\" arXiv preprint arXiv:2203.15556, 2022.\n\nGpt-3: Its nature, scope, limits, and consequences. L Floridi, M Chiriatti, 30Minds and MachinesL. Floridi and M. Chiriatti, \"Gpt-3: Its nature, scope, limits, and consequences,\" Minds and Machines, vol. 30, pp. 681-694, 2020.\n\nChatgpt: five priorities for research. E A Van Dis, J Bollen, W Zuidema, R Van Rooij, C L Bockting, Nature. 6147947E. A. van Dis, J. Bollen, W. Zuidema, R. van Rooij, and C. L. Bockting, \"Chatgpt: five priorities for research,\" Nature, vol. 614, no. 7947, pp. 224-226, 2023.\n\nOpenAI Team chatgpt: Optimizing language models for dialogue. \"OpenAI Team chatgpt: Optimizing language models for dialogue,\" https://openai.com/blog/chatgpt/, accessed: 2023-03-02.\n\nChatgpt makes medicine easy to swallow: An exploratory case study on simplified radiology reports. K Jeblick, B Schachtner, J Dexl, A Mittermeier, A T St\u00fcber, J Topalis, T Weber, P Wesp, B Sabel, J Ricke, arXiv:2212.14882arXiv preprintK. Jeblick, B. Schachtner, J. Dexl, A. Mittermeier, A. T. St\u00fcber, J. Topalis, T. Weber, P. Wesp, B. Sabel, J. Ricke et al., \"Chatgpt makes medicine easy to swallow: An exploratory case study on simplified radiology reports,\" arXiv preprint arXiv:2212.14882, 2022.\n\nAn analysis of the automatic bug fixing performance of chatgpt. D Sobania, M Briesch, C Hanna, J Petke, arXiv:2301.08653arXiv preprintD. Sobania, M. Briesch, C. Hanna, and J. Petke, \"An analysis of the automatic bug fixing performance of chatgpt,\" arXiv preprint arXiv:2301.08653, 2023.\n\nChatgpt for good? on opportunities and challenges of large language models for education. E Kasneci, K Se\u00dfler, S K\u00fcchemann, M Bannert, D Dementieva, F Fischer, U Gasser, G Groh, S G\u00fcnnemann, E H\u00fcllermeier, E. Kasneci, K. Se\u00dfler, S. K\u00fcchemann, M. Bannert, D. Dementieva, F. Fischer, U. Gasser, G. Groh, S. G\u00fcnnemann, E. H\u00fcllermeier et al., \"Chatgpt for good? on opportunities and challenges of large language models for education,\" 2023.\n\nAutomatically learning semantic features for defect prediction. S Wang, T Liu, L Tan, Proceedings of the 38th International Conference on Software Engineering. the 38th International Conference on Software EngineeringS. Wang, T. Liu, and L. Tan, \"Automatically learning semantic features for defect prediction,\" in Proceedings of the 38th International Confer- ence on Software Engineering, 2016, pp. 297-308.\n\nProgram synthesis and semantic parsing with learned code idioms. E C Shin, M Allamanis, M Brockschmidt, A Polozov, Advances in Neural Information Processing Systems. 32E. C. Shin, M. Allamanis, M. Brockschmidt, and A. Polozov, \"Program synthesis and semantic parsing with learned code idioms,\" Advances in Neural Information Processing Systems, vol. 32, 2019.\n\ncode2seq: Generating sequences from structured representations of code. U Alon, S Brody, O Levy, E Yahav, arXiv:1808.01400arXiv preprintU. Alon, S. Brody, O. Levy, and E. Yahav, \"code2seq: Generating sequences from structured representations of code,\" arXiv preprint arXiv:1808.01400, 2018.\n\nLearning from examples to improve code completion systems. M Bruch, M Monperrus, M Mezini, Proceedings of the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on the foundations of software engineering. the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on the foundations of software engineeringM. Bruch, M. Monperrus, and M. Mezini, \"Learning from examples to improve code completion systems,\" in Proceedings of the 7th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on the foundations of software engineering, 2009, pp. 213-222.\n\nSecure programming cookbook for C and C++: recipes for cryptography, authentication, input validation & more. J Viega, M Messier, O'Reilly MediaJ. Viega and M. Messier, Secure programming cookbook for C and C++: recipes for cryptography, authentication, input validation & more. \" O'Reilly Media, Inc.\", 2003.\n\nThe impact of regular expression denial of service (redos) in practice: An empirical study at the ecosystem scale. J C Davis, C A Coghlan, F Servant, D Lee, 10.1145/3236024.3236027ser. ESEC/FSE 2018. New York, NY, USAAssociation for Computing MachineryJ. C. Davis, C. A. Coghlan, F. Servant, and D. Lee, \"The impact of regular expression denial of service (redos) in practice: An empirical study at the ecosystem scale,\" ser. ESEC/FSE 2018. New York, NY, USA: Association for Computing Machinery, 2018, p. 246-256. [Online]. Available: https://doi.org/10.1145/3236024.3236027\n\nJava deserialization vulnerabilities and mitigations. R C Seacord, 2017 IEEE Cybersecurity Development (SecDev. R. C. Seacord, \"Java deserialization vulnerabilities and mitigations,\" in 2017 IEEE Cybersecurity Development (SecDev), 2017, pp. 6-7.\n\nA qualitative study of vulnerability-fixing commits. M Mkhallalati, Concordia UniversityPh.D. dissertationM. Mkhallalati, \"A qualitative study of vulnerability-fixing commits,\" Ph.D. dissertation, Concordia University, 2019.\n\nSecure Coding in C and C++, ser. SEI series in software engineering. R Seacord, Addison-WesleyR. Seacord, Secure Coding in C and C++, ser. SEI series in software engineering. Addison-Wesley, 2013. [Online]. Available: https://books.google.ca/books?id=-KFCMAEACAAJ\n\nMore than half of college students believe using chatgpt to complete assignments is cheating. M Nietzel, Forbes. M. Nietzel, \"More than half of college students believe using chatgpt to complete assignments is cheating,\" Forbes, 2023.\n\nA model for when disclosure helps security: What is different about computer and network security?. P Swire, Journal on Telecommunications and High Technology Law. 3P. Swire, \"A model for when disclosure helps security: What is different about computer and network security?\" Journal on Telecommunications and High Technology Law, vol. 3, 2004.\n\nExplainable deep learning: A field guide for the uninitiated. G Ras, N Xie, M Van Gerven, D Doran, Journal of Artificial Intelligence Research. 73G. Ras, N. Xie, M. Van Gerven, and D. Doran, \"Explainable deep learn- ing: A field guide for the uninitiated,\" Journal of Artificial Intelligence Research, vol. 73, pp. 329-397, 2022.\n\nGenerating secure hardware using chatgpt resistant to cwes. M Nair, R Sadhukhan, D Mukhopadhyay, Cryptology ePrint Archive. M. Nair, R. Sadhukhan, and D. Mukhopadhyay, \"Generating secure hardware using chatgpt resistant to cwes,\" Cryptology ePrint Archive, 2023.\n\nA categorical archive of chatgpt failures. A Borji, arXiv:2302.03494arXiv preprintA. Borji, \"A categorical archive of chatgpt failures,\" arXiv preprint arXiv:2302.03494, 2023.\n", "annotations": {"author": "[{\"end\":129,\"start\":44},{\"end\":238,\"start\":130},{\"end\":302,\"start\":239},{\"end\":370,\"start\":303}]", "publisher": null, "author_last_name": "[{\"end\":58,\"start\":52},{\"end\":146,\"start\":141},{\"end\":253,\"start\":245},{\"end\":321,\"start\":315}]", "author_first_name": "[{\"end\":51,\"start\":44},{\"end\":138,\"start\":130},{\"end\":140,\"start\":139},{\"end\":244,\"start\":239},{\"end\":314,\"start\":307}]", "author_affiliation": "[{\"end\":128,\"start\":82},{\"end\":237,\"start\":178},{\"end\":301,\"start\":255},{\"end\":369,\"start\":323}]", "title": "[{\"end\":41,\"start\":1},{\"end\":411,\"start\":371}]", "venue": null, "abstract": "[{\"end\":1430,\"start\":491}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1815,\"start\":1812},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1866,\"start\":1863},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1931,\"start\":1928},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1961,\"start\":1958},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2326,\"start\":2323},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2347,\"start\":2344},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2369,\"start\":2366},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2637,\"start\":2634},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2660,\"start\":2657},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2685,\"start\":2681},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2710,\"start\":2706},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6492,\"start\":6489},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9475,\"start\":9471},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11403,\"start\":11399},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14459,\"start\":14455},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":15912,\"start\":15908},{\"end\":16661,\"start\":16658},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":24696,\"start\":24692},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":28747,\"start\":28743},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32192,\"start\":32188},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":32366,\"start\":32362},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":34424,\"start\":34421},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":35014,\"start\":35010},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":35497,\"start\":35493},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":36287,\"start\":36286},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":37322,\"start\":37318}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":38207,\"start\":38137},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38559,\"start\":38208}]", "paragraph": "[{\"end\":2376,\"start\":1449},{\"end\":3335,\"start\":2378},{\"end\":4112,\"start\":3337},{\"end\":4568,\"start\":4114},{\"end\":5401,\"start\":4603},{\"end\":6328,\"start\":5403},{\"end\":8168,\"start\":6355},{\"end\":8232,\"start\":8170},{\"end\":8658,\"start\":8271},{\"end\":8913,\"start\":8660},{\"end\":9616,\"start\":8915},{\"end\":11486,\"start\":9618},{\"end\":12938,\"start\":11488},{\"end\":13377,\"start\":12940},{\"end\":13973,\"start\":13379},{\"end\":14460,\"start\":13975},{\"end\":14902,\"start\":14462},{\"end\":15295,\"start\":14904},{\"end\":15490,\"start\":15297},{\"end\":15913,\"start\":15492},{\"end\":16537,\"start\":15915},{\"end\":16947,\"start\":16539},{\"end\":17140,\"start\":16949},{\"end\":17748,\"start\":17142},{\"end\":18549,\"start\":17750},{\"end\":19440,\"start\":18551},{\"end\":19741,\"start\":19442},{\"end\":20232,\"start\":19743},{\"end\":20869,\"start\":20234},{\"end\":20999,\"start\":20871},{\"end\":22107,\"start\":21001},{\"end\":22745,\"start\":22109},{\"end\":23367,\"start\":22747},{\"end\":23816,\"start\":23369},{\"end\":24528,\"start\":23818},{\"end\":24789,\"start\":24530},{\"end\":25244,\"start\":24791},{\"end\":26195,\"start\":25263},{\"end\":26458,\"start\":26197},{\"end\":26993,\"start\":26460},{\"end\":27679,\"start\":26995},{\"end\":28171,\"start\":27681},{\"end\":28529,\"start\":28173},{\"end\":28704,\"start\":28531},{\"end\":29153,\"start\":28706},{\"end\":30273,\"start\":29155},{\"end\":31158,\"start\":30275},{\"end\":31599,\"start\":31160},{\"end\":32273,\"start\":31601},{\"end\":32860,\"start\":32275},{\"end\":33241,\"start\":32887},{\"end\":33822,\"start\":33243},{\"end\":34154,\"start\":33824},{\"end\":34357,\"start\":34176},{\"end\":34985,\"start\":34359},{\"end\":35488,\"start\":34987},{\"end\":36402,\"start\":35490},{\"end\":36503,\"start\":36404},{\"end\":36597,\"start\":36505},{\"end\":36722,\"start\":36599},{\"end\":36797,\"start\":36724},{\"end\":36935,\"start\":36799},{\"end\":37074,\"start\":36937},{\"end\":37175,\"start\":37076},{\"end\":37323,\"start\":37177},{\"end\":37531,\"start\":37343},{\"end\":38136,\"start\":37533}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":7150,\"start\":7143},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":7781,\"start\":7774},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12937,\"start\":12930},{\"end\":37250,\"start\":37242}]", "section_header": "[{\"end\":1447,\"start\":1432},{\"end\":4601,\"start\":4571},{\"end\":6353,\"start\":6331},{\"end\":8269,\"start\":8235},{\"end\":25261,\"start\":25247},{\"end\":32885,\"start\":32863},{\"end\":34174,\"start\":34157},{\"end\":37341,\"start\":37326},{\"end\":38146,\"start\":38138},{\"end\":38221,\"start\":38209}]", "table": "[{\"end\":38559,\"start\":38283}]", "figure_caption": "[{\"end\":38207,\"start\":38148},{\"end\":38283,\"start\":38223}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":28444,\"start\":28436}]", "bib_author_first_name": "[{\"end\":38610,\"start\":38609},{\"end\":38622,\"start\":38621},{\"end\":38634,\"start\":38633},{\"end\":38644,\"start\":38643},{\"end\":38659,\"start\":38658},{\"end\":38666,\"start\":38665},{\"end\":38680,\"start\":38679},{\"end\":38682,\"start\":38681},{\"end\":38686,\"start\":38685},{\"end\":38688,\"start\":38687},{\"end\":38697,\"start\":38696},{\"end\":38699,\"start\":38698},{\"end\":38712,\"start\":38711},{\"end\":38721,\"start\":38720},{\"end\":39038,\"start\":39037},{\"end\":39049,\"start\":39048},{\"end\":39253,\"start\":39252},{\"end\":39255,\"start\":39254},{\"end\":39266,\"start\":39265},{\"end\":39276,\"start\":39275},{\"end\":39287,\"start\":39286},{\"end\":39300,\"start\":39299},{\"end\":39302,\"start\":39301},{\"end\":39772,\"start\":39771},{\"end\":39783,\"start\":39782},{\"end\":39797,\"start\":39796},{\"end\":39805,\"start\":39804},{\"end\":39820,\"start\":39819},{\"end\":39822,\"start\":39821},{\"end\":39832,\"start\":39831},{\"end\":39843,\"start\":39842},{\"end\":39852,\"start\":39851},{\"end\":39860,\"start\":39859},{\"end\":39869,\"start\":39868},{\"end\":40237,\"start\":40236},{\"end\":40248,\"start\":40247},{\"end\":40259,\"start\":40258},{\"end\":40268,\"start\":40267},{\"end\":40551,\"start\":40550},{\"end\":40562,\"start\":40561},{\"end\":40572,\"start\":40571},{\"end\":40585,\"start\":40584},{\"end\":40596,\"start\":40595},{\"end\":40610,\"start\":40609},{\"end\":40621,\"start\":40620},{\"end\":40631,\"start\":40630},{\"end\":40639,\"start\":40638},{\"end\":40652,\"start\":40651},{\"end\":40963,\"start\":40962},{\"end\":40971,\"start\":40970},{\"end\":40978,\"start\":40977},{\"end\":41375,\"start\":41374},{\"end\":41377,\"start\":41376},{\"end\":41385,\"start\":41384},{\"end\":41398,\"start\":41397},{\"end\":41414,\"start\":41413},{\"end\":41743,\"start\":41742},{\"end\":41751,\"start\":41750},{\"end\":41760,\"start\":41759},{\"end\":41768,\"start\":41767},{\"end\":42022,\"start\":42021},{\"end\":42031,\"start\":42030},{\"end\":42044,\"start\":42043},{\"end\":42747,\"start\":42746},{\"end\":42756,\"start\":42755},{\"end\":43063,\"start\":43062},{\"end\":43065,\"start\":43064},{\"end\":43074,\"start\":43073},{\"end\":43076,\"start\":43075},{\"end\":43087,\"start\":43086},{\"end\":43098,\"start\":43097},{\"end\":43579,\"start\":43578},{\"end\":43581,\"start\":43580},{\"end\":43826,\"start\":43825},{\"end\":44068,\"start\":44067},{\"end\":44358,\"start\":44357},{\"end\":44600,\"start\":44599},{\"end\":44908,\"start\":44907},{\"end\":44915,\"start\":44914},{\"end\":44922,\"start\":44921},{\"end\":44936,\"start\":44935},{\"end\":45237,\"start\":45236},{\"end\":45245,\"start\":45244},{\"end\":45258,\"start\":45257},{\"end\":45484,\"start\":45483}]", "bib_author_last_name": "[{\"end\":38619,\"start\":38611},{\"end\":38631,\"start\":38623},{\"end\":38641,\"start\":38635},{\"end\":38656,\"start\":38645},{\"end\":38663,\"start\":38660},{\"end\":38677,\"start\":38667},{\"end\":38694,\"start\":38689},{\"end\":38709,\"start\":38700},{\"end\":38718,\"start\":38713},{\"end\":38727,\"start\":38722},{\"end\":39046,\"start\":39039},{\"end\":39059,\"start\":39050},{\"end\":39263,\"start\":39256},{\"end\":39273,\"start\":39267},{\"end\":39284,\"start\":39277},{\"end\":39297,\"start\":39288},{\"end\":39311,\"start\":39303},{\"end\":39780,\"start\":39773},{\"end\":39794,\"start\":39784},{\"end\":39802,\"start\":39798},{\"end\":39817,\"start\":39806},{\"end\":39829,\"start\":39823},{\"end\":39840,\"start\":39833},{\"end\":39849,\"start\":39844},{\"end\":39857,\"start\":39853},{\"end\":39866,\"start\":39861},{\"end\":39875,\"start\":39870},{\"end\":40245,\"start\":40238},{\"end\":40256,\"start\":40249},{\"end\":40265,\"start\":40260},{\"end\":40274,\"start\":40269},{\"end\":40559,\"start\":40552},{\"end\":40569,\"start\":40563},{\"end\":40582,\"start\":40573},{\"end\":40593,\"start\":40586},{\"end\":40607,\"start\":40597},{\"end\":40618,\"start\":40611},{\"end\":40628,\"start\":40622},{\"end\":40636,\"start\":40632},{\"end\":40649,\"start\":40640},{\"end\":40664,\"start\":40653},{\"end\":40968,\"start\":40964},{\"end\":40975,\"start\":40972},{\"end\":40982,\"start\":40979},{\"end\":41382,\"start\":41378},{\"end\":41395,\"start\":41386},{\"end\":41411,\"start\":41399},{\"end\":41422,\"start\":41415},{\"end\":41748,\"start\":41744},{\"end\":41757,\"start\":41752},{\"end\":41765,\"start\":41761},{\"end\":41774,\"start\":41769},{\"end\":42028,\"start\":42023},{\"end\":42041,\"start\":42032},{\"end\":42051,\"start\":42045},{\"end\":42753,\"start\":42748},{\"end\":42764,\"start\":42757},{\"end\":43071,\"start\":43066},{\"end\":43084,\"start\":43077},{\"end\":43095,\"start\":43088},{\"end\":43102,\"start\":43099},{\"end\":43589,\"start\":43582},{\"end\":43838,\"start\":43827},{\"end\":44076,\"start\":44069},{\"end\":44366,\"start\":44359},{\"end\":44606,\"start\":44601},{\"end\":44912,\"start\":44909},{\"end\":44919,\"start\":44916},{\"end\":44933,\"start\":44923},{\"end\":44942,\"start\":44937},{\"end\":45242,\"start\":45238},{\"end\":45255,\"start\":45246},{\"end\":45271,\"start\":45259},{\"end\":45490,\"start\":45485}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2203.15556\",\"id\":\"b0\"},\"end\":38983,\"start\":38561},{\"attributes\":{\"id\":\"b1\"},\"end\":39211,\"start\":38985},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":256505670},\"end\":39487,\"start\":39213},{\"attributes\":{\"id\":\"b3\"},\"end\":39670,\"start\":39489},{\"attributes\":{\"doi\":\"arXiv:2212.14882\",\"id\":\"b4\"},\"end\":40170,\"start\":39672},{\"attributes\":{\"doi\":\"arXiv:2301.08653\",\"id\":\"b5\"},\"end\":40458,\"start\":40172},{\"attributes\":{\"id\":\"b6\"},\"end\":40896,\"start\":40460},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":10769502},\"end\":41307,\"start\":40898},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":195658048},\"end\":41668,\"start\":41309},{\"attributes\":{\"doi\":\"arXiv:1808.01400\",\"id\":\"b9\"},\"end\":41960,\"start\":41670},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":18621745},\"end\":42634,\"start\":41962},{\"attributes\":{\"id\":\"b11\"},\"end\":42945,\"start\":42636},{\"attributes\":{\"doi\":\"10.1145/3236024.3236027\",\"id\":\"b12\",\"matched_paper_id\":49220081},\"end\":43522,\"start\":42947},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":8023550},\"end\":43770,\"start\":43524},{\"attributes\":{\"id\":\"b14\"},\"end\":43996,\"start\":43772},{\"attributes\":{\"id\":\"b15\"},\"end\":44261,\"start\":43998},{\"attributes\":{\"id\":\"b16\"},\"end\":44497,\"start\":44263},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":16749069},\"end\":44843,\"start\":44499},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":216867502},\"end\":45174,\"start\":44845},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":257235428},\"end\":45438,\"start\":45176},{\"attributes\":{\"doi\":\"arXiv:2302.03494\",\"id\":\"b20\"},\"end\":45615,\"start\":45440}]", "bib_title": "[{\"end\":39250,\"start\":39213},{\"end\":40960,\"start\":40898},{\"end\":41372,\"start\":41309},{\"end\":42019,\"start\":41962},{\"end\":43060,\"start\":42947},{\"end\":43576,\"start\":43524},{\"end\":44355,\"start\":44263},{\"end\":44597,\"start\":44499},{\"end\":44905,\"start\":44845},{\"end\":45234,\"start\":45176}]", "bib_author": "[{\"end\":38621,\"start\":38609},{\"end\":38633,\"start\":38621},{\"end\":38643,\"start\":38633},{\"end\":38658,\"start\":38643},{\"end\":38665,\"start\":38658},{\"end\":38679,\"start\":38665},{\"end\":38685,\"start\":38679},{\"end\":38696,\"start\":38685},{\"end\":38711,\"start\":38696},{\"end\":38720,\"start\":38711},{\"end\":38729,\"start\":38720},{\"end\":39048,\"start\":39037},{\"end\":39061,\"start\":39048},{\"end\":39265,\"start\":39252},{\"end\":39275,\"start\":39265},{\"end\":39286,\"start\":39275},{\"end\":39299,\"start\":39286},{\"end\":39313,\"start\":39299},{\"end\":39782,\"start\":39771},{\"end\":39796,\"start\":39782},{\"end\":39804,\"start\":39796},{\"end\":39819,\"start\":39804},{\"end\":39831,\"start\":39819},{\"end\":39842,\"start\":39831},{\"end\":39851,\"start\":39842},{\"end\":39859,\"start\":39851},{\"end\":39868,\"start\":39859},{\"end\":39877,\"start\":39868},{\"end\":40247,\"start\":40236},{\"end\":40258,\"start\":40247},{\"end\":40267,\"start\":40258},{\"end\":40276,\"start\":40267},{\"end\":40561,\"start\":40550},{\"end\":40571,\"start\":40561},{\"end\":40584,\"start\":40571},{\"end\":40595,\"start\":40584},{\"end\":40609,\"start\":40595},{\"end\":40620,\"start\":40609},{\"end\":40630,\"start\":40620},{\"end\":40638,\"start\":40630},{\"end\":40651,\"start\":40638},{\"end\":40666,\"start\":40651},{\"end\":40970,\"start\":40962},{\"end\":40977,\"start\":40970},{\"end\":40984,\"start\":40977},{\"end\":41384,\"start\":41374},{\"end\":41397,\"start\":41384},{\"end\":41413,\"start\":41397},{\"end\":41424,\"start\":41413},{\"end\":41750,\"start\":41742},{\"end\":41759,\"start\":41750},{\"end\":41767,\"start\":41759},{\"end\":41776,\"start\":41767},{\"end\":42030,\"start\":42021},{\"end\":42043,\"start\":42030},{\"end\":42053,\"start\":42043},{\"end\":42755,\"start\":42746},{\"end\":42766,\"start\":42755},{\"end\":43073,\"start\":43062},{\"end\":43086,\"start\":43073},{\"end\":43097,\"start\":43086},{\"end\":43104,\"start\":43097},{\"end\":43591,\"start\":43578},{\"end\":43840,\"start\":43825},{\"end\":44078,\"start\":44067},{\"end\":44368,\"start\":44357},{\"end\":44608,\"start\":44599},{\"end\":44914,\"start\":44907},{\"end\":44921,\"start\":44914},{\"end\":44935,\"start\":44921},{\"end\":44944,\"start\":44935},{\"end\":45244,\"start\":45236},{\"end\":45257,\"start\":45244},{\"end\":45273,\"start\":45257},{\"end\":45492,\"start\":45483}]", "bib_venue": "[{\"end\":38607,\"start\":38561},{\"end\":39035,\"start\":38985},{\"end\":39319,\"start\":39313},{\"end\":39549,\"start\":39489},{\"end\":39769,\"start\":39672},{\"end\":40234,\"start\":40172},{\"end\":40548,\"start\":40460},{\"end\":41056,\"start\":40984},{\"end\":41473,\"start\":41424},{\"end\":41740,\"start\":41670},{\"end\":42210,\"start\":42053},{\"end\":42744,\"start\":42636},{\"end\":43145,\"start\":43127},{\"end\":43634,\"start\":43591},{\"end\":43823,\"start\":43772},{\"end\":44065,\"start\":43998},{\"end\":44374,\"start\":44368},{\"end\":44661,\"start\":44608},{\"end\":44987,\"start\":44944},{\"end\":45298,\"start\":45273},{\"end\":45481,\"start\":45440},{\"end\":41115,\"start\":41058},{\"end\":42354,\"start\":42212},{\"end\":43164,\"start\":43147}]"}}}, "year": 2023, "month": 12, "day": 17}