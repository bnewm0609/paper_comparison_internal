{"id": 244346239, "updated": "2023-11-08 15:15:06.352", "metadata": {"title": "ClipCap: CLIP Prefix for Image Captioning", "authors": "[{\"first\":\"Ron\",\"last\":\"Mokady\",\"middle\":[]},{\"first\":\"Amir\",\"last\":\"Hertz\",\"middle\":[]},{\"first\":\"Amit\",\"last\":\"Bermano\",\"middle\":[\"H.\"]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Image captioning is a fundamental task in vision-language understanding, where the model predicts a textual informative caption to a given input image. In this paper, we present a simple approach to address this task. We use CLIP encoding as a prefix to the caption, by employing a simple mapping network, and then fine-tunes a language model to generate the image captions. The recently proposed CLIP model contains rich semantic features which were trained with textual context, making it best for vision-language perception. Our key idea is that together with a pre-trained language model (GPT2), we obtain a wide understanding of both visual and textual data. Hence, our approach only requires rather quick training to produce a competent captioning model. Without additional annotations or pre-training, it efficiently generates meaningful captions for large-scale and diverse datasets. Surprisingly, our method works well even when only the mapping network is trained, while both CLIP and the language model remain frozen, allowing a lighter architecture with less trainable parameters. Through quantitative evaluation, we demonstrate our model achieves comparable results to state-of-the-art methods on the challenging Conceptual Captions and nocaps datasets, while it is simpler, faster, and lighter. Our code is available in https://github.com/rmokady/CLIP_prefix_caption.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2111.09734", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2111-09734", "doi": null}}, "content": {"source": {"pdf_hash": "a7aa150b55d64d339b1c154d6d88455fc3cbc44f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.09734v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "410e90f95038e107dd23c39f3c12e2f4503f7590", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a7aa150b55d64d339b1c154d6d88455fc3cbc44f.txt", "contents": "\nClipCap: CLIP Prefix for Image Captioning\n\n\nRon Mokady \nThe Blavatnik School of Computer Science\nTel Aviv University\n\n\nAmir Hertz \nThe Blavatnik School of Computer Science\nTel Aviv University\n\n\nAmit H Bermano \nThe Blavatnik School of Computer Science\nTel Aviv University\n\n\nClipCap: CLIP Prefix for Image Captioning\n\nImage captioning is a fundamental task in visionlanguage understanding, where the model predicts a textual informative caption to a given input image. In this paper, we present a simple approach to address this task. We use CLIP encoding as a prefix to the caption, by employing a simple mapping network, and then fine-tunes a language model to generate the image captions. The recently proposed CLIP model contains rich semantic features which were trained with textual context, making it best for vision-language perception. Our key idea is that together with a pre-trained language model (GPT2), we obtain a wide understanding of both visual and textual data. Hence, our approach only requires rather quick training to produce a competent captioning model. Without additional annotations or pre-training, it efficiently generates meaningful captions for large-scale and diverse datasets. Surprisingly, our method works well even when only the mapping network is trained, while both CLIP and the language model remain frozen, allowing a lighter architecture with less trainable parameters. Through quantitative evaluation, we demonstrate our model achieves comparable results to state-of-the-art methods on the challenging Conceptual Captions and nocaps datasets, while it is simpler, faster, and lighter. Our code is available in https://github. com/rmokady/CLIP_prefix_caption. arXiv:2111.09734v1 [cs.CV] 18 Nov 2021 CLIP \"A cat is sleeping on top of a blanket on a bed.\" Const.GPT2Prefix embeddingsCaption tokens Mapping NetworkFigure 2. Overview of our transformer-based architecture, enabling the generation of meaningful captions while both CLIP and the language model, GPT-2, are frozen. To extract a fixed length prefix, we train a lightweight transformer-based mapping network from the CLIP embedding space and a learned constant to GPT-2. At inference, we employ GPT-2 to generate the caption given the prefix embeddings. We also suggest a MLP-based architecture, refer to Sec. 3 for more details.\n\nIntroduction\n\nIn image captioning, the task is to provide a meaningful and valid caption for a given input image in a natural language. This task poses two main challenges. The first is semantic understanding. This aspect ranges from simple tasks such as detecting the main object, to more involved ones, such as understanding the relations between depicted parts of the image. For example, in the top-left image of Fig. 1, the model understands that the object is a gift. The second challenge is the large number of possible ways to describe a single image. In this aspect, the training dataset typically dictates the preferable option for a given image. * Equal contribution.\n\nA politician receives a gift from politician.\n\nA collage of different colored ties on a white background.\n\nSilhouette of a woman practicing yoga on the beach at sunset.\n\nAerial view of a road in autumn. Many approaches have been proposed for image captioning [4,9,13,19,34,35,42,44,47]. Typically, these works utilize an encoder for visual cues and a textual decoder to produce the final caption. Essentially, this induces the need to bridge the challenging gap between the visual and textual representations. For this reason, such models are resource hungry. They require extensive training time, a large number of trainable parameters, a massive dataset, and in some cases even additional annotations (such as detection results), which limit their practical applicability.\n\nExcessive training time is even more restrictive for applications that require several training procedures. For instance, training multiple captioning models over various datasets could provide different users (or applications) with different captions for the same image. Additionally, given fresh samples, it is desirable to update the model routinely with the new data. Therefore, a lightweight captioning model is preferable. Specifically, a model with faster training times and fewer trainable parameters would be beneficial, especially if it does not require additional supervision.\n\nIn this paper, we leverage powerful vision-language pretrained models to simplify the captioning process. More specifically, we use the CLIP (Contrastive Language-Image Pre-Training) encoder, recently introduced by Radford et al. [29]. CLIP is designed to impose a shared representation for both images and text prompts. It is trained over a vast number of images and textual descriptions using a contrastive loss. Hence, its visual and textual representations are well correlated. As we demonstrate, this correlation saves training time and data requirements.\n\nAs illustrated in Fig. 2, our method produces a prefix for each caption by applying a mapping network over the CLIP embedding. This prefix is a fixed size embeddings sequence, concatenated to the caption embeddings. These are fed to a language model, which is fine-tuned along with the mapping network training. At inference, the language model generates the caption word after word, starting from the CLIP prefix. This scheme narrows the aforementioned gap between the visual and textual worlds, allowing the employment of a simple mapping network. To achieve even a lighter model, we introduce another variant of our method, where we train only the mapping network, while both CLIP and the language model are kept frozen. By utilizing the expressive transformer architecture, we successfully produce meaningful captions, while imposing substantially less trainable parameters. Our approach is inspired by Li et al. [20], which demonstrates the ability to efficiently adapt a language model for new tasks by concatenating a learned prefix. We use GPT-2 [30] as our language model, which has been demonstrated to generate rich and diverse texts.\n\nAs our approach exploits the rich visual-textual representation of CLIP, our model requires significantly lower training time. For instance, we train our model on a single Nvidia GTX1080 GPU for 80 hours over the three million samples of the massive Conceptual Captions dataset. Nevertheless, our model generalizes well to complex scenes, as can be seen in Fig. 1 (e.g., practicing yoga on the beach at sunset). We evaluate our method extensively, demonstrating successful realistic and meaningful captions. Even though our model requires less training time, it still achieves comparable results to state-of-the-art approaches over the challenging Conceptual Captions [33] and nocaps [1] datasets, and marginally lower for the more restricted COCO [7,22] benchmark. In addition, we provide a thorough analysis of the required prefix length and the effect of fine-tuning the language model, including interpretation of our produced prefixes. Overall, our main contributions are as follow:\n\n\u2022 A lightweight captioning approach that utilizes pretrained frozen models for both visual and textual processing.\n\n\u2022 Even when the language model is fine-tuned, our approach is simpler and faster to train, while demonstrating comparable results to state-of-the-art over challenging datasets.\n\n\nRelated Works\n\nRecently, Radford et al. [29] presented a novel approach, known as CLIP, to jointly represent images and text descriptions. CLIP comprises two encoders, one for visual cues and one for text. It was trained over more than 400 million image-text pairs guided by unsupervised contrastive loss, resulting in rich semantic latent space shared by both visual and textual data. Many works have already used CLIP successfully for computer vision tasks that require the understanding of some auxiliary text, such as generating or editing an image based on a natural language condition [5,14,28]. In this paper, we utilize the powerful CLIP model for the task of image captioning. Note that our method does not employ the CLIP's textual encoder, since there is no input text, and the output text is generated by a language model.\n\nCommonly, image captioning [34] models first encode the input pixels as feature vectors, which are then used to produce the final sequence of words. Early works utilize the features extracted from a pre-trained classification network [6,9,13,42], while later works [4,19,47] exploit the more expressive features of an object detection network [31]. Though a pre-trained object detection network is available for the popular COCO benchmark [7,22], it is not necessarily true for other datasets. This implies that most methods would require additional object detection annotations to operate over new and diverse datasets. To further leverage the visual cues, an attention mechanism is usually utilized [4,6,42] to focus on specific visual features. Moreover, recent models apply self-attention [16,43] or use an expressive visual Transformer [12] as an encoder [23]. Our work uses the expressive embedding of CLIP for visual representation. Since CLIP was trained over an extremely large number of images, we can operate on any set of natural images without additional annotations.\n\nTo produce the caption itself, a textual decoder is employed. Early works have used LSTM variants [8,38,39], while recent works [16,26] adopted the improved transformer architecture [36]. Built upon the transformer, one of the most notable works is BERT [11], demonstrating the dominance of the newly introduced paradigm. With this paradigm, the language model is first pre-trained over a large data collection to solve an auxiliary task. Then, the model is fine-tuned for a specific task, where additional supervision is used. As our visual information resides in the prefix, we utilize a powerful auto-regressive language model, GPT-2 [30]. Considering the training loss term, earlier works adopt the effective cross-entropy, while contemporary methods also apply self-critical sequence training [15,32,45]. That is, an additional training stage to optimize the CIDEr metric. We deliberately refrain from this optimization to retain a quick training procedure.\n\nMost close to ours, are works that employ vision-andlanguage pre-training to create a shared latent space of both vision and text [19,25,35,46,47]. Zhou et al. [47] use visual tokens extracted from object detector as a prefix to caption tokens. The entire model is then pre-trained to perform prediction utilizing the BERT [11] architecture. Li et al. [19] and Zhang et al. [46] also utilize BERT, but require the additional supervision of object tags. Hence, these methods are limited to datasets in which such object detectors or annotations are available. The approach of Wang et al. [40] mitigate the need for supplementary annotations, but still perform an extensive pre-train process with millions of imagetext pairs, resulting in a lengthy training time. This exhaustive pre-training step is required to compensate for the lack of joint representation of language and vision, which we inherently obtained by employing CLIP.\n\n\nMethod\n\nWe start with our problem statement. Given a dataset of paired images and captions {x i , c i } N i=1 , our goal is to learn the generation of a meaningful caption for an unseen input image. We can refer to the captions as a sequence of tokens c i = c i 1 , . . . , c i , where we pad the tokens to a maximal length . Our training objective is then the following:\nmax \u03b8 N i=1 log p \u03b8 (c i 1 , . . . , c i | x i ),(1)\nwhere \u03b8 denotes the model's trainable parameters. Our key idea is to use the rich semantic embedding of CLIP, which contains, virtually, the essential visual data, as a condition. Following recent works [47], we consider the condition as a prefix to the caption. Since the required semantic information is encapsulated in the prefix, we can utilize an autoregressive language model that predicts the next token without considering future tokens. Thus, our objective can be described as:\nmax \u03b8 N i=1 j=1 log p \u03b8 (c i j | x i , c i 1 , . . . , c i j\u22121 )(2)\n\nOverview\n\nAn illustration of our method is provided in Fig. 2. We use GPT-2 (large) as our language model, and utilize its tokenizer to project the caption to a sequence of embeddings. To extract visual information from an image x i , we use the visual encoder of a pre-trained CLIP [29] model. Next, we employ a light mapping network, denoted F , to map the CLIP embedding to k embedding vectors:\np i 1 , . . . , p i k = F (CLIP(x i )).(3)\nWhere each vector p i j has the same dimension as a word embedding. We then concatenate the obtained visual embedding to the caption c i embeddings:\nZ i = p i 1 , . . . , p i k , c i 1 , . . . , c i .(4)\nDuring training, we feed the language model with the prefix-caption concatenation\n{Z i } N i=1 .\nOur training objective is predicting the caption tokens conditioned on the prefix in an autoregressive fashion. To this purpose, we train the mapping component F using the simple, yet effective, cross-entropy loss:\nL X = \u2212 N i=1 j=1 log p \u03b8 (c i j | p i 1 , . . . , p i k , c i 1 , . . . , c i j\u22121 ). (5)\nWe now turn to discuss two variants of our method regarding the additional fine-tuning of the language model and their implications.\n\n\nLanguage model fine-tuning\n\nOur main challenge during training is to translate between the representations of CLIP and the language model. Even though both models develop a rich and diverse representation of text, their latent spaces are independent, as they were not jointly trained. Moreover, each captioning dataset incorporates a different style, which may not be natural for the pre-trained language model. Hence, we propose fine-tuning the language model during the training of the mapping network. This provides additional flexibility for the networks and yields a more expressive outcome.\n\nHowever, fine-tuning the language model naturally increases the number of trainable parameters substantially. Thus, we present an additional variant of our approach, in which we keep the language model fixed during training. Our attempt to adjust a frozen language model is inspired by the work of Li and Liang [20]. In their work, they accommodate such a pre-trained model to an unfamiliar task by learning only a prefix. Such prefix is automatically optimized to steer the language model towards the new objective during a standard training procedure. Following this approach, we suggest avoiding the fine-tuning to realize an even lighter model, where only the mapping network is trained. As presented in Section 4, our model not only produces realistic and meaningful captions, but also achieves superior results for some of the experiments without finetuning the language model. Note that fine-tuning CLIP does not benefit resulting quality, but does increase training time and complexity. We hence postulate that the CLIP space already encapsulates the required information, and adapting it towards specific styles does not contribute to flexibility.\n\n\nMapping Network Architecture\n\nOur key component is the mapping network, which translates the CLIP embedding to the GPT-2 space. When the language model is simultaneously fine-tuned, the mapping is less challenging, as we easily control both networks. Therefore, in this case, we can employ a simple Multi-Layer Perceptron (MLP). We have achieved realistic and meaningful captions even when utilizing only a single hidden layer, as CLIP is pre-trained for a vision-language objective.\n\nNevertheless, when the language model is frozen, we propose utilizing the more expressive transformer [36] architecture. The transformer enables global attention between input tokens while reducing the number of parameters for long sequences. This allows us to improve our results by increasing prefix size, as shown in Section. 4. We feed the transformer network with two inputs, the visual encoding of CLIP and a learned constant input. The constant has a dual role, first, to retrieve meaningful information from CLIP embedding through the multi-head attention. Second, it learns to adjust the fixed language model to the new data. This is demonstrated in Section. 4, where we offer interpretability for our generated prefix. As can be seen, when the language model is fixed, the transformer mapping network learns a meticulous set of embeddings without any textual meaning. These are optimized to tame the language model.\n\n\nInference\n\nDuring inference, we extract the visual prefix of an input image x using the CLIP encoder and the mapping network F . We start generating the caption conditioned on the visual prefix, and predict the next tokens one by one, guided by the language model output. For each token, the language model outputs probabilities for all vocabulary tokens, which are used to determine the next one by employing a greedy approach or beam search.\n\n\nResults\n\nDatasets. We use the COCO-captions [7,22], nocaps [1] , and Conceptual Captions [33] datasets. We split the former according to the Karpathy et al. [17] split, where the training set contains 120, 000 images and 5 captions per image. Since COCO is limited to 80 classes, the nocaps dataset is designed to measure generalization to unseen classes and concepts. It contains only validation and test sets, with the training utilizing COCO itself. The nocaps dataset is divided to three parts -in-domain contains images portraying only COCO classes, near-domain contains both COCO and novel classes, and out-of-domain consists of only novel classes. As suggested by Li et al. [19], we evaluate the model using only the validation set. Though some methods utilize object tags of the novel classes, we only consider the setting of no additional supervision, as we find it more applicable in practice. Therefore, we do not employ a constrained beam search [2]. The Conceptual Captions dataset consists of 3M pairs of images and captions, harvested from the web and post-processed. It is considered to be more challenging than COCO due to the larger variety of styles of both the images and the captions, while not limited to specific classes. To focus on the concepts, specific entities in this dataset are replaced with general notions. For example, in Fig. 1, the names are replaced with \"politician\". For evaluation, we use the validation set, consisting of 12.5K images, as the test set is not publicly available. Consequently, we did not use this set for validation.\n\nBaselines. We compare our method to the state-of-the-art works of Li et al. [19] (known as Oscar), Vision-Language Pre-training model (VLP) [47], and the eminent work of Anderson et al. [4], denoted BUTD. These models first produce visual features using an object detection network [31]. BUTD then utilizes an LSTM to generate the captions, while VLP and Oscar employ a transformer, trained simi-  Photograph of the sign being repaired by brave person.\n\nGlobes : the green 3d person carrying in hands globe.\n\nThe player staring intently at a computer screen.\n\nThe -bedroom stone cottage can sleep people. VLP Actors in a scene from the movie.\n\nThe sign at the entrance. Templates: green cartoon character holding the earth globe.\n\nPerson works on a video.\n\nThe master bedroom has a king -sized bed with a queen size bed. Ours; MLP + GPT2 tuning Actor sits in a hotel room.\n\nThe sign at the entrance. 3d render of a man holding a globe.\n\nPerson, a student, watches a video on his laptop.\n\nThe property is on the market for \u00a3 1.\n\nOurs; Transformer person sitting on a chair in a room.\n\na sign is seen at the entrance to the store.\n\nstock image of a man holding the earth.\n\nportrait of a young boy playing video game.\n\none of the bedrooms in the house has been converted into a living room. Figure 4. Uncurated results of the first five images in our test set for Conceptual Captions [33].\n\nA person standing in front of a rock formation in the desert.\n\nA man holding a banana in front of a river.\n\nTwo horned goats crossing a road in the desert.\n\nA person sitting at a table with a tray of sushi. larly to BERT [11]. Both VLP and Oscar exploit an extensive pre-trained procedure over millions of image-text pairs. Oscar [19] also uses additional supervision compared to our setting, in the form of object tags for each image.\n\nOur default configuration employs the transformer mapping network, without fine-tuning the language model, denoted Ours; Transformer. Additionally, we also evaluate our variant that utilizes the MLP mapping network, and fine-tunes the language model, denoted Ours; MLP + GPT2 tuning. Other configurations are evaluated in Tab. 1(D).\n\nEvaluation metrics. Similar to Li et al. [19], we validate our results over the COCO dataset using the common metrics BLEU [27], METEOR [10], CIDEr [37] and SPICE [3], and for the nocaps dataset using CIDEr and SPICE. For the Conceptual Captions, we report the ROUGE-L [21], CIDEr, and SPICE, as suggested by the authors [33].\n\nFurthermore, we measure the training time and the number of trainable parameters to validate the applicability of our method. Reducing the training time allows to quickly obtain a new model for new data, create an ensemble of models, and decrease energy consumption. Similar to other works, we report training time in GPU hours, and the GPU model used. The number of trainable parameters is a popular measure to indicate model feasibility.\n\nQuantitative evaluation. Quantitative results for the challenging Conceptual Captions dataset are presented in Tab. 1(A). As can be seen, we surpass the results of VLP, while requiring orders of magnitude less training time. We note that our lightweight model, which does not fine-tune GPT-2, achieves an inferior result for this dataset. We hypothesize that due to the large variety of styles, a more expressive model is required than our light model, which induces a significantly lower parameter count. We compare only to VLP, as the other baselines haven't published results nor trained models for this dataset.\n\nTab. 1(B) presents results for the nocaps dataset, where we achieve comparable results to the state-of-the-art method Oscar. As can be seen, Oscar achieves a slightly better SPICE score and we attain a slightly better CIDEr score. Still, our method uses a fraction of training time and trainable parameters with no additional object tags required, hence it is much more useful in practice.\n\n\nGPT-2 tuning\n\nCaption a motorcycle is on display in a showroom.  Figure 6. Prefix Interpretability. We present both the generated caption and our prefix interpretation. Upper: Ours; MLP + GPT2 tuning. Bottom: Ours; Transformer.\n\nTab. 1(C) present the results for the COCO dataset. Oscar reaches the best results, however, it uses additional input in the form of object tags. Our results are closed to VLP and BUTD which utilize considerably more parameters and training time. Note that the training time of VLP and Oscar does not include the pre-training step. For instance, pretraining of VLP requires training over Conceptual Captions which consumes 1200 GPU hours.\n\nBoth Conceptual Captions and nocaps are designed to model a larger variety of visual concepts than COCO. Therefore, we conclude our method is preferable for generalizing to diverse data using a quick training procedure. This originates from utilizing the already rich semantic representations of both CLIP and GPT-2.\n\nQualitative evaluation. Visual results of the uncurated first examples in our test sets of both Conceptual Captions and COCO datasets are presented in Figs. 3 and 4 respectively. As can be seen, our generated captions are meaningful and depict the image successfully for both datasets. We present additional examples collected from the web in Fig. 1. As can be seen, our Conceptual Captions model generalizes well to arbitrary unseen images as it was trained over a sizable and diverse set of images. We also present in Fig. 5 results over smartphone images, to further demonstrate generalization to new scenarios. Moreover, our model successfully identifies uncommon objects even when trained only over COCO. For example, our method recognizes the wooden spoons or the cake with a candle better than Oscar in Fig. 3, since CLIP is pre-trained over a diverse set of images. However, our method still fails in some cases, such as recognizing the bicycle next to the train in Fig. 3. This is inherited from the CLIP model, which does not perceive the bicycle in the first place. We conclude that our model would benefit from improving CLIP object detection ability, but leave this direction for future work. For Conceptual Captions, our method mostly produces accurate captions, such as perceiving the green 3d person in Fig. 4. As expected, our method still suffers from data bias. For instance, it depicts the bedroom image in Fig. 4 as \"The property is on the market for \u00a3 1\" after witnessing such captions of property advertising during training.\n\nLanguage model fine-tuning. As described in Section. 3, fine-tuning the language model results in a much more expressive model, but that is also more susceptible to overfitting, as the amount of trainable parameters increases. As can be seen in Tab. 1, the two variants -with and without the language model fine-tuning -are comparable. Over the extremely complicated Conceptual Captions dataset, we get superior results with the fine-tuning. While over the popular COCO dataset, avoiding the fine-tuning achieves better results. Regarding nocaps dataset, the results are roughly equal, thus the lighter model would be preferable. We thus hypothesize that extremely elaborated datasets or ones that present a unique style require more expressiveness, and hence the more likely it is to benefit from the fine-tuning.\n\nPrefix Interpretability. To further understand our method and results, we suggest interpreting the generated prefixes as a sequence of words. Since the prefix and word embeddings share the same latent space, they can be treated similarly. We define the interpretation of each of the k prefix embeddings as the closest vocabulary token, under cosine similarity. Fig. 6 shows examples of images, the generated captions, and their prefix interpretations. The interpretation is meaningful when both the mapping network and GPT-2 are trained. In this case, the interpretation contains salient words that associate with the content of the image. For Instance, motorcycle and showcase in the first example. However, when we only train the mapping network, the interpretation becomes essentially unreadable since the network is also charged with maneuvering the fixed language model. Indeed, a considerable part of the prefix embeddings is shared across different images for the same model, as it performs the same adjustment to GPT-2.\n\nPrefix length. Li and Liang [20] showed that increasing the size of the prefix length, up to a certain value, improves the performance of the model in an underlying task. Moreover, the saturation length might differ between tasks. For the image captioning task, we conduct an ablation over the prefix lengths using the COCO dataset over two configurations of our method: Ours; Transformer and Ours; MLP + GPT2 tuning. The results are summarized in Fig. 7. For each prefix size and configuration, we train the network for 5 epochs and report the BLEU@4 and CIDEr scores over the test and train sets.\n\nAs can be seen in Fig. 7a, increasing the prefix size while allowing tuning of the language model results in overfitting to the training set, due to the large number of trainable parameters. However, when the language model is frozen, we experience improvement for both the training and test evaluations, as can be seen in Fig. 7b. Naturally, extremely small prefix length yields inferior results as the model is not expressive enough. In addition, we point out that the MLP architecture is inherently more limited as it is not scalable for a long prefix. For example, a prefix size of 40 implies a network with over 450M parameters, which is unfeasible for our single GPU setting. The transformer architecture allows increasing the prefix size with only marginal increment to the number of the parameters, but only up to 80 -due to the quadratic memory cost of the attention mechanism.\n\nMapping network. An ablation study for the mapping network architecture is shown in Tab. 1(C),(D). As can be seen, with language model fine-tuning, the MLP achieves better results. However, the transformer is superior when the language model is frozen. We conclude that when employing the fine-tuning of the language model, the expressive power of the transformer architecture is unnecessary. Implementation details. We used the prefix length of K = 10 for the MLP mapping networks, where the MLP contains a single hidden layer. For the transformer mapping network, we set the CLIP embedding to K = 10 constants tokens and use 8 multi-head self-attention layers with 8 heads each. We train for 10 epochs using a batch size of 40. For optimization, we use AdamW [18] with weight   decay fix as introduced by Loshchilov et al. [24], with a learning rate of 2e \u22125 and 5000 warm-up steps. For GPT-2 we employ the implementation of Wolf et al. [41].\n\n\nConclusion\n\nOverall, our CLIP-based image-captioning method is simple to use, doesn't require any additional annotations, and is faster to train. Even though we propose a simpler model, it demonstrates more merit as the dataset becomes richer and more diverse. We consider our approach as part of a new image captioning paradigm, concentrating on leveraging existing models, while only training a minimal mapping network. This approach essentially learns to adapt existing semantic understanding of the pre-trained models to the style of the target dataset, instead of learning new semantic entities. We believe the utilization of these powerful pre-trained models would gain traction in the near future. Therefore, the understanding of how to harness these components is of great interest. For future work, we plan to incorporate pre-trained models (e.g., CLIP), to other challenging tasks, such as visual question answering or image to 3D translation, through the utilization of mapping networks.\n\nFigure 1 .\n1Our ClipCap model produces captions depcting the respective images. Here, the results are of a model that was trained over the Conceptual Captions dataset.\n\nFigure 3 .\n3Uncurated results of the first five images in the COCO test set (Karpathy et al. [17] split). Ground Truth A life in photographyin pictures.\n\nFigure 5 .\n5Results over smartphone photos. Top: using our Conceptual Captions model. Bottom: COCO model. As demonstrated, our approach generalizes well to newly photographed images.\n\n\n) MLP mapping network with fine-tuning of the language model.\n\n\nmapping network with frozen language model.\n\nFigure 7 .\n7Effect of the prefix length on the captioning performance over the COCO-captions dataset. For each prefix length, we report the BLEU@4 (red) and CIDERr (blue) scores over the test and train (dashed line) sets.\n\n( A )\nAConceptual Captions Model ROUGE-L \u2191 CIDEr \u2191 SPICE \u2191 #Params (M) \u2193 Training Time \u2193 Table 1. Quantitative evaluation. As can be seen, our method achieves comparable results for both nocaps and Conceptual Captions with much faster training time.VLP \n24.35 \n77.57 \n16.59 \n115 \n1200h (V100) \n\nOurs; MLP + GPT2 tuning \n26.71 \n87.26 \n18.5 \n156 \n80h (GTX1080) \n\nOurs; Transformer \n25.12 \n71.82 \n16.07 \n43 \n72h (GTX1080) \n\n(B) nocaps \n\nin-domain \nnear-domain out-of-domain \nOverall \nModel \nCIDEr\u2191 SPICE \u2191 CIDEr SPICE CIDEr SPICE CIDEr SPICE Params\u2193 Time\u2193 \n\nBUTD [4] \n74.3 \n11.5 \n56.9 \n10.3 \n30.1 \n8.1 \n54.3 \n10.1 \n52 \n960h \n\nOscar [19] \n79.6 \n12.3 \n66.1 11.5 45.3 \n9.7 \n63.8 11.2 \n135 \n74h \n\nOurs; MLP + GPT2 \ntuning \n\n79.73 \n12.2 \n67.69 11.26 49.35 9.7 \n65.7 \n11.1 \n156 \n7h \n\nOurs; Transformer \n84.85 12.14 66.82 10.92 49.14 9.57 65.83 10.86 \n43 \n6h \n\n(C) COCO \n\nModel \nB@4 \u2191 METEOR \u2191 CIDEr \u2191 SPICE \u2191 #Params (M) \u2193 Training Time \u2193 \n\nBUTD [4] \n36.2 \n27.0 \n113.5 \n20.3 \n52 \n960h (M40) \n\nVLP [47] \n36.5 \n28.4 \n117.7 \n21.3 \n115 \n48h (V100) \n\nOscar [19] \n36.58 \n30.4 \n124.12 23.17 \n135 \n74h (V100) \n\nOurs; Transformer \n33.53 \n27.45 \n113.08 \n21.05 \n43 \n6h (GTX1080) \n\nOurs; MLP + GPT2 tuning \n32.15 \n27.1 \n108.35 \n20.12 \n156 \n7h (GTX1080) \n\n(D) Ablation \n\nOurs; Transformer + GPT2 tun-\ning \n\n32.22 \n27.79 \n109.83 \n20.63 \n167 \n7h (GTX1080) \n\nOurs; MLP \n27.39 \n24.4 \n92.38 \n18.04 \n32 \n6h (GTX1080) \n\nGround Truth A man with a red helmet \non a small moped on a \ndirt road \n\nA young girl inhales \nwith the intent of blow-\ning out a candle. \n\nA man on a bicycle rid-\ning next to a train. \n\na wooden cutting board \ntopped with sliced up \nfood. \n\nA kitchen is shown with \na variety of items on the \ncounters. \nOscar \na man riding a motorcy-\ncle down a dirt road. \n\na woman sitting at a ta-\nble with a plate of food. \n\na woman riding a bike \ndown a street next to a \ntrain. \n\na woman sitting at a ta-\nble with a plate of food. \n\na kitchen with a sink, \ndishwasher and a win-\ndow. \nOurs; MLP + \nGPT2 tuning \na man riding a motorcy-\ncle on a dirt road. \n\na woman is eating a \npiece of cake with a can-\ndle. \n\na man is standing next to \na train. \n\na row of wooden cut-\nting boards with wooden \nspoons. \n\na kitchen with a sink, \nstove, and window. \n\nOurs; \nTransformer \na man is riding a motor-\nbike on a dirt road. \n\na young girl sitting at a \ntable with a cup of cake. \n\na man is standing next to \na train. \n\na wooden table with a \nbunch of wood tools on \nit. \n\na kitchen with a sink \nand a window. \n\n\n\nnocaps: novel object captioning at scale. Harsh Agrawal, Karan Desai, Yufei Wang, Xinlei Chen, Rishabh Jain, Mark Johnson, Dhruv Batra, Devi Parikh, Stefan Lee, Peter Anderson, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision24Harsh Agrawal, Karan Desai, Yufei Wang, Xinlei Chen, Rishabh Jain, Mark Johnson, Dhruv Batra, Devi Parikh, Ste- fan Lee, and Peter Anderson. nocaps: novel object caption- ing at scale. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 8948-8957, 2019. 2, 4\n\nGuided open vocabulary image captioning with constrained beam search. Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould, arXiv:1612.00576arXiv preprintPeter Anderson, Basura Fernando, Mark Johnson, and Stephen Gould. Guided open vocabulary image cap- tioning with constrained beam search. arXiv preprint arXiv:1612.00576, 2016. 4\n\nSpice: Semantic propositional image caption evaluation. Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould, European conference on computer vision. SpringerPeter Anderson, Basura Fernando, Mark Johnson, and Stephen Gould. Spice: Semantic propositional image cap- tion evaluation. In European conference on computer vision, pages 382-398. Springer, 2016. 6\n\nBottom-up and top-down attention for image captioning and visual question answering. Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, Lei Zhang, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionPeter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, and Lei Zhang. Bottom-up and top-down attention for image captioning and visual question answering. In Proceedings of the IEEE con- ference on computer vision and pattern recognition, pages 6077-6086, 2018. 1, 3, 4, 5\n\n. David Bau, Alex Andonian, Audrey Cui, Yeonhwan Park, Ali Jahanian, Aude Oliva, Antonio Torralba, arXiv:2103.10951Paint by word. arXiv preprintDavid Bau, Alex Andonian, Audrey Cui, YeonHwan Park, Ali Jahanian, Aude Oliva, and Antonio Torralba. Paint by word. arXiv preprint arXiv:2103.10951, 2021. 2\n\nSca-cnn: Spatial and channel-wise attention in convolutional networks for image captioning. Long Chen, Hanwang Zhang, Jun Xiao, Liqiang Nie, Jian Shao, Wei Liu, Tat-Seng Chua, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionLong Chen, Hanwang Zhang, Jun Xiao, Liqiang Nie, Jian Shao, Wei Liu, and Tat-Seng Chua. Sca-cnn: Spatial and channel-wise attention in convolutional networks for im- age captioning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5659-5667, 2017. 3\n\nMicrosoft coco captions: Data collection and evaluation server. Xinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Doll\u00e1r, C Lawrence Zitnick, arXiv:1504.0032524arXiv preprintXinlei Chen, Hao Fang, Tsung-Yi Lin, Ramakrishna Vedan- tam, Saurabh Gupta, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325, 2015. 2, 3, 4\n\nRegularizing rnns for caption generation by reconstructing the past with the present. Xinpeng Chen, Lin Ma, Wenhao Jiang, Jian Yao, Wei Liu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionXinpeng Chen, Lin Ma, Wenhao Jiang, Jian Yao, and Wei Liu. Regularizing rnns for caption generation by reconstruct- ing the past with the present. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7995-8003, 2018. 3\n\nLearning a recurrent visual representation for image caption generation. Xinlei Chen, Lawrence Zitnick, arXiv:1411.565413arXiv preprintXinlei Chen and C Lawrence Zitnick. Learning a recurrent visual representation for image caption generation. arXiv preprint arXiv:1411.5654, 2014. 1, 3\n\nMeteor universal: Language specific translation evaluation for any target language. Michael Denkowski, Alon Lavie, Proceedings of the ninth workshop on statistical machine translation. the ninth workshop on statistical machine translationMichael Denkowski and Alon Lavie. Meteor universal: Lan- guage specific translation evaluation for any target language. In Proceedings of the ninth workshop on statistical machine translation, pages 376-380, 2014. 6\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova Bert, arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. 36arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018. 3, 6\n\nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, arXiv:2010.11929Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprintAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, et al. An image is worth 16x16 words: Trans- formers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020. 3\n\nFrom captions to visual concepts and back. Saurabh Hao Fang, Forrest Gupta, Iandola, K Rupesh, Li Srivastava, Piotr Deng, Jianfeng Doll\u00e1r, Xiaodong Gao, Margaret He, John C Mitchell, Platt, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition13Hao Fang, Saurabh Gupta, Forrest Iandola, Rupesh K Sri- vastava, Li Deng, Piotr Doll\u00e1r, Jianfeng Gao, Xiaodong He, Margaret Mitchell, John C Platt, et al. From captions to vi- sual concepts and back. In Proceedings of the IEEE con- ference on computer vision and pattern recognition, pages 1473-1482, 2015. 1, 3\n\nStylegan-nada: Clip-guided domain adaptation of image generators. Rinon Gal, Or Patashnik, Haggai Maron, Gal Chechik, Daniel Cohen-Or, arXiv:2108.00946arXiv preprintRinon Gal, Or Patashnik, Haggai Maron, Gal Chechik, and Daniel Cohen-Or. Stylegan-nada: Clip-guided do- main adaptation of image generators. arXiv preprint arXiv:2108.00946, 2021. 2\n\nSelf-critical n-step training for image captioning. Junlong Gao, Shiqi Wang, Shanshe Wang, Siwei Ma, Wen Gao, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionJunlong Gao, Shiqi Wang, Shanshe Wang, Siwei Ma, and Wen Gao. Self-critical n-step training for image captioning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6300-6308, 2019. 3\n\nSimao Herdade, Armin Kappeler, Kofi Boakye, Joao Soares, arXiv:1906.05963Image captioning: Transforming objects into words. arXiv preprintSimao Herdade, Armin Kappeler, Kofi Boakye, and Joao Soares. Image captioning: Transforming objects into words. arXiv preprint arXiv:1906.05963, 2019. 3\n\nDeep visual-semantic alignments for generating image descriptions. Andrej Karpathy, Li Fei-Fei, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition45Andrej Karpathy and Li Fei-Fei. Deep visual-semantic align- ments for generating image descriptions. In Proceedings of the IEEE conference on computer vision and pattern recog- nition, pages 3128-3137, 2015. 4, 5\n\nAdam: A method for stochastic optimization. CoRR, abs/1412. P Diederik, Jimmy Kingma, Ba, 6980Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2015. 8\n\nObject-semantics aligned pre-training for vision-language tasks. Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, European Conference on Computer Vision. Springer56Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, et al. Oscar: Object-semantics aligned pre-training for vision-language tasks. In European Conference on Computer Vision, pages 121-137. Springer, 2020. 1, 3, 4, 5, 6\n\nPrefix-tuning: Optimizing continuous prompts for generation. Lisa Xiang, Percy Li, Liang, arXiv:2101.00190arXiv preprintXiang Lisa Li and Percy Liang. Prefix-tuning: Optimiz- ing continuous prompts for generation. arXiv preprint arXiv:2101.00190, 2021. 2, 4, 8\n\nAutomatic evaluation of machine translation quality using longest common subsequence and skip-bigram statistics. Chin-Yew Lin, Franz Josef Och, Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04). the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04)Chin-Yew Lin and Franz Josef Och. Automatic evaluation of machine translation quality using longest common sub- sequence and skip-bigram statistics. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04), pages 605-612, 2004. 6\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, European conference on computer vision. Springer24Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740-755. Springer, 2014. 2, 3, 4\n\nCptr: Full transformer network for image captioning. Wei Liu, Sihan Chen, Longteng Guo, Xinxin Zhu, Jing Liu, arXiv:2101.10804arXiv preprintWei Liu, Sihan Chen, Longteng Guo, Xinxin Zhu, and Jing Liu. Cptr: Full transformer network for image captioning. arXiv preprint arXiv:2101.10804, 2021. 3\n\n. Ilya Loshchilov, Frank Hutter, arXiv:1711.05101Decoupled weight decay regularization. arXiv preprintIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017. 8\n\nVilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee, arXiv:1908.02265arXiv preprintJiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. Vilbert: Pretraining task-agnostic visiolinguistic represen- tations for vision-and-language tasks. arXiv preprint arXiv:1908.02265, 2019. 3\n\nDual-level collaborative transformer for image captioning. Yunpeng Luo, Jiayi Ji, Xiaoshuai Sun, Liujuan Cao, Yongjian Wu, Feiyue Huang, Chia-Wen Lin, Rongrong Ji, arXiv:2101.06462arXiv preprintYunpeng Luo, Jiayi Ji, Xiaoshuai Sun, Liujuan Cao, Yongjian Wu, Feiyue Huang, Chia-Wen Lin, and Rongrong Ji. Dual-level collaborative transformer for image caption- ing. arXiv preprint arXiv:2101.06462, 2021. 3\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting of the Association for Computational Linguistics. the 40th annual meeting of the Association for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311-318, 2002. 6\n\nStyleclip: Text-driven manipulation of stylegan imagery. Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, Dani Lischinski, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionOr Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, and Dani Lischinski. Styleclip: Text-driven manipulation of stylegan imagery. In Proceedings of the IEEE/CVF Inter- national Conference on Computer Vision, pages 2085-2094, 2021. 2\n\nLearning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, arXiv:2103.0002023arXiv preprintAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learn- ing transferable visual models from natural language super- vision. arXiv preprint arXiv:2103.00020, 2021. 2, 3\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 183Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsu- pervised multitask learners. OpenAI blog, 1(8):9, 2019. 2, 3\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. Kaiming Shaoqing Ren, Ross He, Jian Girshick, Sun, Advances in neural information processing systems. 284Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information process- ing systems, 28:91-99, 2015. 3, 4\n\nSelf-critical sequence training for image captioning. J Steven, Etienne Rennie, Youssef Marcheret, Jerret Mroueh, Vaibhava Ross, Goel, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionSteven J Rennie, Etienne Marcheret, Youssef Mroueh, Jerret Ross, and Vaibhava Goel. Self-critical sequence training for image captioning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 7008-7024, 2017. 3\n\nConceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning. Piyush Sharma, Nan Ding, Sebastian Goodman, Radu Soricut, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsLong Papers16Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. Conceptual captions: A cleaned, hypernymed, im- age alt-text dataset for automatic image captioning. In Pro- ceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2556-2565, 2018. 2, 4, 6\n\nFrom show to tell: A survey on image captioning. Matteo Stefanini, Marcella Cornia, Lorenzo Baraldi, Silvia Cascianelli, Giuseppe Fiameni, Rita Cucchiara, arXiv:2107.0691213arXiv preprintMatteo Stefanini, Marcella Cornia, Lorenzo Baraldi, Silvia Cascianelli, Giuseppe Fiameni, and Rita Cucchiara. From show to tell: A survey on image captioning. arXiv preprint arXiv:2107.06912, 2021. 1, 3\n\nLxmert: Learning crossmodality encoder representations from transformers. Hao Tan, Mohit Bansal, arXiv:1908.0749013arXiv preprintHao Tan and Mohit Bansal. Lxmert: Learning cross- modality encoder representations from transformers. arXiv preprint arXiv:1908.07490, 2019. 1, 3\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. 34Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko- reit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998-6008, 2017. 3, 4\n\nCider: Consensus-based image description evaluation. Ramakrishna Vedantam, Lawrence Zitnick, Devi Parikh, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionRamakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh. Cider: Consensus-based image description evalua- tion. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4566-4575, 2015. 6\n\nShow and tell: A neural image caption generator. Oriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionOriol Vinyals, Alexander Toshev, Samy Bengio, and Du- mitru Erhan. Show and tell: A neural image caption gen- erator. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3156-3164, 2015. 3\n\nSkeleton key: Image captioning by skeletonattribute decomposition. Yufei Wang, Zhe Lin, Xiaohui Shen, Scott Cohen, W Garrison, Cottrell, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionYufei Wang, Zhe Lin, Xiaohui Shen, Scott Cohen, and Garri- son W Cottrell. Skeleton key: Image captioning by skeleton- attribute decomposition. In Proceedings of the IEEE con- ference on computer vision and pattern recognition, pages 7272-7281, 2017. 3\n\nSimvlm: Simple visual language model pretraining with weak supervision. Zirui Wang, Jiahui Yu, Adams Wei Yu, Zihang Dai, Yulia Tsvetkov, Yuan Cao, arXiv:2108.10904arXiv preprintZirui Wang, Jiahui Yu, Adams Wei Yu, Zihang Dai, Yulia Tsvetkov, and Yuan Cao. Simvlm: Simple visual language model pretraining with weak supervision. arXiv preprint arXiv:2108.10904, 2021. 3\n\nTransformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Le Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander M Lhoest, Rush, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2020 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsOnlineAssociation for Computational LinguisticsThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chau- mond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Trans- formers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online, Oct. 2020. Association for Computa- tional Linguistics. 8\n\nRich Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention. Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, PMLRInternational conference on machine learning. 13Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption gen- eration with visual attention. In International conference on machine learning, pages 2048-2057. PMLR, 2015. 1, 3\n\nLearning to collocate neural modules for image captioning. Xu Yang, Hanwang Zhang, Jianfei Cai, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer VisionXu Yang, Hanwang Zhang, and Jianfei Cai. Learning to col- locate neural modules for image captioning. In Proceedings of the IEEE/CVF International Conference on Computer Vi- sion, pages 4250-4260, 2019. 3\n\nExploring visual relationship for image captioning. Ting Yao, Yingwei Pan, Yehao Li, Tao Mei, Proceedings of the European conference on computer vision (ECCV). the European conference on computer vision (ECCV)Ting Yao, Yingwei Pan, Yehao Li, and Tao Mei. Exploring visual relationship for image captioning. In Proceedings of the European conference on computer vision (ECCV), pages 684-699, 2018. 1\n\nLi Zhang, Flood Sung, Feng Liu, Tao Xiang, arXiv:1706.09601Shaogang Gong, Yongxin Yang, and Timothy M Hospedales. Actorcritic sequence training for image captioning. arXiv preprintLi Zhang, Flood Sung, Feng Liu, Tao Xiang, Shaogang Gong, Yongxin Yang, and Timothy M Hospedales. Actor- critic sequence training for image captioning. arXiv preprint arXiv:1706.09601, 2017. 3\n\nVinvl: Revisiting visual representations in vision-language models. Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang, Yejin Choi, Jianfeng Gao, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionPengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang, Yejin Choi, and Jianfeng Gao. Vinvl: Revisiting visual representations in vision-language models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5579- 5588, 2021. 3\n\nUnified vision-language pretraining for image captioning and vqa. Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Jason Corso, Jianfeng Gao, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Ja- son Corso, and Jianfeng Gao. Unified vision-language pre- training for image captioning and vqa. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 13041-13049, 2020. 1, 3, 4, 5\n", "annotations": {"author": "[{\"end\":119,\"start\":45},{\"end\":194,\"start\":120},{\"end\":273,\"start\":195},{\"end\":119,\"start\":45},{\"end\":194,\"start\":120},{\"end\":273,\"start\":195}]", "publisher": null, "author_last_name": "[{\"end\":55,\"start\":49},{\"end\":130,\"start\":125},{\"end\":209,\"start\":202},{\"end\":55,\"start\":49},{\"end\":130,\"start\":125},{\"end\":209,\"start\":202}]", "author_first_name": "[{\"end\":48,\"start\":45},{\"end\":124,\"start\":120},{\"end\":199,\"start\":195},{\"end\":201,\"start\":200},{\"end\":48,\"start\":45},{\"end\":124,\"start\":120},{\"end\":199,\"start\":195},{\"end\":201,\"start\":200}]", "author_affiliation": "[{\"end\":118,\"start\":57},{\"end\":193,\"start\":132},{\"end\":272,\"start\":211},{\"end\":118,\"start\":57},{\"end\":193,\"start\":132},{\"end\":272,\"start\":211}]", "title": "[{\"end\":42,\"start\":1},{\"end\":315,\"start\":274},{\"end\":42,\"start\":1},{\"end\":315,\"start\":274}]", "venue": null, "abstract": "[{\"end\":2326,\"start\":317},{\"end\":2326,\"start\":317}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3269,\"start\":3266},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3271,\"start\":3269},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3274,\"start\":3271},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3277,\"start\":3274},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3280,\"start\":3277},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3283,\"start\":3280},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3286,\"start\":3283},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3289,\"start\":3286},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3292,\"start\":3289},{\"end\":4597,\"start\":4587},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4606,\"start\":4602},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5855,\"start\":5851},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5992,\"start\":5988},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6753,\"start\":6749},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6768,\"start\":6765},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6832,\"start\":6829},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6835,\"start\":6832},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7409,\"start\":7405},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7959,\"start\":7956},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7962,\"start\":7959},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7965,\"start\":7962},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8232,\"start\":8228},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8438,\"start\":8435},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8440,\"start\":8438},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8443,\"start\":8440},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8446,\"start\":8443},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8469,\"start\":8466},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8472,\"start\":8469},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8475,\"start\":8472},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8548,\"start\":8544},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8643,\"start\":8640},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8646,\"start\":8643},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8905,\"start\":8902},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8907,\"start\":8905},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8910,\"start\":8907},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8998,\"start\":8994},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9001,\"start\":8998},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9046,\"start\":9042},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9065,\"start\":9061},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9384,\"start\":9381},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9387,\"start\":9384},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":9390,\"start\":9387},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9415,\"start\":9411},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9418,\"start\":9415},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9469,\"start\":9465},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9541,\"start\":9537},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9924,\"start\":9920},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10085,\"start\":10081},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10088,\"start\":10085},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":10091,\"start\":10088},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10381,\"start\":10377},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10384,\"start\":10381},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10387,\"start\":10384},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10390,\"start\":10387},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10393,\"start\":10390},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10411,\"start\":10407},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10574,\"start\":10570},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10603,\"start\":10599},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10625,\"start\":10621},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10838,\"start\":10834},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":11812,\"start\":11808},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12448,\"start\":12444},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14256,\"start\":14252},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":15691,\"start\":15687},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17006,\"start\":17003},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17009,\"start\":17006},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17021,\"start\":17018},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":17052,\"start\":17048},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":17120,\"start\":17116},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17644,\"start\":17640},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":17920,\"start\":17917},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":18614,\"start\":18610},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18678,\"start\":18674},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18723,\"start\":18720},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18820,\"start\":18816},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":19919,\"start\":19915},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20147,\"start\":20143},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20256,\"start\":20252},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20738,\"start\":20734},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20820,\"start\":20816},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20833,\"start\":20829},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":20845,\"start\":20841},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20859,\"start\":20856},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20966,\"start\":20962},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":21018,\"start\":21014},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26885,\"start\":26881},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29106,\"start\":29102},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":29170,\"start\":29166},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":29284,\"start\":29280},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3269,\"start\":3266},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3271,\"start\":3269},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3274,\"start\":3271},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3277,\"start\":3274},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3280,\"start\":3277},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3283,\"start\":3280},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3286,\"start\":3283},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3289,\"start\":3286},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3292,\"start\":3289},{\"end\":4597,\"start\":4587},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4606,\"start\":4602},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5855,\"start\":5851},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5992,\"start\":5988},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6753,\"start\":6749},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6768,\"start\":6765},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6832,\"start\":6829},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6835,\"start\":6832},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7409,\"start\":7405},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7959,\"start\":7956},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7962,\"start\":7959},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7965,\"start\":7962},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8232,\"start\":8228},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8438,\"start\":8435},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8440,\"start\":8438},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8443,\"start\":8440},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8446,\"start\":8443},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8469,\"start\":8466},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8472,\"start\":8469},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8475,\"start\":8472},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8548,\"start\":8544},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8643,\"start\":8640},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8646,\"start\":8643},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8905,\"start\":8902},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8907,\"start\":8905},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8910,\"start\":8907},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8998,\"start\":8994},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9001,\"start\":8998},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9046,\"start\":9042},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9065,\"start\":9061},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9384,\"start\":9381},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9387,\"start\":9384},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":9390,\"start\":9387},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9415,\"start\":9411},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9418,\"start\":9415},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9469,\"start\":9465},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9541,\"start\":9537},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9924,\"start\":9920},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10085,\"start\":10081},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10088,\"start\":10085},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":10091,\"start\":10088},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10381,\"start\":10377},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10384,\"start\":10381},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10387,\"start\":10384},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10390,\"start\":10387},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10393,\"start\":10390},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10411,\"start\":10407},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10574,\"start\":10570},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10603,\"start\":10599},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10625,\"start\":10621},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10838,\"start\":10834},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":11812,\"start\":11808},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12448,\"start\":12444},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14256,\"start\":14252},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":15691,\"start\":15687},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17006,\"start\":17003},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17009,\"start\":17006},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17021,\"start\":17018},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":17052,\"start\":17048},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":17120,\"start\":17116},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17644,\"start\":17640},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":17920,\"start\":17917},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":18614,\"start\":18610},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":18678,\"start\":18674},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18723,\"start\":18720},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18820,\"start\":18816},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":19919,\"start\":19915},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20147,\"start\":20143},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20256,\"start\":20252},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20738,\"start\":20734},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20820,\"start\":20816},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20833,\"start\":20829},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":20845,\"start\":20841},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20859,\"start\":20856},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20966,\"start\":20962},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":21018,\"start\":21014},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26885,\"start\":26881},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29106,\"start\":29102},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":29170,\"start\":29166},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":29284,\"start\":29280}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30455,\"start\":30287},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30609,\"start\":30456},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30793,\"start\":30610},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30857,\"start\":30794},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30903,\"start\":30858},{\"attributes\":{\"id\":\"fig_5\"},\"end\":31126,\"start\":30904},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33612,\"start\":31127},{\"attributes\":{\"id\":\"fig_0\"},\"end\":30455,\"start\":30287},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30609,\"start\":30456},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30793,\"start\":30610},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30857,\"start\":30794},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30903,\"start\":30858},{\"attributes\":{\"id\":\"fig_5\"},\"end\":31126,\"start\":30904},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33612,\"start\":31127}]", "paragraph": "[{\"end\":3005,\"start\":2342},{\"end\":3052,\"start\":3007},{\"end\":3112,\"start\":3054},{\"end\":3175,\"start\":3114},{\"end\":3781,\"start\":3177},{\"end\":4370,\"start\":3783},{\"end\":4932,\"start\":4372},{\"end\":6079,\"start\":4934},{\"end\":7068,\"start\":6081},{\"end\":7184,\"start\":7070},{\"end\":7362,\"start\":7186},{\"end\":8199,\"start\":7380},{\"end\":9281,\"start\":8201},{\"end\":10245,\"start\":9283},{\"end\":11177,\"start\":10247},{\"end\":11551,\"start\":11188},{\"end\":12091,\"start\":11605},{\"end\":12558,\"start\":12171},{\"end\":12750,\"start\":12602},{\"end\":12887,\"start\":12806},{\"end\":13117,\"start\":12903},{\"end\":13340,\"start\":13208},{\"end\":13939,\"start\":13371},{\"end\":15097,\"start\":13941},{\"end\":15583,\"start\":15130},{\"end\":16510,\"start\":15585},{\"end\":16956,\"start\":16524},{\"end\":18532,\"start\":16968},{\"end\":18986,\"start\":18534},{\"end\":19041,\"start\":18988},{\"end\":19092,\"start\":19043},{\"end\":19176,\"start\":19094},{\"end\":19263,\"start\":19178},{\"end\":19289,\"start\":19265},{\"end\":19406,\"start\":19291},{\"end\":19469,\"start\":19408},{\"end\":19520,\"start\":19471},{\"end\":19560,\"start\":19522},{\"end\":19616,\"start\":19562},{\"end\":19662,\"start\":19618},{\"end\":19703,\"start\":19664},{\"end\":19748,\"start\":19705},{\"end\":19920,\"start\":19750},{\"end\":19983,\"start\":19922},{\"end\":20028,\"start\":19985},{\"end\":20077,\"start\":20030},{\"end\":20357,\"start\":20079},{\"end\":20691,\"start\":20359},{\"end\":21019,\"start\":20693},{\"end\":21460,\"start\":21021},{\"end\":22077,\"start\":21462},{\"end\":22468,\"start\":22079},{\"end\":22698,\"start\":22485},{\"end\":23138,\"start\":22700},{\"end\":23456,\"start\":23140},{\"end\":25006,\"start\":23458},{\"end\":25822,\"start\":25008},{\"end\":26851,\"start\":25824},{\"end\":27451,\"start\":26853},{\"end\":28339,\"start\":27453},{\"end\":29285,\"start\":28341},{\"end\":30286,\"start\":29300},{\"end\":3005,\"start\":2342},{\"end\":3052,\"start\":3007},{\"end\":3112,\"start\":3054},{\"end\":3175,\"start\":3114},{\"end\":3781,\"start\":3177},{\"end\":4370,\"start\":3783},{\"end\":4932,\"start\":4372},{\"end\":6079,\"start\":4934},{\"end\":7068,\"start\":6081},{\"end\":7184,\"start\":7070},{\"end\":7362,\"start\":7186},{\"end\":8199,\"start\":7380},{\"end\":9281,\"start\":8201},{\"end\":10245,\"start\":9283},{\"end\":11177,\"start\":10247},{\"end\":11551,\"start\":11188},{\"end\":12091,\"start\":11605},{\"end\":12558,\"start\":12171},{\"end\":12750,\"start\":12602},{\"end\":12887,\"start\":12806},{\"end\":13117,\"start\":12903},{\"end\":13340,\"start\":13208},{\"end\":13939,\"start\":13371},{\"end\":15097,\"start\":13941},{\"end\":15583,\"start\":15130},{\"end\":16510,\"start\":15585},{\"end\":16956,\"start\":16524},{\"end\":18532,\"start\":16968},{\"end\":18986,\"start\":18534},{\"end\":19041,\"start\":18988},{\"end\":19092,\"start\":19043},{\"end\":19176,\"start\":19094},{\"end\":19263,\"start\":19178},{\"end\":19289,\"start\":19265},{\"end\":19406,\"start\":19291},{\"end\":19469,\"start\":19408},{\"end\":19520,\"start\":19471},{\"end\":19560,\"start\":19522},{\"end\":19616,\"start\":19562},{\"end\":19662,\"start\":19618},{\"end\":19703,\"start\":19664},{\"end\":19748,\"start\":19705},{\"end\":19920,\"start\":19750},{\"end\":19983,\"start\":19922},{\"end\":20028,\"start\":19985},{\"end\":20077,\"start\":20030},{\"end\":20357,\"start\":20079},{\"end\":20691,\"start\":20359},{\"end\":21019,\"start\":20693},{\"end\":21460,\"start\":21021},{\"end\":22077,\"start\":21462},{\"end\":22468,\"start\":22079},{\"end\":22698,\"start\":22485},{\"end\":23138,\"start\":22700},{\"end\":23456,\"start\":23140},{\"end\":25006,\"start\":23458},{\"end\":25822,\"start\":25008},{\"end\":26851,\"start\":25824},{\"end\":27451,\"start\":26853},{\"end\":28339,\"start\":27453},{\"end\":29285,\"start\":28341},{\"end\":30286,\"start\":29300}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11604,\"start\":11552},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12159,\"start\":12092},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12601,\"start\":12559},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12805,\"start\":12751},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12902,\"start\":12888},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13207,\"start\":13118},{\"attributes\":{\"id\":\"formula_0\"},\"end\":11604,\"start\":11552},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12159,\"start\":12092},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12601,\"start\":12559},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12805,\"start\":12751},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12902,\"start\":12888},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13207,\"start\":13118}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2340,\"start\":2328},{\"attributes\":{\"n\":\"2.\"},\"end\":7378,\"start\":7365},{\"attributes\":{\"n\":\"3.\"},\"end\":11186,\"start\":11180},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12169,\"start\":12161},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13369,\"start\":13343},{\"attributes\":{\"n\":\"3.3.\"},\"end\":15128,\"start\":15100},{\"attributes\":{\"n\":\"3.4.\"},\"end\":16522,\"start\":16513},{\"attributes\":{\"n\":\"4.\"},\"end\":16966,\"start\":16959},{\"end\":22483,\"start\":22471},{\"attributes\":{\"n\":\"5.\"},\"end\":29298,\"start\":29288},{\"end\":30298,\"start\":30288},{\"end\":30467,\"start\":30457},{\"end\":30621,\"start\":30611},{\"end\":30915,\"start\":30905},{\"end\":31133,\"start\":31128},{\"attributes\":{\"n\":\"1.\"},\"end\":2340,\"start\":2328},{\"attributes\":{\"n\":\"2.\"},\"end\":7378,\"start\":7365},{\"attributes\":{\"n\":\"3.\"},\"end\":11186,\"start\":11180},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12169,\"start\":12161},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13369,\"start\":13343},{\"attributes\":{\"n\":\"3.3.\"},\"end\":15128,\"start\":15100},{\"attributes\":{\"n\":\"3.4.\"},\"end\":16522,\"start\":16513},{\"attributes\":{\"n\":\"4.\"},\"end\":16966,\"start\":16959},{\"end\":22483,\"start\":22471},{\"attributes\":{\"n\":\"5.\"},\"end\":29298,\"start\":29288},{\"end\":30298,\"start\":30288},{\"end\":30467,\"start\":30457},{\"end\":30621,\"start\":30611},{\"end\":30915,\"start\":30905},{\"end\":31133,\"start\":31128}]", "table": "[{\"end\":33612,\"start\":31377},{\"end\":33612,\"start\":31377}]", "figure_caption": "[{\"end\":30455,\"start\":30300},{\"end\":30609,\"start\":30469},{\"end\":30793,\"start\":30623},{\"end\":30857,\"start\":30796},{\"end\":30903,\"start\":30860},{\"end\":31126,\"start\":30917},{\"end\":31377,\"start\":31135},{\"end\":30455,\"start\":30300},{\"end\":30609,\"start\":30469},{\"end\":30793,\"start\":30623},{\"end\":30857,\"start\":30796},{\"end\":30903,\"start\":30860},{\"end\":31126,\"start\":30917},{\"end\":31377,\"start\":31135}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2750,\"start\":2744},{\"end\":4958,\"start\":4952},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6444,\"start\":6438},{\"end\":12222,\"start\":12216},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18321,\"start\":18315},{\"end\":19830,\"start\":19822},{\"end\":22544,\"start\":22536},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":23807,\"start\":23801},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23984,\"start\":23978},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24274,\"start\":24268},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24438,\"start\":24432},{\"end\":24783,\"start\":24777},{\"end\":24891,\"start\":24885},{\"end\":26191,\"start\":26185},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27307,\"start\":27301},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27478,\"start\":27471},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27783,\"start\":27776},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2750,\"start\":2744},{\"end\":4958,\"start\":4952},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6444,\"start\":6438},{\"end\":12222,\"start\":12216},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18321,\"start\":18315},{\"end\":19830,\"start\":19822},{\"end\":22544,\"start\":22536},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":23807,\"start\":23801},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23984,\"start\":23978},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24274,\"start\":24268},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24438,\"start\":24432},{\"end\":24783,\"start\":24777},{\"end\":24891,\"start\":24885},{\"end\":26191,\"start\":26185},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27307,\"start\":27301},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27478,\"start\":27471},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27783,\"start\":27776}]", "bib_author_first_name": "[{\"end\":33661,\"start\":33656},{\"end\":33676,\"start\":33671},{\"end\":33689,\"start\":33684},{\"end\":33702,\"start\":33696},{\"end\":33716,\"start\":33709},{\"end\":33727,\"start\":33723},{\"end\":33742,\"start\":33737},{\"end\":33754,\"start\":33750},{\"end\":33769,\"start\":33763},{\"end\":33780,\"start\":33775},{\"end\":34287,\"start\":34282},{\"end\":34304,\"start\":34298},{\"end\":34319,\"start\":34315},{\"end\":34336,\"start\":34329},{\"end\":34615,\"start\":34610},{\"end\":34632,\"start\":34626},{\"end\":34647,\"start\":34643},{\"end\":34664,\"start\":34657},{\"end\":35011,\"start\":35006},{\"end\":35030,\"start\":35022},{\"end\":35040,\"start\":35035},{\"end\":35056,\"start\":35050},{\"end\":35068,\"start\":35064},{\"end\":35085,\"start\":35078},{\"end\":35096,\"start\":35093},{\"end\":35558,\"start\":35553},{\"end\":35568,\"start\":35564},{\"end\":35585,\"start\":35579},{\"end\":35599,\"start\":35591},{\"end\":35609,\"start\":35606},{\"end\":35624,\"start\":35620},{\"end\":35639,\"start\":35632},{\"end\":35949,\"start\":35945},{\"end\":35963,\"start\":35956},{\"end\":35974,\"start\":35971},{\"end\":35988,\"start\":35981},{\"end\":35998,\"start\":35994},{\"end\":36008,\"start\":36005},{\"end\":36022,\"start\":36014},{\"end\":36530,\"start\":36524},{\"end\":36540,\"start\":36537},{\"end\":36555,\"start\":36547},{\"end\":36572,\"start\":36561},{\"end\":36590,\"start\":36583},{\"end\":36603,\"start\":36598},{\"end\":36622,\"start\":36612},{\"end\":36983,\"start\":36976},{\"end\":36993,\"start\":36990},{\"end\":37004,\"start\":36998},{\"end\":37016,\"start\":37012},{\"end\":37025,\"start\":37022},{\"end\":37506,\"start\":37500},{\"end\":37806,\"start\":37799},{\"end\":37822,\"start\":37818},{\"end\":38175,\"start\":38170},{\"end\":38192,\"start\":38184},{\"end\":38206,\"start\":38200},{\"end\":38220,\"start\":38212},{\"end\":38230,\"start\":38221},{\"end\":38544,\"start\":38538},{\"end\":38563,\"start\":38558},{\"end\":38580,\"start\":38571},{\"end\":38597,\"start\":38593},{\"end\":38618,\"start\":38611},{\"end\":38631,\"start\":38625},{\"end\":38652,\"start\":38645},{\"end\":38671,\"start\":38663},{\"end\":38687,\"start\":38682},{\"end\":39178,\"start\":39171},{\"end\":39196,\"start\":39189},{\"end\":39214,\"start\":39213},{\"end\":39225,\"start\":39223},{\"end\":39243,\"start\":39238},{\"end\":39258,\"start\":39250},{\"end\":39275,\"start\":39267},{\"end\":39289,\"start\":39281},{\"end\":39298,\"start\":39294},{\"end\":39300,\"start\":39299},{\"end\":39845,\"start\":39840},{\"end\":39853,\"start\":39851},{\"end\":39871,\"start\":39865},{\"end\":39882,\"start\":39879},{\"end\":39898,\"start\":39892},{\"end\":40181,\"start\":40174},{\"end\":40192,\"start\":40187},{\"end\":40206,\"start\":40199},{\"end\":40218,\"start\":40213},{\"end\":40226,\"start\":40223},{\"end\":40612,\"start\":40607},{\"end\":40627,\"start\":40622},{\"end\":40642,\"start\":40638},{\"end\":40655,\"start\":40651},{\"end\":40972,\"start\":40966},{\"end\":40985,\"start\":40983},{\"end\":41413,\"start\":41412},{\"end\":41429,\"start\":41424},{\"end\":41624,\"start\":41618},{\"end\":41631,\"start\":41629},{\"end\":41645,\"start\":41637},{\"end\":41659,\"start\":41650},{\"end\":41674,\"start\":41667},{\"end\":41682,\"start\":41679},{\"end\":41696,\"start\":41690},{\"end\":41710,\"start\":41703},{\"end\":41717,\"start\":41715},{\"end\":41728,\"start\":41724},{\"end\":42133,\"start\":42129},{\"end\":42146,\"start\":42141},{\"end\":42451,\"start\":42443},{\"end\":42468,\"start\":42457},{\"end\":42978,\"start\":42970},{\"end\":42991,\"start\":42984},{\"end\":43004,\"start\":42999},{\"end\":43020,\"start\":43015},{\"end\":43033,\"start\":43027},{\"end\":43046,\"start\":43042},{\"end\":43061,\"start\":43056},{\"end\":43080,\"start\":43070},{\"end\":43446,\"start\":43443},{\"end\":43457,\"start\":43452},{\"end\":43472,\"start\":43464},{\"end\":43484,\"start\":43478},{\"end\":43494,\"start\":43490},{\"end\":43692,\"start\":43688},{\"end\":43710,\"start\":43705},{\"end\":44007,\"start\":44001},{\"end\":44017,\"start\":44012},{\"end\":44029,\"start\":44025},{\"end\":44044,\"start\":44038},{\"end\":44341,\"start\":44334},{\"end\":44352,\"start\":44347},{\"end\":44366,\"start\":44357},{\"end\":44379,\"start\":44372},{\"end\":44393,\"start\":44385},{\"end\":44404,\"start\":44398},{\"end\":44420,\"start\":44412},{\"end\":44434,\"start\":44426},{\"end\":44752,\"start\":44745},{\"end\":44768,\"start\":44763},{\"end\":44781,\"start\":44777},{\"end\":44796,\"start\":44788},{\"end\":45263,\"start\":45261},{\"end\":45281,\"start\":45275},{\"end\":45289,\"start\":45286},{\"end\":45307,\"start\":45301},{\"end\":45322,\"start\":45318},{\"end\":45778,\"start\":45774},{\"end\":45792,\"start\":45788},{\"end\":45797,\"start\":45793},{\"end\":45808,\"start\":45803},{\"end\":45824,\"start\":45818},{\"end\":45840,\"start\":45833},{\"end\":45854,\"start\":45846},{\"end\":45870,\"start\":45864},{\"end\":45885,\"start\":45879},{\"end\":45900,\"start\":45894},{\"end\":45914,\"start\":45910},{\"end\":46286,\"start\":46282},{\"end\":46303,\"start\":46296},{\"end\":46313,\"start\":46308},{\"end\":46326,\"start\":46321},{\"end\":46338,\"start\":46333},{\"end\":46351,\"start\":46347},{\"end\":46642,\"start\":46635},{\"end\":46661,\"start\":46657},{\"end\":46670,\"start\":46666},{\"end\":47005,\"start\":47004},{\"end\":47021,\"start\":47014},{\"end\":47037,\"start\":47030},{\"end\":47055,\"start\":47049},{\"end\":47072,\"start\":47064},{\"end\":47577,\"start\":47571},{\"end\":47589,\"start\":47586},{\"end\":47605,\"start\":47596},{\"end\":47619,\"start\":47615},{\"end\":48171,\"start\":48165},{\"end\":48191,\"start\":48183},{\"end\":48207,\"start\":48200},{\"end\":48223,\"start\":48217},{\"end\":48245,\"start\":48237},{\"end\":48259,\"start\":48255},{\"end\":48584,\"start\":48581},{\"end\":48595,\"start\":48590},{\"end\":48816,\"start\":48810},{\"end\":48830,\"start\":48826},{\"end\":48844,\"start\":48840},{\"end\":48858,\"start\":48853},{\"end\":48875,\"start\":48870},{\"end\":48888,\"start\":48883},{\"end\":48890,\"start\":48889},{\"end\":48904,\"start\":48898},{\"end\":48918,\"start\":48913},{\"end\":49285,\"start\":49274},{\"end\":49304,\"start\":49296},{\"end\":49318,\"start\":49314},{\"end\":49744,\"start\":49739},{\"end\":49763,\"start\":49754},{\"end\":49776,\"start\":49772},{\"end\":49792,\"start\":49785},{\"end\":50239,\"start\":50234},{\"end\":50249,\"start\":50246},{\"end\":50262,\"start\":50255},{\"end\":50274,\"start\":50269},{\"end\":50283,\"start\":50282},{\"end\":50776,\"start\":50771},{\"end\":50789,\"start\":50783},{\"end\":50799,\"start\":50794},{\"end\":50803,\"start\":50800},{\"end\":50814,\"start\":50808},{\"end\":50825,\"start\":50820},{\"end\":50840,\"start\":50836},{\"end\":51135,\"start\":51129},{\"end\":51150,\"start\":51142},{\"end\":51164,\"start\":51158},{\"end\":51177,\"start\":51171},{\"end\":51195,\"start\":51188},{\"end\":51213,\"start\":51206},{\"end\":51226,\"start\":51219},{\"end\":51238,\"start\":51235},{\"end\":51250,\"start\":51246},{\"end\":51263,\"start\":51257},{\"end\":51278,\"start\":51275},{\"end\":51291,\"start\":51288},{\"end\":51307,\"start\":51302},{\"end\":51334,\"start\":51328},{\"end\":51345,\"start\":51339},{\"end\":51361,\"start\":51355},{\"end\":51372,\"start\":51367},{\"end\":51375,\"start\":51373},{\"end\":51387,\"start\":51380},{\"end\":51401,\"start\":51394},{\"end\":51417,\"start\":51410},{\"end\":51434,\"start\":51425},{\"end\":51436,\"start\":51435},{\"end\":52403,\"start\":52397},{\"end\":52413,\"start\":52408},{\"end\":52422,\"start\":52418},{\"end\":52439,\"start\":52430},{\"end\":52450,\"start\":52445},{\"end\":52468,\"start\":52462},{\"end\":52877,\"start\":52875},{\"end\":52891,\"start\":52884},{\"end\":52906,\"start\":52899},{\"end\":53303,\"start\":53299},{\"end\":53316,\"start\":53309},{\"end\":53327,\"start\":53322},{\"end\":53335,\"start\":53332},{\"end\":53649,\"start\":53647},{\"end\":53662,\"start\":53657},{\"end\":53673,\"start\":53669},{\"end\":53682,\"start\":53679},{\"end\":54098,\"start\":54089},{\"end\":54112,\"start\":54106},{\"end\":54124,\"start\":54117},{\"end\":54136,\"start\":54129},{\"end\":54146,\"start\":54143},{\"end\":54160,\"start\":54154},{\"end\":54172,\"start\":54167},{\"end\":54187,\"start\":54179},{\"end\":54703,\"start\":54697},{\"end\":54715,\"start\":54710},{\"end\":54728,\"start\":54725},{\"end\":54743,\"start\":54736},{\"end\":54753,\"start\":54748},{\"end\":54769,\"start\":54761},{\"end\":33661,\"start\":33656},{\"end\":33676,\"start\":33671},{\"end\":33689,\"start\":33684},{\"end\":33702,\"start\":33696},{\"end\":33716,\"start\":33709},{\"end\":33727,\"start\":33723},{\"end\":33742,\"start\":33737},{\"end\":33754,\"start\":33750},{\"end\":33769,\"start\":33763},{\"end\":33780,\"start\":33775},{\"end\":34287,\"start\":34282},{\"end\":34304,\"start\":34298},{\"end\":34319,\"start\":34315},{\"end\":34336,\"start\":34329},{\"end\":34615,\"start\":34610},{\"end\":34632,\"start\":34626},{\"end\":34647,\"start\":34643},{\"end\":34664,\"start\":34657},{\"end\":35011,\"start\":35006},{\"end\":35030,\"start\":35022},{\"end\":35040,\"start\":35035},{\"end\":35056,\"start\":35050},{\"end\":35068,\"start\":35064},{\"end\":35085,\"start\":35078},{\"end\":35096,\"start\":35093},{\"end\":35558,\"start\":35553},{\"end\":35568,\"start\":35564},{\"end\":35585,\"start\":35579},{\"end\":35599,\"start\":35591},{\"end\":35609,\"start\":35606},{\"end\":35624,\"start\":35620},{\"end\":35639,\"start\":35632},{\"end\":35949,\"start\":35945},{\"end\":35963,\"start\":35956},{\"end\":35974,\"start\":35971},{\"end\":35988,\"start\":35981},{\"end\":35998,\"start\":35994},{\"end\":36008,\"start\":36005},{\"end\":36022,\"start\":36014},{\"end\":36530,\"start\":36524},{\"end\":36540,\"start\":36537},{\"end\":36555,\"start\":36547},{\"end\":36572,\"start\":36561},{\"end\":36590,\"start\":36583},{\"end\":36603,\"start\":36598},{\"end\":36622,\"start\":36612},{\"end\":36983,\"start\":36976},{\"end\":36993,\"start\":36990},{\"end\":37004,\"start\":36998},{\"end\":37016,\"start\":37012},{\"end\":37025,\"start\":37022},{\"end\":37506,\"start\":37500},{\"end\":37806,\"start\":37799},{\"end\":37822,\"start\":37818},{\"end\":38175,\"start\":38170},{\"end\":38192,\"start\":38184},{\"end\":38206,\"start\":38200},{\"end\":38220,\"start\":38212},{\"end\":38230,\"start\":38221},{\"end\":38544,\"start\":38538},{\"end\":38563,\"start\":38558},{\"end\":38580,\"start\":38571},{\"end\":38597,\"start\":38593},{\"end\":38618,\"start\":38611},{\"end\":38631,\"start\":38625},{\"end\":38652,\"start\":38645},{\"end\":38671,\"start\":38663},{\"end\":38687,\"start\":38682},{\"end\":39178,\"start\":39171},{\"end\":39196,\"start\":39189},{\"end\":39214,\"start\":39213},{\"end\":39225,\"start\":39223},{\"end\":39243,\"start\":39238},{\"end\":39258,\"start\":39250},{\"end\":39275,\"start\":39267},{\"end\":39289,\"start\":39281},{\"end\":39298,\"start\":39294},{\"end\":39300,\"start\":39299},{\"end\":39845,\"start\":39840},{\"end\":39853,\"start\":39851},{\"end\":39871,\"start\":39865},{\"end\":39882,\"start\":39879},{\"end\":39898,\"start\":39892},{\"end\":40181,\"start\":40174},{\"end\":40192,\"start\":40187},{\"end\":40206,\"start\":40199},{\"end\":40218,\"start\":40213},{\"end\":40226,\"start\":40223},{\"end\":40612,\"start\":40607},{\"end\":40627,\"start\":40622},{\"end\":40642,\"start\":40638},{\"end\":40655,\"start\":40651},{\"end\":40972,\"start\":40966},{\"end\":40985,\"start\":40983},{\"end\":41413,\"start\":41412},{\"end\":41429,\"start\":41424},{\"end\":41624,\"start\":41618},{\"end\":41631,\"start\":41629},{\"end\":41645,\"start\":41637},{\"end\":41659,\"start\":41650},{\"end\":41674,\"start\":41667},{\"end\":41682,\"start\":41679},{\"end\":41696,\"start\":41690},{\"end\":41710,\"start\":41703},{\"end\":41717,\"start\":41715},{\"end\":41728,\"start\":41724},{\"end\":42133,\"start\":42129},{\"end\":42146,\"start\":42141},{\"end\":42451,\"start\":42443},{\"end\":42468,\"start\":42457},{\"end\":42978,\"start\":42970},{\"end\":42991,\"start\":42984},{\"end\":43004,\"start\":42999},{\"end\":43020,\"start\":43015},{\"end\":43033,\"start\":43027},{\"end\":43046,\"start\":43042},{\"end\":43061,\"start\":43056},{\"end\":43080,\"start\":43070},{\"end\":43446,\"start\":43443},{\"end\":43457,\"start\":43452},{\"end\":43472,\"start\":43464},{\"end\":43484,\"start\":43478},{\"end\":43494,\"start\":43490},{\"end\":43692,\"start\":43688},{\"end\":43710,\"start\":43705},{\"end\":44007,\"start\":44001},{\"end\":44017,\"start\":44012},{\"end\":44029,\"start\":44025},{\"end\":44044,\"start\":44038},{\"end\":44341,\"start\":44334},{\"end\":44352,\"start\":44347},{\"end\":44366,\"start\":44357},{\"end\":44379,\"start\":44372},{\"end\":44393,\"start\":44385},{\"end\":44404,\"start\":44398},{\"end\":44420,\"start\":44412},{\"end\":44434,\"start\":44426},{\"end\":44752,\"start\":44745},{\"end\":44768,\"start\":44763},{\"end\":44781,\"start\":44777},{\"end\":44796,\"start\":44788},{\"end\":45263,\"start\":45261},{\"end\":45281,\"start\":45275},{\"end\":45289,\"start\":45286},{\"end\":45307,\"start\":45301},{\"end\":45322,\"start\":45318},{\"end\":45778,\"start\":45774},{\"end\":45792,\"start\":45788},{\"end\":45797,\"start\":45793},{\"end\":45808,\"start\":45803},{\"end\":45824,\"start\":45818},{\"end\":45840,\"start\":45833},{\"end\":45854,\"start\":45846},{\"end\":45870,\"start\":45864},{\"end\":45885,\"start\":45879},{\"end\":45900,\"start\":45894},{\"end\":45914,\"start\":45910},{\"end\":46286,\"start\":46282},{\"end\":46303,\"start\":46296},{\"end\":46313,\"start\":46308},{\"end\":46326,\"start\":46321},{\"end\":46338,\"start\":46333},{\"end\":46351,\"start\":46347},{\"end\":46642,\"start\":46635},{\"end\":46661,\"start\":46657},{\"end\":46670,\"start\":46666},{\"end\":47005,\"start\":47004},{\"end\":47021,\"start\":47014},{\"end\":47037,\"start\":47030},{\"end\":47055,\"start\":47049},{\"end\":47072,\"start\":47064},{\"end\":47577,\"start\":47571},{\"end\":47589,\"start\":47586},{\"end\":47605,\"start\":47596},{\"end\":47619,\"start\":47615},{\"end\":48171,\"start\":48165},{\"end\":48191,\"start\":48183},{\"end\":48207,\"start\":48200},{\"end\":48223,\"start\":48217},{\"end\":48245,\"start\":48237},{\"end\":48259,\"start\":48255},{\"end\":48584,\"start\":48581},{\"end\":48595,\"start\":48590},{\"end\":48816,\"start\":48810},{\"end\":48830,\"start\":48826},{\"end\":48844,\"start\":48840},{\"end\":48858,\"start\":48853},{\"end\":48875,\"start\":48870},{\"end\":48888,\"start\":48883},{\"end\":48890,\"start\":48889},{\"end\":48904,\"start\":48898},{\"end\":48918,\"start\":48913},{\"end\":49285,\"start\":49274},{\"end\":49304,\"start\":49296},{\"end\":49318,\"start\":49314},{\"end\":49744,\"start\":49739},{\"end\":49763,\"start\":49754},{\"end\":49776,\"start\":49772},{\"end\":49792,\"start\":49785},{\"end\":50239,\"start\":50234},{\"end\":50249,\"start\":50246},{\"end\":50262,\"start\":50255},{\"end\":50274,\"start\":50269},{\"end\":50283,\"start\":50282},{\"end\":50776,\"start\":50771},{\"end\":50789,\"start\":50783},{\"end\":50799,\"start\":50794},{\"end\":50803,\"start\":50800},{\"end\":50814,\"start\":50808},{\"end\":50825,\"start\":50820},{\"end\":50840,\"start\":50836},{\"end\":51135,\"start\":51129},{\"end\":51150,\"start\":51142},{\"end\":51164,\"start\":51158},{\"end\":51177,\"start\":51171},{\"end\":51195,\"start\":51188},{\"end\":51213,\"start\":51206},{\"end\":51226,\"start\":51219},{\"end\":51238,\"start\":51235},{\"end\":51250,\"start\":51246},{\"end\":51263,\"start\":51257},{\"end\":51278,\"start\":51275},{\"end\":51291,\"start\":51288},{\"end\":51307,\"start\":51302},{\"end\":51334,\"start\":51328},{\"end\":51345,\"start\":51339},{\"end\":51361,\"start\":51355},{\"end\":51372,\"start\":51367},{\"end\":51375,\"start\":51373},{\"end\":51387,\"start\":51380},{\"end\":51401,\"start\":51394},{\"end\":51417,\"start\":51410},{\"end\":51434,\"start\":51425},{\"end\":51436,\"start\":51435},{\"end\":52403,\"start\":52397},{\"end\":52413,\"start\":52408},{\"end\":52422,\"start\":52418},{\"end\":52439,\"start\":52430},{\"end\":52450,\"start\":52445},{\"end\":52468,\"start\":52462},{\"end\":52877,\"start\":52875},{\"end\":52891,\"start\":52884},{\"end\":52906,\"start\":52899},{\"end\":53303,\"start\":53299},{\"end\":53316,\"start\":53309},{\"end\":53327,\"start\":53322},{\"end\":53335,\"start\":53332},{\"end\":53649,\"start\":53647},{\"end\":53662,\"start\":53657},{\"end\":53673,\"start\":53669},{\"end\":53682,\"start\":53679},{\"end\":54098,\"start\":54089},{\"end\":54112,\"start\":54106},{\"end\":54124,\"start\":54117},{\"end\":54136,\"start\":54129},{\"end\":54146,\"start\":54143},{\"end\":54160,\"start\":54154},{\"end\":54172,\"start\":54167},{\"end\":54187,\"start\":54179},{\"end\":54703,\"start\":54697},{\"end\":54715,\"start\":54710},{\"end\":54728,\"start\":54725},{\"end\":54743,\"start\":54736},{\"end\":54753,\"start\":54748},{\"end\":54769,\"start\":54761}]", "bib_author_last_name": "[{\"end\":33669,\"start\":33662},{\"end\":33682,\"start\":33677},{\"end\":33694,\"start\":33690},{\"end\":33707,\"start\":33703},{\"end\":33721,\"start\":33717},{\"end\":33735,\"start\":33728},{\"end\":33748,\"start\":33743},{\"end\":33761,\"start\":33755},{\"end\":33773,\"start\":33770},{\"end\":33789,\"start\":33781},{\"end\":34296,\"start\":34288},{\"end\":34313,\"start\":34305},{\"end\":34327,\"start\":34320},{\"end\":34342,\"start\":34337},{\"end\":34624,\"start\":34616},{\"end\":34641,\"start\":34633},{\"end\":34655,\"start\":34648},{\"end\":34670,\"start\":34665},{\"end\":35020,\"start\":35012},{\"end\":35033,\"start\":35031},{\"end\":35048,\"start\":35041},{\"end\":35062,\"start\":35057},{\"end\":35076,\"start\":35069},{\"end\":35091,\"start\":35086},{\"end\":35102,\"start\":35097},{\"end\":35562,\"start\":35559},{\"end\":35577,\"start\":35569},{\"end\":35589,\"start\":35586},{\"end\":35604,\"start\":35600},{\"end\":35618,\"start\":35610},{\"end\":35630,\"start\":35625},{\"end\":35648,\"start\":35640},{\"end\":35954,\"start\":35950},{\"end\":35969,\"start\":35964},{\"end\":35979,\"start\":35975},{\"end\":35992,\"start\":35989},{\"end\":36003,\"start\":35999},{\"end\":36012,\"start\":36009},{\"end\":36027,\"start\":36023},{\"end\":36535,\"start\":36531},{\"end\":36545,\"start\":36541},{\"end\":36559,\"start\":36556},{\"end\":36581,\"start\":36573},{\"end\":36596,\"start\":36591},{\"end\":36610,\"start\":36604},{\"end\":36630,\"start\":36623},{\"end\":36988,\"start\":36984},{\"end\":36996,\"start\":36994},{\"end\":37010,\"start\":37005},{\"end\":37020,\"start\":37017},{\"end\":37029,\"start\":37026},{\"end\":37511,\"start\":37507},{\"end\":37529,\"start\":37513},{\"end\":37816,\"start\":37807},{\"end\":37828,\"start\":37823},{\"end\":38182,\"start\":38176},{\"end\":38198,\"start\":38193},{\"end\":38210,\"start\":38207},{\"end\":38235,\"start\":38231},{\"end\":38556,\"start\":38545},{\"end\":38569,\"start\":38564},{\"end\":38591,\"start\":38581},{\"end\":38609,\"start\":38598},{\"end\":38623,\"start\":38619},{\"end\":38643,\"start\":38632},{\"end\":38661,\"start\":38653},{\"end\":38680,\"start\":38672},{\"end\":38695,\"start\":38688},{\"end\":39187,\"start\":39179},{\"end\":39202,\"start\":39197},{\"end\":39211,\"start\":39204},{\"end\":39221,\"start\":39215},{\"end\":39236,\"start\":39226},{\"end\":39248,\"start\":39244},{\"end\":39265,\"start\":39259},{\"end\":39279,\"start\":39276},{\"end\":39292,\"start\":39290},{\"end\":39309,\"start\":39301},{\"end\":39316,\"start\":39311},{\"end\":39849,\"start\":39846},{\"end\":39863,\"start\":39854},{\"end\":39877,\"start\":39872},{\"end\":39890,\"start\":39883},{\"end\":39907,\"start\":39899},{\"end\":40185,\"start\":40182},{\"end\":40197,\"start\":40193},{\"end\":40211,\"start\":40207},{\"end\":40221,\"start\":40219},{\"end\":40230,\"start\":40227},{\"end\":40620,\"start\":40613},{\"end\":40636,\"start\":40628},{\"end\":40649,\"start\":40643},{\"end\":40662,\"start\":40656},{\"end\":40981,\"start\":40973},{\"end\":40993,\"start\":40986},{\"end\":41422,\"start\":41414},{\"end\":41436,\"start\":41430},{\"end\":41440,\"start\":41438},{\"end\":41627,\"start\":41625},{\"end\":41635,\"start\":41632},{\"end\":41648,\"start\":41646},{\"end\":41665,\"start\":41660},{\"end\":41677,\"start\":41675},{\"end\":41688,\"start\":41683},{\"end\":41701,\"start\":41697},{\"end\":41713,\"start\":41711},{\"end\":41722,\"start\":41718},{\"end\":41732,\"start\":41729},{\"end\":42139,\"start\":42134},{\"end\":42149,\"start\":42147},{\"end\":42156,\"start\":42151},{\"end\":42455,\"start\":42452},{\"end\":42472,\"start\":42469},{\"end\":42982,\"start\":42979},{\"end\":42997,\"start\":42992},{\"end\":43013,\"start\":43005},{\"end\":43025,\"start\":43021},{\"end\":43040,\"start\":43034},{\"end\":43054,\"start\":43047},{\"end\":43068,\"start\":43062},{\"end\":43088,\"start\":43081},{\"end\":43450,\"start\":43447},{\"end\":43462,\"start\":43458},{\"end\":43476,\"start\":43473},{\"end\":43488,\"start\":43485},{\"end\":43498,\"start\":43495},{\"end\":43703,\"start\":43693},{\"end\":43717,\"start\":43711},{\"end\":44010,\"start\":44008},{\"end\":44023,\"start\":44018},{\"end\":44036,\"start\":44030},{\"end\":44048,\"start\":44045},{\"end\":44345,\"start\":44342},{\"end\":44355,\"start\":44353},{\"end\":44370,\"start\":44367},{\"end\":44383,\"start\":44380},{\"end\":44396,\"start\":44394},{\"end\":44410,\"start\":44405},{\"end\":44424,\"start\":44421},{\"end\":44437,\"start\":44435},{\"end\":44761,\"start\":44753},{\"end\":44775,\"start\":44769},{\"end\":44786,\"start\":44782},{\"end\":44800,\"start\":44797},{\"end\":45273,\"start\":45264},{\"end\":45284,\"start\":45282},{\"end\":45299,\"start\":45290},{\"end\":45316,\"start\":45308},{\"end\":45333,\"start\":45323},{\"end\":45786,\"start\":45779},{\"end\":45801,\"start\":45798},{\"end\":45816,\"start\":45809},{\"end\":45831,\"start\":45825},{\"end\":45844,\"start\":45841},{\"end\":45862,\"start\":45855},{\"end\":45877,\"start\":45871},{\"end\":45892,\"start\":45886},{\"end\":45908,\"start\":45901},{\"end\":45920,\"start\":45915},{\"end\":46294,\"start\":46287},{\"end\":46306,\"start\":46304},{\"end\":46319,\"start\":46314},{\"end\":46331,\"start\":46327},{\"end\":46345,\"start\":46339},{\"end\":46361,\"start\":46352},{\"end\":46655,\"start\":46643},{\"end\":46664,\"start\":46662},{\"end\":46679,\"start\":46671},{\"end\":46684,\"start\":46681},{\"end\":47012,\"start\":47006},{\"end\":47028,\"start\":47022},{\"end\":47047,\"start\":47038},{\"end\":47062,\"start\":47056},{\"end\":47077,\"start\":47073},{\"end\":47083,\"start\":47079},{\"end\":47584,\"start\":47578},{\"end\":47594,\"start\":47590},{\"end\":47613,\"start\":47606},{\"end\":47627,\"start\":47620},{\"end\":48181,\"start\":48172},{\"end\":48198,\"start\":48192},{\"end\":48215,\"start\":48208},{\"end\":48235,\"start\":48224},{\"end\":48253,\"start\":48246},{\"end\":48269,\"start\":48260},{\"end\":48588,\"start\":48585},{\"end\":48602,\"start\":48596},{\"end\":48824,\"start\":48817},{\"end\":48838,\"start\":48831},{\"end\":48851,\"start\":48845},{\"end\":48868,\"start\":48859},{\"end\":48881,\"start\":48876},{\"end\":48896,\"start\":48891},{\"end\":48911,\"start\":48905},{\"end\":48929,\"start\":48919},{\"end\":49294,\"start\":49286},{\"end\":49312,\"start\":49305},{\"end\":49325,\"start\":49319},{\"end\":49752,\"start\":49745},{\"end\":49770,\"start\":49764},{\"end\":49783,\"start\":49777},{\"end\":49798,\"start\":49793},{\"end\":50244,\"start\":50240},{\"end\":50253,\"start\":50250},{\"end\":50267,\"start\":50263},{\"end\":50280,\"start\":50275},{\"end\":50292,\"start\":50284},{\"end\":50302,\"start\":50294},{\"end\":50781,\"start\":50777},{\"end\":50792,\"start\":50790},{\"end\":50806,\"start\":50804},{\"end\":50818,\"start\":50815},{\"end\":50834,\"start\":50826},{\"end\":50844,\"start\":50841},{\"end\":51140,\"start\":51136},{\"end\":51156,\"start\":51151},{\"end\":51169,\"start\":51165},{\"end\":51186,\"start\":51178},{\"end\":51204,\"start\":51196},{\"end\":51217,\"start\":51214},{\"end\":51233,\"start\":51227},{\"end\":51244,\"start\":51239},{\"end\":51255,\"start\":51251},{\"end\":51273,\"start\":51264},{\"end\":51286,\"start\":51279},{\"end\":51300,\"start\":51292},{\"end\":51326,\"start\":51308},{\"end\":51337,\"start\":51335},{\"end\":51353,\"start\":51346},{\"end\":51365,\"start\":51362},{\"end\":51378,\"start\":51376},{\"end\":51392,\"start\":51388},{\"end\":51408,\"start\":51402},{\"end\":51423,\"start\":51418},{\"end\":51443,\"start\":51437},{\"end\":51449,\"start\":51445},{\"end\":52406,\"start\":52404},{\"end\":52416,\"start\":52414},{\"end\":52428,\"start\":52423},{\"end\":52443,\"start\":52440},{\"end\":52460,\"start\":52451},{\"end\":52481,\"start\":52469},{\"end\":52882,\"start\":52878},{\"end\":52897,\"start\":52892},{\"end\":52910,\"start\":52907},{\"end\":53307,\"start\":53304},{\"end\":53320,\"start\":53317},{\"end\":53330,\"start\":53328},{\"end\":53339,\"start\":53336},{\"end\":53655,\"start\":53650},{\"end\":53667,\"start\":53663},{\"end\":53677,\"start\":53674},{\"end\":53688,\"start\":53683},{\"end\":54104,\"start\":54099},{\"end\":54115,\"start\":54113},{\"end\":54127,\"start\":54125},{\"end\":54141,\"start\":54137},{\"end\":54152,\"start\":54147},{\"end\":54165,\"start\":54161},{\"end\":54177,\"start\":54173},{\"end\":54191,\"start\":54188},{\"end\":54708,\"start\":54704},{\"end\":54723,\"start\":54716},{\"end\":54734,\"start\":54729},{\"end\":54746,\"start\":54744},{\"end\":54759,\"start\":54754},{\"end\":54773,\"start\":54770},{\"end\":33669,\"start\":33662},{\"end\":33682,\"start\":33677},{\"end\":33694,\"start\":33690},{\"end\":33707,\"start\":33703},{\"end\":33721,\"start\":33717},{\"end\":33735,\"start\":33728},{\"end\":33748,\"start\":33743},{\"end\":33761,\"start\":33755},{\"end\":33773,\"start\":33770},{\"end\":33789,\"start\":33781},{\"end\":34296,\"start\":34288},{\"end\":34313,\"start\":34305},{\"end\":34327,\"start\":34320},{\"end\":34342,\"start\":34337},{\"end\":34624,\"start\":34616},{\"end\":34641,\"start\":34633},{\"end\":34655,\"start\":34648},{\"end\":34670,\"start\":34665},{\"end\":35020,\"start\":35012},{\"end\":35033,\"start\":35031},{\"end\":35048,\"start\":35041},{\"end\":35062,\"start\":35057},{\"end\":35076,\"start\":35069},{\"end\":35091,\"start\":35086},{\"end\":35102,\"start\":35097},{\"end\":35562,\"start\":35559},{\"end\":35577,\"start\":35569},{\"end\":35589,\"start\":35586},{\"end\":35604,\"start\":35600},{\"end\":35618,\"start\":35610},{\"end\":35630,\"start\":35625},{\"end\":35648,\"start\":35640},{\"end\":35954,\"start\":35950},{\"end\":35969,\"start\":35964},{\"end\":35979,\"start\":35975},{\"end\":35992,\"start\":35989},{\"end\":36003,\"start\":35999},{\"end\":36012,\"start\":36009},{\"end\":36027,\"start\":36023},{\"end\":36535,\"start\":36531},{\"end\":36545,\"start\":36541},{\"end\":36559,\"start\":36556},{\"end\":36581,\"start\":36573},{\"end\":36596,\"start\":36591},{\"end\":36610,\"start\":36604},{\"end\":36630,\"start\":36623},{\"end\":36988,\"start\":36984},{\"end\":36996,\"start\":36994},{\"end\":37010,\"start\":37005},{\"end\":37020,\"start\":37017},{\"end\":37029,\"start\":37026},{\"end\":37511,\"start\":37507},{\"end\":37529,\"start\":37513},{\"end\":37816,\"start\":37807},{\"end\":37828,\"start\":37823},{\"end\":38182,\"start\":38176},{\"end\":38198,\"start\":38193},{\"end\":38210,\"start\":38207},{\"end\":38235,\"start\":38231},{\"end\":38556,\"start\":38545},{\"end\":38569,\"start\":38564},{\"end\":38591,\"start\":38581},{\"end\":38609,\"start\":38598},{\"end\":38623,\"start\":38619},{\"end\":38643,\"start\":38632},{\"end\":38661,\"start\":38653},{\"end\":38680,\"start\":38672},{\"end\":38695,\"start\":38688},{\"end\":39187,\"start\":39179},{\"end\":39202,\"start\":39197},{\"end\":39211,\"start\":39204},{\"end\":39221,\"start\":39215},{\"end\":39236,\"start\":39226},{\"end\":39248,\"start\":39244},{\"end\":39265,\"start\":39259},{\"end\":39279,\"start\":39276},{\"end\":39292,\"start\":39290},{\"end\":39309,\"start\":39301},{\"end\":39316,\"start\":39311},{\"end\":39849,\"start\":39846},{\"end\":39863,\"start\":39854},{\"end\":39877,\"start\":39872},{\"end\":39890,\"start\":39883},{\"end\":39907,\"start\":39899},{\"end\":40185,\"start\":40182},{\"end\":40197,\"start\":40193},{\"end\":40211,\"start\":40207},{\"end\":40221,\"start\":40219},{\"end\":40230,\"start\":40227},{\"end\":40620,\"start\":40613},{\"end\":40636,\"start\":40628},{\"end\":40649,\"start\":40643},{\"end\":40662,\"start\":40656},{\"end\":40981,\"start\":40973},{\"end\":40993,\"start\":40986},{\"end\":41422,\"start\":41414},{\"end\":41436,\"start\":41430},{\"end\":41440,\"start\":41438},{\"end\":41627,\"start\":41625},{\"end\":41635,\"start\":41632},{\"end\":41648,\"start\":41646},{\"end\":41665,\"start\":41660},{\"end\":41677,\"start\":41675},{\"end\":41688,\"start\":41683},{\"end\":41701,\"start\":41697},{\"end\":41713,\"start\":41711},{\"end\":41722,\"start\":41718},{\"end\":41732,\"start\":41729},{\"end\":42139,\"start\":42134},{\"end\":42149,\"start\":42147},{\"end\":42156,\"start\":42151},{\"end\":42455,\"start\":42452},{\"end\":42472,\"start\":42469},{\"end\":42982,\"start\":42979},{\"end\":42997,\"start\":42992},{\"end\":43013,\"start\":43005},{\"end\":43025,\"start\":43021},{\"end\":43040,\"start\":43034},{\"end\":43054,\"start\":43047},{\"end\":43068,\"start\":43062},{\"end\":43088,\"start\":43081},{\"end\":43450,\"start\":43447},{\"end\":43462,\"start\":43458},{\"end\":43476,\"start\":43473},{\"end\":43488,\"start\":43485},{\"end\":43498,\"start\":43495},{\"end\":43703,\"start\":43693},{\"end\":43717,\"start\":43711},{\"end\":44010,\"start\":44008},{\"end\":44023,\"start\":44018},{\"end\":44036,\"start\":44030},{\"end\":44048,\"start\":44045},{\"end\":44345,\"start\":44342},{\"end\":44355,\"start\":44353},{\"end\":44370,\"start\":44367},{\"end\":44383,\"start\":44380},{\"end\":44396,\"start\":44394},{\"end\":44410,\"start\":44405},{\"end\":44424,\"start\":44421},{\"end\":44437,\"start\":44435},{\"end\":44761,\"start\":44753},{\"end\":44775,\"start\":44769},{\"end\":44786,\"start\":44782},{\"end\":44800,\"start\":44797},{\"end\":45273,\"start\":45264},{\"end\":45284,\"start\":45282},{\"end\":45299,\"start\":45290},{\"end\":45316,\"start\":45308},{\"end\":45333,\"start\":45323},{\"end\":45786,\"start\":45779},{\"end\":45801,\"start\":45798},{\"end\":45816,\"start\":45809},{\"end\":45831,\"start\":45825},{\"end\":45844,\"start\":45841},{\"end\":45862,\"start\":45855},{\"end\":45877,\"start\":45871},{\"end\":45892,\"start\":45886},{\"end\":45908,\"start\":45901},{\"end\":45920,\"start\":45915},{\"end\":46294,\"start\":46287},{\"end\":46306,\"start\":46304},{\"end\":46319,\"start\":46314},{\"end\":46331,\"start\":46327},{\"end\":46345,\"start\":46339},{\"end\":46361,\"start\":46352},{\"end\":46655,\"start\":46643},{\"end\":46664,\"start\":46662},{\"end\":46679,\"start\":46671},{\"end\":46684,\"start\":46681},{\"end\":47012,\"start\":47006},{\"end\":47028,\"start\":47022},{\"end\":47047,\"start\":47038},{\"end\":47062,\"start\":47056},{\"end\":47077,\"start\":47073},{\"end\":47083,\"start\":47079},{\"end\":47584,\"start\":47578},{\"end\":47594,\"start\":47590},{\"end\":47613,\"start\":47606},{\"end\":47627,\"start\":47620},{\"end\":48181,\"start\":48172},{\"end\":48198,\"start\":48192},{\"end\":48215,\"start\":48208},{\"end\":48235,\"start\":48224},{\"end\":48253,\"start\":48246},{\"end\":48269,\"start\":48260},{\"end\":48588,\"start\":48585},{\"end\":48602,\"start\":48596},{\"end\":48824,\"start\":48817},{\"end\":48838,\"start\":48831},{\"end\":48851,\"start\":48845},{\"end\":48868,\"start\":48859},{\"end\":48881,\"start\":48876},{\"end\":48896,\"start\":48891},{\"end\":48911,\"start\":48905},{\"end\":48929,\"start\":48919},{\"end\":49294,\"start\":49286},{\"end\":49312,\"start\":49305},{\"end\":49325,\"start\":49319},{\"end\":49752,\"start\":49745},{\"end\":49770,\"start\":49764},{\"end\":49783,\"start\":49777},{\"end\":49798,\"start\":49793},{\"end\":50244,\"start\":50240},{\"end\":50253,\"start\":50250},{\"end\":50267,\"start\":50263},{\"end\":50280,\"start\":50275},{\"end\":50292,\"start\":50284},{\"end\":50302,\"start\":50294},{\"end\":50781,\"start\":50777},{\"end\":50792,\"start\":50790},{\"end\":50806,\"start\":50804},{\"end\":50818,\"start\":50815},{\"end\":50834,\"start\":50826},{\"end\":50844,\"start\":50841},{\"end\":51140,\"start\":51136},{\"end\":51156,\"start\":51151},{\"end\":51169,\"start\":51165},{\"end\":51186,\"start\":51178},{\"end\":51204,\"start\":51196},{\"end\":51217,\"start\":51214},{\"end\":51233,\"start\":51227},{\"end\":51244,\"start\":51239},{\"end\":51255,\"start\":51251},{\"end\":51273,\"start\":51264},{\"end\":51286,\"start\":51279},{\"end\":51300,\"start\":51292},{\"end\":51326,\"start\":51308},{\"end\":51337,\"start\":51335},{\"end\":51353,\"start\":51346},{\"end\":51365,\"start\":51362},{\"end\":51378,\"start\":51376},{\"end\":51392,\"start\":51388},{\"end\":51408,\"start\":51402},{\"end\":51423,\"start\":51418},{\"end\":51443,\"start\":51437},{\"end\":51449,\"start\":51445},{\"end\":52406,\"start\":52404},{\"end\":52416,\"start\":52414},{\"end\":52428,\"start\":52423},{\"end\":52443,\"start\":52440},{\"end\":52460,\"start\":52451},{\"end\":52481,\"start\":52469},{\"end\":52882,\"start\":52878},{\"end\":52897,\"start\":52892},{\"end\":52910,\"start\":52907},{\"end\":53307,\"start\":53304},{\"end\":53320,\"start\":53317},{\"end\":53330,\"start\":53328},{\"end\":53339,\"start\":53336},{\"end\":53655,\"start\":53650},{\"end\":53667,\"start\":53663},{\"end\":53677,\"start\":53674},{\"end\":53688,\"start\":53683},{\"end\":54104,\"start\":54099},{\"end\":54115,\"start\":54113},{\"end\":54127,\"start\":54125},{\"end\":54141,\"start\":54137},{\"end\":54152,\"start\":54147},{\"end\":54165,\"start\":54161},{\"end\":54177,\"start\":54173},{\"end\":54191,\"start\":54188},{\"end\":54708,\"start\":54704},{\"end\":54723,\"start\":54716},{\"end\":54734,\"start\":54729},{\"end\":54746,\"start\":54744},{\"end\":54759,\"start\":54754},{\"end\":54773,\"start\":54770}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":56517630},\"end\":34210,\"start\":33614},{\"attributes\":{\"doi\":\"arXiv:1612.00576\",\"id\":\"b1\"},\"end\":34552,\"start\":34212},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11933981},\"end\":34919,\"start\":34554},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3753452},\"end\":35549,\"start\":34921},{\"attributes\":{\"doi\":\"arXiv:2103.10951\",\"id\":\"b4\"},\"end\":35851,\"start\":35551},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":206596371},\"end\":36458,\"start\":35853},{\"attributes\":{\"doi\":\"arXiv:1504.00325\",\"id\":\"b6\"},\"end\":36888,\"start\":36460},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4717181},\"end\":37425,\"start\":36890},{\"attributes\":{\"doi\":\"arXiv:1411.5654\",\"id\":\"b8\"},\"end\":37713,\"start\":37427},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":5923323},\"end\":38168,\"start\":37715},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b10\"},\"end\":38536,\"start\":38170},{\"attributes\":{\"doi\":\"arXiv:2010.11929\",\"id\":\"b11\"},\"end\":39126,\"start\":38538},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":9254582},\"end\":39772,\"start\":39128},{\"attributes\":{\"doi\":\"arXiv:2108.00946\",\"id\":\"b13\"},\"end\":40120,\"start\":39774},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":119304359},\"end\":40605,\"start\":40122},{\"attributes\":{\"doi\":\"arXiv:1906.05963\",\"id\":\"b15\"},\"end\":40897,\"start\":40607},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":8517067},\"end\":41350,\"start\":40899},{\"attributes\":{\"id\":\"b17\"},\"end\":41551,\"start\":41352},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":215754208},\"end\":42066,\"start\":41553},{\"attributes\":{\"doi\":\"arXiv:2101.00190\",\"id\":\"b19\"},\"end\":42328,\"start\":42068},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1586456},\"end\":42925,\"start\":42330},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":14113767},\"end\":43388,\"start\":42927},{\"attributes\":{\"doi\":\"arXiv:2101.10804\",\"id\":\"b22\"},\"end\":43684,\"start\":43390},{\"attributes\":{\"doi\":\"arXiv:1711.05101\",\"id\":\"b23\"},\"end\":43901,\"start\":43686},{\"attributes\":{\"doi\":\"arXiv:1908.02265\",\"id\":\"b24\"},\"end\":44273,\"start\":43903},{\"attributes\":{\"doi\":\"arXiv:2101.06462\",\"id\":\"b25\"},\"end\":44679,\"start\":44275},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":11080756},\"end\":45202,\"start\":44681},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":232428282},\"end\":45701,\"start\":45204},{\"attributes\":{\"doi\":\"arXiv:2103.00020\",\"id\":\"b28\"},\"end\":46227,\"start\":45703},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":160025533},\"end\":46553,\"start\":46229},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":10328909},\"end\":46948,\"start\":46555},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":206594923},\"end\":47470,\"start\":46950},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":51876975},\"end\":48114,\"start\":47472},{\"attributes\":{\"doi\":\"arXiv:2107.06912\",\"id\":\"b33\"},\"end\":48505,\"start\":48116},{\"attributes\":{\"doi\":\"arXiv:1908.07490\",\"id\":\"b34\"},\"end\":48781,\"start\":48507},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":13756489},\"end\":49219,\"start\":48783},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":9026666},\"end\":49688,\"start\":49221},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":1169492},\"end\":50165,\"start\":49690},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":764110},\"end\":50697,\"start\":50167},{\"attributes\":{\"doi\":\"arXiv:2108.10904\",\"id\":\"b39\"},\"end\":51067,\"start\":50699},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":208117506},\"end\":52286,\"start\":51069},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b41\",\"matched_paper_id\":1055111},\"end\":52814,\"start\":52288},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":121347508},\"end\":53245,\"start\":52816},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":52304560},\"end\":53645,\"start\":53247},{\"attributes\":{\"doi\":\"arXiv:1706.09601\",\"id\":\"b44\"},\"end\":54019,\"start\":53647},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":235692795},\"end\":54629,\"start\":54021},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":202734445},\"end\":55150,\"start\":54631},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":56517630},\"end\":34210,\"start\":33614},{\"attributes\":{\"doi\":\"arXiv:1612.00576\",\"id\":\"b1\"},\"end\":34552,\"start\":34212},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11933981},\"end\":34919,\"start\":34554},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3753452},\"end\":35549,\"start\":34921},{\"attributes\":{\"doi\":\"arXiv:2103.10951\",\"id\":\"b4\"},\"end\":35851,\"start\":35551},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":206596371},\"end\":36458,\"start\":35853},{\"attributes\":{\"doi\":\"arXiv:1504.00325\",\"id\":\"b6\"},\"end\":36888,\"start\":36460},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4717181},\"end\":37425,\"start\":36890},{\"attributes\":{\"doi\":\"arXiv:1411.5654\",\"id\":\"b8\"},\"end\":37713,\"start\":37427},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":5923323},\"end\":38168,\"start\":37715},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b10\"},\"end\":38536,\"start\":38170},{\"attributes\":{\"doi\":\"arXiv:2010.11929\",\"id\":\"b11\"},\"end\":39126,\"start\":38538},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":9254582},\"end\":39772,\"start\":39128},{\"attributes\":{\"doi\":\"arXiv:2108.00946\",\"id\":\"b13\"},\"end\":40120,\"start\":39774},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":119304359},\"end\":40605,\"start\":40122},{\"attributes\":{\"doi\":\"arXiv:1906.05963\",\"id\":\"b15\"},\"end\":40897,\"start\":40607},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":8517067},\"end\":41350,\"start\":40899},{\"attributes\":{\"id\":\"b17\"},\"end\":41551,\"start\":41352},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":215754208},\"end\":42066,\"start\":41553},{\"attributes\":{\"doi\":\"arXiv:2101.00190\",\"id\":\"b19\"},\"end\":42328,\"start\":42068},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1586456},\"end\":42925,\"start\":42330},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":14113767},\"end\":43388,\"start\":42927},{\"attributes\":{\"doi\":\"arXiv:2101.10804\",\"id\":\"b22\"},\"end\":43684,\"start\":43390},{\"attributes\":{\"doi\":\"arXiv:1711.05101\",\"id\":\"b23\"},\"end\":43901,\"start\":43686},{\"attributes\":{\"doi\":\"arXiv:1908.02265\",\"id\":\"b24\"},\"end\":44273,\"start\":43903},{\"attributes\":{\"doi\":\"arXiv:2101.06462\",\"id\":\"b25\"},\"end\":44679,\"start\":44275},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":11080756},\"end\":45202,\"start\":44681},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":232428282},\"end\":45701,\"start\":45204},{\"attributes\":{\"doi\":\"arXiv:2103.00020\",\"id\":\"b28\"},\"end\":46227,\"start\":45703},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":160025533},\"end\":46553,\"start\":46229},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":10328909},\"end\":46948,\"start\":46555},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":206594923},\"end\":47470,\"start\":46950},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":51876975},\"end\":48114,\"start\":47472},{\"attributes\":{\"doi\":\"arXiv:2107.06912\",\"id\":\"b33\"},\"end\":48505,\"start\":48116},{\"attributes\":{\"doi\":\"arXiv:1908.07490\",\"id\":\"b34\"},\"end\":48781,\"start\":48507},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":13756489},\"end\":49219,\"start\":48783},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":9026666},\"end\":49688,\"start\":49221},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":1169492},\"end\":50165,\"start\":49690},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":764110},\"end\":50697,\"start\":50167},{\"attributes\":{\"doi\":\"arXiv:2108.10904\",\"id\":\"b39\"},\"end\":51067,\"start\":50699},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":208117506},\"end\":52286,\"start\":51069},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b41\",\"matched_paper_id\":1055111},\"end\":52814,\"start\":52288},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":121347508},\"end\":53245,\"start\":52816},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":52304560},\"end\":53645,\"start\":53247},{\"attributes\":{\"doi\":\"arXiv:1706.09601\",\"id\":\"b44\"},\"end\":54019,\"start\":53647},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":235692795},\"end\":54629,\"start\":54021},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":202734445},\"end\":55150,\"start\":54631}]", "bib_title": "[{\"end\":33654,\"start\":33614},{\"end\":34608,\"start\":34554},{\"end\":35004,\"start\":34921},{\"end\":35943,\"start\":35853},{\"end\":36974,\"start\":36890},{\"end\":37797,\"start\":37715},{\"end\":39169,\"start\":39128},{\"end\":40172,\"start\":40122},{\"end\":40964,\"start\":40899},{\"end\":41616,\"start\":41553},{\"end\":42441,\"start\":42330},{\"end\":42968,\"start\":42927},{\"end\":44743,\"start\":44681},{\"end\":45259,\"start\":45204},{\"end\":46280,\"start\":46229},{\"end\":46633,\"start\":46555},{\"end\":47002,\"start\":46950},{\"end\":47569,\"start\":47472},{\"end\":48808,\"start\":48783},{\"end\":49272,\"start\":49221},{\"end\":49737,\"start\":49690},{\"end\":50232,\"start\":50167},{\"end\":51127,\"start\":51069},{\"end\":52395,\"start\":52288},{\"end\":52873,\"start\":52816},{\"end\":53297,\"start\":53247},{\"end\":54087,\"start\":54021},{\"end\":54695,\"start\":54631},{\"end\":33654,\"start\":33614},{\"end\":34608,\"start\":34554},{\"end\":35004,\"start\":34921},{\"end\":35943,\"start\":35853},{\"end\":36974,\"start\":36890},{\"end\":37797,\"start\":37715},{\"end\":39169,\"start\":39128},{\"end\":40172,\"start\":40122},{\"end\":40964,\"start\":40899},{\"end\":41616,\"start\":41553},{\"end\":42441,\"start\":42330},{\"end\":42968,\"start\":42927},{\"end\":44743,\"start\":44681},{\"end\":45259,\"start\":45204},{\"end\":46280,\"start\":46229},{\"end\":46633,\"start\":46555},{\"end\":47002,\"start\":46950},{\"end\":47569,\"start\":47472},{\"end\":48808,\"start\":48783},{\"end\":49272,\"start\":49221},{\"end\":49737,\"start\":49690},{\"end\":50232,\"start\":50167},{\"end\":51127,\"start\":51069},{\"end\":52395,\"start\":52288},{\"end\":52873,\"start\":52816},{\"end\":53297,\"start\":53247},{\"end\":54087,\"start\":54021},{\"end\":54695,\"start\":54631}]", "bib_author": "[{\"end\":33671,\"start\":33656},{\"end\":33684,\"start\":33671},{\"end\":33696,\"start\":33684},{\"end\":33709,\"start\":33696},{\"end\":33723,\"start\":33709},{\"end\":33737,\"start\":33723},{\"end\":33750,\"start\":33737},{\"end\":33763,\"start\":33750},{\"end\":33775,\"start\":33763},{\"end\":33791,\"start\":33775},{\"end\":34298,\"start\":34282},{\"end\":34315,\"start\":34298},{\"end\":34329,\"start\":34315},{\"end\":34344,\"start\":34329},{\"end\":34626,\"start\":34610},{\"end\":34643,\"start\":34626},{\"end\":34657,\"start\":34643},{\"end\":34672,\"start\":34657},{\"end\":35022,\"start\":35006},{\"end\":35035,\"start\":35022},{\"end\":35050,\"start\":35035},{\"end\":35064,\"start\":35050},{\"end\":35078,\"start\":35064},{\"end\":35093,\"start\":35078},{\"end\":35104,\"start\":35093},{\"end\":35564,\"start\":35553},{\"end\":35579,\"start\":35564},{\"end\":35591,\"start\":35579},{\"end\":35606,\"start\":35591},{\"end\":35620,\"start\":35606},{\"end\":35632,\"start\":35620},{\"end\":35650,\"start\":35632},{\"end\":35956,\"start\":35945},{\"end\":35971,\"start\":35956},{\"end\":35981,\"start\":35971},{\"end\":35994,\"start\":35981},{\"end\":36005,\"start\":35994},{\"end\":36014,\"start\":36005},{\"end\":36029,\"start\":36014},{\"end\":36537,\"start\":36524},{\"end\":36547,\"start\":36537},{\"end\":36561,\"start\":36547},{\"end\":36583,\"start\":36561},{\"end\":36598,\"start\":36583},{\"end\":36612,\"start\":36598},{\"end\":36632,\"start\":36612},{\"end\":36990,\"start\":36976},{\"end\":36998,\"start\":36990},{\"end\":37012,\"start\":36998},{\"end\":37022,\"start\":37012},{\"end\":37031,\"start\":37022},{\"end\":37513,\"start\":37500},{\"end\":37531,\"start\":37513},{\"end\":37818,\"start\":37799},{\"end\":37830,\"start\":37818},{\"end\":38184,\"start\":38170},{\"end\":38200,\"start\":38184},{\"end\":38212,\"start\":38200},{\"end\":38237,\"start\":38212},{\"end\":38558,\"start\":38538},{\"end\":38571,\"start\":38558},{\"end\":38593,\"start\":38571},{\"end\":38611,\"start\":38593},{\"end\":38625,\"start\":38611},{\"end\":38645,\"start\":38625},{\"end\":38663,\"start\":38645},{\"end\":38682,\"start\":38663},{\"end\":38697,\"start\":38682},{\"end\":39189,\"start\":39171},{\"end\":39204,\"start\":39189},{\"end\":39213,\"start\":39204},{\"end\":39223,\"start\":39213},{\"end\":39238,\"start\":39223},{\"end\":39250,\"start\":39238},{\"end\":39267,\"start\":39250},{\"end\":39281,\"start\":39267},{\"end\":39294,\"start\":39281},{\"end\":39311,\"start\":39294},{\"end\":39318,\"start\":39311},{\"end\":39851,\"start\":39840},{\"end\":39865,\"start\":39851},{\"end\":39879,\"start\":39865},{\"end\":39892,\"start\":39879},{\"end\":39909,\"start\":39892},{\"end\":40187,\"start\":40174},{\"end\":40199,\"start\":40187},{\"end\":40213,\"start\":40199},{\"end\":40223,\"start\":40213},{\"end\":40232,\"start\":40223},{\"end\":40622,\"start\":40607},{\"end\":40638,\"start\":40622},{\"end\":40651,\"start\":40638},{\"end\":40664,\"start\":40651},{\"end\":40983,\"start\":40966},{\"end\":40995,\"start\":40983},{\"end\":41424,\"start\":41412},{\"end\":41438,\"start\":41424},{\"end\":41442,\"start\":41438},{\"end\":41629,\"start\":41618},{\"end\":41637,\"start\":41629},{\"end\":41650,\"start\":41637},{\"end\":41667,\"start\":41650},{\"end\":41679,\"start\":41667},{\"end\":41690,\"start\":41679},{\"end\":41703,\"start\":41690},{\"end\":41715,\"start\":41703},{\"end\":41724,\"start\":41715},{\"end\":41734,\"start\":41724},{\"end\":42141,\"start\":42129},{\"end\":42151,\"start\":42141},{\"end\":42158,\"start\":42151},{\"end\":42457,\"start\":42443},{\"end\":42474,\"start\":42457},{\"end\":42984,\"start\":42970},{\"end\":42999,\"start\":42984},{\"end\":43015,\"start\":42999},{\"end\":43027,\"start\":43015},{\"end\":43042,\"start\":43027},{\"end\":43056,\"start\":43042},{\"end\":43070,\"start\":43056},{\"end\":43090,\"start\":43070},{\"end\":43452,\"start\":43443},{\"end\":43464,\"start\":43452},{\"end\":43478,\"start\":43464},{\"end\":43490,\"start\":43478},{\"end\":43500,\"start\":43490},{\"end\":43705,\"start\":43688},{\"end\":43719,\"start\":43705},{\"end\":44012,\"start\":44001},{\"end\":44025,\"start\":44012},{\"end\":44038,\"start\":44025},{\"end\":44050,\"start\":44038},{\"end\":44347,\"start\":44334},{\"end\":44357,\"start\":44347},{\"end\":44372,\"start\":44357},{\"end\":44385,\"start\":44372},{\"end\":44398,\"start\":44385},{\"end\":44412,\"start\":44398},{\"end\":44426,\"start\":44412},{\"end\":44439,\"start\":44426},{\"end\":44763,\"start\":44745},{\"end\":44777,\"start\":44763},{\"end\":44788,\"start\":44777},{\"end\":44802,\"start\":44788},{\"end\":45275,\"start\":45261},{\"end\":45286,\"start\":45275},{\"end\":45301,\"start\":45286},{\"end\":45318,\"start\":45301},{\"end\":45335,\"start\":45318},{\"end\":45788,\"start\":45774},{\"end\":45803,\"start\":45788},{\"end\":45818,\"start\":45803},{\"end\":45833,\"start\":45818},{\"end\":45846,\"start\":45833},{\"end\":45864,\"start\":45846},{\"end\":45879,\"start\":45864},{\"end\":45894,\"start\":45879},{\"end\":45910,\"start\":45894},{\"end\":45922,\"start\":45910},{\"end\":46296,\"start\":46282},{\"end\":46308,\"start\":46296},{\"end\":46321,\"start\":46308},{\"end\":46333,\"start\":46321},{\"end\":46347,\"start\":46333},{\"end\":46363,\"start\":46347},{\"end\":46657,\"start\":46635},{\"end\":46666,\"start\":46657},{\"end\":46681,\"start\":46666},{\"end\":46686,\"start\":46681},{\"end\":47014,\"start\":47004},{\"end\":47030,\"start\":47014},{\"end\":47049,\"start\":47030},{\"end\":47064,\"start\":47049},{\"end\":47079,\"start\":47064},{\"end\":47085,\"start\":47079},{\"end\":47586,\"start\":47571},{\"end\":47596,\"start\":47586},{\"end\":47615,\"start\":47596},{\"end\":47629,\"start\":47615},{\"end\":48183,\"start\":48165},{\"end\":48200,\"start\":48183},{\"end\":48217,\"start\":48200},{\"end\":48237,\"start\":48217},{\"end\":48255,\"start\":48237},{\"end\":48271,\"start\":48255},{\"end\":48590,\"start\":48581},{\"end\":48604,\"start\":48590},{\"end\":48826,\"start\":48810},{\"end\":48840,\"start\":48826},{\"end\":48853,\"start\":48840},{\"end\":48870,\"start\":48853},{\"end\":48883,\"start\":48870},{\"end\":48898,\"start\":48883},{\"end\":48913,\"start\":48898},{\"end\":48931,\"start\":48913},{\"end\":49296,\"start\":49274},{\"end\":49314,\"start\":49296},{\"end\":49327,\"start\":49314},{\"end\":49754,\"start\":49739},{\"end\":49772,\"start\":49754},{\"end\":49785,\"start\":49772},{\"end\":49800,\"start\":49785},{\"end\":50246,\"start\":50234},{\"end\":50255,\"start\":50246},{\"end\":50269,\"start\":50255},{\"end\":50282,\"start\":50269},{\"end\":50294,\"start\":50282},{\"end\":50304,\"start\":50294},{\"end\":50783,\"start\":50771},{\"end\":50794,\"start\":50783},{\"end\":50808,\"start\":50794},{\"end\":50820,\"start\":50808},{\"end\":50836,\"start\":50820},{\"end\":50846,\"start\":50836},{\"end\":51142,\"start\":51129},{\"end\":51158,\"start\":51142},{\"end\":51171,\"start\":51158},{\"end\":51188,\"start\":51171},{\"end\":51206,\"start\":51188},{\"end\":51219,\"start\":51206},{\"end\":51235,\"start\":51219},{\"end\":51246,\"start\":51235},{\"end\":51257,\"start\":51246},{\"end\":51275,\"start\":51257},{\"end\":51288,\"start\":51275},{\"end\":51302,\"start\":51288},{\"end\":51328,\"start\":51302},{\"end\":51339,\"start\":51328},{\"end\":51355,\"start\":51339},{\"end\":51367,\"start\":51355},{\"end\":51380,\"start\":51367},{\"end\":51394,\"start\":51380},{\"end\":51410,\"start\":51394},{\"end\":51425,\"start\":51410},{\"end\":51445,\"start\":51425},{\"end\":51451,\"start\":51445},{\"end\":52408,\"start\":52397},{\"end\":52418,\"start\":52408},{\"end\":52430,\"start\":52418},{\"end\":52445,\"start\":52430},{\"end\":52462,\"start\":52445},{\"end\":52483,\"start\":52462},{\"end\":52884,\"start\":52875},{\"end\":52899,\"start\":52884},{\"end\":52912,\"start\":52899},{\"end\":53309,\"start\":53299},{\"end\":53322,\"start\":53309},{\"end\":53332,\"start\":53322},{\"end\":53341,\"start\":53332},{\"end\":53657,\"start\":53647},{\"end\":53669,\"start\":53657},{\"end\":53679,\"start\":53669},{\"end\":53690,\"start\":53679},{\"end\":54106,\"start\":54089},{\"end\":54117,\"start\":54106},{\"end\":54129,\"start\":54117},{\"end\":54143,\"start\":54129},{\"end\":54154,\"start\":54143},{\"end\":54167,\"start\":54154},{\"end\":54179,\"start\":54167},{\"end\":54193,\"start\":54179},{\"end\":54710,\"start\":54697},{\"end\":54725,\"start\":54710},{\"end\":54736,\"start\":54725},{\"end\":54748,\"start\":54736},{\"end\":54761,\"start\":54748},{\"end\":54775,\"start\":54761},{\"end\":33671,\"start\":33656},{\"end\":33684,\"start\":33671},{\"end\":33696,\"start\":33684},{\"end\":33709,\"start\":33696},{\"end\":33723,\"start\":33709},{\"end\":33737,\"start\":33723},{\"end\":33750,\"start\":33737},{\"end\":33763,\"start\":33750},{\"end\":33775,\"start\":33763},{\"end\":33791,\"start\":33775},{\"end\":34298,\"start\":34282},{\"end\":34315,\"start\":34298},{\"end\":34329,\"start\":34315},{\"end\":34344,\"start\":34329},{\"end\":34626,\"start\":34610},{\"end\":34643,\"start\":34626},{\"end\":34657,\"start\":34643},{\"end\":34672,\"start\":34657},{\"end\":35022,\"start\":35006},{\"end\":35035,\"start\":35022},{\"end\":35050,\"start\":35035},{\"end\":35064,\"start\":35050},{\"end\":35078,\"start\":35064},{\"end\":35093,\"start\":35078},{\"end\":35104,\"start\":35093},{\"end\":35564,\"start\":35553},{\"end\":35579,\"start\":35564},{\"end\":35591,\"start\":35579},{\"end\":35606,\"start\":35591},{\"end\":35620,\"start\":35606},{\"end\":35632,\"start\":35620},{\"end\":35650,\"start\":35632},{\"end\":35956,\"start\":35945},{\"end\":35971,\"start\":35956},{\"end\":35981,\"start\":35971},{\"end\":35994,\"start\":35981},{\"end\":36005,\"start\":35994},{\"end\":36014,\"start\":36005},{\"end\":36029,\"start\":36014},{\"end\":36537,\"start\":36524},{\"end\":36547,\"start\":36537},{\"end\":36561,\"start\":36547},{\"end\":36583,\"start\":36561},{\"end\":36598,\"start\":36583},{\"end\":36612,\"start\":36598},{\"end\":36632,\"start\":36612},{\"end\":36990,\"start\":36976},{\"end\":36998,\"start\":36990},{\"end\":37012,\"start\":36998},{\"end\":37022,\"start\":37012},{\"end\":37031,\"start\":37022},{\"end\":37513,\"start\":37500},{\"end\":37531,\"start\":37513},{\"end\":37818,\"start\":37799},{\"end\":37830,\"start\":37818},{\"end\":38184,\"start\":38170},{\"end\":38200,\"start\":38184},{\"end\":38212,\"start\":38200},{\"end\":38237,\"start\":38212},{\"end\":38558,\"start\":38538},{\"end\":38571,\"start\":38558},{\"end\":38593,\"start\":38571},{\"end\":38611,\"start\":38593},{\"end\":38625,\"start\":38611},{\"end\":38645,\"start\":38625},{\"end\":38663,\"start\":38645},{\"end\":38682,\"start\":38663},{\"end\":38697,\"start\":38682},{\"end\":39189,\"start\":39171},{\"end\":39204,\"start\":39189},{\"end\":39213,\"start\":39204},{\"end\":39223,\"start\":39213},{\"end\":39238,\"start\":39223},{\"end\":39250,\"start\":39238},{\"end\":39267,\"start\":39250},{\"end\":39281,\"start\":39267},{\"end\":39294,\"start\":39281},{\"end\":39311,\"start\":39294},{\"end\":39318,\"start\":39311},{\"end\":39851,\"start\":39840},{\"end\":39865,\"start\":39851},{\"end\":39879,\"start\":39865},{\"end\":39892,\"start\":39879},{\"end\":39909,\"start\":39892},{\"end\":40187,\"start\":40174},{\"end\":40199,\"start\":40187},{\"end\":40213,\"start\":40199},{\"end\":40223,\"start\":40213},{\"end\":40232,\"start\":40223},{\"end\":40622,\"start\":40607},{\"end\":40638,\"start\":40622},{\"end\":40651,\"start\":40638},{\"end\":40664,\"start\":40651},{\"end\":40983,\"start\":40966},{\"end\":40995,\"start\":40983},{\"end\":41424,\"start\":41412},{\"end\":41438,\"start\":41424},{\"end\":41442,\"start\":41438},{\"end\":41629,\"start\":41618},{\"end\":41637,\"start\":41629},{\"end\":41650,\"start\":41637},{\"end\":41667,\"start\":41650},{\"end\":41679,\"start\":41667},{\"end\":41690,\"start\":41679},{\"end\":41703,\"start\":41690},{\"end\":41715,\"start\":41703},{\"end\":41724,\"start\":41715},{\"end\":41734,\"start\":41724},{\"end\":42141,\"start\":42129},{\"end\":42151,\"start\":42141},{\"end\":42158,\"start\":42151},{\"end\":42457,\"start\":42443},{\"end\":42474,\"start\":42457},{\"end\":42984,\"start\":42970},{\"end\":42999,\"start\":42984},{\"end\":43015,\"start\":42999},{\"end\":43027,\"start\":43015},{\"end\":43042,\"start\":43027},{\"end\":43056,\"start\":43042},{\"end\":43070,\"start\":43056},{\"end\":43090,\"start\":43070},{\"end\":43452,\"start\":43443},{\"end\":43464,\"start\":43452},{\"end\":43478,\"start\":43464},{\"end\":43490,\"start\":43478},{\"end\":43500,\"start\":43490},{\"end\":43705,\"start\":43688},{\"end\":43719,\"start\":43705},{\"end\":44012,\"start\":44001},{\"end\":44025,\"start\":44012},{\"end\":44038,\"start\":44025},{\"end\":44050,\"start\":44038},{\"end\":44347,\"start\":44334},{\"end\":44357,\"start\":44347},{\"end\":44372,\"start\":44357},{\"end\":44385,\"start\":44372},{\"end\":44398,\"start\":44385},{\"end\":44412,\"start\":44398},{\"end\":44426,\"start\":44412},{\"end\":44439,\"start\":44426},{\"end\":44763,\"start\":44745},{\"end\":44777,\"start\":44763},{\"end\":44788,\"start\":44777},{\"end\":44802,\"start\":44788},{\"end\":45275,\"start\":45261},{\"end\":45286,\"start\":45275},{\"end\":45301,\"start\":45286},{\"end\":45318,\"start\":45301},{\"end\":45335,\"start\":45318},{\"end\":45788,\"start\":45774},{\"end\":45803,\"start\":45788},{\"end\":45818,\"start\":45803},{\"end\":45833,\"start\":45818},{\"end\":45846,\"start\":45833},{\"end\":45864,\"start\":45846},{\"end\":45879,\"start\":45864},{\"end\":45894,\"start\":45879},{\"end\":45910,\"start\":45894},{\"end\":45922,\"start\":45910},{\"end\":46296,\"start\":46282},{\"end\":46308,\"start\":46296},{\"end\":46321,\"start\":46308},{\"end\":46333,\"start\":46321},{\"end\":46347,\"start\":46333},{\"end\":46363,\"start\":46347},{\"end\":46657,\"start\":46635},{\"end\":46666,\"start\":46657},{\"end\":46681,\"start\":46666},{\"end\":46686,\"start\":46681},{\"end\":47014,\"start\":47004},{\"end\":47030,\"start\":47014},{\"end\":47049,\"start\":47030},{\"end\":47064,\"start\":47049},{\"end\":47079,\"start\":47064},{\"end\":47085,\"start\":47079},{\"end\":47586,\"start\":47571},{\"end\":47596,\"start\":47586},{\"end\":47615,\"start\":47596},{\"end\":47629,\"start\":47615},{\"end\":48183,\"start\":48165},{\"end\":48200,\"start\":48183},{\"end\":48217,\"start\":48200},{\"end\":48237,\"start\":48217},{\"end\":48255,\"start\":48237},{\"end\":48271,\"start\":48255},{\"end\":48590,\"start\":48581},{\"end\":48604,\"start\":48590},{\"end\":48826,\"start\":48810},{\"end\":48840,\"start\":48826},{\"end\":48853,\"start\":48840},{\"end\":48870,\"start\":48853},{\"end\":48883,\"start\":48870},{\"end\":48898,\"start\":48883},{\"end\":48913,\"start\":48898},{\"end\":48931,\"start\":48913},{\"end\":49296,\"start\":49274},{\"end\":49314,\"start\":49296},{\"end\":49327,\"start\":49314},{\"end\":49754,\"start\":49739},{\"end\":49772,\"start\":49754},{\"end\":49785,\"start\":49772},{\"end\":49800,\"start\":49785},{\"end\":50246,\"start\":50234},{\"end\":50255,\"start\":50246},{\"end\":50269,\"start\":50255},{\"end\":50282,\"start\":50269},{\"end\":50294,\"start\":50282},{\"end\":50304,\"start\":50294},{\"end\":50783,\"start\":50771},{\"end\":50794,\"start\":50783},{\"end\":50808,\"start\":50794},{\"end\":50820,\"start\":50808},{\"end\":50836,\"start\":50820},{\"end\":50846,\"start\":50836},{\"end\":51142,\"start\":51129},{\"end\":51158,\"start\":51142},{\"end\":51171,\"start\":51158},{\"end\":51188,\"start\":51171},{\"end\":51206,\"start\":51188},{\"end\":51219,\"start\":51206},{\"end\":51235,\"start\":51219},{\"end\":51246,\"start\":51235},{\"end\":51257,\"start\":51246},{\"end\":51275,\"start\":51257},{\"end\":51288,\"start\":51275},{\"end\":51302,\"start\":51288},{\"end\":51328,\"start\":51302},{\"end\":51339,\"start\":51328},{\"end\":51355,\"start\":51339},{\"end\":51367,\"start\":51355},{\"end\":51380,\"start\":51367},{\"end\":51394,\"start\":51380},{\"end\":51410,\"start\":51394},{\"end\":51425,\"start\":51410},{\"end\":51445,\"start\":51425},{\"end\":51451,\"start\":51445},{\"end\":52408,\"start\":52397},{\"end\":52418,\"start\":52408},{\"end\":52430,\"start\":52418},{\"end\":52445,\"start\":52430},{\"end\":52462,\"start\":52445},{\"end\":52483,\"start\":52462},{\"end\":52884,\"start\":52875},{\"end\":52899,\"start\":52884},{\"end\":52912,\"start\":52899},{\"end\":53309,\"start\":53299},{\"end\":53322,\"start\":53309},{\"end\":53332,\"start\":53322},{\"end\":53341,\"start\":53332},{\"end\":53657,\"start\":53647},{\"end\":53669,\"start\":53657},{\"end\":53679,\"start\":53669},{\"end\":53690,\"start\":53679},{\"end\":54106,\"start\":54089},{\"end\":54117,\"start\":54106},{\"end\":54129,\"start\":54117},{\"end\":54143,\"start\":54129},{\"end\":54154,\"start\":54143},{\"end\":54167,\"start\":54154},{\"end\":54179,\"start\":54167},{\"end\":54193,\"start\":54179},{\"end\":54710,\"start\":54697},{\"end\":54725,\"start\":54710},{\"end\":54736,\"start\":54725},{\"end\":54748,\"start\":54736},{\"end\":54761,\"start\":54748},{\"end\":54775,\"start\":54761}]", "bib_venue": "[{\"end\":33920,\"start\":33864},{\"end\":35245,\"start\":35183},{\"end\":36170,\"start\":36108},{\"end\":37172,\"start\":37110},{\"end\":37953,\"start\":37900},{\"end\":39459,\"start\":39397},{\"end\":40381,\"start\":40315},{\"end\":41136,\"start\":41074},{\"end\":42653,\"start\":42572},{\"end\":44963,\"start\":44891},{\"end\":45464,\"start\":45408},{\"end\":47226,\"start\":47164},{\"end\":47790,\"start\":47718},{\"end\":49468,\"start\":49406},{\"end\":49941,\"start\":49879},{\"end\":50445,\"start\":50383},{\"end\":51662,\"start\":51562},{\"end\":53041,\"start\":52985},{\"end\":53456,\"start\":53407},{\"end\":54342,\"start\":54276},{\"end\":54884,\"start\":54838},{\"end\":33920,\"start\":33864},{\"end\":35245,\"start\":35183},{\"end\":36170,\"start\":36108},{\"end\":37172,\"start\":37110},{\"end\":37953,\"start\":37900},{\"end\":39459,\"start\":39397},{\"end\":40381,\"start\":40315},{\"end\":41136,\"start\":41074},{\"end\":42653,\"start\":42572},{\"end\":44963,\"start\":44891},{\"end\":45464,\"start\":45408},{\"end\":47226,\"start\":47164},{\"end\":47790,\"start\":47718},{\"end\":49468,\"start\":49406},{\"end\":49941,\"start\":49879},{\"end\":50445,\"start\":50383},{\"end\":51662,\"start\":51562},{\"end\":53041,\"start\":52985},{\"end\":53456,\"start\":53407},{\"end\":54342,\"start\":54276},{\"end\":54884,\"start\":54838},{\"end\":33862,\"start\":33791},{\"end\":34280,\"start\":34212},{\"end\":34710,\"start\":34672},{\"end\":35181,\"start\":35104},{\"end\":36106,\"start\":36029},{\"end\":36522,\"start\":36460},{\"end\":37108,\"start\":37031},{\"end\":37498,\"start\":37427},{\"end\":37898,\"start\":37830},{\"end\":38327,\"start\":38253},{\"end\":38809,\"start\":38713},{\"end\":39395,\"start\":39318},{\"end\":39838,\"start\":39774},{\"end\":40313,\"start\":40232},{\"end\":40729,\"start\":40680},{\"end\":41072,\"start\":40995},{\"end\":41410,\"start\":41352},{\"end\":41772,\"start\":41734},{\"end\":42127,\"start\":42068},{\"end\":42570,\"start\":42474},{\"end\":43128,\"start\":43090},{\"end\":43441,\"start\":43390},{\"end\":43999,\"start\":43903},{\"end\":44332,\"start\":44275},{\"end\":44889,\"start\":44802},{\"end\":45406,\"start\":45335},{\"end\":45772,\"start\":45703},{\"end\":46374,\"start\":46363},{\"end\":46735,\"start\":46686},{\"end\":47162,\"start\":47085},{\"end\":47716,\"start\":47629},{\"end\":48163,\"start\":48116},{\"end\":48579,\"start\":48507},{\"end\":48980,\"start\":48931},{\"end\":49404,\"start\":49327},{\"end\":49877,\"start\":49800},{\"end\":50381,\"start\":50304},{\"end\":50769,\"start\":50699},{\"end\":51560,\"start\":51451},{\"end\":52531,\"start\":52487},{\"end\":52983,\"start\":52912},{\"end\":53405,\"start\":53341},{\"end\":53811,\"start\":53706},{\"end\":54274,\"start\":54193},{\"end\":54836,\"start\":54775},{\"end\":33862,\"start\":33791},{\"end\":34280,\"start\":34212},{\"end\":34710,\"start\":34672},{\"end\":35181,\"start\":35104},{\"end\":36106,\"start\":36029},{\"end\":36522,\"start\":36460},{\"end\":37108,\"start\":37031},{\"end\":37498,\"start\":37427},{\"end\":37898,\"start\":37830},{\"end\":38327,\"start\":38253},{\"end\":38809,\"start\":38713},{\"end\":39395,\"start\":39318},{\"end\":39838,\"start\":39774},{\"end\":40313,\"start\":40232},{\"end\":40729,\"start\":40680},{\"end\":41072,\"start\":40995},{\"end\":41410,\"start\":41352},{\"end\":41772,\"start\":41734},{\"end\":42127,\"start\":42068},{\"end\":42570,\"start\":42474},{\"end\":43128,\"start\":43090},{\"end\":43441,\"start\":43390},{\"end\":43999,\"start\":43903},{\"end\":44332,\"start\":44275},{\"end\":44889,\"start\":44802},{\"end\":45406,\"start\":45335},{\"end\":45772,\"start\":45703},{\"end\":46374,\"start\":46363},{\"end\":46735,\"start\":46686},{\"end\":47162,\"start\":47085},{\"end\":47716,\"start\":47629},{\"end\":48163,\"start\":48116},{\"end\":48579,\"start\":48507},{\"end\":48980,\"start\":48931},{\"end\":49404,\"start\":49327},{\"end\":49877,\"start\":49800},{\"end\":50381,\"start\":50304},{\"end\":50769,\"start\":50699},{\"end\":51560,\"start\":51451},{\"end\":52531,\"start\":52487},{\"end\":52983,\"start\":52912},{\"end\":53405,\"start\":53341},{\"end\":53811,\"start\":53706},{\"end\":54274,\"start\":54193},{\"end\":54836,\"start\":54775}]"}}}, "year": 2023, "month": 12, "day": 17}