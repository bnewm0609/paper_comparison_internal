{"id": 235490679, "updated": "2023-10-06 01:43:04.12", "metadata": {"title": "FedCM: Federated Learning with Client-level Momentum", "authors": "[{\"first\":\"Jing\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Sen\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Liwei\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Andrew\",\"last\":\"Yao\",\"middle\":[\"Chi-Chih\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": 6, "day": 21}, "abstract": "Federated Learning is a distributed machine learning approach which enables model training without data sharing. In this paper, we propose a new federated learning algorithm, Federated Averaging with Client-level Momentum (FedCM), to tackle problems of partial participation and client heterogeneity in real-world federated learning applications. FedCM aggregates global gradient information in previous communication rounds and modifies client gradient descent with a momentum-like term, which can effectively correct the bias and improve the stability of local SGD. We provide theoretical analysis to highlight the benefits of FedCM. We also perform extensive empirical studies and demonstrate that FedCM achieves superior performance in various tasks and is robust to different levels of client numbers, participation rate and client heterogeneity.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2106.10874", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2106-10874", "doi": null}}, "content": {"source": {"pdf_hash": "d2addcff05a7944a59f3b0a88087cc043313fc47", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.10874v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "fd5c4511f4b60568b2924177ca82356d3f866077", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d2addcff05a7944a59f3b0a88087cc043313fc47.txt", "contents": "\nFedCM: Federated Learning with Client-level Momentum\n\n\nJing Xu \nSchool of EECS\nPeking University\n\n\nSen Wang wangsen31@huawei.com \nTheory Lab\nHuawei Technologies, Co.Ltd\n2021Labs, Hong Kong\n\nLiwei Wang wanglw@pku.edu.cn \nMOE\nSchool of EECS\nKey Laboratory of Machine Perception\nPeking University\n\n\nAndrew andrewcyao@tsinghua.edu.cn \nChi-Chih Yao \nInstitute for Interdisciplinary Information Sciences\nTsinghua University\n\n\nFedCM: Federated Learning with Client-level Momentum\n\nFederated Learning is a distributed machine learning approach which enables model training without data sharing. In this paper, we propose a new federated learning algorithm, Federated Averaging with Client-level Momentum (FedCM), to tackle problems of partial participation and client heterogeneity in real-world federated learning applications. FedCM aggregates global gradient information in previous communication rounds and modifies client gradient descent with a momentum-like term, which can effectively correct the bias and improve the stability of local SGD. We provide theoretical analysis to highlight the benefits of FedCM. We also perform extensive empirical studies and demonstrate that FedCM achieves superior performance in various tasks and is robust to different levels of client numbers, participation rate and client heterogeneity.Despite their empirical success, recent federated optimization algorithms are faced with the following two challenges of federated learning:Constrained Communication and Limited Participation. In the so-called cross-device setting, the participating clients consist of a large number, usually millions or more[Kairouz et al., 2019], of edge computing devices such as mobile phones. The communication between server and edge devices, typically slow and expensive, becomes a bottleneck in many federated learning tasks. Moreover, the connection link between server and clients is highly unreliable, which indicates that only a Preprint. Under review.\n\nIntroduction\n\nFederated Learning, first proposed in [McMahan et al., 2017], has gradually evolved into a standard approach for large-scale machine learning [Kairouz et al., 2019, Li et al., 2020. In contrast to traditional machine learning paradigms which train a model on a pre-collected dataset, federated learning utilizes the large amount of geographically distributed data in edge devices such as smartphones, wearable devices, or institutions such as hospitals and banks, to train a centralized model without transmitting the data. Furthermore, federated learning achieves the most basic level of data privacy in this manner, which is crucial for various applications [Regulation, 2016].\n\nTypically, federated Learning tasks are formulated into finite-sum optimization problems and usually solved using variants of distributed optimization algorithms. One of the most popular federated learning algorithms, FedAvg [McMahan et al., 2017], generalizes distributed SGD and performs multiple local gradient updates per round to save communication cost. Ever since its appearance, Various federated optimization algorithms [Li et al., 2018, Karimireddy et al., 2020b, Reddi et al., 2020, Acar et al., 2021 are proposed which make further efforts to accommodate SGD to federated learning setting. small portion of devices are able to participate in each communication rounds [Reddi et al., 2020]. The low participation rate makes it difficult to maintain client states between communication. As we will shown in experiments, existing methods [Karimireddy et al., 2020b] which keep local states between communication suffer a severe performance drop when we decrease client participation rate.\n\nClient Heterogeneity. The heterogeneity of client data arises naturally as the patterns of local training data reflect the usage of the device by a particular user, which can be quite different from the population distribution. It has been demonstrated both empirically and theoretically [Zhao et al., 2018, Karimireddy et al., 2020b] that client heterogeneity can introduce a drift in client updates and give rise to slower and unstable convergence, which is often termed as client drift. Recently, some works [Hsu et al., 2019, Xie et al., 2019, Reddi et al., 2020 extends traditional adaptive optimization methods to federated learning setting. Despite their empirical performance, these methods are not able to alleviate client drift, as they only involve server level adaptation and fail to modify local update directions.\n\nTo properly handle client heterogeneity, a federated learning algorithm is required to incorporate global gradient information into client local updates, in order to close the gap between local and global loss function. Furthermore, the global gradient information should not only contain gradient information computed in this round, but also keep track of gradient information obtained in previous rounds, which belongs to clients inactive this round due to limited participation.\n\nMotivated by above challenges and discussions, we propose a novel federated learning algorithm, Federated Averaging with Client-level Momentum (FedCM), which introduces a momentum term that aggregates global gradient information in previous rounds to modify the gradient steps of client updates. Instead of directly applying traditional momentum method to client or server updates, FedCM seamlessly incorporates the usage and update of momentum term into client and server gradient steps of FedAvg.\n\nFedCM has two major strengths over existing algorithms to tackle aforementioned challenges of federated learning. Firstly, FedCM do not require clients to maintain states between rounds, which saves client storage costs and guarantees performance in low client participation scenarios, compared with algorithms that keep control variates at client side [Karimireddy et al., 2020b, Acar et al., 2021. Secondly, In contrast to previous works that focus on server side momentum [Hsu et al., 2019, Reddi et al., 2020, in FedCM each client performs gradient descent using a combination of its local gradient as well as the global momentum that contains gradient information of other clients, which alleviates the influence of client heterogeneity. Our theoretical and empirical findings demonstrate the benefits of FedCM over existing methods.\n\nContributions. We summarize our contributions as follows:\n\n1. We propose FedCM, a novel, efficient and robust federated optimization algorithm, in which the server maintains a momentum term to guide client gradient updates. We show that FedCM is compatible with the real-world settings of cross-device federated learning, and successfully tackles the problem of client heterogeneity and partial participation.\n\n2. We give the convergence analysis of FedCM for strongly convex, general convex and nonconvex functions. The communication upper bounds we obtain match the best known results of our interest. Our analysis highlights the benefits of introducing client momentum in FedCM and shows the trade off in hyperparameter selection.\n\n3. We perform extensive experiments on CIFAR10 and CIFAR100 datasets, across various choices including client numbers, participation rate, client heterogeneity. We demonstrate that our method consistently outperforms other strong baselines and is more robust to client heterogeneity and partial participation.\n\n\nRelated works\n\nFederated learning was first proposed in McMahan et al. [2017], which summarizes the key properties of federated learning as non-iidness, unbalancedness, massively distribution, limited communication and proposes FedAvg algorithm as a solution. We refer the readers to Li et al. [2020] and Kairouz et al. [2019] for a more detailed overview of this field. Here we highlight the problem of non-iidness, also known as client heterogeneity, in federated learning. Client heterogeneity consists of statistical heterogeneity, i.e. the data distributions differ across different clients, and system heterogeneity, i.e. the hardware capabilities such as computational power, storage, communication speed vary for different clients. In this work we mostly focus on the former one. Client heterogeneity is first empirically observed by Zhao et al. [2018], which demonstrates that the performance of FedAvg has a significant degeneration on non-iid client training data. A lot of works make further efforts to explore the influence of heterogeneity in federated learning [Hsu et al., 2019, Hsieh et al., 2020, Wang et al., 2020. Some works propose personalization strategy [Dinh et al., 2020, Jiang et al., 2019, Hanzely et al., 2020, which can be combined with our method.\n\nThis work focuses on the optimization perspective of federated learning. Distributed optimization methods [Zinkevich et al., 2010, Boyd et al., 2011, Dean et al., 2012, Shamir et al., 2014, Stich, 2018 have been well studied for large scale machine learning before federated learning emerged.  [Zhang et al., 2020, Acar et al., 2021. Most of them require full participation, additional communication or client storage, which can be problematic in federated learning tasks. There is another line of work focusing on modifying server updates using momentum terms, which is related to FedCM. However, these methods focus on introducing momentum into either server-side updates [Hsu et al., 2019, Huo et al., 2020, Reddi et al., 2020 or client side updates , while FedCM incorporates the usage and update of momentum term into both local and global updates.\n\n\nPreliminaries\n\n\nNotations and Problem Formulation\n\nThroughout this paper, we use N and N + for non-negative integers and positive integers respectively. For n \u2208 N, let [n] be a short hand for the indicies {0, 1, \u00b7 \u00b7 \u00b7 , n \u2212 1}. \u00b7 denotes the Euclidean 2 norm if not otherwise specified. We use O to denote asymptotic upper bound which hides logarithmic factors. We use lowercase x to denote model parameters and lowercase z to denote training data or test data. (x, z) stands for the loss of data z evaluated at model parameters x.\n\nIn federated learning, we assume that there are totally N clients which hold their private data and perform local computation, as well as a central server which sends and receives messages from the clients. The i-th client holds n i data points {z i,j } j\u2208[ni] drawn from distribution D i . Note that D i may differ across different clients, which corresponds to client heterogeneity. Let f i (x) be the loss function of the i-th client, i.e. f i (x) = E z\u223cDi (x, z), and its empirical counterpart a\u015d\nf i (x) = 1 ni j\u2208[ni] (x, z i,j ).\nThe goal of federated learning is to minimize the average loss of all the clients, which can be formulated as argmin\nx f (x) = 1 N i\u2208[N ] f i (x)(1)\nTypically, federated learning algorithms orchestrates communication between server and clients to find the parameters x which minimizes the empirical loss functionf (\nx) = 1 N i\u2208[N ]f i (x).\nTherefore, we drop the superscript and only considers empirical risk minimization thereafter.\n\n\nFedAvg Algorithm\n\nFedAvg [McMahan et al., 2017] is one of the most popular methods to solve problem 1. FedAvg works as follows: in t-th communication round, the server randomly selects S clients and broadcasts its model parameters x t to them. After receiving the global model, these clients parallelly perform K local stochastic gradient descent using their private data, and send the resulting model x t i,K back to the server. After collecting the client models, the server averages their parameters to get the new global model x t+1 . The Pesudocode of FedAvg is given in algorithm 1. Note that we introduce the gradient average \u2206 t as the pseudo gradient with a server learning rate \u03b7 g . The original version in [McMahan et al., 2017] corresponds to \u03b7 g = K\u03b7 l in our formulation. It has been shown that choosing an appropriate global learning rate can improve the convergence of FedAvg [Reddi et al., 2020].\n\nAlgorithm 1 FedAvg 1: Initialization: x 0 , learning rates \u03b7 l , \u03b7 g , number of communication rounds T , number of local iterations K 2: for t = 0 to T \u2212 1 do 3:\n\nSample subset S of clients 4:\n\nfor Each client i \u2208 S in parallel do 5:\nx t i,0 = x t 6:\nfor k = 0 to K \u2212 1 do 7:\n\nCompute an unbiased estimate g t i,k of \u2207f i (x t i,k )\n\n8:\nx t i,k+1 = x t i,k \u2212 \u03b7 l g t i,k 9:\nend for 10:\n\u2206 t i = x t i,K \u2212 x t 11:\nend for 12:\n\u2206 t+1 = \u2212 1 \u03b7 l K|S| i\u2208S \u2206 t i\n13:\n\nx t+1 = x t \u2212 \u03b7 g \u2206 t+1 14: end for 4 Algorithm\n\nIn this section, we describe FedCM algorithm, and give explanations on how FedCM reduces client heterogeneity and improve convergence. Then we discuss the features of FedCM and show that FedCM is compatible with real-world federated learning settings.\n\n\nFedCM algorithm\n\nIn each communication round of FedAvg, \u2206 t serves as the direction for server model update. Noting that \u2206 t aggregates the gradient information of participating clients, a natural idea is to reuse \u2206 t to guide the client gradient descent in next communication round. This leads to the FedCM algorithm.\n\nThe pseudocode of FedCM is given in algorithm 2. Note that compared with FedAvg in algorithm 1, the only modification is in line 8, where we use the weighted average of current client gradient g t i,k and descent direction of the server model in previous round \u2206 t , as the parameter update direction for the client. \u2206 t is updated by the server when updating server model (see line 13), by averaging the parameter change \u2206 t i of all participating clients. Define the gradient average in the t-th global epoch as\u2206 t :\n\u2206 t = 1 K|S| i\u2208S,k\u2208[K] g t i,k\nThen we have the following lemma regarding the update of {\u2206 t }:\n\nLemma 4.1. \u2206 t is the exponential moving average of client gradients, i.e. \u2206 t+1 = \u03b1\u2206 t + (1 \u2212 \u03b1)\u2206 t Algorithm 2 FedCM 1: Initialization: x 0 , \u2206 0 = 0, decay parameter \u03b1 \u2208 (0, 1], learning rates \u03b7 l , \u03b7 g , number of communication rounds T , number of local iterations K 2: for t = 0 to T \u2212 1 do 3:\n\nSample subset S of clients 4:\n\nfor Each client i \u2208 S in parallel do 5:\nx t i,0 = x t 6:\nfor k = 0 to K \u2212 1 do 7:\n\nCompute an unbiased estimate \ng t i,k of \u2207f i (x t i,k ) 8: v t i,k = \u03b1g t i,k + (1 \u2212 \u03b1)\u2206 t 9: x t i,k+1 = x t i,k \u2212 \u03b7 l v t i,\u2206 t i = x t i,K \u2212 x t 12:\nend for 13:\n\u2206 t+1 = \u2212 1 \u03b7 l K|S| i\u2208S \u2206 t i 14: x t+1 = x t \u2212 \u03b7 g \u2206 t+1 15: end for Proof. \u2206 t+1 = \u2212 1 \u03b7 l K|S| i\u2208S \u2206 t i = \u2212 1 \u03b7 l K|S| i\u2208S (x t i,K \u2212 x t ) = \u2212 1 \u03b7 l K|S| i\u2208S K\u22121 k=0 \u2212\u03b7 l (\u03b1g t i,k + (1 \u2212 \u03b1)\u2206 t ) = 1 K|S| i\u2208S K\u22121 k=0 (\u03b1g t i,k + (1 \u2212 \u03b1)\u2206 t ) = \u03b1\u2206 t + (1 \u2212 \u03b1)\u2206 t\nLemma 4.1 implies that \u2206 t is the exponential moving average of past client gradients, which is similar to the momentum term in traditional optimization algorithms, justifying the name of FedCM. Note that despite only a subset of all clients are sampled each round, the gradient information of past local updates is still contained in \u2206 t . Therefore, FedCM is robust to partial client participation in federated learning. Furthermore, the momentum term \u2206 t serves as an approximation to the gradient of the global loss function \u2207f (\nx), i.e. \u2206 t \u2248 \u2207f (x t ). Therefore, we have v t i,k = \u03b1g t i,k + (1 \u2212 \u03b1)\u2206 t \u2248 g t i,k + (1 \u2212 \u03b1)(\u2207f (x t ) \u2212 \u2207f i (x t ))\nThis implies that FedCM adds a correction term to the local gradient direction, and this term asymptotically aligns with the difference between global and local gradient. This observation explains why FedCM reduces client heterogeneity and achieves better performance.\n\n\nDiscussions\n\nWhile there exists some related works [Karimireddy et al., 2020b, Acar et al., 2021 which also handle client heterogeneity by modifying local SGD procedure, one of the distinguishing features of FedCM is that clients do not have to keep local states in FedCM, which has the following major advantages. First, the history-free property of the algorithm makes cross-device federated learning much more flexible in a 'plug and use' manner, as the server does not have to resort to the same clients every round and any new-arriving client can join the training immediately without any warmup. Second, it saves the storage burden of clients, which can be crucial for some mobile devices. Furthermore, the stored local states can easily get stale if only a small fraction of devices are active each round, and this will hurt the convergence of the algorithm [Reddi et al., 2020].\n\nOne may wonder whether transmitting momentum term \u2206 t in FedCM will increase communication burden. First we point out that FedCM only increases the server-to-client communication, i.e. broadcasting the momentum term together with the parameter. The communication in the client-toserver direction remains unchanged. This is compatible with the asymmetric property of Internet service: the uplink is typically much slower than downlink [Kone\u010dn\u1ef3 et al., 2016]. For example the global average Internet speeds for mobile phones are 48.40 Mbps download v.s. 12.60 Mbps upload [speedtest.net, 2021]. Moreover, it is impossible to remove the bias in local gradient update caused by client heterogeneity, without additional information from the server and local states stored by the clients. In this sense, it is unavoidable to use additional communication if clients do not store local states.\n\n\nConvergence analysis\n\nWe give the theoretical analysis of FedCM in this section. First, we state the convexity and smoothness assumptions about the local loss function f i (x) and the global loss function f (x), which are standard in optimization literature [Reddi et al., 2020, Karimireddy et al., 2020b.\nAssumption 1 (Convexity). f i is \u00b5-strongly-convex for all i \u2208 [N ], i.e. f i (y) \u2265 f i (x) + \u2207f i (x), y \u2212 x + \u00b5 2 y \u2212 x 2\nfor all x, y in its domain and i \u2208 [N ]. We allow \u00b5 = 0, which corresponds to general convex functions.\nAssumption 2 (Smoothness). f i is L-smooth for all i \u2208 [N ], i.e. \u2207f i (x) \u2212 \u2207f i (y) \u2264 L x \u2212 y for all x, y in its domain and i \u2208 [N ].\nThe following assumption is commonly taken in analysis of momentum-like algorithms [Reddi et al., 2020, Tong et al., 2020. Assumption 3 (Bounded gradient). f has G-bounded gradients, i.e.\n\n\u2207f (x) \u2264 G for all x.\n\nNote that in assumption 3,we only require the global loss function, instead of every local loss function, to have bounded gradient. Otherwise, assumption 5 would be redundant.\n\nThe next two assumptions bound the gradient noise at both local and global levels. Assumption 4 (Unbiasedness and bounded variance of stochastic gradient). The stochastic gradient \u2207f i (x, \u03be) computed by the i-th client at model parameter x using minibatch \u03be is an unbiased\nestimator of \u2207f i (x) with variance bounded by \u03c3 2 l , i.e. E \u03be [\u2207f i (x, \u03be)] = \u2207f i (x), E \u03be \u2207f i (x, \u03be) \u2212 \u2207f i (x) 2 \u2264 \u03c3 2 l for all x and i \u2208 [N ].\nAssumption 5 (Bounded heterogeneity). The dissimilarity of f i (x) and f (x) is bounded as follows:\n1 N N \u22121 i=0 \u2207f i (x) \u2212 \u2207f (x) 2 \u2264 \u03c3 2 g for all x.\nAssumption 4 bounds the variance of stochastic gradient, which is common in stochastic optimization analysis [Bubeck, 2014]. Assumption 5 bounds the gradient difference between global and local loss function, which is a widely-used approach to characterize client heterogeneity in federated optimization literature [Li et al., 2018, Reddi et al., 2020.\n\nBased on the above assumptions, we derive the following convergence result for FedCM algorithm.\n\nTheorem 5.1. Let assumption 2 to 5 hold. Assume that in each round, a subset S with size |S| = S is sampled uniformly without replacement from N clients. Define z t = x t + 1\u2212\u03b1 \u03b1 (x t \u2212 x t\u22121 ). For any \u03b1 \u2208 (0, 1] and a proper choice of \u03b7 g , \u03b7 l , the iterates of the algorithm 2 satisfy:\n\n1. Strongly convex: If assumption 1 holds with \u00b5 > 0, then for w t =\n(1\u2212 \u00b5\u03b7g 2 ) \u2212t\u22121 t\u2208[T ] (1\u2212 \u00b5\u03b7g 2 ) \u2212t\u22121 , we have Ef \uf8eb \uf8ed t\u2208[T ] w t z t \uf8f6 \uf8f8 \u2212 f (x * ) = O C 1 + C 2 \u00b5KST + L (C 1 + KSC 2 ) \u03b1 2 \u00b5 2 KST 2 + \u00b5De \u2212 T 2 2. General convex: If assumption 1 holds with \u00b5 = 0, we have Ef \uf8eb \uf8ed 1 T t\u2208[T ] z t \uf8f6 \uf8f8 \u2212 f (x * ) = O D(C 1 + C 2 ) KST + 3 D 2 (C 1 + KSC 2 ) \u03b1 2 KST 2 3. Non-convex: We have 1 T t\u2208[T ] E \u2207f (z t ) 2 = O LF (C 1 + C 2 ) KST + 3 L 2 F 2 (C 1 + KSC 2 ) \u03b1 2 KST 2 Where C 1 = \u03c3 2 l + K(1 \u2212 S N )\u03c3 2 g + KSG 2 , C 2 = \u03b1 \u03c3 2 l K + \u03c3 2 g + G 2 , D = x 0 \u2212 x * 2 for x * = argmin x f (x) and F = f (x 0 ) \u2212 f * for f * = min x f (x).\nThe proof is deferred to appendix B. The convergence rates of FedCM justify our claim that FedCM is robust to the distributed nature of federated learning. Our result is free of the term N S , which exists in the convergence rate of SCAFFOLD [Karimireddy et al., 2020b] and FedDyn [Acar et al., 2021] as they require clients to maintain local states. Consequently, if the participation rate S N tends to 0, the average loss of SCAFFOLD and FedDyn will tend to infinity, even if the number of participating clients S is fixed. As is shown by our convergence bound, FedCM is free of this issue, which is compatible with our empirical findings that FedCM is stable under different levels of distribution and participation (see section 6.2).\n\nThe above convergence results also explain why FedCM can handle client heterogeneity by clarifying the role the hyperparameter \u03b1 play in FedCM. The term C 2 in the bound increases with \u03b1. This aligns with our previous explanation that a smaller \u03b1 implies more global gradient information is used in client updates, which alleviates the influence of client heterogeneity. However, the 1 \u03b1 in the bound means that an extremely small \u03b1 will slow down the algorithm convergence, which is typical for momentum-like algorithms. Fortunately, the dominating term in the above bounds is 1 \u03b1 -free, and therefore a small \u03b1 will not ruin the asymptotic results of the theorem.\n\nIn the above theorem, we obtain results with respect to auxiliary z t instead of the x t . Note that this only slightly modifies the final output of the algorithm without changing any intermediate procedures. Typically, z t plays an important role in the analysis of momentum-like algorithms [Tong et al., 2020]. What's more, the results above involve an weighted average of all intermediate results instead of only the final one. This is inevitable if we use a constant learning rate [Li et al., 2019b]. Our proof can be easily modified to avoid this issue by using a decaying learning rate.\n\n\nExperiments\n\nIn this section, we present empirical evaluations of FedCM and competing federated learning methods, to highlight the benefits of introducing client level momentum to federated optimization.\n\n\nSettings\n\nDatasets, Tasks and Models. We evaluate our method on CIFAR10 and CIFAR100 [Krizhevsky et al., 2009] datasets, with usual train/test splits. In order to provide a thorough evaluation of different methods under various federated scenarios, the experiments are performed on two different federated learning settings: in setting I, we have 100 clients with 10% participation rate; in setting II, we have 500 clients, with 2% participation rate. In each round, each client is activated independently of each other, with probability 0.1 and 0.02 respectively. In both settings, we create an iid and non-iid version the training data split. For the iid version, we randomly assign training data to each clients; for the non-iid version, We simulate the data heterogeneity by sampling the label ratios from a Dirichlet distribution with parameter 0.6 [Hsu et al., 2019]. We keep the training data on each client balanced, i.e., each client holds 500 training data points in setting I and 100 in setting II. We adopt a standard Resnet-18 [He et al., 2016] as our classifier, with batch normalization replaced by group normalization [Wu andHe, 2018, Hsieh et al., 2020].\n\nMethods. We compare FedCM with the four baseline methods, FedAvg [McMahan et al., 2017], SCAFFOLD [Karimireddy et al., 2020b], FedDyn [Acar et al., 2021] and FedAdam [Reddi et al., 2020]. Both SCAFFOLD and FedDyn tackle the problem of client heterogeneity, by using a control variate as in SVRG [Johnson and Zhang, 2013] or aligning local loss functions with global loss function via maintaining a dual variable. FedAdam extends Adam optimizer [Kingma and Ba, 2014] to server updates in FedAvg but keeps local updates unchanged, which is closely related to but different from our method. In order to provide a fair evaluation of different methods under realistic federated learning settings, we report the test accuracy after 4000 communication rounds in all experiments instead of the training loss. We provide the implementation details and hyperparameter selections in appendix C.\n\n\nResults on CIFAR10 and CIFAR100\n\nThe test accuracy of FedCM and competing baselines on CIFAR10 and CIFAR100 under different settings are given in Table 1 and 2. The corresponding convergence plots are provided in appendix C. We observe that FedCM consistently outperforms other strong baselines in different tasks. In particular, despite that FedCM does not use adaptive learning rate, it still achieves higher accuracy than FedAdam, which demonstrates the effectiveness of client momentum over server momentum.\n\nWe find that FedCM is robust to different levels of participation. As shown in the table, the test accuracy of FedAvg and SCAFFOLD drop by approximately 8% and 6% respectively on CIFAR10 when we decrease the participation rate. By comparison, the test accuracy drop is much less severe for FedCM. For instance, the accuracy drop of FedCM on CIFAR10 is 1.07% for IID split and 1.37% for Dirichlet-0.6 split. We attribute the drop of SCAFFOLD to the local states that SCAFFOLD maintains at client side. This corresponds to our theoretical findings in section 5. In contrast, FedCM avoids this issue and is robust to different participation levels. Note that only the number of active clients S, instead of total number of clients N , appears in the dominating term in Theorem 5.1 and the convergence bound of competing algorithms [Karimireddy et al., 2020b, Reddi et al., 2020, Acar et al., 2021, so in our experiment the expected number of active clients is fixed to 10, in order for a fair analysis of the effect of participation rate.\n\nThe experiment results also support our claim that FedCM is more robust to client heterogeneity. Not only does FedCM achieves highest test accuracy under different heterogeneity levels, we can also observe that the accuracy gap of FedCM between IID and Dirichlet-0.6 split is smaller compared to methods without client level modification. Taking CIFAR10 dataset with 100 clients and 10% participation as an example, the accuracy drop of FedCM is 0.31%, smaller than 0.77% of FedAdam and 0.66% of FedAvg.\n\nTo sum up, the experiments on CIFAR10 and CIFAR100 under different settings align with our theoretical findings that FedCM is able to tackle the challenges of partial participation and client heterogeneity in federated learning tasks, by appropriately incorporating global information into client gradient updates.  \n\n\nSensitivity Analysis of \u03b1 in FedCM\n\nAs shown in our theoretical analysis, \u03b1 reduces the effect of client heterogeneity by balancing the global information and local information in client gradient updates. To validate this, we also perform experiments to analyze the effect of \u03b1, the only algorithm-dependent hyperparameter of FedCM, on the convergence and performance of FedCM algorithms.\n\nWe test FedCM with \u03b1 taken values in {0.01, 0.03, 0.05, 0.1, 0.3, 1.0}, on CIFAR10 datasets with Dirichlet-0.6 split on 100 clients, 10% participating setting. The test accuracies are shown in Table  3 and the convergence plots are provided in Figure 1. We find that FedCM successfully converges to stationary points under all these \u03b1 choices, as guaranteed by our convergence analysis. However, the stationary points of different \u03b1 show different generalization ability, which results in varying test accuracies in Table 3. We note that setting \u03b1 too small or too large will harm the convergence and generalization of FedCM. As shown in Figure 1, FedCM will suffer from oscillation and slow convergence when \u03b1 = 0.01. Despite this, FedCM with \u03b1 < 1 consistently outperforms FedAvg corresponding to \u03b1 = 1.0, which supports the effectiveness of client level momentum. Empirically, we find that performance is best when setting \u03b1 to about 0.1, which aligns with traditional momentum algorithms. \n\n\nConclusion\n\nIn this paper, we propose FedCM, a novel, efficient and robust federated learning algorithm which modifies local gradient update with a momentum term that aggregates global gradient information. We give the convergence rates of FedCM that match the best known results of distributed gradient algorithms. We also conduct extensive experiments to demonstrate that FedCM outperforms existing federated learning algorithms under various scenarios. Our theoretical and empirical evaluations highlight the robustness of FedCM to client heterogeneity and low participation in federated learning tasks. This work explores an approach to aggregate the past gradient to modify client gradient descent directions. Future directions include utilizing higher order information of past gradients to extend adaptive optimization algorithms into client and server updates of Federated Averaging.  A Additional related works MimeLite. MimeLite [Karimireddy et al., 2020a] is an algorithmic framework proposed in a a recent work, which adapts centralized optimization algorithm to federated learning setting. In MimeLite, server statistics such as momentum are applied to client gradient steps in order to alleviate client heterogeneity. MimeLite can be further generalized into Mime, by introducing control variate to handle client heterogeneity as in SCAFFOLD algorithm. FedCM and MimeLite share some similarities as both methods aim to tackle client heterogeneity by using a global momentum term to modify local gradient steps.\n\nThe major difference between FedCM and MimeLite is the way in which momentum term is computed and maintained. Slightly abusing the notations in algorithm 2, the momentum term in MimeLite is updated using additional full batch gradient \u2207f i (x t i,0 ), while the momentum in FedCM is updated using an average of the minibatch gradient {\u2207f i (x t i,k , \u03be t i,k )} k\u2208 [K] . The way FedCM computes momentum has two major strengths. Firstly, MimeLite requires additional client computation cost and client-to-server communication burden to calculate and transmit the full batch gradient. FedCM is free of this issue by incorporating the update of the momentum term into the aggregation of client models, which is more efficient and light-weight. Secondly, the momentum in MimeLite is computed on the previously synchronized model x t i,0 , which will get stale if the number of local gradient steps is large. By contrast, FedCM utilizes all the model parameters in the optimization trajectory {x t i,k } k\u2208 [K] to compute the momentum, which are closer to the current model parameter x t+1 and thus more informative.\n\nSLOWMO. SLOWMO [Wang et al., 2019] is a momentum-type algorithm to solve distributed optimization problem. The major characteristic of SLOWMO is that an additional momentum step is applied to the averaged model parameters in each communication round, to improve the convergence of distributed training. SLOWMO uses the difference between consecutive server model parameters to update momentum, which shares a similar strategy with FedDyn. However, momentum in SLOWMO is not applied to modify client gradient updates, which differs from FedCM. Lin et al. [2021]. For each client, QG-DSGDm maintains a quasi-global momentum term by averaging the model updates of neighbouring clients. The authors show that incorporating quasi-global momentum term into local gradient steps can reduce data heterogeneity and stabilize convergence. The biggest difference between QG-DSGDm and FedCM is that QG-DSGDm focuses on decentralized setting and FedCM handles centralized setting. As a consequence, each client in QG-DSGDm holds its own momentum which is synchronized occasionally with its neighbouring clients, while in FedCM the server holds a unique momentum term which is applied to all participating clients.\n\n\nQG-DSGDm. QG-DSGDm is a momentum-based decentralized optimization method proposed in\n\n\nB Proofs\n\n\nB.1 Preliminary lemmas\nLemma B.1. For v 1 , v 2 , \u00b7 \u00b7 \u00b7 , v n \u2208 R d , we have n i=1 v i 2 \u2264 n n i=1 v i 2 Lemma B.2. For v 1 , v 2 \u2208 R d , we have v 1 + v 2 2 \u2264 (1 + a) v 1 2 + 1 + 1 a v 2 2 Lemma B.3. Let X 1 , X 2 \u00b7 \u00b7 \u00b7 X n be random variables in R d . Suppose that {X i \u2212 \u03be i } form a mar- tingale difference sequence, i.e. E[X i \u2212 \u03be i |X 1 \u00b7 \u00b7 \u00b7 X i\u22121 ] = 0. If E X i \u2212 \u03be i 2 \u2264 \u03c3 2 , then we have E n i=1 X i 2 \u2264 2 n i=1 \u03be i 2 + 2n\u03c3 2\nLemma B.4. For \u00b5-strongly convex and L-smooth function f , and any x, y, z in its domain, the following is true:\n\u2207f (x), y \u2212 z \u2264 f (y) \u2212 f (z) \u2212 \u00b5 4 y \u2212 z 2 + L z \u2212 x 2\nWe refer the readers to Karimireddy et al. [2020b] for a detailed proof of the above lemmas. The following two lemmas are also adapted from Karimireddy et al. [2020b], which we will apply in the proof to unroll the recursion.\nLemma B.5. Let a t = 1 \u03b7 (1 \u2212 \u00b5\u03b7) b t \u2212 b t+1 + c 1 \u03b7 + c 2 \u03b7 2\nfor a non-negative sequence {b n } n\u22650 , constants c 1 , c 2 \u2265 0, \u00b5 > 0 and parameters \u03b7 > 0. Then for any T \u2208 N + , there exists a constant step-size \u03b7 < 1 \u00b5 and weights w t =\n(1\u2212\u00b5\u03b7) \u2212t\u22121 t\u2208[T ] (1\u2212\u00b5\u03b7) \u2212t\u22121 such that t\u2208[T ] w t a t = O(\u00b5b 0 e \u2212 T 2 + c 1 \u00b5T + c 2 \u00b5 2 T 2 )\nProof. We substitute the value of a t and merge the telescoping sum as\nt\u2208[T ] w t a t = t\u2208[T ] 1 \u03b7 t\u2208[T ] (1 \u2212 \u00b5\u03b7) \u2212t\u22121 (1 \u2212 \u00b5\u03b7) \u2212t b t \u2212 (1 \u2212 \u00b5\u03b7) \u2212t\u22121 b t+1 + c 1 \u03b7 + c 2 \u03b7 2 \u2264 1 \u03b7 t\u2208[T ] (1 \u2212 \u00b5\u03b7) \u2212t\u22121 b 0 + c 1 \u03b7 + c 2 \u03b7 2 = \u00b5(1 \u2212 \u00b5\u03b7) T 1 \u2212 (1 \u2212 \u00b5\u03b7) T b 0 + c 1 \u03b7 + c 2 \u03b7 2 \u2264 2\u00b5b 0 e \u2212\u00b5\u03b7T + c 1 \u03b7 + c 2 \u03b7 2\nThe last step follows from (1 \u2212 \u00b5\u03b7) T \u2264 e \u2212\u00b5\u03b7T and e \u2212\u00b5\u03b7T \u2264 e \u22121 \u2264 1 2 . Take \u03b7 = min 1 \u00b5T log\n\u00b5 2 b 2 0 T c1 , 1 2\u00b5 , we get t\u2208[T ] w t a t = O \u00b5b 0 e \u2212\u00b5 1 2\u00b5 T + \u00b5b 0 e \u2212\u00b5 1 \u00b5T log \u00b5 2 b 2 0 T c 1 T + c 1 \u00b5T + c 2 \u00b5 2 T 2 = O \u00b5b 0 e \u2212 T 2 + c 1 \u00b5T + c 2 \u00b5 2 T 2 Lemma B.6. Let a t = 1 \u03b7 (b t \u2212 b t+1 ) + c 1 \u03b7 + c 2 \u03b7 2\nfor a non-negative sequence {b n } n\u22650 , constants c 1 , c 2 \u2265 0 and parameters \u03b7 > 0. Then for any T \u2208 N + , there exists a constant step-size \u03b7 such that\n1 T t\u2208[T ] a t = O( b 0 c 1 T + 3 b 2 0 c 2 T 2 )\nProof. Unrolling the sum, we get\n1 T t\u2208[T ] a t \u2264 1 \u03b7T b 0 + c 1 \u03b7 + c 2 \u03b7 2\nTake \u03b7 = min b0 c1T , 3 b0 c2T and the result follows.\n\n\nB.2 Proof of the main theorem\n\nFirst, we define the auxiliary sequence {z t }:\nz t = x t + 1 \u2212 \u03b1 \u03b1 (x t \u2212 x t\u22121 )\nLemma B.7. The following update rule holds for {z t } z t+1 = z t \u2212 \u03b7 g\u2206t .\n\nProof.\nz t+1 = x t+1 + 1 \u2212 \u03b1 \u03b1 (x t+1 \u2212 x t ) = x t \u2212 \u03b7 g \u2206 t+1 + 1 \u2212 \u03b1 \u03b1 (\u2212\u03b7 g \u2206 t+1 ) = z t \u2212 1 \u2212 \u03b1 \u03b1 (\u2212\u03b7 g \u2206 t ) \u2212 \u03b7 g \u2206 t+1 + 1 \u2212 \u03b1 \u03b1 (\u2212\u03b7 g \u2206 t+1 ) = z t \u2212 \u03b7 g 1 \u03b1 \u2206 t+1 \u2212 1 \u2212 \u03b1 \u03b1 \u2206 t = z t \u2212 \u03b7 g 1 \u03b1 (\u03b1\u2206 t + (1 \u2212 \u03b1)\u2206 t ) \u2212 1 \u2212 \u03b1 \u03b1 \u2206 t = z t \u2212 \u03b7 g\u2206t\nIn the following proof, we suppose that every client C k receives the x t and \u2206 t from the server, then performs local gradient descent to generate {x t i,k } 0\u2264i\u2264K\u22121 . However, only the selected clients in S t sends their local update results \u2206 t i to the server. Note that although this modification violates the setting of federated learning, it keeps the output of the algorithm unchanged.\nDefine \u03b5 t = 1 KN i\u2208[N ],k\u2208[k] E x t \u2212 x t i,k 2\nwhich corresponds to the client drift in the t-th epoch. \u03b5 t can be upper bounded by the following lemma:\nLemma B.8. Suppose \u03b7 l \u2264 1 4LK , we have \u03b5 t \u2264 3K\u03b7 2 l 6\u03b1K\u03c3 2 g + 6\u03b1KG 2 + 2(1 \u2212 \u03b1)KE \u2206 t 2 + \u03b1 2 \u03c3 2 l Proof. Define t k = 1 N i\u2208[N ] E x t i,k \u2212 x t 2\nas the client drift in the k-th local epoch of the t-th global iteration. Note that t\n0 = 0. For k \u2265 1 we have t k = 1 N i\u2208[N ] E x t i,k\u22121 \u2212 \u03b7 l (\u03b1g t i,k\u22121 + (1 \u2212 \u03b1)\u2206 t ) \u2212 x t 2 \u2264 1 N i\u2208[N ] E x t i,k\u22121 \u2212 \u03b7 l (\u03b1\u2207f i (x t i,k\u22121 ) + (1 \u2212 \u03b1)\u2206 t ) \u2212 x t 2 + \u03b1 2 \u03b7 2 l \u03c3 2 l \u2264 1 N i\u2208[N ] E (1 + a) x t i,k\u22121 \u2212 x t + 1 + 1 a \u03b7 l (\u03b1\u2207f i (x t i,k\u22121 ) + (1 \u2212 \u03b1)\u2206 t ) 2 + \u03b1 2 \u03b7 2 l \u03c3 2 l\nwhere we seperate the mean and variance and use the inequality B.2. a is a constant to be chosen later. We further bound the second term as\n1 N i\u2208[N ] E \u03b7 l (\u03b1\u2207f i (x t i,k\u22121 ) + (1 \u2212 \u03b1)\u2206 t ) 2 \u2264 1 N \u03b7 2 l i\u2208[N ] E \u03b1[\u2207f i (x t i,k\u22121 ) \u2212 \u2207f i (x t ) + \u2207f i (x t ) \u2212 \u2207f (x t ) + \u2207f (x t )] + (1 \u2212 \u03b1)\u2206 t 2 \u2264 1 N \u03b7 2 l i\u2208[N ] E(3\u03b1 \u2207f i (x t i,k\u22121 ) \u2212 \u2207f i (x t ) 2 + 3\u03b1 \u2207f i (x t ) \u2212 \u2207f (x t ) 2 + 3\u03b1 \u2207f (x t ) 2 + (1 \u2212 \u03b1) \u2206 t 2 ) \u2264 \u03b7 2 l (3\u03b1L 2 t k\u22121 + 3\u03b1\u03c3 2 g + 3\u03b1G 2 + (1 \u2212 \u03b1)E \u2206 t 2 )\nHence we have\nt k \u2264 (1 + a) + 1 + 1 a 3\u03b1L 2 \u03b7 2 l t k\u22121 + 1 + 1 a \u03b7 2 l 3\u03b1\u03c3 2 g + 3\u03b1G 2 + (1 \u2212 \u03b1)E \u2206 t 2 + \u03b1 2 \u03b7 2 l \u03c3 2 l\nFor K = 1, take a = 1 and the lemma holds due to the above inequality. Suppose that K \u2265 2 thereafter and take a = 1 2K\u22121 . It follows from \u03b7 l \u2264 1 4LK that\n(1 + a) + 1 + 1 a 3\u03b1L 2 \u03b7 2 l \u2264 1 + 1 K \u2212 1 Therefore, t k \u2264 1 + 1 K \u2212 1 t k\u22121 + \u03b7 2 l 6\u03b1K\u03c3 2 g + 6\u03b1KG 2 + 2(1 \u2212 \u03b1)KE \u2206 t 2 + \u03b1 2 \u03c3 2 l\nUnrolling the recursion, noting that t 0 = 0 and (k \u2212 1)\n1 K \u2212 1 + 1 k \u2212 1 \u03b7 2 l 6\u03b1K\u03c3 2 g + 6\u03b1KG 2 + 2(1 \u2212 \u03b1)KE \u2206 t 2 + \u03b1 2 \u03c3 2 l \u2264 3K\u03b7 2 l 6\u03b1K\u03c3 2 g + 6\u03b1KG 2 + 2(1 \u2212 \u03b1)KE \u2206 t 2 + \u03b1 2 \u03c3 2 l Finally, we have \u03b5 t = 1 K k\u2208[K] t k+1 \u2264 3K\u03b7 2 l 6\u03b1K\u03c3 2 g + 6\u03b1KG 2 + 2(1 \u2212 \u03b1)KE \u2206 t 2 + \u03b1 2 \u03c3 2 l\nwhich finishes the proof of the lemma.\n\nNext we upper bound the norm of\u2206 t .\n\nLemma B.9. The expectation of the norm of\u2206 t in any global epoch t \u2208 [T ] can be bounded as\nE \u2206 t 2 \u2264 10L 2 \u03b5 t + 10G 2 + 12 S (1 \u2212 S N )\u03c3 2 g + 2\u03c3 2 l KS\nProof. Define I t i as the random variable which indicates client i is selected in the t-th global epoch. For k \u2208 [K], we have the following bound:\nE 1 S i\u2208S \u2207f i (x t i,k ) 2 = E 1 S i\u2208[N ] \u2207f i (x t i,k )I t i 2 = E 1 S i\u2208[N ] \u2207f i (x t i,k )I t i , 1 S j\u2208[N ] \u2207f j (x t j,k )I t j = E 1 S 2 \uf8ee \uf8f0 i,j\u2208[N ],i =j \u2207f i (x t i,k ), \u2207f j (x t j,k ) E[I t i I t j ] + i\u2208[N ] \u2207f i (x t i,k ), \u2207f i (x t i,k ) E[I t i ] \uf8f9 \uf8fb = E 1 S 2 \uf8ee \uf8f0 i,j\u2208[N ],i =j S(S \u2212 1) N (N \u2212 1) \u2207f i (x t i,k ), \u2207f j (x t j,k ) + i\u2208[N ] S N \u2207f i (x t i,k ), \u2207f i (x t i,k ) \uf8f9 \uf8fb = E 1 S 2 \uf8ee \uf8f0 i,j\u2208[N ] S(S \u2212 1) N (N \u2212 1) \u2207f i (x t i,k ), \u2207f j (x t j,k ) + i\u2208[N ] S(N \u2212 S) N (N \u2212 1) \u2207f i (x t i,k ), \u2207f i (x t i,k ) \uf8f9 \uf8fb \u2264 E 1 N 2 i\u2208[N ] \u2207f i (x t i,k ) 2 + E N \u2212 S SN (N \u2212 1) i\u2208[N ] \u2207f i (x t i,k ) 2 \u2264 E 1 N i\u2208[N ] (\u2207f i (x t i,k ) \u2212 \u2207f i (x t )) + \u2207f (x t ) 2 + E N \u2212 S SN (N \u2212 1) i\u2208[N ] (\u2207f i (x t i,k ) \u2212 \u2207f i (x t )) + (\u2207f i (x t ) \u2212 \u2207f (x t )) + \u2207f (x t ) 2 \u2264 2E 1 N i\u2208[N ] (\u2207f i (x t i,k ) \u2212 \u2207f i (x t )) 2 + 2E \u2207f (x t ) 2 + 3E N \u2212 S SN (N \u2212 1) i\u2208[N ] \u2207f i (x t i,k ) \u2212 \u2207f i (x t ) 2 + 3E N \u2212 S SN (N \u2212 1) i\u2208[N ] \u2207f i (x t ) \u2212 \u2207f (x t ) 2 + 3E N \u2212 S S(N \u2212 1) \u2207f (x t ) 2 \u2264 5L 2 1 N i\u2208[N ] E x t i,k \u2212 x t 2 + 5G 2 + 6 S (1 \u2212 S N )\u03c3 2 g\nIn the above inequality, we use the properties of sampling without replacement, lemma B.1, the smoothness of f i and the definition of G and \u03c3 g sequentially.\n\nAccording to lemma B.3, we have\nE \u2206 t 2 \u2264 2E 1 KS i\u2208S,k\u2208[K] \u2207f i (x t i,k ) 2 + 2\u03c3 2 l KS \u2264 2E 1 K k\u2208[K] 1 S i\u2208S \u2207f i (x t i,k ) 2 + 2\u03c3 2 l KS \u2264 10L 2 \u03b5 t + 10G 2 + 12 S (1 \u2212 S N )\u03c3 2 g + 2\u03c3 2 l KS\n, and the proof of the lemma is complete.\n\nThe next lemma is a simple corollary of lemma 4.1\n\nLemma B.10. The norm of {\u2206 t } and {\u2206 t } satisfies the following inequality\n\u2206 t+1 2 \u2264 \u03b1 \u2206 t+1 2 + (1 \u2212 \u03b1) \u2206 t 2\nProof. Note that \u2206 t+1 = \u03b1\u2206 t + (1 \u2212 \u03b1)\u2206 t and apply Jenson's inequality.\n\nWe next bound the norm of\u2206 t and \u2206 t .\n\nLemma B.11. Let C 1 = 10KSG 2 + 12K(1 \u2212 S N )\u03c3 2 g + 2\u03c3 2 l and C 2 = 6\u03b1\u03c3 2 g + 6\u03b1G 2 + \u03b1\u03c3 2 l K as in the statement of the theorem. Suppose that \u03b7 l \u2264 1 8KL , then we have the following bound on \u2206 t 2 and \u2206 t 2 :\nmax{E \u2206 t 2 , E \u2206 t 2 } \u2264 16C 1 KS + 480K 2 L 2 \u03b7 2 l C 2\nProof. We prove the lemma by induction. Denote V = 16C1 KS + 480K 2 L 2 \u03b7 2 l C 2 . Note that \u2206 0 2 = 0. Now we assume that E \u2206 t 2 \u2264 V . Then we have\nE \u2206 t 2 \u2264 10L 2 \u03b5 t + C 1 KS \u2264 10L 2 \u00b7 3K\u03b7 2 l [2(1 \u2212 \u03b1)KE \u2206 t 2 + KC 2 ] + C 1 KS \u2264 60K 2 L 2 \u03b7 2 l V + 30K 2 L 2 \u03b7 2 l C 2 + C 1 KS \u2264 V\nThe last step is due to the assumption that \u03b7 l \u2264 1 8LK . According to lemma B.10, we can bound E \u2206 t+1 2 as\nE \u2206 t+1 2 \u2264 \u03b1E \u2206 t+1 2 + (1 \u2212 \u03b1)E \u2206 t 2 \u2264 \u03b1V + (1 \u2212 \u03b1)V \u2264 V\nThis finishes the induction.\n\nFinally, we return to the proof of the main theorem.\n\nProof. We first prove the convex case.\n\nBy lemma B.7, we expand z t+1 \u2212 x * 2 as\nE z t+1 \u2212 x * 2 = E z t \u2212 x * 2 + 2\u03b7 g E x * \u2212 z t ,\u2206 t + \u03b7 2 g E \u2206 t 2\nUsing perturbed strong convexity inequality B.4, We bound the second term as\nE x * \u2212 z t ,\u2206 t = E x * \u2212 z t , 1 KN i\u2208[N ],k\u2208[K] \u2207f i (x t i,k ) \u2264 1 KN i\u2208[N ],k\u2208[K] E f i (x * ) \u2212 f i (z t ) \u2212 \u00b5 4 x * \u2212 z t 2 + L x t i,k \u2212 z t 2 \u2264 f (x * ) \u2212 Ef (z t ) \u2212 \u00b5 4 E x * \u2212 z t 2 + L KN i\u2208[N ],k\u2208[K] [2E x t i,k \u2212 x t 2 + 2E z t \u2212 x t 2 ] = f (x * ) \u2212 Ef (z t ) \u2212 \u00b5 4 E x * \u2212 z t 2 + 2L\u03b5 t + 2(1 \u2212 \u03b1) 2 \u03b1 2 L\u03b7 2 g E \u2206 t 2 Therefore, we have E z t+1 \u2212 x * 2 \u2264 E z t \u2212 x * 2 + 2\u03b7 g f (x * ) \u2212 Ef (z t ) \u2212 \u00b5 4 E x * \u2212 z t 2 + 2L\u03b5 t + 2(1 \u2212 \u03b1) 2 \u03b1 2 L\u03b7 2 g E \u2206 t 2 + \u03b7 2 g E \u2206 t 2 \u2264 2\u03b7 g f (x * ) \u2212 Ef (z t ) + 1 \u2212 \u00b5\u03b7 g 2 E z t \u2212 x * 2 + 4L\u03b7 g \u03b5 t + 4(1 \u2212 \u03b1) 2 \u03b1 2 L\u03b7 3 g E \u2206 t 2 + \u03b7 2 g E \u2206 t 2 \u2264 2\u03b7 g f (x * ) \u2212 Ef (z t ) + 1 \u2212 \u00b5\u03b7 g 2 E z t \u2212 x * 2 + 4L\u03b7 g \u03b5 t + 4(1 \u2212 \u03b1) 2 \u03b1 2 L\u03b7 3 g V + \u03b7 2 g V\nRearranging the terms and take \u03b7 l = min min(\u03b7g,1)\n8LK , 1 8LSK 2 , we get Ef (z t ) \u2212 f (x * ) = O \uf8eb \uf8ed 1 \u03b7 g 1 \u2212 \u00b5\u03b7 g 2 E z t \u2212 x * 2 \u2212 E z t+1 \u2212 x * 2 + K 2 \u03b7 2 l L(C 2 + V ) + L \u03b1 2 \u03b7 2 g V + \u03b7 g V \uf8f6 \uf8f8 = O \uf8eb \uf8ed 1 \u03b7 g 1 \u2212 \u00b5\u03b7 g 2 E z t \u2212 x * 2 \u2212 E z t+1 \u2212 x * 2 + \u03b7 g V + \u03b7 2 g L(C 2 + V ) + L \u03b1 2 \u03b7 2 g V \uf8f6 \uf8f8 If \u00b5 > 0, let the averaging weight w t = (1\u2212 \u00b5\u03b7g 2 ) \u2212t\u22121 t\u2208[T ] (1\u2212 \u00b5\u03b7g 2 ) \u2212t\u22121 .\nApplying lemma B.5, we know that there exists an appropriate \u03b7 g such that\nt\u2208[T ] w t Ef (z t ) \u2212 f (x * ) = O \u00b5De \u2212 T 2 + V \u00b5T + L(C 2 + V ) \u03b1 2 \u00b5 2 T 2 = O \u00b5De \u2212 T 2 + C 1 + C 2 \u00b5KST + L (C 1 + KSC 2 ) \u03b1 2 \u00b5 2 KST 2\nIf \u00b5 = 0, apply lemma B.6, we know that\n1 T t\u2208[T ] Ef (z t ) \u2212 f (x * ) = O D(C 1 + C 2 ) KST + 3 D 2 (C 1 + KSC 2 ) \u03b1 2 KST 2\nApplying Jenson's Inequality, we obtain the desired results.\n\nFor the general non-convex case, we proceed as follows. Using the smoothness of f , we expand f (z t+1 ) as\nEf (z t+1 ) = Ef (z t ) + E \u2207f (z t ), z t+1 \u2212 z t + L 2 E z t+1 \u2212 z t 2 = Ef (z t ) \u2212 \u03b7 g E \u2207f (z t ), 1 KN i\u2208[N ],k\u2208[K] \u2207f i (x t i,k ) + L 2 E z t+1 \u2212 z t 2 = Ef (z t ) \u2212 \u03b7 g E \u2207f (z t ) 2 + L 2 \u03b7 2 g E \u2206 t 2 \u2212 \u03b7 g E \u2207f (z t ), 1 KN i\u2208[N ],k\u2208[K] (\u2207f i (x t i,k ) \u2212 \u2207f i (z t )) \u2264 Ef (z t ) \u2212 \u03b7 g E \u2207f (z t ) 2 + L 2 \u03b7 2 g E \u2206 t 2 + 1 2 \u03b7 g E \u2207f (z t ) 2 + 1 2 \u03b7 g 1 KN i\u2208[N ],k\u2208[K] E \u2207f i (x t i,k ) \u2212 \u2207f i (z t ) 2 \u2264 Ef (z t ) \u2212 \u03b7 g E \u2207f (z t ) 2 + L 2 \u03b7 2 g E \u2206 t 2 + 1 2 \u03b7 g E \u2207f (z t ) 2 + \u03b7 g 1 KN i\u2208[N ],k\u2208[K] (E \u2207f i (x t i,k ) \u2212 \u2207f i (x t ) 2 + E \u2207f i (x t ) \u2212 \u2207f i (z t ) 2 ) \u2264 Ef (z t ) \u2212 \u03b7 g E \u2207f (z t ) 2 + L 2 \u03b7 2 g E \u2206 t 2 + 1 2 \u03b7 g E \u2207f (z t ) 2 + \u03b7 g L 2 \u03b5 t + \u03b7 g L 2 1 \u2212 \u03b1 \u03b1 2 \u03b7 2 g E \u2206 t 2 \u2264 Ef (z t ) \u2212 1 2 \u03b7 g E \u2207f (z t ) 2 + L 2 \u03b7 2 g E \u2206 t 2 + \u03b7 g L 2 \u03b5 t + \u03b7 3 g L 2 1 \u2212 \u03b1 \u03b1 2 E \u2206 t 2\nRearranging the terms and take \u03b7 l = min min(\u03b7g,1)\n8LK , 1 8LSK 2 , we get E \u2207f (z t ) 2 \u2264 2 \u03b7 g (Ef (z t ) \u2212 Ef (z t+1 )) + L\u03b7 g \u2206 t 2 + 2L 2 \u03b5 t + 2\u03b7 2 g L 2 1 \u2212 \u03b1 \u03b1 2 E \u2206 t 2 = O 1 \u03b7 g (Ef (z t ) \u2212 Ef (z t+1 )) + \u03b7 g LV + \u03b7 2 g L 2 (C 2 + V ) + \u03b7 2 g L 2 1 \u2212 \u03b1 \u03b1 2 V\nApplying lemma B.6, we know that there exists an appropriate \u03b7 g such that\n1 T t\u2208[T ] E \u2207f (z t ) 2 = O \uf8eb \uf8ec \uf8ed LV F T + 3 L 2 (C 2 + 1 \u03b1 2 V )F 2 T 2 \uf8f6 \uf8f7 \uf8f8 = O LF (C 1 + C 2 ) KST + 3 L 2 F 2 (C 1 + KSC 2 ) \u03b1 2 KST 2 C Experiment details C.1 Dataset generation\nThe experiments are conducted on CIFAR10 and CIFAR100 datasets. We follow the usual train/test splits, i.e. 50000 training images are assigned to clients for training and 10000 test images are reserved to evaluate test accuracy. Normalization is applied as preprocessing for both training and test images.\n\nThe training data split is balanced in all settings, i.e., each client holds the same amount of data. For IID splits, the training data is randomly assigned to each client. For non-IID splits, we use Dirichlet distribution to simulate heterogeneous client distribution [Hsieh et al., 2020, Yurochkin et al., 2019, Acar et al., 2021. For each client, we first draw a vector q \u223c Dir(\u03b1p) from a Dirichlet distribution as the class distribution, where p is an all one vector with length equal to the number of classes and \u03b1 > 0 is a concentration parameter. Then the training data of each class is sampled from the training set according to p. \u03b1 has a negative correlation with the client heterogeneity, i.e. larger \u03b1 implies more similar data distribution across clients.\n\n\nC.2 Hyperparameter selection\n\nWe report our hyperparameter selection strategy as follows. The number of local training epochs over each client's local training set is selected from {2, 5}. The minibatch size for local SGD is selected from {20, 50}. Local learning rate \u03b7 l is selected from {0.1, 1.0}. We apply exponential decay on \u03b7 l as in Acar et al. [2021], and the decaying parameter is selected from {0.998, 0.999, 0.9995, 1.0}. In our implementation, the global learning rate \u03b7 g in line 14 is multiplies by \u03b7 l K, i.e., \u03b7 g = 1 corresponds to averaging all client models in the global update. In light of this, we search \u03b7 g from {0.1, 1.0}. We apply weight decay of 0.001 to prevent overfitting.\n\nAs for algorithm-dependent hyperparameters, \u03b1 in FedCM and FedAdam is selected from {0.05, 0.1}, \u03b1 in FedDyn is selected from {0.001, 0.01, 0.1}, \u03c4 in FedAdam is set to 0.01. FedDyn requires exact minimization in local updates, but we find that 5-step local SGD with appropriate learning rates suffices to achieve nearly 100% accuracy on clients local training data.\n\nFor experiments on CIFAR10 dataset, we choose 5 as the number of local training epochs, 50 as batchsize and 0.1 as local learning rate \u03b7 l . The learning rate decay parameter is set to 0.998 except for FedDyn, which is set to 0.9995. The global learning rate \u03b7 g is set to 1.0 except for FedAdam, which is set to 0.1. We choose \u03b1 = 0.1 in FedCM for 100 devices 10% participation Dirichlet 0.6 setting, and \u03b1 = 0.05 for other settings. We select \u03b1 = 0.1 in FedAdam and \u03b1 = 0.01 in FedDyn for all settings.\n\nFor experiments on CIFAR100 dataset, we choose 2 as the number of local training epochs, except for FedCM in 500 devices 2% participation setting where we choose 5. The batchsize is set to 50 for FedCM and FedAdam, and set to 20 for other methods. We choose 0.1 as local learning rate \u03b7 l . The learning rate decay parameter is set to 0.999 for FedDyn and 0.998 for others. The global learning rate \u03b7 g is set to 0.1 for FedAdam, and 1.0 for others. We choose \u03b1 = 0.05 for FedCM and \u03b1 = 0.1 for FedAdam. For FedDyn, we choose \u03b1 = 0.01 in 100 devices 10% participation setting, and \u03b1 = 0.001 in 500 devices 2% participation setting.\n\n\nC.3 Convergence plots\n\nThe training plots of FedCM and competing baselines on CIFAR10 and CIFAR100 datasets under various settings are provided in 2 and 3. We have the following observation.\n\nFirstly, FedCM outperforms other strong baselines across different participation rate and heterogeneity levels. From the convergence plots, we observe that the performance gap between FedCM and baselines methods is larger in the 500 devices 2% participation setting. This verifies our claim that FedCM is robust to the limited participation nature of federated learning.\n\nFurthermore, we observe that the convergence of FedCM is more stable compared with FedAdam. The convergence curves of FedAdam suffer a lot of oscillation, especially in the Dirichlet-0.6 setting. This is the consequence of client drift, as the inconsistency between the loss functions of different clients introduces additional noise into the optimization process. By comparison, FedCM alleviates client drift by utilizing global momentum term in client updates, and is relatively unaffected by this issue.  Figure 3: The convergence plots of CIFAR100 with IID and Dirichlet 0.6 split for 10% and 2% client participation rate.\n\n\nTheorem 5.1 gives the convergence rate of FedCM for strongly convex, general convex and nonconvex functions. For a precision requirement of , We obtain an upper bound on the communication rounds of O 1 \u00b5KS in strongly-convex setting, O 1 KS 2 in general convex setting, and O L KS 2in non-convex setting, all of which match the best known results for distributed SGD algorithms[Karimireddy et al., 2020b].\n\nFigure 1 :\n1The convergence plot of FedCM with different \u03b1.\n\nTable 1 :\n1The test accuracy of different methods on CIFAR10. Setting I: 100 clients, 10% participation. Setting II: 500 clients, 2% participation.Setting \nDataset \nTest Accuracy(%) \nFedCM FedAvg FedAdam SCAFFOLD FedDyn \n\nI \nIID \n87.92 \n82.80 \n87.54 \n85.41 \n85.51 \nDirichlet-0.6 \n87.61 \n82.14 \n86.77 \n84.62 \n85.14 \n\nII \nIID \n86.85 \n74.72 \n85.25 \n79.19 \n83.39 \nDirichlet-0.6 \n86.24 \n73.93 \n84.62 \n78.59 \n82.25 \n\n\n\nTable 2 :\n2The test accuracy of different methods on CIFAR100. Setting I: 100 clients, 10% partici-\npation. Setting II: 500 clients, 2% participation. \n\nSetting \nDataset \nTest Accuracy(%) \nFedCM FedAvg FedAdam SCAFFOLD FedDyn \n\nI \nIID \n58.16 \n49.18 \n54.91 \n55.68 \n53.52 \nDirichlet-0.6 \n57.96 \n47.76 \n54.67 \n55.31 \n52.95 \n\nII \nIID \n56.68 \n40.93 \n52.31 \n47.91 \n48.19 \nDirichlet-0.6 \n56.64 \n40.08 \n52.24 \n47.71 \n47.98 \n\n\n\nTable 3 :\n3The test accuracy of FedCM with different \u03b1.\u03b1 \n0.01 \n0.03 \n0.05 \n0.1 \n0.3 \n1.0 \ntest accuracy (%) 85.93 86.55 87.50 87.61 85.90 82.14 \n\n\n\n\nS. P. Karimireddy, M. Jaggi, S. Kale, M. Mohri, S. J. Reddi, S. U. Stich, and A. T. Suresh. Mime: Mimicking centralized stochastic algorithms in federated learning. arXiv preprint arXiv:2008.03606, 2020a. S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International Conference on Machine Learning, X. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang. On the convergence of fedavg on non-iid data. arXiv preprint arXiv:1907.02189, 2019b. X. Liang, S. Shen, J. Liu, Z. Pan, E. Chen, and Y. Cheng. Variance reduced local sgd with lower communication complexity. arXiv preprint arXiv:1912.12844, 2019. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pages 1273-1282. PMLR, 2017. R. Pathak and M. J. Wainwright. Fedsplit: An algorithmic framework for fast federated optimization.pages 5132-5143. PMLR, 2020b. \n\nD. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint \narXiv:1412.6980, 2014. \n\nJ. Kone\u010dn\u1ef3, H. B. McMahan, F. X. Yu, P. Richt\u00e1rik, A. T. Suresh, and D. Bacon. Federated learning: \nStrategies for improving communication efficiency. arXiv preprint arXiv:1610.05492, 2016. \n\nA. Krizhevsky, G. Hinton, et al. Learning multiple layers of features from tiny images. 2009. \n\nT. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith. Federated optimization in \nheterogeneous networks. arXiv preprint arXiv:1812.06127, 2018. \n\nT. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smithy. Feddane: A federated \nnewton-type method. In 2019 53rd Asilomar Conference on Signals, Systems, and Computers, \npages 1227-1231. IEEE, 2019a. \n\nT. Li, A. K. Sahu, A. Talwalkar, and V. Smith. Federated learning: Challenges, methods, and future \ndirections. IEEE Signal Processing Magazine, 37(3):50-60, 2020. \n\nT. Lin, S. P. Karimireddy, S. U. Stich, and M. Jaggi. Quasi-global momentum: Accelerating decen-\ntralized deep learning on heterogeneous data. arXiv preprint arXiv:2102.04761, 2021. \n\nW. Liu, L. Chen, Y. Chen, and W. Zhang. Accelerating federated learning via momentum gradient \ndescent. IEEE Transactions on Parallel and Distributed Systems, 31(8):1754-1766, 2020. \n\narXiv preprint arXiv:2005.05238, 2020. \n\nS. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Kone\u010dn\u1ef3, S. Kumar, and H. B. McMahan. \nAdaptive federated optimization. arXiv preprint arXiv:2003.00295, 2020. \n\nG. D. P. Regulation. Regulation eu 2016/679 of the european parliament and of the council of 27 april \n2016. Official Journal of the European Union. Available at: http://ec. europa. eu/justice/data-\nprotection/reform/files/regulation oj en. pdf (accessed 20 September 2017), 2016. \n\nO. Shamir, N. Srebro, and T. Zhang. Communication-efficient distributed optimization using an \napproximate newton-type method. In International conference on machine learning, pages 1000-\n1008. PMLR, 2014. \n\nspeedtest.net. speedtest.net, 2021. URL https://www.speedtest.net/global-index. \n\nS. U. Stich. Local sgd converges fast and communicates little. arXiv preprint arXiv:1805.09767, \n2018. \n\nQ. Tong, G. Liang, and J. Bi. Effective federated adaptive gradient methods with non-iid decentral-\nized data. arXiv preprint arXiv:2009.06557, 2020. \n\n\n\nFigure 2: The convergence plots of CIFAR10 with IID and Dirichlet 0.6 split for 10% and 2% client participation rate.0 \n\n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.60 \n\n0.65 \n\n0.70 \n\n0.75 \n\n0.80 \n\n0.85 \n\n0.90 \n\nTest Accuracy \n\nCIFAR10 100 Devices 10% Participation IID \n\nFedCM \nFedAvg \nFedAdam \nSCAFFOLD \nFedDyn \n\n(a) \n\n0 \n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.60 \n\n0.65 \n\n0.70 \n\n0.75 \n\n0.80 \n\n0.85 \n\n0.90 \n\nTest Accuracy \n\nCIFAR10 100 Devices 10% Participation Dirichlet 0.6 \n\nFedCM \nFedAvg \nFedAdam \nSCAFFOLD \nFedDyn \n\n(b) \n\n0 \n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.60 \n\n0.65 \n\n0.70 \n\n0.75 \n\n0.80 \n\n0.85 \n\n0.90 \n\nTest Accuracy \n\nCIFAR10 500 Devices 2% Participation IID \n\nFedCM \nFedAvg \nFedAdam \nSCAFFOLD \nFedDyn \n\n(c) \n\n0 \n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.60 \n\n0.65 \n\n0.70 \n\n0.75 \n\n0.80 \n\n0.85 \n\n0.90 \n\nTest Accuracy \n\nCIFAR10 500 Devices 2% Participation Dirichlet 0.6 \n\nFedCM \nFedAvg \nFedAdam \nSCAFFOLD \nFedDyn \n\n(d) \n\n0 \n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.30 \n\n0.35 \n\n0.40 \n\n0.45 \n\n0.50 \n\n0.55 \n\n0.60 \n\nTest Accuracy \n\nCIFAR100 100 Devices 10% Participation IID \n\nFedCM \nFedAvg \nFedAdam \nSCAFFOLD \nFedDyn \n\n(a) \n\n0 \n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.30 \n\n0.35 \n\n0.40 \n\n0.45 \n\n0.50 \n\n0.55 \n\n0.60 \n\nTest Accuracy \n\nCIFAR100 100 Devices 10% Participation Dirichlet 0.6 \n\nFedCM \nFedAvg \nFedAdam \nSCAFFOLD \nFedDyn \n\n(b) \n\n0 \n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.30 \n\n0.35 \n\n0.40 \n\n0.45 \n\n0.50 \n\n0.55 \n\n0.60 \n\nTest Accuracy \n\nCIFAR100 500 Devices 2% Participation IID \n\nFedCM \nFedAvg \nFedAdam \nSCAFFOLD \nFedDyn \n\n(c) \n\n0 \n500 1000 1500 2000 2500 3000 3500 4000 \nCommunication Rounds \n\n0.30 \n\n0.35 \n\n0.40 \n\n0.45 \n\n0.50 \n\n0.55 \n\n0.60 \n\nTest Accuracy \n\nCIFAR100 500 Devices 2% Participation Dirichlet 0.6 \n\nFedCM \nFedAvg \nFedAdam \nSACFFOLD \nFedDyn \n\n(d) \n\n\nk\u22121 + 1 k \u2212 1 \u2264 3k for k \u2265 2, we get the following t k \u2264 (k \u2212 1)\n\nFederated learning based on dynamic regularization. D A E Acar, Y Zhao, R M Navarro, M Mattina, P N Whatmough, V Saligrama, International Conference on Learning Representations. D. A. E. Acar, Y. Zhao, R. M. Navarro, M. Mattina, P. N. Whatmough, and V. Saligrama. Federated learning based on dynamic regularization. In International Conference on Learning Representa- tions, 2021.\n\nDistributed optimization and statistical learning via the alternating direction method of multipliers. S Boyd, N Parikh, E Chu, Now Publishers IncS. Boyd, N. Parikh, and E. Chu. Distributed optimization and statistical learning via the alternating direction method of multipliers. Now Publishers Inc, 2011.\n\nS Bubeck, arXiv:1405.4980Convex optimization: Algorithms and complexity. arXiv preprintS. Bubeck. Convex optimization: Algorithms and complexity. arXiv preprint arXiv:1405.4980, 2014.\n\nLarge scale distributed deep networks. J Dean, G S Corrado, R Monga, K Chen, M Devin, Q V Le, M Z Mao, M Ranzato, A Senior, P Tucker, J. Dean, G. S. Corrado, R. Monga, K. Chen, M. Devin, Q. V. Le, M. Z. Mao, M. Ranzato, A. Senior, P. Tucker, et al. Large scale distributed deep networks. 2012.\n\nPersonalized federated learning with moreau envelopes. C T Dinh, N H Tran, T D Nguyen, arXiv:2006.08848arXiv preprintC. T. Dinh, N. H. Tran, and T. D. Nguyen. Personalized federated learning with moreau envelopes. arXiv preprint arXiv:2006.08848, 2020.\n\nLower bounds and optimal algorithms for personalized federated learning. F Hanzely, S Hanzely, S Horv\u00e1th, P Richt\u00e1rik, arXiv:2010.02372arXiv preprintF. Hanzely, S. Hanzely, S. Horv\u00e1th, and P. Richt\u00e1rik. Lower bounds and optimal algorithms for personalized federated learning. arXiv preprint arXiv:2010.02372, 2020.\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionK. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016.\n\nThe non-iid data quagmire of decentralized machine learning. K Hsieh, A Phanishayee, O Mutlu, P Gibbons, International Conference on Machine Learning. PMLRK. Hsieh, A. Phanishayee, O. Mutlu, and P. Gibbons. The non-iid data quagmire of decentralized machine learning. In International Conference on Machine Learning, pages 4387-4398. PMLR, 2020.\n\nMeasuring the effects of non-identical data distribution for federated visual classification. T.-M H Hsu, H Qi, M Brown, arXiv:1909.06335arXiv preprintT.-M. H. Hsu, H. Qi, and M. Brown. Measuring the effects of non-identical data distribution for federated visual classification. arXiv preprint arXiv:1909.06335, 2019.\n\nZ Huo, Q Yang, B Gu, L C Huang, arXiv:2002.02090Faster on-device training using new federated momentum algorithm. arXiv preprintZ. Huo, Q. Yang, B. Gu, L. C. Huang, et al. Faster on-device training using new federated momen- tum algorithm. arXiv preprint arXiv:2002.02090, 2020.\n\nImproving federated learning personalization via model agnostic meta learning. Y Jiang, J Kone\u010dn\u1ef3, K Rush, S Kannan, arXiv:1909.12488arXiv preprintY. Jiang, J. Kone\u010dn\u1ef3, K. Rush, and S. Kannan. Improving federated learning personalization via model agnostic meta learning. arXiv preprint arXiv:1909.12488, 2019.\n\nAccelerating stochastic gradient descent using predictive variance reduction. R Johnson, T Zhang, Advances in neural information processing systems. 26R. Johnson and T. Zhang. Accelerating stochastic gradient descent using predictive variance reduc- tion. Advances in neural information processing systems, 26:315-323, 2013.\n\nP Kairouz, H B Mcmahan, B Avent, A Bellet, M Bennis, A N Bhagoji, K Bonawitz, Z Charles, G Cormode, R Cummings, arXiv:1912.04977Advances and open problems in federated learning. arXiv preprintP. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, et al. Advances and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.\n\nSlowmo: Improving communication-efficient distributed sgd with slow momentum. J Wang, V Tantia, N Ballas, M Rabbat, arXiv:1910.00643arXiv preprintJ. Wang, V. Tantia, N. Ballas, and M. Rabbat. Slowmo: Improving communication-efficient dis- tributed sgd with slow momentum. arXiv preprint arXiv:1910.00643, 2019.\n\nTackling the objective inconsistency problem in heterogeneous federated optimization. J Wang, Q Liu, H Liang, G Joshi, H V Poor, arXiv:2007.07481arXiv preprintJ. Wang, Q. Liu, H. Liang, G. Joshi, and H. V. Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. arXiv preprint arXiv:2007.07481, 2020.\n\nGroup normalization. Y Wu, K He, Proceedings of the European conference on computer vision (ECCV). the European conference on computer vision (ECCV)Y. Wu and K. He. Group normalization. In Proceedings of the European conference on computer vision (ECCV), pages 3-19, 2018.\n\nLocal adaalter: Communication-efficient stochastic gradient descent with adaptive learning rates. C Xie, O Koyejo, I Gupta, H Lin, arXiv:1911.09030arXiv preprintC. Xie, O. Koyejo, I. Gupta, and H. Lin. Local adaalter: Communication-efficient stochastic gradient descent with adaptive learning rates. arXiv preprint arXiv:1911.09030, 2019.\n\nFederated accelerated stochastic gradient descent. H Yuan, T Ma, arXiv:2006.08950arXiv preprintH. Yuan and T. Ma. Federated accelerated stochastic gradient descent. arXiv preprint arXiv:2006.08950, 2020.\n\nBayesian nonparametric federated learning of neural networks. M Yurochkin, M Agarwal, S Ghosh, K Greenewald, N Hoang, Y Khazaeni, International Conference on Machine Learning. PMLRM. Yurochkin, M. Agarwal, S. Ghosh, K. Greenewald, N. Hoang, and Y. Khazaeni. Bayesian nonparametric federated learning of neural networks. In International Conference on Machine Learning, pages 7252-7261. PMLR, 2019.\n\nFedpd: A federated learning framework with optimal rates and adaptivity to non-iid data. X Zhang, M Hong, S Dhople, W Yin, Y Liu, arXiv:2005.11418arXiv preprintX. Zhang, M. Hong, S. Dhople, W. Yin, and Y. Liu. Fedpd: A federated learning framework with optimal rates and adaptivity to non-iid data. arXiv preprint arXiv:2005.11418, 2020.\n\nY Zhao, M Li, L Lai, N Suda, D Civin, V Chandra, arXiv:1806.00582Federated learning with non-iid data. arXiv preprintY. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582, 2018.\n\nParallelized stochastic gradient descent. M Zinkevich, M Weimer, A J Smola, L Li, NIPS. 4page 4. CiteseerM. Zinkevich, M. Weimer, A. J. Smola, and L. Li. Parallelized stochastic gradient descent. In NIPS, volume 4, page 4. Citeseer, 2010.\n", "annotations": {"author": "[{\"end\":99,\"start\":56},{\"end\":190,\"start\":100},{\"end\":296,\"start\":191},{\"end\":331,\"start\":297},{\"end\":420,\"start\":332}]", "publisher": null, "author_last_name": "[{\"end\":63,\"start\":61},{\"end\":108,\"start\":104},{\"end\":201,\"start\":197},{\"end\":344,\"start\":341}]", "author_first_name": "[{\"end\":60,\"start\":56},{\"end\":103,\"start\":100},{\"end\":196,\"start\":191},{\"end\":303,\"start\":297},{\"end\":340,\"start\":332}]", "author_affiliation": "[{\"end\":98,\"start\":65},{\"end\":189,\"start\":131},{\"end\":295,\"start\":221},{\"end\":419,\"start\":346}]", "title": "[{\"end\":53,\"start\":1},{\"end\":473,\"start\":421}]", "venue": null, "abstract": "[{\"end\":1974,\"start\":475}]", "bib_ref": "[{\"end\":2050,\"start\":2028},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2153,\"start\":2132},{\"end\":2170,\"start\":2153},{\"end\":2668,\"start\":2650},{\"end\":2918,\"start\":2896},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3116,\"start\":3100},{\"end\":3143,\"start\":3116},{\"end\":3163,\"start\":3143},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3182,\"start\":3163},{\"end\":3371,\"start\":3351},{\"end\":3545,\"start\":3518},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3976,\"start\":3958},{\"end\":4003,\"start\":3976},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4198,\"start\":4181},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4216,\"start\":4198},{\"end\":4236,\"start\":4216},{\"end\":5861,\"start\":5835},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5880,\"start\":5861},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5974,\"start\":5957},{\"end\":5994,\"start\":5974},{\"end\":7446,\"start\":7425},{\"end\":7669,\"start\":7663},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7695,\"start\":7674},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8229,\"start\":8211},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8462,\"start\":8445},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8482,\"start\":8462},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8501,\"start\":8482},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8565,\"start\":8547},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8585,\"start\":8565},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8607,\"start\":8585},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8778,\"start\":8755},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8797,\"start\":8778},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8816,\"start\":8797},{\"end\":8837,\"start\":8816},{\"end\":8850,\"start\":8837},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8962,\"start\":8943},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8981,\"start\":8962},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9340,\"start\":9323},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9358,\"start\":9340},{\"end\":9378,\"start\":9358},{\"end\":11057,\"start\":11035},{\"end\":11750,\"start\":11728},{\"end\":11923,\"start\":11903},{\"end\":15478,\"start\":15452},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":15497,\"start\":15478},{\"end\":16286,\"start\":16266},{\"end\":16745,\"start\":16723},{\"end\":16880,\"start\":16859},{\"end\":17454,\"start\":17435},{\"end\":17481,\"start\":17454},{\"end\":17950,\"start\":17931},{\"end\":17969,\"start\":17950},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18937,\"start\":18923},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19145,\"start\":19129},{\"end\":19165,\"start\":19145},{\"end\":20474,\"start\":20447},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":20505,\"start\":20486},{\"end\":21922,\"start\":21903},{\"end\":22114,\"start\":22096},{\"end\":22521,\"start\":22497},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23284,\"start\":23266},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":23469,\"start\":23452},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23553,\"start\":23546},{\"end\":23582,\"start\":23553},{\"end\":23672,\"start\":23650},{\"end\":23710,\"start\":23674},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":23738,\"start\":23719},{\"end\":23771,\"start\":23751},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23905,\"start\":23880},{\"end\":24050,\"start\":24029},{\"end\":25838,\"start\":25812},{\"end\":25858,\"start\":25838},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":25877,\"start\":25858},{\"end\":29197,\"start\":29151},{\"end\":30125,\"start\":30122},{\"end\":30762,\"start\":30759},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30904,\"start\":30885},{\"end\":31430,\"start\":31413},{\"end\":32829,\"start\":32803},{\"end\":32945,\"start\":32938},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":43752,\"start\":43733},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":43776,\"start\":43752},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":43795,\"start\":43776},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":44595,\"start\":44577}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":48047,\"start\":47640},{\"attributes\":{\"id\":\"fig_1\"},\"end\":48108,\"start\":48048},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":48521,\"start\":48109},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":48940,\"start\":48522},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":49089,\"start\":48941},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":52474,\"start\":49090},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":54427,\"start\":52475}]", "paragraph": "[{\"end\":2669,\"start\":1990},{\"end\":3668,\"start\":2671},{\"end\":4497,\"start\":3670},{\"end\":4980,\"start\":4499},{\"end\":5480,\"start\":4982},{\"end\":6320,\"start\":5482},{\"end\":6379,\"start\":6322},{\"end\":6731,\"start\":6381},{\"end\":7055,\"start\":6733},{\"end\":7366,\"start\":7057},{\"end\":8647,\"start\":7384},{\"end\":9502,\"start\":8649},{\"end\":10036,\"start\":9556},{\"end\":10538,\"start\":10038},{\"end\":10690,\"start\":10574},{\"end\":10889,\"start\":10723},{\"end\":11007,\"start\":10914},{\"end\":11924,\"start\":11028},{\"end\":12088,\"start\":11926},{\"end\":12119,\"start\":12090},{\"end\":12160,\"start\":12121},{\"end\":12202,\"start\":12178},{\"end\":12259,\"start\":12204},{\"end\":12263,\"start\":12261},{\"end\":12312,\"start\":12301},{\"end\":12350,\"start\":12339},{\"end\":12385,\"start\":12382},{\"end\":12434,\"start\":12387},{\"end\":12687,\"start\":12436},{\"end\":13008,\"start\":12707},{\"end\":13528,\"start\":13010},{\"end\":13624,\"start\":13560},{\"end\":13925,\"start\":13626},{\"end\":13956,\"start\":13927},{\"end\":13997,\"start\":13958},{\"end\":14039,\"start\":14015},{\"end\":14070,\"start\":14041},{\"end\":14205,\"start\":14194},{\"end\":15007,\"start\":14474},{\"end\":15398,\"start\":15130},{\"end\":16287,\"start\":15414},{\"end\":17174,\"start\":16289},{\"end\":17482,\"start\":17199},{\"end\":17710,\"start\":17607},{\"end\":18035,\"start\":17848},{\"end\":18058,\"start\":18037},{\"end\":18235,\"start\":18060},{\"end\":18510,\"start\":18237},{\"end\":18761,\"start\":18662},{\"end\":19166,\"start\":18814},{\"end\":19263,\"start\":19168},{\"end\":19554,\"start\":19265},{\"end\":19624,\"start\":19556},{\"end\":20942,\"start\":20205},{\"end\":21609,\"start\":20944},{\"end\":22203,\"start\":21611},{\"end\":22409,\"start\":22219},{\"end\":23583,\"start\":22422},{\"end\":24468,\"start\":23585},{\"end\":24982,\"start\":24504},{\"end\":26019,\"start\":24984},{\"end\":26524,\"start\":26021},{\"end\":26842,\"start\":26526},{\"end\":27233,\"start\":26881},{\"end\":28228,\"start\":27235},{\"end\":29755,\"start\":28243},{\"end\":30868,\"start\":29757},{\"end\":32070,\"start\":30870},{\"end\":32722,\"start\":32610},{\"end\":33004,\"start\":32779},{\"end\":33245,\"start\":33069},{\"end\":33414,\"start\":33344},{\"end\":33747,\"start\":33653},{\"end\":34130,\"start\":33975},{\"end\":34213,\"start\":34181},{\"end\":34312,\"start\":34258},{\"end\":34393,\"start\":34346},{\"end\":34504,\"start\":34429},{\"end\":34512,\"start\":34506},{\"end\":35152,\"start\":34759},{\"end\":35307,\"start\":35202},{\"end\":35546,\"start\":35461},{\"end\":35981,\"start\":35842},{\"end\":36340,\"start\":36327},{\"end\":36605,\"start\":36450},{\"end\":36798,\"start\":36742},{\"end\":37067,\"start\":37029},{\"end\":37105,\"start\":37069},{\"end\":37198,\"start\":37107},{\"end\":37409,\"start\":37262},{\"end\":38631,\"start\":38473},{\"end\":38664,\"start\":38633},{\"end\":38872,\"start\":38831},{\"end\":38923,\"start\":38874},{\"end\":39001,\"start\":38925},{\"end\":39111,\"start\":39038},{\"end\":39151,\"start\":39113},{\"end\":39366,\"start\":39153},{\"end\":39575,\"start\":39425},{\"end\":39822,\"start\":39714},{\"end\":39911,\"start\":39883},{\"end\":39965,\"start\":39913},{\"end\":40005,\"start\":39967},{\"end\":40047,\"start\":40007},{\"end\":40196,\"start\":40120},{\"end\":40956,\"start\":40906},{\"end\":41374,\"start\":41300},{\"end\":41557,\"start\":41518},{\"end\":41705,\"start\":41645},{\"end\":41814,\"start\":41707},{\"end\":42677,\"start\":42627},{\"end\":42971,\"start\":42897},{\"end\":43462,\"start\":43157},{\"end\":44232,\"start\":43464},{\"end\":44939,\"start\":44265},{\"end\":45307,\"start\":44941},{\"end\":45813,\"start\":45309},{\"end\":46446,\"start\":45815},{\"end\":46639,\"start\":46472},{\"end\":47011,\"start\":46641},{\"end\":47639,\"start\":47013}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10573,\"start\":10539},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10722,\"start\":10691},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10913,\"start\":10890},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12177,\"start\":12161},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12300,\"start\":12264},{\"attributes\":{\"id\":\"formula_5\"},\"end\":12338,\"start\":12313},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12381,\"start\":12351},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13559,\"start\":13529},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14014,\"start\":13998},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14168,\"start\":14071},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14193,\"start\":14168},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14473,\"start\":14206},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15129,\"start\":15008},{\"attributes\":{\"id\":\"formula_13\"},\"end\":17606,\"start\":17483},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17847,\"start\":17711},{\"attributes\":{\"id\":\"formula_15\"},\"end\":18661,\"start\":18511},{\"attributes\":{\"id\":\"formula_16\"},\"end\":18813,\"start\":18762},{\"attributes\":{\"id\":\"formula_17\"},\"end\":20204,\"start\":19625},{\"attributes\":{\"id\":\"formula_18\"},\"end\":32609,\"start\":32194},{\"attributes\":{\"id\":\"formula_19\"},\"end\":32778,\"start\":32723},{\"attributes\":{\"id\":\"formula_20\"},\"end\":33068,\"start\":33005},{\"attributes\":{\"id\":\"formula_21\"},\"end\":33343,\"start\":33246},{\"attributes\":{\"id\":\"formula_22\"},\"end\":33652,\"start\":33415},{\"attributes\":{\"id\":\"formula_23\"},\"end\":33974,\"start\":33748},{\"attributes\":{\"id\":\"formula_24\"},\"end\":34180,\"start\":34131},{\"attributes\":{\"id\":\"formula_25\"},\"end\":34257,\"start\":34214},{\"attributes\":{\"id\":\"formula_26\"},\"end\":34428,\"start\":34394},{\"attributes\":{\"id\":\"formula_27\"},\"end\":34758,\"start\":34513},{\"attributes\":{\"id\":\"formula_28\"},\"end\":35201,\"start\":35153},{\"attributes\":{\"id\":\"formula_29\"},\"end\":35460,\"start\":35308},{\"attributes\":{\"id\":\"formula_30\"},\"end\":35841,\"start\":35547},{\"attributes\":{\"id\":\"formula_31\"},\"end\":36326,\"start\":35982},{\"attributes\":{\"id\":\"formula_32\"},\"end\":36449,\"start\":36341},{\"attributes\":{\"id\":\"formula_33\"},\"end\":36741,\"start\":36606},{\"attributes\":{\"id\":\"formula_34\"},\"end\":37028,\"start\":36799},{\"attributes\":{\"id\":\"formula_35\"},\"end\":37261,\"start\":37199},{\"attributes\":{\"id\":\"formula_36\"},\"end\":38472,\"start\":37410},{\"attributes\":{\"id\":\"formula_37\"},\"end\":38830,\"start\":38665},{\"attributes\":{\"id\":\"formula_38\"},\"end\":39037,\"start\":39002},{\"attributes\":{\"id\":\"formula_39\"},\"end\":39424,\"start\":39367},{\"attributes\":{\"id\":\"formula_40\"},\"end\":39713,\"start\":39576},{\"attributes\":{\"id\":\"formula_41\"},\"end\":39882,\"start\":39823},{\"attributes\":{\"id\":\"formula_42\"},\"end\":40119,\"start\":40048},{\"attributes\":{\"id\":\"formula_43\"},\"end\":40905,\"start\":40197},{\"attributes\":{\"id\":\"formula_44\"},\"end\":41299,\"start\":40957},{\"attributes\":{\"id\":\"formula_45\"},\"end\":41517,\"start\":41375},{\"attributes\":{\"id\":\"formula_46\"},\"end\":41644,\"start\":41558},{\"attributes\":{\"id\":\"formula_47\"},\"end\":42626,\"start\":41815},{\"attributes\":{\"id\":\"formula_48\"},\"end\":42896,\"start\":42678},{\"attributes\":{\"id\":\"formula_49\"},\"end\":43156,\"start\":42972}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24624,\"start\":24617},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27436,\"start\":27428},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27758,\"start\":27751}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1988,\"start\":1976},{\"attributes\":{\"n\":\"2\"},\"end\":7382,\"start\":7369},{\"attributes\":{\"n\":\"3\"},\"end\":9518,\"start\":9505},{\"attributes\":{\"n\":\"3.1\"},\"end\":9554,\"start\":9521},{\"attributes\":{\"n\":\"3.2\"},\"end\":11026,\"start\":11010},{\"attributes\":{\"n\":\"4.1\"},\"end\":12705,\"start\":12690},{\"attributes\":{\"n\":\"4.2\"},\"end\":15412,\"start\":15401},{\"attributes\":{\"n\":\"5\"},\"end\":17197,\"start\":17177},{\"attributes\":{\"n\":\"6\"},\"end\":22217,\"start\":22206},{\"attributes\":{\"n\":\"6.1\"},\"end\":22420,\"start\":22412},{\"attributes\":{\"n\":\"6.2\"},\"end\":24502,\"start\":24471},{\"attributes\":{\"n\":\"6.3\"},\"end\":26879,\"start\":26845},{\"attributes\":{\"n\":\"7\"},\"end\":28241,\"start\":28231},{\"end\":32157,\"start\":32073},{\"end\":32168,\"start\":32160},{\"end\":32193,\"start\":32171},{\"end\":34344,\"start\":34315},{\"end\":44263,\"start\":44235},{\"end\":46470,\"start\":46449},{\"end\":48059,\"start\":48049},{\"end\":48119,\"start\":48110},{\"end\":48532,\"start\":48523},{\"end\":48951,\"start\":48942}]", "table": "[{\"end\":48521,\"start\":48257},{\"end\":48940,\"start\":48534},{\"end\":49089,\"start\":48997},{\"end\":52474,\"start\":50094},{\"end\":54427,\"start\":52594}]", "figure_caption": "[{\"end\":48047,\"start\":47642},{\"end\":48108,\"start\":48061},{\"end\":48257,\"start\":48121},{\"end\":48997,\"start\":48953},{\"end\":50094,\"start\":49092},{\"end\":52594,\"start\":52477}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27487,\"start\":27479},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27881,\"start\":27873},{\"end\":47529,\"start\":47521}]", "bib_author_first_name": "[{\"end\":54547,\"start\":54546},{\"end\":54551,\"start\":54548},{\"end\":54559,\"start\":54558},{\"end\":54567,\"start\":54566},{\"end\":54569,\"start\":54568},{\"end\":54580,\"start\":54579},{\"end\":54591,\"start\":54590},{\"end\":54593,\"start\":54592},{\"end\":54606,\"start\":54605},{\"end\":54980,\"start\":54979},{\"end\":54988,\"start\":54987},{\"end\":54998,\"start\":54997},{\"end\":55185,\"start\":55184},{\"end\":55409,\"start\":55408},{\"end\":55417,\"start\":55416},{\"end\":55419,\"start\":55418},{\"end\":55430,\"start\":55429},{\"end\":55439,\"start\":55438},{\"end\":55447,\"start\":55446},{\"end\":55456,\"start\":55455},{\"end\":55458,\"start\":55457},{\"end\":55464,\"start\":55463},{\"end\":55466,\"start\":55465},{\"end\":55473,\"start\":55472},{\"end\":55484,\"start\":55483},{\"end\":55494,\"start\":55493},{\"end\":55720,\"start\":55719},{\"end\":55722,\"start\":55721},{\"end\":55730,\"start\":55729},{\"end\":55732,\"start\":55731},{\"end\":55740,\"start\":55739},{\"end\":55742,\"start\":55741},{\"end\":55992,\"start\":55991},{\"end\":56003,\"start\":56002},{\"end\":56014,\"start\":56013},{\"end\":56025,\"start\":56024},{\"end\":56281,\"start\":56280},{\"end\":56287,\"start\":56286},{\"end\":56296,\"start\":56295},{\"end\":56303,\"start\":56302},{\"end\":56699,\"start\":56698},{\"end\":56708,\"start\":56707},{\"end\":56723,\"start\":56722},{\"end\":56732,\"start\":56731},{\"end\":57082,\"start\":57078},{\"end\":57084,\"start\":57083},{\"end\":57091,\"start\":57090},{\"end\":57097,\"start\":57096},{\"end\":57305,\"start\":57304},{\"end\":57312,\"start\":57311},{\"end\":57320,\"start\":57319},{\"end\":57326,\"start\":57325},{\"end\":57328,\"start\":57327},{\"end\":57664,\"start\":57663},{\"end\":57673,\"start\":57672},{\"end\":57684,\"start\":57683},{\"end\":57692,\"start\":57691},{\"end\":57975,\"start\":57974},{\"end\":57986,\"start\":57985},{\"end\":58223,\"start\":58222},{\"end\":58234,\"start\":58233},{\"end\":58236,\"start\":58235},{\"end\":58247,\"start\":58246},{\"end\":58256,\"start\":58255},{\"end\":58266,\"start\":58265},{\"end\":58276,\"start\":58275},{\"end\":58278,\"start\":58277},{\"end\":58289,\"start\":58288},{\"end\":58301,\"start\":58300},{\"end\":58312,\"start\":58311},{\"end\":58323,\"start\":58322},{\"end\":58714,\"start\":58713},{\"end\":58722,\"start\":58721},{\"end\":58732,\"start\":58731},{\"end\":58742,\"start\":58741},{\"end\":59034,\"start\":59033},{\"end\":59042,\"start\":59041},{\"end\":59049,\"start\":59048},{\"end\":59058,\"start\":59057},{\"end\":59067,\"start\":59066},{\"end\":59069,\"start\":59068},{\"end\":59307,\"start\":59306},{\"end\":59313,\"start\":59312},{\"end\":59658,\"start\":59657},{\"end\":59665,\"start\":59664},{\"end\":59675,\"start\":59674},{\"end\":59684,\"start\":59683},{\"end\":59951,\"start\":59950},{\"end\":59959,\"start\":59958},{\"end\":60167,\"start\":60166},{\"end\":60180,\"start\":60179},{\"end\":60191,\"start\":60190},{\"end\":60200,\"start\":60199},{\"end\":60214,\"start\":60213},{\"end\":60223,\"start\":60222},{\"end\":60593,\"start\":60592},{\"end\":60602,\"start\":60601},{\"end\":60610,\"start\":60609},{\"end\":60620,\"start\":60619},{\"end\":60627,\"start\":60626},{\"end\":60843,\"start\":60842},{\"end\":60851,\"start\":60850},{\"end\":60857,\"start\":60856},{\"end\":60864,\"start\":60863},{\"end\":60872,\"start\":60871},{\"end\":60881,\"start\":60880},{\"end\":61139,\"start\":61138},{\"end\":61152,\"start\":61151},{\"end\":61162,\"start\":61161},{\"end\":61164,\"start\":61163},{\"end\":61173,\"start\":61172}]", "bib_author_last_name": "[{\"end\":54556,\"start\":54552},{\"end\":54564,\"start\":54560},{\"end\":54577,\"start\":54570},{\"end\":54588,\"start\":54581},{\"end\":54603,\"start\":54594},{\"end\":54616,\"start\":54607},{\"end\":54985,\"start\":54981},{\"end\":54995,\"start\":54989},{\"end\":55002,\"start\":54999},{\"end\":55192,\"start\":55186},{\"end\":55414,\"start\":55410},{\"end\":55427,\"start\":55420},{\"end\":55436,\"start\":55431},{\"end\":55444,\"start\":55440},{\"end\":55453,\"start\":55448},{\"end\":55461,\"start\":55459},{\"end\":55470,\"start\":55467},{\"end\":55481,\"start\":55474},{\"end\":55491,\"start\":55485},{\"end\":55501,\"start\":55495},{\"end\":55727,\"start\":55723},{\"end\":55737,\"start\":55733},{\"end\":55749,\"start\":55743},{\"end\":56000,\"start\":55993},{\"end\":56011,\"start\":56004},{\"end\":56022,\"start\":56015},{\"end\":56035,\"start\":56026},{\"end\":56284,\"start\":56282},{\"end\":56293,\"start\":56288},{\"end\":56300,\"start\":56297},{\"end\":56307,\"start\":56304},{\"end\":56705,\"start\":56700},{\"end\":56720,\"start\":56709},{\"end\":56729,\"start\":56724},{\"end\":56740,\"start\":56733},{\"end\":57088,\"start\":57085},{\"end\":57094,\"start\":57092},{\"end\":57103,\"start\":57098},{\"end\":57309,\"start\":57306},{\"end\":57317,\"start\":57313},{\"end\":57323,\"start\":57321},{\"end\":57334,\"start\":57329},{\"end\":57670,\"start\":57665},{\"end\":57681,\"start\":57674},{\"end\":57689,\"start\":57685},{\"end\":57699,\"start\":57693},{\"end\":57983,\"start\":57976},{\"end\":57992,\"start\":57987},{\"end\":58231,\"start\":58224},{\"end\":58244,\"start\":58237},{\"end\":58253,\"start\":58248},{\"end\":58263,\"start\":58257},{\"end\":58273,\"start\":58267},{\"end\":58286,\"start\":58279},{\"end\":58298,\"start\":58290},{\"end\":58309,\"start\":58302},{\"end\":58320,\"start\":58313},{\"end\":58332,\"start\":58324},{\"end\":58719,\"start\":58715},{\"end\":58729,\"start\":58723},{\"end\":58739,\"start\":58733},{\"end\":58749,\"start\":58743},{\"end\":59039,\"start\":59035},{\"end\":59046,\"start\":59043},{\"end\":59055,\"start\":59050},{\"end\":59064,\"start\":59059},{\"end\":59074,\"start\":59070},{\"end\":59310,\"start\":59308},{\"end\":59316,\"start\":59314},{\"end\":59662,\"start\":59659},{\"end\":59672,\"start\":59666},{\"end\":59681,\"start\":59676},{\"end\":59688,\"start\":59685},{\"end\":59956,\"start\":59952},{\"end\":59962,\"start\":59960},{\"end\":60177,\"start\":60168},{\"end\":60188,\"start\":60181},{\"end\":60197,\"start\":60192},{\"end\":60211,\"start\":60201},{\"end\":60220,\"start\":60215},{\"end\":60232,\"start\":60224},{\"end\":60599,\"start\":60594},{\"end\":60607,\"start\":60603},{\"end\":60617,\"start\":60611},{\"end\":60624,\"start\":60621},{\"end\":60631,\"start\":60628},{\"end\":60848,\"start\":60844},{\"end\":60854,\"start\":60852},{\"end\":60861,\"start\":60858},{\"end\":60869,\"start\":60865},{\"end\":60878,\"start\":60873},{\"end\":60889,\"start\":60882},{\"end\":61149,\"start\":61140},{\"end\":61159,\"start\":61153},{\"end\":61170,\"start\":61165},{\"end\":61176,\"start\":61174}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":235614315},\"end\":54874,\"start\":54494},{\"attributes\":{\"id\":\"b1\"},\"end\":55182,\"start\":54876},{\"attributes\":{\"doi\":\"arXiv:1405.4980\",\"id\":\"b2\"},\"end\":55367,\"start\":55184},{\"attributes\":{\"id\":\"b3\"},\"end\":55662,\"start\":55369},{\"attributes\":{\"doi\":\"arXiv:2006.08848\",\"id\":\"b4\"},\"end\":55916,\"start\":55664},{\"attributes\":{\"doi\":\"arXiv:2010.02372\",\"id\":\"b5\"},\"end\":56232,\"start\":55918},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":206594692},\"end\":56635,\"start\":56234},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":203610177},\"end\":56982,\"start\":56637},{\"attributes\":{\"doi\":\"arXiv:1909.06335\",\"id\":\"b8\"},\"end\":57302,\"start\":56984},{\"attributes\":{\"doi\":\"arXiv:2002.02090\",\"id\":\"b9\"},\"end\":57582,\"start\":57304},{\"attributes\":{\"doi\":\"arXiv:1909.12488\",\"id\":\"b10\"},\"end\":57894,\"start\":57584},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":6587578},\"end\":58220,\"start\":57896},{\"attributes\":{\"doi\":\"arXiv:1912.04977\",\"id\":\"b12\"},\"end\":58633,\"start\":58222},{\"attributes\":{\"doi\":\"arXiv:1910.00643\",\"id\":\"b13\"},\"end\":58945,\"start\":58635},{\"attributes\":{\"doi\":\"arXiv:2007.07481\",\"id\":\"b14\"},\"end\":59283,\"start\":58947},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":4076251},\"end\":59557,\"start\":59285},{\"attributes\":{\"doi\":\"arXiv:1911.09030\",\"id\":\"b16\"},\"end\":59897,\"start\":59559},{\"attributes\":{\"doi\":\"arXiv:2006.08950\",\"id\":\"b17\"},\"end\":60102,\"start\":59899},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":168170092},\"end\":60501,\"start\":60104},{\"attributes\":{\"doi\":\"arXiv:2005.11418\",\"id\":\"b19\"},\"end\":60840,\"start\":60503},{\"attributes\":{\"doi\":\"arXiv:1806.00582\",\"id\":\"b20\"},\"end\":61094,\"start\":60842},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":7885987},\"end\":61334,\"start\":61096}]", "bib_title": "[{\"end\":54544,\"start\":54494},{\"end\":56278,\"start\":56234},{\"end\":56696,\"start\":56637},{\"end\":57972,\"start\":57896},{\"end\":59304,\"start\":59285},{\"end\":60164,\"start\":60104},{\"end\":61136,\"start\":61096}]", "bib_author": "[{\"end\":54558,\"start\":54546},{\"end\":54566,\"start\":54558},{\"end\":54579,\"start\":54566},{\"end\":54590,\"start\":54579},{\"end\":54605,\"start\":54590},{\"end\":54618,\"start\":54605},{\"end\":54987,\"start\":54979},{\"end\":54997,\"start\":54987},{\"end\":55004,\"start\":54997},{\"end\":55194,\"start\":55184},{\"end\":55416,\"start\":55408},{\"end\":55429,\"start\":55416},{\"end\":55438,\"start\":55429},{\"end\":55446,\"start\":55438},{\"end\":55455,\"start\":55446},{\"end\":55463,\"start\":55455},{\"end\":55472,\"start\":55463},{\"end\":55483,\"start\":55472},{\"end\":55493,\"start\":55483},{\"end\":55503,\"start\":55493},{\"end\":55729,\"start\":55719},{\"end\":55739,\"start\":55729},{\"end\":55751,\"start\":55739},{\"end\":56002,\"start\":55991},{\"end\":56013,\"start\":56002},{\"end\":56024,\"start\":56013},{\"end\":56037,\"start\":56024},{\"end\":56286,\"start\":56280},{\"end\":56295,\"start\":56286},{\"end\":56302,\"start\":56295},{\"end\":56309,\"start\":56302},{\"end\":56707,\"start\":56698},{\"end\":56722,\"start\":56707},{\"end\":56731,\"start\":56722},{\"end\":56742,\"start\":56731},{\"end\":57090,\"start\":57078},{\"end\":57096,\"start\":57090},{\"end\":57105,\"start\":57096},{\"end\":57311,\"start\":57304},{\"end\":57319,\"start\":57311},{\"end\":57325,\"start\":57319},{\"end\":57336,\"start\":57325},{\"end\":57672,\"start\":57663},{\"end\":57683,\"start\":57672},{\"end\":57691,\"start\":57683},{\"end\":57701,\"start\":57691},{\"end\":57985,\"start\":57974},{\"end\":57994,\"start\":57985},{\"end\":58233,\"start\":58222},{\"end\":58246,\"start\":58233},{\"end\":58255,\"start\":58246},{\"end\":58265,\"start\":58255},{\"end\":58275,\"start\":58265},{\"end\":58288,\"start\":58275},{\"end\":58300,\"start\":58288},{\"end\":58311,\"start\":58300},{\"end\":58322,\"start\":58311},{\"end\":58334,\"start\":58322},{\"end\":58721,\"start\":58713},{\"end\":58731,\"start\":58721},{\"end\":58741,\"start\":58731},{\"end\":58751,\"start\":58741},{\"end\":59041,\"start\":59033},{\"end\":59048,\"start\":59041},{\"end\":59057,\"start\":59048},{\"end\":59066,\"start\":59057},{\"end\":59076,\"start\":59066},{\"end\":59312,\"start\":59306},{\"end\":59318,\"start\":59312},{\"end\":59664,\"start\":59657},{\"end\":59674,\"start\":59664},{\"end\":59683,\"start\":59674},{\"end\":59690,\"start\":59683},{\"end\":59958,\"start\":59950},{\"end\":59964,\"start\":59958},{\"end\":60179,\"start\":60166},{\"end\":60190,\"start\":60179},{\"end\":60199,\"start\":60190},{\"end\":60213,\"start\":60199},{\"end\":60222,\"start\":60213},{\"end\":60234,\"start\":60222},{\"end\":60601,\"start\":60592},{\"end\":60609,\"start\":60601},{\"end\":60619,\"start\":60609},{\"end\":60626,\"start\":60619},{\"end\":60633,\"start\":60626},{\"end\":60850,\"start\":60842},{\"end\":60856,\"start\":60850},{\"end\":60863,\"start\":60856},{\"end\":60871,\"start\":60863},{\"end\":60880,\"start\":60871},{\"end\":60891,\"start\":60880},{\"end\":61151,\"start\":61138},{\"end\":61161,\"start\":61151},{\"end\":61172,\"start\":61161},{\"end\":61178,\"start\":61172}]", "bib_venue": "[{\"end\":54670,\"start\":54618},{\"end\":54977,\"start\":54876},{\"end\":55255,\"start\":55209},{\"end\":55406,\"start\":55369},{\"end\":55717,\"start\":55664},{\"end\":55989,\"start\":55918},{\"end\":56386,\"start\":56309},{\"end\":56786,\"start\":56742},{\"end\":57076,\"start\":56984},{\"end\":57416,\"start\":57352},{\"end\":57661,\"start\":57584},{\"end\":58043,\"start\":57994},{\"end\":58398,\"start\":58350},{\"end\":58711,\"start\":58635},{\"end\":59031,\"start\":58947},{\"end\":59382,\"start\":59318},{\"end\":59655,\"start\":59559},{\"end\":59948,\"start\":59899},{\"end\":60278,\"start\":60234},{\"end\":60590,\"start\":60503},{\"end\":60943,\"start\":60907},{\"end\":61182,\"start\":61178},{\"end\":56450,\"start\":56388},{\"end\":59433,\"start\":59384}]"}}}, "year": 2023, "month": 12, "day": 17}