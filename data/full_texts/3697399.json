{"id": 3697399, "updated": "2023-09-30 06:27:54.083", "metadata": {"title": "Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders", "authors": "[{\"first\":\"Jesse\",\"last\":\"Engel\",\"middle\":[]},{\"first\":\"Cinjon\",\"last\":\"Resnick\",\"middle\":[]},{\"first\":\"Adam\",\"last\":\"Roberts\",\"middle\":[]},{\"first\":\"Sander\",\"last\":\"Dieleman\",\"middle\":[]},{\"first\":\"Douglas\",\"last\":\"Eck\",\"middle\":[]},{\"first\":\"Karen\",\"last\":\"Simonyan\",\"middle\":[]},{\"first\":\"Mohammad\",\"last\":\"Norouzi\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2017, "month": 4, "day": 5}, "abstract": "Generative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autoencoder model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1704.01279", "mag": "2951535099", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icml/EngelRRDNES17", "doi": null}}, "content": {"source": {"pdf_hash": "595a23ab15bf32983b1d233ceca47b2146fb64e6", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1704.01279v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "d3ff102fae4cb65798af0994cb2d8c731349df8c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/595a23ab15bf32983b1d233ceca47b2146fb64e6.txt", "contents": "\nNeural Audio Synthesis of Musical Notes with WaveNet Autoencoders\n\n\nJesse Engel \nCinjon Resnick \nAdam Roberts \nSander Dieleman \nDouglas Eck \nKaren Simonyan \nMohammad Norouzi \nNeural Audio Synthesis of Musical Notes with WaveNet Autoencoders\n\nGenerative models in vision have seen rapid progress due to algorithmic improvements and the availability of high-quality image datasets. In this paper, we offer contributions in both these areas to enable similar progress in audio modeling. First, we detail a powerful new WaveNet-style autoencoder model that conditions an autoregressive decoder on temporal codes learned from the raw audio waveform. Second, we introduce NSynth, a large-scale and high-quality dataset of musical notes that is an order of magnitude larger than comparable public datasets. Using NSynth, we demonstrate improved qualitative and quantitative performance of the WaveNet autoencoder over a well-tuned spectral autoencoder baseline. Finally, we show that the model learns a manifold of embeddings that allows for morphing between instruments, meaningfully interpolating in timbre to create new types of sounds that are realistic and expressive.\n\nIntroduction\n\nAudio synthesis is important for a large range of applications including text-to-speech (TTS) systems and music generation. Audio generation algorithms, know as vocoders in TTS and synthesizers in music, respond to higher-level control signals to create fine-grained audio waveforms. Synthesizers have a long history of being hand-designed instruments, accepting control signals such as 'pitch', 'velocity', and filter parameters to shape the tone, timbre, and dynamics of a sound (Pinch et al., 2009). In spite of their limitations, or perhaps because of them, synthesizers have had a profound effect on the course of music and culture in the past half century (Punk, 2014).\n\nIn this paper, we outline a data-driven approach to audio synthesis. Rather than specifying a specific arrangement of oscillators or an algorithm for sample playback, such as in FM Synthesis or Granular Synthesis (Chowning, 1973;Xenakis, 1971), we show that it is possible to generate new types of expressive and realistic instrument sounds with a neural network model. Further, we show that this model can learn a semantically meaningful hidden representation that can be used as a high-level control signal for manipulating tone, timbre, and dynamics during playback.\n\nExplicitly, our two contributions to advance the state of generative audio modeling are:\n\n\u2022 A WaveNet-style autoencoder that learns temporal hidden codes to effectively capture longer term structure without external conditioning.\n\n\u2022 NSynth: a large-scale dataset for exploring neural audio synthesis of musical notes.\n\nThe primary motivation for our novel autoencoder structure follows from the recent advances in autoregressive models like WaveNet (van den Oord et al., 2016a) and SampleRNN (Mehri et al., 2016). They have proven to be effective at modeling short and medium scale (\u223c500ms) signals, but rely on external conditioning for longer-term dependencies. Our autoencoder removes the need for that external conditioning. It consists of a WaveNet-like encoder that infers hidden embeddings distributed in time and a WaveNet decoder that uses those embeddings to effectively reconstruct the original audio. This structure allows the size of an embedding to scale with the size of the input and encode over much longer time scales. the availability of high-quality and large-scale datasets such as MNIST (LeCun et al., 1998), SVHN (Netzer et al., 2011), CIFAR (Krizhevsky & Hinton, 2009) and ImageNet (Deng et al., 2009). While generative models are notoriously hard to evaluate (Theis et al., 2015), these datasets provide a common test bed for consistent qualitative and quantitative evaluation, such as with the use of the Inception score .\n\nWe recognized the need for an audio dataset that was as approachable as those in the image domain. Audio signals found in the wild contain multi-scale dependencies that prove particularly difficult to model (Raffel, 2016;Bertin-Mahieux et al., 2011;King et al., 2008;Thickstun et al., 2016), leading many previous efforts at data-driven audio synthesis to focus on more constrained domains such as texture synthesis or training small parametric models (Sarroff & Casey, 2014;Mc-Dermott et al., 2009).\n\nInspired by the large, high-quality image datasets, NSynth is an order of magnitude larger than comparable public datasets (Humphrey, 2016). It consists of \u223c300k four-second annotated notes sampled at 16kHz from \u223c1k harmonic musical instruments.\n\nAfter introducing the models and describing the dataset, we evaluate the performance of the WaveNet autoencoder over a baseline convolutional autoencoder model trained on spectrograms. We examine the tasks of reconstruction and interpolation, and analyze the learned space of embeddings. For qualitative evaluation, download audio files for all examples mentioned in this paper here. Despite our best efforts to convey analysis in plots, listening to the samples is essential to understanding this paper and we strongly encourage the reader to listen along as they read.\n\n\nModels\n\n\nWaveNet Autoencoder\n\nWaveNet (van den Oord et al., 2016a) is a powerful generative approach to probabilistic modeling of raw audio. In this section we describe our novel WaveNet autoencoder structure. The primary motivation for this approach is to attain consistent long-term structure without external conditioning. A secondary motivation is to use the learned encodings for applications such as meaningful audio interpolation.\n\nRecalling the original WaveNet architecture described in (van den Oord et al., 2016a), at each step a stack of dilated convolutions predicts the next sample of audio from a fixed-size input of prior sample values. The joint probability of the audio x is factorized as a product of conditional probabilities:\np(x) = N i=1 p(x i |x 1 , ..., x N \u22121 )\nUnconditional generation from this model manifests as \"babbling\" due to the lack of longer term structure (Listen: CAUTION, VERY LOUD! (ex1, ex2, ex3, ex4)). However, (van den Oord et al., 2016a) showed in the context of speech that long-range structure can be enforced by conditioning on temporally aligned linguistic features.\n\nOur autoencoder removes the need for that external conditioning. It works by taking raw audio waveform as input from which the encoder produces an embedding Z = f (x). Next, we causally shift the same input and feed it into the decoder, which reproduces the input waveform. The joint probablity is now:\np(x) = N i=1 p(x i |x 1 , ..., x N \u22121 , f (x))\nWe could parameterize Z as a latent variable p(Z|x) that we would have to marginalize over , but in practice we have found this to be less effective. As discussed in , this may be due to the decoder being so powerful that it can ignore the latent variables unless they encode a much larger context that's otherwise inaccessible.\n\nNote that the decoder could completely ignore the deterministic encoding and degenerate to a standard unconditioned WaveNet. However, because the encoding is a strong signal for the supervised output, the model learns to utilize it.\n\nDuring inference, the decoder autoregressively generates a single output sample at a time conditioned on an embedding and a starting palette of zeros. The embedding can be inferred deterministically from audio or drawn from other points in the embedding space, e.g. through interpolation or analogy (White, 2016).\n\nFigure 1b depicts the model architecture in more detail. The temporal encoder model is a 30-layer nonlinear residual network of dilated convolutions followed by 1x1 convolutions. Each convolution has 128 channels and precedes a ReLU nonlinearity. The output feed into another 1x1 convolution before downsampling with average pooling to get the encoding Z. We call it a 'temporal encoding' because the result is a sequence of hidden codes with separate dimensions for time and channel. The time resolution depends on the stride of the pooling. We tune the stride, keeping total size of the embedding constant (\u223c32x compression).\n\nIn the trade-off between temporal resolution and embedding expressivity, we find a sweet spot at a stride of 512 (32ms) with 16 dimensions per timestep, yielding a 125x16 embedding for each NSynth note. We additionally explore models that condition on global attributes by utilizing a one-hot pitch embedding. The WaveNet decoder model is similar to that presented in (van den Oord et al., 2016a). We condition it by biasing every layer with a different linear projection of the temporal embeddings. Since the decoder does not downsample anywhere in the network, we upsample the temporal encodings to the original audio rate with nearest neighbor interpolation. As in the original design, we quantize our input audio using 8-bit mu-law encoding and predict each output step with a softmax over the resulting 256 values.\n\nThis WaveNet autoencoder is a deep and expressive network, but has the trade-off of being limited in temporal context to the chunk-size of the training audio. While this is sufficient for consistently encoding the identity of a sound and interpolating among many sounds, achieving larger context would be better and is an area of ongoing research.\n\n\nBaseline: Spectral Autoencoder\n\nAs a point of comparison, we set out to create a straightforward yet strong baseline for the our neural audio synthesis experiments. Inspired by image models (Vincent et al., 2010), we explore convolutional autoencoder structures with a bottleneck that forces the model to find a compressed representation for an entire note. Figure 1a shows a block diagram of our baseline architecture. The convolutional encoder and decoder are each 10 layers deep with 2x2 strides and 4x4 kernels. Every layer is followed by a leaky-ReLU (0.1) nonlinearity and batch normalization (Ioffe & Szegedy, 2015). The number of channels grows from 128 to 1024 before a linear fully-connected layer creates a single 1984 1 dimensional hidden vector (Z) to match that of the WaveNet autoencoder.\n\nGiven the simplicity of the architecture, we examined a range of input representations. Using the raw waveform as input with a mean-squared error (MSE) cost proved difficult to train and highlighted the inadequacy of the independent Gaussian assumption. Spectral representations such as the real and imaginary components of the Fast Fourier Transform (FFT) fared better, but suffered from low perceptual quality despite achieving low MSE cost. We found that training on the log magnitude of the power spectra, peak normalized to be between 0 and 1, correlated better with perceptual distortion.\n\nWe also explored several representations of phase, in-cluding instantaneous frequency and circular normal cost functions (see Appendix), but in each case independently estimating phase and magnitude led to poor sample quality due to phase errors. We find a large improvement by estimating only the magnitude and using a well established iterative technique to reconstruct the phase (Griffin & Lim, 1984). To get the best results, we used a large FFT size (1024) relative to the hop size (256) and ran the algorithm for 1000 iterations. As a final heuristic, we weighted the MSE loss, starting at 10 for 0Hz and decreasing linearly to 1 at 4000Hz and above. At the expense of some precision in timbre, this created more phase coherence for the fundamentals of notes, where errors in the linear spectrum lead to a larger relative error in frequency.\n\n\nTraining\n\nWe train all models with stochastic gradient descent with an Adam optimizer (Kingma & Ba, 2014). The baseline models commonly use a learning rate of 1e-4, while the WaveNet models use a schedule, starting at 2e-4 and descending to 6e-5, 2e-5, and 6e-6 at iterations 120k, 180k, and 240k respectively. The baseline models train asynchronously for 1800k iterations with a batch size of 8. The WaveNet models train synchronously for 250k iterations with a batch size of 32.\n\n\nThe NSynth Dataset\n\nTo evaluate our WaveNet autoencoder model, we wanted an audio dataset that let us explore the learned embeddings. Musical notes are an ideal setting for this study as we hypothesize that the embeddings will capture structure such as pitch, dynamics, and timbre. While several smaller datasets currently exist (Goto et al., 2003;Romani Picas et al., 2015), deep networks train better on abundant, high-quality data, motivating the development of a new dataset.\n\n\nA Dataset of Musical Notes\n\nNSynth consists of 306 043 musical notes, each with a unique pitch, timbre, and envelope. For 1006 instruments from commercial sample libraries, we generated four second, monophonic 16kHz audio snippets, referred to as notes, by ranging over every pitch of a standard MIDI piano (21-108) as well as five different velocities 2 (25, 50, 75, 100, 127). The note was held for the first three seconds and allowed to decay for the final second. Some instruments are not capable of producing all 88 pitches in this range, resulting in an average of 65.4 pitches per instrument. Furthermore, the commercial sample packs occasionally contain duplicate sounds across multiple velocities, leaving an average of 4.75 unique velocities per pitch.\n\n\nAnnotations\n\nWe also annotated each of the notes with three additional pieces of information based on a combination of human evaluation and heuristic algorithms:\n\n\u2022 Source: The method of sound production for the note's instrument. This can be one of 'acoustic' or 'electronic' for instruments that were recorded from acoustic or electronic instruments, respectively, or 'synthetic' for synthesized instruments.\n\n\u2022 Family: The high-level family of which the note's instrument is a member. Each instrument is a member of exactly one family. See Appendix for the complete list.\n\n\u2022 Qualities: Sonic qualities of the note. See Appendix for the complete list of classes and their co-occurrences. Each note is annotated with zero or more qualities.\n\n\nAvailability\n\nThe full NSynth dataset is available for download at https://magenta.tensorflow.org/datasets/nsynth as TFRecord files split into training and holdout sets. Each note is represented by a serialized TensorFlow Example protocol buffer containing the note and annotations. Details of the format can be found in the README.\n\n\nEvaluation\n\nWe evaluate and analyze our models on the tasks of note reconstruction, instrument interpolation, and pitch interpolation.\n\nAudio is notoriously hard to represent visually. Magnitude spectrograms capture many aspects of a signal for analytics, but two spectrograms that appear very similar to the eye can correspond to audio that sound drastically different due to phase differences. We have included supplemental audio examples of every plot and encourage the reader to listen along as they read.\n\nThat said, in our analysis we present examples as plots of the constant-q transform (CQT) (Brown, 1991), which is useful because it is shift invariant to changes in the fundamental frequency. In this way, the struc- ture and envelope of the overtone series (higher harmonics) determines the dynamics and timbre of a note, regardless of its base frequency. However, due to the logarithmic binning of frequencies, transient noise-like impulses appear as rainbow \"pyramidal spikes\" rather than straight broadband lines. We display CQTs with a pitch range of 24-96 (C2-C8), hop size of 256, 40 bins per octave, and a filter scale of 0.8.\n\nAs phase plays such an essential part in sample quality, we have attempted to show both magnitude and phase on the same plot. The intensity of lines is proportional to the log magnitude of the power spectrum while the color is given by the derivative of the unrolled phase ('instantaneous frequency') (Boashash, 1992). We display the derivative of the phase because it creates a solid continuous line for a harmonic of a consistent frequency. We can understand this because if the instantaneous frequency of a harmonic (f harm ) and an FFT bin (f bin ) are not exactly equal, each timestep will introduce a constant phase shift, \u2206\u03c6 = (f bin \u2212 f harm ) hopsize samplerate . We affectionately re-fer to these instantaneous frequency colored spectrograms as \"Rainbowgrams\" due to their tendency to form rainbows as the instantaneous frequencies modulate up and down.\n\n\nReconstruction\n\nFigure 2 displays rainbowgrams for notes from 3 different instruments in the holdout set, where the original notes are on the first column and the model reconstructions are on the second and third columns. Each note has a similar structure with some noise on onset, a fundamental frequency with a series of harmonics, and a decay. For all the WaveNet models, there is a slight built-in distortion due to the compression of the mulaw encoding. It is a minor effect for many samples, but is more pronounced for lower frequencies. Using different representations without this distortion is an ongoing area of research.\n\nWhile each rainbowgram matches the general contour of the original note, we can hear a pronounced difference in sample quality that we can ascribe to certain features. For the Glockenspiel, we can see that the WaveNet autoencoder reproduces the magnitude and phase of the fundamental (solid blue stripe, (A)), and also the noise on attack (vertical rainbow spike (B)).\n\nThere is a slight error in the fundamental as it starts a little high and quickly descends to the correct pitch (C). In contrast, the baseline has a more percussive, multitonal sound, similar to a bell or gong. The fundamental is still present, but so are other frequencies, and the phases estimated from the Griffin-Lim procedure are noisy as indicated by the blurred horizontal rainbow texture (D).\n\nThe electric piano has a more clearly defined harmonic series (the horizontal rainbow solid lines, (E)) and a noise on the beginning and end of the note (vertical rainbow spikes, (F)). Listening to the sound, we hear that it is slightly distorted, which promotes these upper harmonics. Both the WaveNet autoencoder and the baseline produce rainbowgrams with similar shapes to the original, but with different types of phase artifacts. The WaveNet model has sufficient phase structure to model the distortion, but has a slight wavering of the instantaneous frequency of some harmonics, as seen in the color change in harmonic stripes (G). In contrast, the baseline lacks the structure in phase to maintain the punchy character of the original note, and produces a duller sound that is slightly out of tune. This is represented in the less brightly colored harmonics due to phase noise (H).\n\nThe flugelhorn displays perhaps the starkest difference between the two models. The sound combines rich harmonics (many lines), non-tonal wind and lip noise (background color), and vibrato -oscillation of pitch that results in a corresponding rainbow of color in all of the harmonics. While the WaveNet autoencoder does not replicate the exact trace of the vibrato (I), it creates a very similar rainbowgram with oscillations in the instantaneous frequency at all levels synced across the harmonics (J). This results in a rich and natural sounding reconstruction with all three aspects of the original sound. The baseline, by comparison, is unable to model such structure. It creates a more or less correct harmonic series, but the phase has lots of random perturbations. Visually this shows up as colors which are faded and speckled with rainbow noise (K), which contrasts with the bright colors of the original and WaveNet examples. Acoustically, this manifests as an unappealing buzzing sound laid over an inexpressive and consistent series of harmonics. The WaveNet model also produces a few inaudible discontinuities visually evidenced by the vertical rainbow spikes (L).\n\n\nQuantitative Comparison\n\nInspired by the use of the Inception Score for images , we train a multi-task classification network to perform a quantitative comparison of the model reconstructions by predicting pitch and quality labels on the NSynth dataset (details in the Appendix). The network configuration is the same as the baseline encoder and testing is done on reconstructions of a randomly chosen subset of 4096 examples from the held-out set. The results in Table 1 confirm our qualititive observation that the WaveNet reconstructions are of superior quality. The classifier is \u223c70% more successful at extracting pitch from the reconstructed WaveNet samples than the baseline and several points higher for predicting quality information, giving an accuracy roughly equal to the original audio.\n\n\nInterpolation in Timbre and Dynamics\n\nGiven the limited factors of variation in the dataset, we know that a successful embedding space (Z) should span the range of timbre and dynamics in its reconstructions. In Figure 3, we show reconstructions from linear interpolations (0.5:0.5) in the Z space among three different instruments and additionally compare these to interpolations in the original audio space. The latter are simple super-positions of the individual instruments' rainbowgrams. This is perceptually equivalent to the two instruments being played at the same time.\n\nIn contrast, we find that the generative models fuse aspects of the instruments. As we saw in Section 4.1, the WaveNet autoencoder models the data much more realistically than the baseline, so it is no surprise that it also learns a manifold of codes that yield more perceptually interesting reconstructions.\n\nFor example, in the interpolated note between the bass and flute (Figure 3, column 2), we can hear and see that both the baseline and WaveNet models blend the harmonic structure of the two instruments while imposing the amplitude envelope of the bass note onto the upper harmonics of the flute note. However, the WaveNet model goes beyond this to create a dynamic mixing of the overtones in time, even jumping to a higher harmonic at the end of the note (A). This sound captures expressive aspects of the timbre and dynamics of both the bass and flute, but is distinctly separate from either original note. This contrasts with the interpolation in audio space, where the dynamics and timbre of the two notes is independent. The baseline model also introduces phase distortion similar to those in the reconstructions of the bass and flute.\n\nWe see this phenomenon again in the interpolation between flute and organ (Figure 3, column 4). Both models also seem to create new harmonic structure, rather than just overlay the original harmonics. The WaveNet model adds additional harmonics as well as a sub-harmonic to the original flute note, all while preserving phase relationships (B). The resulting sound has the breathiness of a flute, with the upper frequency modulation of an organ. By contrast, the lack of phase structure in the baseline leads to a new harmonic yet dull sound lacking a unique character.\n\nThe WaveNet model additionally has a tendency to exaggerate amplitude modulation behavior, while the baseline suppresses it. If we examine the original organ sound (Figure 3, column 5), we can see a subtle modulation signified by the blue harmonics periodically fading to black (C). The baseline model misses this behavior completely as it is washed out. Conversely, the WaveNet model amplifies the behavior, adding in new harmonics not present in the original note and modulating all the harmonics. This is seen in the figure by four vertical black stripes that align with the four modulations of the original signal (D).\n\n\nEntanglement of Pitch and Timbre\n\nBy conditioning on pitch during training, we hypothesize that we should be able to generate multiple pitches from a single Z vector that preserve the identity of timbre and dynamics. Our initial attempts were unsuccessful, as it seems our models had learned to ignore the conditioning variable. We investigate this further with classification and correlation studies. \n\n\nPitch Classification from Z\n\nOne way to study the entanglement of pitch and Z is to consider the pitch classification accuracy from embeddings. If training with pitch conditioning disentangles the representation of pitch and timbre, then we would expect a linear pitch classifier trained on the embeddings to drop in accuracy. To test this, we train a series of baseline autoencoder models with different embedding sizes, both with and without pitch conditioning. For each model, we then train a logistic regression pitch classifier on its embeddings and test on a random sample of 4096 held-out embeddings.\n\nThe first two rows of Table 2 demonstrate that the baseline and WaveNet models decrease in classification accuracy by 13-30% when adding pitch conditioning during training. This is indicative a reduced presence of pitch information in the latent code and thus a decoupling of pitch and timbre information. Further, as the total embedding size decreases below 512, the accuracy drop becomes much more pronounced, reaching a 75% relative decrease. This is likely due to the greater expressivity of larger embeddings, where there is less to be gained from utilizing the pitch conditioning. However, as the embedding size decreases, so too does reconstruction quality. This is more pronounced for the WaveNet models, which have farther to fall in terms of sample quality.\n\nAs a proof of principle, we find that for a baseline model with an embedding size of 128, we are able to successfully balance reconstruction quality and response to conditioning. Figure 4 demonstrates two octaves of a C major chord created from a single embedding of an electric piano note, but conditioned on different pitches. The resulting harmonic structure of the original note is only partially preserved across the range. As we shift the pitch upwards, a sub-harmonic emerges (A) such that the pitch +12 note is similar to the original except that the harmonics of the octave are accentuated in amplitude. This aligns with our pitch classification results, where we find that pitches are most commonly confused with those one octave away (see Appendix). These errors can account for as much as 20% absolute classification error.\n\n\nZ Correlation across Pitch\n\nWe can gain further insight into the relationship between timbre and pitch by examining the correlation of WaveNet embeddings among pitches for a given instrument. Figure 5 shows correlations for several instruments across their entire 88 note range at velocity 127. We see that each instrument has a unique partitioning into two or more registers over which notes of different pitches have similar embeddings. Even the average over all instruments shows a broad distinction between high and low registers. On reflection, this is unsurprising as the timbre and dynamics of an instrument can vary dramatically across its range.\n\n\nGeneralization of Temporal Encodings\n\nThe WaveNet autoencoder model has some unique properties that allow it to generalize to situations not in the dataset. Since the model learns embeddings that bias an autoregressive decoder, they effectively act as a \"driving function\" for a nonlinear oscillator / infinite impulse response filter. This is made clear by Figure 6, where the embeddings follow a magnitude contour similar to that of the rainbowgrams of their corresponding sounds in Figures 2 and 3.\n\nFurther, much like a spectrogram, the embeddings only capture a local context. This lets them gener-alize in time. The model has only ever seen single notes with sound that lasts for up to three seconds, and yet Figure 7 demonstrates that it can successfully reconstruct both a whole series of notes, as well as notes played for longer than three seconds. While the WaveNet autoencoder adds more harmonics to the original timbre of the organ instrument, it follows the fundamental frequency as it plays up two octaves of a C major arpeggio, back down a G dominant arrpeggio, and holds for several seconds on the base note. The fact that it has never seen a transition between two notes is clear, as the fundamental frequency actually glissandos smoothly between new notes.\n\n\nConclusion and Future Directions\n\nIn this paper, we have introduced a WaveNet autoencoder model that captures long term structure without the need for external conditioning and demonstrated its effectiveness on the new NSynth dataset for generative modeling of audio.\n\nThe WaveNet autoencoder that we describe is a powerful representation for which there remain multiple avenues of exploration. It builds upon the fine-grained local understanding of the original WaveNet work and provides access to a useful hidden space. However, due to memory constraints, it is unable to fully capture global context. Overcoming this limitation is an important open problem.\n\nNSynth was inspired by image recognition datasets that have been core to recent progress in deep learning. Similar to how many image datasets focus on a single object per example, NSynth hones in on a single note. Indeed, much modern music production employs such a factorization, using MIDI for note sequences and software synthesizers for timbre. Noteto-note dependencies can be partly restored by passing sequence-level timbre and dynamics information to the note-level synthesizer. While not perfect, this factorization is based on the physics of many instruments and is surprisingly effective.\n\nWe encourage the broader community to use NSynth as a benchmark and entry point into audio machine learning. We also view NSynth as a building block for future datasets and envision a high-quality multi-note dataset for tasks like generation and transcription that involve learning complex language-like dependencies. \n\n\nAppendices A. Phase Representation for the Baseline Model\n\nWe explored several audio representations for our baseline model. Each representation uses an MSE cost and always includes the magnitude of the STFT spectrogram. We found that training on the peak-normalized log magnitude of the power spectra correlated better with perceptual distortion. When using phase in teh objective, we regress on the phase angle. We can assume a circular normal distribution (Bishop, 2006) for the phase with a log likelihood loss proportional to cos(\u03c0 * (x \u2212x)). Figure 8 shows CQT spectrograms of reconstructions of a trumpet sound from models trained on each input representation. We also include audio of each reconstruction, which is essential listening to hear the improvement of the perceptual weighting.\n\n\nB. Description of Quality Tags\n\nWe provide quality annotations for the 10 different note qualities described below. None of the tags are mutually exclusive by definition except for Bright and Dark. However, it is possible for a note to be neither Bright nor Dark.\n\n\u2022 Bright: A large amount of high frequency content and strong upper harmonics.\n\n\u2022 Dark: A distinct lack of high frequency content, giving a muted and bassy sound. Also sometimes described as 'Warm'.\n\n\u2022 Distortion: Waveshaping that produces a distinctive crunchy sound and presence of many harmonics. Sometimes paired with non-harmonic noise.\n\n\u2022 Fast Decay: Amplitude envelope of all harmonics decays substantially before the 'note-off' point at 3 seconds.\n\n\u2022 Long Release: Amplitude envelope decays slowly after the 'note-off' point, sometimes still present at the end of the sample at 4 seconds.\n\n\u2022 Multiphonic: Presence of overtone frequencies related to more than one fundamental frequency.\n\n\u2022 Non-Linear Envelope: Modulation of the sound with a distinct envelope behavior different than the monotonic decrease of the note. Can also include filter envelopes as well as dynamic envelopes.\n\n\u2022 Percussive: A loud non-harmonic sound at note onset.\n\n\u2022 Reverb: Room acoustics that were not able to be removed from the original sample.\n\n\u2022 Tempo-Synced: Rhythmic modulation of the sound to a fixed tempo.\n\n\nC. Details of Pitch and Quality Classifier\n\nWe train a multi-task classification model to do pitch and quality tag classification on the entire NSynth dataset. We use the the encoder structure from the baseline model with the exception that there is no bottleneck (see Figure 10). We use a softmax-crossentropy loss for the pitch labels as they are mutually exclusive and a sigmoid-crossentropy loss for the quality tags as they are not. Note that since the architecture uses only magnitude spectra, it cannot take advantage of the improved phase coherence of the WaveNet samples.    Figure 9. Confusion matrix for linear pitch classification model trained on embeddings from a WaveNet autoencoder. The prodominant error is predicting the wrong octave (being off by 12 tones). Training with pitch conditioning reduces the classifer accuracy.\n\nNeural Audio Synthesis of Musical Notes with WaveNet Autoencoders Figure 10. Model architecture for pitch and quality classification. Like the baseline encoder, each convolution layer is followed by batch normalization and a Leaky-ReLU (0.1 off-slope).\n\nFigure 1 .\n1Models considered in this paper. For both models, we optionally condition on pitch by concatenating the hidden embedding with a one-hot pitch representation. 1a. Baseline spectral autoencoder: Each block represents a nonlinear 2-D convolution with stride (s), kernel size (k), and channels (#). 1b. The WaveNet autoencoder: Downsampling in the encoder occurs only in the average pooling layer. The embeddings are distributed in time and upsampled with nearest neighbor interpolation to the original resolution before biasing each layer of the decoder. 'NC' indicates non-causal convolution. '1x1' indicates a 1-D convolution with kernel size 1. See Section 2.1 for further details.\n\nFigure 2 .\n2Reconstructions of notes from three different instruments. Each note is displayed as a \"Rainbowgram\", a CQT spectrogram with intensity of lines proportional to the log magnitude of the power spectrum and color given by the derivative of the phase. Time is on the horizontal axis and frequency on the vertical axis. See Section 4.1 for details. (Listen: Glockenspiel (O, W, B), Electric Piano (O, W, B), Flugelhorn (O, W, B))\n\nFigure 3 .\n3Rainbowgrams of linear interpolations between three different notes from instruments in the holdout set. For the original rainbowgrams, the raw audio is linearly mixed. For the models, samples are generated from linear interpolations in embedding space. See Section 4.2 for details.(Listen: Original (B, BF, F, FO, O, OB), WaveNet (B, BF, F, FO, O, OB), Baseline (B, BF, F, FO, O, OB))\n\nFigure 4 .Figure 5 .\n45Conditioning on pitch. These rainbowgrams are reconstructions of a single electric piano note from the holdout set. They were synthesized with the baseline model (128 hidden dimensions). By holding Z constant and conditioning on different pitches, we can play two octaves of a C major chord from a single embedding. The original pitch (MIDI C60) is dashed in white for comparison. See Section 4.3.1 for details. (Listen: -12, -8, -5, 0, +4, +7, +12) Correlation of embeddings across pitch for three different instruments and the average across all instruments. These embeddings were taken from a WaveNet model trained without pitch conditioning.\n\nFigure 6 .\n6Temporal embeddings for three different instruments. The different colors represent the 16 different dimensions of the embeddings for 125 timesteps (each 32ms). Note that the embedding have a contour similar to the magnitude contour of the original note and decay close to zero when there is no sound. With this in mind, they can be thought of as a \"driving function\" for a nonlinear oscillator / infinite impulse response filter.\n\nFigure 7 .\n7Rainbowgrams of a series of notes reconstructed by the WaveNet autoencoder. The model was never trained on more than one note at a time or on clips longer than four seconds, but it does a fair job of reconstructing this ten-second long scale. (Listen: Original, Reconstruction)\n\nFigure 8 .\n8Reconstructions from baseline models trained with different phase representations. For Griffin-Lim, only the magnitude is modeled, and an 1000 iterations of an iterative technique is used to estimate the phase. (Listen: Original, Griffin-Lim Perceptual Weighting, Griffin-Lim, Phase Derivative, Phase)\n\nTable 1 .\n1Classification accuracy of a deep nonlinear pitch and quality classifier on reconstructions of a test set.Pitch Quality \n\nOriginal Audio \n91.6% \n90.1% \nWaveNet Recon 79.6% \n88.9% \nBaseline Recon \n46.9% \n85.2% \n\n\n\nTable 2 .\n2Classification accuracy (in percentage) of a linear \npitch classifier trained on learned embeddings. The decou-\npling of pitch and embedding becomes more pronounced \nat smaller embedding sizes as shown by the larger relative \ndecrease in classification accuracy. \n\nZ \nNo Pitch Pitch Relative \nSize \nCond. \nCond. \nChange \n\nWaveNet 1984 \n58.1 \n40.5 \n-30.4 \nBaseline \n1984 \n63.8 \n55.2 \n-13.5 \nBaseline \n1024 \n57.4 \n42.1 \n-26.7 \nBaseline \n512 \n63.2 \n21.8 \n-65.5 \nBaseline \n256 \n57.7 \n21.0 \n-63.6 \nBaseline \n128 \n58.2 \n21.2 \n-63.6 \nBaseline \n64 \n59.8 \n15.2 \n-74.6 \n\n\n\n\nStacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. Journal of Machine Learning Research, 11(Dec):3371-3408, 2010. White, Tom. Sampling generative networks: Notes on a few effective techniques. CoRR, abs/1609.04468, 2016. URL http://arxiv.org/abs/1609.04468. Xenakis, Iannis. Formalized music. 1971.\n\nTable 3 .\n3Instrument annotations. Instruments are labeled with both a source and a family. The source denotes how each instrument's notes are generated: acoustic instrument, electronic instrument, or by software synthesis. The family denotes a high-level class for each instrument.Source \nFamily \nAcoust Electr Synth \nTotal \n\nBass \n200 \n8387 \n60 368 \n68 955 \nBrass \n13 760 \n70 \n0 \n13 830 \nFlute \n6572 \n70 \n2816 \n9458 \nGuitar \n13 343 \n16 805 \n5275 \n35 423 \nKeyboard \n8508 \n42 709 \n3838 \n55 055 \nMallet \n27 722 \n5581 \n1763 \n35 066 \nOrgan \n176 \n36 401 \n0 \n36 577 \nReed \n14 262 \n76 \n528 \n14 866 \nString \n20 510 \n84 \n0 \n20 594 \nSynth Lead 0 \n0 \n5501 \n5501 \nVocal \n3925 \n140 \n6688 \n10 753 \n\nTotal \n108 978 110 224 86 777 \n306 043 \n\n\n\nTable 4 .\n4Co-occurrence probabilities and marginal frequencies of quality annotations. Both are presented as percentages.Quality \nBright \nDark \nDistortion \n\nFast Decay \nLong Release \nMultiphonic \nNonlinear Env \nPercussive \n\nReverb \nTempo-Synced \n\nDark \n0.0 \nDistortion \n25.9 \n2.5 \nFast Decay \n10.0 \n7.5 \n8.1 \nLong Release \n9.0 \n5.2 \n9.8 \n0.0 \nMultiphonic \n6.0 \n1.5 \n5.4 \n2.8 \n6.9 \nNonlinear Env \n8.5 \n1.4 \n6.6 \n2.1 \n6.7 \n8.6 \nPercussive \n6.2 \n5.1 \n3.0 \n52.0 \n0.8 \n2.4 0.9 \nCo-occurrence \n\nReverb \n6.6 \n8.9 \n0.3 \n13.0 13.7 0.7 3.5 12.4 \nTempo-Synced \n2.4 \n1.8 \n5.2 \n0.4 \n6.4 \n9.3 2.3 \n1.5 \n0.0 \n\nFrequency \n13.5 11.0 17.0 14.7 \n8.5 \n3.4 3.2 10.2 16.8 1.8 \n\n\nThis size was aligned with a WaveNet autoencoder that had a pooling stride of 1024 and a 62x32 embedding.\nMIDI velocity is similar to volume control and they have a direct relationship. For physical intuition, higher velocity corresponds to pressing a piano key harder.\n\nThe million song dataset. Bertin-Mahieux, Ellis Thierry, P W Daniel, Brian Whitman, Paul Lamere, ISMIR. 210Bertin-Mahieux, Thierry, Ellis, Daniel PW, Whitman, Brian, and Lamere, Paul. The million song dataset. In ISMIR, volume 2, pp. 10, 2011.\n\nPattern Recognition and Machine Learning (Information Science and Statistics). Christopher M Bishop, Bishop, Christopher M. Pattern Recognition and Ma- chine Learning (Information Science and Statistics).\n\nEstimating and interpreting the instantaneous frequency of a signal. i. fundamentals. Boualem Boashash, Proceedings of the IEEE. the IEEE80Boashash, Boualem. Estimating and interpreting the instantaneous frequency of a signal. i. fundamentals. Proceedings of the IEEE, 80(4):520-538, 1992.\n\nCalculation of a constant q spectral transform. Judith C Brown, The Journal of the Acoustical Society of America. 891Brown, Judith C. Calculation of a constant q spectral transform. The Journal of the Acoustical Society of America, 89(1):425-434, 1991.\n\n. Xi Chen, Kingma, P Diederik, Salimans, Tim, Duan, Yan, Prafulla, Schulman, John, Ilya Sutskever, Pieter Abbeel, abs/1611.02731Variational lossy autoencoder. CoRRChen, Xi, Kingma, Diederik P., Salimans, Tim, Duan, Yan, Dhariwal, Prafulla, Schulman, John, Sutskever, Ilya, and Abbeel, Pieter. Variational lossy autoencoder. CoRR, abs/1611.02731, 2016. URL http://arxiv.org/abs/1611.02731.\n\nThe synthesis of complex audio spectra by means of frequency modulation. John M Chowning, 21Journal of the audio engineering societyChowning, John M. The synthesis of complex audio spectra by means of frequency modulation. Jour- nal of the audio engineering society, 21(7):526-534, 1973.\n\nImageNet: A Large-Scale Hierarchical Image Database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, CVPR09. Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09, 2009.\n\nGenerative adversarial nets. Ian Goodfellow, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Warde - Bing, Farley, David, Ozair, Sherjil, Aaron Courville, Yoshua Bengio, Advances in neural information processing systems. Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua. Generative adversarial nets. In Advances in neural information processing systems, pp. 2672-2680, 2014.\n\nRwc music database: Music genre database and musical instrument sound database. Masataka Goto, Hashiguchi, Hiroki, Takuichi Nishimura, Ryuichi Oka, Goto, Masataka, Hashiguchi, Hiroki, Nishimura, Takuichi, and Oka, Ryuichi. Rwc music database: Music genre database and musical instrument sound database. 2003.\n\nSignal estimation from modified short-time fourier transform. Daniel Griffin, Jae Lim, IEEE Transactions on Acoustics, Speech, and Signal Processing. 322Griffin, Daniel and Lim, Jae. Signal estimation from modified short-time fourier transform. IEEE Trans- actions on Acoustics, Speech, and Signal Processing, 32(2):236-243, 1984.\n\nPixelvae: A latent variable model for natural images. Gulrajani, Ishaan, Kumar, Kundan, Ahmed, Faruk, Adrien Taiga, Ali, Visin, Francesco, David V\u00e1zquez, Aaron C Courville, abs/1611.05013CoRRGulrajani, Ishaan, Kumar, Kundan, Ahmed, Faruk, Taiga, Adrien Ali, Visin, Francesco, V\u00e1zquez, David, and Courville, Aaron C. Pixelvae: A la- tent variable model for natural images. CoRR, abs/1611.05013, 2016. URL http://arxiv.org/ abs/1611.05013.\n\nMinst, a collection of musical sound datasets. Eric J Humphrey, Humphrey, Eric J. Minst, a collection of musical sound datasets, 2016. URL https://github.com/ ejhumphrey/minst-dataset/.\n\nBatch normalization: Accelerating deep network training by reducing internal covariate shift. Sergey Ioffe, Christian Szegedy, abs/1502.03167CoRRIoffe, Sergey and Szegedy, Christian. Batch normaliza- tion: Accelerating deep network training by reduc- ing internal covariate shift. CoRR, abs/1502.03167, 2015. URL http://arxiv.org/abs/1502.03167.\n\nThe blizzard challenge. Simon King, Clark Robert, A J Mayo, Catherine Karaiskos, Vasilis , King, Simon, Clark, Robert AJ, Mayo, Catherine, and Karaiskos, Vasilis. The blizzard challenge 2008. 2008.\n\nAdam: A method for stochastic optimization. CoRR, abs/1412. Diederik P Kingma, Jimmy Ba, 6980Kingma, Diederik P. and Ba, Jimmy. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014. URL http://arxiv.org/ abs/1412.6980.\n\nDiederik P Kingma, Max Welling, arXiv:1312.6114Auto-encoding variational bayes. arXiv preprintKingma, Diederik P and Welling, Max. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, Krizhevsky, Alex and Hinton, Geoffrey. Learning mul- tiple layers of features from tiny images. 2009.\n\nThe mnist database of handwritten digits. Yann Lecun, Corinna Cortes, Burges, J C Christopher, LeCun, Yann, Cortes, Corinna, and Burges, Christo- pher JC. The mnist database of handwritten digits, 1998.\n\nSound texture synthesis via filter statistics. Josh H Mcdermott, Oxenham, J Andrew, Simoncelli, P Eero, Applications of Signal Processing to Audio and Acoustics, 2009. WASPAA'09. IEEE Workshop on. IEEEMcDermott, Josh H, Oxenham, Andrew J, and Si- moncelli, Eero P. Sound texture synthesis via fil- ter statistics. In Applications of Signal Processing to Audio and Acoustics, 2009. WASPAA'09. IEEE Workshop on, pp. 297-300. IEEE, 2009.\n\nSamplernn: An unconditional end-to-end neural audio generation model. Mehri, Soroush, Kumar, Kundan, Gulrajani, Ishaan, Kumar, Rithesh, Jain, Shubham, Jose Sotelo, Aaron C Courville, Yoshua Bengio, abs/1612.07837CoRRMehri, Soroush, Kumar, Kundan, Gulrajani, Ishaan, Kumar, Rithesh, Jain, Shubham, Sotelo, Jose, Courville, Aaron C., and Bengio, Yoshua. Sam- plernn: An unconditional end-to-end neural audio generation model. CoRR, abs/1612.07837, 2016. URL http://arxiv.org/abs/1612.07837.\n\nReading digits in natural images with unsupervised feature learning. Yuval Netzer, Wang, Tao, Coates, Adam, Alessandro Bissacco, Bo Wu, Andrew Y Ng, NIPS workshop on deep learning and unsupervised feature learning. 2011Netzer, Yuval, Wang, Tao, Coates, Adam, Bissacco, Alessandro, Wu, Bo, and Ng, Andrew Y. Reading digits in natural images with unsupervised feature learning. In NIPS workshop on deep learning and unsupervised feature learning, volume 2011, pp. 5, 2011.\n\nAnalog days: The invention and impact of the Moog synthesizer. Trevor J Pinch, Frank Trocco, T J Pinch, Harvard University PressPinch, Trevor J, Trocco, Frank, and Pinch, TJ. Analog days: The invention and impact of the Moog synthe- sizer. Harvard University Press, 2009.\n\nGiorgio by morodor. Daft Punk, Punk, Daft. Giorgio by morodor, 2014. URL https: //www.youtube.com/watch?v=zhl-Cs1-sG4.\n\nLearning-Based Methods for Comparing Sequences, with Applications to Audio-to-MIDI Alignment and Matching. Colin Raffel, COLUMBIA UNIVERSITYPhD thesisRaffel, Colin. Learning-Based Methods for Compar- ing Sequences, with Applications to Audio-to-MIDI Alignment and Matching. PhD thesis, COLUMBIA UNIVERSITY, 2016.\n\nA real-time system for measuring sound goodness in instrumental sounds. Romani Picas, Parra Oriol, Rodriguez, Hector, Dabiri, Dara, Tokuda, Hiroshi, Hariya, Wataru, Koji Oishi, Xavier Serra, Audio Engineering Society Convention 138. Audio Engineering Society. Romani Picas, Oriol, Parra Rodriguez, Hector, Dabiri, Dara, Tokuda, Hiroshi, Hariya, Wataru, Oishi, Koji, and Serra, Xavier. A real-time system for measuring sound goodness in instrumental sounds. In Audio Engineering Society Convention 138. Audio Engi- neering Society, 2015.\n\n. Tim Salimans, Ian J Goodfellow, Zaremba, Wojciech, Cheung, Vicki, Alec Radford, Xi Chen, Improved techniques for training gans. CoRR, abs/1606.03498Salimans, Tim, Goodfellow, Ian J., Zaremba, Wo- jciech, Cheung, Vicki, Radford, Alec, and Chen, Xi. Improved techniques for training gans. CoRR, abs/1606.03498, 2016. URL http://arxiv.org/ abs/1606.03498.\n\nMusical audio synthesis using autoencoding neural nets. Andy M Sarroff, Michael A Casey, ICMC. Sarroff, Andy M and Casey, Michael A. Musical audio synthesis using autoencoding neural nets. In ICMC, 2014.\n\nA note on the evaluation of generative models. Lucas Theis, A\u00e4ron Oord, Van Den, Matthias Bethge, arXiv:1511.01844arXiv preprintTheis, Lucas, Oord, A\u00e4ron van den, and Bethge, Matthias. A note on the evaluation of generative models. arXiv preprint arXiv:1511.01844, 2015.\n\nLearning features of music from scratch. John Thickstun, Zaid Harchaoui, Kakade, Sham ; Van Den Oord, A\u00e4ron, Dieleman, Sander, Zen, Heiga, Simonyan, Karen, Vinyals, Oriol, Alex Graves, Kalchbrenner, Nal, Andrew W Senior, Koray Kavukcuoglu, abs/1609.03499Wavenet: A generative model for raw. preprintThickstun, John, Harchaoui, Zaid, and Kakade, Sham. Learning features of music from scratch. In preprint, https: // arxiv. org/ abs/ 1611. 09827 , 2016. van den Oord, A\u00e4ron, Dieleman, Sander, Zen, Heiga, Simonyan, Karen, Vinyals, Oriol, Graves, Alex, Kalchbrenner, Nal, Senior, Andrew W., and Kavukcuoglu, Koray. Wavenet: A generative model for raw audio. CoRR, abs/1609.03499, 2016a. URL http://arxiv.org/abs/1609.03499.\n\nPixel recurrent neural networks. CoRR, abs/1601.06759. Van Den Oord, A\u00e4ron, Nal Kalchbrenner, Koray Kavukcuoglu, van den Oord, A\u00e4ron, Kalchbrenner, Nal, and Kavukcuoglu, Koray. Pixel recurrent neural net- works. CoRR, abs/1601.06759, 2016b. URL http: //arxiv.org/abs/1601.06759.\n\n. Pascal Vincent, Larochelle, Hugo, Lajoie, Isabelle, Yoshua Bengio, Pierre-Antoine Manzagol, Vincent, Pascal, Larochelle, Hugo, Lajoie, Isabelle, Bengio, Yoshua, and Manzagol, Pierre-Antoine.\n", "annotations": {"author": "[{\"end\":81,\"start\":69},{\"end\":97,\"start\":82},{\"end\":111,\"start\":98},{\"end\":128,\"start\":112},{\"end\":141,\"start\":129},{\"end\":157,\"start\":142},{\"end\":175,\"start\":158},{\"end\":81,\"start\":69},{\"end\":97,\"start\":82},{\"end\":111,\"start\":98},{\"end\":128,\"start\":112},{\"end\":141,\"start\":129},{\"end\":157,\"start\":142},{\"end\":175,\"start\":158}]", "publisher": null, "author_last_name": "[{\"end\":80,\"start\":75},{\"end\":96,\"start\":89},{\"end\":110,\"start\":103},{\"end\":127,\"start\":119},{\"end\":140,\"start\":137},{\"end\":156,\"start\":148},{\"end\":174,\"start\":167},{\"end\":80,\"start\":75},{\"end\":96,\"start\":89},{\"end\":110,\"start\":103},{\"end\":127,\"start\":119},{\"end\":140,\"start\":137},{\"end\":156,\"start\":148},{\"end\":174,\"start\":167}]", "author_first_name": "[{\"end\":74,\"start\":69},{\"end\":88,\"start\":82},{\"end\":102,\"start\":98},{\"end\":118,\"start\":112},{\"end\":136,\"start\":129},{\"end\":147,\"start\":142},{\"end\":166,\"start\":158},{\"end\":74,\"start\":69},{\"end\":88,\"start\":82},{\"end\":102,\"start\":98},{\"end\":118,\"start\":112},{\"end\":136,\"start\":129},{\"end\":147,\"start\":142},{\"end\":166,\"start\":158}]", "author_affiliation": null, "title": "[{\"end\":66,\"start\":1},{\"end\":241,\"start\":176},{\"end\":66,\"start\":1},{\"end\":241,\"start\":176}]", "venue": null, "abstract": "[{\"end\":1167,\"start\":243},{\"end\":1167,\"start\":243}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b21\"},\"end\":1684,\"start\":1664},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1857,\"start\":1845},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2089,\"start\":2073},{\"end\":2103,\"start\":2089},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2908,\"start\":2889},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2943,\"start\":2923},{\"end\":3560,\"start\":3534},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3588,\"start\":3567},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3622,\"start\":3596},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3656,\"start\":3637},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3735,\"start\":3715},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4102,\"start\":4088},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4130,\"start\":4102},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4148,\"start\":4130},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4171,\"start\":4148},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4356,\"start\":4333},{\"end\":4380,\"start\":4356},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4522,\"start\":4506},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5727,\"start\":5699},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6185,\"start\":6157},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8574,\"start\":8546},{\"end\":9561,\"start\":9539},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9971,\"start\":9948},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11153,\"start\":11132},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11705,\"start\":11686},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12431,\"start\":12412},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12457,\"start\":12431},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15023,\"start\":15010},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15872,\"start\":15856},{\"end\":30234,\"start\":30220},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":1684,\"start\":1664},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1857,\"start\":1845},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2089,\"start\":2073},{\"end\":2103,\"start\":2089},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2908,\"start\":2889},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2943,\"start\":2923},{\"end\":3560,\"start\":3534},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3588,\"start\":3567},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3622,\"start\":3596},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3656,\"start\":3637},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3735,\"start\":3715},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4102,\"start\":4088},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4130,\"start\":4102},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4148,\"start\":4130},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4171,\"start\":4148},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4356,\"start\":4333},{\"end\":4380,\"start\":4356},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4522,\"start\":4506},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5727,\"start\":5699},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6185,\"start\":6157},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8574,\"start\":8546},{\"end\":9561,\"start\":9539},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9971,\"start\":9948},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11153,\"start\":11132},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11705,\"start\":11686},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12431,\"start\":12412},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12457,\"start\":12431},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15023,\"start\":15010},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15872,\"start\":15856},{\"end\":30234,\"start\":30220}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33716,\"start\":33022},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34154,\"start\":33717},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34553,\"start\":34155},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35223,\"start\":34554},{\"attributes\":{\"id\":\"fig_4\"},\"end\":35667,\"start\":35224},{\"attributes\":{\"id\":\"fig_5\"},\"end\":35958,\"start\":35668},{\"attributes\":{\"id\":\"fig_6\"},\"end\":36273,\"start\":35959},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":36497,\"start\":36274},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":37071,\"start\":36498},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":37437,\"start\":37072},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38166,\"start\":37438},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":38825,\"start\":38167},{\"attributes\":{\"id\":\"fig_0\"},\"end\":33716,\"start\":33022},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34154,\"start\":33717},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34553,\"start\":34155},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35223,\"start\":34554},{\"attributes\":{\"id\":\"fig_4\"},\"end\":35667,\"start\":35224},{\"attributes\":{\"id\":\"fig_5\"},\"end\":35958,\"start\":35668},{\"attributes\":{\"id\":\"fig_6\"},\"end\":36273,\"start\":35959},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":36497,\"start\":36274},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":37071,\"start\":36498},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":37437,\"start\":37072},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38166,\"start\":37438},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":38825,\"start\":38167}]", "paragraph": "[{\"end\":1858,\"start\":1183},{\"end\":2429,\"start\":1860},{\"end\":2519,\"start\":2431},{\"end\":2660,\"start\":2521},{\"end\":2748,\"start\":2662},{\"end\":3879,\"start\":2750},{\"end\":4381,\"start\":3881},{\"end\":4628,\"start\":4383},{\"end\":5200,\"start\":4630},{\"end\":5640,\"start\":5233},{\"end\":5949,\"start\":5642},{\"end\":6318,\"start\":5990},{\"end\":6622,\"start\":6320},{\"end\":6998,\"start\":6670},{\"end\":7232,\"start\":7000},{\"end\":7547,\"start\":7234},{\"end\":8176,\"start\":7549},{\"end\":8997,\"start\":8178},{\"end\":9346,\"start\":8999},{\"end\":10152,\"start\":9381},{\"end\":10748,\"start\":10154},{\"end\":11597,\"start\":10750},{\"end\":12080,\"start\":11610},{\"end\":12562,\"start\":12103},{\"end\":13327,\"start\":12593},{\"end\":13491,\"start\":13343},{\"end\":13740,\"start\":13493},{\"end\":13904,\"start\":13742},{\"end\":14071,\"start\":13906},{\"end\":14406,\"start\":14088},{\"end\":14543,\"start\":14421},{\"end\":14918,\"start\":14545},{\"end\":15553,\"start\":14920},{\"end\":16418,\"start\":15555},{\"end\":17052,\"start\":16437},{\"end\":17422,\"start\":17054},{\"end\":17824,\"start\":17424},{\"end\":18714,\"start\":17826},{\"end\":19892,\"start\":18716},{\"end\":20694,\"start\":19920},{\"end\":21274,\"start\":20735},{\"end\":21584,\"start\":21276},{\"end\":22424,\"start\":21586},{\"end\":22995,\"start\":22426},{\"end\":23619,\"start\":22997},{\"end\":24024,\"start\":23656},{\"end\":24634,\"start\":24056},{\"end\":25403,\"start\":24636},{\"end\":26240,\"start\":25405},{\"end\":26897,\"start\":26271},{\"end\":27401,\"start\":26938},{\"end\":28175,\"start\":27403},{\"end\":28445,\"start\":28212},{\"end\":28838,\"start\":28447},{\"end\":29438,\"start\":28840},{\"end\":29758,\"start\":29440},{\"end\":30556,\"start\":29820},{\"end\":30822,\"start\":30591},{\"end\":30902,\"start\":30824},{\"end\":31022,\"start\":30904},{\"end\":31165,\"start\":31024},{\"end\":31279,\"start\":31167},{\"end\":31420,\"start\":31281},{\"end\":31517,\"start\":31422},{\"end\":31714,\"start\":31519},{\"end\":31770,\"start\":31716},{\"end\":31855,\"start\":31772},{\"end\":31923,\"start\":31857},{\"end\":32767,\"start\":31970},{\"end\":33021,\"start\":32769},{\"end\":1858,\"start\":1183},{\"end\":2429,\"start\":1860},{\"end\":2519,\"start\":2431},{\"end\":2660,\"start\":2521},{\"end\":2748,\"start\":2662},{\"end\":3879,\"start\":2750},{\"end\":4381,\"start\":3881},{\"end\":4628,\"start\":4383},{\"end\":5200,\"start\":4630},{\"end\":5640,\"start\":5233},{\"end\":5949,\"start\":5642},{\"end\":6318,\"start\":5990},{\"end\":6622,\"start\":6320},{\"end\":6998,\"start\":6670},{\"end\":7232,\"start\":7000},{\"end\":7547,\"start\":7234},{\"end\":8176,\"start\":7549},{\"end\":8997,\"start\":8178},{\"end\":9346,\"start\":8999},{\"end\":10152,\"start\":9381},{\"end\":10748,\"start\":10154},{\"end\":11597,\"start\":10750},{\"end\":12080,\"start\":11610},{\"end\":12562,\"start\":12103},{\"end\":13327,\"start\":12593},{\"end\":13491,\"start\":13343},{\"end\":13740,\"start\":13493},{\"end\":13904,\"start\":13742},{\"end\":14071,\"start\":13906},{\"end\":14406,\"start\":14088},{\"end\":14543,\"start\":14421},{\"end\":14918,\"start\":14545},{\"end\":15553,\"start\":14920},{\"end\":16418,\"start\":15555},{\"end\":17052,\"start\":16437},{\"end\":17422,\"start\":17054},{\"end\":17824,\"start\":17424},{\"end\":18714,\"start\":17826},{\"end\":19892,\"start\":18716},{\"end\":20694,\"start\":19920},{\"end\":21274,\"start\":20735},{\"end\":21584,\"start\":21276},{\"end\":22424,\"start\":21586},{\"end\":22995,\"start\":22426},{\"end\":23619,\"start\":22997},{\"end\":24024,\"start\":23656},{\"end\":24634,\"start\":24056},{\"end\":25403,\"start\":24636},{\"end\":26240,\"start\":25405},{\"end\":26897,\"start\":26271},{\"end\":27401,\"start\":26938},{\"end\":28175,\"start\":27403},{\"end\":28445,\"start\":28212},{\"end\":28838,\"start\":28447},{\"end\":29438,\"start\":28840},{\"end\":29758,\"start\":29440},{\"end\":30556,\"start\":29820},{\"end\":30822,\"start\":30591},{\"end\":30902,\"start\":30824},{\"end\":31022,\"start\":30904},{\"end\":31165,\"start\":31024},{\"end\":31279,\"start\":31167},{\"end\":31420,\"start\":31281},{\"end\":31517,\"start\":31422},{\"end\":31714,\"start\":31519},{\"end\":31770,\"start\":31716},{\"end\":31855,\"start\":31772},{\"end\":31923,\"start\":31857},{\"end\":32767,\"start\":31970},{\"end\":33021,\"start\":32769}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5989,\"start\":5950},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6669,\"start\":6623},{\"attributes\":{\"id\":\"formula_0\"},\"end\":5989,\"start\":5950},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6669,\"start\":6623}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":20366,\"start\":20359},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24665,\"start\":24658},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":20366,\"start\":20359},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24665,\"start\":24658}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1181,\"start\":1169},{\"attributes\":{\"n\":\"2.\"},\"end\":5209,\"start\":5203},{\"attributes\":{\"n\":\"2.1.\"},\"end\":5231,\"start\":5212},{\"attributes\":{\"n\":\"2.2.\"},\"end\":9379,\"start\":9349},{\"attributes\":{\"n\":\"2.3.\"},\"end\":11608,\"start\":11600},{\"attributes\":{\"n\":\"3.\"},\"end\":12101,\"start\":12083},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12591,\"start\":12565},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13341,\"start\":13330},{\"attributes\":{\"n\":\"3.2.1.\"},\"end\":14086,\"start\":14074},{\"attributes\":{\"n\":\"4.\"},\"end\":14419,\"start\":14409},{\"attributes\":{\"n\":\"4.1.\"},\"end\":16435,\"start\":16421},{\"attributes\":{\"n\":\"4.1.1.\"},\"end\":19918,\"start\":19895},{\"attributes\":{\"n\":\"4.2.\"},\"end\":20733,\"start\":20697},{\"attributes\":{\"n\":\"4.3.\"},\"end\":23654,\"start\":23622},{\"attributes\":{\"n\":\"4.3.1.\"},\"end\":24054,\"start\":24027},{\"attributes\":{\"n\":\"4.3.2.\"},\"end\":26269,\"start\":26243},{\"attributes\":{\"n\":\"4.4.\"},\"end\":26936,\"start\":26900},{\"attributes\":{\"n\":\"5.\"},\"end\":28210,\"start\":28178},{\"end\":29818,\"start\":29761},{\"end\":30589,\"start\":30559},{\"end\":31968,\"start\":31926},{\"end\":33033,\"start\":33023},{\"end\":33728,\"start\":33718},{\"end\":34166,\"start\":34156},{\"end\":34575,\"start\":34555},{\"end\":35235,\"start\":35225},{\"end\":35679,\"start\":35669},{\"end\":35970,\"start\":35960},{\"end\":36284,\"start\":36275},{\"end\":36508,\"start\":36499},{\"end\":37448,\"start\":37439},{\"end\":38177,\"start\":38168},{\"attributes\":{\"n\":\"1.\"},\"end\":1181,\"start\":1169},{\"attributes\":{\"n\":\"2.\"},\"end\":5209,\"start\":5203},{\"attributes\":{\"n\":\"2.1.\"},\"end\":5231,\"start\":5212},{\"attributes\":{\"n\":\"2.2.\"},\"end\":9379,\"start\":9349},{\"attributes\":{\"n\":\"2.3.\"},\"end\":11608,\"start\":11600},{\"attributes\":{\"n\":\"3.\"},\"end\":12101,\"start\":12083},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12591,\"start\":12565},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13341,\"start\":13330},{\"attributes\":{\"n\":\"3.2.1.\"},\"end\":14086,\"start\":14074},{\"attributes\":{\"n\":\"4.\"},\"end\":14419,\"start\":14409},{\"attributes\":{\"n\":\"4.1.\"},\"end\":16435,\"start\":16421},{\"attributes\":{\"n\":\"4.1.1.\"},\"end\":19918,\"start\":19895},{\"attributes\":{\"n\":\"4.2.\"},\"end\":20733,\"start\":20697},{\"attributes\":{\"n\":\"4.3.\"},\"end\":23654,\"start\":23622},{\"attributes\":{\"n\":\"4.3.1.\"},\"end\":24054,\"start\":24027},{\"attributes\":{\"n\":\"4.3.2.\"},\"end\":26269,\"start\":26243},{\"attributes\":{\"n\":\"4.4.\"},\"end\":26936,\"start\":26900},{\"attributes\":{\"n\":\"5.\"},\"end\":28210,\"start\":28178},{\"end\":29818,\"start\":29761},{\"end\":30589,\"start\":30559},{\"end\":31968,\"start\":31926},{\"end\":33033,\"start\":33023},{\"end\":33728,\"start\":33718},{\"end\":34166,\"start\":34156},{\"end\":34575,\"start\":34555},{\"end\":35235,\"start\":35225},{\"end\":35679,\"start\":35669},{\"end\":35970,\"start\":35960},{\"end\":36284,\"start\":36275},{\"end\":36508,\"start\":36499},{\"end\":37448,\"start\":37439},{\"end\":38177,\"start\":38168}]", "table": "[{\"end\":36497,\"start\":36392},{\"end\":37071,\"start\":36510},{\"end\":38166,\"start\":37721},{\"end\":38825,\"start\":38290},{\"end\":36497,\"start\":36392},{\"end\":37071,\"start\":36510},{\"end\":38166,\"start\":37721},{\"end\":38825,\"start\":38290}]", "figure_caption": "[{\"end\":33716,\"start\":33035},{\"end\":34154,\"start\":33730},{\"end\":34553,\"start\":34168},{\"end\":35223,\"start\":34578},{\"end\":35667,\"start\":35237},{\"end\":35958,\"start\":35681},{\"end\":36273,\"start\":35972},{\"end\":36392,\"start\":36286},{\"end\":37437,\"start\":37074},{\"end\":37721,\"start\":37450},{\"end\":38290,\"start\":38179},{\"end\":33716,\"start\":33035},{\"end\":34154,\"start\":33730},{\"end\":34553,\"start\":34168},{\"end\":35223,\"start\":34578},{\"end\":35667,\"start\":35237},{\"end\":35958,\"start\":35681},{\"end\":36273,\"start\":35972},{\"end\":36392,\"start\":36286},{\"end\":37437,\"start\":37074},{\"end\":37721,\"start\":37450},{\"end\":38290,\"start\":38179}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9716,\"start\":9707},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20916,\"start\":20908},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21660,\"start\":21651},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22520,\"start\":22500},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23170,\"start\":23161},{\"end\":25592,\"start\":25584},{\"end\":26443,\"start\":26435},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27266,\"start\":27258},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27400,\"start\":27385},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":30317,\"start\":30309},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32204,\"start\":32195},{\"end\":32518,\"start\":32510},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32844,\"start\":32835},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9716,\"start\":9707},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20916,\"start\":20908},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21660,\"start\":21651},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22520,\"start\":22500},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23170,\"start\":23161},{\"end\":25592,\"start\":25584},{\"end\":26443,\"start\":26435},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27266,\"start\":27258},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27400,\"start\":27385},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":30317,\"start\":30309},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32204,\"start\":32195},{\"end\":32518,\"start\":32510},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32844,\"start\":32835}]", "bib_author_first_name": "[{\"end\":39144,\"start\":39139},{\"end\":39155,\"start\":39154},{\"end\":39157,\"start\":39156},{\"end\":39171,\"start\":39166},{\"end\":39185,\"start\":39181},{\"end\":39432,\"start\":39421},{\"end\":39434,\"start\":39433},{\"end\":39641,\"start\":39634},{\"end\":39893,\"start\":39887},{\"end\":39895,\"start\":39894},{\"end\":40097,\"start\":40095},{\"end\":40113,\"start\":40112},{\"end\":40180,\"start\":40176},{\"end\":40198,\"start\":40192},{\"end\":40560,\"start\":40556},{\"end\":40562,\"start\":40561},{\"end\":40826,\"start\":40825},{\"end\":40834,\"start\":40833},{\"end\":40842,\"start\":40841},{\"end\":40855,\"start\":40851},{\"end\":40861,\"start\":40860},{\"end\":40867,\"start\":40866},{\"end\":41055,\"start\":41052},{\"end\":41112,\"start\":41107},{\"end\":41114,\"start\":41113},{\"end\":41157,\"start\":41152},{\"end\":41175,\"start\":41169},{\"end\":41565,\"start\":41557},{\"end\":41600,\"start\":41592},{\"end\":41619,\"start\":41612},{\"end\":41855,\"start\":41849},{\"end\":41868,\"start\":41865},{\"end\":42227,\"start\":42221},{\"end\":42263,\"start\":42258},{\"end\":42278,\"start\":42273},{\"end\":42280,\"start\":42279},{\"end\":42609,\"start\":42605},{\"end\":42611,\"start\":42610},{\"end\":42845,\"start\":42839},{\"end\":42862,\"start\":42853},{\"end\":43121,\"start\":43116},{\"end\":43133,\"start\":43128},{\"end\":43143,\"start\":43142},{\"end\":43145,\"start\":43144},{\"end\":43161,\"start\":43152},{\"end\":43180,\"start\":43173},{\"end\":43359,\"start\":43351},{\"end\":43361,\"start\":43360},{\"end\":43375,\"start\":43370},{\"end\":43536,\"start\":43528},{\"end\":43538,\"start\":43537},{\"end\":43550,\"start\":43547},{\"end\":43790,\"start\":43786},{\"end\":43811,\"start\":43803},{\"end\":43969,\"start\":43965},{\"end\":43984,\"start\":43977},{\"end\":44002,\"start\":44001},{\"end\":44004,\"start\":44003},{\"end\":44178,\"start\":44174},{\"end\":44180,\"start\":44179},{\"end\":44202,\"start\":44201},{\"end\":44224,\"start\":44223},{\"end\":44718,\"start\":44714},{\"end\":44732,\"start\":44727},{\"end\":44734,\"start\":44733},{\"end\":44752,\"start\":44746},{\"end\":45127,\"start\":45122},{\"end\":45171,\"start\":45161},{\"end\":45184,\"start\":45182},{\"end\":45195,\"start\":45189},{\"end\":45197,\"start\":45196},{\"end\":45594,\"start\":45588},{\"end\":45596,\"start\":45595},{\"end\":45609,\"start\":45604},{\"end\":45619,\"start\":45618},{\"end\":45621,\"start\":45620},{\"end\":45822,\"start\":45818},{\"end\":46030,\"start\":46025},{\"end\":46310,\"start\":46304},{\"end\":46323,\"start\":46318},{\"end\":46401,\"start\":46397},{\"end\":46415,\"start\":46409},{\"end\":46775,\"start\":46772},{\"end\":46789,\"start\":46786},{\"end\":46791,\"start\":46790},{\"end\":46842,\"start\":46838},{\"end\":46854,\"start\":46852},{\"end\":47186,\"start\":47182},{\"end\":47188,\"start\":47187},{\"end\":47205,\"start\":47198},{\"end\":47207,\"start\":47206},{\"end\":47383,\"start\":47378},{\"end\":47396,\"start\":47391},{\"end\":47420,\"start\":47412},{\"end\":47648,\"start\":47644},{\"end\":47664,\"start\":47660},{\"end\":47779,\"start\":47775},{\"end\":47813,\"start\":47807},{\"end\":47815,\"start\":47814},{\"end\":47829,\"start\":47824},{\"end\":48404,\"start\":48401},{\"end\":48424,\"start\":48419},{\"end\":48613,\"start\":48607},{\"end\":48665,\"start\":48659},{\"end\":48688,\"start\":48674},{\"end\":39144,\"start\":39139},{\"end\":39155,\"start\":39154},{\"end\":39157,\"start\":39156},{\"end\":39171,\"start\":39166},{\"end\":39185,\"start\":39181},{\"end\":39432,\"start\":39421},{\"end\":39434,\"start\":39433},{\"end\":39641,\"start\":39634},{\"end\":39893,\"start\":39887},{\"end\":39895,\"start\":39894},{\"end\":40097,\"start\":40095},{\"end\":40113,\"start\":40112},{\"end\":40180,\"start\":40176},{\"end\":40198,\"start\":40192},{\"end\":40560,\"start\":40556},{\"end\":40562,\"start\":40561},{\"end\":40826,\"start\":40825},{\"end\":40834,\"start\":40833},{\"end\":40842,\"start\":40841},{\"end\":40855,\"start\":40851},{\"end\":40861,\"start\":40860},{\"end\":40867,\"start\":40866},{\"end\":41055,\"start\":41052},{\"end\":41112,\"start\":41107},{\"end\":41114,\"start\":41113},{\"end\":41157,\"start\":41152},{\"end\":41175,\"start\":41169},{\"end\":41565,\"start\":41557},{\"end\":41600,\"start\":41592},{\"end\":41619,\"start\":41612},{\"end\":41855,\"start\":41849},{\"end\":41868,\"start\":41865},{\"end\":42227,\"start\":42221},{\"end\":42263,\"start\":42258},{\"end\":42278,\"start\":42273},{\"end\":42280,\"start\":42279},{\"end\":42609,\"start\":42605},{\"end\":42611,\"start\":42610},{\"end\":42845,\"start\":42839},{\"end\":42862,\"start\":42853},{\"end\":43121,\"start\":43116},{\"end\":43133,\"start\":43128},{\"end\":43143,\"start\":43142},{\"end\":43145,\"start\":43144},{\"end\":43161,\"start\":43152},{\"end\":43180,\"start\":43173},{\"end\":43359,\"start\":43351},{\"end\":43361,\"start\":43360},{\"end\":43375,\"start\":43370},{\"end\":43536,\"start\":43528},{\"end\":43538,\"start\":43537},{\"end\":43550,\"start\":43547},{\"end\":43790,\"start\":43786},{\"end\":43811,\"start\":43803},{\"end\":43969,\"start\":43965},{\"end\":43984,\"start\":43977},{\"end\":44002,\"start\":44001},{\"end\":44004,\"start\":44003},{\"end\":44178,\"start\":44174},{\"end\":44180,\"start\":44179},{\"end\":44202,\"start\":44201},{\"end\":44224,\"start\":44223},{\"end\":44718,\"start\":44714},{\"end\":44732,\"start\":44727},{\"end\":44734,\"start\":44733},{\"end\":44752,\"start\":44746},{\"end\":45127,\"start\":45122},{\"end\":45171,\"start\":45161},{\"end\":45184,\"start\":45182},{\"end\":45195,\"start\":45189},{\"end\":45197,\"start\":45196},{\"end\":45594,\"start\":45588},{\"end\":45596,\"start\":45595},{\"end\":45609,\"start\":45604},{\"end\":45619,\"start\":45618},{\"end\":45621,\"start\":45620},{\"end\":45822,\"start\":45818},{\"end\":46030,\"start\":46025},{\"end\":46310,\"start\":46304},{\"end\":46323,\"start\":46318},{\"end\":46401,\"start\":46397},{\"end\":46415,\"start\":46409},{\"end\":46775,\"start\":46772},{\"end\":46789,\"start\":46786},{\"end\":46791,\"start\":46790},{\"end\":46842,\"start\":46838},{\"end\":46854,\"start\":46852},{\"end\":47186,\"start\":47182},{\"end\":47188,\"start\":47187},{\"end\":47205,\"start\":47198},{\"end\":47207,\"start\":47206},{\"end\":47383,\"start\":47378},{\"end\":47396,\"start\":47391},{\"end\":47420,\"start\":47412},{\"end\":47648,\"start\":47644},{\"end\":47664,\"start\":47660},{\"end\":47779,\"start\":47775},{\"end\":47813,\"start\":47807},{\"end\":47815,\"start\":47814},{\"end\":47829,\"start\":47824},{\"end\":48404,\"start\":48401},{\"end\":48424,\"start\":48419},{\"end\":48613,\"start\":48607},{\"end\":48665,\"start\":48659},{\"end\":48688,\"start\":48674}]", "bib_author_last_name": "[{\"end\":39137,\"start\":39123},{\"end\":39152,\"start\":39145},{\"end\":39164,\"start\":39158},{\"end\":39179,\"start\":39172},{\"end\":39192,\"start\":39186},{\"end\":39441,\"start\":39435},{\"end\":39650,\"start\":39642},{\"end\":39901,\"start\":39896},{\"end\":40102,\"start\":40098},{\"end\":40110,\"start\":40104},{\"end\":40122,\"start\":40114},{\"end\":40132,\"start\":40124},{\"end\":40137,\"start\":40134},{\"end\":40143,\"start\":40139},{\"end\":40148,\"start\":40145},{\"end\":40158,\"start\":40150},{\"end\":40168,\"start\":40160},{\"end\":40174,\"start\":40170},{\"end\":40190,\"start\":40181},{\"end\":40205,\"start\":40199},{\"end\":40571,\"start\":40563},{\"end\":40831,\"start\":40827},{\"end\":40839,\"start\":40835},{\"end\":40849,\"start\":40843},{\"end\":40858,\"start\":40856},{\"end\":40864,\"start\":40862},{\"end\":40875,\"start\":40868},{\"end\":41066,\"start\":41056},{\"end\":41081,\"start\":41068},{\"end\":41087,\"start\":41083},{\"end\":41094,\"start\":41089},{\"end\":41101,\"start\":41096},{\"end\":41105,\"start\":41103},{\"end\":41119,\"start\":41115},{\"end\":41127,\"start\":41121},{\"end\":41134,\"start\":41129},{\"end\":41141,\"start\":41136},{\"end\":41150,\"start\":41143},{\"end\":41167,\"start\":41158},{\"end\":41182,\"start\":41176},{\"end\":41570,\"start\":41566},{\"end\":41582,\"start\":41572},{\"end\":41590,\"start\":41584},{\"end\":41610,\"start\":41601},{\"end\":41623,\"start\":41620},{\"end\":41863,\"start\":41856},{\"end\":41872,\"start\":41869},{\"end\":42182,\"start\":42173},{\"end\":42190,\"start\":42184},{\"end\":42197,\"start\":42192},{\"end\":42205,\"start\":42199},{\"end\":42212,\"start\":42207},{\"end\":42219,\"start\":42214},{\"end\":42233,\"start\":42228},{\"end\":42238,\"start\":42235},{\"end\":42245,\"start\":42240},{\"end\":42256,\"start\":42247},{\"end\":42271,\"start\":42264},{\"end\":42290,\"start\":42281},{\"end\":42620,\"start\":42612},{\"end\":42851,\"start\":42846},{\"end\":42870,\"start\":42863},{\"end\":43126,\"start\":43122},{\"end\":43140,\"start\":43134},{\"end\":43150,\"start\":43146},{\"end\":43171,\"start\":43162},{\"end\":43368,\"start\":43362},{\"end\":43378,\"start\":43376},{\"end\":43545,\"start\":43539},{\"end\":43558,\"start\":43551},{\"end\":43801,\"start\":43791},{\"end\":43818,\"start\":43812},{\"end\":43975,\"start\":43970},{\"end\":43991,\"start\":43985},{\"end\":43999,\"start\":43993},{\"end\":44016,\"start\":44005},{\"end\":44190,\"start\":44181},{\"end\":44199,\"start\":44192},{\"end\":44209,\"start\":44203},{\"end\":44221,\"start\":44211},{\"end\":44229,\"start\":44225},{\"end\":44638,\"start\":44633},{\"end\":44647,\"start\":44640},{\"end\":44654,\"start\":44649},{\"end\":44662,\"start\":44656},{\"end\":44673,\"start\":44664},{\"end\":44681,\"start\":44675},{\"end\":44688,\"start\":44683},{\"end\":44697,\"start\":44690},{\"end\":44703,\"start\":44699},{\"end\":44712,\"start\":44705},{\"end\":44725,\"start\":44719},{\"end\":44744,\"start\":44735},{\"end\":44759,\"start\":44753},{\"end\":45134,\"start\":45128},{\"end\":45140,\"start\":45136},{\"end\":45145,\"start\":45142},{\"end\":45153,\"start\":45147},{\"end\":45159,\"start\":45155},{\"end\":45180,\"start\":45172},{\"end\":45187,\"start\":45185},{\"end\":45200,\"start\":45198},{\"end\":45602,\"start\":45597},{\"end\":45616,\"start\":45610},{\"end\":45627,\"start\":45622},{\"end\":45827,\"start\":45823},{\"end\":46037,\"start\":46031},{\"end\":46316,\"start\":46311},{\"end\":46329,\"start\":46324},{\"end\":46340,\"start\":46331},{\"end\":46348,\"start\":46342},{\"end\":46356,\"start\":46350},{\"end\":46362,\"start\":46358},{\"end\":46370,\"start\":46364},{\"end\":46379,\"start\":46372},{\"end\":46387,\"start\":46381},{\"end\":46395,\"start\":46389},{\"end\":46407,\"start\":46402},{\"end\":46421,\"start\":46416},{\"end\":46784,\"start\":46776},{\"end\":46802,\"start\":46792},{\"end\":46811,\"start\":46804},{\"end\":46821,\"start\":46813},{\"end\":46829,\"start\":46823},{\"end\":46836,\"start\":46831},{\"end\":46850,\"start\":46843},{\"end\":46859,\"start\":46855},{\"end\":47196,\"start\":47189},{\"end\":47213,\"start\":47208},{\"end\":47389,\"start\":47384},{\"end\":47401,\"start\":47397},{\"end\":47410,\"start\":47403},{\"end\":47427,\"start\":47421},{\"end\":47658,\"start\":47649},{\"end\":47674,\"start\":47665},{\"end\":47682,\"start\":47676},{\"end\":47703,\"start\":47684},{\"end\":47710,\"start\":47705},{\"end\":47720,\"start\":47712},{\"end\":47728,\"start\":47722},{\"end\":47733,\"start\":47730},{\"end\":47740,\"start\":47735},{\"end\":47750,\"start\":47742},{\"end\":47757,\"start\":47752},{\"end\":47766,\"start\":47759},{\"end\":47773,\"start\":47768},{\"end\":47786,\"start\":47780},{\"end\":47800,\"start\":47788},{\"end\":47805,\"start\":47802},{\"end\":47822,\"start\":47816},{\"end\":47841,\"start\":47830},{\"end\":48392,\"start\":48380},{\"end\":48399,\"start\":48394},{\"end\":48417,\"start\":48405},{\"end\":48436,\"start\":48425},{\"end\":48621,\"start\":48614},{\"end\":48633,\"start\":48623},{\"end\":48639,\"start\":48635},{\"end\":48647,\"start\":48641},{\"end\":48657,\"start\":48649},{\"end\":48672,\"start\":48666},{\"end\":48697,\"start\":48689},{\"end\":39137,\"start\":39123},{\"end\":39152,\"start\":39145},{\"end\":39164,\"start\":39158},{\"end\":39179,\"start\":39172},{\"end\":39192,\"start\":39186},{\"end\":39441,\"start\":39435},{\"end\":39650,\"start\":39642},{\"end\":39901,\"start\":39896},{\"end\":40102,\"start\":40098},{\"end\":40110,\"start\":40104},{\"end\":40122,\"start\":40114},{\"end\":40132,\"start\":40124},{\"end\":40137,\"start\":40134},{\"end\":40143,\"start\":40139},{\"end\":40148,\"start\":40145},{\"end\":40158,\"start\":40150},{\"end\":40168,\"start\":40160},{\"end\":40174,\"start\":40170},{\"end\":40190,\"start\":40181},{\"end\":40205,\"start\":40199},{\"end\":40571,\"start\":40563},{\"end\":40831,\"start\":40827},{\"end\":40839,\"start\":40835},{\"end\":40849,\"start\":40843},{\"end\":40858,\"start\":40856},{\"end\":40864,\"start\":40862},{\"end\":40875,\"start\":40868},{\"end\":41066,\"start\":41056},{\"end\":41081,\"start\":41068},{\"end\":41087,\"start\":41083},{\"end\":41094,\"start\":41089},{\"end\":41101,\"start\":41096},{\"end\":41105,\"start\":41103},{\"end\":41119,\"start\":41115},{\"end\":41127,\"start\":41121},{\"end\":41134,\"start\":41129},{\"end\":41141,\"start\":41136},{\"end\":41150,\"start\":41143},{\"end\":41167,\"start\":41158},{\"end\":41182,\"start\":41176},{\"end\":41570,\"start\":41566},{\"end\":41582,\"start\":41572},{\"end\":41590,\"start\":41584},{\"end\":41610,\"start\":41601},{\"end\":41623,\"start\":41620},{\"end\":41863,\"start\":41856},{\"end\":41872,\"start\":41869},{\"end\":42182,\"start\":42173},{\"end\":42190,\"start\":42184},{\"end\":42197,\"start\":42192},{\"end\":42205,\"start\":42199},{\"end\":42212,\"start\":42207},{\"end\":42219,\"start\":42214},{\"end\":42233,\"start\":42228},{\"end\":42238,\"start\":42235},{\"end\":42245,\"start\":42240},{\"end\":42256,\"start\":42247},{\"end\":42271,\"start\":42264},{\"end\":42290,\"start\":42281},{\"end\":42620,\"start\":42612},{\"end\":42851,\"start\":42846},{\"end\":42870,\"start\":42863},{\"end\":43126,\"start\":43122},{\"end\":43140,\"start\":43134},{\"end\":43150,\"start\":43146},{\"end\":43171,\"start\":43162},{\"end\":43368,\"start\":43362},{\"end\":43378,\"start\":43376},{\"end\":43545,\"start\":43539},{\"end\":43558,\"start\":43551},{\"end\":43801,\"start\":43791},{\"end\":43818,\"start\":43812},{\"end\":43975,\"start\":43970},{\"end\":43991,\"start\":43985},{\"end\":43999,\"start\":43993},{\"end\":44016,\"start\":44005},{\"end\":44190,\"start\":44181},{\"end\":44199,\"start\":44192},{\"end\":44209,\"start\":44203},{\"end\":44221,\"start\":44211},{\"end\":44229,\"start\":44225},{\"end\":44638,\"start\":44633},{\"end\":44647,\"start\":44640},{\"end\":44654,\"start\":44649},{\"end\":44662,\"start\":44656},{\"end\":44673,\"start\":44664},{\"end\":44681,\"start\":44675},{\"end\":44688,\"start\":44683},{\"end\":44697,\"start\":44690},{\"end\":44703,\"start\":44699},{\"end\":44712,\"start\":44705},{\"end\":44725,\"start\":44719},{\"end\":44744,\"start\":44735},{\"end\":44759,\"start\":44753},{\"end\":45134,\"start\":45128},{\"end\":45140,\"start\":45136},{\"end\":45145,\"start\":45142},{\"end\":45153,\"start\":45147},{\"end\":45159,\"start\":45155},{\"end\":45180,\"start\":45172},{\"end\":45187,\"start\":45185},{\"end\":45200,\"start\":45198},{\"end\":45602,\"start\":45597},{\"end\":45616,\"start\":45610},{\"end\":45627,\"start\":45622},{\"end\":45827,\"start\":45823},{\"end\":46037,\"start\":46031},{\"end\":46316,\"start\":46311},{\"end\":46329,\"start\":46324},{\"end\":46340,\"start\":46331},{\"end\":46348,\"start\":46342},{\"end\":46356,\"start\":46350},{\"end\":46362,\"start\":46358},{\"end\":46370,\"start\":46364},{\"end\":46379,\"start\":46372},{\"end\":46387,\"start\":46381},{\"end\":46395,\"start\":46389},{\"end\":46407,\"start\":46402},{\"end\":46421,\"start\":46416},{\"end\":46784,\"start\":46776},{\"end\":46802,\"start\":46792},{\"end\":46811,\"start\":46804},{\"end\":46821,\"start\":46813},{\"end\":46829,\"start\":46823},{\"end\":46836,\"start\":46831},{\"end\":46850,\"start\":46843},{\"end\":46859,\"start\":46855},{\"end\":47196,\"start\":47189},{\"end\":47213,\"start\":47208},{\"end\":47389,\"start\":47384},{\"end\":47401,\"start\":47397},{\"end\":47410,\"start\":47403},{\"end\":47427,\"start\":47421},{\"end\":47658,\"start\":47649},{\"end\":47674,\"start\":47665},{\"end\":47682,\"start\":47676},{\"end\":47703,\"start\":47684},{\"end\":47710,\"start\":47705},{\"end\":47720,\"start\":47712},{\"end\":47728,\"start\":47722},{\"end\":47733,\"start\":47730},{\"end\":47740,\"start\":47735},{\"end\":47750,\"start\":47742},{\"end\":47757,\"start\":47752},{\"end\":47766,\"start\":47759},{\"end\":47773,\"start\":47768},{\"end\":47786,\"start\":47780},{\"end\":47800,\"start\":47788},{\"end\":47805,\"start\":47802},{\"end\":47822,\"start\":47816},{\"end\":47841,\"start\":47830},{\"end\":48392,\"start\":48380},{\"end\":48399,\"start\":48394},{\"end\":48417,\"start\":48405},{\"end\":48436,\"start\":48425},{\"end\":48621,\"start\":48614},{\"end\":48633,\"start\":48623},{\"end\":48639,\"start\":48635},{\"end\":48647,\"start\":48641},{\"end\":48657,\"start\":48649},{\"end\":48672,\"start\":48666},{\"end\":48697,\"start\":48689}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":9770532},\"end\":39340,\"start\":39097},{\"attributes\":{\"id\":\"b1\"},\"end\":39546,\"start\":39342},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":60809946},\"end\":39837,\"start\":39548},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":44239681},\"end\":40091,\"start\":39839},{\"attributes\":{\"doi\":\"abs/1611.02731\",\"id\":\"b4\"},\"end\":40481,\"start\":40093},{\"attributes\":{\"id\":\"b5\"},\"end\":40770,\"start\":40483},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":57246310},\"end\":41021,\"start\":40772},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":1033682},\"end\":41475,\"start\":41023},{\"attributes\":{\"id\":\"b8\"},\"end\":41785,\"start\":41477},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":53067},\"end\":42117,\"start\":41787},{\"attributes\":{\"doi\":\"abs/1611.05013\",\"id\":\"b10\"},\"end\":42556,\"start\":42119},{\"attributes\":{\"id\":\"b11\"},\"end\":42743,\"start\":42558},{\"attributes\":{\"doi\":\"abs/1502.03167\",\"id\":\"b12\"},\"end\":43090,\"start\":42745},{\"attributes\":{\"id\":\"b13\"},\"end\":43289,\"start\":43092},{\"attributes\":{\"id\":\"b14\"},\"end\":43526,\"start\":43291},{\"attributes\":{\"doi\":\"arXiv:1312.6114\",\"id\":\"b15\"},\"end\":43729,\"start\":43528},{\"attributes\":{\"id\":\"b16\"},\"end\":43921,\"start\":43731},{\"attributes\":{\"id\":\"b17\"},\"end\":44125,\"start\":43923},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14081214},\"end\":44561,\"start\":44127},{\"attributes\":{\"doi\":\"abs/1612.07837\",\"id\":\"b19\"},\"end\":45051,\"start\":44563},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":16852518},\"end\":45523,\"start\":45053},{\"attributes\":{\"id\":\"b21\"},\"end\":45796,\"start\":45525},{\"attributes\":{\"id\":\"b22\"},\"end\":45916,\"start\":45798},{\"attributes\":{\"id\":\"b23\"},\"end\":46230,\"start\":45918},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":59054499},\"end\":46768,\"start\":46232},{\"attributes\":{\"id\":\"b25\"},\"end\":47124,\"start\":46770},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":10495264},\"end\":47329,\"start\":47126},{\"attributes\":{\"doi\":\"arXiv:1511.01844\",\"id\":\"b27\"},\"end\":47601,\"start\":47331},{\"attributes\":{\"doi\":\"abs/1609.03499\",\"id\":\"b28\",\"matched_paper_id\":11445252},\"end\":48323,\"start\":47603},{\"attributes\":{\"id\":\"b29\"},\"end\":48603,\"start\":48325},{\"attributes\":{\"id\":\"b30\"},\"end\":48797,\"start\":48605},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":9770532},\"end\":39340,\"start\":39097},{\"attributes\":{\"id\":\"b1\"},\"end\":39546,\"start\":39342},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":60809946},\"end\":39837,\"start\":39548},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":44239681},\"end\":40091,\"start\":39839},{\"attributes\":{\"doi\":\"abs/1611.02731\",\"id\":\"b4\"},\"end\":40481,\"start\":40093},{\"attributes\":{\"id\":\"b5\"},\"end\":40770,\"start\":40483},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":57246310},\"end\":41021,\"start\":40772},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":1033682},\"end\":41475,\"start\":41023},{\"attributes\":{\"id\":\"b8\"},\"end\":41785,\"start\":41477},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":53067},\"end\":42117,\"start\":41787},{\"attributes\":{\"doi\":\"abs/1611.05013\",\"id\":\"b10\"},\"end\":42556,\"start\":42119},{\"attributes\":{\"id\":\"b11\"},\"end\":42743,\"start\":42558},{\"attributes\":{\"doi\":\"abs/1502.03167\",\"id\":\"b12\"},\"end\":43090,\"start\":42745},{\"attributes\":{\"id\":\"b13\"},\"end\":43289,\"start\":43092},{\"attributes\":{\"id\":\"b14\"},\"end\":43526,\"start\":43291},{\"attributes\":{\"doi\":\"arXiv:1312.6114\",\"id\":\"b15\"},\"end\":43729,\"start\":43528},{\"attributes\":{\"id\":\"b16\"},\"end\":43921,\"start\":43731},{\"attributes\":{\"id\":\"b17\"},\"end\":44125,\"start\":43923},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14081214},\"end\":44561,\"start\":44127},{\"attributes\":{\"doi\":\"abs/1612.07837\",\"id\":\"b19\"},\"end\":45051,\"start\":44563},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":16852518},\"end\":45523,\"start\":45053},{\"attributes\":{\"id\":\"b21\"},\"end\":45796,\"start\":45525},{\"attributes\":{\"id\":\"b22\"},\"end\":45916,\"start\":45798},{\"attributes\":{\"id\":\"b23\"},\"end\":46230,\"start\":45918},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":59054499},\"end\":46768,\"start\":46232},{\"attributes\":{\"id\":\"b25\"},\"end\":47124,\"start\":46770},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":10495264},\"end\":47329,\"start\":47126},{\"attributes\":{\"doi\":\"arXiv:1511.01844\",\"id\":\"b27\"},\"end\":47601,\"start\":47331},{\"attributes\":{\"doi\":\"abs/1609.03499\",\"id\":\"b28\",\"matched_paper_id\":11445252},\"end\":48323,\"start\":47603},{\"attributes\":{\"id\":\"b29\"},\"end\":48603,\"start\":48325},{\"attributes\":{\"id\":\"b30\"},\"end\":48797,\"start\":48605}]", "bib_title": "[{\"end\":39121,\"start\":39097},{\"end\":39632,\"start\":39548},{\"end\":39885,\"start\":39839},{\"end\":40823,\"start\":40772},{\"end\":41050,\"start\":41023},{\"end\":41847,\"start\":41787},{\"end\":44172,\"start\":44127},{\"end\":45120,\"start\":45053},{\"end\":46302,\"start\":46232},{\"end\":47180,\"start\":47126},{\"end\":47642,\"start\":47603},{\"end\":39121,\"start\":39097},{\"end\":39632,\"start\":39548},{\"end\":39885,\"start\":39839},{\"end\":40823,\"start\":40772},{\"end\":41050,\"start\":41023},{\"end\":41847,\"start\":41787},{\"end\":44172,\"start\":44127},{\"end\":45120,\"start\":45053},{\"end\":46302,\"start\":46232},{\"end\":47180,\"start\":47126},{\"end\":47642,\"start\":47603}]", "bib_author": "[{\"end\":39139,\"start\":39123},{\"end\":39154,\"start\":39139},{\"end\":39166,\"start\":39154},{\"end\":39181,\"start\":39166},{\"end\":39194,\"start\":39181},{\"end\":39443,\"start\":39421},{\"end\":39652,\"start\":39634},{\"end\":39903,\"start\":39887},{\"end\":40104,\"start\":40095},{\"end\":40112,\"start\":40104},{\"end\":40124,\"start\":40112},{\"end\":40134,\"start\":40124},{\"end\":40139,\"start\":40134},{\"end\":40145,\"start\":40139},{\"end\":40150,\"start\":40145},{\"end\":40160,\"start\":40150},{\"end\":40170,\"start\":40160},{\"end\":40176,\"start\":40170},{\"end\":40192,\"start\":40176},{\"end\":40207,\"start\":40192},{\"end\":40573,\"start\":40556},{\"end\":40833,\"start\":40825},{\"end\":40841,\"start\":40833},{\"end\":40851,\"start\":40841},{\"end\":40860,\"start\":40851},{\"end\":40866,\"start\":40860},{\"end\":40877,\"start\":40866},{\"end\":41068,\"start\":41052},{\"end\":41083,\"start\":41068},{\"end\":41089,\"start\":41083},{\"end\":41096,\"start\":41089},{\"end\":41103,\"start\":41096},{\"end\":41107,\"start\":41103},{\"end\":41121,\"start\":41107},{\"end\":41129,\"start\":41121},{\"end\":41136,\"start\":41129},{\"end\":41143,\"start\":41136},{\"end\":41152,\"start\":41143},{\"end\":41169,\"start\":41152},{\"end\":41184,\"start\":41169},{\"end\":41572,\"start\":41557},{\"end\":41584,\"start\":41572},{\"end\":41592,\"start\":41584},{\"end\":41612,\"start\":41592},{\"end\":41625,\"start\":41612},{\"end\":41865,\"start\":41849},{\"end\":41874,\"start\":41865},{\"end\":42184,\"start\":42173},{\"end\":42192,\"start\":42184},{\"end\":42199,\"start\":42192},{\"end\":42207,\"start\":42199},{\"end\":42214,\"start\":42207},{\"end\":42221,\"start\":42214},{\"end\":42235,\"start\":42221},{\"end\":42240,\"start\":42235},{\"end\":42247,\"start\":42240},{\"end\":42258,\"start\":42247},{\"end\":42273,\"start\":42258},{\"end\":42292,\"start\":42273},{\"end\":42622,\"start\":42605},{\"end\":42853,\"start\":42839},{\"end\":42872,\"start\":42853},{\"end\":43128,\"start\":43116},{\"end\":43142,\"start\":43128},{\"end\":43152,\"start\":43142},{\"end\":43173,\"start\":43152},{\"end\":43183,\"start\":43173},{\"end\":43370,\"start\":43351},{\"end\":43380,\"start\":43370},{\"end\":43547,\"start\":43528},{\"end\":43560,\"start\":43547},{\"end\":43803,\"start\":43786},{\"end\":43820,\"start\":43803},{\"end\":43977,\"start\":43965},{\"end\":43993,\"start\":43977},{\"end\":44001,\"start\":43993},{\"end\":44018,\"start\":44001},{\"end\":44192,\"start\":44174},{\"end\":44201,\"start\":44192},{\"end\":44211,\"start\":44201},{\"end\":44223,\"start\":44211},{\"end\":44231,\"start\":44223},{\"end\":44640,\"start\":44633},{\"end\":44649,\"start\":44640},{\"end\":44656,\"start\":44649},{\"end\":44664,\"start\":44656},{\"end\":44675,\"start\":44664},{\"end\":44683,\"start\":44675},{\"end\":44690,\"start\":44683},{\"end\":44699,\"start\":44690},{\"end\":44705,\"start\":44699},{\"end\":44714,\"start\":44705},{\"end\":44727,\"start\":44714},{\"end\":44746,\"start\":44727},{\"end\":44761,\"start\":44746},{\"end\":45136,\"start\":45122},{\"end\":45142,\"start\":45136},{\"end\":45147,\"start\":45142},{\"end\":45155,\"start\":45147},{\"end\":45161,\"start\":45155},{\"end\":45182,\"start\":45161},{\"end\":45189,\"start\":45182},{\"end\":45202,\"start\":45189},{\"end\":45604,\"start\":45588},{\"end\":45618,\"start\":45604},{\"end\":45629,\"start\":45618},{\"end\":45829,\"start\":45818},{\"end\":46039,\"start\":46025},{\"end\":46318,\"start\":46304},{\"end\":46331,\"start\":46318},{\"end\":46342,\"start\":46331},{\"end\":46350,\"start\":46342},{\"end\":46358,\"start\":46350},{\"end\":46364,\"start\":46358},{\"end\":46372,\"start\":46364},{\"end\":46381,\"start\":46372},{\"end\":46389,\"start\":46381},{\"end\":46397,\"start\":46389},{\"end\":46409,\"start\":46397},{\"end\":46423,\"start\":46409},{\"end\":46786,\"start\":46772},{\"end\":46804,\"start\":46786},{\"end\":46813,\"start\":46804},{\"end\":46823,\"start\":46813},{\"end\":46831,\"start\":46823},{\"end\":46838,\"start\":46831},{\"end\":46852,\"start\":46838},{\"end\":46861,\"start\":46852},{\"end\":47198,\"start\":47182},{\"end\":47215,\"start\":47198},{\"end\":47391,\"start\":47378},{\"end\":47403,\"start\":47391},{\"end\":47412,\"start\":47403},{\"end\":47429,\"start\":47412},{\"end\":47660,\"start\":47644},{\"end\":47676,\"start\":47660},{\"end\":47684,\"start\":47676},{\"end\":47705,\"start\":47684},{\"end\":47712,\"start\":47705},{\"end\":47722,\"start\":47712},{\"end\":47730,\"start\":47722},{\"end\":47735,\"start\":47730},{\"end\":47742,\"start\":47735},{\"end\":47752,\"start\":47742},{\"end\":47759,\"start\":47752},{\"end\":47768,\"start\":47759},{\"end\":47775,\"start\":47768},{\"end\":47788,\"start\":47775},{\"end\":47802,\"start\":47788},{\"end\":47807,\"start\":47802},{\"end\":47824,\"start\":47807},{\"end\":47843,\"start\":47824},{\"end\":48394,\"start\":48380},{\"end\":48401,\"start\":48394},{\"end\":48419,\"start\":48401},{\"end\":48438,\"start\":48419},{\"end\":48623,\"start\":48607},{\"end\":48635,\"start\":48623},{\"end\":48641,\"start\":48635},{\"end\":48649,\"start\":48641},{\"end\":48659,\"start\":48649},{\"end\":48674,\"start\":48659},{\"end\":48699,\"start\":48674},{\"end\":39139,\"start\":39123},{\"end\":39154,\"start\":39139},{\"end\":39166,\"start\":39154},{\"end\":39181,\"start\":39166},{\"end\":39194,\"start\":39181},{\"end\":39443,\"start\":39421},{\"end\":39652,\"start\":39634},{\"end\":39903,\"start\":39887},{\"end\":40104,\"start\":40095},{\"end\":40112,\"start\":40104},{\"end\":40124,\"start\":40112},{\"end\":40134,\"start\":40124},{\"end\":40139,\"start\":40134},{\"end\":40145,\"start\":40139},{\"end\":40150,\"start\":40145},{\"end\":40160,\"start\":40150},{\"end\":40170,\"start\":40160},{\"end\":40176,\"start\":40170},{\"end\":40192,\"start\":40176},{\"end\":40207,\"start\":40192},{\"end\":40573,\"start\":40556},{\"end\":40833,\"start\":40825},{\"end\":40841,\"start\":40833},{\"end\":40851,\"start\":40841},{\"end\":40860,\"start\":40851},{\"end\":40866,\"start\":40860},{\"end\":40877,\"start\":40866},{\"end\":41068,\"start\":41052},{\"end\":41083,\"start\":41068},{\"end\":41089,\"start\":41083},{\"end\":41096,\"start\":41089},{\"end\":41103,\"start\":41096},{\"end\":41107,\"start\":41103},{\"end\":41121,\"start\":41107},{\"end\":41129,\"start\":41121},{\"end\":41136,\"start\":41129},{\"end\":41143,\"start\":41136},{\"end\":41152,\"start\":41143},{\"end\":41169,\"start\":41152},{\"end\":41184,\"start\":41169},{\"end\":41572,\"start\":41557},{\"end\":41584,\"start\":41572},{\"end\":41592,\"start\":41584},{\"end\":41612,\"start\":41592},{\"end\":41625,\"start\":41612},{\"end\":41865,\"start\":41849},{\"end\":41874,\"start\":41865},{\"end\":42184,\"start\":42173},{\"end\":42192,\"start\":42184},{\"end\":42199,\"start\":42192},{\"end\":42207,\"start\":42199},{\"end\":42214,\"start\":42207},{\"end\":42221,\"start\":42214},{\"end\":42235,\"start\":42221},{\"end\":42240,\"start\":42235},{\"end\":42247,\"start\":42240},{\"end\":42258,\"start\":42247},{\"end\":42273,\"start\":42258},{\"end\":42292,\"start\":42273},{\"end\":42622,\"start\":42605},{\"end\":42853,\"start\":42839},{\"end\":42872,\"start\":42853},{\"end\":43128,\"start\":43116},{\"end\":43142,\"start\":43128},{\"end\":43152,\"start\":43142},{\"end\":43173,\"start\":43152},{\"end\":43183,\"start\":43173},{\"end\":43370,\"start\":43351},{\"end\":43380,\"start\":43370},{\"end\":43547,\"start\":43528},{\"end\":43560,\"start\":43547},{\"end\":43803,\"start\":43786},{\"end\":43820,\"start\":43803},{\"end\":43977,\"start\":43965},{\"end\":43993,\"start\":43977},{\"end\":44001,\"start\":43993},{\"end\":44018,\"start\":44001},{\"end\":44192,\"start\":44174},{\"end\":44201,\"start\":44192},{\"end\":44211,\"start\":44201},{\"end\":44223,\"start\":44211},{\"end\":44231,\"start\":44223},{\"end\":44640,\"start\":44633},{\"end\":44649,\"start\":44640},{\"end\":44656,\"start\":44649},{\"end\":44664,\"start\":44656},{\"end\":44675,\"start\":44664},{\"end\":44683,\"start\":44675},{\"end\":44690,\"start\":44683},{\"end\":44699,\"start\":44690},{\"end\":44705,\"start\":44699},{\"end\":44714,\"start\":44705},{\"end\":44727,\"start\":44714},{\"end\":44746,\"start\":44727},{\"end\":44761,\"start\":44746},{\"end\":45136,\"start\":45122},{\"end\":45142,\"start\":45136},{\"end\":45147,\"start\":45142},{\"end\":45155,\"start\":45147},{\"end\":45161,\"start\":45155},{\"end\":45182,\"start\":45161},{\"end\":45189,\"start\":45182},{\"end\":45202,\"start\":45189},{\"end\":45604,\"start\":45588},{\"end\":45618,\"start\":45604},{\"end\":45629,\"start\":45618},{\"end\":45829,\"start\":45818},{\"end\":46039,\"start\":46025},{\"end\":46318,\"start\":46304},{\"end\":46331,\"start\":46318},{\"end\":46342,\"start\":46331},{\"end\":46350,\"start\":46342},{\"end\":46358,\"start\":46350},{\"end\":46364,\"start\":46358},{\"end\":46372,\"start\":46364},{\"end\":46381,\"start\":46372},{\"end\":46389,\"start\":46381},{\"end\":46397,\"start\":46389},{\"end\":46409,\"start\":46397},{\"end\":46423,\"start\":46409},{\"end\":46786,\"start\":46772},{\"end\":46804,\"start\":46786},{\"end\":46813,\"start\":46804},{\"end\":46823,\"start\":46813},{\"end\":46831,\"start\":46823},{\"end\":46838,\"start\":46831},{\"end\":46852,\"start\":46838},{\"end\":46861,\"start\":46852},{\"end\":47198,\"start\":47182},{\"end\":47215,\"start\":47198},{\"end\":47391,\"start\":47378},{\"end\":47403,\"start\":47391},{\"end\":47412,\"start\":47403},{\"end\":47429,\"start\":47412},{\"end\":47660,\"start\":47644},{\"end\":47676,\"start\":47660},{\"end\":47684,\"start\":47676},{\"end\":47705,\"start\":47684},{\"end\":47712,\"start\":47705},{\"end\":47722,\"start\":47712},{\"end\":47730,\"start\":47722},{\"end\":47735,\"start\":47730},{\"end\":47742,\"start\":47735},{\"end\":47752,\"start\":47742},{\"end\":47759,\"start\":47752},{\"end\":47768,\"start\":47759},{\"end\":47775,\"start\":47768},{\"end\":47788,\"start\":47775},{\"end\":47802,\"start\":47788},{\"end\":47807,\"start\":47802},{\"end\":47824,\"start\":47807},{\"end\":47843,\"start\":47824},{\"end\":48394,\"start\":48380},{\"end\":48401,\"start\":48394},{\"end\":48419,\"start\":48401},{\"end\":48438,\"start\":48419},{\"end\":48623,\"start\":48607},{\"end\":48635,\"start\":48623},{\"end\":48641,\"start\":48635},{\"end\":48649,\"start\":48641},{\"end\":48659,\"start\":48649},{\"end\":48674,\"start\":48659},{\"end\":48699,\"start\":48674}]", "bib_venue": "[{\"end\":39685,\"start\":39677},{\"end\":39685,\"start\":39677},{\"end\":39199,\"start\":39194},{\"end\":39419,\"start\":39342},{\"end\":39675,\"start\":39652},{\"end\":39951,\"start\":39903},{\"end\":40554,\"start\":40483},{\"end\":40883,\"start\":40877},{\"end\":41233,\"start\":41184},{\"end\":41555,\"start\":41477},{\"end\":41935,\"start\":41874},{\"end\":42171,\"start\":42119},{\"end\":42603,\"start\":42558},{\"end\":42837,\"start\":42745},{\"end\":43114,\"start\":43092},{\"end\":43349,\"start\":43291},{\"end\":43606,\"start\":43575},{\"end\":43784,\"start\":43731},{\"end\":43963,\"start\":43923},{\"end\":44322,\"start\":44231},{\"end\":44631,\"start\":44563},{\"end\":45266,\"start\":45202},{\"end\":45586,\"start\":45525},{\"end\":45816,\"start\":45798},{\"end\":46023,\"start\":45918},{\"end\":46490,\"start\":46423},{\"end\":47219,\"start\":47215},{\"end\":47376,\"start\":47331},{\"end\":47892,\"start\":47857},{\"end\":48378,\"start\":48325},{\"end\":39199,\"start\":39194},{\"end\":39419,\"start\":39342},{\"end\":39675,\"start\":39652},{\"end\":39951,\"start\":39903},{\"end\":40554,\"start\":40483},{\"end\":40883,\"start\":40877},{\"end\":41233,\"start\":41184},{\"end\":41555,\"start\":41477},{\"end\":41935,\"start\":41874},{\"end\":42171,\"start\":42119},{\"end\":42603,\"start\":42558},{\"end\":42837,\"start\":42745},{\"end\":43114,\"start\":43092},{\"end\":43349,\"start\":43291},{\"end\":43606,\"start\":43575},{\"end\":43784,\"start\":43731},{\"end\":43963,\"start\":43923},{\"end\":44322,\"start\":44231},{\"end\":44631,\"start\":44563},{\"end\":45266,\"start\":45202},{\"end\":45586,\"start\":45525},{\"end\":45816,\"start\":45798},{\"end\":46023,\"start\":45918},{\"end\":46490,\"start\":46423},{\"end\":47219,\"start\":47215},{\"end\":47376,\"start\":47331},{\"end\":47892,\"start\":47857},{\"end\":48378,\"start\":48325}]"}}}, "year": 2023, "month": 12, "day": 17}