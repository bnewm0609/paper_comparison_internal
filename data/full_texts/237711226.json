{"id": 237711226, "updated": "2023-08-13 17:44:03.93", "metadata": {"title": "NeuNAC: A novel fragile watermarking algorithm for integrity protection of neural networks", "authors": "[{\"first\":\"Marco\",\"last\":\"Botta\",\"middle\":[]},{\"first\":\"Davide\",\"last\":\"Cavagnino\",\"middle\":[]},{\"first\":\"Roberto\",\"last\":\"Esposito\",\"middle\":[]}]", "venue": "Inf. Sci.", "journal": "Inf. Sci.", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "The last decade has witnessed a massive deployment of Machine Learning tools in every-day life automated tasks. Neural Networks are nowadays in use in a growing number of application areas because of their excellent performances. Unfortunately, it has been shown by many researchers that they can be attacked and fooled in several different ways, and this can dangerously impair their ability to correctly perform their tasks. In this paper we describe a watermarking algorithm that can protect and verify the integrity of (Deep) Neural Networks when deployed in safety critical systems, such as autonomous driving systems or monitoring and surveillance systems. (cid:1) 2021 The Authors. Published by Elsevier Inc. ThisisanopenaccessarticleundertheCCBY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3175121854", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/isci/BottaCE21", "doi": "10.1016/j.ins.2021.06.073"}}, "content": {"source": {"pdf_hash": "bb78a5c7dd3649c59bbde2069d406b649278852f", "pdf_src": "ScienceParsePlus", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBYNCND", "open_access_url": "https://doi.org/10.1016/j.ins.2021.06.073", "status": "HYBRID"}}, "grobid": {"id": "8d4213f55c72015dab6e8b399bec7699f8a65f9a", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/bb78a5c7dd3649c59bbde2069d406b649278852f.txt", "contents": "\nNeuNAC: A novel fragile watermarking algorithm for integrity protection of neural networks\n\n\nMarco Botta \nComputer Science Department\nUniversity of Turin\nCorso Svizzera 18510149TorinoItaly\n\nDavide Cavagnino \nComputer Science Department\nUniversity of Turin\nCorso Svizzera 18510149TorinoItaly\n\nRoberto Esposito \nComputer Science Department\nUniversity of Turin\nCorso Svizzera 18510149TorinoItaly\n\nNeuNAC: A novel fragile watermarking algorithm for integrity protection of neural networks\n10.1016/j.ins.2021.06.073Article history: Received 18 January 2021 Received in revised form 20 May 2021 Accepted 23 June 2021 Available online 25 June 2021a r t i c l e i n f oDeep neural network Fragile watermarking Integrity protection Linear transformation\na b s t r a c tThe last decade has witnessed a massive deployment of Machine Learning tools in everyday life automated tasks. Neural Networks are nowadays in use in a growing number of application areas because of their excellent performances. Unfortunately, it has been shown by many researchers that they can be attacked and fooled in several different ways, and this can dangerously impair their ability to correctly perform their tasks. In this paper we describe a watermarking algorithm that can protect and verify the integrity of (Deep) Neural Networks when deployed in safety critical systems, such as autonomous driving systems or monitoring and surveillance systems.\n\nIntroduction\n\nIn the last decade the fast development of deep learning (DL) techniques has generated a massive interest in building, training and deploying systems that heavily relies on these models. The most popular class of deep learning models is Deep Neural Networks (DNN), which has been successfully adopted in many artificial intelligence applications, such as image recognition [14], natural language processing [21] and speech recognition [2,12]. A state-of-the-art Neural Network (NN) or DNN model is usually made of a large number of structured layers and a huge number of parameters to train. Therefore, a lot of computational resources, storage and time is needed to generate such a model and to deploy it in the product. Once deployed into a safety critical system, it is important to be able to verify the integrity of the model, in order to guarantee that it has not been tampered with. To achieve such an aim, a fragile watermarking method could be used to insert a watermark into the model to be protected and ensure the integrity of the system by checking if the watermark is intact.\n\nIn the field of computer security, the branch related to digital watermarking deals with the protection, in a wide sense, of digital objects. One of the main characteristics of watermarking is the embedding of a watermark signal w directly into the digital host object O: this differentiates watermarking from digital signatures which are an extra information to be carried along with the host object O. The watermark w may be a binary or real valued signal, and may also be, in some cases, the digital signature of the object O.\n\nMany watermarking algorithms have been developed, with different objectives in mind, but all have the same high-level structure; in general, protecting an object with a watermark involves two complementary operations.\n\nThe first operation is the embedding E: it is performed only once and, in general, off-line, thus it may require more computational resources than the second step. The embedding phase embeds a watermark sequence w into the host object O: to make the whole process secure, or to increase its security, this phase may use a secret key k. The object O w resulting from the embedding procedure may thus be expressed as O w \u00bc E O; w; k \u00f0 \u00de . The second operation is the validation (or verification or detection) V: this procedure is performed every time the need arises for testing if an object contains a watermark signal, therefore a fast and light process is to be preferred. When a possibly watermarked and altered object O 0 w must be tested, the object is given to the validation function V O 0 w , which returns a boolean value stating if the watermark is present and eventually extracts the contained watermark signal w 0 . In general, V requires the secret key k used by E and, in some watermarking algorithm, also the host object O and/or the original watermark w. This means that V may depend on all these parameters and hence is written as V O 0 w ; w; k; O . Obviously, the kind of parameters required during validation changes the field of application of the algorithm. A wide variety of watermarking algorithms have been developed to fit different goals and fields of application. To make their differences apparent, it is then useful to classify them by their characteristics, properties, and constraints. Also, in the following discussion, we will show how each property or characteristic applies to the specific case of the object of this study: i.e., the embedding of watermarks in Neural Networks.\n\nTransparency: a watermarking algorithm may follow a white-box or a black-box approach depending on the visibility of the NN in the validation phase. If the validation function has no direct access to the parameters and structure of the NN, the approach is black-box, otherwise it is white-box. To clarify, in black-box systems, since the validation function cannot access the parameters of the NN, to establish if the watermark is present, V can only check the output of the NN over one or more samples.\n\nReversibility: if the validation phase may recover the host object O from the watermarked one the algorithm is called reversible, otherwise it is called non-reversible or irreversible. Recovering may need the secret key k used during embedding and, possibly, the watermark signal w. In case a NN is marked with a non-reversible algorithm, particular care must be given by the algorithm developer to show that the embedding of the watermark signal does not impact the NN performances.\n\nBlindness: if the validation phase needs the host object O, that is V is in the form V O 0 w ; \u00c1 \u00c1 \u00c1 ; O , then the algorithm is called informed, or non-blind; otherwise, it is called blind. Applications where the NN is deployed in an external environment necessarily require blind watermarking algorithms. Robustness: if the application context requires contrasting attacks to the watermarked object aimed at the removal of the watermark then the algorithm must be robust and the validation function should be able to recover the presence of the watermark signal even if the watermarked object has undergone severe modifications: this is the case of copyright protection, when a NN developer wants to protect its rights as owner of a product which required skills, efforts and computing power in training a NN. On the other hand, if the purpose of the application is to discover attacks aimed at modifying the NN behavior then a fragile watermarking algorithm is needed which has a validation function that detects the minimal modification to the watermarked object: for example, if a NN operates in a critical environment (e.g. driving a car or flying an airplane) it is important to be able to check its integrity.\n\nImperceptibility: this property is more related to multimedia objects, like music, images, videos, and refers to a subjective judgment of a human on the watermarked object stating if the watermark signal (e.g., a logo superimposed on an image or on a TV broadcast to identify the producer of the content) is visible (audible), in which case the watermark is said perceptible, or not (imperceptible). In some cases, the watermark is intentionally left perceptible, but in the NN context this has little sense because the main goal is to watermark a NN to the minimum extent to avoid altering its expected behavior.\n\nDomain of embedding: the watermark signal may be embedded by directly modifying the original data of the host object (like the vertex coordinates of a 3D model or the pixel values of a digital image) or the original data may be transformed in a different domain, like the Singular Values Decomposition domain or the Wavelet Transform domain. In these cases, the watermark is embedded into the computed coefficients and finally the modified coefficients are converted back to the original domain by means of an inverse transform. In the first context the algorithm is said to work in spatial domain, time domain or host domain, whereas if a transform is involved, the watermark is embedded into the frequency domain. In the case of NN, algorithms may operate directly on the network parameters and structure or transform them in some chosen frequency domain before embedding.\n\nIn this paper, we describe NeuNAC (Neural Network Authenticity Checker), a fragile watermarking algorithm that may be applied to generic (deep or not) neural networks: it adopts a white-box approach to protect network structure and weights, it is blind, fragile and secure. Security is ensured by embedding the watermark in a secret frequency domain defined by the Karhunen-Lo\u00e8ve Transform (KLT). Even if the algorithm is non-reversible, we will show that for many different tasks there is no degradation in performances of the watermarked neural network with respect to the original one. Starting from the framework proposed in [5], in this paper we devise a solution to face the new challenges posed by the digital object to be watermarked, i.e., a neural network. In this context, in fact, in addition to showing that the watermarked object has minimal distortion with respect to the original one (as it is normally done with images), one needs to take into consideration also the properties of reliability and performance. Specifically, one should demonstrate that it is very hard to find inputs producing diverging outputs for the host and the watermarked neural networks. Moreover, the intrinsic representation of a neural network needs a watermark embedding method that: i) is able to cope with the floating-point coding of the network weights and ii) protects the network structure.\n\nThe main properties and innovations of the NeuNAC algorithm with respect to the previous works are:\n\nimproved NN tamper detection and localization: the integrity of the NN may be efficiently verified and any alteration to the parameters or to the structure of the NN can be detected with very high probability; moreover, the algorithm may localize at block level (as defined in Section 4) the tampered area; security: given that the watermark string is built applying a cryptographic hash function to some NN parameters and successively embedded into a secret frequency domain defined by a secret key, the watermarked object is protected against intentional and unintentional attacks and the watermark signal cannot be extracted by unauthorized entities; lower distortion: given that the modification of the weight values is made in the less significant digits of the floating-point representation, the distortion introduced by the watermark embedding is lower than the one the algorithm introduces for images; adapted watermark generation strategy: the watermark generation uses a secret key and the MSBs of some weights that are not modified by the embedding procedure; efficacy: as we will show in Section 5, the performances of the watermarked NN model are not impacted by the slight modifications due to the insertion of the watermark; fast and light integrity check: the complexity of the verification algorithm is linear in the number of NN parameters and it is designed to allow a sampling-based check of the integrity of the network so to make it usable in real time applications; targeting embedded systems: NeuNAC has been designed from the get-go to target embedded systems. Its unique design allows a hardware implementation of the verification process adding an additional level of security to the system.\n\nThe NeuNAC algorithm has been developed for DNNs deployed into safety-critical systems, such as (semi) autonomous car driving systems, energy monitoring systems etc., for which (intentional) tampering might cause severe and seriously damaging accidents. In these systems, a periodic and possibly asynchronous check for integrity should be constantly carried out. For instance, let us consider a DNN installed on a self-driving car to recognize pedestrians. It is not enough to check the integrity of the network at startup, as a malicious attacker could compromise the network afterwards. We propose to constantly and asynchronously validate the integrity of the network during its normal use and stop the system as soon as a tampering is detected. The validation phase of NeuNAC is very fast (few milliseconds) and can be easily implemented into a cheap hardware device.\n\n\nRelated works\n\nDue to the widespread diffusion of images over the Internet, digital image watermarking has received much attention for more than a decade [3]. Recently, the massive deployment of Neural Networks, which require large engineering and computation efforts to be trained and possibly also to perform critical tasks, has posed the problem of protecting the intellectual property and the integrity of such networks.\n\nFor what concerns black-box algorithms, [32] proposes a DNN watermarking algorithm for copyright protection; ownership can be proved by querying the proprietary DNN model operated by a third party. To obtain this result, the model is trained with secret pre-defined watermark patterns that produce specific classifications. Also, in [1] the authors use backdooring and the definition of a trigger-set to watermark a DNN that can be subsequently tested for copyright protection without accessing the network parameters. [11] proposes a framework to perform robust watermarking of a DNN for embedded systems: to achieve a black-box approach, the DNN is fine-tuned with original examples both unmodified and modified with a mark derived from a signature, the latter examples producing a different classification label. [6] describes the Black-Marks framework: this black-box approach fine tunes a DNN to embed a binary watermark string by first creating a set of pairs (key image, label) with an adversarial attack and then embedding the set into the DNN. Adversarial examples are used in [20] to watermark a model by slightly altering its decision frontier. Szyller et al. [28] modify the classification output of the neural network in order to prevent model stealing attacks. Another black-box approach, tailored to protect DNNs for image processing operations rather than classification tasks, is presented in [25], where the authors exploit the overparameterization of the DNNs to produce a predefined output image when given a particular input image.\n\nWang and Kerschbaum in [30] show that the white-box method proposed in [23,29] may be attacked by exploiting the weight variance and the watermark removed with overwriting operations that embed another watermark: moreover, the new watermark does not suffer of the defect present in [23,29]. In a more recent paper [31] Wang and Kerschbaum present a robust watermarking algorithm which is undetectable and whose watermark extraction function is performed by a deep neural network trained with an adversarial network.\n\nThe above approaches differ from NeuNAC because their task is copyright protection, so the watermark must be robust to attacks that aim at its removal. All of these approaches use a black-box algorithm during ownership testing, while some finetune the networks and others build appropriate inputs that enable the watermark detection. NeuNAC, on the contrary, is intended for integrity protection. The watermark needs to be extremely fragile so that it easily breaks when the DNN is altered.\n\nThe only method we are aware of that is designed for integrity protection as NeuNAC is presented in [15] where the authors propose VerIDeep. VerIDeep is a black-box method that builds special examples that are sensible to minimal modifications of the neural network. Submitting them to an altered DNN would make the network to produce outputs that are different from the ones expected, thus allowing the system to identify that the network has been altered. Even though Ver-IDeep shares several properties with NeuNAC, it is not designed for embedded systems because its black-box verification procedure requires querying the network synchronously, i.e., the network cannot be used while verifying its integrity. Neu-NAC verification procedure, instead, can be run asynchronously while the DNN is in use.\n\n\nEmbedding tools\n\nNeuNAC makes use of two important tools to embed the watermark into the neural network weights, namely the Karhunen-Lo\u00e8ve Transform (KLT) and Genetic Algorithms (GA). This section gives a brief description of both; a detailed explanation of their use and methods of application is presented in [5].\n\nThe Karhunen-Lo\u00e8ve Transform (also known as Principal Component Analysis, PCA) belongs to the set of linear transformations. A linear transformation is a mapping from an n-dimensional vector space to an m-dimensional vector space that can be described by a matrix A (called kernel of the transformation) of size m \u00c2 n. In our case n \u00bc m.\n\nGiven two vector spaces V, W of dimension n and a vector x 2 V then the forward transform is computed as y \u00bc Ax, y 2 W: the elements of y are called coefficients of the transform. If A is square and full rank, the inverse transformation can be com-\nputed as x \u00bc A \u00c01 y.\nExamples of linear transformations are the Discrete Cosine Transform (DCT) and the Fourier transform which have fixed kernels (for a pre-determined value of n).\n\nThe KLT has not a fixed kernel: in fact, its kernel matrix may be derived from a set of vectors X & V, card X \u00f0 \u00de > n (where card X \u00f0 \u00de represents the cardinality of the set X). Given a set of vectors X the transformation is computed as it follows:\n\nfirst the mean vector of X, l \u00bc E X f g, where E : f g represents the expected value operator, and the covariance matrix\nC \u00bc E X \u00c0 l \u00f0 \u00deX \u00c0 l \u00f0 \u00de T n o are computed, then\nthe eigenvectors of C and their associated eigenvalues are evaluated and sorted by descending order of eigenvalue; the sorted eigenvectors are used to build the orthonormal kernel matrix A arranging them by rows.\n\nThe forward KLT of a vector v is computed as\ny \u00bc A v \u00c0 l \u00f0 \u00de \u00f01\u00de and the inverse KLT is evaluated with v \u00bc A \u00c01 y \u00fe l:\u00f02\u00de\nAs it will be presented in the following, the neural network parameters may be given a total order and grouped into contiguous non-overlapping sequences: from each sequence it is possible to compute a set of n features (called, in the following section, Watermark Embedding Unit) to be used for embedding a digital watermark. In particular, the neural network parameters are modified so that the KLT (defined by an n-dimensional kernel A) coefficients computed on the features store the watermark string.\n\nThe KLT kernel may be computed from any set of n-dimensional vectors: keeping this set secret allows the calculation of the coefficients of the transform, and consequently the watermark embedding space, only to authorized entities making the overall system secure. A simple method to have a set of n-dimensional vectors is to use the pixel values of an image or the samples of a sound, but obviously other approaches are possible.\n\nA detailed presentation of KLT may be found in [9]. The modification of the neural network parameters to embed the watermark bit string into the features' KLT coefficients requires the solution of a complex non-linear problem. One possible method to cope with this non-linearity is to use a Genetic Algorithm. The reasons for this choice are the simplicity of the implementation, the availability of several ready to use libraries, the very good performances both in terms of solution quality and running time, and the fact that can be easily parallelized for even faster execution. GAs are a computational method that emulates the evolution of a population of biological individuals. Individuals are evaluated according to a fitness function and made evolve towards an optimal solution (i.e., one having the best value of the fitness function). A problem may be solved using a GA if its solutions: 1) can be stored in a sequence (record) of parameters: each instance of such a sequence represents an individual; 2) it is possible to evaluate the degree of goodness of an individual to fit the solution computing a (fitness) function.\n\nA GA starts by generating (randomly or supervised by some problem-driven heuristic) a population of individuals; then, it evolves this population in a series of epochs. In each epoch individuals are reproduced to build a new population for the next epoch. The individuals are selected, according to their fitness value, to generate offspring with the objective of improving the quality of the solutions encoded. The reproduction is performed by mixing their descriptions; moreover, a mutation is randomly applied to some individuals to extend the solution search space. The population for the new epoch is built taking some individuals from the old population and some among the offspring according to various possible strategies. The evolution process stops after a pre-defined number of epochs is reached or an individual with the desired fitness value (e.g., below a predefined threshold) is obtained.\n\nA deeper discussion on GAs may be found in [8,13] and an analysis of GA parameters in this context was presented in [4].\n\n\nNeuNAC algorithm\n\nThe Neural Networks Authenticity Checker (NeuNAC) algorithm has the objective to insert a fragile watermark into the parameters of a trained DNN, without disrupting the ability to perform its task at the same level of performances as without the watermark. By appropriately grouping parameters into blocks, the presented algorithm also protects the structure of the model as a by-product of the embedding process (i.e., it is able to detect changes in the structure of the model in addition to changes to the weights).\n\nThe main modules of the method are the Embedder and the Extractor. Moreover, following the MIMIC framework [5], three other complementary modules are employed to perform accessory functions. The data flow between these modules is shown in Fig. 1. The description of the modules is presented in the following.\n\nThe Key generator module derives a KLT orthonormal basis (i.e., a kernel) from a secret set of vectors of the required size: presently we use n \u00bc 32 (see the Section 3). The computed orthonormal basis defines a secret embedding space that must be known to both the Embedder and the Extractor modules (like a secret key in symmetric encryption algorithms). We suggest using a secret image to form the set of vectors from which compute the KLT kernel, as proposed in [5].\n\nIn order to apply the embedding procedure, the parameters (each one represented with a 4 byte float in IEEE 754 format) of the DNN are grouped into blocks consisting of S elements each (S \u00bc 16 in the running example), called Parameter Unit (PU). There are several ways to make these groupings depending on the tampering localization granularity one would like to achieve. The simplest way to build the PUs is by extracting all the parameters from the DNN model (given a total order) and splitting them into sequences of length S. Another possible approach consists in proceeding level-wise, such as extracting all the parameters in a level and splitting them in sets of S elements. Yet another approach could be to consider each unit input weights and extracting the PU from them. It should be pointed out that even the first strategy outlined above allows to detect a structural change to the DNN, such as an added or removed unit, connection or level, but not a unit type replacement (such as swapping a sigmoid for ReLU). As a matter of fact, any such structural change will result into a different grouping of the weights and therefore a possibly different watermark will be extracted, signalling the tampering.\n\nA portion of the watermark bit string w, built by the Watermark generator module, will be embedded in each PU. The string w is computed as a function of some DNN parameters (that will not be modified by the embedding step, as it will be clear in the following): starting from some bytes of these parameters a cryptographic hash function (c.h.f.), like the Secure Hash Algorithm 3, SHA-3 [16], is initialized and called to produce a bit string of the desired length. The security of the c.h.f. is not strictly required given that the embedding space is secret (the KLT kernel is known to embedder and extractor only), nonetheless its application is considered a good practice aimed at thwarting any possible attack.\n\nGiven a PU built as described above, a 32 bytes Watermark Embedding Unit (WEU) is derived concatenating the 16 parameters' least significant bytes (LSB) considering each value in its binary format (4 bytes float representation in IEEE 754 format) and a fingerprint of 16 bytes computed from the 3 most significant bytes (MSB) of each parameter value (see Fig. 2). In particular, the fingerprint is computed as follows: the 3 MSBs of each parameter value are concatenated together to form a string of bytes that is input to an MD5 c.h.f. [26] that returns a 16 bytes digest. In Fig. 2 note the bytes marked with vertical stripes: they are the LSBs of the mantissa of each float value. As it will be discussed presenting the Embedder, the watermark is inserted by altering only these bytes, while keeping unaltered the fingerprint bytes.\n\nThe Embedder produces a watermarked (Deep) Neural Network with a fragile watermark, operating one WEU at a time and independently among WEUs (thus, the process can be easily parallelized): each WEU is assigned a (consecutive) portion w s of the w bit string output by the Watermark generator. If m is the length of the string w s then we say that m is the payload in bpb (bits per block): this algorithm parameter is chosen a priori taking into account the fact that large values require more embedding effort but reduce the probability that an attack on a single WEU goes undetected, as it will be discussed in the conclusions.\n\nEach WEU is considered a vector i 1 ; where count\u00f0 c 1 ; c 2 ; \u00c1 \u00c1 \u00c1 ; c 32 \u00f0 \u00de ; w s \u00de returns the number of watermark bits correctly present into the coefficients. Note that only individuals for which count returns m will be considered as solutions to the optimization problem. The GA is run for a maximum number of epochs (in all experiments reported below was 2000) or until the Fitness gets smaller than a threshold e, whichever comes first. The GA evolves a population of 100 individuals, uses a single point crossover operator with probability p c \u00bc 0:8, a mutation operator that increments of AE1 one or more g i , with probability p m \u00bc 0:05, and a population replacement factor of 95% with elitism.\n\nSome possible methods to store a bit string w s into a set of coefficients are presented in [5]. If the length of w s is m then one possible storing rule is to consider a (predefined) subset of m coefficients, choose m positions and assign a bit to each coefficient in the subset: a coefficient c is considered as carrying a bit b in position p if and only if\nb \u00bc round c2 \u00c0p \u00c0 \u00c1 mod2:\u00f04\u00de\nWhen this rule applies, we say that the set of coefficients store w s if the m chosen coefficients carry the bits of w s in the m chosen positions.\n\nWe found the GA particularly suitable for solving the non-linear problem of minimally modifying a set of integer numbers i 17 ; i 18 ; \u00c1 \u00c1 \u00c1 ; i 32 \u00f0 \u00de so that their KLT coefficients store a specific bit string. When the WEU stores the watermark bit string, the corresponding LSBs are used to replace the original LSBs of the DNN parameters.\n\nWhen the GA has processed all the WEUs then the DNN model with the new modified parameters contains the fragile watermark. This watermark allows for the integrity check that can be performed by the Extractor and Verifier modules: note, in fact, that the KLT coefficients of each WEU depend not only on the parameters' LSBs but also on the MSBs parts.\n\nThe Extractor first calls the Watermark generator module to build the expected watermark string w XP , that is the string that should be contained in the DNN if it was not forged. After that, the module builds the WEUs and using the KLT basis provided by the Key generator module extracts 32 coefficients from every WEU and from them gets the m bits according to the method used in embedding (e.g., the one defined in (4)). By concatenating all the bit strings extracted from the WEUs the Extractor composes the extracted watermark string w XT .\n\nThe Verifier module matches the two strings w XP and w XT ; if they are equal then the DNN is marked as authentic, otherwise it is tagged as potentially forged. It is quite straightforward to mark the forged WEUs because given a position number 0::T \u00c0 1 \u00bd to every WEU according to the portion of the watermark string w assigned during embedding, then the length of w (and consequently of w XP and w XT ) will be mT, where m is the bpb payload: numbering the bits of w from 0 to mT \u00c0 1, if the bits of the strings w XP and w XT in position F differ then the F=m b c-th WEU has been forged. A DNN may be forged in several different ways, namely: modifying at least one of the weights, or altering one of the parameters of the activation functions, or removing or adding a single unit or a whole level to a DNN, or shuffling the order of the levels.\n\nNeuNAC can protect the integrity of a DNN and detect the mentioned tampering attacks; in particular, if at least one of the weights or activation function parameters has been altered then the block containing the changed weight/parameter will be tagged as tampered. In all the remaining cases, the entire DNN will be tagged as tampered, because w XP and w XT will be different in a large number of WEUs, and when this happens it is very likely that the network structure has been tampered with.\n\n\nExperimental evaluation\n\nIn Subsection 5.1 we evaluate the performances of the proposed watermarking method on several Deep Neural Network architectures and show its ability to detect tampering without affecting the DNN performances. As a further evidence of how effective the technique is to avoid influencing the DNN performances, in Subsection 5.2 we leverage adversarial attacks as a way to force the watermarked network to diverge from the original one.\n\n\nPerformance results\n\nIt should be pointed out that here we are not interested in the absolute performances of the considered DNNs on the example application domains, because they are not relevant to evaluate a watermarking method. Instead, we are interested in showing that such performances are not affected by the introduction of a watermark signal, that obviously alters the DNN parameters. To such an aim, we will measure the distortion introduced by the embedding phase and report performances of the proposed watermarking method (as usually done in the field) in terms of Peak Signal-to-Noise Ratio (PSNR, the higher the better) and distortion computed as Mean Absolute Error (MAE, the lower the better). PSNR and MAE are computed from the weights in the network as follows:\nPSNR \u00bc 10log 10 max w i 2W w i j j 2 P w i 2W;w 0 i 2W 0 w i \u00c0w 0 i \u00f0 \u00de 2 card W \u00f0 \u00de \u00f05\u00de MAE \u00bc P w i 2W;w 0 i 2W 0 w i \u00c0 w 0 i card W \u00f0 \u00de\u00f06\u00de\nwhere W and W 0 are the sets of weights of the host and watermarked NN respectively, card W \u00f0 \u00de represents the number of elements in the set W and w i and w 0 i are the weights in corresponding positions in the host and watermarked NNs. Moreover, we also report performances in terms of classification accuracy difference between the original and watermarked DNN and show that there is no difference. Table 1 reports the characteristics of the considered DNNs along with the datasets and tasks on which they have been tested. We selected several different DNN architectures, ranging from simple multilayer perceptron (2 fully connected layers) to Deep Convolutional Networks, such as Resnet29, to Recurrent Neural Networks, with different number of parameters, in order to show the ability of NeuNAC to watermark any network. These networks have been trained and tested on publicly available benchmarks, such as MNIST [19], CIFAR-10 [18] and Nietzsche [24] datasets. Table 2 reports the performances of NeuNAC: the quality of the watermarked networks is extremely high, as shown by the very low distortion introduced by the embedding process and by the fact that there are no differences in performances between the original and the watermarked networks.\n\nA comparison with other approaches is not straightforward as there are no white-box approaches for fragile watermarking, as far as we know, and the black-box approaches cannot report distortion values, as some of them are not actually embedding a watermark into the network. Nevertheless, Table 3 reports performance degradation and false positive rates of some watermarking methods as published by the authors of these studies and averaged over the set of experiments they performed. Most of them insert a robust watermark and are black-box methods, so a direct comparison is not possible.\n\nThe first two methods reported in Table 3 show a degradation in the performances of the watermarked networks and being robust watermarking methods do not report detection rates. BlackMarks and DeepMarks show an improvement in performances because the embedding process fine-tunes the target network, so improving its performances, but they have a low false positive rate, that goes to zero for specific settings. VeriDeep is a fragile watermarking method that shows very similar performances as NeuNAC but, being a black-box method, its detection strategy can only spot modifications to the network that change the classification output of sensitive examples. NeuNAC, instead, can detect even the smallest change in more than 95% of the cases, as shown by the following sensitivity of the watermark experiment, that establishes the ability to detect tampering.\n\nIt is worth noting that, if the network has not been tampered with, NeuNAC verification procedure is guaranteed to correctly stating that the network is authentic, i.e., there are no false positives. Also, any structure modifications to the network, such as removing a layer or even a single connection, will result in an extracted watermark that is out of sync with the embedded one, as the watermark bit string also depends on the size of the network, and the network will be correctly identified as tampered. Moreover, a fine-tuning of the network will result in changing many weights of the network, and even very small changes might drastically change the binary representation of some parameter values, and therefore the extracted watermark will be different from the embedded one.\n\nIn order to provide a quantitative measure of the method sensitivity, we performed the experiments reported in Table 4. The table reports the percentage of blocks altered by performing a single fine-tuning step (1 epoch) on the considered network architectures along with the percentage of blocks found tampered by the verification procedure of NeuNAC w.r.t. the modified blocks. As pointed out above, any manipulation of the networks results in more than 92% of altered blocks, on average, and NeuNAC verification procedure is able to detect 99:65% of such alterations. To be clear, to detect a tampering attempt, the verifier only needs to identify the change of a single block. Hence, the experiments show the extreme sensitivity of NeuNAC on these kind of network modifications.\n\nFurthermore, we consider every single WEU and systematically modify by AE1 or AE2 the value of each byte of the 16 bytes corresponding to the LSBs of the DNN parameters. This modification is the smallest possible perturbation as it is applied to the least significant bits of the mantissa of the DNN parameter. Table 5 reports the number of times a WEU is detected as Table 1 Benchmark neural network architectures. Here, 32C5(1) indicates a convolutional layer with 32 output channels and 5 \u00c2 5 filters applied with a stride of 1, MP2 (1) denotes a max-pooling layer over regions of size 2 \u00c2 2 and stride of 1, D(0.2) is a dropout layer with 0:2 probability and 512FC is a fully-connected layer with 512 output neurons. Moreover, LSTM stands for Long Short Term Memory cell.\n\n\nModel No.\n\nModel Type Model architecture Total # of parameters Task  Dataset   1  MLP  784-512FC-10FC  623290  Classification  MNIST  2 Shallow CNN 28*28-32C5 (1) [20] Black-box, robust \u00c00:26 low N/A BlackMarks [6] Black-box, robust 0:009 low N/A DeepMarks [7] White-box, robust 0:04 low high VeriDeep [15] Black  Table 1, as the procedure does not depend on the specific architecture of the DNN model, but only on the type of modification performed.\n\nAs it can be noted, such a small tampering goes undetected in less than 5% of the cases, while, e.g., VeriDeep would not be able to detect such tampering (as implied by the second experiment in the next Section which introduces an attacking technique that is arguably more precise than VeriDeep in detecting these kinds of tampering). We would also argue that such small tamperings would not produce any meaningful behavioral change in the network, making them not worthwhile as a possible attack vector.\n\n\nAdversarial experiments\n\nNeuNAC protects from network tampering without compromising the predictions of the model. In this section we try to investigate this statement by studying the difference in behavior of the watermarked network w.r.t. the original network. To do that, we designed two sets of experiments where, using different approaches, we build tampered images designed to make the two networks differ in their outputs (when they do, we say that the predictions of the two networks diverged on that input). In Section 5.2.1 we shall try to find the closest adversarial image [27] for one of the two networks and check how the other network behaves on the tampered input. As we shall see, the two networks behave identically in these situations and a more focused attack is needed to compromise this behavior. In Section 5.2.2 we devise a technique that leverages the knowledge of both networks to build examples that make their predictions diverge (using a different technique, but much in the same spirit of VerIDeep [15] approach). We anticipate that also in this case it is very hard to fabricate an input image that exercises the small differences in the networks introduced by our watermarking algorithm. Since the introduced technique leverages more information than VerIDeep and is almost never able to create adversarial examples that make the two networks diverge, we conclude that VerIDeep would not be able to detect the tampering on the network introduced by our watermarking algorithm. Also, since our algorithm would, instead, be able to detect such small changes, we conclude that NeuNAC is much more likely than VerIDeep to detect very small changes to the network. This is not an unexpected result, because VerIDeep, being a black-box method, works in a more constrained setting.\n\n\nFGSM adversarial examples\n\nThe Fast Gradient Sign Method (FGSM) is a technique proposed by Goodfellow et al. [10] for the problem of generating adversarial examples. In that paper a fast algorithm is presented that is able to inject a small amount of well-crafted noise into an image and make the network to fail in recognizing it. The algorithm works by updating the image x using the rule:  Experiments were conducted on the MNIST and the CIFAR datasets using three different models on MNIST and two different models on CIFAR. For each dataset/model combination, we extracted 5; 000 training samples and 5; 000 test samples and generated adversarial examples for them. We repeated the process twice: once using the original network to build the adversarial image and once using the watermarked network. A total of 100; 000 images were, thus, generated. For each image we start with \u00bc 0:001and then increase this value by 0:001 until either we reach 0:5 or we observe a change in the classification from the tested network. When we reach 0:5, we label that experiment as a failure in generating the adversarial example. Among the 100; 000 images we generated, we have observed 9; 008 failures. In the rest of the cases, we used the adversarial image to check the predictions of the two networks. In all cases the watermarked network showed to be very robust to the attack: the two networks predicted the same label for the adversarial example.\n\nIn addition to the above result, we leverage some side information from the performed experiments to further investigate the differences between the networks. In particular, since we repeated the experiments using both networks on the same set of images, we are in the position of checking if, despite giving identical outputs, they behaved differently during the experiments. Tables 6 and 7 show for each dataset/model the number of times the FGSM algorithm failed to build the adversarial image when the original network is used (column 3) and when the watermarked network is used (column 4). In all cases these numbers match, so in this respect there is no difference in the behavior of the two networks. Columns 5 and 6 report the average needed to generate the adversarial image (failures are not counted). As we can see, only in three cases (marked as *1, *2 and *3) the two networks showed very minimal differences. Details of the problems found in these three cases are reported Table 8. For each case number (which references the corresponding lines on Tables 6 and 7) we report the id of the image, the value found by the original network ( column) and of the watermarked network ( w column), the correct label for the image (y column) and the labels assigned by the original network to the attacking image (y 0 column) and by the watermarked network (y 0 w column). For case *1, we found three images with a small change in the behavior of the networks. For image 4010 and 4101 we can observe that a slightly different has been needed to produce the adversarial example. Results for image 881 is more interesting as the is the same, but the adversarial labels differ. To clarify: the difference is caused by two different attacking images found by the FGSM algorithm obtained by launching the algorithm on the two networks using the same input. The two networks do not diverge on these inputs, but they agree on different labels depending on which network was used to generate the input. We speculate that, in these cases, the gradient pointed to a place where labels 9, 5 and 6 competed and that a slight deviation in the direction caused the change in the labels assigned by the networks. On the examples reported for cases *2 and *3, except for image 4434, we observe only a small deviation of the values. Example 4434 is the most interesting case since we observe a deviation in both and the adversarial labels.\n\nThe seven cases we reported show that there exist properties of the networks that do change due to the presence of the watermark. Based on the results of the experiments, we conjecture that the gradient of the loss function taken with respect to the input image is very seldomly and very slightly changed by the watermark. The conjecture explains what we observed in the seven cases (out of the 100; 000 experiments) we reported above.\n\n\nTwo networks adversarial examples\n\nThe FSGM experiments provide evidence that it is very hard to find cases where the two networks differ in their outputs. In order to further test this claim, we devised a novel adversarial algorithm explicitly tailored to make the two predictions diverge.\n\nThe technique is general but let us assume, for the sake of the discussion, that the activation function on the output of the network is a softmax. Let us denote with N\u00f0x\u00de and N 0 \u00f0x\u00de the outputs of the original and of the watermarked networks respectively. Let l denote the cross-entropy loss and let y 0 and y 1 be the one-hot-encoding of the best and of the second-best predictions by N\u00f0x\u00de evaluated once and for all before the algorithm start. We define the loss L of our problem as \nL N x \u00f0 \u00de; N 0 x \u00f0 \u00de \u00bc l N x \u00f0 \u00de; y 0 \u00f0 \u00de\u00fel\u00f0N 0 x \u00f0 \u00de; y 1 \u00de\u00f08\u00dex x \u00c0 gr x L\u00f0N x \u00f0 \u00de; N 0 x \u00f0 \u00de\u00de:\u00f09\u00de\nIt should be apparent that by descending the gradient of that particular loss function, we are searching for an input image x that makes N\u00f0x\u00de to predict y 0 and N 0 \u00f0x\u00de to predict y 1 , hence making the two networks diverge. The particular choice of y 0 and y 1 simplifies the task since y 0 is already the label that is ranked the highest by network N\u00f0x\u00de and y 1 is its second-best choice (hence the easiest label to ''reach\" by updating x).\n\nWe experimented with the same dataset and models described in Section 5.2.1. In each experiment we adopted Adam [17] for performing the gradient descent and run it for 10; 000 rounds (stopping every 10 rounds to check if the network outputs diverged). The initial value of the learning rate g has been set to 0:001.\n\nDue to the high cost of the optimization procedure, we could not afford to experiment with 5; 000 images per experiment and therefore reduced that number to 100. In total we attempted the construction of 1; 000 adversarial images. In two cases, we found adversarial images that were able to make the watermarked network and the original network to behave differently. In both cases, the attack succeeded on the baseline neural network model, while more complex networks never diverged under this type of attack. The two images that made the networks to diverge are reported in Figs. 3 and 4.\n\nThis experiment shows how difficult it is to find a valid attack that makes the two networks to produce different outputs. While we acknowledge that it can be done, we would like to stress the fact that even in the most favorable conditions (simultaneous white box attack on both networks) the attack succeeded only on 0:2% of the trials and with a large computational cost.\n\nWe also verified that the attack is very brittle and the smallest change to the images makes the two networks to agree again on the answer. Specifically, we tried to perturb the images in two different ways: in one case we lighten up the image by the smallest possible value (we added 1 to the value of every pixel in the image), in the other case we made the smallest possible modification to the image, i.e., we added (and, in a distinct experiment, subtracted) 1 to a single pixel in the image. In the first case we verified that the networks went back to agreeing on the assigned labels after the lighting up of the image. In the second case, we systematically changed every single pixel in the image and verified that, with the exception of a single pixel position (let it be position p), the change would ruin the attack, making the two networks to agree again on the label to be assigned. In the specific case of the pixel in position p, we verified that changing the perturbation to \u00fe2 (or \u00c02) would also ruin the attack.\n\nIn summary, all the experiments we performed show that it is almost impossible to induce a different behavior between the original and the watermarked networks. While adversarial attacks are possible, they are very hard to find: they would work only on the simplest models, the attacker would need to have the two networks in hands and he/she would need to be ready to sustain large computational costs. They would also be very brittle: the smallest change in the attacked image would defeat the attack. Brittleness is particularly important in many contexts since it makes these kinds of attack very hard to deploy in real scenarios (e.g., in the case of self-driving vehicles, the noise in capturing the signal would be enough to make the attack fail).  \n\n\nDiscussion\n\nThe embedding procedure of NeuNAC results in very low distortion that does not influence the performances of the neural networks, as shown by the experiments described in the previous section. We also proposed a novel way to validate a fragile watermarking algorithm for DNNs, by performing a thorough analysis of sensitivity of tampering detection: this analysis reveals the ability of the verification procedure to detect the smallest tampering in more than 95% of the cases. As mentioned, any other modification of a DNN would result in larger tampering that will be easily detected.\n\nIn principle, even a small change in a network parameter might affect the network performance, as it is the case with generative networks that produce numerical outputs. In such networks, the output generated by the watermarked version of the DNN differs from the original one. This is the reason why NeuNAC, in its current implementation, cannot be used to  watermark generative neural networks, such as DeepDream [22]. In contrast, in case of classification networks, the tiny changes introduced by NeuNAC are cut off by the classification and/or MaxPooling layers. Almost all the existing works on neural network watermarking are about copyright protection, being VeriDeep the only notable exception, but integrity protection and authentication are very important tasks that require a fragile watermarking scheme such as the one implemented by NeuNAC.\n\nAs previously stated, the proposed method is secure because the watermark embedding space is secret. In case of a payload of m bpb the probability that a random modification of the NN parameters in a PU goes undetected is 1=2 m , thus the probability that an attack changing the contents of k PUs is not identified by the proposed scheme is 1=2 m \u00c0 \u00c1 k \u00bc 1=2 mk : this probability exponentially drops with the number of tampered PUs.\n\nOne drawback of the current implementation of NeuNAC is that it does not protect from activation function changes, when there is no change in number of parameters. A possible solution that will be investigated in the future is to make the watermark also dependent on the structure and the activation functions of the neurons (right now is only dependent on the number of parameters). Another aspect that needs more investigation is how to split the network structure in meaningful parts that could be watermarked separately and allow to better localize the tampering or make the method resilient to possible permutations of network blocks (e.g., a convolutional layer) that do not change the network behaviour.\n\n\nConclusions\n\nIn this paper, we presented NeuNAC, a white-box watermarking method for integrity protection of (Deep) Neural Networks. It can be applied to any kind of neural network architecture (deep or shallow), as it inserts a watermark bit string into the parameters of the network. The order in which the parameters are considered is relevant, as this also allows to protect the structure of the network from neuron and/or layer rearrangement/addition/removal operations. NeuNAC quality is outstanding, as it does not have any impact on the performances of the network and the average PSNR is greater than 181 dB.\n\nThe main goal of NeuNAC is to protect the integrity of neural networks for safety-critical systems once deployed into their operating environment. In order to guarantee the authenticity of the network, the watermark verification process has been designed to be very fast so that it can be performed frequently. It can also work on a sampled set of WEUs and it can be realized into a hardware device for even faster and (hence) secure execution.\n\n\nDeclaration of Competing Interest\n\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\ni 2 ;Fig. 1 .\n21\u00c1 \u00c1 \u00c1 ; i 32 \u00f0 \u00deof 32 bytes coding integers: the GA modifies the sixteen bytes i 17 ; i 18 ; \u00c1 \u00c1 \u00c1 ; i 32 \u00f0 \u00de corresponding to the LSBs of the DNN parameters in the WEU (i.e. the vertical striped bytes in Fig. 2) in such a way that the 32 coefficients c 1 ; c 2 ; \u00c1 \u00c1 \u00c1 ; c 32 \u00f0 \u00de \u00bc KLT i 1 ; i 2 ; \u00c1 \u00c1 \u00c1 ; i 32 \u00f0 \u00de of the KLT of the WEU (computed according to equation (1)) Interconnections between the modules of the proposed algorithm and data interchanged. corresponding w s string. Each individual of the GA population consists of 16 integers g 1 ; g 2 ; \u00c1 \u00c1 \u00c1 ; g 16 \u00f0 \u00de defining the modification of the integers i 17 ; i 18 ; \u00c1 \u00c1 \u00c1 ; i 32 \u00f0 \u00de ; the GA fitness function privileges small modifications (e.g., 0, \u00fe1, \u00c01, \u00fe2, \u00c02,. . .) and requires that c 1 ; c 2 ; \u00c1 \u00c1 \u00c1 ; c 32\u00f0 \u00de store w s . In other terms, the GA tries to minimize the magnitude of the updates needed to change i 17 ; i 18 ; \u00c1 \u00c1 \u00c1 ; i 32 \u00f0 \u00de so that the KLT i 1 ; i 2 ; \u00c1 \u00c1 \u00c1 ; i 32 \u00f0 \u00de coefficients carry (store) the watermark payload. In particular, we used the following fitness function that tries to combine the quality of the solution and the insertion of the watermark: \u00fe m \u00c0 count\u00f0 c 1 ; c 2 ; \u00c1 \u00c1 \u00c1 ; c 32 \u00f0 \u00de ; w s \u00de \u00f0 3\u00de\n\nFig. 2 .\n2Structure of the Watermark Embedding Unit.\n\n\na percentage of all possible modifications. The reported values for Resnet29 model are consistent with all other DNN models outlined in\n\n\ne., the adversarial image x 0 is built by moving x in the direction that causes the fastest change in the output of the network. In our experiments, we start with a very small value of and increase it until the network changes its prediction. The resulting image is very similar (very often indistinguishable) to the original image and a human is perfectly able to recognize the correct subject. We argue that these are important examples to check when we try to demonstrate that the watermarked network (does not) behaves differently from the original network: two networks that are operationally different have different decision boundaries and examples that lie nearby the decision boundaries are more likely to exercise the difference in behavior. This is exactly the case with FGSM examples since examples are modified using very small steps ( \u00bc 0:001) and we stop as soon as the output of the attacked network changes.\n\nFig. 3 .\n3Original (left) and adversarial (right) images that causes the two networks to output different labels (CIFAR dataset).\n\nFig. 4 .\n4Original (left) and adversarial (right) images that causes the two networks to output different labels (MNIST dataset).\n\nTable 2\n2Performance results.Model No. \nPSNR [dB] \nMAE \u00bd\u00c210 \u00c09 \nPerformance difference \n\n1 \n172:33 \n0:324 \n0 \n2 \n172:58 \n0:195 \n0 \n3 \n168:46 \n1:66 \n0 \n4 \n178:59 \n0:209 \n0 \n5 \n189:02 \n0:383 \n0 \n6 \n190:54 \n0:144 \n0 \n7 \n183:36 \n19:9 \n0 \nAverage \n181:99 \n3:26 \n0 \n\n\n\nTable 3\n3Comparison results.Method \nMethod type \nPerformance difference (%) \nFalse positive rate (%) \nDetection rate (%) \n\nWang & Kershbaum [31] \nWhite-box, robust \n\u00c00:4 \nNot reported \nN/A \nLe Merrer et al. \n\nTable 4\n4Tampering detection after a fine-tuning step.Model No. \n% of altered blocks \n% of recognized tampered blocks \n\n1 \n9 1 :51 \n99:69 \n2 \n100 \n99:59 \n3 \n9 9 :15 \n99:57 \n4 \n100 \n99:59 \n5 \n9 7 :06 \n99:62 \n6 \n6 7 :46 \n99:60 \n7 \n100 \n99:88 \nAverage \n92:73 \n99:65 \n\n\n\nTable 6\n6FGSM experiments on the CIFAR dataset. Numbers on the left of the table are referenced in Table VIII and corresponds to experiments where we observe some difference in the behavior of the networks. and generate the adversarial examples by descending the gradient of L using the following update rule:Model \nTrain/Test \nNumber of failures \nAverage \n\nOriginal \nWatermarked \nOriginal \nWatermarked \n\nBaseline \ntrain \n287 \n287 \n0:048649 \n0:048649 \nbaseline \ntest \n317 \n317 \n0:057502 \n0:057502 \n*1 \nresnet20 \ntrain \n213 \n213 \n0:044305 \n0:044303 \n*2 \nresnet20 \ntest \n232 \n232 \n0:050750 \n0:050747 \n\n\nTable 7\n7FGSM experiments on the MNIST dataset. Numbers on the left of the table are referenced in Table VIII and correspond to experiments where we observe some difference in the behavior of the networks.Model \nTrain/test \nNumber of failures \nAverage \n\nOriginal \nWatermarked \nOriginal \nWatermarked \n\nbaseline \ntrain \n525 \n525 \n0:111667 \n0:111667 \nbaseline \ntest \n386 \n386 \n0:092779 \n0:092779 \nlarge \ntrain \n1027 \n1027 \n0:257718 \n0:257718 \nlarge \ntest \n773 \n773 \n0:216779 \n0:216779 \nlargemodel \ntrain \n395 \n395 \n0:241232 \n0:241232 \n*3 \nlargemodel \ntest \n349 \n349 \n0:227074 \n0:227073 \n\n\n\nTable 8\n8Differences in behavior found in the FGSM experiments.Case \nimage \n\n\nw \n\ny \ny 0 \ny \n\n0 \n\nw \n\n*1 \n881 \n0:026 \n0:026 \n9 \n5 \n3 \n*1 \n4010 \n0:344 \n0:340 \n3 \n6 \n6 \n*1 \n4101 \n0:018 \n0:014 \n1 \n8 \n8 \n*2 \n1536 \n0:277 \n0:281 \n3 \n2 \n2 \n*2 \n4434 \n0:034 \n0:022 \n2 \n3 \n8 \n*2 \n4749 \n0:375 \n0:371 \n3 \n6 \n6 \n*3 \n3059 \n0:046 \n0:042 \n7 \n1 \n1 \n\nAcknowledgementsThis work has been partially funded by the EU Horizon 2020 research and innovation program ECSEL Joint Undertaking (JU) under Grant Agreement No. 876487, NextPerception project -''Next Generation Smart Perception Sensors and Distributed Intelligence for Proactive Human Monitoring in Health, Wellbeing, and Automotive Systems.\" The JU receives support from the EU Horizon 2020 research and innovation programme and the nations involved in the mentioned projects. The work reflects only the authors' views; the European Commission is not responsible for any use that may be made of the information it contains.\nY Adi, C Baum, M Cisse, B Pinkas, J Keshet, Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring. Proceedings of the 27th USENIX Security Symposium (USENIX Security)Y. Adi, C. Baum, M. Cisse, B. Pinkas, J. Keshet, Turning Your Weakness Into a Strength: Watermarking Deep Neural Networks by Backdooring, in: In: Proceedings of the 27th USENIX Security Symposium (USENIX Security), 2018, pp. 1615-1631.\n\nDeep Speech 2: End-to-End Speech Recognition in English and Mandarin. D Amodei, arXiv:1512.02595v1cs.CLD. Amodei et al., Deep Speech 2: End-to-End Speech Recognition in English and Mandarin, arXiv:1512.02595v1 [cs.CL], available at https://arxiv.org/ abs/1512.02595 (2015).\n\nM Begum, M S Uddin, 10.3390/info11020110Digital Image Watermarking Techniques: A Review. 11110M. Begum, M.S. Uddin, Digital Image Watermarking Techniques: A Review, Inform. MDPI 11 (2) (2020) 110, https://doi.org/10.3390/info11020110.\n\nAutomatic Selection of GA Parameters for Fragile Watermarking. M Botta, D Cavagnino, V Pomponiu, LNCS. 8602M. Botta, D. Cavagnino, V. Pomponiu, Automatic Selection of GA Parameters for Fragile Watermarking, LNCS 8602 (2014) 526-537.\n\nA modular framework for color image watermarking, Signal Process. M Botta, D Cavagnino, V Pomponiu, 119M. Botta, D. Cavagnino, V. Pomponiu, A modular framework for color image watermarking, Signal Process. 119 (2016) 102-114.\n\nH Chen, B D Rouhani, F Koushanfar, arXiv:1904.00344v1BlackMarks: Blackbox Multibit Watermarking for Deep Neural Networks. cs.MMH. Chen, B.D. Rouhani, F. Koushanfar, BlackMarks: Blackbox Multibit Watermarking for Deep Neural Networks, arXiv:1904.00344v1 [cs.MM], available at https://arxiv.org/abs/1904.00344 (2019).\n\nDeepMarks: A Secure Fingerprinting Framework for Digital Rights Management of Deep Learning Models. H Chen, B D Rouhani, C Fu, J Zhao, F Koushanfar, 10.1145/3323873.3325042Proceedings of the 2019 on International Conference on Multimedia Retrieval (ICMR '19). the 2019 on International Conference on Multimedia Retrieval (ICMR '19)Ottawa ON Canada; New York, NY, USAACMH. Chen, B.D. Rouhani, C. Fu, J. Zhao, F. Koushanfar, DeepMarks: A Secure Fingerprinting Framework for Digital Rights Management of Deep Learning Models, In: Proceedings of the 2019 on International Conference on Multimedia Retrieval (ICMR '19), Ottawa ON Canada, ACM, New York, NY, USA, 2019, pp. 105-113, https://doi.org/10.1145/3323873.3325042\n\nGenetic Algorithms in Search. D E Goldberg, Optimization and Machine Learning. Addison-Wesley Publishing CompanyD.E. Goldberg, Genetic Algorithms in Search, Addison-Wesley Publishing Company, Optimization and Machine Learning, 1989.\n\nR C Gonzalez, P Wintz, Digital Image Processing. Addison-Wesley Publishing Company2nd ed.R.C. Gonzalez, P. Wintz, Digital Image Processing, 2nd ed.,., Addison-Wesley Publishing Company, 1987.\n\nI J Goodfellow, J Shlens, C Szegedy, arXiv:1412.6572v3Explaining and Harnessing Adversarial Examples. stat.MLI.J. Goodfellow, J. Shlens, C. Szegedy, Explaining and Harnessing Adversarial Examples, arXiv:1412.6572v3 [stat.ML], available at https://arxiv.org/abs/ 1412.6572 (2015).\n\nWatermarking Deep Neural Networks for Embedded Systems. J Guo, M Potkonjak, 10.1145/3240765.32408622018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD). San Diego, CA, USAJ. Guo, M. Potkonjak, Watermarking Deep Neural Networks for Embedded Systems, In: 2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), San Diego, CA, USA, 2018, pp. 1-8, doi: 10.1145/3240765.3240862\n\nA Y Hannun, C Case, J Casper, B Catanzaro, G Diamos, E Elsen, R Prenger, S Satheesh, S Sengupta, A Coates, A Y Ng, arXiv:1412.5567v2Deep Speech: Scaling Up Endto-end Speech Recognition. cs.CLA.Y. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta, A. Coates, A.Y. Ng, Deep Speech: Scaling Up End- to-end Speech Recognition, arXiv:1412.5567v2 [cs.CL], available at http://arxiv.org/abs/1412.5567 (2014).\n\nA.-E Hassanien, A Abraham, J Kacprzyk, J F Peters, 10.1007/978-3-540-76827-2_1Computational Intelligence in Multimedia Processing: Foundation and Trends. Hassanien A.E., Abraham A., Kacprzyk J.Berlin, HeidelbergSpringer96Computational Intelligence in Multimedia Processing: Recent AdvancesA.-E. Hassanien, A. Abraham, J. Kacprzyk, J.F. Peters, Computational Intelligence in Multimedia Processing: Foundation and Trends, In: Hassanien A.E., Abraham A., Kacprzyk J. (eds) Computational Intelligence in Multimedia Processing: Recent Advances. Studies in Computational Intelligence, vol. 96, Springer, Berlin, Heidelberg, 2008, https://doi.org/10.1007/978-3-540-76827-2_1\n\nDeep Residual Learning for Image Recognition. K He, X Zhang, S Ren, J Sun, 10.1109/CVPR.2016.902016 IEEE Conference on Computer Vision and Pattern Recognition. CVPR, Las Vegas, NVK. He, X. Zhang, S. Ren, J. Sun, Deep Residual Learning for Image Recognition, In: 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR, Las Vegas, NV, 2016, pp. 770-778, doi: 10.1109/CVPR.2016.90\n\nZ He, T Zhang, R B Lee, arXiv:1808.03277v2VerIDeep: Verifying Integrity of Deep Neural Networks through Sensitive-Sample Fingerprinting. Z. He, T. Zhang, R.B. Lee, VerIDeep: Verifying Integrity of Deep Neural Networks through Sensitive-Sample Fingerprinting, arXiv:1808.03277v2, available at https://arxiv.org/abs/1808.03277 (2018).\n\nP Hernandez, NIST Releases SHA-3 Cryptographic Hash Standard. Retrieved on 4th December 2020.P. Hernandez, NIST Releases SHA-3 Cryptographic Hash Standard, 2015, Available at https://www.nist.gov/news-events/news/2015/08/nist-releases- sha-3-cryptographic-hash-standard (Retrieved on 4th December 2020.)\n\n. D P Kingma, J L Ba, Adam , arXiv:1412.6980v96980A Method for Stochastic Optimizationcs.LGD.P. Kingma, J.L. Ba, Adam: A Method for Stochastic Optimization arXiv:1412.6980v9 [cs.LG], available at https://arxiv.org/abs/1412.6980 2017.\n\nImagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Adv. Neural Inform. Process. Syst. A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks, Adv. Neural Inform. Process. Syst. (2012) 1097-1105.\n\nThe MNIST database of hand-written digits. Y Lecun, C Cortes, C J Burges, Y. LeCun, C. Cortes, C.J. Burges, The MNIST database of hand-written digits. http://yann.lecun.com/exdb/mnist (1998).\n\nAdversarial frontier stitching for remote neural network watermarking. E Le Merrer, P P\u00e9rez, G Tr\u00e9dan, 10.1007/s00521-019-04434-zNeural Comput & Applic. 3213E. Le Merrer, P. P\u00e9rez, G. Tr\u00e9dan, Adversarial frontier stitching for remote neural network watermarking, Neural Comput & Applic 32 (13) (2020) 9233- 9244, https://doi.org/10.1007/s00521-019-04434-z.\n\nEffective Approaches to Attention-based Neural Machine Translation. M.-T Luong, H Pham, C D Manning, 10.18653/v1/D15-1166Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsM.-T. Luong, H. Pham, and C.D. Manning, Effective Approaches to Attention-based Neural Machine Translation, In: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, 2015, pp. 1412-1421, doi: 10.18653/v1/D15-1166\n\nDeepDream -a code example for visualizing Neural Networks. A Mordvintsev, C Olah, M Tyka, Google Research. A. Mordvintsev, C. Olah, M. Tyka, DeepDream -a code example for visualizing Neural Networks, Google Research (2015) https://ai.googleblog.com/ 2015/07/deepdream-code-example-for-visualizing.html\n\nDigital watermarking for deep neural networks. Y Nagai, Y Uchida, S Sakazawa, S Satoh, 10.1007/s13735-018-0147-1Int. J. Multimedia Inform. Retrieval. 71Y. Nagai, Y. Uchida, S. Sakazawa, S. Satoh, Digital watermarking for deep neural networks, Int. J. Multimedia Inform. Retrieval 7 (1) (2018) 3-16, https://doi.org/10.1007/s13735-018-0147-1.\n\nNietzsche texts: A rich dataset of English text. Nietzsche texts: A rich dataset of English text. https://www.kaggle.com/pankrzysiu/nietzsche-texts\n\nWatermarking deep neural networks in image processing. Y Quan, H Teng, Y Chen, H Ji, 10.1109/TNNLS.596238510.1109/TNNLS.2020.2991378IEEE Trans. Neural Networks Learn. Syst. 325Y. Quan, H. Teng, Y. Chen, H. Ji, Watermarking deep neural networks in image processing, IEEE Trans. Neural Networks Learn. Syst. 32 (5) (2021) 1852- 1865, https://doi.org/10.1109/TNNLS.596238510.1109/TNNLS.2020.2991378.\n\nThe MD5 Message-Digest Algorithm, RFC 1321. R Rivest, R. Rivest, The MD5 Message-Digest Algorithm, RFC 1321, April 1992.\n\nC Szegedy, W Zaremba, I Sutskever, J Bruna, D Erhan, I Goodfellow, R Fergus, arXiv:1312.6199v4Intriguing properties of neural networks. 6199cs.CVC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, R. Fergus, Intriguing properties of neural networks, arXiv:1312.6199v4 [cs.CV], available at https://arxiv.org/abs/1312.6199 (2014).\n\nS Szyller, B Atli, S Marchal, N Asokan, arXiv:1906.00830v4DAWN: Dynamic Adversarial Watermarking of Neural Networks. cs.CRS. Szyller, B. Gul Atli, S. Marchal, N. Asokan, DAWN: Dynamic Adversarial Watermarking of Neural Networks, arXiv:1906.00830v4 [cs.CR], available at http://arxiv.org/abs/1906.00830 (2019).\n\nEmbedding Watermarks into Deep Neural Networks. Y Uchida, Y Nagai, S Sakazawa, S Satoh, 10.1145/3078971.307897Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval (ICMR '17). the 2017 ACM on International Conference on Multimedia Retrieval (ICMR '17)New York, NY, USAACMY. Uchida, Y. Nagai, S. Sakazawa, S. Satoh, Embedding Watermarks into Deep Neural Networks, In: Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval (ICMR '17), ACM, New York, NY, USA, 2017, pp. 269-277, https://doi.org/10.1145/3078971.307897\n\nT Wang, F Kerschbaum, 10.1109/ICASSP.2019.8682202Attacks on Digital Watermarks for Deep Neural Networks, in: In: ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing. T. Wang, F. Kerschbaum, Attacks on Digital Watermarks for Deep Neural Networks, in: In: ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019, pp. 2622-2626, https://doi.org/10.1109/ICASSP.2019.8682202.\n\n. T Wang, F Kerschbaum, Riga, arXiv:1910.14268v3Covert and Robust White-Box Watermarking of Deep Neural Networkscs.CRT. Wang, F. Kerschbaum, RIGA: Covert and Robust White-Box Watermarking of Deep Neural Networks, arXiv:1910.14268v3 [cs.CR], available at https://arxiv.org/abs/1910.14268 (2020).\n\nProtecting Intellectual Property of Deep Neural Networks with Watermarking. J Zhang, Z Gu, J Jang, H Wu, M Ph, H Stoecklin, I Huang, Molloy, 10.1145/3196494.3196550Proceedings of the 2018 Asia Conference on Computer and Communications Security (AsiaCCS '18). the 2018 Asia Conference on Computer and Communications Security (AsiaCCS '18)J. Zhang, Z. Gu, J. Jang, H. Wu, M.Ph. Stoecklin, H. Huang, I. Molloy, Protecting Intellectual Property of Deep Neural Networks with Watermarking, In: Proceedings of the 2018 Asia Conference on Computer and Communications Security (AsiaCCS '18), 2018, pp. 159-172, https://doi.org/10.1145/ 3196494.3196550\n", "annotations": {"author": "[{\"end\":190,\"start\":94},{\"end\":292,\"start\":191},{\"end\":394,\"start\":293}]", "publisher": null, "author_last_name": "[{\"end\":105,\"start\":100},{\"end\":207,\"start\":198},{\"end\":309,\"start\":301}]", "author_first_name": "[{\"end\":99,\"start\":94},{\"end\":197,\"start\":191},{\"end\":300,\"start\":293}]", "author_affiliation": "[{\"end\":189,\"start\":107},{\"end\":291,\"start\":209},{\"end\":393,\"start\":311}]", "title": "[{\"end\":91,\"start\":1},{\"end\":485,\"start\":395}]", "venue": null, "abstract": "[{\"end\":1422,\"start\":746}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":1815,\"start\":1811},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":1849,\"start\":1845},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1876,\"start\":1873},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1879,\"start\":1876},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9325,\"start\":9322},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12937,\"start\":12934},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13250,\"start\":13246},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13542,\"start\":13539},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13729,\"start\":13725},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14025,\"start\":14022},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14296,\"start\":14292},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":14381,\"start\":14377},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14620,\"start\":14616},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14787,\"start\":14783},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14835,\"start\":14831},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14838,\"start\":14835},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":15046,\"start\":15042},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15049,\"start\":15046},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":15078,\"start\":15074},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":15873,\"start\":15869},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16890,\"start\":16887},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19409,\"start\":19406},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21447,\"start\":21444},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21450,\"start\":21447},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21520,\"start\":21517},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":22172,\"start\":22169},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":22840,\"start\":22837},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":24451,\"start\":24447},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25317,\"start\":25313},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27048,\"start\":27045},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":32384,\"start\":32380},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32399,\"start\":32395},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32418,\"start\":32414},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":36690,\"start\":36686},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36737,\"start\":36734},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":36783,\"start\":36780},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":36829,\"start\":36825},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":38071,\"start\":38067},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":38514,\"start\":38510},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39404,\"start\":39400},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":45043,\"start\":45039},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":49022,\"start\":49018}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":53100,\"start\":51879},{\"attributes\":{\"id\":\"fig_1\"},\"end\":53154,\"start\":53101},{\"attributes\":{\"id\":\"fig_3\"},\"end\":53292,\"start\":53155},{\"attributes\":{\"id\":\"fig_4\"},\"end\":54219,\"start\":53293},{\"attributes\":{\"id\":\"fig_5\"},\"end\":54350,\"start\":54220},{\"attributes\":{\"id\":\"fig_6\"},\"end\":54481,\"start\":54351},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":54744,\"start\":54482},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":54953,\"start\":54745},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":55220,\"start\":54954},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":55821,\"start\":55221},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":56408,\"start\":55822},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":56742,\"start\":56409}]", "paragraph": "[{\"end\":2527,\"start\":1438},{\"end\":3058,\"start\":2529},{\"end\":3277,\"start\":3060},{\"end\":4991,\"start\":3279},{\"end\":5496,\"start\":4993},{\"end\":5981,\"start\":5498},{\"end\":7200,\"start\":5983},{\"end\":7815,\"start\":7202},{\"end\":8691,\"start\":7817},{\"end\":10083,\"start\":8693},{\"end\":10184,\"start\":10085},{\"end\":11904,\"start\":10186},{\"end\":12777,\"start\":11906},{\"end\":13204,\"start\":12795},{\"end\":14758,\"start\":13206},{\"end\":15275,\"start\":14760},{\"end\":15767,\"start\":15277},{\"end\":16573,\"start\":15769},{\"end\":16891,\"start\":16593},{\"end\":17230,\"start\":16893},{\"end\":17480,\"start\":17232},{\"end\":17662,\"start\":17502},{\"end\":17912,\"start\":17664},{\"end\":18034,\"start\":17914},{\"end\":18297,\"start\":18085},{\"end\":18343,\"start\":18299},{\"end\":18925,\"start\":18421},{\"end\":19357,\"start\":18927},{\"end\":20493,\"start\":19359},{\"end\":21399,\"start\":20495},{\"end\":21521,\"start\":21401},{\"end\":22060,\"start\":21542},{\"end\":22370,\"start\":22062},{\"end\":22841,\"start\":22372},{\"end\":24058,\"start\":22843},{\"end\":24774,\"start\":24060},{\"end\":25611,\"start\":24776},{\"end\":26241,\"start\":25613},{\"end\":26951,\"start\":26243},{\"end\":27312,\"start\":26953},{\"end\":27489,\"start\":27342},{\"end\":27832,\"start\":27491},{\"end\":28184,\"start\":27834},{\"end\":28731,\"start\":28186},{\"end\":29580,\"start\":28733},{\"end\":30076,\"start\":29582},{\"end\":30537,\"start\":30104},{\"end\":31320,\"start\":30561},{\"end\":32716,\"start\":31462},{\"end\":33308,\"start\":32718},{\"end\":34170,\"start\":33310},{\"end\":34959,\"start\":34172},{\"end\":35743,\"start\":34961},{\"end\":36520,\"start\":35745},{\"end\":36973,\"start\":36534},{\"end\":37479,\"start\":36975},{\"end\":39288,\"start\":37507},{\"end\":40735,\"start\":39318},{\"end\":43163,\"start\":40737},{\"end\":43600,\"start\":43165},{\"end\":43893,\"start\":43638},{\"end\":44382,\"start\":43895},{\"end\":44925,\"start\":44483},{\"end\":45242,\"start\":44927},{\"end\":45835,\"start\":45244},{\"end\":46211,\"start\":45837},{\"end\":47242,\"start\":46213},{\"end\":48000,\"start\":47244},{\"end\":48601,\"start\":48015},{\"end\":49457,\"start\":48603},{\"end\":49892,\"start\":49459},{\"end\":50604,\"start\":49894},{\"end\":51224,\"start\":50620},{\"end\":51670,\"start\":51226},{\"end\":51878,\"start\":51708}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17501,\"start\":17481},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18084,\"start\":18035},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18420,\"start\":18344},{\"attributes\":{\"id\":\"formula_3\"},\"end\":27341,\"start\":27313},{\"attributes\":{\"id\":\"formula_4\"},\"end\":31461,\"start\":31321},{\"attributes\":{\"id\":\"formula_5\"},\"end\":44446,\"start\":44383},{\"attributes\":{\"id\":\"formula_6\"},\"end\":44482,\"start\":44446}]", "table_ref": "[{\"end\":31870,\"start\":31863},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":32436,\"start\":32429},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":33014,\"start\":33007},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":33351,\"start\":33344},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":35079,\"start\":35072},{\"end\":36063,\"start\":36056},{\"end\":36120,\"start\":36113},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":36658,\"start\":36586},{\"end\":36844,\"start\":36837},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41128,\"start\":41114},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":41731,\"start\":41724}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1436,\"start\":1424},{\"attributes\":{\"n\":\"2.\"},\"end\":12793,\"start\":12780},{\"attributes\":{\"n\":\"3.\"},\"end\":16591,\"start\":16576},{\"attributes\":{\"n\":\"4.\"},\"end\":21540,\"start\":21524},{\"attributes\":{\"n\":\"5.\"},\"end\":30102,\"start\":30079},{\"attributes\":{\"n\":\"5.1.\"},\"end\":30559,\"start\":30540},{\"end\":36532,\"start\":36523},{\"attributes\":{\"n\":\"5.2.\"},\"end\":37505,\"start\":37482},{\"attributes\":{\"n\":\"5.2.1.\"},\"end\":39316,\"start\":39291},{\"attributes\":{\"n\":\"5.2.2.\"},\"end\":43636,\"start\":43603},{\"attributes\":{\"n\":\"6.\"},\"end\":48013,\"start\":48003},{\"attributes\":{\"n\":\"7.\"},\"end\":50618,\"start\":50607},{\"end\":51706,\"start\":51673},{\"end\":51893,\"start\":51880},{\"end\":53110,\"start\":53102},{\"end\":54229,\"start\":54221},{\"end\":54360,\"start\":54352},{\"end\":54490,\"start\":54483},{\"end\":54753,\"start\":54746},{\"end\":54962,\"start\":54955},{\"end\":55229,\"start\":55222},{\"end\":55830,\"start\":55823},{\"end\":56417,\"start\":56410}]", "table": "[{\"end\":54744,\"start\":54512},{\"end\":54953,\"start\":54774},{\"end\":55220,\"start\":55009},{\"end\":55821,\"start\":55531},{\"end\":56408,\"start\":56028},{\"end\":56742,\"start\":56473}]", "figure_caption": "[{\"end\":53100,\"start\":51896},{\"end\":53154,\"start\":53112},{\"end\":53292,\"start\":53157},{\"end\":54219,\"start\":53295},{\"end\":54350,\"start\":54231},{\"end\":54481,\"start\":54362},{\"end\":54512,\"start\":54492},{\"end\":54774,\"start\":54755},{\"end\":55009,\"start\":54964},{\"end\":55531,\"start\":55231},{\"end\":56028,\"start\":55832},{\"end\":56473,\"start\":56419}]", "figure_ref": "[{\"end\":22307,\"start\":22301},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25137,\"start\":25131},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25359,\"start\":25353}]", "bib_author_first_name": "[{\"end\":57370,\"start\":57369},{\"end\":57377,\"start\":57376},{\"end\":57385,\"start\":57384},{\"end\":57394,\"start\":57393},{\"end\":57404,\"start\":57403},{\"end\":57877,\"start\":57876},{\"end\":58082,\"start\":58081},{\"end\":58091,\"start\":58090},{\"end\":58093,\"start\":58092},{\"end\":58381,\"start\":58380},{\"end\":58390,\"start\":58389},{\"end\":58403,\"start\":58402},{\"end\":58618,\"start\":58617},{\"end\":58627,\"start\":58626},{\"end\":58640,\"start\":58639},{\"end\":58779,\"start\":58778},{\"end\":58787,\"start\":58786},{\"end\":58789,\"start\":58788},{\"end\":58800,\"start\":58799},{\"end\":59196,\"start\":59195},{\"end\":59204,\"start\":59203},{\"end\":59206,\"start\":59205},{\"end\":59217,\"start\":59216},{\"end\":59223,\"start\":59222},{\"end\":59231,\"start\":59230},{\"end\":59843,\"start\":59842},{\"end\":59845,\"start\":59844},{\"end\":60047,\"start\":60046},{\"end\":60049,\"start\":60048},{\"end\":60061,\"start\":60060},{\"end\":60240,\"start\":60239},{\"end\":60242,\"start\":60241},{\"end\":60256,\"start\":60255},{\"end\":60266,\"start\":60265},{\"end\":60577,\"start\":60576},{\"end\":60584,\"start\":60583},{\"end\":60931,\"start\":60930},{\"end\":60933,\"start\":60932},{\"end\":60943,\"start\":60942},{\"end\":60951,\"start\":60950},{\"end\":60961,\"start\":60960},{\"end\":60974,\"start\":60973},{\"end\":60984,\"start\":60983},{\"end\":60993,\"start\":60992},{\"end\":61004,\"start\":61003},{\"end\":61016,\"start\":61015},{\"end\":61028,\"start\":61027},{\"end\":61038,\"start\":61037},{\"end\":61040,\"start\":61039},{\"end\":61387,\"start\":61383},{\"end\":61400,\"start\":61399},{\"end\":61411,\"start\":61410},{\"end\":61423,\"start\":61422},{\"end\":61425,\"start\":61424},{\"end\":62099,\"start\":62098},{\"end\":62105,\"start\":62104},{\"end\":62114,\"start\":62113},{\"end\":62121,\"start\":62120},{\"end\":62447,\"start\":62446},{\"end\":62453,\"start\":62452},{\"end\":62462,\"start\":62461},{\"end\":62464,\"start\":62463},{\"end\":62781,\"start\":62780},{\"end\":63088,\"start\":63087},{\"end\":63090,\"start\":63089},{\"end\":63100,\"start\":63099},{\"end\":63102,\"start\":63101},{\"end\":63111,\"start\":63107},{\"end\":63386,\"start\":63385},{\"end\":63400,\"start\":63399},{\"end\":63413,\"start\":63412},{\"end\":63415,\"start\":63414},{\"end\":63664,\"start\":63663},{\"end\":63673,\"start\":63672},{\"end\":63683,\"start\":63682},{\"end\":63685,\"start\":63684},{\"end\":63885,\"start\":63884},{\"end\":63888,\"start\":63886},{\"end\":63898,\"start\":63897},{\"end\":63907,\"start\":63906},{\"end\":64243,\"start\":64239},{\"end\":64252,\"start\":64251},{\"end\":64260,\"start\":64259},{\"end\":64262,\"start\":64261},{\"end\":64843,\"start\":64842},{\"end\":64858,\"start\":64857},{\"end\":64866,\"start\":64865},{\"end\":65134,\"start\":65133},{\"end\":65143,\"start\":65142},{\"end\":65153,\"start\":65152},{\"end\":65165,\"start\":65164},{\"end\":65634,\"start\":65633},{\"end\":65642,\"start\":65641},{\"end\":65650,\"start\":65649},{\"end\":65658,\"start\":65657},{\"end\":66021,\"start\":66020},{\"end\":66099,\"start\":66098},{\"end\":66110,\"start\":66109},{\"end\":66121,\"start\":66120},{\"end\":66134,\"start\":66133},{\"end\":66143,\"start\":66142},{\"end\":66152,\"start\":66151},{\"end\":66166,\"start\":66165},{\"end\":66451,\"start\":66450},{\"end\":66462,\"start\":66461},{\"end\":66470,\"start\":66469},{\"end\":66481,\"start\":66480},{\"end\":66810,\"start\":66809},{\"end\":66820,\"start\":66819},{\"end\":66829,\"start\":66828},{\"end\":66841,\"start\":66840},{\"end\":67330,\"start\":67329},{\"end\":67338,\"start\":67337},{\"end\":67791,\"start\":67790},{\"end\":67799,\"start\":67798},{\"end\":68161,\"start\":68160},{\"end\":68170,\"start\":68169},{\"end\":68176,\"start\":68175},{\"end\":68184,\"start\":68183},{\"end\":68190,\"start\":68189},{\"end\":68196,\"start\":68195},{\"end\":68209,\"start\":68208}]", "bib_author_last_name": "[{\"end\":57374,\"start\":57371},{\"end\":57382,\"start\":57378},{\"end\":57391,\"start\":57386},{\"end\":57401,\"start\":57395},{\"end\":57411,\"start\":57405},{\"end\":57884,\"start\":57878},{\"end\":58088,\"start\":58083},{\"end\":58099,\"start\":58094},{\"end\":58387,\"start\":58382},{\"end\":58400,\"start\":58391},{\"end\":58412,\"start\":58404},{\"end\":58624,\"start\":58619},{\"end\":58637,\"start\":58628},{\"end\":58649,\"start\":58641},{\"end\":58784,\"start\":58780},{\"end\":58797,\"start\":58790},{\"end\":58811,\"start\":58801},{\"end\":59201,\"start\":59197},{\"end\":59214,\"start\":59207},{\"end\":59220,\"start\":59218},{\"end\":59228,\"start\":59224},{\"end\":59242,\"start\":59232},{\"end\":59854,\"start\":59846},{\"end\":60058,\"start\":60050},{\"end\":60067,\"start\":60062},{\"end\":60253,\"start\":60243},{\"end\":60263,\"start\":60257},{\"end\":60274,\"start\":60267},{\"end\":60581,\"start\":60578},{\"end\":60594,\"start\":60585},{\"end\":60940,\"start\":60934},{\"end\":60948,\"start\":60944},{\"end\":60958,\"start\":60952},{\"end\":60971,\"start\":60962},{\"end\":60981,\"start\":60975},{\"end\":60990,\"start\":60985},{\"end\":61001,\"start\":60994},{\"end\":61013,\"start\":61005},{\"end\":61025,\"start\":61017},{\"end\":61035,\"start\":61029},{\"end\":61043,\"start\":61041},{\"end\":61397,\"start\":61388},{\"end\":61408,\"start\":61401},{\"end\":61420,\"start\":61412},{\"end\":61432,\"start\":61426},{\"end\":62102,\"start\":62100},{\"end\":62111,\"start\":62106},{\"end\":62118,\"start\":62115},{\"end\":62125,\"start\":62122},{\"end\":62450,\"start\":62448},{\"end\":62459,\"start\":62454},{\"end\":62468,\"start\":62465},{\"end\":62791,\"start\":62782},{\"end\":63097,\"start\":63091},{\"end\":63105,\"start\":63103},{\"end\":63397,\"start\":63387},{\"end\":63410,\"start\":63401},{\"end\":63422,\"start\":63416},{\"end\":63670,\"start\":63665},{\"end\":63680,\"start\":63674},{\"end\":63692,\"start\":63686},{\"end\":63895,\"start\":63889},{\"end\":63904,\"start\":63899},{\"end\":63914,\"start\":63908},{\"end\":64249,\"start\":64244},{\"end\":64257,\"start\":64253},{\"end\":64270,\"start\":64263},{\"end\":64855,\"start\":64844},{\"end\":64863,\"start\":64859},{\"end\":64871,\"start\":64867},{\"end\":65140,\"start\":65135},{\"end\":65150,\"start\":65144},{\"end\":65162,\"start\":65154},{\"end\":65171,\"start\":65166},{\"end\":65639,\"start\":65635},{\"end\":65647,\"start\":65643},{\"end\":65655,\"start\":65651},{\"end\":65661,\"start\":65659},{\"end\":66028,\"start\":66022},{\"end\":66107,\"start\":66100},{\"end\":66118,\"start\":66111},{\"end\":66131,\"start\":66122},{\"end\":66140,\"start\":66135},{\"end\":66149,\"start\":66144},{\"end\":66163,\"start\":66153},{\"end\":66173,\"start\":66167},{\"end\":66459,\"start\":66452},{\"end\":66467,\"start\":66463},{\"end\":66478,\"start\":66471},{\"end\":66488,\"start\":66482},{\"end\":66817,\"start\":66811},{\"end\":66826,\"start\":66821},{\"end\":66838,\"start\":66830},{\"end\":66847,\"start\":66842},{\"end\":67335,\"start\":67331},{\"end\":67349,\"start\":67339},{\"end\":67796,\"start\":67792},{\"end\":67810,\"start\":67800},{\"end\":67816,\"start\":67812},{\"end\":68167,\"start\":68162},{\"end\":68173,\"start\":68171},{\"end\":68181,\"start\":68177},{\"end\":68187,\"start\":68185},{\"end\":68193,\"start\":68191},{\"end\":68206,\"start\":68197},{\"end\":68215,\"start\":68210},{\"end\":68223,\"start\":68217}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":57804,\"start\":57369},{\"attributes\":{\"doi\":\"arXiv:1512.02595v1\",\"id\":\"b1\"},\"end\":58079,\"start\":57806},{\"attributes\":{\"doi\":\"10.3390/info11020110\",\"id\":\"b2\"},\"end\":58315,\"start\":58081},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":13496048},\"end\":58549,\"start\":58317},{\"attributes\":{\"id\":\"b4\"},\"end\":58776,\"start\":58551},{\"attributes\":{\"doi\":\"arXiv:1904.00344v1\",\"id\":\"b5\"},\"end\":59093,\"start\":58778},{\"attributes\":{\"doi\":\"10.1145/3323873.3325042\",\"id\":\"b6\",\"matched_paper_id\":174802321},\"end\":59810,\"start\":59095},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":61406969},\"end\":60044,\"start\":59812},{\"attributes\":{\"id\":\"b8\"},\"end\":60237,\"start\":60046},{\"attributes\":{\"doi\":\"arXiv:1412.6572v3\",\"id\":\"b9\"},\"end\":60518,\"start\":60239},{\"attributes\":{\"doi\":\"10.1145/3240765.3240862\",\"id\":\"b10\",\"matched_paper_id\":53242536},\"end\":60928,\"start\":60520},{\"attributes\":{\"doi\":\"arXiv:1412.5567v2\",\"id\":\"b11\"},\"end\":61381,\"start\":60930},{\"attributes\":{\"doi\":\"10.1007/978-3-540-76827-2_1\",\"id\":\"b12\"},\"end\":62050,\"start\":61383},{\"attributes\":{\"doi\":\"10.1109/CVPR.2016.90\",\"id\":\"b13\",\"matched_paper_id\":206594692},\"end\":62444,\"start\":62052},{\"attributes\":{\"doi\":\"arXiv:1808.03277v2\",\"id\":\"b14\"},\"end\":62778,\"start\":62446},{\"attributes\":{\"id\":\"b15\"},\"end\":63083,\"start\":62780},{\"attributes\":{\"doi\":\"arXiv:1412.6980v9\",\"id\":\"b16\"},\"end\":63318,\"start\":63085},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":195908774},\"end\":63618,\"start\":63320},{\"attributes\":{\"id\":\"b18\"},\"end\":63811,\"start\":63620},{\"attributes\":{\"doi\":\"10.1007/s00521-019-04434-z\",\"id\":\"b19\",\"matched_paper_id\":11008755},\"end\":64169,\"start\":63813},{\"attributes\":{\"doi\":\"10.18653/v1/D15-1166\",\"id\":\"b20\",\"matched_paper_id\":1998416},\"end\":64781,\"start\":64171},{\"attributes\":{\"id\":\"b21\"},\"end\":65084,\"start\":64783},{\"attributes\":{\"doi\":\"10.1007/s13735-018-0147-1\",\"id\":\"b22\",\"matched_paper_id\":3357507},\"end\":65427,\"start\":65086},{\"attributes\":{\"id\":\"b23\"},\"end\":65576,\"start\":65429},{\"attributes\":{\"doi\":\"10.1109/TNNLS.596238510.1109/TNNLS.2020.2991378\",\"id\":\"b24\",\"matched_paper_id\":218636005},\"end\":65974,\"start\":65578},{\"attributes\":{\"id\":\"b25\"},\"end\":66096,\"start\":65976},{\"attributes\":{\"doi\":\"arXiv:1312.6199v4\",\"id\":\"b26\"},\"end\":66448,\"start\":66098},{\"attributes\":{\"doi\":\"arXiv:1906.00830v4\",\"id\":\"b27\"},\"end\":66759,\"start\":66450},{\"attributes\":{\"doi\":\"10.1145/3078971.307897\",\"id\":\"b28\",\"matched_paper_id\":13060737},\"end\":67327,\"start\":66761},{\"attributes\":{\"doi\":\"10.1109/ICASSP.2019.8682202\",\"id\":\"b29\"},\"end\":67786,\"start\":67329},{\"attributes\":{\"doi\":\"arXiv:1910.14268v3\",\"id\":\"b30\"},\"end\":68082,\"start\":67788},{\"attributes\":{\"doi\":\"10.1145/3196494.3196550\",\"id\":\"b31\",\"matched_paper_id\":44085059},\"end\":68726,\"start\":68084}]", "bib_title": "[{\"end\":58378,\"start\":58317},{\"end\":59193,\"start\":59095},{\"end\":59840,\"start\":59812},{\"end\":60574,\"start\":60520},{\"end\":62096,\"start\":62052},{\"end\":63383,\"start\":63320},{\"end\":63882,\"start\":63813},{\"end\":64237,\"start\":64171},{\"end\":64840,\"start\":64783},{\"end\":65131,\"start\":65086},{\"end\":65631,\"start\":65578},{\"end\":66807,\"start\":66761},{\"end\":68158,\"start\":68084}]", "bib_author": "[{\"end\":57376,\"start\":57369},{\"end\":57384,\"start\":57376},{\"end\":57393,\"start\":57384},{\"end\":57403,\"start\":57393},{\"end\":57413,\"start\":57403},{\"end\":57886,\"start\":57876},{\"end\":58090,\"start\":58081},{\"end\":58101,\"start\":58090},{\"end\":58389,\"start\":58380},{\"end\":58402,\"start\":58389},{\"end\":58414,\"start\":58402},{\"end\":58626,\"start\":58617},{\"end\":58639,\"start\":58626},{\"end\":58651,\"start\":58639},{\"end\":58786,\"start\":58778},{\"end\":58799,\"start\":58786},{\"end\":58813,\"start\":58799},{\"end\":59203,\"start\":59195},{\"end\":59216,\"start\":59203},{\"end\":59222,\"start\":59216},{\"end\":59230,\"start\":59222},{\"end\":59244,\"start\":59230},{\"end\":59856,\"start\":59842},{\"end\":60060,\"start\":60046},{\"end\":60069,\"start\":60060},{\"end\":60255,\"start\":60239},{\"end\":60265,\"start\":60255},{\"end\":60276,\"start\":60265},{\"end\":60583,\"start\":60576},{\"end\":60596,\"start\":60583},{\"end\":60942,\"start\":60930},{\"end\":60950,\"start\":60942},{\"end\":60960,\"start\":60950},{\"end\":60973,\"start\":60960},{\"end\":60983,\"start\":60973},{\"end\":60992,\"start\":60983},{\"end\":61003,\"start\":60992},{\"end\":61015,\"start\":61003},{\"end\":61027,\"start\":61015},{\"end\":61037,\"start\":61027},{\"end\":61045,\"start\":61037},{\"end\":61399,\"start\":61383},{\"end\":61410,\"start\":61399},{\"end\":61422,\"start\":61410},{\"end\":61434,\"start\":61422},{\"end\":62104,\"start\":62098},{\"end\":62113,\"start\":62104},{\"end\":62120,\"start\":62113},{\"end\":62127,\"start\":62120},{\"end\":62452,\"start\":62446},{\"end\":62461,\"start\":62452},{\"end\":62470,\"start\":62461},{\"end\":62793,\"start\":62780},{\"end\":63099,\"start\":63087},{\"end\":63107,\"start\":63099},{\"end\":63114,\"start\":63107},{\"end\":63399,\"start\":63385},{\"end\":63412,\"start\":63399},{\"end\":63424,\"start\":63412},{\"end\":63672,\"start\":63663},{\"end\":63682,\"start\":63672},{\"end\":63694,\"start\":63682},{\"end\":63897,\"start\":63884},{\"end\":63906,\"start\":63897},{\"end\":63916,\"start\":63906},{\"end\":64251,\"start\":64239},{\"end\":64259,\"start\":64251},{\"end\":64272,\"start\":64259},{\"end\":64857,\"start\":64842},{\"end\":64865,\"start\":64857},{\"end\":64873,\"start\":64865},{\"end\":65142,\"start\":65133},{\"end\":65152,\"start\":65142},{\"end\":65164,\"start\":65152},{\"end\":65173,\"start\":65164},{\"end\":65641,\"start\":65633},{\"end\":65649,\"start\":65641},{\"end\":65657,\"start\":65649},{\"end\":65663,\"start\":65657},{\"end\":66030,\"start\":66020},{\"end\":66109,\"start\":66098},{\"end\":66120,\"start\":66109},{\"end\":66133,\"start\":66120},{\"end\":66142,\"start\":66133},{\"end\":66151,\"start\":66142},{\"end\":66165,\"start\":66151},{\"end\":66175,\"start\":66165},{\"end\":66461,\"start\":66450},{\"end\":66469,\"start\":66461},{\"end\":66480,\"start\":66469},{\"end\":66490,\"start\":66480},{\"end\":66819,\"start\":66809},{\"end\":66828,\"start\":66819},{\"end\":66840,\"start\":66828},{\"end\":66849,\"start\":66840},{\"end\":67337,\"start\":67329},{\"end\":67351,\"start\":67337},{\"end\":67798,\"start\":67790},{\"end\":67812,\"start\":67798},{\"end\":67818,\"start\":67812},{\"end\":68169,\"start\":68160},{\"end\":68175,\"start\":68169},{\"end\":68183,\"start\":68175},{\"end\":68189,\"start\":68183},{\"end\":68195,\"start\":68189},{\"end\":68208,\"start\":68195},{\"end\":68217,\"start\":68208},{\"end\":68225,\"start\":68217}]", "bib_venue": "[{\"end\":57500,\"start\":57413},{\"end\":57874,\"start\":57806},{\"end\":58168,\"start\":58121},{\"end\":58418,\"start\":58414},{\"end\":58615,\"start\":58551},{\"end\":58898,\"start\":58831},{\"end\":59353,\"start\":59267},{\"end\":59889,\"start\":59856},{\"end\":60093,\"start\":60069},{\"end\":60339,\"start\":60293},{\"end\":60690,\"start\":60619},{\"end\":61114,\"start\":61062},{\"end\":61535,\"start\":61461},{\"end\":62210,\"start\":62147},{\"end\":62581,\"start\":62488},{\"end\":62840,\"start\":62793},{\"end\":63457,\"start\":63424},{\"end\":63661,\"start\":63620},{\"end\":63964,\"start\":63942},{\"end\":64378,\"start\":64292},{\"end\":64888,\"start\":64873},{\"end\":65234,\"start\":65198},{\"end\":65476,\"start\":65429},{\"end\":65749,\"start\":65710},{\"end\":66018,\"start\":65976},{\"end\":66232,\"start\":66192},{\"end\":66565,\"start\":66508},{\"end\":66961,\"start\":66871},{\"end\":67531,\"start\":67378},{\"end\":68341,\"start\":68248},{\"end\":59461,\"start\":59355},{\"end\":60710,\"start\":60692},{\"end\":61594,\"start\":61576},{\"end\":62231,\"start\":62212},{\"end\":64451,\"start\":64380},{\"end\":67055,\"start\":66963},{\"end\":68421,\"start\":68343}]"}}}, "year": 2023, "month": 12, "day": 17}