{"id": 244346139, "updated": "2023-10-05 19:34:15.143", "metadata": {"title": "Near-Optimal Quantum Algorithms for Multivariate Mean Estimation", "authors": "[{\"first\":\"Arjan\",\"last\":\"Cornelissen\",\"middle\":[]},{\"first\":\"Yassine\",\"last\":\"Hamoudi\",\"middle\":[]},{\"first\":\"Sofiene\",\"last\":\"Jerbi\",\"middle\":[]}]", "venue": "Proceedings of the 54th Symposium on Theory of Computing (STOC), pages 33-43, 2022", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "We propose the first near-optimal quantum algorithm for estimating in Euclidean norm the mean of a vector-valued random variable with finite mean and covariance. Our result aims at extending the theory of multivariate sub-Gaussian estimators to the quantum setting. Unlike classically, where any univariate estimator can be turned into a multivariate estimator with at most a logarithmic overhead in the dimension, no similar result can be proved in the quantum setting. Indeed, Heinrich ruled out the existence of a quantum advantage for the mean estimation problem when the sample complexity is smaller than the dimension. Our main result is to show that, outside this low-precision regime, there is a quantum estimator that outperforms any classical estimator. Our approach is substantially more involved than in the univariate setting, where most quantum estimators rely only on phase estimation. We exploit a variety of additional algorithmic techniques such as amplitude amplification, the Bernstein-Vazirani algorithm, and quantum singular value transformation. Our analysis also uses concentration inequalities for multivariate truncated statistics. We develop our quantum estimators in two different input models that showed up in the literature before. The first one provides coherent access to the binary representation of the random variable and it encompasses the classical setting. In the second model, the random variable is directly encoded into the phases of quantum registers. This model arises naturally in many quantum algorithms but it is often incomparable to having classical samples. We adapt our techniques to these two settings and we show that the second model is strictly weaker for solving the mean estimation problem. Finally, we describe several applications of our algorithms, notably in measuring the expectation values of commuting observables and in the field of machine learning.", "fields_of_study": "[\"Physics\",\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2111.09787", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/stoc/CornelissenHJ22", "doi": "10.1145/3519935.3520045"}}, "content": {"source": {"pdf_hash": "682664f86aa9eaeb5fcdc485fee03a8ee8c7f887", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.09787v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3519935.3520045", "status": "BRONZE"}}, "grobid": {"id": "6f4e1a5e1388dcc15ae271f9dd4078df492922ea", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/682664f86aa9eaeb5fcdc485fee03a8ee8c7f887.txt", "contents": "\nNear-Optimal Quantum Algorithms for Multivariate Mean Estimation\nJuly 20, 2022\n\nArjan Cornelissen \nYassine Hamoudi \nSofiene Jerbi \nNear-Optimal Quantum Algorithms for Multivariate Mean Estimation\nJuly 20, 2022\nWe propose the first near-optimal quantum algorithm for estimating in Euclidean norm the mean of a vector-valued random variable with finite mean and covariance. Our result aims at extending the theory of multivariate sub-Gaussian estimators [LM19a] to the quantum setting. Unlike classically, where any univariate estimator can be turned into a multivariate estimator with at most a logarithmic overhead in the dimension, no similar result can be proved in the quantum setting. Indeed, Heinrich [Hei04] ruled out the existence of a quantum advantage for the mean estimation problem when the sample complexity is smaller than the dimension. Our main result is to show that, outside this low-precision regime, there does exist a quantum estimator that outperforms any classical estimator. More precisely, we prove that the approximation error can be decreased by a factor of about the square root of the ratio between the dimension and the sample complexity. Our approach is substantially more involved than in the univariate setting, where most quantum estimators rely only on phase estimation. We exploit a variety of additional algorithmic techniques such as linear amplitude amplification, the Bernstein-Vazirani algorithm, and quantum singular value transformation. Our analysis is also deeply rooted in proving concentration inequalities for multivariate truncated statistics.We develop our quantum estimators in two different input models that showed up in the literature before. The first one provides coherent access to the binary representation of the random variable and it encompasses the classical setting. In the second model, the random variable is directly encoded into the phases of quantum registers. This model arises naturally in many quantum algorithms but it is often incomparable to having classical samples. We adapt our techniques to these two settings and we show that the second model is strictly weaker than the other one for solving the mean estimation problem. Finally, we describe several applications of our algorithms, notably in measuring the expectation values of commuting observables and in the field of machine learning. * QuSoft, University of Amsterdam. arjan.cornelissen@cwi.nl\n\nIntroduction\n\nMonte Carlo methods are used extensively in various fields of science and engineering, such as statistical physics [BH10], finance [Gla03], or machine learning [AFDJ03]. At the core of these methods is a Monte Carlo process, e.g., a randomized algorithm, whose expected outcome is to be estimated via repeated random executions. Quantum computers can speed-up this approach at two different levels [Mon15]. First, novel algorithmic techniques such as Hamiltonian simulation [Fey82] or quantum walks [Sze04] provide faster Monte Carlo simulation processes. Secondly, quantum metrology algorithms (such as phase estimation [Kit95]) give better error rates for computing statistics on these processes. The present paper focuses on this second point through the lens of the mean estimation problem. In this problem, the objective is to compute the closest possible estimate \u00b5 to the mean \u00b5 = E[X] of a random variable X representing the output of some black-box process. Given the ability to repeat this process n times (the sample complexity), one seeks to minimize the error \u00b5 \u2212 \u00b5 made with high probability.\n\nIn the classical setting, a beautiful theory [LM19a] has been developed to solve the mean estimation problem in Euclidean norm. Under the sole assumption that the covariance matrix \u03a3 of X exists, it turns out that the optimal non-asymptotic error behaves as if X followed the Gaussian distribution N (\u00b5, \u03a3). This motivated the use of the adjective sub-Gaussian to qualify the optimal classical estimators. In one dimension, the most well-known sub-Gaussian estimator is arguably the median-of-means [NY83; JVV86; AMS99]. The first computationally efficient sub-Gaussian estimator in high dimension was only found recently by Hopkins [Hop20]. These estimators achieve an optimal error of \u00b5 \u2212 \u00b5 2 \u2264 O Tr(\u03a3)/n + \u03a3 log(1/\u03b4)/n with probability 1 \u2212 \u03b4.\n\nIn the quantum setting, the univariate case X \u2208 R has been studied since the early works on quantum counting [BBHT98]. The celebrated amplitude estimation algorithm [BHMT02] provides a smaller error rate for estimating the mean of any Bernoulli random variable compared to the classical estimators. For general univariate distributions, a series of quantum estimators [Gro98; Ter99; AW99; Hei02; WCNA09; BDGT11; Mon15; HM19; Ham21] culminated into a near-optimal algorithm that outperforms any classical estimator. On the other hand, the multivariate case X \u2208 R d , appearing notably in machine learning applications, remains largely unaddressed by quantum algorithms. Classically, it admits a simple near-optimal approach: the d coordinates of \u00b5 can all be estimated simultaneously with d univariate sub-Gaussian estimators run in parallel (i.e., using the same samples from X) with only a logarithmic overhead log(d) in sample complexity (due to the Hoeffding bound). In the quantum scenario however, this simultaneous evaluation of several univariate expectation values is more complicated. Indeed, the quantum algorithms for the univariate case rely on quantum amplitude estimation [BHMT02], which involves as a critical step an encoding of the expectation value in the relative phase of a quantum register. At first sight, it is unclear how a vector of d phases could be encoded simultaneously into d registers without requiring a linear overhead in d. In fact, a lower bound proved by Heinrich [Hei04] rules out the possibility of simply a log(d) overhead for the quantum multivariate mean estimation problem.\n\nOur paper develops near-optimal and computationally efficient quantum mean estimators for vector-valued random variables of arbitrary dimension with binary oracle access. Unlike in the univariate setting (d = 1), where the optimal quantum estimator [Ham21] is strictly more efficient than any classical estimator, we identify two different regimes in higher dimension: (i) if a quantum estimator is limited to accessing the input at most d times (i.e. n \u2264 d) then no advantage can be gained over the classical sub-Gaussian estimators, (ii) if it can access the input at least d times (i.e. n \u2265 d) then the approximation error can be reduced by a near-optimal factor of d/n compared to classical sub-Gaussian estimators.\n\nWe complement this work with new quantum estimators in the weaker phase oracle access model, where the information about X are directly encoded into the phases of quantum registers. This model has been considered before [GAW19], albeit not in the context of quantum mean estimation. We adapt some of our techniques to this model and show that here we can even obtain near-optimal estimators with respect to any p -norm, with p \u2208 [1, \u221e], thereby providing a complete characterization of the query complexities involved in the mean estimation problem. This part of our work shares some overlap with a related paper by a subset of the authors [CJ21] that focused on the probability and phases oracles models for multivariate Monte Carlo estimation.\n\n\nContributions\n\nOur main contribution is the design of new quantum mean estimators that achieve the best possible error rates, up to logarithmic factors, in the multivariate setting. We investigate this problem in two different quantum input models. We first consider the binary oracle model in Section 3, which generalizes in a natural way the classical sample complexity and is the most frequent setting used in previous work (e.g. [AW99; Hei02; BHH11; BDGT11; Mon15;Ham21]). In this model, the access to a d-dimensional random variable X : \u2126 \u2192 R d over a probability space (\u2126, 2 \u2126 , P) is provided through two unitary operators: one that prepares a superposition over the probability space U P : |0 \u2192 \u03c9\u2208\u2126 P(\u03c9)|\u03c9 , and one that evaluates the random variable over the sample set B X : |\u03c9 | 0 \u2192 |\u03c9 |X(\u03c9) . Note that the mean to be estimated is \u00b5 = \u03c9\u2208\u2126 P(\u03c9)X(\u03c9). Our first main contribution is to provide an optimal multivariate quantum mean estimator in this setting. Our approach is substantially more involved than in the univariate case [Ham21]. A core primitive developed in our work is a new estimator for random variables bounded in 2 -norm. This can be seen as a multivariate version of the well-known Amplitude Estimation algorithm [BHMT02]. Our techniques are based on the Bernstein-Vazirani algorithm [BV97] (more precisely, its generalization to estimating a linear function over the reals [Jor05]), the quantum singular value transformation framework [GSLW19], and tail inequalities for truncated statistics. We state our first result below with respect to the \u221e -norm to highlight that it will be more natural to use this metric in our algorithms and convert to 2 -norm by standard norm inequalities.\n\nTheorem 3.3 (Informal). There is a quantum estimator that estimates the mean \u00b5 of any d-dimensional random variable X with error \u00b5 \u2212 \u00b5 \u221e \u2264 \u221a L 2 log(d) n and success probability 2/3, given an upper bound L 2 \u2265 E[ X 2 ] and O(n) queries to the oracles U P and B X . The error made by this estimator in 2 -norm is \u00b5 \u2212 \u00b5 2 \u2264 \u221a dL 2 log(d) n\n\n.\n\nAs an illustration of this result, one can simultaneously estimate the expectation values of d univariate random variables X 1 , . . . , X d distributed in [0, 1] each with error \u221a d log(d)/n by doing O(n) queries. In comparison, running the Amplitude Estimation algorithm on each random variable separately (with O(n/d) queries) would result in an error of d/n.\n\nSimilarly to the Amplitude Estimation algorithm, the above primitive estimator does not always provide an optimal error rate with respect to the trace Tr(\u03a3) = E[ X 2 2 ] \u2212 E[X] 2 2 of the covariance matrix \u03a3 of X. Moreover, it requires the 2 -norm of X to be bounded by 1. We improve upon this result to design the next optimal quantum mean estimator.\n\nTheorem 3.5 (Informal). There is a quantum estimator in the binary oracle model that estimates the mean \u00b5 of any d-dimensional random variable X with error\n\u00b5 \u2212 \u00b5 2 \u2264 \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 Tr(\u03a3) n , if n \u2264 d, \u221a d Tr(\u03a3) log(d) n , if n > d,\nand success probability 2/3, given O(n) queries to the oracles U P and B X .\n\nThis bound is achieved by using any classical sub-Gaussian estimators [LM19a] when n \u2264 d, and a new quantum estimator when n \u2265 d. We show that these two regimes are inevitable since no quantum speed-up is possible when n \u2264 d, whereas our quantum estimator is optimal when n \u2265 d. Our lower bounds are based on the quantum query complexity of approximating a bit string whose entries are determined by parity functions.\n\nTheorems 3.7 and 3.8 (Informal). For any estimator that uses at most n binary oracle queries, there is a d-dimensional random variable X such that, with probability 2/3, the error is at least\n\u00b5 \u2212 \u00b5 2 \u2265 \u2126 Tr(\u03a3) n if n \u2264 d, and \u00b5 \u2212 \u00b5 2 \u2265 \u2126 \u221a d Tr(\u03a3) n if n \u2265 d.\nNext, in Section 4, we investigate the mean estimation problem in the phase oracle model where the aforementioned unitary B X is replaced with phase access P X : |\u03c9 |j \u2192 e iX(\u03c9) j |\u03c9 |j to the coordinates of X. This model can be efficiently simulated using a binary oracle but the converse is generally not true. In fact, even obtaining one classical sample from X using a phase oracle is generally a hard task. On the other hand, as explained in [GAW19], this model arises naturally in the context of variational quantum eigensolvers, QAOA, and quantum auto-encoders for instance. This reason motivates understanding what is the optimal error rate for mean estimation in this weaker setting. Although a phase oracle does not allow to obtain an error depending on the covariance matrix, we manage to adapt some of the techniques developed for binary oracles to arrive at an optimal estimator when X is bounded in \u221e -norm by X \u221e \u2264 1/4. Interestingly, our results differ qualitatively from those in the binary oracle setting in two aspects. First, our estimator does not make the same number of queries to the oracles U P and P X , and the optimal precision depends in fact differently on these two parameters. Second, in this model, we are actually able to tightly characterize the optimal performance with respect to all p -norms, where p \u2208 [1, \u221e], up to polylogarithmic factors. We state our results here only with respect to the 2 -norm for ease of exposition and comparison to the binary oracle setting, and we show that these results are nearly optimal in Theorem 4.10.\n\nTheorem 4.5 (Informal). There is a quantum estimator that estimates the mean \u00b5 of any d-dimensional random variable X such that X \u221e \u2264 1/4 with error\n\u00b5 \u2212 \u00b5 2 \u2264 \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 max d n , d 3/2 n \u00b7 log(d), if n \u2264 d, max d n , d 3/2 n \u00b7 log(d), if n > d,\nand success probability 2/3, given O(n) queries to the oracle U P and O(n ) queries to the oracle P X .\n\nFinally, we conclude this paper by giving some applications of the above results in Section 5. We first explain how our formulation of the multivariate mean estimation problem covers the general task of estimating the expectation values of several mutually commuting observables with respect to a given quantum state (Section 5.1). We then present several applications in the literature, and notably in quantum machine learning (training variational quantum circuits, Boltzmann machines, or reinforcement learning policies), where this problem arises (Section 5.2).\n\n\nProof overview\n\nWe give a high-level description of the algorithms developed in Section 3 for addressing the mean estimation problem in the binary oracle model. Similar techniques are employed in Section 4 for the phase oracle model. We simplify the exposition by replacing Tr(\u03a3) = E[ X \u2212 \u00b5 2 2 ] with the second moment E[ X 2 2 ], and by taking the failure probability \u03b4 to be a small constant. The approximation error \u00b5 \u2212 \u00b5 \u221e is measured here with respect to the \u221e -norm. is encoded as the phase of a particular unitary operator and estimated with error 1/n using phase estimation [Kit95]. Then, by standard trigonometric identities, | \u03d5 \u2212 \u03d5| \u2264 1/n implies that |sin 2 ( \u03d5) \u2212 E[X]| \u2264 2 E[X]/n + 1/n 2 (the lower-order term 1/n 2 can be removed by testing if E[X] \u2264 1/n 2 and outputting 0 if this is the case). We generalize this idea to higher dimensions in a novel way by considering the directional mean function u \u2192 u, E[X] where u \u2208 R d . By using a constant number of queries to X and amplitude-to-phase conversion techniques [GAW19], one can efficiently approximate the unitary |u \u2192 e i u,E[X] |u if | u, X | \u2264 1 almost surely. We could then estimate the directional mean u, E[X] with phase estimation, for sufficiently many values of u, in order to reconstruct an estimate of E[X]. However, this approach would incur a linear cost in the dimension d. Instead, since the directional mean is a linear function in u, we can use a variant of the Bernstein-Vazirani algorithm [BV97] to directly recover the entire vector E[X] (up to a certain precision) with fewer queries. This idea is also at the heart of the quantum gradient estimation algorithms [Jor05; GAW19], however it requires two major improvements for our setting. First, we can only make the assumptions that X is bounded in 2 -norm (i.e. X 2 \u2264 1) and u in \u221e -norm (i.e. u \u221e \u2264 1). However, these two conditions do not imply that | u, X | \u2264 1 as needed by the amplitude-to-phase conversion technique. We overcome this issue by proving tail inequalities for inner products and directional means (Lemma 3.1) showing that they do not exceed 1 with high probability under our assumptions. Hence, by suitable truncations, this gives us a first version of a bounded estimator with error 1/n. Secondly, we need to incorporate information about X in the error. We cannot reproduce the univariate approach by encoding arcsin( | u, Near-Optimal multivariate estimator. We build on the above bounded estimator to remove the assumption on the boundedness of X and decrease the error to E[ X 2 2 ]/n. Similarly to the univariate case [Hei02; Mon15; HM19; Ham21], we decompose X = X 0 + X 1 + X 2 + . . . into a sequence of truncated random variables X j = X1 a j\u22121 < X 2 \u2264a j over slices of the 2ball, where the values outside the range (a j\u22121 , a j ] are mapped to 0. The truncation levels 0 = a \u22121 < a 0 < a 1 < a 2 < . . . are chosen so that the bounded estimator performs well on each X j individually. In the univariate setting, this sequence followed a geometric progression of ratio 2. Here, we instead choose a j to be the quantile value of order 2 \u2212j satisfying Pr[ X 2 \u2265 a j ] \u2248 2 \u2212j . This new choice has the advantage that the expected norm of X j can be explicitly bounded as E[ X j 2 ] \u2264 2 \u2212j\u22121 (Equation (3)), a property needed by our bounded estimator. Moreover, we show that this sequence increases slowly enough so that a j \u2264 2 j/2 E[ X 2 2 ] (Equation (2)). Consequently, the bounded estimator can estimate separately the mean of each X j with an error of a j E[ X j 2 ]/n \u2264 2 \u22121/2 E[ X 2 2 ]/n (where the a j factor comes from normalizing X j to make it fit into the unit 2 -ball). Finally, each quantile a j can be computed (approximately) in time O(2 \u2212j/2 ) using the quantile estimator developed in [Ham21] (Proposition 2.9), and we only need to consider j \u2264 O(log n) truncated random variables since the part of X above that threshold does not contribute to a significant portion of the mean (Equation (4)). This leads to the final error of E[ X 2 2 ]/n (Theorem 3.4).\nE[X] |) instead of u, E[X] into\n\nRelated work\n\nThere is an extensive literature on classical mean estimators and we refer the reader to [LM19a] for an excellent survey on the optimal sub-Gaussian estimators in Euclidean norm. We point out that the empirical mean estimator is generally not optimal, and its error is captured by several standard concentration bounds such as the Chebyshev, Chernoff and Bernstein inequalities.\n\nThere is a series of quantum univariate mean estimators [Gro98; AW99; BDGT11] that get close to the error 1/n for random variables distributed in [0, 1] (and success probability 2/3). The amplitude estimation algorithm [BHMT02;Ter99] leads to a sharper bound of \u221a \u00b5/n.\n\nNevertheless, the mean \u00b5 is always larger than or equal to the variance \u03c3 2 when X is distributed in [0, 1]. The question of improving the dependence on \u03c3 2 was considered in [Hei02; Mon15; HM19; Ham21], where it is shown that the optimal error is \u03c3/n. There are very few works addressing the quantum multivariate mean estimation problem. Heinrich [Hei04] proved that the error rate must depend on 1/n when the dimension is sufficiently large. Our lower bound in the n \u2264 d regime (Theorem 3.7) refines this statement by adding a dependence on the covariance matrix. In a recent work, van Apeldoorn [Ape21] proposed a \"multidimensional Amplitude Estimation\" algorithm. However, it only applies to a restricted set of random variables and the error does not recover that of Amplitude Estimation when d = 1. More precisely, the author described a quantum algorithm for estimating with error 1/n (in \u221e -norm) a probability vector p = (p 1 , . . . , p d ) given access to a unitary U : |0 \u2192 i \u221a p i |i . This is a special case of the multivariate mean estimation problem, where the random variable X \u2208 {0, 1} d is equal to the basis vector e i with probability p i . Applying our main result (Theorem 3.4) to X decreases the error given in [Ape21] by a factor of Tr(\u03a3) = (1 \u2212 i\u2208[d] p 2 i ) 1/2 . Our work shares some similarities with the quantum gradient estimation algorithm of Jordan [Jor05; GAW19], which also uses an extension of the Bernstein-Vazirani algorithm to linear functions over the reals. However, unlike gradient estimation, the mean estimation problem requires combining this technique with further algorithmic steps.\n\n\nPreliminaries\n\n\nNotations\n\nThroughout the paper we use the O(x) and \u2126(x) notations to hide factors that are polylogarithmic in the argument x. We let | 0 denote a multiple qubits state |0 . . . 0 . We use the notation H aux when referring to an auxiliary Hilbert space of sufficiently large dimension. We consider the family of p -norms, defined as follows.\n\nDefinition 2.1 ( p -norm). Given p \u2208 [1, +\u221e), the p -norm x p of a d-dimensional vector x is defined as x p = ( i\u2208[d] |x i | p ) 1/p if p < \u221e, and x \u221e = max i\u2208[d] |x i |. We also let x = x 2 denote the 2 -norm, and for a matrix M we set M to be the induced 2 -norm (or spectral norm).\n\nGiven x \u2208 R d and 0 \u2264 a < b, we define the following truncation with respect to the 2 -norm.\nx b a = x if a < x 2 \u2264 b, 0 otherwise.\nWe recall the definition of a multivariate random variable. We only consider finite probability spaces for finite encoding reasons. Throughout the paper d \u2208 N will denote the dimension of the random variable whose mean is to be estimated.\n\nDefinition 2.2 (Random variable). A (finite) random variable is a function X : \u2126 \u2192 E for some probability space (\u2126, 2 \u2126 , P), where \u2126 is a finite sample set, P : \u2126 \u2192 [0, 1] is a probability mass function and E \u2282 R d is the finite support of X. The covariance matrix \u03a3 \u2208 R d\u00d7d of X is defined as\n\u03a3 = E[XX ] \u2212 E[X]E[X] .\nWe say that X is univariate if the dimension is d = 1, and multivariate otherwise. For any norm . over R d , we let X denote the univariate random variable \u03c9 \u2192 X(\u03c9) . Finally, we recall the definition of a quantile value (using the complementary cumulative distribution function).\n\nDefinition 2.3 (Quantile). Given a discrete real-valued random variable X and a real p \u2208 [0, 1], the quantile of order p is the number Q(p) = sup{x \u2208 R : Pr[X \u2265 x] \u2265 p}.\n\n\nInput models\n\nThe input to the multivariate mean estimation problem is represented by a random variable X taking values in R d . In this section, we describe two possible access models for quantum estimators. Before that, we first recall the classical model, which we refer to as a random experiment.\n\nDefinition 2.4 (Random experiment). Given a random variable X on a probability space (\u2126, 2 \u2126 , P), we define a random experiment as the process of drawing a sample \u03c9 \u2208 \u2126 according to P and observing the value of X(\u03c9) \u2208 R d .\n\nIn the quantum setting, we make a distinction between accessing the probability mass function P and evaluating the function X : \u2126 \u2192 E. The first operation is provided by means of a quantum experiment, defined in the following way.\n\nDefinition 2.5 (Quantum experiment). Consider a random variable X on a probability space (\u2126, 2 \u2126 , P). Let H \u2126 be a Hilbert space with basis states {|\u03c9 } \u03c9\u2208\u2126 and fix a unitary U P acting on H \u2126 such that U P : |0 \u2192 \u03c9\u2208\u2126 P(\u03c9)|\u03c9 assuming 0 \u2208 \u2126. We define a quantum experiment as the process of applying the unitary U P or its inverse U \u22121 P on any state in H \u2126 . We note that P is sometimes assumed to be the uniform distribution over some large set \u2126 = [N ] (e.g. [Gro98; NW99; Hei02; BHH11; CFMW10; BDGT11; LW19]). In this case, the access to the unitary U P need not be provided as part of the input.\n\nWe now describe two different quantum oracles for evaluating X. The first oracle provides a direct access to the value of X(\u03c9). This model is the most commonly used in previous work on quantum mean estimation (e.g. [Gro98; Ter99; NW99; Hei02; BDGT11; Mon15; HM19]).\n\nDefinition 2.6 (Binary oracle). Consider a finite random variable X : \u2126 \u2192 E on a probability space (\u2126, 2 \u2126 , P). Let H \u2126 and H E be two Hilbert spaces with basis states {|\u03c9 } \u03c9\u2208\u2126 and {|x } x\u2208E respectively. We say that a unitary B X acting on H \u2126 \u2297 H E is a binary oracle for X if\nB X : |\u03c9 | 0 \u2192 |\u03c9 |X(\u03c9)\nfor all \u03c9 \u2208 \u2126, assuming 0 \u2208 E.\n\nObserve that one random experiment can be simulated by preparing the state \u03c9\u2208\u2126 P(\u03c9)|\u03c9 |X(\u03c9) and measuring its last register in the {|x } x\u2208E basis. This requires using one quantum experiment and one call to the binary oracle.\n\nOur second type of oracle provides individual access to the coordinates of X(\u03c9), encoded into the phases of a query operator. This model appears naturally in the context of variational eigensolvers, QAOA, and training variational auto-encoders [GAW19], albeit not in relation to the quantum mean estimation problem. This input model can be efficiently simulated using a binary oracle, but the converse is generally not true. In fact, even obtaining one classical sample from X may not be easy to do using a phase oracle.\n\nDefinition 2.7 (Phase oracle). Consider a finite random variable X : \u2126 \u2192 E on a probability space (\u2126, 2 \u2126 , P). Let H \u2126 be a Hilbert space with basis states {|\u03c9 } \u03c9\u2208\u2126 . We say that a unitary P X acting on H \u2126 \u2297 C d is a phase oracle for X if P X : |\u03c9 |j \u2192 e iX(\u03c9) j |\u03c9 |j for all \u03c9 \u2208 \u2126 and j \u2208 [d].\n\n\nAlgorithmic tools\n\nWe first recall the optimal classical error bound for estimating the mean of a multivariate random variable with respect to the Euclidean norm.\n\nProposition 2.8 (Classical sub-Gaussian estimators, [LM19a]). Let X be a d-dimensional random variable with mean \u00b5 and covariance matrix \u03a3. Given \u03b4 \u2208 (0, 1) and n \u2265 log(1/\u03b4), the sub-Gaussian estimators outputs a mean estimate \u00b5 such that\n\u00b5 \u2212 \u00b5 2 \u2264 Tr(\u03a3) n + \u03a3 log(1/\u03b4) n with probability at least 1 \u2212 \u03b4, by using O(n) random experiments.\nWe now present four quantum subroutines used in our work. We first need an algorithm introduced in [DH96; NW99] and generalized in [Ham21] for estimating the quantiles (Definition 2.3) of a univariate random variable quadratically faster than it is possible classically.\n\nProposition 2.9 (Quantile estimator, [Ham21]). Let X be a univariate random variable. Given two reals p, \u03b4 \u2208 (0, 1), the quantile estimation algorithm Quantile(X, p, \u03b4) returns an approximate quantile Q that satisfies\nQ(p) \u2264 Q \u2264 Q(cp)\nwith probability at least 1\u2212\u03b4 for some universal constant c \u2208 (0, 1). The algorithm uses O log(1/\u03b4) \u221a p quantum experiments and binary oracle queries to X.\n\nNext, we will use a variant of amplitude amplification [BHMT02] that provides a precise linear amplification of the amplitude.\n\nProposition 2.10 (Linear amplitude amplification, Theorem 6.10 in [Low17] or Lemma 11 in [GL20]). Let V be a unitary operator and let \u03a0 be a projection operator acting on the same Hilbert space. Given two reals t \u2265 1 and \u2208 (0, 1) there is a unitary operator V t, that can be implemented with O(t log(1/ )) applications of V , V \u2020 and I \u2212 2\u03a0, and such that\n\u03a0V t, | 0 \u2212 t \u03a0V | 0 \u2264 if t \u03a0V | 0 \u2264 1/2.\nFinally, the next two results provide efficient algorithms for converting between phase and amplitude encodings.\n\nLemma 2.11 (Amplitude-to-Phase conversion, Corollary 4.1 in [GAW19]). Let V be a unitary operator acting on some Hilbert space H U \u2297 H such that\nV : |u | 0 \u2192 |u ( 1 \u2212 p u |\u03c8 0 u |0 + \u221a p u |\u03c8 1 u |1 )\nwhere {|u } u\u2208U is the standard basis of H U , p u \u2208 (0, 1) and |\u03c8 0 u , |\u03c8 1 u are some arbitrary unit states. Then, given two reals t \u2265 0 and \u2208 (0, 1), there is a unitary operator P t, acting on\nH U \u2297 H \u2297 H aux that can be implemented with O(t + log(1/ )) applications of V and V \u2020 , such that P t, : |u | 0 \u2192 |u |\u03d5 u where |\u03d5 u \u2212 e itpu | 0 \u2264 , for all u \u2208 U .\nLemma 2.12 (Phase-to-Amplitude conversion, Lemma 16 in [GAW17]). Let P be a unitary operator acting on some Hilbert space H U such that\nP : |u \u2192 e ipu |u\nwhere {|u } u\u2208U is the standard basis of H U and p u \u2208 [\u03b4, 1 \u2212 \u03b4] for some \u03b4 \u2208 (0, 1/2). Then, given a real \u2208 (0, 1), there is a unitary operator V ,\u03b4 acting on H U \u2297 H aux \u2297 C 2 that can be implemented with O(log(1/ )/\u03b4) applications of P and P \u2020 , such that\nV ,\u03b4 : |u | 0 |0 \u2192 |u p u | 0 |0 + 1 \u2212 p u |\u03c8 |1 where p u \u2212 \u221a p u \u2264 ,\nfor all u \u2208 U and some state |\u03c8 .\n\n\nMean estimation with binary oracles\n\n\nBounded multivariate estimator\n\nIn this section, we generalize the univariate bounded estimator [Ter99; WCNA09; Mon15] derived from Amplitude Estimation [BHMT02] to the multivariate setting X \u2208 R d . Our main ingredient is the construction of an approximate phase oracle for the directional mean u, E[X] , where the vectors u \u2208 R d are selected from the grid of points,\nG = j m \u2212 1 2 + 1 2m : j \u2208 {0, . . . , m \u2212 1} d \u2282 (\u22121/2, 1/2) d\nwith m being defined in step 2 of Algorithm 1. We let u \u223c G denote a vector obtained according to the uniform distribution over G. We also define H G to be the Hilbert space whose standard basis is indexed by the elements of G. Our algorithm requires encoding the inner product u, X into an amplitude. However, this quantity can be as large as \u221a d assuming X 2 \u2264 1. The next crucial result shows that it is in fact much smaller than \u221a d for most values of u.\n\nLemma 3.1. Let \u03b1 > 0. For any vector x \u2208 R d and any random variable X over R d we have,\nPr u\u223cG \u03b1| u, x | \u2265 x 2 \u2264 2e \u22122/\u03b1 2 and Pr u\u223cG \u03b1E[| u, X |] \u2265 E[ X 2 ] \u2264 \u03b1/2.\nProof. We use that the coordinates of a uniformly random vector u \u2208 G are independent centered random variables bounded in (\u22121/2, 1/2). The first result is obtained using Hoeffding's inequality,\nPr u [\u03b1| u, x | \u2265 x 2 ] \u2264 2 exp \u22122 x 2 2 d j=1 |\u03b1x j | 2 = 2e \u22122/\u03b1 2 , since E u [ u, x ] = 0 for all x \u2208 R d . For the second result, we have by Markov's inequality that Pr u\u223cG \u03b1E[| u, X |] \u2265 E[ X 2 ] \u2264 Eu[\u03b1E[| u,X |]] E[ X 2 ] = \u03b1E[Eu[| u,X |]] E[ X 2 ] . By Cauchy-Schwarz inequality, E u [| u, x |] \u2264 E u [ u, x 2 ] = d j=1 E u j [(u j x j ) 2 ] \u2264 x 2 /2 for all x \u2208 R d . Thus, Pr u\u223cG [\u03b1E[| u, X |] \u2265 E[ X 2 ]] \u2264 \u03b1/2.\nUsing the above lemma, one can encode (for most values of u) the truncated directional mean E[ \u03b1 u, X 1 0 ] into an amplitude and apply oracle conversion techniques to approximate the phase oracle |u \u2192 e iE[ \u03b1 u,X 1 0 ] |u with accuracy at cost O(log(1/ )). The cost of applying m times this oracle is then O(m log(1/ )). We describe a more subtle algorithm where the latter complexity becomes O(m \u221a L 2 log 2 (1/ )) given an upper-bound Proposition 3.2 (Directional mean oracle). Let X be a d-dimensional bounded random variable such that X 2 \u2264 1. Given four reals L 2 \u2208 (0, 1], m \u2265 1/L 2 , \u03b1, \u2208 (0, 1) such that E[ X 2 ] \u2264 L 2 , there exists a unitary operator P X,L 2 ,m,\u03b1, : |u | 0 \u2192 |u |\u03d5 u acting on H G \u2297 H aux that can be implemented using O m \u221a L 2 log 2 (1/ ) quantum experiments and binary oracle queries to X, and such that\nL 2 \u2265 E[ X 2 ].|\u03d5 u \u2212 e imE[ \u03b1 u,X 1 0 ] | 0 \u2264 for a fraction at least 1 \u2212 \u03b1/2 of all u \u2208 G.\nProof. Fix u and consider the random variable X + defined over the same probability space as X such that X + (\u03c9) = X(\u03c9) when \u03b1 u, X(\u03c9) > 0 and X + (\u03c9) = 0 otherwise. Similarly, define X \u2212 such that X \u2212 (\u03c9) = X(\u03c9) if \u03b1 u, X(\u03c9) < 0 and X \u2212 (\u03c9) = 0 otherwise. Since E \u03b1 u, X 1 0 = E \u03b1 u, X + 1 0 + E \u03b1 u, X \u2212 1 0 it is sufficient to explain how to construct a unitary P + : |u | 0 \u2192 |u |\u03d5 +,u such that |\u03d5 +,u \u2212 e imE[ \u03b1 u,X + 1 0 ] | 0 \u2264 /2 when \u03b1E[| u, X |] \u2264 L 2 . One can construct P \u2212 that encodes E \u03b1 u, X \u2212 1 0 using a similar approach. The proposition then follows by taking the product P X,L 2 ,m,\u03b1, = P + P \u2212 and noting that Pr\nu [\u03b1E[| u, X |] \u2265 L 2 ] \u2264 \u03b1/2 by the second part of Lemma 3.1 since E[ X 2 ] \u2264 L 2 .\nThere are three steps in the construction of P + . First, we construct a unitary V + acting on H G \u2297 H \u2126 \u2297 H E \u2297 C 2 as follows,\nV + : |u | 0 |0 \u2192 \u03c9\u2208\u2126 P(\u03c9)|u |\u03c9, X(\u03c9) |0 \u2192 \u03c9\u2208\u2126 P(\u03c9)|u |\u03c9, X(\u03c9) 1 \u2212 \u03b1 u, X + (\u03c9) 1 0 |0 + \u03b1 u, X + (\u03c9) 1 0 |1 = 1 \u2212 E[ \u03b1 u, X + 1 0 ]|u |\u03c8 0 u |0 + E[ \u03b1 u, X + 1 0 ]|u |\u03c8 1 u |1\nwhere the first step uses one quantum experiment and one binary oracle query to X, the second step performs a sequence of controlled rotations, and in the last line |\u03c8 0 u , |\u03c8 1 u are some irrelevant unit states. Secondly, if L 2 < 1/4, we apply the Linear Amplitude Amplification algorithm of Proposition 2.10 on V + with t = 1/(2 \u221a L 2 ) and accuracy /(32mL 2 ), which gives a unitary\nW + : |u | 0 |0 \u2192 \u221a 1 \u2212 p u |u |\u03c8 0 u |0 + \u221a p u |u |\u03c8 1 u |1 where, for each u \u2208 G, \u221a p u \u2212 E[ \u03b1 u, X + 1 0 ] 4L 2 \u2264 32mL 2 , if E[ \u03b1 u, X + 1 0 ] \u2264 L 2 , using O(log(mL 2 / )/ \u221a L 2 ) applications of V + and V \u2020 + . If L 2 < 1/4 we directly take W + = V + .\nThirdly, we define L 2 = min(L 2 , 1/4) and apply the phase conversion algorithm of Lemma 2.11 on W + with t = 4mL 2 and accuracy /4. We obtain a unitary P + : |u | 0 \u2192 |u |\u03d5 +,u such that, by the triangle inequality, the state |\u03d5 +,u satisfies |\u03d5\n+,u \u2212 e imE[ \u03b1 u,X + 1 0 ] | 0 \u2264 |\u03d5 +,u \u2212 e i4mL 2 pu | 0 + e i4mL 2 pu \u2212 e imE[ \u03b1 u,X + 1 0 ] \u2264 /4 + 4mL 2 p u \u2212 mE[ \u03b1 u, X + 1 0 ] = /4 + 4mL 2 \u221a p u \u2212 E[ \u03b1 u,X + 1 0 ] 4L 2 \u00b7 \u221a p u + E[ \u03b1 u,X + 1 0 ] 4L 2 . Thus, for each u \u2208 G, |\u03d5 +,u \u2212 e imE[ \u03b1 u,X + 1 0 ] | 0 \u2264 /2, if E[ \u03b1 u, X + 1 0 ] \u2264 L 2 ,\nand P + uses O(mL 2 +log(1/ )) applications of W + and W \u2020 + . Overall, we used O(m \u221a L 2 log 2 (1/ )) quantum experiments and binary oracle queries to X to implement one application of P + . Moreover, the condition E[ \u03b1 u, X +\n1 0 ] \u2264 L 2 is implied by \u03b1E[| u, X |] \u2264 L 2 .\nWe finally describe the algorithm that estimates the mean of any bounded random variable (Algorithm 1). Our approach relies on applying the quantum Fourier transform over G to the above directional mean oracle in a similar manner as in previous work (e.g. [BV97; Jor05; GAW19]). The results of Lemma 3.1 play again a central role in the analysis.\nTheorem 3.3 (Bounded multivariate estimator). Let X be a d-dimensional bounded random variable such that X 2 \u2264 1. Given three reals L 2 \u2208 (0, 1], \u03b4 \u2208 (0, 1) and n \u2265 1 such that E[ X 2 ] \u2264 L 2 , the bounded multivariate estimator QBounded d (X, L 2 , n, \u03b4) (Algorithm 1) outputs a mean estimate \u00b5 of \u00b5 = E[X] such that \u00b5 \u2212 \u00b5 \u221e \u2264 \u221a L 2 log(d/\u03b4) n\nwith probability at least 1 \u2212 \u03b4. It uses O(n) quantum experiments and binary oracle queries to X.\nProof. If n \u2264 log(d/\u03b4) \u221a L 2 then by choosing \u00b5 = 0 at step 1 we directly have \u00b5 \u2212 \u00b5 \u221e \u2264 E[ X 2 ] \u2264 \u221a L 2 log(d/\u03b4) n\n. Thus, we can suppose from now on that n > log(d/\u03b4) \u221a L 2 (in particular, m \u2265 1/L 2 ).\n1. If n \u2264 log(d/\u03b4) \u221a L 2 then output \u00b5 = 0. 2. Set \u03b1 = 1 \u221a log(400\u03c0n \u221a d)\nand m = 2\nlog 8\u03c0 \u03b1 \u00b7 n \u221a L 2 log(d/\u03b4) .\n3. For k = 1, . . . , 18 log(d/\u03b4) :\n\n(a) Compute the uniform superposition |G := 1 \nm d/2 u\u2208G |u over G. (b) Compute the state |\u03c8 := P X,L 2 ,m,\u03b1, |G | 0 \u2208 H G \u2297 H aux , where P X,L 2 ,m,v (k) \u2208 G denote the obtained result. Set \u00b5 (k) = 2\u03c0 \u03b1 v (k) .\n4. Output the coordinate-wise median \u00b5 = median( \u00b5 (1) , . . . , \u00b5 ( 18 log(d/\u03b4) ) ).\n\nAlgorithm 1: Bounded multivariate estimator, QBounded d (X, L 2 , n, \u03b4).\n\nLet |\u03c8 , |\u03c8 \u2208 H G \u2297 H aux be the two unit states defined as follows,\n|\u03c8 = 1 m d/2 u\u2208G e imE[ \u03b1 u,X 1 0 ] |u | 0 and |\u03c8 = 1 m d/2 u\u2208G e im\u03b1 u,E[X] |u | 0 .\nWe first show that the state |\u03c8 at step 3b satisfies |\u03c8 \u2212 |\u03c8 \u2264 1/12. On one hand, by Proposition 3.2, we have |\u03c8 \u2212 |\u03c8 2 = 1\nm d u P X,L 2 ,m,\u03b1, (|u | 0 ) \u2212 e imE[ \u03b1 u,X 1 0 ] |u | 0 2 \u2264 2 + \u03b1.\nOn the other hand, by using the inequality sin 2 (x) \u2264 |x|, we have |\u03c8 \u2212 |\u03c8 2 =\n4 m d u\u2208G sin 2 m 2 E \u03b1 u, X 1 0 \u2212 \u03b1 u, E[X] \u2264 2m m d u\u2208G E \u03b1 u, X 1 0 \u2212 \u03b1 u, E[X] \u2264 2m m d E u \u03b1 u, X 1 0 \u2212 \u03b1 u, X \u2264 2m\u03b1 \u221a d Pr u [\u03b1| u, X | > 1] where the last step uses | u, X | \u2264 \u221a d.\nBy the first part of Lemma 3.1, we have Pr u \u03b1| u, X | \u2265 1 \u2264 2e \u22122/\u03b1 2 since X 2 \u2264 1. Thus, |\u03c8 \u2212 |\u03c8 2 \u2264 4m\u03b1 \u221a de \u22122/\u03b1 2 . By the triangle inequality, |\u03c8 \u2212 |\u03c8 \u2264 \u221a 2 + \u03b1 + 2 \u221a m\u03b1d 1/4 e \u22121/\u03b1 2 \u2264 1/12. We now analyse steps 3c and 3d of the algorithm assuming |\u03c8 is replaced with |\u03c8 . Let v \u2208 G denote the vector obtained by measuring the first register of (QFT \u22121 G \u2297 I aux )|\u03c8 in the computational basis. Since the phases satisfy \u03b1E[X] \u221e \u2264 2\u03c0/3, we can apply the analysis of phase estimation (e.g. [GAW19, Lemma 5.1]) to conclude that v j \u2212 \u03b1 2\u03c0 E[X] j \u2264 4/m with probability at least 5/6 for each j \u2208 [d]. By replacing |\u03c8 with |\u03c8 , we achieve the same result with probability at least 5/6 \u2212 2 |\u03c8 \u2212 |\u03c8 \u2265 2/3. Finally, by the Chernoff bound,\n\u00b5 \u2212 E[X] \u221e \u2264 8\u03c0/(\u03b1m) \u2264 \u221a L 2 log(d/\u03b4)/n with probability at least 1 \u2212 \u03b4.\n\nThe total number of quantum experiments and binary oracle queries to\nX is O(log(d/\u03b4) \u00b7 m \u221a L 2 log 2 (1/ )) = O(n/\u03b1) = O(n).\n\nNear-optimal multivariate estimator\n\nWe describe in Algorithm 2 our main quantum algorithm for estimating the mean of a ddimensional random variable in the binary oracle model. Our approach relies on applying the bounded multivariate estimator, developed in the previous section, to a sequence of carefully chosen truncated random variables.\n\nTheorem 3.4 (Near-optimal multivariate estimator). Let X be a d-dimensional random variable with mean \u00b5 and covariance matrix \u03a3. Given two reals \u03b4 \u2208 (0, 1) and n \u2265 log(d/\u03b4), the 1. Set k = 2 log 2 \u221a 2n log(d/\u03b4) and n = n \u00b7 (k+1)4 log(5kd/\u03b4)\n\u221a c log(d/\u03b4)\nwhere c is the constant mentioned in Theorem 2.9.\n\n2. Run any classical sub-Gaussian estimator (Proposition 2.8) on X using O(log(1/\u03b4)) samples to compute a mean estimate \u03b7 \u2208 R d such that Pr \u03b7 \u2212 \u00b5 2 > Tr(\u03a3) \u2264 \u03b4/2.\n\n3. Define the random variable Y = X \u2212 \u03b7.\n\n4. For j = 0, . . . , k:\n\n(a) Compute an estimate a j of the quantile of order 2 \u2212j of Y 2 by using the quantile estimator Quantile( Y 2 , 2 \u2212j , \u03b4/(5k)).\n(b) Define the bounded random variable Y j = 1 a j Y a j a j\u22121 (where a \u22121 = 0). If a j\u22121 = a j then set \u00b5 j = 0, else compute an estimate \u00b5 j of E[Y j ] by using the bounded multivariate estimator QBounded d (Y j , 2 \u2212(j\u22121) , n , \u03b4/(5k)). 5. Output \u00b5 = \u03b7 + k j=0 a j \u00b5 j .\nAlgorithm 2: Near-optimal multivariate estimator, QEstimator d (X, n, \u03b4).\n\nquantum multivariate estimator QEstimator d (X, n, \u03b4) (Algorithm 2) outputs a mean estimate \u00b5 such that\n\u00b5 \u2212 \u00b5 \u221e \u2264 Tr(\u03a3) log(d/\u03b4) n\nwith probability at least 1 \u2212 \u03b4. It uses O(n) quantum experiments and binary oracle queries to X.\n\nProof. The main part of the proof is to show that the mean estimate\n\u00b5 Y = k j=0 a j \u00b5 j of \u00b5 Y = E[Y ] satisfies \u00b5 Y \u2212 \u00b5 Y \u221e \u2264 E[ Y 2 2 ] log(d/\u03b4) \u221a 2n (1) with probability at least 1 \u2212 \u03b4/2. The theorem follows since \u00b5 \u2212 \u00b5 \u221e = \u00b5 Y \u2212 \u00b5 Y \u221e and E[ Y 2 2 ] = E[ X \u2212 \u00b5 2 2 ] + \u00b5 \u2212 \u03b7 2 2 = Tr(\u03a3) + \u00b5 \u2212 \u03b7 2 2 \u2264 2 Tr(\u03a3),\nwhere the last inequality holds with probability at least 1 \u2212 \u03b4/2. The algorithms uses O(k2 k/2 log(k/\u03b4) + kn ) = O(n) quantum experiments and binary oracle queries to X.\n\nWe now turn to the proof of Equation (1). We make the assumption that all the subroutines used in step 4 are successful, which is the case with probability at least (1 \u2212 \u03b4/(5k)) 2k+2 \u2265 1 \u2212 \u03b4/2. The sequence (a j ) j of quantile estimates computed at step 4a satisfies Q(2 \u2212j ) \u2264 a j \u2264 Q(c2 \u2212j ) for all j \u2208 {0, . . . , k}, where c is the constant mentioned in Theorem 2.9. On one hand, by Markov's inequality,\nPr[ Y 2 \u2265 a j ] = Pr[ Y 2 2 \u2265 a 2 j ] \u2264 E[ Y 2 2 ]/a 2 j .\nOn the other hand, by definition of the quantile function,\nPr[ Y 2 \u2265 a j ] \u2265 Pr[ Y 2 \u2265 Q(c2 \u2212j )] \u2265 c2 \u2212j . Thus, a j \u2264 c \u22121/2 2 j/2 E[ Y 2 2 ]. (2) Since Pr[ Y 2 > a j\u22121 ] \u2264 Pr[ Y 2 > Q(2 \u2212(j\u22121) )] < 2 \u2212(j\u22121) , we also have that E[ Y j 2 ] < 2 \u2212(j\u22121) .(3)\nHence, 2 \u2212(j\u22121) is a valid upper bound on the expectation of Y j 2 . Consequently, by Theorem 3.3,\neach estimate \u00b5 j satisfies \u00b5 j \u2212 E[Y j ] \u221e \u2264 2 \u2212(j\u22121)/2 log(5kd/\u03b4) n . Moreover, the truncated random variable Y +\u221e a k satisfies, Y +\u221e a k \u221e \u2264 Y +\u221e a k 2 \u2264 E[ Y 2 2 ] Pr[ Y 2 > a k ] \u2264 E[ Y 2 2 ] 2 k/2 (4)\nwhere the first step is by monotonicity of the norm and the second is by Cauchy-Schwartz inequality. Overall, the error is\n\u00b5 Y \u2212 \u00b5 Y \u221e \u2264 k j=0 a j 2 \u2212(j\u22121)/2 log(5kd/\u03b4) n + Y +\u221e a k \u221e \u2264 (k+1) \u221a 2E[ Y 2 2 ] log(5kd/\u03b4) \u221a cn + \u221a E[ Y 2 2 ] 2 k/2 \u2264 \u221a E[ Y 2 2 ] log(d/\u03b4) \u221a 2n\n.\n\nAs a direct corollary of Proposition 2.8 and Theorem 3.4, we obtain the following result for estimating the mean in Euclidean norm. We prove in the next section that these bounds are optimal for all values of n and d, up to logarithmic factors.\n\nTheorem 3.5 (Multivariate estimator in Euclidean norm). There exists a quantum estimator with the following properties. Let X be a d-dimensional random variable with mean \u00b5 and covariance matrix \u03a3. Given two reals \u03b4 \u2208 (0, 1) and n \u2265 log(d/\u03b4), the estimator outputs a mean estimate \u00b5 such that\n\u00b5 \u2212 \u00b5 2 \u2264 \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 Tr(\u03a3) n + \u03a3 log(1/\u03b4) n , if n \u2264 d, \u221a d Tr(\u03a3) log(d/\u03b4) n , if n > d,\nwith probability at least 1 \u2212 \u03b4. It uses O(n) quantum experiments and binary oracle queries to X.\n\nProof. If n \u2264 d we use any classical sub-Gaussian estimator (Proposition 2.8). If n > d we use the quantum estimator of Theorem 3.4 and the norm inequality\n\u00b5 \u2212 \u00b5 2 \u2264 \u221a d \u00b5 \u2212 \u00b5 \u221e .\n\nLower bounds\n\nOur lower bounds are based on reductions from the following composition problem, where the goal is to approximate an N -bit string whose entries are determined by parities over M bits.  We now show that the quantum mean estimators developed in the previous sections are tight (up to logarithmic factors). For simplicity in the proof, we only consider the case of approximation in Euclidean norm. We first prove that the mean estimation problem admits no quantum advantage when the complexity parameter n is smaller than the dimension. The proof works by a reduction from the Search \u03b1n \u2022 Parity 1 problem (where \u03b1 is the constant mentioned in Lemma 3.6).\n\nTheorem 3.7 (Low-precision regime). Consider two integers n, d such that n \u2264 d/\u03b1. Fix \u03c3 > 0 and let P \u03c3 denote the set of all d-dimensional quantum random variables with covariance matrix \u03a3 such that Tr(\u03a3) = \u03c3 2 . Then, for any quantum estimator that uses at most n binary oracle queries, there exists X \u2208 P \u03c3 such that the estimator returns a mean estimate \u00b5 of \u00b5 = E[X] that satisfies \u00b5 \u2212 \u00b5 2 \u2265 \u2126 Tr(\u03a3) n with probability at least 2/3.\n\n\nProof.\n\nWe assume for simplicity that \u03b1 is even and d is a power of two (the other cases can be handled by simple padding arguments). Consider the partial Hadamard matrix H \u2208 R \u03b1n\u00d7d such that\nH i,j = 1 d (\u22121) i,j , where i, j \u2208 {0, 1} log(d)\nare written over log(d) bits. Note that HH = I \u03b1n and the spectral norm of H is H = 1. Let (\u2126, 2 \u2126 , P) be the probability space such that \u2126 = [\u03b1n] and P(\u03c9) = 1/(\u03b1n) for all \u03c9 \u2208 \u2126. For any vector b \u2208 {0, 1} \u03b1n with Hamming weight b 1 = \u03b1n/2, define the random variable X (b) : \u2126 \u2192 R d such that,\nX (b) (i) = \u03b1\u03c3 n (\u03b1 2 n \u2212 \u03b1)/2 b i H i where H i \u2208 R d is the i-th row of H. The expectation of X (b) is E[X (b) ] = \u03c3 \u221a n(\u03b1 2 n\u2212\u03b1)/2 H b and the trace of its covariance matrix is Tr(\u03a3) = E[ X (b) 2 2 ] \u2212 E[X (b) ] 2 2 = 2\u03b1\u03c3 2 \u03b1 2 n\u2212\u03b1 b 1 \u2212 2\u03c3 2 n(\u03b1 2 n\u2212\u03b1) b 1 = \u03c3 2 .\nGiven any quantum estimator that uses n binary oracle queries to X (b) and outputs an estimate \u00b5 of \u00b5 = E[X (b) ], we can transform it into an algorithm for the Search \u03b1n \u2022 Parity 1 problem that uses n queries to b and returns the estimate b = \u221a n(\u03b1 2 n\u2212\u03b1)/2 \u03c3\nH \u00b5 with error b \u2212 b 2 \u2264 \u221a n(\u03b1 2 n\u2212\u03b1)/2 \u03c3 H( \u00b5 \u2212 \u00b5) 2 \u2264 \u03b1n \u03c3 \u00b5 \u2212 \u00b5 2 . Thus, by Lemma 3.6, there exists an input b such that \u00b5 \u2212 \u00b5 2 \u2265 \u03c3 \u03b1n b \u2212 b 2 = \u2126 \u03c3 \u221a n .\nWe now prove that the quantum estimator of Theorem 3.5 is optimal in the regime where n is larger than the dimension. The proof works by a reduction from the Search d \u2022 Parity \u03b1n/d problem.\n\nTheorem 3.8 (High-precision regime). Consider two integers n, d such that n > d/\u03b1. Fix \u03c3 > 0 and let P \u03c3 denote the set of all d-dimensional quantum random variables with covariance matrix \u03a3 such that Tr(\u03a3) = \u03c3 2 . Then, for any quantum estimator that uses at most n binary oracle queries, there exists X \u2208 P \u03c3 such that the estimator returns a mean estimate \u00b5 of \u00b5 = E[X] that satisfies\n\u00b5 \u2212 \u00b5 2 \u2265 \u2126 d Tr(\u03a3) n\nwith probability at least 2/3.\n\n\nProof.\n\nWe assume for simplicity that \u03b1n is a multiple of d, and d is even (the other cases can be handled by simple padding arguments  \u00b5. Thus, by Lemma 3.6, there exists an input A such that\nX (A) (i, j) = \u03b1\u03c3n (\u03b1n) 2 \u2212 2d 2 (\u22121) 1+A i,j e i where e i \u2208 R\u00b5 \u2212 \u00b5 2 \u2265 2\u03c3 \u221a (\u03b1n) 2 \u2212d 2 b \u2212 b (A) 2 = \u2126 \u221a d\u03c3 n .\n\nMean estimation with phase oracles\n\nIn some cases, we might not have access to the random variable X through a binary oracle B X , as considered in the previous part of this paper, but merely through a less powerful oracle. Several such input models arise naturally in the literature. For instance, in [GAW19], it is shown how phase oracles and probability oracles arise naturally in the context of variational quantum eigensolvers, QAOA, and quantum auto-encoders. In [Ape21], the author considers a quantum operation that prepares an unknown distribution, which we henceforth refer to as a distribution oracle. In [CJ21], we consider the multivariate mean estimation problem relative to all these input models.\n\nThere is one profound qualitative difference between all of these input models and the binary oracle setting considered in the previous section, which is that these input oracles in some sense preserve proximity. That is to say, if we have two random variables X and X, whose values differ by at most in some norm, then the operator norm difference between their respective input oracles is bounded by O(poly( )) too. This qualitatively differentiates this setting from the one considered in the previous sections, and we refer to input models satisfying this property as analog models.\n\nFor ease of exposition, in this part of the paper we only consider the case where our random variable X takes values bounded in the d-dimensional hypercube [\u22121/4, 1/4] d , and can be accessed through a phase oracle P X , as defined in Definition 2.7. We refer to [CJ21] for a more elaborate exposition of the other input models mentioned at the start of this section. Just like in the previous section, we assume to have access to the probability space via the oracle U P of Definition 2.5.\n\nSince its values are contained in the hypercube [\u22121/4, 1/4] d , the random variable X satisfies Var[X j ] \u2264 1/16 for all j \u2208 [d], and hence Tr[\u03a3] \u2264 d/16. This suggests that we can use the results from the previous section naively, to obtain a multivariate mean estimator in this setting as well.\n\nThere are two naive ways of approaching this. First, we can simulate a call to the binary oracle B X , considered in the previous part of this paper, using d consecutive runs of phase estimation on this phase oracle. Thus, if one only cares about the performance of the multivariate mean estimator expressed in the number of calls to U P , then it is clear that the same results can be obtained, that is, with n calls to U P , one can obtain a multivariate mean estimator that finds an approximation \u00b5 to \u00b5 which satisfies \u00b5 \u2212 \u00b5 \u221e = O( \u221a d/n). Secondly, if one only cares about the number of calls to P X , then a little more elaborate construction also readily reduces to the binary oracle setting. Using Lemma 2.12, one can turn the phase oracle P X into a probability oracle that given input |\u03c9 |j |0 prepares the state |\u03c9 |j ( 1/2 + X(\u03c9) j |1 + 1/2 \u2212 X(\u03c9) j |0 ). This operation can be combined with U P and an operation that prepares the uniform superposition over all j \u2208 [d], to obtain the operator U that acts as\nU : |0 |0 |0 \u2192 \u03c9\u2208\u2126 P(\u03c9)|\u03c9 \u2297 1 \u221a d d j=1 |j \u2297 1 2 + X(\u03c9) j |1 + 1 2 \u2212 X(\u03c9) j |0 .\nNow, let \u2126 = \u2126 \u00d7 [d] \u00d7 {0, 1}, and let P(\u03c9, j, b) = P(\u03c9)/(2d) \u2212 (\u22121) b P(\u03c9)X(\u03c9) j /d be a probability measure on \u2126. Furthermore, let the random variable Y : \u2126 \u2192 R d be defined as Y (\u03c9, j, b) = (1 i=j\u2227b=1 ) i\u2208 [d] . Then, implementing a binary oracle B Y is trivial, and the operation U above implements the operation U P . Finally, observe that E[Y ] = 1/(2d) + E[X]/d. Therefore, we can find an approximation\n\u00b5 Y to \u00b5 Y = E[Y ] which satisfies \u00b5 Y \u2212 \u00b5 Y \u221e = O( \u221a d/n ),\nwith n calls to U . Since U requires only polylogarithmically many calls to P X , and since E[Y ] is shrunk by a factor of d compared to \u00b5 = E[X], we can obtain an estimate \u00b5 such that \u00b5 \u2212 \u00b5 \u221e = O(d 3/2 /n ), with O(n ) calls to P X . Note that this approach also uses O(n ) calls to U P , so its performance in terms of number of quantum experiments is significantly worse compared to the previous approach.\n\nThe above two considerations lead to the natural question whether it is possible to combine both approaches, i.e., whether with n calls to U P and n calls to P X , it is possible to obtain an estimate \u00b5 that satisfies \u00b5 \u2212 \u00b5 \u221e = O(max{ \u221a d/n, d 3/2 /n }). In this section, we show that this is indeed possible, and that one can even shave off a factor of \u221a d in the second branch of the maximum. This result is displayed in Theorem 4.3.\n\nInterestingly, the performance of this algorithm can only be shown to be optimal in the regime where n \u2265 d and n \u2265 d, which we refer to as the high-precision regime. In the low-precision regime, i.e., when either n < d or n < d, we spend some extra effort to characterize the optimal precision one can obtain. If n < d, then the situation turns out to be simple, since one can only attain the trivial precision \u00b5 \u2212 \u00b5 \u221e = O(1), which can even be achieved without making any queries at all. On the other hand, if n < d and n \u2265 d, then a small modification of the algorithm is enough to attain an optimal scaling of \u00b5 \u2212 \u00b5 \u221e = O(1/ \u221a n), up to polylogarithmic factors. The low-precision regime is included in the statement of Theorem 4.4.\n\nAs a final note, we remark that one can also use our techniques to obtain quantum mean estimators with performance guarantees in other p -norms, i.e., where p \u2208 [1, \u221e). All precision results follow directly from simple norm conversion, i.e., they are a multiplicative factor \u0398(d 1/p ) worse compared to the \u221e -case. We also show this to be optimal, up to polylogarithmic factors.\n\n\nNear-optimal multivariate mean estimator in the high-precision regime\n\nThe main technical ingredient for the phase oracle setting is presented here, which is the construction of the multivariate mean estimator in \u221e -norm, in the high-precision regime. Throughout, we let G be the same grid as in the previous section, i.e.,\nG = j m \u2212 1 2 + 1 2m : j \u2208 {0, . . . , m \u2212 1} d \u2282 (\u22121/2, 1/2) d .\nwhere m is a number to be determined later. When we write u \u223c G, we mean that u is taken uniformly over all elements of G, and again we let H G be the Hilbert space spanned by mutually orthogonal computational basis states |u , for all u \u2208 G. We start by showing how one can use the phase oracle P X to compute the inner product between any vector u \u2208 G and the outcome of the random variable X(\u03c9), and prepare the result as a phase rotation. The techniques used here are similar to those exhibited in the proof of Proposition 3.2.\n\nLemma 4.1 (Directional phase oracle). Let d \u2208 N, \u2208 (0, 1), m \u2265 0, and X a random variable bounded by [\u22121/4, 1/4] d . Then there exists an operator L X,m, : |u |\u03c9 | 0 \u2192 |u |\u03c9 |\u03d5 u,\u03c9 acting on H G \u2297 H \u2126 \u2297 H aux , that can be implemented using O((m + log(1/ )) log(m/ )) queries to P X , and such that |\u03d5 u,\u03c9 \u2212 e i m d u,X(\u03c9) | 0 \u2264 .\n\nProof. For every u \u2208 G, we let u (+) , u (\u2212) \u2208 R d be defined as u \n|\u03d5 +,u,\u03c9 \u2212 e i m d u (+) ,X(\u03c9) | 0 \u2264 2 , and |\u03d5 \u2212,u,\u03c9 \u2212 e i m d u (\u2212) ,X(\u03c9) | 0 \u2264 2 ,\nbecause then L X,m, = L + L \u2020 \u2212 . We now proceed to show how to implement L + , and omit the construction of L \u2212 since it is completely analogous.\n\nFirst, we note that by adding a global phase to every call of P X , and some local rotation on the control qubit at every controlled call of P X , we can just as well implement the operation |\u03c9 |j \u2192 e i( 1 2 +X(\u03c9) j ) |\u03c9 |j .\n\nNext, we turn this operation into a probability oracle acting on H \u2126 \u2297 C d \u2297 (C 2 ) \u2297(k+1) , using Lemma 2.12, with \u03b4 = 1/4, and precision 2 /(64m 2 ). This implements the operation V + : |\u03c9 |j | 0 |0 \u2192 |\u03c9 |j ( 1 \u2212 p \u03c9,j | 0 |0 + \u221a p \u03c9,j |\u03c8 |1 ), for some state |\u03c8 , using O(log(m/ )) calls to P X , such that\n\u221a p \u03c9,j \u2212 1 2 + X(\u03c9) j \u2264 2 64m 2 .\nNext, we can implement the following operation without any queries,\n|u |\u03c9 |0 | 0 \u2192 |u |\u03c9 \uf8eb \uf8ed d j=1 u (+) j d |j + 1 \u2212 u (+) 1 d |0 \uf8f6 \uf8f8 | 0 ,\nwhich is a valid operation since u (+) 1 /d \u2264 1/2 < 1. By using next one call to V + , we implement the operation W + : |u |\u03c9 | 0 |0 \u2192 |u |\u03c9 \u221a p u,\u03c9 |\u03c8 1 u,\u03c9 |1 + 1 \u2212 p u,\u03c9 |\u03c8 0 u,\u03c9 |0 , where |\u03c8 0 u,\u03c9 and |\u03c8 1 u,\u03c9 are unit vectors, with a single call to V + , such that\np u,\u03c9 \u2212 1 d u (+) , 1 2 + X(\u03c9) = d j=1 u (+) j d p \u03c9,j \u2212 d j=1 u (+) j d 1 2 + X(\u03c9) j \u2264 d j=1 u (+) j d p \u03c9,j \u2212 1 2 + X(\u03c9) j = d j=1 u (+) j d \u221a p \u03c9,j \u2212 1 2 + X(\u03c9) j \u00b7 \u221a p \u03c9,j + 1 2 + X(\u03c9) j \u2264 2 u (+) 1 d \u00b7 2 64m 2 \u2264 2 64m 2 .\nFurthermore, for all a, b > 0, we have that\n| \u221a a + \u221a b| \u2265 max{ \u221a a, \u221a b} = max{a, b} \u2265 |a \u2212 b|, and hence \u221a a \u2212 \u221a b = |a \u2212 b| \u221a a + \u221a b \u2264 |a \u2212 b| |a \u2212 b| = |a \u2212 b|,\nwhich implies that\n\u221a p u,\u03c9 \u2212 1 d u (+) , 1 2 + X(\u03c9) \u2264 p u,\u03c9 \u2212 1 d u (+) , 1 2 + X(\u03c9) \u2264 8m .(5)\nNext, we turn the operation W + back into a phase oracle using the amplitude-to-phase conversion algorithm of Lemma 2.11, with t = m and accuracy /4, whereby we implement the unitary P : |u | 0 \u2192 |u |\u03c8 u,\u03c9 using O(m + log(1/ )) applications of W + , which by the triangle inequality satisfies\n|\u03c8 u,\u03c9 \u2212 e i m d u (+) , 1 2 +X(\u03c9) | 0 \u2264 |\u03c8 u,\u03c9 \u2212 e impu,\u03c9 | 0 + e impu,\u03c9 \u2212 e i m d u (+) , 1 2 +X(\u03c9) \u2264 4 + mp u,\u03c9 \u2212 m d u (+) , 1 2 + X(\u03c9) = 4 + m \u221a p u,\u03c9 \u2212 1 d u (+) , 1 2 + X(\u03c9) \u00b7 \u221a p u,\u03c9 + 1 d u (+) , 1 2 + X(\u03c9) \u2264 4 + 2m \u00b7 8m = 2 .\nFinally, just like at the start of this proof, we can get rid of the extra global phase m u (+) , 1/2 by adding a phase gate to the control qubit whenever we call P in a controlled manner. The resulting operation implements L + .\n\nIt remains to check the number of calls to P X we made throughout this proof. The number of calls to W + is O(m+log(1/ )), each of which makes 1 call to V + , which again performs O(log(m/ )) calls to P X . Thus, the total number of calls to P X amounts to O((m + log(1/ )) log(m/ )). This completes the proof.\n\nOne important subtlety that is a possible source for confusion is that in Equation (5), the thing that p u,\u03c9 approximates is u (+) , 1/2 + X(\u03c9) /d, and not u, 1/2 + X(\u03c9) /d. From Lemma 3.1, we know that the typical value of the latter would be 1/2 + X(\u03c9) 2 /d \u2264 1/ \u221a d, and hence if we were approximating this, we could amplify away this subnormalization of 1/ \u221a d before converting everything back into a phase oracle. We cannot use this trick, however, since the typical value of u (+) , 1/2 + X(\u03c9) can be much bigger than 1/ \u221a d. In fact, our optimality results later on in this section show that there is indeed no way to circumvent this.\n\nNext, we show how the directional phase oracle we constructed in Lemma 4.1 can be used to construct a directional means oracle, in a similar spirit as in Proposition 3.2. This is the objective of the following Lemma.\n\nLemma 4.2 (Directional mean oracle constructed from phase oracle queries). Let d \u2208 N, , \u03b7 \u2208 (0, 1), m \u2265 /(6 \u221a d), and X a random variable bounded by [\u22121/4, 1/4] d . There exists a unitary operator P X,m,\u03b7, : |u |0 \u2192 |u |\u03d5 u acting on H G \u2297 H aux that can be implemented using O( \u221a dm log 2 (1/( \u03b7))) quantum experiments and O(dm log 4 (1/( \u03b7))) queries to P X , and such that |\u03d5 u \u2212 e im u,E[X] | 0 \u2264 , for a fraction at least 1 \u2212 \u03b7/2 of all u \u2208 G.\n\nProof. Let K 1 , K 2 > 0 be constants to be fixed later. By setting\nm = d log 144dm 2 ( 1 2 + \u221a d) 2 \u03b7 , and = 1 4K 1 log m \u221a d \u03b7 \u00b7 K 2 m \u221a d \u03b7 + log 1\nin Lemma 4.1, we can implement a directional phase oracle, i.e., an operation that acts as |u |\u03c9 | 0 \u2192 |u |\u03c9 |\u03c7 u,\u03c9 , such that\n|\u03c7 u,\u03c9 \u2212 e i m d u,X(\u03c9) | 0 \u2264 ,\nwith O((m + log(1/ )) \u00b7 log(m / )) calls to P X .\n\nWithout incurring any extra overhead or error, we can also implement the operation |u |\u03c9 | 0 \u2192 |u |\u03c9 |\u03c8 u,\u03c9 , such that\n|\u03c8 u,\u03c9 \u2212 e i 1 2 + m d u,X(\u03c9) | 0 \u2264 ,\nsince we can always apply some Z-rotation with angle 1/2 to the control qubit if we want to implement this mapping in a controlled fashion. Next, using Lemma 2.12 with \u03b4 = 1/4 and precision (m ) 2 2 /(144d 2 m 2 ), we can turn the above operation into a probability oracle, acting as V + : |u |\u03c9 | 0 |0 \u2192 |u |\u03c9 |\u03d5 u,\u03c9 , with C 1 = O(log(dm/(m ))) calls to the directional phase oracle, and we let K 1 be the constant suppressed by the big-O-notation. It follows that\n|\u03d5 u,\u03c9 \u2212 1 \u2212 p u,\u03c9 | 0 |0 \u2212 \u221a p u,\u03c9 |\u03c8 |1 \u2264 C 1 , and \u221a p u,\u03c9 \u2212 1 2 + m d u, X(\u03c9) \u2264 (m ) 2 2 144d 2 m 2 , if 4m | u, X(\u03c9) | \u2264 d.(6)\nLet B u,\u03c9 \u2208 {0, 1} be 1 whenever 4m | u, X(\u03c9) | > d. Then for all \u03c9 \u2208 \u2126, we have using Lemma 3.1,\nPr u\u223cG [B u,\u03c9 ] = Pr u\u223cG 4m | u, X(\u03c9) | > d \u2264 Pr u\u223cG m \u221a d | u, X(\u03c9) | > X(\u03c9) 2 \u2264 2e \u2212 2d (m ) 2 ,\nand using xe \u2212x \u2264 e \u2212x/2 , for all x \u2265 0, we find\nPr u\u223cG [B u,\u03c9 ] \u2264 2 \u00b7 (m ) 2 2d \u00b7 2d (m ) 2 e \u2212 2d (m ) 2 \u2264 (m ) 2 d e \u2212 d (m ) 2 \u2264 (m ) 2 d e \u2212 log 144dm 2 ( 1 2 + \u221a d ) 2 \u03b7 = (m ) 2 2 \u03b7 144d 2 m 2 1 2 + \u221a d .\nThus, by averaging over all \u03c9's, we find that\n1 |G| u\u2208G \u03c9\u2208\u2126 P(\u03c9)B u,\u03c9 \u2264 (m ) 2 2 \u03b7 144d 2 m 2 1 2 + \u221a d ,\nand hence by the pigeonhole principle, we have that for at least a (1 \u2212 \u03b7/2)-fraction of u \u2208 G,\n\u03c9\u2208\u2126 P(\u03c9)B u,\u03c9 \u2264 (m ) 2 2 72d 2 m 2 1 2 + \u221a d ,\ni.e., for a (1\u2212\u03b7/2)-fraction of u \u2208 G, the probability of sampling an \u03c9 such that the approximation from Equation (6) holds is lower bounded by the right-hand side of the above equation. Next, we prepend V + with the mapping |u |0 | 0 |0 \u2192 |u \u03c9\u2208\u2126 P(\u03c9)|\u03c9 | 0 |0 , which can be implemented with one quantum experiment. The combined operation performs the mapping W + : |u | 0 |0 \u2192 |u |\u03c8 u , with one call to V + , where\n|\u03c8 u \u2212 1 \u2212 p u |\u03c8 0 u |0 + \u221a p u |\u03c8 1 u |1 \u2264 C 1 ,\nfor some states |\u03c8 0 u and |\u03c8 1 u , and such that for at least a (1 \u2212 \u03b7/2)-fraction of u \u2208 G,\np u \u2212 E 1 2 + m d u, X = \u03c9\u2208\u2126 P(\u03c9)p u,\u03c9 \u2212 \u03c9\u2208\u2126 P(\u03c9) 1 2 + m d u, X(\u03c9) \u2264 \u03c9\u2208\u2126 P(\u03c9) p u,\u03c9 \u2212 1 2 + m d u, X(\u03c9) \u2264 \u03c9\u2208\u2126 P(\u03c9)B u,\u03c9 \u00b7 1 2 + m + \u03c9\u2208\u2126 P(\u03c9)(1 \u2212 B u,\u03c9 ) \u221a p u,\u03c9 \u2212 1 2 + m d u, X(\u03c9) \u00b7 2 \u2264 (m ) 2 2 1 2 + m 72d 2 m 2 1 2 + \u221a d + 2 \u00b7 (m ) 2 2 144d 2 m 2 \u2264 (m ) 2 2 36d 2 m 2 ,\nwhere in the last line we used that m \u2264 \u221a d. We conclude that for at least a (1 \u2212 \u03b7/2)-fraction of u \u2208 G,\n\u221a p u \u2212 1 2 + m d u, E[X] \u2264 p u \u2212 E 1 2 + m d u, X \u2264 m 6dm ,\nfollowing a same argument as in the proof of the previous lemma. Then, we convert the resulting operation W + back into a phase oracle, using Lemma 2.11 with precision /4, and t = dm/m . Then, the resulting operation performs |u |0 \u2192 |u |\u03c7 u with C 2 = O(dm/m + log(1/ )) calls to W + , and we let K 2 be the constant suppressed by the big-O-notation. Then we find, by the triangle inequality, that for at least a (1 \u2212 \u03b7/2)-fraction of u \u2208 G,\n|\u03c7 u \u2212 e i dm m 1 2 + m d u,E[X] | 0 \u2264 C 1 C 2 + |\u03c7 u \u2212 e i dm m pu | 0 + e i dm m pu \u2212 e i dm m 1 2 + m d u,E[X] \u2264 4 + 4 + dm m p u \u2212 dm m 1 2 + m d u, E[X] = 2 + dm m \u221a p u \u2212 m d u, E[X] \u00b7 \u221a p u + m d u, E[X] \u2264 2 + dm m \u00b7 m 6dm \u00b7 2 + m 6dm \u2264 2 + 6 \u00b7 3 = ,\nwhere we used that m \u2264 \u221a d and m \u2265 /(6 \u221a d) in the last inequality. Finally, we can remove the unnecessary global phase dm/(2m ) by applying some Z-rotation on any control qubit when we call the above operation in a controlled manner, which does not incur any additional overhead in terms of the number of queries or error. Thus, we have shown how to implement P X,m,\u03b7, .\n\nIt remains to check how many quantum experiments and queries to P X we have performed throughout its construction. Multiplying the complexities appearing earlier in this proof together results in This completes the proof. Now, we are ready to put everything together, and provide a full construction of a multivariate quantum mean estimator using phase oracles. The core idea is to use the bounded multivariate estimator from Algorithm 1, with slightly tweaked constants to accommodate for the slight differences in the guarantees we have on the precision of the directional means oracle. The full algorithm is presented in Algorithm 3. 3. Output the coordinate-wise median, \u00b5 = median( \u00b5 (1) , . . . , \u00b5 ( 18 log(d/\u03b4) ) ).\nO dm m + log 1 \u00b7 log dm m = O \u221a\nAlgorithm 3: Multivariate mean estimator with phase oracles, QPhase d (X, n, n , \u03b4).\n\nTheorem 4.3 (High-precision multivariate mean estimator with phase oracles). Let d \u2208 N, \u03b4 \u2208 (0, 1), n \u2265 log(d/\u03b4), n \u2265 \u221a d log(d/\u03b4), and X a random variable bounded by [\u22121/4, 1/4] d , with \u00b5 = E[X]. Then the multivariate mean estimator with phase oracles, QPhase d (X, n, \u03b4) (Algorithm 3), finds an approximation to the mean, \u00b5, that with probability at least 1 \u2212 \u03b4 satisfies\n\u00b5 \u2212 \u00b5 \u221e \u2264 max \u221a d n , d n \u00b7 log d \u03b4 ,\nwith O(n) calls to U P and O(n ) calls to P X .\n\nProof. We follow the general proof strategy from Theorem 3.3, and let\n|\u03c8 = 1 \u221a m d u\u2208G e im u,E[X] |u | 0 .\nFrom the performance guarantee on P X,m,\u03b7, that we proved in Lemma 4.2, we find that |\u03c8 \u2212 |\u03c8 2 \u2264 u\u2208G |\u03d5 u \u2212 e im u,E[X] | 0 2 /m \u2264 \u03b7 + 2 \u2264 1/144. We now analyze the remainder of the algorithm as if the state |\u03c8 was prepared, instead of |\u03c8 . Let v \u2208 G be the outcome of the measurement performed in step 2d of the algorithm. Since E[X] \u221e \u2264 1/4 < 2\u03c0/3, by the standard analysis of the phase estimation algorithm, as can for instance be found in Equation (5.34) in [NC11], for every j \u2208 [d] we have | v j \u2212 E[X]/(2\u03c0)| \u2264 4/m with probability at least 5/6. If we now factor in that we start with |\u03c8 rather than |\u03c8 , the probability goes down from 5/6 to 2/3. Finally, from the Chernoff bound, it follows that \u00b5 \u2212 E[X] \u221e \u2264 8\u03c0/m \u2264 \u221a d log(d/\u03b4)/k with probability at least 1 \u2212 \u03b4, from which the claim follows.\n\nIt remains to analyze the query complexity claims. We make O(log(d/\u03b4)) calls to the directional means oracle from Lemma 4.2, from which we find that the number of quantum experiments is O( \u221a dm log 2 (1/( \u03b7)) log(d/\u03b4)) = O (k) = O(n), and similarly the number of calls to P X is O(dm log 4 (1/( \u03b7)) log(d/\u03b4)) = O(k \u221a d) = O(n ), completing the proof.\n\nLater on in this section, we find corresponding lower bounds on the precision that scale as \u2126(max{ \u221a d/n, d/n }), implying that the performance guarantee we obtain here is optimal up to polylogarithmic factors. However, this lower bound only holds in the regime where both n \u2265 d and n \u2265 d, and surprisingly it turns out that one can do better in the case where either n < d or n < d. We show this in the next section.\n\n\nNear-optimal multivariate mean estimator in the low-precision regime\n\nIt turns out that the performance of Algorithm 3 is only optimal in the regime where n \u2265 d and n \u2265 d. In this section, we take a look at the regime where we have very few calls to the input oracles to spend, more specifically where n < d or n < d. We refer to this regime as the low-precision regime.\n\nIf n < d, then the performance bound on Algorithm 3 becomes at least d/n > 1. However, we know a priori that E[X] is contained in [\u22121/4, 1/4] d , so if we just output the all-zeros vector, we will do better than what Theorem 4.3 suggests. Moreover, we will show in the next section that this is actually optimal, i.e., if one has less than d queries to P X to spend, one might as well just output the all-zeros vector, since there is nothing one can do that will provably result in a significantly better estimate.\n\nThis leaves the regime where n < d and n \u2265 d, and it turns out that in this regime there is indeed a non-trivial approach that beats the complexity obtained by Algorithm 3. The modification is very simple -one just samples from the probability space n times, and then runs Algorithm 3 with the empirical distribution. The algorithm is presented in Algorithm 4, and the performance guarantees are presented in Theorem 4.4.\n\n1. Set k = 2n/ log(d/\u03b4) .\n\n2. For = 1, . . . , 32 log(d/\u03b4) :\n\n(a) Obtain samples \u03c9 (1) , . . . , \u03c9 (k ) from the probability space, and let P be the empirical distribution based on the observed samples.\n\n(b) Run steps 2a to 2d of Algorithm 3, with k = 2n / \u221a d, all other parameters chosen identically, and the quantum experiment oracle U P constructed from the observed samples. Denote the outcome by \u00b5 ( ) .\n\n3. Output the coordinate-wise median, \u00b5 = median( \u00b5 (1) , . . . , \u00b5 ( 18 log(d/\u03b4) ) ).\n\nAlgorithm 4: Low-precision multivariate mean estimator, QLowPrecPhase d (X, n, n , \u03b4).\n\nTheorem 4.4 (Low-precision analog mean estimator). Let d \u2208 N, \u03b4 \u2208 (0, 1), n \u2265 log(d/\u03b4), n \u2265 \u221a d log(d/\u03b4), and X a random variable with values contained in [\u22121/4, 1/4] d , with \u00b5 = E[X]. Then, QLowPrecPhase d (X, n, n , \u03b4) (Algorithm 4) finds an approximation to the mean, \u00b5, that with probability at least 1 \u2212 \u03b4 satisfies\n\u00b5 \u2212 \u00b5 \u221e \u2264 max 1 \u221a n , d n \u00b7 log d \u03b4 ,\nwith O(n) calls to U P , and O(n ) calls to P X .\n\nProof. Since we only call U P in step 2a, it is clear we perform a total of O(k log(d/\u03b4)) = O(n) quantum experiments. Similarly, the number of calls to the phase oracle P X is twice that in a run of Algorithm 3 with n > n / \u221a d, from which we readily deduce that it is indeed O(n ). It remains to check the precision guarantee. To that end, let \nP \u03c9 = |{j \u2208 [k ] : \u03c9 (j) =E[\u00b5 j ] \u2212 \u00b5 j = \u03c9\u2208\u2126 P \u03c9 X j (\u03c9) \u2212 P(\u03c9)X j (\u03c9) \u2264 1 4 \u03c9\u2208\u2126 P \u03c9 \u2212 P(\u03c9) ,\nand also, using that E[P \u03c9 ] = P(\u03c9),\nE \uf8ee \uf8f0 \u03c9\u2208\u2126 P \u03c9 \u2212 P(\u03c9) 2 \uf8f9 \uf8fb = Var \u03c9\u2208\u2126 P \u03c9 \u2212 P(\u03c9) = \u03c9\u2208\u2126 Var P \u03c9 = \u03c9\u2208\u2126 P(\u03c9)(1 \u2212 P(\u03c9)) k \u2264 \u03c9\u2208\u2126 P(\u03c9) k = 1 k .\nTherefore, by Markov's inequality, for all j \u2208 [d],\nP \u00b5 j \u2212 \u00b5 j > log(d/\u03b4) 2 \u221a n \u2264 P \u03c9\u2208\u2126 P \u03c9 \u2212 P(\u03c9) > 4 \u221a k = P \uf8ee \uf8f0 \u03c9\u2208\u2126 P \u03c9 \u2212 P(\u03c9) 2 > 16 k \uf8f9 \uf8fb \u2264 1 16 .\nThus, by the triangle inequality, for every j \u2208 [d] and \u2208 [ 32 log(d/\u03b4) ], with probability at least 2/3\u00b715/16 = 5/8 we have that | \u00b5 ( )\nj \u2212\u00b5 j | \u2264 | \u00b5 ( ) j \u2212\u00b5 j |+|\u00b5 j \u2212\u00b5 j | \u2264 (d/(2n )+1/(2 \u221a n))\u00b7log(d/\u03b4) \u2264 max{1/ \u221a n, d/n } \u00b7 log(d/\u03b4).\nFinally, it follows from the Chernoff bound that after 32 log(d/\u03b4) iterations, we obtain that \u00b5 \u2212 \u00b5 \u221e \u2264 max{1/ \u221a n, d/n } \u00b7 log(d/\u03b4), completing the proof.\n\nWe have now described all algorithms. For convenience, we aggregate all algorithmic results in one self-contained statement.\n\nTheorem 4.5. Let d, n, n \u2208 N, \u03b4 \u2208 (0, 1), and X a random variable with values contained in [\u22121/4, 1/4] d , with \u00b5 = E[X]. Then, we can find an approximation to the mean, \u00b5, that with probability at least 1 \u2212 \u03b4 satisfies with O(n) calls to U P , and O(n ) calls to P X . Furthermore, for all p \u2208 [1, \u221e), we obtain the same performance guarantees on \u00b5 \u2212 \u00b5 p , but multiplied with d 1/p .\n\u00b5 \u2212 \u00b5 \u221e \u2264 \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 1, if n < d\nProof. All statements are already present in Theorem 4.3 and Theorem 4.4, except for the case where p \u2208 [1, \u221e), which follows from the norm inequality\nx p \u2264 d 1/p x \u221e , for all x \u2208 R d .\nThere exist at least three ways in which this result can be generalized. For instance, one can ask the question how many queries are required if instead of assuming that the random variable is bounded by [\u22121/4, 1/4] d , it is instead bounded by some q -ball of radius 1/4, with q \u2208 [1, \u221e). One can also wonder how many queries are required when one wants to obtain an approximation of OE[X], where O is some d-dimensional rotation matrix, i.e., a matrix that satisfies O T O = I. Finally, if one has access to X through some other oracle than a phase oracle, then one can also wonder how many queries to such an oracle are required to solve the multivariate mean estimation problem. These questions are all addressed in [CJ21], albeit only in the high-precision regime. It is an interesting direction for further research to tightly characterize the query complexities of these problems in the low-precision setting as well.\n\n\nLower bounds\n\nWe now turn our attention to proving lower bounds on the number of queries required to the input oracles. We first focus our attention on the high-precision regime, and will show later on that the lower bounds in the low-precision regimes follow via some reduction from those that we prove in the high-precision regime.\n\nAs is customary with lower bounding, we would like to embed a problem whose hardness has already been shown before in the setting we consider here, in order to conclude that this problem must be at least as hard to solve. We start by considering the problem of recovering a constant fraction of the bits in a bit string when we are given access to it by means of a fractional phase oracle.\n\nLemma 4.6. Let \u2208 (0, \u03c0], d \u2208 N, and suppose that we have access to a bit string b \u2208 {0, 1} d through controlled calls to a fractional phase oracle F : |j \u2192 e i b j |j . Then, in order to find a bit string b \u2208 {0, 1} d such that b \u2212 b 1 \u2264 d/4 with probability at least 2/3, we must make at least \u2126(d/ ) calls to F .\n\nProof. First, we argue that it is sufficient to consider the case where = \u03c0. Indeed, in general, the query complexity of any problem is increased by a multiplicative factor of \u0398(1/ ), when one changes the input model from a regular phase oracle F \u03c0 to a fractional phase oracle F . In Appendix B of [LMR+11], this is proven for problems that can be phrased as a binary function. However, since the problem we consider here does not have a unique correct output on every given input, we must combine their technique with the general adversary bound for relations, as derived by [Bel15], to arrive at the desired result. More details can be found in [CJ21].\n\nThus, it remains to focus on the case where = \u03c0. Suppose that we have an algorithm A that finds a bit string b \u2208 {0, 1} d such that with probability at least 2/3, we have b \u2212 b 1 \u2264 d/4, i.e., b and b differ in at most d/4 bits. Then, we can let B be the quantum algorithm that first runs A to obtain such a bit string b, and then selects uniformly at random a bit string b \u2208 {0, 1} d that satisfies b \u2212 b 1 \u2264 d/4. We have M = d/4 t=0 d t possible choices, which implies that the probability of this algorithm outputting b exactly is lower bounded by 2/3 \u00b7 1/M . By the information theoretic lower bound, i.e., Equation (4) in [FGGS99], the number of queries to F \u03c0 , performed by B and hence also by A, denoted by Q, satisfies\n2 d \u2264 3 2 \u00b7 d 4 t=0 d t Q t=0 d t \u2264 3 2 \u00b7 2 d(H( 1 4 )+H( Q d )) ,\nwhere in the final inequality, we used a well-known approximation sums of binomial coefficients, as proven for instance in Lemma 16.19 in [FG06], and\nH(x) = \u2212x log(x) \u2212 (1 \u2212 x) log(1 \u2212 x)\nis the binary entropy function. Taking logarithms on both sides yields that H(Q/d) \u2265 1\u2212H(1/4)+o(1), which implies that Q = \u2126(d), completing the proof.\n\nThe hardness of this problem can be used as a black box to show the high-precision lower bound on the precision we can attain, expressed in the number of calls to P X , as is shown in the theorem below.\n\nTheorem 4.7. Let d \u2208 N, n \u2265 d, and suppose that we have a quantum algorithm that finds an approximation \u00b5 of the mean \u00b5 of any random variable with values contained in [\u22121/4, 1/4] d , using n queries to P X . Then, there exist instances in which case the error between \u00b5 and \u00b5 satisfies\n\u00b5 \u2212 \u00b5 1 = \u2126 d 2 n ,\nwith probability at least 2/3.\n\nProof. Let = d/n , and b \u2208 {0, 1} d a bit string, that we can access through controlled calls to a fractional phase oracle F : |j \u2192 e i b j |j . Then, we know from Lemma 4.6 that it takes \u2126(d/ ) = \u2126(n ) calls to F to find a bit string b \u2208 {0, 1} d such that b \u2212 b 1 \u2264 d/4. Now, let \u2126 = {0}, with P(0) = 1, which implies that U P = I. Let the random variable X : \u2126 \u2192 R d be defined as X(0) j = b j . This implies that P X : |0 |j \u2192 e i b j |0 |j , and hence P X can be implemented with one call to F . Furthermore, we have \u00b5 = E[X] = b, and hence if we can find an approximation \u00b5 to the mean satisfying \u00b5 \u2212 \u00b5 \u2264 d 2 /(8n ), then we have\nmin b\u2208{0,1} d \u00b5 \u2212 b 1 = 1 min b\u2208{0,1} d \u00b5 \u2212 b 1 \u2264 1 \u00b5 \u2212 \u00b5 1 ,\nand hence, if we take b to be the bit string attaining the minimum in the left-hand side, we find by the triangle inequality\nb \u2212 b 1 \u2264 \u00b5 \u2212 b 1 + \u00b5 \u2212 b 1 \u2264 1 \u00b5 \u2212 \u00b5 1 + 1 \u00b5 \u2212 \u00b5 1 = 2 \u00b5 \u2212 \u00b5 1 \u2264 d 4 .\nBut we know that this takes at least \u2126(n ) calls to F , and hence obtaining an estimate \u00b5 that satisfies \u00b5 \u2212 \u00b5 1 \u2264 d 2 /(8n ) requires at least \u2126(n ) queries to P X as well. Thus, if we only have n queries to spend, there must exist instances such that \u00b5 \u2212 \u00b5 1 = \u2126(d 2 /n ) with high probability, completing the proof.\n\nIn order to give a similar lower bound in terms of the number of quantum experiments, we need to subtly change the problem to finding a vector b \u2208 {0, 1} d such that\nH( b \u2212 b) 1 \u2264 d/4,\nwhere H is a d-dimensional normalized Hadamard matrix, i.e., the entries of H are all \u00b11/ \u221a d, and H T H = I. This problem is quite different in nature compared to the problem considered in Lemma 4.6, since the number of bits in which b and b differ seems to no longer tells us anything useful about whether this condition is met. For instance, if b = 0 and b = 1, i.e., they differ in all bits, then H( b \u2212 b) = \u221a de 1 , and so the condition is met as long as d is large enough. Suprisingly, however, we are able to show that this problem is equally hard as the non-rotated problem up to constants, i.e., it still takes \u2126(d/ ) calls to F to find a b that satisfies this rotated condition. The details can be found in the lemma below. Proof. Similarly as in the proof of Lemma 4.6, it suffices to consider the case where = \u03c0. Suppose that we have a quantum algorithm A that finds a bit string b \u2208 {0, 1} d satisfying the condition posed in the statement of the lemma with probability at least 2/3. Using heavy-duty tools from statistics, it is shown in Appendix B of [CJ21] that\nPr b\u223c{0,1} d H( b \u2212 b) 1 \u2264 d 4 \u2264 2 \u2212Cd , with C = log(e) 2 1 2 \u221a 2 \u2212 1 4 2 \u2208 (0, 1).\nThus, if know b \u2208 {0, 1} d and that H( b \u2212 b) 1 \u2264 d/4, then there are less than 2 (1\u2212C)d possible choices left for b. Thus, the algorithm B, that first runs A to obtain a vector b such that\nH( b \u2212 b) 1 \u2264 d/4\n, and subsequently takes any b that satisfies H( b \u2212 b) 1 \u2264 d/4 uniformly at random, will recover b exactly with probability lower bounded by 2/3 \u00b7 2 (C\u22121)d . Analogously as in the proof of Lemma 4.6, this implies that\n2 d \u2264 3 2 \u00b7 2 (1\u2212C)d \u00b7 Q t=0 d t \u2264 3 2 \u00b7 2 (1\u2212C)d+dH( Q d ) ,\nand taking the logarithm on both sides implies that H(Q/d) \u2265 C + o(1), which in turn implies that Q = \u2126(d), completing the proof.\n\nWe now show how the hardness of problem considered in the previous lemma can be used to lower bound the query complexity in the mean estimation problem.\n\nTheorem 4.9. Let d \u2208 N, n \u2265 d, and suppose that we have a quantum algorithm that finds an approximation \u00b5 to the mean \u00b5 of any random variable with values contained in [\u22121/4, 1/4] d , using n queries to U P . Then, there exist instances in which case the error between \u00b5 and \u00b5 satisfies\n\u00b5 \u2212 \u00b5 1 = \u2126 d 3 2 n ,\nwith probability at least 2/3.\n\nProof. Let d be the biggest power of 2 below or equal to d. Let = d /n, = arcsin( ), and suppose that we have access to some hidden bit string b \u2208 {0, 1} d by means of controlled calls to a fractional phase oracle F : |j \u2192 e i b j |j . We know from Lemma 4.8 that it takes \u2126(d / ) = \u2126(n) calls to find a bit string b such that H( b \u2212 b) 1 \u2264 d /4. Now, let \u2126 = [d ] \u00d7 {0, 1}, and for every b \u2208 {0, 1} d , let the probability measure P b on \u2126 be defined as\nP b (j, x) = 1 d cos 2 \u03c0 4 + (\u22121) x b j 2 , for all j \u2208 [d ], x \u2208 {0, 1}.\nObserve that with one call to F , we can implement\n1 \u221a 2d d j=1 (|j |0 + i|j |1 ) F \u2192 1 \u221a 2d d j=1 (|j |0 + ie i b j |j |1 ) = d j=1 e i \u03c0 4 +i b j 2 \u221a 2d e \u2212i \u03c0 4 \u2212i b j 2 |j |0 + e i \u03c0 4 +i b j 2 |j |1 I\u2297(SH) \u2192 d j=1 e i \u03c0 4 +i b j 2 \u221a d cos \u03c0 4 + b j 2 |j |0 + sin \u03c0 4 + b j 2 |j |1 = (j,x)\u2208\u2126 e i \u03c0 4 +i b j 2 \u221a d cos \u03c0 4 + (\u22121) x b j 2 |j |x = (j,x)\u2208\u2126 P b (j, x)e i \u03c0 4 +i b j 2 |j |x ,\nand hence we can implement U P b with one call to F . 1 Next, let the random variable X : \u2126 \u2192 R d be defined as\nX(j, x) = x \u221a d 4\nHe j ,\n\n\nApplications\n\nIn this section, we describe some applications of our results. We first explain how our formulation of the multivariate mean estimation problem covers the general task of estimating the expectation values of several mutually commuting observables with respect to a given quantum state. We then present several applications in the literature, and notably in quantum machine learning, where this problem arises.\n\n\nEstimating expectation values of commuting observables\n\n\nClassical versus quantum experiments\n\nFrom a classical perspective, the mean estimation problem is commonly described by a random experiment (or Monte Carlo process) that draws a classical sample \u03c9 (e.g., a bit-string) from a certain probability space (\u2126, 2 \u2126 , P) and leads to the associated observation X(\u03c9) \u2208 R d (see Definition 2.4). It is then quite clear that our generalization to quantum experiments, defined by a unitary U P that prepares a superposition over basis states |\u03c9 , \u03c9 \u2208 \u2126, and a unitary B X that evaluates X for the same basis states (see Definitions 2.5 and 2.6) can simulate such a random experiment. However, from a physical perspective, quantum experiments are also more general. The basis states {|\u03c9 } \u03c9\u2208\u2126 do not need to be computational basis states, and can be themselves superpositions of computational basis states or include arbitrary phases. Therefore, in our definition of quantum experiments, the unitaries U P can indeed be arbitrary unitaries acting on a given Hilbert space H, and what really matters here is the definition of the basis {|\u03c9 } \u03c9\u2208\u2126 of H.\n\n\nProblem definition\n\nWith this observation, we can now move to the problem of estimating expectation values of mutually commuting observables. Let U be a unitary transformation that prepares a given quantum state |\u03c8 = U |0 in a given m-qubit Hilbert space H, and let O 1 , . . . , O d be d mutually commuting observables (i.e., Hermitian operators) acting on H. We want to compute estimates of the d expectation values O i = \u03c8|O i |\u03c8 . Since the observables commute, they all share a common eigenbasis {|\u03c6 j } 1\u2264j\u22642 m , to which they assign eigenvalues \u03bb i = (\u03bb i,1 , . . . , \u03bb i,2 m ) \u2208 R 2 m , respectively. Let us therefore look at the expression of |\u03c8 = U |0 in this eigenbasis:\nU : |0 \u2192 2 m j=1 P(\u03c6 j )e i\u03d5 j |\u03c6 j(7)\nfor some phases \u03d5 j \u2208 [0, 2\u03c0] and real amplitudes P(\u03c6 j ) such that 2 m j=1 P(\u03c6 j ) = 1. If we now take U P to be the unitary U , {|\u03c9 } \u03c9\u2208\u2126 to be e i\u03d5 j |\u03c6 j 1\u2264j\u22642 m , and X(\u03c9) to be X(\u03c6 j ) = (\u03bb 1,j , . . . , \u03bb d,j ) (i.e., the eigenvalues \u03bb i,j assigned by each of the observables O i to |\u03c6 j ), the problem of estimating the d expectation values O i = \u03c8|O i |\u03c8 fits our formulation of the (quantum) mean estimation problem. Indeed, note that the phases e i\u03d5 j do not contribute to the expectation values O i = \u03c8|O i |\u03c8 = 2 m j=1 P(\u03c6 j )\u03bb i,j , and therefore absorbing them in the basis states |\u03c9 does not influence the mean values to be estimated (nor our algorithms).\n\n\nApplicability assumptions\n\nFor the applicability of our algorithms to this problem, we assume that a description of the eigenbasis {|\u03c6 j } 1\u2264j\u22642 m , in terms of a unitary transformation V : |j \u2192 |\u03c6 j from computational basis states |j to eigenvectors |\u03c6 j , and the eigenvalues {\u03bb i } 1\u2264i\u2264d of the observables {O i } 1\u2264i\u2264d are known. These are the same assumptions that one would have in quantum algorithms for the univariate version of this problem (i.e., with one observable) [KOS07;WCNA09] or in a setting where one would directly estimate the expectation values O i = \u03c8|O i |\u03c8 = \u03c8|V \u039b i V \u2020 |\u03c8 for \u039b i = diag(\u03bb i,1 , . . . , \u03bb i,2 m ) by applying V \u2020 on |\u03c8 , measuring computational basis states |j , and using several measurement outcomes {|j , (\u03bb 1,j , . . . , \u03bb d,j )} to simultaneously 2 compute these estimates. Note that, in practice, the same transformation V \u2020 would be absorbed in the unitary U P used in our algorithms, as to make the basis states {|\u03c9 } \u03c9\u2208\u2126 computational basis states, and ease the implementation of the unitaries B X and P X (using single-qubit rotations controlled by computational basis states).\n\n\nExamples of applications\n\n\nTraining variational quantum circuits\n\nA straightforward application appears in some variational quantum algorithms for machine learning [BLSF19]. In a multidimensional regression setting [MNKF18] or a reinforcement learning setting [JGM+21; SJD21], a variational quantum circuit defined by a parametrized and data-dependent unitary U (x, \u03b8) and a set of observables (O 1 , . . . , O d ) can be used as a hypothesis family f \u03b8 (x) = ( O 1 x,\u03b8 , . . . , O d x,\u03b8 ), for O i x,\u03b8 = 0 \u2297n |U \u2020 (x, \u03b8)O i U (x, \u03b8)|0 \u2297n , to model target functions g with d-dimensional outputs. When the observables O 1 , . . . , O d all commute (e.g., commuting tensor products of Pauli operators or projectors on some basis states, for an arbitrary basis), the problem of estimating f \u03b8 (x) fits the problem definition above.\n\n\nTraining Boltzmann machines\n\nAnother application considers the problem of estimating updates of a Boltzmann machine in a machine learning setting (e.g., a classification or generative modeling problem) [WKS16; WW19; KW17; JTN+21]. Take for instance a Boltzmann machine defined by a Hamiltonian:\nH = i<j J i,j \u03c3 z i \u03c3 z j + i b i \u03c3 z i(8)\nwhere J i,j and b i are real weights and biases and \u03c3 z i is a Pauli-Z operator acting on a qubit i out of n total qubits. The updates on the weights and biases of this Boltzmann machine take the form:\n\u2206J i,j = \u2212L(J, b) \u03c3 z i \u03c3 z j , \u2206b i = \u2212L(J, b) \u03c3 z i(9)\nwhere L(J, b) is a loss dependent on the Boltzmann machine performance at the machine learning task and the expectation values \u03c3 z i , \u03c3 z i \u03c3 j z are with respect to the Gibbs state:\n|\u03c8 = 1 Tr x [e \u2212H ] x e \u2212H(x) |x(10)\nfor computational basis states |x . Assume having access to a unitary U that prepares the Gibbs state of Equation (10), e.g., using one of the subroutines in [WKS16; WW19; KW17; JTN+21], then estimating the updates of the Boltzmann machine is an instance of the problem above for observables \u2212L(J, b)\u03c3 z i \u03c3 z j , \u2212L(J, b)\u03c3 z i i,j , i.e., weighted \u03c3 z i and \u03c3 z i \u03c3 z j operators, which are all diagonal in the computational basis.\n\n\nTraining policies in reinforcement learning\n\nIn the context of reinforcement learning [SB18], an agent-environment interaction is described by a Monte Carlo process where, for a sequence of interactions, an agent acts probabilistically on its environment, the latter updates its state (probabilistically) depending on the actions of the agent and issues a real-valued reward r t . The goal of the agent is to find a policy (i.e., a probability distribution \u03c0(a t |s t ) of actions a t given states s t ) that maximizes its expected rewards V (\u03c0) = T t=1 r t for T interactions with the environment. To do this, policy-based reinforcement learning algorithms define a certain family of parametrized policies \u03c0 \u03b8 \u2208 \u03a0 \u03b8 (e.g., deep neural networks) and explore this policy family using gradient ascent on the expected rewards V (\u03c0 \u03b8 ). The so-called policy gradient theorem [SMSM99] gives a formulation of the gradient of the expected rewards V (\u03c0 \u03b8 ) with respect to the parameters \u03b8 \u2208 R d of the policy as:\n\n\u2207 \u03b8 V (\u03c0 \u03b8 ) = E s 1 ,a 1 ,r 1 ,s 2 ,a 2 ,r 2 ,... T t=1 \u2207 \u03b8 log(\u03c0 \u03b8 (a t |s t )) T t =t r t .\n\nThis gradient is therefore given by the expectation value of the d-dimensional random variable X(s 1 , a 1 , r 1 , s 2 , . . .) = T t=1 \u2207 \u03b8 log(\u03c0 \u03b8 (a t |s t )) T t =t r t (or equivalently, d observables that are all diagonal in the computational basis) with respect to all possible interactions with the environment, following a policy \u03c0 \u03b8 . In order for our mean estimators to be applicable here, our only assumption on the environment is that we have oracle access to its dynamics, notably its state-transitions |s t |a t |0 \u2192 s t+1 P (s t+1 |s t , a t )|s t |a t |s t+1\n\nand its reward function |s t |0 \u2192 |s t |r t .\n\nAs for the policy, we assume having the ability to implement \u03c0 \u03b8 coherently (i.e., similarly to U P ), and to construct a (classical) circuit that computes the gradient \u2207 \u03b8 log(\u03c0 \u03b8 (a t |s t )) given s t , a t , \u03b8.\n\n\nDiscussion\n\nIn this work, we developed near-optimal quantum mean estimators in two different input models. In the binary oracle setting, we managed to obtain matching upper and lower bounds up to polylogarithmic factors, when we measure the performance of our estimator with respect to the Euclidean norm. We did not investigate the problem of deriving sharp bounds for other norms in this model. In the classical literature, sample-optimal estimators for general norms were given in [LM19b]. One case that could be interesting to further study is the \u221e -norm, since it arises naturally in our quantum algorithm as well as in the applications we consider. By combining the one-dimensional result with a union bound, one can obtain a classical estimator that achieves a precision of max j\u2208 [d] Var[X j ] log(d/\u03b4)/n, whereas quantumly we obtained j\u2208[d] Var[X j ] log(d/\u03b4)/n. It would be interesting to figure out whether some combination of these two approaches can be shown to be optimal in all regimes.\n\nOne further observation is that we do not assume to have any knowledge about \u03a3 beforehand. Some preliminary considerations seem to indicate that in some p -norms, especially where p < 2, it might be useful to know bounds on the individual diagonal entries of this covariance matrix. Whether these considerations are fundamental, or can be worked around, is also an interesting question to address in the future.\n\nthank Ronald de Wolf and Joran van Apeldoorn for insightful discussions and helpful tips. Furthermore, AC would like to extend his gratitude to the anonymous legends that answered the Math Overflow post related to this research [MO21]. SJ acknowledges support from the Austrian Science Fund (FWF) through the projects DK-ALM:W1259-N27 and SFB BeyondC F7102. SJ also acknowledges the Austrian Academy of Sciences as a recipient of the DOC Fellowship.\n\n\n\u03b1, is the directional mean oracle constructed in Proposition 3.2 with = 1/25.(c) Compute the state |\u03c6 := (QFT \u22121 G \u2297 I aux )|\u03c8 where the unitary QFT G : |u \u2192 1 m d/2 v\u2208G e 2i\u03c0m u,v |v is the quantum Fourier transform over G. (d) Measure the H G register of |\u03c6 in the computational basis and let\n\nProblem 1 (\n1Search N \u2022 Parity M ). Let N, M \u2265 1 be two integers. Let A N,M denote the set of all matrices A \u2208 {0, 1} N \u00d7M such that N/2 rows have Hamming weights M/2 , and the other rows have Hamming weights M/2 + 1. Define the vector b (A) \u2208 {0, 1} N such that, if the i-th row of A has Hamming weight M/2 , 1, if the i-th row of A has Hamming weight M/2 + 1, for each i \u2208 [N ]. Then, the Search N \u2022 Parity M problem consists of finding a vector b \u2208 R N that minimizes b \u2212 b (A) 2 given a quantum oracle |i, j \u2192 (\u22121) A i,j |i, j to A \u2208 A N,M . We use the next lower bound for the Search N \u2022 Parity M problem, which states that \u2126(N M ) queries are needed to approximate the vector b (A) with small error. The proof can be easily adapted from that of [Ape21, Lemma 11] or [CJ21, Lemma 5.7].\n\nLemma 3. 6 .\n6Let \u03b1 > 1 be a sufficiently large constant. Consider any quantum algorithm for the Search N \u2022 Parity M problem that uses at most N M/\u03b1 queries on all inputs. Then, there exists an input A \u2208 A N,M such that this algorithm returns a vector b satisfying b \u2212 b (A) 2 \u2265 \u2126( \u221a N ) with probability at least 2/3.\n\n\nd is the i-th indicator vector. The expectation of X (A) is E[X (A) ] = 2\u03c3 \u221a (\u03b1n) 2 \u2212d 2 b (A) and the trace of its covariance matrix is Tr(\u03a3) = E[ X (A) 2 2 ] \u2212 E[X (A) ] 2 2 = (\u03b1\u03c3n) 2 (\u03b1n) 2 \u2212d 2 \u2212 4\u03c3 2 (\u03b1n) 2 \u2212d 2 b (A) 2 1 = \u03c3 2 since b (A)has Hamming weight d/2. Given any quantum estimator that uses n binary oracle queries to X (A) and outputs an estimate \u00b5 of \u00b5 = E[X (A) ], we can transform it into an algorithm for the Search d \u2022 Parity \u03b1n/d problem that uses n queries to A\n\n=\nmax{u j , 0} and u (\u2212) j = \u2212 min{u j , 0}, for all j \u2208 [d]. Note u = u (+) \u2212 u (\u2212) , and hence u, X(\u03c9) = u (+) , X(\u03c9) \u2212 u (\u2212) , X(\u03c9) . Thus, it suffices to implement operations L + : |u |\u03c9 | 0 \u2192 |u |\u03c9 |\u03d5 +,\u03c9,u and L \u2212 : |u |\u03c9 | 0 \u2192 |u |\u03c9 |\u03d5 \u2212,u,\u03c9 that satisfy\n\n\nFor = 1, . . . , 18 log(d/\u03b4) : (a) Compute the uniform superposition |G := 1 m d/2 u\u2208G |u over G. (b) Compute the state |\u03c8 := P X,m,\u03b7, |G | 0 \u2208 H G \u2297 H aux , where P X,m,\u03b7, is the directional means oracle constructed in Lemma 4.2 with = 1/(12 \u221a 2). (c) Compute the state |\u03c6 := (QFT \u22121 G \u2297 I aux )|\u03c8 where the unitary QFT G : |u \u2192 1 m d/2 v\u2208G e 2i\u03c0m u,v |v is the quantum Fourier transform over G. (d) Measure the H G register of |\u03c6 in the computational basis and let v ( ) \u2208 G denote the obtained result. Set \u00b5 ( ) = 2\u03c0 v ( ) .\n\nLemma 4 . 8 .\n48Let \u2208 (0, \u03c0], d \u2208 N a power of 2, and let H be a d-dimensional Hadamard matrix, i.e., all entries of H are \u00b11/ \u221a d, and H T H = I. Suppose we have access to a bit string b \u2208 {0, 1} d by means of a fractional phase oracle F : |j \u2192 e i b j |j . In order to find a bit string b \u2208 {0, 1} d such that H( b \u2212 b) 1 , the number of calls to F satisfies \u2126(d/ ).\n\n\nBounded multivariate estimator. The main obstacle when trying to generalize most quantum univariate estimators (e.g. [Ter99; Hei02; WCNA09; Mon15; HM19; Ham21]) to the multivariate setting is the absence of an estimator for bounded multivariate random variables. In the univariate setting, such an estimator is provided by the well-known Amplitude Estimation algorithm [BHMT02] which, by a well-known trick [Ter99; WCNA09; Mon15], can estimate the mean of any random variable bounded in [\u22121, 1] with an error on the order of E[|X|]/n. It is worth recalling how this estimator works when X is bounded in [0, 1]: the value \u03d5 = arcsin( E[X])\n\n\nthe phase, since it would no longer be a linear function. Instead, we use the quantum singular value transformation framework [GSLW19] to linearly amplify the (squared) amplitude encoding the directional mean u, E[X] into u, E[X] E[ X 2 ] , before applying the amplitude-to-phase conversion technique. Since this amplification step requires O(1/ E[ X 2 ]) queries, this leaves us with O(n E[ X 2 ]) iterations available for the vector recovering step. Hence, the rescaled mean E[X] E[ X 2 ] is estimated with error 1/(n E[ X 2 ]), which translates into the improved error of E[ X 2 ]/n for E[X] (Theorem 3.3).\n\n\nThe dependence on E[ X 2 ] generalizes the dependence on E[|X|] provided by the univariate bounded estimator [Ter99; BHMT02; WCNA09; Mon15].\n\n\nfor all \u03c9 \u2208 \u2126. For any input A \u2208 A d,\u03b1n/d to the Search d \u2022 Parity \u03b1n/d problem, define the random variable X (A) : \u2126 \u2192 R d such that,). Let (\u2126, 2 \u2126 , P) be the probability space such \nthat \u2126 = [d] \u00d7 [\u03b1n/d] and P(\u03c9) = 1/(\u03b1n) \nNote that we don't have to worry about the extra global phase here -we can absorb it in the definition of the state |\u03c9 , i.e., if \u03c9 = (j, x) we can define |\u03c9 = e i\u03c0/4+i b j /2 |j |x , and then use all the machinery from the rest of this document.\nWhen the observables do not commute, one cannot \"parallelize\" measurements in such a manner, and would then be required to use different techniques like shadow tomography [Aar20; HKP20].\nAcknowledgmentsAC and SJ would like to thank Vedran Dunjko and M\u0101ris Ozols for pointing us in the direction of this problem, and for many insightful and motivating discussions. AC would also like towhere H is a (d \u00d7 d )-dimensional normalized Hadamard matrix, i.e., H T H = I, whose first row and column have all positive signs. Such a Hadamard matrix exists because we know that d is a power of 2. Furthermore,Hb,Thus, if we find an approximation \u00b5 to \u00b5 such thatand hence if we let b be the bit string for which the minimum in the above expression is attained, then we find thatWe know that constructing such a bit string b requires \u2126(n) queries to F , and hence we find that in order to find an (d ) 3/2 /(16n)-precise 1 -approximation of the mean of a random variable, we need to make at least \u2126(n) calls to U P as well. Thus, if we have only n queries to spend, there must be an instance for which the 1 -approximation satisfies \u2126(d 3/2 /n). This completes the proof.We can now use the results obtained in Theorem 4.7 and Theorem 4.9 as black boxes to obtain results in different norms and regimes.Theorem 4.10. Let d \u2208 N, n, n \u2265 1, and suppose that we have a quantum algorithm that finds an approximation \u00b5 to the mean \u00b5 of any random variable with values contained in [\u22121/4, 1/4] d , using n queries to U P and n queries to P X . Then, there exist instances such thatif n < d,, if n \u2265 d and n < d,with probability at least 2/3. Moreover, the same expressions multiplied by d 1/p\u22121 can be obtained as lower bounds for \u00b5 \u2212 \u00b5 p , for all p \u2208 (1, \u221e].Proof. If n, n \u2265 d, then we know from Theorem 4.7 and Theorem 4.9 that \u00b5 \u2212 \u00b5 1 = \u2126 max d 3 2 n , d 2 n .Next, let 1 \u2264 n < d, and let k = d/n . Let X : \u2126 \u2192 R n be a random variable, and define X : \u2126 \u2192 R d by X(\u03c9) = X (\u03c9) \u2297 1 k , padded with an appropriate number of zeros in the final entries. We find thatand hence, if we find an approximation of \u00b5 \u2208 R d to \u00b5 = E[X], then we can define \u00b5 \u2208 R n as \u00b5 j = k =1 \u00b5 k(j\u22121)+ /k, which impliesFinally, the result for different values for p \u2208 (1, \u221e] follows directly from H\u00f6lder's inequality, since for all x \u2208 R d , we have x p \u2265 d 1/p\u22121 x 1 . This completes the proof.We aggregate all our results inFigure 1.Figure 1: Overview of the different regimes of the mean estimation problem. The horizontal and vertical axes show n and n , i.e., the number of queries to U P and P X , respectively. The complexities shown in the figure are the optimal error scaling of \u00b5 \u2212 \u00b5 \u221e that can be achieved with particular choices for n and n . The tildes are hiding polylogarithmic factors in n, n , d and 1/\u03b4. For the optimal error scalings of \u00b5 \u2212 \u00b5 p for p \u2208 [1, \u221e), one can simply multiply the expressions above by d 1/p .\nShadow Tomography of Quantum States. S Aaronson, 10.1137/18M120275XSIAM Journal on Computing. 4930S. Aaronson. \"Shadow Tomography of Quantum States\". In: SIAM Journal on Computing 49.5 (2020), STOC18-368-STOC18-394. doi: 10.1137/18M120275X (cit. on p. 30).\n\nAn Introduction to MCMC for Machine Learning. C Andrieu, N Freitas, A Doucet, M I Jordan, 10.1023/a:1020281327116Machine Learning. 501C. Andrieu, N. de Freitas, A. Doucet, and M. I. Jordan. \"An Introduction to MCMC for Machine Learning\". In: Machine Learning 50.1 (2003), pp. 5-43. doi: 10.1023/a:1020281327116 (cit. on p. 1).\n\nThe Space Complexity of Approximating the Frequency Moments. N Alon, Y Matias, M Szegedy, 10.1006/jcss.1997.1545Journal of Computer and System Sciences. 581N. Alon, Y. Matias, and M. Szegedy. \"The Space Complexity of Approximating the Frequency Moments\". In: Journal of Computer and System Sciences 58.1 (1999), pp. 137-147. doi: 10.1006/jcss.1997.1545 (cit. on p. 2).\n\nQuantum Probability Oracles & Multidimensional Amplitude Estimation. J Van Apeldoorn, 10.4230/LIPIcs.TQC.2021.9doi: 10. 4230/LIPIcs.TQC.2021.9Proceedings of the 16th Conference on the Theory of Quantum Computation, Communication and Cryptography (TQC). 2021. the 16th Conference on the Theory of Quantum Computation, Communication and Cryptography (TQC). 2021911cit. on pp. 6, 13, 15J. van Apeldoorn. \"Quantum Probability Oracles & Multidimensional Amplitude Estimation\". In: Proceedings of the 16th Conference on the Theory of Quantum Computation, Communication and Cryptography (TQC). 2021, 9:1-9:11. doi: 10. 4230/LIPIcs.TQC.2021.9 (cit. on pp. 6, 13, 15).\n\nD S Abrams, C P Williams, 10.48550/arXiv.quant-ph/9908083Fast Quantum Algorithms for Numerical Integrals and Stochastic Processes. cit. on pp. 2, 3, 5)D. S. Abrams and C. P. Williams. Fast Quantum Algorithms for Numerical Integrals and Stochastic Processes. arXiv:quant-ph/9908083. 1999. doi: 10.48550/arXiv. quant-ph/9908083 (cit. on pp. 2, 3, 5).\n\nTight Bounds on Quantum Searching. M Boyer, G Brassard, P H\u00f8yer, A Tapp, 10.1002/(SICI)1521-3978(199806)46:4/5<493::AID-PROP493>3.0.CO;2-Pdoi: 10.1002/ (SICI)1521-3978Fortschritte der Physik. 4624/5<493::AID-PROP493>3.0.CO;2-P (citM. Boyer, G. Brassard, P. H\u00f8yer, and A. Tapp. \"Tight Bounds on Quantum Searching\". In: Fortschritte der Physik 46.4-5 (1998), pp. 493-505. doi: 10.1002/ (SICI)1521-3978(199806)46:4/5<493::AID-PROP493>3.0.CO;2-P (cit. on p. 2).\n\nAn Optimal Quantum Algorithm to Approximate the Mean and its Application for Approximating the Median of a Set of Points over an Arbitrary Distance. G Brassard, F Dupuis, S Gambs, A Tapp, 10.48550/arXiv.1106.4267arXiv:1106.4267quant-ph. cit. on pp. 2, 3, 5, 7G. Brassard, F. Dupuis, S. Gambs, and A. Tapp. An Optimal Quantum Algorithm to Approximate the Mean and its Application for Approximating the Median of a Set of Points over an Arbitrary Distance. arXiv:1106.4267 [quant-ph]. 2011. doi: 10.48550/arXiv.1106.4267 (cit. on pp. 2, 3, 5, 7).\n\nA Belovs, arXiv:1504.06943Variations on Quantum Adversary. quant-phA. Belovs. Variations on Quantum Adversary. arXiv:1504.06943 [quant-ph].\n\n. 10.48550/arXiv.1504.06943242015. doi: 10.48550/arXiv.1504.06943 (cit. on p. 24).\n\nMonte Carlo Simulation in Statistical Physics. K Binder, D W Heermann, 10.1007/978-3-642-03163-2Springer15th ed. Graduate texts in physics. citK. Binder and D. W. Heermann. Monte Carlo Simulation in Statistical Physics. 5th ed. Graduate texts in physics. Springer, 2010. doi: 10.1007/978-3-642-03163- 2 (cit. on p. 1).\n\nQuantum Algorithms for Testing Properties of Distributions. S Bravyi, A W Harrow, A Hassidim, 10.1109/TIT.2011.2134250IEEE Transactions on Information Theory. 57cit. on pp. 3, 7S. Bravyi, A. W. Harrow, and A. Hassidim. \"Quantum Algorithms for Testing Properties of Distributions\". In: IEEE Transactions on Information Theory 57.6 (2011), pp. 3971-3981. doi: 10.1109/TIT.2011.2134250 (cit. on pp. 3, 7).\n\nQuantum Amplitude Amplification and Estimation. G Brassard, P H\u00f8yer, M Mosca, A Tapp, 10.1090/conm/305/05215doi: 10. 1090/conm/305/05215Contemporary Mathematics 305. cit. on pp. 2-5, 8, 9G. Brassard, P. H\u00f8yer, M. Mosca, and A. Tapp. \"Quantum Amplitude Amplification and Estimation\". In: Contemporary Mathematics 305 (2002), pp. 53-74. doi: 10. 1090/conm/305/05215 (cit. on pp. 2-5, 8, 9).\n\nParameterized Quantum Circuits as Machine Learning Models. M Benedetti, E Lloyd, S Sack, M Fiorentini, 10.1088/2058-9565/ab4eb5Quantum Science and Technology. 430M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini. \"Parameterized Quantum Circuits as Machine Learning Models\". In: Quantum Science and Technology 4.4 (2019), p. 043001. doi: 10.1088/2058-9565/ab4eb5 (cit. on p. 30).\n\nQuantum Complexity Theory. E Bernstein, U V Vazirani, 10.1137/S0097539796300921doi: 10 . 1137 / S0097539796300921SIAM Journal on Computing. 26cit. on pp. 3, 5, 10E. Bernstein and U. V. Vazirani. \"Quantum Complexity Theory\". In: SIAM Journal on Computing 26.5 (1997), pp. 1411-1473. doi: 10 . 1137 / S0097539796300921 (cit. on pp. 3, 5, 10).\n\nNew Results on Quantum Property Testing. S Chakraborty, E Fischer, A Matsliah, R De Wolf, 10.4230/LIPIcs.FSTTCS.2010.145Proceedings of the 30th Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS). 2010. the 30th Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS). 20107S. Chakraborty, E. Fischer, A. Matsliah, and R. de Wolf. \"New Results on Quantum Property Testing\". In: Proceedings of the 30th Conference on Foundations of Software Technology and Theoretical Computer Science (FSTTCS). 2010, pp. 145-156. doi: 10.4230/LIPIcs.FSTTCS.2010.145 (cit. on p. 7).\n\nQuantum Algorithms for Multivariate Monte Carlo Estimation. A Cornelissen, S Jerbi, doi.org/10.48550/arXiv.2107.03410cit. on pp. 2, 13, 15, 24, 26A. Cornelissen and S. Jerbi. Quantum Algorithms for Multivariate Monte Carlo Es- timation. arXiv:2107.03410 [quant-ph]. 2021. doi: doi.org/10.48550/arXiv. 2107.03410 (cit. on pp. 2, 13, 15, 24, 26).\n\nC D\u00fcrr, P H\u00f8yer, 10.48550/arXiv.quant-ph/9607014A Quantum Algorithm for Finding the Minimum. 8C. D\u00fcrr and P. H\u00f8yer. A Quantum Algorithm for Finding the Minimum. arXiv: quant-ph/9607014. 1996. doi: 10.48550/arXiv.quant-ph/9607014 (cit. on p. 8).\n\nSimulating Physics with Computers. R P Feynman, 10.1007/BF02650179International Journal of Theoretical Physics. 1R. P. Feynman. \"Simulating Physics with Computers\". In: International Journal of Theoretical Physics 21.6/7 (1982). doi: 10.1007/BF02650179 (cit. on p. 1).\n\n. J Flum, M Grohe, 10.1007/3-540-29953-XParameterized Complexity Theory. Texts in Theoretical Computer Science. An EATCS Series. 25SpringerJ. Flum and M. Grohe. Parameterized Complexity Theory. Texts in Theoretical Computer Science. An EATCS Series. Springer, 2006. doi: 10.1007/3-540-29953- X (cit. on p. 25).\n\nBound on the Number of Functions that Can Be Distinguished with k Quantum Queries. E Farhi, J Goldstone, S Gutmann, M Sipser, 10.1103/PhysRevA.60.4331Physical Review A. 6024E. Farhi, J. Goldstone, S. Gutmann, and M. Sipser. \"Bound on the Number of Functions that Can Be Distinguished with k Quantum Queries\". In: Physical Review A 60 (1999), pp. 4331-4333. doi: 10.1103/PhysRevA.60.4331 (cit. on p. 24).\n\nOptimizing Quantum Optimization Algorithms via Faster Quantum Gradient Computation. A Gily\u00e9n, S Arunachalam, N Wiebe, arXiv:1711.00465quant-phA. Gily\u00e9n, S. Arunachalam, and N. Wiebe. Optimizing Quantum Optimization Algo- rithms via Faster Quantum Gradient Computation. arXiv:1711.00465 [quant-ph].\n\n. 10.1137/1.9781611975482.8782017. doi: 10.1137/1.9781611975482.87 (cit. on p. 8).\n\nOptimizing Quantum Optimization Algorithms via Faster Quantum Gradient Computation. A Gily\u00e9n, S Arunachalam, N Wiebe, 10.1137/1.9781611975482.87doi: 10.1137/1. 9781611975482Proceedings of the 30th Symposium on Discrete Algorithms (SODA). the 30th Symposium on Discrete Algorithms (SODA)87cit. on pp. 2, 4-8, 10, 11, 15A. Gily\u00e9n, S. Arunachalam, and N. Wiebe. \"Optimizing Quantum Optimization Algorithms via Faster Quantum Gradient Computation\". In: Proceedings of the 30th Symposium on Discrete Algorithms (SODA). 2019, pp. 1425-1444. doi: 10.1137/1. 9781611975482.87 (cit. on pp. 2, 4-8, 10, 11, 15).\n\nDistributional Property Testing in a Quantum World. A Gily\u00e9n, T Li, 10.4230/LIPIcs.ITCS.2020.25Proceedings of the 11th Innovations in Theoretical Computer Science Conference, (ITCS). 2020. the 11th Innovations in Theoretical Computer Science Conference, (ITCS). 20208A. Gily\u00e9n and T. Li. \"Distributional Property Testing in a Quantum World\". In: Proceedings of the 11th Innovations in Theoretical Computer Science Conference, (ITCS). 2020, 25:1-25:19. doi: 10.4230/LIPIcs.ITCS.2020.25 (cit. on p. 8).\n\nMonte Carlo Methods in Financial Engineering. P Glasserman, 10.1007/978-0-387-21617-1Springer1New YorkP. Glasserman. Monte Carlo Methods in Financial Engineering. Springer New York, 2003. doi: 10.1007/978-0-387-21617-1 (cit. on p. 1).\n\nA Framework for Fast Quantum Mechanical Algorithms. L K Grover, 10.1145/276698.276712Proceedings of the 30th Symposium on Theory of Computing (STOC). the 30th Symposium on Theory of Computing (STOC)cit. on pp. 2, 5, 7L. K. Grover. \"A Framework for Fast Quantum Mechanical Algorithms\". In: Pro- ceedings of the 30th Symposium on Theory of Computing (STOC). 1998, pp. 53-62. doi: 10.1145/276698.276712 (cit. on pp. 2, 5, 7).\n\nQuantum Singular Value Transformation and Beyond: Exponential Improvements for Quantum Matrix Arithmetics. A Gily\u00e9n, Y Su, G H Low, N Wiebe, 10.1145/3313276.3316366Proceedings of the 51st Symposium on Theory of Computing (STOC). the 51st Symposium on Theory of Computing (STOC)cit. on pp. 3, 5)A. Gily\u00e9n, Y. Su, G. H. Low, and N. Wiebe. \"Quantum Singular Value Transfor- mation and Beyond: Exponential Improvements for Quantum Matrix Arithmetics\". In: Proceedings of the 51st Symposium on Theory of Computing (STOC). 2019, pp. 193-204. doi: 10.1145/3313276.3316366 (cit. on pp. 3, 5).\n\nQuantum Sub-Gaussian Mean Estimator. Y Hamoudi, 10.4230/LIPIcs.ESA.2021.5050:1-50:17. doi: 10.4230/ LIPIcs.ESA.2021.50Proceedings of the 29th European Symposium on Algorithms (ESA). 2021. the 29th European Symposium on Algorithms (ESA). 20218Y. Hamoudi. \"Quantum Sub-Gaussian Mean Estimator\". In: Proceedings of the 29th European Symposium on Algorithms (ESA). 2021, 50:1-50:17. doi: 10.4230/ LIPIcs.ESA.2021.50 (cit. on pp. 2-6, 8).\n\nQuantum Summation with an Application to Integration. S Heinrich, 10.1006/jcom.2001.0629doi: 10 . 1006 / jcom . 2001 . 0629Journal of Complexity. 18S. Heinrich. \"Quantum Summation with an Application to Integration\". In: Journal of Complexity 18.1 (2002), pp. 1-50. doi: 10 . 1006 / jcom . 2001 . 0629 (cit. on pp. 2-7).\n\nOn the Power of Quantum Algorithms for Vector Valued Mean Computation. S Heinrich, 10.1515/mcma.2004.10.3-4.297Monte Carlo Methods and Applications. 10cit. on pp. 1, 2, 6)S. Heinrich. \"On the Power of Quantum Algorithms for Vector Valued Mean Computation\". In: Monte Carlo Methods and Applications 10.3-4 (2004), pp. 297- 310. doi: 10.1515/mcma.2004.10.3-4.297 (cit. on pp. 1, 2, 6).\n\nPredicting Many Properties of a Quantum System from Very Few Measurements. H.-Y Huang, R Kueng, J Preskill, 10.1038/s41567-020-0932-7Nature Physics. 1630H.-Y. Huang, R. Kueng, and J. Preskill. \"Predicting Many Properties of a Quantum System from Very Few Measurements\". In: Nature Physics 16.10 (2020), pp. 1050- 1057. doi: 10.1038/s41567-020-0932-7 (cit. on p. 30).\n\nQuantum Chebyshev's Inequality and Applications. Y Hamoudi, F Magniez, 10.4230/LIPIcs.ICALP.2019.69Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP). the 46th International Colloquium on Automata, Languages, and Programming (ICALP)6916cit. on pp. 2, 4-7Y. Hamoudi and F. Magniez. \"Quantum Chebyshev's Inequality and Applications\". In: Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP). 2019, 69:1-69:16. doi: 10.4230/LIPIcs.ICALP.2019.69 (cit. on pp. 2, 4-7).\n\nMean Estimation with Sub-Gaussian Rates in Polynomial Time. S B Hopkins, 10.1214/19-AOS1843The Annals of Statistics. 48citS. B. Hopkins. \"Mean Estimation with Sub-Gaussian Rates in Polynomial Time\". In: The Annals of Statistics 48.2 (2020), pp. 1193-1213. doi: 10.1214/19-AOS1843 (cit. on p. 2).\n\nS Jerbi, C Gyurik, S C Marshall, H J Briegel, V Dunjko, arXiv:2103.05577Parametrized Quantum Policies for Reinforcement Learning. quant-phS. Jerbi, C. Gyurik, S. C. Marshall, H. J. Briegel, and V. Dunjko. Parametrized Quantum Policies for Reinforcement Learning. arXiv:2103.05577 [quant-ph].\n\n. 10.48550/arXiv.2103.05577302021. doi: 10.48550/arXiv.2103.05577 (cit. on p. 30).\n\nFast Quantum Algorithm for Numerical Gradient Estimation. S P Jordan, 10.1103/PhysRevLett.95.050501Physical Review Letters. 9550501cit. on pp. 3, 5, 6, 10S. P. Jordan. \"Fast Quantum Algorithm for Numerical Gradient Estimation\". In: Physical Review Letters 95.5 (2005), p. 050501. doi: 10.1103/PhysRevLett.95. 050501 (cit. on pp. 3, 5, 6, 10).\n\nQuantum Enhancements for Deep Reinforcement Learning in Large Spaces. S Jerbi, L M Trenkwalder, H P Nautrup, H J Briegel, V Dunjko, 10.1103/prxquantum.2.010328PRX Quantum. 230S. Jerbi, L. M. Trenkwalder, H. P. Nautrup, H. J. Briegel, and V. Dunjko. \"Quantum Enhancements for Deep Reinforcement Learning in Large Spaces\". In: PRX Quantum 2.1 (2021), p. 010328. doi: 10.1103/prxquantum.2.010328 (cit. on p. 30).\n\nRandom Generation of Combinatorial Structures from a Uniform Distribution. M R Jerrum, L G Valiant, V V Vazirani, 10.1016/0304-3975(86)90174-XTheoretical Computer Science. 432M. R. Jerrum, L. G. Valiant, and V. V. Vazirani. \"Random Generation of Combi- natorial Structures from a Uniform Distribution\". In: Theoretical Computer Science 43 (1986), pp. 169-188. doi: 10.1016/0304-3975(86)90174-X (cit. on p. 2).\n\nA Kitaev, 10.48550/arXiv.quant-ph/9511026Quantum Measurements and the Abelian Stabilizer Problem. cit. on pp. 1, 4)A. Kitaev. Quantum Measurements and the Abelian Stabilizer Problem. arXiv: quant-ph/9511026. 1995. doi: 10.48550/arXiv.quant-ph/9511026 (cit. on pp. 1, 4).\n\nOptimal Quantum Measurements of Expectation Values of Observables. E Knill, G Ortiz, R D Somma, 10.1103/PhysRevA.75.012328Physical Review A. 75129E. Knill, G. Ortiz, and R. D. Somma. \"Optimal Quantum Measurements of Expec- tation Values of Observables\". In: Physical Review A 75.1 (2007), p. 012328. doi: 10.1103/PhysRevA.75.012328 (cit. on p. 29).\n\nTomography and Generative Training with Quantum Boltzmann Machines. M Kieferov\u00e1, N Wiebe, 10.1103/physreva.96.062327doi: 10.1103/ physreva.96.062327Physical Review A. 9630M. Kieferov\u00e1 and N. Wiebe. \"Tomography and Generative Training with Quantum Boltzmann Machines\". In: Physical Review A 96.6 (2017), p. 062327. doi: 10.1103/ physreva.96.062327 (cit. on p. 30).\n\nMean Estimation and Regression Under Heavy-Tailed Distributions: A Survey. G Lugosi, S Mendelson, 10.1007/s10208-019-09427-xFoundations of Computational Mathematics. 19cit. on pp. 1-3, 5, 8)G. Lugosi and S. Mendelson. \"Mean Estimation and Regression Under Heavy-Tailed Distributions: A Survey\". In: Foundations of Computational Mathematics 19.5 (2019), pp. 1145-1190. doi: 10.1007/s10208-019-09427-x (cit. on pp. 1-3, 5, 8).\n\nNear-Optimal Mean Estimators with Respect to General Norms. G Lugosi, S Mendelson, 10.1007/s00440-019-00906-4Probability Theory and Related Fields. 17531citG. Lugosi and S. Mendelson. \"Near-Optimal Mean Estimators with Respect to General Norms\". In: Probability Theory and Related Fields 175.3-4 (2019), pp. 957- 973. doi: 10.1007/s00440-019-00906-4 (cit. on p. 31).\n\nQuantum Query Complexity of State Conversion. T Lee, R Mittal, B W Reichardt, R \u0160palek, M Szegedy, 10.1109/FOCS.2011.75Proceedings of the 52nd Symposium on Foundations of Computer Science (FOCS. the 52nd Symposium on Foundations of Computer Science (FOCS24T. Lee, R. Mittal, B. W. Reichardt, R. \u0160palek, and M. Szegedy. \"Quantum Query Complexity of State Conversion\". In: Proceedings of the 52nd Symposium on Founda- tions of Computer Science (FOCS). 2011, pp. 344-353. doi: 10.1109/FOCS.2011.75 (cit. on p. 24).\n\nQuantum Signal Processing by Single-Qubit Dynamics. G H Low, 8PhD thesis. Massachusetts Institute of TechnologyG. H. Low. \"Quantum Signal Processing by Single-Qubit Dynamics\". PhD thesis. Massachusetts Institute of Technology, 2017 (cit. on p. 8).\n\nQuantum Query Complexity of Entropy Estimation. T Li, X Wu, 10.1109/TIT.2018.2883306doi: 10.1109/ TIT.2018.2883306IEEE Transactions on Information Theory. 657T. Li and X. Wu. \"Quantum Query Complexity of Entropy Estimation\". In: IEEE Transactions on Information Theory 65.5 (2019), pp. 2899-2921. doi: 10.1109/ TIT.2018.2883306 (cit. on p. 7).\n\nQuantum Circuit Learning. K Mitarai, M Negoro, M Kitagawa, K Fujii, 10.1103/physreva.98.032309Physical Review A. 9830K. Mitarai, M. Negoro, M. Kitagawa, and K. Fujii. \"Quantum Circuit Learning\". In: Physical Review A 98.3 (2018), p. 032309. doi: 10.1103/physreva.98.032309 (cit. on p. 30).\n\nProbability of 1 -norms of vertices of the rotated Hamming cube. 32Probability of 1 -norms of vertices of the rotated Hamming cube. Available at https://mathoverflow.net/q/390129/92442. 2021 (cit. on p. 32).\n\nQuantum Speedup of Monte Carlo Methods. A Montanaro, 10.1098/rspa.2015.0301Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences. 4719A. Montanaro. \"Quantum Speedup of Monte Carlo Methods\". In: Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences 471.2181 (2015), p. 20150301. doi: 10.1098/rspa.2015.0301 (cit. on pp. 1-7, 9).\n\nM A Nielsen, I L Chuang, 10.1017/CBO9780511976667doi: 10. 1017/CBO9780511976667Quantum Computation and Quantum Information: 10th Anniversary Edition. Cambridge University Press2110th edM. A. Nielsen and I. L. Chuang. Quantum Computation and Quantum Information: 10th Anniversary Edition. 10th ed. Cambridge University Press, 2011. doi: 10. 1017/CBO9780511976667 (cit. on p. 21).\n\nThe Quantum Query Complexity of Approximating the Median and Related Statistics. A Nayak, F Wu, 10.1145/301250.301349Proceedings of the 31st Symposium on Theory of Computing (STOC). the 31st Symposium on Theory of Computing (STOC)cit. on pp. 7, 8)A. Nayak and F. Wu. \"The Quantum Query Complexity of Approximating the Median and Related Statistics\". In: Proceedings of the 31st Symposium on Theory of Computing (STOC). 1999, pp. 384-393. doi: 10.1145/301250.301349 (cit. on pp. 7, 8).\n\nProblem Complexity and Method Efficiency in Optimization. A S Nemirovsky, D B Yudin, John Wiley & SonsA. S. Nemirovsky and D. B. Yudin. Problem Complexity and Method Efficiency in Optimization. John Wiley & Sons, 1983 (cit. on p. 2).\n\nReinforcement Learning: An Introduction. Second. R S Sutton, A G Barto, The MIT Press30R. S. Sutton and A. G. Barto. Reinforcement Learning: An Introduction. Second. The MIT Press, 2018 (cit. on p. 30).\n\nA Skolik, S Jerbi, V Dunjko, 10.48550/arXiv.2103.15084arXiv:2103.15084Quantum Agents in the Gym: A Variational Quantum Algorithm for Deep Q-Learning. 30quant-phA. Skolik, S. Jerbi, and V. Dunjko. Quantum Agents in the Gym: A Variational Quantum Algorithm for Deep Q-Learning. arXiv:2103.15084 [quant-ph]. 2021. doi: 10.48550/arXiv.2103.15084 (cit. on p. 30).\n\nPolicy Gradient Methods for Reinforcement Learning with Function Approximation. R S Sutton, D Mcallester, S Singh, Y Mansour, Proceedings of the 12th International Conference on Neural Information Processing Systems (NIPS). the 12th International Conference on Neural Information Processing Systems (NIPS)31citR. S. Sutton, D. McAllester, S. Singh, and Y. Mansour. \"Policy Gradient Methods for Reinforcement Learning with Function Approximation\". In: Proceedings of the 12th International Conference on Neural Information Processing Systems (NIPS). 1999, pp. 1057-1063 (cit. on p. 31).\n\nQuantum Speed-Up of Markov Chain Based Algorithms. M Szegedy, 10.1109/FOCS.2004.53Proceedings of the 45th Symposium on Foundations of Computer Science (FOCS). the 45th Symposium on Foundations of Computer Science (FOCS)1M. Szegedy. \"Quantum Speed-Up of Markov Chain Based Algorithms\". In: Proceed- ings of the 45th Symposium on Foundations of Computer Science (FOCS). 2004, pp. 32-41. doi: 10.1109/FOCS.2004.53 (cit. on p. 1).\n\nQuantum Algorithms and Quantum Entanglement. B M , University of AmsterdamPhD thesiscit. on pp. 2, 4, 5, 7, 9B. M. Terhal. \"Quantum Algorithms and Quantum Entanglement\". PhD thesis. University of Amsterdam, 1999 (cit. on pp. 2, 4, 5, 7, 9).\n\nQuantum Algorithm for Approximating Partition Functions. P Wocjan, C.-F Chiang, D Nagaj, A Abeyesinghe, 10.1103/PhysRevA.80.022340Physical Review A. 8022340cit. on pp. 2, 4, 9P. Wocjan, C.-F. Chiang, D. Nagaj, and A. Abeyesinghe. \"Quantum Algorithm for Approximating Partition Functions\". In: Physical Review A 80.2 (2009), p. 022340. doi: 10.1103/PhysRevA.80.022340 (cit. on pp. 2, 4, 9, 29).\n\nQuantum Deep Learning. N Wiebe, A Kapoor, K M Svore, 10.26421/QIC16.7-8-1Quantum Information & Computation. 1630citN. Wiebe, A. Kapoor, and K. M. Svore. \"Quantum Deep Learning\". In: Quantum Information & Computation 16.7&8 (2016), pp. 541-587. doi: 10.26421/QIC16.7- 8-1 (cit. on p. 30).\n\nN Wiebe, L Wossnig, 10.48550/arXiv.1905.09902arXiv:1905.09902Generative Training of Quantum Boltzmann Machines with Hidden Units. 30quant-phN. Wiebe and L. Wossnig. Generative Training of Quantum Boltzmann Machines with Hidden Units. arXiv:1905.09902 [quant-ph]. 2019. doi: 10.48550/arXiv. 1905.09902 (cit. on p. 30).\n", "annotations": {"author": "[{\"end\":99,\"start\":81},{\"end\":116,\"start\":100},{\"end\":131,\"start\":117}]", "publisher": null, "author_last_name": "[{\"end\":98,\"start\":87},{\"end\":115,\"start\":108},{\"end\":130,\"start\":125}]", "author_first_name": "[{\"end\":86,\"start\":81},{\"end\":107,\"start\":100},{\"end\":124,\"start\":117}]", "author_affiliation": null, "title": "[{\"end\":65,\"start\":1},{\"end\":196,\"start\":132}]", "venue": null, "abstract": "[{\"end\":2428,\"start\":211}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2565,\"start\":2559},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2582,\"start\":2575},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2612,\"start\":2604},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2849,\"start\":2842},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2925,\"start\":2918},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":2950,\"start\":2943},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3072,\"start\":3065},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3604,\"start\":3597},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4192,\"start\":4185},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4416,\"start\":4408},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4472,\"start\":4464},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5493,\"start\":5485},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5806,\"start\":5799},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6172,\"start\":6165},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6864,\"start\":6857},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7283,\"start\":7277},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":7853,\"start\":7847},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7859,\"start\":7853},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8431,\"start\":8424},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8632,\"start\":8624},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8701,\"start\":8695},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":8792,\"start\":8785},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8855,\"start\":8847},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":10540,\"start\":10533},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11596,\"start\":11589},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14225,\"start\":14218},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14675,\"start\":14668},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15121,\"start\":15115},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17417,\"start\":17410},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":17824,\"start\":17817},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18335,\"start\":18327},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":18341,\"start\":18335},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":18733,\"start\":18726},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18983,\"start\":18976},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19620,\"start\":19613},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24244,\"start\":24237},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":25039,\"start\":25032},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":25457,\"start\":25450},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":25635,\"start\":25628},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":26046,\"start\":26038},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":26184,\"start\":26177},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26206,\"start\":26200},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26690,\"start\":26683},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":27250,\"start\":27243},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":27908,\"start\":27900},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":43806,\"start\":43799},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":43973,\"start\":43966},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":44119,\"start\":44113},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":45068,\"start\":45062},{\"end\":46902,\"start\":46899},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":60276,\"start\":60270},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":66300,\"start\":66294},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":67850,\"start\":67842},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":68127,\"start\":68120},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":68197,\"start\":68191},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":68834,\"start\":68826},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":69138,\"start\":69132},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":72350,\"start\":72344},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":78070,\"start\":78063},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":78077,\"start\":78070},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":78889,\"start\":78881},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":78940,\"start\":78932},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":80894,\"start\":80888},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":81681,\"start\":81673},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":83235,\"start\":83228},{\"end\":83536,\"start\":83533},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":84395,\"start\":84389}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":84907,\"start\":84611},{\"attributes\":{\"id\":\"fig_1\"},\"end\":85699,\"start\":84908},{\"attributes\":{\"id\":\"fig_2\"},\"end\":86019,\"start\":85700},{\"attributes\":{\"id\":\"fig_3\"},\"end\":86506,\"start\":86020},{\"attributes\":{\"id\":\"fig_4\"},\"end\":86769,\"start\":86507},{\"attributes\":{\"id\":\"fig_5\"},\"end\":87299,\"start\":86770},{\"attributes\":{\"id\":\"fig_6\"},\"end\":87669,\"start\":87300},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":88310,\"start\":87670},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":88922,\"start\":88311},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":89065,\"start\":88923},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":89293,\"start\":89066}]", "paragraph": "[{\"end\":3550,\"start\":2444},{\"end\":4297,\"start\":3552},{\"end\":5914,\"start\":4299},{\"end\":6635,\"start\":5916},{\"end\":7382,\"start\":6637},{\"end\":9097,\"start\":7400},{\"end\":9436,\"start\":9099},{\"end\":9439,\"start\":9438},{\"end\":9803,\"start\":9441},{\"end\":10156,\"start\":9805},{\"end\":10313,\"start\":10158},{\"end\":10461,\"start\":10385},{\"end\":10880,\"start\":10463},{\"end\":11073,\"start\":10882},{\"end\":12715,\"start\":11142},{\"end\":12865,\"start\":12717},{\"end\":13065,\"start\":12962},{\"end\":13632,\"start\":13067},{\"end\":17680,\"start\":13651},{\"end\":18106,\"start\":17728},{\"end\":18376,\"start\":18108},{\"end\":20007,\"start\":18378},{\"end\":20367,\"start\":20037},{\"end\":20653,\"start\":20369},{\"end\":20747,\"start\":20655},{\"end\":21025,\"start\":20787},{\"end\":21321,\"start\":21027},{\"end\":21626,\"start\":21346},{\"end\":21797,\"start\":21628},{\"end\":22100,\"start\":21814},{\"end\":22326,\"start\":22102},{\"end\":22558,\"start\":22328},{\"end\":23160,\"start\":22560},{\"end\":23427,\"start\":23162},{\"end\":23709,\"start\":23429},{\"end\":23764,\"start\":23734},{\"end\":23991,\"start\":23766},{\"end\":24513,\"start\":23993},{\"end\":24813,\"start\":24515},{\"end\":24978,\"start\":24835},{\"end\":25218,\"start\":24980},{\"end\":25589,\"start\":25319},{\"end\":25808,\"start\":25591},{\"end\":25981,\"start\":25826},{\"end\":26109,\"start\":25983},{\"end\":26466,\"start\":26111},{\"end\":26621,\"start\":26509},{\"end\":26767,\"start\":26623},{\"end\":27020,\"start\":26824},{\"end\":27323,\"start\":27188},{\"end\":27601,\"start\":27342},{\"end\":27706,\"start\":27673},{\"end\":28116,\"start\":27779},{\"end\":28639,\"start\":28181},{\"end\":28729,\"start\":28641},{\"end\":29001,\"start\":28807},{\"end\":30260,\"start\":29425},{\"end\":30988,\"start\":30354},{\"end\":31202,\"start\":31074},{\"end\":31767,\"start\":31380},{\"end\":32275,\"start\":32028},{\"end\":32804,\"start\":32577},{\"end\":33198,\"start\":32852},{\"end\":33641,\"start\":33544},{\"end\":33846,\"start\":33759},{\"end\":33930,\"start\":33921},{\"end\":33996,\"start\":33961},{\"end\":34044,\"start\":33998},{\"end\":34296,\"start\":34211},{\"end\":34370,\"start\":34298},{\"end\":34440,\"start\":34372},{\"end\":34650,\"start\":34527},{\"end\":34799,\"start\":34720},{\"end\":35726,\"start\":34988},{\"end\":36268,\"start\":35964},{\"end\":36510,\"start\":36270},{\"end\":36573,\"start\":36524},{\"end\":36738,\"start\":36575},{\"end\":36780,\"start\":36740},{\"end\":36806,\"start\":36782},{\"end\":36936,\"start\":36808},{\"end\":37284,\"start\":37211},{\"end\":37389,\"start\":37286},{\"end\":37514,\"start\":37417},{\"end\":37583,\"start\":37516},{\"end\":38000,\"start\":37830},{\"end\":38411,\"start\":38002},{\"end\":38529,\"start\":38471},{\"end\":38826,\"start\":38728},{\"end\":39157,\"start\":39035},{\"end\":39308,\"start\":39307},{\"end\":39554,\"start\":39310},{\"end\":39848,\"start\":39556},{\"end\":40034,\"start\":39937},{\"end\":40191,\"start\":40036},{\"end\":40884,\"start\":40231},{\"end\":41323,\"start\":40886},{\"end\":41517,\"start\":41334},{\"end\":41863,\"start\":41568},{\"end\":42393,\"start\":42133},{\"end\":42743,\"start\":42554},{\"end\":43132,\"start\":42745},{\"end\":43185,\"start\":43155},{\"end\":43380,\"start\":43196},{\"end\":44209,\"start\":43533},{\"end\":44797,\"start\":44211},{\"end\":45289,\"start\":44799},{\"end\":45586,\"start\":45291},{\"end\":46608,\"start\":45588},{\"end\":47099,\"start\":46690},{\"end\":47569,\"start\":47161},{\"end\":48006,\"start\":47571},{\"end\":48742,\"start\":48008},{\"end\":49123,\"start\":48744},{\"end\":49449,\"start\":49197},{\"end\":50047,\"start\":49516},{\"end\":50379,\"start\":50049},{\"end\":50448,\"start\":50381},{\"end\":50681,\"start\":50535},{\"end\":50908,\"start\":50683},{\"end\":51219,\"start\":50910},{\"end\":51322,\"start\":51255},{\"end\":51666,\"start\":51396},{\"end\":51937,\"start\":51894},{\"end\":52078,\"start\":52060},{\"end\":52447,\"start\":52155},{\"end\":52913,\"start\":52684},{\"end\":53225,\"start\":52915},{\"end\":53869,\"start\":53227},{\"end\":54087,\"start\":53871},{\"end\":54537,\"start\":54089},{\"end\":54606,\"start\":54539},{\"end\":54818,\"start\":54691},{\"end\":54900,\"start\":54851},{\"end\":55021,\"start\":54902},{\"end\":55526,\"start\":55060},{\"end\":55756,\"start\":55659},{\"end\":55905,\"start\":55856},{\"end\":56114,\"start\":56069},{\"end\":56270,\"start\":56175},{\"end\":56735,\"start\":56318},{\"end\":56880,\"start\":56787},{\"end\":57260,\"start\":57155},{\"end\":57764,\"start\":57322},{\"end\":58394,\"start\":58023},{\"end\":59119,\"start\":58396},{\"end\":59236,\"start\":59152},{\"end\":59612,\"start\":59238},{\"end\":59698,\"start\":59651},{\"end\":59769,\"start\":59700},{\"end\":60609,\"start\":59808},{\"end\":60961,\"start\":60611},{\"end\":61380,\"start\":60963},{\"end\":61753,\"start\":61453},{\"end\":62269,\"start\":61755},{\"end\":62692,\"start\":62271},{\"end\":62719,\"start\":62694},{\"end\":62754,\"start\":62721},{\"end\":62896,\"start\":62756},{\"end\":63103,\"start\":62898},{\"end\":63191,\"start\":63105},{\"end\":63279,\"start\":63193},{\"end\":63602,\"start\":63281},{\"end\":63690,\"start\":63641},{\"end\":64037,\"start\":63692},{\"end\":64169,\"start\":64133},{\"end\":64327,\"start\":64276},{\"end\":64566,\"start\":64429},{\"end\":64825,\"start\":64670},{\"end\":64951,\"start\":64827},{\"end\":65338,\"start\":64953},{\"end\":65537,\"start\":65387},{\"end\":66498,\"start\":65574},{\"end\":66834,\"start\":66515},{\"end\":67225,\"start\":66836},{\"end\":67541,\"start\":67227},{\"end\":68198,\"start\":67543},{\"end\":68926,\"start\":68200},{\"end\":69143,\"start\":68994},{\"end\":69332,\"start\":69182},{\"end\":69536,\"start\":69334},{\"end\":69824,\"start\":69538},{\"end\":69875,\"start\":69845},{\"end\":70512,\"start\":69877},{\"end\":70699,\"start\":70575},{\"end\":71090,\"start\":70772},{\"end\":71257,\"start\":71092},{\"end\":72355,\"start\":71277},{\"end\":72630,\"start\":72441},{\"end\":72867,\"start\":72649},{\"end\":73059,\"start\":72930},{\"end\":73213,\"start\":73061},{\"end\":73501,\"start\":73215},{\"end\":73554,\"start\":73524},{\"end\":74010,\"start\":73556},{\"end\":74135,\"start\":74085},{\"end\":74587,\"start\":74476},{\"end\":74612,\"start\":74606},{\"end\":75038,\"start\":74629},{\"end\":76187,\"start\":75136},{\"end\":76871,\"start\":76210},{\"end\":77582,\"start\":76911},{\"end\":78714,\"start\":77612},{\"end\":79546,\"start\":78783},{\"end\":79843,\"start\":79578},{\"end\":80088,\"start\":79887},{\"end\":80329,\"start\":80146},{\"end\":80799,\"start\":80367},{\"end\":81807,\"start\":80847},{\"end\":81903,\"start\":81809},{\"end\":82478,\"start\":81905},{\"end\":82525,\"start\":82480},{\"end\":82741,\"start\":82527},{\"end\":83746,\"start\":82756},{\"end\":84159,\"start\":83748},{\"end\":84610,\"start\":84161}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10384,\"start\":10314},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11141,\"start\":11074},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12961,\"start\":12866},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17712,\"start\":17681},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20786,\"start\":20748},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21345,\"start\":21322},{\"attributes\":{\"id\":\"formula_6\"},\"end\":23733,\"start\":23710},{\"attributes\":{\"id\":\"formula_7\"},\"end\":25318,\"start\":25219},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25825,\"start\":25809},{\"attributes\":{\"id\":\"formula_9\"},\"end\":26508,\"start\":26467},{\"attributes\":{\"id\":\"formula_10\"},\"end\":26823,\"start\":26768},{\"attributes\":{\"id\":\"formula_11\"},\"end\":27187,\"start\":27021},{\"attributes\":{\"id\":\"formula_12\"},\"end\":27341,\"start\":27324},{\"attributes\":{\"id\":\"formula_13\"},\"end\":27672,\"start\":27602},{\"attributes\":{\"id\":\"formula_14\"},\"end\":28180,\"start\":28117},{\"attributes\":{\"id\":\"formula_15\"},\"end\":28806,\"start\":28730},{\"attributes\":{\"id\":\"formula_16\"},\"end\":29424,\"start\":29002},{\"attributes\":{\"id\":\"formula_17\"},\"end\":30276,\"start\":30261},{\"attributes\":{\"id\":\"formula_18\"},\"end\":30353,\"start\":30276},{\"attributes\":{\"id\":\"formula_19\"},\"end\":31073,\"start\":30989},{\"attributes\":{\"id\":\"formula_20\"},\"end\":31379,\"start\":31203},{\"attributes\":{\"id\":\"formula_21\"},\"end\":32027,\"start\":31768},{\"attributes\":{\"id\":\"formula_22\"},\"end\":32576,\"start\":32276},{\"attributes\":{\"id\":\"formula_23\"},\"end\":32851,\"start\":32805},{\"attributes\":{\"id\":\"formula_24\"},\"end\":33543,\"start\":33199},{\"attributes\":{\"id\":\"formula_25\"},\"end\":33758,\"start\":33642},{\"attributes\":{\"id\":\"formula_26\"},\"end\":33920,\"start\":33847},{\"attributes\":{\"id\":\"formula_27\"},\"end\":33960,\"start\":33931},{\"attributes\":{\"id\":\"formula_28\"},\"end\":34148,\"start\":34045},{\"attributes\":{\"id\":\"formula_29\"},\"end\":34210,\"start\":34148},{\"attributes\":{\"id\":\"formula_30\"},\"end\":34526,\"start\":34441},{\"attributes\":{\"id\":\"formula_31\"},\"end\":34719,\"start\":34651},{\"attributes\":{\"id\":\"formula_32\"},\"end\":34987,\"start\":34800},{\"attributes\":{\"id\":\"formula_33\"},\"end\":35799,\"start\":35727},{\"attributes\":{\"id\":\"formula_34\"},\"end\":35925,\"start\":35870},{\"attributes\":{\"id\":\"formula_35\"},\"end\":36523,\"start\":36511},{\"attributes\":{\"id\":\"formula_36\"},\"end\":37210,\"start\":36937},{\"attributes\":{\"id\":\"formula_37\"},\"end\":37416,\"start\":37390},{\"attributes\":{\"id\":\"formula_38\"},\"end\":37829,\"start\":37584},{\"attributes\":{\"id\":\"formula_39\"},\"end\":38470,\"start\":38412},{\"attributes\":{\"id\":\"formula_40\"},\"end\":38727,\"start\":38530},{\"attributes\":{\"id\":\"formula_41\"},\"end\":39034,\"start\":38827},{\"attributes\":{\"id\":\"formula_42\"},\"end\":39306,\"start\":39158},{\"attributes\":{\"id\":\"formula_43\"},\"end\":39936,\"start\":39849},{\"attributes\":{\"id\":\"formula_44\"},\"end\":40215,\"start\":40192},{\"attributes\":{\"id\":\"formula_45\"},\"end\":41567,\"start\":41518},{\"attributes\":{\"id\":\"formula_46\"},\"end\":42132,\"start\":41864},{\"attributes\":{\"id\":\"formula_47\"},\"end\":42553,\"start\":42394},{\"attributes\":{\"id\":\"formula_48\"},\"end\":43154,\"start\":43133},{\"attributes\":{\"id\":\"formula_49\"},\"end\":43444,\"start\":43381},{\"attributes\":{\"id\":\"formula_50\"},\"end\":43495,\"start\":43444},{\"attributes\":{\"id\":\"formula_51\"},\"end\":46689,\"start\":46609},{\"attributes\":{\"id\":\"formula_52\"},\"end\":47160,\"start\":47100},{\"attributes\":{\"id\":\"formula_53\"},\"end\":49515,\"start\":49450},{\"attributes\":{\"id\":\"formula_54\"},\"end\":50534,\"start\":50449},{\"attributes\":{\"id\":\"formula_55\"},\"end\":51254,\"start\":51220},{\"attributes\":{\"id\":\"formula_56\"},\"end\":51395,\"start\":51323},{\"attributes\":{\"id\":\"formula_57\"},\"end\":51893,\"start\":51667},{\"attributes\":{\"id\":\"formula_58\"},\"end\":52059,\"start\":51938},{\"attributes\":{\"id\":\"formula_59\"},\"end\":52154,\"start\":52079},{\"attributes\":{\"id\":\"formula_60\"},\"end\":52683,\"start\":52448},{\"attributes\":{\"id\":\"formula_61\"},\"end\":54690,\"start\":54607},{\"attributes\":{\"id\":\"formula_62\"},\"end\":54850,\"start\":54819},{\"attributes\":{\"id\":\"formula_63\"},\"end\":55059,\"start\":55022},{\"attributes\":{\"id\":\"formula_64\"},\"end\":55658,\"start\":55527},{\"attributes\":{\"id\":\"formula_65\"},\"end\":55855,\"start\":55757},{\"attributes\":{\"id\":\"formula_66\"},\"end\":56068,\"start\":55906},{\"attributes\":{\"id\":\"formula_67\"},\"end\":56174,\"start\":56115},{\"attributes\":{\"id\":\"formula_68\"},\"end\":56317,\"start\":56271},{\"attributes\":{\"id\":\"formula_69\"},\"end\":56786,\"start\":56736},{\"attributes\":{\"id\":\"formula_70\"},\"end\":57154,\"start\":56881},{\"attributes\":{\"id\":\"formula_71\"},\"end\":57321,\"start\":57261},{\"attributes\":{\"id\":\"formula_72\"},\"end\":58022,\"start\":57765},{\"attributes\":{\"id\":\"formula_73\"},\"end\":59151,\"start\":59120},{\"attributes\":{\"id\":\"formula_74\"},\"end\":59650,\"start\":59613},{\"attributes\":{\"id\":\"formula_75\"},\"end\":59807,\"start\":59770},{\"attributes\":{\"id\":\"formula_76\"},\"end\":63640,\"start\":63603},{\"attributes\":{\"id\":\"formula_77\"},\"end\":64064,\"start\":64038},{\"attributes\":{\"id\":\"formula_78\"},\"end\":64132,\"start\":64064},{\"attributes\":{\"id\":\"formula_79\"},\"end\":64275,\"start\":64170},{\"attributes\":{\"id\":\"formula_80\"},\"end\":64428,\"start\":64328},{\"attributes\":{\"id\":\"formula_81\"},\"end\":64669,\"start\":64567},{\"attributes\":{\"id\":\"formula_82\"},\"end\":65386,\"start\":65339},{\"attributes\":{\"id\":\"formula_83\"},\"end\":65573,\"start\":65538},{\"attributes\":{\"id\":\"formula_84\"},\"end\":68993,\"start\":68927},{\"attributes\":{\"id\":\"formula_85\"},\"end\":69181,\"start\":69144},{\"attributes\":{\"id\":\"formula_86\"},\"end\":69844,\"start\":69825},{\"attributes\":{\"id\":\"formula_87\"},\"end\":70574,\"start\":70513},{\"attributes\":{\"id\":\"formula_88\"},\"end\":70771,\"start\":70700},{\"attributes\":{\"id\":\"formula_89\"},\"end\":71276,\"start\":71258},{\"attributes\":{\"id\":\"formula_90\"},\"end\":72440,\"start\":72356},{\"attributes\":{\"id\":\"formula_91\"},\"end\":72648,\"start\":72631},{\"attributes\":{\"id\":\"formula_92\"},\"end\":72929,\"start\":72868},{\"attributes\":{\"id\":\"formula_93\"},\"end\":73523,\"start\":73502},{\"attributes\":{\"id\":\"formula_94\"},\"end\":74084,\"start\":74011},{\"attributes\":{\"id\":\"formula_95\"},\"end\":74475,\"start\":74136},{\"attributes\":{\"id\":\"formula_96\"},\"end\":74605,\"start\":74588},{\"attributes\":{\"id\":\"formula_97\"},\"end\":76910,\"start\":76872},{\"attributes\":{\"id\":\"formula_98\"},\"end\":79886,\"start\":79844},{\"attributes\":{\"id\":\"formula_99\"},\"end\":80145,\"start\":80089},{\"attributes\":{\"id\":\"formula_100\"},\"end\":80366,\"start\":80330}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2442,\"start\":2430},{\"attributes\":{\"n\":\"1.1\"},\"end\":7398,\"start\":7385},{\"attributes\":{\"n\":\"1.2\"},\"end\":13649,\"start\":13635},{\"attributes\":{\"n\":\"1.3\"},\"end\":17726,\"start\":17714},{\"attributes\":{\"n\":\"2\"},\"end\":20023,\"start\":20010},{\"attributes\":{\"n\":\"2.1\"},\"end\":20035,\"start\":20026},{\"attributes\":{\"n\":\"2.2\"},\"end\":21812,\"start\":21800},{\"attributes\":{\"n\":\"2.3\"},\"end\":24833,\"start\":24816},{\"attributes\":{\"n\":\"3\"},\"end\":27744,\"start\":27709},{\"attributes\":{\"n\":\"3.1\"},\"end\":27777,\"start\":27747},{\"end\":35869,\"start\":35801},{\"attributes\":{\"n\":\"3.2\"},\"end\":35962,\"start\":35927},{\"attributes\":{\"n\":\"3.3\"},\"end\":40229,\"start\":40217},{\"end\":41332,\"start\":41326},{\"end\":43194,\"start\":43188},{\"attributes\":{\"n\":\"4\"},\"end\":43531,\"start\":43497},{\"attributes\":{\"n\":\"4.1\"},\"end\":49195,\"start\":49126},{\"attributes\":{\"n\":\"4.2\"},\"end\":61451,\"start\":61383},{\"attributes\":{\"n\":\"4.3\"},\"end\":66513,\"start\":66501},{\"attributes\":{\"n\":\"5\"},\"end\":74627,\"start\":74615},{\"attributes\":{\"n\":\"5.1\"},\"end\":75095,\"start\":75041},{\"attributes\":{\"n\":\"5.1.1\"},\"end\":75134,\"start\":75098},{\"attributes\":{\"n\":\"5.1.2\"},\"end\":76208,\"start\":76190},{\"attributes\":{\"n\":\"5.1.3\"},\"end\":77610,\"start\":77585},{\"attributes\":{\"n\":\"5.2\"},\"end\":78741,\"start\":78717},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":78781,\"start\":78744},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":79576,\"start\":79549},{\"attributes\":{\"n\":\"5.2.3\"},\"end\":80845,\"start\":80802},{\"attributes\":{\"n\":\"6\"},\"end\":82754,\"start\":82744},{\"end\":84920,\"start\":84909},{\"end\":85713,\"start\":85701},{\"end\":86509,\"start\":86508},{\"end\":87314,\"start\":87301}]", "table": "[{\"end\":89293,\"start\":89202}]", "figure_caption": "[{\"end\":84907,\"start\":84613},{\"end\":85699,\"start\":84922},{\"end\":86019,\"start\":85715},{\"end\":86506,\"start\":86022},{\"end\":86769,\"start\":86510},{\"end\":87299,\"start\":86772},{\"end\":87669,\"start\":87317},{\"end\":88310,\"start\":87672},{\"end\":88922,\"start\":88313},{\"end\":89065,\"start\":88925},{\"end\":89202,\"start\":89068}]", "figure_ref": null, "bib_author_first_name": "[{\"end\":92473,\"start\":92472},{\"end\":92740,\"start\":92739},{\"end\":92751,\"start\":92750},{\"end\":92762,\"start\":92761},{\"end\":92772,\"start\":92771},{\"end\":92774,\"start\":92773},{\"end\":93083,\"start\":93082},{\"end\":93091,\"start\":93090},{\"end\":93101,\"start\":93100},{\"end\":93461,\"start\":93460},{\"end\":94053,\"start\":94052},{\"end\":94055,\"start\":94054},{\"end\":94065,\"start\":94064},{\"end\":94067,\"start\":94066},{\"end\":94438,\"start\":94437},{\"end\":94447,\"start\":94446},{\"end\":94459,\"start\":94458},{\"end\":94468,\"start\":94467},{\"end\":95011,\"start\":95010},{\"end\":95023,\"start\":95022},{\"end\":95033,\"start\":95032},{\"end\":95042,\"start\":95041},{\"end\":95408,\"start\":95407},{\"end\":95680,\"start\":95679},{\"end\":95690,\"start\":95689},{\"end\":95692,\"start\":95691},{\"end\":96013,\"start\":96012},{\"end\":96023,\"start\":96022},{\"end\":96025,\"start\":96024},{\"end\":96035,\"start\":96034},{\"end\":96405,\"start\":96404},{\"end\":96417,\"start\":96416},{\"end\":96426,\"start\":96425},{\"end\":96435,\"start\":96434},{\"end\":96806,\"start\":96805},{\"end\":96819,\"start\":96818},{\"end\":96828,\"start\":96827},{\"end\":96836,\"start\":96835},{\"end\":97155,\"start\":97154},{\"end\":97168,\"start\":97167},{\"end\":97170,\"start\":97169},{\"end\":97511,\"start\":97510},{\"end\":97526,\"start\":97525},{\"end\":97537,\"start\":97536},{\"end\":97549,\"start\":97548},{\"end\":98170,\"start\":98169},{\"end\":98185,\"start\":98184},{\"end\":98456,\"start\":98455},{\"end\":98464,\"start\":98463},{\"end\":98737,\"start\":98736},{\"end\":98739,\"start\":98738},{\"end\":98974,\"start\":98973},{\"end\":98982,\"start\":98981},{\"end\":99367,\"start\":99366},{\"end\":99376,\"start\":99375},{\"end\":99389,\"start\":99388},{\"end\":99400,\"start\":99399},{\"end\":99773,\"start\":99772},{\"end\":99783,\"start\":99782},{\"end\":99798,\"start\":99797},{\"end\":100156,\"start\":100155},{\"end\":100166,\"start\":100165},{\"end\":100181,\"start\":100180},{\"end\":100727,\"start\":100726},{\"end\":100737,\"start\":100736},{\"end\":101223,\"start\":101222},{\"end\":101465,\"start\":101464},{\"end\":101467,\"start\":101466},{\"end\":101944,\"start\":101943},{\"end\":101954,\"start\":101953},{\"end\":101960,\"start\":101959},{\"end\":101962,\"start\":101961},{\"end\":101969,\"start\":101968},{\"end\":102460,\"start\":102459},{\"end\":102912,\"start\":102911},{\"end\":103251,\"start\":103250},{\"end\":103643,\"start\":103639},{\"end\":103652,\"start\":103651},{\"end\":103661,\"start\":103660},{\"end\":103982,\"start\":103981},{\"end\":103993,\"start\":103992},{\"end\":104548,\"start\":104547},{\"end\":104550,\"start\":104549},{\"end\":104785,\"start\":104784},{\"end\":104794,\"start\":104793},{\"end\":104804,\"start\":104803},{\"end\":104806,\"start\":104805},{\"end\":104818,\"start\":104817},{\"end\":104820,\"start\":104819},{\"end\":104831,\"start\":104830},{\"end\":105220,\"start\":105219},{\"end\":105222,\"start\":105221},{\"end\":105576,\"start\":105575},{\"end\":105585,\"start\":105584},{\"end\":105587,\"start\":105586},{\"end\":105602,\"start\":105601},{\"end\":105604,\"start\":105603},{\"end\":105615,\"start\":105614},{\"end\":105617,\"start\":105616},{\"end\":105628,\"start\":105627},{\"end\":105992,\"start\":105991},{\"end\":105994,\"start\":105993},{\"end\":106004,\"start\":106003},{\"end\":106006,\"start\":106005},{\"end\":106017,\"start\":106016},{\"end\":106019,\"start\":106018},{\"end\":106328,\"start\":106327},{\"end\":106667,\"start\":106666},{\"end\":106676,\"start\":106675},{\"end\":106685,\"start\":106684},{\"end\":106687,\"start\":106686},{\"end\":107018,\"start\":107017},{\"end\":107031,\"start\":107030},{\"end\":107390,\"start\":107389},{\"end\":107400,\"start\":107399},{\"end\":107801,\"start\":107800},{\"end\":107811,\"start\":107810},{\"end\":108155,\"start\":108154},{\"end\":108162,\"start\":108161},{\"end\":108172,\"start\":108171},{\"end\":108174,\"start\":108173},{\"end\":108187,\"start\":108186},{\"end\":108197,\"start\":108196},{\"end\":108674,\"start\":108673},{\"end\":108676,\"start\":108675},{\"end\":108919,\"start\":108918},{\"end\":108925,\"start\":108924},{\"end\":109242,\"start\":109241},{\"end\":109253,\"start\":109252},{\"end\":109263,\"start\":109262},{\"end\":109275,\"start\":109274},{\"end\":109756,\"start\":109755},{\"end\":110105,\"start\":110104},{\"end\":110107,\"start\":110106},{\"end\":110118,\"start\":110117},{\"end\":110120,\"start\":110119},{\"end\":110566,\"start\":110565},{\"end\":110575,\"start\":110574},{\"end\":111029,\"start\":111028},{\"end\":111031,\"start\":111030},{\"end\":111045,\"start\":111044},{\"end\":111047,\"start\":111046},{\"end\":111255,\"start\":111254},{\"end\":111257,\"start\":111256},{\"end\":111267,\"start\":111266},{\"end\":111269,\"start\":111268},{\"end\":111410,\"start\":111409},{\"end\":111420,\"start\":111419},{\"end\":111429,\"start\":111428},{\"end\":111850,\"start\":111849},{\"end\":111852,\"start\":111851},{\"end\":111862,\"start\":111861},{\"end\":111876,\"start\":111875},{\"end\":111885,\"start\":111884},{\"end\":112408,\"start\":112407},{\"end\":112830,\"start\":112829},{\"end\":112832,\"start\":112831},{\"end\":113084,\"start\":113083},{\"end\":113097,\"start\":113093},{\"end\":113107,\"start\":113106},{\"end\":113116,\"start\":113115},{\"end\":113445,\"start\":113444},{\"end\":113454,\"start\":113453},{\"end\":113464,\"start\":113463},{\"end\":113466,\"start\":113465},{\"end\":113711,\"start\":113710},{\"end\":113720,\"start\":113719}]", "bib_author_last_name": "[{\"end\":92482,\"start\":92474},{\"end\":92748,\"start\":92741},{\"end\":92759,\"start\":92752},{\"end\":92769,\"start\":92763},{\"end\":92781,\"start\":92775},{\"end\":93088,\"start\":93084},{\"end\":93098,\"start\":93092},{\"end\":93109,\"start\":93102},{\"end\":93475,\"start\":93462},{\"end\":94062,\"start\":94056},{\"end\":94076,\"start\":94068},{\"end\":94444,\"start\":94439},{\"end\":94456,\"start\":94448},{\"end\":94465,\"start\":94460},{\"end\":94473,\"start\":94469},{\"end\":95020,\"start\":95012},{\"end\":95030,\"start\":95024},{\"end\":95039,\"start\":95034},{\"end\":95047,\"start\":95043},{\"end\":95415,\"start\":95409},{\"end\":95687,\"start\":95681},{\"end\":95701,\"start\":95693},{\"end\":96020,\"start\":96014},{\"end\":96032,\"start\":96026},{\"end\":96044,\"start\":96036},{\"end\":96414,\"start\":96406},{\"end\":96423,\"start\":96418},{\"end\":96432,\"start\":96427},{\"end\":96440,\"start\":96436},{\"end\":96816,\"start\":96807},{\"end\":96825,\"start\":96820},{\"end\":96833,\"start\":96829},{\"end\":96847,\"start\":96837},{\"end\":97165,\"start\":97156},{\"end\":97179,\"start\":97171},{\"end\":97523,\"start\":97512},{\"end\":97534,\"start\":97527},{\"end\":97546,\"start\":97538},{\"end\":97557,\"start\":97550},{\"end\":98182,\"start\":98171},{\"end\":98191,\"start\":98186},{\"end\":98461,\"start\":98457},{\"end\":98470,\"start\":98465},{\"end\":98747,\"start\":98740},{\"end\":98979,\"start\":98975},{\"end\":98988,\"start\":98983},{\"end\":99373,\"start\":99368},{\"end\":99386,\"start\":99377},{\"end\":99397,\"start\":99390},{\"end\":99407,\"start\":99401},{\"end\":99780,\"start\":99774},{\"end\":99795,\"start\":99784},{\"end\":99804,\"start\":99799},{\"end\":100163,\"start\":100157},{\"end\":100178,\"start\":100167},{\"end\":100187,\"start\":100182},{\"end\":100734,\"start\":100728},{\"end\":100740,\"start\":100738},{\"end\":101234,\"start\":101224},{\"end\":101474,\"start\":101468},{\"end\":101951,\"start\":101945},{\"end\":101957,\"start\":101955},{\"end\":101966,\"start\":101963},{\"end\":101975,\"start\":101970},{\"end\":102468,\"start\":102461},{\"end\":102921,\"start\":102913},{\"end\":103260,\"start\":103252},{\"end\":103649,\"start\":103644},{\"end\":103658,\"start\":103653},{\"end\":103670,\"start\":103662},{\"end\":103990,\"start\":103983},{\"end\":104001,\"start\":103994},{\"end\":104558,\"start\":104551},{\"end\":104791,\"start\":104786},{\"end\":104801,\"start\":104795},{\"end\":104815,\"start\":104807},{\"end\":104828,\"start\":104821},{\"end\":104838,\"start\":104832},{\"end\":105229,\"start\":105223},{\"end\":105582,\"start\":105577},{\"end\":105599,\"start\":105588},{\"end\":105612,\"start\":105605},{\"end\":105625,\"start\":105618},{\"end\":105635,\"start\":105629},{\"end\":106001,\"start\":105995},{\"end\":106014,\"start\":106007},{\"end\":106028,\"start\":106020},{\"end\":106335,\"start\":106329},{\"end\":106673,\"start\":106668},{\"end\":106682,\"start\":106677},{\"end\":106693,\"start\":106688},{\"end\":107028,\"start\":107019},{\"end\":107037,\"start\":107032},{\"end\":107397,\"start\":107391},{\"end\":107410,\"start\":107401},{\"end\":107808,\"start\":107802},{\"end\":107821,\"start\":107812},{\"end\":108159,\"start\":108156},{\"end\":108169,\"start\":108163},{\"end\":108184,\"start\":108175},{\"end\":108194,\"start\":108188},{\"end\":108205,\"start\":108198},{\"end\":108680,\"start\":108677},{\"end\":108922,\"start\":108920},{\"end\":108928,\"start\":108926},{\"end\":109250,\"start\":109243},{\"end\":109260,\"start\":109254},{\"end\":109272,\"start\":109264},{\"end\":109281,\"start\":109276},{\"end\":109766,\"start\":109757},{\"end\":110115,\"start\":110108},{\"end\":110127,\"start\":110121},{\"end\":110572,\"start\":110567},{\"end\":110578,\"start\":110576},{\"end\":111042,\"start\":111032},{\"end\":111053,\"start\":111048},{\"end\":111264,\"start\":111258},{\"end\":111275,\"start\":111270},{\"end\":111417,\"start\":111411},{\"end\":111426,\"start\":111421},{\"end\":111436,\"start\":111430},{\"end\":111859,\"start\":111853},{\"end\":111873,\"start\":111863},{\"end\":111882,\"start\":111877},{\"end\":111893,\"start\":111886},{\"end\":112416,\"start\":112409},{\"end\":113091,\"start\":113085},{\"end\":113104,\"start\":113098},{\"end\":113113,\"start\":113108},{\"end\":113128,\"start\":113117},{\"end\":113451,\"start\":113446},{\"end\":113461,\"start\":113455},{\"end\":113472,\"start\":113467},{\"end\":113717,\"start\":113712},{\"end\":113728,\"start\":113721}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.1137/18M120275X\",\"id\":\"b0\",\"matched_paper_id\":2346228},\"end\":92691,\"start\":92435},{\"attributes\":{\"doi\":\"10.1023/a:1020281327116\",\"id\":\"b1\",\"matched_paper_id\":38363},\"end\":93019,\"start\":92693},{\"attributes\":{\"doi\":\"10.1006/jcss.1997.1545\",\"id\":\"b2\",\"matched_paper_id\":1627911},\"end\":93389,\"start\":93021},{\"attributes\":{\"doi\":\"10.4230/LIPIcs.TQC.2021.9\",\"id\":\"b3\",\"matched_paper_id\":235600055},\"end\":94050,\"start\":93391},{\"attributes\":{\"id\":\"b4\"},\"end\":94400,\"start\":94052},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":10032711},\"end\":94859,\"start\":94402},{\"attributes\":{\"id\":\"b6\"},\"end\":95405,\"start\":94861},{\"attributes\":{\"id\":\"b7\"},\"end\":95546,\"start\":95407},{\"attributes\":{\"id\":\"b8\"},\"end\":95630,\"start\":95548},{\"attributes\":{\"id\":\"b9\"},\"end\":95950,\"start\":95632},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7402734},\"end\":96354,\"start\":95952},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":54753},\"end\":96744,\"start\":96356},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":189999815},\"end\":97125,\"start\":96746},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":676378},\"end\":97467,\"start\":97127},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":2361496},\"end\":98107,\"start\":97469},{\"attributes\":{\"id\":\"b15\"},\"end\":98453,\"start\":98109},{\"attributes\":{\"id\":\"b16\"},\"end\":98699,\"start\":98455},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":124545445},\"end\":98969,\"start\":98701},{\"attributes\":{\"id\":\"b18\"},\"end\":99281,\"start\":98971},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":117048998},\"end\":99686,\"start\":99283},{\"attributes\":{\"id\":\"b20\"},\"end\":99985,\"start\":99688},{\"attributes\":{\"id\":\"b21\"},\"end\":100069,\"start\":99987},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":303249},\"end\":100672,\"start\":100071},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":59599595},\"end\":101174,\"start\":100674},{\"attributes\":{\"id\":\"b24\"},\"end\":101410,\"start\":101176},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":7893499},\"end\":101834,\"start\":101412},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":46941335},\"end\":102420,\"start\":101836},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":237347169},\"end\":102855,\"start\":102422},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":14365504},\"end\":103177,\"start\":102857},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":16231012},\"end\":103562,\"start\":103179},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":211205098},\"end\":103930,\"start\":103564},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":51676694},\"end\":104485,\"start\":103932},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":53047266},\"end\":104782,\"start\":104487},{\"attributes\":{\"id\":\"b33\"},\"end\":105075,\"start\":104784},{\"attributes\":{\"id\":\"b34\"},\"end\":105159,\"start\":105077},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":33700469},\"end\":105503,\"start\":105161},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":221848910},\"end\":105914,\"start\":105505},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":266961},\"end\":106325,\"start\":105916},{\"attributes\":{\"id\":\"b38\"},\"end\":106597,\"start\":106327},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":27888608},\"end\":106947,\"start\":106599},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":119491098},\"end\":107312,\"start\":106949},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":184487057},\"end\":107738,\"start\":107314},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":88523740},\"end\":108106,\"start\":107740},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":16114463},\"end\":108619,\"start\":108108},{\"attributes\":{\"id\":\"b44\"},\"end\":108868,\"start\":108621},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":20575311},\"end\":109213,\"start\":108870},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":117542570},\"end\":109504,\"start\":109215},{\"attributes\":{\"id\":\"b47\"},\"end\":109713,\"start\":109506},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":3007616},\"end\":110102,\"start\":109715},{\"attributes\":{\"id\":\"b49\"},\"end\":110482,\"start\":110104},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":2348},\"end\":110968,\"start\":110484},{\"attributes\":{\"id\":\"b51\"},\"end\":111203,\"start\":110970},{\"attributes\":{\"id\":\"b52\"},\"end\":111407,\"start\":111205},{\"attributes\":{\"id\":\"b53\"},\"end\":111767,\"start\":111409},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":1211821},\"end\":112354,\"start\":111769},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":1901085},\"end\":112782,\"start\":112356},{\"attributes\":{\"id\":\"b56\"},\"end\":113024,\"start\":112784},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":14553824},\"end\":113419,\"start\":113026},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":2700333},\"end\":113708,\"start\":113421},{\"attributes\":{\"id\":\"b59\"},\"end\":114027,\"start\":113710}]", "bib_title": "[{\"end\":92470,\"start\":92435},{\"end\":92737,\"start\":92693},{\"end\":93080,\"start\":93021},{\"end\":93458,\"start\":93391},{\"end\":94435,\"start\":94402},{\"end\":96010,\"start\":95952},{\"end\":96402,\"start\":96356},{\"end\":96803,\"start\":96746},{\"end\":97152,\"start\":97127},{\"end\":97508,\"start\":97469},{\"end\":98734,\"start\":98701},{\"end\":99364,\"start\":99283},{\"end\":100153,\"start\":100071},{\"end\":100724,\"start\":100674},{\"end\":101462,\"start\":101412},{\"end\":101941,\"start\":101836},{\"end\":102457,\"start\":102422},{\"end\":102909,\"start\":102857},{\"end\":103248,\"start\":103179},{\"end\":103637,\"start\":103564},{\"end\":103979,\"start\":103932},{\"end\":104545,\"start\":104487},{\"end\":105217,\"start\":105161},{\"end\":105573,\"start\":105505},{\"end\":105989,\"start\":105916},{\"end\":106664,\"start\":106599},{\"end\":107015,\"start\":106949},{\"end\":107387,\"start\":107314},{\"end\":107798,\"start\":107740},{\"end\":108152,\"start\":108108},{\"end\":108916,\"start\":108870},{\"end\":109239,\"start\":109215},{\"end\":109753,\"start\":109715},{\"end\":110563,\"start\":110484},{\"end\":111847,\"start\":111769},{\"end\":112405,\"start\":112356},{\"end\":113081,\"start\":113026},{\"end\":113442,\"start\":113421}]", "bib_author": "[{\"end\":92484,\"start\":92472},{\"end\":92750,\"start\":92739},{\"end\":92761,\"start\":92750},{\"end\":92771,\"start\":92761},{\"end\":92783,\"start\":92771},{\"end\":93090,\"start\":93082},{\"end\":93100,\"start\":93090},{\"end\":93111,\"start\":93100},{\"end\":93477,\"start\":93460},{\"end\":94064,\"start\":94052},{\"end\":94078,\"start\":94064},{\"end\":94446,\"start\":94437},{\"end\":94458,\"start\":94446},{\"end\":94467,\"start\":94458},{\"end\":94475,\"start\":94467},{\"end\":95022,\"start\":95010},{\"end\":95032,\"start\":95022},{\"end\":95041,\"start\":95032},{\"end\":95049,\"start\":95041},{\"end\":95417,\"start\":95407},{\"end\":95689,\"start\":95679},{\"end\":95703,\"start\":95689},{\"end\":96022,\"start\":96012},{\"end\":96034,\"start\":96022},{\"end\":96046,\"start\":96034},{\"end\":96416,\"start\":96404},{\"end\":96425,\"start\":96416},{\"end\":96434,\"start\":96425},{\"end\":96442,\"start\":96434},{\"end\":96818,\"start\":96805},{\"end\":96827,\"start\":96818},{\"end\":96835,\"start\":96827},{\"end\":96849,\"start\":96835},{\"end\":97167,\"start\":97154},{\"end\":97181,\"start\":97167},{\"end\":97525,\"start\":97510},{\"end\":97536,\"start\":97525},{\"end\":97548,\"start\":97536},{\"end\":97559,\"start\":97548},{\"end\":98184,\"start\":98169},{\"end\":98193,\"start\":98184},{\"end\":98463,\"start\":98455},{\"end\":98472,\"start\":98463},{\"end\":98749,\"start\":98736},{\"end\":98981,\"start\":98973},{\"end\":98990,\"start\":98981},{\"end\":99375,\"start\":99366},{\"end\":99388,\"start\":99375},{\"end\":99399,\"start\":99388},{\"end\":99409,\"start\":99399},{\"end\":99782,\"start\":99772},{\"end\":99797,\"start\":99782},{\"end\":99806,\"start\":99797},{\"end\":100165,\"start\":100155},{\"end\":100180,\"start\":100165},{\"end\":100189,\"start\":100180},{\"end\":100736,\"start\":100726},{\"end\":100742,\"start\":100736},{\"end\":101236,\"start\":101222},{\"end\":101476,\"start\":101464},{\"end\":101953,\"start\":101943},{\"end\":101959,\"start\":101953},{\"end\":101968,\"start\":101959},{\"end\":101977,\"start\":101968},{\"end\":102470,\"start\":102459},{\"end\":102923,\"start\":102911},{\"end\":103262,\"start\":103250},{\"end\":103651,\"start\":103639},{\"end\":103660,\"start\":103651},{\"end\":103672,\"start\":103660},{\"end\":103992,\"start\":103981},{\"end\":104003,\"start\":103992},{\"end\":104560,\"start\":104547},{\"end\":104793,\"start\":104784},{\"end\":104803,\"start\":104793},{\"end\":104817,\"start\":104803},{\"end\":104830,\"start\":104817},{\"end\":104840,\"start\":104830},{\"end\":105231,\"start\":105219},{\"end\":105584,\"start\":105575},{\"end\":105601,\"start\":105584},{\"end\":105614,\"start\":105601},{\"end\":105627,\"start\":105614},{\"end\":105637,\"start\":105627},{\"end\":106003,\"start\":105991},{\"end\":106016,\"start\":106003},{\"end\":106030,\"start\":106016},{\"end\":106337,\"start\":106327},{\"end\":106675,\"start\":106666},{\"end\":106684,\"start\":106675},{\"end\":106695,\"start\":106684},{\"end\":107030,\"start\":107017},{\"end\":107039,\"start\":107030},{\"end\":107399,\"start\":107389},{\"end\":107412,\"start\":107399},{\"end\":107810,\"start\":107800},{\"end\":107823,\"start\":107810},{\"end\":108161,\"start\":108154},{\"end\":108171,\"start\":108161},{\"end\":108186,\"start\":108171},{\"end\":108196,\"start\":108186},{\"end\":108207,\"start\":108196},{\"end\":108682,\"start\":108673},{\"end\":108924,\"start\":108918},{\"end\":108930,\"start\":108924},{\"end\":109252,\"start\":109241},{\"end\":109262,\"start\":109252},{\"end\":109274,\"start\":109262},{\"end\":109283,\"start\":109274},{\"end\":109768,\"start\":109755},{\"end\":110117,\"start\":110104},{\"end\":110129,\"start\":110117},{\"end\":110574,\"start\":110565},{\"end\":110580,\"start\":110574},{\"end\":111044,\"start\":111028},{\"end\":111055,\"start\":111044},{\"end\":111266,\"start\":111254},{\"end\":111277,\"start\":111266},{\"end\":111419,\"start\":111409},{\"end\":111428,\"start\":111419},{\"end\":111438,\"start\":111428},{\"end\":111861,\"start\":111849},{\"end\":111875,\"start\":111861},{\"end\":111884,\"start\":111875},{\"end\":111895,\"start\":111884},{\"end\":112418,\"start\":112407},{\"end\":112835,\"start\":112829},{\"end\":113093,\"start\":113083},{\"end\":113106,\"start\":113093},{\"end\":113115,\"start\":113106},{\"end\":113130,\"start\":113115},{\"end\":113453,\"start\":113444},{\"end\":113463,\"start\":113453},{\"end\":113474,\"start\":113463},{\"end\":113719,\"start\":113710},{\"end\":113730,\"start\":113719}]", "bib_venue": "[{\"end\":92527,\"start\":92502},{\"end\":92822,\"start\":92806},{\"end\":93172,\"start\":93133},{\"end\":93648,\"start\":93533},{\"end\":94181,\"start\":94109},{\"end\":94592,\"start\":94569},{\"end\":95008,\"start\":94861},{\"end\":95464,\"start\":95433},{\"end\":95677,\"start\":95632},{\"end\":96109,\"start\":96070},{\"end\":96520,\"start\":96492},{\"end\":96903,\"start\":96873},{\"end\":97265,\"start\":97240},{\"end\":97709,\"start\":97589},{\"end\":98167,\"start\":98109},{\"end\":98546,\"start\":98503},{\"end\":98811,\"start\":98767},{\"end\":99098,\"start\":99011},{\"end\":99450,\"start\":99433},{\"end\":99770,\"start\":99688},{\"end\":100307,\"start\":100244},{\"end\":100861,\"start\":100769},{\"end\":101220,\"start\":101176},{\"end\":101560,\"start\":101497},{\"end\":102063,\"start\":102000},{\"end\":102608,\"start\":102540},{\"end\":103001,\"start\":102980},{\"end\":103326,\"start\":103290},{\"end\":103711,\"start\":103697},{\"end\":104127,\"start\":104031},{\"end\":104602,\"start\":104578},{\"end\":104912,\"start\":104856},{\"end\":105283,\"start\":105260},{\"end\":105675,\"start\":105664},{\"end\":106086,\"start\":106058},{\"end\":106423,\"start\":106368},{\"end\":106738,\"start\":106721},{\"end\":107114,\"start\":107097},{\"end\":107478,\"start\":107438},{\"end\":107886,\"start\":107849},{\"end\":108301,\"start\":108227},{\"end\":108671,\"start\":108621},{\"end\":109023,\"start\":108984},{\"end\":109326,\"start\":109309},{\"end\":109569,\"start\":109506},{\"end\":109873,\"start\":109790},{\"end\":110252,\"start\":110183},{\"end\":110664,\"start\":110601},{\"end\":111026,\"start\":110970},{\"end\":111252,\"start\":111205},{\"end\":111557,\"start\":111479},{\"end\":111991,\"start\":111895},{\"end\":112513,\"start\":112438},{\"end\":112827,\"start\":112784},{\"end\":113173,\"start\":113156},{\"end\":113527,\"start\":113494},{\"end\":113838,\"start\":113771},{\"end\":93750,\"start\":93650},{\"end\":97816,\"start\":97711},{\"end\":100357,\"start\":100309},{\"end\":100940,\"start\":100863},{\"end\":101610,\"start\":101562},{\"end\":102113,\"start\":102065},{\"end\":102663,\"start\":102610},{\"end\":104210,\"start\":104129},{\"end\":108362,\"start\":108303},{\"end\":110714,\"start\":110666},{\"end\":112074,\"start\":111993},{\"end\":112575,\"start\":112515}]"}}}, "year": 2023, "month": 12, "day": 17}