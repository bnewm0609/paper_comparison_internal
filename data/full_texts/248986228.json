{"id": 248986228, "updated": "2023-12-01 14:56:15.574", "metadata": {"title": "Adversarial Sticker: A Stealthy Attack Method in the Physical World", "authors": "[{\"first\":\"Xingxing\",\"last\":\"Wei\",\"middle\":[]},{\"first\":\"Ying\",\"last\":\"Guo\",\"middle\":[]},{\"first\":\"Jie\",\"last\":\"Yu\",\"middle\":[]}]", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "publication_date": {"year": 2023, "month": 3, "day": 1}, "abstract": "To assess the vulnerability of deep learning in the physical world, recent works introduce adversarial patches and apply them on different tasks. In this paper, we propose another kind of adversarial patch: the Meaningful Adversarial Sticker, a physically feasible and stealthy attack method by using real stickers existing in our life. Unlike the previous adversarial patches by designing perturbations, our method manipulates the sticker's pasting position and rotation angle on the objects to perform physical attacks. Because the position and rotation angle are less affected by the printing loss and color distortion, adversarial stickers can keep good attacking performance in the physical world. Besides, to make adversarial stickers more practical in real scenes, we conduct attacks in the black-box setting with the limited information rather than the white-box setting with all the details of threat models. To effectively solve for the sticker's parameters, we design the Region based Heuristic Differential Evolution Algorithm, which utilizes the new-found regional aggregation of effective solutions and the adaptive adjustment strategy of the evaluation criteria. Our method is comprehensively verified in the face recognition and then extended to the image retrieval and traffic sign recognition. Extensive experiments show the proposed method is effective and efficient in complex physical conditions and has a good generalization for different tasks.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "35604977", "pubmedcentral": null, "dblp": "journals/pami/WeiGY23", "doi": "10.1109/tpami.2022.3176760"}}, "content": {"source": {"pdf_hash": "5c7684e5f1c08a07448196cc69c27d2df0195ced", "pdf_src": "IEEE", "pdf_uri": "[\"https://export.arxiv.org/pdf/2104.06728v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2104.06728", "status": "GREEN"}}, "grobid": {"id": "9cae60e6f68c5ed225b9ce604580cb39ec56a4bd", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/5c7684e5f1c08a07448196cc69c27d2df0195ced.txt", "contents": "\nAdversarial Sticker: A Stealthy Attack Method in the Physical World\n\n\nMember, IEEEXingxing Wei \nYing Guo \nJie Yu \nAdversarial Sticker: A Stealthy Attack Method in the Physical World\n10.1109/TPAMI.2022.3176760Index Terms-Deep learning modelsadversarial examplesadversarial patchrobustnessphysical world\nTo assess the vulnerability of deep learning in the physical world, recent works introduce adversarial patches and apply them on different tasks. In this paper, we propose another kind of adversarial patch: the Meaningful Adversarial Sticker, a physically feasible and stealthy attack method by using real stickers existing in our life. Unlike the previous adversarial patches by designing perturbations, our method manipulates the sticker's pasting position and rotation angle on the objects to perform physical attacks. Because the position and rotation angle are less affected by the printing loss and color distortion, adversarial stickers can keep good attacking performance in the physical world. Besides, to make adversarial stickers more practical in real scenes, we conduct attacks in the black-box setting with the limited information rather than the white-box setting with all the details of threat models. To effectively solve for the sticker's parameters, we design the Region based Heuristic Differential Evolution Algorithm, which utilizes the new-found regional aggregation of effective solutions and the adaptive adjustment strategy of the evaluation criteria. Our method is comprehensively verified in the face recognition and then extended to the image retrieval and traffic sign recognition. Extensive experiments show the proposed method is effective and efficient in complex physical conditions and has a good generalization for different tasks.\n\n\u00c7\n\n\nINTRODUCTION\n\nW ITH the development of Deep Neural Networks (DNNs), DNNs based vision systems have shown the excellent performance in different tasks [1], [2], [3]. However, DNNs are vulnerable to adversarial examples [4], [5]. By adding a small malicious perturbation to the input example, the system can make a wrong identity judgement, resulting in serious consequences.\n\nIn real scenarios, however, DNNs based vision systems work by directly scanning objects. So attackers can only change the object's appearance in the physical world to provide malicious inputs to the camera, which is more challenging and needs to tackle complex physical conditions such as lighting, distance, and posture changes. To make adversarial examples available in the physical world, recent works introduce the adversarial patch [6]. They do not restrict the perturbations' magnitude, and generate adversarial perturbations in a fixed region. Experiments show the patch can be placed on the objects, and causes the classifier to output a targeted class. Up to now, researchers have applied adversarial patches on different tasks, such as face recognition [7], [8], [9], [10], object detection [11], [12], pedestrian detection [13], [14], etc.\n\nDespite the success of adversarial patches, they have two limitations. The first one is that the patch's perturbation pattern will face a complex transfer process from the digital domain to the physical world. Specifically, Expectation Over Transformation (EOT) [15], Total Variation (TV) loss, and non-printability score (NPS) loss [9], [10] are used to ensure the attacking performance of real-world adversarial examples. EOT considers a set of transformations of objects (postures, distance changes, etc.) when generating adversarial perturbations. The TV loss is designed to make the perturbations more smooth, and the NPS loss is to deal with the difference between digital pixel values and the actual printed appearance. On the one hand, these operations lead to high computation costs, for example, EOT needs to exhaust different transformations. On the other hand, the perturbations' values will inevitably become distorted due to the limitation of printing devices despite the usage of the TV and NPS losses. Last but not least, the current physical perturbations are meaningless and irregular, not natural enough in the appearance, and prone to arouse the human's suspicion. These disadvantages motivate us to explore new forms of adversarial patches to address the above issues. The second one is that most previous adversarial patches are based on the white-box attack setting [6], [8], [9], [13], [14]. It means that they require detailed structures and parameters of the targeted models. However, the above information usually cannot be easily obtained especially in the actual applications. Instead, some commercial online vision APIs (e.g., Face++ and Microsoft cloud services) usually return the predicted identities and scores for the uploaded images. By utilizing this limited information, exploring the querybased black-box attack to construct adversarial patches is a more reasonable solution in most real scenarios than the previous white-box attacks.\n\nConsidering the above two points, this paper aims to solve the following problem: under the black-box setting with some limited information, how to utilize the existing material in our life to easily construct a stealthy adversarial patch which is robust to the complex physical changes.\n\nIn this paper, we propose to construct a novel form of adversarial patches called the Meaningful Adversarial Sticker via a query-based black-box attack. Instead of generating an adversarial perturbation pattern like the traditional adversarial patch, we use the real meaningful stickers existing in our life and manipulate the stickers' pasting positions and rotation angles on the objects to perform the physical attacks. Compared with the performance due to perturbations, the attack performance caused by stickers' positions and rotation angles is easier to maintain when attacks are transferred from the digital domain to the physical world (see Section 3.5), and the loss functions mentioned before (EOT, TV and NPS losses, etc.) are not necessary. Furthermore, sticking colorful stickers on objects can be usually seen in our life (shown in Fig. 1), so this form of attacks looks natural and stealthy, and is not easy to arouse the human's suspicion. In addition, considering the real scenario where only the limited information can be obtained, we design a query-based method to efficiently search for the available parameters. Thus the physical black-box attacks are achieved.\n\nTechnically, to search for the appropriate attack parameters, we formalize the process into an optimization problem and solve it using an evolution method which follows the principle of \"survival of the fittest\" in the iterative evolution process. Considering the query limit in the actual scenario, we design a new Region based Heuristic Differential Evolution (RHDE) algorithm to improve the efficiency. We find that the stickers' locations of successful attacks show a regional aggregation. Based on this, RHDE combines the inbreeding and random crossover to generate the offspring, and adjusts the evaluation criteria adaptively to better guide the search direction. We also design a sticker deformation calculation method to make the sticker's shape fit the curvature changes of different positions on the human face realistically. The proposed method is first verified on the face recognition, and then extended to the image retrieval and traffic sign recognition tasks. The code is available at https://github.com/ jinyugy21/Adv-Stickers_RHDE.\n\nIn summary, this paper has the following contributions:\n\nWe propose the Meaningful Adversarial Sticker, a novel adversarial patch method with the good practical applicability. We manipulate the fusing operation and parameters of real stickers on the objects instead of designing perturbation patterns like most of the existing works. Experiments show this manner has a good transferability from the digital domain to the physical world. We specialize in black-box physical attacks on DNNs based vision systems with some limited information, and further design a Region based Heuristic Differential Evolution (RHDE) algorithm to improve the query efficiency. We find that the stickers' locations of successful attacks show a regional aggregation. RHDE makes full use of this phenomenon and can adjust the evolution direction adaptively according to the state of the population. We verify the proposed method on three tasks: face recognition, image retrieval, and traffic sign recognition. For the face recognition, experimental results in the physical environment show that it can naturally maintain attack effects under different physical conditions and at most 98.46% of the video frames can be successfully attacked while continuously changing the face postures. For the image retrieval and traffic sign recognition, our method also shows a good generalization. The remainder of this paper is organized as follows. Section 2 briefly reviews the related work. We introduce the details of the proposed meaningful adversarial stickers against the face recognition task in Section 3. Section 4 presents extensions to the image retrieval and traffic sign recognition tasks. Sections 5 and 6 show a series of experimental results. Finally, we conclude the whole paper in Section 7.\n\n\nRELATED WORK\n\nIn this section, we review the existing works of adversarial examples in the digital and physical world, respectively.\n\n\nDigital Attacks\n\nBox-constrained L-BFGS [4], C&W [16], Deepfool [17], etc. carry out attacks via optimization mechanisms. The classical attack method FGSM [5] is a one-step approach based on the gradient information of DNNs. PGD [18] is a multi-step iterative method using projected gradient descent on the negative loss function to generate adversarial examples. Instead of generating noises on the whole image, [19] explores the case where the noise is allowed to be visible but confined to a small, localized patch of the image, without covering any of the main object(s) in the image. The above methods are conducted in the white-box setting, where the attackers have access to the structures and weights of the threat models.\n\nBlack-box attacks do not require detailed parameters of models. For transfer-based methods, the adversarial examples generated for one model can be transferred to another model to achieve successful attacks [20], [21], [22], [23], [24]. For score-based methods, the probabilities predicted by target models are known and methods such as gradient estimation [25] and random search [26], [27] are often used in this setting. Besides, decision-based methods are suitable for more restrictive scenarios where only the final model decisions are known [28], [29]. Dong et al. [7] conduct digital attacks on face recognition systems in this setting and model the local geometry of solving directions to improve the efficiency. Attacks aiming to get a different class from the true label are called un-targeted attacks (or dodging in the face recognition), while those targeting a specific class are called targeted attacks (or impersonation in the face recognition). In our case, we conduct black-box attacks and focus on more practical physical attacks.\n\n\nPhysical Attacks\n\nPhysical attacks play an increasingly important role due to their great application values. To make adversarial examples available in the physical world, many works have been proposed. Specifically, Kurakin et al. [30] verify the feasibility of physical attacks by the fact that the perturbed images being captured by the camera still have attack effects. In [15], the EOT algorithm makes adversarial patches robust to multiple physical transformations.\n\nAdversarial patch [6] is one of the main forms of physical attacks, and has been successfully applied in many computer vision tasks, such as automatic driving, face recognition, object detection. We give the detailed descriptions as follows:\n\nFor face recognition cases, the initial attack is in the form of 2D-printed face photos or 3D facial masks [31]. Later, some researchers generate eyeglass frames with perturbations attached to fool the face recognition systems [8], [10]. Zhou et al. [32] carry out attacks by a cap mounting LED device which illuminates the face using infrared perturbations. Adv-Hat [9] achieves attacks by sticking rectangular stickers with adversarial perturbations to the hat. Adversarial light projection attacks [33] project transformationinvariant adversarial patterns onto people's faces. Some other methods [34], [35] paste black and white patches with an attacking effect onto the face or the wearable accessory.\n\nFor automatic driving tasks, Eykholt et al. [36] use Robust Physical Perturbations to generate the adversarial graffiti which is robust under physical conditions. [37] proposes the physical translucent patch, placed on the camera lens, which results in the failure to detect the stop sign while correctly identifying the other objects. The authors in [38] craft and camouflage physical-world adversarial examples into natural styles that appear legitimate to human observers to construct adversarial traffic signs. Several relevant studies considering the safety of the autonomous driving can also be found in [39], [40].\n\nFor object detection tasks, [41] extends physical attacks to more challenging object detection models and proposes the \"Disappearance Attack\". The work in [13] uses the adversarial patch to hide a person from a person detector. Adversarial T-shirts [14] can apply the deformable adversarial patch on the T-shirts to fool the person detector. Wu et al. [42] present a detailed study of physical world attacks using printed posters and wearable clothes, and quantify their performances with different metrics.\n\nIn our method, we propose another kind of adversarial patch, which uses the real stickers that actually exist in our life. The proposed adversarial stickers conduct black-box attacks by changing the real stickers' pasting parameters instead of the patches' perturbations and thus do not need to be generated or printed, which is physically feasible and stealthy.\n\n\nMETHODOLOGY\n\nIn this section, we choose the face recognition as the target task, and first introduce the regional aggregation of effective parameters, then detail the proposed Region based Differential Evolution algorithm, and finally introduce the calculation method of the sticker deformation in the process of parameter solving.\n\n\nProblem Formulation\n\nIn the face recognition task, given a clean face image x x, the goal of the adversarial attack is to make the face recognition model predict a wrong identity of the perturbed face image x x adv . Formally, the perturbed face with the adversarial patch can be formulated as Eq. (1), where is the Hadamard product andx x is the adversarial perturbations. A is a mask matrix to constrain the shape and pasting position of the patch, where the value of the pasting area is 1.\nx x adv \u00bc \u00f01 \u00c0 A\u00de x x \u00fe A x x:(1)\nThe previous methods mainly optimizex x with a pre-fixed A. In contrast, our method does not generatex x, but chooses the existing sticker in our life asx x, which is shown in Fig. 2. When the sticker is chosen, the shape of A is fixed. In the following section, we will show how to obtain the optimal pasting position of A in the face to perform adversarial attacks.\n\n\nRegional Aggregation\n\nBefore introducing the detailed method, we first explore the influence of pasting positions for the face recognition task. In such scenes, liveness detection, which mainly relies on motions (e.g., blinking, mouth opening), depth or texture features of the face [43], is often used to confirm the real physiological characteristics of the object and resists attacks such as photos, masks, and screen re-shoots. To ensure a natural look and not interfere with the liveness detection, pasting positions of stickers cannot cover the facial features. Thus, a face mask matrix M F 2 R n\u00c2m which contains ones in valid regions (e.g., cheek and forehead), and zeros in invalid regions (e.g., eyes and mouth) is used to constrain the candidate pasting areas of stickers. We randomly select 1,000 images from LFW and CelebA datasets respectively, and use the first sticker in Fig. 2, then traverse every valid pasting position by an exhaustive method to query the FaceNet [44] model. It is found that the positions achieving successful attacks are not discretely distributed, but show an aggregation phenomenon. Among all the faces that can be successfully attacked on the two datasets, the faces with clustered positions account for 96.5% and 97.8%, respectively, of which 58.7% and 61.2% are clustered in only one area (like Figs. 3a and 3b), and 37.8% and 36.6% have multiple clustered areas (like Fig. 3c). We also analyze the probability variations of ground-truth labelst and predicted wrong labels t after attacks when we take the point with the highest value of t as the center o \u00c3 and randomly choose one direction to spread outward. In the small area around o \u00c3 , the probability of t decreases with the increase of distance to o \u00c3 , while the trend for the probability oft is the opposite. Fig. 3 shows several examples.\n\nThis phenomenon inspires us to search for the optimal position with a heuristic manner, i.e., continuing to search for the next position around the previously available position. In this way, we can improve the efficiency of searching attack parameters. Based on this idea, a region based differential evolution algorithm is designed, which is shown in Section 3.3.\n\n\nRegion Based Heuristic Differential Evolution\n\nLet f\u00f0\u00c1\u00de denote the face recognition model and f\u00f0x x; t\u00de denote the probability that the model predicts a face image x x as label t. u u \u00bc \u00f0u 1 ; . . . ; u i ; . . . ; u d \u00de is the set of attack parameters (including pasting position, rotation angle, etc.). Given the ground-truth labelt for x x and a real sticker image s, the goal of a dodging (un-targeted) attack is to find the optimal attack parameters u u \u00c3 to make the probability corresponding tot as small as possible, so that a person different fromt is regarded as the top-1 identity. So the objective function of the dodging attack can be formalized as min u u L dodging \u00f0u u\u00de \u00bc f\u00f0g\u00f0x x; s; u u\u00de;t\u00de;\n\n(\n\nwhere g\u00f0x x; s; u u\u00de represents the generated new face image after transforming sticker s according to u u and combining the obtained sticker with the face. Details of sticker transformation are shown in Section 3.4. For the impersonation (targeted) attack, given a target identity t \u00c3 , the objective function is defined as follows:\nmin u u L impersonation \u00f0u u\u00de \u00bc 1 \u00c0 f g\u00f0x x; s; u u\u00de; t \u00c3 \u00f0 \u00de :(3)\nSince we have no access to the specific parameters of f\u00f0\u00c1\u00de, we carry out score-based black-box attacks by querying the model to obtain predicted labels and probabilities. Although gradient estimation [25] can solve the optimization problem along the gradient descent direction, in our case, the ranges of position parameters are discontinuous due to the invalid positions. Accordingly, the objective functions are discontinuous and their smoothness with respect to the parameters is also unknown, so it is not suitable to use the gradient-based method to optimize Eqs. (2) and (3). Therefore, we use an evolutionary method, starting from a group of randomly generated solutions in the search space and using the crossover and mutation to generate the offspring, making the fittest survive according to the evaluation criteria, and finally find the appropriate solution in the iterative evolution process.\n\n\nAlgorithm 1. Region Based Heuristic Differential Evolution Algorithm\n\nInput: Network f\u00f0\u00c1\u00de, face image x x and labelt, the attack objective function L\u00f0u u\u00de, the number of parameters d, value range \u00f0u L ; u U \u00de, population size P , maximum number of iterations T , hyperparameter l, r, a, r, d Output: u u \u00c3 1: Initialize X X\u00f00\u00de randomly in \u00bdu L i ; u U i \u00f01 i d\u00de, J \u00f0u\u00de = L\u00f0u\u00de, flag = 0, stop = T ; 2: for k = 0 to T \u00c01 do 3: Sort X X\u00f0k\u00de in ascending order according to J \u00f0u\u00de; 4: if X X 0 \u00f0k\u00de makes the attack successful then 5: stop = k; break; 6: end if 7: Generate candidate population C C\u00f0k\u00de if i 2 \u00bd1; m\u00c3P C C i \u00f0k\u00de according to Eq. (6) if i 2 \u00bdm\u00c3P \u00fe1; P C C i \u00f0k\u00de according to Eq. (5) 8: if \u00f0t 1 \u00f0C g \u00c3 \u00f0k\u00de\u00de \u00bc\u00bct and flag \u00bc\u00bc 0\u00de then 9:\n\nbound according to Eq. (7) 10:\n\nif bound d then 11:\n\nflag \u00bc 1; t t \u00bc t 2 ; Update J \u00f0u\u00de according to Eq. (8) 12:\n\nend if 13: end if 14: X X i \u00f0k \u00fe 1\u00de the better one between X X i \u00f0k\u00de and C C i \u00f0k\u00de 15: end for 16: Sort X X\u00f0stop\u00de in ascending order according to J \u00f0u\u00de; 17: return X X 0 \u00f0stop\u00de However, using traditional evolutionary algorithms directly is not efficient enough because the characteristics of face recognition scenes are not fully considered. In this paper, we propose a novel Region based Heuristic Differential Evolution (RHDE) algorithm to accelerate the search for solutions. We design a new strategy for the offspring's generation, which utilizes the regional aggregation of positions with attacking effectiveness. To better guide the search direction, we also use an adaptive evaluation criteria adjustment method to adjust the attack target in time according to the current state of the solutions. Taking the dodging attack for example, the overall RHDE algorithm is outlined in Algorithm 1. Details are shown in the following.\n\n\nAttack Setting\n\nIn the evolutionary approach, a population represents a set of multiple solution vectors and each individual in the population represents a solution vector. Given the population size P and the number of attack parameters to be solved d, the kth generation population X X\u00f0k\u00de is represented as Fig. 3. Examples reflecting the regional aggregation of positions for successful attacks. The top row shows the distribution of these positions, and the bottom row shows the probabilities of the ground-truth labelt and predicted wrong label t versus the distance to the center.\nX X\u00f0k\u00de :\u00bc X X i \u00f0k\u00deju L j X X ij \u00f0k\u00de u U j ; 1 i P; 1 j d n o ;(4)\nwhere X X ij \u00f0k\u00de is the jth parameter value of the ith individual in the kth population. \u00f0u L j ; u U j \u00de is the change range of the jth parameter. Specifically, each individual in the population represents a tuple containing the pasting position, rotation angle, etc. In each iteration, a new offspring is formed through the crossover and mutation between individuals in the parent population. According to the evaluation criteria, better individuals are selected from the offspring and the parent to create the next generation (new solutions).\n\nIn Algorithm 1, we first randomly initialize the population X X\u00f00\u00de on the premise of ensuring that the parameters of each individual are within the corresponding value range (Step 1). Then we generate candidate populations C C\u00f0k\u00de in an iterative evolution process (Step 7). Based on the evaluation criterion J \u00f0u u\u00de, better individuals between C C\u00f0k\u00de and X X\u00f0k\u00de are chosen to form the next generation X X\u00f0k\u00fe1\u00de. The process stops when the attack using the optimal individual in the current population as the attack parameters is successful (Step 4) or when the maximum number of iterations T is reached. The generation strategy of C C\u00f0k\u00de and the establishment of J \u00f0u u\u00de are detailed in Sections 3.3.2 and 3.3.3.\n\n\nStrategies for the Offspring's Generation\n\nIn our proposed algorithm, we use crossover between random individuals and inbreeding of superior individuals to generate candidate populations C C\u00f0k\u00de. The first method follows the traditional evolutionary algorithm, and can be formalized as follows:\nC C i \u00f0k\u00de \u00bc clip X X g \u00c3 \u00f0k\u00de \u00fe a X X g 1 \u00f0k\u00de \u00c0 X X g 2 \u00f0k\u00de \u00c0 \u00c1 \u00c0 \u00c1 ;(5)\nwhere C C i \u00f0k\u00de is the ith individual in the kth candidate population. g 1 ; g 2 are random numbers. g \u00c3 denotes the index number of the best individual in X X\u00f0k\u00de and g \u00c3 6 \u00bc g 1 \n6 \u00bc g 2 .\na is a scale factor and clip\u00f0\u00c1\u00de is a clipping operation to keep individuals within the range described in Eq. (4). Because the solutions with adversarial effects tend to cluster in a certain region in the parameter space, we propose an inbreeding method, which finds solutions in the regions near the superior solutions of each generation to speed up the solving process. Specifically, the superior individuals in the current population are selected first (by a ratio of m). f fhX X i \u00f0k\u00de; j; li is defined as an operation, which takes the position in individual X X i \u00f0k\u00de as the center, takes out the position parameter at the step size l in the jth direction around the center, and forms a new individual together with the rest of the parameters in X X i \u00f0k\u00de. f f is applied in r directions around the superior individuals (i.e., 1 j r), and the individuals that minimize the loss function (most satisfied with the objective function) around each superior individual are selected as the offspring. The formula is defined as follows:\nC C i \u00f0k\u00de \u00bc f f X X i \u00f0k\u00de; arg min j L f f X X i \u00f0k\u00de; j; l h i \u00f0 \u00de ; l :(6)\nCombining these two methods, we take advantage of the regional aggregation of effective solutions by the inbreeding on the one hand, and generate more diverse solutions by a random method on the other hand, avoiding the local optimum that the inbreeding may fall into.\n\n\nAdaptive Adjustment of the Evaluation Criteria\n\nThe solving process can be regarded as an explorationexploitation process. For the evaluation criterion J \u00f0u u\u00de (the smaller the better), which evaluates the unfitness of individuals in a population, it is generally equal to the value of the objective function L\u00f0u u\u00de (Step 1). For the dodging attack, we design an adaptive strategy to adjust the evaluation criterion (Step 8-13). In the initial stage, there is no selected target identity, so we let J \u00f0u u\u00de follow L\u00f0u u\u00de to reduce the predicted probability of the ground-truth labelt, so as to explore as many solutions as possible in the parameter space. When the population evolves to a good state (i.e., the difference between the predicted probability of top-1 class t 1 and top-2 class t 2 corresponding to the optimal individual C C g \u00c3 \u00f0k\u00de is less than the threshold value d), we start to exploit the information of top-2 class t 2 and transform the solving direction to improving the predicted probability of t 2 . After abbreviating f\u00f0g\u00f0x x; s; u u\u00de; t\u00de to f t \u00f0u u\u00de, the indicator to determine whether the population has reached a good state is formulated as\nbound \u00bc f t 1 C C g \u00c3 \u00f0k\u00de \u00c0 \u00c1 \u00c0 f t 2 C C g \u00c3 \u00f0k\u00de \u00c0 \u00c1 :(7)\nSelect t 2 as the prompted object t t, then J \u00f0u u\u00de is updated to\nJ \u00f0u u\u00de \u00bcft\u00f0u u\u00de\u00c0f t t \u00f0u u\u00de \u00fe r 1\u00c0f t t \u00f0u u\u00de=ft\u00f0u u\u00de \u00c0 \u00c1 ;(8)\nwhere r is a scale factor. This criterion reduces the probability difference between the promoted class and the groundtruth class, increases the predicted probability of the promoted object, and speeds up the solution of attack parameters. The candidate population C C\u00f0k\u00de and the current population X X\u00f0k\u00de are judged by the above J \u00f0u u\u00de, and the better individuals are selected to form the next generation X X\u00f0k \u00fe 1\u00de (Step 14). For the impersonation attack, its solving objective is clear, that is, to raise the probability of the specified target identity. Therefore, the criterion is not adjusted (i.e., omit\n\nStep [8][9][10][11][12][13], and the solution is always along the direction of maximizing the probability of the target identity.\n\n\nThe Generation of Adversarial Stickers\n\nAfter specifying the attack parameters, we deform the sticker accordingly to simulate the effect of the sticker on the face more realistically so that its shape fits the curvature of the face at the current position. We first use the 3DMM method [45] to generate a 3D model of a given 2D face image, and the 3D coordinates corresponding to the face position are obtained. Then we use the information of the X-Z plane where the highest point \u00f0x 0 ; y 0 ; z 0 \u00de of the pasting area is located to carry out the bending transformation, and then use the information of the Y-Z plane where \u00f0x 0 ; y 0 ; z 0 \u00de is located to rotate the sticker in 3D space. The complete process of the shape transformation is shown in Fig. 4. For the bending transformation, the Y -axis coordinates of the sticker remain unchanged, we bend the sticker on the X-Z plane, and finally get the sticker A A of size h \u00c2 w n . The projection of points on the X-Z plane can be approximated as a parabola z \u00bc a\u00f0x \u00c0 c\u00de 2 \u00fe b, where c \u00bc x 0 , a \u00bc\u00c0Dh=\u00f0Ds\u00de 2 , b \u00bc \u00c0a\u00f0w n \u00c0c\u00de 2 , Ds is an arbitrary length and Dh is the length on the Z-axis corresponding to Ds. The annotations of variables above and the visual effects are shown in Fig. 5. To ensure that the arc length of the bent sticker A A is equal to the original width w, the width w n of A A satisfies Z w n 0 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 1 \u00fe 4a 2 \u00f0x \u00c0 c\u00de 2 q dx \u00bc w:\n\nBased on the parabola formula, we can get the matrix M A 2 R 3\u00c2\u00f0h\u00c3w n \u00de containing the 3D coordinates of all pixels on the sticker A A.\n\nThe bilinear interpolation and backward mapping are used to obtain the pixel value of each point in A A. Let v p \u00f0i; j\u00de denote the pixel value at the position \u00f0i; j\u00de in the image p, then the pixel value on the sticker A A is calculated as follows v A \u00f0i; j\u00de \u00bc g T T i;\nZ j 0 ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 1 \u00fe 4a 2 \u00f0x \u00c0 c\u00de 2 q dx ;(10)\nwhere i 2 \u00bd0; h\u00de, j 2 \u00bd0; w n \u00de, g p \u00f0i; j\u00de is used to calculate the pixel value corresponding to the position \u00f0i; j\u00de on the image p after the interpolation. Specifically,\ng p \u00f0u; v\u00de \u00bc g p \u00f0buc \u00fe Du; bvc \u00fe Dv \u00c1 \u00bc \u00f01 \u00c0 Du\u00de\u00f01 \u00c0 Dv\u00de \u00c1 v p \u00f0buc; bvc\u00de \u00fe Dv\u00f01 \u00c0 Du\u00de \u00c1 v p \u00f0buc; bvc \u00fe 1\u00de \u00fe Du\u00f01 \u00c0 Dv\u00de \u00c1 v p \u00f0buc \u00fe 1; bvc\u00de \u00fe DuDv \u00c1 v p \u00f0buc \u00fe 1; bvc \u00fe 1 \u00c1 ;(11)\nwhere bxc returns the largest integer less than or equal to x. For the rotation transformation, the information on the Y-Z plane reflects the rotation angle u of the sticker, and u of most of the sticker area is approximated to that of the entire sticker. Dy denotes an arbitrary length and Dz is the corresponding length on the Z-axis, then u is calculated as follows:\nu \u00bc sign h \u00c0 2y 0 \u00f0 \u00de\u00c1arctan\u00f0Dz=Dy\u00de;(12)\nwhere u, Dy, Dz, etc. are marked in Fig. 5. After the angle is calculated, the stickers after bending transformation are rotated in the 3-D space. Specifically, let M B denote the matrix formed by the coordinates of each point after rotation, then\nM B \u00bc 1 0 0 0 cos u \u00c0 sin u 0 sin u cos u 2 6 4 3 7 5MA:(13)\nAccording to the information of X and Y coordinates in M B , the 2-D pattern of the sticker after the complete deformation can be obtained by using the bilinear interpolation formulated in Eq. (11).\n\n\nImplementation in the Physical World\n\nBased on the above method, the attack parameters corresponding to the subjects' faces are solved in the digital environment. When conducting the physical attacks, we only need to paste the real stickers on the subjects' faces according to the calculated parameters. In this process, there are several points worth noting. (1) Our method does not involve the printing and making process, so there is no need to use the NPS and TV losses with high calculation costs. (2) We do not use the EOT in the solving process to guarantee the performance under different physical conditions but experiments in Section 5.2.4 demonstrate that our method is robust under different physical conditions, such as changing face postures, which shows the good adaptability of our method. (3) Even if there is a slight deviation between the calculated solution and the actual pasting position and angle, the follow-up experiments show that owing to the regional aggregation, it can still achieve good attacking results, verifying that the attack effectiveness caused by positions and rotation angles tends to keep consistent when the attacks are transferred to the physical environment.\n\n\nEXTENSIONS TO OTHER APPLICATIONS\n\nBesides the face recognition, our method can be easily extended to other applications. In this section, we introduce two applications: image retrieval and traffic sign recognition.  \n\n\nImage Retrieval\n\nImage Retrieval (IR) system returns a list of similar images sorted by the similarity with the query image. Compared with adversarial attacks on the face recognition task, which constructs adversarial patches according to the returned labels and confidence scores, attacks for image retrieval are more challenging due to the similarity scores between query images and candidate images usually cannot be obtained in the black-box setting (such as Bing Image Search API, etc). To address this issue, we use the Relevance-based score proposed in [46] as the similarity score, and then use the method in Section 3 to solve for the available position and rotation angle of stickers.\n\nSpecifically, given a query image x x and a dataset G, the image retrieval system f will return top-k images.\nRList k \u00f0x x; f\u00de \u00bc x x 1 ; . . .; x x i ; . . .; x x k jx x i 2 G f g :(14)\nThe returned images are sorted according to the similarity with the query image x x, where k is the number of images in the list. For most IR systems, because they usually return finite images, thus k ( jGj.\n\nTo perform a successful attack, the objective function can be formulated as RList k \u00f0x x; f\u00de \\ RList k \u00f0x x; f\u00de \u00bc ;; (15) wherex x is the adversarial query image generated using the adversarial sticker described in the previous section. To solve the above equation, we use the relevance-based score [46] to measure the attack effect L\u00f0x x; y y\u00de \u00bc\nX k i\u00bc1 v i ' i ;(16)\nwherex x \u00bc g\u00f0x x; s; u u\u00de in Eq. (2), y y \u00bc RList k \u00f0x x; f\u00de, and v i represents the \"prior sampling probability\" [46] and is given as\nv i \u00bc 2 r i \u00c0 1 P k i\u00bc1 \u00f02 r i \u00c0 1\u00de ;(17)\nwhere r i \u00bc k \u00c0 i, ' i denotes \"attack failure probability\" [46] and is defined as follows:\n' i \u00bc v i ; x x i 2 RList k \u00f0x x; f\u00de: 0; x x i = 2 RList k \u00f0x x; f\u00de: &(18)\nWith the help of this defined relevance-based score, we can use L\u00f0x x; y y\u00de as L\u00f0u u\u00de in Algorithm 1, making L\u00f0x x; y y\u00de as small as possible, to perform adversarial attacks. If L\u00f0x x; y y\u00de \u00bc 0, Eq. (15) is achieved, and the attack is successful. However, we find it difficult to attack successfully when k is small, and the attack effect is not obvious, which can be found in Fig. 6.\n\nThe main reason for the above phenomenon is that the approach we evaluate the attack effect can only confirm the empty set between the top-k retrieved results before and after attacks. As a large number of similar images appear in the dataset, we will still get the secondary k similar images to the query image. Therefore, the relevance-based score with a small k is not sensitive enough to attacks, which could be not good for guiding to generate adversarial examples.\n\nBased on the above analysis, we decide to expand the retrieved images list of the query image before the attack, so that our list contains enough images similar to the query image. Because k is decided by the IR system, and cannot be changed by us. Instead, we propose an iterative query method to obtain more similar images. Specifically, we first get the top-k retrieved images returned from the IR system for the original query image, and then for each retrieved image, we search for its top-k images again. Finally, all the above images (at most k \u00fe k 2 images) are regarded as candidate images. The process is illustrated in Fig. 7. In practice, we can first perform the attacks using the k images output by the IR system, if the attacking effect is satisfied, the attack task is finished. If the attacking effect is not satisfied, we can expand the returned images using the iterative version, and judge the effect again.\n\n\nTraffic Sign Recognition\n\nFor the traffic sign recognition, attacks are extended to object detection models, which are used to detect and label multiple traffic signs within a scene [41]. Instead of being limited to returning the class of a single object in the image, the detector predicts both the locations (bounding boxes) and labels of multiple objects. Therefore, attacks in this task are more challenging. The attacks against object detectors can be divided into Disappearance Attacks and Classification Attacks. The goal of the former is to make the detector unable to detect the attacked sign (i.e., cannot return the bounding box corresponding to the object), while the latter focuses on modifying the label of the attacked detectable traffic sign.\n\nGiven an image with multiple traffic signs, assume the object detector successfully detects and classifies the traffic  6. Failed attack results when k is small (e.g., k \u00bc 5). The image in the red box is the adversarial example. We can find that the retrieved images are still relevant to adversarial query image after the attack even though its original top-k images are subverted. sign I I and its bounding box is denoted as O 0 . Our goal is to paste the adversarial sticker on this traffic sign to make the object detector predict wrong results. In each attack iteration, because the image has multiple traffic signs, the object detector may output multiple bounding boxes O O \u00bcfO i j i \u00bc 1;. . . ;ng, we first need to align the target traffic sign I I. For that, we find out the bounding box O \u00c3 that has the largest IoU value [47] (i.e., the overlap area) with the reference box O 0 . This process can be expressed as\nO \u00c3 \u00bc arg max i IoU O i \u00f0 \u00de \u00bc arg max i O 0 \\ O i j j O 0 [ O i j j :(19)\nIf IoU value [47] of O \u00c3 is greater than the threshold u, O \u00c3 is considered as the bounding box O I I corresponding to the traffic sign I I in each attack iteration. After aligning the bounding box in each attack iteration, we can obtain the score returned by the object detector f\u00f0\u00c1\u00de for the target traffic sign I I, that is f\u00f0x x; I I; t\u00de \u00bc s O I I ; t \u00f0 \u00de;\n\nwhere s\u00f0O I I ; t\u00de is the probability that the object corresponding to the bounding box O I I is predicted as the label t.\n\nAfter obtaining the score of the attacked object, we can perform the classification attack according to the method described in Section 3 to modify the predicted label of I I. In the iterative process, if O O is an empty set or no bounding box meets the threshold u, it is considered that the disappearance attack is realized.\n\n\nEXPERIMENTS AND RESULTS\n\n\nExperimental Settings\n\nTarget Models. We choose three representative face recognition models, CosFace [48], SphereFace [49] and FaceNet [44], as our target models. The open-source models 123 are used to extract feature representations of faces. For the identification, we use the model to get the face embedding, and then take its nearest neighbor among all the identities in the dataset as the result of recognition. For the classification, we add the full connection layer after the above open-source model, and then fine-tune it on the corresponding datasets. The dodging attack and the impersonation attack are conducted on all the above models.\n\nDatasets. We perform experiments on two public datasets: Labeled Faces in the Wild (LFW) 4 and CelebFaces Attribute (CelebA). 5 All 5749 identities of LFW and 8192 identities of CelebA are used to construct their own face databases. We select 1,000 images randomly from each of the two datasets to carry out attacks. Before attacks, we ensure that all the selected clean images can be correctly recognized by the model in both the face classification and identification tasks.\n\nMetrics. Two metrics, Fooling Rate (FR) and the Number of Queries (NQ), are used to evaluate the attack performance. The former refers to the percentage of all testing images that can be successfully attacked, while the latter refers to the number of model queries required for successful attacks. To study the effectiveness against face recognition modules, it is considered a successful attack if the face can successfully pass face detection and liveness detection but are identified as the wrong identity.\n\nImplementation. We use dlib library to extract 81 feature points of the face and fill the effective region to generate mask M F . d is equal to 2 in our case. u 1 refers to the index of the pasting position in the indexed set of valid points V :\u00bc f\u00f0i; j\u00de j M F ij \u00bc 1g and u 2 is the rotation angle. We set r equal to 8. The default l is equal to 1, and l is increased if the corresponding point in the parameter space has already been accessed.\n\nIn addition, we refer to the setting in [50] and set a of Eq. (5) to 0.5. To ensure the balance between the two terms in Eq. (8), we set r \u00bc 20. For the maximum number of iterations T , we set it to 30 based on the experience. For the population size P , we set it to 80, 100, 120, and 140 respectively and perform some simple verifications, and find that when P increases from 120 to 140, there is no obvious improvement in the success rate. Since the increase of P will introduce a higher query cost, we set P \u00bc 120 in the subsequent experiments. The threshold value d is used to judge whether the probability difference reaches a small value, so we empirically set it to a small number (i.e., d \u00bc 10).\n\n\nExperimental Results\n\n\nPerformance Comparisons in the Digital World\n\nFirst, we report the performance of our method on the LFW and CelebA against FaceNet, SphereFace, and CosFace, respectively. We use three different stickers to conduct dodging and impersonation attacks under the face classification task and evaluate the fooling rate and the number of queries. The results are shown in Table 1 and three groups of visual examples are given in Fig. 8. For the impersonation attack, we use the top-2 class for each face as the target class for simplicity.\n\nFrom the above results, we can see: (1) The proposed Meaningful Adversarial Sticker method has shown good attack effectiveness in both dodging and impersonation attacks, achieving fooling rates of up to 81.78% and 51.11% respectively. (2) We can implement an attack at the magnitude of hundreds of queries, and, understandably, an impersonation attack requires more queries than a dodging attack, since the former requires perturbing the image to a specific class. (3) Under our attack, SphereFace shows strong robustness in both dodging and impersonation attacks, while FaceNet is relatively vulnerable.\n\nFor different stickers, all of them can achieve successful attacks, but show different attack effects. Stickers with colorful patterns or some facial features (e.g., sticker 2 and sticker 3) show stronger attack effectiveness, especially in the case of a dodging attack. We also make statistics on the paste positions of different stickers when successful attacks are achieved, as shown in Table 2. It can be seen that when using the same sticker, the proportions of different positions do not show a significant difference, and each position remains at about 20%. But overall, the proportion is slightly higher between the eyes and slightly lower at the chin. Moreover, this phenomenon is consistent across different stickers.\n\n\nComparisons With SOTA Methods\n\nComparisons between our method and other physically realizable attacks for the face recognition on the same face images in the LFW are shown in Table 3. Since there are no existing physical attacks on the face recognition in the black-box setting, we can only use the adversarial examples generated in the white-box setting to carry out transferbased black-box attacks when calculating the performance of the previous methods. Although score-based black-box attacks can also be carried out through the gradient estimation, it is not realistic because the estimation of large areas of pixel gradients requires a large number of model queries.\n\nHere we choose adv-hat [9] and adv-glasses [8] which have great performance on the white-box setting. For our method, we use the results of dodging attacks by pasting sticker 2 to compare with other methods. The results in Table 3 show that our method can achieve better attack effectiveness in a shorter time when attacking different networks. It outperforms adv-hat with at most more than 83% improvement and adv-glasses with at most 85% improvement, while the average time to attack each image is reduced by 78% and 86% respectively. The qualitative comparisons between our method and adv-hat [9] and advglasses [8] are given in Fig. 9.    \n\n\nAblation Study\n\nIn this section, we first demonstrate the effectiveness of each component in the proposed method, and report the performance when each component of our RHDE algorithm is added separately. We conduct experiments on the LFW dataset to carry out dodging attacks using sticker 2. In all experiments, the population size P and iteration number T are consistent. Starting from the traditional differential evolution algorithm (DE), we add the adaptive adjustment strategy (adaptive-DE) and the region-based offspring generation strategy (region-DE), respectively, The comparison results are shown in Table 4.\n\nWe can see that under the same maximum number of iterations, the fooling rates of directly using DE are very low and relatively more queries are required. When the adaptive adjustment strategy and the offspring's generation strategy are added respectively, the fooling rates of both are improved. When the two strategies are used together, the fooling rates are greatly improved, and the queries required are significantly reduced.\n\nWe also conduct experiments on the upper bound of the achievable fooling rate. We take 30 different angles of stickers at an interval of 12 degrees, consider every valid paste position of the face, and traverse all possible solutions in the search space. When a successful attack is implemented, the traversal is stopped. The corresponding results of dodging attacks using sticker 2 on the LFW dataset are shown in the \"upper bound\" of Table 4. It can be seen that the upper bound of the face recognition on these three models is only 3.26%, 3.23%, and 4.07% higher than our method, but NQ is 11,162, 12,499, and 12,320 more than our method. This proves that our method can efficiently find the successful solution.\n\n\nAttacks in the Physical World\n\nIn this section, we report the performance of our meaningful adversarial stickers in the physical environment. Fig. 10 presents the predicted probabilities of three subjects corresponding to the ground-truth identity before and after attacks in the physical environment. The results show that the probabilities in different models are significantly reduced, and the maximum reduction in FaceNet, Sphere-Face, and CosFace after attacks are 0.64, 0.65, and 0.76, respectively. This proves that the generated attack parameters in the digital environment can still maintain a good attack performance when applied to the physical world.\n\nWe also report the results of fooling rates in complex physical conditions. We use the parameters calculated in the digital world, change face postures (counterclockwise rotation of the head) in the physical world, and count the percentage of successful attacks in consecutive frames. To prove the necessity of the 3D deformation (described in Section 3.4), we also calculate the relevant physical results of the parameters generated when 3D deformation is not Results are obtained on the LFW dataset to carry out dodging attacks using sticker 2. Fig. 10. The predicted probabilities of ground-truth labels before and after attacks in the physical environment. The numbers next to the vertical line represent the difference in the probability on each model. considered. Table 5 shows the above results for some subjects and Fig. 11 shows the visual examples of our method at different face postures. It demonstrates that our method still has a good attacking performance when changing face postures in the physical world. If the curvature of the human cheek is ignored and the 3D deformation is not considered, the corresponding performance in the physical environment will be greatly weakened. Importantly, it can maintain such good attack effectiveness in the physical world without considering complex physical conditions when solving parameters.\n\n\nRobustness of Meaningful Adversarial Stickers\n\nWe also test the robustness of our method in response to defense measures. We here choose adversarial training [51] as the defense method and conduct experiments on the LFW dataset. Specifically, we train two kinds of robust models using the generated adversarial examples with the sticker 1 and sticker 2 in Fig. 8, respectively. And then the adversarial sticker attacks are conducted against these robust models using the sticker 2. Table 6 lists the fooling rate and the number of queries of dodging attacks after the defense with sticker 2, as well as the changes compared to the results without defense. Generally speaking, the fooling rate will decrease and the query number will increase because of the improved robustness after the adversarial training. It can be seen that if we use the same sticker for the models' training and subsequent attacks, adversarial training does cause a drop in the fooling rate (i.e., the last two lines of Table 6). However, if the stickers used for training (sticker 1) and subsequent attacks (sticker 2) are different, the variation range of fooling rates and queries is relatively small, with the maximum variation range of 3.06% and 17\n\nrespectively. This shows that only a sticker is \"seen\" in the training set, adversarial training can resist the attacks caused by this sticker. However, in practice, the sticker types are so wide that defenders often have no way of knowing which sticker patterns are used by attackers. Therefore, it is more common for adversarial training and attacks to use different stickers. So in real applications, our attack method has a good robustness against the adversarial training.\n\n\nResults of the Face Identification Task\n\nBesides face classification models mentioned above, there is another face recognition task called face identification models widely used in our life. Different from the face classification, where the model outputs the identity label and probability with a classifier based on the extracted features, the face identification uses the face feature representation obtained by the models (CosFace, SphereFace, and FaceNet, etc) to calculate the cosine similarity with all face images in the database, and takes the class with the highest similarity as the predicted identity, which belongs to the category of the metric learning.\n\nIn this subsection, we show the corresponding results about the face identification task. In addition to the opensource model FaceNet, we also conduct experiments on the commercial face recognition API service 6 to verify the effectiveness of our method in the practical scenario. The results of using different stickers to attack faces in the LFW and CelebA datasets are shown in Table 7 and Fig. 12 presents some examples in the digital world. It can be seen that in the face identification task, our attack method can still  shows better robustness than face classification based on the traditional model classification. This phenomenon is worthy of our further exploration. Fig. 13 gives some examples of physical attacks under the face identification task. We also show the results of using multiple stickers to attack the face identification task. Fig. 14 shows some visual examples. The results show that when using multiple stickers to attack (the stickers do not cover the key features of the face and do not overlap each other), it can still achieve a good attack performance.\n\n\nEXTENSIONS TO OTHER APPLICATIONS\n\nIn this section, we introduce the corresponding experimental results versus the traffic sign recognition task and image retrieval task.\n\n\nImage Retrieval\n\nTo attack the image retrieval system, we choose the In-shop clothes retrieval task [52], which is to determine if two images taken in the shop belong to the same clothing item. The used dataset [52] contains 54, 642 images of 11, 735 clothing items. Top-k retrieval accuracy (recall@K) is adopted to measure the performance of fashion retrieval. We use the deep-fashion-retrieval 7 as the target image retrieval system to attack.\n\nThe quantitative attack performance is given in Table 8. From the table, we can see that for the same image retrieval system, the adversarial query image obtains lower Recall@K than the original query image. The gap is nearly 0.6. The number of query times is 343. This table shows that our method can use a few query times to achieve a big performance drop.\n\nTwo attacking examples are shown in Fig. 15. From the figure, we can see that the image system can successfully search for the similar clothes with the original query cloth (the first row and the third row), but when the sticker is pasted on the query cloth, the returned clothes by the image retrieval system are weakly correlated with the given input (the second row and fourth row). For example, after putting the sticker on the jeans, the retrieval system returns some jackets' images. The pasted sticker is small compared with the cloth, but it will affect the results output by the image retrieval system, which shows the weak robustness of the image retrieval system against adversarial attacks. We report the fooling rate (FR) and the number of queries (NQ) of the adversarial examples generated by different stickers on the LFW and CelebA datasets against FaceNet and the commercial API service (cml. API).  \n\n\nTraffic Sign Recognition\n\nTo test the performance, we use the Tsinghua-Tencent 100 K (TT100 K) dataset [53] to conduct adversarial attacks. It provides 100,000 images containing 30,000 Chinese traffic-sign instances, which cover large variations in illuminance and weather conditions. We use the YOLO [54] object detector as the threat model. We train YOLO using the training dataset in TT100 K, and then test it on 1,000 images randomly selected from the testing dataset in TT100 K. The final YOLO achieves 0.82 mAP. We first give the attacking performance in the digital world. Some results are illustrated in Fig. 16 (classification attack) and Fig. 17 (disappearance attack). In Fig. 16, YOLO detector can successfully detect and classify the traffic sign for the original images, but mis-classify them for the adversarial images. In Fig. 17, YOLO detector even fails to detect the traffic sign region. These results show that our adversarial stickers are effective for the object detection task. In these adversarial examples, our stickers are small and a majority of them do not shelter from the foreground region in the traffic sign. The quantitative attack performance on TT100 K for traffic sign recognition using an adversarial sticker is given in Table 9, where we can see that the mAP is significantly dropped from the original 0.82 to the current 0.23 after performing adversarial attacks. The drop error reaches 0.59 (the corresponding fooling rate is 85%). This result shows the effectiveness of the adversarial sticker against the traffic sign recognition task. The average query time is 435, which is also efficient.\n\nWe also give the attacking performance in the physical world. For that, we first paste the sticker on the real traffic sign using the pre-computed position, and then use the camera to capture the image at different distances and angles. The captured image is finally fed to the YOLO detector to predict the result. Fig. 18 shows the attack performance of the two signs at different angles and distances. For the traffic sign \"Speed Limit 100,\" the top row fools the object detector to predict it as \"Speed Limit 40 or 30,\" and Fig. 15. Two groups of attack results for the image retrieval system. The image in the red box is the adversarial example. We can find that the returned clothes after the attack are not related to the original results.     the object detector in the second row predicts \"Motor Vehicles Only\" as \"Pedestrian Crossing,\" which verifies the effectiveness of adversarial stickers in the physical world.\n\n\nCONCLUSION\n\nIn this paper, we proposed the Meaningful Adversarial Sticker, a physically feasible and stealthy attack method for black-box attacks in the physical world. We conducted attacks based on the real stickers in our life by changing their pasting positions, rotation angles, and other parameters. To solve for the parameters efficiently, we designed RHDE algorithm, which adopted the offspring's generation strategy based on the aggregation of effective solutions and the adaptive adjustment strategy of the evaluation criteria. Extensive experiments in the digital and physical world on the face recognition, image retrieval, and traffic sign recognition demonstrated the effectiveness of our method. In the case that the model information is unknown, computer vision systems can also be successfully misled in a concealed way, which reveals the potential safety hazard. \n\nFig. 1 .\n1Examples of pasting stickers on the face and traffic sign in our life, respectively.\n\nFig. 2 .\n2Some examples of stickers used in our experiments.\n\nFig. 4 .\n4The process of bending and rotating the sticker (the yellow dot indicates the highest point of the pasting area).\n\nFig. 5 .\n5The transformation process of the sticker pattern. The top row is the schematic diagram of variable annotation involved in the deformation, the second row shows the change of sticker patterns on the 2D X-Y plane, and the third row is the stereogram of the corresponding sticker.\n\nFig.\nFig. 6. Failed attack results when k is small (e.g., k \u00bc 5). The image in the red box is the adversarial example. We can find that the retrieved images are still relevant to adversarial query image after the attack even though its original top-k images are subverted.\n\nFig. 7 .\n7Illustration for the proposed iterative query image retrieval.\n\nFig. 8 .\n8Examples of attacks using different stickers. For each group, the three images correspond to the un-attacked original image, the image after attacks, and the image corresponding to the predicted wrong class after attacks. The black text denotes the predicted correct name and the red text denotes the predicted wrong name after attacks.\n\nFig. 11 .\n11Examples showing the attack effectiveness at different face postures in the physical environment (un-targeted attacks). The black text on the right side denotes the predicted wrong name after attacks.\n\nFig. 12 .\n12Examples using different stickers under the face identification task in the digital world. The black text denotes the predicted correct name and the red text denotes the predicted wrong name after attacks.\n\nFig. 13 .\n13Examples of attacks using different stickers under the face identification task in the physical world. The black text at the bottom of the image denotes the identified person's name and the corresponding cosine similarity (shown in brackets).7. https://github.com/ihciah/deep-fashion-retrieval\n\nFig. 16 .\n16Classification Attack for traffic sign recognition in the digital world. The top row denotes the results on the original images, and the bottom row denotes the results on the adversarial images.\n\nFig. 17 .\n17Disappearance attack for traffic sign recognition in the digital world. The top row denotes the results on the original images, and the bottom row denotes the results on the adversarial images.\n\nFig. 14 .\n14Examples using multiple stickers under the face identification task. The black text at the bottom of the image denotes the identified person's name and the corresponding cosine similarity (shown in brackets).\n\nTABLE 2 The\n2Distribution Percentage of the Three Stickers in Different Positions When the Attack is SuccessfulForehead \nBetween \nEyebrows \n\nLeft \nCheek \n\nRight \nCheek \n\nChin \n\nsticker1 17.39% \n28.50% \n19.42% 20.56% 14.13% \nsticker2 20.03% \n24.15% \n20.14% 20.63% 15.05% \nsticker3 20.11% \n27.36% \n20.49% 21.23% 10.81% \n\n\n\nTABLE 3\n3Comparisons of the Fooling Rate and Average Time With Two SOTA Physical Methods for Face Recognition Systems in the Black-Box SettingFaceNet SphereFace CosFace average time \n\nadv-hat \n28.85% \n10.36% \n26.66% \n325.37 s \nadv-glasses 21.21% \n10.63% \n9.83% \n536.25 s \nours \n76.26% \n64.08% \n69.82% \n69.97 s \n\nFig. 9. Comparisons of our meaningful Adv-sticker with other attack \nmethods (Adv-hat [9], Adv-glasses [8], [10]) for FR systems. Our \napproach uses real stickers without relying on the generated perturba-\ntion patterns and printed accessories. \n\n\n\nTABLE 1 The\n1Results of Attacks on the Face Classification TaskDatasets \nLFW \nCelebA \n\nModel \nFaceNet \nSphereFace \nCosFace \nFaceNet \nSphereFace \nCosFace \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \n\nDodging \n\nsticker 1 63.22% 489 42.74% 691 54.28% 527 73.51% 518 57.18% 596 69.47% 530 \nsticker 2 76.26% 478 64.08% 629 69.82% 484 81.78% 483 72.93% 576 79.26% 487 \nsticker 3 73.64% 442 44.50% 604 66.59% 455 80.33% 511 59.92% 548 72.80% 496 \n\nImpersonation \n\nsticker 1 51.11% 636 30.70% 718 48.06% 563 48.18% 610 37.32% 644 42.90% 653 \nsticker 2 50.00% 715 31.00% 870 45.93% 658 48.96% 652 41.67% 747 47.73% 637 \nsticker 3 46.28% 691 29.50% 716 45.54% 662 47.84% 625 39.18% 700 45.83% 638 \n\nWe report the fooling rate (FR) and the number of queries (NQ) of the adversarial examples generated by different stickers on the LFW and CelebA datasets \nagainst FaceNet, SphereFace and CosFace. \n\n\nTABLE 4 The\n4Fooling Rate (FR) and the Number of Queries (NQ) \nof the Ablation Study \n\nFaceNet \nSphereFace \nCosFace \nFR \nNQ \nFR \nNQ \nFR \nNQ \n\nDE \n29.03% 1107 21.88% 1262 31.83% 768 \nadaptive-DE 41.96% 764 34.38% 862 38.12% 564 \nregion-DE \n54.81% 871 41.67% 970 55.59% 519 \nRHDE (ours) 76.26% 478 64.08% 629 69.82% 484 \nupper bound 79.52% 11640 67.31% 13128 73.89% 12804 \n\n\n\nTABLE 5 The\n5Percentage of Video Frames Successfully Attacked When Different Subjects Continuously Change Their Face Postures in the Physical Environmentmodel \nsubject \nwith-def \nno-def \ndifference \n\nFaceNet \n\nA \n98.46% \n59.78% \n38.68% \nB \n98.30% \n48.74% \n49.56% \nC \n92.94% \n48.39% \n44.55% \nD \n97.50% \n53.87% \n43.63% \nE \n98.16% \n58.96% \n39.20% \nF \n95.36% \n48.25% \n47.11% \nG \n97.87% \n51.16% \n46.71% \nH \n98.24% \n57.85% \n40.39% \nI \n96.97% \n55.73% \n41.24% \n\nSphereFace \n\nA \n91.30% \n55.17% \n36.13% \nB \n83.45% \n33.33% \n50.12% \nC \n85.92% \n40.76% \n45.16% \nD \n83.87% \n40.88% \n42.99% \nE \n84.92% \n41.24% \n43.68% \nF \n89.76% \n48.60% \n41.16% \nG \n90.45% \n49.71% \n40.74% \nH \n86.90% \n44.54% \n42.36% \nI \n83.48% \n42.93% \n40.55% \n\nCosFace \n\nA \n85.37% \n48.09% \n37.28% \nB \n86.96% \n46.67% \n40.29% \nC \n82.61% \n45.45% \n37.16% \nD \n84.39% \n44.96% \n39.43% \nE \n86.06% \n47.61% \n38.45% \nF \n83.42% \n41.79% \n41.63% \nG \n84.88% \n45.82% \n39.06% \nH \n82.29% \n43.60% \n38.69% \nI \n85.91% \n48.95% \n36.96% \n\nwith-def: using 3 d deformation in parameters' solving process. \nno-def: pasting the sticker directly without considering deformation. \ndifference: the difference between with-def and no-def. \n\n\nTABLE 6 The\n6Fooling Rate (FR) and the Number of Queries (NQ) After Adversarial Training, and the Changes Compared to the Undefended Situations (Shown in Brackets)Here we use sticker 2 to conduct dodging attacks on LFW.6. https://intl.cloud.tencent.com/product/facerecognition maintain the good attack performance with a natural appearance in both dodging attack and impersonation attacks, achieving the fooling rate of at most 80.03% and 58.82%, respectively. It can also reach 46.17% and 40.25% on the commercial API. Although the performance is slightly lower than that of the open-source model, it is still acceptable because the commercial system includes some defense mechanisms such as the image compression. Besides, in most cases, face identification based on the metric learningtraining \nFaceNet \nSphereFace \nCosFace \n\nsticker1 \nFR \n74.18% \n(#2.08%) \n61.02% \n(#3.06%) \n67.46% \n(#2.36%) \nNQ \n485 \n(\" 7) \n646 \n(\" 17) \n498 \n(\" 14) \n\nsticker2 \nFR \n60.35% \n(#15.91%) \n47.29% \n(#16.79%) \n51.09% \n(#18.73%) \nNQ \n532 \n(\" 54) \n675 \n(\" 46) \n544 \n(\" 60) \n\n\n\nTABLE 7 The\n7Results of Attacks on the Face Identification TaskDodging \nImpersonation \nLFW \nCelebA \nLFW \nCelebA \nFaceNet \ncml. API \nFaceNet \ncml. API \nFaceNet \ncml. API \nFaceNet \ncml. API \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \nFR \nNQ \n\nsticker1 43.11% 504 39.05% 524 66.44% 574 43.95% 513 41.63% 586 34.65% 594 58.82% 552 37.96% 581 \nsticker2 43.68% 484 42.81% 492 75.41% 472 46.17% 489 42.11% 596 35.24% 575 55.87% 511 40.25% 572 \nsticker3 48.82% 422 40.76% 485 80.03% 439 45.50% 467 46.85% 587 35.93% 583 55.15% 563 39.51% 590 \n\n\n\nTABLE 9 The\n9Quantitative Attack Performance for Traffic Sign Recognition Using an Adversarial StickerOriginal \nAdversarial \n\nmAP \n0.82 \n0.23 \nFR \n0 \n83.5% \nNQ \n0 \n435 \n\n\n\nTABLE 8 The\n8Attack Results for Image Retrieval Using Adversarial StickersRecall@K \n1 \n10 \n20 \n30 \n40 \nNQ \n\nOriginal \n0.642 \n0.868 \n0.910 \n0.926 \n0.938 \n0 \nAdversarial \n0.068 \n0.214 \n0.296 \n0.346 \n0.360 \n343 \n\n\n\n\nXingxing Wei (Member, IEEE) received the BS degree in automation from Beihang University, China, and the PhD degree in computer science from Tianjin University. He is now an associate professor in Beihang University (BUAA). His research interests include computer vision, adversarial machine learning and its applications. He is the author of referred journals and conferences in IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Transactions on Multimedia, IEEE Transactions on Cybernetics, IEEE Transactions on Geoscience and Remote Sensing; International Journal of Computer Vision, Pattern Recognition, Computer Vision and Image Understanding; CVPR, ICCV, ECCV, ACMMM, AAAI, IJCAI etc. Ying Guo is now working toward the master's degree with the School of Computer Science and Engineering, Beihang University (BUAA). Her research interests include deep learning and adversarial robustness in machine learning. Jie Yu is now working toward the master's degree with the School of Computer Science and Engineering, Beihang University (BUAA). His research interests include deep learning, compter vision and adversarial robustness.\n\" For more information on this or any other computing topic, please visit our Digital Library at www.computer.org/csdl.\nACKNOWLEDGMENTSWe also thank anonymous reviewers for their valuable suggestions.\nDeep learning for 3D point clouds: A survey. Y Guo, H Wang, Q Hu, H Liu, L Liu, M Bennamoun, IEEE Trans. Pattern Anal. Mach. Intell. 4312Y. Guo, H. Wang, Q. Hu, H. Liu, L. Liu, and M. Bennamoun, \"Deep learning for 3D point clouds: A survey,\" IEEE Trans. Pat- tern Anal. Mach. Intell., vol. 43, no. 12, pp. 4338-4364, Dec. 2021.\n\nImage segmentation using deep learning: A survey. S Minaee, Y Y Boykov, F Porikli, A J Plaza, N Kehtarnavaz, D Terzopoulos, 10.1109/TPAMI.2021.3059968IEEE Trans. Pattern Anal. Mach. Intell., early access. S. Minaee, Y. Y. Boykov, F. Porikli, A. J. Plaza, N. Kehtarnavaz, and D. Terzopoulos, \"Image segmentation using deep learning: A survey,\" IEEE Trans. Pattern Anal. Mach. Intell., early access, Feb. 17, 2021, doi: 10.1109/TPAMI.2021.3059968.\n\nMultimodal machine learning: A survey and taxonomy. T Baltru Saitis, C Ahuja, L.-P Morency, IEEE Trans. Pattern Anal. Mach. Intell. 412T. Baltru saitis, C. Ahuja, and L.-P. Morency, \"Multimodal machine learning: A survey and taxonomy,\" IEEE Trans. Pattern Anal. Mach. Intell., vol. 41, no. 2, pp. 423-443, Feb. 2019.\n\nIntriguing properties of neural networks. C Szegedy, arXiv:1312.6199C. Szegedy et al., \"Intriguing properties of neural networks,\" 2013, arXiv:1312.6199.\n\nExplaining and harnessing adversarial examples. I J Goodfellow, J Shlens, C Szegedy, arXiv:1412.6572I. J. Goodfellow, J. Shlens, and C. Szegedy, \"Explaining and har- nessing adversarial examples,\" 2014, arXiv:1412.6572.\n\nAdversarial patch. T B Brown, D Man E, A Roy, M Abadi, J Gilmer, arXiv:1712.09665T. B. Brown, D. Man e, A. Roy, M. Abadi, and J. Gilmer, \"Adversarial patch,\" 2017, arXiv:1712.09665.\n\nEfficient decision-based black-box adversarial attacks on face recognition. Y Dong, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitY. Dong et al., \"Efficient decision-based black-box adversarial attacks on face recognition,\" in Proc. IEEE Conf. Comput. Vis. Pat- tern Recognit., 2019, pp. 7714-7722.\n\nAccessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. M Sharif, S Bhagavatula, L Bauer, M K Reiter, Proc. ACM SIGSAC Conf. ACM SIGSAC ConfM. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, \"Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recog- nition,\" in Proc. ACM SIGSAC Conf. Comput. Commun. Secur., 2016, pp. 1528-1540.\n\nAdvHat: Real-world adversarial attack on arcface face id system. S Komkov, A Petiushko, arXiv:1908.08705S. Komkov and A. Petiushko, \"AdvHat: Real-world adversarial attack on arcface face id system,\" 2019, arXiv:1908.08705.\n\nA general framework for adversarial examples with objectives. M Sharif, S Bhagavatula, L Bauer, M K Reiter, ACM Trans. Privacy Secur. 223M. Sharif, S. Bhagavatula, L. Bauer, and M. K. Reiter, \"A general framework for adversarial examples with objectives,\" ACM Trans. Privacy Secur., vol. 22, no. 3, pp. 1-30, 2019.\n\nDPatch: An adversarial patch attack on object detectors. X Liu, H Yang, Z Liu, L Song, H Li, Y Chen, arXiv:1806.02299X. Liu, H. Yang, Z. Liu, L. Song, H. Li, and Y. Chen, \"DPatch: An adversarial patch attack on object detectors,\" 2018, arXiv:1806.02299.\n\nObject hider: Adversarial patch attack against object detectors. Y Zhao, H Yan, X Wei, arXiv:2010.149742020Y. Zhao, H. Yan, and X. Wei, \"Object hider: Adversarial patch attack against object detectors,\" 2020, arXiv:2010.14974.\n\nFooling automated surveillance cameras: Adversarial patches to attack person detection. S Thys, W Van Ranst, T Goedem, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Workshops. IEEE Conf. Comput. Vis. Pattern Recognit. WorkshopsS. Thys, W. Van Ranst, and T. Goedem e, \"Fooling automated sur- veillance cameras: Adversarial patches to attack person detection,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. Work- shops, 2019, pp. 49-55.\n\nAdversarial t-shirt! evading person detectors in a physical world. K Xu, Proc. Eur. Conf. Comput. Vis. Eur. Conf. Comput. VisK. Xu et al., \"Adversarial t-shirt! evading person detectors in a physi- cal world,\" in Proc. Eur. Conf. Comput. Vis., 2020, pp. 665-681.\n\nSynthesizing robust adversarial examples. A Athalye, L Engstrom, A Ilyas, K Kwok, Proc. Int. Conf. Mach. Learn. A. Athalye, L. Engstrom, A. Ilyas, and K. Kwok, \"Synthesizing robust adversarial examples,\" in Proc. Int. Conf. Mach. Learn., 2018, pp. 284-293.\n\nTowards evaluating the robustness of neural networks. N Carlini, D Wagner, Proc. 2017 IEEE Symp. 2017 IEEE SympN. Carlini and D. Wagner, \"Towards evaluating the robustness of neural networks,\" in Proc. 2017 IEEE Symp. Secur. Privacy, 2017, pp. 39-57.\n\nDeepFool: A simple and accurate method to fool deep neural networks. S.-M Moosavi-Dezfooli, A Fawzi, P Frossard, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitS.-M. Moosavi-Dezfooli, A. Fawzi, and P. Frossard, \"DeepFool: A simple and accurate method to fool deep neural networks,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 2574-2582.\n\nTowards deep learning models resistant to adversarial attacks. A Madry, A Makelov, L Schmidt, D Tsipras, A Vladu, arXiv:1706.06083A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, \"Towards deep learning models resistant to adversarial attacks,\" 2017, arXiv:1706.06083.\n\nLaVAN: Localized and visible adversarial noise. D Karmon, D Zoran, Y Goldberg, Proc. Int. Conf. Mach. Learn. D. Karmon, D. Zoran, and Y. Goldberg, \"LaVAN: Localized and visible adversarial noise,\" in Proc. Int. Conf. Mach. Learn., 2018, pp. 2507-2515.\n\nBoosting adversarial attacks with momentum. Y Dong, Proc. IEEE Conf. Comput. Vis. IEEE Conf. Comput. VisY. Dong et al., \"Boosting adversarial attacks with momentum,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2018, pp. 9185-9193.\n\nDelving into transferable adversarial examples and black-box attacks. Y Liu, X Chen, C Liu, D Song, arXiv:1611.02770Y. Liu, X. Chen, C. Liu, and D. Song, \"Delving into transferable adversarial examples and black-box attacks,\" 2016, arXiv:1611.02770.\n\nUniversal adversarial attack on attention and the resulting dataset DAmageNet. S Chen, Z He, C Sun, J Yang, X Huang, IEEE Trans. Pattern Anal. Mach. Intell. 444S. Chen, Z. He, C. Sun, J. Yang, and X. Huang, \"Universal adver- sarial attack on attention and the resulting dataset DAmageNet,\" IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, no. 4, pp. 2188- 2197, Apr. 2022.\n\nA hamiltonian Monte Carlo method for probabilistic adversarial attack and learning. H Wang, G Li, X Liu, L Lin, IEEE Trans. Pattern Anal. Mach. Intell. 444H. Wang, G. Li, X. Liu, and L. Lin, \"A hamiltonian Monte Carlo method for probabilistic adversarial attack and learning,\" IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, no. 4, pp. 1725-1737, Apr. 2022.\n\nExamples of adversarial attacks for traffic sign recognition in different physical conditions including angles and distances. Roughly speaking, D1-D2 denote 1 m, 3 m, respectively, and A1-A5. Fig, 18denote 0 ; 5 ; 10 ; 15 ; 20 , respectively. The black text at the bottom of the image denotes the predicted class and its associated probability (shown in bracketsFig. 18. Examples of adversarial attacks for traffic sign recognition in different physical conditions including angles and distances. Roughly speaking, D1-D2 denote 1 m, 3 m, respectively, and A1-A5 denote 0 ; 5 ; 10 ; 15 ; 20 , respectively. The black text at the bottom of the image denotes the pre- dicted class and its associated probability (shown in brackets).\n\nUnderstanding and enhancing the transferability of adversarial examples. L Wu, arXiv:1802.09707L. Wu et al., \"Understanding and enhancing the transferability of adversarial examples,\" 2018, arXiv:1802.09707.\n\nZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. P.-Y Chen, H Zhang, Y Sharma, J Yi, C.-J Hsieh, Proc. 10th ACM Workshop Artif. Intell. Secur. 10th ACM Workshop Artif. Intell. SecurP.-Y. Chen, H. Zhang, Y. Sharma, J. Yi, and C.-J. Hsieh, \"ZOO: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models,\" in Proc. 10th ACM Workshop Artif. Intell. Secur., 2017, pp. 15-26.\n\nSquare attack: A query-efficient black-box adversarial attack via random search. M Andriushchenko, F Croce, N Flammarion, M Hein, Proc. Eur. Conf. Comput. Vis. Eur. Conf. Comput. VisM. Andriushchenko, F. Croce, N. Flammarion, and M. Hein, \"Square attack: A query-efficient black-box adversarial attack via random search,\" in Proc. Eur. Conf. Comput. Vis., 2020, pp. 484-501.\n\nSimple black-box adversarial attacks. C Guo, J Gardner, Y You, A G Wilson, K Weinberger, Proc. Int. Conf. Mach. Learn. Int. Conf. Mach. LearnC. Guo, J. Gardner, Y. You, A. G. Wilson, and K. Weinberger, \"Simple black-box adversarial attacks,\" in Proc. Int. Conf. Mach. Learn., 2019, pp. 2484-2493.\n\nDecision-based adversarial attacks: Reliable attacks against black-box machine learning models. W Brendel, J Rauber, M Bethge, Proc. Int. Conf. Learn. Representations. Int. Conf. Learn. RepresentationsW. Brendel, J. Rauber, and M. Bethge, \"Decision-based adversarial attacks: Reliable attacks against black-box machine learning mod- els,\" in Proc. Int. Conf. Learn. Representations, 2018.\n\nQuery-efficient hard-label black-box attack: An optimizationbased approach. M Cheng, T Le, P.-Y Chen, H Zhang, J Yi, C.-J Hsieh, Proc. Int. Conf. Learn. Representations. Int. Conf. Learn. RepresentationsM. Cheng, T. Le, P.-Y. Chen, H. Zhang, J. Yi, and C.-J. Hsieh, \"Query-efficient hard-label black-box attack: An optimization- based approach,\" in Proc. Int. Conf. Learn. Representations, 2018.\n\nAdversarial examples in the physical world. A Kurakin, I Goodfellow, S Bengio, arXiv:1607.02533A. Kurakin, I. Goodfellow, and S. Bengio, \"Adversarial examples in the physical world,\" 2016, arXiv:1607.02533.\n\nIntroduction to Face Presentation Attack Detection. J Hernandez-Ortega, J Fierrez, A Morales, J Galbally, Springer International PublishingCham, SwitzerlandJ. Hernandez-Ortega, J. Fierrez, A. Morales, and J. Galbally, Intro- duction to Face Presentation Attack Detection. Cham, Switzerland: Springer International Publishing, 2019, pp. 187-206.\n\nInvisible mask: Practical attacks on face recognition with infrared. Z Zhou, D Tang, X Wang, W Han, X Liu, K Zhang, arXiv:1803.04683Z. Zhou, D. Tang, X. Wang, W. Han, X. Liu, and K. Zhang, \"Invisible mask: Practical attacks on face recognition with infrared,\" 2018, arXiv:1803.04683.\n\nAdversarial light projection attacks on face recognition systems: A feasibility study. D.-L Nguyen, S S Arora, Y Wu, H Yang, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops, 2020. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops, 2020D.-L. Nguyen, S. S. Arora, Y. Wu, and H. Yang, \"Adversarial light projection attacks on face recognition systems: A feasibility study,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops, 2020, pp. 814-815.\n\nReal-world attack on MTCNN face detection system. E Kaziakhmedov, K Kireev, G Melnikov, M Pautov, A Petiushko, Proc. Int. Multi-Conf. Eng. Int. Multi-Conf. EngE. Kaziakhmedov, K. Kireev, G. Melnikov, M. Pautov, and A. Petiushko, \"Real-world attack on MTCNN face detection sys- tem,\" in Proc. Int. Multi-Conf. Eng., Comput. Inf. Sci., 2019, pp. 0422-0427.\n\nOn adversarial patches: Real-world attack on arcface-100 face recognition system. M Pautov, G Melnikov, E Kaziakhmedov, K Kireev, A Petiushko, Proc. Int. Multi-Conf. Eng. Int. Multi-Conf. EngM. Pautov, G. Melnikov, E. Kaziakhmedov, K. Kireev, and A. Petiushko, \"On adversarial patches: Real-world attack on arc- face-100 face recognition system,\" in Proc. Int. Multi-Conf. Eng., Comput. Inf. Sci., 2019, pp. 0391-0396.\n\nRobust physical-world attacks on deep learning visual classification. K Eykholt, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitK. Eykholt et al., \"Robust physical-world attacks on deep learning visual classification,\" in Proc. IEEE Conf. Comput. Vis. Pattern Rec- ognit., 2018, pp. 1625-1634.\n\nThe translucent patch: A physical and universal attack on object detectors. A Zolfi, M Kravchik, Y Elovici, A Shabtai, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. IEEE/CVF Conf. Comput. Vis. Pattern RecognitA. Zolfi, M. Kravchik, Y. Elovici, and A. Shabtai, \"The translucent patch: A physical and universal attack on object detectors,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., 2021, pp. 15232-15241.\n\nAdversarial camouflage: Hiding physical-world attacks with natural styles. R Duan, X Ma, Y Wang, J Bailey, A K Qin, Y Yang, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. IEEE/CVF Conf. Comput. Vis. Pattern RecognitR. Duan, X. Ma, Y. Wang, J. Bailey, A. K. Qin, and Y. Yang, \"Adversarial camouflage: Hiding physical-world attacks with nat- ural styles,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., 2020, pp. 1000-1008.\n\nNote on attacking object detectors with adversarial stickers. K Eykholt, arXiv:1712.08062K. Eykholt et al., \"Note on attacking object detectors with adver- sarial stickers,\" 2017, arXiv:1712.08062.\n\nDARTS: Deceiving autonomous cars with toxic signs. C Sitawarin, A N Bhagoji, A Mosenia, M Chiang, P Mittal, arXiv:1802.06430C. Sitawarin, A. N. Bhagoji, A. Mosenia, M. Chiang, and P. Mittal, \"DARTS: Deceiving autonomous cars with toxic signs,\" 2018, arXiv:1802.06430.\n\nPhysical adversarial examples for object detectors. D Song, Proc. 12th USENIX Workshop Offensive Technol. 12th USENIX Workshop Offensive TechnolD. Song et al., \"Physical adversarial examples for object detectors,\" in Proc. 12th USENIX Workshop Offensive Technol., 2018, Art. no. 1.\n\nMaking an invisibility cloak: Real world adversarial attacks on object detectors. Z Wu, S.-N Lim, L S Davis, T Goldstein, Proc. Eur. Conf. Comput. Vis. Eur. Conf. Comput. VisZ. Wu, S.-N. Lim, L. S. Davis, and T. Goldstein, \"Making an invisi- bility cloak: Real world adversarial attacks on object detectors,\" in Proc. Eur. Conf. Comput. Vis., 2020, pp. 1-17.\n\nA survey on anti-spoofing methods for face recognition with RGB cameras of generic consumer devices. Z Ming, M Visani, M M Luqman, J.-C Burie, arXiv:2010.041452020Z. Ming, M. Visani, M. M. Luqman, and J.-C. Burie, \"A survey on anti-spoofing methods for face recognition with RGB cameras of generic consumer devices,\" 2020, arXiv:2010.04145.\n\nFaceNet: A unified embedding for face recognition and clustering. F Schroff, D Kalenichenko, J Philbin, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitF. Schroff, D. Kalenichenko, and J. Philbin, \"FaceNet: A unified embedding for face recognition and clustering,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2015, pp. 815-823.\n\nA morphable model for the synthesis of 3D faces. V Blanz, T Vetter, Proc. 26th Annu. Conf. Comput. Graph. Interactive Techn. 26th Annu. Conf. Comput. Graph. Interactive TechnV. Blanz and T. Vetter, \"A morphable model for the synthesis of 3D faces,\" in Proc. 26th Annu. Conf. Comput. Graph. Interactive Techn., 1999, pp. 187-194.\n\nQAIR: Practical query-efficient black-box attacks for image retrieval. X Li, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. IEEE/CVF Conf. Comput. Vis. Pattern RecognitX. Li et al., \"QAIR: Practical query-efficient black-box attacks for image retrieval,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Rec- ognit., 2021, pp. 3330-3339.\n\nUnitBox: An advanced object detection network. J Yu, Y Jiang, Z Wang, Z Cao, T Huang, Proc. 24th ACM Int. Conf. Multimedia. 24th ACM Int. Conf. MultimediaJ. Yu, Y. Jiang, Z. Wang, Z. Cao, and T. Huang, \"UnitBox: An advanced object detection network,\" in Proc. 24th ACM Int. Conf. Multimedia, 2016, pp. 516-520.\n\nCosFace: Large margin cosine loss for deep face recognition. H Wang, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. IEEE/CVF Conf. Comput. Vis. Pattern RecognitH. Wang et al., \"CosFace: Large margin cosine loss for deep face recognition,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recog- nit., 2018, pp. 5265-5274.\n\nSphereFace: Deep hypersphere embedding for face recognition. W Liu, Y Wen, Z Yu, M Li, B Raj, L Song, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitW. Liu, Y. Wen, Z. Yu, M. Li, B. Raj, and L. Song, \"SphereFace: Deep hypersphere embedding for face recognition,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2017, pp. 212-220.\n\nOne pixel attack for fooling deep neural networks. J Su, D V Vargas, K Sakurai, IEEE Trans. Evol. Comput. 235J. Su, D. V. Vargas, and K. Sakurai, \"One pixel attack for fooling deep neural networks,\" IEEE Trans. Evol. Comput., vol. 23, no. 5, pp. 828-841, Oct. 2019.\n\nTowards deep learning models resistant to adversarial attacks. A Madry, A Makelov, L Schmidt, D Tsipras, A Vladu, Proc. Int. Conf. Learn. Representations. Int. Conf. Learn. RepresentationsA. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, \"Towards deep learning models resistant to adversarial attacks,\" in Proc. Int. Conf. Learn. Representations, 2018.\n\nDeepFashion: Powering robust clothes recognition and retrieval with rich annotations. Z Liu, P Luo, S Qiu, X Wang, X Tang, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitZ. Liu, P. Luo, S. Qiu, X. Wang, and X. Tang, \"DeepFashion: Powering robust clothes recognition and retrieval with rich annotations,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 1096-1104.\n\nTrafficsign detection and classification in the wild. Z Zhu, D Liang, S Zhang, X Huang, B Li, S Hu, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitZ. Zhu, D. Liang, S. Zhang, X. Huang, B. Li, and S. Hu, \"Traffic- sign detection and classification in the wild,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2016, pp. 2110-2118.\n\nYou only look once: Unified, real-time object detection. J Redmon, S Divvala, R Girshick, A Farhadi, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitJ. Redmon, S. Divvala, R. Girshick, and A. Farhadi, \"You only look once: Unified, real-time object detection,\" in Proc. IEEE Conf. Com- put. Vis. Pattern Recognit., 2016, pp. 779-788.\n", "annotations": {"author": "[{\"end\":96,\"start\":71},{\"end\":106,\"start\":97},{\"end\":114,\"start\":107}]", "publisher": null, "author_last_name": "[{\"end\":95,\"start\":92},{\"end\":105,\"start\":102},{\"end\":113,\"start\":111}]", "author_first_name": "[{\"end\":91,\"start\":83},{\"end\":101,\"start\":97},{\"end\":110,\"start\":107}]", "author_affiliation": null, "title": "[{\"end\":68,\"start\":1},{\"end\":182,\"start\":115}]", "venue": null, "abstract": "[{\"end\":1770,\"start\":303}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1929,\"start\":1926},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1934,\"start\":1931},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1939,\"start\":1936},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1997,\"start\":1994},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2002,\"start\":1999},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2591,\"start\":2588},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2917,\"start\":2914},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2922,\"start\":2919},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2927,\"start\":2924},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2933,\"start\":2929},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2956,\"start\":2952},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2962,\"start\":2958},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2989,\"start\":2985},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2995,\"start\":2991},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3269,\"start\":3265},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3339,\"start\":3336},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3345,\"start\":3341},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4395,\"start\":4392},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4400,\"start\":4397},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4405,\"start\":4402},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4411,\"start\":4407},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4417,\"start\":4413},{\"end\":5929,\"start\":5917},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9463,\"start\":9460},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9473,\"start\":9469},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9488,\"start\":9484},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9578,\"start\":9575},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9653,\"start\":9649},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9837,\"start\":9833},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10363,\"start\":10359},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10369,\"start\":10365},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10375,\"start\":10371},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10381,\"start\":10377},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10387,\"start\":10383},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10513,\"start\":10509},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10536,\"start\":10532},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10542,\"start\":10538},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10702,\"start\":10698},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10708,\"start\":10704},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10725,\"start\":10722},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":11438,\"start\":11434},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11583,\"start\":11579},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11696,\"start\":11693},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12029,\"start\":12025},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12148,\"start\":12145},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12154,\"start\":12150},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":12172,\"start\":12168},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12288,\"start\":12285},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12423,\"start\":12419},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":12521,\"start\":12517},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12527,\"start\":12523},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12673,\"start\":12669},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":12792,\"start\":12788},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12980,\"start\":12976},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":13239,\"start\":13235},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":13245,\"start\":13241},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":13280,\"start\":13276},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13407,\"start\":13403},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13501,\"start\":13497},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":13604,\"start\":13600},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":15640,\"start\":15636},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":16341,\"start\":16337},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":18884,\"start\":18880},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":19252,\"start\":19249},{\"end\":21692,\"start\":21686},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":23836,\"start\":23835},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27209,\"start\":27206},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":27212,\"start\":27209},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27216,\"start\":27212},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27220,\"start\":27216},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":27224,\"start\":27220},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":27228,\"start\":27224},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":27623,\"start\":27619},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":32635,\"start\":32631},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33283,\"start\":33279},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":33465,\"start\":33461},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":33649,\"start\":33645},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":33772,\"start\":33768},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":35849,\"start\":35845},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":37259,\"start\":37255},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":37438,\"start\":37434},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":38367,\"start\":38363},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":38384,\"start\":38380},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":38401,\"start\":38397},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":39002,\"start\":39001},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":39039,\"start\":39038},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":40392,\"start\":40388},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":43648,\"start\":43645},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":43668,\"start\":43665},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":44221,\"start\":44218},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":44240,\"start\":44237},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":48217,\"start\":48213},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":51796,\"start\":51792},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":51907,\"start\":51903},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":53527,\"start\":53523},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":53725,\"start\":53721},{\"end\":55589,\"start\":55582}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":56958,\"start\":56863},{\"attributes\":{\"id\":\"fig_1\"},\"end\":57020,\"start\":56959},{\"attributes\":{\"id\":\"fig_2\"},\"end\":57145,\"start\":57021},{\"attributes\":{\"id\":\"fig_3\"},\"end\":57435,\"start\":57146},{\"attributes\":{\"id\":\"fig_4\"},\"end\":57709,\"start\":57436},{\"attributes\":{\"id\":\"fig_5\"},\"end\":57783,\"start\":57710},{\"attributes\":{\"id\":\"fig_6\"},\"end\":58131,\"start\":57784},{\"attributes\":{\"id\":\"fig_7\"},\"end\":58345,\"start\":58132},{\"attributes\":{\"id\":\"fig_8\"},\"end\":58564,\"start\":58346},{\"attributes\":{\"id\":\"fig_9\"},\"end\":58871,\"start\":58565},{\"attributes\":{\"id\":\"fig_10\"},\"end\":59079,\"start\":58872},{\"attributes\":{\"id\":\"fig_11\"},\"end\":59286,\"start\":59080},{\"attributes\":{\"id\":\"fig_12\"},\"end\":59508,\"start\":59287},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":59829,\"start\":59509},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":60390,\"start\":59830},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":61282,\"start\":60391},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":61656,\"start\":61283},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":62816,\"start\":61657},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":63873,\"start\":62817},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":64424,\"start\":63874},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":64596,\"start\":64425},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":64808,\"start\":64597},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":65961,\"start\":64809}]", "paragraph": "[{\"end\":2149,\"start\":1790},{\"end\":3001,\"start\":2151},{\"end\":4976,\"start\":3003},{\"end\":5265,\"start\":4978},{\"end\":6451,\"start\":5267},{\"end\":7503,\"start\":6453},{\"end\":7560,\"start\":7505},{\"end\":9282,\"start\":7562},{\"end\":9417,\"start\":9299},{\"end\":10150,\"start\":9437},{\"end\":11199,\"start\":10152},{\"end\":11673,\"start\":11220},{\"end\":11916,\"start\":11675},{\"end\":12623,\"start\":11918},{\"end\":13246,\"start\":12625},{\"end\":13755,\"start\":13248},{\"end\":14119,\"start\":13757},{\"end\":14453,\"start\":14135},{\"end\":14948,\"start\":14477},{\"end\":15350,\"start\":14983},{\"end\":17196,\"start\":15375},{\"end\":17563,\"start\":17198},{\"end\":18274,\"start\":17613},{\"end\":18277,\"start\":18276},{\"end\":18612,\"start\":18279},{\"end\":19584,\"start\":18680},{\"end\":20326,\"start\":19657},{\"end\":20358,\"start\":20328},{\"end\":20379,\"start\":20360},{\"end\":20440,\"start\":20381},{\"end\":21375,\"start\":20442},{\"end\":21963,\"start\":21394},{\"end\":22576,\"start\":22031},{\"end\":23289,\"start\":22578},{\"end\":23585,\"start\":23335},{\"end\":23837,\"start\":23658},{\"end\":24882,\"start\":23848},{\"end\":25227,\"start\":24959},{\"end\":26398,\"start\":25278},{\"end\":26523,\"start\":26458},{\"end\":27199,\"start\":26588},{\"end\":27330,\"start\":27201},{\"end\":28829,\"start\":27373},{\"end\":28966,\"start\":28831},{\"end\":29236,\"start\":28968},{\"end\":29542,\"start\":29371},{\"end\":30094,\"start\":29725},{\"end\":30383,\"start\":30136},{\"end\":30643,\"start\":30445},{\"end\":31849,\"start\":30684},{\"end\":32068,\"start\":31886},{\"end\":32765,\"start\":32088},{\"end\":32876,\"start\":32767},{\"end\":33160,\"start\":32953},{\"end\":33508,\"start\":33162},{\"end\":33665,\"start\":33531},{\"end\":33799,\"start\":33708},{\"end\":34259,\"start\":33875},{\"end\":34731,\"start\":34261},{\"end\":35660,\"start\":34733},{\"end\":36421,\"start\":35689},{\"end\":37346,\"start\":36423},{\"end\":37780,\"start\":37421},{\"end\":37904,\"start\":37782},{\"end\":38232,\"start\":37906},{\"end\":38910,\"start\":38284},{\"end\":39388,\"start\":38912},{\"end\":39899,\"start\":39390},{\"end\":40346,\"start\":39901},{\"end\":41052,\"start\":40348},{\"end\":41610,\"start\":41124},{\"end\":42216,\"start\":41612},{\"end\":42945,\"start\":42218},{\"end\":43620,\"start\":42979},{\"end\":44265,\"start\":43622},{\"end\":44886,\"start\":44284},{\"end\":45319,\"start\":44888},{\"end\":46036,\"start\":45321},{\"end\":46701,\"start\":46070},{\"end\":48052,\"start\":46703},{\"end\":49281,\"start\":48102},{\"end\":49760,\"start\":49283},{\"end\":50429,\"start\":49804},{\"end\":51517,\"start\":50431},{\"end\":51689,\"start\":51554},{\"end\":52138,\"start\":51709},{\"end\":52498,\"start\":52140},{\"end\":53417,\"start\":52500},{\"end\":55053,\"start\":53446},{\"end\":55979,\"start\":55055},{\"end\":56862,\"start\":55994}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14982,\"start\":14949},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18679,\"start\":18613},{\"attributes\":{\"id\":\"formula_3\"},\"end\":22030,\"start\":21964},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23657,\"start\":23586},{\"attributes\":{\"id\":\"formula_5\"},\"end\":23847,\"start\":23838},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24958,\"start\":24883},{\"attributes\":{\"id\":\"formula_7\"},\"end\":26457,\"start\":26399},{\"attributes\":{\"id\":\"formula_8\"},\"end\":26587,\"start\":26524},{\"attributes\":{\"id\":\"formula_10\"},\"end\":29370,\"start\":29237},{\"attributes\":{\"id\":\"formula_11\"},\"end\":29724,\"start\":29543},{\"attributes\":{\"id\":\"formula_12\"},\"end\":30135,\"start\":30095},{\"attributes\":{\"id\":\"formula_13\"},\"end\":30444,\"start\":30384},{\"attributes\":{\"id\":\"formula_14\"},\"end\":32952,\"start\":32877},{\"attributes\":{\"id\":\"formula_15\"},\"end\":33530,\"start\":33509},{\"attributes\":{\"id\":\"formula_16\"},\"end\":33707,\"start\":33666},{\"attributes\":{\"id\":\"formula_17\"},\"end\":33874,\"start\":33800},{\"attributes\":{\"id\":\"formula_18\"},\"end\":37420,\"start\":37347}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":41450,\"start\":41443},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":42615,\"start\":42608},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":43130,\"start\":43123},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":43852,\"start\":43845},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":44885,\"start\":44878},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":45764,\"start\":45757},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":47480,\"start\":47473},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":48544,\"start\":48537},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":49055,\"start\":49048},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":50819,\"start\":50812},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":52195,\"start\":52188},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":54685,\"start\":54678}]", "section_header": "[{\"end\":1773,\"start\":1772},{\"attributes\":{\"n\":\"1\"},\"end\":1788,\"start\":1776},{\"attributes\":{\"n\":\"2\"},\"end\":9297,\"start\":9285},{\"attributes\":{\"n\":\"2.1\"},\"end\":9435,\"start\":9420},{\"attributes\":{\"n\":\"2.2\"},\"end\":11218,\"start\":11202},{\"attributes\":{\"n\":\"3\"},\"end\":14133,\"start\":14122},{\"attributes\":{\"n\":\"3.1\"},\"end\":14475,\"start\":14456},{\"attributes\":{\"n\":\"3.2\"},\"end\":15373,\"start\":15353},{\"attributes\":{\"n\":\"3.3\"},\"end\":17611,\"start\":17566},{\"end\":19655,\"start\":19587},{\"attributes\":{\"n\":\"3.3.1\"},\"end\":21392,\"start\":21378},{\"attributes\":{\"n\":\"3.3.2\"},\"end\":23333,\"start\":23292},{\"attributes\":{\"n\":\"3.3.3\"},\"end\":25276,\"start\":25230},{\"attributes\":{\"n\":\"3.4\"},\"end\":27371,\"start\":27333},{\"attributes\":{\"n\":\"3.5\"},\"end\":30682,\"start\":30646},{\"attributes\":{\"n\":\"4\"},\"end\":31884,\"start\":31852},{\"attributes\":{\"n\":\"4.1\"},\"end\":32086,\"start\":32071},{\"attributes\":{\"n\":\"4.2\"},\"end\":35687,\"start\":35663},{\"attributes\":{\"n\":\"5\"},\"end\":38258,\"start\":38235},{\"attributes\":{\"n\":\"5.1\"},\"end\":38282,\"start\":38261},{\"attributes\":{\"n\":\"5.2\"},\"end\":41075,\"start\":41055},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":41122,\"start\":41078},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":42977,\"start\":42948},{\"attributes\":{\"n\":\"5.2.3\"},\"end\":44282,\"start\":44268},{\"attributes\":{\"n\":\"5.2.4\"},\"end\":46068,\"start\":46039},{\"attributes\":{\"n\":\"5.2.5\"},\"end\":48100,\"start\":48055},{\"attributes\":{\"n\":\"5.3\"},\"end\":49802,\"start\":49763},{\"attributes\":{\"n\":\"6\"},\"end\":51552,\"start\":51520},{\"attributes\":{\"n\":\"6.1\"},\"end\":51707,\"start\":51692},{\"attributes\":{\"n\":\"6.2\"},\"end\":53444,\"start\":53420},{\"attributes\":{\"n\":\"7\"},\"end\":55992,\"start\":55982},{\"end\":56872,\"start\":56864},{\"end\":56968,\"start\":56960},{\"end\":57030,\"start\":57022},{\"end\":57155,\"start\":57147},{\"end\":57441,\"start\":57437},{\"end\":57719,\"start\":57711},{\"end\":57793,\"start\":57785},{\"end\":58142,\"start\":58133},{\"end\":58356,\"start\":58347},{\"end\":58575,\"start\":58566},{\"end\":58882,\"start\":58873},{\"end\":59090,\"start\":59081},{\"end\":59297,\"start\":59288},{\"end\":59521,\"start\":59510},{\"end\":59838,\"start\":59831},{\"end\":60403,\"start\":60392},{\"end\":61295,\"start\":61284},{\"end\":61669,\"start\":61658},{\"end\":62829,\"start\":62818},{\"end\":63886,\"start\":63875},{\"end\":64437,\"start\":64426},{\"end\":64609,\"start\":64598}]", "table": "[{\"end\":59829,\"start\":59621},{\"end\":60390,\"start\":59973},{\"end\":61282,\"start\":60455},{\"end\":61656,\"start\":61297},{\"end\":62816,\"start\":61811},{\"end\":63873,\"start\":63606},{\"end\":64424,\"start\":63938},{\"end\":64596,\"start\":64528},{\"end\":64808,\"start\":64672}]", "figure_caption": "[{\"end\":56958,\"start\":56874},{\"end\":57020,\"start\":56970},{\"end\":57145,\"start\":57032},{\"end\":57435,\"start\":57157},{\"end\":57709,\"start\":57442},{\"end\":57783,\"start\":57721},{\"end\":58131,\"start\":57795},{\"end\":58345,\"start\":58145},{\"end\":58564,\"start\":58359},{\"end\":58871,\"start\":58578},{\"end\":59079,\"start\":58885},{\"end\":59286,\"start\":59093},{\"end\":59508,\"start\":59300},{\"end\":59621,\"start\":59523},{\"end\":59973,\"start\":59840},{\"end\":60455,\"start\":60405},{\"end\":61811,\"start\":61671},{\"end\":63606,\"start\":62831},{\"end\":63938,\"start\":63888},{\"end\":64528,\"start\":64439},{\"end\":64672,\"start\":64611},{\"end\":65961,\"start\":64811}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6120,\"start\":6114},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15165,\"start\":15159},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16247,\"start\":16241},{\"end\":16773,\"start\":16766},{\"end\":17172,\"start\":17166},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":28089,\"start\":28083},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":28574,\"start\":28568},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":30178,\"start\":30172},{\"end\":34258,\"start\":34252},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":35369,\"start\":35363},{\"end\":36544,\"start\":36543},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":41506,\"start\":41500},{\"end\":44260,\"start\":44254},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":46188,\"start\":46181},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":47257,\"start\":47250},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":47534,\"start\":47527},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":48417,\"start\":48411},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":50831,\"start\":50824},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":51116,\"start\":51109},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":51292,\"start\":51285},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":52543,\"start\":52536},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":54039,\"start\":54032},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":54098,\"start\":54068},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":54110,\"start\":54103},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":54265,\"start\":54258},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":55377,\"start\":55370}]", "bib_author_first_name": "[{\"end\":66209,\"start\":66208},{\"end\":66216,\"start\":66215},{\"end\":66224,\"start\":66223},{\"end\":66230,\"start\":66229},{\"end\":66237,\"start\":66236},{\"end\":66244,\"start\":66243},{\"end\":66543,\"start\":66542},{\"end\":66553,\"start\":66552},{\"end\":66555,\"start\":66554},{\"end\":66565,\"start\":66564},{\"end\":66576,\"start\":66575},{\"end\":66578,\"start\":66577},{\"end\":66587,\"start\":66586},{\"end\":66602,\"start\":66601},{\"end\":66992,\"start\":66991},{\"end\":67009,\"start\":67008},{\"end\":67021,\"start\":67017},{\"end\":67300,\"start\":67299},{\"end\":67461,\"start\":67460},{\"end\":67463,\"start\":67462},{\"end\":67477,\"start\":67476},{\"end\":67487,\"start\":67486},{\"end\":67653,\"start\":67652},{\"end\":67655,\"start\":67654},{\"end\":67664,\"start\":67663},{\"end\":67673,\"start\":67672},{\"end\":67680,\"start\":67679},{\"end\":67689,\"start\":67688},{\"end\":67893,\"start\":67892},{\"end\":68247,\"start\":68246},{\"end\":68257,\"start\":68256},{\"end\":68272,\"start\":68271},{\"end\":68281,\"start\":68280},{\"end\":68283,\"start\":68282},{\"end\":68615,\"start\":68614},{\"end\":68625,\"start\":68624},{\"end\":68836,\"start\":68835},{\"end\":68846,\"start\":68845},{\"end\":68861,\"start\":68860},{\"end\":68870,\"start\":68869},{\"end\":68872,\"start\":68871},{\"end\":69147,\"start\":69146},{\"end\":69154,\"start\":69153},{\"end\":69162,\"start\":69161},{\"end\":69169,\"start\":69168},{\"end\":69177,\"start\":69176},{\"end\":69183,\"start\":69182},{\"end\":69410,\"start\":69409},{\"end\":69418,\"start\":69417},{\"end\":69425,\"start\":69424},{\"end\":69661,\"start\":69660},{\"end\":69669,\"start\":69668},{\"end\":69682,\"start\":69681},{\"end\":70083,\"start\":70082},{\"end\":70322,\"start\":70321},{\"end\":70333,\"start\":70332},{\"end\":70345,\"start\":70344},{\"end\":70354,\"start\":70353},{\"end\":70592,\"start\":70591},{\"end\":70603,\"start\":70602},{\"end\":70862,\"start\":70858},{\"end\":70882,\"start\":70881},{\"end\":70891,\"start\":70890},{\"end\":71250,\"start\":71249},{\"end\":71259,\"start\":71258},{\"end\":71270,\"start\":71269},{\"end\":71281,\"start\":71280},{\"end\":71292,\"start\":71291},{\"end\":71515,\"start\":71514},{\"end\":71525,\"start\":71524},{\"end\":71534,\"start\":71533},{\"end\":71764,\"start\":71763},{\"end\":72030,\"start\":72029},{\"end\":72037,\"start\":72036},{\"end\":72045,\"start\":72044},{\"end\":72052,\"start\":72051},{\"end\":72290,\"start\":72289},{\"end\":72298,\"start\":72297},{\"end\":72304,\"start\":72303},{\"end\":72311,\"start\":72310},{\"end\":72319,\"start\":72318},{\"end\":72670,\"start\":72669},{\"end\":72678,\"start\":72677},{\"end\":72684,\"start\":72683},{\"end\":72691,\"start\":72690},{\"end\":73751,\"start\":73750},{\"end\":74005,\"start\":74001},{\"end\":74013,\"start\":74012},{\"end\":74022,\"start\":74021},{\"end\":74032,\"start\":74031},{\"end\":74041,\"start\":74037},{\"end\":74457,\"start\":74456},{\"end\":74475,\"start\":74474},{\"end\":74484,\"start\":74483},{\"end\":74498,\"start\":74497},{\"end\":74790,\"start\":74789},{\"end\":74797,\"start\":74796},{\"end\":74808,\"start\":74807},{\"end\":74815,\"start\":74814},{\"end\":74817,\"start\":74816},{\"end\":74827,\"start\":74826},{\"end\":75146,\"start\":75145},{\"end\":75157,\"start\":75156},{\"end\":75167,\"start\":75166},{\"end\":75516,\"start\":75515},{\"end\":75525,\"start\":75524},{\"end\":75534,\"start\":75530},{\"end\":75542,\"start\":75541},{\"end\":75551,\"start\":75550},{\"end\":75560,\"start\":75556},{\"end\":75881,\"start\":75880},{\"end\":75892,\"start\":75891},{\"end\":75906,\"start\":75905},{\"end\":76097,\"start\":76096},{\"end\":76117,\"start\":76116},{\"end\":76128,\"start\":76127},{\"end\":76139,\"start\":76138},{\"end\":76460,\"start\":76459},{\"end\":76468,\"start\":76467},{\"end\":76476,\"start\":76475},{\"end\":76484,\"start\":76483},{\"end\":76491,\"start\":76490},{\"end\":76498,\"start\":76497},{\"end\":76766,\"start\":76762},{\"end\":76776,\"start\":76775},{\"end\":76778,\"start\":76777},{\"end\":76787,\"start\":76786},{\"end\":76793,\"start\":76792},{\"end\":77203,\"start\":77202},{\"end\":77219,\"start\":77218},{\"end\":77229,\"start\":77228},{\"end\":77241,\"start\":77240},{\"end\":77251,\"start\":77250},{\"end\":77591,\"start\":77590},{\"end\":77601,\"start\":77600},{\"end\":77613,\"start\":77612},{\"end\":77629,\"start\":77628},{\"end\":77639,\"start\":77638},{\"end\":77999,\"start\":77998},{\"end\":78341,\"start\":78340},{\"end\":78350,\"start\":78349},{\"end\":78362,\"start\":78361},{\"end\":78373,\"start\":78372},{\"end\":78764,\"start\":78763},{\"end\":78772,\"start\":78771},{\"end\":78778,\"start\":78777},{\"end\":78786,\"start\":78785},{\"end\":78796,\"start\":78795},{\"end\":78798,\"start\":78797},{\"end\":78805,\"start\":78804},{\"end\":79188,\"start\":79187},{\"end\":79376,\"start\":79375},{\"end\":79389,\"start\":79388},{\"end\":79391,\"start\":79390},{\"end\":79402,\"start\":79401},{\"end\":79413,\"start\":79412},{\"end\":79423,\"start\":79422},{\"end\":79646,\"start\":79645},{\"end\":79959,\"start\":79958},{\"end\":79968,\"start\":79964},{\"end\":79975,\"start\":79974},{\"end\":79977,\"start\":79976},{\"end\":79986,\"start\":79985},{\"end\":80338,\"start\":80337},{\"end\":80346,\"start\":80345},{\"end\":80356,\"start\":80355},{\"end\":80358,\"start\":80357},{\"end\":80371,\"start\":80367},{\"end\":80645,\"start\":80644},{\"end\":80656,\"start\":80655},{\"end\":80672,\"start\":80671},{\"end\":81005,\"start\":81004},{\"end\":81014,\"start\":81013},{\"end\":81357,\"start\":81356},{\"end\":81673,\"start\":81672},{\"end\":81679,\"start\":81678},{\"end\":81688,\"start\":81687},{\"end\":81696,\"start\":81695},{\"end\":81703,\"start\":81702},{\"end\":81999,\"start\":81998},{\"end\":82323,\"start\":82322},{\"end\":82330,\"start\":82329},{\"end\":82337,\"start\":82336},{\"end\":82343,\"start\":82342},{\"end\":82349,\"start\":82348},{\"end\":82356,\"start\":82355},{\"end\":82689,\"start\":82688},{\"end\":82695,\"start\":82694},{\"end\":82697,\"start\":82696},{\"end\":82707,\"start\":82706},{\"end\":82968,\"start\":82967},{\"end\":82977,\"start\":82976},{\"end\":82988,\"start\":82987},{\"end\":82999,\"start\":82998},{\"end\":83010,\"start\":83009},{\"end\":83355,\"start\":83354},{\"end\":83362,\"start\":83361},{\"end\":83369,\"start\":83368},{\"end\":83376,\"start\":83375},{\"end\":83384,\"start\":83383},{\"end\":83742,\"start\":83741},{\"end\":83749,\"start\":83748},{\"end\":83758,\"start\":83757},{\"end\":83767,\"start\":83766},{\"end\":83776,\"start\":83775},{\"end\":83782,\"start\":83781},{\"end\":84121,\"start\":84120},{\"end\":84131,\"start\":84130},{\"end\":84142,\"start\":84141},{\"end\":84154,\"start\":84153}]", "bib_author_last_name": "[{\"end\":66213,\"start\":66210},{\"end\":66221,\"start\":66217},{\"end\":66227,\"start\":66225},{\"end\":66234,\"start\":66231},{\"end\":66241,\"start\":66238},{\"end\":66254,\"start\":66245},{\"end\":66550,\"start\":66544},{\"end\":66562,\"start\":66556},{\"end\":66573,\"start\":66566},{\"end\":66584,\"start\":66579},{\"end\":66599,\"start\":66588},{\"end\":66614,\"start\":66603},{\"end\":67006,\"start\":66993},{\"end\":67015,\"start\":67010},{\"end\":67029,\"start\":67022},{\"end\":67308,\"start\":67301},{\"end\":67474,\"start\":67464},{\"end\":67484,\"start\":67478},{\"end\":67495,\"start\":67488},{\"end\":67661,\"start\":67656},{\"end\":67670,\"start\":67665},{\"end\":67677,\"start\":67674},{\"end\":67686,\"start\":67681},{\"end\":67696,\"start\":67690},{\"end\":67898,\"start\":67894},{\"end\":68254,\"start\":68248},{\"end\":68269,\"start\":68258},{\"end\":68278,\"start\":68273},{\"end\":68290,\"start\":68284},{\"end\":68622,\"start\":68616},{\"end\":68635,\"start\":68626},{\"end\":68843,\"start\":68837},{\"end\":68858,\"start\":68847},{\"end\":68867,\"start\":68862},{\"end\":68879,\"start\":68873},{\"end\":69151,\"start\":69148},{\"end\":69159,\"start\":69155},{\"end\":69166,\"start\":69163},{\"end\":69174,\"start\":69170},{\"end\":69180,\"start\":69178},{\"end\":69188,\"start\":69184},{\"end\":69415,\"start\":69411},{\"end\":69422,\"start\":69419},{\"end\":69429,\"start\":69426},{\"end\":69666,\"start\":69662},{\"end\":69679,\"start\":69670},{\"end\":69689,\"start\":69683},{\"end\":70086,\"start\":70084},{\"end\":70330,\"start\":70323},{\"end\":70342,\"start\":70334},{\"end\":70351,\"start\":70346},{\"end\":70359,\"start\":70355},{\"end\":70600,\"start\":70593},{\"end\":70610,\"start\":70604},{\"end\":70879,\"start\":70863},{\"end\":70888,\"start\":70883},{\"end\":70900,\"start\":70892},{\"end\":71256,\"start\":71251},{\"end\":71267,\"start\":71260},{\"end\":71278,\"start\":71271},{\"end\":71289,\"start\":71282},{\"end\":71298,\"start\":71293},{\"end\":71522,\"start\":71516},{\"end\":71531,\"start\":71526},{\"end\":71543,\"start\":71535},{\"end\":71769,\"start\":71765},{\"end\":72034,\"start\":72031},{\"end\":72042,\"start\":72038},{\"end\":72049,\"start\":72046},{\"end\":72057,\"start\":72053},{\"end\":72295,\"start\":72291},{\"end\":72301,\"start\":72299},{\"end\":72308,\"start\":72305},{\"end\":72316,\"start\":72312},{\"end\":72325,\"start\":72320},{\"end\":72675,\"start\":72671},{\"end\":72681,\"start\":72679},{\"end\":72688,\"start\":72685},{\"end\":72695,\"start\":72692},{\"end\":73141,\"start\":73138},{\"end\":73754,\"start\":73752},{\"end\":74010,\"start\":74006},{\"end\":74019,\"start\":74014},{\"end\":74029,\"start\":74023},{\"end\":74035,\"start\":74033},{\"end\":74047,\"start\":74042},{\"end\":74472,\"start\":74458},{\"end\":74481,\"start\":74476},{\"end\":74495,\"start\":74485},{\"end\":74503,\"start\":74499},{\"end\":74794,\"start\":74791},{\"end\":74805,\"start\":74798},{\"end\":74812,\"start\":74809},{\"end\":74824,\"start\":74818},{\"end\":74838,\"start\":74828},{\"end\":75154,\"start\":75147},{\"end\":75164,\"start\":75158},{\"end\":75174,\"start\":75168},{\"end\":75522,\"start\":75517},{\"end\":75528,\"start\":75526},{\"end\":75539,\"start\":75535},{\"end\":75548,\"start\":75543},{\"end\":75554,\"start\":75552},{\"end\":75566,\"start\":75561},{\"end\":75889,\"start\":75882},{\"end\":75903,\"start\":75893},{\"end\":75913,\"start\":75907},{\"end\":76114,\"start\":76098},{\"end\":76125,\"start\":76118},{\"end\":76136,\"start\":76129},{\"end\":76148,\"start\":76140},{\"end\":76465,\"start\":76461},{\"end\":76473,\"start\":76469},{\"end\":76481,\"start\":76477},{\"end\":76488,\"start\":76485},{\"end\":76495,\"start\":76492},{\"end\":76504,\"start\":76499},{\"end\":76773,\"start\":76767},{\"end\":76784,\"start\":76779},{\"end\":76790,\"start\":76788},{\"end\":76798,\"start\":76794},{\"end\":77216,\"start\":77204},{\"end\":77226,\"start\":77220},{\"end\":77238,\"start\":77230},{\"end\":77248,\"start\":77242},{\"end\":77261,\"start\":77252},{\"end\":77598,\"start\":77592},{\"end\":77610,\"start\":77602},{\"end\":77626,\"start\":77614},{\"end\":77636,\"start\":77630},{\"end\":77649,\"start\":77640},{\"end\":78007,\"start\":78000},{\"end\":78347,\"start\":78342},{\"end\":78359,\"start\":78351},{\"end\":78370,\"start\":78363},{\"end\":78381,\"start\":78374},{\"end\":78769,\"start\":78765},{\"end\":78775,\"start\":78773},{\"end\":78783,\"start\":78779},{\"end\":78793,\"start\":78787},{\"end\":78802,\"start\":78799},{\"end\":78810,\"start\":78806},{\"end\":79196,\"start\":79189},{\"end\":79386,\"start\":79377},{\"end\":79399,\"start\":79392},{\"end\":79410,\"start\":79403},{\"end\":79420,\"start\":79414},{\"end\":79430,\"start\":79424},{\"end\":79651,\"start\":79647},{\"end\":79962,\"start\":79960},{\"end\":79972,\"start\":79969},{\"end\":79983,\"start\":79978},{\"end\":79996,\"start\":79987},{\"end\":80343,\"start\":80339},{\"end\":80353,\"start\":80347},{\"end\":80365,\"start\":80359},{\"end\":80377,\"start\":80372},{\"end\":80653,\"start\":80646},{\"end\":80669,\"start\":80657},{\"end\":80680,\"start\":80673},{\"end\":81011,\"start\":81006},{\"end\":81021,\"start\":81015},{\"end\":81360,\"start\":81358},{\"end\":81676,\"start\":81674},{\"end\":81685,\"start\":81680},{\"end\":81693,\"start\":81689},{\"end\":81700,\"start\":81697},{\"end\":81709,\"start\":81704},{\"end\":82004,\"start\":82000},{\"end\":82327,\"start\":82324},{\"end\":82334,\"start\":82331},{\"end\":82340,\"start\":82338},{\"end\":82346,\"start\":82344},{\"end\":82353,\"start\":82350},{\"end\":82361,\"start\":82357},{\"end\":82692,\"start\":82690},{\"end\":82704,\"start\":82698},{\"end\":82715,\"start\":82708},{\"end\":82974,\"start\":82969},{\"end\":82985,\"start\":82978},{\"end\":82996,\"start\":82989},{\"end\":83007,\"start\":83000},{\"end\":83016,\"start\":83011},{\"end\":83359,\"start\":83356},{\"end\":83366,\"start\":83363},{\"end\":83373,\"start\":83370},{\"end\":83381,\"start\":83377},{\"end\":83389,\"start\":83385},{\"end\":83746,\"start\":83743},{\"end\":83755,\"start\":83750},{\"end\":83764,\"start\":83759},{\"end\":83773,\"start\":83768},{\"end\":83779,\"start\":83777},{\"end\":83785,\"start\":83783},{\"end\":84128,\"start\":84122},{\"end\":84139,\"start\":84132},{\"end\":84151,\"start\":84143},{\"end\":84162,\"start\":84155}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":209501181},\"end\":66490,\"start\":66163},{\"attributes\":{\"doi\":\"10.1109/TPAMI.2021.3059968\",\"id\":\"b1\",\"matched_paper_id\":210702798},\"end\":66937,\"start\":66492},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":10137425},\"end\":67255,\"start\":66939},{\"attributes\":{\"doi\":\"arXiv:1312.6199\",\"id\":\"b3\"},\"end\":67410,\"start\":67257},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b4\"},\"end\":67631,\"start\":67412},{\"attributes\":{\"doi\":\"arXiv:1712.09665\",\"id\":\"b5\"},\"end\":67814,\"start\":67633},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":104291897},\"end\":68156,\"start\":67816},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207241700},\"end\":68547,\"start\":68158},{\"attributes\":{\"doi\":\"arXiv:1908.08705\",\"id\":\"b8\"},\"end\":68771,\"start\":68549},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":132058467},\"end\":69087,\"start\":68773},{\"attributes\":{\"doi\":\"arXiv:1806.02299\",\"id\":\"b10\"},\"end\":69342,\"start\":69089},{\"attributes\":{\"doi\":\"arXiv:2010.14974\",\"id\":\"b11\"},\"end\":69570,\"start\":69344},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":121124946},\"end\":70013,\"start\":69572},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":208310168},\"end\":70277,\"start\":70015},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":2645819},\"end\":70535,\"start\":70279},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":2893830},\"end\":70787,\"start\":70537},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":12387176},\"end\":71184,\"start\":70789},{\"attributes\":{\"doi\":\"arXiv:1706.06083\",\"id\":\"b17\"},\"end\":71464,\"start\":71186},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":3641286},\"end\":71717,\"start\":71466},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":4119221},\"end\":71957,\"start\":71719},{\"attributes\":{\"doi\":\"arXiv:1611.02770\",\"id\":\"b20\"},\"end\":72208,\"start\":71959},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":210714099},\"end\":72583,\"start\":72210},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":222379599},\"end\":72944,\"start\":72585},{\"attributes\":{\"id\":\"b23\"},\"end\":73675,\"start\":72946},{\"attributes\":{\"doi\":\"arXiv:1802.09707\",\"id\":\"b24\"},\"end\":73884,\"start\":73677},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2179389},\"end\":74373,\"start\":73886},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":208527215},\"end\":74749,\"start\":74375},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":86541092},\"end\":75047,\"start\":74751},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":2410333},\"end\":75437,\"start\":75049},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":49672236},\"end\":75834,\"start\":75439},{\"attributes\":{\"doi\":\"arXiv:1607.02533\",\"id\":\"b30\"},\"end\":76042,\"start\":75836},{\"attributes\":{\"id\":\"b31\"},\"end\":76388,\"start\":76044},{\"attributes\":{\"doi\":\"arXiv:1803.04683\",\"id\":\"b32\"},\"end\":76673,\"start\":76390},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":214641445},\"end\":77150,\"start\":76675},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":204509675},\"end\":77506,\"start\":77152},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":204734223},\"end\":77926,\"start\":77508},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":29162614},\"end\":78262,\"start\":77928},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":229363390},\"end\":78686,\"start\":78264},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":213175526},\"end\":79123,\"start\":78688},{\"attributes\":{\"doi\":\"arXiv:1712.08062\",\"id\":\"b39\"},\"end\":79322,\"start\":79125},{\"attributes\":{\"doi\":\"arXiv:1802.06430\",\"id\":\"b40\"},\"end\":79591,\"start\":79324},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":49904930},\"end\":79874,\"start\":79593},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":207757900},\"end\":80234,\"start\":79876},{\"attributes\":{\"doi\":\"arXiv:2010.04145\",\"id\":\"b43\"},\"end\":80576,\"start\":80236},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":206592766},\"end\":80953,\"start\":80578},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":203705211},\"end\":81283,\"start\":80955},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":232110811},\"end\":81623,\"start\":81285},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":15883006},\"end\":81935,\"start\":81625},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":68589},\"end\":82259,\"start\":81937},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":206596594},\"end\":82635,\"start\":82261},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":2698863},\"end\":82902,\"start\":82637},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":3488815},\"end\":83266,\"start\":82904},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":206593370},\"end\":83685,\"start\":83268},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":3355585},\"end\":84061,\"start\":83687},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":206594738},\"end\":84435,\"start\":84063}]", "bib_title": "[{\"end\":66206,\"start\":66163},{\"end\":66540,\"start\":66492},{\"end\":66989,\"start\":66939},{\"end\":67890,\"start\":67816},{\"end\":68244,\"start\":68158},{\"end\":68833,\"start\":68773},{\"end\":69658,\"start\":69572},{\"end\":70080,\"start\":70015},{\"end\":70319,\"start\":70279},{\"end\":70589,\"start\":70537},{\"end\":70856,\"start\":70789},{\"end\":71512,\"start\":71466},{\"end\":71761,\"start\":71719},{\"end\":72287,\"start\":72210},{\"end\":72667,\"start\":72585},{\"end\":73999,\"start\":73886},{\"end\":74454,\"start\":74375},{\"end\":74787,\"start\":74751},{\"end\":75143,\"start\":75049},{\"end\":75513,\"start\":75439},{\"end\":76760,\"start\":76675},{\"end\":77200,\"start\":77152},{\"end\":77588,\"start\":77508},{\"end\":77996,\"start\":77928},{\"end\":78338,\"start\":78264},{\"end\":78761,\"start\":78688},{\"end\":79643,\"start\":79593},{\"end\":79956,\"start\":79876},{\"end\":80642,\"start\":80578},{\"end\":81002,\"start\":80955},{\"end\":81354,\"start\":81285},{\"end\":81670,\"start\":81625},{\"end\":81996,\"start\":81937},{\"end\":82320,\"start\":82261},{\"end\":82686,\"start\":82637},{\"end\":82965,\"start\":82904},{\"end\":83352,\"start\":83268},{\"end\":83739,\"start\":83687},{\"end\":84118,\"start\":84063}]", "bib_author": "[{\"end\":66215,\"start\":66208},{\"end\":66223,\"start\":66215},{\"end\":66229,\"start\":66223},{\"end\":66236,\"start\":66229},{\"end\":66243,\"start\":66236},{\"end\":66256,\"start\":66243},{\"end\":66552,\"start\":66542},{\"end\":66564,\"start\":66552},{\"end\":66575,\"start\":66564},{\"end\":66586,\"start\":66575},{\"end\":66601,\"start\":66586},{\"end\":66616,\"start\":66601},{\"end\":67008,\"start\":66991},{\"end\":67017,\"start\":67008},{\"end\":67031,\"start\":67017},{\"end\":67310,\"start\":67299},{\"end\":67476,\"start\":67460},{\"end\":67486,\"start\":67476},{\"end\":67497,\"start\":67486},{\"end\":67663,\"start\":67652},{\"end\":67672,\"start\":67663},{\"end\":67679,\"start\":67672},{\"end\":67688,\"start\":67679},{\"end\":67698,\"start\":67688},{\"end\":67900,\"start\":67892},{\"end\":68256,\"start\":68246},{\"end\":68271,\"start\":68256},{\"end\":68280,\"start\":68271},{\"end\":68292,\"start\":68280},{\"end\":68624,\"start\":68614},{\"end\":68637,\"start\":68624},{\"end\":68845,\"start\":68835},{\"end\":68860,\"start\":68845},{\"end\":68869,\"start\":68860},{\"end\":68881,\"start\":68869},{\"end\":69153,\"start\":69146},{\"end\":69161,\"start\":69153},{\"end\":69168,\"start\":69161},{\"end\":69176,\"start\":69168},{\"end\":69182,\"start\":69176},{\"end\":69190,\"start\":69182},{\"end\":69417,\"start\":69409},{\"end\":69424,\"start\":69417},{\"end\":69431,\"start\":69424},{\"end\":69668,\"start\":69660},{\"end\":69681,\"start\":69668},{\"end\":69691,\"start\":69681},{\"end\":70088,\"start\":70082},{\"end\":70332,\"start\":70321},{\"end\":70344,\"start\":70332},{\"end\":70353,\"start\":70344},{\"end\":70361,\"start\":70353},{\"end\":70602,\"start\":70591},{\"end\":70612,\"start\":70602},{\"end\":70881,\"start\":70858},{\"end\":70890,\"start\":70881},{\"end\":70902,\"start\":70890},{\"end\":71258,\"start\":71249},{\"end\":71269,\"start\":71258},{\"end\":71280,\"start\":71269},{\"end\":71291,\"start\":71280},{\"end\":71300,\"start\":71291},{\"end\":71524,\"start\":71514},{\"end\":71533,\"start\":71524},{\"end\":71545,\"start\":71533},{\"end\":71771,\"start\":71763},{\"end\":72036,\"start\":72029},{\"end\":72044,\"start\":72036},{\"end\":72051,\"start\":72044},{\"end\":72059,\"start\":72051},{\"end\":72297,\"start\":72289},{\"end\":72303,\"start\":72297},{\"end\":72310,\"start\":72303},{\"end\":72318,\"start\":72310},{\"end\":72327,\"start\":72318},{\"end\":72677,\"start\":72669},{\"end\":72683,\"start\":72677},{\"end\":72690,\"start\":72683},{\"end\":72697,\"start\":72690},{\"end\":73143,\"start\":73138},{\"end\":73756,\"start\":73750},{\"end\":74012,\"start\":74001},{\"end\":74021,\"start\":74012},{\"end\":74031,\"start\":74021},{\"end\":74037,\"start\":74031},{\"end\":74049,\"start\":74037},{\"end\":74474,\"start\":74456},{\"end\":74483,\"start\":74474},{\"end\":74497,\"start\":74483},{\"end\":74505,\"start\":74497},{\"end\":74796,\"start\":74789},{\"end\":74807,\"start\":74796},{\"end\":74814,\"start\":74807},{\"end\":74826,\"start\":74814},{\"end\":74840,\"start\":74826},{\"end\":75156,\"start\":75145},{\"end\":75166,\"start\":75156},{\"end\":75176,\"start\":75166},{\"end\":75524,\"start\":75515},{\"end\":75530,\"start\":75524},{\"end\":75541,\"start\":75530},{\"end\":75550,\"start\":75541},{\"end\":75556,\"start\":75550},{\"end\":75568,\"start\":75556},{\"end\":75891,\"start\":75880},{\"end\":75905,\"start\":75891},{\"end\":75915,\"start\":75905},{\"end\":76116,\"start\":76096},{\"end\":76127,\"start\":76116},{\"end\":76138,\"start\":76127},{\"end\":76150,\"start\":76138},{\"end\":76467,\"start\":76459},{\"end\":76475,\"start\":76467},{\"end\":76483,\"start\":76475},{\"end\":76490,\"start\":76483},{\"end\":76497,\"start\":76490},{\"end\":76506,\"start\":76497},{\"end\":76775,\"start\":76762},{\"end\":76786,\"start\":76775},{\"end\":76792,\"start\":76786},{\"end\":76800,\"start\":76792},{\"end\":77218,\"start\":77202},{\"end\":77228,\"start\":77218},{\"end\":77240,\"start\":77228},{\"end\":77250,\"start\":77240},{\"end\":77263,\"start\":77250},{\"end\":77600,\"start\":77590},{\"end\":77612,\"start\":77600},{\"end\":77628,\"start\":77612},{\"end\":77638,\"start\":77628},{\"end\":77651,\"start\":77638},{\"end\":78009,\"start\":77998},{\"end\":78349,\"start\":78340},{\"end\":78361,\"start\":78349},{\"end\":78372,\"start\":78361},{\"end\":78383,\"start\":78372},{\"end\":78771,\"start\":78763},{\"end\":78777,\"start\":78771},{\"end\":78785,\"start\":78777},{\"end\":78795,\"start\":78785},{\"end\":78804,\"start\":78795},{\"end\":78812,\"start\":78804},{\"end\":79198,\"start\":79187},{\"end\":79388,\"start\":79375},{\"end\":79401,\"start\":79388},{\"end\":79412,\"start\":79401},{\"end\":79422,\"start\":79412},{\"end\":79432,\"start\":79422},{\"end\":79653,\"start\":79645},{\"end\":79964,\"start\":79958},{\"end\":79974,\"start\":79964},{\"end\":79985,\"start\":79974},{\"end\":79998,\"start\":79985},{\"end\":80345,\"start\":80337},{\"end\":80355,\"start\":80345},{\"end\":80367,\"start\":80355},{\"end\":80379,\"start\":80367},{\"end\":80655,\"start\":80644},{\"end\":80671,\"start\":80655},{\"end\":80682,\"start\":80671},{\"end\":81013,\"start\":81004},{\"end\":81023,\"start\":81013},{\"end\":81362,\"start\":81356},{\"end\":81678,\"start\":81672},{\"end\":81687,\"start\":81678},{\"end\":81695,\"start\":81687},{\"end\":81702,\"start\":81695},{\"end\":81711,\"start\":81702},{\"end\":82006,\"start\":81998},{\"end\":82329,\"start\":82322},{\"end\":82336,\"start\":82329},{\"end\":82342,\"start\":82336},{\"end\":82348,\"start\":82342},{\"end\":82355,\"start\":82348},{\"end\":82363,\"start\":82355},{\"end\":82694,\"start\":82688},{\"end\":82706,\"start\":82694},{\"end\":82717,\"start\":82706},{\"end\":82976,\"start\":82967},{\"end\":82987,\"start\":82976},{\"end\":82998,\"start\":82987},{\"end\":83009,\"start\":82998},{\"end\":83018,\"start\":83009},{\"end\":83361,\"start\":83354},{\"end\":83368,\"start\":83361},{\"end\":83375,\"start\":83368},{\"end\":83383,\"start\":83375},{\"end\":83391,\"start\":83383},{\"end\":83748,\"start\":83741},{\"end\":83757,\"start\":83748},{\"end\":83766,\"start\":83757},{\"end\":83775,\"start\":83766},{\"end\":83781,\"start\":83775},{\"end\":83787,\"start\":83781},{\"end\":84130,\"start\":84120},{\"end\":84141,\"start\":84130},{\"end\":84153,\"start\":84141},{\"end\":84164,\"start\":84153}]", "bib_venue": "[{\"end\":67988,\"start\":67948},{\"end\":68330,\"start\":68315},{\"end\":69801,\"start\":69750},{\"end\":70140,\"start\":70118},{\"end\":70648,\"start\":70634},{\"end\":70990,\"start\":70950},{\"end\":71823,\"start\":71801},{\"end\":74133,\"start\":74095},{\"end\":74557,\"start\":74535},{\"end\":74892,\"start\":74870},{\"end\":75250,\"start\":75217},{\"end\":75642,\"start\":75609},{\"end\":76930,\"start\":76869},{\"end\":77311,\"start\":77291},{\"end\":77699,\"start\":77679},{\"end\":78097,\"start\":78057},{\"end\":78479,\"start\":78435},{\"end\":78908,\"start\":78864},{\"end\":79737,\"start\":79699},{\"end\":80050,\"start\":80028},{\"end\":80770,\"start\":80730},{\"end\":81129,\"start\":81080},{\"end\":81458,\"start\":81414},{\"end\":81779,\"start\":81749},{\"end\":82102,\"start\":82058},{\"end\":82451,\"start\":82411},{\"end\":83092,\"start\":83059},{\"end\":83479,\"start\":83439},{\"end\":83875,\"start\":83835},{\"end\":84252,\"start\":84212},{\"end\":66294,\"start\":66256},{\"end\":66695,\"start\":66642},{\"end\":67069,\"start\":67031},{\"end\":67297,\"start\":67257},{\"end\":67458,\"start\":67412},{\"end\":67650,\"start\":67633},{\"end\":67946,\"start\":67900},{\"end\":68313,\"start\":68292},{\"end\":68612,\"start\":68549},{\"end\":68905,\"start\":68881},{\"end\":69144,\"start\":69089},{\"end\":69407,\"start\":69344},{\"end\":69748,\"start\":69691},{\"end\":70116,\"start\":70088},{\"end\":70389,\"start\":70361},{\"end\":70632,\"start\":70612},{\"end\":70948,\"start\":70902},{\"end\":71247,\"start\":71186},{\"end\":71573,\"start\":71545},{\"end\":71799,\"start\":71771},{\"end\":72027,\"start\":71959},{\"end\":72365,\"start\":72327},{\"end\":72735,\"start\":72697},{\"end\":73136,\"start\":72946},{\"end\":73748,\"start\":73677},{\"end\":74093,\"start\":74049},{\"end\":74533,\"start\":74505},{\"end\":74868,\"start\":74840},{\"end\":75215,\"start\":75176},{\"end\":75607,\"start\":75568},{\"end\":75878,\"start\":75836},{\"end\":76094,\"start\":76044},{\"end\":76457,\"start\":76390},{\"end\":76867,\"start\":76800},{\"end\":77289,\"start\":77263},{\"end\":77677,\"start\":77651},{\"end\":78055,\"start\":78009},{\"end\":78433,\"start\":78383},{\"end\":78862,\"start\":78812},{\"end\":79185,\"start\":79125},{\"end\":79373,\"start\":79324},{\"end\":79697,\"start\":79653},{\"end\":80026,\"start\":79998},{\"end\":80335,\"start\":80236},{\"end\":80728,\"start\":80682},{\"end\":81078,\"start\":81023},{\"end\":81412,\"start\":81362},{\"end\":81747,\"start\":81711},{\"end\":82056,\"start\":82006},{\"end\":82409,\"start\":82363},{\"end\":82741,\"start\":82717},{\"end\":83057,\"start\":83018},{\"end\":83437,\"start\":83391},{\"end\":83833,\"start\":83787},{\"end\":84210,\"start\":84164}]"}}}, "year": 2023, "month": 12, "day": 17}