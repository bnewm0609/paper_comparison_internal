{"id": 9803807, "updated": "2023-09-30 15:26:21.179", "metadata": {"title": "Maximum-Likelihood Augmented Discrete Generative Adversarial Networks", "authors": "[{\"first\":\"Tong\",\"last\":\"Che\",\"middle\":[]},{\"first\":\"Yanran\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Ruixiang\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"R\",\"last\":\"Hjelm\",\"middle\":[\"Devon\"]},{\"first\":\"Wenjie\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Yangqiu\",\"last\":\"Song\",\"middle\":[]},{\"first\":\"Yoshua\",\"last\":\"Bengio\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2017, "month": 2, "day": 26}, "abstract": "Despite the successes in capturing continuous distributions, the application of generative adversarial networks (GANs) to discrete settings, like natural language tasks, is rather restricted. The fundamental reason is the difficulty of back-propagation through discrete random variables combined with the inherent instability of the GAN training objective. To address these problems, we propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks. Instead of directly optimizing the GAN objective, we derive a novel and low-variance objective using the discriminator's output that follows corresponds to the log-likelihood. Compared with the original, the new objective is proved to be consistent in theory and beneficial in practice. The experimental results on various discrete datasets demonstrate the effectiveness of the proposed approach.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1702.07983", "mag": "2593383075", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/CheLZHLSB17", "doi": null}}, "content": {"source": {"pdf_hash": "4fc0ea6db600850908264652e1a5d7904f66ca58", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1702.07983v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "e3f78709c54f9d6c632925b3ebe719c3701c32c4", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4fc0ea6db600850908264652e1a5d7904f66ca58.txt", "contents": "\nMaximum-Likelihood Augmented Discrete Generative Adversarial Networks\n\n\nTong Che \nYanran Li \nRuixiang Zhang \nDevon Hjelm \nWenjie Li \nYangqiu Song \nYoshua Bengio \nMaximum-Likelihood Augmented Discrete Generative Adversarial Networks\n\nDespite the successes in capturing continuous distributions, the application of generative adversarial networks (GANs) to discrete settings, like natural language tasks, is rather restricted.\n\nIntroduction\n\nGenerative models are appealing because they provide ways to obtain insights on the underlying data distribution and statistics. In particular, these models play a pivot role in many natural language processing tasks such as language modeling, machine translation, and dialogue generation. However, the generated sentences are often unsatisfactory (Sordoni et al., 2015;Bowman et al., 2015;Serban et al., 2017;Wiseman & Rush, 2016). For example, they often lack of consistency in long-term semantics and have less coherence in high-level topics and syntactics (Bowman et al., 2015;Zhang et al., 2016a). This is largely attributed to the defect in the dominant training approach for existing discrete generative models. To generate discrete sequences, it is popular to adopt autoregressive models through teacher forcing (Williams & Zipser, 1989) which, nevertheless, causes the exposure bias problem (Ranzato et al., 2016). The existing approach trains auto-regressive models to maximize the conditional probabilities of next tokens based on the ground-truth histories. In other words, during training, auto-regressive generative models are only exposed to the ground truths from the data distribution rather than those from the model distribution, i.e., its own predictions. It prohibits the trained model to take advantage of learning in the the context of its previous generated words to make the next prediction, resulting in a bias and difficulty in approaching the true underlying distribution (Ranzato et al., 2016;Bengio et al., 2015). Another limitation of teacher forcing is that it is inapplicable to those auto-regressive models with latent random variables, which have performed better than autoregressive (deterministic state) recurrent neural networks (i.e. usual RNNs, LSTMs or GRUs) on multiple tasks (Serban et al., 2017;Miao et al., 2016;Zhang et al., 2016a).\n\nAn alternative and attractive solution to training autoregressive models is using generative adversarial networks (GAN) (Goodfellow et al., 2014). The above discussed problem can be prevented if the generative models were able to visit its own predictions during training and had an overall view on the generated sequences. We suggest to facilitate the training of autoregressive models with an additional discriminator under the GAN setting. With a discriminator trained to separate real versus generated sequences, the generative model is able to make use of the knowledge of the discriminator to improve itself. Since the discriminator is trained on the entire sequence, it can in principle provide the training signal to avoid the problem of exposure bias.\n\nHowever, it is nontrivial to apply GANs to discrete data as it is difficult to optimize of the generator using the signal provided by the discriminator. In fact, it is usually very hard to push the generated distribution to the real data distribution, if not impossible, by moving the generated sequence (e.g., a faulty sentence) towards a \"true\" one (e.g., a correct sentence) in a high dimensional discrete state space. As standard back-propagation fails in discrete settings, the generator can be optimized using the discriminator's output as a reward via reinforcement learning. Unfortunately, arXiv:1702.07983v1 [cs.AI] 26 Feb 2017 even with careful pre-training, we found that the policy has difficulties to get positive and stable reward signals from the discriminator.\n\nTo tackle these limitations, we propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks (MaliGAN). At the core of this model is the novel GAN training objective which sidesteps the stability issue happening when using the discriminator output as a direct reinforcement learning reward. Alternatively, we develop a normalized maximum likelihood optimization target inspired by (Norouzi et al., 2016b). We use importance sampling and several variance reduction techniques in order to successfully optimize this objective. The procedure was discovered independently from us by Hjelm et al. (2017) in the context of image generation.\n\nThe new target brings several attractive properties in the proposed MaliGAN. First, it is theoretically consistent and easier to optimize (Section 3.2). Second, it allows the model not only to maximize the likelihood of good behaviors, but also to minimize the likelihood of bad behaviors, with the help of a GAN discriminator. Equipped with these strengths, the model focuses more on improving itself by gaining beneficial knowledge that is not yet well acquired, and excluding the most probable and harmful behaviors. Combined with several proposed variance reduction techniques, the proposed MaliGAN successfully and stably models discrete data sequences (Section 4).\n\n\nPreliminaries and Overview\n\nThe basic framework for discrete sequence generation is to fit a set of data {x i } N i=1 coming from an underlying generating distribution p d by training a parameterized autoregressive probabilistic model p \u03b8 .\n\nIn this work, we aim to generate discrete data, especially discrete sequential data, under the GAN setting (Goodfellow et al., 2014). GAN defines a framework for training generative models by posing it as a minimax game against a discriminative model. The goal of the generator G is to match its distribution p g to the real data distribution p d . To achieve this, the generator transforms noise z sampled from p(z) to a data sample G(z). Following this, the discriminator D is trained to distinguish between the samples coming from p d and p g , and can be used to provide a training signal to the generator.\n\nWhen applying the GAN framework to discrete data, the discontinuity prohibits the update of the generator parameters via standard back-propagation. To tackle this, one way is to employ a typical reinforcement learning (RL) strategy that directly uses the GAN discriminator's output, D or log D as a reward. In practice, the problem is usually solved by REINFORCE-like algorithms (Williams, 1992), perhaps with some variance reduction techniques.\n\nFormally, we train a generator G(x) together with a discriminator D(x). In its original form, the discriminator is trained to distinguish between the generating distribution p \u03b8 and the real data distribution p d . The generator is then trained to maximize E x\u223cp \u03b8 [log D(x)]. Namely, the objective for the generator to optimize is as follows:\n\nLGAN\n(\u03b8) = \u2212Ex\u223cp \u03b8 [log D(x)] \u2248 \u2212 1 n n i=1 log D(xi), xi \u223c p \u03b8 .\nOur work is related to the viewpoint of casting the GAN training as a reinforcement learning problem with a moving reward signal monotone in D(x). Define the normalized probability distribution q (x) = 1 Z(D) D(x) 1/\u03c4 in some bounded region to guarantee integrability (note that D is an approximation to p d p+p d if D is well trained) and also put a maximum-entropy regularizer H(p \u03b8 ) to encourage diversity, yielding the regularized loss:\n\nLGAN\n(\u03b8) = \u2212Ex\u223cp \u03b8 [log D(x)] \u2212 \u03c4 H(p \u03b8 ) = \u03c4 KL(p \u03b8 ||q ) + c(D)(1)\nwhere c(D) is a constant depending only on D. Hence, optimizing the traditional GAN is basically equivalent to optimizing the KL-divergence KL(p \u03b8 ||q ). One major problem with this approach is that q always moves with D, which is undesirable for both stability and convergence. When we have some samples x i \u223c p \u03b8 , we want to change \u03b8 a bit in order to adjust the likelihood of samples x i to improve the quality of the generator. However, since initially p generates very bad sequences, it have little chance of generating good sequences in order to get positive rewards. Though the dedicated pre-training and variance reduction mechanisms help (Yu et al., 2017), the RL algorithm based on the moving reward signal still seems very unstable and does not work on large scale datasets.\n\nWe therefore propose to utilize the information of the discriminator as an additional source of training signals, on top of the maximum-likelihood objective. We employ importance sampling to make the objective trainable. The novel training objective has much less variance than that in vanilla reinforcement learning approaches that directly adopt D or log D as reward signals. The analysis and discussions will be presented in more detail in Section 3.2.\n\n\nMaximum-Likelihood Augmented Discrete Generative Adversarial Networks\n\nIn this section, we present the details of the proposed model. At the heart of this model is a novel training ob-jective that significantly reduces the variance during training, including the theoretical and practical analysis on the objective's equivalence and attractive properties. We also show how this core algorithm can be combined with several variance reduction techniques to form the full MaliGAN algorithm for discrete sequence generation.\n\n\nBasic Model of MaliGAN\n\nWe propose Maximum-Likelihood Augmented Discrete Generative Adversarial Networks (MaliGAN) to generate the discrete data. With MaliGAN, we train a discriminator D(x) with the standard objective that GAN employs. What is different from GANs is a novel objective for the generator to optimize, using importance sampling, which makes the training procedure closer to maximum likelihood (MLE) training of auto-regressive models, and thus being more stable and with less variance in the gradients.\n\nTo do so, we keep a delayed copy p (x) of the generator whose parameters are updated less often in order to stabilize training. From the basic property of GANs, we know that an optimal D has the property D(x) = p d p d +p . So in this case, we have p d = D 1\u2212D p . Therefore, we set the target distribution q for maximum likelihood training to be\nD 1\u2212D p . Let r D (x) = D(x) 1\u2212D(x)\n, we define the augmented target distribution as:\nq(x) = 1 Z(\u03b8 ) D(x) 1 \u2212 D(x) p (x) = r D (x) Z(\u03b8 ) p (x)\nRegarding q as a fixed probability distribution, then the target to optimize is:\nL G (\u03b8) = KL(q(x)||p \u03b8 (x))\nThis objective has an attractive property that q is a \"fixed\" distribution during training, i.e., if D is sufficiently trained, then q is always approximately the data generating distribution p d . By defining the gradient as \u2207L G = E q [\u2207 \u03b8 log p \u03b8 (x)], we have the following importance sampling formula:\n\u2207L G = E p [ q(x) p (x) \u2207 \u03b8 log p \u03b8 (x)] = 1 Z E p \u03b8 [r D (x)\u2207 \u03b8 log p \u03b8 (x)]\nwhere we assume that p = p \u03b8 and the delayed generator is only one step behind the current update in the experiments. This importance sampling procedure was discovered independently from us by (Hjelm et al., 2017). We propose to optimize the generator using the following novel gradient estimator:\n\u2207L G (\u03b8) \u2248 m i=1 ( r D (x i ) i r D (x i ) \u2212 b)\u2207 log p \u03b8 (x i ) = E({x i } m 1 )(2)\nwhere b is a baseline from reinforcement learning in order to reduce variance. In practice, we let b increase very slowly from 0 to 1. Combined with the objective of the discriminator in an ordinary GAN, we get the proposed Mali-GAN algorithm as shown in Algorithm 1.\n\n\nAlgorithm 1 MaliGAN\n\nRequire: A generator p with parameters \u03b8.\nA discriminator D(x) with parameters \u03b8 d . A baseline b. 1: for number of training iterations do 2: for k steps do 3: Sample a minibatch of samples {xi} m i=1 from p \u03b8 . 4: Sample a minibatch of samples {yi} m i=1 from p d . 5:\nUpdate the parameter of discriminator by taking gradient ascend of discriminator loss\ni [\u2207 \u03b8 d log D(yi)] + i [\u2207 \u03b8 d log(1 \u2212 D(x i ))]\n6: end for 7: Sample a minibatch of samples {xi} m i=1 from p \u03b8 . 8: Update the generator by applying gradient update\nm i=1 ( rD(xi) i rD(xi) \u2212 b)\u2207 log p \u03b8 (xi) 9: end for\n\nAnalysis\n\nThe proposed objective in Eq. 2 is also theoretically guaranteed to be sound. In the following theorem, we show that our training objective approximately optimizes the KL divergence KL(q(x)||p \u03b8 (x)) when D is close to optimal. What's more, the objective still makes sense when D is well trained but far from optimal.\n\nTheorem 3.1. We have the following two theoretical guarantees for our new training objective.\n\n(i) If discriminator D(x) is optimal between delayed generator p and real data distribution p d , we have the following equation.\nE p d [log p \u03b8 (x)] = 1 Z(\u03b8 ) E p [r D (x) log p \u03b8 (x)] where Z(\u03b8 ) = E p [r D (x)] = 1. (ii) If D(x)\nis trained well but not sufficiently, namely, \u2200x, D(x) lies between 0.5 and p d p d +p , we have the property that for m \u2192 \u221e, almost surely\nE({x i } m 1 ) \u00b7 \u2207 \u03b8 KL(p d ||p \u03b8 ) > 0 (3)\nThe above gives us a condition for our objective to still push the generator in a descent direction even when the discriminator is not trained to optimality.\n\nIn addition to its attractiveness in theory, we now demonstrate why the gradient estimator in Eq. 2 of \u2207L G (\u03b8) practically can produce better training signal for the generator than the original GAN objective. Similar discussions can be found in (Bornschein & Bengio, 2015;Norouzi et al., 2016a).\n\nIn the original GAN setting from a reinforcement learning perspective, e.g. the inclusive KL in Eq. 1, the free running auto-regressive model can be viewed as an RL agent exploring the state space and getting a reward, D or log D, at the end of the exploration. The model then tries to adjust the probability of each of its exploration paths according to this reward. However, this gradient estimator would be drastically inefficient when almost all generated paths had a very small discriminator output. Unfortunately, this is very common in GAN training and cannot even be solved with a carefully selected baseline.\n\nIn the MaliGAN objective, however, the partition function Z is estimated using the samples from the minibatch, which helps dealing with the above dilemma. When we choose, for example, baseline b = 1, we can see that the sum of the weights on the generated paths are zero, and the probability of each path is adjusted not according to the absolute value of the discriminator output, but its relative quality in that minibatch. This ensures that the model can always learn something as long as there exist some generations better than others in that mini-batch. Furthermore, the previous theorem ensures the consistency of the mini-batch level normalization procedure.\n\nFrom a theoretical point of view, this normalization procedure also helps. Although at the first glance, when D is optimal, one can prove that Z = 1, so estimating Z seems to only introduce additional variance to the model. However, using this estimator in fact reduces the variance due to the following reason: r D (x) is actually a function with singularity when x is in a region \u2126 in the data space on which D(x) \u2248 1. Even with very careful pre-training, such a region \u2126 r D 0 and p (\u2126) \u2248 0, making the ratio blow up.\nIn our target 1 Z(\u03b8 ) E p [r D (x) log p \u03b8 (x)]\n, since it is almost impossible to get samples from \u2126 with p in a reasonable size mini-batch, the actual distribution we are sampling from is a \"regularized\" distribution p \\\u2126 where p \\\u2126 (\u2126) = 0 and p \\\u2126 \u2248 p . So when doing importance sampling to estimate our training objective\n\u2207L G = E p d [\u2207 \u03b8 log p \u03b8 (x)]\nwith small mini-batches, we are actually doing normalizedweights importance sampling based on p \\\u2126 :\n\u2207L G \u2248 E p \\\u2126 [r D (x)\u2207 \u03b8 log p \u03b8 (x)]/E p \\\u2126 [r D (x)]. Since the Monte Carlo estimator has much more variance to estimate E p [r D (x)\u2207 \u03b8 log p \u03b8 (x)] than E p \\\u2126 [r D (x)\u2207 \u03b8 log p \u03b8 (x)],\nin practical mini-batch training settings, we can view that we are doing importance sampling with the distribution p \\\u2126 , and this objective has much less variance compared to importance sampling with p on r D which has an infinite singularity. This is why estimating Z = E p \\\u2126 [r D (x)] is important in order to reduce the variance in the mini-batch training setting.\n\nWhen training auto-regressive models with teacher forcing, a serious problem is exposure bias (Ranzato et al., 2016;Norouzi et al., 2016b;Lamb et al., 2016). Namely, the model is only trained on demonstrated behaviors (real data samples), but we also want it to be trained on free-running behaviors. When we set a positive baseline b > 0, the model first generates m samples, and then tries to adjust the probabilities of each generated samples by trying to reinforce the best behaviors and exclude the worse behaviors relatively to those in the mini-batch.\n\n\nVariance Reduction in MaliGAN\n\nThe proposed renormalized objective in MaliGAN supports much more stable training behavior than the RL objective in a standard GAN. Nevertheless, when the long sequence generation procedure consists of multiple steps of random sampling, we find it is better to further integrate the following advanced variance reduction techniques.\n\n\nMONTE CARLO TREE SEARCH\n\nInstead of using the same weight for all time steps in one sample, we use the following formula which is well known in the RL literature:\nE p \u03b8 [r D (x)\u2207p(x)] = E p \u03b8 [ L t=1 Q(a t , s t )\u2207p \u03b8 (a t |s t )]\nwhere Q(a, s) stands for the \"expected total reward\" given by r D = D 1\u2212D of generating token a given previous generation s, which can be estimated with, e.g., Monte Carlo tree search (MCTS, Silver et al. (2016)).\n\nThus, following the gradient estimator presented in Theorem 3.1, we derive another gradient estimator:\n\u2207L G (\u03b8) \u2248 i L i m Q(a i t , s i t ) m,Li i,t Q(a i t , s i t )\u2207 log p \u03b8 (a i t |s i t )\nwhere m is the size of the mini-batch. Using Monte Carlo tree search brings in several benefits. First, it allows different steps of the generated sample to be adjusted with different weights. Second, it gives us a more stable estimator of the partition function Z. Both of these two properties can dramatically reduce the variance of our proposed estimator.\n\n\nMIXED MLE-MALI TRAINING\n\nWhen dealing with long sequences, the above model may result in accumulated variance. To alleviate the issue, we significantly reduce the variance by clamping the input using the training data for N time steps, and switch to free running mode for the remaining T \u2212 N time steps. Then during our training procedure, inspired from Ranzato et al. (2016), we slowly move N from T towards 0.\n\nThe training objective is equivalent to setting q in the last section to:\nq(x 0 , x 1 , \u00b7 \u00b7 \u00b7 x L ) = p d (x 0 , \u00b7 \u00b7 \u00b7 x N )q(x N +1 , \u00b7 \u00b7 \u00b7 x L |x 0 , \u00b7 \u00b7 \u00b7 x N )\nWe also assume D is trained on the real samples and fake samples generated by\np f (x 0 , \u00b7 \u00b7 \u00b7 x L ) = p d (x 0 , \u00b7 \u00b7 \u00b7 x N )p \u03b8 (x N +1 , \u00b7 \u00b7 \u00b7 x L |x 0 , \u00b7 \u00b7 \u00b7 x N ) Let x \u2264N = (x 0 , x 1 , \u00b7 \u00b7 \u00b7 x N ), x >N = (x N +1 , \u00b7 \u00b7 \u00b7 x L ), we have: \u2207L G =E q [\u2207 log p \u03b8 (x)] =E p d [\u2207 log p \u03b8 (x \u2264N )] + E q [\u2207 log p \u03b8 (x >N |x <N )] =E p d [\u2207 log p \u03b8 (x 0 , x 1 , \u00b7 \u00b7 \u00b7 x T )] + 1 Z E p \u03b8 [ L t=N +1 r D (x)\u2207 log p \u03b8 (a t |s t )]\nFor each sample x i from the real data batch, if it has length larger than N , we fix the first N words of x i , and then sample n times from our model till the end of the sequence, and get n samples {x i,j } n j=1 . We then have the following series of mini-batch estimators for each 0 \u2264 N \u2264 T :\n\u2207L N G \u2248 m,n i=1,j=1 ( r D (x i,j ) j r D (x i,j ) \u2212 b)\u2207 log p \u03b8 (x >N i,j |x \u2264N i ) + 1 m m i=1 N t=0 p \u03b8 (a i t |s i t ) = E N (x i,j )(4)\nOne difference is that in this model, we normalize the coefficients r D (x i,j ) based only on samples generated from a single real data sample x i . The reason of using this trick will be explained in next sub-section.\n\nWe have the following theorem which guarantees the theoretical property of this estimator.\n\nTheorem 3.2. When D is correctly trained but not optimal in the sense of Theorem 3.1, when m \u2192 \u221e, we almost surely have \u22000 \u2264 N \u2264 T ,\nE N (x i,j ) \u00b7 \u2207 \u03b8 KL(p d ||p \u03b8 ) > 0(5)\n\nSINGLE REAL DATA BASED RENORMALIZATION\n\nMany generative models have multiple layers of randomnesses. For example, in auto-regressive models, the samples are generated via multiple sampling steps. Other examples include hierarchical generative models like deep Boltzmann machines and deep belief networks (Salakhutdinov & Hinton, 2009;Hinton, 2009).\n\nIn these models, high-level random variables are usually responsible for modeling high-level decisions or \"modes\" of the probability distribution. Changing them can result in much larger effects than that from changing low-level variables. Motivated by this observation, in each mini-batch we first draw a mini-batch of samples (e.g. 32) of highlevel latent variables, and then for each high level value we draw a number of low level data samples (e.g. 32).\n\nThen we re-estimate the partition function Z from the lowlevel samples that are generated by each high-level samples. Because lower-level sampling has a much smaller variance, the model can receive better gradient signals from the weights provided by the discriminator.\n\nThis sampling principle is corresponding to applying the mixed MLE-Mali training discussed above in the autoregressive settings. In this case we first sample a few data samples, then fix the first N words and let the network generate a lot of samples after N as our next mini-batch. We refer this full algorithm to sequential MaliGAN with Mixed MLE Training, which is summarized in Algorithm 2.\n\n\nAlgorithm 2 Sequential MaliGAN with Mixed MLE Training\n\nRequire: A generator p with parameters \u03b8. A discriminator D(x) with parameters \u03b8 d . Maximum sequence length T , step size K. Update the discriminator by taking gradient ascend of discriminator loss.\ni [\u2207 \u03b8 d log D(yi)] + i [\u2207 \u03b8 d log(1 \u2212 D(x i ))]\n9: end for 10: Sample a minibatch of sequences {xi} m i=1 from p d . 11: For each sample xi with length larger than N in the minibatch, clamp the generator to the first N words of s, and freely run the model to generate m samples xi,j, j = 1, \u00b7 \u00b7 \u00b7 m till the end of the sequence. 12: Update the generator by applying the mixed MLE-Mali gradient update\n\u2207L N G \u2248 m,n i=1,j=1 ( rD(xi,j) j rD(xi,j) \u2212 b)\u2207 log p \u03b8 (x >N i,j |x \u2264N i ) + 1 m m i=1 N t=0 p \u03b8 (a i t |s i t )\n\n13: end for\n\nThe reason why doing this single real sample based renormalization is beneficial can be summarized around two elements. First, consider S is a sample from the training set. The first N words S \u2264N should be completed by our model. The conditional distribution p d (S >N |S \u2264N ) should be much simpler than the full distribution p d . Namely, p d (S >N |S \u2264N ) consists of only one or a few \"modes\". So this renormalization technique can be viewed as trying to train the model on these simpler conditional distributions, which gives more stable gradients.\n\nSecond, this normalization scheme makes our model robust to mode missing, which is a common failure pattern when training GANs (Che et al., 2016). Single sample based renormalization ensures that for every real sample S, the model can receive a moderately strong training signal for how to perform better on generating S >N conditioned on S \u2264N . However, in batch-wise renormalization as in the basic MaliGAN, this is not possible because there might be some completions S with r D (S ) very large, so other training samples in that mini-batch receives very little gradient signals.\n\n\nExperiments\n\nTo examine the effectiveness of the proposed algorithms, we conduct experiments on three discrete sequence generation tasks. We achieve promising results on all three tasks, including a standard and challenging language modeling task. From the empirical results and the following analysis, we demonstrate the soundness of MaliGAN and show its robustness to overfitting.\n\n\nDiscrete MNIST\n\nWe first evaluate MaliGAN on the binarized image generation task for the MNIST hand-written digits dataset, similar with Hjelm et al. (2017). The original datasets have 60,000 and 10,000 samples in the training and testing sets, respectively. We split the training set and randomly selected 10,000 samples for validation. We adopted as the generator a deep convolutional neural network based on the DCGAN architecture (Radford et al., 2015). To generate the discrete samples, we sample from the generator's output binomial distribution. We adopt Algorithm 1 of MaliGAN for training and use the single latent variable renormalization technique for variance reduction.\n\nTo compare our proposed MaliGAN with the models trained using the discriminator's output as a direct reward, we also train a generator with the same network architecture, but use the output of the discriminator as the weight of generated samples. We denote it as the REINFORCE-like model. The comparison results are shown in Figure 1 and   \n\n\nPoem Generation\n\nWe examine the effectiveness of our model on a Chinese poem generation task. Typically, there are two genres of Chinese poems. We refer with Poem-5 and Poem-7 to those consisting of 5 or 7 Chinese characters each in a short sentence, respectively. We use the dataset provided in (Zhang & Lapata, 2014), and split them in the standard way 1 .\n\nThe generator is a one-layer LSTM (Hochreiter & J\u00fcrgen Schmidhuber, 1997) with 32 hidden units for Poem-5 and 100 for Poem-7. Our discriminators are two-layer Bi-LSTMs with 32 hidden neurons. We denote our models trained with Algorithm 1 and Algorithm 2 as MaliGANbasic and MaliGAN-full. We choose two compared models, the auto-regressive model with same architecture but trained with maximum likelihood (MLE), and Seq-GAN (Yu et al., 2017). Following Yu et al. (2017), we report the BLEU-2 scores in Table 4.2 (Papineni et al., 2002).\n\nMaliGAN-full obtained the best BLEU-2 scores on par on both tasks, and MaliGAN-basic was the next best. Clearly, MLE lagged far behind despite the same architecture, which should be attributed to the inherent defect in the MLE teacher-forcing training framework. As pointed by previous researchers Wiseman & Rush (2016), BLEU might not be a proper evaluation metric, we also calculate the Perplexity of these four models, obtaining qualitatively similar results. The best scores are reported in Table 4.2 and the Perplexity curves are illustrated in Figure 3.  From the above figures, we can see how our models perform during the training procedure. Although with some oscillations, both MaliGAN-basic and MaliGAN-full achieved lower perplexity. Especially on Poem-7 from Figure 3, our proposed models both prevent overfitting when MLE ended up with that. A comparison between the training curve of MaliGAN-basic and that of MaliGAN-full, we can find that the latter has less variance. This demonstrates the effectiveness of the advanced variance reduction techniques in our full model. The peak in the MLE curve on Poem-5 in Figure 3 is, however, unlikely to be a result of overfitting because that MLE \"recovered\" from it fast and continued to convergence till the end. In fact, we find it harder to train a stable MLE model on Poem-5 than on Poem-7. We conjecture this resulted from the intricate mutual influence between the improper evaluation and the small training data size.\n\n\nSentence-Level Language Modeling\n\nWe also examine the proposed algorithm on a more challenging task, sentence-level language modeling, which can be considered as a fundamental task with applications to various discrete sequence generation tasks. To explore the possibilities and limitations of our algorithm, we conduct extensive experiments on the standard Penn Treebank (PTB) dataset (Marcus et al., 1993) through parameter searching and model ablations. For evaluation we report sentence-level perplexity, which is the averaged perplexity on all sentences in the test set. For simplicity and efficiency, we adopt a 1-layer GRU (Cho et al., 2014) as our generator, and set the same setting for the baseline model trained with standard teacher forcing (Williams & Zipser, 1989). We use a Bi-directional GRU net-work as our discriminator. To stabilize training and provide good initialization for the generator, we first pre-train our generator on the training set using teacher forcing, then we train two models, MaliGAN-basic and MaliGANfull. MaliGAN-basic is trained with Algorithm 1 without MCTS. MaliGAN-full is trained by Algorithm 2 with all the variance reduction techniques included.\n\nNote that the computational cost of MCTS is very large, so we remove all sentences longer than 35 words in the training set. We set N = 30 and K = 5 at the beginning of the training and pre-train our discriminator to make it reliable enough to provide informative and correct signals for the generator. The perplexity shown in Table 4.3 is achieved by our best performing model, which has 200 hidden neurons and 200 dimensions for word embeddings. It is encouraging to see that our model is more robust to overfitting in consideration of the relative small size of the PTB data. These results strengthen our belief to realize our algorithm on even larger datasets, which we leave as a future work.\n\nThe positive result again demonstrates the effectiveness of MaliGAN, whose primary component is the novel optimization objective we propose in Eq. 2. Besides, we also gain insights from the model ablation tests about the advanced variance reduction techniques provided in Section 3.3. Combined with the Perplexity curve in Figure 3, we can see that with advanced techniques, MaliGANfull performed in a more stable way during training and can to some extent achieve lower perplexity scores than MaliGAN-basic. We believe these fruitful techniques will be beneficial in other similar problem settings.\n\n\nRelated Work\n\nTo improve the performance of discrete auto-regressive models, some researchers aim to tackle the exposure bias problem, which is discussed detailed in (Ranzato et al., 2016;Serban et al., 2016;Wiseman & Rush, 2016). The problem occurs when the training algorithm prohibits models to be exposed to their own predictions during training.\n\nThe second issue is the discrepancy between the objective during training and the evaluation metric during testing, which is analyzed in Ranzato et al. (2016) and then summarized as Loss-Evaluation Mismatch by Wiseman & Rush (2016). Typically, the objectives in training auto-regressive models are to maximize the word-level probabilities, while in test-time, we often evaluate the models using sequencelevel metrics, such as BLEU (Papineni et al., 2002). To alleviate these two issues, the most straightforward way is to add the evaluation metrics into the objective in the training phase. Because these metrics are often discrete which cannot be utilized through standard back-propagation, researchers generally seek help from reinforcement learning. Ranzato et al. (2016) exploits REINFORCE algorithm (Williams, 1992) and proposes several model variants to well situate the algorithm in text generation applications. Liu et al. (2016) shares similar idea and directly optimizes image caption metrics through policy gradient methods (Igel, 2005). There exists a third issue, namely Label Bias, especially in sequence-to-sequence learning framework, which obstacles the MLE trained models to be optimized globally (Andor et al., 2016;Wiseman & Rush, 2016) To addresses the abovementioned issues in training autoregressive models, we propose to formulate the problem under the setting of generative adversarial networks. Initially proposed by Goodfellow et al. (2014), generative adversarial network (GAN) has attracted a lot of attention because it provides a powerful framework to generate promising samples through a min-max game. Researchers have successfully applied GAN to generate promising images conditionally (Mirza & Osindero, 2014;Reed et al., 2016;Zhang et al., 2016b) and unconditionally (Radford et al., 2015;Nguyen et al., 2016), to realize image manipulation and super-resolution S\u00f8nderby et al., 2017;Ledig et al., 2016), and to produce video sequences (Mathieu et al., 2016;Zhou & Berg, 2016;Saito & Matsumoto, 2016). Despite these successes, the feasibility and advantage on applying GAN to text generation are restrictedly explored yet noteworthy.\n\nIt is appealing to generate discrete sequences using GAN as discussed above. The generative models are able to utilize the discriminator's output to make up the information of its own distribution, which is inaccessible if trained by teacher forcing (Williams & Zipser, 1989;Ranzato et al., 2016). However, it is nontrivial to train GAN on discrete data due to its discontinuity nature. The instability inherent in GAN training makes things even worse (Salimans et al., 2016;Che et al., 2016;. Lamb et al. (2016) exploits adversarial domain adaption to regularize the training of recurrent neural networks. Yu et al. (2017) applies GAN to discrete sequence generation by directly optimizing the discrete dis-criminator's rewards. They adopt Monte Carlo tree search technique (Silver et al., 2016). Similar technique has been employed in Li et al. (2017) which improves response generation by using adversarial learning.\n\nIn Bornschein & Bengio (2015), which inspired us, the authors propose a way of doing mini-batch reweighting when training latent variable models with discrete variables. However, they make use of inference network which are infeasible in the GAN setting.\n\nOur work is also closely related to Norouzi et al. (2016b). In Norouzi et al. (2016b), they propose to work with the objective KL(p d ||p \u03b8 ) in a conditional generation setting. In this case, the situation is similar with ours because rewards such as BLEU scores are available. However, conditional generation metrics such as BLEU scores are decomposable to each time steps, so this property can make them able to directly sample from the augmented distributions, which is not possible for sequence-level GANs, e.g., language modeling. So we have to use importance sampling to train the model.\n\n\nDiscussions and Future Work\n\nIn spite of their great popularity on continuous datasets such as images, GANs haven't yet achieved an equivalent success in discrete domains such as natural language processing. We observed that the main cause of this gap is that while the discriminator can almost perfectly discriminate the good samples from the bad ones, it is notoriously difficult to pass this information to the generator due to the difficulty of credit assignment through discrete computation and inherent instability of RL algorithms applied to dynamic environments with sparse reward.\n\nIn this work, we take a different approach. We start first from the maximum likelihood training objective KL(p d ||p \u03b8 ), and then use importance sampling combined with the discriminator output to derive a novel training objective. We argue that although this objective looks similar to the objective used in reinforcement learning, the normalization in fact does reduce the variance of the estimator by ignoring the region \u2126 in the data space around the singularity of r D in which the generator p \u03b8 has almost zero probability to get samples from. Namely, by estimating the partition function Z using samples, we are approximately doing normalized importance sampling with another distribution p \\\u2126 which has much lower variance c.f. Section 3.2. Practically, this single real sample normalization process combined with mixed training (Ranzato et al., 2016) successfully avoided the missing mode problem by providing equivalent training signal for each mode.\n\nBesides successfully reducing the variances of normal reinforcement learning algorithms, our algorithm is surpris-ingly robust to overfitting. Teacher forcing is prone to overfit, because by maximizing the likelihood of the training data, the model can easily fit not only the regularities but also the noise in the data. However in our model, if the generator tries to fit too much noise in the data, the generated sample will not look good and hopefully the discriminator will be able to capture the differences between the generated and the real samples very easily.\n\nAs for future work, we are going to train the model on large datasets such as Google's one billion words (Chelba et al., 2014) and on conditional generation cases such as dialogue generation.\n\n\nA baseline b, sampling multiplicity m. 1: N = T 2: Optional: Pretrain model using pure MLE with some epochs. 3: for number of training iterations do 4: N = N -K 5: for k steps do 6: Sample a minibatch of sequences {yi} m i=1 from p d . 7: While keeping the first N steps the same as {yi} m i=1 , sample a minibatch of sequences {xi} m i=1 from p \u03b8 from time step N . 8:\n\nFigure 2 .\n2The two figures in the first line are training losses of the generator and discriminator from the proposed MaliGAN. We can see the training process of MaliGAN with variance reduction techniques is stable and the loss curve is meaningful. The bottom two figures inFigure 2are samples generated by the REINFORCE-like model and by Mali-GAN. Clearly, the samples generated by MaliGAN have much better visual quality and resemble closely the training data.\n\nFigure 1 .\n1The training loss of the generator (left) and the discriminator (right) of MaliGAN on Discrete MNIST task.\n\nFigure 2 .\n2Samples generated by REINFORCE-like model (left) and by MaliGAN (right).\n\nFigure 3 .\n3Perplexity curves on Poem-5 (left) and Poem-7 (right).\n\nTable 1 .\n1Experimental results on Poetry Generation task. The result of SeqGAN is directly taken from(Yu et al., 2017).Model \nPoem-5 \nPoem-7 \n\nBLEU-2 \nPPL \nBLEU-2 \nPPL \n\nMLE \n0.6934 \n564.1 \n0.3186 \n192.7 \nSeqGAN \n0.7389 \n-\n-\n-\nMaliGAN-basic \n0.7406 \n548.6 \n0.4892 \n182.2 \nMaliGAN-full \n0.7628 \n542.7 \n0.5526 \n180.2 \n\n\n\nTable 2 .\n2Experimental results on PTB. Note that we evaluate the models in sentence-level.MLE MaliGAN-basic MaliGAN-full \n\nValid-Perplexity 141.9 \n131.6 \n128.0 \nTest-Perplexity 138.2 \n125.3 \n123.8 \n\nFrom Table 4.3 we can see, the simplest model trained \nby MaliGAN reduced the perplexity of the baseline effec-\ntively. Both the basic and the full model, i.e., MaliGAN-\nbasic and MaliGAN-full obtained a notably lower perplex-\nity compared with the MLE model. Although the PTB \ndataset is much more difficult, we obtain results consistent \nwith Table 4.2. \nhttp://homepages.inf.ed.ac.uk/mlap/Data/ EMNLP14/\n\nGlobally normalized transition-based neural networks. Daniel Andor, Chris Alberti, Weiss, David, Severyn, Aliaksei, Alessandro Presta, Ganchev, Kuzman, Slav Petrov, Michael Collins, abs/1603.06042CoRRAndor, Daniel, Alberti, Chris, Weiss, David, Sev- eryn, Aliaksei, Presta, Alessandro, Ganchev, Kuz- man, Petrov, Slav, and Collins, Michael. Globally normalized transition-based neural networks. CoRR, abs/1603.06042, 2016.\n\nTowards principled methods for training generative adversarial networks. Mart\u00edn Arjovsky, L\u00e9on Bottou, abs/1701.04862CoRRArjovsky, Mart\u00edn and Bottou, L\u00e9on. Towards principled methods for training generative adversarial networks. CoRR, abs/1701.04862, 2017.\n\n. Mart\u00edn Arjovsky, Soumith Chintala, Bottou, L\u00e9on, Wasserstein Gan, Corr, abs/1701.07875Arjovsky, Mart\u00edn, Chintala, Soumith, and Bottou, L\u00e9on. Wasserstein gan. CoRR, abs/1701.07875, 2017.\n\nScheduled sampling for sequence prediction with recurrent neural networks. Bengio, Samy, Vinyals, Oriol, Navdeep Jaitly, Noam Shazeer, Advances in Neural Information Processing Systems. Bengio, Samy, Vinyals, Oriol, Jaitly, Navdeep, and Shazeer, Noam. Scheduled sampling for sequence pre- diction with recurrent neural networks. In Advances in Neural Information Processing Systems, pp. 1171-1179, 2015.\n\nReweighted wakesleep. J\u00f6rg Bornschein, Yoshua Bengio, Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)Bornschein, J\u00f6rg and Bengio, Yoshua. Reweighted wake- sleep. In Proceedings of the International Conference on Learning Representations (ICLR), 2015.\n\nGenerating sentences from a continuous space. Samuel R Bowman, Vilnis, Luke, Vinyals, Oriol, Andrew M Dai, Rafal Jozefowicz, Bengio, Samy, arXiv:1511.06349arXiv preprintBowman, Samuel R, Vilnis, Luke, Vinyals, Oriol, Dai, An- drew M, Jozefowicz, Rafal, and Bengio, Samy. Gener- ating sentences from a continuous space. arXiv preprint arXiv:1511.06349, 2015.\n\nChe, Tong, Li, Jacob Yanran, Athul Paul, Yoshua Bengio, Wenjie Li, arXiv:1612.02136Mode regularized generative adversarial networks. arXiv preprintChe, Tong, Li, Yanran, Jacob, Athul Paul, Bengio, Yoshua, and Li, Wenjie. Mode regularized generative adversarial networks. arXiv preprint arXiv:1612.02136, 2016.\n\nOne billion word benchmark for measuring progress in statistical language modeling. Ciprian Chelba, Mikolov, Tomas, Schuster, Mike, Ge, Qi, Thorsten Brants, Phillipp Koehn, abs/1312.3005CoRRChelba, Ciprian, Mikolov, Tomas, Schuster, Mike, Ge, Qi, Brants, Thorsten, and Koehn, Phillipp. One billion word benchmark for measuring progress in statistical language modeling. CoRR, abs/1312.3005, 2014.\n\nKyunghyun Cho, Van Merri\u00ebnboer, Bart, Dzmitry Bahdanau, Yoshua Bengio, arXiv:1409.1259On the properties of neural machine translation: Encoder-decoder approaches. arXiv preprintCho, Kyunghyun, Van Merri\u00ebnboer, Bart, Bahdanau, Dzmitry, and Bengio, Yoshua. On the properties of neu- ral machine translation: Encoder-decoder approaches. arXiv preprint arXiv:1409.1259, 2014.\n\nGenerative adversarial nets. Ian Goodfellow, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Warde - Bing, Farley, David, Ozair, Sherjil, Aaron Courville, Yoshua Bengio, Advances in Neural Information Processing Systems. Goodfellow, Ian, Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, and Bengio, Yoshua. Generative adversarial nets. In Advances in Neural Information Processing Systems, pp. 2672-2680, 2014.\n\nGeoffrey E Hinton, Deep belief networks. Scholarpedia. 45947Hinton, Geoffrey E. Deep belief networks. Scholarpedia, 4(5):5947, 2009.\n\nBoundary-seeking generative adversarial networks. Hjelm, Devon, Che Jacob, Tong, Kyunghyun Cho, Yoshua Bengio, Hjelm, R Devon, Jacob, Athul, Che, Tong, Cho, Kyunghyun, and Bengio, Yoshua. Boundary-seeking generative adversarial networks. 2017.\n\nLong shortterm memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural Computation. 9Hochreiter, Sepp and J\u00fcrgen Schmidhuber. Long short- term memory. Neural Computation, 9:1735-1780, 1997.\n\nPolicy gradient methods for reinforcement learning with function approximation. C Igel, Igel, C. Policy gradient methods for reinforcement learning with function approximation. 2005.\n\nProfessor forcing: A new algorithm for training recurrent networks. Alex Lamb, Goyal, Anirudh, Ying Zhang, Zhang, Saizheng, Aaron C Courville, Yoshua Bengio, Advances In Neural Information Processing Systems. Lamb, Alex, Goyal, Anirudh, Zhang, Ying, Zhang, Saizheng, Courville, Aaron C., and Bengio, Yoshua. Professor forcing: A new algorithm for training recur- rent networks. In Advances In Neural Information Pro- cessing Systems, pp. 4601-4609, 2016.\n\nPhoto-realistic single image super-resolution using a generative adversarial network. Christian Ledig, Theis, Lucas, Husz\u00e1r, Ferenc, Jose Caballero, Aitken, Andrew, Tejani, Alykhan, Totz, Johannes, Zehan Wang, Wenzhe Shi, arXiv:1609.04802arXiv preprintLedig, Christian, Theis, Lucas, Husz\u00e1r, Ferenc, Caballero, Jose, Aitken, Andrew, Tejani, Alykhan, Totz, Johannes, Wang, Zehan, and Shi, Wenzhe. Photo-realistic sin- gle image super-resolution using a generative adversarial network. arXiv preprint arXiv:1609.04802, 2016.\n\nAdversarial learning for neural dialogue generation. Jiwei Li, Monroe, Shi, Tianlin, Alan Ritter, Dan Jurafsky, arXiv:1701.06547arXiv preprintLi, Jiwei, Monroe, Will, Shi, Tianlin, Ritter, Alan, and Ju- rafsky, Dan. Adversarial learning for neural dialogue generation. arXiv preprint arXiv:1701.06547, 2017.\n\nOptimization of image description metrics using policy gradient methods. Liu, Siqi, Zhu, Zhenhai, Ye, Ning, Sergio Guadarrama, Kevin Murphy, abs/1612.00370CoRRLiu, Siqi, Zhu, Zhenhai, Ye, Ning, Guadarrama, Sergio, and Murphy, Kevin. Optimization of image descrip- tion metrics using policy gradient methods. CoRR, abs/1612.00370, 2016.\n\nBuilding a large annotated corpus of english: The penn treebank. Mitchell P Marcus, Mary Marcinkiewicz, Ann, Beatrice Santorini, Computational linguistics. 192Marcus, Mitchell P, Marcinkiewicz, Mary Ann, and San- torini, Beatrice. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313-330, 1993.\n\nDeep multi-scale video prediction beyond mean square error. Michael Mathieu, Camille Couprie, Yann Lecun, Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)Mathieu, Michael, Couprie, Camille, and LeCun, Yann. Deep multi-scale video prediction beyond mean square error. In Proceedings of the International Conference on Learning Representations (ICLR), 2016.\n\nNeural variational inference for text processing. Yishu Miao, Lei Yu, Phil Blunsom, abs/1511.06038CoRRMiao, Yishu, Yu, Lei, and Blunsom, Phil. Neu- ral variational inference for text processing. CoRR, abs/1511.06038, 2016.\n\nMehdi Mirza, Simon Osindero, arXiv:1411.1784Conditional generative adversarial nets. arXiv preprintMirza, Mehdi and Osindero, Simon. Conditional genera- tive adversarial nets. arXiv preprint arXiv:1411.1784, 2014.\n\nPlug & play generative networks: Conditional iterative generation of images in latent space. Anh Nguyen, Jason Yosinski, Bengio, Yoshua, Alexey Dosovitskiy, Jeff Clune, arXiv:1612.00005arXiv preprintNguyen, Anh, Yosinski, Jason, Bengio, Yoshua, Dosovit- skiy, Alexey, and Clune, Jeff. Plug & play generative networks: Conditional iterative generation of images in latent space. arXiv preprint arXiv:1612.00005, 2016.\n\nReward augmented maximum likelihood for neural structured prediction. Mohammad Norouzi, Bengio, Samy, Chen, Zhifeng, Jaitly, Navdeep, Schuster, Mike, Yonghui Wu, Dale Schuurmans, NIPS. Norouzi, Mohammad, Bengio, Samy, Chen, Zhifeng, Jaitly, Navdeep, Schuster, Mike, Wu, Yonghui, and Schuurmans, Dale. Reward augmented maximum likeli- hood for neural structured prediction. In NIPS, 2016a.\n\nReward augmented maximum likelihood for neural structured prediction. Mohammad Norouzi, Bengio, Samy, Jaitly, Navdeep, Schuster, Mike, Wu, Yonghui, Schuurmans, Dale, Advances In Neural Information Processing Systems. Norouzi, Mohammad, Bengio, Samy, Jaitly, Navdeep, Schuster, Mike, Wu, Yonghui, Schuurmans, Dale, et al. Reward augmented maximum likelihood for neural structured prediction. In Advances In Neural Informa- tion Processing Systems, pp. 1723-1731, 2016b.\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Roukos, Salim, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting on association for computational linguistics. the 40th annual meeting on association for computational linguisticsAssociation for Computational LinguisticsPapineni, Kishore, Roukos, Salim, Ward, Todd, and Zhu, Wei-Jing. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th an- nual meeting on association for computational linguis- tics, pp. 311-318. Association for Computational Lin- guistics, 2002.\n\nUnsupervised representation learning with deep convolutional generative adversarial networks. Alec Radford, Luke Metz, Chintala, Soumith, arXiv:1511.06434arXiv preprintRadford, Alec, Metz, Luke, and Chintala, Soumith. Un- supervised representation learning with deep convolu- tional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.\n\nSequence level training with recurrent neural networks. Marc &apos; Ranzato, Aurelio, Chopra, Sumit, Michael Auli, Wojciech Zaremba, Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)Ranzato, Marc'Aurelio, Chopra, Sumit, Auli, Michael, and Zaremba, Wojciech. Sequence level training with recur- rent neural networks. In Proceedings of the International Conference on Learning Representations (ICLR), 2016.\n\nGenerative adversarial text-to-image synthesis. Reed, Scott, Akata, Zeynep, Yan, Xinchen, Logeswaran, Lajanugen, Bernt Schiele, Lee, Honglak, Proceedings of The 33rd International Conference on Machine Learning. The 33rd International Conference on Machine LearningReed, Scott, Akata, Zeynep, Yan, Xinchen, Logeswaran, Lajanugen, Schiele, Bernt, and Lee, Honglak. Gener- ative adversarial text-to-image synthesis. In Proceed- ings of The 33rd International Conference on Machine Learning, 2016.\n\nMasaki Saito, Eiichi Matsumoto, arXiv:1611.06624Temporal generative adversarial nets. arXiv preprintSaito, Masaki and Matsumoto, Eiichi. Temporal genera- tive adversarial nets. arXiv preprint arXiv:1611.06624, 2016.\n\nDeep boltzmann machines. Ruslan Salakhutdinov, Geoffrey E Hinton, AISTATS. 13Salakhutdinov, Ruslan and Hinton, Geoffrey E. Deep boltz- mann machines. In AISTATS, volume 1, pp. 3, 2009.\n\n. Tim Salimans, Ian J Goodfellow, Zaremba, Wojciech, Cheung, Vicki, Alec Radford, Xi Chen, Improved techniques for training gans. CoRR, abs/1606.03498Salimans, Tim, Goodfellow, Ian J., Zaremba, Wojciech, Cheung, Vicki, Radford, Alec, and Chen, Xi. Improved techniques for training gans. CoRR, abs/1606.03498, 2016.\n\nBuilding end-toend dialogue systems using generative hierarchical neural network models. Iulian V Serban, Alessandro Sordoni, Bengio, Yoshua, Aaron Courville, Joelle Pineau, AAAI-16. Serban, Iulian V, Sordoni, Alessandro, Bengio, Yoshua, Courville, Aaron, and Pineau, Joelle. Building end-to- end dialogue systems using generative hierarchical neu- ral network models. In AAAI-16, 2016.\n\nA hierarchical latent variable encoderdecoder model for generating dialogues. Iulian V Serban, Alessandro Sordoni, Lowe, Ryan, Charlin, Laurent, Joelle Pineau, Aaron Courville, Yoshua Bengio, Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17. Serban, Iulian V, Sordoni, Alessandro, Lowe, Ryan, Char- lin, Laurent, Pineau, Joelle, Courville, Aaron, and Ben- gio, Yoshua. A hierarchical latent variable encoder- decoder model for generating dialogues. In Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17), 2017.\n\nMastering the game of go with deep neural networks and tree search. David Silver, Aja Huang, Chris J Maddison, Guez, Arthur, Sifre, Laurent, Van Den Driessche, George, Schrittwieser, Julian, Antonoglou, Ioannis, Panneershelvam, Veda, Lanctot, Marc, Dieleman, Sander, Grewe, Dominik, Nham, John, Kalchbrenner, Sutskever, Ilya, Lillicrap, Timothy, Madeleine Leach, Kavukcuoglu, Koray, Thore Graepel, Demis Hassabis, Nature. 529Silver, David, Huang, Aja, Maddison, Chris J, Guez, Arthur, Sifre, Laurent, van den Driessche, George, Schrittwieser, Julian, Antonoglou, Ioannis, Panneer- shelvam, Veda, Lanctot, Marc, Dieleman, Sander, Grewe, Dominik, Nham, John, Kalchbrenner, Nal, Sutskever, Ilya, Lillicrap, Timothy, Leach, Madeleine, Kavukcuoglu, Koray, Graepel, Thore, and Hassabis, Demis. Mastering the game of go with deep neural net- works and tree search. Nature, 529 7587:484-9, 2016.\n\nAmortised map inference for image super-resolution. Casper S\u00f8nderby, Kaae, Jose Caballero, Theis, Lucas, Wenzhe Shi, Ferenc Husz\u00e1r, Proceedings of the International Conference on Learning Representations (ICLR. the International Conference on Learning Representations (ICLRS\u00f8nderby, Casper Kaae, Caballero, Jose, Theis, Lucas, Shi, Wenzhe, and Husz\u00e1r, Ferenc. Amortised map infer- ence for image super-resolution. In Proceedings of the International Conference on Learning Representations (ICLR), 2017.\n\nA neural network approach to context-sensitive generation of conversational responses. Alessandro Sordoni, Galley, Michel, Auli, Michael, Chris Brockett, Ji Yangfeng, Mitchell, Margaret, Nie, Jian-Yun, Jianfeng Gao, William B Dolan, HLT-NAACL. Sordoni, Alessandro, Galley, Michel, Auli, Michael, Brockett, Chris, Ji, Yangfeng, Mitchell, Margaret, Nie, Jian-Yun, Gao, Jianfeng, and Dolan, William B. A neu- ral network approach to context-sensitive generation of conversational responses. In HLT-NAACL, 2015.\n\nSimple statistical gradient-following algorithms for connectionist reinforcement learning. Ronald J Williams, Machine learning. 83-4Williams, Ronald J. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4):229-256, 1992.\n\nA learning algorithm for continually running fully recurrent neural networks. Ronald J Williams, David Zipser, Neural computation. 12Williams, Ronald J and Zipser, David. A learning algo- rithm for continually running fully recurrent neural net- works. Neural computation, 1(2):270-280, 1989.\n\nSequence-tosequence learning as beam-search optimization. Sam Wiseman, Alexander M Rush, Proceeddings of Conference on Empirical Methods in Natural Language Processing (EMNLP). eeddings of Conference on Empirical Methods in Natural Language essing (EMNLP)Wiseman, Sam and Rush, Alexander M. Sequence-to- sequence learning as beam-search optimization. In Pro- ceeddings of Conference on Empirical Methods in Natu- ral Language Processing (EMNLP), 2016.\n\nSeqgan: sequence generative adversarial nets with policy gradient. Lantao Yu, Zhang, Weinan, Jun Wang, Yong Yu, Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17. Yu, Lantao, Zhang, Weinan, Wang, Jun, and Yu, Yong. Se- qgan: sequence generative adversarial nets with policy gradient. In Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17), 2017.\n\nVariational neural machine translation. Zhang, Biao, Xiong, Deyi, Su, Jinsong, Hong Duan, Min Zhang, EMNLP. Zhang, Biao, Xiong, Deyi, Su, Jinsong, Duan, Hong, and Zhang, Min. Variational neural machine translation. In EMNLP, 2016a.\n\nHan Zhang, Xu, Tao, Li, Hongsheng, Zhang, Shaoting, Huang, Xiaolei, Xiaogang Wang, Dimitris Metaxas, Stackgan, arXiv:1612.03242Text to photo-realistic image synthesis with stacked generative adversarial networks. Zhang, Han, Xu, Tao, Li, Hongsheng, Zhang, Shaot- ing, Huang, Xiaolei, Wang, Xiaogang, and Metaxas, Dimitris. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks. arXiv:1612.03242, 2016b.\n\nChinese poetry generation with recurrent neural networks. Xingxing Zhang, Mirella Lapata, EMNLP. Zhang, Xingxing and Lapata, Mirella. Chinese poetry gen- eration with recurrent neural networks. In EMNLP, pp. 670-680, 2014.\n\nLearning temporal transformations from time-lapse videos. Yipin Zhou, Tamara L Berg, European Conference on Computer Vision. SpringerZhou, Yipin and Berg, Tamara L. Learning temporal trans- formations from time-lapse videos. In European Confer- ence on Computer Vision, pp. 262-277. Springer, 2016.\n\nGenerative visual manipulation on the natural image manifold. Jun-Yan Zhu, Kr\u00e4henb\u00fchl, Philipp, Eli Shechtman, Alexei A Efros, Proceedings of European Conference on Computer Vision (ECCV). European Conference on Computer Vision (ECCV)Zhu, Jun-Yan, Kr\u00e4henb\u00fchl, Philipp, Shechtman, Eli, and Efros, Alexei A. Generative visual manipulation on the natural image manifold. In Proceedings of European Conference on Computer Vision (ECCV), 2016.\n", "annotations": {"author": "[{\"end\":82,\"start\":73},{\"end\":93,\"start\":83},{\"end\":109,\"start\":94},{\"end\":122,\"start\":110},{\"end\":133,\"start\":123},{\"end\":147,\"start\":134},{\"end\":162,\"start\":148}]", "publisher": null, "author_last_name": "[{\"end\":81,\"start\":78},{\"end\":92,\"start\":90},{\"end\":108,\"start\":103},{\"end\":121,\"start\":116},{\"end\":132,\"start\":130},{\"end\":146,\"start\":142},{\"end\":161,\"start\":155}]", "author_first_name": "[{\"end\":77,\"start\":73},{\"end\":89,\"start\":83},{\"end\":102,\"start\":94},{\"end\":115,\"start\":110},{\"end\":129,\"start\":123},{\"end\":141,\"start\":134},{\"end\":154,\"start\":148}]", "author_affiliation": null, "title": "[{\"end\":70,\"start\":1},{\"end\":232,\"start\":163}]", "venue": null, "abstract": "[{\"end\":425,\"start\":234}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b36\"},\"end\":811,\"start\":789},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":831,\"start\":811},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":851,\"start\":831},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":872,\"start\":851},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1022,\"start\":1001},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":1042,\"start\":1022},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":1286,\"start\":1261},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":1363,\"start\":1341},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":1963,\"start\":1941},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1983,\"start\":1963},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2280,\"start\":2259},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2298,\"start\":2280},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2317,\"start\":2298},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2466,\"start\":2441},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4282,\"start\":4259},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4476,\"start\":4457},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5561,\"start\":5536},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6436,\"start\":6420},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8076,\"start\":8059},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10895,\"start\":10875},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13205,\"start\":13178},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13227,\"start\":13205},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16175,\"start\":16153},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":16197,\"start\":16175},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16215,\"start\":16197},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17427,\"start\":17407},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":18359,\"start\":18338},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":20247,\"start\":20217},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20259,\"start\":20247},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22877,\"start\":22859},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23858,\"start\":23839},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24158,\"start\":24136},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":25047,\"start\":25025},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":25162,\"start\":25123},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":25529,\"start\":25512},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":25557,\"start\":25541},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25623,\"start\":25600},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":25945,\"start\":25924},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":27518,\"start\":27497},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":27759,\"start\":27741},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27889,\"start\":27864},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":29794,\"start\":29772},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":29814,\"start\":29794},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":29835,\"start\":29814},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":30116,\"start\":30095},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":30189,\"start\":30168},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":30412,\"start\":30389},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":30732,\"start\":30711},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":30777,\"start\":30762},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":30895,\"start\":30878},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31005,\"start\":30993},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":31193,\"start\":31173},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":31214,\"start\":31193},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":31425,\"start\":31401},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":31701,\"start\":31677},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":31719,\"start\":31701},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":31739,\"start\":31719},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31782,\"start\":31760},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31802,\"start\":31782},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":31877,\"start\":31855},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":31896,\"start\":31877},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31951,\"start\":31929},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":31969,\"start\":31951},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31993,\"start\":31969},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":32403,\"start\":32378},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":32424,\"start\":32403},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":32603,\"start\":32580},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":32620,\"start\":32603},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":32640,\"start\":32622},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":32751,\"start\":32735},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":32924,\"start\":32903},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":32981,\"start\":32965},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":33078,\"start\":33052},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33363,\"start\":33341},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33390,\"start\":33368},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":35352,\"start\":35330},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":36152,\"start\":36131},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":37449,\"start\":37432}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36589,\"start\":36218},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37054,\"start\":36590},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37174,\"start\":37055},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37260,\"start\":37175},{\"attributes\":{\"id\":\"fig_4\"},\"end\":37328,\"start\":37261},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":37648,\"start\":37329},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":38206,\"start\":37649}]", "paragraph": "[{\"end\":2319,\"start\":441},{\"end\":3081,\"start\":2321},{\"end\":3859,\"start\":3083},{\"end\":4512,\"start\":3861},{\"end\":5184,\"start\":4514},{\"end\":5427,\"start\":5215},{\"end\":6039,\"start\":5429},{\"end\":6486,\"start\":6041},{\"end\":6831,\"start\":6488},{\"end\":6837,\"start\":6833},{\"end\":7340,\"start\":6899},{\"end\":7346,\"start\":7342},{\"end\":8197,\"start\":7411},{\"end\":8654,\"start\":8199},{\"end\":9177,\"start\":8728},{\"end\":9696,\"start\":9204},{\"end\":10044,\"start\":9698},{\"end\":10130,\"start\":10081},{\"end\":10268,\"start\":10188},{\"end\":10603,\"start\":10297},{\"end\":10979,\"start\":10682},{\"end\":11331,\"start\":11064},{\"end\":11396,\"start\":11355},{\"end\":11710,\"start\":11625},{\"end\":11877,\"start\":11760},{\"end\":12260,\"start\":11943},{\"end\":12355,\"start\":12262},{\"end\":12486,\"start\":12357},{\"end\":12728,\"start\":12589},{\"end\":12930,\"start\":12773},{\"end\":13228,\"start\":12932},{\"end\":13847,\"start\":13230},{\"end\":14515,\"start\":13849},{\"end\":15037,\"start\":14517},{\"end\":15364,\"start\":15086},{\"end\":15496,\"start\":15396},{\"end\":16057,\"start\":15688},{\"end\":16616,\"start\":16059},{\"end\":16982,\"start\":16650},{\"end\":17147,\"start\":17010},{\"end\":17429,\"start\":17216},{\"end\":17533,\"start\":17431},{\"end\":17981,\"start\":17623},{\"end\":18395,\"start\":18009},{\"end\":18470,\"start\":18397},{\"end\":18638,\"start\":18561},{\"end\":19283,\"start\":18987},{\"end\":19644,\"start\":19425},{\"end\":19736,\"start\":19646},{\"end\":19870,\"start\":19738},{\"end\":20261,\"start\":19953},{\"end\":20720,\"start\":20263},{\"end\":20991,\"start\":20722},{\"end\":21387,\"start\":20993},{\"end\":21645,\"start\":21446},{\"end\":22047,\"start\":21695},{\"end\":22730,\"start\":22177},{\"end\":23314,\"start\":22732},{\"end\":23699,\"start\":23330},{\"end\":24384,\"start\":23718},{\"end\":24726,\"start\":24386},{\"end\":25087,\"start\":24746},{\"end\":25624,\"start\":25089},{\"end\":27108,\"start\":25626},{\"end\":28303,\"start\":27145},{\"end\":29002,\"start\":28305},{\"end\":29603,\"start\":29004},{\"end\":29956,\"start\":29620},{\"end\":32126,\"start\":29958},{\"end\":33047,\"start\":32128},{\"end\":33303,\"start\":33049},{\"end\":33899,\"start\":33305},{\"end\":34491,\"start\":33931},{\"end\":35453,\"start\":34493},{\"end\":36024,\"start\":35455},{\"end\":36217,\"start\":36026}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6898,\"start\":6838},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7410,\"start\":7347},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10080,\"start\":10045},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10187,\"start\":10131},{\"attributes\":{\"id\":\"formula_4\"},\"end\":10296,\"start\":10269},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10681,\"start\":10604},{\"attributes\":{\"id\":\"formula_6\"},\"end\":11063,\"start\":10980},{\"attributes\":{\"id\":\"formula_7\"},\"end\":11624,\"start\":11397},{\"attributes\":{\"id\":\"formula_8\"},\"end\":11759,\"start\":11711},{\"attributes\":{\"id\":\"formula_9\"},\"end\":11931,\"start\":11878},{\"attributes\":{\"id\":\"formula_10\"},\"end\":12588,\"start\":12487},{\"attributes\":{\"id\":\"formula_11\"},\"end\":12772,\"start\":12729},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15085,\"start\":15038},{\"attributes\":{\"id\":\"formula_13\"},\"end\":15395,\"start\":15365},{\"attributes\":{\"id\":\"formula_14\"},\"end\":15687,\"start\":15497},{\"attributes\":{\"id\":\"formula_15\"},\"end\":17215,\"start\":17148},{\"attributes\":{\"id\":\"formula_16\"},\"end\":17622,\"start\":17534},{\"attributes\":{\"id\":\"formula_17\"},\"end\":18560,\"start\":18471},{\"attributes\":{\"id\":\"formula_18\"},\"end\":18986,\"start\":18639},{\"attributes\":{\"id\":\"formula_19\"},\"end\":19424,\"start\":19284},{\"attributes\":{\"id\":\"formula_20\"},\"end\":19911,\"start\":19871},{\"attributes\":{\"id\":\"formula_21\"},\"end\":21694,\"start\":21646},{\"attributes\":{\"id\":\"formula_22\"},\"end\":22162,\"start\":22048}]", "table_ref": "[{\"end\":25597,\"start\":25590},{\"end\":26128,\"start\":26121},{\"end\":28639,\"start\":28632}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":439,\"start\":427},{\"attributes\":{\"n\":\"2.\"},\"end\":5213,\"start\":5187},{\"attributes\":{\"n\":\"3.\"},\"end\":8726,\"start\":8657},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9202,\"start\":9180},{\"end\":11353,\"start\":11334},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11941,\"start\":11933},{\"attributes\":{\"n\":\"3.3.\"},\"end\":16648,\"start\":16619},{\"attributes\":{\"n\":\"3.3.1.\"},\"end\":17008,\"start\":16985},{\"attributes\":{\"n\":\"3.3.2.\"},\"end\":18007,\"start\":17984},{\"attributes\":{\"n\":\"3.3.3.\"},\"end\":19951,\"start\":19913},{\"end\":21444,\"start\":21390},{\"end\":22175,\"start\":22164},{\"attributes\":{\"n\":\"4.\"},\"end\":23328,\"start\":23317},{\"attributes\":{\"n\":\"4.1.\"},\"end\":23716,\"start\":23702},{\"attributes\":{\"n\":\"4.2.\"},\"end\":24744,\"start\":24729},{\"attributes\":{\"n\":\"4.3.\"},\"end\":27143,\"start\":27111},{\"attributes\":{\"n\":\"5.\"},\"end\":29618,\"start\":29606},{\"attributes\":{\"n\":\"6.\"},\"end\":33929,\"start\":33902},{\"end\":36601,\"start\":36591},{\"end\":37066,\"start\":37056},{\"end\":37186,\"start\":37176},{\"end\":37272,\"start\":37262},{\"end\":37339,\"start\":37330},{\"end\":37659,\"start\":37650}]", "table": "[{\"end\":37648,\"start\":37450},{\"end\":38206,\"start\":37741}]", "figure_caption": "[{\"end\":36589,\"start\":36220},{\"end\":37054,\"start\":36603},{\"end\":37174,\"start\":37068},{\"end\":37260,\"start\":37188},{\"end\":37328,\"start\":37274},{\"end\":37450,\"start\":37341},{\"end\":37741,\"start\":37661}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":24719,\"start\":24711},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":26184,\"start\":26176},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":26760,\"start\":26752},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":29335,\"start\":29327}]", "bib_author_first_name": "[{\"end\":38318,\"start\":38312},{\"end\":38331,\"start\":38326},{\"end\":38384,\"start\":38374},{\"end\":38414,\"start\":38410},{\"end\":38430,\"start\":38423},{\"end\":38761,\"start\":38755},{\"end\":38776,\"start\":38772},{\"end\":38948,\"start\":38942},{\"end\":38966,\"start\":38959},{\"end\":39241,\"start\":39234},{\"end\":39254,\"start\":39250},{\"end\":39560,\"start\":39556},{\"end\":39579,\"start\":39573},{\"end\":39934,\"start\":39928},{\"end\":39936,\"start\":39935},{\"end\":39981,\"start\":39975},{\"end\":39983,\"start\":39982},{\"end\":39994,\"start\":39989},{\"end\":40261,\"start\":40256},{\"end\":40275,\"start\":40270},{\"end\":40288,\"start\":40282},{\"end\":40303,\"start\":40297},{\"end\":40643,\"start\":40636},{\"end\":40700,\"start\":40692},{\"end\":40717,\"start\":40709},{\"end\":40959,\"start\":40950},{\"end\":40968,\"start\":40965},{\"end\":40995,\"start\":40988},{\"end\":41012,\"start\":41006},{\"end\":41355,\"start\":41352},{\"end\":41412,\"start\":41407},{\"end\":41414,\"start\":41413},{\"end\":41457,\"start\":41452},{\"end\":41475,\"start\":41469},{\"end\":41785,\"start\":41777},{\"end\":41787,\"start\":41786},{\"end\":41978,\"start\":41975},{\"end\":42001,\"start\":41992},{\"end\":42013,\"start\":42007},{\"end\":42183,\"start\":42179},{\"end\":42202,\"start\":42196},{\"end\":42424,\"start\":42423},{\"end\":42599,\"start\":42595},{\"end\":42626,\"start\":42622},{\"end\":42656,\"start\":42651},{\"end\":42658,\"start\":42657},{\"end\":42676,\"start\":42670},{\"end\":43078,\"start\":43069},{\"end\":43120,\"start\":43116},{\"end\":43186,\"start\":43181},{\"end\":43199,\"start\":43193},{\"end\":43565,\"start\":43560},{\"end\":43596,\"start\":43592},{\"end\":43608,\"start\":43605},{\"end\":43930,\"start\":43924},{\"end\":43948,\"start\":43943},{\"end\":44226,\"start\":44218},{\"end\":44228,\"start\":44227},{\"end\":44241,\"start\":44237},{\"end\":44270,\"start\":44262},{\"end\":44565,\"start\":44558},{\"end\":44582,\"start\":44575},{\"end\":44596,\"start\":44592},{\"end\":45005,\"start\":45000},{\"end\":45015,\"start\":45012},{\"end\":45024,\"start\":45020},{\"end\":45179,\"start\":45174},{\"end\":45192,\"start\":45187},{\"end\":45485,\"start\":45482},{\"end\":45499,\"start\":45494},{\"end\":45532,\"start\":45526},{\"end\":45550,\"start\":45546},{\"end\":45885,\"start\":45877},{\"end\":45964,\"start\":45957},{\"end\":45973,\"start\":45969},{\"end\":46275,\"start\":46267},{\"end\":46738,\"start\":46731},{\"end\":46768,\"start\":46764},{\"end\":46783,\"start\":46775},{\"end\":47367,\"start\":47363},{\"end\":47381,\"start\":47377},{\"end\":47685,\"start\":47681},{\"end\":47692,\"start\":47686},{\"end\":47733,\"start\":47726},{\"end\":47748,\"start\":47740},{\"end\":48243,\"start\":48238},{\"end\":48627,\"start\":48621},{\"end\":48641,\"start\":48635},{\"end\":48869,\"start\":48863},{\"end\":48893,\"start\":48885},{\"end\":48895,\"start\":48894},{\"end\":49029,\"start\":49026},{\"end\":49043,\"start\":49040},{\"end\":49045,\"start\":49044},{\"end\":49096,\"start\":49092},{\"end\":49108,\"start\":49106},{\"end\":49435,\"start\":49429},{\"end\":49437,\"start\":49436},{\"end\":49456,\"start\":49446},{\"end\":49487,\"start\":49482},{\"end\":49505,\"start\":49499},{\"end\":49812,\"start\":49806},{\"end\":49814,\"start\":49813},{\"end\":49833,\"start\":49823},{\"end\":49879,\"start\":49873},{\"end\":49893,\"start\":49888},{\"end\":49911,\"start\":49905},{\"end\":50343,\"start\":50338},{\"end\":50355,\"start\":50352},{\"end\":50368,\"start\":50363},{\"end\":50370,\"start\":50369},{\"end\":50625,\"start\":50616},{\"end\":50658,\"start\":50653},{\"end\":50673,\"start\":50668},{\"end\":51217,\"start\":51211},{\"end\":51238,\"start\":51234},{\"end\":51270,\"start\":51264},{\"end\":51282,\"start\":51276},{\"end\":51760,\"start\":51750},{\"end\":51806,\"start\":51801},{\"end\":51819,\"start\":51817},{\"end\":51873,\"start\":51865},{\"end\":51886,\"start\":51879},{\"end\":51888,\"start\":51887},{\"end\":52269,\"start\":52263},{\"end\":52271,\"start\":52270},{\"end\":52540,\"start\":52534},{\"end\":52542,\"start\":52541},{\"end\":52558,\"start\":52553},{\"end\":52811,\"start\":52808},{\"end\":52830,\"start\":52821},{\"end\":52832,\"start\":52831},{\"end\":53276,\"start\":53270},{\"end\":53299,\"start\":53296},{\"end\":53310,\"start\":53306},{\"end\":53662,\"start\":53658},{\"end\":53672,\"start\":53669},{\"end\":53815,\"start\":53812},{\"end\":53888,\"start\":53880},{\"end\":53903,\"start\":53895},{\"end\":54323,\"start\":54315},{\"end\":54338,\"start\":54331},{\"end\":54544,\"start\":54539},{\"end\":54557,\"start\":54551},{\"end\":54559,\"start\":54558},{\"end\":54850,\"start\":54843},{\"end\":54880,\"start\":54877},{\"end\":54898,\"start\":54892},{\"end\":54900,\"start\":54899}]", "bib_author_last_name": "[{\"end\":38324,\"start\":38319},{\"end\":38339,\"start\":38332},{\"end\":38346,\"start\":38341},{\"end\":38353,\"start\":38348},{\"end\":38362,\"start\":38355},{\"end\":38372,\"start\":38364},{\"end\":38391,\"start\":38385},{\"end\":38400,\"start\":38393},{\"end\":38408,\"start\":38402},{\"end\":38421,\"start\":38415},{\"end\":38438,\"start\":38431},{\"end\":38770,\"start\":38762},{\"end\":38783,\"start\":38777},{\"end\":38957,\"start\":38949},{\"end\":38975,\"start\":38967},{\"end\":38983,\"start\":38977},{\"end\":38989,\"start\":38985},{\"end\":39006,\"start\":38991},{\"end\":39012,\"start\":39008},{\"end\":39210,\"start\":39204},{\"end\":39216,\"start\":39212},{\"end\":39225,\"start\":39218},{\"end\":39232,\"start\":39227},{\"end\":39248,\"start\":39242},{\"end\":39262,\"start\":39255},{\"end\":39571,\"start\":39561},{\"end\":39586,\"start\":39580},{\"end\":39943,\"start\":39937},{\"end\":39951,\"start\":39945},{\"end\":39957,\"start\":39953},{\"end\":39966,\"start\":39959},{\"end\":39973,\"start\":39968},{\"end\":39987,\"start\":39984},{\"end\":40005,\"start\":39995},{\"end\":40013,\"start\":40007},{\"end\":40019,\"start\":40015},{\"end\":40244,\"start\":40241},{\"end\":40250,\"start\":40246},{\"end\":40254,\"start\":40252},{\"end\":40268,\"start\":40262},{\"end\":40280,\"start\":40276},{\"end\":40295,\"start\":40289},{\"end\":40306,\"start\":40304},{\"end\":40650,\"start\":40644},{\"end\":40659,\"start\":40652},{\"end\":40666,\"start\":40661},{\"end\":40676,\"start\":40668},{\"end\":40682,\"start\":40678},{\"end\":40686,\"start\":40684},{\"end\":40690,\"start\":40688},{\"end\":40707,\"start\":40701},{\"end\":40723,\"start\":40718},{\"end\":40963,\"start\":40960},{\"end\":40980,\"start\":40969},{\"end\":40986,\"start\":40982},{\"end\":41004,\"start\":40996},{\"end\":41019,\"start\":41013},{\"end\":41366,\"start\":41356},{\"end\":41381,\"start\":41368},{\"end\":41387,\"start\":41383},{\"end\":41394,\"start\":41389},{\"end\":41401,\"start\":41396},{\"end\":41405,\"start\":41403},{\"end\":41419,\"start\":41415},{\"end\":41427,\"start\":41421},{\"end\":41434,\"start\":41429},{\"end\":41441,\"start\":41436},{\"end\":41450,\"start\":41443},{\"end\":41467,\"start\":41458},{\"end\":41482,\"start\":41476},{\"end\":41794,\"start\":41788},{\"end\":41966,\"start\":41961},{\"end\":41973,\"start\":41968},{\"end\":41984,\"start\":41979},{\"end\":41990,\"start\":41986},{\"end\":42005,\"start\":42002},{\"end\":42020,\"start\":42014},{\"end\":42194,\"start\":42184},{\"end\":42214,\"start\":42203},{\"end\":42429,\"start\":42425},{\"end\":42604,\"start\":42600},{\"end\":42611,\"start\":42606},{\"end\":42620,\"start\":42613},{\"end\":42632,\"start\":42627},{\"end\":42639,\"start\":42634},{\"end\":42649,\"start\":42641},{\"end\":42668,\"start\":42659},{\"end\":42683,\"start\":42677},{\"end\":43084,\"start\":43079},{\"end\":43091,\"start\":43086},{\"end\":43098,\"start\":43093},{\"end\":43106,\"start\":43100},{\"end\":43114,\"start\":43108},{\"end\":43130,\"start\":43121},{\"end\":43138,\"start\":43132},{\"end\":43146,\"start\":43140},{\"end\":43154,\"start\":43148},{\"end\":43163,\"start\":43156},{\"end\":43169,\"start\":43165},{\"end\":43179,\"start\":43171},{\"end\":43191,\"start\":43187},{\"end\":43203,\"start\":43200},{\"end\":43568,\"start\":43566},{\"end\":43576,\"start\":43570},{\"end\":43581,\"start\":43578},{\"end\":43590,\"start\":43583},{\"end\":43603,\"start\":43597},{\"end\":43617,\"start\":43609},{\"end\":43892,\"start\":43889},{\"end\":43898,\"start\":43894},{\"end\":43903,\"start\":43900},{\"end\":43912,\"start\":43905},{\"end\":43916,\"start\":43914},{\"end\":43922,\"start\":43918},{\"end\":43941,\"start\":43931},{\"end\":43955,\"start\":43949},{\"end\":44235,\"start\":44229},{\"end\":44255,\"start\":44242},{\"end\":44260,\"start\":44257},{\"end\":44280,\"start\":44271},{\"end\":44573,\"start\":44566},{\"end\":44590,\"start\":44583},{\"end\":44602,\"start\":44597},{\"end\":45010,\"start\":45006},{\"end\":45018,\"start\":45016},{\"end\":45032,\"start\":45025},{\"end\":45185,\"start\":45180},{\"end\":45201,\"start\":45193},{\"end\":45492,\"start\":45486},{\"end\":45508,\"start\":45500},{\"end\":45516,\"start\":45510},{\"end\":45524,\"start\":45518},{\"end\":45544,\"start\":45533},{\"end\":45556,\"start\":45551},{\"end\":45893,\"start\":45886},{\"end\":45901,\"start\":45895},{\"end\":45907,\"start\":45903},{\"end\":45913,\"start\":45909},{\"end\":45922,\"start\":45915},{\"end\":45930,\"start\":45924},{\"end\":45939,\"start\":45932},{\"end\":45949,\"start\":45941},{\"end\":45955,\"start\":45951},{\"end\":45967,\"start\":45965},{\"end\":45984,\"start\":45974},{\"end\":46283,\"start\":46276},{\"end\":46291,\"start\":46285},{\"end\":46297,\"start\":46293},{\"end\":46305,\"start\":46299},{\"end\":46314,\"start\":46307},{\"end\":46324,\"start\":46316},{\"end\":46330,\"start\":46326},{\"end\":46334,\"start\":46332},{\"end\":46343,\"start\":46336},{\"end\":46355,\"start\":46345},{\"end\":46361,\"start\":46357},{\"end\":46747,\"start\":46739},{\"end\":46755,\"start\":46749},{\"end\":46762,\"start\":46757},{\"end\":46773,\"start\":46769},{\"end\":46787,\"start\":46784},{\"end\":47375,\"start\":47368},{\"end\":47386,\"start\":47382},{\"end\":47396,\"start\":47388},{\"end\":47405,\"start\":47398},{\"end\":47700,\"start\":47693},{\"end\":47709,\"start\":47702},{\"end\":47717,\"start\":47711},{\"end\":47724,\"start\":47719},{\"end\":47738,\"start\":47734},{\"end\":47756,\"start\":47749},{\"end\":48177,\"start\":48173},{\"end\":48184,\"start\":48179},{\"end\":48191,\"start\":48186},{\"end\":48199,\"start\":48193},{\"end\":48204,\"start\":48201},{\"end\":48213,\"start\":48206},{\"end\":48225,\"start\":48215},{\"end\":48236,\"start\":48227},{\"end\":48251,\"start\":48244},{\"end\":48256,\"start\":48253},{\"end\":48265,\"start\":48258},{\"end\":48633,\"start\":48628},{\"end\":48651,\"start\":48642},{\"end\":48883,\"start\":48870},{\"end\":48902,\"start\":48896},{\"end\":49038,\"start\":49030},{\"end\":49056,\"start\":49046},{\"end\":49065,\"start\":49058},{\"end\":49075,\"start\":49067},{\"end\":49083,\"start\":49077},{\"end\":49090,\"start\":49085},{\"end\":49104,\"start\":49097},{\"end\":49113,\"start\":49109},{\"end\":49444,\"start\":49438},{\"end\":49464,\"start\":49457},{\"end\":49472,\"start\":49466},{\"end\":49480,\"start\":49474},{\"end\":49497,\"start\":49488},{\"end\":49512,\"start\":49506},{\"end\":49821,\"start\":49815},{\"end\":49841,\"start\":49834},{\"end\":49847,\"start\":49843},{\"end\":49853,\"start\":49849},{\"end\":49862,\"start\":49855},{\"end\":49871,\"start\":49864},{\"end\":49886,\"start\":49880},{\"end\":49903,\"start\":49894},{\"end\":49918,\"start\":49912},{\"end\":50350,\"start\":50344},{\"end\":50361,\"start\":50356},{\"end\":50379,\"start\":50371},{\"end\":50385,\"start\":50381},{\"end\":50393,\"start\":50387},{\"end\":50400,\"start\":50395},{\"end\":50409,\"start\":50402},{\"end\":50428,\"start\":50411},{\"end\":50436,\"start\":50430},{\"end\":50451,\"start\":50438},{\"end\":50459,\"start\":50453},{\"end\":50471,\"start\":50461},{\"end\":50480,\"start\":50473},{\"end\":50496,\"start\":50482},{\"end\":50502,\"start\":50498},{\"end\":50511,\"start\":50504},{\"end\":50517,\"start\":50513},{\"end\":50527,\"start\":50519},{\"end\":50535,\"start\":50529},{\"end\":50542,\"start\":50537},{\"end\":50551,\"start\":50544},{\"end\":50557,\"start\":50553},{\"end\":50563,\"start\":50559},{\"end\":50577,\"start\":50565},{\"end\":50588,\"start\":50579},{\"end\":50594,\"start\":50590},{\"end\":50605,\"start\":50596},{\"end\":50614,\"start\":50607},{\"end\":50631,\"start\":50626},{\"end\":50644,\"start\":50633},{\"end\":50651,\"start\":50646},{\"end\":50666,\"start\":50659},{\"end\":50682,\"start\":50674},{\"end\":51226,\"start\":51218},{\"end\":51232,\"start\":51228},{\"end\":51248,\"start\":51239},{\"end\":51255,\"start\":51250},{\"end\":51262,\"start\":51257},{\"end\":51274,\"start\":51271},{\"end\":51289,\"start\":51283},{\"end\":51768,\"start\":51761},{\"end\":51776,\"start\":51770},{\"end\":51784,\"start\":51778},{\"end\":51790,\"start\":51786},{\"end\":51799,\"start\":51792},{\"end\":51815,\"start\":51807},{\"end\":51828,\"start\":51820},{\"end\":51838,\"start\":51830},{\"end\":51848,\"start\":51840},{\"end\":51853,\"start\":51850},{\"end\":51863,\"start\":51855},{\"end\":51877,\"start\":51874},{\"end\":51894,\"start\":51889},{\"end\":52280,\"start\":52272},{\"end\":52551,\"start\":52543},{\"end\":52565,\"start\":52559},{\"end\":52819,\"start\":52812},{\"end\":52837,\"start\":52833},{\"end\":53279,\"start\":53277},{\"end\":53286,\"start\":53281},{\"end\":53294,\"start\":53288},{\"end\":53304,\"start\":53300},{\"end\":53313,\"start\":53311},{\"end\":53624,\"start\":53619},{\"end\":53630,\"start\":53626},{\"end\":53637,\"start\":53632},{\"end\":53643,\"start\":53639},{\"end\":53647,\"start\":53645},{\"end\":53656,\"start\":53649},{\"end\":53667,\"start\":53663},{\"end\":53678,\"start\":53673},{\"end\":53821,\"start\":53816},{\"end\":53825,\"start\":53823},{\"end\":53830,\"start\":53827},{\"end\":53834,\"start\":53832},{\"end\":53845,\"start\":53836},{\"end\":53852,\"start\":53847},{\"end\":53862,\"start\":53854},{\"end\":53869,\"start\":53864},{\"end\":53878,\"start\":53871},{\"end\":53893,\"start\":53889},{\"end\":53911,\"start\":53904},{\"end\":53921,\"start\":53913},{\"end\":54329,\"start\":54324},{\"end\":54345,\"start\":54339},{\"end\":54549,\"start\":54545},{\"end\":54564,\"start\":54560},{\"end\":54854,\"start\":54851},{\"end\":54866,\"start\":54856},{\"end\":54875,\"start\":54868},{\"end\":54890,\"start\":54881},{\"end\":54906,\"start\":54901}]", "bib_entry": "[{\"attributes\":{\"doi\":\"abs/1603.06042\",\"id\":\"b0\"},\"end\":38680,\"start\":38258},{\"attributes\":{\"doi\":\"abs/1701.04862\",\"id\":\"b1\"},\"end\":38938,\"start\":38682},{\"attributes\":{\"doi\":\"abs/1701.07875\",\"id\":\"b2\"},\"end\":39127,\"start\":38940},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":1820089},\"end\":39532,\"start\":39129},{\"attributes\":{\"id\":\"b4\"},\"end\":39880,\"start\":39534},{\"attributes\":{\"doi\":\"arXiv:1511.06349\",\"id\":\"b5\"},\"end\":40239,\"start\":39882},{\"attributes\":{\"doi\":\"arXiv:1612.02136\",\"id\":\"b6\"},\"end\":40550,\"start\":40241},{\"attributes\":{\"doi\":\"abs/1312.3005\",\"id\":\"b7\"},\"end\":40948,\"start\":40552},{\"attributes\":{\"doi\":\"arXiv:1409.1259\",\"id\":\"b8\"},\"end\":41321,\"start\":40950},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1033682},\"end\":41775,\"start\":41323},{\"attributes\":{\"id\":\"b10\"},\"end\":41909,\"start\":41777},{\"attributes\":{\"id\":\"b11\"},\"end\":42154,\"start\":41911},{\"attributes\":{\"id\":\"b12\"},\"end\":42341,\"start\":42156},{\"attributes\":{\"id\":\"b13\"},\"end\":42525,\"start\":42343},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":14994977},\"end\":42981,\"start\":42527},{\"attributes\":{\"doi\":\"arXiv:1609.04802\",\"id\":\"b15\"},\"end\":43505,\"start\":42983},{\"attributes\":{\"doi\":\"arXiv:1701.06547\",\"id\":\"b16\"},\"end\":43814,\"start\":43507},{\"attributes\":{\"doi\":\"abs/1612.00370\",\"id\":\"b17\"},\"end\":44151,\"start\":43816},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":252796},\"end\":44496,\"start\":44153},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":205514},\"end\":44948,\"start\":44498},{\"attributes\":{\"doi\":\"abs/1511.06038\",\"id\":\"b20\"},\"end\":45172,\"start\":44950},{\"attributes\":{\"doi\":\"arXiv:1411.1784\",\"id\":\"b21\"},\"end\":45387,\"start\":45174},{\"attributes\":{\"doi\":\"arXiv:1612.00005\",\"id\":\"b22\"},\"end\":45805,\"start\":45389},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":3631537},\"end\":46195,\"start\":45807},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":3631537},\"end\":46665,\"start\":46197},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":11080756},\"end\":47267,\"start\":46667},{\"attributes\":{\"doi\":\"arXiv:1511.06434\",\"id\":\"b26\"},\"end\":47623,\"start\":47269},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":7147309},\"end\":48123,\"start\":47625},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1563370},\"end\":48619,\"start\":48125},{\"attributes\":{\"doi\":\"arXiv:1611.06624\",\"id\":\"b29\"},\"end\":48836,\"start\":48621},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":877639},\"end\":49022,\"start\":48838},{\"attributes\":{\"id\":\"b31\"},\"end\":49338,\"start\":49024},{\"attributes\":{\"id\":\"b32\"},\"end\":49726,\"start\":49340},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":14857825},\"end\":50268,\"start\":49728},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":515925},\"end\":51157,\"start\":50270},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":6138149},\"end\":51661,\"start\":51159},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":94285},\"end\":52170,\"start\":51663},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":2332513},\"end\":52454,\"start\":52172},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":14711886},\"end\":52748,\"start\":52456},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":2783746},\"end\":53201,\"start\":52750},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":3439214},\"end\":53577,\"start\":53203},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":9134916},\"end\":53810,\"start\":53579},{\"attributes\":{\"doi\":\"arXiv:1612.03242\",\"id\":\"b42\"},\"end\":54255,\"start\":53812},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":12964363},\"end\":54479,\"start\":54257},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":1955345},\"end\":54779,\"start\":54481},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":14924561},\"end\":55219,\"start\":54781}]", "bib_title": "[{\"end\":39202,\"start\":39129},{\"end\":39554,\"start\":39534},{\"end\":41350,\"start\":41323},{\"end\":42177,\"start\":42156},{\"end\":42593,\"start\":42527},{\"end\":44216,\"start\":44153},{\"end\":44556,\"start\":44498},{\"end\":45875,\"start\":45807},{\"end\":46265,\"start\":46197},{\"end\":46729,\"start\":46667},{\"end\":47679,\"start\":47625},{\"end\":48171,\"start\":48125},{\"end\":48861,\"start\":48838},{\"end\":49427,\"start\":49340},{\"end\":49804,\"start\":49728},{\"end\":50336,\"start\":50270},{\"end\":51209,\"start\":51159},{\"end\":51748,\"start\":51663},{\"end\":52261,\"start\":52172},{\"end\":52532,\"start\":52456},{\"end\":52806,\"start\":52750},{\"end\":53268,\"start\":53203},{\"end\":53617,\"start\":53579},{\"end\":54313,\"start\":54257},{\"end\":54537,\"start\":54481},{\"end\":54841,\"start\":54781}]", "bib_author": "[{\"end\":38326,\"start\":38312},{\"end\":38341,\"start\":38326},{\"end\":38348,\"start\":38341},{\"end\":38355,\"start\":38348},{\"end\":38364,\"start\":38355},{\"end\":38374,\"start\":38364},{\"end\":38393,\"start\":38374},{\"end\":38402,\"start\":38393},{\"end\":38410,\"start\":38402},{\"end\":38423,\"start\":38410},{\"end\":38440,\"start\":38423},{\"end\":38772,\"start\":38755},{\"end\":38785,\"start\":38772},{\"end\":38959,\"start\":38942},{\"end\":38977,\"start\":38959},{\"end\":38985,\"start\":38977},{\"end\":38991,\"start\":38985},{\"end\":39008,\"start\":38991},{\"end\":39014,\"start\":39008},{\"end\":39212,\"start\":39204},{\"end\":39218,\"start\":39212},{\"end\":39227,\"start\":39218},{\"end\":39234,\"start\":39227},{\"end\":39250,\"start\":39234},{\"end\":39264,\"start\":39250},{\"end\":39573,\"start\":39556},{\"end\":39588,\"start\":39573},{\"end\":39945,\"start\":39928},{\"end\":39953,\"start\":39945},{\"end\":39959,\"start\":39953},{\"end\":39968,\"start\":39959},{\"end\":39975,\"start\":39968},{\"end\":39989,\"start\":39975},{\"end\":40007,\"start\":39989},{\"end\":40015,\"start\":40007},{\"end\":40021,\"start\":40015},{\"end\":40246,\"start\":40241},{\"end\":40252,\"start\":40246},{\"end\":40256,\"start\":40252},{\"end\":40270,\"start\":40256},{\"end\":40282,\"start\":40270},{\"end\":40297,\"start\":40282},{\"end\":40308,\"start\":40297},{\"end\":40652,\"start\":40636},{\"end\":40661,\"start\":40652},{\"end\":40668,\"start\":40661},{\"end\":40678,\"start\":40668},{\"end\":40684,\"start\":40678},{\"end\":40688,\"start\":40684},{\"end\":40692,\"start\":40688},{\"end\":40709,\"start\":40692},{\"end\":40725,\"start\":40709},{\"end\":40965,\"start\":40950},{\"end\":40982,\"start\":40965},{\"end\":40988,\"start\":40982},{\"end\":41006,\"start\":40988},{\"end\":41021,\"start\":41006},{\"end\":41368,\"start\":41352},{\"end\":41383,\"start\":41368},{\"end\":41389,\"start\":41383},{\"end\":41396,\"start\":41389},{\"end\":41403,\"start\":41396},{\"end\":41407,\"start\":41403},{\"end\":41421,\"start\":41407},{\"end\":41429,\"start\":41421},{\"end\":41436,\"start\":41429},{\"end\":41443,\"start\":41436},{\"end\":41452,\"start\":41443},{\"end\":41469,\"start\":41452},{\"end\":41484,\"start\":41469},{\"end\":41796,\"start\":41777},{\"end\":41968,\"start\":41961},{\"end\":41975,\"start\":41968},{\"end\":41986,\"start\":41975},{\"end\":41992,\"start\":41986},{\"end\":42007,\"start\":41992},{\"end\":42022,\"start\":42007},{\"end\":42196,\"start\":42179},{\"end\":42216,\"start\":42196},{\"end\":42431,\"start\":42423},{\"end\":42606,\"start\":42595},{\"end\":42613,\"start\":42606},{\"end\":42622,\"start\":42613},{\"end\":42634,\"start\":42622},{\"end\":42641,\"start\":42634},{\"end\":42651,\"start\":42641},{\"end\":42670,\"start\":42651},{\"end\":42685,\"start\":42670},{\"end\":43086,\"start\":43069},{\"end\":43093,\"start\":43086},{\"end\":43100,\"start\":43093},{\"end\":43108,\"start\":43100},{\"end\":43116,\"start\":43108},{\"end\":43132,\"start\":43116},{\"end\":43140,\"start\":43132},{\"end\":43148,\"start\":43140},{\"end\":43156,\"start\":43148},{\"end\":43165,\"start\":43156},{\"end\":43171,\"start\":43165},{\"end\":43181,\"start\":43171},{\"end\":43193,\"start\":43181},{\"end\":43205,\"start\":43193},{\"end\":43570,\"start\":43560},{\"end\":43578,\"start\":43570},{\"end\":43583,\"start\":43578},{\"end\":43592,\"start\":43583},{\"end\":43605,\"start\":43592},{\"end\":43619,\"start\":43605},{\"end\":43894,\"start\":43889},{\"end\":43900,\"start\":43894},{\"end\":43905,\"start\":43900},{\"end\":43914,\"start\":43905},{\"end\":43918,\"start\":43914},{\"end\":43924,\"start\":43918},{\"end\":43943,\"start\":43924},{\"end\":43957,\"start\":43943},{\"end\":44237,\"start\":44218},{\"end\":44257,\"start\":44237},{\"end\":44262,\"start\":44257},{\"end\":44282,\"start\":44262},{\"end\":44575,\"start\":44558},{\"end\":44592,\"start\":44575},{\"end\":44604,\"start\":44592},{\"end\":45012,\"start\":45000},{\"end\":45020,\"start\":45012},{\"end\":45034,\"start\":45020},{\"end\":45187,\"start\":45174},{\"end\":45203,\"start\":45187},{\"end\":45494,\"start\":45482},{\"end\":45510,\"start\":45494},{\"end\":45518,\"start\":45510},{\"end\":45526,\"start\":45518},{\"end\":45546,\"start\":45526},{\"end\":45558,\"start\":45546},{\"end\":45895,\"start\":45877},{\"end\":45903,\"start\":45895},{\"end\":45909,\"start\":45903},{\"end\":45915,\"start\":45909},{\"end\":45924,\"start\":45915},{\"end\":45932,\"start\":45924},{\"end\":45941,\"start\":45932},{\"end\":45951,\"start\":45941},{\"end\":45957,\"start\":45951},{\"end\":45969,\"start\":45957},{\"end\":45986,\"start\":45969},{\"end\":46285,\"start\":46267},{\"end\":46293,\"start\":46285},{\"end\":46299,\"start\":46293},{\"end\":46307,\"start\":46299},{\"end\":46316,\"start\":46307},{\"end\":46326,\"start\":46316},{\"end\":46332,\"start\":46326},{\"end\":46336,\"start\":46332},{\"end\":46345,\"start\":46336},{\"end\":46357,\"start\":46345},{\"end\":46363,\"start\":46357},{\"end\":46749,\"start\":46731},{\"end\":46757,\"start\":46749},{\"end\":46764,\"start\":46757},{\"end\":46775,\"start\":46764},{\"end\":46789,\"start\":46775},{\"end\":47377,\"start\":47363},{\"end\":47388,\"start\":47377},{\"end\":47398,\"start\":47388},{\"end\":47407,\"start\":47398},{\"end\":47702,\"start\":47681},{\"end\":47711,\"start\":47702},{\"end\":47719,\"start\":47711},{\"end\":47726,\"start\":47719},{\"end\":47740,\"start\":47726},{\"end\":47758,\"start\":47740},{\"end\":48179,\"start\":48173},{\"end\":48186,\"start\":48179},{\"end\":48193,\"start\":48186},{\"end\":48201,\"start\":48193},{\"end\":48206,\"start\":48201},{\"end\":48215,\"start\":48206},{\"end\":48227,\"start\":48215},{\"end\":48238,\"start\":48227},{\"end\":48253,\"start\":48238},{\"end\":48258,\"start\":48253},{\"end\":48267,\"start\":48258},{\"end\":48635,\"start\":48621},{\"end\":48653,\"start\":48635},{\"end\":48885,\"start\":48863},{\"end\":48904,\"start\":48885},{\"end\":49040,\"start\":49026},{\"end\":49058,\"start\":49040},{\"end\":49067,\"start\":49058},{\"end\":49077,\"start\":49067},{\"end\":49085,\"start\":49077},{\"end\":49092,\"start\":49085},{\"end\":49106,\"start\":49092},{\"end\":49115,\"start\":49106},{\"end\":49446,\"start\":49429},{\"end\":49466,\"start\":49446},{\"end\":49474,\"start\":49466},{\"end\":49482,\"start\":49474},{\"end\":49499,\"start\":49482},{\"end\":49514,\"start\":49499},{\"end\":49823,\"start\":49806},{\"end\":49843,\"start\":49823},{\"end\":49849,\"start\":49843},{\"end\":49855,\"start\":49849},{\"end\":49864,\"start\":49855},{\"end\":49873,\"start\":49864},{\"end\":49888,\"start\":49873},{\"end\":49905,\"start\":49888},{\"end\":49920,\"start\":49905},{\"end\":50352,\"start\":50338},{\"end\":50363,\"start\":50352},{\"end\":50381,\"start\":50363},{\"end\":50387,\"start\":50381},{\"end\":50395,\"start\":50387},{\"end\":50402,\"start\":50395},{\"end\":50411,\"start\":50402},{\"end\":50430,\"start\":50411},{\"end\":50438,\"start\":50430},{\"end\":50453,\"start\":50438},{\"end\":50461,\"start\":50453},{\"end\":50473,\"start\":50461},{\"end\":50482,\"start\":50473},{\"end\":50498,\"start\":50482},{\"end\":50504,\"start\":50498},{\"end\":50513,\"start\":50504},{\"end\":50519,\"start\":50513},{\"end\":50529,\"start\":50519},{\"end\":50537,\"start\":50529},{\"end\":50544,\"start\":50537},{\"end\":50553,\"start\":50544},{\"end\":50559,\"start\":50553},{\"end\":50565,\"start\":50559},{\"end\":50579,\"start\":50565},{\"end\":50590,\"start\":50579},{\"end\":50596,\"start\":50590},{\"end\":50607,\"start\":50596},{\"end\":50616,\"start\":50607},{\"end\":50633,\"start\":50616},{\"end\":50646,\"start\":50633},{\"end\":50653,\"start\":50646},{\"end\":50668,\"start\":50653},{\"end\":50684,\"start\":50668},{\"end\":51228,\"start\":51211},{\"end\":51234,\"start\":51228},{\"end\":51250,\"start\":51234},{\"end\":51257,\"start\":51250},{\"end\":51264,\"start\":51257},{\"end\":51276,\"start\":51264},{\"end\":51291,\"start\":51276},{\"end\":51770,\"start\":51750},{\"end\":51778,\"start\":51770},{\"end\":51786,\"start\":51778},{\"end\":51792,\"start\":51786},{\"end\":51801,\"start\":51792},{\"end\":51817,\"start\":51801},{\"end\":51830,\"start\":51817},{\"end\":51840,\"start\":51830},{\"end\":51850,\"start\":51840},{\"end\":51855,\"start\":51850},{\"end\":51865,\"start\":51855},{\"end\":51879,\"start\":51865},{\"end\":51896,\"start\":51879},{\"end\":52282,\"start\":52263},{\"end\":52553,\"start\":52534},{\"end\":52567,\"start\":52553},{\"end\":52821,\"start\":52808},{\"end\":52839,\"start\":52821},{\"end\":53281,\"start\":53270},{\"end\":53288,\"start\":53281},{\"end\":53296,\"start\":53288},{\"end\":53306,\"start\":53296},{\"end\":53315,\"start\":53306},{\"end\":53626,\"start\":53619},{\"end\":53632,\"start\":53626},{\"end\":53639,\"start\":53632},{\"end\":53645,\"start\":53639},{\"end\":53649,\"start\":53645},{\"end\":53658,\"start\":53649},{\"end\":53669,\"start\":53658},{\"end\":53680,\"start\":53669},{\"end\":53823,\"start\":53812},{\"end\":53827,\"start\":53823},{\"end\":53832,\"start\":53827},{\"end\":53836,\"start\":53832},{\"end\":53847,\"start\":53836},{\"end\":53854,\"start\":53847},{\"end\":53864,\"start\":53854},{\"end\":53871,\"start\":53864},{\"end\":53880,\"start\":53871},{\"end\":53895,\"start\":53880},{\"end\":53913,\"start\":53895},{\"end\":53923,\"start\":53913},{\"end\":54331,\"start\":54315},{\"end\":54347,\"start\":54331},{\"end\":54551,\"start\":54539},{\"end\":54566,\"start\":54551},{\"end\":54856,\"start\":54843},{\"end\":54868,\"start\":54856},{\"end\":54877,\"start\":54868},{\"end\":54892,\"start\":54877},{\"end\":54908,\"start\":54892}]", "bib_venue": "[{\"end\":38310,\"start\":38258},{\"end\":38753,\"start\":38682},{\"end\":39313,\"start\":39264},{\"end\":39666,\"start\":39588},{\"end\":39926,\"start\":39882},{\"end\":40372,\"start\":40324},{\"end\":40634,\"start\":40552},{\"end\":41111,\"start\":41036},{\"end\":41533,\"start\":41484},{\"end\":41830,\"start\":41796},{\"end\":41959,\"start\":41911},{\"end\":42234,\"start\":42216},{\"end\":42421,\"start\":42343},{\"end\":42734,\"start\":42685},{\"end\":43067,\"start\":42983},{\"end\":43558,\"start\":43507},{\"end\":43887,\"start\":43816},{\"end\":44307,\"start\":44282},{\"end\":44682,\"start\":44604},{\"end\":44998,\"start\":44950},{\"end\":45257,\"start\":45218},{\"end\":45480,\"start\":45389},{\"end\":45990,\"start\":45986},{\"end\":46412,\"start\":46363},{\"end\":46872,\"start\":46789},{\"end\":47361,\"start\":47269},{\"end\":47836,\"start\":47758},{\"end\":48335,\"start\":48267},{\"end\":48705,\"start\":48669},{\"end\":48911,\"start\":48904},{\"end\":49521,\"start\":49514},{\"end\":49984,\"start\":49920},{\"end\":50690,\"start\":50684},{\"end\":51368,\"start\":51291},{\"end\":51905,\"start\":51896},{\"end\":52298,\"start\":52282},{\"end\":52585,\"start\":52567},{\"end\":52925,\"start\":52839},{\"end\":53379,\"start\":53315},{\"end\":53685,\"start\":53680},{\"end\":54023,\"start\":53939},{\"end\":54352,\"start\":54347},{\"end\":54604,\"start\":54566},{\"end\":54968,\"start\":54908},{\"end\":39731,\"start\":39668},{\"end\":44747,\"start\":44684},{\"end\":46942,\"start\":46874},{\"end\":47901,\"start\":47838},{\"end\":48390,\"start\":48337},{\"end\":51432,\"start\":51370},{\"end\":53005,\"start\":52927},{\"end\":55015,\"start\":54970}]"}}}, "year": 2023, "month": 12, "day": 17}