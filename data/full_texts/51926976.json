{"id": 51926976, "updated": "2023-09-30 18:02:29.924", "metadata": {"title": "code2seq: Generating Sequences from Structured Representations of Code", "authors": "[{\"first\":\"Uri\",\"last\":\"Alon\",\"middle\":[]},{\"first\":\"Omer\",\"last\":\"Levy\",\"middle\":[]},{\"first\":\"Eran\",\"last\":\"Yahav\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2018, "month": 8, "day": 4}, "abstract": "The ability to generate natural language sequences from source code snippets has a variety of applications such as code summarization, documentation, and retrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine translation (NMT), have achieved state-of-the-art performance on these tasks by treating source code as a sequence of tokens. We present ${\\rm {\\scriptsize CODE2SEQ}}$: an alternative approach that leverages the syntactic structure of programming languages to better encode source code. Our model represents a code snippet as the set of compositional paths in its abstract syntax tree (AST) and uses attention to select the relevant paths while decoding. We demonstrate the effectiveness of our approach for two tasks, two programming languages, and four datasets of up to $16$M examples. Our model significantly outperforms previous models that were specifically designed for programming languages, as well as state-of-the-art NMT models.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1808.01400", "mag": "2951861246", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iclr/AlonBLY19", "doi": null}}, "content": {"source": {"pdf_hash": "f6cfbb075b6ae54b81ce94c064d06696dafd0d4e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1808.01400v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "7d5deffde98b1a2c0fecfdff4ce5abeffc03a0c5", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f6cfbb075b6ae54b81ce94c064d06696dafd0d4e.txt", "contents": "\nCODE2SEQ: GENERATING SEQUENCES FROM STRUCTURED REPRESENTATIONS OF CODE\n\n\nUri Alon urialon@cs.technion.ac.il \nFacebook AI Research\nTechnion, Technion\n\nOmer Levy omerlevy@gmail.com \nFacebook AI Research\nTechnion, Technion\n\nEran Yahav yahave@cs.technion.ac.il \nFacebook AI Research\nTechnion, Technion\n\nCODE2SEQ: GENERATING SEQUENCES FROM STRUCTURED REPRESENTATIONS OF CODE\n\nThe ability to generate natural language sequences from source code snippets has a variety of applications such as code summarization, documentation, and retrieval. Sequence-to-sequence (seq2seq) models, adopted from neural machine translation (NMT), have achieved state-of-the-art performance on these tasks by treating source code as a sequence of tokens. We present CODE2SEQ: an alternative approach that leverages the syntactic structure of programming languages to better encode source code. Our model represents a code snippet as the set of compositional paths in its abstract syntax tree (AST) and uses attention to select the relevant paths while decoding. We demonstrate the effectiveness of our approach for two tasks, two programming languages, and four datasets of up to 16M examples. Our model significantly outperforms previous models that were specifically designed for programming languages, as well as state-of-the-art NMT models.\n\nINTRODUCTION\n\nModeling the relation between source code and natural language can be used for automatic code summarization (Allamanis et al., 2016), documentation (Iyer et al., 2016), retrieval (Allamanis et al., 2015b), and even generation (Balog et al., 2016;Rabinovich et al., 2017;Yin and Neubig, 2017;Devlin et al., 2017;Murali et al., 2017). In this work, we consider the general problem of generating a natural language sequence from a given snippet of source code.\n\nA direct approach is to frame the problem as a machine translation problem, where the source sentence is the sequence of tokens in the code and the target sentence is a corresponding natural language sequence. This approach allows one to apply state-of-the-art neural machine translation (NMT) models from the sequence-to-sequence (seq2seq) paradigm Luong et al., 2015;Vaswani et al., 2017), yielding state-ofthe-art performance on various code captioning and documentation benchmarks (Iyer et al., 2016;Allamanis et al., 2016;Loyola et al., 2017) despite having extremely long source sequences.\n\nWe present an alternative approach for encoding source code that leverages the syntactic structure of programming languages: CODE2SEQ. Specifically, we represent a given code snippet as a set of compositional paths over its abstract syntax tree (AST), where each path is compressed to a fixed-length vector using LSTMs (Hochreiter and Schmidhuber, 1997). During decoding, CODE2SEQ attends over a different weighted sum of the path-vectors to produce each output token, much like NMT models attend over token representations in the source sentence.\n\nWe show the effectiveness of our code2seq model on two tasks: (1) code summarization (Figure 1a), where we predict a Java method's name given its body, and (2) code captioning (Figure 1b), where we predict a natural language sentence that describes a given C# snippet. On both tasks, our CODE2SEQ model outperforms models that were explicitly designed for code, such as the model of Allamanis et al. (2016) and CodeNN (Iyer et al., 2016), as well as state-of-the-art NMT models (Luong et al., 2015;Vaswani et al., 2017). To examine the importance of each component of the 1 arXiv:1808.01400v2 [cs.LG] 10 Oct 2018\n\nCode summarization in Java:\n\nCode captioning in C#: (a) (b) Figure 1: Example of (a) code summarization of a Java code snippet, and (b) code captioning of a C# code snippet, along with the predictions produced by our models. The highlighted paths in each example are the top-attended paths in each decoding step. Because of space limitations we included only the top attended path for each decoding step, but hundreds of paths are attended at each step. Additional examples are presented in Appendix A and Appendix B.\n\nmodel, we conduct a thorough ablation study. In particular, we show the importance of structural encoding of code, by showing how our model yields a significant improvement over an ablation that uses only token-level information without syntactic paths. To the best of our knowledge, this is the first work to leverage the syntactic structure of code for end-to-end generation of sequences.\n\n\nREPRESENTING CODE AS AST PATHS\n\nAn Abstract Syntax Tree (AST) is a tree which uniquely represents a source code snippet in a given language and grammar. The leaves of the tree are called terminals, and usually refer to userdefined values which represent identifiers and names from the code. The non-leaf nodes are called nonterminals and represent a restricted set of structures in the language, e.g., loops, expressions, and variable declarations. For example, Figure 2c shows a partial AST for the code snippet of Figure 2a. Names (such as num) and types (such as int) are represented as values of terminals; syntactic structures such as variable declaration (VarDec) and a do-while loop (DoStmt) are represented as nonterminals.\n\nGiven the AST of a code snippet, we consider all pairwise paths between terminals, and represent them as sequences of terminal and nonterminal nodes. We then use these paths with their terminals' values to represent the code snippet itself. For example, consider the two Java methods of Figure 2. Both of these methods count occurrences of a character in a string. They have exactly the same functionality, although a different implementation, and therefore different surface forms. Encoding these snippets of code as sequences of tokens might overlook the recurring patterns that suggest the common method name. However, a structural observation reveals syntactic paths that are common to both methods, and differ only in a single node of a Do-while statement versus a For statement. This example shows the effectiveness of a syntactic encoding of code. Such an encoder can generalize much better to unseen examples because the AST normalizes a lot of the surface form variance. Since our encoding is compositional, the encoder can generalize even if the paths are not identical (e.g., a For node in one path and a While in the other).\n\nSince a code snippet can contain an arbitrary number of such paths, we sample k paths as the representation of the code snippet. To avoid bias, k new paths are sampled afresh in every training iteration. In Section 5 we show that this runtime-sampling provides regularization and improves results compared to sampling the same k paths for each example in advance.\n\nFormally, we use C to denote a given snippet of code. Every training iteration k pairs of terminals are uniformly sampled from within the AST of C. Each pair of terminals v i 1 , v i li implies a single path between them: v i 1 v i 2 ...v i li . Finally, the input code example is represented as a set of these k random AST paths:\nv 1 1 v 1 2 ...v 1 l1 , ..., v k 1 v k 2 ...v k l k\n, where l j is the length of the jth path.  Figure 2: An example of two Java methods that have exactly the same functionality. Although having a different sequential (token-based) representation, considering syntactic patterns reveals recurring paths, which might differ only in a single node (a ForStmt node instead of a Do-while node).\n\n\nMODEL ARCHITECTURE\n\nOur model follows the standard encoder-decoder architecture for NMT (Section 3.1), with the significant difference that the encoder does not read the input as a flat sequence of tokens. Instead, the encoder creates a vector representation for each AST path separately (Section 3.2). The decoder then attends over the encoded AST paths (rather than the encoded tokens) while generating the target sequence. An illustration of our model is shown in Figure 3.\n\n\nENCODER-DECODER FRAMEWORK\n\nContemporary NMT models are largely based on an encoder-decoder architecture Luong et al., 2015;, where the encoder maps an input sequence of tokens x = (x 1 , ..., x n ) to a sequence of continuous representations z = (z 1 , ..., z n ). Given z, the decoder then generates a sequence of output tokens y = (y 1 , ..., y m ) one token at a time, hence modeling the conditional probability: p (y 1 , ..., y m |x 1 , ..., x n ).\n\nAt each decoding step, the probability of the next target token depends on the previously generated token, and can therefore be factorized as:\n\np (y 1 , ..., y m |x 1 , ..., x n ) = m j=1 p (y j |y <j , z 1 , ..., z n )\n\nIn attention-based models, at each time step t in the decoding phase, a context vector c t is computed by attending over the elements in z using the decoding state h t , typically computed by an LSTM.\n\u03b1 t = sof tmax (h t W a z) c t = n i \u03b1 t i z i(2)\nThe context vector c t and the decoding state h t are then combined to predict the current target token y t . Previous work differs in the way the context vector is computed and in the way it is combined with the current decoding state. A standard approach (Luong et al., 2015) is to pass c t and h t through a multi-layer perceptron (MLP) and then predict the probability of the next token using softmax:\np (y t |y <t , z 1 , ..., z n ) = sof tmax (W s tanh (W c [c t ; h t ]))(3)\n\nAST ENCODER\n\nGiven a set of AST paths (x 1 , ..., x k ), our goal is to create a vector representation z i for each path\nx i = v i 1 v i 2 ...v i li .\nWe represent each path separately using a bi-directional LSTM to encode the path, and sub-token embeddings to capture the compositional nature of the terminals' values (the tokens).\n\nPath Representation Each AST path is composed of nodes and their child indices from a limited vocabulary of up to 364 symbols. We represent each node using a learned embedding matrix E nodes and then encode the entire sequence using the final states of a bi-directional LSTM:\nh 1 , ..., h l = LST M (E nodes v1 , ..., E nodes v l ) (4) encode path(v 1 ...v l ) = [h \u2192 l ; h \u2190 1 ](5)\nToken Representation The first and last node of an AST path are terminals whose values are tokens in the code. Following Allamanis et al. (2015a;, we split code tokens into subtokens; for example, a token with the value ArrayList, will be decomposed into Array and List. This is somewhat analogous to byte-pair encoding in NMT (Sennrich et al., 2016), although in the case of programming languages, coding conventions such as camel notation provide us with an explicit partition of each token. Specifically, we use a learned embedding matrix E subtokens to represent each subtoken, and then sum the subtoken vectors to represent the full token:\nencode token(w) = s\u2208split(w) E subtokens s(6)\nThe LSTM decoder may also predict subtokens at each step (e.g. when generating method names), although the decoder's subtoken embedding matrix will be different.\n\n\nCombined Representation\n\nTo represent the entire path x = v 1 ...v l , we concatenate the path's representation with each of the token representation of each terminal node, and apply a fullyconnected layer:\nz = tanh (W in [encode path(v 1 ...v l ); encode token(value(v 1 )); encode token(value(v l ))]) (7)\nwhere value is the mapping of a terminal node to its associated value, and W in is a (2d path + 2d token ) \u00d7 d hidden matrix.\n\nDecoder Start State To provide the decoder with an initial state, we average the combined representations of all the paths:\nh 0 = 1 k k i=1 z i(8)\nUnlike typical encoder-decoder models, the order of the input random paths is not taken into account. Each path is encoded separately and the combined representations are aggregated with mean pooling to initialize the decoder's state. This represents the given source code as a set of random paths.\n\nAttention Finally, the decoder generates the output sequence while attending over the combined representations z i , ...z k , similarly to the way that seq2seq models attend over the source symbols.\n\n\nEXPERIMENTS\n\nWe evaluate our model on two code-to-sequence tasks: summarization (Section 4.1), in which we predict Java methods' names from their bodies, and captioning (Section 4.2), where we generate natural language descriptions of C# code snippets. We thus demonstrate that our approach can produce both method names and natural language outputs, and can encode a code snippet in any language for which an AST can be constructed (i.e., a parser exists).\n\nSetup The values of all of the parameters are initialized using the initialization heuristic of Glorot and Bengio (2010). We optimize the cross-entropy loss (Rubinstein, 1999;2001) with a Nesterov momentum (Nesterov, 1983) of 0.95 and an initial learning rate of 0.01, decayed by a factor of 0.95 every epoch. We apply dropout (Srivastava et al., 2014) of 0.25 on the input vectors x j , and a recurrent dropout of 0.5 on the LSTM that encodes the AST paths. We used d tokens = d nodes = d hidden = d target = 128. Each LSTM that encodes the AST paths had 128 cells and the decoder LSTM had 320 cells. We used k = 200 as the number of random paths on each example.\n\n\nCODE SUMMARIZATION\n\nIn this task, we predict a Java method's name given its body. As was previously observed (Allamanis et al., 2016;Alon et al., 2018a), this is a good benchmark because a method name in open-source Java projects tends to be succinct and precise, and a method body is often a complete logical unit. We predict the target method name as a sequence of sub-tokens, e.g., setMaxConnectionsPerServer is predicted as the sequence \"set max connections per server\". The target sequence length is about 3 on average. We adopt the measure used by Allamanis et al. (2016) and Alon et al. (2018a), who measured precision, recall, and F1 score over the target sequence, case insensitive.\n\nData We experiment with this task across three datsets:\n\nJava-small -Contains 11 relatively large Java projects, which were originally used for 11 distinct models for training and predicting within the scope of the same project (Allamanis et al., 2016). We use the same data, but train and predict across projects: we took 9 projects for training, 1 project for validation and 1 project as our test set. This dataset contains about 700K examples.\n\nJava-med -A new dataset of the 1000 top-starred Java projects from GitHub. We randomly select 800 projects for training, 100 for validation and 100 for testing. This dataset contains about 4M examples and we make it publicly available.\n\nJava-large -A new dataset of the 9500 top-starred Java projects from GitHub that were created since January 2007. We randomly select 9000 projects for training, 200 for validation and 300 for testing. This dataset contains about 16M examples and we make it publicly available.\n\nBaselines We re-trained all of the baselines on all of the datasets of this task using the original implementations of the authors. We compare CODE2SEQ to the following baselines: Allamanis et al. (2016) who used a convolutional attention network to predict method names, syntactic paths with Conditional Random Fields (CRFs) (Alon et al., 2018b), and code2vec (Alon et al., 2018a). In addition, we compared to three NMT baselines that read the input source code as a stream of tokens: a 2-layer bidirectional encoder-decoder LSTMs (split tokens and full tokens) with global attention (Luong et al., 2015), and the Transformer (Vaswani et al., 2017) which achieved state-of-the-art results for translation tasks.\n\nOur model is incomparable to the model of Allamanis et al. (2018) because they targeted a different task of predicting variable names, and are unable to generate target sequences. We could not compare to the work of Liang and Zhu (2018) due to replicability issues. 1\n\nWe put significant effort to strengthen the NMT baselines in order to provide a fair comparison: (1) we split tokens to subtokens, as in our model (e.g., HashSet \u2192 Hash Set) -this was shown to Performance Table 1 shows the results for the code summarization task. Our model significantly outperforms the baselines in both precision and recall across all the three datasets, demonstrating that there is added value in leveraging ASTs to encode source code. Our model improves over the best baselines, BiLSTM with split tokens, by between 4 to 8 F1 points on all benchmarks. The BiLSTM with split tokens consistently achieved about 10 F1 score more than BiLSTM with full tokens, and for this reason we included only a split token Transformer baseline. Our model outperforms ConvAttention (Allamanis et al., 2016), which was designed specifically for this task, and outperforms Paths+CRFs (Alon et al., 2018b) which used syntactic features. Examples for predictions made by our model and each of the baselines can be found in Appendix B.\n\nData Efficiency ConvAttention (Allamanis et al., 2016) performed even better than the Transformer on the Java-small dataset, but could not scale and leverage the larger datasets. Paths+CRFs showed very low results on the Java-small dataset, which is expected due to the sparse nature of their paths and the CRF model. When comparing our model with the best among the baselines (BiLSTM with split tokens), we see that our model achieves a relative improvement of 7.3% on Java-large, but as the dataset goes smaller -the larger the relative difference becomes: 13% on Java-med and 22% on Java-small; when comparing to the Transformer: a relative improvement of 23% on Java-large and 37% on Java-small. These results show the data efficiency of our architecture: while the data-hungry NMT baselines require large datasets, our model can leverage both small and large datasets.\n\n\nCODE CAPTIONING\n\nFor this task we consider predicting a full natural language sentence given a short C# code snippet. We used the dataset of CodeNN (Iyer et al., 2016), which consists of 66,015 pairs of questions and answers from StackOverflow. They used a semi-supervised classifier to filter irrelevant examples and asked human annotators to provide two additional titles for the examples in the test set, making a total of three reference titles for each code snippet. The target sequence length in this task is about 10 on average. This dataset is especially challenging as it is orders of magnitude smaller than the code summarization datasets. Additionally, StackOverflow code snippets are typically short, incomplete at times, and aim to provide an answer to a very specific question. We evaluated using BLEU score with smoothing, using the same evaluation scripts as Iyer et al. (2016).\n\nBaselines We present results compared to CodeNN, 2-layer bidirectional LSTMs with attention, and the Transformer. As before, we provide a fair comparison by splitting tokens to subtokens, and replacing UNK during inference. We also include numbers from baselines used by Iyer et al. (2016).  Iyer et al. (2016), and verified by us. Another visualization can be found in Appendix C.\n\nModel BLEU MOSES \u2020 (Koehn et al., 2007) 11.57 IR \u2020 13.66 SUM-NN \u2020 (Rush et al., 2015) 19.31 2-layer BiLSTM 19.78 Transformer (Vaswani et al., 2017) 19.68 CodeNN \u2020 (Iyer et al., 2016) 20.53 code2seq 23.04\n\nResults \n\n\nABLATION STUDY\n\nTo better understand the importance of different components of our model, we conducted an extensive ablation study. We vary our model in different ways and measure the change in performance. These experiments were performed for the code summarization task, on the validation set of the Java-med dataset. We examine several alternative designs:\n\n1. No AST nodes -instead of encoding an AST path using an LSTM, take only the first and last terminal values for constructing an input vector 2. No decoder -no sequential decoding; instead, predict the target sequence as a single symbol using a single softmax layer.\n\n3. No token splitting -no subtoken encoding; instead, embed the full token.\n\n\n4.\n\nNo tokens -use only the AST nodes without using the values associated with the terminals.\n\n\n5.\n\nNo attention -decode the target sequence given the initial decoder state, without attention.\n\n\n6.\n\nNo random -no re-sampling of k paths in each iteration; instead, sample in advance and use the same k paths for each example throughout the whole training process. Table 3 shows the results of these alternatives. As seen, not encoding AST nodes resulted in a degradation especially in the precision: a decrease of 5.42 compared to 2.66 for the recall. Using a single prediction with no decoder reduces recall by more than a third. This shows that the method name prediction task should be addressed as a sequential prediction, despite the methods' relatively short names. Using no token splitting or no tokens at all drastically hurt the results, showing the significance of encoding both subtokens and syntactic paths. Despite the low results of no tokens, it is still surprising that the model can achieve around half the score of the full model, as using no tokens is equivalent to reasoning about code which has no identifier names, types, APIs, and constant values and can be very difficult even for a human. The no attention experiment shows the contribution of attention in our model, which is very close in its relative value to the contribution of attention in seq2seq models (Luong et al., 2015;. The no random experiment shows the positive contribution of sampling k different paths afresh on every training iteration, instead of using the same sample of paths from each example during whole training. This approach provides data-level regularization that gives additional improvement to a model that is very powerful already. Another visualization can be found in Appendix C. \n\n\nRELATED WORK\n\nThe growing availability of open source repositories creates new opportunities for using machine learning to process source code en masse. Several papers model code as a sequence of tokens (Iyer et al., 2016;Allamanis et al., 2016;Loyola et al., 2017), characters (Bielik et al., 2017), and API calls (Raychev et al., 2014). While sometimes obtaining satisfying results, these models treat code as a sequence rather than a tree. This forces these techniques to implicitly re-learn the (predefined) syntax of the programming language, wasting resources and reducing accuracy.\n\nCode representation models that use syntactic information have usually been evaluated on relatively easier tasks, which mainly focus on \"filling the blanks\" in a given program (Alon et al., 2018b;Allamanis et al., 2018) or semantic classification of code snippets (Alon et al., 2018a). Moreover, none of the models that use syntactic relations are compositional, and therefore the number of possible syntactic relations is fixed either before or after training, and often consumes a lot of memory. The syntactic paths of Alon et al. (2018b;a) are represented monolithically, and are therefore limited to only a subset of the paths that were observed enough times during training. As a result, they cannot represent unseen relations. In contrast, by representing AST paths node-by-node using LSTMs, our model can represent and use any syntactic path in any unseen example. Further, our model decodes the output sequence step-by-step while attending over the input paths, and can thus generate unseen sequences, compared to code2vec (Alon et al., 2018a) which has a closed vocabulary. Allamanis et al. (2018) represent code with Gated Graph Neural Networks. Nodes in the graph represent identifiers, and edges represent syntactic and semantic relations in the code such as \"Com-putedFrom\" and \"LastWrite\". The kinds of edges (features) are designed for the semantics of a specific programming language, for a specific task, and require an expert to think of and implement.\n\nIn contrast, our model has minimal assumptions on the input language and is general enough not to require neither expert semantic knowledge nor the manual design of features. Our model can therefore be easily implemented for various input languages. Liang and Zhu (2018) presented a Tree-RNN model for learning code, but its evaluation contains many irregularities (for example, the seq2seq baselines were deprived of non-alphanumeric tokens, which are critical for capturing assignments, method calls, and other basic operations).\n\n\nCONCLUSION\n\nWe presented a novel code-to-sequence model which considers the unique syntactic structure of source code with a sequential modeling of natural language. The core idea is to sample paths in the Abstract Syntax Tree of a code snippet, encode those paths with an LSTM and attend to them while generating the target sequence.\n\nWe demonstrate our approach by using it to predict method names across three datasets of varying sizes, predict natural language captions given partial and short code snippets, in two programming languages. Our model performs significantly better than previous programming-language-oriented works and state of the art NMT models applied in our settings.\n\nWe believe that the principles presented in this paper can serve as a basis for a wide range of tasks which involve source code and natural language, and can be extended to other kinds of generated outputs. To this end, we make all our code, datasets, and trained models publicly available.\n\n\n8\n\nA CODE CAPTIONING EXAMPLES Figure 5 contains examples from our test set for the code captioning task in C#, along with the prediction of our model and each of the baselines. Figure 4 shows a timestep-by-timestep example, with the symbol decoded at each timestep and the top-attended path at that step. The width of the path is proportional to the attention it was given by the model (because of space limitations we included only the top-attended path for each decoding step, but hundreds of paths are attended at each step). Figure 7 contains examples from our test set for the code summarization task in C#, along with the prediction of our model and each of the baselines. The presented predictions are made by models that were trained on the same Java-large dataset.\n\n\nB CODE SUMMARIZATION\n\nC CODE CAPTIONING RESULTS Figure 8 shows a bar chart of the BLEU score of our model and the baselines, in the code captioning task (predicting natural language descriptions for C# code snippets). The numbers are the same as in Table 2. D CODE SUMMARIZATION RESULTS Figure 9 shows a bar chart of the F1 score of our model and the baselines, in the code summarization task (predicting method names in Java). The numbers are the F1 columns from Table 1. E ABLATION STUDY RESULTS Figure 10 shows a bar chart of the relative decrease in precision and recall for each of the ablations described in Section 5 and presented in Table 3.\n\nSensitivity to k we experimented with different values of k, the number of sampled paths from each example (which we set to 200 in the final model). Lower values than k = 100 showed worse results. Decreasing to k = 100 showed a minor degradation, and increasing to k = 300 did not seem to consistently improve.   \n\nFigure 3 :\n3Our model encodes each AST path as a vector, and uses their average as the decoder's start state. The decoder generates an output sequence while attending over the encoded paths.\n\nFigure 4 :Figure 8 :\n48child node to a treeview in c # Example of code captioning for a C# code snippet from our test set. The text boxes at the bottom of each figure are the predictions produced by our model at each decoding step. The highlighted paths in each figure are the top-attended paths in each decoding step, and their widths are proportional to their attention weight (because of space limitations we included only the topattended path for each decoding step, but hundreds of paths are attended at each step)\u2020(Koehn et al., 2007) IR \u2020 SUM-NN \u2020(Rush et al., 2015) 2-layer BiLSTM (split tokens) Transformer (split tokens) CodeNN \u2020(Iyer et al., 2016) code2seq (this work) Visualization of the BLEU score of our model compared to the baselines, for the code captioning task. The values are the the same as in\n\nFigure 10 :\n10The relative decrease in precision and recall in each of the ablations, compared to the full model.\n\nTable 1 :\n1Our model significantly outperforms previous PL-oriented and NMT models. Another visualization can be found in Appendix D.Model \nJava-small \nJava-med \nJava-large \n\nPrec \nRec \nF1 \nPrec \nRec \nF1 \nPrec \nRec \nF1 \n\nConvAttention (Allamanis et al., 2016) \n50.25 \n24.62 \n33.05 \n60.82 \n26.75 \n37.16 \n60.71 \n27.60 \n37.95 \nPaths+CRFs (Alon et al., 2018b) \n8.39 \n5.63 \n6.74 \n32.56 \n20.37 \n25.06 \n32.56 \n20.37 \n25.06 \ncode2vec (Alon et al., 2018a) \n18.51 \n18.74 \n18.62 \n38.12 \n28.31 \n32.49 \n48.15 \n38.40 \n42.73 \n2-layer BiLSTM (no token splitting) \n32.40 \n20.40 \n25.03 \n48.37 \n30.29 \n37.25 \n58.02 \n37.73 \n45.73 \n2-layer BiLSTM \n42.63 \n29.97 \n35.20 \n55.15 \n41.75 \n47.52 \n63.53 \n48.77 \n55.18 \nTransformer (Vaswani et al., 2017) \n38.13 \n26.70 \n31.41 \n50.11 \n35.01 \n41.22 \n59.13 \n40.58 \n48.13 \n\ncode2seq \n50.64 \n37.40 \n43.02 \n61.24 \n47.07 \n53.23 \n64.03 \n55.02 \n59.19 \nAbsolute Gain over BiLSTM \n+8.01 \n+7.43 \n+7.82 \n+6.09 \n+5.32 \n+5.71 \n+0.50 \n+6.25 \n+4.01 \n\nimprove the results by about 10 F1 points (Table 1), (2) we deliberately kept the original casing of \nthe source tokens since we found it to improve their results, and (3) during inference, we replaced \ngenerated UNK tokens with the source tokens that were given the highest attention. For the 2-layer \nBiLSTM we used embeddings of size 512, each of the encoder and decoder had 512 cells, and \nthe default hyperparameters of OpenNMT (Klein et al., 2017). For the Transformer, we used their \noriginal hyperparameters (Vaswani et al., 2017). This resulted in a Transformer model with 169M \nparameters, a BiLSTM model with 134M parameters, while our code2seq model had only 37M. 2 \n\n\n\nTable 2 :\n2Our model outperforms previous work in the code captioning task. \u2020 Results previously reported by\n\nTable 2\n2summarizes the results for the code captioning task. Our model achieves a BLEU \nscore of 23.04, which improves by 2.51 points (12.2% relative) over CodeNN, who introduced this \ndataset, and over all the other baselines including BiLSTMs and the Transformer, which achieved \nslightly lower results than CodeNN. Examples for predictions made by our model and each of the \nbaselines can be found in Appendix E. These results show that when the training examples are \nshort and incomplete code snippets, our model generalizes better to unseen examples than a shallow \ntextual token-level approach, thanks to its syntactic observation of the data. \n\n\n\nTable 3 :\n3Variations on the code2seq model, performed on the dev set of Java-med.Model \nPrecision Recall F1 \n\u2206F1 \n\ncode2seq (original model) \n60.93 \n45.77 \n52.27 \n\nNo AST nodes (only tokens) \n55.51 \n43.11 \n48.53 \n-3.74 \nNo decoder \n47.99 \n28.96 \n36.12 -16.15 \nNo token splitting \n48.53 \n34.80 \n40.53 -11.74 \nNo tokens (only AST nodes) \n33.78 \n21.23 \n26.07 -26.20 \nNo attention \n57.00 \n41.89 \n48.29 \n-3.98 \nNo random (sample k paths in advance) 59.08 \n44.07 \n50.49 \n-1.78 \n\n\n\nTable 2 .\n2Our model achieves significantly higher results than the baselines.Figure 9: Visualization of the F1 score of our model compared to the baselines, for the code summarization task, across datasets. The values are the F1 columns from Table 1. Our model achieves significantly higher results than the baselines.Java-small \nJava-med \nJava-large \n\n10 \n\n20 \n\n30 \n\n40 \n\n50 \n\n60 \n\n33.05 \n\n37.16 \n37.95 \n\n6.74 \n\n25.06 \n25.06 \n\n18.62 \n\n32.49 \n\n42.73 \n\n25.03 \n\n37.25 \n\n45.73 \n\n35.2 \n\n47.52 \n\n55.18 \n\n31.41 \n\n41.22 \n\n48.13 \n\n43.02 \n\n53.23 \n\n59.19 \n\nF1 \nscore \n\nConvAttention \nPaths+CRFs \ncode2vec \n2-layer BiLSTM (full tokens) \n2-layer BiLSTM (split tokens) \nTransformer (split tokens) \ncode2seq (this work) \n\n\nWhile the code ofLiang and Zhu (2018) is technically available, it lacks running instructions. We also tried running our model on their benchmarks, but could not obtain the same preprocessed and train/test partitioned data. The authors could not provide instructions or data by the time of this submission.\nWe also trained versions of the NMT baselines in which we down-matched the sizes and number of parameters to our model. These baselines seemed to benefit from more parameters, so the results reported here are for the versions that had many more parameters than our model.\nModel PredictionMOSES \u2020(Koehn et al., 2007)How can TreeView TreeView a TreeView nodes from XML parentText string to a treeview node from a TreeView parentText of a tree treeNodeDivisions from to child childText XML node of MDI child childText created in a tree nodes in IR \u2020 How to set the name of a tabPage progragmatically SUM-NN \u2020(Rush et al., 2015)how to get data from xml file in c# 2-layer BiLSTM (split tokens) how to add child nodes to treeview Transformer (split tokens) how to add child node in treeview in c # CodeNN \u2020(Iyer et al., 2016)How to get all child nodes in TreeView ? code2seq (this work) add a child node to a treeview in c # var excel = new ExcelQueryFactory(\"excelFileName\"); var firstRow = excel.Worksheet().First(); var companyName = firstRow[\"CompanyName\"];Model PredictionMOSES \u2020(Koehn et al., 2007)How into string based on an firstRow a companyName firstRow ? How to IR \u2020 Facebook C# SDK Get Current User SUM-NN \u2020(Rush et al., 2015)how can i get the value of a string? 2-layer BiLSTM (split tokens) how to get the value of a cell in excel using c # Transformer (split tokens) getting the first row in excel CodeNN \u2020(Iyer et al., 2016)how do I get the value of an xml file in c # ? code2seq (this work) get the value of a column in excel using c #(Iyer et al., 2016)How to get the value of an array in C # ? code2seq (this work) get the image from a pdf file in c # void Main() { string text = File.ReadAllText(@\"T:\\File1.txt\"); int num = 0; text = (Regex.Replace(text, \"map\", delegate(Match m) { return \"map\" + num++; })); File.WriteAllText(@\"T:\\File1.txt\", text); }Model PredictionMOSES \u2020(Koehn et al., 2007)How to File then How to HTML ? C # How to Write to IR \u2020 C# remove extra carriage returns from Stream SUM-NN \u2020(Rush et al., 2015)how do i create a text file in c# 2-layer BiLSTM (split tokens) how to read a text file from a text file Transformer (split tokens) how to write a . txt file in c # CodeNN \u2020(Iyer et al., 2016)how to read a text file in c # ? code2seq (this work) replace a string in a text fileModelPrediction ConvAttention(Allamanis et al., 2016)add Paths+CRFs(Alon et al., 2018b)call code2vec(Alon et al., 2018a)log response 2-layer BiLSTM (full tokens) handle request 2-layer BiLSTM (split tokens) report child request Transformer (split tokens) add child Gold: add child request code2seq (this work) add child request public static int ______(int value) { return value <= 0 ? 1 : value >= 0x40000000 ? 0x40000000 : 1 << (32 -Integer.numberOfLeadingZeros(value -1)); }ModelPrediction ConvAttention(Allamanis et al., 2016)get Paths+CRFs(Alon et al., 2018b)test bit inolz code2vec(Alon et al., 2018a)multiply 2-layer BiLSTM (full tokens) next power of two 2-layer BiLSTM (split tokens) { (replaced UNK) Transformer (split tokens) get bit length Gold: find next positive power of two code2seq (this work) get power of twoModelPrediction ConvAttention(Allamanis et al., 2016)is Paths+CRFs(Alon et al., 2018b)equals code2vec(Alon et al., 2018a)contains ignore case 2-layer BiLSTM (full tokens) contains ignore case 2-layer BiLSTM (split tokens) contains Transformer (split tokens) contains Gold:contains ignore case code2seq (this work) contains ignore caseFigure 7: Java examples from our test set for the code summarization task, along with the prediction of our model and each of the baselines.\nSuggesting accurate method and class names. Miltiadis Allamanis, Earl T Barr, Christian Bird, Charles Sutton, http:/doi.acm.org/10.1145/2786805.2786849Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015. the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015New York, NY, USAACMMiltiadis Allamanis, Earl T. Barr, Christian Bird, and Charles Sutton. Suggesting accurate method and class names. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, pages 38-49, New York, NY, USA, 2015a. ACM. ISBN 978- 1-4503-3675-8. doi:10.1145/2786805.2786849. URL http://doi.acm.org/10.1145/ 2786805.2786849.\n\nBimodal Modelling of Source Code and Natural Language. Miltiadis Allamanis, Daniel Tarlow, Andrew D Gordon, Yi Wei, Proceedings of the 32nd International Conference on Machine Learning. the 32nd International Conference on Machine Learning37JMLR.orgMiltiadis Allamanis, Daniel Tarlow, Andrew D. Gordon, and Yi Wei. Bimodal Modelling of Source Code and Natural Language. In Proceedings of the 32nd International Conference on Machine Learning, volume 37 of JMLR Proceedings, pages 2123-2132. JMLR.org, 2015b.\n\nA convolutional attention network for extreme summarization of source code. Miltiadis Allamanis, Hao Peng, Charles A Sutton, Proceedings of the 33nd International Conference on Machine Learning. the 33nd International Conference on Machine LearningNew York City, NY, USAMiltiadis Allamanis, Hao Peng, and Charles A. Sutton. A convolutional attention network for ex- treme summarization of source code. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pages 2091-2100, 2016. URL http://jmlr.org/proceedings/papers/v48/allamanis16.html.\n\nLearning to represent programs with graphs. Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi, ICLR. Miltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs with graphs. In ICLR, 2018.\n\nUri Alon, Meital Zilberstein, Omer Levy, Eran Yahav, arXiv:1803.09473code2vec: Learning distributed representations of code. arXiv preprintUri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. code2vec: Learning distributed repre- sentations of code. arXiv preprint arXiv:1803.09473, 2018a.\n\nA general path-based representation for predicting program properties. Uri Alon, Meital Zilberstein, Omer Levy, Eran Yahav, http:/doi.acm.org/10.1145/3192366.3192412Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018. the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018New York, NY, USAACMUri Alon, Meital Zilberstein, Omer Levy, and Eran Yahav. A general path-based representation for predicting program properties. In Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2018, pages 404-419, New York, NY, USA, 2018b. ACM. ISBN 978-1-4503-5698-5. doi:10.1145/3192366.3192412. URL http: //doi.acm.org/10.1145/3192366.3192412.\n\nNeural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. CoRR, abs/1409.0473, 2014. URL http://arxiv.org/ abs/1409.0473.\n\nMatej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, Daniel Tarlow, Deepcoder, arXiv:1611.01989Learning to write programs. arXiv preprintMatej Balog, Alexander L Gaunt, Marc Brockschmidt, Sebastian Nowozin, and Daniel Tarlow. Deepcoder: Learning to write programs. arXiv preprint arXiv:1611.01989, 2016.\n\nPHOG: probabilistic model for code. Pavol Bielik, Veselin Raychev, Martin T Vechev, Proceedings of the 33nd International Conference on Machine Learning. the 33nd International Conference on Machine LearningNew York City, NY, USAPavol Bielik, Veselin Raychev, and Martin T. Vechev. PHOG: probabilistic model for code. In Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pages 2933-2942, 2016. URL http://jmlr.org/ proceedings/papers/v48/bielik16.html.\n\nProgram synthesis for character level language modeling. Pavol Bielik, Veselin Raychev, Martin Vechev, ICLR. Pavol Bielik, Veselin Raychev, and Martin Vechev. Program synthesis for character level language modeling. In ICLR, 2017.\n\nLearning phrase representations using rnn encoder-decoder for statistical machine translation. Kyunghyun Cho, Bart Van Merri\u00ebnboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio, arXiv:1406.1078arXiv preprintKyunghyun Cho, Bart Van Merri\u00ebnboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Hol- ger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.\n\nRobustfill: Neural program learning under noisy i/o. Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-Rahman Mohamed, Pushmeet Kohli, International Conference on Machine Learning. Jacob Devlin, Jonathan Uesato, Surya Bhupatiraju, Rishabh Singh, Abdel-rahman Mohamed, and Pushmeet Kohli. Robustfill: Neural program learning under noisy i/o. In International Conference on Machine Learning, pages 990-998, 2017.\n\nUnderstanding the difficulty of training deep feedforward neural networks. Xavier Glorot, Yoshua Bengio, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. the Thirteenth International Conference on Artificial Intelligence and StatisticsXavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, pages 249-256, 2010.\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, 10.1162/neco.1997.9.8.1735Neural Comput. 98Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural Comput., 9(8):1735- 1780, November 1997. ISSN 0899-7667. doi:10.1162/neco.1997.9.8.1735. URL http://dx. doi.org/10.1162/neco.1997.9.8.1735.\n\nSummarizing source code using a neural attention model. Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Luke Zettlemoyer, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016. the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016Berlin, GermanyLong Papers1Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. Summarizing source code using a neural attention model. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Volume 1: Long Papers, 2016. URL http://aclweb.org/anthology/P/P16/P16-1195.pdf.\n\nOpenNMT: Open-Source Toolkit for Neural Machine Translation. G Klein, Y Kim, Y Deng, J Senellart, A M Rush, G. Klein, Y. Kim, Y. Deng, J. Senellart, and A. M. Rush. OpenNMT: Open-Source Toolkit for Neural Machine Translation. ArXiv e-prints, 2017.\n\nMoses: Open source toolkit for statistical machine translation. Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond\u0159ej Bojar, Alexandra Constantin, Evan Herbst, Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL '07. the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL '07Stroudsburg, PA, USAAssociation for Computational LinguisticsPhilipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond\u0159ej Bojar, Alexandra Constantin, and Evan Herbst. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL '07, pages 177-180, Stroudsburg, PA, USA, 2007. Association for Computational Linguistics. URL http://dl.acm.org/citation.cfm?id=1557769.\n\nAutomatic generation of text descriptive comments for code blocks. Yuding Liang, Kenny Qili Zhu, Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence. the Thirty-Second AAAI Conference on Artificial IntelligenceNew Orleans, Louisiana, USAYuding Liang and Kenny Qili Zhu. Automatic generation of text descriptive comments for code blocks. In Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018, 2018. URL https://www.aaai.org/ocs/ index.php/AAAI/AAAI18/paper/view/16492.\n\nA neural architecture for generating natural language descriptions from source code changes. Pablo Loyola, Edison Marrese-Taylor, Yutaka Matsuo, 10.18653/v1/P17-2045Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2Short Papers)Pablo Loyola, Edison Marrese-Taylor, and Yutaka Matsuo. A neural architecture for generating natural language descriptions from source code changes. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 287- 292. Association for Computational Linguistics, 2017. doi:10.18653/v1/P17-2045. URL http: //www.aclweb.org/anthology/P17-2045.\n\nEffective approaches to attention-based neural machine translation. Thang Luong, Hieu Pham, Christopher D Manning, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalThang Luong, Hieu Pham, and Christopher D. Manning. Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 1412-1421, 2015. URL http://aclweb.org/anthology/D/D15/D15-1166.pdf.\n\nBayesian sketch learning for program synthesis. CoRR, abs/1703.05698. Vijayaraghavan Murali, Swarat Chaudhuri, Chris Jermaine, Vijayaraghavan Murali, Swarat Chaudhuri, and Chris Jermaine. Bayesian sketch learning for pro- gram synthesis. CoRR, abs/1703.05698, 2017. URL http://arxiv.org/abs/1703.\n\nA method for solving the convex programming problem with convergence rate o (1/k\u02c62). E Yurii, Nesterov, In Dokl. Akad. Nauk SSSR. 269Yurii E Nesterov. A method for solving the convex programming problem with convergence rate o (1/k\u02c62). In Dokl. Akad. Nauk SSSR, volume 269, pages 543-547, 1983.\n\nAbstract syntax networks for code generation and semantic parsing. Maxim Rabinovich, Mitchell Stern, Dan Klein, 10.18653/v1/P17-1105Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational Linguistics1Association for Computational LinguisticsMaxim Rabinovich, Mitchell Stern, and Dan Klein. Abstract syntax networks for code genera- tion and semantic parsing. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1139-1149. Association for Com- putational Linguistics, 2017. doi:10.18653/v1/P17-1105. URL http://www.aclweb.org/ anthology/P17-1105.\n\nCode completion with statistical language models. Veselin Raychev, Martin Vechev, Eran Yahav, http:/doi.acm.org/10.1145/2666356.2594321SIGPLAN Not. 496Veselin Raychev, Martin Vechev, and Eran Yahav. Code completion with statistical language models. SIGPLAN Not., 49(6):419-428, June 2014. ISSN 0362-1340. doi:10.1145/2666356.2594321. URL http://doi.acm.org/10.1145/2666356.2594321.\n\nPredicting program properties from \"big code. Veselin Raychev, Martin Vechev, Andreas Krause, http:/doi.acm.org/10.1145/2676726.2677009Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL '15. the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL '15New York, NY, USAACMVeselin Raychev, Martin Vechev, and Andreas Krause. Predicting program properties from \"big code\". In Proceedings of the 42Nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL '15, pages 111-124, New York, NY, USA, 2015. ACM. ISBN 978-1-4503-3300-9. doi:10.1145/2676726.2677009. URL http://doi.acm.org/ 10.1145/2676726.2677009.\n\nProbabilistic model for code with decision trees. Veselin Raychev, Pavol Bielik, Martin Vechev, http:/doi.acm.org/10.1145/2983990.2984041Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2016. the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2016New York, NY, USAACMVeselin Raychev, Pavol Bielik, and Martin Vechev. Probabilistic model for code with decision trees. In Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications, OOPSLA 2016, pages 731-747, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4444-9. doi:10.1145/2983990.2984041. URL http://doi.acm.org/10.1145/2983990.2984041.\n\nThe cross-entropy method for combinatorial and continuous optimization. Reuven Rubinstein, Methodology and computing in applied probability. 12Reuven Rubinstein. The cross-entropy method for combinatorial and continuous optimization. Methodology and computing in applied probability, 1(2):127-190, 1999.\n\nCombinatorial optimization, cross-entropy, ants and rare events. Y Reuven, Rubinstein, 54Stochastic optimization: algorithms and applicationsReuven Y Rubinstein. Combinatorial optimization, cross-entropy, ants and rare events. Stochastic optimization: algorithms and applications, 54:303-363, 2001.\n\nA neural attention model for abstractive sentence summarization. Alexander M Rush, Sumit Chopra, Jason Weston, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAlexander M. Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive sentence summarization. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 379-389, 2015. URL http://aclweb.org/anthology/D/D15/D15-1044.pdf.\n\nNeural machine translation of rare words with subword units. Rico Sennrich, Barry Haddow, Alexandra Birch, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, Germany1Association for Computational LinguisticsRico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715-1725, Berlin, Germany, August 2016. As- sociation for Computational Linguistics. URL http://www.aclweb.org/anthology/ P16-1162.\n\nDropout: a simple way to prevent neural networks from overfitting. Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov, Journal of machine learning research. 151Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of machine learning research, 15(1):1929-1958, 2014.\n\nSequence to sequence learning with neural networks. Ilya Sutskever, Oriol Vinyals, Quoc V Le, Advances in neural information processing systems. Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104-3112, 2014.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Infor- mation Processing Systems, pages 6000-6010, 2017.\n\nA syntactic neural model for general-purpose code generation. Pengcheng Yin, Graham Neubig, 10.18653/v1/P17-1041Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics1Long Papers)Pengcheng Yin and Graham Neubig. A syntactic neural model for general-purpose code genera- tion. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguis- tics (Volume 1: Long Papers), pages 440-450. Association for Computational Linguistics, 2017. doi:10.18653/v1/P17-1041. URL http://www.aclweb.org/anthology/P17-1041.\n", "annotations": {"author": "[{\"end\":150,\"start\":74},{\"end\":221,\"start\":151},{\"end\":299,\"start\":222}]", "publisher": null, "author_last_name": "[{\"end\":82,\"start\":78},{\"end\":160,\"start\":156},{\"end\":232,\"start\":227}]", "author_first_name": "[{\"end\":77,\"start\":74},{\"end\":155,\"start\":151},{\"end\":226,\"start\":222}]", "author_affiliation": "[{\"end\":149,\"start\":110},{\"end\":220,\"start\":181},{\"end\":298,\"start\":259}]", "title": "[{\"end\":71,\"start\":1},{\"end\":370,\"start\":300}]", "venue": null, "abstract": "[{\"end\":1319,\"start\":372}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1467,\"start\":1443},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":1502,\"start\":1483},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1539,\"start\":1514},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1581,\"start\":1561},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1605,\"start\":1581},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":1626,\"start\":1605},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1646,\"start\":1626},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":1666,\"start\":1646},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2163,\"start\":2144},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2184,\"start\":2163},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2298,\"start\":2279},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2321,\"start\":2298},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2341,\"start\":2321},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2744,\"start\":2710},{\"end\":3036,\"start\":3025},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3346,\"start\":3323},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3377,\"start\":3358},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3438,\"start\":3418},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3459,\"start\":3438},{\"end\":3537,\"start\":3533},{\"end\":3609,\"start\":3606},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8027,\"start\":8008},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9107,\"start\":9087},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10175,\"start\":10151},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10380,\"start\":10357},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12547,\"start\":12523},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12602,\"start\":12584},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12607,\"start\":12602},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12648,\"start\":12633},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12779,\"start\":12754},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13227,\"start\":13203},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13246,\"start\":13227},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13671,\"start\":13648},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13695,\"start\":13676},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14039,\"start\":14015},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14953,\"start\":14930},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15096,\"start\":15076},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15131,\"start\":15111},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15355,\"start\":15335},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":15399,\"start\":15377},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15529,\"start\":15506},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15700,\"start\":15680},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16543,\"start\":16519},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16639,\"start\":16619},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16823,\"start\":16799},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17812,\"start\":17793},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18538,\"start\":18520},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18830,\"start\":18812},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18851,\"start\":18833},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18963,\"start\":18943},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":19009,\"start\":18990},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":19071,\"start\":19049},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19106,\"start\":19087},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":21251,\"start\":21231},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21859,\"start\":21840},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":21882,\"start\":21859},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":21902,\"start\":21882},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21936,\"start\":21915},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21974,\"start\":21952},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22423,\"start\":22403},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22446,\"start\":22423},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":22511,\"start\":22491},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22767,\"start\":22748},{\"end\":22769,\"start\":22767},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23278,\"start\":23258},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":23333,\"start\":23310},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23969,\"start\":23949},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":27691,\"start\":27671},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":27724,\"start\":27705},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":27809,\"start\":27790},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":31708,\"start\":31688}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":27149,\"start\":26958},{\"attributes\":{\"id\":\"fig_1\"},\"end\":27966,\"start\":27150},{\"attributes\":{\"id\":\"fig_2\"},\"end\":28081,\"start\":27967},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":29717,\"start\":28082},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":29827,\"start\":29718},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":30483,\"start\":29828},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":30959,\"start\":30484},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":31670,\"start\":30960}]", "paragraph": "[{\"end\":1792,\"start\":1335},{\"end\":2389,\"start\":1794},{\"end\":2938,\"start\":2391},{\"end\":3552,\"start\":2940},{\"end\":3581,\"start\":3554},{\"end\":4071,\"start\":3583},{\"end\":4463,\"start\":4073},{\"end\":5197,\"start\":4498},{\"end\":6335,\"start\":5199},{\"end\":6700,\"start\":6337},{\"end\":7032,\"start\":6702},{\"end\":7422,\"start\":7085},{\"end\":7901,\"start\":7445},{\"end\":8356,\"start\":7931},{\"end\":8500,\"start\":8358},{\"end\":8577,\"start\":8502},{\"end\":8779,\"start\":8579},{\"end\":9235,\"start\":8830},{\"end\":9433,\"start\":9326},{\"end\":9645,\"start\":9464},{\"end\":9922,\"start\":9647},{\"end\":10674,\"start\":10030},{\"end\":10882,\"start\":10721},{\"end\":11091,\"start\":10910},{\"end\":11318,\"start\":11193},{\"end\":11443,\"start\":11320},{\"end\":11765,\"start\":11467},{\"end\":11965,\"start\":11767},{\"end\":12425,\"start\":11981},{\"end\":13091,\"start\":12427},{\"end\":13785,\"start\":13114},{\"end\":13842,\"start\":13787},{\"end\":14233,\"start\":13844},{\"end\":14470,\"start\":14235},{\"end\":14748,\"start\":14472},{\"end\":15462,\"start\":14750},{\"end\":15731,\"start\":15464},{\"end\":16767,\"start\":15733},{\"end\":17642,\"start\":16769},{\"end\":18539,\"start\":17662},{\"end\":18922,\"start\":18541},{\"end\":19127,\"start\":18924},{\"end\":19137,\"start\":19129},{\"end\":19499,\"start\":19156},{\"end\":19767,\"start\":19501},{\"end\":19844,\"start\":19769},{\"end\":19940,\"start\":19851},{\"end\":20039,\"start\":19947},{\"end\":21634,\"start\":20046},{\"end\":22225,\"start\":21651},{\"end\":23697,\"start\":22227},{\"end\":24230,\"start\":23699},{\"end\":24567,\"start\":24245},{\"end\":24922,\"start\":24569},{\"end\":25214,\"start\":24924},{\"end\":25990,\"start\":25220},{\"end\":26642,\"start\":26015},{\"end\":26957,\"start\":26644}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7084,\"start\":7033},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8829,\"start\":8780},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9311,\"start\":9236},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9463,\"start\":9434},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10029,\"start\":9923},{\"attributes\":{\"id\":\"formula_6\"},\"end\":10720,\"start\":10675},{\"attributes\":{\"id\":\"formula_7\"},\"end\":11192,\"start\":11092},{\"attributes\":{\"id\":\"formula_8\"},\"end\":11466,\"start\":11444}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":15945,\"start\":15938},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":20217,\"start\":20210},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26250,\"start\":26242},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26465,\"start\":26457},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26641,\"start\":26634}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1333,\"start\":1321},{\"attributes\":{\"n\":\"2\"},\"end\":4496,\"start\":4466},{\"attributes\":{\"n\":\"3\"},\"end\":7443,\"start\":7425},{\"attributes\":{\"n\":\"3.1\"},\"end\":7929,\"start\":7904},{\"attributes\":{\"n\":\"3.2\"},\"end\":9324,\"start\":9313},{\"end\":10908,\"start\":10885},{\"attributes\":{\"n\":\"4\"},\"end\":11979,\"start\":11968},{\"attributes\":{\"n\":\"4.1\"},\"end\":13112,\"start\":13094},{\"attributes\":{\"n\":\"4.2\"},\"end\":17660,\"start\":17645},{\"attributes\":{\"n\":\"5\"},\"end\":19154,\"start\":19140},{\"end\":19849,\"start\":19847},{\"end\":19945,\"start\":19943},{\"end\":20044,\"start\":20042},{\"attributes\":{\"n\":\"6\"},\"end\":21649,\"start\":21637},{\"attributes\":{\"n\":\"7\"},\"end\":24243,\"start\":24233},{\"end\":25218,\"start\":25217},{\"end\":26013,\"start\":25993},{\"end\":26969,\"start\":26959},{\"end\":27171,\"start\":27151},{\"end\":27979,\"start\":27968},{\"end\":28092,\"start\":28083},{\"end\":29728,\"start\":29719},{\"end\":29836,\"start\":29829},{\"end\":30494,\"start\":30485},{\"end\":30970,\"start\":30961}]", "table": "[{\"end\":29717,\"start\":28216},{\"end\":30483,\"start\":29838},{\"end\":30959,\"start\":30567},{\"end\":31670,\"start\":31280}]", "figure_caption": "[{\"end\":27149,\"start\":26971},{\"end\":27966,\"start\":27174},{\"end\":28081,\"start\":27982},{\"end\":28216,\"start\":28094},{\"end\":29827,\"start\":29730},{\"end\":30567,\"start\":30496},{\"end\":31280,\"start\":30972}]", "figure_ref": "[{\"end\":3127,\"start\":3116},{\"end\":3622,\"start\":3614},{\"end\":4937,\"start\":4928},{\"end\":4991,\"start\":4982},{\"end\":5494,\"start\":5486},{\"end\":7137,\"start\":7129},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7900,\"start\":7892},{\"end\":25255,\"start\":25247},{\"end\":25402,\"start\":25394},{\"end\":25754,\"start\":25746},{\"end\":26049,\"start\":26041},{\"end\":26288,\"start\":26280},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":26500,\"start\":26491}]", "bib_author_first_name": "[{\"end\":35648,\"start\":35639},{\"end\":35664,\"start\":35660},{\"end\":35666,\"start\":35665},{\"end\":35682,\"start\":35673},{\"end\":35696,\"start\":35689},{\"end\":36373,\"start\":36364},{\"end\":36391,\"start\":36385},{\"end\":36406,\"start\":36400},{\"end\":36408,\"start\":36407},{\"end\":36419,\"start\":36417},{\"end\":36903,\"start\":36894},{\"end\":36918,\"start\":36915},{\"end\":36932,\"start\":36925},{\"end\":36934,\"start\":36933},{\"end\":37484,\"start\":37475},{\"end\":37500,\"start\":37496},{\"end\":37522,\"start\":37515},{\"end\":37662,\"start\":37659},{\"end\":37675,\"start\":37669},{\"end\":37693,\"start\":37689},{\"end\":37704,\"start\":37700},{\"end\":38028,\"start\":38025},{\"end\":38041,\"start\":38035},{\"end\":38059,\"start\":38055},{\"end\":38070,\"start\":38066},{\"end\":38828,\"start\":38821},{\"end\":38848,\"start\":38839},{\"end\":38860,\"start\":38854},{\"end\":39062,\"start\":39057},{\"end\":39079,\"start\":39070},{\"end\":39081,\"start\":39080},{\"end\":39093,\"start\":39089},{\"end\":39117,\"start\":39108},{\"end\":39133,\"start\":39127},{\"end\":39420,\"start\":39415},{\"end\":39436,\"start\":39429},{\"end\":39452,\"start\":39446},{\"end\":39454,\"start\":39453},{\"end\":39968,\"start\":39963},{\"end\":39984,\"start\":39977},{\"end\":40000,\"start\":39994},{\"end\":40242,\"start\":40233},{\"end\":40252,\"start\":40248},{\"end\":40276,\"start\":40270},{\"end\":40294,\"start\":40287},{\"end\":40310,\"start\":40305},{\"end\":40327,\"start\":40321},{\"end\":40343,\"start\":40337},{\"end\":40698,\"start\":40693},{\"end\":40715,\"start\":40707},{\"end\":40729,\"start\":40724},{\"end\":40750,\"start\":40743},{\"end\":40770,\"start\":40758},{\"end\":40788,\"start\":40780},{\"end\":41154,\"start\":41148},{\"end\":41169,\"start\":41163},{\"end\":41616,\"start\":41612},{\"end\":41635,\"start\":41629},{\"end\":41970,\"start\":41960},{\"end\":41984,\"start\":41977},{\"end\":41999,\"start\":41994},{\"end\":42012,\"start\":42008},{\"end\":42642,\"start\":42641},{\"end\":42651,\"start\":42650},{\"end\":42658,\"start\":42657},{\"end\":42666,\"start\":42665},{\"end\":42679,\"start\":42678},{\"end\":42681,\"start\":42680},{\"end\":42900,\"start\":42893},{\"end\":42912,\"start\":42908},{\"end\":42929,\"start\":42920},{\"end\":42942,\"start\":42937},{\"end\":42967,\"start\":42959},{\"end\":42984,\"start\":42978},{\"end\":43001,\"start\":42995},{\"end\":43013,\"start\":43009},{\"end\":43029,\"start\":43020},{\"end\":43044,\"start\":43037},{\"end\":43056,\"start\":43051},{\"end\":43069,\"start\":43063},{\"end\":43086,\"start\":43077},{\"end\":43103,\"start\":43099},{\"end\":43980,\"start\":43974},{\"end\":43998,\"start\":43988},{\"end\":44572,\"start\":44567},{\"end\":44587,\"start\":44581},{\"end\":44610,\"start\":44604},{\"end\":45333,\"start\":45328},{\"end\":45345,\"start\":45341},{\"end\":45363,\"start\":45352},{\"end\":45365,\"start\":45364},{\"end\":45974,\"start\":45960},{\"end\":45989,\"start\":45983},{\"end\":46006,\"start\":46001},{\"end\":46274,\"start\":46273},{\"end\":46556,\"start\":46551},{\"end\":46577,\"start\":46569},{\"end\":46588,\"start\":46585},{\"end\":47252,\"start\":47245},{\"end\":47268,\"start\":47262},{\"end\":47281,\"start\":47277},{\"end\":47631,\"start\":47624},{\"end\":47647,\"start\":47641},{\"end\":47663,\"start\":47656},{\"end\":48353,\"start\":48346},{\"end\":48368,\"start\":48363},{\"end\":48383,\"start\":48377},{\"end\":49196,\"start\":49190},{\"end\":49489,\"start\":49488},{\"end\":49797,\"start\":49788},{\"end\":49799,\"start\":49798},{\"end\":49811,\"start\":49806},{\"end\":49825,\"start\":49820},{\"end\":50408,\"start\":50404},{\"end\":50424,\"start\":50419},{\"end\":50442,\"start\":50433},{\"end\":51108,\"start\":51102},{\"end\":51129,\"start\":51121},{\"end\":51131,\"start\":51130},{\"end\":51144,\"start\":51140},{\"end\":51161,\"start\":51157},{\"end\":51179,\"start\":51173},{\"end\":51518,\"start\":51514},{\"end\":51535,\"start\":51530},{\"end\":51551,\"start\":51545},{\"end\":51816,\"start\":51810},{\"end\":51830,\"start\":51826},{\"end\":51844,\"start\":51840},{\"end\":51858,\"start\":51853},{\"end\":51875,\"start\":51870},{\"end\":51888,\"start\":51883},{\"end\":51890,\"start\":51889},{\"end\":51904,\"start\":51898},{\"end\":51918,\"start\":51913},{\"end\":52285,\"start\":52276},{\"end\":52297,\"start\":52291}]", "bib_author_last_name": "[{\"end\":35658,\"start\":35649},{\"end\":35671,\"start\":35667},{\"end\":35687,\"start\":35683},{\"end\":35703,\"start\":35697},{\"end\":36383,\"start\":36374},{\"end\":36398,\"start\":36392},{\"end\":36415,\"start\":36409},{\"end\":36423,\"start\":36420},{\"end\":36913,\"start\":36904},{\"end\":36923,\"start\":36919},{\"end\":36941,\"start\":36935},{\"end\":37494,\"start\":37485},{\"end\":37513,\"start\":37501},{\"end\":37530,\"start\":37523},{\"end\":37667,\"start\":37663},{\"end\":37687,\"start\":37676},{\"end\":37698,\"start\":37694},{\"end\":37710,\"start\":37705},{\"end\":38033,\"start\":38029},{\"end\":38053,\"start\":38042},{\"end\":38064,\"start\":38060},{\"end\":38076,\"start\":38071},{\"end\":38837,\"start\":38829},{\"end\":38852,\"start\":38849},{\"end\":38867,\"start\":38861},{\"end\":39068,\"start\":39063},{\"end\":39087,\"start\":39082},{\"end\":39106,\"start\":39094},{\"end\":39125,\"start\":39118},{\"end\":39140,\"start\":39134},{\"end\":39151,\"start\":39142},{\"end\":39427,\"start\":39421},{\"end\":39444,\"start\":39437},{\"end\":39461,\"start\":39455},{\"end\":39975,\"start\":39969},{\"end\":39992,\"start\":39985},{\"end\":40007,\"start\":40001},{\"end\":40246,\"start\":40243},{\"end\":40268,\"start\":40253},{\"end\":40285,\"start\":40277},{\"end\":40303,\"start\":40295},{\"end\":40319,\"start\":40311},{\"end\":40335,\"start\":40328},{\"end\":40350,\"start\":40344},{\"end\":40705,\"start\":40699},{\"end\":40722,\"start\":40716},{\"end\":40741,\"start\":40730},{\"end\":40756,\"start\":40751},{\"end\":40778,\"start\":40771},{\"end\":40794,\"start\":40789},{\"end\":41161,\"start\":41155},{\"end\":41176,\"start\":41170},{\"end\":41627,\"start\":41617},{\"end\":41647,\"start\":41636},{\"end\":41975,\"start\":41971},{\"end\":41992,\"start\":41985},{\"end\":42006,\"start\":42000},{\"end\":42024,\"start\":42013},{\"end\":42648,\"start\":42643},{\"end\":42655,\"start\":42652},{\"end\":42663,\"start\":42659},{\"end\":42676,\"start\":42667},{\"end\":42686,\"start\":42682},{\"end\":42906,\"start\":42901},{\"end\":42918,\"start\":42913},{\"end\":42935,\"start\":42930},{\"end\":42957,\"start\":42943},{\"end\":42976,\"start\":42968},{\"end\":42993,\"start\":42985},{\"end\":43007,\"start\":43002},{\"end\":43018,\"start\":43014},{\"end\":43035,\"start\":43030},{\"end\":43049,\"start\":43045},{\"end\":43061,\"start\":43057},{\"end\":43075,\"start\":43070},{\"end\":43097,\"start\":43087},{\"end\":43110,\"start\":43104},{\"end\":43986,\"start\":43981},{\"end\":44002,\"start\":43999},{\"end\":44579,\"start\":44573},{\"end\":44602,\"start\":44588},{\"end\":44617,\"start\":44611},{\"end\":45339,\"start\":45334},{\"end\":45350,\"start\":45346},{\"end\":45373,\"start\":45366},{\"end\":45981,\"start\":45975},{\"end\":45999,\"start\":45990},{\"end\":46015,\"start\":46007},{\"end\":46280,\"start\":46275},{\"end\":46290,\"start\":46282},{\"end\":46567,\"start\":46557},{\"end\":46583,\"start\":46578},{\"end\":46594,\"start\":46589},{\"end\":47260,\"start\":47253},{\"end\":47275,\"start\":47269},{\"end\":47287,\"start\":47282},{\"end\":47639,\"start\":47632},{\"end\":47654,\"start\":47648},{\"end\":47670,\"start\":47664},{\"end\":48361,\"start\":48354},{\"end\":48375,\"start\":48369},{\"end\":48390,\"start\":48384},{\"end\":49207,\"start\":49197},{\"end\":49496,\"start\":49490},{\"end\":49508,\"start\":49498},{\"end\":49804,\"start\":49800},{\"end\":49818,\"start\":49812},{\"end\":49832,\"start\":49826},{\"end\":50417,\"start\":50409},{\"end\":50431,\"start\":50425},{\"end\":50448,\"start\":50443},{\"end\":51119,\"start\":51109},{\"end\":51138,\"start\":51132},{\"end\":51155,\"start\":51145},{\"end\":51171,\"start\":51162},{\"end\":51193,\"start\":51180},{\"end\":51528,\"start\":51519},{\"end\":51543,\"start\":51536},{\"end\":51554,\"start\":51552},{\"end\":51824,\"start\":51817},{\"end\":51838,\"start\":51831},{\"end\":51851,\"start\":51845},{\"end\":51868,\"start\":51859},{\"end\":51881,\"start\":51876},{\"end\":51896,\"start\":51891},{\"end\":51911,\"start\":51905},{\"end\":51929,\"start\":51919},{\"end\":52289,\"start\":52286},{\"end\":52304,\"start\":52298}]", "bib_entry": "[{\"attributes\":{\"doi\":\"http:/doi.acm.org/10.1145/2786805.2786849\",\"id\":\"b0\",\"matched_paper_id\":9279336},\"end\":36307,\"start\":35595},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":2706277},\"end\":36816,\"start\":36309},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2723946},\"end\":37429,\"start\":36818},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3495200},\"end\":37657,\"start\":37431},{\"attributes\":{\"doi\":\"arXiv:1803.09473\",\"id\":\"b4\"},\"end\":37952,\"start\":37659},{\"attributes\":{\"doi\":\"http:/doi.acm.org/10.1145/3192366.3192412\",\"id\":\"b5\",\"matched_paper_id\":4383884},\"end\":38727,\"start\":37954},{\"attributes\":{\"id\":\"b6\"},\"end\":39055,\"start\":38729},{\"attributes\":{\"doi\":\"arXiv:1611.01989\",\"id\":\"b7\"},\"end\":39377,\"start\":39057},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":13020969},\"end\":39904,\"start\":39379},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":51818292},\"end\":40136,\"start\":39906},{\"attributes\":{\"doi\":\"arXiv:1406.1078\",\"id\":\"b10\"},\"end\":40638,\"start\":40138},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":6933074},\"end\":41071,\"start\":40640},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":5575601},\"end\":41586,\"start\":41073},{\"attributes\":{\"doi\":\"10.1162/neco.1997.9.8.1735\",\"id\":\"b13\",\"matched_paper_id\":1915014},\"end\":41902,\"start\":41588},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":8820379},\"end\":42578,\"start\":41904},{\"attributes\":{\"id\":\"b15\"},\"end\":42827,\"start\":42580},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":794019},\"end\":43905,\"start\":42829},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":19194935},\"end\":44472,\"start\":43907},{\"attributes\":{\"doi\":\"10.18653/v1/P17-2045\",\"id\":\"b18\",\"matched_paper_id\":17355},\"end\":45258,\"start\":44474},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1998416},\"end\":45888,\"start\":45260},{\"attributes\":{\"id\":\"b20\"},\"end\":46186,\"start\":45890},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":145918791},\"end\":46482,\"start\":46188},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1105\",\"id\":\"b22\",\"matched_paper_id\":13529592},\"end\":47193,\"start\":46484},{\"attributes\":{\"doi\":\"http:/doi.acm.org/10.1145/2666356.2594321\",\"id\":\"b23\",\"matched_paper_id\":13040187},\"end\":47576,\"start\":47195},{\"attributes\":{\"doi\":\"http:/doi.acm.org/10.1145/2676726.2677009\",\"id\":\"b24\",\"matched_paper_id\":14571254},\"end\":48294,\"start\":47578},{\"attributes\":{\"doi\":\"http:/doi.acm.org/10.1145/2983990.2984041\",\"id\":\"b25\",\"matched_paper_id\":2658344},\"end\":49116,\"start\":48296},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":18838459},\"end\":49421,\"start\":49118},{\"attributes\":{\"id\":\"b27\"},\"end\":49721,\"start\":49423},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1918428},\"end\":50341,\"start\":49723},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1114678},\"end\":51033,\"start\":50343},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":6844431},\"end\":51460,\"start\":51035},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7961699},\"end\":51781,\"start\":51462},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":13756489},\"end\":52212,\"start\":51783},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1041\",\"id\":\"b33\",\"matched_paper_id\":12718048},\"end\":52891,\"start\":52214}]", "bib_title": "[{\"end\":35637,\"start\":35595},{\"end\":36362,\"start\":36309},{\"end\":36892,\"start\":36818},{\"end\":37473,\"start\":37431},{\"end\":38023,\"start\":37954},{\"end\":39413,\"start\":39379},{\"end\":39961,\"start\":39906},{\"end\":40691,\"start\":40640},{\"end\":41146,\"start\":41073},{\"end\":41610,\"start\":41588},{\"end\":41958,\"start\":41904},{\"end\":42891,\"start\":42829},{\"end\":43972,\"start\":43907},{\"end\":44565,\"start\":44474},{\"end\":45326,\"start\":45260},{\"end\":46271,\"start\":46188},{\"end\":46549,\"start\":46484},{\"end\":47243,\"start\":47195},{\"end\":47622,\"start\":47578},{\"end\":48344,\"start\":48296},{\"end\":49188,\"start\":49118},{\"end\":49786,\"start\":49723},{\"end\":50402,\"start\":50343},{\"end\":51100,\"start\":51035},{\"end\":51512,\"start\":51462},{\"end\":51808,\"start\":51783},{\"end\":52274,\"start\":52214}]", "bib_author": "[{\"end\":35660,\"start\":35639},{\"end\":35673,\"start\":35660},{\"end\":35689,\"start\":35673},{\"end\":35705,\"start\":35689},{\"end\":36385,\"start\":36364},{\"end\":36400,\"start\":36385},{\"end\":36417,\"start\":36400},{\"end\":36425,\"start\":36417},{\"end\":36915,\"start\":36894},{\"end\":36925,\"start\":36915},{\"end\":36943,\"start\":36925},{\"end\":37496,\"start\":37475},{\"end\":37515,\"start\":37496},{\"end\":37532,\"start\":37515},{\"end\":37669,\"start\":37659},{\"end\":37689,\"start\":37669},{\"end\":37700,\"start\":37689},{\"end\":37712,\"start\":37700},{\"end\":38035,\"start\":38025},{\"end\":38055,\"start\":38035},{\"end\":38066,\"start\":38055},{\"end\":38078,\"start\":38066},{\"end\":38839,\"start\":38821},{\"end\":38854,\"start\":38839},{\"end\":38869,\"start\":38854},{\"end\":39070,\"start\":39057},{\"end\":39089,\"start\":39070},{\"end\":39108,\"start\":39089},{\"end\":39127,\"start\":39108},{\"end\":39142,\"start\":39127},{\"end\":39153,\"start\":39142},{\"end\":39429,\"start\":39415},{\"end\":39446,\"start\":39429},{\"end\":39463,\"start\":39446},{\"end\":39977,\"start\":39963},{\"end\":39994,\"start\":39977},{\"end\":40009,\"start\":39994},{\"end\":40248,\"start\":40233},{\"end\":40270,\"start\":40248},{\"end\":40287,\"start\":40270},{\"end\":40305,\"start\":40287},{\"end\":40321,\"start\":40305},{\"end\":40337,\"start\":40321},{\"end\":40352,\"start\":40337},{\"end\":40707,\"start\":40693},{\"end\":40724,\"start\":40707},{\"end\":40743,\"start\":40724},{\"end\":40758,\"start\":40743},{\"end\":40780,\"start\":40758},{\"end\":40796,\"start\":40780},{\"end\":41163,\"start\":41148},{\"end\":41178,\"start\":41163},{\"end\":41629,\"start\":41612},{\"end\":41649,\"start\":41629},{\"end\":41977,\"start\":41960},{\"end\":41994,\"start\":41977},{\"end\":42008,\"start\":41994},{\"end\":42026,\"start\":42008},{\"end\":42650,\"start\":42641},{\"end\":42657,\"start\":42650},{\"end\":42665,\"start\":42657},{\"end\":42678,\"start\":42665},{\"end\":42688,\"start\":42678},{\"end\":42908,\"start\":42893},{\"end\":42920,\"start\":42908},{\"end\":42937,\"start\":42920},{\"end\":42959,\"start\":42937},{\"end\":42978,\"start\":42959},{\"end\":42995,\"start\":42978},{\"end\":43009,\"start\":42995},{\"end\":43020,\"start\":43009},{\"end\":43037,\"start\":43020},{\"end\":43051,\"start\":43037},{\"end\":43063,\"start\":43051},{\"end\":43077,\"start\":43063},{\"end\":43099,\"start\":43077},{\"end\":43112,\"start\":43099},{\"end\":43988,\"start\":43974},{\"end\":44004,\"start\":43988},{\"end\":44581,\"start\":44567},{\"end\":44604,\"start\":44581},{\"end\":44619,\"start\":44604},{\"end\":45341,\"start\":45328},{\"end\":45352,\"start\":45341},{\"end\":45375,\"start\":45352},{\"end\":45983,\"start\":45960},{\"end\":46001,\"start\":45983},{\"end\":46017,\"start\":46001},{\"end\":46282,\"start\":46273},{\"end\":46292,\"start\":46282},{\"end\":46569,\"start\":46551},{\"end\":46585,\"start\":46569},{\"end\":46596,\"start\":46585},{\"end\":47262,\"start\":47245},{\"end\":47277,\"start\":47262},{\"end\":47289,\"start\":47277},{\"end\":47641,\"start\":47624},{\"end\":47656,\"start\":47641},{\"end\":47672,\"start\":47656},{\"end\":48363,\"start\":48346},{\"end\":48377,\"start\":48363},{\"end\":48392,\"start\":48377},{\"end\":49209,\"start\":49190},{\"end\":49498,\"start\":49488},{\"end\":49510,\"start\":49498},{\"end\":49806,\"start\":49788},{\"end\":49820,\"start\":49806},{\"end\":49834,\"start\":49820},{\"end\":50419,\"start\":50404},{\"end\":50433,\"start\":50419},{\"end\":50450,\"start\":50433},{\"end\":51121,\"start\":51102},{\"end\":51140,\"start\":51121},{\"end\":51157,\"start\":51140},{\"end\":51173,\"start\":51157},{\"end\":51195,\"start\":51173},{\"end\":51530,\"start\":51514},{\"end\":51545,\"start\":51530},{\"end\":51556,\"start\":51545},{\"end\":51826,\"start\":51810},{\"end\":51840,\"start\":51826},{\"end\":51853,\"start\":51840},{\"end\":51870,\"start\":51853},{\"end\":51883,\"start\":51870},{\"end\":51898,\"start\":51883},{\"end\":51913,\"start\":51898},{\"end\":51931,\"start\":51913},{\"end\":52291,\"start\":52276},{\"end\":52306,\"start\":52291}]", "bib_venue": "[{\"end\":35942,\"start\":35844},{\"end\":36548,\"start\":36495},{\"end\":37088,\"start\":37013},{\"end\":38337,\"start\":38228},{\"end\":39608,\"start\":39533},{\"end\":41357,\"start\":41276},{\"end\":42222,\"start\":42125},{\"end\":43333,\"start\":43221},{\"end\":44168,\"start\":44081},{\"end\":44800,\"start\":44728},{\"end\":45550,\"start\":45463},{\"end\":46777,\"start\":46705},{\"end\":47933,\"start\":47823},{\"end\":48721,\"start\":48577},{\"end\":50009,\"start\":49922},{\"end\":50626,\"start\":50539},{\"end\":52487,\"start\":52415},{\"end\":35842,\"start\":35746},{\"end\":36493,\"start\":36425},{\"end\":37011,\"start\":36943},{\"end\":37536,\"start\":37532},{\"end\":37782,\"start\":37728},{\"end\":38226,\"start\":38119},{\"end\":38819,\"start\":38729},{\"end\":39195,\"start\":39169},{\"end\":39531,\"start\":39463},{\"end\":40013,\"start\":40009},{\"end\":40231,\"start\":40138},{\"end\":40840,\"start\":40796},{\"end\":41274,\"start\":41178},{\"end\":41688,\"start\":41675},{\"end\":42123,\"start\":42026},{\"end\":42639,\"start\":42580},{\"end\":43219,\"start\":43112},{\"end\":44079,\"start\":44004},{\"end\":44726,\"start\":44639},{\"end\":45461,\"start\":45375},{\"end\":45958,\"start\":45890},{\"end\":46316,\"start\":46292},{\"end\":46703,\"start\":46616},{\"end\":47341,\"start\":47330},{\"end\":47821,\"start\":47713},{\"end\":48575,\"start\":48433},{\"end\":49257,\"start\":49209},{\"end\":49486,\"start\":49423},{\"end\":49920,\"start\":49834},{\"end\":50537,\"start\":50450},{\"end\":51231,\"start\":51195},{\"end\":51605,\"start\":51556},{\"end\":51980,\"start\":51931},{\"end\":52413,\"start\":52326}]"}}}, "year": 2023, "month": 12, "day": 17}