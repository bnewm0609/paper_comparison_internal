{"id": 237640304, "updated": "2023-03-25 18:30:40.196", "metadata": {"title": "Crowdsourcing of Parallel Corpora: the Case of Style Transfer for Detoxification", "authors": "[{\"first\":\"Daryna\",\"last\":\"Dementieva\",\"middle\":[]},{\"first\":\"Sergey\",\"last\":\"Ustyantsev\",\"middle\":[]},{\"first\":\"David\",\"last\":\"Dale\",\"middle\":[]},{\"first\":\"Olga\",\"last\":\"Kozlova\",\"middle\":[]},{\"first\":\"Nikita\",\"last\":\"Semenov\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Panchenko\",\"middle\":[]},{\"first\":\"Varvara\",\"last\":\"Logacheva\",\"middle\":[]}]", "venue": "CSW@VLDB", "journal": "35-49", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "One of the ways to fighting toxicity online is to automatically rewrite toxic messages. This is a sequenceto-sequence task, and the easiest way of solving it is to train an encoder-decoder model on a set of parallel sentences (pairs of sentences with the same meaning, where one is offensive and the other is not). However, such data does not exist, making researchers resort to non-parallel corpora. We close this gap by suggesting a crowdsourcing scenario for creating a parallel dataset of detoxifying paraphrases. In our first experiments, we collect paraphrases for 1,200 toxic sentences. We describe and analyse the crowdsourcing setup and the resulting corpus.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/csw/DementievaUDKSP21", "doi": null}}, "content": {"source": {"pdf_hash": "d113e7cf8adf596e4d7c692b6d9d23179a243b78", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "35ec5b05d7b43de3d7bf34bd982850606ef1d283", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d113e7cf8adf596e4d7c692b6d9d23179a243b78.txt", "contents": "\nCrowdsourcing of Parallel Corpora: the Case of Style Transfer for Detoxification\n\n\nDaryna Dementieva \nSkolkovo Institute of Science and Technology\nMoscowRussia\n\nSergey Ustyantsev \nSkolkovo Institute of Science and Technology\nMoscowRussia\n\nDavid Dale \nSkolkovo Institute of Science and Technology\nMoscowRussia\n\nOlga Kozlova \nMobile TeleSystems (MTS)\nMoscowRussia\n\nNikita Semenov \nMobile TeleSystems (MTS)\nMoscowRussia\n\nAlexander Panchenko \nSkolkovo Institute of Science and Technology\nMoscowRussia\n\nVarvara Logacheva \nSkolkovo Institute of Science and Technology\nMoscowRussia\n\nCrowdsourcing of Parallel Corpora: the Case of Style Transfer for Detoxification\ntoxicitydatasetcrowdsourcingparallel data\nOne of the ways to fighting toxicity online is to automatically rewrite toxic messages. This is a sequenceto-sequence task, and the easiest way of solving it is to train an encoder-decoder model on a set of parallel sentences (pairs of sentences with the same meaning, where one is offensive and the other is not). However, such data does not exist, making researchers resort to non-parallel corpora. We close this gap by suggesting a crowdsourcing scenario for creating a parallel dataset of detoxifying paraphrases. In our first experiments, we collect paraphrases for 1,200 toxic sentences. We describe and analyse the crowdsourcing setup and the resulting corpus.\n\nIntroduction\n\nToxicity is a major problem on the Internet. There are multiple strategies for fighting it. Detection of toxicity, being a popular area of research in NLP [1,2,3], is a necessary first step for any toxicity removal strategy. There exist multiple methods for toxicity detection [4,5] and datasets [6,7,8] which can be used as training data for toxicity detection models.\n\nToxic messages can differ in terms of their content. For some of them, the offence is the only content, and their only goal is to insult the reader. On the other hand, other messages classified as toxic can contain a non-toxic and useful content that is only expressed in a toxic way. If we manage to rewrite such messages to eliminate the toxicity and save the content, we will be able to keep a constructive and peaceful discussion and prevent it from decaying to a row of insults.\n\nThe task of detoxification of text has already been tackled by several researchers [9,10,11]. This task is usually formulated as a style transfer task [12] -a task of rewriting a text with keeping the original content as much as possible and changing a particular attribute (author profile, text sentiment, degree of complexity, etc.). This attribute is referred to as style. In the case of detoxification, the task is to transfer text from toxic to neutral (non-toxic) style. It is similar to the tasks of rewriting texts with a varying degree of formality [13,14] or politeness [15,16].\n\nAs with many other sequence-to-sequence tasks (machine translation, text summarization, paraphrasing), style transfer can be successfully solved using encoder-decoder models trained on parallel data [14,17]. This is the easiest training setup because it contains a correct answer towards which a model can be optimised. However, for the majority of style transfer tasks, the parallel data is unavailable [12]. Therefore, style transfer models are usually trained on non-parallel datasets. If parallel data was available, they could perform better with smaller training corpora. The experiments show that training even on an extremely small parallel dataset can yield a well-performing style transfer model [18].\n\nThe goal of our work is to close this gap for one of the directions of text style transfer, namely detoxification. We collect a parallel dataset via crowdsourcing. We ask crowd workers to rewrite the toxic sentences in a non-toxic way and employ other workers to verify the rewritten versions. We ask several workers to paraphrase each of the toxic messages and yield multiple paraphrases.\n\nOur main contribution is a new crowdsourcing setup for collecting parallel data for style transfer tasks (in our case -for detoxification task). We also release a collected parallel dataset. 1\n\n\nRelated Work\n\nHere we discuss the approaches to creating training data for style transfer and, in particular, for detoxification task.\n\n\nStyle Transfer Datasets\n\nThe vast majority of datasets for style transfer are non-parallel. Thus, they consist of two or more subcorpora of a particular style. The subcorpora are not related to one another. Collecting such datasets is usually relatively easy because we do not need to label the texts for style explicitly. The style labels often already exist in the data (as in case of positive and negative reviews [12] 2 ) or their source serves as a label (e.g. texts from Twitter can be labelled with \"Twitter\" style, scientific articles get a label \"academic\", etc.). In these cases, data collection boils down to fetching the texts from the original sources, and the corpus size depends solely on the number of texts in these sources. A more complicated scenario is required when \"style\" is not a property of the data source. In the case of corpora labelled for toxicity, each text has to be manually labelled for the presence or absence of toxic content. However, even in this case, it is possible to collect a large number of texts -the size of the first Jigsaw dataset [19] contains 140,000 sentences, and the aggregated size of three Jigsaw datasets [19,20,21] is around 2 million unique entities.\n\nIn contrast to that, parallel corpora are more difficult to generate. For some other tasks, the parallel data may appear naturally, so that researchers do not need to perform \"translation\" for the research purposes. For example, translations between languages are generated simply because there is a need to transfer the information to people who do not speak the source language. Similarly, the summarization task can use abstracts of scientific papers [22], \"TL;DR\" sections of social media posts [23] and summaries of news articles [24], which are created for convenience and not solely for textual data collection. There exist examples of naturally created parallel style transfer datasets. One of them is the Bible dataset [17] which exists in multiple translations of different epochs. Another example is the simple-to-regular Wikipedia dataset [25] which was generated automatically by aligning the text of Wikipedia with that of Simple Wikipedia. Likewise, a biased-to-neutral Wikipedia corpus [26] was created automatically using the information on article edits.\n\nBesides these special cases, there exists a large style transfer dataset that was created from scratch. This is GYAFC dataset [14] which contains informal sentences and their formal versions written by crowd workers and reviewed by experts. They used Amazon Mechanical Turk to collect the data. The task was only to generate the paraphrasing and the quality control was done manually. We suggest a new pipeline that does not require manual selection of samples for the dataset and provide automatic control of the quality.\n\n\nToxicity Datasets\n\nThere exist a large number of datasets labelled for toxicity. They contain sentences and paragraphs from various social media such as Twitter [6,27,7], Reddit [28,29], Facebook [30]. There exist a number of datasets based on Wikipedia talk pages -namely, Jigsaw datasets [19,20,21] and some others [8]. The majority of data is labelled via crowdsourcing, except for several expert-labelled corpora [6]. The labels usually include several varieties of toxicity, for example, they differentiate between offence and hate speech [27,7]. Some datasets are restricted to a particular type of toxicity, e.g. sexism and racism [6,7] or explore a particular type of toxicity, for example, toxic unanswerable questions [29]. The size of the datasets ranges from 9,000 [7] to 100,000 sentences [8], of which toxic sentences usually constitute 25-30%.\n\nNone of these datasets is parallel, because they were created for toxicity classification, and not for rewriting of toxic sentences. However, in works on text detoxification, the authors use these datasets either directly for training their models or to train classifiers which are then used for automatically labelling more data with (toxic or neutral) style. Nogueira dos Santos et al. [9] use the Reddit and Twitter corpora automatically labelled for toxicity using a pre-trained classifier. Tran et al. [10] collect a subset of controversial Reddit comments and label them automatically based on the presence or absence of offensive words from a manually constructed list. In the work [11] the authors use the only large dataset with manual toxicity labelling, namely, the Jigsaw dataset used in the competition of fighting the Unintended bias in toxicity detection [20]. Similarly to this work, we employ one of the Jigsaw datasets. However, our work is the first to create a parallel detoxification corpus.\n\n\nParaphrase Generation Pipeline\n\nWe ask crowd workers to rewrite toxic sentences so that they keep the original content and do not sound offensive. We hire workers via Yandex.Toloka 3 platform. Since the phrases produced by crowd workers can be of low quality, they should not be used without revision. In [14] this revision was conducted by experts. We suggest an alternative setup where sentences are also verified by (other) crowd workers.\n\nThe objective of detoxification is to rephrase a toxic sentence so that (i) it keeps the original content and (ii) stops being toxic. Thus, we create three crowdsourcing projects: one for collecting paraphrases and another two for checking if these paraphrases conform to the two objectives. We apply the three tasks to the data sequentially. The overall pipeline is shown in Figure 1.\n\n\nTask 1: Generation\n\nIn the first task, we ask users to rephrase a given sentence so that it does not sound offensive. Workers are shown a phrase and should rewrite them in a textbox (see Figure 2a).\n\nHowever, not all sentences can be detoxified. First, there exist sentences that do not contain any non-toxic content -so removing toxicity from them would leave nothing from the original sentences. Consider the following examples:\n\n\u2022 It sucks that you're an awful person, \u2022 Maybe they should deport you back to your country, or your grandparents country.\n\nTheir only content is an offence towards the reader, so if we detoxify them, their sense will differ substantially.\n\nSecondly, since we pre-select sentences for detoxification semi-automatically (see Section 4.1), some of the input sentences can be non-toxic and need no detoxification. Finally, some of the given sentences can be unclear to workers due to lack of context or simply because they are meaningless.\n\nIf we do not give the worker the possibility to skip a sentence without providing a paraphrase, we can yield a large number of bad-quality paraphrases. Therefore, we extend the task interface with the option \"I can't rewrite the text\". When a user chooses it, they are shown the possible reasons for the inability to rewrite (see Figure 2b).\n\nOn the other hand, some workers can use the \"I can't rewrite\" option to cheat. Since choosing this option is faster than rewriting a sentence, they can choose it too often. To avoid that, we give each input sentence to three workers and pay them for choosing the \"I can't rewrite\" option only if two or more of them agree on it. Otherwise, if a worker submits a paraphrase, we check it manually in Tasks 2 and 3 and pay only for the paraphrases approved during both tasks.  \n\n\nTask 2: Content Preservation Check\n\nAfter having generated the paraphrases, we show them to users along with the original messages and ask if the meanings of the two sentences are close. This procedure checks if the content was preserved in the detoxified version of the input sentence and also implicitly filters out senseless outputs because they obviously do not keep the original content. The task interface is shown in Figure 3.\n\n\nTask 3: Toxicity Check\n\nThe second series of paraphrases review checks if the workers succeeded in eliminating toxicity. We show users the paraphrases and ask if they contain any offence or swear words (see Figure 4).\n\nBesides filtering out unsuitable paraphrases, Tasks 2 and 3 serve for paying for work done in Task 1. Namely, we only pay for paraphrases which the checks in Tasks 2 and 3.\n\nThe overall data collection pipeline is the following:\n\n\u2022 We select sentences for rewriting, \u2022 We feed the sentences to Task 1, \u2022 We feed the paraphrases generated in Task 1 to Task 2,\n\n\u2022 We feed the paraphrases which passed Task 2 to Task 3, \u2022 We pay for paraphrases from Task 1, if they passed checks in Task 2 and Task 3, \u2022 We pay for \"I can't rewrite\" answers if two or more workers agreed on them.\n\n\nCrowdsourcing Settings\n\nHere we describe the settings of our crowdsourcing projects in more detail.  \n\n\nData Preprocessing\n\nWe fetch data for manual rewriting from two sources: (i) Jigsaw dataset of toxic sentences [19], and (ii) Reddit&Twitter dataset used by [9]. The Reddit&Twitter dataset was pre-processed by the authors [9]. This preprocessing included dividing original comments into sentences and automatically classifying them as toxic or nontoxic with a pre-trained classifier. The reason for this is that the original comments can be long, and generation models perform worse on longer texts. We use this Reddit&Twitter data and perform the analogous preprocessing for the Jigsaw dataset: we divide it into sentences and classify them with a pre-trained toxicity classifier.\n\nTo train a classifier, we merge the English parts of the three datasets by Jigsaw [19,20,21], containing around 2 million examples. We take half of this merged dataset and fine-tune a RoBERTa model [31] on it. We use the roberta-large model from the original repository. The classifier reaching the AUC-ROC of 0.98 and F 1 -score of 0.76 on the test set of the first Jigsaw dataset.\n\nWe select only sentences classified as toxic, whose length is between 5 and 20 words (for both datasets). The lower length limit serves for filtering out overly short sentences which are difficult to understand without context. The upper limit is for the convenience of workers who struggle with the rewriting of long sentences.\n\n\nMultiple Labellings\n\nWe ask several workers to label each example. For Tasks 2 and 3, we compute the final label using the Dawid-Skene aggregation method [32] which defines the true label iteratively giving more weight to the answers of workers whose opinion more often agrees with that of other workers.\n\nIn Task 1 the number of labellings per task is 3. In Tasks 2 and 3, the number of labellings per task is defined dynamically depending on the agreement on the task. First, the minimum number of users (3 in our setting) label an example, and if their agreement is above a threshold (0.8 in our setting), the task is not sent to extra labelling. Otherwise, the system fetches up to the maximum number of labellings (5 in our setting) until the agreement reaches the threshold.\n\n\nInstructions\n\nThe instruction for crowd workers says that they should rewrite the given sentences so that they mean the same as the original ones, but do not sound offensive anymore. We do not explicitly define the notion of offensiveness, because we suggest that it should be an intuitively clear concept. Instead of giving a definition of toxicity, we give examples of toxic and non-toxic sentences.\n\n\nTraining of Workers\n\nFor all tasks, workers have to complete a set of training tasks to be admitted to work on paid tasks. These tasks have a pre-defined correct answer. If a user answer does not match the correct one, the user is shown a hint which explains their mistake. Workers are admitted to the paid task if they completed the training with a score above a threshold: 40% correct answers for Task 1, 90% for Tasks 2 and 3. Such low acceptance score for Task 1 is due to the task complexity -there is no single answer whether the sentence can be rewritten into a civil manner or not because different people from different cultural background can have different perspective on the toxicity. At the same time, even such a low score allows us to ban the user that just select only one answer, for example, and do not put effort into thorough task completeness. Task 2 and 3 have more exact answer and, as a result, have a higher threshold of acceptance.\n\nIn addition to that, we provide extra training tasks during labelling. Training tasks are added to labelling examples. If a worker makes an error in such tasks, they are shown an explanation. Workers are not penalised for making errors. We need these tasks to reinforce the worker's understanding of the task.\n\n\nQuality Control\n\nTo control the quality, we occasionally add control tasks during labelling. These tasks have a pre-defined correct answer. If a worker makes too many mistakes in these tasks, they are banned. In our projects, a worker is banned if they make 3 or more mistakes in the latest 4 control tasks.\n\nAnother means of control that we use is the agreement between users. If a user disagrees with the majority (3 or more) of users in over 66% cases, this user is banned.\n\n\nPayment\n\nIn Yandex.Toloka, a task page shown to workers can contain multiple tasks. Therefore, customers set the payment per task page. In Task 1, a page contains 4 tasks for labelling and one control task and costs $0.02. In Tasks 2 and 3, a page consists of 10 labelling tasks, 1 to 2 training tasks and 1 to 2 control tasks and costs $0.01. The number of training and control tasks is defined by the agreement of the worker with others. Tasks 2 and 3 are paid instantly, whereas in Task 1 we check the paraphrases before paying. If a worker indicated that a sentence cannot be paraphrased, we pay for this answer only if at least one other worker agreed with that. If a worker typed in a paraphrase, we send it to Tasks 2 and 3 and pay only for the ones approved by both tasks. The payment procedure is shown in why is the scale of that graph so fucked up? Why is the scale of that graph not placed rightly.\n\nJigsaw the chinese came out of this looking like lying, petulant children.\n\nThe chinese came out of this looking like dishonest, bad tempered children.\n\nyoure a libby so dont talk ridiculous like you would vote any other way.\n\nYou're a liberal so you wouldn't vote other way.\n\nshe is a lying disgrace who refuses to accept that she lost.\n\nShe is lying because she does not want to accept she has lost.\n\nall you trump clowns are seriously messed up. Trumps voters are seriously mislead.\n\nif you think so, you are making a clown out of yourself. It is wrong of you to think that way.\n\n\nTable 1\n\nExamples of detoxifying paraphrases from our corpus. Figure 1: the green arrows indicate variants where we pay for Task 1 and the red arrows show when it is not paid.\n\n\nData and Pipeline Analysis\n\nWe tested a pipeline for collecting parallel detoxification data. As a proof of concept, we collected a dataset with paraphrases for 1,244 toxic sentences, each having 1-5 paraphrase variants, resulting in 5,228 paraphrases overall. The examples of generated paraphrases are given in Table 1.\n\n\nData Statistics\n\nThe statistics of the paraphrases written by crowd workers are presented in Table 2. For both Jigsaw and Reddit&Twitter datasets, we used the equal number of sentences (1,200) as the input to the crowdsourcing pipeline from Figure 1. From this input data, 675 samples from Jigsaw (56%) received at least one good paraphrase, while for the Reddit dataset this amount is smaller -569 samples (47%).   Some of the input samples could not be paraphrased or all paraphrases generated for them were rejected during verification. Others yielded one or more paraphrases. The distribution of the different results is shown in Figure 5. The pictures for Jigsaw and Reddit datasets differ. Besides the mentioned difference in the number of input samples which received paraphrases, Reddit has a larger number of sentences with more than one paraphrase. These sentences are probably easier to detoxify because multiple workers succeeded in providing paraphrases for them. Reddit has more of such sentences. The annotators consistency is quite high ( Table 2, columns 6 and 7). For Task2 and Task3 for both datasets \u226592% of all marked up samples have the confidence in the decision of \u226590%. We compute the cost of manual annotation. The cost per input sample is the cost of generating 1-5 paraphrases for the sample and checking these paraphrases for toxicity and content matching. The cost of the final sentence pair includes the cost of processing the inputs for which no good paraphrases were generated. Thus, this parameter depends not only on crowdsourcing settings but also on the dataset, because the percentage of detoxifiable sentences may vary for different data sources.\n\nMultiple paraphrases can give us a better insight into the phenomenon of toxicity. Namely, by comparing multiple paraphrases of one sentence we can detect its toxicity regions with higher confidence. While a single paraphrase can be uninformative (e.g. it can fully rephrase a sentence where toxicity could be eliminated by replacing several words), multiple paraphrases show a more objective picture. Table 3 shows examples of such cases. The colour is brighter for words Original to think that she's been doing that kind of shit for yeaaaars Paraphrase her behaviour has been constant for years. to think that she's been doing that kind of thing for years. to think that she's been doing that for years. to think she's been doing that for years. to think that she's been doing this kind of thing for years she is been doing those things for years to think that she's been doing it for years.\n\n\nOriginal\n\nthis is why the country is fucked up.\n\nParaphrase this is why the country does not going well. this is why the country is not growing country is suffering because of this this is why the country is bad. this is why this country is messed up. that's why the country is lost that's why this country is in such a mess. this country is bad this may be the reason why our country is not so progressive this is why the country isn't developing. this is why the county has problems.\n\n\nTable 3\n\nDetermination of the most toxic regions of a sentence based on multiple detoxifications.\n\nthat are absent in the detoxified versions more often. It can be seen that while some non-toxic words can occasionally be removed, the joint statistics of multiple paraphrases identifies the regions of toxicity. This token-level information can be useful for toxicity classification as well. As shown in [33], the rationales (highlighted phrases that justify the class label assigned to a sentence) improve the performance of text classifiers and their explainability. The token-level degree of toxicity can serve as a rationale for sentence-level classifiers. Also, it can be seen from Tables 1 and 3 that there can be some grammatical mistakes in both original and generated sentences. The reason for that is that the majority of English content in the Internet is produced by people for whom English is a second language. The same situation about language we have for the annotators in our task. So, we consider these mistakes as natural for both original and detoxified sentences.\n\n\nCrowdsourcers Performance\n\nThroughout data collection, up to 2,000 crowd workers participated in our experiments (in each task). However, around 1/2 (Tasks 2 and 3) to 3/4 (Task 1) of them were banned for cheating (too fast answers, failed captcha checks, errors in control questions).\n\nWe can measure the performance of crowd workers with a number of parameters. These are their agreement computed as the average confidence computed with Dawid-Skene aggregation method [32] and their performance on pre-labelling training and control tasks. In the most challenging Task 1 the performance on the control questions was 32.8% of correct answers. In Tasks 2 and 3 these numbers were 63.4% and 86.9%, respectively. Thus, Task 3 was the easiest. This is corroborated by the fact that users completed this task faster. It took them on average 1 minute 31 seconds to label 13-15 sentences (one task page) as toxic or safe. For Task 2 this number is 3 minutes 8 seconds (for 13-15 tasks), and one Task 1 page was completed on average in 5 minutes 17 seconds (5 tasks).\n\nIn addition to that, Task 3 was rated higher by crowd workers than the other two tasks. In Yandex.Toloka workers can rate projects by four parameters:\n\n\u2022 how interesting the task is (formulated as \"Would you complete this task in the future?\"), \u2022 clarity of instructions, \u2022 task interface, \u2022 communication with the requester.\n\nTask 3 got an average score of 4.77, whereas Tasks 1 and 2 got scores of 4.51 and 4.64, respectively.\n\n\nConclusions and Future Work\n\nWe describe a crowdsourcing setup for the collection of parallel data for the detoxification task. The data consists of pairs of sentences, one of them is toxic, and the other one has the same meaning but is not offensive. In our setup workers write paraphrases for toxic sentences and verify the content preservation and the absence of toxicity.\n\nWe collected 1-5 manually written paraphrases for over 1,200 toxic sentences from Reddit, Twitter, and Wikipedia discussion pages. This corpus is relatively small. However, we believe that even this dataset can be used for supervised training of a detoxification model, for example, for fine-tuning of a large language model, such as GPT-2 [34] or T5 [35]. Besides, it can be used for the training of a token-level toxicity classifier and as a source of extra information in a sentence-level toxicity classifier.\n\nThe most evident direction of future work is the collection of a larger dataset and investigation of the optimal number of parallel examples for the training of a well-performing detoxification model. In addition to that, we would like to further improve our crowdsourcing pipeline by finding the optimal number of labellings per sample and compare the cost and efficiency of setups with one and multiple paraphrases.\n\nWe would also like to further research the usefulness of multiple paraphrases for a single toxic message for the training and evaluation of detoxification models. Finally, our experiments show that data from different sources can have different properties important for parallel data collection. Namely, the Reddit dataset has more sentences that can be paraphrased. It would be useful for further data collection to investigate the properties of different datasets.\n\nFigure 1 :\n1The pipeline of crowdsourcing for generation of detoxifying paraphrases.\n\nFigure 2 :\n2Interface of Task 1 (generation of paraphrases).\n\nFigure 3 :\n3Interface of Task 2 (evaluation of content match).\n\nFigure 4 :\n4Interface of Task 3 (evaluation of toxicity).\n\nFigure 5 :\n5Distribution of results of detoxification experiments.\n\nOriginal Paraphrase\nOriginalRedditthis is scaring the shit out of me. This is really scaring me.this is a joke , are you all fucking retards? \nThis is a joke, are you all crazy? \n\neverybody is such a fucking pussy. \nEverybody is acting cowardly. \n\ndid you think i was going to sit back and let some \nimbecile spew hatred towards me? \n\nDid you think I was going to let \nan unreasonable person hate me? \n\ncalm the fuck down, cnn. \nPlease calm your nerves, CNN. \n\n\n\nTable 2\n2Statistics of the crowdsourcing experiments and final datasets.0 \n200 \n400 \n600 \n800 \n1000 \n1200 \n\nReddit \n\nJigsaw \n\nCannot rewrite \nLow confidence \nOne para. \nTwo para. \nThree para. \n>3 para. \n\n\nhttps://toloka.yandex.com\n\nSemEval-2020 task 12: Multilingual offensive language identification in social media. M Zampieri, P Nakov, S Rosenthal, P Atanasova, G Karadzhov, H Mubarak, L Derczynski, Z Pitenis, \u00c7 \u00c7\u00f6ltekin, Proceedings of the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational Linguistics. the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational LinguisticsBarcelonaM. Zampieri, P. Nakov, S. Rosenthal, P. Atanasova, G. Karadzhov, H. Mubarak, L. Derczyn- ski, Z. Pitenis, \u00c7. \u00c7\u00f6ltekin, SemEval-2020 task 12: Multilingual offensive language identifi- cation in social media (OffensEval 2020), in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational Linguistics, Barcelona (online), 2020, pp. 1425-1447. URL: https://www.aclweb.org/anthology/2020.semeval-1.188.\n\nTowards non-toxic landscapes: Automatic toxic comment detection using DNN. A G Sa, I Illina, D Fohr, Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying, European Language Resources Association (ELRA). the Second Workshop on Trolling, Aggression and Cyberbullying, European Language Resources Association (ELRA)Marseille, FranceA. G. D'Sa, I. Illina, D. Fohr, Towards non-toxic landscapes: Automatic toxic comment detection using DNN, in: Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying, European Language Resources Association (ELRA), Marseille, France, 2020, pp. 21-25. URL: https://www.aclweb.org/anthology/2020.trac-1.4.\n\nFortifying toxic speech detectors against veiled toxicity. X Han, Y Tsvetkov, 10.18653/v1/2020.emnlp-main.622Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsX. Han, Y. Tsvetkov, Fortifying toxic speech detectors against veiled toxicity, in: Pro- ceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), Association for Computational Linguistics, Online, 2020, pp. 7732-7739. URL: https://www.aclweb.org/anthology/2020.emnlp-main.622. doi:10.18653/v1/2020. emnlp-main.622.\n\nA survey on hate speech detection using natural language processing. A Schmidt, M Wiegand, 10.18653/v1/W17-1101Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media. the Fifth International Workshop on Natural Language Processing for Social MediaValencia, SpainAssociation for Computational LinguisticsA. Schmidt, M. Wiegand, A survey on hate speech detection using natural language processing, in: Proceedings of the Fifth International Workshop on Natural Language Processing for Social Media, Association for Computational Linguistics, Valencia, Spain, 2017, pp. 1-10. URL: https://aclanthology.org/W17-1101. doi:10.18653/v1/W17-1101.\n\nZero-shot crosslingual content filtering: Offensive language and hate speech detection. A Pelicon, R Shekhar, M Martinc, B \u0160krlj, M Purver, S Pollak, Proceedings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation. the EACL Hackashop on News Media Content Analysis and Automated Report GenerationAssociation for Computational LinguisticsA. Pelicon, R. Shekhar, M. Martinc, B. \u0160krlj, M. Purver, S. Pollak, Zero-shot cross- lingual content filtering: Offensive language and hate speech detection, in: Proceed- ings of the EACL Hackashop on News Media Content Analysis and Automated Report Generation, Association for Computational Linguistics, Online, 2021, pp. 30-34. URL: https://aclanthology.org/2021.hackashop-1.5.\n\nHateful symbols or hateful people? predictive features for hate speech detection on Twitter. Z Waseem, D Hovy, 10.18653/v1/N16-2013Proceedings of the NAACL Student Research Workshop. the NAACL Student Research WorkshopSan Diego, CaliforniaAssociation for Computational LinguisticsZ. Waseem, D. Hovy, Hateful symbols or hateful people? predictive features for hate speech detection on Twitter, in: Proceedings of the NAACL Student Research Workshop, Association for Computational Linguistics, San Diego, California, 2016, pp. 88-93. URL: https://aclanthology.org/N16-2013. doi:10.18653/v1/N16-2013.\n\nSemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter. V Basile, C Bosco, E Fersini, D Nozza, V Patti, F M Pardo, P Rosso, M Sanguinetti, 10.18653/v1/S19-2007Proceedings of the 13th International Workshop on Semantic Evaluation. the 13th International Workshop on Semantic EvaluationMinneapolis, Minnesota, USAAssociation for Computational LinguisticsV. Basile, C. Bosco, E. Fersini, D. Nozza, V. Patti, F. M. Rangel Pardo, P. Rosso, M. Sanguinetti, SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter, in: Proceedings of the 13th International Workshop on Semantic Evaluation, Association for Computational Linguistics, Minneapolis, Minnesota, USA, 2019, pp. 54-63. URL: https://aclanthology.org/S19-2007. doi:10.18653/v1/S19-2007.\n\nSubversive toxicity detection using sentiment information. E Brassard-Gourdeau, R Khoury, 10.18653/v1/W19-3501Proceedings of the Third Workshop on Abusive Language Online, Association for Computational Linguistics. the Third Workshop on Abusive Language Online, Association for Computational LinguisticsFlorence, ItalyE. Brassard-Gourdeau, R. Khoury, Subversive toxicity detection using sentiment in- formation, in: Proceedings of the Third Workshop on Abusive Language Online, As- sociation for Computational Linguistics, Florence, Italy, 2019, pp. 1-10. URL: https: //aclanthology.org/W19-3501. doi:10.18653/v1/W19-3501.\n\nFighting offensive language on social media with unsupervised text style transfer. C Nogueira, I Santos, I Melnyk, Padhi, 10.18653/v1/P18-2031Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics2Short Papers)C. Nogueira dos Santos, I. Melnyk, I. Padhi, Fighting offensive language on social media with unsupervised text style transfer, in: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), Association for Computational Linguistics, Melbourne, Australia, 2018, pp. 189-194. URL: https:// aclanthology.org/P18-2031. doi:10.18653/v1/P18-2031.\n\nTowards a friendly online community: An unsupervised style transfer framework for profanity redaction. M Tran, Y Zhang, M Soleymani, 10.18653/v1/2020.coling-main.190Proceedings of the 28th International Conference on Computational Linguistics, International Committee on Computational Linguistics. the 28th International Conference on Computational Linguistics, International Committee on Computational LinguisticsBarcelona, SpainM. Tran, Y. Zhang, M. Soleymani, Towards a friendly online community: An unsupervised style transfer framework for profanity redaction, in: Proceedings of the 28th International Conference on Computational Linguistics, International Committee on Computational Linguistics, Barcelona, Spain (Online), 2020, pp. 2107-2114. URL: https://aclanthology.org/ 2020.coling-main.190. doi:10.18653/v1/2020.coling-main.190.\n\nCivil rephrases of toxic texts with self-supervised transformers. L Laugier, J Pavlopoulos, J Sorensen, L Dixon, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeAssociation for Computational LinguisticsL. Laugier, J. Pavlopoulos, J. Sorensen, L. Dixon, Civil rephrases of toxic texts with self-supervised transformers, in: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Association for Computational Linguistics, Online, 2021, pp. 1442-1461. URL: https://aclanthology.org/ 2021.eacl-main.124.\n\nDelete, retrieve, generate: a simple approach to sentiment and style transfer. J Li, R Jia, H He, P Liang, 10.18653/v1/N18-1169Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaAssociation for Computational Linguistics1J. Li, R. Jia, H. He, P. Liang, Delete, retrieve, generate: a simple approach to sentiment and style transfer, in: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), Association for Computational Linguistics, New Orleans, Louisiana, 2018, pp. 1865-1874. URL: https://aclanthology.org/N18-1169. doi:10.18653/v1/N18-1169.\n\nGenerating formality-tuned summaries using input-dependent rewards. K Chawla, B V Srinivasan, N Chhaya, 10.18653/v1/K19-1078Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL). the 23rd Conference on Computational Natural Language Learning (CoNLL)Hong Kong, ChinaAssociation for Computational LinguisticsK. Chawla, B. V. Srinivasan, N. Chhaya, Generating formality-tuned summaries using input-dependent rewards, in: Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL), Association for Computational Linguistics, Hong Kong, China, 2019, pp. 833-842. URL: https://aclanthology.org/K19-1078. doi:10.18653/ v1/K19-1078.\n\nDear sir or madam, may I introduce the GYAFC dataset: Corpus, benchmarks and metrics for formality style transfer. S Rao, J Tetreault, 10.18653/v1/N18-1012Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, Louisiana1Association for Computational LinguisticsS. Rao, J. Tetreault, Dear sir or madam, may I introduce the GYAFC dataset: Corpus, bench- marks and metrics for formality style transfer, in: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), Association for Computational Linguis- tics, New Orleans, Louisiana, 2018, pp. 129-140. URL: https://aclanthology.org/N18-1012. doi:10.18653/v1/N18-1012.\n\nA computational approach to politeness with application to social factors. C Danescu-Niculescu-Mizil, M Sudhof, D Jurafsky, J Leskovec, C Potts, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. the 51st Annual Meeting of the Association for Computational LinguisticsSofia, BulgariaAssociation for Computational Linguistics1C. Danescu-Niculescu-Mizil, M. Sudhof, D. Jurafsky, J. Leskovec, C. Potts, A computational approach to politeness with application to social factors, in: Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Association for Computational Linguistics, Sofia, Bulgaria, 2013, pp. 250-259. URL: https: //aclanthology.org/P13-1025.\n\nPoliteness transfer: A tag and generate approach. A Madaan, A Setlur, T Parekh, B Poczos, G Neubig, Y Yang, R Salakhutdinov, A W Black, S Prabhumoye, 10.18653/v1/2020.acl-main.169Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsA. Madaan, A. Setlur, T. Parekh, B. Poczos, G. Neubig, Y. Yang, R. Salakhutdinov, A. W. Black, S. Prabhumoye, Politeness transfer: A tag and generate approach, in: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, Online, 2020, pp. 1869-1881. URL: https://aclanthology.org/ 2020.acl-main.169. doi:10.18653/v1/2020.acl-main.169.\n\nEvaluating prose style transfer with the bible. K Carlson, A Riddell, D Rockmore, Royal Society Open Science. 5K. Carlson, A. Riddell, D. Rockmore, Evaluating prose style transfer with the bible, Royal Society Open Science 5 (2018).\n\nMethods for detoxification of texts for the russian language. D Dementieva, D Moskovskiy, V Logacheva, D O Kozlova, N Semenov, A Panchenko, doi:99.9999Proceedings of the International Conference. the International ConferenceMoscow, RussiaD.Dementieva, D.Moskovskiy, V.Logacheva, D. O.Kozlova, N.Semenov, A.Panchenko, Meth- ods for detoxification of texts for the russian language, in: Proceedings of the International Conference \"Dialogue 2021\", Moscow, Russia, 2021. doi:99.9999/woot07-S422.\n\n. Jigsaw, Toxic comment classification challenge. Jigsaw, Toxic comment classification challenge, https://www.kaggle.com/c/jigsaw-toxic- comment-classification-challenge, 2018. Accessed: 2021-03-01.\n\nJigsaw unintended bias in toxicity classification. Jigsaw, Jigsaw, Jigsaw unintended bias in toxicity classification, https://www.kaggle.com/c/jigsaw- unintended-bias-in-toxicity-classification, 2019. Accessed: 2021-03-01.\n\nJigsaw multilingual toxic comment classification. Jigsaw, Jigsaw, Jigsaw multilingual toxic comment classification, https://www.kaggle.com/c/jigsaw- multilingual-toxic-comment-classification, 2020. Accessed: 2021-03-01.\n\nTLDR: Extreme summarization of scientific documents. I Cachola, K Lo, A Cohan, D Weld, 10.18653/v1/2020.findings-emnlp.428Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational LinguisticsI. Cachola, K. Lo, A. Cohan, D. Weld, TLDR: Extreme summarization of scientific documents, in: Findings of the Association for Computational Linguistics: EMNLP 2020, Association for Computational Linguistics, Online, 2020, pp. 4766-4777. URL: https://aclanthology.org/ 2020.findings-emnlp.428. doi:10.18653/v1/2020.findings-emnlp.428.\n\nMining Reddit to learn automatic summarization. M V\u00f6lske, M Potthast, S Syed, B Stein, Tl;Dr, 10.18653/v1/W17-4508Proceedings of the Workshop on New Frontiers in Summarization. the Workshop on New Frontiers in SummarizationCopenhagen, DenmarkAssociation for Computational LinguisticsM. V\u00f6lske, M. Potthast, S. Syed, B. Stein, TL;DR: Mining Reddit to learn automatic summarization, in: Proceedings of the Workshop on New Frontiers in Summarization, Association for Computational Linguistics, Copenhagen, Denmark, 2017, pp. 59-63. URL: https://aclanthology.org/W17-4508. doi:10.18653/v1/W17-4508.\n\nBlunsom, Teaching machines to read and comprehend. K M Hermann, T Kocisky, E Grefenstette, L Espeholt, W Kay, M Suleyman, P , Advances in Neural Information Processing Systems. C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, R. GarnettCurran Associates, Inc28K. M. Hermann, T. Kocisky, E. Grefenstette, L. Espeholt, W. Kay, M. Suleyman, P. Blun- som, Teaching machines to read and comprehend, in: C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, R. Garnett (Eds.), Advances in Neural Information Processing Systems, volume 28, Curran Associates, Inc., 2015. URL: https://proceedings.neurips.cc/paper/2015/ file/afdec7005cc9f14302cd0474fd0f3c96-Paper.pdf.\n\nA monolingual tree-based translation model for sentence simplification. Z Zhu, D Bernhard, I Gurevych, Proceedings of the 23rd International Conference on Computational Linguistics. the 23rd International Conference on Computational LinguisticsBeijing, ChinaColing 2010 Organizing CommitteeZ. Zhu, D. Bernhard, I. Gurevych, A monolingual tree-based translation model for sentence simplification, in: Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), Coling 2010 Organizing Committee, Beijing, China, 2010, pp. 1353-1361. URL: https://aclanthology.org/C10-1152.\n\nAutomatically neutralizing subjective bias in text. R Pryzant, R D Martinez, N Dass, S Kurohashi, D Jurafsky, D Yang, The Thirty-Second Innovative Applications of Artificial Intelligence Conference. New York, NY, USAAAAI Press2020The Tenth AAAI Symposium on Educational Advances in Artificial IntelligenceR. Pryzant, R. D. Martinez, N. Dass, S. Kurohashi, D. Jurafsky, D. Yang, Automatically neutralizing subjective bias in text, in: The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelli- gence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, AAAI Press, 2020, pp. 480-489. URL: https://aaai.org/ojs/index.php/AAAI/article/view/5385.\n\nAutomated hate speech detection and the problem of offensive language. T Davidson, D Warmsley, M W Macy, I Weber, Proceedings of the Eleventh International Conference on Web and Social Media, ICWSM 2017. the Eleventh International Conference on Web and Social Media, ICWSM 2017Montr\u00e9al, Qu\u00e9bec, CanadaAAAI PressT. Davidson, D. Warmsley, M. W. Macy, I. Weber, Automated hate speech detection and the problem of offensive language, in: Proceedings of the Eleventh International Conference on Web and Social Media, ICWSM 2017, Montr\u00e9al, Qu\u00e9bec, Canada, May 15-18, 2017, AAAI Press, 2017, pp. 512-515. URL: https://aaai.org/ocs/index.php/ICWSM/ICWSM17/ paper/view/15665.\n\nTowards a comprehensive taxonomy and large-scale annotated corpus for online slur usage. J Kurrek, H M Saleem, D Ruths, 10.18653/v1/2020.alw-1.17Proceedings of the Fourth Workshop on Online Abuse and Harms. the Fourth Workshop on Online Abuse and HarmsAssociation for Computational LinguisticsJ. Kurrek, H. M. Saleem, D. Ruths, Towards a comprehensive taxonomy and large-scale annotated corpus for online slur usage, in: Proceedings of the Fourth Workshop on Online Abuse and Harms, Association for Computational Linguistics, Online, 2020, pp. 138-149. URL: https://aclanthology.org/2020.alw-1.17. doi:10.18653/v1/2020.alw-1.17.\n\nS Bagga, A Piper, D Ruths, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeAssociation for Computational Linguisticsare you kidding me?\": Detecting unpalatable questions on RedditS. Bagga, A. Piper, D. Ruths, \"are you kidding me?\": Detecting unpalatable questions on Reddit, in: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Association for Computational Linguistics, Online, 2021, pp. 2083-2099. URL: https://aclanthology.org/2021.eacl-main.179.\n\nBenchmarking aggression identification in social media. R Kumar, A K Ojha, S Malmasi, M Zampieri, Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018). the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018)Santa Fe, New Mexico, USAAssociation for Computational LinguisticsR. Kumar, A. K. Ojha, S. Malmasi, M. Zampieri, Benchmarking aggression identification in social media, in: Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018), Association for Computational Linguistics, Santa Fe, New Mexico, USA, 2018, pp. 1-11. URL: https://aclanthology.org/W18-4401.\n\nY Liu, M Ott, N Goyal, J Du, M Joshi, D Chen, O Levy, M Lewis, L Zettlemoyer, V Stoyanov, arXiv:1907.11692A robustly optimized BERT pretraining approach. RobertaY. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, V. Stoy- anov, Roberta: A robustly optimized BERT pretraining approach, CoRR abs/1907.11692 (2019). URL: http://arxiv.org/abs/1907.11692. arXiv:1907.11692.\n\nMaximum likelihood estimation of observer error-rates using the em algorithm. A P Dawid, A Skene, Journal of The Royal Statistical Society Series C-applied Statistics. 28A. P. Dawid, A. Skene, Maximum likelihood estimation of observer error-rates using the em algorithm, Journal of The Royal Statistical Society Series C-applied Statistics 28 (1979) 20-28.\n\nHatexplain: A benchmark dataset for explainable hate speech detection. B Mathew, P Saha, S M Yimam, C Biemann, P Goyal, A Mukherjee, Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event. AAAI PressB. Mathew, P. Saha, S. M. Yimam, C. Biemann, P. Goyal, A. Mukherjee, Hatexplain: A benchmark dataset for explainable hate speech detection, in: Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021, AAAI Press, 2021, pp. 14867-14875. URL: https://ojs.aaai.org/index.php/AAAI/article/view/17745.\n\nLanguage models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, OpenAI blog. 19A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever, Language models are unsupervised multitask learners, OpenAI blog 1 (2019) 9.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, Journal of Machine Learning Research. 21C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, P. J. Liu, Exploring the limits of transfer learning with a unified text-to-text transformer, Journal of Machine Learning Research 21 (2020) 1-67. URL: http://jmlr.org/papers/v21/20-074.html.\n", "annotations": {"author": "[{\"end\":161,\"start\":84},{\"end\":239,\"start\":162},{\"end\":310,\"start\":240},{\"end\":363,\"start\":311},{\"end\":418,\"start\":364},{\"end\":498,\"start\":419},{\"end\":576,\"start\":499}]", "publisher": null, "author_last_name": "[{\"end\":101,\"start\":91},{\"end\":179,\"start\":169},{\"end\":250,\"start\":246},{\"end\":323,\"start\":316},{\"end\":378,\"start\":371},{\"end\":438,\"start\":429},{\"end\":516,\"start\":507}]", "author_first_name": "[{\"end\":90,\"start\":84},{\"end\":168,\"start\":162},{\"end\":245,\"start\":240},{\"end\":315,\"start\":311},{\"end\":370,\"start\":364},{\"end\":428,\"start\":419},{\"end\":506,\"start\":499}]", "author_affiliation": "[{\"end\":160,\"start\":103},{\"end\":238,\"start\":181},{\"end\":309,\"start\":252},{\"end\":362,\"start\":325},{\"end\":417,\"start\":380},{\"end\":497,\"start\":440},{\"end\":575,\"start\":518}]", "title": "[{\"end\":81,\"start\":1},{\"end\":657,\"start\":577}]", "venue": null, "abstract": "[{\"end\":1367,\"start\":700}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1541,\"start\":1538},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1543,\"start\":1541},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1545,\"start\":1543},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1663,\"start\":1660},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":1665,\"start\":1663},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1682,\"start\":1679},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1684,\"start\":1682},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1686,\"start\":1684},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2325,\"start\":2322},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2328,\"start\":2325},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2331,\"start\":2328},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2394,\"start\":2390},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2801,\"start\":2797},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2804,\"start\":2801},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2823,\"start\":2819},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2826,\"start\":2823},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3032,\"start\":3028},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3035,\"start\":3032},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3237,\"start\":3233},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3539,\"start\":3535},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4686,\"start\":4682},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5348,\"start\":5344},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5430,\"start\":5426},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5433,\"start\":5430},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5436,\"start\":5433},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5933,\"start\":5929},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5978,\"start\":5974},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6014,\"start\":6010},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6207,\"start\":6203},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6330,\"start\":6326},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6481,\"start\":6477},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6679,\"start\":6675},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7238,\"start\":7235},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7241,\"start\":7238},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7243,\"start\":7241},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7256,\"start\":7252},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7259,\"start\":7256},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7274,\"start\":7270},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7368,\"start\":7364},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7371,\"start\":7368},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7374,\"start\":7371},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7394,\"start\":7391},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7494,\"start\":7491},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7622,\"start\":7618},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7624,\"start\":7622},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7715,\"start\":7712},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7717,\"start\":7715},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7806,\"start\":7802},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7854,\"start\":7851},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7879,\"start\":7876},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8325,\"start\":8322},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8445,\"start\":8441},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8627,\"start\":8623},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8808,\"start\":8804},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9258,\"start\":9254},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13023,\"start\":13019},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13068,\"start\":13065},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13133,\"start\":13130},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13677,\"start\":13673},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13680,\"start\":13677},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13683,\"start\":13680},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13793,\"start\":13789},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14464,\"start\":14460},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":19428,\"start\":19425},{\"end\":19432,\"start\":19428},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22718,\"start\":22714},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":23871,\"start\":23867},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25611,\"start\":25607},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":25622,\"start\":25618}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":26752,\"start\":26667},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26814,\"start\":26753},{\"attributes\":{\"id\":\"fig_3\"},\"end\":26878,\"start\":26815},{\"attributes\":{\"id\":\"fig_4\"},\"end\":26937,\"start\":26879},{\"attributes\":{\"id\":\"fig_5\"},\"end\":27005,\"start\":26938},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":27468,\"start\":27006},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":27674,\"start\":27469}]", "paragraph": "[{\"end\":1752,\"start\":1383},{\"end\":2237,\"start\":1754},{\"end\":2827,\"start\":2239},{\"end\":3540,\"start\":2829},{\"end\":3931,\"start\":3542},{\"end\":4125,\"start\":3933},{\"end\":4262,\"start\":4142},{\"end\":5473,\"start\":4290},{\"end\":6547,\"start\":5475},{\"end\":7071,\"start\":6549},{\"end\":7932,\"start\":7093},{\"end\":8946,\"start\":7934},{\"end\":9390,\"start\":8981},{\"end\":9777,\"start\":9392},{\"end\":9978,\"start\":9800},{\"end\":10210,\"start\":9980},{\"end\":10334,\"start\":10212},{\"end\":10451,\"start\":10336},{\"end\":10748,\"start\":10453},{\"end\":11091,\"start\":10750},{\"end\":11567,\"start\":11093},{\"end\":12003,\"start\":11606},{\"end\":12223,\"start\":12030},{\"end\":12397,\"start\":12225},{\"end\":12453,\"start\":12399},{\"end\":12583,\"start\":12455},{\"end\":12801,\"start\":12585},{\"end\":12905,\"start\":12828},{\"end\":13589,\"start\":12928},{\"end\":13973,\"start\":13591},{\"end\":14303,\"start\":13975},{\"end\":14610,\"start\":14327},{\"end\":15086,\"start\":14612},{\"end\":15490,\"start\":15103},{\"end\":16450,\"start\":15514},{\"end\":16761,\"start\":16452},{\"end\":17071,\"start\":16781},{\"end\":17240,\"start\":17073},{\"end\":18153,\"start\":17252},{\"end\":18229,\"start\":18155},{\"end\":18306,\"start\":18231},{\"end\":18380,\"start\":18308},{\"end\":18430,\"start\":18382},{\"end\":18492,\"start\":18432},{\"end\":18556,\"start\":18494},{\"end\":18640,\"start\":18558},{\"end\":18736,\"start\":18642},{\"end\":18914,\"start\":18748},{\"end\":19237,\"start\":18945},{\"end\":20925,\"start\":19257},{\"end\":21820,\"start\":20927},{\"end\":21870,\"start\":21833},{\"end\":22308,\"start\":21872},{\"end\":22408,\"start\":22320},{\"end\":23394,\"start\":22410},{\"end\":23682,\"start\":23424},{\"end\":24457,\"start\":23684},{\"end\":24609,\"start\":24459},{\"end\":24784,\"start\":24611},{\"end\":24887,\"start\":24786},{\"end\":25265,\"start\":24919},{\"end\":25779,\"start\":25267},{\"end\":26198,\"start\":25781},{\"end\":26666,\"start\":26200}]", "formula": null, "table_ref": "[{\"end\":19236,\"start\":19229},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":19340,\"start\":19333},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":20302,\"start\":20295},{\"end\":21336,\"start\":21329}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1381,\"start\":1369},{\"attributes\":{\"n\":\"2.\"},\"end\":4140,\"start\":4128},{\"attributes\":{\"n\":\"2.1.\"},\"end\":4288,\"start\":4265},{\"attributes\":{\"n\":\"2.2.\"},\"end\":7091,\"start\":7074},{\"attributes\":{\"n\":\"3.\"},\"end\":8979,\"start\":8949},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9798,\"start\":9780},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11604,\"start\":11570},{\"attributes\":{\"n\":\"3.3.\"},\"end\":12028,\"start\":12006},{\"attributes\":{\"n\":\"4.\"},\"end\":12826,\"start\":12804},{\"attributes\":{\"n\":\"4.1.\"},\"end\":12926,\"start\":12908},{\"attributes\":{\"n\":\"4.2.\"},\"end\":14325,\"start\":14306},{\"attributes\":{\"n\":\"4.3.\"},\"end\":15101,\"start\":15089},{\"attributes\":{\"n\":\"4.4.\"},\"end\":15512,\"start\":15493},{\"attributes\":{\"n\":\"4.5.\"},\"end\":16779,\"start\":16764},{\"attributes\":{\"n\":\"4.6.\"},\"end\":17250,\"start\":17243},{\"end\":18746,\"start\":18739},{\"attributes\":{\"n\":\"5.\"},\"end\":18943,\"start\":18917},{\"attributes\":{\"n\":\"5.1.\"},\"end\":19255,\"start\":19240},{\"end\":21831,\"start\":21823},{\"end\":22318,\"start\":22311},{\"attributes\":{\"n\":\"5.2.\"},\"end\":23422,\"start\":23397},{\"attributes\":{\"n\":\"6.\"},\"end\":24917,\"start\":24890},{\"end\":26678,\"start\":26668},{\"end\":26764,\"start\":26754},{\"end\":26826,\"start\":26816},{\"end\":26890,\"start\":26880},{\"end\":26949,\"start\":26939},{\"end\":27026,\"start\":27007},{\"end\":27477,\"start\":27470}]", "table": "[{\"end\":27468,\"start\":27103},{\"end\":27674,\"start\":27542}]", "figure_caption": "[{\"end\":26752,\"start\":26680},{\"end\":26814,\"start\":26766},{\"end\":26878,\"start\":26828},{\"end\":26937,\"start\":26892},{\"end\":27005,\"start\":26951},{\"end\":27103,\"start\":27035},{\"end\":27542,\"start\":27479}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9776,\"start\":9768},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9977,\"start\":9967},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":11089,\"start\":11080},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":12002,\"start\":11994},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":12221,\"start\":12213},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18809,\"start\":18801},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19489,\"start\":19481},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":19882,\"start\":19874}]", "bib_author_first_name": "[{\"end\":27789,\"start\":27788},{\"end\":27801,\"start\":27800},{\"end\":27810,\"start\":27809},{\"end\":27823,\"start\":27822},{\"end\":27836,\"start\":27835},{\"end\":27849,\"start\":27848},{\"end\":27860,\"start\":27859},{\"end\":27874,\"start\":27873},{\"end\":27885,\"start\":27884},{\"end\":28647,\"start\":28646},{\"end\":28649,\"start\":28648},{\"end\":28655,\"start\":28654},{\"end\":28665,\"start\":28664},{\"end\":29311,\"start\":29310},{\"end\":29318,\"start\":29317},{\"end\":30000,\"start\":29999},{\"end\":30011,\"start\":30010},{\"end\":30700,\"start\":30699},{\"end\":30711,\"start\":30710},{\"end\":30722,\"start\":30721},{\"end\":30733,\"start\":30732},{\"end\":30742,\"start\":30741},{\"end\":30752,\"start\":30751},{\"end\":31456,\"start\":31455},{\"end\":31466,\"start\":31465},{\"end\":32062,\"start\":32061},{\"end\":32072,\"start\":32071},{\"end\":32081,\"start\":32080},{\"end\":32092,\"start\":32091},{\"end\":32101,\"start\":32100},{\"end\":32110,\"start\":32109},{\"end\":32112,\"start\":32111},{\"end\":32121,\"start\":32120},{\"end\":32130,\"start\":32129},{\"end\":32847,\"start\":32846},{\"end\":32868,\"start\":32867},{\"end\":33495,\"start\":33494},{\"end\":33507,\"start\":33506},{\"end\":33517,\"start\":33516},{\"end\":34291,\"start\":34290},{\"end\":34299,\"start\":34298},{\"end\":34308,\"start\":34307},{\"end\":35097,\"start\":35096},{\"end\":35108,\"start\":35107},{\"end\":35123,\"start\":35122},{\"end\":35135,\"start\":35134},{\"end\":35858,\"start\":35857},{\"end\":35864,\"start\":35863},{\"end\":35871,\"start\":35870},{\"end\":35877,\"start\":35876},{\"end\":36747,\"start\":36746},{\"end\":36757,\"start\":36756},{\"end\":36759,\"start\":36758},{\"end\":36773,\"start\":36772},{\"end\":37479,\"start\":37478},{\"end\":37486,\"start\":37485},{\"end\":38395,\"start\":38394},{\"end\":38422,\"start\":38421},{\"end\":38432,\"start\":38431},{\"end\":38444,\"start\":38443},{\"end\":38456,\"start\":38455},{\"end\":39121,\"start\":39120},{\"end\":39131,\"start\":39130},{\"end\":39141,\"start\":39140},{\"end\":39151,\"start\":39150},{\"end\":39161,\"start\":39160},{\"end\":39171,\"start\":39170},{\"end\":39179,\"start\":39178},{\"end\":39196,\"start\":39195},{\"end\":39198,\"start\":39197},{\"end\":39207,\"start\":39206},{\"end\":39911,\"start\":39910},{\"end\":39922,\"start\":39921},{\"end\":39933,\"start\":39932},{\"end\":40159,\"start\":40158},{\"end\":40173,\"start\":40172},{\"end\":40187,\"start\":40186},{\"end\":40200,\"start\":40199},{\"end\":40202,\"start\":40201},{\"end\":40213,\"start\":40212},{\"end\":40224,\"start\":40223},{\"end\":41289,\"start\":41288},{\"end\":41300,\"start\":41299},{\"end\":41306,\"start\":41305},{\"end\":41315,\"start\":41314},{\"end\":41854,\"start\":41853},{\"end\":41864,\"start\":41863},{\"end\":41876,\"start\":41875},{\"end\":41884,\"start\":41883},{\"end\":42453,\"start\":42452},{\"end\":42455,\"start\":42454},{\"end\":42466,\"start\":42465},{\"end\":42477,\"start\":42476},{\"end\":42493,\"start\":42492},{\"end\":42505,\"start\":42504},{\"end\":42512,\"start\":42511},{\"end\":42524,\"start\":42523},{\"end\":43123,\"start\":43122},{\"end\":43130,\"start\":43129},{\"end\":43142,\"start\":43141},{\"end\":43708,\"start\":43707},{\"end\":43719,\"start\":43718},{\"end\":43721,\"start\":43720},{\"end\":43733,\"start\":43732},{\"end\":43741,\"start\":43740},{\"end\":43754,\"start\":43753},{\"end\":43766,\"start\":43765},{\"end\":44548,\"start\":44547},{\"end\":44560,\"start\":44559},{\"end\":44572,\"start\":44571},{\"end\":44574,\"start\":44573},{\"end\":44582,\"start\":44581},{\"end\":45234,\"start\":45233},{\"end\":45244,\"start\":45243},{\"end\":45246,\"start\":45245},{\"end\":45256,\"start\":45255},{\"end\":45775,\"start\":45774},{\"end\":45784,\"start\":45783},{\"end\":45793,\"start\":45792},{\"end\":46534,\"start\":46533},{\"end\":46543,\"start\":46542},{\"end\":46545,\"start\":46544},{\"end\":46553,\"start\":46552},{\"end\":46564,\"start\":46563},{\"end\":47126,\"start\":47125},{\"end\":47133,\"start\":47132},{\"end\":47140,\"start\":47139},{\"end\":47149,\"start\":47148},{\"end\":47155,\"start\":47154},{\"end\":47164,\"start\":47163},{\"end\":47172,\"start\":47171},{\"end\":47180,\"start\":47179},{\"end\":47189,\"start\":47188},{\"end\":47204,\"start\":47203},{\"end\":47609,\"start\":47608},{\"end\":47611,\"start\":47610},{\"end\":47620,\"start\":47619},{\"end\":47960,\"start\":47959},{\"end\":47970,\"start\":47969},{\"end\":47978,\"start\":47977},{\"end\":47980,\"start\":47979},{\"end\":47989,\"start\":47988},{\"end\":48000,\"start\":47999},{\"end\":48009,\"start\":48008},{\"end\":48864,\"start\":48863},{\"end\":48875,\"start\":48874},{\"end\":48881,\"start\":48880},{\"end\":48890,\"start\":48889},{\"end\":48898,\"start\":48897},{\"end\":48908,\"start\":48907},{\"end\":49160,\"start\":49159},{\"end\":49170,\"start\":49169},{\"end\":49181,\"start\":49180},{\"end\":49192,\"start\":49191},{\"end\":49199,\"start\":49198},{\"end\":49209,\"start\":49208},{\"end\":49219,\"start\":49218},{\"end\":49227,\"start\":49226},{\"end\":49233,\"start\":49232},{\"end\":49235,\"start\":49234}]", "bib_author_last_name": "[{\"end\":27798,\"start\":27790},{\"end\":27807,\"start\":27802},{\"end\":27820,\"start\":27811},{\"end\":27833,\"start\":27824},{\"end\":27846,\"start\":27837},{\"end\":27857,\"start\":27850},{\"end\":27871,\"start\":27861},{\"end\":27882,\"start\":27875},{\"end\":27894,\"start\":27886},{\"end\":28652,\"start\":28650},{\"end\":28662,\"start\":28656},{\"end\":28670,\"start\":28666},{\"end\":29315,\"start\":29312},{\"end\":29327,\"start\":29319},{\"end\":30008,\"start\":30001},{\"end\":30019,\"start\":30012},{\"end\":30708,\"start\":30701},{\"end\":30719,\"start\":30712},{\"end\":30730,\"start\":30723},{\"end\":30739,\"start\":30734},{\"end\":30749,\"start\":30743},{\"end\":30759,\"start\":30753},{\"end\":31463,\"start\":31457},{\"end\":31471,\"start\":31467},{\"end\":32069,\"start\":32063},{\"end\":32078,\"start\":32073},{\"end\":32089,\"start\":32082},{\"end\":32098,\"start\":32093},{\"end\":32107,\"start\":32102},{\"end\":32118,\"start\":32113},{\"end\":32127,\"start\":32122},{\"end\":32142,\"start\":32131},{\"end\":32865,\"start\":32848},{\"end\":32875,\"start\":32869},{\"end\":33504,\"start\":33496},{\"end\":33514,\"start\":33508},{\"end\":33524,\"start\":33518},{\"end\":33531,\"start\":33526},{\"end\":34296,\"start\":34292},{\"end\":34305,\"start\":34300},{\"end\":34318,\"start\":34309},{\"end\":35105,\"start\":35098},{\"end\":35120,\"start\":35109},{\"end\":35132,\"start\":35124},{\"end\":35141,\"start\":35136},{\"end\":35861,\"start\":35859},{\"end\":35868,\"start\":35865},{\"end\":35874,\"start\":35872},{\"end\":35883,\"start\":35878},{\"end\":36754,\"start\":36748},{\"end\":36770,\"start\":36760},{\"end\":36780,\"start\":36774},{\"end\":37483,\"start\":37480},{\"end\":37496,\"start\":37487},{\"end\":38419,\"start\":38396},{\"end\":38429,\"start\":38423},{\"end\":38441,\"start\":38433},{\"end\":38453,\"start\":38445},{\"end\":38462,\"start\":38457},{\"end\":39128,\"start\":39122},{\"end\":39138,\"start\":39132},{\"end\":39148,\"start\":39142},{\"end\":39158,\"start\":39152},{\"end\":39168,\"start\":39162},{\"end\":39176,\"start\":39172},{\"end\":39193,\"start\":39180},{\"end\":39204,\"start\":39199},{\"end\":39218,\"start\":39208},{\"end\":39919,\"start\":39912},{\"end\":39930,\"start\":39923},{\"end\":39942,\"start\":39934},{\"end\":40170,\"start\":40160},{\"end\":40184,\"start\":40174},{\"end\":40197,\"start\":40188},{\"end\":40210,\"start\":40203},{\"end\":40221,\"start\":40214},{\"end\":40234,\"start\":40225},{\"end\":40598,\"start\":40592},{\"end\":40847,\"start\":40841},{\"end\":41070,\"start\":41064},{\"end\":41297,\"start\":41290},{\"end\":41303,\"start\":41301},{\"end\":41312,\"start\":41307},{\"end\":41320,\"start\":41316},{\"end\":41861,\"start\":41855},{\"end\":41873,\"start\":41865},{\"end\":41881,\"start\":41877},{\"end\":41890,\"start\":41885},{\"end\":41897,\"start\":41892},{\"end\":42463,\"start\":42456},{\"end\":42474,\"start\":42467},{\"end\":42490,\"start\":42478},{\"end\":42502,\"start\":42494},{\"end\":42509,\"start\":42506},{\"end\":42521,\"start\":42513},{\"end\":43127,\"start\":43124},{\"end\":43139,\"start\":43131},{\"end\":43151,\"start\":43143},{\"end\":43716,\"start\":43709},{\"end\":43730,\"start\":43722},{\"end\":43738,\"start\":43734},{\"end\":43751,\"start\":43742},{\"end\":43763,\"start\":43755},{\"end\":43771,\"start\":43767},{\"end\":44557,\"start\":44549},{\"end\":44569,\"start\":44561},{\"end\":44579,\"start\":44575},{\"end\":44588,\"start\":44583},{\"end\":45241,\"start\":45235},{\"end\":45253,\"start\":45247},{\"end\":45262,\"start\":45257},{\"end\":45781,\"start\":45776},{\"end\":45790,\"start\":45785},{\"end\":45799,\"start\":45794},{\"end\":46540,\"start\":46535},{\"end\":46550,\"start\":46546},{\"end\":46561,\"start\":46554},{\"end\":46573,\"start\":46565},{\"end\":47130,\"start\":47127},{\"end\":47137,\"start\":47134},{\"end\":47146,\"start\":47141},{\"end\":47152,\"start\":47150},{\"end\":47161,\"start\":47156},{\"end\":47169,\"start\":47165},{\"end\":47177,\"start\":47173},{\"end\":47186,\"start\":47181},{\"end\":47201,\"start\":47190},{\"end\":47213,\"start\":47205},{\"end\":47617,\"start\":47612},{\"end\":47626,\"start\":47621},{\"end\":47967,\"start\":47961},{\"end\":47975,\"start\":47971},{\"end\":47986,\"start\":47981},{\"end\":47997,\"start\":47990},{\"end\":48006,\"start\":48001},{\"end\":48019,\"start\":48010},{\"end\":48872,\"start\":48865},{\"end\":48878,\"start\":48876},{\"end\":48887,\"start\":48882},{\"end\":48895,\"start\":48891},{\"end\":48905,\"start\":48899},{\"end\":48918,\"start\":48909},{\"end\":49167,\"start\":49161},{\"end\":49178,\"start\":49171},{\"end\":49189,\"start\":49182},{\"end\":49196,\"start\":49193},{\"end\":49206,\"start\":49200},{\"end\":49216,\"start\":49210},{\"end\":49224,\"start\":49220},{\"end\":49230,\"start\":49228},{\"end\":49239,\"start\":49236}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":219635956},\"end\":28569,\"start\":27702},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":208157933},\"end\":29249,\"start\":28571},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.622\",\"id\":\"b2\",\"matched_paper_id\":236941247},\"end\":29928,\"start\":29251},{\"attributes\":{\"doi\":\"10.18653/v1/W17-1101\",\"id\":\"b3\",\"matched_paper_id\":9626793},\"end\":30609,\"start\":29930},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":232345006},\"end\":31360,\"start\":30611},{\"attributes\":{\"doi\":\"10.18653/v1/N16-2013\",\"id\":\"b5\",\"matched_paper_id\":1721388},\"end\":31959,\"start\":31362},{\"attributes\":{\"doi\":\"10.18653/v1/S19-2007\",\"id\":\"b6\",\"matched_paper_id\":184483123},\"end\":32785,\"start\":31961},{\"attributes\":{\"doi\":\"10.18653/v1/W19-3501\",\"id\":\"b7\",\"matched_paper_id\":203447304},\"end\":33409,\"start\":32787},{\"attributes\":{\"doi\":\"10.18653/v1/P18-2031\",\"id\":\"b8\",\"matched_paper_id\":29165442},\"end\":34185,\"start\":33411},{\"attributes\":{\"doi\":\"10.18653/v1/2020.coling-main.190\",\"id\":\"b9\",\"matched_paper_id\":226227404},\"end\":35028,\"start\":34187},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":231861515},\"end\":35776,\"start\":35030},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1169\",\"id\":\"b11\",\"matched_paper_id\":4937880},\"end\":36676,\"start\":35778},{\"attributes\":{\"doi\":\"10.18653/v1/K19-1078\",\"id\":\"b12\",\"matched_paper_id\":209076846},\"end\":37361,\"start\":36678},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1012\",\"id\":\"b13\",\"matched_paper_id\":4859003},\"end\":38317,\"start\":37363},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":12383721},\"end\":39068,\"start\":38319},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.169\",\"id\":\"b15\",\"matched_paper_id\":215811473},\"end\":39860,\"start\":39070},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":21186239},\"end\":40094,\"start\":39862},{\"attributes\":{\"doi\":\"doi:99.9999\",\"id\":\"b17\",\"matched_paper_id\":234777967},\"end\":40588,\"start\":40096},{\"attributes\":{\"id\":\"b18\"},\"end\":40788,\"start\":40590},{\"attributes\":{\"id\":\"b19\"},\"end\":41012,\"start\":40790},{\"attributes\":{\"id\":\"b20\"},\"end\":41233,\"start\":41014},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.428\",\"id\":\"b21\",\"matched_paper_id\":216867622},\"end\":41803,\"start\":41235},{\"attributes\":{\"doi\":\"10.18653/v1/W17-4508\",\"id\":\"b22\",\"matched_paper_id\":2204603},\"end\":42399,\"start\":41805},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":6203757},\"end\":43048,\"start\":42401},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":15636533},\"end\":43653,\"start\":43050},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":208248333},\"end\":44474,\"start\":43655},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":1733167},\"end\":45142,\"start\":44476},{\"attributes\":{\"doi\":\"10.18653/v1/2020.alw-1.17\",\"id\":\"b27\",\"matched_paper_id\":226283752},\"end\":45772,\"start\":45144},{\"attributes\":{\"id\":\"b28\"},\"end\":46475,\"start\":45774},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":59336626},\"end\":47123,\"start\":46477},{\"attributes\":{\"doi\":\"arXiv:1907.11692\",\"id\":\"b30\"},\"end\":47528,\"start\":47125},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":45813168},\"end\":47886,\"start\":47530},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":229332119},\"end\":48808,\"start\":47888},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":160025533},\"end\":49074,\"start\":48810},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":204838007},\"end\":49553,\"start\":49076}]", "bib_title": "[{\"end\":27786,\"start\":27702},{\"end\":28644,\"start\":28571},{\"end\":29308,\"start\":29251},{\"end\":29997,\"start\":29930},{\"end\":30697,\"start\":30611},{\"end\":31453,\"start\":31362},{\"end\":32059,\"start\":31961},{\"end\":32844,\"start\":32787},{\"end\":33492,\"start\":33411},{\"end\":34288,\"start\":34187},{\"end\":35094,\"start\":35030},{\"end\":35855,\"start\":35778},{\"end\":36744,\"start\":36678},{\"end\":37476,\"start\":37363},{\"end\":38392,\"start\":38319},{\"end\":39118,\"start\":39070},{\"end\":39908,\"start\":39862},{\"end\":40156,\"start\":40096},{\"end\":41286,\"start\":41235},{\"end\":41851,\"start\":41805},{\"end\":42450,\"start\":42401},{\"end\":43120,\"start\":43050},{\"end\":43705,\"start\":43655},{\"end\":44545,\"start\":44476},{\"end\":45231,\"start\":45144},{\"end\":46531,\"start\":46477},{\"end\":47606,\"start\":47530},{\"end\":47957,\"start\":47888},{\"end\":48861,\"start\":48810},{\"end\":49157,\"start\":49076}]", "bib_author": "[{\"end\":27800,\"start\":27788},{\"end\":27809,\"start\":27800},{\"end\":27822,\"start\":27809},{\"end\":27835,\"start\":27822},{\"end\":27848,\"start\":27835},{\"end\":27859,\"start\":27848},{\"end\":27873,\"start\":27859},{\"end\":27884,\"start\":27873},{\"end\":27896,\"start\":27884},{\"end\":28654,\"start\":28646},{\"end\":28664,\"start\":28654},{\"end\":28672,\"start\":28664},{\"end\":29317,\"start\":29310},{\"end\":29329,\"start\":29317},{\"end\":30010,\"start\":29999},{\"end\":30021,\"start\":30010},{\"end\":30710,\"start\":30699},{\"end\":30721,\"start\":30710},{\"end\":30732,\"start\":30721},{\"end\":30741,\"start\":30732},{\"end\":30751,\"start\":30741},{\"end\":30761,\"start\":30751},{\"end\":31465,\"start\":31455},{\"end\":31473,\"start\":31465},{\"end\":32071,\"start\":32061},{\"end\":32080,\"start\":32071},{\"end\":32091,\"start\":32080},{\"end\":32100,\"start\":32091},{\"end\":32109,\"start\":32100},{\"end\":32120,\"start\":32109},{\"end\":32129,\"start\":32120},{\"end\":32144,\"start\":32129},{\"end\":32867,\"start\":32846},{\"end\":32877,\"start\":32867},{\"end\":33506,\"start\":33494},{\"end\":33516,\"start\":33506},{\"end\":33526,\"start\":33516},{\"end\":33533,\"start\":33526},{\"end\":34298,\"start\":34290},{\"end\":34307,\"start\":34298},{\"end\":34320,\"start\":34307},{\"end\":35107,\"start\":35096},{\"end\":35122,\"start\":35107},{\"end\":35134,\"start\":35122},{\"end\":35143,\"start\":35134},{\"end\":35863,\"start\":35857},{\"end\":35870,\"start\":35863},{\"end\":35876,\"start\":35870},{\"end\":35885,\"start\":35876},{\"end\":36756,\"start\":36746},{\"end\":36772,\"start\":36756},{\"end\":36782,\"start\":36772},{\"end\":37485,\"start\":37478},{\"end\":37498,\"start\":37485},{\"end\":38421,\"start\":38394},{\"end\":38431,\"start\":38421},{\"end\":38443,\"start\":38431},{\"end\":38455,\"start\":38443},{\"end\":38464,\"start\":38455},{\"end\":39130,\"start\":39120},{\"end\":39140,\"start\":39130},{\"end\":39150,\"start\":39140},{\"end\":39160,\"start\":39150},{\"end\":39170,\"start\":39160},{\"end\":39178,\"start\":39170},{\"end\":39195,\"start\":39178},{\"end\":39206,\"start\":39195},{\"end\":39220,\"start\":39206},{\"end\":39921,\"start\":39910},{\"end\":39932,\"start\":39921},{\"end\":39944,\"start\":39932},{\"end\":40172,\"start\":40158},{\"end\":40186,\"start\":40172},{\"end\":40199,\"start\":40186},{\"end\":40212,\"start\":40199},{\"end\":40223,\"start\":40212},{\"end\":40236,\"start\":40223},{\"end\":40600,\"start\":40592},{\"end\":40849,\"start\":40841},{\"end\":41072,\"start\":41064},{\"end\":41299,\"start\":41288},{\"end\":41305,\"start\":41299},{\"end\":41314,\"start\":41305},{\"end\":41322,\"start\":41314},{\"end\":41863,\"start\":41853},{\"end\":41875,\"start\":41863},{\"end\":41883,\"start\":41875},{\"end\":41892,\"start\":41883},{\"end\":41899,\"start\":41892},{\"end\":42465,\"start\":42452},{\"end\":42476,\"start\":42465},{\"end\":42492,\"start\":42476},{\"end\":42504,\"start\":42492},{\"end\":42511,\"start\":42504},{\"end\":42523,\"start\":42511},{\"end\":42527,\"start\":42523},{\"end\":43129,\"start\":43122},{\"end\":43141,\"start\":43129},{\"end\":43153,\"start\":43141},{\"end\":43718,\"start\":43707},{\"end\":43732,\"start\":43718},{\"end\":43740,\"start\":43732},{\"end\":43753,\"start\":43740},{\"end\":43765,\"start\":43753},{\"end\":43773,\"start\":43765},{\"end\":44559,\"start\":44547},{\"end\":44571,\"start\":44559},{\"end\":44581,\"start\":44571},{\"end\":44590,\"start\":44581},{\"end\":45243,\"start\":45233},{\"end\":45255,\"start\":45243},{\"end\":45264,\"start\":45255},{\"end\":45783,\"start\":45774},{\"end\":45792,\"start\":45783},{\"end\":45801,\"start\":45792},{\"end\":46542,\"start\":46533},{\"end\":46552,\"start\":46542},{\"end\":46563,\"start\":46552},{\"end\":46575,\"start\":46563},{\"end\":47132,\"start\":47125},{\"end\":47139,\"start\":47132},{\"end\":47148,\"start\":47139},{\"end\":47154,\"start\":47148},{\"end\":47163,\"start\":47154},{\"end\":47171,\"start\":47163},{\"end\":47179,\"start\":47171},{\"end\":47188,\"start\":47179},{\"end\":47203,\"start\":47188},{\"end\":47215,\"start\":47203},{\"end\":47619,\"start\":47608},{\"end\":47628,\"start\":47619},{\"end\":47969,\"start\":47959},{\"end\":47977,\"start\":47969},{\"end\":47988,\"start\":47977},{\"end\":47999,\"start\":47988},{\"end\":48008,\"start\":47999},{\"end\":48021,\"start\":48008},{\"end\":48874,\"start\":48863},{\"end\":48880,\"start\":48874},{\"end\":48889,\"start\":48880},{\"end\":48897,\"start\":48889},{\"end\":48907,\"start\":48897},{\"end\":48920,\"start\":48907},{\"end\":49169,\"start\":49159},{\"end\":49180,\"start\":49169},{\"end\":49191,\"start\":49180},{\"end\":49198,\"start\":49191},{\"end\":49208,\"start\":49198},{\"end\":49218,\"start\":49208},{\"end\":49226,\"start\":49218},{\"end\":49232,\"start\":49226},{\"end\":49241,\"start\":49232}]", "bib_venue": "[{\"end\":28012,\"start\":27896},{\"end\":28796,\"start\":28672},{\"end\":29454,\"start\":29360},{\"end\":30136,\"start\":30041},{\"end\":30857,\"start\":30761},{\"end\":31543,\"start\":31493},{\"end\":32233,\"start\":32164},{\"end\":33000,\"start\":32897},{\"end\":33640,\"start\":33553},{\"end\":34483,\"start\":34352},{\"end\":35263,\"start\":35143},{\"end\":36047,\"start\":35905},{\"end\":36887,\"start\":36802},{\"end\":37660,\"start\":37518},{\"end\":38551,\"start\":38464},{\"end\":39336,\"start\":39249},{\"end\":39970,\"start\":39944},{\"end\":40290,\"start\":40247},{\"end\":40638,\"start\":40600},{\"end\":40839,\"start\":40790},{\"end\":41062,\"start\":41014},{\"end\":41426,\"start\":41357},{\"end\":41980,\"start\":41919},{\"end\":42576,\"start\":42527},{\"end\":43230,\"start\":43153},{\"end\":43852,\"start\":43773},{\"end\":44678,\"start\":44590},{\"end\":45349,\"start\":45289},{\"end\":45921,\"start\":45801},{\"end\":46662,\"start\":46575},{\"end\":47277,\"start\":47231},{\"end\":47696,\"start\":47628},{\"end\":48278,\"start\":48021},{\"end\":48931,\"start\":48920},{\"end\":49277,\"start\":49241},{\"end\":28124,\"start\":28014},{\"end\":28924,\"start\":28798},{\"end\":29535,\"start\":29456},{\"end\":30233,\"start\":30138},{\"end\":30940,\"start\":30859},{\"end\":31601,\"start\":31545},{\"end\":32316,\"start\":32235},{\"end\":33105,\"start\":33002},{\"end\":33734,\"start\":33642},{\"end\":34617,\"start\":34485},{\"end\":35370,\"start\":35265},{\"end\":36198,\"start\":36049},{\"end\":36975,\"start\":36889},{\"end\":37811,\"start\":37662},{\"end\":38640,\"start\":38553},{\"end\":39410,\"start\":39338},{\"end\":40334,\"start\":40292},{\"end\":42047,\"start\":41982},{\"end\":43308,\"start\":43232},{\"end\":43871,\"start\":43854},{\"end\":44777,\"start\":44680},{\"end\":45396,\"start\":45351},{\"end\":46028,\"start\":45923},{\"end\":46761,\"start\":46664},{\"end\":47286,\"start\":47279}]"}}}, "year": 2023, "month": 12, "day": 17}