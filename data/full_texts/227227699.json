{"id": 227227699, "updated": "2023-10-06 08:18:53.269", "metadata": {"title": "NeuralFusion: Online Depth Fusion in Latent Space", "authors": "[{\"first\":\"Silvan\",\"last\":\"Weder\",\"middle\":[]},{\"first\":\"Johannes\",\"last\":\"Schonberger\",\"middle\":[\"L.\"]},{\"first\":\"Marc\",\"last\":\"Pollefeys\",\"middle\":[]},{\"first\":\"Martin\",\"last\":\"Oswald\",\"middle\":[\"R.\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 11, "day": 30}, "abstract": "We present a novel online depth map fusion approach that learns depth map aggregation in a latent feature space. While previous fusion methods use an explicit scene representation like signed distance functions (SDFs), we propose a learned feature representation for the fusion. The key idea is a separation between the scene representation used for the fusion and the output scene representation, via an additional translator network. Our neural network architecture consists of two main parts: a depth and feature fusion sub-network, which is followed by a translator sub-network to produce the final surface representation (e.g. TSDF) for visualization or other tasks. Our approach is an online process, handles high noise levels, and is particularly able to deal with gross outliers common for photometric stereo-based depth maps. Experiments on real and synthetic data demonstrate improved results compared to the state of the art, especially in challenging scenarios with large amounts of noise and outliers.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2011.14791", "mag": "3107860744", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/WederSPO21", "doi": "10.1109/cvpr46437.2021.00318"}}, "content": {"source": {"pdf_hash": "a3f51c88131ad41971f60dae71e7811dc51b0b87", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2011.14791v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "https://arxiv.org/pdf/2011.14791", "status": "GREEN"}}, "grobid": {"id": "6116570b82680615db83d31ee45e1773c212bd61", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/a3f51c88131ad41971f60dae71e7811dc51b0b87.txt", "contents": "\nNeuralFusion: Online Depth Fusion in Latent Space\n\n\nSilvan Weder \nDepartment of Computer Science\nETH Zurich\n\nJohannes L Sch\u00f6nberger \nMicrosoft Mixed Reality and AI Zurich Lab\n\n\nMarc Pollefeys \nDepartment of Computer Science\nETH Zurich\n\nMicrosoft Mixed Reality and AI Zurich Lab\n\n\nMartin R Oswald \nDepartment of Computer Science\nETH Zurich\n\nNeuralFusion: Online Depth Fusion in Latent Space\n012984711A8E2FA26B4ADEF9ED8D5082\nWe present a novel online depth map fusion approach that learns depth map aggregation in a latent feature space.While previous fusion methods use an explicit scene representation like signed distance functions (SDFs), we propose a learned feature representation for the fusion.The key idea is a separation between the scene representation used for the fusion and the output scene representation, via an additional translator network.Our neural network architecture consists of two main parts: a depth and feature fusion subnetwork, which is followed by a translator sub-network to produce the final surface representation (e.g.TSDF) for visualization or other tasks.Our approach is an online process, handles high noise levels, and is particularly able to deal with gross outliers common for photometric stereobased depth maps.Experiments on real and synthetic data demonstrate improved results compared to the state of the art, especially in challenging scenarios with large amounts of noise and outliers.The source code will be made available at https://github.com/weders/NeuralFusion.\n\nIntroduction\n\nReconstructing the geometry of a scene is a central component of many applications in 3D computer vision.Awareness of the surrounding geometry enables robots to navigate, augmented and mixed reality devices to accurately project the information into the user's field of view, and serves as the basis for many 3D scene understanding tasks.\n\nIn this paper, we consider online surface reconstruction by fusing a stream of depth maps with known camera calibration.The fundamental challenge in this task is that depth maps are typically noisy, incomplete, and contain outliers.Depth map fusion is a key component in many 3D reconstruction methods, like KinectFusion [40], VoxelHashing [42], InfiniTAM [23], and many others.The vast majority of methods builds upon the concept of averaging truncated signed distance functions (TSDFs), as proposed in the pioneering work by Curless and Levoy [9].This approach is so popular due to its simple, highly parallelizable, and real-time capable TSDF Fusion [9] RoutedFusion [63] Ours\n\nFigure 1.Results of our end-to-end depth fusion on real-world MVS data [29].Our method learns to separate outliers and true geometry without the need of filtering heuristics.\n\nway of fusing noisy depth maps into a surface.However, it has difficulties with handling outliers and thin geometry, which can be mainly attributed to the local integration of depth values in the TSDF volume.\n\nTo tackle this fundamental limitation, existing methods use various heuristics to filter outliers in decoupled pre-or post-processing steps.Such filtering techniques entail the usual trade-off in terms of balancing accuracy against completeness.Especially in an online fusion system, striking this balance is extremely challenging in the pre-filtering stage, because it is difficult to distinguish between a first surface measurement and an outlier.Consequently, to achieve complete surface reconstructions, one must use conservative pre-filtering, which in turn requires careful post-filtering of outliers by non-local reasoning on the TSDF volume or the final mesh.This motivates our key idea to use different scene representations for the fusion and final method output, while all prior works perform depth fusion and filtering directly in the output representation.In contrast, we perform the fusion step in a latent scene representation, implicitly learned to encode features like confidence information or local scene information.A final translation step simultaneously filters and decodes this learned scene representation into the final output relevant to downstream applications.\n\n\narXiv:2011.14791v2 [cs.CV] 8 Jun 2021\n\nIn summary, we make the following contributions:\n\n\u2022 We propose a novel, end-to-end trainable network architecture, which separates the scene representations for depth fusion and the final output into two different modules.\n\n\u2022 The proposed latent representation yields more accurate and complete fusion results for larger feature dimensions allowing to balance accuracy against resource demands.\n\n\u2022 Our network architecture allows for end-to-end learnable outlier filtering within a translation step that significantly improves outlier handling.\n\n\u2022 Although fully trainable, our approach still only performs very localized updates to the global map which maintains the online capability of the overall approach.\n\n\nRelated Work\n\nRepresentation Learning for 3D Reconstruction.Many works proposed learning-based algorithms using implicit shape representations.Ladicky et al. [31] learn to regress a mesh from a point cloud using a random forest.The concurrent works OccupancyNetworks [38], DeepSDF [43], and IM-NET [5] encode the object surface as the decision boundary of a trained classification or regression network.These methods only use a single feature vector to encode an entire scene or object within a unit cube and are, unlike our approach, not suitable for large-scale scenes.This was improved in [3,7,21,45] which use multiple features to encode parts of the scene.[8,19,25,50,51] extract image features and learn scene occupancy labels from single or multi-view images.DISN [66] works in a similar fashion but regresses SDF values.Chiyu et al. [22] propose a local implicit grid representation for 3D scenes.However, they encode the scene through direct optimization of the latent representation through a pre-trained neural network.More recently, Scene Representation Networks [58] learn to reconstruct novel views from a single RGB image.Liu et al. [33] learn implicit 3D shapes from 2D images in a self-supervised manner.These works also operate within a unit cube and are difficult to scale to larger scenes.DeepVoxels [57] encodes visual information in a feature grid with a neural network to generate novel, high-quality views onto an observed object.Nevertheless, the work is not directly applicable to a 3D reconstruction task.Our method combines the concept of learned scene representations with data fusion in a learned latent space.Recently, several works proposed a more local scene representation [1,15,16] that allows larger scale scenes and multiple objects.Further, [34,41] learn implicit representations with 2D supervision via differentiable rendering.Overall, none of all mentioned works consider online updates of the shape representation as new information becomes available and adding such functionality is by no means straightforward.\n\nClassic Online Depth Fusion Approaches.The majority of depth map fusion approaches are built upon the seminal \"TSDF Fusion\" work by Curless and Levoy [9], which fuses depth maps using an implicit representation by averaging TSDFs on a dense voxel grid.This approach especially became popular with the wide availability of lowcost depth sensors like the Kinect and has led to works like KinectFusion [40] and related works like sparse-sequence fusion [67], BundleFusion [12], or variants on sparse grids like VoxelHashing [42], InfiniTAM [46], Voxgraph [47], octree-based approaches [14,35,60], or hierarchical hashing [24].However, the output of these methods usually contains typical noise artifacts, such as surface thickening and outlier blobs.Another line of works uses a surfel-based representation and directly fuses depth values into a sparse point cloud [27,32,36,56,61,64].This representation perfectly adapts to inhomogeneous sampling densities, requires low memory storage, but also lacks connectivity and topological surface information.An overview of depth fusion approaches is given in [74].\n\nClassic Global Depth Fusion Approaches.While online approaches only process one depth map at a time, global approaches use all information at once and typically apply additional smoothness priors like total variation [30,68], its variants including semantic information [6,17,18,52,53], or refine surface details using color information [73].Consequently, their high compute and memory requirements prevent their application in online scenarios unlike ours.Learned Global Depth Fusion Approaches.Octnet [49] and its follow-up OctnetFusion [48] fuse depth maps using TSDF fusion into an octree and then post-processes the fused geometry using machine learning.RayNet [44] uses a learned Markov random field and a view-invariant feature representation to model view dependencies.SurfaceNet [20] jointly estimates multi-view stereo depth maps and the fused geometry, but requires to store a volumetric grid for each input depth map.3DMV [11] optimizes shape and semantics of a pre-fused TSDF scene of given 2D view information.Contrary to these methods, we learn online depth fusion and can process an arbitrary number of input views.Learned Online Depth Fusion Approaches.\n\nIn the context of simultaneous localization and mapping, CodeSLAM [2], SceneCode [70] and DeepFactors [10] learn a 2.5D depth representation and its probabilistic fusion rather than fusing into a full 3D model.The DeepTAM [71] mapping algorithm builds upon traditional cost volume computation with hand-crafted photoconsistency measures, which are fed into a neural network to estimate depth, but full 3D model fusion is not considered.DeFuSR [13] refines depth maps by improving cross-view consistency via reprojection, but it is not real-time capable.Similar to our approach, Weder et al. [63] perform online reconstruction and learn the fusion updates and weights.In contrast to our work, all information is fused into an SDF representation which requires handcrafted pre-or post-filtering to handle outliers, which is not end-to-end trainable.The recent ATLAS [39] method fuses features from RGB input into a voxel grid and then regresses a TSDF volume.While our method learns the fusion of features, they use simple weighted averaging.Their large ResNet50 backbone limits real-time capabilities.Sequence to Vector Learning.\n\nOn a high-level, our method processes a variable length sequence of depth maps and learns a 3D shape represented by a fixed length vector.It is thus loosely related to areas like video representation learning [59] or sentiment analysis [37,69] which processes text, audio or video to estimate a single vectorial value.In contrast to these works, we process 3D data and explicitly model spatial geometric relationships.\n\n\nMethod\n\nOverview.Given a stream of input depth maps D t : R 2 \u2192 R with known camera calibration for each time step t \u2208 N, we aim to fuse all surface information into a globally consistent scene representation g : R 3 \u2192 R N while removing noise and outliers as well as complete potentially missing observations.The final output of our method is a TSDF map s : R 3 \u2192 R, which can be processed into a mesh with standard iso-surface extraction methods as well as an occupancy map o : R 3 \u2192 [0, 1]. Figure 2 provides an overview of our method.The key idea is to decouple the scene representation for geometry fusion from the output scene representation.This decoupling is motivated by the difficulty for existing methods to handle outliers within an online fusion method.Therefore, we propose to fuse geometric information into a latent feature space without any preliminary outlier prefiltering.A subsequent translator network then decodes the latent feature space into the output scene representation (e.g., a TSDF grid).This approach allows for better and end-toend trainable handling of outliers and avoids any handcrafted post-filtering, which is inherently difficult to tune and typically decreases the completeness of the reconstruction.Furthermore, the learned latent representation also enables to capture complex and higher resolution shape information, leading to more accurate reconstruction results.\n\nOur feature fusion pipeline consists of four key stages depicted as networks in Figure 2. The first stage extracts the current state of the global feature volume into a local, view-aligned feature volume using an affine mapping defined by the given camera parameters.After the extraction, this local feature volume is passed together with the new depth measurement and the ray directions through a feature fusion network.This feature fusion network predicts optimal updates for the local feature volume, given the new measurement and its old state.The updates are integrated back into the global feature volume using the inverse affine mapping defined in the first stage.These three stages form the core of the fusion pipeline and are executed iteratively on the input depth map stream.An additional fourth stage translates the feature volume into an application-specific scene representation, such as a TSDF volume, from which one can finally render a mesh for visualization.We detail our pipeline in the following and we refer to the supplementary material for additional low-level architectural details.Feature Extraction.The goal of iteratively fusing depth measurements is to (a) fuse information about previously unknown geometry, (b) increase the confidence about already fused geometry, and (c) to correct wrong or erroneous entries in the scene.Towards these goals, the fusion process takes the new measurements to update the previous scene state g t\u22121 , which encodes all previously seen geometry.For a fast depth integration, we extract a local view-aligned feature subvolume v t\u22121 with one ray per depth measurement centered at the measured depth via nearest neighbor search in the grid positions.Each ray of features in the local feature volume is concatenated with the ray direction and the new depth measurement.This feature volume is then passed to the fusion network.Feature Fusion.The fusion network fuses the new depth measurements D t into the existing local feature representation v t\u22121 .Therefore, we pass the feature volume through four convolutional blocks to encode neighborhood information from a larger receptive field.Each of these encoding blocks, consists of two convolutional layers with a kernel size of three.These layers are followed by layer normalization and tanh activation function.We found layer normalization to be crucial for training convergence.The output of each block is concatenated with its input, thereby generating a successively larger feature volume with increasing receptive field.The decoder then takes the output of the four encoding blocks to predict feature updates.The decoder consists of four blocks with two convolutional layers and interleaved layer normalization and tanh activation.The output of the final layer is passed through a single linear layer.Finally, the predicted feature updates are normalized and passed as v t to the feature integration.Feature Integration.The updated feature state is integrated back into the global feature grid by using the inverse global-local grid correspondences of the extraction mapping.Similar to the extraction, we write the mapped features into the nearest neighbor grid location.Since this mapping is not unique, we aggregate colliding updates using an average pooling operation.Finally, the pooled features are combined with old ones using a per-voxel running average operation, where we use the update counts as weights.This residual update operation ensures stable training and a homogeneous latent space, as compared to direct prediction of the global features.Both the feature extraction and integration steps are inspired by [63], but they use tri-linear interpolation instead of nearest-neighbor sampling.When extracting and integrat-                .Proposed online reconstruction approach.Our pipeline consists of two main parts: 1) A fusion network with its extraction and integration layers, and 2) A translator network that translates the feature representation into an interpretable TSDF representation.For any new depth map D t a local, view-aligned feature grid v t\u22121 is extracted from the previous global feature grid g t\u22121 .The fusion network updates the local feature grid v t which is then integrated back into an updated global feature grid g t .The translator network is independent of the fusion process and can be used asynchronously for an efficient fusion process.\nI 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 u V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 O B k J z h n J i C W V a 2 F s J G 1 F N G d q E S j Y E b / n l V d K 6I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 u V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 O B k J z h n J i C W V a 2 F s J G 1 F N G d q E S j Y E b / n l V d K 6I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 u V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 O B k J z h n J i C W V a 2 F s J G 1 F N G d q E S j Y E b / n l V d K 6I 5 G v / z V G 8 Q s j b h C J q k x X c 9 N 0 M + o R s E k n 5 Z 6 q e E J Z W M 6 5 F 1 L F Y 2 4 8 b P 5 u V N y Z p U B C W N t S y G Z q 7 8 n M h o Z M 4 k C 2 x l R H J l l b y b + 5 3 V T D K / 9 T K g k R a 7 Y Y l G Y S o I x m f 1 O B k J z h n J i C W V a 2 F s J G 1 F N G d q E S j Y E b / n l V d K 6 r H p u 1 b u v V e o 3 e R x F O I F T O A c P r q A O d 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P 2 2 o 9 P < / l a t e x i t > D t < l a t e x i t s h a 1 _ b a s e 6 4 = \" G f P o x A / / r V r k y a n f z m a v 7 q 1 6 p Q w = \" > A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i z q w W M F 0 x b a W D b b T b t 0 s w m 7 E 6 G E / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T K U w 6 L r f z s r q 2 v r G Z m m r v L 2 z u 7 d f O T h s m i T T j P s s k Y l u h 9 R w K R T 3 U a D k 7 V R z G o e S t 8 L R z d R v P X F t R K I e c J z y I K Y D J S L B K F r J v 3 3 M c d K r V N 2 a O w N Z J l 5 B q l C g 0 a t 8 d f s J y 2 K u k E l q T M d z U w x y q l E w y S f l b m Z 4 S t m I D n j H U k V j b o J 8 d u y E n F q l T 6 J E 2 1 J I Z u r v i Z z G x o z j 0 H b G F I d m 0 Z u K / 3 m d D K O r I B c q z Z A r N l 8 U Z Z J g Q q a f k 7 7 Q n K E c W 0 K Z F v Z W w o Z U U 4 Yf P o x A / / r V r k y a n f z m a v 7 q 1 6 p Q w = \" > A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i z q w W M F 0 x b a W D b b T b t 0 s w m 7 E 6 G E / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T K U w 6 L r f z s r q 2 v r G Z m m r v L 2 z u 7 d f O T h s m i T T j P s s k Y l u h 9 R w K R T 3 U a D k 7 V R z G o e S t 8 L R z d R v P X F t R K I e c J z y I K Y D J S L B K F r J v 3 3 M c d K r V N 2 a O w N Z J l 5 B q l C g 0 a t 8 d f s J y 2 K u k E l q T M d z U w x y q l E w y S f l b m Z 4 S t m I D n j H U k V j b o J 8 d u y E n F q l T 6 J E 2 1 J I Z u r v i Z z G x o z j 0 H b G F I d m 0 Z u K / 3 m d D K O r I B c q z Z A r N l 8 U Z Z J g Q q a f k 7 7 Q n K E c W 0 K Z F v Z W w o Z U U 4 Yf P o x A / / r V r k y a n f z m a v 7 q 1 6 p Q w = \" > A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i z q w W M F 0 x b a W D b b T b t 0 s w m 7 E 6 G E / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T K U w 6 L r f z s r q 2 v r G Z m m r v L 2 z u 7 d f O T h s m i T T j P s s k Y l u h 9 R w K R T 3 U a D k 7 V R z G o e S t 8 L R z d R v P X F t R K I e c J z y I K Y D J S L B K F r J v 3 3 M c d K r V N 2 a O w N Z J l 5 B q l C g 0 a t 8 d f s J y 2 K u k E l q T M d z U w x y q l E w y S f l b m Z 4 S t m I D n j H U k V j b o J 8 d u y E n F q l T 6 J E 2 1 J I Z u r v i Z z G x o z j 0 H b G F I d m 0 Z u K / 3 m d D K O r I B c q z Z A r N l 8 U Z Z J g Q q a f k 7 7 Q n K E c W 0 K Z F v Z W w o Z U U 4 Yf P o x A / / r V r k y a n f z m a v 7 q 1 6 p Q w = \" > A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k I e i z q w W M F 0 x b a W D b b T b t 0 s w m 7 E 6 G E / g Y v H h T x 6 g / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v T K U w 6 L r f z s r q 2 v r G Z m m r v L 2 z u 7 d f O T h s m i T T j P s s k Y l u h 9 R w K R T 3 U a D k 7 V R z G o e S t 8 L R z d R v P X F t R K I e c J z y I K Y D J S L B K F r J v 3 3 M c d K r V N 2 a O w N Z J l 5 B q l C g 0 a t 8 d f s J y 2 K u k E l q T M d z U w x y q l E w y S f l b m Z 4 S t m I D n j H U k V j b o J 8 d u y E n F q l T 6 J E 2 1 J I Z u r v i Z z G x o z j 0 H b G F I d m 0 Z u K / 3 m d D K O r I B c q z Z A r N l 8 U Z Z J g Q q a f k 7 7 Q n K E c W 0 K Z F v Z W w o Z U U 4 YU c o t q p X y w = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y U R Q Y 9 F P X i s Y D + g j W W z 3 b R L N 5 u w O x F K 6 I / w 4 k E R r / 4 e b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k Q K g 6 7 7 7 R R W V t f W N 4 q b p a 3 t n d 2 9 8 v 5 B 0 8 S p Z r z B Y h n r d k A N l 0 L x B g q U v J 1 o T q N A 8 l Y w u p n 6 r S e u j Y j V A 4 4 T 7 k d 0 o E Q o G E U r t W 4 f M z z z J r 1 y x a 2 6 M 5 B l 4 u W k A j n q v f J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L q p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I i V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t k Q v M W X l 0 n z v O q 5 V e / +U c o t q p X y w = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y U R Q Y 9 F P X i s Y D + g j W W z 3 b R L N 5 u w O x F K 6 I / w 4 k E R r / 4 e b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k Q K g 6 7 7 7 R R W V t f W N 4 q b p a 3 t n d 2 9 8 v 5 B 0 8 S p Z r z B Y h n r d k A N l 0 L x B g q U v J 1 o T q N A 8 l Y w u p n 6 r S e u j Y j V A 4 4 T 7 k d 0 o E Q o G E U r t W 4 f M z z z J r 1 y x a 2 6 M 5 B l 4 u W k A j n q v f J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L q p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I i V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t k Q v M W X l 0 n z v O q 5 V e / +o E Q o G E U r t W 4 f M z z z J r 1 y x a 2 6 M 5 B l 4 u W k A j n q v f J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L q p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I i V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t k Q v M W X l 0 n z v O q 5 V e / +o E Q o G E U r t W 4 f M z z z J r 1 y x a 2 6 M 5 B l 4 u W k A j n q v f J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L q p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I i V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t k Q v M W X l 0 n z v O q 5 V e / +X R s T q A c c J 9 y M 6 U C I U j K K V W r e P G Z 5 X J 7 1 S 2 a 2 4 M 5 B l 4 u W k D D n q v d J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L s p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I q V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t o Q v M W X l 0 m z W v H c i n d / UX R s T q A c c J 9 y M 6 U C I U j K K V W r e P G Z 5 X J 7 1 S 2 a 2 4 M 5 B l 4 u W k D D n q v d J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L s p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I q V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t o Q v M W X l 0 m z W v H c i n d / UX R s T q A c c J 9 y M 6 U C I U j K K V W r e P G Z 5 X J 7 1 S 2 a 2 4 M 5 B l 4 u W k D D n q v d J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L s p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I q V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t o Q v M W X l 0 m z W v H c i n d / UX R s T q A c c J 9 y M 6 U C I U j K K V W r e P G Z 5 X J 7 1 S 2 a 2 4 M 5 B l 4 u W k D D n q v d J X t x + z N O I K m a T G d D w 3 Q T + j G g W T f F L s p o Y n l I 3 o g H c s V T T i x s 9 m 5 0 7 I q V X 6 J I y 1 L Y V k p v 6 e y G h k z D g K b G d E c W g W v a n 4 n 9 d J M b z y M 6 G S F L l i 8 0 V h K g n G Z P o 7 6 Q v N G c q x J Z R p Y W 8 l b E g 1 Z W g T K t o Q v M W X l 0 m z W v H c i n d / U\ning features instead of SDF values, we empirically found that nearest-neighbor interpolation produces better results and leads to more stable convergence during training.\n\n\nFeature Translation.\n\nIn the final and possibly asynchronous step, we translate the latent scene representation g t into a representation usable for visualization of the scene (e.g., signed distance field or occupancy grid).The network architecture in this step is inspired by IM-Net [5].For efficient and complete translation, we sample a regular grid of world coordinates.Then, at each of these sampled points p i , the translator aggregates the information stored in the features of the local neighborhood and predicts the TSDF s(p i ) as well as occupancy o(p i ) for this specific grid location.To this end, the translator concatenates the feature vectors of the 5 \u00d7 5 \u00d7 5 neighborhood and compresses them into a single feature vector using a linear layer followed by tanh activation.Next, the so combined features are concatenated with the query point feature g t (p i ) and passed through the remaining translation network, which consists of four linear layers interleaved with tanh activations and channel-wise dropout preventing the network from overfitting to a single feature channel.According to the desired output ranges, the TSDF head is activated using tanh, while the occupancy head uses a sigmoid activation.After each layer, we concatenate the output with the original query point feature g t (p i ).\n\nTraining Procedure and Loss Function.All networks are jointly trained end-to-end.In each training epoch, we randomly shuffle the input depth maps and iteratively fuse them one by one into the corresponding latent feature grid g : R \u2192 R N .After integrating the depth map into the latent feature grid, we query the translator network, where the latent feature grid was just updated, and render the TSDF s : R \u2192 R and occupancy o : R 3 \u2192 [0, 1].The entire pipeline is optimized using the following loss function:\nL = 1 n i \u03bb 1 L 1 (s i , \u015di ) + \u03bb 2 L 2 (s i , \u015di ) + \u03bb o L o (o i , \u00f4i ) + \u03bb g \u03c3 2 ch (g) ,(1)\nwhere L 1 and L 2 denote the L 1 and L 2 norms, and L o is the binary cross-entropy on the predicted occupancy.The L 2 loss is helpful with outliers, whereas the L 1 loss improves the reconstruction of fine details.In each step, n denotes the number of all updated feature grid locations.When training with outlier contaminated data, we found that setting n equal to all visited feature grid locations yields the best results.Therefore, n is a crucial hyperparameter when training the pipeline.Moreover, \u015di and \u00f4i denote the ground-truth TSDF and occupancy value, respectively.To avoid large deviations for a single feature in the latent space, we regularize the feature grid g by penalizing the mean of the channel-wise variance by \u03c3 2 ch (g).We empirically set the loss weights to \u03bb 1 = 1., \u03bb 2 = 10., \u03bb o = 0.01, and \u03bb g = 0.05.\n\n\nExperiments\n\nWe first discuss implementation details and evaluation metrics before evaluating our method on synthetic and realworld data in comparison to other methods.We further analyze our method for varying numbers of features N in an ablation study.We provide additional experiments and results in the supplementary material.Implementation Details.Our pipeline is implemented in PyTorch and trained on an NVIDIA RTX 2080.All networks were trained using the Adam optimizer [28] with an initial learning rate of 0.01, which was adapted using an exponential learning rate scheduler at a rate of 0.998.For momentum and beta, we empirically found the default parameters to yield the best results.We trained all networks on synthetic data being augmented with artificial noise and outliers.The batch-size is set to one due to the nature of the sequential fusion process.However, we accumulate the gradients across 8 scene update steps and then update the Figure 3. Left: The feature fusion network consists of a latent space encoder that fuses information from neighboring rays.This is followed by a latent updated predictor that predicts the updates for the latent space.Finally, the predicted features are normalized along the feature vector dimension.Right: The translator network consists of a series of neural blocks with linear layers, channel-wise dropout, and tanh activations.The first block extracts neighborhood information that is concatenated with the central feature vector.From the concatenated features the TSDF value is then predicted.All joining arrows correspond to a concatenation operation.\n\nnetwork parameters.Our un-optimized implementation runs at \u223c 7 frames per seconds with a depth map resolution of 240 \u00d7 320 on an NVIDIA RTX 2080.This demonstrates the real-time applicability of our approach.Evaluation Metrics.We use the following evaluation metrics to quantify the performance of our approach: Mean Squared Error (MSE), Mean Absolute Distance (MAD), Accuracy (Acc.),Intersection-over-Union (IoU), Mesh Completeness (M.C.) Mesh Accuracy (M.A.), and F1 score.Further details are in the supplementary material.\n\n\nResults on Synthetic Data\n\nDatasets.We used the synthetic ShapeNet [4] and ModelNet [65] datasets for performance evaluation.From ShapeNet, we selected 13 classes for training and evaluate on the same test set as [63] consisting of 60 objects from six classes, for which pretrained models [43] are available.For ModelNet [65], we trained and tested on 10 classes using the train-test split from [63].We first generated watertight models using the mesh-fusion pipeline used in [38] and computed TSDFs using the mesh-to-sdf1 library.Additionally, we render depth frames for 100 randomly sampled camera views for each mesh.These depth maps are the input to our pipeline and existing methods.For both datasets, we found that training on one single object per class is sufficient for generalization to any other object and class.Comparison to Existing Methods.\n\nFor performance comparisons, we fuse depth maps and augment them with artificial depth-dependent noise as in [48].We compare to state-of-the-art learned scene representation methods DeepSDF [43], OccupancyNetworks [38], and IF-Net [7], as well as to the online fusion methods TSDF Fusion [9] and RoutedFusion [63].We further implemented two additional baselines to demonstrate the benefits of a fully learned scene representation for depth map fusion: (1) one baseline performs a learned 2D noise filtering before fusing the frames using TSDF Fusion [9], and (2) a baseline that post-  Our fusion approach consistently outperforms all baselines and state of the art in both, scene representation and depth map fusion.The performance differences to [63] are also visualized in Figure 5.\n\nprocesses models fused by TSDF Fusion using a simplification of our translation network -the principle is similar to OctnetFusion [48], but on a dense grid.Further details on these baselines is given in the supplementary material.We compare all baselines on the test set of Weder et al. [63] in Figure 4.For input data augmentation, we used the same scale 0.005 as in [63].Figure 4 shows that our method significantly outperforms all existing depth map fusion as well as learned scene representations.We especially emphasize the increase in IoU by more than 10%.This significant increase is due to many fine-grained improvements, where Routed-Fusion [63] wrongly predicts the sign, as shown in Figure 5.In all experiments, we set the truncation distance of TSDF Fusion to 4cm, which is similar to the receptive field of our fusion network.Mesh Completeness Error (lower is better)\n\nTSDF Fusion RoutedFusion Ours w/ Routing Ours Figure 6.Reconstruction from Noisy Depth Maps.Our method outperforms existing depth fusion methods for various input noise levels.The performance can be further boosted by preprocessing the depth maps with the routing network from [63] leading to better robustness to high input noise levels, while it over-smoothes in the absence of noise.\n\nHigher Input Noise Levels.We also assess our method in fusing depth maps corrupted with higher noise levels on the ModelNet dataset [65] in Figure 6.For this experiment, we augment the input depth maps with three different noise levels.We fuse the corrupted depth maps using standard TSDF Fusion [9] and RoutedFusion [63].Since Weder et al. [63] showed that their proposed routing network significantly improved the robustness to higher input noise levels, we also tested our method with depth maps pre-processed by a routing network.For these experiments, we use the pre-trained routing network provided by [63].\n\nOutlier Handling.A main drawback of [63] is its limitation in handling outliers.To this end, we run an experiment, where we augment the input depth maps with random outlier blobs.We create this data by sampling an outlier map from a fixed distribution scaled by a fixed outlier scale.Additionally, we sample three masks with a given probability (outlier fraction) and dilate it once, twice, and three times, respectively.Then, these masks are used to select the outliers from the outlier map.We report the results of this experiment in Figure 7.\n\nNote that the results might be better with even higher outlier fractions since we only evaluate on updated grid locations.The consistency in outlier filtering and increase in updated grid locations improves the metrics.\n\n\nAblation Study\n\nIn a series of ablation studies, we discuss several benefits of our pipeline and justify design choices.Iterative Fusion.Ideally, fusion algorithms should be independent from the number of integrated frames and steadily improve the reconstruction as new information becomes available.In Figure 8, we show that our method is not only better than competing algorithms from the start, but also continuously improves the reconstruction as more data is fused.The metrics are averaged at every fusion step over all scenes in the test set used for all experiments on ShapeNet [4].Frame Order Permutation.Our method does not leverage any temporal information from the camera trajectory apart from the previous fusion result.This design choice allows to apply the method also to a broader class of scenarios (e.g.Multi-View Stereo).Ideally, an online fusion method should be invariant to permutations of the fusion frame order.To verify this property, we evaluated the performance of our method in fusing the same set of frames in ten different random frame orders.Figure 9 shows that our method converges to the same result for any frame order and thus seems to be invariant to frame order permutations.Feature Dimension.An important hyperparameter of our method is the feature dimension N .Therefore, we show quantitative results for the reconstruction from noisy and outlier contaminated depth maps using varying N in Table 1.We observe that a larger N clearly improves the results, but the performance eventually saturates, which justifies our choice of N = 8 features throughout the paper.Latent Space Visualization.In order to verify our hypothesis that the translator network mostly filters outliers, since the fusion network can hardly distinguish between first entries and outliers, we visualize the fused latent space in Figure 10.While the translated end result is outlier free, the latent space clearly shows that the fusion network keeps track of most measurements.\n\n\nReal-World Data\n\nWe also evaluate on real-world data and large-scale scenes to demonstrate scalability and generalization.Scene3D Dataset.\n\nFor real-world data evaluation, we use the lounge and stonewall scenes from the Scene3D dataset [72].For comparability to [63], we only fuse every 10th frame from the trajectory using a model solely trained on synthetic ModelNet [65] data augmented with artificial noise and outliers.[9] Fusion [63] Ours Fusion [9] Fusion [63] Ours Our method outperforms state-of-the-art depth fusion methods regardless of the outlier fraction, but in particular with larger outlier amounts.\n\nNote that high outlier rates are common in multi-view stereo as shown in the supp.material of [29].\n\nFigure 8. Performance of iterative fusion over time.Our method consistently outperforms both baselines [9,63] at every step of the fusion procedure.Figure 9. Random frame order permutations.The proposed method seems to be largely invariant to the frame integration order, since it always converges to the same result.\n\nXY-Plane XZ-Plane YZ-Plane Output Mesh\n\nFigure 10.Visualization of our learned latent space encoding.\n\nOur asynchronous fusion network integrates all measurements including outliers, but the translator effectively filters the outliers to generate a clean output mesh.In Figure 11, we present qualitative results of reconstructions from real-world depth maps compared to RoutedFusion [63] and TSDF Fusion [9].We note that our method reconstructs the scene with significantly higher completeness than [63].This is due to our learned translation from feature to TSDF space, which allows to better handle noise artifacts and outliers without the need for hand-tuned, heuristic post-filtering.Further, we show improved outlier and noise artefact removal compared to TSDF Fusion [9] while being on par with respect to completeness.These results are also quantitatively shown in Table 2.\n\nTanks and Temples Dataset.In order to demonstrate our methods outlier handling capability, we also run experiments on the Tanks and Temples dataset [29].We computed stereo depth maps using COLMAP [54,55] and fused this data using our method, PSR [26], TSDF Fusion [9], and Routed-Fusion [63].To demonstrate the easy applicability to new datasets in scenarios with limited ground-truth, we train our method on one single scene (Ignatius) from the Tanks and Temples training set.We reconstructed a dense mesh using Poisson Surface Reconstruction (PSR) [26], rendered artificial depth maps, and used TSDF Fusion to generate a ground-truth SDF.Then, we used this ground-truth to train Lounge Stone wall Input Frame TSDF Fusion [9] RoutedFusion [63] Ours Figure 11.Depth map fusion results on Scene3D [72].Our method yields significantly better completeness than RoutedFusion [63] (see stonewall) and is on par with TSDF Fusion [9].However, our method better removes noise and outlier artifacts (see lounge reconstruction).\nCaterpillar Truck M60\nInput Frame PSR [26] TSDF Fusion [9] RoutedFusion [63] Ours Figure 12. Results on Tanks and Temples [29].Our method significantly reduces the number of outliers compared to the other methods without using any outlier filtering heuristic and solely learning it from data.We especially highlight the results on the caterpillar scene, where our proposed method filters most outliers while the reconstructions of competing methods are heavily cluttered with outliers.\n\nthe fusion of stereo depth maps.Figure 12 shows the reconstructions of the unseen Caterpillar, Truck, and M60 scene from [29].Our proposed method significantly reduces the amount of outliers in the scene across all models.While [63] shows comparable results on some scenes, it is heavily dependent on its outlier post-filter, which fails as soon as there are too many outliers in the scene (see also Figure 1).Further, they also pre-process the depth maps using a 2D denoising network while our network uses the raw depth maps.\n\nLimitations.While our pipeline shows excellent generalization capabilities (e.g.generalizing from a single MVS training scene), it is biased to the number of observations integrated during training leading to less complete results on some test scene parts with very few observations.However, this issue can be overcome by a more diverse set of training sequences with different number of observations.\n\n\nConclusion\n\nWe presented a novel approach to online depth map fusion with real-time capability.The key idea is to perform the fusion operation in a learned latent space that allows to encode additional information about undesired outliers and super-resolution complex shape information.The separation of scene representations for fusion and final output allows for an end-to-end trainable post-filtering as a translator network, which takes the latent scene encoding and decodes it into a standard TSDF representation.Our experiments on various synthetic and real-world datasets demonstrate superior reconstruction results, especially in the presence of large amounts of noise and outliers.\n\nIn order to compare our method to state-of-the-art learning-based methods and standard TSDF fusion, we compute the following six metrics on reconstructions: Mean Squared Error (MSE) and Mean Absolute Distance (MAD).The mean squared error measures the reconstruction error on the TSDF field by penalizing large surface deviations and outliers.The mean absolute distance is also computed on the TSDF grid.However, it mainly quantifies the performance on reconstructing fine geometric details.Accuracy (Acc.),F1 Score, Intersection-over-Union (IoU): The accuracy is computed over the occupancy obtained from the sign of the TSDF grid.We also report the F1 score, which is the harmonic mean of precision and recall.By measuring both, completeness and accuracy, it is a more holistic metric for quantifying the performance of a reconstruction method.Moreover, we measure the IoU on the occupancy grid.The IoU especially quantifies artifacts typically encountered in reconstructions from noisy depth maps, such as surface and corner thickening and the vanishing of fine geometric details.Mesh Completeness (M.C.) and Accuracy (M.A.) We compute the completeness using the evaluation pipeline from [62].The completeness describes the distance from points sampled on the ground-truth mesh to the closest point on the reconstructed mesh.Vice-versa, the accuracy computes the distance from points sampled on the reconstructed mesh to the closest point on the ground-truth mesh.\n\n\nB. Reproducibility\n\nFor reproducibility, our source code will be made publicly available upon publication.We further present more details of our fusion pipeline in the following.\n\n\nB.1. Details on Pipeline Architecture\n\nOur method consists of four neural network components that are used for (i) sub-volume extraction of the global canonical feature volume, (ii) fusion of previously fused feature with a new depth map , (iii) integration of the fused updates back into the global feature volume, and (iv) translation from the latent feature space to TSDF and occupancy.(i) Extraction Layer.In the extraction layer, we extract the current state of the global feature volume into a viewdependent canonical feature volume defined by the camera parameters of the current measurement.In a first step, we un-project all depth pixels into the global feature grid using the camera parameters:\np XY Z = R t \u22121 K \u22121 p 1(2)\nwhere p XY Z are the coordinates of the un-projected point in world coordinates and p = (p x , p y , d) T are the pixel co-ordinates with its corresponding depth measurements.In a second step, we sample points around p XY Z in a window centered at p XY Z and aligned with the direction of the viewing ray.This procedure is inspired by the extraction step used in [63].Finally, we convert the coordinates of each sampled point to grid coordinates and extract the current feature state using nearest-neighbor interpolation.(ii) Feature Fusion Network.The feature fusion network consists of three components: Feature Encoder, Feature Decoder, and Feature Normalization, which are detailed in the following.\n\n1. Feature Encoder: The feature encoder is built from four network blocks each consisting of the following modules: 1) a 2D convolution having kernel size of 3 and zero padding reducing the number of input channels, 2) a layer normalization, 3) tanh activation, 4) again a 2D convolution having kernel size of 3 and zero padding but without reducing the channels, 5) layer normalization, and 6) tanh activation.The ouput of each block is concatenated with its input and passed to the next block.\n\n2. Feature Decoder: The feature decoder also consists of four neural blocks, of which each has the same design as the neural blocks in the feature encoder.However, instead of having a kernel-size of three, the convolutional layers in the feature decoder have a kernel-size of one.The motivation behind this choice is that the encoder has already encoded enough neighboring information and, therefore, the decoder predicts the feature updates based on the encoded information for each ray separately.\n\n3. Feature Normalization: After predicting the feature updates for each position in the local, view-dependent feature volume, we normalize each feature vector.This normalization prevents the feature values from becoming too large and, therefore, it improves the pipeline's capability to update the scene.\n\n(iii) Integration Layer.In the integration layer, we integrate the predicted feature updates from the fusion network back into the global feature volume.Therefore, we aggregate all updates that are mapped to the same global feature grid location using the correspondence given by the camera parameters.Then, we use an average pooling to combine multiple correspondences to the same grid location.Finally, we update the feature volume by using a running average update similar to [9].\n\n(iv) Feature Translation Network.The feature translation network renders the output modalities (TSDF and occupancy) from the latent feature representation for a specific query point p i .It consists of three components: a neighbor-hood interpolator, a translation MLP, and two network heads predicting the output modalities.\n\n1. Neighborhood Interpolator: The neighborhood interpolator encodes information from the neighboring feature vector into a single feature vector.Therefore, all neighboring feature vectors are concatenated and passed through a single linear layer followed by tanh activation.The output has the same dimension as one single feature vector.\n\n\nTranslation MLP:\n\nThe output of the neighborhood interpolator is concatenated with the query point feature vector g t (p i ) and passed through the translation MLP.The translation MLP is built from four linear layers interleaved with tanh activations.During training, the output of each layer is further passed through a channelwise dropout layer with dropout probability p = 0.2.\n\nThe first layer has 32 output channels, the second layer has 16 output channels, and the third and fourth layer have each 8 output channels.The output of each layer is concatenated with the query point feature vector.The output of the final layer is then passed to the two network output heads.\n\n\nNetwork Output Heads:\n\nThe translation network has two network output heads.Each head takes the output of the MLP as an input and predicts a translation modality.The TSDF head predicts the TSDF using a single linear layer outputting one channel that is followed by a tanh activation.The output of the activation is further scaled by the truncation band of the ground-truth TSDF (0.04) to map it into the correct value range.The occupancy head is also passed through a linear layer but activated using a sigmoid activation to map into a unit interval.\n\n\nB.2. Details on Hyperparameters\n\nTable 3 summarizes the choice of all hyperparameters that we used for all experiments in our work.\n\n\nC. Qualtitative Results\n\nIn this section, we present more qualitative results to demonstrate the performance of our method.\n\n\nC.1. Synthetic Data\n\nIn Figure 14, we show additional qualitative results for the outlier robustness experiment that we presented in the main paper.Our method is consistently better in filtering outliers than existing methods that have no outlier filtering or filter outliers heuristically.\n\n\nC.2. Real-World Data\n\nIn Figure 15 we show more results on the real-world Scene3D [72] dataset.With this experiment, we demonstrate that our method generalizes well to real-world data and is able to fuse and reconstruct measurements of large-scale real-world scenes.\n\n\nD. Further Evaluation D.1. Generalization from a Single Object\n\nIn order to demonstrate the compactness and generalization performance of our network, we train it only on a single chair object from the ModelNet [65] dataset.We augment the input depth maps with artificial noise of scale 0.01.We report the results in Table 4 and show that our method trained on a single object achieves almost the same performance as our method trained on the full training set.Moreover, it outperforms the currently best performing method -Rout-edFusion [63] -that is trained on the full training set.This result indicates the applicability of our method to many realworld scenarios, where the sensor setup might change.In fact, only very little training data is required to retrain our method and achieve state-of-the-art reconstruction results.\n\n\nD.2. Loss Ablation\n\nWe have also run an ablation study to evaluate the importance of the different terms in our loss function.In Figure 13, we show that the combination of all three loss terms yields best results.The binary cross entropy is particularly useful to improve convergence in the beginning of the training as the network learns to predict a coarse shape that is further refined by the losses on the SDF as training progresses.\n\n\nMesh Reconstruction\n\nOutlier Projection TSDF Fusion [9] RoutedFusion [63] Ours TSDF Fusion [9] RoutedFusion [63] Ours TSDF Fusion [9] RoutedFusion [63]  Figure 15.Additional results on Scene3D [72].Our method reconstructs scenes with significantly higher completeness.This is due to the learned translation that can effectively discriminate between outliers and geometry.Furthermore, our method can filter large outlier blobs.\n\n1 <\n1\nl a t e x i t s h a 1 _ b a s e 6 4 = \" / + p 3 y C C u Z 5 c 2P d x Q 7 d O x r Y k + L 3 g = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R g h 6 L X j x W s B / Q x r L Z b t q l m 0 3 Y n Q g l 9 Ed 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 h P X R s T q A S c J 9 y M 6 V C I U j K K V 2 s P H D C + 8 a b 9 c c a v u H G S V e D m p Q\n\n\n\n\nr H p u 1 b u v V e o 3 e R x F O I F T O A c P r q A O d 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P 2 2 o 9 P < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" / + p 3 y C C u Z 5 c 2 P d x Q 7 d O x r Y k + L 3 g = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R g h 6 L X j x W s B / Q x r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 h P X R s T q A S c J 9 y M 6 V C I U j K K V 2 s P H D C + 8 a b 9 c c a v u H G S V e D m p Q\n\n\n\n\nr H p u 1 b u v V e o 3 e R x F O I F T O A c P r q A O d 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P 2 2 o 9 P < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" / + p 3 y C C u Z 5 c 2 P d x Q 7 d O x r Y k + L 3 g = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R g h 6 L X j x W s B / Q x r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 h P X R s T q A S c J 9 y M 6 V C I U j K K V 2 s P H D C + 8 a b 9 c c a v u H G S V e D m p Q\n\n\n\n\nr H p u 1 b u v V e o 3 e R x F O I F T O A c P r q A O d 9 C A J j A Y w z O 8 w p u T O C / O u / O x a C 0 4 + c w x / I H z + Q P 2 2 o 9 P < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" / + p 3 y C C u Z 5 c 2 P d x Q 7 d O x r Y k + L 3 g = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y W R g h 6 L X j x W s B / Q x r L Z b t q l m 0 3 Y n Q g l 9 E d 4 8 a C I V 3 + P N / + N 2 z Y H b X 0 w 8 H h v h p l 5 Q S K F Q d f 9 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o Z e J U M 9 5 k s Y x 1 J 6 C G S 6 F 4 E w V K 3 k k 0 p 1 E g e T s Y 3 8 7 8 9 h P X R s T q A S c J 9 y M 6 V C I U j K K V 2 s P H D C + 8 a b 9 c c a v u H G S V e D m p Q\n\n\n\n\n2 n 7 I N w V t 8 e Z k 0 z 2 u e W / P u L 6 r 1 6 y K O E h z D C Z y B B 5 d Q h z t o g A 8 M B D z D K 7 w 5 y n l x 3 p 2 P e e u K U 8 w c w R 8 4 n z / k 7 o 6 6 < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" G\n\n\n\n\n2 n 7 I N w V t 8 e Z k 0 z 2 u e W / P u L 6 r 1 6 y K O E h z D C Z y B B 5 d Q h z t o g A 8 M B D z D K 7 w 5 y n l x 3 p 2 P e e u K U 8 w c w R 8 4 n z / k 7 o 6 6 < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" G\n\n\n\n\n2 n 7 I N w V t 8 e Z k 0 z 2 u e W / P u L 6 r 1 6 y K O E h z D C Z y B B 5 d Q h z t o g A 8 M B D z D K 7 w 5 y n l x 3 p 2 P e e u K U 8 w c w R 8 4 n z / k 7 o 6 6 < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" G\n\n\n\n\n2 n 7 I N w V t 8 e Z k 0 z 2 u e W / P u L 6 r 1 6 y K O E h z D C Z y B B 5 d Q h z t o g A 8 M B D z D K 7 w 5 y n l x 3 p 2 P e e u K U 8 w c w R 8 4 n z / k 7 o 6 6 < / l a t e x i t > D t < l a t e x i t s h a 1 _ b a s e 6 4 = \" v T e P S J 1 h V B d m b e n h q K\n\n\n\n\no l K 7 z u M o w h E c w y l 4 c A k 1 u I M 6 N I D B C J 7 h F d 6 c x H l x 3 p 2 P e W v B y W c O 4 Q + c z x / A / I 8 s < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" v T e P S J 1 h V B d m b e n h q K\n\n\n\n\no l K 7 z u M o w h E c w y l 4 c A k 1 u I M 6 N I D B C J 7 h F d 6 c x H l x 3 p 2 P e W v B y W c O 4 Q + c z x / A / I 8 s < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" v T e P S J 1 h V B d m b e n h q K U c o t q p X y w = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y U R Q Y 9 F P X i s Y D + g j W W z 3 b R L N 5 u w O x F K 6 I / w 4 k E R r / 4 e b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k Q K g 6 7 7 7 R R W V t f W N 4 q b p a 3 t n d 2 9 8 v 5 B 0 8 S p Z r z B Y h n r d k A N l 0 L x B g q U v J 1 o T q N A 8 l Y w u p n 6 r S e u j Y j V A 4 4 T 7 k d 0\n\n\n\n\no l K 7 z u M o w h E c w y l 4 c A k 1 u I M 6 N I D B C J 7 h F d 6 c x H l x 3 p 2 P e W v B y W c O 4 Q + c z x / A / I 8 s < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" v T e P S J 1 h V B d m b e n h q K U c o t q p X y w = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B i y U R Q Y 9 F P X i s Y D + g j W W z 3 b R L N 5 u w O x F K 6 I / w 4 k E R r / 4 e b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g k Q K g 6 7 7 7 R R W V t f W N 4 q b p a 3 t n d 2 9 8 v 5 B 0 8 S p Z r z B Y h n r d k A N l 0 L x B g q U v J 1 o T q N A 8 l Y w u p n 6 r S e u j Y j V A 4 4 T 7 k d 0\n\n\n\n\no l K 7 z u M o w h E c w y l 4 c A k 1 u I M 6 N I D B C J 7 h F d 6 c x H l x 3 p 2 P e W v B y W c O 4 Q + c z x / A / I 8 s < / l a t e x i t > D t < l a t e x i t s h a 1 _ b a s e 6 4 = \" 8 l U t g 8 t N W r N g Y P J O e B b A Q 4 9 W V R o = \" > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R F 0 G N R D x 4 r 2 A 9 o Y 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1 h P\n\n\n\n\na 5 d 5 3 E U 4 B h O 4 A w 8 u I Q a 3 E E d G s B g B M / w C m 9 O 4 r w 4 7 8 7 H v H X F y W e O 4 A + c z x / C g Y 8 t < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 8 l U t g 8 t N W r N g Y P J O e B b A Q 4 9 W V R o = \" > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R F 0 G N R D x 4 r 2 A 9 o Y 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1 h P\n\n\n\n\na 5 d 5 3 E U 4 B h O 4 A w 8 u I Q a 3 E E d G s B g B M / w C m 9 O 4 r w 4 7 8 7 H v H X F y W e O 4 A + c z x / C g Y 8 t < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 8 l U t g 8 t N W r N g Y P J O e B b A Q 4 9 W V R o = \" > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R F 0 G N R D x 4 r 2 A 9 o Y 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1 h P\n\n\n\n\na 5 d 5 3 E U 4 B h O 4 A w 8 u I Q a 3 E E d G s B g B M / w C m 9 O 4 r w 4 7 8 7 H v H X F y W e O 4 A + c z x / C g Y 8 t < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 8 l U t g 8 t N W r N g Y P J O e B b A Q 4 9 W V R o = \" > A A A B 7 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 s S R F 0 G N R D x 4 r 2 A 9 o Y 9 l s N + 3 S z S b s T o Q S + i O 8 e F D E q 7 / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1 h P\n\n\n\n\nFigure2.Proposed online reconstruction approach.Our pipeline consists of two main parts: 1) A fusion network with its extraction and integration layers, and 2) A translator network that translates the feature representation into an interpretable TSDF representation.For any new depth map D t a local, view-aligned feature grid v t\u22121 is extracted from the previous global feature grid g t\u22121 .The fusion network updates the local feature grid v t which is then integrated back into an updated global feature grid g t .The translator network is independent of the fusion process and can be used asynchronously for an efficient fusion process.\n\n\nFigure 4 .\n4\nFigure 4. Quantitative and qualitative results on ShapeNet [4].Our fusion approach consistently outperforms all baselines and state of the art in both, scene representation and depth map fusion.The performance differences to[63] are also visualized in Figure5.\n\n\n11 Figure 5 .\n115\nFigure 5. Mesh Accuracy (M.A.) visualization on ShapeNet meshes.Our method consistently reconstructs more accurate meshes than the baseline depth fusion methods.Especially thin geometries (table/chair legs, lamp cable) are reconstructed with better accuracy.\n\n\nFigure 7 .\n7\nFigure 7. Reconstruction from Outlier-Contaminated Data.The left table states performance measures for various outlier fractions.The figures on the right show corresponding reconstruction results and errors projected on the xy-plane for an exemplary ModelNet [65] model.Our method outperforms state-of-the-art depth fusion methods regardless of the outlier fraction, but in particular with larger outlier amounts.Note that high outlier rates are common in multi-view stereo as shown in the supp.material of[29].\n\n\n1 Figure 14 .\n114\nFigure 14.More qualitative results for different outlier fractions on ModelNet[65] examples.Our method consistently removes more outliers than existing depth map fusion methods.Even for large outlier fractions, our method successfully filters almost all of them.\n\n\nTable 1 .\n1\nAblation Study.We assess our method for different numbers of feature dimensions N .The performance saturates around N = 8.Note that N = 1 did not converge.\nN MSE\u2193 MAD\u2193 Acc.\u2191 IoU\u2191[e-05][e-02][%] [0,1]1----29.450.64 94.67 0.71744.030.30 97.51 0.86383.990.29 97.46 0.862163.910.29 97.50 0.863\n\nTable 2 .\n2\nTSDF Fusion [9] 21.01 22.58 17.67 21.16 21.88 26.31 39.56 42.5718.91 18.63 RoutedFusion [63] 20.50 41.32 19.44 80.54 22.63 53.45 38.07 57.35 19.20 41.41 Ours 18.19 18.88 17.01 20.27 16.45 17.96 19.06 20.25 15.87 16.96 Quantitative\nBurghersStonewallLoungeCopyroom Cactusgarden\nMethod M.A. M.C.M.A. M.C.M.A. M.C.M.A. M.C.M.A. M.C. evaluation on Scene3D [72].Evaluated are mesh accuracy (M.A.) [mm] & mesh completeness (M.C.) [mm].\n\n\nTable 3 .\n3\nNetwork hyperparameters\nOptimizerNameADAM\u03b2 10.9\u03b2 20.9991.e \u2212 08Learning Rate SchedulingInitial Learning Rate0.01Decay0.998Loss Weights\u03bb 11.0\u03bb 210.0\u03bb o0.01\u03bb g0.05LossL1L2L1 + L2L1 + L2 + BCE0.90IoU0.85Epoch0510152025\nFigure 13.Loss Ablation.All losses combined yield best results.\n\n\nTable 4 .\n4\nOur method trained on the standard training split and on a single chair object only.The model trained on a single object is almost on par with our model trained on the full training set and outperforms the next best existing method trained on the full training set.\nMethodMSE\u2193MAD\u2193Acc.\u2191IoU\u2191[e-05][e-02][%][0,1]RoutedFusion [63] (full training set)6.790.5694.440.821Ours (full training set)4.840.4296.300.874Ours (single object)3.940.4494.510.848\nhttps://github.com/marian42/mesh_to_sdf\nAcknowledgments.We thank Akihito Seki from Toshiba Japan for insightful discussions and valuable comments.This research was supported by Toshiba and Innosuisse funding (Grant No. 34475.1 IP-ICT).\nMeshlet priors for 3d mesh reconstruction. Abhishek Badki, Orazio Gallo, Jan Kautz, Pradeep Sen, CoRR, abs/2001.017442020\n\nCodeslam -learning a compact, optimisable representation for dense visual SLAM. Michael Bloesch, Jan Czarnowski, Ronald Clark, Stefan Leutenegger, Andrew J Davison, 2018 IEEE Conference on Computer Vision and Pattern Recognition. Salt Lake City, UT, USA2018. June 18-22. 2018. 2018\n\nDeep local shapes: Learning local SDF priors for detailed 3d reconstruction. Rohan Chabra, Jan Eric Lenssen, Eddy Ilg, Tanner Schmidt, Julian Straub, Steven Lovegrove, Richard A Newcombe, Proc. European Conference on Computer Vision (ECCV), volume 12374 of Lecture Notes in Computer Science. Andrea Vedaldi, Horst Bischof, Thomas Brox, Jan-Michael Frahm, European Conference on Computer Vision (ECCV), volume 12374 of Lecture Notes in Computer ScienceSpringer2020\n\nShapenet: An information-rich 3d model repository. X Angel, Thomas A Chang, Leonidas J Funkhouser, Pat Guibas, Qi-Xing Hanrahan, Zimo Huang, Silvio Li, Manolis Savarese, Shuran Savva, Hao Song, Jianxiong Su, Li Xiao, Fisher Yi, Yu, CoRR, abs/1512.030122015\n\nLearning implicit fields for generative shape modeling. Zhiqin Chen, Hao Zhang, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)2019\n\nMulti-label semantic 3d reconstruction using voxel blocks. Ian Cherabier, Christian H\u00e4ne, Martin R Oswald, Marc Pollefeys, International Conference on 3D Vision (3DV). 2016\n\nImplicit functions in feature space for 3d shape reconstruction and completion. Julian Chibane, Thiemo Alldieck, Gerard Pons-Moll, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEEjun 2020\n\n3d-r2n2: A unified approach for single and multi-view 3d object reconstruction. Danfei Christopher B Choy, Junyoung Xu, Kevin Gwak, Silvio Chen, Savarese, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)2016\n\nA volumetric method for building complex models from range images. Brian Curless, Marc Levoy, Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1996. the 23rd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1996New Orleans, LA, USAAugust 4-9, 1996. 1996\n\nDeepfactors: Real-time probabilistic dense monocular slam. Czarnowski, Laidlow, Clark, Davison, IEEE Robotics and Automation Letters. 52020\n\nJoint 3d-multi-view prediction for 3d semantic scene segmentation. Angela Dai, Matthias Nie\u00dfner, Computer Vision -ECCV 2018 -15th European Conference. Munich, GermanySeptember 8-14. 2018. 20183Proceedings, Part X\n\nBundlefusion: Real-time globally consistent 3d reconstruction using on-the-fly surface reintegration. Angela Dai, Matthias Nie\u00dfner, Michael Zollh\u00f6fer, Shahram Izadi, Christian Theobalt, ACM Trans. Graph. 363182017\n\nDefusr: Learning nonvolumetric depth fusion using successive reprojections. Simon Donn\u00e9, Andreas Geiger, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)Computer Vision Foundation / IEEE2019\n\nFusion of depth maps with multiple scales. Simon Fuhrmann, Michael Goesele, ACM Trans. Graph. 3062011\n\nDeep structured implicit functions. Kyle Genova, Forrester Cole, Avneesh Sud, Aaron Sarna, Thomas A Funkhouser, CoRR, abs/1912.061262019\n\nLearning shape templates with structured implicit functions. Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna, William T Freeman, Thomas A Funkhouser, CoRR, abs/1904.064472019\n\nJoint 3d scene reconstruction and class segmentation. Christian H\u00e4ne, Christopher Zach, Andrea Cohen, Roland Angst, Marc Pollefeys, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)2013\n\nDense semantic 3d reconstruction. Christian H\u00e4ne, Christopher Zach, Andrea Cohen, Marc Pollefeys, IEEE Transactions on Pattern Analysis and Machine Intelligence. 3992017\n\nDeep volumetric video from very sparse multi-view performance capture. Zeng Huang, Tianye Li, Weikai Chen, Yajie Zhao, Jun Xing, Chloe Legendre, Linjie Luo, Chongyang Ma, Hao Li, Proc. European Conference on Computer Vision (ECCV), volume 11220 of Lecture Notes in Computer Science. Vittorio Ferrari, Martial Hebert, Cristian Sminchisescu, Yair Weiss, European Conference on Computer Vision (ECCV), volume 11220 of Lecture Notes in Computer ScienceSpringer2018\n\nSurfacenet: An end-to-end 3d neural network for multiview stereopsis. Mengqi Ji, Juergen Gall, Haitian Zheng, Yebin Liu, Lu Fang, IEEE International Conference on Computer Vision, ICCV 2017. Venice, ItalyOctober 22-29, 2017. 2017\n\nLocal implicit grid representations for 3d scenes. Max Chiyu, Avneesh Jiang, Ameesh Sud, Jingwei Makadia, Matthias Huang, Thomas A Nie\u00dfner, Funkhouser, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)IEEE2020\n\nLocal implicit grid representations for 3d scenes. Max Chiyu, Avneesh Jiang, Ameesh Sud, Jingwei Makadia, Matthias Huang, Thomas A Nie\u00dfner, Funkhouser, CoRR, abs/2003.089812020\n\nVery high frame rate volumetric integration of depth images on mobile devices. Olaf K\u00e4hler, Adrian Victor, Carl Prisacariu, Xin Yuheng Ren, Sun, H S Philip, David W Torr, Murray, IEEE Trans. Vis. Comput. Graph. 21112015\n\nHierarchical voxel block hashing for efficient integration of depth images. Olaf K\u00e4hler, Adrian Victor, Prisacariu, P C Julien, David W Valentin, Murray, IEEE Robotics and Automation Letters. 112016\n\nLearning a multi-view stereo machine. Abhishek Kar, Christian H\u00e4ne, Jitendra Malik, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems. Isabelle Guyon, Samy Ulrike Von Luxburg, Hanna M Bengio, Rob Wallach, S V N Fergus, Roman Vishwanathan, Garnett, Long Beach, CA, USA2017, 4-9 December 2017. 2017\n\nScreened poisson surface reconstruction. M Michael, Hugues Kazhdan, Hoppe, ACM Trans. Graph. 323132013\n\nReal-time 3d reconstruction in dynamic scenes using point-based fusion. Maik Keller, Damien Lefloch, Martin Lambers, Shahram Izadi, Tim Weyrich, Andreas Kolb, 2013 International Conference on 3D Vision, 3DV 2013. Seattle, Washington, USAJune 29 -July 1, 2013. 2013\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, ICLR 20153rd International Conference on Learning Representations. San Diego, CA, USAMay 7-9, 2015. 2015Conference Track Proceedings\n\nTanks and temples: Benchmarking large-scale scene reconstruction. Arno Knapitsch, Jaesik Park, Qian-Yi Zhou, Vladlen Koltun, ACM Transactions on Graphics. 3642017\n\nContinuous global optimization in multiview 3d reconstruction. Kalin Kolev, Maria Klodt, Thomas Brox, Daniel Cremers, International Journal of Computer Vision. 8412009\n\nFrom point clouds to mesh using regression. Lubor Ladicky, Olivier Saurer, Sohyeon Jeong, Fabio Maninchedda, Marc Pollefeys, IEEE International Conference on Computer Vision, ICCV 2017. Venice, ItalyOctober 22-29, 2017. 2017\n\nAnisotropic point-based fusion. Damien Lefloch, Tim Weyrich, Andreas Kolb, 18th International Conference on Information Fusion, FUSION 2015. Washington, DC, USAJuly 6-9, 2015. 2015\n\nLearning to infer implicit surfaces without 3d supervision. Shichen Liu, Shunsuke Saito, Weikai Chen, Hao Li, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019. M Hanna, Hugo Wallach, Alina Larochelle, Beygelzimer, Emily B Florence D'alch\u00e9-Buc, Roman Fox, Garnett, NeurIPS; Vancouver, BC, Canada2019, 8-14 December 2019. 2019\n\nDIST: rendering deep implicit signed distance function with differentiable sphere tracing. Shaohui Liu, Yinda Zhang, Songyou Peng, Boxin Shi, Marc Pollefeys, Zhaopeng Cui, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)IEEE2020\n\nAn efficient octree design for local variational range image fusion. Nico Marniok, Ole Johannsen, Bastian Goldluecke, Proc. German Conference on Pattern Recognition (GCPR). German Conference on Pattern Recognition (GCPR)2017\n\nSemanticfusion: Dense 3d semantic mapping with convolutional neural networks. John Mccormac, Ankur Handa, Andrew J Davison, Stefan Leutenegger, IEEE. 2017. 2017. May 29 -June 3, 2017. 2017IEEE\n\nSentiment analysis algorithms and applications: A survey. Walaa Medhat, Ahmed Hassan, Hoda Korashy, Ain Shams Engineering Journal. 542014\n\nOccupancy networks: Learning 3d reconstruction in function space. Lars M Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, Andreas Geiger, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)2019\n\nAtlas: Endto-end 3d scene reconstruction from posed images. Zak Murez, James Tarrence Van As, Ayan Bartolozzi, Vijay Sinha, Andrew Badrinarayanan, Rabinovich, Proc. European Conference on Computer Vision (ECCV). European Conference on Computer Vision (ECCV)2020\n\nKinectfusion: Real-time dense surface mapping and tracking. Richard A Newcombe, Shahram Izadi, Otmar Hilliges, David Molyneaux, David Kim, Andrew J Davison, Pushmeet Kohli, Jamie Shotton, Steve Hodges, Andrew W Fitzgibbon, 10th IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2011. Basel, SwitzerlandOctober 26-29, 2011. 2011\n\nDifferentiable volumetric rendering: Learning implicit 3d representations without 3d supervision. Michael Niemeyer, Lars M Mescheder, Michael Oechsle, Andreas Geiger, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)IEEE2020\n\nReal-time 3d reconstruction at scale using voxel hashing. Matthias Nie\u00dfner, Michael Zollh\u00f6fer, Shahram Izadi, Marc Stamminger, ACM Trans. Graph. 326112013\n\nDeepSDF: Learning continuous signed distance functions for shape representation. Jeong Joon Park, Peter Florence, Julian Straub, Richard A Newcombe, Steven Lovegrove, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)2019\n\nRaynet: Learning volumetric 3d reconstruction with ray potentials. Despoina Paschalidou, Ali Osman Ulusoy, Carolin Schmitt, Luc Van Gool, Andreas Geiger, 2018 IEEE Conference on Computer Vision and Pattern Recognition. Salt Lake City, UT, USA2018. June 18-22. 2018. 2018\n\nConvolutional occupancy networks. Songyou Peng, Michael Niemeyer, Lars M Mescheder, Marc Pollefeys, Andreas Geiger, Proc. European Conference on Computer Vision (ECCV). European Conference on Computer Vision (ECCV)2020\n\nInfinitam v3: A framework for large-scale 3d reconstruction with loop closure. Adrian Victor, Olaf Prisacariu, Stuart K\u00e4hler, Michael Golodetz, Tommaso Sapienza, Cavallari, H S Philip, David William Torr, Murray, CoRR, abs/1708.007832017\n\nVoxgraph: Globally consistent, volumetric mapping using signed distance function submaps. V Reijgwart, A Millane, H Oleynikova, R Siegwart, C Cadena, J Nieto, IEEE Robotics and Automation Letters. 2020\n\nOctnetfusion: Learning depth fusion from data. Gernot Riegler, Ali Osman Ulusoy, Horst Bischof, Andreas Geiger, 2017 International Conference on 3D Vision, 3DV 2017. Qingdao, ChinaOctober 10-12, 2017. 2017\n\nOctnet: Learning deep 3d representations at high resolutions. Gernot Riegler, Ali Osman Ulusoy, Andreas Geiger, 2017 IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, USA2017. July 21-26, 2017. 2017\n\nPIFu: Pixel-aligned implicit function for high-resolution clothed human digitization. Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Hao Li, Angjoo Kanazawa, Proc. International Conference on Computer Vision (ICCV). International Conference on Computer Vision (ICCV)IEEE2019\n\nPifuhd: Multi-level pixel-aligned implicit function for high-resolution 3d human digitization. Shunsuke Saito, Tomas Simon, Jason M Saragih, Hanbyul Joo, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)IEEE2020\n\nSemantic 3d reconstruction with continuous regularization and ray potentials using a visibility consistency constraint. Nikolay Savinov, Christian H\u00e4ne, Lubor Ladicky, Marc Pollefeys, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)2016\n\nDiscrete optimization of ray potentials for semantic 3d reconstruction. Nikolay Savinov, Lubor Ladicky, Christian Hane, Marc Pollefeys, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)2015\n\nStructure-from-motion revisited. J L Sch\u00f6nberger, J Frahm, Proc. International Conference on Computer Vision and Pattern Recognition (CVPR). International Conference on Computer Vision and Pattern Recognition (CVPR)2016\n\nPixelwise view selection for unstructured multi-view stereo. Johannes L Sch\u00f6nberger, Enliang Zheng, Jan-Michael Frahm, Marc Pollefeys, Proc. European Conference on Computer Vision (ECCV). Lecture Notes in Computer Science. Bastian Leibe, Jiri Matas, Nicu Sebe, Max Welling, European Conference on Computer Vision (ECCV)Springer20169907\n\nSurfelmeshing: Online surfel-based mesh reconstruction. Thomas Sch\u00f6ps, Torsten Sattler, Marc Pollefeys, IEEE Transactions on Pattern Analysis and Machine Intelligence. 2019\n\nDeepvoxels: Learning persistent 3d feature embeddings. Justus Vincent Sitzmann, Felix Thies, Matthias Heide, Gordon Nie\u00dfner, Michael Wetzstein, Zollh\u00f6fer, IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019. Long Beach, CA, USAJune 16-20, 2019. 2019\n\nScene representation networks: Continuous 3d-structureaware neural scene representations. Michael Vincent Sitzmann, Gordon Zollh\u00f6fer, Wetzstein, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. NeurIPS; Vancouver, BC, Canada2019. 2019, 8-14 December 2019. 2019\n\nUnsupervised learning of video representations using LSTMs. Nitish Srivastava, Elman Mansimov, Ruslan Salakhutdinov, ICML. 2015\n\nLarge-scale multi-resolution surface reconstruction from RGB-D sequences. Frank Steinbr\u00fccker, Christian Kerl, Daniel Cremers, IEEE International Conference on Computer Vision, ICCV 2013. Sydney, AustraliaDecember 1-8, 2013. 2013\n\nMulti-resolution surfel maps for efficient dense 3d modeling and tracking. J\u00f6rg St\u00fcckler, Sven Behnke, J. Visual Communication and Image Representation. 2512014\n\nLearning 3d shape completion from laser scan data with weak supervision. David Stutz, Andreas Geiger, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Computer Society2018\n\nRoutedFusion: Learning real-time depth map fusion. Silvan Weder, Johannes L Sch\u00f6nberger, Marc Pollefeys, Martin R Oswald, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). June 2020\n\nElasticfusion: Realtime dense SLAM and light source estimation. Thomas Whelan, Renato F Salas-Moreno, Ben Glocker, Andrew J Davison, Stefan Leutenegger, I. J. Robotics Res. 35142016\n\n3d shapenets: A deep representation for volumetric shapes. Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, Jianxiong Xiao, IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015. Boston, MA, USAIEEE Computer SocietyJune 7-12, 2015. 2015\n\nDISN: deep implicit surface network for high-quality single-view 3d reconstruction. Qiangeng Xu, Weiyue Wang, Duygu Ceylan, Radom\u00edr Mech, Ulrich Neumann, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. NeurIPS; Vancouver, BC, Canada2019. 2019, 8-14 December 2019. 2019\n\nSurface reconstruction via fusing sparse-sequence of depth images. Long Yang, Qingan Yan, Yanping Fu, Chunxia Xiao, IEEE Trans. Vis. Comput. Graph. 2422018\n\nA globally optimal algorithm for robust tv-l1 range image integration. Christopher Zach, Thomas Pock, Horst Bischof, Proc. International Conference on Computer Vision (ICCV). International Conference on Computer Vision (ICCV)2007\n\nDeep learning for sentiment analysis: A survey. Lei Zhang, Shuai Wang, Bing Liu, WIREs Data Mining and Knowledge Discovery. 84e12532018\n\nScenecode: Monocular dense semantic reconstruction using learned encoded scene representations. Shuaifeng Zhi, Michael Bloesch, Stefan Leutenegger, Andrew J Davison, IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2019. Long Beach, CA, USAJune 16-20, 2019. 2019\n\nDeeptam: Deep tracking and mapping with convolutional neural networks. Huizhong Zhou, Benjamin Ummenhofer, Thomas Brox, Int. J. Comput. Vis. 12832020\n\nDense scene reconstruction with points of interest. Qian-Yi Zhou, Vladlen Koltun, ACM Trans. Graph. 3242013\n\nShading-based refinement on volumetric signed distance functions. Michael Zollh\u00f6fer, Angela Dai, Matthias Innmann, Chenglei Wu, Marc Stamminger, Christian Theobalt, Matthias Nie\u00dfner, 96:1-96:14ACM Trans. Graph. 3442015\n\nState of the Art on 3D Reconstruction with RGB-D Cameras. Computer Graphics Forum (Eurographics State of the Art Reports. M Zollh\u00f6fer, P Stotko, A G\u00f6rlitz, C Theobalt, M Nie\u00dfner, R Klein, A Kolb, 2018. 201837\n", "annotations": {"author": "[{\"end\":109,\"start\":53},{\"end\":177,\"start\":110},{\"end\":280,\"start\":178},{\"end\":340,\"start\":281}]", "publisher": null, "author_last_name": "[{\"end\":65,\"start\":60},{\"end\":132,\"start\":121},{\"end\":192,\"start\":183},{\"end\":296,\"start\":290}]", "author_first_name": "[{\"end\":59,\"start\":53},{\"end\":118,\"start\":110},{\"end\":120,\"start\":119},{\"end\":182,\"start\":178},{\"end\":287,\"start\":281},{\"end\":289,\"start\":288}]", "author_affiliation": "[{\"end\":108,\"start\":67},{\"end\":176,\"start\":134},{\"end\":235,\"start\":194},{\"end\":279,\"start\":237},{\"end\":339,\"start\":298}]", "title": "[{\"end\":50,\"start\":1},{\"end\":390,\"start\":341}]", "venue": null, "abstract": "[{\"end\":1511,\"start\":424}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2192,\"start\":2188},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2211,\"start\":2207},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2227,\"start\":2223},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2415,\"start\":2412},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2523,\"start\":2520},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":2541,\"start\":2537},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2623,\"start\":2619},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5039,\"start\":5035},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5148,\"start\":5144},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5162,\"start\":5158},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5178,\"start\":5175},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5472,\"start\":5469},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5474,\"start\":5472},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5477,\"start\":5474},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":5480,\"start\":5477},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5541,\"start\":5538},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5544,\"start\":5541},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5547,\"start\":5544},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5550,\"start\":5547},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":5553,\"start\":5550},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":5652,\"start\":5648},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5722,\"start\":5718},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":5956,\"start\":5952},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6029,\"start\":6025},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":6201,\"start\":6197},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6587,\"start\":6584},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6590,\"start\":6587},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6593,\"start\":6590},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6660,\"start\":6656},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6663,\"start\":6660},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7086,\"start\":7083},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7336,\"start\":7332},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":7387,\"start\":7383},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7406,\"start\":7402},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":7458,\"start\":7454},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7474,\"start\":7470},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":7489,\"start\":7485},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7519,\"start\":7515},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":7522,\"start\":7519},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":7525,\"start\":7522},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7555,\"start\":7551},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7799,\"start\":7795},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7802,\"start\":7799},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":7805,\"start\":7802},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":7808,\"start\":7805},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":7811,\"start\":7808},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":7814,\"start\":7811},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":8037,\"start\":8033},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8261,\"start\":8257},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":8264,\"start\":8261},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8313,\"start\":8310},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8316,\"start\":8313},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8319,\"start\":8316},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8322,\"start\":8319},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":8325,\"start\":8322},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":8381,\"start\":8377},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":8547,\"start\":8543},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":8583,\"start\":8579},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8710,\"start\":8706},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8832,\"start\":8828},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8978,\"start\":8974},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9281,\"start\":9278},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":9297,\"start\":9293},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":9438,\"start\":9434},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9659,\"start\":9655},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":9807,\"start\":9803},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10080,\"start\":10076},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":10555,\"start\":10551},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10582,\"start\":10578},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":10585,\"start\":10582},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":15812,\"start\":15808},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25697,\"start\":25694},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28651,\"start\":28647},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":30379,\"start\":30376},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":30397,\"start\":30393},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":30526,\"start\":30522},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":30602,\"start\":30598},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":30634,\"start\":30630},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":30708,\"start\":30704},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":30789,\"start\":30785},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":31279,\"start\":31275},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":31360,\"start\":31356},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":31384,\"start\":31380},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":31400,\"start\":31397},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":31457,\"start\":31454},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":31479,\"start\":31475},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":31719,\"start\":31716},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":31918,\"start\":31914},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":32087,\"start\":32083},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":32244,\"start\":32240},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":32325,\"start\":32321},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":32607,\"start\":32603},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":33116,\"start\":33112},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":33359,\"start\":33355},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":33522,\"start\":33519},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":33544,\"start\":33540},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":33568,\"start\":33564},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":33835,\"start\":33831},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":33878,\"start\":33874},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":35195,\"start\":35192},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":36835,\"start\":36831},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":36861,\"start\":36857},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":36968,\"start\":36964},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":37022,\"start\":37019},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":37034,\"start\":37030},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":37050,\"start\":37047},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":37062,\"start\":37058},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":37311,\"start\":37307},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":37420,\"start\":37417},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":37423,\"start\":37420},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":38020,\"start\":38016},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38040,\"start\":38037},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":38136,\"start\":38132},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38409,\"start\":38406},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":38667,\"start\":38663},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":38715,\"start\":38711},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":38718,\"start\":38715},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":38765,\"start\":38761},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":38782,\"start\":38779},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":38806,\"start\":38802},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":39069,\"start\":39065},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":39241,\"start\":39238},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":39259,\"start\":39255},{\"end\":39274,\"start\":39265},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":39315,\"start\":39311},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":39390,\"start\":39386},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":39441,\"start\":39438},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":39576,\"start\":39572},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":39592,\"start\":39589},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":39610,\"start\":39606},{\"end\":39625,\"start\":39616},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":39660,\"start\":39656},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":40146,\"start\":40142},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":40253,\"start\":40249},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":42840,\"start\":42836},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":44396,\"start\":44392},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":46520,\"start\":46517},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":49060,\"start\":49056},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":49458,\"start\":49454},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":49785,\"start\":49781},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":50571,\"start\":50568},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":50589,\"start\":50585},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":50610,\"start\":50607},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":50628,\"start\":50624},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":50649,\"start\":50646},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":50667,\"start\":50663},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":50713,\"start\":50709},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":59327,\"start\":59323},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":60164,\"start\":60160},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":60268,\"start\":60264}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":51482,\"start\":50943},{\"attributes\":{\"id\":\"fig_1\"},\"end\":52186,\"start\":51483},{\"attributes\":{\"id\":\"fig_2\"},\"end\":52890,\"start\":52187},{\"attributes\":{\"id\":\"fig_3\"},\"end\":53594,\"start\":52891},{\"attributes\":{\"id\":\"fig_4\"},\"end\":53832,\"start\":53595},{\"attributes\":{\"id\":\"fig_5\"},\"end\":54070,\"start\":53833},{\"attributes\":{\"id\":\"fig_6\"},\"end\":54308,\"start\":54071},{\"attributes\":{\"id\":\"fig_7\"},\"end\":54584,\"start\":54309},{\"attributes\":{\"id\":\"fig_8\"},\"end\":54814,\"start\":54585},{\"attributes\":{\"id\":\"fig_9\"},\"end\":55436,\"start\":54815},{\"attributes\":{\"id\":\"fig_10\"},\"end\":56058,\"start\":55437},{\"attributes\":{\"id\":\"fig_11\"},\"end\":56658,\"start\":56059},{\"attributes\":{\"id\":\"fig_12\"},\"end\":57252,\"start\":56659},{\"attributes\":{\"id\":\"fig_13\"},\"end\":57846,\"start\":57253},{\"attributes\":{\"id\":\"fig_14\"},\"end\":58440,\"start\":57847},{\"attributes\":{\"id\":\"fig_15\"},\"end\":59084,\"start\":58441},{\"attributes\":{\"id\":\"fig_16\"},\"end\":59360,\"start\":59085},{\"attributes\":{\"id\":\"fig_17\"},\"end\":59639,\"start\":59361},{\"attributes\":{\"id\":\"fig_18\"},\"end\":60166,\"start\":59640},{\"attributes\":{\"id\":\"fig_20\"},\"end\":60449,\"start\":60167},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":60752,\"start\":60450},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":61195,\"start\":60753},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":61489,\"start\":61196},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":61947,\"start\":61490}]", "paragraph": "[{\"end\":1865,\"start\":1527},{\"end\":2546,\"start\":1867},{\"end\":2722,\"start\":2548},{\"end\":2932,\"start\":2724},{\"end\":4122,\"start\":2934},{\"end\":4212,\"start\":4164},{\"end\":4386,\"start\":4214},{\"end\":4558,\"start\":4388},{\"end\":4708,\"start\":4560},{\"end\":4874,\"start\":4710},{\"end\":6931,\"start\":4891},{\"end\":8038,\"start\":6933},{\"end\":9210,\"start\":8040},{\"end\":10340,\"start\":9212},{\"end\":10760,\"start\":10342},{\"end\":12170,\"start\":10771},{\"end\":16566,\"start\":12172},{\"end\":25407,\"start\":25237},{\"end\":26728,\"start\":25432},{\"end\":27240,\"start\":26730},{\"end\":28168,\"start\":27337},{\"end\":29780,\"start\":28184},{\"end\":30306,\"start\":29782},{\"end\":31164,\"start\":30336},{\"end\":31951,\"start\":31166},{\"end\":32833,\"start\":31953},{\"end\":33221,\"start\":32835},{\"end\":33836,\"start\":33223},{\"end\":34383,\"start\":33838},{\"end\":34604,\"start\":34385},{\"end\":36592,\"start\":34623},{\"end\":36733,\"start\":36612},{\"end\":37211,\"start\":36735},{\"end\":37312,\"start\":37213},{\"end\":37631,\"start\":37314},{\"end\":37671,\"start\":37633},{\"end\":37734,\"start\":37673},{\"end\":38513,\"start\":37736},{\"end\":39533,\"start\":38515},{\"end\":40019,\"start\":39556},{\"end\":40548,\"start\":40021},{\"end\":40951,\"start\":40550},{\"end\":41644,\"start\":40966},{\"end\":43112,\"start\":41646},{\"end\":43293,\"start\":43135},{\"end\":44000,\"start\":43335},{\"end\":44732,\"start\":44029},{\"end\":45229,\"start\":44734},{\"end\":45730,\"start\":45231},{\"end\":46036,\"start\":45732},{\"end\":46521,\"start\":46038},{\"end\":46847,\"start\":46523},{\"end\":47186,\"start\":46849},{\"end\":47569,\"start\":47207},{\"end\":47865,\"start\":47571},{\"end\":48418,\"start\":47891},{\"end\":48552,\"start\":48454},{\"end\":48678,\"start\":48580},{\"end\":48971,\"start\":48702},{\"end\":49240,\"start\":48996},{\"end\":50073,\"start\":49307},{\"end\":50513,\"start\":50096},{\"end\":50942,\"start\":50537},{\"end\":51481,\"start\":50950},{\"end\":52185,\"start\":51486},{\"end\":52889,\"start\":52190},{\"end\":53593,\"start\":52894},{\"end\":53831,\"start\":53598},{\"end\":54069,\"start\":53836},{\"end\":54307,\"start\":54074},{\"end\":54583,\"start\":54312},{\"end\":54813,\"start\":54588},{\"end\":55435,\"start\":54818},{\"end\":56057,\"start\":55440},{\"end\":56657,\"start\":56062},{\"end\":57251,\"start\":56662},{\"end\":57845,\"start\":57256},{\"end\":58439,\"start\":57850},{\"end\":59083,\"start\":58444},{\"end\":59359,\"start\":59099},{\"end\":59638,\"start\":59380},{\"end\":60165,\"start\":59654},{\"end\":60448,\"start\":60186},{\"end\":60618,\"start\":60463},{\"end\":60996,\"start\":60766},{\"end\":61194,\"start\":61042},{\"end\":61232,\"start\":61209},{\"end\":61488,\"start\":61425},{\"end\":61768,\"start\":61503}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16884,\"start\":16567},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17201,\"start\":16884},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17518,\"start\":17201},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18823,\"start\":17518},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19598,\"start\":18823},{\"attributes\":{\"id\":\"formula_5\"},\"end\":20373,\"start\":19598},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21148,\"start\":20373},{\"attributes\":{\"id\":\"formula_7\"},\"end\":21939,\"start\":21148},{\"attributes\":{\"id\":\"formula_8\"},\"end\":22730,\"start\":21939},{\"attributes\":{\"id\":\"formula_9\"},\"end\":23129,\"start\":22730},{\"attributes\":{\"id\":\"formula_10\"},\"end\":23528,\"start\":23129},{\"attributes\":{\"id\":\"formula_11\"},\"end\":23955,\"start\":23528},{\"attributes\":{\"id\":\"formula_12\"},\"end\":24382,\"start\":23955},{\"attributes\":{\"id\":\"formula_13\"},\"end\":24809,\"start\":24382},{\"attributes\":{\"id\":\"formula_14\"},\"end\":25236,\"start\":24809},{\"attributes\":{\"id\":\"formula_15\"},\"end\":27336,\"start\":27241},{\"attributes\":{\"id\":\"formula_16\"},\"end\":44028,\"start\":44001}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36042,\"start\":36041},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":38512,\"start\":38511},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":48461,\"start\":48460},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":49567,\"start\":49566}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1525,\"start\":1513},{\"end\":4162,\"start\":4125},{\"attributes\":{\"n\":\"2.\"},\"end\":4889,\"start\":4877},{\"attributes\":{\"n\":\"3.\"},\"end\":10769,\"start\":10763},{\"end\":25430,\"start\":25410},{\"attributes\":{\"n\":\"4.\"},\"end\":28182,\"start\":28171},{\"attributes\":{\"n\":\"4.1.\"},\"end\":30334,\"start\":30309},{\"attributes\":{\"n\":\"4.2.\"},\"end\":34621,\"start\":34607},{\"attributes\":{\"n\":\"4.3.\"},\"end\":36610,\"start\":36595},{\"attributes\":{\"n\":\"5.\"},\"end\":40964,\"start\":40954},{\"end\":43133,\"start\":43115},{\"end\":43333,\"start\":43296},{\"attributes\":{\"n\":\"2.\"},\"end\":47205,\"start\":47189},{\"attributes\":{\"n\":\"3.\"},\"end\":47889,\"start\":47868},{\"end\":48452,\"start\":48421},{\"end\":48578,\"start\":48555},{\"end\":48700,\"start\":48681},{\"end\":48994,\"start\":48974},{\"end\":49305,\"start\":49243},{\"end\":50094,\"start\":50076},{\"end\":50535,\"start\":50516},{\"end\":50947,\"start\":50944},{\"end\":59096,\"start\":59086},{\"end\":59375,\"start\":59362},{\"end\":59651,\"start\":59641},{\"end\":60181,\"start\":60168},{\"end\":60460,\"start\":60451},{\"end\":60763,\"start\":60754},{\"end\":61206,\"start\":61197},{\"end\":61500,\"start\":61491}]", "table": "[{\"end\":60752,\"start\":60619},{\"end\":61041,\"start\":60997},{\"end\":61424,\"start\":61233},{\"end\":61947,\"start\":61769}]", "figure_caption": "[{\"end\":51482,\"start\":50949},{\"end\":52186,\"start\":51485},{\"end\":52890,\"start\":52189},{\"end\":53594,\"start\":52893},{\"end\":53832,\"start\":53597},{\"end\":54070,\"start\":53835},{\"end\":54308,\"start\":54073},{\"end\":54584,\"start\":54311},{\"end\":54814,\"start\":54587},{\"end\":55436,\"start\":54817},{\"end\":56058,\"start\":55439},{\"end\":56658,\"start\":56061},{\"end\":57252,\"start\":56661},{\"end\":57846,\"start\":57255},{\"end\":58440,\"start\":57849},{\"end\":59084,\"start\":58443},{\"end\":59360,\"start\":59098},{\"end\":59639,\"start\":59379},{\"end\":60166,\"start\":59653},{\"end\":60449,\"start\":60185},{\"end\":60619,\"start\":60462},{\"end\":60997,\"start\":60765},{\"end\":61233,\"start\":61208},{\"end\":61769,\"start\":61502}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2556,\"start\":2555},{\"end\":11265,\"start\":11264},{\"end\":12260,\"start\":12259},{\"end\":29132,\"start\":29131},{\"end\":31950,\"start\":31949},{\"attributes\":{\"ref_id\":\"fig_16\"},\"end\":32256,\"start\":32255},{\"attributes\":{\"ref_id\":\"fig_16\"},\"end\":32334,\"start\":32333},{\"end\":32655,\"start\":32654},{\"end\":32889,\"start\":32888},{\"end\":33371,\"start\":33370},{\"attributes\":{\"ref_id\":\"fig_18\"},\"end\":34382,\"start\":34381},{\"end\":34918,\"start\":34917},{\"end\":35687,\"start\":35686},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36454,\"start\":36452},{\"end\":37322,\"start\":37321},{\"end\":37470,\"start\":37469},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":37682,\"start\":37680},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":37912,\"start\":37910},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":40062,\"start\":40060},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":40429,\"start\":40428},{\"attributes\":{\"ref_id\":\"fig_16\"},\"end\":48714,\"start\":48712},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":49008,\"start\":49006},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":50214,\"start\":50212},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":50678,\"start\":50676}]", "bib_author_first_name": "[{\"end\":62235,\"start\":62227},{\"end\":62249,\"start\":62243},{\"end\":62260,\"start\":62257},{\"end\":62275,\"start\":62268},{\"end\":62394,\"start\":62387},{\"end\":62407,\"start\":62404},{\"end\":62426,\"start\":62420},{\"end\":62440,\"start\":62434},{\"end\":62460,\"start\":62454},{\"end\":62462,\"start\":62461},{\"end\":62672,\"start\":62667},{\"end\":62684,\"start\":62681},{\"end\":62689,\"start\":62685},{\"end\":62703,\"start\":62699},{\"end\":62715,\"start\":62709},{\"end\":62731,\"start\":62725},{\"end\":62746,\"start\":62740},{\"end\":62765,\"start\":62758},{\"end\":62767,\"start\":62766},{\"end\":62888,\"start\":62882},{\"end\":62903,\"start\":62898},{\"end\":62919,\"start\":62913},{\"end\":62937,\"start\":62926},{\"end\":63107,\"start\":63106},{\"end\":63121,\"start\":63115},{\"end\":63123,\"start\":63122},{\"end\":63139,\"start\":63131},{\"end\":63141,\"start\":63140},{\"end\":63157,\"start\":63154},{\"end\":63173,\"start\":63166},{\"end\":63188,\"start\":63184},{\"end\":63202,\"start\":63196},{\"end\":63214,\"start\":63207},{\"end\":63231,\"start\":63225},{\"end\":63242,\"start\":63239},{\"end\":63258,\"start\":63249},{\"end\":63265,\"start\":63263},{\"end\":63278,\"start\":63272},{\"end\":63375,\"start\":63369},{\"end\":63385,\"start\":63382},{\"end\":63617,\"start\":63614},{\"end\":63638,\"start\":63629},{\"end\":63651,\"start\":63645},{\"end\":63653,\"start\":63652},{\"end\":63666,\"start\":63662},{\"end\":63815,\"start\":63809},{\"end\":63831,\"start\":63825},{\"end\":63848,\"start\":63842},{\"end\":64027,\"start\":64021},{\"end\":64056,\"start\":64048},{\"end\":64066,\"start\":64061},{\"end\":64079,\"start\":64073},{\"end\":64289,\"start\":64284},{\"end\":64303,\"start\":64299},{\"end\":64764,\"start\":64758},{\"end\":64778,\"start\":64770},{\"end\":65013,\"start\":65007},{\"end\":65027,\"start\":65019},{\"end\":65044,\"start\":65037},{\"end\":65063,\"start\":65056},{\"end\":65080,\"start\":65071},{\"end\":65201,\"start\":65196},{\"end\":65216,\"start\":65209},{\"end\":65468,\"start\":65463},{\"end\":65486,\"start\":65479},{\"end\":65563,\"start\":65559},{\"end\":65581,\"start\":65572},{\"end\":65595,\"start\":65588},{\"end\":65606,\"start\":65601},{\"end\":65620,\"start\":65614},{\"end\":65622,\"start\":65621},{\"end\":65726,\"start\":65722},{\"end\":65744,\"start\":65735},{\"end\":65757,\"start\":65751},{\"end\":65771,\"start\":65766},{\"end\":65786,\"start\":65779},{\"end\":65788,\"start\":65787},{\"end\":65804,\"start\":65798},{\"end\":65806,\"start\":65805},{\"end\":65908,\"start\":65899},{\"end\":65926,\"start\":65915},{\"end\":65939,\"start\":65933},{\"end\":65953,\"start\":65947},{\"end\":65965,\"start\":65961},{\"end\":66182,\"start\":66173},{\"end\":66200,\"start\":66189},{\"end\":66213,\"start\":66207},{\"end\":66225,\"start\":66221},{\"end\":66385,\"start\":66381},{\"end\":66399,\"start\":66393},{\"end\":66410,\"start\":66404},{\"end\":66422,\"start\":66417},{\"end\":66432,\"start\":66429},{\"end\":66444,\"start\":66439},{\"end\":66461,\"start\":66455},{\"end\":66476,\"start\":66467},{\"end\":66484,\"start\":66481},{\"end\":66601,\"start\":66593},{\"end\":66618,\"start\":66611},{\"end\":66635,\"start\":66627},{\"end\":66654,\"start\":66650},{\"end\":66848,\"start\":66842},{\"end\":66860,\"start\":66853},{\"end\":66874,\"start\":66867},{\"end\":66887,\"start\":66882},{\"end\":66895,\"start\":66893},{\"end\":67057,\"start\":67054},{\"end\":67072,\"start\":67065},{\"end\":67086,\"start\":67080},{\"end\":67099,\"start\":67092},{\"end\":67117,\"start\":67109},{\"end\":67131,\"start\":67125},{\"end\":67133,\"start\":67132},{\"end\":67375,\"start\":67372},{\"end\":67390,\"start\":67383},{\"end\":67404,\"start\":67398},{\"end\":67417,\"start\":67410},{\"end\":67435,\"start\":67427},{\"end\":67449,\"start\":67443},{\"end\":67451,\"start\":67450},{\"end\":67582,\"start\":67578},{\"end\":67597,\"start\":67591},{\"end\":67610,\"start\":67606},{\"end\":67626,\"start\":67623},{\"end\":67645,\"start\":67644},{\"end\":67647,\"start\":67646},{\"end\":67661,\"start\":67656},{\"end\":67663,\"start\":67662},{\"end\":67800,\"start\":67796},{\"end\":67815,\"start\":67809},{\"end\":67837,\"start\":67836},{\"end\":67839,\"start\":67838},{\"end\":67853,\"start\":67848},{\"end\":67855,\"start\":67854},{\"end\":67966,\"start\":67958},{\"end\":67981,\"start\":67972},{\"end\":67996,\"start\":67988},{\"end\":68126,\"start\":68118},{\"end\":68138,\"start\":68134},{\"end\":68164,\"start\":68159},{\"end\":68166,\"start\":68165},{\"end\":68178,\"start\":68175},{\"end\":68189,\"start\":68188},{\"end\":68193,\"start\":68190},{\"end\":68207,\"start\":68202},{\"end\":68323,\"start\":68322},{\"end\":68339,\"start\":68333},{\"end\":68461,\"start\":68457},{\"end\":68476,\"start\":68470},{\"end\":68492,\"start\":68486},{\"end\":68509,\"start\":68502},{\"end\":68520,\"start\":68517},{\"end\":68537,\"start\":68530},{\"end\":68696,\"start\":68695},{\"end\":68712,\"start\":68707},{\"end\":68929,\"start\":68925},{\"end\":68947,\"start\":68941},{\"end\":68961,\"start\":68954},{\"end\":68975,\"start\":68968},{\"end\":69091,\"start\":69086},{\"end\":69104,\"start\":69099},{\"end\":69118,\"start\":69112},{\"end\":69131,\"start\":69125},{\"end\":69241,\"start\":69236},{\"end\":69258,\"start\":69251},{\"end\":69274,\"start\":69267},{\"end\":69287,\"start\":69282},{\"end\":69305,\"start\":69301},{\"end\":69456,\"start\":69450},{\"end\":69469,\"start\":69466},{\"end\":69486,\"start\":69479},{\"end\":69667,\"start\":69660},{\"end\":69681,\"start\":69673},{\"end\":69695,\"start\":69689},{\"end\":69705,\"start\":69702},{\"end\":69830,\"start\":69829},{\"end\":69842,\"start\":69838},{\"end\":69857,\"start\":69852},{\"end\":69888,\"start\":69883},{\"end\":69890,\"start\":69889},{\"end\":69918,\"start\":69913},{\"end\":70093,\"start\":70086},{\"end\":70104,\"start\":70099},{\"end\":70119,\"start\":70112},{\"end\":70131,\"start\":70126},{\"end\":70141,\"start\":70137},{\"end\":70161,\"start\":70153},{\"end\":70406,\"start\":70402},{\"end\":70419,\"start\":70416},{\"end\":70438,\"start\":70431},{\"end\":70641,\"start\":70637},{\"end\":70657,\"start\":70652},{\"end\":70671,\"start\":70665},{\"end\":70673,\"start\":70672},{\"end\":70689,\"start\":70683},{\"end\":70816,\"start\":70811},{\"end\":70830,\"start\":70825},{\"end\":70843,\"start\":70839},{\"end\":70962,\"start\":70958},{\"end\":70964,\"start\":70963},{\"end\":70983,\"start\":70976},{\"end\":71000,\"start\":70993},{\"end\":71020,\"start\":71011},{\"end\":71037,\"start\":71030},{\"end\":71271,\"start\":71268},{\"end\":71284,\"start\":71279},{\"end\":71306,\"start\":71302},{\"end\":71324,\"start\":71319},{\"end\":71338,\"start\":71332},{\"end\":71538,\"start\":71531},{\"end\":71540,\"start\":71539},{\"end\":71558,\"start\":71551},{\"end\":71571,\"start\":71566},{\"end\":71587,\"start\":71582},{\"end\":71604,\"start\":71599},{\"end\":71616,\"start\":71610},{\"end\":71618,\"start\":71617},{\"end\":71636,\"start\":71628},{\"end\":71649,\"start\":71644},{\"end\":71664,\"start\":71659},{\"end\":71679,\"start\":71673},{\"end\":71681,\"start\":71680},{\"end\":71922,\"start\":71915},{\"end\":71937,\"start\":71933},{\"end\":71939,\"start\":71938},{\"end\":71958,\"start\":71951},{\"end\":71975,\"start\":71968},{\"end\":72216,\"start\":72208},{\"end\":72233,\"start\":72226},{\"end\":72252,\"start\":72245},{\"end\":72264,\"start\":72260},{\"end\":72397,\"start\":72387},{\"end\":72409,\"start\":72404},{\"end\":72426,\"start\":72420},{\"end\":72442,\"start\":72435},{\"end\":72444,\"start\":72443},{\"end\":72461,\"start\":72455},{\"end\":72710,\"start\":72702},{\"end\":72727,\"start\":72724},{\"end\":72749,\"start\":72742},{\"end\":72762,\"start\":72759},{\"end\":72780,\"start\":72773},{\"end\":72948,\"start\":72941},{\"end\":72962,\"start\":72955},{\"end\":72977,\"start\":72973},{\"end\":72979,\"start\":72978},{\"end\":72995,\"start\":72991},{\"end\":73014,\"start\":73007},{\"end\":73212,\"start\":73206},{\"end\":73225,\"start\":73221},{\"end\":73244,\"start\":73238},{\"end\":73260,\"start\":73253},{\"end\":73278,\"start\":73271},{\"end\":73301,\"start\":73300},{\"end\":73303,\"start\":73302},{\"end\":73317,\"start\":73312},{\"end\":73325,\"start\":73318},{\"end\":73457,\"start\":73456},{\"end\":73470,\"start\":73469},{\"end\":73481,\"start\":73480},{\"end\":73495,\"start\":73494},{\"end\":73507,\"start\":73506},{\"end\":73517,\"start\":73516},{\"end\":73622,\"start\":73616},{\"end\":73635,\"start\":73632},{\"end\":73655,\"start\":73650},{\"end\":73672,\"start\":73665},{\"end\":73844,\"start\":73838},{\"end\":73857,\"start\":73854},{\"end\":73879,\"start\":73872},{\"end\":74094,\"start\":74086},{\"end\":74106,\"start\":74102},{\"end\":74119,\"start\":74114},{\"end\":74135,\"start\":74129},{\"end\":74150,\"start\":74147},{\"end\":74161,\"start\":74155},{\"end\":74393,\"start\":74385},{\"end\":74406,\"start\":74401},{\"end\":74419,\"start\":74414},{\"end\":74421,\"start\":74420},{\"end\":74438,\"start\":74431},{\"end\":74737,\"start\":74730},{\"end\":74756,\"start\":74747},{\"end\":74768,\"start\":74763},{\"end\":74782,\"start\":74778},{\"end\":75035,\"start\":75028},{\"end\":75050,\"start\":75045},{\"end\":75069,\"start\":75060},{\"end\":75080,\"start\":75076},{\"end\":75288,\"start\":75287},{\"end\":75290,\"start\":75289},{\"end\":75305,\"start\":75304},{\"end\":75544,\"start\":75536},{\"end\":75546,\"start\":75545},{\"end\":75567,\"start\":75560},{\"end\":75586,\"start\":75575},{\"end\":75598,\"start\":75594},{\"end\":75705,\"start\":75698},{\"end\":75717,\"start\":75713},{\"end\":75729,\"start\":75725},{\"end\":75739,\"start\":75736},{\"end\":75874,\"start\":75868},{\"end\":75890,\"start\":75883},{\"end\":75904,\"start\":75900},{\"end\":76047,\"start\":76041},{\"end\":76071,\"start\":76066},{\"end\":76087,\"start\":76079},{\"end\":76101,\"start\":76095},{\"end\":76118,\"start\":76111},{\"end\":76352,\"start\":76345},{\"end\":76377,\"start\":76371},{\"end\":76648,\"start\":76642},{\"end\":76666,\"start\":76661},{\"end\":76683,\"start\":76677},{\"end\":76790,\"start\":76785},{\"end\":76814,\"start\":76805},{\"end\":76827,\"start\":76821},{\"end\":77020,\"start\":77016},{\"end\":77035,\"start\":77031},{\"end\":77181,\"start\":77176},{\"end\":77196,\"start\":77189},{\"end\":77356,\"start\":77350},{\"end\":77372,\"start\":77364},{\"end\":77374,\"start\":77373},{\"end\":77392,\"start\":77388},{\"end\":77410,\"start\":77404},{\"end\":77412,\"start\":77411},{\"end\":77573,\"start\":77567},{\"end\":77588,\"start\":77582},{\"end\":77590,\"start\":77589},{\"end\":77608,\"start\":77605},{\"end\":77624,\"start\":77618},{\"end\":77626,\"start\":77625},{\"end\":77642,\"start\":77636},{\"end\":77752,\"start\":77745},{\"end\":77763,\"start\":77757},{\"end\":77776,\"start\":77770},{\"end\":77791,\"start\":77785},{\"end\":77804,\"start\":77796},{\"end\":77818,\"start\":77812},{\"end\":77834,\"start\":77825},{\"end\":78063,\"start\":78055},{\"end\":78074,\"start\":78068},{\"end\":78086,\"start\":78081},{\"end\":78102,\"start\":78095},{\"end\":78115,\"start\":78109},{\"end\":78378,\"start\":78374},{\"end\":78391,\"start\":78385},{\"end\":78404,\"start\":78397},{\"end\":78416,\"start\":78409},{\"end\":78546,\"start\":78535},{\"end\":78559,\"start\":78553},{\"end\":78571,\"start\":78566},{\"end\":78746,\"start\":78743},{\"end\":78759,\"start\":78754},{\"end\":78770,\"start\":78766},{\"end\":78937,\"start\":78928},{\"end\":78950,\"start\":78943},{\"end\":78966,\"start\":78960},{\"end\":78986,\"start\":78980},{\"end\":78988,\"start\":78987},{\"end\":79191,\"start\":79183},{\"end\":79206,\"start\":79198},{\"end\":79225,\"start\":79219},{\"end\":79322,\"start\":79315},{\"end\":79336,\"start\":79329},{\"end\":79445,\"start\":79438},{\"end\":79463,\"start\":79457},{\"end\":79477,\"start\":79469},{\"end\":79495,\"start\":79487},{\"end\":79504,\"start\":79500},{\"end\":79526,\"start\":79517},{\"end\":79545,\"start\":79537},{\"end\":79715,\"start\":79714},{\"end\":79728,\"start\":79727},{\"end\":79738,\"start\":79737},{\"end\":79749,\"start\":79748},{\"end\":79761,\"start\":79760},{\"end\":79772,\"start\":79771},{\"end\":79781,\"start\":79780}]", "bib_author_last_name": "[{\"end\":62241,\"start\":62236},{\"end\":62255,\"start\":62250},{\"end\":62266,\"start\":62261},{\"end\":62279,\"start\":62276},{\"end\":62402,\"start\":62395},{\"end\":62418,\"start\":62408},{\"end\":62432,\"start\":62427},{\"end\":62452,\"start\":62441},{\"end\":62470,\"start\":62463},{\"end\":62679,\"start\":62673},{\"end\":62697,\"start\":62690},{\"end\":62707,\"start\":62704},{\"end\":62723,\"start\":62716},{\"end\":62738,\"start\":62732},{\"end\":62756,\"start\":62747},{\"end\":62776,\"start\":62768},{\"end\":62896,\"start\":62889},{\"end\":62911,\"start\":62904},{\"end\":62924,\"start\":62920},{\"end\":62943,\"start\":62938},{\"end\":63113,\"start\":63108},{\"end\":63129,\"start\":63124},{\"end\":63152,\"start\":63142},{\"end\":63164,\"start\":63158},{\"end\":63182,\"start\":63174},{\"end\":63194,\"start\":63189},{\"end\":63205,\"start\":63203},{\"end\":63223,\"start\":63215},{\"end\":63237,\"start\":63232},{\"end\":63247,\"start\":63243},{\"end\":63261,\"start\":63259},{\"end\":63270,\"start\":63266},{\"end\":63281,\"start\":63279},{\"end\":63285,\"start\":63283},{\"end\":63380,\"start\":63376},{\"end\":63391,\"start\":63386},{\"end\":63627,\"start\":63618},{\"end\":63643,\"start\":63639},{\"end\":63660,\"start\":63654},{\"end\":63676,\"start\":63667},{\"end\":63823,\"start\":63816},{\"end\":63840,\"start\":63832},{\"end\":63858,\"start\":63849},{\"end\":64046,\"start\":64028},{\"end\":64059,\"start\":64057},{\"end\":64071,\"start\":64067},{\"end\":64084,\"start\":64080},{\"end\":64094,\"start\":64086},{\"end\":64297,\"start\":64290},{\"end\":64309,\"start\":64304},{\"end\":64619,\"start\":64609},{\"end\":64628,\"start\":64621},{\"end\":64635,\"start\":64630},{\"end\":64644,\"start\":64637},{\"end\":64768,\"start\":64765},{\"end\":64786,\"start\":64779},{\"end\":65017,\"start\":65014},{\"end\":65035,\"start\":65028},{\"end\":65054,\"start\":65045},{\"end\":65069,\"start\":65064},{\"end\":65089,\"start\":65081},{\"end\":65207,\"start\":65202},{\"end\":65223,\"start\":65217},{\"end\":65477,\"start\":65469},{\"end\":65494,\"start\":65487},{\"end\":65570,\"start\":65564},{\"end\":65586,\"start\":65582},{\"end\":65599,\"start\":65596},{\"end\":65612,\"start\":65607},{\"end\":65633,\"start\":65623},{\"end\":65733,\"start\":65727},{\"end\":65749,\"start\":65745},{\"end\":65764,\"start\":65758},{\"end\":65777,\"start\":65772},{\"end\":65796,\"start\":65789},{\"end\":65817,\"start\":65807},{\"end\":65913,\"start\":65909},{\"end\":65931,\"start\":65927},{\"end\":65945,\"start\":65940},{\"end\":65959,\"start\":65954},{\"end\":65975,\"start\":65966},{\"end\":66187,\"start\":66183},{\"end\":66205,\"start\":66201},{\"end\":66219,\"start\":66214},{\"end\":66235,\"start\":66226},{\"end\":66391,\"start\":66386},{\"end\":66402,\"start\":66400},{\"end\":66415,\"start\":66411},{\"end\":66427,\"start\":66423},{\"end\":66437,\"start\":66433},{\"end\":66453,\"start\":66445},{\"end\":66465,\"start\":66462},{\"end\":66479,\"start\":66477},{\"end\":66487,\"start\":66485},{\"end\":66609,\"start\":66602},{\"end\":66625,\"start\":66619},{\"end\":66648,\"start\":66636},{\"end\":66660,\"start\":66655},{\"end\":66851,\"start\":66849},{\"end\":66865,\"start\":66861},{\"end\":66880,\"start\":66875},{\"end\":66891,\"start\":66888},{\"end\":66900,\"start\":66896},{\"end\":67063,\"start\":67058},{\"end\":67078,\"start\":67073},{\"end\":67090,\"start\":67087},{\"end\":67107,\"start\":67100},{\"end\":67123,\"start\":67118},{\"end\":67141,\"start\":67134},{\"end\":67153,\"start\":67143},{\"end\":67381,\"start\":67376},{\"end\":67396,\"start\":67391},{\"end\":67408,\"start\":67405},{\"end\":67425,\"start\":67418},{\"end\":67441,\"start\":67436},{\"end\":67459,\"start\":67452},{\"end\":67471,\"start\":67461},{\"end\":67589,\"start\":67583},{\"end\":67604,\"start\":67598},{\"end\":67621,\"start\":67611},{\"end\":67637,\"start\":67627},{\"end\":67642,\"start\":67639},{\"end\":67654,\"start\":67648},{\"end\":67668,\"start\":67664},{\"end\":67676,\"start\":67670},{\"end\":67807,\"start\":67801},{\"end\":67822,\"start\":67816},{\"end\":67834,\"start\":67824},{\"end\":67846,\"start\":67840},{\"end\":67864,\"start\":67856},{\"end\":67872,\"start\":67866},{\"end\":67970,\"start\":67967},{\"end\":67986,\"start\":67982},{\"end\":68002,\"start\":67997},{\"end\":68132,\"start\":68127},{\"end\":68157,\"start\":68139},{\"end\":68173,\"start\":68167},{\"end\":68186,\"start\":68179},{\"end\":68200,\"start\":68194},{\"end\":68220,\"start\":68208},{\"end\":68229,\"start\":68222},{\"end\":68331,\"start\":68324},{\"end\":68347,\"start\":68340},{\"end\":68354,\"start\":68349},{\"end\":68468,\"start\":68462},{\"end\":68484,\"start\":68477},{\"end\":68500,\"start\":68493},{\"end\":68515,\"start\":68510},{\"end\":68528,\"start\":68521},{\"end\":68542,\"start\":68538},{\"end\":68705,\"start\":68697},{\"end\":68719,\"start\":68713},{\"end\":68723,\"start\":68721},{\"end\":68939,\"start\":68930},{\"end\":68952,\"start\":68948},{\"end\":68966,\"start\":68962},{\"end\":68982,\"start\":68976},{\"end\":69097,\"start\":69092},{\"end\":69110,\"start\":69105},{\"end\":69123,\"start\":69119},{\"end\":69139,\"start\":69132},{\"end\":69249,\"start\":69242},{\"end\":69265,\"start\":69259},{\"end\":69280,\"start\":69275},{\"end\":69299,\"start\":69288},{\"end\":69315,\"start\":69306},{\"end\":69464,\"start\":69457},{\"end\":69477,\"start\":69470},{\"end\":69491,\"start\":69487},{\"end\":69671,\"start\":69668},{\"end\":69687,\"start\":69682},{\"end\":69700,\"start\":69696},{\"end\":69708,\"start\":69706},{\"end\":69836,\"start\":69831},{\"end\":69850,\"start\":69843},{\"end\":69868,\"start\":69858},{\"end\":69881,\"start\":69870},{\"end\":69911,\"start\":69891},{\"end\":69922,\"start\":69919},{\"end\":69931,\"start\":69924},{\"end\":70097,\"start\":70094},{\"end\":70110,\"start\":70105},{\"end\":70124,\"start\":70120},{\"end\":70135,\"start\":70132},{\"end\":70151,\"start\":70142},{\"end\":70165,\"start\":70162},{\"end\":70414,\"start\":70407},{\"end\":70429,\"start\":70420},{\"end\":70449,\"start\":70439},{\"end\":70650,\"start\":70642},{\"end\":70663,\"start\":70658},{\"end\":70681,\"start\":70674},{\"end\":70701,\"start\":70690},{\"end\":70823,\"start\":70817},{\"end\":70837,\"start\":70831},{\"end\":70851,\"start\":70844},{\"end\":70974,\"start\":70965},{\"end\":70991,\"start\":70984},{\"end\":71009,\"start\":71001},{\"end\":71028,\"start\":71021},{\"end\":71044,\"start\":71038},{\"end\":71277,\"start\":71272},{\"end\":71300,\"start\":71285},{\"end\":71317,\"start\":71307},{\"end\":71330,\"start\":71325},{\"end\":71353,\"start\":71339},{\"end\":71365,\"start\":71355},{\"end\":71549,\"start\":71541},{\"end\":71564,\"start\":71559},{\"end\":71580,\"start\":71572},{\"end\":71597,\"start\":71588},{\"end\":71608,\"start\":71605},{\"end\":71626,\"start\":71619},{\"end\":71642,\"start\":71637},{\"end\":71657,\"start\":71650},{\"end\":71671,\"start\":71665},{\"end\":71692,\"start\":71682},{\"end\":71931,\"start\":71923},{\"end\":71949,\"start\":71940},{\"end\":71966,\"start\":71959},{\"end\":71982,\"start\":71976},{\"end\":72224,\"start\":72217},{\"end\":72243,\"start\":72234},{\"end\":72258,\"start\":72253},{\"end\":72275,\"start\":72265},{\"end\":72402,\"start\":72398},{\"end\":72418,\"start\":72410},{\"end\":72433,\"start\":72427},{\"end\":72453,\"start\":72445},{\"end\":72471,\"start\":72462},{\"end\":72722,\"start\":72711},{\"end\":72740,\"start\":72728},{\"end\":72757,\"start\":72750},{\"end\":72771,\"start\":72763},{\"end\":72787,\"start\":72781},{\"end\":72953,\"start\":72949},{\"end\":72971,\"start\":72963},{\"end\":72989,\"start\":72980},{\"end\":73005,\"start\":72996},{\"end\":73021,\"start\":73015},{\"end\":73219,\"start\":73213},{\"end\":73236,\"start\":73226},{\"end\":73251,\"start\":73245},{\"end\":73269,\"start\":73261},{\"end\":73287,\"start\":73279},{\"end\":73298,\"start\":73289},{\"end\":73310,\"start\":73304},{\"end\":73330,\"start\":73326},{\"end\":73338,\"start\":73332},{\"end\":73467,\"start\":73458},{\"end\":73478,\"start\":73471},{\"end\":73492,\"start\":73482},{\"end\":73504,\"start\":73496},{\"end\":73514,\"start\":73508},{\"end\":73523,\"start\":73518},{\"end\":73630,\"start\":73623},{\"end\":73648,\"start\":73636},{\"end\":73663,\"start\":73656},{\"end\":73679,\"start\":73673},{\"end\":73852,\"start\":73845},{\"end\":73870,\"start\":73858},{\"end\":73886,\"start\":73880},{\"end\":74100,\"start\":74095},{\"end\":74112,\"start\":74107},{\"end\":74127,\"start\":74120},{\"end\":74145,\"start\":74136},{\"end\":74153,\"start\":74151},{\"end\":74170,\"start\":74162},{\"end\":74399,\"start\":74394},{\"end\":74412,\"start\":74407},{\"end\":74429,\"start\":74422},{\"end\":74442,\"start\":74439},{\"end\":74745,\"start\":74738},{\"end\":74761,\"start\":74757},{\"end\":74776,\"start\":74769},{\"end\":74792,\"start\":74783},{\"end\":75043,\"start\":75036},{\"end\":75058,\"start\":75051},{\"end\":75074,\"start\":75070},{\"end\":75090,\"start\":75081},{\"end\":75302,\"start\":75291},{\"end\":75311,\"start\":75306},{\"end\":75558,\"start\":75547},{\"end\":75573,\"start\":75568},{\"end\":75592,\"start\":75587},{\"end\":75608,\"start\":75599},{\"end\":75711,\"start\":75706},{\"end\":75723,\"start\":75718},{\"end\":75734,\"start\":75730},{\"end\":75747,\"start\":75740},{\"end\":75881,\"start\":75875},{\"end\":75898,\"start\":75891},{\"end\":75914,\"start\":75905},{\"end\":76064,\"start\":76048},{\"end\":76077,\"start\":76072},{\"end\":76093,\"start\":76088},{\"end\":76109,\"start\":76102},{\"end\":76128,\"start\":76119},{\"end\":76139,\"start\":76130},{\"end\":76369,\"start\":76353},{\"end\":76387,\"start\":76378},{\"end\":76398,\"start\":76389},{\"end\":76659,\"start\":76649},{\"end\":76675,\"start\":76667},{\"end\":76697,\"start\":76684},{\"end\":76803,\"start\":76791},{\"end\":76819,\"start\":76815},{\"end\":76835,\"start\":76828},{\"end\":77029,\"start\":77021},{\"end\":77042,\"start\":77036},{\"end\":77187,\"start\":77182},{\"end\":77203,\"start\":77197},{\"end\":77362,\"start\":77357},{\"end\":77386,\"start\":77375},{\"end\":77402,\"start\":77393},{\"end\":77419,\"start\":77413},{\"end\":77580,\"start\":77574},{\"end\":77603,\"start\":77591},{\"end\":77616,\"start\":77609},{\"end\":77634,\"start\":77627},{\"end\":77654,\"start\":77643},{\"end\":77755,\"start\":77753},{\"end\":77768,\"start\":77764},{\"end\":77783,\"start\":77777},{\"end\":77794,\"start\":77792},{\"end\":77810,\"start\":77805},{\"end\":77823,\"start\":77819},{\"end\":77839,\"start\":77835},{\"end\":78066,\"start\":78064},{\"end\":78079,\"start\":78075},{\"end\":78093,\"start\":78087},{\"end\":78107,\"start\":78103},{\"end\":78123,\"start\":78116},{\"end\":78383,\"start\":78379},{\"end\":78395,\"start\":78392},{\"end\":78407,\"start\":78405},{\"end\":78421,\"start\":78417},{\"end\":78551,\"start\":78547},{\"end\":78564,\"start\":78560},{\"end\":78579,\"start\":78572},{\"end\":78752,\"start\":78747},{\"end\":78764,\"start\":78760},{\"end\":78774,\"start\":78771},{\"end\":78941,\"start\":78938},{\"end\":78958,\"start\":78951},{\"end\":78978,\"start\":78967},{\"end\":78996,\"start\":78989},{\"end\":79196,\"start\":79192},{\"end\":79217,\"start\":79207},{\"end\":79230,\"start\":79226},{\"end\":79327,\"start\":79323},{\"end\":79343,\"start\":79337},{\"end\":79455,\"start\":79446},{\"end\":79467,\"start\":79464},{\"end\":79485,\"start\":79478},{\"end\":79498,\"start\":79496},{\"end\":79515,\"start\":79505},{\"end\":79535,\"start\":79527},{\"end\":79553,\"start\":79546},{\"end\":79725,\"start\":79716},{\"end\":79735,\"start\":79729},{\"end\":79746,\"start\":79739},{\"end\":79758,\"start\":79750},{\"end\":79769,\"start\":79762},{\"end\":79778,\"start\":79773},{\"end\":79786,\"start\":79782}]", "bib_entry": "[{\"attributes\":{\"doi\":\"CoRR, abs/2001.01744\",\"id\":\"b0\"},\"end\":62305,\"start\":62184},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":4624670},\"end\":62588,\"start\":62307},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":214623267},\"end\":63053,\"start\":62590},{\"attributes\":{\"doi\":\"CoRR, abs/1512.03012\",\"id\":\"b3\"},\"end\":63311,\"start\":63055},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":54457478},\"end\":63553,\"start\":63313},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":22155964},\"end\":63727,\"start\":63555},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":211817828},\"end\":63939,\"start\":63729},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":6325059},\"end\":64215,\"start\":63941},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":12358833},\"end\":64548,\"start\":64217},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":210701396},\"end\":64689,\"start\":64550},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":4408791},\"end\":64903,\"start\":64691},{\"attributes\":{\"id\":\"b11\"},\"end\":65118,\"start\":64905},{\"attributes\":{\"id\":\"b12\"},\"end\":65418,\"start\":65120},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":53234888},\"end\":65521,\"start\":65420},{\"attributes\":{\"doi\":\"CoRR, abs/1912.06126\",\"id\":\"b14\"},\"end\":65659,\"start\":65523},{\"attributes\":{\"doi\":\"CoRR, abs/1904.06447\",\"id\":\"b15\"},\"end\":65843,\"start\":65661},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":6868780},\"end\":66137,\"start\":65845},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":24859917},\"end\":66308,\"start\":66139},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":52955951},\"end\":66770,\"start\":66310},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":9035204},\"end\":67001,\"start\":66772},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":214606025},\"end\":67319,\"start\":67003},{\"attributes\":{\"doi\":\"CoRR, abs/2003.08981\",\"id\":\"b21\"},\"end\":67497,\"start\":67321},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":10809456},\"end\":67718,\"start\":67499},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":14266582},\"end\":67918,\"start\":67720},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":19285959},\"end\":68279,\"start\":67920},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":1371704},\"end\":68383,\"start\":68281},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":17260589},\"end\":68649,\"start\":68385},{\"attributes\":{\"doi\":\"ICLR 2015\",\"id\":\"b27\",\"matched_paper_id\":6628106},\"end\":68857,\"start\":68651},{\"attributes\":{\"id\":\"b28\"},\"end\":69021,\"start\":68859},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1730515},\"end\":69190,\"start\":69023},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":7791671},\"end\":69416,\"start\":69192},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":12271369},\"end\":69598,\"start\":69418},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":202785348},\"end\":69993,\"start\":69600},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":208512845},\"end\":70331,\"start\":69995},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":9151627},\"end\":70557,\"start\":70333},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":206852649},\"end\":70751,\"start\":70559},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":16768404},\"end\":70890,\"start\":70753},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":54465161},\"end\":71206,\"start\":70892},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":214612128},\"end\":71469,\"start\":71208},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":11830123},\"end\":71815,\"start\":71471},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":209376368},\"end\":72148,\"start\":71817},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":207207064},\"end\":72304,\"start\":72150},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":58007025},\"end\":72633,\"start\":72306},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":43992332},\"end\":72905,\"start\":72635},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":212646575},\"end\":73125,\"start\":72907},{\"attributes\":{\"doi\":\"CoRR, abs/1708.00783\",\"id\":\"b45\"},\"end\":73364,\"start\":73127},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":208881001},\"end\":73567,\"start\":73366},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":17104434},\"end\":73774,\"start\":73569},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":206596552},\"end\":73998,\"start\":73776},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":152282359},\"end\":74288,\"start\":74000},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":214743286},\"end\":74608,\"start\":74290},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":14329201},\"end\":74954,\"start\":74610},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":2600475},\"end\":75252,\"start\":74956},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":1728538},\"end\":75473,\"start\":75254},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":977535},\"end\":75810,\"start\":75475},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":52898857},\"end\":75984,\"start\":75812},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":54444417},\"end\":76253,\"start\":75986},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":174798113},\"end\":76580,\"start\":76255},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":11699847},\"end\":76709,\"start\":76582},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":13035872},\"end\":76939,\"start\":76711},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":11828469},\"end\":77101,\"start\":76941},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":46901688},\"end\":77297,\"start\":77103},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":210165091},\"end\":77501,\"start\":77299},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":21124365},\"end\":77684,\"start\":77503},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":206592833},\"end\":77969,\"start\":77686},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":166228177},\"end\":78305,\"start\":77971},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":6311373},\"end\":78462,\"start\":78307},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":2428913},\"end\":78693,\"start\":78464},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":10694510},\"end\":78830,\"start\":78695},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":80628300},\"end\":79110,\"start\":78832},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":201815307},\"end\":79261,\"start\":79112},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":14440062},\"end\":79370,\"start\":79263},{\"attributes\":{\"doi\":\"96:1-96:14\",\"id\":\"b72\",\"matched_paper_id\":14670870},\"end\":79590,\"start\":79372},{\"attributes\":{\"id\":\"b73\"},\"end\":79800,\"start\":79592}]", "bib_title": "[{\"end\":62385,\"start\":62307},{\"end\":62665,\"start\":62590},{\"end\":63367,\"start\":63313},{\"end\":63612,\"start\":63555},{\"end\":63807,\"start\":63729},{\"end\":64019,\"start\":63941},{\"end\":64282,\"start\":64217},{\"end\":64607,\"start\":64550},{\"end\":64756,\"start\":64691},{\"end\":65005,\"start\":64905},{\"end\":65194,\"start\":65120},{\"end\":65461,\"start\":65420},{\"end\":65897,\"start\":65845},{\"end\":66171,\"start\":66139},{\"end\":66379,\"start\":66310},{\"end\":66840,\"start\":66772},{\"end\":67052,\"start\":67003},{\"end\":67576,\"start\":67499},{\"end\":67794,\"start\":67720},{\"end\":67956,\"start\":67920},{\"end\":68320,\"start\":68281},{\"end\":68455,\"start\":68385},{\"end\":68693,\"start\":68651},{\"end\":68923,\"start\":68859},{\"end\":69084,\"start\":69023},{\"end\":69234,\"start\":69192},{\"end\":69448,\"start\":69418},{\"end\":69658,\"start\":69600},{\"end\":70084,\"start\":69995},{\"end\":70400,\"start\":70333},{\"end\":70635,\"start\":70559},{\"end\":70809,\"start\":70753},{\"end\":70956,\"start\":70892},{\"end\":71266,\"start\":71208},{\"end\":71529,\"start\":71471},{\"end\":71913,\"start\":71817},{\"end\":72206,\"start\":72150},{\"end\":72385,\"start\":72306},{\"end\":72700,\"start\":72635},{\"end\":72939,\"start\":72907},{\"end\":73454,\"start\":73366},{\"end\":73614,\"start\":73569},{\"end\":73836,\"start\":73776},{\"end\":74084,\"start\":74000},{\"end\":74383,\"start\":74290},{\"end\":74728,\"start\":74610},{\"end\":75026,\"start\":74956},{\"end\":75285,\"start\":75254},{\"end\":75534,\"start\":75475},{\"end\":75866,\"start\":75812},{\"end\":76039,\"start\":75986},{\"end\":76343,\"start\":76255},{\"end\":76640,\"start\":76582},{\"end\":76783,\"start\":76711},{\"end\":77014,\"start\":76941},{\"end\":77174,\"start\":77103},{\"end\":77348,\"start\":77299},{\"end\":77565,\"start\":77503},{\"end\":77743,\"start\":77686},{\"end\":78053,\"start\":77971},{\"end\":78372,\"start\":78307},{\"end\":78533,\"start\":78464},{\"end\":78741,\"start\":78695},{\"end\":78926,\"start\":78832},{\"end\":79181,\"start\":79112},{\"end\":79313,\"start\":79263},{\"end\":79436,\"start\":79372}]", "bib_author": "[{\"end\":62243,\"start\":62227},{\"end\":62257,\"start\":62243},{\"end\":62268,\"start\":62257},{\"end\":62281,\"start\":62268},{\"end\":62404,\"start\":62387},{\"end\":62420,\"start\":62404},{\"end\":62434,\"start\":62420},{\"end\":62454,\"start\":62434},{\"end\":62472,\"start\":62454},{\"end\":62681,\"start\":62667},{\"end\":62699,\"start\":62681},{\"end\":62709,\"start\":62699},{\"end\":62725,\"start\":62709},{\"end\":62740,\"start\":62725},{\"end\":62758,\"start\":62740},{\"end\":62778,\"start\":62758},{\"end\":63115,\"start\":63106},{\"end\":63131,\"start\":63115},{\"end\":63154,\"start\":63131},{\"end\":63166,\"start\":63154},{\"end\":63184,\"start\":63166},{\"end\":63196,\"start\":63184},{\"end\":63207,\"start\":63196},{\"end\":63225,\"start\":63207},{\"end\":63239,\"start\":63225},{\"end\":63249,\"start\":63239},{\"end\":63263,\"start\":63249},{\"end\":63272,\"start\":63263},{\"end\":63283,\"start\":63272},{\"end\":63287,\"start\":63283},{\"end\":63382,\"start\":63369},{\"end\":63393,\"start\":63382},{\"end\":63629,\"start\":63614},{\"end\":63645,\"start\":63629},{\"end\":63662,\"start\":63645},{\"end\":63678,\"start\":63662},{\"end\":63825,\"start\":63809},{\"end\":63842,\"start\":63825},{\"end\":63860,\"start\":63842},{\"end\":64048,\"start\":64021},{\"end\":64061,\"start\":64048},{\"end\":64073,\"start\":64061},{\"end\":64086,\"start\":64073},{\"end\":64096,\"start\":64086},{\"end\":64299,\"start\":64284},{\"end\":64311,\"start\":64299},{\"end\":64621,\"start\":64609},{\"end\":64630,\"start\":64621},{\"end\":64637,\"start\":64630},{\"end\":64646,\"start\":64637},{\"end\":64770,\"start\":64758},{\"end\":64788,\"start\":64770},{\"end\":65019,\"start\":65007},{\"end\":65037,\"start\":65019},{\"end\":65056,\"start\":65037},{\"end\":65071,\"start\":65056},{\"end\":65091,\"start\":65071},{\"end\":65209,\"start\":65196},{\"end\":65225,\"start\":65209},{\"end\":65479,\"start\":65463},{\"end\":65496,\"start\":65479},{\"end\":65572,\"start\":65559},{\"end\":65588,\"start\":65572},{\"end\":65601,\"start\":65588},{\"end\":65614,\"start\":65601},{\"end\":65635,\"start\":65614},{\"end\":65735,\"start\":65722},{\"end\":65751,\"start\":65735},{\"end\":65766,\"start\":65751},{\"end\":65779,\"start\":65766},{\"end\":65798,\"start\":65779},{\"end\":65819,\"start\":65798},{\"end\":65915,\"start\":65899},{\"end\":65933,\"start\":65915},{\"end\":65947,\"start\":65933},{\"end\":65961,\"start\":65947},{\"end\":65977,\"start\":65961},{\"end\":66189,\"start\":66173},{\"end\":66207,\"start\":66189},{\"end\":66221,\"start\":66207},{\"end\":66237,\"start\":66221},{\"end\":66393,\"start\":66381},{\"end\":66404,\"start\":66393},{\"end\":66417,\"start\":66404},{\"end\":66429,\"start\":66417},{\"end\":66439,\"start\":66429},{\"end\":66455,\"start\":66439},{\"end\":66467,\"start\":66455},{\"end\":66481,\"start\":66467},{\"end\":66489,\"start\":66481},{\"end\":66853,\"start\":66842},{\"end\":66867,\"start\":66853},{\"end\":66882,\"start\":66867},{\"end\":66893,\"start\":66882},{\"end\":66902,\"start\":66893},{\"end\":67065,\"start\":67054},{\"end\":67080,\"start\":67065},{\"end\":67092,\"start\":67080},{\"end\":67109,\"start\":67092},{\"end\":67125,\"start\":67109},{\"end\":67143,\"start\":67125},{\"end\":67155,\"start\":67143},{\"end\":67383,\"start\":67372},{\"end\":67398,\"start\":67383},{\"end\":67410,\"start\":67398},{\"end\":67427,\"start\":67410},{\"end\":67443,\"start\":67427},{\"end\":67461,\"start\":67443},{\"end\":67473,\"start\":67461},{\"end\":67591,\"start\":67578},{\"end\":67606,\"start\":67591},{\"end\":67623,\"start\":67606},{\"end\":67639,\"start\":67623},{\"end\":67644,\"start\":67639},{\"end\":67656,\"start\":67644},{\"end\":67670,\"start\":67656},{\"end\":67678,\"start\":67670},{\"end\":67809,\"start\":67796},{\"end\":67824,\"start\":67809},{\"end\":67836,\"start\":67824},{\"end\":67848,\"start\":67836},{\"end\":67866,\"start\":67848},{\"end\":67874,\"start\":67866},{\"end\":67972,\"start\":67958},{\"end\":67988,\"start\":67972},{\"end\":68004,\"start\":67988},{\"end\":68333,\"start\":68322},{\"end\":68349,\"start\":68333},{\"end\":68356,\"start\":68349},{\"end\":68470,\"start\":68457},{\"end\":68486,\"start\":68470},{\"end\":68502,\"start\":68486},{\"end\":68517,\"start\":68502},{\"end\":68530,\"start\":68517},{\"end\":68544,\"start\":68530},{\"end\":68707,\"start\":68695},{\"end\":68721,\"start\":68707},{\"end\":68725,\"start\":68721},{\"end\":68941,\"start\":68925},{\"end\":68954,\"start\":68941},{\"end\":68968,\"start\":68954},{\"end\":68984,\"start\":68968},{\"end\":69099,\"start\":69086},{\"end\":69112,\"start\":69099},{\"end\":69125,\"start\":69112},{\"end\":69141,\"start\":69125},{\"end\":69251,\"start\":69236},{\"end\":69267,\"start\":69251},{\"end\":69282,\"start\":69267},{\"end\":69301,\"start\":69282},{\"end\":69317,\"start\":69301},{\"end\":69466,\"start\":69450},{\"end\":69479,\"start\":69466},{\"end\":69493,\"start\":69479},{\"end\":69673,\"start\":69660},{\"end\":69689,\"start\":69673},{\"end\":69702,\"start\":69689},{\"end\":69710,\"start\":69702},{\"end\":70099,\"start\":70086},{\"end\":70112,\"start\":70099},{\"end\":70126,\"start\":70112},{\"end\":70137,\"start\":70126},{\"end\":70153,\"start\":70137},{\"end\":70167,\"start\":70153},{\"end\":70416,\"start\":70402},{\"end\":70431,\"start\":70416},{\"end\":70451,\"start\":70431},{\"end\":70652,\"start\":70637},{\"end\":70665,\"start\":70652},{\"end\":70683,\"start\":70665},{\"end\":70703,\"start\":70683},{\"end\":70825,\"start\":70811},{\"end\":70839,\"start\":70825},{\"end\":70853,\"start\":70839},{\"end\":70976,\"start\":70958},{\"end\":70993,\"start\":70976},{\"end\":71011,\"start\":70993},{\"end\":71030,\"start\":71011},{\"end\":71046,\"start\":71030},{\"end\":71279,\"start\":71268},{\"end\":71302,\"start\":71279},{\"end\":71319,\"start\":71302},{\"end\":71332,\"start\":71319},{\"end\":71355,\"start\":71332},{\"end\":71367,\"start\":71355},{\"end\":71551,\"start\":71531},{\"end\":71566,\"start\":71551},{\"end\":71582,\"start\":71566},{\"end\":71599,\"start\":71582},{\"end\":71610,\"start\":71599},{\"end\":71628,\"start\":71610},{\"end\":71644,\"start\":71628},{\"end\":71659,\"start\":71644},{\"end\":71673,\"start\":71659},{\"end\":71694,\"start\":71673},{\"end\":71933,\"start\":71915},{\"end\":71951,\"start\":71933},{\"end\":71968,\"start\":71951},{\"end\":71984,\"start\":71968},{\"end\":72226,\"start\":72208},{\"end\":72245,\"start\":72226},{\"end\":72260,\"start\":72245},{\"end\":72277,\"start\":72260},{\"end\":72404,\"start\":72387},{\"end\":72420,\"start\":72404},{\"end\":72435,\"start\":72420},{\"end\":72455,\"start\":72435},{\"end\":72473,\"start\":72455},{\"end\":72724,\"start\":72702},{\"end\":72742,\"start\":72724},{\"end\":72759,\"start\":72742},{\"end\":72773,\"start\":72759},{\"end\":72789,\"start\":72773},{\"end\":72955,\"start\":72941},{\"end\":72973,\"start\":72955},{\"end\":72991,\"start\":72973},{\"end\":73007,\"start\":72991},{\"end\":73023,\"start\":73007},{\"end\":73221,\"start\":73206},{\"end\":73238,\"start\":73221},{\"end\":73253,\"start\":73238},{\"end\":73271,\"start\":73253},{\"end\":73289,\"start\":73271},{\"end\":73300,\"start\":73289},{\"end\":73312,\"start\":73300},{\"end\":73332,\"start\":73312},{\"end\":73340,\"start\":73332},{\"end\":73469,\"start\":73456},{\"end\":73480,\"start\":73469},{\"end\":73494,\"start\":73480},{\"end\":73506,\"start\":73494},{\"end\":73516,\"start\":73506},{\"end\":73525,\"start\":73516},{\"end\":73632,\"start\":73616},{\"end\":73650,\"start\":73632},{\"end\":73665,\"start\":73650},{\"end\":73681,\"start\":73665},{\"end\":73854,\"start\":73838},{\"end\":73872,\"start\":73854},{\"end\":73888,\"start\":73872},{\"end\":74102,\"start\":74086},{\"end\":74114,\"start\":74102},{\"end\":74129,\"start\":74114},{\"end\":74147,\"start\":74129},{\"end\":74155,\"start\":74147},{\"end\":74172,\"start\":74155},{\"end\":74401,\"start\":74385},{\"end\":74414,\"start\":74401},{\"end\":74431,\"start\":74414},{\"end\":74444,\"start\":74431},{\"end\":74747,\"start\":74730},{\"end\":74763,\"start\":74747},{\"end\":74778,\"start\":74763},{\"end\":74794,\"start\":74778},{\"end\":75045,\"start\":75028},{\"end\":75060,\"start\":75045},{\"end\":75076,\"start\":75060},{\"end\":75092,\"start\":75076},{\"end\":75304,\"start\":75287},{\"end\":75313,\"start\":75304},{\"end\":75560,\"start\":75536},{\"end\":75575,\"start\":75560},{\"end\":75594,\"start\":75575},{\"end\":75610,\"start\":75594},{\"end\":75883,\"start\":75868},{\"end\":75900,\"start\":75883},{\"end\":75916,\"start\":75900},{\"end\":76066,\"start\":76041},{\"end\":76079,\"start\":76066},{\"end\":76095,\"start\":76079},{\"end\":76111,\"start\":76095},{\"end\":76130,\"start\":76111},{\"end\":76141,\"start\":76130},{\"end\":76371,\"start\":76345},{\"end\":76389,\"start\":76371},{\"end\":76400,\"start\":76389},{\"end\":76661,\"start\":76642},{\"end\":76677,\"start\":76661},{\"end\":76699,\"start\":76677},{\"end\":76805,\"start\":76785},{\"end\":76821,\"start\":76805},{\"end\":76837,\"start\":76821},{\"end\":77031,\"start\":77016},{\"end\":77044,\"start\":77031},{\"end\":77189,\"start\":77176},{\"end\":77205,\"start\":77189},{\"end\":77364,\"start\":77350},{\"end\":77388,\"start\":77364},{\"end\":77404,\"start\":77388},{\"end\":77421,\"start\":77404},{\"end\":77582,\"start\":77567},{\"end\":77605,\"start\":77582},{\"end\":77618,\"start\":77605},{\"end\":77636,\"start\":77618},{\"end\":77656,\"start\":77636},{\"end\":77757,\"start\":77745},{\"end\":77770,\"start\":77757},{\"end\":77785,\"start\":77770},{\"end\":77796,\"start\":77785},{\"end\":77812,\"start\":77796},{\"end\":77825,\"start\":77812},{\"end\":77841,\"start\":77825},{\"end\":78068,\"start\":78055},{\"end\":78081,\"start\":78068},{\"end\":78095,\"start\":78081},{\"end\":78109,\"start\":78095},{\"end\":78125,\"start\":78109},{\"end\":78385,\"start\":78374},{\"end\":78397,\"start\":78385},{\"end\":78409,\"start\":78397},{\"end\":78423,\"start\":78409},{\"end\":78553,\"start\":78535},{\"end\":78566,\"start\":78553},{\"end\":78581,\"start\":78566},{\"end\":78754,\"start\":78743},{\"end\":78766,\"start\":78754},{\"end\":78776,\"start\":78766},{\"end\":78943,\"start\":78928},{\"end\":78960,\"start\":78943},{\"end\":78980,\"start\":78960},{\"end\":78998,\"start\":78980},{\"end\":79198,\"start\":79183},{\"end\":79219,\"start\":79198},{\"end\":79232,\"start\":79219},{\"end\":79329,\"start\":79315},{\"end\":79345,\"start\":79329},{\"end\":79457,\"start\":79438},{\"end\":79469,\"start\":79457},{\"end\":79487,\"start\":79469},{\"end\":79500,\"start\":79487},{\"end\":79517,\"start\":79500},{\"end\":79537,\"start\":79517},{\"end\":79555,\"start\":79537},{\"end\":79727,\"start\":79714},{\"end\":79737,\"start\":79727},{\"end\":79748,\"start\":79737},{\"end\":79760,\"start\":79748},{\"end\":79771,\"start\":79760},{\"end\":79780,\"start\":79771},{\"end\":79788,\"start\":79780}]", "bib_venue": "[{\"end\":62225,\"start\":62184},{\"end\":62535,\"start\":62472},{\"end\":62880,\"start\":62778},{\"end\":63104,\"start\":63055},{\"end\":63473,\"start\":63393},{\"end\":63721,\"start\":63678},{\"end\":63925,\"start\":63860},{\"end\":64160,\"start\":64096},{\"end\":64415,\"start\":64311},{\"end\":64682,\"start\":64646},{\"end\":64840,\"start\":64788},{\"end\":65107,\"start\":65091},{\"end\":65305,\"start\":65225},{\"end\":65512,\"start\":65496},{\"end\":65557,\"start\":65523},{\"end\":65720,\"start\":65661},{\"end\":66057,\"start\":65977},{\"end\":66299,\"start\":66237},{\"end\":66591,\"start\":66489},{\"end\":66961,\"start\":66902},{\"end\":67235,\"start\":67155},{\"end\":67370,\"start\":67321},{\"end\":67708,\"start\":67678},{\"end\":67910,\"start\":67874},{\"end\":68116,\"start\":68004},{\"end\":68372,\"start\":68356},{\"end\":68596,\"start\":68544},{\"end\":68790,\"start\":68734},{\"end\":69012,\"start\":68984},{\"end\":69181,\"start\":69141},{\"end\":69376,\"start\":69317},{\"end\":69557,\"start\":69493},{\"end\":69827,\"start\":69710},{\"end\":70247,\"start\":70167},{\"end\":70504,\"start\":70451},{\"end\":70707,\"start\":70703},{\"end\":70882,\"start\":70853},{\"end\":71126,\"start\":71046},{\"end\":71418,\"start\":71367},{\"end\":71770,\"start\":71694},{\"end\":72064,\"start\":71984},{\"end\":72293,\"start\":72277},{\"end\":72553,\"start\":72473},{\"end\":72852,\"start\":72789},{\"end\":73074,\"start\":73023},{\"end\":73204,\"start\":73127},{\"end\":73561,\"start\":73525},{\"end\":73733,\"start\":73681},{\"end\":73951,\"start\":73888},{\"end\":74228,\"start\":74172},{\"end\":74524,\"start\":74444},{\"end\":74874,\"start\":74794},{\"end\":75172,\"start\":75092},{\"end\":75393,\"start\":75313},{\"end\":75661,\"start\":75610},{\"end\":75696,\"start\":75663},{\"end\":75978,\"start\":75916},{\"end\":76210,\"start\":76141},{\"end\":76512,\"start\":76400},{\"end\":76703,\"start\":76699},{\"end\":76896,\"start\":76837},{\"end\":77092,\"start\":77044},{\"end\":77270,\"start\":77205},{\"end\":77490,\"start\":77421},{\"end\":77674,\"start\":77656},{\"end\":77910,\"start\":77841},{\"end\":78237,\"start\":78125},{\"end\":78453,\"start\":78423},{\"end\":78637,\"start\":78581},{\"end\":78817,\"start\":78776},{\"end\":79067,\"start\":78998},{\"end\":79251,\"start\":79232},{\"end\":79361,\"start\":79345},{\"end\":79581,\"start\":79565},{\"end\":79712,\"start\":79592},{\"end\":62560,\"start\":62537},{\"end\":63041,\"start\":62945},{\"end\":63549,\"start\":63475},{\"end\":64211,\"start\":64162},{\"end\":64526,\"start\":64417},{\"end\":64857,\"start\":64842},{\"end\":65381,\"start\":65307},{\"end\":66133,\"start\":66059},{\"end\":66758,\"start\":66662},{\"end\":66976,\"start\":66963},{\"end\":67311,\"start\":67237},{\"end\":68250,\"start\":68231},{\"end\":68622,\"start\":68598},{\"end\":68810,\"start\":68792},{\"end\":69391,\"start\":69378},{\"end\":69578,\"start\":69559},{\"end\":69963,\"start\":69933},{\"end\":70323,\"start\":70249},{\"end\":70553,\"start\":70506},{\"end\":71202,\"start\":71128},{\"end\":71465,\"start\":71420},{\"end\":71790,\"start\":71772},{\"end\":72140,\"start\":72066},{\"end\":72629,\"start\":72555},{\"end\":72877,\"start\":72854},{\"end\":73121,\"start\":73076},{\"end\":73749,\"start\":73735},{\"end\":73970,\"start\":73953},{\"end\":74280,\"start\":74230},{\"end\":74600,\"start\":74526},{\"end\":74950,\"start\":74876},{\"end\":75248,\"start\":75174},{\"end\":75469,\"start\":75395},{\"end\":75794,\"start\":75749},{\"end\":76231,\"start\":76212},{\"end\":76544,\"start\":76514},{\"end\":76915,\"start\":76898},{\"end\":77927,\"start\":77912},{\"end\":78269,\"start\":78239},{\"end\":78689,\"start\":78639},{\"end\":79088,\"start\":79069}]"}}}, "year": 2023, "month": 12, "day": 17}