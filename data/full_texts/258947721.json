{"id": 258947721, "updated": "2023-12-02 14:06:43.172", "metadata": {"title": "PandaGPT: One Model To Instruction-Follow Them All", "authors": "[{\"first\":\"Yixuan\",\"last\":\"Su\",\"middle\":[]},{\"first\":\"Tian\",\"last\":\"Lan\",\"middle\":[]},{\"first\":\"Huayang\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Jialu\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Yan\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Deng\",\"last\":\"Cai\",\"middle\":[]}]", "venue": "TLLM", "journal": "Proceedings of the 1st Workshop on Taming Large Language Models: Controllability in the era of Interactive Assistants!", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "We present PandaGPT, an approach to emPower large lANguage moDels with visual and Auditory instruction-following capabilities. Our pilot experiments show that PandaGPT can perform complex tasks such as detailed image description generation, writing stories inspired by videos, and answering questions about audios. More interestingly, PandaGPT can take multimodal inputs simultaneously and compose their semantics naturally. For example, PandaGPT can connect how objects look in an image/video and how they sound in an audio. To do so, PandaGPT combines the multimodal encoders from ImageBind and the large language models from Vicuna. Notably, only aligned image-text pairs are required for the training of PandaGPT. Thanks to the strong capability of ImageBind in embedding data from different modalities into the same space, PandaGPT displays emergent, i.e. zero-shot, cross-modal behaviors for data other than image and text (e.g., video, audio, depth, thermal, and IMU). We hope that PandaGPT serves as an initial step toward building AGI that can perceive and understand inputs in different modalities holistically, as we humans do.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": "2023.tllm-1.2", "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2305-16355", "doi": "10.48550/arxiv.2305.16355"}}, "content": {"source": {"pdf_hash": "42ad2326be97627246c442ebd5f8d19918a515ce", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2023.tllm-1.2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2305.16355", "status": "CLOSED"}}, "grobid": {"id": "01cf3b66e1dd7a9cdbcfd400246b88a4d3d9322f", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/42ad2326be97627246c442ebd5f8d19918a515ce.txt", "contents": "\nPandaGPT: One Model To Instruction-Follow Them All\n\n\nYixuan Su \nUniversity of Cambridge\nNara Institute of Science and Technology \u2663 Tencent AI Lab\n\n\nTian Lan \nUniversity of Cambridge\nNara Institute of Science and Technology \u2663 Tencent AI Lab\n\n\nHuayang Li \nUniversity of Cambridge\nNara Institute of Science and Technology \u2663 Tencent AI Lab\n\n\nJialu Xu \nUniversity of Cambridge\nNara Institute of Science and Technology \u2663 Tencent AI Lab\n\n\nYan Wang \nUniversity of Cambridge\nNara Institute of Science and Technology \u2663 Tencent AI Lab\n\n\nDeng Cai \nUniversity of Cambridge\nNara Institute of Science and Technology \u2663 Tencent AI Lab\n\n\nPandaGPT: One Model To Instruction-Follow Them All\nF80CC37B586739C3CC42AA1AFA9EF64A\nWe present PandaGPT, an approach to emPower large lANguage moDels with visual and Auditory instruction-following capabilities.Our pilot experiments show that PandaGPT can perform complex tasks such as detailed image description generation, writing stories inspired by videos, and answering questions about audios.More interestingly, PandaGPT can take multimodal inputs simultaneously and compose their semantics naturally.For example, PandaGPT can connect how objects look in an image/video and how they sound in an audio.To do so, PandaGPT combines the multimodal encoders from ImageBind and the large language models from Vicuna.Notably, only aligned image-text pairs are required for the training of PandaGPT.Thanks to the strong capability of ImageBind in embedding data from different modalities into the same space, PandaGPT displays emergent, i.e. zero-shot, cross-modal behaviors for data other than image and text (e.g., video, audio, depth, thermal, and IMU).We hope that PandaGPT serves as an initial step toward building AGI that can perceive and understand inputs in different modalities holistically, as we humans do.\n\nIntroduction\n\nHumans possess remarkable abilities to perceive and understand information from diverse sensory modalities, such as seeing a painting and hearing an audio guide.Analogously, to learn simultaneously, holistically, and directly from many different forms of information holds great promise for enabling machines to have a more comprehensive and better understanding of the world.To this end, there has been an emergent interest in developing artificial intelligence (AI) systems capable of perceiving and understanding information from multiple modalities simultaneously in a manner similar to humans.\n\nHowever, much of the prior research has focused on tackling individual modalities in isolation.For instance, while significant progress has been made in text-to-image retrieval and generation (Radford et al., 2021), visually-grounded instruction following (Liu et al., 2023;Zhu et al., 2023), and speech understanding and generation (Zhang et al., 2023a), these advances have largely been confined to separate combinations of text and other modalities or, at best, a few visual modalities (e.g., image and video).These models are limited in their ability to connect information from different modalities and lack the capacity to perceive and understand multimodal inputs holistically, thereby neglecting the inherent richness and complementary nature of multimodal data.\n\nIn this paper, we present PandaGPT, the first general-purpose model capable of instructionfollowing data from six modalities.PandaGPT leverages the power of multimodal encoders from ImageBind (Girdhar et al., 2023) and the expressive language models from Vicuna (Chiang et al., 2023), demonstrating impressive and emergent cross-modal capabilities across six modalities, namely, image/video, text, audio, depth, thermal, and inertial measurement units (IMU).Crucially, PandaGPT achieves these capabilities despite being only trained on aligned image-text pairs, thanks to the shared embedding space provided by Image-Bind.\n\nThis integration of multimodal information enables PandaGPT to perform a wide range of tasks, including generating detailed descriptions of images, composing engaging stories inspired by videos, and providing accurate answers to questions about audio inputs.Most interestingly, the core innovation of PandaGPT lies in its ability to naturally compose the semantics of multimodal inputs, which enables a rich set of compositional multimodal tasks across different modalities.For example, it can seamlessly connect the visual appearance of objects in a photo with their corresponding sounds in an audio clip, producing a cohesive and comprehensive understanding of the scene.These cross-modal capabilities empower the model to go beyond traditional unimodal analysis.We hope PandaGPT serves as an initial step toward building AGI that can perceive and understand inputs in different modalities holistically, as humans do.\n\n\nRelated Work\n\nLarge Language Models.Large language models (LLMs) pre-trained over massive unlabeled text have dominated the field of natural language processing (NLP) today (Radford et al., 2018;Devlin et al., 2019;Radford et al., 2019;Brown et al., 2020;Su et al., 2021Su et al., , 2022b)).With alignment techniques such as supervised instruction tuning (Sanh et al., 2021;Wei et al., 2021;Mishra et al., 2021) and reinforcement learning from human feedback (Stiennon et al., 2020;Ouyang et al., 2022), LLMs exhibit surprisingly effective zero-and few-shot generalization abilities to perform almost any NLP tasks.The most successful examples could be Ope-nAI's ChatGPT (OpenAI, 2023b) and GPT4 (Ope-nAI, 2023a), which have made a profound impact on the entire AI research community and beyond.There also have been enormous open-source efforts to replicate the success, such as BLOOM (Scao et al., 2022), LLaMA (Touvron et al., 2023), Alpaca (Taori et al., 2023), Vicuna (Chiang et al., 2023), OpenAlpaca (Su et al., 2023) among many others.\n\nMulti-modal Alignment.Feature alignment among multiple modalities has attracted great interest for its applications such as cross-modal retrieval (Frome et al., 2013;Faghri et al., 2017;Alayrac et al., 2020).Recently, CLIP (Radford et al., 2021) learns a joint embedding space for image and text.Flamingo (Alayrac et al., 2022), BLIP-2 (Li et al., 2023), and MAGIC (Su et al., 2022a) bridge powerful pre-trained vision-only and language-only models and show strong zero-shot abilities.Audio-CLIP (Guzhov et al., 2022) adds audio into the CLIP framework for audio classification.Image-Bind (Girdhar et al., 2023) learn a joint embedding across six different modalities (image/video, text, audio, depth, thermal, and IMU data) using image-paired data only.More recently, there has been a surge of interest to combine multi-modal alignment and large language models for multimodal instruction following.LLaVa (Liu et al., 2023), Mini-GPT4 (Zhu et al., 2023), and Video-LLaMA (Zhang et al., 2023b) enable visuallygrounded instruction following.DetGPT (Pi et al., 2023) proposes reasoning-based object detection.SpeechGPT (Zhang et al., 2023a) adds speech understanding and generation abilities to LLMs.However, these advances have largely been confined to separate combinations of text and other modalities (e.g., image/video or audio).\n\n\nMethod\n\nPandaGPT combines the multi-modal encoders from ImageBind (Girdhar et al., 2023) and the large language models from Vicuna (Chiang et al., 2023), achieving impressive capabilities in vision-and audio-grounded instruction following tasks.To align the feature space of multimodal encoders from ImageBind and large language models from Vicuna1 , we train PandaGPT using 160k imagelanguage instruction-following data released by Liu et al. (2023) and Zhu et al. (2023).Each training instance consists of an image I and a multi-turn conversation data (x 1 , y 1 , ..., x n , y n ), where x i and y i are the human's instruction and the system's response at the i-th turn, respectively.To reduce the number of trainable parameters, we only train (i) a linear projection matrix f to connect the representation produced by ImageBind to Vicuna; and (ii) additional LoRA (Hu et al., 2021) weights on the Vicuna's attention modules.2 Figure 1 illustrates the architecture of PandaGPT.\n\nThe training objective of PandaGPT is defined as\nL(\u03b8 f , \u03b8 l ) = n i=1 p \u03b8 (y i |x <i , y <i\u22121 , f (h I )), (1)\nwhere \u03b8 f and \u03b8 l correspond to the learnable parameters of the linear projection matrix and LoRA weights.The h I is the image representation produced by ImageBind and \u03b8 = {\u03b8 f , \u03b8 l , \u03b8 1 , \u03b8 2 }, where \u03b8 1 and \u03b8 2 are frozen parameters of Im-ageBind and Vicuna, respectively.Note that the loss is only computed from the part of system responses during training.We train PandaGPT on the image-language instruction-following dataset for two epochs using a learning rate of 5e-4 with linear decay.The maximum sequence length for Vicuna-13B is set to 400 based on our computation resources (8\u00d7A100 40G GPUs).The training takes around 7 hours to complete.\n\n\nCapabilities of PandaGPT\n\nCompared to existing multimodal instructionfollowing models trained individually for one particular modality, PandaGPT can understand and combine the information in different forms together, including image/video, text, audio, depth (3D), thermal (infrared radiation), and inertial measurement units (IMU) readings.We find that the capabilities of PandaGPT include but are not limited to: \u2022 multimodal arithmetic: PandaGPT is also capable of working with input composed across\n\n\nConclusion and Limitations\n\nIn this study, we present PandaGPT, the first general-purpose model capable of instructionfollowing data from six modalities.2. We only use one embedding vector from Im- ageBind for the content in other modalities than text.More research into fine-grained feature extraction such as cross-modal attention mechanisms could be beneficial for the improvement of performance.\n\n3. PandaGPT currently only allows multimodal information to be used as input, future possibilities include generating richer multimedia content (e.g., creating images and response in audio).\n\n4. New benchmarks to evaluate the composition ability of multimodal inputs is demanded.\n\n5. PandaGPT can also exhibit several common deficiencies of existing language models, including hallucination, toxicity, and stereotypes.\n\nLastly, we would like to note that PandaGPT is a research prototype and cannot be readily used for real-world applications.\n\nA More Examples of PandaGPT 17\n\nFigure 1 :\n1\nFigure 1: Illustration of PandaGPT.During training, we only train the linear projection matrix and the additional LoRA weights (as indicated with dashed boxes) while keeping the parameters of ImageBind and Vicuna frozen.\n\n\nFigure 2 :\n2\nFigure 2: Example showing PandaGPT's capability in image-grounded question answering.\n\n\nFigure 3 :\n3\nFigure 3: Example showing PandaGPT's capability in image/video-inspired creative writing.\n\n\n\u2022\n\nimage/video-grounded question answering: see examples of Figure 2 , 6, and 7. \u2022 image/video-inspired creative writing: see examples of Figure 3. \u2022 visual and auditory reasoning: see examples of Figure 4, 8, and 9.\n\n\nFigure 4 :\n4\nFigure 4: Example showing PandaGPT's capability in visual reasoning.\n\n\nFigure 5 :\n5\nFigure 5: Example showing PandaGPT's capability in multimodal arithmetic (Image and Audio).\n\n\nFigure 6 :\n6\nFigure 6: Example showing PandaGPT's capability in image-grounded question answering.\n\n\nFigure 7 :\n7\nFigure 7: Example showing PandaGPT's capability in video-grounded question answering.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe use the version-0 of Vicuna-13B as our base language model.\nThe total number of trainable parameters is around 0.4% of the parameters of Vicuna.\nFigure 8: Example showing PandaGPT's capability in auditory reasoning.\nFigure 9: Example showing PandaGPT's capability in auditory reasoning.\nFigure 11: Example showing PandaGPT's capability in multimodal arithmetic (Video and Audio).\nFigure 12: Example showing PandaGPT's capability in multimodal arithmetic (Video and Audio).\n\nFlamingo: a visual language model for few-shot learning. Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, Advances in Neural Information Processing Systems. 202235\n\nSelf-supervised multimodal versatile networks. Jean-Baptiste Alayrac, Adria Recasens, Rosalia Schneider, Relja Arandjelovi\u0107, Jason Ramapuram, Jeffrey De Fauw, Lucas Smaira, Sander Dieleman, Andrew Zisserman, Advances in Neural Information Processing Systems. 202033\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033\n\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality. \n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies20191\n\nVse++: Improving visualsemantic embeddings with hard negatives. Fartash Faghri, David J Fleet, Jamie Ryan Kiros, Sanja Fidler, arXiv:1707.056122017arXiv preprint\n\nDevise: A deep visual-semantic embedding model. Andrea Frome, Greg S Corrado, Jon Shlens, Samy Bengio, Jeff Dean, Marc ' , Aurelio Ranzato, Tomas Mikolov, Advances in neural information processing systems. 201326\n\nImagebind: One embedding space to bind them all. Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin, Ishan Misra, arXiv:2305.056652023arXiv preprint\n\nAudioclip: Extending clip to image, text and audio. Andrey Guzhov, Federico Raue, ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE2022J\u00f6rn Hees, and Andreas Dengel\n\nJ Edward, Yelong Hu, Phillip Shen, Zeyuan Wallis, Yuanzhi Allen-Zhu, Shean Li, Lu Wang, Weizhu Wang, Chen, arXiv:2106.09685Lora: Low-rank adaptation of large language models. 2021arXiv preprint\n\nBlip-2: Bootstrapping language-image pretraining with frozen image encoders and large language models. Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi, arXiv:2301.125972023arXiv preprint\n\nHaotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee, Visual instruction tuning. 2023\n\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, Hannaneh Hajishirzi, arXiv:2104.08773Natural instructions: Benchmarking generalization to new tasks from natural language instructions. 2021arXiv preprint\n\nOpenAI. 2023a. Gpt-4 technical report. OpenAI. 2023b. Introducing chatgpt. \n\nTraining language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in Neural Information Processing Systems. 202235\n\nDetgpt: Detect what you need via reasoning. Renjie Pi, Jiahui Gao, Shizhe Diao, Rui Pan, Hanze Dong, Jipeng Zhang, Lewei Yao, Lingpeng Kong, Tong Zhang, 2023\n\nLearning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, International conference on machine learning. PMLR2021\n\nImproving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, 2018\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019\n\nTeven Le Scao, Arun Raja, et al. 2021. Multitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, arXiv:2110.08207arXiv preprint\n\nTeven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili\u0107, Daniel Hesslow, Roman Castagn\u00e9, Alexandra Sasha Luccioni, Fran\u00e7ois Yvon, Matthias Gall\u00e9, arXiv:2211.05100Bloom: A 176b-parameter open-access multilingual language model. 2022arXiv preprint\n\nLearning to summarize with human feedback. Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, Paul F Christiano, Advances in Neural Information Processing Systems. 202033\n\nOpenalpaca: A fully open-source instruction-following model based on openllama. Yixuan Su, Tian Lan, Deng Cai, 2023\n\nLanguage models can see: plugging visual controls in text generation. Yixuan Su, Tian Lan, Yahui Liu, Fangyu Liu, Dani Yogatama, Yan Wang, Lingpeng Kong, Nigel Collier, arXiv:2205.026552022aarXiv preprint\n\nA contrastive framework for neural text generation. Yixuan Su, Tian Lan, Yan Wang, Dani Yogatama, Lingpeng Kong, Nigel Collier, Advances in Neural Information Processing Systems. 2022b35\n\nYixuan Su, Lei Shu, Elman Mansimov, Arshit Gupta, Deng Cai, Yi-An Lai, Yi Zhang, arXiv:2109.14739Multi-task pre-training for plug-and-play task-oriented dialogue system. 2021arXiv preprint\n\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto, Stanford alpaca: An instruction-following llama model. 2023\n\nThibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timoth\u00e9e Lachaux, Baptiste Lacroix, Naman Rozi\u00e8re, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971Llama: Open and efficient foundation language models. 2023arXiv preprint\n\nAndrew M Dai, and Quoc V Le. 2021. Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Du, arXiv:2109.01652arXiv preprint\n\nSpeechgpt: Empowering large language models with intrinsic cross-modal conversational abilities. Dong Zhang, Shimin Li, Xin Zhang, Jun Zhan, Pengyu Wang, Yaqian Zhou, Xipeng Qiu, 2023a\n\nVideollama: An instruction-finetuned visual language model for video understanding. Hang Zhang, Xin Li, Lidong Bing, 2023b\n\nDeyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, Mohamed Elhoseiny, arXiv:2304.10592Minigpt-4: Enhancing vision-language understanding with advanced large language models. 2023arXiv preprint\n", "annotations": {"author": "[{\"end\":148,\"start\":54},{\"end\":242,\"start\":149},{\"end\":338,\"start\":243},{\"end\":432,\"start\":339},{\"end\":526,\"start\":433},{\"end\":620,\"start\":527}]", "publisher": null, "author_last_name": "[{\"end\":63,\"start\":61},{\"end\":157,\"start\":154},{\"end\":253,\"start\":251},{\"end\":347,\"start\":345},{\"end\":441,\"start\":437},{\"end\":535,\"start\":532}]", "author_first_name": "[{\"end\":60,\"start\":54},{\"end\":153,\"start\":149},{\"end\":250,\"start\":243},{\"end\":344,\"start\":339},{\"end\":436,\"start\":433},{\"end\":531,\"start\":527}]", "author_affiliation": "[{\"end\":147,\"start\":65},{\"end\":241,\"start\":159},{\"end\":337,\"start\":255},{\"end\":431,\"start\":349},{\"end\":525,\"start\":443},{\"end\":619,\"start\":537}]", "title": "[{\"end\":51,\"start\":1},{\"end\":671,\"start\":621}]", "venue": null, "abstract": "[{\"end\":1836,\"start\":705}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2666,\"start\":2644},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2726,\"start\":2708},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2743,\"start\":2726},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2806,\"start\":2785},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3438,\"start\":3416},{\"end\":3507,\"start\":3486},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4965,\"start\":4943},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4985,\"start\":4965},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5006,\"start\":4985},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5025,\"start\":5006},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5040,\"start\":5025},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5060,\"start\":5040},{\"end\":5144,\"start\":5125},{\"end\":5161,\"start\":5144},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":5181,\"start\":5161},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5252,\"start\":5229},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5272,\"start\":5252},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5673,\"start\":5655},{\"end\":5704,\"start\":5673},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5733,\"start\":5713},{\"end\":5763,\"start\":5742},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5793,\"start\":5776},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5980,\"start\":5960},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6000,\"start\":5980},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6021,\"start\":6000},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6059,\"start\":6037},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6141,\"start\":6119},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6167,\"start\":6150},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6197,\"start\":6179},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6331,\"start\":6310},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6424,\"start\":6403},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6738,\"start\":6720},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6768,\"start\":6750},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6807,\"start\":6786},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6878,\"start\":6861},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6952,\"start\":6931},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7237,\"start\":7215},{\"end\":7301,\"start\":7280},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7599,\"start\":7582},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7621,\"start\":7604},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8035,\"start\":8018}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":10616,\"start\":10381},{\"attributes\":{\"id\":\"fig_1\"},\"end\":10717,\"start\":10617},{\"attributes\":{\"id\":\"fig_2\"},\"end\":10822,\"start\":10718},{\"attributes\":{\"id\":\"fig_3\"},\"end\":11041,\"start\":10823},{\"attributes\":{\"id\":\"fig_4\"},\"end\":11125,\"start\":11042},{\"attributes\":{\"id\":\"fig_5\"},\"end\":11232,\"start\":11126},{\"attributes\":{\"id\":\"fig_6\"},\"end\":11333,\"start\":11233},{\"attributes\":{\"id\":\"fig_7\"},\"end\":11434,\"start\":11334},{\"end\":11439,\"start\":11435},{\"end\":11444,\"start\":11440},{\"end\":11449,\"start\":11445}]", "paragraph": "[{\"end\":2450,\"start\":1852},{\"end\":3222,\"start\":2452},{\"end\":3846,\"start\":3224},{\"end\":4767,\"start\":3848},{\"end\":5812,\"start\":4784},{\"end\":7146,\"start\":5814},{\"end\":8130,\"start\":7157},{\"end\":8180,\"start\":8132},{\"end\":8896,\"start\":8244},{\"end\":9401,\"start\":8925},{\"end\":9803,\"start\":9432},{\"end\":9995,\"start\":9805},{\"end\":10084,\"start\":9997},{\"end\":10223,\"start\":10086},{\"end\":10348,\"start\":10225},{\"end\":10380,\"start\":10350},{\"end\":10615,\"start\":10395},{\"end\":10716,\"start\":10631},{\"end\":10821,\"start\":10732},{\"end\":11040,\"start\":10827},{\"end\":11124,\"start\":11056},{\"end\":11231,\"start\":11140},{\"end\":11332,\"start\":11247},{\"end\":11433,\"start\":11348}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8243,\"start\":8181}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1850,\"start\":1838},{\"attributes\":{\"n\":\"2\"},\"end\":4782,\"start\":4770},{\"attributes\":{\"n\":\"3\"},\"end\":7155,\"start\":7149},{\"attributes\":{\"n\":\"4\"},\"end\":8923,\"start\":8899},{\"attributes\":{\"n\":\"5\"},\"end\":9430,\"start\":9404},{\"end\":10392,\"start\":10382},{\"end\":10628,\"start\":10618},{\"end\":10729,\"start\":10719},{\"end\":10825,\"start\":10824},{\"end\":11053,\"start\":11043},{\"end\":11137,\"start\":11127},{\"end\":11244,\"start\":11234},{\"end\":11345,\"start\":11335}]", "table": null, "figure_caption": "[{\"end\":10616,\"start\":10394},{\"end\":10717,\"start\":10630},{\"end\":10822,\"start\":10731},{\"end\":11041,\"start\":10826},{\"end\":11125,\"start\":11055},{\"end\":11232,\"start\":11139},{\"end\":11333,\"start\":11246},{\"end\":11434,\"start\":11347},{\"end\":11439,\"start\":11437},{\"end\":11444,\"start\":11442},{\"end\":11449,\"start\":11447}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8088,\"start\":8087}]", "bib_author_first_name": "[{\"end\":11997,\"start\":11984},{\"end\":12011,\"start\":12007},{\"end\":12028,\"start\":12021},{\"end\":12041,\"start\":12034},{\"end\":12053,\"start\":12049},{\"end\":12064,\"start\":12060},{\"end\":12078,\"start\":12073},{\"end\":12091,\"start\":12085},{\"end\":12109,\"start\":12100},{\"end\":12127,\"start\":12120},{\"end\":12257,\"start\":12244},{\"end\":12272,\"start\":12267},{\"end\":12290,\"start\":12283},{\"end\":12307,\"start\":12302},{\"end\":12327,\"start\":12322},{\"end\":12346,\"start\":12339},{\"end\":12349,\"start\":12347},{\"end\":12361,\"start\":12356},{\"end\":12376,\"start\":12370},{\"end\":12393,\"start\":12387},{\"end\":12506,\"start\":12503},{\"end\":12522,\"start\":12514},{\"end\":12533,\"start\":12529},{\"end\":12548,\"start\":12541},{\"end\":12563,\"start\":12558},{\"end\":12565,\"start\":12564},{\"end\":12582,\"start\":12574},{\"end\":12599,\"start\":12593},{\"end\":12619,\"start\":12613},{\"end\":12633,\"start\":12627},{\"end\":12648,\"start\":12642},{\"end\":12723,\"start\":12716},{\"end\":12739,\"start\":12732},{\"end\":12746,\"start\":12744},{\"end\":12756,\"start\":12752},{\"end\":12772,\"start\":12764},{\"end\":12780,\"start\":12777},{\"end\":12795,\"start\":12788},{\"end\":12809,\"start\":12803},{\"end\":12825,\"start\":12818},{\"end\":12840,\"start\":12834},{\"end\":12842,\"start\":12841},{\"end\":13052,\"start\":13047},{\"end\":13069,\"start\":13061},{\"end\":13083,\"start\":13077},{\"end\":13097,\"start\":13089},{\"end\":13481,\"start\":13474},{\"end\":13495,\"start\":13490},{\"end\":13497,\"start\":13496},{\"end\":13510,\"start\":13505},{\"end\":13528,\"start\":13523},{\"end\":13627,\"start\":13621},{\"end\":13639,\"start\":13635},{\"end\":13641,\"start\":13640},{\"end\":13654,\"start\":13651},{\"end\":13667,\"start\":13663},{\"end\":13680,\"start\":13676},{\"end\":13691,\"start\":13687},{\"end\":13693,\"start\":13692},{\"end\":13703,\"start\":13696},{\"end\":13718,\"start\":13713},{\"end\":13841,\"start\":13836},{\"end\":13860,\"start\":13851},{\"end\":13877,\"start\":13871},{\"end\":13889,\"start\":13883},{\"end\":13903,\"start\":13897},{\"end\":13926,\"start\":13920},{\"end\":13940,\"start\":13935},{\"end\":14042,\"start\":14036},{\"end\":14059,\"start\":14051},{\"end\":14206,\"start\":14205},{\"end\":14221,\"start\":14215},{\"end\":14233,\"start\":14226},{\"end\":14246,\"start\":14240},{\"end\":14262,\"start\":14255},{\"end\":14279,\"start\":14274},{\"end\":14286,\"start\":14284},{\"end\":14299,\"start\":14293},{\"end\":14509,\"start\":14503},{\"end\":14520,\"start\":14514},{\"end\":14531,\"start\":14525},{\"end\":14548,\"start\":14542},{\"end\":14597,\"start\":14590},{\"end\":14611,\"start\":14603},{\"end\":14624,\"start\":14616},{\"end\":14633,\"start\":14629},{\"end\":14637,\"start\":14634},{\"end\":14683,\"start\":14676},{\"end\":14698,\"start\":14692},{\"end\":14715,\"start\":14709},{\"end\":14731,\"start\":14723},{\"end\":15029,\"start\":15025},{\"end\":15045,\"start\":15038},{\"end\":15052,\"start\":15050},{\"end\":15065,\"start\":15060},{\"end\":15082,\"start\":15075},{\"end\":15101,\"start\":15095},{\"end\":15116,\"start\":15111},{\"end\":15132,\"start\":15124},{\"end\":15150,\"start\":15142},{\"end\":15162,\"start\":15158},{\"end\":15277,\"start\":15271},{\"end\":15288,\"start\":15282},{\"end\":15300,\"start\":15294},{\"end\":15310,\"start\":15307},{\"end\":15321,\"start\":15316},{\"end\":15334,\"start\":15328},{\"end\":15347,\"start\":15342},{\"end\":15361,\"start\":15353},{\"end\":15372,\"start\":15368},{\"end\":15461,\"start\":15457},{\"end\":15475,\"start\":15471},{\"end\":15480,\"start\":15476},{\"end\":15491,\"start\":15486},{\"end\":15507,\"start\":15501},{\"end\":15523,\"start\":15516},{\"end\":15537,\"start\":15529},{\"end\":15553,\"start\":15547},{\"end\":15568,\"start\":15562},{\"end\":15583,\"start\":15577},{\"end\":15597,\"start\":15593},{\"end\":15726,\"start\":15722},{\"end\":15743,\"start\":15736},{\"end\":15759,\"start\":15756},{\"end\":15774,\"start\":15770},{\"end\":15849,\"start\":15845},{\"end\":15866,\"start\":15859},{\"end\":15876,\"start\":15871},{\"end\":15889,\"start\":15884},{\"end\":15901,\"start\":15896},{\"end\":15914,\"start\":15910},{\"end\":16060,\"start\":16054},{\"end\":16073,\"start\":16067},{\"end\":16087,\"start\":16082},{\"end\":16103,\"start\":16096},{\"end\":16105,\"start\":16104},{\"end\":16119,\"start\":16112},{\"end\":16134,\"start\":16130},{\"end\":16152,\"start\":16145},{\"end\":16168,\"start\":16162},{\"end\":16216,\"start\":16211},{\"end\":16232,\"start\":16226},{\"end\":16249,\"start\":16238},{\"end\":16262,\"start\":16257},{\"end\":16278,\"start\":16272},{\"end\":16291,\"start\":16285},{\"end\":16306,\"start\":16301},{\"end\":16326,\"start\":16317},{\"end\":16332,\"start\":16327},{\"end\":16351,\"start\":16343},{\"end\":16366,\"start\":16358},{\"end\":16523,\"start\":16518},{\"end\":16538,\"start\":16534},{\"end\":16554,\"start\":16547},{\"end\":16565,\"start\":16559},{\"end\":16579,\"start\":16575},{\"end\":16593,\"start\":16586},{\"end\":16604,\"start\":16600},{\"end\":16619,\"start\":16614},{\"end\":16632,\"start\":16628},{\"end\":16634,\"start\":16633},{\"end\":16792,\"start\":16786},{\"end\":16801,\"start\":16797},{\"end\":16811,\"start\":16807},{\"end\":16899,\"start\":16893},{\"end\":16908,\"start\":16904},{\"end\":16919,\"start\":16914},{\"end\":16931,\"start\":16925},{\"end\":16941,\"start\":16937},{\"end\":16955,\"start\":16952},{\"end\":16970,\"start\":16962},{\"end\":16982,\"start\":16977},{\"end\":17087,\"start\":17081},{\"end\":17096,\"start\":17092},{\"end\":17105,\"start\":17102},{\"end\":17116,\"start\":17112},{\"end\":17135,\"start\":17127},{\"end\":17147,\"start\":17142},{\"end\":17223,\"start\":17217},{\"end\":17231,\"start\":17228},{\"end\":17242,\"start\":17237},{\"end\":17259,\"start\":17253},{\"end\":17271,\"start\":17267},{\"end\":17282,\"start\":17277},{\"end\":17290,\"start\":17288},{\"end\":17412,\"start\":17407},{\"end\":17426,\"start\":17420},{\"end\":17444,\"start\":17438},{\"end\":17456,\"start\":17452},{\"end\":17472,\"start\":17465},{\"end\":17483,\"start\":17477},{\"end\":17499,\"start\":17494},{\"end\":17516,\"start\":17507},{\"end\":17518,\"start\":17517},{\"end\":17598,\"start\":17591},{\"end\":17620,\"start\":17613},{\"end\":17635,\"start\":17629},{\"end\":17655,\"start\":17645},{\"end\":17674,\"start\":17666},{\"end\":17692,\"start\":17684},{\"end\":17707,\"start\":17702},{\"end\":17721,\"start\":17717},{\"end\":17735,\"start\":17729},{\"end\":17931,\"start\":17926},{\"end\":17944,\"start\":17937},{\"end\":17953,\"start\":17952},{\"end\":17969,\"start\":17963},{\"end\":17981,\"start\":17976},{\"end\":17985,\"start\":17982},{\"end\":17996,\"start\":17991},{\"end\":18004,\"start\":18001},{\"end\":18150,\"start\":18146},{\"end\":18164,\"start\":18158},{\"end\":18172,\"start\":18169},{\"end\":18183,\"start\":18180},{\"end\":18196,\"start\":18190},{\"end\":18209,\"start\":18203},{\"end\":18222,\"start\":18216},{\"end\":18323,\"start\":18319},{\"end\":18334,\"start\":18331},{\"end\":18345,\"start\":18339},{\"end\":18364,\"start\":18359},{\"end\":18373,\"start\":18370},{\"end\":18388,\"start\":18380},{\"end\":18400,\"start\":18395},{\"end\":18412,\"start\":18405}]", "bib_author_last_name": "[{\"end\":12005,\"start\":11998},{\"end\":12019,\"start\":12012},{\"end\":12032,\"start\":12029},{\"end\":12047,\"start\":12042},{\"end\":12058,\"start\":12054},{\"end\":12071,\"start\":12065},{\"end\":12083,\"start\":12079},{\"end\":12098,\"start\":12092},{\"end\":12118,\"start\":12110},{\"end\":12136,\"start\":12128},{\"end\":12265,\"start\":12258},{\"end\":12281,\"start\":12273},{\"end\":12300,\"start\":12291},{\"end\":12320,\"start\":12308},{\"end\":12337,\"start\":12328},{\"end\":12354,\"start\":12350},{\"end\":12368,\"start\":12362},{\"end\":12385,\"start\":12377},{\"end\":12403,\"start\":12394},{\"end\":12512,\"start\":12507},{\"end\":12527,\"start\":12523},{\"end\":12539,\"start\":12534},{\"end\":12556,\"start\":12549},{\"end\":12572,\"start\":12566},{\"end\":12591,\"start\":12583},{\"end\":12611,\"start\":12600},{\"end\":12625,\"start\":12620},{\"end\":12640,\"start\":12634},{\"end\":12655,\"start\":12649},{\"end\":12730,\"start\":12724},{\"end\":12742,\"start\":12740},{\"end\":12750,\"start\":12747},{\"end\":12762,\"start\":12757},{\"end\":12775,\"start\":12773},{\"end\":12786,\"start\":12781},{\"end\":12801,\"start\":12796},{\"end\":12816,\"start\":12810},{\"end\":12832,\"start\":12826},{\"end\":12851,\"start\":12843},{\"end\":13059,\"start\":13053},{\"end\":13075,\"start\":13070},{\"end\":13087,\"start\":13084},{\"end\":13107,\"start\":13098},{\"end\":13488,\"start\":13482},{\"end\":13503,\"start\":13498},{\"end\":13521,\"start\":13511},{\"end\":13535,\"start\":13529},{\"end\":13633,\"start\":13628},{\"end\":13649,\"start\":13642},{\"end\":13661,\"start\":13655},{\"end\":13674,\"start\":13668},{\"end\":13685,\"start\":13681},{\"end\":13711,\"start\":13704},{\"end\":13726,\"start\":13719},{\"end\":13849,\"start\":13842},{\"end\":13869,\"start\":13861},{\"end\":13881,\"start\":13878},{\"end\":13895,\"start\":13890},{\"end\":13918,\"start\":13904},{\"end\":13933,\"start\":13927},{\"end\":13946,\"start\":13941},{\"end\":14049,\"start\":14043},{\"end\":14064,\"start\":14060},{\"end\":14213,\"start\":14207},{\"end\":14224,\"start\":14222},{\"end\":14238,\"start\":14234},{\"end\":14253,\"start\":14247},{\"end\":14272,\"start\":14263},{\"end\":14282,\"start\":14280},{\"end\":14291,\"start\":14287},{\"end\":14304,\"start\":14300},{\"end\":14310,\"start\":14306},{\"end\":14512,\"start\":14510},{\"end\":14523,\"start\":14521},{\"end\":14540,\"start\":14532},{\"end\":14552,\"start\":14549},{\"end\":14601,\"start\":14598},{\"end\":14614,\"start\":14612},{\"end\":14627,\"start\":14625},{\"end\":14641,\"start\":14638},{\"end\":14690,\"start\":14684},{\"end\":14707,\"start\":14699},{\"end\":14721,\"start\":14716},{\"end\":14742,\"start\":14732},{\"end\":15036,\"start\":15030},{\"end\":15048,\"start\":15046},{\"end\":15058,\"start\":15053},{\"end\":15073,\"start\":15066},{\"end\":15093,\"start\":15083},{\"end\":15109,\"start\":15102},{\"end\":15122,\"start\":15117},{\"end\":15140,\"start\":15133},{\"end\":15156,\"start\":15151},{\"end\":15166,\"start\":15163},{\"end\":15280,\"start\":15278},{\"end\":15292,\"start\":15289},{\"end\":15305,\"start\":15301},{\"end\":15314,\"start\":15311},{\"end\":15326,\"start\":15322},{\"end\":15340,\"start\":15335},{\"end\":15351,\"start\":15348},{\"end\":15366,\"start\":15362},{\"end\":15378,\"start\":15373},{\"end\":15469,\"start\":15462},{\"end\":15484,\"start\":15481},{\"end\":15499,\"start\":15492},{\"end\":15514,\"start\":15508},{\"end\":15527,\"start\":15524},{\"end\":15545,\"start\":15538},{\"end\":15560,\"start\":15554},{\"end\":15575,\"start\":15569},{\"end\":15591,\"start\":15584},{\"end\":15603,\"start\":15598},{\"end\":15734,\"start\":15727},{\"end\":15754,\"start\":15744},{\"end\":15768,\"start\":15760},{\"end\":15784,\"start\":15775},{\"end\":15857,\"start\":15850},{\"end\":15869,\"start\":15867},{\"end\":15882,\"start\":15877},{\"end\":15894,\"start\":15890},{\"end\":15908,\"start\":15902},{\"end\":15924,\"start\":15915},{\"end\":16065,\"start\":16061},{\"end\":16080,\"start\":16074},{\"end\":16094,\"start\":16088},{\"end\":16110,\"start\":16106},{\"end\":16128,\"start\":16120},{\"end\":16143,\"start\":16135},{\"end\":16160,\"start\":16153},{\"end\":16177,\"start\":16169},{\"end\":16224,\"start\":16217},{\"end\":16236,\"start\":16233},{\"end\":16255,\"start\":16250},{\"end\":16270,\"start\":16263},{\"end\":16283,\"start\":16279},{\"end\":16299,\"start\":16292},{\"end\":16315,\"start\":16307},{\"end\":16341,\"start\":16333},{\"end\":16356,\"start\":16352},{\"end\":16372,\"start\":16367},{\"end\":16532,\"start\":16524},{\"end\":16545,\"start\":16539},{\"end\":16557,\"start\":16555},{\"end\":16573,\"start\":16566},{\"end\":16584,\"start\":16580},{\"end\":16598,\"start\":16594},{\"end\":16612,\"start\":16605},{\"end\":16626,\"start\":16620},{\"end\":16645,\"start\":16635},{\"end\":16795,\"start\":16793},{\"end\":16805,\"start\":16802},{\"end\":16815,\"start\":16812},{\"end\":16902,\"start\":16900},{\"end\":16912,\"start\":16909},{\"end\":16923,\"start\":16920},{\"end\":16935,\"start\":16932},{\"end\":16950,\"start\":16942},{\"end\":16960,\"start\":16956},{\"end\":16975,\"start\":16971},{\"end\":16990,\"start\":16983},{\"end\":17090,\"start\":17088},{\"end\":17100,\"start\":17097},{\"end\":17110,\"start\":17106},{\"end\":17125,\"start\":17117},{\"end\":17140,\"start\":17136},{\"end\":17155,\"start\":17148},{\"end\":17226,\"start\":17224},{\"end\":17235,\"start\":17232},{\"end\":17251,\"start\":17243},{\"end\":17265,\"start\":17260},{\"end\":17275,\"start\":17272},{\"end\":17286,\"start\":17283},{\"end\":17296,\"start\":17291},{\"end\":17418,\"start\":17413},{\"end\":17436,\"start\":17427},{\"end\":17450,\"start\":17445},{\"end\":17463,\"start\":17457},{\"end\":17475,\"start\":17473},{\"end\":17492,\"start\":17484},{\"end\":17505,\"start\":17500},{\"end\":17528,\"start\":17519},{\"end\":17611,\"start\":17599},{\"end\":17627,\"start\":17621},{\"end\":17643,\"start\":17636},{\"end\":17664,\"start\":17656},{\"end\":17682,\"start\":17675},{\"end\":17700,\"start\":17693},{\"end\":17715,\"start\":17708},{\"end\":17727,\"start\":17722},{\"end\":17742,\"start\":17736},{\"end\":17749,\"start\":17744},{\"end\":17935,\"start\":17932},{\"end\":17950,\"start\":17945},{\"end\":17961,\"start\":17954},{\"end\":17974,\"start\":17970},{\"end\":17989,\"start\":17986},{\"end\":17999,\"start\":17997},{\"end\":18011,\"start\":18005},{\"end\":18015,\"start\":18013},{\"end\":18156,\"start\":18151},{\"end\":18167,\"start\":18165},{\"end\":18178,\"start\":18173},{\"end\":18188,\"start\":18184},{\"end\":18201,\"start\":18197},{\"end\":18214,\"start\":18210},{\"end\":18226,\"start\":18223},{\"end\":18329,\"start\":18324},{\"end\":18337,\"start\":18335},{\"end\":18350,\"start\":18346},{\"end\":18368,\"start\":18365},{\"end\":18378,\"start\":18374},{\"end\":18393,\"start\":18389},{\"end\":18403,\"start\":18401},{\"end\":18422,\"start\":18413}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":248476411},\"end\":12195,\"start\":11927},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":220249786},\"end\":12462,\"start\":12197},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":218971783},\"end\":12714,\"start\":12464},{\"attributes\":{\"id\":\"b3\"},\"end\":12963,\"start\":12716},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":52967399},\"end\":13408,\"start\":12965},{\"attributes\":{\"doi\":\"arXiv:1707.05612\",\"id\":\"b5\"},\"end\":13571,\"start\":13410},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":261138},\"end\":13785,\"start\":13573},{\"attributes\":{\"doi\":\"arXiv:2305.05665\",\"id\":\"b7\"},\"end\":13982,\"start\":13787},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":235624127},\"end\":14203,\"start\":13984},{\"attributes\":{\"doi\":\"arXiv:2106.09685\",\"id\":\"b9\"},\"end\":14398,\"start\":14205},{\"attributes\":{\"doi\":\"arXiv:2301.12597\",\"id\":\"b10\"},\"end\":14588,\"start\":14400},{\"attributes\":{\"id\":\"b11\"},\"end\":14674,\"start\":14590},{\"attributes\":{\"doi\":\"arXiv:2104.08773\",\"id\":\"b12\"},\"end\":14877,\"start\":14676},{\"attributes\":{\"id\":\"b13\"},\"end\":14954,\"start\":14879},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":246426909},\"end\":15225,\"start\":14956},{\"attributes\":{\"id\":\"b15\"},\"end\":15384,\"start\":15227},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":231591445},\"end\":15659,\"start\":15386},{\"attributes\":{\"id\":\"b17\"},\"end\":15790,\"start\":15661},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":160025533},\"end\":15946,\"start\":15792},{\"attributes\":{\"doi\":\"arXiv:2110.08207\",\"id\":\"b19\"},\"end\":16209,\"start\":15948},{\"attributes\":{\"doi\":\"arXiv:2211.05100\",\"id\":\"b20\"},\"end\":16473,\"start\":16211},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":221665105},\"end\":16704,\"start\":16475},{\"attributes\":{\"id\":\"b22\"},\"end\":16821,\"start\":16706},{\"attributes\":{\"doi\":\"arXiv:2205.02655\",\"id\":\"b23\"},\"end\":17027,\"start\":16823},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":246823043},\"end\":17215,\"start\":17029},{\"attributes\":{\"doi\":\"arXiv:2109.14739\",\"id\":\"b25\"},\"end\":17405,\"start\":17217},{\"attributes\":{\"id\":\"b26\"},\"end\":17589,\"start\":17407},{\"attributes\":{\"doi\":\"arXiv:2302.13971\",\"id\":\"b27\"},\"end\":17839,\"start\":17591},{\"attributes\":{\"doi\":\"arXiv:2109.01652\",\"id\":\"b28\"},\"end\":18047,\"start\":17841},{\"attributes\":{\"id\":\"b29\"},\"end\":18233,\"start\":18049},{\"attributes\":{\"id\":\"b30\"},\"end\":18357,\"start\":18235},{\"attributes\":{\"doi\":\"arXiv:2304.10592\",\"id\":\"b31\"},\"end\":18546,\"start\":18359}]", "bib_title": "[{\"end\":11982,\"start\":11927},{\"end\":12242,\"start\":12197},{\"end\":12501,\"start\":12464},{\"end\":13045,\"start\":12965},{\"end\":13619,\"start\":13573},{\"end\":14034,\"start\":13984},{\"end\":15023,\"start\":14956},{\"end\":15455,\"start\":15386},{\"end\":15843,\"start\":15792},{\"end\":16516,\"start\":16475},{\"end\":17079,\"start\":17029}]", "bib_author": "[{\"end\":12007,\"start\":11984},{\"end\":12021,\"start\":12007},{\"end\":12034,\"start\":12021},{\"end\":12049,\"start\":12034},{\"end\":12060,\"start\":12049},{\"end\":12073,\"start\":12060},{\"end\":12085,\"start\":12073},{\"end\":12100,\"start\":12085},{\"end\":12120,\"start\":12100},{\"end\":12138,\"start\":12120},{\"end\":12267,\"start\":12244},{\"end\":12283,\"start\":12267},{\"end\":12302,\"start\":12283},{\"end\":12322,\"start\":12302},{\"end\":12339,\"start\":12322},{\"end\":12356,\"start\":12339},{\"end\":12370,\"start\":12356},{\"end\":12387,\"start\":12370},{\"end\":12405,\"start\":12387},{\"end\":12514,\"start\":12503},{\"end\":12529,\"start\":12514},{\"end\":12541,\"start\":12529},{\"end\":12558,\"start\":12541},{\"end\":12574,\"start\":12558},{\"end\":12593,\"start\":12574},{\"end\":12613,\"start\":12593},{\"end\":12627,\"start\":12613},{\"end\":12642,\"start\":12627},{\"end\":12657,\"start\":12642},{\"end\":12732,\"start\":12716},{\"end\":12744,\"start\":12732},{\"end\":12752,\"start\":12744},{\"end\":12764,\"start\":12752},{\"end\":12777,\"start\":12764},{\"end\":12788,\"start\":12777},{\"end\":12803,\"start\":12788},{\"end\":12818,\"start\":12803},{\"end\":12834,\"start\":12818},{\"end\":12853,\"start\":12834},{\"end\":13061,\"start\":13047},{\"end\":13077,\"start\":13061},{\"end\":13089,\"start\":13077},{\"end\":13109,\"start\":13089},{\"end\":13490,\"start\":13474},{\"end\":13505,\"start\":13490},{\"end\":13523,\"start\":13505},{\"end\":13537,\"start\":13523},{\"end\":13635,\"start\":13621},{\"end\":13651,\"start\":13635},{\"end\":13663,\"start\":13651},{\"end\":13676,\"start\":13663},{\"end\":13687,\"start\":13676},{\"end\":13696,\"start\":13687},{\"end\":13713,\"start\":13696},{\"end\":13728,\"start\":13713},{\"end\":13851,\"start\":13836},{\"end\":13871,\"start\":13851},{\"end\":13883,\"start\":13871},{\"end\":13897,\"start\":13883},{\"end\":13920,\"start\":13897},{\"end\":13935,\"start\":13920},{\"end\":13948,\"start\":13935},{\"end\":14051,\"start\":14036},{\"end\":14066,\"start\":14051},{\"end\":14215,\"start\":14205},{\"end\":14226,\"start\":14215},{\"end\":14240,\"start\":14226},{\"end\":14255,\"start\":14240},{\"end\":14274,\"start\":14255},{\"end\":14284,\"start\":14274},{\"end\":14293,\"start\":14284},{\"end\":14306,\"start\":14293},{\"end\":14312,\"start\":14306},{\"end\":14514,\"start\":14503},{\"end\":14525,\"start\":14514},{\"end\":14542,\"start\":14525},{\"end\":14554,\"start\":14542},{\"end\":14603,\"start\":14590},{\"end\":14616,\"start\":14603},{\"end\":14629,\"start\":14616},{\"end\":14643,\"start\":14629},{\"end\":14692,\"start\":14676},{\"end\":14709,\"start\":14692},{\"end\":14723,\"start\":14709},{\"end\":14744,\"start\":14723},{\"end\":15038,\"start\":15025},{\"end\":15050,\"start\":15038},{\"end\":15060,\"start\":15050},{\"end\":15075,\"start\":15060},{\"end\":15095,\"start\":15075},{\"end\":15111,\"start\":15095},{\"end\":15124,\"start\":15111},{\"end\":15142,\"start\":15124},{\"end\":15158,\"start\":15142},{\"end\":15168,\"start\":15158},{\"end\":15282,\"start\":15271},{\"end\":15294,\"start\":15282},{\"end\":15307,\"start\":15294},{\"end\":15316,\"start\":15307},{\"end\":15328,\"start\":15316},{\"end\":15342,\"start\":15328},{\"end\":15353,\"start\":15342},{\"end\":15368,\"start\":15353},{\"end\":15380,\"start\":15368},{\"end\":15471,\"start\":15457},{\"end\":15486,\"start\":15471},{\"end\":15501,\"start\":15486},{\"end\":15516,\"start\":15501},{\"end\":15529,\"start\":15516},{\"end\":15547,\"start\":15529},{\"end\":15562,\"start\":15547},{\"end\":15577,\"start\":15562},{\"end\":15593,\"start\":15577},{\"end\":15605,\"start\":15593},{\"end\":15736,\"start\":15722},{\"end\":15756,\"start\":15736},{\"end\":15770,\"start\":15756},{\"end\":15786,\"start\":15770},{\"end\":15859,\"start\":15845},{\"end\":15871,\"start\":15859},{\"end\":15884,\"start\":15871},{\"end\":15896,\"start\":15884},{\"end\":15910,\"start\":15896},{\"end\":15926,\"start\":15910},{\"end\":16067,\"start\":16054},{\"end\":16082,\"start\":16067},{\"end\":16096,\"start\":16082},{\"end\":16112,\"start\":16096},{\"end\":16130,\"start\":16112},{\"end\":16145,\"start\":16130},{\"end\":16162,\"start\":16145},{\"end\":16179,\"start\":16162},{\"end\":16226,\"start\":16211},{\"end\":16238,\"start\":16226},{\"end\":16257,\"start\":16238},{\"end\":16272,\"start\":16257},{\"end\":16285,\"start\":16272},{\"end\":16301,\"start\":16285},{\"end\":16317,\"start\":16301},{\"end\":16343,\"start\":16317},{\"end\":16358,\"start\":16343},{\"end\":16374,\"start\":16358},{\"end\":16534,\"start\":16518},{\"end\":16547,\"start\":16534},{\"end\":16559,\"start\":16547},{\"end\":16575,\"start\":16559},{\"end\":16586,\"start\":16575},{\"end\":16600,\"start\":16586},{\"end\":16614,\"start\":16600},{\"end\":16628,\"start\":16614},{\"end\":16647,\"start\":16628},{\"end\":16797,\"start\":16786},{\"end\":16807,\"start\":16797},{\"end\":16817,\"start\":16807},{\"end\":16904,\"start\":16893},{\"end\":16914,\"start\":16904},{\"end\":16925,\"start\":16914},{\"end\":16937,\"start\":16925},{\"end\":16952,\"start\":16937},{\"end\":16962,\"start\":16952},{\"end\":16977,\"start\":16962},{\"end\":16992,\"start\":16977},{\"end\":17092,\"start\":17081},{\"end\":17102,\"start\":17092},{\"end\":17112,\"start\":17102},{\"end\":17127,\"start\":17112},{\"end\":17142,\"start\":17127},{\"end\":17157,\"start\":17142},{\"end\":17228,\"start\":17217},{\"end\":17237,\"start\":17228},{\"end\":17253,\"start\":17237},{\"end\":17267,\"start\":17253},{\"end\":17277,\"start\":17267},{\"end\":17288,\"start\":17277},{\"end\":17298,\"start\":17288},{\"end\":17420,\"start\":17407},{\"end\":17438,\"start\":17420},{\"end\":17452,\"start\":17438},{\"end\":17465,\"start\":17452},{\"end\":17477,\"start\":17465},{\"end\":17494,\"start\":17477},{\"end\":17507,\"start\":17494},{\"end\":17530,\"start\":17507},{\"end\":17613,\"start\":17591},{\"end\":17629,\"start\":17613},{\"end\":17645,\"start\":17629},{\"end\":17666,\"start\":17645},{\"end\":17684,\"start\":17666},{\"end\":17702,\"start\":17684},{\"end\":17717,\"start\":17702},{\"end\":17729,\"start\":17717},{\"end\":17744,\"start\":17729},{\"end\":17751,\"start\":17744},{\"end\":17937,\"start\":17926},{\"end\":17952,\"start\":17937},{\"end\":17963,\"start\":17952},{\"end\":17976,\"start\":17963},{\"end\":17991,\"start\":17976},{\"end\":18001,\"start\":17991},{\"end\":18013,\"start\":18001},{\"end\":18017,\"start\":18013},{\"end\":18158,\"start\":18146},{\"end\":18169,\"start\":18158},{\"end\":18180,\"start\":18169},{\"end\":18190,\"start\":18180},{\"end\":18203,\"start\":18190},{\"end\":18216,\"start\":18203},{\"end\":18228,\"start\":18216},{\"end\":18331,\"start\":18319},{\"end\":18339,\"start\":18331},{\"end\":18352,\"start\":18339},{\"end\":18370,\"start\":18359},{\"end\":18380,\"start\":18370},{\"end\":18395,\"start\":18380},{\"end\":18405,\"start\":18395},{\"end\":18424,\"start\":18405}]", "bib_venue": "[{\"end\":13403,\"start\":13276},{\"end\":12187,\"start\":12138},{\"end\":12454,\"start\":12405},{\"end\":12706,\"start\":12657},{\"end\":12961,\"start\":12853},{\"end\":13251,\"start\":13109},{\"end\":13274,\"start\":13253},{\"end\":13472,\"start\":13410},{\"end\":13777,\"start\":13728},{\"end\":13834,\"start\":13787},{\"end\":14164,\"start\":14066},{\"end\":14378,\"start\":14328},{\"end\":14501,\"start\":14400},{\"end\":14668,\"start\":14643},{\"end\":14857,\"start\":14760},{\"end\":14952,\"start\":14879},{\"end\":15217,\"start\":15168},{\"end\":15269,\"start\":15227},{\"end\":15649,\"start\":15605},{\"end\":15720,\"start\":15661},{\"end\":15937,\"start\":15926},{\"end\":16052,\"start\":15948},{\"end\":16453,\"start\":16390},{\"end\":16696,\"start\":16647},{\"end\":16784,\"start\":16706},{\"end\":16891,\"start\":16823},{\"end\":17206,\"start\":17157},{\"end\":17385,\"start\":17314},{\"end\":17583,\"start\":17530},{\"end\":17819,\"start\":17767},{\"end\":17924,\"start\":17841},{\"end\":18144,\"start\":18049},{\"end\":18317,\"start\":18235},{\"end\":18526,\"start\":18440}]"}}}, "year": 2023, "month": 12, "day": 17}