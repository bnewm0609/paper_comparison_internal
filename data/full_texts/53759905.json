{"id": 53759905, "updated": "2023-09-28 07:25:30.423", "metadata": {"title": "fastMRI: An Open Dataset and Benchmarks for Accelerated MRI", "authors": "[{\"first\":\"Jure\",\"last\":\"Zbontar\",\"middle\":[]},{\"first\":\"Florian\",\"last\":\"Knoll\",\"middle\":[]},{\"first\":\"Anuroop\",\"last\":\"Sriram\",\"middle\":[]},{\"first\":\"Tullie\",\"last\":\"Murrell\",\"middle\":[]},{\"first\":\"Zhengnan\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Matthew\",\"last\":\"Muckley\",\"middle\":[\"J.\"]},{\"first\":\"Aaron\",\"last\":\"Defazio\",\"middle\":[]},{\"first\":\"Ruben\",\"last\":\"Stern\",\"middle\":[]},{\"first\":\"Patricia\",\"last\":\"Johnson\",\"middle\":[]},{\"first\":\"Mary\",\"last\":\"Bruno\",\"middle\":[]},{\"first\":\"Marc\",\"last\":\"Parente\",\"middle\":[]},{\"first\":\"Krzysztof\",\"last\":\"Geras\",\"middle\":[\"J.\"]},{\"first\":\"Joe\",\"last\":\"Katsnelson\",\"middle\":[]},{\"first\":\"Hersh\",\"last\":\"Chandarana\",\"middle\":[]},{\"first\":\"Zizhao\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Michal\",\"last\":\"Drozdzal\",\"middle\":[]},{\"first\":\"Adriana\",\"last\":\"Romero\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Rabbat\",\"middle\":[]},{\"first\":\"Pascal\",\"last\":\"Vincent\",\"middle\":[]},{\"first\":\"Nafissa\",\"last\":\"Yakubova\",\"middle\":[]},{\"first\":\"James\",\"last\":\"Pinkerton\",\"middle\":[]},{\"first\":\"Duo\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Erich\",\"last\":\"Owens\",\"middle\":[]},{\"first\":\"C.\",\"last\":\"Zitnick\",\"middle\":[\"Lawrence\"]},{\"first\":\"Michael\",\"last\":\"Recht\",\"middle\":[\"P.\"]},{\"first\":\"Daniel\",\"last\":\"Sodickson\",\"middle\":[\"K.\"]},{\"first\":\"Yvonne\",\"last\":\"Lui\",\"middle\":[\"W.\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background.", "fields_of_study": "[\"Computer Science\",\"Engineering\",\"Physics\",\"Mathematics\"]", "external_ids": {"arxiv": "1811.08839", "mag": "2900756484", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1811-08839", "doi": null}}, "content": {"source": {"pdf_hash": "de8da4caee17c48b36255315546d461d3c5b9828", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "e9b1a7c3279894de13484d9935b2071fcbfb7967", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/de8da4caee17c48b36255315546d461d3c5b9828.txt", "contents": "\nfastMRI: An Open Dataset and Benchmarks for Accelerated MRI\n\n\nJure Zbontar \nFacebook AI Research\n\n\nFlorian Knoll \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nAnuroop Sriram \nFacebook AI Research\n\n\nTullie Murrell \nFacebook AI Research\n\n\nZhengnan Huang \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nMatthew J Muckley \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nAaron Defazio \nFacebook AI Research\n\n\nRuben Stern \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nPatricia Johnson \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nMary Bruno \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nMarc Parente \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nKrzysztof J Geras \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nJoe Katsnelson \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nHersh Chandarana \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nZizhao Zhang \nUniversity of Florida\n\n\nMichal Drozdzal \nFacebook AI Research\n\n\nAdriana Romero \nFacebook AI Research\n\n\nMichael Rabbat \nFacebook AI Research\n\n\nPascal Vincent \nFacebook AI Research\n\n\nNafissa Yakubova \nFacebook AI Research\n\n\nJames Pinkerton \nFacebook AI Research\n\n\nDuo Wang \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nErich Owens \nFacebook AI Research\n\n\nC Lawrence Zitnick \nFacebook AI Research\n\n\nMichael P Recht \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nDaniel K Sodickson \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nYvonne W Lui \nNYU School of Medicine 3 NYU Center for Data Science\n\n\nfastMRI: An Open Dataset and Benchmarks for Accelerated MRI\n\nAccelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background. arXiv:1811.08839v2 [cs.CV] 11 Dec 2019 artifacts are introduced which must be eliminated in the course of image reconstruction. This can be achieved by incorporating additional a priori knowledge during the image reconstruction process.The last two years have seen the rapid development of machine learning approaches for MR image reconstruction, which hold great promise for further acceleration of MR image acquisition[10,48,11,35,60]. Some of the first work on this subject was presented at the 2016 annual meeting of the International Society for Magnetic Resonance in Medicine (ISMRM). The 2017 ISMRM annual meeting included, for the first time, a dedicated session on machine learning for image reconstruction, and presentations on the subject at the 2018 annual meeting spanned multiple focused sessions, including a dedicated category for abstracts.Despite this substantial increase in research activity, the field of MR image reconstruction still lacks large-scale, public datasets with consistent evaluation metrics and baselines. Many MR image reconstruction studies use datasets that are not openly available to the research community. This makes it challenging to reproduce and validate comparisons of different approaches, and it restricts access to work on this important problem to researchers associated with or cooperating with large academic medical centers where such data is available.In contrast, research in computer vision applications such as object classification has greatly benefited from the availability of large-scale datasets associated with challenges such as the Ima-geNet Large Scale Visual Recognition Challenge (ILSVRC)[31]. Such challenges have served as a catalyst for the recent explosion in research activity on deep learning[21].The goal of the fastMRI dataset is to provide a first step towards enabling similar breakthroughs in the machine-learning-based reconstruction of accelerated MR images. In this work we describe the first large-scale release of raw MRI data that includes 8344 volumes, consisting of 167,375 slices 1 , associated with in vivo examinations from a range of MRI systems. In addition, we are releasing processed MR images in DICOM format from 20,000 knee and brain examinations from a representative clinical patient population, consisting of more than 1.57 million slices.Prior to providing details about the dataset and about target reconstruction tasks with associated benchmarks, we begin with a brief primer on MR image acquisition and reconstruction, in order to enable non-MRI-experts to get up to speed quickly on the information content of the dataset. In general, both the fastMRI dataset and this paper aim to connect the data science and the MRI research communities, with the overall goal of advancing the state of the art in accelerated MRI.\n\nIntroduction\n\nThe excellent soft tissue contrast and flexibility of magnetic resonance imaging (MRI) makes it a very powerful diagnostic tool for a wide range of disorders, including neurological, musculoskeletal, and oncological diseases. However, the long acquisition time in MRI, which can easily exceed 30 minutes, leads to low patient throughput, problems with patient comfort and compliance, artifacts from patient motion, and high exam costs.\n\nAs a consequence, increasing imaging speed has been a major ongoing research goal since the advent of MRI in the 1970s. Increases in imaging speed have been achieved through both hardware developments (such as improved magnetic field gradients) and software advances (such as new pulse sequences). One noteworthy development in this context is parallel imaging, introduced in the 1990s, which allows multiple data points to be sampled simultaneously, rather than in a traditional sequential order [39,26,9].\n\nThe introduction of compressed sensing (CS) in 2006 [2,23] promised another breakthrough in the reduction of MR scan time. At their core, CS techniques speed up the MR acquisition by acquiring less measurement data than has previously been required to reconstruct diagnostic quality images. Since undersampling of this kind violates the Nyquist-Shannon sampling theorem, aliasing 2 Introduction to MR Image Acquisition and Reconstruction MR imaging is an indirect process, whereby cross-sectional images of the subject's anatomy are produced from frequency and phase measurements instead of direct, spatially-resolved measurements. A measuring instrument, known as a receiver coil, is placed in proximity to the area to be imaged ( Figure 1). During imaging, a sequence of spatially-and temporally-varying magnetic fields, called a \"pulse sequence,\" is applied by the MRI machine. This induces the body to emit resonant electromagnetic response fields which are measured by the receiver coil. The measurements typically correspond to points along a prescribed path through the multidimensional Fourier-space representation of an imaged body. This Fourier space is known as k-space in the medical imaging community. In the most basic usage of MR imaging, the full Fourier-space representation of a region is captured by a sequence of samples that tile the space up to a specified maximum frequency. The spatially-resolved image m can be estimated from the full k-space y by performing an inverse multidimensional Fourier transform:\nm = F \u22121 (y),(1)\nwherem is a noise-corrupted estimate of the true image m.\n\nThe number of samples captured in k-space is a limiting factor for the speed of MR imaging. Fewer samples can be captured by sampling up to a lower maximum frequency, however this produces images of lower spatial resolution. An alternative undersampling approach involves omitting some number of k-space samples within a given maximum frequency range, which then results in aliasing artifacts. In order to remove these artifacts and infer the true underlying spatial structure of the imaged subject, one may apply a number of possible reconstruction strategies.\n\n\nParallel MR Imaging\n\nIn parallel MR imaging, multiple receiver coils are used, each of which produces a separate k-space measurement matrix. Each of these matrices is different, since the view each coil provides of the imaged volume is modulated by the differential sensitivity that coil exhibits to MR signal arising from different regions. In other words, each coil measures Fourier components of the imaged volume multiplied by a complex-valued position-dependent coil sensitivity map S i . The measured k-space signal y i for coil i in an array of n c coils is given by\ny i = F (S i m) + noise,(2)\nwhere the multiplication is entry-wise. This is illustrated in Figure 2b, which shows the absolute value of the inverse discrete Fourier transform (DFT) of fully-sampled complex-valued k-space signals for each coil in a 15-element coil array. Each coil is typically highly sensitive in one region, and its sensitivity falls off significantly in other regions. If the sensitivity maps are known, and the k-space sampling is full (i.e., satisfying the Nyquist sampling condition), then the set of linear relations between m and each y i defines a linear system that is overdetermined by a factor of n c . It may be inverted using a pseudoinverse operation to produce a reconstruction of m, as long as the linear system is full rank. The quality of this reconstruction will depend on the measurement noise, since the signal-to-noise ratio is poor in parts of the volume where the coil sensitivity is low.\n\nIn accelerated parallel imaging, each coil's k-space signal is undersampled. As long as the total number of measurements across all coils exceeds the number of image voxels to be reconstructed, an unregularized least squares solution can still be used, leading to a theoretical n c -fold  speedup over fully-sampled single-coil imaging. Each extra coil effectively produces an additional \"sensitivity-encoded\" measurement of the volume [26], which augments the frequency and phase encoded measurements obtained from the sequential application of magnetic field gradients in the MR pulse sequence. Estimates of coil sensitivity patterns, required for inversion of the undersampled multi-coil linear system, may be generated from separate low-resolution calibration scans. They may also be derived directly from the k-space measurements by fully sampling a comparatively small central region of k-space, which corresponds to low spatial frequencies.\n\nIn practice, the use of sub-sampling results in significant amplification of noise, and regularization is usually needed. In cases where a tight imaging field of view is used, or at imaging depths exceeding the dimensions of the individual coils, the sensitivity patterns of different coils spread out, thereby lowering the effective rank of the linear system, increasing noise amplification associated with the inverse operation, and limiting the maximum practical acceleration. As a result, in the clinic, parallel imaging acceleration factors are typically on the order of two to three.\n\n\nMachine Learning Reconstruction of Undersampled MRI Data\n\nClassical approaches to MRI reconstruction solve a regularized inverse optimization problem to find the spatially-resolved image from the sub-sampled k-space data, in both the single-coil and the multi-coil case. We describe the classical approach in more detail in Section 6. In the machine learning approach, a reconstruction functionm\n= B(y)(3)\nis learned from input and output pair tuples (y, m) drawn from a population. The goal is to find a function B that minimizes the risk (i.e., expected loss) over the population distribution:\nB * = arg min B R(B), where R(B) = E (y,m) [L (B (y) , m)] .\nWe discuss error metrics that may be used as loss functions L in Section 5. In practice this optimization problem must be approximated with the empirical risk using a sample {(m (i) , y (i) )} n data i=1 from the population, with respect to a loss function L:\nR empirical (B) = 1 n data n data i=1 L B y (i) , m (i) .(4)\n\nPrior Public Datasets\n\nThe availability of public datasets has played an important role in advancing research in medical imaging, providing benchmarks to compare different approaches and leading to more impactful contributions. Early works such as DDSM [13], SLIVER07 [14] and CAUSE07 [8] triggered increasing efforts to collect new larger-scale biomedical datasets, which resulted in over one hundred public releases (counting the entries on https://grand-challenge.org/) to advance medical image analysis research. The vast majority of these datasets, which include a range of medical imaging modalities, are designed to test the limits of current methods in the tasks of segmentation, classification, and detection. Datasets such as BraTS [24], LUNA [37], ChestX-ray [50], DeepLesion [55], and Camelyon [1], UK biobank 2 , ADNI (Alzheimers Disease Neuroimaging Initiative) 3 4 . However, none of the most prominent public MRI datasets include k-space imaging data. However, the current lack of large-scale reference standards for MR image reconstruction hinders progress in this important area. Most research uses synthetic k-space data that is not directly acquired but rather obtained from post-processing of already-reconstructed images [5,38,57,56,27]. Research using small-scale proprietary raw k-space datasets is also common [15,36,35,33,22].\n\nIn order to address the above-mentioned shortcomings, recent efforts have been devoted to collecting and publicly releasing datasets containing raw (unprocessed) k-space data; see, e.g., [34,11]. However, the size of these existing datasets remains small. As an example, Table 1 lists publicly available knee MR datasets containing raw k-space data. Although datasets such as these provide a valuable test bed for signal processing methods, larger datasets encompassing different anatomy are required to fully realize the potential of deep learning.\n\n\nThe fastMRI Dataset and Associated Tasks\n\nThe fastMRI dataset (http://fastmri.med.nyu.edu/) contains four types of data from MRI acquisitions of knees and brains Raw multi-coil k-space data: unprocessed complex-valued multi-coil MR measurements.\n\nEmulated single-coil k-space data: combined k-space data derived from multi-coil k-space data in such as way as to approximate single-coil acquisitions, for evaluation of single-coil reconstruction algorithms.\n\nGround-truth images: real-valued images reconstructed from fully-sampled multi-coil acquisitions using the simple root-sum-of-squares method detailed below. These may be used as references to evaluate the quality of reconstructions.\n\nDICOM images: spatially-resolved images for which the raw data was discarded during the acquisition process. These images are provided to represent a larger variety of machines and settings than are present in the raw data.\n\nThis data was designed to enable two distinct types of tasks:\n\n1. Single-coil reconstruction task: reconstruct images approximating the ground-truth from undersampled single-coil data.\n\n2. Multi-coil reconstruction task: reconstruct images approximating the ground-truth from undersampled multi-coil data.\n\nFor each task we provide an official split of the k-space data and ground-truth images into training and validation subsets that contain fully-sampled acquisitions, as well as test and challenge subsets which contain k-space data that have been subjected to undersampling masks as described below. Ground-truth images are not being released for the test and challenge datasets. During training of a machine-learning model, the training k-space data should be programmatically masked following the same procedure. The challenge subsets are not being released at the time of writing and are reserved for future challenges associated with the fastMRI dataset.\n\nThe rationale for having a single-coil reconstruction task (and for providing simulated single-coil data), even though reconstruction from multi-coil data is expected to be more precise, is twofold: (i) to lower the barrier of entry for researchers who may not be familiar with MRI data, since the use of a single coil removes a layer of complexity, and (ii) to include a task that is relevant for the single-coil MRI machines still in use throughout the world.\n\nThe DICOM images may be useful as additional data for training. Their distribution is different from that of the ground-truth images, since they were acquired with a larger diversity of scanners, manners of acquisition, reconstruction methods, and post-processing algorithms, so the application of transfer-learning techniques may be necessary. Most DICOM images are the result of accelerated parallel imaging acquisitions and corresponding reconstructions, with image quality that differs from that of putative fully-sampled acquisitions and reconstructions. The ground-truth images may, in many cases, represent a higher standard of image quality than the clinical gold standard, for which full sampling is not routine or even practical.\n\n\nAnonymization\n\nCuration of the datasets described here was part of a study approved by the NYU School of Medicine Institutional Review Board. Raw data was anonymized via conversion to the vendorneutral ISMRMRD format [18]. DICOM data was anonymized using the RSNA clinical trial processor. We performed manual inspection of each DICOM image for the presence of unexpected protected health information (PHI), manual checking of metadata in raw data files, as well as spot checking of all metadata and image content.\n\n\nKnee k-space Data\n\nMulti-coil raw data was stored for 1,594 scans acquired for the purpose of diagnostic knee MRI. For each scan, a single fully sampled MRI volume was acquired on one of three clinical 3T systems (Siemens Magnetom Skyra, Prisma and Biograph mMR) or one clinical 1.5T system (Siemens Magnetom Aera). Data acquisition used a 15 channel knee coil array and conventional Cartesian 2D TSE protocol employed clinically at NYU School of Medicine. The dataset includes data from two pulse sequences, yielding coronal proton-density weighting with (PDFS, 798 scans) and without (PD, 796 scans) fat suppression (see Figure 3). Sequence parameters are, as per standard clinical protocol, matched as closely as possible between the systems. The following sequence parameters were used: Echo train length 4, matrix size 320 \u00d7 320, in-plane resolution 0.5mm\u00d70.5mm, slice thickness 3mm, no gap between slices. Timing varied between systems, with repetition time (TR) ranging between 2200 and 3000 milliseconds, and echo time (TE) between 27 and 34 milliseconds.\n\n\nBrain k-space Data\n\nData from 6970 fully sampled brain MRIs were obtained using 11 magnets across 5 clinical locations using 1.5T and 3T field strengths. Magnets include the 3T Prisma, Skyra, Biograph, Tim Trio and the 1.5T Avanto and Aera Magnetom (Siemens Healthcare, Erlangen Germany). The raw dataset  includes axial T1 weighted, T2 weighted and FLAIR images. Some of the T1 weighted acquisitions included admissions of contrast agent (labelled T1 POST) (see Figure 4). Not all imaging volumes included all pulse sequences. The exact distribution of contrasts and field strengths is given in table 3.\n\nTo ensure data de-identification, we used only axial 2-D images in this dataset. We used zero matrices to replace the k-space slices 5mm below the orbital rim. All processed k-spaces were then reconstructed to images in DICOM format, loaded into a picture archival communication system (PACS) and all images were visually checked by certified MR technologists to confirm exclusion of identifying facial features.\n\n\nKnee emulated Single-coil k-Space Data\n\nWe used an emulated single-coil (ESC) methodology to simulate single-coil data from a multi-coil acquisition [43]. ESC computes a complex-valued linear combination of the responses from multiple coils, with the linear combination fitted to the ground-truth root-sum-of-squares reconstruction in the least-squares sense.\n\n\nKnee DICOM Data\n\nIn addition to the scanner raw data described above, the fastMRI dataset includes DICOM data from 10,000 clinical knee MRI scans. These images represent a wider variety of scanners and pulse sequences than those represented in the collection of raw data. Each MR exam for which DICOM images are included typically consisted of five clinical pulse sequences:\n\n1. Coronal proton-density weighting without fat suppression, 2. Coronal proton-density weighting with fat suppression, 3. Sagittal proton-density weighting without fat suppression, 4. Sagittal T2 weighting with fat suppression, and 5. Axial T2 weighting with fat suppression.\n\nThe two coronal sequences have the same basic specifications (matrix size, etc) as the sequences associated with raw data. The sagittal and axial sequences have different matrix sizes and have no direct correspondence to the sequences represented in raw data.\n\nThe Fourier transformation of an image from a DICOM file does not directly correspond to the originally measured raw data, due to the inclusion of additional post-processing steps in the vendorspecific reconstruction pipeline. Most of the DICOM images are also derived from accelerated acquisitions and are reconstructed with parallel imaging algorithms, since this baseline acceleration represents the current clinical standard. The image quality of DICOM images, therefore, is not equivalent to that of the ground truth images directly associated with fully sampled raw data. The DICOM images are distinct from the validation, test, or challenge sets.\n\n\nBrain DICOM\n\n10,000 brain MRI DICOM studies are also included. Axial 2D image volumes are included with the following pulse sequences: T1, T2, and T2 FLAIR. All studies represent unique individuals and there is no subject overlap with the brain rawdata. In addition to the deidentification procedures detailed above, the brain image volumes were cropped to exclude identifiable facial features, following which each image was visually inspected to confirm appropriate deidentification. Finally, we present 10,000 brain MRI DICOM studies from 10,000 unique subjects, each one including axial 2D DICOM image volumes through the majority of the brain representing a broad range of neurological pathologies. Not all studies include all pulse sequences.\n\n\nGround Truth\n\nThe root-sum-of-squares reconstruction method applied to the fully sampled k-space data [28] provides the ground truth for the multi-coil dataset. The single-coil dataset includes two ground truth reconstructions, which we denote ESC and RSS. The ESC ground truth is given by the inverse Fourier transform of the single-coil data, and the RSS ground truth is given by the root-sum-ofsquares reconstruction computed on the multi-coil data that were used to generate the virtual single-coil k-space data. All ground truth images are cropped to the central 320 \u00d7 320 pixel region to compensate for readout-direction oversampling that is standard in clinical MR examinations.\n\nThe root-sum-of-squares approach [28] is one of the most commonly-used coil combination methods in clinical imaging. It first applies the inverse Fourier Transform to the k-space data from each coil:m\ni = F \u22121 (y i ),(5)\nwhere y i is the k-space data from the ith coil andm i is the ith coil image. Then, the individual coil images are combined voxel by voxel as follows:\nm rss = nc i=0 |m i | 2 1/2 ,(6)\nwherem rss is the final image estimate and n c is the number of coils. The root-sum-of-squares image estimate is known to converge to the optimal, unbiased estimate of m in the high-SNR limit [20].    \n\n\nDataset Split\n\nEach volume is randomly assigned to one of the following six component datasets: training, validation, multi-coil test, single-coil test, multi-coil challenge, or single-coil challenge. Table 4 shows the number of volumes assigned to each dataset. The training and validation datasets may be used to fit model parameters or to determine hyperparameter values. The test dataset is used to compare the results across different approaches. To ensure that models do not overfit to the test set, the ground truth reconstructions are not publicly released for this set. Evaluation on the test set is accomplished by uploading results to the public leaderboard at http://fastmri.org/. The challenge portion of the dataset will be forthcoming. A volume from the train or validation dataset is used in both the single-coil and multi-coil tracks, whereas a volume from the test or challenge dataset is only used in either the single-coil or the multi-coil track. Volumes were only included in a single test or challenge set to ensure information from one could not be used to help the result in another.\n\n\nCartesian Undersampling\n\nVolumes in the test and challenge datasets contain undersampled k-space data. The undersampling is performed by retrospectively masking k-space lines from a fully-sampled acquisition. k-space lines are omitted only in the phase encoding direction, so as to simulate physically realizable accelerations in 2D data acquisitions. The same undersampling mask is applied to all slices in a volume, with each case consisting of a single volume. The overall acceleration factor is set randomly to either four or eight (representing a four-fold or an eight-fold acceleration, respectively), with equal probability for each.\n\nAll undersampling masks are generated by first including some number of adjacent lowestfrequency k-space lines to provide a fully-sampled k-space region. When the acceleration factor equals four, the fully-sampled central region includes 8% of all k-space lines; when it equals eight, 4% of all k-space lines are included. The remaining k-space lines are included differently for both knee and brain cases. For knee, the remaining k-space lines are included uniformly at random, with the probability set so that, on average, the undersampling mask achieves the desired acceleration factor. Random undersampling is chosen in order to meet the general conditions for compressed sensing [2,23], for a fair comparison of learned reconstruction algorithms with traditional sparsitybased regularizers. For brain, after a random offset from the start, the remaining lines are sampled equidistant from each other with a spacing that achieves the desired acceleration factor. Equidistant was chosen because of ease of implementation on existing MRI machines. Figure 5 depicts the kspace trajectories for random and equidistant undersampling at four and eight acceleration factors.\n\n\nMetrics\n\nThe assessment of MRI reconstruction quality is of paramount relevance to develop and compare machine learning and medical imaging systems [51,53,3,58]. The most commonly used evaluation metrics in the MRI reconstruction literature [3] include (normalized) mean squared error, which measures pixel-wise intensity differences between reconstructed and reference images, and signalto-noise ratio, which measures the degree to which image information rises above background noise. These metrics are appealing because they are easy to understand and efficient to compute. However, they both evaluate pixels independently, ignoring the overall image structure.\n\nAdditional metrics have been introduced in the literature to capture structural distortion [41,6,58]. For example, the structural similarity index [53] and its extended version, multiscale structural   [52], provide a mechanism to assess the perceived quality of an image using local image patches.\n\nThe most recent developments in the computer vision literature leverage pretrained deep neural networks to measure the perceptual quality of an image by computing differences at the representation level [19], or by means of a downstream task such as classification [32].\n\nIn the remainder of this section, we review the definitions of the commonly-used metrics of normalized mean square error, peak signal-to-noise ratio, and structural similarity. As is discussed later, while we expect these metrics to serve as a familiar starting point, we also hope that the fastMRI dataset will enable robust investigations into improved evaluation metrics as well as improved reconstruction algorithms.\n\n\nNormalized Mean Square Error\n\nThe normalized mean square error (NMSE) between a reconstructed image or image volume represented as a vectorv and a reference image or volume v is defined as\nNMSE(v, v) = v \u2212 v 2 2 v 2 2 ,(7)\nwhere \u00b7 2 2 is the squared Euclidean norm, and the subtraction is performed entry-wise. In this work we report NMSE values computed and normalized over full image volumes rather than individual slices, since image-wise normalization can result in strong variations across a volume.\n\nNMSE is widely used, and we recommend that it be reported as the primary measure of reconstruction quality for experiments on the fastMRI dataset. However, due to the many downsides of NMSE, such as a tendency to favor smoothness rather than sharpness, we recommend also reporting additional metrics such as those described below.\n\n\nPeak Signal-to-Noise Ratio\n\nThe peak signal-to-noise ratio (PSNR) represents the ratio between the power of the maximum possible image intensity across a volume and the power of distorting noise and other errors:\nPSNR(v, v) = 10 log 10 max(v) 2 MSE(v, v) .(8)\nHerev is the reconstructed volume, v is the target volume, max(v) is the largest entry in the target volume v, MSE(v, v) is the mean square error betweenv and v defined as 1 n v \u2212 v 2 2 and n is the number of entries in the target volume v. Higher values of PSNR (as opposed to lower values of NMSE) indicate a better reconstruction.\n\n\nStructural Similarity\n\nThe structural similarity (SSIM) index measures the similarity between two images by exploiting the inter-dependencies among nearby pixels. SSIM is inherently able to evaluate structural properties of the objects in an image and is computed at different image locations by using a sliding window. The resulting similarity between two image patchesm and m is defined as\nSSIM(m, m) = (2\u00b5m\u00b5 m + c 1 )(2\u03c3m m + c 2 ) (\u00b5 2 m + \u00b5 2 m + c 1 )(\u03c3 2 m + \u03c3 2 m + c 2 ) ,(9)\nwhere \u00b5m and \u00b5 m are the average pixel intensities inm and m, \u03c3 2 m and \u03c3 2 m are their variances, \u03c3m m is the covariance betweenm and m and c 1 and c 2 are two variables to stabilize the division; c 1 = (k 1 L) 2 and c 2 = (k 2 L) 2 . For SSIM values reported in this paper, we choose a window size of 7 \u00d7 7, we set k 1 = 0.01, k 2 = 0.03, and define L as the maximum value of the target volume, L = max(v).\n\n\nL1 Error\n\nIt is sometimes advantageous to use the L1 loss\nL 1 (v, v) = v \u2212 v 1 ,(10)\nfor training machine learning models on computer vision tasks, even when evaluation is performed under L2 norm losses such as MSE [59]. The baseline models in Section 6.3 were trained using L1 loss.  \n\n\nBaseline Models\n\nAlong with releasing the fastMRI data, we detail two reference approaches to be used as reconstruction baselines: a classical non-machine learning approach, and a deep-learning approach. Each of these baselines has versions tailored for single-coil or multi-coil data. The \"classical\" baselines are comprised of reconstruction methods developed by the MRI community over the last 30+ years.\n\nThese methods have been extensively tested and validated, and many have demonstrated robustness sufficient for inclusion in the clinical workflow. By comparison, machine learning reconstruction methods are relatively new in MRI, and deep-learning reconstruction techniques in particular have emerged only in the past few years. We include some deliberately rudimentary deep-learning models as starting points, with the expectation that future learning algorithms will provide markedly improved performance.\n\n\nSingle-coil Classical Baselines (knee only)\n\nIn the single-coil imaging setting, the task is to reconstruct an image, m, from k-space observations, y. In the presence of undersampling, the vector y has a length smaller than that of m. Therefore there are, in principle, infinitely many possibilities for m that can be mapped onto a single y.\n\nThe advent of compressed sensing [2,23] provided a framework for reconstruction of images from undersampled data that closely approximate images derived from fully-sampled data, subject to sparsity constraints. Compressed sensing theory requires the images in question to be sparse in some transform domain. Two common examples are to assume sparsity in the wavelet domain, or to assume sparsity of the spatial gradients of the image. The particular assumption impacts the mathematical formulation of the reconstruction problem, either in the cost function or through a regularization term. More concretely, the sparse reconstruction approach consists of finding an image m whose Fourier space representation is close to the measured k-space matrix y at all measured spatial frequencies, yet at the same time minimizes a sparsity-inducing objective R(m) that penalizes unnatural reconstructions:\nminimize m R (m) s.t. P (F (m)) \u2212 y 2 2 \u2264 .(11)\nHere, P is a projection function that zeros out entries that are masked, and is a specified small threshold value. In most applications it is easier to work with a soft penalty instead of a constraint, so the Lagrangian dual form of Equation 11 is used instead, with penalty parameter \u03bb:\nminimize m 1 2 P (F (m)) \u2212 y 2 2 + \u03bbR (m) .(12)\nFor a convex regularizer R, there exists, for any choice > 0, a value \u03bb such that these two formulations have equivalent solutions. The most common regularizers used for MRI are:\nR L1 (m) = m 1 , R wavelet (m) = \u03a8 (m) 1 (\u03a8 is a discrete wavelet transform) , R T V (m) = i,j |m i+1,j \u2212 m i,j | 2 + |m i,j+1 \u2212 m i,j | 2 .\nThe L1 penalty works best when the MR images are sparse in image space, for instance in vascular imaging (e.g., Yamamoto et al. [54]). This is not the case for most MRI applications. The totalvariation (TV) penalty encourages sparsity in the spatial gradients of the reconstructed image, as given by a local finite-difference approximation [30] (Figure 6g). The TV regularizer can be very effective for some imaging protocols, but it also has a tendency to remove detail (Figure 6h). The R wavelet penalty encourages sparsity in the discrete wavelet transform of the image. Most natural images exhibit significant sparsity when expressed in a wavelet basis. The most commonly used transform is the Multiscale Daubechies (DB2) transform (Figure 6e). To date, due to their computational complexity as well as their tendency to introduce compression artifacts or oversmoothing, compressed sensing approaches have taken some time to gain acceptance in the clinic, though commercial implementations of compressed sensing are currently beginning to appear. The single-coil classical baseline provided with the fastMRI dataset was adopted from the widely-used open-source BART toolkit (Appendix B), using total variation as the regularizer. We ran the optimization algorithm for 200 iterations on each slice independently. Table 5 summarizes the results of applying this method to the single-coil validation data with different regularization strengths and different acceleration factors. These results indicate that NMSE and PSNR metrics are highly (inversely) correlated and generally favor models with stronger regularization than SSIM does. Stronger regularization generally results in smoother images that lack the fine texture of the ground truth images. A regularization parameter of 0.01 yields the best results for 4-fold acceleration in most cases, whereas the higher 8-fold acceleration gets slightly better results with a regularization parameter of 0.1.  \n\n\nSingle-coil classical baseline (TV model) applied to knee validation data\n\n\nMulti-coil Classical Baselines\n\nWhen multiple receiver coils are used, the reconstruction process must combine information from multiple channels into one image. Multi-coil acquisitions currently represent the norm in clinical practice, for two principal reasons: they provide increased SNR, as compared with single-coil acquisitions, over extended fields of view, and they enable acceleration via parallel imaging. Equation 2 in Section 2.1 describes the forward model for parallel imaging. The SENSE formulation [26] of parallel image reconstruction involves direct inversion of this forward model, via a suitable pseudoinverse. Leveraging the convolution property of the Fourier Transform reveals the following convolution relationship:\ny i = g i F (m) + noise.(13)\nHere g i is the Fourier Transform of the coil sensitivity pattern S i and denotes the convolution operation. The GRAPPA/SMASH formulation of parallel image reconstruction [39,9] involves filling in missing k-space data via combinations of acquired k-space data within a defined convolution kernel, prior to inverse Fourier transformation.\n\nEither formulation requires estimates of the coil sensitivity information in S i or g i , which may be derived either from a separate reference scan or directly from the acquired undersampled k-space data itself. Reference scan methods are often used in the SENSE formulation, whereas GRAPPA formulations are typically self-calibrating, relying on subsets of fully-sampled data generally in central k-space regions.\n\nThe parallel imaging techniques described above may be combined productively with compressed sensing, via the use of sparsity-based regularizers. For example, one may extend Equation 12 in Section 6.1 above to include multi-coil data as follows:\nminimize m 1 2 nc i=1 P (F (S i m)) \u2212 y i 2 2 + \u03bbR (m) .(14)\nVarious methods may be used to solve this reconstruction problem. One frequently-used method is the ESPIRiT approach [45], which harmonizes parallel imaging and compressed sensing in a unified framework.\n\nAs was the case for the classical single-coil baseline, the classical multi-coil baseline provided with the fastMRI dataset was adopted from the BART toolkit (Appendix B). In the multi-coil case, the ESPIRiT algorithm was used to estimate coil sensitivities, and to perform parallel image reconstruction in combination with compressed sensing using a total-variation regularizer.\n\nMulti-coil classical baseline (TV model) applied to knee validation data  Results using this baseline model are summarized in Table 6 and 7 . The experimental setup is identical to the single-coil scenario, except that we compare the reconstructions with the rootsum-of-squares ground truth instead of the ESC ground truth.\n\n\nSingle-coil Deep-Learning Baselines (knee only)\n\nVarious deep-learning techniques based on Convolutional Neural Networks have recently been proposed to tackle the problem of reconstructing MR images from undersampled k-space data [10,48,11,35,60,17,12]. Many of these proposed methods are based on the U-Net architecture introduced in [29]. U-Net models and their variants have successfully been used for many image-to-image prediction tasks including MRI reconstruction [17,12] and image segmentation [29].\n\nThe U-Net single-coil baseline model included with the fastMRI data release (Figure 7) consists of two deep convolutional networks, a down-sampling path followed by an up-sampling path. The down-sampling path consists of blocks of two 3\u00d73 convolutions each followed by instance normalization [46] and Rectified Linear Unit (ReLU) activation functions. The blocks are interleaved by down-sampling operations consisting of max-pooling layers with stride 2 which halve each spatial dimension. The up-sampling path consists of blocks with a similar structure to the down-sampling path, interleaved with bilinear up-sampling layers which double the resolution between blocks. Each block consists of two 3\u00d73 convolutions with instance normalization [46] and ReLU activation layers. In contrast to the down-sampling path, the up-sampling path concatenates two inputs to the first convolution in each block: the up-sampled activations from the previous block, together with the activations that follow the skip connection from the block in the down-sampling path with the same resolution (horizontal arrows in Figure 7). At the end of the up-sampling path, we  For the single-coil MRI reconstruction case, the zero-filled image is used as the input to the model. The zero-filled image is obtained by first inserting zeros at the location of all unobserved k-space values, applying a two-dimensional Inverse Fourier Transform (IFT) to the result, and finally computing the absolute value. The result is center cropped to remove any readout and phase oversampling. Using the notation from section 6.1, the zero-filled image is given bym = C( F \u22121 (P(y)) ), where C is the linear operator corresponding to the center cropping and F \u22121 is the two-dimensional IFT.\n\nThe entire network is trained on the training data in an end-to-end manner to minimize the mean absolute error with respect to corresponding ground truth images. Let B \u03b8 (m) be the function computed by the U-Net model, where \u03b8 represents the parameters of the model. Then the training process corresponds to the following optimization problem:\nminimize \u03b8 1 2 n data i=0 B \u03b8 (m (i) ) \u2212 m (i) 1 ,(15)\nwhere the ground truths m (i) are obtained using the ESC method described in Section 4.4. Our particular single-coil U-Net baseline model was trained on 973 image volumes in the training set, using the RMSProp algorithm [42]. We used an initial learning rate of 0.001, which was multiplied by 0.1 after 40 epochs, after which the model was trained for an additional 10 epochs. During training, we randomly sampled a different mask for each training example in each epoch independently using the protocol described in Section 4.9 for the test data. At the end of each epoch, we recorded the NMSE on the validation data. After training, we picked the model that achieved the lowest validation NMSE. Table 8 presents the results from running trained U-Net models of different capacities on the single-coil validation data. These results indicate that the trained U-Net models perform significantly better than the classical baseline method. The best U-Net models obtain 40-50% relative improvement over the classical methods (see Table 5) in terms of NMSE.\n\nThe performance of the U-Net models continues to increase with increasing model capacity, and even the largest model with over 200 million parameters is unable to overfit the training data. These improvements begin to saturate after 50 million parameters for the simpler 4-fold acceleration case. However, for the more challenging 8-fold acceleration task, the largest model performs significantly better than the smaller models. This suggests that models with very large capacities trained on large amounts of data can enable high acceleration factors. Table 9 compares the performance of the classical and the U-Net baseline models for the singlecoil task, as applied to the test dataset. For the classical baseline model, we chose the best regularization weights for each modality and for each acceleration factor based on the validation data results, resulting in a regularization weight of 0.1 for 8-fold acceleration on Proton Density without fat suppression and 0.01 for every other case. For the U-Net baseline model, we chose the model with the largest capacity.\n\n\nMulti-coil Deep-Learning Baselines\n\nIn the multi-coil MRI reconstruction task, we have one set of undersampled k-space measurements from each coil, and a different zero-filled image can be computed from each coil. These coil images can be combined using the root-sum-of-squares algorithm. Letm i be the zero-filled image from coil i. Withm rss defined as in Equation 6, the U-Net model described in Section 6.3 can be used for the multi-coil reconstruction task by simply feeding this combined image in as input: B \u03b8 (m rss ). The model is trained to minimize the mean absolute error loss similarly to the single-coil task. The training procedure is also identical to the single-coil case except that the root-sum-of-squares image is used as the ground truth as described in Section 4.7.\n\nAs is the case for the single-coil task, the multi-coil U-Net baselines substantially outperform the classical baseline models (compare Table 10 and 11 with Table 6 and 7). Note that this is true despite the fact that the multi-coil U-Net baseline defined above does not take coil sensitivity information into account, and therefore neither includes a direct parallel image reconstruction nor accounts for sparsity or other correlations among coils. Models that incorporate coil sensitivity information are expected to perform better than the current multi-coil U-Net baselines. Table 10 and Table 11 shows, once again, that the performance of the U-Net models improves with model size, with the largest U-Net baseline model providing the best performance. Table 12 compares the performance of the classical and the U-Net baseline models for the multi-coil task, as applied to the test dataset. For the classical baseline model, we chose the best regularization weights for each modality and for each acceleration factor based on the validation data results. For knees this resulted in a regularization weight of 0.001 for 4-fold undersampling for Proton Density with Fat Suppression and 0.01 for every other acquisition type. For brain this resulted in a regularization weight of 0.001 for 8-fold AXFLAIR and 4-fold AXT1, and 0.01 for every other acquisition type. For the U-Net baseline model, we chose the model with the largest capacity.\n\nTo appreciate the value of the dataset size, we study how model performance scales with the amount of data used to train a model. To this end, we trained several U-Net models with varying model capacities on different sized subsets of the training data. Figure 8 shows the SSIM metric computed on the validation data for the multi-coil task. It is evident from these results that training with larger amounts of data yields substantial improvements in the quality of reconstructions, which highlights the need for the release of large datasets like fastMRI.\n\nAs mentioned in Section 4.5, the fastMRI dataset also includes a large set of DICOM images that can be used as additional training data. It is possible that the baseline U-Net models could be improved further by making use of this additional data. \n\n\nDiscussion\n\nMR image reconstruction is an inverse problem, and thus it has many connections to inverse problems in the computer vision literature [40,7,4,47], such as super-resolution, denoising and in-painting. In all of these inverse problems, the goal is to recover a high-dimensional ground truth image from a lower-dimensional measurement. Such ill-posed problems are very difficult to solve since there exists an infinite number of high-dimensional images that can result in the same-low dimensional measurement. In order to simplify the problem, an assumption is often made that only a small number of high-resolution images would correspond to natural images [4]. Given that MRI reconstruction is a similar inverse problem, we hope that the computer vision community, as well as the medical imaging community, will find our dataset beneficial.\n\nIn the clinical setting, radiologists use MRI to search for abnormalities, make diagnoses, and recommend treatment options. Thus, contrary to many computer vision problems where small texture changes might not necessarily alter the overall satisfaction of the observer, in MRI reconstruction, extra care should be taken to ensure that the human interpreter is not misled by a very plausible but not necessarily correct reconstruction. This is especially important as image generation techniques increase in their ability to generate photo-realistic results [49]. Therefore some research effort should be devoted to look for solutions that, by design, ensure correct diagnosis, and we hope that our dataset will provide a testbed for new ideas in these directions as well.\n\nAn important question in MRI reconstruction is the choice of the evaluation metric. The current consensus in the MRI community is that global metrics, such as NMSE, SSIM and PSNR, do not necessarily capture the level of detail required for proper evaluation of MRI reconstruction algorithms [25,16]. A natural question arises: what would the optimal metric be? An ideal MRI reconstruction algorithm should produce sharp, trustworthy images, that ultimately ensure the proper radiologic interpretation. While our dataset will help ensure consistent evaluation, we hope that it will also trigger research on MRI reconstruction metrics. This goal will be impossible to achieve without clinical studies involving radiologists evaluating fully-sampled and undersampled MRI reconstructions to make sure that both images lead to the same diagnosis.\n\nAlthough this dataset provides an excellent entry point for machine learning methods for MR reconstruction, there are some aspects of MR imaging that we have not yet considered here. Phys-  ical effects such as spin relaxation, eddy currents and field distortions are not at present explicitly accounted for in our retrospective undersampling approaches or our baseline models. The manifestation of these effects depends upon the object being imaged, the MRI scanner used, and even the sampling pattern selected. Extending the results from methods developed for this challenge to the clinic remains an open problem, but we believe the provision of this dataset is an important first step on the path to this goal.\n\n\nConclusion\n\nIn this work we detailed the fastMRI dataset: the largest raw MRI dataset to be made publicly available to date. Previous public datasets have focused on post-processed magnitude images for specific biologic and pathologic questions. Although our dataset was originally acquired for a focused task, the inclusion of raw k-space data allows methods to be developed for the imaging pipeline itself, in principle allowing them to be applied on any MRI scanner for any imaging task. In addition to the data, we provide evaluation metrics and baseline algorithms to aid the research community in assessing new approaches. Consistent evaluation of MRI reconstruction techniques is provided by a leaderboard using held-out test data.\n\nWe hope that the availability of this dataset will accelerate research in MR image reconstruction, and will serve as a benchmark during training and validation of new algorithms.\n\n\nAcknowledgements\n\nWe acknowledge grant support from the National Institutes of Health under grants NIH R01 EB024532 and NIH P41 EB017183. We would also like to thank Michela Paganini and Mark Tygert.        Table 12: Comparison of classical and U-Net baseline performance for the multi-coil task with knee test data.\n\nacquisition Acquisition protocol. For knee images this is either CORPD or CORPDF, indicating coronal proton density with or without fat saturation, respectively (see Figure 3). For Brain images this is AXFLAIR, AXT1, AXT1POST or AXT2 (see Figure 4).\n\nismrmrd header The XML header copied verbatim from the ISMRMRD file that was used to generate the HDF5 file. It contains information about the scanner, field of view, dimensions of k-space, and sequence parameters.\n\npatient id A unique string identifying the examination, and substituting anonymously for the patient identification.\n\nnorm, max The Euclidean norm and the largest entry of the target volume. For the multi-coil track the target volume is stored in reconstruction rss. For the single-coil track the target volume is stored in reconstruction esc. These two attributes are only available in the training and validation datasets.\n\nacceleration Acceleration factor of the undersampled k-space trajectory (either 4 or 8). This attribute is only available in the test dataset.\n\nnum low frequency The number of low-frequency k-space lines in the undersampled k-space trajectory. This attribute is only available in the test dataset.\n\nThe rest of this section describes the format of the HDF5 files for the multi-coil and single-coil tracks.\n\n\nA.1 Multi-coil Track\n\n{knee,brain} multicoil train.tar.gz Training dataset for the multi-coil track. The HDF5 files contain the following tensors:\n\nkspace Multi-coil k-space data. The shape of the kspace tensor is (number of slices, number of coils, height, width).\n\nreconstruction rss root-sum-of-squares reconstruction of the multi-coil k-space data. The shape of the reconstruction rss tensor is (number of slices, r height, r width). For knee images, height and width have been cropped to 320 x 320.\n\n{knee,brain} multicoil val.tar.gz Validation dataset for the multi-coil track. The HDF5 files have the same structure as the HDF5 files in multicoil train.tar.gz.\n\n{knee,brain} multicoil test.tar.gz Test dataset for the multi-coil track. The HDF5 files contain the following tensors:\n\nkspace Undersampled multi-coil k-space. The shape of the kspace tensor is (number of slices, number of coils, height, width).\n\nmask Defines the undersampled Cartesian k-space trajectory. The number of elements in the mask tensor is the same as the width of k-space.\n\n\nbart fftshift 7 input output\n\nThe input and output are specified without file extensions. The value 7 above is a bitmask indicating the image is stored in axis 0,1,2 (1+2+4) of the input array. This bitmask is used in the commands that follow also. Uncentered k-space data is easily identified by comparing the magnitude of the corners versus the center of the array. Centered FFTs of natural data will have the largest magnitudes near the center of the array when plotted.\n\nParallel MR imaging is often performed as a two-step process consisting of coil-sensitivity estimation, then reconstruction assuming the estimated sensitivity maps are exact. BART implements this approach through the ecalib and pics commands. The coil-sensitivity maps can be estimated using the ESPIRiT approach using the command bart ecalib -m1 Produce a single set of sensitivity maps -r26 Number of fully sampled reference lines input output_sens\n\nThe central reference region is used by BART to estimate the coil sensitivities. This area is also known as the auto-calibration region. The number of lines used in our masking procedure is a percentage of the k-space width, as described in Section 4.2.\n\nGiven the estimated coil sensitivities, a reconstruction using TV regularization can be performed with The output of this command is in CFL format. It can be converted to a PNG using bart toimg. When using L1 wavelet regularization, the character \"W\" should be used in the R option, with the additional -m argument to ensure that ADMM is used.\n\nFigure 1 :\n1The receiver coil housing and its positioning on a patient for a knee MR examination.\n\nFigure 2 :\n2Multi-coil MRI reconstruction\n\nFigure 3 :\n3A proton-density weighted image (a) with fat suppression (PDFS) and (b) without fat suppression (PD\n\nFigure 4 :\n4Axial brain MRI images with different contrasts: (a) FLAIR, (b) T1 weighted (c) T1 weighted with contrast agent (T1 POST), and (d) T2 weighted.\n\nFigure 5 :\n5Examples of undersampled k-space trajectories similarity\n\nFigure 6 :\n6Single-coil reconstruction\n\nFigure 7 :\n7Single-coil baseline U-Net architecture include a series of 1\u00d71 convolutions that reduce the number of channels to one without changing the spatial resolution.\n\nFigure 8 :\n8Results from training the U-Net on different amounts of training data for the multi-coil knee challenge with 4-fold acceleration (left) and 8-fold acceleration (right). Each line represents a model with a different number of channels.\n\nFigure 9 :Figure 10 :\n910Example Example brain reconstructions\n\n\u2022\nV1 (Nov 2018): Arxiv preprint describing the fastMRI knee dataset. \u2022 V2 (Dec 2019): Added neuro dataset.\n\n\nTV (T) with regularizer strength 0.05, with bitmask 7 input output_sens output\n\nTable 1 :\n1Publicly available MRI datasets containing k-space data TCIA (The Cancer Imaging Archive)\n\nTable 3 :\n3Number of scans for the different contrasts and scanner field strengths of the brain raw dataset.\n\n\n). Fat has a high signal response in MR imaging, which can make details in other regions difficult to see. Fat-suppressed scans typically have higher noise.Volumes \nSlices \n\nMulti-coil Single-coil Multi-coil Single-coil \n\ntraining \n973 \n973 \n34,742 \n34,742 \nvalidation \n199 \n199 \n7,135 \n7,135 \ntest \n118 \n108 \n4,092 \n3,903 \nchallenge \n104 \n92 \n3,810 \n3,305 \n\n\n\nTable 4 :\n4Volumes and slices in each set(a) \n\n\n\nTable 5 :\n5Validation set results for the classical baseline model with Total Variation regularization for the single-coil task. Bold-faced numbers indicate the best performance for each image quality metric.\n\nTable 6 :\n6Validation set results for the classical baseline model with Total Variation regularization for the knee multi-coil task. Bold-faced numbers indicate the best performance for each image quality metric.\n\n\nMulti-coil classical baseline (TV model) applied to brain validation dataAcceleration Regularization Weight \nSequence \nNMSE \nPSNR SSIM \n\n10 \u22124 \nAXT1 0.03971 \n31.63 \n0.5677 \nAXT1POST 0.02581 \n32.39 \n0.5814 \nAXT2 0.03624 \n30.66 \n0.528 \nAXFLAIR \n0.189 \n26.85 \n0.4512 \n\n10 \u22123 \nAXT1 0.03818 31.82 0.5724 \nAXT1POST 0.02353 \n32.81 0.5919 \nAXT2 0.03457 \n30.86 0.5312 \n4-fold \nAXFLAIR \n0.1869 \n26.96 0.4651 \n\n10 \u22122 \nAXT1 0.03888 \n31.7 \n0.5376 \nAXT1POST 0.02199 33.17 0.5522 \nAXT2 0.03419 30.9 \n0.4923 \nAXFLAIR 0.1886 \n26.75 \n0.4435 \n\n10 \u22121 \nAXT1 0.04916 \n30.54 \n0.5193 \nAXT1POST 0.02956 \n31.84 \n0.5284 \nAXT2 0.04708 \n29.39 \n0.4651 \nAXFLAIR \n0.1934 \n26.14 \n0.4048 \n\n10 \u22124 \nAXT1 0.06911 \n29.01 \n0.4823 \nAXT1POST 0.05457 \n29.09 \n0.498 \nAXT2 0.07904 \n27.05 \n0.4426 \nAXFLAIR \n0.4421 \n23.93 \n0.3549 \n\n10 \u22123 \nAXT1 0.06721 \n29.13 \n0.488 \nAXT1POST 0.05287 \n29.24 \n0.5039 \nAXT2 \n0.078 \n27.11 \n0.4405 \n8-fold \nAXFLAIR 0.1869 26.96 0.4627 \n\n10 \u22122 \nAXT1 0.05935 29.68 0.5145 \nAXT1POST 0.04514 29.92 \n0.5325 \nAXT2 0.07486 27.29 0.4336 \nAXFLAIR \n0.3893 \n24.15 \n0.3678 \n\n10 \u22121 \nAXT1 0.06322 \n29.35 0.5928 \nAXT1POST 0.04904 \n29.54 0.6187 \nAXT2 \n0.0874 \n26.6 \n0.495 \nAXFLAIR \n0.2773 \n24.66 0.4726 \n\n\n\nTable 7 :\n7Validation set results for the classical baseline model with Total Variation regularization for the brain multi-coil task. Bold-faced numbers indicate the best performance for each image quality metric.Single-coil U-Net baseline applied to knee validation dataAcceleration Channels #Params \nNMSE \nPSNR \nSSIM \n\nPD \nPDFS \nPD \nPDFS \nPD \nPDFS \n\n4-fold \n32 \n3.35M \n0.0161 \n0.0531 33.78 29.90 \n0.81 \n0.631 \n64 \n13.39M \n0.0157 \n0.0528 33.90 \n29.9 \n0.813 0.633 \n128 \n53.54M \n0.0154 0.0525 34.01 29.95 0.815 0.634 \n256 \n214.16M 0.0154 0.0525 34.00 29.95 0.815 0.636 \n\n8-fold \n32 \n3.35M \n0.0283 \n0.0698 31.13 \n28.6 \n0.754 0.555 \n64 \n13.39M \n0.0272 \n0.0693 31.30 28.63 0.758 0.558 \n128 \n53.54M \n0.0265 \n0.0686 31.44 28.68 0.761 0.558 \n256 \n214.16M 0.0261 0.0682 31.5 28.71 0.762 0.559 \n\n\n\nTable 8 :\n8Validation set results for the U-Net baseline model trained for the single-coil task. The channels column denotes the number of output channels of the first convolution in the model. Doubling this number of channels roughly quadruples the total number of parameters in the model. Bold-faced numbers indicate the best performance for each image quality metric.Single-coil classical and U-Net baselines applied to test dataModel \nAcceleration NMSE PSNR SSIM \n\nClassical Model (Total Variation) \n4-fold \n0.0479 30.69 0.603 \n8-fold \n0.0795 27.12 0.469 \nAggregate \n0.0648 28.77 0.531 \n\nU-Net \n4-fold \n0.0320 32.22 0.754 \n8-fold \n0.0480 29.45 0.651 \nAggregate \n0.0406 \n30.7 \n0.699 \n\n\n\nTable 9 :\n9Comparison of classical and U-Net baseline performance for the single-coil task with test data Multi-coil U-Net baseline applied to knee validation dataAcceleration Channels #Params \nNMSE \nPSNR \nSSIM \n\nPD \nPDFS \nPD \nPDFS \nPD \nPDFS \n\n4-fold \n32 \n3.35M \n0.0066 \n0.0122 \n36.7 \n35.97 0.9192 \n0.8595 \n64 \n13.39M \n0.0063 \n0.0120 36.95 36.11 0.9224 \n0.8615 \n128 \n53.54M \n0.0057 \n0.0113 37.38 36.33 0.9266 \n0.8641 \n256 \n214.16M 0.0054 0.0112 37.58 36.39 0.9287 0.8655 \n\n8-fold \n32 \n3.35M \n0.0144 \n0.0197 33.31 33.82 0.8778 \n0.8213 \n64 \n13.39M \n0.0136 \n0.0198 33.56 33.93 0.8825 \n0.8238 \n128 \n53.54M \n0.0123 \n0.0179 34.01 34.25 0.8892 \n0.8277 \n256 \n214.16M 0.0120 0.0181 34.12 34.23 0.8915 0.8286 \n\n\n\nTable 10 :\n10Validation set results for the U-Net baseline model trained for the multi-coil task. Boldfaced numbers indicate the best performance for each image quality metric.Multi-coil U-Net baseline applied to brain validation dataAcceleration Channels #Params \nSequence \nNMSE \nPSNR SSIM \n\n32 \n3.35M \nAXT1 0.01498 \n35.67 \n0.9215 \nAXT1POST \n0.013 \n35.43 \n0.9298 \nAXT2 0.02249 \n32.51 \n0.9112 \nAXFLAIR \n0.1572 \n30.73 \n0.7869 \n\n64 \n13.39M \nAXT1 0.01571 \n35.57 \n0.922 \nAXT1POST 0.01313 \n35.41 \n0.9307 \nAXT2 0.02014 \n32.98 \n0.9151 \n4-fold \nAXFLAIR \n0.1579 \n30.96 \n0.7917 \n\n128 \n53.54M \nAXT1 \n0.0142 \n35.92 \n0.9243 \nAXT1POST 0.01231 \n35.69 \n0.9332 \nAXT2 0.01855 \n33.34 \n0.9175 \nAXFLAIR \n0.1566 \n30.98 \n0.7932 \n\n256 \n214.16M \nAXT1 0.01317 36.24 0.9275 \nAXT1POST 0.0111 36.11 0.9361 \nAXT2 0.01733 33.63 0.9207 \nAXFLAIR 0.1532 31.52 0.7985 \n\n32 \n3.35M \nAXT1 0.04289 \n31.5 \n0.8885 \nAXT1POST 0.04186 \n31.71 \n0.8816 \nAXT2 0.04357 \n30.86 \n0.8759 \nAXFLAIR 0.1594 32.86 0.8188 \n\n64 \n13.39M \nAXT1 0.04205 32.56 0.8876 \nAXT1POST 0.04034 \n31.89 \n0.883 \nAXT2 0.04248 \n31.1 \n0.8753 \n8-fold \nAXFLAIR \n0.1818 \n30.49 \n0.7843 \n\n128 \n53.54M \nAXT1 0.04706 \n31.82 \n0.8804 \nAXT1POST 0.04005 \n31.47 \n0.8828 \nAXT2 0.04311 \n30.13 \n0.8806 \nAXFLAIR \n0.2 \n28.97 \n0.7779 \n\n256 \n214.16M \nAXT1 \n0.0443 \n32.02 \n0.8837 \nAXT1POST 0.04028 31.95 0.8845 \nAXT2 0.04167 31.29 0.8811 \nAXFLAIR \n0.1565 \n30.49 \n0.7805 \n\n\n\nTable 11 :\n11Validation set results for the U-Net baseline model trained for the brain multi-coil task. Bold-faced numbers indicate the best performance for each image quality metric.Multi-coil classical and U-Net baselines applied to test dataDataset \nModel \nAcceleration NMSE PSNR SSIM \n\nKnee \nClassical Model (Total Variation) \n4-fold \n0.0503 \n30.88 \n0.628 \n8-fold \n0.0760 \n28.25 \n0.593 \nAggregate \n0.0633 \n29.54 \n0.610 \nU-Net \n4-fold \n0.0106 \n35.91 \n0.904 \n8-fold \n0.0171 \n33.57 \n0.858 \nAggregate \n0.0139 \n34.7 \n0.881 \n\nBrain \nClassical Model (Total Variation) \n4-fold \n0.1388 \n27.53 0.4439 \n8-fold \n0.03753 31.32 0.5135 \nAggregate \n0.0882 \n29.42 0.4787 \nU-Net \n4-fold \n0.0107 \n38.13 0.9446 \n8-fold \n0.0233 \n34.52 0.9146 \nAggregate \n0.017 \n36.325 0.9296 \n\n\nA slice corresponds to one image.\nhttps://imaging.ukbiobank.ac.uk 3 http://adni.loni.usc.edu/about/#core-container 5 Dataset Volumes Body part MR scan type NYU dataset[11] 100 knee PD, T2 Stanford dataset 2D FSE 89 knee PD\nhttps://www.cancerimagingarchive.net/\nVersion 0.4.03 https://mrirecon.github.io/bart/\nA.2 Single-coil Track (knee only) knee singlecoil train.tar.gz Training dataset for the single-coil track. Note that only the knee dataset has a single-coil track. The HDF5 files contain the following tensors:kspace Emulated single-coil k-space data. The shape of the kspace tensor is (number of slices, height, width).reconstruction rss root-sum-of-squares reconstruction of the multi-coil k-space that was used to derive the emulated single-coil k-space cropped to the center 320 \u00d7 320 region. The shape of the reconstruction rss tensor is (number of slices, 320, 320).reconstruction esc The inverse Fourier transform of the single-coil k-space data cropped to the center 320 \u00d7 320 region. The shape of the reconstruction esc tensor is (number of slices, 320, 320).knee singlecoil val.tar.gz Validation dataset for the single-coil track. The HDF5 files have the same structure as the HDF5 files in singlecoil train.tar.gz.knee singlecoil test.tar.gz Test dataset for the single-coil track. Note that only the knee dataset has a single-coil track. The HDF5 files contain the following tensors:kspace Undersampled emulated single-coil k-space. The shape of the kspace tensor is (number of slices, height, width).mask Defines the undersampled Cartesian k-space trajectory. The number of elements in the mask tensor is the same as the width of k-space.B Classical Reconstruction with BARTThe Berkeley Advanced Reconstruction Toolbox (BART)[44]5 contains implementations of standard methods for coil sensitivity estimation and undersampled MR image reconstruction incorporating parallel imaging and compressed sensing. We used this tool to produce the classical baseline MSE estimates, as well as the illustrations inFigure 2. In this section we provide a brief introduction to the tool sufficient for reproducing our baseline results. We will use as an example a 640x368 undersampled MRI scan with 15 coils. The target region is a 320 \u00d7 320 central region which will be cropped to after reconstruction. BART provides a command line interface which acts on files in a simple storage format. Each multidimensional array is stored in a pair of files, a header file .hdr and a data file .cfl. The header file contains the dimensions of the array given in ASCII. In our running example, this should be input.hdr:640 368 15The CFL file contains the raw data in column-major order, stored as complex float values. Missing k-space values are indicated by 0 entries. BART provides Python and MATLAB interfaces for reading and writing this format.When working with k-space data with BART, it is simplest to use data in \"centered\" form, where the low frequency values are in the center of the image, and the high frequency values are at the edges. Most FFT libraries output the data in uncentered form. BART provides a tool for conversion:\nDiagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer. Mitko Babak Ehteshami Bejnordi, Paul Johannes Van Veta, Bram Diest, Nico Van Ginneken, Geert Karssemeijer, Litjens, Awm Jeroen, Meyke Van Der Laak, Hermsen, F Quirine, Maschenka Manson, Balkenhol, Journal of the American Medical Association. 31822Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes Van Diest, Bram Van Ginneken, Nico Karsse- meijer, Geert Litjens, Jeroen AWM Van Der Laak, Meyke Hermsen, Quirine F Manson, Maschenka Balkenhol, et al. Diagnostic assessment of deep learning algorithms for detection of lymph node metas- tases in women with breast cancer. Journal of the American Medical Association, 318(22), 2017.\n\nRobust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information. J Emmanuel, Justin Cand\u00e8s, Terence Romberg, Tao, IEEE Transactions on Information Theory. 522Emmanuel J Cand\u00e8s, Justin Romberg, and Terence Tao. Robust uncertainty principles: Exact sig- nal reconstruction from highly incomplete frequency information. IEEE Transactions on Information Theory, 52(2), 2006.\n\nSeven challenges in image quality assessment: past, present, and future research. M Damon, Chandler, ISRN Signal Processing. Damon M Chandler. Seven challenges in image quality assessment: past, present, and future research. ISRN Signal Processing, 2013.\n\nOne network to solve them all -solving linear inverse problems using deep projection models. Jen-Hao Rick Chang, Chun-Liang Li, Barnab\u00e1s P\u00f3czos, B V K Vijaya Kumar, Aswin C Sankaranarayanan, IEEE International Conference on Computer Vision (ICCV. Jen-Hao Rick Chang, Chun-Liang Li, Barnab\u00e1s P\u00f3czos, B. V. K. Vijaya Kumar, and Aswin C. Sankara- narayanan. One network to solve them all -solving linear inverse problems using deep projection models. IEEE International Conference on Computer Vision (ICCV), 2017.\n\nA transfer-learning approach for accelerated MRI using deep neural networks. Salman Ul , Hassan Dar, \u00c7 Tolga, Ukur, arXiv preprintSalman Ul Hassan Dar and Tolga \u00c7 ukur. A transfer-learning approach for accelerated MRI using deep neural networks. arXiv preprint, 2017.\n\nPerceptual quality metrics applied to still image compression. P Michael, Andrew P Eckert, Bradley, Signal Processing. 703Michael P Eckert and Andrew P Bradley. Perceptual quality metrics applied to still image compression. Signal Processing, 70(3), 1998.\n\nInverseNet: Solving inverse problems with splitting networks. Kai Fan, Qi Wei, Wenlin Wang, Amit Chakraborty, Katherine A Heller, arXiv preprintKai Fan, Qi Wei, Wenlin Wang, Amit Chakraborty, and Katherine A. Heller. InverseNet: Solving inverse problems with splitting networks. arXiv preprint, 2017.\n\n3d segmentation in the clinic: A grand challenge. Tobias Bram Van Ginneken, Martin Heimann, Styner, MICCAI Workshop on 3D Segmentation in the Clinic: A Grand Challenge. Bram Van Ginneken, Tobias Heimann, and Martin Styner. 3d segmentation in the clinic: A grand challenge. In MICCAI Workshop on 3D Segmentation in the Clinic: A Grand Challenge, 2007.\n\nGeneralized autocalibrating partially parallel acquisitions (GRAPPA). A Mark, Griswold, M Peter, Robin M Jakob, Mathias Heidemann, Vladimir Nittka, Jianmin Jellus, Berthold Wang, Axel Kiefer, Haase, Magnetic Resonance in Medicine. 476Mark A Griswold, Peter M Jakob, Robin M Heidemann, Mathias Nittka, Vladimir Jellus, Jianmin Wang, Berthold Kiefer, and Axel Haase. Generalized autocalibrating partially parallel acquisitions (GRAPPA). Magnetic Resonance in Medicine, 47(6), 2002.\n\nLearning a Variational Model for Compressed Sensing MRI Reconstruction. Kerstin Hammernik, Florian Knoll, K Daniel, Thomas Sodickson, Pock, Magnetic Resonance in Medicine (ISMRM). Kerstin Hammernik, Florian Knoll, Daniel K Sodickson, and Thomas Pock. Learning a Variational Model for Compressed Sensing MRI Reconstruction. In Magnetic Resonance in Medicine (ISMRM), 2016.\n\nLearning a variational network for reconstruction of accelerated MRI data. Kerstin Hammernik, Teresa Klatzer, Erich Kobler, Michael P Recht, Daniel K Sodickson, Thomas Pock, Florian Knoll, Magnetic Resonance in Medicine. Kerstin Hammernik, Teresa Klatzer, Erich Kobler, Michael P. Recht, Daniel K. Sodickson, Thomas Pock, and Florian Knoll. Learning a variational network for reconstruction of accelerated MRI data. Magnetic Resonance in Medicine, 2018.\n\nFraming U-Net via deep convolutional framelets: Application to sparseview CT. Yoseob Han, Jong Chul Ye, IEEE Transactions on Medical Imaging. 376Yoseob Han and Jong Chul Ye. Framing U-Net via deep convolutional framelets: Application to sparse- view CT. IEEE Transactions on Medical Imaging, 37(6), 2018.\n\nCurrent status of the digital database for screening mammography. Michael Heath, Kevin Bowyer, Daniel Kopans, P Kegelmeyer, Richard Moore, Kyong Chang, S Munishkumaran, Digital Mammography. Michael Heath, Kevin Bowyer, Daniel Kopans, P Kegelmeyer, Richard Moore, Kyong Chang, and S Munishkumaran. Current status of the digital database for screening mammography. In Digital Mammography, 1998.\n\nComparison and evaluation of methods for liver segmentation from CT datasets. Tobias Heimann, Bram Van Ginneken, A Martin, Yulia Styner, Volker Arzhaeva, Christian Aurich, Andreas Bauer, Christoph Beck, Reinhard Becker, Gy\u00f6rgy Beichel, Bekes, IEEE Transactions on Medical Imaging. 288Tobias Heimann, Bram Van Ginneken, Martin A Styner, Yulia Arzhaeva, Volker Aurich, Christian Bauer, Andreas Beck, Christoph Becker, Reinhard Beichel, Gy\u00f6rgy Bekes, et al. Comparison and evaluation of methods for liver segmentation from CT datasets. IEEE Transactions on Medical Imaging, 28(8), 2009.\n\nYue Huang, John Paisley, Xianbo Chen, Xinghao Ding, Feng Huang, Xiao-Ping Zhang, MR image reconstruction from undersampled k-space with bayesian dictionary learning. arXiv preprintYue Huang, John Paisley, Xianbo Chen, Xinghao Ding, Feng Huang, and Xiao-Ping Zhang. MR image reconstruction from undersampled k-space with bayesian dictionary learning. arXiv preprint, 2013.\n\nApplication of perceptual difference model on regularization techniques of parallel MR imaging. Donglai Huo, Dan Xu, Zhi-Pei Liang, David Wilson, Magnetic Resonance Imaging. 242Donglai Huo, Dan Xu, Zhi-Pei Liang, and David Wilson. Application of perceptual difference model on regularization techniques of parallel MR imaging. Magnetic Resonance Imaging, 24(2), 2006.\n\nDeep learning for undersampled MRI reconstruction. Hwa Pyung Chang Min Hyun, Sung Min Kim, Sungchul Lee, Jin Keun Lee, Seo, Physics in medicine and biology. 6313Chang Min Hyun, Hwa Pyung Kim, Sung Min Lee, Sungchul Lee, and Jin Keun Seo. Deep learning for undersampled MRI reconstruction. Physics in medicine and biology, 63(13), 2018.\n\nISMRM raw data format: a proposed standard for MRI raw datasets. Magnetic resonance in medicine. J Souheil, Joseph D Inati, Naegele, Vinai Nicholas R Zwart, Roopchansingh, J Martin, Lizak, C David, Chia-Ying Hansen, David Liu, Peter Atkinson, Sebastian Kellman, Kozerke, 77Souheil J Inati, Joseph D Naegele, Nicholas R Zwart, Vinai Roopchansingh, Martin J Lizak, David C Hansen, Chia-Ying Liu, David Atkinson, Peter Kellman, Sebastian Kozerke, et al. ISMRM raw data format: a proposed standard for MRI raw datasets. Magnetic resonance in medicine, 77(1), 2017.\n\nPerceptual losses for real-time style transfer and super-resolution. Justin Johnson, Alexandre Alahi, Li Fei-Fei, European Conference on Computer Vision. Justin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In European Conference on Computer Vision, 2016.\n\nSNR-optimality of sum-of-squares reconstruction for phased-array magnetic resonance imaging. Deniz Erik G Larsson, Rui Erdogmus, Yan, C Jose, Jeffrey R Principe, Fitzsimmons, Journal of Magnetic Resonance. 1631Erik G Larsson, Deniz Erdogmus, Rui Yan, Jose C Principe, and Jeffrey R Fitzsimmons. SNR-optimality of sum-of-squares reconstruction for phased-array magnetic resonance imaging. Journal of Magnetic Resonance, 163(1), 2003.\n\nDeep Learning. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, Nature. 5217553Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep Learning. Nature, 521(7553), 2015.\n\nRecurrent inference machines for accelerated MRI reconstruction. Kai Lonning, Patrick Putzky, W A Matthan, Max Caan, Welling, Kai Lonning, Patrick Putzky, Matthan W. A. Caan, and Max Welling. Recurrent inference machines for accelerated MRI reconstruction, 2018.\n\nSparse MRI: The Application of Compressed Sensing for Rapid MR Imaging. Michael Lustig, David Donoho, John M Pauly, Magnetic Resonance in Medicine. 586Michael Lustig, David Donoho, and John M Pauly. Sparse MRI: The Application of Compressed Sensing for Rapid MR Imaging. Magnetic Resonance in Medicine, 58(6), 2007.\n\n. H Bjoern, Andrs Menze, Stefan Jakab, Jayashree Bauer, Keyvan Kalpathy-Cramer, Farahani, Justin Kirby, Yuliya Burren, Nicole Porz, Johannes Slotboom, Roland Wiest, Levente Lanczi, Elizabeth RBjoern H. Menze, Andrs Jakab, Stefan Bauer, Jayashree Kalpathy-Cramer, Keyvan Farahani, Justin Kirby, Yuliya Burren, Nicole Porz, Johannes Slotboom, Roland Wiest, Levente Lanczi, Elizabeth R.\n\nThe multimodal brain tumor image segmentation benchmark (BRATS). Marc-Andr Gerstner, Tal Weber, Brian B Arbel, Nicholas Avants, Patricia Ayache, D Louis Buendia, Nicolas Collins, Jason J Cordier, Antonio Corso, Tilak Criminisi, Herve Das, Delingette, Christopher R Demiralp, Michel Durst, Senan Dojat, Joana Doyle, Florence Festa, Ezequiel Forbes, Ben Geremia, Polina Glocker, Xiaotao Golland, Andac Guo, Hamamci, M Khan, Raj Iftekharuddin, Nigel M Jena, Ender John, Danial Konukoglu, Jos Antonio Lashkari, Raphael Mariz, Srgio Meier, Doina Pereira, Stephen J Precup, Tammy Riklin Price, Raviv, M S Syed, Michael T Reza, Duygu Ryan, Lawrence H Sarikaya, Hoo-Chang Schwartz, Jamie Shin, Carlos A Shotton, Nuno Silva, Nagesh K Sousa, Gbor Subbanna, Thomas J Szkely, Owen M Taylor, Nicholas J Thomas, Gzde B Tustison, Flor Vasseur, Max Wintermark, Dong Hye Ye, Liang Zhao, Binsheng Zhao, Darko Zikic, Marcel Prastawa, Mauricio Reyes, Koen Van Leemput, IEEE Transactions on Medical Imaging. 3410Gerstner, Marc-Andr Weber, Tal Arbel, Brian B. Avants, Nicholas Ayache, Patricia Buendia, D. Louis Collins, Nicolas Cordier, Jason J. Corso, Antonio Criminisi, Tilak Das, Herve Delingette, agatay Demiralp, Christopher R. Durst, Michel Dojat, Senan Doyle, Joana Festa, Florence Forbes, Ezequiel Geremia, Ben Glocker, Polina Golland, Xiaotao Guo, Andac Hamamci, Khan M. Iftekharuddin, Raj Jena, Nigel M. John, Ender Konukoglu, Danial Lashkari, Jos Antonio Mariz, Raphael Meier, Srgio Pereira, Doina Precup, Stephen J. Price, Tammy Riklin Raviv, Syed M. S. Reza, Michael T. Ryan, Duygu Sarikaya, Lawrence H. Schwartz, Hoo-Chang Shin, Jamie Shotton, Carlos A. Silva, Nuno Sousa, Nagesh K. Subbanna, Gbor Szkely, Thomas J. Taylor, Owen M. Thomas, Nicholas J. Tustison, Gzde B. nal, Flor Vasseur, Max Wintermark, Dong Hye Ye, Liang Zhao, Binsheng Zhao, Darko Zikic, Marcel Prastawa, Mauricio Reyes, and Koen Van Leemput. The multimodal brain tumor image segmentation benchmark (BRATS). IEEE Transactions on Medical Imaging, 34(10), 2015.\n\nA new perceptual difference model for diagnostically relevant quantitative image quality evaluation: A preliminary study. Jun Miao, Feng Huang, Sreenath Narayan, David L Wilson, Magnetic Resonance Imaging. 314Jun Miao, Feng Huang, Sreenath Narayan, and David L. Wilson. A new perceptual difference model for diagnostically relevant quantitative image quality evaluation: A preliminary study. Magnetic Resonance Imaging, 31(4), 2013.\n\nSENSE: sensitivity encoding for fast MRI. Magnetic resonance in medicine. Markus Klaas P Pruessmann, Markus B Weiger, Peter Scheidegger, Boesiger, 42Klaas P Pruessmann, Markus Weiger, Markus B Scheidegger, and Peter Boesiger. SENSE: sensitivity encoding for fast MRI. Magnetic resonance in medicine, 42(5), 1999.\n\nCompressed sensing dynamic MRI reconstruction using GPUaccelerated 3d convolutional sparse coding. Minh Tran, Won-Ki Quan, Jeong, Medical Image Computing and Computer-Assisted Intervention (MICCAI). Tran Minh Quan and Won-Ki Jeong. Compressed sensing dynamic MRI reconstruction using GPU- accelerated 3d convolutional sparse coding. In Medical Image Computing and Computer-Assisted Inter- vention (MICCAI), 2016.\n\nThe NMR phased array. Magnetic resonance in medicine. B Peter, Roemer, A William, Cecil E Edelstein, Hayes, P Steven, Otward M Souza, Mueller, 16Peter B Roemer, William A Edelstein, Cecil E Hayes, Steven P Souza, and Otward M Mueller. The NMR phased array. Magnetic resonance in medicine, 16(2), 1990.\n\nU-Net: Convolutional networks for biomedical image segmentation. Olaf Ronneberger, Philipp Fischer, Thomas Brox, Medical Image Computing and Computer-Assisted Intervention. Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional networks for biomedical image segmentation. Medical Image Computing and Computer-Assisted Intervention, 2015.\n\nNonlinear total variation based noise removal algorithms. Stanley Leonid I Rudin, Emad Osher, Fatemi, Physica D: nonlinear phenomena. 601-4Leonid I Rudin, Stanley Osher, and Emad Fatemi. Nonlinear total variation based noise removal algorithms. Physica D: nonlinear phenomena, 60(1-4), 1992.\n\nImageNet Large Scale Visual Recognition Challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C Berg, Li Fei-Fei, International Journal of Computer Vision. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, 2015.\n\nImproved techniques for training GANs. Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, Advances in Neural Information Processing Systems. Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training GANs. In Advances in Neural Information Processing Systems, 2016.\n\nDeep convolutional neural networks for accelerated dynamic magnetic resonance imaging. Christopher M Sandino, Neerav Dixit, Joseph Y Cheng, S Shreyas, Vasanawala, Stanford UniversityTechnical reportChristopher M. Sandino, Neerav Dixit, Joseph Y. Cheng, and Shreyas S Vasanawala. Deep convolu- tional neural networks for accelerated dynamic magnetic resonance imaging. Technical report, Stanford University, 2017.\n\nShreyas Vasanawala, and Ge Healthcare. Creation of fully sampled MR data repository for compressed sensing of the knee. Anne Marie Sawyer, Michael Lustig, Marcus Alley, Phdmartin Uecker, Patrick Virtue, Peng Lai, Anne Marie Sawyer, Michael Lustig, Marcus Alley, Phdmartin Uecker, Patrick Virtue, Peng Lai, Shreyas Vasanawala, and Ge Healthcare. Creation of fully sampled MR data repository for compressed sensing of the knee, 2013.\n\nA deep cascade of convolutional neural networks for MR image reconstruction. Information Processing in Medical Imaging. Jo Schlemper, Jose Caballero, Joseph V Hajnal, Anthony N Price, Daniel Rueckert, Jo Schlemper, Jose Caballero, Joseph V. Hajnal, Anthony N. Price, and Daniel Rueckert. A deep cascade of convolutional neural networks for MR image reconstruction. Information Processing in Medical Imaging, 2017.\n\nA deep cascade of convolutional neural networks for dynamic MR image reconstruction. Jo Schlemper, Jose Caballero, Joseph V Hajnal, Anthony N Price, Daniel Rueckert, IEEE Transactions on medical imaging. 372Jo Schlemper, Jose Caballero, Joseph V. Hajnal, Anthony N. Price, and Daniel Rueckert. A deep cascade of convolutional neural networks for dynamic MR image reconstruction. IEEE Transactions on medical imaging, 37(2), 2018.\n\nBram van Ginneken, and Colin Jacobs. Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules. Arnaud Arindra, Adiyoso Setio, Alberto Traverso, Thomas De Bel, Moira S N Berens, Cas Van Den, Piergiorgio Bogaard, Hao Cerello, Qi Chen, Maria Evelina Dou, Bram Fantacci, Robbert Geurts, Pheng-Ann Van Der Gugten, Bart Heng, Jansen, M J Michael, Valentin De Kaste, Jack Kotov, -Hung Yu, Lin, T M C Jeroen, Alexander Manders, Juan Carlos S\u00f3nora-Mengana, Mathias Garc\u00eda-Naranjo, Marco Prokop, Cornelia Saletta, Ernst Th Schaefer-Prokop, Luuk Scholten, Miranda M Scholten, Ernesto Lopez Snoeren, Jef Torres, Nicole Vandemeulebroucke, Walasek, C A Guido, Zuidhof, in computed tomography images: the LUNA16 challenge. Medical Image AnalysisArnaud Arindra Adiyoso Setio, Alberto Traverso, Thomas de Bel, Moira S. N. Berens, Cas van den Bo- gaard, Piergiorgio Cerello, Hao Chen, Qi Dou, Maria Evelina Fantacci, Bram Geurts, Robbert van der Gugten, Pheng-Ann Heng, Bart Jansen, Michael M. J. de Kaste, Valentin Kotov, Jack Yu-Hung Lin, Jeroen T. M. C. Manders, Alexander S\u00f3nora-Mengana, Juan Carlos Garc\u00eda-Naranjo, Mathias Prokop, Marco Saletta, Cornelia Schaefer-Prokop, Ernst Th. Scholten, Luuk Scholten, Miranda M. Snoeren, Ernesto Lopez Torres, Jef Vandemeulebroucke, Nicole Walasek, Guido C. A. Zuidhof, Bram van Gin- neken, and Colin Jacobs. Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the LUNA16 challenge. Medical Image Analysis, 2017.\n\nAccelerated magnetic resonance imaging by adversarial neural network. Ohad Shitrit, Tammy Riklin Raviv, ; M. Jorge Cardoso, Tal Arbel, Gustavo Carneiro, F Tanveer, Jo\u00e3o Syeda-Mahmood, R S Manuel, Mehdi Tavares, Andrew P Moradi, Hayit Bradley, Jo\u00e3o Paulo Greenspan, Anant Papa, Jacinto C Madabhushi, Jaime S Nascimento, Cardoso, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support. Vasileios Belagiannis, and Zhi LuOhad Shitrit and Tammy Riklin Raviv. Accelerated magnetic resonance imaging by adversarial neu- ral network. In M. Jorge Cardoso, Tal Arbel, Gustavo Carneiro, Tanveer F. Syeda-Mahmood, Jo\u00e3o Manuel R. S. Tavares, Mehdi Moradi, Andrew P. Bradley, Hayit Greenspan, Jo\u00e3o Paulo Papa, Anant Madabhushi, Jacinto C. Nascimento, Jaime S. Cardoso, Vasileios Belagiannis, and Zhi Lu, editors, Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, 2017.\n\nSimultaneous acquisition of spatial harmonics (SMASH): fast imaging with radiofrequency coil arrays. Magnetic resonance in medicine. K Daniel, Warren J Sodickson, Manning, 38Daniel K Sodickson and Warren J Manning. Simultaneous acquisition of spatial harmonics (SMASH): fast imaging with radiofrequency coil arrays. Magnetic resonance in medicine, 38(4), 1997.\n\nComputer vision algorithms and applications. Richard Szeliski, SpringerRichard Szeliski. Computer vision algorithms and applications. Springer, 2011.\n\nPerceptual image distortion. C Patrick, David J Teo, Heeger, IEEE International Conference on Image Processing (ICIP). 2Patrick C Teo and David J Heeger. Perceptual image distortion. In IEEE International Conference on Image Processing (ICIP), volume 2, 1994.\n\nLecture 6.5 -rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning. Tijmen Tieleman, Geoffrey Hinton, Tijmen Tieleman and Geoffrey Hinton. Lecture 6.5 -rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning, 2012.\n\nSimulating single-coil MRI from the responses of multiple coils. Mark Tygert, Jure Zbontar, arXiv preprintMark Tygert and Jure Zbontar. Simulating single-coil MRI from the responses of multiple coils. arXiv preprint, 2018.\n\nSoftware toolbox and programming library for compressed sensing and parallel imaging. Martin Uecker, Patrick Virtue, Frank Ong, Mark J Murphy, Marcus T Alley, Shreyas S Vasanawala, Michael Lustig, ISMRM Workshop on Data Sampling and Image Reconstruction. Martin Uecker, Patrick Virtue, Frank Ong, Mark J. Murphy, Marcus T. Alley, Shreyas S. Vasanawala, and Michael Lustig. Software toolbox and programming library for compressed sensing and parallel imaging. In ISMRM Workshop on Data Sampling and Image Reconstruction, 2013.\n\nESPIRiT -an eigenvalue approach to autocalibrating parallel MRI: where SENSE meets GRAPPA. Magnetic resonance in medicine. Martin Uecker, Peng Lai, J Mark, Patrick Murphy, Michael Virtue, Elad, M John, Pauly, S Shreyas, Michael Vasanawala, Lustig, 71Martin Uecker, Peng Lai, Mark J Murphy, Patrick Virtue, Michael Elad, John M Pauly, Shreyas S Vasanawala, and Michael Lustig. ESPIRiT -an eigenvalue approach to autocalibrating parallel MRI: where SENSE meets GRAPPA. Magnetic resonance in medicine, 71(3), 2014.\n\nInstance normalization: The missing ingredient for fast stylization. Dmitry Ulyanov, Andrea Vedaldi, Victor S Lempitsky, arXiv preprintDmitry Ulyanov, Andrea Vedaldi, and Victor S. Lempitsky. Instance normalization: The missing ingredient for fast stylization. arXiv preprint, 2016.\n\nDmitry Ulyanov, Andrea Vedaldi, Victor S Lempitsky, Deep image prior. arXiv preprintDmitry Ulyanov, Andrea Vedaldi, and Victor S. Lempitsky. Deep image prior. arXiv preprint, 2017.\n\nAccelerating magnetic resonance imaging via deep learning. Shanshan Wang, Zhenghang Su, Leslie Ying, Xi Peng, Shun Zhu, Feng Liang, Dagan Feng, Dong Liang, IEEE International Symposium on Biomedical Imaging (ISBI). Shanshan Wang, Zhenghang Su, Leslie Ying, Xi Peng, Shun Zhu, Feng Liang, Dagan Feng, and Dong Liang. Accelerating magnetic resonance imaging via deep learning. In IEEE International Symposium on Biomedical Imaging (ISBI), 2016.\n\nHighresolution image synthesis and semantic manipulation with conditional GANs. Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, Bryan Catanzaro, Conference on Computer Vision and Pattern Recognition (CVPR). Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao, Jan Kautz, and Bryan Catanzaro. High- resolution image synthesis and semantic manipulation with conditional GANs. Conference on Computer Vision and Pattern Recognition (CVPR), 2018.\n\nChestX-ray8: Hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, Ronald Summers, 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR. Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, and Ronald Summers. ChestX-ray8: Hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. In 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR), 2017.\n\nMean squared error: Love it or leave it? a new look at signal fidelity measures. IEEE signal processing magazine. Zhou Wang, Alan C Bovik, 26Zhou Wang and Alan C Bovik. Mean squared error: Love it or leave it? a new look at signal fidelity measures. IEEE signal processing magazine, 26(1), 2009.\n\nMultiscale structural similarity for image quality assessment. Zhou Wang, P Eero, Alan C Simoncelli, Bovik, Asilomar Conference on Signals, Systems & Computers. Zhou Wang, Eero P Simoncelli, and Alan C Bovik. Multiscale structural similarity for image quality assessment. In Asilomar Conference on Signals, Systems & Computers, 2003.\n\nImage quality assessment: from error visibility to structural similarity. Zhou Wang, Alan C Bovik, R Hamid, Eero P Sheikh, Simoncelli, IEEE transactions on image processing. 134Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE transactions on image processing, 13(4):600-612, 2004.\n\nMagnetic resonance angiography with compressed sensing: An evaluation of moyamoya disease. Takayuki Yamamoto, Yasutaka Okada, Akira Fushimi, Koji Yamamoto, Sachi Fujimoto, Hikaru Okuchi, Jun C Fukutomi, Takeshi Takahashi, Susumu Funaki, Aur\u00e9lien F Miyamoto, Yutaka Stalder, Peter Natsuaki, Kaori Speier, Togashi, PloS one. Takayuki Yamamoto, T Okada, Yasutaka Fushimi, Akira Yamamoto, Koji Fujimoto, Sachi Okuchi, Hikaru Fukutomi, Jun C. Takahashi, Takeshi Funaki, Susumu Miyamoto, Aur\u00e9lien F. Stalder, Yutaka Natsuaki, Peter Speier, and Kaori Togashi. Magnetic resonance angiography with compressed sensing: An evaluation of moyamoya disease. In PloS one, 2018.\n\nDeeplesion: Automated mining of large-scale lesion annotations and universal lesion detection with deep learning. Ke Yan, Xiaosong Wang, Le Lu, Ronald Summers, Journal of Medical Imaging. 5Ke Yan, Xiaosong Wang, Le Lu, and Ronald Summers. Deeplesion: Automated mining of large-scale lesion annotations and universal lesion detection with deep learning. Journal of Medical Imaging, 5, 2018.\n\nDeep ADMM-Net for compressive sensing MRI. Yan Yang, Jian Sun, Huibin Li, Zongben Xu, Advances in Neural Information Processing Systems. 29Yan Yang, Jian Sun, Huibin Li, and Zongben Xu. Deep ADMM-Net for compressive sensing MRI. Advances in Neural Information Processing Systems 29, 2016.\n\nADMM-Net: A deep learning approach for compressive sensing MRI. Yan Yang, Jian Sun, Huibin Li, Zongben Xu, arXiv preprintYan Yang, Jian Sun, Huibin Li, and Zongben Xu. ADMM-Net: A deep learning approach for compressive sensing MRI. arXiv preprint, 2017.\n\nFSIM: a feature similarity index for image quality assessment. Lin Zhang, Lei Zhang, Xuanqin Mou, David Zhang, IEEE transactions on Image Processing. 208Lin Zhang, Lei Zhang, Xuanqin Mou, David Zhang, et al. FSIM: a feature similarity index for image quality assessment. IEEE transactions on Image Processing, 20(8), 2011.\n\nLoss functions for image restoration with neural networks. Hang Zhao, Orazio Gallo, Iuri Frosio, Jan Kautz, IEEE Transactions on Computational Imaging. 31Hang Zhao, Orazio Gallo, Iuri Frosio, and Jan Kautz. Loss functions for image restoration with neural networks. IEEE Transactions on Computational Imaging, 3(1), 2017.\n\nImage reconstruction by domain-transform manifold learning. Bo Zhu, Jeremiah Z Liu, Stephen F Cauley, Bruce R Rosen, Matthew S Rosen, Nature. 5557697Bo Zhu, Jeremiah Z. Liu, Stephen F. Cauley, Bruce R. Rosen, and Matthew S. Rosen. Image recon- struction by domain-transform manifold learning. Nature, 555(7697), 2018.\n", "annotations": {"author": "[{\"end\":99,\"start\":63},{\"end\":169,\"start\":100},{\"end\":208,\"start\":170},{\"end\":247,\"start\":209},{\"end\":318,\"start\":248},{\"end\":392,\"start\":319},{\"end\":430,\"start\":393},{\"end\":498,\"start\":431},{\"end\":571,\"start\":499},{\"end\":638,\"start\":572},{\"end\":707,\"start\":639},{\"end\":781,\"start\":708},{\"end\":852,\"start\":782},{\"end\":925,\"start\":853},{\"end\":963,\"start\":926},{\"end\":1003,\"start\":964},{\"end\":1042,\"start\":1004},{\"end\":1081,\"start\":1043},{\"end\":1120,\"start\":1082},{\"end\":1161,\"start\":1121},{\"end\":1201,\"start\":1162},{\"end\":1266,\"start\":1202},{\"end\":1302,\"start\":1267},{\"end\":1345,\"start\":1303},{\"end\":1417,\"start\":1346},{\"end\":1492,\"start\":1418},{\"end\":1561,\"start\":1493}]", "publisher": null, "author_last_name": "[{\"end\":75,\"start\":68},{\"end\":113,\"start\":108},{\"end\":184,\"start\":178},{\"end\":223,\"start\":216},{\"end\":262,\"start\":257},{\"end\":336,\"start\":329},{\"end\":406,\"start\":399},{\"end\":442,\"start\":437},{\"end\":515,\"start\":508},{\"end\":582,\"start\":577},{\"end\":651,\"start\":644},{\"end\":725,\"start\":720},{\"end\":796,\"start\":786},{\"end\":869,\"start\":859},{\"end\":938,\"start\":933},{\"end\":979,\"start\":971},{\"end\":1018,\"start\":1012},{\"end\":1057,\"start\":1051},{\"end\":1096,\"start\":1089},{\"end\":1137,\"start\":1129},{\"end\":1177,\"start\":1168},{\"end\":1210,\"start\":1206},{\"end\":1278,\"start\":1273},{\"end\":1321,\"start\":1314},{\"end\":1361,\"start\":1356},{\"end\":1436,\"start\":1427},{\"end\":1505,\"start\":1502}]", "author_first_name": "[{\"end\":67,\"start\":63},{\"end\":107,\"start\":100},{\"end\":177,\"start\":170},{\"end\":215,\"start\":209},{\"end\":256,\"start\":248},{\"end\":326,\"start\":319},{\"end\":328,\"start\":327},{\"end\":398,\"start\":393},{\"end\":436,\"start\":431},{\"end\":507,\"start\":499},{\"end\":576,\"start\":572},{\"end\":643,\"start\":639},{\"end\":717,\"start\":708},{\"end\":719,\"start\":718},{\"end\":785,\"start\":782},{\"end\":858,\"start\":853},{\"end\":932,\"start\":926},{\"end\":970,\"start\":964},{\"end\":1011,\"start\":1004},{\"end\":1050,\"start\":1043},{\"end\":1088,\"start\":1082},{\"end\":1128,\"start\":1121},{\"end\":1167,\"start\":1162},{\"end\":1205,\"start\":1202},{\"end\":1272,\"start\":1267},{\"end\":1304,\"start\":1303},{\"end\":1313,\"start\":1305},{\"end\":1353,\"start\":1346},{\"end\":1355,\"start\":1354},{\"end\":1424,\"start\":1418},{\"end\":1426,\"start\":1425},{\"end\":1499,\"start\":1493},{\"end\":1501,\"start\":1500}]", "author_affiliation": "[{\"end\":98,\"start\":77},{\"end\":168,\"start\":115},{\"end\":207,\"start\":186},{\"end\":246,\"start\":225},{\"end\":317,\"start\":264},{\"end\":391,\"start\":338},{\"end\":429,\"start\":408},{\"end\":497,\"start\":444},{\"end\":570,\"start\":517},{\"end\":637,\"start\":584},{\"end\":706,\"start\":653},{\"end\":780,\"start\":727},{\"end\":851,\"start\":798},{\"end\":924,\"start\":871},{\"end\":962,\"start\":940},{\"end\":1002,\"start\":981},{\"end\":1041,\"start\":1020},{\"end\":1080,\"start\":1059},{\"end\":1119,\"start\":1098},{\"end\":1160,\"start\":1139},{\"end\":1200,\"start\":1179},{\"end\":1265,\"start\":1212},{\"end\":1301,\"start\":1280},{\"end\":1344,\"start\":1323},{\"end\":1416,\"start\":1363},{\"end\":1491,\"start\":1438},{\"end\":1560,\"start\":1507}]", "title": "[{\"end\":60,\"start\":1},{\"end\":1621,\"start\":1562}]", "venue": null, "abstract": "[{\"end\":5208,\"start\":1623}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b39\"},\"end\":6162,\"start\":6158},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6165,\"start\":6162},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6167,\"start\":6165},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6225,\"start\":6222},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6228,\"start\":6225},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10286,\"start\":10282},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12623,\"start\":12619},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12638,\"start\":12634},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12654,\"start\":12651},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13112,\"start\":13108},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13123,\"start\":13119},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":13140,\"start\":13136},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":13157,\"start\":13153},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13175,\"start\":13172},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13243,\"start\":13242},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13245,\"start\":13244},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13612,\"start\":13609},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":13615,\"start\":13612},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":13618,\"start\":13615},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":13621,\"start\":13618},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":13624,\"start\":13621},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13705,\"start\":13701},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":13708,\"start\":13705},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":13711,\"start\":13708},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":13714,\"start\":13711},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13717,\"start\":13714},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":13911,\"start\":13907},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13914,\"start\":13911},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":17580,\"start\":17576},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":20116,\"start\":20112},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20821,\"start\":20820},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":22752,\"start\":22748},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":23370,\"start\":23366},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":23934,\"start\":23930},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26382,\"start\":26379},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26385,\"start\":26382},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":27021,\"start\":27017},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":27024,\"start\":27021},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":27026,\"start\":27024},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":27029,\"start\":27026},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":27113,\"start\":27110},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":27630,\"start\":27626},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27632,\"start\":27630},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":27635,\"start\":27632},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":27686,\"start\":27682},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":27741,\"start\":27737},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":28042,\"start\":28038},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":28104,\"start\":28100},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":31080,\"start\":31076},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":32446,\"start\":32443},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32449,\"start\":32446},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":34142,\"start\":34138},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":34354,\"start\":34350},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":36568,\"start\":36564},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":36994,\"start\":36990},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":36996,\"start\":36994},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":38004,\"start\":38000},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39029,\"start\":39025},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":39032,\"start\":39029},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":39035,\"start\":39032},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":39038,\"start\":39035},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":39041,\"start\":39038},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":39044,\"start\":39041},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":39047,\"start\":39044},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":39134,\"start\":39130},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":39270,\"start\":39266},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":39273,\"start\":39270},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":39301,\"start\":39297},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":39600,\"start\":39596},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":40051,\"start\":40047},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":41680,\"start\":41676},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":46777,\"start\":46773},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":46779,\"start\":46777},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":46781,\"start\":46779},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":46784,\"start\":46781},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":47297,\"start\":47294},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":48041,\"start\":48037},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":48548,\"start\":48544},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":48551,\"start\":48548},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":62845,\"start\":62841}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":55034,\"start\":54936},{\"attributes\":{\"id\":\"fig_2\"},\"end\":55077,\"start\":55035},{\"attributes\":{\"id\":\"fig_3\"},\"end\":55190,\"start\":55078},{\"attributes\":{\"id\":\"fig_4\"},\"end\":55347,\"start\":55191},{\"attributes\":{\"id\":\"fig_6\"},\"end\":55417,\"start\":55348},{\"attributes\":{\"id\":\"fig_8\"},\"end\":55457,\"start\":55418},{\"attributes\":{\"id\":\"fig_9\"},\"end\":55630,\"start\":55458},{\"attributes\":{\"id\":\"fig_10\"},\"end\":55878,\"start\":55631},{\"attributes\":{\"id\":\"fig_12\"},\"end\":55942,\"start\":55879},{\"attributes\":{\"id\":\"fig_13\"},\"end\":56050,\"start\":55943},{\"attributes\":{\"id\":\"fig_14\"},\"end\":56131,\"start\":56051},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":56233,\"start\":56132},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":56343,\"start\":56234},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":56705,\"start\":56344},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":56754,\"start\":56706},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":56964,\"start\":56755},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":57178,\"start\":56965},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":58353,\"start\":57179},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":59142,\"start\":58354},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":59832,\"start\":59143},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":60535,\"start\":59833},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":61911,\"start\":60536},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":62673,\"start\":61912}]", "paragraph": "[{\"end\":5659,\"start\":5224},{\"end\":6168,\"start\":5661},{\"end\":7700,\"start\":6170},{\"end\":7775,\"start\":7718},{\"end\":8338,\"start\":7777},{\"end\":8914,\"start\":8362},{\"end\":9844,\"start\":8943},{\"end\":10793,\"start\":9846},{\"end\":11384,\"start\":10795},{\"end\":11782,\"start\":11445},{\"end\":11982,\"start\":11793},{\"end\":12303,\"start\":12044},{\"end\":13718,\"start\":12389},{\"end\":14269,\"start\":13720},{\"end\":14517,\"start\":14314},{\"end\":14728,\"start\":14519},{\"end\":14962,\"start\":14730},{\"end\":15187,\"start\":14964},{\"end\":15250,\"start\":15189},{\"end\":15373,\"start\":15252},{\"end\":15494,\"start\":15375},{\"end\":16152,\"start\":15496},{\"end\":16615,\"start\":16154},{\"end\":17356,\"start\":16617},{\"end\":17873,\"start\":17374},{\"end\":18939,\"start\":17895},{\"end\":19546,\"start\":18962},{\"end\":19960,\"start\":19548},{\"end\":20322,\"start\":20003},{\"end\":20699,\"start\":20342},{\"end\":20976,\"start\":20701},{\"end\":21237,\"start\":20978},{\"end\":21892,\"start\":21239},{\"end\":22643,\"start\":21908},{\"end\":23331,\"start\":22660},{\"end\":23533,\"start\":23333},{\"end\":23704,\"start\":23554},{\"end\":23939,\"start\":23738},{\"end\":25050,\"start\":23957},{\"end\":25693,\"start\":25078},{\"end\":26866,\"start\":25695},{\"end\":27533,\"start\":26878},{\"end\":27833,\"start\":27535},{\"end\":28105,\"start\":27835},{\"end\":28527,\"start\":28107},{\"end\":28718,\"start\":28560},{\"end\":29034,\"start\":28753},{\"end\":29366,\"start\":29036},{\"end\":29581,\"start\":29397},{\"end\":29962,\"start\":29629},{\"end\":30356,\"start\":29988},{\"end\":30858,\"start\":30450},{\"end\":30918,\"start\":30871},{\"end\":31146,\"start\":30946},{\"end\":31556,\"start\":31166},{\"end\":32064,\"start\":31558},{\"end\":32408,\"start\":32112},{\"end\":33305,\"start\":32410},{\"end\":33641,\"start\":33354},{\"end\":33868,\"start\":33690},{\"end\":35971,\"start\":34010},{\"end\":36789,\"start\":36082},{\"end\":37157,\"start\":36819},{\"end\":37574,\"start\":37159},{\"end\":37821,\"start\":37576},{\"end\":38086,\"start\":37883},{\"end\":38467,\"start\":38088},{\"end\":38792,\"start\":38469},{\"end\":39302,\"start\":38844},{\"end\":41055,\"start\":39304},{\"end\":41400,\"start\":41057},{\"end\":42509,\"start\":41456},{\"end\":43582,\"start\":42511},{\"end\":44372,\"start\":43621},{\"end\":45815,\"start\":44374},{\"end\":46374,\"start\":45817},{\"end\":46624,\"start\":46376},{\"end\":47478,\"start\":46639},{\"end\":48251,\"start\":47480},{\"end\":49094,\"start\":48253},{\"end\":49809,\"start\":49096},{\"end\":50550,\"start\":49824},{\"end\":50730,\"start\":50552},{\"end\":51049,\"start\":50751},{\"end\":51300,\"start\":51051},{\"end\":51516,\"start\":51302},{\"end\":51634,\"start\":51518},{\"end\":51942,\"start\":51636},{\"end\":52086,\"start\":51944},{\"end\":52241,\"start\":52088},{\"end\":52349,\"start\":52243},{\"end\":52498,\"start\":52374},{\"end\":52617,\"start\":52500},{\"end\":52855,\"start\":52619},{\"end\":53019,\"start\":52857},{\"end\":53140,\"start\":53021},{\"end\":53267,\"start\":53142},{\"end\":53407,\"start\":53269},{\"end\":53883,\"start\":53440},{\"end\":54335,\"start\":53885},{\"end\":54590,\"start\":54337},{\"end\":54935,\"start\":54592}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7717,\"start\":7701},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8942,\"start\":8915},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11792,\"start\":11783},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12043,\"start\":11983},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12364,\"start\":12304},{\"attributes\":{\"id\":\"formula_5\"},\"end\":23553,\"start\":23534},{\"attributes\":{\"id\":\"formula_6\"},\"end\":23737,\"start\":23705},{\"attributes\":{\"id\":\"formula_7\"},\"end\":28752,\"start\":28719},{\"attributes\":{\"id\":\"formula_8\"},\"end\":29628,\"start\":29582},{\"attributes\":{\"id\":\"formula_9\"},\"end\":30449,\"start\":30357},{\"attributes\":{\"id\":\"formula_10\"},\"end\":30945,\"start\":30919},{\"attributes\":{\"id\":\"formula_11\"},\"end\":33353,\"start\":33306},{\"attributes\":{\"id\":\"formula_12\"},\"end\":33689,\"start\":33642},{\"attributes\":{\"id\":\"formula_13\"},\"end\":34009,\"start\":33869},{\"attributes\":{\"id\":\"formula_14\"},\"end\":36818,\"start\":36790},{\"attributes\":{\"id\":\"formula_15\"},\"end\":37882,\"start\":37822},{\"attributes\":{\"id\":\"formula_16\"},\"end\":41455,\"start\":41401}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":13998,\"start\":13991},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":24150,\"start\":24143},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":35333,\"start\":35326},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":38602,\"start\":38595},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":42160,\"start\":42153},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":42490,\"start\":42483},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":43072,\"start\":43065},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":44538,\"start\":44510},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":44961,\"start\":44953},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":44974,\"start\":44966},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":45139,\"start\":45131},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":50948,\"start\":50940}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":5222,\"start\":5210},{\"attributes\":{\"n\":\"2.1\"},\"end\":8360,\"start\":8341},{\"attributes\":{\"n\":\"2.2\"},\"end\":11443,\"start\":11387},{\"attributes\":{\"n\":\"3\"},\"end\":12387,\"start\":12366},{\"attributes\":{\"n\":\"4\"},\"end\":14312,\"start\":14272},{\"attributes\":{\"n\":\"4.1\"},\"end\":17372,\"start\":17359},{\"attributes\":{\"n\":\"4.2\"},\"end\":17893,\"start\":17876},{\"attributes\":{\"n\":\"4.3\"},\"end\":18960,\"start\":18942},{\"attributes\":{\"n\":\"4.4\"},\"end\":20001,\"start\":19963},{\"attributes\":{\"n\":\"4.5\"},\"end\":20340,\"start\":20325},{\"attributes\":{\"n\":\"4.6\"},\"end\":21906,\"start\":21895},{\"attributes\":{\"n\":\"4.7\"},\"end\":22658,\"start\":22646},{\"attributes\":{\"n\":\"4.8\"},\"end\":23955,\"start\":23942},{\"attributes\":{\"n\":\"4.9\"},\"end\":25076,\"start\":25053},{\"attributes\":{\"n\":\"5\"},\"end\":26876,\"start\":26869},{\"attributes\":{\"n\":\"5.1\"},\"end\":28558,\"start\":28530},{\"attributes\":{\"n\":\"5.2\"},\"end\":29395,\"start\":29369},{\"attributes\":{\"n\":\"5.3\"},\"end\":29986,\"start\":29965},{\"attributes\":{\"n\":\"5.4\"},\"end\":30869,\"start\":30861},{\"attributes\":{\"n\":\"6\"},\"end\":31164,\"start\":31149},{\"attributes\":{\"n\":\"6.1\"},\"end\":32110,\"start\":32067},{\"end\":36047,\"start\":35974},{\"attributes\":{\"n\":\"6.2\"},\"end\":36080,\"start\":36050},{\"attributes\":{\"n\":\"6.3\"},\"end\":38842,\"start\":38795},{\"attributes\":{\"n\":\"6.4\"},\"end\":43619,\"start\":43585},{\"attributes\":{\"n\":\"7\"},\"end\":46637,\"start\":46627},{\"attributes\":{\"n\":\"8\"},\"end\":49822,\"start\":49812},{\"attributes\":{\"n\":\"9\"},\"end\":50749,\"start\":50733},{\"end\":52372,\"start\":52352},{\"end\":53438,\"start\":53410},{\"end\":54947,\"start\":54937},{\"end\":55046,\"start\":55036},{\"end\":55089,\"start\":55079},{\"end\":55202,\"start\":55192},{\"end\":55359,\"start\":55349},{\"end\":55429,\"start\":55419},{\"end\":55469,\"start\":55459},{\"end\":55642,\"start\":55632},{\"end\":55901,\"start\":55880},{\"end\":55945,\"start\":55944},{\"end\":56142,\"start\":56133},{\"end\":56244,\"start\":56235},{\"end\":56716,\"start\":56707},{\"end\":56765,\"start\":56756},{\"end\":56975,\"start\":56966},{\"end\":58364,\"start\":58355},{\"end\":59153,\"start\":59144},{\"end\":59843,\"start\":59834},{\"end\":60547,\"start\":60537},{\"end\":61923,\"start\":61913}]", "table": "[{\"end\":56705,\"start\":56502},{\"end\":56754,\"start\":56748},{\"end\":58353,\"start\":57254},{\"end\":59142,\"start\":58626},{\"end\":59832,\"start\":59576},{\"end\":60535,\"start\":59997},{\"end\":61911,\"start\":60771},{\"end\":62673,\"start\":62157}]", "figure_caption": "[{\"end\":55034,\"start\":54949},{\"end\":55077,\"start\":55048},{\"end\":55190,\"start\":55091},{\"end\":55347,\"start\":55204},{\"end\":55417,\"start\":55361},{\"end\":55457,\"start\":55431},{\"end\":55630,\"start\":55471},{\"end\":55878,\"start\":55644},{\"end\":55942,\"start\":55905},{\"end\":56050,\"start\":55946},{\"end\":56131,\"start\":56053},{\"end\":56233,\"start\":56144},{\"end\":56343,\"start\":56246},{\"end\":56502,\"start\":56346},{\"end\":56748,\"start\":56718},{\"end\":56964,\"start\":56767},{\"end\":57178,\"start\":56977},{\"end\":57254,\"start\":57181},{\"end\":58626,\"start\":58366},{\"end\":59576,\"start\":59155},{\"end\":59997,\"start\":59845},{\"end\":60771,\"start\":60550},{\"end\":62157,\"start\":61926}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6910,\"start\":6902},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9015,\"start\":9006},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18507,\"start\":18499},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":19413,\"start\":19405},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26753,\"start\":26745},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":33598,\"start\":33587},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":34365,\"start\":34355},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":34491,\"start\":34481},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":34756,\"start\":34746},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":39390,\"start\":39380},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":40415,\"start\":40406},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":43953,\"start\":43943},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":46079,\"start\":46071},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":51225,\"start\":51217},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":51298,\"start\":51290}]", "bib_author_first_name": "[{\"end\":65933,\"start\":65928},{\"end\":65977,\"start\":65960},{\"end\":65988,\"start\":65984},{\"end\":66000,\"start\":65996},{\"end\":66020,\"start\":66015},{\"end\":66047,\"start\":66044},{\"end\":66061,\"start\":66056},{\"end\":66086,\"start\":66085},{\"end\":66105,\"start\":66096},{\"end\":66666,\"start\":66665},{\"end\":66683,\"start\":66677},{\"end\":66699,\"start\":66692},{\"end\":67055,\"start\":67054},{\"end\":67333,\"start\":67321},{\"end\":67351,\"start\":67341},{\"end\":67364,\"start\":67356},{\"end\":67374,\"start\":67373},{\"end\":67378,\"start\":67375},{\"end\":67398,\"start\":67393},{\"end\":67400,\"start\":67399},{\"end\":67823,\"start\":67817},{\"end\":67826,\"start\":67824},{\"end\":67835,\"start\":67829},{\"end\":67842,\"start\":67841},{\"end\":68073,\"start\":68072},{\"end\":68091,\"start\":68083},{\"end\":68331,\"start\":68328},{\"end\":68339,\"start\":68337},{\"end\":68351,\"start\":68345},{\"end\":68362,\"start\":68358},{\"end\":68385,\"start\":68376},{\"end\":68387,\"start\":68386},{\"end\":68624,\"start\":68618},{\"end\":68650,\"start\":68644},{\"end\":68991,\"start\":68990},{\"end\":69009,\"start\":69008},{\"end\":69022,\"start\":69017},{\"end\":69024,\"start\":69023},{\"end\":69039,\"start\":69032},{\"end\":69059,\"start\":69051},{\"end\":69075,\"start\":69068},{\"end\":69092,\"start\":69084},{\"end\":69103,\"start\":69099},{\"end\":69480,\"start\":69473},{\"end\":69499,\"start\":69492},{\"end\":69508,\"start\":69507},{\"end\":69523,\"start\":69517},{\"end\":69856,\"start\":69849},{\"end\":69874,\"start\":69868},{\"end\":69889,\"start\":69884},{\"end\":69905,\"start\":69898},{\"end\":69907,\"start\":69906},{\"end\":69921,\"start\":69915},{\"end\":69923,\"start\":69922},{\"end\":69941,\"start\":69935},{\"end\":69955,\"start\":69948},{\"end\":70313,\"start\":70307},{\"end\":70323,\"start\":70319},{\"end\":70608,\"start\":70601},{\"end\":70621,\"start\":70616},{\"end\":70636,\"start\":70630},{\"end\":70646,\"start\":70645},{\"end\":70666,\"start\":70659},{\"end\":70679,\"start\":70674},{\"end\":70688,\"start\":70687},{\"end\":71013,\"start\":71007},{\"end\":71043,\"start\":71042},{\"end\":71057,\"start\":71052},{\"end\":71072,\"start\":71066},{\"end\":71092,\"start\":71083},{\"end\":71108,\"start\":71101},{\"end\":71125,\"start\":71116},{\"end\":71140,\"start\":71132},{\"end\":71155,\"start\":71149},{\"end\":71517,\"start\":71514},{\"end\":71529,\"start\":71525},{\"end\":71545,\"start\":71539},{\"end\":71559,\"start\":71552},{\"end\":71570,\"start\":71566},{\"end\":71587,\"start\":71578},{\"end\":71990,\"start\":71983},{\"end\":71999,\"start\":71996},{\"end\":72011,\"start\":72004},{\"end\":72024,\"start\":72019},{\"end\":72310,\"start\":72307},{\"end\":72316,\"start\":72311},{\"end\":72337,\"start\":72333},{\"end\":72341,\"start\":72338},{\"end\":72355,\"start\":72347},{\"end\":72364,\"start\":72361},{\"end\":72369,\"start\":72365},{\"end\":72691,\"start\":72690},{\"end\":72707,\"start\":72701},{\"end\":72709,\"start\":72708},{\"end\":72731,\"start\":72726},{\"end\":72766,\"start\":72765},{\"end\":72783,\"start\":72782},{\"end\":72800,\"start\":72791},{\"end\":72814,\"start\":72809},{\"end\":72825,\"start\":72820},{\"end\":72845,\"start\":72836},{\"end\":73230,\"start\":73224},{\"end\":73249,\"start\":73240},{\"end\":73259,\"start\":73257},{\"end\":73575,\"start\":73570},{\"end\":73595,\"start\":73592},{\"end\":73612,\"start\":73611},{\"end\":73628,\"start\":73619},{\"end\":73930,\"start\":73926},{\"end\":73944,\"start\":73938},{\"end\":73961,\"start\":73953},{\"end\":74142,\"start\":74139},{\"end\":74159,\"start\":74152},{\"end\":74169,\"start\":74168},{\"end\":74171,\"start\":74170},{\"end\":74184,\"start\":74181},{\"end\":74417,\"start\":74410},{\"end\":74431,\"start\":74426},{\"end\":74446,\"start\":74440},{\"end\":74658,\"start\":74657},{\"end\":74672,\"start\":74667},{\"end\":74686,\"start\":74680},{\"end\":74703,\"start\":74694},{\"end\":74717,\"start\":74711},{\"end\":75114,\"start\":75105},{\"end\":75128,\"start\":75125},{\"end\":75141,\"start\":75136},{\"end\":75143,\"start\":75142},{\"end\":75159,\"start\":75151},{\"end\":75176,\"start\":75168},{\"end\":75186,\"start\":75185},{\"end\":75192,\"start\":75187},{\"end\":75209,\"start\":75202},{\"end\":75224,\"start\":75219},{\"end\":75226,\"start\":75225},{\"end\":75243,\"start\":75236},{\"end\":75256,\"start\":75251},{\"end\":75273,\"start\":75268},{\"end\":75302,\"start\":75291},{\"end\":75304,\"start\":75303},{\"end\":75321,\"start\":75315},{\"end\":75334,\"start\":75329},{\"end\":75347,\"start\":75342},{\"end\":75363,\"start\":75355},{\"end\":75379,\"start\":75371},{\"end\":75391,\"start\":75388},{\"end\":75407,\"start\":75401},{\"end\":75424,\"start\":75417},{\"end\":75439,\"start\":75434},{\"end\":75455,\"start\":75454},{\"end\":75465,\"start\":75462},{\"end\":75486,\"start\":75481},{\"end\":75488,\"start\":75487},{\"end\":75500,\"start\":75495},{\"end\":75513,\"start\":75507},{\"end\":75528,\"start\":75525},{\"end\":75536,\"start\":75529},{\"end\":75554,\"start\":75547},{\"end\":75567,\"start\":75562},{\"end\":75580,\"start\":75575},{\"end\":75597,\"start\":75590},{\"end\":75599,\"start\":75598},{\"end\":75613,\"start\":75608},{\"end\":75620,\"start\":75614},{\"end\":75636,\"start\":75635},{\"end\":75638,\"start\":75637},{\"end\":75652,\"start\":75645},{\"end\":75654,\"start\":75653},{\"end\":75666,\"start\":75661},{\"end\":75681,\"start\":75673},{\"end\":75683,\"start\":75682},{\"end\":75703,\"start\":75694},{\"end\":75719,\"start\":75714},{\"end\":75732,\"start\":75726},{\"end\":75734,\"start\":75733},{\"end\":75748,\"start\":75744},{\"end\":75762,\"start\":75756},{\"end\":75764,\"start\":75763},{\"end\":75776,\"start\":75772},{\"end\":75793,\"start\":75787},{\"end\":75795,\"start\":75794},{\"end\":75808,\"start\":75804},{\"end\":75810,\"start\":75809},{\"end\":75827,\"start\":75819},{\"end\":75829,\"start\":75828},{\"end\":75842,\"start\":75838},{\"end\":75844,\"start\":75843},{\"end\":75859,\"start\":75855},{\"end\":75872,\"start\":75869},{\"end\":75889,\"start\":75885},{\"end\":75893,\"start\":75890},{\"end\":75903,\"start\":75898},{\"end\":75918,\"start\":75910},{\"end\":75930,\"start\":75925},{\"end\":75944,\"start\":75938},{\"end\":75963,\"start\":75955},{\"end\":75975,\"start\":75971},{\"end\":77189,\"start\":77186},{\"end\":77200,\"start\":77196},{\"end\":77216,\"start\":77208},{\"end\":77231,\"start\":77226},{\"end\":77233,\"start\":77232},{\"end\":77578,\"start\":77572},{\"end\":77605,\"start\":77599},{\"end\":77607,\"start\":77606},{\"end\":77621,\"start\":77616},{\"end\":77915,\"start\":77911},{\"end\":77928,\"start\":77922},{\"end\":78281,\"start\":78280},{\"end\":78298,\"start\":78297},{\"end\":78313,\"start\":78308},{\"end\":78315,\"start\":78314},{\"end\":78335,\"start\":78334},{\"end\":78352,\"start\":78344},{\"end\":78598,\"start\":78594},{\"end\":78619,\"start\":78612},{\"end\":78635,\"start\":78629},{\"end\":78951,\"start\":78944},{\"end\":78972,\"start\":78968},{\"end\":79234,\"start\":79230},{\"end\":79251,\"start\":79248},{\"end\":79261,\"start\":79258},{\"end\":79274,\"start\":79266},{\"end\":79290,\"start\":79283},{\"end\":79305,\"start\":79301},{\"end\":79317,\"start\":79310},{\"end\":79331,\"start\":79325},{\"end\":79348,\"start\":79342},{\"end\":79364,\"start\":79357},{\"end\":79385,\"start\":79376},{\"end\":79387,\"start\":79386},{\"end\":79396,\"start\":79394},{\"end\":79771,\"start\":79768},{\"end\":79785,\"start\":79782},{\"end\":79806,\"start\":79798},{\"end\":79821,\"start\":79816},{\"end\":79834,\"start\":79830},{\"end\":79846,\"start\":79844},{\"end\":80191,\"start\":80180},{\"end\":80193,\"start\":80192},{\"end\":80209,\"start\":80203},{\"end\":80223,\"start\":80217},{\"end\":80225,\"start\":80224},{\"end\":80234,\"start\":80233},{\"end\":80631,\"start\":80627},{\"end\":80637,\"start\":80632},{\"end\":80653,\"start\":80646},{\"end\":80668,\"start\":80662},{\"end\":80685,\"start\":80676},{\"end\":80701,\"start\":80694},{\"end\":80714,\"start\":80710},{\"end\":81062,\"start\":81060},{\"end\":81078,\"start\":81074},{\"end\":81096,\"start\":81090},{\"end\":81098,\"start\":81097},{\"end\":81114,\"start\":81107},{\"end\":81116,\"start\":81115},{\"end\":81130,\"start\":81124},{\"end\":81442,\"start\":81440},{\"end\":81458,\"start\":81454},{\"end\":81476,\"start\":81470},{\"end\":81478,\"start\":81477},{\"end\":81494,\"start\":81487},{\"end\":81496,\"start\":81495},{\"end\":81510,\"start\":81504},{\"end\":81929,\"start\":81923},{\"end\":81946,\"start\":81939},{\"end\":81961,\"start\":81954},{\"end\":81978,\"start\":81972},{\"end\":81992,\"start\":81987},{\"end\":81996,\"start\":81993},{\"end\":82008,\"start\":82005},{\"end\":82029,\"start\":82018},{\"end\":82042,\"start\":82039},{\"end\":82054,\"start\":82052},{\"end\":82066,\"start\":82061},{\"end\":82074,\"start\":82067},{\"end\":82084,\"start\":82080},{\"end\":82102,\"start\":82095},{\"end\":82120,\"start\":82111},{\"end\":82141,\"start\":82137},{\"end\":82157,\"start\":82156},{\"end\":82159,\"start\":82158},{\"end\":82177,\"start\":82169},{\"end\":82192,\"start\":82188},{\"end\":82205,\"start\":82200},{\"end\":82216,\"start\":82215},{\"end\":82220,\"start\":82217},{\"end\":82238,\"start\":82229},{\"end\":82252,\"start\":82248},{\"end\":82259,\"start\":82253},{\"end\":82283,\"start\":82276},{\"end\":82305,\"start\":82300},{\"end\":82322,\"start\":82314},{\"end\":82337,\"start\":82332},{\"end\":82340,\"start\":82338},{\"end\":82362,\"start\":82358},{\"end\":82380,\"start\":82373},{\"end\":82382,\"start\":82381},{\"end\":82400,\"start\":82393},{\"end\":82406,\"start\":82401},{\"end\":82419,\"start\":82416},{\"end\":82434,\"start\":82428},{\"end\":82464,\"start\":82463},{\"end\":82466,\"start\":82465},{\"end\":83420,\"start\":83416},{\"end\":83435,\"start\":83430},{\"end\":83460,\"start\":83450},{\"end\":83473,\"start\":83470},{\"end\":83488,\"start\":83481},{\"end\":83500,\"start\":83499},{\"end\":83514,\"start\":83510},{\"end\":83531,\"start\":83530},{\"end\":83533,\"start\":83532},{\"end\":83547,\"start\":83542},{\"end\":83563,\"start\":83557},{\"end\":83565,\"start\":83564},{\"end\":83579,\"start\":83574},{\"end\":83593,\"start\":83589},{\"end\":83599,\"start\":83594},{\"end\":83616,\"start\":83611},{\"end\":83630,\"start\":83623},{\"end\":83632,\"start\":83631},{\"end\":83650,\"start\":83645},{\"end\":83652,\"start\":83651},{\"end\":84420,\"start\":84419},{\"end\":84437,\"start\":84429},{\"end\":84700,\"start\":84693},{\"end\":84829,\"start\":84828},{\"end\":84844,\"start\":84839},{\"end\":84846,\"start\":84845},{\"end\":85202,\"start\":85196},{\"end\":85221,\"start\":85213},{\"end\":85479,\"start\":85475},{\"end\":85492,\"start\":85488},{\"end\":85726,\"start\":85720},{\"end\":85742,\"start\":85735},{\"end\":85756,\"start\":85751},{\"end\":85766,\"start\":85762},{\"end\":85768,\"start\":85767},{\"end\":85783,\"start\":85777},{\"end\":85785,\"start\":85784},{\"end\":85800,\"start\":85793},{\"end\":85802,\"start\":85801},{\"end\":85822,\"start\":85815},{\"end\":86290,\"start\":86284},{\"end\":86303,\"start\":86299},{\"end\":86310,\"start\":86309},{\"end\":86324,\"start\":86317},{\"end\":86340,\"start\":86333},{\"end\":86356,\"start\":86355},{\"end\":86371,\"start\":86370},{\"end\":86388,\"start\":86381},{\"end\":86749,\"start\":86743},{\"end\":86765,\"start\":86759},{\"end\":86781,\"start\":86775},{\"end\":86783,\"start\":86782},{\"end\":86964,\"start\":86958},{\"end\":86980,\"start\":86974},{\"end\":86996,\"start\":86990},{\"end\":86998,\"start\":86997},{\"end\":87207,\"start\":87199},{\"end\":87223,\"start\":87214},{\"end\":87234,\"start\":87228},{\"end\":87243,\"start\":87241},{\"end\":87254,\"start\":87250},{\"end\":87264,\"start\":87260},{\"end\":87277,\"start\":87272},{\"end\":87288,\"start\":87284},{\"end\":87673,\"start\":87664},{\"end\":87687,\"start\":87680},{\"end\":87700,\"start\":87693},{\"end\":87712,\"start\":87706},{\"end\":87721,\"start\":87718},{\"end\":87734,\"start\":87729},{\"end\":88197,\"start\":88189},{\"end\":88209,\"start\":88204},{\"end\":88218,\"start\":88216},{\"end\":88230,\"start\":88223},{\"end\":88247,\"start\":88235},{\"end\":88263,\"start\":88257},{\"end\":88774,\"start\":88770},{\"end\":88785,\"start\":88781},{\"end\":88787,\"start\":88786},{\"end\":89020,\"start\":89016},{\"end\":89028,\"start\":89027},{\"end\":89039,\"start\":89035},{\"end\":89041,\"start\":89040},{\"end\":89366,\"start\":89362},{\"end\":89377,\"start\":89373},{\"end\":89379,\"start\":89378},{\"end\":89388,\"start\":89387},{\"end\":89402,\"start\":89396},{\"end\":89763,\"start\":89755},{\"end\":89782,\"start\":89774},{\"end\":89795,\"start\":89790},{\"end\":89809,\"start\":89805},{\"end\":89825,\"start\":89820},{\"end\":89842,\"start\":89836},{\"end\":89854,\"start\":89851},{\"end\":89856,\"start\":89855},{\"end\":89874,\"start\":89867},{\"end\":89892,\"start\":89886},{\"end\":89909,\"start\":89901},{\"end\":89911,\"start\":89910},{\"end\":89928,\"start\":89922},{\"end\":89943,\"start\":89938},{\"end\":89959,\"start\":89954},{\"end\":90444,\"start\":90442},{\"end\":90458,\"start\":90450},{\"end\":90467,\"start\":90465},{\"end\":90478,\"start\":90472},{\"end\":90765,\"start\":90762},{\"end\":90776,\"start\":90772},{\"end\":90788,\"start\":90782},{\"end\":90800,\"start\":90793},{\"end\":91076,\"start\":91073},{\"end\":91087,\"start\":91083},{\"end\":91099,\"start\":91093},{\"end\":91111,\"start\":91104},{\"end\":91330,\"start\":91327},{\"end\":91341,\"start\":91338},{\"end\":91356,\"start\":91349},{\"end\":91367,\"start\":91362},{\"end\":91651,\"start\":91647},{\"end\":91664,\"start\":91658},{\"end\":91676,\"start\":91672},{\"end\":91688,\"start\":91685},{\"end\":91973,\"start\":91971},{\"end\":91987,\"start\":91979},{\"end\":91989,\"start\":91988},{\"end\":92002,\"start\":91995},{\"end\":92004,\"start\":92003},{\"end\":92018,\"start\":92013},{\"end\":92020,\"start\":92019},{\"end\":92035,\"start\":92028},{\"end\":92037,\"start\":92036}]", "bib_author_last_name": "[{\"end\":65958,\"start\":65934},{\"end\":65982,\"start\":65978},{\"end\":65994,\"start\":65989},{\"end\":66013,\"start\":66001},{\"end\":66033,\"start\":66021},{\"end\":66042,\"start\":66035},{\"end\":66054,\"start\":66048},{\"end\":66074,\"start\":66062},{\"end\":66083,\"start\":66076},{\"end\":66094,\"start\":66087},{\"end\":66112,\"start\":66106},{\"end\":66123,\"start\":66114},{\"end\":66675,\"start\":66667},{\"end\":66690,\"start\":66684},{\"end\":66707,\"start\":66700},{\"end\":66712,\"start\":66709},{\"end\":67061,\"start\":67056},{\"end\":67071,\"start\":67063},{\"end\":67339,\"start\":67334},{\"end\":67354,\"start\":67352},{\"end\":67371,\"start\":67365},{\"end\":67391,\"start\":67379},{\"end\":67417,\"start\":67401},{\"end\":67839,\"start\":67836},{\"end\":67848,\"start\":67843},{\"end\":67854,\"start\":67850},{\"end\":68081,\"start\":68074},{\"end\":68098,\"start\":68092},{\"end\":68107,\"start\":68100},{\"end\":68335,\"start\":68332},{\"end\":68343,\"start\":68340},{\"end\":68356,\"start\":68352},{\"end\":68374,\"start\":68363},{\"end\":68394,\"start\":68388},{\"end\":68642,\"start\":68625},{\"end\":68658,\"start\":68651},{\"end\":68666,\"start\":68660},{\"end\":68996,\"start\":68992},{\"end\":69006,\"start\":68998},{\"end\":69015,\"start\":69010},{\"end\":69030,\"start\":69025},{\"end\":69049,\"start\":69040},{\"end\":69066,\"start\":69060},{\"end\":69082,\"start\":69076},{\"end\":69097,\"start\":69093},{\"end\":69110,\"start\":69104},{\"end\":69117,\"start\":69112},{\"end\":69490,\"start\":69481},{\"end\":69505,\"start\":69500},{\"end\":69515,\"start\":69509},{\"end\":69533,\"start\":69524},{\"end\":69539,\"start\":69535},{\"end\":69866,\"start\":69857},{\"end\":69882,\"start\":69875},{\"end\":69896,\"start\":69890},{\"end\":69913,\"start\":69908},{\"end\":69933,\"start\":69924},{\"end\":69946,\"start\":69942},{\"end\":69961,\"start\":69956},{\"end\":70317,\"start\":70314},{\"end\":70331,\"start\":70324},{\"end\":70614,\"start\":70609},{\"end\":70628,\"start\":70622},{\"end\":70643,\"start\":70637},{\"end\":70657,\"start\":70647},{\"end\":70672,\"start\":70667},{\"end\":70685,\"start\":70680},{\"end\":70702,\"start\":70689},{\"end\":71021,\"start\":71014},{\"end\":71040,\"start\":71023},{\"end\":71050,\"start\":71044},{\"end\":71064,\"start\":71058},{\"end\":71081,\"start\":71073},{\"end\":71099,\"start\":71093},{\"end\":71114,\"start\":71109},{\"end\":71130,\"start\":71126},{\"end\":71147,\"start\":71141},{\"end\":71163,\"start\":71156},{\"end\":71170,\"start\":71165},{\"end\":71523,\"start\":71518},{\"end\":71537,\"start\":71530},{\"end\":71550,\"start\":71546},{\"end\":71564,\"start\":71560},{\"end\":71576,\"start\":71571},{\"end\":71593,\"start\":71588},{\"end\":71994,\"start\":71991},{\"end\":72002,\"start\":72000},{\"end\":72017,\"start\":72012},{\"end\":72031,\"start\":72025},{\"end\":72331,\"start\":72317},{\"end\":72345,\"start\":72342},{\"end\":72359,\"start\":72356},{\"end\":72373,\"start\":72370},{\"end\":72378,\"start\":72375},{\"end\":72699,\"start\":72692},{\"end\":72715,\"start\":72710},{\"end\":72724,\"start\":72717},{\"end\":72748,\"start\":72732},{\"end\":72763,\"start\":72750},{\"end\":72773,\"start\":72767},{\"end\":72780,\"start\":72775},{\"end\":72789,\"start\":72784},{\"end\":72807,\"start\":72801},{\"end\":72818,\"start\":72815},{\"end\":72834,\"start\":72826},{\"end\":72853,\"start\":72846},{\"end\":72862,\"start\":72855},{\"end\":73238,\"start\":73231},{\"end\":73255,\"start\":73250},{\"end\":73267,\"start\":73260},{\"end\":73590,\"start\":73576},{\"end\":73604,\"start\":73596},{\"end\":73609,\"start\":73606},{\"end\":73617,\"start\":73613},{\"end\":73637,\"start\":73629},{\"end\":73650,\"start\":73639},{\"end\":73936,\"start\":73931},{\"end\":73951,\"start\":73945},{\"end\":73968,\"start\":73962},{\"end\":74150,\"start\":74143},{\"end\":74166,\"start\":74160},{\"end\":74179,\"start\":74172},{\"end\":74189,\"start\":74185},{\"end\":74198,\"start\":74191},{\"end\":74424,\"start\":74418},{\"end\":74438,\"start\":74432},{\"end\":74452,\"start\":74447},{\"end\":74665,\"start\":74659},{\"end\":74678,\"start\":74673},{\"end\":74692,\"start\":74687},{\"end\":74709,\"start\":74704},{\"end\":74733,\"start\":74718},{\"end\":74743,\"start\":74735},{\"end\":75123,\"start\":75115},{\"end\":75134,\"start\":75129},{\"end\":75149,\"start\":75144},{\"end\":75166,\"start\":75160},{\"end\":75183,\"start\":75177},{\"end\":75200,\"start\":75193},{\"end\":75217,\"start\":75210},{\"end\":75234,\"start\":75227},{\"end\":75249,\"start\":75244},{\"end\":75266,\"start\":75257},{\"end\":75277,\"start\":75274},{\"end\":75289,\"start\":75279},{\"end\":75313,\"start\":75305},{\"end\":75327,\"start\":75322},{\"end\":75340,\"start\":75335},{\"end\":75353,\"start\":75348},{\"end\":75369,\"start\":75364},{\"end\":75386,\"start\":75380},{\"end\":75399,\"start\":75392},{\"end\":75415,\"start\":75408},{\"end\":75432,\"start\":75425},{\"end\":75443,\"start\":75440},{\"end\":75452,\"start\":75445},{\"end\":75460,\"start\":75456},{\"end\":75479,\"start\":75466},{\"end\":75493,\"start\":75489},{\"end\":75505,\"start\":75501},{\"end\":75523,\"start\":75514},{\"end\":75545,\"start\":75537},{\"end\":75560,\"start\":75555},{\"end\":75573,\"start\":75568},{\"end\":75588,\"start\":75581},{\"end\":75606,\"start\":75600},{\"end\":75626,\"start\":75621},{\"end\":75633,\"start\":75628},{\"end\":75643,\"start\":75639},{\"end\":75659,\"start\":75655},{\"end\":75671,\"start\":75667},{\"end\":75692,\"start\":75684},{\"end\":75712,\"start\":75704},{\"end\":75724,\"start\":75720},{\"end\":75742,\"start\":75735},{\"end\":75754,\"start\":75749},{\"end\":75770,\"start\":75765},{\"end\":75785,\"start\":75777},{\"end\":75802,\"start\":75796},{\"end\":75817,\"start\":75811},{\"end\":75836,\"start\":75830},{\"end\":75853,\"start\":75845},{\"end\":75867,\"start\":75860},{\"end\":75883,\"start\":75873},{\"end\":75896,\"start\":75894},{\"end\":75908,\"start\":75904},{\"end\":75923,\"start\":75919},{\"end\":75936,\"start\":75931},{\"end\":75953,\"start\":75945},{\"end\":75969,\"start\":75964},{\"end\":75987,\"start\":75976},{\"end\":77194,\"start\":77190},{\"end\":77206,\"start\":77201},{\"end\":77224,\"start\":77217},{\"end\":77240,\"start\":77234},{\"end\":77597,\"start\":77579},{\"end\":77614,\"start\":77608},{\"end\":77633,\"start\":77622},{\"end\":77643,\"start\":77635},{\"end\":77920,\"start\":77916},{\"end\":77933,\"start\":77929},{\"end\":77940,\"start\":77935},{\"end\":78287,\"start\":78282},{\"end\":78295,\"start\":78289},{\"end\":78306,\"start\":78299},{\"end\":78325,\"start\":78316},{\"end\":78332,\"start\":78327},{\"end\":78342,\"start\":78336},{\"end\":78358,\"start\":78353},{\"end\":78367,\"start\":78360},{\"end\":78610,\"start\":78599},{\"end\":78627,\"start\":78620},{\"end\":78640,\"start\":78636},{\"end\":78966,\"start\":78952},{\"end\":78978,\"start\":78973},{\"end\":78986,\"start\":78980},{\"end\":79246,\"start\":79235},{\"end\":79256,\"start\":79252},{\"end\":79264,\"start\":79262},{\"end\":79281,\"start\":79275},{\"end\":79299,\"start\":79291},{\"end\":79308,\"start\":79306},{\"end\":79323,\"start\":79318},{\"end\":79340,\"start\":79332},{\"end\":79355,\"start\":79349},{\"end\":79374,\"start\":79365},{\"end\":79392,\"start\":79388},{\"end\":79404,\"start\":79397},{\"end\":79780,\"start\":79772},{\"end\":79796,\"start\":79786},{\"end\":79814,\"start\":79807},{\"end\":79828,\"start\":79822},{\"end\":79842,\"start\":79835},{\"end\":79851,\"start\":79847},{\"end\":80201,\"start\":80194},{\"end\":80215,\"start\":80210},{\"end\":80231,\"start\":80226},{\"end\":80242,\"start\":80235},{\"end\":80254,\"start\":80244},{\"end\":80644,\"start\":80638},{\"end\":80660,\"start\":80654},{\"end\":80674,\"start\":80669},{\"end\":80692,\"start\":80686},{\"end\":80708,\"start\":80702},{\"end\":80718,\"start\":80715},{\"end\":81072,\"start\":81063},{\"end\":81088,\"start\":81079},{\"end\":81105,\"start\":81099},{\"end\":81122,\"start\":81117},{\"end\":81139,\"start\":81131},{\"end\":81452,\"start\":81443},{\"end\":81468,\"start\":81459},{\"end\":81485,\"start\":81479},{\"end\":81502,\"start\":81497},{\"end\":81519,\"start\":81511},{\"end\":81937,\"start\":81930},{\"end\":81952,\"start\":81947},{\"end\":81970,\"start\":81962},{\"end\":81985,\"start\":81979},{\"end\":82003,\"start\":81997},{\"end\":82016,\"start\":82009},{\"end\":82037,\"start\":82030},{\"end\":82050,\"start\":82043},{\"end\":82059,\"start\":82055},{\"end\":82078,\"start\":82075},{\"end\":82093,\"start\":82085},{\"end\":82109,\"start\":82103},{\"end\":82135,\"start\":82121},{\"end\":82146,\"start\":82142},{\"end\":82154,\"start\":82148},{\"end\":82167,\"start\":82160},{\"end\":82186,\"start\":82178},{\"end\":82198,\"start\":82193},{\"end\":82208,\"start\":82206},{\"end\":82213,\"start\":82210},{\"end\":82227,\"start\":82221},{\"end\":82246,\"start\":82239},{\"end\":82274,\"start\":82260},{\"end\":82298,\"start\":82284},{\"end\":82312,\"start\":82306},{\"end\":82330,\"start\":82323},{\"end\":82356,\"start\":82341},{\"end\":82371,\"start\":82363},{\"end\":82391,\"start\":82383},{\"end\":82414,\"start\":82407},{\"end\":82426,\"start\":82420},{\"end\":82452,\"start\":82435},{\"end\":82461,\"start\":82454},{\"end\":82472,\"start\":82467},{\"end\":82481,\"start\":82474},{\"end\":83428,\"start\":83421},{\"end\":83448,\"start\":83436},{\"end\":83468,\"start\":83461},{\"end\":83479,\"start\":83474},{\"end\":83497,\"start\":83489},{\"end\":83508,\"start\":83501},{\"end\":83528,\"start\":83515},{\"end\":83540,\"start\":83534},{\"end\":83555,\"start\":83548},{\"end\":83572,\"start\":83566},{\"end\":83587,\"start\":83580},{\"end\":83609,\"start\":83600},{\"end\":83621,\"start\":83617},{\"end\":83643,\"start\":83633},{\"end\":83663,\"start\":83653},{\"end\":83672,\"start\":83665},{\"end\":84427,\"start\":84421},{\"end\":84447,\"start\":84438},{\"end\":84456,\"start\":84449},{\"end\":84709,\"start\":84701},{\"end\":84837,\"start\":84830},{\"end\":84850,\"start\":84847},{\"end\":84858,\"start\":84852},{\"end\":85211,\"start\":85203},{\"end\":85228,\"start\":85222},{\"end\":85486,\"start\":85480},{\"end\":85500,\"start\":85493},{\"end\":85733,\"start\":85727},{\"end\":85749,\"start\":85743},{\"end\":85760,\"start\":85757},{\"end\":85775,\"start\":85769},{\"end\":85791,\"start\":85786},{\"end\":85813,\"start\":85803},{\"end\":85829,\"start\":85823},{\"end\":86297,\"start\":86291},{\"end\":86307,\"start\":86304},{\"end\":86315,\"start\":86311},{\"end\":86331,\"start\":86325},{\"end\":86347,\"start\":86341},{\"end\":86353,\"start\":86349},{\"end\":86361,\"start\":86357},{\"end\":86368,\"start\":86363},{\"end\":86379,\"start\":86372},{\"end\":86399,\"start\":86389},{\"end\":86407,\"start\":86401},{\"end\":86757,\"start\":86750},{\"end\":86773,\"start\":86766},{\"end\":86793,\"start\":86784},{\"end\":86972,\"start\":86965},{\"end\":86988,\"start\":86981},{\"end\":87008,\"start\":86999},{\"end\":87212,\"start\":87208},{\"end\":87226,\"start\":87224},{\"end\":87239,\"start\":87235},{\"end\":87248,\"start\":87244},{\"end\":87258,\"start\":87255},{\"end\":87270,\"start\":87265},{\"end\":87282,\"start\":87278},{\"end\":87294,\"start\":87289},{\"end\":87678,\"start\":87674},{\"end\":87691,\"start\":87688},{\"end\":87704,\"start\":87701},{\"end\":87716,\"start\":87713},{\"end\":87727,\"start\":87722},{\"end\":87744,\"start\":87735},{\"end\":88202,\"start\":88198},{\"end\":88214,\"start\":88210},{\"end\":88221,\"start\":88219},{\"end\":88233,\"start\":88231},{\"end\":88255,\"start\":88248},{\"end\":88271,\"start\":88264},{\"end\":88779,\"start\":88775},{\"end\":88793,\"start\":88788},{\"end\":89025,\"start\":89021},{\"end\":89033,\"start\":89029},{\"end\":89052,\"start\":89042},{\"end\":89059,\"start\":89054},{\"end\":89371,\"start\":89367},{\"end\":89385,\"start\":89380},{\"end\":89394,\"start\":89389},{\"end\":89409,\"start\":89403},{\"end\":89421,\"start\":89411},{\"end\":89772,\"start\":89764},{\"end\":89788,\"start\":89783},{\"end\":89803,\"start\":89796},{\"end\":89818,\"start\":89810},{\"end\":89834,\"start\":89826},{\"end\":89849,\"start\":89843},{\"end\":89865,\"start\":89857},{\"end\":89884,\"start\":89875},{\"end\":89899,\"start\":89893},{\"end\":89920,\"start\":89912},{\"end\":89936,\"start\":89929},{\"end\":89952,\"start\":89944},{\"end\":89966,\"start\":89960},{\"end\":89975,\"start\":89968},{\"end\":90448,\"start\":90445},{\"end\":90463,\"start\":90459},{\"end\":90470,\"start\":90468},{\"end\":90486,\"start\":90479},{\"end\":90770,\"start\":90766},{\"end\":90780,\"start\":90777},{\"end\":90791,\"start\":90789},{\"end\":90803,\"start\":90801},{\"end\":91081,\"start\":91077},{\"end\":91091,\"start\":91088},{\"end\":91102,\"start\":91100},{\"end\":91114,\"start\":91112},{\"end\":91336,\"start\":91331},{\"end\":91347,\"start\":91342},{\"end\":91360,\"start\":91357},{\"end\":91373,\"start\":91368},{\"end\":91656,\"start\":91652},{\"end\":91670,\"start\":91665},{\"end\":91683,\"start\":91677},{\"end\":91694,\"start\":91689},{\"end\":91977,\"start\":91974},{\"end\":91993,\"start\":91990},{\"end\":92011,\"start\":92005},{\"end\":92026,\"start\":92021},{\"end\":92043,\"start\":92038}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":205086555},\"end\":66558,\"start\":65810},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":7033413},\"end\":66970,\"start\":66560},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":72132264},\"end\":67226,\"start\":66972},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":13603634},\"end\":67738,\"start\":67228},{\"attributes\":{\"id\":\"b4\"},\"end\":68007,\"start\":67740},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":16122613},\"end\":68264,\"start\":68009},{\"attributes\":{\"id\":\"b6\"},\"end\":68566,\"start\":68266},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":6471904},\"end\":68918,\"start\":68568},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":14724155},\"end\":69399,\"start\":68920},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":67339858},\"end\":69772,\"start\":69401},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3815411},\"end\":70227,\"start\":69774},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":121126},\"end\":70533,\"start\":70229},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":3334390},\"end\":70927,\"start\":70535},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":16635890},\"end\":71512,\"start\":70929},{\"attributes\":{\"id\":\"b14\"},\"end\":71885,\"start\":71514},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":23789513},\"end\":72254,\"start\":71887},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":9447921},\"end\":72591,\"start\":72256},{\"attributes\":{\"id\":\"b17\"},\"end\":73153,\"start\":72593},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":980236},\"end\":73475,\"start\":73155},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":17743610},\"end\":73909,\"start\":73477},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1779661},\"end\":74072,\"start\":73911},{\"attributes\":{\"id\":\"b21\"},\"end\":74336,\"start\":74074},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":15370510},\"end\":74653,\"start\":74338},{\"attributes\":{\"id\":\"b23\"},\"end\":75038,\"start\":74655},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1739295},\"end\":77062,\"start\":75040},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":28033485},\"end\":77496,\"start\":77064},{\"attributes\":{\"id\":\"b26\"},\"end\":77810,\"start\":77498},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":42502395},\"end\":78224,\"start\":77812},{\"attributes\":{\"id\":\"b28\"},\"end\":78527,\"start\":78226},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":3719281},\"end\":78884,\"start\":78529},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":13133466},\"end\":79177,\"start\":78886},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":2930547},\"end\":79727,\"start\":79179},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":1687220},\"end\":80091,\"start\":79729},{\"attributes\":{\"id\":\"b33\"},\"end\":80505,\"start\":80093},{\"attributes\":{\"id\":\"b34\"},\"end\":80938,\"start\":80507},{\"attributes\":{\"id\":\"b35\"},\"end\":81353,\"start\":80940},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":18068061},\"end\":81784,\"start\":81355},{\"attributes\":{\"id\":\"b37\"},\"end\":83344,\"start\":81786},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":206709308},\"end\":84284,\"start\":83346},{\"attributes\":{\"id\":\"b39\"},\"end\":84646,\"start\":84286},{\"attributes\":{\"id\":\"b40\"},\"end\":84797,\"start\":84648},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":1370281},\"end\":85058,\"start\":84799},{\"attributes\":{\"id\":\"b42\"},\"end\":85408,\"start\":85060},{\"attributes\":{\"id\":\"b43\"},\"end\":85632,\"start\":85410},{\"attributes\":{\"id\":\"b44\"},\"end\":86159,\"start\":85634},{\"attributes\":{\"id\":\"b45\"},\"end\":86672,\"start\":86161},{\"attributes\":{\"id\":\"b46\"},\"end\":86956,\"start\":86674},{\"attributes\":{\"id\":\"b47\"},\"end\":87138,\"start\":86958},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":686320},\"end\":87582,\"start\":87140},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":41805341},\"end\":88043,\"start\":87584},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":8945673},\"end\":88654,\"start\":88045},{\"attributes\":{\"id\":\"b51\"},\"end\":88951,\"start\":88656},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":60600316},\"end\":89286,\"start\":88953},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":207761262},\"end\":89662,\"start\":89288},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":24297838},\"end\":90326,\"start\":89664},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":51708282},\"end\":90717,\"start\":90328},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":15520156},\"end\":91007,\"start\":90719},{\"attributes\":{\"id\":\"b57\"},\"end\":91262,\"start\":91009},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":10649298},\"end\":91586,\"start\":91264},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":5334482},\"end\":91909,\"start\":91588},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":4173387},\"end\":92228,\"start\":91911}]", "bib_title": "[{\"end\":65926,\"start\":65810},{\"end\":66663,\"start\":66560},{\"end\":67052,\"start\":66972},{\"end\":67319,\"start\":67228},{\"end\":68070,\"start\":68009},{\"end\":68616,\"start\":68568},{\"end\":68988,\"start\":68920},{\"end\":69471,\"start\":69401},{\"end\":69847,\"start\":69774},{\"end\":70305,\"start\":70229},{\"end\":70599,\"start\":70535},{\"end\":71005,\"start\":70929},{\"end\":71981,\"start\":71887},{\"end\":72305,\"start\":72256},{\"end\":73222,\"start\":73155},{\"end\":73568,\"start\":73477},{\"end\":73924,\"start\":73911},{\"end\":74408,\"start\":74338},{\"end\":75103,\"start\":75040},{\"end\":77184,\"start\":77064},{\"end\":77909,\"start\":77812},{\"end\":78592,\"start\":78529},{\"end\":78942,\"start\":78886},{\"end\":79228,\"start\":79179},{\"end\":79766,\"start\":79729},{\"end\":81438,\"start\":81355},{\"end\":83414,\"start\":83346},{\"end\":84826,\"start\":84799},{\"end\":85718,\"start\":85634},{\"end\":87197,\"start\":87140},{\"end\":87662,\"start\":87584},{\"end\":88187,\"start\":88045},{\"end\":89014,\"start\":88953},{\"end\":89360,\"start\":89288},{\"end\":89753,\"start\":89664},{\"end\":90440,\"start\":90328},{\"end\":90760,\"start\":90719},{\"end\":91325,\"start\":91264},{\"end\":91645,\"start\":91588},{\"end\":91969,\"start\":91911}]", "bib_author": "[{\"end\":65960,\"start\":65928},{\"end\":65984,\"start\":65960},{\"end\":65996,\"start\":65984},{\"end\":66015,\"start\":65996},{\"end\":66035,\"start\":66015},{\"end\":66044,\"start\":66035},{\"end\":66056,\"start\":66044},{\"end\":66076,\"start\":66056},{\"end\":66085,\"start\":66076},{\"end\":66096,\"start\":66085},{\"end\":66114,\"start\":66096},{\"end\":66125,\"start\":66114},{\"end\":66677,\"start\":66665},{\"end\":66692,\"start\":66677},{\"end\":66709,\"start\":66692},{\"end\":66714,\"start\":66709},{\"end\":67063,\"start\":67054},{\"end\":67073,\"start\":67063},{\"end\":67341,\"start\":67321},{\"end\":67356,\"start\":67341},{\"end\":67373,\"start\":67356},{\"end\":67393,\"start\":67373},{\"end\":67419,\"start\":67393},{\"end\":67829,\"start\":67817},{\"end\":67841,\"start\":67829},{\"end\":67850,\"start\":67841},{\"end\":67856,\"start\":67850},{\"end\":68083,\"start\":68072},{\"end\":68100,\"start\":68083},{\"end\":68109,\"start\":68100},{\"end\":68337,\"start\":68328},{\"end\":68345,\"start\":68337},{\"end\":68358,\"start\":68345},{\"end\":68376,\"start\":68358},{\"end\":68396,\"start\":68376},{\"end\":68644,\"start\":68618},{\"end\":68660,\"start\":68644},{\"end\":68668,\"start\":68660},{\"end\":68998,\"start\":68990},{\"end\":69008,\"start\":68998},{\"end\":69017,\"start\":69008},{\"end\":69032,\"start\":69017},{\"end\":69051,\"start\":69032},{\"end\":69068,\"start\":69051},{\"end\":69084,\"start\":69068},{\"end\":69099,\"start\":69084},{\"end\":69112,\"start\":69099},{\"end\":69119,\"start\":69112},{\"end\":69492,\"start\":69473},{\"end\":69507,\"start\":69492},{\"end\":69517,\"start\":69507},{\"end\":69535,\"start\":69517},{\"end\":69541,\"start\":69535},{\"end\":69868,\"start\":69849},{\"end\":69884,\"start\":69868},{\"end\":69898,\"start\":69884},{\"end\":69915,\"start\":69898},{\"end\":69935,\"start\":69915},{\"end\":69948,\"start\":69935},{\"end\":69963,\"start\":69948},{\"end\":70319,\"start\":70307},{\"end\":70333,\"start\":70319},{\"end\":70616,\"start\":70601},{\"end\":70630,\"start\":70616},{\"end\":70645,\"start\":70630},{\"end\":70659,\"start\":70645},{\"end\":70674,\"start\":70659},{\"end\":70687,\"start\":70674},{\"end\":70704,\"start\":70687},{\"end\":71023,\"start\":71007},{\"end\":71042,\"start\":71023},{\"end\":71052,\"start\":71042},{\"end\":71066,\"start\":71052},{\"end\":71083,\"start\":71066},{\"end\":71101,\"start\":71083},{\"end\":71116,\"start\":71101},{\"end\":71132,\"start\":71116},{\"end\":71149,\"start\":71132},{\"end\":71165,\"start\":71149},{\"end\":71172,\"start\":71165},{\"end\":71525,\"start\":71514},{\"end\":71539,\"start\":71525},{\"end\":71552,\"start\":71539},{\"end\":71566,\"start\":71552},{\"end\":71578,\"start\":71566},{\"end\":71595,\"start\":71578},{\"end\":71996,\"start\":71983},{\"end\":72004,\"start\":71996},{\"end\":72019,\"start\":72004},{\"end\":72033,\"start\":72019},{\"end\":72333,\"start\":72307},{\"end\":72347,\"start\":72333},{\"end\":72361,\"start\":72347},{\"end\":72375,\"start\":72361},{\"end\":72380,\"start\":72375},{\"end\":72701,\"start\":72690},{\"end\":72717,\"start\":72701},{\"end\":72726,\"start\":72717},{\"end\":72750,\"start\":72726},{\"end\":72765,\"start\":72750},{\"end\":72775,\"start\":72765},{\"end\":72782,\"start\":72775},{\"end\":72791,\"start\":72782},{\"end\":72809,\"start\":72791},{\"end\":72820,\"start\":72809},{\"end\":72836,\"start\":72820},{\"end\":72855,\"start\":72836},{\"end\":72864,\"start\":72855},{\"end\":73240,\"start\":73224},{\"end\":73257,\"start\":73240},{\"end\":73269,\"start\":73257},{\"end\":73592,\"start\":73570},{\"end\":73606,\"start\":73592},{\"end\":73611,\"start\":73606},{\"end\":73619,\"start\":73611},{\"end\":73639,\"start\":73619},{\"end\":73652,\"start\":73639},{\"end\":73938,\"start\":73926},{\"end\":73953,\"start\":73938},{\"end\":73970,\"start\":73953},{\"end\":74152,\"start\":74139},{\"end\":74168,\"start\":74152},{\"end\":74181,\"start\":74168},{\"end\":74191,\"start\":74181},{\"end\":74200,\"start\":74191},{\"end\":74426,\"start\":74410},{\"end\":74440,\"start\":74426},{\"end\":74454,\"start\":74440},{\"end\":74667,\"start\":74657},{\"end\":74680,\"start\":74667},{\"end\":74694,\"start\":74680},{\"end\":74711,\"start\":74694},{\"end\":74735,\"start\":74711},{\"end\":74745,\"start\":74735},{\"end\":75125,\"start\":75105},{\"end\":75136,\"start\":75125},{\"end\":75151,\"start\":75136},{\"end\":75168,\"start\":75151},{\"end\":75185,\"start\":75168},{\"end\":75202,\"start\":75185},{\"end\":75219,\"start\":75202},{\"end\":75236,\"start\":75219},{\"end\":75251,\"start\":75236},{\"end\":75268,\"start\":75251},{\"end\":75279,\"start\":75268},{\"end\":75291,\"start\":75279},{\"end\":75315,\"start\":75291},{\"end\":75329,\"start\":75315},{\"end\":75342,\"start\":75329},{\"end\":75355,\"start\":75342},{\"end\":75371,\"start\":75355},{\"end\":75388,\"start\":75371},{\"end\":75401,\"start\":75388},{\"end\":75417,\"start\":75401},{\"end\":75434,\"start\":75417},{\"end\":75445,\"start\":75434},{\"end\":75454,\"start\":75445},{\"end\":75462,\"start\":75454},{\"end\":75481,\"start\":75462},{\"end\":75495,\"start\":75481},{\"end\":75507,\"start\":75495},{\"end\":75525,\"start\":75507},{\"end\":75547,\"start\":75525},{\"end\":75562,\"start\":75547},{\"end\":75575,\"start\":75562},{\"end\":75590,\"start\":75575},{\"end\":75608,\"start\":75590},{\"end\":75628,\"start\":75608},{\"end\":75635,\"start\":75628},{\"end\":75645,\"start\":75635},{\"end\":75661,\"start\":75645},{\"end\":75673,\"start\":75661},{\"end\":75694,\"start\":75673},{\"end\":75714,\"start\":75694},{\"end\":75726,\"start\":75714},{\"end\":75744,\"start\":75726},{\"end\":75756,\"start\":75744},{\"end\":75772,\"start\":75756},{\"end\":75787,\"start\":75772},{\"end\":75804,\"start\":75787},{\"end\":75819,\"start\":75804},{\"end\":75838,\"start\":75819},{\"end\":75855,\"start\":75838},{\"end\":75869,\"start\":75855},{\"end\":75885,\"start\":75869},{\"end\":75898,\"start\":75885},{\"end\":75910,\"start\":75898},{\"end\":75925,\"start\":75910},{\"end\":75938,\"start\":75925},{\"end\":75955,\"start\":75938},{\"end\":75971,\"start\":75955},{\"end\":75989,\"start\":75971},{\"end\":77196,\"start\":77186},{\"end\":77208,\"start\":77196},{\"end\":77226,\"start\":77208},{\"end\":77242,\"start\":77226},{\"end\":77599,\"start\":77572},{\"end\":77616,\"start\":77599},{\"end\":77635,\"start\":77616},{\"end\":77645,\"start\":77635},{\"end\":77922,\"start\":77911},{\"end\":77935,\"start\":77922},{\"end\":77942,\"start\":77935},{\"end\":78289,\"start\":78280},{\"end\":78297,\"start\":78289},{\"end\":78308,\"start\":78297},{\"end\":78327,\"start\":78308},{\"end\":78334,\"start\":78327},{\"end\":78344,\"start\":78334},{\"end\":78360,\"start\":78344},{\"end\":78369,\"start\":78360},{\"end\":78612,\"start\":78594},{\"end\":78629,\"start\":78612},{\"end\":78642,\"start\":78629},{\"end\":78968,\"start\":78944},{\"end\":78980,\"start\":78968},{\"end\":78988,\"start\":78980},{\"end\":79248,\"start\":79230},{\"end\":79258,\"start\":79248},{\"end\":79266,\"start\":79258},{\"end\":79283,\"start\":79266},{\"end\":79301,\"start\":79283},{\"end\":79310,\"start\":79301},{\"end\":79325,\"start\":79310},{\"end\":79342,\"start\":79325},{\"end\":79357,\"start\":79342},{\"end\":79376,\"start\":79357},{\"end\":79394,\"start\":79376},{\"end\":79406,\"start\":79394},{\"end\":79782,\"start\":79768},{\"end\":79798,\"start\":79782},{\"end\":79816,\"start\":79798},{\"end\":79830,\"start\":79816},{\"end\":79844,\"start\":79830},{\"end\":79853,\"start\":79844},{\"end\":80203,\"start\":80180},{\"end\":80217,\"start\":80203},{\"end\":80233,\"start\":80217},{\"end\":80244,\"start\":80233},{\"end\":80256,\"start\":80244},{\"end\":80646,\"start\":80627},{\"end\":80662,\"start\":80646},{\"end\":80676,\"start\":80662},{\"end\":80694,\"start\":80676},{\"end\":80710,\"start\":80694},{\"end\":80720,\"start\":80710},{\"end\":81074,\"start\":81060},{\"end\":81090,\"start\":81074},{\"end\":81107,\"start\":81090},{\"end\":81124,\"start\":81107},{\"end\":81141,\"start\":81124},{\"end\":81454,\"start\":81440},{\"end\":81470,\"start\":81454},{\"end\":81487,\"start\":81470},{\"end\":81504,\"start\":81487},{\"end\":81521,\"start\":81504},{\"end\":81939,\"start\":81923},{\"end\":81954,\"start\":81939},{\"end\":81972,\"start\":81954},{\"end\":81987,\"start\":81972},{\"end\":82005,\"start\":81987},{\"end\":82018,\"start\":82005},{\"end\":82039,\"start\":82018},{\"end\":82052,\"start\":82039},{\"end\":82061,\"start\":82052},{\"end\":82080,\"start\":82061},{\"end\":82095,\"start\":82080},{\"end\":82111,\"start\":82095},{\"end\":82137,\"start\":82111},{\"end\":82148,\"start\":82137},{\"end\":82156,\"start\":82148},{\"end\":82169,\"start\":82156},{\"end\":82188,\"start\":82169},{\"end\":82200,\"start\":82188},{\"end\":82210,\"start\":82200},{\"end\":82215,\"start\":82210},{\"end\":82229,\"start\":82215},{\"end\":82248,\"start\":82229},{\"end\":82276,\"start\":82248},{\"end\":82300,\"start\":82276},{\"end\":82314,\"start\":82300},{\"end\":82332,\"start\":82314},{\"end\":82358,\"start\":82332},{\"end\":82373,\"start\":82358},{\"end\":82393,\"start\":82373},{\"end\":82416,\"start\":82393},{\"end\":82428,\"start\":82416},{\"end\":82454,\"start\":82428},{\"end\":82463,\"start\":82454},{\"end\":82474,\"start\":82463},{\"end\":82483,\"start\":82474},{\"end\":83430,\"start\":83416},{\"end\":83450,\"start\":83430},{\"end\":83470,\"start\":83450},{\"end\":83481,\"start\":83470},{\"end\":83499,\"start\":83481},{\"end\":83510,\"start\":83499},{\"end\":83530,\"start\":83510},{\"end\":83542,\"start\":83530},{\"end\":83557,\"start\":83542},{\"end\":83574,\"start\":83557},{\"end\":83589,\"start\":83574},{\"end\":83611,\"start\":83589},{\"end\":83623,\"start\":83611},{\"end\":83645,\"start\":83623},{\"end\":83665,\"start\":83645},{\"end\":83674,\"start\":83665},{\"end\":84429,\"start\":84419},{\"end\":84449,\"start\":84429},{\"end\":84458,\"start\":84449},{\"end\":84711,\"start\":84693},{\"end\":84839,\"start\":84828},{\"end\":84852,\"start\":84839},{\"end\":84860,\"start\":84852},{\"end\":85213,\"start\":85196},{\"end\":85230,\"start\":85213},{\"end\":85488,\"start\":85475},{\"end\":85502,\"start\":85488},{\"end\":85735,\"start\":85720},{\"end\":85751,\"start\":85735},{\"end\":85762,\"start\":85751},{\"end\":85777,\"start\":85762},{\"end\":85793,\"start\":85777},{\"end\":85815,\"start\":85793},{\"end\":85831,\"start\":85815},{\"end\":86299,\"start\":86284},{\"end\":86309,\"start\":86299},{\"end\":86317,\"start\":86309},{\"end\":86333,\"start\":86317},{\"end\":86349,\"start\":86333},{\"end\":86355,\"start\":86349},{\"end\":86363,\"start\":86355},{\"end\":86370,\"start\":86363},{\"end\":86381,\"start\":86370},{\"end\":86401,\"start\":86381},{\"end\":86409,\"start\":86401},{\"end\":86759,\"start\":86743},{\"end\":86775,\"start\":86759},{\"end\":86795,\"start\":86775},{\"end\":86974,\"start\":86958},{\"end\":86990,\"start\":86974},{\"end\":87010,\"start\":86990},{\"end\":87214,\"start\":87199},{\"end\":87228,\"start\":87214},{\"end\":87241,\"start\":87228},{\"end\":87250,\"start\":87241},{\"end\":87260,\"start\":87250},{\"end\":87272,\"start\":87260},{\"end\":87284,\"start\":87272},{\"end\":87296,\"start\":87284},{\"end\":87680,\"start\":87664},{\"end\":87693,\"start\":87680},{\"end\":87706,\"start\":87693},{\"end\":87718,\"start\":87706},{\"end\":87729,\"start\":87718},{\"end\":87746,\"start\":87729},{\"end\":88204,\"start\":88189},{\"end\":88216,\"start\":88204},{\"end\":88223,\"start\":88216},{\"end\":88235,\"start\":88223},{\"end\":88257,\"start\":88235},{\"end\":88273,\"start\":88257},{\"end\":88781,\"start\":88770},{\"end\":88795,\"start\":88781},{\"end\":89027,\"start\":89016},{\"end\":89035,\"start\":89027},{\"end\":89054,\"start\":89035},{\"end\":89061,\"start\":89054},{\"end\":89373,\"start\":89362},{\"end\":89387,\"start\":89373},{\"end\":89396,\"start\":89387},{\"end\":89411,\"start\":89396},{\"end\":89423,\"start\":89411},{\"end\":89774,\"start\":89755},{\"end\":89790,\"start\":89774},{\"end\":89805,\"start\":89790},{\"end\":89820,\"start\":89805},{\"end\":89836,\"start\":89820},{\"end\":89851,\"start\":89836},{\"end\":89867,\"start\":89851},{\"end\":89886,\"start\":89867},{\"end\":89901,\"start\":89886},{\"end\":89922,\"start\":89901},{\"end\":89938,\"start\":89922},{\"end\":89954,\"start\":89938},{\"end\":89968,\"start\":89954},{\"end\":89977,\"start\":89968},{\"end\":90450,\"start\":90442},{\"end\":90465,\"start\":90450},{\"end\":90472,\"start\":90465},{\"end\":90488,\"start\":90472},{\"end\":90772,\"start\":90762},{\"end\":90782,\"start\":90772},{\"end\":90793,\"start\":90782},{\"end\":90805,\"start\":90793},{\"end\":91083,\"start\":91073},{\"end\":91093,\"start\":91083},{\"end\":91104,\"start\":91093},{\"end\":91116,\"start\":91104},{\"end\":91338,\"start\":91327},{\"end\":91349,\"start\":91338},{\"end\":91362,\"start\":91349},{\"end\":91375,\"start\":91362},{\"end\":91658,\"start\":91647},{\"end\":91672,\"start\":91658},{\"end\":91685,\"start\":91672},{\"end\":91696,\"start\":91685},{\"end\":91979,\"start\":91971},{\"end\":91995,\"start\":91979},{\"end\":92013,\"start\":91995},{\"end\":92028,\"start\":92013},{\"end\":92045,\"start\":92028}]", "bib_venue": "[{\"end\":66168,\"start\":66125},{\"end\":66753,\"start\":66714},{\"end\":67095,\"start\":67073},{\"end\":67473,\"start\":67419},{\"end\":67815,\"start\":67740},{\"end\":68126,\"start\":68109},{\"end\":68326,\"start\":68266},{\"end\":68735,\"start\":68668},{\"end\":69149,\"start\":69119},{\"end\":69579,\"start\":69541},{\"end\":69993,\"start\":69963},{\"end\":70369,\"start\":70333},{\"end\":70723,\"start\":70704},{\"end\":71208,\"start\":71172},{\"end\":71678,\"start\":71595},{\"end\":72059,\"start\":72033},{\"end\":72411,\"start\":72380},{\"end\":72688,\"start\":72593},{\"end\":73307,\"start\":73269},{\"end\":73681,\"start\":73652},{\"end\":73976,\"start\":73970},{\"end\":74137,\"start\":74074},{\"end\":74484,\"start\":74454},{\"end\":76025,\"start\":75989},{\"end\":77268,\"start\":77242},{\"end\":77570,\"start\":77498},{\"end\":78009,\"start\":77942},{\"end\":78278,\"start\":78226},{\"end\":78700,\"start\":78642},{\"end\":79018,\"start\":78988},{\"end\":79446,\"start\":79406},{\"end\":79902,\"start\":79853},{\"end\":80178,\"start\":80093},{\"end\":80625,\"start\":80507},{\"end\":81058,\"start\":80940},{\"end\":81557,\"start\":81521},{\"end\":81921,\"start\":81786},{\"end\":83767,\"start\":83674},{\"end\":84417,\"start\":84286},{\"end\":84691,\"start\":84648},{\"end\":84916,\"start\":84860},{\"end\":85194,\"start\":85060},{\"end\":85473,\"start\":85410},{\"end\":85887,\"start\":85831},{\"end\":86282,\"start\":86161},{\"end\":86741,\"start\":86674},{\"end\":87026,\"start\":87010},{\"end\":87353,\"start\":87296},{\"end\":87806,\"start\":87746},{\"end\":88341,\"start\":88273},{\"end\":88768,\"start\":88656},{\"end\":89112,\"start\":89061},{\"end\":89460,\"start\":89423},{\"end\":89985,\"start\":89977},{\"end\":90514,\"start\":90488},{\"end\":90854,\"start\":90805},{\"end\":91071,\"start\":91009},{\"end\":91412,\"start\":91375},{\"end\":91738,\"start\":91696},{\"end\":92051,\"start\":92045}]"}}}, "year": 2023, "month": 12, "day": 17}