{"id": 240433507, "updated": "2023-10-05 19:57:49.628", "metadata": {"title": "Personalized Federated Learning for ECG Classification Based on Feature Alignment", "authors": "[{\"first\":\"Renjie\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Junzhou\",\"last\":\"Luo\",\"middle\":[]},{\"first\":\"Junbo\",\"last\":\"Qian\",\"middle\":[]},{\"first\":\"Jiahui\",\"last\":\"Jin\",\"middle\":[]}]", "venue": "Security and Communication Networks", "journal": "Security and Communication Networks", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Electrocardiogram (ECG) data classification is a hot research area for its application in medical information processing. However, insufficient data, privacy preserve, and local deployment are still challenging difficulties. To address these problems, a novel personalized federated learning method for ECG classification is proposed in this paper. First, a global model is trained with federated learning framework on multiple local data clients. )en, we use the global model and private data to train the local model. To reduce the feature inconsistency between global and private local data and for better fitting the private local data, a novel \u201dfeature alignment\u201d module is devised to guarantee the uniformity, which contains two parts, global alignment and local alignment, respectively. For global alignment, the graphmetric of batch data is used to constrain the dissimilarity between features generated by the global model and local model. For local alignment, triplet loss is adopted to increase discriminative ability for local private data. Comprehensive experiments on our collected dataset are evaluated. )e results show that the proposed method can be better adapted to local data and exhibit superior ability of generalization.", "fields_of_study": null, "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.1155/2021/6217601"}}, "content": {"source": {"pdf_hash": "4a6347c35669a4f11714c628921e3b69cd1f2c88", "pdf_src": "Anansi", "pdf_uri": "[\"https://downloads.hindawi.com/journals/scn/2021/6217601.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://downloads.hindawi.com/journals/scn/2021/6217601.pdf", "status": "GOLD"}}, "grobid": {"id": "ee4a470b2400a18baceb780863f9592493f040c7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4a6347c35669a4f11714c628921e3b69cd1f2c88.txt", "contents": "\nPersonalized Federated Learning for ECG Classification Based on Feature Alignment\nPublished 1 November 2021\n\nRenjie Tang tangrj@seu.edu.cn \nSchool of Computer Science and Engineering\nSoutheast University\n211189NanjingJiangsu ProvinceChina\n\nChina Mobile Group Zhejiang Co., Ltd\nZhejiang Province310016HangzhouChina\n\nJunzhou Luo \nSchool of Computer Science and Engineering\nSoutheast University\n211189NanjingJiangsu ProvinceChina\n\nJunbo Qian \nChina Mobile Group Zhejiang Co., Ltd\nZhejiang Province310016HangzhouChina\n\nJiahui Jin \nSchool of Computer Science and Engineering\nSoutheast University\n211189NanjingJiangsu ProvinceChina\n\nPersonalized Federated Learning for ECG Classification Based on Feature Alignment\nPublished 1 November 202110.1155/2021/6217601Received 22 June 2021; Revised 15 September 2021; Accepted 4 October 2021;Research Article Correspondence should be addressed to Renjie Tang; Academic Editor: Lianbo Ma\nElectrocardiogram (ECG) data classification is a hot research area for its application in medical information processing. However, insufficient data, privacy preserve, and local deployment are still challenging difficulties. To address these problems, a novel personalized federated learning method for ECG classification is proposed in this paper. First, a global model is trained with federated learning framework on multiple local data clients. en, we use the global model and private data to train the local model. To reduce the feature inconsistency between global and private local data and for better fitting the private local data, a novel \"feature alignment\" module is devised to guarantee the uniformity, which contains two parts, global alignment and local alignment, respectively. For global alignment, the graph metric of batch data is used to constrain the dissimilarity between features generated by the global model and local model. For local alignment, triplet loss is adopted to increase discriminative ability for local private data. Comprehensive experiments on our collected dataset are evaluated. e results show that the proposed method can be better adapted to local data and exhibit superior ability of generalization.\n\nIntroduction\n\nStatistics of WHO report that heart disease is the most lethal chronic disease. Nearly 17.7 million people die of cardiovascular disease every year, which accounts for 31% of the total deaths in the world [1]. Electrocardiogram (ECG) is a physiological signal which is widely used in heart health monitoring. It contains many pathological information related to heart activity, and it is an effective way for monitoring and diagnosis of cardiovascular disease [2]. ECG is a long series of data and can be lasted for days, so it is very time and label consuming for monitoring and diagnosis with human experts. erefore, it is necessary to use artificial intelligence technology for automatic cardiovascular disease diagnosis.\n\nUsing the advanced machine learning technology especially deep learning, the cardiovascular recognition model can be trained with labeled ECG data, i.e., the method proposed in [3] achieves 0.837 F1 value for 12 kinds of cardiac irregularities. However, most state of the art methods are based on public available training datasets, which are relatively small and with limited varieties. Moreover, they are very difficult to deploy in practical applications.\n\nIn order to expand available cardiovascular information and guarantee the privacy, data from multiple medical institutions can be combined as a unified dataset, which can be used to train a superior global model with federated learning framework [4]. Federated learning is a special machine learning model using datasets that are distributed across multiple devices while preventing data leakage. It is also a privacy-preserving decentralized collaborative learning technique [5].\n\nere have been works that adopted federated learning for medical data processing and model training [6,7].\n\nIn this way, a centralized global model can be trained based on data from a large number of local nodes. en, the global model is deployed to the local model for data prediction. However, there is a big challenge for which local models will get different performance by using the same global model. is is because data distributions of local clients vary with the global trained data distribution. erefore, personalization of the global model for each client becomes necessary to overcome the problem posed by heterogeneity of data distribution [8].\n\nDevice in terms of storage, computation, and communication capabilities will generate heterogeneous data. For ECG, sampling frequency and duration are different based on parameters setting and environment, which leads to nonuniform of pacing signal, left ventricular high voltage, and other diagnostic patterns. When there is large difference between data distributions of global server and local clients, it is hard to directly measure the feature inconsistency between them. Hence, this makes it difficult to deploy the global ECG classification model to local client with acceptable performance.\n\nIn order to solve these problems, a novel personalized federated learning framework for ECG data classification is proposed. First, a global ECG classification model is trained with a typical federated learning method across multiple local clients. en, the global model is inherited to local model and served as the backbone part. During local model personalized training, the inherited part model is fixed. e local model is personalized based on the proposed feature alignment module. To utilize the generalization of the global model, we form the features of batch data into graph representation, so the internal structure between nodes can be preserved. e graph distance between global feature and local feature is used for global alignment constrain. From another point of view, local alignment is used to make the model better adapt to local private data. e metric learning method is adopted, and a triplet loss is designed to make data point of same class close to each other and negative data point far away. Finally, these loss functions are combined together for model training. By the proposed method, the consistency between global and local data can be learned, and the local personalized model is built with better adaptability and generalization. As far as we know, there are no related research studies for problems of personalized ECG classification. e main contributions of this paper are two folds:\n\n(i) In order to reduce the difference between global and local data, a novel feature alignment module is designed. With graph constraint and triplet metric, it can make the local model with better adaptability and generalization. (ii) Extensive experimental evaluations are carried out, and performance analyses are reported from multiple aspects. e rest of this paper is organized as follows. Section 2 gives the related works. Section 3 describes the methodology. Experimental evaluation and analysis are given in Section 4. Section 5 concludes this paper.\n\n\nRelated Works\n\nRelated works are introduced in this section, including ECG data classification method, federated learning framework, and personalization in federated learning.\n\n\nECG Classification Method.\n\nWith well-designed feature representation, ECG classification can be realized by models based on Bayes, K-means, Decision tree, and Linear Discriminate classifiers [9][10][11], along with commonly used optimization techniques [12,13]. Features like cycle and higher order of QRS wave were extracted in reference [14]. en, a fuzzy neural network was trained as classifier. Wavelet transform was used for feature extraction in reference [15]. Reference [16] adopted support vector machine for ECG classification.\n\nA convolutional neural network method suitable for multilead ECG data was proposed in reference [17]. e stacked denosing autoencoder recognition model was used in reference [18] for ECG data. In reference [19], deep belief networks were used to construct the model for arrhythmia diagnosis.\n\ne convolutional neural networks model was used in reference [20] for heart beat classification. In reference [21], the deep factor decomposition method was used to decrease the influence of complex noise on ECG signal. Deep autoencoder was first used for singal denosing and reconstruction, and then fully convolutional network was trained as classifier. In reference [22], nonnegative matrix factorization was used for data dimension reduction and feature was extracted with sparse representation. Feature representation with multiple scales was proposed in reference [23], and progressive decisions were fused for final classification.\n\n\nFederated\n\nLearning. In order to utilize massive distributed data storage and keep the privacy, federated learning is a useful framework to provide efficient training from data island and make model collaboration [4]. In reference [24], local models are trained at each local node, and only the updated parameters set is shared for global training. A multitask-based federated learning method was proposed in reference [25], which can solve the problem of high communication cost and fault tolerance. In reference [26], a safe client-server was first constructed. Data were allocated according to different local users. A homomorphic encryption method was designed for model parameter aggregation so as to improve server security [27]. A differential privacy method for federated learning was introduced in reference [28]. It provides protection for client data by hiding the customer's contribution during training. A ternary quantization method was proposed in reference [29], which optimizes the quantized networks and reduces lots of redundant parameters and excessive communication costs. To address problems of unlabeled and unannotated ondevice data, reference [30] used a deep temporal neural network to train an auxiliary task by optimizing a contrastive objective with multiview strategy on diverse data sets.\n\n\nPersonalization in Federated\n\nLearning. Federated learning can be used to train a global model by utilizing distributed local data. However, for different local clients, the benefits they get from global model may vary greatly for various data distributions. To cope with non-IID data distributions of clients, personalized federated learning has been proposed to improve performance of each local client by training a personalized local model. Reference [31] reported that local models' performances were hard to improve during federated learning, which may even worse than training only using local data. erefore, it is important for model personalization according to specific local node. In reference [32], local nodes were first clustered, and each group models were training separately. In reference [33], part parameters of the global model were copied to the local model, and then local model was finetuned using local data. e metalearning method was adopted in reference [34], which treated model personalization as a meta testing procedure. In reference [35], there was a balance between global and local models. Global and local models were combined for final classification. In reference [36], the local model and global model were considered as two experts, and the personalized model was trained by mixed output of the personalized model and global model. Similar work was studied in reference [37]. Reference [38] introduced an attentive message passing mechanism to facilitate the collaboration effectiveness between clients.\n\n\nMethodology\n\nIn this section, the proposed personalized federated learning for ECG classification based on feature alignment is described. Figure 1 gives the main framework of the proposed method. First, a global model M G \u2032 is constructed with a typical federated learning framework from multiple local clients. en, for each client c i , we train a personalized local model with private dataset. e local model contains three parts, including M G , M C , and M f . M G is inherited from the global model M G \u2032 . M C is a convolution neural networks module for local feature extraction and representation. M f is a fully connected layer or softmax layer to form the final classifier. During local model training, M G is fixed to maintain the generalization ability of the global model. Specially, two alignment modules, global alignment and local alignment, are designed to constrain the feature distribution between local model and global model, which are realized by constraints of graph representation of feature generated by M G and M C , along with metric learning for intraclass and interclass losses. Finally, global alignment loss L a , local alignment loss L t , and cross-entropy loss L c are all incorporated to optimize the objective function. Details are described in the following subsections.\n\n\nGlobal Model Training.\n\nIn order to make the best use of distributed data and privacy guarantee, federated learning is a popular way for model training. In the first step, the global model M G \u2032 is trained with a most widely used federated learning framework FedAvg [39], which is synchronous update for each communication round. Figure 2 demonstrates the framework for global model training in our work. ere are n clients, and each contains a local dataset P i and a local model M i . Initially, the global server sends the model parameters to all clients. en, each client c i performs local model training based on local data and then sends parameter update w i back to the server. e server collects all local updates, and the global model parameters are optimized, and this process is repeated for multiple times. For efficiency, the global model can be updated when part of local updates is collected.\nlc i w i \ufffd 1 n i n i k\ufffd1 l x k , y k , w i ,(1)min w i lc i w i .(2)\nFor client c i , its model parameter w i is trained with local data (x k , y k ) \u2208 P i . Equation (1) gives the loss function lc i , which is the mean value of loss l () for all training data. n i is the total number of data in P i . en, equation (2) gives the minimize objective by adjusting w i with SGD and BP method.\n\nWhen clients finish their training, the server updates the global model parameter w G by averaging all client model's parameters w i . As shown in equations (3) and (4), N is the number of clients and t i is the weight threshold for each model.\ne G \ufffd 1 N N i\ufffd1 t i * w i , N i\ufffd1 t i \ufffd 1,(3)min w G 1 N N i\ufffd1 lc i w G .(4)\nw G is distributed to all clients after one iteration, and each client uses s G as the base model to make further training using equations (1) and (2). After multiple iterations, the global model M G \u2032 can be trained with optimal performance. Moreover, other federated learning frameworks can also be adopted for global model training.\n\n\nLocal Model Training.\n\ne global model M G \u2032 is trained with federated learning over distributed data in the last subsection. However, M G \u2032 cannot be directly deployed to local clients for local data inference when there is large difference between data distributions of global server and local clients. In this subsection, a personalized model adaptation method is designed based on the global trained model and private data of a specific client. e local model For better fitting the local private data, a special constraint strategy \"feature alignment\" is devised to guarantee the uniformity between global and local models. e alignment module is further divided into two parts, global alignment and local alignment, which are described as follows.\n\n\nSecurity and Communication Networks\n\n\nGlobal Alignment.\n\nA global alignment module is first designed to constrain the local model training by constructing the structure between feature nodes. Different from other methods, the batch training data are used to from a graph structure, which can represent the relationship between data node. In this way, effect of single data feature shift can be reduced and relation between data nodes is retained. As shown in Figure 3, for ith training batch data samples (X i , Y i ) in a private dataset, its global feature f g (X i ) and local feature f p (X i ) are extracted through models M G and M C . en, the batch training data are treated as the basic group for global alignment operation. e features of samples are then used to construct graph representation using f g (X i ) and f p (X i ). Suppose there are n samples in a training batch, then the graph representation contains n nodes and n 2 edges. e nodes of graph are represented with the features of samples in a training batch, and the edges of graph are represented by the distances between nodes. gm(X i ) and gp(X i ) are used to denote the graph representation of ith batch data by global and local models, respectively.\n\nIn order to measure the similarity between two batch data, matrix format is used to represent the graph structure representation. In this paper, only edges between nodes are incorporated for representation. It is hypothesis that the internal skeleton between nodes of a graph is more important and should be learned from the global model. If the node feature is used, then there will be strong probability that the local model is more like the global model. e white and yellow matrices in Figure 3 are used to denote gm(X i ) and gp(X i ), which are formulated as equations (5) and (6). e represents the edge between two nodes. x i j and x i k are two training samples in X i .\ngm X i \ufffd \u222a x i j ,x i k \u2208X i e fg x i j , fg x i k ,(5)gp X i \ufffd \u222a x i j ,x i k \u2208X i e fp x i j , fp x i k .(6)\nEquation (7) gives the distance metric for two graph representations of a given batch data X i . d() means a distance computation method, and |X i | denotes the size of batch data. Basically, all edges of two feature graph representations are compared.\nd X i \ufffd d gm X i , gp X i \ufffd 1 X i x i j ,x i k \u2208X i d e fg x i j , fg x i k , \u00b7 e(fp) x i j , fp x i k .(7)\n\nLocal Alignment.\n\nFor model personalization with local private data, a local alignment module is also designed, which aims to increase the classification performance for local private data. As shown in Figure 4, for a sample training batch data (X i , Y i ) in a private dataset, its local feature f p (X i ) is extracted through models M C . en, the batch training data are used as the basic group for local alignment operation. Using metric learning method, we try to decrease distance between features from the same class; otherwise, the distance is increased. A training sample is randomly selected from f p (X i ), which is denoted as f p (x a i ). It is called anchor sample. en, another two samples are selected. One sample has the same label with anchor, and the other sample has different label. ese three samples constitute a triplet\n(f p (x a i ), f p (x p i ), f p (x n i )), where f p (x p i )\ndenotes the positive sample and f p (x n i ) denotes the negative sample. rough training, it is expected to decrease the distance between f p (x a i ) and f p (x p i ) and increase the distance between f p (x a i ) and f p (x n i ). e constraint is shown in the following equation:\nf p x a i \u2212 f p x p i 2 2 + \u03b1\u2329 f p x a i \u2212 f p x n i 2 2 , \u2200 f p x a i , f p x p i , f p x n i \u2208 \u0393,(8)\nwhere \u03b1 is the threshold for minimal distance and \u0393 is the triplet set.\n\n\nTraining Objective Function.\n\ne final loss function of our proposed model contains three parts, global alignment loss L a , local alignment loss L t , and cross-entropy loss L c , respectively.\n\nGlobal alignment loss L a is given in equation (9), which is inherited from equation (7). M means the number of batch data in all training dataset and i indicates the index of batch data.\nL a \ufffd M i\ufffd1 d X i .(9)\nLocal alignment loss L t is given in equation (10), which is on the basis of equation (8). \"+\" means that function value is 0 when content in [ ] is smaller than 0; otherwise, it is the normal loss function value. \u0393 i is the triplet set for ith batch data.\nL t \ufffd M i\ufffd1 \u2200 f p x a i ( ),fp x p i ( ),fp x n i ( ) \u2208 \u0393 i f p x a i \u2212 f p x p i 2 2 \u2212 f p x a i \u2212 f p x n i 2 2 + a + .(10)\nCross-entropy loss L c is given in equation (11). CE() is the standard cross-entropy function. M and i are the same as equation (8). Y(X i ) is the ground truth label of batch data X i , and Y \u2032 (X i ) is the output value of the local model.\nL c \ufffd M i\ufffd1 CE Y X i , Y \u2032 X i .(11)\ne final loss function L is a combination of L a , L t , and L c , as shown in equation (12). w a , w t , and w c are weighted hyperparameters. L is used to update the parameter of M C and M f modules in the local personalized model:\nL \ufffd w a * L a + w t * L t + w c * L c .(12)\n\nExperimental Evaluation\n\nIn this section, dataset description and experiment setting are first given. en, the performance of the proposed method for personalized ECG classification is evaluated in terms of various environments.\n\n\nDataset and Experiment Setting.\n\nAs there are no research studies on personalized federated learning for ECG classification, we construct a specific circumstance to evaluate the proposed algorithm. We collect about 120,000 ECG data from 8 hospitals. Table 1 gives the detail description of dataset. Six symptoms such as sinus rhythm, sinus arrhythmia, sinus tachycardia, sinus bradycardia, T-wave Security and Communication Networks alternans, and normal are selected, which are the commonest types and data rich. ere are 20201, 18581, 13682, 15854, 14211, and 38524 for types of sinus rhythm, sinus arrhythmia, sinus tachycardia, sinus bradycardia, T-wave alternans, and normal, respectively. Data distributions of each medical institution are also listed in Table 2.\n\nIn our research, each medical institution is corresponded to a local node, and these local nodes provide private data for global training. Hence, the federated learning circumstance is set up.\n\n\nBase Model Training.\n\ne server (global model) employs the FedAvg to train the model globally whereas each local client updates its model locally after successive global aggregations using the SGD style algorithm. e CNN model with ResNet-34 is used as the base network structure for both global model and local model.\n\nEach experiment is run for 100 global aggregations, with e \ufffd 4 epochs for SGD between successive global aggregations. e constant learning rate of 0.01 is used across global aggregations and clients. Table 3 gives the classification result of each local node after federated learning. Average classification rate is used as the metric in our work. ere are two node types, local and global.\n\ne global model has a classification rate of 82.6%. For local nodes, there are two evaluations. Local nodes 1 to 8 obtain the classification rate of 89.48%, 88.76%, 90.25%, 91.54%, 88.31%, 89.57%, 90.18%, and 90.54%, respectively, on their corresponding local private data set. Meanwhile, local nodes 1 to 8 obtain the classification rate of 54.65%, 57.18%, 49.75%, 51.43%, 48.92%, 46.35%, 52.45%, and 50.20%, respectively, on global testing data set. It can be obviously seen that the performance of local models is better than that of global model on private data. Local models get low performance on global data data, with about 30% lower than the global model. ese\n\nindicate that local models are more preferable to local data, while the global model trained with traditional federated learning framework needs further improvement. erefore, it is urgent requirement to make model personalization.\n\n\nModel Personalization Evaluation.\n\nIn this subsection, the proposed personalization model-based feature alignment is evaluated. e global model M G \u2032 obtained in the above subsection is first downloaded to each local node, and then the personalized model for each local node is trained on the basis of local data set D p and M G \u2032 . Complying with Section 2, w a , w t , and w c are set with 0.3, 0.3, and 0.4, respectively. Batch size is set with 16, and learning rate is 0.001. Table 4 gives the result of model personalization. Column 1 is the node index. Column 2 and 3 are average performance on local data with models of training with only local data and training with personalization. Column 4 and 5 are average performance on global data with models of training with only local data and training with personalization. It can be seen that the performance of model with personalization is decreased with about 3%. is demonstrates that the personalization model is less deviated to distribution of local data. For global testing data, the performance of the model with personalization is greatly increased with about 15-18%. It is a good validation that the personalization model is more generalized.\n\n\nComparisons with Other Methods.\n\nIn this subsection, some related model personalization methods are compared with our proposed model. We implement algorithms of [31,34,35], and the average classification rate on local and global testing data is evaluated. Table 5 demonstrates the comparison result. Methods in [33][34][35] get an average performance of 84.41%, 82.70%, and 83.55% on local node testing data and 79.80%, 78.68%, and 76.45% on global testing data. ere are about 4% and 6% compared with our proposed method, and this validates the effectiveness of the proposed personalization framework and feature alignment module.\n\n\nEffect of Global Alignment and Local Alignment.\n\nIn this subsection, effect of global alignment and local alignment is evaluated. Global alignment and local alignment are two  novel operations proposed in our work, which aims to catch the generalization ability of the global model and extract the discrimination ability of local private data. Here, the effect of global alignment and local alignment by assigning them different weights is evaluated. Table 6 demonstrates the comparison result. Five parameter settings for w a , w t , and w c are adopted. It can be seen from the   Sinus rhythm  2924  1940  2308  1483  3610  3103  3645  1188  Sinus arrhythmia  2451  1720  1893  1264  3171  2728  3513  1841  Sinus tachycardia  1913  1283  1407  1308  2262  2178  2619  712  Sinus bradycardia  2046  1523  1660  1418  2898  2665  2857  787  T-wave alternans  1850  1295  1477  1227  2418  2260  2767  917  Normal  5533  3866  3920  3653  6652  6196 7473 1231   \nM C f p (X i ) f p (x i a ) f p (x i p ) f p (x i n ) f p (x i\n\nConclusions\n\nis work proposes a novel personalized federated learning method for ECG classification. We explore feature alignment for personalization strategies on both global and local sides.\n\nrough experiments on our collected dataset, it shows that personalization benefits the local model with high performance and more generalization. To our knowledge, this is the first evaluation of personalization federated learning for ECG data analysis.\n\nOur future works will focus on two aspects: (1) we will make more in-depth research on the personalization method with specific structure and (2) external dataset should be used to improve model performance, such as webly grabbed data [40].\n\n\nData Availability\n\nDataset used in this research is private.\n\n\nConflicts of Interest\n\ne authors declare that there are no conflicts of interest.  \n\n\nM L contains 3 main components, M L \ufffd M G , M C , M f . M G is inherited by the global trained model M G \u2032 , which serves as the backbone and is fixed during local model training. M C and M f are used for local feature representation and final classifier of the local model.\n\nFigure 1 :Figure 2 :\n12Main framework of the proposed method. Global model training with federated learning.\n\nFigure 3 :\n3Demonstration of the global alignment module.\n\nFigure 4 :\n4Demonstration of the local alignment module.\n\nTable 1 :\n1Dataset used in our experiment.No. \nType \nQuantity \n1 \nSinus rhythm \n20201 \n2 \nSinus arrhythmia \n18581 \n3 \nSinus tachycardia \n13682 \n4 \nSinus bradycardia \n15854 \n5 \nT-wave alternans \n14211 \n6 \nSinus normal \n38524 \n\nBatch data \n\nCNN \n\nMetric \nlearning \n\nLocal dataset \n\nBatch feature \ngeneration \n(X i , Y i ) \n\n\n\n\ntable that with the raise of w a , value avg. (local) increases; meanwhile, the value of avg. (global) decreases. ere are similar appearances for w t . w a and w t are two parameters to trade off the performance balance between global data and local data. Parameter setting with 0.3, 0.3, and 0.4 obtains the optimal performance. 4.6. Evaluation of Execution Time. In this subsection, personalized model execution time is evaluated. ree CNNs structures with various training batch sizes are tested. Table 7 shows that the VGG16 model costs the most execution time, with 1.26 s, 1.67 s, 2.31 s, and 3.74 s for the batch size of 8, 12, 16, and 24 for each training iteration. ResNet-34 gets the least execution time, with about 58% of VGG16's. For model inference, three models take 0.120 s,\n\nTable 2 :\n2Data distributions of each medical institution.Type \nNode1 \nNode2 \nNode3 \nNode4 \nNode5 \nNode6 \nNode7 \nNode8 \n\n\nTable 3 :\n3Performance of each local node after federated learning.Node type \nNo. \nClassification rate (local) \nClassification rate (global) \nLocal \n1 \n89.48 \n54.65 \nLocal \n2 \n88.76 \n57.18 \nLocal \n3 \n90.25 \n49.75 \nLocal \n4 \n91.54 \n51.43 \nLocal \n5 \n88.31 \n48.92 \nLocal \n6 \n89.57 \n46.35 \nLocal \n7 \n90.18 \n52.45 \nLocal \n8 \n90.54 \n50.20 \nGlobal \n82.6 \n\n\n\nTable 4 :\n4Performance of each local node after federated learning.Node \nAvg. (local) \nAvg. (local with personalization) \nAvg. (global) \nAvg. (global with personalization) \n1 \n89.48 \n86.25 \n54.65 \n84.42 \n2 \n88.76 \n87.18 \n57.18 \n83.25 \n3 \n90.25 \n87.50 \n49.75 \n84.58 \n4 \n91.54 \n88.42 \n51.43 \n83.60 \n5 \n88.31 \n85.85 \n48.92 \n82.46 \n6 \n89.57 \n85.34 \n46.35 \n83.15 \n7 \n90.18 \n87.68 \n52.45 \n84.56 \n8 \n90.54 \n88.15 \n50.20 \n84.10 \n\n\n\nTable 5 :\n5Comparisons with other methods. 076 s, and 0.063 s for testing data, respectively. ResNet-34 is the preferred model for its excellent performance and acceptable cost.Algorithm \n\n\nTable 6 :\n6Effect of global alignment and local alignment.w a \nw t \nw c \nAvg. (local) \nAvg. (global) \n\n0.5 \n0.1 \n0.4 \n90.5 \n60.28 \n0.4 \n0.2 \n0.4 \n85.8 \n80.7 \n0.3 \n0.3 \n0.4 \n87.85 \n83.92 \n0.2 \n0.4 \n0.4 \n86.0 \n81.1 \n0.1 \n0.5 \n0.4 \n80.3 \n83.2 \n\n\n\nTable 7 :\n7Execution time (seconds).Execution time \nBatch size \nVGG16 \nInception-v4 \nResNet-34 \n\nTraining time \n\n8 \n1.26 \n1.03 \n0.97 \n12 \n1.67 \n1.29 \n1.18 \n16 \n2.31 \n1.85 \n1.72 \n24 \n3.74 \n2.26 \n2.15 \nTesting time \nx \n0.12 \n0.076 \n0.063 \n\n8 \nSecurity and Communication Networks \n\n\nWorld Health Statistics 2020, Monitoring Health for the SDGs, Sustainable Development Goals, World health organization. Geneva SwitzerlandWorld Health Statistics 2020, Monitoring Health for the SDGs, Sustainable Development Goals, World health organization, Geneva Switzerland, 2020.\n\nA survey on ECG analysis. S K Berkaya, A K Uysal, E S Gunal, S Ergin, S Gunal, M B Gulmezoglu, Biomedical Signal Processing and Control. 43S. K. Berkaya, A. K. Uysal, E. S. Gunal, S. Ergin, S. Gunal, and M. B. Gulmezoglu, \"A survey on ECG analysis,\" Biomedical Signal Processing and Control, vol. 43, pp. 216-235, 2018.\n\nCardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network. A Y Hannun, P Rajpurkar, M Haghpanahi, Nature Medicine. 251A. Y. Hannun, P. Rajpurkar, M. Haghpanahi et al., \"Cardi- ologist-level arrhythmia detection and classification in am- bulatory electrocardiograms using a deep neural network,\" Nature Medicine, vol. 25, no. 1, pp. 65-69, 2019.\n\nFederated Optimization: Distributed Machine Learning for On-Device intelligence. J Konecn\u00fd, H B Mcmahan, D Ramage, P Richt\u00e1rik, J. Konecn\u00fd, H. B. McMahan, D. Ramage, and P. Richt\u00e1rik, \"Federated Optimization: Distributed Machine Learning for On-Device intelligence,\" 2016, http://arxiv.org/abs/1610. 02527.\n\nFederated machine learning. Q Yang, Y Liu, T Chen, Y Tong, ACM Transactions on Intelligent Systems and Technology. 102Q. Yang, Y. Liu, T. Chen, and Y. Tong, \"Federated machine learning,\" ACM Transactions on Intelligent Systems and Technology, vol. 10, no. 2, pp. 1-19, 2019.\n\nFederated learning of predictive models from federated Electronic Health Records. T S Brisimi, R Chen, T Mela, A Olshevsky, I C Paschalidis, W Shi, International Journal of Medical Informatics. 112T. S. Brisimi, R. Chen, T. Mela, A. Olshevsky, I. C. Paschalidis, and W. Shi, \"Federated learning of predictive models from federated Electronic Health Records,\" International Journal of Medical Informatics, vol. 112, pp. 59-67, 2018.\n\nPredicting adverse drug reactions on distributed health data using federated learning. O Choudhury, Y Park, T Salonidis, A Divanis, A Sylla, Das, Proceedings of the AMIA . Annual Symposium proceedings. the AMIA . Annual Symposium proceedingsWashington, D.C., USAO. Choudhury, Y. Park, T. Salonidis, A. G Divanis, I Sylla, and A. K Das, \"Predicting adverse drug reactions on distributed health data using federated learning,\" in Proceedings of the AMIA . Annual Symposium proceedings, pp. 313-322, Washington, D.C., USA, November 2019.\n\nSurvey of Personalization Techniques for Federated Learning. V Kulkarni, M Kulkarni, A Pant, V. Kulkarni, M. Kulkarni, and A. Pant, \"Survey of Person- alization Techniques for Federated Learning,\" 2020, https:// arxiv.org/abs/2003.08673.\n\nA Bayesian classification of heart rate variability data. R J Muirhead, R D Puff, Physica A: Statistical and eoretical Physics. 3363R. J. Muirhead and R. D. Puff, \"A Bayesian classification of heart rate variability data,\" Physica A: Statistical and eo- retical Physics, vol. 336, no. 3, pp. 503-513, 2004.\n\nPremature ventricular contraction classification by theKth nearest-neighbours rule. I Christov, I Jekova, G Bortolan, Physiological Measurement. 261I. Christov, I. Jekova, and G. Bortolan, \"Premature ventricular contraction classification by theKth nearest-neighbours rule,\" Physiological Measurement, vol. 26, no. 1, pp. 123-130, 2005.\n\nAn interpretable classifier for detection of cardiac arrhythmias by using the fuzzy decision tree. O Behadada, M Chikh, Artificial Intelligence Research. 23O. Behadada and M. Chikh, \"An interpretable classifier for detection of cardiac arrhythmias by using the fuzzy decision tree,\" Artificial Intelligence Research, vol. 2, no. 3, pp. 45-58, 2013.\n\nEnhancing Learning Efficiency of Brain Storm Optimization via Orthogonal Learning Design. L Ma, S Cheng, Y Shi, IEEE Transactions on Systems, Man, and Cybernetics: Systems. 5111L. Ma, S. Cheng, and Y. Shi, \"Enhancing Learning Efficiency of Brain Storm Optimization via Orthogonal Learning Design,\" IEEE Transactions on Systems, Man, and Cybernetics: Systems, vol. 51, no. 11, 2020.\n\nAn adaptive localized decision variable analysis approach to large-scale multi-objective and many-objective optimization. L Ma, M Huang, S Yang, R Wang, X Wang, IEEE Transactions on Cybernetics. L. Ma, M. Huang, S. Yang, R. Wang, and X. Wang, \"An adaptive localized decision variable analysis approach to large-scale multi-objective and many-objective optimization,\" IEEE Transactions on Cybernetics, 2021.\n\nECG beat recognition using fuzzy hybrid neural network. S Osowski, T H H L Tran, IEEE Transactions on Biomedical Engineering. 4811S. Osowski and T. H. H. L. Tran, \"ECG beat recognition using fuzzy hybrid neural network,\" IEEE Transactions on Bio- medical Engineering, vol. 48, no. 11, pp. 1265-1271, 2001.\n\nECG beat classifier designed by combined neural network model. I Guler, E Ubeyli, Pattern Recognition. 382I. Guler and E. Ubeyli, \"ECG beat classifier designed by combined neural network model,\" Pattern Recognition, vol. 38, no. 2, pp. 199-208, 2005.\n\nECG beats classification using multiclass support vector machines with error correcting output codes. E D \u00dcbeyli, Digital Signal Processing. 173E. D.\u00dcbeyli, \"ECG beats classification using multiclass support vector machines with error correcting output codes,\" Digital Signal Processing, vol. 17, no. 3, pp. 675-684, 2007.\n\nA stacked contractive denoising auto-encoder for ECG signal denoising. P Xiong, H Wang, M Liu, F Lin, Z Hou, X Liu, Physiological Measurement. 3712P. Xiong, H. Wang, M. Liu, F. Lin, Z. Hou, and X. Liu, \"A stacked contractive denoising auto-encoder for ECG signal denoising,\" Physiological Measurement, vol. 37, no. 12, pp. 2214-2230, 2016.\n\nDeep learning approach for active classification of electrocardiogram signals. M M A Rahhal, Y Bazi, H Alhichri, N Alajlan, F Melgani, R R Yager, Information Sciences. 345M. M. A. Rahhal, Y. Bazi, H. AlHichri, N. Alajlan, F. Melgani, and R. R. Yager, \"Deep learning approach for active classi- fication of electrocardiogram signals,\" Information Sciences, vol. 345, pp. 340-354, 2016.\n\nA novel method for classification of ECG arrhythmias using deep belief networks. Z Y Wu, X Q Ding, G R Zhang, ID 1650021International Journal of Computational Intelligence and Applications. 154Z. Y. Wu, X. Q. Ding, and G. R. Zhang, \"A novel method for classification of ECG arrhythmias using deep belief net- works,\" International Journal of Computational Intelligence and Applications, vol. 15, no. 4, Article ID 1650021, 2016.\n\nA deep convolutional neural network model to classify heartbeats. U R Acharya, S L Oh, Y Hagiwara, Computers in Biology and Medicine. 89U. R. Acharya, S. L. Oh, Y. Hagiwara et al., \"A deep con- volutional neural network model to classify heartbeats,\" Computers in Biology and Medicine, vol. 89, pp. 389-396, 2017.\n\nECG signal denoising based on deep factor analysis. G Wang, L Yang, M Liu, Biomedical Signal Processing and Control. 57G. Wang, L. Yang, M. Liu et al., \"ECG signal denoising based on deep factor analysis,\" Biomedical Signal Processing and Control, vol. 57, 2020.\n\nRobust ECG biometrics using GNMF and sparse representation. R Li, G Yang, K Wang, Y Huang, F Yuan, Y Yin, Pattern Recognition Letters. 129R. Li, G. Yang, K. Wang, Y. Huang, F. Yuan, and Y. Yin, \"Robust ECG biometrics using GNMF and sparse represen- tation,\" Pattern Recognition Letters, vol. 129, pp. 70-76, 2020.\n\nDeep timefrequency representation and progressive decision fusion for ECG classification. J Zhang, J Tian, Y Cao, Y Yang, X Xu, Ar- ticle ID 105402Knowledge-Based Systems. 190J. Zhang, J. Tian, Y. Cao, Y. Yang, and X. Xu, \"Deep time- frequency representation and progressive decision fusion for ECG classification,\" Knowledge-Based Systems, vol. 190, Ar- ticle ID 105402, 2020.\n\nPrivacy-preserving deep learning. R Shokri, V Shmatikov, Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security. the 22nd ACM SIGSAC Conference on Computer and Communications SecurityNew York, NYACMR. Shokri and V. Shmatikov, \"Privacy-preserving deep learning,\" in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1310-1321, ACM, New York, NY, October 2015.\n\nFederated multi-task learning. V Smith, C K Chiang, M Sanjabi, S T Ameet, Proceedings of the Annual Conference on Neural Information Processing Systems. the Annual Conference on Neural Information Processing SystemsLong Beach, CA, USAV. Smith, C. K. Chiang, M. Sanjabi, and S. T. Ameet, \"Fed- erated multi-task learning,\" in Proceedings of the Annual Conference on Neural Information Processing Systems, pp. 4424-4434, Long Beach, CA, USA, December 2017.\n\nFederated Learning of Deep Networks Using Model averaging. H B Mcmahan, E Moore, D Ramage, Y A B Ag\u00fcera, H. B. McMahan, E. Moore, D. Ramage, and Y. A. B. Ag\u00fcera, \"Federated Learning of Deep Networks Using Model aver- aging,\" 2016, http://arxiv.org/abs/1602.05629.\n\nPrivacypreserving deep learning via additively homomorphic encryption. Y Aono, T Hayashi, L Wang, S Moriai, IEEE Transactions on Information Forensics and Security. 135Y. Aono, T. Hayashi, L. Wang, and S. Moriai, \"Privacy- preserving deep learning via additively homomorphic en- cryption,\" IEEE Transactions on Information Forensics and Security, vol. 13, no. 5, pp. 1333-1345, 2018.\n\nDifferentially Private Federated Learning: A Client Level perspective. R C Geyer, T Klein, M Nabi, R. C. Geyer, T. Klein, and M. Nabi, \"Differentially Private Federated Learning: A Client Level perspective,\" 2017, http:// arxiv.org/abs/1712.07557.\n\nTernary compression for communication-efficient federated learning. J Xu, W Du, Y Jin, W He, R Cheng, IEEE Transactions on Neural Networks and Learning Systems. J. Xu, W. Du, Y. Jin, W. He, and R. Cheng, \"Ternary com- pression for communication-efficient federated learning,\" IEEE Transactions on Neural Networks and Learning Systems, pp. 1-15, 2021.\n\nFederated self-supervised learning of multisensor representations for embedded intelligence. F D Saeed, T Salim, J Ozcelebi, Lukkien, IEEE Internet of ings Journal. 82A Saeed, F. D. Salim, T. Ozcelebi, and J. Lukkien, \"Federated self-supervised learning of multisensor representations for embedded intelligence,\" IEEE Internet of ings Journal, vol. 8, no. 2, pp. 1030-1040, 2021.\n\nSalvaging Federated Learning by Local Adaptation. T Yu, E Bagdasaryan, V Shmatikov, T. Yu, E. Bagdasaryan, and V. Shmatikov, \"Salvaging Fed- erated Learning by Local Adaptation,\" 2020, https://arxiv.org/ abs/2002.04758.\n\nree Approaches for Personalization with Applications to Federated Learning. Y Mansour, M Mohri, J Ro, A T Suresh, Y. Mansour, M. Mohri, J. Ro, and A. T. Suresh, \" ree Approaches for Personalization with Applications to Feder- ated Learning,\" 2020, https://arxiv.org/abs/2002.10619.\n\nFederated Evaluation of On-Device Personalization. K Wang, R Mathews, C Kiddon, H Eichner, F Beaufays, D Ramage, K. Wang, R. Mathews, C. Kiddon, H. Eichner, F. Beaufays, and D. Ramage, \"Federated Evaluation of On-Device Per- sonalization,\" 2019.\n\nImproving Federated Learning Personalization via Model Agnostic Meta Learning. Y Jiang, J Konecny, K Rush, S Kannan, arXiv:1909.12488arXiv preprintY. Jiang, J. Konecny, K. Rush, and S. Kannan, \"Improving Federated Learning Personalization via Model Agnostic Meta Learning,\" arXiv preprint arXiv:1909.12488, 2019, https:// arxiv.org/abs/1909.12488.\n\nFederated Learning of a Mixture of Global and Local Models. F Hanzely, P Richtarik, F. Hanzely and P. Richtarik, \"Federated Learning of a Mixture of Global and Local Models,\" 2020, https://arxiv.org/abs/2002. 05516.\n\nPFL-MoE: personalized federated learning based on mixture of experts. B Guo, Y Mei, D Xiao, W Wu, Web and Big Data. 1B. Guo, Y. Mei, D. Xiao, and W. Wu, \"PFL-MoE: personalized federated learning based on mixture of experts,\" Web and Big Data, vol. 1, pp. 480-486, 2021.\n\nAdaptive Personalized Federated Learning. Y Deng, M M Kamani, M Mahdavi, Y. Deng, M. M. Kamani, and M. Mahdavi, \"Adaptive Per- sonalized Federated Learning,\" 2020, https://arxiv.org/abs/ 2003.13461.\n\nPersonalized Cross-Silo Federated Learning On Non-Iid Data. Y Huang, L Chu, Z Zhou, 2021AAAI, CA, USAY. Huang, L. Chu, Z. Zhou et al., Personalized Cross-Silo Federated Learning On Non-Iid Data, pp. 7865-7873, AAAI, CA, USA, 2021.\n\nCommunication-efficient learning of deep networks from decentralized data. B Mcmahan, E Moore, D Ramage, S Hampson, Y B A Blaise, Proceedings of the 20th International Conference on Artificial Intelligence and Statistics. the 20th International Conference on Artificial Intelligence and StatisticsFt. Lauderdale, FL, USAB. McMahan, E. Moore, D. Ramage, S. Hampson, and Y. B. A. Blaise, \"Communication-efficient learning of deep networks from decentralized data,\" in Proceedings of the 20th International Conference on Artificial Intelligence and Sta- tistics, pp. 1273-1282, Ft. Lauderdale, FL, USA, April 2017.\n\nOn Localized Discrepancy for Domain Adaptation. Y Zhang, M Long, J Wang, I J Michael, Y. Zhang, M. Long, J. Wang, and I. J. Michael, \"On Localized Discrepancy for Domain Adaptation,\" 2020, https://arxiv.org/ abs/2008.06242.\n", "annotations": {"author": "[{\"end\":315,\"start\":110},{\"end\":428,\"start\":316},{\"end\":515,\"start\":429},{\"end\":627,\"start\":516}]", "publisher": null, "author_last_name": "[{\"end\":121,\"start\":117},{\"end\":327,\"start\":324},{\"end\":439,\"start\":435},{\"end\":526,\"start\":523}]", "author_first_name": "[{\"end\":116,\"start\":110},{\"end\":323,\"start\":316},{\"end\":434,\"start\":429},{\"end\":522,\"start\":516}]", "author_affiliation": "[{\"end\":239,\"start\":141},{\"end\":314,\"start\":241},{\"end\":427,\"start\":329},{\"end\":514,\"start\":441},{\"end\":626,\"start\":528}]", "title": "[{\"end\":82,\"start\":1},{\"end\":709,\"start\":628}]", "venue": null, "abstract": "[{\"end\":2166,\"start\":924}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2390,\"start\":2387},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2645,\"start\":2642},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3088,\"start\":3085},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3617,\"start\":3614},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3847,\"start\":3844},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3952,\"start\":3949},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3954,\"start\":3952},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4503,\"start\":4500},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7458,\"start\":7455},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7462,\"start\":7458},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7466,\"start\":7462},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7521,\"start\":7517},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7524,\"start\":7521},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7607,\"start\":7603},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7730,\"start\":7726},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7746,\"start\":7742},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7903,\"start\":7899},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7980,\"start\":7976},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8012,\"start\":8008},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8159,\"start\":8155},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8208,\"start\":8204},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8467,\"start\":8463},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8668,\"start\":8664},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8951,\"start\":8948},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8970,\"start\":8966},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9158,\"start\":9154},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9253,\"start\":9249},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9469,\"start\":9465},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9556,\"start\":9552},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9712,\"start\":9708},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9907,\"start\":9903},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10516,\"start\":10512},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10766,\"start\":10762},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10867,\"start\":10863},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11041,\"start\":11037},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":11125,\"start\":11121},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11261,\"start\":11257},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11469,\"start\":11465},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11485,\"start\":11481},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":13180,\"start\":13176},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14679,\"start\":14676},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17433,\"start\":17430},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":19860,\"start\":19857},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20202,\"start\":20198},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20285,\"start\":20282},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":20524,\"start\":20520},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24888,\"start\":24884},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24891,\"start\":24888},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":24894,\"start\":24891},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25038,\"start\":25034},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25042,\"start\":25038},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":25046,\"start\":25042},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":27071,\"start\":27067}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":27498,\"start\":27222},{\"attributes\":{\"id\":\"fig_1\"},\"end\":27608,\"start\":27499},{\"attributes\":{\"id\":\"fig_2\"},\"end\":27667,\"start\":27609},{\"attributes\":{\"id\":\"fig_3\"},\"end\":27725,\"start\":27668},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":28049,\"start\":27726},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":28841,\"start\":28050},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":28963,\"start\":28842},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":29314,\"start\":28964},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":29738,\"start\":29315},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":29928,\"start\":29739},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":30172,\"start\":29929},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":30452,\"start\":30173}]", "paragraph": "[{\"end\":2906,\"start\":2182},{\"end\":3366,\"start\":2908},{\"end\":3848,\"start\":3368},{\"end\":3955,\"start\":3850},{\"end\":4504,\"start\":3957},{\"end\":5104,\"start\":4506},{\"end\":6522,\"start\":5106},{\"end\":7082,\"start\":6524},{\"end\":7260,\"start\":7100},{\"end\":7801,\"start\":7291},{\"end\":8093,\"start\":7803},{\"end\":8732,\"start\":8095},{\"end\":10054,\"start\":8746},{\"end\":11598,\"start\":10087},{\"end\":12907,\"start\":11614},{\"end\":13815,\"start\":12934},{\"end\":14205,\"start\":13885},{\"end\":14451,\"start\":14207},{\"end\":14864,\"start\":14529},{\"end\":15617,\"start\":14890},{\"end\":16846,\"start\":15677},{\"end\":17525,\"start\":16848},{\"end\":17889,\"start\":17637},{\"end\":18842,\"start\":18017},{\"end\":19187,\"start\":18906},{\"end\":19362,\"start\":19291},{\"end\":19558,\"start\":19395},{\"end\":19747,\"start\":19560},{\"end\":20027,\"start\":19771},{\"end\":20395,\"start\":20154},{\"end\":20665,\"start\":20433},{\"end\":20938,\"start\":20736},{\"end\":21709,\"start\":20974},{\"end\":21903,\"start\":21711},{\"end\":22222,\"start\":21928},{\"end\":22612,\"start\":22224},{\"end\":23281,\"start\":22614},{\"end\":23513,\"start\":23283},{\"end\":24720,\"start\":23551},{\"end\":25353,\"start\":24756},{\"end\":26318,\"start\":25405},{\"end\":26575,\"start\":26396},{\"end\":26830,\"start\":26577},{\"end\":27072,\"start\":26832},{\"end\":27135,\"start\":27094},{\"end\":27221,\"start\":27161}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13863,\"start\":13816},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13884,\"start\":13863},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14497,\"start\":14452},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14528,\"start\":14497},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17581,\"start\":17526},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17636,\"start\":17581},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17997,\"start\":17890},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18905,\"start\":18843},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19290,\"start\":19188},{\"attributes\":{\"id\":\"formula_9\"},\"end\":19770,\"start\":19748},{\"attributes\":{\"id\":\"formula_10\"},\"end\":20153,\"start\":20028},{\"attributes\":{\"id\":\"formula_11\"},\"end\":20432,\"start\":20396},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20709,\"start\":20666},{\"attributes\":{\"id\":\"formula_13\"},\"end\":26381,\"start\":26319}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21198,\"start\":21191},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":21708,\"start\":21701},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":22430,\"start\":22423},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":24002,\"start\":23995},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":24986,\"start\":24979},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":25814,\"start\":25807},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":26305,\"start\":25938}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2180,\"start\":2168},{\"attributes\":{\"n\":\"2.\"},\"end\":7098,\"start\":7085},{\"attributes\":{\"n\":\"2.1.\"},\"end\":7289,\"start\":7263},{\"attributes\":{\"n\":\"2.2.\"},\"end\":8744,\"start\":8735},{\"attributes\":{\"n\":\"2.3.\"},\"end\":10085,\"start\":10057},{\"attributes\":{\"n\":\"3.\"},\"end\":11612,\"start\":11601},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12932,\"start\":12910},{\"attributes\":{\"n\":\"3.2.\"},\"end\":14888,\"start\":14867},{\"end\":15655,\"start\":15620},{\"attributes\":{\"n\":\"3.2.1.\"},\"end\":15675,\"start\":15658},{\"attributes\":{\"n\":\"3.2.2.\"},\"end\":18015,\"start\":17999},{\"attributes\":{\"n\":\"3.3.\"},\"end\":19393,\"start\":19365},{\"attributes\":{\"n\":\"4.\"},\"end\":20734,\"start\":20711},{\"attributes\":{\"n\":\"4.1.\"},\"end\":20972,\"start\":20941},{\"attributes\":{\"n\":\"4.2.\"},\"end\":21926,\"start\":21906},{\"attributes\":{\"n\":\"4.3.\"},\"end\":23549,\"start\":23516},{\"attributes\":{\"n\":\"4.4.\"},\"end\":24754,\"start\":24723},{\"attributes\":{\"n\":\"4.5.\"},\"end\":25403,\"start\":25356},{\"attributes\":{\"n\":\"5.\"},\"end\":26394,\"start\":26383},{\"end\":27092,\"start\":27075},{\"end\":27159,\"start\":27138},{\"end\":27520,\"start\":27500},{\"end\":27620,\"start\":27610},{\"end\":27679,\"start\":27669},{\"end\":27736,\"start\":27727},{\"end\":28852,\"start\":28843},{\"end\":28974,\"start\":28965},{\"end\":29325,\"start\":29316},{\"end\":29749,\"start\":29740},{\"end\":29939,\"start\":29930},{\"end\":30183,\"start\":30174}]", "table": "[{\"end\":28049,\"start\":27769},{\"end\":28963,\"start\":28901},{\"end\":29314,\"start\":29032},{\"end\":29738,\"start\":29383},{\"end\":29928,\"start\":29917},{\"end\":30172,\"start\":29988},{\"end\":30452,\"start\":30210}]", "figure_caption": "[{\"end\":27498,\"start\":27224},{\"end\":27608,\"start\":27523},{\"end\":27667,\"start\":27622},{\"end\":27725,\"start\":27681},{\"end\":27769,\"start\":27738},{\"end\":28841,\"start\":28052},{\"end\":28901,\"start\":28854},{\"end\":29032,\"start\":28976},{\"end\":29383,\"start\":29327},{\"end\":29917,\"start\":29751},{\"end\":29988,\"start\":29941},{\"end\":30210,\"start\":30185}]", "figure_ref": "[{\"end\":11748,\"start\":11740},{\"end\":13248,\"start\":13240},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16087,\"start\":16079},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17345,\"start\":17337},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18209,\"start\":18201}]", "bib_author_first_name": "[{\"end\":30766,\"start\":30765},{\"end\":30768,\"start\":30767},{\"end\":30779,\"start\":30778},{\"end\":30781,\"start\":30780},{\"end\":30790,\"start\":30789},{\"end\":30792,\"start\":30791},{\"end\":30801,\"start\":30800},{\"end\":30810,\"start\":30809},{\"end\":30819,\"start\":30818},{\"end\":30821,\"start\":30820},{\"end\":31182,\"start\":31181},{\"end\":31184,\"start\":31183},{\"end\":31194,\"start\":31193},{\"end\":31207,\"start\":31206},{\"end\":31550,\"start\":31549},{\"end\":31561,\"start\":31560},{\"end\":31563,\"start\":31562},{\"end\":31574,\"start\":31573},{\"end\":31584,\"start\":31583},{\"end\":31805,\"start\":31804},{\"end\":31813,\"start\":31812},{\"end\":31820,\"start\":31819},{\"end\":31828,\"start\":31827},{\"end\":32135,\"start\":32134},{\"end\":32137,\"start\":32136},{\"end\":32148,\"start\":32147},{\"end\":32156,\"start\":32155},{\"end\":32164,\"start\":32163},{\"end\":32177,\"start\":32176},{\"end\":32179,\"start\":32178},{\"end\":32194,\"start\":32193},{\"end\":32573,\"start\":32572},{\"end\":32586,\"start\":32585},{\"end\":32594,\"start\":32593},{\"end\":32607,\"start\":32606},{\"end\":32618,\"start\":32617},{\"end\":33083,\"start\":33082},{\"end\":33095,\"start\":33094},{\"end\":33107,\"start\":33106},{\"end\":33319,\"start\":33318},{\"end\":33321,\"start\":33320},{\"end\":33333,\"start\":33332},{\"end\":33335,\"start\":33334},{\"end\":33653,\"start\":33652},{\"end\":33665,\"start\":33664},{\"end\":33675,\"start\":33674},{\"end\":34006,\"start\":34005},{\"end\":34018,\"start\":34017},{\"end\":34347,\"start\":34346},{\"end\":34353,\"start\":34352},{\"end\":34362,\"start\":34361},{\"end\":34762,\"start\":34761},{\"end\":34768,\"start\":34767},{\"end\":34777,\"start\":34776},{\"end\":34785,\"start\":34784},{\"end\":34793,\"start\":34792},{\"end\":35104,\"start\":35103},{\"end\":35115,\"start\":35114},{\"end\":35121,\"start\":35116},{\"end\":35418,\"start\":35417},{\"end\":35427,\"start\":35426},{\"end\":35709,\"start\":35708},{\"end\":35711,\"start\":35710},{\"end\":36002,\"start\":36001},{\"end\":36011,\"start\":36010},{\"end\":36019,\"start\":36018},{\"end\":36026,\"start\":36025},{\"end\":36033,\"start\":36032},{\"end\":36040,\"start\":36039},{\"end\":36351,\"start\":36350},{\"end\":36355,\"start\":36352},{\"end\":36365,\"start\":36364},{\"end\":36373,\"start\":36372},{\"end\":36385,\"start\":36384},{\"end\":36396,\"start\":36395},{\"end\":36407,\"start\":36406},{\"end\":36409,\"start\":36408},{\"end\":36739,\"start\":36738},{\"end\":36741,\"start\":36740},{\"end\":36747,\"start\":36746},{\"end\":36749,\"start\":36748},{\"end\":36757,\"start\":36756},{\"end\":36759,\"start\":36758},{\"end\":37154,\"start\":37153},{\"end\":37156,\"start\":37155},{\"end\":37167,\"start\":37166},{\"end\":37169,\"start\":37168},{\"end\":37175,\"start\":37174},{\"end\":37455,\"start\":37454},{\"end\":37463,\"start\":37462},{\"end\":37471,\"start\":37470},{\"end\":37727,\"start\":37726},{\"end\":37733,\"start\":37732},{\"end\":37741,\"start\":37740},{\"end\":37749,\"start\":37748},{\"end\":37758,\"start\":37757},{\"end\":37766,\"start\":37765},{\"end\":38072,\"start\":38071},{\"end\":38081,\"start\":38080},{\"end\":38089,\"start\":38088},{\"end\":38096,\"start\":38095},{\"end\":38104,\"start\":38103},{\"end\":38395,\"start\":38394},{\"end\":38405,\"start\":38404},{\"end\":38824,\"start\":38823},{\"end\":38833,\"start\":38832},{\"end\":38835,\"start\":38834},{\"end\":38845,\"start\":38844},{\"end\":38856,\"start\":38855},{\"end\":38858,\"start\":38857},{\"end\":39308,\"start\":39307},{\"end\":39310,\"start\":39309},{\"end\":39321,\"start\":39320},{\"end\":39330,\"start\":39329},{\"end\":39340,\"start\":39339},{\"end\":39344,\"start\":39341},{\"end\":39585,\"start\":39584},{\"end\":39593,\"start\":39592},{\"end\":39604,\"start\":39603},{\"end\":39612,\"start\":39611},{\"end\":39970,\"start\":39969},{\"end\":39972,\"start\":39971},{\"end\":39981,\"start\":39980},{\"end\":39990,\"start\":39989},{\"end\":40216,\"start\":40215},{\"end\":40222,\"start\":40221},{\"end\":40228,\"start\":40227},{\"end\":40235,\"start\":40234},{\"end\":40241,\"start\":40240},{\"end\":40593,\"start\":40592},{\"end\":40595,\"start\":40594},{\"end\":40604,\"start\":40603},{\"end\":40613,\"start\":40612},{\"end\":40931,\"start\":40930},{\"end\":40937,\"start\":40936},{\"end\":40952,\"start\":40951},{\"end\":41178,\"start\":41177},{\"end\":41189,\"start\":41188},{\"end\":41198,\"start\":41197},{\"end\":41204,\"start\":41203},{\"end\":41206,\"start\":41205},{\"end\":41436,\"start\":41435},{\"end\":41444,\"start\":41443},{\"end\":41455,\"start\":41454},{\"end\":41465,\"start\":41464},{\"end\":41476,\"start\":41475},{\"end\":41488,\"start\":41487},{\"end\":41711,\"start\":41710},{\"end\":41720,\"start\":41719},{\"end\":41731,\"start\":41730},{\"end\":41739,\"start\":41738},{\"end\":42041,\"start\":42040},{\"end\":42052,\"start\":42051},{\"end\":42268,\"start\":42267},{\"end\":42275,\"start\":42274},{\"end\":42282,\"start\":42281},{\"end\":42290,\"start\":42289},{\"end\":42511,\"start\":42510},{\"end\":42519,\"start\":42518},{\"end\":42521,\"start\":42520},{\"end\":42531,\"start\":42530},{\"end\":42729,\"start\":42728},{\"end\":42738,\"start\":42737},{\"end\":42745,\"start\":42744},{\"end\":42976,\"start\":42975},{\"end\":42987,\"start\":42986},{\"end\":42996,\"start\":42995},{\"end\":43006,\"start\":43005},{\"end\":43017,\"start\":43016},{\"end\":43021,\"start\":43018},{\"end\":43562,\"start\":43561},{\"end\":43571,\"start\":43570},{\"end\":43579,\"start\":43578},{\"end\":43587,\"start\":43586},{\"end\":43589,\"start\":43588}]", "bib_author_last_name": "[{\"end\":30776,\"start\":30769},{\"end\":30787,\"start\":30782},{\"end\":30798,\"start\":30793},{\"end\":30807,\"start\":30802},{\"end\":30816,\"start\":30811},{\"end\":30832,\"start\":30822},{\"end\":31191,\"start\":31185},{\"end\":31204,\"start\":31195},{\"end\":31218,\"start\":31208},{\"end\":31558,\"start\":31551},{\"end\":31571,\"start\":31564},{\"end\":31581,\"start\":31575},{\"end\":31594,\"start\":31585},{\"end\":31810,\"start\":31806},{\"end\":31817,\"start\":31814},{\"end\":31825,\"start\":31821},{\"end\":31833,\"start\":31829},{\"end\":32145,\"start\":32138},{\"end\":32153,\"start\":32149},{\"end\":32161,\"start\":32157},{\"end\":32174,\"start\":32165},{\"end\":32191,\"start\":32180},{\"end\":32198,\"start\":32195},{\"end\":32583,\"start\":32574},{\"end\":32591,\"start\":32587},{\"end\":32604,\"start\":32595},{\"end\":32615,\"start\":32608},{\"end\":32624,\"start\":32619},{\"end\":32629,\"start\":32626},{\"end\":33092,\"start\":33084},{\"end\":33104,\"start\":33096},{\"end\":33112,\"start\":33108},{\"end\":33330,\"start\":33322},{\"end\":33340,\"start\":33336},{\"end\":33662,\"start\":33654},{\"end\":33672,\"start\":33666},{\"end\":33684,\"start\":33676},{\"end\":34015,\"start\":34007},{\"end\":34024,\"start\":34019},{\"end\":34350,\"start\":34348},{\"end\":34359,\"start\":34354},{\"end\":34366,\"start\":34363},{\"end\":34765,\"start\":34763},{\"end\":34774,\"start\":34769},{\"end\":34782,\"start\":34778},{\"end\":34790,\"start\":34786},{\"end\":34798,\"start\":34794},{\"end\":35112,\"start\":35105},{\"end\":35126,\"start\":35122},{\"end\":35424,\"start\":35419},{\"end\":35434,\"start\":35428},{\"end\":35718,\"start\":35712},{\"end\":36008,\"start\":36003},{\"end\":36016,\"start\":36012},{\"end\":36023,\"start\":36020},{\"end\":36030,\"start\":36027},{\"end\":36037,\"start\":36034},{\"end\":36044,\"start\":36041},{\"end\":36362,\"start\":36356},{\"end\":36370,\"start\":36366},{\"end\":36382,\"start\":36374},{\"end\":36393,\"start\":36386},{\"end\":36404,\"start\":36397},{\"end\":36415,\"start\":36410},{\"end\":36744,\"start\":36742},{\"end\":36754,\"start\":36750},{\"end\":36765,\"start\":36760},{\"end\":37164,\"start\":37157},{\"end\":37172,\"start\":37170},{\"end\":37184,\"start\":37176},{\"end\":37460,\"start\":37456},{\"end\":37468,\"start\":37464},{\"end\":37475,\"start\":37472},{\"end\":37730,\"start\":37728},{\"end\":37738,\"start\":37734},{\"end\":37746,\"start\":37742},{\"end\":37755,\"start\":37750},{\"end\":37763,\"start\":37759},{\"end\":37770,\"start\":37767},{\"end\":38078,\"start\":38073},{\"end\":38086,\"start\":38082},{\"end\":38093,\"start\":38090},{\"end\":38101,\"start\":38097},{\"end\":38107,\"start\":38105},{\"end\":38402,\"start\":38396},{\"end\":38415,\"start\":38406},{\"end\":38830,\"start\":38825},{\"end\":38842,\"start\":38836},{\"end\":38853,\"start\":38846},{\"end\":38864,\"start\":38859},{\"end\":39318,\"start\":39311},{\"end\":39327,\"start\":39322},{\"end\":39337,\"start\":39331},{\"end\":39351,\"start\":39345},{\"end\":39590,\"start\":39586},{\"end\":39601,\"start\":39594},{\"end\":39609,\"start\":39605},{\"end\":39619,\"start\":39613},{\"end\":39978,\"start\":39973},{\"end\":39987,\"start\":39982},{\"end\":39995,\"start\":39991},{\"end\":40219,\"start\":40217},{\"end\":40225,\"start\":40223},{\"end\":40232,\"start\":40229},{\"end\":40238,\"start\":40236},{\"end\":40247,\"start\":40242},{\"end\":40601,\"start\":40596},{\"end\":40610,\"start\":40605},{\"end\":40622,\"start\":40614},{\"end\":40631,\"start\":40624},{\"end\":40934,\"start\":40932},{\"end\":40949,\"start\":40938},{\"end\":40962,\"start\":40953},{\"end\":41186,\"start\":41179},{\"end\":41195,\"start\":41190},{\"end\":41201,\"start\":41199},{\"end\":41213,\"start\":41207},{\"end\":41441,\"start\":41437},{\"end\":41452,\"start\":41445},{\"end\":41462,\"start\":41456},{\"end\":41473,\"start\":41466},{\"end\":41485,\"start\":41477},{\"end\":41495,\"start\":41489},{\"end\":41717,\"start\":41712},{\"end\":41728,\"start\":41721},{\"end\":41736,\"start\":41732},{\"end\":41746,\"start\":41740},{\"end\":42049,\"start\":42042},{\"end\":42062,\"start\":42053},{\"end\":42272,\"start\":42269},{\"end\":42279,\"start\":42276},{\"end\":42287,\"start\":42283},{\"end\":42293,\"start\":42291},{\"end\":42516,\"start\":42512},{\"end\":42528,\"start\":42522},{\"end\":42539,\"start\":42532},{\"end\":42735,\"start\":42730},{\"end\":42742,\"start\":42739},{\"end\":42750,\"start\":42746},{\"end\":42984,\"start\":42977},{\"end\":42993,\"start\":42988},{\"end\":43003,\"start\":42997},{\"end\":43014,\"start\":43007},{\"end\":43028,\"start\":43022},{\"end\":43568,\"start\":43563},{\"end\":43576,\"start\":43572},{\"end\":43584,\"start\":43580},{\"end\":43597,\"start\":43590}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":30737,\"start\":30454},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":21690511},\"end\":31058,\"start\":30739},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":57574627},\"end\":31466,\"start\":31060},{\"attributes\":{\"id\":\"b3\"},\"end\":31774,\"start\":31468},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":59337327},\"end\":32050,\"start\":31776},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":3679574},\"end\":32483,\"start\":32052},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":216030941},\"end\":33019,\"start\":32485},{\"attributes\":{\"id\":\"b7\"},\"end\":33258,\"start\":33021},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":121304820},\"end\":33566,\"start\":33260},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":23271977},\"end\":33904,\"start\":33568},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":8777792},\"end\":34254,\"start\":33906},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":213676839},\"end\":34637,\"start\":34256},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":231679155},\"end\":35045,\"start\":34639},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":6964298},\"end\":35352,\"start\":35047},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":32534211},\"end\":35604,\"start\":35354},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":36536667},\"end\":35928,\"start\":35606},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":35083651},\"end\":36269,\"start\":35930},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3813318},\"end\":36655,\"start\":36271},{\"attributes\":{\"doi\":\"ID 1650021\",\"id\":\"b18\",\"matched_paper_id\":5342226},\"end\":37085,\"start\":36657},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":8353148},\"end\":37400,\"start\":37087},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":210985396},\"end\":37664,\"start\":37402},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":209905552},\"end\":37979,\"start\":37666},{\"attributes\":{\"doi\":\"Ar- ticle ID 105402\",\"id\":\"b22\",\"matched_paper_id\":209386919},\"end\":38358,\"start\":37981},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":20714},\"end\":38790,\"start\":38360},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":3586416},\"end\":39246,\"start\":38792},{\"attributes\":{\"id\":\"b25\"},\"end\":39511,\"start\":39248},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":204815617},\"end\":39896,\"start\":39513},{\"attributes\":{\"id\":\"b27\"},\"end\":40145,\"start\":39898},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":212634185},\"end\":40497,\"start\":40147},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":220793490},\"end\":40878,\"start\":40499},{\"attributes\":{\"id\":\"b30\"},\"end\":41099,\"start\":40880},{\"attributes\":{\"id\":\"b31\"},\"end\":41382,\"start\":41101},{\"attributes\":{\"id\":\"b32\"},\"end\":41629,\"start\":41384},{\"attributes\":{\"doi\":\"arXiv:1909.12488\",\"id\":\"b33\"},\"end\":41978,\"start\":41631},{\"attributes\":{\"id\":\"b34\"},\"end\":42195,\"start\":41980},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":229923401},\"end\":42466,\"start\":42197},{\"attributes\":{\"id\":\"b36\"},\"end\":42666,\"start\":42468},{\"attributes\":{\"id\":\"b37\"},\"end\":42898,\"start\":42668},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":14955348},\"end\":43511,\"start\":42900},{\"attributes\":{\"id\":\"b39\"},\"end\":43736,\"start\":43513}]", "bib_title": "[{\"end\":30763,\"start\":30739},{\"end\":31179,\"start\":31060},{\"end\":31802,\"start\":31776},{\"end\":32132,\"start\":32052},{\"end\":32570,\"start\":32485},{\"end\":33316,\"start\":33260},{\"end\":33650,\"start\":33568},{\"end\":34003,\"start\":33906},{\"end\":34344,\"start\":34256},{\"end\":34759,\"start\":34639},{\"end\":35101,\"start\":35047},{\"end\":35415,\"start\":35354},{\"end\":35706,\"start\":35606},{\"end\":35999,\"start\":35930},{\"end\":36348,\"start\":36271},{\"end\":36736,\"start\":36657},{\"end\":37151,\"start\":37087},{\"end\":37452,\"start\":37402},{\"end\":37724,\"start\":37666},{\"end\":38069,\"start\":37981},{\"end\":38392,\"start\":38360},{\"end\":38821,\"start\":38792},{\"end\":39582,\"start\":39513},{\"end\":40213,\"start\":40147},{\"end\":40590,\"start\":40499},{\"end\":42265,\"start\":42197},{\"end\":42973,\"start\":42900}]", "bib_author": "[{\"end\":30778,\"start\":30765},{\"end\":30789,\"start\":30778},{\"end\":30800,\"start\":30789},{\"end\":30809,\"start\":30800},{\"end\":30818,\"start\":30809},{\"end\":30834,\"start\":30818},{\"end\":31193,\"start\":31181},{\"end\":31206,\"start\":31193},{\"end\":31220,\"start\":31206},{\"end\":31560,\"start\":31549},{\"end\":31573,\"start\":31560},{\"end\":31583,\"start\":31573},{\"end\":31596,\"start\":31583},{\"end\":31812,\"start\":31804},{\"end\":31819,\"start\":31812},{\"end\":31827,\"start\":31819},{\"end\":31835,\"start\":31827},{\"end\":32147,\"start\":32134},{\"end\":32155,\"start\":32147},{\"end\":32163,\"start\":32155},{\"end\":32176,\"start\":32163},{\"end\":32193,\"start\":32176},{\"end\":32200,\"start\":32193},{\"end\":32585,\"start\":32572},{\"end\":32593,\"start\":32585},{\"end\":32606,\"start\":32593},{\"end\":32617,\"start\":32606},{\"end\":32626,\"start\":32617},{\"end\":32631,\"start\":32626},{\"end\":33094,\"start\":33082},{\"end\":33106,\"start\":33094},{\"end\":33114,\"start\":33106},{\"end\":33332,\"start\":33318},{\"end\":33342,\"start\":33332},{\"end\":33664,\"start\":33652},{\"end\":33674,\"start\":33664},{\"end\":33686,\"start\":33674},{\"end\":34017,\"start\":34005},{\"end\":34026,\"start\":34017},{\"end\":34352,\"start\":34346},{\"end\":34361,\"start\":34352},{\"end\":34368,\"start\":34361},{\"end\":34767,\"start\":34761},{\"end\":34776,\"start\":34767},{\"end\":34784,\"start\":34776},{\"end\":34792,\"start\":34784},{\"end\":34800,\"start\":34792},{\"end\":35114,\"start\":35103},{\"end\":35128,\"start\":35114},{\"end\":35426,\"start\":35417},{\"end\":35436,\"start\":35426},{\"end\":35720,\"start\":35708},{\"end\":36010,\"start\":36001},{\"end\":36018,\"start\":36010},{\"end\":36025,\"start\":36018},{\"end\":36032,\"start\":36025},{\"end\":36039,\"start\":36032},{\"end\":36046,\"start\":36039},{\"end\":36364,\"start\":36350},{\"end\":36372,\"start\":36364},{\"end\":36384,\"start\":36372},{\"end\":36395,\"start\":36384},{\"end\":36406,\"start\":36395},{\"end\":36417,\"start\":36406},{\"end\":36746,\"start\":36738},{\"end\":36756,\"start\":36746},{\"end\":36767,\"start\":36756},{\"end\":37166,\"start\":37153},{\"end\":37174,\"start\":37166},{\"end\":37186,\"start\":37174},{\"end\":37462,\"start\":37454},{\"end\":37470,\"start\":37462},{\"end\":37477,\"start\":37470},{\"end\":37732,\"start\":37726},{\"end\":37740,\"start\":37732},{\"end\":37748,\"start\":37740},{\"end\":37757,\"start\":37748},{\"end\":37765,\"start\":37757},{\"end\":37772,\"start\":37765},{\"end\":38080,\"start\":38071},{\"end\":38088,\"start\":38080},{\"end\":38095,\"start\":38088},{\"end\":38103,\"start\":38095},{\"end\":38109,\"start\":38103},{\"end\":38404,\"start\":38394},{\"end\":38417,\"start\":38404},{\"end\":38832,\"start\":38823},{\"end\":38844,\"start\":38832},{\"end\":38855,\"start\":38844},{\"end\":38866,\"start\":38855},{\"end\":39320,\"start\":39307},{\"end\":39329,\"start\":39320},{\"end\":39339,\"start\":39329},{\"end\":39353,\"start\":39339},{\"end\":39592,\"start\":39584},{\"end\":39603,\"start\":39592},{\"end\":39611,\"start\":39603},{\"end\":39621,\"start\":39611},{\"end\":39980,\"start\":39969},{\"end\":39989,\"start\":39980},{\"end\":39997,\"start\":39989},{\"end\":40221,\"start\":40215},{\"end\":40227,\"start\":40221},{\"end\":40234,\"start\":40227},{\"end\":40240,\"start\":40234},{\"end\":40249,\"start\":40240},{\"end\":40603,\"start\":40592},{\"end\":40612,\"start\":40603},{\"end\":40624,\"start\":40612},{\"end\":40633,\"start\":40624},{\"end\":40936,\"start\":40930},{\"end\":40951,\"start\":40936},{\"end\":40964,\"start\":40951},{\"end\":41188,\"start\":41177},{\"end\":41197,\"start\":41188},{\"end\":41203,\"start\":41197},{\"end\":41215,\"start\":41203},{\"end\":41443,\"start\":41435},{\"end\":41454,\"start\":41443},{\"end\":41464,\"start\":41454},{\"end\":41475,\"start\":41464},{\"end\":41487,\"start\":41475},{\"end\":41497,\"start\":41487},{\"end\":41719,\"start\":41710},{\"end\":41730,\"start\":41719},{\"end\":41738,\"start\":41730},{\"end\":41748,\"start\":41738},{\"end\":42051,\"start\":42040},{\"end\":42064,\"start\":42051},{\"end\":42274,\"start\":42267},{\"end\":42281,\"start\":42274},{\"end\":42289,\"start\":42281},{\"end\":42295,\"start\":42289},{\"end\":42518,\"start\":42510},{\"end\":42530,\"start\":42518},{\"end\":42541,\"start\":42530},{\"end\":42737,\"start\":42728},{\"end\":42744,\"start\":42737},{\"end\":42752,\"start\":42744},{\"end\":42986,\"start\":42975},{\"end\":42995,\"start\":42986},{\"end\":43005,\"start\":42995},{\"end\":43016,\"start\":43005},{\"end\":43030,\"start\":43016},{\"end\":43570,\"start\":43561},{\"end\":43578,\"start\":43570},{\"end\":43586,\"start\":43578},{\"end\":43599,\"start\":43586}]", "bib_venue": "[{\"end\":32747,\"start\":32687},{\"end\":38586,\"start\":38504},{\"end\":39026,\"start\":38945},{\"end\":43220,\"start\":43122},{\"end\":30572,\"start\":30454},{\"end\":30874,\"start\":30834},{\"end\":31235,\"start\":31220},{\"end\":31547,\"start\":31468},{\"end\":31889,\"start\":31835},{\"end\":32244,\"start\":32200},{\"end\":32685,\"start\":32631},{\"end\":33080,\"start\":33021},{\"end\":33386,\"start\":33342},{\"end\":33711,\"start\":33686},{\"end\":34058,\"start\":34026},{\"end\":34427,\"start\":34368},{\"end\":34832,\"start\":34800},{\"end\":35171,\"start\":35128},{\"end\":35455,\"start\":35436},{\"end\":35745,\"start\":35720},{\"end\":36071,\"start\":36046},{\"end\":36437,\"start\":36417},{\"end\":36845,\"start\":36777},{\"end\":37219,\"start\":37186},{\"end\":37517,\"start\":37477},{\"end\":37799,\"start\":37772},{\"end\":38151,\"start\":38128},{\"end\":38502,\"start\":38417},{\"end\":38943,\"start\":38866},{\"end\":39305,\"start\":39248},{\"end\":39676,\"start\":39621},{\"end\":39967,\"start\":39898},{\"end\":40306,\"start\":40249},{\"end\":40662,\"start\":40633},{\"end\":40928,\"start\":40880},{\"end\":41175,\"start\":41101},{\"end\":41433,\"start\":41384},{\"end\":41708,\"start\":41631},{\"end\":42038,\"start\":41980},{\"end\":42311,\"start\":42295},{\"end\":42508,\"start\":42468},{\"end\":42726,\"start\":42668},{\"end\":43120,\"start\":43030},{\"end\":43559,\"start\":43513}]"}}}, "year": 2023, "month": 12, "day": 17}