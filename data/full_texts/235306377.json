{"id": 235306377, "updated": "2023-10-06 02:13:06.781", "metadata": {"title": "Anomaly Attribution with Likelihood Compensation", "authors": "[{\"first\":\"Tsuyoshi\",\"last\":\"Id'e\",\"middle\":[]},{\"first\":\"Amit\",\"last\":\"Dhurandhar\",\"middle\":[]},{\"first\":\"Jivr'i\",\"last\":\"Navr'atil\",\"middle\":[]},{\"first\":\"Moninder\",\"last\":\"Singh\",\"middle\":[]},{\"first\":\"Naoki\",\"last\":\"Abe\",\"middle\":[]}]", "venue": "Proceedings of the AAAI Conference on Artificial Intelligence, 35(5), 4131-4138, 2021", "journal": "4131-4138", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "This paper addresses the task of explaining anomalous predictions of a black-box regression model. When using a black-box model, such as one to predict building energy consumption from many sensor measurements, we often have a situation where some observed samples may significantly deviate from their prediction. It may be due to a sub-optimal black-box model, or simply because those samples are outliers. In either case, one would ideally want to compute a ``responsibility score'' indicative of the extent to which an input variable is responsible for the anomalous output. In this work, we formalize this task as a statistical inverse problem: Given model deviation from the expected value, infer the responsibility score of each of the input variables. We propose a new method called likelihood compensation (LC), which is founded on the likelihood principle and computes a correction to each input variable. To the best of our knowledge, this is the first principled framework that computes a responsibility score for real valued anomalous model deviations. We apply our approach to a real-world building energy prediction task and confirm its utility based on expert feedback.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2208.10679", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2208-10679", "doi": "10.1609/aaai.v35i5.16535"}}, "content": {"source": {"pdf_hash": "51d0cb42e733e8159dabca998d779af9c07dee79", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2208.10679v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "74e5576cd2bdb81cb9a03b5f1218d5f6c86022e0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/51d0cb42e733e8159dabca998d779af9c07dee79.txt", "contents": "\nAnomaly Attribution with Likelihood Compensation\n\n\nTsuyoshi Id\u00e9 \nIBM Research\nT. J. Watson Research Center\n\n\nAmit Dhurandhar \nIBM Research\nT. J. Watson Research Center\n\n\nJi\u0159\u00ed Navr\u00e1til \nIBM Research\nT. J. Watson Research Center\n\n\nMoninder Singh moninder@us.ibm.com \nIBM Research\nT. J. Watson Research Center\n\n\nNaoki Abe nabe@us.ibm.com \nIBM Research\nT. J. Watson Research Center\n\n\nAnomaly Attribution with Likelihood Compensation\n\nThis paper addresses the task of explaining anomalous predictions of a black-box regression model. When using a black-box model, such as one to predict building energy consumption from many sensor measurements, we often have a situation where some observed samples may significantly deviate from their prediction. It may be due to a sub-optimal black-box model, or simply because those samples are outliers. In either case, one would ideally want to compute a \"responsibility score\" indicative of the extent to which an input variable is responsible for the anomalous output. In this work, we formalize this task as a statistical inverse problem: Given model deviation from the expected value, infer the responsibility score of each of the input variables. We propose a new method called likelihood compensation (LC), which is founded on the likelihood principle and computes a correction to each input variable. To the best of our knowledge, this is the first principled framework that computes a responsibility score for real valued anomalous model deviations. We apply our approach to a real-world building energy prediction task and confirm its utility based on expert feedback.\n\nIntroduction\n\nWith the rapid development of Internet-of-Things technologies, anomaly detection has played a critical role in modern industrial applications of artificial intelligence (AI). One of the recent technology trends is to create a \"digital twin\" using a highly flexible machine learning model, typically deep neural networks, for monitoring the health of the production system (Tao et al. 2018). However, the more representational power the model has, the more difficult it is to understand its behavior. In particular, explaining deviations between predictions and true/expected measurements is one of the main pain points. A large deviation from the truth may be due to sub-optimal model training, or simply because the observed samples are outliers. If the model is black-box and the training dataset is not available, it is hard to determine which of these two situations have occurred. Nonetheless, we would still want to provide information to help end-users' in their decision making.\n\nAs such, in this paper we propose a method that can compute a \"responsibility score\" for each variable of a given Copyright \u00a9 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. input. We aver to this task as anomaly attribution. Specifically, we are concerned with model-agnostic anomaly attribution for black-box regression models, where we want to explain the deviation between the models prediction and the true/expected output in as concise a manner as possible. As a concrete example, consider the scenario of monitoring building energy consumption as the target variable y (see Section 5 for the detail). The input to the model is a multivariate sensor measurement x that is typically real-valued and noisy. Under the assumption that the model is blackbox and the training data are not available, our goal is to compute a numerical score for each of the input variables, quantifying the extent to which they are responsible for the judgment that a given test sample is anomalous.\n\nAnomaly attribution has been studied typically as a subtask of anomaly detection to date. For instance, in subspacebased anomaly detection, computing each variable's responsibility has been part of the standard procedure for years (Chandola, Banerjee, and Kumar 2009). However, there is little work on how anomaly attribution can be done when the model is black-box and the training data set is not available. In the XAI (explainable AI) community, on the other hand, growing attention has been paid to \"post-hoc\" explanations of black-box prediction models. Examples of the techniques include feature subset selection, feature importance scoring, and sample importance scoring (Costabello et al. 2019;Molnar 2019;Samek et al. 2019). For anomaly attribution, there are at least two post-hoc explanation approaches that are potentially applicable: (1) those based on the expected conditional deviation, best known as the Shapley value, which was first introduced to the machine learning community by\u0160trumbelj and Kononenko (2010), and (2) those based on local linear models, best known under the name of LIME (Local Interpretable Model-agnostic Explanations) (Ribeiro, Singh, and Guestrin 2016). In spite of their popularity, these two approaches may not be directly useful for anomaly attribution: Given a test sample (x t , y t ), these methods may explain what the value of f (x t ) itself can be attributed to. However, what is more relevant is explaining the deviation of f (x t ) from the actual y t .\n\nTo address this limitation, we propose likelihood compensation (LC), a new local anomaly attribution approach for black-box regression models. We formalize the task of anomaly attribution as a statistical inverse problem that in-arXiv:2208.10679v1 [cs.LG] 23 Aug 2022 observed sample observed sample Figure 1: Illustration of the likelihood compensation along the i-th axis (\u03b4 i ). For a given test sample (y t , x t ), LC seeks a perturbation that achieves the best possible fit with the black-box regression model y = f (x), which could be nonsmooth (the red curves). For more details please refer to Section 4. fers a perturbation to the test input x t from the deviation y t \u2212f (x t ), conversely to the forward problem that computes the deviation (or its variants) from (x t , y t ). As illustrated in Fig. 1, LC can be viewed intuitively as the \"deviation measured horizontally\" if certain conditions are met. This admits direct interpretation as it suggests an action that might be taken to bring back the outlying sample to normalcy. Importantly, LC does not use any problem-specific assumptions but is built upon the maximum likelihood principle, the basic principle in statistical machine learning. To the best of our knowledge, this is the first principled framework for modelagnostic anomaly attribution in the regression setting.\n\n\nRelated Work\n\nAlthough the machine learning community had not paid much attention to explainability of AI (XAI) in the blackbox setting until recently, the last few years has seen a surge of interest in XAI research. For general background, Gade et al. (2020) provides a useful summary of major research issues in XAI for industries. In a more specific context of inddustrial anomaly detection, Langone et al. (2020) and Amarasinghe et al. (2018) give a useful summary of practical requirements of XAI in the deep learning era. An extensive survey on various XAI methodologies is given in (Costabello et al. 2019;Molnar 2019;Samek et al. 2019).\n\nSo far most of the model-agnostic post-hoc explanation studies are designed for classification, often restricted to image classification. As discussed before, two approaches are potentially applicable to the task of anomaly attribution in the black-box regression setting, namely the Shapley value (SV) (\u0160trumbelj andKononenko 2010, 2014;Casalicchio, Molnar, and Bischl 2018) and the LIME Guestrin 2016, 2018). The relationship between the two was discussed by Lundberg et al. (2017) assuming binary inputs. In the context of anomaly detection from noisy, realvalued data, two recent studies, Zhang et al. (2019) and Giurgiu et al. (2019), proposed a method built on LIME and SV, respectively. While these belong to the earliest modelagnostic XAI studies for anomaly detection, they naturally inherit the limitations of the existing approaches mentioned in introduction. Recently, Lucic et al. (2020) proposed a LIME-based approach for identifying a variable-wise normal range, which although related is different from our formulation of the anomaly attribution problem. Zemicheal et al. (2019) proposed an SV-like feature scoring method in the context of outlier detection, however, this does not apply to the regression setting.\n\nOne of the main contributions of this work is the proposal of a generic XAI framework for input attribution built upon the likelihood principle. The method of integrated gradient (Sundararajan, Taly, and Yan 2017) is another generic input attribution approach applicable to the black-box setting. Sipple (2020) recently applied it to anomaly detection and explanation. However, it is applicable to only the classification setting and, as pointed out by Sipple (2020), the need for the \"baseline input\" makes it less useful in practice. Layerwise relevance propagation (Bach et al. 2015) is another well-known input attribution method and has been applied to real-world anomaly attribution tasks (Amarasinghe, Kenney, and Manic 2018). However, it is deep-learning-specific and assumes we have white-box access to the model.\n\nAnother research thread relevant to our work revolves around the counterfactual approach, which focuses on what is missing in the model (or training data) rather than what exists. In the context of image classification, the idea of counterfactuals is naturally translated into perturbation-based explanation (Fong and Vedaldi 2017). Recent works (Dhurandhar et al. 2018;Wachter, Mittelstadt, and Russell 2017) proposed the idea of contrastive explanation, which attempts to find a perturbation best characterizing a classification instance such that the probability of choosing a different class supersedes the original prediction. Our approach is similar in spirit, but as mentioned above, is designed for regression and uses a very different objective function. Moreover, both of these methods (Dhurandhar et al. 2018;Wachter, Mittelstadt, and Russell 2017) require white-box access, while ours is a black-box approach.\n\n\nProblem Setting\n\nAs mentioned before, we focus on the task of anomaly attribution in the regression setting rather than classification or unsupervised settings. Throughout the paper, the input variable x is assumed to be noisy, multivariate, and real-valued in general. Our task is formally stated as follows: Definition 1 (Anomaly detection and attribution). Given a black-box regression model y = f (x) and a test data set D test : (1) compute the score to represent the degree of anomaly of the prediction on D test ; (2) compute the responsibility score for each input variable for the prediction being anomalous.\n\nThe black-box regression model is assumed to be deterministic with y \u2208 R and x \u2208 R M , where M \u2265 2 is the dimensionality of the input random variable x. The functional form of f (\u22c5) and the dependency on model parameters are not available to us. The training data on which the model was trained is not available either. The only interface to the model we are given is x, which follows an unknown distri-bution P (x). Queries to get the response f (x) can be performed cheaply at any x.\n\nThe test data set is denoted as D test = {(x t , y t ) t = 1, . . . , N test }, where t is the index for the t-th test sample and N test is the number of test samples. When N test = 1, the task may be called the outlier detection and attribution.\n\nAnomaly detection as forward problem Assume that, from the deterministic regression model, we can somehow obtain p(y x), a probability density over y given the input signal x (see Sec. 4.2 for a proposed approach to do this). The standard approach to quantifying the degree of anomaly is to use the negative log-likelihood of test samples. Under the i.i.d. assumption, it can be written as\na(D test ) = \u2212 1 N test t\u2208Dtest ln p(y t x t ),(1)\nwhich is called the anomaly score for D test (or the outlier score for a single sample dataset). An anomaly is declared when a(D test ) exceeds a predefined threshold.\n\nAnomaly attribution as inverse problem The above anomaly/outlier detection formulation is standard. However, the anomaly/outlier attribution is more challenging when the underlying model is black-box. This is in some sense an inverse problem: The function f (x) readily gives an estimate of y from x, but, in general, there is no obvious way to do the reverse in the multivariate case. When an estimate f (x t ) looks 'bad' in light of an observed y t , what can we say about the contribution, or responsibility, of the input variables? Section 4 below gives our proposed answer to this question.\n\nNotation We use boldface to denote vectors. The i-th dimension of a vector \u03b4 is denoted as \u03b4 i . The 1 and 2 norms of a vector are denoted by \u22c5 1 and \u22c5 2 , respectively, and are defined as \u03b4 1 \u225c \u2211 i \u03b4 i and \u03b4 2 \u225c \u2211 i \u03b4 2 i . The sign function sign(\u03b4 i ) is defined as being 1 for \u03b4 i > 0, and \u22121 for \u03b4 i < 0. For \u03b4 i = 0, the function takes a value in [\u22121, 1]. For a vector input, the definition applies element-wise, giving a vector of the same size as the input.\n\nWe distinguish between a random variable and its realizations with a superscript. For notational simplicity, we symbolically use p(\u22c5) to represent different probability distributions, whenever there is no confusion. For instance, p(x) is used to represent the probability density of a random variable x while p(y x) is a different distribution of another random variable y conditioned on x. The Gaussian distribution of a random variable y is denoted by N (y \u22c5, \u22c5), where the first and the second arguments after the bar are the mean and the variance, respectively. The multivariate Gaussian distribution is defined in a similar way.\n\n\nThe Method of Likelihood Compensation\n\nThis section presents the key idea of \"likelihood compensation\" as illustrated in Fig. 1. We start with a likelihood-based interpretation of LIME to highlight the idea.\n\n\nImproving Likelihood via Corrected Input\n\nFor a given test sample (y t , x t ), LIME minimizes the lasso objective to let the sparse regression estimation process select a subset of the variables. From a Bayesian perspective, it can be rewritten as a MAP (maximum a posteriori) problem:\nLIME: max \u03b2 \u27e8ln p(y x t , \u03b2) p(\u03b2) \u27e9 vic(x t ) subject to y = f (x),(2)\nwhere \u27e8\u22c5\u27e9 vic(x t ) denotes the expectation over random samples generated from an assumed local distribution in the vicinity of x t . For p's above, LIME uses the Gaussian observation model p(y x, \u03b2) = N (y \u03b2 0 + \u03b2 \u22ba x, \u03c3 2 ) and the Laplace prior p(\u03b2) \u221d exp (\u2212\u03bd \u03b2 1 ). Here \u03c3 2 , \u03bd are hyperparameters. The regression coefficient \u03b2 as well as the intercept \u03b2 0 captures the local linear structure of f and is interpreted as the sensitivity of f at x t . From the viewpoint of actionability, however, the slope can be less useful than x itself, particularly for the purpose of outlier attribution. If (x t , y t ) is an outlier far from the population, how can we expect to obtain actionable insights from the local slope? Another issue is that y t plays no role in this formulation. Notice the constraint of maximization: LIME amounts to assuming that the model is always right and is not sensitive to the question of whether (y t , x t ) is an outlier or not.\n\nKeeping this in mind, we propose to introduce a directly interpretable parameter \u03b4 as a correction term to x, rather than the slope as in LIME:\nProposed: max \u03b4 ln p(y t f (x t + \u03b4)) p(\u03b4) , (3) p(y f (x + \u03b4)) = N (y f (x + \u03b4), \u03c3 2 (x)).(4)\nThe prior p(\u03b4) can be designed to reflect problem-specific constraints such as infeasible regions so that the resultant x + \u03b4 is a realistic or high probability input. Considering the well-known issue of lasso that in the presence of multiple correlated explanatory variables it tends to pick one at random (Roy, Chakraborty et al. 2017), we employ p(\u03b4) \u221d exp \u2212 1 2 \u03bb \u03b4 2 2 \u2212 \u03bd \u03b4 1 . \u03c3 2 (x) is the local variance representing the uncertainty of prediction (see Sec. 4.2), and \u03bb, \u03bd are hyperparameters controlling the sparsity and the overall scale of \u03b4 (see Sec. 4.4 for typical values). We call \u03b4 the likelihood compensation (LC) as it compensates for the loss in likelihood incurred by an anomalous prediction. Note that, unlike LIME, our explainabiliy model is neither linear nor additive, being free from the \"masking effect\" (Hastie, Tibshirani, and Friedman 2009) observed in linear XAI models.\n\nWe can naturally extend the point-wise definition of Eq.\n\n(3) to a collection of test samples. For the Gaussian observation and the elastic net prior, we have the following optimization problem for the LC for D test :\nmin \u03b4 \u23a7 \u23aa \u23aa \u23a8 \u23aa \u23aa \u23a9 1 N test Ntest t=1 y t \u2212 f (x t + \u03b4) 2 2\u03c3 2 t + \u03bb 2 \u03b4 2 2 + \u03bd \u03b4 1 \u23ab \u23aa \u23aa \u23ac \u23aa \u23aa \u23ad ,(5)\nwhere \u03c3 2 t is the local variance evaluated at x t . This is the main problem studied in this paper.\n\n\nDeriving Probabilistic Prediction Model\n\nSo far we have assumed the predictive distribution p(y x) is given. Now let us think about how to derive it from the deterministic black-box regression model y = f (x).\n\nIf there are too few test samples, we have no choice but to set \u03c3 2 t to a constant using prior knowledge. Otherwise, we can obtain an estimate of \u03c3 2 t using a subset of D test in a cross-validation (CV)-like fashion. Let D t ho = {(x (n) , y (n) ) n = 1, . . . , N ho } \u2282 D test be a held-out data set that does not include the given test sample (x t , y t ). For the observation model Eq. (4) and the test sample x t , we consider a locally weighted version of maximum likelihood:\nmax \u03c3 2 N ho n=1 w n (x t ) ln 1 \u221a 2\u03c0\u03c3 2 \u2212 (y (n) \u2212 f (x (n) )) 2 2\u03c3 2 ,(6)\nwhere w n (x t ) is the similarity between x t and x (n) . A reasonable choice for w n is the Gaussian kernel:\nw n (x t ) = N (x (n) x t , diag(\u03b7)),(7)\nwhere diag(\u03b7) is a diagonal matrix whose i-th diagonal is given by \u03b7 i , which can be of the same order as the sample variance of x i evaluated on D ho . The maximizer of Eq. (6) can be found by differentiating w.r.t. \u03c3 \u22122 . The solution is given by\n\u03c3 2 t = 1 \u2211 m w m (x t ) N ho n=1 w n (x t ) y (n) \u2212 f (x (n) ) 2 .(8)\nThis has to be computed for each x t \u2208 D test .\n\n\nSolving the Optimization Problem\n\nAlthough seemingly simple, solving the optimization problem (5) is generally challenging. Due to the black-box nature of f , we do not have access to the parametric form of f , let alone the gradient. In addition, as is the case in deep neural networks, f can be non-smooth (see the red curves in Fig. 1), which makes numerical estimation of the gradient tricky.\n\nTo derive an optimization algorithm, we first note that there are two origins of non-smoothness in the objective function in (5). One is inherent to f while the other is due to the added 1 penalty. To separate them, let us denote the objective function in Eq. (5) as J(\u03b4)+\u03bd \u03b4 1 , where J contains the first and second terms. Since we are interested only in a local solution in the vicinity of \u03b4 = 0, it is natural to adopt an iterative update algorithm starting from \u03b4 \u2248 0. Suppose that we have an estimate \u03b4 = \u03b4 old that we wish to update. If we have a reasonable approximation of the gradient in its vicinity, denoted by \u27ea\u2207J(\u03b4 old )\u27eb, the next estimate can be found by\n\u03b4 new = arg min \u03b4 J(\u03b4 old ) + (\u03b4 \u2212 \u03b4 old ) \u22ba \u27ea\u2207J(\u03b4 old )\u27eb + 1 2\u03ba \u03b4 \u2212 \u03b4 old 2 2 + \u03bd \u03b4 1(9)\nin the same spirit of the proximal gradient (Parikh, Boyd et al. 2014), where \u03ba is a hyperparameter representing the learning rate. Notice that the first three terms in the curly bracket correspond to a second-order approximation of J(\u03b4)\n\nin the vicinity of \u03b4 old . We find the best estimate under this approximation. The r.h.s. has an analytic solution. Define \u03c6 \u225c \u03b4 old \u2212 \u03ba\u27ea\u2207J(\u03b4 old )\u27eb. The optimality condition is \u03b4 \u2212 \u03c6 + \u03ba\u03bd sign(\u03b4) = 0. If \u03c6 i > \u03ba\u03bd holds for the i-th dimension, by \u03c6 i \u00b1 \u03ba > 0, we have \u03b4 i = \u03c6 i \u2212 \u03ba\u03bd sign(\u03b4 i ) = \u03c6 i \u2212 \u03ba\u03bd. Similar arguments straightforwardly verify the following solution:\n\u03b4 i = \u23a7 \u23aa \u23aa \u23aa \u23aa \u23a8 \u23aa \u23aa \u23aa \u23aa \u23a9 \u03c6 i \u2212 \u03ba\u03bd, \u03c6 i > \u03ba\u03bd 0, \u03c6 i \u2264 \u03ba\u03bd \u03c6 i + \u03ba\u03bd, \u03c6 i < \u2212\u03ba\u03bd .(10)\nPerforming differentiation, we see that \u03c6 is given by\n\u03c6 = (1 \u2212 \u03ba\u03bb)\u03b4 old + \u03ba 1 N test Ntest t=1 y t \u2212 f (x t + \u03b4) \u03c3 2 t \u27ea \u2202f (x t + \u03b4) \u2202\u03b4 \u27eb . (11)\nNote that f (x t + \u03b4) is readily available at any \u03b4 without approximation. Here we provide some intuition behind the updating equation (11). Convergence is achieved when either the deviation y t \u2212 f or the gradient \u27ea\u2202f \u2202\u03b4\u27eb vanishes at x t + \u03b4. The former and the latter correspond, respectively, to the situations illustrated in Fig. 1 (a) and (b). As shown in the figure, \u03b4 i corresponds to the horizontal deviation along the x i axis between the test sample and the regression function. If there is no horizontal intersection on the regression surface it seeks the zero gradient point based on a smooth surrogate of the gradient. To find \u27ea\u2202f \u2202\u03b4\u27eb, a smooth surrogate of the gradient, we propose a simple sampling-based procedure. Specifically, we draw N s samples from a local distribution at x t + \u03b4 as\n\nx [m] \u223c N (\u22c5 x t + \u03b4, diag(\u03b7)),\n\nand fit a linear regression model\nf = \u03b2 0 + \u03b2 \u22ba x on the pop- ulated local data set {(x [m] , f [m] ) m = 1, . . . , N s }, where f [m] = f (x [m]\n). Solving the least squares problem, we have\n\u27ea \u2202f (x t + \u03b4) \u2202\u03b4 \u27eb = \u03b2 = \u03a8 s \u03a8 \u22ba s + \u03b5I M \u22121 \u03a8 s f s ,(13)\nwhere \u03b5 \u2248 0 is a small positive constant added to the diagonals for numerical stability. In Eq. (13) \n\n\nAlgorithm Summary\n\nAlgorithm 1 summarizes the iterative procedure for finding \u03b4. The most important parameter is the 1 regularization strength \u03bd, which has to be hand-tuned depending on the business requirements of the application of interest. On the other hand, the 2 strength \u03bb controls the overall scale of \u03b4. It can be fixed to some value between 0 and 1. In our experiments, it was adjusted so its scale is on the same order as LIME's output for consistency. It is generally recommended to rescale the input variables to have the zero for all x t \u2208 D test do 8:\n\nCompute \u03b2 with Eq. (13). 9:\nUpdate g \u2190 g + \u03b2 y t \u2212f (x t +\u03b4) Ntest\u03c3 2 t . 10: end for 11: \u03c6 = (1 \u2212 \u03ba\u03bb)\u03b4 + \u03bag.\n\n12:\n\nFind \u03b4 with Eq. (10). 13: until convergence. 14: return \u03b4 mean and unit variance before starting the iteration (assuming N test \u226b 1), and retrieve the scale factors after convergence. For the learning rate \u03ba, in our experiments, we fixed \u03ba = 0.1 and shrank it (geometrically) by a factor of 0.98 in every iteration.\n\nIn addition to the parameters listed in Algorithm 1, the sampling-based estimation of the gradient Eq. (13) requires two minor parameters, N s , \u03b7. In the experiment, we fixed N s = 1 000 following (Ribeiro, Singh, and Guestrin 2016) and \u03b7 i = 1 for all i after standardization. The same \u03b7 was used for Eq. (7).\n\n\nExperiments\n\nWe now describe our experimental design and baselines we compare against in the empirical studies that follow.\n\nEvaluation strategy Explainability of AI is generally evaluated from three major perspectives (Costabello et al. 2019): decomposability, simulatability, and algorithmic transparency. In post-hoc explanations of black-box models, decomposability and simulatability are most important. We thus design our experiments to answer the following questions: a) whether LC can provide extra information on specific anomalous samples beyond the baseline methods (decomposability), b) whether LC can robustly compute the responsibility score under heavy noise (simulatability), and c) whether LC can provide actionable insights in a realworld business scenario (simulatability). Regarding the third question, we validated our approach with feedback from domain experts as opposed to \"crowd sourced\" studies with lay users. In industrial applications, the end-user's interests can be highly specific to particular business needs and the system's inner workings tend to be difficult for non-experts to understand and simulate.\n\nBaselines We compare LC with three possible alternatives: (1) Z-score and extended versions of (2) Shapley val- ues (SV) and (3) LIME. The Z-score is the standard univariate outlier detection method in the unsupervised setting, and that of x t i is defined as (x t i \u2212 m i ) \u03c3 i , where m i , \u03c3 i are the mean and the standard deviation of x i in D test , respectively. Shapley values (SV) and LIME are used as a proxy of the prior works (Zhang et al. 2019;Giurgiu and Schumann 2019;Lucic, Haned, and de Rijke 2020), which used SV or LIME in certain tasks similar to ours. For fair comparison, we extended these methods to be applied on the deviation f \u2212 y instead of f itself, and name them LIME+ and SV+, respectively. We dropped SV+ in the building energy experiment as the training data was not available to compute the null/base values for each variable that SV requires. Note that contrastive and counterfactual methods such as (Dhurandhar et al. 2018;Wachter, Mittelstadt, and Russell 2017) are not valid competitors here as they require white-box access to the model and are predominantly used in classification settings.\n\nTwo-Dimensional Mexican Hat One of the major features of LC is its capability to provide explanations relevant to specific anomalous samples. To illustrate this, we used the two-dimensional Mexican Hat for the regression function f (x) \u221d (1 \u2212 1 2 x 2 2 ) exp(\u2212 1 2 x 2 2 ) as shown in Fig. 2 (a). Suppose we have obtained a test sample at x t = (1, 0) \u22ba . By symmetry, LIME+ has only the x 1 component, which can be analytically calculated to be \u22120.29 at this x t when \u03bd \u2192 0 + . Similarly, LC has only the x 1 component, and is computed through iterative updates with the aid of analytic expression of the gradient. For SV+, we used uniform sam- pling from [\u22124, 4] 2 to evaluate the expectations. Figure 2 (b) shows the calculated values of \u03b4 1 as a function of y t with \u03bd = 0, \u03bb = 0.01. Figure 3 compares Z-score, SV+, LIME+, and LC for the two particular values of y t , corresponding to the f > y t and f < y t cases. As shown, Z-score, SV+, and LIME+ are not able to distinguish between the two cases, demonstrating the limited utility in anomaly attribution. In contrast, LC's value of \u03b4 1 corresponds to the horizontal distance between the test point and the curve of f as shown in Fig. 2. Hence we can think of it as a measure of \"horizontal deviation,\" as we illustrated earlier in Fig. 1.\n\nBoston Housing Next we used Boston Housing data (Belsley 1980) to test the robustness to noise. The task is to predict the median home price ('MEDV') of the districts in Boston with M = 13 input variables such as the percentage of lower status of the population ('LSTAT') and the average number of rooms ('RM'). As one might expect, the data is very noisy. As an illustrative example, Fig. 4 shows scatter plots between y (MEDV) and two selected input variables (LSTAT, RM), which have the highest correlations with y. We held out 20% of the data as D test (N test = 101), and trained a random forest on the rest. Then we picked the two top outliers, as highlighted as #3 and # 7 in Fig. 4. These are the two samples with the highest outlier scores of Eq. (1), to which not only LSTAT and RM but also all the other variables contributed. Figure 5 compares the results of LC with the baselines for these outliers. For the 1 parameter, we gave \u03bd = 0.1 for LC, then chose \u03bd = 0.005 for LIME+, so that LIME+ has on average the same number of nonzero elements as LC. The 2 parameter \u03bb was chosen as 0.5 for LC and LIME+ to have approximately the same scale. For SV+, all the 2 M \u22121 M = 53 248 combinations were evaluated with the empirical distribution of the training samples, which are actually supposed to be unavailable in our setting, requiring about an hour to finish on a laptop PC (Core i7-8850H) for each test sample, while LC required only several seconds. From the figure, we see that overall SV+, LIME+, and LC are consistent in the sense that most of the weights appear on a few common variables including LSTAT. Z-score behaves quite differently, reflecting the fact that it is agnostic to the y-x relationship. For these outliers, LC gave positive and negative scores for LSTAT and RM in Fig. 5, respectively. Checking the scatter plots in Fig. 4, we can confirm the LC's characterization as the horizontal deviation that a positive (negative) score means \"a positive (negative) shift will give a better fit.\" In contrast, LIME+ simply indicates whether the local slope is positive or negative, independently how the test samples deviate. In fact, one can mathematically show that LIME+ is invariant to the value of y, meaning that LIME cannot be a useful tool for instance-specific anomaly attribution.\n\nIn SV+, the situation is more subtle. It does not allow simple interpretations like LC or LIME+. The sign of the scores unpredictably becomes negative or positive, probably due to complicated effects of higher-order correlations. This suggests SV's tendency to be unstable under noise. In fact, our bootstrap analysis (not included for page limitation) shows that the SV+ scores are vulnerable to noise; The top three variables with the highest absolute SV+ scores gave a 35.3% variability relative to the mean. In addition, SV+ needs training data or the true distribution of x for Monte Carlo evaluation. Z-score, LIME+, and LC do not have such a requirement. Along with the prohibitive computational cost, those limitations make it impractical to apply SV+ to real-world system monitoring scenarios of the type presented below.\n\n\nReal-World Application: Building Energy Management\n\nFinally, we applied LC to a building administration task. Collaborating with an entity offering building management services and products, we obtained energy consumption data for an office building in India. The total wattage is predicted by a black-box model as a function of weather-related (temperature, humidity, etc.) and time-related variables (time of day, day of week, month, etc.). There are two intended usages of the predictive model. One is near future prediction with short time windows for optimizing HVAC (heating, ventilating, and air conditioning) system control. The other is retrospective analysis over the last few months for the purpose of planning long-term improvement of the building facility and its management policies. In the retrospective analysis, it is critical to get clear explanation on unusual events.\n\nAt the beginning of the project, we interviewed 10 professionals on what kind of model explainability would be most useful for them. Their top priority capabilities were uncertainty quantification in forecasting and anomaly diagnosis in retrospective analysis. Our choices in the current research reflect these business requirements.\n\nWe obtained a one month worth of test data with M = 12 input variables recorded hourly. We first computed \u03c3 2 t according to Eq. (8) in which we leave (y t , x t ) out for each t. For each of the test samples, we computed the outlier score by Eq. (1) under the Gaussian observation model, which resulted in a few conspicuous anomalies as shown in Fig. 6. An important business question was who or what may be responsible for those anomalies.\n\nTo obtain insights regarding the detected anomalies, we computed the LC score as shown in Fig. 7, where we computed \u03b4 each day with N test = 24 in Eq. (5), and visualized \u03b4 2 2 . For the Z-score, we visualized the daily mean of the absolute values. For LIME+, we computed regression coefficients for every sample, and visualized the 2 norm of their daily mean. We used (\u03bd, \u03bb) = (0.1, 0.5), which was determined by the level of sparsity and scale preferred by the domain experts.\n\nAs shown in the plot, the LC score clearly highlights a few variables whenever the outlier score is exceptionally high in Fig. 6, while the Z-score and LIME+ do not provide much information beyond the trivial weekly patterns. The pattern of LIME+ was very stable over 0 < \u03bd \u2264 1, showing empirical evidence of insensitivity to outliers. As mentioned before, one can mathematically prove this important fact: LIME+ as well as SV+ are invariant to the translation in f . On the other hand, the Z-score sensitively captures the variability in the weather-related variables, but it fails to explain the deviations in Fig. 6. This is understandable because the Zscore does not reflect the relationship between y and x. The artifact seen in the \"daytype\" variables is due to the one-hot encoding of the day of week.\n\nFinally, with LC, the variables highlighted around October 19 (Thursday) are 'timeofday', 'daytype Sa', and 'daytype Su', implying that those days had an unusual daily wattage pattern for a weekday and looked more like weekend days. Interestingly, it turned out that the 19th was a national holiday in India and many workers were off on and around that date. Thus we conclude that the anomaly is most likely not due to any faulty building facility, but due to the model limitation caused by the lack of full calendar information. Though simple, such pointed insights made possible by our method were highly appreciated by the professionals.\n\n\nConclusions\n\nWe have proposed a new method for model-agnostic explainability in the context of regression-based anomaly attribution. To the best of our knowledge, the proposed method provides the first principled framework for contrastive explainability in regression. The recommended responsibility score Likelihood Compensation is built upon the maximum likelihood principle. This is very different from the objectives used to obtain contrastive explanations in the classification setting. We demonstrated the advantages of the proposed method based on synthetic and real data, as well as on a real-world use-case of building energy management where we sought expert feedback.\n\nFigure 2 :Figure 3 :\n23Mexican Hat: (a) The x 2 = 0 slice of f (x). (b) Computed \u03b4 1 as a function of y t . Mexican Hat: Comparison of the responsibility scores evaluated at y t = 0.2 (upper) and 0 (lower).\n\nFigure 4 :\n4Boston Housing: Pairwise scatter plot between y (MEDV) and two selected input variables (LSTAT, RM).\n\nFigure 5 :Figure 6 :\n56Boston Housing: Comparison of the responsibility scores for the top two outliers (#3 and #7). Building Energy: Outlier score computed with Eq. (1) for the test data.\n\nFigure 7 :\n7Building Energy: Comparison of the responsibility scores computed for the test data.\nAcknowledgementsThe authors thank Dr. Kaoutar El Maghraoui for her support and technical suggestions. T.I. is partially supported by the Department of Energy National Energy Technology Laboratory under Award Number DE-OE0000911. A part of this report was prepared as an account of work sponsored by an agency of the United States Government. Neither the United States Government nor any agency thereof, nor any of their employees, makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. Reference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof.\nToward explainable deep neural network based anomaly detection. K References Amarasinghe, K Kenney, M Manic, Proc. Intl. Conf. Human System Interaction (HSI). Intl. Conf. Human System Interaction (HSI)IEEEReferences Amarasinghe, K.; Kenney, K.; and Manic, M. 2018. Toward explainable deep neural network based anomaly detection. In Proc. Intl. Conf. Human System Interaction (HSI), 311- 317. IEEE.\n\nOn pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. S Bach, A Binder, G Montavon, F Klauschen, K.-R M\u00fcller, W Samek, PloS one. 107130140Bach, S.; Binder, A.; Montavon, G.; Klauschen, F.; M\u00fcller, K.-R.; and Samek, W. 2015. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance prop- agation. PloS one 10(7): e0130140.\n\n. K Belsley, Belsley, K. .\n\nRegression diagnostics: Identifying Influential Data and Sources of Collinearity. W , WileyW. 1980. Regression diagnostics: Identifying Influential Data and Sources of Collinearity. Wiley.\n\nVisualizing the feature importance for black box models. G Casalicchio, C Molnar, B Bischl, Proc. Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Joint European Conference on Machine Learning and Knowledge Discovery in DatabasesSpringerCasalicchio, G.; Molnar, C.; and Bischl, B. 2018. Visu- alizing the feature importance for black box models. In Proc. Joint European Conference on Machine Learning and Knowledge Discovery in Databases, 655-670. Springer.\n\nAnomaly Detection: A Survey. V Chandola, A Banerjee, V Kumar, ACM Computing Survey. 413Chandola, V.; Banerjee, A.; and Kumar, V. 2009. Anomaly Detection: A Survey. ACM Computing Survey 41(3): 1-58.\n\nOn Explainable AI: From Theory to Motivation, Applications and Limitations. L Costabello, F Giannotti, R Guidotti, P Hitzler, F L\u00e9cu\u00e9, P Minervini, K Sarker, Tutorial, AAAI Conference on Artificial Intelligence. Costabello, L.; Giannotti, F.; Guidotti, R.; Hitzler, P.; L\u00e9cu\u00e9, F.; Minervini, P.; and Sarker, K. 2019. On Explainable AI: From Theory to Motivation, Applications and Limitations. In Tutorial, AAAI Conference on Artificial Intelligence.\n\nExplanations based on the missing: Towards contrastive explanations with pertinent negatives. A Dhurandhar, P.-Y Chen, R Luss, C.-C Tu, P Ting, K Shanmugam, P Das, Advances in Neural Information Processing Systems. Dhurandhar, A.; Chen, P.-Y.; Luss, R.; Tu, C.-C.; Ting, P.; Shanmugam, K.; and Das, P. 2018. Explanations based on the missing: Towards contrastive explanations with pertinent negatives. In Advances in Neural Information Processing Systems, 592-603.\n\nInterpretable explanations of black boxes by meaningful perturbation. R C Fong, A Vedaldi, Proc. IEEE Intl. Conf. Computer Vision. IEEE Intl. Conf. Computer VisionFong, R. C.; and Vedaldi, A. 2017. Interpretable explana- tions of black boxes by meaningful perturbation. In Proc. IEEE Intl. Conf. Computer Vision, 3429-3437.\n\n. K Gade, S Geyik, K Kenthapadi, V Mithal, A Taly, Gade, K.; Geyik, S.; Kenthapadi, K.; Mithal, V.; and Taly, A.\n\nExplainable AI in Industry: Practical Challenges and Lessons Learned. Companion Proceedings of the Web Conference. 2020Explainable AI in Industry: Practical Challenges and Lessons Learned. In Companion Proceedings of the Web Conference 2020, 303-304.\n\nAdditive Explanations for Anomalies Detected from Multivariate Temporal Data. I Giurgiu, A Schumann, Proc. Intl. Conf. Information and Knowledge Management. Intl. Conf. Information and Knowledge ManagementACMGiurgiu, I.; and Schumann, A. 2019. Additive Explanations for Anomalies Detected from Multivariate Temporal Data. In Proc. Intl. Conf. Information and Knowledge Manage- ment, 2245-2248. ACM.\n\nThe Elements of Statistical Learning: Data Mining, Inference, and Prediction. T Hastie, R Tibshirani, J Friedman, Springer2 editionHastie, T.; Tibshirani, R.; and Friedman, J. 2009. The El- ements of Statistical Learning: Data Mining, Inference, and Prediction. Springer, 2 edition.\n\nInterpretable Anomaly Prediction: Predicting anomalous behavior in industry 4.0 settings via regularized logistic regression tools. R Langone, A Cuzzocrea, N Skantzos, Data & Knowledge Engineering 101850Langone, R.; Cuzzocrea, A.; and Skantzos, N. 2020. Inter- pretable Anomaly Prediction: Predicting anomalous behav- ior in industry 4.0 settings via regularized logistic regression tools. Data & Knowledge Engineering 101850.\n\nWhy does my model fail? contrastive local explanations for retail forecasting. A Lucic, H Haned, M De Rijke, Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. the 2020 Conference on Fairness, Accountability, and TransparencyLucic, A.; Haned, H.; and de Rijke, M. 2020. Why does my model fail? contrastive local explanations for retail forecast- ing. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, 90-98.\n\nA unified approach to interpreting model predictions. S M Lundberg, S.-I Lee, Advances in Neural Information Processing Systems. Lundberg, S. M.; and Lee, S.-I. 2017. A unified approach to interpreting model predictions. In Advances in Neural Information Processing Systems, 4765-4774.\n\nInterpretable machine learning. C Molnar, LuluMolnar, C. 2019. Interpretable machine learning. Lulu.\n\n. N Parikh, S Boyd, Proximal algorithms. Foundations and Trends in Optimization. 13Parikh, N.; Boyd, S.; et al. 2014. Proximal algorithms. Foun- dations and Trends in Optimization 1(3): 127-239.\n\nWhy should I trust you?: Explaining the predictions of any classifier. M T Ribeiro, S Singh, C Guestrin, Proc. ACM SIGKDD Intl. Conf. Knowledge Discovery and Data Mining. ACM SIGKDD Intl. Conf. Knowledge Discovery and Data MiningACMRibeiro, M. T.; Singh, S.; and Guestrin, C. 2016. Why should I trust you?: Explaining the predictions of any classi- fier. In Proc. ACM SIGKDD Intl. Conf. Knowledge Discov- ery and Data Mining, 1135-1144. ACM.\n\nAnchors: High-precision model-agnostic explanations. M T Ribeiro, S Singh, C Guestrin, Proc. AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial IntelligenceRibeiro, M. T.; Singh, S.; and Guestrin, C. 2018. Anchors: High-precision model-agnostic explanations. In Proc. AAAI Conference on Artificial Intelligence.\n\nSelection of tuning parameters, solution paths and standard errors for Bayesian lassos. V Roy, S Chakraborty, Bayesian Analysis. 123Roy, V.; Chakraborty, S.; et al. 2017. Selection of tuning parameters, solution paths and standard errors for Bayesian lassos. Bayesian Analysis 12(3): 753-778.\n\nExplainable AI: interpreting, explaining and visualizing deep learning. W Samek, G Montavon, A Vedaldi, L K Hansen, K.-R M\u00fcller, Springer Nature11700Samek, W.; Montavon, G.; Vedaldi, A.; Hansen, L. K.; and M\u00fcller, K.-R. 2019. Explainable AI: interpreting, explain- ing and visualizing deep learning, volume 11700. Springer Nature.\n\nInterpretable, Multidimensional, Multimodal Anomaly Detection with Negative Sampling for Detection of Device Failure. J Sipple, Proc. Intl. Conf. Machine Learning. Intl. Conf. Machine LearningSipple, J. 2020. Interpretable, Multidimensional, Multi- modal Anomaly Detection with Negative Sampling for De- tection of Device Failure. In Proc. Intl. Conf. Machine Learning, 9016-9025.\n\nAn efficient explanation of individual classifications using game theory. E Strumbelj, I Kononenko, Journal of Machine Learning Research. 11Strumbelj, E.; and Kononenko, I. 2010. An efficient expla- nation of individual classifications using game theory. Jour- nal of Machine Learning Research 11(Jan): 1-18.\n\nExplaining prediction models and individual predictions with feature contributions. E Strumbelj, I Kononenko, Knowledge and information systems. 413Strumbelj, E.; and Kononenko, I. 2014. Explaining predic- tion models and individual predictions with feature contribu- tions. Knowledge and information systems 41(3): 647-665.\n\nAxiomatic attribution for deep networks. M Sundararajan, A Taly, Yan , Q , Proc. Intl. Conf. Machine Learning. Intl. Conf. Machine LearningSundararajan, M.; Taly, A.; and Yan, Q. 2017. Axiomatic attribution for deep networks. In Proc. Intl. Conf. Machine Learning, 3319-3328.\n\nDigital twin-driven product design, manufacturing and service with big data. F Tao, J Cheng, Q Qi, M Zhang, H Zhang, F Sui, The International Journal of Advanced Manufacturing Technology. 949Tao, F.; Cheng, J.; Qi, Q.; Zhang, M.; Zhang, H.; and Sui, F. 2018. Digital twin-driven product design, manufacturing and service with big data. The International Journal of Ad- vanced Manufacturing Technology 94(9-12): 3563-3576.\n\nCounterfactual explanations without opening the black box: Automated decisions and the GDPR. S Wachter, B Mittelstadt, C Russell, Harvard Journal of Law & Technology. 31841Wachter, S.; Mittelstadt, B.; and Russell, C. 2017. Counter- factual explanations without opening the black box: Auto- mated decisions and the GDPR. Harvard Journal of Law & Technology 31: 841.\n\nAnomaly detection in the presence of missing values for weather data quality control. T Zemicheal, T G Dietterich, Proc. ACM SIGCAS Conf. Computing and Sustainable Societies. ACM SIGCAS Conf. Computing and Sustainable SocietiesZemicheal, T.; and Dietterich, T. G. 2019. Anomaly detec- tion in the presence of missing values for weather data qual- ity control. In Proc. ACM SIGCAS Conf. Computing and Sustainable Societies, 65-73.\n\nACE-An Anomaly Contribution Explainer for Cyber-Security Applications. X Zhang, M Marwah, I Lee, M Arlitt, D Goldwasser, Proc. IEEE Intl. Conf. Big Data. IEEE Intl. Conf. Big DataZhang, X.; Marwah, M.; Lee, I.-t.; Arlitt, M.; and Gold- wasser, D. 2019. ACE-An Anomaly Contribution Explainer for Cyber-Security Applications. In Proc. IEEE Intl. Conf. Big Data, 1991-2000.\n", "annotations": {"author": "[{\"end\":109,\"start\":52},{\"end\":170,\"start\":110},{\"end\":229,\"start\":171},{\"end\":309,\"start\":230},{\"end\":380,\"start\":310}]", "publisher": null, "author_last_name": "[{\"end\":64,\"start\":61},{\"end\":125,\"start\":115},{\"end\":184,\"start\":176},{\"end\":244,\"start\":239},{\"end\":319,\"start\":316}]", "author_first_name": "[{\"end\":60,\"start\":52},{\"end\":114,\"start\":110},{\"end\":175,\"start\":171},{\"end\":238,\"start\":230},{\"end\":315,\"start\":310}]", "author_affiliation": "[{\"end\":108,\"start\":66},{\"end\":169,\"start\":127},{\"end\":228,\"start\":186},{\"end\":308,\"start\":266},{\"end\":379,\"start\":337}]", "title": "[{\"end\":49,\"start\":1},{\"end\":429,\"start\":381}]", "venue": null, "abstract": "[{\"end\":1613,\"start\":431}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2018,\"start\":2001},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3922,\"start\":3886},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4357,\"start\":4333},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4369,\"start\":4357},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4387,\"start\":4369},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4848,\"start\":4813},{\"end\":5415,\"start\":5411},{\"end\":6767,\"start\":6749},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6924,\"start\":6903},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6954,\"start\":6929},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7121,\"start\":7097},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7133,\"start\":7121},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7151,\"start\":7133},{\"end\":7471,\"start\":7457},{\"end\":7492,\"start\":7471},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7529,\"start\":7492},{\"end\":7563,\"start\":7543},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7637,\"start\":7615},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7766,\"start\":7747},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7792,\"start\":7771},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8054,\"start\":8035},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8248,\"start\":8225},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8599,\"start\":8565},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8696,\"start\":8690},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8852,\"start\":8839},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8972,\"start\":8954},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9541,\"start\":9518},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9580,\"start\":9556},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9619,\"start\":9580},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10030,\"start\":10006},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10069,\"start\":10030},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15905,\"start\":15875},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16438,\"start\":16399},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":19420,\"start\":19394},{\"end\":21004,\"start\":21001},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":22623,\"start\":22588},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22947,\"start\":22923},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24301,\"start\":24282},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24327,\"start\":24301},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":24359,\"start\":24327},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24802,\"start\":24778},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":24841,\"start\":24802},{\"end\":26336,\"start\":26322}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33908,\"start\":33701},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34022,\"start\":33909},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34212,\"start\":34023},{\"attributes\":{\"id\":\"fig_3\"},\"end\":34310,\"start\":34213}]", "paragraph": "[{\"end\":2615,\"start\":1629},{\"end\":3653,\"start\":2617},{\"end\":5161,\"start\":3655},{\"end\":6505,\"start\":5163},{\"end\":7152,\"start\":6522},{\"end\":8384,\"start\":7154},{\"end\":9208,\"start\":8386},{\"end\":10131,\"start\":9210},{\"end\":10751,\"start\":10151},{\"end\":11238,\"start\":10753},{\"end\":11486,\"start\":11240},{\"end\":11877,\"start\":11488},{\"end\":12096,\"start\":11929},{\"end\":12694,\"start\":12098},{\"end\":13160,\"start\":12696},{\"end\":13795,\"start\":13162},{\"end\":14005,\"start\":13837},{\"end\":14294,\"start\":14050},{\"end\":15327,\"start\":14366},{\"end\":15472,\"start\":15329},{\"end\":16469,\"start\":15568},{\"end\":16527,\"start\":16471},{\"end\":16688,\"start\":16529},{\"end\":16894,\"start\":16794},{\"end\":17106,\"start\":16938},{\"end\":17591,\"start\":17108},{\"end\":17778,\"start\":17668},{\"end\":18069,\"start\":17820},{\"end\":18188,\"start\":18141},{\"end\":18587,\"start\":18225},{\"end\":19259,\"start\":18589},{\"end\":19587,\"start\":19350},{\"end\":19961,\"start\":19589},{\"end\":20100,\"start\":20047},{\"end\":20997,\"start\":20193},{\"end\":21030,\"start\":20999},{\"end\":21065,\"start\":21032},{\"end\":21224,\"start\":21179},{\"end\":21386,\"start\":21285},{\"end\":21955,\"start\":21408},{\"end\":21984,\"start\":21957},{\"end\":22388,\"start\":22073},{\"end\":22701,\"start\":22390},{\"end\":22827,\"start\":22717},{\"end\":23842,\"start\":22829},{\"end\":24973,\"start\":23844},{\"end\":26272,\"start\":24975},{\"end\":28587,\"start\":26274},{\"end\":29419,\"start\":28589},{\"end\":30309,\"start\":29474},{\"end\":30644,\"start\":30311},{\"end\":31087,\"start\":30646},{\"end\":31567,\"start\":31089},{\"end\":32377,\"start\":31569},{\"end\":33019,\"start\":32379},{\"end\":33700,\"start\":33035}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11928,\"start\":11878},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14365,\"start\":14295},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15567,\"start\":15473},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16793,\"start\":16689},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17667,\"start\":17592},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17819,\"start\":17779},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18140,\"start\":18070},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19349,\"start\":19260},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20046,\"start\":19962},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20192,\"start\":20101},{\"attributes\":{\"id\":\"formula_11\"},\"end\":21178,\"start\":21066},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21284,\"start\":21225},{\"attributes\":{\"id\":\"formula_13\"},\"end\":22066,\"start\":21985}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1627,\"start\":1615},{\"attributes\":{\"n\":\"2\"},\"end\":6520,\"start\":6508},{\"attributes\":{\"n\":\"3\"},\"end\":10149,\"start\":10134},{\"attributes\":{\"n\":\"4\"},\"end\":13835,\"start\":13798},{\"attributes\":{\"n\":\"4.1\"},\"end\":14048,\"start\":14008},{\"attributes\":{\"n\":\"4.2\"},\"end\":16936,\"start\":16897},{\"attributes\":{\"n\":\"4.3\"},\"end\":18223,\"start\":18191},{\"attributes\":{\"n\":\"4.4\"},\"end\":21406,\"start\":21389},{\"end\":22071,\"start\":22068},{\"attributes\":{\"n\":\"5\"},\"end\":22715,\"start\":22704},{\"end\":29472,\"start\":29422},{\"attributes\":{\"n\":\"6\"},\"end\":33033,\"start\":33022},{\"end\":33722,\"start\":33702},{\"end\":33920,\"start\":33910},{\"end\":34044,\"start\":34024},{\"end\":34224,\"start\":34214}]", "table": null, "figure_caption": "[{\"end\":33908,\"start\":33725},{\"end\":34022,\"start\":33922},{\"end\":34212,\"start\":34047},{\"end\":34310,\"start\":34226}]", "figure_ref": "[{\"end\":5471,\"start\":5463},{\"end\":5976,\"start\":5970},{\"end\":13925,\"start\":13919},{\"end\":18528,\"start\":18522},{\"end\":20532,\"start\":20522},{\"end\":25270,\"start\":25260},{\"end\":25684,\"start\":25672},{\"end\":25771,\"start\":25763},{\"end\":26169,\"start\":26163},{\"end\":26271,\"start\":26265},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":26665,\"start\":26659},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":26963,\"start\":26957},{\"end\":27120,\"start\":27112},{\"end\":28078,\"start\":28072},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":28130,\"start\":28124},{\"end\":30999,\"start\":30993},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":31185,\"start\":31179},{\"end\":31697,\"start\":31691},{\"end\":32187,\"start\":32181}]", "bib_author_first_name": "[{\"end\":35489,\"start\":35488},{\"end\":35515,\"start\":35514},{\"end\":35525,\"start\":35524},{\"end\":35924,\"start\":35923},{\"end\":35932,\"start\":35931},{\"end\":35942,\"start\":35941},{\"end\":35954,\"start\":35953},{\"end\":35970,\"start\":35966},{\"end\":35980,\"start\":35979},{\"end\":36225,\"start\":36224},{\"end\":36333,\"start\":36332},{\"end\":36498,\"start\":36497},{\"end\":36513,\"start\":36512},{\"end\":36523,\"start\":36522},{\"end\":36964,\"start\":36963},{\"end\":36976,\"start\":36975},{\"end\":36988,\"start\":36987},{\"end\":37210,\"start\":37209},{\"end\":37224,\"start\":37223},{\"end\":37237,\"start\":37236},{\"end\":37249,\"start\":37248},{\"end\":37260,\"start\":37259},{\"end\":37269,\"start\":37268},{\"end\":37282,\"start\":37281},{\"end\":37679,\"start\":37678},{\"end\":37696,\"start\":37692},{\"end\":37704,\"start\":37703},{\"end\":37715,\"start\":37711},{\"end\":37721,\"start\":37720},{\"end\":37729,\"start\":37728},{\"end\":37742,\"start\":37741},{\"end\":38121,\"start\":38120},{\"end\":38123,\"start\":38122},{\"end\":38131,\"start\":38130},{\"end\":38378,\"start\":38377},{\"end\":38386,\"start\":38385},{\"end\":38395,\"start\":38394},{\"end\":38409,\"start\":38408},{\"end\":38419,\"start\":38418},{\"end\":38820,\"start\":38819},{\"end\":38831,\"start\":38830},{\"end\":39220,\"start\":39219},{\"end\":39230,\"start\":39229},{\"end\":39244,\"start\":39243},{\"end\":39558,\"start\":39557},{\"end\":39569,\"start\":39568},{\"end\":39582,\"start\":39581},{\"end\":39933,\"start\":39932},{\"end\":39942,\"start\":39941},{\"end\":39951,\"start\":39950},{\"end\":40383,\"start\":40382},{\"end\":40385,\"start\":40384},{\"end\":40400,\"start\":40396},{\"end\":40648,\"start\":40647},{\"end\":40720,\"start\":40719},{\"end\":40730,\"start\":40729},{\"end\":40985,\"start\":40984},{\"end\":40987,\"start\":40986},{\"end\":40998,\"start\":40997},{\"end\":41007,\"start\":41006},{\"end\":41410,\"start\":41409},{\"end\":41412,\"start\":41411},{\"end\":41423,\"start\":41422},{\"end\":41432,\"start\":41431},{\"end\":41781,\"start\":41780},{\"end\":41788,\"start\":41787},{\"end\":42059,\"start\":42058},{\"end\":42068,\"start\":42067},{\"end\":42080,\"start\":42079},{\"end\":42091,\"start\":42090},{\"end\":42093,\"start\":42092},{\"end\":42106,\"start\":42102},{\"end\":42437,\"start\":42436},{\"end\":42775,\"start\":42774},{\"end\":42788,\"start\":42787},{\"end\":43095,\"start\":43094},{\"end\":43108,\"start\":43107},{\"end\":43378,\"start\":43377},{\"end\":43394,\"start\":43393},{\"end\":43404,\"start\":43401},{\"end\":43408,\"start\":43407},{\"end\":43691,\"start\":43690},{\"end\":43698,\"start\":43697},{\"end\":43707,\"start\":43706},{\"end\":43713,\"start\":43712},{\"end\":43722,\"start\":43721},{\"end\":43731,\"start\":43730},{\"end\":44130,\"start\":44129},{\"end\":44141,\"start\":44140},{\"end\":44156,\"start\":44155},{\"end\":44490,\"start\":44489},{\"end\":44503,\"start\":44502},{\"end\":44505,\"start\":44504},{\"end\":44906,\"start\":44905},{\"end\":44915,\"start\":44914},{\"end\":44925,\"start\":44924},{\"end\":44932,\"start\":44931},{\"end\":44942,\"start\":44941}]", "bib_author_last_name": "[{\"end\":35512,\"start\":35490},{\"end\":35522,\"start\":35516},{\"end\":35531,\"start\":35526},{\"end\":35929,\"start\":35925},{\"end\":35939,\"start\":35933},{\"end\":35951,\"start\":35943},{\"end\":35964,\"start\":35955},{\"end\":35977,\"start\":35971},{\"end\":35986,\"start\":35981},{\"end\":36233,\"start\":36226},{\"end\":36510,\"start\":36499},{\"end\":36520,\"start\":36514},{\"end\":36530,\"start\":36524},{\"end\":36973,\"start\":36965},{\"end\":36985,\"start\":36977},{\"end\":36994,\"start\":36989},{\"end\":37221,\"start\":37211},{\"end\":37234,\"start\":37225},{\"end\":37246,\"start\":37238},{\"end\":37257,\"start\":37250},{\"end\":37266,\"start\":37261},{\"end\":37279,\"start\":37270},{\"end\":37289,\"start\":37283},{\"end\":37690,\"start\":37680},{\"end\":37701,\"start\":37697},{\"end\":37709,\"start\":37705},{\"end\":37718,\"start\":37716},{\"end\":37726,\"start\":37722},{\"end\":37739,\"start\":37730},{\"end\":37746,\"start\":37743},{\"end\":38128,\"start\":38124},{\"end\":38139,\"start\":38132},{\"end\":38383,\"start\":38379},{\"end\":38392,\"start\":38387},{\"end\":38406,\"start\":38396},{\"end\":38416,\"start\":38410},{\"end\":38424,\"start\":38420},{\"end\":38828,\"start\":38821},{\"end\":38840,\"start\":38832},{\"end\":39227,\"start\":39221},{\"end\":39241,\"start\":39231},{\"end\":39253,\"start\":39245},{\"end\":39566,\"start\":39559},{\"end\":39579,\"start\":39570},{\"end\":39591,\"start\":39583},{\"end\":39939,\"start\":39934},{\"end\":39948,\"start\":39943},{\"end\":39960,\"start\":39952},{\"end\":40394,\"start\":40386},{\"end\":40404,\"start\":40401},{\"end\":40655,\"start\":40649},{\"end\":40727,\"start\":40721},{\"end\":40735,\"start\":40731},{\"end\":40995,\"start\":40988},{\"end\":41004,\"start\":40999},{\"end\":41016,\"start\":41008},{\"end\":41420,\"start\":41413},{\"end\":41429,\"start\":41424},{\"end\":41441,\"start\":41433},{\"end\":41785,\"start\":41782},{\"end\":41800,\"start\":41789},{\"end\":42065,\"start\":42060},{\"end\":42077,\"start\":42069},{\"end\":42088,\"start\":42081},{\"end\":42100,\"start\":42094},{\"end\":42113,\"start\":42107},{\"end\":42444,\"start\":42438},{\"end\":42785,\"start\":42776},{\"end\":42798,\"start\":42789},{\"end\":43105,\"start\":43096},{\"end\":43118,\"start\":43109},{\"end\":43391,\"start\":43379},{\"end\":43399,\"start\":43395},{\"end\":43695,\"start\":43692},{\"end\":43704,\"start\":43699},{\"end\":43710,\"start\":43708},{\"end\":43719,\"start\":43714},{\"end\":43728,\"start\":43723},{\"end\":43735,\"start\":43732},{\"end\":44138,\"start\":44131},{\"end\":44153,\"start\":44142},{\"end\":44164,\"start\":44157},{\"end\":44500,\"start\":44491},{\"end\":44516,\"start\":44506},{\"end\":44912,\"start\":44907},{\"end\":44922,\"start\":44916},{\"end\":44929,\"start\":44926},{\"end\":44939,\"start\":44933},{\"end\":44953,\"start\":44943}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":52007797},\"end\":35821,\"start\":35424},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":9327892},\"end\":36220,\"start\":35823},{\"attributes\":{\"id\":\"b2\"},\"end\":36248,\"start\":36222},{\"attributes\":{\"id\":\"b3\"},\"end\":36438,\"start\":36250},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":4938861},\"end\":36932,\"start\":36440},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":207172599},\"end\":37131,\"start\":36934},{\"attributes\":{\"id\":\"b6\"},\"end\":37582,\"start\":37133},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3401346},\"end\":38048,\"start\":37584},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1633753},\"end\":38373,\"start\":38050},{\"attributes\":{\"id\":\"b9\"},\"end\":38487,\"start\":38375},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":218522539},\"end\":38739,\"start\":38489},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":207756954},\"end\":39139,\"start\":38741},{\"attributes\":{\"id\":\"b12\"},\"end\":39423,\"start\":39141},{\"attributes\":{\"id\":\"b13\"},\"end\":39851,\"start\":39425},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":208310368},\"end\":40326,\"start\":39853},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":21889700},\"end\":40613,\"start\":40328},{\"attributes\":{\"id\":\"b16\"},\"end\":40715,\"start\":40615},{\"attributes\":{\"id\":\"b17\"},\"end\":40911,\"start\":40717},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":13029170},\"end\":41354,\"start\":40913},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":3366554},\"end\":41690,\"start\":41356},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":51945079},\"end\":41984,\"start\":41692},{\"attributes\":{\"id\":\"b21\"},\"end\":42316,\"start\":41986},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":220646832},\"end\":42698,\"start\":42318},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":14451872},\"end\":43008,\"start\":42700},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":2449098},\"end\":43334,\"start\":43010},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":16747630},\"end\":43611,\"start\":43336},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":114484028},\"end\":44034,\"start\":43613},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":3995299},\"end\":44401,\"start\":44036},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":52165697},\"end\":44832,\"start\":44403},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":208527759},\"end\":45204,\"start\":44834}]", "bib_title": "[{\"end\":35486,\"start\":35424},{\"end\":35921,\"start\":35823},{\"end\":36495,\"start\":36440},{\"end\":36961,\"start\":36934},{\"end\":37207,\"start\":37133},{\"end\":37676,\"start\":37584},{\"end\":38118,\"start\":38050},{\"end\":38557,\"start\":38489},{\"end\":38817,\"start\":38741},{\"end\":39930,\"start\":39853},{\"end\":40380,\"start\":40328},{\"end\":40982,\"start\":40913},{\"end\":41407,\"start\":41356},{\"end\":41778,\"start\":41692},{\"end\":42434,\"start\":42318},{\"end\":42772,\"start\":42700},{\"end\":43092,\"start\":43010},{\"end\":43375,\"start\":43336},{\"end\":43688,\"start\":43613},{\"end\":44127,\"start\":44036},{\"end\":44487,\"start\":44403},{\"end\":44903,\"start\":44834}]", "bib_author": "[{\"end\":35514,\"start\":35488},{\"end\":35524,\"start\":35514},{\"end\":35533,\"start\":35524},{\"end\":35931,\"start\":35923},{\"end\":35941,\"start\":35931},{\"end\":35953,\"start\":35941},{\"end\":35966,\"start\":35953},{\"end\":35979,\"start\":35966},{\"end\":35988,\"start\":35979},{\"end\":36235,\"start\":36224},{\"end\":36336,\"start\":36332},{\"end\":36512,\"start\":36497},{\"end\":36522,\"start\":36512},{\"end\":36532,\"start\":36522},{\"end\":36975,\"start\":36963},{\"end\":36987,\"start\":36975},{\"end\":36996,\"start\":36987},{\"end\":37223,\"start\":37209},{\"end\":37236,\"start\":37223},{\"end\":37248,\"start\":37236},{\"end\":37259,\"start\":37248},{\"end\":37268,\"start\":37259},{\"end\":37281,\"start\":37268},{\"end\":37291,\"start\":37281},{\"end\":37692,\"start\":37678},{\"end\":37703,\"start\":37692},{\"end\":37711,\"start\":37703},{\"end\":37720,\"start\":37711},{\"end\":37728,\"start\":37720},{\"end\":37741,\"start\":37728},{\"end\":37748,\"start\":37741},{\"end\":38130,\"start\":38120},{\"end\":38141,\"start\":38130},{\"end\":38385,\"start\":38377},{\"end\":38394,\"start\":38385},{\"end\":38408,\"start\":38394},{\"end\":38418,\"start\":38408},{\"end\":38426,\"start\":38418},{\"end\":38830,\"start\":38819},{\"end\":38842,\"start\":38830},{\"end\":39229,\"start\":39219},{\"end\":39243,\"start\":39229},{\"end\":39255,\"start\":39243},{\"end\":39568,\"start\":39557},{\"end\":39581,\"start\":39568},{\"end\":39593,\"start\":39581},{\"end\":39941,\"start\":39932},{\"end\":39950,\"start\":39941},{\"end\":39962,\"start\":39950},{\"end\":40396,\"start\":40382},{\"end\":40406,\"start\":40396},{\"end\":40657,\"start\":40647},{\"end\":40729,\"start\":40719},{\"end\":40737,\"start\":40729},{\"end\":40997,\"start\":40984},{\"end\":41006,\"start\":40997},{\"end\":41018,\"start\":41006},{\"end\":41422,\"start\":41409},{\"end\":41431,\"start\":41422},{\"end\":41443,\"start\":41431},{\"end\":41787,\"start\":41780},{\"end\":41802,\"start\":41787},{\"end\":42067,\"start\":42058},{\"end\":42079,\"start\":42067},{\"end\":42090,\"start\":42079},{\"end\":42102,\"start\":42090},{\"end\":42115,\"start\":42102},{\"end\":42446,\"start\":42436},{\"end\":42787,\"start\":42774},{\"end\":42800,\"start\":42787},{\"end\":43107,\"start\":43094},{\"end\":43120,\"start\":43107},{\"end\":43393,\"start\":43377},{\"end\":43401,\"start\":43393},{\"end\":43407,\"start\":43401},{\"end\":43411,\"start\":43407},{\"end\":43697,\"start\":43690},{\"end\":43706,\"start\":43697},{\"end\":43712,\"start\":43706},{\"end\":43721,\"start\":43712},{\"end\":43730,\"start\":43721},{\"end\":43737,\"start\":43730},{\"end\":44140,\"start\":44129},{\"end\":44155,\"start\":44140},{\"end\":44166,\"start\":44155},{\"end\":44502,\"start\":44489},{\"end\":44518,\"start\":44502},{\"end\":44914,\"start\":44905},{\"end\":44924,\"start\":44914},{\"end\":44931,\"start\":44924},{\"end\":44941,\"start\":44931},{\"end\":44955,\"start\":44941}]", "bib_venue": "[{\"end\":35625,\"start\":35583},{\"end\":36704,\"start\":36622},{\"end\":38213,\"start\":38181},{\"end\":38946,\"start\":38898},{\"end\":40109,\"start\":40044},{\"end\":41142,\"start\":41084},{\"end\":41535,\"start\":41493},{\"end\":42510,\"start\":42482},{\"end\":43475,\"start\":43447},{\"end\":44630,\"start\":44578},{\"end\":45013,\"start\":44988},{\"end\":35581,\"start\":35533},{\"end\":35996,\"start\":35988},{\"end\":36330,\"start\":36250},{\"end\":36620,\"start\":36532},{\"end\":37016,\"start\":36996},{\"end\":37343,\"start\":37291},{\"end\":37797,\"start\":37748},{\"end\":38179,\"start\":38141},{\"end\":38602,\"start\":38559},{\"end\":38896,\"start\":38842},{\"end\":39217,\"start\":39141},{\"end\":39555,\"start\":39425},{\"end\":40042,\"start\":39962},{\"end\":40455,\"start\":40406},{\"end\":40645,\"start\":40615},{\"end\":40796,\"start\":40737},{\"end\":41082,\"start\":41018},{\"end\":41491,\"start\":41443},{\"end\":41819,\"start\":41802},{\"end\":42056,\"start\":41986},{\"end\":42480,\"start\":42446},{\"end\":42836,\"start\":42800},{\"end\":43153,\"start\":43120},{\"end\":43445,\"start\":43411},{\"end\":43799,\"start\":43737},{\"end\":44201,\"start\":44166},{\"end\":44576,\"start\":44518},{\"end\":44986,\"start\":44955}]"}}}, "year": 2023, "month": 12, "day": 17}