{"id": 258479779, "updated": "2023-11-08 16:58:05.635", "metadata": {"title": "Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study", "authors": "[{\"first\":\"Sajjad\",\"last\":\"Rahmani\",\"middle\":[]},{\"first\":\"AmirHossein\",\"last\":\"Naghshzan\",\"middle\":[]},{\"first\":\"Latifa\",\"last\":\"Guerrouj\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Our research investigates the recommendation of code examples to aid software developers, a practice that saves developers significant time by providing ready-to-use code snippets. The focus of our study is Stack Overflow, a commonly used resource for coding discussions and solutions, particularly in the context of the Java programming language. We applied BERT, a powerful Large Language Model (LLM) that enables us to transform code examples into numerical vectors by extracting their semantic information. Once these numerical representations are prepared, we identify Approximate Nearest Neighbors (ANN) using Locality-Sensitive Hashing (LSH). Our research employed two variants of LSH: Random Hyperplane-based LSH and Query-Aware LSH. We rigorously compared these two approaches across four parameters: HitRate, Mean Reciprocal Rank (MRR), Average Execution Time, and Relevance. Our study revealed that the Query-Aware (QA) approach showed superior performance over the Random Hyperplane-based (RH) method. Specifically, it exhibited a notable improvement of 20% to 35% in HitRate for query pairs compared to the RH approach. Furthermore, the QA approach proved significantly more time-efficient, with its speed in creating hashing tables and assigning data samples to buckets being at least four times faster. It can return code examples within milliseconds, whereas the RH approach typically requires several seconds to recommend code examples. Due to the superior performance of the QA approach, we tested it against PostFinder and FaCoY, the state-of-the-art baselines. Our QA method showed comparable efficiency proving its potential for effective code recommendation.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2305.03017", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2305-03017", "doi": "10.48550/arxiv.2305.03017"}}, "content": {"source": {"pdf_hash": "d91413b011141a2312e727b8c9ae1a9b2d2b43f9", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2305.03017v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "9fd274510daa87d16e2502a1de9f194389636470", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d91413b011141a2312e727b8c9ae1a9b2d2b43f9.txt", "contents": "\nImproving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study\n\n\nSajjad Rahmani sajjad.rahmani.1@ens.etsmtl.ca \nEcole de technologie superieure Montreal\nCanada\n\nAmirhossein Naghshzan amirhossein.naghshzan.1@ens.etsmtl.ca \nEcole de technologie superieure Montreal\nCanada\n\nLatifa Guerrouj latifa.guerrouj@etsmtl.ca \nEcole de technologie superieure Montreal\nCanada\n\nImproving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study\nIndex Terms-Stack OverflowBERTLSHANNHitRateMRRLLMRelevance\nOur research investigates the recommendation of code examples to aid software developers, a practice that saves developers significant time by providing ready-to-use code snippets. The focus of our study is Stack Overflow, a commonly used resource for coding discussions and solutions, particularly in the context of the Java programming language.We applied BERT, a powerful Large Language Model (LLM) that enables us to transform code examples into numerical vectors by extracting their semantic information. Once these numerical representations are prepared, we identify Approximate Nearest Neighbors (ANN) using Locality-Sensitive Hashing (LSH). Our research employed two variants of LSH: Random Hyperplanebased LSH and Query-Aware LSH. We rigorously compared these two approaches across four parameters: HitRate, Mean Reciprocal Rank (MRR), Average Execution Time, and Relevance.Our study revealed that the Query-Aware (QA) approach showed superior performance over the Random Hyperplanebased (RH) method. Specifically, it exhibited a notable improvement of 20% to 35% in HitRate for query pairs compared to the RH approach. Furthermore, the QA approach proved significantly more time-efficient, with its speed in creating hashing tables and assigning data samples to buckets being at least four times faster. It can return code examples within milliseconds, whereas the RH approach typically requires several seconds to recommend code examples. Due to the superior performance of the QA approach, we tested it against PostFinder and FaCoY, the state-of-the-art baselines. Our QA method showed comparable efficiency proving its potential for effective code recommendation.\n\nI. INTRODUCTION\n\nRecommendation systems have become ubiquitous in various fields to enhance task efficiency and quality. Zhou et al. [27] note that software developers frequently write similar code examples multiple times due to the need to implement comparable functionalities in different projects. Therefore, during the software development process, a recommendation system can assist programmers in completing their tasks quickly and effectively by presenting them with the most pertinent and high-quality examples written by other programmers [2]. Open-source projects and informal documentation are the two main sources of information that developers rely on to perform programming tasks. For instance, GitHub provides open-source projects that offer code examples for various tasks and code resources for use.\n\nInformal documentation, as opposed to Open-Source projects, comprises data sources that developers use to exchange information and ideas about various tasks. These sources may include incomplete code examples such as bug reports, emails, and Stack Overflow posts [21]. However, code examples in informal documentation are typically trapped in natural language comments, which can make it challenging to extract relevant code entities and elements. Therefore, the objective of this paper is to propose a recommendation system that can suggest relevant code examples from Stack Overflow based on developers' needs and tasks. Stack Overflow was chosen as the data source for the recommendation system as it is one of the most popular resources among developers for addressing programming issues [22]. The research specifically targets Java code examples posted on Stack Overflow in response to questions, between 2008 and May 2022, and preserved in dump files. Once pre-processing is done, the code examples are translated into numerical vectors using the BERT model, followed by the execution of two LSH-based algorithms: Random Hyperplane-based LSH and Query-Aware LSH, to minimize the search space and detect code examples that are similar to a user's query. Our decision to use both BERT and LSH was motivated by two key factors. Firstly, BERT has demonstrated its ability to extract semantic information from natural language texts in various applications, including cross-lingual translation [3], [39]. We believe that this capability can also be leveraged to extract semantic information from code examples and identify similarities between them. Secondly, due to the large amount of data samples exceeding 60K, it can be a tedious task to locate relevant code examples. However, LSH-based approaches like Random Hyperplane-based and Query-Aware can be utilized to minimize the search space and facilitate the process of discovering relevant code examples. Our focus in this paper is to evaluate the performance of our LSH-based algorithms by exploring three main research questions: RQ1: How do the Random Hyperplane-based LSH and \n\n\nA. Informal Documentation\n\nInfoZilla [15], aims to extract various components from bug reports, including patches, Stack traces, source code, and enumerations. To extract code elements, this approach employs an island parser based on the concept of islands within the sea, which searches for islands based on identifiers. The term \"island\" in this context refers to classes, conditional statements, functions, and assignments that can be used to locate code elements in discussions. The island parser used by InfoZilla is based on the works of Moonen et al. [16] and Bacchelli et al. [17]. Our approach differs from this research in that we do not utilize an island parser to identify code entities within discussions. Instead, we focus on extracting code examples from Stack Overflow posts that are enclosed by \u00a1code\u00bf tags. The purpose of this effort is to gather and suggest high-quality code examples according to the needs of developers.\n\nACE [18] utilizes the island parser concept along with naming conventions, such as Camel Case, to extract code elements that are embedded within informal documentation. This approach employs an island parser to locate Java code elements within Stack Overflow posts. ACE searches for qualified terms in the posts, including package names, variable declarations, and qualified variables, as well as class concepts like inheritance, constructors, and exceptions.\n\nDiamantopoulos et al. [19] have proposed an approach to extract code entities from Stack Overflow posts. This approach extracts three types of entities from Stack Overflow, i.e., Java code examples, including Assignments (AM), Function calls (FC), and Class instantiations (CI). Our approach utilizes the attention mechanism [4] implemented in the BERT model to identify similar code examples based on their semantic similarity rather than relying solely on code entities such as classes, variables, and functions.\n\nNaghshzan et al. [5], [6] presented a new approach to generating natural language summaries for Android API methods using Stack Overflow discussions. The approach was evaluated through a survey of 16 developers and found to be a useful complementary source of information for software development and maintenance tasks. The study contributes to the field of code summarization and highlights the potential of unofficial documentation in the process.\n\nAbdalkareem et al. [20] have proposed a method for extracting code examples from Stack Overflow posts by filtering special tags. The technique involves encoding the bodies of Stack Overflow posts in HTML, which allows for the identification of code examples embedded within <code>tags through a process of filtering. We have applied this approach in our work as our dataset had the same structure as its and the code element extraction method was applicable in our work for filtering code examples that were trapped inside Stack Overflow posts.\n\nKim et al. [21] presented FaCoY, which is a code-to-code recommendation system designed to identify code examples that are semantically similar to the query code. This work suffers from the drawback of producing a significant number of false positives, i.e., returning a large number of irrelevant Stack Overflow posts as a result.\n\nThe study by Rubei et al. [22] introduces PostFinder, a recommendation system plugin for Eclipse IDE that extracts contextual information from a developing project and Stack Overflow posts to provide recommendations for software developers.\n\n\nB. Open-source projects\n\nNguyen et al. [23] proposed FOCUS (API FunctiOn Calls and USage patterns) as a method to suggest a group of methods that are frequently utilized together by developers while working with particular APIs in their development projects. The suggested methods are accompanied by usage patterns that serve as a reference for developers to complete their coding tasks. This approach recommends API methods based on the collaborative filtering concept. Using FOCUS, developers receive recommendations for relevant API invocations and code examples as useful references.\n\nWang et al. [24] introduced UP-Miner (Usage-pattern Miner), which mines commonly used API methods from source code by applying BI-Directional Extension(BIDE) algorithm [11].\n\nGu et al. [25] developed DeepAPI, a deep learning-based approach that generates API usage sequences by applying RNN Encoder-Decoder [10]. DeepAPI has relied on GitHub and JavaDoc to provide recommendations for code examples and overlooked valuable sources of informal documentation such as Stack Overflow. Our method, on the other hand, takes advantage of Stack Overflow by utilizing code examples tagged as answers to questions.\n\nRaychev et al. [26] proposed an approach for code completion that utilizes neural networks. The primary concept of their approach is to employ a natural language processing model to forecast probabilities of sentences while searching for sequences of method invocations to complete the code.\n\nZhou et al. [27] developed Lancer, a code-to-code recommendation system that utilizes the BERT model to address the Out Of Vocabulary (OOV) problem in code recommendation. Additionally, the approach employs the PageRank algorithm [12] to discover relevant libraries that are used together. In contrast to Lancer, which utilizes open-source projects, our approach concentrates on recommending code examples from Stack Overflow. Additionally, we employ a hybrid approach that involves the use of both BERT and LSH algorithms, as opposed to PageRank and BERT. Although our methodology differs from theirs, we employ the same evaluation metrics, specifically the HitRate parameter, to assess the effectiveness of our recommended code examples.\n\n\nC. Locality Sensitive Hashing for Recommendation Systems\n\nDing et al. [28] utilized a combination of graph search and Locality-Sensitive Hashing (LSH) to locate similar instances of assembly code. Specifically, their approach involved using a hybrid strategy that relied on assembly code sources, especially when the main source code was not available. This technique, referred to as Adaptive LSH (ALSH), employed a tree structure to conduct the search. Upon receiving a query (q), the algorithm located the leaf node in various prefix trees. After a sufficient number of points had been identified, the subtrees were divided, and the search moved up a level, eliminating the least similar samples to decrease the search space.\n\nSilavong et al. [29] introduced a code-to-code recommendation system that employs Locality Sensitive Hashing. The research utilizes ANTLR (ANother Tool for Language Recognition) to extract the Abstract Syntax Tree (AST) of code examples and then generates the Simplified Parse Tree (SPT) of the extracted structure. The system is query-based and relies on Minwise Hashing, which is based on four feature sets: Token, Parent, Sibling, and Variable Usages.\n\nZhang et al. [30] introduced a recommendation system that uses both Locality Sensitive Hashing (LSH) and Collaborative Filtering (CF) simultaneously. To address issues related to time, space, and accuracy, they utilized a hybrid approach that combined minHash and SimHash to generate a signature matrix. The system then assigned signatures to buckets, grouping the most similar items in the same buckets.\n\nAytekin et al. [31] presented an updated version of Locality Sensitive Hashing (LSH) that can be used to develop a recommendation system with high accuracy, even when working with vast amounts of data. Their approach is faster than the standard LSH and recommends more diverse candidates.\n\nIII. METHODOLOGY In this section, we will describe the main steps of our methodology for recommending code examples using Stack Overflow: Data collection, data preprocessing, Extraction of code examples, applying the BERT model, using LSH algorithms for recommending code examples,s and model assessment.\n\n\nA. Data Collection\n\nOur input dataset consists of Stack Overflow posts, which are among the most widely-used sources for accessing discussions related to various API methods in different programming languages. To carry out our work, we downloaded Stack Overflow dump files. The dump files we obtained encompass all the discussions posted on Stack Overflow from 2008 to 2022. Similar to the approach followed in the study by Kim et al. [21], we have retrieved the archived dump files of Stack Overflow posts and imported them into an SQL Server database.\n\n\nB. Data Pre-processing\n\nOnce the dataset was imported into an SQL database for organizational purposes, we proceeded to clean the data. This involved pre-processing the data to prepare it for the next step. To achieve this, we followed a four-step process.\n\nStep 1: When we attempted to filter Stack Overflow posts that contained Java code examples using the Java tag, we found that many posts labeled with Java also included code examples in other programming languages such as Javascript and C. Therefore, we filtered the posts to only include those that had Java code examples and excluded any that incorporated examples of other programming languages.\n\nStep 2: Our database contains rows that represent posts and each row has 20 columns that display various aspects of a post. To obtain the posts necessary for our analysis, we have used the columns Id, AcceptedAnswerId, and Score for filtering. Id is a post's unique identifier and AcceptedAnswerId indicates the Id of the post that is marked as the answer to a question post. Typically, most question posts have corresponding answer posts, and the AcceptedAnswerId of the answer post is recorded in the database. The valid AcceptedAnswerId values are stored in a table within the database for use in the subsequent steps.\n\nStep 3: During this step, the answer posts are retrieved from the SQL database by filtering the posts where the \"Id\" equals the \"AcceptedAnswerId\". However, it is important to note that some questions on Stack Overflow may not have any answers, resulting in an empty \"AcceptedAnswerId\" field in those particular rows.\n\nStep 4: After the filtration process in the previous steps, the resulting dataset contains Answer posts that have been specifically labeled by developers and their corresponding scores, indicating the level of approval and popularity among other users. we further applied a threshold on the score values and selected posts with scores greater than or equal to 2.\n\n\nC. Extraction of Code Examples from Informal Documentation\n\nFollowing the extraction of answer posts, it was necessary to extract code examples due to their integration with natural language comments. To achieve this, we filtered the code by identifying <pre><code> and </code></pre> tags within the posts to extract relevant examples. We replicated the approach suggested by Abdalkareem et al. [20] for code\n\n\nModel Assessment\n\nRecommending Code Examples Using LSH Applying Bert Model  example extraction from Stack Overflow posts during this process. Table I demonstrates a summary of followed steps for filtering high-quality posts which were accomplished during steps 2 and 3 of our methodology.\n\n\nD. Applying BERT model\n\nWe utilized the sentence transformers framework in Python to applying the BERT model to our extracted code examples. This framework allows for the representation of text and images as dense numerical vectors. Our research used the pretrained BERT model, which has been made publicly accessible in over 100 languages. We fine-tuned this model based on our dataset. Each code example sample was fed as input to BERT, which combined token-based and semantic-based information to create a uniform (1*768) vector.\n\n\nE. Recommending Code Examples Using LSH\n\nAfter embedding code examples into numerical vectors, we have applied two LSH algorithms, namely the Random Hyperplane-based approach and the Query-aware approach, to tackle our problem. The former assigns data samples into different buckets without taking the query into account, whereas the latter considers the query when assigning data samples. We incorporated both methods in our methodology and compared their outcomes, as previous research, has suggested that the Query-Aware approach (i.e., the second algorithm) performs better than Query-Oblivious approaches (i.e., the first algorithm) in retrieving data samples similar to a given query [32].\n\n\n1) Random Hyperplane-based LSH:\n\nTo recommend code examples for API methods, we utilized Algorithm 1 from the work of Charikar et al. [33] to perform dimensionality reduction of numerical vectors from high to lower dimensions. The resulting numbers were converted from decimal to binary values and sorted into buckets based on their binary values. This approach helped to find similar items to a given query, whether it be a natural language question or an API method, in a lower-dimensional space, using both data samples (code examples) and query vectors.\n\nTo explain the Random Hyperplane-based LSH algorithm, we followed the steps outlined in Algorithm 1. In this algorithm, data samples' vectors (D) are multiplied by randomized vectors (R), and the number of hash tables (M) determines how many times this process is repeated. This reduces the dimensionality of the data samples by mapping them to a lower dimension (k) (step 4). The resulting values are converted to binary values of 1 and 0 based on whether they are greater than or less than 0 (steps 5 and 6) and assigned to buckets based on their binary values (step 7).\n\nThe same process is applied to the query vector, and the resulting vector is also assigned to a bucket (steps 9 to 13). Data samples with the same bucket ID as the query vector are collected from all hash tables, and the cosine similarity between each data sample and the query vector is calculated and ranked based on their similarity values (from top to bottom) (step 15). Finally, the top N recommendations are returned to the user based on the number of recommendations (step 16).\n\nTo perform the mapping of data samples from a higher dimension to a lower one, we used random vectors of dimension (768 * d) that followed a Gaussian distribution. This is in line with Charikar's approach of using Gaussian distribution to create random vectors for mapping data samples to ddimensional vectors.\n\n2) Query-aware approach: Query-oblivious methods assign data samples to buckets without taking into account the query, which may result in similar data samples being filtered out from the candidate set for the query. To address this issue, Huang et al. [32] proposed the Query-Aware LSH, where the query plays a role in assigning objects (data samples) to query bucket partitions. Similar to the Random Hyperplanebased algorithm, the Query-Aware algorithm is applied to code examples as data samples and natural language questions or API methods as queries. The Query-Aware approach resolves the problem of random shift that occurs when mapping data samples to a lower-dimensional space to assign them to buckets in traditional Query-Oblivious LSH algorithms. For example, E2LSH [7] applies a random shift (b) after mapping the data sample into a lower-dimensional space. This random shift may negatively affect the process of finding the most similar data samples and assigning them to different buckets  For Data Samples: 4: ResultN * K \u2190 DN * 768 * R768 * K ;\n\n\n5:\n\nSgnResult \u2190 Sign(ResultN * K ); 6: if the items of the SgnResult are negative assign 0, otherwise they are already 1;\n\n\n7:\n\nBucketId \u2190 k1 2 i * SgnResult[i]; 8: For Query Vector: 9: For Q as Query vector and R as a Randomized vector;\n\n\n10:\n\nQResultN * K \u2190 Q1 * 768 * R768 * K ;\n\n\n11:\n\nSgnQRes \u2190 Sign(QResultN * K ); 12: if the items of the SgnQRes are negative assign 0, otherwise they are already 1; Increase #Col(Oi) if the |Hi(Oi) Hi(q)| <= w/2; 5: if #Col(Oi) \u2265 l then 6:\nC = C \u222a Oi; 7:\nend if 8: end for 9: Calculate the Euclidean distance between Oi in C and q 10: Sort the Euclidean distances incrementally; 11: Retrieve the top N candidates as recommendation items from the sorted list;\n\n14: end for 15: Retrieve the samples (u) that are at the same bucket as query vector (q) from all of the hash tables and rank them based on Cosine similarity; 16: Retrieve top N similar samples as recommendation items; from the query. The Query-Aware approach simplifies the computation by eliminating the random shifting step [32].\n\nAlgorithm 2 represents data samples with D, randomized vector with R, number of hash tables with M, and the threshold value with l. The threshold value specifies the number of times that the Euclidean distance between a hash vector of a data sample and the query's hash vector is less than or equal to w/2. In this algorithm, based on the number of hash tables, random vectors are generated. In each hash table, data samples are multiplied by their corresponding random vector to generate their hash values (step 3). Then, the Euclidean distance of each data sample's hash value is measured against the hash value of the query sample. If the distance value is less than or equal to w/2, the occurrence number of these samples is incremented by 1 (step 4). If the occurrence number of a data sample (i.e., code example) is greater than or equal to the threshold value l, it is added to the candidate set (C) (steps 5 to 7). After collecting the candidate samples, their Euclidean distance from the query vector is calculated and ranked incrementally (steps 9 to 10). Finally, the top N samples are recommended as the most similar code examples to the query (step 11). This approach filters the data samples based on the given query in two steps: (1) filtering based on the hash value similarity of the samples and the query and (2) selecting the filtered samples based on their similarity to the query.\n\n\nF. Model Assessment\n\nOnce we implemented our LSH-based algorithms, which were the Random Hyperplane-based and Query-Aware approaches, we needed to evaluate their performance. To achieve this, and for comparison purposes, we utilized four different metrics: HitRate, Mean Reciprocal Rank (MRR), Average Execution time, and Relevance. HitRate and MRR were chosen based on their adoption by previous research [27], while the Relevance metric was taken from PostFinder [22].\n\n\nIV. EMPIRICAL EVALUATION\n\nWe have conducted two experiments to evaluate our LSHbased approach. Firstly, we compared two LSH-based algorithms, namely Random Hyperplane-based LSH and Query-Aware LSH, based on four metrics: Hit Rate, Mean Reciprocal Rank, Average Execution Time, and Relevance.\n\nFor the second part, we selected the algorithm that yielded better results for the aforementioned metrics and compared it with two state-of-the-art baselines, namely PostFinder and FaCoY, based on three additional metrics: Relevance, Success Rate, and Precision.\n\n\nA. Variable Selection\n\nIn this section, we will introduce and clarify the metrics that we utilized to evaluate our work. Our research focuses on the type of approach employed as the independent variable, with two distinct values for this factor:\n\n\u2022 Random Hyperplane-based LSH approach \u2022 Query-Aware LSH approach Within our study, we have examined several dependent variables, such as HitRate, MRR, Average execution time, and Relevance. In the following sections, we will provide a more detailed explanation of each of these metrics.\n\nHitRate: When given a set of queries (Q), the HitRate@k metric calculates the proportion of queries that have generated at least one relevant result among the top k recommended items. The following formula provides a definition for this parameter [27]: The result returned is not relevant 2\nHitRate@K = 1 H(R(Q), k) (1) |Q| q\u2208Q\nThere are some hints but still out of context 3\n\nThe results incorporate some relevant results but not key features 4\n\nThe returned results are in the context of the query and are helpful\n\nBased on the provided equation, Q represents a set of queries and H(R(Q), k) is a function that returns 1 if at least one relevant item appears among the top k recommended items. Otherwise, it returns 0. The HitRate metric is computed as the average of the 0 and 1 values, and a higher value of this metric indicates a more effective recommendation system. Specifically, if the HitRate value is close to 1, it suggests that the recommendation system is successful.\n\n\nMean Reciprocal Rank (MRR):\n\nThe MRR metric is calculated as the average of the inverse of the first rank of the recommended items when the HitRate occurs. To illustrate, suppose that two queries have been executed and the HitRate of returned results for each of them is at the second and third ranks, respectively. In this case, the MRR is the average of (1/2 + 1/3). The following formula defines the MRR metric ( [27]).\n\nof Java work experience, 40% had 2 to 3 years of experience, and 27% had over 3 years of experience. The metrics' values were determined based on the highest percentage values. For example, if the Relevance metric is considered, and 5% of the participants chose a score of 0, 5% selected a score of 1, 20% chose a score of 2, 45% selected a score of 3, and 25% chose a score of 4 (as shown in Table II), a Relevance value of 3 would be recorded. During the experiment, the developers evaluated the recommendation items individually based on the above-mentioned metrics.\n\n\nD. Analysis Method\n\nTo compare metrics between two algorithms with numerical values, such as relevance, we used the Wilcoxon Rank Sum Test [35]- [37]. This non-parametric test was chosen because our data did not follow a normal distribution. The test works by ranking the data samples from lowest to highest and summing the ranks of the two groups. It evaluates whether there is a significant difference between the medians of the two groups. Next, we examined the hypotheses by comparing the obtained values with predetermined threshold values [37]. Two hypotheses were formulated for the comparison, with the first one assuming no difference between the two dependent groups, and the alternative hypothesis assuming a difference between the two dependent groups. We utilized the Wilcoxon Rank Sum test to evaluate the Relevance metric for both algorithms investigated in our list of queries, which consisted of either natural language queries or Java API methods. A detailed discussion of this will be presented in the Results section. Relevance: In our study, we use a metric called \"Relevance\" which indicates the score assigned by developers to the recommended items, specifically code examples in our case [22]. The scores are determined according to table II.\n\n\nB. Study Design\n\nWe used the randomized block design [34] when conducting our survey with software developers. We divided the participants into three categories: junior, intermediate, and senior, based on their years of experience in software development. We generated a block by randomly selecting one person from each category. Then, the treatment options were randomly assigned within each block.\n\n\nC. Participants\n\nThe metrics were evaluated by a group of 15 software developers with varying levels of expertise, ranging from junior to senior. Among the developers, 33% had 1 to 2 years In order to compare our approach with baselines, we need to measure the defined metrics in PostFinder [22]. The main difference between our work and these studies is that they measure the introduced metrics based on the recommended Stack Overflow posts, which include both comments and code snippets. However, our work measures those metrics based solely on code snippets. The primary reason for selecting PostFinder and FaCoY as our baselines is their common data source, Stack Overflow. Additionally, we used 50 queries that PostFinder utilized for evaluation in configuration G to compare itself with FaCoY. These 50 queries were selected from the 10 most popular Java libraries: Jackson, SWT, MongoDB driver, Javax Servlet, JDBC API, JDT core, Apache Camel, Apache Wicket, Twitter4j, and Apache POI [22].\n\nTo further strengthen the validity of our comparison, it is important to acknowledge that PostFinder utilized the dump files of Stack Overflow up until June 2017. In order to maintain consistency and ensure an accurate evaluation, we have specifically filtered the code examples for this part, considering only those with dates up until June 2017. Below are the comparison metrics:\n\nRelevance: This is the score given to the the pair of <query, recommended code examples> based on the table II.\n\nSuccess Rate: The query is considered relevant if at least one of the top 5 retrieved code examples has a score of 3 or 4. The success rate is determined by dividing the number of relevant queries by the total number of queries.\n\nPrecision: The metric calculates the ratio of pairs that receive a score of 3 or 4 in the top 5 recommendations to the total number of pairs. According to Table VII, the results of these 3 measures for PostFinder and FaCoY are extracted from [22].\n\n\nV. RESULTS\n\nThere are two types of queries i.e., Natural Language and API Names-based queries that we have considered for the comparison of LSH-based algorithms that are listed in Table III. These are the queries that are extracted from other publications [21], [38].\n\n\nRQ1:\n\nWhat is the performance comparison between the Random Hyperplane-based LSH and the Query-Aware LSH approaches in recommending code examples, considering metrics such as Hit Rate, Mean Reciprocal Rank, Average execution time, and Relevance? Table IV demonstrates the values of HitRate (3rd to 5th columns), MRR (6th column), and Relevance (7th column) metrics. According to this table, for natural language-based queries, the HitRate values are (0.2, 0.5, 0.55) and (0.5, 0.8, 0.9) respectively for the top 10, 20, and 30 recommendations generated by Random Hyperplane-based LSH and Query-Aware LSH. The results indicate that Query-Aware LSH gives better results than Random Hyperplane-based LSH in terms of HitRate. This is because Query-Aware LSH is capable of identifying more relevant code examples based on the given query. As the number of recommended examples increases, the likelihood of finding relevant code also increases, resulting in a higher HitRate value.\n\nAdditionally, Table IV presents a notable discovery regarding the MRR measure, which reveals a difference in performance depending on the type of query used. Specifically, both the Random Hyperplane-based LSH and Query-Aware LSH algorithms perform better in terms of MRR values when handling API method names as queries, compared to Natural Language-based queries. The two algorithms demonstrate almost identical MRR values for the same query type. A higher MRR value implies that the algorithm returns relevant code examples at a lower rank, while a lower MRR value indicates that the algorithm returns relevant code examples at higher ranks or fails to return any relevant results.\n\nMoreover, table IV provides a summary of the Relevance metric results for the various types of queries and algorithms evaluated. According to our findings, natural language-based queries produce higher Relevance scores when recommending code examples. This result can be attributed to the use of the BERT model, which considers both the semantic and contextual information of queries and code examples ( [3]). As a result, it performs well when processing natural language text compared with API Names. Table V presents the average execution times for the LSH creation and recommendation processes of both the Random Hyperplane-based LSH and the Query-Aware LSH algorithms. We conducted measurements on these elements using varying numbers of hash tables, ranging from 2 to 50. The number of hash tables determines how frequently the hashing algorithm is applied to both the query and data samples. Increasing the number of hash tables leads to more data points being mapped to the same bucket as the query, resulting in a higher likelihood of finding more similar data samples and therefore improving the accuracy of the nearest neighbor search. However, a larger number of hash tables can also increase the computational complexity. Furthermore, Table V   The recommendation time for the Random Hyperplanebased algorithm fluctuates between 0.3241 seconds to 1.241 seconds as the number of Hash tables increases from 2 to 50, as shown in Figure 4. On the other hand, the recommendation time for the Query-Aware LSH algorithm ranges from 0.00077 seconds to 0.000861 seconds, which is significantly lower than that of the Random Hyperplane-based algorithm. Figure  5 illustrates the Boxplot of the recommendation time for both the Random Hyperplane-based and Query-Aware LSH algorithms. As per the plot, the first Quartile, Median, and third Quartile values for the Random Hyperplane-based algorithm are (0.373, 1.236, 1.2814), while for the Query-Aware LSH algorithm, the values are (0.0007476, 0.0008623, 0.0007533). Additionally, the difference between the Maximum and Minimum values for the two algorithms is 0.9573 and 0.0001257, respectively. The results discussed can be accounted for by the approach of Query-Aware LSH, which doesn't necessitate placing all data  samples into buckets. Instead, it focuses on only those samples whose hash values are in proximity to the query's hash value. Additionally, the Query-Aware LSH algorithm decreases the search space by excluding data samples whose hash vectors are near the query during the LSH creation. This takes place at the initial stage of the search process, resulting in the algorithm's ability to identify relevant samples more effectively [32]. RQ2: Does the Random Hyperplane-based LSH approach differ from the Query-Aware LSH approach in terms of Relevance when recommending code examples?\n\nThe second research question was addressed by formulating a null hypothesis and an alternative hypothesis, as stated below:\n\n\u2022 H02: There is no statistically significant difference between the Query-Aware LSH and the Random Hyperplane-based LSH in terms of Relevance. \u2022 Ha2: There is a statistically significant difference between the Query-Aware LSH and the Random Hyperplane-based LSH in terms of Relevance. We present the findings from our evaluation of two algorithms: the Random Hyperplane-based LSH and the Query-Aware LSH. We conducted a comparison between these two algorithms using the Wilcoxon Rank Sum Test. Specifically, we examined whether there was a significant difference between  the algorithms in terms of their ability to provide relevant code examples for both natural language-based and API method names-based queries.\n\nTable VI presents a summary of the \"Relevance\" outcomes for queries based on natural language and API methods' names. For natural language-based queries, the U-value is 107, the U-value is lower than the critical U-value, which indicates that the results are not due to chance and there is a significant difference between the two algorithms in terms of Relevance. Moreover, as shown in table VI for the API methods' names-based queries, since the U-value is higher than the critical U-value, the differences between the two groups are more likely to be attributed to chance. Therefore, the null hypothesis cannot be rejected in this case.  \n\n\nRQ3:\n\n\nVI. THREATS TO VALIDITY\n\nDespite the careful execution of our evaluation step, there are certain factors that could potentially compromise the validity of our empirical evaluation. These threats to validity can be categorized into three distinct categories [40].\n\n\nA. Internal Validity\n\nPotential threats to internal validity in our study include the pre-processing of data samples, which involved filtering based on regular expressions, code example length, and postscore. This process may have inadvertently excluded valid API methods used in some posts with short code examples (one or two lines). As a result, the accuracy of our outcomes could be compromised and necessitates careful consideration. Additionally, code examples demonstrating correct API method usage may have been filtered out due to low scores below the specified threshold values, further posing a threat to result validity.\n\n\nB. External validity\n\nAlthough we tested our algorithms on Java code examples sourced from Stack Overflow posts, it may be necessary to assess their performance on posts containing code examples in different programming languages, such as C/C++ or Python. Doing so would enable us to gauge the ability of our LSHbased algorithms to retrieve relevant code examples in various programming languages and assess their performance based on predefined metrics.\n\n\nC. Conclusion Validity\n\nWe provided all necessary details for replicating our study in the online appendix 1 . However, applying our results to other domains requires careful analysis of that domain to address any uncertainties.\n\n\nVII. CONCLUSION AND FUTURE WORK\n\nBased on our findings, it appears that utilizing natural language-based queries yields more accurate search results compared to API Names-based queries. Additionally, the recommendation system proves to be more effective in retrieving relevant information when using natural language queries. When analyzing both types of queries, the Query-Aware LSH consistently outperforms the Random Hyperplane-based LSH in terms of metrics such as HitRate, MRR (Mean Reciprocal Rank), Average Execution time, and Relevance. Through the use of the Wilcoxon Rank Sum test, we determined that the Query-Aware LSH performs better than the Random Hyperplane-based LSH specifically when the query is in a natural language format, but not for API Names-based queries. Moreover, the comparison of QALSH with PostFinder and FaCoY demonstrates its capability to recommend valuable code examples sourced from Stack Overflow.\n\nIn the future, we aim to advance our approach and transform it into a recommendation system integrated as a plugin in the Eclipse IDE. This integration will enable the system to assist developers with their ongoing tasks within the IDE. We also plan to conduct large-scale controlled experiments, involving software developers utilizing our recommender system for their software engineering and evolution tasks. Additionally, we intend to explore informal documentation sources like email discussions, forums, and bug reports to gather more code examples for enhanced recommendations.\n\nFig. 1 .\n1The main steps of the followed Methodology\n\n\nFirst rank of the relevant result (2) E. Comparison of our work with PostFinder and FaCoY Average Execution Time: Our approach's execution time is measured in two stages: the first stage involves measuring the time taken to apply hashing algorithms to data samples, and the second stage measures the time it takes to return results when hashing has already been applied. These measures are evaluated based on the number of hash tables utilized.\n\nFigure 2\n2illustrates the time of the creation of Hash tables, along with the allocation of data samples to their respective buckets, for the two algorithms proposed, namely the Random Hyperplane-based and the Query-Aware LSH. It can be observed from the figure that the range of values for this metric for these algorithms are (4.77, 113.85) and (1.014, 26.926) respectively.Figure 3displays the Boxplot representation of the LSH creation time for the two algorithms being considered in this study, namely, the Random Hyperplane-based and the Query-Aware LSH algorithms. The figure shows that the first quartile, median, and third quartile values for the first and second algorithms are(11.274, 43.115, 86.153) and(2.297,  10.203, 19.893), respectively. Moreover, the range between the Maximum and Minimum values for the two algorithms are 109.0755 and 25.912, respectively.\n\nFig. 3 .\n3Boxplot of LSH Creation time based on the number of Hash TablesAdapted from[8].\n\nFig. 4 .\n4LSH Recommendation time based on the number of Hash Tables Adapted from[8].\n\nFig. 5 .\n5Boxplot of LSH Recommendation time based on the number of HashTables Adapted from[8].\n\n\nDo any significant differences exist in the Relevance values between the Random Hyperplane-based LSH and Query-Aware LSH algorithms? RQ3: How does the proposed algorithm perform compared to the recent state-of-the-art methods, namely PostFinder and FaCoY? II. RELATED WORK In this part, we have categorized the related work into different sections which are presented as subsections. The first section covers the proposed works on extracting code elements from informal documentation and identifying patterns of API methods that are frequently used together. The next category highlights research on recommending code examples from open-source projects. Finally, we discuss some research works that have utilized LSH in suggesting recommendation systems.Query-Aware LSH algorithms perform in recommending code \nexamples, with regards to metrics such as HitRate, Mean \nReciprocal Rank, Average execution time, and Relevance? \nRQ2: \n\nTABLE I DATA\nIEXTRACTED FROM STACK OVERFLOW.Posts \nCount \nPosts with Java tags and not other programming languages \n377,517 \nPosts incorporating <code> tag \n198,911 \nCode examples with more than 100 characters \n128,688 \nFiltering non-code examples \n97,084 \nCode examples with scores greater than or equal to 2 \n61,361 \n\n\n\n\n1 Random Hyperplane based LSH. Adapted from Charikar et al. [33] 1: For D as Data samples, R as a Randomized vector and M as the number of hash tables; 2: for i \u2190 1 to M do3: \n\n\n\n\nFor D as Data samples and R as a Randomized vector, M as the number of hash tables, l as the threshold of the occurrence of a data sample ; 2: for i \u2190 1 to M do Impose Hash functions by multiplying objects (Oi) and query vector to Randomized vectors;13: \n\nQBucketId \u2190 \nk1 2 i  *  SgnQRes[i]; \n\nAlgorithm 2 Query-Aware LSH. Adapted from Huang et \nal. [32] \n1: 3: \n\n4: \n\n\n\nTABLE II THE\nIISCORING SCALE OF THE RELEVANCE METRICScore \nDescription \n0 \nNo result has been returned \n1 \n\n\n\ndisplays the average execution time for all considered queries, revealing that the Query-Aware LSH algorithm outperforms the Random Hyperplane-based algorithm in both the LSH creation phase and the recommendations generation phase. On average, the Query-Aware LSH algorithm took 11.21 seconds to create hash tables and less than 1 millisecond to generate code examples recommendations. Conversely, the Random Hyperplane-based algorithm took 49.56 seconds on average to create hash tables and 0.98 seconds on average to generate code examples recommendations.\n\nTABLE IV SUMMARY\nIVOF RESULTS OF HITRATE, MRR AND RELEVANCE METRICS FOR DIFFERENT QUERY TYPES. THE AVERAGE EXECUTION TIME OF THE PROPOSED APPROACHES, i.e., Random Hyperplane-based LSH (1) AND Query-Aware LSH (2) (IN SECONDS).Fig. 2. LSH Creation time based on the number of Hash Tables Adapted from [8].Query Type \nApproaches \nHitRate (Top 10) \nHitRate (Top 20) \nHitRate (Top 30) \nMRR \nRelevance \nNatural \nLanguage-based \nQueries \n\nRandom \nHyperplane-based \nLSH \n\n0.2 \n0.5 \n0.55 \n0.0774 \n1.7 \n\nQuery-Aware LSH \n0.5 \n0.8 \n0.9 \n0.2582 \n2.7 \nAPI Names-based Queries \nRandom \nHyperplane-based \nLSH \n\n0.15 \n0.25 \n0.3 \n0.07142 \n2.05 \n\nQuery-Aware LSH \n0.5 \n0.5 \n0.5 \n0.246 \n2.65 \n\nTABLE V \nNumber of hash tables \nLSH creation time(1) \nRecommendation time(1) \nLSH creation time(2) \nRecommendation time(2) \n2 \n4.7735 \n0.3241 \n1.01475 \n0.000779 \n5 \n11.274 \n0.373 \n2.297 \n0.0007476 \n10 \n22.420 \n1.247 \n4.519 \n0.0008069 \n20 \n43.115 \n1.236 \n10.203 \n0.0008623 \n30 \n65.348 \n1.225 \n13.668 \n0.0007353 \n40 \n86.153 \n1.2814 \n19.893 \n0.0007533 \n50 \n113.849 \n1.241 \n26.926 \n0.000861 \n\n\n\nHow does the proposed algorithm perform compared to the recent state-of-the-art methods, namely PostFinder and FaCoY? Since the Query-Aware LSH (QALSH) yielded higher values for the evaluated metrics compared to the Random Hyperplane-based LSH, we selected this algorithm for comparison with the baselines, namely Postfinder and FaCoY. According to Table VII, the average values of success rate, precision, and relevance for QALSH are 0.83, 0.51, 2.64,\n\nTABLE VI THETABLE VII COMPARISON\nVIVIIRESULT OF A WILCOXON RANK SUM TEST BASED ON THE RELEVANCE METRIC FOR DIFFERENT QUERY TYPES OF QUERY AWARE LSH (QALSH) WITH POSTFINDER AND FACOY BASED ON THREE METRICS while the corresponding values for FaCoY are 0.77, 0.33, 2.09 respectively. PostFinder achieved higher values for these metrics, which are 0.95, 0.66, 2.78. Hence, QALSH outperformed FaCoY in three metrics. However, PostFinder achieved better results than QALSH in three measures, even though their average relevance values were closely matched 2.64 vs 2.78.Query Type \nCritical U-value \nU-value \nZ-Score \nCritical P-value \nP-value \nResult \nNatural Language-based \nAPI Names-based \n\n127 \n37 \n\n107 \n47 \n\n-2.5 \n-1.41 \n\n0.05 \n0.05 \n\n.012 \n.16 \n\nSignificant \nNot Significant \n\nSuccess rate \nPrecision \nRelevance \nQALSH \nPostFinder \nFaCoY \nQALSH \nPostFinder \nFaCoY \nQALSH \nPostFinder \nFaCoY \nMean \n0.83 \n0.95 \n0.77 \n0.51 \n0.66 \n0.33 \n2.64 \n2.78 \n2.09 \nStd \n0.38 \n0.22 \n0.42 \n0.25 \n0.30 \n0.26 \n1.06 \n1.01 \n1.01 \nFirst quartile \n1.0 \n1.0 \n1.0 \n0.2 \n0.40 \n0.20 \n2.0 \n2.0 \n1.0 \nSecond quartile \n1.0 \n1.0 \n1.0 \n0.4 \n0.60 \n0.40 \n3.0 \n3.0 \n2.0 \nThird quartile \n1.0 \n1.0 \n1.0 \n0.8 \n1.0 \n0.45 \n4.0 \n4.0 \n3.0 \n\n\nhttps://github.com/scam2023-so/scam-2023\n\nLancer: Your code tell me what you need. S Zhou, B Shen, H Zhong, 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEEZhou, S., Shen, B., & Zhong, H. (2019, November). Lancer: Your code tell me what you need. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE) (pp. 1202-1205). IEEE.\n\nDevelopment of recommendation systems for software engineering: the CROSSMINER experience. J Di Rocco, D Di Ruscio, C Di Sipio, P T Nguyen, R Rubei, Empirical Software Engineering. 26469Di Rocco, J., Di Ruscio, D., Di Sipio, C., Nguyen, P. T., & Rubei, R. (2021). Development of recommendation systems for software engineer- ing: the CROSSMINER experience. Empirical Software Engineering, 26(4), 69.\n\nJ Devlin, M W Chang, K Lee, K Toutanova, arXiv:1810.04805Bert: Pretraining of deep bidirectional transformers for language understanding. arXiv preprintDevlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). Bert: Pre- training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n\nA review on the attention mechanism of deep learning. Z Niu, G Zhong, H Yu, Neurocomputing. 452Niu, Z., Zhong, G., & Yu, H. (2021). A review on the attention mechanism of deep learning. Neurocomputing, 452, 48-62.\n\nLeveraging Unsupervised Learning to Summarize APIs Discussed in Stack Overflow. A Naghshzan, L Guerrouj, O Baysal, 10.1109/SCAM52516.2021.000262021 IEEE 21st International Working Conference on Source Code Analysis and Manipulation (SCAM). LuxembourgA. Naghshzan, L. Guerrouj and O. Baysal, \"Leveraging Unsupervised Learning to Summarize APIs Discussed in Stack Overflow,\" 2021 IEEE 21st International Working Conference on Source Code Analy- sis and Manipulation (SCAM), Luxembourg, 2021, pp. 142-152, doi: 10.1109/SCAM52516.2021.00026.\n\nA Naghshzan, arXiv:2208.06318Towards Code Summarization of APIs Based on Unofficial Documentation Using NLP Techniques. arXiv preprintNaghshzan, A. (2022). Towards Code Summarization of APIs Based on Unofficial Documentation Using NLP Techniques. arXiv preprint arXiv:2208.06318.\n\nLocality-sensitive hashing scheme based on p-stable distributions. M Datar, N Immorlica, P Indyk, V S Mirrokni, Proceedings of the twentieth annual symposium on Computational geometry. the twentieth annual symposium on Computational geometryDatar, M., Immorlica, N., Indyk, P., Mirrokni, V. S. (2004, June). Locality-sensitive hashing scheme based on p-stable distributions. In Proceedings of the twentieth annual symposium on Computational geometry (pp. 253-262).\n\nTowards recommending code examples using informal documentation (Doctoral dissertation. S Rahmani, E\u00b4 cole de technologie supe\u00b4rieureRahmani, S. (2023). Towards recommending code examples using informal documentation (Doctoral dissertation, E\u00b4 cole de technologie supe\u00b4rieure)\n\nF Wilcoxon, Individual comparisons by ranking methods. New YorkSpringerWilcoxon, F. (1992). Individual comparisons by ranking methods (pp. 196-202). Springer New York.\n\nL R Medsker, L C Jain, Recurrent neural networks. Design and Applications. 5Medsker, L. R., Jain, L. C. (2001). Recurrent neural networks. Design and Applications, 5, 64-67.\n\nBIDE: Efficient mining of frequent closed sequences. J Wang, J Han, Proceedings. 20th international conference on data engineering. 20th international conference on data engineeringIEEEWang, J., Han, J. (2004, April). BIDE: Efficient mining of frequent closed sequences. In Proceedings. 20th international conference on data engineering (pp. 79-90). IEEE.\n\nThe Google Pagerank algorithm and how it works. I Rogers, Rogers, I. (2002). The Google Pagerank algorithm and how it works.\n\nFaCoY: a code-to-code search engine. K Kim, D Kim, T F Bissyande\u00b4, E Choi, L Li, J Klein, Y L Traon, Proceedings of the 40th International Conference on Software Engineering. the 40th International Conference on Software EngineeringKim, K., Kim, D., Bissyande\u00b4, T. F., Choi, E., Li, L., Klein, J. & Traon, Y. L. (2018). FaCoY: a code-to-code search engine. Proceedings of the 40th International Conference on Software Engineering, pp. 946-957.\n\nPostFinder: Mining Stack Overflow posts to support software developers. R Rubei, C Di Sipio, P T Nguyen, J Di Rocco, D Di Ruscio, Information and Software Technology. 127106367Rubei, R., Di Sipio, C., Nguyen, P. T., Di Rocco, J. & Di Ruscio, D. (2020). PostFinder: Mining Stack Overflow posts to support software developers. Information and Software Technology, 127, 106367.\n\nExtracting structural information from bug reports. N Bettenburg, R Premraj, T Zimmermann, S Kim, Proceedings of the 2008 international working conference on Mining software repositories. the 2008 international working conference on Mining software repositoriesBettenburg, N., Premraj, R., Zimmermann, T. & Kim, S. (2008). Extracting structural information from bug reports. Proceedings of the 2008 international working conference on Mining software repositories, pp. 27-30.\n\nGenerating robust parsers using island grammars. L Moonen, Proceedings eighth working conference on reverse engineering. eighth working conference on reverse engineeringMoonen, L. (2001). Generating robust parsers using island grammars. Proceedings eighth working conference on reverse engineering, pp. 13- 22.\n\nExtracting structured data from natural language documents with island parsing. A Bacchelli, A Cleve, M Lanza, A Mocci, 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011). Bacchelli, A., Cleve, A., Lanza, M. Mocci, A. (2011). Extracting structured data from natural language documents with island parsing. 2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011), pp. 476-479.\n\nDiscovering essential code elements in informal documentation. P C Rigby, M P Robillard, 35th International Conference on Software Engineering (ICSE). Rigby, P. C. Robillard, M. P. (2013). Discovering essential code elements in informal documentation. 2013 35th International Conference on Software Engineering (ICSE), pp. 832-841.\n\nEmploying source code information to improve question-answering in stack overflow. T Diamantopoulos, A Symeonidis, Diamantopoulos, T. Symeonidis, A. (2015). Employing source code information to improve question-answering in stack overflow. 2015\n\nIEEE/ACM 12th Working Conference on Mining Software Repositories. IEEE/ACM 12th Working Conference on Mining Software Repositories, pp. 454-457.\n\nR Abdalkareem, E Shihab, J Rilling, On code reuse from stackoverflow: An exploratory study on android apps. Information and Software Technology. 88Abdalkareem, R., Shihab, E. Rilling, J. (2017). On code reuse from stackoverflow: An exploratory study on android apps. Information and Software Technology, 88, 148-158.\n\nFaCoY: a code-to-code search engine. K Kim, D Kim, T F Bissyande\u00b4, E Choi, L Li, J Klein, Y L Traon, Proceedings of the 40th International Conference on Software Engineering. the 40th International Conference on Software EngineeringKim, K., Kim, D., Bissyande\u00b4, T. F., Choi, E., Li, L., Klein, J. Traon, Y. L. (2018). FaCoY: a code-to-code search engine. Proceedings of the 40th International Conference on Software Engineering, pp. 946-957.\n\nPostFinder: Mining Stack Overflow posts to support software developers. R Rubei, C Di Sipio, P T Nguyen, J Di Rocco, D Di Ruscio, Information and Software Technology. 127106367Rubei, R., Di Sipio, C., Nguyen, P. T., Di Rocco, J. Di Ruscio, D. (2020). PostFinder: Mining Stack Overflow posts to support software developers. Information and Software Technology, 127, 106367.\n\nFocus: A recommender system for mining api function calls and usage patterns. P T Nguyen, J Di Rocco, D Di Ruscio, L Ochoa, T Di Degueule, M Penta, IEEE/ACM 41st International Conference on Software Engineering (ICSE). Nguyen, P. T., Di Rocco, J., Di Ruscio, D., Ochoa, L., Degueule, T. Di Penta, M. (2019). Focus: A recommender system for mining api function calls and usage patterns. 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE), pp. 1050-1060.\n\nMining succinct and high-coverage API usage patterns from source code. J Wang, Y Dang, H Zhang, K Chen, T Xie, D Zhang, 10th Working Conference on Mining Software Repositories (MSR). Wang, J., Dang, Y., Zhang, H., Chen, K., Xie, T. Zhang, D. (2013). Mining succinct and high-coverage API usage patterns from source code. 2013 10th Working Conference on Mining Software Repositories (MSR), pp. 319-328.\n\nDeep API learning. X Gu, H Zhang, D Zhang, S Kim, Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering. the 2016 24th ACM SIGSOFT international symposium on foundations of software engineeringGu, X., Zhang, H., Zhang, D. Kim, S. (2016). Deep API learning. Proceedings of the 2016 24th ACM SIGSOFT international symposium on foundations of software engineering, pp. 631-642.\n\nCode completion with statistical language models. V Raychev, M Vechev, E Yahav, Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation. the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation23rd IEEE/ACM International Conference on Automated Software EngineeringRaychev, V., Vechev, M. Yahav, E. (2014). Code completion with statistical language models. Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 419-428. via mining open source code on the web. 2008 23rd IEEE/ACM International Conference on Automated Software Engineer- ing, pp. 327-336.\n\nLancer: Your code tell me what you need. S Zhou, B Shen, H Zhong, 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). Zhou, S., Shen, B. Zhong, H. (2019). Lancer: Your code tell me what you need. 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 1202-1205.\n\nKam1n0: Mapreducebased assembly clone search for reverse engineering. S H Ding, B C Fung, P Charland, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on knowledge discovery and data miningDing, S. H., Fung, B. C. Charland, P. (2016). Kam1n0: Mapreduce- based assembly clone search for reverse engineering. Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp. 461-470.\n\n. F Silavong, S Moran, A Georgiadis, R Saphal, R Otter, Silavong, F., Moran, S., Georgiadis, A., Saphal, R. Otter, R. (2022).\n\nSenatus-A Fast and Accurate Code-to-Code Recommendation Engine. Senatus-A Fast and Accurate Code-to-Code Recommendation Engine.\n\nIEEE/ACM 19th International Conference on Mining Software Repositories (MSR). IEEE/ACM 19th International Conference on Mining Software Repositories (MSR), pp. 511-523.\n\nAn efficient recommender system using locality sensitive hashing. K Zhang, S Fan, H J Wang, Proceedings of the 51st Hawaii International Conference on System Sciences. the 51st Hawaii International Conference on System SciencesZhang, K., Fan, S. Wang, H. J. (2018). An efficient recommender system using locality sensitive hashing. Proceedings of the 51st Hawaii International Conference on System Sciences.\n\nReal-time recommendation with locality sensitive hashing. A M Aytekin, T Aytekin, Journal of Intelligent Information Systems. 531Aytekin, A. M. Aytekin, T. (2019). Real-time recommendation with locality sensitive hashing. Journal of Intelligent Information Systems, 53(1), 1-26.\n\nQuery-aware locality-sensitive hashing for approximate nearest neighbor search. Q Huang, J Feng, Y Zhang, Q Fang, W Ng, Proceedings of the VLDB Endowment. the VLDB Endowment9Huang, Q., Feng, J., Zhang, Y., Fang, Q. Ng, W. (2015). Query-aware locality-sensitive hashing for approximate nearest neighbor search. Pro- ceedings of the VLDB Endowment, 9(1), 1-12.\n\nSimilarity estimation techniques from rounding algorithms. M S Charikar, Proceedings of the thirty-fourth annual ACM symposium on Theory of computing. the thirty-fourth annual ACM symposium on Theory of computingCharikar, M. S. (2002). Similarity estimation techniques from rounding algorithms. Proceedings of the thirty-fourth annual ACM symposium on Theory of computing, pp. 380-388.\n\nExperimentation in software engineering. V R Basili, R W Selby, D H Hutchens, IEEE Transactions on software engineering. 7Basili, V. R., Selby, R. W. Hutchens, D. H. (1986). Experimentation in software engineering. IEEE Transactions on software engineering, (7), 733-743.\n\nStatistical methods for the social and behavioral sciences. L A Marascuilo, R C Serlin, WH Freeman/Times Books/Henry Holt CoMarascuilo, L. A. & Serlin, R. C. (1988). Statistical methods for the social and behavioral sciences. WH Freeman/Times Books/Henry Holt Co.\n\nNonparametric statistics for the behavioral sciences. S Siegel, Siegel, S. (1956). Nonparametric statistics for the behavioral sciences.\n\nIndividual comparisons by ranking methods. F Wilcoxon, Breakthroughs in statistics. SpringerWilcoxon, F. (1992). Individual comparisons by ranking methods. In Breakthroughs in statistics (pp. 196-202). Springer.\n\nCodecatch: extracting source code snippets from online sources. T Diamantopoulos, G Karagiannopoulos, A L Symeonidis, Proceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering. the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software EngineeringDiamantopoulos, T., Karagiannopoulos, G. & Symeonidis, A. L. (2018). Codecatch: extracting source code snippets from online sources. Pro- ceedings of the 6th International Workshop on Realizing Artificial Intelligence Synergies in Software Engineering, pp. 21-27.\n\nTransformers: State-of-the-art natural language processing. T Wolf, L Debut, V Sanh, J Chaumond, C Delangue, A Moi, . . Rush, A M , Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations. the 2020 conference on empirical methods in natural language processing: system demonstrationsWolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., ... Rush, A. M. (2020, October). Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations (pp. 38- 45).\n\nPragmatic controlled clinical trials in primary care: the struggle between external and internal validity. M Godwin, L Ruhland, I Casson, S Macdonald, D Delva, R Birtwhistle, . . Seguin, R , BMC medical research methodology. 3Godwin, M., Ruhland, L., Casson, I., MacDonald, S., Delva, D., Birtwhistle, R., ... & Seguin, R. (2003). Pragmatic controlled clinical trials in primary care: the struggle between external and internal validity. BMC medical research methodology, 3, 1-7.\n", "annotations": {"author": "[{\"end\":215,\"start\":120},{\"end\":325,\"start\":216},{\"end\":417,\"start\":326}]", "publisher": null, "author_last_name": "[{\"end\":134,\"start\":127},{\"end\":237,\"start\":228},{\"end\":341,\"start\":333}]", "author_first_name": "[{\"end\":126,\"start\":120},{\"end\":227,\"start\":216},{\"end\":332,\"start\":326}]", "author_affiliation": "[{\"end\":214,\"start\":167},{\"end\":324,\"start\":277},{\"end\":416,\"start\":369}]", "title": "[{\"end\":117,\"start\":1},{\"end\":534,\"start\":418}]", "venue": null, "abstract": "[{\"end\":2270,\"start\":594}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2409,\"start\":2405},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2823,\"start\":2820},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3357,\"start\":3353},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3886,\"start\":3882},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4588,\"start\":4585},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4594,\"start\":4590},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5270,\"start\":5266},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5791,\"start\":5787},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5817,\"start\":5813},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6180,\"start\":6176},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6659,\"start\":6655},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6961,\"start\":6958},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7169,\"start\":7166},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7174,\"start\":7171},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7623,\"start\":7619},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8161,\"start\":8157},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8509,\"start\":8505},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8765,\"start\":8761},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9327,\"start\":9323},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9483,\"start\":9479},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9500,\"start\":9496},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9622,\"start\":9618},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9936,\"start\":9932},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10226,\"start\":10222},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10444,\"start\":10440},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11026,\"start\":11022},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":11701,\"start\":11697},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":12154,\"start\":12150},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12562,\"start\":12558},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13579,\"start\":13575},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16059,\"start\":16055},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17591,\"start\":17587},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":17733,\"start\":17729},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":19783,\"start\":19779},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20308,\"start\":20305},{\"end\":20552,\"start\":20550},{\"end\":20629,\"start\":20627},{\"end\":20755,\"start\":20753},{\"end\":20776,\"start\":20774},{\"end\":20914,\"start\":20911},{\"end\":21046,\"start\":21044},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21069,\"start\":21068},{\"end\":21106,\"start\":21104},{\"end\":21213,\"start\":21210},{\"end\":21306,\"start\":21303},{\"end\":21453,\"start\":21450},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":21622,\"start\":21618},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":23439,\"start\":23435},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":23498,\"start\":23494},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":24847,\"start\":24843},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":26000,\"start\":25996},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":26719,\"start\":26715},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":26725,\"start\":26721},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":27125,\"start\":27121},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":27792,\"start\":27788},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":27902,\"start\":27898},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":28542,\"start\":28538},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":29243,\"start\":29239},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30218,\"start\":30214},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":30482,\"start\":30478},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30488,\"start\":30484},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32561,\"start\":32558},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":34859,\"start\":34855},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":36762,\"start\":36758},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":41077,\"start\":41074},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":41164,\"start\":41161},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":41261,\"start\":41258}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":39663,\"start\":39610},{\"attributes\":{\"id\":\"fig_2\"},\"end\":40110,\"start\":39664},{\"attributes\":{\"id\":\"fig_3\"},\"end\":40987,\"start\":40111},{\"attributes\":{\"id\":\"fig_4\"},\"end\":41078,\"start\":40988},{\"attributes\":{\"id\":\"fig_5\"},\"end\":41165,\"start\":41079},{\"attributes\":{\"id\":\"fig_6\"},\"end\":41262,\"start\":41166},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":42195,\"start\":41263},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":42517,\"start\":42196},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":42697,\"start\":42518},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":43069,\"start\":42698},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":43178,\"start\":43070},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":43739,\"start\":43179},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":44804,\"start\":43740},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":45259,\"start\":44805},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":46462,\"start\":45260}]", "paragraph": "[{\"end\":3088,\"start\":2289},{\"end\":5226,\"start\":3090},{\"end\":6170,\"start\":5256},{\"end\":6631,\"start\":6172},{\"end\":7147,\"start\":6633},{\"end\":7598,\"start\":7149},{\"end\":8144,\"start\":7600},{\"end\":8477,\"start\":8146},{\"end\":8719,\"start\":8479},{\"end\":9309,\"start\":8747},{\"end\":9484,\"start\":9311},{\"end\":9915,\"start\":9486},{\"end\":10208,\"start\":9917},{\"end\":10949,\"start\":10210},{\"end\":11679,\"start\":11010},{\"end\":12135,\"start\":11681},{\"end\":12541,\"start\":12137},{\"end\":12831,\"start\":12543},{\"end\":13137,\"start\":12833},{\"end\":13693,\"start\":13160},{\"end\":13952,\"start\":13720},{\"end\":14351,\"start\":13954},{\"end\":14974,\"start\":14353},{\"end\":15293,\"start\":14976},{\"end\":15657,\"start\":15295},{\"end\":16068,\"start\":15720},{\"end\":16359,\"start\":16089},{\"end\":16894,\"start\":16386},{\"end\":17592,\"start\":16938},{\"end\":18152,\"start\":17628},{\"end\":18726,\"start\":18154},{\"end\":19212,\"start\":18728},{\"end\":19524,\"start\":19214},{\"end\":20588,\"start\":19526},{\"end\":20712,\"start\":20595},{\"end\":20828,\"start\":20719},{\"end\":20872,\"start\":20836},{\"end\":21070,\"start\":20880},{\"end\":21289,\"start\":21086},{\"end\":21623,\"start\":21291},{\"end\":23026,\"start\":21625},{\"end\":23499,\"start\":23050},{\"end\":23793,\"start\":23528},{\"end\":24057,\"start\":23795},{\"end\":24305,\"start\":24083},{\"end\":24594,\"start\":24307},{\"end\":24886,\"start\":24596},{\"end\":24971,\"start\":24924},{\"end\":25041,\"start\":24973},{\"end\":25111,\"start\":25043},{\"end\":25577,\"start\":25113},{\"end\":26002,\"start\":25609},{\"end\":26573,\"start\":26004},{\"end\":27842,\"start\":26596},{\"end\":28244,\"start\":27862},{\"end\":29244,\"start\":28264},{\"end\":29627,\"start\":29246},{\"end\":29740,\"start\":29629},{\"end\":29970,\"start\":29742},{\"end\":30219,\"start\":29972},{\"end\":30489,\"start\":30234},{\"end\":31467,\"start\":30498},{\"end\":32152,\"start\":31469},{\"end\":35007,\"start\":32154},{\"end\":35132,\"start\":35009},{\"end\":35848,\"start\":35134},{\"end\":36491,\"start\":35850},{\"end\":36763,\"start\":36526},{\"end\":37398,\"start\":36788},{\"end\":37855,\"start\":37423},{\"end\":38086,\"start\":37882},{\"end\":39023,\"start\":38122},{\"end\":39609,\"start\":39025}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":21085,\"start\":21071},{\"attributes\":{\"id\":\"formula_1\"},\"end\":24923,\"start\":24887}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":16220,\"start\":16213},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26405,\"start\":26397},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":30173,\"start\":30127},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":30411,\"start\":30402},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":30746,\"start\":30738},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":31491,\"start\":31483},{\"end\":32664,\"start\":32657},{\"end\":33409,\"start\":33402}]", "section_header": "[{\"end\":2287,\"start\":2272},{\"end\":5254,\"start\":5229},{\"end\":8745,\"start\":8722},{\"end\":11008,\"start\":10952},{\"end\":13158,\"start\":13140},{\"end\":13718,\"start\":13696},{\"end\":15718,\"start\":15660},{\"end\":16087,\"start\":16071},{\"end\":16384,\"start\":16362},{\"end\":16936,\"start\":16897},{\"end\":17626,\"start\":17595},{\"end\":20593,\"start\":20591},{\"end\":20717,\"start\":20715},{\"end\":20834,\"start\":20831},{\"end\":20878,\"start\":20875},{\"end\":23048,\"start\":23029},{\"end\":23526,\"start\":23502},{\"end\":24081,\"start\":24060},{\"end\":25607,\"start\":25580},{\"end\":26594,\"start\":26576},{\"end\":27860,\"start\":27845},{\"end\":28262,\"start\":28247},{\"end\":30232,\"start\":30222},{\"end\":30496,\"start\":30492},{\"end\":36498,\"start\":36494},{\"end\":36524,\"start\":36501},{\"end\":36786,\"start\":36766},{\"end\":37421,\"start\":37401},{\"end\":37880,\"start\":37858},{\"end\":38120,\"start\":38089},{\"end\":39619,\"start\":39611},{\"end\":40120,\"start\":40112},{\"end\":40997,\"start\":40989},{\"end\":41088,\"start\":41080},{\"end\":41175,\"start\":41167},{\"end\":42209,\"start\":42197},{\"end\":43083,\"start\":43071},{\"end\":43757,\"start\":43741},{\"end\":45293,\"start\":45261}]", "table": "[{\"end\":42195,\"start\":42019},{\"end\":42517,\"start\":42241},{\"end\":42697,\"start\":42692},{\"end\":43069,\"start\":42950},{\"end\":43178,\"start\":43123},{\"end\":44804,\"start\":44044},{\"end\":46462,\"start\":45824}]", "figure_caption": "[{\"end\":39663,\"start\":39621},{\"end\":40110,\"start\":39666},{\"end\":40987,\"start\":40122},{\"end\":41078,\"start\":40999},{\"end\":41165,\"start\":41090},{\"end\":41262,\"start\":41177},{\"end\":42019,\"start\":41265},{\"end\":42241,\"start\":42211},{\"end\":42692,\"start\":42520},{\"end\":42950,\"start\":42700},{\"end\":43123,\"start\":43086},{\"end\":43739,\"start\":43181},{\"end\":44044,\"start\":43760},{\"end\":45259,\"start\":44807},{\"end\":45824,\"start\":45299}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":33601,\"start\":33593},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":33819,\"start\":33810}]", "bib_author_first_name": "[{\"end\":46547,\"start\":46546},{\"end\":46555,\"start\":46554},{\"end\":46563,\"start\":46562},{\"end\":46949,\"start\":46948},{\"end\":46961,\"start\":46960},{\"end\":46974,\"start\":46973},{\"end\":46986,\"start\":46985},{\"end\":46988,\"start\":46987},{\"end\":46998,\"start\":46997},{\"end\":47259,\"start\":47258},{\"end\":47269,\"start\":47268},{\"end\":47271,\"start\":47270},{\"end\":47280,\"start\":47279},{\"end\":47287,\"start\":47286},{\"end\":47641,\"start\":47640},{\"end\":47648,\"start\":47647},{\"end\":47657,\"start\":47656},{\"end\":47882,\"start\":47881},{\"end\":47895,\"start\":47894},{\"end\":47907,\"start\":47906},{\"end\":48341,\"start\":48340},{\"end\":48689,\"start\":48688},{\"end\":48698,\"start\":48697},{\"end\":48711,\"start\":48710},{\"end\":48720,\"start\":48719},{\"end\":48722,\"start\":48721},{\"end\":49176,\"start\":49175},{\"end\":49366,\"start\":49365},{\"end\":49535,\"start\":49534},{\"end\":49537,\"start\":49536},{\"end\":49548,\"start\":49547},{\"end\":49550,\"start\":49549},{\"end\":49763,\"start\":49762},{\"end\":49771,\"start\":49770},{\"end\":50115,\"start\":50114},{\"end\":50230,\"start\":50229},{\"end\":50237,\"start\":50236},{\"end\":50244,\"start\":50243},{\"end\":50246,\"start\":50245},{\"end\":50260,\"start\":50259},{\"end\":50268,\"start\":50267},{\"end\":50274,\"start\":50273},{\"end\":50283,\"start\":50282},{\"end\":50285,\"start\":50284},{\"end\":50710,\"start\":50709},{\"end\":50719,\"start\":50718},{\"end\":50731,\"start\":50730},{\"end\":50733,\"start\":50732},{\"end\":50743,\"start\":50742},{\"end\":50755,\"start\":50754},{\"end\":51066,\"start\":51065},{\"end\":51080,\"start\":51079},{\"end\":51091,\"start\":51090},{\"end\":51105,\"start\":51104},{\"end\":51540,\"start\":51539},{\"end\":51883,\"start\":51882},{\"end\":51896,\"start\":51895},{\"end\":51905,\"start\":51904},{\"end\":51914,\"start\":51913},{\"end\":52309,\"start\":52308},{\"end\":52311,\"start\":52310},{\"end\":52320,\"start\":52319},{\"end\":52322,\"start\":52321},{\"end\":52662,\"start\":52661},{\"end\":52680,\"start\":52679},{\"end\":52971,\"start\":52970},{\"end\":52986,\"start\":52985},{\"end\":52996,\"start\":52995},{\"end\":53326,\"start\":53325},{\"end\":53333,\"start\":53332},{\"end\":53340,\"start\":53339},{\"end\":53342,\"start\":53341},{\"end\":53356,\"start\":53355},{\"end\":53364,\"start\":53363},{\"end\":53370,\"start\":53369},{\"end\":53379,\"start\":53378},{\"end\":53381,\"start\":53380},{\"end\":53804,\"start\":53803},{\"end\":53813,\"start\":53812},{\"end\":53825,\"start\":53824},{\"end\":53827,\"start\":53826},{\"end\":53837,\"start\":53836},{\"end\":53849,\"start\":53848},{\"end\":54184,\"start\":54183},{\"end\":54186,\"start\":54185},{\"end\":54196,\"start\":54195},{\"end\":54208,\"start\":54207},{\"end\":54221,\"start\":54220},{\"end\":54230,\"start\":54229},{\"end\":54233,\"start\":54231},{\"end\":54245,\"start\":54244},{\"end\":54655,\"start\":54654},{\"end\":54663,\"start\":54662},{\"end\":54671,\"start\":54670},{\"end\":54680,\"start\":54679},{\"end\":54688,\"start\":54687},{\"end\":54695,\"start\":54694},{\"end\":55006,\"start\":55005},{\"end\":55012,\"start\":55011},{\"end\":55021,\"start\":55020},{\"end\":55030,\"start\":55029},{\"end\":55463,\"start\":55462},{\"end\":55474,\"start\":55473},{\"end\":55484,\"start\":55483},{\"end\":56123,\"start\":56122},{\"end\":56131,\"start\":56130},{\"end\":56139,\"start\":56138},{\"end\":56477,\"start\":56476},{\"end\":56479,\"start\":56478},{\"end\":56487,\"start\":56486},{\"end\":56489,\"start\":56488},{\"end\":56497,\"start\":56496},{\"end\":56926,\"start\":56925},{\"end\":56938,\"start\":56937},{\"end\":56947,\"start\":56946},{\"end\":56961,\"start\":56960},{\"end\":56971,\"start\":56970},{\"end\":57416,\"start\":57415},{\"end\":57425,\"start\":57424},{\"end\":57432,\"start\":57431},{\"end\":57434,\"start\":57433},{\"end\":57817,\"start\":57816},{\"end\":57819,\"start\":57818},{\"end\":57830,\"start\":57829},{\"end\":58119,\"start\":58118},{\"end\":58128,\"start\":58127},{\"end\":58136,\"start\":58135},{\"end\":58145,\"start\":58144},{\"end\":58153,\"start\":58152},{\"end\":58458,\"start\":58457},{\"end\":58460,\"start\":58459},{\"end\":58827,\"start\":58826},{\"end\":58829,\"start\":58828},{\"end\":58839,\"start\":58838},{\"end\":58841,\"start\":58840},{\"end\":58850,\"start\":58849},{\"end\":58852,\"start\":58851},{\"end\":59119,\"start\":59118},{\"end\":59121,\"start\":59120},{\"end\":59135,\"start\":59134},{\"end\":59137,\"start\":59136},{\"end\":59378,\"start\":59377},{\"end\":59505,\"start\":59504},{\"end\":59739,\"start\":59738},{\"end\":59757,\"start\":59756},{\"end\":59777,\"start\":59776},{\"end\":59779,\"start\":59778},{\"end\":60337,\"start\":60336},{\"end\":60345,\"start\":60344},{\"end\":60354,\"start\":60353},{\"end\":60362,\"start\":60361},{\"end\":60374,\"start\":60373},{\"end\":60386,\"start\":60385},{\"end\":60393,\"start\":60392},{\"end\":60395,\"start\":60394},{\"end\":60403,\"start\":60402},{\"end\":60405,\"start\":60404},{\"end\":61010,\"start\":61009},{\"end\":61020,\"start\":61019},{\"end\":61031,\"start\":61030},{\"end\":61041,\"start\":61040},{\"end\":61054,\"start\":61053},{\"end\":61063,\"start\":61062},{\"end\":61078,\"start\":61077},{\"end\":61080,\"start\":61079},{\"end\":61090,\"start\":61089}]", "bib_author_last_name": "[{\"end\":46552,\"start\":46548},{\"end\":46560,\"start\":46556},{\"end\":46569,\"start\":46564},{\"end\":46958,\"start\":46950},{\"end\":46971,\"start\":46962},{\"end\":46983,\"start\":46975},{\"end\":46995,\"start\":46989},{\"end\":47004,\"start\":46999},{\"end\":47266,\"start\":47260},{\"end\":47277,\"start\":47272},{\"end\":47284,\"start\":47281},{\"end\":47297,\"start\":47288},{\"end\":47645,\"start\":47642},{\"end\":47654,\"start\":47649},{\"end\":47660,\"start\":47658},{\"end\":47892,\"start\":47883},{\"end\":47904,\"start\":47896},{\"end\":47914,\"start\":47908},{\"end\":48351,\"start\":48342},{\"end\":48695,\"start\":48690},{\"end\":48708,\"start\":48699},{\"end\":48717,\"start\":48712},{\"end\":48731,\"start\":48723},{\"end\":49184,\"start\":49177},{\"end\":49375,\"start\":49367},{\"end\":49545,\"start\":49538},{\"end\":49555,\"start\":49551},{\"end\":49768,\"start\":49764},{\"end\":49775,\"start\":49772},{\"end\":50122,\"start\":50116},{\"end\":50234,\"start\":50231},{\"end\":50241,\"start\":50238},{\"end\":50257,\"start\":50247},{\"end\":50265,\"start\":50261},{\"end\":50271,\"start\":50269},{\"end\":50280,\"start\":50275},{\"end\":50291,\"start\":50286},{\"end\":50716,\"start\":50711},{\"end\":50728,\"start\":50720},{\"end\":50740,\"start\":50734},{\"end\":50752,\"start\":50744},{\"end\":50765,\"start\":50756},{\"end\":51077,\"start\":51067},{\"end\":51088,\"start\":51081},{\"end\":51102,\"start\":51092},{\"end\":51109,\"start\":51106},{\"end\":51547,\"start\":51541},{\"end\":51893,\"start\":51884},{\"end\":51902,\"start\":51897},{\"end\":51911,\"start\":51906},{\"end\":51920,\"start\":51915},{\"end\":52317,\"start\":52312},{\"end\":52332,\"start\":52323},{\"end\":52677,\"start\":52663},{\"end\":52691,\"start\":52681},{\"end\":52983,\"start\":52972},{\"end\":52993,\"start\":52987},{\"end\":53004,\"start\":52997},{\"end\":53330,\"start\":53327},{\"end\":53337,\"start\":53334},{\"end\":53353,\"start\":53343},{\"end\":53361,\"start\":53357},{\"end\":53367,\"start\":53365},{\"end\":53376,\"start\":53371},{\"end\":53387,\"start\":53382},{\"end\":53810,\"start\":53805},{\"end\":53822,\"start\":53814},{\"end\":53834,\"start\":53828},{\"end\":53846,\"start\":53838},{\"end\":53859,\"start\":53850},{\"end\":54193,\"start\":54187},{\"end\":54205,\"start\":54197},{\"end\":54218,\"start\":54209},{\"end\":54227,\"start\":54222},{\"end\":54242,\"start\":54234},{\"end\":54251,\"start\":54246},{\"end\":54660,\"start\":54656},{\"end\":54668,\"start\":54664},{\"end\":54677,\"start\":54672},{\"end\":54685,\"start\":54681},{\"end\":54692,\"start\":54689},{\"end\":54701,\"start\":54696},{\"end\":55009,\"start\":55007},{\"end\":55018,\"start\":55013},{\"end\":55027,\"start\":55022},{\"end\":55034,\"start\":55031},{\"end\":55471,\"start\":55464},{\"end\":55481,\"start\":55475},{\"end\":55490,\"start\":55485},{\"end\":56128,\"start\":56124},{\"end\":56136,\"start\":56132},{\"end\":56145,\"start\":56140},{\"end\":56484,\"start\":56480},{\"end\":56494,\"start\":56490},{\"end\":56506,\"start\":56498},{\"end\":56935,\"start\":56927},{\"end\":56944,\"start\":56939},{\"end\":56958,\"start\":56948},{\"end\":56968,\"start\":56962},{\"end\":56977,\"start\":56972},{\"end\":57422,\"start\":57417},{\"end\":57429,\"start\":57426},{\"end\":57439,\"start\":57435},{\"end\":57827,\"start\":57820},{\"end\":57838,\"start\":57831},{\"end\":58125,\"start\":58120},{\"end\":58133,\"start\":58129},{\"end\":58142,\"start\":58137},{\"end\":58150,\"start\":58146},{\"end\":58156,\"start\":58154},{\"end\":58469,\"start\":58461},{\"end\":58836,\"start\":58830},{\"end\":58847,\"start\":58842},{\"end\":58861,\"start\":58853},{\"end\":59132,\"start\":59122},{\"end\":59144,\"start\":59138},{\"end\":59385,\"start\":59379},{\"end\":59514,\"start\":59506},{\"end\":59754,\"start\":59740},{\"end\":59774,\"start\":59758},{\"end\":59790,\"start\":59780},{\"end\":60342,\"start\":60338},{\"end\":60351,\"start\":60346},{\"end\":60359,\"start\":60355},{\"end\":60371,\"start\":60363},{\"end\":60383,\"start\":60375},{\"end\":60390,\"start\":60387},{\"end\":60400,\"start\":60396},{\"end\":61017,\"start\":61011},{\"end\":61028,\"start\":61021},{\"end\":61038,\"start\":61032},{\"end\":61051,\"start\":61042},{\"end\":61060,\"start\":61055},{\"end\":61075,\"start\":61064},{\"end\":61087,\"start\":61081}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":210692443},\"end\":46855,\"start\":46505},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":232222634},\"end\":47256,\"start\":46857},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b2\"},\"end\":47584,\"start\":47258},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":233562906},\"end\":47799,\"start\":47586},{\"attributes\":{\"doi\":\"10.1109/SCAM52516.2021.00026\",\"id\":\"b4\",\"matched_paper_id\":244532056},\"end\":48338,\"start\":47801},{\"attributes\":{\"doi\":\"arXiv:2208.06318\",\"id\":\"b5\"},\"end\":48619,\"start\":48340},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":747083},\"end\":49085,\"start\":48621},{\"attributes\":{\"id\":\"b7\"},\"end\":49363,\"start\":49087},{\"attributes\":{\"id\":\"b8\"},\"end\":49532,\"start\":49365},{\"attributes\":{\"id\":\"b9\"},\"end\":49707,\"start\":49534},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1053401},\"end\":50064,\"start\":49709},{\"attributes\":{\"id\":\"b11\"},\"end\":50190,\"start\":50066},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":4819701},\"end\":50635,\"start\":50192},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":221980289},\"end\":51011,\"start\":50637},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":2817846},\"end\":51488,\"start\":51013},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":5456487},\"end\":51800,\"start\":51490},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":15044390},\"end\":52243,\"start\":51802},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1178975},\"end\":52576,\"start\":52245},{\"attributes\":{\"id\":\"b18\"},\"end\":52822,\"start\":52578},{\"attributes\":{\"id\":\"b19\"},\"end\":52968,\"start\":52824},{\"attributes\":{\"id\":\"b20\"},\"end\":53286,\"start\":52970},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":4819701},\"end\":53729,\"start\":53288},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":221980289},\"end\":54103,\"start\":53731},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":173173097},\"end\":54581,\"start\":54105},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":13124732},\"end\":54984,\"start\":54583},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":11540100},\"end\":55410,\"start\":54986},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":13040187},\"end\":56079,\"start\":55412},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":210692443},\"end\":56404,\"start\":56081},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":15402514},\"end\":56921,\"start\":56406},{\"attributes\":{\"id\":\"b29\"},\"end\":57048,\"start\":56923},{\"attributes\":{\"id\":\"b30\"},\"end\":57177,\"start\":57050},{\"attributes\":{\"id\":\"b31\"},\"end\":57347,\"start\":57179},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":46948547},\"end\":57756,\"start\":57349},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":85542699},\"end\":58036,\"start\":57758},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3642583},\"end\":58396,\"start\":58038},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":4229473},\"end\":58783,\"start\":58398},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":9558494},\"end\":59056,\"start\":58785},{\"attributes\":{\"id\":\"b37\"},\"end\":59321,\"start\":59058},{\"attributes\":{\"id\":\"b38\"},\"end\":59459,\"start\":59323},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":53662922},\"end\":59672,\"start\":59461},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":49564972},\"end\":60274,\"start\":59674},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":208117506},\"end\":60900,\"start\":60276},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":17855448},\"end\":61381,\"start\":60902}]", "bib_title": "[{\"end\":46544,\"start\":46505},{\"end\":46946,\"start\":46857},{\"end\":47638,\"start\":47586},{\"end\":47879,\"start\":47801},{\"end\":48686,\"start\":48621},{\"end\":49760,\"start\":49709},{\"end\":50227,\"start\":50192},{\"end\":50707,\"start\":50637},{\"end\":51063,\"start\":51013},{\"end\":51537,\"start\":51490},{\"end\":51880,\"start\":51802},{\"end\":52306,\"start\":52245},{\"end\":53323,\"start\":53288},{\"end\":53801,\"start\":53731},{\"end\":54181,\"start\":54105},{\"end\":54652,\"start\":54583},{\"end\":55003,\"start\":54986},{\"end\":55460,\"start\":55412},{\"end\":56120,\"start\":56081},{\"end\":56474,\"start\":56406},{\"end\":57413,\"start\":57349},{\"end\":57814,\"start\":57758},{\"end\":58116,\"start\":58038},{\"end\":58455,\"start\":58398},{\"end\":58824,\"start\":58785},{\"end\":59502,\"start\":59461},{\"end\":59736,\"start\":59674},{\"end\":60334,\"start\":60276},{\"end\":61007,\"start\":60902}]", "bib_author": "[{\"end\":46554,\"start\":46546},{\"end\":46562,\"start\":46554},{\"end\":46571,\"start\":46562},{\"end\":46960,\"start\":46948},{\"end\":46973,\"start\":46960},{\"end\":46985,\"start\":46973},{\"end\":46997,\"start\":46985},{\"end\":47006,\"start\":46997},{\"end\":47268,\"start\":47258},{\"end\":47279,\"start\":47268},{\"end\":47286,\"start\":47279},{\"end\":47299,\"start\":47286},{\"end\":47647,\"start\":47640},{\"end\":47656,\"start\":47647},{\"end\":47662,\"start\":47656},{\"end\":47894,\"start\":47881},{\"end\":47906,\"start\":47894},{\"end\":47916,\"start\":47906},{\"end\":48353,\"start\":48340},{\"end\":48697,\"start\":48688},{\"end\":48710,\"start\":48697},{\"end\":48719,\"start\":48710},{\"end\":48733,\"start\":48719},{\"end\":49186,\"start\":49175},{\"end\":49377,\"start\":49365},{\"end\":49547,\"start\":49534},{\"end\":49557,\"start\":49547},{\"end\":49770,\"start\":49762},{\"end\":49777,\"start\":49770},{\"end\":50124,\"start\":50114},{\"end\":50236,\"start\":50229},{\"end\":50243,\"start\":50236},{\"end\":50259,\"start\":50243},{\"end\":50267,\"start\":50259},{\"end\":50273,\"start\":50267},{\"end\":50282,\"start\":50273},{\"end\":50293,\"start\":50282},{\"end\":50718,\"start\":50709},{\"end\":50730,\"start\":50718},{\"end\":50742,\"start\":50730},{\"end\":50754,\"start\":50742},{\"end\":50767,\"start\":50754},{\"end\":51079,\"start\":51065},{\"end\":51090,\"start\":51079},{\"end\":51104,\"start\":51090},{\"end\":51111,\"start\":51104},{\"end\":51549,\"start\":51539},{\"end\":51895,\"start\":51882},{\"end\":51904,\"start\":51895},{\"end\":51913,\"start\":51904},{\"end\":51922,\"start\":51913},{\"end\":52319,\"start\":52308},{\"end\":52334,\"start\":52319},{\"end\":52679,\"start\":52661},{\"end\":52693,\"start\":52679},{\"end\":52985,\"start\":52970},{\"end\":52995,\"start\":52985},{\"end\":53006,\"start\":52995},{\"end\":53332,\"start\":53325},{\"end\":53339,\"start\":53332},{\"end\":53355,\"start\":53339},{\"end\":53363,\"start\":53355},{\"end\":53369,\"start\":53363},{\"end\":53378,\"start\":53369},{\"end\":53389,\"start\":53378},{\"end\":53812,\"start\":53803},{\"end\":53824,\"start\":53812},{\"end\":53836,\"start\":53824},{\"end\":53848,\"start\":53836},{\"end\":53861,\"start\":53848},{\"end\":54195,\"start\":54183},{\"end\":54207,\"start\":54195},{\"end\":54220,\"start\":54207},{\"end\":54229,\"start\":54220},{\"end\":54244,\"start\":54229},{\"end\":54253,\"start\":54244},{\"end\":54662,\"start\":54654},{\"end\":54670,\"start\":54662},{\"end\":54679,\"start\":54670},{\"end\":54687,\"start\":54679},{\"end\":54694,\"start\":54687},{\"end\":54703,\"start\":54694},{\"end\":55011,\"start\":55005},{\"end\":55020,\"start\":55011},{\"end\":55029,\"start\":55020},{\"end\":55036,\"start\":55029},{\"end\":55473,\"start\":55462},{\"end\":55483,\"start\":55473},{\"end\":55492,\"start\":55483},{\"end\":56130,\"start\":56122},{\"end\":56138,\"start\":56130},{\"end\":56147,\"start\":56138},{\"end\":56486,\"start\":56476},{\"end\":56496,\"start\":56486},{\"end\":56508,\"start\":56496},{\"end\":56937,\"start\":56925},{\"end\":56946,\"start\":56937},{\"end\":56960,\"start\":56946},{\"end\":56970,\"start\":56960},{\"end\":56979,\"start\":56970},{\"end\":57424,\"start\":57415},{\"end\":57431,\"start\":57424},{\"end\":57441,\"start\":57431},{\"end\":57829,\"start\":57816},{\"end\":57840,\"start\":57829},{\"end\":58127,\"start\":58118},{\"end\":58135,\"start\":58127},{\"end\":58144,\"start\":58135},{\"end\":58152,\"start\":58144},{\"end\":58158,\"start\":58152},{\"end\":58471,\"start\":58457},{\"end\":58838,\"start\":58826},{\"end\":58849,\"start\":58838},{\"end\":58863,\"start\":58849},{\"end\":59134,\"start\":59118},{\"end\":59146,\"start\":59134},{\"end\":59387,\"start\":59377},{\"end\":59516,\"start\":59504},{\"end\":59756,\"start\":59738},{\"end\":59776,\"start\":59756},{\"end\":59792,\"start\":59776},{\"end\":60344,\"start\":60336},{\"end\":60353,\"start\":60344},{\"end\":60361,\"start\":60353},{\"end\":60373,\"start\":60361},{\"end\":60385,\"start\":60373},{\"end\":60392,\"start\":60385},{\"end\":60402,\"start\":60392},{\"end\":60408,\"start\":60402},{\"end\":61019,\"start\":61009},{\"end\":61030,\"start\":61019},{\"end\":61040,\"start\":61030},{\"end\":61053,\"start\":61040},{\"end\":61062,\"start\":61053},{\"end\":61077,\"start\":61062},{\"end\":61089,\"start\":61077},{\"end\":61093,\"start\":61089}]", "bib_venue": "[{\"end\":46649,\"start\":46571},{\"end\":47036,\"start\":47006},{\"end\":47394,\"start\":47315},{\"end\":47676,\"start\":47662},{\"end\":48039,\"start\":47944},{\"end\":48458,\"start\":48369},{\"end\":48804,\"start\":48733},{\"end\":49173,\"start\":49087},{\"end\":49418,\"start\":49377},{\"end\":49607,\"start\":49557},{\"end\":49839,\"start\":49777},{\"end\":50112,\"start\":50066},{\"end\":50365,\"start\":50293},{\"end\":50802,\"start\":50767},{\"end\":51199,\"start\":51111},{\"end\":51609,\"start\":51549},{\"end\":52005,\"start\":51922},{\"end\":52394,\"start\":52334},{\"end\":52659,\"start\":52578},{\"end\":52888,\"start\":52824},{\"end\":53113,\"start\":53006},{\"end\":53461,\"start\":53389},{\"end\":53896,\"start\":53861},{\"end\":54322,\"start\":54253},{\"end\":54764,\"start\":54703},{\"end\":55139,\"start\":55036},{\"end\":55588,\"start\":55492},{\"end\":56225,\"start\":56147},{\"end\":56606,\"start\":56508},{\"end\":57112,\"start\":57050},{\"end\":57255,\"start\":57179},{\"end\":57515,\"start\":57441},{\"end\":57882,\"start\":57840},{\"end\":58191,\"start\":58158},{\"end\":58547,\"start\":58471},{\"end\":58904,\"start\":58863},{\"end\":59116,\"start\":59058},{\"end\":59375,\"start\":59323},{\"end\":59543,\"start\":59516},{\"end\":59908,\"start\":59792},{\"end\":60517,\"start\":60408},{\"end\":61125,\"start\":61093},{\"end\":48051,\"start\":48041},{\"end\":48862,\"start\":48806},{\"end\":49428,\"start\":49420},{\"end\":49890,\"start\":49841},{\"end\":50424,\"start\":50367},{\"end\":51274,\"start\":51201},{\"end\":51659,\"start\":51611},{\"end\":53520,\"start\":53463},{\"end\":55229,\"start\":55141},{\"end\":55671,\"start\":55590},{\"end\":56691,\"start\":56608},{\"end\":57576,\"start\":57517},{\"end\":58211,\"start\":58193},{\"end\":58610,\"start\":58549},{\"end\":60011,\"start\":59910},{\"end\":60613,\"start\":60519}]"}}}, "year": 2023, "month": 12, "day": 17}