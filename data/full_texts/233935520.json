{"id": 233935520, "updated": "2023-10-19 02:24:40.699", "metadata": {"title": "Facial expression GAN for voice-driven face generation", "authors": "[{\"first\":\"Zheng\",\"last\":\"Fang\",\"middle\":[]},{\"first\":\"Zhen\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Tingting\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Chih-Chieh\",\"last\":\"Hung\",\"middle\":[]},{\"first\":\"Jiangjian\",\"last\":\"Xiao\",\"middle\":[]},{\"first\":\"Guangjin\",\"last\":\"Feng\",\"middle\":[]}]", "venue": "The Visual Computer", "journal": "The Visual Computer", "publication_date": {"year": 2021, "month": 2, "day": 22}, "abstract": "Cross-modal audiovisual generation is an emerging topic in machine learning. In particular, voice-to-face is one of the most popular research branches, which aims to generate faces from human voice clips. Most recent works in voice-to-face generation do not take emotion information into account. However, it could be widely observed that expressions are the key face attributes to reconstruct sharper and more discriminative faces. In this paper, we propose a novel facial expression GAN (FE-GAN) which takes emotion and expressions into account in face generation. To achieve this goal, we use two auxiliary classifiers to learn more emotion and identity representations between different modalities, respectively. Moreover, we design two discriminators, each focusing on a different aspect of the faces, to measure identity and emotion semantic relevance in generating. The triple loss is designed to make FE-GAN robust to voice variety and keep balance in two different modalities. Extensive experiments are conducted on two real datasets to demonstrate the effectiveness of FE-GAN in both quantitative and qualitative perspectives. The experimental results show that FE-GAN can not only outperform the previous models in terms of FID and IS values, but also generate more realistic face images compared with previous models.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3132207847", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/vc/FangLLHXF22", "doi": "10.1007/s00371-021-02074-w"}}, "content": {"source": {"pdf_hash": "a255f4ee2b043977c204404f8edb95741f8a5243", "pdf_src": "SpringerNature", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "05d1a90e5026212cd7ed40a00d67c6bfceaacdb3", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/a255f4ee2b043977c204404f8edb95741f8a5243.txt", "contents": "\nFacial expression GAN for voice-driven face generation\n2022\n\nZheng Fang \nZhen Liu \nTingting Liu \n\u00b7 Chih-Chieh Hung \nJiangjian Xiao \nGuangjin Feng \nFacial expression GAN for voice-driven face generation\n\nThe Visual Computer\n38202210.1007/s00371-021-02074-wAccepted: 25 January 2021 / Published online: 22 February 2021O R I G I N A L A R T I C L EExpression reconstruction \u00b7 Cross-model generation \u00b7 Voice-to-face generation \u00b7 Generative adversarial networks\nCross-modal audiovisual generation is an emerging topic in machine learning. In particular, voice-to-face is one of the most popular research branches, which aims to generate faces from human voice clips. Most recent works in voice-to-face generation do not take emotion information into account. However, it could be widely observed that expressions are the key face attributes to reconstruct sharper and more discriminative faces. In this paper, we propose a novel facial expression GAN (FE-GAN) which takes emotion and expressions into account in face generation. To achieve this goal, we use two auxiliary classifiers to learn more emotion and identity representations between different modalities, respectively. Moreover, we design two discriminators, each focusing on a different aspect of the faces, to measure identity and emotion semantic relevance in generating. The triple loss is designed to make FE-GAN robust to voice variety and keep balance in two different modalities. Extensive experiments are conducted on two real datasets to demonstrate the effectiveness of FE-GAN in both quantitative and qualitative perspectives. The experimental results show that FE-GAN can not only outperform the previous models in terms of FID and IS values, but also generate more realistic face images compared with previous models.\n\nIntroduction\n\nCross-modal generation aims to generate data from one modality conditioned on another correlated modality, which has attracted a lot of research efforts. Early researches on cross-model generation usually generate low-dimensional data from high-dimensional data, such as voice-to-text [1,2] and image-to-text [3,4]. Recently, thanks to the rapid growth of generative adversarial networks (GANs) [5] and with increase in multi-modal datasets [6], it is possible to generate B Zhen Liu liuzhen@nbu.edu.cn Zheng Fang 1901100018@nbu.edu.cn 1 complex data from low-dimensional data, such as text-toimage [7,8] and audio-to-image [9,10]. Note that the audio and visual information are the most important perceptual modalities in our daily life. We believe that the research on cross-modal audiovisual generation can endow machines with humanized capabilities of imagination and interpretation. Here, we leverage the voices to directly generate speakers' facial images by GANs.\n\nMany previous works have been done in solving the audio-image generation problem. Duarte et al. proposed conditional GANs (cGANs) [11] to directly generate face from voice [12]. Later, Wen et al. used an auxiliary classifier GANs (AC-GANs) [15] to directly generate face [14]. Oh et al. leveraged the encoder-decoder network to learn the crossmodal visual-audio mutual relationship, then generated the face based on the corresponding static face and voice [13]. However, generated faces from studies above are usually with certain unsatisfactory artifacts and missing parts. The reasons are twofold. First, face generation in previous works usually considers identity information of target faces but leave alone the corresponding facial expressions. It can be observed that one's expression can usually change with different emotions when she/he talks to others. Emotion would be a key to construct high-quality facial image. Second, we find that GANs with a single discriminator are not able for learning the complex mapping relationships between audio and visual modalities. That is, a constraint that only allows the generated images to be on the one manifold of the truth data distribution.\n\nTo improve the quality of faces generated, it is a promising way to have multiple discriminators, rather than only one, to help the generator learn from more fine-grained face features extracted from audio.\n\nIn this paper, we propose a novel model, facial expression GANs (abbr. as FE-GAN) to generate faces by given voice information. In a nutshell, FE-GAN considers emotion and identity variations from face and voice simultaneously. The existence of semantic consistency in human's voice and face [16,17] inspires us to adopt both identify labels and emotion labels for model training. Specifically, more discriminators could take the emotion and identity constraints into account so that the generator can also retain more emotion and identity characteristics. The simplified pipeline of the proposed method is shown in Fig. 1. The core of FE-GAN is composed of one generator network (G-net) and two discriminatorclassifier pairs, say (C1-net, D1-net) and (C2-net, D2-net). In the generating process, the voice encoder extracts the Fbank features F v from voice clip V and obtain voice embedding E v by V-net. Next, taking E v as an input, generator G-net generates the face image I G . Finally, the two discriminators D1-net and D2-net are used to distinguish whether or not a face image is real or fake, meanwhile, the auxiliary classifier C1-net and C2-net predict its identity and emotion. This design of FE-GAN can not only learn one-to-one mapping between faces and voices but also capture various emotions of the target person that are correlated with the input speech. Our contributions can be summarized as follows:\n\n(1) We propose an effective GAN model (FE-GAN) for cross-modal voice-to-face generation. It explores the emotional and identity relationship in cross-modal voiceto-image task and generates sharper facial images with expression. (2) We adopt two discriminators and two classifiers in GANs. They help the model generate more realistic images, and transfer the label information to generator. Besides, we explore the multiply discriminators and classifiers optimization problem, a triple loss is presented to optimize the FE-GAN. (3) We conduct qualitative and quantitative experiments on RAVDESS [18] and eNTERFACE [19] dataset, the results show that FE-GAN outperforms previous GANs methods [12,14] and achieves the best performance in the series metrics with remarkable improvements. The rest of the paper is organized as follows. Section 2 lists the previous relevant research works. Section 3 gives the technical detail of the proposed approach FE-GAN. Section 4 reports the experimental results. Section 5 concludes this paper. Fig. 1 The simplified pipeline of the proposed method. Our method has divided into two parts: voice encoder (gray dashed box) and FE-GAN (blue dashed box). (1) Voice encoder consists of VAD (voice activity detection) and V-net, which takes Fbank features F v as input, and outputs embedding features E v . (2) FE-GAN consists of five parts: G-net, C1-net, C2-net, D1-net and D2-net. The FE-GAN is used to transfer embedding E v into face image I G , then to predict its sources (true or fake) and categories (emotion and identity) 2 Related work\n\n\nGenerative adversarial networks\n\nGANs [5] is an excellent game theory architecture. It is easily assembled with others backbone networks and mechanisms. A vanilla GANs [5] consists of two neural networks: a generator and discriminator. Given a random sample with noise, the generator attempts to generate image for fooling the discriminator. Then, the discriminator is responsible for distinguishing generated image and real image. In order to address the training instability and get high-quality generated results, many variants of GAN have been developed. For example, conditional GANs (cGANs) [11] introduces a conditional constraint to get more attribute information, the condition could be class labels, object attributes or feature embeddings. However, it will bring additional noise to network and increases extra burdens to training process. Compared to cGANs, auxiliary classifier GANs (AC-GANs) [15] leverage an additional auxiliary classifier to assist in supervising the learning process, which is share weights with discriminator and can help GANS to generate sharper images. Besides, dual discriminator GANs (D2GANs) [20] and generative multi-adversarial networks (GMANs) [21], which use multiple discriminators to improve generation performance, extend GANs architecture.\n\nRecently, many cross-modal methods use GANs and their variants to generate face from voice [12][13][14][22][23][24][25]. Inspired by the above success of GANs in cross-modal generation task, we establish our FE-GAN model based on AC-GANs [15] and D2GANs [20]. Different from the two GANs, we employ two discriminator and corresponding classifiers to guide the generator for producing photo-realistic facial images.\n\n\nAudio representations selection and extraction\n\nIn human interaction, voice contains various emotions and identity information, which conveyed by linguistic information (e.g., word, sentence and language meaning) [26] and prosodic information (e.g., voice pitch, tempo, loudness and intonation) [27]. The linguistic contents are dynamic variation and highly dependent on word dictionaries and language model [26,28]. However, it is unreliable and difficult to infer speaker's emotion and identity state by linguistic features [29]. Compared to linguistic information, the prosodic information are global-level and they cannot describe the dynamic variation in voice [30]. Thus, we decide to learn audio representations from speech prosody, and transfer the emotional and identity knowledge into face images.\n\nThe quality of audio representations influences the results of generation methods. Most audio-related methods involve the analysis of a speech representations using either handcrafted prosody features (e.g., Mel Frequency Cepstral Coefficients (MFCCs), Perceptual Linear Prediction (PLP), Spectrograms, Fbank and Fourier transforms), or through a neural network which indirectly learns high-level representations. Compared to these hand-crafted methods [31,32], the convolutional neural networks (CNNs) are enabled to learn robust high-dimensional features, which achieve high accuracy in emotion and identity classification [30,33,34]. Therefore, we also use CNNs as audio feature extractors (Vnet) to extract emotion and identity information from prosody features. Our experiments prove that CNNs are able to learn temporal filters across features and distill an entire utterance down into a static representation by fully connected layer to model.\n\n\nAudio-to-visual generation\n\nMany methods have been proposed to reconstruct visual information from different types of audio signals. Existing studies in audio-to-visual generation mainly synthesize a specific talking face from an audio clip and a still image. For example, Chung et al. [23] use facial landmarks and voice clip to synthesize a talking face video by an encoder-decoder CNNs model. Chen et al. [22] design a cascade GANs combined RNN to learn joint features from voice clip and facial landmarks to generate talking face video on the features. Furthermore, Vougioukas et al. [24] and Yi et al. [35] consider facial expressions in generation. They adopt GANs to synthesize a talking face video from voice and image.\n\nOn the other hand, some methods try to generate lip shapes from voice to synthesize a specific identity face with lip shape. Suwajanakorn et al. [36] and Jalalifar et al. [37] use the long-short term memory (LSTM) network to generate talking mouth features from voice to synthesize a talking video of Obama conditioned on these landmarks. To improve the quality of synthesis lip, Sadoughi and Busso [38] propose cGANs to learn emotion features from the speech, and generate lip animation with different expressions. However, these methods need to parametrize the reconstructed face model a priori, this often requires post-processing using computer graphics techniques to produce realistic albeit subject-dependent results.\n\nThere are very few works try to leverage audio to directly generate facial image, which is different from the abovementioned methods using both audio and visual modalities as inputs. Existing methods on voice-to-face generation [12][13][14] use CNNs to extract embedding features from input voice, then the feature is feed into the generator or decoder to generate corresponding images. Moreover, some works generate images condition on music directly [10,39]. To overcome shortcomings of the conventional cross-modal GANs model and generate more realistic face, we introduce the emotion to our facial expression GAN (FE-GAN) and perform voiceto-face generation.\n\n\nProposed methods\n\n\nOverview of V-net and FE-GAN\n\nThis section gives the detailed architecture of V-net and FE-GAN, as shown in Fig. 2. V-net is a standard CNNs with normalization, which learns a voice embedding from speech prosody feature. FE-GAN is composed of G-net (which generates a face image from a voice embedding), D1-net with C1-net, and D2-net with C2-net (two pairs of a discriminator with its classifier to identify whether a face image is true from identity and emotion perspectives, respectively).\n\nAfter extracting speakers' voice and face from videos, we can obtain the training dataset tuples of F v , I T , l ve , l vi , l fe , l fi , where F v are the Fbank features extracted from speakers' voice, I T is the face image, and l xy is the label of y based on attribute x where x can be v (voice) or f (face) and y can be i (identity) or e (emotion). Given the identity label l vi and the Fbank feature F v , we firstly pre-train V-net to classify a person through her voice. After pre-training of V-net, the voice embeddings E v of each voice can be extracted.\n\nSubsequently, given a voice embedding E v with Gaussian noise N g , G-net is trained to generate the target face I G . Concurrently, we use the true face I T with labels (l fi , l fe ) and fake faces I G with labels (l ve , l vi ) to train the discriminators D1-net and D2-net, with the auxiliary network C1-net and C2-net. In this way, D1-net and D2-net are trained to distinguish input face image I T or I G is true or fake, respectively; C1-net and C2-net are trained to classify the emotion and identify labels of input face, respectively. Besides, the proposed triple loss combining loss equations from the generator, the discriminators and the classifiers are designed to optimize FE-GAN.\n\n\nPre-processing and V-net\n\nWe firstly use voice activity detection (VAD) module [40] for original voice to remove the silent frames (e.g., in RAVDESS datasets, the average duration time of the original voice is 3.6 s. After removing silent parts, it is shortened into 2.4 s.). Then, the voice clips are resampled at 32 kHz and a single audio channel is preserved. Next, we repeat the audio clips 3 4 times and eliminate the redundancy so that they all become 10 s long. Furthermore, Fbank features (F v ), MFCC and Spectrogram are calculated by fast Fourier transform with window length of 33 ms (milliseconds), and a hop length is 16 ms. In addition, we use the face detector based on Resnet-18 in Dlib [41] to detect the face regions from video, and resize them to 128\u223c128 pixels. To augment the training data, we use random cropping in audio features and left-right flipping in image, the cropping length is 300-800 ms.\n\nOur V-net aim to classify features F v into different identity categories and extract voice embedding features E v .\nV-net takes 64 \u00d7 T (frequency \u00d7 time) dimensional F v as input, and outputs 1 \u00d7 128 dimensional features E v .\nThe top row of Fig. 2 shows the network architecture of V-net where there are 5 one-dimensional convolutional layers 1D-Conv1, 1D-Conv2, . . ., and 1D-Conv5 with kernel size 3, stride 2 and padding 1 and a batch normalization (BN) operation is followed with Leaky-ReLU as the activation function. After the 5th convolutional layers, the temporal channels of F v have been decimated to 256. Next, we apply the average 1D pooling layer along the temporal dimension. This allows us to efficiently aggregate information over time and makes the model applicable to input speech of varying duration. By the 1D pooling layer, Vnet compresses features E v to 1 \u00d7 128 dimensions. Besides, cross-entropy loss with softmax function is used to train Vnet.\n\n\nG-net\n\nG-net will learn the emotion and identity mapping between voice embeddings and generated images so that it can generate more realistic face images to deceive discriminators. The architecture of G-net is shown in the middle row in Fig. 2. First of all, the voice embedding E v is concatenated with 1 \u00d7 128 dimensional noise N g and this concatenated embedding is mapped to 1 \u00d7 1 \u00d7 128 by two fully connected layers (FC1, FC2) with BN operation and ReLU function. Then, we use 6 two-dimensional transposed convolution layers (Tr-Conv1 6) to upsample to 3\u00d7128\u00d7128 dimensional I G . Each layer has kernel size 4, stride 2 and padding 1 followed by BN and ReLU. Apart from the first layer (kernel size 4, stride 1 and padding 0) and the last layer (kernel size 1, stride 1 and padding 0). The number of channels in transposed layers is 1024-512-256-128-64-32. To improve the generative capacity of G-net, we add a dropout strategy and Tanh activation function inspired by Wasserstein GANs [42].\n\n\nD-net and C-net\n\nThe original AC-GANs conducts backpropagation mainly determined by one discriminator and one classifier. One discriminator only judges the images from the one perspective, but not the different semantic perspectives. Likewise, one classifier is not able to solve multi-label consistency problem. In the paper, we argue that corresponding voice and face can match with the two types semantic label. Therefore, apart from distinguishing real or fake identity attributes of the speaker from D1-net, we also distinguish real or fake emotion attributes by D2-net. To further control the label consistency in generating, we use two corresponding classifiers C1-net and C2-net to make sure the generated faces belong to the same label with input audios.\n\nD1-net and D2-net are designed to discriminate whether the input image is real face I T or fake I G . In this way, the fake label and true label are, respectively, couple with I G and I T , then input them into D1-net and D2-net to get two scores. The two discriminators architecture is shown in bottom row in Fig. 2. They both have 6 two-dimensional convolution layers. Each layer is only followed by a Leaky-ReLU function. The number of channels in convolution layers is inverse of G-net that is 32-64-128-256-512-1024, and the other parameters like kernel size, stride are also inverse. Finally, we apply a FC7 with 1 channel and sigmoid activation function to obtain a score as the output. Besides, our discriminators base on DCGANs [43] architecture.\n\nC1-net is emotion classifier that helps achieve expression reconstruction of the speakers. And the C2-net is identity classifier that ensures the speakers' facial identity. In other words, the emotional category of I G and corresponding voice emotion label Lve should keep consistent, and face emotion label Lfe is consistent with the category of I T . In addition, C1-net and C2-net share weights with the convolution layers in D1-net and D2-net, respectively. The architectures of the classifiers are similar to D1-net and D2-net, as shown in bottom row in Fig. 2, they also consist of the 6 twodimensional convolution layers followed by Leaky-ReLU functions, a FC7 and softmax function. The FC7 of the two classifiers have i and m channels, respectively (i denotes the number of speakers, and m denotes voice emotion categories).\n\n\nTriple loss\n\nOur triple loss is composed of three parts: The G-net loss L G , two discriminator losses L D1 and L D2 , and two classifier losses L C1 and L C2 . The generator and discriminator losses are both designed to reduce the differences between true face I T and generated face I G . The classifier losses target to guarantee the semantic consistency, which can control the generated faces in the specific class domains. Here, we use these losses to optimize the different parts of FE-GAN, the backpropagating paths of these losses are shown in Fig. 2.\n\nFirst, we adopt the cross-entropy loss with softmax activation as losses of two classifiers. Here, the loss equations of L C1 and L C2 are defined as: \nL C1 = \u2212\nwhere p(l) denotes the probability of the label l, l j fe and l j ve denotes the j-th face and voice emotion labels, respectively; l j fe (C2, I T ) and l j fe (C2, I G ) denotes that the predicted label by C2-net given the true and generated faces are the j-th emotion label, respectively; m denotes the numbers of emotion categories.\n\nThen, the generator loss L G of G-net is defined as:\nL G = 1 2 E (e v ,N g )\u223cdata [\u2212logD 1 G e v , N g \u2212logD 2 G e v , N g ](3)\nwhere D 1 , D 2 and G represent the discriminators D1-net, D2net and generator G-net, respectively; embedding feature E v is from V-net; G(E v , N g ) takes E v and a random noise N g as input, and generates a fake image I G , that is, G e v , N g = I G ; D 1 (G(.))is the score assigned by discriminator D1-net, D 2 (G(.)) is similar to D 1 that is the score assigned by D2net, e.g., D 1 (I T ) is the score from D1-net given a real image I T . Meanwhile, the two discriminators loss L D1 and L D2 are formulated as:\nL D i=1,2 = E (I T )\u223cdata log (D i (I T )) + E (e v ,N g )\u223cdata log 1 \u2212 D i G E v , N g .(4)\nFinally, we implement cross-entropy loss with sigmoid function as loss functions L G , L D1 and L D2 , and our triple loss L triple is a combination of the above four losses:\narg min {G,C1,C2} max {D1,D2} L triple = L G + \u03bb 1 L D1 +\u03bb 2 L D2 + L C1 + L C2(5)\nwhere \u03bb 1 and \u03bb 2 are the hyper-parameters to control the relative weight of L D1 and L D2 , respectively. In triple loss, the generator learns to minimize the score that can obtained by the generated I G , then the two discriminators learn to give higher score to the real images I T and give lower score to the generated images I G to maximize L D1 and L D2 . Besides, the two classifiers need to minimize L C1 and L C2 between the predicted label from I G or I T and the target emotion and identity label.\n\nNote that the proposed triple loss is different from the loss in Triangle GANs (\u0394-GANs) [44] and Triple GANs [45], which adopts their triple loss between the input image and the reconstruction image in the image space. In this paper, we employ the two different modalities triple loss to optimize our FE-GAN. In addition, FE-GAN is trained in a semisupervised manner. The generator and the discriminators are trained iteratively. That is, the generator is fixed, and two discriminators and two classifiers are updated once. Then, we fix the discriminator, and update the parameters of the generator.\n\n\nExperiments\n\n\nDatasets and settings\n\nTo validate the performance of FE-GAN in voice-to-face generation task, our experiments are run on two multi-modal datasets: RAVDESS [18] and eNTERFACE [18]. They are collected in lab-controlled environments where the speakers are asked to read the given sentences with certain voice emotions and facial expressions. RAVDESS consists of 1440 clips, which are expressed by 24 actors with 8 emotion categories. eNTERFACE contains 1166 clips, which are expressed by 43 speakers with 6 emotion categories. Table 1 summarizes the details of the datasets used in our work.\n\nOur model is implemented in PyTorch and trained on Nvidia GeForce RTX 2080ti. V-net and FE-GAN are trained separately. First, using RAVDESS [18] or eNTERFACE [19] datasets, V-net is pre-trained where SGD optimizer is chosen, the batch size is 64 and the initial learning rate is 0.03 which decreases by half for every 100 epochs. Next, FE-GAN is trained with Adam optimizer, the batch size is set to 64 and the learning rate is 0.0002. In addition, the hyper-parameters \u03bb 1 and \u03bb 2 in triple loss is 0.7 and 0.3, respectively.\n\n\nEvaluation metrics\n\nTo evaluate realism and variation of the generated images, we choose Inception score (IS) [46], Fr\u00e9chet Inception Distance (FID) [47] and classification accuracy as quantitative metrics.\nIS (g) = exp E x\u223cg D K L p y x p (y)(6)\nwhere x \u223c g represents generated images from generator; p(y) and p(y|x) are marginal label distribution and conditional label distribution, respectively. FID measures the quality of an overall generative images. FID computes the Wasserstein-2 distance between the generated images and the real images in the feature space from by a pre-trained Inception-v3 network [48]. The FID is defined as follows:\nF I D (x, g) = \u03bc x \u2212 \u03bc g 2 2 +T r \u239b \u239d x + g \u22122 x g 1 2 \u239e \u23a0 (7)\nwhere (\u03bc x , \u03bc g ) and ( x , g ) are the means and covariances of the images from the true dataset distribution and generator's learned distribution, respectively. The authors of FID [47] shows that FID is consistent with human judgment and more robust to noise than IS.\n\nIn our experiments, a lower IS value indicates that the model can produce the images that are less variety and not associated with voice features; a higher IS indicates that the model falls into mode collapse and the images have blurry parts. Thus, the reasonable IS of models is similar to the datasets. FID is a more confident and comprehensive metric. A lower FID value means the generated images are closer to the distribution of a dataset. In addition, to evaluate the model's performance regarding the identity and emotion preservation, we compute the emotion and identity classification accuracy by VGG-Face network [49]. The way to obtain accuracy is that the VGG-Face are pre-trained on RAVDESS or eNTERFACE dataset, and then we use the pre-trained VGG-Face on our generated results. Due to the  [12,14] lack of the emotion in generating, we are not able to compute emotion accuracy of their works.\n\n\nAblation experiments\n\nTwo ablation experiments are conducted on RAVDESS dataset to (1) find which kind of audio feature is the most suitable feature for our task, and (2) analyze the contribution of each component of our FE-GAN.\n\nFirst of all, we perform ablation experiment on different audio features: MFCC, Fbank and Spectrogram. Specifically, we report IS and FID by using the same model and training method with audio features varied. Table 2 shows the quantitative results. Fbank can lead to the highest FID score (58.79) and IS score (1.71) and MFCC is in the second place with a litter higher value FID (64.35) and a lower IS (1.65). Compared to Fbank and MFCC, Spectrogram performs the worst where FID score (96. 16) and IS score (1.91) are the highest IS (1.91) among all the audio features. The reason may be threefold: (1) Spectrogram is too primitive so that it may include many irrelevant emotion and identity information in audio; (2) MFCC outperforms Spectrogram, but it only retains 13dimensional features that related to speech content, and discards some information about emotion and identity; (3) Fbank is best because it preserves more prosodic and acoustic information from the inputting voice. Figure 3 shows the qualitative results. We can observe that Fbank can obtain better generated images compared with MFCC and Spectrogram. In general, images generated by Fbank is sharper and with more distinct expressions in mouth and eye. Therefore, Fbank feature is selected in the rest of experiments.\n\nSecond, we conduct an experiment to evaluate the impact of four components in FE-GAN, say (a) C1-net, (b) C2-net, (c) D1-net and (d) D2-net. These four components share the same baseline (FE-GAN) but a particular part is abandoned. That is to say, FE-GAN is running without (a) C1-net, (b) C2-net, (c) D1-net and (d) D2-net. Table 2 shows their IS and FID scores. can make a dramatic improvement in FID by 42.3% and in IS by 12.8%. As C1-net and D1-net share weights, the well-trained C1-net can provide the basic identity information to D1-net so that the generated images of different speakers are forced to keep the consistency of identity label between voices and images. (b) Influence of C2-net: If adding C2-net, it can lead to further improvement in FID by 47.0% and in IS by 10.4%. The emotion feature is a special identity feature that relies on facial attributes, and the single C1-net has weak representation ability to extract emotion features. Thus, we use C2-net to learn the emotion representation from voice. The union of C1-net and C2-net can progressively reduce the collapse mode in training and improve the classification accuracy of generated images. (c) Influence of D1-net: If using D1-net, it can improve FID by 53.8% and IS by 3.4%. The discriminator loss L D1 provides G-net strong guidance toward the groundtruth. Besides, C1-net shares weights with D1-net, it can optimize G-net from point of view of the identity label distribution. Therefore, G-net knows the way to learn identity semantic relevance between image and voice. (d) Influence of D2-net: The single discriminator only discerns images by one attribution and it cannot exactly control the content of generated images. Therefore, we add two discriminators to improve distinguish ability and generation performance. Extra D2-net can supply the missing emotion information to our model. Table 3 shows that D2-net can improve 34.7% in FID and 2.3% in IS, which means that the two discriminator performs better than the single discriminator and further improve image quality. The shared weights also could help to learn better D2-net.\n\nFinally, Fig. 4 visualizes the influence of above components. The generated images by full model have more fine-grained details and are more similar to the ground truth. \n\n\nRobustness tests\n\nRobustness of FE-GAN is evaluated in this section. Two robustness experiments are conducted to verify how FID and First of all, we study the effect between various levels of noise and quality of images. On RAVDESS dataset, we add different intensities of babble noises to voice with four Signal Noise Ratio (SNRs): 1 dB, 5 dB, 10 dB and 25 dB. The qualitative results for the experiments with added noise can be seen in Figs. 5 and 6. While the noise intensity is increased, we observe that the generated images are gradually to be blurry and unrecognizable. The reason may be that the useful features can be destroyed by noises as no identity and emotion information in noises. Moreover, the quantitative results of this experiment are reported in Table 3. We also observe that the FID and IS scores of various levels of noise gradually decrease, which are also consistent with the qualitative results.\n\nThe effect of different audio durations on FE-GAN is then evaluated. We conduct experiment on 1 s, 3 s, 5 s and 10 s voice segments. We observe that the audio duration has obvious effect on the quality of the reconstructions, as shown in Figs. 5 and 6. The qualitative results show that a longer duration of the input voice can improve the performance. For example, when using 10 s voice segments (the 4th column in Figs. 5 and 6), the generated faces are seen to be more clear, recognizable and less background noises. Furthermore, the corresponding quantitative results are also shown in Table 3. We find that feeding longer audio segments as input leads to considerable improvement in the FID and IS scores, that Besides, Figs. 5 and 6 also show qualitative comparison of the effect of gender. We find that the model is able to successfully capture the latent attributes like gender, reconstructing the facial image with different voices.\n\n\nComparison to state-of-the-art\n\nTo verify the effectiveness of our FE-GAN model, we compare with two state-of-the-art methods on RAVDESS and eNTERFACE datasets, say AC-GAN [14] and CGANs [12]. Table 4 shows the comparison results of FID and IS, and Table 5 shows results of identity classification accuracy. We first conduct comparison on the RAVDESS. Table 4 shows that FE-GAN performs better than AC-GAN, which can improve FID by 23.7% and IS by 2.8%. Compared with CGANs method, FE-GAN also improves FID by 48.1% and IS by 2.3%. As shown in Table 5, we make an improvement in training accuracy of identity by 9.7%, 15.1% compared with AC-GANs and CGANs, respectively. In the testing dataset, FE-GAN can achieve an increase of 9.8% and 18.0% compared with AC-GANs and CGANs. Besides, FE-GAN always achieves the high emotion accuracy of 95.08% in the training dataset. These quantitative results reveal that the sufficient utilization of both identity and emotion infor-   Fig. 7, which also based on our FE-GAN and two competitors. It can be seen that FE-GAN can not only generate the faces with more exactly identity information, but also maintain the more expression information. Our results have less noise in background and are more realistic than without emotion samples.\n\nTo further verify the robustness of our method for voice-toface generation, we evaluate our method on another dataset eNTERFACE and also give the comparison results in Tables 4  and 5. In Table 4, we observe that our method achieves the highest IS (1.89) and the lowest FID (84.58), demonstrating the effectiveness and robustness of our method. As shown in  Table 5, FE-GAN also achieves the highest identity accuracy in training (99.23%) and testing (76.83%). FE-GAN outperforms comparison methods in eNTERFACE. However, there are still some defects in the generated images. Figure 8 shows that the faces are blurs and artifacts, even corrupted facial expressions around eyes, nose and mouth regions. Besides, our method also gets the low emotion accuracy of 73.15% on training images. This is because of the imbalanced data distribution and large variance between same class of training data. A low-quality and bad-controlled dataset may cause unstable generation results. Although the images in Fig. 8 are not sharp, we can still see that the identity of the generated images is semantically consistent with the input audio information, which means our method has captured the semantic attribution from speech features to some extent.\n\n\nLimitation of FE-GAN\n\nDuring our experiments, we found there are some generated images which have observable failures as shown in Figs. 3, 4 and 7. The major problems include moderate artifacts (e.g., the texture and color of face seem unnatural), loss of facial contours and details (e.g., tooth, hair and eyebrow region are obscure or missing), and minor semantic inconsistency (e.g., compared with GT images). There are the two main reasons for these problems: (1) The intra-personal and interpersonal variances of emotion are large in datasets, which make FE-GAN hard to learn these face and voice emotion features effectively. (2) The input embedding features are only from the single modality (voice) instead of multiple modalities (voice and face). That is, a part of facial attributes is irrelevant to speakers' voices so that the generator cannot build these mapping between voice and face. Therefore, it is unable to generate high-quality tooth, hair, eyebrow and head pose by only using single modality features.\n\n\nConclusion\n\nFacial expression plays an important role in high-quality face generation. Human perception is very sensitive to subtle facial expression. Therefore, without taking emotion about this face and voice into account, it is hard to generate shaper and proper face images. In this paper, we propose a novel FE-GAN to consider the emotion in voice-to-face generation problem. Specifically, audio emotion and identity are used to directly generate face images with expressions. We proposed FE-GAN which includes one generator and two discriminators with their auxiliary classifiers. The core idea is to use auxiliary classifiers to help discriminators to better identify whether a face image is generated or true based on the identity and emotion represented in this image. Therefore, the generator can be trained to generate more realistic face images. Finally, the proposed triple loss facilitates the generalization and optimization ability of the model. Experimental results show that our proposed method outperforms the state-of-the-art approaches in both quantitative and qualitative perspectives.\n\nFE-GAN has its own limitation. Firstly, the output based on single generator has model collapse and over-fitting problems. For example, some facial identity features and emotional features cover up each other, resulting in a lot of ambiguous and pixel jittering in images, and some emotion samples are insufficient, which can affect the generation of face images. On the other hand, the model is hard to achieve the best balance between the two discriminators in training. In addition, the intensity of the expressions should be considered to further improve the quality of generated images. \n\nFig. 2\n2The detailed architecture of V-net and FE-GAN. The symbol + represents concatenation operation; the / represents OR operation chooses the corresponding labels, and the label symbol l fe , l fi , l vi , l ve (yellow blocks) represent face emotion, face identity, voice emotion and voice identity, respectively; I T and I G (gray blocks) represent real face from dataset and fake face from G-net, respectively; blue line and green dotted line denote forward and backward propagation paths, respectively. The dimensions of input and output are denoted on top of the blocks. Besides, the loss equations L G , L D1 , L D2 , L C1 , L C2 (green blocks) and other symbols are described in the rest of Sect. 3\n\n\n(C1, I G )(1)where p(l) denotes the probability of the label l, l j fi and l j vi denotes the j-th face and voice identity labels, respectively; l j fi (C1, I T ) and l j vi (C1, I G ) denotes that the predicted label by C1-net given the true and generated faces are the j-th face identify label, respectively; n denotes the numbers of identity categories. ve log p l j ve (C2, I G )\n\n( a )\naInfluence of C1-net: If adding C1-net into the model, it\n\nFig. 4\n4Ablation experiments 2: generated images by four components that performed on the RAVDESS dataset. The red circle depicts the obscured and incorrect regions under analysis for different expressions is, reconstructed faces capture the personal attributes and emotions better, regardless of which of the levels of noise are added.\n\nFig. 5 Fig. 6\n56Robustness Robustness tests with male speakers: generated images by voices with different noisy conditions and duration times that performed on the RAVDESS dataset\n\nFig. 8\n8Generated images of different methods on the eNTERFACE dataset\n\nTable 1 Summary\n1of datasets' \nsample numbers, duration time \nand emotion categories \n\nDatasets \nSpeakers \nEmotion categories \n(numbers) \n\nDuration time (h) \n\nRAVDESS \n24(12 M, 12 F) \nHappy (384), angry (384), \nsad (384), surprise (384), \nfear (384), disgust (384), \ncalm (384), neutral (192) \n\n\u223c 4 \n\neNTERFACE \n43(34 M, 8 F) \nHappy (213), anger (217), \nsad (216), surprise (216), \nfear (216), disgust (216) \n\n\u223c 11 \n\nM for male, F for female \n\nprevious works \n\nTable 2\n2Ablation experiments: \nFID and IS results of different \naudio features, duration time, \nnoises and components on \nRAVDESS dataset \n\nExperiments \nAblation items \nFID Score \nIS Score \n\nAudio features \nSpectrogram \n96.16 \n1.91 \n\nMFCCs \n64.35 \n1.65 \n\nFbank (our method) \n58.79 \n1.71 \n\nNetwork components \nWithout C1-net or C2-net \n101.94/110.84 \n1.96/1.91 \n\nWithout D1-net or D2-net \n127.12/90.02 \n1.77/1.67 \n\n\n\nTable 3\n3Robustness tests: FID and IS results of different duration times \nand noises on RAVDESS dataset \n\nExperiments \nInput items \nFID Score \nIS Score \n\nNoise intensity (dB) \n1 \n61.56 \n1.71 \n\n5 \n68.08 \n1.73 \n\n10 \n72.92 \n1.63 \n\n25 \n93.57 \n1.43 \n\nAudio duration time (s) \n1 \n72.70 \n1.67 \n\n3 \n67.98 \n1.68 \n\n5 \n64.17 \n1.72 \n\n10 \n58.54 \n1.71 \n\nIS scores vary when different input conditions are given: (1) \nthe audio with different levels of noise; (2) the audio with \ndifferent time durations. \n\n\nTable 4\n4FID and IS results of different methods on RAVDESS and eNTERFACE datasetMethods \nFID score \nIS score \n\nRAVDESS \neNTERFACE \nRAVDESS \neNTERFACE \n\nFE-GAN (our method) \n58.79 \n84.58 \n1.71 \n1.89 \n\nAC-GANs [14] \n77.04 \n94.26 \n1.76 \n1.71 \n\nCGANs [12] \n113.31 \n129.28 \n1.75 \n1.78 \n\nGround truth (GT) \n-\n-\n1.71 \n1.94 \n\n\n\nTable 5 Identity\n5Fig. 7Generated images of different methods on the RAVDESS dataset. The red circles depict the eye regions under analysis for different expressions mation from voice can significantly boost the performance of classification task. Furthermore, the qualitative results of RAVDESS are as shown inclassification \naccuracy of different methods \non RAVDESS and \neNTERFACE dataset \n\nMethods \nTraining (%) \nTesting (%) \n\nRAVDESS \neNTERFACE \nRAVDESS \neNTERFACE \n\nFE-GAN (our method) \n99.40 \n99.23 \n84.64 \n76.83 \n\nAC-GANs [14] \n89.37 \n92.10 \n74.79 \n68.03 \n\nCGANs [12] \n84.22 \n83.57 \n66.67 \n59.27 \n\n\n\nZheng Fang received his masters degree in 2018 from Wenzhou University, China. Now, he is pursuing the PhD degree in Faculty of Electrical Engineering and Computer Science, Ningbo University, China. His research interest is affective computing. Liu is a professor in Faculty of Electrical Engineering and Computer Science, Ningbo University, China. His main research interests include virtual reality and artificial intelligence. Tingting Liu is an associate professor in College of Science and Technology, Ningbo University, China. Her research interests include virtual reality and artificial intelligence. Chih-Chieh Hung is an assistant professor in the Department of Management Information System, National Chung Hsing University (NCHU), Taiwan. His research interests include data mining, pervasive and mobile computing, big data systems, e-commerce intelligence, and artificial intelligence. Jiangjian Xiao is a professor at Ningbo Industrial Technology Research Institute, CAS. His research interests include computer vision, computer graphics, and visualization. He is a member of ACM and IEEE. He also is an associate editor of Machine Vision and Application Journal. Feng received his bachelors degree from Ningbo Institute of Technology, Zhejiang University, China, in 2018. Now he is pursuing the masters degree in Faculty of Electrical Engineering and Computer Science, Ningbo University, China. His research interest is human action recognition.Zhen Guangjing \nCompliance with ethical standardsConflict of interest All authors declare that they have no conflict of interest.\nRobust speech recognition using generative adversarial networks. A Sriram, H Jun, Y Gaur, S Satheesh, 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). Sriram, A., Jun, H., Gaur, Y., Satheesh, S.: Robust speech recog- nition using generative adversarial networks. In: 2018 IEEE International Conference on Acoustics, Speech and Signal Pro- cessing (ICASSP), pp. 5639-5643 (2018)\n\nS H Dumpala, I Sheikh, R Chakraborty, S K Kopparapu, arXiv:1912.11151A Cycle-GAN approach to model natural perturbations in speech for ASR applications. arXiv preprintDumpala, S.H., Sheikh, I., Chakraborty, R., Kopparapu, S.K.: A Cycle-GAN approach to model natural perturbations in speech for ASR applications. arXiv preprint arXiv:1912.11151 (2019)\n\nTowards diverse and natural image descriptions via a conditional gan. B Dai, S Fidler, R Urtasun, D Lin, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionDai, B., Fidler, S., Urtasun, R., Lin, D.: Towards diverse and natural image descriptions via a conditional gan. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2970- 2979 (2017)\n\nImproving image captioning with conditional generative adversarial nets. C Chen, S Mu, W Xiao, Z Ye, L Wu, Q Ju, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceChen, C., Mu, S., Xiao, W., Ye, Z., Wu, L., Ju, Q.: Improving image captioning with conditional generative adversarial nets. In: Proceedings of the AAAI Conference on Artificial Intelligence, pp. 8142-8150 (2019)\n\nGenerative adversarial nets. I Goodfellow, J Pougetabadie, M Mirza, B Xu, D Wardefarley, S Ozair, A Courville, Y Bengio, Advances in Neural Information Processing Systems. Goodfellow, I., Pougetabadie, J., Mirza, M., Xu, B., Wardefarley, D., Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. In: Advances in Neural Information Processing Systems, pp. 2672- 2680 (2014)\n\nA review of affective computing: from unimodal analysis to multimodal fusion. S Poria, E Cambria, R Bajpai, A Hussain, Inf. Fusion. 37Poria, S., Cambria, E., Bajpai, R., Hussain, A.: A review of affec- tive computing: from unimodal analysis to multimodal fusion. Inf. Fusion 37, 98-125 (2017)\n\nCookGAN: meal image synthesis from ingredients. F Han, R Guerrero, V Pavlovic, Computer Vision and Pattern Recognition. arXiv. Han, F., Guerrero, R., Pavlovic, V.: CookGAN: meal image syn- thesis from ingredients. Computer Vision and Pattern Recognition. arXiv (2020)\n\nText2FaceGAN: face generation from fine grained textual descriptions. O R Nasir, S K Jha, M S Grover, Y Yu, A Kumar, R R Shah, IEEE International Conference on Multimedia Big Data. Nasir, O.R., Jha, S.K., Grover, M.S., Yu, Y., Kumar, A., Shah, R.R.: Text2FaceGAN: face generation from fine grained textual descriptions. In: IEEE International Conference on Multimedia Big Data, pp. 58-67 (2019)\n\nImage generation associated with music data. Y Qiu, H Kataoka, Computer Vision and Pattern Recognition (CVPR). Qiu, Y., Kataoka, H.: Image generation associated with music data. In: Computer Vision and Pattern Recognition (CVPR), pp. 2510- 2513 (2018)\n\nTowards audio to scene image synthesis using generative adversarial network. C Wan, S Chuang, H Lee, International Conference on Acoustics Speech and Signal Processing (ICASSP). Wan, C., Chuang, S., Lee, H.: Towards audio to scene image synthesis using generative adversarial network. In: International Conference on Acoustics Speech and Signal Processing (ICASSP), pp. 496-500 (2019)\n\nImage-to-image translation with conditional adversarial networks. P Isola, J Zhu, T Zhou, A A Efros, Computer Vision and Pattern Recognition (CVPR). Isola, P., Zhu, J., Zhou, T., Efros, A.A.: Image-to-image translation with conditional adversarial networks. In: Computer Vision and Pattern Recognition (CVPR), pp. 5967-5976 (2017)\n\nWav2Pix: speech-conditioned face generation using generative adversarial networks. A Duarte, F Roldan, M Tubau, J Escur, S Pascual, A Salvador, E Mohedano, K Mcguinness, J Torres, X Giroinieto, International Conference on Acoustics Speech and Signal Processing (ICASSP). Duarte, A., Roldan, F., Tubau, M., Escur, J., Pascual, S., Sal- vador, A., Mohedano, E., Mcguinness, K., Torres, J., Giroinieto, X.: Wav2Pix: speech-conditioned face generation using generative adversarial networks. In: International Conference on Acoustics Speech and Signal Processing (ICASSP), pp. 8633-8637 (2019)\n\nSpeech2Face: learning the face behind a voice. T Oh, T Dekel, C Kim, I Mosseri, W T Freeman, M Rubinstein, W Matusik, Computer Vision and Pattern Recognition (CVPR). Oh, T., Dekel, T., Kim, C., Mosseri, I., Freeman, W.T., Rubinstein, M., Matusik, W.: Speech2Face: learning the face behind a voice. In: Computer Vision and Pattern Recognition (CVPR), pp. 7539-7548 (2019)\n\nFace reconstruction from voice using generative adversarial networks. Y Wen, R Singh, B Raj, Advances in Neural Information Processing Systems (NIPS). Wen, Y., Singh, R., Raj, B.: Face reconstruction from voice using generative adversarial networks. In: Advances in Neural Informa- tion Processing Systems (NIPS), pp. 5265-5274 (2019)\n\nConditional image synthesis with auxiliary classifier GANs. A Odena, C Olah, J Shlens, International Conference on Machine Learning. Odena, A., Olah, C., Shlens, J.: Conditional image synthesis with auxiliary classifier GANs. In: International Conference on Machine Learning, pp. 2642-2651 (2017)\n\nMatching novel face and voice identity using static and dynamic facial images. H M J Smith, A K Dunn, T Baguley, P C Stacey, Atten. Percept. Psychophys. 783Smith, H.M.J., Dunn, A.K., Baguley, T., Stacey, P.C.: Match- ing novel face and voice identity using static and dynamic facial images. Atten. Percept. Psychophys. 78(3), 868-879 (2016)\n\nSeeing voices and hearing faces: cross-modal biometric matching. A Nagrani, S Albanie, A Zisserman, Computer Vision and Pattern Recognition (CVPR). Nagrani, A., Albanie, S., Zisserman, A.: Seeing voices and hearing faces: cross-modal biometric matching. In: Computer Vision and Pattern Recognition (CVPR), pp. 8427-8436 (2018)\n\nThe Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): a dynamic, multimodal set of facial and vocal expressions in North American English. S R Livingstone, F A Russo, PLOS ONE. 135Livingstone, S.R., Russo, F.A.: The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): a dynamic, multimodal set of facial and vocal expressions in North American English. PLOS ONE 13(5), 1-35 (2018)\n\nThe eNTERFACE'05 audio-visual emotion database. O Martin, I Kotsia, B Macq, I Pitas, 22nd International Conference on Data Engineering Workshops (ICDEW'06). IEEE Computer SocietyMartin, O., Kotsia, I., Macq, B., Pitas, I.: The eNTERFACE'05 audio-visual emotion database. In: 22nd International Conference on Data Engineering Workshops (ICDEW'06), pp. 8-8. IEEE Computer Society (2006)\n\nDual discriminator generative adversarial nets. T D Nguyen, T Le, H Vu, D Phung, Advances in Neural Information Processing Systems (NIPS). Nguyen, T.D., Le, T., Vu, H., Phung, D.: Dual discriminator generative adversarial nets. In: Advances in Neural Information Processing Systems (NIPS), pp. 2670-2680 (2017)\n\nGenerative multiadversarial networks. I Durugkar, I Gemp, S Mahadevan, International Conference on Learning Representations. Durugkar, I., Gemp, I., Mahadevan, S.: Generative multi- adversarial networks. In: International Conference on Learning Representations (2017)\n\nHierarchical crossmodal talking face generation with dynamic pixel-wise loss. L Chen, R K Maddox, Z Duan, C Xu, Computer Vision and Pattern Recognition (CVPR). Chen, L., Maddox, R.K., Duan, Z., Xu, C.: Hierarchical cross- modal talking face generation with dynamic pixel-wise loss. In: Computer Vision and Pattern Recognition (CVPR), pp. 7832-7841 (2019)\n\nJ S Chung, A Jamaludin, A Zisserman, You said that? In: British Machine Vision Conference (BMVC. Chung, J.S., Jamaludin, A., Zisserman, A.: You said that? In: British Machine Vision Conference (BMVC) (2017)\n\nEnd-to-end speech-driven facial animation with temporal GANs. K Vougioukas, S Petridis, M Pantic, British Machine Vision Conference (BMVC). Vougioukas, K., Petridis, S., Pantic, M.: End-to-end speech-driven facial animation with temporal GANs. In: British Machine Vision Conference (BMVC) (2018)\n\nRealistic speech-driven facial animation with GANs. V Konstantinos, P Stavros, P Maja, Int. J. Comput. Vis. 85Konstantinos, V., Stavros, P., Maja, P.: Realistic speech-driven facial animation with GANs. Int. J. Comput. Vis. 8(5), 1398-1413 (2020)\n\nHybrid CTC/attention architecture for end-to-end speech recognition. S Watanabe, S Kim, J R Hershey, T Hori, IEEE J. Sel. Top. Signal Process. 118Watanabe, S., Kim, S., Hershey, J.R., Hori, T.: Hybrid CTC/attention architecture for end-to-end speech recognition. IEEE J. Sel. Top. Signal Process. 11(8), 1240-1253 (2017)\n\nAutomatic speech emotion recognition: a survey. P Chandrasekar, S Chapaneri, D Jayaswal, International Conference on Circuits. Chandrasekar, P., Chapaneri, S., Jayaswal, D.: Automatic speech emotion recognition: a survey. In: International Conference on Cir- cuits, pp. 341-346 (2014)\n\nA hybrid of deep CNN and bidirectional LSTM for automatic speech recognition. V Passricha, R K Aggarwal, J. Intell. Syst. 291Passricha, V., Aggarwal, R.K.: A hybrid of deep CNN and bidi- rectional LSTM for automatic speech recognition. J. Intell. Syst. 29(1), 1261-1274 (2019)\n\nA survey of affect recognition methods: audio, visual, and spontaneous expressions. Z Zeng, M Pantic, G I Roisman, T S Huang, IEEE Trans. Pattern Anal. Mach. Intell. 311Zeng, Z., Pantic, M., Roisman, G.I., Huang, T.S.: A survey of affect recognition methods: audio, visual, and spontaneous expressions. IEEE Trans. Pattern Anal. Mach. Intell. 31(1), 39-58 (2009)\n\nUsing regional saliency for speech emotion recognition. Z Aldeneh, E M Provost, International Conference on Acoustics, Speech and Signal Processing. Aldeneh, Z., Provost, E.M.: Using regional saliency for speech emotion recognition. In: International Conference on Acoustics, Speech and Signal Processing, pp. 2741-2745 (2017)\n\nAcoustic emotion recognition using linear and nonlinear cepstral coefficients. F Chenchah, Z Lachiri, Int. J. Adv. Comput. Sci. Appl. 611Chenchah, F., Lachiri, Z.: Acoustic emotion recognition using lin- ear and nonlinear cepstral coefficients. Int. J. Adv. Comput. Sci. Appl. 6(11), 1-4 (2015)\n\nEmotion recognition system from artificial Marathi speech using MFCC and LDA techniques. V B Waghmare, R R Deshmukh, P P Shrishrimal, G B Janvale, B B Ambedkar, International Conference on Advances in Communication, Network, and Computing. Waghmare, V.B., Deshmukh, R.R., Shrishrimal, P.P., Janvale, G.B., Ambedkar, B.B.: Emotion recognition system from artificial Marathi speech using MFCC and LDA techniques. In: Interna- tional Conference on Advances in Communication, Network, and Computing (2014)\n\nSpeech emotion classification using attention-based LSTM. Y Xie, R Liang, Z Liang, C Huang, C Zou, B Schuller, IEEE Trans. Audio Speech Lang. Process. 2711Xie, Y., Liang, R., Liang, Z., Huang, C., Zou, C., Schuller, B.: Speech emotion classification using attention-based LSTM. IEEE Trans. Audio Speech Lang. Process. 27(11), 1675-1685 (2019)\n\nSpeech emotion recognition using CNN. Z Huang, M Dong, Q Mao, Y Zhan, the Proceedings of the 22nd ACM international conference on Multimedia. Huang, Z., Dong, M., Mao, Q., Zhan, Y.: Speech emotion recogni- tion using CNN. In: the Proceedings of the 22nd ACM international conference on Multimedia, pp. 801-804\n\nAudio-driven talking face video generation with learning-based personalized head pose. R Yi, Z Ye, J Zhang, H Bao, Y Liu, arXiv:2002.10137arXiv preprintYi, R., Ye, Z., Zhang, J., Bao, H., Liu, Y.: Audio-driven talking face video generation with learning-based personalized head pose. arXiv preprint arXiv:2002.10137 (2020)\n\nSynthesizing Obama: learning lip sync from audio. S Suwajanakorn, S M Seitz, I Kemelmachershlizerman, ACM Trans. Graph. (TOG). 364Suwajanakorn, S., Seitz, S.M., Kemelmachershlizerman, I.: Syn- thesizing Obama: learning lip sync from audio. ACM Trans. Graph. (TOG) 36(4), 1-13 (2017)\n\nS A Jalalifar, H Hasani, H Aghajan, arXiv:1803.07461Speech-driven facial reenactment using conditional generative adversarial networks. arXiv preprintJalalifar, S.A., Hasani, H., Aghajan, H.: Speech-driven facial reen- actment using conditional generative adversarial networks. arXiv preprint arXiv:1803.07461 (2018)\n\nSpeech-driven expressive talking lips with conditional sequential generative adversarial networks. N Sadoughi, C Busso, 10.1109/TAFFC.2019.2916031IEEE Trans. Affect. Comput. Sadoughi, N., Busso, C.: Speech-driven expressive talking lips with conditional sequential generative adversarial networks. IEEE Trans. Affect. Comput. (2019). https://doi.org/10.1109/TAFFC. 2019.2916031\n\nCascade attention guided residue learning GAN for cross-modal translation. B Duan, W Wang, H Tang, H Latapie, Y Yan, arXiv:1907.01826arXiv preprintDuan, B., Wang, W., Tang, H., Latapie, H., Yan, Y.: Cascade atten- tion guided residue learning GAN for cross-modal translation. arXiv preprint arXiv:1907.01826 (2019)\n\nA robust frontend for VAD: exploiting contextual, discriminative and spectral cues of human voice. M Van Segbroeck, A Tsiartas, S S Narayanan, Conference of the International Speech Communication Association. Van Segbroeck, M., Tsiartas, A., Narayanan, S.S.: A robust fron- tend for VAD: exploiting contextual, discriminative and spectral cues of human voice. In: Conference of the International Speech Communication Association, pp. 704-708 (2013)\n\nDlib-ml: a machine learning toolkit. D E King, J. Mach. Learn. Res. 10King, D.E.: Dlib-ml: a machine learning toolkit. J. Mach. Learn. Res. 10, 1755-1758 (2009)\n\nImproved training of Wasserstein Gans. I Gulrajani, F Ahmed, M Arjovsky, V Dumoulin, A C Courville, Advances in Neural Information Processing Systems. Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C.: Improved training of Wasserstein Gans. In: Advances in Neu- ral Information Processing Systems, pp. 5767-5777 (2017)\n\nUnsupervised representation learning with deep convolutional generative adversarial networks. A Radford, L Metz, S Chintala, International Conference on Learning Representations. Radford, A., Metz, L., Chintala, S.: Unsupervised representation learning with deep convolutional generative adversarial networks. In: International Conference on Learning Representations (2016)\n\nTriangle generative adversarial networks. Z Gan, L Chen, W Wang, Y Pu, Y Zhang, H Liu, C Li, L Carin, Advances in Neural Information Processing Systems. Gan, Z., Chen, L., Wang, W., Pu, Y., Zhang, Y., Liu, H., Li, C., Carin, L.: Triangle generative adversarial networks. In: Advances in Neural Information Processing Systems, pp. 5247-5256 (2017)\n\nTriple generative adversarial nets. C Li, K Xu, J Zhu, B Zhang, Advances in Neural Information Processing Systems. Li, C., Xu, K., Zhu, J., Zhang, B.: Triple generative adversarial nets. In: Advances in Neural Information Processing Systems, pp. 4088-4098 (2017)\n\nImproved techniques for training GANs. T Salimans, I Goodfellow, W Zaremba, V Cheung, A Radford, X Chen, Neural Information Processing Systems. Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X.: Improved techniques for training GANs. In: Neural Information Processing Systems, pp. 2234-2242 (2016)\n\nGANs trained by a two time-scale update rule converge to a local nash equilibrium. M Heusel, H Ramsauer, T Unterthiner, B Nessler, S Hochreiter, Neural Information Processing Systems. Heusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S.: GANs trained by a two time-scale update rule converge to a local nash equilibrium. In: Neural Information Processing Systems, pp. 6626-6637 (2017)\n\nRethinking the inception architecture for computer vision. C Szegedy, V Vanhoucke, S Ioffe, J Shlens, Z Wojna, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionSzegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception architecture for computer vision. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2818-2826 (2016)\n\nDeep face recognition. O M Parkhi, A Vedaldi, A Zisserman, British Machine Vision Conference. Parkhi, O.M., Vedaldi, A., Zisserman, A.: Deep face recognition. In: British Machine Vision Conference (2015)\n\nPublisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Publisher's Note Springer Nature remains neutral with regard to juris- dictional claims in published maps and institutional affiliations.\n", "annotations": {"author": "[{\"end\":73,\"start\":62},{\"end\":83,\"start\":74},{\"end\":97,\"start\":84},{\"end\":116,\"start\":98},{\"end\":132,\"start\":117},{\"end\":147,\"start\":133},{\"end\":73,\"start\":62},{\"end\":83,\"start\":74},{\"end\":97,\"start\":84},{\"end\":116,\"start\":98},{\"end\":132,\"start\":117},{\"end\":147,\"start\":133}]", "publisher": null, "author_last_name": "[{\"end\":72,\"start\":68},{\"end\":82,\"start\":79},{\"end\":96,\"start\":93},{\"end\":115,\"start\":100},{\"end\":131,\"start\":127},{\"end\":146,\"start\":142},{\"end\":72,\"start\":68},{\"end\":82,\"start\":79},{\"end\":96,\"start\":93},{\"end\":115,\"start\":100},{\"end\":131,\"start\":127},{\"end\":146,\"start\":142}]", "author_first_name": "[{\"end\":67,\"start\":62},{\"end\":78,\"start\":74},{\"end\":92,\"start\":84},{\"end\":99,\"start\":98},{\"end\":126,\"start\":117},{\"end\":141,\"start\":133},{\"end\":67,\"start\":62},{\"end\":78,\"start\":74},{\"end\":92,\"start\":84},{\"end\":99,\"start\":98},{\"end\":126,\"start\":117},{\"end\":141,\"start\":133}]", "author_affiliation": null, "title": "[{\"end\":55,\"start\":1},{\"end\":202,\"start\":148},{\"end\":55,\"start\":1},{\"end\":202,\"start\":148}]", "venue": "[{\"end\":223,\"start\":204},{\"end\":223,\"start\":204}]", "abstract": "[{\"end\":1788,\"start\":459},{\"end\":1788,\"start\":459}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2092,\"start\":2089},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2094,\"start\":2092},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2116,\"start\":2113},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2118,\"start\":2116},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2202,\"start\":2199},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2248,\"start\":2245},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2406,\"start\":2403},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2408,\"start\":2406},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2431,\"start\":2428},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2434,\"start\":2431},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2910,\"start\":2906},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2952,\"start\":2948},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3020,\"start\":3016},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3051,\"start\":3047},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3236,\"start\":3232},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4476,\"start\":4472},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4479,\"start\":4476},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6200,\"start\":6196},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6219,\"start\":6215},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6296,\"start\":6292},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6299,\"start\":6296},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7222,\"start\":7219},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7352,\"start\":7349},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7782,\"start\":7778},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8091,\"start\":8087},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8317,\"start\":8313},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8372,\"start\":8368},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8565,\"start\":8561},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8569,\"start\":8565},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8573,\"start\":8569},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8577,\"start\":8573},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8581,\"start\":8577},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8585,\"start\":8581},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8589,\"start\":8585},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8712,\"start\":8708},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8728,\"start\":8724},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9104,\"start\":9100},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9186,\"start\":9182},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9299,\"start\":9295},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9302,\"start\":9299},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9417,\"start\":9413},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9557,\"start\":9553},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10153,\"start\":10149},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10156,\"start\":10153},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10325,\"start\":10321},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10328,\"start\":10325},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10331,\"start\":10328},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10939,\"start\":10935},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11061,\"start\":11057},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11241,\"start\":11237},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":11260,\"start\":11256},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11527,\"start\":11523},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11553,\"start\":11549},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11781,\"start\":11777},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12335,\"start\":12331},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12339,\"start\":12335},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12343,\"start\":12339},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12559,\"start\":12555},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12562,\"start\":12559},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":14628,\"start\":14624},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":15252,\"start\":15248},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":17437,\"start\":17433},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":18947,\"start\":18943},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22456,\"start\":22452},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":22477,\"start\":22473},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23140,\"start\":23136},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23159,\"start\":23155},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23715,\"start\":23711},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23733,\"start\":23729},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24214,\"start\":24210},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":24253,\"start\":24249},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":24716,\"start\":24712},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":24999,\"start\":24995},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":25711,\"start\":25707},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":25893,\"start\":25889},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":25896,\"start\":25893},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26719,\"start\":26716},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31853,\"start\":31849},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":31868,\"start\":31864},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":34832,\"start\":34829},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2092,\"start\":2089},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2094,\"start\":2092},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2116,\"start\":2113},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2118,\"start\":2116},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2202,\"start\":2199},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2248,\"start\":2245},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2406,\"start\":2403},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2408,\"start\":2406},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2431,\"start\":2428},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2434,\"start\":2431},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2910,\"start\":2906},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2952,\"start\":2948},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3020,\"start\":3016},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3051,\"start\":3047},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3236,\"start\":3232},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4476,\"start\":4472},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4479,\"start\":4476},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6200,\"start\":6196},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6219,\"start\":6215},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6296,\"start\":6292},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6299,\"start\":6296},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7222,\"start\":7219},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7352,\"start\":7349},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7782,\"start\":7778},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8091,\"start\":8087},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8317,\"start\":8313},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8372,\"start\":8368},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8565,\"start\":8561},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8569,\"start\":8565},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8573,\"start\":8569},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8577,\"start\":8573},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8581,\"start\":8577},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8585,\"start\":8581},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8589,\"start\":8585},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8712,\"start\":8708},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8728,\"start\":8724},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9104,\"start\":9100},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9186,\"start\":9182},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9299,\"start\":9295},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9302,\"start\":9299},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9417,\"start\":9413},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9557,\"start\":9553},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10153,\"start\":10149},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10156,\"start\":10153},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10325,\"start\":10321},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10328,\"start\":10325},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10331,\"start\":10328},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10939,\"start\":10935},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11061,\"start\":11057},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11241,\"start\":11237},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":11260,\"start\":11256},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11527,\"start\":11523},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11553,\"start\":11549},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11781,\"start\":11777},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12335,\"start\":12331},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12339,\"start\":12335},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12343,\"start\":12339},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12559,\"start\":12555},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12562,\"start\":12559},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":14628,\"start\":14624},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":15252,\"start\":15248},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":17437,\"start\":17433},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":18947,\"start\":18943},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22456,\"start\":22452},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":22477,\"start\":22473},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23140,\"start\":23136},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23159,\"start\":23155},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23715,\"start\":23711},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23733,\"start\":23729},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24214,\"start\":24210},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":24253,\"start\":24249},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":24716,\"start\":24712},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":24999,\"start\":24995},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":25711,\"start\":25707},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":25893,\"start\":25889},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":25896,\"start\":25893},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26719,\"start\":26716},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31853,\"start\":31849},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":31868,\"start\":31864},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":34832,\"start\":34829}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37634,\"start\":36925},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38020,\"start\":37635},{\"attributes\":{\"id\":\"fig_2\"},\"end\":38085,\"start\":38021},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38423,\"start\":38086},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38604,\"start\":38424},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38676,\"start\":38605},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39137,\"start\":38677},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":39554,\"start\":39138},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":40049,\"start\":39555},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":40370,\"start\":40050},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":40977,\"start\":40371},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42455,\"start\":40978},{\"attributes\":{\"id\":\"fig_0\"},\"end\":37634,\"start\":36925},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38020,\"start\":37635},{\"attributes\":{\"id\":\"fig_2\"},\"end\":38085,\"start\":38021},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38423,\"start\":38086},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38604,\"start\":38424},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38676,\"start\":38605},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39137,\"start\":38677},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":39554,\"start\":39138},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":40049,\"start\":39555},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":40370,\"start\":40050},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":40977,\"start\":40371},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42455,\"start\":40978}]", "paragraph": "[{\"end\":2774,\"start\":1804},{\"end\":3970,\"start\":2776},{\"end\":4178,\"start\":3972},{\"end\":5600,\"start\":4180},{\"end\":7178,\"start\":5602},{\"end\":8468,\"start\":7214},{\"end\":8884,\"start\":8470},{\"end\":9694,\"start\":8935},{\"end\":10646,\"start\":9696},{\"end\":11376,\"start\":10677},{\"end\":12101,\"start\":11378},{\"end\":12765,\"start\":12103},{\"end\":13279,\"start\":12817},{\"end\":13846,\"start\":13281},{\"end\":14542,\"start\":13848},{\"end\":15466,\"start\":14571},{\"end\":15584,\"start\":15468},{\"end\":16439,\"start\":15696},{\"end\":17438,\"start\":16449},{\"end\":18204,\"start\":17458},{\"end\":18961,\"start\":18206},{\"end\":19795,\"start\":18963},{\"end\":20357,\"start\":19811},{\"end\":20510,\"start\":20359},{\"end\":20855,\"start\":20520},{\"end\":20909,\"start\":20857},{\"end\":21502,\"start\":20985},{\"end\":21770,\"start\":21596},{\"end\":22362,\"start\":21854},{\"end\":22963,\"start\":22364},{\"end\":23569,\"start\":23003},{\"end\":24097,\"start\":23571},{\"end\":24306,\"start\":24120},{\"end\":24748,\"start\":24347},{\"end\":25082,\"start\":24812},{\"end\":25991,\"start\":25084},{\"end\":26222,\"start\":26016},{\"end\":27514,\"start\":26224},{\"end\":29635,\"start\":27516},{\"end\":29807,\"start\":29637},{\"end\":30731,\"start\":29828},{\"end\":31674,\"start\":30733},{\"end\":32955,\"start\":31709},{\"end\":34194,\"start\":32957},{\"end\":35220,\"start\":34219},{\"end\":36330,\"start\":35235},{\"end\":36924,\"start\":36332},{\"end\":2774,\"start\":1804},{\"end\":3970,\"start\":2776},{\"end\":4178,\"start\":3972},{\"end\":5600,\"start\":4180},{\"end\":7178,\"start\":5602},{\"end\":8468,\"start\":7214},{\"end\":8884,\"start\":8470},{\"end\":9694,\"start\":8935},{\"end\":10646,\"start\":9696},{\"end\":11376,\"start\":10677},{\"end\":12101,\"start\":11378},{\"end\":12765,\"start\":12103},{\"end\":13279,\"start\":12817},{\"end\":13846,\"start\":13281},{\"end\":14542,\"start\":13848},{\"end\":15466,\"start\":14571},{\"end\":15584,\"start\":15468},{\"end\":16439,\"start\":15696},{\"end\":17438,\"start\":16449},{\"end\":18204,\"start\":17458},{\"end\":18961,\"start\":18206},{\"end\":19795,\"start\":18963},{\"end\":20357,\"start\":19811},{\"end\":20510,\"start\":20359},{\"end\":20855,\"start\":20520},{\"end\":20909,\"start\":20857},{\"end\":21502,\"start\":20985},{\"end\":21770,\"start\":21596},{\"end\":22362,\"start\":21854},{\"end\":22963,\"start\":22364},{\"end\":23569,\"start\":23003},{\"end\":24097,\"start\":23571},{\"end\":24306,\"start\":24120},{\"end\":24748,\"start\":24347},{\"end\":25082,\"start\":24812},{\"end\":25991,\"start\":25084},{\"end\":26222,\"start\":26016},{\"end\":27514,\"start\":26224},{\"end\":29635,\"start\":27516},{\"end\":29807,\"start\":29637},{\"end\":30731,\"start\":29828},{\"end\":31674,\"start\":30733},{\"end\":32955,\"start\":31709},{\"end\":34194,\"start\":32957},{\"end\":35220,\"start\":34219},{\"end\":36330,\"start\":35235},{\"end\":36924,\"start\":36332}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15695,\"start\":15585},{\"attributes\":{\"id\":\"formula_1\"},\"end\":20519,\"start\":20511},{\"attributes\":{\"id\":\"formula_3\"},\"end\":20984,\"start\":20910},{\"attributes\":{\"id\":\"formula_4\"},\"end\":21595,\"start\":21503},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21853,\"start\":21771},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24346,\"start\":24307},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24811,\"start\":24749},{\"attributes\":{\"id\":\"formula_0\"},\"end\":15695,\"start\":15585},{\"attributes\":{\"id\":\"formula_1\"},\"end\":20519,\"start\":20511},{\"attributes\":{\"id\":\"formula_3\"},\"end\":20984,\"start\":20910},{\"attributes\":{\"id\":\"formula_4\"},\"end\":21595,\"start\":21503},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21853,\"start\":21771},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24346,\"start\":24307},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24811,\"start\":24749}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":23512,\"start\":23505},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26441,\"start\":26434},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":27848,\"start\":27841},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":29397,\"start\":29390},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30584,\"start\":30577},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":31330,\"start\":31323},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":31877,\"start\":31870},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":31933,\"start\":31926},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32036,\"start\":32029},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":32228,\"start\":32221},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":33140,\"start\":33125},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":33152,\"start\":33145},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":33322,\"start\":33315},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":23512,\"start\":23505},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26441,\"start\":26434},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":27848,\"start\":27841},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":29397,\"start\":29390},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30584,\"start\":30577},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":31330,\"start\":31323},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":31877,\"start\":31870},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":31933,\"start\":31926},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32036,\"start\":32029},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":32228,\"start\":32221},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":33140,\"start\":33125},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":33152,\"start\":33145},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":33322,\"start\":33315}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1802,\"start\":1790},{\"attributes\":{\"n\":\"2.1\"},\"end\":7212,\"start\":7181},{\"attributes\":{\"n\":\"2.2\"},\"end\":8933,\"start\":8887},{\"attributes\":{\"n\":\"2.3\"},\"end\":10675,\"start\":10649},{\"attributes\":{\"n\":\"3\"},\"end\":12784,\"start\":12768},{\"attributes\":{\"n\":\"3.1\"},\"end\":12815,\"start\":12787},{\"attributes\":{\"n\":\"3.2\"},\"end\":14569,\"start\":14545},{\"attributes\":{\"n\":\"3.3\"},\"end\":16447,\"start\":16442},{\"attributes\":{\"n\":\"3.4\"},\"end\":17456,\"start\":17441},{\"attributes\":{\"n\":\"3.5\"},\"end\":19809,\"start\":19798},{\"attributes\":{\"n\":\"4\"},\"end\":22977,\"start\":22966},{\"attributes\":{\"n\":\"4.1\"},\"end\":23001,\"start\":22980},{\"attributes\":{\"n\":\"4.2\"},\"end\":24118,\"start\":24100},{\"attributes\":{\"n\":\"4.3\"},\"end\":26014,\"start\":25994},{\"attributes\":{\"n\":\"4.4\"},\"end\":29826,\"start\":29810},{\"attributes\":{\"n\":\"4.5\"},\"end\":31707,\"start\":31677},{\"attributes\":{\"n\":\"4.6\"},\"end\":34217,\"start\":34197},{\"attributes\":{\"n\":\"5\"},\"end\":35233,\"start\":35223},{\"end\":36932,\"start\":36926},{\"end\":38027,\"start\":38022},{\"end\":38093,\"start\":38087},{\"end\":38438,\"start\":38425},{\"end\":38612,\"start\":38606},{\"end\":38693,\"start\":38678},{\"end\":39146,\"start\":39139},{\"end\":39563,\"start\":39556},{\"end\":40058,\"start\":40051},{\"end\":40388,\"start\":40372},{\"attributes\":{\"n\":\"1\"},\"end\":1802,\"start\":1790},{\"attributes\":{\"n\":\"2.1\"},\"end\":7212,\"start\":7181},{\"attributes\":{\"n\":\"2.2\"},\"end\":8933,\"start\":8887},{\"attributes\":{\"n\":\"2.3\"},\"end\":10675,\"start\":10649},{\"attributes\":{\"n\":\"3\"},\"end\":12784,\"start\":12768},{\"attributes\":{\"n\":\"3.1\"},\"end\":12815,\"start\":12787},{\"attributes\":{\"n\":\"3.2\"},\"end\":14569,\"start\":14545},{\"attributes\":{\"n\":\"3.3\"},\"end\":16447,\"start\":16442},{\"attributes\":{\"n\":\"3.4\"},\"end\":17456,\"start\":17441},{\"attributes\":{\"n\":\"3.5\"},\"end\":19809,\"start\":19798},{\"attributes\":{\"n\":\"4\"},\"end\":22977,\"start\":22966},{\"attributes\":{\"n\":\"4.1\"},\"end\":23001,\"start\":22980},{\"attributes\":{\"n\":\"4.2\"},\"end\":24118,\"start\":24100},{\"attributes\":{\"n\":\"4.3\"},\"end\":26014,\"start\":25994},{\"attributes\":{\"n\":\"4.4\"},\"end\":29826,\"start\":29810},{\"attributes\":{\"n\":\"4.5\"},\"end\":31707,\"start\":31677},{\"attributes\":{\"n\":\"4.6\"},\"end\":34217,\"start\":34197},{\"attributes\":{\"n\":\"5\"},\"end\":35233,\"start\":35223},{\"end\":36932,\"start\":36926},{\"end\":38027,\"start\":38022},{\"end\":38093,\"start\":38087},{\"end\":38438,\"start\":38425},{\"end\":38612,\"start\":38606},{\"end\":38693,\"start\":38678},{\"end\":39146,\"start\":39139},{\"end\":39563,\"start\":39556},{\"end\":40058,\"start\":40051},{\"end\":40388,\"start\":40372}]", "table": "[{\"end\":39137,\"start\":38695},{\"end\":39554,\"start\":39148},{\"end\":40049,\"start\":39565},{\"end\":40370,\"start\":40132},{\"end\":40977,\"start\":40683},{\"end\":42455,\"start\":42440},{\"end\":39137,\"start\":38695},{\"end\":39554,\"start\":39148},{\"end\":40049,\"start\":39565},{\"end\":40370,\"start\":40132},{\"end\":40977,\"start\":40683},{\"end\":42455,\"start\":42440}]", "figure_caption": "[{\"end\":37634,\"start\":36934},{\"end\":38020,\"start\":37637},{\"end\":38085,\"start\":38029},{\"end\":38423,\"start\":38095},{\"end\":38604,\"start\":38441},{\"end\":38676,\"start\":38614},{\"end\":40132,\"start\":40060},{\"end\":40683,\"start\":40390},{\"end\":42440,\"start\":40980},{\"end\":37634,\"start\":36934},{\"end\":38020,\"start\":37637},{\"end\":38085,\"start\":38029},{\"end\":38423,\"start\":38095},{\"end\":38604,\"start\":38441},{\"end\":38676,\"start\":38614},{\"end\":40132,\"start\":40060},{\"end\":40683,\"start\":40390},{\"end\":42440,\"start\":40980}]", "figure_ref": "[{\"end\":4802,\"start\":4796},{\"end\":6639,\"start\":6633},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12901,\"start\":12895},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15717,\"start\":15711},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16685,\"start\":16679},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18522,\"start\":18516},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19528,\"start\":19522},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20356,\"start\":20350},{\"end\":27219,\"start\":27211},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":29652,\"start\":29646},{\"end\":32657,\"start\":32651},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":33541,\"start\":33533},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":33961,\"start\":33955},{\"end\":4802,\"start\":4796},{\"end\":6639,\"start\":6633},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12901,\"start\":12895},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15717,\"start\":15711},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16685,\"start\":16679},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18522,\"start\":18516},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19528,\"start\":19522},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20356,\"start\":20350},{\"end\":27219,\"start\":27211},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":29652,\"start\":29646},{\"end\":32657,\"start\":32651},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":33541,\"start\":33533},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":33961,\"start\":33955}]", "bib_author_first_name": "[{\"end\":42636,\"start\":42635},{\"end\":42646,\"start\":42645},{\"end\":42653,\"start\":42652},{\"end\":42661,\"start\":42660},{\"end\":42989,\"start\":42988},{\"end\":42991,\"start\":42990},{\"end\":43002,\"start\":43001},{\"end\":43012,\"start\":43011},{\"end\":43027,\"start\":43026},{\"end\":43029,\"start\":43028},{\"end\":43411,\"start\":43410},{\"end\":43418,\"start\":43417},{\"end\":43428,\"start\":43427},{\"end\":43439,\"start\":43438},{\"end\":43849,\"start\":43848},{\"end\":43857,\"start\":43856},{\"end\":43863,\"start\":43862},{\"end\":43871,\"start\":43870},{\"end\":43877,\"start\":43876},{\"end\":43883,\"start\":43882},{\"end\":44241,\"start\":44240},{\"end\":44255,\"start\":44254},{\"end\":44271,\"start\":44270},{\"end\":44280,\"start\":44279},{\"end\":44286,\"start\":44285},{\"end\":44301,\"start\":44300},{\"end\":44310,\"start\":44309},{\"end\":44323,\"start\":44322},{\"end\":44677,\"start\":44676},{\"end\":44686,\"start\":44685},{\"end\":44697,\"start\":44696},{\"end\":44707,\"start\":44706},{\"end\":44941,\"start\":44940},{\"end\":44948,\"start\":44947},{\"end\":44960,\"start\":44959},{\"end\":45232,\"start\":45231},{\"end\":45234,\"start\":45233},{\"end\":45243,\"start\":45242},{\"end\":45245,\"start\":45244},{\"end\":45252,\"start\":45251},{\"end\":45254,\"start\":45253},{\"end\":45264,\"start\":45263},{\"end\":45270,\"start\":45269},{\"end\":45279,\"start\":45278},{\"end\":45281,\"start\":45280},{\"end\":45603,\"start\":45602},{\"end\":45610,\"start\":45609},{\"end\":45888,\"start\":45887},{\"end\":45895,\"start\":45894},{\"end\":45905,\"start\":45904},{\"end\":46263,\"start\":46262},{\"end\":46272,\"start\":46271},{\"end\":46279,\"start\":46278},{\"end\":46287,\"start\":46286},{\"end\":46289,\"start\":46288},{\"end\":46612,\"start\":46611},{\"end\":46622,\"start\":46621},{\"end\":46632,\"start\":46631},{\"end\":46641,\"start\":46640},{\"end\":46650,\"start\":46649},{\"end\":46661,\"start\":46660},{\"end\":46673,\"start\":46672},{\"end\":46685,\"start\":46684},{\"end\":46699,\"start\":46698},{\"end\":46709,\"start\":46708},{\"end\":47166,\"start\":47165},{\"end\":47172,\"start\":47171},{\"end\":47181,\"start\":47180},{\"end\":47188,\"start\":47187},{\"end\":47199,\"start\":47198},{\"end\":47201,\"start\":47200},{\"end\":47212,\"start\":47211},{\"end\":47226,\"start\":47225},{\"end\":47561,\"start\":47560},{\"end\":47568,\"start\":47567},{\"end\":47577,\"start\":47576},{\"end\":47887,\"start\":47886},{\"end\":47896,\"start\":47895},{\"end\":47904,\"start\":47903},{\"end\":48204,\"start\":48203},{\"end\":48208,\"start\":48205},{\"end\":48217,\"start\":48216},{\"end\":48219,\"start\":48218},{\"end\":48227,\"start\":48226},{\"end\":48238,\"start\":48237},{\"end\":48240,\"start\":48239},{\"end\":48532,\"start\":48531},{\"end\":48543,\"start\":48542},{\"end\":48554,\"start\":48553},{\"end\":48954,\"start\":48953},{\"end\":48956,\"start\":48955},{\"end\":48971,\"start\":48970},{\"end\":48973,\"start\":48972},{\"end\":49263,\"start\":49262},{\"end\":49273,\"start\":49272},{\"end\":49283,\"start\":49282},{\"end\":49291,\"start\":49290},{\"end\":49649,\"start\":49648},{\"end\":49651,\"start\":49650},{\"end\":49661,\"start\":49660},{\"end\":49667,\"start\":49666},{\"end\":49673,\"start\":49672},{\"end\":49951,\"start\":49950},{\"end\":49963,\"start\":49962},{\"end\":49971,\"start\":49970},{\"end\":50260,\"start\":50259},{\"end\":50268,\"start\":50267},{\"end\":50270,\"start\":50269},{\"end\":50280,\"start\":50279},{\"end\":50288,\"start\":50287},{\"end\":50538,\"start\":50537},{\"end\":50540,\"start\":50539},{\"end\":50549,\"start\":50548},{\"end\":50562,\"start\":50561},{\"end\":50808,\"start\":50807},{\"end\":50822,\"start\":50821},{\"end\":50834,\"start\":50833},{\"end\":51095,\"start\":51094},{\"end\":51111,\"start\":51110},{\"end\":51122,\"start\":51121},{\"end\":51360,\"start\":51359},{\"end\":51372,\"start\":51371},{\"end\":51379,\"start\":51378},{\"end\":51381,\"start\":51380},{\"end\":51392,\"start\":51391},{\"end\":51661,\"start\":51660},{\"end\":51677,\"start\":51676},{\"end\":51690,\"start\":51689},{\"end\":51977,\"start\":51976},{\"end\":51990,\"start\":51989},{\"end\":51992,\"start\":51991},{\"end\":52261,\"start\":52260},{\"end\":52269,\"start\":52268},{\"end\":52279,\"start\":52278},{\"end\":52281,\"start\":52280},{\"end\":52292,\"start\":52291},{\"end\":52294,\"start\":52293},{\"end\":52597,\"start\":52596},{\"end\":52608,\"start\":52607},{\"end\":52610,\"start\":52609},{\"end\":52948,\"start\":52947},{\"end\":52960,\"start\":52959},{\"end\":53254,\"start\":53253},{\"end\":53256,\"start\":53255},{\"end\":53268,\"start\":53267},{\"end\":53270,\"start\":53269},{\"end\":53282,\"start\":53281},{\"end\":53284,\"start\":53283},{\"end\":53299,\"start\":53298},{\"end\":53301,\"start\":53300},{\"end\":53312,\"start\":53311},{\"end\":53314,\"start\":53313},{\"end\":53726,\"start\":53725},{\"end\":53733,\"start\":53732},{\"end\":53742,\"start\":53741},{\"end\":53751,\"start\":53750},{\"end\":53760,\"start\":53759},{\"end\":53767,\"start\":53766},{\"end\":54050,\"start\":54049},{\"end\":54059,\"start\":54058},{\"end\":54067,\"start\":54066},{\"end\":54074,\"start\":54073},{\"end\":54410,\"start\":54409},{\"end\":54416,\"start\":54415},{\"end\":54422,\"start\":54421},{\"end\":54431,\"start\":54430},{\"end\":54438,\"start\":54437},{\"end\":54697,\"start\":54696},{\"end\":54713,\"start\":54712},{\"end\":54715,\"start\":54714},{\"end\":54724,\"start\":54723},{\"end\":54931,\"start\":54930},{\"end\":54933,\"start\":54932},{\"end\":54946,\"start\":54945},{\"end\":54956,\"start\":54955},{\"end\":55348,\"start\":55347},{\"end\":55360,\"start\":55359},{\"end\":55703,\"start\":55702},{\"end\":55711,\"start\":55710},{\"end\":55719,\"start\":55718},{\"end\":55727,\"start\":55726},{\"end\":55738,\"start\":55737},{\"end\":56043,\"start\":56042},{\"end\":56060,\"start\":56059},{\"end\":56072,\"start\":56071},{\"end\":56074,\"start\":56073},{\"end\":56431,\"start\":56430},{\"end\":56433,\"start\":56432},{\"end\":56595,\"start\":56594},{\"end\":56608,\"start\":56607},{\"end\":56617,\"start\":56616},{\"end\":56629,\"start\":56628},{\"end\":56641,\"start\":56640},{\"end\":56643,\"start\":56642},{\"end\":56990,\"start\":56989},{\"end\":57001,\"start\":57000},{\"end\":57009,\"start\":57008},{\"end\":57313,\"start\":57312},{\"end\":57320,\"start\":57319},{\"end\":57328,\"start\":57327},{\"end\":57336,\"start\":57335},{\"end\":57342,\"start\":57341},{\"end\":57351,\"start\":57350},{\"end\":57358,\"start\":57357},{\"end\":57364,\"start\":57363},{\"end\":57655,\"start\":57654},{\"end\":57661,\"start\":57660},{\"end\":57667,\"start\":57666},{\"end\":57674,\"start\":57673},{\"end\":57922,\"start\":57921},{\"end\":57934,\"start\":57933},{\"end\":57948,\"start\":57947},{\"end\":57959,\"start\":57958},{\"end\":57969,\"start\":57968},{\"end\":57980,\"start\":57979},{\"end\":58292,\"start\":58291},{\"end\":58302,\"start\":58301},{\"end\":58314,\"start\":58313},{\"end\":58329,\"start\":58328},{\"end\":58340,\"start\":58339},{\"end\":58672,\"start\":58671},{\"end\":58683,\"start\":58682},{\"end\":58696,\"start\":58695},{\"end\":58705,\"start\":58704},{\"end\":58715,\"start\":58714},{\"end\":59116,\"start\":59115},{\"end\":59118,\"start\":59117},{\"end\":59128,\"start\":59127},{\"end\":59139,\"start\":59138},{\"end\":42636,\"start\":42635},{\"end\":42646,\"start\":42645},{\"end\":42653,\"start\":42652},{\"end\":42661,\"start\":42660},{\"end\":42989,\"start\":42988},{\"end\":42991,\"start\":42990},{\"end\":43002,\"start\":43001},{\"end\":43012,\"start\":43011},{\"end\":43027,\"start\":43026},{\"end\":43029,\"start\":43028},{\"end\":43411,\"start\":43410},{\"end\":43418,\"start\":43417},{\"end\":43428,\"start\":43427},{\"end\":43439,\"start\":43438},{\"end\":43849,\"start\":43848},{\"end\":43857,\"start\":43856},{\"end\":43863,\"start\":43862},{\"end\":43871,\"start\":43870},{\"end\":43877,\"start\":43876},{\"end\":43883,\"start\":43882},{\"end\":44241,\"start\":44240},{\"end\":44255,\"start\":44254},{\"end\":44271,\"start\":44270},{\"end\":44280,\"start\":44279},{\"end\":44286,\"start\":44285},{\"end\":44301,\"start\":44300},{\"end\":44310,\"start\":44309},{\"end\":44323,\"start\":44322},{\"end\":44677,\"start\":44676},{\"end\":44686,\"start\":44685},{\"end\":44697,\"start\":44696},{\"end\":44707,\"start\":44706},{\"end\":44941,\"start\":44940},{\"end\":44948,\"start\":44947},{\"end\":44960,\"start\":44959},{\"end\":45232,\"start\":45231},{\"end\":45234,\"start\":45233},{\"end\":45243,\"start\":45242},{\"end\":45245,\"start\":45244},{\"end\":45252,\"start\":45251},{\"end\":45254,\"start\":45253},{\"end\":45264,\"start\":45263},{\"end\":45270,\"start\":45269},{\"end\":45279,\"start\":45278},{\"end\":45281,\"start\":45280},{\"end\":45603,\"start\":45602},{\"end\":45610,\"start\":45609},{\"end\":45888,\"start\":45887},{\"end\":45895,\"start\":45894},{\"end\":45905,\"start\":45904},{\"end\":46263,\"start\":46262},{\"end\":46272,\"start\":46271},{\"end\":46279,\"start\":46278},{\"end\":46287,\"start\":46286},{\"end\":46289,\"start\":46288},{\"end\":46612,\"start\":46611},{\"end\":46622,\"start\":46621},{\"end\":46632,\"start\":46631},{\"end\":46641,\"start\":46640},{\"end\":46650,\"start\":46649},{\"end\":46661,\"start\":46660},{\"end\":46673,\"start\":46672},{\"end\":46685,\"start\":46684},{\"end\":46699,\"start\":46698},{\"end\":46709,\"start\":46708},{\"end\":47166,\"start\":47165},{\"end\":47172,\"start\":47171},{\"end\":47181,\"start\":47180},{\"end\":47188,\"start\":47187},{\"end\":47199,\"start\":47198},{\"end\":47201,\"start\":47200},{\"end\":47212,\"start\":47211},{\"end\":47226,\"start\":47225},{\"end\":47561,\"start\":47560},{\"end\":47568,\"start\":47567},{\"end\":47577,\"start\":47576},{\"end\":47887,\"start\":47886},{\"end\":47896,\"start\":47895},{\"end\":47904,\"start\":47903},{\"end\":48204,\"start\":48203},{\"end\":48208,\"start\":48205},{\"end\":48217,\"start\":48216},{\"end\":48219,\"start\":48218},{\"end\":48227,\"start\":48226},{\"end\":48238,\"start\":48237},{\"end\":48240,\"start\":48239},{\"end\":48532,\"start\":48531},{\"end\":48543,\"start\":48542},{\"end\":48554,\"start\":48553},{\"end\":48954,\"start\":48953},{\"end\":48956,\"start\":48955},{\"end\":48971,\"start\":48970},{\"end\":48973,\"start\":48972},{\"end\":49263,\"start\":49262},{\"end\":49273,\"start\":49272},{\"end\":49283,\"start\":49282},{\"end\":49291,\"start\":49290},{\"end\":49649,\"start\":49648},{\"end\":49651,\"start\":49650},{\"end\":49661,\"start\":49660},{\"end\":49667,\"start\":49666},{\"end\":49673,\"start\":49672},{\"end\":49951,\"start\":49950},{\"end\":49963,\"start\":49962},{\"end\":49971,\"start\":49970},{\"end\":50260,\"start\":50259},{\"end\":50268,\"start\":50267},{\"end\":50270,\"start\":50269},{\"end\":50280,\"start\":50279},{\"end\":50288,\"start\":50287},{\"end\":50538,\"start\":50537},{\"end\":50540,\"start\":50539},{\"end\":50549,\"start\":50548},{\"end\":50562,\"start\":50561},{\"end\":50808,\"start\":50807},{\"end\":50822,\"start\":50821},{\"end\":50834,\"start\":50833},{\"end\":51095,\"start\":51094},{\"end\":51111,\"start\":51110},{\"end\":51122,\"start\":51121},{\"end\":51360,\"start\":51359},{\"end\":51372,\"start\":51371},{\"end\":51379,\"start\":51378},{\"end\":51381,\"start\":51380},{\"end\":51392,\"start\":51391},{\"end\":51661,\"start\":51660},{\"end\":51677,\"start\":51676},{\"end\":51690,\"start\":51689},{\"end\":51977,\"start\":51976},{\"end\":51990,\"start\":51989},{\"end\":51992,\"start\":51991},{\"end\":52261,\"start\":52260},{\"end\":52269,\"start\":52268},{\"end\":52279,\"start\":52278},{\"end\":52281,\"start\":52280},{\"end\":52292,\"start\":52291},{\"end\":52294,\"start\":52293},{\"end\":52597,\"start\":52596},{\"end\":52608,\"start\":52607},{\"end\":52610,\"start\":52609},{\"end\":52948,\"start\":52947},{\"end\":52960,\"start\":52959},{\"end\":53254,\"start\":53253},{\"end\":53256,\"start\":53255},{\"end\":53268,\"start\":53267},{\"end\":53270,\"start\":53269},{\"end\":53282,\"start\":53281},{\"end\":53284,\"start\":53283},{\"end\":53299,\"start\":53298},{\"end\":53301,\"start\":53300},{\"end\":53312,\"start\":53311},{\"end\":53314,\"start\":53313},{\"end\":53726,\"start\":53725},{\"end\":53733,\"start\":53732},{\"end\":53742,\"start\":53741},{\"end\":53751,\"start\":53750},{\"end\":53760,\"start\":53759},{\"end\":53767,\"start\":53766},{\"end\":54050,\"start\":54049},{\"end\":54059,\"start\":54058},{\"end\":54067,\"start\":54066},{\"end\":54074,\"start\":54073},{\"end\":54410,\"start\":54409},{\"end\":54416,\"start\":54415},{\"end\":54422,\"start\":54421},{\"end\":54431,\"start\":54430},{\"end\":54438,\"start\":54437},{\"end\":54697,\"start\":54696},{\"end\":54713,\"start\":54712},{\"end\":54715,\"start\":54714},{\"end\":54724,\"start\":54723},{\"end\":54931,\"start\":54930},{\"end\":54933,\"start\":54932},{\"end\":54946,\"start\":54945},{\"end\":54956,\"start\":54955},{\"end\":55348,\"start\":55347},{\"end\":55360,\"start\":55359},{\"end\":55703,\"start\":55702},{\"end\":55711,\"start\":55710},{\"end\":55719,\"start\":55718},{\"end\":55727,\"start\":55726},{\"end\":55738,\"start\":55737},{\"end\":56043,\"start\":56042},{\"end\":56060,\"start\":56059},{\"end\":56072,\"start\":56071},{\"end\":56074,\"start\":56073},{\"end\":56431,\"start\":56430},{\"end\":56433,\"start\":56432},{\"end\":56595,\"start\":56594},{\"end\":56608,\"start\":56607},{\"end\":56617,\"start\":56616},{\"end\":56629,\"start\":56628},{\"end\":56641,\"start\":56640},{\"end\":56643,\"start\":56642},{\"end\":56990,\"start\":56989},{\"end\":57001,\"start\":57000},{\"end\":57009,\"start\":57008},{\"end\":57313,\"start\":57312},{\"end\":57320,\"start\":57319},{\"end\":57328,\"start\":57327},{\"end\":57336,\"start\":57335},{\"end\":57342,\"start\":57341},{\"end\":57351,\"start\":57350},{\"end\":57358,\"start\":57357},{\"end\":57364,\"start\":57363},{\"end\":57655,\"start\":57654},{\"end\":57661,\"start\":57660},{\"end\":57667,\"start\":57666},{\"end\":57674,\"start\":57673},{\"end\":57922,\"start\":57921},{\"end\":57934,\"start\":57933},{\"end\":57948,\"start\":57947},{\"end\":57959,\"start\":57958},{\"end\":57969,\"start\":57968},{\"end\":57980,\"start\":57979},{\"end\":58292,\"start\":58291},{\"end\":58302,\"start\":58301},{\"end\":58314,\"start\":58313},{\"end\":58329,\"start\":58328},{\"end\":58340,\"start\":58339},{\"end\":58672,\"start\":58671},{\"end\":58683,\"start\":58682},{\"end\":58696,\"start\":58695},{\"end\":58705,\"start\":58704},{\"end\":58715,\"start\":58714},{\"end\":59116,\"start\":59115},{\"end\":59118,\"start\":59117},{\"end\":59128,\"start\":59127},{\"end\":59139,\"start\":59138}]", "bib_author_last_name": "[{\"end\":42643,\"start\":42637},{\"end\":42650,\"start\":42647},{\"end\":42658,\"start\":42654},{\"end\":42670,\"start\":42662},{\"end\":42999,\"start\":42992},{\"end\":43009,\"start\":43003},{\"end\":43024,\"start\":43013},{\"end\":43039,\"start\":43030},{\"end\":43415,\"start\":43412},{\"end\":43425,\"start\":43419},{\"end\":43436,\"start\":43429},{\"end\":43443,\"start\":43440},{\"end\":43854,\"start\":43850},{\"end\":43860,\"start\":43858},{\"end\":43868,\"start\":43864},{\"end\":43874,\"start\":43872},{\"end\":43880,\"start\":43878},{\"end\":43886,\"start\":43884},{\"end\":44252,\"start\":44242},{\"end\":44268,\"start\":44256},{\"end\":44277,\"start\":44272},{\"end\":44283,\"start\":44281},{\"end\":44298,\"start\":44287},{\"end\":44307,\"start\":44302},{\"end\":44320,\"start\":44311},{\"end\":44330,\"start\":44324},{\"end\":44683,\"start\":44678},{\"end\":44694,\"start\":44687},{\"end\":44704,\"start\":44698},{\"end\":44715,\"start\":44708},{\"end\":44945,\"start\":44942},{\"end\":44957,\"start\":44949},{\"end\":44969,\"start\":44961},{\"end\":45240,\"start\":45235},{\"end\":45249,\"start\":45246},{\"end\":45261,\"start\":45255},{\"end\":45267,\"start\":45265},{\"end\":45276,\"start\":45271},{\"end\":45286,\"start\":45282},{\"end\":45607,\"start\":45604},{\"end\":45618,\"start\":45611},{\"end\":45892,\"start\":45889},{\"end\":45902,\"start\":45896},{\"end\":45909,\"start\":45906},{\"end\":46269,\"start\":46264},{\"end\":46276,\"start\":46273},{\"end\":46284,\"start\":46280},{\"end\":46295,\"start\":46290},{\"end\":46619,\"start\":46613},{\"end\":46629,\"start\":46623},{\"end\":46638,\"start\":46633},{\"end\":46647,\"start\":46642},{\"end\":46658,\"start\":46651},{\"end\":46670,\"start\":46662},{\"end\":46682,\"start\":46674},{\"end\":46696,\"start\":46686},{\"end\":46706,\"start\":46700},{\"end\":46720,\"start\":46710},{\"end\":47169,\"start\":47167},{\"end\":47178,\"start\":47173},{\"end\":47185,\"start\":47182},{\"end\":47196,\"start\":47189},{\"end\":47209,\"start\":47202},{\"end\":47223,\"start\":47213},{\"end\":47234,\"start\":47227},{\"end\":47565,\"start\":47562},{\"end\":47574,\"start\":47569},{\"end\":47581,\"start\":47578},{\"end\":47893,\"start\":47888},{\"end\":47901,\"start\":47897},{\"end\":47911,\"start\":47905},{\"end\":48214,\"start\":48209},{\"end\":48224,\"start\":48220},{\"end\":48235,\"start\":48228},{\"end\":48247,\"start\":48241},{\"end\":48540,\"start\":48533},{\"end\":48551,\"start\":48544},{\"end\":48564,\"start\":48555},{\"end\":48968,\"start\":48957},{\"end\":48979,\"start\":48974},{\"end\":49270,\"start\":49264},{\"end\":49280,\"start\":49274},{\"end\":49288,\"start\":49284},{\"end\":49297,\"start\":49292},{\"end\":49658,\"start\":49652},{\"end\":49664,\"start\":49662},{\"end\":49670,\"start\":49668},{\"end\":49679,\"start\":49674},{\"end\":49960,\"start\":49952},{\"end\":49968,\"start\":49964},{\"end\":49981,\"start\":49972},{\"end\":50265,\"start\":50261},{\"end\":50277,\"start\":50271},{\"end\":50285,\"start\":50281},{\"end\":50291,\"start\":50289},{\"end\":50546,\"start\":50541},{\"end\":50559,\"start\":50550},{\"end\":50572,\"start\":50563},{\"end\":50819,\"start\":50809},{\"end\":50831,\"start\":50823},{\"end\":50841,\"start\":50835},{\"end\":51108,\"start\":51096},{\"end\":51119,\"start\":51112},{\"end\":51127,\"start\":51123},{\"end\":51369,\"start\":51361},{\"end\":51376,\"start\":51373},{\"end\":51389,\"start\":51382},{\"end\":51397,\"start\":51393},{\"end\":51674,\"start\":51662},{\"end\":51687,\"start\":51678},{\"end\":51699,\"start\":51691},{\"end\":51987,\"start\":51978},{\"end\":52001,\"start\":51993},{\"end\":52266,\"start\":52262},{\"end\":52276,\"start\":52270},{\"end\":52289,\"start\":52282},{\"end\":52300,\"start\":52295},{\"end\":52605,\"start\":52598},{\"end\":52618,\"start\":52611},{\"end\":52957,\"start\":52949},{\"end\":52968,\"start\":52961},{\"end\":53265,\"start\":53257},{\"end\":53279,\"start\":53271},{\"end\":53296,\"start\":53285},{\"end\":53309,\"start\":53302},{\"end\":53323,\"start\":53315},{\"end\":53730,\"start\":53727},{\"end\":53739,\"start\":53734},{\"end\":53748,\"start\":53743},{\"end\":53757,\"start\":53752},{\"end\":53764,\"start\":53761},{\"end\":53776,\"start\":53768},{\"end\":54056,\"start\":54051},{\"end\":54064,\"start\":54060},{\"end\":54071,\"start\":54068},{\"end\":54079,\"start\":54075},{\"end\":54413,\"start\":54411},{\"end\":54419,\"start\":54417},{\"end\":54428,\"start\":54423},{\"end\":54435,\"start\":54432},{\"end\":54442,\"start\":54439},{\"end\":54710,\"start\":54698},{\"end\":54721,\"start\":54716},{\"end\":54746,\"start\":54725},{\"end\":54943,\"start\":54934},{\"end\":54953,\"start\":54947},{\"end\":54964,\"start\":54957},{\"end\":55357,\"start\":55349},{\"end\":55366,\"start\":55361},{\"end\":55708,\"start\":55704},{\"end\":55716,\"start\":55712},{\"end\":55724,\"start\":55720},{\"end\":55735,\"start\":55728},{\"end\":55742,\"start\":55739},{\"end\":56057,\"start\":56044},{\"end\":56069,\"start\":56061},{\"end\":56084,\"start\":56075},{\"end\":56438,\"start\":56434},{\"end\":56605,\"start\":56596},{\"end\":56614,\"start\":56609},{\"end\":56626,\"start\":56618},{\"end\":56638,\"start\":56630},{\"end\":56653,\"start\":56644},{\"end\":56998,\"start\":56991},{\"end\":57006,\"start\":57002},{\"end\":57018,\"start\":57010},{\"end\":57317,\"start\":57314},{\"end\":57325,\"start\":57321},{\"end\":57333,\"start\":57329},{\"end\":57339,\"start\":57337},{\"end\":57348,\"start\":57343},{\"end\":57355,\"start\":57352},{\"end\":57361,\"start\":57359},{\"end\":57370,\"start\":57365},{\"end\":57658,\"start\":57656},{\"end\":57664,\"start\":57662},{\"end\":57671,\"start\":57668},{\"end\":57680,\"start\":57675},{\"end\":57931,\"start\":57923},{\"end\":57945,\"start\":57935},{\"end\":57956,\"start\":57949},{\"end\":57966,\"start\":57960},{\"end\":57977,\"start\":57970},{\"end\":57985,\"start\":57981},{\"end\":58299,\"start\":58293},{\"end\":58311,\"start\":58303},{\"end\":58326,\"start\":58315},{\"end\":58337,\"start\":58330},{\"end\":58351,\"start\":58341},{\"end\":58680,\"start\":58673},{\"end\":58693,\"start\":58684},{\"end\":58702,\"start\":58697},{\"end\":58712,\"start\":58706},{\"end\":58721,\"start\":58716},{\"end\":59125,\"start\":59119},{\"end\":59136,\"start\":59129},{\"end\":59149,\"start\":59140},{\"end\":42643,\"start\":42637},{\"end\":42650,\"start\":42647},{\"end\":42658,\"start\":42654},{\"end\":42670,\"start\":42662},{\"end\":42999,\"start\":42992},{\"end\":43009,\"start\":43003},{\"end\":43024,\"start\":43013},{\"end\":43039,\"start\":43030},{\"end\":43415,\"start\":43412},{\"end\":43425,\"start\":43419},{\"end\":43436,\"start\":43429},{\"end\":43443,\"start\":43440},{\"end\":43854,\"start\":43850},{\"end\":43860,\"start\":43858},{\"end\":43868,\"start\":43864},{\"end\":43874,\"start\":43872},{\"end\":43880,\"start\":43878},{\"end\":43886,\"start\":43884},{\"end\":44252,\"start\":44242},{\"end\":44268,\"start\":44256},{\"end\":44277,\"start\":44272},{\"end\":44283,\"start\":44281},{\"end\":44298,\"start\":44287},{\"end\":44307,\"start\":44302},{\"end\":44320,\"start\":44311},{\"end\":44330,\"start\":44324},{\"end\":44683,\"start\":44678},{\"end\":44694,\"start\":44687},{\"end\":44704,\"start\":44698},{\"end\":44715,\"start\":44708},{\"end\":44945,\"start\":44942},{\"end\":44957,\"start\":44949},{\"end\":44969,\"start\":44961},{\"end\":45240,\"start\":45235},{\"end\":45249,\"start\":45246},{\"end\":45261,\"start\":45255},{\"end\":45267,\"start\":45265},{\"end\":45276,\"start\":45271},{\"end\":45286,\"start\":45282},{\"end\":45607,\"start\":45604},{\"end\":45618,\"start\":45611},{\"end\":45892,\"start\":45889},{\"end\":45902,\"start\":45896},{\"end\":45909,\"start\":45906},{\"end\":46269,\"start\":46264},{\"end\":46276,\"start\":46273},{\"end\":46284,\"start\":46280},{\"end\":46295,\"start\":46290},{\"end\":46619,\"start\":46613},{\"end\":46629,\"start\":46623},{\"end\":46638,\"start\":46633},{\"end\":46647,\"start\":46642},{\"end\":46658,\"start\":46651},{\"end\":46670,\"start\":46662},{\"end\":46682,\"start\":46674},{\"end\":46696,\"start\":46686},{\"end\":46706,\"start\":46700},{\"end\":46720,\"start\":46710},{\"end\":47169,\"start\":47167},{\"end\":47178,\"start\":47173},{\"end\":47185,\"start\":47182},{\"end\":47196,\"start\":47189},{\"end\":47209,\"start\":47202},{\"end\":47223,\"start\":47213},{\"end\":47234,\"start\":47227},{\"end\":47565,\"start\":47562},{\"end\":47574,\"start\":47569},{\"end\":47581,\"start\":47578},{\"end\":47893,\"start\":47888},{\"end\":47901,\"start\":47897},{\"end\":47911,\"start\":47905},{\"end\":48214,\"start\":48209},{\"end\":48224,\"start\":48220},{\"end\":48235,\"start\":48228},{\"end\":48247,\"start\":48241},{\"end\":48540,\"start\":48533},{\"end\":48551,\"start\":48544},{\"end\":48564,\"start\":48555},{\"end\":48968,\"start\":48957},{\"end\":48979,\"start\":48974},{\"end\":49270,\"start\":49264},{\"end\":49280,\"start\":49274},{\"end\":49288,\"start\":49284},{\"end\":49297,\"start\":49292},{\"end\":49658,\"start\":49652},{\"end\":49664,\"start\":49662},{\"end\":49670,\"start\":49668},{\"end\":49679,\"start\":49674},{\"end\":49960,\"start\":49952},{\"end\":49968,\"start\":49964},{\"end\":49981,\"start\":49972},{\"end\":50265,\"start\":50261},{\"end\":50277,\"start\":50271},{\"end\":50285,\"start\":50281},{\"end\":50291,\"start\":50289},{\"end\":50546,\"start\":50541},{\"end\":50559,\"start\":50550},{\"end\":50572,\"start\":50563},{\"end\":50819,\"start\":50809},{\"end\":50831,\"start\":50823},{\"end\":50841,\"start\":50835},{\"end\":51108,\"start\":51096},{\"end\":51119,\"start\":51112},{\"end\":51127,\"start\":51123},{\"end\":51369,\"start\":51361},{\"end\":51376,\"start\":51373},{\"end\":51389,\"start\":51382},{\"end\":51397,\"start\":51393},{\"end\":51674,\"start\":51662},{\"end\":51687,\"start\":51678},{\"end\":51699,\"start\":51691},{\"end\":51987,\"start\":51978},{\"end\":52001,\"start\":51993},{\"end\":52266,\"start\":52262},{\"end\":52276,\"start\":52270},{\"end\":52289,\"start\":52282},{\"end\":52300,\"start\":52295},{\"end\":52605,\"start\":52598},{\"end\":52618,\"start\":52611},{\"end\":52957,\"start\":52949},{\"end\":52968,\"start\":52961},{\"end\":53265,\"start\":53257},{\"end\":53279,\"start\":53271},{\"end\":53296,\"start\":53285},{\"end\":53309,\"start\":53302},{\"end\":53323,\"start\":53315},{\"end\":53730,\"start\":53727},{\"end\":53739,\"start\":53734},{\"end\":53748,\"start\":53743},{\"end\":53757,\"start\":53752},{\"end\":53764,\"start\":53761},{\"end\":53776,\"start\":53768},{\"end\":54056,\"start\":54051},{\"end\":54064,\"start\":54060},{\"end\":54071,\"start\":54068},{\"end\":54079,\"start\":54075},{\"end\":54413,\"start\":54411},{\"end\":54419,\"start\":54417},{\"end\":54428,\"start\":54423},{\"end\":54435,\"start\":54432},{\"end\":54442,\"start\":54439},{\"end\":54710,\"start\":54698},{\"end\":54721,\"start\":54716},{\"end\":54746,\"start\":54725},{\"end\":54943,\"start\":54934},{\"end\":54953,\"start\":54947},{\"end\":54964,\"start\":54957},{\"end\":55357,\"start\":55349},{\"end\":55366,\"start\":55361},{\"end\":55708,\"start\":55704},{\"end\":55716,\"start\":55712},{\"end\":55724,\"start\":55720},{\"end\":55735,\"start\":55728},{\"end\":55742,\"start\":55739},{\"end\":56057,\"start\":56044},{\"end\":56069,\"start\":56061},{\"end\":56084,\"start\":56075},{\"end\":56438,\"start\":56434},{\"end\":56605,\"start\":56596},{\"end\":56614,\"start\":56609},{\"end\":56626,\"start\":56618},{\"end\":56638,\"start\":56630},{\"end\":56653,\"start\":56644},{\"end\":56998,\"start\":56991},{\"end\":57006,\"start\":57002},{\"end\":57018,\"start\":57010},{\"end\":57317,\"start\":57314},{\"end\":57325,\"start\":57321},{\"end\":57333,\"start\":57329},{\"end\":57339,\"start\":57337},{\"end\":57348,\"start\":57343},{\"end\":57355,\"start\":57352},{\"end\":57361,\"start\":57359},{\"end\":57370,\"start\":57365},{\"end\":57658,\"start\":57656},{\"end\":57664,\"start\":57662},{\"end\":57671,\"start\":57668},{\"end\":57680,\"start\":57675},{\"end\":57931,\"start\":57923},{\"end\":57945,\"start\":57935},{\"end\":57956,\"start\":57949},{\"end\":57966,\"start\":57960},{\"end\":57977,\"start\":57970},{\"end\":57985,\"start\":57981},{\"end\":58299,\"start\":58293},{\"end\":58311,\"start\":58303},{\"end\":58326,\"start\":58315},{\"end\":58337,\"start\":58330},{\"end\":58351,\"start\":58341},{\"end\":58680,\"start\":58673},{\"end\":58693,\"start\":58684},{\"end\":58702,\"start\":58697},{\"end\":58712,\"start\":58706},{\"end\":58721,\"start\":58716},{\"end\":59125,\"start\":59119},{\"end\":59136,\"start\":59129},{\"end\":59149,\"start\":59140}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":32806222},\"end\":42986,\"start\":42570},{\"attributes\":{\"doi\":\"arXiv:1912.11151\",\"id\":\"b1\"},\"end\":43338,\"start\":42988},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":665667},\"end\":43773,\"start\":43340},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":29152002},\"end\":44209,\"start\":43775},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":1033682},\"end\":44596,\"start\":44211},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":205433041},\"end\":44890,\"start\":44598},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":211505950},\"end\":45159,\"start\":44892},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":208291362},\"end\":45555,\"start\":45161},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53338491},\"end\":45808,\"start\":45557},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":51970352},\"end\":46194,\"start\":45810},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":6200260},\"end\":46526,\"start\":46196},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":85498398},\"end\":47116,\"start\":46528},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":162183917},\"end\":47488,\"start\":47118},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":202774172},\"end\":47824,\"start\":47490},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1099052},\"end\":48122,\"start\":47826},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":14592574},\"end\":48464,\"start\":48124},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":4559198},\"end\":48792,\"start\":48466},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":21704094},\"end\":49212,\"start\":48794},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":16185196},\"end\":49598,\"start\":49214},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1059659},\"end\":49910,\"start\":49600},{\"attributes\":{\"id\":\"b20\"},\"end\":50179,\"start\":49912},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":109936942},\"end\":50535,\"start\":50181},{\"attributes\":{\"id\":\"b22\"},\"end\":50743,\"start\":50537},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":44061183},\"end\":51040,\"start\":50745},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":189928265},\"end\":51288,\"start\":51042},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":24376954},\"end\":51610,\"start\":51290},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":14370274},\"end\":51896,\"start\":51612},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":86766369},\"end\":52174,\"start\":51898},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":584690},\"end\":52538,\"start\":52176},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1493342},\"end\":52866,\"start\":52540},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":29479128},\"end\":53162,\"start\":52868},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":14211082},\"end\":53665,\"start\":53164},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":199017595},\"end\":54009,\"start\":53667},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":6122620},\"end\":54320,\"start\":54011},{\"attributes\":{\"doi\":\"arXiv:2002.10137\",\"id\":\"b34\"},\"end\":54644,\"start\":54322},{\"attributes\":{\"id\":\"b35\"},\"end\":54928,\"start\":54646},{\"attributes\":{\"doi\":\"arXiv:1803.07461\",\"id\":\"b36\"},\"end\":55246,\"start\":54930},{\"attributes\":{\"doi\":\"10.1109/TAFFC.2019.2916031\",\"id\":\"b37\",\"matched_paper_id\":44113436},\"end\":55625,\"start\":55248},{\"attributes\":{\"doi\":\"arXiv:1907.01826\",\"id\":\"b38\"},\"end\":55941,\"start\":55627},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":14918835},\"end\":56391,\"start\":55943},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":6155330},\"end\":56553,\"start\":56393},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":10894094},\"end\":56893,\"start\":56555},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":11758569},\"end\":57268,\"start\":56895},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":7448250},\"end\":57616,\"start\":57270},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":17579179},\"end\":57880,\"start\":57618},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":1687220},\"end\":58206,\"start\":57882},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":326772},\"end\":58610,\"start\":58208},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":206593880},\"end\":59090,\"start\":58612},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":4637184},\"end\":59295,\"start\":59092},{\"attributes\":{\"id\":\"b49\"},\"end\":59570,\"start\":59297},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":32806222},\"end\":42986,\"start\":42570},{\"attributes\":{\"doi\":\"arXiv:1912.11151\",\"id\":\"b1\"},\"end\":43338,\"start\":42988},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":665667},\"end\":43773,\"start\":43340},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":29152002},\"end\":44209,\"start\":43775},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":10319744},\"end\":44596,\"start\":44211},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":205433041},\"end\":44890,\"start\":44598},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":211505950},\"end\":45159,\"start\":44892},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":208291362},\"end\":45555,\"start\":45161},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53338491},\"end\":45808,\"start\":45557},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":51970352},\"end\":46194,\"start\":45810},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":6200260},\"end\":46526,\"start\":46196},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":85498398},\"end\":47116,\"start\":46528},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":162183917},\"end\":47488,\"start\":47118},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":202774172},\"end\":47824,\"start\":47490},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1099052},\"end\":48122,\"start\":47826},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":14592574},\"end\":48464,\"start\":48124},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":4559198},\"end\":48792,\"start\":48466},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":21704094},\"end\":49212,\"start\":48794},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":257721499},\"end\":49598,\"start\":49214},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1059659},\"end\":49910,\"start\":49600},{\"attributes\":{\"id\":\"b20\"},\"end\":50179,\"start\":49912},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":109936942},\"end\":50535,\"start\":50181},{\"attributes\":{\"id\":\"b22\"},\"end\":50743,\"start\":50537},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":44061183},\"end\":51040,\"start\":50745},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":189928265},\"end\":51288,\"start\":51042},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":24376954},\"end\":51610,\"start\":51290},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":14370274},\"end\":51896,\"start\":51612},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":86766369},\"end\":52174,\"start\":51898},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":584690},\"end\":52538,\"start\":52176},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1493342},\"end\":52866,\"start\":52540},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":29479128},\"end\":53162,\"start\":52868},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":14211082},\"end\":53665,\"start\":53164},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":199017595},\"end\":54009,\"start\":53667},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":6122620},\"end\":54320,\"start\":54011},{\"attributes\":{\"doi\":\"arXiv:2002.10137\",\"id\":\"b34\"},\"end\":54644,\"start\":54322},{\"attributes\":{\"id\":\"b35\"},\"end\":54928,\"start\":54646},{\"attributes\":{\"doi\":\"arXiv:1803.07461\",\"id\":\"b36\"},\"end\":55246,\"start\":54930},{\"attributes\":{\"doi\":\"10.1109/TAFFC.2019.2916031\",\"id\":\"b37\",\"matched_paper_id\":44113436},\"end\":55625,\"start\":55248},{\"attributes\":{\"doi\":\"arXiv:1907.01826\",\"id\":\"b38\"},\"end\":55941,\"start\":55627},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":14918835},\"end\":56391,\"start\":55943},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":6155330},\"end\":56553,\"start\":56393},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":10894094},\"end\":56893,\"start\":56555},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":11758569},\"end\":57268,\"start\":56895},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":7448250},\"end\":57616,\"start\":57270},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":17579179},\"end\":57880,\"start\":57618},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":1687220},\"end\":58206,\"start\":57882},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":326772},\"end\":58610,\"start\":58208},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":206593880},\"end\":59090,\"start\":58612},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":4637184},\"end\":59295,\"start\":59092},{\"attributes\":{\"id\":\"b49\"},\"end\":59570,\"start\":59297}]", "bib_title": "[{\"end\":42633,\"start\":42570},{\"end\":43408,\"start\":43340},{\"end\":43846,\"start\":43775},{\"end\":44238,\"start\":44211},{\"end\":44674,\"start\":44598},{\"end\":44938,\"start\":44892},{\"end\":45229,\"start\":45161},{\"end\":45600,\"start\":45557},{\"end\":45885,\"start\":45810},{\"end\":46260,\"start\":46196},{\"end\":46609,\"start\":46528},{\"end\":47163,\"start\":47118},{\"end\":47558,\"start\":47490},{\"end\":47884,\"start\":47826},{\"end\":48201,\"start\":48124},{\"end\":48529,\"start\":48466},{\"end\":48951,\"start\":48794},{\"end\":49260,\"start\":49214},{\"end\":49646,\"start\":49600},{\"end\":49948,\"start\":49912},{\"end\":50257,\"start\":50181},{\"end\":50805,\"start\":50745},{\"end\":51092,\"start\":51042},{\"end\":51357,\"start\":51290},{\"end\":51658,\"start\":51612},{\"end\":51974,\"start\":51898},{\"end\":52258,\"start\":52176},{\"end\":52594,\"start\":52540},{\"end\":52945,\"start\":52868},{\"end\":53251,\"start\":53164},{\"end\":53723,\"start\":53667},{\"end\":54047,\"start\":54011},{\"end\":54694,\"start\":54646},{\"end\":55345,\"start\":55248},{\"end\":56040,\"start\":55943},{\"end\":56428,\"start\":56393},{\"end\":56592,\"start\":56555},{\"end\":56987,\"start\":56895},{\"end\":57310,\"start\":57270},{\"end\":57652,\"start\":57618},{\"end\":57919,\"start\":57882},{\"end\":58289,\"start\":58208},{\"end\":58669,\"start\":58612},{\"end\":59113,\"start\":59092},{\"end\":42633,\"start\":42570},{\"end\":43408,\"start\":43340},{\"end\":43846,\"start\":43775},{\"end\":44238,\"start\":44211},{\"end\":44674,\"start\":44598},{\"end\":44938,\"start\":44892},{\"end\":45229,\"start\":45161},{\"end\":45600,\"start\":45557},{\"end\":45885,\"start\":45810},{\"end\":46260,\"start\":46196},{\"end\":46609,\"start\":46528},{\"end\":47163,\"start\":47118},{\"end\":47558,\"start\":47490},{\"end\":47884,\"start\":47826},{\"end\":48201,\"start\":48124},{\"end\":48529,\"start\":48466},{\"end\":48951,\"start\":48794},{\"end\":49260,\"start\":49214},{\"end\":49646,\"start\":49600},{\"end\":49948,\"start\":49912},{\"end\":50257,\"start\":50181},{\"end\":50805,\"start\":50745},{\"end\":51092,\"start\":51042},{\"end\":51357,\"start\":51290},{\"end\":51658,\"start\":51612},{\"end\":51974,\"start\":51898},{\"end\":52258,\"start\":52176},{\"end\":52594,\"start\":52540},{\"end\":52945,\"start\":52868},{\"end\":53251,\"start\":53164},{\"end\":53723,\"start\":53667},{\"end\":54047,\"start\":54011},{\"end\":54694,\"start\":54646},{\"end\":55345,\"start\":55248},{\"end\":56040,\"start\":55943},{\"end\":56428,\"start\":56393},{\"end\":56592,\"start\":56555},{\"end\":56987,\"start\":56895},{\"end\":57310,\"start\":57270},{\"end\":57652,\"start\":57618},{\"end\":57919,\"start\":57882},{\"end\":58289,\"start\":58208},{\"end\":58669,\"start\":58612},{\"end\":59113,\"start\":59092}]", "bib_author": "[{\"end\":42645,\"start\":42635},{\"end\":42652,\"start\":42645},{\"end\":42660,\"start\":42652},{\"end\":42672,\"start\":42660},{\"end\":43001,\"start\":42988},{\"end\":43011,\"start\":43001},{\"end\":43026,\"start\":43011},{\"end\":43041,\"start\":43026},{\"end\":43417,\"start\":43410},{\"end\":43427,\"start\":43417},{\"end\":43438,\"start\":43427},{\"end\":43445,\"start\":43438},{\"end\":43856,\"start\":43848},{\"end\":43862,\"start\":43856},{\"end\":43870,\"start\":43862},{\"end\":43876,\"start\":43870},{\"end\":43882,\"start\":43876},{\"end\":43888,\"start\":43882},{\"end\":44254,\"start\":44240},{\"end\":44270,\"start\":44254},{\"end\":44279,\"start\":44270},{\"end\":44285,\"start\":44279},{\"end\":44300,\"start\":44285},{\"end\":44309,\"start\":44300},{\"end\":44322,\"start\":44309},{\"end\":44332,\"start\":44322},{\"end\":44685,\"start\":44676},{\"end\":44696,\"start\":44685},{\"end\":44706,\"start\":44696},{\"end\":44717,\"start\":44706},{\"end\":44947,\"start\":44940},{\"end\":44959,\"start\":44947},{\"end\":44971,\"start\":44959},{\"end\":45242,\"start\":45231},{\"end\":45251,\"start\":45242},{\"end\":45263,\"start\":45251},{\"end\":45269,\"start\":45263},{\"end\":45278,\"start\":45269},{\"end\":45288,\"start\":45278},{\"end\":45609,\"start\":45602},{\"end\":45620,\"start\":45609},{\"end\":45894,\"start\":45887},{\"end\":45904,\"start\":45894},{\"end\":45911,\"start\":45904},{\"end\":46271,\"start\":46262},{\"end\":46278,\"start\":46271},{\"end\":46286,\"start\":46278},{\"end\":46297,\"start\":46286},{\"end\":46621,\"start\":46611},{\"end\":46631,\"start\":46621},{\"end\":46640,\"start\":46631},{\"end\":46649,\"start\":46640},{\"end\":46660,\"start\":46649},{\"end\":46672,\"start\":46660},{\"end\":46684,\"start\":46672},{\"end\":46698,\"start\":46684},{\"end\":46708,\"start\":46698},{\"end\":46722,\"start\":46708},{\"end\":47171,\"start\":47165},{\"end\":47180,\"start\":47171},{\"end\":47187,\"start\":47180},{\"end\":47198,\"start\":47187},{\"end\":47211,\"start\":47198},{\"end\":47225,\"start\":47211},{\"end\":47236,\"start\":47225},{\"end\":47567,\"start\":47560},{\"end\":47576,\"start\":47567},{\"end\":47583,\"start\":47576},{\"end\":47895,\"start\":47886},{\"end\":47903,\"start\":47895},{\"end\":47913,\"start\":47903},{\"end\":48216,\"start\":48203},{\"end\":48226,\"start\":48216},{\"end\":48237,\"start\":48226},{\"end\":48249,\"start\":48237},{\"end\":48542,\"start\":48531},{\"end\":48553,\"start\":48542},{\"end\":48566,\"start\":48553},{\"end\":48970,\"start\":48953},{\"end\":48981,\"start\":48970},{\"end\":49272,\"start\":49262},{\"end\":49282,\"start\":49272},{\"end\":49290,\"start\":49282},{\"end\":49299,\"start\":49290},{\"end\":49660,\"start\":49648},{\"end\":49666,\"start\":49660},{\"end\":49672,\"start\":49666},{\"end\":49681,\"start\":49672},{\"end\":49962,\"start\":49950},{\"end\":49970,\"start\":49962},{\"end\":49983,\"start\":49970},{\"end\":50267,\"start\":50259},{\"end\":50279,\"start\":50267},{\"end\":50287,\"start\":50279},{\"end\":50293,\"start\":50287},{\"end\":50548,\"start\":50537},{\"end\":50561,\"start\":50548},{\"end\":50574,\"start\":50561},{\"end\":50821,\"start\":50807},{\"end\":50833,\"start\":50821},{\"end\":50843,\"start\":50833},{\"end\":51110,\"start\":51094},{\"end\":51121,\"start\":51110},{\"end\":51129,\"start\":51121},{\"end\":51371,\"start\":51359},{\"end\":51378,\"start\":51371},{\"end\":51391,\"start\":51378},{\"end\":51399,\"start\":51391},{\"end\":51676,\"start\":51660},{\"end\":51689,\"start\":51676},{\"end\":51701,\"start\":51689},{\"end\":51989,\"start\":51976},{\"end\":52003,\"start\":51989},{\"end\":52268,\"start\":52260},{\"end\":52278,\"start\":52268},{\"end\":52291,\"start\":52278},{\"end\":52302,\"start\":52291},{\"end\":52607,\"start\":52596},{\"end\":52620,\"start\":52607},{\"end\":52959,\"start\":52947},{\"end\":52970,\"start\":52959},{\"end\":53267,\"start\":53253},{\"end\":53281,\"start\":53267},{\"end\":53298,\"start\":53281},{\"end\":53311,\"start\":53298},{\"end\":53325,\"start\":53311},{\"end\":53732,\"start\":53725},{\"end\":53741,\"start\":53732},{\"end\":53750,\"start\":53741},{\"end\":53759,\"start\":53750},{\"end\":53766,\"start\":53759},{\"end\":53778,\"start\":53766},{\"end\":54058,\"start\":54049},{\"end\":54066,\"start\":54058},{\"end\":54073,\"start\":54066},{\"end\":54081,\"start\":54073},{\"end\":54415,\"start\":54409},{\"end\":54421,\"start\":54415},{\"end\":54430,\"start\":54421},{\"end\":54437,\"start\":54430},{\"end\":54444,\"start\":54437},{\"end\":54712,\"start\":54696},{\"end\":54723,\"start\":54712},{\"end\":54748,\"start\":54723},{\"end\":54945,\"start\":54930},{\"end\":54955,\"start\":54945},{\"end\":54966,\"start\":54955},{\"end\":55359,\"start\":55347},{\"end\":55368,\"start\":55359},{\"end\":55710,\"start\":55702},{\"end\":55718,\"start\":55710},{\"end\":55726,\"start\":55718},{\"end\":55737,\"start\":55726},{\"end\":55744,\"start\":55737},{\"end\":56059,\"start\":56042},{\"end\":56071,\"start\":56059},{\"end\":56086,\"start\":56071},{\"end\":56440,\"start\":56430},{\"end\":56607,\"start\":56594},{\"end\":56616,\"start\":56607},{\"end\":56628,\"start\":56616},{\"end\":56640,\"start\":56628},{\"end\":56655,\"start\":56640},{\"end\":57000,\"start\":56989},{\"end\":57008,\"start\":57000},{\"end\":57020,\"start\":57008},{\"end\":57319,\"start\":57312},{\"end\":57327,\"start\":57319},{\"end\":57335,\"start\":57327},{\"end\":57341,\"start\":57335},{\"end\":57350,\"start\":57341},{\"end\":57357,\"start\":57350},{\"end\":57363,\"start\":57357},{\"end\":57372,\"start\":57363},{\"end\":57660,\"start\":57654},{\"end\":57666,\"start\":57660},{\"end\":57673,\"start\":57666},{\"end\":57682,\"start\":57673},{\"end\":57933,\"start\":57921},{\"end\":57947,\"start\":57933},{\"end\":57958,\"start\":57947},{\"end\":57968,\"start\":57958},{\"end\":57979,\"start\":57968},{\"end\":57987,\"start\":57979},{\"end\":58301,\"start\":58291},{\"end\":58313,\"start\":58301},{\"end\":58328,\"start\":58313},{\"end\":58339,\"start\":58328},{\"end\":58353,\"start\":58339},{\"end\":58682,\"start\":58671},{\"end\":58695,\"start\":58682},{\"end\":58704,\"start\":58695},{\"end\":58714,\"start\":58704},{\"end\":58723,\"start\":58714},{\"end\":59127,\"start\":59115},{\"end\":59138,\"start\":59127},{\"end\":59151,\"start\":59138},{\"end\":42645,\"start\":42635},{\"end\":42652,\"start\":42645},{\"end\":42660,\"start\":42652},{\"end\":42672,\"start\":42660},{\"end\":43001,\"start\":42988},{\"end\":43011,\"start\":43001},{\"end\":43026,\"start\":43011},{\"end\":43041,\"start\":43026},{\"end\":43417,\"start\":43410},{\"end\":43427,\"start\":43417},{\"end\":43438,\"start\":43427},{\"end\":43445,\"start\":43438},{\"end\":43856,\"start\":43848},{\"end\":43862,\"start\":43856},{\"end\":43870,\"start\":43862},{\"end\":43876,\"start\":43870},{\"end\":43882,\"start\":43876},{\"end\":43888,\"start\":43882},{\"end\":44254,\"start\":44240},{\"end\":44270,\"start\":44254},{\"end\":44279,\"start\":44270},{\"end\":44285,\"start\":44279},{\"end\":44300,\"start\":44285},{\"end\":44309,\"start\":44300},{\"end\":44322,\"start\":44309},{\"end\":44332,\"start\":44322},{\"end\":44685,\"start\":44676},{\"end\":44696,\"start\":44685},{\"end\":44706,\"start\":44696},{\"end\":44717,\"start\":44706},{\"end\":44947,\"start\":44940},{\"end\":44959,\"start\":44947},{\"end\":44971,\"start\":44959},{\"end\":45242,\"start\":45231},{\"end\":45251,\"start\":45242},{\"end\":45263,\"start\":45251},{\"end\":45269,\"start\":45263},{\"end\":45278,\"start\":45269},{\"end\":45288,\"start\":45278},{\"end\":45609,\"start\":45602},{\"end\":45620,\"start\":45609},{\"end\":45894,\"start\":45887},{\"end\":45904,\"start\":45894},{\"end\":45911,\"start\":45904},{\"end\":46271,\"start\":46262},{\"end\":46278,\"start\":46271},{\"end\":46286,\"start\":46278},{\"end\":46297,\"start\":46286},{\"end\":46621,\"start\":46611},{\"end\":46631,\"start\":46621},{\"end\":46640,\"start\":46631},{\"end\":46649,\"start\":46640},{\"end\":46660,\"start\":46649},{\"end\":46672,\"start\":46660},{\"end\":46684,\"start\":46672},{\"end\":46698,\"start\":46684},{\"end\":46708,\"start\":46698},{\"end\":46722,\"start\":46708},{\"end\":47171,\"start\":47165},{\"end\":47180,\"start\":47171},{\"end\":47187,\"start\":47180},{\"end\":47198,\"start\":47187},{\"end\":47211,\"start\":47198},{\"end\":47225,\"start\":47211},{\"end\":47236,\"start\":47225},{\"end\":47567,\"start\":47560},{\"end\":47576,\"start\":47567},{\"end\":47583,\"start\":47576},{\"end\":47895,\"start\":47886},{\"end\":47903,\"start\":47895},{\"end\":47913,\"start\":47903},{\"end\":48216,\"start\":48203},{\"end\":48226,\"start\":48216},{\"end\":48237,\"start\":48226},{\"end\":48249,\"start\":48237},{\"end\":48542,\"start\":48531},{\"end\":48553,\"start\":48542},{\"end\":48566,\"start\":48553},{\"end\":48970,\"start\":48953},{\"end\":48981,\"start\":48970},{\"end\":49272,\"start\":49262},{\"end\":49282,\"start\":49272},{\"end\":49290,\"start\":49282},{\"end\":49299,\"start\":49290},{\"end\":49660,\"start\":49648},{\"end\":49666,\"start\":49660},{\"end\":49672,\"start\":49666},{\"end\":49681,\"start\":49672},{\"end\":49962,\"start\":49950},{\"end\":49970,\"start\":49962},{\"end\":49983,\"start\":49970},{\"end\":50267,\"start\":50259},{\"end\":50279,\"start\":50267},{\"end\":50287,\"start\":50279},{\"end\":50293,\"start\":50287},{\"end\":50548,\"start\":50537},{\"end\":50561,\"start\":50548},{\"end\":50574,\"start\":50561},{\"end\":50821,\"start\":50807},{\"end\":50833,\"start\":50821},{\"end\":50843,\"start\":50833},{\"end\":51110,\"start\":51094},{\"end\":51121,\"start\":51110},{\"end\":51129,\"start\":51121},{\"end\":51371,\"start\":51359},{\"end\":51378,\"start\":51371},{\"end\":51391,\"start\":51378},{\"end\":51399,\"start\":51391},{\"end\":51676,\"start\":51660},{\"end\":51689,\"start\":51676},{\"end\":51701,\"start\":51689},{\"end\":51989,\"start\":51976},{\"end\":52003,\"start\":51989},{\"end\":52268,\"start\":52260},{\"end\":52278,\"start\":52268},{\"end\":52291,\"start\":52278},{\"end\":52302,\"start\":52291},{\"end\":52607,\"start\":52596},{\"end\":52620,\"start\":52607},{\"end\":52959,\"start\":52947},{\"end\":52970,\"start\":52959},{\"end\":53267,\"start\":53253},{\"end\":53281,\"start\":53267},{\"end\":53298,\"start\":53281},{\"end\":53311,\"start\":53298},{\"end\":53325,\"start\":53311},{\"end\":53732,\"start\":53725},{\"end\":53741,\"start\":53732},{\"end\":53750,\"start\":53741},{\"end\":53759,\"start\":53750},{\"end\":53766,\"start\":53759},{\"end\":53778,\"start\":53766},{\"end\":54058,\"start\":54049},{\"end\":54066,\"start\":54058},{\"end\":54073,\"start\":54066},{\"end\":54081,\"start\":54073},{\"end\":54415,\"start\":54409},{\"end\":54421,\"start\":54415},{\"end\":54430,\"start\":54421},{\"end\":54437,\"start\":54430},{\"end\":54444,\"start\":54437},{\"end\":54712,\"start\":54696},{\"end\":54723,\"start\":54712},{\"end\":54748,\"start\":54723},{\"end\":54945,\"start\":54930},{\"end\":54955,\"start\":54945},{\"end\":54966,\"start\":54955},{\"end\":55359,\"start\":55347},{\"end\":55368,\"start\":55359},{\"end\":55710,\"start\":55702},{\"end\":55718,\"start\":55710},{\"end\":55726,\"start\":55718},{\"end\":55737,\"start\":55726},{\"end\":55744,\"start\":55737},{\"end\":56059,\"start\":56042},{\"end\":56071,\"start\":56059},{\"end\":56086,\"start\":56071},{\"end\":56440,\"start\":56430},{\"end\":56607,\"start\":56594},{\"end\":56616,\"start\":56607},{\"end\":56628,\"start\":56616},{\"end\":56640,\"start\":56628},{\"end\":56655,\"start\":56640},{\"end\":57000,\"start\":56989},{\"end\":57008,\"start\":57000},{\"end\":57020,\"start\":57008},{\"end\":57319,\"start\":57312},{\"end\":57327,\"start\":57319},{\"end\":57335,\"start\":57327},{\"end\":57341,\"start\":57335},{\"end\":57350,\"start\":57341},{\"end\":57357,\"start\":57350},{\"end\":57363,\"start\":57357},{\"end\":57372,\"start\":57363},{\"end\":57660,\"start\":57654},{\"end\":57666,\"start\":57660},{\"end\":57673,\"start\":57666},{\"end\":57682,\"start\":57673},{\"end\":57933,\"start\":57921},{\"end\":57947,\"start\":57933},{\"end\":57958,\"start\":57947},{\"end\":57968,\"start\":57958},{\"end\":57979,\"start\":57968},{\"end\":57987,\"start\":57979},{\"end\":58301,\"start\":58291},{\"end\":58313,\"start\":58301},{\"end\":58328,\"start\":58313},{\"end\":58339,\"start\":58328},{\"end\":58353,\"start\":58339},{\"end\":58682,\"start\":58671},{\"end\":58695,\"start\":58682},{\"end\":58704,\"start\":58695},{\"end\":58714,\"start\":58704},{\"end\":58723,\"start\":58714},{\"end\":59127,\"start\":59115},{\"end\":59138,\"start\":59127},{\"end\":59151,\"start\":59138}]", "bib_venue": "[{\"end\":43566,\"start\":43514},{\"end\":43997,\"start\":43951},{\"end\":58864,\"start\":58802},{\"end\":43566,\"start\":43514},{\"end\":43997,\"start\":43951},{\"end\":58864,\"start\":58802},{\"end\":42758,\"start\":42672},{\"end\":43139,\"start\":43057},{\"end\":43512,\"start\":43445},{\"end\":43949,\"start\":43888},{\"end\":44381,\"start\":44332},{\"end\":44728,\"start\":44717},{\"end\":45017,\"start\":44971},{\"end\":45340,\"start\":45288},{\"end\":45666,\"start\":45620},{\"end\":45986,\"start\":45911},{\"end\":46343,\"start\":46297},{\"end\":46797,\"start\":46722},{\"end\":47282,\"start\":47236},{\"end\":47639,\"start\":47583},{\"end\":47957,\"start\":47913},{\"end\":48275,\"start\":48249},{\"end\":48612,\"start\":48566},{\"end\":48989,\"start\":48981},{\"end\":49369,\"start\":49299},{\"end\":49737,\"start\":49681},{\"end\":50035,\"start\":49983},{\"end\":50339,\"start\":50293},{\"end\":50632,\"start\":50574},{\"end\":50883,\"start\":50843},{\"end\":51148,\"start\":51129},{\"end\":51431,\"start\":51399},{\"end\":51737,\"start\":51701},{\"end\":52018,\"start\":52003},{\"end\":52340,\"start\":52302},{\"end\":52687,\"start\":52620},{\"end\":53000,\"start\":52970},{\"end\":53402,\"start\":53325},{\"end\":53816,\"start\":53778},{\"end\":54151,\"start\":54081},{\"end\":54407,\"start\":54322},{\"end\":54771,\"start\":54748},{\"end\":55064,\"start\":54982},{\"end\":55420,\"start\":55394},{\"end\":55700,\"start\":55627},{\"end\":56150,\"start\":56086},{\"end\":56459,\"start\":56440},{\"end\":56704,\"start\":56655},{\"end\":57072,\"start\":57020},{\"end\":57421,\"start\":57372},{\"end\":57731,\"start\":57682},{\"end\":58024,\"start\":57987},{\"end\":58390,\"start\":58353},{\"end\":58800,\"start\":58723},{\"end\":59184,\"start\":59151},{\"end\":59431,\"start\":59297},{\"end\":42758,\"start\":42672},{\"end\":43139,\"start\":43057},{\"end\":43512,\"start\":43445},{\"end\":43949,\"start\":43888},{\"end\":44381,\"start\":44332},{\"end\":44728,\"start\":44717},{\"end\":45017,\"start\":44971},{\"end\":45340,\"start\":45288},{\"end\":45666,\"start\":45620},{\"end\":45986,\"start\":45911},{\"end\":46343,\"start\":46297},{\"end\":46797,\"start\":46722},{\"end\":47282,\"start\":47236},{\"end\":47639,\"start\":47583},{\"end\":47957,\"start\":47913},{\"end\":48275,\"start\":48249},{\"end\":48612,\"start\":48566},{\"end\":48989,\"start\":48981},{\"end\":49369,\"start\":49299},{\"end\":49737,\"start\":49681},{\"end\":50035,\"start\":49983},{\"end\":50339,\"start\":50293},{\"end\":50632,\"start\":50574},{\"end\":50883,\"start\":50843},{\"end\":51148,\"start\":51129},{\"end\":51431,\"start\":51399},{\"end\":51737,\"start\":51701},{\"end\":52018,\"start\":52003},{\"end\":52340,\"start\":52302},{\"end\":52687,\"start\":52620},{\"end\":53000,\"start\":52970},{\"end\":53402,\"start\":53325},{\"end\":53816,\"start\":53778},{\"end\":54151,\"start\":54081},{\"end\":54407,\"start\":54322},{\"end\":54771,\"start\":54748},{\"end\":55064,\"start\":54982},{\"end\":55420,\"start\":55394},{\"end\":55700,\"start\":55627},{\"end\":56150,\"start\":56086},{\"end\":56459,\"start\":56440},{\"end\":56704,\"start\":56655},{\"end\":57072,\"start\":57020},{\"end\":57421,\"start\":57372},{\"end\":57731,\"start\":57682},{\"end\":58024,\"start\":57987},{\"end\":58390,\"start\":58353},{\"end\":58800,\"start\":58723},{\"end\":59184,\"start\":59151},{\"end\":59431,\"start\":59297}]"}}}, "year": 2023, "month": 12, "day": 17}