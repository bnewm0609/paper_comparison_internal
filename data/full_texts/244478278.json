{"id": 244478278, "updated": "2023-04-05 00:00:08.572", "metadata": {"title": "A C LOSER L OOK AT L OSS W EIGHTING IN M ULTI - T ASK L EARNING", "authors": "[{\"first\":\"Baijiong\",\"last\":\"Lin\",\"middle\":[]},{\"first\":\"Feiyang\",\"last\":\"Ye\",\"middle\":[]},{\"first\":\"Yu\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Multi-Task Learning (MTL) has achieved great success in various fields, however, how to balance different tasks to avoid negative effects is still a key problem. To achieve the task balancing, there exist many works to balance task losses or gradients. In this paper, we unify eight representative task balancing methods from the perspective of loss weighting and provide a consistent experimental comparison. Moreover, we surprisingly find that training a MTL model with random weights sampled from a distribution can achieve comparable performance over state-of-the-art baselines. Based on this finding, we propose a simple yet effective weighting strategy called Random Loss Weighting (RLW), which can be implemented in only one additional line of code over existing works. Theoretically, we analyze the convergence of RLW and reveal that RLW has a higher probability to escape local minima than existing models with fixed task weights, resulting in a better generalization ability. Empirically, we extensively evaluate the proposed RLW method on six image datasets and four multilingual tasks from the XTREME benchmark to show the effectiveness of the proposed RLW strategy when compared with state-of-the-art strategies.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2111-10603", "doi": null}}, "content": {"source": {"pdf_hash": "31d4dd7f7b3de9af04c9571a623a75850603a928", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2111.10603v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "369da28d2d026e1febb47a3a7af27eba4338df0f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/31d4dd7f7b3de9af04c9571a623a75850603a928.txt", "contents": "\nA CLOSER LOOK AT LOSS WEIGHTING IN MULTI- TASK LEARNING\n\n\nBaijiong Lin \nDepartment of Computer Science and Engineering Southern\nUniversity of Science and Technology Shenzhen\nChina\n\nFeiyang Ye \nDepartment of Computer Science and Engineering Southern\nUniversity of Science and Technology Shenzhen\nChina\n\nYu Zhang yu.zhang.ust@gmail.com \nDepartment of Computer Science and Engineering Southern\nUniversity of Science and Technology Shenzhen\nChina\n\nA CLOSER LOOK AT LOSS WEIGHTING IN MULTI- TASK LEARNING\n\nMulti-Task Learning (MTL) has achieved great success in various fields, however, how to balance different tasks to avoid negative effects is still a key problem. To achieve the task balancing, there exist many works to balance task losses or gradients. In this paper, we unify eight representative task balancing methods from the perspective of loss weighting and provide a consistent experimental comparison. Moreover, we surprisingly find that training a MTL model with random weights sampled from a distribution can achieve comparable performance over state-of-the-art baselines. Based on this finding, we propose a simple yet effective weighting strategy called Random Loss Weighting (RLW), which can be implemented in only one additional line of code over existing works. Theoretically, we analyze the convergence of RLW and reveal that RLW has a higher probability to escape local minima than existing models with fixed task weights, resulting in a better generalization ability. Empirically, we extensively evaluate the proposed RLW method on six image datasets and four multilingual tasks from the XTREME benchmark to show the effectiveness of the proposed RLW strategy when compared with state-of-the-art strategies. . Non-asymptotic analysis of stochastic approximation algorithms for machine learning. In gradient descent, weighted sampling, and the randomized kaczmarz algorithm. Mathematical Programming, 155(1-2):549-573, 2016. . Adapting visual category models to new domains. In . Pal. Learning general purpose distributed sentence representations via large scale multi-task learning. In . Gradient vaccine: Investigating and improving multi-task optimization in massively multilingual models. In\n\nINTRODUCTION\n\nMulti-Task Learning (MTL) (Zhang & Yang, 2021;Vandenhende et al., 2021) aims to jointly train several related tasks to improve their generalization performance by leveraging common knowledge among them. Since this learning paradigm can not only significantly reduce the model size and increase the inference speed but also improve the performance, it has been successfully applied in various fields of deep learning, such as Computer Vision (CV) (Vandenhende et al., 2021), Natural Language Processing (NLP) (Chen et al., 2021), reinforcement learning (Zhang & Yang, 2021) and so on. However, when all the tasks are not related enough, which may be reflected via conflicting gradients or dominating gradients (Yu et al., 2020), it is more difficult to train a multi-task model than training them separately because some tasks dominantly influence model parameters, leading to unsatisfactory performance for other tasks. This phenomenon is related to the task balancing problem (Vandenhende et al., 2021) in MTL. Recently, several works focus on tackling this issue from an optimization perspective via balancing task losses or gradients.\n\nIn this paper, we investigate eight State-Of-The-Art (SOTA) task balancing approaches and unify them as loss weighting strategies. According to the way of generating loss weights, those methods can be divided into three types, including the solving approach such as directly solving a quadratic optimization problem in a multi-objective formulation as weights (Sener & Koltun, 2018), the calculating approach such as projecting conflict gradients (Yu et al., 2020), and the learning approach such as learning weights in a gradient descent manner (Chen et al., 2018b). On the other hand, since there are some discrepancies of the implementation details such as using different backbone networks for training or different metrics for the evaluation among those SOTA weighting methods, leading to inconsistent comparisons, we provide a unified testbed on six CV datasets and four multilingual problems from the XTREME benchmark (Hu et al., 2020) for those SOTA weighting strategies to show a fair comparison.\n\nIn addition, inspired by dynamic weighting processes in those SOTA strategies where loss weights vary over training iterations or epochs, we have a sudden whim: what will happen if a MTL model is trained with random loss weights? Specifically, in each training iteration, we first sample the loss weights from a distribution with some normalization and then minimize the aggregated loss weighted by the normalized random weights. Surprisingly, this seemingly unreliable method can not only converge but also achieve comparable performance with the SOTA weighting strategies. Based on this observations, we proposed a simple yet effective weighting strategy for MTL, called Random Loss Weighting (RLW). It is very easy to implement RLW by adding only one line of code and this strategy does not incur any additionally computational cost. An implementation example of RLW in PyTorch (Paszke et al., 2019) is shown below. 1 outputs = model(inputs) 2 loss = criterion(outputs, labels) # [1, task_num] vector 3 weight = F.softmax(torch.randn(task_num), dim=-1) # RLW is only this! 4 loss = torch.sum(loss * weight) 5 optimizer.zero_grad() 6 loss.backward() 7 optimizer.step () To show the effectiveness of RLW, we provide both theoretical analyses and empirical evaluations. Firstly, the objective function of RLW can be considered as a doubly stochastic optimization problem when optimizing by stochastic gradient descent or its variants, where the randomness is from both the mini-batch sampling of the data for each task and the random sampling of loss weights. From this perspective, we give a convergence analysis for RLW. Besides, we can show that RLW has a higher probability to escape local minima when compared with fixing loss weights, resulting in a better generalization performance. Empirically, as described before, we compare RLW with SOTA weighting approaches on six CV datasets and four multilingual problems to show its competitive performance.\n\nIn summary, the main contributions of this paper are four-fold.\n\n\u2022 We provide a unified testbed on six multi-task computer vision datasets and four multilingual problems from the XTREME benchmark for a fair comparison among eight SOTA weighting methods and the proposed RLW method.\n\n\u2022 We propose a simple yet effective RLW strategy, which we think is an ignored baseline in MTL.\n\n\u2022 We provide the convergence guarantee and effectiveness analysis for RLW.\n\n\u2022 Experiments show that RLW can achieve comparable performance with SOTA weighting methods without bringing any additionally computational cost.\n\n\nPRELIMINARY\n\nSuppose there are T tasks and task t has its corresponding dataset D t . An MTL model usually contains two parts of parameters: task-sharing parameters \u03b8 and task-specific parameters {\u03c8 t } T t=1 . For example, in CV, \u03b8 usually denotes parameters in the feature extractor shared by all tasks and \u03c8 t represents the task-specific output module for task t. Let t (\u00b7; \u03b8, \u03c8 t ) denotes a task-specific loss function for task t. Then the objective function of a MTL model can be formulated as\nL MTL = T t=1 \u03bb t t (D t ; \u03b8, \u03c8 t ),(1)\nwhere t (D t ; \u03b8, \u03c8 t ) denotes the average loss on D t for task t and {\u03bb t } T t=1 are task-specific loss weights with a constraint that \u03bb t \u2265 0 for all t. When minimizing Eq. (1) by Stochastic Gradient Descent (SGD) or its variants, the task-specific parameters {\u03c8 t } T t=1 are simply updated based on the corresponding task gradient \u2207 \u03c8t t (D t ; \u03b8, \u03c8 t ), while the task-sharing parameters \u03b8 should be updated by all the task losses jointly as\n\u03b8 = \u03b8 \u2212 \u03b7 T t=1 \u03bb t \u2207 \u03b8 t (D t ; \u03b8, \u03c8 t ),(2)\nwhere \u03b7 is a learning rate. Obviously, for the update of task-sharing parameters \u03b8, the loss weighting (i.e., {\u03bb t } T t=1 in Eq. (1)) influences \u03b8 via the aggregated gradient essentially and the gradient weighting in Eq. (2) during the backward process has the same effect as the loss weighting when they are using the same weights. Therefore, we can ignore the level on which the weights act and focus on the generation of weights. For simplicity, these two types of weighting are all referred to as loss weighting in the following sections.\n\nApparently, the most simple method for loss weighting is to set a same weight for every tasks, i.e., without loss of generality, \u03bb t = 1 T for all t. This approach is a common baseline in MTL and it is called Equally Weighting (EW) in this paper. To tackle the task balancing problem and improve the performance of MTL model, there are several works to study how to generate appropriate weights. In this paper, we investigate eight SOTA weighting strategies, i.e. Gradient Normalization (GradNorm) (Chen et al., 2018b) According to different ways of generating loss weights, we categorize those loss weighting strategies into three types: the learning approach, the solving approach, and the calculating approach. Both GradNorm and UW consider the loss weights {\u03bb t } T t=1 in Eq. (1) as learnable parameters and explicitly optimize them by gradient descent. MGDA casts MTL as a multi-objective optimization problem and directly solves the loss weights {\u03bb t } T t=1 in Eq. (1) by solving a quadratic programming problem. DWA, PCGrad, GradDrop and GradVac directly compute the weights {\u03bb t } T t=1 by combining gradients and/or losses of all the tasks. IMTL is a hybrid strategy, which combines the learning and the calculating approaches. We summarize those strategies from the perspective of loss weighting in Table 5 in Appendix A.\n\nWe now unify those eight SOTA methods as loss weighting strategies, i.e., generating loss weights {\u03bb t } T t=1 in Eq. (1). Noticeably, almost all the existing strategies except EW need to incur intensive computation to generate loss weights in every iteration, such as solving a quadratic optimization problem in MGDA, and operating on high-dimensional gradients in PCGrad, GradDrop, IMTL, and GradVac. Different from those strategies, the proposed RLW strategy generates loss weights in a sampling way, thus it is as efficient as EW without bringing additionally computational costs.\n\n\nTHE RLW METHOD\n\nIn this section, we introduce the proposed RLW method. The RLW method is a simple loss weighting strategy and it considers the loss weights \u03bb = (\u03bb 1 , \u00b7 \u00b7 \u00b7 , \u03bb T ) \u2208 R T as random variables. Formally, the objective function of the RLW method is formulated as\nL RLW (\u03b8) = E \u03bb \u03bb (D; \u03b8) = E \u03bb [\u03bb] (D; \u03b8),(3)\nwhere E[\u00b7] denotes the expectation and (D; \u03b8) = ( 1 (D 1 ; \u03b8), \u00b7 \u00b7 \u00b7 , T (D T ; \u03b8)) where we omit the task-specific parameters {\u03c8 t } T t=1 in Eq. (3) for brevity. To guarantee loss weights in \u03bb to be nonnegative, we can first sample\u03bb = (\u03bb 1 , \u00b7 \u00b7 \u00b7 ,\u03bb T ) from any distribution p(\u03bb) and then normalize\u03bb into \u03bb via a mapping f , where f : R T \u2192 \u2206 T is a normalization function for example softmax function and \u2206 T denotes a convex hull in R T , i.e. \u03bb \u2208 \u2206 T means T t=1 \u03bb t = 1 and \u03bb t \u2265 0 for all t. Note that in most cases p(\u03bb) is different from p(\u03bb).\n\nIn Eq. (3), p(\u03bb) is usually too complex to compute its expectation E \u03bb [\u03bb], thus a stochastic approximation scheme is adopted to minimize Eq. (3). When the mini-batch SGD (Bottou, 1991) or its variants is used to minimize Eq. (3) as most deep learning models did, Eq. (3) can be viewed as a doubly stochastic optimization problem, where the randomness is from both the mini-batch data sampling for each task and the randomly sampling of the loss weights. In the following, we show that the approximated gradient \u2207 \u03b8 \u03bb (D; \u03b8) is an unbiased estimation of the true gradient of L RLW (\u03b8), whereD denotes a mini-batch data sampled from all the tasks. Specifically, asD t is a mini-batch data sampled from D t to calculate the stochastic gradient \u2207 \u03b8 t (D t ; \u03b8) to approximate the full gradient \u2207 \u03b8 t (D t ; \u03b8) for task t, we have ED[\u2207 \u03b8 (D; \u03b8)] = \u2207 \u03b8 (D; \u03b8). Therefore, when we further randomly sample a weight vector \u03bb, we have\nE \u03bb ED[\u2207 \u03b8 \u03bb (D; \u03b8)] = E \u03bb [\u03bb] \u2207 \u03b8 (D; \u03b8) = \u2207 \u03b8 L RLW (\u03b8),\nwhich verifies that \u2207 \u03b8 \u03bb (D; \u03b8) is an unbiased estimation.\n\nIn practice, it is very easy to implement the RLW method without modifying network architecture or bringing additionally computational costs. Specifically, in each iteration, we first sample\u03bb from p(\u03bb) and normalize it to obtain \u03bb via appropriate normalization function f , and then minimize the aggregated loss weighted by \u03bb. The entire algorithm of RLW (i.e., minimizing Eq. (3)) via SGD is shown in Algorithm 1. Apparently, the only difference between the proposed RLW strategy and the widely used EW strategy is Line 7 in Algorithm 1 and it is very easy to implement with only one line of code.\n\n\nAlgorithm 1 Optimization Algorithm for RLW by SGD\n\nInput: numbers of iterations K, numbers of tasks T , learning rate \u03b7, dataset {Dt} T t=1 , weight distribution p(\u03bb) 1: Randomly initialized \u03b80; 2: for k = 1 to K do 3:\n\nfor t = 1 to T do 4:\n\nSample a mini-batch dataDt from Dt; 5:\n\nCompute loss t(Dt; \u03b8 k ); 6: end for 7:\n\nSample weights\u03bb from p(\u03bb) and normalize it into \u03bb via f ; RLW is only this 8: \u03b8 k+1 = \u03b8 k \u2212 \u03b7\u2207 \u03b8 T t=1 \u03bbt t(Dt; \u03b8 k ); 9: end for\n\nIn this paper, we use six different distributions for p(\u03bb) in the proposed RLW method, including uniform distribution between 0 and 1 (denoted by Uniform), standard normal distribution (denoted by Normal), Dirichlet distribution with \u03b1 = 1 (denoted by Dirichlet), Bernoulli distribution with probability 1/2 (denoted by Bernoulli), Bernoulli distribution with probability 1/2 and a constraint T t=1\u03bb t = 1 (denoted by constrained Bernoulli), and normal distribution with a random mean and a random variance both sampling from a uniform distribution U(0, 1) for each task (denoted by random Normal). We set f as a function of f (\u03bb) =\u03bb/( T t=1\u03bb t ) if p(\u03bb) is the Bernoulli distribution or the constrained Bernoulli distribution and a softmax function for the other types of distribution. When sampling from the first five types of distribution, E[\u03bb] is simply proportional to ( 1 T , \u00b7 \u00b7 \u00b7 , 1 T ), thus it is fair to compare with the EW strategy. When p(\u03bb) is a random Normal distribution, it means each\u03bb t is sampled from a normal distribution with random mean and variance, thus it is intractable to compute the expectation for p(\u03bb) and combining with such distribution can further show the effectiveness of RLW.\n\nWhen sampling from a Bernoulli distribution, the weights for all tasks are either 0 or 1, i.e., \u03bb t \u2208 {0, 1} for all t. In this way, just a subset of tasks contributes to updating the task-sharing parameters \u03b8. This manner can be viewed as the mini-batch sampling on the task level. If considering an additional constraint that T t=1\u03bb t = 1, it implies only one task is involved in the update of the tasksharing parameters in each iteration. Although there are some works (Dong et al., 2015;Liu et al., 2015a;S\u00f8gaard & Goldberg, 2016;Subramanian et al., 2018;Sanh et al., 2019;Liu et al., 2019b) adopting this strategy to train a MTL model, it is a special case in the proposed RLW strategy and beyond existing works, we also provide theoretical analyses to show the effectiveness of the proposed RLW method.\n\n\nANALYSIS\n\nAs the optimization procedure of the RLW method can be viewed as the doubly stochastic optimization, this strategy increases the randomness compared with the fixed loss weights methods optimizing via SGD (denoted by FW), where EW is a special case. In this section, we focus on analyzing how the extra randomness from the loss weights sampling affects the convergence and effectiveness of RLW compared with FW.\n\nIn the case of without misunderstanding, we simply use t (\u03b8) instead of t (D t ; \u03b8) to denote the loss function of task t for brevity in this section and Appendix B. For the ease of the analysis, we need to make the following assumption.\n\nAssumption 1. The loss function t (\u03b8) of task t is L t -Lipschitz continuous w.r.t \u03b8, and that\nE Dt [ t (D t ; \u03b8) 2 ] = \u03c3 2 t . Loss weights in \u03bb satisfy E \u03bb [\u03bb] = \u00b5.\nIn the following theorem, we analyze the convergence property of Algorithm 1 for RLW.\n\nTheorem 1. Suppose the loss function t (\u03b8) of task t is c t -strongly convex. We define \u03b8 * = arg min \u03b8 L RLW (\u03b8) and denote by \u03b8 k the solution in the k-th iteration. When \u03b7, the step size or equivalently the learning rate in SGD, satisfies \u03b7 \u2264 1/2c, where c = min 1\u2264t\u2264T {c t }, under Assumption 1 we have\nE[ \u03b8 k \u2212 \u03b8 * 2 ] \u2264 (1 \u2212 2\u03b7c) k \u03b8 0 \u2212 \u03b8 * 2 + \u03b7\u03ba 2c ,(4)\nwhere \u03ba = T t=1 \u03c3 2 t . Then for any positive \u03b5,\nE[ \u03b8 k \u2212 \u03b8 * 2 ] \u2264 \u03b5 can be achieved after k = \u03ba 2\u03b5c 2 log \u03b50 \u03b5 iterations with \u03b7 = \u03b5c \u03ba , where \u03b5 0 = E[ \u03b8 0 \u2212 \u03b8 * 2 ].\nTheorem 1 shows that the RLW method with the fixed step size has a linear convergence up to a radius around the optimal solution, which is similar to FW according to the property of the standard SGD method (Moulines & Bach, 2011;Needell et al., 2016). Although RLW has a larger \u03ba than FW, i.e., \u03ba FW = T t=1 \u00b5 2 t \u00b7 T t=1 \u03c3 2 t \u2264 \u03ba, possibly requiring more iterations for RLW method to reach the same accuracy with FW, our empirical experiments in Appendix C.1 show that this does not cause much impact in practice.\n\nWe next analyze the effectiveness of the RLW method from the perspective of stochastic optimization. It is observed that the SGD method can escape sharp local minima and converge to a better solution than Gradient Descent (GD) techniques under various settings with the help of noisy gradients (Hardt et al., 2016;Kleinberg et al., 2018). Inspired by those works, we first provide the following Theorem 2 and then leverage this theorem to show that the extra randomness in the RLW method can help RLW to better escape sharp local minima and achieve a better generalization performance than FW.\n\nFor the ease of presentation, we introduction some notations. Here we consider the update step of these stochastic methods as \u03b8 k+1 = \u03b8 k \u2212\u03b7(\u2207\u00b5 (\u03b8 k )+\u03be k ), where \u03be k is a noise with E[\u03be k ] = 0 and \u03be k 2 \u2264 r. Here r denotes the intensity of the noise. For the analysis, we construct an intermediate\nsequence \u03d5 k = \u03b8 k \u2212 \u03b7\u2207\u00b5 (\u03b8 k ). Then we get E \u03be k [\u03d5 k+1 ] = \u03d5 k \u2212 \u03b7\u2207E \u03be k [\u00b5 (\u03d5 k \u2212 \u03b7\u03be k )].\nTherefore, the sequence {\u03d5 k } can be regarded as an approximation of using GD to minimize the\nfunction E \u03be k [\u00b5 (\u03d5 \u2212 \u03b7\u03be k )]. Theorem 2. Suppose \u2207 t (\u03b8) is M t -Lipschitz continuous and \u03be k 2 \u2264 r. If the loss function t (\u03b8) of task t is c t -one point strongly convex w.r.t a local minimum \u03b8 * after convolved with noise \u03be, i.e., \u2207E \u03be t (\u03d5 \u2212 \u03b7\u03be), \u03d5 \u2212 \u03b8 * \u2265 c t \u03d5 \u2212 \u03b8 * 2 , then under Assumption 1 we have \u03d5 K \u2212 \u03b8 * 2 \u2264 2\u03b2 \u03c1\u03b4 with probability at least 1\u2212\u03b4 after K = 1 \u03c1 log \u03c1\u03b50 \u03b2 iterations with \u03b7 \u2264 c M 2 , where \u03b5 0 = E[ \u03d5 0 \u2212\u03b8 * 2 ], c = min 1\u2264t\u2264T {c t }, M = max 1\u2264t\u2264T {M t }, \u03c1 = 2\u03b7c \u2212 \u03b7 2 M 2 and \u03b2 = \u03b7 2 r 2 (1 + \u03b7M ) 2 .\nFirstly, Theorem 2 only requires that t (\u03b8) is c t -one point strongly convex w.r.t \u03b8 * after convolved with noise \u03be, which is much weak than the convexity assumption and can hold for deep neural networks. Moreover, this theorem implies that for both RLW and FW methods, their solutions have a high probability to get close to a local minimum \u03b8 * depending on the noise \u03be. Note that by adding extra noise, the sharp local minimum will disappear and only the flat local minimum with a large diameter will still exist (Kleinberg et al., 2018). On the other hand, those flat local minima may satisfy one point strongly convexity assumption in Theorem 2, thus the diameter of the converged flat local minimum is affected by the noise intensity. Due to the extra randomness from loss weights sampling, the RLW method can provide a stronger noise (i.e. a larger r) than FW (referred to Appendix B.3). Hence RLW can better escape sharp local minima and converge to a flatter local minimum than FW, resulting in better generalization performance.\n\n\nEXPERIMENTS\n\nIn this section, we empirically evaluate the proposed RLW method by conducting experiments on six computer vision datasets (i.e., NYUv2, CityScapes, CelebA, PASCAL-Context, Office-31, and Office-Home) and four multilingual problems from the XTREME benchmark (Hu et al., 2020). Due to page limit, experimental results of the CityScapes, CelebA, Office-31, Office-Home datasets and two multilingual problems are put in Appendix C.\n\n\nDATASETS\n\nThe NYUv2 dataset (Silberman et al., 2012) is an indoor scene understanding dataset, which consists of video sequences recorded by the RGB and Depth cameras in the Microsoft Kinect. It contains 795 and 654 images with ground-truths for training and validation, respectively. This dataset includes three tasks: 13-class semantic segmentation, depth estimation, and surface normal prediction.\n\nThe PASCAL-Context dataset (Mottaghi et al., 2014) is an annotation extension of the PASCAL VOC 2010 challenge. It contains 10,103 images, which are divided into two parts: 4,998 for training and 5,105 for validation. We consider two tasks with annotations in this dataset: 21-class semantic segmentation and 7-class human part segmentation. By following (Maninis et al., 2019), we generate two additional tasks, including the saliency estimation and surface normal estimation tasks where their ground-truth labels are computed by the label distillation using pretrained state-of-theart models (Bansal et al., 2017;Chen et al., 2018a).\n\nThe XTREME benchmark (Hu et al., 2020) is a large-scale multilingual multi-task benchmark for cross-lingual generalization evaluation, which covers fifty languages and contains nine tasks. We conduct experiments on four tasks containing Named Entity Recognition (NER), Part-Of-Speech (POS) tagging, Natural Language Inference (NIL), and Paraphrase Identification (PI) from this benchmark. On each task, we construct a multilingual problem by choosing the four languages with the largest number of data. The more details are provided in Appendix C.6.\n\n\nIMPLEMENTATION DETAILS\n\nThe network architecture used adopt the hard-parameter sharing pattern (Caruana, 1993), which shares bottom layers of the network for all tasks and uses separate top layers for each task. Other architectures with more parameter sharing manners are provided in Section 5.7. The implementation details on each dataset are introduced in the following.\n\nFor the NYUv2 dataset, the DeepLabV3+ architecture (Chen et al., 2018a) is used. Specifically, a ResNet-50 network pretrained on the ImageNet dataset with dilated convolutions (Yu et al., 2017) is used as a shared encoder among tasks and the Atrous Spatial Pyramid Pooling (ASPP) (Chen et al., 2018a) module is used as task-specific head for each task. Input images are resized to 288 \u00d7 384. The Adam optimizer (Kingma & Ba, 2015) with the learning rate as 10 \u22124 and the weight decay as 10 \u22125 is used for training and the batch size is set to 8. We use the cross-entropy loss, L 1 loss and cosine loss as the loss function of the semantic segmentation, depth estimation and surface normal prediction tasks, respectively. For the PASCAL-Context dataset, the network architecture is similar to that on NYUv2 dataset with a shallower ResNet-18 network used as the shared encoder due to constraints of computing resources. All input images are resized to 512 \u00d7 512. The Adam optimizer with both the learning rate and weight decay as 10 \u22124 is applied for training and the batch size is set to 12. The cross-entropy loss is used for two segmentation tasks and saliency estimation task, while the normal estimation task uses the L 1 loss. For each multilingual problem in the XTREME benchmark, a pretrained multilingual BERT (mBERT) model (Devlin et al., 2019) implemented via the open source transformers library (Wolf et al., 2020) is used as the shared encoder among languages and a fully connected layer is used as the language-specific output layer for each language. The Adam optimizer with the learning rate as 2 \u00d7 10 \u22125 and the weight decay as 10 \u22128 is used for training and the batch size is set to 32. The cross-entropy loss is used for the four multilingual problems.\n\n\nEVALUATION METRIC\n\nTo measure the performance of MTL models in a scalar metric, for homogeneous MTL problems (e.g., the Office-31 dataset) which contain tasks of the same type such as the classification task, we directly average the performance metrics among tasks. For heterogeneous MTL problems (e.g., the NYUv2 dataset) that contain tasks of different types, by following (Maninis et al., 2019; Vandenhende et al., 2021), we compute the average of the relative improvement over the EW method on each metric of each task as\n\u2206 p = 100% \u00d7 1 T T t=1 1 N t Nt n=1 (\u22121) pt,n (M t,n \u2212 M EW t,n ) M EW t,n ,\nwhere N t denotes the number of metrics in task t, M t,n denotes the performance of a task balancing strategy for the nth metric in task t, M EW t,n is defined similarly for the EW strategy, and p t,n is set to 1 if a higher value indicates better performance for the nth metric in task t and otherwise 0.\n\n\nRESULTS ON THE NYUV2 DATASET\n\nThe results on the NYUv2 validation dataset are shown in Table 1. It is noticeable that the proposed RLW strategy can achieve comparable performance with SOTA baseline methods. Firstly, RLW with six weight distributions can always outperform EW, which implies that training in a doubly stochastic manner can have a better generalization ability. Secondly, RLW can achieve a balanced improvement on all tasks. That is, RLW has comparable or better performance on each metric in each task when compared with EW, resulting in a large \u2206 p . Different from RLW, many baseline methods achieve unbalanced performance on all the tasks. For example, IMTL significantly outperforms other methods on the normal prediction task but has unsatisfactory performance on the other two tasks. Hence, this can be one advantage of the proposed RLW strategy since MTL aims to improve the generalization performance of each task as much as possible. Thirdly, RLW with some distributions (i.e., \"constrained Bernoulli\" and \"Normal\") can improve the generalization performance by more than 1%, which is significantly better than baseline methods. Even, RLW with the constrained Bernoulli distribution can entirely dominate not only the EW method but also some baseline methods such as GradNorm, UW, DWA, and GradDrop, on each task, which demonstrates the effectiveness of the RLW method.\n\nMoreover, we compare the average time of training one epoch for each loss weighting strategy with the same batch size (i.e., 8) on a single NVIDIA GeForce RTX 3090 GPU. The relative training speed of each method over the EW method is reported as \u2206 t in Table 1. Noticeably, the proposed RLW strategy is as computationally efficient as EW, while some baseline methods are computeintensive. For example, PCGrad and GradVac take about twice the time of EW for each epoch because of computing the gradients of parameters. MGDA spends a lot of time to solve a complex quadratic programming problem. Furthermore, \u2206 t of those baseline methods will increase as the network becomes deeper, while the proposed RLW strategy is architecture-agnostic and always as efficient as EW.\n\nBy combining the above analysis, we think that the proposed RLW method is an effective and efficient loss weighting strategy for MTL.\n\n\nRESULTS ON THE PASCAL-CONTEXT DATASET\n\nThe results on the PASCAL-Context validation dataset are shown in Table 2. The empirical observations are similar to those on the NYUv2 dataset. Specifically, RLW with different distributions can outperform EW, which means RLW has a better generalization ability. Most baseline methods have unsatisfactory performance on this dataset and the best baseline, i.e., MGDA, achieves the largest \u2206 p of 0.18%. Thus, RLW outperforms many baseline methods. Moreover, RLW with the constrained Bernoulli distribution achieves the highest improvement of 0.46%. Furthermore, RLW does achieve more balanced improvement than some baseline methods. For example, GradNorm performs not so good on the saliency estimation task, leading to the lowest \u2206 p . Although IMTL significantly improves the performance of the surface normal estimation task, it performs unsatisfactorily on the other tasks especially the semantic segmentation task. Moreover, the relative training speed of each method over the EW method is similar to the NYUv2 dataset and hence we omit it in Table 2.   We study four multilingual problems from the XTREME benchmark (Hu et al., 2020) and show experimental results of POS and PI in Table 3. Due to the page limit, the results of NLI and NER are placed in Table 12 in the Appendix. Different from heterogeneous MTL problems on the NYUv2 and PASCAL-Context datasets, in these multilingual problems, each language has its own input data, which is usually called homogeneous MTL problems (Zhang & Yang, 2021). According to the results in Tables 3, RLW with diverse distributions still outperforms EW in all the two multilingual problems, which further shows the effectiveness of RLW on different type of MTL problem. Besides, RLW achieves comparable and even better performance than those baseline methods. For example, on the POS multilingual problem, RLW has the highest average F1 score and it achieves the best average accuracy on the PI problem.\n\n\nRLW WITH DIFFERENT ARCHITECTURES\n\nThe proposed RLW strategy can be seamlessly combined with other MTL network architectures without increasing additional computation cost. To see this, we combine the RLW strategy with three SOTA MTL architectures, i.e., cross-stitch network ( Table 4. Due to page limit, the results for the cross-stitch and NDDR-CNN networks are put in Tables 6 and 7 in the Appendix, respectively.\n\nAccording to the results, we have some observations. Firstly, compared with the performance when using the DMTL architecture (i.e., the results on Table 1), the performance of each loss weighting strategy with the deeper MTAN architecture is improved, especially on the surface normal estimation task, which is due to the larger capacity of the MTAN. Secondly, the RLW strategy with different distributions can outperform EW, which indicates the effectiveness of RLW with more advanced and deeper architectures. Thirdly, compared with baseline methods, the proposed RLW method can achieve competitive performance. For example, RLW with the random normal distribution can improve over EW by 0.76% and is among the top-3 methods.\n\n\nCONCLUSIONS\n\nIn this paper, we have unified eight state-of-the-art task balancing methods from the loss weighting perspective. Based on randomly sampling task weights from distributions, we propose a simple RLW strategy that can achieve comparable performance with state-of-the-art baselines. We analyze the convergence property of the proposed RLW method and the double stochasticity that can help escape sharp local minima. Finally, we provide a consistent and comparative comparison to show the effectiveness of the proposed RLW method on six computer vision datasets and four multilingual tasks from the XTREME benchmark. In our future studies, we will apply the proposed RLW method to more fields such as reinforcement learning. \n\n\nAPPENDIX A SUMMARY OF LOSS WEIGHTING STRATEGIES\n\nIn this section, we summarize the eight SOTA methods introduced in Section 2 from a perspective of loss weighting. We define G = [g 1 , \u00b7 \u00b7 \u00b7 , g T ] and u t = g t / g t , where g t = \u2207 \u03b8 t (D t ; \u03b8) denotes the gradient of t (D t ; \u03b8) with respect to \u03b8. Let R T + denote the non-negative subspace in the T -dimensional space R T , 1 denote (1, \u00b7 \u00b7 \u00b7 , 1), I denote an identity matrix, diag(a) denote a diagonal matrix with its principal diagonal a, [\u00b7] + be the ReLU operation, sgn(\u00b7) represent the sign function, and I(\u00b7) denote the indicator function. The summary of different methods is in Table 5. \nApproach Strategy Weight \u03bb (k-th iteration) Conv. * Not Grad. \u2020 EW ( 1 T , \u00b7 \u00b7 \u00b7 , 1 T ) Learning GradNorm min \u03bb T t=1 \u03bb t g t \u2212 gr \u03b1 t , where g = ( T t=1 \u03bb t g t )/T, r t =\u02dc t /( 1 T T j=1\u02dc j ) t = t / 0 t , and \u03b1 is pre-defined UW min \u03bb (\u03bb + 1 log(\u03bb )/2), s.t. \u03bb \u2208 R T + IMTL-L min \u03bb (\u03bb \u2212 1 log(\u03bb) ), s.t. \u03bb \u2208 R T + Solving MGDA arg min \u03bb \u03bb G 2 | \u03bb \u2208 \u2206 T Calculating DWA T \u00d7 softmax( k\u22121 / k\u22122 ) PCGrad 1(I + CN ),\nwhere N = diag(1/ g 1 , \u00b7 \u00b7 \u00b7 , 1/ g T ),\nC = [C pq ] T \u00d7T , C pp = 0, C pq = \u2212 g p + p <q C pp u p u q + GradDrop 1 s + (I \u2212 diag(s))M , where s \u2208 [0, 1] T is pre-defined, M = diag I(d > e) I(G > 0)+ diag I(d < e) I(G < 0), d = (1/2) 1 + 1G/( T t=1 g t ) , e \u223c Uniform(0, 1),G = sgn(\u03b8) G IMTL-G [1 \u2212 1\u03b1 2:T , \u03b1 2:T ], where \u03b1 2:T = g 1 N (DN ) \u22121 , N = 1 u 1 \u2212 U 2:T , D = 1 g 1 \u2212 G 2:T GradVac 1(I + CN ), where N = diag(1/ g 1 , \u00b7 \u00b7 \u00b7 , 1/ g T ), C = [C pq ] T \u00d7T , C pp = 0, C pq = sgn(\u03c6 pq \u2212 \u03c6 pq ) * \u011d p * A(\u03c6 pq , \u03c6 pq ) , A(\u03c6 pq , \u03c6 pq ) =\u03c6 pq \u221a 1\u2212(\u03c6pq) 2 \u2212\u03c6pq \u221a 1\u2212(\u03c6pq) 2 \u221a 1\u2212(\u03c6pq) 2 , \u03c6 pq = (\u011d p \u00b7 g q )/( \u011d p g q ), g p = g p + p <q C pp u p , \u03c6 pq = (1 \u2212 \u03b2)\u03c6 pq + \u03b2\u03c6 pq ,\n\u03b2 is pre-defined, and\u03c6 pq is initialized as 0\n\n\nSampling\n\nRLW ( Since t is c t -strongly convex w.r.t \u03b8, for L RLW (\u03b8) = \u03bb (\u03b8), for any two points \u03b8 1 and \u03b8 2 in R d , we have\n\u2207\u03bb (\u03b8 1 ) \u2212 \u2207\u03bb (\u03b8 2 ), \u03b8 1 \u2212 \u03b8 2 = T t=1 \u03bb t \u2207 t (\u03b8 1 ) \u2212 \u2207 t (\u03b8 2 ), \u03b8 1 \u2212 \u03b8 2 \u2265 T t=1 c t \u03bb t \u03b8 1 \u2212 \u03b8 2 2 .(5)\nSince\n0 \u2264 \u03bb t \u2264 1, we have T t=1 c t \u03bb t \u2265 c, where c = min 1\u2264t\u2264T {c t }.\nThen for any \u03bb, L RLW (\u03b8) is c-strongly convex.\n\nWith notations in Theorem 1, we have\n\u03b8 k+1 \u2212 \u03b8 * 2 = \u03b8 k \u2212 \u03b8 * \u2212 \u03b7\u2207\u03bb (D; \u03b8 k ) 2 = \u03b8 k \u2212 \u03b8 * 2 \u2212 2\u03b7 \u03b8 k \u2212 \u03b8 * , \u2207\u03bb (D; \u03b8 k ) + \u03b7 2 \u2207\u03bb (D; \u03b8 k ) 2 .\nNote that E \u03bb ED[\u2207\u03bb (D; \u03b8 k )] = \u2207\u00b5 (D; \u03b8 k ) and\nE \u03bb ED[ \u2207\u03bb (D; \u03b8 k ) 2 ] \u2264 E \u03bb ED[ \u03bb 2 \u2207 (D; \u03b8 k ) 2 ] \u2264 E \u03bb T t=1 \u03bb 2 t \u00b7 T t=1 \u03c3 2 t \u2264 T t=1 \u03c3 2 t ,\nwhere the first inequality is due to the Cauchy-Schwarz inequality and the third inequality is due to 0 \u2264 \u03bb t \u2264 1. Then, by defining \u03ba = T t=1 \u03c3 2 t , we obtain\nE \u03bb ED[ \u03b8 k+1 \u2212 \u03b8 * 2 ] \u2264 \u03b8 k \u2212 \u03b8 * 2 \u2212 2\u03b7 \u03b8 k \u2212 \u03b8 * , \u2207\u00b5 (\u03b8 k ) + \u03b7 2 \u03ba \u2264 (1 \u2212 2\u03b7c) \u03b8 k \u2212 \u03b8 * 2 + \u03b7 2 \u03ba.(6)\nIf 1 \u2212 2\u03b7c > 0, we recursively apply the inequality (6) over the first k iterations and we can obtain\nE[ \u03b8 k+1 \u2212 \u03b8 * 2 ] \u2264 (1 \u2212 2\u03b7c) k \u03b8 0 \u2212 \u03b8 * 2 + k\u22121 j=0 (1 \u2212 2\u03b7c) j \u03b7 2 \u03ba \u2264 (1 \u2212 2\u03b7c) k \u03b8 0 \u2212 \u03b8 * 2 + \u03b7\u03ba 2c .\nThus the inequality (4) holds if \u00b5 \u2264 1 2c . According to inequality (6), the minimal value of a quadratic function g \u03b5 (\u03b7) = (1 \u2212 2\u03b7c)\u03b5 + \u03b7 2 \u03ba is achieved at \u03b7 * = \u03b5c \u03ba . By setting \u03b8 0 \u2212 \u03b8 * 2 = \u03b5 0 , we have\nE[ \u03b8 k+1 \u2212 \u03b8 * 2 ] \u2264 g \u03b8 k \u2212\u03b8 * 2 (\u03b7 * ) = (1 \u2212 2 \u03b8 k \u2212 \u03b8 * 2 c 2 \u03ba ) \u03b8 k \u2212 \u03b8 * 2 \u2264 (1 \u2212 2\u03b5c 2 \u03ba ) \u03b8 k \u2212 \u03b8 * 2 \u2264 (1 \u2212 2\u03b5c 2 \u03ba ) k \u03b5 0 . Then if E[ \u03b8 k+1 \u2212 \u03b8 * 2 ] \u2265 \u03b5, we have \u03b5 \u2264 (1 \u2212 2\u03b5c 2 \u03ba ) k \u03b5 0 . Therefore, k \u2264 \u03ba 2\u03b5c 2 log \u03b50 \u03b5 .\n\nB.2 PROOF OF THEOREM 2\n\nSince \u03d5 k = \u03b8 k \u2212 \u03b7\u2207\u00b5 (\u03b8 k ) and \u03b8 k+1 = \u03b8 k \u2212 \u03b7(\u2207\u00b5 (\u03b8 k ) + \u03be k ), we have\n\u03d5 k+1 = \u03d5 k \u2212 \u03b7\u03be k \u2212 \u2207\u00b5 (\u03d5 k \u2212 \u03b7\u03be k ).\nSince the loss function t (\u03b8) of task t is c t -one point strongly convex w.r.t a given point \u03b8 * after convolved with noise \u03be, similar to inequality (5), we have\n\u2207E \u03be [\u00b5 (\u03d5 \u2212 \u03b7\u03be)], \u03d5 \u2212 \u03b8 * \u2265 c \u03d5 \u2212 \u03b8 * 2 ,\nwhere c = min 1\u2264t\u2264T {c t }. Since \u2207 t (\u03b8) is M t -Lipschitz continuous, for any two points \u03b8 1 and \u03b8 2 in R d , we have\n\u2207\u00b5 (\u03b8 1 ) \u2212 \u2207\u00b5 (\u03b8 2 ) = T t=1 \u00b5 t \u2207 t (\u03b8 1 ) \u2212 \u2207 t (\u03b8 2 ) \u2264 T t=1 M t \u00b5 t \u03b8 1 \u2212 \u03b8 2 .(7)\nNote that\nT t=1 M t \u00b5 t \u2264 M , where M = max 1\u2264t\u2264T {M t }. Therefore, \u2207\u00b5 (\u03b8) is M -Lipschitz continuous. Then we can get E[ \u03d5 k+1 \u2212 \u03b8 * 2 ] = E[ \u03d5 k \u2212 \u03b7\u03be k \u2212 \u2207\u00b5 (\u03d5 k \u2212 \u03b7\u03be k ) \u2212 \u03b8 * 2 ] \u2264 E[ \u03d5 k \u2212 \u03b8 * 2 + \u03b7\u03be k 2 + \u2207\u00b5 (\u03d5 k \u2212 \u03b7\u03be k ) 2 \u2212 2 \u03d5 k \u2212 \u03b8 * , \u03b7\u03be k \u2212 2 \u03d5 k \u2212 \u03b8 * , \u2207\u00b5 (\u03d5 k \u2212 \u03b7\u03be k ) + 2 \u2207\u00b5 (\u03d5 k \u2212 \u03b7\u03be k ), \u03b7\u03be k ] \u2264 \u03d5 k \u2212 \u03b8 * 2 + \u03b7 2 r 2 + E[ \u2207\u00b5 (\u03d5 k \u2212 \u03b7\u03be k ) 2 ] \u2212 2\u03b7c \u03d5 k \u2212 \u03b8 * 2 + 2E[ \u2207\u00b5 (\u03d5 k \u2212 \u03b7\u03be k ) \u2212 \u2207\u00b5 (\u03d5 k ), \u03b7\u03be k ] \u2264 (1 \u2212 2\u03b7c) \u03d5 k \u2212 \u03b8 * 2 + \u03b7 2 r 2 + \u03b7 2 E[ M (\u03b8 * \u2212 (\u03d5 k \u2212 \u03b7\u03be k )) 2 ] + 2\u03b7 3 r 2 M \u2264 (1 \u2212 2\u03b7c) \u03d5 k \u2212 \u03b8 * 2 + \u03b7 2 r 2 + \u03b7 2 M 2 \u03d5 k \u2212 \u03b8 * 2 + E[ \u03d5 k \u2212 \u03b8 * , \u03b7\u03be k ] + \u03b7 2 M 2 E[ \u03b7\u03be k 2 ] + 2\u03b7 3 r 2 M \u2264 (1 \u2212 2\u03b7c + \u03b7 2 M 2 ) \u03d5 k \u2212 \u03b8 * 2 + \u03b7 2 r 2 (1 + \u03b7M ) 2 ,\nwhere the second inequality is due to the convexity assumption and E[\u03be k ] = 0, the third and forth inequalities are due to the Lipschitz continuity. We set \u03c1 = 2\u03b7c \u2212 \u03b7 2 M 2 and \u03b2 = \u03b7 2 r 2 (1 + \u03b7M ) 2 . If \u03c1 \u2265 0, we have \u03b7 \u2264 c M 2 , then we get\nE[ \u03d5 k+1 \u2212 \u03b8 * 2 ] \u2264 (1 \u2212 \u03c1) \u03d5 k \u2212 \u03b8 * 2 + \u03b2 \u2264 (1 \u2212 \u03c1) k \u03d5 0 \u2212 \u03b8 * 2 + k\u22121 j=0 (1 \u2212 \u03c1) j \u03b2 \u2264 (1 \u2212 \u03c1) k \u03d5 0 \u2212 \u03b8 * 2 + \u03b2 \u03c1 . So if k \u2264 1 \u03c1 log \u03c1\u03b50 \u03b2 , we have E[ \u03d5 k+1 \u2212 \u03b8 * 2 ] \u2264 2\u03b2 \u03c1 .\nThen by the Markov inequality, with probability at least 1 \u2212 \u03b4, we have\n\u03d5 K \u2212 \u03b8 * 2 \u2264 2\u03b2 \u03c1\u03b4 .\n\nB.3 NOISE UPPER BOUND\n\nSuppose the noise produced by the FW method is\u03be = \u2207\u00b5 (D; \u03b8) \u2212 \u2207\u00b5 (D; \u03b8) and \u03be 2 \u2264 R. The noise produced by the RLW method is \u03be = \u2207\u03bb (D; \u03b8) \u2212 \u2207\u00b5 (D; \u03b8) . We have\n\u03be 2 = \u2207\u03bb (D; \u03b8) \u2212 \u2207\u00b5 (D; \u03b8) + \u2207\u00b5 (D; \u03b8) \u2212 \u2207\u00b5 (D; \u03b8) 2 = (\u03bb \u2212 \u00b5 )\u2207 (D; \u03b8) 2 + 2 (\u03bb \u2212 \u00b5 ) (D; \u03b8),\u03be + \u03be 2 .\nBecause the noise\u03be can be any direction, there exists a constant s > 0 such that \u03be 2 = R and \u03be = s(\u03bb \u2212 \u00b5 )\u2207 (D; \u03b8). Then, we have \u03be 2 \u2264 (1 + 2s) \u03bb \u2212 \u00b5 2 \u2207 (D; \u03b8) 2 + R. Thus, the norm of the noise provided by the RLW method has a larger least upper bound than FW.\n\n\nB.4 CONVERGENCE WITH DECREASING LEARNING RATE\n\nIn the following theorem, we show the convergence analysis and generalization bound of the RLW method under the strong convexity case with decreasing step sizes.\n\nTheorem 3. Suppose the loss function t (\u03b8) of task t is c t -strongly convex and Assumption 1 holds. Then if we choose \u03b7 k = \u03b1/k and \u03b1 > 1/2c, we have\nE[ \u03b8 k \u2212 \u03b8 * 2 ] \u2264 max{2\u03b1 2 \u03ba(2\u03b1c \u2212 1) \u22121 , \u03b8 0 \u2212 \u03b8 * 2 } k ,\nwhere \u03ba = T t=1 \u03c3 2 t and c = min 1\u2264t\u2264T {c t }. Moreover, by defining the optimal loss function as L RLW (\u03b8 * ), we can obtain the following generalization bound as\nE[ L RLW (\u03b8 k ) \u2212 L RLW (\u03b8 * ) ] \u2264 max{\u03b1 2 L\u03ba(2\u03b1c \u2212 1) \u22121 , L \u03b8 0 \u2212 \u03b8 * 2 } k , where L = max 1\u2264t\u2264T {L t }.\nProof. According to inequality (6), by setting \u03b7 = \u03b1/k, we have\nE[ \u03b8 k+1 \u2212 \u03b8 * 2 ] \u2264 (1 \u2212 2\u03b1c k ) \u03b8 k \u2212 \u03b8 * 2 + \u03b1 2 \u03ba k 2 .\nThen by induction we can get\nE[ \u03b8 k+1 \u2212 \u03b8 * 2 ] \u2264 Q k . where Q = max{2\u03b1 2 \u03ba(2\u03b1c \u2212 1) \u22121 , \u03b8 0 \u2212 \u03b8 * 2 }.\nSince t (\u03b8) is L t -Lipschitz continuous, similar to inequality (7), for any two points \u03b8 1 and \u03b8 2 in R d , we have\n\u2207L RLW (\u03b8 1 ) \u2212 \u2207L RLW (\u03b8 2 ) \u2264 T t=1 L t \u00b5 t \u03b8 1 \u2212 \u03b8 2 . Therefore, L RLW (\u03b8) is L-Lipschitz continuous, where L = max 1\u2264t\u2264T {L t }.\nThen we can get\nE[ L RLW (\u03b8 k ) \u2212 L RLW (\u03b8 * ) ] \u2264 L 2 E[ \u03b8 k \u2212 \u03b8 * 2 ] \u2264 LQ 2k ,\nwhere we reach the conclusion.\n\n\nC ADDITIONAL EXPERIMENTAL RESULTS\n\n\nC.1 EXPERIMENTS ON CONVERGENCE\n\nIn Figure 1, we empirically compare the convergence speed of the EW and RLW methods in terms of the performance curve on both the NYUv2 and CelebA validation datasets.\n\nOn the NYUv2 dataset with three tasks, the performance curves of the RLW method with three different distributions are both consistent with the EW method, which indicates the RLW method has a similar convergence property to the EW method. As the number of tasks increases, i.e., on the CelebA dataset with forty tasks, we find that the RLW method with the Normal and Bernoulli distributions still converges as fast as the EW method, while the RLW method with the constrained Bernoulli distribution converges slower. One reason for this phenomenon is that only one task is used for updating the parameters in each training iteration.\n\nIn summary, the proposed RLW strategy combined with all the distributions except the constrained Bernoulli distribution has similar training efficiency to the EW method.  Table 4). Firstly, the performance of each loss weighting strategy with the deeper NDDR-CNN architecture is improved on the three tasks, while only the surface normal estimation task can be improved with the cross-stitch network. Secondly, the RLW strategy significantly outperform EW on both architectures. Thirdly, compared with the baseline methods, RLW can achieve comparable or even better performance than all the baseline methods except IMTL on both two architectures. For example, RLW with the constrained Bernoulli distribution has an improvement of 1.79% on the cross-stitch architecture, which is slightly lower than the best performed method, IMTL. Besides, RLW with the Normal distribution is among the top-2 methods based on the NDDR-CNN network. \n\n\nC.3 RESULTS ON THE CITYSCAPES DATASET\n\nDataset The CityScapes dataset (Cordts et al., 2016) is a large-scale urban street scenes understanding dataset and it is comprised of a diverse set of stereo video sequences recorded from 50 different cities in fine weather during the daytime. It contains 2,975 and 500 annotated images for training and validation, respectively. This dataset includes two tasks: 7-class semantic segmentation and depth estimation. Implementation Details The network architecture and optimizer on the CityScapes dataset are the same as those of the NYUv2 dataset. We resize all the images to 128 \u00d7 256 and set the batch size as 64 for training. The Adam optimizer (Kingma & Ba, 2015) with the learning rate as 10 \u22124 and the weight decay as 10 \u22125 is used. We use the cross-entropy loss and L 1 loss for the semantic segmentation and depth estimation tasks, respectively.\n\n\nResults\n\nAccording to the results shown in Table 8, we can see that all the loss weighting strategies except the GradDrop method outperform EW. Especially, the PCGrad and MGDA methods can achieve a significant improvement of 2.79% and 2.60% in terms of \u2206 p , respectively. Compared with those baseline methods, the RLW strategy not only outperforms EW by using the six different distributions but also achieves comparable performance with those baseline methods. For example, RLW with the Dirichlet distribution can improve over EW by 1.95% and is among the top-3 methods. Implementation Details We use the ResNet-18 network as a sharing feature extractor and a fully connected layer with two output units as a task-specific head for each task. All the input images are resized to 64 \u00d7 64. The Adam optimizer with the learning rate as 10 \u22123 is applied for training and the batch size is set to 512. The cross-entropy loss is used for the 40 tasks.\n\nResults Since the number of tasks is large, we only report the average classification accuracy on the forty tasks in the CelebA dataset and the results are shown in Table 9. The proposed RLW strategy slightly outperforms EW and performs comparable with all the baseline methods.  (Cl), product images (Pr), and real-world images (Rw). It has 15,500 labeled images in total and each domain contains 65 classes. We divide the entire data in the same proportion as Office-31. For both two datasets, we consider the multi-class classification problem on each domain as a task. Similar to multilingual tasks from the XTREME benchmark, each task in both Office-31 and Office-Home datasets has its own input images, thus MTL problems in these two datasets are homogeneous MTL problems (Zhang & Yang, 2021).\n\nImplementation Details We use the same configuration for both Office-31 and Office-Home datasets. Specifically, the ResNet-18 network pretrained on the ImageNet dataset is used as a sharing backbone among tasks and a fully connected layer is applied as a task-specific output layer for each task. All the input images are resized to 224 \u00d7 224. We use the Adam optimizer with the learning rate as 10 \u22123 and set the batch size to 64 for training. The cross-entropy loss is applied for all tasks of both two datasets. Results According to the results on Office-31 and Office-Home datasets shown in Table 10, it is noticeable that RLW with six different types of distributions outperforms EW on both datasets. In addition, the RLW method performs better than most baseline methods. Moreover, the RLW method with the constrained Bernoulli distribution achieves the best average classification accuracy on both Office-31 and Office-Home datasets, and this strategy achieve 100% accuracy on the DSLR domain in the Office-31 dataset.  (Conneau et al., 2018) are used for training and evaluation, respectively. For the NER, NIL, and PI tasks, the same four languages including English (en), Mandarin (zh), German (de), and Spanish (es), are used. For the POS task, Telugu (te) and Vietnamese (vi) instead of German and Spanish are used. The numbers of data for all the tasks are summarized in Table 11. \n\n\nResults\n\nThe results on the NLI and NER multilingual tasks are shown in Table 12. The empirical observations are similar to those on the POS and PI tasks shown in Table 3. Specifically, the RLW method with all the distributions outperforms EW in the two multilingual problems. In addition, RLW achieves comparable and even better performance than those baseline methods. For example, on the NLI multilingual problem, RLW achieve the highest average accuracy. \n\n\n, Uncertainty Weights (UW) (Kendall et al., 2018), MGDA (Sener & Koltun, 2018), Dynamic Weight Average (DWA) (Liu et al., 2019a), Projecting Conflicting Gradient (PCGrad) (Yu et al., 2020), Gradient sign Dropout (GradDrop) (Chen et al., 2020), Impartial Multi-Task Learning (IMTL) (Liu et al., 2021), and Gradient Vaccine (GradVac) (Wang et al., 2021).\n\n\nMisra et al., 2016), Multi-Task Attention Network (MTAN) (Liu et al., 2019a), and CNN with Neural Discriminative Dimensionality Reduction layer (NDDR-CNN) (Gao et al., 2019) and evaluate all the methods on the NYUv2 dataset. Experimental results when using the MTAN architecture are shown in\n\n\nours) f (\u03bb), where\u03bb \u223c p(\u03bb) and f is a normalization function\n\nFigure 1 :\n1Comparison on the convergence speed of EW and the proposed RLW strategy on the NYUv2 dataset (Left) and the CelebA dataset (Right), respectively.C.2 ADDITIONAL RESULTS OF RLW ON DIFFERENT ARCHITECTURESThe results of different loss weighting strategies with the cross-stitch and NDDR-CNN networks are put in Tables 6 and 7, respectively. The empirical observations are similar to those with the MTAN architecture (i.e.,\n\nC. 6\n6ADDITIONAL RESULTS ON XTREME BENCHMARK Datasets The datasets used in the NER, POS, and PI tasks are the Wikiann dataset (Pan et al., 2017), Universal Dependency v2.5 treebanks (Nivre et al., 2020), and PAWS-X dataset (Yang et al., 2019), respectively. For the NIL task, the MultiNLI dataset (Williams et al., 2018) and the XNLI dataset\n\nTable 1 :\n1Performance on the NYUv2 validation dataset with three tasks: 13-class semantic segmentation, depth estimation, and surface normal prediction. The best results for each task on each measure are highlighted in bold. \u2191 (\u2193) indicates that the higher (lower) the result, the better the performance.Weighting \nSegmentation \nDepth \nSurface Normal \n\n\u2206p\u2191 \n\u2206t\u2193 \nStrategy \nmIoU\u2191 Pix Acc\u2191 Abs Err\u2193 Rel Err\u2193 \nAngle Distance \nWithin t \u2022 \n\nMean\u2193 Median\u2193 11.25\u2191 22.5\u2191 \n30\u2191 \n\nEW \n53.91 \n75.56 \n0.3840 \n0.1567 \n23.6338 17.2451 \n34.94 60.65 71.81 +0.00 \n\u00d71.00 \nGradNorm \n53.81 \n75.35 \n0.3863 \n0.1556 \n23.6106 17.2565 \n34.98 60.58 71.76 \u22120.06 \n\u00d71.82 \nUW \n53.15 \n75.41 \n0.3817 \n0.1576 \n23.6487 17.2040 \n34.98 60.71 71.80 \u22120.24 \n\u00d71.01 \nMGDA \n53.66 \n75.37 \n0.3864 \n0.1610 \n23.4757 16.9912 \n35.44 61.17 72.16 \u22120.35 \n\u00d72.64 \nDWA \n53.33 \n75.42 \n0.3834 \n0.1556 \n23.5806 17.1242 \n35.18 60.88 71.91 +0.07 \u00d71.00 \nPCGrad \n53.34 \n75.43 \n0.3857 \n0.1600 \n23.2293 16.6966 \n36.09 61.80 72.66 +0.12 \n\u00d72.10 \nGradDrop \n53.80 \n75.56 \n0.3857 \n0.1587 \n23.8726 17.1406 \n35.10 60.72 71.60 \u22120.33 \n\u00d71.84 \nIMTL \n52.90 \n74.88 \n0.3883 \n0.1632 \n23.0534 16.5304 \n36.30 62.20 73.08 \u22120.35 \n\u00d71.82 \nGradVac \n53.52 \n75.43 \n0.3840 \n0.1559 \n23.2892 16.8601 \n35.67 61.53 72.46 +0.48 \n\u00d72.11 \n\nRLW (Uniform) \n54.09 \n75.78 \n0.3826 \n0.1563 \n23.6272 17.2711 \n34.73 60.67 71.87 +0.17 \n\n\u00d71.00 \n\nRLW (Normal) \n54.19 \n75.98 \n0.3789 \n0.1570 \n23.1984 16.7944 \n35.71 61.74 72.77 +1.02 \nRLW (Dirichlet) \n53.54 \n75.45 \n0.3834 \n0.1547 \n23.6392 17.0715 \n35.28 60.92 71.88 +0.27 \nRLW (Bernoulli) \n53.72 \n75.62 \n0.3850 \n0.1610 \n23.1413 16.6591 \n36.08 61.98 72.86 +0.28 \nRLW (constrained Bernoulli) \n54.32 \n75.78 \n0.3779 \n0.1533 \n23.2101 16.9354 \n35.41 61.44 72.58 +1.29 \nRLW (random Normal) \n54.08 \n75.77 \n0.3815 \n0.1581 \n23.5598 16.9577 \n35.53 61.20 72.13 +0.39 \n\n\n\nTable 2 :\n2Performance on the PASCAL-Context validation dataset with four tasks: 21-class semantic segmentation (abbreviated as SS), 7-class human parts segmentation (abbreviated as HPS), saliency estimation, and surface normal prediction. The best results for each task on each measure are highlighted in bold. \u2191 (\u2193) indicates that the higher (lower) the result, the better the performance.Weighting \nSS \nHPS \nSaliency \nSurface Normal \n\n\u2206 p \u2191 \nStrategy \nmIoU\u2191 mIoU\u2191 mIoU\u2191 maxF\u2191 \nAngle Distance \nWithin t \u2022 \n\nMean\u2193 RMSE\u2193 11.25\u2191 22.5\u2191 \n30\u2191 \n\nEW \n64.52 \n58.71 \n64.31 \n77.11 \n17.6444 26.1634 \n42.24 75.93 86.97 +0.00 \nGradNorm \n64.13 \n58.49 \n61.64 \n72.46 \n18.0455 26.4642 \n41.03 74.90 86.26 \u22121.94 \nUW \n63.72 \n59.13 \n64.47 \n77.26 \n17.4962 26.0463 \n42.64 76.48 87.35 +0.09 \nMGDA \n63.34 \n58.86 \n64.79 \n77.54 \n17.3070 25.8584 \n43.30 77.14 87.79 +0.18 \nDWA \n64.32 \n58.61 \n64.30 \n77.15 \n17.4065 25.9242 \n42.72 76.71 87.59 +0.14 \nPCGrad \n63.58 \n58.68 \n63.79 \n76.71 \n17.2376 25.8572 \n43.69 77.11 87.70 \u22120.08 \nGradDrop \n64.04 \n59.36 \n62.31 \n73.10 \n17.3246 25.8966 \n43.29 76.92 87.63 \u22120.58 \nIMTL \n62.67 \n58.35 \n62.92 \n73.21 \n16.8026 25.4852 \n45.02 78.49 88.65 \u22120.81 \nGradVac \n62.99 \n58.63 \n64.30 \n77.15 \n17.1852 25.7621 \n43.55 77.41 88.00 \u22120.10 \n\nRLW (Uniform) \n63.52 \n59.03 \n63.75 \n76.71 \n17.0261 25.6528 \n44.21 77.77 88.24 +0.27 \nRLW (Normal) \n64.14 \n58.43 \n64.05 \n76.86 \n17.1794 25.7734 \n43.69 77.31 87.91 +0.16 \nRLW (Dirichlet) \n63.97 \n58.88 \n64.30 \n77.19 \n17.2147 25.8093 \n43.67 77.33 87.89 +0.37 \nRLW (Bernoulli) \n64.34 \n58.35 \n64.28 \n77.03 \n17.3379 25.9016 \n43.18 76.93 87.66 +0.11 \nRLW (constrained Bernoulli) \n65.07 \n58.52 \n64.19 \n76.96 \n17.3377 25.9005 \n43.30 77.04 87.69 +0.46 \nRLW (random Normal) \n64.09 \n59.15 \n63.84 \n76.76 \n17.3860 25.9472 \n42.98 76.73 87.54 +0.16 \n\n\nTable 3 :\n3Performance on two multilingual problems, i.e. POS and PI from the XTREME benchmark. The best results for each language are highlighted in bold.Weighting \nPOS (F1 Score) \nPI (Accuracy) \n\nStrategy \nen \nzh \nte \nvi \nAvg \nen \nzh \nde \nes \nAvg \n\nEW \n95.02 88.89 91.16 87.11 90.55 94.09 84.59 89.44 90.24 89.59 \nGradNorm \n95.01 88.91 91.88 87.06 90.71 94.39 85.94 90.99 91.44 90.69 \nUW \n94.89 88.77 90.96 87.12 90.44 93.74 85.44 90.24 91.29 90.18 \nMGDA \n95.08 88.97 92.35 87.12 90.88 94.64 84.99 89.84 90.89 90.09 \nDWA \n95.02 89.03 91.87 87.27 90.80 94.69 84.99 89.49 91.44 90.15 \nPCGrad \n94.85 88.42 90.72 86.71 90.18 94.19 85.49 89.09 91.24 90.00 \nGradDrop \n95.08 89.06 90.65 87.17 90.49 94.29 84.44 89.69 90.94 89.84 \nIMTL \n94.87 88.80 92.18 86.72 90.65 94.54 84.79 90.14 90.99 90.12 \nGradVac \n94.87 88.41 90.62 86.47 90.09 94.29 84.94 89.19 90.89 89.83 \n\nRLW (Uniform) \n95.06 89.00 92.31 86.93 90.83 94.69 85.79 90.29 91.94 90.68 \nRLW (Normal) \n95.01 88.87 92.86 86.85 90.90 94.39 85.34 90.04 91.84 90.40 \nRLW (Dirichlet) \n95.16 88.96 91.64 87.24 90.75 94.24 84.39 89.99 90.99 89.90 \nRLW (Bernoulli) \n95.13 89.10 91.13 87.03 90.60 95.09 85.89 90.24 91.99 90.80 \nRLW (constrained Bernoulli) 94.98 89.05 92.33 86.87 90.81 94.69 85.49 90.19 90.99 90.34 \nRLW (random Normal) \n95.07 89.00 91.10 87.25 90.60 94.79 84.94 89.54 90.99 90.07 \n\n\n\nTable 4 :\n4Performance under the MTAN architecture on the NYUv2 validation dataset with three tasks: 13-class semantic segmentation, depth estimation, and surface normal prediction. The best results for each task on each measure are highlighted in bold. \u2191 (\u2193) indicates that the higher (lower) the result, the better the performance.Weighting \nSegmentation \nDepth \nSurface Normal \n\n\u2206 p \u2191 \nStrategy \nmIoU\u2191 Pix Acc\u2191 Abs Err\u2193 Rel Err\u2193 \nAngle Distance \nWithin t \u2022 \n\nMean\u2193 Median\u2193 11.25\u2191 22.5\u2191 \n30\u2191 \n\nEW \n53.77 \n75.79 \n0.3789 \n0.1546 \n22.8344 16.6021 \n36.37 62.45 73.32 +0.00 \nGradNorm \n54.75 \n75.89 \n0.3797 \n0.1537 \n22.6295 16.2829 \n37.09 63.12 73.87 +0.83 \nUW \n54.80 \n75.97 \n0.3767 \n0.1536 \n22.6744 16.3050 \n36.90 63.14 73.87 +0.95 \nMGDA \n53.94 \n75.97 \n0.3788 \n0.1573 \n22.6157 16.1395 \n37.24 63.38 73.94 +0.37 \nDWA \n53.71 \n75.72 \n0.3801 \n0.1539 \n23.1560 16.8354 \n35.95 61.85 72.79 \u22120.39 \nPCGrad \n53.83 \n75.70 \n0.3823 \n0.1568 \n22.9481 16.3528 \n37.05 62.76 73.37 \u22120.16 \nGradDrop \n53.83 \n75.85 \n0.3754 \n0.1530 \n22.7846 16.4156 \n36.77 62.74 73.51 +0.57 \nIMTL \n53.39 \n75.20 \n0.3807 \n0.1549 \n22.2571 15.8336 \n38.04 64.11 74.59 +0.72 \nGradVac \n54.52 \n75.68 \n0.3755 \n0.1546 \n22.9389 16.5692 \n36.48 62.33 73.20 +0.34 \n\nRLW (Uniform) \n54.27 \n75.51 \n0.3820 \n0.1548 \n22.9640 16.4375 \n36.89 62.65 73.29 +0.08 \nRLW (Normal) \n53.70 \n75.62 \n0.3791 \n0.1551 \n22.8395 16.3328 \n37.05 62.82 73.44 +0.16 \nRLW (Dirichlet) \n53.36 \n75.08 \n0.3778 \n0.1514 \n22.8803 16.3579 \n36.99 62.80 73.40 +0.35 \nRLW (Bernoulli) \n53.46 \n75.74 \n0.3820 \n0.1517 \n22.5642 16.2013 \n37.21 63.29 73.96 +0.61 \nRLW (constrained Bernoulli) \n54.11 \n75.47 \n0.3821 \n0.1558 \n22.7969 16.2204 \n36.93 62.90 73.56 +0.10 \nRLW (random Normal) \n54.10 \n75.77 \n0.3802 \n0.1554 \n22.4400 16.0336 \n37.74 63.68 74.17 +0.76 \n\n\n\n\nurban scene understanding. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 3213-3223, 2016. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4171-4186, 2019. Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 7482-7491, 2018. Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings of the 3rd International Conference on Learning Representations, 2015. Liyang Liu, Yi Li, Zhanghui Kuang, Jing-Hao Xue, Yimin Chen, Wenming Yang, Qingmin Liao, and Wayne Zhang. Towards impartial multi-task learning. In Proceedings of the 9th International Conference on Learning Representations, 2021. Shikun Liu, Edward Johns, and Andrew J. Davison. End-to-end multi-task learning with attention. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. 1871-1880, 2019a. Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision, 2015b. Adina Williams, Nikita Nangia, and Samuel R. Bowman. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 1112-1122, 2018. Yu Zhang and Qiang Yang. A survey on multi-task learning. IEEE Transactions on Knowledge and Data Engineering, 2021.Daxiang Dong, Hua Wu, Wei He, Dianhai Yu, and Haifeng Wang. Multi-task learning for multiple \nlanguage translation. In Proceedings of the 53rd Annual Meeting of the Association for Compu-\ntational Linguistics and the 7th International Joint Conference on Natural Language Processing \nof the Asian Federation of Natural Language Processing, pp. 1723-1732, 2015. \n\nYuan Gao, Jiayi Ma, Mingbo Zhao, Wei Liu, and Alan L Yuille. Nddr-cnn: Layerwise feature \nfusing in multi-task cnns by neural discriminative dimensionality reduction. In Proceedings of \nthe IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3205-3214, 2019. \n\nMoritz Hardt, Ben Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic \ngradient descent. In Processing of the International Conference on Machine Learning, pp. 1225-\n1234. PMLR, 2016. \n\nJunjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and Melvin Johnson. \nXTREME: A massively multilingual multi-task benchmark for evaluating cross-lingual generali-\nsation. In Proceedings of the 37th International Conference on Machine Learning, volume 119, \npp. 4411-4421. PMLR, 2020. \n\nBobby Kleinberg, Yuanzhi Li, and Yang Yuan. An alternative view: When does sgd escape local \nminima? In Processing of the International Conference on Machine Learning, pp. 2698-2707. \nPMLR, 2018. \n\nXiaodong Liu, Jianfeng Gao, Xiaodong He, Li Deng, Kevin Duh, and Ye-Yi Wang. Representation \nlearning using multi-task deep neural networks for semantic classification and information re-\ntrieval. In Proceedings of the 2015 Conference of the North American Chapter of the Association \nfor Computational Linguistics: Human Language Technologies, pp. 912-921, 2015a. \n\nXiaodong Liu, Pengcheng He, Weizhu Chen, and Jianfeng Gao. Multi-task deep neural networks \nfor natural language understanding. In Proceedings of the 57th Conference of the Association for \nComputational Linguistics, pp. 4487-4496, 2019b. \n\nKevis-Kokitsi Maninis, Ilija Radosavovic, and Iasonas Kokkinos. Attentive single-tasking of multi-\nple tasks. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pp. \n1851-1860, 2019. \n\nIshan Misra, Abhinav Shrivastava, Abhinav Gupta, and Martial Hebert. Cross-stitch networks for \nmulti-task learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern \nRecognition, pp. 3994-4003, 2016. \nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, \nPierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick \nvon Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, \nMariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural \nlanguage processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural \nLanguage Processing, pp. 38-45, 2020. \n\nYinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. PAWS-X: A cross-lingual adversar-\nial dataset for paraphrase identification. In Proceedings of the 2019 Conference on Empirical \nMethods in Natural Language Processing and the 9th International Joint Conference on Natural \nLanguage Processing, pp. 3685-3690, 2019. \n\nFisher Yu, Vladlen Koltun, and Thomas A. Funkhouser. Dilated residual networks. In Proceedings \nof the IEEE Conference on Computer Vision and Pattern Recognition, pp. 636-644, 2017. \n\nTianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine, Karol Hausman, and Chelsea Finn. \nGradient surgery for multi-task learning. In Proceedings of the 33rd Advances in Neural Infor-\nmation Processing Systems, 2020. \n\n\n\nTable 5 :\n5A summary of SOTA weighting strategies from a perspective of loss weighing.  *  means \nwhether a convergence analysis (abbreviated as Conv.) is provided in the original paper.  \u2020 denotes \nthat the corresponding weighting strategy needs not to compute gradients (abbreviated as Not Grad.) \nfor generating loss weights \u03bb. \n\n\n\nTable 6 :\n6Performance of different loss weighting strategies with the cross-stitch architecture on theNYUv2 validation dataset with three tasks: 13-class semantic segmentation, depth estimation, and \nsurface normal prediction. The best results for each task on each measure are highlighted in bold. \u2191 \n(\u2193) means the higher (lower) the result, the better the performance. \n\nWeighting \nSegmentation \nDepth \nSurface Normal \n\n\u2206 p \u2191 \nStrategy \nmIoU\u2191 Pix Acc\u2191 Abs Err\u2193 Rel Err\u2193 \nAngle Distance \nWithin t \u2022 \n\nMean\u2193 Median\u2193 11.25\u2191 22.5\u2191 \n30\u2191 \n\nEW \n53.39 \n75.06 \n0.3822 \n0.1595 \n23.1939 16.6749 \n35.99 61.79 72.69 +0.00 \nGradNorm \n53.92 \n75.39 \n0.3833 \n0.1547 \n22.7461 16.2463 \n37.15 63.02 73.57 +1.42 \nUW \n53.88 \n75.76 \n0.3820 \n0.1587 \n23.1397 16.4221 \n36.61 62.30 72.91 +0.71 \nMGDA \n53.33 \n75.07 \n0.3877 \n0.1584 \n23.1588 16.6327 \n36.41 61.75 72.57 \u22120.05 \nDWA \n52.62 \n75.02 \n0.3801 \n0.1563 \n23.4577 16.7667 \n36.13 61.51 72.24 +0.02 \nPCGrad \n53.83 \n75.58 \n0.3853 \n0.1568 \n22.5621 16.0502 \n37.80 63.43 73.89 +1.45 \nGradDrop \n52.23 \n74.96 \n0.3855 \n0.1583 \n22.7940 15.9848 \n37.79 63.25 73.53 +0.56 \nIMTL \n54.16 \n75.83 \n0.3833 \n0.1571 \n22.3801 15.9137 \n37.81 63.97 74.46 +1.89 \nGradVac \n52.93 \n75.22 \n0.3871 \n0.1559 \n22.4499 15.8148 \n38.31 63.96 74.21 +1.42 \n\nRLW (Uniform) \n53.23 \n75.19 \n0.3870 \n0.1576 \n22.8859 16.3011 \n37.06 62.55 73.17 +0.53 \nRLW (Normal) \n53.34 \n75.32 \n0.3804 \n0.1577 \n22.9278 16.2227 \n37.25 62.68 73.27 +0.95 \nRLW (Dirichlet) \n52.86 \n75.30 \n0.3859 \n0.1604 \n22.9058 16.0335 \n37.66 62.98 73.31 +0.47 \nRLW (Bernoulli) \n53.44 \n75.33 \n0.3782 \n0.1558 \n22.8759 16.1796 \n37.27 62.79 73.29 +1.33 \nRLW (constrained Bernoulli) \n53.25 \n75.28 \n0.3819 \n0.1530 \n22.5622 15.9059 \n37.80 63.39 73.78 +1.79 \nRLW (random Normal) \n53.22 \n75.21 \n0.3861 \n0.1607 \n22.6981 15.8673 \n37.97 63.44 73.73 +0.79 \n\n\n\nTable 7 :\n7Performance of different loss weighting strategies with the NDDR-CNN architecture on the NYUv2 validation dataset with three tasks: 13-class semantic segmentation, depth estimation, and surface normal prediction. The best results for each task on each measure are highlighted in bold. \u2191 (\u2193) means the higher (lower) the result, the better the performance.Weighting \nSegmentation \nDepth \nSurface Normal \n\n\u2206 p \u2191 \nStrategy \nmIoU\u2191 Pix Acc\u2191 Abs Err\u2193 Rel Err\u2193 \nAngle Distance \nWithin t \u2022 \n\nMean\u2193 Median\u2193 11.25\u2191 22.5\u2191 \n30\u2191 \n\nEW \n53.93 \n75.56 \n0.3835 \n0.1566 \n22.7908 16.1512 \n37.16 63.14 73.65 +0.00 \nGradNorm \n54.47 \n75.37 \n0.3882 \n0.1551 \n22.4295 15.9649 \n37.89 63.76 74.22 +0.51 \nUW \n54.16 \n75.60 \n0.3795 \n0.1541 \n22.6800 16.2123 \n37.19 63.05 73.66 +0.52 \nMGDA \n53.65 \n75.19 \n0.3841 \n0.1579 \n22.7391 16.0227 \n37.48 63.29 73.70 \u22120.19 \nDWA \n54.24 \n75.50 \n0.3835 \n0.1600 \n22.6793 16.0649 \n37.40 63.33 73.83 \u22120.13 \nPCGrad \n53.83 \n75.08 \n0.3867 \n0.1575 \n22.5083 15.9023 \n38.03 63.73 74.10 +0.07 \nGradDrop \n53.82 \n75.40 \n0.3841 \n0.1536 \n22.8330 16.4121 \n36.85 62.78 73.36 \u22120.02 \nIMTL \n54.49 \n75.68 \n0.3808 \n0.1531 \n21.9939 15.3531 \n39.42 65.10 75.18 +2.00 \nGradVac \n53.99 \n75.62 \n0.3874 \n0.1546 \n22.5202 15.9511 \n37.96 63.68 74.05 +0.47 \n\nRLW (Uniform) \n53.90 \n75.47 \n0.3859 \n0.1579 \n22.5236 15.8438 \n37.94 63.77 74.11 +0.18 \nRLW (Normal) \n53.93 \n75.31 \n0.3828 \n0.1532 \n22.4460 15.7951 \n38.04 63.93 74.24 +0.88 \nRLW (Dirichlet) \n53.17 \n74.88 \n0.3814 \n0.1561 \n22.5713 15.8921 \n37.88 63.64 73.99 +0.14 \nRLW (Bernoulli) \n54.04 \n75.13 \n0.3818 \n0.1563 \n22.4328 15.8549 \n37.99 63.76 74.10 +0.53 \nRLW (constrained Bernoulli) \n53.77 \n75.24 \n0.3816 \n0.1531 \n22.7075 16.0182 \n37.50 63.24 73.75 +0.49 \nRLW (random Normal) \n53.90 \n75.60 \n0.3847 \n0.1592 \n22.5007 16.0155 \n37.82 63.62 74.03 +0.02 \n\n\n\nTable 8 :\n8Performance on the CityScapes validation dataset with two tasks: 7-class semantic segmentation and depth estimation. The best results for each task on each measure are highlighted in bold. \u2191 (\u2193) means the higher (lower) the result, the better the performance.C.4 RESULTS ON THE CELEBA DATASETDataset The CelebA dataset (Liu et al., 2015b) is a large-scale face attributes dataset with 202,599 face images, each of which has 40 attribute annotations. It is split into three parts:162,770, 19,867  and 19,962  images for training, validation and test, respectively. This dataset contains 40 tasks and each task is a binary classification problem for one attribute.Weighting \nSegmentation \nDepth \n\u2206 p \u2191 \nStrategy \nmIoU\u2191 Pix Acc\u2191 Abs Err\u2193 Rel Err\u2193 \n\nEW \n68.72 \n91.50 \n0.0134 \n46.5974 \n+0.00 \nGradNorm \n68.70 \n91.41 \n0.0133 \n45.6962 \n+0.64 \nUW \n68.72 \n91.48 \n0.0134 \n45.0403 \n+0.83 \nMGDA \n68.36 \n91.17 \n0.0123 \n45.1606 \n+2.60 \nDWA \n68.62 \n91.45 \n0.0132 \n47.1341 \n+0.04 \nPCGrad \n70.16 \n91.93 \n0.0128 \n44.6817 +2.79 \nGradDrop \n68.53 \n91.46 \n0.0134 \n47.1396 \n\u22120.37 \nIMTL \n68.74 \n91.50 \n0.0128 \n45.8279 \n+1.54 \nGradVac \n69.89 \n91.94 \n0.0126 \n47.2281 \n+1.70 \n\nRLW (Uniform) \n68.74 \n91.54 \n0.0132 \n45.2453 \n+1.12 \nRLW (Normal) \n68.82 \n91.53 \n0.0132 \n46.1333 \n+0.67 \nRLW (Dirichlet) \n69.37 \n91.75 \n0.0132 \n44.2218 \n+1.95 \nRLW (Bernoulli) \n69.59 \n91.81 \n0.0130 \n47.0400 \n+0.91 \nRLW (constrained Bernoulli) \n69.49 \n91.81 \n0.0128 \n46.9825 \n+1.28 \nRLW (random Normal) \n68.59 \n91.51 \n0.0132 \n46.7122 \n+0.27 \n\n\nTable 9 :\n9Average classification accuracy (%) of different methods on the CelebA dataset with forty tasks. The best results for each task on each measure are highlighted in bold. RESULTS ON THE OFFICE-31 AND OFFICE-HOME DATASETS Datasets The Office-31 dataset (Saenko et al., 2010) consists of three domains: Amazon (A), DSLR (D), and Webcam (W), where each domain contains 31 object categories. The Office-31 dataset contains 4,110 labeled images and we randomly split these samples with 60% for training, 20% for validation, and the rest 20% for test. The Office-Home dataset (Venkateswara et al., 2017) has four domains: artistic images (Ar), clip artWeighting \nAvg Acc \nStrategy \n\nEW \n90.70 \nGradNorm \n90.77 \nUW \n90.84 \nMGDA \n90.73 \nDWA \n90.77 \nPCGrad \n90.85 \nGradDrop \n90.71 \nIMTL \n90.91 \nGradVac \n90.75 \n\nRLW (Uniform) \n90.86 \nRLW (Normal) \n90.73 \nRLW (Dirichlet) \n90.89 \nRLW (Bernoulli) \n90.71 \nRLW (constrained Bernoulli) \n90.81 \nRLW (random Normal) \n90.88 \n\nC.5 \n\nTable 10 :\n10Classification accuracy (%) of different methods on the Office-31 and Office-Home datasets. The best results for each task are highlighted in bold.Weighting \nOffice-31 \nOffice-Home \n\nStrategy \nA \nD \nW \nAvg \nAr \nCl \nPr \nRw \nAvg \n\nEW \n87.17 98.36 99.44 94.99 68.88 80.93 91.73 81.72 80.81 \nGradNorm \n86.66 99.18 98.89 94.91 68.88 80.49 91.73 82.70 80.95 \nUW \n87.35 99.18 98.89 95.13 69.63 82.55 91.20 81.08 81.12 \nMGDA \n87.52 99.18 99.44 95.38 69.44 79.30 91.63 81.72 80.52 \nDWA \n87.52 99.18 99.44 95.38 70.39 79.95 90.36 82.05 80.69 \nPCGrad \n87.00 98.36 98.33 94.56 68.31 80.71 90.57 81.94 80.38 \nGradDrop \n87.17 98.36 98.89 94.80 68.50 81.47 91.41 81.40 80.69 \nIMTL \n87.52 98.36 98.89 94.92 67.93 80.49 91.94 82.05 80.60 \nGradVac \n88.71 98.36 98.89 95.32 67.93 82.01 91.84 81.72 80.87 \n\nRLW (Uniform) \n88.71 98.36 98.89 95.32 70.01 81.79 90.88 80.97 80.92 \nRLW (Normal) \n88.03 99.18 98.89 95.36 69.44 80.93 90.36 82.70 80.86 \nRLW (Dirichlet) \n88.37 99.18 98.89 95.48 70.01 81.69 91.31 81.18 81.05 \nRLW (Bernoulli) \n88.20 99.18 98.89 95.42 68.69 82.23 91.73 81.72 81.09 \nRLW (constrained Bernoulli) 88.37 \n100 \n99.44 95.94 70.77 81.69 91.41 82.05 81.48 \nRLW (random Normal) \n88.37 98.36 98.89 95.20 68.88 82.12 91.41 81.72 81.03 \n\n\n\nTable 11 :\n11The numbers of training, validation, and test data for each language in each task from the XTREME benchmark. NER POS NIL PI en 20.0K+10.0K+10.0K 6.9K+1.8K+3.2K 392.7K+2.5K+5.0K 49.4K+2.0K+2.0K zh 20.5K+10.3K+10.3K 4.0K+0.5K+2.9K 392.7K+2.5K+5.0K 49.4K+2.0K+2.0K de 20.0K+10.0K+10.0K -392.7K+2.5K+5.0K 49.4K+2.0K+2.0K es 20.0K+10.0K+10.0K -392.7K+2.5K+5.0K 49.4K+2.0K+2.0Kte \n-\n1.0K+0.1K+0.1K \n-\n-\nvi \n-\n1.4K+0.8K+0.8K \n-\n-\n\n\n\nTable 12 :\n12Performance on two multilingual problems, i.e., NLI and NER from the XTREME benchmark. The best results for each language are highlighted in bold.EW 82.05 77.04 77.80 78.48 78.84 85.21 83.61 90.73 92.89 88.11 GradNorm 83.33 77.34 78.20 79.54 79.60 85.70 84.16 91.13 93.17 88.54 UW 82.93 77.58 77.96 79.72 79.55 85.59 84.42 91.14 93.24 88.60 MGDA 83.11 77.32 77.84 79.02 79.32 85.68 84.13 90.99 93.28 88.Dirichlet) 82.99 76.92 77.40 78.56 78.97 85.31 83.97 91.06 93.18 88.38 RLW (Bernoulli) 83.11 77.52 78.10 78.84 79.39 85.59 83.84 91.09 93.01 88.38 RLW (constrained Bernoulli) 82.69 76.54 77.74 78.70 78.92 85.56 83.31 90.98 92.86 88.18 RLW (random Normal) 83.65 77.72 77.78 79.16 79.58 85.15 84.09 90.94 93.22 88.35Weighting \nNLI (Accuracy) \nNER (F1 Score) \n\nStrategy \nen \nzh \nde \nes \nAvg \nen \nzh \nde \nes \nAvg \n\n52 \nDWA \n83.17 77.52 78.06 79.56 79.58 85.55 84.42 90.91 93.22 88.53 \nPCGrad \n82.55 77.06 78.84 79.24 79.42 84.69 82.26 90.17 92.72 87.46 \nGradDrop \n82.15 76.10 77.36 78.22 78.46 85.92 84.45 91.06 93.29 88.68 \nIMTL \n82.63 77.78 76.56 79.28 79.06 84.97 83.92 90.82 92.79 88.12 \nGradVac \n81.39 76.74 76.94 78.50 78.39 84.38 82.54 90.03 92.29 87.31 \n\nRLW (Uniform) \n83.21 78.14 78.04 79.58 79.74 85.48 84.18 90.92 93.30 88.47 \nRLW (Normal) \n82.63 76.36 77.26 79.24 78.87 85.25 83.79 91.24 93.30 88.40 \nRLW (\n\nAayush Bansal, Xinlei Chen, Bryan C Russell, Abhinav Gupta, Deva Ramanan Pixelnet, arXiv:1702.06506Representation of the pixels, by the pixels, and for the pixels. arXiv preprintAayush Bansal, Xinlei Chen, Bryan C. Russell, Abhinav Gupta, and Deva Ramanan. Pixelnet: Representation of the pixels, by the pixels, and for the pixels. arXiv preprint arXiv:1702.06506, 2017.\n\nStochastic gradient learning in neural networks. L\u00e9on Bottou, Proceedings of Neuro-N\u0131mes. Neuro-N\u0131mes9112L\u00e9on Bottou. Stochastic gradient learning in neural networks. Proceedings of Neuro-N\u0131mes, 91(8): 12, 1991.\n\nMultitask learning: A knowledge-based source of inductive bias. Rich Caruana, Proceedings of the 10th International Conference on Machine Learning. the 10th International Conference on Machine LearningRich Caruana. Multitask learning: A knowledge-based source of inductive bias. In Proceedings of the 10th International Conference on Machine Learning, pp. 41-48, 1993.\n\nEncoderdecoder with atrous separable convolution for semantic image segmentation. Yukun Liang-Chieh Chen, George Zhu, Florian Papandreou, Hartwig Schroff, Adam, Proceedings of the 14th European Conference on Computer Vision. the 14th European Conference on Computer Vision11211Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. Encoder- decoder with atrous separable convolution for semantic image segmentation. In Proceedings of the 14th European Conference on Computer Vision, volume 11211, pp. 833-851, 2018a.\n\nShijie Chen, Yu Zhang, Qiang Yang, arXiv:2109.09138Multi-task learning in natural language processing: An overview. arXiv preprintShijie Chen, Yu Zhang, and Qiang Yang. Multi-task learning in natural language processing: An overview. arXiv preprint arXiv: 2109.09138, 2021.\n\nGradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks. Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich, Proceedings of the International Conference on Machine Learning. the International Conference on Machine LearningPMLRZhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and Andrew Rabinovich. Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks. In Proceedings of the International Conference on Machine Learning, pp. 794-803. PMLR, 2018b.\n\nJust pick a sign: Optimizing deep multitask models with gradient sign dropout. Zhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong, Henrik Kretzschmar, Yuning Chai, Dragomir Anguelov, Proceedings of the 33rd Advances in Neural Information Processing Systems. the 33rd Advances in Neural Information Processing SystemsZhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong, Henrik Kretzschmar, Yuning Chai, and Dragomir Anguelov. Just pick a sign: Optimizing deep multitask models with gradient sign dropout. In Proceedings of the 33rd Advances in Neural Information Processing Systems, 2020.\n\nXNLI: evaluating cross-lingual sentence representations. Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel R Bowman, Holger Schwenk, Veselin Stoyanov, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingAlexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel R. Bowman, Holger Schwenk, and Veselin Stoyanov. XNLI: evaluating cross-lingual sentence representations. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pp. 2475-2485, 2018.\n\nUwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic. Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The cityscapes dataset for semantic\n\n. Roozbeh Mottaghi, Xianjie Chen, Xiaobai Liu, Nam-Gyu Cho, Seong-Whan Lee, Sanja Fidler, Roozbeh Mottaghi, Xianjie Chen, Xiaobai Liu, Nam-Gyu Cho, Seong-Whan Lee, Sanja Fidler,\n", "annotations": {"author": "[{\"end\":181,\"start\":59},{\"end\":302,\"start\":182},{\"end\":444,\"start\":303}]", "publisher": null, "author_last_name": "[{\"end\":71,\"start\":68},{\"end\":192,\"start\":190},{\"end\":311,\"start\":306}]", "author_first_name": "[{\"end\":67,\"start\":59},{\"end\":189,\"start\":182},{\"end\":305,\"start\":303}]", "author_affiliation": "[{\"end\":180,\"start\":73},{\"end\":301,\"start\":194},{\"end\":443,\"start\":336}]", "title": "[{\"end\":56,\"start\":1},{\"end\":500,\"start\":445}]", "venue": null, "abstract": "[{\"end\":2214,\"start\":502}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2276,\"start\":2256},{\"end\":2301,\"start\":2276},{\"end\":2702,\"start\":2676},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2757,\"start\":2738},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2802,\"start\":2782},{\"end\":2956,\"start\":2939},{\"end\":3233,\"start\":3207},{\"end\":3751,\"start\":3729},{\"end\":3833,\"start\":3816},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3935,\"start\":3915},{\"end\":4311,\"start\":4294},{\"end\":5547,\"start\":5545},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9037,\"start\":9017},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11503,\"start\":11489},{\"end\":15126,\"start\":15107},{\"end\":15144,\"start\":15126},{\"end\":15169,\"start\":15144},{\"end\":15194,\"start\":15169},{\"end\":15212,\"start\":15194},{\"end\":15230,\"start\":15212},{\"end\":17123,\"start\":17100},{\"end\":17144,\"start\":17123},{\"end\":17725,\"start\":17705},{\"end\":17748,\"start\":17725},{\"end\":19571,\"start\":19547},{\"end\":20968,\"start\":20945},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21533,\"start\":21512},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21552,\"start\":21533},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":22217,\"start\":22202},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22552,\"start\":22532},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22780,\"start\":22761},{\"end\":22911,\"start\":22892},{\"end\":23834,\"start\":23813},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":29016,\"start\":28996},{\"end\":40253,\"start\":40232},{\"end\":40868,\"start\":40849},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":42804,\"start\":42784},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":43856,\"start\":43834}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":45018,\"start\":44664},{\"attributes\":{\"id\":\"fig_1\"},\"end\":45312,\"start\":45019},{\"attributes\":{\"id\":\"fig_2\"},\"end\":45375,\"start\":45313},{\"attributes\":{\"id\":\"fig_3\"},\"end\":45807,\"start\":45376},{\"attributes\":{\"id\":\"fig_4\"},\"end\":46150,\"start\":45808},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":47951,\"start\":46151},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":49720,\"start\":47952},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":51064,\"start\":49721},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":52819,\"start\":51065},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":58307,\"start\":52820},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":58642,\"start\":58308},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":60438,\"start\":58643},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":62226,\"start\":60439},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":63730,\"start\":62227},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":64704,\"start\":63731},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":65949,\"start\":64705},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":66388,\"start\":65950},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":67721,\"start\":66389}]", "paragraph": "[{\"end\":3367,\"start\":2230},{\"end\":4374,\"start\":3369},{\"end\":6333,\"start\":4376},{\"end\":6398,\"start\":6335},{\"end\":6616,\"start\":6400},{\"end\":6713,\"start\":6618},{\"end\":6789,\"start\":6715},{\"end\":6935,\"start\":6791},{\"end\":7438,\"start\":6951},{\"end\":7927,\"start\":7479},{\"end\":8517,\"start\":7974},{\"end\":9852,\"start\":8519},{\"end\":10438,\"start\":9854},{\"end\":10716,\"start\":10457},{\"end\":11316,\"start\":10763},{\"end\":12243,\"start\":11318},{\"end\":12362,\"start\":12303},{\"end\":12962,\"start\":12364},{\"end\":13183,\"start\":13016},{\"end\":13205,\"start\":13185},{\"end\":13245,\"start\":13207},{\"end\":13286,\"start\":13247},{\"end\":13417,\"start\":13288},{\"end\":14633,\"start\":13419},{\"end\":15443,\"start\":14635},{\"end\":15866,\"start\":15456},{\"end\":16105,\"start\":15868},{\"end\":16201,\"start\":16107},{\"end\":16359,\"start\":16274},{\"end\":16667,\"start\":16361},{\"end\":16772,\"start\":16724},{\"end\":17409,\"start\":16894},{\"end\":18004,\"start\":17411},{\"end\":18306,\"start\":18006},{\"end\":18496,\"start\":18402},{\"end\":20069,\"start\":19031},{\"end\":20513,\"start\":20085},{\"end\":20916,\"start\":20526},{\"end\":21553,\"start\":20918},{\"end\":22104,\"start\":21555},{\"end\":22479,\"start\":22131},{\"end\":24252,\"start\":22481},{\"end\":24780,\"start\":24274},{\"end\":25163,\"start\":24858},{\"end\":26559,\"start\":25196},{\"end\":27330,\"start\":26561},{\"end\":27465,\"start\":27332},{\"end\":29458,\"start\":27507},{\"end\":29877,\"start\":29495},{\"end\":30606,\"start\":29879},{\"end\":31343,\"start\":30622},{\"end\":31998,\"start\":31395},{\"end\":32458,\"start\":32417},{\"end\":33147,\"start\":33102},{\"end\":33277,\"start\":33160},{\"end\":33396,\"start\":33391},{\"end\":33512,\"start\":33465},{\"end\":33550,\"start\":33514},{\"end\":33711,\"start\":33662},{\"end\":33975,\"start\":33815},{\"end\":34186,\"start\":34085},{\"end\":34506,\"start\":34296},{\"end\":34844,\"start\":34769},{\"end\":35046,\"start\":34884},{\"end\":35209,\"start\":35090},{\"end\":35308,\"start\":35299},{\"end\":36228,\"start\":35982},{\"end\":36485,\"start\":36414},{\"end\":36692,\"start\":36532},{\"end\":37061,\"start\":36798},{\"end\":37272,\"start\":37111},{\"end\":37424,\"start\":37274},{\"end\":37651,\"start\":37487},{\"end\":37823,\"start\":37760},{\"end\":37912,\"start\":37884},{\"end\":38106,\"start\":37990},{\"end\":38256,\"start\":38241},{\"end\":38353,\"start\":38323},{\"end\":38591,\"start\":38424},{\"end\":39225,\"start\":38593},{\"end\":40159,\"start\":39227},{\"end\":41054,\"start\":40201},{\"end\":42004,\"start\":41066},{\"end\":42805,\"start\":42006},{\"end\":44201,\"start\":42807},{\"end\":44663,\"start\":44213}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7478,\"start\":7439},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7973,\"start\":7928},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10762,\"start\":10717},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12302,\"start\":12244},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16273,\"start\":16202},{\"attributes\":{\"id\":\"formula_5\"},\"end\":16723,\"start\":16668},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16893,\"start\":16773},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18401,\"start\":18307},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19030,\"start\":18497},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24857,\"start\":24781},{\"attributes\":{\"id\":\"formula_10\"},\"end\":32416,\"start\":31999},{\"attributes\":{\"id\":\"formula_11\"},\"end\":33101,\"start\":32459},{\"attributes\":{\"id\":\"formula_12\"},\"end\":33390,\"start\":33278},{\"attributes\":{\"id\":\"formula_13\"},\"end\":33464,\"start\":33397},{\"attributes\":{\"id\":\"formula_14\"},\"end\":33661,\"start\":33551},{\"attributes\":{\"id\":\"formula_15\"},\"end\":33814,\"start\":33712},{\"attributes\":{\"id\":\"formula_16\"},\"end\":34084,\"start\":33976},{\"attributes\":{\"id\":\"formula_17\"},\"end\":34295,\"start\":34187},{\"attributes\":{\"id\":\"formula_18\"},\"end\":34743,\"start\":34507},{\"attributes\":{\"id\":\"formula_19\"},\"end\":34883,\"start\":34845},{\"attributes\":{\"id\":\"formula_20\"},\"end\":35089,\"start\":35047},{\"attributes\":{\"id\":\"formula_21\"},\"end\":35298,\"start\":35210},{\"attributes\":{\"id\":\"formula_22\"},\"end\":35981,\"start\":35309},{\"attributes\":{\"id\":\"formula_23\"},\"end\":36413,\"start\":36229},{\"attributes\":{\"id\":\"formula_24\"},\"end\":36507,\"start\":36486},{\"attributes\":{\"id\":\"formula_25\"},\"end\":36797,\"start\":36693},{\"attributes\":{\"id\":\"formula_26\"},\"end\":37486,\"start\":37425},{\"attributes\":{\"id\":\"formula_27\"},\"end\":37759,\"start\":37652},{\"attributes\":{\"id\":\"formula_28\"},\"end\":37883,\"start\":37824},{\"attributes\":{\"id\":\"formula_29\"},\"end\":37989,\"start\":37913},{\"attributes\":{\"id\":\"formula_30\"},\"end\":38240,\"start\":38107},{\"attributes\":{\"id\":\"formula_31\"},\"end\":38322,\"start\":38257}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":9837,\"start\":9830},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":25260,\"start\":25253},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":26821,\"start\":26814},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":27580,\"start\":27573},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":28563,\"start\":28556},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":28701,\"start\":28694},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":28775,\"start\":28767},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":29745,\"start\":29738},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":30033,\"start\":30026},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31996,\"start\":31989},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":39405,\"start\":39398},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":41107,\"start\":41100},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":42178,\"start\":42171},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":43410,\"start\":43402},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":44199,\"start\":44191},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":44284,\"start\":44276},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":44374,\"start\":44367}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2228,\"start\":2216},{\"attributes\":{\"n\":\"2\"},\"end\":6949,\"start\":6938},{\"attributes\":{\"n\":\"3\"},\"end\":10455,\"start\":10441},{\"end\":13014,\"start\":12965},{\"attributes\":{\"n\":\"4\"},\"end\":15454,\"start\":15446},{\"attributes\":{\"n\":\"5\"},\"end\":20083,\"start\":20072},{\"attributes\":{\"n\":\"5.1\"},\"end\":20524,\"start\":20516},{\"attributes\":{\"n\":\"5.2\"},\"end\":22129,\"start\":22107},{\"attributes\":{\"n\":\"5.3\"},\"end\":24272,\"start\":24255},{\"attributes\":{\"n\":\"5.4\"},\"end\":25194,\"start\":25166},{\"attributes\":{\"n\":\"5.5\"},\"end\":27505,\"start\":27468},{\"attributes\":{\"n\":\"5.7\"},\"end\":29493,\"start\":29461},{\"attributes\":{\"n\":\"6\"},\"end\":30620,\"start\":30609},{\"end\":31393,\"start\":31346},{\"end\":33158,\"start\":33150},{\"end\":34767,\"start\":34745},{\"end\":36530,\"start\":36509},{\"end\":37109,\"start\":37064},{\"end\":38389,\"start\":38356},{\"end\":38422,\"start\":38392},{\"end\":40199,\"start\":40162},{\"end\":41064,\"start\":41057},{\"end\":44211,\"start\":44204},{\"end\":45387,\"start\":45377},{\"end\":45813,\"start\":45809},{\"end\":46161,\"start\":46152},{\"end\":47962,\"start\":47953},{\"end\":49731,\"start\":49722},{\"end\":51075,\"start\":51066},{\"end\":58318,\"start\":58309},{\"end\":58653,\"start\":58644},{\"end\":60449,\"start\":60440},{\"end\":62237,\"start\":62228},{\"end\":63741,\"start\":63732},{\"end\":64716,\"start\":64706},{\"end\":65961,\"start\":65951},{\"end\":66400,\"start\":66390}]", "table": "[{\"end\":47951,\"start\":46457},{\"end\":49720,\"start\":48344},{\"end\":51064,\"start\":49877},{\"end\":52819,\"start\":51399},{\"end\":58307,\"start\":54670},{\"end\":58642,\"start\":58320},{\"end\":60438,\"start\":58747},{\"end\":62226,\"start\":60806},{\"end\":63730,\"start\":62901},{\"end\":64704,\"start\":64387},{\"end\":65949,\"start\":64866},{\"end\":66388,\"start\":66335},{\"end\":67721,\"start\":67120}]", "figure_caption": "[{\"end\":45018,\"start\":44666},{\"end\":45312,\"start\":45021},{\"end\":45375,\"start\":45315},{\"end\":45807,\"start\":45389},{\"end\":46150,\"start\":45815},{\"end\":46457,\"start\":46163},{\"end\":48344,\"start\":47964},{\"end\":49877,\"start\":49733},{\"end\":51399,\"start\":51077},{\"end\":54670,\"start\":52822},{\"end\":58747,\"start\":58655},{\"end\":60806,\"start\":60451},{\"end\":62901,\"start\":62239},{\"end\":64387,\"start\":63743},{\"end\":64866,\"start\":64719},{\"end\":66335,\"start\":65964},{\"end\":67120,\"start\":66403}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":38435,\"start\":38427}]", "bib_author_first_name": "[{\"end\":67729,\"start\":67723},{\"end\":67744,\"start\":67738},{\"end\":67756,\"start\":67751},{\"end\":67758,\"start\":67757},{\"end\":67775,\"start\":67768},{\"end\":67787,\"start\":67783},{\"end\":67795,\"start\":67788},{\"end\":68148,\"start\":68144},{\"end\":68376,\"start\":68372},{\"end\":68765,\"start\":68760},{\"end\":68790,\"start\":68784},{\"end\":68803,\"start\":68796},{\"end\":68823,\"start\":68816},{\"end\":69230,\"start\":69224},{\"end\":69239,\"start\":69237},{\"end\":69252,\"start\":69247},{\"end\":69592,\"start\":69588},{\"end\":69604,\"start\":69599},{\"end\":69628,\"start\":69621},{\"end\":69640,\"start\":69634},{\"end\":70106,\"start\":70102},{\"end\":70119,\"start\":70113},{\"end\":70134,\"start\":70127},{\"end\":70147,\"start\":70142},{\"end\":70161,\"start\":70155},{\"end\":70181,\"start\":70175},{\"end\":70196,\"start\":70188},{\"end\":70676,\"start\":70670},{\"end\":70690,\"start\":70686},{\"end\":70708,\"start\":70699},{\"end\":70722,\"start\":70717},{\"end\":70739,\"start\":70733},{\"end\":70741,\"start\":70740},{\"end\":70756,\"start\":70750},{\"end\":70773,\"start\":70766},{\"end\":71319,\"start\":71313},{\"end\":71335,\"start\":71328},{\"end\":71352,\"start\":71343},{\"end\":71364,\"start\":71360},{\"end\":71380,\"start\":71374},{\"end\":71399,\"start\":71392},{\"end\":71597,\"start\":71590},{\"end\":71615,\"start\":71608},{\"end\":71629,\"start\":71622},{\"end\":71642,\"start\":71635},{\"end\":71658,\"start\":71648},{\"end\":71669,\"start\":71664}]", "bib_author_last_name": "[{\"end\":67736,\"start\":67730},{\"end\":67749,\"start\":67745},{\"end\":67766,\"start\":67759},{\"end\":67781,\"start\":67776},{\"end\":67804,\"start\":67796},{\"end\":68155,\"start\":68149},{\"end\":68384,\"start\":68377},{\"end\":68782,\"start\":68766},{\"end\":68794,\"start\":68791},{\"end\":68814,\"start\":68804},{\"end\":68831,\"start\":68824},{\"end\":68837,\"start\":68833},{\"end\":69235,\"start\":69231},{\"end\":69245,\"start\":69240},{\"end\":69257,\"start\":69253},{\"end\":69597,\"start\":69593},{\"end\":69619,\"start\":69605},{\"end\":69632,\"start\":69629},{\"end\":69651,\"start\":69641},{\"end\":70111,\"start\":70107},{\"end\":70125,\"start\":70120},{\"end\":70140,\"start\":70135},{\"end\":70153,\"start\":70148},{\"end\":70173,\"start\":70162},{\"end\":70186,\"start\":70182},{\"end\":70205,\"start\":70197},{\"end\":70684,\"start\":70677},{\"end\":70697,\"start\":70691},{\"end\":70715,\"start\":70709},{\"end\":70731,\"start\":70723},{\"end\":70748,\"start\":70742},{\"end\":70764,\"start\":70757},{\"end\":70782,\"start\":70774},{\"end\":71326,\"start\":71320},{\"end\":71341,\"start\":71336},{\"end\":71358,\"start\":71353},{\"end\":71372,\"start\":71365},{\"end\":71390,\"start\":71381},{\"end\":71408,\"start\":71400},{\"end\":71606,\"start\":71598},{\"end\":71620,\"start\":71616},{\"end\":71633,\"start\":71630},{\"end\":71646,\"start\":71643},{\"end\":71662,\"start\":71659},{\"end\":71676,\"start\":71670}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1702.06506\",\"id\":\"b0\"},\"end\":68093,\"start\":67723},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":12410481},\"end\":68306,\"start\":68095},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":18522085},\"end\":68676,\"start\":68308},{\"attributes\":{\"id\":\"b3\"},\"end\":69222,\"start\":68678},{\"attributes\":{\"doi\":\"arXiv:2109.09138\",\"id\":\"b4\"},\"end\":69497,\"start\":69224},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":4703661},\"end\":70021,\"start\":69499},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":222341884},\"end\":70611,\"start\":70023},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":52271711},\"end\":71230,\"start\":70613},{\"attributes\":{\"id\":\"b8\"},\"end\":71586,\"start\":71232},{\"attributes\":{\"id\":\"b9\"},\"end\":71765,\"start\":71588}]", "bib_title": "[{\"end\":68142,\"start\":68095},{\"end\":68370,\"start\":68308},{\"end\":68758,\"start\":68678},{\"end\":69586,\"start\":69499},{\"end\":70100,\"start\":70023},{\"end\":70668,\"start\":70613}]", "bib_author": "[{\"end\":67738,\"start\":67723},{\"end\":67751,\"start\":67738},{\"end\":67768,\"start\":67751},{\"end\":67783,\"start\":67768},{\"end\":67806,\"start\":67783},{\"end\":68157,\"start\":68144},{\"end\":68386,\"start\":68372},{\"end\":68784,\"start\":68760},{\"end\":68796,\"start\":68784},{\"end\":68816,\"start\":68796},{\"end\":68833,\"start\":68816},{\"end\":68839,\"start\":68833},{\"end\":69237,\"start\":69224},{\"end\":69247,\"start\":69237},{\"end\":69259,\"start\":69247},{\"end\":69599,\"start\":69588},{\"end\":69621,\"start\":69599},{\"end\":69634,\"start\":69621},{\"end\":69653,\"start\":69634},{\"end\":70113,\"start\":70102},{\"end\":70127,\"start\":70113},{\"end\":70142,\"start\":70127},{\"end\":70155,\"start\":70142},{\"end\":70175,\"start\":70155},{\"end\":70188,\"start\":70175},{\"end\":70207,\"start\":70188},{\"end\":70686,\"start\":70670},{\"end\":70699,\"start\":70686},{\"end\":70717,\"start\":70699},{\"end\":70733,\"start\":70717},{\"end\":70750,\"start\":70733},{\"end\":70766,\"start\":70750},{\"end\":70784,\"start\":70766},{\"end\":71328,\"start\":71313},{\"end\":71343,\"start\":71328},{\"end\":71360,\"start\":71343},{\"end\":71374,\"start\":71360},{\"end\":71392,\"start\":71374},{\"end\":71410,\"start\":71392},{\"end\":71608,\"start\":71590},{\"end\":71622,\"start\":71608},{\"end\":71635,\"start\":71622},{\"end\":71648,\"start\":71635},{\"end\":71664,\"start\":71648},{\"end\":71678,\"start\":71664}]", "bib_venue": "[{\"end\":67885,\"start\":67822},{\"end\":68183,\"start\":68157},{\"end\":68454,\"start\":68386},{\"end\":68901,\"start\":68839},{\"end\":69338,\"start\":69275},{\"end\":69716,\"start\":69653},{\"end\":70280,\"start\":70207},{\"end\":70870,\"start\":70784},{\"end\":71311,\"start\":71232},{\"end\":68196,\"start\":68185},{\"end\":68509,\"start\":68456},{\"end\":68950,\"start\":68903},{\"end\":69766,\"start\":69718},{\"end\":70340,\"start\":70282},{\"end\":70943,\"start\":70872}]"}}}, "year": 2023, "month": 12, "day": 17}