{"id": 3162051, "updated": "2023-09-28 22:05:22.161", "metadata": {"title": "mixup: Beyond Empirical Risk Minimization", "authors": "[{\"first\":\"Hongyi\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Moustapha\",\"last\":\"Cisse\",\"middle\":[]},{\"first\":\"Yann\",\"last\":\"Dauphin\",\"middle\":[\"N.\"]},{\"first\":\"David\",\"last\":\"Lopez-Paz\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2017, "month": 10, "day": 25}, "abstract": "Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1710.09412", "mag": "2963399829", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iclr/ZhangCDL18", "doi": null}}, "content": {"source": {"pdf_hash": "c0672186ed39c276a476dc5dd4d3ccf548d29eee", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1710.09412v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "cccf77b9c3b0f52bccbecab566b6188d25de2ed2", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c0672186ed39c276a476dc5dd4d3ccf548d29eee.txt", "contents": "\nmixup: BEYOND EMPIRICAL RISK MINIMIZATION\n\n\nHongyi Zhang \nMIT\n\n\nMoustapha Cisse \nMIT\n\n\nYann N Dauphin \nMIT\n\n\nDavid Lopez-Paz \nMIT\n\n\nFair \nMIT\n\n\nmixup: BEYOND EMPIRICAL RISK MINIMIZATION\n\nLarge deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks. * Alphabetical order.\n\nINTRODUCTION\n\nLarge deep neural networks have enabled breakthroughs in fields such as computer vision (Krizhevsky et al., 2012), speech recognition , and reinforcement learning (Silver et al., 2016). In most successful applications, these neural networks share two commonalities. First, they are trained as to minimize their average error over the training data, a learning rule also known as the Empirical Risk Minimization (ERM) principle (Vapnik, 1998). Second, the size of these state-of-theart neural networks scales linearly with the number of training examples. For instance, the network of Springenberg et al. (2015) used 10 6 parameters to model the 5 \u00b7 10 4 images in the CIFAR-10 dataset, the network of (Simonyan & Zisserman, 2015) used 10 8 parameters to model the 10 6 images in the ImageNet-2012 dataset, and the network of Chelba et al. (2013) used 2 \u00b7 10 10 parameters to model the 10 9 words in the One Billion Word dataset.\n\nStrikingly, a classical result in learning theory (Vapnik & Chervonenkis, 1971) tells us that the convergence of ERM is guaranteed as long as the size of the learning machine (e.g., the neural network) does not increase with the number of training data. Here, the size of a learning machine is measured in terms of its number of parameters or, relatedly, its VC-complexity (Harvey et al., 2017).\n\nThis contradiction challenges the suitability of ERM to train our current neural network models, as highlighted in recent research. On the one hand, ERM allows large neural networks to memorize (instead of generalize from) the training data even in the presence of strong regularization, or in classification problems where the labels are assigned at random . On the other hand, neural networks trained with ERM change their predictions drastically when evaluated on examples just outside the training distribution (Szegedy et al., 2014), also known as adversarial examples. This evidence suggests that ERM is unable to explain or provide generalization on testing distributions that differ only slightly from the training data. However, what is the alternative to ERM?\n\nThe method of choice to train on similar but different examples to the training data is known as data augmentation (Simard et al., 1998), formalized by the Vicinal Risk Minimization (VRM) principle (Chapelle et al., 2000). In VRM, human knowledge is required to describe a vicinity or neighborhood around each example in the training data. Then, additional virtual examples can be drawn from the vicinity distribution of the training examples to enlarge the support of the training distribution. For instance, when performing image classification, it is common to define the vicinity of one image as the set of its horizontal reflections, slight rotations, and mild scalings. While data augmentation consistently leads to improved generalization (Simard et al., 1998), the procedure is dataset-dependent, and thus requires the use of expert knowledge. Furthermore, data augmentation assumes that the examples in the vicinity share the same class, and does not model the vicinity relation across examples of different classes.\n\nContribution Motivated by these issues, we introduce a simple and data-agnostic data augmentation routine, termed mixup (Section 2). In a nutshell, mixup constructs virtual training examples\nx = \u03bbx i + (1 \u2212 \u03bb)x j , y = \u03bby i + (1 \u2212 \u03bb)y j ,\nwhere (x i , y i ) and (x j , y j ) are two examples drawn at random from our training data, and \u03bb \u2208 [0, 1]. Therefore, mixup extends the training distribution by incorporating the prior knowledge that linear interpolations of feature vectors should lead to linear interpolations of the associated targets. mixup can be implemented in a few lines of code, and introduces minimal computation overhead.\n\nDespite its simplicity, mixup allows a new state-of-the-art performance in the CIFAR-10, CIFAR-100, and ImageNet-2012 image classification datasets (Sections 3.1 and 3.2). Furthermore, mixup increases the robustness of neural networks when learning from corrupt labels (Section 3.4), or facing adversarial examples (Section 3.5). Finally, mixup improves generalization on speech (Sections 3.3) and tabular (Section 3.6) data, and can be used to stabilize the training of GANs (Section 3.7). The source-code necessary to replicate our experiments is available at:\n\nhttps://coming.soon/mixup.\n\nWe conclude by exploring the connections to prior work (Section 4), as well as offering some points for discussion (Section 5).\n\n\nFROM EMPIRICAL RISK MINIMIZATION TO mixup\n\nIn supervised learning, we are interested in finding a function f \u2208 F that describes the relationship between a random feature vector X and a random target vector Y , which follow the joint distribution P (X, Y ). To this end, we first define a loss function that penalizes the differences between predictions f (x) and actual targets y, for examples (x, y) \u223c P . Then, we minimize the average of the loss function over the data distribution P , also known as the expected risk:\nR(f ) = (f (x), y)dP (x, y).\nUnfortunately, the distribution P is unknown in most practical situations. Instead, we usually have access to a set of training data D = {(x i , y i )} n i=1 , where (x i , y i ) \u223c P for all i = 1, . . . , n. Using the training data D, we may approximate P by the empirical distribution\nP \u03b4 (x, y) = 1 n n i=1 \u03b4(x = x i , y = y i ),\nwhere \u03b4(x = x i , y = y i ) is a Dirac mass centered at (x i , y i ). Using the empirical distribution P \u03b4 , we can now approximate the expected risk by the empirical risk:\nR \u03b4 (f ) = (f (x), y)dP \u03b4 (x, y) = 1 n n i=1 (f (x i ), y i ).(1)\nLearning the function f by minimizing (1) is known as the Empirical Risk Minimization (ERM) principle (Vapnik, 1998). While efficient to compute, the empirical risk (1) monitors the behaviour of f only at a finite set of n examples. When considering functions with a number parameters comparable to n (such as large neural networks), one trivial way to minimize (1) is to memorize the training data . Memorization, in turn, leads to the undesirable behaviour of f outside the training data (Szegedy et al., 2014).\n\nHowever, the na\u00efve estimate P \u03b4 is one out of many possible choices to approximate the true distribution P . For instance, in the Vicinal Risk Minimization (VRM) principle (Chapelle et al., 2000), the distribution P is approximated by  where \u03bd is a vicinity distribution that measures the probability of finding the virtual feature-target pair (x,\u1ef9) in the vicinity of the training feature-target pair (x i , y i ). In particular, Chapelle et al. (2000) considered Gaussian vicinities \u03bd(x,\u1ef9|x i , y i ) = N (x \u2212 x i , \u03c3 2 )\u03b4(\u1ef9 = y i ), which is equivalent to augmenting the training data with additive Gaussian noise. To learn using VRM, we sample the vicinal distribution to construct a dataset D \u03bd := {(x i ,\u1ef9 i )} m i=1 , and minimize the empirical vicinal risk:\nP \u03bd (x,\u1ef9) = 1 n n i=1 \u03bd(x,\u1ef9|x i , y i ),R \u03bd (f ) = 1 m m i=1 (f (x i ),\u1ef9 i ).\nThe contribution of this paper is to propose a generic vicinal distribution, called mixup:\n\u00b5(x,\u1ef9|x i , y i ) = 1 n n j E \u03bb [\u03b4(x = \u03bb \u00b7 x i + (1 \u2212 \u03bb) \u00b7 x j ,\u1ef9 = \u03bb \u00b7 y i + (1 \u2212 \u03bb) \u00b7 y j )] ,\nwhere \u03bb \u223c Beta(\u03b1, \u03b1), for \u03b1 \u2208 (0, \u221e). In a nutshell, sampling from the mixup vicinal distribution produces virtual feature-target vectorsx\n= \u03bbx i + (1 \u2212 \u03bb)x j , y = \u03bby i + (1 \u2212 \u03bb)y j ,\nwhere (x i , y i ) and (x j , y j ) are two feature-target vectors drawn at random from the training data, and \u03bb \u2208 [0, 1]. The mixup hyper-parameter \u03b1 controls the strength of interpolation between feature-target pairs, recovering the ERM principle as \u03b1 \u2192 0.\n\nThe implementation of mixup training is straightforward, and introduces a minimal computation overhead. Figure 1a shows the few lines of code necessary to implement mixup training in PyTorch. Finally, we mention alternative design choices. First, we have observed that performing convex combinations of three or more examples with weights sampled from a Dirichlet distribution works similarly well, but increases the computation cost of mixup. Second, our current implementation uses a single data loader to obtain one minibatch, and then mixup is applied to the same minibatch after random shuffling. We found this strategy works equally well, while reducing I/O requirements. Third, interpolating only between inputs with equal label did not lead to the performance gains of mixup discussed in the sequel.\n\nWhat is mixup doing? The mixup vicinal distribution can be understood as a form of data augmentation that encourages the model f to behave linearly in-between training examples. We argue that this linear behaviour reduces the amount of undesirable oscillations when predicting outside the training examples. Also, linearity is a good inductive bias from the perspective of Occam's razor, since it is one of the simplest possible behaviors. Figure 1b shows that mixup leads to decision boundaries that transition linearly from class to class, providing a smoother estimate of uncertainty. Figure 2 illustrate the average behaviors of two neural network models trained on the CIFAR-10 dataset using ERM and mixup. Both models have the same architecture, are trained with the same procedure, and are evaluated at the same points in-between randomly sampled training data. The model trained with mixup is more stable in terms of model predictions and gradient norms in-between training samples.   \n\n\nEXPERIMENTS\n\n\nIMAGENET CLASSIFICATION\n\nWe evaluate mixup on the ImageNet-2012 classification dataset (Russakovsky et al., 2015). This dataset contains 1.3 million training images and 50,000 validation images, from a total of 1,000 classes. For training, we follow standard data augmentation practices: scale and aspect ratio distortions, random crops, and horizontal flips (Goyal et al., 2017). During evaluation, only the 224 \u00d7 224 central crop of each image is tested. We use mixup and ERM to train several state-of-the-art ImageNet-2012 classification models, and report both top-1 and top-5 error rates in Table 1.\n\nFor all the experiments in this section, we use data-parallel distributed training with a minibatch size of 1,024. We use the learning rate schedule described in (Goyal et al., 2017). Specifically, the learning rate is increased linearly from 0.1 to 0.4 during the first 5 epochs, and it is then divided by 10 after 30, 60 and 80 epochs when training for 90 epochs; or after 60, 120 and 180 epochs when training for 200 epochs.\n\nFor mixup, we find that \u03b1 \u2208 [0.1, 0.4] leads to improved performance over ERM, whereas for large \u03b1, mixup leads to underfitting. We also find that models with higher capacities and/or longer training runs are the ones to benefit the most from mixup. For example, when trained for 90 epochs, the mixup   variants of ResNet-101 and ResNeXt-101 obtain a greater improvement (0.5% to 0.6%) over their ERM analogues than the gain of smaller models such as ResNet-50 (0.2%). When trained for 200 epochs, the top-1 error of the mixup variant of ResNet-50 is further reduced by 1.2% compared to the 90 epoch run, whereas its ERM analogue stays the same.\n\n\nCIFAR-10 AND CIFAR-100\n\nWe conduct additional image classification experiments on the CIFAR-10 and CIFAR-100 datasets to further evaluate the generalization performance of mixup. In particular, we compare ERM and mixup training for: PreAct ResNet-18  as implemented in (Liu, 2017), WideResNet-28-10 (Zagoruyko & Komodakis, 2016a) as implemented in (Zagoruyko & Komodakis, 2016b), and DenseNet (Huang et al., 2017) as implemented in (Veit, 2017). For DenseNet, we change the growth rate to 40 to follow the DenseNet-BC-190 specification from (Huang et al., 2017). For mixup, we fix \u03b1 = 1, which results in interpolations \u03bb uniformly distributed between zero and one. All models are trained on a single Nvidia Tesla P100 GPU for 200 epochs on the training set with 128 examples per minibatch, and evaluated on the test set. Learning rates start at 0.1 and are divided by 10 after 100 and 150 epochs for all models except WideResNet. For WideResNet, we follow (Zagoruyko & Komodakis, 2016a) and divide the learning rate by 10 after 60, 120 and 180 epochs. Weight decay is set to 10 \u22124 . We do not use dropout in these experiments.\n\nWe summarize our results in Figure 3a. In both CIFAR-10 and CIFAR-100 classification problems, the models trained using mixup significantly outperform their analogues trained with ERM. As seen in Figure 3b, mixup and ERM converge at a similar speed to their best test errors. Note that the DenseNet models in (Huang et al., 2017) were trained for 300 epochs with further learning rate decays scheduled at the 150 and 225 epochs, which may explain the discrepancy the performance of DenseNet reported in Figure 3a and the original result of Huang et al. (2017).\n\n\nSPEECH DATA\n\nNext, we perform speech recognition experiments using the Google commands dataset (Warden, 2017). The dataset contains 65,000 utterances, where each utterance is about one-second long and belongs to one out of 30 classes. The classes correspond to voice commands such as yes, no, down, left, as pronounced by a few thousand different speakers. To preprocess the utterances, we first extract normalized spectrograms from the original waveforms at a sampling rate of 16 kHz. Next, we zero-pad the spectrograms to equalize their sizes at 160 \u00d7 101. For speech data, it is reasonable to apply mixup both at the waveform and spectrogram levels. Here, we apply mixup at the spectrogram level just before feeding the data to the network.\n\nFor this experiment, we compare a LeNet (Lecun et al., 2001) and a VGG-11 (Simonyan & Zisserman, 2015) architecture, each of them composed by two convolutional and two fully-connected layers. We train each model for 30 epochs with minibatches of 100 examples, using Adam as the optimizer (Kingma & Ba, 2015). Training starts with a learning rate equal to 3 \u00d7 10 \u22123 and is divided by 10 every 10 epochs. For mixup, we use a warm-up period of five epochs where we train the network on  original training examples, since we find it speeds up initial convergence. Table 4 shows that mixup outperforms ERM on this task, specially when using VGG-11, the model with larger capacity.\n\n\nMEMORIZATION OF CORRUPTED LABELS\n\nFollowing , we evaluate the robustness of ERM and mixup models against randomly corrupted labels. We hypothesize that increasing the strength of mixup interpolation \u03b1 should generate virtual examples further from the training examples, making memorization more difficult to achieve. In particular, it should be easier to learn interpolations between real examples compared to memorizing interpolations involving random labels. We adapt an open-source implementation (Zhang, 2017) to generate three CIFAR-10 training sets, where 20%, 50%, or 80% of the labels are replaced by random noise, respectively. All the test labels are kept intact for evaluation. Dropout (Srivastava et al., 2014) is considered the state-of-the-art method for learning with corrupted labels (Arpit et al., 2017). Thus, we compare in these experiments mixup, dropout, and ERM. For mixup, we choose \u03b1 \u2208 {1, 2, 8, 32}; for dropout, we add one dropout layer in each PreAct block after the ReLU activation layer between two convolution layers, as suggested in (Zagoruyko & Komodakis, 2016a). We choose the dropout probability p \u2208 {0.5, 0.7, 0.8, 0.9}. These experiments use the PreAct ResNet-18  model implemented in (Liu, 2017). All the other settings are the same as in Section 3.2.\n\nWe summarize our results in Table 2, where we note the best test error achieved during the training session, as well as the final test error after 200 epochs. To quantify the amount of memorization, we also evaluate the training errors at the last epoch on real labels and corrupted labels. As the training progresses with a smaller learning rate (e.g. less than 0.01), the ERM model starts to overfit the corrupted labels. When using a large probability (e.g. 0.7 or 0.8), dropout can effectively reduce overfitting. Interestingly, mixup with a large \u03b1 (e.g. 8 or 32) outperforms dropout on both the best and last epoch test errors, and achieves lower training error on real labels while remaining resistant to noisy labels.  \n\n\nMetric Method FGSM I-FGSM\n\n\nROBUSTNESS TO ADVERSARIAL EXAMPLES\n\nOne undesirable consequence of models trained using ERM is their fragility to adversarial examples (Szegedy et al., 2014). Adversarial examples are obtained by adding tiny (visually imperceptible) perturbations to legitimate examples in order to deteriorate the performance of the model. The adversarial noise is generated by ascending the gradient of the loss surface with respect to the legitimate example. Improving the robustness to adversarial examples is a topic of active research.\n\nAmong the several methods aiming to solve this problem, some have proposed to penalize the norm of the Jacobian of the model to control its Lipschitz constant (Drucker & Le Cun, 1992;Cisse et al., 2017;Bartlett et al., 2017;Hein & Andriushchenko, 2017). Other approaches perform data augmentation by producing and training on adversarial examples (Goodfellow et al., 2015). Unfortunately, all of these methods add a significant computational overhead to ERM, due to costly regularization (Cisse et al., 2017) or data augmentation (Goodfellow et al., 2015) procedures. Here, we show that mixup can significantly improve the robustness of neural networks without hindering the speed of ERM by penalizing the norm of the gradient of the loss w.r.t a given input along the most plausible directions (e.g. the directions to other training points). Indeed, Figure 2 shows that mixup results in models having a smaller loss and gradient norm between examples compared to vanilla ERM.\n\nTo assess the robustness of mixup models to adversarial examples, we use three ResNet-101 models: two of them trained using ERM on ImageNet-2012, and the third trained using mixup. In the first set of experiments, we study the robustness of one ERM model and the mixup model against white box attacks. That is, for each of the two models, we use the model itself to generate adversarial examples, either using the Fast Gradient Sign Method (FGSM) or the Iterative FGSM (I-FGSM) methods (Goodfellow et al., 2015), allowing a maximum perturbation of = 4 for every pixel. For I-FGSM, we use 10 iterations with equal step size. In the second set of experiments, we evaluate robustness against black box attacks. That is, we use the first ERM model to produce adversarial examples using FGSM and I-FGSM. Then, we test the robustness of the second ERM model and the mixup model to these examples. The results of both settings are summarized in Table 3.\n\nFor the FGSM white box attack, the mixup model is 2.7 times more robust than the ERM model in terms of Top-1 error. For the FGSM black box attack, the mixup model is 1.25 times more robust than the ERM model in terms of Top-1 error. Also, while both mixup and ERM are not robust to white box I-FGSM attacks, mixup is about 40% more robust than ERM in the black box I-FGSM setting. Overall, mixup produces neural networks that are significantly more robust than ERM against adversarial examples in white box and black settings without additional overhead compared to ERM.\n\n\nTABULAR DATA\n\nTo further explore the performance of mixup on non-image data, we performed a series of experiments on six arbitrary classification problems drawn from the UCI dataset (Lichman, 2013). The neural networks in this section are fully-connected, and have two hidden layers of 128 ReLU units. The parameters of these neural networks are learned using Adam (Kingma & Ba, 2015) with default hyper-parameters, over 10 epochs of mini-batches of size 16.   \n\n\nSTABILIZATION OF GENERATIVE ADVERSARIAL NETWORKS (GANS)\n\nGenerative Adversarial Networks, also known as GANs , are a powerful family of implicit generative models. In GANs, a generator and a discriminator compete against each other to model a distribution P . On the one hand, the generator g competes to transform noise vectors z \u223c Q into fake samples g(z) that resemble real samples x \u223c P . On the other hand, the discriminator competes to distinguish between real samples x and fake samples g(z). Mathematically, training a GAN is equivalent to solving the optimization problem\nmax g min d E x,z (d(x), 1) + (d(g(z)), 0),\nwhere is the binary cross entropy loss. Unfortunately, solving the previous min-max equation is a notoriously difficult optimization problem (Goodfellow, 2016), since the discriminator often provides the generator with vanishing gradients. We argue that mixup should stabilize GAN training because it acts as a regularizer on the gradients of the discriminator, akin to the binary classifier in Figure 1b. Then, the smoothness of the discriminator guarantees a stable source of gradient information to the generator. The mixup formulation of GANs is:\nmax g min d E\nx,z,\u03bb (d(\u03bbx + (1 \u2212 \u03bb)g(z)), \u03bb). \n\n\nRELATED WORK\n\nData augmentation lies at the heart of all successful applications of deep learning, ranging from image classification (Krizhevsky et al., 2012) to speech recognition (Graves et al., 2013;Amodei et al., 2016). In all cases, substantial domain knowledge is leveraged to design suitable data transformations leading to improved generalization. In image classification, for example, one routinely uses rotation, translation, cropping, resizing, flipping (Lecun et al., 2001;Simonyan & Zisserman, 2015), and random erasing (Zhong et al., 2017) to enforce visually plausible invariances in the model through the training data. Similarly, in speech recognition, noise injection is a prevalent practice to improve the robustness and accuracy of the trained models (Amodei et al., 2016).\n\nMore related to mixup, DeVries & Taylor (2017) show that interpolation and extrapolation in feature space can improve generalization. However, their proposal only operates at the feature level and does not account for changes in the corresponding labels. Recent approaches have also proposed to regularize the output distribution of a neural network by label smoothing (Szegedy et al., 2016), or penalizing high-confidence softmax distributions (Pereyra et al., 2017). These methods bear similarities with mixup in the sense that supervision depends on multiple smooth labels, rather than on single hard labels as in traditional ERM. However, the label smoothing in these works is applied or regularized independently from the associated feature values.\n\nmixup enjoys several desirable aspects of previous data augmentation and regularization schemes without suffering from their drawbacks. Like the method of DeVries & Taylor (2017), it does not require significant domain knowledge. Like label smoothing, the supervision of every example is not overly dominated by the ground-truth label. Unlike both of these approaches, the mixup transformation establishes a linear relationship between data augmentation and the supervision signal. We believe that this leads to a strong regularizer that improves generalization as demonstrated by our experiments. The linearity constraint, through its effect on the derivatives of the function approximated, also relates mixup to other methods such as Sobolev training of neural networks (Czarnecki et al., 2017) or WGAN-GP (Gulrajani et al., 2017).\n\n\nDISCUSSION\n\nWe have proposed mixup, a data-agnostic and straightforward data augmentation principle. We have shown that mixup is a form of vicinal risk minimization, which trains on virtual examples constructed as the linear interpolation of two random examples from the training set and their labels.\n\nIncorporating mixup into existing training pipelines reduces to a few lines of code, and introduces little or no computational overhead. Throughout an extensive evaluation, we have shown that mixup improves the generalization error of state-of-the-art models on ImageNet, CIFAR, speech, and tabular datasets. Furthermore, mixup helps to combat memorization of corrupt labels, sensitivity to adversarial examples, and instability in adversarial training.\n\nIn our experiments, the following trend is consistent: with increasingly large \u03b1, the training error on real data increases, while the generalization gap decreases. This sustains our hypothesis that mixup implicitly controls model complexity. However, we do not yet have a good theory for understanding the 'sweet spot' of this bias-variance trade-off. For example, in CIFAR-10 classification we can get very low training error on real data even when \u03b1 \u2192 \u221e (i.e., training only on averages of pairs of real examples), whereas in ImageNet classification, the training error on real data increases significantly with \u03b1 \u2192 \u221e. Based on our ImageNet and Google commands experiments with different model architectures, we conjecture that increasing the model capacity would make training error less sensitive to large \u03b1, hence giving mixup a more significant advantage.\n\nmixup also opens up several possibilities for further exploration. First, is it possible to make similar ideas work on other types of supervised learning problems, such as regression and structured prediction? While generalizing mixup to regression problems is straightforward, its application to structured prediction problems such as image segmentation remains less obvious. Second, can similar methods prove helpful beyond supervised learning? The interpolation principle seems like a reasonable inductive bias which might also help in unsupervised, semi-supervised, and reinforcement learning. Can we extend mixup to feature-label extrapolation to guarantee a robust model behavior far away from the training data? Although our discussion of these directions is still speculative, we are excited about the possibilities mixup opens up, and hope that our observations will prove useful for future development.\n\nFigure 1 :\n1Illustration of mixup, which converges to ERM as \u03b1 \u2192 0.\n\n\nerrors in-between training data. Evaluated at x = \u03bbxi +(1\u2212\u03bb)xj, a prediction is counted as a \"miss\" if it does not belong to {yi, yj}. The model trained with mixup has fewer misses. of the gradients of the model w.r.t. input in-between training data, evaluated at x = \u03bbxi + (1 \u2212 \u03bb)xj. The model trained with mixup has smaller gradient norms.\n\nFigure 2 :\n2mixup leads to more robust model behaviors in-between the training data.\n\n\nerror evolution for the best ERM and mixup models.\n\nFigure 3 :\n3Test errors for ERM and mixup on the CIFAR experiments.\n\nFigure 5 :\n5Effect of mixup on stabilizing GAN training at iterations 10, 100, 1000, 10000, and 20000.\n\nFigure 5\n5illustrates the stabilizing effect of mixup the training of GAN (orange samples) when modeling two toy datasets (blue samples). The neural networks in these experiments are fullyconnected and have three hidden layers of 512 ReLU units. The generator network accepts twodimensional Gaussian noise vectors. The networks are trained for 20,000 mini-batches of size 128 using the Adam optimizer with default parameters, where the discriminator is trained for five iterations before every generator iteration. The training of mixup GANs seems promisingly robust to hyper-parameter and architectural choices.\n\n\nResNeXt-101 64*4d ERM (Xie et al., 2016)Table 1: Validation errors for ERM and mixup on the development set of ImageNet-2012.Model \nMethod \nEpochs Top-1 Error Top-5 Error \n\nResNet-50 \nERM (Goyal et al., 2017) \n90 \n23.5 \n-\nmixup \u03b1 = 0.2 \n90 \n23.3 \n6.6 \nResNet-101 \nERM (Goyal et al., 2017) \n90 \n22.1 \n-\nmixup \u03b1 = 0.2 \n90 \n21.5 \n5.6 \nResNeXt-101 32*4d ERM (Xie et al., 2016) \n100 \n21.2 \n-\nERM \n90 \n21.2 \n5.6 \nmixup \u03b1 = 0.4 \n90 \n20.7 \n5.3 \n100 \n20.4 \n5.3 \nmixup \u03b1 = 0.4 \n90 \n19.8 \n4.9 \nResNet-50 \nERM \n200 \n23.6 \n7.0 \nmixup \u03b1 = 0.2 \n200 \n22.1 \n6.1 \nResNet-101 \nERM \n200 \n22.0 \n6.1 \nmixup \u03b1 = 0.2 \n200 \n20.8 \n5.4 \nResNeXt-101 32*4d ERM \n200 \n21.3 \n5.9 \nmixup \u03b1 = 0.4 \n200 \n20.1 \n5.0 \n\n\n\n\nFigure 4: Classification errors of ERM and mixup on the Google commands dataset.Model \n\nMethod \nValidation set Test set \n\nLeNet \nERM \n9.8 \n10.3 \nmixup (\u03b1 = 0.1) \n10.1 \n10.8 \nmixup (\u03b1 = 0.2) \n10.2 \n11.3 \n\nVGG-11 \nERM \n5.0 \n4.6 \nmixup (\u03b1 = 0.1) \n4.0 \n3.8 \nmixup (\u03b1 = 0.2) \n3.9 \n3.4 \n\nLabel corruption Method \nTest error \nTraining error \n\nBest Last \nReal Corrupted \n\n20% \nERM \n12.7 16.6 \n0.05 \n0.28 \nERM + dropout (p = 0.7) \n8.8 10.4 \n5.26 \n83.55 \nmixup (\u03b1 = 8) \n5.9 \n6.4 \n2.27 \n86.32 \n\n50% \nERM \n18.8 44.6 \n0.26 \n0.64 \nERM + dropout (p = 0.8) 14.1 15.5 12.71 \n86.98 \nmixup (\u03b1 = 32) \n11.3 12.7 \n5.84 \n85.71 \n\n80% \nERM \n36.5 73.9 \n0.62 \n0.83 \nERM + dropout (p = 0.8) 30.9 35.1 29.84 \n86.37 \nmixup (\u03b1 = 32) \n25.3 30.9 18.92 \n85.44 \n\n\n\nTable 2 :\n2Results on the corrupted label experiments for the best models.\n\nTable 3 :\n3Classification errors of ERM and mixup models when tested on adversarial examples.\n\nTable 4\n4shows that mixup improves the average test error on four out of the six considered datasets, and never underperforms ERM.Dataset \n\nERM mixup \n\nAbalone \n74.0 \n73.6 \nArcene \n57.6 \n48.0 \nArrhythmia \n56.6 \n46.3 \n\nDataset \nERM mixup \n\nHtru2 \n2.0 \n2.0 \nIris \n21.3 \n17.3 \nPhishing \n16.3 \n15.2 \n\n\n\nTable 4 :\n4ERM and mixup classification errors on the UCI datasets.\nACKNOWLEDGEMENTSWe would like to thank Priya Goyal, Yossi Adi and the PyTorch team.\nDeep speech 2: End-to-end speech recognition in english and mandarin. D Amodei, S Ananthanarayanan, R Anubhai, J Bai, E Battenberg, C Case, J Casper, B Catanzaro, Q Cheng, G Chen, ICML. D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen, et al. Deep speech 2: End-to-end speech recognition in english and mandarin. In ICML, 2016.\n\nA closer look at memorization in deep networks. D Arpit, S Jastrzebski, N Ballas, D Krueger, E Bengio, M S Kanwal, T Maharaj, A Fischer, A Courville, Y Bengio, D. Arpit, S. Jastrzebski, N. Ballas, D. Krueger, E. Bengio, M. S. Kanwal, T. Maharaj, A. Fischer, A. Courville, Y. Bengio, et al. A closer look at memorization in deep networks. ICML, 2017.\n\nP Bartlett, D J Foster, M Telgarsky, Spectrally-normalized margin bounds for neural networks. NIPS. P. Bartlett, D. J. Foster, and M. Telgarsky. Spectrally-normalized margin bounds for neural networks. NIPS, 2017.\n\nO Chapelle, J Weston, L Bottou, V Vapnik, Vicinal risk minimization. NIPS. O. Chapelle, J. Weston, L. Bottou, and V. Vapnik. Vicinal risk minimization. NIPS, 2000.\n\nOne billion word benchmark for measuring progress in statistical language modeling. C Chelba, T Mikolov, M Schuster, Q Ge, T Brants, P Koehn, T Robinson, arXivC. Chelba, T. Mikolov, M. Schuster, Q. Ge, T. Brants, P. Koehn, and T. Robinson. One billion word benchmark for measuring progress in statistical language modeling. arXiv, 2013.\n\nM Cisse, P Bojanowski, E Grave, Y Dauphin, N Usunier, Parseval networks: Improving robustness to adversarial examples. ICML. M. Cisse, P. Bojanowski, E. Grave, Y. Dauphin, and N. Usunier. Parseval networks: Improving robustness to adversarial examples. ICML, 2017.\n\nW M Czarnecki, S Osindero, M Jaderberg, G \u015awirszcz, R Pascanu, Sobolev training for neural networks. NIPS. W. M. Czarnecki, S. Osindero, M. Jaderberg, G.\u015awirszcz, and R. Pascanu. Sobolev training for neural networks. NIPS, 2017.\n\nDataset augmentation in feature space. T Devries, G W Taylor, T. DeVries and G. W. Taylor. Dataset augmentation in feature space. ICLR Workshops, 2017.\n\nImproving generalization performance using double backpropagation. H Drucker, Y Le Cun, IEEE Transactions on Neural Networks. 36H. Drucker and Y. Le Cun. Improving generalization performance using double backpropagation. IEEE Transactions on Neural Networks, 3(6):991-997, 1992.\n\nI Goodfellow, Tutorial: Generative adversarial networks. NIPS. I. Goodfellow. Tutorial: Generative adversarial networks. NIPS, 2016.\n\nI Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Generative adversarial nets. NIPS. I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. NIPS, 2014.\n\nExplaining and harnessing adversarial examples. I J Goodfellow, J Shlens, C Szegedy, ICLRI. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. ICLR, 2015.\n\nP Goyal, P Doll\u00e1r, R Girshick, P Noordhuis, L Wesolowski, A Kyrola, A Tulloch, Y Jia, K He, Accurate, large minibatch SGD: Training imageNet in 1 hour. arXiv. P. Goyal, P. Doll\u00e1r, R. Girshick, P. Noordhuis, L. Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, and K. He. Accurate, large minibatch SGD: Training imageNet in 1 hour. arXiv, 2017.\n\nSpeech recognition with deep recurrent neural networks. A Graves, A Mohamed, G Hinton, ICASSP. IEEE. A. Graves, A.-r. Mohamed, and G. Hinton. Speech recognition with deep recurrent neural networks. In ICASSP. IEEE, 2013.\n\nImproved training of wasserstein gans. I Gulrajani, F Ahmed, M Arjovsky, V Dumoulin, A Courville, I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville. Improved training of wasserstein gans. NIPS, 2017.\n\nNearly-tight VC-dimension bounds for piecewise linear neural networks. N Harvey, C Liaw, A Mehrabian, JMLRN. Harvey, C. Liaw, and A. Mehrabian. Nearly-tight VC-dimension bounds for piecewise linear neural networks. JMLR, 2017.\n\nK He, X Zhang, S Ren, J Sun, Identity mappings in deep residual networks. ECCV. K. He, X. Zhang, S. Ren, and J. Sun. Identity mappings in deep residual networks. ECCV, 2016.\n\nFormal guarantees on the robustness of a classifier against adversarial manipulation. M Hein, M Andriushchenko, M. Hein and M. Andriushchenko. Formal guarantees on the robustness of a classifier against adversarial manipulation. NIPS, 2017.\n\nDeep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. G Hinton, L Deng, D Yu, G E Dahl, A Mohamed, N Jaitly, A Senior, V Vanhoucke, P Nguyen, T N Sainath, IEEE Signal Processing Magazine. G. Hinton, L. Deng, D. Yu, G. E. Dahl, A.-r. Mohamed, N. Jaitly, A. Senior, V. Vanhoucke, P. Nguyen, T. N. Sainath, et al. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, 2012.\n\n. G Huang, Z Liu, L Van Der Maaten, K Q Weinberger, G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. CVPR, 2017.\n\nAdam: A method for stochastic optimization. D Kingma, J Ba, ICLRD. Kingma and J. Ba. Adam: A method for stochastic optimization. ICLR, 2015.\n\nA Krizhevsky, I Sutskever, G E Hinton, ImageNet classification with deep convolutional neural networks. NIPS. A. Krizhevsky, I. Sutskever, and G. E. Hinton. ImageNet classification with deep convolutional neural networks. NIPS, 2012.\n\nGradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of IEEE. IEEEY. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of IEEE, 2001.\n\nUCI machine learning repository. M Lichman, M. Lichman. UCI machine learning repository, 2013.\n\n. K Liu, K. Liu, 2017. URL https://github.com/kuangliu/pytorch-cifar.\n\nRegularizing neural networks by penalizing confident output distributions. G Pereyra, G Tucker, J Chorowski, \u0141 Kaiser, G Hinton, G. Pereyra, G. Tucker, J. Chorowski, \u0141. Kaiser, and G. Hinton. Regularizing neural networks by penalizing confident output distributions. ICLR Workshops, 2017.\n\n. O Russakovsky, J Deng, H Su, J Krause, S Satheesh, S Ma, Z Huang, A Karpathy, A Khosla, M Bernstein, A C Berg, L Fei-Fei, ImageNet large scale visual recognition challenge. IJCVO. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet large scale visual recognition challenge. IJCV, 2015.\n\nMastering the game of Go with deep neural networks and tree search. D Silver, A Huang, C J Maddison, A Guez, L Sifre, G Van Den Driessche, J Schrittwieser, I Antonoglou, V Panneershelvam, M Lanctot, Nature. D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, et al. Mastering the game of Go with deep neural networks and tree search. Nature, 2016.\n\nTransformation invariance in pattern recognitiontangent distance and tangent propagation. P Simard, Y Lecun, J Denker, B Victorri, Neural networks: tricks of the tradeP. Simard, Y. LeCun, J. Denker, and B. Victorri. Transformation invariance in pattern recognitiontangent distance and tangent propagation. Neural networks: tricks of the trade, 1998.\n\nVery deep convolutional networks for large-scale image recognition. K Simonyan, A Zisserman, ICLRK. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. ICLR, 2015.\n\nStriving for simplicity: The all convolutional net. ICLR Workshops. J T Springenberg, A Dosovitskiy, T Brox, M Riedmiller, J. T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller. Striving for simplicity: The all convolutional net. ICLR Workshops, 2015.\n\nDropout: a simple way to prevent neural networks from overfitting. N Srivastava, G E Hinton, A Krizhevsky, I Sutskever, R Salakhutdinov, Journal of Machine Learning Research. 151N. Srivastava, G. E. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1):1929-1958, 2014.\n\nIntriguing properties of neural networks. C Szegedy, W Zaremba, I Sutskever, J Bruna, D Erhan, I J Goodfellow, R Fergus, ICLRC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. J. Goodfellow, and R. Fergus. Intriguing properties of neural networks. ICLR, 2014.\n\nRethinking the inception architecture for computer vision. C Szegedy, V Vanhoucke, S Ioffe, J Shlens, Z Wojna, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionC. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016.\n\nStatistical learning theory. V N Vapnik, J. WileyV. N. Vapnik. Statistical learning theory. J. Wiley, 1998.\n\nOn the uniform convergence of relative frequencies of events to their probabilities. V Vapnik, A Y Chervonenkis, Theory of Probability and its Applications. V. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and its Applications, 1971.\n\n. A Veit, A. Veit, 2017. URL https://github.com/andreasveit. P. Warden, 2017. URL https://research.googleblog.com/2017/08/ launching-speech-commands-dataset.html.\n\nS Xie, R Girshick, P Doll\u00e1r, Z Tu, K He, Aggregated residual transformations for deep neural networks. CVPR. S. Xie, R. Girshick, P. Doll\u00e1r, Z. Tu, and K. He. Aggregated residual transformations for deep neural networks. CVPR, 2016.\n\nS Zagoruyko, N Komodakis, Wide residual networks. BMVC. S. Zagoruyko and N. Komodakis. Wide residual networks. BMVC, 2016a.\n\n. S Zagoruyko, N Komodakis, S. Zagoruyko and N. Komodakis, 2016b. URL https://github.com/szagoruyko/ wide-residual-networks.\n\nUnderstanding deep learning requires rethinking generalization. C Zhang, S Bengio, M Hardt, B Recht, O Vinyals, C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals. Understanding deep learning requires rethinking generalization. ICLR, 2017.\n\n. C Zhang, C. Zhang, 2017. URL https://github.com/pluskid/fitting-random-labels.\n\nZ Zhong, L Zheng, G Kang, S Li, Y Yang, Random erasing data augmentation. arXiv. Z. Zhong, L. Zheng, G. Kang, S. Li, and Y. Yang. Random erasing data augmentation. arXiv, 2017.\n", "annotations": {"author": "[{\"end\":64,\"start\":45},{\"end\":87,\"start\":65},{\"end\":109,\"start\":88},{\"end\":132,\"start\":110},{\"end\":144,\"start\":133}]", "publisher": null, "author_last_name": "[{\"end\":57,\"start\":52},{\"end\":80,\"start\":75},{\"end\":102,\"start\":95},{\"end\":125,\"start\":116},{\"end\":137,\"start\":133}]", "author_first_name": "[{\"end\":51,\"start\":45},{\"end\":74,\"start\":65},{\"end\":92,\"start\":88},{\"end\":94,\"start\":93},{\"end\":115,\"start\":110}]", "author_affiliation": "[{\"end\":63,\"start\":59},{\"end\":86,\"start\":82},{\"end\":108,\"start\":104},{\"end\":131,\"start\":127},{\"end\":143,\"start\":139}]", "title": "[{\"end\":42,\"start\":1},{\"end\":186,\"start\":145}]", "venue": null, "abstract": "[{\"end\":1017,\"start\":188}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b21\"},\"end\":1146,\"start\":1121},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":1217,\"start\":1196},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":1474,\"start\":1460},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":1643,\"start\":1617},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":1762,\"start\":1734},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":1878,\"start\":1858},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2041,\"start\":2013},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2357,\"start\":2336},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2897,\"start\":2875},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3267,\"start\":3246},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3352,\"start\":3329},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3898,\"start\":3877},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6760,\"start\":6746},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":7156,\"start\":7134},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7354,\"start\":7331},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7612,\"start\":7590},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10568,\"start\":10542},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10834,\"start\":10814},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11243,\"start\":11223},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12418,\"start\":12407},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":12516,\"start\":12486},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12551,\"start\":12531},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12582,\"start\":12570},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12699,\"start\":12679},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":13125,\"start\":13095},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13596,\"start\":13576},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13826,\"start\":13807},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14634,\"start\":14615},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14677,\"start\":14649},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14882,\"start\":14863},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":15766,\"start\":15753},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15975,\"start\":15950},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":16073,\"start\":16053},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":16347,\"start\":16317},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":16485,\"start\":16474},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":17458,\"start\":17436},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18010,\"start\":17986},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18029,\"start\":18010},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18051,\"start\":18029},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":18079,\"start\":18051},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18199,\"start\":18174},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18335,\"start\":18315},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18382,\"start\":18357},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":19316,\"start\":19291},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20523,\"start\":20508},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20710,\"start\":20691},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21574,\"start\":21556},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22173,\"start\":22148},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22217,\"start\":22196},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22237,\"start\":22217},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22500,\"start\":22480},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":22527,\"start\":22500},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":22568,\"start\":22548},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22807,\"start\":22786},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23201,\"start\":23179},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23277,\"start\":23255},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":24361,\"start\":24337},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":24397,\"start\":24373}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":27004,\"start\":26936},{\"attributes\":{\"id\":\"fig_1\"},\"end\":27348,\"start\":27005},{\"attributes\":{\"id\":\"fig_2\"},\"end\":27434,\"start\":27349},{\"attributes\":{\"id\":\"fig_3\"},\"end\":27487,\"start\":27435},{\"attributes\":{\"id\":\"fig_4\"},\"end\":27556,\"start\":27488},{\"attributes\":{\"id\":\"fig_5\"},\"end\":27660,\"start\":27557},{\"attributes\":{\"id\":\"fig_6\"},\"end\":28274,\"start\":27661},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":28958,\"start\":28275},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":29689,\"start\":28959},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":29765,\"start\":29690},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":29860,\"start\":29766},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":30159,\"start\":29861},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":30228,\"start\":30160}]", "paragraph": "[{\"end\":1961,\"start\":1033},{\"end\":2358,\"start\":1963},{\"end\":3129,\"start\":2360},{\"end\":4156,\"start\":3131},{\"end\":4348,\"start\":4158},{\"end\":4797,\"start\":4397},{\"end\":5361,\"start\":4799},{\"end\":5389,\"start\":5363},{\"end\":5518,\"start\":5391},{\"end\":6042,\"start\":5564},{\"end\":6358,\"start\":6072},{\"end\":6577,\"start\":6405},{\"end\":7157,\"start\":6644},{\"end\":7924,\"start\":7159},{\"end\":8093,\"start\":8003},{\"end\":8329,\"start\":8191},{\"end\":8634,\"start\":8376},{\"end\":9443,\"start\":8636},{\"end\":10438,\"start\":9445},{\"end\":11059,\"start\":10480},{\"end\":11488,\"start\":11061},{\"end\":12135,\"start\":11490},{\"end\":13265,\"start\":12162},{\"end\":13827,\"start\":13267},{\"end\":14573,\"start\":13843},{\"end\":15250,\"start\":14575},{\"end\":16541,\"start\":15287},{\"end\":17270,\"start\":16543},{\"end\":17825,\"start\":17337},{\"end\":18803,\"start\":17827},{\"end\":19751,\"start\":18805},{\"end\":20323,\"start\":19753},{\"end\":20787,\"start\":20340},{\"end\":21370,\"start\":20847},{\"end\":21965,\"start\":21415},{\"end\":22012,\"start\":21980},{\"end\":22808,\"start\":22029},{\"end\":23563,\"start\":22810},{\"end\":24398,\"start\":23565},{\"end\":24702,\"start\":24413},{\"end\":25157,\"start\":24704},{\"end\":26021,\"start\":25159},{\"end\":26935,\"start\":26023}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4396,\"start\":4349},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6071,\"start\":6043},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6404,\"start\":6359},{\"attributes\":{\"id\":\"formula_3\"},\"end\":6643,\"start\":6578},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7965,\"start\":7925},{\"attributes\":{\"id\":\"formula_5\"},\"end\":8002,\"start\":7965},{\"attributes\":{\"id\":\"formula_6\"},\"end\":8190,\"start\":8094},{\"attributes\":{\"id\":\"formula_7\"},\"end\":8375,\"start\":8330},{\"attributes\":{\"id\":\"formula_8\"},\"end\":21414,\"start\":21371},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21979,\"start\":21966}]", "table_ref": "[{\"end\":11058,\"start\":11051},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":15142,\"start\":15135},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":16578,\"start\":16571},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":19750,\"start\":19743}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1031,\"start\":1019},{\"attributes\":{\"n\":\"2\"},\"end\":5562,\"start\":5521},{\"attributes\":{\"n\":\"3\"},\"end\":10452,\"start\":10441},{\"attributes\":{\"n\":\"3.1\"},\"end\":10478,\"start\":10455},{\"attributes\":{\"n\":\"3.2\"},\"end\":12160,\"start\":12138},{\"attributes\":{\"n\":\"3.3\"},\"end\":13841,\"start\":13830},{\"attributes\":{\"n\":\"3.4\"},\"end\":15285,\"start\":15253},{\"end\":17298,\"start\":17273},{\"attributes\":{\"n\":\"3.5\"},\"end\":17335,\"start\":17301},{\"attributes\":{\"n\":\"3.6\"},\"end\":20338,\"start\":20326},{\"attributes\":{\"n\":\"3.7\"},\"end\":20845,\"start\":20790},{\"attributes\":{\"n\":\"4\"},\"end\":22027,\"start\":22015},{\"attributes\":{\"n\":\"5\"},\"end\":24411,\"start\":24401},{\"end\":26947,\"start\":26937},{\"end\":27360,\"start\":27350},{\"end\":27499,\"start\":27489},{\"end\":27568,\"start\":27558},{\"end\":27670,\"start\":27662},{\"end\":29700,\"start\":29691},{\"end\":29776,\"start\":29767},{\"end\":29869,\"start\":29862},{\"end\":30170,\"start\":30161}]", "table": "[{\"end\":28958,\"start\":28402},{\"end\":29689,\"start\":29041},{\"end\":30159,\"start\":29992}]", "figure_caption": "[{\"end\":27004,\"start\":26949},{\"end\":27348,\"start\":27007},{\"end\":27434,\"start\":27362},{\"end\":27487,\"start\":27437},{\"end\":27556,\"start\":27501},{\"end\":27660,\"start\":27570},{\"end\":28274,\"start\":27672},{\"end\":28402,\"start\":28277},{\"end\":29041,\"start\":28961},{\"end\":29765,\"start\":29702},{\"end\":29860,\"start\":29778},{\"end\":29992,\"start\":29871},{\"end\":30228,\"start\":30172}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8749,\"start\":8740},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9894,\"start\":9885},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":10041,\"start\":10033},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":13304,\"start\":13295},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":13472,\"start\":13463},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":13779,\"start\":13770},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18686,\"start\":18678},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":21819,\"start\":21810}]", "bib_author_first_name": "[{\"end\":30384,\"start\":30383},{\"end\":30394,\"start\":30393},{\"end\":30414,\"start\":30413},{\"end\":30425,\"start\":30424},{\"end\":30432,\"start\":30431},{\"end\":30446,\"start\":30445},{\"end\":30454,\"start\":30453},{\"end\":30464,\"start\":30463},{\"end\":30477,\"start\":30476},{\"end\":30486,\"start\":30485},{\"end\":30761,\"start\":30760},{\"end\":30770,\"start\":30769},{\"end\":30785,\"start\":30784},{\"end\":30795,\"start\":30794},{\"end\":30806,\"start\":30805},{\"end\":30816,\"start\":30815},{\"end\":30818,\"start\":30817},{\"end\":30828,\"start\":30827},{\"end\":30839,\"start\":30838},{\"end\":30850,\"start\":30849},{\"end\":30863,\"start\":30862},{\"end\":31064,\"start\":31063},{\"end\":31076,\"start\":31075},{\"end\":31078,\"start\":31077},{\"end\":31088,\"start\":31087},{\"end\":31279,\"start\":31278},{\"end\":31291,\"start\":31290},{\"end\":31301,\"start\":31300},{\"end\":31311,\"start\":31310},{\"end\":31528,\"start\":31527},{\"end\":31538,\"start\":31537},{\"end\":31549,\"start\":31548},{\"end\":31561,\"start\":31560},{\"end\":31567,\"start\":31566},{\"end\":31577,\"start\":31576},{\"end\":31586,\"start\":31585},{\"end\":31782,\"start\":31781},{\"end\":31791,\"start\":31790},{\"end\":31805,\"start\":31804},{\"end\":31814,\"start\":31813},{\"end\":31825,\"start\":31824},{\"end\":32048,\"start\":32047},{\"end\":32050,\"start\":32049},{\"end\":32063,\"start\":32062},{\"end\":32075,\"start\":32074},{\"end\":32088,\"start\":32087},{\"end\":32100,\"start\":32099},{\"end\":32317,\"start\":32316},{\"end\":32328,\"start\":32327},{\"end\":32330,\"start\":32329},{\"end\":32498,\"start\":32497},{\"end\":32509,\"start\":32508},{\"end\":32711,\"start\":32710},{\"end\":32845,\"start\":32844},{\"end\":32859,\"start\":32858},{\"end\":32876,\"start\":32875},{\"end\":32885,\"start\":32884},{\"end\":32891,\"start\":32890},{\"end\":32907,\"start\":32906},{\"end\":32916,\"start\":32915},{\"end\":32929,\"start\":32928},{\"end\":33170,\"start\":33169},{\"end\":33172,\"start\":33171},{\"end\":33186,\"start\":33185},{\"end\":33196,\"start\":33195},{\"end\":33317,\"start\":33316},{\"end\":33326,\"start\":33325},{\"end\":33336,\"start\":33335},{\"end\":33348,\"start\":33347},{\"end\":33361,\"start\":33360},{\"end\":33375,\"start\":33374},{\"end\":33385,\"start\":33384},{\"end\":33396,\"start\":33395},{\"end\":33403,\"start\":33402},{\"end\":33711,\"start\":33710},{\"end\":33721,\"start\":33720},{\"end\":33732,\"start\":33731},{\"end\":33916,\"start\":33915},{\"end\":33929,\"start\":33928},{\"end\":33938,\"start\":33937},{\"end\":33950,\"start\":33949},{\"end\":33962,\"start\":33961},{\"end\":34166,\"start\":34165},{\"end\":34176,\"start\":34175},{\"end\":34184,\"start\":34183},{\"end\":34323,\"start\":34322},{\"end\":34329,\"start\":34328},{\"end\":34338,\"start\":34337},{\"end\":34345,\"start\":34344},{\"end\":34584,\"start\":34583},{\"end\":34592,\"start\":34591},{\"end\":34848,\"start\":34847},{\"end\":34858,\"start\":34857},{\"end\":34866,\"start\":34865},{\"end\":34872,\"start\":34871},{\"end\":34874,\"start\":34873},{\"end\":34882,\"start\":34881},{\"end\":34893,\"start\":34892},{\"end\":34903,\"start\":34902},{\"end\":34913,\"start\":34912},{\"end\":34926,\"start\":34925},{\"end\":34936,\"start\":34935},{\"end\":34938,\"start\":34937},{\"end\":35255,\"start\":35254},{\"end\":35264,\"start\":35263},{\"end\":35271,\"start\":35270},{\"end\":35289,\"start\":35288},{\"end\":35291,\"start\":35290},{\"end\":35463,\"start\":35462},{\"end\":35473,\"start\":35472},{\"end\":35561,\"start\":35560},{\"end\":35575,\"start\":35574},{\"end\":35588,\"start\":35587},{\"end\":35590,\"start\":35589},{\"end\":35853,\"start\":35852},{\"end\":35862,\"start\":35861},{\"end\":35872,\"start\":35871},{\"end\":35882,\"start\":35881},{\"end\":36084,\"start\":36083},{\"end\":36149,\"start\":36148},{\"end\":36293,\"start\":36292},{\"end\":36304,\"start\":36303},{\"end\":36314,\"start\":36313},{\"end\":36327,\"start\":36326},{\"end\":36337,\"start\":36336},{\"end\":36510,\"start\":36509},{\"end\":36525,\"start\":36524},{\"end\":36533,\"start\":36532},{\"end\":36539,\"start\":36538},{\"end\":36549,\"start\":36548},{\"end\":36561,\"start\":36560},{\"end\":36567,\"start\":36566},{\"end\":36576,\"start\":36575},{\"end\":36588,\"start\":36587},{\"end\":36598,\"start\":36597},{\"end\":36611,\"start\":36610},{\"end\":36613,\"start\":36612},{\"end\":36621,\"start\":36620},{\"end\":36958,\"start\":36957},{\"end\":36968,\"start\":36967},{\"end\":36977,\"start\":36976},{\"end\":36979,\"start\":36978},{\"end\":36991,\"start\":36990},{\"end\":36999,\"start\":36998},{\"end\":37008,\"start\":37007},{\"end\":37029,\"start\":37028},{\"end\":37046,\"start\":37045},{\"end\":37060,\"start\":37059},{\"end\":37078,\"start\":37077},{\"end\":37419,\"start\":37418},{\"end\":37429,\"start\":37428},{\"end\":37438,\"start\":37437},{\"end\":37448,\"start\":37447},{\"end\":37748,\"start\":37747},{\"end\":37760,\"start\":37759},{\"end\":37956,\"start\":37955},{\"end\":37958,\"start\":37957},{\"end\":37974,\"start\":37973},{\"end\":37989,\"start\":37988},{\"end\":37997,\"start\":37996},{\"end\":38217,\"start\":38216},{\"end\":38231,\"start\":38230},{\"end\":38233,\"start\":38232},{\"end\":38243,\"start\":38242},{\"end\":38257,\"start\":38256},{\"end\":38270,\"start\":38269},{\"end\":38579,\"start\":38578},{\"end\":38590,\"start\":38589},{\"end\":38601,\"start\":38600},{\"end\":38614,\"start\":38613},{\"end\":38623,\"start\":38622},{\"end\":38632,\"start\":38631},{\"end\":38634,\"start\":38633},{\"end\":38648,\"start\":38647},{\"end\":38867,\"start\":38866},{\"end\":38878,\"start\":38877},{\"end\":38891,\"start\":38890},{\"end\":38900,\"start\":38899},{\"end\":38910,\"start\":38909},{\"end\":39295,\"start\":39294},{\"end\":39297,\"start\":39296},{\"end\":39460,\"start\":39459},{\"end\":39470,\"start\":39469},{\"end\":39472,\"start\":39471},{\"end\":39704,\"start\":39703},{\"end\":39866,\"start\":39865},{\"end\":39873,\"start\":39872},{\"end\":39885,\"start\":39884},{\"end\":39895,\"start\":39894},{\"end\":39901,\"start\":39900},{\"end\":40100,\"start\":40099},{\"end\":40113,\"start\":40112},{\"end\":40227,\"start\":40226},{\"end\":40240,\"start\":40239},{\"end\":40415,\"start\":40414},{\"end\":40424,\"start\":40423},{\"end\":40434,\"start\":40433},{\"end\":40443,\"start\":40442},{\"end\":40452,\"start\":40451},{\"end\":40599,\"start\":40598},{\"end\":40679,\"start\":40678},{\"end\":40688,\"start\":40687},{\"end\":40697,\"start\":40696},{\"end\":40705,\"start\":40704},{\"end\":40711,\"start\":40710}]", "bib_author_last_name": "[{\"end\":30391,\"start\":30385},{\"end\":30411,\"start\":30395},{\"end\":30422,\"start\":30415},{\"end\":30429,\"start\":30426},{\"end\":30443,\"start\":30433},{\"end\":30451,\"start\":30447},{\"end\":30461,\"start\":30455},{\"end\":30474,\"start\":30465},{\"end\":30483,\"start\":30478},{\"end\":30491,\"start\":30487},{\"end\":30767,\"start\":30762},{\"end\":30782,\"start\":30771},{\"end\":30792,\"start\":30786},{\"end\":30803,\"start\":30796},{\"end\":30813,\"start\":30807},{\"end\":30825,\"start\":30819},{\"end\":30836,\"start\":30829},{\"end\":30847,\"start\":30840},{\"end\":30860,\"start\":30851},{\"end\":30870,\"start\":30864},{\"end\":31073,\"start\":31065},{\"end\":31085,\"start\":31079},{\"end\":31098,\"start\":31089},{\"end\":31288,\"start\":31280},{\"end\":31298,\"start\":31292},{\"end\":31308,\"start\":31302},{\"end\":31318,\"start\":31312},{\"end\":31535,\"start\":31529},{\"end\":31546,\"start\":31539},{\"end\":31558,\"start\":31550},{\"end\":31564,\"start\":31562},{\"end\":31574,\"start\":31568},{\"end\":31583,\"start\":31578},{\"end\":31595,\"start\":31587},{\"end\":31788,\"start\":31783},{\"end\":31802,\"start\":31792},{\"end\":31811,\"start\":31806},{\"end\":31822,\"start\":31815},{\"end\":31833,\"start\":31826},{\"end\":32060,\"start\":32051},{\"end\":32072,\"start\":32064},{\"end\":32085,\"start\":32076},{\"end\":32097,\"start\":32089},{\"end\":32108,\"start\":32101},{\"end\":32325,\"start\":32318},{\"end\":32337,\"start\":32331},{\"end\":32506,\"start\":32499},{\"end\":32516,\"start\":32510},{\"end\":32722,\"start\":32712},{\"end\":32856,\"start\":32846},{\"end\":32873,\"start\":32860},{\"end\":32882,\"start\":32877},{\"end\":32888,\"start\":32886},{\"end\":32904,\"start\":32892},{\"end\":32913,\"start\":32908},{\"end\":32926,\"start\":32917},{\"end\":32936,\"start\":32930},{\"end\":33183,\"start\":33173},{\"end\":33193,\"start\":33187},{\"end\":33204,\"start\":33197},{\"end\":33323,\"start\":33318},{\"end\":33333,\"start\":33327},{\"end\":33345,\"start\":33337},{\"end\":33358,\"start\":33349},{\"end\":33372,\"start\":33362},{\"end\":33382,\"start\":33376},{\"end\":33393,\"start\":33386},{\"end\":33400,\"start\":33397},{\"end\":33406,\"start\":33404},{\"end\":33718,\"start\":33712},{\"end\":33729,\"start\":33722},{\"end\":33739,\"start\":33733},{\"end\":33926,\"start\":33917},{\"end\":33935,\"start\":33930},{\"end\":33947,\"start\":33939},{\"end\":33959,\"start\":33951},{\"end\":33972,\"start\":33963},{\"end\":34173,\"start\":34167},{\"end\":34181,\"start\":34177},{\"end\":34194,\"start\":34185},{\"end\":34326,\"start\":34324},{\"end\":34335,\"start\":34330},{\"end\":34342,\"start\":34339},{\"end\":34349,\"start\":34346},{\"end\":34589,\"start\":34585},{\"end\":34607,\"start\":34593},{\"end\":34855,\"start\":34849},{\"end\":34863,\"start\":34859},{\"end\":34869,\"start\":34867},{\"end\":34879,\"start\":34875},{\"end\":34890,\"start\":34883},{\"end\":34900,\"start\":34894},{\"end\":34910,\"start\":34904},{\"end\":34923,\"start\":34914},{\"end\":34933,\"start\":34927},{\"end\":34946,\"start\":34939},{\"end\":35261,\"start\":35256},{\"end\":35268,\"start\":35265},{\"end\":35286,\"start\":35272},{\"end\":35302,\"start\":35292},{\"end\":35470,\"start\":35464},{\"end\":35476,\"start\":35474},{\"end\":35572,\"start\":35562},{\"end\":35585,\"start\":35576},{\"end\":35597,\"start\":35591},{\"end\":35859,\"start\":35854},{\"end\":35869,\"start\":35863},{\"end\":35879,\"start\":35873},{\"end\":35890,\"start\":35883},{\"end\":36092,\"start\":36085},{\"end\":36153,\"start\":36150},{\"end\":36301,\"start\":36294},{\"end\":36311,\"start\":36305},{\"end\":36324,\"start\":36315},{\"end\":36334,\"start\":36328},{\"end\":36344,\"start\":36338},{\"end\":36522,\"start\":36511},{\"end\":36530,\"start\":36526},{\"end\":36536,\"start\":36534},{\"end\":36546,\"start\":36540},{\"end\":36558,\"start\":36550},{\"end\":36564,\"start\":36562},{\"end\":36573,\"start\":36568},{\"end\":36585,\"start\":36577},{\"end\":36595,\"start\":36589},{\"end\":36608,\"start\":36599},{\"end\":36618,\"start\":36614},{\"end\":36629,\"start\":36622},{\"end\":36965,\"start\":36959},{\"end\":36974,\"start\":36969},{\"end\":36988,\"start\":36980},{\"end\":36996,\"start\":36992},{\"end\":37005,\"start\":37000},{\"end\":37026,\"start\":37009},{\"end\":37043,\"start\":37030},{\"end\":37057,\"start\":37047},{\"end\":37075,\"start\":37061},{\"end\":37086,\"start\":37079},{\"end\":37426,\"start\":37420},{\"end\":37435,\"start\":37430},{\"end\":37445,\"start\":37439},{\"end\":37457,\"start\":37449},{\"end\":37757,\"start\":37749},{\"end\":37770,\"start\":37761},{\"end\":37971,\"start\":37959},{\"end\":37986,\"start\":37975},{\"end\":37994,\"start\":37990},{\"end\":38008,\"start\":37998},{\"end\":38228,\"start\":38218},{\"end\":38240,\"start\":38234},{\"end\":38254,\"start\":38244},{\"end\":38267,\"start\":38258},{\"end\":38284,\"start\":38271},{\"end\":38587,\"start\":38580},{\"end\":38598,\"start\":38591},{\"end\":38611,\"start\":38602},{\"end\":38620,\"start\":38615},{\"end\":38629,\"start\":38624},{\"end\":38645,\"start\":38635},{\"end\":38655,\"start\":38649},{\"end\":38875,\"start\":38868},{\"end\":38888,\"start\":38879},{\"end\":38897,\"start\":38892},{\"end\":38907,\"start\":38901},{\"end\":38916,\"start\":38911},{\"end\":39304,\"start\":39298},{\"end\":39467,\"start\":39461},{\"end\":39485,\"start\":39473},{\"end\":39709,\"start\":39705},{\"end\":39870,\"start\":39867},{\"end\":39882,\"start\":39874},{\"end\":39892,\"start\":39886},{\"end\":39898,\"start\":39896},{\"end\":39904,\"start\":39902},{\"end\":40110,\"start\":40101},{\"end\":40123,\"start\":40114},{\"end\":40237,\"start\":40228},{\"end\":40250,\"start\":40241},{\"end\":40421,\"start\":40416},{\"end\":40431,\"start\":40425},{\"end\":40440,\"start\":40435},{\"end\":40449,\"start\":40444},{\"end\":40460,\"start\":40453},{\"end\":40605,\"start\":40600},{\"end\":40685,\"start\":40680},{\"end\":40694,\"start\":40689},{\"end\":40702,\"start\":40698},{\"end\":40708,\"start\":40706},{\"end\":40716,\"start\":40712}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":11590585},\"end\":30710,\"start\":30313},{\"attributes\":{\"id\":\"b1\"},\"end\":31061,\"start\":30712},{\"attributes\":{\"id\":\"b2\"},\"end\":31276,\"start\":31063},{\"attributes\":{\"id\":\"b3\"},\"end\":31441,\"start\":31278},{\"attributes\":{\"id\":\"b4\"},\"end\":31779,\"start\":31443},{\"attributes\":{\"id\":\"b5\"},\"end\":32045,\"start\":31781},{\"attributes\":{\"id\":\"b6\"},\"end\":32275,\"start\":32047},{\"attributes\":{\"id\":\"b7\"},\"end\":32428,\"start\":32277},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":28693889},\"end\":32708,\"start\":32430},{\"attributes\":{\"id\":\"b9\"},\"end\":32842,\"start\":32710},{\"attributes\":{\"id\":\"b10\"},\"end\":33119,\"start\":32844},{\"attributes\":{\"id\":\"b11\"},\"end\":33314,\"start\":33121},{\"attributes\":{\"id\":\"b12\"},\"end\":33652,\"start\":33316},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":206741496},\"end\":33874,\"start\":33654},{\"attributes\":{\"id\":\"b14\"},\"end\":34092,\"start\":33876},{\"attributes\":{\"id\":\"b15\"},\"end\":34320,\"start\":34094},{\"attributes\":{\"id\":\"b16\"},\"end\":34495,\"start\":34322},{\"attributes\":{\"id\":\"b17\"},\"end\":34737,\"start\":34497},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":206485943},\"end\":35250,\"start\":34739},{\"attributes\":{\"id\":\"b19\"},\"end\":35416,\"start\":35252},{\"attributes\":{\"id\":\"b20\"},\"end\":35558,\"start\":35418},{\"attributes\":{\"id\":\"b21\"},\"end\":35793,\"start\":35560},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":14542261},\"end\":36048,\"start\":35795},{\"attributes\":{\"id\":\"b23\"},\"end\":36144,\"start\":36050},{\"attributes\":{\"id\":\"b24\"},\"end\":36215,\"start\":36146},{\"attributes\":{\"id\":\"b25\"},\"end\":36505,\"start\":36217},{\"attributes\":{\"id\":\"b26\"},\"end\":36887,\"start\":36507},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":515925},\"end\":37326,\"start\":36889},{\"attributes\":{\"id\":\"b28\"},\"end\":37677,\"start\":37328},{\"attributes\":{\"id\":\"b29\"},\"end\":37885,\"start\":37679},{\"attributes\":{\"id\":\"b30\"},\"end\":38147,\"start\":37887},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":6844431},\"end\":38534,\"start\":38149},{\"attributes\":{\"id\":\"b32\"},\"end\":38805,\"start\":38536},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":206593880},\"end\":39263,\"start\":38807},{\"attributes\":{\"id\":\"b34\"},\"end\":39372,\"start\":39265},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":8142232},\"end\":39699,\"start\":39374},{\"attributes\":{\"id\":\"b36\"},\"end\":39863,\"start\":39701},{\"attributes\":{\"id\":\"b37\"},\"end\":40097,\"start\":39865},{\"attributes\":{\"id\":\"b38\"},\"end\":40222,\"start\":40099},{\"attributes\":{\"id\":\"b39\"},\"end\":40348,\"start\":40224},{\"attributes\":{\"id\":\"b40\"},\"end\":40594,\"start\":40350},{\"attributes\":{\"id\":\"b41\"},\"end\":40676,\"start\":40596},{\"attributes\":{\"id\":\"b42\"},\"end\":40854,\"start\":40678}]", "bib_title": "[{\"end\":30381,\"start\":30313},{\"end\":32495,\"start\":32430},{\"end\":33708,\"start\":33654},{\"end\":34845,\"start\":34739},{\"end\":35850,\"start\":35795},{\"end\":36955,\"start\":36889},{\"end\":38214,\"start\":38149},{\"end\":38864,\"start\":38807},{\"end\":39457,\"start\":39374}]", "bib_author": "[{\"end\":30393,\"start\":30383},{\"end\":30413,\"start\":30393},{\"end\":30424,\"start\":30413},{\"end\":30431,\"start\":30424},{\"end\":30445,\"start\":30431},{\"end\":30453,\"start\":30445},{\"end\":30463,\"start\":30453},{\"end\":30476,\"start\":30463},{\"end\":30485,\"start\":30476},{\"end\":30493,\"start\":30485},{\"end\":30769,\"start\":30760},{\"end\":30784,\"start\":30769},{\"end\":30794,\"start\":30784},{\"end\":30805,\"start\":30794},{\"end\":30815,\"start\":30805},{\"end\":30827,\"start\":30815},{\"end\":30838,\"start\":30827},{\"end\":30849,\"start\":30838},{\"end\":30862,\"start\":30849},{\"end\":30872,\"start\":30862},{\"end\":31075,\"start\":31063},{\"end\":31087,\"start\":31075},{\"end\":31100,\"start\":31087},{\"end\":31290,\"start\":31278},{\"end\":31300,\"start\":31290},{\"end\":31310,\"start\":31300},{\"end\":31320,\"start\":31310},{\"end\":31537,\"start\":31527},{\"end\":31548,\"start\":31537},{\"end\":31560,\"start\":31548},{\"end\":31566,\"start\":31560},{\"end\":31576,\"start\":31566},{\"end\":31585,\"start\":31576},{\"end\":31597,\"start\":31585},{\"end\":31790,\"start\":31781},{\"end\":31804,\"start\":31790},{\"end\":31813,\"start\":31804},{\"end\":31824,\"start\":31813},{\"end\":31835,\"start\":31824},{\"end\":32062,\"start\":32047},{\"end\":32074,\"start\":32062},{\"end\":32087,\"start\":32074},{\"end\":32099,\"start\":32087},{\"end\":32110,\"start\":32099},{\"end\":32327,\"start\":32316},{\"end\":32339,\"start\":32327},{\"end\":32508,\"start\":32497},{\"end\":32518,\"start\":32508},{\"end\":32724,\"start\":32710},{\"end\":32858,\"start\":32844},{\"end\":32875,\"start\":32858},{\"end\":32884,\"start\":32875},{\"end\":32890,\"start\":32884},{\"end\":32906,\"start\":32890},{\"end\":32915,\"start\":32906},{\"end\":32928,\"start\":32915},{\"end\":32938,\"start\":32928},{\"end\":33185,\"start\":33169},{\"end\":33195,\"start\":33185},{\"end\":33206,\"start\":33195},{\"end\":33325,\"start\":33316},{\"end\":33335,\"start\":33325},{\"end\":33347,\"start\":33335},{\"end\":33360,\"start\":33347},{\"end\":33374,\"start\":33360},{\"end\":33384,\"start\":33374},{\"end\":33395,\"start\":33384},{\"end\":33402,\"start\":33395},{\"end\":33408,\"start\":33402},{\"end\":33720,\"start\":33710},{\"end\":33731,\"start\":33720},{\"end\":33741,\"start\":33731},{\"end\":33928,\"start\":33915},{\"end\":33937,\"start\":33928},{\"end\":33949,\"start\":33937},{\"end\":33961,\"start\":33949},{\"end\":33974,\"start\":33961},{\"end\":34175,\"start\":34165},{\"end\":34183,\"start\":34175},{\"end\":34196,\"start\":34183},{\"end\":34328,\"start\":34322},{\"end\":34337,\"start\":34328},{\"end\":34344,\"start\":34337},{\"end\":34351,\"start\":34344},{\"end\":34591,\"start\":34583},{\"end\":34609,\"start\":34591},{\"end\":34857,\"start\":34847},{\"end\":34865,\"start\":34857},{\"end\":34871,\"start\":34865},{\"end\":34881,\"start\":34871},{\"end\":34892,\"start\":34881},{\"end\":34902,\"start\":34892},{\"end\":34912,\"start\":34902},{\"end\":34925,\"start\":34912},{\"end\":34935,\"start\":34925},{\"end\":34948,\"start\":34935},{\"end\":35263,\"start\":35254},{\"end\":35270,\"start\":35263},{\"end\":35288,\"start\":35270},{\"end\":35304,\"start\":35288},{\"end\":35472,\"start\":35462},{\"end\":35478,\"start\":35472},{\"end\":35574,\"start\":35560},{\"end\":35587,\"start\":35574},{\"end\":35599,\"start\":35587},{\"end\":35861,\"start\":35852},{\"end\":35871,\"start\":35861},{\"end\":35881,\"start\":35871},{\"end\":35892,\"start\":35881},{\"end\":36094,\"start\":36083},{\"end\":36155,\"start\":36148},{\"end\":36303,\"start\":36292},{\"end\":36313,\"start\":36303},{\"end\":36326,\"start\":36313},{\"end\":36336,\"start\":36326},{\"end\":36346,\"start\":36336},{\"end\":36524,\"start\":36509},{\"end\":36532,\"start\":36524},{\"end\":36538,\"start\":36532},{\"end\":36548,\"start\":36538},{\"end\":36560,\"start\":36548},{\"end\":36566,\"start\":36560},{\"end\":36575,\"start\":36566},{\"end\":36587,\"start\":36575},{\"end\":36597,\"start\":36587},{\"end\":36610,\"start\":36597},{\"end\":36620,\"start\":36610},{\"end\":36631,\"start\":36620},{\"end\":36967,\"start\":36957},{\"end\":36976,\"start\":36967},{\"end\":36990,\"start\":36976},{\"end\":36998,\"start\":36990},{\"end\":37007,\"start\":36998},{\"end\":37028,\"start\":37007},{\"end\":37045,\"start\":37028},{\"end\":37059,\"start\":37045},{\"end\":37077,\"start\":37059},{\"end\":37088,\"start\":37077},{\"end\":37428,\"start\":37418},{\"end\":37437,\"start\":37428},{\"end\":37447,\"start\":37437},{\"end\":37459,\"start\":37447},{\"end\":37759,\"start\":37747},{\"end\":37772,\"start\":37759},{\"end\":37973,\"start\":37955},{\"end\":37988,\"start\":37973},{\"end\":37996,\"start\":37988},{\"end\":38010,\"start\":37996},{\"end\":38230,\"start\":38216},{\"end\":38242,\"start\":38230},{\"end\":38256,\"start\":38242},{\"end\":38269,\"start\":38256},{\"end\":38286,\"start\":38269},{\"end\":38589,\"start\":38578},{\"end\":38600,\"start\":38589},{\"end\":38613,\"start\":38600},{\"end\":38622,\"start\":38613},{\"end\":38631,\"start\":38622},{\"end\":38647,\"start\":38631},{\"end\":38657,\"start\":38647},{\"end\":38877,\"start\":38866},{\"end\":38890,\"start\":38877},{\"end\":38899,\"start\":38890},{\"end\":38909,\"start\":38899},{\"end\":38918,\"start\":38909},{\"end\":39306,\"start\":39294},{\"end\":39469,\"start\":39459},{\"end\":39487,\"start\":39469},{\"end\":39711,\"start\":39703},{\"end\":39872,\"start\":39865},{\"end\":39884,\"start\":39872},{\"end\":39894,\"start\":39884},{\"end\":39900,\"start\":39894},{\"end\":39906,\"start\":39900},{\"end\":40112,\"start\":40099},{\"end\":40125,\"start\":40112},{\"end\":40239,\"start\":40226},{\"end\":40252,\"start\":40239},{\"end\":40423,\"start\":40414},{\"end\":40433,\"start\":40423},{\"end\":40442,\"start\":40433},{\"end\":40451,\"start\":40442},{\"end\":40462,\"start\":40451},{\"end\":40607,\"start\":40598},{\"end\":40687,\"start\":40678},{\"end\":40696,\"start\":40687},{\"end\":40704,\"start\":40696},{\"end\":40710,\"start\":40704},{\"end\":40718,\"start\":40710}]", "bib_venue": "[{\"end\":35917,\"start\":35913},{\"end\":39059,\"start\":38997},{\"end\":30497,\"start\":30493},{\"end\":30758,\"start\":30712},{\"end\":31161,\"start\":31100},{\"end\":31351,\"start\":31320},{\"end\":31525,\"start\":31443},{\"end\":31904,\"start\":31835},{\"end\":32152,\"start\":32110},{\"end\":32314,\"start\":32277},{\"end\":32554,\"start\":32518},{\"end\":32771,\"start\":32724},{\"end\":32971,\"start\":32938},{\"end\":33167,\"start\":33121},{\"end\":33473,\"start\":33408},{\"end\":33753,\"start\":33741},{\"end\":33913,\"start\":33876},{\"end\":34163,\"start\":34094},{\"end\":34400,\"start\":34351},{\"end\":34581,\"start\":34497},{\"end\":34979,\"start\":34948},{\"end\":35460,\"start\":35418},{\"end\":35668,\"start\":35599},{\"end\":35911,\"start\":35892},{\"end\":36081,\"start\":36050},{\"end\":36290,\"start\":36217},{\"end\":37094,\"start\":37088},{\"end\":37416,\"start\":37328},{\"end\":37745,\"start\":37679},{\"end\":37953,\"start\":37887},{\"end\":38322,\"start\":38286},{\"end\":38576,\"start\":38536},{\"end\":38995,\"start\":38918},{\"end\":39292,\"start\":39265},{\"end\":39529,\"start\":39487},{\"end\":39972,\"start\":39906},{\"end\":40153,\"start\":40125},{\"end\":40412,\"start\":40350},{\"end\":40757,\"start\":40718}]"}}}, "year": 2023, "month": 12, "day": 17}