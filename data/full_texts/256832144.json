{"id": 256832144, "updated": "2023-03-09 14:33:30.123", "metadata": {"title": "BA-GNN: Behavior-aware graph neural network for session-based recommendation", "authors": "[{\"first\":\"Yongquan\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Qiuyu\",\"last\":\"Song\",\"middle\":[]},{\"first\":\"Zhongying\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Hui\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Maoguo\",\"last\":\"Gong\",\"middle\":[]}]", "venue": "Frontiers of Computer Science", "journal": "Frontiers of Computer Science", "publication_date": {"year": 2023, "month": 2, "day": 14}, "abstract": "Session-based recommendation is a popular research topic that aims to predict users\u2019 next possible interactive item by exploiting anonymous sessions. The existing studies mainly focus on making predictions by considering users\u2019 single interactive behavior. Some recent efforts have been made to exploit multiple interactive behaviors, but they generally ignore the influences of different interactive behaviors and the noise in interactive sequences. To address these problems, we propose a behavior-aware graph neural network for session-based recommendation. First, different interactive sequences are modeled as directed graphs. Thus, the item representations are learned via graph neural networks. Then, a sparse self-attention module is designed to remove the noise in behavior sequences. Finally, the representations of different behavior sequences are aggregated with the gating mechanism to obtain the session representations. Experimental results on two public datasets show that our proposed method outperforms all competitive baselines. The source code is available at the website of GitHub.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/fcsc/LiangSZZG23", "doi": "10.1007/s11704-022-2324-x"}}, "content": {"source": {"pdf_hash": "786125bb641c8d6d45afc0deaaf7fe08e02a485b", "pdf_src": "Springer", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "13ae3be099673e294df66e01155e90772894e548", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/786125bb641c8d6d45afc0deaaf7fe08e02a485b.txt", "contents": "\nBA-GNN: Behavior-aware graph neural network for session-based recommendation\n\n\nYongquan Liang \nSchool of Computer Science and Engineering\nShandong University of Science and Technology\n266590QingdaoChina\n\nQiuyu Song \nSchool of Computer Science and Engineering\nShandong University of Science and Technology\n266590QingdaoChina\n\nZhongying Zhao \nSchool of Computer Science and Engineering\nShandong University of Science and Technology\n266590QingdaoChina\n\nHui Zhou \nSchool of Electronic Engineering\nXidian University\nXi'an 710071China\n\nMaoguo Gong \nSchool of Computer Science and Engineering\nShandong University of Science and Technology\n266590QingdaoChina\n\nSchool of Electronic Engineering\nXidian University\nXi'an 710071China\n\nBA-GNN: Behavior-aware graph neural network for session-based recommendation\n10.1007/s11704-022-2324-xHigher Education Press 2023session-based recommendationmultiple inter- active behaviorsgraph neural networks\nSession-based recommendation is a popular research topic that aims to predict users' next possible interactive item by exploiting anonymous sessions. The existing studies mainly focus on making predictions by considering users' single interactive behavior. Some recent efforts have been made to exploit multiple interactive behaviors, but they generally ignore the influences of different interactive behaviors and the noise in interactive sequences. To address these problems, we propose a behavior-aware graph neural network for session-based recommendation. First, different interactive sequences are modeled as directed graphs. Thus, the item representations are learned via graph neural networks. Then, a sparse self-attention module is designed to remove the noise in behavior sequences. Finally, the representations of different behavior sequences are aggregated with the gating mechanism to obtain the session representations. Experimental results on two public datasets show that our proposed method outperforms all competitive baselines. The source code is available at the website of GitHub.\n\nIntroduction\n\nWith the rapid development of Internet technology, the explosive generation of data has brought about a severe information overload problem. Recommendation system can quickly provide us with the information that we are interested in by mining the historical interaction data and modeling users' profiles or preferences. However, it is usually difficult to obtain users' profiles because of privacy protection. In addition, users' preferences are instantaneous and variable, making it difficult to mine long-term user interests. To solve the above problems, researchers propose session-based recommendation (SR for short). SR refers to predicting the next interactive item that users may be interested in by mining the hidden preference in an anonymous session, where the session consists of multiple items that a user has clicked or bought in the past time slot [1]. Thus, SR is able to capture users' short-term and variable preferences, providing more timely and accurate recommendations for users. SR has become a popular research direction in recent years.\n\nThe majority of popular SR methods are mainly designed based on deep neural networks. For example, GRU4Rec [2] and NARM [3] are based on Recurrent Neural Network (RNN). They capture the dynamic users' preferences. The methods based on Graph Neural Network(GNN) model sessions as graphs and capture complex item transitions [4\u22127]. Although the above methods perform well and promote this area quickly, they only exploit single interactive behavior during the recommendation.\n\nIn fact, the session contains different types of behaviors. For example, a user may first click on an item and then perform a series of actions such as favorites, purchases. These actions are beneficial to mine users' dynamic preferences, and then improve the accuracy of recommendation.\n\nTherefore, recent studies are carried out to take multiple interactive behaviors into consideration. Wang et al. [8] proposed MGNN-SPred which constructs a multi-relational behavior graph based on two kinds of action sequences. With the help of all interactive behaviors, the users' preference representations are well learned, significantly improving the accuracy of the recommendation. However, the following limitations remain to be overcome.\n\n(1) Various types of interactive actions have different effects on recommendation. As is shown in Fig. 1(a), a user clicks foundation, lipstick, perfume, and eye shadow, and finally buy a bottle of foundation. It implies that the user is interested in make-up. The previous efforts on multiple actions focus on treating a certain action as a target, and the other actions are considered as auxiliaries. To model users' real preferences and improve the performance of recommendation, both the actions of click and buy should be considered simultaneously.\n\n(2) Noise is widely existed in historical interactive data. It is common that we may click a certain item or advertisement accidentally, when we browse what we are interested in. As is shown in Fig. 1(b), a user clicks foundation, lipstick, mouse, perfume, shoes and buys a lipstick. Obviously, the mouse and shoes are noise data that should be removed.\n\nTo solve these problems, we propose a behavior-aware graph neural network for session-based recommendation, BA-GNN. Specifically, we first construct directed graphs for click and purchase sequences to obtain the item representations. Then, a sparse self-attention module is designed to remove the noise in click sequences. The session representations are composed of the behavior sequences representations. Finally, we predict the users' next interactive items by session representations and item representations.\n\nOur main contributions are summarized as follows:\n\n\u2022 We propose a behavior-aware graph neural network for session-based recommendation. We fully consider the influences of different interactive behaviors, and construct directed graphs for the sequences with two kinds of interactive actions, respectively. \u2022 To remove the noise in interactive behavior sequences, we design a sparse self-attention module that obtains better sequence representations. \u2022 We conduct extensive experiments on two public datasets and compare with multiple baselines. The experimental results show that our proposed method achieves the best performance.\n\n\nRelated work\n\nTraditional SR methods are based on Markov Chain and nearest neighbor. Shani et al. [9] exploited Markov Chain to capture sequence signals in sessions. Rendle et al. [10] combined Markov Chain with the matrix factorization, which imitates the behavior sequence by combining two neighboring clicks. Garg et al. [11], Jannach and Ludewig [12] defined a neighbor session as a session that contains any item of the current session. Although the above methods are effective, they cannot capture the high-order structural features of sequences.\n\nIn recent years, with the rapid development of deep learning, SR methods based on neural networks have been widely used. For example, Hidasi et al. [2] utilized RNN with Gated Recurrent Unit (GRU) for the first time, and added the GRU layer to capture the interactive sequences. Tan et al. [13] used RNN to capture the sequential information and optimized the method by data augmentation. Li et al. [3] utilized RNN and an attention mechanism to capture the user's global and local preference representations in the current session. Liu et al. [14] proposed a short-term memory priority method based on Multilayer Perceptron (MLP). This method captures the user's current interest by the last click, and obtains the global interest via an attention mechanism. Song et al. [15] exploited a Variational Auto-encoder (VAE) to combine the user's long-term interest and short-term interest, and applied RNN to capture the user's interest transformation. Wang et al. [16] proposed a mixed channel method to accommodate the user's multi-purpose item subset, recommending more diverse items to satisfy the user's different purposes.\n\nWu et al. [5] first applied GNN in SR by converting sessions into directed graphs. This method generates item representations via Gated Graph Neural Network (GGNN), and then fusing item representations to obtain the session representations. Yu et al. [7] designed a target-aware attention mechanism based on SR-GNN to activate interest in target items for different users. Xu et al. [6] proposed a method that captures the global dependencies of items with a self-attention mechanism. Wang et al. [4] used GNN to learn session-level item representations based on the current session graph and global-level item representations based on the global graph, respectively, and then combined them with a position-aware attention mechanism to obtain the final session representation. Qiu et al.\n\n[17] designed a weighted attention layer to learn the embedding of items, and proposed a readout function to generate session embeddings based on the learned node features. Gwadabe and Liu [18] applied Graph Convolutional Network(GCN) to learn the general session interest and GGNN to learn the sequential patterns.\n\nAll the above methods only exploit single interaction behavior information, ignoring the effects of multiple interactive behaviors for users' interests. Therefore, Le et al. [19] proposed CBS which uses twin networks (dual RNN architecture) to improve the accuracy of next-item recommendation. Meng et al. [20] integrated users' multiple interactive behaviors and item knowledge into multi-task learning. This method captures item transition patterns in sessions. Wang et al. [8] constructed a multi-relational item graph based on all behavior sequences, and learned the global item representations to capture users' preferences.\n\nIn this paper, we take both the advantages of GNN and multiple behavior information while subtly removing noise interference with session representations.\n\n\nPreliminaries\n\n\nProblem statement\nV = {v 1 , v 2 , . . . , v m } s s = [ v s,1 , v s,2 , . . . , v s,n ] v s,i \u2208 V i s(c) = [ v c,1 , v c,2 , . . . , v c,|s(c)| ] s v c,i \u2208 V i s(p) = [ v p,1 , v p,2 , . . . , v p,|s(p)| ] s v p,i \u2208 V i\nLet denote a set of items. The sequence of items for session is denoted as , where denotes the th item in the sequence.\n\ndenotes the click sequence in session , where denotes the th item clicked by the user. denotes the purchase sequence in session , where denotes the -th item purchased by the user.\n\n\ns s(c) s(p)\n\n\nProblem. Prediction of session-based recommendation.\n\nGiven a session , two kinds of action graphs are constructed by the click sequence and the purchase sequence , respectively. The goal of session recommendation is to predict the next item that the user is most likely to interact with. The input is all sessions. The output is the probability that all candidate items interact with users. The notations mainly used in this paper are shown in Table 1.\n\n\nThe proposed method\n4.1 Overall framework s = [ v c,1 , v c,2 , v c,4 , v c,3 , v c,2 , v p,1 , v p,4 , v p,3 ]\nThe overall framework is shown in Fig. 2. For a session , BA-GNN consists of the following five modules: (1) Constructing graphs. It is used to construct directed graphs for different action sequences.         The overall framework of our proposed method. We first construct directed graphs for different action sequences. Then we learn the behavior-level item representations via GGNN. Next, a sparse self-attention module is designed to remove the noise in the click sequences. After that, we learn representations for action sequences and sessions. Finally, we make predictions and recommendations Yongquan LIANG et al. BA-GNN: Behavior-aware graph neural network for session-based recommendation 3\n\nrepresentation, output the probability of the selected item, and make recommendations for users.\n\n\nConstructing graphs\nb G b = (V, E b ) v b,i \u2208 V i b ( v b,i\u22121 , v b,i ) \u2208 E b v b,i\u22121 v b,i b A b G b A (out) b A (in) b\nFor a particular behavior sequence , we construct the graph , where the node denotes the th item in the sequence , the edge denotes the node and are adjacent interactive items in the sequence , and denotes the adjacency matrix of the graph which is a concatenation of the out-degree matrix and the indegree matrix .\nG c G p V = {v 1 , v 2 , . . . , v m }\nAccording to the above construction, we get the click sequence graph and the purchase sequence graph . All nodes are embedded into a uniform vector space and obtained the initial representations by random initialization.\n\n\nBehavior-level item representations\nv c,i G c v c,i\nInspired by SR-GNN [5], GGNN [21] can be used to learn behavior-level item representations. For a node in the click graph , the update functions of the node vector is shown as follows:\na (t) c,i = A T c,i: [ v (t\u22121) c,1 , . . . , v (t\u22121) c,|s(c)| ] T + b,(1)z (t) c,i = \u03c3 ( W z a (t) c,i + U z v (t\u22121) c,i ) ,(2)r (t) c,i = \u03c3 ( W r a (t) c,i + U r v (t\u22121) c,i ) , (3) v (t) c,i = tanh ( W o a (t) c,i + U o ( r (t) c,i \u2299 v (t\u22121) c,i )) ,(4)v (t) c,i = ( 1 \u2212 z (t) c,i ) \u2299 v (t\u22121) c,i + z (t) c,i \u2299 v (t) c,i ,(5)t A c,i: A c v c,i [ v (t\u22121) c,1 , . . . , v (t\u22121) c,|s(c)| ] (t \u2212 1) b a (t) c,i v c,i z c,i ( 1 \u2212 z (t) c,i ) r c,i \u03c3(\u00b7) \u2299 W U v (t) c,i v c,i\nwhere is the number of node propagation, is the two columns of the adjacency matrix corresponding to the node , denotes the list of node vectors of the click sequence in the step propagation, is the bias vector, denotes the representation of the current node vector after combining it with the connected node vectors in the graph, denotes the update gate, which is controlled by to forget the information, denotes the reset gate, which is controlled to generate new information, denotes the sigmoid activation function, denotes the element-wise multiplication operator, and are the trainable parameter matrices, and is the final representation of the updated node vector . \nc,i v c = [ v c,1 , v c,2 , . . . , v c,|s(c)| ]\nAfter updating all node vectors in the graph to reach convergence, the click item representation of behaviorlevel is obtained, and the node vector list of the click sequence is denoted as\n\n.\nv p,i v p = [ v p,1 , v p,2 , . . . , v p,|s(p)| ]\nThe update process of node vectors in the purchase sequence is the same as the click sequence. After updating all node vectors in the graph to reach convergence, the purchase item representation of behavior-level is obtained, and the node vector list of the purchase sequence is denoted as\n\n.\nv g,i\nThe global item representation is obtained by summing the node vector of the two action sequences:\nv g,i = v c,i + v p,i .(6)\n\nSparse self-attention module\n\nThe attention mechanism requires a transformation function to convert attention weights into probabilities, and the current widely used transformation function is the softmax function [22]. However, when there is noise in data, the softmax function assigns weights to noise data, limiting the item representations. The sparsemax function [23] is proposed to solve this problem. It converges the weight to zero for data with lower weights, thus eliminating the effect of noise on item representations. In this paper, we use the sparsemax function instead of the softmax function in the attention mechanism to remove the noise in click sequences. The sparsemax function is shown in Eq. (7):\nF(x) = argmin p\u2208\u2206 d\u22121 ||p\u2212 x|| 2 ,(7)\u2206 d\u22121 = { p \u2208 R d | 1 T p = 1, p \u2a7e 0 } d \u2212 1 x p\nwhere denotes the dimensional simplex, and denote the input vector and output vector, respectively.\n\nUsers may have mistaken touches when clicking on items, resulting in noise in the click sequences. To solve this problem, inspired by DSAN [24], a sparse self-attention module is designed to reduce the effect of noise, and obtain more effective behavior sequence representations.\n\nScaled Dot-Product Attention [25] is used to capture the dependencies between pairs of items in the sequence, combined with the sparsemax function to obtain item representations with the attention weights:\nA(Q, K, V) = sparsemax ( QK T \u221a d ) V,(8)Q K V Q = V = v c Q K Q\nwhere is the query value matrix, is the key matrix, and is the value matrix of the item. For each click sequence, let , and to distinguish from , is transformed projectively as shown in Eq. (9):\nK = f (v c W K + b K )\n,\n(9) f (\u00b7) W K b K\nwhere denotes the ReLU activation function, denotes the weight matrix, and denotes the bias vector. Nonlinear transformations are made on Position-wise Feed-Forward Networks [25]:\nF(A(Q, K, V)) = max (0, A(Q, K, V)W 1 + b 1 )W 2 + b 2 ,(10)W 1 W 2 b 1 b 2 where\n, denote the weight matrices and , denote the bias vectors, respectively.\n\nThe sparse self-attentive module is defined formally as shown in Eq. (11): To reduce the complexity, the mean-pooling operation is used to obtain the behavior sequence representations [8]. Let\nx c = SSAN (v c ) ,(11)s(c) z s(p) s(p)\ndenotes the representation of the click sequence , and denotes the representation of the purchase sequence :\nz s(c) = \u2211 |s(c)| i=1 x c,i |s(c)| . (12) z s(p) = \u2211 |s(p)| i=1 v p,i |s(p)| .(13)\nConsidering that each action has different influences on the session representation, the importance weights of the click sequence are calculated using a gated attention mechanism, as shown in Eq. (14): The session representation is obtained by making a weighted sum of the click sequence representation and the purchase sequence representation , as shown in Eq. (15):\n\u03b1 = \u03c3 ( W s [z s(c) ; z s(p) ] ) ,(14)s = \u03b1 \u00b7 z s(c) + (1 \u2212 \u03b1) \u00b7 z s(p) .(15)\n\nPrediction and recommendation\ns v g,\u00ee z i v i \u2208 V\nTo predict the probability of each candidate item being interacted with, the session representation multiply with the global item representation to calculate the recommendation score for each candidate item :\n\u1e91 i = s T v g,i .(16)\nz\u0177 The score vectors for all candidate items need to be normalized. We apply the softmax function and calculate the probability distribution , as shown in Eq. (17):\n\u0177 = softmax(\u1e91).\n(17) The loss function is defined as a binary cross-entropy loss. We optimize our method by minimizing the loss, as shown in Eq. (18):\nL(\u0177) = \u2212 m \u2211 i=1 y i log (\u0177 i ) + (1 \u2212 y i ) log (1 \u2212\u0177 i ) ,(18)\ny where denotes the one-hot encoding vector of the item ground truth.\n\n\nExperiments\n\n\nDatasets\n\nWe conduct experiments on two public datasets to verify the effectiveness of our proposed method. The details of the datasets are shown in Table 2.\n\nYoochoose: The Yoochoose dataset is created for the RecSys Challenge 2015 and contains data from consumers' behavior data on an e-commerce website over the course of six months. The interactive actions used in our experiments are click and purchase.\n\n\nREES46 (Cosmetics):\n\nThe REES46 (Cosmetics) comes from the REES46 Marketing Platform which contains users' behavior data in an online cosmetic store within 5 months. The interactive actions used in our experiments are click and purchase.\ns(p) = [ v p,1 , v p,2 , . . . , v p,|s(p)| ] ([ v p,1 ] , v p,2 ) , ([ v p,1 , v p,2 ] , v p,3 ) , . . . , ([ v p,1 , v p,2 , . . . , v p,|s(p)|\u22121 ] , v p,|s(p)| ) s(c) = [ v c,1 , v c,2 , . . . , v c,|s(c)| ]\nFor the experiments, we processed the dataset as follows: (1) We filter out sessions that are 1 in length. (2) Each session is processed into a purchase sequence and a click sequence.\n\n(3) For all behavior sequences, we establish a maximum sequence length L, and then we only keep the last L items when the sequence length is longer than L. (4) The sequences and labels are generated by splitting the behavior sequences. For the purchase sequence , the inputs and labels are . For the click sequence , only keep the click items before being purchased, avoiding the labels are known. (5) We divide the first 4/5 of datasets into training data in chronological order, and use 1/3 of the remaining data as the validation data to optimize the hyper-parameters, and 2/3 of the remaining data as the test data.\n\n\nBaselines\n\nTo verify the effectiveness of our proposed method, we compared it with different types of baselines. Two traditional methods are POP and Item-KNN, three RNN-based methods are GRU4Rec, NARM and STAMP, two GNN-based methods are SR-GNN and GC-SAN, and a multiple interactive behavior method is MGNN-SPred. POP: The top K frequently appearing items in the training set are counted and recommended as the top K items.\n\nItem-KNN [26]: It recommends the item that is most similar to the current session's item. The cosine similarity is used to calculate the distance between item vectors.\n\nGRU4Rec [2]: It models sessions by RNN and captures the interaction sequences of items through the GRU layer.\n\nNARM [3]: It generates item representations using RNN. The global and local preference representations are then acquired via an attention mechanism.\n\nSTAMP [14]: It learns general interest representations from the long-term memory and current interest representations from the short-term memory. The session representation is obtained by combining the two interest representations. SR-GNN [5]: It creates a directed graph from the session and uses GGNN to capture the complex item transition patterns. The session representations are generated by the attention mechanism.\n\nGC-SAN [6]: It uses GGNN to generate item representations. The session representations are attained by a selfattention mechanism. This method has the ability to capture item global dependencies.\n\nMGNN-Spred [8]: It designs an MGNN network for learning the relationships between global items and fusing target and auxiliary behavior sequences into a session representation through a gating mechanism. For the baseline methods, we use the same parameter settings suggested in their paper.\n\n\nEvaluation Metrics\n\nThree common evaluation metrics used in this paper are HR@K, MRR@K, and NDCG@K. They are abbreviated as H@K, M@K, and N@K, respectively.\n\nHR@K: It calculates the proportion of accurately recommended items among the top-K items in the recommendation list.\n\nMRR@K: It calculates the average of the reciprocal rankings of accurately recommended items. The countdown rank is set to 0 when the rank exceeds K. MRR takes into account the order in which recommendations are ranked, with a higher MRR number indicating that the accurate recommendation is at the top of the list.\n\nNDCG@K: It is used to evaluate the correctness of sorting results. The DCG score of each user's actual list is calculated, which is represented by IDCG, then normalizes each user's score using the ratio of DCG to IDCG, and finally averages each user's score to reach the result.\n\n\nParameter settings\n\nIn our method, all parameters are initialized using a Gaussian distribution with mean 0 and standard deviation 0.1. The dimension of embedding is 64, the batch size is 64, the dropout rate is 0.5, the learning rate is 0.001, the optimizer is the default Adam optimizer. In Yoochoose, the propagation step of GGNN is set to 2, in REES46 (Cosmetics) is set to 3. In both datasets, the epoch is set to 100. We use the early stopping to solve the problem of model overfitting. The early stop round is set to 30. When the metrics in the validation set do not improve within 30 consecutive epochs, the iteration is stopped.\n\nIn GRU4Rec, the mini-batch size is set to 500, and the initial learning rate is 0.01. In NARM, the dimension of item embedding is 50, the initial learning rate sets to 0.001, and the mini-batch size is 512. In STAMP, the dimension of item embedding is 100, and the initial learning rate sets to 0.005, the mini-batch setting is 512. In SR-GNN, the dimension of item embedding is 100, the initial learning rate is set to 0.001, and the batch size is 100. In GC-SAN, the dimension of item embedding is 100, the initial learning rate is set to 0.001, and the batch size is 50. In MGNN-Spred, the dimension of item embedding is 64, and the mini-batch size is 64.\n\n\nComparison with baselines\n\nWe carried out some experiments and compared results with baselines to demonstrate the overall performance of our proposed method. The evaluation results of the top-100 recommendations are shown in Table 3, and bold font indicates the best results. The \"Improve\" row displays the rising percentage of BA-GNN over baselines with the best result.\n\nAs is shown in Table 3, BA-GNN attains the optimal results on both datasets, with an improvement of 4.0%\u221226.9% on Yoochoose and 4.8%\u22129.2% on REES46 (Cosmetics). The following conclusions can be drawn from Table 3:\n\n(1) POP and Item-KNN are traditional recommendation methods. POP recommends based on the frequency of items in the training set and regards the items most frequently clicked as the user's interest. Item-KNN recommends based on the cosine similarity between the current item and the previous items, it only recommends items with high similarity. Item-KNN performs better than POP, that is because Item-KNN is able to capture the similarity between items. However, these two methods do not consider users' complex item transitions, and they cannot capture dependencies between items, thus limiting the effect of recommendation.\n\n(2) GRU4Rec, NARM, and STAMP are three methods implemented based on RNN. GRU4Rec uses GRU unit to capture the sequence information of the session, and achieves good results in both datasets. NARM further uses the attention mechanism on the basis of GRU4Rec, and achieves better results than GRU4Rec in REES46 (Cosmetics). STAMP proposes a short-term interest-first attention mechanism to capture the user's current interest, and achieves better results on Yoochoose than either GRU4Rec or NARM. In the experiments, all three methods outperform the traditional methods, which indicates that the RNN-based methods can effectively process the sequential information in a session and capture the user's item transition relationship, showing the effectiveness of deep neural network methods in the field of session-based recommendation. However, these three methods cannot capture the complex interactions between users and items, and only consider the one-direction transitions between consecutive items. (3) SR-GNN and GC-SAN are two GNN-based methods. SR-GNN employs GGNN to obtain item representations, and uses attention mechanisms to generate session representations that capture the implicit connectivity of user interactions, with good performance in both datasets. GC-SAN focuses on capturing long-term dependencies between items, does not adapt well to the variability of purchase behavior, and shows lower experimental results than SR-GNN. These two methods outperform the above methods in terms of overall effectiveness, demonstrating that using graph neural network modeling can capture more accurate node representations and complex dependencies between items. However, the above methods only consider single interactive behavior information and ignore the importance of multiple interactive behavior information for session-based recommendation.\n\n(4) MGNN-SPred and BA-GNN exploit multiple interactive behavior information. MGNN-SPred significantly improves the accuracy of recommendations by learning the relationships between global items through the designed MGNN network. This method integrates the current session's target and auxiliary behavioral sequences through a gating attention mechanism. Both methods outperform the above sessionbased recommendation methods based on single interactive behavior information, which demonstrates that using multiple interactive behavior information helps capture user preference at a micro-grained level better and can greatly increase the precision of session-based recommendations.\n\n(5) BA-GNN achieves the best results on both two datasets.\n\nThe specific reason is that we fully consider the differences between different behaviors and treat different action sequences separately to avoid the mutual influence of different behavioral representations, which can better capture the intention of user interactions and exploit the hidden user's interest behind the interactions. At the same time, we denoise the click sequences to optimize the representations, which can more realistically reflect user preference. Further, to verify the effectiveness of our method more comprehensively, we granularly evaluated the top-5, top-10, top-20, and top-50 recommendations of the proposed BA-GNN and compared them with the best performing method (MGNN-Spred) in the baselines. The experimental results are shown in Table 4. From Table 4, we can find that our method achieves the best results under all evaluation metrics. And the larger value of top-K, the higher accuracy can be obtained. The experimental results fully demonstrate the effectiveness of our model.\n\n\nAblation study\n\nWe conduct experiments to verify the validity of each part of the method. The experimental results are shown in Table 5. \"BA-GNN\" indicates our complete method. \"w/o separate\" means removing the parts of the different behavior sequences that are treated separately, i.e., constructing two action sequences in a directed graph without distinguishing the types of behavior edges to obtain behavior sequence representations. \"w/o sparse\" means removing the sparse self-attention module from the click sequence.  Table 5 shows that BA-GNN outperforms \"w/o separate\", which indicates that the fused behavior sequences do not consider the variability of different actions, resulting in the node representation of different interactive behavior sequences affecting each other, further making the learned behavior representation inaccurate. Therefore, it is necessary to treat different behavior sequences separately. BA-GNN outperforms \"w/o sparse\", proving the effectiveness of the sparse self-attentive module. After removing this module, the click sequence does not remove the noise from the node representation and cannot reflect the user's intention and interest accurately. This experiment demonstrates that the denoised sequence representation can provide better recommendation results for users for click sequences. Therefore, it is necessary to denoise the click sequence. 5.7 Impact of parameters 5.7.1 Analyses of maximum sequence length We analyze the effect of the maximum sequence length L on the method performance, and the experimental results are shown in Fig. 3.\n\nAs is shown in Fig. 3, both datasets show an overall trend of increasing and then decreasing. The change in REES46 (Cosmetics) is more apparent, which indicates this dataset has a higher sensitivity to sequence length. Specifically, on the dataset REES46(Cosmetics), the value of HR@100 shows a trend of increasing, then decreasing, and reaches the best experimental results when the maximum sequence length is 2. After that, the experimental results decreases significantly as the length increased. This is because there are many long sessions in REES46 (Cosmetics). When the maximum sequence length keeps increasing, the information fused by the method for long sessions also keeps increasing, weakening the method to capture user's short-term interest. In Yoochoose, the best experimental results are obtained when the maximum sequence length is 3, then the results decrease significantly but eventually stable. This is because most sessions in Yoochoose are short sessions, and the method's ability to aggregate session information gradually stabilizes even if the maximum sequence length keeps increasing.\n\n\nAnalyses of GGNN propagation step\n\nWe analyze the effect of GGNN propagation steps t on the method performance, and the experimental results are shown in Fig. 4.\n\nAs is shown in Fig. 4, both two datasets reach the worst results when the propagation step t is 1, which proves the necessity of using GGNN. For REES46 (Cosmetics), the value of HR@100 gradually grows as the propagation steps rise, and the best result is reached when the propagation step t is 4. The limitation of computational resources blocks us verify whether the value of HR@100 will continue to increase when the propagation step t is 5. However, it is obvious that the difference between the results at propagation steps 3 and 4 is not significant. Thus, we can assume that the experimental results are good enough when the propagation step is 4. For Yoochoose, the best results are obtained when the propagation step is 3. Then the value of HR@100 decreases significantly when the propagation step is 4. It indicates that the increase in iterations causes the hidden state representation of each node to converge to the same value. As a result, the node representations become smooth, making the nodes indistinguishable and deteriorating the experimental results.\n\n\nConclusion\n\nIn this paper, we propose a behavior-aware graph neural network called BA-GNN for session-based recommendation. This method builds graphs for the sequences with different interactive behaviors separately, and a sparse self-attention module is designed to remove the noise in click sequences. Then it captures the weights of all sequence representations to get the session representations, and calculates item scores to predict the next interaction of users. We conduct extensive experiments on two publicly available real datasets, and the experimental results demonstrate that our proposed method achieves the best performance.\n\nIn the future, we will consider artificially adding noise to simulate the sequence data, thus quantitatively studying the effects of length and noise. In addition, we will also consider applying other attribute information of items to enrich the representations of sessions. (CASNDST202007). Fig. 3 The effect of the maximum sequence length L  \n\nFig. 1\n1Fig. 1 A toy sample of users' session interactions\n\n( 2 )\n2Behavior-level item representations. Behavior-level item representations are obtained from different action sequences via gated graph neural networks. It then sums the behaviorlevel item representations to get the global item representations. (3) Sparse self-attention module. The module eliminates the noise in the click sequence. (4) Representation learning for actions and session. It takes the item representations in different action sequences to obtain the sequence representations by mean pooling layers. Then the gated attention mechanism is used to assign different weights to the different sequence representations and sum them up to obtain the session representation. (5) Prediction and recommendation. It is used to calculate candidate item scores by the global item representations and the session\n\n\nThe representation of the click sequence .\n\n\nThe representation of the purchase sequence .\u03b1 s(c) The weight of the click sequence . s s The representation of the session .\n\nFig. 2\n2Fig. 2 The overall framework of our proposed method. We first construct directed graphs for different action sequences. Then we learn the behavior-level item representations via GGNN. Next, a sparse self-attention module is designed to remove the noise in the click sequences. After that, we learn representations for action sequences and sessions. Finally, we make predictions and recommendations\n\n\nthe new item representations of the node vector list after being updated by this module. 4.5 Representation learning for actions and session z s(c)\n\nFig. 4\n4The effect of GGNN propagation step t\n\nTable 1\n1The notations used in this paper The sequence of items for session .Notations \nDescriptions \n\nV \nThe item set. \n\nm \nThe number of items. \n\ns \ns \ns(c) \ns \nThe click sequence of session . \n\n|s(c)| \ns(c) \nThe number of items in the click sequence \n. \n\ns(p) \ns \nThe purchase sequence of session . \n\n|s(p)| \ns(p) \nThe number of items in the purchase sequence \n. \n\n\n\nTable 2\n2Statistics of the datasetsDataset \nYoochoose \nREES46 (Cosmetics) \nitems \n52,740 \n52,810 \nsessions \n9,249,729 \n1,356,762 \ntraining data \n163,005 \n550,958 \nvalidation data \n12,985 \n39,379 \ntest data \n25,971 \n78,758 \n\n\n\nTable 3\n3Results of all methodsMethods \nYoochoose \nREES46 (Cosmetics) \nH@100 \nM@100 \nN@100 \nH@100 \nM@100 \nN@100 \nPOP \n6.0950 \n0.2529 \n1.2231 \n17.8013 \n2.2265 \n5.0135 \nItem-KNN \n15.2860 \n1.9415 \n4.4040 \n20.6950 \n2.3011 \n5.7206 \nGRU4Rec \n19.1140 \n2.5292 \n5.5830 \n24.7119 \n2.7627 \n6.7571 \nNARM \n18.7750 \n2.5819 \n5.5813 \n25.1056 \n2.7782 \n6.8263 \nSTAMP \n20.3610 \n2.3487 \n5.6879 \n23.3025 \n2.5899 \n6.3133 \nSR-GNN \n21.2620 \n2.6892 \n6.1232 \n24.8550 \n2.7372 \n6.7573 \nGC-SAN \n19.7180 \n2.5218 \n5.6861 \n24.9783 \n2.3933 \n6.5303 \nMGNN-SPred \n27.9200 \n3.5058 \n8.0442 \n29.9960 \n3.6662 \n8.4361 \nBA-GNN \n29.0510 \n4.4517 \n9.0820 \n31.4380 \n4.0046 \n9.0115 \n\nImprove \n4.05% \n26.98% \n12.90% \n4.81% \n9.23% \n6.82% \n\n\n\nTable 4\n4Evaluation results for different top-K recommendationsMethods \nYoochoose \nREES46 (Cosmetics) \nH@5 \nM@5 \nN@5 \nH@5 \nM@5 \nN@5 \nMGNN-Spred \n4.6470 \n2.1964 \n2.7984 \n4.8120 \n2.4305 \n3.0164 \nBA-GNN \n5.1020 \n2.4405 \n3.0936 \n5.5220 \n2.7960 \n3.4667 \n\nImprove \n9.79% \n11.11% \n10.55% \n14.75% \n15.04% \n14.93% \nH@10 \nM@10 \nN@10 \nH@10 \nM@10 \nN@10 \nMGNN-Spred \n8.0510 \n2.6406 \n3.8889 \n7.9190 \n2.8398 \n4.0157 \nBA-GNN \n8.6900 \n2.9127 \n4.2474 \n9.0950 \n3.2677 \n4.6169 \n\nImprove \n7.94% \n10.30% \n9.22% \n14.85% \n15.07% \n14.97% \nH@20 \nM@20 \nN@20 \nH@20 \nM@20 \nN@20 \nMGNN-Spred \n13.3030 \n2.9970 \n5.2068 \n12.5510 \n3.1564 \n5.1808 \nBA-GNN \n13.4920 \n3.2444 \n5.4596 \n14.0370 \n3.6071 \n5.8618 \n\nImprove \n1.42% \n8.25% \n4.86% \n11.84% \n14.28% \n13.14% \nH@50 \nM@50 \nN@50 \nH@50 \nM@50 \nN@50 \nMGNN-Spred \n21.9170 \n3.2733 \n6.9191 \n20.8470 \n3.4167 \n6.8200 \nBA-GNN \n22.5558 \n3.7482 \n7.4309 \n22.7850 \n3.8821 \n7.5915 \n\nImprove \n2.91% \n14.51% \n7.40% \n9.30% \n13.62% \n11.31% \nH@100 \nM@100 \nN@100 \nH@100 \nM@100 \nN@100 \nMGNN-Spred \n27.9200 \n3.5058 \n8.0442 \n29.9960 \n3.6662 \n8.4361 \nBA-GNN \n29.0510 \n4.4517 \n9.0820 \n31.4380 \n4.0046 \n9.0115 \n\nImprove \n4.05% \n26.98% \n12.90% \n4.81% \n9.23% \n6.82% \n\nTable 5 Ablation experiment \n\nMethods \nYoochoose \nREES46 (Cosmetics) \nH@100 \nM@100 \nN@100 \nH@100 \nM@100 \nN@100 \nw/o separate \n28.3560 \n3.9098 \n8.4807 \n29.5160 \n3.4642 \n8.1763 \nw/o sparse \n27.8540 \n3.4610 \n7.7134 \n29.7950 \n3.4410 \n8.2250 \nBA-GNN \n29.0510 \n4.4517 \n9.0820 \n31.4380 \n4.0046 \n9.0115 \n\n\n\npublished more than 40 papers in international journals and conferences, such as IEEE Transactions on Network Science and Engineering, ACM Transactions on Multimedia Computing, Communications, and Applications. Hui Zhou received the MS degree in computer science from Shandong University of Science and Technology, China in 2020. She is currently pursuing PhD degree in pattern recognition and intelligent systems from School of Electronic Engineering, the Key Laboratory of Intelligent Perception and Image Understanding of Ministry of Education of China, Xidian University, China. Her research interests include graph neural networks, network embedding, and artificial intelligence. Maoguo Gong (Corresponding author) received the BSc degree in electronic engineering and the PhD degree in electronic science and technology from Xidian University, China in 2003 and 2009, respectively. Since 2006, he has been a Teacher with Xidian University, where he was promoted as an Associate Professor and as a Full Professor in 2008 and 2010, with exceptive admission. His research interests are in the areas of computational intelligence with applications to optimization, learning, data mining, and image understanding. Prof. Gong is currently the Vice Chair of the IEEE Computational Intelligence Society Task Force on Memetic Computing. He is an Executive Committee Member of the Chinese Association for Artificial Intelligence and a Senior Member of the Chinese Computer Federation.8 \nFront. Comput. Sci., 2023, 17(6): 176613 \n\nFront. Comput. Sci., 2023, 17(6): 176613\nFront. Comput. Sci., 2023, 17(6): 176613\n\nA survey on session-based recommender systems. S Wang, L Cao, Y Wang, Q Z Sheng, M A Orgun, D Lian, ACM Computing Surveys. 2022738Wang S, Cao L, Wang Y, Sheng Q Z, Orgun M A, Lian D. A survey on session-based recommender systems. ACM Computing Surveys, 2022, 54(7): 154:1-154:38\n\nSession-based recommendations with recurrent neural networks. B Hidasi, A Karatzoglou, L Baltrunas, D Tikk, Proceedings of the 4th International Conference on Learning Representations. the 4th International Conference on Learning RepresentationsHidasi B, Karatzoglou A, Baltrunas L, Tikk D. Session-based recommendations with recurrent neural networks. In: Proceedings of the 4th International Conference on Learning Representations. 2016, 1-10\n\nNeural attentive sessionbased recommendation. J Li, P Ren, Z Chen, Z Ren, T Lian, J Ma, Proceedings of 2017 ACM Conference on Information and Knowledge Management. 2017 ACM Conference on Information and Knowledge ManagementLi J, Ren P, Chen Z, Ren Z, Lian T, Ma J. Neural attentive session- based recommendation. In: Proceedings of 2017 ACM Conference on Information and Knowledge Management. 2017, 1419-1428\n\nGlobal context enhanced graph neural networks for session-based recommendation. Z Wang, W Wei, G Cong, X L Li, X L Mao, M Qiu, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020Wang Z, Wei W, Cong G, Li X L, Mao X L, Qiu M. Global context enhanced graph neural networks for session-based recommendation. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020, 169-178\n\nSession-based recommendation with graph neural networks. S Wu, Y Tang, Y Zhu, L Wang, X Xie, T Tan, Proceedings of the 33rd AAAI Conference on Artificial Intelligence. the 33rd AAAI Conference on Artificial Intelligence2019Wu S, Tang Y, Zhu Y, Wang L, Xie X, Tan T. Session-based recommendation with graph neural networks. In: Proceedings of the 33rd AAAI Conference on Artificial Intelligence. 2019, 346-353\n\nGraph contextualized self-attention network for session-based recommendation. C Xu, P Zhao, Y Liu, V S Sheng, J Xu, F Zhuang, J Fang, X Zhou, Proceedings of the 28th International Joint Conference on Artificial Intelligence. the 28th International Joint Conference on Artificial Intelligence2019Xu C, Zhao P, Liu Y, Sheng V S, Xu J, Zhuang F, Fang J, Zhou X. Graph contextualized self-attention network for session-based recommendation. In: Proceedings of the 28th International Joint Conference on Artificial Intelligence. 2019, 3940-3946\n\nTAGNN: target attentive graph neural networks for session-based recommendation. F Yu, Y Zhu, Q Liu, S Wu, L Wang, T Tan, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020Yu F, Zhu Y, Liu Q, Wu S, Wang L, Tan T. TAGNN: target attentive graph neural networks for session-based recommendation. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020, 1921-1924\n\nBeyond clicks: modeling multi-relational item graph for session-based target behavior prediction. W Wang, W Zhang, S Liu, Q Liu, B Zhang, L Lin, H Zha, Proceedings of the Web Conference 2020. 2020. the Web Conference 2020. 2020Wang W, Zhang W, Liu S, Liu Q, Zhang B, Lin L, Zha H. Beyond clicks: modeling multi-relational item graph for session-based target behavior prediction. In: Proceedings of the Web Conference 2020. 2020, 3056-3062\n\nAn MDP-based recommender system. G Shani, D Heckerman, R I Brafman, Journal of Machine Learning Research. 69Shani G, Heckerman D, Brafman R I.. An MDP-based recommender system. Journal of Machine Learning Research, 2005, 6(9): 1265-1295\n\nFactorizing personalized Markov chains for next-basket recommendation. S Rendle, C Freudenthaler, L Schmidt-Thieme, Proceedings of the 19th International Conference on World Wide Web. the 19th International Conference on World Wide WebRendle S, Freudenthaler C, Schmidt-Thieme L. Factorizing personalized Markov chains for next-basket recommendation. In: Proceedings of the 19th International Conference on World Wide Web. 2010, 811-820\n\nSequence and time aware neighborhood for session-based recommendations: STAN. D Garg, P Gupta, P Malhotra, L Vig, G Shroff, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 42nd International ACM SIGIR Conference on Research and Development in Information RetrievalGarg D, Gupta P, Malhotra P, Vig L, Shroff G. Sequence and time aware neighborhood for session-based recommendations: STAN. In: Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2019, 1069-1072\n\nWhen recurrent neural networks meet the neighborhood for session-based recommendation. D Jannach, M Ludewig, Proceedings of the 11th ACM Conference on Recommender Systems. the 11th ACM Conference on Recommender SystemsJannach D, Ludewig M. When recurrent neural networks meet the neighborhood for session-based recommendation. In: Proceedings of the 11th ACM Conference on Recommender Systems. 2017, 306-310\n\nImproved recurrent neural networks for sessionbased recommendations. Y K Tan, X Xu, Y Liu, Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. the 1st Workshop on Deep Learning for Recommender SystemsTan Y K, Xu X, Liu Y. Improved recurrent neural networks for session- based recommendations. In: Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. 2016, 17-22\n\nSTAMP: short-term attention/memory priority model for session-based recommendation. Q Liu, Y Zeng, R Mokhosi, H Zhang, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningLiu Q, Zeng Y, Mokhosi R, Zhang H. STAMP: short-term attention/memory priority model for session-based recommendation. In: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2018, 1831-1839\n\nISLF: interest shift and latent factors combination model for session-based recommendation. J Song, H Shen, Z Ou, J Zhang, T Xiao, S Liang, Proceedings of the 28th International Joint Conference on Artificial Intelligence. the 28th International Joint Conference on Artificial Intelligence2019Song J, Shen H, Ou Z, Zhang J, Xiao T, Liang S. ISLF: interest shift and latent factors combination model for session-based recommendation. In: Proceedings of the 28th International Joint Conference on Artificial Intelligence. 2019, 5765-5771\n\nModeling multipurpose sessions for next-item recommendations via mixture-channel purpose routing networks. S Wang, L Hu, Y Wang, Q Z Sheng, M Orgun, L Cao, Proceedings of the 28th International Joint Conference on Artificial Intelligence. the 28th International Joint Conference on Artificial Intelligence2019Wang S, Hu L, Wang Y, Sheng Q Z, Orgun M, Cao L. Modeling multi- purpose sessions for next-item recommendations via mixture-channel purpose routing networks. In: Proceedings of the 28th International Joint Conference on Artificial Intelligence. 2019, 3771-3777\n\nRethinking the item order in session-based recommendation with graph neural networks. R Qiu, J Li, Z Huang, H Yin, Proceedings of the 28th ACM International Conference on Information and Knowledge 17. the 28th ACM International Conference on Information and Knowledge 17Qiu R, Li J, Huang Z, Yin H. Rethinking the item order in session-based recommendation with graph neural networks. In: Proceedings of the 28th ACM International Conference on Information and Knowledge 17. Management. 2019, 579-588\n\nImproving graph neural network for sessionbased recommendation system via non-sequential interactions. T R Gwadabe, Y Liu, Neurocomputing. 468Gwadabe T R, Liu Y. Improving graph neural network for session- based recommendation system via non-sequential interactions. Neurocomputing, 2022, 468: 111-122\n\nModeling contemporaneous basket sequences with twin networks for next-item recommendation. D T Le, H W Lauw, Y Fang, Proceedings of the 27th International Joint Conference on Artificial Intelligence. the 27th International Joint Conference on Artificial IntelligenceLe D T, Lauw H W, Fang Y. Modeling contemporaneous basket sequences with twin networks for next-item recommendation. In: Proceedings of the 27th International Joint Conference on Artificial Intelligence. 2018, 3414-3420\n\nIncorporating user micro-behaviors and item knowledge into multi-task learning for session-based recommendation. W Meng, D Yang, Y Xiao, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020Meng W, Yang D, Xiao Y. Incorporating user micro-behaviors and item knowledge into multi-task learning for session-based recommendation. In: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. 2020, 1091-1100\n\nGated graph sequence neural networks. Y Li, D Tarlow, M Brockschmidt, R Zemel, Proceedings of the 4th International Conference on Learning Representations. the 4th International Conference on Learning RepresentationsLi Y, Tarlow D, Brockschmidt M, Zemel R S. Gated graph sequence neural networks. In: Proceedings of the 4th International Conference on Learning Representations. 2016, 1-20\n\nProbabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition. J Bridle, Neurocomputing. 68Bridle J S. Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition. Neurocomputing, 1990, 68 : 227-236\n\nSoftmax to Sparsemax: a sparse model of attention and multi-label classification. A F T Martins, R F Astudillo, From, Proceedings of the 33rd International Conference on Machine Learning. the 33rd International Conference on Machine LearningMartins A F T, Astudillo R F. From Softmax to Sparsemax: a sparse model of attention and multi-label classification. In: Proceedings of the 33rd International Conference on Machine Learning. 2016, 1614-1623\n\nDual sparse attention network for session-based recommendation. J Yuan, Z Song, M Sun, X Wang, W Zhao, Proceedings of the 35th AAAI Conference on Artificial Intelligence. the 35th AAAI Conference on Artificial Intelligence2021Yuan J, Song Z, Sun M, Wang X, Zhao W X. Dual sparse attention network for session-based recommendation. In: Proceedings of the 35th AAAI Conference on Artificial Intelligence. 2021, 4635-4643\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, \u0141 Kaiser, I Polosukhin, Proceedings of the 31st International Conference on Neural Information Processing Systems. the 31st International Conference on Neural Information Processing SystemsVaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez A N, Kaiser \u0141, Polosukhin I. Attention is all you need. In: Proceedings of the 31st International Conference on Neural Information Processing Systems. 2017, 6000-6010\n\nItem-based collaborative filtering recommendation algorithms. B Sarwar, G Karypis, J Konstan, J Riedl, Proceedings of the 10th International Conference on World Wide Web. the 10th International Conference on World Wide WebSarwar B, Karypis G, Konstan J, Riedl J. Item-based collaborative filtering recommendation algorithms. In: Proceedings of the 10th International Conference on World Wide Web. 2001, 285-295\n\nHe is currently a professor in School of. China. His research interests include social network analysis, expert system and data mining. Yongquan Liang received the PhD degree from Institute of Computing Technology ; Computer Science and Engineering, Shandong University of Science and TechnologyYongquan Liang received the PhD degree from Institute of Computing Technology, Chinese Academy of Sciences, China in 1999. He is currently a professor in School of Computer Science and Engineering, Shandong University of Science and Technology, China. His research interests include social network analysis, expert system and data mining.\n\nHer research interests include sessionbased recommendation and graph neural networks. ChinaQiuyu Song is pursuing the Master degree in School of Computer Science and Engineering, Shandong University of Science and TechnologyQiuyu Song is pursuing the Master degree in School of Computer Science and Engineering, Shandong University of Science and Technology, China. Her research interests include sessionbased recommendation and graph neural networks.\n", "annotations": {"author": "[{\"end\":204,\"start\":80},{\"end\":325,\"start\":205},{\"end\":450,\"start\":326},{\"end\":530,\"start\":451},{\"end\":722,\"start\":531}]", "publisher": null, "author_last_name": "[{\"end\":94,\"start\":89},{\"end\":215,\"start\":211},{\"end\":340,\"start\":336},{\"end\":459,\"start\":455},{\"end\":542,\"start\":538}]", "author_first_name": "[{\"end\":88,\"start\":80},{\"end\":210,\"start\":205},{\"end\":335,\"start\":326},{\"end\":454,\"start\":451},{\"end\":537,\"start\":531}]", "author_affiliation": "[{\"end\":203,\"start\":96},{\"end\":324,\"start\":217},{\"end\":449,\"start\":342},{\"end\":529,\"start\":461},{\"end\":651,\"start\":544},{\"end\":721,\"start\":653}]", "title": "[{\"end\":77,\"start\":1},{\"end\":799,\"start\":723}]", "venue": null, "abstract": "[{\"end\":2036,\"start\":934}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2917,\"start\":2914},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3224,\"start\":3221},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3237,\"start\":3234},{\"end\":3442,\"start\":3437},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3994,\"start\":3991},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6484,\"start\":6481},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6567,\"start\":6563},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6711,\"start\":6707},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6737,\"start\":6733},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7088,\"start\":7085},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7231,\"start\":7227},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7339,\"start\":7336},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7485,\"start\":7481},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7713,\"start\":7709},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7902,\"start\":7898},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8076,\"start\":8073},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8317,\"start\":8314},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8449,\"start\":8446},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8563,\"start\":8560},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9045,\"start\":9041},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9347,\"start\":9343},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9479,\"start\":9475},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9648,\"start\":9645},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":12654,\"start\":12651},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12665,\"start\":12661},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14898,\"start\":14894},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15052,\"start\":15048},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":15729,\"start\":15725},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15900,\"start\":15896},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":16554,\"start\":16550},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16900,\"start\":16897},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20439,\"start\":20435},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20606,\"start\":20603},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20714,\"start\":20711},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":20866,\"start\":20862},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21098,\"start\":21095},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21289,\"start\":21286},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21489,\"start\":21486}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33756,\"start\":33697},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34575,\"start\":33757},{\"attributes\":{\"id\":\"fig_6\"},\"end\":34620,\"start\":34576},{\"attributes\":{\"id\":\"fig_7\"},\"end\":34749,\"start\":34621},{\"attributes\":{\"id\":\"fig_8\"},\"end\":35156,\"start\":34750},{\"attributes\":{\"id\":\"fig_10\"},\"end\":35306,\"start\":35157},{\"attributes\":{\"id\":\"fig_11\"},\"end\":35353,\"start\":35307},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":35723,\"start\":35354},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":35949,\"start\":35724},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36641,\"start\":35950},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":38092,\"start\":36642},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":39620,\"start\":38093}]", "paragraph": "[{\"end\":3112,\"start\":2052},{\"end\":3587,\"start\":3114},{\"end\":3876,\"start\":3589},{\"end\":4323,\"start\":3878},{\"end\":4878,\"start\":4325},{\"end\":5233,\"start\":4880},{\"end\":5748,\"start\":5235},{\"end\":5799,\"start\":5750},{\"end\":6380,\"start\":5801},{\"end\":6935,\"start\":6397},{\"end\":8061,\"start\":6937},{\"end\":8850,\"start\":8063},{\"end\":9167,\"start\":8852},{\"end\":9798,\"start\":9169},{\"end\":9954,\"start\":9800},{\"end\":10313,\"start\":10194},{\"end\":10494,\"start\":10315},{\"end\":10964,\"start\":10565},{\"end\":11780,\"start\":11079},{\"end\":11878,\"start\":11782},{\"end\":12317,\"start\":12002},{\"end\":12577,\"start\":12357},{\"end\":12816,\"start\":12632},{\"end\":13962,\"start\":13289},{\"end\":14199,\"start\":14012},{\"end\":14202,\"start\":14201},{\"end\":14543,\"start\":14254},{\"end\":14546,\"start\":14545},{\"end\":14651,\"start\":14553},{\"end\":15398,\"start\":14710},{\"end\":15584,\"start\":15485},{\"end\":15865,\"start\":15586},{\"end\":16072,\"start\":15867},{\"end\":16332,\"start\":16138},{\"end\":16357,\"start\":16356},{\"end\":16555,\"start\":16376},{\"end\":16711,\"start\":16638},{\"end\":16905,\"start\":16713},{\"end\":17054,\"start\":16946},{\"end\":17505,\"start\":17138},{\"end\":17843,\"start\":17635},{\"end\":18030,\"start\":17866},{\"end\":18181,\"start\":18047},{\"end\":18316,\"start\":18247},{\"end\":18490,\"start\":18343},{\"end\":18741,\"start\":18492},{\"end\":18981,\"start\":18765},{\"end\":19376,\"start\":19193},{\"end\":19997,\"start\":19378},{\"end\":20424,\"start\":20011},{\"end\":20593,\"start\":20426},{\"end\":20704,\"start\":20595},{\"end\":20854,\"start\":20706},{\"end\":21277,\"start\":20856},{\"end\":21473,\"start\":21279},{\"end\":21765,\"start\":21475},{\"end\":21924,\"start\":21788},{\"end\":22042,\"start\":21926},{\"end\":22358,\"start\":22044},{\"end\":22638,\"start\":22360},{\"end\":23278,\"start\":22661},{\"end\":23938,\"start\":23280},{\"end\":24312,\"start\":23968},{\"end\":24527,\"start\":24314},{\"end\":25154,\"start\":24529},{\"end\":27011,\"start\":25156},{\"end\":27693,\"start\":27013},{\"end\":27753,\"start\":27695},{\"end\":28766,\"start\":27755},{\"end\":30358,\"start\":28785},{\"end\":31470,\"start\":30360},{\"end\":31634,\"start\":31508},{\"end\":32707,\"start\":31636},{\"end\":33350,\"start\":32722},{\"end\":33696,\"start\":33352}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10193,\"start\":9991},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11078,\"start\":10987},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12001,\"start\":11901},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12356,\"start\":12318},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12631,\"start\":12616},{\"attributes\":{\"id\":\"formula_5\"},\"end\":12890,\"start\":12817},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12944,\"start\":12890},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13072,\"start\":12944},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13144,\"start\":13072},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13288,\"start\":13144},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14011,\"start\":13963},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14253,\"start\":14203},{\"attributes\":{\"id\":\"formula_12\"},\"end\":14552,\"start\":14547},{\"attributes\":{\"id\":\"formula_13\"},\"end\":14678,\"start\":14652},{\"attributes\":{\"id\":\"formula_14\"},\"end\":15436,\"start\":15399},{\"attributes\":{\"id\":\"formula_15\"},\"end\":15484,\"start\":15436},{\"attributes\":{\"id\":\"formula_16\"},\"end\":16114,\"start\":16073},{\"attributes\":{\"id\":\"formula_17\"},\"end\":16137,\"start\":16114},{\"attributes\":{\"id\":\"formula_18\"},\"end\":16355,\"start\":16333},{\"attributes\":{\"id\":\"formula_19\"},\"end\":16375,\"start\":16358},{\"attributes\":{\"id\":\"formula_20\"},\"end\":16616,\"start\":16556},{\"attributes\":{\"id\":\"formula_21\"},\"end\":16637,\"start\":16616},{\"attributes\":{\"id\":\"formula_22\"},\"end\":16929,\"start\":16906},{\"attributes\":{\"id\":\"formula_23\"},\"end\":16945,\"start\":16929},{\"attributes\":{\"id\":\"formula_24\"},\"end\":17137,\"start\":17055},{\"attributes\":{\"id\":\"formula_25\"},\"end\":17544,\"start\":17506},{\"attributes\":{\"id\":\"formula_26\"},\"end\":17583,\"start\":17544},{\"attributes\":{\"id\":\"formula_27\"},\"end\":17634,\"start\":17615},{\"attributes\":{\"id\":\"formula_28\"},\"end\":17865,\"start\":17844},{\"attributes\":{\"id\":\"formula_29\"},\"end\":18046,\"start\":18031},{\"attributes\":{\"id\":\"formula_30\"},\"end\":18246,\"start\":18182},{\"attributes\":{\"id\":\"formula_31\"},\"end\":19192,\"start\":18982}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":10963,\"start\":10956},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":18489,\"start\":18482},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":24173,\"start\":24166},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":24336,\"start\":24329},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":24526,\"start\":24519},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":28524,\"start\":28517},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":28538,\"start\":28531},{\"end\":28904,\"start\":28897},{\"end\":29301,\"start\":29294}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2050,\"start\":2038},{\"attributes\":{\"n\":\"2\"},\"end\":6395,\"start\":6383},{\"attributes\":{\"n\":\"3\"},\"end\":9970,\"start\":9957},{\"attributes\":{\"n\":\"3.1\"},\"end\":9990,\"start\":9973},{\"end\":10508,\"start\":10497},{\"end\":10563,\"start\":10511},{\"attributes\":{\"n\":\"4\"},\"end\":10986,\"start\":10967},{\"attributes\":{\"n\":\"4.2\"},\"end\":11900,\"start\":11881},{\"attributes\":{\"n\":\"4.3\"},\"end\":12615,\"start\":12580},{\"attributes\":{\"n\":\"4.4\"},\"end\":14708,\"start\":14680},{\"attributes\":{\"n\":\"4.6\"},\"end\":17614,\"start\":17585},{\"attributes\":{\"n\":\"5\"},\"end\":18330,\"start\":18319},{\"attributes\":{\"n\":\"5.1\"},\"end\":18341,\"start\":18333},{\"end\":18763,\"start\":18744},{\"attributes\":{\"n\":\"5.2\"},\"end\":20009,\"start\":20000},{\"attributes\":{\"n\":\"5.3\"},\"end\":21786,\"start\":21768},{\"attributes\":{\"n\":\"5.4\"},\"end\":22659,\"start\":22641},{\"attributes\":{\"n\":\"5.5\"},\"end\":23966,\"start\":23941},{\"attributes\":{\"n\":\"5.6\"},\"end\":28783,\"start\":28769},{\"attributes\":{\"n\":\"5.7.2\"},\"end\":31506,\"start\":31473},{\"attributes\":{\"n\":\"6\"},\"end\":32720,\"start\":32710},{\"end\":33704,\"start\":33698},{\"end\":33763,\"start\":33758},{\"end\":34757,\"start\":34751},{\"end\":35314,\"start\":35308},{\"end\":35362,\"start\":35355},{\"end\":35732,\"start\":35725},{\"end\":35958,\"start\":35951},{\"end\":36650,\"start\":36643}]", "table": "[{\"end\":35723,\"start\":35432},{\"end\":35949,\"start\":35760},{\"end\":36641,\"start\":35982},{\"end\":38092,\"start\":36706},{\"end\":39620,\"start\":39575}]", "figure_caption": "[{\"end\":33756,\"start\":33706},{\"end\":34575,\"start\":33765},{\"end\":34620,\"start\":34578},{\"end\":34749,\"start\":34623},{\"end\":35156,\"start\":34759},{\"end\":35306,\"start\":35159},{\"end\":35353,\"start\":35316},{\"end\":35432,\"start\":35364},{\"end\":35760,\"start\":35734},{\"end\":35982,\"start\":35960},{\"end\":36706,\"start\":36652},{\"end\":39575,\"start\":38095}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4432,\"start\":4423},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5083,\"start\":5074},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11119,\"start\":11113},{\"end\":30357,\"start\":30351},{\"end\":30381,\"start\":30375},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":31633,\"start\":31627},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":31657,\"start\":31651},{\"end\":33650,\"start\":33644}]", "bib_author_first_name": "[{\"end\":39752,\"start\":39751},{\"end\":39760,\"start\":39759},{\"end\":39767,\"start\":39766},{\"end\":39777,\"start\":39774},{\"end\":39788,\"start\":39785},{\"end\":39797,\"start\":39796},{\"end\":40047,\"start\":40046},{\"end\":40057,\"start\":40056},{\"end\":40072,\"start\":40071},{\"end\":40085,\"start\":40084},{\"end\":40477,\"start\":40476},{\"end\":40483,\"start\":40482},{\"end\":40490,\"start\":40489},{\"end\":40498,\"start\":40497},{\"end\":40505,\"start\":40504},{\"end\":40513,\"start\":40512},{\"end\":40921,\"start\":40920},{\"end\":40929,\"start\":40928},{\"end\":40936,\"start\":40935},{\"end\":40946,\"start\":40943},{\"end\":40954,\"start\":40951},{\"end\":40961,\"start\":40960},{\"end\":41505,\"start\":41504},{\"end\":41511,\"start\":41510},{\"end\":41519,\"start\":41518},{\"end\":41526,\"start\":41525},{\"end\":41534,\"start\":41533},{\"end\":41541,\"start\":41540},{\"end\":41936,\"start\":41935},{\"end\":41942,\"start\":41941},{\"end\":41950,\"start\":41949},{\"end\":41959,\"start\":41956},{\"end\":41968,\"start\":41967},{\"end\":41974,\"start\":41973},{\"end\":41984,\"start\":41983},{\"end\":41992,\"start\":41991},{\"end\":42479,\"start\":42478},{\"end\":42485,\"start\":42484},{\"end\":42492,\"start\":42491},{\"end\":42499,\"start\":42498},{\"end\":42505,\"start\":42504},{\"end\":42513,\"start\":42512},{\"end\":43094,\"start\":43093},{\"end\":43102,\"start\":43101},{\"end\":43111,\"start\":43110},{\"end\":43118,\"start\":43117},{\"end\":43125,\"start\":43124},{\"end\":43134,\"start\":43133},{\"end\":43141,\"start\":43140},{\"end\":43469,\"start\":43468},{\"end\":43478,\"start\":43477},{\"end\":43491,\"start\":43490},{\"end\":43493,\"start\":43492},{\"end\":43745,\"start\":43744},{\"end\":43755,\"start\":43754},{\"end\":43772,\"start\":43771},{\"end\":44190,\"start\":44189},{\"end\":44198,\"start\":44197},{\"end\":44207,\"start\":44206},{\"end\":44219,\"start\":44218},{\"end\":44226,\"start\":44225},{\"end\":44790,\"start\":44789},{\"end\":44801,\"start\":44800},{\"end\":45183,\"start\":45180},{\"end\":45190,\"start\":45189},{\"end\":45196,\"start\":45195},{\"end\":45602,\"start\":45601},{\"end\":45609,\"start\":45608},{\"end\":45617,\"start\":45616},{\"end\":45628,\"start\":45627},{\"end\":46146,\"start\":46145},{\"end\":46154,\"start\":46153},{\"end\":46162,\"start\":46161},{\"end\":46168,\"start\":46167},{\"end\":46177,\"start\":46176},{\"end\":46185,\"start\":46184},{\"end\":46698,\"start\":46697},{\"end\":46706,\"start\":46705},{\"end\":46712,\"start\":46711},{\"end\":46722,\"start\":46719},{\"end\":46731,\"start\":46730},{\"end\":46740,\"start\":46739},{\"end\":47248,\"start\":47247},{\"end\":47255,\"start\":47254},{\"end\":47261,\"start\":47260},{\"end\":47270,\"start\":47269},{\"end\":47769,\"start\":47766},{\"end\":47780,\"start\":47779},{\"end\":48060,\"start\":48057},{\"end\":48068,\"start\":48065},{\"end\":48076,\"start\":48075},{\"end\":48567,\"start\":48566},{\"end\":48575,\"start\":48574},{\"end\":48583,\"start\":48582},{\"end\":49121,\"start\":49120},{\"end\":49127,\"start\":49126},{\"end\":49137,\"start\":49136},{\"end\":49153,\"start\":49152},{\"end\":49604,\"start\":49603},{\"end\":49897,\"start\":49892},{\"end\":49908,\"start\":49907},{\"end\":49910,\"start\":49909},{\"end\":50324,\"start\":50323},{\"end\":50332,\"start\":50331},{\"end\":50340,\"start\":50339},{\"end\":50347,\"start\":50346},{\"end\":50355,\"start\":50354},{\"end\":50707,\"start\":50706},{\"end\":50718,\"start\":50717},{\"end\":50729,\"start\":50728},{\"end\":50739,\"start\":50738},{\"end\":50752,\"start\":50751},{\"end\":50763,\"start\":50760},{\"end\":50772,\"start\":50771},{\"end\":50782,\"start\":50781},{\"end\":51251,\"start\":51250},{\"end\":51261,\"start\":51260},{\"end\":51272,\"start\":51271},{\"end\":51283,\"start\":51282}]", "bib_author_last_name": "[{\"end\":39757,\"start\":39753},{\"end\":39764,\"start\":39761},{\"end\":39772,\"start\":39768},{\"end\":39783,\"start\":39778},{\"end\":39794,\"start\":39789},{\"end\":39802,\"start\":39798},{\"end\":40054,\"start\":40048},{\"end\":40069,\"start\":40058},{\"end\":40082,\"start\":40073},{\"end\":40090,\"start\":40086},{\"end\":40480,\"start\":40478},{\"end\":40487,\"start\":40484},{\"end\":40495,\"start\":40491},{\"end\":40502,\"start\":40499},{\"end\":40510,\"start\":40506},{\"end\":40516,\"start\":40514},{\"end\":40926,\"start\":40922},{\"end\":40933,\"start\":40930},{\"end\":40941,\"start\":40937},{\"end\":40949,\"start\":40947},{\"end\":40958,\"start\":40955},{\"end\":40965,\"start\":40962},{\"end\":41508,\"start\":41506},{\"end\":41516,\"start\":41512},{\"end\":41523,\"start\":41520},{\"end\":41531,\"start\":41527},{\"end\":41538,\"start\":41535},{\"end\":41545,\"start\":41542},{\"end\":41939,\"start\":41937},{\"end\":41947,\"start\":41943},{\"end\":41954,\"start\":41951},{\"end\":41965,\"start\":41960},{\"end\":41971,\"start\":41969},{\"end\":41981,\"start\":41975},{\"end\":41989,\"start\":41985},{\"end\":41997,\"start\":41993},{\"end\":42482,\"start\":42480},{\"end\":42489,\"start\":42486},{\"end\":42496,\"start\":42493},{\"end\":42502,\"start\":42500},{\"end\":42510,\"start\":42506},{\"end\":42517,\"start\":42514},{\"end\":43099,\"start\":43095},{\"end\":43108,\"start\":43103},{\"end\":43115,\"start\":43112},{\"end\":43122,\"start\":43119},{\"end\":43131,\"start\":43126},{\"end\":43138,\"start\":43135},{\"end\":43145,\"start\":43142},{\"end\":43475,\"start\":43470},{\"end\":43488,\"start\":43479},{\"end\":43501,\"start\":43494},{\"end\":43752,\"start\":43746},{\"end\":43769,\"start\":43756},{\"end\":43787,\"start\":43773},{\"end\":44195,\"start\":44191},{\"end\":44204,\"start\":44199},{\"end\":44216,\"start\":44208},{\"end\":44223,\"start\":44220},{\"end\":44233,\"start\":44227},{\"end\":44798,\"start\":44791},{\"end\":44809,\"start\":44802},{\"end\":45187,\"start\":45184},{\"end\":45193,\"start\":45191},{\"end\":45200,\"start\":45197},{\"end\":45606,\"start\":45603},{\"end\":45614,\"start\":45610},{\"end\":45625,\"start\":45618},{\"end\":45634,\"start\":45629},{\"end\":46151,\"start\":46147},{\"end\":46159,\"start\":46155},{\"end\":46165,\"start\":46163},{\"end\":46174,\"start\":46169},{\"end\":46182,\"start\":46178},{\"end\":46191,\"start\":46186},{\"end\":46703,\"start\":46699},{\"end\":46709,\"start\":46707},{\"end\":46717,\"start\":46713},{\"end\":46728,\"start\":46723},{\"end\":46737,\"start\":46732},{\"end\":46744,\"start\":46741},{\"end\":47252,\"start\":47249},{\"end\":47258,\"start\":47256},{\"end\":47267,\"start\":47262},{\"end\":47274,\"start\":47271},{\"end\":47777,\"start\":47770},{\"end\":47784,\"start\":47781},{\"end\":48063,\"start\":48061},{\"end\":48073,\"start\":48069},{\"end\":48081,\"start\":48077},{\"end\":48572,\"start\":48568},{\"end\":48580,\"start\":48576},{\"end\":48588,\"start\":48584},{\"end\":49124,\"start\":49122},{\"end\":49134,\"start\":49128},{\"end\":49150,\"start\":49138},{\"end\":49159,\"start\":49154},{\"end\":49611,\"start\":49605},{\"end\":49905,\"start\":49898},{\"end\":49920,\"start\":49911},{\"end\":49926,\"start\":49922},{\"end\":50329,\"start\":50325},{\"end\":50337,\"start\":50333},{\"end\":50344,\"start\":50341},{\"end\":50352,\"start\":50348},{\"end\":50360,\"start\":50356},{\"end\":50715,\"start\":50708},{\"end\":50726,\"start\":50719},{\"end\":50736,\"start\":50730},{\"end\":50749,\"start\":50740},{\"end\":50758,\"start\":50753},{\"end\":50769,\"start\":50764},{\"end\":50779,\"start\":50773},{\"end\":50793,\"start\":50783},{\"end\":51258,\"start\":51252},{\"end\":51269,\"start\":51262},{\"end\":51280,\"start\":51273},{\"end\":51289,\"start\":51284}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":61153541},\"end\":39982,\"start\":39704},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11810482},\"end\":40428,\"start\":39984},{\"attributes\":{\"id\":\"b2\"},\"end\":40838,\"start\":40430},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":220730170},\"end\":41445,\"start\":40840},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":53219431},\"end\":41855,\"start\":41447},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":199465865},\"end\":42396,\"start\":41857},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":218516936},\"end\":42993,\"start\":42398},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":211171550},\"end\":43433,\"start\":42995},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":875571},\"end\":43671,\"start\":43435},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":207178809},\"end\":44109,\"start\":43673},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":197928312},\"end\":44700,\"start\":44111},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":31923308},\"end\":45109,\"start\":44702},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2552056},\"end\":45515,\"start\":45111},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":50775765},\"end\":46051,\"start\":45517},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":199466310},\"end\":46588,\"start\":46053},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":199466144},\"end\":47159,\"start\":46590},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":207758412},\"end\":47661,\"start\":47161},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":243218534},\"end\":47964,\"start\":47663},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":51609715},\"end\":48451,\"start\":47966},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":219636253},\"end\":49080,\"start\":48453},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":8393918},\"end\":49470,\"start\":49082},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":59636530},\"end\":49808,\"start\":49472},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":16432551},\"end\":50257,\"start\":49810},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":235306600},\"end\":50677,\"start\":50259},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":13756489},\"end\":51186,\"start\":50679},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":8047550},\"end\":51598,\"start\":51188},{\"attributes\":{\"id\":\"b26\"},\"end\":52233,\"start\":51600},{\"attributes\":{\"id\":\"b27\"},\"end\":52686,\"start\":52235}]", "bib_title": "[{\"end\":39749,\"start\":39704},{\"end\":40044,\"start\":39984},{\"end\":40474,\"start\":40430},{\"end\":40918,\"start\":40840},{\"end\":41502,\"start\":41447},{\"end\":41933,\"start\":41857},{\"end\":42476,\"start\":42398},{\"end\":43091,\"start\":42995},{\"end\":43466,\"start\":43435},{\"end\":43742,\"start\":43673},{\"end\":44187,\"start\":44111},{\"end\":44787,\"start\":44702},{\"end\":45178,\"start\":45111},{\"end\":45599,\"start\":45517},{\"end\":46143,\"start\":46053},{\"end\":46695,\"start\":46590},{\"end\":47245,\"start\":47161},{\"end\":47764,\"start\":47663},{\"end\":48055,\"start\":47966},{\"end\":48564,\"start\":48453},{\"end\":49118,\"start\":49082},{\"end\":49601,\"start\":49472},{\"end\":49890,\"start\":49810},{\"end\":50321,\"start\":50259},{\"end\":50704,\"start\":50679},{\"end\":51248,\"start\":51188},{\"end\":51640,\"start\":51600}]", "bib_author": "[{\"end\":39759,\"start\":39751},{\"end\":39766,\"start\":39759},{\"end\":39774,\"start\":39766},{\"end\":39785,\"start\":39774},{\"end\":39796,\"start\":39785},{\"end\":39804,\"start\":39796},{\"end\":40056,\"start\":40046},{\"end\":40071,\"start\":40056},{\"end\":40084,\"start\":40071},{\"end\":40092,\"start\":40084},{\"end\":40482,\"start\":40476},{\"end\":40489,\"start\":40482},{\"end\":40497,\"start\":40489},{\"end\":40504,\"start\":40497},{\"end\":40512,\"start\":40504},{\"end\":40518,\"start\":40512},{\"end\":40928,\"start\":40920},{\"end\":40935,\"start\":40928},{\"end\":40943,\"start\":40935},{\"end\":40951,\"start\":40943},{\"end\":40960,\"start\":40951},{\"end\":40967,\"start\":40960},{\"end\":41510,\"start\":41504},{\"end\":41518,\"start\":41510},{\"end\":41525,\"start\":41518},{\"end\":41533,\"start\":41525},{\"end\":41540,\"start\":41533},{\"end\":41547,\"start\":41540},{\"end\":41941,\"start\":41935},{\"end\":41949,\"start\":41941},{\"end\":41956,\"start\":41949},{\"end\":41967,\"start\":41956},{\"end\":41973,\"start\":41967},{\"end\":41983,\"start\":41973},{\"end\":41991,\"start\":41983},{\"end\":41999,\"start\":41991},{\"end\":42484,\"start\":42478},{\"end\":42491,\"start\":42484},{\"end\":42498,\"start\":42491},{\"end\":42504,\"start\":42498},{\"end\":42512,\"start\":42504},{\"end\":42519,\"start\":42512},{\"end\":43101,\"start\":43093},{\"end\":43110,\"start\":43101},{\"end\":43117,\"start\":43110},{\"end\":43124,\"start\":43117},{\"end\":43133,\"start\":43124},{\"end\":43140,\"start\":43133},{\"end\":43147,\"start\":43140},{\"end\":43477,\"start\":43468},{\"end\":43490,\"start\":43477},{\"end\":43503,\"start\":43490},{\"end\":43754,\"start\":43744},{\"end\":43771,\"start\":43754},{\"end\":43789,\"start\":43771},{\"end\":44197,\"start\":44189},{\"end\":44206,\"start\":44197},{\"end\":44218,\"start\":44206},{\"end\":44225,\"start\":44218},{\"end\":44235,\"start\":44225},{\"end\":44800,\"start\":44789},{\"end\":44811,\"start\":44800},{\"end\":45189,\"start\":45180},{\"end\":45195,\"start\":45189},{\"end\":45202,\"start\":45195},{\"end\":45608,\"start\":45601},{\"end\":45616,\"start\":45608},{\"end\":45627,\"start\":45616},{\"end\":45636,\"start\":45627},{\"end\":46153,\"start\":46145},{\"end\":46161,\"start\":46153},{\"end\":46167,\"start\":46161},{\"end\":46176,\"start\":46167},{\"end\":46184,\"start\":46176},{\"end\":46193,\"start\":46184},{\"end\":46705,\"start\":46697},{\"end\":46711,\"start\":46705},{\"end\":46719,\"start\":46711},{\"end\":46730,\"start\":46719},{\"end\":46739,\"start\":46730},{\"end\":46746,\"start\":46739},{\"end\":47254,\"start\":47247},{\"end\":47260,\"start\":47254},{\"end\":47269,\"start\":47260},{\"end\":47276,\"start\":47269},{\"end\":47779,\"start\":47766},{\"end\":47786,\"start\":47779},{\"end\":48065,\"start\":48057},{\"end\":48075,\"start\":48065},{\"end\":48083,\"start\":48075},{\"end\":48574,\"start\":48566},{\"end\":48582,\"start\":48574},{\"end\":48590,\"start\":48582},{\"end\":49126,\"start\":49120},{\"end\":49136,\"start\":49126},{\"end\":49152,\"start\":49136},{\"end\":49161,\"start\":49152},{\"end\":49613,\"start\":49603},{\"end\":49907,\"start\":49892},{\"end\":49922,\"start\":49907},{\"end\":49928,\"start\":49922},{\"end\":50331,\"start\":50323},{\"end\":50339,\"start\":50331},{\"end\":50346,\"start\":50339},{\"end\":50354,\"start\":50346},{\"end\":50362,\"start\":50354},{\"end\":50717,\"start\":50706},{\"end\":50728,\"start\":50717},{\"end\":50738,\"start\":50728},{\"end\":50751,\"start\":50738},{\"end\":50760,\"start\":50751},{\"end\":50771,\"start\":50760},{\"end\":50781,\"start\":50771},{\"end\":50795,\"start\":50781},{\"end\":51260,\"start\":51250},{\"end\":51271,\"start\":51260},{\"end\":51282,\"start\":51271},{\"end\":51291,\"start\":51282}]", "bib_venue": "[{\"end\":40229,\"start\":40169},{\"end\":40653,\"start\":40594},{\"end\":41188,\"start\":41086},{\"end\":41666,\"start\":41615},{\"end\":42148,\"start\":42082},{\"end\":42740,\"start\":42638},{\"end\":43222,\"start\":43193},{\"end\":43908,\"start\":43857},{\"end\":44444,\"start\":44348},{\"end\":44920,\"start\":44874},{\"end\":45333,\"start\":45276},{\"end\":45815,\"start\":45734},{\"end\":46342,\"start\":46276},{\"end\":46895,\"start\":46829},{\"end\":47431,\"start\":47362},{\"end\":48232,\"start\":48166},{\"end\":48811,\"start\":48709},{\"end\":49298,\"start\":49238},{\"end\":50051,\"start\":49998},{\"end\":50481,\"start\":50430},{\"end\":50960,\"start\":50886},{\"end\":51410,\"start\":51359},{\"end\":39825,\"start\":39804},{\"end\":40167,\"start\":40092},{\"end\":40592,\"start\":40518},{\"end\":41084,\"start\":40967},{\"end\":41613,\"start\":41547},{\"end\":42080,\"start\":41999},{\"end\":42636,\"start\":42519},{\"end\":43191,\"start\":43147},{\"end\":43539,\"start\":43503},{\"end\":43855,\"start\":43789},{\"end\":44346,\"start\":44235},{\"end\":44872,\"start\":44811},{\"end\":45274,\"start\":45202},{\"end\":45732,\"start\":45636},{\"end\":46274,\"start\":46193},{\"end\":46827,\"start\":46746},{\"end\":47360,\"start\":47276},{\"end\":47800,\"start\":47786},{\"end\":48164,\"start\":48083},{\"end\":48707,\"start\":48590},{\"end\":49236,\"start\":49161},{\"end\":49627,\"start\":49613},{\"end\":49996,\"start\":49928},{\"end\":50428,\"start\":50362},{\"end\":50884,\"start\":50795},{\"end\":51357,\"start\":51291},{\"end\":51734,\"start\":51642},{\"end\":52319,\"start\":52235}]"}}}, "year": 2023, "month": 12, "day": 17}