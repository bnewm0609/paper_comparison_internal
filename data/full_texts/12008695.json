{"id": 12008695, "updated": "2023-03-25 16:29:23.36", "metadata": {"title": "Hyperdimensional biosignal processing: A case study for EMG-based hand gesture recognition", "authors": "[{\"first\":\"Abbas\",\"last\":\"Rahimi\",\"middle\":[]},{\"first\":\"Simone\",\"last\":\"Benatti\",\"middle\":[]},{\"first\":\"Pentti\",\"last\":\"Kanerva\",\"middle\":[]},{\"first\":\"Luca\",\"last\":\"Benini\",\"middle\":[]},{\"first\":\"Jan\",\"last\":\"Rabaey\",\"middle\":[\"M.\"]}]", "venue": "2016 IEEE International Conference on Rebooting Computing (ICRC)", "journal": "2016 IEEE International Conference on Rebooting Computing (ICRC)", "publication_date": {"year": 2016, "month": null, "day": null}, "abstract": "The mathematical properties of high-dimensional spaces seem remarkably suited for describing behaviors produces by brains. Brain-inspired hyperdimensional computing (HDC) explores the emulation of cognition by computing with hypervectors as an alternative to computing with numbers. Hypervectors are high-dimensional, holographic, and (pseudo)random with independent and identically distributed (i.i.d.) components. These features provide an opportunity for energy-efficient computing applied to cyberbiological and cybernetic systems. We describe the use of HDC in a smart prosthetic application, namely hand gesture recognition from a stream of Electromyography (EMG) signals. Our algorithm encodes a stream of analog EMG signals that are simultaneously generated from four channels to a single hypervector. The proposed encoding effectively captures spatial and temporal relations across and within the channels to represent a gesture. This HDC encoder achieves a high level of classification accuracy (97.8%) with only 1/3 the training data required by state-of-the-art SVM on the same task. HDC exhibits fast and accurate learning explicitly allowing online and continuous learning. We further enhance the encoder to adaptively mitigate the effect of gesture-timing uncertainties across different subjects endogenously; further, the encoder inherently maintains the same accuracy when there is up to 30% overlapping between two consecutive gestures in a classification window.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2554538030", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icrc/RahimiBKBR16", "doi": "10.1109/icrc.2016.7738683"}}, "content": {"source": {"pdf_hash": "e6298dd550a4a72f9819702ce6bee578b888d316", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "1ed1f568f1cb573fb6e1dae841134aa3b7f4c2dd", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e6298dd550a4a72f9819702ce6bee578b888d316.txt", "contents": "\nHyperdimensional Biosignal Processing: A Case Study for EMG-based Hand Gesture Recognition\n\n\nAbbas Rahimi \nSimone Benatti simone.benatti@unibo.it \nPentti Kanerva pkanerva@berkeley.edu \nRedwood Center for Theoretical Neuroscience \u00a7 D-ITET, Integrated System Laboratory, ETHZ\nUniversity of California\nBerkeley., ZurichSwitzerland\n\nLuca Benini luca.benini@unibo.it \nJan M Rabaey \n\nEECS Department\nUniversity of California\nUniversity of Bologna\nBerkeleyItaly\n\nHyperdimensional Biosignal Processing: A Case Study for EMG-based Hand Gesture Recognition\n\nThe mathematical properties of high-dimensional spaces seem remarkably suited for describing behaviors produces by brains. Brain-inspired hyperdimensional computing (HDC) explores the emulation of cognition by computing with hypervectors as an alternative to computing with numbers. Hypervectors are high-dimensional, holographic, and (pseudo)random with independent and identically distributed (i.i.d.) components. These features provide an opportunity for energy-efficient computing applied to cyberbiological and cybernetic systems.We describe the use of HDC in a smart prosthetic application, namely hand gesture recognition from a stream of Electromyography (EMG) signals. Our algorithm encodes a stream of analog EMG signals that are simultaneously generated from four channels to a single hypervector. The proposed encoding effectively captures spatial and temporal relations across and within the channels to represent a gesture. This HDC encoder achieves a high level of classification accuracy (97.8%) with only 1/3 the training data required by state-of-the-art SVM on the same task. HDC exhibits fast and accurate learning explicitly allowing online and continuous learning. We further enhance the encoder to adaptively mitigate the effect of gesture-timing uncertainties across different subjects endogenously; further, the encoder inherently maintains the same accuracy when there is up to 30% overlapping between two consecutive gestures in a classification window.\n\nI. INTRODUCTION\n\nOver the past decades, the semiconductor industry has been immensely successful at increasing computing power while reducing cost and energy consumption. This has been achieved thanks to availability of efficient predictable CMOS devices supporting deterministic operations. Unfortunately energy efficiency of CMOS devices is challenged when scaling down to nanometer dimensions. Maintaining a deterministic model of computing ultimately puts a lower bound on the amount of energy scaling that can be obtained. This bound is primarily set by the variability and reliability of the devices.\n\nIt is therefore worth exploring alternative computational models that enable further size and energy scaling by abandoning the deterministic requirement. Brain-inspired information processing architectures provide significant increase in energy efficiency, asymptotically approaching the efficiency of brain computation, while aligning well with the variability of nanoscale devices [1], [2]. Our approach is focused on a computational theory called hyperdimensional computing (HDC) [5]. In this formalism, information is represented in high-dimensional vectors called hypervectors. The mathematical properties of high-dimensional spaces correlate strongly with behaviors controlled by the brain [3], [4], [5], [6], hence HDC explores the emulation of cognition by computing with hypervectors as an alternative to computing with numbers. Hypervectors are high-dimensional, e.g., 10,000 dimensions (D = 10,000), (pseudo)random with i.i.d. components, and holographic. It means that every piece of information contained in the hypervector is distributed equally over all the components. Such hypervectors can then be mathematically manipulated to not only classify but also to bind, associate, and perform other types of cognitive operations in a straightforward manner [7]. In addition, these mathematical operations also ensure that the resulting hypervector is unique and thus learning can take place in a single shot.\n\nBy requiring very low energy, hyperdimensional computing is a prime candidate for applications such as wearable biosignal processing and cybernetic systems. In addition, HDC has some unique properties and features that make it extremely well matched to emerging 3D nanoscale technology. Key properties include: (1) HDC paradigm is universal and complete. (2) In contrast to other neuro-inspired approaches, in which learning is separate from execution, learning in HDC shares its constructs with execution, is relatively lightweight, and can be realized in an online fashion on a small low-energy device. (3) By its very nature, HDC is extremely robust in the presence of component variation, defects and failure, and it tolerates noise in the signal leading to ultra low-energy computation. (4) HDC is memory-centric by manipulating and comparing large patterns, within the memory; operations are either local or can be performed in a distributed fashion.\n\nHDC has been used for language recognition as well as text classification solely from a stream of input letters. More specifically, HDC can identify the language of unknown sentences from 21 European languages [8], [2], and classify Reuters news articles to eight topics [9] with very high accuracy. In this paper, we show how HDC can be used for biosignal processing given a set of parallel and analog streaming inputs. Accordingly, we develop an encoding algorithm using HDC for hand gesture recognition from a stream of EMG signals. Our algorithm encodes a stream of analog EMG signals that are simultaneously generated from four channels to a single hypervector representing a hand gesture. The proposed encoding effectively captures spatial and temporal correlations across and within the channels to describe a gesture. Our proposed HDC surpasses the state-of-the-art support vector machine (SVM) [10] for the hand gesture recognition in four aspects: (1) HDC exhibits an average recognition accuracy of 90.8% (2% higher than SVM) by only encoding spatial correlation across the four channels. (2) Encoding also the temporal correlation by considering consecutive samples over time, boosts the accuracy of HDC to 100%, and on average to 97.8% (8.1% higher than SVM). We further enhance the encoder to adaptively mitigate the effect of gesture-timing uncertainties by endogenously observing the distance measures between the encoded input patterns and learned patterns. (3) HDC maintains the aforementioned accuracy when there is up to 30% overlapping between two gestures in a window of classification, even with reduced dimensionality of D = 6,000. (4) For the aforementioned comparisons, 25% of dataset is used for training both classifiers. HDC learns quickly, making it a prime candidate for online and continuous learning. For accuracy on par with HDC, SVM requires 3.2\u00d7 as much training data. The algorithms and techniques described in this paper are all publicly released. 1 This paper is organized as follows. In Section II, we describe EMG signal processing and its background, including data acquisition, preprocessing, system description, and finally the state-of-the-art SVM gesture classification. In Section III, we introduce hyperdimensional computing and discuss how its operations can be used to form a new classifier. In Section IV, we present our algorithm for EMG-based hand gesture recognition using hyperdimensional computing. In Section V, we provide more experimental results. Section VI concludes this paper.\n\n\nII. ELECTROMYOGRAPHY (EMG) A. EMG Signal and Acquisition\n\nThe muscular contractions are generated by the electrical activity of nerve cells called motoneurons. Their cell bodies are located in the spinal cord and their axons are directly connected to the target muscles. The stimulus that generates a muscular contraction propagates from the brain cortex to the target muscles as an electrical potential, named action potential (AP). APs are generated by the passage of Na+ and K+ ions along nerve cell membranes. As a result of this ion flow, the nerve impulses propagate towards the muscle cells and start the contractions [11]. The EMG signal represents the monitoring of this electrophysiological activity. The signal results from the superposition of all the APs of the cells underlying a couple of metal electrodes, placed on the skin and aligned parallel to the muscle fibers. The surface EMG electrodes are made by two conductive plates each one connected to the inputs of a differential amplifier that sense the action potential of muscular cells.\n\nThe maximum amplitude of this signal is 20 mV (-10 to +10) depending on the dimension of the muscle fibers, on the distance between the muscle and the electrodes and on the electrode properties. Signals of this kind are also very noisy and difficult to manage even if the maximum bandwidth does not exceed 2 kHz. The main causes are noise from motion artifacts, fiber crosstalk, electrical equipment and the floating ground of the human body.\n\nHence, the typical EMG acquisition in high-end gesture recognition applications is based on active analog sensors that 1 https://github.com/abbas-rahimi/HDC-EMG provide a high-quality signal [12]. Such sensors represent the commercial solution for EMG acquisitions, both in research and industrial applications. These sensors perform a fullanalog signal conditioning based on a bandpass discrete filter, an instrumentation amplifier with a high gain stage, and an offset cancellation feedback circuit. The bandwidth of the Ottobock [12] sensor is 90-450 Hz with a further notch filter for the 50 Hz. This is because the sensors for the classification of the gestures do not need extensive frequency information but a clear low-noise signal is preferable. The EMG raw signal is a zero-mean differential signal and the preprocessing is done in hardware by the internal circuitry of the active sensors. The EMG differential signal is integrated and a low pass filter is applied to extract the envelope of the signal. Furthermore a notch filter is applied to remove the residual power-line interference. Fig. 1 shows the raw signal acquired from the electrodes (a) and the enveloped output of the active EMG sensor (b).\n\n\nB. Background and Related Work\n\nThe robustness and the reliability are major requirements in the design of EMG gesture recognition systems. In the commercial devices, used in prosthetics [13] or telesurgery [14], the recognition of the muscular activity is based on threshold detections. The recognition of the users' intended movements are encoded in predefined sequences of muscular contractions related to the wrist flexion and extension. Despite its robustness, this approach suffers from several drawbacks, since it is a unnatural way of interaction, requiring a highlevel of concentration and a long time to learn. Instead, pattern recognition approaches aim to address these limits by proposing a natural way to recognize hand gestures based on EMG.  Several studies focused on both acquisition setup and signal processing algorithms required in this application. The number of electrodes and their placement [15] has a high impact on the design of an EMG hand gesture recognition system. Moreover, many studies have focused on machine learning techniques for EMG-based gesture recognition [16]. These techniques include both linear and nonlinear methods, such as LDA [17], SVM [18], [10], ANN [19], and a combination of two heterogeneous classifiers to obtain a better classification accuracy [20], [21]. Results show accuracies around and beyond 90% with the use of feature extraction techniques to improve the performance. The main limit of these typical machine learning approaches is the high number of training data needed to achieve such accuracies. We will show that HDC can reach the same accuracy with much less training data.\n\n\nC. System Description and Experimental Setup\n\nEMG data acquisition is based on a four sensors that cover the muscles involved in hand movement from a physiological point of view. The muscles of the forearm are divided in four groups, and the use of surface EMG sensors requires that muscle near the skin surface must be targeted for the classification. Functionally, we can separate the forearm muscles in two classes: muscles in the internal part of the forearm (flexor radialis carpi, palmares longus, flexor carpi ulnaris, flexor superioris digitalis), involved in flexion movements, and muscles placed in the external part of the forearm (externsor comunis digitorum, extensor digiti minimi, externsor carpi ulnaris), involved mainly in extension movements.\n\nBy placing sensors on the flexor carpi radialis, flexor carpi ulnaris, extensor digitorum communis and extensor carpi ulnaris we obtained a good differentiation in classification patterns. The assumption for a multi-gesture control system is that the set of signals and features describing a given state of muscular activation are different from one state of activation to another.\n\nThe dataset used in this paper is based on the collection of the EMG signals of the most common hand gesture used in daily life. The selected gestures are: closed hand, open hand, 2-finger pinch, and point index. The classification includes also the rest position of the hand, recorded between two subsequent gestures. The data were collected from nine subjects [22]. Here, we use a subset of the data for five subjects. The collected sequences are composed of 10 repetitions of muscular contraction three seconds each. Between each contraction there are three seconds of rest. The gestures are sampled at 500 Hz. Subjects wear an elastic strip with the four EMG sensors [12]. See Fig. 1.\n\nThe theoretical framework of the SVM is the evolution of the logistic regression methods, through the application of the large margin classification. The goal of training is to define the optimal separation hyperplanes between classes by minimizing a cost function. Such hyperplanes are made up of a subset of the input data, and their vectors are called support vectors (SVs). The SVs are calculated through the the solution of a convex optimization problem [23] that produces the global minimum of the cost function.\n\nDue to its robustness and the good results reported in the literature, SVM has become the classification technique of choice for EMG-based gesture recognition [24], [25], [26]. The classification algorithm calculates the distance of the input data from this decision boundary. When the two classes are not linearly separable the data space is mapped to an higher-dimensional space through a kernel trick to define a similarity function between the margin hyperplane and the classification data. The classification algorithm is based on a decision function that calculates the distances of an input vector with all the SVs. In particular, the formula of the decision function to classify a new input instance is:\nf (x) = N i=1 y i \u03b1 i K x, s i \u2212 \u03c1 f (x) > 0, x \u2208 Cl 1 f (x) < 0, x \u2208 Cl 2(1)\nwhere Cl 1 and Cl 2 , are the two classes, x \u2208 R k is the input features vector, s i \u2208 R k , i = 1, ..., N are the support vectors, \u03b1 i are the support values, while y i denotes the class they reference (y i = +1 for Cl 1 , y i = \u22121 for Cl 2 ) and K \u00b7, \u00b7 denotes the kernel function. Fig. 2 shows training and testing (classification) flows for SVM. The EMG dataset is labeled using a threshold assigning the gesture labels to the input EMG data. We use 25% of this dataset to generate training data using a uniform random sampling. This training session can be performed offline. In Section V-B, we explore the trade-offs with increasing the fraction of training data. These labeled data are the input of the training algorithm that builds the SVM model (i.e., the list of the SVs). The decision function (1) calculates the label of an input vector comparing its distance from the SVs that represent the decision boundary The output is the label associated with a decoded gesture. The SVM and the HDC are trained and tested on the same data as shown in Fig. 2.\n\nIII. HYPERDIMENSIONAL COMPUTING BACKGROUND The brain's circuits are massive in terms of numbers of neurons and synapses, suggesting that large circuits are fundamental to the brain's computing. Hyperdimensional computing [5], [6] explores this idea by looking at computing with ultra-wide words -that is, with very high-dimensional vectors, or hypervectors. There exist a huge number of different, nearly orthogonal hypervectors with the dimensionality in the thousands (D = 10,000) [27]. This lets us combine two such hypervectors into a new hypervector using well-defined vector space operations, while keeping the information of the two with high probability.\n\nHypervectors are made using random indexing [3], [4] with operations akin to multiplication, addition, and permutation that form an algebra over the vector space (e.g., a field). Random indexing represents information by projecting data onto hypervectors. It is incremental, scalable, and computes hypervectors in a single pass over the input data. Random indexing generates hypervectors that are initially taken from a 10,000-dimensional space and have an equal number of randomly placed +1s and \u22121s, i.e., {\u22121, +1} 10,000 . Such hypervectors are used to represent the basic elements, e.g., the 26 letters of the Latin alphabet and the (ASCII) space for text inputs. These seed letter hypervectors are generated (pseudo)randomly with i.i.d. components. Hypervectors are holographic, too; a hypervector contains all the information combined and spread across all its bits in a full holistic representation so that no bit is more responsible to store any piece of information than another. Hypervectors can be compared for similarity using a distance metric over the vector space.\n\nHyperdimensional computing has been used for identifying the source language of text samples from a sequence of N consecutive letters (N -grams) [8], [2]. The letter trigrams of a text sample are encoded into a hypervector by the random indexing and vector space operations to represent a language. In the same vein, pentagrams of letters have been used for classifying news articles [9].\n\n\nA. MAP Operations\n\nWe consider a variant of the multiplication, addition, and permutation (MAP) coding described in [28] to define the hyperdimensional vector space. The MAP operations on the hypervectors are defined as follows. Point-wise multiplication of two hypervectors A and B, is denoted by A * B. It produces a vector that is dissimilar to its constituent vectors; hence multiplication is well suited for binding two hypervectors. Point-wise addition is denoted by A + B. Information from a pair of hypervectors A and B is stored and utilized in a single hypervector by exploiting the addition operation. That is, the sum of two separate hypervectors naturally preserves unique information from each hypervector because of the mathematical properties of vector addition. This addition is well suited for representing sets. Multiplication, or binding, takes two vectors and yields a third, A * B , that is dissimilar (orthogonal) to the two; and addition, or bundling, takes several vectors and yields their mean vector [A + B + ... + X] that is maximally similar to them. In the following, we describe how these two operations can holistically encode a data record composed of various fields [7].\n\nA data record consists of a set of variables (attributes, fields) and their values (fillers); for example, the variables x, y, z with values a, b, c, respectively. The holistic encoding is done as follows. The variable-value pair x = a is encoded by the hypervector X * A that binds the corresponding hypervectors, and the entire record is encoded by the hypervector R = [(X * A) + (Y * B) + (Z * C)] which includes both the variables and the values, and each of them spans the entire 10,000-bit hypervector.\n\nFinally, the third operation is a permutation, \u03c1, that rotates the hypervector coordinates. It is implemented as a cyclic right-shift by one position. The permutation operation generates a dissimilar pseudo-orthogonal hypervector that is good for storing a sequence. In geometry sense, the permutation rotates the hypervector in the space. For example, the sequence trigram of a-b-c, is stored as the hypervector \u03c1(\u03c1A * B) * C = \u03c1\u03c1A * \u03c1B * C. This efficiently distinguishes the sequence a-b-c from a-c-b, since a rotated hypervector is uncorrelated to all the other hypervectors.\n\nCosine similarity is used to measure similarity between two hypervectors by measuring the cosine of the angle between them using a dot product. It is defined as cos(A, B) = |A * B |, where A and B are the length-normalized vectors of A and B, respectively, and |C| denotes the sum of the elements in C. It is thus a measure of orientation and not magnitude: two hypervectors with the same orientation have a cosine similarity of 1, two orthogonal hypervectors have a similarity of 0, and two hypervectors diametrically opposed have a similarity of \u22121.\n\n\nIV. HDC ENCODING FOR EMG SIGNALS\n\nIn this section, we describe how MAP operations can be used to encode the enveloped EMG signals. As described in Section II-A, there are four channels and every channel produces an analog signal with an amplitude of 0 mV to 20 mV. To have a linear quantization with a resolution of 1 mV, we discretize the channel's signal to 21 discrete levels as shown in Fig. 4. We design an encoder that accepts a stream of such discretized levels from the channels and computes a hypervector that represents a gesture. We first describe how spatial correlation across the channels can be encoded.\n\n\nA. Encoding Spatial Correlation into a Holistic Record\n\nWe draw an analogy from [7] to generate a holistic record to bind information across the channels together. Each channel is treated as a separate field, and its signal level is interpreted as a value for the field. Hence, there are four fields in the record, namely, CH1, CH2, CH3, and CH4. To represent these fields into hyperspace, we use an item memory (iM) that assigns a unique but random hypervector to every field. This assignment is fixed throughout the computation, and formed four unique orthogonal hypervectors, {iM(CH1) \u22a5 iM(CH2) \u22a5 iM(CH3) \u22a5 iM(CH4)}, as the basic fields. Fig. 3(left) illustrates the cosine similarity measures between these hypervectors in iM which is implemented using a lookup table with four symbols.\n\nEvery field has to be assigned its value which is a signal level ranging from 0 to 20. To represent these 21 discrete levels, we use a method of mapping quantities and dates \"continuously\" to hypervectors [29]. In this continuous vector space, orthogonal endpoint hypervectors are generated for the minimum and maximum levels in the range. Hypervectors for intermediate levels are then generated by weighted interpolation between these endpoints. To perform such mapping we consider a continuous item memory (CiM). CiM assigns an orthogonal hypervector for the minimum signal level (0 mV). For the remaining 20 levels, their corresponding hypervectors are generated by getting gradually further from the minimum hypervector such that the hypervector for maximum signal level (20 mV) is orthogonal to the minimum one, i.e., CiM(0  \n\n\nOE\n\n\nN-gram[t]\n\n\nOE(R[t-1]) OE OE 2 (R[t-2]) OE\n\n\n* OE N-1 (R[t-N+1]) R[t]\n\nSpatial encoder Temporal encoder Y Fig. 4. Spatiotemporal HDC encoder: 1) Spatial encoder to capture correlation across the channels by forming a holistic record; 2) Temporal encoder to capture correlations within channels by rotating records to generate N -gram. mV) \u22a5 CiM(20 mV). If two hypervectors are dissimilar in D/2 of their components, they are orthogonal to each other. Hence, in each step of generating a new hypervector for the next intermediate levels, we flip D/2/20 components of the hypervector assigned to the previous level. Such continuous mapping better represents the adjacent levels since their corresponding hypervectors are similar to each other. Fig. 3(right) illustrates the cosine similarity measures between each pair of hypervectors in CiM. As opposed to iM, the similarity between hypervectors in CiM is smooth, hence continuous. CiM is implemented using a lookup table as catalogs of meaningful levels with 21 symbols.\n\nThe projection of a channel to the hyperspace is done by pairing a vector from iM with a vector from CiM. We quadruple iM and CiM, with the same contents, for all four channels to allow simultaneous mapping of the EMG inputs to the hyperspace as shown in the left side of Fig. 4. After projecting into the hyperspace, the multiplication operation is used to bind each channel to its signal level for every timestamp t, for instance, for the first channel, iM(CH1) * ). This record captures the spatial correlation between the four channels for a given time-aligned sample of EMG signals.\n\nNext step is to generate a gesture hypervector, GV, to represent a known gesture. We generate five such vectors, each of which representing one of the five gestures described in Section II-C. As mentioned, in our training dataset each timestamp t is labeled with a gesture tag Label[t]\u2208 {1, 2, 3, 4, 5}, including the rest position. For every gesture, its corresponding GV acts as a set that contains all the records that are labeled with that specific gesture. Hence, the addition operation bundles R[t] observed in every timestamp to a single sum hypervector GV as follows: GV(Label[t]) += R[t]. Before adding a new record R[t] to GV, we check whether this record is already in GV. This checking forms a conditional addition that adds R[t] to GV when cos(GV (Label[t]), R[t]) < 0.9. If GV has a high cosine similarity (\u2265 0.9) with R[t], it means that the record is already in GV, hence there is no need to add the redundant record.\n\nAfter training, these five GVs are stored in an associative memory as the learned patterns. The same encoding is used for both training and testing (i.e., classification) as shown in Fig. 2. When testing, we call the output of the encoder a \"query hypervector\" since its label is unknown. In the spatial encoder, the query hypervector is a record R[t] because we are performing sample-by-sample classification. The query hypervector is then sent to the associative memory to identify its source gesture. Determining the gesture of an unknown sample is done by comparing its query to all stored GVs using the cosine similarity. Finally, the associative memory selects the highest similarity among the five measures and returns its associated label as the gesture that the query hypervector has been generated from. Fig. 5 compares the classification accuracy of HDC using this spatial encoding with SVM described in Section II-C. Across five subjects, HDC achieved on average 90.8% classification accuracy, 2% higher than SVM. We have observed that most of misclassifications take place during transitions between two consecutive gestures. This is due to purely vertical slicing of EMG signals. Moreover, a gesture has time-dependent components that require considering a set of samples over time. To address this issue, we develop a temporal encoder applied in cascade after the aforementioned spatial encoder, described in the following section.\n\n\nB. Encoding Spatiotemporal Correlations by Rotating Records\n\nHDC can encode sequences by using the permutation operation, \u03c1. As shown in Section III-A, permutation has been used to encode a sequence of N letters to form an N -gram hypervector. By analogy, a sequence of four records with time stamps t\u22123, t\u22122, t\u22121, t is encoded as follows: The first hypervector R[t\u22123] is rotated thrice \u03c1 3 R[t\u22123], the second hypervector is rotated twice \u03c1 2 R[t\u22122], the third is rotated once \u03c1 R[t\u22121], and finally there is no rotation for the last hypervector R[t]. The four hypervectors are then combined with point-wise multiplication into a single hypervector for the tetragram, as shown in Fig. 4. For N -grams at large this becomes N -\ngram[t]= N \u22121 i=0 \u03c1 i R[t\u2212i].\nAs done in the spatial encoder, a single sum hypervector GV is computed for every gesture using the conditional addition: GV(Label[t]) += Ngram[t]. These five GVs are stored into the associative memory as the spatiotemporal learned patterns.\n\nWith this encoding algorithm, one important step is to determine the proper size of an N -gram to be able to capture the entire gesture. In this regard, we measured the number of samples available in a gesture. The first two columns of Table I show the mean (i.e., duration) and standard deviation for the number of samples during various gestures of every subject. As mentioned in Section II-C, every gesture is three seconds long sampled at 500 Hz. To fit the samples of a gesture in an Ngram, we applied a downsampling by integer factors shown in the third column. Hence, the gestures can be represented by Ngrams where N \u2208 [1,10]. However, for testing and classifying a gesture, there is typically a window of W samples where W > N . Hence, we slide the N -gram through the window one step at a time and generate W \u2212 N + 1 N -grams as query hypervectors, among which we choose the one that has the highest similarity with the stored GVs in the associative memory. Fig 7 shows accuracy results of this classification when using different N -grams. Using N -grams with N \u2265 2 significantly improves the classification accuracy, while there is a saturation or drop in accuracy for N -gram sizes larger than 6. The last column in Table I lists the sizes for N that maximize accuracy for each subject. Using these N -grams in HDC leads to 97.8% classification accuracy averaged across the five subjects. HDC with spatiotemporal encoding shows 7% higher accuracy compared to solely spatial encoding.\n\nWe also compare the classification accuracy of downsampled EMG signals with SVM. In Section II-C, the four channels have been used as the input features for SVM compatible with [10]. To capture temporal correlations in SVM, we use all samples in an N -gram as the features. This forms a brute-force SVM with 4N input features. As shown in Fig 7, accuracy of SVM gets worse by using N > 1. Its best accuracy, on average 89.7%, is achieved with N = 1. By using the N -grams listed in Table I HDC achieves on average 8.1% higher accuracy compared to SVM with N = 1.\n\n\nC. Adaptive Encoder Using Feedback\n\nAlthough the temporal correlations are well-captured by the proper N -gram, its size varies from subject to subject. For instance, even with using the same downsampling rate of 250, the best N -gram sizes for subjects S3 and S4 are 3 and 5.\n\nTo mitigate the effect of such dynamic gesture-timing uncertainties across subjects, we design an adaptive mechanism to adjust the size of N -grams during classification. To control the size of N -grams on-the-fly, we define a feedback to close  Fig. 6. Using feedback to adaptively tune N -grams based on stored patterns in associative memory.\n\na loop from the associative memory to the encoder as shown in Fig. 6. We use the cosine similarity metric produced in the associative memory as the criterion and maximize it by tuning the size of N -gram for the encoder. This controller starts with an individual spatial record (N = 1) and measures its corresponding cosine similarity through the feedback. If the measured similarity is low, the controller keeps increasing N in the available range until a maximum similarity is reached. Fig. 8 shows the cosine similarity tested for various Ngrams, where N \u2208 [1,10], when the associative memory is trained for a fixed N -gram. The graphs show average and standard deviation of cosine similarity for all available gestures in the dataset. As shown, the cosine similarity is maximized when the size of N -gram used for encoder is matched with the size of N -gram patterns that are stored in the associative memory. Such a distinction is extremely robust: when the tested N -gram (in the encoder) and the trained N -gram (in the associative memory) are matched, the cosine similarity is 13.1\u00d7 larger on average, with a very large safety margin. This ensures that by looking at the output of the associative memory the proper size of N -gram for the encoder can be inferred. The presented feedback mechanism enables an adaptive encoder to be robustly reused across various subjects (independent of their chosen N ) for the classification.\n\n\nV. EXPERIMENTAL RESULTS\n\nIn this section, we present more experimental results and sensitivity analyses for classification accuracy. For every experiment (Figs 9 and 10), we measure the mean and the standard deviation of classification accuracy across the five subjects.\n\n\nA. Overlapping Gestures in a Classification Window\n\nAlthough capturing temporal correlations of the EMG signal improves classification accuracy in principle, it poses two main challenges: (1) What is the proper size of an N -gram to represent the gestures? (2) What if the window of the signal to be classified is wider than the trained N -gram? Using the feedback presented in Section IV-C addresses the first issue; HDC can determine N -gram for encoding based on the stored patterns in the associative memory. Here, we address the second issue. Such an N -gram typically lies in a window with W > N samples to be used for identifying the gesture. The results presented in the earlier sections contain only one gesture in the classification window. Here, we widen  the window so that it can include multiple gestures (up to 3). This experiment assesses the ability of HDC to identify the correct gesture when there is no precise partitioning between consecutive gestures but a \"gray\" region between them. Fig. 9 shows the classification accuracy with increasing gesture-timing uncertainties as the number of gestures in the window is increased from 1 to 3. Our labeling considers the first gesture in the window as the true label, assuming the subject is moving very quickly. HDC maintains its original accuracy of 97.8% if there is up to 30% overlapping between two gestures in a single window of classification. The accuracy Number of gestures in a single window of classification 1 1 .1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2 2.1 2.2 2 drops to 79.8% when there are two gestures in the window, and finally to 46.9% with three gestures.\n\n\nB. Learning Rate\n\nAs mentioned in Section II-C, only 25% of the dataset is used for training in the results presented thus far. Fig. 10 explores the classification accuracy as a function of training set size. The classification accuracy is improved by increasing the fraction of training data for both SVM and HDC, but their learning slopes are different. HDC shows an average accuracy of 86.8% when 10% of total dataset is used for training. By increasing the training fraction to 25%, HDC reaches to 97.8% accuracy; after this point increasing the training fraction does not bring accuracy improvement. However, this is not the case for SVM since it requires 3.2\u00d7 as much training data (i.e., 80%) to reach to the same accuracy as HDC does with 25%.\n\nIncreasing the fraction of training data increases the number of support vectors used in SVM: by increasing the training fraction from 10% to 80%, the number of support vectors increases from 30 to 155. This translates directly to higher execution time during classification. On the other hand, HDC adds more patterns into the GVs since increasing the training set size generates new N -grams that are not yet in the sum hypervectors. For instance, HDC adds 83 new patterns by moving from 10% to 25%. However, HDC uses the same hardware structure to store these extra patterns, hence increasing the number of learned patterns does not impact the classification time. In addition, the operations needed for learning and classification are similar in HDC, explicitly allowing continuous learning. In a nutshell, HDC learns quickly and its ability to exploit low-precision scalar operations within a \"fixed\" hardware structure makes it a prime candidate for online low-cost learning.\n\nWe further measure the accuracy of HDC while reducing dimensionality of hypervectors from D = 10,000 to D = 100. HDC is able to maintain its original accuracy by reducing D to 6,000. After this point, the accuracy drops to 96% until D\n\nFig. 1 .\n1EMG Signal: (a) Raw acquired data, (b) Enveloped data.\n\nFig. 2 .\n2Training and classification scheme for SVM and HDC.\n\nFig. 3 .\n3Cosine similarity between hypervectors stored in iM and CiM.\n\n\nCiM(S CH1 [t]). Finally, to form a record (R[t]) all the four bound fields are bundled by addition operations, i.e., R[t] = iM(CH1) * CiM(S CH1 [t]) + iM(CH2) * CiM(S CH2 [t]) + iM(CH3) * CiM(S CH3 [t]) + iM(CH4) * CiM(S CH4 [t]\n\nFig. 5 .\n5Sample-by-sample gesture classification using spatial encoder.\n\nFig. 7 .Fig. 8 .\n78Classification accuracy for various sizes of N -gram using spatiotemporal encoder. Cosine similarity measures for various tested N -grams when the associative memory is trained with a fixed N -gram.\n\nFig. 9 .\n9Accuracy with overlapping gestures in a classification window.\n\nTABLE I STATISTICS\nIFOR THE NUMBER OF SAMPLES IN A GESTURE.Subjects \nMean \nStd \nDownsampling \nN \nS1 \n1809 \n503 250 \n4 \nS2 \n1678 \n814 250 \n4 \nS3 \n1666 \n941 250 \n3 \nS4 \n1563 \n590 250 \n5 \nS5 \n1148 \n542 50 \n4 \n\n\n= 300. Below this dimension, the accuracy drops significantly to 62%. We should not that the implementation of HDC is hardware friendly, and exhibits energy efficiency and robustness benefits compared to the traditional machine learning methods[2]. Hyperdimensional computing is memory-centric and effectively merges computation and storage into a single fabric. Its implementation can be accomplished in a traditional 2D process, however a 3D approach where logic and memory are stacked on top of each other can lead to a far more efficient realization.VI. CONCLUSIONThis paper presents an application of hyperdimensional computing to the classification of hand gestures from Electromyography recordings. Very simple vector-space operations are used to encode analog input signals for classification. Our algorithm encodes spatiotemporal EMG signals from multiple channels into a hypervector representing a gesture and achieves a high level of accuracy (97.8%) with only 1/3 the training data required by state-of-the-art support vector machines. Programming HDC is learning-based and uses the same algorithms as subsequent classification. HDC can be adaptive and the resulting classification accuracy is robust: our encoder can adjust to variations in gesture-timing and other uncertainties across different subjects, for each of which the classification can be done correctly even with 30% overlapping between two neighboring gestures. VII. ACKNOWLEDGMENT This work was supported by Systems on Nanoscale Information fabriCs (SONIC), one of the six SRC STARnet Centers, sponsored by MARCO and DARPA.\nA 0.25 V 460 nW asynchronous neural signal processor with inherent leakage suppression. T.-T Liu, J Rabaey, IEEE Journal. 48Solid-State CircuitsT.-T. Liu and J. Rabaey, \"A 0.25 V 460 nW asynchronous neural signal processor with inherent leakage suppression,\" Solid-State Circuits, IEEE Journal of, vol. 48, pp. 897-906, April 2013.\n\nA robust and energy efficient classifier using brain-inspired hyperdimensional computing. A Rahimi, P Kanerva, J M Rabaey, IEEE/ACM International Symposium on. in Low Power Electronics and DesignA. Rahimi, P. Kanerva, and J. M. Rabaey, \"A robust and energy efficient classifier using brain-inspired hyperdimensional computing,\" in Low Power Electronics and Design (ISLPED), 2016 IEEE/ACM International Symposium on, August 2016.\n\nRandom indexing of text samples for latent semantic analysis. P Kanerva, J Kristoferson, A Holst, Proceedings of the 22nd Annual Conference of the Cognitive Science Society. the 22nd Annual Conference of the Cognitive Science SocietyErlbaum1036P. Kanerva, J. Kristoferson, and A. Holst, \"Random indexing of text samples for latent semantic analysis,\" in Proceedings of the 22nd Annual Conference of the Cognitive Science Society, p. 1036, Erlbaum, 2000.\n\nAn introduction to random indexing. M Sahlgren, Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering. M. Sahlgren, \"An introduction to random indexing,\" in Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering, TKE 2005, 2005.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive Computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors,\" Cognitive Com- putation, vol. 1, no. 2, pp. 139-159, 2009.\n\nComputing with 10,000-bitwords. P Kanerva, Proc. 52nd Annual Allerton Conference on Communication, Control, and Computing. 52nd Annual Allerton Conference on Communication, Control, and ComputingP. Kanerva, \"Computing with 10,000-bitwords,\" in Proc. 52nd Annual Allerton Conference on Communication, Control, and Computing, 2014.\n\nWhat we mean when we say 'What's the dollar of Mexico?': Prototypes and mapping in concept space. P Kanerva, AAAI Fall Symposium: Quantum Informatics for Cognitive, Social, and Semantic Processes. P. Kanerva, \"What we mean when we say 'What's the dollar of Mexico?': Prototypes and mapping in concept space,\" in AAAI Fall Symposium: Quantum Informatics for Cognitive, Social, and Semantic Processes, pp. 2-6, 2010.\n\nLanguage recognition using random indexing. A Joshi, J Halseth, P Kanerva, Quantum Interaction 2016 Conference Proceedings. in pressA. Joshi, J. Halseth, and P. Kanerva, \"Language recognition using random indexing,\" in Quantum Interaction 2016 Conference Proceedings, in press.\n\nHyperdimensional computing for text classification. F R Najafabadi, A Rahimi, P Kanerva, J M Rabaey, Design, Automation Test in Europe Conference Exhibition (DATE). University BoothF. R. Najafabadi, A. Rahimi, P. Kanerva, and J. M. Rabaey, \"Hyperdimensional computing for text classification,\" Design, Automation Test in Europe Conference Exhibition (DATE), University Booth, 2016.\n\nA versatile embedded platform for EMG acquisition and gesture recognition. S Benatti, F Casamassima, B Milosevic, E Farella, P Schnle, S Fateh, T Burger, Q Huang, L Benini, IEEE Transactions on Biomedical Circuits and Systems. 9S. Benatti, F. Casamassima, B. Milosevic, E. Farella, P. Schnle, S. Fateh, T. Burger, Q. Huang, and L. Benini, \"A versatile embedded platform for EMG acquisition and gesture recognition,\" IEEE Transactions on Biomedical Circuits and Systems, vol. 9, pp. 620-630, Oct 2015.\n\nMuscles alive. J V Basmajian, C De Luca, Muscles alive: their functions revealed by electromyography. 278126J. V. Basmajian and C. De Luca, \"Muscles alive,\" Muscles alive: their functions revealed by electromyography, vol. 278, p. 126, 1985.\n\nOttobock Sensor 13E200. \"Ottobock Sensor 13E200.\" http://www.ottobock.com/.\n\nExperimental study of an EMG-controlled 5-dof anthropomorphic prosthetic hand for motion restoration. D Yang, L Jiang, Q Huang, R Liu, H Liu, J. Intell. Robotics Syst. 76D. Yang, L. Jiang, Q. Huang, R. Liu, and H. Liu, \"Experimental study of an EMG-controlled 5-dof anthropomorphic prosthetic hand for motion restoration,\" J. Intell. Robotics Syst., vol. 76, pp. 427-441, 2014.\n\nEmg-based teleoperation of a robot arm using low-dimensional representation. P K Artemiadis, K J Kyriakopoulos, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems. P. K. Artemiadis and K. J. Kyriakopoulos, \"Emg-based teleoperation of a robot arm using low-dimensional representation,\" in 2007 IEEE/RSJ International Con- ference on Intelligent Robots and Systems, pp. 489-495, Oct 2007.\n\nA comparison of surface and intramuscular myoelectric signal classification. L Hargrove, K Englehart, B Hudgins, Biomedical Engineering. 54IEEE Transactions onL. Hargrove, K. Englehart, and B. Hudgins, \"A comparison of surface and intramuscular myoelectric signal classification,\" Biomedical Engineering, IEEE Transactions on, vol. 54, pp. 847-853, May 2007.\n\nMyoelectric control systemsa survey. Biomedical Signal Processing and Control. 24\"Myoelectric control systemsa survey,\" Biomedical Signal Processing and Control, vol. 2, no. 4, pp. 275 -294, 2007.\n\nAn adaptation strategy of using LDA classifier for EMG pattern recognition. H Zhang, Y Zhao, F Yao, L Xu, P Shang, G Li, International Conference of the IEEE Engineering in Medicine and Biology Society. H. Zhang, Y. Zhao, F. Yao, L. Xu, P. Shang, and G. Li, \"An adaptation strategy of using LDA classifier for EMG pattern recognition,\" in International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 4267-4270, 2013.\n\nSupport vector machine-based classification scheme for myoelectric control applied to upper limb. M A Oskoei, S Member, H Hu, M. A. Oskoei, S. Member, and H. Hu, \"Support vector machine-based classification scheme for myoelectric control applied to upper limb.\"\n\nElectromygraphy (EMG) signal based hand gesture recognition using artificial neural network (ANN). M Ahsan, M Ibrahimy, O Khalifa, 4th International Conference On. Mechatronics (ICOM)M. Ahsan, M. Ibrahimy, and O. Khalifa, \"Electromygraphy (EMG) signal based hand gesture recognition using artificial neural network (ANN),\" in Mechatronics (ICOM), 2011 4th International Conference On, pp. 1-6, May 2011.\n\nHybrid soft computing systems for electromyographic signals analysis: a review. H.-B Xie, T Guo, S Bai, S Dokos, BioMedical Engineering OnLine. 131H.-B. Xie, T. Guo, S. Bai, and S. Dokos, \"Hybrid soft computing systems for electromyographic signals analysis: a review,\" BioMedical Engineering OnLine, vol. 13, no. 1, pp. 1-19, 2014.\n\nHybrid EMG classifier based on HMM and SVM for hand gesture recognition in prosthetics. M Rossi, S Benatti, E Farella, L Benini, Industrial Technology, 2015 IEEE International Conference on. IEEEM. Rossi, S. Benatti, E. Farella, and L. Benini, \"Hybrid EMG classifier based on HMM and SVM for hand gesture recognition in prosthetics,\" in Industrial Technology, 2015 IEEE International Conference on, pp. 1700-1705, IEEE, 2015.\n\nAnalysis of robust implementation of an EMG pattern recognition based control. S Benatti, E Farella, E Gruppioni, L Benini, International Conference on Bio-inspired Systems and Signal Processing. S. Benatti, E. Farella, E. Gruppioni, and L. Benini, \"Analysis of robust implemen- tation of an EMG pattern recognition based control,\" in International Conference on Bio-inspired Systems and Signal Processing 2014, pp. 45-54, 2014.\n\nMultiplicative updates for nonnegative quadratic programming in support vector machines. F Sha, L K Saul, D D Lee, Advances in neural information processing systems. F. Sha, L. K. Saul, and D. D. Lee, \"Multiplicative updates for nonnegative quadratic programming in support vector machines,\" in Advances in neural information processing systems, pp. 1041-1048, 2002.\n\nEMG-based hand gesture recognition with flexible analog front end. S Benatti, B Milosevic, F Casamassima, P Schnle, P Bunjaku, S Fateh, Q Huang, L Benini, 2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings. S. Benatti, B. Milosevic, F. Casamassima, P. Schnle, P. Bunjaku, S. Fateh, Q. Huang, and L. Benini, \"EMG-based hand gesture recognition with flexible analog front end,\" in 2014 IEEE Biomedical Circuits and Systems Conference (BioCAS) Proceedings, pp. 57-60, Oct 2014.\n\nSurface EMG pattern recognition for real-time control of a wrist Exoskeleton. Z O Khokhar, Biomedical engineering online. 91Z. O. Khokhar, et al., \"Surface EMG pattern recognition for real-time control of a wrist Exoskeleton,\" Biomedical engineering online, 9(1), 2010.\n\nEMG pattern recognition and grasping force estimation: Improvement to the myocontrol of multi-dof prosthetic hands. D Yang, J Zhao, Y Gu, L Jiang, H Liu, IEEE/RSJ International Conference on. IEEEIntelligent Robots and SystemsD. Yang, J. Zhao, Y. Gu, L. Jiang, and H. Liu, \"EMG pattern recognition and grasping force estimation: Improvement to the myocontrol of multi-dof prosthetic hands,\" in Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ International Conference on, pp. 516-521, IEEE, 2009.\n\nP Kanerva, Sparse Distributed Memory. Cambridge, MA, USAMIT PressP. Kanerva, Sparse Distributed Memory. Cambridge, MA, USA: MIT Press, 1988.\n\nMultiplicative binding, representation operators & analogy. R W Gayler, Advances in analogy researchR. W. Gayler, \"Multiplicative binding, representation operators & analogy,\" Ad- vances in analogy research, 1998.\n\nReasoning with vectors: A continuous model for fast robust inference. D Widdows, T Cohen, Logic Journal of the IGPL. 232D. Widdows and T. Cohen, \"Reasoning with vectors: A continuous model for fast robust inference,\" in Logic Journal of the IGPL, vol. 23, no. 2, pp. 141-173, 2015.\n", "annotations": {"author": "[{\"end\":107,\"start\":94},{\"end\":147,\"start\":108},{\"end\":329,\"start\":148},{\"end\":363,\"start\":330},{\"end\":377,\"start\":364},{\"end\":456,\"start\":378}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":100},{\"end\":122,\"start\":115},{\"end\":162,\"start\":155},{\"end\":341,\"start\":335},{\"end\":376,\"start\":370}]", "author_first_name": "[{\"end\":99,\"start\":94},{\"end\":114,\"start\":108},{\"end\":154,\"start\":148},{\"end\":334,\"start\":330},{\"end\":367,\"start\":364},{\"end\":369,\"start\":368}]", "author_affiliation": "[{\"end\":328,\"start\":186},{\"end\":455,\"start\":379}]", "title": "[{\"end\":91,\"start\":1},{\"end\":547,\"start\":457}]", "venue": null, "abstract": "[{\"end\":2029,\"start\":549}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3025,\"start\":3022},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3030,\"start\":3027},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3125,\"start\":3122},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3338,\"start\":3335},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3343,\"start\":3340},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3348,\"start\":3345},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3353,\"start\":3350},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3910,\"start\":3907},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4418,\"start\":4415},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5231,\"start\":5228},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5236,\"start\":5233},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5292,\"start\":5289},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5925,\"start\":5921},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6121,\"start\":6118},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7005,\"start\":7004},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8189,\"start\":8185},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9257,\"start\":9253},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9598,\"start\":9594},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10471,\"start\":10467},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10491,\"start\":10487},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11200,\"start\":11196},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11381,\"start\":11377},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11459,\"start\":11455},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11469,\"start\":11465},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":11475,\"start\":11471},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11485,\"start\":11481},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11585,\"start\":11581},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11591,\"start\":11587},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13438,\"start\":13434},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":13747,\"start\":13743},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14225,\"start\":14221},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14445,\"start\":14441},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14451,\"start\":14447},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14457,\"start\":14453},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16359,\"start\":16356},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16364,\"start\":16361},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16622,\"start\":16618},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16846,\"start\":16843},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16851,\"start\":16848},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":18028,\"start\":18025},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18033,\"start\":18030},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18267,\"start\":18264},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":18391,\"start\":18387},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":19474,\"start\":19471},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21826,\"start\":21823},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":22744,\"start\":22740},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":28997,\"start\":28994},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":29000,\"start\":28997},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":30046,\"start\":30042},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":31617,\"start\":31614},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":31620,\"start\":31617},{\"end\":34253,\"start\":34250}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36438,\"start\":36373},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36501,\"start\":36439},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36573,\"start\":36502},{\"attributes\":{\"id\":\"fig_4\"},\"end\":36804,\"start\":36574},{\"attributes\":{\"id\":\"fig_5\"},\"end\":36878,\"start\":36805},{\"attributes\":{\"id\":\"fig_6\"},\"end\":37097,\"start\":36879},{\"attributes\":{\"id\":\"fig_7\"},\"end\":37171,\"start\":37098},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":37380,\"start\":37172}]", "paragraph": "[{\"end\":2637,\"start\":2048},{\"end\":4058,\"start\":2639},{\"end\":5016,\"start\":4060},{\"end\":7557,\"start\":5018},{\"end\":8616,\"start\":7618},{\"end\":9060,\"start\":8618},{\"end\":10277,\"start\":9062},{\"end\":11923,\"start\":10312},{\"end\":12687,\"start\":11972},{\"end\":13070,\"start\":12689},{\"end\":13760,\"start\":13072},{\"end\":14280,\"start\":13762},{\"end\":14993,\"start\":14282},{\"end\":16133,\"start\":15072},{\"end\":16797,\"start\":16135},{\"end\":17878,\"start\":16799},{\"end\":18268,\"start\":17880},{\"end\":19475,\"start\":18290},{\"end\":19985,\"start\":19477},{\"end\":20566,\"start\":19987},{\"end\":21119,\"start\":20568},{\"end\":21740,\"start\":21156},{\"end\":22533,\"start\":21799},{\"end\":23365,\"start\":22535},{\"end\":24393,\"start\":23444},{\"end\":24982,\"start\":24395},{\"end\":25917,\"start\":24984},{\"end\":27365,\"start\":25919},{\"end\":28093,\"start\":27429},{\"end\":28365,\"start\":28124},{\"end\":29863,\"start\":28367},{\"end\":30427,\"start\":29865},{\"end\":30706,\"start\":30466},{\"end\":31052,\"start\":30708},{\"end\":32489,\"start\":31054},{\"end\":32762,\"start\":32517},{\"end\":34400,\"start\":32817},{\"end\":35154,\"start\":34421},{\"end\":36136,\"start\":35156},{\"end\":36372,\"start\":36138}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15071,\"start\":14994},{\"attributes\":{\"id\":\"formula_1\"},\"end\":28123,\"start\":28094}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":28610,\"start\":28603},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":29603,\"start\":29596},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30354,\"start\":30347}]", "section_header": "[{\"end\":2046,\"start\":2031},{\"end\":7616,\"start\":7560},{\"end\":10310,\"start\":10280},{\"end\":11970,\"start\":11926},{\"end\":18288,\"start\":18271},{\"end\":21154,\"start\":21122},{\"end\":21797,\"start\":21743},{\"end\":23370,\"start\":23368},{\"end\":23382,\"start\":23373},{\"end\":23415,\"start\":23385},{\"end\":23442,\"start\":23418},{\"end\":27427,\"start\":27368},{\"end\":30464,\"start\":30430},{\"end\":32515,\"start\":32492},{\"end\":32815,\"start\":32765},{\"end\":34419,\"start\":34403},{\"end\":36382,\"start\":36374},{\"end\":36448,\"start\":36440},{\"end\":36511,\"start\":36503},{\"end\":36814,\"start\":36806},{\"end\":36896,\"start\":36880},{\"end\":37107,\"start\":37099},{\"end\":37191,\"start\":37173}]", "table": "[{\"end\":37380,\"start\":37232}]", "figure_caption": "[{\"end\":36438,\"start\":36384},{\"end\":36501,\"start\":36450},{\"end\":36573,\"start\":36513},{\"end\":36804,\"start\":36576},{\"end\":36878,\"start\":36816},{\"end\":37097,\"start\":36899},{\"end\":37171,\"start\":37109},{\"end\":37232,\"start\":37193}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10168,\"start\":10162},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13759,\"start\":13753},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15362,\"start\":15356},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16132,\"start\":16126},{\"end\":21519,\"start\":21513},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22396,\"start\":22384},{\"end\":23485,\"start\":23479},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":24128,\"start\":24115},{\"end\":24673,\"start\":24667},{\"end\":25753,\"start\":25744},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":26108,\"start\":26102},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26739,\"start\":26733},{\"end\":28053,\"start\":28047},{\"end\":29346,\"start\":29335},{\"end\":30210,\"start\":30204},{\"end\":30960,\"start\":30954},{\"end\":31122,\"start\":31116},{\"end\":31548,\"start\":31542},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":32661,\"start\":32646},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":33778,\"start\":33772},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34300,\"start\":34254},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":34538,\"start\":34531}]", "bib_author_first_name": "[{\"end\":39075,\"start\":39071},{\"end\":39082,\"start\":39081},{\"end\":39407,\"start\":39406},{\"end\":39417,\"start\":39416},{\"end\":39428,\"start\":39427},{\"end\":39430,\"start\":39429},{\"end\":39809,\"start\":39808},{\"end\":39820,\"start\":39819},{\"end\":39836,\"start\":39835},{\"end\":40238,\"start\":40237},{\"end\":40712,\"start\":40711},{\"end\":40979,\"start\":40978},{\"end\":41376,\"start\":41375},{\"end\":41738,\"start\":41737},{\"end\":41747,\"start\":41746},{\"end\":41758,\"start\":41757},{\"end\":42025,\"start\":42024},{\"end\":42027,\"start\":42026},{\"end\":42041,\"start\":42040},{\"end\":42051,\"start\":42050},{\"end\":42062,\"start\":42061},{\"end\":42064,\"start\":42063},{\"end\":42431,\"start\":42430},{\"end\":42442,\"start\":42441},{\"end\":42457,\"start\":42456},{\"end\":42470,\"start\":42469},{\"end\":42481,\"start\":42480},{\"end\":42491,\"start\":42490},{\"end\":42500,\"start\":42499},{\"end\":42510,\"start\":42509},{\"end\":42519,\"start\":42518},{\"end\":42873,\"start\":42872},{\"end\":42875,\"start\":42874},{\"end\":42888,\"start\":42887},{\"end\":43280,\"start\":43279},{\"end\":43288,\"start\":43287},{\"end\":43297,\"start\":43296},{\"end\":43306,\"start\":43305},{\"end\":43313,\"start\":43312},{\"end\":43634,\"start\":43633},{\"end\":43636,\"start\":43635},{\"end\":43650,\"start\":43649},{\"end\":43652,\"start\":43651},{\"end\":44044,\"start\":44043},{\"end\":44056,\"start\":44055},{\"end\":44069,\"start\":44068},{\"end\":44601,\"start\":44600},{\"end\":44610,\"start\":44609},{\"end\":44618,\"start\":44617},{\"end\":44625,\"start\":44624},{\"end\":44631,\"start\":44630},{\"end\":44640,\"start\":44639},{\"end\":45066,\"start\":45065},{\"end\":45068,\"start\":45067},{\"end\":45078,\"start\":45077},{\"end\":45088,\"start\":45087},{\"end\":45330,\"start\":45329},{\"end\":45339,\"start\":45338},{\"end\":45351,\"start\":45350},{\"end\":45719,\"start\":45715},{\"end\":45726,\"start\":45725},{\"end\":45733,\"start\":45732},{\"end\":45740,\"start\":45739},{\"end\":46058,\"start\":46057},{\"end\":46067,\"start\":46066},{\"end\":46078,\"start\":46077},{\"end\":46089,\"start\":46088},{\"end\":46476,\"start\":46475},{\"end\":46487,\"start\":46486},{\"end\":46498,\"start\":46497},{\"end\":46511,\"start\":46510},{\"end\":46916,\"start\":46915},{\"end\":46923,\"start\":46922},{\"end\":46925,\"start\":46924},{\"end\":46933,\"start\":46932},{\"end\":46935,\"start\":46934},{\"end\":47262,\"start\":47261},{\"end\":47273,\"start\":47272},{\"end\":47286,\"start\":47285},{\"end\":47301,\"start\":47300},{\"end\":47311,\"start\":47310},{\"end\":47322,\"start\":47321},{\"end\":47331,\"start\":47330},{\"end\":47340,\"start\":47339},{\"end\":47772,\"start\":47771},{\"end\":47774,\"start\":47773},{\"end\":48081,\"start\":48080},{\"end\":48089,\"start\":48088},{\"end\":48097,\"start\":48096},{\"end\":48103,\"start\":48102},{\"end\":48112,\"start\":48111},{\"end\":48472,\"start\":48471},{\"end\":48674,\"start\":48673},{\"end\":48676,\"start\":48675},{\"end\":48899,\"start\":48898},{\"end\":48910,\"start\":48909}]", "bib_author_last_name": "[{\"end\":39079,\"start\":39076},{\"end\":39089,\"start\":39083},{\"end\":39414,\"start\":39408},{\"end\":39425,\"start\":39418},{\"end\":39437,\"start\":39431},{\"end\":39817,\"start\":39810},{\"end\":39833,\"start\":39821},{\"end\":39842,\"start\":39837},{\"end\":40247,\"start\":40239},{\"end\":40720,\"start\":40713},{\"end\":40987,\"start\":40980},{\"end\":41384,\"start\":41377},{\"end\":41744,\"start\":41739},{\"end\":41755,\"start\":41748},{\"end\":41766,\"start\":41759},{\"end\":42038,\"start\":42028},{\"end\":42048,\"start\":42042},{\"end\":42059,\"start\":42052},{\"end\":42071,\"start\":42065},{\"end\":42439,\"start\":42432},{\"end\":42454,\"start\":42443},{\"end\":42467,\"start\":42458},{\"end\":42478,\"start\":42471},{\"end\":42488,\"start\":42482},{\"end\":42497,\"start\":42492},{\"end\":42507,\"start\":42501},{\"end\":42516,\"start\":42511},{\"end\":42526,\"start\":42520},{\"end\":42885,\"start\":42876},{\"end\":42896,\"start\":42889},{\"end\":43285,\"start\":43281},{\"end\":43294,\"start\":43289},{\"end\":43303,\"start\":43298},{\"end\":43310,\"start\":43307},{\"end\":43317,\"start\":43314},{\"end\":43647,\"start\":43637},{\"end\":43666,\"start\":43653},{\"end\":44053,\"start\":44045},{\"end\":44066,\"start\":44057},{\"end\":44077,\"start\":44070},{\"end\":44607,\"start\":44602},{\"end\":44615,\"start\":44611},{\"end\":44622,\"start\":44619},{\"end\":44628,\"start\":44626},{\"end\":44637,\"start\":44632},{\"end\":44643,\"start\":44641},{\"end\":45075,\"start\":45069},{\"end\":45085,\"start\":45079},{\"end\":45091,\"start\":45089},{\"end\":45336,\"start\":45331},{\"end\":45348,\"start\":45340},{\"end\":45359,\"start\":45352},{\"end\":45723,\"start\":45720},{\"end\":45730,\"start\":45727},{\"end\":45737,\"start\":45734},{\"end\":45746,\"start\":45741},{\"end\":46064,\"start\":46059},{\"end\":46075,\"start\":46068},{\"end\":46086,\"start\":46079},{\"end\":46096,\"start\":46090},{\"end\":46484,\"start\":46477},{\"end\":46495,\"start\":46488},{\"end\":46508,\"start\":46499},{\"end\":46518,\"start\":46512},{\"end\":46920,\"start\":46917},{\"end\":46930,\"start\":46926},{\"end\":46939,\"start\":46936},{\"end\":47270,\"start\":47263},{\"end\":47283,\"start\":47274},{\"end\":47298,\"start\":47287},{\"end\":47308,\"start\":47302},{\"end\":47319,\"start\":47312},{\"end\":47328,\"start\":47323},{\"end\":47337,\"start\":47332},{\"end\":47347,\"start\":47341},{\"end\":47782,\"start\":47775},{\"end\":48086,\"start\":48082},{\"end\":48094,\"start\":48090},{\"end\":48100,\"start\":48098},{\"end\":48109,\"start\":48104},{\"end\":48116,\"start\":48113},{\"end\":48480,\"start\":48473},{\"end\":48683,\"start\":48677},{\"end\":48907,\"start\":48900},{\"end\":48916,\"start\":48911}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":14731196},\"end\":39314,\"start\":38983},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":9812826},\"end\":39744,\"start\":39316},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":60571601},\"end\":40199,\"start\":39746},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":17228581},\"end\":40584,\"start\":40201},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":733980},\"end\":40944,\"start\":40586},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":13894815},\"end\":41275,\"start\":40946},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":7149851},\"end\":41691,\"start\":41277},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":17269653},\"end\":41970,\"start\":41693},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":201625025},\"end\":42353,\"start\":41972},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":9243959},\"end\":42855,\"start\":42355},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":219223081},\"end\":43098,\"start\":42857},{\"attributes\":{\"id\":\"b11\"},\"end\":43175,\"start\":43100},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":207174016},\"end\":43554,\"start\":43177},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":16074135},\"end\":43964,\"start\":43556},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":25293393},\"end\":44324,\"start\":43966},{\"attributes\":{\"id\":\"b15\"},\"end\":44522,\"start\":44326},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":3050701},\"end\":44965,\"start\":44524},{\"attributes\":{\"id\":\"b17\"},\"end\":45228,\"start\":44967},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":44974405},\"end\":45633,\"start\":45230},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1695607},\"end\":45967,\"start\":45635},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":25062632},\"end\":46394,\"start\":45969},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":15953456},\"end\":46824,\"start\":46396},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":911723},\"end\":47192,\"start\":46826},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":6339752},\"end\":47691,\"start\":47194},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":236314},\"end\":47962,\"start\":47693},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2754154},\"end\":48469,\"start\":47964},{\"attributes\":{\"id\":\"b26\"},\"end\":48611,\"start\":48471},{\"attributes\":{\"id\":\"b27\"},\"end\":48826,\"start\":48613},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":18702275},\"end\":49109,\"start\":48828}]", "bib_title": "[{\"end\":39069,\"start\":38983},{\"end\":39404,\"start\":39316},{\"end\":39806,\"start\":39746},{\"end\":40235,\"start\":40201},{\"end\":40709,\"start\":40586},{\"end\":40976,\"start\":40946},{\"end\":41373,\"start\":41277},{\"end\":41735,\"start\":41693},{\"end\":42022,\"start\":41972},{\"end\":42428,\"start\":42355},{\"end\":42870,\"start\":42857},{\"end\":43277,\"start\":43177},{\"end\":43631,\"start\":43556},{\"end\":44041,\"start\":43966},{\"end\":44361,\"start\":44326},{\"end\":44598,\"start\":44524},{\"end\":45327,\"start\":45230},{\"end\":45713,\"start\":45635},{\"end\":46055,\"start\":45969},{\"end\":46473,\"start\":46396},{\"end\":46913,\"start\":46826},{\"end\":47259,\"start\":47194},{\"end\":47769,\"start\":47693},{\"end\":48078,\"start\":47964},{\"end\":48896,\"start\":48828}]", "bib_author": "[{\"end\":39081,\"start\":39071},{\"end\":39091,\"start\":39081},{\"end\":39416,\"start\":39406},{\"end\":39427,\"start\":39416},{\"end\":39439,\"start\":39427},{\"end\":39819,\"start\":39808},{\"end\":39835,\"start\":39819},{\"end\":39844,\"start\":39835},{\"end\":40249,\"start\":40237},{\"end\":40722,\"start\":40711},{\"end\":40989,\"start\":40978},{\"end\":41386,\"start\":41375},{\"end\":41746,\"start\":41737},{\"end\":41757,\"start\":41746},{\"end\":41768,\"start\":41757},{\"end\":42040,\"start\":42024},{\"end\":42050,\"start\":42040},{\"end\":42061,\"start\":42050},{\"end\":42073,\"start\":42061},{\"end\":42441,\"start\":42430},{\"end\":42456,\"start\":42441},{\"end\":42469,\"start\":42456},{\"end\":42480,\"start\":42469},{\"end\":42490,\"start\":42480},{\"end\":42499,\"start\":42490},{\"end\":42509,\"start\":42499},{\"end\":42518,\"start\":42509},{\"end\":42528,\"start\":42518},{\"end\":42887,\"start\":42872},{\"end\":42898,\"start\":42887},{\"end\":43287,\"start\":43279},{\"end\":43296,\"start\":43287},{\"end\":43305,\"start\":43296},{\"end\":43312,\"start\":43305},{\"end\":43319,\"start\":43312},{\"end\":43649,\"start\":43633},{\"end\":43668,\"start\":43649},{\"end\":44055,\"start\":44043},{\"end\":44068,\"start\":44055},{\"end\":44079,\"start\":44068},{\"end\":44609,\"start\":44600},{\"end\":44617,\"start\":44609},{\"end\":44624,\"start\":44617},{\"end\":44630,\"start\":44624},{\"end\":44639,\"start\":44630},{\"end\":44645,\"start\":44639},{\"end\":45077,\"start\":45065},{\"end\":45087,\"start\":45077},{\"end\":45093,\"start\":45087},{\"end\":45338,\"start\":45329},{\"end\":45350,\"start\":45338},{\"end\":45361,\"start\":45350},{\"end\":45725,\"start\":45715},{\"end\":45732,\"start\":45725},{\"end\":45739,\"start\":45732},{\"end\":45748,\"start\":45739},{\"end\":46066,\"start\":46057},{\"end\":46077,\"start\":46066},{\"end\":46088,\"start\":46077},{\"end\":46098,\"start\":46088},{\"end\":46486,\"start\":46475},{\"end\":46497,\"start\":46486},{\"end\":46510,\"start\":46497},{\"end\":46520,\"start\":46510},{\"end\":46922,\"start\":46915},{\"end\":46932,\"start\":46922},{\"end\":46941,\"start\":46932},{\"end\":47272,\"start\":47261},{\"end\":47285,\"start\":47272},{\"end\":47300,\"start\":47285},{\"end\":47310,\"start\":47300},{\"end\":47321,\"start\":47310},{\"end\":47330,\"start\":47321},{\"end\":47339,\"start\":47330},{\"end\":47349,\"start\":47339},{\"end\":47784,\"start\":47771},{\"end\":48088,\"start\":48080},{\"end\":48096,\"start\":48088},{\"end\":48102,\"start\":48096},{\"end\":48111,\"start\":48102},{\"end\":48118,\"start\":48111},{\"end\":48482,\"start\":48471},{\"end\":48685,\"start\":48673},{\"end\":48909,\"start\":48898},{\"end\":48918,\"start\":48909}]", "bib_venue": "[{\"end\":39103,\"start\":39091},{\"end\":39474,\"start\":39439},{\"end\":39918,\"start\":39844},{\"end\":40380,\"start\":40249},{\"end\":40743,\"start\":40722},{\"end\":41067,\"start\":40989},{\"end\":41472,\"start\":41386},{\"end\":41815,\"start\":41768},{\"end\":42135,\"start\":42073},{\"end\":42580,\"start\":42528},{\"end\":42957,\"start\":42898},{\"end\":43122,\"start\":43100},{\"end\":43343,\"start\":43319},{\"end\":43740,\"start\":43668},{\"end\":44101,\"start\":44079},{\"end\":44403,\"start\":44363},{\"end\":44725,\"start\":44645},{\"end\":45063,\"start\":44967},{\"end\":45392,\"start\":45361},{\"end\":45777,\"start\":45748},{\"end\":46158,\"start\":46098},{\"end\":46590,\"start\":46520},{\"end\":46990,\"start\":46941},{\"end\":47422,\"start\":47349},{\"end\":47813,\"start\":47784},{\"end\":48154,\"start\":48118},{\"end\":48507,\"start\":48482},{\"end\":48671,\"start\":48613},{\"end\":48943,\"start\":48918},{\"end\":39986,\"start\":39920},{\"end\":41141,\"start\":41069},{\"end\":42153,\"start\":42137},{\"end\":48527,\"start\":48509}]"}}}, "year": 2023, "month": 12, "day": 17}