{"id": 222066712, "updated": "2023-10-06 10:51:24.859", "metadata": {"title": "INSPIRED: Toward Sociable Recommendation Dialog Systems", "authors": "[{\"first\":\"Shirley\",\"last\":\"Hayati\",\"middle\":[\"Anugrah\"]},{\"first\":\"Dongyeop\",\"last\":\"Kang\",\"middle\":[]},{\"first\":\"Qingxiaoyang\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Weiyan\",\"last\":\"Shi\",\"middle\":[]},{\"first\":\"Zhou\",\"last\":\"Yu\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "publication_date": {"year": 2020, "month": 9, "day": 29}, "abstract": "In recommendation dialogs, humans commonly disclose their preference and make recommendations in a friendly manner. However, this is a challenge when developing a sociable recommendation dialog system, due to the lack of dialog dataset annotated with such sociable strategies. Therefore, we present INSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation with measures for successful recommendations. To better understand how humans make recommendations in communication, we design an annotation scheme related to recommendation strategies based on social science theories and annotate these dialogs. Our analysis shows that sociable recommendation strategies, such as sharing personal opinions or communicating with encouragement, more frequently lead to successful recommendations. Based on our dataset, we train end-to-end recommendation dialog systems with and without our strategy labels. In both automatic and human evaluation, our model with strategy incorporation outperforms the baseline model. This work is a first step for building sociable recommendation dialog systems with a basis of social science theories.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2009.14306", "mag": "3106454043", "acl": "2020.emnlp-main.654", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/HayatiKZSY20", "doi": "10.18653/v1/2020.emnlp-main.654"}}, "content": {"source": {"pdf_hash": "943f1c9cae41d7635a40dc9d836edd94418e26c8", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2009.14306v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/2020.emnlp-main.654.pdf", "status": "HYBRID"}}, "grobid": {"id": "5f5001e787eb291ccb0d30ee23838013d92d1ab9", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/943f1c9cae41d7635a40dc9d836edd94418e26c8.txt", "contents": "\nINSPIRED: Toward Sociable Recommendation Dialog Systems\n\n\nShirley Anugrah Hayati sahayati@ucdavis.edu \nDepartment of Computer Science\nDavis \u2606\nUniversity of California\nUniversity of California\nBerkeley\n\nDongyeop Kang dongyeopk@berkeley.edu \nDepartment of Computer Science\nDavis \u2606\nUniversity of California\nUniversity of California\nBerkeley\n\n\u2606 Qingxiaoyang \nDepartment of Computer Science\nDavis \u2606\nUniversity of California\nUniversity of California\nBerkeley\n\nZhu \nDepartment of Computer Science\nDavis \u2606\nUniversity of California\nUniversity of California\nBerkeley\n\nWeiyan Shi wyshi@ucdavis.edu \nDepartment of Computer Science\nDavis \u2606\nUniversity of California\nUniversity of California\nBerkeley\n\n\u2661 Zhou \nDepartment of Computer Science\nDavis \u2606\nUniversity of California\nUniversity of California\nBerkeley\n\nYu \u2661 \nDepartment of Computer Science\nDavis \u2606\nUniversity of California\nUniversity of California\nBerkeley\n\nINSPIRED: Toward Sociable Recommendation Dialog Systems\n\nIn recommendation dialogs, humans commonly disclose their preference and make recommendations in a friendly manner. However, this is a challenge in developing a sociable recommendation dialog system, due to the lack of dialog dataset annotated with such sociable strategies. Therefore, we present INSPIRED, a new dataset of 1,001 human-human dialogs for movie recommendation with measures for successful recommendations. To better understand how humans make recommendations in communication, we design an annotation scheme related to recommendation strategies based on social science theories and annotate these dialogs. Our analysis shows that sociable recommendation strategies, such as sharing personal opinions or communicating with encouragement, more frequently lead to successful recommendations. Based on our dataset, we train end-to-end recommendation dialog systems with and without our strategy labels. In both automatic and human evaluation, our model with strategy incorporation outperforms the baseline model. This work is a first step for building sociable recommendation dialog systems with a basis of social science theories 1 .\n\nIntroduction\n\nSociable conversational agents build rapport with users, in order to gain trust and favor from them. Social science researchers believe that the rapport influence a more persuasive recommendation to successfully suggest an item that satisfies user needs (Yoo et al., 2012;Gkika and Lekakos;Pecune et al., 2019;Gretzel and Fesenmaier, 2006).\n\nHowever, existing works on recommendation dialog systems lack a study about communication strategies used by human speakers for making successful and persuasive recommendations. They col-Figure 1: An example snippet of human-human recommendation dialog in INSPIRED. REC refers a person who recommends a movie and SEEK refers a person who looks for a recommendation. Above each recommender's utterance is the recommendation strategy annotated by human workers. Best seen in colors. lect the dataset in scenario-based settings or convert product review datasets into question-answering conversations (Reschke et al., 2013;Yan et al., 2017;Sun and Zhang, 2018;Kang et al., 2019;Li et al., 2018). Common issues with these types of datasets are: (1) homologous utterances, (2) mostly question-answering pairs, and (3) lack of user engagement.\n\nIn this work, we aim to validate whether sociable recommendation strategies are effective for making a successful recommendation in a dialog. To do so,  Table 1: Comparison of related recommendation dialog datasets. \"QA\" refers to question-answer pairs. \"Mixed\" indicates that the conversations contain both statements and question-answer pairs. CONVREC collected 385 humancurated dialogs, but only released 875,721 simulated dialogs.\n\nwe propose INSPIRED, a recommendation dialog dataset of two-paired crowd-workers in a natural setting, with additional annotations for sociable recommendation strategies. The dataset consists of 1,001 dialogs, and each utterance is manually annotated with the sociable strategies based on social science theory. To encourage more natural dialog flow, we do not set any restrictions on the number of movies or the type of movies to recommend.  Table 11 and 12 in the Appendix. Our analyses show that sociable recommendation strategies are correlated with successful recommendation in dialogs. These insights motivate us to build a more sociable recommendation dialog system to achieve better persuasion outcomes.\n\nFor extrinsic evaluation, we build two end-to-end dialog systems trained on the INSPIRED dataset: one is encoded with recommendation strategies and the other is not. We find that the model encoded with our strategy annotations performs better in both automatic and human evaluation.\n\nWe believe that enriching the intersection between social science and computational linguistics in INSPIRED opens plenty of rooms for future studies on sociable recommendation dialog.\n\n\nRelated Work\n\nSocial science theories on recommendation. Psychological researchers believe that interactions with recommendation systems should not only be seen from a technical perspective but should also be examined from a social and emotional perspective (Zanker et al., 2006). Yoo et al. (2012) propose that credibility, likeability, friendliness, humor, and other language styles are significant factors for persuasive recommendations. Pecune et al. (2019) has studied modeling social explanation for movie rec-ommendation, such as personal opinion and personal experience. H\u00e4ubl and Murray (2003) find that more information on recommendation may help consumers make better purchase decisions, but leave them overwhelmed with the abundant information. Inspired by these theories, we borrow such principles in the design of our sociable recommendation strategies.\n\n\nConversational\n\nrecommendation systems. While studies on conversational recommendation systems have been done, none of them focus on the sociable recommendation strategies for persuasive outcome. This is is due to the lack of existing datasets for studying effective strategies in recommendation dialog. Table 1 compares  different factors across the recommendation dialog  datasets including INSPIRED. Prior works on recommendation dialogs collect data based on template-based question-answering pairs from user reviews (Thompson et al., 2004;Reschke et al., 2013;Sun and Zhang, 2018;Zhang et al., 2018b). These datasets contain structured utterances where the recommender continuously asks for the seeker's product preference. Kang et al. (2019) collected goal-driven recommendation dialogs (GORECDIAL) in a gamified setting where both speakers are given a small set of movies with descriptions to find the best recommendation. This role-play game setting may not effectively reflect the real-world situation since the seeker pretends that they like the given movies.\n\nThe most similar work to ours is Li et al. (2018)'s REDIAL dataset which consists of chit-chats for movie recommendation. However, the recommendations are conditioned on the movies mentioned in the dialog, and not directly on the language usage. Also, they tend to mention only movie names rather than an in-depth discussion on the movie preference.\n\nOur work is also closely related to Radlinski et al. (2019) on movie preference elicitation and Fabian Galetzka1 (2020) on movie discussion in the dialog setting. Preference elicitation is an important step for the human recommender to comprehend seeker's taste before recommendation, but these datasets are not recommendation conversations.\n\nMeanwhile, dialogs in INSPIRED have both stages: preference elicitation and recommendation. INSPIRED also captures sociable recommendation strategies in conversations and measures recommendation with ratings.\n\nSociability in dialog systems. In human-human conversations, people engage in a talk that does not only contain task-oriented topics (Bickmore and Cassell, 2005). Thus, sociability has raised more attention in dialog systems as they become more sociable, engaging, and user-adaptive (Zhang et al., 2018a;Shi and Yu, 2018;G\u00f6ker and Thompson, 2000). Zhang et al. (2018a) proposed a chit-chat dataset and presented the task of more personalized dialogs system conditioned on user profile information. Sociability leads to a more persuasive conversation (Yoo et al., 2012), so social skills are essential for dialog systems to make successful recommendations.\n\nCommunication strategies on specific tasks, such as donation and product price negotiation, have been found useful for task completion (Wang et al., 2019;Zhou et al., 2019). In this work, we connect different sociable strategies with recommendation in dialog settings and show that sociable strategies have a positive impact on recommendation success.\n\n\nRecommendation Dialog Collection\n\n\nMovie Database Creation\n\nTo ensure that the recommended movie has trailers and metadata information, we curate a database with all movie trailers from Movieclips Trailer 2 released between 2008 and 2020, and movies from MovieLens dataset (Harper and Konstan, 2015). In total, we have 17,869 movies with trailers and metadata information. We design a simple movie search interface (Figure 2) to assist recommenders in searching for a movie.\n\n\nRecommendation Task\n\nWe recruit crowd-workers from Amazon Mechanical Turk. In each conversation, two workers are randomly paired and assigned different roles: one as a recommender and another as a seeker. Our collection set-up is more realistic compared to prior works as (1) recommenders have no limitations of the number of movies to recommend, (2) seekers accept or reject a movie following their true preference, and (3) we record if seekers actually watch the video trailer or not.\n\n\nRecommender.\n\nRecommenders' task is to recommend a movie successfully to the seeker. Before chatting, we show them tips for sociable recommendation strategies with example utterances. Then they chat with the seekers in two phases: user information gathering and movie recommendation. In the user information gathering phase, recommenders are asked to understand the seekers' movie tastes. In the recommendation phase, the recommenders can still request seekers' preference while browsing movies to recommend. We encourage the recommenders to continue the conversation until seekers accept a movie.\n\nSeeker. Seekers are asked to talk about movie recommendations without any strategy support. After they complete the conversation, seekers can opt to accept or reject the provided movie recommendations. If the seekers accept the recommendation, they can watch the entire recommended movie trailer or part of it, or simply skip it after the conversation. We record how long seekers watched the recommended movie trailer and ask them to rate the trailer on 5-Likert scale in the post-task survey.  \n\n\nDialog Data Collection Details\n\nWe use ParlAI platform (Miller et al., 2017) and hire 1,594 US crowd-workers from Amazon Mechanical Turk with a minimum of 90% task acceptance rate. The dialog collection process lasted from November 2019 to March 2020. Workers first fill out questionnaires related to their personality traits and values before their conversations. The questionnaire consists of three personality trait models: the Big Five personality traits (15 questions) (Goldberg, 1993), the Schwartz Portrait Value (10 questions) (Schwartz, 2003), and the Decision Making Style (2 questions) (Hamilton et al., 2016) 3 . Then, recommenders start the conversation and both workers should chat for a minimum of 10 turns or until a recommendation is made. After the conversation ends, both workers will answer a post-task survey of demographic questions such as age, and gender. Seekers are asked to rate the trailer with a high score (4 or 5 stars) on a 5-Likert scale and provide the reason of why they reject or do not finish watching the video. Both workers receive a bonus up to $2 if they complete the entire process in addition to the base pay of $0.5. Table 2 presents statistics of the collected dataset 4 . Even though our dataset has relatively small number of samples compared to REDIAL or GORECDIAL, it has human annotations on each sociable strategy. Moreover, our dataset can be 3 We also release this personality information in our dataset for future work 4 Dialog collection interfaces are in appendix H in Appendix\n\n\nCases #Dialogs\n\nAccept (Rating 4-5) 532 (53.1%) Accept (Rating 3 or lower) 45 (4.5%) Accept (Other Reasons) 289 (28.9%) Accept Uninterested 123 (12.3%) Reject 12 (1.2%) Table 3: Statistics of dialogs when the seekers accept or reject the final recommended movie. \"Accept (Rating 4-5)\" means that the seekers accept the recommendation and give rating 4 or 5, and the same is for \"Accept (Rating 3 or lower)\". \"Accept (Other Reasons)\" suggests that the seeker gives other reasons for not finishing the video. \"Accept Uninterested\" indicates that the seekers accept the recommendation, do not finish watching the video, and explains in the post-task survey that they are not interested in the recommended video.\n\nused in combination with other datasets in a semisupervised setting, as shown in our implementation of recommendation dialog systems in \u00a76. The statistics of accept and reject cases are shown in Table 3. We have higher number of successful cases (79.7%) compared to failure cases. This shows that people tend to accept recommendations, and it is not surprising since watching a video trailer is an entertaining, low-risk activity. For training the dialog model, we use every dialog from all cases so that the dialog system will be able to respond to diverse responses.\n\n\nRecommendation Strategy Annotation\n\n\nStrategy Definition\n\nAfter conversations are collected, two experts, trained with linguistics background, develop an annotation scheme using content analysis method (Krippendorff, 2004) and from past study on human behavior in making recommendations. Similar approaches have been done in prior studies on work for persuasion task (Wang et al., 2019) or negotiation task (Zhou et al., 2019). We divide the recommendation strategies into two categories: sociable strategies and preference elicitation strategies. Sociable strategies are also derived from our literature study on the social science theories.\n\nSociable strategies contain eight strategies related to the recommendation task. These strategies relate to the recommenders trying to build rapport with the seekers.\n\n\u2022 Personal opinion refers to a condition when recommenders express their subjective opinion\n\n\nCategory Example\n\nPERSONAL OPINION \"I really like Disney's more recent princesses\" PERSONAL EXPERIENCE \"I have Disney+ and watched it everyday!\" SIMILARITY \"Oh, I love Disney as well.\" ENCOURAGEMENT \"You should definitely watch it!\" OFFERING HELP \"I'm here to help you find a trailer!\" PREFERENCE CONFIRMATION \"So do you like Disney movies in general?\"\n\nCREDIBILITY \"It's about a dog named Lady who runs away with a stray named Tramp\" SELF-MODELING \"We are planning to go see Maleficent, we heard it was a very good movie.\" EXPERIENCE INQUIRY \"Have you seen the new Lady and the Tramp?\"\n\nOPINION INQUIRY \"What do you like about the Avengers: End-game?\" RECOMMENDATION \"You should check out Shazam!\" about a movie, including its plot, actors, or other movie attributes.\n\n\u2022 Personal experience refers to the use of sharing personal experience related to a movie. For example, recommenders may say that they watch the movie several times to convince the seekers that the movie is good. Both personal opinion and personal experience are part of self-disclosure that leads to establishing rapport with the seekers (Altman, 1973).\n\n\u2022 Similarity refers to a condition when the recommenders are empathizing and being like-minded toward seekers about their movie preference to produce similarity among them. Similarity is believed to influence the seekers' liking for the source that leads to trust the recommenders' judgment more (O'Keefe, 2004), following Lazarsfeld and Merton (1964)'s homophily theory that states humans like other people who are similar to them.\n\n\u2022 Encouragement is the use of praise of the seekers' movie taste and encouragement to watch a recommended movie to build rapport and promote the recommended movie.\n\n\u2022 Offering help is a strategy when the recommenders disclose explicit intention to help the seeker or being transparent. It is a part of \"transparency\" strategy from Gretzel and Fesenmaier (2006).\n\n\u2022 Preference confirmation is a strategy when the recommenders ask or rephrase the seeker's prefer-ence. This strategy is also a part of \"transparency\" strategy which states that the recommenders disclose their thinking process of understanding the seekers' preference.\n\n\u2022 Self-modeling is a strategy when the recommender becomes a role model to do something first so that the Seeker would follow (Dowrick, 1999).\n\n\u2022 Credibility happens when the recommender shows expertise and trustworthiness in providing information to persuade the seeker (Fogg, 2002;O'Keefe, 2004;Rhoads and Cialdini, 2002). In our study, a recommender is doing credibility appeal when they provide factual information about movie attributes, such as the plot, actors, or awards that the movie has.\n\nPreference elicitation inquiries include the following inquiries that are asked by the recommenders to know the seekers' movie tastes.\n\n\u2022 Experience inquiry asks for seeker's experience on movie watching, such as whether a seeker has watched a certain movie or not.\n\n\u2022 Opinion inquiry asks for seeker's opinion on movie-related attributes. Example answers for this inquiry is the seeker's explanation on what they like about the plot or if they admire the actors' acting skill.\n\nOther kinds of utterances, such as greetings or thanks, fall into non-strategy category. We also label sentences which are recommendation. Recommendation is defined as when the recommender  suggests a new movie title for the first time for the seeker. 30% of the recommendation sentences are \"experience inquiries\", 27% are \"encouragement\", and 14% are \"personal opinion\". Example annotated utterances are displayed in Table 4. Meanwhile, Table 5 shows the number of annotated utterances in INSPIRED.\n\n\nAnnotation Quality\n\nTo ensure annotation quality, we separate our annotation study in two steps. First, we hire two experts with linguistics training to perform annotation, in order to test the validity of the scheme. The two experts annotated 30 randomly selected conversations and reached a Kappa agreement of 0.77, suggesting that our scheme is possible to replicate. Our dataset contains more than 18k utterances, so it's too costly to hire experts to annotate all of them. In the second step, We hire US-based crowdworkers (95% task acceptance) from Amazon Mechanical Turk for the annotation tasks. In each task, a worker was given a tutorial of the annotation and then they were given 10 dialogs to annotate. One of the dialogs was labeled by experts to calibrate the quality of the worker's annotation, called as evaluation dialog. Five workers work on the same task. We filter out workers whose score is below the threshold 0.60 on the evaluation dialog. To set this threshold in a reasonable value, we conducted the following study. This time we ran onetask in which all the dialogs are already labeled with the experts including the evaluation dialogs. We found that if the workers' score on the evaluation dialog is above 0.60, their agreement score with the expert's annotation on the rest of the dialogs in this task is 0.77.\n\nThese selected high quality crowd-workers annotate the rest of the dialogs. We still have five workers annotate the same dialog. If more than one worker disagrees on a utterance's annotation, the experts are then involved to annotate them as quality control. The inter-annotator majority agreement among all workers is 0.78 over all dialogs. The annotation scheme for the crowd-workers are provided in Figure 12 in the Appendix.\n\n\nStrategy Analyses\n\n\nDistribution of Strategies over Dialog\n\nAs shown in Figure 3, we observe that different sociable strategies are unequally distributed across conversation turns. Most notably, \"offering help\" and \"similarity\" often happen at the beginning, indicating that recommenders strategically attempt to build rapport with seekers at the early stages. Then, \"credibility\" and \"personal opinion\" frequently appear in the conversations, as recommenders seek to persuade. Moreover, \"encouragement\" mostly appears in the middle and at the end of conversations.\n\n\nWhat Strategies Contribute to Successful\n\nRecommendations?\n\nWe study the association of sociable strategies and successful recommendations. A recommendation is considered successful if seekers finish watching a substantial portion of the recommended movie trailer and rate the trailer with a high score (4 or 5 stars). We set a threshold that seekers need to watch at least more than 50% of the video duration since some videos have advertisements at the end, etc. On the other hand, a recommendation is considered unsuccessful if the seekers reject the recommendation (\"Reject\") or skip watching the trailer (\"Accept Uninterested\"). Thus, for our analysis, we use 532 successful dialogs and 135 unsuccessful dialogs for our analysis on association of strategies in successful recommendations.\n\nTo analyze the effect of our sociable recommendation strategies on success of recommendation, we run a logistic regression model to predict the success of recommendation (1 = successful, 0 = unsuccessful). We use frequency of the strategy in a dialog as the feature value. Table 6 shows the coefficients of each strategy with respect to the recommendation. We observe that \"personal opinion\", \"similarity\", \"encouragement\", and \"credibility\" strategies have a significant positive effect on successful recommendations. This confirms with the previous studies that more sociable recommenders are more likely to be successful in the recommendation.\n\n\"Similarity\" strategy has the highest coefficient value which suggests that if the recommender is conforming to the seeker's preference, the seeker is more likely to favor the recommendation. This also supports the theory in O'Keefe (2004) that likeability helps in recommendation. We also observe that all the preference elicitation inquiries are not significantly contributing to the successful recommendation. From this result, we are not saying that recommenders need not to query seekers' preferences since it is crucial to understand their tastes. However, a more sociable approach is necessary for a more successful recommendation.\n\n\nAre Sociable Strategies Still Significant with the Presence of Movie Attributes?\n\nIn a recommendation task, a natural question to ask is how big a role the recommended product plays in the acceptance of recommendation. If the quality of the product matters more than how you recom-  mend, it makes more sense to improve the products rather than the recommendation skills. Therefore, we also analyze if adding movie attributes, such as the genre, recent release date, and the number of likes of the movie trailer have an impact on successful recommendation along with the eight sociable strategies and two preference elicitation inquiries.\n\nFor the popularity, we categorize the top 10% movies in terms of the number of likes to be popular and the rest to be non-popular in our database. A movie is said to be recent if it is released in 2019 or 2020. For the genre, we select the top five most popular genres in the movie database. When we check with the recommended movies in INSPIRED, 96% of recommended movies are covered by the top five genres.\n\nResults of the analysis between the strategies and movie attributes are shown in Table 8 in the Appendix. Sociable strategies remain significantly correlated with successful recommendations. Recommenders who perform \"similarity\" strategy, express \"personal opinion\", and show \"encouragement\" are more likely to successfully recommend a movie (p < 0.05). Surprisingly, none of the movie attributes has significant effect on successful recommendations. A possible reason is that the seekers' movie tastes are so diverse that movie attributes such as genre do not have a significant impact on the recommendation success.  Figure 4: The Seeker's language model (Seeker LM) and the Recommender's language model (Recommender LM) are separate memory. The Seeker LM input at turn t is the seeker's utterance S utt t consisting of a sequence of tokens s t0 , s t1 , ...s tn . The Recommender LM input at turn t is the recommender's utterance R utt t consisting of a sequence of tokens r t0 , r t1 , ..., r tn . The <strategy t > prepended as a special token. For the baseline, the recommender's input does not contain the strategies.\n\n\nRecommendation Dialog Systems\n\nTo evaluate how the strategies in INSPIRED are useful in creating a more engaging and persuasive recommendation dialog, we develop a generative dialog model as our baseline to compare against our strategy-incorporated dialog system. We split the dialogs into 801/100/100 for train/validation/test split. We use external recommendation system from TMDB 5 with heuristics to select the movies.\n\nMore details for heuristics and training set-up are in the Appendix.\n\n\nBaseline Model\n\nThe baseline dialog model uses two separate Transformer-based pretrained language models (Vaswani et al., 2017;Radford et al., 2019;Wu et al., 2019) to learn the recommender's and seeker's language models separately in alternating order. Both language models are trained to maximize the likelihood of generating ground truth utterance on the alternating memory as shown in Figure 4. The model is pretrained on non-task related corpus, WebText, and task-related corpus: recommendation dataset from REDIAL (Li et al., 2018) and movie preference elicitation dataset (Radlinski et al., 2019). Then, we fine-tune the model with INSPIRED.\n\nWe replace movie attributes such as titles, actors, and genres with indexed placeholders. It is because in a single conversation, multiple attributes may be mentioned several times. The replacement with placeholders improves factual correctness as we replace them back with the original movie attributes later. At the end of the sentence, we append the attribute information as below:\n\nOriginal The model first generates five candidate sentences. Then, it randomly selects a generated candidate that either contains \"encouragement\" strategy or has the greatest sentence length. In our experiment, we have tried various combinations of the top three strategies (e.g., \"encouragement\" only, \"encouragement\" and \"similarity\"), and it turns out that \"encouragement\" only model gave the best result. Moreover, the sentence length selection is based on our intuition when chatting with the system. This aligns from our findings, \"encouragement\" is the second most frequently used strategy when humans make recommendations ( \u00a74.1), and \"recommendation\" is associated positively with successful recommendation (Table 8) 6 .\n\nTo decide if a sentence is a recommendation or not, we train a BERT-based recommendation classifier that receives an input of recommender's current utterance and seeker's utterances from previous turn with 95.4% accuracy and 91.2 % F1-score. While the index in the placeholder may become a Model PPL\u2193 BLEU-4\u2191 Baseline 9.28 5.11 Strategy 8.93 6.63 proxy to decide whether the system needs to recommend a movie or not, it is not strictly supervised. Thus, if a generated sentence is labeled as \"recommendation\", we enforce our dialog system to recommend a new movie.\n\n\nResults\n\nWe compare the baseline dialog model without strategy supervision against our dialog model with strategy supervision. We use both automatic metrics and human evaluation. For automatic metrics, we compute perplexity and BLEU scores (Papineni et al., 2002), suggesting that prepending strategies improves the model performance as shown in Table 7. For human evaluation, twenty-eight participants chat with both models for 2-3 times for a more reliable judgment. We randomize which model they will chat first, in order to avoid exposure bias. After chatting, they are asked to decide which model is better in these five aspects: fluency, consistency, naturalness, persuasiveness, and engagingness. If they are unable to distinguish the dialog systems, they are allowed to choose \"can't tell\" option.\n\nResults in Figure 5 suggest that human users prefer the model with strategy over the baseline in all aspects 7 . It is interesting to see that although the strategy model is preferred on all metrics, people find the two model differs the most in engagingness, followed by naturalness. This supports our hypothesis that human users will find the conversations more engaging and more natural with sociable strategies incorporated in recommendation dialog systems.\n\n\nConclusion and Future Work\n\nIn this work, we have introduced INSPIRED, a new recommendation dialog dataset collected in natural setting and annotated with sociable recommendation strategies. We analyze the connection between different strategies and the recommendation results. Our findings show that sociable strategies do have a positive impact on the acceptance of recommendation and dialog quality. This work opens up several 7 We also run additional user study with five-scale ratings on these five aspects with results in Table 10  directions for future studies in building sociable and personalized recommendation dialog systems as follows: First, we will explore more ways of utilizing the strategies, including dynamic strategy selection after decoding. Then, we plan to investigate the strategy patterns for people with different personalities and movie preferences to make dialog system more personalized. Finally, another interesting exploration is to extend the model with a jointly trainable movie recommendation and movie information modules. \n\n\nA Movie Trailer Database Creation\n\nFor each movie, we obtain metadata information from Youtube and add other movie attributes, such as plot, actors, and genre using OMBD API 8 .\n\nWe enrich the movies from MovieLens datasets (Harper and Konstan, 2015) with more movie trailers by searching the movie title and \"trailer\" on Youtube with a duration restriction of less than 5 minutes. We choose the trailers that are shorter than 5 minutes so that the crowd-workers do not have to spend a long time on watching them. We used the first retrieved link of the video under the duration constraint. We remove movies without a retrieved trailer from our database. Our motivation to use MovieLens and include more trailers is to link our movie database with MovieLens user review, so that it can be used for future work on building recommendation systems.  \n\n\nB Heuristics for Recommendation System\n\nOur heuristics for the recommendation system to handle cold-start is as follows. If the seeker never mentions a movie before and the generated text of the recommender dialog system is labeled as \"recommendation\", the most recent movie with the last mentioned genre will be recommended. If the seeker already mentioned a movie, we will query the last mentioned movie with positive or neutral sentiment to the recommendation system for recommendation. The first recommended movie from the recommendation system output will be chosen by our dialog system. If the movie has been recommended, we will choose the next recommended movie in the recommendation output list.\n\nTo detect which movies are favored by the seekers and movie titles in the sentence, we use the modules from Liang et al. (2020). The sentiment classifier is a BERT-based (Devlin et al., 2019) model trained on Stanford Sentiment dataset (Socher et al., 2013). For the movie title detection, the model is a bidirectional LSTM-CRF with character-augmented word embedding for the input combined with retrieving similar movie title in the movie database. The movie database is from TMDB. The model was trained on speech transcripts.\n\nTo detect movie genre in the sentence, we use regular expression matching for these genres following movie information from OMDB in our database: Action, Animation, Biography, Comedy, Crime, Drama, Documentary, Fantasy, History, Horror, Mystery, Musical, News, Romance, Sport, Thriller, War, and Western. To detect movie actors, actresses, and directors, we use pattern matching for capitalized first letter and find if the name exists in TMDB search for people.\n\n\nC Dialog Model\n\nThe dialog model p(d) of a dialog d with T turns is defined as follows:\np(d) = T t=1 p s (s t |s <t , r <t )p r (r t |s <t , r <t ) (1)\nwhere s is the seeker's utterance at turn t and r is the recommender's utterance at turn t, and p s (s t |s <t , r <t ) is the probability of generating the seeker's utterance given the history. The conversation history is represented by they query/key/value features using self-attention. Interested reader can refer to Wu et al. (2019) for more details.\n\n\nD Training Set-up\n\nWe adopt GPT-2 small, which is a 12-head, 12layer, and 768-hidden size Transformer, with 117M parameters. We use pre-trained GPT-2 Byte Pair Encoding (BPE) tokenizer with the extended vocabulary of 50,310 tokens to tokenize texts. The optimizer is AdamW (Loshchilov and Hutter, 2019), and the number of warm-up steps is 100. The learning rate is set to 3 \u00d7 10 \u22125 , and the dropout rate is set to 0.1. All experiments are run with an NVIDIA GeForce GTX 1080 Ti GPU. The movie information in the input data, such as actress/actor's name, movie genre and movie plot, is delexicalized as special tokens. The real information (genre, movie title, etc.) is appended to the utterance. In addition, the strategy label is also treated as special tokens.\n\nWe leverage the ReDial (Li et al., 2018) and movie preference elicitation datasets (Radlinski et al., 2019) to conduct task-related pretraining. It takes around 1.37 hour to finish one epoch in pretraining the model.\n\nAs for the training on INSPIRED dataset, it takes around 16 minutes to finish one epoch. We train the model until it converges. The baseline model usually converges after the second epoch while the strategy-incorporated model after the third epoch.\n\nDuring the inference stage, we combined top-k based sampling and top-p based sampling (Nucleus Sampling method (Holtzman et al., 2019)). We keep the highest probability tokens whose cumulative probability mass exceeds the threshold p. We manually tuned the threshold of temperature, p and k to make both model achieve their best performance.\n\nThe temperature is set as 0.82 for baseline and 0.8 for the strategy-incorporated model. For both model, the threshold of k is set as 400 and the upperbound of p is set as 0.9. We manually tune the hyperparameters.\n\nFor the strategy-incorporated model, the strategy is generated first and the utterance is then generated conditioned on the strategy. Although it is a loose constraint, the model learned categorical strategic patterns. For completeness, we also provide validation perplexity and BLEU-4 score in Table 9 Model Test Valid PPL BLEU-4 PPL BLEU-4 Baseline 9.28 5.11 9.21 5.09 Strategy 8.93\n\n6.63 8.90 7.55 Table 9: Results for automatic metrics in both validation and test data.\n\n\nE Additional User Study\n\nIn addition to the comparison study done by human users mentioned in \u00a76.3, we conduct another user study which asks each participant to rate from 1 (worst) to 5 (best) for the same five aspects: fluency, consistency, naturalness, persuasiveness, and engagingness. For each model, 25 participants chat interactively with it (in total: 50 users). Unlike the user study in \u00a76.3 where 1 user interacts with both models, this time a user interacts with one model since users do not need to compare. These participants are different from the ones reported in the comparison user study ( \u00a76.3). From Table 10, we can see that the strategy model has higher ratings than the baseline model in all aspects.\n\n\nF Example Human-Human Dialogs in INSPIRED\n\nWe include 2 annotated examples of human-human dialogs in Table 11 and 12.\n\n\nG Example Human-System Dialogs\n\nWe include example dialog of human seeker and the baseline model in Table 13 and an example strategyincorporated dialog model in Table 14 from user study. In the user study of evaluating the dialog system, we do not set a minimum turn for the human user. Figure 6, 7, 9, 11 show dialog collection interface. Figure 12 and 13 are dialog annotation interfaces for the crowd-workers.\n\n\nH Dialog Collection and Annotation Interfaces\n\n\nModel\n\nFluency Consistency Naturalness Persuasiveness Engagingness  Table 10: Average score for human ratings on a 5-point Likert scale. Note that the human-human dialogues were collected before the user study and we did not measure fluency and consistency for human recommender. Table 14: Example dialog of human-system. REC SYS refers strategy-incorporated recommendation dialog system and SEEK to human Seeker.   \n\n\nFigure 1 shows an example of annotated dialog. More examples are in\n\nFigure 2 :\n2Movie search interface for recommenders.\n\nFigure 3 :\n3Distribution of sociable strategies over the dialog turns. Best viewed in color.\n\nFigure 5 :\n5Human evaluation result. \"Flu.\" stands for fluency, \"cons.\": consistency, \"nat.\": naturalness, \"pers.\": persuasiveness, and \"eng.\": engagingness.\n\nFigure 6 :Figure 7 :Figure 8 :Figure 9 :\n6789Onboarding page of both seekers and recommenders Strategy tips for recommenders before they start chatting Recommender's chat interface during preference elicitation phase Recommender's chat interface during recommendation phase. On the left side is the search bar.\n\nFigure 10 :\n10Seeker's chat interface after they finish the chat, and the Recommender sends over the movie. Seeker can choose to accept or reject.\n\nFigure 11 :Figure 13 :\n1113A page for seeker to watch the recommended videoFigure 12: A screenshot of the website interface describing strategy definition for annotation task for the crowdworkers Interface for crowd-workers to annotate the dialogs\n\n\narXiv:2009.14306v2 [cs.CL] 8 Oct 2020Dataset \n\nINSPIRED \nCONVREC \nGORECDIAL \nREDIAL \n(Sun and Zhang, 2018) (Kang et al., 2019) (Li et al., 2018) \n\nNaturalness \n\n\n\n\nSociable Strategies \n\n\n\n\nMovie Information \n\n\n\n\nConversation Types \nMixed \nQA \nMixed \nMixed \n#Dialogs \n1,001 \n385 \n9,125 \n10,006 \n#Utterances \n35,811 \n-\n160,904 \n182,150 \n\n\n\nTable 2 :\n2INSPIRED's statistics. # denotes the number.\n\nTable 4 :\n4Example utterances for each strategy.\n\nTable 5 :\n5Statistics of the number of utterances annotated with strategies in INSPIRED.\n\nTable 6 :\n6Associations between different strategies and \nsuccessful recommendation. *p < 0.05, **p < 0.01 \n\n\n\n\nyou should also see[MOVIE TITLE 1]  with [MOVIE P ACTOR 0]; title: La La Land (2016), The Amazing Spider-Man (2012); people: Emma Stone\": \"If you like La La Land, you should \nalso see Amazing Spiderman with Emma Stone\" \nWith \nplaceholder: \n\"If \nyou \nlike \n\n[MOVIE TITLE 0], \n\nyou should also see \n\n[MOVIE TITLE 1] \n\nwith \n\n[MOVIE P ACTOR 0]; \n\nmovies: La La Land (2016), The Amazing \nSpider-Man (2012); people: Emma Stone\" \n\n6.2 Strategy-incorporated Model \n\nWe prepend the strategy as a special token to the \ninput utterance so that the model does not only gen-\nerate sentences but also strategies. Similar method \nwas used to control text generation style (Rashkin \net al., 2019) as a simple and effective way to incor-\nporate the strategies. The input to the encoder is as \nfollows: \nPrepend: \"encouragement If you like \n\n[MOVIE TITLE 0], \n\n\n\nTable 7 :\n7Results for automatic metrics.\n\nTable 8 :\n8The associations between different strategies, movie attributes, and successful recommendations. *p < 0.058 omdbapi.com \n\n\nyoutube.com/user/movieclipsTRAILERS\nhttps://www.themoviedb.org/\nWe tried multi-task learning for utterance generation and strategy prediction, and the automatic metric result is comparable with the prepend method.\nAcknowledgmentsWe would like to thank members of the NLP lab at UC Davis for discussion and participation in the pilot study. We are also grateful for human evaluation participants and Mechanical Turk workers on contributions of building this dataset.Conversation 1 LabelREC: Hi There! No Strategy What types of movies do you like to watch?Offering Help SEEK: Hello! I'm more of an action movie or a good romance and mystery movie. REC:I just saw the trailer for Knives Out when I went to see Joker and it looked like Self-Modeling a good mix of action and mystery! SEEK: I seen that one too as I seen Joker about a month ago.I thought about asking my fiance about going and seeing it. REC:It looks like a good movie for people who like many different movies. Personal Opinion It also has a great cast! Personal Opinion I was surprised to see Chris Evans in the trailer! Personal Opinion SEEK: Maybe with Chris Evans in it it'll be easier to convince my fiance to see it.Do you know who else is in the cast? REC:Daniel Craig and Jamie Lee Curtis are also in the cast. Credibility Daniel Craig does a lot of 007 so definitely a good hearthrob role Encouragement to convince the misses lol! SEEK: I am the misses lol. But he loves the bond movies so that should be a good incentive for him to go see it. Do you have any other recommendations? REC:The new Star Wars comes out in less than a month, if you are into the franchise. SEEK: He is, I think he told me we're getting it when it comes out to add to our movie collection.REC:Well that is another great action movie. Encouragement I also recommend the John Wick series Encouragement SEEK: I haven't seen any of that series. Could you tell me what the general plot is> REC:John Wick is a former member of a gang, he was basically an assassin. Credibility He falls in love and quits the game, but then his wife dies, and someone comes in Credibility and kills his dog. He then goes on a revenge rampage against the people who broke into his house.Credibility I have yet to watch the 3rd one but the action scenes were really cool! Personal Opinion SEEK: Oh I'd definitely would cry at the dogs death. REC:It is really sad! Similarity the dog was a last gift from his dying wife which makes it so much worse Personal Opinion SEEK: I couldn't even finish I am legend because of the dog dying.Anything with animal death makes me ball like a baby. REC:Marley & Me had me crying for a good half hour so I completely understand that! Similarity SEEK: I avoided that movie because someone told me he passed away.My fiance took me to see jurrasic world as our first date and I cried at the dinosuars dying. REC:I would definitely avoid that movie if animal deaths make you said. Similarity Oh that is so cute though! No Strategy SEEK: Yeah, he had to calm me down for about an hour and bought me ice cream to apologize for it. REC:Aww that is so sweet. No Strategy Given that you dont want to see animals die, and you are looking for an Pref. Confirmation Action/Mystery, I think Knives Out would be a good movie choice. Do you agree?Pref. Confirmation SEEK: I do agree with that. When it comes out i'll bring it up for date night. Thank you!! My 20 year old son liked that. Personal Experience I have only seen a couple parts.Personal Experience You've no doubt seen the MIB series, but those were kind of good as well.Personal Opinion SEEK: Can you tell me what you like about MIB? I like Will Smith, but I haven't see any of the movies. REC:Oh, yeah. Acknowledgment They're telling us to quit the hit, but real quick.No Strategy He's funny and creative in it and he's great when paired with Tommy Lee Jones. Personal Opinion It's just creative and makes you laugh unexpectedly.Personal Opinion Anyway, that's all I got.No Strategy It was nice talking to you.No Strategy SEEK: It was great talking to you. I'll be sure to check out your recommendations.  I've never watched that before REC SYS: Awesome! It is a comedy movie.Do you prefer movies that have a little bit of humor or are more of an action/adventure type of movie? SEEK:A bit of humor is goodd REC SYS: Onward is a good one for sure. It is a fun comedy. SEEK:What is that one about? REC SYS: \"In a suburban fantasy world, two teenage elf brothers embark on an extraordinary quest to discover if there is still a little magic left out there.\" SEEK:Oh that's cool. I might watch that one then REC SYS: Onward is a great movie to see if you are into comedy movies. You should definitely watch it.\nAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, arXiv:1904.09751The curious case of neural text degeneration. arXiv preprintAri Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751.\n\nRecommendation as a communication game: Self-supervised bot-play for goal-oriented dialogue. Dongyeop Kang, Anusha Balakrishnan, Pararth Shah, Paul Crook, Y-Lan Boureau, Jason Weston, 10.18653/v1/D19-1203Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsDongyeop Kang, Anusha Balakrishnan, Pararth Shah, Paul Crook, Y-Lan Boureau, and Jason Weston. 2019. Recommendation as a communication game: Self-supervised bot-play for goal-oriented dialogue. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan- guage Processing (EMNLP-IJCNLP), pages 1951- 1961, Hong Kong, China. Association for Computa- tional Linguistics.\n\nReliability in content analysis: Some common misconceptions and recommendations. Klaus Krippendorff, Human communication research. 303Klaus Krippendorff. 2004. Reliability in content analysis: Some common misconceptions and rec- ommendations. Human communication research, 30(3):411-433.\n\nFriendship as social process: a substantive and methodological analysis. F Paul, Robert Lazarsfeld, King Merton, Van NostrandNew YorkPaul F. Lazarsfeld and Robert King Merton. 1964. Friendship as social process: a substantive and methodological analysis. pages 18-66, New York. Van Nostrand.\n\nTowards deep conversational recommendations. Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, Chris Pal, Advances in Neural Information Processing Systems. Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, and Chris Pal. 2018. Towards deep conversational recommenda- tions. In Advances in Neural Information Process- ing Systems, pages 9725-9735.\n\nGunrock 2.0: A user adaptive social conversational system. Kaihui Liang, Austin Chau, Yu Li, Xueyuan Lu, Dian Yu, Mingyang Zhou Zhou, Ishan Jain, Sam Davidson, Josh Arnold, Minh Nguyen, Zhou Yu, 3rd Proceedings of Alexa Prize. Alexa Prize 2020Kaihui Liang, Austin Chau, Yu Li, Xueyuan Lu, Dian Yu, Mingyang Zhou Zhou, Ishan Jain, Sam David- son, Josh Arnold, Minh Nguyen, and Zhou Yu. 2020. Gunrock 2.0: A user adaptive social conversational system. In 3rd Proceedings of Alexa Prize (Alexa Prize 2020).\n\nDecoupled weight decay regularization. Ilya Loshchilov, Frank Hutter, International Conference on Learning Representations. Ilya Loshchilov and Frank Hutter. 2019. Decoupled weight decay regularization. In International Con- ference on Learning Representations.\n\nA H Miller, W Feng, A Fisch, J Lu, D Batra, A Bordes, D Parikh, J Weston, arXiv:1705.06476Parlai: A dialog research software platform. arXiv preprintA. H. Miller, W. Feng, A. Fisch, J. Lu, D. Batra, A. Bor- des, D. Parikh, and J. Weston. 2017. Parlai: A dialog research software platform. arXiv preprint arXiv:1705.06476.\n\nTrends and prospects in persuasion theory and research. Daniel James, O&apos; Keefe, Readings in persuasion, social influence, and compliance gaining. Pearson/Allyn and BaconDaniel James O'Keefe. 2004. Trends and prospects in persuasion theory and research. In Readings in per- suasion, social influence, and compliance gaining, pages 31-43. Pearson/Allyn and Bacon.\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting on association for computational linguistics. the 40th annual meeting on association for computational linguisticsAssociation for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic eval- uation of machine translation. In Proceedings of the 40th annual meeting on association for compu- tational linguistics, pages 311-318. Association for Computational Linguistics.\n\nA model of social explanations for a conversational movie recommendation system. Florian Pecune, Shruti Murali, Vivian Tsai, Yoichi Matsuyama, Justine Cassell, 10.1145/3349537.3351899Proceedings of the 7th International Conference on Human-Agent Interaction, HAI '19. the 7th International Conference on Human-Agent Interaction, HAI '19New York, NY, USAACMFlorian Pecune, Shruti Murali, Vivian Tsai, Yoichi Mat- suyama, and Justine Cassell. 2019. A model of social explanations for a conversational movie rec- ommendation system. In Proceedings of the 7th International Conference on Human-Agent Interac- tion, HAI '19, pages 135-143, New York, NY, USA. ACM.\n", "annotations": {"author": "[{\"end\":202,\"start\":59},{\"end\":339,\"start\":203},{\"end\":454,\"start\":340},{\"end\":558,\"start\":455},{\"end\":687,\"start\":559},{\"end\":794,\"start\":688},{\"end\":899,\"start\":795}]", "publisher": null, "author_last_name": "[{\"end\":81,\"start\":75},{\"end\":216,\"start\":212},{\"end\":354,\"start\":342},{\"end\":569,\"start\":566},{\"end\":694,\"start\":690}]", "author_first_name": "[{\"end\":66,\"start\":59},{\"end\":74,\"start\":67},{\"end\":211,\"start\":203},{\"end\":341,\"start\":340},{\"end\":458,\"start\":455},{\"end\":565,\"start\":559},{\"end\":689,\"start\":688},{\"end\":797,\"start\":795},{\"end\":799,\"start\":798}]", "author_affiliation": "[{\"end\":201,\"start\":104},{\"end\":338,\"start\":241},{\"end\":453,\"start\":356},{\"end\":557,\"start\":460},{\"end\":686,\"start\":589},{\"end\":793,\"start\":696},{\"end\":898,\"start\":801}]", "title": "[{\"end\":56,\"start\":1},{\"end\":955,\"start\":900}]", "venue": null, "abstract": "[{\"end\":2102,\"start\":957}]", "bib_ref": "[{\"end\":2390,\"start\":2372},{\"end\":2408,\"start\":2390},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2428,\"start\":2408},{\"end\":2457,\"start\":2428},{\"end\":3080,\"start\":3058},{\"end\":3097,\"start\":3080},{\"end\":3117,\"start\":3097},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3135,\"start\":3117},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3151,\"start\":3135},{\"end\":5197,\"start\":5176},{\"end\":5216,\"start\":5199},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5379,\"start\":5359},{\"end\":5520,\"start\":5497},{\"end\":6332,\"start\":6309},{\"end\":6353,\"start\":6332},{\"end\":6373,\"start\":6353},{\"end\":6393,\"start\":6373},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6535,\"start\":6517},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6908,\"start\":6892},{\"end\":7924,\"start\":7896},{\"end\":8067,\"start\":8046},{\"end\":8084,\"start\":8067},{\"end\":8109,\"start\":8084},{\"end\":8131,\"start\":8111},{\"end\":8331,\"start\":8313},{\"end\":8574,\"start\":8555},{\"end\":8592,\"start\":8574},{\"end\":9073,\"start\":9047},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10913,\"start\":10892},{\"end\":11327,\"start\":11311},{\"end\":11388,\"start\":11372},{\"end\":11457,\"start\":11434},{\"end\":12233,\"start\":12232},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13876,\"start\":13856},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":15997,\"start\":15982},{\"end\":16480,\"start\":16451},{\"end\":16894,\"start\":16879},{\"end\":17036,\"start\":17024},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17050,\"start\":17036},{\"end\":17076,\"start\":17050},{\"end\":25457,\"start\":25435},{\"end\":25478,\"start\":25457},{\"end\":25494,\"start\":25478},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25867,\"start\":25850},{\"end\":25933,\"start\":25909},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27927,\"start\":27904},{\"end\":29366,\"start\":29365},{\"end\":30246,\"start\":30220},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":31679,\"start\":31660},{\"end\":31809,\"start\":31788},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":33358,\"start\":33329},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":33861,\"start\":33844},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":34423,\"start\":34400}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37117,\"start\":37048},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37171,\"start\":37118},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37265,\"start\":37172},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37424,\"start\":37266},{\"attributes\":{\"id\":\"fig_4\"},\"end\":37736,\"start\":37425},{\"attributes\":{\"id\":\"fig_5\"},\"end\":37884,\"start\":37737},{\"attributes\":{\"id\":\"fig_6\"},\"end\":38133,\"start\":37885},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38472,\"start\":38134},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":38529,\"start\":38473},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38579,\"start\":38530},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":38669,\"start\":38580},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":38780,\"start\":38670},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":39627,\"start\":38781},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":39670,\"start\":39628},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":39805,\"start\":39671}]", "paragraph": "[{\"end\":2458,\"start\":2118},{\"end\":3297,\"start\":2460},{\"end\":3733,\"start\":3299},{\"end\":4446,\"start\":3735},{\"end\":4730,\"start\":4448},{\"end\":4915,\"start\":4732},{\"end\":5785,\"start\":4932},{\"end\":6857,\"start\":5804},{\"end\":7208,\"start\":6859},{\"end\":7551,\"start\":7210},{\"end\":7761,\"start\":7553},{\"end\":8418,\"start\":7763},{\"end\":8771,\"start\":8420},{\"end\":9248,\"start\":8834},{\"end\":9737,\"start\":9272},{\"end\":10337,\"start\":9754},{\"end\":10834,\"start\":10339},{\"end\":12370,\"start\":10869},{\"end\":13081,\"start\":12389},{\"end\":13651,\"start\":13083},{\"end\":14296,\"start\":13712},{\"end\":14464,\"start\":14298},{\"end\":14557,\"start\":14466},{\"end\":14912,\"start\":14578},{\"end\":15146,\"start\":14914},{\"end\":15328,\"start\":15148},{\"end\":15684,\"start\":15330},{\"end\":16118,\"start\":15686},{\"end\":16283,\"start\":16120},{\"end\":16481,\"start\":16285},{\"end\":16751,\"start\":16483},{\"end\":16895,\"start\":16753},{\"end\":17251,\"start\":16897},{\"end\":17387,\"start\":17253},{\"end\":17518,\"start\":17389},{\"end\":17730,\"start\":17520},{\"end\":18232,\"start\":17732},{\"end\":19573,\"start\":18255},{\"end\":20003,\"start\":19575},{\"end\":20571,\"start\":20066},{\"end\":20632,\"start\":20616},{\"end\":21367,\"start\":20634},{\"end\":22015,\"start\":21369},{\"end\":22655,\"start\":22017},{\"end\":23296,\"start\":22740},{\"end\":23706,\"start\":23298},{\"end\":24832,\"start\":23708},{\"end\":25257,\"start\":24866},{\"end\":25327,\"start\":25259},{\"end\":25978,\"start\":25346},{\"end\":26364,\"start\":25980},{\"end\":27095,\"start\":26366},{\"end\":27661,\"start\":27097},{\"end\":28469,\"start\":27673},{\"end\":28932,\"start\":28471},{\"end\":29993,\"start\":28963},{\"end\":30173,\"start\":30031},{\"end\":30843,\"start\":30175},{\"end\":31550,\"start\":30886},{\"end\":32079,\"start\":31552},{\"end\":32543,\"start\":32081},{\"end\":32633,\"start\":32562},{\"end\":33053,\"start\":32698},{\"end\":33819,\"start\":33075},{\"end\":34037,\"start\":33821},{\"end\":34287,\"start\":34039},{\"end\":34630,\"start\":34289},{\"end\":34846,\"start\":34632},{\"end\":35232,\"start\":34848},{\"end\":35321,\"start\":35234},{\"end\":36045,\"start\":35349},{\"end\":36165,\"start\":36091},{\"end\":36580,\"start\":36200},{\"end\":37047,\"start\":36638}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":32697,\"start\":32634}]", "table_ref": "[{\"end\":3459,\"start\":3452},{\"end\":4186,\"start\":4178},{\"end\":6190,\"start\":6092},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":12005,\"start\":11998},{\"end\":12549,\"start\":12542},{\"end\":13285,\"start\":13278},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":18158,\"start\":18151},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":18178,\"start\":18171},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":21649,\"start\":21642},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":23796,\"start\":23789},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":27091,\"start\":27082},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":28017,\"start\":28010},{\"end\":29471,\"start\":29463},{\"end\":35150,\"start\":35143},{\"end\":35256,\"start\":35249},{\"end\":35950,\"start\":35942},{\"end\":36157,\"start\":36149},{\"end\":36276,\"start\":36268},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":36337,\"start\":36329},{\"end\":36707,\"start\":36699},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":36919,\"start\":36911}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2116,\"start\":2104},{\"attributes\":{\"n\":\"2\"},\"end\":4930,\"start\":4918},{\"end\":5802,\"start\":5788},{\"attributes\":{\"n\":\"3\"},\"end\":8806,\"start\":8774},{\"attributes\":{\"n\":\"3.1\"},\"end\":8832,\"start\":8809},{\"attributes\":{\"n\":\"3.2\"},\"end\":9270,\"start\":9251},{\"end\":9752,\"start\":9740},{\"attributes\":{\"n\":\"3.3\"},\"end\":10867,\"start\":10837},{\"end\":12387,\"start\":12373},{\"attributes\":{\"n\":\"4\"},\"end\":13688,\"start\":13654},{\"attributes\":{\"n\":\"4.1\"},\"end\":13710,\"start\":13691},{\"end\":14576,\"start\":14560},{\"attributes\":{\"n\":\"4.2\"},\"end\":18253,\"start\":18235},{\"attributes\":{\"n\":\"5\"},\"end\":20023,\"start\":20006},{\"attributes\":{\"n\":\"5.1\"},\"end\":20064,\"start\":20026},{\"attributes\":{\"n\":\"5.2\"},\"end\":20614,\"start\":20574},{\"attributes\":{\"n\":\"5.3\"},\"end\":22738,\"start\":22658},{\"attributes\":{\"n\":\"6\"},\"end\":24864,\"start\":24835},{\"attributes\":{\"n\":\"6.1\"},\"end\":25344,\"start\":25330},{\"attributes\":{\"n\":\"6.3\"},\"end\":27671,\"start\":27664},{\"attributes\":{\"n\":\"7\"},\"end\":28961,\"start\":28935},{\"end\":30029,\"start\":29996},{\"end\":30884,\"start\":30846},{\"end\":32560,\"start\":32546},{\"end\":33073,\"start\":33056},{\"end\":35347,\"start\":35324},{\"end\":36089,\"start\":36048},{\"end\":36198,\"start\":36168},{\"end\":36628,\"start\":36583},{\"end\":36636,\"start\":36631},{\"end\":37129,\"start\":37119},{\"end\":37183,\"start\":37173},{\"end\":37277,\"start\":37267},{\"end\":37466,\"start\":37426},{\"end\":37749,\"start\":37738},{\"end\":37908,\"start\":37886},{\"end\":38483,\"start\":38474},{\"end\":38540,\"start\":38531},{\"end\":38590,\"start\":38581},{\"end\":38680,\"start\":38671},{\"end\":39638,\"start\":39629},{\"end\":39681,\"start\":39672}]", "table": "[{\"end\":38472,\"start\":38173},{\"end\":38780,\"start\":38682},{\"end\":39627,\"start\":38919},{\"end\":39805,\"start\":39789}]", "figure_caption": "[{\"end\":37117,\"start\":37050},{\"end\":37171,\"start\":37131},{\"end\":37265,\"start\":37185},{\"end\":37424,\"start\":37279},{\"end\":37736,\"start\":37471},{\"end\":37884,\"start\":37752},{\"end\":38133,\"start\":37913},{\"end\":38173,\"start\":38136},{\"end\":38529,\"start\":38485},{\"end\":38579,\"start\":38542},{\"end\":38669,\"start\":38592},{\"end\":38919,\"start\":38783},{\"end\":39670,\"start\":39640},{\"end\":39789,\"start\":39683}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9198,\"start\":9189},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19986,\"start\":19977},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20086,\"start\":20078},{\"end\":24335,\"start\":24327},{\"end\":25727,\"start\":25719},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":28490,\"start\":28482},{\"end\":36463,\"start\":36455},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":36517,\"start\":36508}]", "bib_author_first_name": "[{\"end\":44524,\"start\":44521},{\"end\":44538,\"start\":44535},{\"end\":44547,\"start\":44545},{\"end\":44559,\"start\":44552},{\"end\":44573,\"start\":44568},{\"end\":44906,\"start\":44898},{\"end\":44919,\"start\":44913},{\"end\":44941,\"start\":44934},{\"end\":44952,\"start\":44948},{\"end\":44965,\"start\":44960},{\"end\":44980,\"start\":44975},{\"end\":45947,\"start\":45942},{\"end\":46224,\"start\":46223},{\"end\":46237,\"start\":46231},{\"end\":46495,\"start\":46488},{\"end\":46506,\"start\":46500},{\"end\":46515,\"start\":46507},{\"end\":46529,\"start\":46523},{\"end\":46545,\"start\":46538},{\"end\":46564,\"start\":46557},{\"end\":46579,\"start\":46574},{\"end\":46929,\"start\":46923},{\"end\":46943,\"start\":46937},{\"end\":46952,\"start\":46950},{\"end\":46964,\"start\":46957},{\"end\":46973,\"start\":46969},{\"end\":46986,\"start\":46978},{\"end\":47003,\"start\":46998},{\"end\":47013,\"start\":47010},{\"end\":47028,\"start\":47024},{\"end\":47041,\"start\":47037},{\"end\":47054,\"start\":47050},{\"end\":47412,\"start\":47408},{\"end\":47430,\"start\":47425},{\"end\":47633,\"start\":47632},{\"end\":47635,\"start\":47634},{\"end\":47645,\"start\":47644},{\"end\":47653,\"start\":47652},{\"end\":47662,\"start\":47661},{\"end\":47668,\"start\":47667},{\"end\":47677,\"start\":47676},{\"end\":47687,\"start\":47686},{\"end\":47697,\"start\":47696},{\"end\":48017,\"start\":48011},{\"end\":48032,\"start\":48025},{\"end\":48394,\"start\":48387},{\"end\":48410,\"start\":48405},{\"end\":48423,\"start\":48419},{\"end\":48438,\"start\":48430},{\"end\":49009,\"start\":49002},{\"end\":49024,\"start\":49018},{\"end\":49039,\"start\":49033},{\"end\":49052,\"start\":49046},{\"end\":49071,\"start\":49064}]", "bib_author_last_name": "[{\"end\":44533,\"start\":44525},{\"end\":44543,\"start\":44539},{\"end\":44550,\"start\":44548},{\"end\":44566,\"start\":44560},{\"end\":44578,\"start\":44574},{\"end\":44911,\"start\":44907},{\"end\":44932,\"start\":44920},{\"end\":44946,\"start\":44942},{\"end\":44958,\"start\":44953},{\"end\":44973,\"start\":44966},{\"end\":44987,\"start\":44981},{\"end\":45960,\"start\":45948},{\"end\":46229,\"start\":46225},{\"end\":46248,\"start\":46238},{\"end\":46261,\"start\":46250},{\"end\":46498,\"start\":46496},{\"end\":46521,\"start\":46516},{\"end\":46536,\"start\":46530},{\"end\":46555,\"start\":46546},{\"end\":46572,\"start\":46565},{\"end\":46583,\"start\":46580},{\"end\":46935,\"start\":46930},{\"end\":46948,\"start\":46944},{\"end\":46955,\"start\":46953},{\"end\":46967,\"start\":46965},{\"end\":46976,\"start\":46974},{\"end\":46996,\"start\":46987},{\"end\":47008,\"start\":47004},{\"end\":47022,\"start\":47014},{\"end\":47035,\"start\":47029},{\"end\":47048,\"start\":47042},{\"end\":47057,\"start\":47055},{\"end\":47423,\"start\":47413},{\"end\":47437,\"start\":47431},{\"end\":47642,\"start\":47636},{\"end\":47650,\"start\":47646},{\"end\":47659,\"start\":47654},{\"end\":47665,\"start\":47663},{\"end\":47674,\"start\":47669},{\"end\":47684,\"start\":47678},{\"end\":47694,\"start\":47688},{\"end\":47704,\"start\":47698},{\"end\":48023,\"start\":48018},{\"end\":48038,\"start\":48033},{\"end\":48403,\"start\":48395},{\"end\":48417,\"start\":48411},{\"end\":48428,\"start\":48424},{\"end\":48442,\"start\":48439},{\"end\":49016,\"start\":49010},{\"end\":49031,\"start\":49025},{\"end\":49044,\"start\":49040},{\"end\":49062,\"start\":49053},{\"end\":49079,\"start\":49072}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1904.09751\",\"id\":\"b0\"},\"end\":44803,\"start\":44521},{\"attributes\":{\"doi\":\"10.18653/v1/D19-1203\",\"id\":\"b1\",\"matched_paper_id\":202538681},\"end\":45859,\"start\":44805},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":15407535},\"end\":46148,\"start\":45861},{\"attributes\":{\"id\":\"b3\"},\"end\":46441,\"start\":46150},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":53513571},\"end\":46862,\"start\":46443},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":227012631},\"end\":47367,\"start\":46864},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":53592270},\"end\":47630,\"start\":47369},{\"attributes\":{\"doi\":\"arXiv:1705.06476\",\"id\":\"b7\"},\"end\":47953,\"start\":47632},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":151496197},\"end\":48321,\"start\":47955},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":11080756},\"end\":48919,\"start\":48323},{\"attributes\":{\"doi\":\"10.1145/3349537.3351899\",\"id\":\"b10\",\"matched_paper_id\":203621193},\"end\":49579,\"start\":48921}]", "bib_title": "[{\"end\":44896,\"start\":44805},{\"end\":45940,\"start\":45861},{\"end\":46486,\"start\":46443},{\"end\":46921,\"start\":46864},{\"end\":47406,\"start\":47369},{\"end\":48009,\"start\":47955},{\"end\":48385,\"start\":48323},{\"end\":49000,\"start\":48921}]", "bib_author": "[{\"end\":44535,\"start\":44521},{\"end\":44545,\"start\":44535},{\"end\":44552,\"start\":44545},{\"end\":44568,\"start\":44552},{\"end\":44580,\"start\":44568},{\"end\":44913,\"start\":44898},{\"end\":44934,\"start\":44913},{\"end\":44948,\"start\":44934},{\"end\":44960,\"start\":44948},{\"end\":44975,\"start\":44960},{\"end\":44989,\"start\":44975},{\"end\":45962,\"start\":45942},{\"end\":46231,\"start\":46223},{\"end\":46250,\"start\":46231},{\"end\":46263,\"start\":46250},{\"end\":46500,\"start\":46488},{\"end\":46523,\"start\":46500},{\"end\":46538,\"start\":46523},{\"end\":46557,\"start\":46538},{\"end\":46574,\"start\":46557},{\"end\":46585,\"start\":46574},{\"end\":46937,\"start\":46923},{\"end\":46950,\"start\":46937},{\"end\":46957,\"start\":46950},{\"end\":46969,\"start\":46957},{\"end\":46978,\"start\":46969},{\"end\":46998,\"start\":46978},{\"end\":47010,\"start\":46998},{\"end\":47024,\"start\":47010},{\"end\":47037,\"start\":47024},{\"end\":47050,\"start\":47037},{\"end\":47059,\"start\":47050},{\"end\":47425,\"start\":47408},{\"end\":47439,\"start\":47425},{\"end\":47644,\"start\":47632},{\"end\":47652,\"start\":47644},{\"end\":47661,\"start\":47652},{\"end\":47667,\"start\":47661},{\"end\":47676,\"start\":47667},{\"end\":47686,\"start\":47676},{\"end\":47696,\"start\":47686},{\"end\":47706,\"start\":47696},{\"end\":48025,\"start\":48011},{\"end\":48040,\"start\":48025},{\"end\":48405,\"start\":48387},{\"end\":48419,\"start\":48405},{\"end\":48430,\"start\":48419},{\"end\":48444,\"start\":48430},{\"end\":49018,\"start\":49002},{\"end\":49033,\"start\":49018},{\"end\":49046,\"start\":49033},{\"end\":49064,\"start\":49046},{\"end\":49081,\"start\":49064}]", "bib_venue": "[{\"end\":45362,\"start\":45186},{\"end\":48597,\"start\":48529},{\"end\":49274,\"start\":49189},{\"end\":44640,\"start\":44596},{\"end\":45184,\"start\":45009},{\"end\":45990,\"start\":45962},{\"end\":46221,\"start\":46150},{\"end\":46634,\"start\":46585},{\"end\":47089,\"start\":47059},{\"end\":47491,\"start\":47439},{\"end\":47765,\"start\":47722},{\"end\":48104,\"start\":48040},{\"end\":48527,\"start\":48444},{\"end\":49187,\"start\":49104}]"}}}, "year": 2023, "month": 12, "day": 17}