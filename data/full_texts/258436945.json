{"id": 258436945, "updated": "2023-10-25 11:56:41.544", "metadata": {"title": "VPGTrans: Transfer Visual Prompt Generator across LLMs", "authors": "[{\"first\":\"Ao\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Hao\",\"last\":\"Fei\",\"middle\":[]},{\"first\":\"Yuan\",\"last\":\"Yao\",\"middle\":[]},{\"first\":\"Wei\",\"last\":\"Ji\",\"middle\":[]},{\"first\":\"Li\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Zhiyuan\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Tat-Seng\",\"last\":\"Chua\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "While developing a new multimodal LLM (MLLM) by pre-training on tremendous image-text pairs from scratch can be exceedingly resource-consuming, connecting an existing LLM with a comparatively lightweight visual prompt generator (VPG) becomes a feasible paradigm. However, further tuning the VPG part of the MLLM still suffers from indispensable computational costs, i.e., requiring thousands of GPU hours and millions of training data. One alternative solution is to transfer an existing VPG from any existing MLLMs for the target MLLM. In this work, we for the first time investigate the VPG transferability across LLMs, and explore a solution to reduce the cost of VPG transfer. We first study the VPG transfer across different LLM sizes (e.g., small-to-large), and across different LLM types, through which we diagnose the key factors to maximize the transfer efficiency. Based on our observation, we design a two-stage transfer framework named VPGTrans, which is simple yet highly effective. Through extensive experiments, we demonstrate that VPGTrans helps significantly speed up the transfer learning process without compromising performance. Remarkably, it helps achieve the VPG transfer from BLIP-2 OPT$_\\text{2.7B}$ to BLIP-2 OPT$_\\text{6.7B}$ with over 10 times speed-up and 10.7% training data compared with connecting a VPG to OPT$_\\text{6.7B}$ from scratch. Further, a series of intriguing findings and potential rationales behind them are provided and discussed. Finally, we showcase the practical value of our VPGTrans approach, by customizing two novel MLLMs, including VL-LLaMA and VL-Vicuna, with recently released LLaMA and Vicuna LLMs.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2305.01278", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2305-01278", "doi": "10.48550/arxiv.2305.01278"}}, "content": {"source": {"pdf_hash": "0046306876ff2d5600699327e52bc29fa5e9ec91", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2305.01278v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "1073cc599809233fb1b652cc0f5f8ba2c533e598", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/0046306876ff2d5600699327e52bc29fa5e9ec91.txt", "contents": "\nVPGTrans: Transfer Visual Prompt Generator across LLMs\n24 Oct 2023\n\nAo Zhang zhanga6@outlook.com \nSchool of Computing\nNExT++ Lab\nNational University of Singapore\n\n\nHao Fei haofei37@nus.edu.sg \nSchool of Computing\nNExT++ Lab\nNational University of Singapore\n\n\nYuan Yao yaoyuanthu@163.com \nDepartment of Computer Science and Technology\nTsinghua University\n\n\nWei Ji \nSchool of Computing\nNExT++ Lab\nNational University of Singapore\n\n\nLi Li \nSchool of Computing\nNExT++ Lab\nNational University of Singapore\n\n\nZhiyuan Liu \nDepartment of Computer Science and Technology\nTsinghua University\n\n\nTat-Seng Chua \nSchool of Computing\nNExT++ Lab\nNational University of Singapore\n\n\n\n37th Conference on Neural Information Processing Systems\n2023NeurIPS\n\nVPGTrans: Transfer Visual Prompt Generator across LLMs\n24 Oct 202341912320547E33CE00C42F4429964C42arXiv:2305.01278v2[cs.CV]\nSince developing a new multimodal LLM (MLLM) by pre-training on a tremendous amount of image-text pairs from scratch is exceedingly resource-consuming, connecting an existing LLM with a comparatively lightweight visual prompt generator (VPG) becomes a feasible paradigm.However, further tuning the VPG component of the MLLM still incurs significant computational costs, such as thousands of GPU hours and millions of training data points.An alternative solution is to transfer an existing VPG from one MLLM to the target MLLM.In this work, we investigate VPG transferability across LLMs for the first time, aiming to reduce the cost of VPG transfer.Specifically, we explore VPG transfer across different LLM sizes (e.g., small-to-large) and types.We identify key factors to maximize the transfer efficiency, based on which we develop a simple yet highly effective two-stage transfer framework, called VPGTrans.Notably, it enables VPG transfer from BLIP-2 OPT 2.7B to BLIP-2 OPT 6.7B with less than 10% of GPU hours using only 10.7% of the training data compared to training a VPG for OPT 6.7B from scratch.Furthermore, we provide a series of intriguing findings and discuss potential explanations behind them.Finally, we showcase the practical value of our VPGTrans approach, by customizing two novel MLLMs, including VL-LLaMA and VL-Vicuna, with the recently released LLaMA and Vicuna LLMs.\n\nIntroduction\n\nBackground.Recent years have witnessed a great rise in large-scale language models (LLMs) in ushering the human-like artificial intelligence.Text-based LLMs [42,7,44] are further enhanced by associating with other modalities such as vision, leading to the multimodal LLMs (MLLMs), such as BLIP-2 [30], Flamingo [2], GPT-4 [8] for multimodal dialog system, and PaLM-E [16] for embodied AI system.To construct a MLLM, a visual prompt generator (VPG) module (cf.Fig. 1(a)) that produces soft prompts for the input images/videos is added 2 for bridging the gap between vision and language modalities.Currently, such architecture has been frequently adopted by many popular MLLMs [30,27].For example, BLIP-2 pre-trains a CLIP-ViT [43] combined with a Q-Former as VPG.To obtain the final MLLM, the VPG needs to be tuned.Ideally, the vast LLM backbone can remain untouched, leaving only the relatively lightweight VPG module to be fully or partially updated. 3otivation.However, building a MLLM is inevitably computation-expensive, due to the huge overhead brought by the LLM.For example, training a BLIP-2 FlanT5 XXL needs over 600 A100-GPU hours on over 100 million image-text pairs.Hopefully, transferring a pre-trained VPG (which is the main body of trainable parts) from an existing MLLM to a novel LLM instead of training from scratch, 4 offers a promising solution.Intuitively, all the MLLMs literally can share the same VPG infrastructure and utility, 5 which makes the VPG transfer theoretically feasible.In this work, we thus investigate the potential of transferring VPG across LLMs.\n\nProposal.Specifically, this paper examines the transferability of VPG across LLMs: 1) with different sizes (the same type), i.e. , transfer across LLM sizes, and 2) across different LLM types, i.e. , transfer across LLM type, as illustrated in Fig. 1(b).\n\n\u2022 [Transfer across LLM Sizes (TaS)].It has been a typical practice for LLM-related research [8] to validate the training strategy and the hyperparameter on smaller models (e.g., OPT 2.7B ) and then scale up to larger ones (e.g., OPT 6.7B ).It is thus worth exploring whether a VPG trained on a smaller LLM can be transferred to a larger LLM, resulting in reduced computational costs & data, and maintaining comparable performance.\u2022 [Transfer across LLM Types (TaT)].With a well-tuned VPG for a type of LLM, it is interesting to see if VPG can be transferred to other types of LLMs even with different architectures (e.g., decoder v.s.encoder-decoder).If the transfer can be achieved, how to make it more efficient?\n\nWe conduct a series of exploratory analyses (cf.\u00a73.1) to identify the key factors for transfer efficiency.\n\nBased on our empirical study, we design a two-stage transfer learning framework (cf.\u00a73.2), namely VPGTrans, that includes a projector warm-up (stage-1) and vanilla fine-tuning (stage-2).For stage-1, we find that warming up the projector before VPG tuning can effectively reduce the training step for adapting a pre-trained VPG to a new LLM, and avoid the potential performance drop in the adaptation.To achieve an efficient warm-up, the projector will be well-initialized and then trained with an extremely large learning rate (5 \u00d7 lr).For stage-2, there is a vanilla fine-tuning of both the VPG and projector.Despite its simplicity, VPGTrans is able to significantly speed up the VPG-transfer process without harming the performance.\n\n\nResults and Findings.\n\nVia extensive experiments on the transfer across LLM sizes and types (cf.\n\n\u00a74 & \u00a75), we gain the following key observations:\n\n\u2022 VPGTrans helps to avoid the performance drop caused by directly inheriting the VPG and achieves at most 10 times acceleration for the small-to-large transfer across LLMs in the same type.\u2022 VPGTrans can also achieve comparable or better performance than training from scratch and achieve at most 5 times acceleration for the transfers between different model types.\u2022 Notably, our VPGTrans helps to achieve a BLIP-2 ViT-G OPT 2.7B\u21926.7Btransfer with less than 10% of GPU hours and 10.7% of training data required for the original model training.\u2022 Furthermore, our framework can even outperform the original BLIP-2 OPT 6.7B on most of the evaluated datasets, with a +2.9 improvement on VQAv2 and a +3.4 improvement on OKVQA.\n\nOur investigation further reveals some intriguing findings, for which we provide possible explanations:\n\n2 Also including a linear projector for dimension matching.\u2022 When conducting TaS from LLM src to LLM tgt , the size of LLM src is not the larger the better.The transfer sometimes even follows a counterintuitive principle of \"the smaller the LLM src size, the more speed-up and better performance\" (cf.\u00a74.2). \u2022 When conducting TaT, efficient VPG transfer can not be achieved between two small LLMs with our VPGTrans, due to the large gap between small LLMs' embedding space (cf.\u00a75.2).\n\nContributions.In this study, we show for the first time that effective VPG transfer across LLMs can be achieved under most conditions, suggesting that it is possible to build a new MLLM with considerably lower computational cost, as seen in Fig. 2. To summarize, we make the following key contributions:\n\n\u2022 Effective approach.We investigate the key factors for VPG-transfer efficiency and propose a two-stage transfer framework VPGTrans.The approach helps to achieve a highly-efficient VPG transfer across LLMs with less training data and even task improvements.\u2022 Intriguing findings.By exploring the VPG transfer across LLMs, we reveal several intriguing findings and provide potential explanations that will shed light on further research.\u2022 Open source.We showcase how to customize a novel GPT-4-like MLLM with our VPGTrans (cf.\u00a76), and release two multimodal-version MLLMs: VL-LLaMA and VL-Vicuna.All codes and models is released at https://github.com/VPGTrans/VPGTrans.\n\n\nPreliminary\n\nThis section will outlines the existing prevailing MLLMs, and elaborates on the settings of the exploratory analyses of these MLLMs.\n\n\nMLLM\n\nArchitecture.As illustrated in Fig. 1(a), current MLLMs mostly adopt a common architecture, including a visual prompt generator (VPG), a projector, and a backbone LLM.Typically, VPG takes images/videos as inputs, and encodes the visual input into a fixed length of soft prompts.Then, a linear projector is employed to align the soft prompt's dimension to LLM's word embedding dimension.Finally, the LLM will generate sentences based on the information from the soft prompt.\n\nWe list some of the recent representative MLLMs in Table 1.[54] NF-ResNet-50 [6] NF-ResNet-50 GPT-2-like \u2020 [42] No Flamingo [2] NFNet-F6 [6]+Resampler [21] Resampler Chinchilla [18] Xattn-Dense PaLM-E [16] ViT [15] / OSRT [49] All PaLM [11] No BLIP-2 [30] EVA-CLIP [52] + Q-Former [30] Q-Former OPT [60] / Flan-T5 [12] No\n\nTraining Paradigm.Given a MLLM, typically the VPG and linear projector will be trained, fully or partially.For example, PaLM-E updates all of the parameters of VPG in the pre-training stage, while BLIP-2 and Flamingo freeze the ViTs and tune their Q-Former and Resampler, respectively.As the main part of the whole architecture, the LLM is usually frozen during the training or tuned only a small portion (e.g., 10B for Flamingo-80B).KOSMOS-1 is an exception, which does not use a pre-trained LLM but trains the LLM from scratch.Such a training paradigm typically results in much longer training time and data (both multimodal and pure text corpus).Recent works [30,16] show that adopting an existing LLM and freezing all of its parameters can also achieve excellent performance with significantly reduced computational cost, which leads to the trend of adapting frozen pre-trained LLM.For example, BLIP-2 FlanT5 XXL (12.1B) can achieve better zero-shot VQAv2 performance (65.0% in Acc.) compared with KOSMOS-1 (51.0% in Acc.) and Flamingo-80B (56.3% in Acc.).Thus, in this paper, we mainly focus on VPG transfer across frozen LLMs.\n\n\nExperiment Settings\n\nArchitecture.We adopt BLIP-2's architecture and training paradigm.In our exploration experiments, we consider using the VPG that consists of a CLIP ViT-L/14 [43], and a Q-Former that has already undergone a BLIP-like pre-training (the 1st stage pre-training in BLIP-2's paper [30]).\n\nTraining Data.For all of the exploration experiments, we adopt human-annotated COCO caption dataset [34] and web image-text pairs SBU dataset [40], which results in 1.4 million image-text pairs.\n\nTransfer Direction.For the small-to-large model transfer among the same type of LLMs, we investigate: 1) OPT [60] (decoder-only) series including 125M, 350M, 1.3B, and 2.7B, and 2) FlanT5 [12] (encoder-decoder) ranging base, large, and XL.For the transfer across different types of LLMs, we consider the ones of OPT and FlanT5 with similar sizes.\n\nEvaluation.To evaluate the performance of MLLMs, we choose two caption datasets: (1) COCO caption [34] (2) NoCaps [1], and three VQA datasets: (3) VQAv2 [4] (4) GQA [20] (5) OKVQA [37].We make evaluations after the pre-training without task-specific fine-tuning and report the CIDEr [55] for all caption tasks and accuracy for all VQA tasks.\n\nImplementation Details.We follow the same implementation details of BLIP-2, via the open code. 6Concretely, we use FP16 and BFloat16 for OPT and FlanT5 respectively in the model training.\n\nFor the learning rate, we first conduct a linear warm-up from 1e-6 to 1e-4, and then use a cosine learning rate schedule with the minimal lr=1e-5 for 10 epochs.Due to the limited data amount, we slightly decrease the batch size, which we find beneficial for the final performance.Specifically, we set the batch size of 1,728 and 1,152 for OPT and FlanT5-based models, respectively.\n\n\nMaximizing the Transfer Efficiency with a Two-stage Transfer Strategy\n\nIn this section, we first identify the key factors for maximizing transfer efficiency, based on which we then motivate our solution for better transfer.\n\n\nExploratory Analysis: Identifying Key Factors for VPG Transfer\n\nVia selected experiments of small-to-large transfer among OPT models, we can obtain the following key observations.More systematical comparisons are conducted in the later section (cf.\u00a74).\n\n\u2022 Inheriting the trained VPG can accelerate training.To demonstrate this, we compare the convergence rates of VPG training on OPT 350M from scratch, and inheriting VPG trained on OPT 125M .The patterns are shown in Fig. 3. Overall, we find that inheriting VPG trained on OPT 125M accelerates convergence, particularly for two caption tasks.However, for datasets that require fine-grained visual perception such as VQAv2 and GQA, directly conduct continue training with an inherited VPG will harm the performance.We hypothesize that tuning VPG with a randomly initialized projector will compromise the existing fine-grained visual perception ability of VPG.The possible reason can be that, the VPG is typically a pre-trained model with powerful visual perception ability, and thus updating based on the gradient passed through a random projector will mislead the VPG at the initial steps [2,33,23].\n\n\u2022 Warming up the linear projector can prevent performance drop and expedite VPG training.\n\nTo verify this, we first conduct a warm-up training of the linear projector for 3 epochs, during which both VPG and LLM are frozen.Subsequently, we jointly train VPG and the projector and plot the performance curve in Fig. 4 (the warm-up process is not included in this figure).The results show that the performance drop observed in Fig. 3 can be avoided in Fig. 4. Additionally, we observe that the warm-up training leads to fewer training steps required for VPG and projector joint training.However, we must emphasize that warming up is a costly step.In the case of a large LLM, such as 6.7B, the trainable parameters of BLIP-2's VPG will account for less than 10% of the total parameters, where freezing VPG can only lead to a reduction of 5.4% of A100 hours (36.9 out of 684.0 A100  hours).We will elaborate on how to accelerate the linear projector warm-up in our later discussion (cf.3.1).\u2022 Initializing LLM tgt 's projector with the help of the word converter can accelerate the linear projector warm-up.In fact, the VPG and projector trained on LLM src have already learned how to map the visual content to LLM src 's understandable soft prompt [39].If we can convert the LLM src 's soft prompt to LLM tgt 's soft prompt, we can directly get a VPG suitable for LLM tgt .One natural idea is to leverage the word embeddings of both models as a proxy for the soft prompt [25].The intuition behind the scene is that, the soft prompt works in the same format as normal words.\n\nTo validate our hypothesis, we conduct an experiment on the transfer from OPT 125M to OPT 1.3B .\n\nAfter training a linear word embedding converter (cf.\u00a73.2(b)), we initialize the projector for OPT 1.3B with the merged linear operation of the projector for OPT 125M and converter.As shown in Table 2, we observe that the initialization can reduce the 3 epochs' warm-up to 2 epochs.\u2022 Linear projector warm-up enables faster convergence with an extremely large learning rate.To determine the most efficient transfer practice, we experiment with training the projector using different learning rates.Surprisingly, we find that the linear projector enables fast and stable convergence with an extremely large learning rate.Specifically, by setting the learning rate to 5 times of the original value, the COCO caption's CIDEr score can reach 133.1 with 1 epoch training, which is higher than the 3 epochs results of w/o init.as shown in Table 2.\n\n\nA Two-stage VPG Transfer Framework\n\nBy connecting all the dots as discussed above in \u00a73.1, we now design our two-stage VPGTrans framework for more efficient VPG transfer.As shown in Fig. 5, the stage-1 of VPGTrans performs projector warm-up and the stage-2 carries out a vanilla fine-tuning.Our results demonstrate that the VPGTrans is simple yet effective that can significantly speed up the transfer without compromising performance.Detailed results are given in the later sections (cf.\u00a74 & 5).\n\n\u25b6 Stage-1: Projector Warm-up.\n\n(a) Inherit VPG.We first initialize the VPG for LLM tgt with the VPG trained on LLM src .(b) Projector Initialization.Then, we initialize the projector for LLM tgt merged from the projector of LLM src and a linear word converter.Formally, we define the linear projector of LLM src as f s (x) = W s x + b s , the linear projector for LLM tgt as f t (x) = W t x + b t , and the word converter as g c (x) = W c x + b c .tokenization methods, we optimize based on the overlapped tokens.Formally, for every given token k, we denote its word embeddings of LLM src and LLM tgt as x s and x t .Then, we minimize the loss:\nL = 1 \u2212 sim(g c (x s ), x t ) .(1)\nOnce we obtain the word converter g c (\u2022), we can easily merge it with the projector of LLM src as:\nf t (x) = f s (g c (x)) = W s (W c x + b c ) + b s ,(2)\nresulting in f t 's weight and bias as\nW t = W s W c and b t = W s b c + b s .\n(c) Warm-up Training.Then, we only train the projector in this stage with a frozen VPG and LLM.Specifically, we train the projector for 1 epoch with 5 times of the normal learning rate.\n\n\u25b6 Stage-2: Vanilla Fine-tuning.\n\n(d) Vanilla Fine-tuning.In the final step, we conduct a joint training of VPG and projector for n epochs with a normal learning rate.\n\n\nExp-I: Transfer across Different Model Sizes\n\nIn this section, we conduct experiments to systematically illustrate the effectiveness of our VPGTrans and analyze the relationship between transfer efficiency and model size.For simplicity, we use TaS to represent the transfer across different model sizes.\n\n\nExperimental Settings\n\nIn this part, we introduce baselines and transfer variants.For details about training data and implementation details, please refer to the experiment settings in the Preliminary (cf.2.2).\n\nBaselines.We mainly compare our VPGTrans with training from scratch (TFS) and VPG inheritance (VPG Inherit), where we report their performance on the aforementioned 5 tasks without further task-specific fine-tuning.For our VPGTrans, the word converter training only requires updating a linear layer on tokenized text data and typically takes less than 10 minutes on 1 A100 GPU with less than 15G GPU memory.Meanwhile, freezing the VPG can lead to at least 14 A100 minutes speed-up per epoch.Therefore, we consider the whole stage-1 training as the 1st epoch for simplicity.\n\nTransfer Variants.We conducted experiments on transfer learning using 1) the OPT model across four different sizes: 125M, 350M, 1.3B, and 2.7B, and 2) the FlanT5 model across three sizes: base, large, and XL.However, we encountered significant instability during training with FlanT5 large .As a result, we mainly present the transfer results between FlanT5 base and FlanT5 XL .\n\n\nVPGTrans Enabling Faster Convergence without Performance Drop under TaS\n\nFirst of all, as shown in Fig. 6, our VPGTrans can consistently accelerate the model convergence.For COCO caption and NoCaps that require more training steps to converge, our VPGTrans (green line) can be higher than the other two lines (blue and orange lines).To give a quantitative evaluation of the    3, our VPGTrans can achieve at least 4 times speed-up on 40% of Transfer-Task variants.Furthermore, for the two caption datasets, which take a long time to converge, our VPGTrans OPT 125M\u21922.7Bdelivers a 10 times speed-up.\n\nMoreover, when compared with the VPG inherit in Fig. 6, our VPGTrans can achieve a higher speed-up rate on all of the variants on caption tasks, and achieve better performance on most variants except for OPT 1.3B\u21922.7B .We refer the readers to Appendix \u00a7C.3 for more comparisons.\n\nWe provide interesting findings with respect to the efficiency transfer by VPGTrans in the following.\n\n\u2022 The smaller size of LLM src , the easier the transfer.In our OPT based experiments, we notice an interesting phenomenon: when transferring to a given LLM tgt , both the convergence rate and optimal performance are roughly inversely proportional to the size of LLM src .For example, as shown in Table 3, the OPT 125M\u21922.7Band OPT 350M\u21922.7Bhave much higher speed-up rate than OPT 1.3B\u21922.7Bon all of the datasets.Meanwhile, as demonstrated in Fig. 6, the optimal performance of OPT 125M\u21922.7B is better than OPT 1.3B\u21922.7Bon 3 VQA tasks.We hypothesize that training VPG on larger OPT will have a worse influence on VPG's existing fine-grained perception ability, which might be caused by the enlarging embedding dimensions.To validate our hypothesis, we fix the VPG weight and only tune linear projectors to test VPGs trained on different LLM src through cross-size transfer.The SPICE [3] metric on COCO caption is used to evaluate the VPG's visual perception ability, where SPICE is specifically designed for visual concept perception in captions.As shown in Fig. 7, for each row, given the LLM tar , the performance of VPG trained on smaller LLM src can outperform the larger ones in most conditions, which indicates a better visual perception ability of VPG trained on smaller LLM src .Therefore, adapting a VPG from a smaller OPT model which is less affected, is helpful to take fewer steps to reach the TFS's best performance and achieve even better performance.In this section, we further investigate the transfer across different model types.For simplicity, we mark this type of transfer as TaT.\n\n\nScale-up Experiments\n\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\ufffd\ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd\ufffd\ufffd\n\nExperimental Settings\n\nIn this part, we introduce baselines and transfer variants.For details about training data and implementation details, please refer to the experiment settings in the Preliminary (cf.2.2).\n\nBaselines.We mainly compare our VPGTrans with training from scratch (TFS), and report the performance on the aforementioned 5 tasks.Other details (cf.4.1) are totally the same with TaS experiments.\n\nTransfer Variants.We conducted experiments on transfer learning between 1) OPT 350M and FlanT5 base , and 2) OPT 2.7B and FlanT5 XL .\n\n\nVPGTrans Enabling Faster Convergence only on Large LLMs under TaT\n\n\u2022 There is no speed-up of TaT between two small LLMs.A finding is that on TaT our VPGTrans does not show speed-up for small models, and even shows a degeneration of training speed in the initial several epochs.As shown in Fig. 8, when transferring from OPT 350M to FlanT5 base , the convergence speed of VPGTrans is even slower than TFS in the initial several epochs.\n\n\u2022 Speed-up of VPGTrans happens in large LLMs.However, when moving to the large LLMs like OPT 2.7B and FlanT5 XL , there is an obvious speed-up.As shown in Table 3, we can see at least 2 times speed-up when transferring from FlanT5 XL to OPT 2.7B .We empirically find that the soft prompts for larger LLM are more linear transferrable among different LLM types.As shown in Fig. 8, when transferring between FlanT5 base and OPT 350M , the VGPTrans' 1st epoch results on two caption datasets are limited, where only a linear operation can be trained.The result of OPT 350M \u2192FlanT5 base on the COCO caption is even near to zero.By contrast, the result of FlanT5 XL \u2192OPT 2.7B with our VPGTrans are obviously higher than TFS.We hypothesize that larger LLM typically learned more generalizable text embeddings and share more similarity among relative word distances, which enables an easier VPG transfer.\n\n\nCustomizing New MLLMs with Any LLMs\n\nAbove, we thoroughly certify the efficacy of our proposed VPGTrans approach for higher efficient transfer of VPG.In this section, we illustrate how to apply the VPGTrans framework for VPG transfer to customize new MLLMs with any LLMs.\n\nVL-LLaMA.By applying our VPGTrans, we can equip the recently released LLaMA [53] model with a VPG trained on BLIP-2 OPT 6.7B to perceive the visual information.As shown in Table 4, we can see that our VL-LLaMA can outperform the original BLIP-2 OPT 6.7B on all datasets.\n\nVL-Vicuna.An exciting application of our VPGTrans is to build a GPT-4 [8] style multimodal conversation chatbot.To achieve our goal, we employ Vicuna [10] as our base LLM.Similarly, we transfer the VPG from BLIP-2 OPT 6.7B , and add an extra instruction tuning using MiniGPT-4's selfinstruct data [62].We compare our model with MiniGPT-4 in Fig. 9.When compared to MiniGPT-4, our VL-Vicuna shows better visual perception ability.Please refer to Appendix \u00a7E for more cases.In How many people are in the image?\n\nThere are two people in the image.\n\nWhat are they doing?\n\nThe two people in the image are both holding baseball bats and standing on a baseball field.\n\nOne person is the pitcher, and the other is the catcher.The pitcher is holding the baseball bat and preparing to throw the ball to the catcher.The catcher is standing behind the home plate and holding the glove, ready to catch the ball.\n\nHow many people are in the image?\n\nThere are three people in the image: the batter, the catcher, and the umpire.\n\nWhat are they doing?\n\nThe batter is standing in the batter's box, holding a bat, and waiting for the pitcher to throw the ball.\n\nThe catcher is standing behind the plate, holding the catcher's mitt, and ready to catch the ball if the batter hits it.The umpire is standing behind the catcher, holding the umpire's mask, and ready to make a call on any balls and strikes.\n\n\nMiniGPT-4 VL-Vicuna\n\nTell me anything you know about the man in the image.\n\nTell me anything you know about the man in the image.\n\nThe man in the image is an actor named Leonardo DiCaprio.He was born on November 11, 1974, in Los Angeles, California, USA.He is known for his roles in films such as Titanic, Inception, and The Wolf of Wall Street.DiCaprio has won several awards for his acting, including an Academy Award for Best Actor for his role in The Revenant.\n\nThe man in the image is wearing a gray sweater and sitting in front of a fireplace.He has a serious expression on his face and is looking off into the distance.The room appears to be dimly lit, with shadows cast on the walls and floor.There is a sense of stillness and quiet in the scene.addition, we also report the ranking and ELO ratings for our VL-Vicuna compared with the other 7 SOTA multimodal chatbots in Table 5 (The evaluation is done by Multimodality Chatbot Arena platform 7 ).The results show the effectiveness of our VL-Vicuna compared with existing SOTA models.\n\n\nConclusion\n\nIn this work, we conduct a comprehensive investigation to the problem of VPG transferability across LLMs.We first explore the key factors for maximizing the transfer efficiency under the VPG transfer across different LLM sizes and types.Based on the key findings, we propose a novel two-stage transfer framework, namely VPGTrans, which can help to achieve comparable or better performance while significantly reducing the training costs.Moreover, a list of important findings and possible reasons behind them are shown and discussed.Finally, we demonstrate the practical value of our VPGTrans, by customizing new MLLMs via VPG transfer from existing MLLMs.\n\nA Related Work\n\n\nA.1 Vision and Language Models\n\nVision and language models (VLMs) [50,29,32,31] aim at understanding visual and textual information with a single model.Previously, the VLM mainly employs a pre-trained object detector as its feature extractor and conducts unsupervised training on a huge amount of image-text pairs.For example, VL-Bert [50], ViL-Bert [36] and Uniter [9] adopt Faster-RCNN [47] to extract image information into object features and take advantage of the masked language model as their pre-training task.Later, due to the prevalence of vision transformer (ViT), the VLM paradigm is turned into end-to-end training with a ViT as the visual encoder.The representative works include ALBEF [28], BLIP [29], and BEIT-v3 [56], which show the state-of-the-arts supervised training performance on a wide range of downstream tasks.\n\nRecently, LLMs have shown their remarkable capability as zero/few-shot learners [7] and a series of emergent abilities [57] like in-context learning [7], and chain-of-thoughts reasoning [58].A new paradigm, i.e., MLLMs is created by associating the VLM or pure vision encoders with LLMs.As we illustrated before, the VLM or visual encoders are typically able to convert the input vision signals into LLM-understandable soft prompts, and thus we call them VPG.The MLLMs advance in inheriting the great potentials of the backbone LLMs, and thus are capable of achieving excellent zero/few-shot performances [2,30] on downstream tasks or be equipped with visual planning ability [16].However, connecting the VPG to the existing LLMs with further tuning is costly.Even the BLIP-2 [30], targeted at efficient training, will take over 600 A100 GPU hours on over 100M image-text pairs for its largest model.With this regard, our proposed VPGTrans can effectively reduce the cost of building new MLLMs with the help of existing ones.\n\n\nA.2 Prompt Transfer\n\nIn this paper, we investigate the VPG transfer, where the soft prompt is to represent the content of specific inputs like images and videos.In addition to the content prompt, the more explored soft prompt is the task prompt [24,61,22], where a sequence of soft prompts are tuned to assist the pre-trained models to achieve better performance on specific tasks.There have already been some works exploring the transferability of task prompts.For example, Su et al. [51] conducts a series of experiments to illustrate the transferability across tasks and models.Specifically, Su et al. [51] find that the transfer between similar tasks is beneficial for training speed-up and better performance.Lester et al. [25] proposes to recycle soft prompts across models with vocab-to-vocab transformations, or linear-combination transformations.Note that our word converter initialization is similar to the idea of vocab-to-vocab transformations.However, we do not observe a zero-shot transfer in our experiments like them, which indicates a potential difference between the content prompts and task prompts.Another way of soft prompt transfer [14] is to conduct prompt tuning on discrete prompts, and thus the discrete prompts can be directly shared across models.Different from these task prompts transfer works, our VPG transfer scenario actually suffers from fewer limitations.For example, the task soft prompts transfer suffers from the dimension change problem, where the main body of the trainable parameters should be processed.However, our VPG (the main trainable parameters) can naturally be shared among LLMs with different embedding dimensions and leave the dimension change problem to a simple projector with ignorable parameters.\n\n\nB Extended Findings in Exploratory Analysis\n\nIn this section, we show extended findings of exploratory analysis (cf.\u00a73.1).\n\n\u2022 1. Merely tuning the projector can not achieve the best performance.We want to clarify that merely tuning the projector is insufficient for achieving the best performance.Notably, as shown in Fig. 10, significant performance gaps are observed between the \"only linear\" (green curve) and \"train from scratch\" (orange curve) approaches for COCO caption and NoCaps.Therefore, if the goal is to build a multimodal conversation robot using carefully collected dialog data, training only the linear projector is insufficient to align with the provided data.\u2022 2. Word embedding converter can not replace a trained linear projector.As demonstrated in Fig. 11, we observe a common pattern: the last token of soft prompts is closest to EOS, while the middle tokens represent the image content.Such a phenomenon indicates a similarity between soft prompts and word embeddings.However, they are not identical.For instance, the norm of soft prompts is typically around 10 times the average norm of word embeddings.It is important to note that the linear projector initialization cannot replace the warm-up training.Using only the linear projector initialization even yields a random performance.We believe that a better understanding of how prompt works will further benefit the VPG's transfer learning.\n\n\u2022 3. The projector warm-up is robust to a larger learning rate, while VPG can not.The first thing we want to clarify is that the 5 times normal learning rate will result in a training crash for VPG.Additionally, we find that although increasing the learning rate to 10 times in the projector warm-up does not yield any additional acceleration, the projector can converge without crashing during training.\n\n\nC Extended TaS Experiments\n\nIn this section, we first illustrate extending findings of TaS experiments (cf.\u00a74).Then, we introduce the implementation details of scale-up experiments.We also plot a more complete version of Fig. 6 in Fig. 13.\n\n\nC.1 VPGTrans Enabling Stable Training under TaS\n\nAs we illustrated before, FlanT5 large training is extremely unstable.Even when the learning rate is adjusted to one-tenth of its original value, the model does not converge or shows a very slow convergence rate after 4 epochs.However, we find that by lowering the learning rate for stage-2 training, our VPGTrans can achieve stable training on FlanT5 large .We plot the performance curve of the COCO caption in Fig. 12.\n\n\nC.2 VPGTrans Enabling Training with Less Data under TaS\n\nWe empirically find that TaS can reduce the requirement for the amount of training data.By reducing the training data to only COCO, we find no obvious performance drop.However, we want to stress that the retained data should be of high quality, which means that if the same number of SBU data   is retained, the performance especially for captioning will drop.The conclusion can also be found in Table 4.We refer the readers to the next subsection for more details.\n\n\nC.3 Comparison between VPGTrans and VPG Inherit\n\nAs shown in Fig. 13, the green line (our VPGTrans) can be higher than the orange line (VPG inherit) for the majority of various conditions.Especially when considering the best performance of different tasks, our VPGTrans can achieve better performance than VPG inherit (non \"-\" in Table 6) for over 74% Transfer-Task variants.Moreover, among the variants that our VPGTrans can achieve better performance, our VPGTrans can also achieve a speed-up on 69.2% conditions.\n\n\nC.4 Scale-up Experiment Implementation Details\n\nThe scale-up experiment refers to the results in Table 4.We try to imitate BLIP-2's pre-training data composition.First of all, two human-annotated datasets COCO and VG are used.SBU is also used.Then, BLIP-2 uses BLIP to generate captions for the 115M web images and rank them with CLIP ViT-L/14.We also adopt similar synthetic data from Laion-COCO. 8 We report the concrete number of data we use in Table 4.For the stage-1 training, we keep the same as the previous validation experiments where COCO and SBU are used for warm-up with a 5 times the learning rate.Then, we use COCO, VG, and Laion-COCO for the stage-2 training.Note that we have tried to include Laion-COCO and VG for the stage-1 training, but found no obvious difference and thus use COCO and SBU for simplicity.For VL-Vicuna, to align with the conversation scenario, we further fine-tune our VL-Vicuna with MiniGPT-4's self-instruct data, which is 3,439 image-text pairs.\n\n\nD Extended TaT Experiments\n\nIn this section, we mainly illustrate extending findings of TaT experiments (cf.\u00a75).We plot a more complete version of Fig. 8 in Fig. 14.\n\n\nD.1 Linear Transfer Gap between Different LLM's Visual Prompts\n\nAs illustrated in Section 5.2, it is more difficult to transfer between two small LLMs with our VPGTrans due to the weaker linear transferability between two small LLMs' visual prompts.To better support our results, we compare the results of tuning only the projector (i.e.linear transfer) and the best results the VPGTrans can achieve.As shown in Table 7, we can see that when conducting transfers between two large models (OPT 350M and FlanT5 base ), the performance is typically far from the optimal results.However, when we transfer between OPT 2.7B and FlanT5 XL , the linear performance is near to the optimal performance.There is a 25.7 points gap between FlanT5 base \u2192 OPT 350M 's linear and best on COCO caption datasets but only 7.2 points gap between FlanT5 XL \u2192 OPT 2.7B 's linear and best.If considering the transfer between the small to large LLMs under TaT, both the VPG's visual perception ability and transfer gap should be considered.We leave the systematical exploration for future works.\n\n\nE Extended Results for MLLM Customization\n\nWe show more comparisons between VL-Vicuna and MiniGPT-4 in Fig. 15.We can see that our VL-Vicuna has better visual perception ability.For example, when MiniGPT-4 falsely recognizes the three people in the image as two in the first example, our VL-Vicuna can not only recognize the number of people but also tell their roles.Moreover, our VL-Vicuna can successfully link the vision content with external knowledge.In the third example, our VL-Vicuna can recognize Leonardo and link the content with his films like Titanic.\n\n\nF Potential Impact and Limitations\n\nOur VPGTrans is designed for building new MLLMs with lower computational cost, i.e., shorter training time and less training data.With an already pre-trained MLLM, VPGTrans enables fast VPG transfer to build either a larger MLLM or a MLLM with a different type of LLM.We hope VPGTrans can facilitate teams in LLM communicty to customize their MLLMs with reduced cost.There are also possible limitations of the current version of VPGTrans.The first one is that our VPGTrans should rely on some already-aligned VPGs.The second potential limitation is that the VPGTrans-built MLLMs still suffer from the common problems of content generation AI systems [45,46,48,7].For example, the VL-Vicuna may make up some sentences with falsely recognized visual facts, like what is shown in Fig. 16.It is worth exploring associating our VPGTrans with training safer models [5,41,38].\n\nFigure 1 :\n1\nFigure 1: (a) The general architecture of MLLMs, e.g., BLIP-2 [30] and PaLM-E [16], including a visual prompt generator (VPG), a linear projector and a backbone LLM.Typically, to tune the MLLM, only the VPG and the projector are updated, while the LLM is kept frozen.(b) This work investigates the VPG transferability across LLMs, including different LLM sizes and LLM types.\n\n\nFigure 3 :\n3\nFigure 3: Comparisons between i) inheriting VPG from OPT 125M and training it with randomly initialized projector for OPT 350M and ii) training VPG and randomly initialized projector for OPT 350M from scratch.\n\n\nFigure 4 :\n4\nFigure 4: First warming-up then transferring can avoid performance drop on VQAv2 and accelerate convergence for COCO caption.\n\n\nFigure 5 :\n5\nFigure 5: Our two-stage VPGTrans framework.Stage-1 is to first (a) inherit the VPG of LLM src and (b) initialize the projector by merging the projector of LLM src and word converter.(c) Then the projector will be warmed up for 1 epoch with a large learning rate.Stage-2 is to (d) conduct a vanilla fine-tuning for the VPG and projector for n epochs.\n\n\nFigure 6 :\n6\nFigure 6: Comparison between different methods across 3 TaS variants on tasks.Note that the model is directly evaluated after pre-training without further fine-tuning.Please refer to Appendix \u00a7C for other transfer variants.\n\n\nFigure 8 :\n8\nFigure 8: Comparison between different methods across 2 TaT variants on 5 tasks.Note that the model is directly evaluated after pre-training without further fine-tuning.Please refer to Appendix \u00a7D for other transfer variants.\n\n\nFigure 7 :\n7\nFigure 7: The confusion matrix.Only linear layers are trained for VPG evaluation.Models are tested on COCO caption with SPICE metric to compare the VPGs trained on different LLM src .\n\n\nFigure 9 :\n9\nFigure 9: Comparison between MiniGPT-4 and our VL-Vicuna.\n\n\nFigure 10 :\n10\nFigure 10: Comparisons between i) inheriting VPG from OPT 125M and training it with randomly initialized projector for OPT 350M and ii) training VPG and randomly initialized projector for OPT 350M from scratch.iii) training only the projector.\n\n\nFigure 11 :\n11\nFigure 11: Interpreting generated soft prompts for OPT 125M with nearest words.\n\n\nFigure 12 :\n12\nFigure 12: Comparison of training FlanT5 large using different methods.\n\n\n\n\nFigure 2: Comparing the cost between training VPG from scratch vs. transferring VPG via our VPGTrans strategy.Note the LLM via VPGTrans is FlanT5 XL\u2192XXL and OPT 2.7B\u21926.7B, respectively.\nBLIP-2 (ViT-G + FlanT5 XXL )BLIP-2 (ViT-G + OPT 6.7B )684.02801.8121.6631.52586.8129.0VPGTrans (Ours)65.2 65.257.2 54.3Train from scratch32.4132.75.359.0241.713.8GPU hoursCostTrain dataVQAv2GPU hoursCostTrain dataVQAv2(A100)(USD)(M)(acc.)(A100)(USD)(M)(acc.)\n\nTable 1 :\n1\nMLLMs architectures and pre-training paradigm.\u2020: it is a GPT-2-like LLM with relative position embeddings.\nMLLMsVPGVPG TrainableLLMLLM TrainableKOSMOS-1 [19]CLIP [43]AllRand. Init. LMAllFrozen\n\nTable 2 :\n21130.2126.12132.7131.63133.4132.8\nComparison between linear projector warm-up with/without word embedding initialization.The metric is COCO caption's CIDEr.Epoch w/ init.w/o init.\n\n\nTable 3 :\n3\nThe speed-up rate of our VPGTrans compared with training from scratch (TFS).The symbol \"-\" means VPGTrans can not achieve better performance than TFS.\nTransferCOCO Caption NoCaps VQAv2 GQA OKVQAOPT 125M\u2192350M1.73.01.05.05.0OPT 125M\u21921.3B9.010.09.0-2.0OPT 350M\u21921.3B4.55.09.02.02.0OPT 125M\u21922.7B10.010.02.02.03.0OPT 350M\u21922.7B10.010.02.0-3.0OPT 1.3B\u21922.7B3.33.32.0-1.5FlanT5 base\u2192XL1.01.13.04.02.0FlanT5 XL \u2192 OPT 2.7B5.05.02.02.03.0OPT 2.7B \u2192 FlanT5 XL1.72.0-2.0-\nspeed-up rate, we show the speed-up rate in\n\n\nTable 3 .\n3\nThe speed-up rate is calculated by considering the number of epochs reduced to achieve the best TFS performance on a particular dataset.Formally, given a dataset D, TFS obtains the best performance p on D at epoch e tfs , whereas VPGTrans first achieves a better performance than p at epoch e vt .The speed-up rate on D is given by etfs evt .According to Table\n\n\nTable 4 :\n4\nComparison between models built with our VPGTrans and the original BLIP-2 ViT-G OPT 6.7B and BLIP-2 ViT-G FlanT5 XXL .\nModelsVQAv2 valGQA test-devOKVQA GPU hours training data testBLIP-2 ViT-G OPT 6.7B54.336.436.4631.5129MBLIP-2 ViT-G OPT 2.7B\u21926.7B (ours)57.236.239.859.013.8MVL-LLaMA 7B (ours)58.137.537.467.113.8MBLIP-2 ViT-G FlanT5 XXL65.244.745.9684.0121.6MBLIP-2 ViT-G FlanT5 XL\u2192XXL (ours)65.245.045.032.45.3M\n\nTable 5 :\n5\nComparison between our VL-Vicuna and SOTA MLLMs for multimodal conversation.The evaluation is done by Multimodality Chatbot Arena platform via user voting.\nRank ModelElo Rating1LLaMA-Adapter v2 [17]1023.02LLaVA [35]1019.93VL-Vicuna (ours)1012.14MiniGPT-4 [62]1011.95InstructBLIP [13]999.56mPLUG-Owl [59]996.37Otter [26]981.58BLIP-2 [30]955.85 Exp-II: Transfer across Different Model Types\n\nTable 6 :\n6\nThe speed-up rate of our VPGTrans compared with VPG inherit.The symbol \"-\" means VPGTrans can not achieve better performance than VPG inherit.\nTransferCOCO Caption NoCaps VQAv2 GQA OKVQAOPT 125M\u2192350M1.12.710.06.06.0OPT 125M\u21921.3B-2.7---OPT 350M\u21921.3B-1.71.02.01.0OPT 125M\u21922.7B3.03.03.01.03.0OPT 350M\u21922.7B3.34.51.01.01.0OPT 1.3B\u21922.7B2.33.0---FlanT5 base\u2192XL-1.01.89.00.4\n\nTable 7 :\n7\nComparison between tuning only the projector (i.e.linear transfer) and the best results the VPGTrans achieve.\nTransferCOCO Caption linear bestVQAv2 linear bestFlanT5 base \u2192 OPT 350M 110.8 136.540.4 44.2FlanT5 XL \u2192 OPT 2.7B132.1 139.350.4 50.3OPT 350M \u2192 FlanT5 base1.1122.134.0 49.9OPT 2.7B \u2192 FlanT5 XL106.5 133.251.3 53.5\nNote that Flamingo also inserts some tunable parameters into the LLM part, but recent works[30,16] found that freezing LLM can be more efficient.\nIt is not a rigorous expression, because the VPG is typically a pre-trained model, like CLIP[43]. We use it for simplicity in this paper.\nwhile the projector can not be shared due to the dimension mismatch.\nhttps://github.com/salesforce/lavis\nThe word converter is a linear layer trained with text-only caption data to convert the LLM src 's word embeddings to LLM tgt 's word embeddings. We experiment with optimizing losses based on cosine similarity or Euclidean distance, and observe no significant difference between the two losses. Thus we simply use cosine similarity in our experiments. In cases where LLM src and LLM tgt use different\nhttp://vlarena.opengvlab.com\nhttps://laion.ai/blog/laion-coco\nAcknowledgmentsThis research is supported by NExT++ Lab, Singapore Ministry of Education Academic Research Fund Tier 2 under MOE's official grant number T2EP20221-0023, and CCF-Baidu Open Fund.MiniGPT-4 VL-VicunaWhat is written in the middle sign?The sign says \"Pike Place\" and points in the direction of the building in the background.What does this mean?This sign is indicating the location of Pike Place, which is likely a street or location in the city.The arrow on the sign points in the direction of the building in the background, which is likely a highrise apartment or office building.What is written in the middle sign?The middle sign says \"Pike PI\" What does this mean?\"Pike PI\" is likely a reference to the intersection of Pike Place and Pine Streets in downtown Seattle, Washington.How to cook this dish?To cook this dish, you will need the following ingredients: broccoli, olive oil, garlic, salt, pepper, and red pepper flakes.You will also need a pan or pot to cook the broccoli in.To cook the broccoli, you will need to cut it into small florets and steam it for about 5-7 minutes, or until it is tender.While the broccoli is cooking, you can heat up some olive oil in the pan and add minced garlic and salt to it.Once the broccoli is done, you can add it to the pan with the garlic and oil and stir it together.You can then add some red pepper flakes to give the dish some heat.......How to cook this dish?To cook this dish, you will need the following ingredients: broccoli, olive oil, garlic, salt, and pepper.Here are the steps to cook the dish: 1. Cut the broccoli into small florets.2. Heat some olive oil in a pan over medium heat.Please describe the image.The image is of a three-tiered wedding cake on a wooden table.The cake is decorated with white frosting and red berries.The table is cluttered with plates, silverware, and a vase of flowers.The room appears to be a reception area or banquet hall.The lighting is bright and well-lit, casting shadows on the table and the cake.When is it now in the image?I'm sorry, but as an AI language model, I don't have the ability to determine the current time based on the image you've provided.However, I can tell you that the image appears to be of a bar or restaurant with a clock on the wall.Failure Cases\nNocaps: Novel object captioning at scale. Harsh Agrawal, Karan Desai, Yufei Wang, Xinlei Chen, Rishabh Jain, Mark Johnson, Dhruv Batra, Devi Parikh, Stefan Lee, Peter Anderson, Proceedings of the IEEE/CVF international conference on computer vision. the IEEE/CVF international conference on computer vision2019\n\nFlamingo: a visual language model for few-shot learning. Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, Advances in Neural Information Processing Systems. 202235\n\nSpice: Semantic propositional image caption evaluation. Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould, Computer Vision-ECCV 2016: 14th European Conference. Amsterdam, The NetherlandsSpringerOctober 11-14, 2016. 2016Proceedings, Part V 14\n\nVqa: Visual question answering. Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, Lawrence Zitnick, Devi Parikh, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision2015\n\nTraining a helpful and harmless assistant with reinforcement learning from human feedback. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova Dassarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, arXiv:2204.058622022arXiv preprint\n\nHigh-performance large-scale image recognition without normalization. Andy Brock, Soham De, Samuel L Smith, Karen Simonyan, International Conference on Machine Learning. PMLR2021\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033\n\nS\u00e9bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint\n\nUniter: Universal image-text representation learning. Yen-Chun Chen, Linjie Li, Licheng Yu, Ahmed El Kholy, Faisal Ahmed, Zhe Gan, Yu Cheng, Jingjing Liu, Computer Vision-ECCV 2020: 16th European Conference. Glasgow, UKSpringerAugust 23-28, 2020. 2020Proceedings, Part XXX\n\nVicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, Eric P Xing, March 2023\n\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, arXiv:2204.02311Scaling language modeling with pathways. 2022arXiv preprint\n\nScaling instruction-finetuned language models. Chung Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, arXiv:2210.114162022arXiv preprint\n\nInstructblip: Towards general-purpose vision-language models with instruction tuning. Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng, Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, Steven Hoi, 2023\n\nRlprompt: Optimizing discrete text prompts with reinforcement learning. Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric P Xing, Zhiting Hu, arXiv:2205.125482022arXiv preprint\n\nAn image is worth 16x16 words: Transformers for image recognition at scale. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, arXiv:2010.119292020arXiv preprint\n\nDanny Driess, Fei Xia, S M Mehdi, Corey Sajjadi, Aakanksha Lynch, Brian Chowdhery, Ayzaan Ichter, Jonathan Wahid, Quan Tompson, Tianhe Vuong, Yu, arXiv:2303.03378PaLM-E: An embodied multimodal language model. 2023arXiv preprint\n\nPeng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei Zhang, Pan Lu, Conghui He, Xiangyu Yue, Hongsheng Li, Yu Qiao, arXiv:2304.15010Llama-adapter v2: Parameter-efficient visual instruction model. 2023arXiv preprint\n\nTraining compute-optimal large language models. Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego De Las, Lisa Anne Casas, Johannes Hendricks, Aidan Welbl, Clark, arXiv:2203.155562022arXiv preprint\n\nLanguage is not all you need: Aligning perception with language models. Shaohan Huang, Li Dong, Wenhui Wang, Yaru Hao, Saksham Singhal, Shuming Ma, Tengchao Lv, Lei Cui, Owais Khan Mohammed, Qiang Liu, arXiv:2302.140452023arXiv preprint\n\nGqa: A new dataset for real-world visual reasoning and compositional question answering. A Drew, Christopher D Hudson, Manning, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognition2019\n\nPerceiver: General perception with iterative attention. Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, Joao Carreira, International conference on machine learning. PMLR2021\n\nVisual prompt tuning. Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath Hariharan, Ser-Nam Lim, Computer Vision-ECCV 2022: 17th European Conference. Tel Aviv, IsraelSpringerOctober 23-27, 2022. 2022Proceedings, Part XXXIII\n\nFine-tuning can distort pretrained features and underperform out-of-distribution. Ananya Kumar, Aditi Raghunathan, Robbie Jones, Tengyu Ma, Percy Liang, arXiv:2202.100542022arXiv preprint\n\nThe power of scale for parameter-efficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, arXiv:2104.086912021arXiv preprint\n\nReducing retraining by recycling parameter-efficient prompts. Brian Lester, Joshua Yurtsever, Siamak Shakeri, Noah Constant, arXiv:2208.055772022arXiv preprint\n\nOtter: A multi-modal model with in-context instruction tuning. Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, Ziwei Liu, arXiv:2305.037262023arXiv preprint\n\nJuncheng Li, Kaihang Pan, Zhiqi Ge, Minghe Gao, Hanwang Zhang, Wei Ji, Wenqiao Zhang, Tat-Seng Chua, arXiv:2308.04152Siliang Tang, and Yueting Zhuang. Fine-tuning multimodal llms to follow zero-shot demonstrative instructions. 2023arXiv preprint\n\nAlign before fuse: Vision and language representation learning with momentum distillation. Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong, Steven Chu, Hong Hoi, Advances in neural information processing systems. 342021\n\nBlip: Bootstrapping language-image pre-training for unified vision-language understanding and generation. Junnan Li, Dongxu Li, Caiming Xiong, Steven Hoi, International Conference on Machine Learning. PMLR2022\n\nBLIP-2: Bootstrapping language-image pretraining with frozen image encoders and large language models. Junnan Li, Dongxu Li, Silvio Savarese, Steven Hoi, arXiv:2301.125972023arXiv preprint\n\nMomentdiff: Generative video moment retrieval from random to real. Pandeng Li, Chen-Wei Xie, Hongtao Xie, Liming Zhao, Lei Zhang, Yun Zheng, Deli Zhao, Yongdong Zhang, Advances in neural information processing systems. 2023\n\nProgressive spatio-temporal prototype matching for text-video retrieval. Pandeng Li, Chen-Wei Xie, Liming Zhao, Hongtao Xie, Jiannan Ge, Yun Zheng, Deli Zhao, Yongdong Zhang, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023\n\nDongze Lian, Daquan Zhou, Jiashi Feng, Xinchao Wang, arXiv:2210.08823Scaling & shifting your features: A new baseline for efficient model tuning. 2022arXiv preprint\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, Lawrence Zitnick, Computer Vision-ECCV 2014: 13th European Conference. Zurich, SwitzerlandSpringerSeptember 6-12, 2014. 2014Proceedings, Part V 13\n\nHaotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee, Visual instruction tuning. 2023\n\nVilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks. Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee, Advances in neural information processing systems. 322019\n\nOK-VQA: A visual question answering benchmark requiring external knowledge. Kenneth Marino, Mohammad Rastegari, Ali Farhadi, Roozbeh Mottaghi, Proceedings of the IEEE/cvf conference on computer vision and pattern recognition. the IEEE/cvf conference on computer vision and pattern recognition2019\n\nTeaching language models to support answers with verified quotes. Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song, Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham, Geoffrey Irving, arXiv:2203.111472022arXiv preprint\n\nRon Mokady, Amir Hertz, Amit H Bermano, Clipcap, arXiv:2111.09734Clip prefix for image captioning. 2021arXiv preprint\n\nIm2text: Describing images using 1 million captioned photographs. Vicente Ordonez, Girish Kulkarni, Tamara Berg, Advances in neural information processing systems. 242011\n\nTraining language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in Neural Information Processing Systems. 202235\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 1892019\n\nLearning transferable visual models from natural language supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, International conference on machine learning. PMLR2021\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, The Journal of Machine Learning Research. 2112020\n\nZero-shot text-to-image generation. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever, International Conference on Machine Learning. PMLR2021\n\nHierarchical text-conditional image generation with clip latents. Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen, arXiv:2204.061252022arXiv preprint\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. Kaiming Shaoqing Ren, Ross He, Jian Girshick, Sun, Advances in neural information processing systems. 282015\n\nPhotorealistic text-toimage diffusion models with deep language understanding. Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, Advances in Neural Information Processing Systems. 202235\n\nObject scene representation transformer. S M Mehdi, Daniel Sajjadi, Aravindh Duckworth, Mahendran, Filip Sjoerd Van Steenkiste, Mario Pavetic, Leonidas J Lucic, Klaus Guibas, Thomas Greff, Kipf, Advances in Neural Information Processing Systems. 202235\n\nWeijie Su, Xizhou Zhu, Yue Cao, Bin Li, Lewei Lu, Furu Wei, Jifeng Dai, arXiv:1908.08530Vl-bert: Pre-training of generic visual-linguistic representations. 2019arXiv preprint\n\nOn transferability of prompt tuning for natural language processing. Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, Peng Li, Juanzi Li, Proceedings of the 2022 Conference of the North American Chapter. the 2022 Conference of the North American ChapterHuman Language Technologies2022\n\nQuan Sun, Yuxin Fang, Ledell Wu, Xinlong Wang, Yue Cao, arXiv:2303.15389Eva-clip: Improved training techniques for clip at scale. 2023arXiv preprint\n\nLLaMA: Open and efficient foundation language models. Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timoth\u00e9e Lachaux, Baptiste Lacroix, Naman Rozi\u00e8re, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.139712023arXiv preprint\n\nMultimodal few-shot learning with frozen language models. Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, Oriol Eslami, Felix Vinyals, Hill, Advances in Neural Information Processing Systems. 202134\n\nCIDEr: Consensus-based image description evaluation. Ramakrishna Vedantam, Lawrence Zitnick, Devi Parikh, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2015\n\nImage as a foreign language: Beit pretraining for all vision and vision-language tasks. Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu, Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, arXiv:2208.104422022arXiv preprint\n\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022arXiv preprint\n\nChain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, Denny Zhou, arXiv:2201.119032022arXiv preprint\n\nQinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, Chaoya Jiang, Chenliang Li, Yuanhong Xu, Hehong Chen, Junfeng Tian, Qian Qi, Ji Zhang, Fei Huang, mplug-owl: Modularization empowers large language models with multimodality. 2023\n\nOpt: Open pre-trained transformer language models. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, arXiv:2205.010682022arXiv preprint\n\nLearning to prompt for vision-language models. Kaiyang Zhou, Jingkang Yang, Chen Change Loy, Ziwei Liu, International Journal of Computer Vision. 13092022\n\nMiniGPT-4: Enhancing vision-language understanding with advanced large language models. Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, Mohamed Elhoseiny, arXiv:2304.105922023arXiv preprint\n", "annotations": {"author": "[{\"end\":164,\"start\":69},{\"end\":259,\"start\":165},{\"end\":356,\"start\":260},{\"end\":430,\"start\":357},{\"end\":503,\"start\":431},{\"end\":584,\"start\":504},{\"end\":665,\"start\":585},{\"end\":736,\"start\":666}]", "publisher": null, "author_last_name": "[{\"end\":77,\"start\":72},{\"end\":172,\"start\":169},{\"end\":268,\"start\":265},{\"end\":363,\"start\":361},{\"end\":436,\"start\":434},{\"end\":515,\"start\":512},{\"end\":598,\"start\":594}]", "author_first_name": "[{\"end\":71,\"start\":69},{\"end\":168,\"start\":165},{\"end\":264,\"start\":260},{\"end\":360,\"start\":357},{\"end\":433,\"start\":431},{\"end\":511,\"start\":504},{\"end\":593,\"start\":585}]", "author_affiliation": "[{\"end\":163,\"start\":99},{\"end\":258,\"start\":194},{\"end\":355,\"start\":289},{\"end\":429,\"start\":365},{\"end\":502,\"start\":438},{\"end\":583,\"start\":517},{\"end\":664,\"start\":600},{\"end\":735,\"start\":667}]", "title": "[{\"end\":55,\"start\":1},{\"end\":791,\"start\":737}]", "venue": null, "abstract": "[{\"end\":2252,\"start\":861}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2429,\"start\":2425},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2431,\"start\":2429},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":2434,\"start\":2431},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2568,\"start\":2564},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2582,\"start\":2579},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2593,\"start\":2590},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2639,\"start\":2635},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2947,\"start\":2943},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2950,\"start\":2947},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2997,\"start\":2993},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4208,\"start\":4205},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":8805,\"start\":8801},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8822,\"start\":8819},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8853,\"start\":8849},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8869,\"start\":8866},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8882,\"start\":8879},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8897,\"start\":8893},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8923,\"start\":8919},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8947,\"start\":8943},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8956,\"start\":8952},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":8968,\"start\":8964},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8982,\"start\":8978},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8997,\"start\":8993},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9011,\"start\":9007},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9027,\"start\":9023},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":9045,\"start\":9041},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9060,\"start\":9056},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9731,\"start\":9727},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9734,\"start\":9731},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10382,\"start\":10378},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10501,\"start\":10497},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10609,\"start\":10605},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10651,\"start\":10647},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":10814,\"start\":10810},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10893,\"start\":10889},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11151,\"start\":11147},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11166,\"start\":11163},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11205,\"start\":11202},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11218,\"start\":11214},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11233,\"start\":11229},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":11336,\"start\":11332},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13335,\"start\":13332},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":13338,\"start\":13335},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13341,\"start\":13338},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14592,\"start\":14588},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14815,\"start\":14811},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20967,\"start\":20964},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":24058,\"start\":24054},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24323,\"start\":24320},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24404,\"start\":24400},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":24551,\"start\":24547},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":27438,\"start\":27434},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":27441,\"start\":27438},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":27444,\"start\":27441},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":27447,\"start\":27444},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":27707,\"start\":27703},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":27722,\"start\":27718},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":27737,\"start\":27734},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":27760,\"start\":27756},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28072,\"start\":28068},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":28083,\"start\":28079},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":28101,\"start\":28097},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":28289,\"start\":28286},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":28329,\"start\":28325},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":28358,\"start\":28355},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":28396,\"start\":28392},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":28814,\"start\":28811},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":28817,\"start\":28814},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28886,\"start\":28882},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":28986,\"start\":28982},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":29483,\"start\":29479},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":29486,\"start\":29483},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":29489,\"start\":29486},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":29723,\"start\":29719},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":29843,\"start\":29839},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":29966,\"start\":29962},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30392,\"start\":30388},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":38061,\"start\":38057},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":38064,\"start\":38061},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":38067,\"start\":38064},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":38069,\"start\":38067},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":38269,\"start\":38266},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":38272,\"start\":38269},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":38275,\"start\":38272},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":43975,\"start\":43971},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":43978,\"start\":43975},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":44122,\"start\":44118}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":38667,\"start\":38277},{\"attributes\":{\"id\":\"fig_2\"},\"end\":38892,\"start\":38668},{\"attributes\":{\"id\":\"fig_4\"},\"end\":39033,\"start\":38893},{\"attributes\":{\"id\":\"fig_5\"},\"end\":39398,\"start\":39034},{\"attributes\":{\"id\":\"fig_7\"},\"end\":39637,\"start\":39399},{\"attributes\":{\"id\":\"fig_9\"},\"end\":39878,\"start\":39638},{\"attributes\":{\"id\":\"fig_10\"},\"end\":40077,\"start\":39879},{\"attributes\":{\"id\":\"fig_11\"},\"end\":40150,\"start\":40078},{\"attributes\":{\"id\":\"fig_12\"},\"end\":40411,\"start\":40151},{\"attributes\":{\"id\":\"fig_13\"},\"end\":40508,\"start\":40412},{\"attributes\":{\"id\":\"fig_15\"},\"end\":40597,\"start\":40509},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":41045,\"start\":40598},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":41251,\"start\":41046},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41444,\"start\":41252},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41959,\"start\":41445},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42334,\"start\":41960},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42762,\"start\":42335},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":43164,\"start\":42763},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":43544,\"start\":43165},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":43879,\"start\":43545}]", "paragraph": "[{\"end\":3855,\"start\":2268},{\"end\":4111,\"start\":3857},{\"end\":4827,\"start\":4113},{\"end\":4935,\"start\":4829},{\"end\":5671,\"start\":4937},{\"end\":5770,\"start\":5697},{\"end\":5821,\"start\":5772},{\"end\":6545,\"start\":5823},{\"end\":6650,\"start\":6547},{\"end\":7135,\"start\":6652},{\"end\":7440,\"start\":7137},{\"end\":8110,\"start\":7442},{\"end\":8258,\"start\":8126},{\"end\":8740,\"start\":8267},{\"end\":9063,\"start\":8742},{\"end\":10197,\"start\":9065},{\"end\":10503,\"start\":10221},{\"end\":10699,\"start\":10505},{\"end\":11047,\"start\":10701},{\"end\":11390,\"start\":11049},{\"end\":11579,\"start\":11392},{\"end\":11962,\"start\":11581},{\"end\":12188,\"start\":12036},{\"end\":12443,\"start\":12255},{\"end\":13342,\"start\":12445},{\"end\":13433,\"start\":13344},{\"end\":14913,\"start\":13435},{\"end\":15011,\"start\":14915},{\"end\":15854,\"start\":15013},{\"end\":16353,\"start\":15893},{\"end\":16384,\"start\":16355},{\"end\":16999,\"start\":16386},{\"end\":17134,\"start\":17035},{\"end\":17229,\"start\":17191},{\"end\":17455,\"start\":17270},{\"end\":17488,\"start\":17457},{\"end\":17623,\"start\":17490},{\"end\":17929,\"start\":17672},{\"end\":18142,\"start\":17955},{\"end\":18717,\"start\":18144},{\"end\":19097,\"start\":18719},{\"end\":19698,\"start\":19173},{\"end\":19978,\"start\":19700},{\"end\":20081,\"start\":19980},{\"end\":21681,\"start\":20083},{\"end\":22032,\"start\":21845},{\"end\":22231,\"start\":22034},{\"end\":22366,\"start\":22233},{\"end\":22803,\"start\":22436},{\"end\":23702,\"start\":22805},{\"end\":23976,\"start\":23742},{\"end\":24248,\"start\":23978},{\"end\":24758,\"start\":24250},{\"end\":24794,\"start\":24760},{\"end\":24816,\"start\":24796},{\"end\":24910,\"start\":24818},{\"end\":25148,\"start\":24912},{\"end\":25183,\"start\":25150},{\"end\":25262,\"start\":25185},{\"end\":25284,\"start\":25264},{\"end\":25391,\"start\":25286},{\"end\":25633,\"start\":25393},{\"end\":25710,\"start\":25657},{\"end\":25765,\"start\":25712},{\"end\":26100,\"start\":25767},{\"end\":26678,\"start\":26102},{\"end\":27349,\"start\":26693},{\"end\":27365,\"start\":27351},{\"end\":28204,\"start\":27400},{\"end\":29231,\"start\":28206},{\"end\":30987,\"start\":29255},{\"end\":31112,\"start\":31035},{\"end\":32406,\"start\":31114},{\"end\":32812,\"start\":32408},{\"end\":33054,\"start\":32843},{\"end\":33526,\"start\":33106},{\"end\":34051,\"start\":33586},{\"end\":34569,\"start\":34103},{\"end\":35558,\"start\":34620},{\"end\":35726,\"start\":35589},{\"end\":36800,\"start\":35793},{\"end\":37368,\"start\":36846},{\"end\":38276,\"start\":37407},{\"end\":38666,\"start\":38291},{\"end\":38891,\"start\":38682},{\"end\":39032,\"start\":38907},{\"end\":39397,\"start\":39048},{\"end\":39636,\"start\":39413},{\"end\":39877,\"start\":39652},{\"end\":40076,\"start\":39893},{\"end\":40149,\"start\":40092},{\"end\":40410,\"start\":40167},{\"end\":40507,\"start\":40428},{\"end\":40596,\"start\":40525},{\"end\":40786,\"start\":40601},{\"end\":41165,\"start\":41059},{\"end\":41443,\"start\":41298},{\"end\":41608,\"start\":41458},{\"end\":41958,\"start\":41915},{\"end\":42333,\"start\":41973},{\"end\":42466,\"start\":42348},{\"end\":42931,\"start\":42776},{\"end\":43320,\"start\":43178},{\"end\":43667,\"start\":43558}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17034,\"start\":17000},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17190,\"start\":17135},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17269,\"start\":17230},{\"attributes\":{\"id\":\"formula_3\"},\"end\":21820,\"start\":21705}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":8800,\"start\":8799},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":15213,\"start\":15212},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":15853,\"start\":15852},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":19478,\"start\":19477},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20386,\"start\":20385},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":22967,\"start\":22966},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":24157,\"start\":24156},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":26522,\"start\":26521},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":33989,\"start\":33988},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":34391,\"start\":34390},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":34676,\"start\":34675},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":35027,\"start\":35026},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":36148,\"start\":36147}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2266,\"start\":2254},{\"end\":5695,\"start\":5674},{\"attributes\":{\"n\":\"2\"},\"end\":8124,\"start\":8113},{\"attributes\":{\"n\":\"2.1\"},\"end\":8265,\"start\":8261},{\"attributes\":{\"n\":\"2.2\"},\"end\":10219,\"start\":10200},{\"attributes\":{\"n\":\"3\"},\"end\":12034,\"start\":11965},{\"attributes\":{\"n\":\"3.1\"},\"end\":12253,\"start\":12191},{\"attributes\":{\"n\":\"3.2\"},\"end\":15891,\"start\":15857},{\"attributes\":{\"n\":\"4\"},\"end\":17670,\"start\":17626},{\"attributes\":{\"n\":\"4.1\"},\"end\":17953,\"start\":17932},{\"attributes\":{\"n\":\"4.2\"},\"end\":19171,\"start\":19100},{\"attributes\":{\"n\":\"4.3\"},\"end\":21704,\"start\":21684},{\"attributes\":{\"n\":\"5.1\"},\"end\":21843,\"start\":21822},{\"attributes\":{\"n\":\"5.2\"},\"end\":22434,\"start\":22369},{\"attributes\":{\"n\":\"6\"},\"end\":23740,\"start\":23705},{\"end\":25655,\"start\":25636},{\"attributes\":{\"n\":\"7\"},\"end\":26691,\"start\":26681},{\"end\":27398,\"start\":27368},{\"end\":29253,\"start\":29234},{\"end\":31033,\"start\":30990},{\"end\":32841,\"start\":32815},{\"end\":33104,\"start\":33057},{\"end\":33584,\"start\":33529},{\"end\":34101,\"start\":34054},{\"end\":34618,\"start\":34572},{\"end\":35587,\"start\":35561},{\"end\":35791,\"start\":35729},{\"end\":36844,\"start\":36803},{\"end\":37405,\"start\":37371},{\"end\":38288,\"start\":38278},{\"end\":38679,\"start\":38669},{\"end\":38904,\"start\":38894},{\"end\":39045,\"start\":39035},{\"end\":39410,\"start\":39400},{\"end\":39649,\"start\":39639},{\"end\":39890,\"start\":39880},{\"end\":40089,\"start\":40079},{\"end\":40163,\"start\":40152},{\"end\":40424,\"start\":40413},{\"end\":40521,\"start\":40510},{\"end\":41056,\"start\":41047},{\"end\":41262,\"start\":41253},{\"end\":41455,\"start\":41446},{\"end\":41970,\"start\":41961},{\"end\":42345,\"start\":42336},{\"end\":42773,\"start\":42764},{\"end\":43175,\"start\":43166},{\"end\":43555,\"start\":43546}]", "table": "[{\"end\":41045,\"start\":40787},{\"end\":41251,\"start\":41166},{\"end\":41297,\"start\":41264},{\"end\":41914,\"start\":41609},{\"end\":42762,\"start\":42467},{\"end\":43164,\"start\":42932},{\"end\":43544,\"start\":43321},{\"end\":43879,\"start\":43668}]", "figure_caption": "[{\"end\":38667,\"start\":38290},{\"end\":38892,\"start\":38681},{\"end\":39033,\"start\":38906},{\"end\":39398,\"start\":39047},{\"end\":39637,\"start\":39412},{\"end\":39878,\"start\":39651},{\"end\":40077,\"start\":39892},{\"end\":40150,\"start\":40091},{\"end\":40411,\"start\":40166},{\"end\":40508,\"start\":40427},{\"end\":40597,\"start\":40524},{\"end\":40787,\"start\":40600},{\"end\":41166,\"start\":41058},{\"end\":41609,\"start\":41457},{\"end\":42334,\"start\":41972},{\"end\":42467,\"start\":42347},{\"end\":42932,\"start\":42775},{\"end\":43321,\"start\":43177},{\"end\":43668,\"start\":43557}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2736,\"start\":2732},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4110,\"start\":4106},{\"end\":7384,\"start\":7383},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8304,\"start\":8303},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":12666,\"start\":12665},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":13659,\"start\":13658},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13774,\"start\":13773},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":13799,\"start\":13798},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":16045,\"start\":16044},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":19205,\"start\":19204},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":19754,\"start\":19753},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":20530,\"start\":20529},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":21145,\"start\":21144},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":22664,\"start\":22663},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":23183,\"start\":23182},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":24597,\"start\":24596},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":31315,\"start\":31313},{\"attributes\":{\"ref_id\":\"fig_13\"},\"end\":31766,\"start\":31764},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":33042,\"start\":33041},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":33053,\"start\":33051},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":33525,\"start\":33523},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":34122,\"start\":34120},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":35714,\"start\":35713},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":35725,\"start\":35723},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":36913,\"start\":36911},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":38191,\"start\":38189}]", "bib_author_first_name": "[{\"end\":47058,\"start\":47053},{\"end\":47073,\"start\":47068},{\"end\":47086,\"start\":47081},{\"end\":47099,\"start\":47093},{\"end\":47113,\"start\":47106},{\"end\":47124,\"start\":47120},{\"end\":47139,\"start\":47134},{\"end\":47151,\"start\":47147},{\"end\":47166,\"start\":47160},{\"end\":47177,\"start\":47172},{\"end\":47393,\"start\":47380},{\"end\":47407,\"start\":47403},{\"end\":47424,\"start\":47417},{\"end\":47437,\"start\":47430},{\"end\":47449,\"start\":47445},{\"end\":47460,\"start\":47456},{\"end\":47474,\"start\":47469},{\"end\":47487,\"start\":47481},{\"end\":47505,\"start\":47496},{\"end\":47523,\"start\":47516},{\"end\":47654,\"start\":47649},{\"end\":47671,\"start\":47665},{\"end\":47686,\"start\":47682},{\"end\":47703,\"start\":47696},{\"end\":47888,\"start\":47879},{\"end\":47905,\"start\":47896},{\"end\":47921,\"start\":47915},{\"end\":47934,\"start\":47926},{\"end\":47950,\"start\":47945},{\"end\":47966,\"start\":47958},{\"end\":47980,\"start\":47976},{\"end\":48213,\"start\":48207},{\"end\":48223,\"start\":48219},{\"end\":48236,\"start\":48231},{\"end\":48252,\"start\":48246},{\"end\":48265,\"start\":48261},{\"end\":48276,\"start\":48272},{\"end\":48291,\"start\":48287},{\"end\":48308,\"start\":48299},{\"end\":48319,\"start\":48315},{\"end\":48332,\"start\":48329},{\"end\":48453,\"start\":48449},{\"end\":48466,\"start\":48461},{\"end\":48477,\"start\":48471},{\"end\":48479,\"start\":48478},{\"end\":48492,\"start\":48487},{\"end\":48601,\"start\":48598},{\"end\":48617,\"start\":48609},{\"end\":48628,\"start\":48624},{\"end\":48643,\"start\":48636},{\"end\":48658,\"start\":48653},{\"end\":48660,\"start\":48659},{\"end\":48677,\"start\":48669},{\"end\":48694,\"start\":48688},{\"end\":48714,\"start\":48708},{\"end\":48728,\"start\":48722},{\"end\":48743,\"start\":48737},{\"end\":48820,\"start\":48811},{\"end\":48834,\"start\":48829},{\"end\":48856,\"start\":48851},{\"end\":48872,\"start\":48864},{\"end\":48885,\"start\":48881},{\"end\":48898,\"start\":48895},{\"end\":48911,\"start\":48906},{\"end\":48920,\"start\":48917},{\"end\":48937,\"start\":48930},{\"end\":48947,\"start\":48942},{\"end\":49129,\"start\":49121},{\"end\":49142,\"start\":49136},{\"end\":49154,\"start\":49147},{\"end\":49164,\"start\":49159},{\"end\":49167,\"start\":49165},{\"end\":49181,\"start\":49175},{\"end\":49192,\"start\":49189},{\"end\":49200,\"start\":49198},{\"end\":49216,\"start\":49208},{\"end\":49423,\"start\":49416},{\"end\":49439,\"start\":49432},{\"end\":49446,\"start\":49444},{\"end\":49456,\"start\":49452},{\"end\":49472,\"start\":49464},{\"end\":49480,\"start\":49477},{\"end\":49495,\"start\":49488},{\"end\":49509,\"start\":49503},{\"end\":49525,\"start\":49518},{\"end\":49540,\"start\":49534},{\"end\":49542,\"start\":49541},{\"end\":49556,\"start\":49553},{\"end\":49569,\"start\":49565},{\"end\":49571,\"start\":49570},{\"end\":49599,\"start\":49590},{\"end\":49617,\"start\":49611},{\"end\":49631,\"start\":49626},{\"end\":49647,\"start\":49640},{\"end\":49661,\"start\":49655},{\"end\":49674,\"start\":49670},{\"end\":49688,\"start\":49684},{\"end\":49702,\"start\":49697},{\"end\":49706,\"start\":49703},{\"end\":49721,\"start\":49714},{\"end\":49739,\"start\":49730},{\"end\":49879,\"start\":49874},{\"end\":49893,\"start\":49891},{\"end\":49905,\"start\":49899},{\"end\":49921,\"start\":49915},{\"end\":49930,\"start\":49928},{\"end\":49943,\"start\":49936},{\"end\":49955,\"start\":49951},{\"end\":49966,\"start\":49960},{\"end\":49980,\"start\":49973},{\"end\":50001,\"start\":49991},{\"end\":50140,\"start\":50132},{\"end\":50152,\"start\":50146},{\"end\":50163,\"start\":50157},{\"end\":50175,\"start\":50168},{\"end\":50186,\"start\":50182},{\"end\":50199,\"start\":50194},{\"end\":50214,\"start\":50206},{\"end\":50227,\"start\":50221},{\"end\":50239,\"start\":50232},{\"end\":50252,\"start\":50246},{\"end\":50343,\"start\":50336},{\"end\":50356,\"start\":50350},{\"end\":50373,\"start\":50363},{\"end\":50386,\"start\":50381},{\"end\":50396,\"start\":50393},{\"end\":50409,\"start\":50402},{\"end\":50419,\"start\":50415},{\"end\":50430,\"start\":50426},{\"end\":50432,\"start\":50431},{\"end\":50446,\"start\":50439},{\"end\":50569,\"start\":50563},{\"end\":50588,\"start\":50583},{\"end\":50605,\"start\":50596},{\"end\":50622,\"start\":50618},{\"end\":50643,\"start\":50636},{\"end\":50656,\"start\":50650},{\"end\":50677,\"start\":50670},{\"end\":50696,\"start\":50688},{\"end\":50712,\"start\":50707},{\"end\":50729,\"start\":50722},{\"end\":50778,\"start\":50773},{\"end\":50790,\"start\":50787},{\"end\":50797,\"start\":50796},{\"end\":50799,\"start\":50798},{\"end\":50812,\"start\":50807},{\"end\":50831,\"start\":50822},{\"end\":50844,\"start\":50839},{\"end\":50862,\"start\":50856},{\"end\":50879,\"start\":50871},{\"end\":50891,\"start\":50887},{\"end\":50907,\"start\":50901},{\"end\":51006,\"start\":51002},{\"end\":51019,\"start\":51012},{\"end\":51031,\"start\":51025},{\"end\":51043,\"start\":51039},{\"end\":51055,\"start\":51049},{\"end\":51067,\"start\":51062},{\"end\":51077,\"start\":51074},{\"end\":51088,\"start\":51085},{\"end\":51100,\"start\":51093},{\"end\":51112,\"start\":51105},{\"end\":51127,\"start\":51118},{\"end\":51134,\"start\":51132},{\"end\":51295,\"start\":51289},{\"end\":51315,\"start\":51306},{\"end\":51332,\"start\":51326},{\"end\":51346,\"start\":51341},{\"end\":51366,\"start\":51360},{\"end\":51377,\"start\":51372},{\"end\":51395,\"start\":51390},{\"end\":51408,\"start\":51404},{\"end\":51413,\"start\":51409},{\"end\":51429,\"start\":51421},{\"end\":51446,\"start\":51441},{\"end\":51576,\"start\":51569},{\"end\":51586,\"start\":51584},{\"end\":51599,\"start\":51593},{\"end\":51610,\"start\":51606},{\"end\":51623,\"start\":51616},{\"end\":51640,\"start\":51633},{\"end\":51653,\"start\":51645},{\"end\":51661,\"start\":51658},{\"end\":51672,\"start\":51667},{\"end\":51693,\"start\":51688},{\"end\":51825,\"start\":51824},{\"end\":51843,\"start\":51832},{\"end\":51845,\"start\":51844},{\"end\":52080,\"start\":52074},{\"end\":52094,\"start\":52089},{\"end\":52107,\"start\":52103},{\"end\":52120,\"start\":52115},{\"end\":52136,\"start\":52130},{\"end\":52152,\"start\":52148},{\"end\":52248,\"start\":52241},{\"end\":52260,\"start\":52254},{\"end\":52275,\"start\":52267},{\"end\":52288,\"start\":52282},{\"end\":52302,\"start\":52297},{\"end\":52320,\"start\":52313},{\"end\":52339,\"start\":52332},{\"end\":52561,\"start\":52555},{\"end\":52574,\"start\":52569},{\"end\":52594,\"start\":52588},{\"end\":52608,\"start\":52602},{\"end\":52618,\"start\":52613},{\"end\":52725,\"start\":52720},{\"end\":52738,\"start\":52734},{\"end\":52752,\"start\":52748},{\"end\":52866,\"start\":52861},{\"end\":52881,\"start\":52875},{\"end\":52899,\"start\":52893},{\"end\":52913,\"start\":52909},{\"end\":53025,\"start\":53023},{\"end\":53037,\"start\":53030},{\"end\":53052,\"start\":53045},{\"end\":53066,\"start\":53059},{\"end\":53081,\"start\":53073},{\"end\":53093,\"start\":53088},{\"end\":53143,\"start\":53135},{\"end\":53155,\"start\":53148},{\"end\":53166,\"start\":53161},{\"end\":53177,\"start\":53171},{\"end\":53190,\"start\":53183},{\"end\":53201,\"start\":53198},{\"end\":53213,\"start\":53206},{\"end\":53229,\"start\":53221},{\"end\":53479,\"start\":53473},{\"end\":53495,\"start\":53484},{\"end\":53515,\"start\":53507},{\"end\":53531,\"start\":53525},{\"end\":53545,\"start\":53538},{\"end\":53559,\"start\":53553},{\"end\":53569,\"start\":53565},{\"end\":53746,\"start\":53740},{\"end\":53757,\"start\":53751},{\"end\":53769,\"start\":53762},{\"end\":53783,\"start\":53777},{\"end\":53954,\"start\":53948},{\"end\":53965,\"start\":53959},{\"end\":53976,\"start\":53970},{\"end\":53993,\"start\":53987},{\"end\":54109,\"start\":54102},{\"end\":54122,\"start\":54114},{\"end\":54135,\"start\":54128},{\"end\":54147,\"start\":54141},{\"end\":54157,\"start\":54154},{\"end\":54168,\"start\":54165},{\"end\":54180,\"start\":54176},{\"end\":54195,\"start\":54187},{\"end\":54340,\"start\":54333},{\"end\":54353,\"start\":54345},{\"end\":54365,\"start\":54359},{\"end\":54379,\"start\":54372},{\"end\":54392,\"start\":54385},{\"end\":54400,\"start\":54397},{\"end\":54412,\"start\":54408},{\"end\":54427,\"start\":54419},{\"end\":54576,\"start\":54570},{\"end\":54589,\"start\":54583},{\"end\":54602,\"start\":54596},{\"end\":54616,\"start\":54609},{\"end\":54787,\"start\":54779},{\"end\":54800,\"start\":54793},{\"end\":54813,\"start\":54808},{\"end\":54829,\"start\":54824},{\"end\":54842,\"start\":54836},{\"end\":54855,\"start\":54851},{\"end\":54870,\"start\":54865},{\"end\":54887,\"start\":54879},{\"end\":55034,\"start\":55027},{\"end\":55048,\"start\":55040},{\"end\":55061,\"start\":55053},{\"end\":55070,\"start\":55066},{\"end\":55074,\"start\":55071},{\"end\":55217,\"start\":55211},{\"end\":55227,\"start\":55222},{\"end\":55239,\"start\":55235},{\"end\":55254,\"start\":55248},{\"end\":55402,\"start\":55395},{\"end\":55419,\"start\":55411},{\"end\":55434,\"start\":55431},{\"end\":55451,\"start\":55444},{\"end\":55688,\"start\":55683},{\"end\":55701,\"start\":55697},{\"end\":55719,\"start\":55711},{\"end\":55733,\"start\":55729},{\"end\":55752,\"start\":55745},{\"end\":55765,\"start\":55759},{\"end\":55779,\"start\":55776},{\"end\":55796,\"start\":55788},{\"end\":55808,\"start\":55804},{\"end\":55838,\"start\":55830},{\"end\":55886,\"start\":55883},{\"end\":55899,\"start\":55895},{\"end\":55911,\"start\":55907},{\"end\":55913,\"start\":55912},{\"end\":56075,\"start\":56068},{\"end\":56091,\"start\":56085},{\"end\":56108,\"start\":56102},{\"end\":56247,\"start\":56243},{\"end\":56263,\"start\":56256},{\"end\":56270,\"start\":56268},{\"end\":56283,\"start\":56278},{\"end\":56300,\"start\":56293},{\"end\":56319,\"start\":56313},{\"end\":56334,\"start\":56329},{\"end\":56350,\"start\":56342},{\"end\":56368,\"start\":56360},{\"end\":56380,\"start\":56376},{\"end\":56502,\"start\":56498},{\"end\":56519,\"start\":56512},{\"end\":56529,\"start\":56524},{\"end\":56542,\"start\":56537},{\"end\":56554,\"start\":56549},{\"end\":56567,\"start\":56563},{\"end\":56676,\"start\":56672},{\"end\":56690,\"start\":56686},{\"end\":56695,\"start\":56691},{\"end\":56706,\"start\":56701},{\"end\":56722,\"start\":56716},{\"end\":56738,\"start\":56731},{\"end\":56752,\"start\":56744},{\"end\":56768,\"start\":56762},{\"end\":56783,\"start\":56777},{\"end\":56798,\"start\":56792},{\"end\":56812,\"start\":56808},{\"end\":56964,\"start\":56959},{\"end\":56977,\"start\":56973},{\"end\":56991,\"start\":56987},{\"end\":57010,\"start\":57001},{\"end\":57022,\"start\":57016},{\"end\":57038,\"start\":57031},{\"end\":57052,\"start\":57047},{\"end\":57062,\"start\":57059},{\"end\":57072,\"start\":57067},{\"end\":57074,\"start\":57073},{\"end\":57173,\"start\":57167},{\"end\":57189,\"start\":57182},{\"end\":57205,\"start\":57198},{\"end\":57216,\"start\":57211},{\"end\":57230,\"start\":57223},{\"end\":57241,\"start\":57237},{\"end\":57255,\"start\":57251},{\"end\":57266,\"start\":57262},{\"end\":57406,\"start\":57400},{\"end\":57423,\"start\":57415},{\"end\":57438,\"start\":57434},{\"end\":57452,\"start\":57447},{\"end\":57462,\"start\":57458},{\"end\":57592,\"start\":57585},{\"end\":57611,\"start\":57607},{\"end\":57620,\"start\":57616},{\"end\":57781,\"start\":57774},{\"end\":57798,\"start\":57791},{\"end\":57812,\"start\":57805},{\"end\":57825,\"start\":57821},{\"end\":57833,\"start\":57830},{\"end\":57846,\"start\":57841},{\"end\":57848,\"start\":57847},{\"end\":57863,\"start\":57857},{\"end\":57884,\"start\":57877},{\"end\":57892,\"start\":57885},{\"end\":57905,\"start\":57900},{\"end\":57923,\"start\":57920},{\"end\":58035,\"start\":58034},{\"end\":58037,\"start\":58036},{\"end\":58051,\"start\":58045},{\"end\":58069,\"start\":58061},{\"end\":58097,\"start\":58092},{\"end\":58126,\"start\":58121},{\"end\":58144,\"start\":58136},{\"end\":58146,\"start\":58145},{\"end\":58159,\"start\":58154},{\"end\":58174,\"start\":58168},{\"end\":58253,\"start\":58247},{\"end\":58264,\"start\":58258},{\"end\":58273,\"start\":58270},{\"end\":58282,\"start\":58279},{\"end\":58292,\"start\":58287},{\"end\":58301,\"start\":58297},{\"end\":58313,\"start\":58307},{\"end\":58499,\"start\":58492},{\"end\":58511,\"start\":58504},{\"end\":58523,\"start\":58518},{\"end\":58536,\"start\":58529},{\"end\":58549,\"start\":58543},{\"end\":58562,\"start\":58555},{\"end\":58575,\"start\":58569},{\"end\":58588,\"start\":58581},{\"end\":58598,\"start\":58594},{\"end\":58609,\"start\":58603},{\"end\":58766,\"start\":58762},{\"end\":58777,\"start\":58772},{\"end\":58790,\"start\":58784},{\"end\":58802,\"start\":58795},{\"end\":58812,\"start\":58809},{\"end\":58973,\"start\":58966},{\"end\":58995,\"start\":58988},{\"end\":59010,\"start\":59004},{\"end\":59030,\"start\":59020},{\"end\":59049,\"start\":59041},{\"end\":59067,\"start\":59059},{\"end\":59082,\"start\":59077},{\"end\":59096,\"start\":59092},{\"end\":59110,\"start\":59104},{\"end\":59225,\"start\":59220},{\"end\":59245,\"start\":59240},{\"end\":59247,\"start\":59246},{\"end\":59262,\"start\":59256},{\"end\":59274,\"start\":59269},{\"end\":59288,\"start\":59283},{\"end\":59427,\"start\":59416},{\"end\":59446,\"start\":59438},{\"end\":59460,\"start\":59456},{\"end\":59710,\"start\":59704},{\"end\":59723,\"start\":59717},{\"end\":59731,\"start\":59729},{\"end\":59743,\"start\":59738},{\"end\":59760,\"start\":59752},{\"end\":59772,\"start\":59767},{\"end\":59783,\"start\":59778},{\"end\":59799,\"start\":59794},{\"end\":59822,\"start\":59815},{\"end\":59840,\"start\":59832},{\"end\":59887,\"start\":59882},{\"end\":59895,\"start\":59893},{\"end\":59906,\"start\":59901},{\"end\":59923,\"start\":59918},{\"end\":59938,\"start\":59932},{\"end\":59954,\"start\":59945},{\"end\":59969,\"start\":59965},{\"end\":59987,\"start\":59980},{\"end\":60000,\"start\":59995},{\"end\":60013,\"start\":60007},{\"end\":60180,\"start\":60175},{\"end\":60192,\"start\":60186},{\"end\":60203,\"start\":60199},{\"end\":60223,\"start\":60216},{\"end\":60233,\"start\":60231},{\"end\":60243,\"start\":60239},{\"end\":60253,\"start\":60248},{\"end\":60303,\"start\":60296},{\"end\":60315,\"start\":60308},{\"end\":60326,\"start\":60320},{\"end\":60336,\"start\":60331},{\"end\":60345,\"start\":60341},{\"end\":60357,\"start\":60351},{\"end\":60371,\"start\":60364},{\"end\":60383,\"start\":60378},{\"end\":60397,\"start\":60388},{\"end\":60407,\"start\":60403},{\"end\":60419,\"start\":60413},{\"end\":60436,\"start\":60427},{\"end\":60449,\"start\":60441},{\"end\":60460,\"start\":60454},{\"end\":60474,\"start\":60467},{\"end\":60485,\"start\":60481},{\"end\":60492,\"start\":60490},{\"end\":60503,\"start\":60500},{\"end\":60650,\"start\":60645},{\"end\":60665,\"start\":60658},{\"end\":60679,\"start\":60674},{\"end\":60692,\"start\":60687},{\"end\":60706,\"start\":60702},{\"end\":60720,\"start\":60713},{\"end\":60738,\"start\":60727},{\"end\":60750,\"start\":60746},{\"end\":60761,\"start\":60757},{\"end\":60768,\"start\":60766},{\"end\":60873,\"start\":60866},{\"end\":60888,\"start\":60880},{\"end\":60899,\"start\":60895},{\"end\":60906,\"start\":60900},{\"end\":60917,\"start\":60912},{\"end\":61068,\"start\":61063},{\"end\":61077,\"start\":61074},{\"end\":61092,\"start\":61084},{\"end\":61104,\"start\":61099},{\"end\":61116,\"start\":61109}]", "bib_author_last_name": "[{\"end\":47066,\"start\":47059},{\"end\":47079,\"start\":47074},{\"end\":47091,\"start\":47087},{\"end\":47104,\"start\":47100},{\"end\":47118,\"start\":47114},{\"end\":47132,\"start\":47125},{\"end\":47145,\"start\":47140},{\"end\":47158,\"start\":47152},{\"end\":47170,\"start\":47167},{\"end\":47186,\"start\":47178},{\"end\":47401,\"start\":47394},{\"end\":47415,\"start\":47408},{\"end\":47428,\"start\":47425},{\"end\":47443,\"start\":47438},{\"end\":47454,\"start\":47450},{\"end\":47467,\"start\":47461},{\"end\":47479,\"start\":47475},{\"end\":47494,\"start\":47488},{\"end\":47514,\"start\":47506},{\"end\":47532,\"start\":47524},{\"end\":47663,\"start\":47655},{\"end\":47680,\"start\":47672},{\"end\":47694,\"start\":47687},{\"end\":47709,\"start\":47704},{\"end\":47894,\"start\":47889},{\"end\":47913,\"start\":47906},{\"end\":47924,\"start\":47922},{\"end\":47943,\"start\":47935},{\"end\":47956,\"start\":47951},{\"end\":47974,\"start\":47967},{\"end\":47987,\"start\":47981},{\"end\":48217,\"start\":48214},{\"end\":48229,\"start\":48224},{\"end\":48244,\"start\":48237},{\"end\":48259,\"start\":48253},{\"end\":48270,\"start\":48266},{\"end\":48285,\"start\":48277},{\"end\":48297,\"start\":48292},{\"end\":48313,\"start\":48309},{\"end\":48327,\"start\":48320},{\"end\":48341,\"start\":48333},{\"end\":48459,\"start\":48454},{\"end\":48469,\"start\":48467},{\"end\":48485,\"start\":48480},{\"end\":48501,\"start\":48493},{\"end\":48607,\"start\":48602},{\"end\":48622,\"start\":48618},{\"end\":48634,\"start\":48629},{\"end\":48651,\"start\":48644},{\"end\":48667,\"start\":48661},{\"end\":48686,\"start\":48678},{\"end\":48706,\"start\":48695},{\"end\":48720,\"start\":48715},{\"end\":48735,\"start\":48729},{\"end\":48750,\"start\":48744},{\"end\":48827,\"start\":48821},{\"end\":48849,\"start\":48835},{\"end\":48862,\"start\":48857},{\"end\":48879,\"start\":48873},{\"end\":48893,\"start\":48886},{\"end\":48904,\"start\":48899},{\"end\":48915,\"start\":48912},{\"end\":48928,\"start\":48921},{\"end\":48940,\"start\":48938},{\"end\":48956,\"start\":48948},{\"end\":49134,\"start\":49130},{\"end\":49145,\"start\":49143},{\"end\":49157,\"start\":49155},{\"end\":49173,\"start\":49168},{\"end\":49187,\"start\":49182},{\"end\":49196,\"start\":49193},{\"end\":49206,\"start\":49201},{\"end\":49220,\"start\":49217},{\"end\":49430,\"start\":49424},{\"end\":49442,\"start\":49440},{\"end\":49450,\"start\":49447},{\"end\":49462,\"start\":49457},{\"end\":49475,\"start\":49473},{\"end\":49486,\"start\":49481},{\"end\":49501,\"start\":49496},{\"end\":49516,\"start\":49510},{\"end\":49532,\"start\":49526},{\"end\":49551,\"start\":49543},{\"end\":49563,\"start\":49557},{\"end\":49576,\"start\":49572},{\"end\":49609,\"start\":49600},{\"end\":49624,\"start\":49618},{\"end\":49638,\"start\":49632},{\"end\":49653,\"start\":49648},{\"end\":49668,\"start\":49662},{\"end\":49682,\"start\":49675},{\"end\":49695,\"start\":49689},{\"end\":49712,\"start\":49707},{\"end\":49728,\"start\":49722},{\"end\":49748,\"start\":49740},{\"end\":49889,\"start\":49880},{\"end\":49897,\"start\":49894},{\"end\":49913,\"start\":49906},{\"end\":49926,\"start\":49922},{\"end\":49934,\"start\":49931},{\"end\":49949,\"start\":49944},{\"end\":49958,\"start\":49956},{\"end\":49971,\"start\":49967},{\"end\":49989,\"start\":49981},{\"end\":50008,\"start\":50002},{\"end\":50144,\"start\":50141},{\"end\":50155,\"start\":50153},{\"end\":50166,\"start\":50164},{\"end\":50180,\"start\":50176},{\"end\":50192,\"start\":50187},{\"end\":50204,\"start\":50200},{\"end\":50219,\"start\":50215},{\"end\":50230,\"start\":50228},{\"end\":50244,\"start\":50240},{\"end\":50256,\"start\":50253},{\"end\":50348,\"start\":50344},{\"end\":50361,\"start\":50357},{\"end\":50379,\"start\":50374},{\"end\":50391,\"start\":50387},{\"end\":50400,\"start\":50397},{\"end\":50413,\"start\":50410},{\"end\":50424,\"start\":50420},{\"end\":50437,\"start\":50433},{\"end\":50449,\"start\":50447},{\"end\":50581,\"start\":50570},{\"end\":50594,\"start\":50589},{\"end\":50616,\"start\":50606},{\"end\":50634,\"start\":50623},{\"end\":50648,\"start\":50644},{\"end\":50668,\"start\":50657},{\"end\":50686,\"start\":50678},{\"end\":50705,\"start\":50697},{\"end\":50720,\"start\":50713},{\"end\":50735,\"start\":50730},{\"end\":50785,\"start\":50779},{\"end\":50794,\"start\":50791},{\"end\":50805,\"start\":50800},{\"end\":50820,\"start\":50813},{\"end\":50837,\"start\":50832},{\"end\":50854,\"start\":50845},{\"end\":50869,\"start\":50863},{\"end\":50885,\"start\":50880},{\"end\":50899,\"start\":50892},{\"end\":50913,\"start\":50908},{\"end\":50917,\"start\":50915},{\"end\":51010,\"start\":51007},{\"end\":51023,\"start\":51020},{\"end\":51037,\"start\":51032},{\"end\":51047,\"start\":51044},{\"end\":51060,\"start\":51056},{\"end\":51072,\"start\":51068},{\"end\":51083,\"start\":51078},{\"end\":51091,\"start\":51089},{\"end\":51103,\"start\":51101},{\"end\":51116,\"start\":51113},{\"end\":51130,\"start\":51128},{\"end\":51139,\"start\":51135},{\"end\":51304,\"start\":51296},{\"end\":51324,\"start\":51316},{\"end\":51339,\"start\":51333},{\"end\":51358,\"start\":51347},{\"end\":51370,\"start\":51367},{\"end\":51388,\"start\":51378},{\"end\":51402,\"start\":51396},{\"end\":51419,\"start\":51414},{\"end\":51439,\"start\":51430},{\"end\":51452,\"start\":51447},{\"end\":51459,\"start\":51454},{\"end\":51582,\"start\":51577},{\"end\":51591,\"start\":51587},{\"end\":51604,\"start\":51600},{\"end\":51614,\"start\":51611},{\"end\":51631,\"start\":51624},{\"end\":51643,\"start\":51641},{\"end\":51656,\"start\":51654},{\"end\":51665,\"start\":51662},{\"end\":51686,\"start\":51673},{\"end\":51697,\"start\":51694},{\"end\":51830,\"start\":51826},{\"end\":51852,\"start\":51846},{\"end\":51861,\"start\":51854},{\"end\":52087,\"start\":52081},{\"end\":52101,\"start\":52095},{\"end\":52113,\"start\":52108},{\"end\":52128,\"start\":52121},{\"end\":52146,\"start\":52137},{\"end\":52161,\"start\":52153},{\"end\":52252,\"start\":52249},{\"end\":52265,\"start\":52261},{\"end\":52280,\"start\":52276},{\"end\":52295,\"start\":52289},{\"end\":52311,\"start\":52303},{\"end\":52330,\"start\":52321},{\"end\":52343,\"start\":52340},{\"end\":52567,\"start\":52562},{\"end\":52586,\"start\":52575},{\"end\":52600,\"start\":52595},{\"end\":52611,\"start\":52609},{\"end\":52624,\"start\":52619},{\"end\":52732,\"start\":52726},{\"end\":52746,\"start\":52739},{\"end\":52761,\"start\":52753},{\"end\":52873,\"start\":52867},{\"end\":52891,\"start\":52882},{\"end\":52907,\"start\":52900},{\"end\":52922,\"start\":52914},{\"end\":53028,\"start\":53026},{\"end\":53043,\"start\":53038},{\"end\":53057,\"start\":53053},{\"end\":53071,\"start\":53067},{\"end\":53086,\"start\":53082},{\"end\":53097,\"start\":53094},{\"end\":53146,\"start\":53144},{\"end\":53159,\"start\":53156},{\"end\":53169,\"start\":53167},{\"end\":53181,\"start\":53178},{\"end\":53196,\"start\":53191},{\"end\":53204,\"start\":53202},{\"end\":53219,\"start\":53214},{\"end\":53234,\"start\":53230},{\"end\":53482,\"start\":53480},{\"end\":53505,\"start\":53496},{\"end\":53523,\"start\":53516},{\"end\":53536,\"start\":53532},{\"end\":53551,\"start\":53546},{\"end\":53563,\"start\":53560},{\"end\":53573,\"start\":53570},{\"end\":53749,\"start\":53747},{\"end\":53760,\"start\":53758},{\"end\":53775,\"start\":53770},{\"end\":53787,\"start\":53784},{\"end\":53957,\"start\":53955},{\"end\":53968,\"start\":53966},{\"end\":53985,\"start\":53977},{\"end\":53997,\"start\":53994},{\"end\":54112,\"start\":54110},{\"end\":54126,\"start\":54123},{\"end\":54139,\"start\":54136},{\"end\":54152,\"start\":54148},{\"end\":54163,\"start\":54158},{\"end\":54174,\"start\":54169},{\"end\":54185,\"start\":54181},{\"end\":54201,\"start\":54196},{\"end\":54343,\"start\":54341},{\"end\":54357,\"start\":54354},{\"end\":54370,\"start\":54366},{\"end\":54383,\"start\":54380},{\"end\":54395,\"start\":54393},{\"end\":54406,\"start\":54401},{\"end\":54417,\"start\":54413},{\"end\":54433,\"start\":54428},{\"end\":54581,\"start\":54577},{\"end\":54594,\"start\":54590},{\"end\":54607,\"start\":54603},{\"end\":54621,\"start\":54617},{\"end\":54791,\"start\":54788},{\"end\":54806,\"start\":54801},{\"end\":54822,\"start\":54814},{\"end\":54834,\"start\":54830},{\"end\":54849,\"start\":54843},{\"end\":54863,\"start\":54856},{\"end\":54877,\"start\":54871},{\"end\":54895,\"start\":54888},{\"end\":55038,\"start\":55035},{\"end\":55051,\"start\":55049},{\"end\":55064,\"start\":55062},{\"end\":55078,\"start\":55075},{\"end\":55220,\"start\":55218},{\"end\":55233,\"start\":55228},{\"end\":55246,\"start\":55240},{\"end\":55258,\"start\":55255},{\"end\":55409,\"start\":55403},{\"end\":55429,\"start\":55420},{\"end\":55442,\"start\":55435},{\"end\":55460,\"start\":55452},{\"end\":55695,\"start\":55689},{\"end\":55709,\"start\":55702},{\"end\":55727,\"start\":55720},{\"end\":55743,\"start\":55734},{\"end\":55757,\"start\":55753},{\"end\":55774,\"start\":55766},{\"end\":55786,\"start\":55780},{\"end\":55802,\"start\":55797},{\"end\":55828,\"start\":55809},{\"end\":55845,\"start\":55839},{\"end\":55893,\"start\":55887},{\"end\":55905,\"start\":55900},{\"end\":55921,\"start\":55914},{\"end\":55930,\"start\":55923},{\"end\":56083,\"start\":56076},{\"end\":56100,\"start\":56092},{\"end\":56113,\"start\":56109},{\"end\":56254,\"start\":56248},{\"end\":56266,\"start\":56264},{\"end\":56276,\"start\":56271},{\"end\":56291,\"start\":56284},{\"end\":56311,\"start\":56301},{\"end\":56327,\"start\":56320},{\"end\":56340,\"start\":56335},{\"end\":56358,\"start\":56351},{\"end\":56374,\"start\":56369},{\"end\":56384,\"start\":56381},{\"end\":56510,\"start\":56503},{\"end\":56522,\"start\":56520},{\"end\":56535,\"start\":56530},{\"end\":56547,\"start\":56543},{\"end\":56561,\"start\":56555},{\"end\":56577,\"start\":56568},{\"end\":56684,\"start\":56677},{\"end\":56699,\"start\":56696},{\"end\":56714,\"start\":56707},{\"end\":56729,\"start\":56723},{\"end\":56742,\"start\":56739},{\"end\":56760,\"start\":56753},{\"end\":56775,\"start\":56769},{\"end\":56790,\"start\":56784},{\"end\":56806,\"start\":56799},{\"end\":56818,\"start\":56813},{\"end\":56971,\"start\":56965},{\"end\":56985,\"start\":56978},{\"end\":56999,\"start\":56992},{\"end\":57014,\"start\":57011},{\"end\":57029,\"start\":57023},{\"end\":57045,\"start\":57039},{\"end\":57057,\"start\":57053},{\"end\":57065,\"start\":57063},{\"end\":57078,\"start\":57075},{\"end\":57180,\"start\":57174},{\"end\":57196,\"start\":57190},{\"end\":57209,\"start\":57206},{\"end\":57221,\"start\":57217},{\"end\":57235,\"start\":57231},{\"end\":57249,\"start\":57242},{\"end\":57260,\"start\":57256},{\"end\":57276,\"start\":57267},{\"end\":57413,\"start\":57407},{\"end\":57432,\"start\":57424},{\"end\":57445,\"start\":57439},{\"end\":57456,\"start\":57453},{\"end\":57467,\"start\":57463},{\"end\":57605,\"start\":57593},{\"end\":57614,\"start\":57612},{\"end\":57629,\"start\":57621},{\"end\":57634,\"start\":57631},{\"end\":57789,\"start\":57782},{\"end\":57803,\"start\":57799},{\"end\":57819,\"start\":57813},{\"end\":57828,\"start\":57826},{\"end\":57839,\"start\":57834},{\"end\":57855,\"start\":57849},{\"end\":57875,\"start\":57864},{\"end\":57898,\"start\":57893},{\"end\":57918,\"start\":57906},{\"end\":57932,\"start\":57924},{\"end\":58043,\"start\":58038},{\"end\":58059,\"start\":58052},{\"end\":58079,\"start\":58070},{\"end\":58090,\"start\":58081},{\"end\":58119,\"start\":58098},{\"end\":58134,\"start\":58127},{\"end\":58152,\"start\":58147},{\"end\":58166,\"start\":58160},{\"end\":58180,\"start\":58175},{\"end\":58186,\"start\":58182},{\"end\":58256,\"start\":58254},{\"end\":58268,\"start\":58265},{\"end\":58277,\"start\":58274},{\"end\":58285,\"start\":58283},{\"end\":58295,\"start\":58293},{\"end\":58305,\"start\":58302},{\"end\":58317,\"start\":58314},{\"end\":58502,\"start\":58500},{\"end\":58516,\"start\":58512},{\"end\":58527,\"start\":58524},{\"end\":58541,\"start\":58537},{\"end\":58553,\"start\":58550},{\"end\":58567,\"start\":58563},{\"end\":58579,\"start\":58576},{\"end\":58592,\"start\":58589},{\"end\":58601,\"start\":58599},{\"end\":58612,\"start\":58610},{\"end\":58770,\"start\":58767},{\"end\":58782,\"start\":58778},{\"end\":58793,\"start\":58791},{\"end\":58807,\"start\":58803},{\"end\":58816,\"start\":58813},{\"end\":58986,\"start\":58974},{\"end\":59002,\"start\":58996},{\"end\":59018,\"start\":59011},{\"end\":59039,\"start\":59031},{\"end\":59057,\"start\":59050},{\"end\":59075,\"start\":59068},{\"end\":59090,\"start\":59083},{\"end\":59102,\"start\":59097},{\"end\":59117,\"start\":59111},{\"end\":59124,\"start\":59119},{\"end\":59238,\"start\":59226},{\"end\":59254,\"start\":59248},{\"end\":59267,\"start\":59263},{\"end\":59281,\"start\":59275},{\"end\":59296,\"start\":59289},{\"end\":59302,\"start\":59298},{\"end\":59436,\"start\":59428},{\"end\":59454,\"start\":59447},{\"end\":59467,\"start\":59461},{\"end\":59715,\"start\":59711},{\"end\":59727,\"start\":59724},{\"end\":59736,\"start\":59732},{\"end\":59750,\"start\":59744},{\"end\":59765,\"start\":59761},{\"end\":59776,\"start\":59773},{\"end\":59792,\"start\":59784},{\"end\":59813,\"start\":59800},{\"end\":59830,\"start\":59823},{\"end\":59844,\"start\":59841},{\"end\":59891,\"start\":59888},{\"end\":59899,\"start\":59896},{\"end\":59916,\"start\":59907},{\"end\":59930,\"start\":59924},{\"end\":59943,\"start\":59939},{\"end\":59963,\"start\":59955},{\"end\":59978,\"start\":59970},{\"end\":59993,\"start\":59988},{\"end\":60005,\"start\":60001},{\"end\":60021,\"start\":60014},{\"end\":60184,\"start\":60181},{\"end\":60197,\"start\":60193},{\"end\":60214,\"start\":60204},{\"end\":60229,\"start\":60224},{\"end\":60237,\"start\":60234},{\"end\":60246,\"start\":60244},{\"end\":60258,\"start\":60254},{\"end\":60306,\"start\":60304},{\"end\":60318,\"start\":60316},{\"end\":60329,\"start\":60327},{\"end\":60339,\"start\":60337},{\"end\":60349,\"start\":60346},{\"end\":60362,\"start\":60358},{\"end\":60376,\"start\":60372},{\"end\":60386,\"start\":60384},{\"end\":60401,\"start\":60398},{\"end\":60411,\"start\":60408},{\"end\":60425,\"start\":60420},{\"end\":60439,\"start\":60437},{\"end\":60452,\"start\":60450},{\"end\":60465,\"start\":60461},{\"end\":60479,\"start\":60475},{\"end\":60488,\"start\":60486},{\"end\":60498,\"start\":60493},{\"end\":60509,\"start\":60504},{\"end\":60656,\"start\":60651},{\"end\":60672,\"start\":60666},{\"end\":60685,\"start\":60680},{\"end\":60700,\"start\":60693},{\"end\":60711,\"start\":60707},{\"end\":60725,\"start\":60721},{\"end\":60744,\"start\":60739},{\"end\":60755,\"start\":60751},{\"end\":60764,\"start\":60762},{\"end\":60781,\"start\":60769},{\"end\":60878,\"start\":60874},{\"end\":60893,\"start\":60889},{\"end\":60910,\"start\":60907},{\"end\":60921,\"start\":60918},{\"end\":61072,\"start\":61069},{\"end\":61082,\"start\":61078},{\"end\":61097,\"start\":61093},{\"end\":61107,\"start\":61105},{\"end\":61126,\"start\":61117}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":56517630},\"end\":47321,\"start\":47011},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":248476411},\"end\":47591,\"start\":47323},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11933981},\"end\":47845,\"start\":47593},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3180429},\"end\":48114,\"start\":47847},{\"attributes\":{\"doi\":\"arXiv:2204.05862\",\"id\":\"b4\"},\"end\":48377,\"start\":48116},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":231879922},\"end\":48557,\"start\":48379},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":218971783},\"end\":48809,\"start\":48559},{\"attributes\":{\"doi\":\"arXiv:2303.12712\",\"id\":\"b7\"},\"end\":49065,\"start\":48811},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":216080982},\"end\":49339,\"start\":49067},{\"attributes\":{\"id\":\"b9\"},\"end\":49588,\"start\":49341},{\"attributes\":{\"doi\":\"arXiv:2204.02311\",\"id\":\"b10\"},\"end\":49825,\"start\":49590},{\"attributes\":{\"doi\":\"arXiv:2210.11416\",\"id\":\"b11\"},\"end\":50044,\"start\":49827},{\"attributes\":{\"id\":\"b12\"},\"end\":50262,\"start\":50046},{\"attributes\":{\"doi\":\"arXiv:2205.12548\",\"id\":\"b13\"},\"end\":50485,\"start\":50264},{\"attributes\":{\"doi\":\"arXiv:2010.11929\",\"id\":\"b14\"},\"end\":50771,\"start\":50487},{\"attributes\":{\"doi\":\"arXiv:2303.03378\",\"id\":\"b15\"},\"end\":51000,\"start\":50773},{\"attributes\":{\"doi\":\"arXiv:2304.15010\",\"id\":\"b16\"},\"end\":51239,\"start\":51002},{\"attributes\":{\"doi\":\"arXiv:2203.15556\",\"id\":\"b17\"},\"end\":51495,\"start\":51241},{\"attributes\":{\"doi\":\"arXiv:2302.14045\",\"id\":\"b18\"},\"end\":51733,\"start\":51497},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":152282269},\"end\":52016,\"start\":51735},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":232110866},\"end\":52217,\"start\":52018},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":247618727},\"end\":52471,\"start\":52219},{\"attributes\":{\"doi\":\"arXiv:2202.10054\",\"id\":\"b22\"},\"end\":52660,\"start\":52473},{\"attributes\":{\"doi\":\"arXiv:2104.08691\",\"id\":\"b23\"},\"end\":52797,\"start\":52662},{\"attributes\":{\"doi\":\"arXiv:2208.05577\",\"id\":\"b24\"},\"end\":52958,\"start\":52799},{\"attributes\":{\"doi\":\"arXiv:2305.03726\",\"id\":\"b25\"},\"end\":53133,\"start\":52960},{\"attributes\":{\"doi\":\"arXiv:2308.04152\",\"id\":\"b26\"},\"end\":53380,\"start\":53135},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":236034189},\"end\":53632,\"start\":53382},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":246411402},\"end\":53843,\"start\":53634},{\"attributes\":{\"doi\":\"arXiv:2301.12597\",\"id\":\"b29\"},\"end\":54033,\"start\":53845},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":259360603},\"end\":54258,\"start\":54035},{\"attributes\":{\"id\":\"b31\"},\"end\":54568,\"start\":54260},{\"attributes\":{\"doi\":\"arXiv:2210.08823\",\"id\":\"b32\"},\"end\":54734,\"start\":54570},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":14113767},\"end\":55025,\"start\":54736},{\"attributes\":{\"id\":\"b34\"},\"end\":55111,\"start\":55027},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":199453025},\"end\":55317,\"start\":55113},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":173991173},\"end\":55615,\"start\":55319},{\"attributes\":{\"doi\":\"arXiv:2203.11147\",\"id\":\"b37\"},\"end\":55881,\"start\":55617},{\"attributes\":{\"doi\":\"arXiv:2111.09734\",\"id\":\"b38\"},\"end\":56000,\"start\":55883},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":14579301},\"end\":56172,\"start\":56002},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":246426909},\"end\":56443,\"start\":56174},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":160025533},\"end\":56599,\"start\":56445},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":231591445},\"end\":56874,\"start\":56601},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":204838007},\"end\":57129,\"start\":56876},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":232035663},\"end\":57332,\"start\":57131},{\"attributes\":{\"doi\":\"arXiv:2204.06125\",\"id\":\"b45\"},\"end\":57503,\"start\":57334},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":10328909},\"end\":57693,\"start\":57505},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":248986576},\"end\":57991,\"start\":57695},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":249642130},\"end\":58245,\"start\":57993},{\"attributes\":{\"doi\":\"arXiv:1908.08530\",\"id\":\"b49\"},\"end\":58421,\"start\":58247},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":248405974},\"end\":58760,\"start\":58423},{\"attributes\":{\"doi\":\"arXiv:2303.15389\",\"id\":\"b51\"},\"end\":58910,\"start\":58762},{\"attributes\":{\"doi\":\"arXiv:2302.13971\",\"id\":\"b52\"},\"end\":59160,\"start\":58912},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":235658331},\"end\":59361,\"start\":59162},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":9026666},\"end\":59614,\"start\":59363},{\"attributes\":{\"doi\":\"arXiv:2208.10442\",\"id\":\"b55\"},\"end\":59880,\"start\":59616},{\"attributes\":{\"doi\":\"arXiv:2206.07682\",\"id\":\"b56\"},\"end\":60102,\"start\":59882},{\"attributes\":{\"doi\":\"arXiv:2201.11903\",\"id\":\"b57\"},\"end\":60294,\"start\":60104},{\"attributes\":{\"id\":\"b58\"},\"end\":60592,\"start\":60296},{\"attributes\":{\"doi\":\"arXiv:2205.01068\",\"id\":\"b59\"},\"end\":60817,\"start\":60594},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":237386023},\"end\":60973,\"start\":60819},{\"attributes\":{\"doi\":\"arXiv:2304.10592\",\"id\":\"b61\"},\"end\":61162,\"start\":60975}]", "bib_title": "[{\"end\":47051,\"start\":47011},{\"end\":47378,\"start\":47323},{\"end\":47647,\"start\":47593},{\"end\":47877,\"start\":47847},{\"end\":48447,\"start\":48379},{\"end\":48596,\"start\":48559},{\"end\":49119,\"start\":49067},{\"end\":51822,\"start\":51735},{\"end\":52072,\"start\":52018},{\"end\":52239,\"start\":52219},{\"end\":53471,\"start\":53382},{\"end\":53738,\"start\":53634},{\"end\":54100,\"start\":54035},{\"end\":54331,\"start\":54260},{\"end\":54777,\"start\":54736},{\"end\":55209,\"start\":55113},{\"end\":55393,\"start\":55319},{\"end\":56066,\"start\":56002},{\"end\":56241,\"start\":56174},{\"end\":56496,\"start\":56445},{\"end\":56670,\"start\":56601},{\"end\":56957,\"start\":56876},{\"end\":57165,\"start\":57131},{\"end\":57583,\"start\":57505},{\"end\":57772,\"start\":57695},{\"end\":58032,\"start\":57993},{\"end\":58490,\"start\":58423},{\"end\":59218,\"start\":59162},{\"end\":59414,\"start\":59363},{\"end\":60864,\"start\":60819}]", "bib_author": "[{\"end\":47068,\"start\":47053},{\"end\":47081,\"start\":47068},{\"end\":47093,\"start\":47081},{\"end\":47106,\"start\":47093},{\"end\":47120,\"start\":47106},{\"end\":47134,\"start\":47120},{\"end\":47147,\"start\":47134},{\"end\":47160,\"start\":47147},{\"end\":47172,\"start\":47160},{\"end\":47188,\"start\":47172},{\"end\":47403,\"start\":47380},{\"end\":47417,\"start\":47403},{\"end\":47430,\"start\":47417},{\"end\":47445,\"start\":47430},{\"end\":47456,\"start\":47445},{\"end\":47469,\"start\":47456},{\"end\":47481,\"start\":47469},{\"end\":47496,\"start\":47481},{\"end\":47516,\"start\":47496},{\"end\":47534,\"start\":47516},{\"end\":47665,\"start\":47649},{\"end\":47682,\"start\":47665},{\"end\":47696,\"start\":47682},{\"end\":47711,\"start\":47696},{\"end\":47896,\"start\":47879},{\"end\":47915,\"start\":47896},{\"end\":47926,\"start\":47915},{\"end\":47945,\"start\":47926},{\"end\":47958,\"start\":47945},{\"end\":47976,\"start\":47958},{\"end\":47989,\"start\":47976},{\"end\":48219,\"start\":48207},{\"end\":48231,\"start\":48219},{\"end\":48246,\"start\":48231},{\"end\":48261,\"start\":48246},{\"end\":48272,\"start\":48261},{\"end\":48287,\"start\":48272},{\"end\":48299,\"start\":48287},{\"end\":48315,\"start\":48299},{\"end\":48329,\"start\":48315},{\"end\":48343,\"start\":48329},{\"end\":48461,\"start\":48449},{\"end\":48471,\"start\":48461},{\"end\":48487,\"start\":48471},{\"end\":48503,\"start\":48487},{\"end\":48609,\"start\":48598},{\"end\":48624,\"start\":48609},{\"end\":48636,\"start\":48624},{\"end\":48653,\"start\":48636},{\"end\":48669,\"start\":48653},{\"end\":48688,\"start\":48669},{\"end\":48708,\"start\":48688},{\"end\":48722,\"start\":48708},{\"end\":48737,\"start\":48722},{\"end\":48752,\"start\":48737},{\"end\":48829,\"start\":48811},{\"end\":48851,\"start\":48829},{\"end\":48864,\"start\":48851},{\"end\":48881,\"start\":48864},{\"end\":48895,\"start\":48881},{\"end\":48906,\"start\":48895},{\"end\":48917,\"start\":48906},{\"end\":48930,\"start\":48917},{\"end\":48942,\"start\":48930},{\"end\":48958,\"start\":48942},{\"end\":49136,\"start\":49121},{\"end\":49147,\"start\":49136},{\"end\":49159,\"start\":49147},{\"end\":49175,\"start\":49159},{\"end\":49189,\"start\":49175},{\"end\":49198,\"start\":49189},{\"end\":49208,\"start\":49198},{\"end\":49222,\"start\":49208},{\"end\":49432,\"start\":49416},{\"end\":49444,\"start\":49432},{\"end\":49452,\"start\":49444},{\"end\":49464,\"start\":49452},{\"end\":49477,\"start\":49464},{\"end\":49488,\"start\":49477},{\"end\":49503,\"start\":49488},{\"end\":49518,\"start\":49503},{\"end\":49534,\"start\":49518},{\"end\":49553,\"start\":49534},{\"end\":49565,\"start\":49553},{\"end\":49578,\"start\":49565},{\"end\":49611,\"start\":49590},{\"end\":49626,\"start\":49611},{\"end\":49640,\"start\":49626},{\"end\":49655,\"start\":49640},{\"end\":49670,\"start\":49655},{\"end\":49684,\"start\":49670},{\"end\":49697,\"start\":49684},{\"end\":49714,\"start\":49697},{\"end\":49730,\"start\":49714},{\"end\":49750,\"start\":49730},{\"end\":49891,\"start\":49874},{\"end\":49899,\"start\":49891},{\"end\":49915,\"start\":49899},{\"end\":49928,\"start\":49915},{\"end\":49936,\"start\":49928},{\"end\":49951,\"start\":49936},{\"end\":49960,\"start\":49951},{\"end\":49973,\"start\":49960},{\"end\":49991,\"start\":49973},{\"end\":50010,\"start\":49991},{\"end\":50146,\"start\":50132},{\"end\":50157,\"start\":50146},{\"end\":50168,\"start\":50157},{\"end\":50182,\"start\":50168},{\"end\":50194,\"start\":50182},{\"end\":50206,\"start\":50194},{\"end\":50221,\"start\":50206},{\"end\":50232,\"start\":50221},{\"end\":50246,\"start\":50232},{\"end\":50258,\"start\":50246},{\"end\":50350,\"start\":50336},{\"end\":50363,\"start\":50350},{\"end\":50381,\"start\":50363},{\"end\":50393,\"start\":50381},{\"end\":50402,\"start\":50393},{\"end\":50415,\"start\":50402},{\"end\":50426,\"start\":50415},{\"end\":50439,\"start\":50426},{\"end\":50451,\"start\":50439},{\"end\":50583,\"start\":50563},{\"end\":50596,\"start\":50583},{\"end\":50618,\"start\":50596},{\"end\":50636,\"start\":50618},{\"end\":50650,\"start\":50636},{\"end\":50670,\"start\":50650},{\"end\":50688,\"start\":50670},{\"end\":50707,\"start\":50688},{\"end\":50722,\"start\":50707},{\"end\":50737,\"start\":50722},{\"end\":50787,\"start\":50773},{\"end\":50796,\"start\":50787},{\"end\":50807,\"start\":50796},{\"end\":50822,\"start\":50807},{\"end\":50839,\"start\":50822},{\"end\":50856,\"start\":50839},{\"end\":50871,\"start\":50856},{\"end\":50887,\"start\":50871},{\"end\":50901,\"start\":50887},{\"end\":50915,\"start\":50901},{\"end\":50919,\"start\":50915},{\"end\":51012,\"start\":51002},{\"end\":51025,\"start\":51012},{\"end\":51039,\"start\":51025},{\"end\":51049,\"start\":51039},{\"end\":51062,\"start\":51049},{\"end\":51074,\"start\":51062},{\"end\":51085,\"start\":51074},{\"end\":51093,\"start\":51085},{\"end\":51105,\"start\":51093},{\"end\":51118,\"start\":51105},{\"end\":51132,\"start\":51118},{\"end\":51141,\"start\":51132},{\"end\":51306,\"start\":51289},{\"end\":51326,\"start\":51306},{\"end\":51341,\"start\":51326},{\"end\":51360,\"start\":51341},{\"end\":51372,\"start\":51360},{\"end\":51390,\"start\":51372},{\"end\":51404,\"start\":51390},{\"end\":51421,\"start\":51404},{\"end\":51441,\"start\":51421},{\"end\":51454,\"start\":51441},{\"end\":51461,\"start\":51454},{\"end\":51584,\"start\":51569},{\"end\":51593,\"start\":51584},{\"end\":51606,\"start\":51593},{\"end\":51616,\"start\":51606},{\"end\":51633,\"start\":51616},{\"end\":51645,\"start\":51633},{\"end\":51658,\"start\":51645},{\"end\":51667,\"start\":51658},{\"end\":51688,\"start\":51667},{\"end\":51699,\"start\":51688},{\"end\":51832,\"start\":51824},{\"end\":51854,\"start\":51832},{\"end\":51863,\"start\":51854},{\"end\":52089,\"start\":52074},{\"end\":52103,\"start\":52089},{\"end\":52115,\"start\":52103},{\"end\":52130,\"start\":52115},{\"end\":52148,\"start\":52130},{\"end\":52163,\"start\":52148},{\"end\":52254,\"start\":52241},{\"end\":52267,\"start\":52254},{\"end\":52282,\"start\":52267},{\"end\":52297,\"start\":52282},{\"end\":52313,\"start\":52297},{\"end\":52332,\"start\":52313},{\"end\":52345,\"start\":52332},{\"end\":52569,\"start\":52555},{\"end\":52588,\"start\":52569},{\"end\":52602,\"start\":52588},{\"end\":52613,\"start\":52602},{\"end\":52626,\"start\":52613},{\"end\":52734,\"start\":52720},{\"end\":52748,\"start\":52734},{\"end\":52763,\"start\":52748},{\"end\":52875,\"start\":52861},{\"end\":52893,\"start\":52875},{\"end\":52909,\"start\":52893},{\"end\":52924,\"start\":52909},{\"end\":53030,\"start\":53023},{\"end\":53045,\"start\":53030},{\"end\":53059,\"start\":53045},{\"end\":53073,\"start\":53059},{\"end\":53088,\"start\":53073},{\"end\":53099,\"start\":53088},{\"end\":53148,\"start\":53135},{\"end\":53161,\"start\":53148},{\"end\":53171,\"start\":53161},{\"end\":53183,\"start\":53171},{\"end\":53198,\"start\":53183},{\"end\":53206,\"start\":53198},{\"end\":53221,\"start\":53206},{\"end\":53236,\"start\":53221},{\"end\":53484,\"start\":53473},{\"end\":53507,\"start\":53484},{\"end\":53525,\"start\":53507},{\"end\":53538,\"start\":53525},{\"end\":53553,\"start\":53538},{\"end\":53565,\"start\":53553},{\"end\":53575,\"start\":53565},{\"end\":53751,\"start\":53740},{\"end\":53762,\"start\":53751},{\"end\":53777,\"start\":53762},{\"end\":53789,\"start\":53777},{\"end\":53959,\"start\":53948},{\"end\":53970,\"start\":53959},{\"end\":53987,\"start\":53970},{\"end\":53999,\"start\":53987},{\"end\":54114,\"start\":54102},{\"end\":54128,\"start\":54114},{\"end\":54141,\"start\":54128},{\"end\":54154,\"start\":54141},{\"end\":54165,\"start\":54154},{\"end\":54176,\"start\":54165},{\"end\":54187,\"start\":54176},{\"end\":54203,\"start\":54187},{\"end\":54345,\"start\":54333},{\"end\":54359,\"start\":54345},{\"end\":54372,\"start\":54359},{\"end\":54385,\"start\":54372},{\"end\":54397,\"start\":54385},{\"end\":54408,\"start\":54397},{\"end\":54419,\"start\":54408},{\"end\":54435,\"start\":54419},{\"end\":54583,\"start\":54570},{\"end\":54596,\"start\":54583},{\"end\":54609,\"start\":54596},{\"end\":54623,\"start\":54609},{\"end\":54793,\"start\":54779},{\"end\":54808,\"start\":54793},{\"end\":54824,\"start\":54808},{\"end\":54836,\"start\":54824},{\"end\":54851,\"start\":54836},{\"end\":54865,\"start\":54851},{\"end\":54879,\"start\":54865},{\"end\":54897,\"start\":54879},{\"end\":55040,\"start\":55027},{\"end\":55053,\"start\":55040},{\"end\":55066,\"start\":55053},{\"end\":55080,\"start\":55066},{\"end\":55222,\"start\":55211},{\"end\":55235,\"start\":55222},{\"end\":55248,\"start\":55235},{\"end\":55260,\"start\":55248},{\"end\":55411,\"start\":55395},{\"end\":55431,\"start\":55411},{\"end\":55444,\"start\":55431},{\"end\":55462,\"start\":55444},{\"end\":55697,\"start\":55683},{\"end\":55711,\"start\":55697},{\"end\":55729,\"start\":55711},{\"end\":55745,\"start\":55729},{\"end\":55759,\"start\":55745},{\"end\":55776,\"start\":55759},{\"end\":55788,\"start\":55776},{\"end\":55804,\"start\":55788},{\"end\":55830,\"start\":55804},{\"end\":55847,\"start\":55830},{\"end\":55895,\"start\":55883},{\"end\":55907,\"start\":55895},{\"end\":55923,\"start\":55907},{\"end\":55932,\"start\":55923},{\"end\":56085,\"start\":56068},{\"end\":56102,\"start\":56085},{\"end\":56115,\"start\":56102},{\"end\":56256,\"start\":56243},{\"end\":56268,\"start\":56256},{\"end\":56278,\"start\":56268},{\"end\":56293,\"start\":56278},{\"end\":56313,\"start\":56293},{\"end\":56329,\"start\":56313},{\"end\":56342,\"start\":56329},{\"end\":56360,\"start\":56342},{\"end\":56376,\"start\":56360},{\"end\":56386,\"start\":56376},{\"end\":56512,\"start\":56498},{\"end\":56524,\"start\":56512},{\"end\":56537,\"start\":56524},{\"end\":56549,\"start\":56537},{\"end\":56563,\"start\":56549},{\"end\":56579,\"start\":56563},{\"end\":56686,\"start\":56672},{\"end\":56701,\"start\":56686},{\"end\":56716,\"start\":56701},{\"end\":56731,\"start\":56716},{\"end\":56744,\"start\":56731},{\"end\":56762,\"start\":56744},{\"end\":56777,\"start\":56762},{\"end\":56792,\"start\":56777},{\"end\":56808,\"start\":56792},{\"end\":56820,\"start\":56808},{\"end\":56973,\"start\":56959},{\"end\":56987,\"start\":56973},{\"end\":57001,\"start\":56987},{\"end\":57016,\"start\":57001},{\"end\":57031,\"start\":57016},{\"end\":57047,\"start\":57031},{\"end\":57059,\"start\":57047},{\"end\":57067,\"start\":57059},{\"end\":57080,\"start\":57067},{\"end\":57182,\"start\":57167},{\"end\":57198,\"start\":57182},{\"end\":57211,\"start\":57198},{\"end\":57223,\"start\":57211},{\"end\":57237,\"start\":57223},{\"end\":57251,\"start\":57237},{\"end\":57262,\"start\":57251},{\"end\":57278,\"start\":57262},{\"end\":57415,\"start\":57400},{\"end\":57434,\"start\":57415},{\"end\":57447,\"start\":57434},{\"end\":57458,\"start\":57447},{\"end\":57469,\"start\":57458},{\"end\":57607,\"start\":57585},{\"end\":57616,\"start\":57607},{\"end\":57631,\"start\":57616},{\"end\":57636,\"start\":57631},{\"end\":57791,\"start\":57774},{\"end\":57805,\"start\":57791},{\"end\":57821,\"start\":57805},{\"end\":57830,\"start\":57821},{\"end\":57841,\"start\":57830},{\"end\":57857,\"start\":57841},{\"end\":57877,\"start\":57857},{\"end\":57900,\"start\":57877},{\"end\":57920,\"start\":57900},{\"end\":57934,\"start\":57920},{\"end\":58045,\"start\":58034},{\"end\":58061,\"start\":58045},{\"end\":58081,\"start\":58061},{\"end\":58092,\"start\":58081},{\"end\":58121,\"start\":58092},{\"end\":58136,\"start\":58121},{\"end\":58154,\"start\":58136},{\"end\":58168,\"start\":58154},{\"end\":58182,\"start\":58168},{\"end\":58188,\"start\":58182},{\"end\":58258,\"start\":58247},{\"end\":58270,\"start\":58258},{\"end\":58279,\"start\":58270},{\"end\":58287,\"start\":58279},{\"end\":58297,\"start\":58287},{\"end\":58307,\"start\":58297},{\"end\":58319,\"start\":58307},{\"end\":58504,\"start\":58492},{\"end\":58518,\"start\":58504},{\"end\":58529,\"start\":58518},{\"end\":58543,\"start\":58529},{\"end\":58555,\"start\":58543},{\"end\":58569,\"start\":58555},{\"end\":58581,\"start\":58569},{\"end\":58594,\"start\":58581},{\"end\":58603,\"start\":58594},{\"end\":58614,\"start\":58603},{\"end\":58772,\"start\":58762},{\"end\":58784,\"start\":58772},{\"end\":58795,\"start\":58784},{\"end\":58809,\"start\":58795},{\"end\":58818,\"start\":58809},{\"end\":58988,\"start\":58966},{\"end\":59004,\"start\":58988},{\"end\":59020,\"start\":59004},{\"end\":59041,\"start\":59020},{\"end\":59059,\"start\":59041},{\"end\":59077,\"start\":59059},{\"end\":59092,\"start\":59077},{\"end\":59104,\"start\":59092},{\"end\":59119,\"start\":59104},{\"end\":59126,\"start\":59119},{\"end\":59240,\"start\":59220},{\"end\":59256,\"start\":59240},{\"end\":59269,\"start\":59256},{\"end\":59283,\"start\":59269},{\"end\":59298,\"start\":59283},{\"end\":59304,\"start\":59298},{\"end\":59438,\"start\":59416},{\"end\":59456,\"start\":59438},{\"end\":59469,\"start\":59456},{\"end\":59717,\"start\":59704},{\"end\":59729,\"start\":59717},{\"end\":59738,\"start\":59729},{\"end\":59752,\"start\":59738},{\"end\":59767,\"start\":59752},{\"end\":59778,\"start\":59767},{\"end\":59794,\"start\":59778},{\"end\":59815,\"start\":59794},{\"end\":59832,\"start\":59815},{\"end\":59846,\"start\":59832},{\"end\":59893,\"start\":59882},{\"end\":59901,\"start\":59893},{\"end\":59918,\"start\":59901},{\"end\":59932,\"start\":59918},{\"end\":59945,\"start\":59932},{\"end\":59965,\"start\":59945},{\"end\":59980,\"start\":59965},{\"end\":59995,\"start\":59980},{\"end\":60007,\"start\":59995},{\"end\":60023,\"start\":60007},{\"end\":60186,\"start\":60175},{\"end\":60199,\"start\":60186},{\"end\":60216,\"start\":60199},{\"end\":60231,\"start\":60216},{\"end\":60239,\"start\":60231},{\"end\":60248,\"start\":60239},{\"end\":60260,\"start\":60248},{\"end\":60308,\"start\":60296},{\"end\":60320,\"start\":60308},{\"end\":60331,\"start\":60320},{\"end\":60341,\"start\":60331},{\"end\":60351,\"start\":60341},{\"end\":60364,\"start\":60351},{\"end\":60378,\"start\":60364},{\"end\":60388,\"start\":60378},{\"end\":60403,\"start\":60388},{\"end\":60413,\"start\":60403},{\"end\":60427,\"start\":60413},{\"end\":60441,\"start\":60427},{\"end\":60454,\"start\":60441},{\"end\":60467,\"start\":60454},{\"end\":60481,\"start\":60467},{\"end\":60490,\"start\":60481},{\"end\":60500,\"start\":60490},{\"end\":60511,\"start\":60500},{\"end\":60658,\"start\":60645},{\"end\":60674,\"start\":60658},{\"end\":60687,\"start\":60674},{\"end\":60702,\"start\":60687},{\"end\":60713,\"start\":60702},{\"end\":60727,\"start\":60713},{\"end\":60746,\"start\":60727},{\"end\":60757,\"start\":60746},{\"end\":60766,\"start\":60757},{\"end\":60783,\"start\":60766},{\"end\":60880,\"start\":60866},{\"end\":60895,\"start\":60880},{\"end\":60912,\"start\":60895},{\"end\":60923,\"start\":60912},{\"end\":61074,\"start\":61063},{\"end\":61084,\"start\":61074},{\"end\":61099,\"start\":61084},{\"end\":61109,\"start\":61099},{\"end\":61128,\"start\":61109}]", "bib_venue": "[{\"end\":47259,\"start\":47188},{\"end\":47583,\"start\":47534},{\"end\":47762,\"start\":47711},{\"end\":48056,\"start\":47989},{\"end\":48205,\"start\":48116},{\"end\":48547,\"start\":48503},{\"end\":48801,\"start\":48752},{\"end\":49045,\"start\":48974},{\"end\":49273,\"start\":49222},{\"end\":49414,\"start\":49341},{\"end\":49805,\"start\":49766},{\"end\":49872,\"start\":49827},{\"end\":50130,\"start\":50046},{\"end\":50334,\"start\":50264},{\"end\":50561,\"start\":50487},{\"end\":50980,\"start\":50935},{\"end\":51219,\"start\":51157},{\"end\":51287,\"start\":51241},{\"end\":51567,\"start\":51497},{\"end\":51944,\"start\":51863},{\"end\":52207,\"start\":52163},{\"end\":52396,\"start\":52345},{\"end\":52553,\"start\":52473},{\"end\":52718,\"start\":52662},{\"end\":52859,\"start\":52799},{\"end\":53021,\"start\":52960},{\"end\":53360,\"start\":53252},{\"end\":53624,\"start\":53575},{\"end\":53833,\"start\":53789},{\"end\":53946,\"start\":53845},{\"end\":54252,\"start\":54203},{\"end\":54506,\"start\":54435},{\"end\":54714,\"start\":54639},{\"end\":54948,\"start\":54897},{\"end\":55105,\"start\":55080},{\"end\":55309,\"start\":55260},{\"end\":55543,\"start\":55462},{\"end\":55681,\"start\":55617},{\"end\":55980,\"start\":55948},{\"end\":56164,\"start\":56115},{\"end\":56435,\"start\":56386},{\"end\":56590,\"start\":56579},{\"end\":56864,\"start\":56820},{\"end\":57120,\"start\":57080},{\"end\":57322,\"start\":57278},{\"end\":57398,\"start\":57334},{\"end\":57685,\"start\":57636},{\"end\":57983,\"start\":57934},{\"end\":58237,\"start\":58188},{\"end\":58401,\"start\":58335},{\"end\":58678,\"start\":58614},{\"end\":58890,\"start\":58834},{\"end\":58964,\"start\":58912},{\"end\":59353,\"start\":59304},{\"end\":59546,\"start\":59469},{\"end\":59702,\"start\":59616},{\"end\":60082,\"start\":60039},{\"end\":60173,\"start\":60104},{\"end\":60586,\"start\":60511},{\"end\":60643,\"start\":60594},{\"end\":60963,\"start\":60923},{\"end\":61061,\"start\":60975},{\"end\":47317,\"start\":47261},{\"end\":47790,\"start\":47764},{\"end\":48110,\"start\":48058},{\"end\":49286,\"start\":49275},{\"end\":52012,\"start\":51946},{\"end\":52414,\"start\":52398},{\"end\":54564,\"start\":54508},{\"end\":54969,\"start\":54950},{\"end\":55611,\"start\":55545},{\"end\":58729,\"start\":58680},{\"end\":59610,\"start\":59548}]"}}}, "year": 2023, "month": 12, "day": 17}