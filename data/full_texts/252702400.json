{"id": 252702400, "updated": "2023-10-09 09:22:42.505", "metadata": {"title": "AI\u2011BASED INDOOR LOCALIZATION USING MMWAVE MIMO CHANNELS AT 60 GHZ", "authors": "[{\"first\":\"Shubham\",\"last\":\"Khunteta\",\"middle\":[]},{\"first\":\"Ashok\",\"last\":\"Reddy\",\"middle\":[\"Kumar\"]},{\"first\":\"Avani\",\"last\":\"Agrawal\",\"middle\":[]}]", "venue": "ITU Journal on Future and Evolving Technologies", "journal": "ITU Journal on Future and Evolving Technologies", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "\u2013 In recent years, indoor localization using wireless systems has been an important area of research for its appli\u2011 cations towards health, security and the tracking of users. A Global Positioning System (GPS) is considered as the best solution for localization for outdoor scenarios but it fails to provide accurate positioning for indoor scenarios. Wi\u2011Fi (cid:980)ingerprinting methods using received signal strength from multiple access points are popular for solving indoor localization problem. As the wireless systems move towards higher frequencies, higher bandwidth and a large antenna array, sensing has also become feasible along with communication, which is an important research area towards 6G named as Integrated Communication And Sensing (ISAC). ISAC relies on sensing parameter estimations, such as estimation of (cid:980)ine range, Doppler and angular infor\u2011 mation which contains the signature of the surrounding objects. A localization problem can be solved by analysing the sensing parameters. In this paper, we propose a solution for the localization problem for IEEE 802.11ay WLAN systems based on sig\u2011 nal processing and Machine Learning (ML) in indoor scenarios. First, signal processing is used to estimate the channel in a Doppler and angular domain which separates the signal re(cid:980)lected from the different objects based on their range, velocity and the angular placement. Then, an ML model is used to localize the objects in the different parts of the indoor environment. We use a state\u2011of\u2011the\u2011art ML algorithm such as feed forward neural networks. Further, we evaluate our algorithm for a scenario where there is a room with a transmitter and receiver, and on a dataset generated by a simulator provided by the National Institute of Science and Technology (NIST). We show that the proposed algorithm for localization, which predicts the number of persons in different parts of a room, achieves accuracy of 99% at Signal to Noise Ratio (SNR) of 18 dB and is able to count up to eight persons in a room with 99% accuracy at SNR greater than 0 dB.", "fields_of_study": null, "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.52953/aorf8087"}}, "content": {"source": {"pdf_hash": "48c36af200f9edc1278752e321f17a1093333c0c", "pdf_src": "Anansi", "pdf_uri": "[\"https://www.itu.int/dms_pub/itu-s/opb/jnl/S-JNL-VOL3.ISSUE2-2022-A21-PDF-E.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBYNCND", "open_access_url": "https://www.itu.int/dms_pub/itu-s/opb/jnl/S-JNL-VOL3.ISSUE2-2022-A21-PDF-E.pdf", "status": "HYBRID"}}, "grobid": {"id": "24ed85701785a87e87008103e687644bd8b71376", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/48c36af200f9edc1278752e321f17a1093333c0c.txt", "contents": "\nAI-BASED INDOOR LOCALIZATION USING MMWAVE MIMO CHANNELS AT 60 GHZ\n\n\nShubham Khunteta sk.khunteta@samsung.com \nBeyond 5G Team\nSamsung R&D Institute India-Bengaluru\n\n\nBeyond 5G Team\nSamsung R&D Institute India-Bengaluru\n\n\nAshok Kumar Reddy \nBeyond 5G Team\nSamsung R&D Institute India-Bengaluru\n\n\nAvani Agrawal \nBeyond 5G Team\nSamsung R&D Institute India-Bengaluru\n\n\nAI-BASED INDOOR LOCALIZATION USING MMWAVE MIMO CHANNELS AT 60 GHZ\n644D8A7B0476F913012FD51F34BBA4016GAIAI in wirelessintegrated sensing and communicationlocalizationMLmmWaveRF sensing\nIn recent years, indoor localization using wireless systems has been an important area of research for its applications towards health, security and the tracking of users.A Global Positioning System (GPS) is considered as the best solution for localization for outdoor scenarios but it fails to provide accurate positioning for indoor scenarios.Wi-Fi ingerprinting methods using received signal strength from multiple access points are popular for solving indoor localization problem.As the wireless systems move towards higher frequencies, higher bandwidth and a large antenna array, sensing has also become feasible along with communication, which is an important research area towards 6G named as Integrated Communication And Sensing (ISAC).ISAC relies on sensing parameter estimations, such as estimation of ine range, Doppler and angular information which contains the signature of the surrounding objects.A localization problem can be solved by analysing the sensing parameters.In this paper, we propose a solution for the localization problem for IEEE 802.11ayWLAN systems based on signal processing and Machine Learning (ML) in indoor scenarios.First, signal processing is used to estimate the channel in a Doppler and angular domain which separates the signal re lected from the different objects based on their range, velocity and the angular placement.Then, an ML model is used to localize the objects in the different parts of the indoor environment.We use a state-of-the-art ML algorithm such as feed forward neural networks.Further, we evaluate our algorithm for a scenario where there is a room with a transmitter and receiver, and on a dataset generated by a simulator provided by the National Institute of Science and Technology (NIST).We show that the proposed algorithm for localization, which predicts the number of persons in different parts of a room, achieves accuracy of 99% at Signal to Noise Ratio (SNR) of 18 dB and is able to count up to eight persons in a room with 99% accuracy at SNR greater than 0 dB.\n\nINTRODUCTION\n\nIntegrated Sensing And Communication (ISAC) is an emerging ield and an important area towards 6G where along with the information transfer, sensing is also kept in focus while designing the system [1].Sensing using the existing communication resources pave the path for ISAC.For indoor scenarios, a Wi-Fi signal is a viable option for sensing.Sensing revolves around the knowledge of the scattering of rays from the objects, which provide a unique signature about them.The re lected signal at the receiver, helps to localize the objects or even identify them.Machine learning techniques help in identifying patterns or a signature and can map it to the location in the local map [1].\n\nWith the advancement of 5G, there have been signi icant improvements in system frequency and bandwidth.With the increment in system frequency and bandwidth, the wavelength becomes shorter, which results in ine range estimation for object detection [2].Radio Detection And Ranging (RADAR) has been used for detecting objects.In literature, in order to detect objects, a channel is estimated and a range-Doppler or range-angle heatmap is produced [3], [4].A change in environment causes changes in these heatmaps.The heatmap is unique for each different environment and is considered a ingerprint of the context or abstract local map.With the uniqueness in the heatmap, localization and sensing has become an area of interest in the next generation systems [2].\n\nResearch in ISAC has been done to ind the methods for coexistence of communication systems and RADAR.In [5], an architecture of 5G communication systems and RADAR is designed on chip.As 5G mmWave bands have a higher bandwidth compared to a legacy system and it is expected to be even higher for next generation systems, this allows communication systems to be a great platform for high resolution sensing.In [6], several techniques such as waveform design, sensing signal architecture, and antenna distribution are discussed for coexistence of communication and sensing systems.In [7], convergent 6G communication, localization and sensing systems are de ined and its possible solutions are discussed which also involves Artiicial intelligence (AI) and Recon igurable Intelligent Surfaces (RIS).Possible designs of 6G localization and sensing systems are discussed in [2] with a 100 GHz frequency system, RIS and advance signal processing techniques.For applications related to biomedicine and security, Simultaneous Localization And Mapping (SLAM) to automatically construct maps of complex indoor environments are also discussed in the paper.In [2], challenges to make ISAC feasible, are also discussed, such as high-accuracy cm-level positioning and high-resolution 3D sensing/imaging, eficiently sharing resources in time, frequency and space domains, leveraging the real-time energy-ef icient AI/ML techniques.\n\nAn Indoor Positioning System (IPS) using radio waves has been an area of interest in literature and it is seen as an alternative to Global Positioning System (GPS) in indoor scenarios.A Wi-Fi system provides better connectivity than a cellular system and is usually used for indoor localization [8] [9].Signal strength-based localization methods have been popular in literature where multiple access points are used for triangulation to estimate the location of an object of interest.These methods fail to provide ine range resolution with limited access points, performs poorly in a Non-Line-Of-Sight (NLOS) environment and provide a sub-meter level of accuracy [10].\n\nLocalization using radio signals has always been an area of interest.For an indoor scenario, Wi-Fi is viable and a better option than a cellular system.Several methods have been proposed for indoor localization using Wi-Fi signals such as [8], which describes the implementation of a Wi-Fi ingerprinting method using a Received Signal Strength Indicator (RSSI) from access points to determine the position of users in indoor areas.In [9], multiple Wi-Fi sources around the indoor area are used for localization and object tracking and the algorithm primarily relies on a triangulation method.\n\nAs the RSSI-based method suffers in NLOS conditions, in [10], location-speci ic Channel State Information (CSI) is used as a ingerprint and is claimed to provide 5cm precision in an 20cm\u00d770cm area in a non-line-of-sight of ice environment with one link measurement.In [11], a solution for Simultaneous Localization And Mapping (SLAM) is proposed using channel state information.It captures the local spatial geometry of the area using CSI in a channel chart in such a way that points which are closer in space also appears closer in the channel chart.This is done by extracting features from the channel and applying dimensionality reduction algorithms.In [12], a RADAR is used to capture the 2-D RADAR image of the surroundings and that is used as an input for iterative closest point algorithms to solve a SLAM problem.\n\nIn this paper, we present an algorithm based on signal processing and ML for indoor localization in an ISAC kind of setup.We also propose a model for counting the total number of persons in the environment.We use an indoor scenario such as a room and use a radio signal in the form of the channel estimation ield of Wi-Fi signal (IEEE 802.11ay).At the receiver, we estimate the channel in the Doppler and angular domain to extract the features that are relevant for estimation of the users' location such as range, velocity and the angular information of the users.We refer these features as sensible features further in this paper.Finally, we propose machine learning models to map the features to localize and count the persons in the surroundings.Main contributions of the paper are as follows:\n\n\u2022 Estimating channel in angular domain for Wi-Fi signals (IEEE 802.11ay).\n\n\u2022 Methods for extracting sensible features from the raw data of Wi-Fi signals (IEEE 802.11ay) at the receiver for localization tasks.\n\n\u2022 Proposing a machine learning model for the localization of persons in the surrounding environment.\n\nThis paper is organized as follows: Section 2 describes the system model.In Section 3, sensible features are extracted followed by the ML model description in Section 4, and results are presented followed by the conclusion in Section 5.\n\n\nSYSTEM MODEL\n\nWe respectively.Note that, in Fig. 1, the Golay sequence of length 1024 is re-peated twice and padded with smaller length complemen-tary sequences for better channel estimation in presence of inter-symbol interference and thus the CEF length is   . 512 and  512 also follow the following property and said to be orthogonal to each other [13]:\n\ud835\udf13 \ud835\udc34 512 ,\ud835\udc35 512 (\ud835\udc58) = 0; \u2200\ud835\udc58,(2)\nwhere Without Loss of Generality (WLOG), the surrounding environment is assumed to be static and only persons are assumed to be moving with a velocity of  m/s.The transmitted signal gets re lected from the moving persons and environment and the resultant signal is received at   receiver antennas.We consider an  + 1 tap channel () and it can be shown as  = [ 0 ,  1 ,  2 , ...,   ] where the channel for each tap (  ) can be represented as [14]:\n\ud835\udc3b \ud835\udc56 = \u23a1 \u23a2 \u23a3 \u210e 1,1 (\ud835\udc56) \u22ef \u210e 1,\ud835\udc41 \ud835\udc61\ud835\udc65 (\ud835\udc56) \u22ee \u22f1 \u22ee \u210e \ud835\udc41 \ud835\udc5f\ud835\udc65 ,1 (\ud835\udc56) \u22ef \u210e \ud835\udc41 \ud835\udc5f\ud835\udc65 ,\ud835\udc41 \ud835\udc61\ud835\udc65 (\ud835\udc56) \u23a4 \u23a5 \u23a6 ,(3)\nwhere \u210e , () is the channel coef icient for  \u210e tap between  \u210e receiver antenna and  \u210e transmitter antenna.\n\nThe received signal on   antennas can be represented as follows:\n\ud835\udc4c = \ud835\udc3b\ud835\udc4b + \ud835\udc41 ,(4)\nwhere  = [y(0), ..., y(  +  \u2212 1)], where y() = [ 1 (), ..,    ()]  and  is the noise vector.Transmitted signal matrix() is illed with shifted CEF in the rows as follows:\n\ud835\udc4b = \u23a1 \u23a2 \u23a2 \u23a3 x(0) \u22ef \u22ef x(\ud835\udc41 \ud835\udc60 \u2212 1) 0 \ud835\udc41 \ud835\udc61\ud835\udc65 ,1 \u22ef 0 \ud835\udc41 \ud835\udc61\ud835\udc65 ,1 0 \ud835\udc41 \ud835\udc61\ud835\udc65 ,1 x(0) \u22ef x(\ud835\udc41 \ud835\udc60 \u2212 1) 0 \ud835\udc41 \ud835\udc61\ud835\udc65 ,1 \u22ef \u22ee \u22ee \u22f1 \u22f1 \u22f1 \u22f1 \u22f1 0 \ud835\udc41 \ud835\udc61\ud835\udc65 ,1 0 \ud835\udc41 \ud835\udc61\ud835\udc65 ,1 \u22ef 0 \ud835\udc41 \ud835\udc61\ud835\udc65 ,1 x(0) \u22ef \u22ef x(\ud835\udc41 \ud835\udc60 \u2212 1) \u23a4 \u23a5 \u23a5 \u23a6 ,(5)\nwhere x() = [ 1 (), ...,    ()]  is a vector comprising of all the  \u210e elements of the CEF sequence transmitted from all the transmitter antennas.\n\nAs shown in Fig. 2, at the receiver, the channel is estimated in the tap domain.Channel taps can be perceived as a differentiator for the arrival rays at the receiver being re lected from the persons in the surroundings based on time of arrival and thus captures the information to distinguish the persons located in different parts of the surroundings.Further, we convert the channel in the Doppler domain, which further distinguishes the persons based on their movement speed.Then, the channel is converted in an angular domain, which then separates the persons based on their angular separation.The channel in the angular domain provides the sensible features compared with the raw data at the receiver.These sensible features are then fed to a deep learning-based detector.It consists of feed-forward layers and a softmax layer at the output, which predicts the number of persons in all parts of the surrounding area.\n\n\nALGORITHM DESCRIPTION\n\nIn this section, we describe the algorithm to extract sensible features in sections 3.1-3.3which are channel estimation and conversion to a Doppler and angular domain.\n\nAnd inally, deep learning-based detector is explained in Section 3.4.\n\n\nChannel estimation\n\nIn this section, we describe the method for the channel estimation for IEEE 802.11ay signal which is explained in Section 2. Using (4), the channel can be estimated as least square estimate [15] as follows:\n\u0124 = \ud835\udc4c \ud835\udc4b \ud835\udc47 (\ud835\udc4b\ud835\udc4b \ud835\udc47 ) \u22121 .(6)\nNote that using (6), we get an L-tap channel for every transmitter and receiver antenna pair and dimension of  is   \u00d7   \u00d7  for each and every received packet.Channel taps can be seen as a discriminator for arrival rays at the receiver after re lecting off the objects, which are present in the surroundings.Channel taps depict the Time Difference of Arrival (TDoA) of re lected rays from the various objects in the surroundings, and TDoA of various rays depend on the location of the objects.There can be a scenario where re lected rays from the two objects fall under the same tap of the channel.In this scenario, the two objects cannot be distinguished solely based on the channel taps.We exploit the velocity of the objects to distinguish them further, which is explained in the next section.\n\n\nChannel in delay-Doppler domain\n\nIf there is only one object that falls under a channel tap, the phasor corresponding to the channel tap rotates with a speed (let us assume  radian per samples) that is equivalent to the Doppler or velocity of that object.Fourier Transform (FT) of the discrete time signal corresponding to this tap, results in a peak at  in the frequency domain.\n\nLet us consider a scenario where two objects fall under the same tap of channel.If there are two objects that fall under a channel tap, then the signal corresponding to the tap is the sum of the two phasors corresponding to these two objects and the FT of this signal result in two peaks in frequency domain.The two peaks will be at the frequencies corresponding to the speed of the objects.As we know, Fourier transform resolves any signal in its constituent components, thus Fourier transform performed on a tap in the time domain will resolve the Doppler of the objects, which fall under the same tap.\n\nWe consider   consecutive packets in the time domain for Doppler domain channel processing.The duration of a packet is   seconds.The channel is estimated irst for all these   packets as explained in Section 3.1 and can be represented as follows:\n\ud835\udc3b \ud835\udc61 = [\ud835\udc3b(1), ......, \ud835\udc3b(\ud835\udc3e), ...., \ud835\udc3b(\ud835\udc41 \ud835\udc50 )].(7)\nFor coverage enhancement or to gain in the Signal to Noise Ratio (SNR), the averaging of  consecutive channel estimates is done which results in   / size time domain vector of averaged channel estimates (   ).\n\n   =[mean((1), .., ()), ..\n\nThen   /-point Discrete Fourier Transform (DFT) is performed on each channel tap of    for every tx-rx antenna pair to get the channel in the Doppler domain as follows:\n\ud835\udc3b \ud835\udc37\ud835\udc5c\ud835\udc5d\ud835\udc5d \ud835\udc59 (\ud835\udc51)[\ud835\udc5a, \ud835\udc5b] = DFT(\ud835\udc3b \ud835\udc61 \ud835\udc4e\ud835\udc63\ud835\udc54 \ud835\udc59 [\ud835\udc5a, \ud835\udc5b])(\ud835\udc51),(9)\nwhere  \u2208 {0 \u22ef } is the tap index of the channel,  \u2208 {1 \u22ef   } and  \u2208 {1 \u22ef   } are the receiver and transmitter antenna index and  \u2208 {1 \u22ef    } is the Doppler index or  \u210e bin of DFT.Multiple objects, which fall under the same tap index, can be distinguished now in the Doppler domain.Note that if the two objects which are in same channel tap, have a similar velocity then there is a possibility that these two objects fall under the same tap and Doppler bin and then they can't be distinguished with the Doppler domain channel.\n\nLet us consider a scenario where there are two persons moving with velocity  \u210e1 and  \u210e2 respectively and they fall under the same channel tap.Phasors corresponding to both the persons rotate with the speed  \u210e1 and  \u210e2 radian per samples respectively.A sampling period of the signal    is   ,  \u210e1 and  \u210e2 can be represented as follows:\n\ud835\udf14 \u210e1 = 2\ud835\udf0b\ud835\udc39 \u0394\ud835\udf0f 1 , \ud835\udf14 \u210e2 = 2\ud835\udf0b\ud835\udc39 \u0394\ud835\udf0f 2 , (10)\nwhere  is the carrier frequency.\u0394 1 is the time difference of the rays which are arriving at the receiver, associated with the phase change during the sampling period and can be further simpli ied and written in terms of velocity as:  \u210e1  \n\n\n\ud835\udc50\n\n. Similarly, \u0394 2 can be written as  \u210e2    .A property of Fourier Transform (FT) states that the difference between two consecutive constituent components should be larger than the inverse of number of resolvable bins.Velocity resolution (  ) i.e. minimum velocity difference between two objects, which is needed for them to distinguish, can be estimated using the FT property as follows:\n\ud835\udf14 \u210e2 \u2212 \ud835\udf14 \u210e1 > 2\ud835\udf0b \ud835\udc41 \ud835\udc50 /\ud835\udc3e \u27f9 2\ud835\udf0b\ud835\udc39 \ud835\udc3e\ud835\udc47 \ud835\udc50 (\ud835\udc63 \u210e2 \u2212 \ud835\udc63 \u210e1 ) \ud835\udc50 > 2\ud835\udf0b \ud835\udc41 \ud835\udc50 /\ud835\udc3e putting \ud835\udc39 = \ud835\udc50/\ud835\udf06, \u27f9 \ud835\udc3e\ud835\udc47 \ud835\udc50 (\ud835\udc63 \u210e2 \u2212 \ud835\udc63 \u210e1 ) \ud835\udf06 > 1 \ud835\udc41 \ud835\udc50 /\ud835\udc3e \u27f9 \ud835\udc63 \u210e2 \u2212 \ud835\udc63 \u210e1 > \ud835\udf06 \ud835\udc41 \ud835\udc50 \ud835\udc47 \ud835\udc50 \u27f9 \ud835\udc49 \ud835\udc5f\ud835\udc52\ud835\udc60 = \ud835\udf06 \ud835\udc41 \ud835\udc50 \ud835\udc47 \ud835\udc50 .(11)\nAs shown in (11), velocity resolution depends on the number of the samples used for Doppler domain processing and the time duration of a packet.\n\n\nChannel in delay-Doppler-angular domain\n\nLet us consider a scenario where two objects fall under the same channel tap and Doppler bin (i.e.\u0394 <      ) as shown in (11), they cannot be distinguished solely based on the Doppler domain channel, so we further explore the spatial dimension to make them differentiable.The objective of the conversion of the Doppler domain channel to angular domain, is to resolve the transmit and arrival paths of rays into angular bins.A channel is said to be the sum of multiple paths that originate from the transmitter and arrive at the receiver as follows [16]:\n\ud835\udc3b = \u2211 \ud835\udc56 \ud835\udc4e \ud835\udc56 \ud835\udc52 \ud835\udc5f (\u03a9 \ud835\udc5f\ud835\udc56 )\ud835\udc52 \ud835\udc61 (\u03a9 \ud835\udc61\ud835\udc56 ),(12)\nwhere   is the attenuation associated with the  \u210e path.\n\nThe  \u210e path makes the angle   with the receiver antenna array and   with the transmitter antenna array and \u03a9  and \u03a9  are the respective direction cosines.  (\u03a9) and   (\u03a9) are the transmitted and received unit spatial signature, respectively, along the direction \u03a9 and is calculated as follows [16]:\n\ud835\udc52 \ud835\udc5f (\u03a9) = 1 \u221a(\ud835\udc41 \ud835\udc5f\ud835\udc65 ) \u23a1 \u23a2 \u23a2 \u23a3 1 \ud835\udc52\ud835\udc65\ud835\udc5d(\u2212\ud835\udc572\ud835\udf0b\u0394 \ud835\udc5f \u03a9) \u22ee \ud835\udc52\ud835\udc65\ud835\udc5d(\u2212\ud835\udc572\ud835\udf0b(\ud835\udc41 \ud835\udc5f\ud835\udc65 \u2212 1)\u0394 \ud835\udc5f \u03a9) \u23a4 \u23a5 \u23a5 \u23a6 , (13) \ud835\udc52 \ud835\udc61 (\u03a9) = 1 \u221a(\ud835\udc41 \ud835\udc61\ud835\udc65 ) \u23a1 \u23a2 \u23a2 \u23a3 1 \ud835\udc52\ud835\udc65\ud835\udc5d(\u2212\ud835\udc572\ud835\udf0b\u0394 \ud835\udc61 \u03a9) \u22ee \ud835\udc52\ud835\udc65\ud835\udc5d(\u2212\ud835\udc572\ud835\udf0b(\ud835\udc41 \ud835\udc61\ud835\udc65 \u2212 1)\u0394 \ud835\udc61 \u03a9) \u23a4 \u23a5 \u23a5 \u23a6 ,(14)\nwhere \u0394  and \u0394  are the separation between consecutive antennas normalized by wavelength in the receiver and transmitter antenna arrays.For received signal space, an orthonormal basis can be written as follows [16]:\n\ud835\udf0e \ud835\udc5f = {\ud835\udc52 \ud835\udc5f (0), \ud835\udc52 \ud835\udc5f ( 1 \ud835\udc3f \ud835\udc5f ), ...., \ud835\udc52 \ud835\udc5f ( \ud835\udc41 \ud835\udc5f\ud835\udc65 \u2212 1 \ud835\udc3f \ud835\udc5f )},(15)\nwhere   is length of the receiver antenna array normalized by wavelength.Similarly, the basis for transmit signal space can also be constructed as   .Receive and transmit signals can be represented in the angular domain using basis   and   .Transmitted signal () and received signal ( ) can be represented in the angular domain as follows [16]:\n\ud835\udc4b \ud835\udc4e = \ud835\udc48 * \ud835\udc61 \ud835\udc4b, \ud835\udc4c \ud835\udc4e = \ud835\udc48 * \ud835\udc5f \ud835\udc4c ,(16)\nwhere   and   are the unitary matrices in the signal spaces   and   respectively and can be calculated as follows [16]:\n\ud835\udc48 \ud835\udc61 (\ud835\udc58, \ud835\udc59) = 1 \u221a\ud835\udc41 \ud835\udc61\ud835\udc65 \ud835\udc52\ud835\udc65\ud835\udc5d( \u2212\ud835\udc572\ud835\udf0b\ud835\udc58\ud835\udc59 \ud835\udc41 \ud835\udc61\ud835\udc65 ), \ud835\udc48 \ud835\udc5f (\ud835\udc58, \ud835\udc59) = 1 \u221a\ud835\udc41 \ud835\udc5f\ud835\udc65 \ud835\udc52\ud835\udc65\ud835\udc5d( \u2212\ud835\udc572\ud835\udf0b\ud835\udc58\ud835\udc59 \ud835\udc41 \ud835\udc5f\ud835\udc65 ),(17)\nwhere ,  \u2208 {0 \u22ef   \u2212 1} for   and ,  \u2208 {0 \u22ef   \u2212 1} for   .The angular domain channel can be calculated by putting ( 16) into (4) as follows:\n\ud835\udc3b \ud835\udc4e = \ud835\udc48 * \ud835\udc5f \ud835\udc3b \ud835\udc37\ud835\udc5c\ud835\udc5d\ud835\udc5d \ud835\udc48 \ud835\udc61 .(18)\nThe dimension of   are   \u00d7   \u00d7  \u00d7    , where the irst two dimensions are for angular bins for receiver and transmitter, third dimension is for channel taps and the last dimension is for Doppler bins.This angular domain channel helps in distinguishing the objects further based on angular separation and is used as the input for a deep learning model.\n\n\nDeep learning model for localization\n\nIn this section, the architecture of a Deep Learning (DL) model is described.WLOG, let us assume the surrounding environment is divided into multiple sectors (a total of  sectors).There are a maximum of  persons present in the surroundings with a maximum of  persons in each sector.The DL model predicts how many persons are present in each sector, which is referred to as a localization model.We train another DL model, which is referred to as a counting model and it is trained to predict the total number of persons which are present in the surrounding environment (a maximum of  persons).Absolute value of the channel in the angular domain is used as the input.As shown in Fig. 4, absolute values of the angular channel is fed to a couple of  layers and followed by a softmax layer.For the localization model, the output layer consists of  softmax neurons for each of the  sectors and for the counting model, the output layer is a softmax layer of  neurons.The counting model is used for post-processing of the prediction of the localization model for improving the accuracy.\n\n\nChannel in range-\n\n\nEXPERIMENTAL SETUP AND PERFOR-MANCE EVALUATION\n\nFor the experimental setup, we have considered a dataset provided by National Institute of Technology and Science, USA.The dataset is generated using an IEEE 802.11AayWLAN simulator [17], [18] and it considers an indoor scenario, speci ically a room of dimension (7.8m \u00d77m \u00d73m), which is divided into a total of 9 sectors (sector  to ) as shown in Fig. 6.There are two access points which communicate using IEEE 802.11ay packets, one of which is the transmitter and located at (\u22123.9, 0, 2.8) and the other is the receiver located at (3.9, 0, 2.8).There can be a maximum of four persons in any sector and maximum eight persons in the room.In this simulator, persons are mod-elled as 17 joints for scattering of rays and velocity of persons is around \u2248 1 m/s.The aim is to ind the number of persons in each sector using the received signal.For example, in Fig. 6, there is one person each in sector  and  and the rest of the sectors have 0 persons.For training of the DL model, a total of 15578 different arrangements of persons in the room are considered.Data is generated for multiple Signal to Noise Ratio (SNR) points ranging from \u221218dB to 18dB.In the DL model, there are two dense layers of 3000 and 500 neurons respectively.We have used the Recti ied Linear unit () for activation with L2 regularization.For the localization model, 5  neurons are used for each sectors summing up to a total of 45 neurons.For the counting model, total 9  neurons are used.To avoid over itting, we have used an ADAM optimizer with learning rate 0.0005 and exponential decay every 10000 steps where 1 step training involves 32 samples and the model is trained for 200 epochs.The dataset is imbalanced and there are more samples for less number of persons in any sector, so a weighted learning has been used for different labels.For testing, samples are generated with different noise vectors using the simulator.\n\nThe channel is estimated as mentioned in Section 3.1 and its dimensions are 4\u00d74\u00d745\u00d7128, where the 4 \u210e dimension represents the number of packets (  ) and the other three represent the same information as mentioned in Section 3.1.Then the channel is averaged for  = 8 consecutive times and processed for Doppler domain conversion (Section 3.2) and the dimensions of this channel come out to be 4 \u00d7 4 \u00d7 45 \u00d7 16.Then, they are converted to the angular domain (Section 3.3) and absolute value of this channel is then fed to the DL model (Section 3.4).\n\nWe have drawn the results for both counting model and localization model.For performance evaluation, accuracy of the counting model is drawn and shown in Table 1 which is number of times the total number of persons in the room are predicted correctly.As shown in Table 1, for the dataset with good signal condition, the model predicts correctly for almost all the samples.We have also drawn the counting model results for different numbers of persons present in the room.In the dataset, there are upto eight persons present in the room.We plot the accuracy of the counting model w.r.t number of persons (total 8 plots correspond to the number of persons present in the room) for various SNR points and is shown in Fig. 7.The localization model is also evaluated and its accuracy drawn and shown in Table 2 which is the number of times the total number of persons in each sector is predicted correctly.Here, even if prediction of one sector mismatches from the true label out of nine sectors, we mark it a failure case for the sample.Only if the prediction of all the sectors matches with the true labels, the sample is marked as a success case.Hence, the accuracy of the localization model is less than the counting model.For poor signal conditions, such as SNR -18dB, there is not enough signal information for the DL model to make an accurate prediction.\n\nAs we explained earlier that if the localization model fails to predict only one sector out of the total nine sectors, we mark that sample as a failure for localization model accuracy.In Fig. 8, we compare the accuracy of sectorspeci ic prediction for different numbers of persons with SNR.Here, we consider the prediction of each sector as an independent prediction and show that the accuracy of sector-wise prediction degrades with the increment in the number of the persons in the sectors.At an SNR greater than 0 dB, accuracy of the sector-wise prediction is greater than 95% for any number of persons in the sector.At a lower SNR i .e. SNR lower than \u221210 dB, accuracy of the sector-wise prediction decreases with the increment in the number of persons as shown in Fig. 8. Finally, we discuss the resolutions in the range, velocity and angular domain.In this paper, irst we have tried to distinguish the persons as far as possible using channel estimation and signal processing.We have used machine learning to analyse the extracted features for localization.Two persons can be distinguished if they fall under different taps which means delay in arrival of rays scattered from the two persons should be greater than 0.56 ns (=1/1.76GHz).This information suggests if the separation of persons is more than 17 cm, they can be distinguished.Similarly, using (11) are of size 1/  and 1/  for the receiver and transmitter respectively i.e. 0.5 and 0.5 radian which is 28  for both transmitter and receiver.\n\n\nCONCLUSION\n\nIn this paper, we proposed an indoor localization method, which can assist the research of Integrated Sensing And Communication (ISAC).We observed near-perfect localization accuracy with the collected data.The proposed algorithm contributes to the emerging ISAC technology and is easy to implement.We used both signal processing and machine learning to separate out multiple persons and localize them, which is a novel method.Our future work involves person identi ication along with localization and contribution towards simultaneous location and mapping.\n\nFig. 2 -\n2\nFig. 2 -System model: Signal processing on the raw inputs followed by a machine learning model-based detector for localization\n\n\nFig. 3 -\n3\nFig.3-Channel conversion to Doppler domain: There are total   packets and channel of  consecutive packets are grouped together for averaging.An   /-point DFT is performed for each channel tap.\n\n\n.\n\n., mean(((    \u2212 1)), .., (  )].\n\n\nFig. 4 -\n4\nFig.4 -Deep learning model: Channel in range Doppler angular domain is the input and at output layer, two models are proposed.A counting model which predict the count, the total number of persons in the surroundings (maximum is ) and a localization model which predicts the number of persons in each area of surroundings (a total of  sectors and a maximum of  persons in each sector).Note that, we are using two different neural networks with the same structure for localization and counting activities.\n\n\nFig. 5 Fig. 5 -\n55\nFig. 5 -Post-processing for the localization model predictions: Total number of persons predicted by the counting model is   and by the localization model is   .Result of the localization model is updated with this algorithm until   matches with   .\n\n\nFig. 6 -\n6\nFig. 6 -Experimental setup: A room is considered for dataset generation and it is divided into nine sectors.Samples are generated with different arrangements of the persons in the room.For example, in this igure, there is a person in sector  and  and the rest of the sectors are empty.In this dataset, a training sample corresponds to the transmission of an IEEE 802.11ay packet repeating   = 128 times using   = 4 antennas.We take only the CEF part of the packets for sensing or localization.The dimension of the signal transmitted is 2432 \u00d7 4 \u00d7 128 which is (  \u00d7   \u00d7   ).The carrier frequency is 60 GHz, sampling frequency is 1.76 GHz and the number of channel taps are  = 45 .At the receiver, the signal is received at   = 4 antennas and its dimension is 2476 \u00d7 4 \u00d7 128 (  +  \u2212 1 \u00d7   \u00d7   ).\n\n\nFig. 7 -\n7\nFig. 7 -Counting model accuracy plot w.r.t different number of persons in the room vs SNR.\n\n\nFig. 8 -\n8\nFig. 8 -Accuracy plot based on number of persons in a sector: Localization model prediction accuracy when the sectors are considered as independent samples and the plot shows the accuracy vs SNR performance with different numbers of persons in the sectors.\n\n\n\n\n  512 , 512 () is  \u2212 \u210e element of the crosscorrelation function of sequence  512 and  512 .  seconds over   antennas.The signal of interest is Channel Estimation Field (CEF) which consists of a Golay sequence of length 1024 containing two complementary sequences  512 and  512 .\nChannelestimation fieldTime#1Time#2A512 B512 A128 B128 A512 B512 A128802.11ay packetA512 B512 A128 B128 A512 B512 A128802.11ay packetGolay sequenceTp msSignal transmittedNsxNtxNo. of Tx antennaFig. 1 -Transmitted signal structure of an 802.11ay system: Packets aretransmitted with a period\n\nTable 1 -\n1\nCounting model accuracy: % Number of samples for which the model predicts correctly the total number of persons in the room.\nSNR (dB) Accuracy%1899.901099.82599.76099.60\u2212597.23\u22121074.34\u22121839.01\n\nTable 2 -\n2\nLocalization model accuracy: % Number of samples in which model predicts correctly the number of persons in each sector.\nSNR (dB) Accuracy%1899.001096.09593.68083.13\u2212544.74\u2212105.97\u2212182.00\n\n\n\n[16]locity resolution is 4 cm/sec where  is 5mm as the carrier frequency is 60GHz,   is 128 and   is 1ms.Considering 16 Doppler domain bins, two persons with a velocity difference up to 64 cm/sec can be distinguished if they are at least 4 cm/sec apart in velocity.For angular resolution[16], it can be calculated using a normalized length of antenna array (  and   ) which is 2 with   and   being 4 and resolvable angular bins\n\n\u00a9 International Telecommunication Union, 2022\n\n\u00a9 International Telecommunication Union, 2022 ITU Journal on Future and Evolving Technologies, Volume 3, Issue 2, September 2022\n\u00a9 International Telecommunication Union, 2022 Khunteta et al.: AI-based indoor localization using mmWave MIMO channel at 60 GHz\nACKNOWLEDGMENTWe thank the International Telecommunication Union (ITU) AI/ML 5G challenge team and NIST, USA for providing the dataset and simulator for generating the dataset.The problem statement was one of the open challenges of ITU AI/ML challenge in 5G, 2021 and it was organised by NIST, USA.The solution provided in this paper won the challenge for problem statement PS002 in the 2021 edition of ITU AI/ML for 5G challenge.AUTHORSShubham Khunteta received a Bachelor of Technology degree in electrical engineering from the Indian Institute of Technology, Kanpur, India, in 2014.He joined Samsung R&D Institute India Bangalore, India in July 2014, where he currently is an engineer in a research and development team that works on differentiating solutions for mobile devices.His research interests include algorithm design for the physical layer, beam management, machine learning-assisted communications, integrated sensing and communication, 5G NR systems, 6G, millimeter-wave and machine learning for communications.Ashok Kumar Reddy Chavva (M'06-SM'14) received his Bachelor of Technology degree in electronics and communications engineering from the Jawaharlal Nehru Technological University, Hyderabad, India, in 2003, and an M.E.degree in telecommunication engineering from the Indian Institute of Science, Bangalore, India, in 2005.In June 2005, he joined a wireless startup, Beceem Communications, which later became part of Broadcom.Here, he was involved in developing physical layer algorithms for the irst 4G system based on WiMAX and LTE.He worked with Broadcom till November 2013.Since November 2013, he has been with Samsung R&D Institute India Bangalore, India, where he currently leads an R&D team that works on beyond-5G system design.He is currently pursuing his Ph.D. degree in electrical communication engineering from the Indian Institute of Science.His research interests include algorithm design for the physical layer, performance evaluation of wireless communication systems, 5G NR systems, 6G, millimeterwave and tera-hertz systems, and machine learning for communications.He received the best paper award at IEEE CCNC, Las Vegas, USA, 2016 and best paper (third) at the IEEE World 5G Forum, 2020.Avani Agrawal received a Bachelor of Technology degree in electronics and communications engineering from the International Institute of Information and Technology, Hyderabad, India, in 2020.Since June 2019, she has been with Samsung R&D Institute India Bangalore, India and is a member of the Beyond 5G team in the Mobile Communications Department.Her interest areas include machine learning, computer vision and algorithm development for software.\nIntegrated Sensing and Communication in 6G: Motivations, Use Cases, Requirements, Challenges and Future Directions. Danny Kai, Pin Tan, Jia He, Yanchun Li, Alireza Bayesteh, Yan Chen, Peiying Zhu, Wen Tong, 10.1109/JCS52304.2021.93763242021\n\n6G White Paper on Localization and Sensing. Andre Bourdoux, arXiv:2006.01779v1[eess.SY]2020\n\nRAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. X Gao, arXiv:2011.08981v2[eess.SP]2022\n\nExperiments with mmWave Automotive Radar Test-bed. X Gao, arXiv:1912.12566v3[eess.SP]2022\n\nMillimeter-Wave Radarson-Chip Enabling Next-Generation Cyberphysical Infrastructures. H Aghasi, P Heydari, 10.1109/mcom.001.2000544IEEE Communications Magazine. 2021\n\nJoint Design of Communication and Sensing for Beyond 5G and 6G Systems. T Wild, 10.1109/ACCESS.2021.3059488IEEE Access. 92021\n\nConvergent Communication, Sensing and Localization in 6G Systems: An Overview of Technologies, Opportunities, and Challenges. Carlos D Lima, 10.1109/AC-CESS.2021.30534862021IEEE access\n\nIndoor localization using Wi-Fi method based on Fingerprinting Technique. H Chabbar, M Chami, 10.1109/WITS.2017.7934613International Conference on Wireless Technologies, Embedded and Intelligent Systems (WITS). 2017\n\nIndoor Localization System Using Wi-Fi Technology. A K Z Noor, S Muayad, 10.33103/uot.ijccce.19.2.8Communications, Control and System Engineering (IJCCCE). 192019Iraqi Journal of Computers\n\nHigh accuracy indoor localization: A WiFi-based approach. C Chen, Y Chen, 10.1109/ICASSP.2016.7472878IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 2016\n\nChannel Charting: Locating Users within the Radio Environment using Channel State Information. C Studer, S Medjkouh, arXiv:1807.052472018\n\nIndoor radar SLAM A radar application for vision and GPS denied environments. J W Marck, 2013European Radar Conference\n\nComplementary set of Sequences. Liu Tseng, IEEE Transactions on Information Theory. 185\n\nA. Aperiodic Complementary Sets of Sequences-Based MIMO Frequency Selective Channel Estimation. S Wang, Abdi , IEEE Communication Letters. 910\n\nSpace-Time Block Coding for Wireless Communications. E G Larsson, P Stoica, 2003Cambridge University PressCambridge, UK\n\nFundamentals of Wireless Communication. Vishwanath Tse, 2005In: Chapter: 7.3.4 Angular Domain Representation of MIMO Channels\n\nA collection of open-source tools to simulate IEEE 802.11ad/ay WLAN networks in network simulator ns-3. 2021\n\nQ-D simulation & Modeling framework for sensing. 2021\n", "annotations": {"author": "[{\"end\":220,\"start\":69},{\"end\":294,\"start\":221},{\"end\":364,\"start\":295}]", "publisher": null, "author_last_name": "[{\"end\":85,\"start\":77},{\"end\":238,\"start\":233},{\"end\":308,\"start\":301}]", "author_first_name": "[{\"end\":76,\"start\":69},{\"end\":226,\"start\":221},{\"end\":232,\"start\":227},{\"end\":300,\"start\":295}]", "author_affiliation": "[{\"end\":164,\"start\":111},{\"end\":219,\"start\":166},{\"end\":293,\"start\":240},{\"end\":363,\"start\":310}]", "title": "[{\"end\":66,\"start\":1},{\"end\":430,\"start\":365}]", "venue": null, "abstract": "[{\"end\":2581,\"start\":548}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2797,\"start\":2794},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3279,\"start\":3276},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3533,\"start\":3530},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3730,\"start\":3727},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3735,\"start\":3732},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4040,\"start\":4037},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4150,\"start\":4147},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4454,\"start\":4451},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4627,\"start\":4624},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4914,\"start\":4911},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5193,\"start\":5190},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5758,\"start\":5755},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5762,\"start\":5759},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6127,\"start\":6123},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6372,\"start\":6369},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6567,\"start\":6564},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6784,\"start\":6780},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6996,\"start\":6992},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7384,\"start\":7380},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9252,\"start\":9248},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9730,\"start\":9726},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11900,\"start\":11896},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":16194,\"start\":16190},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":16491,\"start\":16487},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16918,\"start\":16914},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17313,\"start\":17309},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17704,\"start\":17700},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18113,\"start\":18109},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18268,\"start\":18264},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20252,\"start\":20248},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20258,\"start\":20254},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25236,\"start\":25232},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":26350,\"start\":26349}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":26089,\"start\":25950},{\"attributes\":{\"id\":\"fig_1\"},\"end\":26295,\"start\":26090},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26332,\"start\":26296},{\"attributes\":{\"id\":\"fig_3\"},\"end\":26849,\"start\":26333},{\"attributes\":{\"id\":\"fig_4\"},\"end\":27120,\"start\":26850},{\"attributes\":{\"id\":\"fig_5\"},\"end\":27927,\"start\":27121},{\"attributes\":{\"id\":\"fig_6\"},\"end\":28031,\"start\":27928},{\"attributes\":{\"id\":\"fig_7\"},\"end\":28301,\"start\":28032},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":28873,\"start\":28302},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":29079,\"start\":28874},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":29279,\"start\":29080},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":29758,\"start\":29280}]", "paragraph": "[{\"end\":3280,\"start\":2597},{\"end\":4041,\"start\":3282},{\"end\":5458,\"start\":4043},{\"end\":6128,\"start\":5460},{\"end\":6722,\"start\":6130},{\"end\":7545,\"start\":6724},{\"end\":8344,\"start\":7547},{\"end\":8419,\"start\":8346},{\"end\":8554,\"start\":8421},{\"end\":8656,\"start\":8556},{\"end\":8894,\"start\":8658},{\"end\":9253,\"start\":8911},{\"end\":9731,\"start\":9285},{\"end\":9925,\"start\":9819},{\"end\":9991,\"start\":9927},{\"end\":10177,\"start\":10008},{\"end\":10496,\"start\":10351},{\"end\":11419,\"start\":10498},{\"end\":11612,\"start\":11445},{\"end\":11683,\"start\":11614},{\"end\":11912,\"start\":11706},{\"end\":12734,\"start\":11939},{\"end\":13116,\"start\":12770},{\"end\":13722,\"start\":13118},{\"end\":13969,\"start\":13724},{\"end\":14225,\"start\":14016},{\"end\":14253,\"start\":14227},{\"end\":14423,\"start\":14255},{\"end\":14999,\"start\":14474},{\"end\":15335,\"start\":15001},{\"end\":15616,\"start\":15377},{\"end\":16009,\"start\":15622},{\"end\":16322,\"start\":16178},{\"end\":16919,\"start\":16366},{\"end\":17015,\"start\":16960},{\"end\":17314,\"start\":17017},{\"end\":17705,\"start\":17490},{\"end\":18114,\"start\":17770},{\"end\":18269,\"start\":18150},{\"end\":18495,\"start\":18356},{\"end\":18875,\"start\":18525},{\"end\":19995,\"start\":18916},{\"end\":21963,\"start\":20066},{\"end\":22512,\"start\":21965},{\"end\":23870,\"start\":22514},{\"end\":25378,\"start\":23872},{\"end\":25949,\"start\":25393},{\"end\":26088,\"start\":25962},{\"end\":26294,\"start\":26102},{\"end\":26331,\"start\":26300},{\"end\":26848,\"start\":26345},{\"end\":27119,\"start\":26870},{\"end\":27926,\"start\":27133},{\"end\":28030,\"start\":27940},{\"end\":28300,\"start\":28044},{\"end\":28583,\"start\":28305},{\"end\":29011,\"start\":28887},{\"end\":29213,\"start\":29093},{\"end\":29710,\"start\":29283},{\"end\":29757,\"start\":29712}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9284,\"start\":9254},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9818,\"start\":9732},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10007,\"start\":9992},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10350,\"start\":10178},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11938,\"start\":11913},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14015,\"start\":13970},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14473,\"start\":14424},{\"attributes\":{\"id\":\"formula_8\"},\"end\":15375,\"start\":15336},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15376,\"start\":15375},{\"attributes\":{\"id\":\"formula_10\"},\"end\":16177,\"start\":16010},{\"attributes\":{\"id\":\"formula_11\"},\"end\":16959,\"start\":16920},{\"attributes\":{\"id\":\"formula_12\"},\"end\":17489,\"start\":17315},{\"attributes\":{\"id\":\"formula_13\"},\"end\":17769,\"start\":17706},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18149,\"start\":18115},{\"attributes\":{\"id\":\"formula_15\"},\"end\":18355,\"start\":18270},{\"attributes\":{\"id\":\"formula_16\"},\"end\":18524,\"start\":18496}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22675,\"start\":22674},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22784,\"start\":22783},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23319,\"start\":23318}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2595,\"start\":2583},{\"attributes\":{\"n\":\"2.\"},\"end\":8909,\"start\":8897},{\"attributes\":{\"n\":\"3.\"},\"end\":11443,\"start\":11422},{\"attributes\":{\"n\":\"3.1\"},\"end\":11704,\"start\":11686},{\"attributes\":{\"n\":\"3.2\"},\"end\":12768,\"start\":12737},{\"end\":15620,\"start\":15619},{\"attributes\":{\"n\":\"3.3\"},\"end\":16364,\"start\":16325},{\"attributes\":{\"n\":\"3.4\"},\"end\":18914,\"start\":18878},{\"end\":20015,\"start\":19998},{\"attributes\":{\"n\":\"4.\"},\"end\":20064,\"start\":20018},{\"attributes\":{\"n\":\"5.\"},\"end\":25391,\"start\":25381},{\"end\":25959,\"start\":25951},{\"end\":26099,\"start\":26091},{\"end\":26298,\"start\":26297},{\"end\":26342,\"start\":26334},{\"end\":26866,\"start\":26851},{\"end\":27130,\"start\":27122},{\"end\":27937,\"start\":27929},{\"end\":28041,\"start\":28033},{\"end\":28884,\"start\":28875},{\"end\":29090,\"start\":29081}]", "table": "[{\"end\":28873,\"start\":28584},{\"end\":29079,\"start\":29012},{\"end\":29279,\"start\":29214}]", "figure_caption": "[{\"end\":26089,\"start\":25961},{\"end\":26295,\"start\":26101},{\"end\":26332,\"start\":26299},{\"end\":26849,\"start\":26344},{\"end\":27120,\"start\":26869},{\"end\":27927,\"start\":27132},{\"end\":28031,\"start\":27939},{\"end\":28301,\"start\":28043},{\"end\":28584,\"start\":28304},{\"end\":29012,\"start\":28886},{\"end\":29214,\"start\":29092},{\"end\":29711,\"start\":29282}]", "figure_ref": "[{\"end\":8947,\"start\":8946},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10516,\"start\":10515},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19599,\"start\":19598},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":20420,\"start\":20419},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":20926,\"start\":20925},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":23234,\"start\":23233},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":24065,\"start\":24064},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":24647,\"start\":24646}]", "bib_author_first_name": "[{\"end\":32818,\"start\":32813},{\"end\":32827,\"start\":32824},{\"end\":32836,\"start\":32833},{\"end\":32848,\"start\":32841},{\"end\":32860,\"start\":32853},{\"end\":32874,\"start\":32871},{\"end\":32888,\"start\":32881},{\"end\":32897,\"start\":32894},{\"end\":32988,\"start\":32983},{\"end\":33116,\"start\":33115},{\"end\":33207,\"start\":33206},{\"end\":33333,\"start\":33332},{\"end\":33343,\"start\":33342},{\"end\":33486,\"start\":33485},{\"end\":33674,\"start\":33666},{\"end\":33801,\"start\":33800},{\"end\":33812,\"start\":33811},{\"end\":33995,\"start\":33994},{\"end\":33999,\"start\":33996},{\"end\":34007,\"start\":34006},{\"end\":34192,\"start\":34191},{\"end\":34200,\"start\":34199},{\"end\":34419,\"start\":34418},{\"end\":34429,\"start\":34428},{\"end\":34541,\"start\":34540},{\"end\":34543,\"start\":34542},{\"end\":34617,\"start\":34614},{\"end\":34768,\"start\":34767},{\"end\":34779,\"start\":34775},{\"end\":34869,\"start\":34868},{\"end\":34871,\"start\":34870},{\"end\":34882,\"start\":34881},{\"end\":34986,\"start\":34976}]", "bib_author_last_name": "[{\"end\":32822,\"start\":32819},{\"end\":32831,\"start\":32828},{\"end\":32839,\"start\":32837},{\"end\":32851,\"start\":32849},{\"end\":32869,\"start\":32861},{\"end\":32879,\"start\":32875},{\"end\":32892,\"start\":32889},{\"end\":32902,\"start\":32898},{\"end\":32997,\"start\":32989},{\"end\":33120,\"start\":33117},{\"end\":33211,\"start\":33208},{\"end\":33340,\"start\":33334},{\"end\":33351,\"start\":33344},{\"end\":33491,\"start\":33487},{\"end\":33679,\"start\":33675},{\"end\":33809,\"start\":33802},{\"end\":33818,\"start\":33813},{\"end\":34004,\"start\":34000},{\"end\":34014,\"start\":34008},{\"end\":34197,\"start\":34193},{\"end\":34205,\"start\":34201},{\"end\":34426,\"start\":34420},{\"end\":34438,\"start\":34430},{\"end\":34549,\"start\":34544},{\"end\":34623,\"start\":34618},{\"end\":34773,\"start\":34769},{\"end\":34879,\"start\":34872},{\"end\":34889,\"start\":34883},{\"end\":34990,\"start\":34987}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.1109/JCS52304.2021.9376324\",\"id\":\"b0\"},\"end\":32937,\"start\":32697},{\"attributes\":{\"doi\":\"arXiv:2006.01779v1[eess.SY]\",\"id\":\"b1\"},\"end\":33030,\"start\":32939},{\"attributes\":{\"doi\":\"arXiv:2011.08981v2[eess.SP]\",\"id\":\"b2\"},\"end\":33153,\"start\":33032},{\"attributes\":{\"doi\":\"arXiv:1912.12566v3[eess.SP]\",\"id\":\"b3\"},\"end\":33244,\"start\":33155},{\"attributes\":{\"doi\":\"10.1109/mcom.001.2000544\",\"id\":\"b4\",\"matched_paper_id\":230510984},\"end\":33411,\"start\":33246},{\"attributes\":{\"doi\":\"10.1109/ACCESS.2021.3059488\",\"id\":\"b5\",\"matched_paper_id\":232061801},\"end\":33538,\"start\":33413},{\"attributes\":{\"doi\":\"10.1109/AC-CESS.2021.3053486\",\"id\":\"b6\"},\"end\":33724,\"start\":33540},{\"attributes\":{\"doi\":\"10.1109/WITS.2017.7934613\",\"id\":\"b7\",\"matched_paper_id\":23282049},\"end\":33941,\"start\":33726},{\"attributes\":{\"doi\":\"10.33103/uot.ijccce.19.2.8\",\"id\":\"b8\",\"matched_paper_id\":230140975},\"end\":34131,\"start\":33943},{\"attributes\":{\"doi\":\"10.1109/ICASSP.2016.7472878\",\"id\":\"b9\",\"matched_paper_id\":8100653},\"end\":34321,\"start\":34133},{\"attributes\":{\"doi\":\"arXiv:1807.05247\",\"id\":\"b10\"},\"end\":34460,\"start\":34323},{\"attributes\":{\"id\":\"b11\"},\"end\":34580,\"start\":34462},{\"attributes\":{\"id\":\"b12\"},\"end\":34669,\"start\":34582},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":16325040},\"end\":34813,\"start\":34671},{\"attributes\":{\"id\":\"b14\"},\"end\":34934,\"start\":34815},{\"attributes\":{\"id\":\"b15\"},\"end\":35061,\"start\":34936},{\"attributes\":{\"id\":\"b16\"},\"end\":35171,\"start\":35063},{\"attributes\":{\"id\":\"b17\"},\"end\":35226,\"start\":35173}]", "bib_title": "[{\"end\":33330,\"start\":33246},{\"end\":33483,\"start\":33413},{\"end\":33798,\"start\":33726},{\"end\":33992,\"start\":33943},{\"end\":34189,\"start\":34133},{\"end\":34612,\"start\":34582},{\"end\":34765,\"start\":34671}]", "bib_author": "[{\"end\":32824,\"start\":32813},{\"end\":32833,\"start\":32824},{\"end\":32841,\"start\":32833},{\"end\":32853,\"start\":32841},{\"end\":32871,\"start\":32853},{\"end\":32881,\"start\":32871},{\"end\":32894,\"start\":32881},{\"end\":32904,\"start\":32894},{\"end\":32999,\"start\":32983},{\"end\":33122,\"start\":33115},{\"end\":33213,\"start\":33206},{\"end\":33342,\"start\":33332},{\"end\":33353,\"start\":33342},{\"end\":33493,\"start\":33485},{\"end\":33681,\"start\":33666},{\"end\":33811,\"start\":33800},{\"end\":33820,\"start\":33811},{\"end\":34006,\"start\":33994},{\"end\":34016,\"start\":34006},{\"end\":34199,\"start\":34191},{\"end\":34207,\"start\":34199},{\"end\":34428,\"start\":34418},{\"end\":34440,\"start\":34428},{\"end\":34551,\"start\":34540},{\"end\":34625,\"start\":34614},{\"end\":34775,\"start\":34767},{\"end\":34782,\"start\":34775},{\"end\":34881,\"start\":34868},{\"end\":34891,\"start\":34881},{\"end\":34992,\"start\":34976}]", "bib_venue": "[{\"end\":32811,\"start\":32697},{\"end\":32981,\"start\":32939},{\"end\":33113,\"start\":33032},{\"end\":33204,\"start\":33155},{\"end\":33405,\"start\":33377},{\"end\":33531,\"start\":33520},{\"end\":33664,\"start\":33540},{\"end\":33935,\"start\":33845},{\"end\":34097,\"start\":34042},{\"end\":34315,\"start\":34234},{\"end\":34416,\"start\":34323},{\"end\":34538,\"start\":34462},{\"end\":34664,\"start\":34625},{\"end\":34808,\"start\":34782},{\"end\":34866,\"start\":34815},{\"end\":34974,\"start\":34936},{\"end\":35165,\"start\":35063},{\"end\":35220,\"start\":35173}]"}}}, "year": 2023, "month": 12, "day": 17}