{"id": 248811704, "updated": "2023-10-05 14:08:52.276", "metadata": {"title": "Generating Literal and Implied Subquestions to Fact-check Complex Claims", "authors": "[{\"first\":\"Jifan\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Aniruddh\",\"last\":\"Sriram\",\"middle\":[]},{\"first\":\"Eunsol\",\"last\":\"Choi\",\"middle\":[]},{\"first\":\"Greg\",\"last\":\"Durrett\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Verifying political claims is a challenging task, as politicians can use various tactics to subtly misrepresent the facts for their agenda. Existing automatic fact-checking systems fall short here, and their predictions like \u201chalf-true\u201d are not very useful in isolation, since it is unclear which parts of a claim are true and which are not. In this work, we focus on decomposing a complex claim into a comprehensive set of yes-no subquestions whose answers influence the veracity of the claim. We present CLAIMDECOMP, a dataset of decompositions for over 1000 claims. Given a claim and its verification paragraph written by fact-checkers, our trained annotators write subquestions covering both explicit propositions of the original claim and its implicit facets, such as asking about additional political context that changes our view of the claim\u2019s veracity. We study whether state-of-the-art models can generate such subquestions, showing that these models generate reasonable questions to ask, but predicting the comprehensive set of subquestions from the original claim without evidence remains challenging. We further show that these subquestions can help identify relevant evidence to fact-check the full claim and derive the veracity through their answers, suggesting that they can be useful pieces of a fact-checking pipeline.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2205.06938", "mag": null, "acl": "2022.emnlp-main.229", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/ChenSCD22", "doi": "10.18653/v1/2022.emnlp-main.229"}}, "content": {"source": {"pdf_hash": "628f08810dfd5b824caf9d831c79c11102fcd207", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2205.06938v3.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://aclanthology.org/2022.emnlp-main.229.pdf", "status": "HYBRID"}}, "grobid": {"id": "1d4daf598491b67b3ba5f29512e6505fe1668945", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/628f08810dfd5b824caf9d831c79c11102fcd207.txt", "contents": "\nGenerating Literal and Implied Subquestions to Fact-check Complex Claims\n1 Nov 2022\n\nJifan Chen jfchen@cs.utexas.edu \nDepartment of Computer Science\nThe University of Texas at Austin\n\n\nAniruddh Sriram \nDepartment of Computer Science\nThe University of Texas at Austin\n\n\nEunsol Choi \nDepartment of Computer Science\nThe University of Texas at Austin\n\n\nGreg Durrett \nDepartment of Computer Science\nThe University of Texas at Austin\n\n\nGenerating Literal and Implied Subquestions to Fact-check Complex Claims\n1 Nov 2022053BDAC5C8B81BD2E5C14A19509A3395arXiv:2205.06938v3[cs.CL]\nVerifying political claims is a challenging task, as politicians can use various tactics to subtly misrepresent the facts for their agenda.Existing automatic fact-checking systems fall short here, and their predictions like \"half-true\" are not very useful in isolation, since it is unclear which parts of a claim are true or false.In this work, we focus on decomposing a complex claim into a comprehensive set of yes-no subquestions whose answers influence the veracity of the claim.We present CLAIMDE-COMP, a dataset of decompositions for over 1000 claims.Given a claim and its verification paragraph written by fact-checkers, our trained annotators write subquestions covering both explicit propositions of the original claim and its implicit facets, such as additional political context that changes our view of the claim's veracity.We study whether state-of-the-art pretrained models can learn to generate such subquestions.Our experiments show that these models generate reasonable questions, but predicting implied subquestions based only on the claim (without consulting other evidence) remains challenging.Nevertheless, we show that predicted subquestions can help identify relevant evidence to fact-check the full claim and derive the veracity through their answers, suggesting that claim decomposition can be a useful piece of a fact-checking pipeline. 1Joe Biden stated on August 31, 2020 in a speech: \"When I was vice president, violent crime fell 15% in this country.... The murder rate now is up 26% across the nation this year under Donald Trump.\"Claim Decomposi-on: focus of this work Claim Q1: Did the crime rate fall by 15% during Joe Biden's presidency?Q2: Did the murder rate in 2020 increase by 26% from 2019?Q3: Is Biden comparing crime rates from the same time interval in his statement?Q4: Is violent crime rate and murder rate directly comparable?Literal Implied\n\nIntroduction\n\nDespite a flurry of recent research on automated fact-checking (Wang, 2017;Rashkin et al., 2017;Volkova et al., 2017;Ferreira and Vlachos, 2016;Popat et al., 2017;Tschiatschek et al., 2018), we remain far from building reliable fact-checking systems (Nakov et al., 2021).This challenge motivated us to build more explainable models so the explanations can at least help a user interpret the results Figure 1: An example claim decomposition: the top two subquestions follow explicitly from the claim and the bottom two represent implicit reasoning needed to verify the claim.We can use the decomposed questions to retrieve relevant evidence (Section 6), and aggregate the decisions of the sub-questions to derive the final veracity of the claim (Section 5.3).(Atanasova et al., 2020).However, such purely extractive explanations do not necessarily help users interpret a model's reasoning process.An ideal explanation should do what a human-written factcheck does: systematically dissect different parts of the claim and evaluate their veracity.\n\nWe take a step towards explainable fact-checking with a new approach and accompanying dataset, CLAIMDECOMP, of decomposed claims from Poli-tiFact.Annotators are presented with a claim and the justification paragraph written by expert factcheckers, from which they annotate a set of yesno subquestions that give rise to the justification.These subquestions involve checking both the explicit and implicit aspects of the claim (Figure 1).Such a decomposition can play an important role in an interpretable fact verification system.First, the subquestions provide a comprehensive explanation of how the decision is made: in Figure 1, although the individual statistics mentioned by Biden Figure 2: An example of our annotation process.The annotators are instructed to write a set of subquestions, give binary answers to them, and attribute them to a source.If the answer cannot be decided from the justification paragraph, \"Unknown\" is also an option.The question is either based on the claim or justification, and the annotators also select the relevant parts (color-coded in the figure) on which the question is based.\n\nare correct, they are from different time intervals and not directly comparable, which yields the final judgment of the claim as \"half-true\".We can estimate the veracity of a claim using the decisions of the subquestions (Section 5.3).Second, we show that decomposed subquestions allow us to retrieve more relevant paragraphs from the verification document than using the claim alone (Section 6), since some of the subquestions tackle implicit aspects of a claim.We do not build a full pipeline for fact verification in this paper, as there are other significant challenges this poses, including information which is not available online or which needs to be parsed out of statistical tables (Singh et al., 2021).Instead, we focus on showing how these decomposed questions can fit into a fact-checking pipeline through a series of proof-of-concept experiments.\n\nEquipped with CLAIMDECOMP dataset, we train a model to generate decompositions of complex political claims.We experiment with pre-trained sequence-to-sequence models (Raffel et al., 2020), generating either a sequence of questions or a single question using nucleus sampling (Holtzman et al., 2020) over multiple rounds.This model can recover 58% of the subquestions, including some implicit subquestions.To summarize, we show that decomposing complex claims into subquestions can be learned with our dataset, and reasoning with such subquestions can lead improve evidence retrieval and judging the veracity of the whole claim.\n\n\nMotivation and Task\n\nFacing the complexities of real-world political claims, simply giving a final veracity to a claim often fails to be persuasive (Guo et al., 2022).To make the judgment of an automatic fact-checking system understandable, most previous work has focused on generating justifications for models' decisions.Popat et al. (2018); Shu et al. (2019); Lu and Li (2020) used attention weights of the models to highlight the most relevant parts of the evidence, but these only deal with explicit propositions of a claim.Ahmadi et al. (2019); Gad-Elrab et al. (2019) used logic-based systems to generate justifications, yet the systems are often based on existing knowledge graphs and are hard to adapt to complex real-world claims.Atanasova et al. (2020) treated the justification generation as a summarization problem in which they generate a justification paragraph according to some relevant evidence.Even so, it is hard to know which parts of the claim are true and which are not, and how the generated paragraph relates to the veracity.\n\nWhat is missing in the literature is a better intermediate representation of the claim: with more complex claims, explaining the veracity of a whole claim at once becomes more challenging.Therefore, we focus on decomposing the claim into a minimal yet comprehensive set of yes-no subquestions, whose answers can be aggregated into an inherently explainable decision.As the decisions to the subquestions are explicit, it is easier for one to spot the discrepancies between the veracity and the intermediate decisions.\n\nClaims and Justifications Our decomposition process is inspired by fact checking documents written by professional fact checkers.In the data we use from PolitiFact, each claim is paired with a justification paragraph (see Figure 2) which contains the most important factors on which the veracity made by the fact-checkers is based.Understanding what questions are answered in this paragraph will be the core task our annotators will undertake to create our dataset.However, we frame the claim decomposition task (in the next section) without regard to this justification document, as it is not available at test time.\n\nClaim Decomposition Task We define the task of complex claim decomposition.Given a claim c and the context o of the claim (speaker, date, venue of the claim), the goal is to generate a set of N yesno subquestions q = {q 1 , q 2 , ...q N }.The set of subquestions should have the following properties:\n\n\u2022 Comprehensiveness: The questions should cover as many aspects of the claim as possible: the questions should be sufficient for someone to judge the veracity of the claim.\n\n\u2022 Conciseness: The question set should be as minimal as is practical and not contain repeated questions asking about minor, correlated variants seeking the same information.\n\nAn individual subquestion should also exhibit:\n\n\u2022 Relevance: The answer to subquestion should help a reader determine the veracity of the claim.Knowing an answer to a subquestion should change the reader's belief about the veracity of the original claim (Section 5.3).\n\n\u2022 Fluency / Clarity: Each subquestion should be clear, fluent, and grammatically correct (Section 3).\n\nWe do not require subquestions to stand alone (Choi et al., 2021); they are instead interpreted with respect to the claim and its context.\n\n\nEvaluation Metric\n\nWe set the model to generate the target number of subquestions, which matches the number of subquestions in the reference, guaranteeing a concise subquestion set.Thus, we focus on measuring the other properties with referencebased evaluation.Specifically, given an annotated set of subquestions and an automatically predicted set of subquestions, we assess recall: how many subquestions in the reference set are covered by the generated question set?A subquestion in the reference set is considered as being recalled if it is semantically equivalent to one of the generated subquestions by models.2Our notion of equivalence is nuanced and contextual: for example, the following two subquestions are considered semantically equivalent: \"Is voting in person more secure than voting by mail?\" and \"Is there a greater risk of voting fraud with mail-in ballots?\".We manually judge the question equivalence, as our experiments with automatic evaluation metrics did not yield reliable results (details in Appendix E).\n\n\nDataset Collection\n\nClaim / Verification Document Collection We collect political claims and corresponding verification articles from PolitiFact.3Each article contains one justification paragraph (see Figure 2) which states the most important factors on which the veracity made by the fact-checkers is based.Understanding what questions are answered in this paragraph will be the core annotation task.Each claim is classified as one of six labels: pants on fire (most false), false, barely true, half-true, mostly true, and true.We collect the claims from top 50 PolitiFact pages for each label, resulting in a total of 6,859 claims.A claim like \"Approximately 60,000 Canadians currently live undocumented in the USA.\" hinges on checking a single statistic and is less likely to contain information beyond the surface form.Therefore, we mainly focus on studying complex claims  in this paper.To focus on complex claims, we filter claims with 3 or fewer verbs.We also filter out claims that do not have an associated justification paragraph.After the filtering, we get a subset consisting 1,494 complex claims.\n\nDecomposition Annotation Process Given a claim paired with the justification written by the professional fact-checker on PolitiFact, we ask our annotators to reverse engineer the fact-checking process: generate yes-no questions which are answered in the justification.As shown in Figure 2, for each question, the annotators also (1) give the answer;\n\n(2) select the relevant text in the justification or claim that is used for the generation (if any).\n\nThe annotators are instructed to cover as many of the assertions made in the claim as possible without being overly specific in their questions.This process gives rise to both literal questions, which follow directly from the claim, and implied questions, which are not necessarily as easy to predict from the claim itself.These are not attributes labeled by the annotators, but instead labels the authors assign post-hoc (described in Section 5).\n\nWe recruit 8 workers with experience in literature or politics from the freelancing platform Upwork to conduct the annotation.Appendix A includes details about the hiring process, workflow, as well as instructions and the UI.\n\nDataset statistics and inter-annotator agreement Table 1 shows the statistics of our dataset.We collect two sets of annotations per claim to improve subquestion coverage.We collect a total of 6,555 subquestions for 1,200 claims.Most of the questions arise from the justification and most of the questions can be answered by the justification.In addition, we randomly sample 50 claims from the validation set for our human evaluation in the rest of this paper.We name this set Validationsub.\n\nComparing sets of subquestions from different annotators is nontrivial: two annotators may choose different phrasings of individual questions and even different decompositions of the same claim that end up targeting the same pieces of information.Thus, we (the authors) manually compare two sets of annotations to judge inter-annotator agreement: given two sets of subquestions on the same claim, the task is to identify questions for which the semantics are not expressed by the other question set.If no questions are selected, it means that the two annotators show strong agreement on what should be captured in subquestions.Example annotations are shown in Appendix D.\n\nWe randomly sample 50 claims from our dataset and three of the authors conduct the annotation.The authors agree on this comparison task reasonably, with a Fleiss' Kappa (Fleiss, 1971) value of 0.52.The comparison results are shown in Table 2. On average, the semantics of 18.4% questions are not expressed by the other set.This demonstrates the comprehensiveness of our set of questions: only a small fraction is not captured by the other set, indicating that independent annotators are not easily coming up with distinct sets of questions.Because most questions are covered in the other set, we view the agreement as high.A simple heuristic to improve comprehensiveness further is to prefer the annotator who annotated more questions.If we consider the fraction of unmatched questions in the FEWER QS, we see this drops to 8.5%. 4 Through this manual examination, we also found that annotated questions are overall concise, fluent, clear, and grammatical.\n\n\nAutomatic Claim Decomposition\n\nThe goal is to generate a subquestion set q from the input claim c, the context o, and the target number of subquestions k.\n\n\nModels\n\nWe fine-tune a T5-3B (Raffel et al., 2020) model to automate the question generation process under two settings: QG-MULTIPLE and QG-NUCLEUS as shown in Figure 3.Both generation methods generate the same number of subquestions, equal to the number of subquestions generated by an annotator.\n\n\nQG-NUCLEUS\n\n\nQG-MULTIPLE\nT5 T5 q 1 [S]q 2 [S] . . . q N < l a t e x i t s h a 1 _ b a s e 6 4 = \" h h + 8 S M 3 7 L 5 Q 6 E S d i m W V w j 4 t 3 n + 4 = \" > A A A C F X i c b Z D L S s N A F I Y n X m u 9 R V 2 6 G S y C C y l J F X R Z d O N K K t o L N C F M J p N 2 6 E y S z k y E E v o S b n w V N y 4 U c S u 4 8 2 2 c t F n Y 1 h 8 G f r 5 z D n P O 7 y e M S m V Z P 8 b S 8 s r q 2 n p p o 7 y 5 t b 2 z a + 7 t t 2 S c C k y a O G a x 6 P h I E k Y j 0 l R U M d J J B E H c Z 6 T t D 6 7 z e v u R C E n j 6 E G N E u J y 1 I t o S D F S G n n m 6 d C z o c O R 6 g u e d e / d M R x 6 t V n g s C B W U v N b z 6 x Y V W s i u G j s w l R A o Y Z n f j t B j F N O I o U Z k r J r W 4 l y M y Q U x Y y M y 0 4 q S Y L w A P V I V 9 s I c S L d b H L V G B 5 r E s A w F v p F C k 7 o 3 4 k M c S l H 3 N e d + b p y v p b D / 2 r d V I W X b k a j J F U k w t O P w p R B F c M 8 I h h Q Q b B i I 2 0 Q F l T v C n E f C Y S V D r K s Q 7 D n T 1 4 0 r V r V P q v W 7 s 4 r 9 a s i j h I 4 B E f g B N j g A t T B D W i A J s D g C b y A N / B u P B u v x o f x O W 1 d M o q Z A z A j 4 + s X n A O e e g = = < / l a t e x i t > c, N < l a t e x i t s h a 1 _ b a s e 6 4 = \" s t r p G i B m i O 2 i V l 8 J h R L o 2 m l J / H o = \" > A A A C G n i c b Z D L S s N A F I Y n X m u 8 R V 2 6 G S w F F 1 K S K u i y 6 M Z V q W g v 0 I Q w m U z a o Z N L Z y Z C C X 0 O N 7 6 K G x e K u B M 3 v o 2 T N g v b + s P A z 3 f O Y c 7 5 v Y R R I U 3 z R 1 t Z X V v f 2 C x t 6 d s 7 u 3 v 7 x s F h W 8 Q p x 6 S F Y x b z r o c E Y T Q i L U k l I 9 2 E E x R 6 j H S 8 4 U 1 e 7 z w S L m g c P c h x Q p w Q 9 S M a U I y k Q q 5 h 4 b O G X h m 5 F r R D J A c 8 z H r 3 z g S O 3 N o 8 s J k f S 6 F 4 w z X K Z t W c C i 4 b q z B l U K j p G l + 2 H + M 0 J J H E D A n R s 8 x E O h n i k m J G J r q d C p I g P E R 9 0 l M 2 Q i E R T j Y 9 b Q I r i v g w i L l 6 k Y R T + n c i Q 6 E Q 4 9 B T n f m 6 Y r G W w / 9 q v V Q G V 0 5 G o y S V J M K z j 4 K U Q R n D P C f o U 0 6 w Z G N l E O Z U 7 Q r x A H G E p U p T V y F Y i y c v m 3 a t a p 1 X a 3 c X 5 f p 1 E U c J H I M T c A o s c A n q 4 B Y 0 Q Q t g 8 A\nR e w B t 4 1 5 6 1 V + 1 D + 5 y 1 r m j F z B G Y k / b 9 C x 3 3 n 7 g = < / l a t e x i t > c < l a t e x i t s h a 1 _ b a s e 6 4 = \" a S W e i U G j R 0 x 6 J w P Z y 8 f V I f s q m y w = \" > A\nA A C H X i c b Z D L S s N A F I Y n 9 V b j L e r S z W A p u J C S 1 I I u i 2 5 c l Y r 2 A k k I k + m k H T q 5 d G Y i l N A X c e O r u H G h i A s 3 4 t s 4 b b O w r T 8 M / H z n H O a c 3 0 8 Y F d I 0 f 7 T C 2 v r G 5 l Z x W 9 / Z 3 d s / M A 6 P 2 i J O O S Y t H L O Y d 3 0 k C K M R a U k q G e k m n K D Q Z 6 T j D 2 + m 9 c 4 j 4 Y L G 0 Y M c J 8 Q N U T + i A c V I K u Q Z N a y X 8 X l D L 4 8 8 C z o h k g M e Z v a 9 O 4 E j r 7 o I H N a L p V C 8 4 R k l s 2 L O B F e N l Z s S y N X 0 j C + n F + M 0 J J H E D A l h W 2 Y i 3 Q x x S T E j E 9 1 J B U k Q H q I + s Z W N U E i E m 8 2 u m 8 C y I j 0 Y x F y 9 S M I Z / T u R o V C I c e i r z u m 6 Y r k 2 h f / V 7 F Q G V 2 5 G o y S V J M L z j 4 K U Q R n D a V S w R z n B k o 2 V Q Z h T t S v E A 8 Q R l i p Q X Y V g L Z + 8 a t r V i n V R q d 7 V S v X r P I 4 i O A G n 4 A x Y 4 B L U w S 1 o g h b A 4 A m 8 g D f w r j 1 r r 9 q H 9 j l v L W j 5 z D F Y k P b 9 C 4 g / o G g = < / l a t e x i t > q 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" F R m w H z R 1 a N f K m c s W G t 0 s J L n K O t E = \" > A A A C I n i c b V D L S g M x F M 3 U V x 1 f o y 7 d B E v B h Z S Z K q i 7 o h t X p a J 9 w M w w Z N K 0 D c 0 8 m m S E M v R b 3 P g r b l w o 6 k r w Y 8 y 0 s 7 C t h w R O z r m X 3 H v 8 m F E h T f N b K 6 y s r q 1 v F D f 1 r e 2 d 3 T 1 j / 6 A l o o R j 0 s Q R i 3 j H R 4 I w G p K m p J K R T s w J C n x G 2 v 7 w J v P b j 4 Q L G o U P c h w T N 0 D 9 k P Y o R l J J n n E 1 8 i y 9 j N U 5 r e t l 9 Y B O g O S A B 6 l 9 7 0 7 g y K v O C w 7 r R l I o v e 4 Z J b N i T g G X i Z W T E s j R 8 I x P p x v h J C C h x A w J Y V t m L N 0 U c U k x I x P d S Q S J E R 6 i P r E V D V F A h J t O V 5 z A s l K 6 s B d x d U M J p + r f j h Q F Q o w D X 1 V m 4 4 p F L x P / 8 + x E 9 i 7 d l I Z x I k m I Z x / 1 E g Z l B L O 8 Y J d y g i U b K 4 I w p 2 p W i A e I I y x V q r o K w V p c e Z m 0 q h X r r F K 9 O y / V r v M 4 i u A I H I M T Y I E L U A O 3 o A G a A I M n 8\nA L e w L v 2 r L 1 q H 9 r X r L S g 5 T 2 H Y A 7 a z y 9 R W q H K < / l a t e x i t > q 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" U S 1 J r f o / e x q d i j Table 3: Human evaluation results on the Validationsub set (N=146).R-all denotes the recall for all questions; R-literal and R-implied denotes the recall for the literal questions and the implied questions respectively.\nB x 7 E X v 6 o v y z K 0 = \" > A A A C I n i c b V D L S s N A F J 3 U V 4 2 v q E s 3 g 6 X g Q k p S B X V X d O O q V L Q P S E K Y T K f t 0 M m j M x O h h H 6 L G 3 / F j Q t F X Q l + j J M 2 C 9 t 6 m I H D O f d y 7 z 1 + z K i Q p v m t F V Z W 1 9 Y 3 i p v 6 1 v b O 7 p 6 x f 9 A S U c I x a e K I R b z j I 0 E Y D U l T U s l I J + Y E B T 4 j b X 9 4 k / n t R 8 I F j c I H O Y 6 J G 6 B + S H s U I 6 k k z 7 g a e V W 9 j N U 7 r e v l k W d B J 0 B y w I P U v n c n U L n z g s O 6 k R R K r 3 t G y a y Y U 8 B l Y u W k B H I 0 P O P T 6 U Y 4 C U g o M U N C 2 J Y Z S z d F X F L M y E R 3 E k F i h I e o T 2 x F Q x Q Q 4 a b T E y e w r J Q u 7 E V c / V D C q f q 3 I 0 W B E O P A V 5 X Z u m L R y 8 T / P D u R v U s 3 p W G c S B L i 2 a B e w q C M Y J Y X 7 F J O s G R j R R D m V O 0 K 8 Q B x h K V K V V c h W I s n L 5 N W t W K d V a p 3 5 6 X a d R 5 H E R y B Y 3 A C L H A B a u A W N E A T Y P A E X s A b e N e e t V f t Q / u a l R a 0 v O c Q z E H 7 + Q V T F K H L < / l a t e x i t > q N < l a t e x i t s h a 1 _ b a s e 6 4 = \" x d 9 y v T S P B A L H j k A Z 7 0 b B G R i O 6 L c = \" > A A A C I n i c b V D L S g M x F M 3 U V x 1 f V Z d u g q X g Q s p M F d R d 0 Y 2 r U t E + Y G Y Y M p l M G 5 p 5 N M k I Z e i 3 u P F X 3 L h Q 1 J X g x 5 h p u 7 C t h 4 Q c z r m X 3 H u 8 h F E h D e N b K 6 y s r q 1 v F D f 1 r e 2 d 3 b 3 S / k F b x C n H p I V j F v O u h w R h N C I t S S U j 3 Y Q T F H q M d L z B T e 5 3 H g k X N I 4 e 5 C g h T o h 6 E Q 0 o R l J J b u l q 6 D b 0 C l b n V L 1 D 1 4 R 2 i G S f h 5 l 1 7 4 z h 0 K 3 N C z b z Y y m U 3 n B L Z a N q T A C X i T k j Z T B D 0 y 1 9 2 n 6 M 0 5 B E E j M k h G U a i X Q y x C X F j I x 1 O x U k Q X i A e s R S N E I h E U 4 2 W X E M K 0 r x Y R B z d S M J J + r f j g y F Q o x C T 1 X m 4 4 p F L x f / 8 6 x U B p d O R q M k l S T C 0 4 + C l E E Z w z w v 6 F N O s G Q j R R D m V M 0 K c R 9 x h K V K V V c h m I s r L 5 N 2 r W q e V W t 3 5 + X 6 9 S y O I j g C x + A E m O A C 1 M E t a I I W w O A J v I A 3 8 K 4 9 a 6 / a h / Y 1 L S 1 o s 5 5 D M A f t 5 x e D b K H n < / l a t e x i t > . . . < l a t e x i t s h a 1 _ b a s e 6 4 = \" 8 j m 4 0 D y B 7 I i o L D H l 0 o u a + X U r U + s = \" > A A A C K n i c b Z B L S 8 N A E M c 3 9 V X j K + r R y 2 I p e J C S V E G P V S + e S k X 7 g C S E z W b T L t 0 8 u r s R S u j n 8 e J X 8 d K D U r z 6 Q d w + D r Z 1 2 I U / v 5 l h Z v 5 + y q i Q p j n R C h u b W 9 s 7 x V 1 9 b / / g 8 M g 4 P m m J J O O Y N H H C E t 7 x k S C M x q Q p q W S k k 3 K C I p + R t t 9 / m O b b r 4 Q L m s Q v c p g S N 0 L d m I Y U I 6 m Q Z 9 y V B 1 5 d d 1 i Q S K G X s X q X d V 0 x C z o R k j 0 e 5 f a z O 4 I D r 7 o M 5 h 2 K 1 z 2 j Z F b M W c B 1 Y S 1 E C S y i 4 R l j J 0 h w F p F Y Y o a E s C 0 z l W 6 O u K S Y k Z H u Z I K k C P d R l 9 h K x i g i w s 1 n p 4 5 g W Z E A h g l X P 5 Z w R v 9 2 5 C g S Y h j 5 q n K 6 r l j N T e F / O T u T 4 a 2 b 0 z j N J I n x f F C Y M S g T O P U N B p Q T L N l Q C Y Q 5 V b t C 3 E M c Y a n c 1 Z U J 1 u r J 6 6 J V r V h X l e r T d a l 2 v 7 C j C M 7 A O b g A F r g B N f A I G q A J M H g D H + A T f G n v 2 l i b a N / z 0 o K 2 6 D k F S 6 H 9 / A J k q q T o < / l a t\nconcatenated by their annotation order to construct the output.\n\nQG-NUCLEUS We learn a model P (q | c, o) to place a distribution over single subquestions given the claim and output.For training, each annotated subquestion is paired with the claim to form a distinct input-output pair.At inference, we use nucleus sampling to generate questions.See Appendix F for training details.We also train these generators in an oracle setting where the justification paragraph is appended to the claim to understand how well the question generator does with more information.We denote the two oracle models as QG-MULTIPLE-VERIFY and QG-NUCLEUS-VERIFY respectively.\n\nResults All models are trained on the training portion of our dataset and evaluated on the Validation-sub set.One of the authors evaluated the recall of each annotated subquestion in the generated subquestion set.The results are shown in Table 3.We observe that most of the literal questions can be generated while only a few of the implied questions can be recovered.Generating multiple questions as a single sequence (QG-MULTIPLE) is more effective than sampling multiple questions (QG-NUCLEUS).Many questions generated from QG-NUCLEUS are often slightly different but share the same semantics.We see that more than 70% of the literal questions and 18% of the implied questions can be generated by the best QG-MULTIPLE model.By examining the generated implied questions, we find that most of them belong to the domain knowledge category in Section 5. Some questions could be better generated if related evidence were retrieved first, especially for questions of the context category (Section 5).The QG-MULTIPLE-JUSTIFY model can recover most of the literal questions and half of the implied questions.Although this is an oracle setting, it shows that when given proper information about the claim, the T5 model can achieve much better performance.We discuss this retrieval step more in Section 9.\n\nQualitative Analysis While our annotated subquestion sets cover most relevant aspects of the claim, we find some generated questions are good subquestions that are missing in our annotated set, though less important.For example, for our introduction example shown in Figure 1, the QG-NUCLEUS model generates the question \"Is Trump responsible for the increased murder rate?\"Using the question generation model in collaboration with humans might be a promising direction for more comprehensive claim decomposition.See Appendix H for more examples.\n\n\nAnalyzing Decomposition Annotations\n\nIn this section, we study the characteristics of the annotated questions.We aim to answer: (1) How many of the questions address implicit facets of the claim, and what are the characteristics of these?(2) How do our questions differ from previous work on question generation for fact checking (Fan et al., 2020)?(3) Can we aggregate subquestion judgments for the final claim judgment?\n\n\nSubquestion Type Analysis\n\nWe (the authors) manually categorize 285 subquestions from 100 claims in the development set into two disjoint sets: literal and implied, where literal questions are derived from the surface information of the claim -whether a question can be posed by only given the claim, and implied questions are those that need extra knowledge in order to pose.Table 4 shows basic statistics about these sets, including the average number of subquestions for each claim and lexical overlap between subquestions and the base claims, evaluated with ROUGE precision, as one subquestion can be a subsequence of the original claim.On average, each claim contains one implied question which represents the deeper meaning of the claim.These implied questions overlap less with the claim.\n\nWe further manually categorize the implied questions into the following four categories, reflecting what kind of knowledge is needed to pose them (examples in Figure 4).Two authors conduct the analysis over 50 examples and the annotations agree with a Cohen's Kappa (Cohen, 1960) score of 0.74.Domain knowledge The subquestion seeks domain-specific knowledge, for example asking about further steps of a legal or political process.Context The subquestion involves knowing that broader context is relevant, such as whether something is broadly common or the background of the claim (political affiliation of the politician, history of the events stated in the claim, etc).Implicit meaning The subquestion involves unpacking the implicit meaning of the claim, specifically anchored to what the speaker's intent was.Statistical rigor The subquestion involves checking over-claimed or over-generalized statistics (e.g., the highest raw count is not the highest per capita).\n\nMost of the implied subquestions require either domain knowledge or context about the claim, reflecting the challenges behind automatically generating such questions.Table 5: Results from user study on helpfulness (rated 1-5) of a set of generated subquestions for claim verification.We conduct a t-test over the collected scores.\n\n\nComparison to QABriefs\n\nOur work is closely related to the QABriefs dataset (Fan et al., 2020), where they also ask annotators to write questions to reconstruct the process taken by professional fact-checkers provided the claim and its verification document.While sharing similar motivation, we use a significantly different annotation process than theirs, resulting in qualitatively different sets of questions as shown in Figure 5.We notice: (1) Their questions are less comprehensive, often missing important aspects of the claim.(2) Their questions are broader and less focused on the claim.We instructed annotators to provide the source of the annotated subquestions from either claim or verification document.For example, questions like \"What are Payday lenders?\" in the figure will not appear in our dataset as the justification paragraph does not address such question.Fan et al. (2020) dissuaded annotators from providing binary questions; instead, they gather answers to their subquestions after the questions are collected.We focus on binary questions whose verification could help verification of the full claim.See Appendix I for more examples of the comparison.\n\n\nClaim:\n\nThe group With Honor stated on September 10, 2018 in a TV ad: Kentucky Rep. Andy Barr \"would let shady payday lenders take advantage of our troops\" and that he took \"$36,550 from payday lenders.\"Are there any protections for service members using payday lending services?Has Barr's voting record directly affected protection for veterans against payday lenders?\n\nFigure 5: Comparison between our decomposed questions with QABriefs (Fan et al., 2020).In general, our decomposed questions are more comprehensive and relevant to the original claim.User Study To better quantify the difference, we also conduct a user study in which we ask an annotator to rate how useful a set of questions (without answers) are to determine the veracity of a claim.On 42 claims annotated by both approaches, annotators score sets of subquestions on a Likert scale from 1 to 5, where 1 denotes that knowing the answers to the questions does not help at all and 5 denotes that they can accurately judge the claim once they know the answer.We recruit annotators from MTurk.We collect 5-way annotation for each example and conduct the t-test over the results.The details can be found in Appendix C. Table 5 reports the user study results.Our questions achieve a significantly higher relevance score compared to questions from QABriefs.This indicates that we can potentially derive the veracity of the claim from our decomposed questions since they are binary and highly relevant to the claim.\n\n\nDeriving the Veracity of Claims from\n\nDecomposed Questions\n\nIs the veracity of a claim sum of its parts?We estimate whether answers to subquestions can be used to determine the veracity of the claim.\n\nWe predict a veracity score v = 1\nN N i=1 1[a i =\n1] equal to the fraction of subquestions with yes answers.We can map this to the discrete 6-label scale by associating the labels pants on fire, false, barely true, half true, mostly true, and true with the in-\ntervals [0, 1 6 ), [ 1 6 , 2 6 ), [ 2 6 , 3 6 ), [ 3 6 , 4 6 ), [ 4 6 , 5 6 ), [ 5\nTable 6 compares our heuristics with simple baselines (random assignment and most frequent class assignment).Our heuristic easily outperforms the baselines, with the predicted label on average is only shifted by one label, e.g., mostly true vs. true.This demonstrates the potential of building a more complex model to aggregate subquestion-answer sets, which we leave as a future direction.\n\nOur simple aggregation suffers in the following cases: (1) The subquestions are not equal in importance.The first example in Figure 4 contains two yes subquestions and two no subquestions, and our aggregation yields half-true label, differing from gold label barely-true.(2) Not all questions are relevant.As indicated by question aggregation*, we are able to achieve better performance after removing unrelated questions.(3) In few cases, the answer to a question could inversely correlate with the veracity of a claim.For example, the claim states \"Person X implied Y\" and the question asks \"Did person X not imply Y?\" We think all of the cases can be potentially fixed by stronger models.For example, a question salience model can mitigate (1) and ( 2), and promotes researches about understanding core arguments of a complex claim.We leave this as future work.\n\n\nEvidence Retrieval with Decomposition\n\nLastly, we explore using claim decomposition for retrieving evidence paragraphs to verify claims.Retrieval from the web to check claims is an extremely hard problem (Singh et al., 2021).We instead explore a simplified proof-of-concept setting: retrieving relevant paragraphs from the full justification document.These articles are lengthy, containing an average of 12 paragraphs, and with distractors due to entity and concept overlap with the claims.We aim to show two advantages of using the decomposed questions: (1) The implied questions contain information helpful to retrieve evidence beyond the lexical information of the claim.(2) We can convert the subquestions to statements and treat them as hypotheses to apply the off-the-shelf NLI models to retrieve evidence that entails such hypotheses (Chen et al., 2021).\n\n\nEvidence Paragraph Collection\n\nWe first collect human annotation to identify relevant evidence paragraphs.Given the full PolitiFact verification article consisting of m paragraphs p = (p 1 , . . ., p m ) and a subquestion, annotators find paragraphs relevant to the subquestion.As this requires careful document-level reading, we hire three undergraduate linguistics students as annotators.We use the 50 claims from the Validation-sub set and present the annotators with the subquestions and the articles.For each subquestion, for each paragraph in the article, we ask the annotators to choose whether it served as context to the subquestion or whether it supports/refutes the subquestion.The statistics and inter-annotator agreement is shown in Table 7. Out of 12.4 paragraphs on average, 3-4 paragraphs were directly relevant to the claim and the rest of paragraphs mostly provide context.\n\nExperimental Setup We experiment with three off-the-shelf RoBERTa-based (Liu et al., 2019) NLI models trained on three different datasets: MNLI (Williams et al., 2018), NQ-NLI (Chen et al., 2021), and DocNLI (Yin et al., 2021).We com-max \u2026 h 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" y i Z Q Y Y Y w O + F 5 p P + n r g z 8 1 e C g w J\nQ = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s t H M 0 n Q j + h Q 8 p A z a q z 0 M O p 7 / X L F r b p z k F X i 5 a Q C O R r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l q 1 q n d R r d 1 f V u o 3 e R x F O I F T O A c P r q A O d 9 C A J j A Y w j O 8 w p s j n B f n 3 f l Y t B a c f O Y Y / s D 5 / A H 0 j 4 2 U < / l a t e x i t > h 2\n< l a t e x i t s h a 1 _ b a s e 6 4 = \" b p 6 t 7 i I R 0 U j P y g 0 d B 3 e 9 y e Q t z c I = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8\nV 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s t H M 0 n Q j + h Q 8 p A z a q z 0 M O r X + u W K W 3 X n I K v E y 0 k F c j T 6 5 a / e I G Z p h N I w Q b X u e m 5 i / I w q w 5 n A a a m X a k w o G 9 M h d i 2 V N E L t Z / N T p + T M K g M S x s q W N G S u / p 7 I a K T 1 J A p s Z 0 T N S C 9 7 M / E / r 5 u a 8 N r P u E x S g 5 I t F o W p I C Y m s 7 / J g C t k R k w s o U x x e y t h I 6 o o M z a d k g 3 B W 3 5 5 l b R q V e + i W r u / r N R v 8 j i K c A K n c A 4 e X E E d 7 q A B T W A w h G d 4 h T d H O C / O u / O x a C 0 4 + c w x / I H z + Q P 2 E 4 2 V < / l a t e x i t > p 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" d l k u L v R L P K T p e N E p 4 w 3 D S O d a G B U = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s t H M 0 n Q j + h Q 8 p A z a q z 0 k P S 9 f r n i V t 0 5 y C r x c l K B H I 1 + + a s 3 i F k a o T R M U K 2 7 n p s Y P 6 P K c C Z w W u q l G h P K x n S I X U s l j V D 7 2 f z U K T m z y o C E s b I l D Z m r v y c y G m k 9 i Q L b G V E z 0 s v e T P z P 6 6 Y m v P Y z L p P U o G S L R W E q i I n J 7 G 8 y 4 A q Z E R N L K F P c 3 k r Y i C r K j E 2 n Z E P w l l 9 e J a 1 a 1 b u o 1 u 4 v K / W b P I 4 i n M A p n I M H V 1 C H O 2 h A E x g M 4 R l e 4 c 0 R z o v z 7 n w s W g t O P n M M f + B 8 / g A A z o 2 c < / l a t e x i t > h N < l a t e x i t s h a 1 _ b a s e 6 4 = \" Y b t m B R l b o Z 8 I E 3 o 5 a J i e 7 3 V b Y Q Y = \" > A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 k k q 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h\nO 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w a e J U M 9 5 g s Y x 1 O 6 C G S 6 F 4 A w V K 3 k 4 0 p 1 E g e S s Y 3 U z 9 1 h P X R s T q E c c J 9 y M 6 U C I U j K K V H o a 9 u 1 6 p 7 F b c G c g y 8 X J S h h z 1 X u m r 2 4 9 Z G n G F T F J j O p 6 b o J 9 R j Y J J P i l 2 U 8 M T y k Z 0 w D u W K h p x 4 2 e z U y f k 1 C p 9 E s b a l k I y U 3 9 P Z D Q y Z h w F t j O i O D S L 3 l T 8 z + u k G F 7 5 m V B J i l y x + a I w l Q R j M v 2 b 9 I X m D O X Y E s q 0 s L c S N q S a M r T p F G 0 I 3 u L L y 6 R Z r X j n l e r 9 R b l 2 n c d R g G M 4 g T P w 4 B J q c A t 1 a A C D A T z D K 7 w 5 0 n l x 3 p 2 P e e u K k 8 8 c w R 8 4 n z 8 g k o 2 x < / l a t e x i t > p 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" l 1 r j G\nX 6 4 O c Y R X e G U F + v G K y n t 1 E o = \" > A A A B 6 3 i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j 0 4 r G C / Y A 2 l M 1 2 0 i 7 d 3 Y T d j V B C / 4 I X D 4 p 4 9 Q 9 5 8 9 + Y t D l o 6 4 O B x 3 s z z M w L Y s G N d d 1 v Z 2 1 9 Y 3 N r u 7 R T 3 t 3 b P z i s H B 2 3 T Z R o h i 0 W i U h 3 A 2 p Q c I U t y 6 3 A b q y R y k B g J 5 j c 5 X 7 n C b X h k X q 0 0 x h 9 S U e K h 5 x R m 0 v x o F 4 e V K p u z Z 2 D r B K v I F U o 0 B x U v v r D i C U S l W W C G t P z 3 N j 6 K d W W M 4 G z c j 8 x G F M 2 o S P s Z V R R i c Z P 5 7 f O y H m m D E k Y 6 a y U J X P 1 9 0 R K p T F T G W S d k t q x W f Z y 8 T + v l 9 j w x k + 5 i h O L i i 0 W h Y k g N i L 5 4 2 T I N T I r p h m h T P P s V s L G V F N m s 3 j y E L z l l 1 d J u 1 7 z L m v 1 h 6 t q 4 7 a I o w S n c A Y X 4 M E 1 N O A e m t A C B m N 4 h l d 4 c 6 T z 4 r w 7 H 4 v W N a e Y O Y E / c D 5 / A D d j j b E = < / l a t e x i t > p M < l a t e x i t s h a 1 _ b a s e 6 4 = \" a O T z N Q D f d i i J G Y H J Y g E I b P J R r 5 4 = \" > A A A B 6 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F y 9 C B f s B b S i b 7 a R d u r s J u x u h l P 4 F L x 4 U 8 e o f 8 u a / M W l z 0 N Y H A 4 / 3 Z p i Z F 8 S C G + u 6 3 0 5 h b X 1 j c 6 u 4 X d r Z 3 d s / K B 8 e t U y U a I Z N F o l I d w J q U H C F T c u t w E 6 s k c p A Y D s Y 3 2 Z + + w m 1 4 Z F 6 t J M Y f U m H i o e c U Z t J c f + + 1 C 9 X 3 K o 7 B 1 k l X k 4 q k K P R L 3 / 1 B h F L J C r L B D W m 6 7 m x 9 a d U W 8 4 E z k q 9 x G B M 2 Z g O s Z t S R S U a f z q / d U b O U m V A w k i n p S y Z q 7 8 n p l Q a M 5 F B 2 i m p H Z l l L x P / 8 7 q J D a / 9 K V d x Y l G x x a I w E c R G J H u c D L h G Z s U k J Z R p n t 5 K 2 I h q y m w a T x a C t / z y K m n V q t 5 F t f Z w W a n f 5 H E U 4 Q R O 4 RA I = \" > A A A B 7 X i c b V B N S w M x E J 3 4 W e t X 1 a O X Y B E 8 l d 0 q 6 L H o x W M F + w H t U r J p t k 2 b T Z Y k K 5 S l / 8 G L B 0 W 8 + n + 8 + W 9 M 2 z 1 o 6 4 O B x 3 s z z M w L E 8 G N 9 b x v t L a + s b m 1 X d g p 7 u 7 t H x y W j o 6 b R q W a s g Z V Q u l 2 S A w T X L K G 5 V a w d q I Z i U P B W u H 4 b u a 3 n p g 2 X M l H O 0 l Y E J O B 5 B G n x D q p a X o Z H 0 1 7 p b J X 8 e b A q 8 T P S R l y 1 H u l r 2 5 f 0 T R m 0 l J B j O n 4 X m K D j G j L q W D T Y j c 1 L C F 0 T A a s 4 6 g k M T N B N r 9 2 i s + d 0 s e R 0 q 6 k x X P 1 9 0 R G Y m M m c e g 6 Y 2 K H Z t m b i f 9 5 n d R G N 0 H G Z Z J a J u l i U Z Q K b B W e v Y 7 7 X D N q x c Q R Q j V 3 t 2 I 6 J J p Q 6 w I q u h D 8 5 Z d X S b N a 8 S 8 r 1 Y e r c u 0 2 j 6 M A p 3 A G F + D D N d T g H u r Q A A o j e I Z X e E M K v a B 3 9 L F o X U P 5 z A n 8 A f r 8 A e b H j 1 c = < / l a t e x i t > \u2026 Paragraph: Hypotheis (subquestions): N N N \u2026 K e sup < l a t e x i t s h a 1 _ b a s e 6 4 = \" C k T v r H J A Z 7 W N j M J l B a I D B + 2 y b z E = \" > A A A C A H i c b V B N S 8 N A E N 3 U r 1 q / q h 4 8 e A k W w V N J q q D H o h e P F e w H t K V s t p N 2 6 W Y T d i d i C b n 4 V 7 x 4 U M S r P 8 O b / 8 Z N m 4 O 2 P h h 4 v D f D z D w v E l y j 4 3 x b h Z X V t f W N 4 m Z p a 3 t n d 6 + 8 f 9 D S Y a w Y N F k o Q t X x q A b B J T S R o 4 B O p I A G n o C 2 N 7 n J / P Y D K M 1 D e Y / T C P o B H U n u c 0 b R S I P y U S + g O P b 8 B A Z J D + E R E x 1 H a Z o O y h W n 6 s x g L x M 3 J x W S o z E o f / W G I Y s D k M g E 1 b r r O h H 2 E 6 q Q M w F p q R d r i C i b 0 B F 0 D Z U 0 A N 1 P Z g + k 9 q l R h r Y f K l M S 7 Z n 6 e y K h g d b T w D O d 2 b l 6 0 c v E / 7 x u j P 5 V P + E y i h E k m y / y Y 2 F j a G d p 2 E O u g K G Y G k K Z 4 u Z W m 4 2 p o g x N Z i U T g r v 4 8 j J p 1 a r u e b V 2 d 1 G p X + d x F M k x O S F n x C W X p E 5 u S Y M 0 C S M\np e S a v 5 M 1 6 s l 6 s d + t j 3 l q w 8 p l D 8 g f W 5 w 9 W Y Z e I < / l a t e x i t > Top-K p 0 1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" S 8 f l\nI h 6 x d G D h n F c 8 U / o Y X 2 2 3 C m s = \" > A A A B 6 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 m q o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p 7 i b s b o Q S + h e 8 e F D E q 3 / I m / / G T Z q D t j 4 Y e L w 3 w 8 y 8 I O Z M G 9 f 9 d k p r 6 x u b W + X t y s 7 u 3 v 5 B 9 f C o o 6 N E E d o m E Y 9 U L 8 C a c i Z p 2 z D D a S 9 W F I u A 0 2 4 w v c v 8 7 h N V m k X y 0 c x i 6 g s 8 l i x k B J t M i o f e + b B a c + t u D r R K v I L U o E B r W P 0 a j C K S C C o N 4 V j r v u f G x k + x M o x w O q 8 M E k 1 j T K Z 4 T P u W S i y o 9 t P 8 1 j k 6 s 8 o I h Z G y J Q 3 K 1 d 8 T K R Z a z 0 R g O w U 2 E 7 3 s Z e J / X j 8 x 4 Y 2 f M h k n h k q y W B Q m H J k I Z Y + j E V O U G D 6 z B B P F 7 K 2 I T L D C x N h 4 K j Y E b / n l V d J p 1 L 3 L e u P h q t a 8 L e I o w w m c w g V 4 c A 1 N u I c W t I H A B J 7 h F d 4 c 4 b w 4 7 8 7 H o r X k F D P H 8 A f O 5 w 9 h 0 o 3 N < / l a t e x i t > p 0 2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" Z A D x n l m N z B q P 0 u I N C R B V T 5 U o X R M = \" > A A A B 6 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 m q o M e i F 4 8 V 7 A e 0 o W y 2 m 3 b p 7 i b s b o Q S + h e 8 e F D E q 3 / I m / / G T Z q D t j 4 Y e L w 3 w 8 y 8 I O Z M G 9 f 9 d k p r 6 x u b W + X t y s 7 u 3 v 5 B 9 f C o o 6 N E E d o m E Y 9 U L 8 C a c i Z p 2 z D D a S 9 W F I u A 0 2 4 w v c v 8 7 h N V m k X y 0 c x i 6 g s 8 l i x k B J t M i o e N 8 2 G 1 5 t b d H G i V e A W p Q Y H W s P o 1 G E U k E V Q a w r H W f c + N j Z 9 i Z R j h d F 4 Z J J r G m E z x m P Y t l V h Q 7 a f 5 r X N 0 Z p U R C i N l S x q U q 7 8 n U i y 0 n o n A d g p s J n r Z y 8 T / v H 5 i w h s / Z T J O D J V k s S h M O D I R y h 5 H I 6 Y o M X x m C S a K 2 V s R m W C F i b H x V G w I 3 v L L q 6 T T q H u X 9 c b D V a 1 5 W 8 R R h h M 4 h Q v w 4 B q a c A 8 t a A O B C T z D K 7 w 5 w n l x 3 p 2 P R W v J K W a O 4 Q + c z x 9 j V 4 3 O < / l a t e x i t > p 0 M < l a t e x i t s h a 1 _ b a s e 6 4 = \" 5 4 L R o 6 v g Y G l v y 1 J 5 d y G 3 N Z X 4 D f g = \" > A A A B 6 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b R U 9 l t B T 0 W v X g R K t g P a J e S T b N t a J J d k q x Q l v 4 F L x 4 U 8 e o f 8 u a / M d v u Q V s f D D z e m 2 F m X h B z p o 3 r f j u F t f W N z a 3 i d m l n d 2 / / o H x 4 1 N Z R o g h t k Y h H q h t g T T m T t G W Y 4 b Q b K 4 p F w G k n m N x m f u e J K s 0 i + W i m M f U F H k k W M o J N J s W D + / N B u e J W 3 T n Q K v F y U o E c z U H 5 q z + M S C K o N I R j r X u e G x s / x c o w w u m s 1 E 8 0 j T G Z 4 B H t W S q x o N p P 5 7 f O 0 J l V h i i M l C 1 p 0 F z 9 P Z F i o f V U B L Z T Y D P W y 1 4 m / u f 1 E h N e + y m T c W K o J I t F Y c K R i V D 2 O B o y R Y n h U 0 s w U c z e i s g Y K 0 y M j a d k Q / C W X 1 4 l 7 V r V q 1 d r D 5 e V x k 0 e R x F O 4 B Q u w I M r a M A d N K E F B M b w D K /\nw 5 g j n x X l 3 P h a t B S e f O Y Y / c D 5 / A I x e j e k = < / l a t e x i t > 1 \uf8ff j \uf8ff N < l a t e x i t s h a 1 _ b a s e 6 4 = \" x v 5 e Z + z j w N 5 d\n3 A 2 2 X k W w L o o 2 G 8 Q = \" > A A A B + X i c b V B N S 8 N A E J 3 4 W e t X 1 K O X x S J 4 K k k V 9 F j 0 4 k k q 2 A 9 o Q 9 l s p + 3 a z S b u b g o l 9 J 9 4 8 a C I V / + J N / + N S Z u D t j 4 Y 5 v H e D D v 7 / E h w b R z n 2 1 p Z X V v f 2 C x s F b d 3 d v f 2 7 Y P D h g 5 j x b D O Q h G q l k 8 1 C i 6 x b r g R 2 I o U 0 s A X 2 P R H N 5 n f H K P S P J Q P Z h K h F 9 C B 5 H 3 O q E m l r m 2 7 p C P w i T z O 2 1 2 x a 5 e c s j M D W S Z u T k q Q o 9 a 1 v z q 9 k M U B S s M E 1 b r t O p H x E q o M Z w K n x U 6 s M a J s R A f Y T q m k A W o v m V 0 + J a e p 0 i P 9 U K U l D Z m p v z c S G m g 9 C f x 0 M q B m q B e 9 T P z P a 8 e m f + U l X E a x Q c n m D / V j Q U x I s h h I j y t k R k x S Q p n i 6 a 2 E D a m i z K R h Z S G 4 i 1 9 e J o 1 K 2 T 0 v V + 4 v S t X r P I 4 C H M M J n I E L l 1 C F W 6 h B H R i M 4 R l e 4 c 1 K r B f r 3 f q Y j 6 5 Y + c 4 R / I H 1 + Q M R o J H + < / l a t e x i t > s 1j < l a t e x i t s h a 1 _ b a s e 6 4 = \" u p A 2 3 2 s M 6 u N V k 6 q t o G C f B 9 + 5 h l E = \" > A A A B 7 X i c b V B N S w M x E J 3 4 W e t X 1 a O X Y B E 8 l d 0 q 6 L H o x W M F + w H t U r J p t k 2 b T Z Y k K 5 S l / 8 G L B 0 W 8 + n + 8 + W 9 M 2 z 1 o 6 4 O B x 3 s z z M w L E 8 G N 9 b x v t L a + s b m 1 X d g p 7 u 7 t H x y W j o 6 b R q W a s g Z V Q u l 2 S A w T X L K G 5 V a w d q I Z i U P B W u H 4 b u a 3 n p g 2 X M l H O 0 l Y E J O B 5 B G n x D q p a X q Z P 5 r 2 S m W v 4 s 2 B V 4 m f k z L k q P d K X 9 2 + o m n M p K W C G N P x v c Q G G d G W U 8 G m x W 5 q W E L o m A x Y x 1 F J Y m a C b H 7 t F J 8 7 p Y 8 j p V 1 J i + f q 7 4 m M x M Z M 4 t B 1 x s Q O z b I 3 E / / z O q m N b o K M y y S 1 T N L F o i g V 2 C o 8 e x 3 3 u W b U i o k j h G r u b s V 0 S D S h 1 g V U d C H 4 y y + v k m a 1 4 l 9 W q g 9 X 5 d p t H k c B T u E M L s C H a 6 j B P d S h A R R G 8 A y v 8 I Y U e k H v 6 G P R u o b y m R P 4 A / T 5 A 5 F 3 j x 8 = < / l a t e x i t > s 2j < l a t e x i t s h a 1 _ b a s e 6 4 = \" i E w x c B U T h I J I e G p 5 J S S B W w O 6 P N E = \" > A A A B 7 X i c b V B N S w M x E J 3 4 W e t X 1 a O X Y B E 8 l d 0 q 6 L H o x W M F + w H t U r J p t k 2 b T Z Y k K 5 S l / 8 G L B 0 W 8 + n + 8 + W 9 M 2 z 1 o 6 4 O B x 3 s z z M w L E 8 G N 9 b x v t L a + s b m 1 X d g p 7 u 7 t H x y W j o 6 b R q W a s g Z V Q u l 2 S A w T X L K G 5 V a w d q I Z i U P B W u H 4 b u a 3 n p g 2 X M l H O 0 l Y E J O B 5 B G n x D q p a X p Z d T T t l c p e x Z s D r x I / J 2 X I U e + V v r p 9 R d O Y S U s F M a b j e 4 k N M q I t p 4 J N i 9 3 U s I T Q M R m w j q O S x M w E 2 f z a K T 5 3 S h 9 H S r u S F s / V 3 x M Z i Y 2 Z x K H r j I k d m m V v J v 7 n d V I b 3 Q Q Z l 0 l q m a S L R V E q s F V 4 9 j r u c 8 2 o F R N H C N X c 3 Y r p k G h C r Q u o 6 E L w l 1 9 e J c 1 q x b + s V B + u y r X b P I 4 C n M I Z X I A P 1 1 C D e 6 h D A y i M 4 B l e 4 Q 0 p 9 I L e 0 c e i d Q 3 l M y f w B + j z B 5 L 9 j y A = < / l a t e x i t > s Mj < l a t e x i t s h a 1 _ b a s e 6 4 = \" x V Q 2 g B l F u z j 6 v n i W b d W Z Y Z q D d 3 A = \" > A A A B 7 X i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 m t g h 6 L X r w I F e w H t E v J p t k 2 b T Z Z k q x Q l v 4 H L x 4 U 8 e r / 8 e a / M d v u Q V s f D D z e m 2 F m X h B z p o 3 r f j u F t f W N z a 3 i d m l n d 2 / / o H x 4 1 N I y U Y Q 2 i e R S d Q K s K W e C N g 0 z n H Z i R X E U c N o O J r e Z 3 3 6 i S j M p H s 0 0 p n 6 E h 4 K F j G B j p Z b u p / f j W b 9 c c a v u H G i V e D m p Q I 5 G v / z V G 0 i S R F Q Y w r H W X c + N j Z 9 i Z R j h d F b q J Z r G m E z w k H Y t F T i i 2 k / n 1 8 7 Q m V U G K J T K l j B o r v 6 e S H G k 9 T Q K b G e E z U g v e 5 n 4 n 9 d N T H j t p 0 z E i a G C L B a F C U d G o u x 1 N G C K E s O n l m C i m L 0 V k R F W m B g b U M m G 4 C 2 / v E p a t a p 3 U a 0 9 X F b q N 3 k c R T i B U z g H D 6 6 g D n f Q g C Y Q G M M z v M K b I 5 0 X 5 9 3 5 W L Q W n H z m G P 7 A + f w B v B + P O w = = < / l a t e x i t > max max\nFigure 6: Illustration of evidence paragraph retrieval process.The notations corresponds to our descriptions in Section 6.K is a hyperparameter controlling the number of passages to retrieve.with the decomposed claims (from predicted and annotated (gold) subquestions) and the original claim on the Validation-sub set.A random baseline achieves 24.9 F1 and human annotators achieve 69.0 F1.\n\npare the performance of NLI models with random, BM25, and human baselines.We first convert the corresponding subquestions q = q 1 , ..., q N of claim c to a set of statements h = h 1 , ..., h n using GPT-3 (Brown et al., 2020). 5We find that with only 10 examples as demonstration, GPT-3 can perform the conversion quite well (with an error rate less than 5%).For more information about the prompt see Appendix G.\n\nTo retrieve the evidence that supports the statements, we treat the statements as hypotheses and the paragraphs in the article as premises.We feed them into an NLI model to compute the score associated with the \"entailment\" class for every premise and hypothesis pair.Here, the score for paragraph p i and hypothesis h j is defined as the output probability s ij = P (Entailment | p i , h j ).We then select as evidence the top k paragraphs by score across all subquestions: for paragraph p i , we define p i = max({s ij | 1 \u2264 j \u2264 N }), which denotes for each hypothesis from 1 to N that the jth hypothesis h j achieves the highest score with p i .Then e sup = {p i | i \u2208 Top-K({p 1 , ..., p M })}.We set k to be the number of the paragraphs that are annotated with either support or refute.Figure 6 describes this approach.\n\nTo retrieve the evidence that refutes the statements, we follow the same process, but with the negated hypotheses set h generated by GPT3.(Note that our NLI models trained on NQ-NLI and DocNLI only have two classes, entailed and not entailed, and not entailed is not a sufficient basis for retrieval.)The final evidence set is obtained by merging the evidence from the support and refute set.This is achieved by removing duplicates then taking Top-K paragraphs according to the scores.\n\nBM25 baseline model uses retrieval score instead of NLI score.The random baseline randomly assign support, refute, neutral labels to paragraphs based on the paragraph label distribution in Table 7. Human performance is computed by selecting one of the three annotators and comparing their annotations with the other two (we randomly pick one annotator if they do not agree), taking the average over all three annotators.This is not directly comparable to the annotations for the other techniques as the gold labels are slightly different.\n\n\nResults\n\nThe results are shown in Table 8.We see that the decomposed questions are effective to retrieve the evidence.By aggregating evidence from the subquestions, both BM25 and the NLI models can do better than using the claim alone, except for the case of using DocNLI, and BM25 with the predicted decomposition.The best model with gold annotations (59.6) is close to human performance (69.0) in this limited setting, indicating that the detailed and implied information in decomposed questions can help gathering evidence beyond the surface level of the claim.\n\nDocNLI outperforms BM25 on both the annotated decomposition and the predicted decomposition.This demonstrates the potential of using the NLI models to aid the evidence retrieval in the wild, although they must be combined with decomposition to yield good results.\n\n\nRelated Work\n\nFact-checking Vlachos and Riedel (2014) proposed to decompose the fact-checking process into three components: identifying check-worthy claims, retrieving evidence, and producing verdicts.Various datasets have been proposed, including human-generated claims based on Wikepedia (Thorne et al., 2018;Chen et al., 2019;Jiang et al., 2020;Schuster et al., 2021;Aly et al., 2021), real-world political claims (Wang, 2017;Alhindi et al., 2018;Augenstein et al., 2019;Ostrowski et al., 2021;Gupta and Srikumar, 2021), and science claims (Wadden et al., 2020;Saakyan et al., 2021).Our dataset focuses on real-world political claims, particularly more complex claims than past work which necessitate the use of decompositions.\n\nOur implied subquestions go beyond what is mentioned in the claim, asking the intention and political agenda of the speaker.Gabriel et al. (2022) study such implications by gathering expected readers' reactions and writers' intentions towards news headlines, including fake news headlines.\n\nTo produce verdicts of the claims, other work generates explanations for models' predictions.Popat et al. (2017Popat et al. ( , 2018)) 2020) modeled the explanation generation as a summarization task.Combining answers to the decomposed questions in our work can form an explicit explanation of the answer.\n\nQuestion Generation Our work also relates to question generation (QG) (Du et al., 2017), which has been applied to augment data for QA models (Duan et al., 2017;Sachan and Xing, 2018;Alberti et al., 2019), evaluate factual consistency of summaries (Wang et al., 2020;Durmus et al., 2020;Kamoi et al., 2022), identify semantic relations (He et al., 2015;Klein et al., 2020;Pyatkin et al., 2020), and identify useful missing information in a given context (clarification) (Rao and Daum\u00e9 III, 2018;Shwartz et al., 2020;Majumder et al., 2021).Our work is most similar to QABriefs (Fan et al., 2020), but differs from theirs in two ways: (1) We generate yes-no questions directly related to checking the veracity of the claim.(2) Our questions are more comprehensive and precise.\n\n\nConclusion\n\nWe present a dataset containing more than 1,000 real-world complex political claims with their decompositions in question form.With the decompositions, we are able to check the explicit and implicit arguments made in the claims.We also show the decompositions can play an important role in both evidence retrieval and veracity composition of an explainable fact-checking system.\n\n\nInteraction of retrieval and decomposition\n\nThe evidence retrieval performance depends on the quality of the decomposed questions (compare our results on generated questions to those on annotated questions in Section 6).Yet, generating high-quality questions requires relevant evidence context.These two modules cannot be strictly pipelined and we envision that in future work, they will need to interact in an iterative fashion.For example, we could address this with a human-inthe-loop approach.First, retrieve some context passages with the claim to verify as a query, possibly focused on the background of the claim and the person who made the claim.This retrieval can be done by a system or a fact-checker.Then, we use context passages to retrain the QG model with the annotations we have and the fact-checker can make a judgment about those questions, adding new questions if the generated questions do not cover the whole claim.We envision that such a process can make fact-checking easier while providing data to train the retrieval and QG models.\n\n\nDifficulty of automatic question comparison\n\nAs discussed in section 4, automatic metrics to evaluate our set of generated questions do not align well with human judgments.Current automatic metrics are not sensitive enough to minor changes that could lead to different semantics for a question.For example, changing \"Are all students in Georgia required to attend chronically failing schools?\" to \"Are students in Georgia required to attend chronically failing schools?\" yields two questions that draw an important contrast.However, we will get an extremely high BERTScore (0.99) and ROUGE-L score (0.95) between the two questions.Evaluating question similarity without considering how the questions will be used is challenging, since we do not know what minor distinctions in questions may be important.We suggest measuring the quality of the generated questions on some downstream tasks, e.g., evidence retrieval.\n\nGeneral difficulty of the task We have not yet built a full pipeline for fact-checking in the true real-world scenario.Instead, we envision our proposed question decomposition as an important step of such a pipeline, where we can use the candidate decompositions to retrieve deeper information and verify or refute each subquestion, then compose the results of the subquestions into an inherently explainable decision.In this paper, we have shown that the decomposed questions can help the retriever in a clean setting.But retrieving evidence in the wild is extremely hard since some statistics are not accessible through IR and not all available information is trustworthy (Singh et al., 2021), which are issues beyond the scope of this paper.Through the Question Aggregation probing, we also show the potential of composing the veracity of claims through the decisions from the decomposed questions.The proposed dataset opens a door to study the core argument of a complex claim.\n\n\nDomain limitations and lack of representation\n\nThe dataset we collected only consists of English political claims from the PolitiFact website.These claims are US-centric and largely focused on politics; hence, our results should be interpreted with respect to these domain limitations.\n\nBroader impact: opportunities and risks of deployment Automated fact checking can help prevent the propagation of misinformation and has great potential to bring value to society.However, we should proceed with caution as the output of a fact-checking system-the veracity of a claimcould alter users' views toward someone or something.Given this responsibility, we view it as crucial to develop explainable fact-checking systems which inform the users which parts of the claim are supported, which parts are not, and what evidence supports these judgments.In this way, even if the system makes a mistake, users will be able to check the evidence and draw the conclusion themselves.Although we do not present a full fact-checking system here, we believe our dataset and study can help pave the way towards building more explainable systems.By introducing this claim decomposition task and the dataset, we will enable the community to further study the different aspects of real-world complex claims, especially the implied arguments behind the surface information.our annotators from Upwork and UT Austin: Andrew Baldino, Scarlett Boyer, Catherine Coursen, Samantha Dewitt, Abby Mortimer, E Lee Riles, Keegan Shults, Justin Ward, Meona Khetrapal, Misty Peng, Payton Wages, and Maanasa V Darisi.\n\n\nA Question Annotation Workflow\n\n\nA.1 Workflow\n\nTracing the thought process of professional factcheckers requires careful reading.Thus, instead of using crowdsourcing platforms with limited quality control, we recruit 8 workers with experience in literature or politics from the freelancing platform Upwork. 7We pay the annotators $1.75 per claim, which translates to around $30/hour.8Each annotator labeled an initial batch of articles and we provided feedback on their annotation.We communicated with annotators during the process.\n\nWe posted a job advertisement including the description and the payment plan of our task on the Upwork platform.In total 14 workers applied for the position.We first conducted an initial qualification round in which we released an initial batch of 15 documents for the annotators to complete, for which we paid $35.This initial batch was used to judge how suitable the annotators are for this task.We reviewed the annotations and give detailed feedback to each annotator for every claim along with our suggested annotation for reference.We selected annotators whose annotation met our qualifications to continue to the next round.In the initial round, we selected 8 out of the 14 annotators who applied.\n\nAfter the initial round, we released new example batches to the annotators on a weekly basis.Each batch contained 100 examples for which we paid $175.The hired annotators were required to complete at least one batch per week and they could do up to 2 batches per week.9\n\n\nA.2 Annotation Interface\n\nThe interface of the main question decomposition task is shown in Figure 7.\n\n\nB Evidence Annotation Interface\n\nThe interface to annotate the supporting/refuting evidence described in section 6 is shown in Figure 8.\n\n\nC User Study Interface\n\nThe annotation interface of our user study conducted in Section 5.2 is shown in Figure 9.\n\n\nD Inter-annotator Agreement\n\nTwo examples of our inter-annotator agreement assessment are shown in Figure 10.In the first example, we treat Q3 of annotator A as not covered by annotator B. It is a weaker version of Q2 but not mentioned by annotator B. Q4 of annotator A has similar semantics as Q3 of annotator B so we do not mark it.\n\n\nE Automatic Claim Decomposition Evaluation\n\nFor the evaluation in Section 4, we also explored an automated method for assessing whether generated questions match ground truth ones.We aim to define a metric m(q, q) that compares the two sets of generated questions.However, we lack good offthe-shelf methods for comparing sets of strings like this.Instead, we rely on existing scoring functions that can compare single strings, like ROUGE and BERTScore (Zhang et al., 2019).Following other alignment-based methods like SummaC (Laban et al., 2022) for summarization factuality, we view these metrics as: m(q, q) = argmax a s(q a i , qi ), where a is an alignment variable.This problem can be viewed as finding the maximum-weight matching in a bipartite graph.We use the Hungarian algorithm (Kuhn, 1955) to compute this alignment and we take the mean of max matching as the result.The results are shown in Table 9.\n\nThe automatic metrics are not well aligned with the human judgments.We see that the Pearson coefficient between human judgments and the automatic metrics ranges from 0.42-0.54and 0.21-0.45for QG-MULTIPLE and QG-NUCLEUS respectively.The large instability of the Pearson coefficient indicates that the automatic evaluation may not accurately reflect the quality of the generated questions.Therefore, evaluating the generated questions on downstream tasks could be more accurate, hence why we also study evidence retrieval.\n\n\nF Training Details for Question Generation\n\nFor QG-MULTIPLE, each instance of the input and the output are constructed according to the tem-plate:\nN [S]c[S] \u2212\u2192 q 1 [S]q 2 [S], ..., q N\nwhere [S] denotes the separator token of the T5 model.N denotes the number of questions to generate; we introduce this into the input to serve as a control variable and set it to match the number of annotated questions during training.c denotes the claim and q i denotes the ith annotated question and we do not assume a specific order for the questions.\n\nThe model is trained using the seq2seq framework of Hugging Face (Wolf et al., 2020).The max sequence length for input and output is set to 128 and 256 respectively.The batch size is set to 8 and we use DeepSpeed for memory optimization (Rasley et al., 2020).We train the model on our training set for 20 epochs with AdamW (Loshchilov and Hutter, 2018) optimizer and an initial learning rate set to 3e-5.\n\nAt inference, we use beam search with beam size set to 5. We prepend the number of questions to generate (N ) at the start of the claim in the input.\n\nFor QG-NUCLEUS, we construct multiple inputoutput instances (c \u2192 q i ) for each claim, where q i denotes the ith decomposed question of claim c.The max sequence length for input and output are both set to 128.The batch size is set to 16 and we use DeepSpeed for memory optimization.We train the model on our training set for 10 epochs with AdamW optimizer and an initial learning rate set to 3e-5.\n\nWe expect this model to place a flatter distribution over the output space, assigning many possible questions high weight due to the training data including multiple outputs for the same input.At inference, we use nucleus sampling (Holtzman et al., 2019) in which p is set to 0.95 together with top-k sampling (Fan et al., 2018) in which k is set to 50 to generate questions.We filter out the duplicates (exact string match) in the sampled questions set.\n\n\nG GPT-3 for Question Conversion\n\nGiven a question, we let GPT-3 generate its declarative form as well as the negated form of the statement.We achieve this by separating them using \"|\" in the prompt.One advantage of using GPT-3 is that it can easily generate natural sentences.For example, for question \"Are any votes illegally counted in the election?\",GPT-3 generates the statement and its negation as \"Some votes were illegally counted in the election.\"and Model Rouge-1 (P) Rouge-2 (P) Rouge-l (P) Bert-score (P)  \"No votes were illegally counted in the election.\".\n\nA demonstration of the prompt we used for the question conversion is shown as follows:\n\nQuestion: Are unemployment rates for African Americans and Hispanics low today?Statement: Unemployment rates for African Americans and Hispanics are low today.| Unemployment rates for African Americans and Hispanics are not low today.\n\n\nH Qualitative Analysis of Generated Questions\n\nTable 12 includes more examples where the generated questions do not match the annotations but also worth checking.For example, for the second claim, our model generates the question \"Did any other states have a spike in coronavirus cases related to voting?\"Although the gold fact-check did not address this question, this kind of context is the kind of thing a fact-checker may want to be attentive to, even if the answer ends up being no, and we judge this to be a reasonable question to ask given only the claim.\n\n\nI More examples of QABriefs\n\nWe include more examples reflecting the annotation difference between our method and QABriefs in Figure 11.\n\nJ Datasheet for CLAIMDECOMP J.1 Motivation for Datasheet Creation Why was the dataset created?Despite the progress made in automating the fact-checking process, the performance achieved by current models is relatively poor.Systems in this area fundamentally need to be designed with an eye towards human verification, motivating our effort to build more explainable models so that the explanations can be used to interpret a model's behavior.Therefore, we create this dataset to facilitate future research to achieve this goal.We envision that by verifying each question, we can compose the final veracity of the claim in inherently explainable way.\n\nHas the dataset been used already?The dataset has not been used beyond the present paper, where it was used to train a question generation model and in several evaluation conditions.\n\nWho funded the dataset?This dataset was funded by Good Systems, 10 a UT Austin Grand Challenge to develop responsible AI technologies.\n\n\nJ.2 Dataset Composition\n\nWhat are the instances?Each instance is a realworld political claim.All claims are written in English and most of them are US-centric.\n\nalready notable and we are not playing a significant role in spreading false claims as part of our dataset.Moreover, these claims are publicly available on PolitiFact along with expert assessment of their correctness.We believe that there is a low risk of someone being misled by information they see presented in our dataset.\n\nIf it relates to people, does it unfairly advantage or disadvantage a particular social group?\n\nWe acknowledge that, because our dataset only covers English and annotators are required to be located in the US, our dataset lacks representation of claims that are relevant in other languages and to people around the world.The claims themselves could reflect misinformation rooted in racism, sexism, and other forms of intergroup bias.\n\n4\n\nthe maximum amount you can get from payday lenders?What percentage of US troops use a payday lender?helpful background but not precisely about claim useful context but not directly about claim 3 useful context but not directly about claim Has Barr received $36,550 from payday lenders?3Did Barr vote for legislation that would weaken restrictions for payday lenders?\n\n\n\n\nw 8 u I I 6 3 E E D m s B g B M / w C m + O d F 6 c d + d j 0 V p w 8 p l j + A P n 8 w d g a o 3 M < / l a t e x i t > \u2026 s ij < l a t e x i t s h a 1 _ b a s e 6 4 = \" A W N O z Z 7 R s T 0 F r y u D 6 n 0 7 h b o B u\n\n\n\n\n; Shu et al. (2019); Yang et al. (2019); Lu and Li (2020) presented attentionbased explanations; Gad-Elrab et al. (2019); Ahmadi et al. (2019) used logic-based systems, and Atanasova et al. (2020); Kotonya and Toni (\n\n\n\n\nQuestion: Were 1700 mail-in ballots investigated for fraud in Texas?Statement: 1700 mail-in ballots were investigated for fraud in Texas | 1700 mail-in ballots were not investigated for fraud in Texas Question: Is Wisconsin guaranteeing Foxconn nearly $3 billion?Statement: Wisconsin guarantees Foxconn nearly $3 billion.| Wisconsin does not guarantee Foxconn nearly $3 billion.Question: Will changes in this law raise taxes for anyone?Statement: The changes in this law will raise taxes for someone.| The changes in this law will raise taxes for no one.Question: Has Donnelly directly sponsored any of these legislative proposals since becoming a senator?Statement: Donnelly directly sponsored some of these legislative proposals since becoming a senator.| Donnelly directly sponsored none of these legislative proposals since becoming a senator.\n\n\n\n\n\n\n\n\n\n\n\n\nTable 1 :\n1\nStatistics of the CLAIMDECOMP dataset.Each claim is annotated by two annotators, yielding a total of 6,555 subquestions.The second column blocks (Answer % and Source %) report the statistics at the subquestion level; Source % denotes the percentage of subquestions based on the text from the justification or the claim.\n# unique# tokensavg. # subquestionsAnswer %Source %Splitclaimsper claim in single annotationYesNoUnknown Justification ClaimTrain80033.42.748.9 45.35.883.616.4Validation20033.82.748.3 44.86.979.021.0Validation-sub5033.72.945.2 47.87.090.49.6Test20033.22.745.8 43.111.192.17.9\n\nTable 2 :\n2\nInter-annotator agreement assessed by the percentage of questions for which the semantics cannot be matched to the other annotator's set.We name the question set containing more questions as MORE QS and the other one as LESS QS.ALL QS is the average of MORE QS and LESS QS.\n\n\n\n\ne x i t >\nsamplesamplesampleFigure 3: Illustration of our two question generators.QG-MULTIPLE generates all questions as a sequencewhile QG-NUCLEUS generates one question at a timethrough multiple samples.ModelR-all R-literal R-impliedQG-MULTIPLE0.580.740.18QG-NUCLEUS0.430.590.11QG-MULTIPLE-JUSTIFY0.810.950.50QG-NUCLEUS-JUSTIFY0.520.720.18\n\nTable 4 :\n4\nNumber of questions of each type per claim and their lexical overlap with the claim measured by ROUGE-1, ROUGE-2, and ROUGE-L precision (how many n-grams in the question are also in the claim).\nQuestion Type # Questions R1-P R2-P RL-PLiteral2.150.560.300.47Implied1.020.280.090.22\n\nof whether the stock market is correlated with the elec4on. )\n\nClaim: \"When President Obama was elected, the market crashed \u2026 Trump was up 9%, President Obama was down 14.8% and President Bush was down almost 4%.There is an instant reaction on Wall Street.\"Question: Did Obama cause the stock market crash when he was elected?(Domain knowledge With voting by mail, \"you get thousands and thousands of people \u2026 signing ballots all over the place.\"Question: Is there a greater risk of voting fraud with mail-in ballots?(Need to\nDomainknowledge(38.8%)ContextClaim:(37.6%)\n\nknow the background that the claim is about the poten4al risks of mail-in ballots.)\nImplicitClaim: Nancy Pelosi bought $1.25 million in Tesla stock the day before Joe Biden signed an order \"for all federalmeaningvehicles\" to be electric.(16.5%)Question: Were the stock purchases improper insider trading? (\n\nThe claim implies this purchase is insider trading.)\n\nClaim: \"No other country witnesses the number of gun deaths that we do here in the U.S., and it's not even close.\"Question: Is the United States the country with the the highest percentage of gun deaths?(Highest number\nStatisticalrigor(7.1%)\n\nof gun deaths does not entail highest percentage of gun deaths.)\n\nFigure 4: Four types of reasoning needed to address subquestions with their proportion (left column) and examples (right column).It shows that a high proportion of the questions need either domain knowledge or related context.\n\n\nTable 6 :\n6\nClaim classification performance of our question aggregation baseline vs. several baselines on the development set.MAE denotes mean absolute error.\n\n\nTable 7 :\n7\nEvidence paragraph retrieval data statistics on Validation-sub dataset (50 claims).\nper subquestion per example (claim)avg # of paras12.412.4% of context87.668.8% of support5.412.0% of refute8.019.2Fleiss Kappa0.420.42\n\nTable 8 :\n8\nEvidence retrieval performance (F1 score)\nModelDecomposed claim OriginalpredictedgoldclaimMNLI41.048.835.2NQ-NLI38.834.540.9DocNLI44.759.636.9BM2536.247.539.2\n\nTable 9 :\n9\nAutomatic evaluation results on the development set.Here, (P) denotes the Pearson correlation coefficient between the automatic metric and recall-all.-JUSTIFY denotes training the question generator by concatenating the claim and the justification paragraph as the input.\n\nWe release our code and dataset: https://jifan-chen. github.io/ClaimDecomp\nThere are cases where one generated question covers several reference questions, e.g., treating the whole claim as a question, in which case we only consider one of the reference questions to be recalled.\nhttps://www.politifact.com/\nMerging two annotations results in many duplicate questions and deduplicating these without another round of adjudication is cognitively intensive. We opted not to do this due to the effectiveness of simply taking the larger set of questions.\n, 1], respectively. We call this method question aggregation. We use the 50 claims and the corresponding questions from the Validation-sub set for evaluation. We also establish the upper bound (question aggregation*) for this heuristic by having one of the authors remove unrelated questions. On average, 0.3 questions are removed per claim.\nWe release the automatically converted statements and the negations for all of the subquestions in the published dataset.\nhttps://goodsystems.utexas.edu/\nhttps://www.upwork.com/\nWe asked the workers to report their speeds at the end of the task and found their actual hourly rates ranged between $18 and $50 per hour.\nWe intentionally limited this to avoid having a single annotator annotate a large portion of the examples.\nhttps://creativecommons.org/licenses/by-sa/4. 0/legalcode\nAcknowledgmentsThis dataset was funded by Good Systems, 6 a UT Austin Grand Challenge to develop responsible AI technologies, as well as NSF Grant IIS-1814522, NSF CAREER Award IIS-2145280, and gifts from Salesforce and Adobe.We would like to thanki c d Z F d a 9 s w F I Z l 9 2 O t + + V m l 7 0 R C 6 E p p M H u C u 1 l a X Y x 2 C 4 y 2 r S F O B h Z l h N R y T L S c a k x / p O 7 2 8 1 u 9 k e m p I F 2 7 X p A 8 P C + 5 3a 2 c x 6 B e e 3 N x f 9 5 4 x K y 8 0 n N 8 6 I E l t O n R V k p M C g 8 j x u n X D M K o r J A q O b 2 r p j O i C Y U 7 K d 4 N o T w 9 Z P f w s 1 J P / z c P / l x 2 r 6 4 X M a x g Q 7 Q J 9 R F I T p D F + g r G q I R o u i 3 sHow many instances are there?Our dataset consists of two-way annotation of 1,200 claims, and 6,555 decomposed questions.A detailed breakdown of the number of instances can be seen in Table1of the main paper.What data does each instance consist of?Each instance contains a real-world political claim and a set of yes-no questions with associated answers.Does the data rely on external resources?Yes, assembling it requires access to PolitiFact.Are there recommended data splits or evaluation measures?We include the recommended train, development, and test sets for our datasets.The distribution can be found in Table1.J.3 Data Collection ProcessHow was the data collected?We recruit 8 annotators with background in literature or politics from the freelancing platform Upwork.Given a claim paired with the justification written by the professional fact-checker on PolitiFact, we ask our annotators to reverse engineer the fact-checking process: generate yes-no questions which are answered in the justification part.For each question, the annotators also give the answer and select the relevant text in the justification that is used for the generation.The annotators are instructed to cover as many of the assertions made in the claim as possible without being overly specific in their questions.Who was involved in the collection process and what were their roles?The 8 annotators we recruited perform the all the annotation steps outlined above.Over what time frame was the data collected?The dataset was collected over a period from January to April 2022.Does the dataset contain all possible instances?Our dataset does not cover all possible political claims.It mainly include complex political claims made by notable political figures of the U.S. through 2012 to 2021.If the dataset is a sample, then what is the population?It represents a subset of all possible complex political claims which require verifying multiple aspects of the claim to reach a final veracity.Our dataset also only includes claims written in English.J.4 Data PreprocessingWhat preprocessing / cleaning was done?We remove any additional whitespace in the annotated questions, but otherwise we do not postprocess the annotations in any way.Was the raw data saved in addition to the cleaned data?Yes Does this dataset collection/preprocessing procedure achieve the initial motivation?Our collection process indeed achieves our initial goals of creating a high-quality dataset of complex political claims with the decompositions in question form.Using this data, we are able to check the explicit and implicit arguments made by the politicians.J.5 Dataset DistributionHow is the dataset distributed?We make our dataset available at https://jifan-chen.github.io/ClaimDecomp.When was it released?Our data and code is currently available.What license (if any) is it distributed under?CLAIMDECOMP is distributed under the CC BY-SA 4.0 license. 11Who is supporting and maintaining the dataset?This dataset will be maintained by the authors of this paper.Updates will be posted on the dataset website.J.6 Legal and Ethical ConsiderationsWere workers told what the dataset would be used for and did they consent?Crowd workers informed of the goals we sought to achieve through data collection.They also consented to have their responses used in this way through the Amazon Mechanical Turk Participation Agreement (note that even though we recruited through Upwork, workers performed annotation in the Mechanical Turk sandbox).If it relates to people, could this dataset expose people to harm or legal action?Our dataset does not contain any personal information of crowd workers.However, our dataset can include incorrect information in the form of false claims.These claims were made in a public setting by notable political figures; in our assessment, such claims are Claim Barry DuVal stated on September 25, 2015 in an interview: \" We 're the only major oil -producing nation in the world with a self -imposed ban on exporting our crude oil to other nations .\"Justification \"DuVal said the U.S. is the only major oil-producing nation in the world that bans export of its crude oil.Two experts we contacted agreed with DuVal's statement, and officials at the EIA said they're not aware of any other country with similar export restrictions.But the ban is not absolute --a small portion of U.S. crude is exported to Canada.\"According to the claim and its justification above, write down one or more binary questions (answerable by yes/no) that is answerable by the justification part.Remember the three rules: (1) Write questions that are helpful to verify the original claim.(2) Don't write questions that are too specific.You should also provide an answer to your question --yes/no.(3) Add questions from claim if the reasoning part doesn't cover everything.Also, you should copy-paste the justification text you used to generate the question (usually one sentence).Many claims have around 3 questions that are being addressed.We are most interested in collecting a comprehensive set of these questions, so we encourage you to write a few questions.Use the following buttons to add/remove inputs.Instructions:Thank you for participating in this task!The goal of this task is to identify the reasoning process of a fact-checker when checking complex claims made by politicians.The current batch is a pilot, we will adjust the task and scale the task in the future according to your annotations :)We will show you several paragraphs written by a professional fact-checker breaking down reasons why they think a claim is true or false.Your task is to identify the major questions that they are answering in this paragraph, specifically using binary (yes/no) questions.Your question should ideally be one that's motivated by the original claim.This claim was what the fact-checkers were checking, so it was the starting point for their analysis.The questions should not be overly specific.For example, if the analysis describes how unemployment fell by 5% over a six-year time period, the question \"Did unemployment fall over this period?\" is better than \"Did unemployment fall by 5% over a six-year time period?\"The first question is probably the one that the fact-checker set out to answer, and the specific statistics are just part of that answer to the question.Add questions from claim if the reasoning part doesn't cover everything: Sometimes the reasoning part only checks the most important aspects of the claim leaving some minor aspects unchecked.In such cases, you should add questions according to the claim to make sure all aspects in the claim is covered by the questions.Below we provide examples to help you better understand the task.Claim Decision making justification Questions ExplanationBarry DuVal stated on September 25, 2015 in an interview: \"We're the only major oil-producing nation in the world with a self-imposed ban on exporting our crude oil to other nations.\"\"DuVal said the U.S. is the only major oil-producing nation in the world that bans export of its crude oil.Two experts we contacted agreed with DuVal's statement, and officials at the EIA said they're not aware of any other country with similar export restrictions.But the ban is not absolute --a small portion of U.S. crude is exported to Canada.\"So we rate his DuVal's statement Mostly True.Is the U.S. the only major oilproducing nation to ban exports of crude oil?(Yes)The first sentence of the justification is just a restatement of the claim, so we don't write any questions.This question is mainly based on the highlighted sentence of the justification.The main point of the sentence is that the U.S. is the only country that has a ban on exporting our crude oil.This also reflects what's expressed in the original claim.We think answering this question is helpful to check the original claim.Barry DuVal stated on September 25, 2015 in an interview: \"We're the only major oil-producing nation in the world with a self-imposed ban on exporting our crude oil to other nations.\"\"DuVal said the U.S. is the only major oil-producing nation in the world that bans export of its crude oil.Two experts we contacted agreed with DuVal's statement, and officials at the EIA said they're not aware of any other country with similar export restrictions.But the ban is not absolute --a small portion of U.S. crude is exported to Canada.\"So we rate his DuVal's statement Mostly True.Is the U.S. ban on crude oil export a complete ban? (No)Based on the highlighted part, we see it adds extra information over the crude oil ban.Although it is not explicitly mentioned in the original claim, the fact-checker felt that answering this question was important to give more context to the claim.The question \"Is a small portion of US crude exported to Canada?\" is not as good.Since Canada is not presented in the original claim, this was probably not what the fact-checker set out to answer; they only discovered it after doing their research.A Facebook post stated on January 31, 2021: \"Nancy Pelosi bought $1.25 million in Tesla stock the day before Joe Biden signed an order \"for all federal vehicles\" to be electric.\"\"An image shared on Facebook claims that Nancy Pelosi bought $1.25 million in Tesla stock the day before Biden signed an order \"for all federal vehicles\" to be electric, implying that she sought to profit from inside information about new government policies.The House speaker did report transactions involving Tesla stock, but the post misrepresented the purchases and Biden's policies to create the false impression that the transactions represented improper insider trading in Tesla shares.The statement contains an element of truth, but ignoring critical facts would give a different impression.Were the stock purchases improper insider trading?(No)The first part of this sentence talks about that the the stock purchases and Biden's policy were misrepresented, but both the purchase and the policy are mentioned in the original claim.Therefore, we don't ask the questions about the two parts here.This sentence also mentions the claim gives a false impression that this purchase involves insider trading, so we ask the above question here.A Facebook post stated on January 31, 2021: \"Nancy Pelosi bought $1.25 million in Tesla stock the day before Joe Biden signed an order \"for all federal vehicles\" to be electric.\"\"An image shared on Facebook claims that Nancy Pelosi bought $1.25 million in Tesla stock the day before Biden signed an order \"for all federal vehicles\" to be electric, implying that she sought to profit from inside information about new government policies.The House speaker did report transactions involving Tesla stock, but the post misrepresented the purchases and Biden's policies to create the false impression that the transactions represented improper insider trading in Tesla shares.The statement contains an element of truth, but ignoring critical facts would give a different impression.Does the executive order Biden signed require all federal vehicles to be electric?(unknown)Beyond the stock purchases, we need to check whether there actually was an order from Biden about electric vehicles.As the answer is not obvious from the reasoning part, we give \"unknown\" here.We feel like these three questions covered the reasoning that the factchecker wrote.It seems like these were the two most salient aspects they addressed.You can navigate all of the questions by clikcing the following buttons.Notice that you have to finish all the questions before submitting.If you feel the evidence is bad in general, e.g., none of the questions can be answered from the evidence, you may click the \"bad evidence\" button.SubmitIs African American unemployment the lowest ever recorded in the US in 2018?The evidence is bad?Annotation Instructions (Click to collapse)Instructions:Thank you for participating in this task!The goal of this task is to verify complex claims that politicians make: we want to break these claims down into simple pieces and understand how each of these pieces is individually supported or refuted by some evidence.Below is a claim made by Joe Biden:\"We have now created over 3 million jobs since I took office, more jobs than have ever been created in the first five months of any presidency in modern history.\"If we want to check if the whole claim is true, we would like to check the two sub-claims he made: (1) Have over 3 million jobs been created since Biden took office?(2) Is the number of jobs created in the first five months more than any presidency in modern history?Don't worry if you don't have a background on the issue discussed in the claim, your job is not fact-checking.We will provide a document written by a fact checker verifying the claim.The task is as follows:Verify the questions of a claim:Below we offer several questions related to one claim, you will see an article corresponding to the claim written by the professional fact-checkers.Your task is to select the paragraphs in the article that either support or refute the question you wrote.For each paragraph, we provide you three choices:1. Support: This paragraph provides supporting evidence to your question (according to this paragraph, the answer to your question is \"Yes\").2. Refute: This paragraph provides refuting evidence to your question (according to this paragraph, the answer to your question is \"No\").3. Context: This paragraph doesn't directly support or refute the question but acts as context to make you better understand the background of the claim.Every paragraph that is not directly support or refute the question should be marked as context.Usually, there are 1-3 paragraphs that act as the supporting/refuting evidence for the question.We provide an example below to help you better understand the task:Question: Was George Romney a liberal Republican?Question: Did Saul Alinsky write the book \"Rule For Radicals\"?Paragraphs Choice ExplanationAlinsky was a Chicago community organizer who wrote the 1971 book \"\"Rules for Radicals: A Practical Primer for Realistic Radicals.\"\"The book offers advice to activists seeking to influence public policy, covering topics such as class differences and tactics such as disrupting meetings and winning media attention.Support From the paragraph we know Alinsky wrote the book \"Rules for Radicals\"Alinksy didn't dedicate his book to Satan.The word \"\"dedication\"\" isn't included in the intro -though he does have a \"\"personal acknowledgments\"\" section where Alinsky listed his wife and editors.Context Not directly related to the question However, Alinsky did indeed include an opening blurb on Lucifer, attributed to Alinsky himself.The epigraph is one of three; the other two quote Rabbi Hillel and philosopher Thomas Paine.Context Not directly related to the question Question: Did Saul Alinsky dedicate the book, Rules For Radicals to Satan?Paragraphs Choice ExplanationAlinsky was a Chicago community organizer who wrote the 1971 book \"\"Rules for Radicals: A Practical Primer for Realistic Radicals.\"\"The book offers advice to activists seeking to influence public policy, covering topics such as class differences and tactics such as disrupting meetings and winning media attention.Context Not directly related to the questionAlinksy didn't dedicate his book to Satan.The word \"\"dedication\"\" isn't included in the intro -though he does have a \"\"personal acknowledgments\"\" section where Alinsky listed his wife and editors.RefuteFrom the paragraph we know he didn't dedicate his book to Satan However, Alinsky did indeed include an opening blurb on Lucifer, attributed to Alinsky himself.The epigraph is one of three; the other two quote Rabbi Hillel and philosopher Thomas Paine.Context Not directly related to the question Yes No[0] \"President Donald Trump and his team found several positives to tout from the newest round of employment numbers .On Jan. 5 , the day the new numbers were released , presidential daughter and White House official Ivanka Trump tweeted , \"\" The unemployment rate for African Americans fell to 6.8 percent , the lowest ever recorded .We are working hard to bring this rate down even further .\"\" support refute[1] The president himself echoed the talking point in his own tweet Jan. 8 : \"\" African American unemployment is the lowest ever recorded in our country .The Hispanic unemployment rate dropped a full point in the last year and is close to the lowest in recorded history .Dems did nothing for you but get your vote !# NeverForget @foxandfriends .\"\" How accurate is the president 's tweet ?He 's right on the numbers but leaves out economic gains for those groups under Democratic control .support refute[2] Unemployment rates support refute[3] In December 2017 , African -American unemployment fell to 6.8 percent .That 's a record low since the statistic was first calculated in 1972 .The previous record low was 7 percent in April 2000 and September 2017 .The Hispanic unemployment also dropped by a full percentage point , from 5.9 percent in December 2016 to 4.9 percent in December 2017 .As the president said , this is close to the data point 's all -time low , which was 4.8 percent in October and November 2017 .support refute[4] Did Democrats do \"\" nothing \"\" for black and Hispanic unemployment ?The tweet would have been accurate if Trump had stopped after the numbers .But his dig on the Democrats marred his talking point .The unemployment rate for both groups declined dramatically on President Barack Obama 's watch .Black unemployment peaked at 16.6 percent in April 2010 , when Obama was president .It then fell by more than half to 7.8 percent by the time Obama left office in January 2017 .support refute[5] Hispanic unemployment , meanwhile , peaked at 13 percent in August 2009 , then fell to 5.9 percent at the end of Obama 's term in January 2017 --also a drop of more than half .We should note that presidents do n't deserve either full credit or full blame for the unemployment rate on their watch .The president is not all -powerful on economic matters ; broader factors , from the business cycle to changes in technology to demographic shifts , play major roles .Instruction:In this task, you will be given a political claim which may contain true facts and misinformation.We also present two sets of questions related to the claim.Your task is to determine how helpful each question set is in terms of judging the veracity of the claim.For example, whether knowing the answer to each question could help you draw a conclusion that the claim is true, false, half-true, etc. (1 = knowing the answers of the questions, you have no idea whether the claim is true or false, 5 = knowing the answers of the questions, you can make an accurate judgement) Claim:\nExplainable fact checking with probabilistic answer set programming. Naser Ahmadi, Joohyung Lee, Paolo Papotti, Mohammed Saeed, Conference on Truth and Trust Online. 2019\n\nSynthetic QA corpora generation with roundtrip consistency. Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, Michael Collins, 10.18653/v1/P19-1620Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational Linguistics2019\n\nWhere is your evidence: Improving factchecking by justification modeling. Tariq Alhindi, Savvas Petridis, Smaranda Muresan, 10.18653/v1/W18-5513Proceedings of the First Workshop on Fact Extraction and VERification (FEVER). the First Workshop on Fact Extraction and VERification (FEVER)Brussels, BelgiumAssociation for Computational Linguistics2018\n\nFEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information. Rami Aly, Zhijiang Guo, Sejr Michael, James Schlichtkrull, Thorne, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2021Andreas Vlachos, Christos Christodoulopoulos, Oana Cocarascu, and Arpit Mittal\n\nGenerating fact checking explanations. Pepa Atanasova, Jakob Grue Simonsen, Christina Lioma, Isabelle Augenstein, 10.18653/v1/2020.acl-main.656Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020\n\nMultiFC: A real-world multi-domain dataset for evidence-based fact checking of claims. Isabelle Augenstein, Christina Lioma, Dongsheng Wang, Lucas Chaves Lima, Casper Hansen, Christian Hansen, Jakob Grue Simonsen, 10.18653/v1/D19-1475Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, China2019Association for Computational Linguistics\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033\n\nCan NLI models verify QA systems' predictions?. Jifan Chen, Eunsol Choi, Greg Durrett, 10.18653/v1/2021.findings-emnlp.324Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican RepublicAssociation for Computational Linguistics2021\n\nTabFact: A Large-scale Dataset for Table-based Fact Verification. Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou, William Yang, Wang , International Conference on Learning Representations. 2019\n\nDecontextualization: Making sentences stand-alone. Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski, Dipanjan Das, Michael Collins, Transactions of the Association for Computational Linguistics. 92021\n\nA coefficient of agreement for nominal scales. Educational and psychological measurement. Jacob Cohen, 196020\n\nLearning to ask: Neural question generation for reading comprehension. Xinya Du, Junru Shao, Claire Cardie, 10.18653/v1/P17-1123Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics20171\n\nQuestion generation for question answering. Nan Duan, Duyu Tang, Peng Chen, Ming Zhou, 10.18653/v1/D17-1090Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational Linguistics2017\n\nFEQA: A question answering evaluation framework for faithfulness assessment in abstractive summarization. Esin Durmus, He He, Mona Diab, 10.18653/v1/2020.acl-main.454Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020\n\nHierarchical neural story generation. Angela Fan, Mike Lewis, Yann Dauphin, 10.18653/v1/P18-1082Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics20181\n\nGenerating fact checking briefs. Angela Fan, Aleksandra Piktus, Fabio Petroni, Guillaume Wenzek, Marzieh Saeidi, Andreas Vlachos, Antoine Bordes, Sebastian Riedel, 10.18653/v1/2020.emnlp-main.580Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nEmergent: a novel data-set for stance classification. William Ferreira, Andreas Vlachos, 10.18653/v1/N16-1138Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSan Diego, CaliforniaAssociation for Computational Linguistics2016\n\nMeasuring nominal scale agreement among many raters. Joseph L Fleiss, Psychological bulletin. 7653781971\n\nMisinfo reaction frames: Reasoning about readers' reactions to news headlines. Saadia Gabriel, Skyler Hallinan, Maarten Sap, Pemi Nguyen, Franziska Roesner, Eunsol Choi, Yejin Choi, ACL. 2022\n\nExfakt: A framework for explaining facts over knowledge graphs and text. Mohamed H Gad-Elrab, Daria Stepanova, Jacopo Urbani, Gerhard Weikum, Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining. the Twelfth ACM International Conference on Web Search and Data Mining2019\n\nand Andreas Vlachos. 2022. A survey on automated fact-checking. Zhijiang Guo, Michael Schlichtkrull, Transactions of the Association for Computational Linguistics. 10\n\nX-fact: A new benchmark dataset for multilingual fact checking. Ashim Gupta, Vivek Srikumar, 10.18653/v1/2021.acl-short.86Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingOnline. Association for Computational Linguistics20212Short Papers)\n\nQuestion-answer driven semantic role labeling: Using natural language to annotate natural language. Luheng He, Mike Lewis, Luke Zettlemoyer, 10.18653/v1/D15-1076Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational Linguistics2015\n\nThe curious case of neural text degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, International Conference on Learning Representations. 2019\n\nThe Curious Case of Neural Text Degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, Proceedings of the International Conference on Learning Representations (ICLR). the International Conference on Learning Representations (ICLR)2020\n\nHoVer: A dataset for many-hop fact extraction and claim verification. Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles Dognin, Maneesh Singh, Mohit Bansal, 10.18653/v1/2020.findings-emnlp.309Findings of the Association for Computational Linguistics: EMNLP 2020. Online. Association for Computational Linguistics2020\n\nShortcomings of Question Answering Based Factuality Frameworks for Error Localization. Ryo Kamoi, Tanya Goyal, Greg Durrett, arXiv2022\n\nQANom: Question-answer driven SRL for nominalizations. Ayal Klein, Jonathan Mamou, Valentina Pyatkin, Daniela Stepanov, Hangfeng He, Dan Roth, Luke Zettlemoyer, Ido Dagan, 10.18653/v1/2020.coling-main.274Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational LinguisticsBarcelona, Spain2020International Committee on Computational Linguistics\n\nExplainable automated fact-checking for public health claims. Neema Kotonya, Francesca Toni, 10.18653/v1/2020.emnlp-main.623Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nThe Hungarian method for the assignment problem. Harold W Kuhn, Naval research logistics quarterly. 19552\n\nSummaC: Re-visiting NLIbased models for inconsistency detection in summarization. Philippe Laban, Tobias Schnabel, Paul N Bennett, Marti A Hearst, 10.1162/tacl_a_00453Transactions of the Association for Computational Linguistics. 102022\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXivRoBERTa: A Robustly Optimized BERT Pretraining Approach. 2019\n\nDecoupled weight decay regularization. Ilya Loshchilov, Frank Hutter, International Conference on Learning Representations. 2018\n\nGCAN: Graph-aware co-attention networks for explainable fake news detection on social media. Yi-Ju Lu, Cheng-Te Li, 10.18653/v1/2020.acl-main.48Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020\n\nAsk what's missing and what's useful: Improving clarification question generation using global knowledge. Prasad Bodhisattwa, Sudha Majumder, Michel Rao, Julian Galley, Mcauley, 10.18653/v1/2021.naacl-main.340Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterOnline. Association for Computational Linguistics2021\n\nAutomated fact-checking for assisting human fact-checkers. Preslav Nakov, David Corney, Maram Hasanain, Firoj Alam, Tamer Elsayed, Alberto Barr'on-Cedeno, Paolo Papotti, Shaden Shaar, Giovanni Da, San Martino, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI). the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI)2021\n\nMulti-hop fact checking of political claims. Wojciech Ostrowski, Arnav Arora, Pepa Atanasova, Isabelle Augenstein, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI). the Thirtieth International Joint Conference on Artificial Intelligence (IJCAI)2021\n\nWhere the truth lies: Explaining the credibility of emerging claims on the web and social media. Kashyap Popat, Subhabrata Mukherjee, Jannik Str\u00f6tgen, Gerhard Weikum, Proceedings of the 26th International Conference on World Wide Web Companion. the 26th International Conference on World Wide Web Companion2017International World Wide Web Conferences Steering Committee\n\nDeClarE: Debunking fake news and false claims using evidence-aware deep learning. Kashyap Popat, Subhabrata Mukherjee, Andrew Yates, Gerhard Weikum, 10.18653/v1/D18-1003Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational Linguistics2018\n\nQADiscourse -Discourse Relations as QA Pairs: Representation, Crowdsourcing and Baselines. Valentina Pyatkin, Ayal Klein, Reut Tsarfaty, Ido Dagan, 10.18653/v1/2020.emnlp-main.224Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 212020\n\nLearning to ask good questions: Ranking clarification questions using neural expected value of perfect information. Sudha Rao, Hal Daum\u00e9, Iii , 10.18653/v1/P18-1255Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourneAustralia. Association for Computational Linguistics20181\n\nTruth of varying shades: Analyzing language in fake news and political fact-checking. Eunsol Hannah Rashkin, Jin Yea Choi, Svitlana Jang, Yejin Volkova, Choi, 10.18653/v1/D17-1317Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, Denmark2017Association for Computational Linguistics\n\nDeepspeed: System optimizations enable training deep learning models with over 100 billion parameters. Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, Yuxiong He, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining2020\n\nCOVID-fact: Fact extraction and verification of real-world claims on COVID-19 pandemic. Arkadiy Saakyan, Tuhin Chakrabarty, Smaranda Muresan, 10.18653/v1/2021.acl-long.165Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingOnline. Association for Computational Linguistics20211\n\nSelf-training for jointly learning to ask and answer questions. Mrinmaya Sachan, Eric Xing, 10.18653/v1/N18-1058Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, LouisianaAssociation for Computational Linguistics20181\n\nGet Your Vitamin C! Robust Fact Verification with Contrastive Evidence. Tal Schuster, Adam Fisch, Regina Barzilay, 10.18653/v1/2021.naacl-main.52Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterOnline. Association for Computational Linguistics2021\n\ndefend: Explainable fake news detection. Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee, Huan Liu, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. the 25th ACM SIGKDD international conference on knowledge discovery & data mining2019\n\nUnsupervised commonsense question answering with self-talk. Vered Shwartz, Peter West, Le Ronan, Chandra Bras, Yejin Bhagavatula, Choi, 10.18653/v1/2020.emnlp-main.373Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nPrakhar Singh, Anubrata Das, Junyi , Jessy Li, Matthew Lease, arXiv ePrint 2109.09689The Case for Claim Difficulty Assessment in Automatic Fact Checking. 2021\n\nFEVER: a large-scale dataset for fact extraction and VERification. James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, 10.18653/v1/N18-1074Proceedings of the 2018 Conference of the North American Chapter. Long Papers. the 2018 Conference of the North American ChapterNew Orleans, LouisianaAssociation for Computational Linguistics20181\n\nFake news detection in social networks via crowd signals. Sebastian Tschiatschek, Adish Singla, Manuel Gomez-Rodriguez, Arpit Merchant, Andreas Krause, The Web Conference, Alternate Track on Journalism, Misinformation, and Factchecking. 2018\n\nFact checking: Task definition and dataset construction. Andreas Vlachos, Sebastian Riedel, 10.3115/v1/W14-2508Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science. the ACL 2014 Workshop on Language Technologies and Computational Social ScienceBaltimore, MD, USAAssociation for Computational Linguistics2014\n\nSeparating facts from fiction: Linguistic models to classify suspicious and trusted news posts on Twitter. Svitlana Volkova, Kyle Shaffer, Jin Yea Jang, Nathan Hodas, 10.18653/v1/P17-2102Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics20172Short Papers)\n\nFact or fiction: Verifying scientific claims. David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu Wang, Madeleine Van Zuylen, Arman Cohan, Hannaneh Hajishirzi, 10.18653/v1/2020.emnlp-main.609Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational Linguistics2020\n\nAsking and answering questions to evaluate the factual consistency of summaries. Alex Wang, Kyunghyun Cho, Mike Lewis, 10.18653/v1/2020.acl-main.450Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020\n\nLiar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News Detection. William Yang, Wang , 10.18653/v1/P17-2067Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics20172Short Papers)\n\nA broad-coverage challenge corpus for sentence understanding through inference. Adina Williams, Nikita Nangia, Samuel Bowman, 10.18653/v1/N18-1101Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, Louisiana20181Association for Computational Linguistics\n\nTransformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Le Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest, Rush, 10.18653/v1/2020.emnlp-demos.6Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2020 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsOnline. Association for Computational Linguistics2020\n\nXfake: Explainable fake news detector with visualizations. Fan Yang, Sina Shiva K Pentyala, Mengnan Mohseni, Hao Du, Rhema Yuan, Eric D Linder, Shuiwang Ragan, Xia Ji, Hu, The World Wide Web Conference. 2019\n\nDocNLI: A large-scale dataset for documentlevel natural language inference. Wenpeng Yin, Dragomir Radev, Caiming Xiong, 10.18653/v1/2021.findings-acl.435Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Online. Association for Computational Linguistics2021\n\nBERTScore: Evaluating Text Generation with BERT. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, Yoav Artzi, International Conference on Learning Representations (ICLR). 2019\n", "annotations": {"author": "[{\"end\":185,\"start\":86},{\"end\":269,\"start\":186},{\"end\":349,\"start\":270},{\"end\":430,\"start\":350}]", "publisher": null, "author_last_name": "[{\"end\":96,\"start\":92},{\"end\":201,\"start\":195},{\"end\":281,\"start\":277},{\"end\":362,\"start\":355}]", "author_first_name": "[{\"end\":91,\"start\":86},{\"end\":194,\"start\":186},{\"end\":276,\"start\":270},{\"end\":354,\"start\":350}]", "author_affiliation": "[{\"end\":184,\"start\":119},{\"end\":268,\"start\":203},{\"end\":348,\"start\":283},{\"end\":429,\"start\":364}]", "title": "[{\"end\":73,\"start\":1},{\"end\":503,\"start\":431}]", "venue": null, "abstract": "[{\"end\":2459,\"start\":572}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b56\"},\"end\":2550,\"start\":2538},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2571,\"start\":2550},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2592,\"start\":2571},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2619,\"start\":2592},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2638,\"start\":2619},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":2664,\"start\":2638},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2745,\"start\":2725},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3257,\"start\":3233},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5352,\"start\":5332},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5689,\"start\":5668},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5800,\"start\":5777},{\"end\":6298,\"start\":6280},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6474,\"start\":6455},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":6493,\"start\":6476},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6511,\"start\":6495},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6681,\"start\":6661},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6706,\"start\":6683},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6895,\"start\":6872},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9410,\"start\":9391},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":14105,\"start\":14092},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":15089,\"start\":15068},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26209,\"start\":26191},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27360,\"start\":27348},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28480,\"start\":28462},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":29280,\"start\":29263},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":30021,\"start\":30003},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":33072,\"start\":33052},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33708,\"start\":33689},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":34695,\"start\":34677},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":34772,\"start\":34749},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":34800,\"start\":34781},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":34831,\"start\":34813},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":50656,\"start\":50636},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":53584,\"start\":53559},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":53843,\"start\":53822},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":53861,\"start\":53843},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":53880,\"start\":53861},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":53902,\"start\":53880},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":53919,\"start\":53902},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":53961,\"start\":53949},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":53982,\"start\":53961},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":54006,\"start\":53982},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":54029,\"start\":54006},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":54054,\"start\":54029},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":54096,\"start\":54075},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":54117,\"start\":54096},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":54409,\"start\":54388},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":54666,\"start\":54648},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":54689,\"start\":54666},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":54949,\"start\":54932},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":55023,\"start\":55004},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":55045,\"start\":55023},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":55066,\"start\":55045},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":55129,\"start\":55110},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":55149,\"start\":55129},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":55168,\"start\":55149},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":55215,\"start\":55198},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":55234,\"start\":55215},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":55255,\"start\":55234},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":55357,\"start\":55332},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":55378,\"start\":55357},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":55400,\"start\":55378},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":55456,\"start\":55438},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":58701,\"start\":58681},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":63253,\"start\":63233},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":63326,\"start\":63306},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":63581,\"start\":63569},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":64842,\"start\":64823},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":65016,\"start\":64995},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":65110,\"start\":65081},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":65968,\"start\":65945},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":66042,\"start\":66024}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":70035,\"start\":69664},{\"attributes\":{\"id\":\"fig_1\"},\"end\":70258,\"start\":70036},{\"attributes\":{\"id\":\"fig_2\"},\"end\":70479,\"start\":70259},{\"attributes\":{\"id\":\"fig_3\"},\"end\":71331,\"start\":70480},{\"end\":71336,\"start\":71332},{\"end\":71341,\"start\":71337},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":71950,\"start\":71342},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":72238,\"start\":71951},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":72583,\"start\":72239},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":72877,\"start\":72584},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":73447,\"start\":72878},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":73755,\"start\":73448},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":74052,\"start\":73756},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":74347,\"start\":74053},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":74509,\"start\":74348},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":74741,\"start\":74510},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":74913,\"start\":74742},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":75199,\"start\":74914}]", "paragraph": "[{\"end\":3519,\"start\":2475},{\"end\":4638,\"start\":3521},{\"end\":5500,\"start\":4640},{\"end\":6129,\"start\":5502},{\"end\":7182,\"start\":6153},{\"end\":7700,\"start\":7184},{\"end\":8319,\"start\":7702},{\"end\":8621,\"start\":8321},{\"end\":8795,\"start\":8623},{\"end\":8970,\"start\":8797},{\"end\":9018,\"start\":8972},{\"end\":9240,\"start\":9020},{\"end\":9343,\"start\":9242},{\"end\":9483,\"start\":9345},{\"end\":10515,\"start\":9505},{\"end\":11627,\"start\":10538},{\"end\":11978,\"start\":11629},{\"end\":12080,\"start\":11980},{\"end\":12529,\"start\":12082},{\"end\":12756,\"start\":12531},{\"end\":13248,\"start\":12758},{\"end\":13921,\"start\":13250},{\"end\":14879,\"start\":13923},{\"end\":15036,\"start\":14913},{\"end\":15336,\"start\":15047},{\"end\":17693,\"start\":17492},{\"end\":20099,\"start\":19716},{\"end\":23419,\"start\":23356},{\"end\":24010,\"start\":23421},{\"end\":25310,\"start\":24012},{\"end\":25858,\"start\":25312},{\"end\":26282,\"start\":25898},{\"end\":27080,\"start\":26312},{\"end\":28051,\"start\":27082},{\"end\":28383,\"start\":28053},{\"end\":29561,\"start\":28410},{\"end\":29933,\"start\":29572},{\"end\":31041,\"start\":29935},{\"end\":31102,\"start\":31082},{\"end\":31243,\"start\":31104},{\"end\":31278,\"start\":31245},{\"end\":31505,\"start\":31295},{\"end\":31979,\"start\":31589},{\"end\":32845,\"start\":31981},{\"end\":33709,\"start\":32887},{\"end\":34603,\"start\":33743},{\"end\":34942,\"start\":34605},{\"end\":36050,\"start\":35863},{\"end\":38956,\"start\":38125},{\"end\":42908,\"start\":42753},{\"end\":45984,\"start\":45823},{\"end\":50428,\"start\":50038},{\"end\":50843,\"start\":50430},{\"end\":51669,\"start\":50845},{\"end\":52156,\"start\":51671},{\"end\":52696,\"start\":52158},{\"end\":53263,\"start\":52708},{\"end\":53528,\"start\":53265},{\"end\":54262,\"start\":53545},{\"end\":54553,\"start\":54264},{\"end\":54860,\"start\":54555},{\"end\":55636,\"start\":54862},{\"end\":56029,\"start\":55651},{\"end\":57087,\"start\":56076},{\"end\":58005,\"start\":57135},{\"end\":58988,\"start\":58007},{\"end\":59276,\"start\":59038},{\"end\":60571,\"start\":59278},{\"end\":61106,\"start\":60621},{\"end\":61811,\"start\":61108},{\"end\":62082,\"start\":61813},{\"end\":62186,\"start\":62111},{\"end\":62325,\"start\":62222},{\"end\":62441,\"start\":62352},{\"end\":62778,\"start\":62473},{\"end\":63692,\"start\":62825},{\"end\":64214,\"start\":63694},{\"end\":64363,\"start\":64261},{\"end\":64756,\"start\":64402},{\"end\":65162,\"start\":64758},{\"end\":65313,\"start\":65164},{\"end\":65712,\"start\":65315},{\"end\":66168,\"start\":65714},{\"end\":66739,\"start\":66204},{\"end\":66827,\"start\":66741},{\"end\":67063,\"start\":66829},{\"end\":67628,\"start\":67113},{\"end\":67767,\"start\":67660},{\"end\":68418,\"start\":67769},{\"end\":68602,\"start\":68420},{\"end\":68738,\"start\":68604},{\"end\":68900,\"start\":68766},{\"end\":69228,\"start\":68902},{\"end\":69324,\"start\":69230},{\"end\":69663,\"start\":69326},{\"end\":70034,\"start\":69668},{\"end\":70257,\"start\":70039},{\"end\":70478,\"start\":70262},{\"end\":71330,\"start\":70483},{\"end\":71674,\"start\":71355},{\"end\":72237,\"start\":71964},{\"end\":72251,\"start\":72242},{\"end\":72790,\"start\":72597},{\"end\":73404,\"start\":72942},{\"end\":74029,\"start\":73811},{\"end\":74346,\"start\":74120},{\"end\":74508,\"start\":74361},{\"end\":74606,\"start\":74523},{\"end\":74796,\"start\":74755},{\"end\":75198,\"start\":74927}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17491,\"start\":15364},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19715,\"start\":17694},{\"attributes\":{\"id\":\"formula_2\"},\"end\":23355,\"start\":20100},{\"attributes\":{\"id\":\"formula_3\"},\"end\":31294,\"start\":31279},{\"attributes\":{\"id\":\"formula_4\"},\"end\":31588,\"start\":31506},{\"attributes\":{\"id\":\"formula_5\"},\"end\":35862,\"start\":34943},{\"attributes\":{\"id\":\"formula_6\"},\"end\":38124,\"start\":36051},{\"attributes\":{\"id\":\"formula_7\"},\"end\":40808,\"start\":38957},{\"attributes\":{\"id\":\"formula_8\"},\"end\":42752,\"start\":40808},{\"attributes\":{\"id\":\"formula_9\"},\"end\":45822,\"start\":42909},{\"attributes\":{\"id\":\"formula_10\"},\"end\":50037,\"start\":45985},{\"attributes\":{\"id\":\"formula_11\"},\"end\":64401,\"start\":64364}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12814,\"start\":12813},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":14164,\"start\":14163},{\"end\":19887,\"start\":19886},{\"end\":24257,\"start\":24256},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26668,\"start\":26667},{\"end\":28226,\"start\":28225},{\"end\":30755,\"start\":30754},{\"attributes\":{\"ref_id\":\"tab_12\"},\"end\":34465,\"start\":34464},{\"attributes\":{\"ref_id\":\"tab_12\"},\"end\":52354,\"start\":52353},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":52740,\"start\":52739},{\"attributes\":{\"ref_id\":\"tab_15\"},\"end\":63691,\"start\":63690},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":67121,\"start\":67119}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2473,\"start\":2461},{\"attributes\":{\"n\":\"2\"},\"end\":6151,\"start\":6132},{\"end\":9503,\"start\":9486},{\"attributes\":{\"n\":\"3\"},\"end\":10536,\"start\":10518},{\"attributes\":{\"n\":\"4\"},\"end\":14911,\"start\":14882},{\"end\":15045,\"start\":15039},{\"end\":15349,\"start\":15339},{\"end\":15363,\"start\":15352},{\"attributes\":{\"n\":\"5\"},\"end\":25896,\"start\":25861},{\"attributes\":{\"n\":\"5.1\"},\"end\":26310,\"start\":26285},{\"attributes\":{\"n\":\"5.2\"},\"end\":28408,\"start\":28386},{\"end\":29570,\"start\":29564},{\"attributes\":{\"n\":\"5.3\"},\"end\":31080,\"start\":31044},{\"attributes\":{\"n\":\"6\"},\"end\":32885,\"start\":32848},{\"end\":33741,\"start\":33712},{\"end\":52706,\"start\":52699},{\"attributes\":{\"n\":\"7\"},\"end\":53543,\"start\":53531},{\"attributes\":{\"n\":\"8\"},\"end\":55649,\"start\":55639},{\"end\":56074,\"start\":56032},{\"end\":57133,\"start\":57090},{\"end\":59036,\"start\":58991},{\"end\":60604,\"start\":60574},{\"end\":60619,\"start\":60607},{\"end\":62109,\"start\":62085},{\"end\":62220,\"start\":62189},{\"end\":62350,\"start\":62328},{\"end\":62471,\"start\":62444},{\"end\":62823,\"start\":62781},{\"end\":64259,\"start\":64217},{\"end\":66202,\"start\":66171},{\"end\":67111,\"start\":67066},{\"end\":67658,\"start\":67631},{\"end\":68764,\"start\":68741},{\"end\":69666,\"start\":69665},{\"end\":71352,\"start\":71343},{\"end\":71961,\"start\":71952},{\"end\":72594,\"start\":72585},{\"end\":72940,\"start\":72879},{\"end\":73532,\"start\":73449},{\"end\":73809,\"start\":73757},{\"end\":74118,\"start\":74054},{\"end\":74358,\"start\":74349},{\"end\":74520,\"start\":74511},{\"end\":74752,\"start\":74743},{\"end\":74924,\"start\":74915}]", "table": "[{\"end\":71950,\"start\":71675},{\"end\":72583,\"start\":72252},{\"end\":72877,\"start\":72791},{\"end\":73447,\"start\":73405},{\"end\":73755,\"start\":73533},{\"end\":74052,\"start\":74030},{\"end\":74741,\"start\":74607},{\"end\":74913,\"start\":74797}]", "figure_caption": "[{\"end\":70035,\"start\":69667},{\"end\":70258,\"start\":70038},{\"end\":70479,\"start\":70261},{\"end\":71331,\"start\":70482},{\"end\":71336,\"start\":71334},{\"end\":71341,\"start\":71339},{\"end\":71675,\"start\":71354},{\"end\":72238,\"start\":71963},{\"end\":72252,\"start\":72241},{\"end\":72791,\"start\":72596},{\"end\":73405,\"start\":72941},{\"end\":74030,\"start\":73810},{\"end\":74347,\"start\":74119},{\"end\":74509,\"start\":74360},{\"end\":74607,\"start\":74522},{\"end\":74797,\"start\":74754},{\"end\":75199,\"start\":74926}]", "figure_ref": "[{\"end\":2882,\"start\":2881},{\"end\":3955,\"start\":3954},{\"end\":4150,\"start\":4149},{\"end\":4214,\"start\":4213},{\"end\":7932,\"start\":7931},{\"end\":10727,\"start\":10726},{\"end\":11917,\"start\":11916},{\"end\":15207,\"start\":15206},{\"end\":25587,\"start\":25586},{\"end\":27249,\"start\":27248},{\"end\":28818,\"start\":28817},{\"end\":29943,\"start\":29942},{\"end\":32114,\"start\":32113},{\"end\":50046,\"start\":50045},{\"end\":51644,\"start\":51643},{\"end\":62185,\"start\":62184},{\"end\":62324,\"start\":62323},{\"end\":62440,\"start\":62439},{\"end\":62552,\"start\":62550},{\"end\":67766,\"start\":67764}]", "bib_author_first_name": "[{\"end\":96105,\"start\":96100},{\"end\":96122,\"start\":96114},{\"end\":96133,\"start\":96128},{\"end\":96151,\"start\":96143},{\"end\":96268,\"start\":96263},{\"end\":96284,\"start\":96278},{\"end\":96297,\"start\":96292},{\"end\":96311,\"start\":96306},{\"end\":96327,\"start\":96320},{\"end\":96659,\"start\":96654},{\"end\":96675,\"start\":96669},{\"end\":96694,\"start\":96686},{\"end\":97022,\"start\":97018},{\"end\":97036,\"start\":97028},{\"end\":97046,\"start\":97042},{\"end\":97061,\"start\":97056},{\"end\":97308,\"start\":97304},{\"end\":97325,\"start\":97320},{\"end\":97330,\"start\":97326},{\"end\":97350,\"start\":97341},{\"end\":97366,\"start\":97358},{\"end\":97719,\"start\":97711},{\"end\":97741,\"start\":97732},{\"end\":97758,\"start\":97749},{\"end\":97770,\"start\":97765},{\"end\":97777,\"start\":97771},{\"end\":97790,\"start\":97784},{\"end\":97808,\"start\":97799},{\"end\":97822,\"start\":97817},{\"end\":97827,\"start\":97823},{\"end\":98300,\"start\":98297},{\"end\":98316,\"start\":98308},{\"end\":98327,\"start\":98323},{\"end\":98342,\"start\":98335},{\"end\":98357,\"start\":98352},{\"end\":98359,\"start\":98358},{\"end\":98376,\"start\":98368},{\"end\":98393,\"start\":98387},{\"end\":98413,\"start\":98407},{\"end\":98427,\"start\":98421},{\"end\":98442,\"start\":98436},{\"end\":98563,\"start\":98558},{\"end\":98576,\"start\":98570},{\"end\":98587,\"start\":98583},{\"end\":98851,\"start\":98846},{\"end\":98865,\"start\":98858},{\"end\":98879,\"start\":98872},{\"end\":98892,\"start\":98886},{\"end\":98904,\"start\":98900},{\"end\":98918,\"start\":98911},{\"end\":98928,\"start\":98923},{\"end\":98942,\"start\":98935},{\"end\":98953,\"start\":98949},{\"end\":99073,\"start\":99067},{\"end\":99090,\"start\":99080},{\"end\":99108,\"start\":99101},{\"end\":99118,\"start\":99115},{\"end\":99140,\"start\":99132},{\"end\":99153,\"start\":99146},{\"end\":99328,\"start\":99323},{\"end\":99420,\"start\":99415},{\"end\":99430,\"start\":99425},{\"end\":99443,\"start\":99437},{\"end\":99758,\"start\":99755},{\"end\":99769,\"start\":99765},{\"end\":99780,\"start\":99776},{\"end\":99791,\"start\":99787},{\"end\":100153,\"start\":100149},{\"end\":100164,\"start\":100162},{\"end\":100173,\"start\":100169},{\"end\":100469,\"start\":100463},{\"end\":100479,\"start\":100475},{\"end\":100491,\"start\":100487},{\"end\":100802,\"start\":100796},{\"end\":100818,\"start\":100808},{\"end\":100832,\"start\":100827},{\"end\":100851,\"start\":100842},{\"end\":100867,\"start\":100860},{\"end\":100883,\"start\":100876},{\"end\":100900,\"start\":100893},{\"end\":100918,\"start\":100909},{\"end\":101249,\"start\":101242},{\"end\":101267,\"start\":101260},{\"end\":101827,\"start\":101821},{\"end\":101843,\"start\":101837},{\"end\":101861,\"start\":101854},{\"end\":101871,\"start\":101867},{\"end\":101889,\"start\":101880},{\"end\":101905,\"start\":101899},{\"end\":101917,\"start\":101912},{\"end\":102015,\"start\":102008},{\"end\":102017,\"start\":102016},{\"end\":102034,\"start\":102029},{\"end\":102052,\"start\":102046},{\"end\":102068,\"start\":102061},{\"end\":102312,\"start\":102304},{\"end\":102325,\"start\":102318},{\"end\":102477,\"start\":102472},{\"end\":102490,\"start\":102485},{\"end\":103016,\"start\":103010},{\"end\":103025,\"start\":103021},{\"end\":103037,\"start\":103033},{\"end\":103342,\"start\":103339},{\"end\":103356,\"start\":103353},{\"end\":103365,\"start\":103363},{\"end\":103377,\"start\":103370},{\"end\":103391,\"start\":103386},{\"end\":103507,\"start\":103504},{\"end\":103521,\"start\":103518},{\"end\":103530,\"start\":103528},{\"end\":103542,\"start\":103535},{\"end\":103556,\"start\":103551},{\"end\":103788,\"start\":103782},{\"end\":103802,\"start\":103796},{\"end\":103816,\"start\":103811},{\"end\":103831,\"start\":103824},{\"end\":103847,\"start\":103840},{\"end\":103860,\"start\":103855},{\"end\":104120,\"start\":104117},{\"end\":104133,\"start\":104128},{\"end\":104145,\"start\":104141},{\"end\":104225,\"start\":104221},{\"end\":104241,\"start\":104233},{\"end\":104258,\"start\":104249},{\"end\":104275,\"start\":104268},{\"end\":104294,\"start\":104286},{\"end\":104302,\"start\":104299},{\"end\":104313,\"start\":104309},{\"end\":104330,\"start\":104327},{\"end\":104652,\"start\":104647},{\"end\":104671,\"start\":104662},{\"end\":105136,\"start\":105128},{\"end\":105150,\"start\":105144},{\"end\":105165,\"start\":105161},{\"end\":105167,\"start\":105166},{\"end\":105182,\"start\":105177},{\"end\":105184,\"start\":105183},{\"end\":105290,\"start\":105284},{\"end\":105300,\"start\":105296},{\"end\":105311,\"start\":105306},{\"end\":105326,\"start\":105319},{\"end\":105337,\"start\":105331},{\"end\":105350,\"start\":105345},{\"end\":105361,\"start\":105357},{\"end\":105372,\"start\":105368},{\"end\":105384,\"start\":105380},{\"end\":105405,\"start\":105398},{\"end\":105527,\"start\":105523},{\"end\":105545,\"start\":105540},{\"end\":105712,\"start\":105707},{\"end\":105725,\"start\":105717},{\"end\":106086,\"start\":106080},{\"end\":106105,\"start\":106100},{\"end\":106122,\"start\":106116},{\"end\":106134,\"start\":106128},{\"end\":106419,\"start\":106412},{\"end\":106432,\"start\":106427},{\"end\":106446,\"start\":106441},{\"end\":106462,\"start\":106457},{\"end\":106474,\"start\":106469},{\"end\":106491,\"start\":106484},{\"end\":106513,\"start\":106508},{\"end\":106529,\"start\":106523},{\"end\":106545,\"start\":106537},{\"end\":106553,\"start\":106550},{\"end\":106797,\"start\":106789},{\"end\":106814,\"start\":106809},{\"end\":106826,\"start\":106822},{\"end\":106846,\"start\":106838},{\"end\":107144,\"start\":107137},{\"end\":107162,\"start\":107152},{\"end\":107180,\"start\":107174},{\"end\":107198,\"start\":107191},{\"end\":107500,\"start\":107493},{\"end\":107518,\"start\":107508},{\"end\":107536,\"start\":107530},{\"end\":107551,\"start\":107544},{\"end\":107903,\"start\":107894},{\"end\":107917,\"start\":107913},{\"end\":107929,\"start\":107925},{\"end\":107943,\"start\":107940},{\"end\":108300,\"start\":108295},{\"end\":108313,\"start\":108309},{\"end\":108327,\"start\":108323},{\"end\":108346,\"start\":108337},{\"end\":108358,\"start\":108352},{\"end\":108374,\"start\":108367},{\"end\":108388,\"start\":108383},{\"end\":108398,\"start\":108395},{\"end\":108408,\"start\":108403},{\"end\":108410,\"start\":108409},{\"end\":108583,\"start\":108578},{\"end\":108592,\"start\":108589},{\"end\":108603,\"start\":108600},{\"end\":108960,\"start\":108954},{\"end\":108980,\"start\":108977},{\"end\":108984,\"start\":108981},{\"end\":108999,\"start\":108991},{\"end\":109011,\"start\":109006},{\"end\":109379,\"start\":109375},{\"end\":109394,\"start\":109388},{\"end\":109416,\"start\":109408},{\"end\":109432,\"start\":109425},{\"end\":109717,\"start\":109710},{\"end\":109732,\"start\":109727},{\"end\":109754,\"start\":109746},{\"end\":110245,\"start\":110237},{\"end\":110258,\"start\":110254},{\"end\":110714,\"start\":110711},{\"end\":110729,\"start\":110725},{\"end\":110743,\"start\":110737},{\"end\":110998,\"start\":110995},{\"end\":111010,\"start\":111004},{\"end\":111022,\"start\":111016},{\"end\":111036,\"start\":111029},{\"end\":111046,\"start\":111042},{\"end\":111302,\"start\":111297},{\"end\":111317,\"start\":111312},{\"end\":111326,\"start\":111324},{\"end\":111341,\"start\":111334},{\"end\":111353,\"start\":111348},{\"end\":111641,\"start\":111634},{\"end\":111657,\"start\":111649},{\"end\":111668,\"start\":111663},{\"end\":111676,\"start\":111671},{\"end\":111688,\"start\":111681},{\"end\":111866,\"start\":111861},{\"end\":111882,\"start\":111875},{\"end\":111900,\"start\":111892},{\"end\":111926,\"start\":111921},{\"end\":112220,\"start\":112211},{\"end\":112240,\"start\":112235},{\"end\":112255,\"start\":112249},{\"end\":112278,\"start\":112273},{\"end\":112296,\"start\":112289},{\"end\":112460,\"start\":112453},{\"end\":112479,\"start\":112470},{\"end\":112862,\"start\":112854},{\"end\":112876,\"start\":112872},{\"end\":112889,\"start\":112886},{\"end\":112893,\"start\":112890},{\"end\":112906,\"start\":112900},{\"end\":113224,\"start\":113219},{\"end\":113242,\"start\":113233},{\"end\":113252,\"start\":113248},{\"end\":113261,\"start\":113257},{\"end\":113264,\"start\":113262},{\"end\":113280,\"start\":113271},{\"end\":113298,\"start\":113293},{\"end\":113314,\"start\":113306},{\"end\":113665,\"start\":113661},{\"end\":113681,\"start\":113672},{\"end\":113691,\"start\":113687},{\"end\":114027,\"start\":114020},{\"end\":114038,\"start\":114034},{\"end\":114385,\"start\":114380},{\"end\":114402,\"start\":114396},{\"end\":114417,\"start\":114411},{\"end\":114866,\"start\":114860},{\"end\":114881,\"start\":114873},{\"end\":114895,\"start\":114889},{\"end\":114908,\"start\":114902},{\"end\":114926,\"start\":114919},{\"end\":114944,\"start\":114937},{\"end\":114957,\"start\":114950},{\"end\":114969,\"start\":114966},{\"end\":114981,\"start\":114977},{\"end\":114994,\"start\":114988},{\"end\":115009,\"start\":115006},{\"end\":115022,\"start\":115019},{\"end\":115038,\"start\":115033},{\"end\":115065,\"start\":115059},{\"end\":115076,\"start\":115070},{\"end\":115092,\"start\":115086},{\"end\":115103,\"start\":115098},{\"end\":115115,\"start\":115108},{\"end\":115132,\"start\":115125},{\"end\":115148,\"start\":115141},{\"end\":115165,\"start\":115156},{\"end\":115532,\"start\":115529},{\"end\":115543,\"start\":115539},{\"end\":115569,\"start\":115562},{\"end\":115582,\"start\":115579},{\"end\":115592,\"start\":115587},{\"end\":115603,\"start\":115599},{\"end\":115605,\"start\":115604},{\"end\":115622,\"start\":115614},{\"end\":115633,\"start\":115630},{\"end\":115762,\"start\":115755},{\"end\":115776,\"start\":115768},{\"end\":115791,\"start\":115784},{\"end\":116018,\"start\":116012},{\"end\":116032,\"start\":116026},{\"end\":116047,\"start\":116042},{\"end\":116058,\"start\":116052},{\"end\":116060,\"start\":116059},{\"end\":116077,\"start\":116073}]", "bib_author_last_name": "[{\"end\":96112,\"start\":96106},{\"end\":96126,\"start\":96123},{\"end\":96141,\"start\":96134},{\"end\":96157,\"start\":96152},{\"end\":96276,\"start\":96269},{\"end\":96290,\"start\":96285},{\"end\":96304,\"start\":96298},{\"end\":96318,\"start\":96312},{\"end\":96335,\"start\":96328},{\"end\":96667,\"start\":96660},{\"end\":96684,\"start\":96676},{\"end\":96702,\"start\":96695},{\"end\":97026,\"start\":97023},{\"end\":97040,\"start\":97037},{\"end\":97054,\"start\":97047},{\"end\":97075,\"start\":97062},{\"end\":97083,\"start\":97077},{\"end\":97318,\"start\":97309},{\"end\":97339,\"start\":97331},{\"end\":97356,\"start\":97351},{\"end\":97377,\"start\":97367},{\"end\":97730,\"start\":97720},{\"end\":97747,\"start\":97742},{\"end\":97763,\"start\":97759},{\"end\":97782,\"start\":97778},{\"end\":97797,\"start\":97791},{\"end\":97815,\"start\":97809},{\"end\":97836,\"start\":97828},{\"end\":98306,\"start\":98301},{\"end\":98321,\"start\":98317},{\"end\":98333,\"start\":98328},{\"end\":98350,\"start\":98343},{\"end\":98366,\"start\":98360},{\"end\":98385,\"start\":98377},{\"end\":98405,\"start\":98394},{\"end\":98419,\"start\":98414},{\"end\":98434,\"start\":98428},{\"end\":98449,\"start\":98443},{\"end\":98568,\"start\":98564},{\"end\":98581,\"start\":98577},{\"end\":98595,\"start\":98588},{\"end\":98856,\"start\":98852},{\"end\":98870,\"start\":98866},{\"end\":98884,\"start\":98880},{\"end\":98898,\"start\":98893},{\"end\":98909,\"start\":98905},{\"end\":98921,\"start\":98919},{\"end\":98933,\"start\":98929},{\"end\":98947,\"start\":98943},{\"end\":99078,\"start\":99074},{\"end\":99099,\"start\":99091},{\"end\":99113,\"start\":99109},{\"end\":99130,\"start\":99119},{\"end\":99144,\"start\":99141},{\"end\":99161,\"start\":99154},{\"end\":99334,\"start\":99329},{\"end\":99423,\"start\":99421},{\"end\":99435,\"start\":99431},{\"end\":99450,\"start\":99444},{\"end\":99763,\"start\":99759},{\"end\":99774,\"start\":99770},{\"end\":99785,\"start\":99781},{\"end\":99796,\"start\":99792},{\"end\":100160,\"start\":100154},{\"end\":100167,\"start\":100165},{\"end\":100178,\"start\":100174},{\"end\":100473,\"start\":100470},{\"end\":100485,\"start\":100480},{\"end\":100499,\"start\":100492},{\"end\":100806,\"start\":100803},{\"end\":100825,\"start\":100819},{\"end\":100840,\"start\":100833},{\"end\":100858,\"start\":100852},{\"end\":100874,\"start\":100868},{\"end\":100891,\"start\":100884},{\"end\":100907,\"start\":100901},{\"end\":100925,\"start\":100919},{\"end\":101258,\"start\":101250},{\"end\":101275,\"start\":101268},{\"end\":101704,\"start\":101689},{\"end\":101835,\"start\":101828},{\"end\":101852,\"start\":101844},{\"end\":101865,\"start\":101862},{\"end\":101878,\"start\":101872},{\"end\":101897,\"start\":101890},{\"end\":101910,\"start\":101906},{\"end\":101922,\"start\":101918},{\"end\":102027,\"start\":102018},{\"end\":102044,\"start\":102035},{\"end\":102059,\"start\":102053},{\"end\":102075,\"start\":102069},{\"end\":102316,\"start\":102313},{\"end\":102339,\"start\":102326},{\"end\":102483,\"start\":102478},{\"end\":102499,\"start\":102491},{\"end\":103019,\"start\":103017},{\"end\":103031,\"start\":103026},{\"end\":103049,\"start\":103038},{\"end\":103351,\"start\":103343},{\"end\":103361,\"start\":103357},{\"end\":103368,\"start\":103366},{\"end\":103384,\"start\":103378},{\"end\":103396,\"start\":103392},{\"end\":103516,\"start\":103508},{\"end\":103526,\"start\":103522},{\"end\":103533,\"start\":103531},{\"end\":103549,\"start\":103543},{\"end\":103561,\"start\":103557},{\"end\":103794,\"start\":103789},{\"end\":103809,\"start\":103803},{\"end\":103822,\"start\":103817},{\"end\":103838,\"start\":103832},{\"end\":103853,\"start\":103848},{\"end\":103867,\"start\":103861},{\"end\":104126,\"start\":104121},{\"end\":104139,\"start\":104134},{\"end\":104153,\"start\":104146},{\"end\":104231,\"start\":104226},{\"end\":104247,\"start\":104242},{\"end\":104266,\"start\":104259},{\"end\":104284,\"start\":104276},{\"end\":104297,\"start\":104295},{\"end\":104307,\"start\":104303},{\"end\":104325,\"start\":104314},{\"end\":104336,\"start\":104331},{\"end\":104660,\"start\":104653},{\"end\":104676,\"start\":104672},{\"end\":105001,\"start\":104988},{\"end\":105142,\"start\":105137},{\"end\":105159,\"start\":105151},{\"end\":105175,\"start\":105168},{\"end\":105191,\"start\":105185},{\"end\":105294,\"start\":105291},{\"end\":105304,\"start\":105301},{\"end\":105317,\"start\":105312},{\"end\":105329,\"start\":105327},{\"end\":105343,\"start\":105338},{\"end\":105355,\"start\":105351},{\"end\":105366,\"start\":105362},{\"end\":105378,\"start\":105373},{\"end\":105396,\"start\":105385},{\"end\":105414,\"start\":105406},{\"end\":105538,\"start\":105528},{\"end\":105552,\"start\":105546},{\"end\":105715,\"start\":105713},{\"end\":105728,\"start\":105726},{\"end\":106098,\"start\":106087},{\"end\":106114,\"start\":106106},{\"end\":106126,\"start\":106123},{\"end\":106141,\"start\":106135},{\"end\":106150,\"start\":106143},{\"end\":106425,\"start\":106420},{\"end\":106439,\"start\":106433},{\"end\":106455,\"start\":106447},{\"end\":106467,\"start\":106463},{\"end\":106482,\"start\":106475},{\"end\":106506,\"start\":106492},{\"end\":106521,\"start\":106514},{\"end\":106535,\"start\":106530},{\"end\":106548,\"start\":106546},{\"end\":106561,\"start\":106554},{\"end\":106807,\"start\":106798},{\"end\":106820,\"start\":106815},{\"end\":106836,\"start\":106827},{\"end\":106857,\"start\":106847},{\"end\":107150,\"start\":107145},{\"end\":107172,\"start\":107163},{\"end\":107189,\"start\":107181},{\"end\":107205,\"start\":107199},{\"end\":107506,\"start\":107501},{\"end\":107528,\"start\":107519},{\"end\":107542,\"start\":107537},{\"end\":107558,\"start\":107552},{\"end\":107911,\"start\":107904},{\"end\":107923,\"start\":107918},{\"end\":107938,\"start\":107930},{\"end\":107949,\"start\":107944},{\"end\":108307,\"start\":108301},{\"end\":108321,\"start\":108314},{\"end\":108335,\"start\":108328},{\"end\":108350,\"start\":108347},{\"end\":108365,\"start\":108359},{\"end\":108381,\"start\":108375},{\"end\":108393,\"start\":108389},{\"end\":108401,\"start\":108399},{\"end\":108414,\"start\":108411},{\"end\":108587,\"start\":108584},{\"end\":108598,\"start\":108593},{\"end\":108975,\"start\":108961},{\"end\":108989,\"start\":108985},{\"end\":109004,\"start\":109000},{\"end\":109019,\"start\":109012},{\"end\":109025,\"start\":109021},{\"end\":109386,\"start\":109380},{\"end\":109406,\"start\":109395},{\"end\":109423,\"start\":109417},{\"end\":109435,\"start\":109433},{\"end\":109725,\"start\":109718},{\"end\":109744,\"start\":109733},{\"end\":109762,\"start\":109755},{\"end\":110252,\"start\":110246},{\"end\":110263,\"start\":110259},{\"end\":110723,\"start\":110715},{\"end\":110735,\"start\":110730},{\"end\":110752,\"start\":110744},{\"end\":111002,\"start\":110999},{\"end\":111014,\"start\":111011},{\"end\":111027,\"start\":111023},{\"end\":111040,\"start\":111037},{\"end\":111050,\"start\":111047},{\"end\":111310,\"start\":111303},{\"end\":111322,\"start\":111318},{\"end\":111332,\"start\":111327},{\"end\":111346,\"start\":111342},{\"end\":111365,\"start\":111354},{\"end\":111371,\"start\":111367},{\"end\":111647,\"start\":111642},{\"end\":111661,\"start\":111658},{\"end\":111679,\"start\":111677},{\"end\":111694,\"start\":111689},{\"end\":111873,\"start\":111867},{\"end\":111890,\"start\":111883},{\"end\":111919,\"start\":111901},{\"end\":111933,\"start\":111927},{\"end\":112233,\"start\":112221},{\"end\":112247,\"start\":112241},{\"end\":112271,\"start\":112256},{\"end\":112287,\"start\":112279},{\"end\":112303,\"start\":112297},{\"end\":112468,\"start\":112461},{\"end\":112486,\"start\":112480},{\"end\":112870,\"start\":112863},{\"end\":112884,\"start\":112877},{\"end\":112898,\"start\":112894},{\"end\":112912,\"start\":112907},{\"end\":113231,\"start\":113225},{\"end\":113246,\"start\":113243},{\"end\":113255,\"start\":113253},{\"end\":113269,\"start\":113265},{\"end\":113291,\"start\":113281},{\"end\":113304,\"start\":113299},{\"end\":113325,\"start\":113315},{\"end\":113670,\"start\":113666},{\"end\":113685,\"start\":113682},{\"end\":113697,\"start\":113692},{\"end\":114032,\"start\":114028},{\"end\":114394,\"start\":114386},{\"end\":114409,\"start\":114403},{\"end\":114424,\"start\":114418},{\"end\":114871,\"start\":114867},{\"end\":114887,\"start\":114882},{\"end\":114900,\"start\":114896},{\"end\":114917,\"start\":114909},{\"end\":114935,\"start\":114927},{\"end\":114948,\"start\":114945},{\"end\":114964,\"start\":114958},{\"end\":114975,\"start\":114970},{\"end\":114986,\"start\":114982},{\"end\":115004,\"start\":114995},{\"end\":115017,\"start\":115010},{\"end\":115031,\"start\":115023},{\"end\":115057,\"start\":115039},{\"end\":115068,\"start\":115066},{\"end\":115084,\"start\":115077},{\"end\":115096,\"start\":115093},{\"end\":115106,\"start\":115104},{\"end\":115123,\"start\":115116},{\"end\":115139,\"start\":115133},{\"end\":115154,\"start\":115149},{\"end\":115172,\"start\":115166},{\"end\":115178,\"start\":115174},{\"end\":115537,\"start\":115533},{\"end\":115560,\"start\":115544},{\"end\":115577,\"start\":115570},{\"end\":115585,\"start\":115583},{\"end\":115597,\"start\":115593},{\"end\":115612,\"start\":115606},{\"end\":115628,\"start\":115623},{\"end\":115636,\"start\":115634},{\"end\":115640,\"start\":115638},{\"end\":115766,\"start\":115763},{\"end\":115782,\"start\":115777},{\"end\":115797,\"start\":115792},{\"end\":116024,\"start\":116019},{\"end\":116040,\"start\":116033},{\"end\":116050,\"start\":116048},{\"end\":116071,\"start\":116061},{\"end\":116083,\"start\":116078}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":195317031},\"end\":96201,\"start\":96031},{\"attributes\":{\"doi\":\"10.18653/v1/P19-1620\",\"id\":\"b1\",\"matched_paper_id\":189762081},\"end\":96578,\"start\":96203},{\"attributes\":{\"doi\":\"10.18653/v1/W18-5513\",\"id\":\"b2\",\"matched_paper_id\":53640239},\"end\":96927,\"start\":96580},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":235391052},\"end\":97263,\"start\":96929},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.656\",\"id\":\"b4\",\"matched_paper_id\":215744944},\"end\":97622,\"start\":97265},{\"attributes\":{\"doi\":\"10.18653/v1/D19-1475\",\"id\":\"b5\",\"matched_paper_id\":202541363},\"end\":98256,\"start\":97624},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":218971783},\"end\":98508,\"start\":98258},{\"attributes\":{\"doi\":\"10.18653/v1/2021.findings-emnlp.324\",\"id\":\"b7\",\"matched_paper_id\":233296493},\"end\":98778,\"start\":98510},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":198917339},\"end\":99014,\"start\":98780},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":231861577},\"end\":99231,\"start\":99016},{\"attributes\":{\"id\":\"b10\"},\"end\":99342,\"start\":99233},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1123\",\"id\":\"b11\",\"matched_paper_id\":2172129},\"end\":99709,\"start\":99344},{\"attributes\":{\"doi\":\"10.18653/v1/D17-1090\",\"id\":\"b12\",\"matched_paper_id\":427742},\"end\":100041,\"start\":99711},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.454\",\"id\":\"b13\",\"matched_paper_id\":218571335},\"end\":100423,\"start\":100043},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1082\",\"id\":\"b14\",\"matched_paper_id\":44134226},\"end\":100761,\"start\":100425},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.580\",\"id\":\"b15\",\"matched_paper_id\":226262339},\"end\":101186,\"start\":100763},{\"attributes\":{\"doi\":\"10.18653/v1/N16-1138\",\"id\":\"b16\",\"matched_paper_id\":1434196},\"end\":101634,\"start\":101188},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":143544759},\"end\":101740,\"start\":101636},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":238857348},\"end\":101933,\"start\":101742},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":53597419},\"end\":102238,\"start\":101935},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":237304047},\"end\":102406,\"start\":102240},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-short.86\",\"id\":\"b21\",\"matched_paper_id\":235457983},\"end\":102908,\"start\":102408},{\"attributes\":{\"doi\":\"10.18653/v1/D15-1076\",\"id\":\"b22\",\"matched_paper_id\":1848109},\"end\":103291,\"start\":102910},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":127986954},\"end\":103456,\"start\":103293},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":127986954},\"end\":103710,\"start\":103458},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.309\",\"id\":\"b25\",\"matched_paper_id\":226278099},\"end\":104028,\"start\":103712},{\"attributes\":{\"doi\":\"arXiv\",\"id\":\"b26\"},\"end\":104164,\"start\":104030},{\"attributes\":{\"doi\":\"10.18653/v1/2020.coling-main.274\",\"id\":\"b27\",\"matched_paper_id\":227230348},\"end\":104583,\"start\":104166},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.623\",\"id\":\"b28\",\"matched_paper_id\":224802782},\"end\":104937,\"start\":104585},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":9426884},\"end\":105044,\"start\":104939},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00453\",\"id\":\"b30\",\"matched_paper_id\":244345901},\"end\":105282,\"start\":105046},{\"attributes\":{\"doi\":\"arXiv\",\"id\":\"b31\"},\"end\":105482,\"start\":105284},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":53592270},\"end\":105612,\"start\":105484},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.48\",\"id\":\"b33\",\"matched_paper_id\":216144503},\"end\":105972,\"start\":105614},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.340\",\"id\":\"b34\",\"matched_paper_id\":233231257},\"end\":106351,\"start\":105974},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":232233764},\"end\":106742,\"start\":106353},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":221655732},\"end\":107038,\"start\":106744},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":4837028},\"end\":107409,\"start\":107040},{\"attributes\":{\"doi\":\"10.18653/v1/D18-1003\",\"id\":\"b38\",\"matched_paper_id\":52215843},\"end\":107801,\"start\":107411},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.224\",\"id\":\"b39\",\"matched_paper_id\":222140906},\"end\":108210,\"start\":107803},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":204838007},\"end\":108460,\"start\":108212},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1255\",\"id\":\"b41\",\"matched_paper_id\":29152969},\"end\":108866,\"start\":108462},{\"attributes\":{\"doi\":\"10.18653/v1/D17-1317\",\"id\":\"b42\",\"matched_paper_id\":29298828},\"end\":109270,\"start\":108868},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":221191193},\"end\":109620,\"start\":109272},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-long.165\",\"id\":\"b44\",\"matched_paper_id\":235364036},\"end\":110171,\"start\":109622},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1058\",\"id\":\"b45\",\"matched_paper_id\":44130298},\"end\":110637,\"start\":110173},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.52\",\"id\":\"b46\",\"matched_paper_id\":232233599},\"end\":110952,\"start\":110639},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":160015036},\"end\":111235,\"start\":110954},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.373\",\"id\":\"b48\",\"matched_paper_id\":215745286},\"end\":111632,\"start\":111237},{\"attributes\":{\"doi\":\"arXiv ePrint 2109.09689\",\"id\":\"b49\"},\"end\":111792,\"start\":111634},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1074\",\"id\":\"b50\",\"matched_paper_id\":4711425},\"end\":112151,\"start\":111794},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":3680951},\"end\":112394,\"start\":112153},{\"attributes\":{\"doi\":\"10.3115/v1/W14-2508\",\"id\":\"b52\",\"matched_paper_id\":1669264},\"end\":112745,\"start\":112396},{\"attributes\":{\"doi\":\"10.18653/v1/P17-2102\",\"id\":\"b53\",\"matched_paper_id\":29259081},\"end\":113171,\"start\":112747},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.609\",\"id\":\"b54\",\"matched_paper_id\":216867133},\"end\":113578,\"start\":113173},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.450\",\"id\":\"b55\",\"matched_paper_id\":215548661},\"end\":113942,\"start\":113580},{\"attributes\":{\"doi\":\"10.18653/v1/P17-2067\",\"id\":\"b56\",\"matched_paper_id\":10326133},\"end\":114298,\"start\":113944},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1101\",\"id\":\"b57\",\"matched_paper_id\":3432876},\"end\":114798,\"start\":114300},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-demos.6\",\"id\":\"b58\",\"matched_paper_id\":208117506},\"end\":115468,\"start\":114800},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":85548567},\"end\":115677,\"start\":115470},{\"attributes\":{\"doi\":\"10.18653/v1/2021.findings-acl.435\",\"id\":\"b60\",\"matched_paper_id\":235458620},\"end\":115961,\"start\":115679},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":127986044},\"end\":116150,\"start\":115963}]", "bib_title": "[{\"end\":96098,\"start\":96031},{\"end\":96261,\"start\":96203},{\"end\":96652,\"start\":96580},{\"end\":97016,\"start\":96929},{\"end\":97302,\"start\":97265},{\"end\":97709,\"start\":97624},{\"end\":98295,\"start\":98258},{\"end\":98556,\"start\":98510},{\"end\":98844,\"start\":98780},{\"end\":99065,\"start\":99016},{\"end\":99413,\"start\":99344},{\"end\":99753,\"start\":99711},{\"end\":100147,\"start\":100043},{\"end\":100461,\"start\":100425},{\"end\":100794,\"start\":100763},{\"end\":101240,\"start\":101188},{\"end\":101687,\"start\":101636},{\"end\":101819,\"start\":101742},{\"end\":102006,\"start\":101935},{\"end\":102302,\"start\":102240},{\"end\":102470,\"start\":102408},{\"end\":103008,\"start\":102910},{\"end\":103337,\"start\":103293},{\"end\":103502,\"start\":103458},{\"end\":103780,\"start\":103712},{\"end\":104219,\"start\":104166},{\"end\":104645,\"start\":104585},{\"end\":104986,\"start\":104939},{\"end\":105126,\"start\":105046},{\"end\":105521,\"start\":105484},{\"end\":105705,\"start\":105614},{\"end\":106078,\"start\":105974},{\"end\":106410,\"start\":106353},{\"end\":106787,\"start\":106744},{\"end\":107135,\"start\":107040},{\"end\":107491,\"start\":107411},{\"end\":107892,\"start\":107803},{\"end\":108293,\"start\":108212},{\"end\":108576,\"start\":108462},{\"end\":108952,\"start\":108868},{\"end\":109373,\"start\":109272},{\"end\":109708,\"start\":109622},{\"end\":110235,\"start\":110173},{\"end\":110709,\"start\":110639},{\"end\":110993,\"start\":110954},{\"end\":111295,\"start\":111237},{\"end\":111859,\"start\":111794},{\"end\":112209,\"start\":112153},{\"end\":112451,\"start\":112396},{\"end\":112852,\"start\":112747},{\"end\":113217,\"start\":113173},{\"end\":113659,\"start\":113580},{\"end\":114018,\"start\":113944},{\"end\":114378,\"start\":114300},{\"end\":114858,\"start\":114800},{\"end\":115527,\"start\":115470},{\"end\":115753,\"start\":115679},{\"end\":116010,\"start\":115963}]", "bib_author": "[{\"end\":96114,\"start\":96100},{\"end\":96128,\"start\":96114},{\"end\":96143,\"start\":96128},{\"end\":96159,\"start\":96143},{\"end\":96278,\"start\":96263},{\"end\":96292,\"start\":96278},{\"end\":96306,\"start\":96292},{\"end\":96320,\"start\":96306},{\"end\":96337,\"start\":96320},{\"end\":96669,\"start\":96654},{\"end\":96686,\"start\":96669},{\"end\":96704,\"start\":96686},{\"end\":97028,\"start\":97018},{\"end\":97042,\"start\":97028},{\"end\":97056,\"start\":97042},{\"end\":97077,\"start\":97056},{\"end\":97085,\"start\":97077},{\"end\":97320,\"start\":97304},{\"end\":97341,\"start\":97320},{\"end\":97358,\"start\":97341},{\"end\":97379,\"start\":97358},{\"end\":97732,\"start\":97711},{\"end\":97749,\"start\":97732},{\"end\":97765,\"start\":97749},{\"end\":97784,\"start\":97765},{\"end\":97799,\"start\":97784},{\"end\":97817,\"start\":97799},{\"end\":97838,\"start\":97817},{\"end\":98308,\"start\":98297},{\"end\":98323,\"start\":98308},{\"end\":98335,\"start\":98323},{\"end\":98352,\"start\":98335},{\"end\":98368,\"start\":98352},{\"end\":98387,\"start\":98368},{\"end\":98407,\"start\":98387},{\"end\":98421,\"start\":98407},{\"end\":98436,\"start\":98421},{\"end\":98451,\"start\":98436},{\"end\":98570,\"start\":98558},{\"end\":98583,\"start\":98570},{\"end\":98597,\"start\":98583},{\"end\":98858,\"start\":98846},{\"end\":98872,\"start\":98858},{\"end\":98886,\"start\":98872},{\"end\":98900,\"start\":98886},{\"end\":98911,\"start\":98900},{\"end\":98923,\"start\":98911},{\"end\":98935,\"start\":98923},{\"end\":98949,\"start\":98935},{\"end\":98956,\"start\":98949},{\"end\":99080,\"start\":99067},{\"end\":99101,\"start\":99080},{\"end\":99115,\"start\":99101},{\"end\":99132,\"start\":99115},{\"end\":99146,\"start\":99132},{\"end\":99163,\"start\":99146},{\"end\":99336,\"start\":99323},{\"end\":99425,\"start\":99415},{\"end\":99437,\"start\":99425},{\"end\":99452,\"start\":99437},{\"end\":99765,\"start\":99755},{\"end\":99776,\"start\":99765},{\"end\":99787,\"start\":99776},{\"end\":99798,\"start\":99787},{\"end\":100162,\"start\":100149},{\"end\":100169,\"start\":100162},{\"end\":100180,\"start\":100169},{\"end\":100475,\"start\":100463},{\"end\":100487,\"start\":100475},{\"end\":100501,\"start\":100487},{\"end\":100808,\"start\":100796},{\"end\":100827,\"start\":100808},{\"end\":100842,\"start\":100827},{\"end\":100860,\"start\":100842},{\"end\":100876,\"start\":100860},{\"end\":100893,\"start\":100876},{\"end\":100909,\"start\":100893},{\"end\":100927,\"start\":100909},{\"end\":101260,\"start\":101242},{\"end\":101277,\"start\":101260},{\"end\":101706,\"start\":101689},{\"end\":101837,\"start\":101821},{\"end\":101854,\"start\":101837},{\"end\":101867,\"start\":101854},{\"end\":101880,\"start\":101867},{\"end\":101899,\"start\":101880},{\"end\":101912,\"start\":101899},{\"end\":101924,\"start\":101912},{\"end\":102029,\"start\":102008},{\"end\":102046,\"start\":102029},{\"end\":102061,\"start\":102046},{\"end\":102077,\"start\":102061},{\"end\":102318,\"start\":102304},{\"end\":102341,\"start\":102318},{\"end\":102485,\"start\":102472},{\"end\":102501,\"start\":102485},{\"end\":103021,\"start\":103010},{\"end\":103033,\"start\":103021},{\"end\":103051,\"start\":103033},{\"end\":103353,\"start\":103339},{\"end\":103363,\"start\":103353},{\"end\":103370,\"start\":103363},{\"end\":103386,\"start\":103370},{\"end\":103398,\"start\":103386},{\"end\":103518,\"start\":103504},{\"end\":103528,\"start\":103518},{\"end\":103535,\"start\":103528},{\"end\":103551,\"start\":103535},{\"end\":103563,\"start\":103551},{\"end\":103796,\"start\":103782},{\"end\":103811,\"start\":103796},{\"end\":103824,\"start\":103811},{\"end\":103840,\"start\":103824},{\"end\":103855,\"start\":103840},{\"end\":103869,\"start\":103855},{\"end\":104128,\"start\":104117},{\"end\":104141,\"start\":104128},{\"end\":104155,\"start\":104141},{\"end\":104233,\"start\":104221},{\"end\":104249,\"start\":104233},{\"end\":104268,\"start\":104249},{\"end\":104286,\"start\":104268},{\"end\":104299,\"start\":104286},{\"end\":104309,\"start\":104299},{\"end\":104327,\"start\":104309},{\"end\":104338,\"start\":104327},{\"end\":104662,\"start\":104647},{\"end\":104678,\"start\":104662},{\"end\":105003,\"start\":104988},{\"end\":105144,\"start\":105128},{\"end\":105161,\"start\":105144},{\"end\":105177,\"start\":105161},{\"end\":105193,\"start\":105177},{\"end\":105296,\"start\":105284},{\"end\":105306,\"start\":105296},{\"end\":105319,\"start\":105306},{\"end\":105331,\"start\":105319},{\"end\":105345,\"start\":105331},{\"end\":105357,\"start\":105345},{\"end\":105368,\"start\":105357},{\"end\":105380,\"start\":105368},{\"end\":105398,\"start\":105380},{\"end\":105416,\"start\":105398},{\"end\":105540,\"start\":105523},{\"end\":105554,\"start\":105540},{\"end\":105717,\"start\":105707},{\"end\":105730,\"start\":105717},{\"end\":106100,\"start\":106080},{\"end\":106116,\"start\":106100},{\"end\":106128,\"start\":106116},{\"end\":106143,\"start\":106128},{\"end\":106152,\"start\":106143},{\"end\":106427,\"start\":106412},{\"end\":106441,\"start\":106427},{\"end\":106457,\"start\":106441},{\"end\":106469,\"start\":106457},{\"end\":106484,\"start\":106469},{\"end\":106508,\"start\":106484},{\"end\":106523,\"start\":106508},{\"end\":106537,\"start\":106523},{\"end\":106550,\"start\":106537},{\"end\":106563,\"start\":106550},{\"end\":106809,\"start\":106789},{\"end\":106822,\"start\":106809},{\"end\":106838,\"start\":106822},{\"end\":106859,\"start\":106838},{\"end\":107152,\"start\":107137},{\"end\":107174,\"start\":107152},{\"end\":107191,\"start\":107174},{\"end\":107207,\"start\":107191},{\"end\":107508,\"start\":107493},{\"end\":107530,\"start\":107508},{\"end\":107544,\"start\":107530},{\"end\":107560,\"start\":107544},{\"end\":107913,\"start\":107894},{\"end\":107925,\"start\":107913},{\"end\":107940,\"start\":107925},{\"end\":107951,\"start\":107940},{\"end\":108309,\"start\":108295},{\"end\":108323,\"start\":108309},{\"end\":108337,\"start\":108323},{\"end\":108352,\"start\":108337},{\"end\":108367,\"start\":108352},{\"end\":108383,\"start\":108367},{\"end\":108395,\"start\":108383},{\"end\":108403,\"start\":108395},{\"end\":108416,\"start\":108403},{\"end\":108589,\"start\":108578},{\"end\":108600,\"start\":108589},{\"end\":108606,\"start\":108600},{\"end\":108977,\"start\":108954},{\"end\":108991,\"start\":108977},{\"end\":109006,\"start\":108991},{\"end\":109021,\"start\":109006},{\"end\":109027,\"start\":109021},{\"end\":109388,\"start\":109375},{\"end\":109408,\"start\":109388},{\"end\":109425,\"start\":109408},{\"end\":109437,\"start\":109425},{\"end\":109727,\"start\":109710},{\"end\":109746,\"start\":109727},{\"end\":109764,\"start\":109746},{\"end\":110254,\"start\":110237},{\"end\":110265,\"start\":110254},{\"end\":110725,\"start\":110711},{\"end\":110737,\"start\":110725},{\"end\":110754,\"start\":110737},{\"end\":111004,\"start\":110995},{\"end\":111016,\"start\":111004},{\"end\":111029,\"start\":111016},{\"end\":111042,\"start\":111029},{\"end\":111052,\"start\":111042},{\"end\":111312,\"start\":111297},{\"end\":111324,\"start\":111312},{\"end\":111334,\"start\":111324},{\"end\":111348,\"start\":111334},{\"end\":111367,\"start\":111348},{\"end\":111373,\"start\":111367},{\"end\":111649,\"start\":111634},{\"end\":111663,\"start\":111649},{\"end\":111671,\"start\":111663},{\"end\":111681,\"start\":111671},{\"end\":111696,\"start\":111681},{\"end\":111875,\"start\":111861},{\"end\":111892,\"start\":111875},{\"end\":111921,\"start\":111892},{\"end\":111935,\"start\":111921},{\"end\":112235,\"start\":112211},{\"end\":112249,\"start\":112235},{\"end\":112273,\"start\":112249},{\"end\":112289,\"start\":112273},{\"end\":112305,\"start\":112289},{\"end\":112470,\"start\":112453},{\"end\":112488,\"start\":112470},{\"end\":112872,\"start\":112854},{\"end\":112886,\"start\":112872},{\"end\":112900,\"start\":112886},{\"end\":112914,\"start\":112900},{\"end\":113233,\"start\":113219},{\"end\":113248,\"start\":113233},{\"end\":113257,\"start\":113248},{\"end\":113271,\"start\":113257},{\"end\":113293,\"start\":113271},{\"end\":113306,\"start\":113293},{\"end\":113327,\"start\":113306},{\"end\":113672,\"start\":113661},{\"end\":113687,\"start\":113672},{\"end\":113699,\"start\":113687},{\"end\":114034,\"start\":114020},{\"end\":114041,\"start\":114034},{\"end\":114396,\"start\":114380},{\"end\":114411,\"start\":114396},{\"end\":114426,\"start\":114411},{\"end\":114873,\"start\":114860},{\"end\":114889,\"start\":114873},{\"end\":114902,\"start\":114889},{\"end\":114919,\"start\":114902},{\"end\":114937,\"start\":114919},{\"end\":114950,\"start\":114937},{\"end\":114966,\"start\":114950},{\"end\":114977,\"start\":114966},{\"end\":114988,\"start\":114977},{\"end\":115006,\"start\":114988},{\"end\":115019,\"start\":115006},{\"end\":115033,\"start\":115019},{\"end\":115059,\"start\":115033},{\"end\":115070,\"start\":115059},{\"end\":115086,\"start\":115070},{\"end\":115098,\"start\":115086},{\"end\":115108,\"start\":115098},{\"end\":115125,\"start\":115108},{\"end\":115141,\"start\":115125},{\"end\":115156,\"start\":115141},{\"end\":115174,\"start\":115156},{\"end\":115180,\"start\":115174},{\"end\":115539,\"start\":115529},{\"end\":115562,\"start\":115539},{\"end\":115579,\"start\":115562},{\"end\":115587,\"start\":115579},{\"end\":115599,\"start\":115587},{\"end\":115614,\"start\":115599},{\"end\":115630,\"start\":115614},{\"end\":115638,\"start\":115630},{\"end\":115642,\"start\":115638},{\"end\":115768,\"start\":115755},{\"end\":115784,\"start\":115768},{\"end\":115799,\"start\":115784},{\"end\":116026,\"start\":116012},{\"end\":116042,\"start\":116026},{\"end\":116052,\"start\":116042},{\"end\":116073,\"start\":116052},{\"end\":116085,\"start\":116073}]", "bib_venue": "[{\"end\":96533,\"start\":96446},{\"end\":96882,\"start\":96803},{\"end\":97569,\"start\":97497},{\"end\":98211,\"start\":98035},{\"end\":98733,\"start\":98703},{\"end\":99663,\"start\":99574},{\"end\":99996,\"start\":99906},{\"end\":100370,\"start\":100298},{\"end\":100715,\"start\":100623},{\"end\":101133,\"start\":101054},{\"end\":101589,\"start\":101441},{\"end\":102234,\"start\":102164},{\"end\":102841,\"start\":102694},{\"end\":103246,\"start\":103159},{\"end\":103706,\"start\":103643},{\"end\":104527,\"start\":104449},{\"end\":104884,\"start\":104805},{\"end\":105919,\"start\":105847},{\"end\":106298,\"start\":106249},{\"end\":106738,\"start\":106659},{\"end\":107034,\"start\":106955},{\"end\":107346,\"start\":107285},{\"end\":107756,\"start\":107668},{\"end\":108157,\"start\":108078},{\"end\":108809,\"start\":108728},{\"end\":109225,\"start\":109135},{\"end\":109616,\"start\":109535},{\"end\":110117,\"start\":109970},{\"end\":110591,\"start\":110442},{\"end\":110899,\"start\":110850},{\"end\":111231,\"start\":111150},{\"end\":111579,\"start\":111500},{\"end\":112105,\"start\":112034},{\"end\":112700,\"start\":112603},{\"end\":113112,\"start\":113023},{\"end\":113533,\"start\":113454},{\"end\":113889,\"start\":113817},{\"end\":114239,\"start\":114150},{\"end\":114752,\"start\":114603},{\"end\":115415,\"start\":115321},{\"end\":96195,\"start\":96159},{\"end\":96444,\"start\":96357},{\"end\":96801,\"start\":96724},{\"end\":97179,\"start\":97085},{\"end\":97495,\"start\":97408},{\"end\":98033,\"start\":97858},{\"end\":98500,\"start\":98451},{\"end\":98701,\"start\":98632},{\"end\":99008,\"start\":98956},{\"end\":99224,\"start\":99163},{\"end\":99321,\"start\":99233},{\"end\":99559,\"start\":99472},{\"end\":99572,\"start\":99561},{\"end\":99904,\"start\":99818},{\"end\":100296,\"start\":100209},{\"end\":100608,\"start\":100521},{\"end\":100621,\"start\":100610},{\"end\":101052,\"start\":100958},{\"end\":101439,\"start\":101297},{\"end\":101728,\"start\":101706},{\"end\":101927,\"start\":101924},{\"end\":102162,\"start\":102077},{\"end\":102402,\"start\":102341},{\"end\":102692,\"start\":102530},{\"end\":103157,\"start\":103071},{\"end\":103450,\"start\":103398},{\"end\":103641,\"start\":103563},{\"end\":103973,\"start\":103904},{\"end\":104115,\"start\":104030},{\"end\":104447,\"start\":104370},{\"end\":104803,\"start\":104709},{\"end\":105037,\"start\":105003},{\"end\":105274,\"start\":105213},{\"end\":105476,\"start\":105421},{\"end\":105606,\"start\":105554},{\"end\":105845,\"start\":105758},{\"end\":106247,\"start\":106183},{\"end\":106657,\"start\":106563},{\"end\":106953,\"start\":106859},{\"end\":107283,\"start\":107207},{\"end\":107666,\"start\":107580},{\"end\":108076,\"start\":107982},{\"end\":108452,\"start\":108416},{\"end\":108713,\"start\":108626},{\"end\":108726,\"start\":108715},{\"end\":109133,\"start\":109047},{\"end\":109533,\"start\":109437},{\"end\":109955,\"start\":109793},{\"end\":109968,\"start\":109957},{\"end\":110427,\"start\":110285},{\"end\":110440,\"start\":110429},{\"end\":110848,\"start\":110784},{\"end\":111148,\"start\":111052},{\"end\":111498,\"start\":111404},{\"end\":111786,\"start\":111719},{\"end\":112019,\"start\":111955},{\"end\":112032,\"start\":112021},{\"end\":112388,\"start\":112305},{\"end\":112601,\"start\":112507},{\"end\":113021,\"start\":112934},{\"end\":113452,\"start\":113358},{\"end\":113815,\"start\":113728},{\"end\":114148,\"start\":114061},{\"end\":114588,\"start\":114446},{\"end\":114601,\"start\":114590},{\"end\":115319,\"start\":115210},{\"end\":115671,\"start\":115642},{\"end\":115906,\"start\":115832},{\"end\":116144,\"start\":116085}]"}}}, "year": 2023, "month": 12, "day": 17}