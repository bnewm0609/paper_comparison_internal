{"id": 238793999, "updated": "2023-10-06 02:50:17.866", "metadata": {"title": "A Novel Deep Learning Based Model for Tropical Intensity Estimation and Post-Disaster Management of Hurricanes", "authors": "[{\"first\":\"Jayanthi\",\"last\":\"Devaraj\",\"middle\":[\"Ganesan\",\"Sumathi\",\"Rajvikram\",\"Madurai\",\"Elavarasan\",\"Subramaniam\",\"Umashankar\"]}]", "venue": null, "journal": "Applied Sciences", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": ": The prediction of severe weather events such as hurricanes is always a challenging task in the history of climate research, and many deep learning models have been developed for predicting the severity of weather events. When a disastrous hurricane strikes a coastal region, it causes serious hazards to human life and habitats and also re\ufb02ects a prodigious amount of economic losses. Therefore, it is necessary to build models to improve the prediction accuracy and to avoid such signi\ufb01cant losses in all aspects. However, it is impractical to predict or monitor every storm formation in real time. Though various techniques exist for diagnosing the tropical cyclone intensity such as convolutional neural networks (CNN), convolutional auto-encoders, recurrent neural network (RNN), etc., there are some challenges involved in estimating the tropical cyclone intensity. This study emphasizes estimating the tropical cyclone intensity to identify the different categories of hurricanes and to perform post-disaster management. An improved deep convolutional neural network (CNN) model is used for predicting the weakest to strongest hurricanes with the intensity values using infrared satellite imagery data and wind speed data from HURDAT2 database. The model achieves a lower Root mean squared error (RMSE) value of 7.6 knots and a Mean squared error (MSE) value of 6.68 knots by adding the batch normalization and dropout layers in the CNN model. Further, it is crucial to predict and evaluate the post-disaster damage for implementing advance measures and planning for the resources. The \ufb01ne-tuning of the pre-trained visual geometry group (VGG 19) model is accomplished to predict the extent of damage and to perform automatic annotation for the image using the satellite imagery data of Greater Houston. VGG 19 is also trained using video datasets for classifying various types of severe weather events and to annotate the weather event automatically. An accuracy of 98% is achieved for hurricane damage prediction and 97% accuracy for classifying severe weather events. The results proved that the proposed models for hurricane intensity estimation and its damage prediction enhances the learning ability, which can ultimately help scientists and meteorologists to comprehend the formation of storm events. Finally, the mitigation steps in reducing the hurricane risks are addressed. study is mean square error (MSE), and epochs denote the number of iterations considered for training the dataset. The predictions are done on the test data after the training process is completed.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": "3160409764", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.3390/app11094129"}}, "content": {"source": {"pdf_hash": "dcf192ea3d1a7c5c3439be6a9287fc02dd026c3c", "pdf_src": "Adhoc", "pdf_uri": "[\"https://web.archive.org/web/20210605034117/https:/res.mdpi.com/d_attachment/applsci/applsci-11-04129/article_deploy/applsci-11-04129.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.mdpi.com/2076-3417/11/9/4129/pdf", "status": "GREEN"}}, "grobid": {"id": "5ebf9a2bf217b91c742f7a20b3557e2ca94ff912", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/dcf192ea3d1a7c5c3439be6a9287fc02dd026c3c.txt", "contents": "\nA Novel Deep Learning Based Model for Tropical Intensity Estimation and Post-Disaster Management of Hurricanes\nPublished: 30 April 2021\n\nJayanthi Devaraj \nDepartment of Information Technology\nSri Venkateswara College of Engineering\n602117ChennaiIndia\n\nSumathi Ganesan \nDepartment of Information Technology\nSri Venkateswara College of Engineering\n602117ChennaiIndia\n\nRajvikram Madurai Elavarasan \nClean and Resilient Energy Systems (CARES) Laboratory\nTexas A&M University\n77553GalvestonTXUSA\n\nUmashankar Subramaniam \nDepartment\nCollege of Engineering\nCommunications and Networks, Renewable Energy Laboratory\nPrince Sultan University\n12435RiyadhSaudi Arabia\n\nA Novel Deep Learning Based Model for Tropical Intensity Estimation and Post-Disaster Management of Hurricanes\nPublished: 30 April 202110.3390/app11094129Received: 6 April 2021 Accepted: 22 April 2021applied sciences Article Academic Editor: Mauro Castelli\nCitation: Devaraj, J.; Ganesan, S.; Elavarasan, R.M.; Subramaniam, U. A Novel Deep Learning Based Model for Tropical Intensity Estimation and Post-Disaster Management of Hurricanes. Appl. Sci. 2021, 11, 4129.\n\nIntroduction\n\nA fast-rotating tropical cyclone storm circulating around a defined center is called a hurricane, and the severity of the occurrence of the hurricane depends on the location and strength of the storm. The cyclic wind movement induces a low pressure in the middle of the hurricane, and thus the air is pushed upwards and the wind flows through the center of the storm. As the wind speed increases, it becomes a tropical storm and emerges into a hurricane, which mostly occurs in the Atlantic Ocean and North Eastern Pacific Ocean with cyclic wind movement whose closed wind speed exceeds 75 mph [1]. Hurricanes tend to grow when they take energy from the warm ocean water. When the wind speed increases, hurricanes strike the land, which incurs severe damage. Hurricanes can be categorized into various types depending on the wind speed parameter. Hurricanes with a wind speed of 74 mph or above are termed category 5 hurricanes, which are cataclysmic in nature [2]. When the wind speed exceeds the above threshold, it is impossible to prevent the occurrence of extreme weather event. A storm induces the abnormal rise of water called a storm surge, and the height of the water level can rise 20 feet or more above the sea level. This is called catastrophic, and the storm surge exceeds 19+ feet. The rise in the sea level that occurs during a tropical cyclone is called a storm surge, which generates strong winds that push the water into the shore and leads to flooding. Flooding and storm surges are the sequential disaster events triggered by hurricanes. The coastal regions are primarily affected by the storm surges, which cause colossal damage. Therefore, it is essential for the scientists to predict the formation of hurricanes using best prediction models well in advance to prevent damage and save human lives [3]. Table 1 shows the classifications of hurricanes with the sustained wind range values. In the stages of hurricane development, the formation of closed isobaric circulation is called tropical depression. Tropical depressions develop into tropical storms when the sustained wind velocity exceeds 63 km/h (39 mph) and is considered a threat. It turns into a hurricane when the wind speed exceeds 119 km/h and is considered as the destructive stage of the tropical storm. The characteristics of wind attributes over various measurement conditions should be analyzed for effective estimation of tropical cyclone intensity. Meteorologists face difficulties in predicting weather events using computational models because of the complexity and randomness involved in the weather variables. Various factors such as the volume of data availability and computational time to analyze and execute mainly depend on the complexity involved in the variables. The sources of data are combined from the observations of weather stations, satellites, and weather balloons. Satellite images such as cloud cover and water vapor changes in the atmosphere are used by scientists for accurate prediction. Numerical weather prediction (NWP) models are dependent on the existing weather models such as the movable fine mesh (MFM) model for tracking the hurricane, and the joint physics-based on machine learning (ML) models can achieve good performance when the output of the physics-based model is fed into the neural networks [4]. The major limitation of the NWP models is that if the forecast period increases, interpolation of a large volume of data occurs and takes more computational time for processing. In order to predict the changes in the atmospheric processes, mathematical models such as global circulation models are used for analysis. It is very difficult for the meteorologists to predict the localized precipitation and the thunderstorms present in the convective storms. If a higher number of processes are involved, the model may take more time to forecast, and there is always a trade-off between the computational speed, accuracy, and the complexity of parameters. Because of the high complex nature of the earth's atmosphere, it is very challenging for the researchers to simulate a 100% accurate model [5]. Spatio-temporal relational probability trees are used for capturing spatio-temporal relationships between weather variables and improving the prediction accuracy of severe weather events [6]. Predicting the storm's lifetime is important to provide early warnings and to take preventive measures. Random forest (RF) classification and regression models predict the closeness of the observed storm with the forecasted storm Appl. Sci. 2021, 11, 4129 3 of 39 and also capture the correlation between the parameters of the data. Machine learning and deep learning can be applied to a variety of high-impact weather applications, and good prediction results can be achieved [7]. Worldwide, more than 100,000 deaths can occur due to hurricanes, and a single event may cause up to 1000 deaths. Large economic losses are incurred, and even $100 billion damage is caused by some storms. Hence, there is a pressing need to accurately predict the intensity of the tropical cyclone for disaster preparedness. Satellite measurements are used for predicting the intensity values. The Dvorak technique was used to estimate the intensity with human interpretation while direct measurements are not available. Based on the cloud features such as length and the curvature of storm outer bands, the intensity is estimated by capturing the relationship between the features [8]. In the advanced Dvorak technique, the passive microwave data and the measurements of the aircraft are included to estimate the intensity, but still lower performance is achieved for the weaker storms [9,10]. The deviation angle variation technique uses infrared satellite imagery and computes the gradient vector, and in this case, the variance is used to estimate the intensity values. However, the center of the tropical cyclone images should be clearly marked, and it is difficult to fit the parameters over multiple regions [11,12]. A passive microwave-imagery-based technique was used to estimate the intensity by capturing the inner structure and the details of the cyclone, but the resulted accuracy was less. The deviation angle variation technique is widely used to estimate the intensity in north Atlantic and Pacific oceans [13,14]. When compared to infrared satellite images, the microwave measurement data have significantly less temporal frequency of observations. Many machine learning (ML) models are capable of learning the data directly without depending on the mathematical equations or models. Recently, ML models have provided good accuracy in predicting the weather events. Modern artificial intelligence (AI) techniques are used for high-impact weather forecasting to extract the features from the weather data and are useful for real-time decision making processes [15]. The main hazardous attributes of hurricanes are winds, rainfall, and storm surges. Destruction can be caused because of the impact of the sustained wind range and can cause damage to the agricultural crops. Tall buildings can shake and fall down, and also because of the pressure differences, the roofs and the buildings are also affected and damaged. ML model predictions are dependent on some set of criteria or based on the value of the threshold. However, the weather variables of the extreme events are dynamic in nature, and spatiotemporal correlation must be identified. ML models cannot produce accurate results in identifying the spatio-temporal relationship between the variables. The deep learning models are capable of capturing higher level feature representation while modeling complex problems. Graphical processing unit (GPU)-based systems enable faster execution of the complex processes related to weather modeling. DL models produce good results with a large volume of training data, and hybrid models still can improve the efficiency and accuracy of the prediction. The consequences of disaster have to be reduced, and it depends on the government, private sectors, communities, and many other social factors to work together [16]. It is also important to identify the disaster-related stressors that are harmful to human beings. There exists a relationship between the characteristics of the COVID-19 pandemic and the post-disaster adversarial health effects due to the impact of weather conditions. Deep learning models help to predict the COVID-19 pandemic by taking into account the dynamic weather variables to reduce the spread of disease and to take necessary preventive measures [17]. Flood security, water sufficiency, ecosystem and environmental stability, human security, and sustainable energy and development are the areas that can be aligned with the impact of severe weather events [18]. Deep belief networks take into consideration of all the weather factors that mainly affect the prediction [19]. The impact of weather prediction plays a major role in wind speed and wind power forecasting. The meteorological attributes and the dynamic weather variables can improve the forecasting accuracy. Wind speed is an important attribute for hurricane prediction, and the deep learning models such as long short term memory (LSTM), its variants, and the hybrid model can predict the wind speed accurately [20].\n\nConsidering all these inferences, Section 2 reviews the existing literature and research contributions. Section 3 describes the datasets used for hurricane intensity estimation, damage prediction, and the methodology for the classification of severe weather events are revealed. Section 4 describes the performance evaluation metrics of the prediction models. Section 5 discusses the results of the performed detailed analysis. Finally, the conclusions are drawn, and the future scopes are presented in Section 6.\n\n\nLiterature Review\n\nIn general, all the types of severe weather events cause serious threats to human lives and property. Based on the advancement of technologies, it is important to forecast such types of extreme events well in advance, and early warnings as well as measures should be implemented to prevent devastating impacts. In this section, the existing literature studies that uses various DL models for forecasting severe weather events are reviewed in Table 2.\n\n\nResearch Gaps and Motivation\n\nFrom the literature study described in Table 2, it is inferred that there are a variety of models for performing time-series and spatio-temporal analysis to predict extreme weather events with its own advantages and limitations. Some of the existing models fail to capture the dynamic nature of weather variables and the physical processes involved for prediction. Presently, the existing literature focuses on predicting the tropical cyclone intensity estimation using variants of convolutional neural networks. Additionally, several types of disasters such as earthquakes, floods, wildfire, hurricanes can be classified using the Deep Convolutional Neural Networks (DCNN) and the pre-trained models such as VGG (Visual Geometry Group), AlexNet, ResNet, InceptionNet. These models are utilized depending on the number of Convolutional layers that is framed for predicting the postdisaster damage incurred by the hurricane. This work mainly aims to improve the accuracy in predicting the tropical cyclone intensity and the classification of damage assessment caused by the disaster.\n\nAs individual and citizen, it is important to understand how to protect ourselves from the hurricane. To reduce the hurricane risk, an improved hurricane accurate forecast is essential and since the limited resources are available for reducing the hurricane hazard, it is considered as an economic problem. Policy officials can analyze the effective investment in forecast generation for reducing the mortality and the property loss. Since hurricanes impose more threat to human lives and damages to properties, it is significantly important to understand the different stages of hurricane and its impact. Hurricane prediction helps to prevent the physical damage at various levels such as individual, business and at the society level. Determining an accurate tropical cyclone intensity values may help to provide early warning. The quality of the initial condition input to the model is significantly important in predicting the hurricane. Estimating the tropical cyclone intensity can help better initialization of the model. The forecast quality can be improved by considering the different aspects such as location of hurricane, intensity, forward speed, storm surge etc. The forecast users, providers and the policy makers can yield more information by evaluating the trade-off between the different aspects. In this study, we present an improved CNN model for estimating the tropical cyclone intensity and its categories effectively. In the proposed model, the max pooling layer is removed and the stride value of the previous convolutional layer is increased to improve the accuracy. Additionally, batch normalization is added after the first convolutional layer, which is used to normalize the input and improves the training time. The satellite image dataset and the corresponding wind speed data from HURDAT2 database are used together for training. Lower RMSE values are obtained using the proposed model when compared to the existing techniques. The model is generalized and is applicable for all the regions (Atlantic and Pacific). The model analyzes the images along with the wind speed data and provides the different categories of hurricanes with its vulnerability. Additionally, the post-disaster management and the classification of extreme weather events are carried out using the pre-trained models, and improved accuracy is obtained.\n\nThe improved deep convolution neural network (I-DCNN) is used for hurricane intensity estimation. CNN with data augmentation and transfer learning using the pretrained network VGG-19 is used for the classification of building damage assessment and for classifying the different types of weather events using a video dataset. The prediction results of the proposed models are compared with the existing models using various performance metrics.\n\nThe novelty and the main contributions of the proposed study are as follows:\n\n\u2022 Exploratory data analysis and visualization of hurricanes is being carried out.\n\n\n\u2022\n\nThe development of improved deep CNN (I-DCNN) model for estimating the intensity using the infrared satellite imagery dataset.\n\n\n\u2022\n\nTo perform a damage assessment of hurricanes and categorization of various extreme weather events using VGG 19 CNN with data augmentation and transfer learning.\n\n\n\u2022\n\nTo explore the mitigation steps in reducing the hurricane risk. To predict the flash flood susceptibility levels using an inference model.\n\nFeature selection is carried out using the information gain ratio. Automated feature selection at higher level using hybrid models can enhance the prediction accuracy.\n\n[24]\n\nRecurrent neural network (RNN) and Genetic algorithm (GA) Hurricane prediction.\n\nAtlantic hurricane data.\n\nProposed model provides nearly 85% greater accuracy than the other traditional models.\n\nDynamic time warping (DWT) that measures the distance between the target hurricanes improves the prediction accuracy.\n\nRNN lacks in capturing the long-term dependencies in the data and fails to produce good results for the changing and dynamic nature of weather variables. Accuracy of 86% is achieved to identify the ATC-20 tags for the test data.\n\nBuilding damage assessment after the occurrence of an earthquake to help the emergency responders and recovery planners.\n\nModel was trained for a single earthquake with a smaller number of textual information and components. Training the model to classify the multiple events with higher level components. [26] Grid-based Recurrent neural network (RNN) Hurricane prediction.\n\nHurricanes and tropical storms from 1920 to 2012 from National Hurricane Center (NHC).  Root-mean-square intensity difference of 8. 39 knots.\n\nCNN estimates the TC intensity as a regression task and the RMSE is reduced to 8.74 kts because of post analysis smoothing.\n\nOperational latency is higher and rain rate observation data in the short time window are not considered.\n\n[32]\n\nSpatio-temporal convolutional sequence to sequence network (STConvS2S) Rainfall Prediction. South America rainfall data and air temperature data.\n\nGood accuracy is achieved with 23% better performance than the RNN-based models.\n\nDuring learning, temporal order can be random, and the length of input and output sequences need not be equal. Spatio-temporal relationships are captured using only CNN.\n\nLong-term dependencies in the temporal data cannot be efficiently handled and difficult to predict severe weather events with the more atmospheric variables. [33] ConvLSTM Hurricane prediction. 20 years of hurricane data from the National Hurricane Center (NHC).\n\nConvLSTM outperforms other models by gaining a good prediction accuracy of 87%.\n\nHurricane trajectories are predicted using density map sequences.\n\nHigh computational costs and memory consumption for training. To improve the accuracy of wind-speed forecasting for enhancing the operational efficiency, power quality, and the economic benefit.\n\nA data preprocessing technique is not employed to reduce the data noise. A hybrid model using a deep neural network (DNN) can improve the accuracy. Short-term wind speed forecasting.\n\nSwedish wind farm located in the Baltic Sea with the forecasting horizon of 10-min ahead and 1-h ahead.\n\nTen minutes ahead for B8 wind turbine at Lillgrund. ED-HGNDO-BiLSTM Model Summer Season:\nRMSE-7.41 \u00d7 10 \u22121 ; MAE-5.32 \u00d7 10 \u22121 ; MAPE-1.24 \u00d7 10 1 ; R -9.77 \u00d7 10 \u22121 ; Root Mean Square Logarithmic Error RMSLE-1.41 \u00d7 10 \u22121 ; Theil's Inequality Co-efficient TIC-6.22 \u00d7 10 \u22122 .\nTo improve the accuracy of short-term wind-speed forecasting using a hybrid model by classifying the wind-speed time-series data and analyzing the performance on four different seasons.\n\nAdvanced feature extraction techniques, meta-heuristics algorithm, and other hybrid deep learning models can improve the accuracy.\n\n[38] Temporal convolutional network model (TCN).\n\nShort-term wind power forecast.\n\nTwelve months of data of 86 wind turbines from a 130 MW utility scale wind farm. Multi-step prediction is done 0, 10, 20, 30, 40 and 50-min ahead.\n\nOptimal power curves are obtained using TCN. TCN outperforms CNN and the hybrid model CNN+LSTM.\n\nTotal wind power is predicted using a TCN model with an orthogonal array tuning method (OATM) to optimize the hyper parameters of the proposed model.\n\nOnly the temporal variables along with the meteorological variables are considered. Identifying the spatio-temporal correlation using hybrid deep learning models can improve the performance of the wind power forecast.\n\n\nMethodology\n\nThis section presents the theoretical background of the related work, the dataset description and the features used to estimate the intensity and the severity of disaster, and the dataset for building damage assessment and classification of various extreme weather events with the proposed methodology.\n\n\nTheoretical Background\n\nDeep learning captures the higher-level representation of features and is widely used in computer vision, image classification, object detection, and pattern recognition algorithms. Convolutional neural networks are mostly adopted in many classification tasks [39]. Depending on the nature of the data, the features are learned by the convolutional layer. Different convolution operations are used for learning the weights of the convolution filter, which takes the input and generates the feature maps. The element-wise non-linear activation function is applied to the results. ReLU activation is used, which captures non-linearity in the network. The spatial size is reduced using the pooling layer, and it is placed between the convolution layers [40]. The average pooling or max pooling technique is used to reduce the number of parameters and to generate more abstract features using a hierarchical structure and a higher level of representation. Convolution and the pooling layers are followed by the flattened and fully connected layers with ReLU activation function. All the nodes can be fully connected to perform higher level reasoning. The back propagation algorithm stochastic gradient descent (SGD) is used to update the parameters and to learn new weights during training.\n\nCNN has been extensively used in estimating the tropical cyclone intensity using passive microwave imagery and the hurricane database [41]. The wind speed estimates are obtained using the linear interpolation on training images. The storm track models are developed using the maximal sustained wind speed and the spatial location information. With the available computing resources, it is difficult to train the deep CNN due to the network depth and the complexity involved in classifying the data. Graphical processing units (GPUs) are mainly used for various computer vision and image classification problems by training millions of higher resolution images [42]. We extend the past work by including the infrared satellite imagery and modifying the network architecture of CNNs.\n\nIn the proposed model, max pooling layers are removed, and batch normalization layer is added after the first 2D convolution layer. With the dropout and batch normalization, the accuracy of the model is improved when compared to the existing works. The convolution operations generate the features map and apply ReLU for non-linearity, which is represented as f(x) = max(0,x).\n\nThe convolution Layer l output at position (i,j) is represented as x ij in Equation (1), where L X L is the size of the filter, w ab is the weight of the kernel at position (p,q), the receptive field is represented as y l\u22121 (i+p)(j+q) at the position (i+p),(j+q), and B l is the bias for Layer l.\nx l ij = L\u22121 \u2211 p=0 L\u22121 \u2211 q=0 w ab y l (i+p)(j+q) + B l(1)\nUsing the hyper parameters and the size of the filters, the spatial size of the output W 0 is computed from the input W i , the Kernel size is denoted as k with stride s and padding p which is represented in Equation (2) as\nW 0 = W i \u2212 k + 2 * p s + 1(2)\nThe normalization takes place by dividing each input x i by the total samples n and is represented in Equation (3) as follows:\n1 + \u221d n \u2211 i x i 2 \u03b2(3)\nwhere \u03b1 and \u03b2 are the learning parameters and RMSProp optimizer is used to minimize the loss function and to learn new weights. The learning rate is adjusted automatically using the RMSProp optimizer. For each parameter, the optimizer chooses a varying learning rate. Additionally, for each parameter, the update is done and is mathematically represented in Equations (4) and (5).\nv t = \u03c1 v t\u22121 + (1 \u2212 \u03c1). g t 2 (4) \u2206w t = \u03b7 \u221a v t + \u2208 * g t 2 , w t + 1 = w t + \u2206w t(5)\nwhere p represents the input learning parameter, is set to a small value to prevent the gradients from blowing up, \u03b7 is the learning rate, and v t and g t denote the gradient squares with exponential average and the gradient, respectively, at time t.\n\nAdam optimizer combines together the heuristics of the RMSProp and momentum. The update in the gradients of the Adam optimizer are given below in Equations (6)-(9).\nv t = \u03b2 1 * v t \u2212 1 \u2212 (1 \u2212 \u03b2 1 ) * g t (6) s t = \u03b2 2 * s t \u2212 1 \u2212 (1 \u2212 \u03b2 2 ) * g t 2 (7) \u2206w t = \u2212\u03b7 v t \u221a s t + \u2208 * g t (8) w t+1 = w t + \u2206w t(9)\nwhere \u03b2 1 and \u03b2 2 are hyperparameters, s t is the exponential average of squares of gradients, and v t is the exponential average of gradients. The comparison between the RMSProp and Adam optimizer is analyzed for hurricane intensity estimation. The dataset description and the proposed methodology are described in detail in the subsequent subsections.\n\n\nDataset Description\n\n\nData for Hurricane Intensity Estimation\n\nThe hurricane image database consists of the collection of satellite images (HURSAT) obtained from the National Centers for Environmental Information that are used for computing intensity prediction [43]. All the images are downloaded in NetCDF format. The hurricane is located at the center of all the images present in the database. Another dataset, called the best track data, is downloaded from the HURDAT2 database available at the National Hurricane Center [44]. Hurricanes of the Atlantic and Pacific oceans with the wind speed at 6-h interval data are present in the best track dataset. HURSAT2 data contains images of all the locations in the world, and best track data contains only windspeed hurricane details of Atlantic and Pacific oceans. The images that match with the HURDAT2 database are only downloaded for all the years. All the satellite images are cropped and resized as a 50 \u00d7 50 square, which retains all the information without loss and also speeds up the data augmentation and model training process.\n\nEach satellite image contains the information such as hurricane name, data, and time of satellite image, but it does not provide the hurricane wind speed details. By searching in the best track dataset by providing the name of the hurricane, the wind speed of that particular image is retrieved. Similarly, all the wind speed of the images are obtained from the HURDAT2 database. Finally, the images are labeled with the corresponding wind speed. Data augmentation is done, since the number of images of the weak tropical cyclones is greater than the number of images of strong tropical cyclones. Data augmentation is used to balance the dataset and to improve the performance. HURDAT2 best track data contains features such as location of the tropical cyclone, maximum sustained wind speed in Knots (kts), year of occurrence, and latitude and longitude at the center.\n\n\nData for Hurricane Damage Prediction\n\nThe data used in this study are extracted from the satellite images of the Greater Houston Area after Hurricane Harvey [45]. All the satellite images are labeled as \"damaged\" or \"undamaged\" in the building damage assessment dataset. The label \"damage\" indicates the images of the affected building due to the hurricane, and the label \"no damage\" indicates the images of the non-affected buildings. The dataset has the attributes such as the path of the image, damage status, location, and latitude and longitude. For damage prediction, a total of 5000 images are used as training data for the no damage category and 5000 images are used for the damage category. For validation and testing, 1000 files for each category were chosen for prediction. Image preprocessing is done using the packages in Keras. Good quality images are retained, and the images that are fully black or with very poor quality are automatically discarded. Simple data transformations are done using APIs to convert the string data type to float.\n\n\nData for Extreme Weather Event Classification\n\nThe dataset was collected from PyImageSearch with a total of 4400 Google images of different weather events such as earthquake, hurricanes, wildfires, and floods [46]. The dataset is divided into 75% for training, 25% for testing, and 10% for validation from the training split. The dataset contains a total of 928 images for cyclones, 1350 images for earthquakes, 1073 images for floods, and 1049 images for wildfires. The minimum and maximum learning rate are 1 \u00d7 10 \u22126 and 1 \u00d7 10 \u22124 , respectively.\n\nThe prediction models used in this study are discussed in the next subsequent sections.\n\n\nMethodology\n\nThis section describes the detailed proposed methodology for identifying the different categories of hurricanes based on the intensity estimation using improved deep CNN (I-DCNN), hurricane damage prediction and severe weather events using VGG19.\n\n\nHurricane Intensity Estimation\n\nThis section provides the details of architecture used for hurricane intensity estimation. Caribbean hurricanes are the most frequently occurring extreme weather event that impacts the Caribbean. This occurs especially due to the large volume of humidity and warm air, which are measured by the power dispersion index (PDI) and Saffir-Simpson scale. The hurricane season in the Greater Caribbean region lasts from June to November, and 85% of the hurricanes occur during the period of August and September. Upon monitoring 100 tropical depressions, it is observed that six out of 10 tropical storms turns into hurricanes every year on average. The most seasonal variability always occurs at the Atlantic Basin. The catastrophic category of damage occurred during the 2017 hurricane season in the Caribbean islands. It led to a significant loss of human life and damage to property, and the hurricane damage assessment after the disaster was carried out. The expected property damage can be predicted using the synthetic hurricane tracks [47]. Using the disturbance index, the detection of droughts and hurricane damage on the Caribbean islands is accomplished. After the hurricane Maria, a strongest hurricane hit Puerto Rico; it took 2.5 months for the recovery after the disaster [48]. The coastal regions are mostly affected by the severe storms that cause damage to human lives and property. Based on the coastal properties, the average return period is ten years for the damaging storm, and 2 percent of the storm occurrence causes destructive damages. Additionally, most of the damages are due to the storm surge and storm winds [49]. The severe hurricane rainfall events that affected the Caribbean region are due to the influence of 2 \u2022 C of global warming. The vulnerability can be assessed using three factors: susceptibility, lack of coping capacities, and lack of adaptation. These factors are used to identify the most critical areas and the crucial variables that lead to vulnerability in any specific area [50]. The total number of storms that occurred is 229 over a period of 65 years. The average wind speed over 65 years is 3.52 knots.\n\nThe most popular programming language, Python, is used for the implementation of this study. Python has a collection of pre-built libraries for image processing, scientific computing, machine learning, deep learning, data analytics, and data visualization. Complex data visualizations can be made using libraries, and visual data models can be easily created, which can help the analysts to discover the hidden patterns in the data. The libraries used for data visualization are Matplotlib, Plotly, Seaborn, GgPlot, and Geoplotlib. Matplotlib is used to embed the various kinds of plots such as scatter plots, error charts, bar charts, pie charts, histograms, etc., into the applications. Plotly provides additional plots such as contour plots, which are not present in the other data visualization libraries. Seaborn, which is based on Matplotlib, is integrated with the data structures such as Numpy and Pandas. Additionally, it provides various plots and the color palette for extracting the patterns in the data. Ggplot uses a high-level application programming interface (API) for creating the plots and isdeeply integrated with Pandas. Geoplotlib is used to create the geographical maps such as dot-density maps, symbol maps, etc., and is widely used for geographical visualizations. Keras, a deep learning framework that is built on top of TensorFlow, is used for implementation to scale a large cluster of graphical processing units (GPUs). Figure 1a shows the bar graph of the month-wise occurrence of storms, and Figure 1b represents the plot of the year and the number of storm counts with respect to the average wind speed frequency for the Caribbean's large storm. Figure 1c,d and Figure 2a,b depict the location of the occurrence of the hurricane and the enlarged version of the map generated using Geopandas. The attributes that denote the points in a three-dimensional space are latitude and longitude. The latitude and longitude coordinates are transformed into points, and the transition probabilities are calculated and added to the next row to determine the occurrence of the next location of the hurricane. Figure 3 shows the plot of the year and the maximum wind speed during different time periods. The heat or density maps are used to visualize the concentration of the feature in any specified area and are useful to identify the correlations between the features. Figure 4 shows the scatter plot of storms that occurred, and Figure 5 depicts the heat map with density contour until 2020. The data density can be depicted using the heatmap, and the correlation between the features are captured. For the spatial point data, the two dimensional kernel density estimation is used.\n\nThe satellite images for the Atlantic and Pacific Oceans' hurricanes are downloaded for all the years, and the images are downloaded, to which the wind speed details are matched from the best track dataset from HURDAT2 database. The storms that do not contain the related information in the best track dataset are filtered. The satellite images from the netcdf files are extracted and stored locally. Since the hurricane is present at the center of all the images, the images are cropped at the center and matched with the maximum sustained wind speed of that hurricane. The best track dataset is filtered to search for the name, time, and date of the hurricane image. The matched images from the HURDAT2 best track data, which contains the records of Atlantic and Eastern/Central Pacific basins, are labeled with the wind speed and saved locally. The IR satellite image is retrieved from the file, the edges are removed, and the image is cropped with aside length of 50 pixels per inch (ppi). Figure 6 shows the architecture diagram for hurricane prediction by estimating the intensity of the tropical cyclone using satellite images. The cropped images are fed to the input layers, followed by a set of convolution operations and batch normalization with dropout. Data augmentation of hurricane images is done to train the data using the convolutional neural network. K-fold validation is used to validate the model, and the augmented images for each fold are generated and combined for training. If the tropical cyclone image is within the range of 50 to 70 knots, two new images are generated. On the other hand, six new images are generated if the tropical cyclone image is within the range of 75 to 100 knots, and 12 new images are generated if the range is greater than or equal to 100 knots.                 dropout. Data augmentation of hurricane images is done to train the data using the convolutional neural network. K-fold validation is used to validate the model, and the augmented images for each fold are generated and combined for training. If the tropical cyclone image is within the range of 50 to 70 knots, two new images are generated. On the other hand, six new images are generated if the tropical cyclone image is within the range of 75 to 100 knots, and 12 new images are generated if the range is greater than or equal to 100 knots. Keras Conv2D is a 2D convolution layer used to create a convolution kernel with input layers and produce the output tensors. The convolutional layers will learn from the number of filters, which is a mandatory parameter of 2D. The sequence of layers is input layers, convolution layer with activation function, pooling layers, and fully connected layers. Max pooling or average pooling is applied on the output of convolution operations to reduce the spatial dimension of the feature maps. It is used to get a small amount of translational invariance at each level. The problem associated with the pooling operation is that after applying several levels of pooling, the information about the precise positions will be lost. It is difficult to use the accurate spatial relationships between the higher-level parts of recognition. In this study, for hurricane intensity estimation, the pooling layer is replaced by a higher stride operation in the previous convolutional layer to speed up the training and reduce the computational time.\n\nIn the proposed methodology, the batch normalization layer is added after the first 2D convolution layer. The accuracy is improved by removing the max-pooling layers, and Keras Conv2D is a 2D convolution layer used to create a convolution kernel with input layers and produce the output tensors. The convolutional layers will learn from the number of filters, which is a mandatory parameter of 2D. The sequence of layers is input layers, convolution layer with activation function, pooling layers, and fully connected layers. Max pooling or average pooling is applied on the output of convolution operations to reduce the spatial dimension of the feature maps. It is used to get a small amount of translational invariance at each level. The problem associated with the pooling operation is that after applying several levels of pooling, the information about the precise positions will be lost. It is difficult to use the accurate spatial relationships between the higher-level parts of recognition. In this study, for hurricane intensity estimation, the pooling layer is replaced by a higher stride operation in the previous convolutional layer to speed up the training and reduce the computational time.\n\nIn the proposed methodology, the batch normalization layer is added after the first 2D convolution layer. The accuracy is improved by removing the max-pooling layers, and the 2D convolution layers are followed by the dropout, fully connected layers with ReLU activation, and the output layer with no activation function. Table 3 represents the different categories of hurricanes with respect to wind speed range in miles/h. To reduce the loss metric value, the optimizer learns the new weights for the model. RmsProp and Adam optimizers are used to configure the model and to modify with the new weights. The mean absolute error (MAE) values are computed by plotting the training and testing loss. The different categories of hurricanes such as tropical depressions, tropical storms, and category 1, 2, 3, and 4 are plotted.\n\nDropout and batch normalization techniques are used to address the challenges in learning a neural network. To reduce the over-fitting of data, the regularization techniques are used, and dropouts are used to modify the network architecture randomly. For better results, dropout requires fine-tuning of the hyper-parameters. For optimizing the learning of the neural network, Adam and RMSProp are used, which are the most commonly used optimizers in Keras. Adam requires more hyper tuning, and RMSProp needs minimal tuning of parameters. Dropout increases the training convergence time, whereas the batch normalization technique helps the model to converge faster and is used to improve the efficiency of the model training. The batch normalization process improves the training time by normalizing the input at each layer. In the proposed architecture, batch normalization is added only after the first 2D convolution layer. The HURDAT2 best track data contains the input features such as storm id, storm name, year, latitude and longitude at the center, and the maximum sustained wind speed. The image with the corresponding wind speed value in the database is fed as an input to the neural network. The features are trained by the first 2D convolution layer and 32 filters with the input shape of 50 \u00d7 50. Then, batch normalization normalizes the input values followed by two 2D convolution layers with 64 filters. The output of the convolutional layers is then fed to the fully connected dense layers, and the target variable is the intensity estimation of the hurricane. Based on the intensity values, the storms are grouped into different categories, and the severity of the disaster is identified by classifying the images.\n\n\nDropout and Batch Normalization\n\nIf the number of training samples in the dataset is much less, it may lead to over-fitting of data, which is a significant challenge. To improve the learning rate of the model and to avoid the over-fitting of data, dropout can be added [51]. The value of dropout for the input layer is 0.1, and for the other internal layers, the dropout can be in the range of 0.5 to 0.8. Some adjustments in the hyper-parameters such as increasing the network size, learning rate, and momentum should be made after adding the dropout. If the above parameters are increased, then they will result in large weight values. To optimize the weight values, the max-norm regularization technique can be adopted.\n\nBatch normalization improves the training speed, and the normalized values are calculated for each mini-batch. This technique increases the learning rate and is used with a lower range of values for dropout. Figure 7 shows that the input values are normalized with the mean value as zero and standard deviation value as one. The learnable parameters Gand \u03b2 are used with the normalized values. Gis the learned scaling factor, and it is initialized as 1. \u03b2 is called the learned offset factor and is initialized to 0. The batch normalization technique improves the accuracy of the CNN model by incurring a very small penalty on the training time.       \n\n\nHurricane Damage Prediction\n\nThis section describes the convolutional neural network used to classify the building images obtained from satellites as damaged or undamaged. The damage assessment of hurricanes is important to identify the number of flooded or damaged buildings. The image classification algorithm, such as the convolutional neural network, is employed to improve the accuracy of damage prediction. The satellite image dataset of Hurricane Harvey in 2017 is considered for hurricane damage prediction, which contains attributes such as the path of the image, damage status, location, latitude and longitude, and many others. The satellite imagery dataset is divided into training, testing, and validation, and classified as flooded/damage and undamaged. In this section, fine-tuning of the pre-trained VGG 19 is used, which gives more accuracy for the damage prediction than the existing VGG 16 model. To assess the damage caused by the occurrence of an extreme weather event, manual inspection of the satellite imagery data is tedious and time-consuming. Therefore, optical sensor imagery data with computer vision and deep learning models will be useful for analyzing the hurricane damage, which can produce accurate results. \n\n\nHurricane Damage Prediction\n\nThis section describes the convolutional neural network used to classify the building images obtained from satellites as damaged or undamaged. The damage assessment of hurricanes is important to identify the number of flooded or damaged buildings. The image classification algorithm, such as the convolutional neural network, is employed to improve the accuracy of damage prediction. The satellite image dataset of Hurricane Harvey in 2017 is considered for hurricane damage prediction, which contains attributes such as the path of the image, damage status, location, latitude and longitude, and many others. The satellite imagery dataset is divided into training, testing, and validation, and classified as flooded/damage and undamaged. In this section, fine-tuning of the pre-trained VGG 19 is used, which gives more accuracy for the damage prediction than the existing VGG 16 model. To assess the damage caused by the occurrence of an extreme weather event, manual inspection of the satellite imagery data is tedious and time-consuming. Therefore, optical sensor imagery data with computer vision and deep learning models will be useful for analyzing the hurricane damage, which can produce accurate results. Hence, the government and other stakeholders can take necessary actions and plan for the available resources. In the satellite imagery, the affected area will be automatically annotated as \"damage\" or \"no damage\".\n\nMachine learning and deep learning models are the main research focus in assessing the optical sensor imagery for post-disaster assessment.\n\nThe satellite imagery data after Hurricane Harvey in the Greater Houston area are considered for training, and the images are obtained from the OpenStreetMap. Figure 9 shows the architectural diagram for hurricane building damage assessment and annotation. The reference network is loaded (VGG 19), and transfer learning takes place through which fine-tuning of the network structure is modified. The new weights are learned and updated by modifying the layers to suit our input dimension. By proper tuning of hyper parameters and optimization, the training speed can be improved [52].\n\nFor damage prediction, a total of 5000 images are used as training data for the no damage category and 5000 images are used for the damage category. For validation and testing, 1000 files for each category were chosen for prediction. Many activation functions such as Relu, tanh, sigmoid, softmax, exponential, soft sign, etc., are available, and the Relu activation function is used in the CNN and max pooling layers. In the output layer, the softmax activation function is used. The two target classes to be predicted include damage or no damage. The data is split into 70% for training and 30% for testing. Data preprocessing and data transformation are undertaken, and the labeled variables in the data are converted into a format that is understood by the model for training so that the prediction accuracy can be improved after normalizing the data. The images are cropped and resized before training, and the images are filtered to obtain the higher quality dataset. The Adam optimization algorithm is used to optimize and update the weights of the network, and training is done on the specified batch size. The errors are reduced and the performance is improved after executing every batch size. The loss function used in this study is mean square error (MSE), and epochs denote the number of iterations considered for training the dataset. The predictions are done on the test data after the training process is completed. available resources. In the satellite imagery, the affected area will be automatically anno-tated as \"damage\" or \"no damage\".\n\nMachine learning and deep learning models are the main research focus in assessing the optical sensor imagery for post-disaster assessment.\n\nThe satellite imagery data after Hurricane Harvey in the Greater Houston area are considered for training, and the images are obtained from the OpenStreetMap. Figure 9 shows the architectural diagram for hurricane building damage assessment and annotation. The reference network is loaded (VGG 19), and transfer learning takes place through which fine-tuning of the network structure is modified. The new weights are learned and updated by modifying the layers to suit our input dimension. By proper tuning of hyper parameters and optimization, the training speed can be improved [52]. For damage prediction, a total of 5000 images are used as training data for the no damage category and 5000 images are used for the damage category. For validation and testing, 1000 files for each category were chosen for prediction. Many activation functions such as Relu, tanh, sigmoid, softmax, exponential, soft sign, etc., are available, and the Relu activation function is used in the CNN and max pooling layers. In the output layer, the softmax activation function is used. The two target classes to be predicted include damage or no damage. The data is split into 70% for training and 30% for testing. Data preprocessing and data transformation are undertaken, and the labeled variables in the data are converted into a format that is understood by the model for training so that the prediction accuracy can be improved after normalizing the data. The images are cropped and resized before training, and the images are filtered to obtain the higher quality dataset. The Adam optimization algorithm is used to optimize and update the weights of the network, and training is done on the specified batch size. The errors are reduced and For hurricane damage prediction, transfer learning can be done using feature extraction, where the network is considered an arbitrary feature extractor. Another way is to fine-tune the hyper parameters, where the weights are fine-tuned to recognize the new object classes. The pre-trained model ResNet can be used as a feature extraction technique, and VGG 19 layers are used for the fine-tuning methodology. VGG 19 provides better accuracy than the ResNet pre-trained model. The images with very poor quality, fully black and very cloudy, are discarded from the dataset. Random flips and rotations on varying angles are done for the augmentation of data for training and validation. VGG 19 layers contain the consequent 2D convolution layers and 2D max pooling layers. The proposed model for hurricane damage prediction contains convolution and max pooling layers, followed by fully connected layers and the output layer. In the proposed model, VGG 19 layers are used for training, and better accuracy is achieved. Using the satellite remote sensing data, the number of flooded or damaged buildings is identified.\n\n\nClassification of Severe Weather Events\n\nThis section describes the automatic detection and classification of weather events such as hurricanes, earthquakes, floods, and wildfires. A deep convolutional neural network called visual geometry group VGG 19, a successor of AlexNet, is used to classify the weather events [53]. The data are trained from the ImageNet, and the class labels in the datasets are initialized. Additionally, classification using video streams of weather events are tested and demonstrated. The minimum and maximum learning rate are specified as 1 \u00d7 10 \u22126 and 1 \u00d7 10 \u22124 , respectively. The batch size and the step size are chosen as 32 and 8. The triangular cyclic learning rate method is adopted, which provides the best learning rate using the LR (learning rate) range test. The LR range test includes the step size, maximum bound value, and the minimum bound value. After each cycle, the learning rate difference is dropped in the triangular learning rate policy. Keras learning rate finder is used to find the optimal learning rates for fine-tuning the VGG 19 CNN on the dataset. Starting at the lower bound, the training of the network takes place, and the learning rate is increased exponentially after each batch update. The training is continued until the maximum learning rate is achieved. Once the initial batch is completed, the learning rate for the next batch is increased.\n\n\nVGG 19 Architecture\n\nImages in the dataset are converted to a fixed size of (224 \u00d7 224) RGB image and are given as inputs to the VGG 19 network. The preprocessing is done by subtracting the mean RGB value from each pixel, which is calculated from the whole training data. Kernels of 3 \u00d7 3 size with a stride size of one pixel are used, and to retain the spatial resolution of the image, spatial padding is used. Additionally, Max pooling was performed over 2 \u00d7 2 pixel windows with a stride of 2. In order to introduce the non-linearity and to improve the computational time, the rectified linear unit (ReLU) is followed by the max pooling layers. Three fully connected layers with the ReLU activation function are used, and the final layer is the output layer with the Softmax function. Figure 10 shows the layered architecture of VGG 19. The optimal learning rate is used with the cyclic learning rates to obtain high accuracy, and faster convergence takes place with CLR. The resized images are added to the data list after preprocessing. One hot encoding is done to convert the labels to an array, and the data are converted to float values. VGG 19 is loaded using the pre-trained ImageNet weights followed by the creation of fully connected layers added to VGG 19. The data augmentation object is instantiated, and the training is done on the whole dataset. Good accuracy is obtained by fine-tuning the layers from 15 to 19. The proposed models are assessed using various performance metrics, which is elaborated in the next section. \n\n\nPerformance Metrics and Evaluation\n\nAll the models proposed in this study are implemented using Tensorflow, Keras, and Scikit-learn. The number of epochs run for the model is 100, with a batch size of 64. The models were trained and tested on the dependent features of satellite images and the HURDAT2 data. The data are split into 70% for training, 20% for testing, and 10% for validation. To evaluate the performance of the models, the metrics used are mean absolute error (MAE), mean absolute percentage error (MAPE), mean squared error (MSE), and root mean squared error (RMSE). In the below specified equations, the predicted output and the actual values are represented.  The proposed models are assessed using various performance metrics, which is elaborated in the next section.\n\n\nPerformance Metrics and Evaluation\n\nAll the models proposed in this study are implemented using Tensorflow, Keras, and Scikit-learn. The number of epochs run for the model is 100, with a batch size of 64. The models were trained and tested on the dependent features of satellite images and the HURDAT2 data. The data are split into 70% for training, 20% for testing, and 10% for validation. To evaluate the performance of the models, the metrics used are mean absolute error (MAE), mean absolute percentage error (MAPE), mean squared error (MSE), and root mean squared error (RMSE). In the below specified equations, the predicted output and the actual values are represented.\nMAE = 1 N N \u2211 i=1 (x i \u2212 x i )(10)Relative RMSE = x p \u2212 x t 2 n\u22121 X p (11) MSE = 1 N N \u2211 i=1 (x i \u2212 x i ) 2 (12) RMSE = 1 N N \u2211 i=1 (x i \u2212 x i ) 2 .(13)\nThe proposed models are evaluated based on the above metrics given in Equations (10)- (13). The performance metric used for classification is the confusion matrix, which describes about four categories of data, i.e., true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). The success-failure ratio is determined by the confusion matrix.\n\nWhen the speed of the wind increases and exceeds a certain threshold value, then severe weather events cause serious damages to human lives, property, and crops. The performance metrics computed for the damage prediction are precision, recall, F1 score, false alarm rate (FAR), probability of detection (POD), and critical success index (CSI), as given in Equations (14)- (18).\n\nPrecision: It is the ratio of actual positive identifications to the total actual hailstorm or hurricane and no hailstorm or no hurricane.\nPrecision = TP TP + FP(14)\nRecall: It is the ratio of the actual positive identifications to the summation of total positive and false positive values.\nRecall = TP TP + FN(15)\nF1 score: It is the measure of the test's accuracy and is calculated from the precision and recall.\nF1 Score = 2\u00b7 precision\u00b7recall precision + recall = TP TP + 1/2(FP + FN)(16)\nFor the critical success index (CSI), also called the threat score (TS), a measure of categorical forecast performance is computed as\nCSI = FP TP + FP(17)\nThe false alarm rate (FAR) is also called the probability of false detection and is computed as\nFAR = TP TP + TN + FP + FN(18)\nThe prediction results of all the models are presented in the subsequent section.\n\n\nResults and Discussions\n\n\nPrediction of Hurricane Intensity\n\nThis section depicts the results of predicting the hurricane intensity using the improved CNN model.\n\nThe accuracy of the modified CNN architecture for estimating the hurricane intensity using Infrared satellite imagery for Atlantic and Pacific regions is depicted in Figure 11a-e. Recent studies use various types of CNN models such as VGG, AlexNet, ResNet, and InceptionNet depending on the dataset and the number of convolutional layers used for predicting the intensity and classifying the damages caused after disaster. Root mean square error (RMSE) and mean squared error loss (MSE) values are computed, and the error values of the k-fold validation is represented in Table 4, where the value of k is 5. Table 4 describes about five-fold validation, and the lower RMSE values are arrived at with 7.6 knots. The batch normalization normalizes each input after the first 2D convolution layer by computing the mean and variance value. Error values are higher before removing max pooling layers. After removing the max pooling layers and increasing the stride value of the previous convolutional layer, the error values are reduced.      Table 5 shows the performance evaluation using the optimizers Adam and RMSProp. Optimizers are used to learn the new weights and the learning rates in the network and to minimize the loss. RMSProp is the gradient-based optimization technique, which is used to balance the step size through the normalization process and avoids the vanishing gradient problem. Adam optimizers are used to handle the sparse gradients and are slower to change their direction. Twelve new images are generated if the value is greater than 100 knots. The results of the Adam optimizer are slightly higher than the RMSProp, and the RMSProp optimizer provides good results with lower RMSE values. Overall, removing max pooling layers provides better results. The addition of batch normalization and dropout layers further improves the performance. The optimizer performances with different techniques are compared in Table 5. The best performance result is obtained for the combined techniques of removing the max pooling layers and adding the batch normalization with dropout. A MAE value of 6.68 knots and an RMSE value of 7.6 knots are obtained using the proposed technique.  \n\n\nHurricane Damage Prediction\n\nThis section presents the results and analysis of hurricane damage prediction after Hurricane Harvey in 2017. The satellite imagery data are divided into training, testing, and validation.\n\nIn Figure 14, training, testing, and validation split, and the labels with the damage and no damage classes with respect to latitude and longitude are plotted. The validation split is considered from the training split data. Figure 15 shows the distribution of RGB values. In the histogram, the x-axis is split into number ranges or the bins where the width of the bar represents the range of the bin and the height represents the total number of data points that lies within that range. The y-axis represents the frequency or count of the distribution of components in a particular bin. Figure 16 shows the sample images of damage/no damage classes. Data transformation takes place where the data are converted to float32 and scaling is done from an unsigned integer in the range of 0 to 255 to float32 with normalized values between 0 to 1. Image augmentation is applied by rotating through 90, 180, or 270 degrees with random flips. The augmented and the original datasets are merged together. The number of samples in the training and validation sets are doubled using image augmentation. Figure 17 shows the results after data preprocessing, where the original dataset is transformed to the RGB format. Initially, the batch size is fixed as 32, and the base model is created from the pre-trained model VGG 19. It converts 128 \u00d7 128 \u00d7 3 image to a 4 \u00d7 4 \u00d7 512 set of feature blocks. Tables 6 and 7 represent the configuration of VGG 19 layers, and the total number of trainable and non-trainable parameters are found after average pooling and dense layers. Table 8 shows the number of trainable and non-trainable parameters after fine-tuning the VGG 19 layers. Transfer learning can be achieved through feature extraction or fine-tuning of layers. Fine-tuning of the layers outperforms the feature extractor technique and provides higher accuracy. Initially, by training the network with the small learning rate, and through the previously learned convolutional layers, a new set of fully connected layers can learn the patterns. Applying fine-tuning leads to higher accuracy, the last few layers of VGG 19 from the layer 15 to Appl. Sci. 2021, 11, 4129 26 of 39 layer 19 are fine-tuned for damage prediction, and automatic annotation of the images is done using the model. The baseline model achieves about 80% accuracy before fine-tuning the layers and is represented in Figure 18. After fine-tuning, the model with 98% accuracy is achieved using VGG 19 and is represented in Figure 19. The critical success index (CSI) is 0.80 and the false alarm rate (FAR) for hurricane damage detection is 0.91. \n\n\nHurricane Damage Prediction\n\nThis section presents the results and analysis of hurricane damage prediction after Hurricane Harvey in 2017. The satellite imagery data are divided into training, testing, and validation.\n\nIn Figure 14, training, testing, and validation split, and the labels with the damage and no damage classes with respect to latitude and longitude are plotted. The validation split is considered from the training split data. Figure 15 shows the distribution of RGB               Figure 18. Accuracy graph before fine-tuning.    Figure 19. Accuracy graph after fine-tuning the layers. Table 9 shows the comparative analysis of existing models and the proposed model. Fine-tuning VGG 19 layers gives the improved accuracy, and it outperforms the other existing techniques. \n\n\nDetection and Annotation of Severe Weather Events\n\nThis section discusses the detection and annotation of different types of severe weather events using the pre-trained network. The dataset was collected from the PyimageSearch with a total of 4400 Google images of different weather events. The dataset is divided into 75% for training, 25% for testing, and 10% for validation from the training split. Classification using video streams of weather events is tested and demonstrated. Figure 20 shows the learning rate with the maximum and minimum bounds. The optimal learning rate is found between 1 \u00d7 10 \u22126 to 1 \u00d7 10 \u22124 , since the loss value drops until 1 \u00d7 10 \u22124 and starts increasing after that, which leads to over-fitting. After fine-tuning the last few layers, the accuracy of the model is increased, and 97% accuracy is achieved in detecting the severe weather events. Figure 21a shows that the validation loss follows the training loss, implying that there is very little over-fitting in the original dataset itself. Figure 21b shows the accuracy graph. Figure 22 shows the learning plot where the cyclical learning rate (CLR) callback is depicted between the optimal range of LR test. The trained model is tested over images and videos of weather events, which have similar semantic contents. The predictions queue, video streams, and the frame dimensions are initialized. The frames of the video streams are stored and resized to the fixed size of 224 \u00d7 224. The automatic annotation of the frame is done by extracting the highest probability class label for the predictions in the queue. contents. The predictions queue, video streams, and the frame dimensions are initialized. The frames of the video streams are stored and resized to the fixed size of 224 \u00d7 224. The automatic annotation of the frame is done by extracting the highest probability class label for the predictions in the queue. Table 10 shows the layer type, output shape, and the number of parameters in VGG 19 layers. The input image is processed by the convolutional layers, followed by nonlinear transforming unit ReLU and a pooling layer. The low-level features can be extracted in the deep learning models through down sampling, which can be achieved by the pooling layers. ReLU is applied to the feature maps generated by the convolutional layers. The pooling layer operates on each feature map and generates a new set of pooled feature maps. The pooling layer will reduce the size of the feature map by a factor of 2, and max pooling computes the maximum value in the set of feature maps. The total number of parameters, the number of trainable and non-trainable parameters using VGG 19, is shown in the table. Table 11 shows the performance evaluation of various metrics for classifying different types of weather events. Figure 23 shows the detection of severe weather events with the annotation of video clips in real-time. The rolling frame classification technique is used, where the rolling average forecast is computed using the standard average. The first calculated average is the simple standard average, and the forecast after the first standard average forecast is called the rolling average prediction. It denotes the process of moving the average value to the next set of n periods of frames. In the datasets collected, there is temporal and semantic similarity between the frames of the video streams and so the average rolling classification approach provides good results. Since the video datasets of different events have temporal correlations and semantic similarities, the high accuracy of 97% is obtained. Figure 23 shows the live detection and annotation of severe weather events using the VGG 19 CNN model. Ninety-seven percent accuracy is achieved after fine-tuning the last five layers.    Table 10 shows the layer type, output shape, and the number of parameters in VGG 19 layers. The input image is processed by the convolutional layers, followed by nonlinear transforming unit ReLU and a pooling layer. The low-level features can be extracted in the deep learning models through down sampling, which can be achieved by the pooling layers. ReLU is applied to the feature maps generated by the convolutional layers. The pooling layer operates on each feature map and generates a new set of pooled feature maps. The pooling layer will reduce the size of the feature map by a factor of 2, and max pooling computes the maximum value in the set of feature maps. The total number of parameters, the number of trainable and non-trainable parameters using VGG 19, is shown in the table. Table 11 shows the performance evaluation of various metrics for classifying different types of weather events. Figure 23 shows the detection of severe weather events with the annotation of video clips in real-time. The rolling frame classification technique is used, where the rolling average forecast is computed using the standard average. The first calculated average is the simple standard average, and the forecast after the first standard average forecast is called the rolling average prediction. It denotes the process of moving the average value to the next set of n periods of frames. In the datasets collected, there is temporal and semantic similarity between the frames of the video streams and so the average rolling classification approach provides good results. Since the video datasets of different events have temporal correlations and semantic similarities, the high accuracy of 97% is obtained. Figure 23 shows the live detection and annotation of severe weather events using the VGG 19 CNN model. Ninety-seven percent accuracy is achieved after fine-tuning the last five layers. \n\n\nHurricane Risk Mitigation\n\nIt is important to understand the risk imposed due to the occurrence of hurricanes and to take necessary steps to avoid significant losses. Human lives can be saved and economic losses can be reduced by implementing the policies and measures in advance and by imparting awareness to the public. The hurricane risk in the Caribbean and Central America is high. Due to the technological advancement in prediction models, the tropical depression can be predicted accurately, and an early warning can be given to the public. Countries can include the mitigation measures by considering the details such as distribution of the occurrence of hurricanes, wind speed and direction, height of the storm surges, etc. The mitigation measures adopted should consider the long-term effects. Additionally, hurricanes cause serious health hazards to people and lead to various types of diseases. The disease incurred might last for months or even years. Building codes can be used to control the building designs, methods, and materials. Formulating the mitigation strategy is an essential step in vulnerability analysis and risk assessment.  Figure 23. Severe weather events detection and classification. Figure 23. Severe weather events detection and classification.\n\n\nConclusions and Future Work\n\nIn this work, the deep learning models are developed to estimate the tropical cyclone intensity and to identify the severity of different categories of hurricane. The conclusions of this exertion are summarized as follows:\n\n\u2022 For hurricane intensity estimation, an improved deep CNN model is trained with the satellite images of hurricane along with the wind speed data. The proposed model provides lower RMSE value of 7.6% and MAE value of 6.68% after removing the max-pooling layers, and adding the batch normalization after first convolution layer.\n\n\n\u2022\n\nFor building damage assessment in context with post-disaster management, transfer learning using feature extraction of VGG 19 CNN achieves a higher accuracy of 98% than VGG 16 model, with most of the predictions as true positives.\n\n\n\u2022\n\nFor classifying the severe weather events, fine-tuning of VGG 19 achieves a higher accuracy of 97% by training the video datasets \u2022 Importance of mitigation measures against hurricane are addressed.\n\nFigure 1 .Figure 2 .\n12(a) Wind speed frequency; (b) storm events year-wise; (c) enlarged version of map; (d) occurrence of large storm. (a) Density of occurrence of storm; (b) point-wise density of occurrence of storm.\n\nFigure 1 .Figure 1 .Figure 2 .\n112(a) Wind speed frequency; (b) storm events year-wise; (c) enlarged version of map; (d) occurrence of large storm. Appl. Sci. 2021, 11, (a) Wind speed frequency; (b) storm events year-wise; (c) enlarged version of map; (d) occurrence of large storm. (a) Density of occurrence of storm; (b) point-wise density of occurrence of storm.\n\nFigure 2 .\n2(a) Density of occurrence of storm; (b) point-wise density of occurrence of storm. Appl. Sci. 2021, 11, x FOR PEER REVIEW 16 of 41\n\nFigure 3 .\n3Storms with respect to time, year, and maximum wind speed.\n\nFigure 4 .\n4Scatter plot of large storm counts.\n\nFigure 5 .\n5Density contour heat map.\n\nFigure 3 .\n3Storms with respect to time, year, and maximum wind speed.\n\nFigure 3 .\n3Storms with respect to time, year, and maximum wind speed.\n\nFigure 4 .\n4Scatter plot of large storm counts.\n\nFigure 5 .\n5Density contour heat map.\n\nFigure 4 .\n4Scatter plot of large storm counts.\n\nFigure 3 .\n3Storms with respect to time, year, and maximum wind speed.\n\nFigure 4 .\n4Scatter plot of large storm counts.\n\nFigure 5 .\n5Density contour heat map.\n\nFigure 5 .\n5Density contour heat map.\n\nFigure 6 .\n6Architecture diagram for hurricane intensity estimation using improved CNN.\n\nFigure 6 .\n6Architecture diagram for hurricane intensity estimation using improved CNN.\n\n. 2021 , 41 Figure 7\n202141711,  x FOR PEER REVIEW 19 of shows that the input values are normalized with the mean value as zero and standard deviation value as one. The learnable parameters \u0263 and \u03b2 are used with the normalized values. \u0263 is the learned scaling factor, and it is initialized as 1. \u03b2 is called the learned offset factor and is initialized to 0. The batch normalization technique improves the accuracy of the CNN model by incurring a very small penalty on the training time.\n\nFigure 7 .\n7Batch normalization with mean and variance.\n\nFigure 8 Figure 7 .\n87depicts the modified architecture for estimating the tropical cyclone intensity. By adding the batch normalization and dropout layers and removing the max pool layers in the CNN model, an improvement in the accuracy is obtained. Batch normalization with mean and variance.\n\nFigure 8\n8depicts the modified architecture for estimating the tropical cyclone intensity. By adding the batch normalization and dropout layers and removing the max pool layers in the CNN model, an improvement in the accuracy is obtained.\n\nFigure 7 .\n7Batch normalization with mean and variance.\n\nFigure 8\n8depicts the modified architecture for estimating the tropical cyclone intensity. By adding the batch normalization and dropout layers and removing the max pool layers in the CNN model, an improvement in the accuracy is obtained.\n\nFigure 8 .\n8Layered architecture for hurricane intensity estimation.\n\nFigure 8 .\n8Layered architecture for hurricane intensity estimation.\n\nFigure 9 .\n9Architecture diagram for hurricane damage classification.\n\nFigure 9 .\n9Architecture diagram for hurricane damage classification.\n\n\nAppl. Sci. 2021, 11, x FOR PEER REVIEW 22 of 41 the training is done on the whole dataset. Good accuracy is obtained by fine-tuning the layers from 15 to 19.\n\nFigure 10 .\n10Architecture of VGG 19.\n\nFigure 10 .\n10Architecture of VGG 19.\n\nFigure 11 .Figure 11 .\n1111Appl. Sci. 2021, 11, Cont. Appl. Sci. 2021, 11, (a) One-fold validation; (b) two-fold validation; (c) three-fold validation; (d) four-fold validation;(e) five-fold validation.\n\nFigure 12 .\n12Absolute errors of different hurricane categories.\n\nFigure 11 .\n11(a) One-fold validation; (b) two-fold validation; (c) three-fold validation; (d) four-fold validation; (e) five-fold validation.\n\nFigure 12 depicts\n12the absolute error values of the different categories of hurricanes based on the intensity estimation of the satellite images. The hurricane strength and the absolute error values are plotted. Totally, 248 samples are tested for tropical depressions, 355 samples for tropical storms, 55 samples for category 1, 19 samples for category 2, 13 samples for category 3, and three samples for category 4. By training the proposed model, the lower error values are achieved through better model initialization of the input by estimating the intensity values. The sample images at different knots using data augmentation and transfer learning are depicted in Figure 13a,b. Two new images are generated if the tropical cyclone intensity value is less than 75 knots. Six new images are generated if the intensity value is between 75 and 100 knots.\n\nFigure 12 .\n12Absolute errors of different hurricane categories.\n\nFigure 12 .\n12Absolute errors of different hurricane categories.\n\nFigure 12 .Figure 13 .Figure 13 .\n121313Absolute errors of different hurricane categories. Cont(a) Sample satellite images after data augmentation. (b) Generation of satellite images after data augmentation.\n\nFigure 13 .\n13(a) Sample satellite images after data augmentation. (b) Generation of satellite images after data augmentation.\n\nFigure 14 .\n14Training and validation test split.\n\nFigure 15 .\n15Histogram distribution of RGB components.\n\nFigure 14 . 41 Figure 14 .\n144114Training and validation test split. Appl. Sci. 2021, 11, x FOR PEER REVIEW 29 of Training and validation test split.\n\nFigure 15 .\n15Histogram distribution of RGB components.\n\nFigure 15 .\n15Histogram distribution of RGB components.\n\nFigure 16 .\n16Sample damage/no damage classes read in BGR.\n\nFigure 17 .\n17Information flow through filters of CNN layers.\n\nFigure 16 .Figure 16 .\n1616Sample damage/no damage classes read in BGR. Appl. Sci. 2021, 11, Sample damage/no damage classes read in BGR.\n\nFigure 17 .\n17Information flow through filters of CNN layers.\n\nFigure 17 .\n17Information flow through filters of CNN layers.\n\nFigure 18 . 41 Figure 19 .\n184119Accuracy graph before fine-tuning.Appl. Sci. 2021, 11, x FOR PEER REVIEW 33 of Accuracy graph after fine-tuning the layers.\n\nFigure 20 .\n20Minimum and maximum bound learning rate values.\n\nFigure 20 .Figure 21 .\n2021Minimum and maximum bound learning rate values. Appl. Sci. 2021, 11, (a) Epochs vs. loss plot. (b) Epochs vs. accuracy plot.\n\nFigure 21 .\n21(a) Epochs vs. loss plot. (b) Epochs vs. accuracy plot.\n\nTable 1 .\n1Hurricane classification with respect to wind range.Region \nDevelopment \nSustained Winds (km/h) \n\nTropical \n\nTropical Storm \nBetween 64 km/hour to 118 \nkm/h (74 miles/h) \n\nHurricane \n> or = 119 km/h (74 miles/h) \n\nTropical Depression \n< or = 63 km/h (39 miles/h) \n\n\n\nTable 2 .\n2Recent studies on extreme weather events prediction using various deep learning models.Ref. \nForecasting Model \nSevere Weather Type \nData Source, Data Set, Sample \nSize and Location \nAccuracy and Evaluation \nPurpose of Prediction \nLimitations \n\n[21] \nConvolutional deep \nneural network (CDNN) \nFlood disaster. \nBig data of flood disaster for a \nperiod of 10 years. \n\nCDNN outperforms \nArtificial neural networks \n(ANN) and DNN with \nhigher accuracy of 91%. \n\nDetection of flood using \nIOT, Big Data, and CDNN \nmodels along with \nHadoop Distributed File \nSystem (HDFS) map \nreduces tasks. \n\nDifficult to acquire good \nprediction results for the \nspatio-temporal variables. \n\n[22] \nDEEPSTORM \n\nIce water path detection \n(IWP) in tropics, \nmid-latitudes, and \nhurricane prediction. \n\nMicrowave radiometer \nobservations, Cloud profiling \nradar (CPR) measurements \nembedded in each radiometer \npixel for the period spanning \nbetween 2006 and 2017. Hurricane \ndata between Sep 2016 to Dec \n2016 are considered. \n\nAverage root mean square \nerror-0.27 kg/m 2 ; \ncorrelation index-0.87; \nfalse alarm rate-24%. \n\nDeep moist atmospheric \nconvection is accurate in \nthe tropics, and IWP works \nwell in the mid-latitudes. \n\nProne to over-fit, difficult \nto capture non-linear \nrelationship between input \nand output data. Does not \nproduce good results for \nlong-term prediction. \n\n[23] \nDeep learning neural \nnetwork (DLNN) \n\nFlood susceptibility \nprediction. \n\nThe high frequency tropical storm \narea in Vietnam with attributes \nsuch as slope, curvature, stream \ndensity, and rainfall are \nconsidered. \n\nDLNN outperforms \nmultilayer perceptron \nneural network and \nsupport vector machine. \nAccuracy rate-92.05% \nPositive predictive value-\n94.55%. \n\n\n\nTable 2 .\n2Cont.Ref. \nForecasting Model \nSevere Weather Type \nData Source, Data Set, Sample \nSize and Location \nAccuracy and Evaluation \nPurpose of Prediction \nLimitations \n\n[25] \nLong short term memory \n(LSTM) \n\nEarthquake impacted \nbuilding damage using \ntextual descriptions. \n\nCalifornia earthquake recorded \nbuilding damage data with 3423 \nbuildings (1552 green tagged, 1674 \nyellow tagged, 197 red tagged). \n\n\n\nTable 2 .\n2Cont.Ref. \nForecasting Model \nSevere Weather Type \nData Source, Data Set, Sample \nSize and Location \nAccuracy and Evaluation \nPurpose of Prediction \nLimitations \n\n[30] \nKnowledge-enhanced \ndeep learning model \n\nTropical cyclone \nboundary layer winds. \n\nStorm parameters such as spatial \ncoordinates, storm size, and \nintensity values. \n\nL2 norm for the noise \ncases with respect to noise \nfree simulation are 0.0055, \n0.0071, and 0.0093. \n\nTo predict the boundary \nlayer winds associated \nwith different tropical \ncyclones. Early warning \ncan be given to prevent the \ntropical cyclone hazard. \n\nTo improve the \nperformance of the \nknowledge enhanced deep \nlearning model, the \nparameters such as \npressure, wind shear, and \nfriction force can be \nconsidered. \n\n[31] \nConvolutional neural \nnetwork (CNN) \nTropical cyclone (TC). \n\nSatellite infrared brightness \ntemperature and microwave \nrain-rate data from 1097 global \nTCs between 2003-14 and \noptimized with data from 188 TCs \nbetween 2015-16. \nTesting data of 94 global TCs \nduring 2017. \n\n\n\nTable 2 .\n2Cont.Ref. \nForecasting Model \nSevere Weather Type \nData Source, Data Set, Sample \nSize and Location \nAccuracy and Evaluation \nPurpose of Prediction \nLimitations \n\n[34] \n\nSingle shot multi box \ndetector (SSD) \nalgorithm. \n\nHurricane Sandy's \npost-disaster damage \nprediction. \n\nHurricane Irma dataset from \nNHC. \n\nDetection accuracy of mF1 \nand mAP increased by \napproximately 20% and \n72% percent and the false \nalarm rate is reduced. \n\nData augmentation and \npre-training improved the \nprediction accuracy. \nGaussian noise deals with \nadaptability of complex \nimages. \n\nReal-time detection is \ncomplex to implement, \nand the model should be \npre-trained on a large \nvolume of datasets. \n\n[35] \nTyphoon wind speed \nprediction. \n\nWeather Research and \nForecasting (WRF) \nmodel and Adaptive \nNeuro-Fuzzy Inference \nSystem (ANFIS). \n\nSix-hourly NCEP reanalysis of the \n16 selected tropical cyclones from \n1985 to 2011 in South China. Sea \ntyphoon characteristics from the \nNational Oceanic and \nAtmospheric Administration \n(NOAA). \n\nANN RMSE-6.11; \nCC-0.95; ANFIS \nRMSE-3.78; CC-0.98. \n\nIntelligent neural \nnetworks outperform \nhydro-dynamic model \nbecause of the repetitive \ncharacteristics of \ntyphoons. \n\nThe model mainly \ndepends on the data \nchosen. For varying \nattributes, it is difficult to \nattain better performance. \n\n[36] \n\nConvolutional neural \nnetwork and long short \nterm memory \n(CNN-LSTM) and \nMulti-factor \nspatio-temporal \ncorrelation-CNN-LSTM \n(MFSTC-CNN-LSTM) \n\nWind speed forecasting. \n\nForty-six sites of data from the \nNational Wind Institute in Texas \nfrom January 1 to June 29, 2018. \nThe dataset contains attributes \nsuch as wind speed, wind \ndirection, temperature, dew point, \nhumidity, etc., with a 5-min \ninterval. \n\nSite name: ASPE Season: \nspring sum of squared \nerror SSE-10809.8; \nMAE-1.0652; \nRMSE-1.4445; \nstandard deviation error \nSDE-1.4444; \nindex of \nagreement(IA)-0.9977; \ndirection accuracy \n(DA)-46.9; Pearson \ncorrelation coefficient \nPCC-0.9400. \n\n\n\nTable 2 .\n2Cont.Ref. \nForecasting Model \nSevere Weather Type \nData Source, Data Set, Sample \nSize and Location \nAccuracy and Evaluation \nPurpose of Prediction \nLimitations \n\n[37] \n\nEvolutionary \ndecomposition-\nhierarchical generalized \nnormal distribution \noptimization-BiLSTM \n(ED-HGNDO-BiLSTM) \n\n\n\nTable 3 .\n3Categories of hurricane.Hurricane Category \nSustained Wind Speed Range (miles/h) \n\nTropical Depression \n<=33 \nTropical Storm \n34-64 \nCategory 1 \n74-95 \nCategory 2 \n96-110 \nCategory 3 \n111-130 \nCategory 4 \n131-155 \nCategory 5 \n>155 \n\n\n\nTable 4 .\n4RMSE values for k-fold validation.Validation Fold \nFold 1 \nFold 2 \nFold 3 \nFold 4 \nFold 5 \n\nRMSE \n17.8 knots \n17.4 knots \n8.2 knots \n8.1 knots \n7.6 knots \n\n\n\nTable 5 .\n5Performance evaluation using different optimizers.Optimizer/Technique Used \nMean Absolute Error (MAE) \nKnots \n\nRoot Mean Square Error \n(RMSE) Knots \nRelative RMSE \n\nRMSProp (no max-pooling, no batch \nnormalization, and only dropout) \n7.21 kts \n9.47 kts \n0.19 \n\nRMSProp (no max-pooling, with \nbatch normalization and dropout) \n6.68 kts \n7.6 kts \n0.17 \n\nAdam optimizer (no max-pooling, no \nbatch normalization, and only \ndropout) \n\n8.68 kts \n10.18 kts \n0.22 \n\nAdam optimizer (no max-pooling, \nwith batch normalization and \ndropout) \n\n8.52 kts \n10.04 kts \n0.20 \n\nAppl. Sci. 2021, 11, x FOR PEER REVIEW \n29 of 41 \n\n\n\nTable 6 .Table 7 .Table 8 .\n678Configuration of VGG 19 layers. Non-trainable params: 20,024,384 Trainable and non-trainable parameters. Model: \"sequential\". Total params: 20,024,384 Trainable params: 513 Non-trainable params: 20,024,384 Configuration details and number of parameters. Model: \"sequential\". Total params: 20,024,384 Trainable params: 7,079,937 Non-trainable params: 12,944,960 Appl. Sci. 2021, 11, x FOR PEER REVIEW 32 of 41Layer (Type) \nOutput Shape \nParam # \n\ninput_1 (InputLayer) \n[(None, 128, 128, 3)] \n0 \nblock1_conv1 (Conv2D) \n(None, 128, 128, 64) \n1792 \nblock1_conv2 (Conv2D) \n(None, 128, 128, 64) \n36,928 \nblock1_pool (MaxPooling2D) \n(None, 64, 64, 64) \n0 \nblock2_conv1 (Conv2D) \n(None, 64, 64, 128) \n73,856 \nblock2_conv2 (Conv2D) \n(None, 64, 64, 128) \n147,584 \nblock2_pool (MaxPooling2D) \n(None, 32, 32, 128) \n0 \nblock3_conv1 (Conv2D) \n(None, 32, 32, 256) \n295,168 \nblock3_conv2 (Conv2D) \n(None, 32, 32, 256) \n590,080 \nblock3_conv3 (Conv2D) \n(None, 32, 32, 256) \n590,080 \nblock3_conv4 (Conv2D) \n(None, 32, 32, 256) \n590,080 \nblock3_pool (MaxPooling2D) \n(None, 16, 16, 256) \n0 \nblock4_conv1 (Conv2D) \n(None, 16, 16, 512) \n1,180,160 \nblock4_conv2 (Conv2D) \n(None, 16, 16, 512) \n2,359,808 \nblock4_conv3 (Conv2D) \n(None, 16, 16, 512) \n2,359,808 \nblock4_conv4 (Conv2D) \n(None, 16, 16, 512) \n2,359,808 \nblock4_pool (MaxPooling2D) \n(None, 8, 8, 512) \n0 \nblock5_conv1 (Conv2D) \n(None, 8, 8, 512) \n2,359,808 \nblock5_conv2 (Conv2D) \n(None, 8, 8, 512) \n2,359,808 \nblock5_conv3 (Conv2D) \n(None, 8, 8, 512) \n2,359,808 \nblock5_conv4 (Conv2D) \n(None, 8, 8, 512) \n2,359,808 \nblock5_pool (MaxPooling2D) \n(None, 4, 4, 512) \n0 \n\nTotal params: 20,024,384 \nTrainable params: 0 \nModel: \"Sequential\" \nLayer (type) \nOutput Shape \nParam # \n\nVgg19 (Model) \nGlobal_averge_pooling2d \ndense (Dense) \n\n(None, 4, 4, 512) \nG1(None, 512) \n(None, 1) \n\n20,024,384 \n0 \n513 \n\nModel: \"Sequential\" \nLayer (Type) \nOutput Shape \nParam # \n\nVgg19 (Model) \nGlobal_averge_pooling2d \ndense (Dense) \n\n(None, 4, 4, 512) \nG1(None, 512) \n(None, 1) \n\n20,024,384 \n0 \n513 \n\n\n\nTable 8 .\n8Configuration details and number of parameters. Model: \"sequential\". Total params: 20,024,384 Trainable params: 7,079,937 Non-trainable params: 12,944,960Model: \"sequential\" \nLayer (Type) \nOutput Shape \nParam # \n\nVgg19 (Model) \nGlobal_averge_pooling2d \ndense (Dense) \n\n(None, 4,4,512) \nG1(None,512) \n(None,1) \n\n20024384 \n0 \n513 \n\n\nTable 9 .\n9Comparative analysis of existing models.Ref \nDisaster Type \nDataset \nModel Used \nAccuracy \n\n[54] \nHurricane \nHurricane satellite \nimages \nDeep CNN \n80.66% \n\n[55] \nFlood \nFlood video \ndataset \nBase CNN \n70% \n\n[56] \nHurricane \nAIDR dataset \nVGG-16 \n74% \n\n[57] \nHurricane \nHurricane Sandy \ndataset \n\nConvolutional Auto-\nencoders \n88.4% \n\n\n\nTable 9 .\n9Comparative analysis of existing models.Ref \nDisaster Type \nDataset \nModel Used \nAccuracy \n\n[54] \nHurricane \nHurricane satellite images \nDeep CNN \n80.66% \n\n[55] \nFlood \nFlood video dataset \nBase CNN \n70% \n\n[56] \nHurricane \nAIDR dataset \nVGG-16 \n74% \n\n[57] \nHurricane \nHurricane Sandy dataset \nConvolutional Auto-encoders \n88.4% \n\n[58] \nHurricane \nHurricane Harvey \nVGG 16 CNN \n89.5% \n\nProposed \nHurricane \nHurricane Harvey \nVGG 19 CNN (with \nfine-tuning) \n98% \n\n\n\nTable 10 .Table 11 .\n1011Layers of VGG19. Total params: 32,872,004 Trainable params: 12,847,620 Non-trainable params: 20,024,384 Performance evaluation for the classification of severe weather events using VGG 19.Layer (Type) \nOutput Shape \nParam # \n\ninput_1 (Input Layer) \n(None, 224, 224, 3) \n0 \nblock1_conv1 (Conv2D) \n(None, 224, 224, 64) \n1792 \nblock1_conv2 (Conv2D) \n(None, 224, 224, 64) \n36,928 \nblock1_pool (MaxPooling2D) \n(None, 112, 112, 64) \n0 \nblock2_conv1 (Conv2D) \n(None, 112, 112, 128) \n73,856 \nblock2_conv2 (Conv2D) \n(None, 112, 112, 128) \n147,584 \nblock2_pool (MaxPooling2D) \n(None, 56, 56, 128) \n0 \nblock3_conv1 (Conv2D) \n(None, 56, 56, 256) \n295,168 \nblock3_conv2 (Conv2D) \n(None, 56, 56, 256) \n590,080 \nblock3_conv3 (Conv2D) \n(None, 56, 56, 256) \n590,080 \nblock3_conv4 (Conv2D) \n(None, 56, 56, 256) \n590,080 \nblock3_pool (MaxPooling2D) \n(None, 28, 28, 256) \n0 \nblock4_conv1 (Conv2D) \n(None, 28, 28, 512) \n1,180,160 \nblock4_conv2 (Conv2D) \n(None, 28, 28, 512) \n2,359,808 \nblock4_conv3 (Conv2D) \n(None, 28, 28, 512) \n2,359,808 \nblock4_conv4 (Conv2D) \n(None, 28, 28, 512) \n2,359,808 \nblock4_pool (MaxPooling2D) \n(None, 14, 14, 512) \n0 \nblock5_conv1 (Conv2D) \n(None, 14, 14, 512) \n2,359,808 \nblock5_conv2 (Conv2D) \n(None, 14, 14, 512) \n2,359,808 \nblock5_conv3 (Conv2D) \n(None, 14, 14, 512) \n2,359,808 \nblock5_conv4 (Conv2D) \n(None, 14, 14, 512) \n2,359,808 \nblock5_pool (MaxPooling2D) \n(None, 7, 7, 512) \n0 \nflatten (Flatten) \n(None, 25,088) \n0 \ndense (Dense) \n(None, 512) \n12,845,568 \ndropout (Dropout) \n(None, 512) \n0 \ndense_1 (Dense) \n(None, 4) \n2052 \n\nPrecision \nRecall \nF1-Score \nSupport \n\nHurricane \n0.98 \n0.96 \n0.97 \n207 \nEarthquake \n0.96 \n0.93 \n0.95 \n364 \nFlood \n0.91 \n0.94 \n0.93 \n265 \nWildfire \n0.97 \n0.98 \n0.97 \n249 \nAccuracy \n0.96 \n1107 \n\n\nAcknowledgments:The authors would like to thank the Department of Information Technology, Sri Venkateswara College of Engineering, Chennai, India. The authors would like to acknowledge the Prince Sultan University for supporting the article processing charges (APC) for this publication. The authors also thank the Clean and Resilient Energy Systems (CARES) Laboratory, Texas A&M University, Galveston, USA, for the technical expertise provided.Conflicts of Interest:The authors declare no conflict of interest.The National Ocean and Atmospheric Administration (NOAA) and the National Hurricane Center (NHC) use different tools to predict the intensity of storms. For predicting the trajectory and strength of the hurricane, it is necessary to understand the structure of the storm and its location. Deep learning models help to accurately forecast the storm intensity at various levels, which helps the government to prevent hazards. To predict the hurricane damage prediction and the loss incurred is difficult, because it mainly depends on the storm severity and the vulnerability of the area the hurricane hits. Hurricanes also threaten the water and sewer systems, flood management, and transportation, in addition to the damages caused by the buildings. Strong hurricanes cause a high risk to public health and human lives, since within a shorter span of time, intensity changes may occur that may lead to human death and damages to property. The prediction of intensity levels using deep learning models provides an earlier warning of the storm formation. The potential future work includes adding a greater number of layers and improving the performance of the proposed model. The hurricane is located at the center of all the images, and there are various challenges related to data preprocessing, such as the removal of noise and distortion removal. It can be improved using efficient pre-processing techniques to enhance the efficiency of the prediction model. Additionally, severe weather events' impact across different countries should be controlled by designing the mitigation steps and including them in the development plan.Author Contributions: The author J.D. developed the main theme of the article and performed the work on conceptualization, data curation, formal analysis, investigation, methodology, software, and writing-original draft; the author S.G. contributed to the conceptualization, data curation, investigation, methodology, software, supervision, validation, and review and editing; R.M.E. contributed to the investigation, methodology, validation, visualization, and review and editing; U.S. contributed to the review and editing of the article. All authors have read and agreed to the published version of the manuscript.\nHurricane names: A bunch of hot air? Weather Clim. Extrem. G Smith, 10.1016/j.wace.2015.11.00612Smith, G. Hurricane names: A bunch of hot air? Weather Clim. Extrem. 2016, 12, 80-84. [CrossRef]\n\nSea of Storms: A History of Hurricanes in the Greater Caribbean from Columbus to Katrina. S B Schwartz, Princeton University PressPrinceton, NJ, USASchwartz, S.B. Sea of Storms: A History of Hurricanes in the Greater Caribbean from Columbus to Katrina; Princeton University Press: Princeton, NJ, USA, 2015.\n\nImpact assessment of coastal hazards due to future changes of tropical cyclones in the North Pacific Ocean. N Mori, T Takemi, 10.1016/j.wace.2015.09.002Weather Clim. Extrem. 11Mori, N.; Takemi, T. Impact assessment of coastal hazards due to future changes of tropical cyclones in the North Pacific Ocean. Weather Clim. Extrem. 2016, 11, 53-69. [CrossRef]\n\nMachine learning for the geosciences: Challenges and opportunities. A Karpatne, I Ebert-Uphoff, S Ravela, H Babaie, V Kumar, 10.1109/TKDE.2018.2861006IEEE Trans. Knowl. Data Eng. 31Karpatne, A.; Ebert-Uphoff, I.; Ravela, S.; Babaie, H.; Kumar, V. Machine learning for the geosciences: Challenges and opportuni- ties. IEEE Trans. Knowl. Data Eng. 2019, 31, 1544-1554. [CrossRef]\n\nWhere are the most intense thunderstorms on Earth?. E Zipser, C Liu, D Cecil, S Nesbitt, S Yorty, 10.1175/BAMS-87-8-1057Bull. Am. Meteorol. Soc. 87Zipser, E.; Liu, C.; Cecil, D.; Nesbitt, S.; Yorty, S. Where are the most intense thunderstorms on Earth? Bull. Am. Meteorol. Soc. 2006, 87, 1057-1071. [CrossRef]\n\nEnhancing understanding and improving prediction of severe weather through spatiotemporal relational learning. D J Gagne, J K Ii; Williams, R A Brown, J B Basara, 10.1007/s10994-013-5343-xMach. Learn. 95Gagne, D.J., II; Williams, J.K.; Brown, R.A.; Basara, J.B. Enhancing understanding and improving prediction of severe weather through spatiotemporal relational learning. Mach. Learn. 2014, 95, 27-50. [CrossRef]\n\nUsing Artificial Intelligence to improve real-time decision making. A Mcgovern, K L Elmore, D J Gagn, S E Ii; Haupt, C D Karstens, R Lagerquist, T Smith, J K Williams, 10.1175/BAMS-D-16-0123.1Bull. Am. Meteorol. Soc. 98McGovern, A.; Elmore, K.L.; Gagn, D.J., II; Haupt, S.E.; Karstens, C.D.; Lagerquist, R.; Smith, T.; Williams, J.K. Using Artificial Intelligence to improve real-time decision making. Bull. Am. Meteorol. Soc. 2017, 98, 2073-2090. [CrossRef]\n\n. Appl. Sci. 11Appl. Sci. 2021, 11, 4129 38 of 39\n\nThe current status of the UW-CIMSS Advanced Dvorak Technique (ADT). T Olander, C Velden, Proceedings of the 30th Conference Hurricanes Tropical Meteorology. the 30th Conference Hurricanes Tropical MeteorologyMadison, WI, USA; Boston, MA, USAAmerican Meteorological SocietyOlander, T.; Velden, C. The current status of the UW-CIMSS Advanced Dvorak Technique (ADT). In Proceedings of the 30th Conference Hurricanes Tropical Meteorology, Madison, WI, USA, 17 April 2012; American Meteorological Society: Boston, MA, USA, 2012.\n\nThe advanced Dvorak technique: Continued development of an objective scheme to estimate tropical cyclone intensity using geostationary infrared satellite imagery. Weather Forecast. T Olander, C Velden, 10.1175/WAF975.122Olander, T.; Velden, C. The advanced Dvorak technique: Continued development of an objective scheme to estimate tropical cyclone intensity using geostationary infrared satellite imagery. Weather Forecast. 2007, 22, 287-298. [CrossRef]\n\nThe advanced Dvorak technique (ADT) for estimating tropical cyclone intensity: Update and new capabilities. Weather Forecast. T Olander, C Velden, 10.1175/WAF-D-19-0007.134Olander, T.; Velden, C. The advanced Dvorak technique (ADT) for estimating tropical cyclone intensity: Update and new capabilities. Weather Forecast. 2019, 34, 905-922. [CrossRef]\n\nEstimating tropical cyclone intensity from infrared image data. Weather Forecast. M Pineros, E Ritchie, J Tyo, 10.1175/WAF-D-10-05062.126Pineros, M.; Ritchie, E.; Tyo, J. Estimating tropical cyclone intensity from infrared image data. Weather Forecast. 2011, 26, 690-698. [CrossRef]\n\nObjective measures of tropical cyclone structure and intensity change from remotely sensed infrared image data. M Pineros, E Ritchie, J Tyo, 10.1109/TGRS.2008.2000819IEEE Trans. Geosci. Remote Sens. 46Pineros, M.; Ritchie, E.; Tyo, J. Objective measures of tropical cyclone structure and intensity change from remotely sensed infrared image data. IEEE Trans. Geosci. Remote Sens. 2008, 46, 3574-3580. [CrossRef]\n\nTropical cyclone intensity estimation in the North Atlantic basin using an improved deviation angle variance technique. Weather Forecast. E Ritchie, G Valliere-Kelley, M Pi\u00f1eros, J Tyo, 10.1175/WAF-D-11-00156.127Ritchie, E.; Valliere-Kelley, G.; Pi\u00f1eros, M.; Tyo, J. Tropical cyclone intensity estimation in the North Atlantic basin using an improved deviation angle variance technique. Weather Forecast. 2012, 27, 1264-1277. [CrossRef]\n\nSatellite-derived tropical cyclone intensity in the North Pacific Ocean using the deviation-angle variance technique. E Ritchie, K Wood, O Rodr\u00edguez-Herrera, M Pineros, J Tyo, 10.1175/WAF-D-13-00133.1Weather Forecast. 29Ritchie, E.; Wood, K.; Rodr\u00edguez-Herrera, O.; Pineros, M.; Tyo, J. Satellite-derived tropical cyclone intensity in the North Pacific Ocean using the deviation-angle variance technique. Weather Forecast. 2014, 29, 505-516. [CrossRef]\n\nAn Analytical Framework for the Investigation of Tropical Cyclone Wind Characteristics over Different Measurement Conditions. L Li, Y Zhou, H Wang, H Zhou, X He, T Wu, 10.3390/app9245385Appl. Sci. 95385Li, L.; Zhou, Y.; Wang, H.; Zhou, H.; He, X.; Wu, T. An Analytical Framework for the Investigation of Tropical Cyclone Wind Characteristics over Different Measurement Conditions. Appl. Sci. 2019, 9, 5385. [CrossRef]\n\nThe changing nature of extreme weather and climate events: Risks to sustainable development. J Hay, N Mimura, 10.1080/19475701003643433Geomat. Nat. Hazards Risk. 1Hay, J.; Mimura, N. The changing nature of extreme weather and climate events: Risks to sustainable development. Geomat. Nat. Hazards Risk 2010, 1, 3-18. [CrossRef]\n\nForecasting of COVID-19 cases using deep learning models: Is it reliable and practically significant? Results Phys. 2021, 21, 103817. J Devaraj, R M Elavarasan, R Pugazhend, G M Shafiullah, S Ganesan, A K Jeysree, I A Khan, E Hossain, 10.1016/j.rinp.2021.103817PubMedDevaraj, J.; Elavarasan, R.M.; Pugazhend, R.; Shafiullah, G.M.; Ganesan, S.; Jeysree, A.K.; Khan, I.A.; Hossain, E. Forecasting of COVID-19 cases using deep learning models: Is it reliable and practically significant? Results Phys. 2021, 21, 103817. [CrossRef] [PubMed]\n\nExtreme weather disasters challenges for sustainable development: Innovating a science and policy framework for disaster-resilient and sustainable. T Raz, C R E U Liwag, A Valentine, L Andres, L T Castro, A C Cu\u00f1a, C Vinarao, T K S Raza, K Mchael, E Marsian, 10.1016/j.pdisas.2020.100066Quezon City, PhilippinesProg. Disaster Sci. 2020, 5, 100066. [CrossRefRaz, T.; Liwag, C.R.E.U.; Valentine, A.; Andres, L.; Castro, L.T.; Cu\u00f1a, A.C.; Vinarao, C.; Raza, T.K.S.; Mchael, K.; Marsian, E.; et al. Extreme weather disasters challenges for sustainable development: Innovating a science and policy framework for disaster-resilient and sustainable, Quezon City, Philippines. Prog. Disaster Sci. 2020, 5, 100066. [CrossRef]\n\nAn improved deep belief network for traffic prediction considering weather factors. X Bao, D Jiang, X Yang, H Wang, 10.1016/j.aej.2020.09.003Alex. Eng. J. 60Bao, X.; Jiang, D.; Yang, X.; Wang, H. An improved deep belief network for traffic prediction considering weather factors. Alex. Eng. J. 2021, 60, 413-420. [CrossRef]\n\nA holistic review on energy forecasting using big data and deep learning models. J Devaraj, R M Elavarasan, G M Shafiullah, T Jamal, I Khan, 10.1002/er.6679Int. J. Energy Res. Devaraj, J.; Elavarasan, R.M.; Shafiullah, G.M.; Jamal, T.; Khan, I. A holistic review on energy forecasting using big data and deep learning models. Int. J. Energy Res. 2021. [CrossRef]\n\nDetection of flood disaster system based on IoT, big data and convolutional deep neural network. M Anbarasana, B A Muthu, C B Sivaparthipan, R Sundarasekar, S Dine, 10.1016/j.comcom.2019.11.022Comput. Commun. 150Anbarasana, M.; Muthu, B.A.; Sivaparthipan, C.B.; Sundarasekar, R.; Dine, S. Detection of flood disaster system based on IoT, big data and convolutional deep neural network. Comput. Commun. 2020, 150, 150-157. [CrossRef]\n\nGlobal monitoring of deep convection using passive microwave observations. J L L Rysman, C Claud, S Dafis, 10.1016/j.atmosres.2020.105244Atmos. Res. Rysman, J.L.L.; Claud, C.; Dafis, S. Global monitoring of deep convection using passive microwave observations. Atmos. Res. 2021, 247, 105244. [CrossRef]\n\nA novel deep learning neural network approach for predicting flash flood susceptibility: A case study at a high frequency tropical storm area. D Tien, D Nhat-Duchoang, F Mart\u00ednez-\u00c1lvarez, P Thi Ngo, P Viet Hoa, T Dat Pham, P Samui, R Costacheij, 10.1016/j.scitotenv.2019.134413Sci. Total Environ. 701Tien, D.; Nhat-DucHoang, D.; Mart\u00ednez-\u00c1lvarez, F.; Thi Ngo, P.; Viet Hoa, P.; Dat Pham, T.; Samui, P.; Costacheij, R. A novel deep learning neural network approach for predicting flash flood susceptibility: A case study at a high frequency tropical storm area. Sci. Total Environ. 2020, 701, 134413. [CrossRef]\n\nA Sparse Recurrent Neural Network for Trajectory Prediction of Atlantic Hurricanes. M M Kordmahalleh, M G Sefidmazgi, A A Homaifar, Proceedings of the Genetic and Evolutionary Computation Conference (GECCO' 16). the Genetic and Evolutionary Computation Conference (GECCO' 16)Denver, CO, USAKordmahalleh, M.M.; Sefidmazgi, M.G.; Homaifar, A.A. A Sparse Recurrent Neural Network for Trajectory Prediction of Atlantic Hurricanes. In Proceedings of the Genetic and Evolutionary Computation Conference (GECCO' 16), Denver, CO, USA, 20-24 July 2016; pp. 957-964.\n\nDeep learning-based classification of earthquake-impacted buildings using textual damage descriptions. S Mangalathu, H V Burton, 10.1016/j.ijdrr.2019.101111Int. J. Disaster Risk Reduct. 36Mangalathu, S.; Burton, H.V. Deep learning-based classification of earthquake-impacted buildings using textual damage descriptions. Int. J. Disaster Risk Reduct. 2019, 36, 101111. [CrossRef]\n\nPredicting Hurricane Trajectories Using a Recurrent Neural Network. S Alemany, J Beltran, A Perez, S Ganzfried, Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19). the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)Honolulu, HI, USAAlemany, S.; Beltran, J.; Perez, A.; Ganzfried, S. Predicting Hurricane Trajectories Using a Recurrent Neural Network. In Proceed- ings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19), Honolulu, HI, USA, 27 January-1 February 2019.\n\nA hybrid CNN-LSTM model for typhoon formation forecasting. R Chen, X Wang, W Zhang, X Zhu, A Li, C Yang, 10.1007/s10707-019-00355-023Chen, R.; Wang, X.; Zhang, W.; Zhu, X.; Li, A.; Yang, C. A hybrid CNN-LSTM model for typhoon formation forecasting. Geoinformatica 2019, 23, 375-396. [CrossRef]\n\nDeep Learning-Based Damage Detection from Aerial SfM Point Clouds. M E Mohammadi, D P Watson, R L Wood, 10.3390/drones3030068368Mohammadi, M.E.; Watson, D.P.; Wood, R.L. Deep Learning-Based Damage Detection from Aerial SfM Point Clouds. Drones 2019, 3, 68. [CrossRef]\n\nForecasting different types of convective weather: A deep learning approach. K H Zhou, Y G Zheng, B Li, 10.1007/s13351-019-8162-6J. Meteorol. Res. 33Zhou, K.H.; Zheng, Y.G.; Li, B. Forecasting different types of convective weather: A deep learning approach. J. Meteorol. Res. 2019, 33, 797-809. [CrossRef]\n\nKnowledge-enhanced deep learning for simulation of tropical cyclone boundary-layer winds. R Snaiki, T Wu, 10.1016/j.jweia.2019.103983J. Wind Eng. Ind. Aerodyn. Snaiki, R.; Wu, T. Knowledge-enhanced deep learning for simulation of tropical cyclone boundary-layer winds. J. Wind Eng. Ind. Aerodyn. 2019, 194, 103983. [CrossRef]\n\nEstimating Tropical Cyclone Intensity by Satellite Imagery Utilizing Convolutional Neural Networks. Weather Forecast. B F Chen, B Chen, R L Elsberry, 10.1175/WAF-D-18-0136.134Chen, B.F.; Chen, B.; Elsberry, R.L. Estimating Tropical Cyclone Intensity by Satellite Imagery Utilizing Convolutional Neural Networks. Weather Forecast. 2019, 34, 447-465. [CrossRef]\n\nSTConvS2S: Spatiotemporal Convolutional Sequence to Sequence Network for weather forecasting. R Castro, Y M Souto, E Ogasawara, F Porto, E Bezerra, 10.1016/j.neucom.2020.09.060Neurocomputing. 426Castro, R.; Souto, Y.M.; Ogasawara, E.; Porto, F.; Bezerra, E. STConvS2S: Spatiotemporal Convolutional Sequence to Sequence Network for weather forecasting. Neurocomputing 2020, 426, 285-298. [CrossRef]\n\nDeep-Hurricane-Tracker: Tracking and Forecasting Extreme Climate Events. S Kim, H Kim, J Lee, S W Yoon, S E Kahou, K Kashinath, M Prabhat, Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV). the IEEE Winter Conference on Applications of Computer Vision (WACV)Waikoloa Village, HI, USAKim, S.; Kim, H.; Lee, J.; Yoon, S.W.; Kahou, S.E.; Kashinath, K.; Prabhat, M. Deep-Hurricane-Tracker: Tracking and Forecasting Extreme Climate Events. In Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV), Waikoloa Village, HI, USA, 7-11 January 2019.\n\n. Appl. Sci. 11Appl. Sci. 2021, 11, 4129 39 of 39\n\nBuilding Damage Detection from Post-Event Aerial Imagery Using Single Shot Multibox Detector. Y Li, W Hu, H Dong, X Zhang, 10.3390/app9061128Appl. Sci. 9Li, Y.; Hu, W.; Dong, H.; Zhang, X. Building Damage Detection from Post-Event Aerial Imagery Using Single Shot Multibox Detector. Appl. Sci. 2019, 9, 1128. [CrossRef]\n\nComparative study on typhoon's wind speed prediction by a neural networks model and a hydrodynamical model. T Haghroosta, 10.1016/j.mex.2019.03.0026Haghroosta, T. Comparative study on typhoon's wind speed prediction by a neural networks model and a hydrodynamical model. MethodsX 2019, 6, 633-640. [CrossRef]\n\nMultifactor spatio-temporal correlation model based on a combination of convolutional neural network and long short-term memory neural network for wind speed forecasting. Y Chen, S Zhang, W Zhang, J Peng, Y Cai, 10.1016/j.enconman.2019.02.018Energy Convers. Manag. 185Chen, Y.; Zhang, S.; Zhang, W.; Peng, J.; Cai, Y. Multifactor spatio-temporal correlation model based on a combination of convolutional neural network and long short-term memory neural network for wind speed forecasting. Energy Convers. Manag. 2019, 185, 783-799. [CrossRef]\n\nA deep learningbased evolutionary model for short-term wind speed forecasting: A case study of the Lillgrund offshore wind farm. M Neshat, M M Nezhad, E Abbasnejad, S Mirjalili, B L Tjernberg, A D Garcia, B Alexander, M Wagner, 10.1016/j.enconman.2021.114002Energy Convers. Manag. 2021, 236, 114002. [CrossRefNeshat, M.; Nezhad, M.M.; Abbasnejad, E.; Mirjalili, S.; Tjernberg, B.L.; Garcia, A.D.; Alexander, B.; Wagner, M. A deep learning- based evolutionary model for short-term wind speed forecasting: A case study of the Lillgrund offshore wind farm. Energy Convers. Manag. 2021, 236, 114002. [CrossRef]\n\nA robust deep learning framework for short-term wind power forecast of a full-scale wind farm using atmospheric variables. R Meka, A Alaeddini, K Bhaganagar, 10.1016/j.energy.2021.119759Meka, R.; Alaeddini, A.; Bhaganagar, K. A robust deep learning framework for short-term wind power forecast of a full-scale wind farm using atmospheric variables. Energy 2021, 221, 119759. [CrossRef]\n\nImageNet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G Hinton, Proceedings of the NIPS'12 Information Processing Systems. the NIPS'12 Information Processing SystemsLake Tahoe, NV, USA1Krizhevsky, A.; Sutskever, I.; Hinton, G. ImageNet classification with deep convolutional neural networks. In Proceedings of the NIPS'12 Information Processing Systems, Lake Tahoe, NV, USA, 3-6 December 2012; Volume 1, pp. 1097-1105.\n\nDeep learning of representations. Y Bengio, A Courville, Handbook on Neural Information Processing. Berlin, GermanySpringer49Bengio, Y.; Courville, A. Deep learning of representations. In Handbook on Neural Information Processing; Springer: Berlin, Germany, 2013; Volume 49, pp. 1-28.\n\nTropical cyclone intensity estimation using a deep convolutional neural network. R Pradhan, R Aygun, M Maskey, R Ramachandran, D Cecil, 10.1109/TIP.2017.2766358IEEE Trans. Image Process. 27PubMedPradhan, R.; Aygun, R.; Maskey, M.; Ramachandran, R.; Cecil, D. Tropical cyclone intensity estimation using a deep convolutional neural network. IEEE Trans. Image Process. 2018, 27, 692-702. [CrossRef] [PubMed]\n\nVisualizing and Understanding Convolutional Networks. M D Zeiler, R Fergus, D Fleet, T Pajdla, B Schiele, Computer Vision-ECCV. Tuytelaars, T.Zurich, SwitzerlandSpringerZeiler, M.D.; Fergus, R. Visualizing and Understanding Convolutional Networks. In Computer Vision-ECCV 2014; Fleet, D., Pajdla, T., Schiele, B., Tuytelaars, T., Eds.; Springer: Zurich, Switzerland, 2014; pp. 818-833.\n\nDataset for Hurricane Is Accessed from NHC. 20Dataset for Hurricane Is Accessed from NHC. Available online: https://www.nhc.noaa.gov/ (accessed on 20 November 2020).\n\nSatellite Imagery Data Are Accessed from HURSAT2. 20Satellite Imagery Data Are Accessed from HURSAT2. Available online: https://www.ncdc.noaa.gov/hursat/ (accessed on 20 November 2020).\n\nSatellite Dataset for Hurricane Damage Prediction Is Accessed from IEEE DataPort. 20Satellite Dataset for Hurricane Damage Prediction Is Accessed from IEEE DataPort. Available online: https://ieee-dataport.org/ keywords/hurricane (accessed on 20 November 2020).\n\nClassification of Extreme Weather Events Dataset from pySearchImage GoogleImages. 30Classification of Extreme Weather Events Dataset from pySearchImage GoogleImages. Available online: https://www. pyimagesearch.com (accessed on 30 December 2020).\n\nHurricane damage risk assessment in the Caribbean: An analysis using synthetic hurricane events and nightlight imagery. L Bertinelli, P Mohan, E Strobl, 10.1016/j.ecolecon.2016.02.004Ecol. Econ. 124Bertinelli, L.; Mohan, P.; Strobl, E. Hurricane damage risk assessment in the Caribbean: An analysis using synthetic hurricane events and nightlight imagery. Ecol. Econ. 2016, 124, 135-144. [CrossRef]\n\nHurricane damage detection on four major Caribbean islands. K M Beurs, N S Mcthompson, B C Owsley, G M Henebry, 10.1016/j.rse.2019.04.028Remote Sens. Environ. 229Beurs, K.M.; McThompson, N.S.; Owsley, B.C.; Henebry, G.M. Hurricane damage detection on four major Caribbean islands. Remote Sens. Environ. 2019, 229, 1-13. [CrossRef]\n\nA hurricane loss risk assessment of coastal properties in the caribbean: Evidence from the Bahamas. K Sealya, E Strobl, 10.1016/j.ocecoaman.2017.09.013Ocean Coast. Manag. 149Sealya, K.; Strobl, E. A hurricane loss risk assessment of coastal properties in the caribbean: Evidence from the Bahamas. Ocean Coast. Manag. 2017, 149, 42-51. [CrossRef]\n\nAssessing Socio economic Vulnerability after a Hurricane: A Combined Use of an Index-Based approach and Principal Components Analysis. N Medina, Y A Abebe, A Sanchez, Z Vojinovic, 10.3390/su12041452Sustainability 2020, 12, 1452. [CrossRefMedina, N.; Abebe, Y.A.; Sanchez, A.; Vojinovic, Z. Assessing Socio economic Vulnerability after a Hurricane: A Combined Use of an Index-Based approach and Principal Components Analysis. Sustainability 2020, 12, 1452. [CrossRef]\n\nDropout: A simple way to prevent neural networks from overfitting. N Srivastava, G Hinton, A Krizhevsky, I Sutskever, R Salakhutdinov, J. Mach. Learn. Res. 15Srivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; Salakhutdinov, R. Dropout: A simple way to prevent neural networks from overfitting. J. Mach. Learn. Res. 2014, 15, 1929-1958.\n\nSpeeding up the Hyperparameter Optimization of Deep Convolutional Neural Networks. T Hinz, N Navarro-Guerrero, S Magg, S Wermter, 10.1142/S1469026818500086Int. J. Comput. Intell. Appl. 17Hinz, T.; Navarro-Guerrero, N.; Magg, S.; Wermter, S. Speeding up the Hyperparameter Optimization of Deep Convolutional Neural Networks. Int. J. Comput. Intell. Appl. 2018, 17, 1850008. [CrossRef]\n\nTwo-stream 3-D convnet fusion for action recognition in videos with arbitrary size and length. X Wang, L Gao, P Wang, X Sun, X Liu, 10.1109/TMM.2017.2749159IEEE Trans. Multimed. 20Wang, X.; Gao, L.; Wang, P.; Sun, X.; Liu, X. Two-stream 3-D convnet fusion for action recognition in videos with arbitrary size and length. IEEE Trans. Multimed. 2018, 20, 634-644. [CrossRef]\n\nTowards operational satellite-based damage-mapping using u-net convolutional network: A case study of 2011 tohoku earthquake-tsunami. Y Bai, E Mas, S Koshimura, 10.3390/rs10101626Remote Sens. 10Bai, Y.; Mas, E.; Koshimura, S. Towards operational satellite-based damage-mapping using u-net convolutional network: A case study of 2011 tohoku earthquake-tsunami. Remote Sens. 2018, 10, 1626. [CrossRef]\n\nSatellite Image Classification Of Building Damages Using Airborne And Satellite Image Samples In A. D Duarte, F Nex, N Kerle, G Vosselman, 10.5194/isprs-annals-IV-2-89-2018Deep Learning Approach. ISPRS Ann. Photogramm. Remote Sens. Spat. Inf. Sci. 4Duarte, D.; Nex, F.; Kerle, N.; Vosselman, G. Satellite Image Classification Of Building Damages Using Airborne And Satellite Image Samples In A Deep Learning Approach. ISPRS Ann. Photogramm. Remote Sens. Spat. Inf. Sci. 2018, 4, 89-96. [CrossRef]\n\nPrototyping a Social Media Flooding Photo Screening System Based on Deep Learning. H Ning, Z Li, M E Hodgson, 10.3390/ijgi9020104ISPRS Int. J. Geo-Inf. 2020Ning, H.; Li, Z.; Hodgson, M.E. Prototyping a Social Media Flooding Photo Screening System Based on Deep Learning. ISPRS Int. J. Geo-Inf. 2020, 9, 104. [CrossRef]\n\nDamage assessment from social media imagery data during disasters. D T Nguyen, F Ofli, M Imran, P Mitra, Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and MiningSydney, AustraliaNguyen, D.T.; Ofli, F.; Imran, M.; Mitra, P. Damage assessment from social media imagery data during disasters. In Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017, Sydney, Australia, 31 July-3 August 2017; pp. 569-576.\n\nBenchmark dataset for automatic damaged building detection from post-hurricane remotely sensed imagery. S A Chen, A Escay, C Haberland, T Schneider, V Staneva, Y Choe, 10.21227/1s3n-f891IEEE Dataport. Chen, S.A.; Escay, A.; Haberland, C.; Schneider, T.; Staneva, V.; Choe, Y. Benchmark dataset for automatic damaged building detection from post-hurricane remotely sensed imagery. IEEE Dataport 2019. [CrossRef]\n", "annotations": {"author": "[{\"end\":252,\"start\":138},{\"end\":366,\"start\":253},{\"end\":492,\"start\":367},{\"end\":657,\"start\":493}]", "publisher": null, "author_last_name": "[{\"end\":154,\"start\":147},{\"end\":268,\"start\":261},{\"end\":395,\"start\":385},{\"end\":515,\"start\":504}]", "author_first_name": "[{\"end\":146,\"start\":138},{\"end\":260,\"start\":253},{\"end\":376,\"start\":367},{\"end\":384,\"start\":377},{\"end\":503,\"start\":493}]", "author_affiliation": "[{\"end\":251,\"start\":156},{\"end\":365,\"start\":270},{\"end\":491,\"start\":397},{\"end\":656,\"start\":517}]", "title": "[{\"end\":111,\"start\":1},{\"end\":768,\"start\":658}]", "venue": null, "abstract": "[{\"end\":1123,\"start\":915}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1736,\"start\":1733},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2103,\"start\":2100},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2962,\"start\":2959},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4468,\"start\":4465},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5265,\"start\":5262},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5457,\"start\":5454},{\"end\":5722,\"start\":5706},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5939,\"start\":5936},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6624,\"start\":6621},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6829,\"start\":6826},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6832,\"start\":6829},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7158,\"start\":7154},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7161,\"start\":7158},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7465,\"start\":7461},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7468,\"start\":7465},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8019,\"start\":8015},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9271,\"start\":9267},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9732,\"start\":9728},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9942,\"start\":9938},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10054,\"start\":10050},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10460,\"start\":10456},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16999,\"start\":16995},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":17199,\"start\":17197},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":18008,\"start\":18004},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":20639,\"start\":20635},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":21129,\"start\":21125},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":21801,\"start\":21797},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22327,\"start\":22323},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":25236,\"start\":25232},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":25500,\"start\":25496},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":27092,\"start\":27088},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":28203,\"start\":28199},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":29965,\"start\":29961},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":30210,\"start\":30206},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":30563,\"start\":30559},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":30949,\"start\":30945},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":41217,\"start\":41213},{\"end\":45463,\"start\":45455},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":45750,\"start\":45746},{\"end\":47750,\"start\":47742},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":48037,\"start\":48033},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":50619,\"start\":50615},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":54960,\"start\":54956},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":55619,\"start\":55615}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":70679,\"start\":70459},{\"attributes\":{\"id\":\"fig_1\"},\"end\":71046,\"start\":70680},{\"attributes\":{\"id\":\"fig_2\"},\"end\":71190,\"start\":71047},{\"attributes\":{\"id\":\"fig_3\"},\"end\":71262,\"start\":71191},{\"attributes\":{\"id\":\"fig_4\"},\"end\":71311,\"start\":71263},{\"attributes\":{\"id\":\"fig_5\"},\"end\":71350,\"start\":71312},{\"attributes\":{\"id\":\"fig_6\"},\"end\":71422,\"start\":71351},{\"attributes\":{\"id\":\"fig_7\"},\"end\":71494,\"start\":71423},{\"attributes\":{\"id\":\"fig_8\"},\"end\":71543,\"start\":71495},{\"attributes\":{\"id\":\"fig_9\"},\"end\":71582,\"start\":71544},{\"attributes\":{\"id\":\"fig_10\"},\"end\":71631,\"start\":71583},{\"attributes\":{\"id\":\"fig_11\"},\"end\":71703,\"start\":71632},{\"attributes\":{\"id\":\"fig_12\"},\"end\":71752,\"start\":71704},{\"attributes\":{\"id\":\"fig_13\"},\"end\":71791,\"start\":71753},{\"attributes\":{\"id\":\"fig_14\"},\"end\":71830,\"start\":71792},{\"attributes\":{\"id\":\"fig_15\"},\"end\":71919,\"start\":71831},{\"attributes\":{\"id\":\"fig_16\"},\"end\":72008,\"start\":71920},{\"attributes\":{\"id\":\"fig_17\"},\"end\":72497,\"start\":72009},{\"attributes\":{\"id\":\"fig_18\"},\"end\":72554,\"start\":72498},{\"attributes\":{\"id\":\"fig_19\"},\"end\":72850,\"start\":72555},{\"attributes\":{\"id\":\"fig_20\"},\"end\":73090,\"start\":72851},{\"attributes\":{\"id\":\"fig_21\"},\"end\":73147,\"start\":73091},{\"attributes\":{\"id\":\"fig_22\"},\"end\":73387,\"start\":73148},{\"attributes\":{\"id\":\"fig_23\"},\"end\":73457,\"start\":73388},{\"attributes\":{\"id\":\"fig_24\"},\"end\":73527,\"start\":73458},{\"attributes\":{\"id\":\"fig_25\"},\"end\":73598,\"start\":73528},{\"attributes\":{\"id\":\"fig_26\"},\"end\":73669,\"start\":73599},{\"attributes\":{\"id\":\"fig_27\"},\"end\":73829,\"start\":73670},{\"attributes\":{\"id\":\"fig_28\"},\"end\":73868,\"start\":73830},{\"attributes\":{\"id\":\"fig_30\"},\"end\":73907,\"start\":73869},{\"attributes\":{\"id\":\"fig_31\"},\"end\":74111,\"start\":73908},{\"attributes\":{\"id\":\"fig_32\"},\"end\":74177,\"start\":74112},{\"attributes\":{\"id\":\"fig_33\"},\"end\":74321,\"start\":74178},{\"attributes\":{\"id\":\"fig_34\"},\"end\":75180,\"start\":74322},{\"attributes\":{\"id\":\"fig_35\"},\"end\":75246,\"start\":75181},{\"attributes\":{\"id\":\"fig_36\"},\"end\":75312,\"start\":75247},{\"attributes\":{\"id\":\"fig_37\"},\"end\":75521,\"start\":75313},{\"attributes\":{\"id\":\"fig_38\"},\"end\":75649,\"start\":75522},{\"attributes\":{\"id\":\"fig_39\"},\"end\":75700,\"start\":75650},{\"attributes\":{\"id\":\"fig_40\"},\"end\":75757,\"start\":75701},{\"attributes\":{\"id\":\"fig_41\"},\"end\":75908,\"start\":75758},{\"attributes\":{\"id\":\"fig_42\"},\"end\":75965,\"start\":75909},{\"attributes\":{\"id\":\"fig_43\"},\"end\":76022,\"start\":75966},{\"attributes\":{\"id\":\"fig_44\"},\"end\":76082,\"start\":76023},{\"attributes\":{\"id\":\"fig_45\"},\"end\":76145,\"start\":76083},{\"attributes\":{\"id\":\"fig_46\"},\"end\":76284,\"start\":76146},{\"attributes\":{\"id\":\"fig_47\"},\"end\":76347,\"start\":76285},{\"attributes\":{\"id\":\"fig_48\"},\"end\":76410,\"start\":76348},{\"attributes\":{\"id\":\"fig_49\"},\"end\":76568,\"start\":76411},{\"attributes\":{\"id\":\"fig_51\"},\"end\":76631,\"start\":76569},{\"attributes\":{\"id\":\"fig_52\"},\"end\":76784,\"start\":76632},{\"attributes\":{\"id\":\"fig_53\"},\"end\":76855,\"start\":76785},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":77133,\"start\":76856},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":78884,\"start\":77134},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":79301,\"start\":78885},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":80357,\"start\":79302},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":82361,\"start\":80358},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":82661,\"start\":82362},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":82907,\"start\":82662},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":83076,\"start\":82908},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":83700,\"start\":83077},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":85747,\"start\":83701},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":86089,\"start\":85748},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":86437,\"start\":86090},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":86912,\"start\":86438},{\"attributes\":{\"id\":\"tab_17\",\"type\":\"table\"},\"end\":88678,\"start\":86913}]", "paragraph": "[{\"end\":10461,\"start\":1139},{\"end\":10976,\"start\":10463},{\"end\":11448,\"start\":10998},{\"end\":12563,\"start\":11481},{\"end\":14920,\"start\":12565},{\"end\":15365,\"start\":14922},{\"end\":15443,\"start\":15367},{\"end\":15526,\"start\":15445},{\"end\":15658,\"start\":15532},{\"end\":15824,\"start\":15664},{\"end\":15968,\"start\":15830},{\"end\":16137,\"start\":15970},{\"end\":16143,\"start\":16139},{\"end\":16224,\"start\":16145},{\"end\":16250,\"start\":16226},{\"end\":16338,\"start\":16252},{\"end\":16457,\"start\":16340},{\"end\":16687,\"start\":16459},{\"end\":16809,\"start\":16689},{\"end\":17063,\"start\":16811},{\"end\":17206,\"start\":17065},{\"end\":17331,\"start\":17208},{\"end\":17438,\"start\":17333},{\"end\":17444,\"start\":17440},{\"end\":17591,\"start\":17446},{\"end\":17673,\"start\":17593},{\"end\":17844,\"start\":17675},{\"end\":18108,\"start\":17846},{\"end\":18189,\"start\":18110},{\"end\":18256,\"start\":18191},{\"end\":18452,\"start\":18258},{\"end\":18636,\"start\":18454},{\"end\":18741,\"start\":18638},{\"end\":18831,\"start\":18743},{\"end\":19200,\"start\":19015},{\"end\":19332,\"start\":19202},{\"end\":19382,\"start\":19334},{\"end\":19415,\"start\":19384},{\"end\":19563,\"start\":19417},{\"end\":19660,\"start\":19565},{\"end\":19811,\"start\":19662},{\"end\":20030,\"start\":19813},{\"end\":20348,\"start\":20046},{\"end\":21661,\"start\":20375},{\"end\":22444,\"start\":21663},{\"end\":22822,\"start\":22446},{\"end\":23120,\"start\":22824},{\"end\":23402,\"start\":23179},{\"end\":23560,\"start\":23434},{\"end\":23964,\"start\":23584},{\"end\":24303,\"start\":24053},{\"end\":24469,\"start\":24305},{\"end\":24967,\"start\":24614},{\"end\":26058,\"start\":25033},{\"end\":26928,\"start\":26060},{\"end\":27987,\"start\":26969},{\"end\":28538,\"start\":28037},{\"end\":28627,\"start\":28540},{\"end\":28889,\"start\":28643},{\"end\":31077,\"start\":28924},{\"end\":33782,\"start\":31079},{\"end\":37176,\"start\":33784},{\"end\":38383,\"start\":37178},{\"end\":39209,\"start\":38385},{\"end\":40941,\"start\":39211},{\"end\":41666,\"start\":40977},{\"end\":42320,\"start\":41668},{\"end\":43565,\"start\":42352},{\"end\":45023,\"start\":43597},{\"end\":45164,\"start\":45025},{\"end\":45751,\"start\":45166},{\"end\":47310,\"start\":45753},{\"end\":47451,\"start\":47312},{\"end\":50295,\"start\":47453},{\"end\":51706,\"start\":50339},{\"end\":53248,\"start\":51730},{\"end\":54037,\"start\":53287},{\"end\":54716,\"start\":54076},{\"end\":55241,\"start\":54870},{\"end\":55620,\"start\":55243},{\"end\":55760,\"start\":55622},{\"end\":55912,\"start\":55788},{\"end\":56036,\"start\":55937},{\"end\":56247,\"start\":56114},{\"end\":56364,\"start\":56269},{\"end\":56477,\"start\":56396},{\"end\":56641,\"start\":56541},{\"end\":58836,\"start\":56643},{\"end\":59056,\"start\":58868},{\"end\":61663,\"start\":59058},{\"end\":61883,\"start\":61695},{\"end\":62456,\"start\":61885},{\"end\":68152,\"start\":62510},{\"end\":69435,\"start\":68182},{\"end\":69689,\"start\":69467},{\"end\":70018,\"start\":69691},{\"end\":70254,\"start\":70024},{\"end\":70458,\"start\":70260}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":19014,\"start\":18832},{\"attributes\":{\"id\":\"formula_1\"},\"end\":23178,\"start\":23121},{\"attributes\":{\"id\":\"formula_2\"},\"end\":23433,\"start\":23403},{\"attributes\":{\"id\":\"formula_3\"},\"end\":23583,\"start\":23561},{\"attributes\":{\"id\":\"formula_4\"},\"end\":24052,\"start\":23965},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24613,\"start\":24470},{\"attributes\":{\"id\":\"formula_6\"},\"end\":54751,\"start\":54717},{\"attributes\":{\"id\":\"formula_7\"},\"end\":54869,\"start\":54751},{\"attributes\":{\"id\":\"formula_8\"},\"end\":55787,\"start\":55761},{\"attributes\":{\"id\":\"formula_9\"},\"end\":55936,\"start\":55913},{\"attributes\":{\"id\":\"formula_10\"},\"end\":56113,\"start\":56037},{\"attributes\":{\"id\":\"formula_11\"},\"end\":56268,\"start\":56248},{\"attributes\":{\"id\":\"formula_12\"},\"end\":56395,\"start\":56365}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":2971,\"start\":2964},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":11447,\"start\":11440},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":11527,\"start\":11520},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":38713,\"start\":38706},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":57222,\"start\":57215},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":57258,\"start\":57251},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":57688,\"start\":57681},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":58581,\"start\":58574},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":60626,\"start\":60619},{\"attributes\":{\"ref_id\":\"tab_15\"},\"end\":62276,\"start\":62269},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":64373,\"start\":64365},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":65164,\"start\":65156},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":66268,\"start\":66260},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":67059,\"start\":67051}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1137,\"start\":1125},{\"attributes\":{\"n\":\"2.\"},\"end\":10996,\"start\":10979},{\"end\":11479,\"start\":11451},{\"end\":15530,\"start\":15529},{\"end\":15662,\"start\":15661},{\"end\":15828,\"start\":15827},{\"attributes\":{\"n\":\"3.\"},\"end\":20044,\"start\":20033},{\"attributes\":{\"n\":\"3.1.\"},\"end\":20373,\"start\":20351},{\"attributes\":{\"n\":\"3.2.\"},\"end\":24989,\"start\":24970},{\"attributes\":{\"n\":\"3.2.1.\"},\"end\":25031,\"start\":24992},{\"attributes\":{\"n\":\"3.2.2.\"},\"end\":26967,\"start\":26931},{\"attributes\":{\"n\":\"3.2.3.\"},\"end\":28035,\"start\":27990},{\"attributes\":{\"n\":\"3.3.\"},\"end\":28641,\"start\":28630},{\"attributes\":{\"n\":\"3.3.1.\"},\"end\":28922,\"start\":28892},{\"attributes\":{\"n\":\"3.3.2.\"},\"end\":40975,\"start\":40944},{\"attributes\":{\"n\":\"3.3.3.\"},\"end\":42350,\"start\":42323},{\"attributes\":{\"n\":\"3.3.3.\"},\"end\":43595,\"start\":43568},{\"attributes\":{\"n\":\"3.3.4.\"},\"end\":50337,\"start\":50298},{\"attributes\":{\"n\":\"3.4.\"},\"end\":51728,\"start\":51709},{\"attributes\":{\"n\":\"4.\"},\"end\":53285,\"start\":53251},{\"attributes\":{\"n\":\"4.\"},\"end\":54074,\"start\":54040},{\"attributes\":{\"n\":\"5.\"},\"end\":56503,\"start\":56480},{\"attributes\":{\"n\":\"5.1.\"},\"end\":56539,\"start\":56506},{\"attributes\":{\"n\":\"5.2.\"},\"end\":58866,\"start\":58839},{\"attributes\":{\"n\":\"5.2.\"},\"end\":61693,\"start\":61666},{\"attributes\":{\"n\":\"5.3.\"},\"end\":62508,\"start\":62459},{\"attributes\":{\"n\":\"5.4.\"},\"end\":68180,\"start\":68155},{\"attributes\":{\"n\":\"6.\"},\"end\":69465,\"start\":69438},{\"end\":70022,\"start\":70021},{\"end\":70258,\"start\":70257},{\"end\":70480,\"start\":70460},{\"end\":70711,\"start\":70681},{\"end\":71058,\"start\":71048},{\"end\":71202,\"start\":71192},{\"end\":71274,\"start\":71264},{\"end\":71323,\"start\":71313},{\"end\":71362,\"start\":71352},{\"end\":71434,\"start\":71424},{\"end\":71506,\"start\":71496},{\"end\":71555,\"start\":71545},{\"end\":71594,\"start\":71584},{\"end\":71643,\"start\":71633},{\"end\":71715,\"start\":71705},{\"end\":71764,\"start\":71754},{\"end\":71803,\"start\":71793},{\"end\":71842,\"start\":71832},{\"end\":71931,\"start\":71921},{\"end\":72030,\"start\":72010},{\"end\":72509,\"start\":72499},{\"end\":72575,\"start\":72556},{\"end\":72860,\"start\":72852},{\"end\":73102,\"start\":73092},{\"end\":73157,\"start\":73149},{\"end\":73399,\"start\":73389},{\"end\":73469,\"start\":73459},{\"end\":73539,\"start\":73529},{\"end\":73610,\"start\":73600},{\"end\":73842,\"start\":73831},{\"end\":73881,\"start\":73870},{\"end\":73931,\"start\":73909},{\"end\":74124,\"start\":74113},{\"end\":74190,\"start\":74179},{\"end\":74340,\"start\":74323},{\"end\":75193,\"start\":75182},{\"end\":75259,\"start\":75248},{\"end\":75347,\"start\":75314},{\"end\":75534,\"start\":75523},{\"end\":75662,\"start\":75651},{\"end\":75713,\"start\":75702},{\"end\":75785,\"start\":75759},{\"end\":75921,\"start\":75910},{\"end\":75978,\"start\":75967},{\"end\":76035,\"start\":76024},{\"end\":76095,\"start\":76084},{\"end\":76169,\"start\":76147},{\"end\":76297,\"start\":76286},{\"end\":76360,\"start\":76349},{\"end\":76438,\"start\":76412},{\"end\":76581,\"start\":76570},{\"end\":76655,\"start\":76633},{\"end\":76797,\"start\":76786},{\"end\":76866,\"start\":76857},{\"end\":77144,\"start\":77135},{\"end\":78895,\"start\":78886},{\"end\":79312,\"start\":79303},{\"end\":80368,\"start\":80359},{\"end\":82372,\"start\":82363},{\"end\":82672,\"start\":82663},{\"end\":82918,\"start\":82909},{\"end\":83087,\"start\":83078},{\"end\":83729,\"start\":83702},{\"end\":85758,\"start\":85749},{\"end\":86100,\"start\":86091},{\"end\":86448,\"start\":86439},{\"end\":86934,\"start\":86914}]", "table": "[{\"end\":77133,\"start\":76920},{\"end\":78884,\"start\":77233},{\"end\":79301,\"start\":78902},{\"end\":80357,\"start\":79319},{\"end\":82361,\"start\":80375},{\"end\":82661,\"start\":82379},{\"end\":82907,\"start\":82698},{\"end\":83076,\"start\":82954},{\"end\":83700,\"start\":83139},{\"end\":85747,\"start\":84141},{\"end\":86089,\"start\":85914},{\"end\":86437,\"start\":86142},{\"end\":86912,\"start\":86490},{\"end\":88678,\"start\":87127}]", "figure_caption": "[{\"end\":70679,\"start\":70483},{\"end\":71046,\"start\":70715},{\"end\":71190,\"start\":71060},{\"end\":71262,\"start\":71204},{\"end\":71311,\"start\":71276},{\"end\":71350,\"start\":71325},{\"end\":71422,\"start\":71364},{\"end\":71494,\"start\":71436},{\"end\":71543,\"start\":71508},{\"end\":71582,\"start\":71557},{\"end\":71631,\"start\":71596},{\"end\":71703,\"start\":71645},{\"end\":71752,\"start\":71717},{\"end\":71791,\"start\":71766},{\"end\":71830,\"start\":71805},{\"end\":71919,\"start\":71844},{\"end\":72008,\"start\":71933},{\"end\":72497,\"start\":72038},{\"end\":72554,\"start\":72511},{\"end\":72850,\"start\":72578},{\"end\":73090,\"start\":72862},{\"end\":73147,\"start\":73104},{\"end\":73387,\"start\":73159},{\"end\":73457,\"start\":73401},{\"end\":73527,\"start\":73471},{\"end\":73598,\"start\":73541},{\"end\":73669,\"start\":73612},{\"end\":73829,\"start\":73672},{\"end\":73868,\"start\":73845},{\"end\":73907,\"start\":73884},{\"end\":74111,\"start\":73936},{\"end\":74177,\"start\":74127},{\"end\":74321,\"start\":74193},{\"end\":75180,\"start\":74343},{\"end\":75246,\"start\":75196},{\"end\":75312,\"start\":75262},{\"end\":75521,\"start\":75354},{\"end\":75649,\"start\":75537},{\"end\":75700,\"start\":75665},{\"end\":75757,\"start\":75716},{\"end\":75908,\"start\":75792},{\"end\":75965,\"start\":75924},{\"end\":76022,\"start\":75981},{\"end\":76082,\"start\":76038},{\"end\":76145,\"start\":76098},{\"end\":76284,\"start\":76174},{\"end\":76347,\"start\":76300},{\"end\":76410,\"start\":76363},{\"end\":76568,\"start\":76445},{\"end\":76631,\"start\":76584},{\"end\":76784,\"start\":76660},{\"end\":76855,\"start\":76800},{\"end\":76920,\"start\":76868},{\"end\":77233,\"start\":77146},{\"end\":78902,\"start\":78897},{\"end\":79319,\"start\":79314},{\"end\":80375,\"start\":80370},{\"end\":82379,\"start\":82374},{\"end\":82698,\"start\":82674},{\"end\":82954,\"start\":82920},{\"end\":83139,\"start\":83089},{\"end\":84141,\"start\":83733},{\"end\":85914,\"start\":85760},{\"end\":86142,\"start\":86102},{\"end\":86490,\"start\":86450},{\"end\":87127,\"start\":86939}]", "figure_ref": "[{\"end\":32537,\"start\":32528},{\"end\":32611,\"start\":32602},{\"end\":32766,\"start\":32757},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":32782,\"start\":32773},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":33215,\"start\":33207},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":33477,\"start\":33469},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":33538,\"start\":33530},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":34786,\"start\":34778},{\"attributes\":{\"ref_id\":\"fig_18\"},\"end\":41884,\"start\":41876},{\"attributes\":{\"ref_id\":\"fig_25\"},\"end\":45333,\"start\":45325},{\"attributes\":{\"ref_id\":\"fig_25\"},\"end\":47620,\"start\":47612},{\"attributes\":{\"ref_id\":\"fig_28\"},\"end\":52506,\"start\":52497},{\"attributes\":{\"ref_id\":\"fig_33\"},\"end\":56819,\"start\":56809},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":59070,\"start\":59061},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":59292,\"start\":59283},{\"attributes\":{\"ref_id\":\"fig_15\"},\"end\":59655,\"start\":59646},{\"attributes\":{\"ref_id\":\"fig_18\"},\"end\":60160,\"start\":60151},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":61444,\"start\":61435},{\"attributes\":{\"ref_id\":\"fig_25\"},\"end\":61549,\"start\":61540},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":61897,\"start\":61888},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":62119,\"start\":62110},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":62173,\"start\":62164},{\"attributes\":{\"ref_id\":\"fig_25\"},\"end\":62222,\"start\":62213},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":62951,\"start\":62942},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":63345,\"start\":63335},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":63494,\"start\":63484},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":63530,\"start\":63521},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":65277,\"start\":65268},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":66081,\"start\":66072},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":67172,\"start\":67163},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":67976,\"start\":67967},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":69319,\"start\":69310},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":69382,\"start\":69373}]", "bib_author_first_name": "[{\"end\":91498,\"start\":91497},{\"end\":91723,\"start\":91722},{\"end\":91725,\"start\":91724},{\"end\":92049,\"start\":92048},{\"end\":92057,\"start\":92056},{\"end\":92365,\"start\":92364},{\"end\":92377,\"start\":92376},{\"end\":92393,\"start\":92392},{\"end\":92403,\"start\":92402},{\"end\":92413,\"start\":92412},{\"end\":92728,\"start\":92727},{\"end\":92738,\"start\":92737},{\"end\":92745,\"start\":92744},{\"end\":92754,\"start\":92753},{\"end\":92765,\"start\":92764},{\"end\":93098,\"start\":93097},{\"end\":93100,\"start\":93099},{\"end\":93109,\"start\":93108},{\"end\":93111,\"start\":93110},{\"end\":93127,\"start\":93126},{\"end\":93129,\"start\":93128},{\"end\":93138,\"start\":93137},{\"end\":93140,\"start\":93139},{\"end\":93470,\"start\":93469},{\"end\":93482,\"start\":93481},{\"end\":93484,\"start\":93483},{\"end\":93494,\"start\":93493},{\"end\":93496,\"start\":93495},{\"end\":93504,\"start\":93503},{\"end\":93506,\"start\":93505},{\"end\":93519,\"start\":93518},{\"end\":93521,\"start\":93520},{\"end\":93533,\"start\":93532},{\"end\":93547,\"start\":93546},{\"end\":93556,\"start\":93555},{\"end\":93558,\"start\":93557},{\"end\":93981,\"start\":93980},{\"end\":93992,\"start\":93991},{\"end\":94619,\"start\":94618},{\"end\":94630,\"start\":94629},{\"end\":95020,\"start\":95019},{\"end\":95031,\"start\":95030},{\"end\":95329,\"start\":95328},{\"end\":95340,\"start\":95339},{\"end\":95351,\"start\":95350},{\"end\":95643,\"start\":95642},{\"end\":95654,\"start\":95653},{\"end\":95665,\"start\":95664},{\"end\":96082,\"start\":96081},{\"end\":96093,\"start\":96092},{\"end\":96112,\"start\":96111},{\"end\":96123,\"start\":96122},{\"end\":96500,\"start\":96499},{\"end\":96511,\"start\":96510},{\"end\":96519,\"start\":96518},{\"end\":96540,\"start\":96539},{\"end\":96551,\"start\":96550},{\"end\":96962,\"start\":96961},{\"end\":96968,\"start\":96967},{\"end\":96976,\"start\":96975},{\"end\":96984,\"start\":96983},{\"end\":96992,\"start\":96991},{\"end\":96998,\"start\":96997},{\"end\":97348,\"start\":97347},{\"end\":97355,\"start\":97354},{\"end\":97718,\"start\":97717},{\"end\":97729,\"start\":97728},{\"end\":97731,\"start\":97730},{\"end\":97745,\"start\":97744},{\"end\":97758,\"start\":97757},{\"end\":97760,\"start\":97759},{\"end\":97774,\"start\":97773},{\"end\":97785,\"start\":97784},{\"end\":97787,\"start\":97786},{\"end\":97798,\"start\":97797},{\"end\":97800,\"start\":97799},{\"end\":97808,\"start\":97807},{\"end\":98270,\"start\":98269},{\"end\":98277,\"start\":98276},{\"end\":98283,\"start\":98278},{\"end\":98292,\"start\":98291},{\"end\":98305,\"start\":98304},{\"end\":98315,\"start\":98314},{\"end\":98317,\"start\":98316},{\"end\":98327,\"start\":98326},{\"end\":98329,\"start\":98328},{\"end\":98337,\"start\":98336},{\"end\":98348,\"start\":98347},{\"end\":98352,\"start\":98349},{\"end\":98360,\"start\":98359},{\"end\":98370,\"start\":98369},{\"end\":98924,\"start\":98923},{\"end\":98931,\"start\":98930},{\"end\":98940,\"start\":98939},{\"end\":98948,\"start\":98947},{\"end\":99246,\"start\":99245},{\"end\":99257,\"start\":99256},{\"end\":99259,\"start\":99258},{\"end\":99273,\"start\":99272},{\"end\":99275,\"start\":99274},{\"end\":99289,\"start\":99288},{\"end\":99298,\"start\":99297},{\"end\":99626,\"start\":99625},{\"end\":99640,\"start\":99639},{\"end\":99642,\"start\":99641},{\"end\":99651,\"start\":99650},{\"end\":99653,\"start\":99652},{\"end\":99670,\"start\":99669},{\"end\":99686,\"start\":99685},{\"end\":100038,\"start\":100037},{\"end\":100042,\"start\":100039},{\"end\":100052,\"start\":100051},{\"end\":100061,\"start\":100060},{\"end\":100410,\"start\":100409},{\"end\":100418,\"start\":100417},{\"end\":100435,\"start\":100434},{\"end\":100455,\"start\":100454},{\"end\":100466,\"start\":100465},{\"end\":100478,\"start\":100477},{\"end\":100490,\"start\":100489},{\"end\":100499,\"start\":100498},{\"end\":100963,\"start\":100962},{\"end\":100965,\"start\":100964},{\"end\":100981,\"start\":100980},{\"end\":100983,\"start\":100982},{\"end\":100997,\"start\":100996},{\"end\":100999,\"start\":100998},{\"end\":101540,\"start\":101539},{\"end\":101554,\"start\":101553},{\"end\":101556,\"start\":101555},{\"end\":101885,\"start\":101884},{\"end\":101896,\"start\":101895},{\"end\":101907,\"start\":101906},{\"end\":101916,\"start\":101915},{\"end\":102418,\"start\":102417},{\"end\":102426,\"start\":102425},{\"end\":102434,\"start\":102433},{\"end\":102443,\"start\":102442},{\"end\":102450,\"start\":102449},{\"end\":102456,\"start\":102455},{\"end\":102721,\"start\":102720},{\"end\":102723,\"start\":102722},{\"end\":102736,\"start\":102735},{\"end\":102738,\"start\":102737},{\"end\":102748,\"start\":102747},{\"end\":102750,\"start\":102749},{\"end\":103000,\"start\":102999},{\"end\":103002,\"start\":103001},{\"end\":103010,\"start\":103009},{\"end\":103012,\"start\":103011},{\"end\":103021,\"start\":103020},{\"end\":103320,\"start\":103319},{\"end\":103330,\"start\":103329},{\"end\":103675,\"start\":103674},{\"end\":103677,\"start\":103676},{\"end\":103685,\"start\":103684},{\"end\":103693,\"start\":103692},{\"end\":103695,\"start\":103694},{\"end\":104012,\"start\":104011},{\"end\":104022,\"start\":104021},{\"end\":104024,\"start\":104023},{\"end\":104033,\"start\":104032},{\"end\":104046,\"start\":104045},{\"end\":104055,\"start\":104054},{\"end\":104390,\"start\":104389},{\"end\":104397,\"start\":104396},{\"end\":104404,\"start\":104403},{\"end\":104411,\"start\":104410},{\"end\":104413,\"start\":104412},{\"end\":104421,\"start\":104420},{\"end\":104423,\"start\":104422},{\"end\":104432,\"start\":104431},{\"end\":104445,\"start\":104444},{\"end\":105066,\"start\":105065},{\"end\":105072,\"start\":105071},{\"end\":105078,\"start\":105077},{\"end\":105086,\"start\":105085},{\"end\":105401,\"start\":105400},{\"end\":105774,\"start\":105773},{\"end\":105782,\"start\":105781},{\"end\":105791,\"start\":105790},{\"end\":105800,\"start\":105799},{\"end\":105808,\"start\":105807},{\"end\":106276,\"start\":106275},{\"end\":106286,\"start\":106285},{\"end\":106288,\"start\":106287},{\"end\":106298,\"start\":106297},{\"end\":106312,\"start\":106311},{\"end\":106325,\"start\":106324},{\"end\":106327,\"start\":106326},{\"end\":106340,\"start\":106339},{\"end\":106342,\"start\":106341},{\"end\":106352,\"start\":106351},{\"end\":106365,\"start\":106364},{\"end\":106878,\"start\":106877},{\"end\":106886,\"start\":106885},{\"end\":106899,\"start\":106898},{\"end\":107207,\"start\":107206},{\"end\":107221,\"start\":107220},{\"end\":107234,\"start\":107233},{\"end\":107634,\"start\":107633},{\"end\":107644,\"start\":107643},{\"end\":107967,\"start\":107966},{\"end\":107978,\"start\":107977},{\"end\":107987,\"start\":107986},{\"end\":107997,\"start\":107996},{\"end\":108013,\"start\":108012},{\"end\":108347,\"start\":108346},{\"end\":108349,\"start\":108348},{\"end\":108359,\"start\":108358},{\"end\":108369,\"start\":108368},{\"end\":108378,\"start\":108377},{\"end\":108388,\"start\":108387},{\"end\":109665,\"start\":109664},{\"end\":109679,\"start\":109678},{\"end\":109688,\"start\":109687},{\"end\":110005,\"start\":110004},{\"end\":110007,\"start\":110006},{\"end\":110016,\"start\":110015},{\"end\":110018,\"start\":110017},{\"end\":110032,\"start\":110031},{\"end\":110034,\"start\":110033},{\"end\":110044,\"start\":110043},{\"end\":110046,\"start\":110045},{\"end\":110377,\"start\":110376},{\"end\":110387,\"start\":110386},{\"end\":110759,\"start\":110758},{\"end\":110769,\"start\":110768},{\"end\":110771,\"start\":110770},{\"end\":110780,\"start\":110779},{\"end\":110791,\"start\":110790},{\"end\":111159,\"start\":111158},{\"end\":111173,\"start\":111172},{\"end\":111183,\"start\":111182},{\"end\":111197,\"start\":111196},{\"end\":111210,\"start\":111209},{\"end\":111520,\"start\":111519},{\"end\":111528,\"start\":111527},{\"end\":111548,\"start\":111547},{\"end\":111556,\"start\":111555},{\"end\":111917,\"start\":111916},{\"end\":111925,\"start\":111924},{\"end\":111932,\"start\":111931},{\"end\":111940,\"start\":111939},{\"end\":111947,\"start\":111946},{\"end\":112330,\"start\":112329},{\"end\":112337,\"start\":112336},{\"end\":112344,\"start\":112343},{\"end\":112697,\"start\":112696},{\"end\":112707,\"start\":112706},{\"end\":112714,\"start\":112713},{\"end\":112723,\"start\":112722},{\"end\":113178,\"start\":113177},{\"end\":113186,\"start\":113185},{\"end\":113192,\"start\":113191},{\"end\":113194,\"start\":113193},{\"end\":113482,\"start\":113481},{\"end\":113484,\"start\":113483},{\"end\":113494,\"start\":113493},{\"end\":113502,\"start\":113501},{\"end\":113511,\"start\":113510},{\"end\":114130,\"start\":114129},{\"end\":114132,\"start\":114131},{\"end\":114140,\"start\":114139},{\"end\":114149,\"start\":114148},{\"end\":114162,\"start\":114161},{\"end\":114175,\"start\":114174},{\"end\":114186,\"start\":114185}]", "bib_author_last_name": "[{\"end\":91504,\"start\":91499},{\"end\":91734,\"start\":91726},{\"end\":92054,\"start\":92050},{\"end\":92064,\"start\":92058},{\"end\":92374,\"start\":92366},{\"end\":92390,\"start\":92378},{\"end\":92400,\"start\":92394},{\"end\":92410,\"start\":92404},{\"end\":92419,\"start\":92414},{\"end\":92735,\"start\":92729},{\"end\":92742,\"start\":92739},{\"end\":92751,\"start\":92746},{\"end\":92762,\"start\":92755},{\"end\":92771,\"start\":92766},{\"end\":93106,\"start\":93101},{\"end\":93124,\"start\":93112},{\"end\":93135,\"start\":93130},{\"end\":93147,\"start\":93141},{\"end\":93479,\"start\":93471},{\"end\":93491,\"start\":93485},{\"end\":93501,\"start\":93497},{\"end\":93516,\"start\":93507},{\"end\":93530,\"start\":93522},{\"end\":93544,\"start\":93534},{\"end\":93553,\"start\":93548},{\"end\":93567,\"start\":93559},{\"end\":93989,\"start\":93982},{\"end\":93999,\"start\":93993},{\"end\":94627,\"start\":94620},{\"end\":94637,\"start\":94631},{\"end\":95028,\"start\":95021},{\"end\":95038,\"start\":95032},{\"end\":95337,\"start\":95330},{\"end\":95348,\"start\":95341},{\"end\":95355,\"start\":95352},{\"end\":95651,\"start\":95644},{\"end\":95662,\"start\":95655},{\"end\":95669,\"start\":95666},{\"end\":96090,\"start\":96083},{\"end\":96109,\"start\":96094},{\"end\":96120,\"start\":96113},{\"end\":96127,\"start\":96124},{\"end\":96508,\"start\":96501},{\"end\":96516,\"start\":96512},{\"end\":96537,\"start\":96520},{\"end\":96548,\"start\":96541},{\"end\":96555,\"start\":96552},{\"end\":96965,\"start\":96963},{\"end\":96973,\"start\":96969},{\"end\":96981,\"start\":96977},{\"end\":96989,\"start\":96985},{\"end\":96995,\"start\":96993},{\"end\":97001,\"start\":96999},{\"end\":97352,\"start\":97349},{\"end\":97362,\"start\":97356},{\"end\":97726,\"start\":97719},{\"end\":97742,\"start\":97732},{\"end\":97755,\"start\":97746},{\"end\":97771,\"start\":97761},{\"end\":97782,\"start\":97775},{\"end\":97795,\"start\":97788},{\"end\":97805,\"start\":97801},{\"end\":97816,\"start\":97809},{\"end\":98274,\"start\":98271},{\"end\":98289,\"start\":98284},{\"end\":98302,\"start\":98293},{\"end\":98312,\"start\":98306},{\"end\":98324,\"start\":98318},{\"end\":98334,\"start\":98330},{\"end\":98345,\"start\":98338},{\"end\":98357,\"start\":98353},{\"end\":98367,\"start\":98361},{\"end\":98378,\"start\":98371},{\"end\":98928,\"start\":98925},{\"end\":98937,\"start\":98932},{\"end\":98945,\"start\":98941},{\"end\":98953,\"start\":98949},{\"end\":99254,\"start\":99247},{\"end\":99270,\"start\":99260},{\"end\":99286,\"start\":99276},{\"end\":99295,\"start\":99290},{\"end\":99303,\"start\":99299},{\"end\":99637,\"start\":99627},{\"end\":99648,\"start\":99643},{\"end\":99667,\"start\":99654},{\"end\":99683,\"start\":99671},{\"end\":99691,\"start\":99687},{\"end\":100049,\"start\":100043},{\"end\":100058,\"start\":100053},{\"end\":100067,\"start\":100062},{\"end\":100415,\"start\":100411},{\"end\":100432,\"start\":100419},{\"end\":100452,\"start\":100436},{\"end\":100463,\"start\":100456},{\"end\":100475,\"start\":100467},{\"end\":100487,\"start\":100479},{\"end\":100496,\"start\":100491},{\"end\":100510,\"start\":100500},{\"end\":100978,\"start\":100966},{\"end\":100994,\"start\":100984},{\"end\":101008,\"start\":101000},{\"end\":101551,\"start\":101541},{\"end\":101563,\"start\":101557},{\"end\":101893,\"start\":101886},{\"end\":101904,\"start\":101897},{\"end\":101913,\"start\":101908},{\"end\":101926,\"start\":101917},{\"end\":102423,\"start\":102419},{\"end\":102431,\"start\":102427},{\"end\":102440,\"start\":102435},{\"end\":102447,\"start\":102444},{\"end\":102453,\"start\":102451},{\"end\":102461,\"start\":102457},{\"end\":102733,\"start\":102724},{\"end\":102745,\"start\":102739},{\"end\":102755,\"start\":102751},{\"end\":103007,\"start\":103003},{\"end\":103018,\"start\":103013},{\"end\":103024,\"start\":103022},{\"end\":103327,\"start\":103321},{\"end\":103333,\"start\":103331},{\"end\":103682,\"start\":103678},{\"end\":103690,\"start\":103686},{\"end\":103704,\"start\":103696},{\"end\":104019,\"start\":104013},{\"end\":104030,\"start\":104025},{\"end\":104043,\"start\":104034},{\"end\":104052,\"start\":104047},{\"end\":104063,\"start\":104056},{\"end\":104394,\"start\":104391},{\"end\":104401,\"start\":104398},{\"end\":104408,\"start\":104405},{\"end\":104418,\"start\":104414},{\"end\":104429,\"start\":104424},{\"end\":104442,\"start\":104433},{\"end\":104453,\"start\":104446},{\"end\":105069,\"start\":105067},{\"end\":105075,\"start\":105073},{\"end\":105083,\"start\":105079},{\"end\":105092,\"start\":105087},{\"end\":105412,\"start\":105402},{\"end\":105779,\"start\":105775},{\"end\":105788,\"start\":105783},{\"end\":105797,\"start\":105792},{\"end\":105805,\"start\":105801},{\"end\":105812,\"start\":105809},{\"end\":106283,\"start\":106277},{\"end\":106295,\"start\":106289},{\"end\":106309,\"start\":106299},{\"end\":106322,\"start\":106313},{\"end\":106337,\"start\":106328},{\"end\":106349,\"start\":106343},{\"end\":106362,\"start\":106353},{\"end\":106372,\"start\":106366},{\"end\":106883,\"start\":106879},{\"end\":106896,\"start\":106887},{\"end\":106910,\"start\":106900},{\"end\":107218,\"start\":107208},{\"end\":107231,\"start\":107222},{\"end\":107241,\"start\":107235},{\"end\":107641,\"start\":107635},{\"end\":107654,\"start\":107645},{\"end\":107975,\"start\":107968},{\"end\":107984,\"start\":107979},{\"end\":107994,\"start\":107988},{\"end\":108010,\"start\":107998},{\"end\":108019,\"start\":108014},{\"end\":108356,\"start\":108350},{\"end\":108366,\"start\":108360},{\"end\":108375,\"start\":108370},{\"end\":108385,\"start\":108379},{\"end\":108396,\"start\":108389},{\"end\":109676,\"start\":109666},{\"end\":109685,\"start\":109680},{\"end\":109695,\"start\":109689},{\"end\":110013,\"start\":110008},{\"end\":110029,\"start\":110019},{\"end\":110041,\"start\":110035},{\"end\":110054,\"start\":110047},{\"end\":110384,\"start\":110378},{\"end\":110394,\"start\":110388},{\"end\":110766,\"start\":110760},{\"end\":110777,\"start\":110772},{\"end\":110788,\"start\":110781},{\"end\":110801,\"start\":110792},{\"end\":111170,\"start\":111160},{\"end\":111180,\"start\":111174},{\"end\":111194,\"start\":111184},{\"end\":111207,\"start\":111198},{\"end\":111224,\"start\":111211},{\"end\":111525,\"start\":111521},{\"end\":111545,\"start\":111529},{\"end\":111553,\"start\":111549},{\"end\":111564,\"start\":111557},{\"end\":111922,\"start\":111918},{\"end\":111929,\"start\":111926},{\"end\":111937,\"start\":111933},{\"end\":111944,\"start\":111941},{\"end\":111951,\"start\":111948},{\"end\":112334,\"start\":112331},{\"end\":112341,\"start\":112338},{\"end\":112354,\"start\":112345},{\"end\":112704,\"start\":112698},{\"end\":112711,\"start\":112708},{\"end\":112720,\"start\":112715},{\"end\":112733,\"start\":112724},{\"end\":113183,\"start\":113179},{\"end\":113189,\"start\":113187},{\"end\":113202,\"start\":113195},{\"end\":113491,\"start\":113485},{\"end\":113499,\"start\":113495},{\"end\":113508,\"start\":113503},{\"end\":113517,\"start\":113512},{\"end\":114137,\"start\":114133},{\"end\":114146,\"start\":114141},{\"end\":114159,\"start\":114150},{\"end\":114172,\"start\":114163},{\"end\":114183,\"start\":114176},{\"end\":114191,\"start\":114187}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.1016/j.wace.2015.11.006\",\"id\":\"b0\"},\"end\":91630,\"start\":91438},{\"attributes\":{\"id\":\"b1\"},\"end\":91938,\"start\":91632},{\"attributes\":{\"doi\":\"10.1016/j.wace.2015.09.002\",\"id\":\"b2\",\"matched_paper_id\":128990339},\"end\":92294,\"start\":91940},{\"attributes\":{\"doi\":\"10.1109/TKDE.2018.2861006\",\"id\":\"b3\",\"matched_paper_id\":42476116},\"end\":92673,\"start\":92296},{\"attributes\":{\"doi\":\"10.1175/BAMS-87-8-1057\",\"id\":\"b4\",\"matched_paper_id\":51044775},\"end\":92984,\"start\":92675},{\"attributes\":{\"doi\":\"10.1007/s10994-013-5343-x\",\"id\":\"b5\",\"matched_paper_id\":1889131},\"end\":93399,\"start\":92986},{\"attributes\":{\"doi\":\"10.1175/BAMS-D-16-0123.1\",\"id\":\"b6\"},\"end\":93859,\"start\":93401},{\"attributes\":{\"id\":\"b7\"},\"end\":93910,\"start\":93861},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":65217039},\"end\":94435,\"start\":93912},{\"attributes\":{\"doi\":\"10.1175/WAF975.1\",\"id\":\"b9\"},\"end\":94891,\"start\":94437},{\"attributes\":{\"doi\":\"10.1175/WAF-D-19-0007.1\",\"id\":\"b10\"},\"end\":95244,\"start\":94893},{\"attributes\":{\"doi\":\"10.1175/WAF-D-10-05062.1\",\"id\":\"b11\"},\"end\":95528,\"start\":95246},{\"attributes\":{\"doi\":\"10.1109/TGRS.2008.2000819\",\"id\":\"b12\",\"matched_paper_id\":9213593},\"end\":95941,\"start\":95530},{\"attributes\":{\"doi\":\"10.1175/WAF-D-11-00156.1\",\"id\":\"b13\"},\"end\":96379,\"start\":95943},{\"attributes\":{\"doi\":\"10.1175/WAF-D-13-00133.1\",\"id\":\"b14\",\"matched_paper_id\":17696166},\"end\":96833,\"start\":96381},{\"attributes\":{\"doi\":\"10.3390/app9245385\",\"id\":\"b15\",\"matched_paper_id\":213843536},\"end\":97252,\"start\":96835},{\"attributes\":{\"doi\":\"10.1080/19475701003643433\",\"id\":\"b16\",\"matched_paper_id\":140580743},\"end\":97581,\"start\":97254},{\"attributes\":{\"doi\":\"10.1016/j.rinp.2021.103817\",\"id\":\"b17\"},\"end\":98119,\"start\":97583},{\"attributes\":{\"doi\":\"10.1016/j.pdisas.2020.100066\",\"id\":\"b18\"},\"end\":98837,\"start\":98121},{\"attributes\":{\"doi\":\"10.1016/j.aej.2020.09.003\",\"id\":\"b19\",\"matched_paper_id\":224973617},\"end\":99162,\"start\":98839},{\"attributes\":{\"doi\":\"10.1002/er.6679\",\"id\":\"b20\",\"matched_paper_id\":234884750},\"end\":99526,\"start\":99164},{\"attributes\":{\"doi\":\"10.1016/j.comcom.2019.11.022\",\"id\":\"b21\",\"matched_paper_id\":211080667},\"end\":99960,\"start\":99528},{\"attributes\":{\"doi\":\"10.1016/j.atmosres.2020.105244\",\"id\":\"b22\",\"matched_paper_id\":224993950},\"end\":100264,\"start\":99962},{\"attributes\":{\"doi\":\"10.1016/j.scitotenv.2019.134413\",\"id\":\"b23\",\"matched_paper_id\":203130534},\"end\":100876,\"start\":100266},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":18070585},\"end\":101434,\"start\":100878},{\"attributes\":{\"doi\":\"10.1016/j.ijdrr.2019.101111\",\"id\":\"b25\",\"matched_paper_id\":88466770},\"end\":101814,\"start\":101436},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":4895519},\"end\":102356,\"start\":101816},{\"attributes\":{\"doi\":\"10.1007/s10707-019-00355-0\",\"id\":\"b27\"},\"end\":102651,\"start\":102358},{\"attributes\":{\"doi\":\"10.3390/drones3030068\",\"id\":\"b28\"},\"end\":102920,\"start\":102653},{\"attributes\":{\"doi\":\"10.1007/s13351-019-8162-6\",\"id\":\"b29\",\"matched_paper_id\":209069508},\"end\":103227,\"start\":102922},{\"attributes\":{\"doi\":\"10.1016/j.jweia.2019.103983\",\"id\":\"b30\",\"matched_paper_id\":204184861},\"end\":103554,\"start\":103229},{\"attributes\":{\"doi\":\"10.1175/WAF-D-18-0136.1\",\"id\":\"b31\"},\"end\":103915,\"start\":103556},{\"attributes\":{\"doi\":\"10.1016/j.neucom.2020.09.060\",\"id\":\"b32\",\"matched_paper_id\":208527264},\"end\":104314,\"start\":103917},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":71152001},\"end\":104918,\"start\":104316},{\"attributes\":{\"id\":\"b34\"},\"end\":104969,\"start\":104920},{\"attributes\":{\"doi\":\"10.3390/app9061128\",\"id\":\"b35\",\"matched_paper_id\":116383595},\"end\":105290,\"start\":104971},{\"attributes\":{\"doi\":\"10.1016/j.mex.2019.03.002\",\"id\":\"b36\"},\"end\":105600,\"start\":105292},{\"attributes\":{\"doi\":\"10.1016/j.enconman.2019.02.018\",\"id\":\"b37\",\"matched_paper_id\":104462373},\"end\":106144,\"start\":105602},{\"attributes\":{\"doi\":\"10.1016/j.enconman.2021.114002\",\"id\":\"b38\"},\"end\":106752,\"start\":106146},{\"attributes\":{\"doi\":\"10.1016/j.energy.2021.119759\",\"id\":\"b39\"},\"end\":107139,\"start\":106754},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":195908774},\"end\":107597,\"start\":107141},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":29888510},\"end\":107883,\"start\":107599},{\"attributes\":{\"doi\":\"10.1109/TIP.2017.2766358\",\"id\":\"b42\",\"matched_paper_id\":7113724},\"end\":108290,\"start\":107885},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":3960646},\"end\":108677,\"start\":108292},{\"attributes\":{\"id\":\"b44\"},\"end\":108844,\"start\":108679},{\"attributes\":{\"id\":\"b45\"},\"end\":109031,\"start\":108846},{\"attributes\":{\"id\":\"b46\"},\"end\":109294,\"start\":109033},{\"attributes\":{\"id\":\"b47\"},\"end\":109542,\"start\":109296},{\"attributes\":{\"doi\":\"10.1016/j.ecolecon.2016.02.004\",\"id\":\"b48\",\"matched_paper_id\":134700965},\"end\":109942,\"start\":109544},{\"attributes\":{\"doi\":\"10.1016/j.rse.2019.04.028\",\"id\":\"b49\",\"matched_paper_id\":164624570},\"end\":110274,\"start\":109944},{\"attributes\":{\"doi\":\"10.1016/j.ocecoaman.2017.09.013\",\"id\":\"b50\",\"matched_paper_id\":158994173},\"end\":110621,\"start\":110276},{\"attributes\":{\"doi\":\"10.3390/su12041452\",\"id\":\"b51\"},\"end\":111089,\"start\":110623},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":6844431},\"end\":111434,\"start\":111091},{\"attributes\":{\"doi\":\"10.1142/S1469026818500086\",\"id\":\"b53\",\"matched_paper_id\":49884298},\"end\":111819,\"start\":111436},{\"attributes\":{\"doi\":\"10.1109/TMM.2017.2749159\",\"id\":\"b54\",\"matched_paper_id\":3438487},\"end\":112193,\"start\":111821},{\"attributes\":{\"doi\":\"10.3390/rs10101626\",\"id\":\"b55\",\"matched_paper_id\":53945894},\"end\":112594,\"start\":112195},{\"attributes\":{\"doi\":\"10.5194/isprs-annals-IV-2-89-2018\",\"id\":\"b56\",\"matched_paper_id\":55605542},\"end\":113092,\"start\":112596},{\"attributes\":{\"doi\":\"10.3390/ijgi9020104\",\"id\":\"b57\",\"matched_paper_id\":203688015},\"end\":113412,\"start\":113094},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":925123},\"end\":114023,\"start\":113414},{\"attributes\":{\"doi\":\"10.21227/1s3n-f891\",\"id\":\"b59\",\"matched_paper_id\":55217329},\"end\":114435,\"start\":114025}]", "bib_title": "[{\"end\":92046,\"start\":91940},{\"end\":92362,\"start\":92296},{\"end\":92725,\"start\":92675},{\"end\":93095,\"start\":92986},{\"end\":93467,\"start\":93401},{\"end\":93978,\"start\":93912},{\"end\":95640,\"start\":95530},{\"end\":96497,\"start\":96381},{\"end\":96959,\"start\":96835},{\"end\":97345,\"start\":97254},{\"end\":98921,\"start\":98839},{\"end\":99243,\"start\":99164},{\"end\":99623,\"start\":99528},{\"end\":100035,\"start\":99962},{\"end\":100407,\"start\":100266},{\"end\":100960,\"start\":100878},{\"end\":101537,\"start\":101436},{\"end\":101882,\"start\":101816},{\"end\":102997,\"start\":102922},{\"end\":103317,\"start\":103229},{\"end\":104009,\"start\":103917},{\"end\":104387,\"start\":104316},{\"end\":105063,\"start\":104971},{\"end\":105771,\"start\":105602},{\"end\":107204,\"start\":107141},{\"end\":107631,\"start\":107599},{\"end\":107964,\"start\":107885},{\"end\":108344,\"start\":108292},{\"end\":109662,\"start\":109544},{\"end\":110002,\"start\":109944},{\"end\":110374,\"start\":110276},{\"end\":111156,\"start\":111091},{\"end\":111517,\"start\":111436},{\"end\":111914,\"start\":111821},{\"end\":112327,\"start\":112195},{\"end\":112694,\"start\":112596},{\"end\":113175,\"start\":113094},{\"end\":113479,\"start\":113414},{\"end\":114127,\"start\":114025}]", "bib_author": "[{\"end\":91506,\"start\":91497},{\"end\":91736,\"start\":91722},{\"end\":92056,\"start\":92048},{\"end\":92066,\"start\":92056},{\"end\":92376,\"start\":92364},{\"end\":92392,\"start\":92376},{\"end\":92402,\"start\":92392},{\"end\":92412,\"start\":92402},{\"end\":92421,\"start\":92412},{\"end\":92737,\"start\":92727},{\"end\":92744,\"start\":92737},{\"end\":92753,\"start\":92744},{\"end\":92764,\"start\":92753},{\"end\":92773,\"start\":92764},{\"end\":93108,\"start\":93097},{\"end\":93126,\"start\":93108},{\"end\":93137,\"start\":93126},{\"end\":93149,\"start\":93137},{\"end\":93481,\"start\":93469},{\"end\":93493,\"start\":93481},{\"end\":93503,\"start\":93493},{\"end\":93518,\"start\":93503},{\"end\":93532,\"start\":93518},{\"end\":93546,\"start\":93532},{\"end\":93555,\"start\":93546},{\"end\":93569,\"start\":93555},{\"end\":93991,\"start\":93980},{\"end\":94001,\"start\":93991},{\"end\":94629,\"start\":94618},{\"end\":94639,\"start\":94629},{\"end\":95030,\"start\":95019},{\"end\":95040,\"start\":95030},{\"end\":95339,\"start\":95328},{\"end\":95350,\"start\":95339},{\"end\":95357,\"start\":95350},{\"end\":95653,\"start\":95642},{\"end\":95664,\"start\":95653},{\"end\":95671,\"start\":95664},{\"end\":96092,\"start\":96081},{\"end\":96111,\"start\":96092},{\"end\":96122,\"start\":96111},{\"end\":96129,\"start\":96122},{\"end\":96510,\"start\":96499},{\"end\":96518,\"start\":96510},{\"end\":96539,\"start\":96518},{\"end\":96550,\"start\":96539},{\"end\":96557,\"start\":96550},{\"end\":96967,\"start\":96961},{\"end\":96975,\"start\":96967},{\"end\":96983,\"start\":96975},{\"end\":96991,\"start\":96983},{\"end\":96997,\"start\":96991},{\"end\":97003,\"start\":96997},{\"end\":97354,\"start\":97347},{\"end\":97364,\"start\":97354},{\"end\":97728,\"start\":97717},{\"end\":97744,\"start\":97728},{\"end\":97757,\"start\":97744},{\"end\":97773,\"start\":97757},{\"end\":97784,\"start\":97773},{\"end\":97797,\"start\":97784},{\"end\":97807,\"start\":97797},{\"end\":97818,\"start\":97807},{\"end\":98276,\"start\":98269},{\"end\":98291,\"start\":98276},{\"end\":98304,\"start\":98291},{\"end\":98314,\"start\":98304},{\"end\":98326,\"start\":98314},{\"end\":98336,\"start\":98326},{\"end\":98347,\"start\":98336},{\"end\":98359,\"start\":98347},{\"end\":98369,\"start\":98359},{\"end\":98380,\"start\":98369},{\"end\":98930,\"start\":98923},{\"end\":98939,\"start\":98930},{\"end\":98947,\"start\":98939},{\"end\":98955,\"start\":98947},{\"end\":99256,\"start\":99245},{\"end\":99272,\"start\":99256},{\"end\":99288,\"start\":99272},{\"end\":99297,\"start\":99288},{\"end\":99305,\"start\":99297},{\"end\":99639,\"start\":99625},{\"end\":99650,\"start\":99639},{\"end\":99669,\"start\":99650},{\"end\":99685,\"start\":99669},{\"end\":99693,\"start\":99685},{\"end\":100051,\"start\":100037},{\"end\":100060,\"start\":100051},{\"end\":100069,\"start\":100060},{\"end\":100417,\"start\":100409},{\"end\":100434,\"start\":100417},{\"end\":100454,\"start\":100434},{\"end\":100465,\"start\":100454},{\"end\":100477,\"start\":100465},{\"end\":100489,\"start\":100477},{\"end\":100498,\"start\":100489},{\"end\":100512,\"start\":100498},{\"end\":100980,\"start\":100962},{\"end\":100996,\"start\":100980},{\"end\":101010,\"start\":100996},{\"end\":101553,\"start\":101539},{\"end\":101565,\"start\":101553},{\"end\":101895,\"start\":101884},{\"end\":101906,\"start\":101895},{\"end\":101915,\"start\":101906},{\"end\":101928,\"start\":101915},{\"end\":102425,\"start\":102417},{\"end\":102433,\"start\":102425},{\"end\":102442,\"start\":102433},{\"end\":102449,\"start\":102442},{\"end\":102455,\"start\":102449},{\"end\":102463,\"start\":102455},{\"end\":102735,\"start\":102720},{\"end\":102747,\"start\":102735},{\"end\":102757,\"start\":102747},{\"end\":103009,\"start\":102999},{\"end\":103020,\"start\":103009},{\"end\":103026,\"start\":103020},{\"end\":103329,\"start\":103319},{\"end\":103335,\"start\":103329},{\"end\":103684,\"start\":103674},{\"end\":103692,\"start\":103684},{\"end\":103706,\"start\":103692},{\"end\":104021,\"start\":104011},{\"end\":104032,\"start\":104021},{\"end\":104045,\"start\":104032},{\"end\":104054,\"start\":104045},{\"end\":104065,\"start\":104054},{\"end\":104396,\"start\":104389},{\"end\":104403,\"start\":104396},{\"end\":104410,\"start\":104403},{\"end\":104420,\"start\":104410},{\"end\":104431,\"start\":104420},{\"end\":104444,\"start\":104431},{\"end\":104455,\"start\":104444},{\"end\":105071,\"start\":105065},{\"end\":105077,\"start\":105071},{\"end\":105085,\"start\":105077},{\"end\":105094,\"start\":105085},{\"end\":105414,\"start\":105400},{\"end\":105781,\"start\":105773},{\"end\":105790,\"start\":105781},{\"end\":105799,\"start\":105790},{\"end\":105807,\"start\":105799},{\"end\":105814,\"start\":105807},{\"end\":106285,\"start\":106275},{\"end\":106297,\"start\":106285},{\"end\":106311,\"start\":106297},{\"end\":106324,\"start\":106311},{\"end\":106339,\"start\":106324},{\"end\":106351,\"start\":106339},{\"end\":106364,\"start\":106351},{\"end\":106374,\"start\":106364},{\"end\":106885,\"start\":106877},{\"end\":106898,\"start\":106885},{\"end\":106912,\"start\":106898},{\"end\":107220,\"start\":107206},{\"end\":107233,\"start\":107220},{\"end\":107243,\"start\":107233},{\"end\":107643,\"start\":107633},{\"end\":107656,\"start\":107643},{\"end\":107977,\"start\":107966},{\"end\":107986,\"start\":107977},{\"end\":107996,\"start\":107986},{\"end\":108012,\"start\":107996},{\"end\":108021,\"start\":108012},{\"end\":108358,\"start\":108346},{\"end\":108368,\"start\":108358},{\"end\":108377,\"start\":108368},{\"end\":108387,\"start\":108377},{\"end\":108398,\"start\":108387},{\"end\":109678,\"start\":109664},{\"end\":109687,\"start\":109678},{\"end\":109697,\"start\":109687},{\"end\":110015,\"start\":110004},{\"end\":110031,\"start\":110015},{\"end\":110043,\"start\":110031},{\"end\":110056,\"start\":110043},{\"end\":110386,\"start\":110376},{\"end\":110396,\"start\":110386},{\"end\":110768,\"start\":110758},{\"end\":110779,\"start\":110768},{\"end\":110790,\"start\":110779},{\"end\":110803,\"start\":110790},{\"end\":111172,\"start\":111158},{\"end\":111182,\"start\":111172},{\"end\":111196,\"start\":111182},{\"end\":111209,\"start\":111196},{\"end\":111226,\"start\":111209},{\"end\":111527,\"start\":111519},{\"end\":111547,\"start\":111527},{\"end\":111555,\"start\":111547},{\"end\":111566,\"start\":111555},{\"end\":111924,\"start\":111916},{\"end\":111931,\"start\":111924},{\"end\":111939,\"start\":111931},{\"end\":111946,\"start\":111939},{\"end\":111953,\"start\":111946},{\"end\":112336,\"start\":112329},{\"end\":112343,\"start\":112336},{\"end\":112356,\"start\":112343},{\"end\":112706,\"start\":112696},{\"end\":112713,\"start\":112706},{\"end\":112722,\"start\":112713},{\"end\":112735,\"start\":112722},{\"end\":113185,\"start\":113177},{\"end\":113191,\"start\":113185},{\"end\":113204,\"start\":113191},{\"end\":113493,\"start\":113481},{\"end\":113501,\"start\":113493},{\"end\":113510,\"start\":113501},{\"end\":113519,\"start\":113510},{\"end\":114139,\"start\":114129},{\"end\":114148,\"start\":114139},{\"end\":114161,\"start\":114148},{\"end\":114174,\"start\":114161},{\"end\":114185,\"start\":114174},{\"end\":114193,\"start\":114185}]", "bib_venue": "[{\"end\":94153,\"start\":94069},{\"end\":101168,\"start\":101090},{\"end\":102100,\"start\":102014},{\"end\":104633,\"start\":104540},{\"end\":107363,\"start\":107302},{\"end\":107714,\"start\":107699},{\"end\":108453,\"start\":108434},{\"end\":113739,\"start\":113629},{\"end\":91495,\"start\":91438},{\"end\":91720,\"start\":91632},{\"end\":92112,\"start\":92092},{\"end\":92473,\"start\":92446},{\"end\":92818,\"start\":92795},{\"end\":93185,\"start\":93174},{\"end\":93616,\"start\":93593},{\"end\":93872,\"start\":93863},{\"end\":94067,\"start\":94001},{\"end\":94616,\"start\":94437},{\"end\":95017,\"start\":94893},{\"end\":95326,\"start\":95246},{\"end\":95727,\"start\":95696},{\"end\":96079,\"start\":95943},{\"end\":96597,\"start\":96581},{\"end\":97030,\"start\":97021},{\"end\":97414,\"start\":97389},{\"end\":97715,\"start\":97583},{\"end\":98267,\"start\":98121},{\"end\":98992,\"start\":98980},{\"end\":99338,\"start\":99320},{\"end\":99735,\"start\":99721},{\"end\":100109,\"start\":100099},{\"end\":100561,\"start\":100543},{\"end\":101088,\"start\":101010},{\"end\":101620,\"start\":101592},{\"end\":102012,\"start\":101928},{\"end\":102415,\"start\":102358},{\"end\":102718,\"start\":102653},{\"end\":103067,\"start\":103051},{\"end\":103387,\"start\":103362},{\"end\":103672,\"start\":103556},{\"end\":104107,\"start\":104093},{\"end\":104538,\"start\":104455},{\"end\":104931,\"start\":104922},{\"end\":105121,\"start\":105112},{\"end\":105398,\"start\":105292},{\"end\":105865,\"start\":105844},{\"end\":106273,\"start\":106146},{\"end\":106875,\"start\":106754},{\"end\":107300,\"start\":107243},{\"end\":107697,\"start\":107656},{\"end\":108070,\"start\":108045},{\"end\":108418,\"start\":108398},{\"end\":108721,\"start\":108679},{\"end\":108894,\"start\":108846},{\"end\":109113,\"start\":109033},{\"end\":109376,\"start\":109296},{\"end\":109737,\"start\":109727},{\"end\":110101,\"start\":110081},{\"end\":110445,\"start\":110427},{\"end\":110756,\"start\":110623},{\"end\":111245,\"start\":111226},{\"end\":111619,\"start\":111591},{\"end\":111997,\"start\":111977},{\"end\":112385,\"start\":112374},{\"end\":112842,\"start\":112768},{\"end\":113244,\"start\":113223},{\"end\":113627,\"start\":113519},{\"end\":114224,\"start\":114211}]"}}}, "year": 2023, "month": 12, "day": 17}