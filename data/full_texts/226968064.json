{"id": 226968064, "updated": "2023-04-05 08:54:39.356", "metadata": {"title": "Personalizing Item Recommendation via Price Understanding", "authors": "[{\"first\":\"Soumya\",\"last\":\"Wadhwa\",\"middle\":[]},{\"first\":\"Ashish\",\"last\":\"Ranjan\",\"middle\":[]},{\"first\":\"Selene\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Jason\",\"last\":\"Cho\",\"middle\":[\"H.\",\"D.\"]},{\"first\":\"Sushant\",\"last\":\"Kumar\",\"middle\":[]},{\"first\":\"Kannan\",\"last\":\"Achan\",\"middle\":[]}]", "venue": "ComplexRec-ImpactRS@RecSys", "journal": null, "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Personalization has gained a lot of traction in the e-commerce domain since there is ample evidence for short-term and long-term benefits of understanding user preferences and ensuring user satisfaction. However, effectively personalizing recommendations is a challenging task, especially at scale. Price is often a key consideration for purchases, and user behavior varies widely depending on demographic and psychological factors. While difficult to model, this is an important signal to consider for user-item recommendation. In this paper, we focus on personalizing and improving the relevance of item recommendations for e-commerce users by lever-aging price as an essential input. More concretely, we segregate items into price bands indicating how expensive they are, infer user affinity to price bands based on historical behavior and use features derived from this knowledge to re-rank items in a real-world recommendation scenario. We experiment with various statistical and machine learning methods to determine item price bands, user price affinities and item price similarities, and demonstrate impact on the recommendation quality for millions of users and items.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3109373729", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/recsys/WadhwaRXCKA20", "doi": null}}, "content": {"source": {"pdf_hash": "646516a41d3364079830f368868ea34770310010", "pdf_src": "DBLP", "pdf_uri": "[\"https://ceur-ws.org/Vol-2697/paper4_complexrec.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "6c9c4f8ef3894707210746f140dcdd67b35a5160", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/646516a41d3364079830f368868ea34770310010.txt", "contents": "\nPersonalizing Item Recommendation via Price Understanding\n\n\nSoumya Wadhwa soumya.wadhwa@walmartlabs.com \nAshish Ranjan ashish.ranjan@walmartlabs.com \nSelene Xu \nJason H D Cho hcho@walmartlabs.com \nKannan Achan kachan@walmartlabs.com \n\nWalmart Labs\nSunnyvaleCalifornia\n\n\nWalmart Labs\nSunnyvaleCalifornia\n\n\nWalmart Labs\nSunnyvaleCalifornia\n\n\nWalmart Labs\nSushant Kumar\nSunnyvaleCalifornia\n\n\nWalmart Labs\nSunnyvaleCalifornia\n\n\nWalmart Labs\nSunnyvaleCalifornia\n\nPersonalizing Item Recommendation via Price Understanding\n\nPersonalization has gained a lot of traction in the e-commerce domain since there is ample evidence for short-term and long-term benefits of understanding user preferences and ensuring user satisfaction. However, effectively personalizing recommendations is a challenging task, especially at scale. Price is often a key consideration for purchases, and user behavior varies widely depending on demographic and psychological factors. While difficult to model, this is an important signal to consider for user-item recommendation. In this paper, we focus on personalizing and improving the relevance of item recommendations for e-commerce users by leveraging price as an essential input. More concretely, we segregate items into price bands indicating how expensive they are, infer user affinity to price bands based on historical behavior and use features derived from this knowledge to re-rank items in a real-world recommendation scenario. We experiment with various statistical and machine learning methods to determine item price bands, user price affinities and item price similarities, and demonstrate impact on the recommendation quality for millions of users and items.\n\nINTRODUCTION\n\nRecommender systems are ubiquitous on websites today. Recommendation algorithms can be based on item-item interactions or user-item feedback. In recent times, websites are increasingly focusing on providing an experience tailored to their users [35] [10] [36] with personalization at the segment or individual level. Understanding user preferences and recommending relevant items to them accordingly has been shown to improve user satisfaction and conversion rates, which is a win-win situation [4] [5]. While it is essential, scaling the personalization of recommendations anchored on combinations of users and items is very challenging, especially in the e-commerce domain where millions of users can potentially interact with millions of items.\n\nFor most users, price is often a key factor for making purchases [14] [8] [34]. Users make price-value trade-offs when they purchase products, and their behavior can vary widely depending on demographic factors such as their salary or location and psychological factors such as money consciousness or additional interest in certain types of products. Let us consider two users. The first user is a sound engineer and is looking to purchase high-quality headphones for use at work. Since this user needs to discern any imperfections, they may be looking to purchase expensive headphones. Another user may decide to purchase headphones to listen to podcasts. As long as this user can understand the podcast, sound quality is not an issue and they can buy lower-priced headphones. To effectively personalize their shopping journey, understanding that the first customer is looking for higher priced headphones and the second customer is looking for lower priced ones will help recommend products they are looking for.\n\nHowever, defining what constitutes a high-priced or low-priced item is a difficult task. In the e-commerce domain, products, of course, have price associated with them. But, we do not know whether a given price is considered expensive or inexpensive for a given type of product, for example, a light bulb and a laptop. $100 may be a bargain for the laptop, but the same price-tag for the light bulb might make it very expensive. Similarly, we need to understand item prices for each product type and categorize them into different price bands (e.g. low vs. high) based on this. Subsequently, we can start understanding which price bands users are likely to purchase from for different product types.\n\nTo summarize, using price to personalize item recommendation is challenging because user price preferences need to be implicitly inferred and vary based on the type of product. Additionally, item prices are not sufficient to determine if a product is considered expensive versus not, and need to be standardized such that they can be compared across different types of products. In this paper, we aim to model user price affinity and item price similarity, and utilize them as input signals along with item-item relevance scores to personalize and improve the quality of item recommendations for e-commerce users. We achieve this using the following:\n\n\u2022 Unsupervised methods to divide items into price bands indicating their degree of expensiveness \u2022 Supervised methods to compute user affinity to different price bands based on their historical interactions \u2022 Item and user price-related features to re-rank items in an actual user-item recommendation setting This is done at the Product Type (PT) level which is the most granular level of the product taxonomy available in the Walmart product catalog. We use a large e-commerce dataset, and experiment with multiple statistical and machine learning methods to determine item price bands, user price affinities and item price similarities. We quantitatively show the positive impact on recommendation quality upon including price-related features in the re-ranking algorithm.\n\n\nRELATED WORK\n\nThere has been extensive research on recommender systems and personalization. Many research efforts have been focused on collaborative filtering-based techniques. Traditional matrix factorization (MF) models [24] and variants [17] [31], incorporating implicit feedback, temporal effects and confidence levels, have proved superior to the classic nearest neighbor approaches in recommending items [33]. Factorization machines [30] have also been used for recommendation to overcome feature sparsity issues. Emerging deep learning based solutions [6] [15] [13] have also shown promising results for recommendation. Item embeddings can be used to compute item-item similarity and recommend items accordingly [37] [11]. For modeling recommendations based on short session-based data, a sequential Recurrent Neural Network [28] (RNN)-based approach can be used to predict the next item [16]. More recently, causal embeddings for recommendation [3] have shown significant improvements over state-of-the-art factorization methods.\n\nPrice is an important factor to consider for users while making an online purchase. In [34], a conceptual framework is developed to explain the effects of the online medium on customer price sensitivity. User price sensitivity and price thresholds are discussed in [14]. Traditional and online supermarkets are compared in terms of user behavior with respect to brand, price and other search attributes in [8], and price sensitivity is found to be higher online. There are also other studies about impact of advertising [20] and brand credibility [9] on price sensitivity. In [38], the potential effect of the consumption occasion (functional vs. hedonic), social context and household income on users' price sensitivity is analyzed. There is substantial additional literature on consumer price sensitivity.\n\nHowever, price has received relatively less attention as an input signal for recommendation. Price is used as a feature in [1] for personalization in the e-commerce domain by taking the ratio of the price of the current item to the average price of previously clicked items. There is also a brief mention of how price can affect user's affinity towards an item in [17]. Authors in [18] perform data analysis of logs to investigate what makes recommendations effective in practice, and include some factors based on \"price levels\" per product category. However, methods for determining these price levels are not discussed and user price affinity is incorporated as an average of recent price levels (not per category). Their focus is on the impact of popularity, discounts, reminders and recency on user click behavior. In [12], Willingness To Pay (WTP) distributions per user and product are modeled, and this is used with discount indication and seller reputation in a context-aware recommendation model to improve recommendation quality. More recently, [40] model the transitive relationship between user-to-item and itemto-price using Graph Convolution Networks [22] (GCN) to make the learned user representations price-aware. They incorporate prices and categories as nodes along with users and items in a heterogeneous graph. They also consider price as a categorical variable and discretize the price value into separate levels based on price ranges but do not experiment with different methods for this.\n\nIn our work, we explore several methods to compute item price bands and explicitly model user price affinity for various types of products, such that these input signals can be leveraged generally for use cases such as recommendation and search. We demonstrate results for user-item and item-item price-related features obtained from different model variations used together with an item-item relevance score for personalizing item-anchored recommendations.\n\n\nMETHODOLOGY\n\nOur goal is to use past item interaction data (such as clicks and add to carts) for a given user and predict their affinity for a particular price band, and eventually incorporate this price understanding into recommendations. To achieve this, items are clustered into price bands at the product type level (Section 3.1), and then user activity patterns are learnt with respect to these item price bands to predict the probability that the user will purchase an item from a particular price band versus others for that product type. These predicted user-item price band affinity scores (Section 3.2) and item-item price band similarity scores (Section 3.3) are used as features along with relevance scores to re-rank item-anchored recommendations (Section 3.4) for personalization using price understanding.\n\n\nItem Price Bands\n\nItem prices vary a lot, from less than 10 dollars for a USB drive to thousands of dollars for a QLED television. However, to decide if an item is expensive or not, just the absolute value of price is insufficient. It is also important to take into consideration the product type since a price of $100 might be low for televisions, but high for a USB drive. Thus, we need to create representations for prices of items for each product type such that they are directly comparable across different items. So, we assign each item to one out of bands using unsupervised methods since labels are unavailable.\n\n3.1.1 Statistical Methods. We first explore statistical methods using item prices for each product type.\n\n\u2022 Range-Based: For example, say television prices vary from $100 to $5100, and we decide to create 3 price bands with price range ratios 3:5:2. Then one unit of the range becomes ($5100 -$100)/(3+5+2) = $500, and the lowest price band extends from $100 to $100 + 3*$500 (= $1600), the middle from $1600 to $2600 + 5*$500 (= $4100) and the highest from $4100 to $4100 + 2*$500 (= $5100). \u2022 Percentile-Based: For example, say, in the above situation, we decide to create 3 price bands with percentiles 30%, 50% and 20%. If there are 200 televisions on our item catalog with 60 TVs having price less than $500, 100 TVs with prices between $500 -$2500 and 40 TVs with prices greater than $2500, then those delineate the price bands. Splitting items into equal bins based on range or percentiles did not work well in practice due to skew in item price distributions and transaction volumes. Creating unequal bins needs extensive manual tuning.\n\n3.1.2 Clustering. Next, we use some common clustering methods to automatically put items from each product type into clusters using the item price values.\n\n\u2022 K-Means [26]: Each item is assigned to the cluster for which the mean price value is closest to the item price. \u2022 Gaussian Mixture Model (GMM) [32]: We assume that all the price values are generated from a mixture of a finite number of normal distributions with unknown means and variances (estimated using Expectation Maximization). We pick the highest probability cluster as the item's price band.\n\n\nTransaction Balancing.\n\nAnother method is based on computing cumulative transaction volumes after arranging items in increasing order of their price value, and determining price band boundaries such that each price band accounts for an equal volume of item transactions. This technique was devised to mitigate data imbalance in the subsequent step of using price bands to compute price affinities based on user activity.\n\n\nUser Price Affinity\n\nAfter assigning price bands to items at the product type level, the next step is to determine the user price affinity per product type. In other words, given a product type, we want to predict the probability that the user will purchase an item from a certain price band versus others. For example, say we are considering two price bands, \"expensive\" and \"cheap\". Sam might have affinities 0.8 and 0.2 towards expensive and cheap fitness trackers, but 0.3 and 0.7 towards expensive and cheap bed frames. This indicates that she likes buying expensive fitness trackers but inexpensive bed frames.\n\nTo predict this, we use historical data to train various machine learning models, using 6 months' data for generating features and the next 1 month for labels. The baseline prediction is based on the transactions in 6 months.\n\n\nBaseline.\n\nFor each user, per product type, we take the number of transactions (trx) in each price band ( ) and normalize it by summing transactions across all price bands for that product type ( ) and user to obtain affinity scores.\nuser_price_affinity ( , ) = # of trx in , # of trx in(1)\n\nMachine\n\nLearning. We consider user price affinity prediction as a multi-class classification (supervised machine learning) problem with number of classes equal to the number of price bands ( ). For each user and product type, we use features such as number of transactions, add to carts and views of items per price band per month (for 6 months) by that user for that product type. We did not have ground truth data for labels. As a proxy, we use the price band which has the maximum number of transactions by the user for that product type, as the label. The aggregation of data for labels is done using the month following the last month used for feature generation. Thus, each data point is used to predict price affinities of a specific user towards different price bands in a particular product type. Subsequently, we use these features and labels to train and test multi-class Logistic Regression (LR) [23] and Decision Tree (DT) [25] models. In LR, for each input data point (feature vector and label ), the model learns weights (weight vector ) and outputs a probability distribution over the price bands ( ) for a given user and product type ( ) which represents their affinity.\nuser_price_affinity ( , ) = exp =1 exp(2)\nWe use two variants -unweighted (LR-unbal) which is the vanilla model and weighted (LR-bal) based on class imbalance, where each data point is assigned a weight while contributing to the loss/gradient computation. The weight balancing heuristic used [21] is inversely proportional to class frequencies: n_samples n_classes * count_y , where is the class label. In DT, data is continuously split based on a certain feature at each step. We also consider random forests and fit multiple decision trees on a number of smaller samples from the data. The final output is the average of different tree outputs.\n\n\nItem Price Similarity\n\nAnother input is the similarity between price bands for items across product types based on user transaction patterns. For example, users who purchase medium-priced televisions might be likely to purchase high-priced sound bars and these ( , ) pairs are similar. This is also used as a feature while re-ranking to capture the itemitem price similarity. Pearson Correlation [2]: We compute the Pearson correlation ( ) between observed transactions for each user for different (product type, price band) pairs (say , and , ), and these are used as the price similarity scores.\nprice2price = , = cov( , ) *(3)\nMatrix Factorization [24]: We learn latent representations for (product type, price band) pairs by creating a user-(product type, price band) transaction matrix and factorizing it. \u00d7 denotes the user representation ( users) and \u00d7 denotes the (product type, price band) representation ( pairs). Embeddings are learned such that is a good approximation of transaction matrix . Cosine similarity between these low-dimensional vectors are used as price similarity scores.\nprice2price = ( ) = \u00b7 || || || ||(4)\n\nRe-Ranking\n\nTo tie everything up, we have a re-ranker engine that is capable of incorporating user price understanding and item price similarity into any item recommendation set such as Viewed also Viewed and Bought also Bought. We use an inference function to combine features related to user preference and item relevance, and predict user-item interactions:\n\n( interacts with | just interacted with ) = ( ( , ), \u210e( , )) (5) where is the user, is the anchor item, is the recommended item, ( , ) represents 's preference for , and \u210e( , ) represents item relevance between and . Currently, the inference function we use is simple logistic regression where user preference score and relevance score are combined linearly. The weights can be learned either at the global level (i.e. same weights across all product types) or at the product type level. There are more details in Section 4.4.\n\n\nEXPERIMENTS AND RESULTS\n\nWe use a real-world proprietary e-commerce dataset from walmart.com for demonstrating results. We determine price bands for few million items and predict price affinity scores for millions of users across around 6000 product types.\n\n\nItem Price Bands\n\nWe explored the trade-off between granularity for more useful user affinity scores and data sparsity issues in user-price band interactions as the number of price bands per product type increases, and decided to use = 5 item price bands for our experiments. We evaluate the discovered item price bands qualitatively, since ground truth labels are unavailable. One way is to look at how price ranges for different products were being split based on different methods described in Section 3.1. Of these, (as shown in Figure 1) we pick k-means and transaction balancing (transac-bal) as methods to further evaluate in the subsequent steps of predicting user affinities and using these to re-rank recommendations. We observe that clustering methods such as k-means put fewer very high priced items into the higher price bands, whereas trying to equalize number of transactions puts fewer items into the lower price bands, which is expected since less expensive items usually have more transactions. We also randomly sample items and inspect the quality of price bands. An example of televisions from 5 price bands (v low-0, low-1, medium-2, high-3 and v high-4) is shown in Figure 2.\n\n\nUser Price Affinity\n\nWe hold out 20% of data to test the trained user price affinity models described in Section 3.2. We use precision, recall and F1 score, which are common multi-class classification evaluation metrics, to assess the performance of different models. Since the classes in the data are not balanced, accuracy is not a good metric. Additionally, we also use the Mean Reciprocal Rank (MRR) to check whether even if the max transaction price band (ground truth label) does not get the maximum price affinity score, it gets a reasonably low (better) rank. Results for different models when price bands are determined using k-means and transac-bal are shown in Table 1 and Table 2 respectively. Random forests did not give much improvement over simple decision trees, so we have omitted those results. For the baseline, we obtain an overall MRR of around 0.51 for kmeans and around 0.37 for transac-bal. All the machine learning methods performed better than the baseline. For logistic regression, we explored hyperparameters aggregation depth: [2,4], maximum iterations: [100,1000], regularization: [0,0.01] and elastic net weights: [0.4,0.8], and were able to obtain an overall MRR of around 0.85 for k-means and around 0.79 for transac-bal. For decision trees, we explored hyperparameters impurity: [\"entropy\", \"gini\"], maximum depth: [10,20,30] and maximum bins: [16,32,64], and were able to obtain an overall MRR of around 0.85 for k-means and around 0.76 for transac-bal. We observe that weighted / class-balanced logistic regression performs the best for both item price banding strategies, but performance varies across different price bands as seen in Figure 3, with metrics falling for higher price bands in the k-means case and remaining at similar levels in the transac-bal case. Figure 4 shows an example of results obtained for product type, price band pairs which are most similar to Medium-2 priced Bed Sheets. We leave quantitative evaluation of methods to the downstream re-ranking application.\n\n\nItem Price Similarity\n\n\nRe-Ranking\n\nWe show how price understanding models perform when implemented on the \"customers who viewed also viewed\" (VAV) application (example shown in Figure 5). We take few million anchor items from VAV and limit to <= 30 recommendations for each item ranked by a \"relevance\" score. This relevance score is based on item-item features such as number of co-views, title match and popularity. The price understanding model offers two additional features for re-ranking on top of the relevance score: user price affinity score and price2price similarity score.\n\nWe first test out various methods used to develop user price affinity. We start with two main methods for item price banding: k-means and transaction balancing. For each item price banding model we have four variations for user price affinity: baseline, logistic regression (unbalanced), logistic regression (balanced) and decision trees. This gives us a total of eight versions of user price affinity scores. The inference function for re-ranking is balanced logistic regression:\n= 0 + 1 \u00d7 relevance + 2 \u00d7 user_price_affinity(6)\nThe weights in the equation above are trained at the global level (as opposed to at each product-type level) and are optimized for items that are co-viewed within each user session. To evaluate performance, we use common ranking evaluation metrics Normalized Discounted Cumulative Gain (NDCG) [19], Mean Hit Rate (MHR), Mean Reciprocal Rank (MRR) and Mean Average Precision (MAP) [27] [7]. The offline evaluation results are shown in Table 4. We limit the evaluation metrics to be based on the top 5 recommendations. We observe that all the models outperform the relevance only model (no re-ranking). The best performing model uses transaction balancing for price banding and applies weighted logistic regression (balanced) to derive user price affinity scores. We now expand on the previously established best performing model and supplement it with item price similarity information between the anchor item and the recommended item. We have two variations of item similarity scores to compare: Pearson correlation and matrix factorization. The inference function now has an additional feature, as follows:\n= 0 + 1 \u00d7 relevance + 2 \u00d7 user_price_affinity + 3 \u00d7 price2price_similarity(7)\nAgain we adopt a balanced logistic regression model to train the above objective function and learn the weights at the global level. The results are shown in Table 5. We observe an even greater boost in performance by adding the price2price feature. Overall, the best performing model uses price2price scores derived from matrix factorization. Compared to the relevance only model, this method shows 0.64% improvement in NDCG, 1% improvement in MHR, and 0.93% improvement in MAP. The improvements in NDCG, MHR and MAP@5 are statistically significant at 5% level in our offline evaluation. Though the MRR is slightly lower, the difference is not statistically significant. Also, since 5-6 recommended items are typically shown on the first pane of the module, metrics such as MHR become more important.\n\nWe further study the weights, 1 2 3 from the inference function to gauge feature importance. After adjusting for feature variance (standard scaling of features), the ratio among the weights 1 : 2 : 3 = 33:3:1. This tells us that the relevance score from the VAV model contributes the most even during re-ranking, but price-related features also add value. The user price affinity feature has greater weight than the price2price feature.    \n\n\nCONCLUSION\n\nIn this paper, we discuss a novel approach to incorporate pricerelated user-item signals into recommender systems to personalize their output. This is done by assigning price bands to items of different types, using historical user-item data to predict user price affinity and using this affinity along with an item price band similarity score to re-rank item recommendations anchored on a (user,    item) pair. We demonstrate statistically significant improvement in offline ranking metrics after explicitly including price inputs (user price affinity using balanced logistic regression with transactionbalanced price bands; item price similarity using matrix factorization). To compute price affinities, other user-website interaction data such as user's historical search queries can also be used. In the future, we plan to learn embeddings which implicitly encode item price information and user representations such that similarity between user and item embeddings is indicative of price affinity. We can also experiment with other pairwise or listwise learning to rank methods to improve the current pointwise ranking function.\n\nFigure 1 :Figure 2 :\n12Different price bands obtained for k-means and transac-bal for product type Televisions An example of items in different price bands obtained for product type Televisions\n\nFigure 3 :Figure 4 :Figure 5 :\n345Comparison of Evaluation Metrics for Balanced Logistic Regression with k-means vs transac-bal item price banding Top 10 similar Product Types, Price Bands to Medium-2 Bed Sheets Viewed also Viewed recommendations for a dog food container item\n\n\nTable 1: k-means to determine Item Price BandsMethod \nPr Band Prec \nRec \nF1 \nMRR \n\nBaseline \n\nV Low \n0.51 \n0.56 \n0.53 \n0.77 \nLow \n0.36 \n0.33 \n0.34 \n0.64 \nMedium 0.11 \n0.09 \n0.10 \n0.40 \nHigh \n0.02 \n0.02 \n0.02 \n0.26 \nV High 0.002 0.001 0.001 0.20 \n\nLR-unbal \n\nV Low \n0.80 \n0.87 \n0.83 \n0.92 \nLow \n0.72 \n0.71 \n0.71 \n0.85 \nMedium 0.67 \n0.52 \n0.59 \n0.71 \nHigh \n0.57 \n0.21 \n0.31 \n0.46 \nV High \n0.87 \n0.02 \n0.05 \n0.24 \n\nLR-bal \n\nV Low \n0.84 \n0.83 \n0.83 \n0.88 \nLow \n0.73 \n0.70 \n0.71 \n0.83 \nMedium 0.59 \n0.63 \n0.61 \n0.78 \nHigh \n0.46 \n0.60 \n0.52 \n0.74 \nV High \n0.11 \n0.37 \n0.18 \n0.58 \n\nDT \n\nV Low \n0.83 \n0.81 \n0.82 \n0.89 \nLow \n0.65 \n0.75 \n0.69 \n0.87 \nMedium 0.61 \n0.46 \n0.53 \n0.68 \nHigh \n0.54 \n0.35 \n0.43 \n0.52 \nV High \n0.05 \n0.01 \n0.01 \n0.21 \n\nMethod \nPr Band Prec Rec \nF1 MRR \n\nBaseline \n\nV Low \n0.06 0.07 0.06 0.48 \nLow \n0.11 0.12 0.11 0.41 \nMedium 0.16 0.17 0.17 0.40 \nHigh \n0.22 0.22 0.22 0.42 \nV High 0.46 0.43 0.44 0.58 \n\nLR-unbal \n\nV Low \n0.59 0.40 0.48 0.54 \nLow \n0.67 0.32 0.44 0.53 \nMedium 0.63 0.40 0.49 0.65 \nHigh \n0.63 0.52 0.57 0.74 \nV High 0.65 0.89 0.75 0.93 \n\nLR-bal \n\nV Low \n0.51 0.55 0.53 0.69 \nLow \n0.60 0.45 0.52 0.64 \nMedium 0.58 0.55 0.56 0.73 \nHigh \n0.59 0.58 0.59 0.75 \nV High 0.76 0.81 0.78 0.87 \n\nDT \n\nV Low \n0.59 0.32 0.42 0.50 \nLow \n0.58 0.39 0.47 0.57 \nMedium 0.59 0.45 0.51 0.63 \nHigh \n0.61 0.47 0.53 0.69 \nV High 0.65 0.86 0.74 0.91 \n\n\n\nTable 2 :\n2transac-bal to determine Item Price Bands\n\nTable 3 :\n3Evaluation Metrics for Different Price Affinity Models\n\n\nItem Price Band Method User Price Affinity Method NDCG@5 MHR@5 MRR@5 MAP@5-Relevance -\n0.4375 \n0.8480 \n0.5418 \n0.2048 \n\nk-means \nBaseline \n0.4381 \n0.8493 \n0.5418 \n0.2053 \nk-means \nLR (unbalanced) \n0.4386 \n0.8504 \n0.5417 \n0.2057 \nk-means \nLR (balanced) \n0.4388 \n0.8508 \n0.5417 \n0.2057 \nk-means \nDecision Trees \n0.4385 \n0.8503 \n0.5416 \n0.2056 \n\ntransac-bal \nBaseline \n0.4384 \n0.8503 \n0.5415 \n0.2054 \ntransac-bal \nLR (unbalanced) \n0.4388 \n0.8519 \n0.5410 \n0.2057 \ntransac-bal \nLR (balanced) \n0.4389 \n0.8524 \n0.5408 \n0.2057 \ntransac-bal \nDecision Trees \n0.4386 \n0.8513 \n0.5411 \n0.2056 \n\n\n\nTable 4 :\n4Evaluation Metrics for Different Re-ranking Experiments (using Price Affinity only)Price Similarity Method NDCG@5 MHR@5 MRR@5 MAP@5 \n\n-Relevance -\n0.4375 \n0.8480 \n0.5418 \n0.2048 \n\nPearson Correlation \n0.4402 \n0.8557 \n0.5403 \n0.2067 \nMatrix Factorization \n0.4403 \n0.8565 \n0.5400 \n0.2067 \n\n\n\nTable 5 :\n5Evaluation Metrics for Different Re-ranking Experiments (using Price Affinity (best) with Price Similarity)\n\nPrathyusha Senthil Kumar, Amit Jaiswal, and Manojkumar Rangasamy Kannadasan. 2020. Personalized Ranking in eCommerce Search. Grigor Aslanyan, Aritra Mandal, Companion Proceedings of the Web Conference 2020. Grigor Aslanyan, Aritra Mandal, Prathyusha Senthil Kumar, Amit Jaiswal, and Manojkumar Rangasamy Kannadasan. 2020. Personalized Ranking in eCommerce Search. In Companion Proceedings of the Web Conference 2020. 96-97.\n\nPearson Correlation Coefficient. Jacob Benesty, Jingdong Chen, Yiteng Huang, Israel Cohen, Noise Reduction in Speech Processing. SpringerJacob Benesty, Jingdong Chen, Yiteng Huang, and Israel Cohen. 2009. Pearson Correlation Coefficient. In Noise Reduction in Speech Processing. Springer, 1-4.\n\nCausal Embeddings for Recommendation. Stephen Bonner, Flavian Vasile, Proceedings of the 12th ACM Conference on Recommender Systems. the 12th ACM Conference on Recommender SystemsStephen Bonner and Flavian Vasile. 2018. Causal Embeddings for Recommen- dation. In Proceedings of the 12th ACM Conference on Recommender Systems. 104-112.\n\nDoes Collaborative Filtering Technology Impact Sales? Empirical Evidence from Amazon.com. Empirical Evidence from Amazon. Pei-Yu Chen, Shin-Yi Wu, Com. Pei-Yu Chen and Shin-yi Wu. 2007. Does Collaborative Filtering Technology Impact Sales? Empirical Evidence from Amazon.com. Empirical Evidence from Amazon.Com (July 8, 2007) (2007).\n\nThe Impact of Online Recommendations and Consumer Feedback on Sales. Pei-Yu Chen, Shin-Yi Wu, Jungsun Yoon, Proceedings. 58Pei-Yu Chen, Shin-yi Wu, and Jungsun Yoon. 2004. The Impact of Online Rec- ommendations and Consumer Feedback on Sales. ICIS 2004 Proceedings (2004), 58.\n\n. Heng-Tze, Levent Cheng, Jeremiah Koc, Tal Harmsen, Tushar Shaked, Hrishi Chandra, Glen Aradhye, Greg Anderson, Wei Corrado, Mustafa Chai, Ispir, Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al.\n\nWide & Deep Learning for Recommender Systems. Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. the 1st Workshop on Deep Learning for Recommender SystemsWide & Deep Learning for Recommender Systems. In Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. 7-10.\n\nBruce Croft, Donald Metzler, Trevor Strohman, Search Engines: Information Retrieval in Practice. Addison-Wesley Reading520W Bruce Croft, Donald Metzler, and Trevor Strohman. 2010. Search Engines: Information Retrieval in Practice. Vol. 520. Addison-Wesley Reading.\n\nConsumer Choice Behavior in Online and Traditional Supermarkets: The Effects of Brand Name, Price, and other Search Attributes. M Alexandru, Arvind Degeratu, Jianan Rangaswamy, Wu, International Journal of Research in Marketing. 17Alexandru M Degeratu, Arvind Rangaswamy, and Jianan Wu. 2000. Consumer Choice Behavior in Online and Traditional Supermarkets: The Effects of Brand Name, Price, and other Search Attributes. International Journal of Research in Marketing 17, 1 (2000), 55-78.\n\nThe Impact of Brand Credibility on Consumer Price Sensitivity. T\u00fclin Erdem, Joffre Swait, Jordan Louviere, International Journal of Research in Marketing. 19T\u00fclin Erdem, Joffre Swait, and Jordan Louviere. 2002. The Impact of Brand Credibility on Consumer Price Sensitivity. International Journal of Research in Marketing 19, 1 (2002), 1-19.\n\nThe Netflix Recommender System: Algorithms, Business Value, and Innovation. A Carlos, Neil Gomez-Uribe, Hunt, ACM Transactions on Management Information Systems (TMIS). 6Carlos A Gomez-Uribe and Neil Hunt. 2015. The Netflix Recommender System: Algorithms, Business Value, and Innovation. ACM Transactions on Management Information Systems (TMIS) 6, 4 (2015), 1-19.\n\nE-commerce in your Inbox: Product Recommendations at Scale. Mihajlo Grbovic, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, Doug Sharp, Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningMihajlo Grbovic, Vladan Radosavljevic, Nemanja Djuric, Narayan Bhamidipati, Jaikit Savla, Varun Bhagwan, and Doug Sharp. 2015. E-commerce in your Inbox: Product Recommendations at Scale. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1809-1818.\n\nPersonal Price Aware Multi-Seller Recommender System: Evidence from eBay. Knowledge-Based Systems. Asnat Greenstein, -Messica , Lior Rokach, 150Asnat Greenstein-Messica and Lior Rokach. 2018. Personal Price Aware Multi- Seller Recommender System: Evidence from eBay. Knowledge-Based Systems 150 (2018), 14-26.\n\nDeepFM: A Factorization-Machine based Neural Network for CTR Prediction. Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He, arXiv:1703.04247arXiv preprintHuifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction. arXiv preprint arXiv:1703.04247 (2017).\n\nConsumer Price Sensitivity and Price Thresholds. Sangman Han, Sunil Gupta, Donald R Lehmann, Journal of Retailing. 77Sangman Han, Sunil Gupta, and Donald R Lehmann. 2001. Consumer Price Sensitivity and Price Thresholds. Journal of Retailing 77, 4 (2001), 435-456.\n\nNeural Collaborative Filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proceedings of the 26th International Conference on World Wide Web. the 26th International Conference on World Wide WebXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web. 173-182.\n\nBal\u00e1zs Hidasi, Alexandros Karatzoglou, arXiv:1511.06939Linas Baltrunas, and Domonkos Tikk. 2015. Session-based Recommendations with Recurrent Neural Networks. arXiv preprintBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2015. Session-based Recommendations with Recurrent Neural Networks. arXiv preprint arXiv:1511.06939 (2015).\n\nCollaborative Filtering for Implicit Feedback datasets. Yifan Hu, Yehuda Koren, Chris Volinsky, Eighth IEEE International Conference on Data Mining. IEEEYifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative Filtering for Implicit Feedback datasets. In 2008 Eighth IEEE International Conference on Data Mining. IEEE, 263-272.\n\nDietmar Jannach, Malte Ludewig, Lukas Lerche, 10.1007/s11257-017-9194-1Session-Based Item Recommendation in e-Commerce: On Short-Term Intents, Reminders, Trends and Discounts. 27Dietmar Jannach, Malte Ludewig, and Lukas Lerche. 2017. Session-Based Item Recommendation in e-Commerce: On Short-Term Intents, Reminders, Trends and Discounts. 27, 3-5 (Dec. 2017), 351-392. https://doi.org/10.1007/s11257-017- 9194-1\n\nCumulated Gain-based Evaluation of IR Techniques. Kalervo J\u00e4rvelin, Jaana Kek\u00e4l\u00e4inen, ACM Transactions on Information Systems (TOIS). 20Kalervo J\u00e4rvelin and Jaana Kek\u00e4l\u00e4inen. 2002. Cumulated Gain-based Evaluation of IR Techniques. ACM Transactions on Information Systems (TOIS) 20, 4 (2002), 422-446.\n\nEmpirical Generalizations about the Impact of Advertising on Price Sensitivity and Price. Anil Kaul, Dick R Wittink, Marketing Science. 14Anil Kaul and Dick R Wittink. 1995. Empirical Generalizations about the Impact of Advertising on Price Sensitivity and Price. Marketing Science 14, 3_supplement (1995), G151-G160.\n\nLogistic Regression in Rare Events Data. Gary King, Langche Zeng, Political Analysis. 9Gary King and Langche Zeng. 2001. Logistic Regression in Rare Events Data. Political Analysis 9, 2 (2001), 137-163.\n\nSemi-Supervised Classification with Graph Convolutional Networks. N Thomas, Max Kipf, Welling, arXiv:1609.02907arXiv preprintThomas N Kipf and Max Welling. 2016. Semi-Supervised Classification with Graph Convolutional Networks. arXiv preprint arXiv:1609.02907 (2016).\n\nLogistic Regression. K David G Kleinbaum, M Dietz, Mitchel Gail, Mitchell Klein, Klein, SpringerDavid G Kleinbaum, K Dietz, M Gail, Mitchel Klein, and Mitchell Klein. 2002. Logistic Regression. Springer.\n\nMatrix Factorization Techniques for Recommender Systems. Yehuda Koren, Robert Bell, Chris Volinsky, Computer. 42Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Tech- niques for Recommender Systems. Computer 42, 8 (2009), 30-37.\n\nFifty Years of Classification and Regression Trees. Wei-Yin Loh, International Statistical Review. 82Wei-Yin Loh. 2014. Fifty Years of Classification and Regression Trees. International Statistical Review 82, 3 (2014), 329-348.\n\nSome Methods for Classification and Analysis of Multivariate Observations. James Macqueen, Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability. the Fifth Berkeley Symposium on Mathematical Statistics and ProbabilityOakland, CA, USA1James MacQueen et al. 1967. Some Methods for Classification and Analysis of Multivariate Observations. In Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Vol. 1. Oakland, CA, USA, 281-297.\n\nIntroduction to Information Retrieval. D Christopher, Hinrich Manning, Prabhakar Sch\u00fctze, Raghavan, Cambridge University PressChristopher D Manning, Hinrich Sch\u00fctze, and Prabhakar Raghavan. 2008. Intro- duction to Information Retrieval. Cambridge University Press.\n\nGradient Calculations for Dynamic Recurrent Neural Networks: A Survey. A Barak, Pearlmutter, IEEE Transactions on Neural networks. 6Barak A Pearlmutter. 1995. Gradient Calculations for Dynamic Recurrent Neural Networks: A Survey. IEEE Transactions on Neural networks 6, 5 (1995), 1212-1228.\n\nScikit-learn: Machine Learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, J Vanderplas, A Passos, D Cournapeau, M Brucher, M Perrot, E Duchesnay, Journal of Machine Learning Research. 12F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cour- napeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research 12 (2011), 2825-2830.\n\nFactorization Machines. Steffen Rendle, IEEE International Conference on Data Mining. IEEE. Steffen Rendle. 2010. Factorization Machines. In 2010 IEEE International Confer- ence on Data Mining. IEEE, 995-1000.\n\nSteffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, arXiv:1205.2618BPR: Bayesian Personalized Ranking from Implicit Feedback. arXiv preprintSteffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian Personalized Ranking from Implicit Feedback. arXiv preprint arXiv:1205.2618 (2012).\n\n. A Douglas, Reynolds, Gaussian Mixture Models. Encyclopedia of Biometrics. 741Douglas A Reynolds. 2009. Gaussian Mixture Models. Encyclopedia of Biometrics 741 (2009).\n\nItem-based Collaborative Filtering Recommendation Algorithms. Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl, Proceedings of the 10th International Conference on World Wide Web. the 10th International Conference on World Wide WebBadrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based Collaborative Filtering Recommendation Algorithms. In Proceedings of the 10th International Conference on World Wide Web. 285-295.\n\nThe Online Medium and Customer Price Sensitivity. Venkatesh Shankar, Arvind Rangaswamy, Michael Pusateri, Working PaperVenkatesh Shankar, Arvind Rangaswamy, and Michael Pusateri. 1999. The Online Medium and Customer Price Sensitivity. Working Paper (1999).\n\nTwo Decades of Recommender Systems at Amazon.com. Brent Smith, Greg Linden, IEEE Internet Computing. 21Brent Smith and Greg Linden. 2017. Two Decades of Recommender Systems at Amazon.com. IEEE Internet Computing 21, 3 (2017), 12-18.\n\nPersonalizing Search via Automated Analysis of Interests and Activities. Jaime Teevan, Susan T Dumais, Eric Horvitz, 10.1145/1076034.1076111Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. the 28th Annual International ACM SIGIR Conference on Research and Development in Information RetrievalSalvador, Brazil; New York, NY, USAAssociation for Computing MachinerySIGIR '05)Jaime Teevan, Susan T. Dumais, and Eric Horvitz. 2005. Personalizing Search via Automated Analysis of Interests and Activities. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (Salvador, Brazil) (SIGIR '05). Association for Computing Machinery, New York, NY, USA, 449-456. https://doi.org/10.1145/1076034.1076111\n\nMeta-prod2vec: Product Embeddings using side-information for Recommendation. Flavian Vasile, Elena Smirnova, Alexis Conneau, Proceedings of the 10th ACM Conference on Recommender Systems. the 10th ACM Conference on Recommender SystemsFlavian Vasile, Elena Smirnova, and Alexis Conneau. 2016. Meta-prod2vec: Product Embeddings using side-information for Recommendation. In Proceedings of the 10th ACM Conference on Recommender Systems. 225-232.\n\nSituational Price Sensitivity: the Role of Consumption Occasion, Social Context and Income. L Kirk, J Jeffrey Wakefield, Inman, Journal of Retailing. 79Kirk L Wakefield and J Jeffrey Inman. 2003. Situational Price Sensitivity: the Role of Consumption Occasion, Social Context and Income. Journal of Retailing 79, 4 (2003), 199-212.\n\n. Matei Zaharia, Reynold S Xin, Patrick Wendell, Tathagata Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen, Shivaram Venkataraman, J Michael, Matei Zaharia, Reynold S. Xin, Patrick Wendell, Tathagata Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen, Shivaram Venkataraman, Michael J.\n\nApache Spark: A Unified Engine for Big Data Processing. Ali Franklin, Joseph Ghodsi, Scott Gonzalez, Ion Shenker, Stoica, 10.1145/2934664Commun. ACM. 59Franklin, Ali Ghodsi, Joseph Gonzalez, Scott Shenker, and Ion Stoica. 2016. Apache Spark: A Unified Engine for Big Data Processing. Commun. ACM 59, 11 (Oct. 2016), 56-65. https://doi.org/10.1145/2934664\n\nPrice-Aware Recommendation with Graph Convolutional Networks. Yu Zheng, Chen Gao, Xiangnan He, Yong Li, Depeng Jin, 2020 IEEE 36th International Conference on Data Engineering (ICDE). IEEEYu Zheng, Chen Gao, Xiangnan He, Yong Li, and Depeng Jin. 2020. Price-Aware Recommendation with Graph Convolutional Networks. In 2020 IEEE 36th Inter- national Conference on Data Engineering (ICDE). IEEE, 133-144.\n", "annotations": {"author": "[{\"end\":105,\"start\":61},{\"end\":150,\"start\":106},{\"end\":161,\"start\":151},{\"end\":197,\"start\":162},{\"end\":234,\"start\":198},{\"end\":269,\"start\":235},{\"end\":304,\"start\":270},{\"end\":339,\"start\":305},{\"end\":388,\"start\":340},{\"end\":423,\"start\":389},{\"end\":458,\"start\":424}]", "publisher": null, "author_last_name": "[{\"end\":74,\"start\":68},{\"end\":119,\"start\":113},{\"end\":160,\"start\":158},{\"end\":175,\"start\":172},{\"end\":210,\"start\":205}]", "author_first_name": "[{\"end\":67,\"start\":61},{\"end\":112,\"start\":106},{\"end\":157,\"start\":151},{\"end\":167,\"start\":162},{\"end\":171,\"start\":168},{\"end\":204,\"start\":198}]", "author_affiliation": "[{\"end\":268,\"start\":236},{\"end\":303,\"start\":271},{\"end\":338,\"start\":306},{\"end\":387,\"start\":341},{\"end\":422,\"start\":390},{\"end\":457,\"start\":425}]", "title": "[{\"end\":58,\"start\":1},{\"end\":516,\"start\":459}]", "venue": null, "abstract": "[{\"end\":1694,\"start\":518}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b35\"},\"end\":1959,\"start\":1955},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":1969,\"start\":1965},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2208,\"start\":2205},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2212,\"start\":2209},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2528,\"start\":2524},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2537,\"start\":2533},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5831,\"start\":5827},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5849,\"start\":5845},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5854,\"start\":5850},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6019,\"start\":6015},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6048,\"start\":6044},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6167,\"start\":6164},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6177,\"start\":6173},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6328,\"start\":6324},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6333,\"start\":6329},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6441,\"start\":6437},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6504,\"start\":6500},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6561,\"start\":6558},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6735,\"start\":6731},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6913,\"start\":6909},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7053,\"start\":7050},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7168,\"start\":7164},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7194,\"start\":7191},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":7224,\"start\":7220},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7579,\"start\":7576},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7821,\"start\":7817},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7838,\"start\":7834},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8280,\"start\":8276},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8513,\"start\":8509},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8623,\"start\":8619},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12087,\"start\":12083},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":12222,\"start\":12218},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14951,\"start\":14947},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14979,\"start\":14975},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":15523,\"start\":15519},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":16275,\"start\":16272},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":16531,\"start\":16527},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20421,\"start\":20418},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20423,\"start\":20421},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20715,\"start\":20711},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":20718,\"start\":20715},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":20721,\"start\":20718},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20744,\"start\":20740},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":20747,\"start\":20744},{\"end\":20750,\"start\":20747},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22802,\"start\":22798},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":22889,\"start\":22885},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22893,\"start\":22890}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":26277,\"start\":26083},{\"attributes\":{\"id\":\"fig_1\"},\"end\":26555,\"start\":26278},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":27915,\"start\":26556},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":27969,\"start\":27916},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":28036,\"start\":27970},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":28621,\"start\":28037},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":28922,\"start\":28622},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":29042,\"start\":28923}]", "paragraph": "[{\"end\":2457,\"start\":1710},{\"end\":3473,\"start\":2459},{\"end\":4174,\"start\":3475},{\"end\":4826,\"start\":4176},{\"end\":5602,\"start\":4828},{\"end\":6642,\"start\":5619},{\"end\":7451,\"start\":6644},{\"end\":8964,\"start\":7453},{\"end\":9423,\"start\":8966},{\"end\":10246,\"start\":9439},{\"end\":10869,\"start\":10267},{\"end\":10975,\"start\":10871},{\"end\":11915,\"start\":10977},{\"end\":12071,\"start\":11917},{\"end\":12474,\"start\":12073},{\"end\":12897,\"start\":12501},{\"end\":13516,\"start\":12921},{\"end\":13743,\"start\":13518},{\"end\":13979,\"start\":13757},{\"end\":15226,\"start\":14047},{\"end\":15873,\"start\":15269},{\"end\":16473,\"start\":15899},{\"end\":16973,\"start\":16506},{\"end\":17372,\"start\":17024},{\"end\":17900,\"start\":17374},{\"end\":18159,\"start\":17928},{\"end\":19359,\"start\":18180},{\"end\":21385,\"start\":19383},{\"end\":21973,\"start\":21424},{\"end\":22455,\"start\":21975},{\"end\":23612,\"start\":22505},{\"end\":24492,\"start\":23691},{\"end\":24934,\"start\":24494},{\"end\":26082,\"start\":24949}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14036,\"start\":13980},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15268,\"start\":15227},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16505,\"start\":16474},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17010,\"start\":16974},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22504,\"start\":22456},{\"attributes\":{\"id\":\"formula_5\"},\"end\":23690,\"start\":23613}]", "table_ref": "[{\"end\":20041,\"start\":20034},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20053,\"start\":20046},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":22946,\"start\":22939},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":23856,\"start\":23849}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1708,\"start\":1696},{\"attributes\":{\"n\":\"2\"},\"end\":5617,\"start\":5605},{\"attributes\":{\"n\":\"3\"},\"end\":9437,\"start\":9426},{\"attributes\":{\"n\":\"3.1\"},\"end\":10265,\"start\":10249},{\"attributes\":{\"n\":\"3.1.3\"},\"end\":12499,\"start\":12477},{\"attributes\":{\"n\":\"3.2\"},\"end\":12919,\"start\":12900},{\"attributes\":{\"n\":\"3.2.1\"},\"end\":13755,\"start\":13746},{\"attributes\":{\"n\":\"3.2.2\"},\"end\":14045,\"start\":14038},{\"attributes\":{\"n\":\"3.3\"},\"end\":15897,\"start\":15876},{\"attributes\":{\"n\":\"3.4\"},\"end\":17022,\"start\":17012},{\"attributes\":{\"n\":\"4\"},\"end\":17926,\"start\":17903},{\"attributes\":{\"n\":\"4.1\"},\"end\":18178,\"start\":18162},{\"attributes\":{\"n\":\"4.2\"},\"end\":19381,\"start\":19362},{\"attributes\":{\"n\":\"4.3\"},\"end\":21409,\"start\":21388},{\"attributes\":{\"n\":\"4.4\"},\"end\":21422,\"start\":21412},{\"attributes\":{\"n\":\"5\"},\"end\":24947,\"start\":24937},{\"end\":26104,\"start\":26084},{\"end\":26309,\"start\":26279},{\"end\":27926,\"start\":27917},{\"end\":27980,\"start\":27971},{\"end\":28632,\"start\":28623},{\"end\":28933,\"start\":28924}]", "table": "[{\"end\":27915,\"start\":26604},{\"end\":28621,\"start\":28113},{\"end\":28922,\"start\":28717}]", "figure_caption": "[{\"end\":26277,\"start\":26107},{\"end\":26555,\"start\":26313},{\"end\":26604,\"start\":26558},{\"end\":27969,\"start\":27928},{\"end\":28036,\"start\":27982},{\"end\":28113,\"start\":28039},{\"end\":28717,\"start\":28634},{\"end\":29042,\"start\":28935}]", "figure_ref": "[{\"end\":18703,\"start\":18695},{\"end\":19358,\"start\":19350},{\"end\":21042,\"start\":21034},{\"end\":21173,\"start\":21165},{\"end\":21574,\"start\":21566}]", "bib_author_first_name": "[{\"end\":29175,\"start\":29169},{\"end\":29192,\"start\":29186},{\"end\":29507,\"start\":29502},{\"end\":29525,\"start\":29517},{\"end\":29538,\"start\":29532},{\"end\":29552,\"start\":29546},{\"end\":29809,\"start\":29802},{\"end\":29825,\"start\":29818},{\"end\":30228,\"start\":30222},{\"end\":30242,\"start\":30235},{\"end\":30510,\"start\":30504},{\"end\":30524,\"start\":30517},{\"end\":30536,\"start\":30529},{\"end\":30731,\"start\":30725},{\"end\":30747,\"start\":30739},{\"end\":30756,\"start\":30753},{\"end\":30772,\"start\":30766},{\"end\":30787,\"start\":30781},{\"end\":30801,\"start\":30797},{\"end\":30815,\"start\":30811},{\"end\":30829,\"start\":30826},{\"end\":30846,\"start\":30839},{\"end\":31324,\"start\":31319},{\"end\":31338,\"start\":31332},{\"end\":31354,\"start\":31348},{\"end\":31714,\"start\":31713},{\"end\":31732,\"start\":31726},{\"end\":31749,\"start\":31743},{\"end\":32143,\"start\":32138},{\"end\":32157,\"start\":32151},{\"end\":32171,\"start\":32165},{\"end\":32494,\"start\":32493},{\"end\":32507,\"start\":32503},{\"end\":32850,\"start\":32843},{\"end\":32866,\"start\":32860},{\"end\":32889,\"start\":32882},{\"end\":32905,\"start\":32898},{\"end\":32925,\"start\":32919},{\"end\":32938,\"start\":32933},{\"end\":32952,\"start\":32948},{\"end\":33549,\"start\":33544},{\"end\":33570,\"start\":33562},{\"end\":33577,\"start\":33573},{\"end\":33836,\"start\":33829},{\"end\":33849,\"start\":33842},{\"end\":33863,\"start\":33856},{\"end\":33875,\"start\":33868},{\"end\":33888,\"start\":33880},{\"end\":34167,\"start\":34160},{\"end\":34178,\"start\":34173},{\"end\":34194,\"start\":34186},{\"end\":34416,\"start\":34408},{\"end\":34425,\"start\":34421},{\"end\":34439,\"start\":34432},{\"end\":34454,\"start\":34447},{\"end\":34463,\"start\":34460},{\"end\":34476,\"start\":34468},{\"end\":34806,\"start\":34800},{\"end\":34825,\"start\":34815},{\"end\":35218,\"start\":35213},{\"end\":35229,\"start\":35223},{\"end\":35242,\"start\":35237},{\"end\":35500,\"start\":35493},{\"end\":35515,\"start\":35510},{\"end\":35530,\"start\":35525},{\"end\":35963,\"start\":35956},{\"end\":35979,\"start\":35974},{\"end\":36302,\"start\":36298},{\"end\":36572,\"start\":36568},{\"end\":36586,\"start\":36579},{\"end\":36798,\"start\":36797},{\"end\":36810,\"start\":36807},{\"end\":37022,\"start\":37021},{\"end\":37043,\"start\":37042},{\"end\":37058,\"start\":37051},{\"end\":37073,\"start\":37065},{\"end\":37268,\"start\":37262},{\"end\":37282,\"start\":37276},{\"end\":37294,\"start\":37289},{\"end\":37519,\"start\":37512},{\"end\":37769,\"start\":37764},{\"end\":38226,\"start\":38225},{\"end\":38247,\"start\":38240},{\"end\":38266,\"start\":38257},{\"end\":38524,\"start\":38523},{\"end\":38787,\"start\":38786},{\"end\":38800,\"start\":38799},{\"end\":38813,\"start\":38812},{\"end\":38825,\"start\":38824},{\"end\":38835,\"start\":38834},{\"end\":38846,\"start\":38845},{\"end\":38856,\"start\":38855},{\"end\":38867,\"start\":38866},{\"end\":38883,\"start\":38882},{\"end\":38892,\"start\":38891},{\"end\":38903,\"start\":38902},{\"end\":38917,\"start\":38916},{\"end\":38927,\"start\":38926},{\"end\":38941,\"start\":38940},{\"end\":38952,\"start\":38951},{\"end\":38962,\"start\":38961},{\"end\":39550,\"start\":39543},{\"end\":39568,\"start\":39559},{\"end\":39588,\"start\":39584},{\"end\":39602,\"start\":39598},{\"end\":39895,\"start\":39894},{\"end\":40130,\"start\":40124},{\"end\":40145,\"start\":40139},{\"end\":40161,\"start\":40155},{\"end\":40175,\"start\":40171},{\"end\":40573,\"start\":40564},{\"end\":40589,\"start\":40583},{\"end\":40609,\"start\":40602},{\"end\":40827,\"start\":40822},{\"end\":40839,\"start\":40835},{\"end\":41084,\"start\":41079},{\"end\":41098,\"start\":41093},{\"end\":41100,\"start\":41099},{\"end\":41113,\"start\":41109},{\"end\":41921,\"start\":41914},{\"end\":41935,\"start\":41930},{\"end\":41952,\"start\":41946},{\"end\":42375,\"start\":42374},{\"end\":42391,\"start\":42382},{\"end\":42622,\"start\":42617},{\"end\":42639,\"start\":42632},{\"end\":42641,\"start\":42640},{\"end\":42654,\"start\":42647},{\"end\":42673,\"start\":42664},{\"end\":42686,\"start\":42679},{\"end\":42702,\"start\":42697},{\"end\":42717,\"start\":42709},{\"end\":42728,\"start\":42724},{\"end\":42744,\"start\":42736},{\"end\":42760,\"start\":42759},{\"end\":42984,\"start\":42981},{\"end\":43001,\"start\":42995},{\"end\":43015,\"start\":43010},{\"end\":43029,\"start\":43026},{\"end\":43345,\"start\":43343},{\"end\":43357,\"start\":43353},{\"end\":43371,\"start\":43363},{\"end\":43380,\"start\":43376},{\"end\":43391,\"start\":43385}]", "bib_author_last_name": "[{\"end\":29184,\"start\":29176},{\"end\":29199,\"start\":29193},{\"end\":29515,\"start\":29508},{\"end\":29530,\"start\":29526},{\"end\":29544,\"start\":29539},{\"end\":29558,\"start\":29553},{\"end\":29816,\"start\":29810},{\"end\":29832,\"start\":29826},{\"end\":30233,\"start\":30229},{\"end\":30245,\"start\":30243},{\"end\":30515,\"start\":30511},{\"end\":30527,\"start\":30525},{\"end\":30541,\"start\":30537},{\"end\":30723,\"start\":30715},{\"end\":30737,\"start\":30732},{\"end\":30751,\"start\":30748},{\"end\":30764,\"start\":30757},{\"end\":30779,\"start\":30773},{\"end\":30795,\"start\":30788},{\"end\":30809,\"start\":30802},{\"end\":30824,\"start\":30816},{\"end\":30837,\"start\":30830},{\"end\":30851,\"start\":30847},{\"end\":30858,\"start\":30853},{\"end\":31330,\"start\":31325},{\"end\":31346,\"start\":31339},{\"end\":31363,\"start\":31355},{\"end\":31724,\"start\":31715},{\"end\":31741,\"start\":31733},{\"end\":31760,\"start\":31750},{\"end\":31764,\"start\":31762},{\"end\":32149,\"start\":32144},{\"end\":32163,\"start\":32158},{\"end\":32180,\"start\":32172},{\"end\":32501,\"start\":32495},{\"end\":32519,\"start\":32508},{\"end\":32525,\"start\":32521},{\"end\":32858,\"start\":32851},{\"end\":32880,\"start\":32867},{\"end\":32896,\"start\":32890},{\"end\":32917,\"start\":32906},{\"end\":32931,\"start\":32926},{\"end\":32946,\"start\":32939},{\"end\":32958,\"start\":32953},{\"end\":33560,\"start\":33550},{\"end\":33584,\"start\":33578},{\"end\":33840,\"start\":33837},{\"end\":33854,\"start\":33850},{\"end\":33866,\"start\":33864},{\"end\":33878,\"start\":33876},{\"end\":33891,\"start\":33889},{\"end\":34171,\"start\":34168},{\"end\":34184,\"start\":34179},{\"end\":34202,\"start\":34195},{\"end\":34419,\"start\":34417},{\"end\":34430,\"start\":34426},{\"end\":34445,\"start\":34440},{\"end\":34458,\"start\":34455},{\"end\":34466,\"start\":34464},{\"end\":34481,\"start\":34477},{\"end\":34813,\"start\":34807},{\"end\":34837,\"start\":34826},{\"end\":35221,\"start\":35219},{\"end\":35235,\"start\":35230},{\"end\":35251,\"start\":35243},{\"end\":35508,\"start\":35501},{\"end\":35523,\"start\":35516},{\"end\":35537,\"start\":35531},{\"end\":35972,\"start\":35964},{\"end\":35990,\"start\":35980},{\"end\":36307,\"start\":36303},{\"end\":36323,\"start\":36309},{\"end\":36577,\"start\":36573},{\"end\":36591,\"start\":36587},{\"end\":36805,\"start\":36799},{\"end\":36815,\"start\":36811},{\"end\":36824,\"start\":36817},{\"end\":37040,\"start\":37023},{\"end\":37049,\"start\":37044},{\"end\":37063,\"start\":37059},{\"end\":37079,\"start\":37074},{\"end\":37086,\"start\":37081},{\"end\":37274,\"start\":37269},{\"end\":37287,\"start\":37283},{\"end\":37303,\"start\":37295},{\"end\":37523,\"start\":37520},{\"end\":37778,\"start\":37770},{\"end\":38238,\"start\":38227},{\"end\":38255,\"start\":38248},{\"end\":38274,\"start\":38267},{\"end\":38284,\"start\":38276},{\"end\":38530,\"start\":38525},{\"end\":38543,\"start\":38532},{\"end\":38797,\"start\":38788},{\"end\":38810,\"start\":38801},{\"end\":38822,\"start\":38814},{\"end\":38832,\"start\":38826},{\"end\":38843,\"start\":38836},{\"end\":38853,\"start\":38847},{\"end\":38864,\"start\":38857},{\"end\":38880,\"start\":38868},{\"end\":38889,\"start\":38884},{\"end\":38900,\"start\":38893},{\"end\":38914,\"start\":38904},{\"end\":38924,\"start\":38918},{\"end\":38938,\"start\":38928},{\"end\":38949,\"start\":38942},{\"end\":38959,\"start\":38953},{\"end\":38972,\"start\":38963},{\"end\":39370,\"start\":39356},{\"end\":39557,\"start\":39551},{\"end\":39582,\"start\":39569},{\"end\":39596,\"start\":39589},{\"end\":39617,\"start\":39603},{\"end\":39903,\"start\":39896},{\"end\":39913,\"start\":39905},{\"end\":40137,\"start\":40131},{\"end\":40153,\"start\":40146},{\"end\":40169,\"start\":40162},{\"end\":40181,\"start\":40176},{\"end\":40581,\"start\":40574},{\"end\":40600,\"start\":40590},{\"end\":40618,\"start\":40610},{\"end\":40833,\"start\":40828},{\"end\":40846,\"start\":40840},{\"end\":41091,\"start\":41085},{\"end\":41107,\"start\":41101},{\"end\":41121,\"start\":41114},{\"end\":41928,\"start\":41922},{\"end\":41944,\"start\":41936},{\"end\":41960,\"start\":41953},{\"end\":42380,\"start\":42376},{\"end\":42401,\"start\":42392},{\"end\":42408,\"start\":42403},{\"end\":42630,\"start\":42623},{\"end\":42645,\"start\":42642},{\"end\":42662,\"start\":42655},{\"end\":42677,\"start\":42674},{\"end\":42695,\"start\":42687},{\"end\":42707,\"start\":42703},{\"end\":42722,\"start\":42718},{\"end\":42734,\"start\":42729},{\"end\":42757,\"start\":42745},{\"end\":42768,\"start\":42761},{\"end\":42993,\"start\":42985},{\"end\":43008,\"start\":43002},{\"end\":43024,\"start\":43016},{\"end\":43037,\"start\":43030},{\"end\":43045,\"start\":43039},{\"end\":43351,\"start\":43346},{\"end\":43361,\"start\":43358},{\"end\":43374,\"start\":43372},{\"end\":43383,\"start\":43381},{\"end\":43395,\"start\":43392}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":29467,\"start\":29044},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":56610673},\"end\":29762,\"start\":29469},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":38027149},\"end\":30098,\"start\":29764},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":167816813},\"end\":30433,\"start\":30100},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2253131},\"end\":30711,\"start\":30435},{\"attributes\":{\"id\":\"b5\"},\"end\":31010,\"start\":30713},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3352400},\"end\":31317,\"start\":31012},{\"attributes\":{\"id\":\"b7\"},\"end\":31583,\"start\":31319},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":7624463},\"end\":32073,\"start\":31585},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":17576199},\"end\":32415,\"start\":32075},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":232184459},\"end\":32781,\"start\":32417},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":14255176},\"end\":33443,\"start\":32783},{\"attributes\":{\"id\":\"b12\"},\"end\":33754,\"start\":33445},{\"attributes\":{\"doi\":\"arXiv:1703.04247\",\"id\":\"b13\"},\"end\":34109,\"start\":33756},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":152778518},\"end\":34374,\"start\":34111},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":13907106},\"end\":34798,\"start\":34376},{\"attributes\":{\"doi\":\"arXiv:1511.06939\",\"id\":\"b16\"},\"end\":35155,\"start\":34800},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":10537313},\"end\":35491,\"start\":35157},{\"attributes\":{\"doi\":\"10.1007/s11257-017-9194-1\",\"id\":\"b18\"},\"end\":35904,\"start\":35493},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1981391},\"end\":36206,\"start\":35906},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":14032094},\"end\":36525,\"start\":36208},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":15000608},\"end\":36729,\"start\":36527},{\"attributes\":{\"doi\":\"arXiv:1609.02907\",\"id\":\"b22\"},\"end\":36998,\"start\":36731},{\"attributes\":{\"id\":\"b23\"},\"end\":37203,\"start\":37000},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":58370896},\"end\":37458,\"start\":37205},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":118748765},\"end\":37687,\"start\":37460},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":6278891},\"end\":38184,\"start\":37689},{\"attributes\":{\"id\":\"b27\"},\"end\":38450,\"start\":38186},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1400872},\"end\":38742,\"start\":38452},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":10659969},\"end\":39330,\"start\":38744},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":17265929},\"end\":39541,\"start\":39332},{\"attributes\":{\"doi\":\"arXiv:1205.2618\",\"id\":\"b31\"},\"end\":39890,\"start\":39543},{\"attributes\":{\"id\":\"b32\"},\"end\":40060,\"start\":39892},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":8047550},\"end\":40512,\"start\":40062},{\"attributes\":{\"id\":\"b34\"},\"end\":40770,\"start\":40514},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":28816020},\"end\":41004,\"start\":40772},{\"attributes\":{\"doi\":\"10.1145/1076034.1076111\",\"id\":\"b36\",\"matched_paper_id\":316030},\"end\":41835,\"start\":41006},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":9120907},\"end\":42280,\"start\":41837},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":153753127},\"end\":42613,\"start\":42282},{\"attributes\":{\"id\":\"b39\"},\"end\":42923,\"start\":42615},{\"attributes\":{\"doi\":\"10.1145/2934664\",\"id\":\"b40\",\"matched_paper_id\":251649227},\"end\":43279,\"start\":42925},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":209367845},\"end\":43682,\"start\":43281}]", "bib_title": "[{\"end\":29167,\"start\":29044},{\"end\":29500,\"start\":29469},{\"end\":29800,\"start\":29764},{\"end\":30220,\"start\":30100},{\"end\":30502,\"start\":30435},{\"end\":31056,\"start\":31012},{\"end\":31711,\"start\":31585},{\"end\":32136,\"start\":32075},{\"end\":32491,\"start\":32417},{\"end\":32841,\"start\":32783},{\"end\":34158,\"start\":34111},{\"end\":34406,\"start\":34376},{\"end\":35211,\"start\":35157},{\"end\":35954,\"start\":35906},{\"end\":36296,\"start\":36208},{\"end\":36566,\"start\":36527},{\"end\":37260,\"start\":37205},{\"end\":37510,\"start\":37460},{\"end\":37762,\"start\":37689},{\"end\":38521,\"start\":38452},{\"end\":38784,\"start\":38744},{\"end\":39354,\"start\":39332},{\"end\":40122,\"start\":40062},{\"end\":40820,\"start\":40772},{\"end\":41077,\"start\":41006},{\"end\":41912,\"start\":41837},{\"end\":42372,\"start\":42282},{\"end\":42979,\"start\":42925},{\"end\":43341,\"start\":43281}]", "bib_author": "[{\"end\":29186,\"start\":29169},{\"end\":29201,\"start\":29186},{\"end\":29517,\"start\":29502},{\"end\":29532,\"start\":29517},{\"end\":29546,\"start\":29532},{\"end\":29560,\"start\":29546},{\"end\":29818,\"start\":29802},{\"end\":29834,\"start\":29818},{\"end\":30235,\"start\":30222},{\"end\":30247,\"start\":30235},{\"end\":30517,\"start\":30504},{\"end\":30529,\"start\":30517},{\"end\":30543,\"start\":30529},{\"end\":30725,\"start\":30715},{\"end\":30739,\"start\":30725},{\"end\":30753,\"start\":30739},{\"end\":30766,\"start\":30753},{\"end\":30781,\"start\":30766},{\"end\":30797,\"start\":30781},{\"end\":30811,\"start\":30797},{\"end\":30826,\"start\":30811},{\"end\":30839,\"start\":30826},{\"end\":30853,\"start\":30839},{\"end\":30860,\"start\":30853},{\"end\":31332,\"start\":31319},{\"end\":31348,\"start\":31332},{\"end\":31365,\"start\":31348},{\"end\":31726,\"start\":31713},{\"end\":31743,\"start\":31726},{\"end\":31762,\"start\":31743},{\"end\":31766,\"start\":31762},{\"end\":32151,\"start\":32138},{\"end\":32165,\"start\":32151},{\"end\":32182,\"start\":32165},{\"end\":32503,\"start\":32493},{\"end\":32521,\"start\":32503},{\"end\":32527,\"start\":32521},{\"end\":32860,\"start\":32843},{\"end\":32882,\"start\":32860},{\"end\":32898,\"start\":32882},{\"end\":32919,\"start\":32898},{\"end\":32933,\"start\":32919},{\"end\":32948,\"start\":32933},{\"end\":32960,\"start\":32948},{\"end\":33562,\"start\":33544},{\"end\":33573,\"start\":33562},{\"end\":33586,\"start\":33573},{\"end\":33842,\"start\":33829},{\"end\":33856,\"start\":33842},{\"end\":33868,\"start\":33856},{\"end\":33880,\"start\":33868},{\"end\":33893,\"start\":33880},{\"end\":34173,\"start\":34160},{\"end\":34186,\"start\":34173},{\"end\":34204,\"start\":34186},{\"end\":34421,\"start\":34408},{\"end\":34432,\"start\":34421},{\"end\":34447,\"start\":34432},{\"end\":34460,\"start\":34447},{\"end\":34468,\"start\":34460},{\"end\":34483,\"start\":34468},{\"end\":34815,\"start\":34800},{\"end\":34839,\"start\":34815},{\"end\":35223,\"start\":35213},{\"end\":35237,\"start\":35223},{\"end\":35253,\"start\":35237},{\"end\":35510,\"start\":35493},{\"end\":35525,\"start\":35510},{\"end\":35539,\"start\":35525},{\"end\":35974,\"start\":35956},{\"end\":35992,\"start\":35974},{\"end\":36309,\"start\":36298},{\"end\":36325,\"start\":36309},{\"end\":36579,\"start\":36568},{\"end\":36593,\"start\":36579},{\"end\":36807,\"start\":36797},{\"end\":36817,\"start\":36807},{\"end\":36826,\"start\":36817},{\"end\":37042,\"start\":37021},{\"end\":37051,\"start\":37042},{\"end\":37065,\"start\":37051},{\"end\":37081,\"start\":37065},{\"end\":37088,\"start\":37081},{\"end\":37276,\"start\":37262},{\"end\":37289,\"start\":37276},{\"end\":37305,\"start\":37289},{\"end\":37525,\"start\":37512},{\"end\":37780,\"start\":37764},{\"end\":38240,\"start\":38225},{\"end\":38257,\"start\":38240},{\"end\":38276,\"start\":38257},{\"end\":38286,\"start\":38276},{\"end\":38532,\"start\":38523},{\"end\":38545,\"start\":38532},{\"end\":38799,\"start\":38786},{\"end\":38812,\"start\":38799},{\"end\":38824,\"start\":38812},{\"end\":38834,\"start\":38824},{\"end\":38845,\"start\":38834},{\"end\":38855,\"start\":38845},{\"end\":38866,\"start\":38855},{\"end\":38882,\"start\":38866},{\"end\":38891,\"start\":38882},{\"end\":38902,\"start\":38891},{\"end\":38916,\"start\":38902},{\"end\":38926,\"start\":38916},{\"end\":38940,\"start\":38926},{\"end\":38951,\"start\":38940},{\"end\":38961,\"start\":38951},{\"end\":38974,\"start\":38961},{\"end\":39372,\"start\":39356},{\"end\":39559,\"start\":39543},{\"end\":39584,\"start\":39559},{\"end\":39598,\"start\":39584},{\"end\":39619,\"start\":39598},{\"end\":39905,\"start\":39894},{\"end\":39915,\"start\":39905},{\"end\":40139,\"start\":40124},{\"end\":40155,\"start\":40139},{\"end\":40171,\"start\":40155},{\"end\":40183,\"start\":40171},{\"end\":40583,\"start\":40564},{\"end\":40602,\"start\":40583},{\"end\":40620,\"start\":40602},{\"end\":40835,\"start\":40822},{\"end\":40848,\"start\":40835},{\"end\":41093,\"start\":41079},{\"end\":41109,\"start\":41093},{\"end\":41123,\"start\":41109},{\"end\":41930,\"start\":41914},{\"end\":41946,\"start\":41930},{\"end\":41962,\"start\":41946},{\"end\":42382,\"start\":42374},{\"end\":42403,\"start\":42382},{\"end\":42410,\"start\":42403},{\"end\":42632,\"start\":42617},{\"end\":42647,\"start\":42632},{\"end\":42664,\"start\":42647},{\"end\":42679,\"start\":42664},{\"end\":42697,\"start\":42679},{\"end\":42709,\"start\":42697},{\"end\":42724,\"start\":42709},{\"end\":42736,\"start\":42724},{\"end\":42759,\"start\":42736},{\"end\":42770,\"start\":42759},{\"end\":42995,\"start\":42981},{\"end\":43010,\"start\":42995},{\"end\":43026,\"start\":43010},{\"end\":43039,\"start\":43026},{\"end\":43047,\"start\":43039},{\"end\":43353,\"start\":43343},{\"end\":43363,\"start\":43353},{\"end\":43376,\"start\":43363},{\"end\":43385,\"start\":43376},{\"end\":43397,\"start\":43385}]", "bib_venue": "[{\"end\":29249,\"start\":29201},{\"end\":29596,\"start\":29560},{\"end\":29895,\"start\":29834},{\"end\":30250,\"start\":30247},{\"end\":30554,\"start\":30543},{\"end\":31130,\"start\":31058},{\"end\":31414,\"start\":31365},{\"end\":31812,\"start\":31766},{\"end\":32228,\"start\":32182},{\"end\":32584,\"start\":32527},{\"end\":33058,\"start\":32960},{\"end\":33542,\"start\":33445},{\"end\":33827,\"start\":33756},{\"end\":34224,\"start\":34204},{\"end\":34549,\"start\":34483},{\"end\":34957,\"start\":34855},{\"end\":35304,\"start\":35253},{\"end\":35667,\"start\":35564},{\"end\":36038,\"start\":35992},{\"end\":36342,\"start\":36325},{\"end\":36611,\"start\":36593},{\"end\":36795,\"start\":36731},{\"end\":37019,\"start\":37000},{\"end\":37313,\"start\":37305},{\"end\":37557,\"start\":37525},{\"end\":37866,\"start\":37780},{\"end\":38223,\"start\":38186},{\"end\":38581,\"start\":38545},{\"end\":39010,\"start\":38974},{\"end\":39422,\"start\":39372},{\"end\":39691,\"start\":39634},{\"end\":39966,\"start\":39915},{\"end\":40249,\"start\":40183},{\"end\":40562,\"start\":40514},{\"end\":40871,\"start\":40848},{\"end\":41264,\"start\":41146},{\"end\":42023,\"start\":41962},{\"end\":42430,\"start\":42410},{\"end\":43073,\"start\":43062},{\"end\":43463,\"start\":43397},{\"end\":29943,\"start\":29897},{\"end\":31189,\"start\":31132},{\"end\":33143,\"start\":33060},{\"end\":34602,\"start\":34551},{\"end\":37955,\"start\":37868},{\"end\":40302,\"start\":40251},{\"end\":41404,\"start\":41266},{\"end\":42071,\"start\":42025}]"}}}, "year": 2023, "month": 12, "day": 17}