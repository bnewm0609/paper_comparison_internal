{"id": 257365525, "updated": "2023-11-04 13:46:30.26", "metadata": {"title": "OpenICL: An Open-Source Framework for In-context Learning", "authors": "[{\"first\":\"Zhenyu\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"YaoXiang\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Jiacheng\",\"last\":\"Ye\",\"middle\":[]},{\"first\":\"Jiangtao\",\"last\":\"Feng\",\"middle\":[]},{\"first\":\"Jingjing\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Yu\",\"last\":\"Qiao\",\"middle\":[]},{\"first\":\"Zhiyong\",\"last\":\"Wu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "In recent years, In-context Learning (ICL) has gained increasing attention and emerged as the new paradigm for large language model (LLM) evaluation. Unlike traditional fine-tuning methods, ICL instead adapts the pre-trained models to unseen tasks without any parameter updates. However, the implementation of ICL is sophisticated due to the diverse retrieval and inference methods involved, as well as the varying pre-processing requirements for different models, datasets, and tasks. A unified and flexible framework for ICL is urgently needed to ease the implementation of the aforementioned components. To facilitate ICL research, we introduce OpenICL, an open-source toolkit for ICL and LLM evaluation. OpenICL is research-friendly with a highly flexible architecture that users can easily combine different components to suit their needs. It also provides various state-of-the-art retrieval and inference methods to streamline the process of adapting ICL to cutting-edge research. The effectiveness of OpenICL has been validated on a wide range of NLP tasks, including classification, QA, machine translation, and semantic parsing. As a side-product, we found OpenICL to be an efficient yet robust tool for LLMs evaluation. OpenICL is released at https://github.com/Shark-NLP/OpenICL", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2303.02913", "mag": null, "acl": "2023.acl-demo.47", "pubmed": null, "pubmedcentral": null, "dblp": "conf/acl/WuWY0FXQ23", "doi": "10.18653/v1/2023.acl-demo.47"}}, "content": {"source": {"pdf_hash": "a55dfc1482c9fa32859d1e8e8c5813f5a22982cc", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.02913v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "b6375983812fb46c5cb2b25540609770b95046d4", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a55dfc1482c9fa32859d1e8e8c5813f5a22982cc.txt", "contents": "\nOpenICL: An Open-Source Framework for In-context Learning\n\n\nZhenyu Wu \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\nYaoxiang Wang wangyaoxiang@pjlab.org.cnfengjiangtao \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\n\u2663 \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\nJiacheng Ye \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\n\u2660 \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\nJiangtao Feng \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\n\u2666 \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\nJingjing Xu \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\n\u2666 \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\nYu Qiao \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\nZhiyong Wu wuzhiyong@pjlab.org.cn \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\n\u2666 \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\n\u2666 Shanghai \nAI Laboratory East China Normal University \u2663 Xiamen University\nThe University of Hong Kong\n\n\nOpenICL: An Open-Source Framework for In-context Learning\nOpenICL is released at https://github. com/Shark-NLP/OpenICL.\nIn recent years, In-context Learning (ICL) has gained increasing attention and emerged as the new paradigm for large language model (LLM) evaluation. Unlike traditional finetuning methods, ICL instead adapts the pretrained models to unseen tasks without any parameter updates. However, the implementation of ICL is sophisticated due to the diverse retrieval and inference methods involved, as well as the varying pre-processing requirements for different models, datasets, and tasks. A unified and flexible framework for ICL is urgently needed to ease the implementation of the aforementioned components. To facilitate ICL research, we introduce OpenICL, an open-source toolkit for ICL and LLM evaluation. OpenICL is research-friendly with a highly flexible architecture that users can easily combine different components to suit their needs. It also provides various state-of-theart retrieval and inference methods to streamline the process of adapting ICL to cuttingedge research. The effectiveness of OpenICL has been validated on a wide range of NLP tasks, including classification, QA, machine translation, and semantic parsing. As a sideproduct, we found OpenICL to be an efficient yet robust tool for LLMs evaluation. et al. 2021.Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.\n\nIntroduction\n\nThe rise of large language models (LLMs) (Brown et al., 2020;Zhang et al., 2022a;Scao et al., 2022) has shown impressive emergent In-Context Learning (ICL) ability (Wei et al., 2022a). Different from finetuning which requires parameter updates, ICL can perform inference with model parameters frozen. ICL sidesteps the resource-intensive nature of fine-tuning, yet still yields comparable results to fine-tuned models in specific tasks Lu et al., 2022;Gao et al., 2021a). However, we observed a lack of a unified framework for ICL. Implementations from existing projects are often high-customized to their own needs, thus making further development and comparisons with previous approaches a challenge.\n\nThe basic ICL pipeline contains two steps: retrieval and inference. Given a testing input X , in the retrieval stage, several examples from the training set are retrieved as in-context demonstrations. In the inference stage, these demonstrations are prepended before X and fed into the LLM to generate the prediction. Researchers have explored various methods for both retrieval(e.g., BM25 (Robertson and Zaragoza, 2009), TopK (Liu et al., 2022;Gao et al., 2021a) and VoteK (Su et al., 2022)) and inference(e.g., perplexity-based (Brown et al., 2020), channel-based , and Chain-of-thoughts (Wei et al., 2022b)). However, these methods are often implemented under different frameworks, and/or evaluated using different LLMs and tasks. These inconsistencies make systematic evaluations and comparisons of various methods challenging, thus hindering the development of better ICL methods.\n\nTo address this issue, we present OpenICL, an open-source and easy-to-use toolkit for ICL. OpenICL has many state-of-the-art retrieval and inference methods built in to facilitate systematic comparison and fast research prototyping. OpenICL also provides a unified and flexible interface for the development and evaluation of new ICL methods. Users can easily incorporate different retrieval and inference methods, as well as different prompt instructions, into their pipelines. To validate OpenICL's implementation and design, we use OpenICL to evaluate LLMs on several NLP tasks, including classification, question answering, translation, and semantic parsing. Our contributions are summarized as follows:\n\n\u2022 We propose OpenICL, an easy-to-use and extensible ICL framework for zero-/few-shot evaluation of language models\n\n\u2022 OpenICL provides a wide range of ICL methods, LLMs, and tasks, requiring as little as a few lines of code to use and paving the way for more extensions in the future.\n\n\u2022 We provide complete tutorials to walk users through the framework, thus facilitating research and development of ICL.\n\n\nRelated Work\n\nIn-context Learning Besides the classic \"pretrain and fine-tune\" paradigm, Brown et al. (2020) proposed In-context learning (ICL), a new paradigm that leverages pre-trained language models to perform new tasks without any gradientbased training. It appends a small number of training examples as prompts before the test input, and have shown to be able to improve LLMs' performance in few-shot scenarios and generalize to a wide range of downstream tasks, such as information retrieval (Tay et al., 2022), fact checking (Rae et al., 2021), commonsense reasoning (Geva et al., 2021), arithmetic reasoning (Cobbe et al., 2021), machine trainslation (Agrawal et al., 2022;Lin et al., 2021a), and data generation , etc. Aside from those early successes, researchers have developed more sophisticated ICL methods that require some intermediate reasoning steps. Among them, chain-of-thoughts (CoT) is the first attempt that significantly surpasses the previous state-of-the-art methods on many reasoning tasks (Wei et al., 2022b). After that, different variants of CoT have been proposed to strengthen its performance, such as Self-Ask (Press et al., 2022), iCAP , Least-to-Most prompting (Zhou et al., 2022), and Selection-Inference (Zhang et al., 2022b;Fu et al., 2022).\n\nDespite the surprising performance, ICL has been criticized for being very sensitive to the choice and ordering of in-context examples Lu et al., 2022). To address this problem, different criterion and context construction methods have been proposed. Gao et al. (2021a) and Liu et al. (2022) select examples that are closer to the test input in the embedding space; a line of work (Su et al., 2022;Levy et al., 2022;Ye et al., 2023) select the most representative examples in the training set to encourage diversity of in-context examples;  observe that Minimum Description Length (MDL) principle can be an effective criterion for in-context example selection.\n\nPrompt Learning Prompt learning ) is a special case of ICL without any incontext examples. Prompt learning comprises various topics including manual template engineering (Petroni et al., 2019;Brown et al., 2020), automated template learning (Wallace et al., 2019;Shin et al., 2020;Li and Liang, 2021), and answer engineering (Gao et al., 2021b;Schick and Sch\u00fctze, 2021). We refer the readers to the usage of Open-Prompt (Ding et al., 2021) which is a toolkit specially designed for prompt learning. In comparison, OpenICL focuses more on integrating various exemplar retrieving approaches and inference strategies for in-context learning. Note that OpenICL can also seamlessly support prompt learning by setting the number of in-context examples to zero and specifying the manual or pre-searched prompt templates by OpenPrompt for different tasks.\n\n\nOpenICL\n\nIn this section, we first explain OpenICL's design principles. Then, we will briefly describe OpenICL's two major components, namely, the Retriever and Inferencer.\n\n\nDesign Principles\n\nThe design principle of OpenICL is to facilitate incontext learning research and enable efficient and robust large language model evaluation. In detail, we consider the following principles:\n\n[P1: Modularity] Since ICL is a fast-evolving research field, the design of OpenICL should be decoupled such that different components can be easily modified to support latest methods and/or combined to suit various tasks and application needs.\n\n[P2: Efficiency] Nowadays, large language models can have hundreds of billions of parameters. To support inference at such a massive scale, OpenICL should be optimized to enable efficient parallel inference.\n\n[P3: Generality] ICL has been widely used in all fields in NLP, so OpenICL needs a flexible interface that enables it to work with various LLMs, tasks, retrieval methods, and inference approaches.\n\n\nRetriever\n\n\nIndex Set\n\n( , ) Figure 1: Overview of the architecture in OpenICL. OpenICL first obtains proper in-context examples from an index set for each test input or for the whole test set via retrieval methods (e.g., TopK or VoteK) specified by the users. Then the in-context examples and test input are concatenated into a single sequence based on the provided prompt template. Finally, all the prompts are fed into the language model to infer the output through defined inference strategies (e.g., Chain-of-thought). These examples, as well asx, are then formatted according to the userdefined prompt template and concatenated to form a text sequence. After that, the Inferencer digests these sequences and fed them into the LLMs to obtain the model prediction\u0176 .\n\n\nPromptTemplate\n\n\nInferencer\nLM \ufffd \ufffd ( , ) \ufffd \ufffd \ufffd j \u2026 \ufffd 22 \u2026 \ufffd 1 \u2026 in-context examples input Test Set \u2026 \u2026 \u2026 \u2026\n\nArchitecture Overview\n\n\nModularity\n\nTo satisfy Principle P1, OpenICL adopts a looselycoupled design between components. These components separate the data pre-processing, retrieval, and inference processes with very flexible interfaces that allow easy customization to fit specific needs. Two major components are detailed below:\n\nRetriever Retriever is responsible for retrieving in-context examples from the pre-existing training data. This module supports both corpuslevel (i.e., only retrieving one group of examples for the whole test set) and instance-level (i.e., retrieving examples for each testing input individually) retrieval methods. OpenICL primarily supports learning-free retrieval methods as follows:\n\n\u2022 Random: Early practice (Brown et al., 2020) of ICL often randomly select examples to construct the context. Although Random brings high variance for ICL performance, it is still the popular choice when there are only a few demonstrations available (Wei et al., 2022b;.\n\n\u2022 Heuristic method: To overcome the disadvantage of Random, various semantic similarity based retrieval methods have been proposed and shown great promise, such as BM25 (Robertson and Zaragoza, 2009), TopK (Liu et al., 2022;Gao et al., 2021a), and VoteK (Su et al., 2022).\n\n\u2022 Model-based method: More recently, researchers have explored using models' confidence in the output to select and order examples, such as entropy (Lu et al., 2022) and MDL .\n\nOpenICL has implemented the existing methods above to facilitate future research and systematic comparison. Furthermore, the flexibility of the Retriever module allows practitioners to select the retrieval method and make further modification that best suits their task and data. The interface of Retriever also allows users to pack those in-context examples and use them somewhere else.\n\nInferencer Inferencer invokes the pretrained language model to generate predictions based on the concatenation of in-context examples and testing input. The Inferencer supports various inference methods:\n\n\u2022 Direct: Brown et al. (2020) use tokens in the vocabulary to represent candidate answers and select the final prediction using the one with the highest probability.\n\n\u2022 Perplexity: (Brown et al., 2020) compute the sentence perplexity of the sequence concatenation of input and candidate answers and select the final prediction using the one with the lowest perplexity.\n\n\u2022 Channel:  proposed to utilize channel models (Yu et al., 2016;Yee et al., 2019) to compute the conditional probability in a reversed direction, i.e., estimating the likelihood of input query given the label.\n\nThe flexibility of Inferencer also allows users to recursively invoke it to support multi-stage ICL methods, such as chain-of-thought (Wei et al., 2022b) and selection-inference (Creswell et al., 2022). Additionally, Inferencer can be augmented with a scorer to evaluate its prediction.\n\n\nEfficiency\n\nTo satisfy Principle P2, we equip OpenICL with various parallelism techniques to enable efficient inference for large-scale models.\n\nData Parallel Data parallel (Li et al., 2020) is a common technique used in parallel computing to improve the efficiency of large-scale computation tasks. OpenICL implements data parallelism to improve the performance of both the retrieval and inference steps. During retrieval and inference, data is divided into smaller batches for processing. Additionally, for models that can fit into GPU's VRAM, OpenICL implements data parallelism by sharding the data across multiple GPUs and performing parallel inference on each GPU with a complete copy of the model. This significantly increases the inference speed when working with large datasets.\n\nModel Parallel In the era of LLMs, models often have billions or hundreds of billions of parameters that exceed modern GPUs' capacity. To handle this problem, we resort to model parallel : a parallel computing technique that divides a large deep learning model into smaller sub-models, each of which can be run on a separate GPU. OpenICL supports model parallelism that users can easily parallelize their models with minimal modification to the code. Currently, we support Megatron  and Zero (Rajbhandari et al., 2019).\n\n\nGenerality\n\nTo satisfy Principle P3, OpenICL is designed to maximize users' productivity by supporting a wide range of models, tasks, and methods:\n\n[Model] OpenICL supports both decoder-only LMs (e.g., GPT family (Radford and Narasimhan, 2018;Radford et al., 2019;Black et al., 2021;Wang and Komatsuzaki, 2021;Black et al., 2022), and encoder-decoder-based LMs (e.g., T5 (Raffel et al., 2020)). We also provide two alternatives for accessing the model: users can directly load model checkpoints for evaluation or access a model via API (e.g., OpenAI's GPT-3 series models; Brown et al. 2020;Chen et al. 2021;Ouyang et al.). 1\n\n[Tasks] With the help of OpenICL, users can easily conduct experiments on both classification and generation tasks. OpenICL integrates Hugging-Face's datasets 2 such that users can access and download thousands of NLP tasks with ease.\n\n[Methods] As aforementioned, OpenICL provides broad support for ICL methods that cover both retrieval and inference. Furthermore, OpenICL offers the flexibility to return the results of the Retriever and Inferencer in a stepby-step manner, making it easy to integrate these intermediate results into other projects.\n\n\nToolkit Walkthrough\n\nIn this section, we demonstrate OpenICL by walking readers through several typical ICL use cases.\n\nExample 1. We first demonstrate how to use OpenICL to develop a typical ICL pipeline for language classification using a few lines of code and conduct evaluation on the popular sentiment classification dataset SST-2 (Socher et al., 2013). As shown in Figure 2, the pipeline begins with a DatasetReader which loads the dataset given its name on HuggingFace Dataset Hub 3 or local file path. Users need to specify the names of columns where the input (\"text\") and output (\"label\") are stored. Secondly, a customized PromptTemplate is instantiated with a dictionary that defines the prompts for each class label. The placeholder </E> and </Q> will be replaced by in-context examples and testing input, separately. After that, we initiate the retriever based on TopK (Liu et al., 2022) and set the number of in-context examples to 8 (\"ice_num = 8\"). We select perplexity-based method to initiate the inferencer and use GPT2-XL as the LLM. Having 1 from openicl import DatasetReader, PromptTemplate 2 from openicl import TopkRetriever, PPLInferencer, AccEvaluator 3 4 # Load dataset 5 data = DatasetReader('gpt3mix/sst2', input_columns= ['text'], output_column='label') 6 7 # Define the prompt template for the task 8 tp_dict = { 0: '</E> Positive Movie Review: </Q>', 9 1: '</E> Negative Movie Review: </Q>' } 10 template = PromptTemplate(tp_dict, {'text':'</Q>'}, ice_token='</E>') 11 12 # Initiate the retriever and inferencer 13 retriever = TopkRetriever(data, ice_num=8) 14 inferencer = PPLInferencer(model_name='gpt2-xl') 15 16 # Run inference and calculate score 17 predictions = inferencer.inference(retriever, ice_template=template) 18 score = AccEvaluator().score(predictions=predictions, references=data.references) Figure 2: Illustration of Example 1 which evaluates the ICL performance of GPT2-XL (1.5B) on SST-2 dataset with PPL inference strategy. 1 from datasets import load_dataset 2 from openicl import DatasetReader, PromptTemplate 3 from openicl import RandomRetriever, GenInferencer, BleuEvaluator  all these been set, we can run the inference by invoking the inferencer (line 17) and calculating the accuracy of the model's prediction(line 18).\n\nExample 2. Figure 3 shows how to use OpenICL to work with generation problems. We consider the popular machine translation dataset WMT16 (Bojar et al., 2016). As in Example 1, we can easily load the dataset, define the prompt template, and initiate the retriever, by feeding new parameters to the function, respectively. The major API difference from Example 1 is that (i) we add some pre-processing for the translation task (line 5); (ii) PPLInferencer is replaced by inferencer tailored for generation (line 16); (iii) we use BLEU to evaluate model performance.\n\nExample 3. OpenICL also supports more advanced ICL methods, as shown in Figure 4. Users can seamlessly switch to CoT by only modifying two lines of code: line 14 defines the template for CoT and line 15 initiates the inferencer with GPT3 using OpenAI's API. Similar multi-step ICL methods such as Self-Consistency  and Selection-Inference (Creswell et al., 2022) can also be easily implemented by inheriting the superclass Inferencer designed in OpenICL.\n\n\nEvaluation\n\nTo demonstrate OpenICL's flexibility we conducted experiments on a diverse set of datasets, LLMs, and ICL methods. We consider PiQA (Bisk et al., 2019) for commonsense reasoning, SST-2 (Socher et al., 2013) for sentiment analysis, GSM8K (Cobbe et al., 2021) for arithmetic reasoning, WMT16 de-en (Bojar et al., 2016) for machine translation and Gigaword (Napoles et al., 2012) for summarization. We've also tested various LLMs, including GPT-Neo (2.7B) (Black et al., 2021;Gao et al., 2020), text-davinci-003 version of GPT-3 (175B), and XGLM (7.5B) (Lin et al., 2021b). We use Ope-nAI's official API 4 to access GPT-3. The detailed setups and results are shown in Figure 5. As we can see, components of OpenICL can be easily chained to support different evaluation needs and replicate results of state-of-the-art methods.\n\n\nConclusion\n\nWe present OpenICL, an open-source toolkit for In-context learning. OpenICL provides a convenient and flexible interface for in-context learning practice and research. Our modular design allows it to support a wide range of LLMs, tasks, and ICL methods with ease. We implement both model parallelism and data parallelism to make inference of large models more efficient. OpenICL is highly extensible, and we will continue to update it to keep pace with the latest research. Despite the promising results, ICL is still in its early stages, and many challenges remain. We believe OpenICL will be a valuable resource for researchers and practitioners to facilitate their research and development.\n\nFigure 1 overviews\n1OpenICL's architecture. For each inputx from the test setX, the Retriever retrieves several (x, y) pairs (represented as one row in the dashed box) from an index set (X, Y ) asx's in-context examples.\n\n4 5Figure 3 :Figure 4 :\n434dataset = load_dataset(\"wmt16\", 'de-en').map(lambda example: example['translation']) 6 7 data = DatasetReader(dataset, input_columns=['de'], output_column='en') 8 9 template = PromptTemplate('</E> German:</German> \\n English: </English>', 10 {'de':'</German>', 'en':'</English>'}, ice_token='</E>') 11 12 retriever = TopkRetriever(data, ice_num=8) 13 14 # Inference by direct generation 15 inferencer = GenInferencer(model_name='facebook/xglm-7.5B') 16 predictions = inferencer.inference(retriever, ice_template=template) 17 18 # calculate Bleu 19 score = BleuEvaluator().score(predictions=predictions, references=data.references) Illustration of Example 2 that evaluates the ICL performance of XGLM (7.5B) on WMT16 (de-en) dataset with direct inference strategy.1 from openicl import DatasetReader, PromptTemplate, Inference by Chain-of-Thought 13 cot_list=[\"Let's think step by step.\", 14 \"\\nTherefore, the answer (arabic numerals) is\"] 15 16 inferencer = CoTInferencer(cot_list=cot_list, api_name='gpt3') 17 predictions = inferencer.inference(retriever, ice_template=template) Illustration of Example 3, which evaluates the ICL performance of text-davinci-003 version of GPT-3 (175B) on GSM8K dataset with Chain-of-thought inference strategy.\n\n\nFigure 5: Evaluation results. We conduct experiments on five representative tasks with OpenICL and use different retrievers, inferencers, language models, and other components. In terms of model usage, we adopt GPT-Neo (2.7B) for SST2, PiQA, and Gigaword, XGLM (7.5B) for WMT16(de-en), and text-davinci-003 version of GPT-3 (175B) for GSM8K.Retriever \n\nInferencer \nLM \nMetric \n\nRandom \n\nTopK \n\nMDL \n\nDirect \n\nChannel \n\nPPL \n\nCoT \n\nGPT2 \n\n\u2026 \n\nGPT3 \n\nXGLM \n\nT5 \n\nWMT16 (de-en) \n\nPiQA \nSST2 \n\nGigaword \n\nGSM8K \n\n75.51 \n\n90.61 \n\n58.15 \n\n32.87 \n\n13.95 \n\n\u2026 \n\nAccuracy \n\nBleu \n\nRouge-L \n\n\u2026 \n\u2026 \n\n\nhttps://openai.com/api/ 2 https://github.com/huggingface/datasets 3 https://huggingface.co/datasets\nhttps://openai.com/api/\n\nTraining verifiers to solve math word problems. Christopher Nakano, John Hesse, Schulman, arXiv:2110.14168arXiv preprintNakano, Christopher Hesse, and John Schulman. 2021. Training verifiers to solve math word prob- lems. arXiv preprint arXiv:2110.14168.\n\nAntonia Creswell, Murray Shanahan, Irina Higgins, 10.48550/arXiv.2205.09712arXiv:2205.09712Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning. arXiv e-prints. Antonia Creswell, Murray Shanahan, and Irina Higgins. 2022. Selection-Inference: Exploiting Large Lan- guage Models for Interpretable Logical Reasoning. arXiv e-prints, page arXiv:2205.09712.\n\nOpenPrompt: An Open-source Framework for Prompt-learning. Ning Ding, Shengding Hu, Weilin Zhao, Yulin Chen, Zhiyuan Liu, Hai-Tao Zheng, Maosong Sun, 10.48550/arXiv.2111.01998arXiv:2111.01998arXiv e-printsNing Ding, Shengding Hu, Weilin Zhao, Yulin Chen, Zhiyuan Liu, Hai-Tao Zheng, and Maosong Sun. 2021. OpenPrompt: An Open-source Frame- work for Prompt-learning. arXiv e-prints, page arXiv:2111.01998.\n\nComplexity-based prompting for multi-step reasoning. Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, Tushar Khot, abs/2210.00720CoRRYao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2022. Complexity-based prompting for multi-step reasoning. CoRR, abs/2210.00720.\n\nLeo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, arXiv:2101.00027The pile: An 800gb dataset of diverse text for language modeling. arXiv preprintLeo Gao, Stella Biderman, Sid Black, Laurence Gold- ing, Travis Hoppe, Charles Foster, Jason Phang, Ho- race He, Anish Thite, Noa Nabeshima, et al. 2020. The pile: An 800gb dataset of diverse text for lan- guage modeling. arXiv preprint arXiv:2101.00027.\n\nMaking pre-trained language models better few-shot learners. Tianyu Gao, Adam Fisch, Danqi Chen, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Tianyu Gao, Adam Fisch, and Danqi Chen. 2021a. Making pre-trained language models better few-shot learners. In Proceedings of the 59th Annual Meet- ing of the Association for Computational Linguistics and the 11th International Joint Conference on Nat- ural Language Processing (Volume 1: Long Papers), pages 3816-3830.\n\nMaking pre-trained language models better few-shot learners. Tianyu Gao, Adam Fisch, Danqi Chen, 10.18653/v1/2021.acl-long.295Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Tianyu Gao, Adam Fisch, and Danqi Chen. 2021b. Making pre-trained language models better few-shot learners. In Proceedings of the 59th Annual Meet- ing of the Association for Computational Linguistics and the 11th International Joint Conference on Nat- ural Language Processing (Volume 1: Long Papers), pages 3816-3830, Online. Association for Computa- tional Linguistics.\n\nMor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, Jonathan Berant, 10.48550/arXiv.2101.02235arXiv:2101.02235Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies. arXiv e-prints. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. 2021. Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies. arXiv e-prints, page arXiv:2101.02235.\n\nItay Levy, Ben Bogin, Jonathan Berant, arXiv:2212.06800Diverse demonstrations improve in-context compositional generalization. arXiv preprintItay Levy, Ben Bogin, and Jonathan Berant. 2022. Diverse demonstrations improve in-context compositional generalization. arXiv preprint arXiv:2212.06800.\n\nShen Li, Yanli Zhao, Rohan Varma, Omkar Salpekar, Pieter Noordhuis, Teng Li, Adam Paszke, Jeff Smith, Brian Vaughan, Pritam Damania, and Soumith Chintala. 2020. Pytorch distributed: Experiences on accelerating data parallel training. Shen Li, Yanli Zhao, Rohan Varma, Omkar Salpekar, Pieter Noordhuis, Teng Li, Adam Paszke, Jeff Smith, Brian Vaughan, Pritam Damania, and Soumith Chin- tala. 2020. Pytorch distributed: Experiences on ac- celerating data parallel training.\n\nPrefix-tuning: Optimizing continuous prompts for generation. Lisa Xiang, Percy Li, Liang, 10.18653/v1/2021.acl-long.353Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingOnline. Association for Computational Linguistics1Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Lan- guage Processing (Volume 1: Long Papers), pages 4582-4597, Online. Association for Computational Linguistics.\n\n. Todor Xi Victoria Lin, Mikel Mihaylov, Tianlu Artetxe, Shuohui Wang, Daniel Chen, Myle Simig, Naman Ott, Shruti Goyal, Jingfei Bhosale, Ramakanth Du, Sam Pasunuru, Punit Shleifer, Vishrav Singh Koura, Chaudhary, O&apos; Brian, Jeff Horo, Luke Wang, Zornitsa Zettlemoyer, Kozareva, Mona T. Diab, VeselinXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Na- man Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettle- moyer, Zornitsa Kozareva, Mona T. Diab, Veselin\n\nFew-shot learning with multilingual language models. Xian Stoyanov, Li, abs/2112.10668CoRRStoyanov, and Xian Li. 2021a. Few-shot learn- ing with multilingual language models. CoRR, abs/2112.10668.\n\nFew-shot learning with multilingual language models. Todor Xi Victoria Lin, Mikel Mihaylov, Tianlu Artetxe, Shuohui Wang, Daniel Chen, Myle Simig, Naman Ott, Shruti Goyal, Jingfei Bhosale, Ramakanth Du, Sam Pasunuru, Punit Shleifer, Vishrav Singh Koura, Chaudhary, O&apos; Brian, Jeff Horo, Luke Wang, Zornitsa Zettlemoyer, Mona T Kozareva, Veselin Diab, Xian Stoyanov, Li, abs/2112.10668CoRRXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Na- man Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettle- moyer, Zornitsa Kozareva, Mona T. Diab, Veselin Stoyanov, and Xian Li. 2021b. Few-shot learn- ing with multilingual language models. CoRR, abs/2112.10668.\n\nWhat makes good in-context examples for gpt-3?. Jiachang Liu, Dinghan Shen, Yizhe Zhang, B William, Lawrence Dolan, Weizhu Carin, Chen, The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. Dee-LIO 2022Proceedings of Deep Learning Inside OutJiachang Liu, Dinghan Shen, Yizhe Zhang, William B Dolan, Lawrence Carin, and Weizhu Chen. 2022. What makes good in-context examples for gpt-3? In Proceedings of Deep Learning Inside Out (Dee- LIO 2022): The 3rd Workshop on Knowledge Ex- traction and Integration for Deep Learning Architec- tures, pages 100-114.\n\nPretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig, abs/2107.13586CoRRPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre- train, prompt, and predict: A systematic survey of prompting methods in natural language processing. CoRR, abs/2107.13586.\n\nFantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, Pontus Stenetorp, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsLong Papers1Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2022. Fantastically ordered prompts and where to find them: Overcom- ing few-shot prompt order sensitivity. In Proceed- ings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Pa- pers), pages 8086-8098.\n\nNoisy channel language model prompting for few-shot text classification. Sewon Min, Mike Lewis, Hannaneh Hajishirzi, Luke Zettlemoyer, 10.18653/v1/2022.acl-long.365Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics1Long Papers)Sewon Min, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2022. Noisy channel language model prompting for few-shot text classification. In Proceedings of the 60th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 5316-5330, Dublin, Ireland. Association for Computational Linguistics.\n\nAnnotated Gigaword. Courtney Napoles, Matthew Gormley, Benjamin Van Durme, Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX). the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX)Montr\u00e9alCourtney Napoles, Matthew Gormley, and Benjamin Van Durme. 2012. Annotated Gigaword. In Pro- ceedings of the Joint Workshop on Automatic Knowl- edge Base Construction and Web-scale Knowledge Extraction (AKBC-WEKEX), pages 95-100, Mon- tr\u00e9al, Canada. Association for Computational Lin- guistics.\n\nTraining language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, Advances in Neural Information Processing Systems. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, et al. Training language models to follow instructions with human feedback. In Advances in Neural Infor- mation Processing Systems.\n\nAssociation for Computational Linguistics. Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller, 10.18653/v1/D19-1250Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaLanguage models as knowledge bases?Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. 2019. Language models as knowl- edge bases? In Proceedings of the 2019 Confer- ence on Empirical Methods in Natural Language Processing and the 9th International Joint Confer- ence on Natural Language Processing (EMNLP- IJCNLP), pages 2463-2473, Hong Kong, China. As- sociation for Computational Linguistics.\n\nMeasuring and narrowing the compositionality gap in language models. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, Mike Lewis, 10.48550/arXiv.2210.03350abs/2210.03350CoRROfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, and Mike Lewis. 2022. Measuring and narrowing the compositionality gap in language models. CoRR, abs/2210.03350.\n\nImproving language understanding by generative pretraining. Alec Radford, Karthik Narasimhan, Alec Radford and Karthik Narasimhan. 2018. Im- proving language understanding by generative pre- training.\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners.\n\nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George Van Den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat Mcaleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato, 10.48550/arXiv.2112.11446arXiv:2112.11446Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. 2021. Scaling Language Models: Methods, Analysis & Insights from Training Gopher. Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hechtman, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart, Simon OsinderoLaura Rimell, Chris DyerJeff Stanway. arXiv e-printsJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susan- nah Young, Eliza Rutherford, Tom Hennigan, Ja- cob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Mari- beth Rauh, Po-Sen Huang, Amelia Glaese, Jo- hannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, An- tonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Ne- matzadeh, Elena Gribovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cy- prien de Masson d'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake Hecht- man, Laura Weidinger, Iason Gabriel, William Isaac, Ed Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stan- way, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. 2021. Scal- ing Language Models: Methods, Analysis & In- sights from Training Gopher. arXiv e-prints, page arXiv:2112.11446.\n\nExploring the limits of transfer learning with a unified text-totext transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 21140Colin Raffel, Noam Shazeer, Adam Roberts, Kather- ine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to- text transformer. Journal of Machine Learning Re- search, 21(140):1-67.\n\nZero: Memory optimization towards training A trillion parameter models. Samyam Rajbhandari, Jeff Rasley, abs/1910.02054CoRROlatunji Ruwase, and Yuxiong HeSamyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. 2019. Zero: Memory optimization towards training A trillion parameter models. CoRR, abs/1910.02054.\n\nThe probabilistic relevance framework: Bm25 and beyond. Stephen Robertson, Hugo Zaragoza, 10.1561/1500000019Foundations and Trends\u00ae in Information Retrieval. 34Stephen Robertson and Hugo Zaragoza. 2009. The probabilistic relevance framework: Bm25 and be- yond. Foundations and Trends\u00ae in Information Re- trieval, 3(4):333-389.\n\n. Angela Teven Le Scao, Christopher Fan, Ellie Akiki, Suzana Pavlick, Daniel Ili\u0107, Roman Hesslow, Alexandra Sasha Castagn\u00e9, Fran\u00e7ois Luccioni, Matthias Yvon, Gall\u00e9, et al. 2022. Bloom: A 176b-parameter open-access multilingual language model. ArXiv preprint, abs/2211.05100Teven Le Scao, Angela Fan, Christopher Akiki, El- lie Pavlick, Suzana Ili\u0107, Daniel Hesslow, Ro- man Castagn\u00e9, Alexandra Sasha Luccioni, Fran\u00e7ois Yvon, Matthias Gall\u00e9, et al. 2022. Bloom: A 176b- parameter open-access multilingual language model. ArXiv preprint, abs/2211.05100.\n\nIt's not just size that matters: Small language models are also few-shot learners. Timo Schick, Hinrich Sch\u00fctze, 10.18653/v1/2021.naacl-main.185Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational LinguisticsTimo Schick and Hinrich Sch\u00fctze. 2021. It's not just size that matters: Small language models are also few-shot learners. In Proceedings of the 2021 Con- ference of the North American Chapter of the Asso- ciation for Computational Linguistics: Human Lan- guage Technologies, pages 2339-2352, Online. As- sociation for Computational Linguistics.\n\nAutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Taylor Shin, Yasaman Razeghi, Robert L Logan, I V , Eric Wallace, Sameer Singh, 10.18653/v1/2020.emnlp-main.346Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational LinguisticsTaylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. 2020. AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. In Proceed- ings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4222-4235, Online. Association for Computational Linguistics.\n\nMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick Legresley, Jared Casper, Bryan Catanzaro, 10.48550/arXiv.1909.08053arXiv:1909.08053Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism. arXiv e-prints. Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catan- zaro. 2019. Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Paral- lelism. arXiv e-prints, page arXiv:1909.08053.\n\nMegatron-lm: Training multi-billion parameter language models using model parallelism. Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick Legresley, Jared Casper, Bryan Catanzaro, abs/1909.08053CoRRMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catan- zaro. 2019. Megatron-lm: Training multi-billion pa- rameter language models using model parallelism. CoRR, abs/1909.08053.\n\nRecursive deep models for semantic compositionality over a sentiment treebank. Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, Christopher Potts, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingSeattle, Washington, USAAssociation for Computational LinguisticsRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment tree- bank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631-1642, Seattle, Washington, USA. Asso- ciation for Computational Linguistics.\n\nHongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, A Noah, Smith, arXiv:2209.01975Selective annotation makes language models better fewshot learners. arXiv preprintHongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A Smith, et al. 2022. Selec- tive annotation makes language models better few- shot learners. arXiv preprint arXiv:2209.01975.\n\nYi Tay, Q Vinh, Mostafa Tran, Jianmo Dehghani, Dara Ni, Harsh Bahri, Zhen Mehta, Kai Qin, Zhe Hui, Jai Zhao, Tal Gupta, William W Schuster, Donald Cohen, Metzler, 10.48550/arXiv.2202.06991arXiv:2202.06991Transformer Memory as a Differentiable Search Index. arXiv e-prints. Yi Tay, Vinh Q. Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, Tal Schuster, William W. Cohen, and Donald Metzler. 2022. Transformer Memory as a Differentiable Search Index. arXiv e-prints, page arXiv:2202.06991.\n\nUniversal adversarial triggers for attacking and analyzing NLP. Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh, 10.18653/v1/D19-1221Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)HongEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019. Universal adversarial trig- gers for attacking and analyzing NLP. In Proceed- ings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th Inter- national Joint Conference on Natural Language Pro- cessing (EMNLP-IJCNLP), pages 2153-2162, Hong\n\nAssociation for Computational Linguistics. China Kong, Kong, China. Association for Computational Lin- guistics.\n\nGPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. Ben Wang, Aran Komatsuzaki, Ben Wang and Aran Komatsuzaki. 2021. GPT- J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/ kingoflolz/mesh-transformer-jax.\n\nIteratively prompt pre-trained language models for chain of thought. Boshi Wang, Xiang Deng, Huan Sun, The 2022 Conference on Empirical Methods for Natural Language Processing. Boshi Wang, Xiang Deng, and Huan Sun. 2022. Itera- tively prompt pre-trained language models for chain of thought. In The 2022 Conference on Empirical Methods for Natural Language Processing.\n\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, 10.48550/arXiv.2203.11171arXiv:2203.11171Self-Consistency Improves Chain of Thought Reasoning in Language Models. arXiv e-prints. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022. Self-Consistency Improves Chain of Thought Reasoning in Language Models. arXiv e-prints, page arXiv:2203.11171.\n\nJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. arXiv preprintJason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022a. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682.\n\nChain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H Chi, Quoc Le, Denny Zhou, abs/2201.11903CoRRJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022b. Chain of thought prompting elicits reasoning in large language models. CoRR, abs/2201.11903.\n\nSelf-adaptive in-context learning. Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, Lingpeng Kong, 10.48550/ARXIV.2212.10375Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, and Ling- peng Kong. 2022. Self-adaptive in-context learning.\n\nProGen: Progressive zero-shot dataset generation via in-context feedback. Jiacheng Ye, Jiahui Gao, Zhiyong Wu, Jiangtao Feng, Tao Yu, Lingpeng Kong, Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsJiacheng Ye, Jiahui Gao, Zhiyong Wu, Jiangtao Feng, Tao Yu, and Lingpeng Kong. 2022. ProGen: Pro- gressive zero-shot dataset generation via in-context feedback. In Findings of the Association for Com- putational Linguistics: EMNLP 2022, pages 3671- 3683, Abu Dhabi, United Arab Emirates. Associa- tion for Computational Linguistics.\n\nCompositional exemplars for in-context learning. Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu, Lingpeng Kong, arXiv:2302.05698arXiv preprintJiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu, and Lingpeng Kong. 2023. Compositional ex- emplars for in-context learning. arXiv preprint arXiv:2302.05698.\n\nSimple and effective noisy channel modeling for neural machine translation. Kyra Yee, Nathan Ng, Yann N Dauphin, Michael Auli, abs/1908.05731CoRRKyra Yee, Nathan Ng, Yann N. Dauphin, and Michael Auli. 2019. Simple and effective noisy channel modeling for neural machine translation. CoRR, abs/1908.05731.\n\nThe neural noisy channel. Lei Yu, Phil Blunsom, Chris Dyer, Edward Grefenstette, Tom\u00e1s Kocisk\u00fd, abs/1611.02554CoRRLei Yu, Phil Blunsom, Chris Dyer, Edward Grefen- stette, and Tom\u00e1s Kocisk\u00fd. 2016. The neural noisy channel. CoRR, abs/1611.02554.\n\n. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, Luke Zettlemoyer, 10.48550/ARXIV.2205.01068Opt: Open pretrained transformer language modelsSusan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher De- wan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mi- haylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. 2022a. Opt: Open pre- trained transformer language models.\n\nAutomatic chain of thought prompting in large language models. Zhuosheng Zhang, Aston Zhang, Mu Li, Alex Smola, abs/2210.03493CoRRZhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022b. Automatic chain of thought prompting in large language models. CoRR, abs/2210.03493.\n\nTony Z Zhao, Eric Wallace, Shi Feng, Dan Klein, Sameer Singh, 10.48550/arXiv.2102.09690arXiv:2102.09690Calibrate Before Use: Improving Few-Shot Performance of Language Models. arXiv e-prints. Tony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate Before Use: Im- proving Few-Shot Performance of Language Mod- els. arXiv e-prints, page arXiv:2102.09690.\n\nCalibrate before use: Improving few-shot performance of language models. Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, Sameer Singh, PMLRInternational Conference on Machine Learning. Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improv- ing few-shot performance of language models. In In- ternational Conference on Machine Learning, pages 12697-12706. PMLR.\n\nLeast-to-most prompting enables complex reasoning in large language models. Denny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. 2022ArXiv preprint, abs/2205.10625Denny Zhou, Nathanael Sch\u00e4rli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi. 2022. Least-to-most prompting enables complex reason- ing in large language models. ArXiv preprint, abs/2205.10625.\n", "annotations": {"author": "[{\"end\":164,\"start\":61},{\"end\":310,\"start\":165},{\"end\":406,\"start\":311},{\"end\":512,\"start\":407},{\"end\":608,\"start\":513},{\"end\":716,\"start\":609},{\"end\":812,\"start\":717},{\"end\":918,\"start\":813},{\"end\":1014,\"start\":919},{\"end\":1116,\"start\":1015},{\"end\":1244,\"start\":1117},{\"end\":1340,\"start\":1245},{\"end\":1445,\"start\":1341}]", "publisher": null, "author_last_name": "[{\"end\":70,\"start\":68},{\"end\":178,\"start\":174},{\"end\":418,\"start\":416},{\"end\":622,\"start\":618},{\"end\":824,\"start\":822},{\"end\":1022,\"start\":1018},{\"end\":1127,\"start\":1125},{\"end\":1351,\"start\":1343}]", "author_first_name": "[{\"end\":67,\"start\":61},{\"end\":173,\"start\":165},{\"end\":312,\"start\":311},{\"end\":415,\"start\":407},{\"end\":514,\"start\":513},{\"end\":617,\"start\":609},{\"end\":718,\"start\":717},{\"end\":821,\"start\":813},{\"end\":920,\"start\":919},{\"end\":1017,\"start\":1015},{\"end\":1124,\"start\":1117},{\"end\":1246,\"start\":1245},{\"end\":1342,\"start\":1341}]", "author_affiliation": "[{\"end\":163,\"start\":72},{\"end\":309,\"start\":218},{\"end\":405,\"start\":314},{\"end\":511,\"start\":420},{\"end\":607,\"start\":516},{\"end\":715,\"start\":624},{\"end\":811,\"start\":720},{\"end\":917,\"start\":826},{\"end\":1013,\"start\":922},{\"end\":1115,\"start\":1024},{\"end\":1243,\"start\":1152},{\"end\":1339,\"start\":1248},{\"end\":1444,\"start\":1353}]", "title": "[{\"end\":58,\"start\":1},{\"end\":1503,\"start\":1446}]", "venue": null, "abstract": "[{\"end\":2885,\"start\":1566}]", "bib_ref": "[{\"end\":2962,\"start\":2942},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2982,\"start\":2962},{\"end\":3000,\"start\":2982},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3084,\"start\":3065},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3353,\"start\":3337},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3371,\"start\":3353},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4025,\"start\":3995},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4050,\"start\":4032},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4068,\"start\":4050},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":4096,\"start\":4079},{\"end\":4155,\"start\":4135},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":4214,\"start\":4195},{\"end\":5717,\"start\":5698},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":6127,\"start\":6109},{\"end\":6161,\"start\":6143},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6204,\"start\":6185},{\"end\":6292,\"start\":6270},{\"end\":6310,\"start\":6292},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":6646,\"start\":6627},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6773,\"start\":6753},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6825,\"start\":6806},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":6872,\"start\":6851},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6888,\"start\":6872},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7042,\"start\":7026},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7160,\"start\":7142},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7182,\"start\":7165},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":7289,\"start\":7272},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7307,\"start\":7289},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7323,\"start\":7307},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7745,\"start\":7723},{\"end\":7764,\"start\":7745},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7816,\"start\":7794},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7834,\"start\":7816},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7853,\"start\":7834},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7897,\"start\":7878},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7922,\"start\":7897},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7992,\"start\":7973},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11312,\"start\":11293},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11513,\"start\":11484},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11539,\"start\":11521},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11557,\"start\":11539},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":11586,\"start\":11569},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11754,\"start\":11737},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":12794,\"start\":12777},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":12811,\"start\":12794},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":13094,\"start\":13075},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13142,\"start\":13119},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":13419,\"start\":13403},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14784,\"start\":14754},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14805,\"start\":14784},{\"end\":14824,\"start\":14805},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":14851,\"start\":14824},{\"end\":14870,\"start\":14851},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14933,\"start\":14912},{\"end\":15132,\"start\":15114},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15149,\"start\":15132},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15163,\"start\":15149},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":16079,\"start\":16058},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16623,\"start\":16605},{\"end\":16982,\"start\":16974},{\"end\":18162,\"start\":18142},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18932,\"start\":18909},{\"end\":19190,\"start\":19171},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":19245,\"start\":19224},{\"end\":19296,\"start\":19270},{\"end\":19355,\"start\":19335},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19415,\"start\":19393},{\"end\":19512,\"start\":19492},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":19529,\"start\":19512}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":20791,\"start\":20570},{\"attributes\":{\"id\":\"fig_1\"},\"end\":22065,\"start\":20792},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":22656,\"start\":22066}]", "paragraph": "[{\"end\":3603,\"start\":2901},{\"end\":4490,\"start\":3605},{\"end\":5199,\"start\":4492},{\"end\":5315,\"start\":5201},{\"end\":5485,\"start\":5317},{\"end\":5606,\"start\":5487},{\"end\":6889,\"start\":5623},{\"end\":7551,\"start\":6891},{\"end\":8400,\"start\":7553},{\"end\":8575,\"start\":8412},{\"end\":8787,\"start\":8597},{\"end\":9033,\"start\":8789},{\"end\":9242,\"start\":9035},{\"end\":9440,\"start\":9244},{\"end\":10213,\"start\":9466},{\"end\":10653,\"start\":10360},{\"end\":11041,\"start\":10655},{\"end\":11313,\"start\":11043},{\"end\":11587,\"start\":11315},{\"end\":11764,\"start\":11589},{\"end\":12153,\"start\":11766},{\"end\":12358,\"start\":12155},{\"end\":12525,\"start\":12360},{\"end\":12728,\"start\":12527},{\"end\":12939,\"start\":12730},{\"end\":13227,\"start\":12941},{\"end\":13373,\"start\":13242},{\"end\":14017,\"start\":13375},{\"end\":14538,\"start\":14019},{\"end\":14687,\"start\":14553},{\"end\":15166,\"start\":14689},{\"end\":15402,\"start\":15168},{\"end\":15719,\"start\":15404},{\"end\":15840,\"start\":15743},{\"end\":18003,\"start\":15842},{\"end\":18568,\"start\":18005},{\"end\":19024,\"start\":18570},{\"end\":19861,\"start\":19039},{\"end\":20569,\"start\":19876}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10322,\"start\":10244}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2899,\"start\":2887},{\"attributes\":{\"n\":\"2\"},\"end\":5621,\"start\":5609},{\"attributes\":{\"n\":\"3\"},\"end\":8410,\"start\":8403},{\"attributes\":{\"n\":\"3.1\"},\"end\":8595,\"start\":8578},{\"end\":9452,\"start\":9443},{\"end\":9464,\"start\":9455},{\"end\":10230,\"start\":10216},{\"end\":10243,\"start\":10233},{\"attributes\":{\"n\":\"3.2\"},\"end\":10345,\"start\":10324},{\"attributes\":{\"n\":\"3.3\"},\"end\":10358,\"start\":10348},{\"attributes\":{\"n\":\"3.4\"},\"end\":13240,\"start\":13230},{\"attributes\":{\"n\":\"3.5\"},\"end\":14551,\"start\":14541},{\"attributes\":{\"n\":\"4\"},\"end\":15741,\"start\":15722},{\"attributes\":{\"n\":\"5\"},\"end\":19037,\"start\":19027},{\"attributes\":{\"n\":\"6\"},\"end\":19874,\"start\":19864},{\"end\":20589,\"start\":20571},{\"end\":20816,\"start\":20793}]", "table": "[{\"end\":22656,\"start\":22409}]", "figure_caption": "[{\"end\":20791,\"start\":20591},{\"end\":22065,\"start\":20820},{\"end\":22409,\"start\":22068}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9480,\"start\":9472},{\"end\":16101,\"start\":16093},{\"end\":17572,\"start\":17564},{\"end\":18024,\"start\":18016},{\"end\":18650,\"start\":18642},{\"end\":19712,\"start\":19704}]", "bib_author_first_name": "[{\"end\":22841,\"start\":22830},{\"end\":22854,\"start\":22850},{\"end\":23045,\"start\":23038},{\"end\":23062,\"start\":23056},{\"end\":23078,\"start\":23073},{\"end\":23491,\"start\":23487},{\"end\":23507,\"start\":23498},{\"end\":23518,\"start\":23512},{\"end\":23530,\"start\":23525},{\"end\":23544,\"start\":23537},{\"end\":23557,\"start\":23550},{\"end\":23572,\"start\":23565},{\"end\":23890,\"start\":23887},{\"end\":23898,\"start\":23895},{\"end\":23911,\"start\":23905},{\"end\":23928,\"start\":23923},{\"end\":23942,\"start\":23936},{\"end\":24118,\"start\":24115},{\"end\":24130,\"start\":24124},{\"end\":24144,\"start\":24141},{\"end\":24160,\"start\":24152},{\"end\":24176,\"start\":24170},{\"end\":24191,\"start\":24184},{\"end\":24205,\"start\":24200},{\"end\":24219,\"start\":24213},{\"end\":24229,\"start\":24224},{\"end\":24240,\"start\":24237},{\"end\":24671,\"start\":24665},{\"end\":24681,\"start\":24677},{\"end\":24694,\"start\":24689},{\"end\":25412,\"start\":25406},{\"end\":25422,\"start\":25418},{\"end\":25435,\"start\":25430},{\"end\":26171,\"start\":26168},{\"end\":26184,\"start\":26178},{\"end\":26199,\"start\":26195},{\"end\":26213,\"start\":26207},{\"end\":26223,\"start\":26220},{\"end\":26238,\"start\":26230},{\"end\":26627,\"start\":26623},{\"end\":26637,\"start\":26634},{\"end\":26653,\"start\":26645},{\"end\":26923,\"start\":26919},{\"end\":26933,\"start\":26928},{\"end\":26945,\"start\":26940},{\"end\":26958,\"start\":26953},{\"end\":26975,\"start\":26969},{\"end\":26991,\"start\":26987},{\"end\":27000,\"start\":26996},{\"end\":27013,\"start\":27009},{\"end\":27026,\"start\":27021},{\"end\":27457,\"start\":27453},{\"end\":27470,\"start\":27465},{\"end\":28239,\"start\":28234},{\"end\":28262,\"start\":28257},{\"end\":28279,\"start\":28273},{\"end\":28296,\"start\":28289},{\"end\":28309,\"start\":28303},{\"end\":28320,\"start\":28316},{\"end\":28333,\"start\":28328},{\"end\":28345,\"start\":28339},{\"end\":28360,\"start\":28353},{\"end\":28379,\"start\":28370},{\"end\":28387,\"start\":28384},{\"end\":28403,\"start\":28398},{\"end\":28421,\"start\":28414},{\"end\":28453,\"start\":28446},{\"end\":28465,\"start\":28461},{\"end\":28476,\"start\":28472},{\"end\":28491,\"start\":28483},{\"end\":28894,\"start\":28890},{\"end\":29093,\"start\":29088},{\"end\":29116,\"start\":29111},{\"end\":29133,\"start\":29127},{\"end\":29150,\"start\":29143},{\"end\":29163,\"start\":29157},{\"end\":29174,\"start\":29170},{\"end\":29187,\"start\":29182},{\"end\":29199,\"start\":29193},{\"end\":29214,\"start\":29207},{\"end\":29233,\"start\":29224},{\"end\":29241,\"start\":29238},{\"end\":29257,\"start\":29252},{\"end\":29275,\"start\":29268},{\"end\":29307,\"start\":29300},{\"end\":29319,\"start\":29315},{\"end\":29330,\"start\":29326},{\"end\":29345,\"start\":29337},{\"end\":29363,\"start\":29359},{\"end\":29365,\"start\":29364},{\"end\":29383,\"start\":29376},{\"end\":29394,\"start\":29390},{\"end\":29891,\"start\":29883},{\"end\":29904,\"start\":29897},{\"end\":29916,\"start\":29911},{\"end\":29925,\"start\":29924},{\"end\":29943,\"start\":29935},{\"end\":29957,\"start\":29951},{\"end\":30537,\"start\":30530},{\"end\":30549,\"start\":30543},{\"end\":30562,\"start\":30556},{\"end\":30575,\"start\":30567},{\"end\":30590,\"start\":30583},{\"end\":30606,\"start\":30600},{\"end\":30960,\"start\":30957},{\"end\":30968,\"start\":30965},{\"end\":30986,\"start\":30978},{\"end\":31003,\"start\":30994},{\"end\":31018,\"start\":31012},{\"end\":31604,\"start\":31599},{\"end\":31614,\"start\":31610},{\"end\":31630,\"start\":31622},{\"end\":31647,\"start\":31643},{\"end\":32289,\"start\":32281},{\"end\":32306,\"start\":32299},{\"end\":32324,\"start\":32316},{\"end\":32944,\"start\":32940},{\"end\":32960,\"start\":32953},{\"end\":32967,\"start\":32965},{\"end\":32980,\"start\":32975},{\"end\":32997,\"start\":32990},{\"end\":33016,\"start\":33010},{\"end\":33031,\"start\":33026},{\"end\":33047,\"start\":33039},{\"end\":33065,\"start\":33057},{\"end\":33077,\"start\":33073},{\"end\":33460,\"start\":33455},{\"end\":33473,\"start\":33470},{\"end\":33496,\"start\":33487},{\"end\":33512,\"start\":33505},{\"end\":33525,\"start\":33520},{\"end\":33542,\"start\":33535},{\"end\":33556,\"start\":33547},{\"end\":34470,\"start\":34466},{\"end\":34482,\"start\":34478},{\"end\":34495,\"start\":34490},{\"end\":34507,\"start\":34501},{\"end\":34521,\"start\":34517},{\"end\":34523,\"start\":34522},{\"end\":34535,\"start\":34531},{\"end\":34830,\"start\":34826},{\"end\":34847,\"start\":34840},{\"end\":35025,\"start\":35021},{\"end\":35039,\"start\":35035},{\"end\":35049,\"start\":35044},{\"end\":35062,\"start\":35057},{\"end\":35074,\"start\":35069},{\"end\":35087,\"start\":35083},{\"end\":35245,\"start\":35241},{\"end\":35247,\"start\":35246},{\"end\":35262,\"start\":35253},{\"end\":35279,\"start\":35273},{\"end\":35290,\"start\":35285},{\"end\":35307,\"start\":35301},{\"end\":35325,\"start\":35318},{\"end\":35336,\"start\":35332},{\"end\":35353,\"start\":35348},{\"end\":35370,\"start\":35365},{\"end\":35385,\"start\":35377},{\"end\":35398,\"start\":35393},{\"end\":35414,\"start\":35411},{\"end\":35430,\"start\":35425},{\"end\":35444,\"start\":35439},{\"end\":35462,\"start\":35455},{\"end\":35477,\"start\":35471},{\"end\":35501,\"start\":35497},{\"end\":35506,\"start\":35502},{\"end\":35526,\"start\":35518},{\"end\":35539,\"start\":35533},{\"end\":35553,\"start\":35547},{\"end\":35570,\"start\":35562},{\"end\":35585,\"start\":35578},{\"end\":35604,\"start\":35597},{\"end\":35620,\"start\":35612},{\"end\":35633,\"start\":35629},{\"end\":35647,\"start\":35642},{\"end\":35664,\"start\":35657},{\"end\":35678,\"start\":35675},{\"end\":35692,\"start\":35689},{\"end\":35702,\"start\":35697},{\"end\":35718,\"start\":35710},{\"end\":35735,\"start\":35730},{\"end\":35754,\"start\":35749},{\"end\":35767,\"start\":35763},{\"end\":35785,\"start\":35780},{\"end\":35803,\"start\":35796},{\"end\":35821,\"start\":35814},{\"end\":35833,\"start\":35829},{\"end\":35848,\"start\":35843},{\"end\":35857,\"start\":35849},{\"end\":35870,\"start\":35862},{\"end\":35884,\"start\":35880},{\"end\":35902,\"start\":35897},{\"end\":35923,\"start\":35916},{\"end\":38159,\"start\":38154},{\"end\":38172,\"start\":38168},{\"end\":38186,\"start\":38182},{\"end\":38205,\"start\":38196},{\"end\":38217,\"start\":38211},{\"end\":38233,\"start\":38226},{\"end\":38247,\"start\":38242},{\"end\":38257,\"start\":38254},{\"end\":38267,\"start\":38262},{\"end\":38269,\"start\":38268},{\"end\":38669,\"start\":38663},{\"end\":38687,\"start\":38683},{\"end\":38975,\"start\":38968},{\"end\":38991,\"start\":38987},{\"end\":39248,\"start\":39242},{\"end\":39275,\"start\":39264},{\"end\":39286,\"start\":39281},{\"end\":39300,\"start\":39294},{\"end\":39316,\"start\":39310},{\"end\":39328,\"start\":39323},{\"end\":39347,\"start\":39338},{\"end\":39353,\"start\":39348},{\"end\":39372,\"start\":39364},{\"end\":39391,\"start\":39383},{\"end\":39879,\"start\":39875},{\"end\":39895,\"start\":39888},{\"end\":40699,\"start\":40693},{\"end\":40713,\"start\":40706},{\"end\":40729,\"start\":40723},{\"end\":40731,\"start\":40730},{\"end\":40740,\"start\":40739},{\"end\":40742,\"start\":40741},{\"end\":40749,\"start\":40745},{\"end\":40765,\"start\":40759},{\"end\":41385,\"start\":41377},{\"end\":41402,\"start\":41395},{\"end\":41416,\"start\":41412},{\"end\":41430,\"start\":41423},{\"end\":41447,\"start\":41442},{\"end\":41461,\"start\":41456},{\"end\":41949,\"start\":41941},{\"end\":41966,\"start\":41959},{\"end\":41980,\"start\":41976},{\"end\":41994,\"start\":41987},{\"end\":42011,\"start\":42006},{\"end\":42025,\"start\":42020},{\"end\":42361,\"start\":42354},{\"end\":42374,\"start\":42370},{\"end\":42390,\"start\":42386},{\"end\":42400,\"start\":42395},{\"end\":42420,\"start\":42409},{\"end\":42422,\"start\":42421},{\"end\":42438,\"start\":42432},{\"end\":42454,\"start\":42443},{\"end\":43073,\"start\":43066},{\"end\":43083,\"start\":43078},{\"end\":43095,\"start\":43091},{\"end\":43101,\"start\":43096},{\"end\":43112,\"start\":43106},{\"end\":43124,\"start\":43118},{\"end\":43136,\"start\":43131},{\"end\":43145,\"start\":43142},{\"end\":43157,\"start\":43153},{\"end\":43173,\"start\":43169},{\"end\":43188,\"start\":43187},{\"end\":43556,\"start\":43554},{\"end\":43563,\"start\":43562},{\"end\":43577,\"start\":43570},{\"end\":43590,\"start\":43584},{\"end\":43605,\"start\":43601},{\"end\":43615,\"start\":43610},{\"end\":43627,\"start\":43623},{\"end\":43638,\"start\":43635},{\"end\":43647,\"start\":43644},{\"end\":43656,\"start\":43653},{\"end\":43666,\"start\":43663},{\"end\":43681,\"start\":43674},{\"end\":43683,\"start\":43682},{\"end\":43700,\"start\":43694},{\"end\":44162,\"start\":44158},{\"end\":44175,\"start\":44172},{\"end\":44188,\"start\":44182},{\"end\":44202,\"start\":44198},{\"end\":44218,\"start\":44212},{\"end\":44988,\"start\":44983},{\"end\":45120,\"start\":45117},{\"end\":45131,\"start\":45127},{\"end\":45374,\"start\":45369},{\"end\":45386,\"start\":45381},{\"end\":45397,\"start\":45393},{\"end\":45676,\"start\":45670},{\"end\":45688,\"start\":45683},{\"end\":45698,\"start\":45694},{\"end\":45715,\"start\":45711},{\"end\":45722,\"start\":45720},{\"end\":45734,\"start\":45728},{\"end\":45752,\"start\":45743},{\"end\":45769,\"start\":45764},{\"end\":46140,\"start\":46135},{\"end\":46148,\"start\":46146},{\"end\":46159,\"start\":46154},{\"end\":46176,\"start\":46171},{\"end\":46191,\"start\":46185},{\"end\":46207,\"start\":46198},{\"end\":46222,\"start\":46218},{\"end\":46240,\"start\":46233},{\"end\":46253,\"start\":46248},{\"end\":46266,\"start\":46260},{\"end\":46661,\"start\":46656},{\"end\":46673,\"start\":46667},{\"end\":46684,\"start\":46680},{\"end\":46704,\"start\":46697},{\"end\":46714,\"start\":46712},{\"end\":46716,\"start\":46715},{\"end\":46726,\"start\":46722},{\"end\":46736,\"start\":46731},{\"end\":46996,\"start\":46989},{\"end\":47009,\"start\":47001},{\"end\":47024,\"start\":47016},{\"end\":47037,\"start\":47029},{\"end\":47254,\"start\":47246},{\"end\":47265,\"start\":47259},{\"end\":47278,\"start\":47271},{\"end\":47291,\"start\":47283},{\"end\":47301,\"start\":47298},{\"end\":47314,\"start\":47306},{\"end\":47855,\"start\":47847},{\"end\":47867,\"start\":47860},{\"end\":47880,\"start\":47872},{\"end\":47890,\"start\":47887},{\"end\":47903,\"start\":47895},{\"end\":48178,\"start\":48174},{\"end\":48190,\"start\":48184},{\"end\":48199,\"start\":48195},{\"end\":48201,\"start\":48200},{\"end\":48218,\"start\":48211},{\"end\":48433,\"start\":48430},{\"end\":48442,\"start\":48438},{\"end\":48457,\"start\":48452},{\"end\":48470,\"start\":48464},{\"end\":48490,\"start\":48485},{\"end\":48656,\"start\":48651},{\"end\":48671,\"start\":48664},{\"end\":48685,\"start\":48680},{\"end\":48698,\"start\":48693},{\"end\":48712,\"start\":48708},{\"end\":48726,\"start\":48719},{\"end\":48744,\"start\":48733},{\"end\":48756,\"start\":48752},{\"end\":48767,\"start\":48763},{\"end\":48774,\"start\":48772},{\"end\":48794,\"start\":48789},{\"end\":48809,\"start\":48805},{\"end\":48818,\"start\":48815},{\"end\":48833,\"start\":48829},{\"end\":48849,\"start\":48843},{\"end\":48862,\"start\":48857},{\"end\":48882,\"start\":48876},{\"end\":48898,\"start\":48892},{\"end\":48909,\"start\":48905},{\"end\":49408,\"start\":49399},{\"end\":49421,\"start\":49416},{\"end\":49431,\"start\":49429},{\"end\":49440,\"start\":49436},{\"end\":49616,\"start\":49612},{\"end\":49618,\"start\":49617},{\"end\":49629,\"start\":49625},{\"end\":49642,\"start\":49639},{\"end\":49652,\"start\":49649},{\"end\":49666,\"start\":49660},{\"end\":50072,\"start\":50067},{\"end\":50083,\"start\":50079},{\"end\":50096,\"start\":50093},{\"end\":50106,\"start\":50103},{\"end\":50120,\"start\":50114},{\"end\":50482,\"start\":50477},{\"end\":50498,\"start\":50489},{\"end\":50510,\"start\":50508},{\"end\":50521,\"start\":50516},{\"end\":50533,\"start\":50527},{\"end\":50548,\"start\":50542},{\"end\":50559,\"start\":50555},{\"end\":50579,\"start\":50572}]", "bib_author_last_name": "[{\"end\":22848,\"start\":22842},{\"end\":22860,\"start\":22855},{\"end\":22870,\"start\":22862},{\"end\":23054,\"start\":23046},{\"end\":23071,\"start\":23063},{\"end\":23086,\"start\":23079},{\"end\":23496,\"start\":23492},{\"end\":23510,\"start\":23508},{\"end\":23523,\"start\":23519},{\"end\":23535,\"start\":23531},{\"end\":23548,\"start\":23545},{\"end\":23563,\"start\":23558},{\"end\":23576,\"start\":23573},{\"end\":23893,\"start\":23891},{\"end\":23903,\"start\":23899},{\"end\":23921,\"start\":23912},{\"end\":23934,\"start\":23929},{\"end\":23947,\"start\":23943},{\"end\":24122,\"start\":24119},{\"end\":24139,\"start\":24131},{\"end\":24150,\"start\":24145},{\"end\":24168,\"start\":24161},{\"end\":24182,\"start\":24177},{\"end\":24198,\"start\":24192},{\"end\":24211,\"start\":24206},{\"end\":24222,\"start\":24220},{\"end\":24235,\"start\":24230},{\"end\":24250,\"start\":24241},{\"end\":24675,\"start\":24672},{\"end\":24687,\"start\":24682},{\"end\":24699,\"start\":24695},{\"end\":25416,\"start\":25413},{\"end\":25428,\"start\":25423},{\"end\":25440,\"start\":25436},{\"end\":26176,\"start\":26172},{\"end\":26193,\"start\":26185},{\"end\":26205,\"start\":26200},{\"end\":26218,\"start\":26214},{\"end\":26228,\"start\":26224},{\"end\":26245,\"start\":26239},{\"end\":26632,\"start\":26628},{\"end\":26643,\"start\":26638},{\"end\":26660,\"start\":26654},{\"end\":26926,\"start\":26924},{\"end\":26938,\"start\":26934},{\"end\":26951,\"start\":26946},{\"end\":26967,\"start\":26959},{\"end\":26985,\"start\":26976},{\"end\":26994,\"start\":26992},{\"end\":27007,\"start\":27001},{\"end\":27019,\"start\":27014},{\"end\":27034,\"start\":27027},{\"end\":27463,\"start\":27458},{\"end\":27473,\"start\":27471},{\"end\":27480,\"start\":27475},{\"end\":28255,\"start\":28240},{\"end\":28271,\"start\":28263},{\"end\":28287,\"start\":28280},{\"end\":28301,\"start\":28297},{\"end\":28314,\"start\":28310},{\"end\":28326,\"start\":28321},{\"end\":28337,\"start\":28334},{\"end\":28351,\"start\":28346},{\"end\":28368,\"start\":28361},{\"end\":28382,\"start\":28380},{\"end\":28396,\"start\":28388},{\"end\":28412,\"start\":28404},{\"end\":28433,\"start\":28422},{\"end\":28444,\"start\":28435},{\"end\":28459,\"start\":28454},{\"end\":28470,\"start\":28466},{\"end\":28481,\"start\":28477},{\"end\":28503,\"start\":28492},{\"end\":28513,\"start\":28505},{\"end\":28903,\"start\":28895},{\"end\":28907,\"start\":28905},{\"end\":29109,\"start\":29094},{\"end\":29125,\"start\":29117},{\"end\":29141,\"start\":29134},{\"end\":29155,\"start\":29151},{\"end\":29168,\"start\":29164},{\"end\":29180,\"start\":29175},{\"end\":29191,\"start\":29188},{\"end\":29205,\"start\":29200},{\"end\":29222,\"start\":29215},{\"end\":29236,\"start\":29234},{\"end\":29250,\"start\":29242},{\"end\":29266,\"start\":29258},{\"end\":29287,\"start\":29276},{\"end\":29298,\"start\":29289},{\"end\":29313,\"start\":29308},{\"end\":29324,\"start\":29320},{\"end\":29335,\"start\":29331},{\"end\":29357,\"start\":29346},{\"end\":29374,\"start\":29366},{\"end\":29388,\"start\":29384},{\"end\":29403,\"start\":29395},{\"end\":29407,\"start\":29405},{\"end\":29895,\"start\":29892},{\"end\":29909,\"start\":29905},{\"end\":29922,\"start\":29917},{\"end\":29933,\"start\":29926},{\"end\":29949,\"start\":29944},{\"end\":29963,\"start\":29958},{\"end\":29969,\"start\":29965},{\"end\":30541,\"start\":30538},{\"end\":30554,\"start\":30550},{\"end\":30565,\"start\":30563},{\"end\":30581,\"start\":30576},{\"end\":30598,\"start\":30591},{\"end\":30613,\"start\":30607},{\"end\":30963,\"start\":30961},{\"end\":30976,\"start\":30969},{\"end\":30992,\"start\":30987},{\"end\":31010,\"start\":31004},{\"end\":31028,\"start\":31019},{\"end\":31608,\"start\":31605},{\"end\":31620,\"start\":31615},{\"end\":31641,\"start\":31631},{\"end\":31659,\"start\":31648},{\"end\":32297,\"start\":32290},{\"end\":32314,\"start\":32307},{\"end\":32334,\"start\":32325},{\"end\":32951,\"start\":32945},{\"end\":32963,\"start\":32961},{\"end\":32973,\"start\":32968},{\"end\":32988,\"start\":32981},{\"end\":33008,\"start\":32998},{\"end\":33024,\"start\":33017},{\"end\":33037,\"start\":33032},{\"end\":33055,\"start\":33048},{\"end\":33071,\"start\":33066},{\"end\":33082,\"start\":33078},{\"end\":33468,\"start\":33461},{\"end\":33485,\"start\":33474},{\"end\":33503,\"start\":33497},{\"end\":33518,\"start\":33513},{\"end\":33533,\"start\":33526},{\"end\":33545,\"start\":33543},{\"end\":33563,\"start\":33557},{\"end\":34476,\"start\":34471},{\"end\":34488,\"start\":34483},{\"end\":34499,\"start\":34496},{\"end\":34515,\"start\":34508},{\"end\":34529,\"start\":34524},{\"end\":34541,\"start\":34536},{\"end\":34838,\"start\":34831},{\"end\":34858,\"start\":34848},{\"end\":35033,\"start\":35026},{\"end\":35042,\"start\":35040},{\"end\":35055,\"start\":35050},{\"end\":35067,\"start\":35063},{\"end\":35081,\"start\":35075},{\"end\":35097,\"start\":35088},{\"end\":35251,\"start\":35248},{\"end\":35271,\"start\":35263},{\"end\":35283,\"start\":35280},{\"end\":35299,\"start\":35291},{\"end\":35316,\"start\":35308},{\"end\":35330,\"start\":35326},{\"end\":35346,\"start\":35337},{\"end\":35363,\"start\":35354},{\"end\":35375,\"start\":35371},{\"end\":35391,\"start\":35386},{\"end\":35409,\"start\":35399},{\"end\":35423,\"start\":35415},{\"end\":35437,\"start\":35431},{\"end\":35453,\"start\":35445},{\"end\":35469,\"start\":35463},{\"end\":35495,\"start\":35478},{\"end\":35516,\"start\":35507},{\"end\":35531,\"start\":35527},{\"end\":35545,\"start\":35540},{\"end\":35560,\"start\":35554},{\"end\":35576,\"start\":35571},{\"end\":35595,\"start\":35586},{\"end\":35610,\"start\":35605},{\"end\":35627,\"start\":35621},{\"end\":35640,\"start\":35634},{\"end\":35655,\"start\":35648},{\"end\":35673,\"start\":35665},{\"end\":35687,\"start\":35679},{\"end\":35695,\"start\":35693},{\"end\":35708,\"start\":35703},{\"end\":35728,\"start\":35719},{\"end\":35747,\"start\":35736},{\"end\":35761,\"start\":35755},{\"end\":35778,\"start\":35768},{\"end\":35794,\"start\":35786},{\"end\":35812,\"start\":35804},{\"end\":35827,\"start\":35822},{\"end\":35841,\"start\":35834},{\"end\":35860,\"start\":35858},{\"end\":35878,\"start\":35871},{\"end\":35895,\"start\":35885},{\"end\":35914,\"start\":35903},{\"end\":35930,\"start\":35924},{\"end\":38166,\"start\":38160},{\"end\":38180,\"start\":38173},{\"end\":38194,\"start\":38187},{\"end\":38209,\"start\":38206},{\"end\":38224,\"start\":38218},{\"end\":38240,\"start\":38234},{\"end\":38252,\"start\":38248},{\"end\":38260,\"start\":38258},{\"end\":38273,\"start\":38270},{\"end\":38681,\"start\":38670},{\"end\":38694,\"start\":38688},{\"end\":38985,\"start\":38976},{\"end\":39000,\"start\":38992},{\"end\":39262,\"start\":39249},{\"end\":39279,\"start\":39276},{\"end\":39292,\"start\":39287},{\"end\":39308,\"start\":39301},{\"end\":39321,\"start\":39317},{\"end\":39336,\"start\":39329},{\"end\":39362,\"start\":39354},{\"end\":39381,\"start\":39373},{\"end\":39396,\"start\":39392},{\"end\":39403,\"start\":39398},{\"end\":39886,\"start\":39880},{\"end\":39903,\"start\":39896},{\"end\":40704,\"start\":40700},{\"end\":40721,\"start\":40714},{\"end\":40737,\"start\":40732},{\"end\":40757,\"start\":40750},{\"end\":40771,\"start\":40766},{\"end\":41393,\"start\":41386},{\"end\":41410,\"start\":41403},{\"end\":41421,\"start\":41417},{\"end\":41440,\"start\":41431},{\"end\":41454,\"start\":41448},{\"end\":41471,\"start\":41462},{\"end\":41957,\"start\":41950},{\"end\":41974,\"start\":41967},{\"end\":41985,\"start\":41981},{\"end\":42004,\"start\":41995},{\"end\":42018,\"start\":42012},{\"end\":42035,\"start\":42026},{\"end\":42368,\"start\":42362},{\"end\":42384,\"start\":42375},{\"end\":42393,\"start\":42391},{\"end\":42407,\"start\":42401},{\"end\":42430,\"start\":42423},{\"end\":42441,\"start\":42439},{\"end\":42460,\"start\":42455},{\"end\":43076,\"start\":43074},{\"end\":43089,\"start\":43084},{\"end\":43104,\"start\":43102},{\"end\":43116,\"start\":43113},{\"end\":43129,\"start\":43125},{\"end\":43140,\"start\":43137},{\"end\":43151,\"start\":43146},{\"end\":43167,\"start\":43158},{\"end\":43185,\"start\":43174},{\"end\":43193,\"start\":43189},{\"end\":43200,\"start\":43195},{\"end\":43560,\"start\":43557},{\"end\":43568,\"start\":43564},{\"end\":43582,\"start\":43578},{\"end\":43599,\"start\":43591},{\"end\":43608,\"start\":43606},{\"end\":43621,\"start\":43616},{\"end\":43633,\"start\":43628},{\"end\":43642,\"start\":43639},{\"end\":43651,\"start\":43648},{\"end\":43661,\"start\":43657},{\"end\":43672,\"start\":43667},{\"end\":43692,\"start\":43684},{\"end\":43706,\"start\":43701},{\"end\":43715,\"start\":43708},{\"end\":44170,\"start\":44163},{\"end\":44180,\"start\":44176},{\"end\":44196,\"start\":44189},{\"end\":44210,\"start\":44203},{\"end\":44224,\"start\":44219},{\"end\":44993,\"start\":44989},{\"end\":45125,\"start\":45121},{\"end\":45143,\"start\":45132},{\"end\":45379,\"start\":45375},{\"end\":45391,\"start\":45387},{\"end\":45401,\"start\":45398},{\"end\":45681,\"start\":45677},{\"end\":45692,\"start\":45689},{\"end\":45709,\"start\":45699},{\"end\":45718,\"start\":45716},{\"end\":45726,\"start\":45723},{\"end\":45741,\"start\":45735},{\"end\":45762,\"start\":45753},{\"end\":45774,\"start\":45770},{\"end\":46144,\"start\":46141},{\"end\":46152,\"start\":46149},{\"end\":46169,\"start\":46160},{\"end\":46183,\"start\":46177},{\"end\":46196,\"start\":46192},{\"end\":46216,\"start\":46208},{\"end\":46231,\"start\":46223},{\"end\":46246,\"start\":46241},{\"end\":46258,\"start\":46254},{\"end\":46274,\"start\":46267},{\"end\":46665,\"start\":46662},{\"end\":46678,\"start\":46674},{\"end\":46695,\"start\":46685},{\"end\":46710,\"start\":46705},{\"end\":46720,\"start\":46717},{\"end\":46729,\"start\":46727},{\"end\":46741,\"start\":46737},{\"end\":46999,\"start\":46997},{\"end\":47014,\"start\":47010},{\"end\":47027,\"start\":47025},{\"end\":47042,\"start\":47038},{\"end\":47257,\"start\":47255},{\"end\":47269,\"start\":47266},{\"end\":47281,\"start\":47279},{\"end\":47296,\"start\":47292},{\"end\":47304,\"start\":47302},{\"end\":47319,\"start\":47315},{\"end\":47858,\"start\":47856},{\"end\":47870,\"start\":47868},{\"end\":47885,\"start\":47881},{\"end\":47893,\"start\":47891},{\"end\":47908,\"start\":47904},{\"end\":48182,\"start\":48179},{\"end\":48193,\"start\":48191},{\"end\":48209,\"start\":48202},{\"end\":48223,\"start\":48219},{\"end\":48436,\"start\":48434},{\"end\":48450,\"start\":48443},{\"end\":48462,\"start\":48458},{\"end\":48483,\"start\":48471},{\"end\":48498,\"start\":48491},{\"end\":48662,\"start\":48657},{\"end\":48678,\"start\":48672},{\"end\":48691,\"start\":48686},{\"end\":48706,\"start\":48699},{\"end\":48717,\"start\":48713},{\"end\":48731,\"start\":48727},{\"end\":48750,\"start\":48745},{\"end\":48761,\"start\":48757},{\"end\":48770,\"start\":48768},{\"end\":48787,\"start\":48775},{\"end\":48803,\"start\":48795},{\"end\":48813,\"start\":48810},{\"end\":48827,\"start\":48819},{\"end\":48841,\"start\":48834},{\"end\":48855,\"start\":48850},{\"end\":48874,\"start\":48863},{\"end\":48890,\"start\":48883},{\"end\":48903,\"start\":48899},{\"end\":48921,\"start\":48910},{\"end\":49414,\"start\":49409},{\"end\":49427,\"start\":49422},{\"end\":49434,\"start\":49432},{\"end\":49446,\"start\":49441},{\"end\":49623,\"start\":49619},{\"end\":49637,\"start\":49630},{\"end\":49647,\"start\":49643},{\"end\":49658,\"start\":49653},{\"end\":49672,\"start\":49667},{\"end\":50077,\"start\":50073},{\"end\":50091,\"start\":50084},{\"end\":50101,\"start\":50097},{\"end\":50112,\"start\":50107},{\"end\":50126,\"start\":50121},{\"end\":50487,\"start\":50483},{\"end\":50506,\"start\":50499},{\"end\":50514,\"start\":50511},{\"end\":50525,\"start\":50522},{\"end\":50540,\"start\":50534},{\"end\":50553,\"start\":50549},{\"end\":50570,\"start\":50560},{\"end\":50588,\"start\":50580}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2110.14168\",\"id\":\"b0\"},\"end\":23036,\"start\":22782},{\"attributes\":{\"doi\":\"10.48550/arXiv.2205.09712\",\"id\":\"b1\"},\"end\":23427,\"start\":23038},{\"attributes\":{\"id\":\"b2\"},\"end\":23832,\"start\":23429},{\"attributes\":{\"id\":\"b3\"},\"end\":24113,\"start\":23834},{\"attributes\":{\"id\":\"b4\"},\"end\":24602,\"start\":24115},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":229923710},\"end\":25343,\"start\":24604},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":229923710},\"end\":26166,\"start\":25345},{\"attributes\":{\"id\":\"b7\"},\"end\":26621,\"start\":26168},{\"attributes\":{\"id\":\"b8\"},\"end\":26917,\"start\":26623},{\"attributes\":{\"id\":\"b9\"},\"end\":27390,\"start\":26919},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":230433941},\"end\":28230,\"start\":27392},{\"attributes\":{\"id\":\"b11\"},\"end\":28835,\"start\":28232},{\"attributes\":{\"id\":\"b12\"},\"end\":29033,\"start\":28837},{\"attributes\":{\"id\":\"b13\"},\"end\":29833,\"start\":29035},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":231632658},\"end\":30424,\"start\":29835},{\"attributes\":{\"id\":\"b15\"},\"end\":30855,\"start\":30426},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":233296494},\"end\":31524,\"start\":30857},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":236956577},\"end\":32259,\"start\":31526},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":9586240},\"end\":32869,\"start\":32261},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":246426909},\"end\":33410,\"start\":32871},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":207783692},\"end\":34395,\"start\":33412},{\"attributes\":{\"id\":\"b21\"},\"end\":34764,\"start\":34397},{\"attributes\":{\"id\":\"b22\"},\"end\":34966,\"start\":34766},{\"attributes\":{\"id\":\"b23\"},\"end\":35239,\"start\":34968},{\"attributes\":{\"id\":\"b24\"},\"end\":38070,\"start\":35241},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":204838007},\"end\":38589,\"start\":38072},{\"attributes\":{\"id\":\"b26\"},\"end\":38910,\"start\":38591},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":207178704},\"end\":39238,\"start\":38912},{\"attributes\":{\"id\":\"b28\"},\"end\":39790,\"start\":39240},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":221703107},\"end\":40600,\"start\":39792},{\"attributes\":{\"id\":\"b30\"},\"end\":41375,\"start\":40602},{\"attributes\":{\"id\":\"b31\"},\"end\":41852,\"start\":41377},{\"attributes\":{\"id\":\"b32\"},\"end\":42273,\"start\":41854},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":990233},\"end\":43064,\"start\":42275},{\"attributes\":{\"id\":\"b34\"},\"end\":43552,\"start\":43066},{\"attributes\":{\"id\":\"b35\"},\"end\":44092,\"start\":43554},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":201698258},\"end\":44938,\"start\":44094},{\"attributes\":{\"id\":\"b37\"},\"end\":45052,\"start\":44940},{\"attributes\":{\"id\":\"b38\"},\"end\":45298,\"start\":45054},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":253098851},\"end\":45668,\"start\":45300},{\"attributes\":{\"id\":\"b40\"},\"end\":46133,\"start\":45670},{\"attributes\":{\"id\":\"b41\"},\"end\":46583,\"start\":46135},{\"attributes\":{\"id\":\"b42\"},\"end\":46952,\"start\":46585},{\"attributes\":{\"id\":\"b43\"},\"end\":47170,\"start\":46954},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":253098311},\"end\":47796,\"start\":47172},{\"attributes\":{\"id\":\"b45\"},\"end\":48096,\"start\":47798},{\"attributes\":{\"id\":\"b46\"},\"end\":48402,\"start\":48098},{\"attributes\":{\"id\":\"b47\"},\"end\":48647,\"start\":48404},{\"attributes\":{\"id\":\"b48\"},\"end\":49334,\"start\":48649},{\"attributes\":{\"id\":\"b49\"},\"end\":49610,\"start\":49336},{\"attributes\":{\"id\":\"b50\"},\"end\":49992,\"start\":49612},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":231979430},\"end\":50399,\"start\":49994},{\"attributes\":{\"id\":\"b52\"},\"end\":50894,\"start\":50401}]", "bib_title": "[{\"end\":24663,\"start\":24604},{\"end\":25404,\"start\":25345},{\"end\":27451,\"start\":27392},{\"end\":29881,\"start\":29835},{\"end\":30955,\"start\":30857},{\"end\":31597,\"start\":31526},{\"end\":32279,\"start\":32261},{\"end\":32938,\"start\":32871},{\"end\":33453,\"start\":33412},{\"end\":38152,\"start\":38072},{\"end\":38966,\"start\":38912},{\"end\":39873,\"start\":39792},{\"end\":40691,\"start\":40602},{\"end\":42352,\"start\":42275},{\"end\":44156,\"start\":44094},{\"end\":45367,\"start\":45300},{\"end\":47244,\"start\":47172},{\"end\":50065,\"start\":49994}]", "bib_author": "[{\"end\":22850,\"start\":22830},{\"end\":22862,\"start\":22850},{\"end\":22872,\"start\":22862},{\"end\":23056,\"start\":23038},{\"end\":23073,\"start\":23056},{\"end\":23088,\"start\":23073},{\"end\":23498,\"start\":23487},{\"end\":23512,\"start\":23498},{\"end\":23525,\"start\":23512},{\"end\":23537,\"start\":23525},{\"end\":23550,\"start\":23537},{\"end\":23565,\"start\":23550},{\"end\":23578,\"start\":23565},{\"end\":23895,\"start\":23887},{\"end\":23905,\"start\":23895},{\"end\":23923,\"start\":23905},{\"end\":23936,\"start\":23923},{\"end\":23949,\"start\":23936},{\"end\":24124,\"start\":24115},{\"end\":24141,\"start\":24124},{\"end\":24152,\"start\":24141},{\"end\":24170,\"start\":24152},{\"end\":24184,\"start\":24170},{\"end\":24200,\"start\":24184},{\"end\":24213,\"start\":24200},{\"end\":24224,\"start\":24213},{\"end\":24237,\"start\":24224},{\"end\":24252,\"start\":24237},{\"end\":24677,\"start\":24665},{\"end\":24689,\"start\":24677},{\"end\":24701,\"start\":24689},{\"end\":25418,\"start\":25406},{\"end\":25430,\"start\":25418},{\"end\":25442,\"start\":25430},{\"end\":26178,\"start\":26168},{\"end\":26195,\"start\":26178},{\"end\":26207,\"start\":26195},{\"end\":26220,\"start\":26207},{\"end\":26230,\"start\":26220},{\"end\":26247,\"start\":26230},{\"end\":26634,\"start\":26623},{\"end\":26645,\"start\":26634},{\"end\":26662,\"start\":26645},{\"end\":26928,\"start\":26919},{\"end\":26940,\"start\":26928},{\"end\":26953,\"start\":26940},{\"end\":26969,\"start\":26953},{\"end\":26987,\"start\":26969},{\"end\":26996,\"start\":26987},{\"end\":27009,\"start\":26996},{\"end\":27021,\"start\":27009},{\"end\":27036,\"start\":27021},{\"end\":27465,\"start\":27453},{\"end\":27475,\"start\":27465},{\"end\":27482,\"start\":27475},{\"end\":28257,\"start\":28234},{\"end\":28273,\"start\":28257},{\"end\":28289,\"start\":28273},{\"end\":28303,\"start\":28289},{\"end\":28316,\"start\":28303},{\"end\":28328,\"start\":28316},{\"end\":28339,\"start\":28328},{\"end\":28353,\"start\":28339},{\"end\":28370,\"start\":28353},{\"end\":28384,\"start\":28370},{\"end\":28398,\"start\":28384},{\"end\":28414,\"start\":28398},{\"end\":28435,\"start\":28414},{\"end\":28446,\"start\":28435},{\"end\":28461,\"start\":28446},{\"end\":28472,\"start\":28461},{\"end\":28483,\"start\":28472},{\"end\":28505,\"start\":28483},{\"end\":28515,\"start\":28505},{\"end\":28905,\"start\":28890},{\"end\":28909,\"start\":28905},{\"end\":29111,\"start\":29088},{\"end\":29127,\"start\":29111},{\"end\":29143,\"start\":29127},{\"end\":29157,\"start\":29143},{\"end\":29170,\"start\":29157},{\"end\":29182,\"start\":29170},{\"end\":29193,\"start\":29182},{\"end\":29207,\"start\":29193},{\"end\":29224,\"start\":29207},{\"end\":29238,\"start\":29224},{\"end\":29252,\"start\":29238},{\"end\":29268,\"start\":29252},{\"end\":29289,\"start\":29268},{\"end\":29300,\"start\":29289},{\"end\":29315,\"start\":29300},{\"end\":29326,\"start\":29315},{\"end\":29337,\"start\":29326},{\"end\":29359,\"start\":29337},{\"end\":29376,\"start\":29359},{\"end\":29390,\"start\":29376},{\"end\":29405,\"start\":29390},{\"end\":29409,\"start\":29405},{\"end\":29897,\"start\":29883},{\"end\":29911,\"start\":29897},{\"end\":29924,\"start\":29911},{\"end\":29935,\"start\":29924},{\"end\":29951,\"start\":29935},{\"end\":29965,\"start\":29951},{\"end\":29971,\"start\":29965},{\"end\":30543,\"start\":30530},{\"end\":30556,\"start\":30543},{\"end\":30567,\"start\":30556},{\"end\":30583,\"start\":30567},{\"end\":30600,\"start\":30583},{\"end\":30615,\"start\":30600},{\"end\":30965,\"start\":30957},{\"end\":30978,\"start\":30965},{\"end\":30994,\"start\":30978},{\"end\":31012,\"start\":30994},{\"end\":31030,\"start\":31012},{\"end\":31610,\"start\":31599},{\"end\":31622,\"start\":31610},{\"end\":31643,\"start\":31622},{\"end\":31661,\"start\":31643},{\"end\":32299,\"start\":32281},{\"end\":32316,\"start\":32299},{\"end\":32336,\"start\":32316},{\"end\":32953,\"start\":32940},{\"end\":32965,\"start\":32953},{\"end\":32975,\"start\":32965},{\"end\":32990,\"start\":32975},{\"end\":33010,\"start\":32990},{\"end\":33026,\"start\":33010},{\"end\":33039,\"start\":33026},{\"end\":33057,\"start\":33039},{\"end\":33073,\"start\":33057},{\"end\":33084,\"start\":33073},{\"end\":33470,\"start\":33455},{\"end\":33487,\"start\":33470},{\"end\":33505,\"start\":33487},{\"end\":33520,\"start\":33505},{\"end\":33535,\"start\":33520},{\"end\":33547,\"start\":33535},{\"end\":33565,\"start\":33547},{\"end\":34478,\"start\":34466},{\"end\":34490,\"start\":34478},{\"end\":34501,\"start\":34490},{\"end\":34517,\"start\":34501},{\"end\":34531,\"start\":34517},{\"end\":34543,\"start\":34531},{\"end\":34840,\"start\":34826},{\"end\":34860,\"start\":34840},{\"end\":35035,\"start\":35021},{\"end\":35044,\"start\":35035},{\"end\":35057,\"start\":35044},{\"end\":35069,\"start\":35057},{\"end\":35083,\"start\":35069},{\"end\":35099,\"start\":35083},{\"end\":35253,\"start\":35241},{\"end\":35273,\"start\":35253},{\"end\":35285,\"start\":35273},{\"end\":35301,\"start\":35285},{\"end\":35318,\"start\":35301},{\"end\":35332,\"start\":35318},{\"end\":35348,\"start\":35332},{\"end\":35365,\"start\":35348},{\"end\":35377,\"start\":35365},{\"end\":35393,\"start\":35377},{\"end\":35411,\"start\":35393},{\"end\":35425,\"start\":35411},{\"end\":35439,\"start\":35425},{\"end\":35455,\"start\":35439},{\"end\":35471,\"start\":35455},{\"end\":35497,\"start\":35471},{\"end\":35518,\"start\":35497},{\"end\":35533,\"start\":35518},{\"end\":35547,\"start\":35533},{\"end\":35562,\"start\":35547},{\"end\":35578,\"start\":35562},{\"end\":35597,\"start\":35578},{\"end\":35612,\"start\":35597},{\"end\":35629,\"start\":35612},{\"end\":35642,\"start\":35629},{\"end\":35657,\"start\":35642},{\"end\":35675,\"start\":35657},{\"end\":35689,\"start\":35675},{\"end\":35697,\"start\":35689},{\"end\":35710,\"start\":35697},{\"end\":35730,\"start\":35710},{\"end\":35749,\"start\":35730},{\"end\":35763,\"start\":35749},{\"end\":35780,\"start\":35763},{\"end\":35796,\"start\":35780},{\"end\":35814,\"start\":35796},{\"end\":35829,\"start\":35814},{\"end\":35843,\"start\":35829},{\"end\":35862,\"start\":35843},{\"end\":35880,\"start\":35862},{\"end\":35897,\"start\":35880},{\"end\":35916,\"start\":35897},{\"end\":35932,\"start\":35916},{\"end\":38168,\"start\":38154},{\"end\":38182,\"start\":38168},{\"end\":38196,\"start\":38182},{\"end\":38211,\"start\":38196},{\"end\":38226,\"start\":38211},{\"end\":38242,\"start\":38226},{\"end\":38254,\"start\":38242},{\"end\":38262,\"start\":38254},{\"end\":38275,\"start\":38262},{\"end\":38683,\"start\":38663},{\"end\":38696,\"start\":38683},{\"end\":38987,\"start\":38968},{\"end\":39002,\"start\":38987},{\"end\":39264,\"start\":39242},{\"end\":39281,\"start\":39264},{\"end\":39294,\"start\":39281},{\"end\":39310,\"start\":39294},{\"end\":39323,\"start\":39310},{\"end\":39338,\"start\":39323},{\"end\":39364,\"start\":39338},{\"end\":39383,\"start\":39364},{\"end\":39398,\"start\":39383},{\"end\":39405,\"start\":39398},{\"end\":39888,\"start\":39875},{\"end\":39905,\"start\":39888},{\"end\":40706,\"start\":40693},{\"end\":40723,\"start\":40706},{\"end\":40739,\"start\":40723},{\"end\":40745,\"start\":40739},{\"end\":40759,\"start\":40745},{\"end\":40773,\"start\":40759},{\"end\":41395,\"start\":41377},{\"end\":41412,\"start\":41395},{\"end\":41423,\"start\":41412},{\"end\":41442,\"start\":41423},{\"end\":41456,\"start\":41442},{\"end\":41473,\"start\":41456},{\"end\":41959,\"start\":41941},{\"end\":41976,\"start\":41959},{\"end\":41987,\"start\":41976},{\"end\":42006,\"start\":41987},{\"end\":42020,\"start\":42006},{\"end\":42037,\"start\":42020},{\"end\":42370,\"start\":42354},{\"end\":42386,\"start\":42370},{\"end\":42395,\"start\":42386},{\"end\":42409,\"start\":42395},{\"end\":42432,\"start\":42409},{\"end\":42443,\"start\":42432},{\"end\":42462,\"start\":42443},{\"end\":43078,\"start\":43066},{\"end\":43091,\"start\":43078},{\"end\":43106,\"start\":43091},{\"end\":43118,\"start\":43106},{\"end\":43131,\"start\":43118},{\"end\":43142,\"start\":43131},{\"end\":43153,\"start\":43142},{\"end\":43169,\"start\":43153},{\"end\":43187,\"start\":43169},{\"end\":43195,\"start\":43187},{\"end\":43202,\"start\":43195},{\"end\":43562,\"start\":43554},{\"end\":43570,\"start\":43562},{\"end\":43584,\"start\":43570},{\"end\":43601,\"start\":43584},{\"end\":43610,\"start\":43601},{\"end\":43623,\"start\":43610},{\"end\":43635,\"start\":43623},{\"end\":43644,\"start\":43635},{\"end\":43653,\"start\":43644},{\"end\":43663,\"start\":43653},{\"end\":43674,\"start\":43663},{\"end\":43694,\"start\":43674},{\"end\":43708,\"start\":43694},{\"end\":43717,\"start\":43708},{\"end\":44172,\"start\":44158},{\"end\":44182,\"start\":44172},{\"end\":44198,\"start\":44182},{\"end\":44212,\"start\":44198},{\"end\":44226,\"start\":44212},{\"end\":44995,\"start\":44983},{\"end\":45127,\"start\":45117},{\"end\":45145,\"start\":45127},{\"end\":45381,\"start\":45369},{\"end\":45393,\"start\":45381},{\"end\":45403,\"start\":45393},{\"end\":45683,\"start\":45670},{\"end\":45694,\"start\":45683},{\"end\":45711,\"start\":45694},{\"end\":45720,\"start\":45711},{\"end\":45728,\"start\":45720},{\"end\":45743,\"start\":45728},{\"end\":45764,\"start\":45743},{\"end\":45776,\"start\":45764},{\"end\":46146,\"start\":46135},{\"end\":46154,\"start\":46146},{\"end\":46171,\"start\":46154},{\"end\":46185,\"start\":46171},{\"end\":46198,\"start\":46185},{\"end\":46218,\"start\":46198},{\"end\":46233,\"start\":46218},{\"end\":46248,\"start\":46233},{\"end\":46260,\"start\":46248},{\"end\":46276,\"start\":46260},{\"end\":46667,\"start\":46656},{\"end\":46680,\"start\":46667},{\"end\":46697,\"start\":46680},{\"end\":46712,\"start\":46697},{\"end\":46722,\"start\":46712},{\"end\":46731,\"start\":46722},{\"end\":46743,\"start\":46731},{\"end\":47001,\"start\":46989},{\"end\":47016,\"start\":47001},{\"end\":47029,\"start\":47016},{\"end\":47044,\"start\":47029},{\"end\":47259,\"start\":47246},{\"end\":47271,\"start\":47259},{\"end\":47283,\"start\":47271},{\"end\":47298,\"start\":47283},{\"end\":47306,\"start\":47298},{\"end\":47321,\"start\":47306},{\"end\":47860,\"start\":47847},{\"end\":47872,\"start\":47860},{\"end\":47887,\"start\":47872},{\"end\":47895,\"start\":47887},{\"end\":47910,\"start\":47895},{\"end\":48184,\"start\":48174},{\"end\":48195,\"start\":48184},{\"end\":48211,\"start\":48195},{\"end\":48225,\"start\":48211},{\"end\":48438,\"start\":48430},{\"end\":48452,\"start\":48438},{\"end\":48464,\"start\":48452},{\"end\":48485,\"start\":48464},{\"end\":48500,\"start\":48485},{\"end\":48664,\"start\":48651},{\"end\":48680,\"start\":48664},{\"end\":48693,\"start\":48680},{\"end\":48708,\"start\":48693},{\"end\":48719,\"start\":48708},{\"end\":48733,\"start\":48719},{\"end\":48752,\"start\":48733},{\"end\":48763,\"start\":48752},{\"end\":48772,\"start\":48763},{\"end\":48789,\"start\":48772},{\"end\":48805,\"start\":48789},{\"end\":48815,\"start\":48805},{\"end\":48829,\"start\":48815},{\"end\":48843,\"start\":48829},{\"end\":48857,\"start\":48843},{\"end\":48876,\"start\":48857},{\"end\":48892,\"start\":48876},{\"end\":48905,\"start\":48892},{\"end\":48923,\"start\":48905},{\"end\":49416,\"start\":49399},{\"end\":49429,\"start\":49416},{\"end\":49436,\"start\":49429},{\"end\":49448,\"start\":49436},{\"end\":49625,\"start\":49612},{\"end\":49639,\"start\":49625},{\"end\":49649,\"start\":49639},{\"end\":49660,\"start\":49649},{\"end\":49674,\"start\":49660},{\"end\":50079,\"start\":50067},{\"end\":50093,\"start\":50079},{\"end\":50103,\"start\":50093},{\"end\":50114,\"start\":50103},{\"end\":50128,\"start\":50114},{\"end\":50489,\"start\":50477},{\"end\":50508,\"start\":50489},{\"end\":50516,\"start\":50508},{\"end\":50527,\"start\":50516},{\"end\":50542,\"start\":50527},{\"end\":50555,\"start\":50542},{\"end\":50572,\"start\":50555},{\"end\":50590,\"start\":50572}]", "bib_venue": "[{\"end\":25012,\"start\":24865},{\"end\":25782,\"start\":25635},{\"end\":27822,\"start\":27675},{\"end\":31202,\"start\":31119},{\"end\":31866,\"start\":31779},{\"end\":32575,\"start\":32460},{\"end\":33938,\"start\":33762},{\"end\":36608,\"start\":36584},{\"end\":40207,\"start\":40080},{\"end\":40979,\"start\":40900},{\"end\":42645,\"start\":42550},{\"end\":44587,\"start\":44423},{\"end\":47423,\"start\":47392},{\"end\":22828,\"start\":22782},{\"end\":23234,\"start\":23129},{\"end\":23485,\"start\":23429},{\"end\":23885,\"start\":23834},{\"end\":24332,\"start\":24268},{\"end\":24863,\"start\":24701},{\"end\":25633,\"start\":25471},{\"end\":26397,\"start\":26288},{\"end\":26748,\"start\":26678},{\"end\":27151,\"start\":27036},{\"end\":27673,\"start\":27511},{\"end\":28888,\"start\":28837},{\"end\":29086,\"start\":29035},{\"end\":30059,\"start\":29971},{\"end\":30528,\"start\":30426},{\"end\":31117,\"start\":31030},{\"end\":31777,\"start\":31690},{\"end\":32458,\"start\":32336},{\"end\":33133,\"start\":33084},{\"end\":33760,\"start\":33585},{\"end\":34464,\"start\":34397},{\"end\":34824,\"start\":34766},{\"end\":35019,\"start\":34968},{\"end\":36127,\"start\":35973},{\"end\":38311,\"start\":38275},{\"end\":38661,\"start\":38591},{\"end\":39068,\"start\":39020},{\"end\":40078,\"start\":39936},{\"end\":40898,\"start\":40804},{\"end\":41615,\"start\":41514},{\"end\":41939,\"start\":41854},{\"end\":42548,\"start\":42462},{\"end\":43284,\"start\":43218},{\"end\":43825,\"start\":43758},{\"end\":44421,\"start\":44246},{\"end\":44981,\"start\":44940},{\"end\":45115,\"start\":45054},{\"end\":45475,\"start\":45403},{\"end\":45904,\"start\":45817},{\"end\":46335,\"start\":46292},{\"end\":46654,\"start\":46585},{\"end\":46987,\"start\":46954},{\"end\":47390,\"start\":47321},{\"end\":47845,\"start\":47798},{\"end\":48172,\"start\":48098},{\"end\":48428,\"start\":48404},{\"end\":49397,\"start\":49336},{\"end\":49802,\"start\":49715},{\"end\":50176,\"start\":50132},{\"end\":50475,\"start\":50401}]"}}}, "year": 2023, "month": 12, "day": 17}