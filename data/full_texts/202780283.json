{"id": 202780283, "updated": "2023-04-05 03:50:06.461", "metadata": {"title": "Differentiable Cloth Simulation for Inverse Problems", "authors": "[{\"first\":\"Junbang\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Ming\",\"last\":\"Lin\",\"middle\":[\"C.\"]},{\"first\":\"Vladlen\",\"last\":\"Koltun\",\"middle\":[]}]", "venue": "NeurIPS", "journal": "771-780", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "We propose a differentiable cloth simulator that can be embedded as a layer in deep neural networks. This approach provides an effective, robust framework for modeling cloth dynamics, self-collisions, and contacts. Due to the high dimensionality of the dynamical system in modeling cloth, traditional gradient computation for collision response can become impractical. To address this problem, we propose to compute the gradient directly using QR decomposition of a much smaller matrix. Experimental results indicate that our method can speed up backpropagation by two orders of magnitude. We demonstrate the presented approach on a number of inverse problems, including parameter estimation and motion control for cloth.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2970529185", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/LiangLK19", "doi": null}}, "content": {"source": {"pdf_hash": "5ae465e174e28024ff59deef043152b7495ba49e", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4f3896690bbdeb19cd7613fafd2701b630dc947c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5ae465e174e28024ff59deef043152b7495ba49e.txt", "contents": "\nDifferentiable Cloth Simulation for Inverse Problems\n\n\nJunbang Liang \nUniversity of Maryland\nCollege Park\n\nMing C Lin \nUniversity of Maryland\nCollege Park\n\nVladlen Koltun \nIntel Labs\n\n\nDifferentiable Cloth Simulation for Inverse Problems\n\nWe propose a differentiable cloth simulator that can be embedded as a layer in deep neural networks. This approach provides an effective, robust framework for modeling cloth dynamics, self-collisions, and contacts. Due to the high dimensionality of the dynamical system in modeling cloth, traditional gradient computation for collision response can become impractical. To address this problem, we propose to compute the gradient directly using QR decomposition of a much smaller matrix. Experimental results indicate that our method can speed up backpropagation by two orders of magnitude. We demonstrate the presented approach on a number of inverse problems, including parameter estimation and motion control for cloth.\n\nIntroduction\n\nDifferentiable physics simulation is a powerful family of techniques that applies gradient-based methods to learning and control of physical systems [7; 8; 29; 13; 25]. It can enable optimization for control, and can also be integrated into neural network frameworks for performing complex tasks. Our work focuses on cloth simulation, which relates to applications in robotics, computer vision, and computer graphics [6; 19; 3; 31; 23; 16; 11]. Our goal is to enable differentiable cloth simulation, which can provide a unified approach to a variety of inverse problems that involve cloth.\n\nDifferentiable cloth simulation is challenging due to a number of factors, which include the high dimensionality of cloth (as compared for example to rigid bodies [7]) and the need to handle contacts and collision. For example, a simple 16\u21e516 grid-based cloth mesh has 289 vertices, 867 variables, and 512 faces when triangulated. Typical resolutions for garments would be at least many thousands, if not millions, of vertices and faces. Previous work that tackled differentiable simulation with collisions set up a static linear solver to account for all constraints [7]. In our simple example with cloth, the number of pairwise constraints would be at least 289\u21e5512 = 140K for vertex-face collisions alone, which renders existing methods impractical even for this simple system. Even if a dynamic solver is applied upon collision, solving a dense linear system with such high dimensionality makes the gradient computation infeasible.\n\nIn this paper, we propose a differentiable cloth simulation algorithm that overcomes the above difficulties. First, we use dynamic collision detection since the actual collision pairs are very sparse. The collision response is solved by quadratic optimization, for which we can use implicit differentiation to compute the gradient. We directly solve the equations derived from implicit differentiation by using the QR decomposition of the constraint matrix, which is much smaller than the original linear system and is often of low rank. This approach reduces the gradient computation to a linear system of a small upper triangular matrix (the R component of the decomposition), which enables fast simulation and backpropagation.\n\nOur experiments indicate that the presented method makes differentiable cloth simulation practical. Using our method, the largest size of the linear system is 10x-20x smaller than the original solver in the backpropagation of the collision response, and the solver is 60x-130x faster. We demonstrate the potential of differentiable cloth simulation in a number of application scenarios, such as physical parameter estimation and motion control of cloth. With only a few samples, the differentiable simulator can optimize its input variables to fit the data, thereby inferring physical parameters from observations and reaching desired control goals.\n\n\nRelated Work\n\nDifferentiable physics. With recent advances in deep learning, there has been increasing interest in differentiable physics simulation, which can be combined with other learning methods to provide physically consistent predictions. Belbute-Peres et al. [7] and Degrave et al. [8] proposed rigid body simulators using a static formulation of the linear complementarity problem (LCP) [5; 4]. Toussaint et al. [29] developed a robot reasoning system that can achieve user-defined tasks and is based on differentiable primitives. Hu et al. [13] implemented a differentiable simulator for soft robots based on the Material Point Method (MPM). They store the object data at every simulation step so that the gradient can be computed out of the box. Schenck and Fox [25] embedded particle-based fluid dynamics into convolutional neural networks, with precomputed signed distance functions for collision handling. They solved or avoided collisions by assuming special object shapes, transferring to an Eulerian grid, or solving the corresponding collision constraint equation.\n\nNone of these methods can be applied to cloth simulation. First, cloth is a 2D surface in a 3D world; thus methods that use an Eulerian grid to compute material density, such as MPM [13], are not applicable. Second, the collision constraints in cloth simulation are more dynamic and complex given the high number of degrees of freedom; thus constructing a static dense LCP for the entire system [7; 8] or constructing the overall state transition graph [29] is inefficient and usually impossible for cloth of common resolution, since contact can happen for every edge-edge or vertex-face pair. Lastly, the shape of cloth changes constantly so self-collision cannot be handled by precomputed signed distance functions [25].\n\nIn contrast, our method uses dynamic collision detection and computes the gradients of the collision response by performing implicit differentiation on the quadratic optimization used for computing the response. We utilize the low dimensionality and rank of the constraint matrix in the quadratic optimization and minimize the computation needed for the gradient propagation by giving an explicit solution to the linear system using QR decomposition of the constraint matrix.\n\nDeep learning and physics. Supervised deep networks have been used to approximate physical dynamics. Mrowca et al. [21] and Li et al. [17] learned interaction networks to model particle systems. Ingraham et al. [14] trained a model to predict protein structures from sequences using a learnable simulator; the simulator predicts the deformation energy as an approximation to the physical process. Deep networks have also been used to support the simulation of fluid dynamics [28; 15; 20]. Our method differs from many works that use deep networks to approximate physical systems in that we backpropagate through the true physical simulation. Thus our method conforms to physical law regardless of the scale of the problem. It can also naturally accept physical parameters as input, which enables learning from data.\n\nDeep learning and cloth. Coupling cloth simulation with deep learning has become a popular way to solve problems such as detail refinement, garment retargeting, and material estimation. Yang et al. [31] proposed a recurrent model to estimate physical cloth parameters from video. L\u00e4hner et al. [16] trained a GAN to generate wrinkles on a coarse garment mesh which can then be automatically registered to a human body using PCA. Gundogdu et al. [11] trained a graph convolutional framework to generate drapes and wrinkles given a roughly registered mesh. Santesteban et al. [24] developed an end-to-end retargeting network using a parametric human body model with displacements to represent the cloth.\n\nThese applications may benefit from our method. For garment retargeting problems, the relationship between body pose and vertex displacement is made explicit via the computed gradient, which can then be applied in network regularization for better performance. For parameter estimation, the differentiable simulation provides an optimization-based solution rather than a learning-based one. Instead of learning statistics from a large amount of data, we can directly apply gradient-based optimization via the simulator, which does not require any training data.\n\n\nDifferentiable Cloth Simulation\n\nIn this section, we introduce the main algorithms for the gradient computation. In general, we follow the computation flow of the common approach to cloth simulation: discretization using the finite element method [9], integration using implicit Euler [2], and collision response on impact zones [22; 12]. We use implicit differentiation in the linear solve and the optimization in order to compute the gradient with respect to the input parameters. The discontinuity introduced by the collision response is negligible because the discontinuous states constitute a zero-measure set. During the backpropagation in the optimization, the gradient values can be directly computed after QR decomposition of the constraint matrix.\n\n\nOverview\n\nWe begin by defining the problem formally and providing common notation. A triangular mesh M = {V, E, F} consists of sets of vertex states, edges, and faces, where the state of the vertices includes both position x and velocity v. Given a cloth mesh M t together with obstacle meshes M obs t at step t, a cloth simulator can compute the mesh state M t+1 at the next step t + 1 based on the computed internal and external forces and the collision response. A simple simulation pipeline is shown in Algorithm 1, where M is the mass matrix, f is the force, and a is the acceleration. For more detailed description of cloth simulation, please refer to Appendix B. All gradients except the linear solve (Line 4 in Algorithm 1) and the collision response (Line 7) can be computed using automatic differentiation in PyTorch [26].\nAlgorithm 1 Cloth simulation 1: v 0 0 2: for t = 1 to n do 3: M, f compute_forces(x, v) 4: a t M 1 f 5: v t v t 1 + a t t 6: x t x t 1 + v t t 7: x t x t + collision_response(x t , v t , x obs t , v obs t ) 8: v t (x t x t 1 )/ t 9: end for\n\nDerivatives of the Physics Solve\n\nIn modern simulation algorithms, implicit Euler is often used for stable integration results. Thus the mass matrix M used in Algorithm 1 often includes the Jacobian of the forces (see Appendix B for the exact formulation). We denote it below asM in order to mark the difference. A linear solve will be needed to compute the acceleration since it is time consuming to computeM 1 . We use implicit differentiation to compute the gradients of the linear solve. Given an equationMa = f with a solution z and the propagated gradient @L @a | a=z , where L is the task-specific loss function, we can use the implicit differentiation formM @a = @f @Ma (1) to derive the gradient as\n@L @M = d a z > @L @f = d > a ,(2)\nwhere d a is obtained from the linear system\nM > d a = @L @a > .(3)\nThe proof is as follows. We take @L @f as an example here, the derivation of @L @M is shown in Appendix A.1:\n@L @f = @L @a \u00b7 @a @f = d > aM \u00b7M \u2020 I = d > a .(4)\nThe first equality is given by the chain rule, the second is given by Equations 1 and 3, andM \u2020 is the pseudoinverse of matrixM.\n\n\nDynamic Collision Detection and Response\n\nAs mentioned in Sec. 1, a static collision solver is not suitable for cloth because the total number of possible collision pairs is very high: quadratic in the number of faces. A common approach in cloth simulation is to dynamically detect collision on the fly and compute the response. We use a bounding volume hierarchy for collision detection [27], and non-rigid impact zones [12] to compute the collision response.\n\nSpecifically, we solve a cubic equation to detect the collision time t of each vertex-face or edge-edge pair that is sufficiently close to contact:\n(x 1 + v 1 t) \u00b7 (x 2 + v 2 t)\u21e5(x 3 + v 3 t) = 0,(5)\nwhere x k and v k (k = 1, 2, 3) are the relative position and velocity to the first vertex. A solution that lies in [0, 1] means that a collision is possible before the next simulation step. After making sure that the pair indeed intersects at time t, we set up one constraint for this collision, forcing the signed distance of this collision pair at time t to be no less than the thickness of the cloth . The signed distance of the vertex-face or edge-edge pair is linear to the vertex position x. The set of all constraints then makes up a quadratic optimization problem as discussed later in Sec. 3.4.\n\nFor backpropagation, we need to compute the derivatives of the solution t since it is related to the parameters of the constraints. We use implicit differentiation here to simplify the process. Generally, given a cubic equation ax 3 + bx 2 + cx + d = 0, its implicit differentiation is of the following form:\n(3ax 2 + 2bx + c)@x = @ax 3 + @bx 2 + @cx + @d.(6)\nTherefore we have \u21e5 @x @a @x @b @x @c @x @d\n\u21e4 = 1 3ax 2 + 2bx + c \u21e5 x 3 x 2 x 1 \u21e4 .(7)\n\nDerivatives of the Collision Response\n\nA general approach to integrating collision constraints into physics simulation has been proposed by Belbute-Peres et al. [7]. However, as mentioned in Sections 1 and 2, constructing a static LCP is often impractical in cloth simulation because of high dimensionality. Collisions that actually happen in each step are very sparse compared to the complete set. Therefore, we use a dynamic approach that incorporates collision detection and response.\n\nCollision handling in our implementation is based on impact zone optimization [22]. It finds all colliding instances using continuous collision detection (Sec. 3.3) and sets up the constraints for all collisions. In order to introduce minimum change to the original mesh state, we develop a QP problem to solve for the constraints. Since the signed distance function is linear in x, the optimization takes a quadratic form:\nminimize z 1 2 (z x) > W(z x)(8)subject to Gz + h \uf8ff 0(9)\nwhere W is a constant diagonal weight matrix related to the mass of each vertex, and G and h are constraint parameters (see Appendix B for more details). We further denote the number of variables and constraints by n and m, i.e. x 2 R n , h 2 R m , and G 2 R m\u21e5n . Note that this optimization is a function with inputs x, G, and h, and output z. Our goal here is to derive @L @x , @L @G , and @L @h given @L @z , where L refers to the loss function.\n\nWhen computing the gradient using implicit differentiation [1], the dimensionality of the linear system (Equation 13) can be too high. Our key observation here is that n > > m > rank(G), since one contact often involves 4 vertices (thus 12 variables) and some contacts may be linearly dependent (e.g. multiple adjacent collision pairs). OptNet [1] solves a linear equation of size m + n, which is more than necessary. We introduce a simpler and more efficient algorithm below to minimize the size of the linear equation.\n\n\nQR Decomposition\n\nTo make things simpler, we assume that G is of full rank in this section. At global minimum z \u21e4 and \u21e4 of the Lagrangian, the following holds for stationarity and complementary slackness conditions:\nWz \u21e4 Wx + G > \u21e4 = 0 (10) D( \u21e4 )(Gz \u21e4 + h) = 0,(11)\nwith their implicit differentiation as\n\uf8ff W G > D( \u21e4 )G D(Gz \u21e4 + h) \uf8ff @z @ = \uf8ff M@x @G > \u21e4 D( \u21e4 )(@Gz \u21e4 + @h) ,(12)\nwhere D() transforms a vector to a diagonal matrix. Using similar derivation to Sec. 3.2, solving the equation\n\uf8ff W G > D( \u21e4 ) G D(Gz \u21e4 + h) \uf8ff d z d = \uf8ff @L @z > 0(13)\ncan provide the desired gradient:\n@L @x = d T z W(14)\n@L @G\n= D( \u21e4 )d z \u21e4> \u21e4 d > z (15) @L @h = d T D( \u21e4 ).(16)\n(See Appendix A.2 for the derivation.) However, as mentioned before, directly solving Equation 13 may be computationally expensive in our case. We show that by performing a QR decomposition, the solution can be derived without solving a large system. To further reduce computation, we assume that no constraint is 'over-satisfied', i.e. Gz \u21e4 + h = 0. We will remove these assumptions later in Sec. 3.4.2. We compute the QR decomposition of\np W 1 G > : p W 1 G > = QR.(17)\nThe solution of Equation 13 can be expressed as\nd z = p W 1 (I QQ > ) p W 1 @L @z > (18) d = D( \u21e4 ) 1 R 1 Q > p W 1 @L @z > ,(19)\nwhere p W 1 is the inverse of the square root of a diagonal matrix. The result above can be verified by substitution in Equation 13.\n\nThe intuition behind Equation 18 is as follows. When perturbing the original point x in an optimization, the resulting displacement of z will be moving along the surface of Gx + h = 0, which will become perpendicular to the normal when the perturbation is small. (Fig. 1 illustrates this idea in two dimensions.) This is where the term I QQ > comes from. Note that p W 1 G > is an n\u21e5m matrix, where n > > m and the QR decomposition will only take O(nm 2 ) time, compared to O((n + m) 3 ) in the original dense linear solve. After that we will need to solve a linear equation in Equation 19, but it is more efficient than solving Equation 13 since it is only of size m, and R is an upper-triangular matrix. In our collision response case, where n \uf8ff 12m, our method can provide up to 183x acceleration in theory. The speed-up in our experiments (Sec. 4) ranges from 60x to 130x for large linear systems.\n\n\nLow-rank Constraints\n\nThe algorithm above cannot be directly applied when G is low-rank, or when some constraint is not at boundary. This will cause R or D( \u21e4 ) to be singular. We now show that the singularity can be avoided via small modifications to the algorithm.\n\nFirst, if k = 0 for the k th constraint then d k doesn't matter. This is because the final result contains only components of D( \u21e4 )d but not d alone, as shown in Equations 15 and 16. Intuitively, if the constraint is over-satisfied, then perturbing the parameters of that constraint will not have impact on z. Based on this observation, we can remove the constraints in G when their corresponding is 0.\n\nNext, if G is of rank k, where k < m, then we can rewrite Equation 17 as\np W 1 G > = Q 1 [R 1 R 2 ],(20)\nwhere Q 1 2 R n\u21e5k , R 1 2 R k\u21e5k , and R 2 2 R k\u21e5(m k) . Getting rid of R 2 (i.e. removing those constraints from the beginning) does not affect the optimization result, but may change so that the computed gradients are incorrect. Therefore, we need to transfer the Lagrange multipliers to the linearly independent terms first:\n1 1 + R 1 1 R 2 2 ,(21)\nwhere 1 and 2 are the Lagrange multipliers corresponding to the constraints on R 1 and R 2 .\n\n\nExperiments\n\nWe conduct three experiments to showcase the power of differentiable cloth simulation. First, we use an ablation study to quantify the performance gained by using our method to compute the gradient. Next, we use the computed gradient to optimize the physical parameters of cloth. Lastly, we demonstrate the ability to control cloth motion.\n\n\nAblation Study\n\nAs mentioned in Sec. 3.4.1, our method for computing the gradients of the optimization can achieve a speed-up of up to 183x in theory. We conduct an ablation study to verify this estimate in practice. In order to clearly measure the timing difference, we design a scenario with many collisions. We put a piece of cloth into an upside-down square pyramid, so that the cloth is forced to fold, come into frequent contact with the pyramid, and collide with itself, as shown in Fig. 2. The experimental results also match well with the theory in Sec. 3.4. Each collision involves a vertex-face or edge-edge pair, which both have 4 vertices and 12 variables. Therefore, the original matrix size (n + m = 13m) should be about 13 times bigger than in our method (m). In our experiment, the ratio of the matrix size is indeed close to 13. Possible reasons for the ratio not being exactly 13 include (a) multiple collision pairs that share the same vertex, making n smaller, and (b) the constraint matrix can be of low rank, as described in Sec. 3 Table 1: Statistics of the backward propagation with and without our method for various mesh resolutions. We report the average values in each cell with the corresponding standard deviations. By using our method, the runtime of gradient computation is reduced by up to two orders of magnitude.\n\n\nMaterial Estimation\n\nIn this experiment, our aim is to learn the material parameters of cloth from observation. The scene features a piece of cloth hanging under gravity and subjected to a constant wind force, as shown in Fig. 3. We use the material model from Wang et al. [30]. It consists of three parts: density d, stretching stiffness S, and bending stiffness B. The stretching stiffness quantifies how large the reaction force will be when the cloth is stretched out; the bending stiffness models how easily the cloth can be bent and folded.\n\nWe used the real-world dataset from Wang et al. [30], which consists of 10 different cloth materials. There are in total 50 frames of simulated data. The first 25 frames are taken as input and all 50 frames are used to measure accuracy. This is a case-by-case optimization problem. Our goal is to fit the observed data in each sequence as well as possible, with no \"training set\" used for training. In our optimization setup, we use SGD with learning rate ranging from 0.01 to 0.1 and momentum from 0.9 to 0.99, depending on the convergence speed. The initial guess is the set of average values across all materials. We define the loss as the average MSE across all frames. In order to speed up optimization, we gradually increase the number of frames used. Specifically, we first optimize the parameters using only 1 simulated frame. We proceed to the second frame after the loss decreases to a certain threshold. This optimization scheme can help obtain a relatively good guess before additional frames are involved.\n\nAs a simple baseline, we measure the total external force and divide it by the observed acceleration to compute the density. For the stretching stiffness, we simplify the model to an isotropic one and record the maximum deformation magnitude along the vertical axis.\n\nSince the effect of the bending stiffness is too subtle to observe, we directly use the averaged value as our prior. We also compare our method with the L-BFGS optimization by Wang et al. [30] using finite difference. We used the PyTorch L-BFGS implementation and set the learning rate ranging from 0.1 to 0.2 depending on the convergence speed.\n\nFor the performance measurement, we use the Frobenius norm normalized by the target as the metric for the material parameters:\nE(P) = kP P 0 k F kP 0 k F ,(22)\nwhere P and P 0 are the estimated and the target physics parameters, which stand for either density d, stretching stiffness S, or bending stiffness B. In order to show the final visual effect, we also measure the average distance of the vertices between the estimated one and the target normalized by the size of the cloth as another metric:\nE(X) = 1 nT L X 1\uf8ffi\uf8ffT,1\uf8ffj\uf8ffn kX i,j Y i,j k 2 ,(23)\nwhere L is the size of the cloth, and X and Y are T \u21e5n\u21e53 matrices denoting the n simulated vertex positions across T frames using the estimated parameter and the target, respectively.\n\nTab. 2 shows the estimation result. We achieve a much smaller error in most measurements in comparison to the baselines. The reason the stiffness matrices do not have low error is that (a) a large part of them describes the nonlinear stress behavior that needs a large deformation of the cloth and is not commonly observed in our environment, (b) different stiffness values can sometimes provide similar results, and (c) the bending force for common cloth materials is too small compared to gravity and the wind forces to make an impact. The   We further demonstrate the power of our differentiable simulator by optimizing control parameters. The task is to drop a piece of cloth into a basket, as shown in Fig. 4. The cloth is originally placed on a table that is away from the basket. The system then applies external forces to the corners of the cloth to lift it and drop it into the basket. The external force is applied for 3 seconds and can be changed during this period. The basket is a box with an open top. A planar obstacle is placed between the cloth and the basket to increase the difficulty of the task.\n\n\nMotion Control\n\nWe define the loss here as the squared distance between the center of mass of the cloth and the bottom of the basket. To demonstrate the ability to embed the simulator into neural networks, we also couple our simulator with a two-layer fully-connected (FC) network that takes the mesh states as input and outputs the control forces. Our methods here are compared to two baselines. One of the baselines is a simple method that computes the momentum needed at every time step. The entire cloth is treated as a point mass and an external force is computed at each time step to control the point mass towards the goal. Obstacles are simply neglected in this method. The other baseline is the PPO algorithm, as implemented in Ray RLlib [18]. The reward function is defined as the negative of the distance of the center of mass of the cloth to the bottom of the basket. Please refer to the Appendix for additional details.  Tab. 3 shows the performance of the different methods and their sample complexity. The error shown in the table is the distance defined above normalized by the size of the cloth. Our method achieves the best performance with a much smaller number of simulation steps. The bottom of the basket in our setting has the same size as the cloth, so a normalized error of less than 50%, as our methods achieve, implies that the cloth is successfully dropped into the basket.\n\n\nConclusion\n\nWe presented a differentiable cloth simulator that can compute the analytical gradient of the simulation function with respect to the input parameters. We used dynamic collision handling and explicitly derived its gradient. Implicit differentiation is used in computing gradients of the linear solver and collision response. Experiments have demonstrated that our method accelerates backpropagation by up to two orders of magnitude.\n\nFigure 1 :\n1Impact of perturbation. A small perturbation of the target position will cause the final result to move along the constraint surface.\n\nFigure 2 :\n2Example frame from the ablation study. A piece of cloth is crumpled inside a square pyramid, so as to generate a large number of collisions.We measure the running time of backpropagation in each quadratic optimization and also the running time of the physics solve as a reference. With all other variables fixed, we compare to the baseline method where the gradients are computed by directly solving Equation13. Timings are listed in Tab. 1. In this experiment, the backpropagation of the physics solve takes from 0.007s to 0.5s, which, together with the timings of the baseline, implies that the collision handling step is the critical bottleneck when there are many collisions in the scene. The results in Tab. 1 show that our proposed method can significantly decrease the matrix size required for computation and thus the actual running time, resolving the bottleneck in backpropagation.\n\nFigure 3 :\n3Example frame from the material estimation scene for cloth blowing in the wind.\n\nFigure 4 :\n4Example frame from the motion control experiment: dropping cloth into a basket.\n\n\ntableshows that the linear part of the stiffness matrix is optimized well. With the computed gradient using our model, one can effectively optimize the unknown parameters that dominate the cloth movement to fit the observed data. We show in the supplementary video that the estimated parameters yield very similar qualitative behavior to the original observation.Compared with regular simulators, our simulator is designed to be embedded in deep networks. When gradients are needed, our simulator shows significant improvement over finite-difference methods, as shown in Tab. 2. Regular simulators need to run one simulation for each input variable to compute the gradient, while our method only needs to run once for all gradients to be computed. Therefore, the more input variables there are during learning, the greater the performance gain that can be achieved by our method over finite-difference methods.Method \nRuntime \n(sec/step/iter) \n\nDensity \nerror (%) \n\nNon-ln streching \nstiffness error (%) \n\nLn streching \nstiffness error (%) \n\nBending stiffness \nerror (%) \n\nSimulation \nerror (%) \n\nBaseline \n-\n68 \u00b1 46 \n74 \u00b1 23 \n160 \u00b1 119 \n70 \u00b1 42 \n12 \u00b1 3.0 \nL-BFGS [30] \n2.89 \u00b1 0.02 \n4.2 \u00b1 5.6 \n64 \u00b1 34 \n72 \u00b1 90 \n70 \u00b1 43 \n4.9 \u00b1 3.3 \nOurs \n2.03 \u00b1 0.06 \n1.8 \u00b1 2.0 \n57 \u00b1 29 \n45 \u00b1 41 \n77 \u00b1 36 \n1.6 \u00b1 1.4 \n\n\n\nTable 2 :\n2Results on the material parameter estimation task. Lower is better. 'Ln' stands for 'linear'. Values of the material parameters are the Frobenius norms of the difference normalized by the Frobenius norm of the target. Values of the simulated result are the average pairwise vertex distance normalized by the size of the cloth. Our gradient-based method yields much smaller error than the baselines.\n\nTable 3 :\n3Motion control results. The table reports the smallest distance to the target position, normalized by the size of the cloth, and the number of samples used during training.\nWe have demonstrated the potential of differentiable cloth simulation in two application scenarios: material estimation and motion control. By making use of the gradients from the physically-aware simulation, our method can optimize the unknown parameters faster and more accurately than gradient-free baselines. Using differentiable simulation, we can learn the intrinsic properties of cloth from observation.One limitation of our existing implementation is that the current simulation architecture is not optimized for large-scale vectorized operations, which introduces some overhead. This can be addressed by a specialized, optimized simulation system based solely on tensor operations.\nOptNet: Differentiable optimization as a layer in neural networks. Brandon Amos, J. Zico Kolter, International Conference on Machine Learning (ICML). Brandon Amos and J. Zico Kolter. OptNet: Differentiable optimization as a layer in neural networks. In International Conference on Machine Learning (ICML), 2017.\n\nLarge steps in cloth simulation. David Baraff, Andrew Witkin, SIGGRAPH. David Baraff and Andrew Witkin. Large steps in cloth simulation. In SIGGRAPH, 1998.\n\nEstimating the material properties of fabric from video. Katherine L Bouman, Bei Xiao, Peter Battaglia, William T Freeman, International Conference on Computer Vision (ICCV). Katherine L. Bouman, Bei Xiao, Peter Battaglia, and William T. Freeman. Estimating the material properties of fabric from video. In International Conference on Computer Vision (ICCV), 2013.\n\nRigid Body Simulation with Contact and Constraints. Michael Bradley Cline, University of British ColumbiaPhD thesisMichael Bradley Cline. Rigid Body Simulation with Contact and Constraints. PhD thesis, University of British Columbia, 2002.\n\n. W Richard, Cottle, Linear Complementarity Problem. SpringerRichard W Cottle. Linear Complementarity Problem. Springer, 2009.\n\nBringing clothing into desired configurations with limited perception. Marco Cusumano-Towner, Arjun Singh, Stephen Miller, James F O&apos;brien, Pieter Abbeel, International Conference on Robotics and Automation (ICRA). Marco Cusumano-Towner, Arjun Singh, Stephen Miller, James F. O'Brien, and Pieter Abbeel. Bringing clothing into desired configurations with limited perception. In International Confer- ence on Robotics and Automation (ICRA), 2011.\n\nEnd-to-end differentiable physics for learning and control. Filipe De Avila Belbute-Peres, Kevin A Smith, Kelsey Allen, Josh Tenenbaum, J Zico Kolter, Advances in Neural Information Processing Systems. Filipe de Avila Belbute-Peres, Kevin A. Smith, Kelsey Allen, Josh Tenenbaum, and J. Zico Kolter. End-to-end differentiable physics for learning and control. In Advances in Neural Information Processing Systems, 2018.\n\nA differentiable physics engine for deep learning in robotics. Jonas Degrave, Michiel Hermans, Joni Dambre, Francis Wyffels, Frontiers in Neurorobotics. 13Jonas Degrave, Michiel Hermans, Joni Dambre, and Francis wyffels. A differentiable physics engine for deep learning in robotics. Frontiers in Neurorobotics, 13, 2019.\n\nA fast finite element solution for cloth modelling. Olaf Etzmu\u00df, Michael Keckeisen, Wolfgang Stra\u00dfer, Pacific Conference on Computer Graphics and Applications. Olaf Etzmu\u00df, Michael Keckeisen, and Wolfgang Stra\u00dfer. A fast finite element solution for cloth modelling. In Pacific Conference on Computer Graphics and Applications, 2003.\n\nDiscrete shells. Eitan Grinspun, N Anil, Mathieu Hirani, Peter Desbrun, Schr\u00f6der, Symposium on Computer Animation. Eitan Grinspun, Anil N Hirani, Mathieu Desbrun, and Peter Schr\u00f6der. Discrete shells. In Symposium on Computer Animation, 2003.\n\nGarNet: A two-stream network for fast and accurate 3D cloth draping. Erhan Gundogdu, Victor Constantin, Amrollah Seifoddini, Minh Dang, Mathieu Salzmann, Pascal Fua, International Conference on Computer Vision (ICCV). Erhan Gundogdu, Victor Constantin, Amrollah Seifoddini, Minh Dang, Mathieu Salzmann, and Pascal Fua. GarNet: A two-stream network for fast and accurate 3D cloth draping. In International Conference on Computer Vision (ICCV), 2019.\n\nRobust treatment of simultaneous collisions. David Harmon, Etienne Vouga, Rasmus Tamstorf, Eitan Grinspun, ACM Trans. Graph. 273David Harmon, Etienne Vouga, Rasmus Tamstorf, and Eitan Grinspun. Robust treatment of simultaneous collisions. ACM Trans. Graph., 27(3), 2008.\n\nChainQueen: A real-time differentiable physical simulator for soft robotics. Yuanming Hu, Jiancheng Liu, Andrew Spielberg, Joshua B Tenenbaum, William T Freeman, Jiajun Wu, Daniela Rus, Wojciech Matusik, International Conference on Robotics and Automation (ICRA). Yuanming Hu, Jiancheng Liu, Andrew Spielberg, Joshua B. Tenenbaum, William T. Freeman, Jiajun Wu, Daniela Rus, and Wojciech Matusik. ChainQueen: A real-time differentiable physical simulator for soft robotics. In International Conference on Robotics and Automation (ICRA), 2019.\n\nLearning protein structure with a differentiable simulator. John Ingraham, Adam Riesselman, Chris Sander, Debora Marks, International Conference on Learning Representations (ICLR). John Ingraham, Adam Riesselman, Chris Sander, and Debora Marks. Learning protein structure with a differentiable simulator. In International Conference on Learning Representations (ICLR), 2019.\n\nDeep learning in fluid dynamics. Nathan Kutz, Journal of Fluid Mechanics. 814J Nathan Kutz. Deep learning in fluid dynamics. Journal of Fluid Mechanics, 814, 2017.\n\nDeepWrinkles: Accurate and realistic clothing modeling. Zorah L\u00e4hner, Daniel Cremers, Tony Tung, European Conference on Computer Vision (ECCV). Zorah L\u00e4hner, Daniel Cremers, and Tony Tung. DeepWrinkles: Accurate and realistic clothing modeling. In European Conference on Computer Vision (ECCV), 2018.\n\nLearning particle dynamics for manipulating rigid bodies, deformable objects, and fluids. Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B Tenenbaum, Antonio Torralba, International Conference on Learning Representations (ICLR). Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B. Tenenbaum, and Antonio Torralba. Learning particle dynamics for manipulating rigid bodies, deformable objects, and fluids. In International Conference on Learning Representations (ICLR), 2019.\n\nRLlib: Abstractions for distributed reinforcement learning. Eric Liang, Richard Liaw, Robert Nishihara, Philipp Moritz, Roy Fox, Ken Goldberg, Joseph E Gonzalez, Michael I Jordan, Ion Stoica, International Conference on Machine Learning (ICML). Eric Liang, Richard Liaw, Robert Nishihara, Philipp Moritz, Roy Fox, Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, and Ion Stoica. RLlib: Abstractions for distributed reinforcement learning. In International Conference on Machine Learning (ICML), 2018.\n\nA geometric approach to robotic laundry folding. Stephen Miller, Jur Van Den, Mario Berg, Trevor Fritz, Kenneth Y Darrell, Pieter Goldberg, Abbeel, I. J. Robotics Res. 312Stephen Miller, Jur van den Berg, Mario Fritz, Trevor Darrell, Kenneth Y. Goldberg, and Pieter Abbeel. A geometric approach to robotic laundry folding. I. J. Robotics Res., 31(2), 2012.\n\nDeep dynamical modeling and control of unsteady fluid flows. Jeremy Morton, Antony Jameson, J Mykel, Freddie Kochenderfer, Witherden, Advances in Neural Information Processing Systems. Jeremy Morton, Antony Jameson, Mykel J Kochenderfer, and Freddie Witherden. Deep dynamical modeling and control of unsteady fluid flows. In Advances in Neural Information Processing Systems, 2018.\n\nFlexible neural representation for physics prediction. Damian Mrowca, Chengxu Zhuang, Elias Wang, Nick Haber, Fei-Fei Li, Josh Tenenbaum, Daniel L Yamins, Advances in Neural Information Processing Systems. Damian Mrowca, Chengxu Zhuang, Elias Wang, Nick Haber, Fei-Fei Li, Josh Tenenbaum, and Daniel L. Yamins. Flexible neural representation for physics prediction. In Advances in Neural Information Processing Systems, 2018.\n\nAdaptive anisotropic remeshing for cloth simulation. Rahul Narain, Armin Samii, James F O&apos;brien, ACM Trans. Graph. 316Rahul Narain, Armin Samii, and James F. O'Brien. Adaptive anisotropic remeshing for cloth simulation. ACM Trans. Graph., 31(6), 2012.\n\nClothCap: Seamless 4D clothing capture and retargeting. Gerard Pons-Moll, Sergi Pujades, Sonny Hu, Michael J Black, ACM Trans. Graph. 364Gerard Pons-Moll, Sergi Pujades, Sonny Hu, and Michael J. Black. ClothCap: Seamless 4D clothing capture and retargeting. ACM Trans. Graph., 36(4), 2017.\n\nLearning-based animation of clothing for virtual try-on. Igor Santesteban, Miguel A Otaduy, Dan Casas, Eurographics. Igor Santesteban, Miguel A. Otaduy, and Dan Casas. Learning-based animation of clothing for virtual try-on. In Eurographics, 2019.\n\nConnor Schenck, Dieter Fox, SPNets: Differentiable fluid dynamics for deep neural networks. In Conference on Robot Learning (CoRL). Connor Schenck and Dieter Fox. SPNets: Differentiable fluid dynamics for deep neural networks. In Conference on Robot Learning (CoRL), 2018.\n\nPyTorch: An imperative style, high-performance deep learning library. Benoit Steiner, Zachary Devito, Soumith Chintala, Sam Gross, Adam Paszke, Francisco Massa, Adam Lerer, Gregory Chanan, Zeming Lin, Edward Yang, Advances in Neural Information Processing Systems. Benoit Steiner, Zachary DeVito, Soumith Chintala, Sam Gross, Adam Paszke, Francisco Massa, Adam Lerer, Gregory Chanan, Zeming Lin, Edward Yang, et al. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems, 2019.\n\nFast continuous collision detection using deforming non-penetration filters. Min Tang, Dinesh Manocha, Ruofeng Tong, Symposium on Interactive 3D Graphics and Games. Min Tang, Dinesh Manocha, and Ruofeng Tong. Fast continuous collision detection using deforming non-penetration filters. In Symposium on Interactive 3D Graphics and Games, 2010.\n\nAccelerating Eulerian fluid simulation with convolutional networks. Jonathan Tompson, Kristofer Schlachter, Pablo Sprechmann, Ken Perlin, International Conference on Machine Learning (ICML). Jonathan Tompson, Kristofer Schlachter, Pablo Sprechmann, and Ken Perlin. Accelerating Eulerian fluid simulation with convolutional networks. In International Conference on Machine Learning (ICML), 2017.\n\nDifferentiable physics and stable modes for tool-use and manipulation planning. Marc Toussaint, Kelsey Allen, Kevin Smith, Joshua Tenenbaum, Robotics: Science and Systems (RSS). Marc Toussaint, Kelsey Allen, Kevin Smith, and Joshua Tenenbaum. Differentiable physics and stable modes for tool-use and manipulation planning. In Robotics: Science and Systems (RSS), 2018.\n\nData-driven elastic models for cloth: Modeling and measurement. Huamin Wang, James F O&apos;brien, Ravi Ramamoorthi, ACM Trans. Graph. 304Huamin Wang, James F. O'Brien, and Ravi Ramamoorthi. Data-driven elastic models for cloth: Modeling and measurement. ACM Trans. Graph., 30(4), 2011.\n\nLearning-based cloth material recovery from video. Shan Yang, Junbang Liang, Ming C Lin, International Conference on Computer Vision (ICCV. Shan Yang, Junbang Liang, and Ming C. Lin. Learning-based cloth material recovery from video. In International Conference on Computer Vision (ICCV), 2017.\n", "annotations": {"author": "[{\"end\":107,\"start\":56},{\"end\":156,\"start\":108},{\"end\":185,\"start\":157}]", "publisher": null, "author_last_name": "[{\"end\":69,\"start\":64},{\"end\":118,\"start\":115},{\"end\":171,\"start\":165}]", "author_first_name": "[{\"end\":63,\"start\":56},{\"end\":112,\"start\":108},{\"end\":114,\"start\":113},{\"end\":164,\"start\":157}]", "author_affiliation": "[{\"end\":106,\"start\":71},{\"end\":155,\"start\":120},{\"end\":184,\"start\":173}]", "title": "[{\"end\":53,\"start\":1},{\"end\":238,\"start\":186}]", "venue": null, "abstract": "[{\"end\":961,\"start\":240}]", "bib_ref": "[{\"end\":1144,\"start\":1126},{\"end\":1420,\"start\":1394},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1734,\"start\":1731},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2139,\"start\":2136},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4158,\"start\":4155},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4181,\"start\":4178},{\"end\":4290,\"start\":4284},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4313,\"start\":4309},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4442,\"start\":4438},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4665,\"start\":4661},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":5158,\"start\":5154},{\"end\":5373,\"start\":5367},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5429,\"start\":5425},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5693,\"start\":5689},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6292,\"start\":6288},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6311,\"start\":6307},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6388,\"start\":6384},{\"end\":6660,\"start\":6648},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7192,\"start\":7188},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7288,\"start\":7284},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7439,\"start\":7435},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7568,\"start\":7564},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8507,\"start\":8504},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8545,\"start\":8542},{\"end\":8594,\"start\":8586},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9848,\"start\":9844},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11586,\"start\":11582},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11619,\"start\":11615},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13074,\"start\":13071},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13481,\"start\":13477},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14393,\"start\":14390},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":14447,\"start\":14445},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14678,\"start\":14675},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16012,\"start\":16010},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16246,\"start\":16244},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16734,\"start\":16733},{\"end\":16838,\"start\":16827},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":19786,\"start\":19785},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":20360,\"start\":20356},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":20683,\"start\":20679},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":22111,\"start\":22107},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24874,\"start\":24870},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":26542,\"start\":26540}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":26118,\"start\":25972},{\"attributes\":{\"id\":\"fig_1\"},\"end\":27023,\"start\":26119},{\"attributes\":{\"id\":\"fig_2\"},\"end\":27116,\"start\":27024},{\"attributes\":{\"id\":\"fig_3\"},\"end\":27209,\"start\":27117},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":28513,\"start\":27210},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":28924,\"start\":28514},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":29109,\"start\":28925}]", "paragraph": "[{\"end\":1566,\"start\":977},{\"end\":2503,\"start\":1568},{\"end\":3234,\"start\":2505},{\"end\":3885,\"start\":3236},{\"end\":4970,\"start\":3902},{\"end\":5694,\"start\":4972},{\"end\":6171,\"start\":5696},{\"end\":6988,\"start\":6173},{\"end\":7691,\"start\":6990},{\"end\":8254,\"start\":7693},{\"end\":9014,\"start\":8290},{\"end\":9849,\"start\":9027},{\"end\":10799,\"start\":10126},{\"end\":10879,\"start\":10835},{\"end\":11011,\"start\":10903},{\"end\":11191,\"start\":11063},{\"end\":11654,\"start\":11236},{\"end\":11803,\"start\":11656},{\"end\":12460,\"start\":11856},{\"end\":12770,\"start\":12462},{\"end\":12865,\"start\":12822},{\"end\":13397,\"start\":12949},{\"end\":13822,\"start\":13399},{\"end\":14329,\"start\":13880},{\"end\":14851,\"start\":14331},{\"end\":15069,\"start\":14872},{\"end\":15159,\"start\":15121},{\"end\":15345,\"start\":15235},{\"end\":15434,\"start\":15401},{\"end\":15460,\"start\":15455},{\"end\":15952,\"start\":15513},{\"end\":16032,\"start\":15985},{\"end\":16247,\"start\":16115},{\"end\":17150,\"start\":16249},{\"end\":17419,\"start\":17175},{\"end\":17824,\"start\":17421},{\"end\":17898,\"start\":17826},{\"end\":18257,\"start\":17931},{\"end\":18374,\"start\":18282},{\"end\":18729,\"start\":18390},{\"end\":20080,\"start\":18748},{\"end\":20629,\"start\":20104},{\"end\":21649,\"start\":20631},{\"end\":21917,\"start\":21651},{\"end\":22264,\"start\":21919},{\"end\":22392,\"start\":22266},{\"end\":22767,\"start\":22426},{\"end\":23002,\"start\":22819},{\"end\":24120,\"start\":23004},{\"end\":25524,\"start\":24139},{\"end\":25971,\"start\":25539}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10090,\"start\":9850},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10834,\"start\":10800},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10902,\"start\":10880},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11062,\"start\":11012},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11855,\"start\":11804},{\"attributes\":{\"id\":\"formula_5\"},\"end\":12821,\"start\":12771},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12908,\"start\":12866},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13855,\"start\":13823},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13879,\"start\":13855},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15120,\"start\":15070},{\"attributes\":{\"id\":\"formula_10\"},\"end\":15234,\"start\":15160},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15400,\"start\":15346},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15454,\"start\":15435},{\"attributes\":{\"id\":\"formula_13\"},\"end\":15512,\"start\":15461},{\"attributes\":{\"id\":\"formula_14\"},\"end\":15984,\"start\":15953},{\"attributes\":{\"id\":\"formula_15\"},\"end\":16114,\"start\":16033},{\"attributes\":{\"id\":\"formula_16\"},\"end\":17930,\"start\":17899},{\"attributes\":{\"id\":\"formula_17\"},\"end\":18281,\"start\":18258},{\"attributes\":{\"id\":\"formula_18\"},\"end\":22425,\"start\":22393},{\"attributes\":{\"id\":\"formula_19\"},\"end\":22818,\"start\":22768}]", "table_ref": "[{\"end\":19794,\"start\":19787}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":975,\"start\":963},{\"attributes\":{\"n\":\"2\"},\"end\":3900,\"start\":3888},{\"attributes\":{\"n\":\"3\"},\"end\":8288,\"start\":8257},{\"attributes\":{\"n\":\"3.1\"},\"end\":9025,\"start\":9017},{\"attributes\":{\"n\":\"3.2\"},\"end\":10124,\"start\":10092},{\"attributes\":{\"n\":\"3.3\"},\"end\":11234,\"start\":11194},{\"attributes\":{\"n\":\"3.4\"},\"end\":12947,\"start\":12910},{\"attributes\":{\"n\":\"3.4.1\"},\"end\":14870,\"start\":14854},{\"attributes\":{\"n\":\"3.4.2\"},\"end\":17173,\"start\":17153},{\"attributes\":{\"n\":\"4\"},\"end\":18388,\"start\":18377},{\"attributes\":{\"n\":\"4.1\"},\"end\":18746,\"start\":18732},{\"attributes\":{\"n\":\"4.2\"},\"end\":20102,\"start\":20083},{\"attributes\":{\"n\":\"4.3\"},\"end\":24137,\"start\":24123},{\"attributes\":{\"n\":\"5\"},\"end\":25537,\"start\":25527},{\"end\":25983,\"start\":25973},{\"end\":26130,\"start\":26120},{\"end\":27035,\"start\":27025},{\"end\":27128,\"start\":27118},{\"end\":28524,\"start\":28515},{\"end\":28935,\"start\":28926}]", "table": "[{\"end\":28513,\"start\":28122}]", "figure_caption": "[{\"end\":26118,\"start\":25985},{\"end\":27023,\"start\":26132},{\"end\":27116,\"start\":27037},{\"end\":27209,\"start\":27130},{\"end\":28122,\"start\":27212},{\"end\":28924,\"start\":28526},{\"end\":29109,\"start\":28937}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16519,\"start\":16512},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":17895,\"start\":17884},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19228,\"start\":19222},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20311,\"start\":20305},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23717,\"start\":23711}]", "bib_author_first_name": "[{\"end\":29875,\"start\":29868},{\"end\":29889,\"start\":29882},{\"end\":30152,\"start\":30147},{\"end\":30167,\"start\":30161},{\"end\":30337,\"start\":30328},{\"end\":30339,\"start\":30338},{\"end\":30351,\"start\":30348},{\"end\":30363,\"start\":30358},{\"end\":30382,\"start\":30375},{\"end\":30384,\"start\":30383},{\"end\":30696,\"start\":30689},{\"end\":30881,\"start\":30880},{\"end\":31082,\"start\":31077},{\"end\":31105,\"start\":31100},{\"end\":31120,\"start\":31113},{\"end\":31134,\"start\":31129},{\"end\":31136,\"start\":31135},{\"end\":31157,\"start\":31151},{\"end\":31524,\"start\":31518},{\"end\":31554,\"start\":31549},{\"end\":31556,\"start\":31555},{\"end\":31570,\"start\":31564},{\"end\":31582,\"start\":31578},{\"end\":31595,\"start\":31594},{\"end\":31600,\"start\":31596},{\"end\":31946,\"start\":31941},{\"end\":31963,\"start\":31956},{\"end\":31977,\"start\":31973},{\"end\":31993,\"start\":31986},{\"end\":32257,\"start\":32253},{\"end\":32273,\"start\":32266},{\"end\":32293,\"start\":32285},{\"end\":32557,\"start\":32552},{\"end\":32569,\"start\":32568},{\"end\":32583,\"start\":32576},{\"end\":32597,\"start\":32592},{\"end\":32852,\"start\":32847},{\"end\":32869,\"start\":32863},{\"end\":32890,\"start\":32882},{\"end\":32907,\"start\":32903},{\"end\":32921,\"start\":32914},{\"end\":32938,\"start\":32932},{\"end\":33278,\"start\":33273},{\"end\":33294,\"start\":33287},{\"end\":33308,\"start\":33302},{\"end\":33324,\"start\":33319},{\"end\":33585,\"start\":33577},{\"end\":33599,\"start\":33590},{\"end\":33611,\"start\":33605},{\"end\":33629,\"start\":33623},{\"end\":33631,\"start\":33630},{\"end\":33650,\"start\":33643},{\"end\":33652,\"start\":33651},{\"end\":33668,\"start\":33662},{\"end\":33680,\"start\":33673},{\"end\":33694,\"start\":33686},{\"end\":34108,\"start\":34104},{\"end\":34123,\"start\":34119},{\"end\":34141,\"start\":34136},{\"end\":34156,\"start\":34150},{\"end\":34646,\"start\":34641},{\"end\":34661,\"start\":34655},{\"end\":34675,\"start\":34671},{\"end\":34983,\"start\":34977},{\"end\":34994,\"start\":34988},{\"end\":35003,\"start\":34999},{\"end\":35019,\"start\":35013},{\"end\":35021,\"start\":35020},{\"end\":35040,\"start\":35033},{\"end\":35416,\"start\":35412},{\"end\":35431,\"start\":35424},{\"end\":35444,\"start\":35438},{\"end\":35463,\"start\":35456},{\"end\":35475,\"start\":35472},{\"end\":35484,\"start\":35481},{\"end\":35501,\"start\":35495},{\"end\":35503,\"start\":35502},{\"end\":35521,\"start\":35514},{\"end\":35523,\"start\":35522},{\"end\":35535,\"start\":35532},{\"end\":35914,\"start\":35907},{\"end\":35926,\"start\":35923},{\"end\":35941,\"start\":35936},{\"end\":35954,\"start\":35948},{\"end\":35969,\"start\":35962},{\"end\":35971,\"start\":35970},{\"end\":35987,\"start\":35981},{\"end\":36283,\"start\":36277},{\"end\":36298,\"start\":36292},{\"end\":36309,\"start\":36308},{\"end\":36324,\"start\":36317},{\"end\":36660,\"start\":36654},{\"end\":36676,\"start\":36669},{\"end\":36690,\"start\":36685},{\"end\":36701,\"start\":36697},{\"end\":36716,\"start\":36709},{\"end\":36725,\"start\":36721},{\"end\":36743,\"start\":36737},{\"end\":36745,\"start\":36744},{\"end\":37084,\"start\":37079},{\"end\":37098,\"start\":37093},{\"end\":37111,\"start\":37106},{\"end\":37113,\"start\":37112},{\"end\":37346,\"start\":37340},{\"end\":37363,\"start\":37358},{\"end\":37378,\"start\":37373},{\"end\":37390,\"start\":37383},{\"end\":37392,\"start\":37391},{\"end\":37636,\"start\":37632},{\"end\":37656,\"start\":37650},{\"end\":37658,\"start\":37657},{\"end\":37670,\"start\":37667},{\"end\":37830,\"start\":37824},{\"end\":37846,\"start\":37840},{\"end\":38174,\"start\":38168},{\"end\":38191,\"start\":38184},{\"end\":38207,\"start\":38200},{\"end\":38221,\"start\":38218},{\"end\":38233,\"start\":38229},{\"end\":38251,\"start\":38242},{\"end\":38263,\"start\":38259},{\"end\":38278,\"start\":38271},{\"end\":38293,\"start\":38287},{\"end\":38305,\"start\":38299},{\"end\":38725,\"start\":38722},{\"end\":38738,\"start\":38732},{\"end\":38755,\"start\":38748},{\"end\":39065,\"start\":39057},{\"end\":39084,\"start\":39075},{\"end\":39102,\"start\":39097},{\"end\":39118,\"start\":39115},{\"end\":39469,\"start\":39465},{\"end\":39487,\"start\":39481},{\"end\":39500,\"start\":39495},{\"end\":39514,\"start\":39508},{\"end\":39825,\"start\":39819},{\"end\":39837,\"start\":39832},{\"end\":39839,\"start\":39838},{\"end\":39858,\"start\":39854},{\"end\":40098,\"start\":40094},{\"end\":40112,\"start\":40105},{\"end\":40124,\"start\":40120},{\"end\":40126,\"start\":40125}]", "bib_author_last_name": "[{\"end\":29880,\"start\":29876},{\"end\":29896,\"start\":29890},{\"end\":30159,\"start\":30153},{\"end\":30174,\"start\":30168},{\"end\":30346,\"start\":30340},{\"end\":30356,\"start\":30352},{\"end\":30373,\"start\":30364},{\"end\":30392,\"start\":30385},{\"end\":30710,\"start\":30697},{\"end\":30889,\"start\":30882},{\"end\":30897,\"start\":30891},{\"end\":31098,\"start\":31083},{\"end\":31111,\"start\":31106},{\"end\":31127,\"start\":31121},{\"end\":31149,\"start\":31137},{\"end\":31164,\"start\":31158},{\"end\":31547,\"start\":31525},{\"end\":31562,\"start\":31557},{\"end\":31576,\"start\":31571},{\"end\":31592,\"start\":31583},{\"end\":31607,\"start\":31601},{\"end\":31954,\"start\":31947},{\"end\":31971,\"start\":31964},{\"end\":31984,\"start\":31978},{\"end\":32001,\"start\":31994},{\"end\":32264,\"start\":32258},{\"end\":32283,\"start\":32274},{\"end\":32301,\"start\":32294},{\"end\":32566,\"start\":32558},{\"end\":32574,\"start\":32570},{\"end\":32590,\"start\":32584},{\"end\":32605,\"start\":32598},{\"end\":32615,\"start\":32607},{\"end\":32861,\"start\":32853},{\"end\":32880,\"start\":32870},{\"end\":32901,\"start\":32891},{\"end\":32912,\"start\":32908},{\"end\":32930,\"start\":32922},{\"end\":32942,\"start\":32939},{\"end\":33285,\"start\":33279},{\"end\":33300,\"start\":33295},{\"end\":33317,\"start\":33309},{\"end\":33333,\"start\":33325},{\"end\":33588,\"start\":33586},{\"end\":33603,\"start\":33600},{\"end\":33621,\"start\":33612},{\"end\":33641,\"start\":33632},{\"end\":33660,\"start\":33653},{\"end\":33671,\"start\":33669},{\"end\":33684,\"start\":33681},{\"end\":33702,\"start\":33695},{\"end\":34117,\"start\":34109},{\"end\":34134,\"start\":34124},{\"end\":34148,\"start\":34142},{\"end\":34162,\"start\":34157},{\"end\":34464,\"start\":34453},{\"end\":34653,\"start\":34647},{\"end\":34669,\"start\":34662},{\"end\":34680,\"start\":34676},{\"end\":34986,\"start\":34984},{\"end\":34997,\"start\":34995},{\"end\":35011,\"start\":35004},{\"end\":35031,\"start\":35022},{\"end\":35049,\"start\":35041},{\"end\":35422,\"start\":35417},{\"end\":35436,\"start\":35432},{\"end\":35454,\"start\":35445},{\"end\":35470,\"start\":35464},{\"end\":35479,\"start\":35476},{\"end\":35493,\"start\":35485},{\"end\":35512,\"start\":35504},{\"end\":35530,\"start\":35524},{\"end\":35542,\"start\":35536},{\"end\":35921,\"start\":35915},{\"end\":35934,\"start\":35927},{\"end\":35946,\"start\":35942},{\"end\":35960,\"start\":35955},{\"end\":35979,\"start\":35972},{\"end\":35996,\"start\":35988},{\"end\":36004,\"start\":35998},{\"end\":36290,\"start\":36284},{\"end\":36306,\"start\":36299},{\"end\":36315,\"start\":36310},{\"end\":36337,\"start\":36325},{\"end\":36348,\"start\":36339},{\"end\":36667,\"start\":36661},{\"end\":36683,\"start\":36677},{\"end\":36695,\"start\":36691},{\"end\":36707,\"start\":36702},{\"end\":36719,\"start\":36717},{\"end\":36735,\"start\":36726},{\"end\":36752,\"start\":36746},{\"end\":37091,\"start\":37085},{\"end\":37104,\"start\":37099},{\"end\":37126,\"start\":37114},{\"end\":37356,\"start\":37347},{\"end\":37371,\"start\":37364},{\"end\":37381,\"start\":37379},{\"end\":37398,\"start\":37393},{\"end\":37648,\"start\":37637},{\"end\":37665,\"start\":37659},{\"end\":37676,\"start\":37671},{\"end\":37838,\"start\":37831},{\"end\":37850,\"start\":37847},{\"end\":38182,\"start\":38175},{\"end\":38198,\"start\":38192},{\"end\":38216,\"start\":38208},{\"end\":38227,\"start\":38222},{\"end\":38240,\"start\":38234},{\"end\":38257,\"start\":38252},{\"end\":38269,\"start\":38264},{\"end\":38285,\"start\":38279},{\"end\":38297,\"start\":38294},{\"end\":38310,\"start\":38306},{\"end\":38730,\"start\":38726},{\"end\":38746,\"start\":38739},{\"end\":38760,\"start\":38756},{\"end\":39073,\"start\":39066},{\"end\":39095,\"start\":39085},{\"end\":39113,\"start\":39103},{\"end\":39125,\"start\":39119},{\"end\":39479,\"start\":39470},{\"end\":39493,\"start\":39488},{\"end\":39506,\"start\":39501},{\"end\":39524,\"start\":39515},{\"end\":39830,\"start\":39826},{\"end\":39852,\"start\":39840},{\"end\":39870,\"start\":39859},{\"end\":40103,\"start\":40099},{\"end\":40118,\"start\":40113},{\"end\":40130,\"start\":40127}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":1791473},\"end\":30112,\"start\":29801},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":326544},\"end\":30269,\"start\":30114},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11325165},\"end\":30635,\"start\":30271},{\"attributes\":{\"id\":\"b3\"},\"end\":30876,\"start\":30637},{\"attributes\":{\"id\":\"b4\"},\"end\":31004,\"start\":30878},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":307718},\"end\":31456,\"start\":31006},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":54091129},\"end\":31876,\"start\":31458},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":5763832},\"end\":32199,\"start\":31878},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":33677617},\"end\":32533,\"start\":32201},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6425185},\"end\":32776,\"start\":32535},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":53763742},\"end\":33226,\"start\":32778},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":3153369},\"end\":33498,\"start\":33228},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":52911940},\"end\":34042,\"start\":33500},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":108301299},\"end\":34418,\"start\":34044},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":47001577},\"end\":34583,\"start\":34420},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":51967305},\"end\":34885,\"start\":34585},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":52917627},\"end\":35350,\"start\":34887},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":49546141},\"end\":35856,\"start\":35352},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6431538},\"end\":36214,\"start\":35858},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":29150074},\"end\":36597,\"start\":36216},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":49348777},\"end\":37024,\"start\":36599},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":2749951},\"end\":37282,\"start\":37026},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":12569740},\"end\":37573,\"start\":37284},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":81979618},\"end\":37822,\"start\":37575},{\"attributes\":{\"id\":\"b24\"},\"end\":38096,\"start\":37824},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":202786778},\"end\":38643,\"start\":38098},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":8514766},\"end\":38987,\"start\":38645},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":41947},\"end\":39383,\"start\":38989},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":46980516},\"end\":39753,\"start\":39385},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":4370381},\"end\":40041,\"start\":39755},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":13358672},\"end\":40337,\"start\":40043}]", "bib_title": "[{\"end\":29866,\"start\":29801},{\"end\":30145,\"start\":30114},{\"end\":30326,\"start\":30271},{\"end\":31075,\"start\":31006},{\"end\":31516,\"start\":31458},{\"end\":31939,\"start\":31878},{\"end\":32251,\"start\":32201},{\"end\":32550,\"start\":32535},{\"end\":32845,\"start\":32778},{\"end\":33271,\"start\":33228},{\"end\":33575,\"start\":33500},{\"end\":34102,\"start\":34044},{\"end\":34451,\"start\":34420},{\"end\":34639,\"start\":34585},{\"end\":34975,\"start\":34887},{\"end\":35410,\"start\":35352},{\"end\":35905,\"start\":35858},{\"end\":36275,\"start\":36216},{\"end\":36652,\"start\":36599},{\"end\":37077,\"start\":37026},{\"end\":37338,\"start\":37284},{\"end\":37630,\"start\":37575},{\"end\":38166,\"start\":38098},{\"end\":38720,\"start\":38645},{\"end\":39055,\"start\":38989},{\"end\":39463,\"start\":39385},{\"end\":39817,\"start\":39755},{\"end\":40092,\"start\":40043}]", "bib_author": "[{\"end\":29882,\"start\":29868},{\"end\":29898,\"start\":29882},{\"end\":30161,\"start\":30147},{\"end\":30176,\"start\":30161},{\"end\":30348,\"start\":30328},{\"end\":30358,\"start\":30348},{\"end\":30375,\"start\":30358},{\"end\":30394,\"start\":30375},{\"end\":30712,\"start\":30689},{\"end\":30891,\"start\":30880},{\"end\":30899,\"start\":30891},{\"end\":31100,\"start\":31077},{\"end\":31113,\"start\":31100},{\"end\":31129,\"start\":31113},{\"end\":31151,\"start\":31129},{\"end\":31166,\"start\":31151},{\"end\":31549,\"start\":31518},{\"end\":31564,\"start\":31549},{\"end\":31578,\"start\":31564},{\"end\":31594,\"start\":31578},{\"end\":31609,\"start\":31594},{\"end\":31956,\"start\":31941},{\"end\":31973,\"start\":31956},{\"end\":31986,\"start\":31973},{\"end\":32003,\"start\":31986},{\"end\":32266,\"start\":32253},{\"end\":32285,\"start\":32266},{\"end\":32303,\"start\":32285},{\"end\":32568,\"start\":32552},{\"end\":32576,\"start\":32568},{\"end\":32592,\"start\":32576},{\"end\":32607,\"start\":32592},{\"end\":32617,\"start\":32607},{\"end\":32863,\"start\":32847},{\"end\":32882,\"start\":32863},{\"end\":32903,\"start\":32882},{\"end\":32914,\"start\":32903},{\"end\":32932,\"start\":32914},{\"end\":32944,\"start\":32932},{\"end\":33287,\"start\":33273},{\"end\":33302,\"start\":33287},{\"end\":33319,\"start\":33302},{\"end\":33335,\"start\":33319},{\"end\":33590,\"start\":33577},{\"end\":33605,\"start\":33590},{\"end\":33623,\"start\":33605},{\"end\":33643,\"start\":33623},{\"end\":33662,\"start\":33643},{\"end\":33673,\"start\":33662},{\"end\":33686,\"start\":33673},{\"end\":33704,\"start\":33686},{\"end\":34119,\"start\":34104},{\"end\":34136,\"start\":34119},{\"end\":34150,\"start\":34136},{\"end\":34164,\"start\":34150},{\"end\":34466,\"start\":34453},{\"end\":34655,\"start\":34641},{\"end\":34671,\"start\":34655},{\"end\":34682,\"start\":34671},{\"end\":34988,\"start\":34977},{\"end\":34999,\"start\":34988},{\"end\":35013,\"start\":34999},{\"end\":35033,\"start\":35013},{\"end\":35051,\"start\":35033},{\"end\":35424,\"start\":35412},{\"end\":35438,\"start\":35424},{\"end\":35456,\"start\":35438},{\"end\":35472,\"start\":35456},{\"end\":35481,\"start\":35472},{\"end\":35495,\"start\":35481},{\"end\":35514,\"start\":35495},{\"end\":35532,\"start\":35514},{\"end\":35544,\"start\":35532},{\"end\":35923,\"start\":35907},{\"end\":35936,\"start\":35923},{\"end\":35948,\"start\":35936},{\"end\":35962,\"start\":35948},{\"end\":35981,\"start\":35962},{\"end\":35998,\"start\":35981},{\"end\":36006,\"start\":35998},{\"end\":36292,\"start\":36277},{\"end\":36308,\"start\":36292},{\"end\":36317,\"start\":36308},{\"end\":36339,\"start\":36317},{\"end\":36350,\"start\":36339},{\"end\":36669,\"start\":36654},{\"end\":36685,\"start\":36669},{\"end\":36697,\"start\":36685},{\"end\":36709,\"start\":36697},{\"end\":36721,\"start\":36709},{\"end\":36737,\"start\":36721},{\"end\":36754,\"start\":36737},{\"end\":37093,\"start\":37079},{\"end\":37106,\"start\":37093},{\"end\":37128,\"start\":37106},{\"end\":37358,\"start\":37340},{\"end\":37373,\"start\":37358},{\"end\":37383,\"start\":37373},{\"end\":37400,\"start\":37383},{\"end\":37650,\"start\":37632},{\"end\":37667,\"start\":37650},{\"end\":37678,\"start\":37667},{\"end\":37840,\"start\":37824},{\"end\":37852,\"start\":37840},{\"end\":38184,\"start\":38168},{\"end\":38200,\"start\":38184},{\"end\":38218,\"start\":38200},{\"end\":38229,\"start\":38218},{\"end\":38242,\"start\":38229},{\"end\":38259,\"start\":38242},{\"end\":38271,\"start\":38259},{\"end\":38287,\"start\":38271},{\"end\":38299,\"start\":38287},{\"end\":38312,\"start\":38299},{\"end\":38732,\"start\":38722},{\"end\":38748,\"start\":38732},{\"end\":38762,\"start\":38748},{\"end\":39075,\"start\":39057},{\"end\":39097,\"start\":39075},{\"end\":39115,\"start\":39097},{\"end\":39127,\"start\":39115},{\"end\":39481,\"start\":39465},{\"end\":39495,\"start\":39481},{\"end\":39508,\"start\":39495},{\"end\":39526,\"start\":39508},{\"end\":39832,\"start\":39819},{\"end\":39854,\"start\":39832},{\"end\":39872,\"start\":39854},{\"end\":40105,\"start\":40094},{\"end\":40120,\"start\":40105},{\"end\":40132,\"start\":40120}]", "bib_venue": "[{\"end\":29949,\"start\":29898},{\"end\":30184,\"start\":30176},{\"end\":30444,\"start\":30394},{\"end\":30687,\"start\":30637},{\"end\":30929,\"start\":30899},{\"end\":31224,\"start\":31166},{\"end\":31658,\"start\":31609},{\"end\":32029,\"start\":32003},{\"end\":32359,\"start\":32303},{\"end\":32648,\"start\":32617},{\"end\":32994,\"start\":32944},{\"end\":33351,\"start\":33335},{\"end\":33762,\"start\":33704},{\"end\":34223,\"start\":34164},{\"end\":34492,\"start\":34466},{\"end\":34727,\"start\":34682},{\"end\":35110,\"start\":35051},{\"end\":35595,\"start\":35544},{\"end\":36024,\"start\":36006},{\"end\":36399,\"start\":36350},{\"end\":36803,\"start\":36754},{\"end\":37144,\"start\":37128},{\"end\":37416,\"start\":37400},{\"end\":37690,\"start\":37678},{\"end\":37954,\"start\":37852},{\"end\":38361,\"start\":38312},{\"end\":38808,\"start\":38762},{\"end\":39178,\"start\":39127},{\"end\":39561,\"start\":39526},{\"end\":39888,\"start\":39872},{\"end\":40181,\"start\":40132}]"}}}, "year": 2023, "month": 12, "day": 17}