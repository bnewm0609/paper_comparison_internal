{"id": 235606379, "updated": "2023-10-06 02:10:54.18", "metadata": {"title": "Bounds on Causal Effects and Application to High Dimensional Data", "authors": "[{\"first\":\"Ang\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Judea\",\"last\":\"Pearl\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": 6, "day": 23}, "abstract": "This paper addresses the problem of estimating causal effects when adjustment variables in the back-door or front-door criterion are partially observed. For such scenarios, we derive bounds on the causal effects by solving two non-linear optimization problems, and demonstrate that the bounds are sufficient. Using this optimization method, we propose a framework for dimensionality reduction that allows one to trade bias for estimation power, and demonstrate its performance using simulation studies.", "fields_of_study": "[\"Mathematics\",\"Computer Science\"]", "external_ids": {"arxiv": "2106.12121", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aaai/LiP22a", "doi": "10.1609/aaai.v36i5.20520"}}, "content": {"source": {"pdf_hash": "3dfac124113ac1827dccfe06237784984642c969", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.12121v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "d3af54d10a6c21b94ac4fd4e32c27f626518f29d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3dfac124113ac1827dccfe06237784984642c969.txt", "contents": "\nBOUNDS ON CAUSAL EFFECTS AND APPLICATION TO HIGH DIMENSIONAL DATA\nApril 28, 2021\n\nAng Li angli@cs.ucla.edu \nLos Angeles Computer Science Department\nLos Angeles Computer Science Department\nUniversity of California\nUniversity of California\n\n\nJudea Pearl \nLos Angeles Computer Science Department\nLos Angeles Computer Science Department\nUniversity of California\nUniversity of California\n\n\nBOUNDS ON CAUSAL EFFECTS AND APPLICATION TO HIGH DIMENSIONAL DATA\nApril 28, 2021\nThis paper addresses the problem of estimating causal effects when adjustment variables in the back-door or front-door criterion are partially observed. For such scenarios, we derive bounds on the causal effects by solving two non-linear optimization problems, and demonstrate that the bounds are sufficient. Using this optimization method, we propose a framework for dimensionality reduction that allows one to trade bias for estimation power, and demonstrate its performance using simulation studies.\n\nIntroduction\n\nEstimating causal effects has been encountered in many areas of industry, marketing, and health science, and it is the most critical problem in causal inference. Pearl's back-door and front-door criteria, along with the adjustment formula [Pearl(1995)], are powerful tools for estimating causal effects. In this paper, the problem of estimating causal effects when adjustment variables in the back-door or front-door criterion are partially observable, or when the adjustment variables have high dimensionality, is addressed.\n\nConsider the problem of estimating the causal effects of X on Y when a sufficient set W \u222a U of confounders is partially observable (see Figure 1a). Because W \u222a U is assumed to be sufficient, the causal effects are identified from measurements on X, Y, W, and U and can be written as P (y|do(x)) = w,u P (y|x, w, u)P (w, u) = w,u P (x, y, w, u)P (w, u) P (x, w, u) .\n\nHowever, if U is unobserved, d-separation tells us immediately that adjusting for W is inadequate by leaving the back-door path X \u2190 \u2212 U \u2212 \u2192 Y unblocked. Therefore, regardless of sample size, the causal effects of X on Y cannot be estimated without bias. However, it turns out that when given a prior distribution P (U ), we can obtain bounds on the causal effects. We will demonstrate later that the midpoints of the bounds are sufficient for estimating the causal effects.\n\nBounding has been proven to be useful in causal inference. [Balke and Pearl(1997a)] provided bounds on causal effects with imperfect compliance, [Tian and Pearl(2000)] proposed bounds on probabilities of causation, [Cai et al.(2008) Cai, Kuroki, Pearl, and Tian] provided bounds on causal effects with the presence of confounded intermediate variables, and [Li and Pearl(2019)] proposed bounds on the benefit function of a unit selection problem.\n\nAlthough P (U ) is assumed to be given, it is usually known regardless of the model itself (e.g., U stands for gender, gene type, blood type, or age). Alternatively, if costs permit, one can estimate P (U ) by re-testing within a small sampled sub-population.\n\nA second problem considered in this paper is that of estimating causal effects when a sufficient set Z of confounders is fully observable (see Figure 1b), but with a high dimensionality (e.g., Z has 1024 instantiates). In such a case, a prohibitively large sample size would be required, which is generally recognized to be impractical. We propose a new framework that transforms the problem associated with Figure 1b    containing W and U , which have much smaller dimensionalities (e.g., W and U have 32 instantiates). We then estimate bounds on causal effects of the equivalent problem and take the midpoints as the effect estimates. We demonstrate through a simulation that this method can deliver good estimates of causal effects of the original problem.\n\n\nPreliminaries & Related Works\n\nIn this section, we review the back-door and front-door criteria and their associated adjustment formulas [Pearl(1995)].\n\nWe use the causal diagrams in [Pearl(1995), Spirtes et al.(2000)Spirtes, Glymour, Scheines, andHeckerman, Pearl(2009), Koller and Friedman(2009)].\n\nOne key concept of a causal diagram is called d-separation [Pearl(2014)].\n\nDefinition 1 (d-separation). In a causal diagram G, a path p is blocked by a set of nodes Z if and only if\n1. p contains a chain of nodes A \u2212 \u2192 B \u2212 \u2192 C or a fork A \u2190 \u2212 B \u2212 \u2192 C such that the middle node B is in Z (i.e., B is conditioned on), or 2. p contains a collider A \u2212 \u2192 B \u2190 \u2212 C such that the collision node B is not in Z, and no descendant of B is in Z.\nIf Z blocks every path between two nodes X and Y , then X and Y are d-separated conditional on Z, and thus are independent conditional on Z, denoted as X \u22a5 \u22a5 Y | Z.\n\nWith the concept of d-separation in a causal diagram, Pearl proposed the back-door and front-door criteria as follows: Definition 2 (Back-Door Criterion). Given an ordered pair of variables (X, Y ) in a directed acyclic graph G, a set of variables Z satisfies the back-door criterion relative to (X, Y ), if no node in Z is a descendant of X, and Z blocks every path between X and Y that contains an arrow into X.\n\nIf a set of variables Z satisfies the back-door criterion for X and Y , the causal effects of X on Y are given by the adjustment formula:\nP (y|do(x)) = z P (y|x, z)P (z).(1)\nDefinition 3 (Front-Door Criterion). A set of variables Z is said to satisfy the front-door criterion relative to an ordered pair of variables (X, Y ) if\n\n\u2022 Z intercepts all directed paths from X to Y ;\n\n\u2022 there is no back-door path from X to Z; and\n\n\u2022 all back-door paths from Z to Y are blocked by X.\n\nIf a set of variables Z satisfies the front-door criterion for X and Y , and if P (x, Z) > 0, then the causal effects of X on Y are given by the adjustment formula:\nP (y|do(x)) = z P (z|x) x P (y|x , z)P (x ).(2)\nThe back-door and front-door criteria are two powerful tools for estimating causal effects; however, causal effects are not identifiable if the set of adjustment variables Z is not fully observable. [Tian and Pearl(2000)] provided the naivest bounds for causal effects (Equation 3), regardless of the causal diagram.\n\nP (x, y) \u2264 P (y|do(x)) \u2264 1 \u2212 P (x, y ).\n\nAs the first contribution of this study, we obtain narrower bounds of the causal effects by leveraging another source of knowledge, i.e., a causal diagram behind data combined with measurements of a set W (observable part of Z) of covariates and a prior information of a set U (unobservable part of Z), in a causal diagram in which the bounds are solutions to two non-linear optimization problems. We illustrate that the midpoints of the bounds are sufficient for estimating the causal effects.\n\nUsing this optimization method, our second contribution is the proposal of a new framework for estimating causal effects when a set of fully observable adjustment variables Z has a high dimensionality without any assumption regarding the data-generating process. [Maathuis et al.(2009)Maathuis, Kalisch, B\u00fchlmann, et al.] proposed a method of estimating causal effects when the number of covariates is larger than the sample size. However, it relies on several assumptions, including the assumption that the distribution of covariates is multivariate normal. The method is limited if the distribution of covariates is unknown or does not have accuracy estimate owing to the limitation of the sample size.\n\n\nBounds on Causal Effects\n\nIn this section, we demonstrate how bounds on causal effects with partially observable back-door or front-door variables can be obtained through non-linear optimizations.\n\n\nPartially Observable Back-Door Variables\n\nTheorem 4. Given a causal diagram G and a distribution compatible with G, let W \u222a U be a set of variables satisfying the back-door criterion in G relative to an ordered pair (X, Y ), where W \u222a U is partially observable, i.e., only probabilities P (X, Y, W ) and P (U ) are given, the causal effects of X on Y are then bounded as follows:\nLB \u2264 P (y|do(x)) \u2264 UB\nwhere LB is the solution to the non-linear optimization problem in Equation 4 and UB is the solution to the non-linear optimization problem in Equation 5.\nLB = min w,u a w,u b w,u c w,u ,(4)U B = max w,u a w,u b w,u c w,u ,(5)\nwhere, u a w,u = P (x, y, w),\nu b w,u = P (w), u c w,u = P (x, w) for all w \u2208 W ;\nand for all w \u2208 W and u \u2208 U,\nb w,u \u2265 c w,u \u2265 a w,u , max{0, p(x, y, w) + p(u) \u2212 1} \u2264 a w,u \u2264 min{P (x, y, w), p(u)}, max{0, p(w) + p(u) \u2212 1} \u2264 b w,u \u2264 min{P (w), p(u)}, max{0, p(x, w) + p(u) \u2212 1} \u2264 c w,u \u2264 min{P (x, w), p(u)}.\n\nPartially Observable Front-Door Variables\n\nTheorem 5. Given a causal diagram G and distribution compatible with G, let W \u222a U be a set of variables satisfying the front-door criterion in G relative to an ordered pair (X, Y ), where W \u222a U is partially observable, i.e., only probabilities P (X, Y, W ) and P (U ) are given and P (x, W, U ) > 0, the causal effects of X on Y are then bounded as follows:\nLB \u2264 P (y|do(x)) \u2264 UB\nwhere LB is the solution to the non-linear optimization problem in Equation 6 and UB is the solution to the non-linear optimization problem in Equation 7.\nLB = min w,u b x,w,u P (x) x a x ,w,u P (x ) b x ,w,u ,(6)U B = max w,u b x,w,u P (x) x a x ,w,u P (x ) b x ,w,u ,(7)\nwhere, u a x,w,u = P (x, y, w), u b x,w,u = P (x, w) for all x \u2208 X and w \u2208 W ;\n\nand for all x \u2208 X,w \u2208 W , and u \u2208 U, b x,w,u \u2265 a x,w,u , max{0, p(x, y, w)\n+ p(u) \u2212 1} \u2264 a x,w,u \u2264 min{P (x, y, w), p(u)}, max{0, p(x, w) + p(u) \u2212 1} \u2264 b x,w,u \u2264 min{P (x, w), p(u)}.\nNotably, if any observational data (e.g., P (U )) are unavailable in the above theorems, we can remove that term, and the rest of non-linear optimization problems still provide valid bounds for the causal effects. In general, midpoints of bounds on causal effects are effective estimates. However, the lower (upper) bounds are also informative, which can be interpreted as the minimal (maximal) causal effects. The proofs of Theorems 4 and 5 are provided in the appendix.\n\n\nExample\n\nHerein, we present a simulated example to demonstrate that the midpoints of the bounds on the causal effects given by Theorem 4 are adequate for estimating the causal effects.\n\n\nCausal Effect of a Drug\n\nDrug manufacturers want to know the causal effect of recovery when a drug is taken. Thus, they conduct an observational study. Here, the recovery rates of 700 patients were recorded. A total of 192 patients chose to take the drug and 508 patients did not. The results of the study are shown in Table 1. Blood type (type O or not) is not the only confounder of taking the drug and recovery. Another confounder is age (below the age of 70 or not). The manufacturers have no data associated with age. They only know that 85.43% of people in their region are below the age of 70.\n\nBecause both age and blood type are confounders of taking the drug and recovery, and the observational data associated with age are unobservable, the causal effect is not identifiable.\n\nLet X = x denote the event that a patient took the drug, and X = x denote the event that a patient did not take the drug. Let Y = y denote the event that a patient recovered, and Y = y denote the event that a patient did not recover. Let W = w represent a patient with blood type O, and W = w represent a patient without blood type O. Let U = u represent a patient below the age of 70, and U = u represent a patient above the age of 70. The causal diagram is shown in Figure 1d.\n\nAn option for the manufacturers could be estimating the causal effect through the Tian-Pearl bounds in Equation 3 and the observational data from Table 1, where\nP (x, y) = w P (y|x, w)P (x|w)P (w) = 0.2257, 1 \u2212 P (x, y ) = 1 \u2212 w P (y |x, w)P (x|w)P (w) = 0.9514.\nTherefore, the bounds on the causal effect estimated using Equation 3 are 0.2257 \u2264 P (y|do(x)) \u2264 0.9514, where the causal information of the covariate W and the prior information P (U ) are not used. These bounds are not sufficiently informative to conclude the actual causal effect. Although one may believe that we can use the midpoint of the bounds (i.e., 0.5886), the gap (i.e., 0.9514 \u2212 0.2257 = 0.7257) between the bounds is not small; hence, this point estimate is unconvincing.\n\nNow, considering the proposed bounds in Theorem 4 with the observational data from Table 1. W \u222a U satisfies the back-door criterion, and P (X, Y, W ) and P (U ) are available. We have 12 optimal variables in each objective  function, because W and U are binary. With the help of the \"SLSQP\" solver [Kraft(1988)] in the scipy package [SciPyCommunity(2020)], we obtain the bounds on the causal effect, which are 0.4728 \u2264 P (y|do(x)) \u2264 0.9514. The lower bound actually increased significantly, and reached close to 0.5, which can help make decisions. The midpoint is 0.7121. Our conclusion is then that the causal effect of recovery when taking the drug is 0.7121. We show in the following section that this estimate of the causal effect is extremely close to the actual causal effect.\n\n\nInformer View of the Causal Effect\n\nAn informer with access to the fully observed observational data, as summarized in Table 2 (Note that although it can be verified that the data in Table 2 are compatible with those in Table 1, we will never know these numbers in reality), would easily calculate the causal effect of recovery when taking the drug using the adjustment formula in Equation 1 (shown in Equation 8). The error of the estimate of the causal effect using Theorem 4 is only (0.7518 \u2212 0.7121)/0.7518 \u2248 5.28%.\nP (y|do(x)) = z,u P (y|x, z, u)P (z, u) = 0.7518.(8)\n\nSimulation Results\n\nHere, we further illustrate that the midpoints of the proposed bounds on causal effects are sufficient for estimating the causal effects, and the midpoints of the proposed bounds in Theorem 4 are better than the midpoints of the Tian-Pearl bounds in Equation 3 based on a random simulation.\n\nWe employ the simplest causal diagram in Figure 1a with binary W , U , such that W \u222a U satisfies the back-door criterion. We randomly generated 1000 sample distributions compatible with the causal diagram (the algorithm for generating the sample distributions is shown in the appendix). The average gap (upper bound \u2212 lower bound) of the Tian-Pearl bounds among 1000 samples is 0.487, and the average gap of the proposed bounds among 1000 samples is 0.383. We then randomly picked 100 out of 1000 sample distributions to draw the graph of the actual causal effects, the midpoints of the Tian-Pearl bounds, and the midpoints of the proposed bounds. The results are shown in Figure 2a.  \n\n\nApplication to High Dimensionality of Adjustment Variables\n\nConsider the problem of estimating the causal effects of X on Y when a sufficient set Z, which satisfies the back-door or front-door criterion, is fully observable (e.g., see Figure 1b) in a causal diagram G but has high dimensionality (e.g., Z has 1024 instantiates), a prohibitive large sample size would be required to estimate the causal effects, which is generally recognized to be impractical. Herein, we propose a new framework to achieve dimensionality reduction.\n\n\nEquivalent Causal Diagram with Observational Data\n\nDefinition 6 (Equivalent causal diagram with observational data). Let G, G be causal diagrams both containing nodes X, Y . O are observational data compatible with G, and O are observational data compatible with G . We say that\n(G, O) is equivalent to (G , O ) if the causal effects of X on Y with (G, O) is equal to the causal effects of X on Y with (G , O ).\nThis equivalent tuple (G , O ) is easy to obtain. We can simply add two new nodes W and U , and remove a node Z in G to obtain G . Let the arrows entering Z in G now enter both W and U in G , and let the arrows exiting Z in G now exit both W and U in G . Finally, add an arrow from U to W . It is easy to show that ( Note that, let Q be the set of variables in G that satisfies the back-door or front-door criterion relative to (X, Y ), then Q satisfies the back-door or front-door criterion relative to (X, Y ) in G , where\nQ = Q if Z / \u2208 Q, Q = Q \\ {Z} \u222a {W, U } if Z \u2208 Q.\nObservational data: Let p be the number of states in W , and q be the number of states in U . The states of Z are the Cartesian product of the states of W and the states of U. In detail, (w j , u k ) is equivalent to z (j\u22121) * q+k , w j is equivalent to \u2228 q k=1 (w j , u k ) = \u2228 q k=1 z (j\u22121) * q+k , and u k is equivalent to \u2228 p j=1 (w j , u k ) = \u2228 p j=1 z (j\u22121) * q+k , i.e., P (w j , u k , V ) = P (z (j\u22121) * q+k , V ) for any V \u2286 {V 1 , ..., V n\u22123 , X, Y }.\n\nFor example, consider the causal diagram in Figure 1b and the observational data (in the form of conditional probability tables (CPTs), where X, Y are binary, and Z has 4 states.) in Table 3. The causal effect, P (y|do(x)), through the adjustment formula in Equation 1, is 0.47. Based on the construction in Theorem 7 (see the appendix for details), we have the causal diagram in Figure 1b with the observational data in Table 3 is equivalent to the causal diagram in Figure  1c with the observational data in Table 4 (all nodes are binary), and we can verify that the causal effect, P (y|do(x)), in the causal diagram in Figure 1c with the observational data in Table 4 is also 0.47.  Figure 1b.  Figure 1c.\nP (z 1 ) 0.3 P (z 2 ) 0.2 P (z 3 ) 0.2 P (z 4 ) 0.3 P (x|z 1 ) 0.1 P (x|z 2 ) 0.4 P (x|z 3 ) 0.5 P (x|z 4 ) 0.7 P (y|x, z 1 ) 0.2 P (y|x , z 1 ) 0.3 P (y|x, z 2 ) 0.7 P (y|x , z 2 ) 0.1 P (y|x, z 3 ) 0.6 P (y|x , z 3 ) 0.5 P (y|x, z 4 ) 0.5 P (y|x , z 4 ) 0.4P (u) 0.5 P (w|u) 0.6 P (w|u ) 0.4 P (x|u, w) 0.1 P (x|u, w ) 0.4 P (x|u , w) 0.5 P (x|u , w ) 0.7 P (y|x, u, w) 0.2 P (y|x , u, w) 0.3 P (y|x, u, w ) 0.7 P (y|x , u, w ) 0.1 P (y|x, u , w) 0.6 P (y|x , u , w) 0.5 P (y|x, u , w ) 0.5 P (y|x , u , w ) 0.4\nNotably, the equivalent tuple is not unique and is transitive\n(i.e., if (G, O) is equivalent to (G , O ), and (G , O ) is equivalent to (G , O ), then (G, O) is equivalent to (G , O )).\n\nDimensionality Reduction\n\nNow, considering the problem in the beginning of Section 5. First, we transform the causal diagram G with the compatible observational data O into an equivalent tuple (G , O ) using Algorithm 1 based on the construction in Theorem 7 (note that the algorithm only construct the structure of the G and assigning the meaning of the states for W, U , the corresponding observatioal data O are then easy to obtain), then the new problem (G , O ) has the same causal effects of X on Y as in (G, O). By picking the dimensionality of W (p in Algorithm 1), we can control the dimensionality of the new problem.\n\nNote that, if Z = (Z 1 , Z 2 , ..., Z m ) in G is a set of variables, we can repeat Algorithm 1 for each variable in Z, and finally obtain W = (W 1 , W 2 , ..., W m ) and U = (U 1 , U 2 , ..., U m ), where the multiplication of the number of states in W is equal to p.\n\nWe then treat the new problem (G , O ) as a partially observable back-door or front-door variables problem in Sections 3.1 and 3.2, where P (X, Y, W ) and P (U ) are given, and we can then obtain the bounds of the causal effects through Theorems 4 and 5. We claim that the midpoints of the bounds are good estimates of the original causal effects. In addition, the bounds themselves will help make decisions.\n\n\nExample\n\nConsider the problem in Figure 1b, where X and Y are binary and Z has 256 states. We randomly generated a distribution P (X, Y, Z) that is compatible with the causal diagram. Because we know the exact distribution, we can easily obtain the causal effects through Equation 1. The causal effect P (y|do(x)) is 0.5527 (the algorithm for generating the distribution is shown in the appendix). Now, we transform the causal diagram with the observational data into an equivalent tuple (G , O ) (G is shown in Figure 1c) using Algorithm 1 (p = 16). We obtain the variable W of 16 states and the variable U of 16 states in G ((w j , u k ) is equivalent to z (j\u22121) * 16+k ). We are then forced to use only observational data P (X, Y, W ) and P (U ) (the construction of P (X, Y, W ) and P (U ) is shown in the appendix), and based on Theorem 4, with the \"SLSQP\" solver, we obtain the bounds on the causal effect p(y|do(x)), which are 0.4595 \u2264 P (y|do(x)) \u2264 0.7012. We see the midpoint, 0.5804, is extremely close to the actual causal effect, 0.5527.\n\nAlgorithm 1: Generate Equivalent Tuple input :A n nodes, (X 1 , X 2 , ..., X n\u22123 , X, Y, Z), causal diagram G and compatible O, p, the number of states in W in G of the equiv. tuple (G , O ). output :A n + 1 nodes, (X 1 , X 2 , ..., X n\u22123 , X, Y, W, U ), causal diagram G , Maping relation M 1 : state of W \u2212 \u2192 state of Z, Maping relation M 2 : state of U \u2212 \u2192 state of Z. begin m \u2190 num_states_in_G(Z); if m mod p = 0 then q \u2190 m/p; end else q \u2190 m/p + 1; end // Set the virtual states for Z such that the probability is 0.\nnum_states_in_G(Z) \u2190 p \u00d7 q; for H in {X 1 , ..., X n\u22123 , X, Y } do num_states_in_G'(H) \u2190 num_states_in_G(H); if Z \u2208Parents_in_G(H) then Parents_in_G'(H) \u2190 Parents_in_G(H)\\{Z} \u222a {W, U }; end else Parents_in_G'(H) \u2190 Parents_in_G(H); end end num_states_in_G'(W ) \u2190 p; num_states_in_G'(U ) \u2190 q; Parents_in_G'(W ) \u2190 Parents_in_G(Z)\u222a{U }; Parents_in_G'(U ) \u2190 Parents_in_G(Z); for i \u2190 1 to p do M 1 (w i ) \u2190 \u2228 q k=1 z (i\u22121) * q+k ; end for i \u2190 1 to q do M 2 (u i ) \u2190 \u2228 p j=1 z (j\u22121) * q+i ; end end\nFinally, lets consider how many samples are required for each method. According to [Roscoe(1975)], each state needs at least 30 samples, and therefore, the exact solution by Equation 1 requires 2 \u00d7 2 \u00d7 256 \u00d7 30 = 30720 samples. However, the proposed bounds based on Theorem 4 only requires max(2 \u00d7 2 \u00d7 16, 16) \u00d7 30 = 1920 samples. If the sample size is still unacceptable, we can use another equivalent tuple with W having 8 states and U having 32 states, we then only require max(2 \u00d7 2 \u00d7 8, 32) \u00d7 30 = 960 samples to obtain the bounds on the causal effects.\n\n\nSimulation Results\n\nSimilarly to the previous simulation, we further illustrate that the bounds on the causal effects of the proposed framework are sufficient for estimating the original causal effects.\n\nOnce again, by employing the simplest causal diagram in Figure 1b, where X and Y are binary and Z has 256 states. We randomly generated 100 sample distributions compatible with the causal diagram (the algorithm for generating the distributions are shown in the appendix). The average gap (upper bound \u2212 lower bound) of the Tian-Pearl bounds among 100 samples is 0.5102, and the average gap of the proposed bounds through Theorems 7 and 4 among 100 samples is 0.0676. We then draw the graph of the actual causal effects, the midpoints of the Tian-Pearl bounds, and the midpoints of the proposed bounds through Theorems 7 and 4. The results are shown in Figure 2b.\n\nFrom Figure 2b, both midpoints of the bounds on the causal effects are good estimates of the actual causal effects, whereas the midpoints of the proposed bounds are slightly closer to the actual causal effects, particularly when the causal effects are close to 0 and 1. Although the trend of the Tian-Pearl bounds is also close to the actual causal effects, the Tian-Pearl bounds are more likely to be parallel with the x-axis. Here, the Tian-Pearl bounds perform well because, in high-dimensionality cases, the randomly generated distributions are more likely to yield causal effects of approximately 0.5. However, the average gap of the proposed bounds among 100 samples, 0.0676, is much smaller than the average gap of the Tian-Pearl bounds among 100 samples, 0.5102. This means that the midpoints of the proposed bounds are more convincing, because the bounds are narrower.\n\n\nDiscussion\n\nHere, we discuss additional features of bounds on causal effects.\n\nFirst, if a whole set of back-door or front-door variables are unobserved, the causal effects have the naivest bounds in Equation 3. When the back-door or front-door variables are gradually observed, the bounds of the causal effects become increasingly narrow. Finally, when the back-door or front-door variables are fully observed, the bounds shrink into point estimates, which are identifiable. This also tells us that, when we pick p in Algorithm 1, we should pick the largest p for which the sample size is sufficient to estimate the observational distributions.\n\nNext, bounds in Theorems 4 and 5 are given by non-linear optimizations. Therefore, the quality of the bounds also depends on the optimization solver. The examples and simulated results in this paper are all obtained from the simplest \"SLSQP\" solver from 1988. The quality of the bounds can be improved if more advanced solvers are applied. Inspired by the idea of Balke's linear programming [Balke and Pearl(1997b)], we may obtain parametric solutions to non-linear optimizations in Theorems 4 and 5, we then do not need a non-linear optimization solver. However, the problem related to a non-linear optimization solver is not the scope of this paper.\n\nIn addition, the constraints in Theorems 4 and 5 are only based on the basic back-door or front-door criterion. We can also add constraints of independencies in a specific graph. For instance, W and U are independent in the causal diagram of Figure 1d, we can then add the constraints that reflect P (W ) and P (U ) as being independent. The greater the number of constraints that are added to the optimizations, the better the bounds we can obtain.\n\nMoreover, if one believes they have a sufficient sample size to estimate causal effects with high dimensionality adjustment variables, the framework in Section 5 could be evidence validating whether the sample size is indeed sufficient.\n\nNext, in Section 5, we transformed (G, O) into (G , O ) to obtain the bounds on causal effects with high dimensionality adjustment variables. However, for a tuple (G, O), multiple equivalent tuples exist by picking a different p in Algorithm 1, and each of the equivalent tuple has bounds for the original causal effects. We can compute bounds for as many equivalent tuples as we want and take the maximal lower bounds and the minimal upper bounds.\n\nFinally, based on numerous experiments, we realized that when P (U ) or P (W ) is specific (i.e., closer to 0 or 1), the proposed bounds are almost identified (i.e., the bounds shrink to point estimates). Therefore, in practice, we can always pick the equivalent tuple to transform, in which the P (U ) or P (W ) is close to 0 or 1.\n\n\nConclusion\n\nWe demonstrated how to estimate causal effects when adjustment variables in the back-door or front-door criterion are partially observable by bounding the causal effects using solutions to non-linear optimizations. We provided examples and simulated results illustrating that the proposed method is sufficient to estimate the causal effects. We also proposed a framework for estimating causal effects when the adjustment variables have a high dimensionality. In summary, we analyzed and demonstrated how causal effects can be gained in practice using a causal diagram.\n\n\nA Proof of Theorem 4\n\nTheorem 4. Given a causal diagram G and a distribution compatible with G, let W \u222a U be a set of variables satisfying the back-door criterion in G relative to an ordered pair (X, Y ), where W \u222a U is partially observable, i.e., only probabilities P (X, Y, W ) and P (U ) are given, the causal effects of X on Y are then bounded as follows:\nLB \u2264 P (y|do(x)) \u2264 UB\nwhere LB is the solution to the non-linear optimization problem in Equation 9 and UB is the solution to the non-linear optimization problem in Equation 10.\nLB = min w,u a w,u b w,u c w,u ,(9)U B = max w,u a w,u b w,u c w,u ,(10)\nwhere, u a w,u = P (x, y, w),\nu b w,u = P (w), u c w,u = P (x, w) for all w \u2208 W ;\nand for all w \u2208 W and u \u2208 U, b w,u \u2265 c w,u \u2265 a w,u , max{0, p(x, y, w)\n+ p(u) \u2212 1} \u2264 a w,u \u2264 min{P (x, y, w), p(u)}, max{0, p(w) + p(u) \u2212 1} \u2264 b w,u \u2264 min{P (w), p(u)}, max{0, p(x, w) + p(u) \u2212 1} \u2264 c w,u \u2264 min{P (x, w), p(u)}.\nProof. To show that the LB and UB bound the actual causal effects, we only need to show that there exists a point in feasible space of the non-linear optimization that w,u aw,ubw,u cw,u is equal to the actual causal effects. Since W \u222a U satisfies the back-door criterion, by adjustment formula in Equation 1, we have,\nP (y|do(x)) = w,u P (y|x, w, u)P (w, u) = w,u P (x, y, w, u)P (w, u) P (x, w, u) Let a w,u = P (x, y, w, u) b w,u = P (w, u) c w,u = P (x, w, u)\nWe now show that the above set of a w,u , b w,u , c w,u are in feasible space. We have,\nfor w \u2208 W u a w,u = u P (x, y, w, u) = P (x, y, w) u b w,u = u P (w, u) = P (w) u c w,u = u P (x, w, u) = P (x, w)\nand, for all w \u2208 W and u \u2208 U b w,u = P (w, u) \u2265 P (x, w, u) = c w,u c w,u = P (x, w, u) \u2265 P (x, y, w, u) = a w,u a w,u = P (x, y, w, u)\n\u2264 min{P (x, y, w), p(u)} b w,u = P (w, u) \u2264 min{P (w), p(u)} c w,u = P (x, w, u) \u2264 min{P (x, w), p(u)} a w,u = P (x, y, w, u) \u2265 max{0, p(x, y, w) + p(u) \u2212 1} b w,u = P (w, u) \u2265 max{0, p(w) + p(u) \u2212 1} c w,u = P (x, w, u) \u2265 max{0, p(x, w) + p(u) \u2212 1}\nTherefore, the above set of a w,u , b w,u , c w,u are in feasible space, and thus, the UB and LB bound the actual causal effects.\n\nB Proof of Theorem 5\n\nTheorem 5. Given a causal diagram G and distribution compatible with G, let W \u222a U be a set of variables satisfying the front-door criterion in G relative to an ordered pair (X, Y ), where W \u222a U is partially observable, i.e., only probabilities P (X, Y, W ) and P (U ) are given and P (x, W, U ) > 0, the causal effects of X on Y are then bounded as follows:\nLB \u2264 P (y|do(x)) \u2264 UB\nwhere LB is the solution to the non-linear optimization problem in Equation 11 and UB is the solution to the non-linear optimization problem in Equation 12.\nLB = min w,u b x,w,u P (x) x a x ,w,u P (x ) b x ,w,u ,(11)U B = max w,u b x,w,u P (x) x a x ,w,u P (x ) b x ,w,u ,(12)\nwhere, u a x,w,u = P (x, y, w), u b x,w,u = P (x, w) for all x \u2208 X and w \u2208 W ;\n\nand for all x \u2208 X,w \u2208 W , and u \u2208 U, b x,w,u \u2265 a x,w,u , max{0, p(x, y, w) + p(u) \u2212 1} \u2264 a x,w,u \u2264 min{P (x, y, w), p(u)}, max{0, p(x, w) + p(u) \u2212 1} \u2264 b x,w,u \u2264 min{P (x, w), p(u)}.\n\nProof. To show that the LB and UB bound the actual causal effects, we only need to show that there exists a point in feasible space of the non-linear optimization that w,u bx,w,u\nP (x) x a x ,w,u P (x ) b x ,w,u\nis equal to the actual causal effects. Since W \u222a U satisfies front-door criterion and P (u, W, U ) > 0, by adjustment formula in Equation 2, we have,\nP (y|do(x)) = w,u P (w, u|x) x P (y|x , w, u)P (x ) = w,u P (x, w, u) P (x) x P (x , y, w, u)P (x ) P (x , w, u)\nLet a x,w,u = P (x, y, w, u) b x,w,u = P (x, w, u)\n\nSimilarly to the proof of Theorem 4, it is easy to show that the above set of a x,w,u , b x,w,u are in feasible space, and therefore, LB and UB bound the actual causal effects.\n\n\nC Proof of Theorem 7\n\nTheorem 7. Let G be a causal diagram containing nodes {V 1 , ..., V n\u22123 , X, Y, Z}. Let O be any observational data compatible with G. Suppose there exists a set of variables that satisfies the back-door or front-door criterion relative to (X, Y ) in G, then, (G, O) is equivalent to (G , O ) (G containing nodes {V 1 , ..., V n\u22123 , X, Y, W, U }; O is observational data compatible with G ), where the number of states in W times the number of states in U is equal to the number of states in Z, and the structure of G and the observational data O are obtained as follows:\n\nStructure of G : Let P arents G (H) be the parents of H in causal diagram G. P arents G (U ) = P arents G (Z), P arents G (W ) = P arents G (Z) \u222a {U },\nP arents G (H) = P arents G (H) if Z / \u2208 P arents G (H) for H \u2208 {V 1 , ..., V n\u22123 , X, Y }, P arents G (H) = P arents G (H) \\ {Z} \u222a {W, U } if Z \u2208 P arents G (H) for H \u2208 {V 1 , ..., V n\u22123 , X, Y }.\nNote that, let Q be the set of variables in G that satisfies the back-door or front-door criterion relative to (X, Y ), then Q satisfies the back-door or front-door criterion relative to (X,\nY ) in G , where Q = Q if Z / \u2208 Q, Q = Q \\ {Z} \u222a {W, U } if Z \u2208 Q.\nObservational data: Let the number of states in W be p, and let the number of states in U be q. The states of Z is the Cartesian product of the states of W and the states of U. In detail, (w j , u k ) is equivalent to z (j\u22121) * q+k , w j is equivalent to \u2228 q k=1 (w j , u k ) = \u2228 q k=1 z (j\u22121) * q+k , and u k is equivalent to \u2228 p j=1 (w j , u k ) = \u2228 p j=1 z (j\u22121) * q+k , i.e., P (w j , u k , V ) = P (z (j\u22121) * q+k , V ) for any V \u2286 {V 1 , ..., V n\u22123 , X, Y }.\n\nProof. First, we show that Q satisfies the back-door or front-door criterion relative to (X, Y ) in G .\n\nIf Q satisfies the back-door criterion relative to (X, Y ) in G, we need to show that,\n\n\u2022 no node in Q is a descendant of X.\n\n\u2022 Q blocks every path between X and Y that contains an arrow into X.\n\nIt is easy to show that if there is a node in Q that is a descendant of X in G , then there is a node in Q that is a descendant of X in G. And if there is a path between X and Y that contains an arrow into X does not blocked by Q in G , then there is a path between X and Y that contains an arrow into X does not blocked by Q in G. Thus, Q satisfies the back-door criterion relative to (X, Y ) in G . Similarly, we can show that if Q satisfies the front-door criterion relative to (X, Y ) in G, then Q satisfies the front-door criterion relative to (X, Y ) in G . Now, we show that (G, O) is equivalent to (G , O ), i.e., show that P (y|do(x)) is the same between (G, O) and (G , O ). Suppose Q satisfies the back-door criterion relative to (X, Y ) in G. By adjustment formula in Equation 1, we have, P (y|do(x)) = q\u2208Q P (y|x, q) \u00d7 P (q) = q\u2208Q P (x,y,q)\u00d7P (q) P (x,q)\n\n. And in G , P (y|do(x)) = q\u2208Q P (y|x, q) \u00d7 P (q) = q\u2208Q P (x,y,q)\u00d7P (q) P (x,q)\n\n, it is obviously that these two causal effects are the same, because P (w j , u k , V ) = P (z (j\u22121) * q+k , V ) for any V \u2286 {V 1 , ..., V n\u22123 , X, Y }. Similarly, we can show that if Q satisfies the front-door criterion relative to (X, Y ) in G, (G, O) is equivalent to (G , O ). D Simulation Algorithm for Generating Sample Distributions in Sections 4.3, 5.3, and 5.4\n\nAlgorithm 2: Generate-cpt() input :n causal diagram nodes (X 1 , ..., X n ) Distribution D output :n conditional probability tables for P (X i |P arents(X i )) begin for i \u2190 1 to n do s \u2190 num-instantiates(X i ) p \u2190 num-instantiates(P arents(X i )) for k \u2190 1 to p do sum \u2190 0 for j \u2190 1 to s do a j \u2190 sample(D) sum \u2190 sum + a j end for j \u2190 1 to s do P (x ij |P arents(X i ) k ) \u2190 a j /sum end end end end\n\nIn our simulation studies, we set D in Algorithm 2 to the uniform distribution. Table 4 of Section 5.1 P (u, w) = P (z 1 ), P (u, w ) = P (z 2 ), P (u , w) = P (z 3 ), P (u , w ) = P (z 4 ), P (u) = P (u, w) + P (u, w ) = P (z 1 ) + P (z 2 ) = 0.5, P (w|u) = P (u, w)/p(u) = P (z 1 )/P (u) = 0.3/0.5 = 0.6, P (w|u ) = P (u , w)/p(u ) = P (z 3 )/(1 \u2212 P (u)) = 0.2/0.5 = 0.4, P (x|u, w) = P (x|z 1 ) = 0.1, P (x|u, w ) = P (x|z 2 ) = 0.4, P (x|u , w) = P (x|z 3 ) = 0.5, P (x|u , w ) = P (x|z 4 ) = 0.7, P (y|x, u, w) = P (y|x, z 1 ) = 0.2, P (y|x , u, w) = P (y|x , z 1 ) = 0.3, P (y|x, u, w ) = P (y|x, z 2 ) = 0.7, P (y|x , u, w ) = P (y|x , z 2 ) = 0.1, P (y|x, u , w) = P (y|x, z 3 ) = 0.6, P (y|x , u , w) = P (y|x , z 3 ) = 0.5, P (y|x, u , w ) = P (y|x, z 4 ) = 0.5, P (y|x , u , w ) = P (y|x , z 4 ) = 0.4.\n\n\nE Construction of the Data in\n\n\nF Construction of the Distribution in Section 5.3\n\nInstead of providing the resulting 1024 rows of the observational data, we provide the details for regenerating the observational data as following steps.\n\n\u2022 Generate P (X, Y, Z) using Algorithm 2. \u2022 Let P (X, Y, w j , u k ) = P (X, Y, z (j\u22121) * 16+k ).\n\n\u2022 Let P (X, Y, w j ) = q k=1 P (X, Y, w j , u k ). \u2022 Let P (X, Y, u k ) = p j=1 P (X, Y, w j , u k ). \u2022 Let P (u k ) = X,Y P (X, Y, u k ).\n\nFor example, P (u 1 ) = X,Y P (X, Y, u 1 ) = P (x, y, u 1 ) + P (x, y , u 1 ) + P (x , y, u 1 ) + P (x , y , u 1 ) = 16 j=1 P (x, y, w j , u 1 ) + 16 j=1 P (x, y , w j , u 1 ) + 16 j=1 P (x , y, w j , u 1 ) + 16 j=1 P (x , y , w j , u 1 ) = 16 j=1 P (x, y, z (j\u22121) * 16+1 ) + 16 j=1 P (x, y , z (j\u22121) * 16+1 ) + 16 j=1 P (x , y, z (j\u22121) * 16+1 ) + 16 j=1 P (x , y , z (j\u22121) * 16+1 ), P (x, y, w 1 ) = 16 k=1 P (x, y, w 1 , u k ) = 16 k=1 P (x, y, z k ).\n\n\ninto an equivalent problem associated withFigure 1c\n\n\n) U is unobserved and independent with W .\n\nFigure 1 :\n1Needed the causal effects of X on Y .\n\nFrom\nFigure 2a, although both midpoints of the bounds on the causal effects are good estimates of the actual causal effects, the midpoints of the proposed bounds are much closer to the actual causal effects, particularly when the causal effects are close to 0 and 1. The average gap (upper bounds \u2212 lower bounds), 0.383, of the proposed bounds among 1000 samples is much smaller than the average gap, 0.487, of the Tian-Pearl bounds among 1000 samples. This means that the midpoints of the proposed bounds are more convincing, because the bounds are narrower.(a) Estimates of causal effects with partially observed confounders.(b) Estimates of causal effects with high dimensional data.\n\nFigure 2 :\n2Bounds on causal effects of 100 sample distributions, where the Tian-Pearl bounds are obtained through Equation 3 and the proposed bounds are obtained through Theorem 4.\n\n\nG, O) and (G , O ) are equivalent if the states of Z are the Cartesian product of the states of W and the states of U . Formally, we have the following theorem (the proof of the theorem is provided in the appendix), Theorem 7. Let G be a causal diagram containing nodes {V 1 , ..., V n\u22123 , X, Y, Z}. Let O be any observational data compatible with G. Suppose there exists a set of variables that satisfies the back-door or front-door criterion relative to (X, Y ) in G, then, (G, O) is equivalent to (G , O ) (G containing nodes {V 1 , ..., V n\u22123 , X, Y, W, U }; O are observational data compatible with G ), where the number of states in W times the number of states in U is equal to the number of states in Z, and the structure of G and the observational data O are obtained as follows: Structure of G : Let P arents G (H) be the parents of H in causal diagram G. P arents G (U ) = P arents G (Z), P arents G (W ) = P arents G (Z) \u222a {U }, P arents G (H) = P arents G (H) if Z / \u2208 P arents G (H) for H \u2208 {V 1 , ..., V n\u22123 , X, Y }, P arents G (H) = P arents G (H) \\ {Z} \u222a {W, U } if Z \u2208 P arents G (H) for H \u2208 {V 1 , ..., V n\u22123 , X, Y }.\n\nTable 1 :\n1Results of an observational study considering \nblood type. \nDrug \nNo Drug \n\nBlood \ntype O \n\n23 out of 36 \nrecovered \n(63.9%) \n\n145 out of 225 \nrecovered \n(64.4%) \n\nNot blood \ntype O \n\n135 out of 156 \nrecovered \n(86.5%) \n\n152 out of 283 \nrecovered \n(53.7%) \n\nOverall \n\n158 out of 192 \nrecovered \n(82.3%) \n\n297 out of 508 \nrecovered \n(58.5%) \n\n\n\nTable 2 :\n2Informer view of the observational data considering blood type and age.Drug \nNo Drug \nBlood \ntype O \nand \nAge \nbelow 70 \n\n3 out of 4 \nrecovered \n(75.0%) \n\n141 out of 219 \nrecovered \n(64.4%) \n\nBlood \ntype O \nand \nAge \nabove 70 \n\n20 out of 32 \nrecovered \n(62.5%) \n\n4 out of 6 \nrecovered \n(66.7%) \n\nNot blood \ntype O \nand \nAge \nbelow 70 \n\n135 out of 151 \nrecovered \n(89.4%) \n\n117 out of 224 \nrecovered \n(52.2%) \n\nNot blood \ntype O \nand \nAge \nabove 70 \n\n0 out of 5 \nrecovered \n(0.0%) \n\n35 out of 59 \nrecovered \n(59.3%) \n\nOverall \n\n158 out of 192 \nrecovered \n(82.3%) \n\n297 out of 508 \nrecovered \n(58.5%) \n\n\n\nTable 3 :\n3Observational data in CPTs compatible with the causal diagram in\n\nTable 4 :\n4Observational data in CPTs compatible with the causal diagram in\n\nBounds on treatment effects from studies with imperfect compliance. Pearl ; Alexander Balke, Judea Pearl, Journal of the American Statistical Association. 92439and Pearl(1997a)] Alexander Balke and Judea Pearl. Bounds on treatment effects from studies with imperfect compliance. Journal of the American Statistical Association, 92(439):1171-1176, 1997a.\n\nProbabilistic counterfactuals: Semantics, computation, and applications. Pearl ; Alexander A Balke, Judea Pearl, UCLA Dept. of Computer ScienceTechnical reportand Pearl(1997b)] Alexander A Balke and Judea Pearl. Probabilistic counterfactuals: Semantics, computation, and applications. Technical report, UCLA Dept. of Computer Science, 1997b.\n\nBounds on direct effect in the presence of confounded intermediate variables. [ Cai, Biometrics. 64Koller and Friedman[Cai et al.(2008)Cai, Kuroki, Pearl, and Tian] Zhihong Cai, Manabu Kuroki, Judea Pearl, and Jin Tian. Bounds on direct effect in the presence of confounded intermediate variables. Biometrics, 64:695-701, 2008. [Koller and Friedman(2009)]\n\nProbabilistic graphical models: Principles and techniques. Daphne Koller, Nir Friedman, MIT pressDaphne Koller and Nir Friedman. Probabilistic graphical models: Principles and techniques. MIT press, 2009.\n\nA software package for sequential quadratic programming. Dieter Kraft, Deutsche Forschungs-und Versuchsanstalt f\u00fcr Luft-und Raumfahrt K\u00f6ln: Forschungsbericht. Wiss. Berichtswesen d. DFVLR. Dieter Kraft. A software package for sequential quadratic programming. Deutsche Forschungs-und Versuchsanstalt f\u00fcr Luft-und Raumfahrt K\u00f6ln: Forschungsbericht. Wiss. Berichtswesen d. DFVLR, 1988. URL https://books.google.com/books?id=4rKaGwAACAAJ.\n\nUnit selection based on counterfactual logic. Pearl ; Ang Li, Judea Li, Pearl, Proceedings of the 28th International Joint Conference on Artificial Intelligence. the 28th International Joint Conference on Artificial IntelligenceAAAI Press[Li and Pearl(2019)] Ang Li and Judea Pearl. Unit selection based on counterfactual logic. In Proceedings of the 28th International Joint Conference on Artificial Intelligence, pages 1793-1799. AAAI Press, 2019.\n\nEstimating high-dimensional intervention effects from observational data. Maathuis, The Annals of Statistics. 376A[Maathuis et al.(2009)Maathuis, Kalisch, B\u00fchlmann, et al.] Marloes H Maathuis, Markus Kalisch, Peter B\u00fchlmann, et al. Estimating high-dimensional intervention effects from observational data. The Annals of Statistics, 37(6A): 3133-3164, 2009.\n\nJudea Pearl. Probabilistic reasoning in intelligent systems: Networks of plausible inference. Judea Pearl, Biometrika. 824Morgan KaufmannCausal diagrams for empirical researchJudea Pearl. Causal diagrams for empirical research. Biometrika, 82(4):669-688, 1995. [Pearl(2009)] Judea Pearl. Causality. Cambridge university press, 2nd edition, 2009. [Pearl(2014)] Judea Pearl. Probabilistic reasoning in intelligent systems: Networks of plausible inference. Morgan Kaufmann, 2014.\n\nFundamental research statistics for the behavioral sciences. John T Roscoe, Marketing. Holt, Rinehart and WinstonJohn T. Roscoe. Fundamental research statistics for the behavioral sciences. Number v. 2 in Editors' Series in Marketing. Holt, Rinehart and Winston, 1975. ISBN 9780030919343. URL https://books.google. com/books?id=Fe8vAAAAMAAJ.\n\nScipycommunity, SciPyCommunity. Scipy reference guide. SciPyCommunity(2020)] SciPyCommunity. Scipy reference guide, 2020. URL https://docs.scipy.org/doc/ scipy/reference/generated/scipy.optimize.minimize.html#rdd2e1855725e-12.\n\nCausation, prediction, and search. Spirtes, MIT press[Spirtes et al.(2000)Spirtes, Glymour, Scheines, and Heckerman] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, prediction, and search. MIT press, 2000.\n\nProbabilities of causation: Bounds and identification. Jin Tian, Judea Pearl, Annals of Mathematics and Artificial Intelligence. 281-4and Pearl(2000)] Jin Tian and Judea Pearl. Probabilities of causation: Bounds and identification. Annals of Mathematics and Artificial Intelligence, 28(1-4):287-313, 2000.\n", "annotations": {"author": "[{\"end\":240,\"start\":83},{\"end\":385,\"start\":241}]", "publisher": null, "author_last_name": "[{\"end\":89,\"start\":87},{\"end\":252,\"start\":247}]", "author_first_name": "[{\"end\":86,\"start\":83},{\"end\":246,\"start\":241}]", "author_affiliation": "[{\"end\":239,\"start\":109},{\"end\":384,\"start\":254}]", "title": "[{\"end\":66,\"start\":1},{\"end\":451,\"start\":386}]", "venue": null, "abstract": "[{\"end\":969,\"start\":467}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1236,\"start\":1224},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2436,\"start\":2413},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2520,\"start\":2499},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2586,\"start\":2569},{\"end\":2616,\"start\":2587},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2730,\"start\":2711},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3974,\"start\":3962},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4020,\"start\":4008},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4073,\"start\":4022},{\"end\":4095,\"start\":4073},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4122,\"start\":4097},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4197,\"start\":4185},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6052,\"start\":6031},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7008,\"start\":6950},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":12480,\"start\":12468},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21394,\"start\":21381},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":24668,\"start\":24645}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36210,\"start\":36157},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36255,\"start\":36211},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36306,\"start\":36256},{\"attributes\":{\"id\":\"fig_3\"},\"end\":36994,\"start\":36307},{\"attributes\":{\"id\":\"fig_4\"},\"end\":37177,\"start\":36995},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38318,\"start\":37178},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38673,\"start\":38319},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":39287,\"start\":38674},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":39364,\"start\":39288},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":39441,\"start\":39365}]", "paragraph": "[{\"end\":1510,\"start\":985},{\"end\":1877,\"start\":1512},{\"end\":2352,\"start\":1879},{\"end\":2800,\"start\":2354},{\"end\":3061,\"start\":2802},{\"end\":3822,\"start\":3063},{\"end\":3976,\"start\":3856},{\"end\":4124,\"start\":3978},{\"end\":4199,\"start\":4126},{\"end\":4307,\"start\":4201},{\"end\":4724,\"start\":4560},{\"end\":5139,\"start\":4726},{\"end\":5278,\"start\":5141},{\"end\":5468,\"start\":5315},{\"end\":5517,\"start\":5470},{\"end\":5564,\"start\":5519},{\"end\":5617,\"start\":5566},{\"end\":5783,\"start\":5619},{\"end\":6148,\"start\":5832},{\"end\":6189,\"start\":6150},{\"end\":6685,\"start\":6191},{\"end\":7391,\"start\":6687},{\"end\":7590,\"start\":7420},{\"end\":7972,\"start\":7635},{\"end\":8149,\"start\":7995},{\"end\":8251,\"start\":8222},{\"end\":8332,\"start\":8304},{\"end\":8932,\"start\":8575},{\"end\":9109,\"start\":8955},{\"end\":9306,\"start\":9228},{\"end\":9382,\"start\":9308},{\"end\":9962,\"start\":9491},{\"end\":10149,\"start\":9974},{\"end\":10752,\"start\":10177},{\"end\":10938,\"start\":10754},{\"end\":11418,\"start\":10940},{\"end\":11580,\"start\":11420},{\"end\":12168,\"start\":11683},{\"end\":12952,\"start\":12170},{\"end\":13474,\"start\":12991},{\"end\":13839,\"start\":13549},{\"end\":14526,\"start\":13841},{\"end\":15060,\"start\":14589},{\"end\":15341,\"start\":15114},{\"end\":15999,\"start\":15475},{\"end\":16512,\"start\":16050},{\"end\":17222,\"start\":16514},{\"end\":17798,\"start\":17737},{\"end\":18551,\"start\":17950},{\"end\":18821,\"start\":18553},{\"end\":19231,\"start\":18823},{\"end\":20283,\"start\":19243},{\"end\":20805,\"start\":20285},{\"end\":21856,\"start\":21298},{\"end\":22061,\"start\":21879},{\"end\":22725,\"start\":22063},{\"end\":23604,\"start\":22727},{\"end\":23684,\"start\":23619},{\"end\":24252,\"start\":23686},{\"end\":24905,\"start\":24254},{\"end\":25356,\"start\":24907},{\"end\":25594,\"start\":25358},{\"end\":26044,\"start\":25596},{\"end\":26378,\"start\":26046},{\"end\":26961,\"start\":26393},{\"end\":27323,\"start\":26986},{\"end\":27501,\"start\":27346},{\"end\":27604,\"start\":27575},{\"end\":27727,\"start\":27657},{\"end\":28201,\"start\":27884},{\"end\":28434,\"start\":28347},{\"end\":28685,\"start\":28550},{\"end\":29065,\"start\":28936},{\"end\":29087,\"start\":29067},{\"end\":29446,\"start\":29089},{\"end\":29625,\"start\":29469},{\"end\":29824,\"start\":29746},{\"end\":30008,\"start\":29826},{\"end\":30188,\"start\":30010},{\"end\":30371,\"start\":30222},{\"end\":30535,\"start\":30485},{\"end\":30713,\"start\":30537},{\"end\":31309,\"start\":30738},{\"end\":31462,\"start\":31311},{\"end\":31851,\"start\":31661},{\"end\":32382,\"start\":31919},{\"end\":32487,\"start\":32384},{\"end\":32575,\"start\":32489},{\"end\":32613,\"start\":32577},{\"end\":32683,\"start\":32615},{\"end\":33552,\"start\":32685},{\"end\":33633,\"start\":33554},{\"end\":34005,\"start\":33635},{\"end\":34407,\"start\":34007},{\"end\":35222,\"start\":34409},{\"end\":35462,\"start\":35308},{\"end\":35561,\"start\":35464},{\"end\":35701,\"start\":35563},{\"end\":36156,\"start\":35703}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4559,\"start\":4308},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5314,\"start\":5279},{\"attributes\":{\"id\":\"formula_2\"},\"end\":5831,\"start\":5784},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7994,\"start\":7973},{\"attributes\":{\"id\":\"formula_5\"},\"end\":8185,\"start\":8150},{\"attributes\":{\"id\":\"formula_6\"},\"end\":8221,\"start\":8185},{\"attributes\":{\"id\":\"formula_7\"},\"end\":8303,\"start\":8252},{\"attributes\":{\"id\":\"formula_8\"},\"end\":8530,\"start\":8333},{\"attributes\":{\"id\":\"formula_9\"},\"end\":8954,\"start\":8933},{\"attributes\":{\"id\":\"formula_10\"},\"end\":9168,\"start\":9110},{\"attributes\":{\"id\":\"formula_11\"},\"end\":9227,\"start\":9168},{\"attributes\":{\"id\":\"formula_12\"},\"end\":9490,\"start\":9383},{\"attributes\":{\"id\":\"formula_13\"},\"end\":11682,\"start\":11581},{\"attributes\":{\"id\":\"formula_14\"},\"end\":13527,\"start\":13475},{\"attributes\":{\"id\":\"formula_15\"},\"end\":15474,\"start\":15342},{\"attributes\":{\"id\":\"formula_16\"},\"end\":16049,\"start\":16000},{\"attributes\":{\"id\":\"formula_17\"},\"end\":17482,\"start\":17223},{\"attributes\":{\"id\":\"formula_18\"},\"end\":17736,\"start\":17482},{\"attributes\":{\"id\":\"formula_19\"},\"end\":17922,\"start\":17799},{\"attributes\":{\"id\":\"formula_20\"},\"end\":21297,\"start\":20806},{\"attributes\":{\"id\":\"formula_21\"},\"end\":27345,\"start\":27324},{\"attributes\":{\"id\":\"formula_22\"},\"end\":27537,\"start\":27502},{\"attributes\":{\"id\":\"formula_23\"},\"end\":27574,\"start\":27537},{\"attributes\":{\"id\":\"formula_24\"},\"end\":27656,\"start\":27605},{\"attributes\":{\"id\":\"formula_25\"},\"end\":27883,\"start\":27728},{\"attributes\":{\"id\":\"formula_26\"},\"end\":28346,\"start\":28202},{\"attributes\":{\"id\":\"formula_27\"},\"end\":28549,\"start\":28435},{\"attributes\":{\"id\":\"formula_28\"},\"end\":28935,\"start\":28686},{\"attributes\":{\"id\":\"formula_29\"},\"end\":29468,\"start\":29447},{\"attributes\":{\"id\":\"formula_30\"},\"end\":29685,\"start\":29626},{\"attributes\":{\"id\":\"formula_31\"},\"end\":29745,\"start\":29685},{\"attributes\":{\"id\":\"formula_32\"},\"end\":30221,\"start\":30189},{\"attributes\":{\"id\":\"formula_33\"},\"end\":30484,\"start\":30372},{\"attributes\":{\"id\":\"formula_34\"},\"end\":31660,\"start\":31463},{\"attributes\":{\"id\":\"formula_35\"},\"end\":31918,\"start\":31852}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":10478,\"start\":10471},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":11574,\"start\":11566},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12260,\"start\":12253},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":13081,\"start\":13074},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":13145,\"start\":13138},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":13182,\"start\":13175},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":16704,\"start\":16697},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":16942,\"start\":16935},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":17031,\"start\":17024},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":17184,\"start\":17177},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":34496,\"start\":34489}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":983,\"start\":971},{\"attributes\":{\"n\":\"2\"},\"end\":3854,\"start\":3825},{\"attributes\":{\"n\":\"3\"},\"end\":7418,\"start\":7394},{\"attributes\":{\"n\":\"3.1\"},\"end\":7633,\"start\":7593},{\"attributes\":{\"n\":\"3.2\"},\"end\":8573,\"start\":8532},{\"attributes\":{\"n\":\"4\"},\"end\":9972,\"start\":9965},{\"attributes\":{\"n\":\"4.1\"},\"end\":10175,\"start\":10152},{\"attributes\":{\"n\":\"4.2\"},\"end\":12989,\"start\":12955},{\"attributes\":{\"n\":\"4.3\"},\"end\":13547,\"start\":13529},{\"attributes\":{\"n\":\"5\"},\"end\":14587,\"start\":14529},{\"attributes\":{\"n\":\"5.1\"},\"end\":15112,\"start\":15063},{\"attributes\":{\"n\":\"5.2\"},\"end\":17948,\"start\":17924},{\"attributes\":{\"n\":\"5.3\"},\"end\":19241,\"start\":19234},{\"attributes\":{\"n\":\"5.4\"},\"end\":21877,\"start\":21859},{\"attributes\":{\"n\":\"6\"},\"end\":23617,\"start\":23607},{\"attributes\":{\"n\":\"7\"},\"end\":26391,\"start\":26381},{\"end\":26984,\"start\":26964},{\"end\":30736,\"start\":30716},{\"end\":35254,\"start\":35225},{\"end\":35306,\"start\":35257},{\"end\":36267,\"start\":36257},{\"end\":36312,\"start\":36308},{\"end\":37006,\"start\":36996},{\"end\":38329,\"start\":38320},{\"end\":38684,\"start\":38675},{\"end\":39298,\"start\":39289},{\"end\":39375,\"start\":39366}]", "table": "[{\"end\":38673,\"start\":38331},{\"end\":39287,\"start\":38757}]", "figure_caption": "[{\"end\":36210,\"start\":36159},{\"end\":36255,\"start\":36213},{\"end\":36306,\"start\":36269},{\"end\":36994,\"start\":36313},{\"end\":37177,\"start\":37008},{\"end\":38318,\"start\":37180},{\"end\":38757,\"start\":38686},{\"end\":39364,\"start\":39300},{\"end\":39441,\"start\":39377}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":1657,\"start\":1648},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":3215,\"start\":3206},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":3480,\"start\":3471},{\"end\":9032,\"start\":9022},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":11417,\"start\":11408},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13891,\"start\":13882},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":14523,\"start\":14514},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14773,\"start\":14764},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16567,\"start\":16558},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16903,\"start\":16894},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16992,\"start\":16982},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17145,\"start\":17136},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17209,\"start\":17200},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17221,\"start\":17212},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19276,\"start\":19267},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19755,\"start\":19746},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22128,\"start\":22119},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22724,\"start\":22715},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":22741,\"start\":22732},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":25158,\"start\":25149},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":29547,\"start\":29536}]", "bib_author_first_name": "[{\"end\":39528,\"start\":39511},{\"end\":39541,\"start\":39536},{\"end\":39890,\"start\":39871},{\"end\":39903,\"start\":39898},{\"end\":40220,\"start\":40219},{\"end\":40563,\"start\":40557},{\"end\":40575,\"start\":40572},{\"end\":40767,\"start\":40761},{\"end\":41198,\"start\":41187},{\"end\":41208,\"start\":41203},{\"end\":42049,\"start\":42044},{\"end\":42493,\"start\":42489},{\"end\":42495,\"start\":42494},{\"end\":43298,\"start\":43295},{\"end\":43310,\"start\":43305}]", "bib_author_last_name": "[{\"end\":39534,\"start\":39529},{\"end\":39547,\"start\":39542},{\"end\":39896,\"start\":39891},{\"end\":39909,\"start\":39904},{\"end\":40224,\"start\":40221},{\"end\":40570,\"start\":40564},{\"end\":40584,\"start\":40576},{\"end\":40773,\"start\":40768},{\"end\":41201,\"start\":41199},{\"end\":41211,\"start\":41209},{\"end\":41218,\"start\":41213},{\"end\":41674,\"start\":41666},{\"end\":42055,\"start\":42050},{\"end\":42502,\"start\":42496},{\"end\":42785,\"start\":42771},{\"end\":43041,\"start\":43034},{\"end\":43303,\"start\":43299},{\"end\":43316,\"start\":43311}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":18365761},\"end\":39796,\"start\":39443},{\"attributes\":{\"id\":\"b1\"},\"end\":40139,\"start\":39798},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":14789328},\"end\":40496,\"start\":40141},{\"attributes\":{\"id\":\"b3\"},\"end\":40702,\"start\":40498},{\"attributes\":{\"id\":\"b4\"},\"end\":41139,\"start\":40704},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":199466391},\"end\":41590,\"start\":41141},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6485746},\"end\":41948,\"start\":41592},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":40176582},\"end\":42426,\"start\":41950},{\"attributes\":{\"id\":\"b8\"},\"end\":42769,\"start\":42428},{\"attributes\":{\"id\":\"b9\"},\"end\":42997,\"start\":42771},{\"attributes\":{\"id\":\"b10\"},\"end\":43238,\"start\":42999},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":150352},\"end\":43545,\"start\":43240}]", "bib_title": "[{\"end\":39509,\"start\":39443},{\"end\":40217,\"start\":40141},{\"end\":40759,\"start\":40704},{\"end\":41185,\"start\":41141},{\"end\":41664,\"start\":41592},{\"end\":42042,\"start\":41950},{\"end\":43293,\"start\":43240}]", "bib_author": "[{\"end\":39536,\"start\":39511},{\"end\":39549,\"start\":39536},{\"end\":39898,\"start\":39871},{\"end\":39911,\"start\":39898},{\"end\":40226,\"start\":40219},{\"end\":40572,\"start\":40557},{\"end\":40586,\"start\":40572},{\"end\":40775,\"start\":40761},{\"end\":41203,\"start\":41187},{\"end\":41213,\"start\":41203},{\"end\":41220,\"start\":41213},{\"end\":41676,\"start\":41666},{\"end\":42057,\"start\":42044},{\"end\":42504,\"start\":42489},{\"end\":42787,\"start\":42771},{\"end\":43043,\"start\":43034},{\"end\":43305,\"start\":43295},{\"end\":43318,\"start\":43305}]", "bib_venue": "[{\"end\":39596,\"start\":39549},{\"end\":39869,\"start\":39798},{\"end\":40236,\"start\":40226},{\"end\":40555,\"start\":40498},{\"end\":40891,\"start\":40775},{\"end\":41301,\"start\":41220},{\"end\":41700,\"start\":41676},{\"end\":42067,\"start\":42057},{\"end\":42487,\"start\":42428},{\"end\":42824,\"start\":42787},{\"end\":43032,\"start\":42999},{\"end\":43367,\"start\":43318},{\"end\":41369,\"start\":41303}]"}}}, "year": 2023, "month": 12, "day": 17}