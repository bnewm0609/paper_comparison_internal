{"id": 251623128, "updated": "2023-12-01 22:46:10.97", "metadata": {"title": "AUGER: Automatically Generating Review Comments with Pre-training Models", "authors": "[{\"first\":\"Lingwei\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Li\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Huaxi\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Jun\",\"last\":\"Yan\",\"middle\":[]},{\"first\":\"Tiejian\",\"last\":\"Luo\",\"middle\":[]},{\"first\":\"Zihan\",\"last\":\"Hua\",\"middle\":[]},{\"first\":\"Geng\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Chun\",\"last\":\"Zuo\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Code review is one of the best practices as a powerful safeguard for software quality. In practice, senior or highly skilled reviewers inspect source code and provide constructive comments, considering what authors may ignore, for example, some special cases. The collaborative validation between contributors results in code being highly qualified and less chance of bugs. However, since personal knowledge is limited and varies, the efficiency and effectiveness of code review practice are worthy of further improvement. In fact, it still takes a colossal and time-consuming effort to deliver useful review comments. This paper explores a synergy of multiple practical review comments to enhance code review and proposes AUGER (AUtomatically GEnerating Review comments): a review comments generator with pre-training models. We first collect empirical review data from 11 notable Java projects and construct a dataset of 10,882 code changes. By leveraging Text-to-Text Transfer Transformer (T5) models, the framework synthesizes valuable knowledge in the training stage and effectively outperforms baselines by 37.38% in ROUGE-L. 29% of our automatic review comments are considered useful according to prior studies. The inference generates just in 20 seconds and is also open to training further. Moreover, the performance also gets improved when thoroughly analyzed in case study.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigsoft/LiYJYLHLZ22", "doi": "10.1145/3540250.3549099"}}, "content": {"source": {"pdf_hash": "c60d9c2e7d87345ff1d9483e47ec4060e56eedd5", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2208.08014v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "64525fb17bfef44f58a8f8cf8ff8a0f29ba89755", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c60d9c2e7d87345ff1d9483e47ec4060e56eedd5.txt", "contents": "\nAUGER: Automatically Generating Review Comments with Pre-training Models CCS CONCEPTS \u2022 Software and its engineering \u2192 Software creation and man- agement; \u2022 Computing methodologies \u2192 Machine learning. KEYWORDS Review Comments, Code Review, Text Generation, Machine Learn- ing ACM Reference Format\n\n\nLingwei Li lilingwei20@mails.ucas.ac.cn \nLi Yang \nHuaxi Jiang jianghuaxi19@mails.ucas.ac.cn \nJun Yan yanjun@ios.ac.cn \nTiejian Luo tjluo@ucas.ac.cn \nZihan Hua \nGeng Liang lianggeng@iscas.ac.cn \nChun Zuo zuochun@sinosoft.com.cn \nLingwei Li \nLi Yang \nHuaxi Jiang \nJun Yan \nTiejian Luo \nZihan Hua \nGeng Liang \nChun Zuo \n\nInstitute of Software\nInstitute of Software\nInstitute of Software, CAS, Univ. of Chinese Academy of Sciences\nInstitute of Software, CAS, Univ. of Chinese Academy of Sciences\nUniv. of Chinese Academy of Sciences\nState Key Laboratory of Computer Science\nCAS\nUniv. of Chinese Academy of Sciences\nCASBeijing, Beijing, Beijing, Beijing, BeijingChina, China, China, China, China\n\n\nUniv. of Chinese Academy of Sciences Wuhan\nInstitute of Software\nWuhan University\nCASBeijingChina, China\n\n\nSinosoft Company Limited\nBeijingChina\n\nAUGER: Automatically Generating Review Comments with Pre-training Models CCS CONCEPTS \u2022 Software and its engineering \u2192 Software creation and man- agement; \u2022 Computing methodologies \u2192 Machine learning. KEYWORDS Review Comments, Code Review, Text Generation, Machine Learn- ing ACM Reference Format\n10.1145/3540250.354909929% of our automatic review comments are considered useful according to prior studies. The inference generates just in 20 seconds and is also open to training further. Moreover, the performance also gets improved when thoroughly analyzed in case study. * Corresponding author Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). ESEC/FSE '22, November 14-18, 2022, Singapore, Singapore. 2022. AUGER: Automatically Generating Review Comments with Pre-training Models. In Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Founda-tions of Software Engineering (ESEC/FSE '22), November 14-18, 2022, Singa-pore, Singapore. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/ 3540250.3549099\nCode review is one of the best practices as a powerful safeguard for software quality. In practice, senior or highly skilled reviewers inspect source code and provide constructive comments, considering what authors may ignore, for example, some special cases. The collaborative validation between contributors results in code being highly qualified and less chance of bugs. However, since personal knowledge is limited and varies, the efficiency and effectiveness of code review practice are worthy of further improvement. In fact, it still takes a colossal and time-consuming effort to deliver useful review comments. This paper explores a synergy of multiple practical review comments to enhance code review and proposes AUGER (AUtomatically GEnerating Review comments): a review comments generator with pre-training models. We first collect empirical review data from 11 notable Java projects and construct a dataset of 10,882 code changes. By leveraging Text-to-Text Transfer Transformer (T5) models, the framework synthesizes valuable knowledge in the training stage and effectively outperforms baselines by 37.38% in ROUGE-L.\n\nINTRODUCTION\n\nModern code review is considered effective in reducing programming defects and improving the quality of software in early phase of development [2,37,52]. Therefore, it is widely adopted nowadays in both open source and industry workflows [3]. Reviewers need to thoroughly understand the source code during code review activities and leave review comments to interact with developers. Figure  1.a shows an example of the review process. (A) First, developers create a pull request to submit code changes. (B) Then, reviewers receive the request and inspect the involved programming files. (C) Once they fully judge and disagree with some lines, (D) reviewers will leave messages and set up a conversation right behind them as in-line review comments. In summary, the assignment of reviewers is to double-check code changes, highlight review lines (bold font) and deliver useful review comments (Figure 1.b).\n\nThe nature of this cross-validation brings high quality to software [13]. For reviewers, they provide professional suggestions \n\n\nCode Changes:\n\nIt seems all implements return true. What's the scenario this has to return false?\n\nReview Comments: a.\n\nb. with their programming experience, which the author may not have been through [44]-for example, a convenient coding style, a particular test case, or a complicated application scenario. For authors, they can learn from perspectives other than themselves and have a higher chance to perform efficiently [4]. However, two factors limit the benefits:\n\n1) The usefulness of existing review comments remains uncertain. Czerwonka et al. found that only 15% of review comments indicate a possible defect [14], and Bosu et al. reported that 34.50% of review comments from five major projects of Microsoft are nonuseful [8]. Studies also proposed that low-quality review comments are considered useless and somehow mislead developers [3,38]. Even so, it seems still inevitable in practice. On the one hand, both authors' and reviewers' programming knowledge is still limited since they can't think over all possible conditions. On the other hand, it is difficult to assign review requests to correct reviewers due to that limitation [58]. The assessment of useful review comments is controversial, too. Studies have argued that useful review comments can successfully identify functional issues or reflect other motivations, such as the social benefits of developers [2,8]. However, research by Rahman et al. reported that review comments could be defined as useful only if they trigger code changes within ten lines after reviewing [44].\n\n2) The heavy involvement of human effort is annoying and timeconsuming. Researchers argued that code review might be the lengthiest part of the development [14,37]. Reviewers have to change work context unwillingly and fully understand a source code from others before commenting. For authors, they can't move forward until reviewers send their review comments back [14]. Both of them are highly time-consuming in practice [3]. On average, it costs developers 6 hours per week to handle code review issues [7]. Furthermore, due to the low efficiency, more contributors are assigned to the review process. Around 20% developers at Mozilla, a free software community, face heavy workloads, i.e., over ten patches/reviews per week beyond their own jobs [31]. In Microsoft Bing, industrial projects can undergo approximately 3,000 code reviews per month [45]. In addition, developers have to spend an extra effort to work as reviewers every time they participate in an unfamiliar project.\n\nPrior studies have made attempts to solve these two issues of review comments. Balachandran proposed Review-Bot, which integrates the output of multiple static analysis tools to publish review comments automatically [3]. Rahman et al. reported that their RevHelper could directly predict whether review comments are useful or not [44]. Though competitive, they work as an indirect integration and validation, not for the review itself. Tufano et al. 's latest study focused on automated code review with automatic code revision and implemented comments generation as a sub-task, too [57]. However, their method remains coarse-grained and only aimed at finding defects in code functions, not review lines.\n\nIn this paper, we explore an unlimited and efficient code reviewer and propose a novel approach, called AUGER, to generate review comments automatically with continuous training at the first step. We leverage pre-training models to synthesize effective manual review comments, thanks to its proven efficiency for big data in Natural Language Processing. From 11 influential open-source Java projects in GitHub 1 (the largest source code host [67]), we first collect those review pairs of code changes and review comments in 20K pull requests, which causes code revision. And then, we process data with heuristic methods and semantic augmentation in Data Preparation. With around 62K pieces of processed data, AUGER addresses the problem into three sub-processes: 1) Review Lines Tagging finds and highlights review lines that get revised after reviewing in code blocks with a unique leading review tag; 2) Cross Pre-training learns the inner correlations between code changes and review comments language with a masked language model from Text-To-Text Transfer Transformer (T5); 3) Comments Generation fine-tunes the pre-trained model further with selected pairs and finally transfers code changes in the programming language to review comments in natural language. Our experiment results show that AUGER achieves 22.97% in ROUGE-L and 4.32% in Perfect Prediction, which outperforms baseline by 37.38% and even 14 times. For efficiency, AUGER generates one piece of review comments as fast as 20 seconds. We also implement subsequent training and illustrate that AUGER can retrain freely in ablation. Moreover, we assess the usefulness of generated review comments with heuristic metrics from prior studies and present case study. We believe that AUGER has achieved our primary goal and is open to improvement in the future. The significant contributions of our paper are:\n\n\u2022 We first formulate an issue of code review as a problem that generating review comments on manual-labelled problematic lines in code functions. To the best of our knowledge, this is the first study exploring an interactive automation by sharpening code changes.\n\n\u2022 To solve the problem, we propose AUGER, an synthetic and efficient generator to generate review comments automatically with instructive review tags, limitless training and immediate generation. \u2022 We evaluate AUGER on 1,088 test data from code review practice in GitHub, and it performs effectively in both automatic evaluation and heuristic assessment.\n\nThe rest of this paper is introduced as follows. Section 2 describes the background and definition of the problem. Section 3 illustrates the detailed approach. Section 4 presents the experiments. Section 5 shows the evaluation of AUGER. Section 6 introduces the related work. Section 7 illustrates threats to validity. Section 8 makes a conclusion.\n\nThe AUGER 2 model and all experimental materials are publicly available to reproduce our results.\n\n\nBACKGROUND\n\nThis section introduces the necessary background and the problem definition.\n\n\nReview Documents\n\nModern code review is usually adopted in grand projects consisting of numerous documents [3,37]. To simplify the illustration, we present involved review documents as several equations:\n= { 1 , 2 , ..., }, _ = { 1 , 2 , ..., } \u2208 , _ = { 1 , 2 , ..., } \u2208 ,(1)\nThe Equation 1 represents the main materials employed during the course. As mentioned above, code review will not commence until a submission of code changes. Hence, given a universal of all documents , we define these submitted code changes as _ . After reviewing, versions of the code that submitters may revise is defined as _ . and denotes code blocks divided by abstract syntax tree (AST) in these two texts, respectively.\n\n\nReview Process\n\nWhen review requests trigger, reviewers are assigned to inspect, analyze, and produce review comments in chronological order [45]. We describe the process with the following symbols:\n= { \u00ec 1 , \u00ec 2 , ..., \u00ec }, \u00ec =< , , , \u00ec >(2)\nThe series of processes is defined as a set in Equation 2. Each element denotes one single reviewers' manipulation at that moment. For each , the inspector notices a code block with possible issues in provided code changes, selects incorrect lines with a click, and leaves review comments . To present it better, we abstract the click operation as a special leading tag to distinguish those highlighted lines in the text. Besides, the system records relevant messages \u00ec such as timestamp and developer id for each submission.\n\n2 https://gitlab.com/ai-for-se-public-data/auger-fse-2022\n\n\nAutomatic Generation\n\nThe automatic generation task is to automate the review process based on materials defined in the above sections. Thus, we formulate our key idea with two equations:\n\u00ec =< _ , >, :< , >\u2192(3)\nIn Equation 3, code review practice is first summarized as a combination of complete submitted code changes _ and reviewers' operation from Equation 1 and Equation 2. The automatic process is defined as: a text generation function from code blocks and review line tags combination < , >, mapping to an output of generated review comments , like the manual one . In other words, the motivation of AUGER is to act as an effective automatic substitution for the human process . Given a universe of documents = { 1 , 2 , ..., } fetched from GitHub projects, Data Preparation selects and pre-processes the review code _ = { 1 , 2 , ..., } and review comments . Review Lines Tagging highlights review lines with special tags where revision will commence, according to _ . Cross Pretraining part learns the inner distribution of review text first, and then Comments Generation transfers the combination (code blocks _ with leading review tags ) into review comments automatically. After fully pre-training and fine-tuning, AUGER can be applied to generate automatic review comments from new code changes _ and manual tags in Application.\n\n\nAPPROACH 3.1 Overview\n\n\nData Preparation\n\n1) Data Fetching: When fetching data from GitHub, we mainly follow the instruction of GitHub GraphQL API 3 . To ensure the effectiveness of review data with experienced review comments, we exactly fetch those review activities that indeed trigger code revisions [8]. Besides, we remove those reviews not for Java code. After eliminating invalid and repetitive data, triplets < _ , _ , > are ready for further process. Figure 3 exhibits an example of Data Preparation: a pair of code changes and review comments input. For code text, we first remove source comments and then implement several processes such as splitting. Almost a same process is reimplemented for comments but an extra data augmentation afterwards.\n\n2) Data Processing: We first check duplicates again to ensure that there is no in-train/in-test/cross-set duplicates causing data inflation [1]. Then we remove nearly 85%(67672) data consisting of two parts: 1) 40.77%(32348) reviews where code revision or review comments include content beyond functions. In terms of functionrelated review activities, they are out-of-range and thus considered noisy. 2) 44.52%(35324) \"<sub_code, comments>\" pairs where code   functions or review comments are shorter than three words or longer than 128. Some of them are considered noise, such as incomplete functions and useless replies like \"fixed\". Besides, big functions are considered smelly [5] and too long for ML models, along with lengthy comments that include code blocks not in natural language. The rest 15%(11672) are regarded as raw data and ready for next process.\n\nThen we convert all text into lowercase, split words and punctuation, and implement word lemmatization using NLTK 4 toolkit (\"seems\" to \"seem\", \"is\" to \"be\" in Figure 3). Then we process code and comments further so that models can quickly learn later.\n\nFor code text, we first totally remove source code comments with a heuristic filter. We preserve every punctuation except \". \" owing to its representation of structure knowledge. In Java, functions and variables are usually named within long and compound words. In this case, we split them into fine-grained sub-words with the help 4 https://nltk.org/ of WordNinja 5 . For example, from \"HavingDefaultValue\" to \"having default value\" in Figure 3.\n\nFor comments, we erase all signs such as \"@\" in natural language. Then acronyms are replaced by their full names referring to Oxford Dictionary 6 (\"What's\" to \"What is\" in Figure 3). After that, We remove all punctuation to preserve semantic words. The process of code fragments in comments is as same as in code text. Last, we select the first 3 sentences when review comments are too long.\n\n3) Data Augmentation: This process is widely applied to handle the lack of training data in NLP [15,28,43]. Though we have fetched enough raw data, the amount decreases sharply after being filtered. Besides, studies reported that data augmentation is able to expand the influence of core knowledge in the training [15]. Hence, we boost triplets < _ , _ , > by 9 times with only increasing review comments using Wei et al. [62].\n\n\nReview Lines Tagging\n\nReviewers actually conduct reviewing on specific code lines. In practice, they highlight review lines first and then make review comments right after them. To be aligned with the fact, we synthesize this fine-grained review knowledge and reprocess the prepared code text to find out those review lines with a review tag . Since we are only concerned about those code blocks indeed get revised afterward, this component is designed to remove irrelevant code blocks, too.\n\n1) Review Lines Locating: In our implementation, we add a special token <review_tag> to the front of review lines. As shown in Equation 4, after receiving code text from Data Preparation, we first compare original code changes _ = { 1 , 2 , ..., } and its revision _ = { 1 , 2 , ..., } to find out different lines . Then we only select valid modifications with a series of line changes. Subsequently, we set <review_tag> at the beginning of it to mark where revision happened. This process follows the practice that developers leave review comments on chosen lines for collaborators easy to understand. Although knowing where to comment is also a problem, it takes as fast as one inference when generating several comments in a batch. Hence, people can select all code lines they want and choose which results to learn or improve. What's more, if review tags are predicted automatically, an additional error is brought to the overall performance.\n= { | \u2208 _ }, = { , +1 , ..., + }, \u2208(4)\n2) Functions Extractor: Studies have demonstrated that noise in input data can badly mislead the performance of language models [16,30]. For safety, functions extractor is a tool to narrow the code range down to the least block . First, we employ javalang 7 to fomulate code files into abstract syntax trees (AST). In AST, the structure of code is arranged in a hierarchy instead of a inclusion. For example, a root node is at the top, while other functions, judgments, and statements follow it. Similar to prior works [36,58], we extract code at the function height and select the one including target <review_tag>.\n\n\nCross Pre-training\n\nRecent studies confirm that the masked language approach in pretraining can facilitate the performance of models in many NLP tasks [15,61]. Therefore, we synthesize review knowledge by pre-training a better contextual representation and bridging the relationship between code and comments with cross pre-training technique. 1) Tokenization: We pair processed comments (from Data Preparation) and functions (from Review Lines Tagging) into < , >. As pre-training usually comes into effect with numerous inputs, we also integrate raw data from Data Preparation to increase < , > directly. Then a T5-base tokenizer is employed to tokenize each of the text pairs (including <review_tag>) in one sentence. According to what BERT has proven effective in token masking [15], we randomly select 10% words to mask.\n\n2) Mask Language Model: In this part, we build a T5-java-based Masked Language Model to do language masking for pre-training. 7 https://github.com/c2nes/javalang/ So far, there has been a lot of varieties of T5 models [34]. We choose a version of CodeTrans [17] already trained on Java documents (from Hugging Face 8 ). First, it works as a cross encoder by encoding both code and comment tokens in one sequence. For <review_tag>, we increase the embedding size by 1 to present it as a special token. Following the generation of T5, we write a prefix here as: \"Generating review comments:\" for all input data. Then we set a mask predicting layer to capture hidden states and output prediction vectors. Then, the softmax layer smooths it into probabilities \u00ec \u03a6:\n\u00ec \u03a6 =< 1 , 2 , ..., | | >, 0 \u2264 1 , 2 , ..., | | \u2264 1 = \u2212 1 | | | | \u2211\ufe01 =1 | | \u2211\ufe01 =1 ( )(6)\nA Cross-entropy Loss is applied to measure the difference between the prediction and the truth. Equation 6 accumulates products of each predicting probability logarithm and golden label (in vocabulary for all masked tokens ), and the purpose of Cross Pre-training process is to reduce the loss.\n\n\nComments Generation\n\nIn Comments Generation, we collect outputs from Data Preparation, Review Lines Tagging, and Cross Pre-training, and then transfer them into review comments products.\n\n1) Text Encoder: Now we successfully have code blocks with review tags review_tag and a pre-trained model. Again, we use the tokenizer of T5 [43] to embed all text, including review_tag and the prefix. The T5 tokenizer encodes all text into 768-dimensional vectors and adds an special end token </s>.\n\n2) Transfer Learning: After fully pre-trained in Cross Pre-training, we further fine-tune the T5 cross encoder on text generation. Such generation is also known as transfer learning, where models trained on a dataset at a large scale are employed to solve a specific task [43,68]:\n( ) = { ( | )| \u2208 , = 1, 2, ..., | |}, ( ) = { ( | )| \u2208 , = 1, 2, ..., | |}(7)\nIn Equation 7, denotes the predicted conditional distributions the model output for the task in domain .\n\nis a domain observation in feature space , while is defined as a specific truth label in . The purpose of transfer learning is to utilize the knowledge in to improve effect on task in domain . In this task, the ground truth here is the real comments from reviewers, which gets prepared in the first step.\n\nNext, the loss function of comments generation is defined as: \n= \u2212 1 | | | | \u2211\ufe01 =1 | | \u2211\ufe01 =1 ( )(8)\nSimilar to the pre-training one, Equation 8 accumulates the difference between each predicting probability and golden label for all generated sentences . And for each sentence, the inference will finish at the prediction of the stop token or the max length.\n\n\nApplication\n\nThe Application is straightforward. We mainly leverage a fully trained model from Comments Generation as a synergy. When new code comes in modern code review, reviewers can freely select review lines first. After being tagged, this coded text is fed into the generation model and transferred into outputs. Finally, the generated comments are integrated into automatic review comments and returned to developers.\n\n\nEXPERIMENTAL DESIGN 4.1 Research Questions\n\nAccording to our research purpose, the evaluation aims at answering the following research questions:\n\n\u2022 RQ1: How effectively does AUGER perform to generate review comments automatically, after synthetic training? \u2022 RQ2: What is the contribution of sub-component designs to the overall performance in AUGER? \u2022 RQ3: To what extent is the usefulness of comments AUGER generated, compared with manual ones?\n\nWe will specifically discuss research questions in Section 5 with the evaluation of AUGER.\n\n\nData Source\n\nTo make sure the quality of the dataset, we select 11 notable Java repositories from GitHub in top 60 stars: Graal 9 , Dubbo 10 , Netty 11 9 https://github.com/oracle/graal/ 10 https://github.com/apache/dubbo/ 11 https://github.com/netty/netty/ , Apollo 12 , Flink 13 , Kafka 14 , Skywalking 15 , Redisson 16 , Bazel 17 , Jenkins 18 , ElasticSearch 19 . What's more, these projects have at least 4,000 pull requests and 100 contributors. The detail of each repository is listed in Table 1. PRs(all) denotes the number of pull requests successfully got from repositories, PRs(suc) denotes the number of pull requests that contain code review comments, and Reviews(suc) denotes valid review nodes in Java.\n\n\nBaselines\n\nTo better answer RQ1, we compare the performance of AUGER with some state-of-the-art baselines. Since we formulate the task as a text generation, we choose three methods that have been proven capable to handle text generation and a latest study of code review [9]:\n\n\u2022 LSTM (Long Short-Term Memory) is a classic type of neural network to store information over extended time intervals [24]. Its novel gate units lessen error backflow sharply and achieves a significant performance on natural language generation [9]. \u2022 COPYNET addresses text generation into \"sequence to sequence\" learning with copying mechanism, which replicates input segments selectively to outputs [19]. \u2022 CodeBERT is a pre-training model proposed by Microsoft, which can effectively solve many downstream tasks in programming language [20]. \u2022 Recently, Tufano et al. made a study on code review automation and introduced a variant of T5 model to handle automatic code revision [57]. The model here we employed is their code-to-comment version.\n\n\nMetrics\n\nWe use the ROUGE metric and Perfect Prediction rate to evaluate AUGER and its baselines. The ROUGE metric is widely used in Machine Translation evaluation [33]. We employ ROUGE-1 and ROUGE-L score, which measure the overlap of words and the longest sequence between hypothesis and reference. Specifically, ROUGE-1 has precision, recall, and F1-score scores on word level. Precision measures the ratio of the correct number in prediction to the amount, recall measures the ratio of the correct number in inference to all samples in truth, and F1-score is a harmonic mean of Precision and Recall. Finally, Perfect Prediction is the rate of forecasts completely the same as ideal ones.\n\n\nExperiment Settings\n\nThis section introduces the main parameters we set in all experiments.\n\n1) Data Partition. After data processing, we preserve those review comments from 3 to 128 length. Same as code text. Then we split 2) Pre-training Model. We employed a base T5 model fine-tuned on Java Code Documentation Generation Multitasks [17], and the model was trained in 60,000 steps and evaluated at every 6,000 step in pre-training. Some key hyperparameters are listed in Table 2.\n\n3) Generation Model. Likewise, we selected the same T5 model to do the generation, and the model was trained in 28,000 steps and evaluated at every 2,000 step in fine-tuning. Table 2 presents some key hyperparameters we set. 4) Experiment Environment. We implemented all training with NVIDIA GeForce RTX 3090 GPU and CUDA 11.4 20 , and it cost 12 hours and 5 hours to pre-train and fine-tunes AUGER, respectively. 5) Implementation of baselines. We leveraged LSTM and Copy-Net built by AllenNLP 21 . The CodeBERT model comes from Hugging Face 22 and the code-to-comment T5 variant comes from the repository of Tufano et al. [57].\n\n\nEVALUATION 5.1 RQ1: Performance of generating comments\n\nThe results in Figure 4 show that AUGER outperforms baselines in every situation. We mainly focus on the Top-10 scores on every metric since they are theoretically the best for 1 to 10. In Top-10, AUGER achieves 22.97%, 4.32%, 26.11%, 27.07%, 25.28% on ROUGE-L, Perfect Prediction, Precision, Recall, and F1-score, and outperforms the best baseline by 37.38%, 14 times, 21.33%, 54.51%, and 38.22%, respectively. It indicates that our approach can generate review comments more precisely than baseline when fully trained, whether in a long statement or word similarity. In other cases shown in Figure  4, AUGER also achieves apparent outperformance from 11.95% up to tens of times as well.\n\nWe thoroughly analyze the results and explain the advantage of AUGER from two perspectives: 1) AUGER performs effectively on knowledge synthesis and text generation thanks to the advanced pre-training and transfer learning techniques. They provide a chance to learn knowledge from data at a large scale, whatever the language is. In that case, T5 is one of the most outstanding models. It outperforms traditional deep learning models like LSTM, CopyNET, BERT on multi-tasks besides code-to-comment generation. 2) Especially, we address review comments generation into a fine-grained task compared with prior works, which inputs highlighted lines led by a review tag within code blocks, not functions themselves. Thus, Review Lines Tagging helps AUGER make pertinent review comments related to key code lines. The benefit will be proven in ablation (Section 5.2), too.\n\nIn addition, it is worth noting that the Perfect Prediction rate of all methods is low. There are two likely causes: 1) Perfect Prediction is indeed a strict metric that requires complete equality between inference and ground truth; 2) methods have limitations on solving this task. LSTM and CopyNET directly implement training on both programming and natural language, which, according to their output, mainly captures the semantics in comments. CodeBERT and Tufano et al. pre-train themselves on various data, including other programming or code-to-code language, which brings uncontrollable noise to their performance on this task. What's more, Tufano et al. trained their T5 without review tags, and it may mislead the model to irrelevant lines. Still, it struggles due to their defectoriented dataset construction, too. LSTM and CopyNET perform worse for that k bigger than 3. It is mainly caused by the overfitting they suffer from when handling text in different languages.\n\nFor efficiency, AUGER automatically generates one piece of review comments in 20 seconds on average. Compared with manual ones made in minutes and hours, AUGER highly alleviates the burden of review process, i.e., inspecting, analyzing and commenting. What's more, AUGER works as a non-resting reviewer with immediate feedback, from which developers can receive review comments just in time. It effectively saves both developers and reviewers time of waiting due to the discrepancy of assignment.\n\nWe also present an example in Figure 5 for intuitive comparison. An instance of review code changes to input and review comments from all baselines are listed in Figure 5. The original code changes declare a protected function \"close()\" and the reviewer highlights a code line that monitors a statement \"transformation-Chain.close()\" and logs a warning message whenever the statement fails. Data Preparation and Review Lines Tagging will process the code into a code sentence as input. The second line shows that human reviewers find defects that the operation in the statement is \"Transformation.close()\" instead of \"Transformation.stop\" and make comments to point it out. Taking it as a reference, we compare each auto-output of machine techniques. AUGER performs the best and successfully find the defect by generating comments as same as a human. Comments from Tufano et al. and CodeBERT are in review language but confused. Although CopyNET and LSTM capture the defect on review lines, the outputs are ambiguous and useless opinions for submitters.\n\nAnswering RQ1: AUGER is capable to synthesize review knowledge and outperforms all baselines on five metrics when generating review comments automatically.\n\n\nRQ2: Ablation experiment\n\nIn the ablation experiment, we first compare AUGER with two fundamental T5 versions widely used in research. These two models \n\n\nReviewers' Comments\n\nNit: the method is Transformation.close(), not \"stop\". The log message should probably reflect that.   results on the upper half of Table 3. These two models are the initial version that are fine-tuned with review tags and processes like word cut, rather than the one Tufano et al. trained with their raw data. The outperformance proved that AUGER could solve the problem more thoroughly than a simple fine-tuning on T5 models (-4.18% and -2.44%). We further remove Review Lines Tagging and Cross Pre-training parts, and the results are shown on the lower half (AUGER -<review_tag>, AUGER -pretraining). Similarly, both removals cause a decline in AUGER's performance (-6.53% and -0.26%).\n\nTo illustrate the unlimited synergy better, we warm boost AUGER at the half of training data and implement subsequent training for the rest. The result in the test (AUGER* in Table 3) shows nearly no efficiency loss and even an increase of ROUGE-L compared with the original one (AUGER). We believe the reason is that all data is randomized and more text related to the test occurs earlier in training steps. However, the overall performance remains stable and indicates that AUGER has the ability of training its synergy further. The results illustrate that each component is contributive to the overall performance. The reasons are as follows: 1) As mentioned in Section 5.1, Review Lines Tagging narrows the scope down to highlighted review lines instead of a complete code file or function and saves models from deviated comprehension. 2) Cross Pre-training thoroughly trains the model with multiple steps and guides it to build the relationship between two different modalities, i.e., programming language and natural language. The improvement of these two modules is essential for AUGER. Notably, the warm boosting of AUGER (AUGER*) performs similarly, even better than AUGER. It indicates that AUGER is capable of working as an unlimited reviewer with subsequent training steps. As mentioned in Section 1, the scalability breaks the limitation of practical code review and sharply reduces the manual effort to grasp unfamiliar programming knowledge.\n\nAnswering RQ2: In the framework of AUGER, every component counts for the overall achievement and supports AUGER to train further.\n\n\nRQ3: The Assessment of Usefulness\n\nSubsections 5.1 and 5.2 demonstrate the ability of AUGER to handle the issues of code review practice being restricted and timeconsuming. Furthermore, to ensure the effectiveness of AUGER, we sample 100 (1%) of the best (not perfect) inference in the test and evaluate the usefulness. As mentioned in Section 1, AUGER is our first step and aimed at commenting as effectively as human reviewers. Hence, according to Rahman et al. [44], we mainly compare it with manual review comments considered useful, which, in other words, indeed trigger source code changes on the author's side after reviewing (described in Section 3.2). The consideration follows the definition of Rahman et al [44]. In that case, the effectiveness has been evaluated early in the last two subsections (5.1 and 5.2) on automatic metrics that calculate the similarity between the generation and ground truth.\n\nHowever, auto-metrics only calculate word similarity between products and ground truth, but no semantics. However, review comments should be understandable. We found that most products of traditional models, i.e., LSTM and CopyNet, are non-readable or suffer from repetition. They are far from use even though they are competitive in auto-metrics. AUGER aims to generate readable comments and make sense for code review, just like humans. Hence, though much difficult, we still compare the usefulness with manual ones, the only qualified reference.\n\nWe first employ the standard proposed by Baccheli et al. [2]. It reported that review comments are supposed to reflect ten of developers' motivations to drive code review. Some of them are for programming issues, while other motivations are for social benefits in several aspects. In that case, we analyze how effectively AUGER performs usefully to reflect them and present the result in Figure 6. The 100 samples successfully cover every aspect of valuable review comments as expected. The distribution is similar to Baccheli et al. of 570 actual data, too [2]: Finding Defects and Code Improvement are the most common reasons (60% and 46%) why developers drive code review, but other factors matter as well, such as Team Awareness of social benefits.\n\nNext, we implement a classification of samples into three types: useful, somewhat useful, non-useful. It refers to the empirical study of Bosu et al. [8], in which they list several assessments for each type. Compared with manual ones, we also classify the ground truth of these 100 samples in the same criterion. For AUGER, it generates comments 29% useful, 22% somewhat useful and 49% non-useful. For reviewers, they perform better: 45% useful, 17% somewhat useful, and 38% non-useful. It seems reviewers present more accurate review comments when inspecting code changes themselves and outperform AUGER by 55.17% for useful comments. However, it decreases to 28.95% when calculating the overprediction of non-useful review comments. Especially, the criterion was built on the analysis of manual hand-writings and overweight the diversity of comment language. For example, they assumed that review comments were somewhat useful whenever they started with a \"nitpick\". But, AUGER characterizes the word as a special feature in review comments text and generate it frequently. What's more, Bosu et al. judged those of social benefits non-useful such as the impressive building of developers. Still, Baccheli et al. argued that it is of great importance for team collaboration [2].\n\n\nCase Study\n\nIn this section, we conduct a case study to understand the effectiveness of AUGER to generate review comments better. We inspect the 100 samples in Section 5.3 and further analyze those not as perfect as humans when calculating Perfect Prediction. Among 96 static FileSystemKind ... { ... <review_tag> if (scheme.startsWith(\\\"s3\\\") || scheme.startsWith(\\\"emr\\\") || scheme.startsWith(\\\"oss\\\")) ... } \"Sounds good, I think hotfix will be better.\" \"why a comparator need to be reset?\" \"what do think about reset be\" \"Should this be debug level? Seems like this could be really spammy.\" \"can we just do this log to debug level\" \"Does UnusedStateRemover class need to be changed too?\" \"could you revert this change since it be unrelated to the change\" \"wrong\" review comments, we find 3 \"nearly perfect\" with only a different word. There are 4 \"wrong\" review comments delivering the same message as the manual one. We report them in Figure 8.\n\nIn Case No.1, reviewers judge the code change of \"if\" judgment practical and advise to raise a hotfix here instead of the merge request. Though not perfect, AUGER also reports a hotfix and successfully captures the critical variable \"schema\".\n\nIn Case No.2, reviewers propose a question about the meaning of the \"reset\" statement. Similarly, AUGER asks the author why to do \"reset\" here in another accent.\n\nIn Case No.3, reviewers point out that the \"log\" statement should be in a \"debug level\" since it's really \"spammy\". For AUGER, though not explaining the reason, it also reports the main issue and suggests setting the \"log\" to \"debug level\".\n\nIn Case No.4, reviewers think that the change of \"UnusedStateRemover\" is not necessary here. AUGER fails to point it out but still suggests removing the change on review lines similarly.\n\nIn conclusion, we totally scan the 100 review comments AUGER generates in the test and find 3 \"nearly perfect\" and 4 \"perfect in meaning\". In that case, we can estimate a latent improvement of AUGER's performance when fully analyzed.\n\nAnswering RQ3: Referring to two criteria of prior works, review comments generated by AUGER are nearly as useful as manual ones. It also reveals an underestimate for those \"wrong\" samples.\n\n\nRELATED WORK\n\nWe focus our discussion on (i) studies on modern code review, (ii) pre-training models, and (iii) approaches to generating source code comments.\n\nModern Code Review. Several studies tried to automate modern code review process due to its time-consuming nature [32,50]. Balachandran's method delivers comments automatically with the integration of multiple static analysis tools [3]. Gupta et al. proposed DeepCodeReviewer (DCR), which uses deep learning to learn review knowledge and predict an ideal one from a repository [21]. Shi et al. tried to predict the approval of the revised code and proposed DACE with the performance of 48% F1-score [49]. Moreover, Tufano et al. recommended code changes directly using their automatic models with the 30% perfect prediction on their dataset [58].\n\nAUGER, compared to the techniques discussed above, is able to generate review comments with given code changes and provide human-like support to modern code review.\n\nPre-training Models. Pre-training models have achieved remarkable success in natural language processing at present [6,25,41,46]. Devlin et al. introduced a simple but powerful model named BERT (Bidirectional Encoder Representations from Transformers) to outperform others on eleven NLP tasks with large margin. The model even surpassed human's performance in challenging areas [15]. Following it, models trained in two stages have sprang up, i.e., learning representations at pre-training and fine-tuning on downstream tasks, and they are open to subsequent training. For example, RoBERTa [35], XLNET [66], and GPT [10]. In addition, models pre-trained on software texts become popular, with the potential to solve tasks like bug reporting [12,48,54].\n\nOwing to the effectiveness of this pattern, recent studies work on exploring a framework for diverse unsupervised text data. It is also known as transfer learning in terms of implementation [27,29,42,47]. Raffel et al. formulated all text-based language problem as a text-to-text problem and proposed a T5 model at large scale [43]. The model is designed based on the transformer architecture open to complicated input with self-attention layers, instead of RNNs or CNNs [11,59]. By combining the knowledge from exploration with scale and new corpus, T5 characterized many tasks into text-totext and achieved state-of-the-art results on benchmarks, including summarization, question answering and text classification [43].\n\nSource Code Comments Generation. Studies on code comments and comprehension of programs can be traced back to 1980s [53,55,64]. During software maintenance, good comments are of great importance to program understanding since developers are able to learn the meaning of code at ease with the help of this descriptive language [56]. However, developers sometimes do not comment their code adequately due to extra efforts, lack of relevant knowledge or overlooking the importance of code comments [51]. Study reported that developers have to spend up to 59% time on these manual activities, which limits the efficiency of software development heavily [65].\n\nAutomatic generation of source code comments just started in the last decade. The early methods focused on information retrieval, such as VSM algorithms [22,23], clone detection [63], and LDA algorithms [40]. After that, with the prosperity of deep learning, Hu et al. [26] and Wan et al. [60] proposed their automatic models with deep neural networks. Recently, pre-training models including CodeBERT [18] and T5 [17] have been proved to outperform the state-of-the-art on comments generation.\n\nDistinct from code comments that describe source code function, review comments are professional knowledge to reflect inappropriate code lines. Hence they have different focuses. Besides, all information code comments have to capture is just from its source code text. However, it requires numerous practices to make useful review comments. We implement similar code-to-comments generation but different in terms of programming comprehension.\n\n\nTHREATS TO VALIDITY\n\nConstruct validity: We use the original review comments written by reviewers as ground truth, assuming that they cause code revision. However, these comments have no guarantee to make sense for code improvement. For example, developers change their code by themselves right after code review activities. Therefore, datasets may contain some suboptimal review comments and affect the evaluation because we measure Perfect Prediction rate that only considers words entirely equal to manual ones. To partially address the threat, we manually analyzed a sample of non-perfect predictions in case study, calculating the percentage of valuable ones from different references.\n\nInternal validity: A study shows that the impact of hyperparameters on T5 models remains unknown [43]. In that case, we fully explore prior works and follow them to set hyperparameters in our approach. We acknowledge that a few of other settings may cause better performance, which is also a part of our future study.\n\nExternal validity: Although the dataset features thousands of instances, we limited our experiments to Java projects. Hence, we do not claim the generalizability for other programming languages. However, we select the notable systems with high-quality code reviews to train our model. Future work will further explore whether AUGER can learn knowledge of projects in different programming languages.\n\n\nCONCLUSION\n\nSince code review practice suffers from the limitation of individual collaboration, this paper proposed a model named AUGER, to generate review comments with pre-training T5 models automatically. We first fetch 79,344 Java reviews in Github and heuristically clean 85.29% noisy data considered useless or irrelevant, such as regular replies. Then we build a framework leveraging Text-to-Text Transfer Transformers (T5) models to automatically integrate and generate review comments. The synergy captures the relationship between code and review language effectively and shows better performance than baselines and high efficiency to immediate feedback. The model is capable to train further and cover unfamiliar programs more freely than individuals. Several criteria from prior studies are also employed to assess the generation as useful human-like review comments to some extent.\n\nWe will further explore a language-agnostic implementation and a broad application to collaborate with professionals reviewing new systems in future work.\n\n\n.apache.skywalking.oap.server.core.analysis.metrics; ... public interface HavingDefaultValue { ... default boolean haveDefault() { return false; ...\n\nFigure 1 :\n1An Example of Code Review on GitHub\n\nFigure 2\n2presents the framework of AUGER, which has five abstract components: A. Data Preparation (3.2); B. Review Lines Tagging (3.3); C. Cross Pre-training (3.4); D. Comments Generation (3.5); E. Application (3.6).\n\n\n2. process (lowercase, acronym, emoji...): 3. data augmentation: it seem all implement return true what be the scenario this have to return false it appear all implement return true what be the scenario this have to return false this seem all implement return true what be the scenario it have to return false ....\n\nFigure 3 :\n3An Example of Data Preparation\n\n\n.close(30, TimeUnit.SECONDS); } catch (Throwable t) { log.warn(\"Could not stop producer\", t); } } try { transformationChain.close(); } catch (Throwable t) { log.warn(\"Could not stop transformation chain\", t); } } protect ... try { transformation chain close ( ) ; } catch ( throw able t ) { <review_tag> log warn ( could not stop transformation chain ' ' , t ) ... } Processed:\n\n\nAUGER the method be transformation close not stop the log message should probably reflect that Tufano et al. If we're going to stop the review, maybe we should change this to info? CodeBERT stop method be producer close not stop the log message should probably reflect that CopyNET i think this should be stop a log chain LSTM i think this be a bug\n\nFigure 5 :\n5an Example of AUGER are from Hugging Face 23 . We trained the common T5-base and the Java pre-trained T5-base model on our dataset and listed their 23 https://huggingface.co/\n\nFigure 6 :Figure 7 :\n67Motivation the Percentage of Useful Review Comments\n\n\"\nWrong\" Review Comments ? 1 \"i think this scheme should be a separate hot fix\" public ... { <review_tag> void reset(); long compare(BaseRow inputRow, int inputIndex, BaseRow currentRow, int currentIndex); ... } \"Wrong\" Review Comments ? 2 public void addRecords (...) { <review_tag> log.info(\\\"{} Added records into the buffered queue of partition {}, new queue size is ...) ... } \"Wrong\" Review Comments ? 3 private void deleteState(...) { <review_tag> ActionListener<Boolean> deleteModelStateListener = ActionListener.wrap( r -> ... } \"Wrong\" Review Comments ?\n\nFigure 8 :\n8Examples in Case Study\n\n\n/* Licensed to the Apache Software Foundation ... */ package org.apache.skywalking.oap.server.core.analysis.metrics; ... @XXX: It seems all implements return 'true'. What's the scenario this has to return 'false'? Many others are not having default value, such as heatmap, labelled value(percentile). org.apache.skywalking.oap.server.core.analysis.metrics; ... @XXX: It seems all implements return 'true'. What's the scenario this has to return 'false'? Code Comments package org apache sky walk oap server core analysis metrics; ... public interface have default value { default boolean have default ( ) { return false ; } default boolean is default value ( ) { return false ; } } 2. process (lowercase, split, lemmatize...): it seem all implement return true what be the scenario this have to return falseReview Comments \n\nfetching \n\nData \nAugmentation \n\nA. Data Preparation (3.2) \nB. Review Lines Tagging (3.3) \n\nReview Code Files \n\nRemove Comments \n\nReplace Delimiters \n\nCut Compound Words \n\nprocessing \n\n<review_tag> \n\nT5* \n\nPrefix \n\nGenerated \nComments \n\nReviewers' \n\nComments \n\ntransfer learning \n\ninput code \n\n... \n\nD. Comments Generation (3.5) \n\n... \n\n... \n... \n\n</s> \n\nT5*: Pre-trained T5 Cross Encoder , \n\nPrefix: \"Output review comments:\" \n\nPrefix \nCode \nReview Comments \n\nT5 Cross Encoder \n\nMask Predicting Layer \n\n... \n\nSoftmax \n\n... \n\n... \n\n, \n\n, \n\n, \n</s> \n... \n... \n\n768 \n\ninput \ntokens \n\nT5-java-based \nMasked Language Model \n\nT5-base Tokenizer \n\n, \n\n, \n\nToken Masking \n\nFunctions \n\ncomments \n\npublic ... { \n... \n<review_tag> \nreturn true \n... \n} \n\nit seems all \nimplements \nreturn true \nwhat is the \nscenario to \nfalse.... \n\npackage ... public < \n> \n{ ... return true ... } private ... \n\nit seems all implements \n<review_tag> return < \n> \nwhat is to false ... \n\nTokenization \n\npackage ... \n... \npublic ... { \n... \nreturn true \n... \n} \n\nReview Line Locating \n\npackage ... \n... \npublic .... \n\npackage ... \n... \npublic ... { \n... \n<review_tag> \nreturn true \n... \n} \n\nAST \n\n... \n\njavalang \n\npublic ... { \n... \n<review_tag> \nreturn true \n... \n} \n\nroot \n\nfunction \n\nreturn \n\njudgement \n\nrevised code \n\nlocated code \n\nFunctions Extractor \n\nC. Cross Pre-training (3.4) \n\nNew Review \nCode \n\nComments \nGeneration (D) \n\nAutomatic Review \nComments \n\nE.Application (3.6) \n\nReview \nLine Tags \n\nGenerated \nComments \n\n... ... \n\n< code, comments >s \n\ncomments \n\ncode \n\nfunctions \n\nfunctions \n\nmodel \n\nmodel \n\nWord Lemmatization \n\nRemove Acronym/Emoji \n\nRemove Replies \n\ncomments \n\ncode \n\nFigure 2: the Framework of AUGER \n\npublic interface HavingDefaultValue { \n/** @return true if the implementation has the definition of default value */ \ndefault boolean haveDefault() { \nreturn false; \n} \ndefault boolean isDefaultValue() { \nreturn false; \n} \n} \n\nReview 1: \n\nReview 2: \n\npackage public interface HavingDefaultValue { \ndefault boolean haveDefault() { \nreturn false; \n} \ndefault boolean isDefaultValue() { \nreturn false; \n} \n} \n\n1. remove comments: \n\n1. remove replies: \n\n\n\nTable 1 :\n1Data SourceRepository \nPRs(all) PRs(suc) Reviews(suc) \n\nGraal \n4,200 \n222 \n904 \nDubbo \n9,500 \n678 \n1,447 \nNetty \n12,000 \n1,365 \n4,938 \nApollo \n4,200 \n98 \n305 \nFlink \n18,200 \n4,759 \n23,274 \nKafka \n11,605 \n2,039 \n10,544 \nSkywalking \n8,350 \n611 \n1,985 \nRedisson \n4,100 \n49 \n82 \nBazel \n14,500 \n515 \n1,651 \nJenkins \n6,100 \n965 \n3,379 \nElasticSearch \n82,200 \n8,215 \n30,735 \n\nTotal \n174,955 19,516 \n79,344 \n\n\n\nTable 2 :\n2Training HyperparametersHyperparameter \nValue \n\nPre-training \nModel \n\nLearning rate \n1e-4 \nMax input length \n256 \nBatch size \n16 \n\nGeneration \nModel \n\nLearning rate \n1e-3 \nLength penalty \n1 \nMax input length \n128 \nMax output length \n128 \nBatch size \n32 \n\nour dataset into 80% training, 10% validation and 10% test, referring \nto Moreno-Torres et al. [39]. \n\n\nTable 3 :\n3the Ablation ResultsMethods \nROUGE-L Perfect Prediction \n\nT5 base \n22.01% \n3.95% \nT5 java \n22.41% \n4.14% \n\nAUGER -<review_tag> \n21.47% \n3.31% \nAUGER -pretraining \n22.91% \n3.95% \nAUGER* \n23.93% \n4.04% \nAUGER \n22.97% \n4.32% \n\n\nhttps://github.com/\nhttps://docs.github.com/en/graphql/\nhttps://github.com/keredson/wordninja/ 6 https://public.oed.com/how-to-use-the-oed/abbreviations/\n+ 2 + ... + | | = 1(5)1 , 2 , ..., | | respectively describes the possibility of the mask to be the first, the second, ..., the last word in the | | length vocabulary. Naturally, we choose the maximum as the prediction back to the model. The loss function in pre-training is defined as:\nhttps://huggingface.co/\nhttps://github.com/apolloconfig/apollo/\nhttps://developer.nvidia.com/cuda-toolkit/ 21 https://allenai.org/allennlp 22 https://huggingface.co/\nACKNOWLEDGMENTSWe sincerely appreciate the valuable feedback from the anonymous reviewers.\nThe adverse effects of code duplication in machine learning models of code. Miltiadis Allamanis, Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software. the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and SoftwareMiltiadis Allamanis. 2019. The adverse effects of code duplication in machine learning models of code. In Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software. 143-153.\n\nExpectations, outcomes, and challenges of modern code review. Alberto Bacchelli, Christian Bird, 10.1109/ICSE.2013.660661735th International Conference on Software Engineering (ICSE). Alberto Bacchelli and Christian Bird. 2013. Expectations, outcomes, and chal- lenges of modern code review. In 2013 35th International Conference on Software Engineering (ICSE). 712-721. https://doi.org/10.1109/ICSE.2013.6606617\n\nReducing human effort and improving quality in peer code reviews using automatic static analysis and reviewer recommendation. Vipin Balachandran, 10.1109/ICSE.2013.660664235th International Conference on Software Engineering (ICSE). 931-940. Vipin Balachandran. 2013. Reducing human effort and improving quality in peer code reviews using automatic static analysis and reviewer recommendation. In 2013 35th International Conference on Software Engineering (ICSE). 931-940. https://doi.org/10.1109/ICSE.2013.6606642\n\nFour eyes are better than two: On the impact of code reviews on software quality. Gabriele Bavota, Barbara Russo, 10.1109/ICSM.2015.73324542015 IEEE International Conference on Software Maintenance and Evolution (ICSME). Gabriele Bavota and Barbara Russo. 2015. Four eyes are better than two: On the impact of code reviews on software quality. In 2015 IEEE International Conference on Software Maintenance and Evolution (ICSME). 81-90. https://doi.org/10.1109/ ICSM.2015.7332454\n\nBad smells in code. Refactoring: Improving the design of existing code 1. Kent Beck, Martin Fowler, Grandma Beck, Kent Beck, Martin Fowler, and Grandma Beck. 1999. Bad smells in code. Refac- toring: Improving the design of existing code 1, 1999 (1999), 75-88.\n\nDomain adaptation with structural correspondence learning. John Blitzer, Ryan Mcdonald, Fernando Pereira, Proceedings of the 2006 conference on empirical methods in natural language processing. the 2006 conference on empirical methods in natural language processingJohn Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Proceedings of the 2006 conference on empirical methods in natural language processing. 120-128.\n\nImpact of peer code review on peer impression formation: A survey. Amiangshu Bosu, C Jeffrey, Carver, ACM/IEEE International Symposium on Empirical Software Engineering and Measurement. IEEEAmiangshu Bosu and Jeffrey C Carver. 2013. Impact of peer code review on peer impression formation: A survey. In 2013 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement. IEEE, 133-142.\n\nCharacteristics of Useful Code Reviews: An Empirical Study at Microsoft. Amiangshu Bosu, Michaela Greiler, Christian Bird, 10.1109/MSR.2015.212015 IEEE/ACM 12th Working Conference on Mining Software Repositories. Amiangshu Bosu, Michaela Greiler, and Christian Bird. 2015. Characteristics of Useful Code Reviews: An Empirical Study at Microsoft. In 2015 IEEE/ACM 12th Working Conference on Mining Software Repositories. 146-156. https://doi.org/10. 1109/MSR.2015.21\n\nA comprehensive survey on machine learning for networking: evolution, applications and research opportunities. Raouf Boutaba, A Mohammad, Noura Salahuddin, Sara Limam, Nashid Ayoubi, Felipe Shahriar, Oscar M Estrada-Solano, Caicedo, Journal of Internet Services and Applications. 9Raouf Boutaba, Mohammad A Salahuddin, Noura Limam, Sara Ayoubi, Nashid Shahriar, Felipe Estrada-Solano, and Oscar M Caicedo. 2018. A comprehensive survey on machine learning for networking: evolution, applications and research opportunities. Journal of Internet Services and Applications 9, 1 (2018), 1-99.\n\nLanguage models are few-shot learners. Benjamin Tom B Brown, Nick Mann, Melanie Ryder, Jared Subbiah, Prafulla Kaplan, Arvind Dhariwal, Pranav Neelakantan, Girish Shyam, Amanda Sastry, Askell, arXiv:2005.14165arXiv preprintTom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165 (2020).\n\nLong short-term memorynetworks for machine reading. Jianpeng Cheng, Li Dong, Mirella Lapata, arXiv:1601.06733arXiv preprintJianpeng Cheng, Li Dong, and Mirella Lapata. 2016. Long short-term memory- networks for machine reading. arXiv preprint arXiv:1601.06733 (2016).\n\nAgnieszka Ciborowska, Kostadin Damevski, arXiv:2112.14169Fast Changeset-based Bug Localization with BERT. arXiv preprintAgnieszka Ciborowska and Kostadin Damevski. 2021. Fast Changeset-based Bug Localization with BERT. arXiv preprint arXiv:2112.14169 (2021).\n\nCode Review is Just Reviewing Code? A Qualitative Study with Practitioners in Industry. Atac\u00edlio Cunha, Tayana Conte, Bruno Gadelha, 10.1145/3474624.3477063Association for Computing MachineryNew York, NY, USAAtac\u00edlio Cunha, Tayana Conte, and Bruno Gadelha. 2021. Code Review is Just Reviewing Code? A Qualitative Study with Practitioners in Industry. Association for Computing Machinery, New York, NY, USA, 269-274. https://doi.org/10. 1145/3474624.3477063\n\nCode Reviews Do Not Find Bugs. How the Current Code Review Best Practice Slows Us Down. Jacek Czerwonka, Michaela Greiler, Jack Tilford, 10.1109/ICSE.2015.1312015 IEEE/ACM 37th IEEE International Conference on Software Engineering. 2Jacek Czerwonka, Michaela Greiler, and Jack Tilford. 2015. Code Reviews Do Not Find Bugs. How the Current Code Review Best Practice Slows Us Down. In 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, Vol. 2. 27-28. https://doi.org/10.1109/ICSE.2015.131\n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805 (2018).\n\nSemantic Noise Matters for Neural Natural Language Generation. Ond\u0159ej Du\u0161ek, David M Howcroft, Verena Rieser, 10.18653/v1/W19-8652Proceedings of the 12th International Conference on Natural Language Generation. the 12th International Conference on Natural Language GenerationTokyo, JapanAssociation for Computational LinguisticsOnd\u0159ej Du\u0161ek, David M. Howcroft, and Verena Rieser. 2019. Semantic Noise Mat- ters for Neural Natural Language Generation. In Proceedings of the 12th Interna- tional Conference on Natural Language Generation. Association for Computational Linguistics, Tokyo, Japan, 421-426. https://doi.org/10.18653/v1/W19-8652\n\nCodeTrans: Towards Cracking the Language of Silicon's Code Through Self-Supervised Deep Learning and High Performance Computing. Ahmed Elnaggar, Wei Ding, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Silvia Severini, Florian Matthes, Burkhard Rost, arXiv:2104.02443arXiv preprintAhmed Elnaggar, Wei Ding, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Silvia Severini, Florian Matthes, and Burkhard Rost. 2021. CodeTrans: Towards Cracking the Language of Silicon's Code Through Self-Supervised Deep Learning and High Performance Computing. arXiv preprint arXiv:2104.02443 (2021).\n\nCodeBERT: A Pre-Trained Model for Programming and Natural Languages. Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, Ming Zhou, 10.18653/v1/2020.findings-emnlp.139Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online. Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. In Findings of the Association for Computational Linguistics: EMNLP 2020. Association for Computa- tional Linguistics, Online, 1536-1547. https://doi.org/10.18653/v1/2020.findings- emnlp.139\n\nIncorporating Copying Mechanism in Sequence-to-Sequence Learning. Jiatao Gu, Zhengdong Lu, Hang Li, O K Victor, Li, 10.18653/v1/P16-1154Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational Linguistics1Long Papers)Jiatao Gu, Zhengdong Lu, Hang Li, and Victor O.K. Li. 2016. Incorporating Copying Mechanism in Sequence-to-Sequence Learning. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Berlin, Germany, 1631-1640. https://doi.org/10.18653/v1/P16-1154\n\nDaya Guo, Shuai Shuo Ren, Zhangyin Lu, Duyu Feng, Shujie Tang, Long Liu, Nan Zhou, Alexey Duan, Shengyu Svyatkovskiy, Fu, arXiv:2009.08366Graphcodebert: Pre-training code representations with data flow. arXiv preprintDaya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, et al. 2020. Graphcodebert: Pre-training code representations with data flow. arXiv preprint arXiv:2009.08366 (2020).\n\nIntelligent code reviews using deep learning. Anshul Gupta, Neel Sundaresan, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'18) Deep Learning Day. the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'18) Deep Learning DayAnshul Gupta and Neel Sundaresan. 2018. Intelligent code reviews using deep learning. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'18) Deep Learning Day.\n\nSupporting program comprehension with source code summarization. Sonia Haiduc, Jairo Aponte, Andrian Marcus, 10.1145/1810295.18103352010 ACM/IEEE 32nd International Conference on Software Engineering. 2Sonia Haiduc, Jairo Aponte, and Andrian Marcus. 2010. Supporting program comprehension with source code summarization. In 2010 ACM/IEEE 32nd Inter- national Conference on Software Engineering, Vol. 2. 223-226. https://doi.org/10. 1145/1810295.1810335\n\nOn the Use of Automated Text Summarization Techniques for Summarizing Source Code. Sonia Haiduc, Jairo Aponte, Laura Moreno, Andrian Marcus, 10.1109/WCRE.2010.1317th Working Conference on Reverse Engineering. Sonia Haiduc, Jairo Aponte, Laura Moreno, and Andrian Marcus. 2010. On the Use of Automated Text Summarization Techniques for Summarizing Source Code. In 2010 17th Working Conference on Reverse Engineering. 35-44. https: //doi.org/10.1109/WCRE.2010.13\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780.\n\nUniversal language model fine-tuning for text classification. Jeremy Howard, Sebastian Ruder, arXiv:1801.06146arXiv preprintJeremy Howard and Sebastian Ruder. 2018. Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146 (2018).\n\nDeep Code Comment Generation. Xing Hu, Ge Li, Xin Xia, David Lo, Zhi Jin, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). Xing Hu, Ge Li, Xin Xia, David Lo, and Zhi Jin. 2018. Deep Code Comment Gener- ation. In 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). 200-20010.\n\nGpipe: Efficient training of giant neural networks using pipeline parallelism. Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, Hyoukjoong Lee, Jiquan Ngiam, V Quoc, Yonghui Le, Wu, Advances in neural information processing systems. 32Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al. 2019. Gpipe: Efficient training of giant neural networks using pipeline parallelism. Advances in neural information processing systems 32 (2019), 103-112.\n\nSpanbert: Improving pre-training by representing and predicting spans. Mandar Joshi, Danqi Chen, Yinhan Liu, S Daniel, Luke Weld, Omer Zettlemoyer, Levy, Transactions of the Association for Computational Linguistics. 8Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S Weld, Luke Zettlemoyer, and Omer Levy. 2020. Spanbert: Improving pre-training by representing and predict- ing spans. Transactions of the Association for Computational Linguistics 8 (2020), 64-77.\n\nCtrl: A conditional transformer language model for controllable generation. Bryan Nitish Shirish Keskar, Mccann, R Lav, Caiming Varshney, Richard Xiong, Socher, arXiv:1909.05858arXiv preprintNitish Shirish Keskar, Bryan McCann, Lav R Varshney, Caiming Xiong, and Richard Socher. 2019. Ctrl: A conditional transformer language model for con- trollable generation. arXiv preprint arXiv:1909.05858 (2019).\n\nOn the Impact of Various Types of Noise on Neural Machine Translation. Huda Khayrallah, Philipp Koehn, 10.18653/v1/W18-2709Proceedings of the 2nd Workshop on Neural Machine Translation and Generation. the 2nd Workshop on Neural Machine Translation and GenerationMelbourne, AustraliaAssociation for Computational LinguisticsHuda Khayrallah and Philipp Koehn. 2018. On the Impact of Various Types of Noise on Neural Machine Translation. In Proceedings of the 2nd Workshop on Neural Machine Translation and Generation. Association for Computational Linguistics, Melbourne, Australia, 74-83. https://doi.org/10.18653/v1/W18-2709\n\nCode Review Quality: How Developers See It. Oleksii Kononenko, Olga Baysal, Michael W Godfrey, 10.1145/2884781.28848402016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). Oleksii Kononenko, Olga Baysal, and Michael W. Godfrey. 2016. Code Review Quality: How Developers See It. In 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). 1028-1038. https://doi.org/10.1145/2884781. 2884840\n\nCode review quality: How developers see it. Oleksii Kononenko, Olga Baysal, Michael W Godfrey, Proceedings of the 38th international conference on software engineering. the 38th international conference on software engineeringOleksii Kononenko, Olga Baysal, and Michael W Godfrey. 2016. Code review quality: How developers see it. In Proceedings of the 38th international conference on software engineering. 1028-1038.\n\nROUGE: A Package for Automatic Evaluation of Summaries. Chin-Yew Lin, Text Summarization Branches Out. Barcelona, SpainAssociation for Computational LinguisticsChin-Yew Lin. 2004. ROUGE: A Package for Automatic Evaluation of Summaries. In Text Summarization Branches Out. Association for Computational Linguistics, Barcelona, Spain, 74-81. https://aclanthology.org/W04-1013\n\nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig, arXiv:2107.13586arXiv preprintPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Gra- ham Neubig. 2021. Pre-train, prompt, and predict: A systematic survey of prompt- ing methods in natural language processing. arXiv preprint arXiv:2107.13586 (2021).\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. arXiv preprintYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 (2019).\n\nUsing Deep Learning to Generate Complete Log Statements. Antonio Mastropaolo, Luca Pascarella, Gabriele Bavota, arXiv:2201.04837arXiv preprintAntonio Mastropaolo, Luca Pascarella, and Gabriele Bavota. 2022. Using Deep Learning to Generate Complete Log Statements. arXiv preprint arXiv:2201.04837 (2022).\n\nThe Impact of Code Review Coverage and Code Review Participation on Software Quality: A Case Study of the Qt, VTK, and ITK Projects. Shane Mcintosh, Yasutaka Kamei, Bram Adams, Ahmed E Hassan, 10.1145/2597073.2597076Proceedings of the 11th Working Conference on Mining Software Repositories. the 11th Working Conference on Mining Software RepositoriesHyderabad, India; New York, NY, USAAssociation for Computing MachineryShane McIntosh, Yasutaka Kamei, Bram Adams, and Ahmed E. Hassan. 2014. The Impact of Code Review Coverage and Code Review Participation on Software Quality: A Case Study of the Qt, VTK, and ITK Projects. In Proceedings of the 11th Working Conference on Mining Software Repositories (Hyderabad, India) (MSR 2014). Association for Computing Machinery, New York, NY, USA, 192-201. https://doi.org/10.1145/2597073.2597076\n\nDo code review practices impact design quality? A case study of the Qt, VTK, and ITK projects. Rodrigo Morales, Shane Mcintosh, Foutse Khomh, 10.1109/SANER.2015.7081827IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER). Rodrigo Morales, Shane McIntosh, and Foutse Khomh. 2015. Do code review practices impact design quality? A case study of the Qt, VTK, and ITK projects. In 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER). 171-180. https://doi.org/10.1109/SANER.2015.7081827\n\nStudy on the Impact of Partition-Induced Dataset Shift on -Fold Cross-Validation. Jose Garc\u00eda Moreno-Torres, Jos\u00e9 A Saez, Francisco Herrera, 10.1109/TNNLS.2012.2199516IEEE Transactions on Neural Networks and Learning Systems. 23Jose Garc\u00eda Moreno-Torres, Jos\u00e9 A. Saez, and Francisco Herrera. 2012. Study on the Impact of Partition-Induced Dataset Shift on -Fold Cross-Validation. IEEE Transactions on Neural Networks and Learning Systems 23, 8 (2012), 1304-1312. https://doi.org/10.1109/TNNLS.2012.2199516\n\nNatural language models for predicting programming comments. Dana Movshovitz, -Attias , William Cohen, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. the 51st Annual Meeting of the Association for Computational LinguisticsShort Papers2Dana Movshovitz-Attias and William Cohen. 2013. Natural language models for predicting programming comments. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 35-40.\n\nImproving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya SutskeverAlec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. 2018. Im- proving language understanding by generative pre-training. (2018).\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 19Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, arXiv:1910.10683arXiv preprintColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2019. Exploring the lim- its of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683 (2019).\n\nPredicting Usefulness of Code Review Comments Using Textual Features and Developer Experience. Chanchal K Mohammad Masudur Rahman, Raula G Roy, Kula, 10.1109/MSR.2017.172017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR). Mohammad Masudur Rahman, Chanchal K. Roy, and Raula G. Kula. 2017. Predict- ing Usefulness of Code Review Comments Using Textual Features and Developer Experience. In 2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR). 215-226. https://doi.org/10.1109/MSR.2017.17\n\nConvergent Contemporary Software Peer Review Practices. C Peter, Christian Rigby, Bird, 10.1145/2491411.2491444Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering. the 2013 9th Joint Meeting on Foundations of Software EngineeringSaint Petersburg, Russia; New York, NY, USAAssociation for Computing MachineryESEC/FSE 2013)Peter C. Rigby and Christian Bird. 2013. Convergent Contemporary Software Peer Review Practices. In Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering (Saint Petersburg, Russia) (ESEC/FSE 2013). Association for Computing Machinery, New York, NY, USA, 202-212. https://doi.org/10. 1145/2491411.2491444\n\nDetecting formal thought disorder by deep contextualized word representations. Justyna Sarzynska-Wawer, Aleksander Wawer, Aleksandra Pawlak, Julia Szymanowska, Izabela Stefaniak, Michal Jarkiewicz, Lukasz Okruszek, Psychiatry Research. 304114135Justyna Sarzynska-Wawer, Aleksander Wawer, Aleksandra Pawlak, Julia Szy- manowska, Izabela Stefaniak, Michal Jarkiewicz, and Lukasz Okruszek. 2021. Detecting formal thought disorder by deep contextualized word representations. Psychiatry Research 304 (2021), 114135.\n\nNoam Shazeer, Youlong Cheng, Niki Parmar, Dustin Tran, Ashish Vaswani, Penporn Koanantakool, Peter Hawkins, Hyoukjoong Lee, Mingsheng Hong, Cliff Young, arXiv:1811.02084Mesh-tensorflow: Deep learning for supercomputers. arXiv preprintNoam Shazeer, Youlong Cheng, Niki Parmar, Dustin Tran, Ashish Vaswani, Pen- porn Koanantakool, Peter Hawkins, HyoukJoong Lee, Mingsheng Hong, Cliff Young, et al. 2018. Mesh-tensorflow: Deep learning for supercomputers. arXiv preprint arXiv:1811.02084 (2018).\n\nISPY: Automatic Issue-Solution Pair Extraction from Community Live Chats. Lin Shi, Ziyou Jiang, Ye Yang, Xiao Chen, Yumin Zhang, Fangwen Mu, Hanzhi Jiang, Qing Wang, arXiv:2109.07055arXiv preprintLin Shi, Ziyou Jiang, Ye Yang, Xiao Chen, Yumin Zhang, Fangwen Mu, Hanzhi Jiang, and Qing Wang. 2021. ISPY: Automatic Issue-Solution Pair Extraction from Community Live Chats. arXiv preprint arXiv:2109.07055 (2021).\n\nAutomatic code review by learning the revision of source code. Shu-Ting Shi, Ming Li, David Lo, Ferdian Thung, Xuan Huo, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Shu-Ting Shi, Ming Li, David Lo, Ferdian Thung, and Xuan Huo. 2019. Automatic code review by learning the revision of source code. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. 4910-4917.\n\nInspecting the history of inspections: An example of evidence-based technology diffusion. Forrest Shull, Carolyn Seaman, IEEE software. 25Forrest Shull and Carolyn Seaman. 2008. Inspecting the history of inspections: An example of evidence-based technology diffusion. IEEE software 25, 1 (2008), 88-90.\n\nA Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques. Xiaotao Song, Hailong Sun, Xu Wang, Jiafei Yan, 10.1109/ACCESS.2019.2931579IEEE Access. 7Xiaotao Song, Hailong Sun, Xu Wang, and Jiafei Yan. 2019. A Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques. IEEE Access 7 (2019), 111411-111428. https://doi.org/10.1109/ACCESS.2019.2931579\n\nPrimers or Reminders? The Effects of Existing Review Comments on Code Review. Davide Spadini, G\u00fcl \u00c7alikli, Alberto Bacchelli, 10.1145/3377811.3380385Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering. the ACM/IEEE 42nd International Conference on Software EngineeringSeoul, South Korea; New York, NY, USAAssociation for Computing MachineryICSE '20)Davide Spadini, G\u00fcl \u00c7alikli, and Alberto Bacchelli. 2020. Primers or Reminders? The Effects of Existing Review Comments on Code Review. In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering (Seoul, South Korea) (ICSE '20). Association for Computing Machinery, New York, NY, USA, 1171-1182. https://doi.org/10.1145/3377811.3380385\n\nTowards Automatically Generating Summary Comments for Java Methods. Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, K Vijay-Shanker, 10.1145/1858996.1859006Proceedings of the IEEE/ACM International Conference on Automated Software Engineering. the IEEE/ACM International Conference on Automated Software EngineeringAntwerp, Belgium; New York, NY, USAAssociation for Computing MachineryASE '10)Giriprasad Sridhara, Emily Hill, Divya Muppaneni, Lori Pollock, and K. Vijay- Shanker. 2010. Towards Automatically Generating Summary Comments for Java Methods. In Proceedings of the IEEE/ACM International Conference on Automated Software Engineering (Antwerp, Belgium) (ASE '10). Association for Computing Machinery, New York, NY, USA, 43-52. https://doi.org/10.1145/1858996.1859006\n\nCode and Named Entity Recognition in StackOverflow. Jeniya Tabassum, Mounica Maddela, Wei Xu, Alan Ritter, 10.18653/v1/2020.acl-main.443Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Online. the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, OnlineJeniya Tabassum, Mounica Maddela, Wei Xu, and Alan Ritter. 2020. Code and Named Entity Recognition in StackOverflow. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Com- putational Linguistics, Online, 4913-4926. https://doi.org/10.18653/v1/2020.acl- main.443\n\nProcedures and Comments vs. the Banker's Algorithm. Ted Tenny, 10.1145/382208.382523SIGCSE Bull. 17Ted Tenny. 1985. Procedures and Comments vs. the Banker's Algorithm. SIGCSE Bull. 17, 3 (sep 1985), 44-53. https://doi.org/10.1145/382208.382523\n\nProgram readability: Procedures versus comments. Ted Tenny, IEEE Transactions on Software Engineering. 14Ted Tenny. 1988. Program readability: Procedures versus comments. IEEE Transactions on Software Engineering 14, 9 (1988), 1271-1279.\n\nRosalia Tufano, Simone Masiero, Antonio Mastropaolo, Luca Pascarella, arXiv:2201.06850Denys Poshyvanyk, and Gabriele Bavota. 2022. Using Pre-Trained Models to Boost Code Review Automation. arXiv preprintRosalia Tufano, Simone Masiero, Antonio Mastropaolo, Luca Pascarella, Denys Poshyvanyk, and Gabriele Bavota. 2022. Using Pre-Trained Models to Boost Code Review Automation. arXiv preprint arXiv:2201.06850 (2022).\n\nTowards Automating Code Review Activities. Rosalia Tufano, Luca Pascarella, Michele Tufanoy, Denys Poshyvanykz, Gabriele Bavota, 2021Rosalia Tufano, Luca Pascarella, Michele Tufanoy, Denys Poshyvanykz, and Gabriele Bavota. 2021. Towards Automating Code Review Activities. In 2021\n\nIEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEEIEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE, 163-174.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998-6008.\n\nImproving Automatic Source Code Summarization via Deep Reinforcement Learning. Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, Philip S Yu, 10.1145/3238147.3238206Association for Computing MachineryNew York, NY, USAYao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S. Yu. 2018. Improving Automatic Source Code Summarization via Deep Reinforcement Learning. Association for Computing Machinery, New York, NY, USA, 397-407. https://doi.org/10.1145/3238147.3238206\n\nTo Pretrain or Not to Pretrain: Examining the Benefits of Pretrainng on Resource Rich Tasks. Sinong Wang, Madian Khabsa, Hao Ma, 10.18653/v1/2020.acl-main.200Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsSinong Wang, Madian Khabsa, and Hao Ma. 2020. To Pretrain or Not to Pretrain: Examining the Benefits of Pretrainng on Resource Rich Tasks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Online, 2209-2213. https://doi.org/10.18653/v1/ 2020.acl-main.200\n\nJason Wei, Kai Zou, arXiv:1901.11196Eda: Easy data augmentation techniques for boosting performance on text classification tasks. arXiv preprintJason Wei and Kai Zou. 2019. Eda: Easy data augmentation techniques for boosting performance on text classification tasks. arXiv preprint arXiv:1901.11196 (2019).\n\nCloCom: Mining existing source code for automatic comment generation. Edmund Wong, Taiyue Liu, Lin Tan, 10.1109/SANER.2015.7081848IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER). Edmund Wong, Taiyue Liu, and Lin Tan. 2015. CloCom: Mining existing source code for automatic comment generation. In 2015 IEEE 22nd International Con- ference on Software Analysis, Evolution, and Reengineering (SANER). 380-389. https://doi.org/10.1109/SANER.2015.7081848\n\nThe Effect of Modularization and Comments on Program Comprehension. S N Woodfield, H E Dunsmore, V Y Shen, Proceedings of the 5th International Conference on Software Engineering. the 5th International Conference on Software EngineeringSan Diego, California, USAIEEE PressICSE '81)S. N. Woodfield, H. E. Dunsmore, and V. Y. Shen. 1981. The Effect of Modular- ization and Comments on Program Comprehension. In Proceedings of the 5th International Conference on Software Engineering (San Diego, California, USA) (ICSE '81). IEEE Press, 215-223.\n\nMeasuring program comprehension: A large-scale field study with professionals. Xin Xia, Lingfeng Bao, David Lo, Zhenchang Xing, Ahmed E Hassan, Shanping Li, IEEE Transactions on Software Engineering. 44Xin Xia, Lingfeng Bao, David Lo, Zhenchang Xing, Ahmed E Hassan, and Shan- ping Li. 2017. Measuring program comprehension: A large-scale field study with professionals. IEEE Transactions on Software Engineering 44, 10 (2017), 951-976.\n\nXlnet: Generalized autoregressive pretraining for language understanding. Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, R Russ, Quoc V Salakhutdinov, Le, Advances in neural information processing systems. 32Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ R Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for language understanding. Advances in neural information processing systems 32 (2019).\n\nReviewer Recommender of Pull-Requests in GitHub. Yue Yu, Huaimin Wang, Gang Yin, Charles X Ling, 10.1109/ICSME.2014.1072014 IEEE International Conference on Software Maintenance and Evolution. Yue Yu, Huaimin Wang, Gang Yin, and Charles X. Ling. 2014. Reviewer Rec- ommender of Pull-Requests in GitHub. In 2014 IEEE International Conference on Software Maintenance and Evolution. 609-612. https://doi.org/10.1109/ICSME. 2014.107\n\n. Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, Qing He, 10.1109/JPROC.2020.30045552021. A Comprehensive Survey on Transfer Learning. Proc. IEEE. 109Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. 2021. A Comprehensive Survey on Transfer Learning. Proc. IEEE 109, 1 (2021), 43-76. https://doi.org/10.1109/JPROC.2020. 3004555\n", "annotations": {"author": "[{\"end\":340,\"start\":300},{\"end\":349,\"start\":341},{\"end\":392,\"start\":350},{\"end\":418,\"start\":393},{\"end\":448,\"start\":419},{\"end\":459,\"start\":449},{\"end\":493,\"start\":460},{\"end\":527,\"start\":494},{\"end\":539,\"start\":528},{\"end\":548,\"start\":540},{\"end\":561,\"start\":549},{\"end\":570,\"start\":562},{\"end\":583,\"start\":571},{\"end\":594,\"start\":584},{\"end\":606,\"start\":595},{\"end\":616,\"start\":607},{\"end\":991,\"start\":617},{\"end\":1098,\"start\":992},{\"end\":1138,\"start\":1099}]", "publisher": null, "author_last_name": "[{\"end\":310,\"start\":308},{\"end\":348,\"start\":344},{\"end\":361,\"start\":356},{\"end\":400,\"start\":397},{\"end\":430,\"start\":427},{\"end\":458,\"start\":455},{\"end\":470,\"start\":465},{\"end\":502,\"start\":499},{\"end\":538,\"start\":536},{\"end\":547,\"start\":543},{\"end\":560,\"start\":555},{\"end\":569,\"start\":566},{\"end\":582,\"start\":579},{\"end\":593,\"start\":590},{\"end\":605,\"start\":600},{\"end\":615,\"start\":612}]", "author_first_name": "[{\"end\":307,\"start\":300},{\"end\":343,\"start\":341},{\"end\":355,\"start\":350},{\"end\":396,\"start\":393},{\"end\":426,\"start\":419},{\"end\":454,\"start\":449},{\"end\":464,\"start\":460},{\"end\":498,\"start\":494},{\"end\":535,\"start\":528},{\"end\":542,\"start\":540},{\"end\":554,\"start\":549},{\"end\":565,\"start\":562},{\"end\":578,\"start\":571},{\"end\":589,\"start\":584},{\"end\":599,\"start\":595},{\"end\":611,\"start\":607}]", "author_affiliation": "[{\"end\":990,\"start\":618},{\"end\":1097,\"start\":993},{\"end\":1137,\"start\":1100}]", "title": "[{\"end\":297,\"start\":1},{\"end\":1435,\"start\":1139}]", "venue": null, "abstract": "[{\"end\":3674,\"start\":2543}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3836,\"start\":3833},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3839,\"start\":3836},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":3842,\"start\":3839},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3931,\"start\":3928},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4670,\"start\":4666},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":4933,\"start\":4929},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5156,\"start\":5153},{\"end\":5281,\"start\":5265},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5352,\"start\":5348},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5465,\"start\":5462},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5579,\"start\":5576},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5582,\"start\":5579},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":5879,\"start\":5875},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6112,\"start\":6109},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6114,\"start\":6112},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6279,\"start\":6275},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6442,\"start\":6438},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":6445,\"start\":6442},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6652,\"start\":6648},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6708,\"start\":6705},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6791,\"start\":6788},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7036,\"start\":7032},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":7136,\"start\":7132},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7487,\"start\":7484},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7602,\"start\":7598},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":7855,\"start\":7851},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":8420,\"start\":8416},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11120,\"start\":11117},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11123,\"start\":11120},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11862,\"start\":11858},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14198,\"start\":14195},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14793,\"start\":14790},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":15335,\"start\":15332},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16711,\"start\":16707},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16714,\"start\":16711},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":16717,\"start\":16714},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16929,\"start\":16925},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":17037,\"start\":17033},{\"end\":17671,\"start\":17661},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18652,\"start\":18648},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":18655,\"start\":18652},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":19043,\"start\":19039},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":19046,\"start\":19043},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19294,\"start\":19290},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":19297,\"start\":19294},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19925,\"start\":19921},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20093,\"start\":20092},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":20188,\"start\":20184},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20227,\"start\":20223},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":21446,\"start\":21442},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":21879,\"start\":21875},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":21882,\"start\":21879},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24067,\"start\":24065},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24696,\"start\":24693},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24821,\"start\":24817},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24947,\"start\":24944},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":25105,\"start\":25101},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":25243,\"start\":25239},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":25385,\"start\":25381},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25618,\"start\":25614},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26483,\"start\":26479},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":27255,\"start\":27251},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":34491,\"start\":34487},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":34745,\"start\":34741},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":35549,\"start\":35546},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36050,\"start\":36047},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":36396,\"start\":36393},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":37522,\"start\":37519},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":40018,\"start\":40014},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":40021,\"start\":40018},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":40135,\"start\":40132},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":40281,\"start\":40277},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":40403,\"start\":40399},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":40545,\"start\":40541},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":40833,\"start\":40830},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":40836,\"start\":40833},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":40839,\"start\":40836},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":40842,\"start\":40839},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":41096,\"start\":41092},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":41308,\"start\":41304},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":41320,\"start\":41316},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":41334,\"start\":41330},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":41459,\"start\":41455},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":41462,\"start\":41459},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":41465,\"start\":41462},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":41662,\"start\":41658},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":41665,\"start\":41662},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":41668,\"start\":41665},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":41671,\"start\":41668},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":41799,\"start\":41795},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":41943,\"start\":41939},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":41946,\"start\":41943},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":42189,\"start\":42185},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":42312,\"start\":42308},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":42315,\"start\":42312},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":42318,\"start\":42315},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":42522,\"start\":42518},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":42691,\"start\":42687},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":42845,\"start\":42841},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":43005,\"start\":43001},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":43008,\"start\":43005},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":43030,\"start\":43026},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":43055,\"start\":43051},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":43121,\"start\":43117},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":43141,\"start\":43137},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":43254,\"start\":43250},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":43266,\"start\":43262},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":44582,\"start\":44578}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":46403,\"start\":46253},{\"attributes\":{\"id\":\"fig_1\"},\"end\":46452,\"start\":46404},{\"attributes\":{\"id\":\"fig_2\"},\"end\":46671,\"start\":46453},{\"attributes\":{\"id\":\"fig_3\"},\"end\":46988,\"start\":46672},{\"attributes\":{\"id\":\"fig_4\"},\"end\":47032,\"start\":46989},{\"attributes\":{\"id\":\"fig_5\"},\"end\":47412,\"start\":47033},{\"attributes\":{\"id\":\"fig_6\"},\"end\":47763,\"start\":47413},{\"attributes\":{\"id\":\"fig_7\"},\"end\":47951,\"start\":47764},{\"attributes\":{\"id\":\"fig_8\"},\"end\":48027,\"start\":47952},{\"attributes\":{\"id\":\"fig_9\"},\"end\":48592,\"start\":48028},{\"attributes\":{\"id\":\"fig_10\"},\"end\":48628,\"start\":48593},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":51606,\"start\":48629},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":52020,\"start\":51607},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":52390,\"start\":52021},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":52627,\"start\":52391}]", "paragraph": "[{\"end\":4596,\"start\":3690},{\"end\":4725,\"start\":4598},{\"end\":4825,\"start\":4743},{\"end\":4846,\"start\":4827},{\"end\":5198,\"start\":4848},{\"end\":6280,\"start\":5200},{\"end\":7266,\"start\":6282},{\"end\":7972,\"start\":7268},{\"end\":9846,\"start\":7974},{\"end\":10111,\"start\":9848},{\"end\":10467,\"start\":10113},{\"end\":10817,\"start\":10469},{\"end\":10916,\"start\":10819},{\"end\":11007,\"start\":10931},{\"end\":11213,\"start\":11028},{\"end\":11714,\"start\":11287},{\"end\":11915,\"start\":11733},{\"end\":12485,\"start\":11960},{\"end\":12544,\"start\":12487},{\"end\":12734,\"start\":12569},{\"end\":13888,\"start\":12758},{\"end\":14648,\"start\":13933},{\"end\":15514,\"start\":14650},{\"end\":15768,\"start\":15516},{\"end\":16216,\"start\":15770},{\"end\":16609,\"start\":16218},{\"end\":17038,\"start\":16611},{\"end\":17532,\"start\":17063},{\"end\":18480,\"start\":17534},{\"end\":19136,\"start\":18520},{\"end\":19964,\"start\":19159},{\"end\":20726,\"start\":19966},{\"end\":21110,\"start\":20816},{\"end\":21299,\"start\":21134},{\"end\":21601,\"start\":21301},{\"end\":21883,\"start\":21603},{\"end\":22066,\"start\":21962},{\"end\":22372,\"start\":22068},{\"end\":22436,\"start\":22374},{\"end\":22731,\"start\":22474},{\"end\":23158,\"start\":22747},{\"end\":23306,\"start\":23205},{\"end\":23608,\"start\":23308},{\"end\":23700,\"start\":23610},{\"end\":24419,\"start\":23716},{\"end\":24697,\"start\":24433},{\"end\":25447,\"start\":24699},{\"end\":26141,\"start\":25459},{\"end\":26235,\"start\":26165},{\"end\":26625,\"start\":26237},{\"end\":27256,\"start\":26627},{\"end\":28003,\"start\":27315},{\"end\":28872,\"start\":28005},{\"end\":29854,\"start\":28874},{\"end\":30352,\"start\":29856},{\"end\":31407,\"start\":30354},{\"end\":31564,\"start\":31409},{\"end\":31719,\"start\":31593},{\"end\":32431,\"start\":31743},{\"end\":33889,\"start\":32433},{\"end\":34020,\"start\":33891},{\"end\":34937,\"start\":34058},{\"end\":35487,\"start\":34939},{\"end\":36241,\"start\":35489},{\"end\":37523,\"start\":36243},{\"end\":38475,\"start\":37538},{\"end\":38719,\"start\":38477},{\"end\":38882,\"start\":38721},{\"end\":39124,\"start\":38884},{\"end\":39312,\"start\":39126},{\"end\":39547,\"start\":39314},{\"end\":39737,\"start\":39549},{\"end\":39898,\"start\":39754},{\"end\":40546,\"start\":39900},{\"end\":40712,\"start\":40548},{\"end\":41466,\"start\":40714},{\"end\":42190,\"start\":41468},{\"end\":42846,\"start\":42192},{\"end\":43342,\"start\":42848},{\"end\":43786,\"start\":43344},{\"end\":44479,\"start\":43810},{\"end\":44798,\"start\":44481},{\"end\":45199,\"start\":44800},{\"end\":46096,\"start\":45214},{\"end\":46252,\"start\":46098}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11286,\"start\":11214},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11959,\"start\":11916},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12757,\"start\":12735},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18519,\"start\":18481},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20815,\"start\":20727},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21961,\"start\":21884},{\"attributes\":{\"id\":\"formula_6\"},\"end\":22473,\"start\":22437}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24204,\"start\":24197},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26624,\"start\":26617},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26809,\"start\":26802},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":31882,\"start\":31875},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32615,\"start\":32608}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3688,\"start\":3676},{\"end\":4741,\"start\":4728},{\"attributes\":{\"n\":\"2\"},\"end\":10929,\"start\":10919},{\"attributes\":{\"n\":\"2.1\"},\"end\":11026,\"start\":11010},{\"attributes\":{\"n\":\"2.2\"},\"end\":11731,\"start\":11717},{\"attributes\":{\"n\":\"2.3\"},\"end\":12567,\"start\":12547},{\"attributes\":{\"n\":\"3\"},\"end\":13912,\"start\":13891},{\"attributes\":{\"n\":\"3.2\"},\"end\":13931,\"start\":13915},{\"attributes\":{\"n\":\"3.3\"},\"end\":17061,\"start\":17041},{\"attributes\":{\"n\":\"3.4\"},\"end\":19157,\"start\":19139},{\"attributes\":{\"n\":\"3.5\"},\"end\":21132,\"start\":21113},{\"attributes\":{\"n\":\"3.6\"},\"end\":22745,\"start\":22734},{\"attributes\":{\"n\":\"4\"},\"end\":23203,\"start\":23161},{\"attributes\":{\"n\":\"4.2\"},\"end\":23714,\"start\":23703},{\"attributes\":{\"n\":\"4.3\"},\"end\":24431,\"start\":24422},{\"attributes\":{\"n\":\"4.4\"},\"end\":25457,\"start\":25450},{\"attributes\":{\"n\":\"4.5\"},\"end\":26163,\"start\":26144},{\"attributes\":{\"n\":\"5\"},\"end\":27313,\"start\":27259},{\"attributes\":{\"n\":\"5.2\"},\"end\":31591,\"start\":31567},{\"end\":31741,\"start\":31722},{\"attributes\":{\"n\":\"5.3\"},\"end\":34056,\"start\":34023},{\"attributes\":{\"n\":\"5.4\"},\"end\":37536,\"start\":37526},{\"attributes\":{\"n\":\"6\"},\"end\":39752,\"start\":39740},{\"attributes\":{\"n\":\"7\"},\"end\":43808,\"start\":43789},{\"attributes\":{\"n\":\"8\"},\"end\":45212,\"start\":45202},{\"end\":46415,\"start\":46405},{\"end\":46462,\"start\":46454},{\"end\":47000,\"start\":46990},{\"end\":47775,\"start\":47765},{\"end\":47973,\"start\":47953},{\"end\":48030,\"start\":48029},{\"end\":48604,\"start\":48594},{\"end\":51617,\"start\":51608},{\"end\":52031,\"start\":52022},{\"end\":52401,\"start\":52392}]", "table": "[{\"end\":51606,\"start\":49438},{\"end\":52020,\"start\":51630},{\"end\":52390,\"start\":52057},{\"end\":52627,\"start\":52423}]", "figure_caption": "[{\"end\":46403,\"start\":46255},{\"end\":46452,\"start\":46417},{\"end\":46671,\"start\":46464},{\"end\":46988,\"start\":46674},{\"end\":47032,\"start\":47002},{\"end\":47412,\"start\":47035},{\"end\":47763,\"start\":47415},{\"end\":47951,\"start\":47777},{\"end\":48027,\"start\":47976},{\"end\":48592,\"start\":48031},{\"end\":48628,\"start\":48606},{\"end\":49438,\"start\":48631},{\"end\":51630,\"start\":51619},{\"end\":52057,\"start\":52033},{\"end\":52423,\"start\":52403}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":4083,\"start\":4074},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":4595,\"start\":4583},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":14359,\"start\":14351},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15684,\"start\":15676},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":16215,\"start\":16207},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":16398,\"start\":16390},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":22517,\"start\":22507},{\"end\":27338,\"start\":27330},{\"end\":27917,\"start\":27908},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":30392,\"start\":30384},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":30524,\"start\":30516},{\"end\":35885,\"start\":35877},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":38474,\"start\":38466}]", "bib_author_first_name": "[{\"end\":53411,\"start\":53402},{\"end\":53993,\"start\":53986},{\"end\":54014,\"start\":54005},{\"end\":54944,\"start\":54936},{\"end\":54960,\"start\":54953},{\"end\":55412,\"start\":55408},{\"end\":55425,\"start\":55419},{\"end\":55441,\"start\":55434},{\"end\":55658,\"start\":55654},{\"end\":55672,\"start\":55668},{\"end\":55691,\"start\":55683},{\"end\":56153,\"start\":56144},{\"end\":56161,\"start\":56160},{\"end\":56567,\"start\":56558},{\"end\":56582,\"start\":56574},{\"end\":56601,\"start\":56592},{\"end\":57068,\"start\":57063},{\"end\":57079,\"start\":57078},{\"end\":57095,\"start\":57090},{\"end\":57112,\"start\":57108},{\"end\":57126,\"start\":57120},{\"end\":57141,\"start\":57135},{\"end\":57157,\"start\":57152},{\"end\":57159,\"start\":57158},{\"end\":57588,\"start\":57580},{\"end\":57606,\"start\":57602},{\"end\":57620,\"start\":57613},{\"end\":57633,\"start\":57628},{\"end\":57651,\"start\":57643},{\"end\":57666,\"start\":57660},{\"end\":57683,\"start\":57677},{\"end\":57703,\"start\":57697},{\"end\":57717,\"start\":57711},{\"end\":58071,\"start\":58063},{\"end\":58081,\"start\":58079},{\"end\":58095,\"start\":58088},{\"end\":58289,\"start\":58280},{\"end\":58310,\"start\":58302},{\"end\":58636,\"start\":58628},{\"end\":58650,\"start\":58644},{\"end\":58663,\"start\":58658},{\"end\":59091,\"start\":59086},{\"end\":59111,\"start\":59103},{\"end\":59125,\"start\":59121},{\"end\":59596,\"start\":59591},{\"end\":59613,\"start\":59605},{\"end\":59627,\"start\":59621},{\"end\":59641,\"start\":59633},{\"end\":59947,\"start\":59941},{\"end\":59960,\"start\":59955},{\"end\":59962,\"start\":59961},{\"end\":59979,\"start\":59973},{\"end\":60653,\"start\":60648},{\"end\":60667,\"start\":60664},{\"end\":60679,\"start\":60674},{\"end\":60690,\"start\":60687},{\"end\":60703,\"start\":60698},{\"end\":60720,\"start\":60711},{\"end\":60736,\"start\":60730},{\"end\":60754,\"start\":60747},{\"end\":60772,\"start\":60764},{\"end\":61197,\"start\":61189},{\"end\":61208,\"start\":61204},{\"end\":61218,\"start\":61214},{\"end\":61228,\"start\":61225},{\"end\":61244,\"start\":61235},{\"end\":61255,\"start\":61251},{\"end\":61268,\"start\":61262},{\"end\":61279,\"start\":61275},{\"end\":61289,\"start\":61285},{\"end\":61300,\"start\":61295},{\"end\":61312,\"start\":61308},{\"end\":61949,\"start\":61943},{\"end\":61963,\"start\":61954},{\"end\":61972,\"start\":61968},{\"end\":61978,\"start\":61977},{\"end\":61980,\"start\":61979},{\"end\":62598,\"start\":62594},{\"end\":62609,\"start\":62604},{\"end\":62628,\"start\":62620},{\"end\":62637,\"start\":62633},{\"end\":62650,\"start\":62644},{\"end\":62661,\"start\":62657},{\"end\":62670,\"start\":62667},{\"end\":62683,\"start\":62677},{\"end\":62697,\"start\":62690},{\"end\":63104,\"start\":63098},{\"end\":63116,\"start\":63112},{\"end\":63653,\"start\":63648},{\"end\":63667,\"start\":63662},{\"end\":63683,\"start\":63676},{\"end\":64125,\"start\":64120},{\"end\":64139,\"start\":64134},{\"end\":64153,\"start\":64148},{\"end\":64169,\"start\":64162},{\"end\":64527,\"start\":64523},{\"end\":64546,\"start\":64540},{\"end\":64763,\"start\":64757},{\"end\":64781,\"start\":64772},{\"end\":64997,\"start\":64993},{\"end\":65004,\"start\":65002},{\"end\":65012,\"start\":65009},{\"end\":65023,\"start\":65018},{\"end\":65031,\"start\":65028},{\"end\":65378,\"start\":65371},{\"end\":65393,\"start\":65386},{\"end\":65406,\"start\":65401},{\"end\":65419,\"start\":65414},{\"end\":65432,\"start\":65427},{\"end\":65442,\"start\":65439},{\"end\":65459,\"start\":65449},{\"end\":65471,\"start\":65465},{\"end\":65480,\"start\":65479},{\"end\":65494,\"start\":65487},{\"end\":65927,\"start\":65921},{\"end\":65940,\"start\":65935},{\"end\":65953,\"start\":65947},{\"end\":65960,\"start\":65959},{\"end\":65973,\"start\":65969},{\"end\":65984,\"start\":65980},{\"end\":66394,\"start\":66389},{\"end\":66427,\"start\":66426},{\"end\":66440,\"start\":66433},{\"end\":66458,\"start\":66451},{\"end\":66792,\"start\":66788},{\"end\":66812,\"start\":66805},{\"end\":67394,\"start\":67387},{\"end\":67410,\"start\":67406},{\"end\":67426,\"start\":67419},{\"end\":67428,\"start\":67427},{\"end\":67826,\"start\":67819},{\"end\":67842,\"start\":67838},{\"end\":67860,\"start\":67851},{\"end\":68259,\"start\":68251},{\"end\":68682,\"start\":68675},{\"end\":68694,\"start\":68688},{\"end\":68707,\"start\":68701},{\"end\":68720,\"start\":68712},{\"end\":68735,\"start\":68728},{\"end\":68751,\"start\":68745},{\"end\":69041,\"start\":69035},{\"end\":69051,\"start\":69047},{\"end\":69062,\"start\":69057},{\"end\":69077,\"start\":69070},{\"end\":69088,\"start\":69082},{\"end\":69101,\"start\":69096},{\"end\":69112,\"start\":69108},{\"end\":69123,\"start\":69119},{\"end\":69135,\"start\":69131},{\"end\":69156,\"start\":69149},{\"end\":69558,\"start\":69551},{\"end\":69576,\"start\":69572},{\"end\":69597,\"start\":69589},{\"end\":69937,\"start\":69932},{\"end\":69956,\"start\":69948},{\"end\":69968,\"start\":69964},{\"end\":69981,\"start\":69976},{\"end\":69983,\"start\":69982},{\"end\":70741,\"start\":70734},{\"end\":70756,\"start\":70751},{\"end\":70773,\"start\":70767},{\"end\":71303,\"start\":71292},{\"end\":71323,\"start\":71319},{\"end\":71325,\"start\":71324},{\"end\":71341,\"start\":71332},{\"end\":71782,\"start\":71778},{\"end\":71802,\"start\":71795},{\"end\":71812,\"start\":71805},{\"end\":72293,\"start\":72289},{\"end\":72310,\"start\":72303},{\"end\":72558,\"start\":72554},{\"end\":72575,\"start\":72568},{\"end\":72585,\"start\":72580},{\"end\":72598,\"start\":72593},{\"end\":72610,\"start\":72605},{\"end\":72623,\"start\":72619},{\"end\":72914,\"start\":72909},{\"end\":72927,\"start\":72923},{\"end\":72941,\"start\":72937},{\"end\":72960,\"start\":72951},{\"end\":72972,\"start\":72966},{\"end\":72988,\"start\":72981},{\"end\":73002,\"start\":72997},{\"end\":73012,\"start\":73009},{\"end\":73024,\"start\":73017},{\"end\":73420,\"start\":73412},{\"end\":73422,\"start\":73421},{\"end\":73453,\"start\":73448},{\"end\":73455,\"start\":73454},{\"end\":73922,\"start\":73921},{\"end\":73939,\"start\":73930},{\"end\":74633,\"start\":74626},{\"end\":74661,\"start\":74651},{\"end\":74679,\"start\":74669},{\"end\":74693,\"start\":74688},{\"end\":74714,\"start\":74707},{\"end\":74732,\"start\":74726},{\"end\":74751,\"start\":74745},{\"end\":75064,\"start\":75060},{\"end\":75081,\"start\":75074},{\"end\":75093,\"start\":75089},{\"end\":75108,\"start\":75102},{\"end\":75121,\"start\":75115},{\"end\":75138,\"start\":75131},{\"end\":75158,\"start\":75153},{\"end\":75178,\"start\":75168},{\"end\":75193,\"start\":75184},{\"end\":75205,\"start\":75200},{\"end\":75631,\"start\":75628},{\"end\":75642,\"start\":75637},{\"end\":75652,\"start\":75650},{\"end\":75663,\"start\":75659},{\"end\":75675,\"start\":75670},{\"end\":75690,\"start\":75683},{\"end\":75701,\"start\":75695},{\"end\":75713,\"start\":75709},{\"end\":76038,\"start\":76030},{\"end\":76048,\"start\":76044},{\"end\":76058,\"start\":76053},{\"end\":76070,\"start\":76063},{\"end\":76082,\"start\":76078},{\"end\":76514,\"start\":76507},{\"end\":76529,\"start\":76522},{\"end\":76813,\"start\":76806},{\"end\":76827,\"start\":76820},{\"end\":76835,\"start\":76833},{\"end\":76848,\"start\":76842},{\"end\":77204,\"start\":77198},{\"end\":77217,\"start\":77214},{\"end\":77234,\"start\":77227},{\"end\":77939,\"start\":77929},{\"end\":77955,\"start\":77950},{\"end\":77967,\"start\":77962},{\"end\":77983,\"start\":77979},{\"end\":77994,\"start\":77993},{\"end\":78713,\"start\":78707},{\"end\":78731,\"start\":78724},{\"end\":78744,\"start\":78741},{\"end\":78753,\"start\":78749},{\"end\":79430,\"start\":79427},{\"end\":79672,\"start\":79669},{\"end\":79866,\"start\":79859},{\"end\":79881,\"start\":79875},{\"end\":79898,\"start\":79891},{\"end\":79916,\"start\":79912},{\"end\":80326,\"start\":80319},{\"end\":80339,\"start\":80335},{\"end\":80359,\"start\":80352},{\"end\":80374,\"start\":80369},{\"end\":80396,\"start\":80388},{\"end\":80752,\"start\":80746},{\"end\":80766,\"start\":80762},{\"end\":80780,\"start\":80776},{\"end\":80794,\"start\":80789},{\"end\":80811,\"start\":80806},{\"end\":80824,\"start\":80819},{\"end\":80826,\"start\":80825},{\"end\":80840,\"start\":80834},{\"end\":80854,\"start\":80849},{\"end\":81224,\"start\":81221},{\"end\":81234,\"start\":81230},{\"end\":81244,\"start\":81241},{\"end\":81259,\"start\":81251},{\"end\":81271,\"start\":81264},{\"end\":81282,\"start\":81278},{\"end\":81293,\"start\":81287},{\"end\":81295,\"start\":81294},{\"end\":81749,\"start\":81743},{\"end\":81762,\"start\":81756},{\"end\":81774,\"start\":81771},{\"end\":82356,\"start\":82351},{\"end\":82365,\"start\":82362},{\"end\":82735,\"start\":82729},{\"end\":82748,\"start\":82742},{\"end\":82757,\"start\":82754},{\"end\":83225,\"start\":83224},{\"end\":83227,\"start\":83226},{\"end\":83240,\"start\":83239},{\"end\":83242,\"start\":83241},{\"end\":83254,\"start\":83253},{\"end\":83256,\"start\":83255},{\"end\":83782,\"start\":83779},{\"end\":83796,\"start\":83788},{\"end\":83807,\"start\":83802},{\"end\":83821,\"start\":83812},{\"end\":83833,\"start\":83828},{\"end\":83835,\"start\":83834},{\"end\":83852,\"start\":83844},{\"end\":84218,\"start\":84212},{\"end\":84231,\"start\":84225},{\"end\":84243,\"start\":84237},{\"end\":84255,\"start\":84250},{\"end\":84268,\"start\":84267},{\"end\":84281,\"start\":84275},{\"end\":84640,\"start\":84637},{\"end\":84652,\"start\":84645},{\"end\":84663,\"start\":84659},{\"end\":84676,\"start\":84669},{\"end\":84678,\"start\":84677},{\"end\":85026,\"start\":85020},{\"end\":85042,\"start\":85035},{\"end\":85051,\"start\":85047},{\"end\":85064,\"start\":85058},{\"end\":85077,\"start\":85069},{\"end\":85090,\"start\":85083},{\"end\":85099,\"start\":85096},{\"end\":85111,\"start\":85107}]", "bib_author_last_name": "[{\"end\":53421,\"start\":53412},{\"end\":54003,\"start\":53994},{\"end\":54019,\"start\":54015},{\"end\":54482,\"start\":54464},{\"end\":54951,\"start\":54945},{\"end\":54966,\"start\":54961},{\"end\":55417,\"start\":55413},{\"end\":55432,\"start\":55426},{\"end\":55446,\"start\":55442},{\"end\":55666,\"start\":55659},{\"end\":55681,\"start\":55673},{\"end\":55699,\"start\":55692},{\"end\":56158,\"start\":56154},{\"end\":56169,\"start\":56162},{\"end\":56177,\"start\":56171},{\"end\":56572,\"start\":56568},{\"end\":56590,\"start\":56583},{\"end\":56606,\"start\":56602},{\"end\":57076,\"start\":57069},{\"end\":57088,\"start\":57080},{\"end\":57106,\"start\":57096},{\"end\":57118,\"start\":57113},{\"end\":57133,\"start\":57127},{\"end\":57150,\"start\":57142},{\"end\":57174,\"start\":57160},{\"end\":57183,\"start\":57176},{\"end\":57600,\"start\":57589},{\"end\":57611,\"start\":57607},{\"end\":57626,\"start\":57621},{\"end\":57641,\"start\":57634},{\"end\":57658,\"start\":57652},{\"end\":57675,\"start\":57667},{\"end\":57695,\"start\":57684},{\"end\":57709,\"start\":57704},{\"end\":57724,\"start\":57718},{\"end\":57732,\"start\":57726},{\"end\":58077,\"start\":58072},{\"end\":58086,\"start\":58082},{\"end\":58102,\"start\":58096},{\"end\":58300,\"start\":58290},{\"end\":58319,\"start\":58311},{\"end\":58642,\"start\":58637},{\"end\":58656,\"start\":58651},{\"end\":58671,\"start\":58664},{\"end\":59101,\"start\":59092},{\"end\":59119,\"start\":59112},{\"end\":59133,\"start\":59126},{\"end\":59603,\"start\":59597},{\"end\":59619,\"start\":59614},{\"end\":59631,\"start\":59628},{\"end\":59651,\"start\":59642},{\"end\":59953,\"start\":59948},{\"end\":59971,\"start\":59963},{\"end\":59986,\"start\":59980},{\"end\":60662,\"start\":60654},{\"end\":60672,\"start\":60668},{\"end\":60685,\"start\":60680},{\"end\":60696,\"start\":60691},{\"end\":60709,\"start\":60704},{\"end\":60728,\"start\":60721},{\"end\":60745,\"start\":60737},{\"end\":60762,\"start\":60755},{\"end\":60777,\"start\":60773},{\"end\":61202,\"start\":61198},{\"end\":61212,\"start\":61209},{\"end\":61223,\"start\":61219},{\"end\":61233,\"start\":61229},{\"end\":61249,\"start\":61245},{\"end\":61260,\"start\":61256},{\"end\":61273,\"start\":61269},{\"end\":61283,\"start\":61280},{\"end\":61293,\"start\":61290},{\"end\":61306,\"start\":61301},{\"end\":61317,\"start\":61313},{\"end\":61952,\"start\":61950},{\"end\":61966,\"start\":61964},{\"end\":61975,\"start\":61973},{\"end\":61987,\"start\":61981},{\"end\":61991,\"start\":61989},{\"end\":62602,\"start\":62599},{\"end\":62618,\"start\":62610},{\"end\":62631,\"start\":62629},{\"end\":62642,\"start\":62638},{\"end\":62655,\"start\":62651},{\"end\":62665,\"start\":62662},{\"end\":62675,\"start\":62671},{\"end\":62688,\"start\":62684},{\"end\":62710,\"start\":62698},{\"end\":62714,\"start\":62712},{\"end\":63110,\"start\":63105},{\"end\":63127,\"start\":63117},{\"end\":63660,\"start\":63654},{\"end\":63674,\"start\":63668},{\"end\":63690,\"start\":63684},{\"end\":64132,\"start\":64126},{\"end\":64146,\"start\":64140},{\"end\":64160,\"start\":64154},{\"end\":64176,\"start\":64170},{\"end\":64538,\"start\":64528},{\"end\":64558,\"start\":64547},{\"end\":64770,\"start\":64764},{\"end\":64787,\"start\":64782},{\"end\":65000,\"start\":64998},{\"end\":65007,\"start\":65005},{\"end\":65016,\"start\":65013},{\"end\":65026,\"start\":65024},{\"end\":65035,\"start\":65032},{\"end\":65384,\"start\":65379},{\"end\":65399,\"start\":65394},{\"end\":65412,\"start\":65407},{\"end\":65425,\"start\":65420},{\"end\":65437,\"start\":65433},{\"end\":65447,\"start\":65443},{\"end\":65463,\"start\":65460},{\"end\":65477,\"start\":65472},{\"end\":65485,\"start\":65481},{\"end\":65497,\"start\":65495},{\"end\":65501,\"start\":65499},{\"end\":65933,\"start\":65928},{\"end\":65945,\"start\":65941},{\"end\":65957,\"start\":65954},{\"end\":65967,\"start\":65961},{\"end\":65978,\"start\":65974},{\"end\":65996,\"start\":65985},{\"end\":66002,\"start\":65998},{\"end\":66416,\"start\":66395},{\"end\":66424,\"start\":66418},{\"end\":66431,\"start\":66428},{\"end\":66449,\"start\":66441},{\"end\":66464,\"start\":66459},{\"end\":66472,\"start\":66466},{\"end\":66803,\"start\":66793},{\"end\":66818,\"start\":66813},{\"end\":67404,\"start\":67395},{\"end\":67417,\"start\":67411},{\"end\":67436,\"start\":67429},{\"end\":67836,\"start\":67827},{\"end\":67849,\"start\":67843},{\"end\":67868,\"start\":67861},{\"end\":68263,\"start\":68260},{\"end\":68686,\"start\":68683},{\"end\":68699,\"start\":68695},{\"end\":68710,\"start\":68708},{\"end\":68726,\"start\":68721},{\"end\":68743,\"start\":68736},{\"end\":68758,\"start\":68752},{\"end\":69045,\"start\":69042},{\"end\":69055,\"start\":69052},{\"end\":69068,\"start\":69063},{\"end\":69080,\"start\":69078},{\"end\":69094,\"start\":69089},{\"end\":69106,\"start\":69102},{\"end\":69117,\"start\":69113},{\"end\":69129,\"start\":69124},{\"end\":69147,\"start\":69136},{\"end\":69165,\"start\":69157},{\"end\":69570,\"start\":69559},{\"end\":69587,\"start\":69577},{\"end\":69604,\"start\":69598},{\"end\":69946,\"start\":69938},{\"end\":69962,\"start\":69957},{\"end\":69974,\"start\":69969},{\"end\":69990,\"start\":69984},{\"end\":70749,\"start\":70742},{\"end\":70765,\"start\":70757},{\"end\":70779,\"start\":70774},{\"end\":71317,\"start\":71304},{\"end\":71330,\"start\":71326},{\"end\":71349,\"start\":71342},{\"end\":71793,\"start\":71783},{\"end\":71818,\"start\":71813},{\"end\":72301,\"start\":72294},{\"end\":72321,\"start\":72311},{\"end\":72566,\"start\":72559},{\"end\":72578,\"start\":72576},{\"end\":72591,\"start\":72586},{\"end\":72603,\"start\":72599},{\"end\":72617,\"start\":72611},{\"end\":72633,\"start\":72624},{\"end\":72921,\"start\":72915},{\"end\":72935,\"start\":72928},{\"end\":72949,\"start\":72942},{\"end\":72964,\"start\":72961},{\"end\":72979,\"start\":72973},{\"end\":72995,\"start\":72989},{\"end\":73007,\"start\":73003},{\"end\":73015,\"start\":73013},{\"end\":73028,\"start\":73025},{\"end\":73446,\"start\":73423},{\"end\":73459,\"start\":73456},{\"end\":73465,\"start\":73461},{\"end\":73928,\"start\":73923},{\"end\":73945,\"start\":73940},{\"end\":73951,\"start\":73947},{\"end\":74649,\"start\":74634},{\"end\":74667,\"start\":74662},{\"end\":74686,\"start\":74680},{\"end\":74705,\"start\":74694},{\"end\":74724,\"start\":74715},{\"end\":74743,\"start\":74733},{\"end\":74760,\"start\":74752},{\"end\":75072,\"start\":75065},{\"end\":75087,\"start\":75082},{\"end\":75100,\"start\":75094},{\"end\":75113,\"start\":75109},{\"end\":75129,\"start\":75122},{\"end\":75151,\"start\":75139},{\"end\":75166,\"start\":75159},{\"end\":75182,\"start\":75179},{\"end\":75198,\"start\":75194},{\"end\":75211,\"start\":75206},{\"end\":75635,\"start\":75632},{\"end\":75648,\"start\":75643},{\"end\":75657,\"start\":75653},{\"end\":75668,\"start\":75664},{\"end\":75681,\"start\":75676},{\"end\":75693,\"start\":75691},{\"end\":75707,\"start\":75702},{\"end\":75718,\"start\":75714},{\"end\":76042,\"start\":76039},{\"end\":76051,\"start\":76049},{\"end\":76061,\"start\":76059},{\"end\":76076,\"start\":76071},{\"end\":76086,\"start\":76083},{\"end\":76520,\"start\":76515},{\"end\":76536,\"start\":76530},{\"end\":76818,\"start\":76814},{\"end\":76831,\"start\":76828},{\"end\":76840,\"start\":76836},{\"end\":76852,\"start\":76849},{\"end\":77212,\"start\":77205},{\"end\":77225,\"start\":77218},{\"end\":77244,\"start\":77235},{\"end\":77948,\"start\":77940},{\"end\":77960,\"start\":77956},{\"end\":77977,\"start\":77968},{\"end\":77991,\"start\":77984},{\"end\":78008,\"start\":77995},{\"end\":78722,\"start\":78714},{\"end\":78739,\"start\":78732},{\"end\":78747,\"start\":78745},{\"end\":78760,\"start\":78754},{\"end\":79436,\"start\":79431},{\"end\":79678,\"start\":79673},{\"end\":79873,\"start\":79867},{\"end\":79889,\"start\":79882},{\"end\":79910,\"start\":79899},{\"end\":79927,\"start\":79917},{\"end\":80333,\"start\":80327},{\"end\":80350,\"start\":80340},{\"end\":80367,\"start\":80360},{\"end\":80386,\"start\":80375},{\"end\":80403,\"start\":80397},{\"end\":80760,\"start\":80753},{\"end\":80774,\"start\":80767},{\"end\":80787,\"start\":80781},{\"end\":80804,\"start\":80795},{\"end\":80817,\"start\":80812},{\"end\":80832,\"start\":80827},{\"end\":80847,\"start\":80841},{\"end\":80865,\"start\":80855},{\"end\":81228,\"start\":81225},{\"end\":81239,\"start\":81235},{\"end\":81249,\"start\":81245},{\"end\":81262,\"start\":81260},{\"end\":81276,\"start\":81272},{\"end\":81285,\"start\":81283},{\"end\":81298,\"start\":81296},{\"end\":81754,\"start\":81750},{\"end\":81769,\"start\":81763},{\"end\":81777,\"start\":81775},{\"end\":82360,\"start\":82357},{\"end\":82369,\"start\":82366},{\"end\":82740,\"start\":82736},{\"end\":82752,\"start\":82749},{\"end\":82761,\"start\":82758},{\"end\":83237,\"start\":83228},{\"end\":83251,\"start\":83243},{\"end\":83261,\"start\":83257},{\"end\":83786,\"start\":83783},{\"end\":83800,\"start\":83797},{\"end\":83810,\"start\":83808},{\"end\":83826,\"start\":83822},{\"end\":83842,\"start\":83836},{\"end\":83855,\"start\":83853},{\"end\":84223,\"start\":84219},{\"end\":84235,\"start\":84232},{\"end\":84248,\"start\":84244},{\"end\":84265,\"start\":84256},{\"end\":84273,\"start\":84269},{\"end\":84295,\"start\":84282},{\"end\":84299,\"start\":84297},{\"end\":84643,\"start\":84641},{\"end\":84657,\"start\":84653},{\"end\":84667,\"start\":84664},{\"end\":84683,\"start\":84679},{\"end\":85033,\"start\":85027},{\"end\":85045,\"start\":85043},{\"end\":85056,\"start\":85052},{\"end\":85067,\"start\":85065},{\"end\":85081,\"start\":85078},{\"end\":85094,\"start\":85091},{\"end\":85105,\"start\":85100},{\"end\":85114,\"start\":85112}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":56482376},\"end\":53922,\"start\":53326},{\"attributes\":{\"doi\":\"10.1109/ICSE.2013.6606617\",\"id\":\"b1\",\"matched_paper_id\":220663293},\"end\":54336,\"start\":53924},{\"attributes\":{\"doi\":\"10.1109/ICSE.2013.6606642\",\"id\":\"b2\",\"matched_paper_id\":15823436},\"end\":54852,\"start\":54338},{\"attributes\":{\"doi\":\"10.1109/ICSM.2015.7332454\",\"id\":\"b3\",\"matched_paper_id\":4499379},\"end\":55332,\"start\":54854},{\"attributes\":{\"id\":\"b4\"},\"end\":55593,\"start\":55334},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15978939},\"end\":56075,\"start\":55595},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":2583854},\"end\":56483,\"start\":56077},{\"attributes\":{\"doi\":\"10.1109/MSR.2015.21\",\"id\":\"b7\",\"matched_paper_id\":9094329},\"end\":56950,\"start\":56485},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":49333709},\"end\":57539,\"start\":56952},{\"attributes\":{\"doi\":\"arXiv:2005.14165\",\"id\":\"b9\"},\"end\":58009,\"start\":57541},{\"attributes\":{\"doi\":\"arXiv:1601.06733\",\"id\":\"b10\"},\"end\":58278,\"start\":58011},{\"attributes\":{\"doi\":\"arXiv:2112.14169\",\"id\":\"b11\"},\"end\":58538,\"start\":58280},{\"attributes\":{\"doi\":\"10.1145/3474624.3477063\",\"id\":\"b12\"},\"end\":58996,\"start\":58540},{\"attributes\":{\"doi\":\"10.1109/ICSE.2015.131\",\"id\":\"b13\",\"matched_paper_id\":29074469},\"end\":59507,\"start\":58998},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b14\"},\"end\":59876,\"start\":59509},{\"attributes\":{\"doi\":\"10.18653/v1/W19-8652\",\"id\":\"b15\",\"matched_paper_id\":207852642},\"end\":60517,\"start\":59878},{\"attributes\":{\"doi\":\"arXiv:2104.02443\",\"id\":\"b16\"},\"end\":61118,\"start\":60519},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.139\",\"id\":\"b17\",\"matched_paper_id\":211171605},\"end\":61875,\"start\":61120},{\"attributes\":{\"doi\":\"10.18653/v1/P16-1154\",\"id\":\"b18\",\"matched_paper_id\":8174613},\"end\":62592,\"start\":61877},{\"attributes\":{\"doi\":\"arXiv:2009.08366\",\"id\":\"b19\"},\"end\":63050,\"start\":62594},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":52219239},\"end\":63581,\"start\":63052},{\"attributes\":{\"doi\":\"10.1145/1810295.1810335\",\"id\":\"b21\",\"matched_paper_id\":10747140},\"end\":64035,\"start\":63583},{\"attributes\":{\"doi\":\"10.1109/WCRE.2010.13\",\"id\":\"b22\",\"matched_paper_id\":7843537},\"end\":64497,\"start\":64037},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1915014},\"end\":64693,\"start\":64499},{\"attributes\":{\"doi\":\"arXiv:1801.06146\",\"id\":\"b24\"},\"end\":64961,\"start\":64695},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":49584534},\"end\":65290,\"start\":64963},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":53670168},\"end\":65848,\"start\":65292},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":198229624},\"end\":66311,\"start\":65850},{\"attributes\":{\"doi\":\"arXiv:1909.05858\",\"id\":\"b28\"},\"end\":66715,\"start\":66313},{\"attributes\":{\"doi\":\"10.18653/v1/W18-2709\",\"id\":\"b29\",\"matched_paper_id\":44090489},\"end\":67341,\"start\":66717},{\"attributes\":{\"doi\":\"10.1145/2884781.2884840\",\"id\":\"b30\",\"matched_paper_id\":6147950},\"end\":67773,\"start\":67343},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":6147950},\"end\":68193,\"start\":67775},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":964287},\"end\":68568,\"start\":68195},{\"attributes\":{\"doi\":\"arXiv:2107.13586\",\"id\":\"b33\"},\"end\":69033,\"start\":68570},{\"attributes\":{\"doi\":\"arXiv:1907.11692\",\"id\":\"b34\"},\"end\":69492,\"start\":69035},{\"attributes\":{\"doi\":\"arXiv:2201.04837\",\"id\":\"b35\"},\"end\":69797,\"start\":69494},{\"attributes\":{\"doi\":\"10.1145/2597073.2597076\",\"id\":\"b36\",\"matched_paper_id\":3257395},\"end\":70637,\"start\":69799},{\"attributes\":{\"doi\":\"10.1109/SANER.2015.7081827\",\"id\":\"b37\",\"matched_paper_id\":14892409},\"end\":71208,\"start\":70639},{\"attributes\":{\"doi\":\"10.1109/TNNLS.2012.2199516\",\"id\":\"b38\",\"matched_paper_id\":14082811},\"end\":71715,\"start\":71210},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":6706547},\"end\":72226,\"start\":71717},{\"attributes\":{\"id\":\"b40\"},\"end\":72499,\"start\":72228},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":160025533},\"end\":72824,\"start\":72501},{\"attributes\":{\"doi\":\"arXiv:1910.10683\",\"id\":\"b42\"},\"end\":73315,\"start\":72826},{\"attributes\":{\"doi\":\"10.1109/MSR.2017.17\",\"id\":\"b43\",\"matched_paper_id\":12012722},\"end\":73863,\"start\":73317},{\"attributes\":{\"doi\":\"10.1145/2491411.2491444\",\"id\":\"b44\",\"matched_paper_id\":11163811},\"end\":74545,\"start\":73865},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":236217063},\"end\":75058,\"start\":74547},{\"attributes\":{\"doi\":\"arXiv:1811.02084\",\"id\":\"b46\"},\"end\":75552,\"start\":75060},{\"attributes\":{\"doi\":\"arXiv:2109.07055\",\"id\":\"b47\"},\"end\":75965,\"start\":75554},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":69522979},\"end\":76415,\"start\":75967},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":11855675},\"end\":76719,\"start\":76417},{\"attributes\":{\"doi\":\"10.1109/ACCESS.2019.2931579\",\"id\":\"b50\",\"matched_paper_id\":198897945},\"end\":77118,\"start\":76721},{\"attributes\":{\"doi\":\"10.1145/3377811.3380385\",\"id\":\"b51\",\"matched_paper_id\":211267959},\"end\":77859,\"start\":77120},{\"attributes\":{\"doi\":\"10.1145/1858996.1859006\",\"id\":\"b52\",\"matched_paper_id\":9790585},\"end\":78653,\"start\":77861},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.443\",\"id\":\"b53\",\"matched_paper_id\":218487168},\"end\":79373,\"start\":78655},{\"attributes\":{\"doi\":\"10.1145/382208.382523\",\"id\":\"b54\",\"matched_paper_id\":40109791},\"end\":79618,\"start\":79375},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":14526326},\"end\":79857,\"start\":79620},{\"attributes\":{\"doi\":\"arXiv:2201.06850\",\"id\":\"b56\"},\"end\":80274,\"start\":79859},{\"attributes\":{\"id\":\"b57\"},\"end\":80555,\"start\":80276},{\"attributes\":{\"id\":\"b58\"},\"end\":80717,\"start\":80557},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":13756489},\"end\":81140,\"start\":80719},{\"attributes\":{\"doi\":\"10.1145/3238147.3238206\",\"id\":\"b60\"},\"end\":81648,\"start\":81142},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.200\",\"id\":\"b61\",\"matched_paper_id\":219708650},\"end\":82349,\"start\":81650},{\"attributes\":{\"doi\":\"arXiv:1901.11196\",\"id\":\"b62\"},\"end\":82657,\"start\":82351},{\"attributes\":{\"doi\":\"10.1109/SANER.2015.7081848\",\"id\":\"b63\",\"matched_paper_id\":16690920},\"end\":83154,\"start\":82659},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":16482255},\"end\":83698,\"start\":83156},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":52988209},\"end\":84136,\"start\":83700},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":195069387},\"end\":84586,\"start\":84138},{\"attributes\":{\"doi\":\"10.1109/ICSME.2014.107\",\"id\":\"b67\",\"matched_paper_id\":2515326},\"end\":85016,\"start\":84588},{\"attributes\":{\"doi\":\"10.1109/JPROC.2020.3004555\",\"id\":\"b68\"},\"end\":85435,\"start\":85018}]", "bib_title": "[{\"end\":53400,\"start\":53326},{\"end\":53984,\"start\":53924},{\"end\":54462,\"start\":54338},{\"end\":54934,\"start\":54854},{\"end\":55652,\"start\":55595},{\"end\":56142,\"start\":56077},{\"end\":56556,\"start\":56485},{\"end\":57061,\"start\":56952},{\"end\":59084,\"start\":58998},{\"end\":59939,\"start\":59878},{\"end\":61187,\"start\":61120},{\"end\":61941,\"start\":61877},{\"end\":63096,\"start\":63052},{\"end\":63646,\"start\":63583},{\"end\":64118,\"start\":64037},{\"end\":64521,\"start\":64499},{\"end\":64991,\"start\":64963},{\"end\":65369,\"start\":65292},{\"end\":65919,\"start\":65850},{\"end\":66786,\"start\":66717},{\"end\":67385,\"start\":67343},{\"end\":67817,\"start\":67775},{\"end\":68249,\"start\":68195},{\"end\":69930,\"start\":69799},{\"end\":70732,\"start\":70639},{\"end\":71290,\"start\":71210},{\"end\":71776,\"start\":71717},{\"end\":72552,\"start\":72501},{\"end\":73410,\"start\":73317},{\"end\":73919,\"start\":73865},{\"end\":74624,\"start\":74547},{\"end\":76028,\"start\":75967},{\"end\":76505,\"start\":76417},{\"end\":76804,\"start\":76721},{\"end\":77196,\"start\":77120},{\"end\":77927,\"start\":77861},{\"end\":78705,\"start\":78655},{\"end\":79425,\"start\":79375},{\"end\":79667,\"start\":79620},{\"end\":80744,\"start\":80719},{\"end\":81741,\"start\":81650},{\"end\":82727,\"start\":82659},{\"end\":83222,\"start\":83156},{\"end\":83777,\"start\":83700},{\"end\":84210,\"start\":84138},{\"end\":84635,\"start\":84588}]", "bib_author": "[{\"end\":53423,\"start\":53402},{\"end\":54005,\"start\":53986},{\"end\":54021,\"start\":54005},{\"end\":54484,\"start\":54464},{\"end\":54953,\"start\":54936},{\"end\":54968,\"start\":54953},{\"end\":55419,\"start\":55408},{\"end\":55434,\"start\":55419},{\"end\":55448,\"start\":55434},{\"end\":55668,\"start\":55654},{\"end\":55683,\"start\":55668},{\"end\":55701,\"start\":55683},{\"end\":56160,\"start\":56144},{\"end\":56171,\"start\":56160},{\"end\":56179,\"start\":56171},{\"end\":56574,\"start\":56558},{\"end\":56592,\"start\":56574},{\"end\":56608,\"start\":56592},{\"end\":57078,\"start\":57063},{\"end\":57090,\"start\":57078},{\"end\":57108,\"start\":57090},{\"end\":57120,\"start\":57108},{\"end\":57135,\"start\":57120},{\"end\":57152,\"start\":57135},{\"end\":57176,\"start\":57152},{\"end\":57185,\"start\":57176},{\"end\":57602,\"start\":57580},{\"end\":57613,\"start\":57602},{\"end\":57628,\"start\":57613},{\"end\":57643,\"start\":57628},{\"end\":57660,\"start\":57643},{\"end\":57677,\"start\":57660},{\"end\":57697,\"start\":57677},{\"end\":57711,\"start\":57697},{\"end\":57726,\"start\":57711},{\"end\":57734,\"start\":57726},{\"end\":58079,\"start\":58063},{\"end\":58088,\"start\":58079},{\"end\":58104,\"start\":58088},{\"end\":58302,\"start\":58280},{\"end\":58321,\"start\":58302},{\"end\":58644,\"start\":58628},{\"end\":58658,\"start\":58644},{\"end\":58673,\"start\":58658},{\"end\":59103,\"start\":59086},{\"end\":59121,\"start\":59103},{\"end\":59135,\"start\":59121},{\"end\":59605,\"start\":59591},{\"end\":59621,\"start\":59605},{\"end\":59633,\"start\":59621},{\"end\":59653,\"start\":59633},{\"end\":59955,\"start\":59941},{\"end\":59973,\"start\":59955},{\"end\":59988,\"start\":59973},{\"end\":60664,\"start\":60648},{\"end\":60674,\"start\":60664},{\"end\":60687,\"start\":60674},{\"end\":60698,\"start\":60687},{\"end\":60711,\"start\":60698},{\"end\":60730,\"start\":60711},{\"end\":60747,\"start\":60730},{\"end\":60764,\"start\":60747},{\"end\":60779,\"start\":60764},{\"end\":61204,\"start\":61189},{\"end\":61214,\"start\":61204},{\"end\":61225,\"start\":61214},{\"end\":61235,\"start\":61225},{\"end\":61251,\"start\":61235},{\"end\":61262,\"start\":61251},{\"end\":61275,\"start\":61262},{\"end\":61285,\"start\":61275},{\"end\":61295,\"start\":61285},{\"end\":61308,\"start\":61295},{\"end\":61319,\"start\":61308},{\"end\":61954,\"start\":61943},{\"end\":61968,\"start\":61954},{\"end\":61977,\"start\":61968},{\"end\":61989,\"start\":61977},{\"end\":61993,\"start\":61989},{\"end\":62604,\"start\":62594},{\"end\":62620,\"start\":62604},{\"end\":62633,\"start\":62620},{\"end\":62644,\"start\":62633},{\"end\":62657,\"start\":62644},{\"end\":62667,\"start\":62657},{\"end\":62677,\"start\":62667},{\"end\":62690,\"start\":62677},{\"end\":62712,\"start\":62690},{\"end\":62716,\"start\":62712},{\"end\":63112,\"start\":63098},{\"end\":63129,\"start\":63112},{\"end\":63662,\"start\":63648},{\"end\":63676,\"start\":63662},{\"end\":63692,\"start\":63676},{\"end\":64134,\"start\":64120},{\"end\":64148,\"start\":64134},{\"end\":64162,\"start\":64148},{\"end\":64178,\"start\":64162},{\"end\":64540,\"start\":64523},{\"end\":64560,\"start\":64540},{\"end\":64772,\"start\":64757},{\"end\":64789,\"start\":64772},{\"end\":65002,\"start\":64993},{\"end\":65009,\"start\":65002},{\"end\":65018,\"start\":65009},{\"end\":65028,\"start\":65018},{\"end\":65037,\"start\":65028},{\"end\":65386,\"start\":65371},{\"end\":65401,\"start\":65386},{\"end\":65414,\"start\":65401},{\"end\":65427,\"start\":65414},{\"end\":65439,\"start\":65427},{\"end\":65449,\"start\":65439},{\"end\":65465,\"start\":65449},{\"end\":65479,\"start\":65465},{\"end\":65487,\"start\":65479},{\"end\":65499,\"start\":65487},{\"end\":65503,\"start\":65499},{\"end\":65935,\"start\":65921},{\"end\":65947,\"start\":65935},{\"end\":65959,\"start\":65947},{\"end\":65969,\"start\":65959},{\"end\":65980,\"start\":65969},{\"end\":65998,\"start\":65980},{\"end\":66004,\"start\":65998},{\"end\":66418,\"start\":66389},{\"end\":66426,\"start\":66418},{\"end\":66433,\"start\":66426},{\"end\":66451,\"start\":66433},{\"end\":66466,\"start\":66451},{\"end\":66474,\"start\":66466},{\"end\":66805,\"start\":66788},{\"end\":66820,\"start\":66805},{\"end\":67406,\"start\":67387},{\"end\":67419,\"start\":67406},{\"end\":67438,\"start\":67419},{\"end\":67838,\"start\":67819},{\"end\":67851,\"start\":67838},{\"end\":67870,\"start\":67851},{\"end\":68265,\"start\":68251},{\"end\":68688,\"start\":68675},{\"end\":68701,\"start\":68688},{\"end\":68712,\"start\":68701},{\"end\":68728,\"start\":68712},{\"end\":68745,\"start\":68728},{\"end\":68760,\"start\":68745},{\"end\":69047,\"start\":69035},{\"end\":69057,\"start\":69047},{\"end\":69070,\"start\":69057},{\"end\":69082,\"start\":69070},{\"end\":69096,\"start\":69082},{\"end\":69108,\"start\":69096},{\"end\":69119,\"start\":69108},{\"end\":69131,\"start\":69119},{\"end\":69149,\"start\":69131},{\"end\":69167,\"start\":69149},{\"end\":69572,\"start\":69551},{\"end\":69589,\"start\":69572},{\"end\":69606,\"start\":69589},{\"end\":69948,\"start\":69932},{\"end\":69964,\"start\":69948},{\"end\":69976,\"start\":69964},{\"end\":69992,\"start\":69976},{\"end\":70751,\"start\":70734},{\"end\":70767,\"start\":70751},{\"end\":70781,\"start\":70767},{\"end\":71319,\"start\":71292},{\"end\":71332,\"start\":71319},{\"end\":71351,\"start\":71332},{\"end\":71795,\"start\":71778},{\"end\":71805,\"start\":71795},{\"end\":71820,\"start\":71805},{\"end\":72303,\"start\":72289},{\"end\":72323,\"start\":72303},{\"end\":72568,\"start\":72554},{\"end\":72580,\"start\":72568},{\"end\":72593,\"start\":72580},{\"end\":72605,\"start\":72593},{\"end\":72619,\"start\":72605},{\"end\":72635,\"start\":72619},{\"end\":72923,\"start\":72909},{\"end\":72937,\"start\":72923},{\"end\":72951,\"start\":72937},{\"end\":72966,\"start\":72951},{\"end\":72981,\"start\":72966},{\"end\":72997,\"start\":72981},{\"end\":73009,\"start\":72997},{\"end\":73017,\"start\":73009},{\"end\":73030,\"start\":73017},{\"end\":73448,\"start\":73412},{\"end\":73461,\"start\":73448},{\"end\":73467,\"start\":73461},{\"end\":73930,\"start\":73921},{\"end\":73947,\"start\":73930},{\"end\":73953,\"start\":73947},{\"end\":74651,\"start\":74626},{\"end\":74669,\"start\":74651},{\"end\":74688,\"start\":74669},{\"end\":74707,\"start\":74688},{\"end\":74726,\"start\":74707},{\"end\":74745,\"start\":74726},{\"end\":74762,\"start\":74745},{\"end\":75074,\"start\":75060},{\"end\":75089,\"start\":75074},{\"end\":75102,\"start\":75089},{\"end\":75115,\"start\":75102},{\"end\":75131,\"start\":75115},{\"end\":75153,\"start\":75131},{\"end\":75168,\"start\":75153},{\"end\":75184,\"start\":75168},{\"end\":75200,\"start\":75184},{\"end\":75213,\"start\":75200},{\"end\":75637,\"start\":75628},{\"end\":75650,\"start\":75637},{\"end\":75659,\"start\":75650},{\"end\":75670,\"start\":75659},{\"end\":75683,\"start\":75670},{\"end\":75695,\"start\":75683},{\"end\":75709,\"start\":75695},{\"end\":75720,\"start\":75709},{\"end\":76044,\"start\":76030},{\"end\":76053,\"start\":76044},{\"end\":76063,\"start\":76053},{\"end\":76078,\"start\":76063},{\"end\":76088,\"start\":76078},{\"end\":76522,\"start\":76507},{\"end\":76538,\"start\":76522},{\"end\":76820,\"start\":76806},{\"end\":76833,\"start\":76820},{\"end\":76842,\"start\":76833},{\"end\":76854,\"start\":76842},{\"end\":77214,\"start\":77198},{\"end\":77227,\"start\":77214},{\"end\":77246,\"start\":77227},{\"end\":77950,\"start\":77929},{\"end\":77962,\"start\":77950},{\"end\":77979,\"start\":77962},{\"end\":77993,\"start\":77979},{\"end\":78010,\"start\":77993},{\"end\":78724,\"start\":78707},{\"end\":78741,\"start\":78724},{\"end\":78749,\"start\":78741},{\"end\":78762,\"start\":78749},{\"end\":79438,\"start\":79427},{\"end\":79680,\"start\":79669},{\"end\":79875,\"start\":79859},{\"end\":79891,\"start\":79875},{\"end\":79912,\"start\":79891},{\"end\":79929,\"start\":79912},{\"end\":80335,\"start\":80319},{\"end\":80352,\"start\":80335},{\"end\":80369,\"start\":80352},{\"end\":80388,\"start\":80369},{\"end\":80405,\"start\":80388},{\"end\":80762,\"start\":80746},{\"end\":80776,\"start\":80762},{\"end\":80789,\"start\":80776},{\"end\":80806,\"start\":80789},{\"end\":80819,\"start\":80806},{\"end\":80834,\"start\":80819},{\"end\":80849,\"start\":80834},{\"end\":80867,\"start\":80849},{\"end\":81230,\"start\":81221},{\"end\":81241,\"start\":81230},{\"end\":81251,\"start\":81241},{\"end\":81264,\"start\":81251},{\"end\":81278,\"start\":81264},{\"end\":81287,\"start\":81278},{\"end\":81300,\"start\":81287},{\"end\":81756,\"start\":81743},{\"end\":81771,\"start\":81756},{\"end\":81779,\"start\":81771},{\"end\":82362,\"start\":82351},{\"end\":82371,\"start\":82362},{\"end\":82742,\"start\":82729},{\"end\":82754,\"start\":82742},{\"end\":82763,\"start\":82754},{\"end\":83239,\"start\":83224},{\"end\":83253,\"start\":83239},{\"end\":83263,\"start\":83253},{\"end\":83788,\"start\":83779},{\"end\":83802,\"start\":83788},{\"end\":83812,\"start\":83802},{\"end\":83828,\"start\":83812},{\"end\":83844,\"start\":83828},{\"end\":83857,\"start\":83844},{\"end\":84225,\"start\":84212},{\"end\":84237,\"start\":84225},{\"end\":84250,\"start\":84237},{\"end\":84267,\"start\":84250},{\"end\":84275,\"start\":84267},{\"end\":84297,\"start\":84275},{\"end\":84301,\"start\":84297},{\"end\":84645,\"start\":84637},{\"end\":84659,\"start\":84645},{\"end\":84669,\"start\":84659},{\"end\":84685,\"start\":84669},{\"end\":85035,\"start\":85020},{\"end\":85047,\"start\":85035},{\"end\":85058,\"start\":85047},{\"end\":85069,\"start\":85058},{\"end\":85083,\"start\":85069},{\"end\":85096,\"start\":85083},{\"end\":85107,\"start\":85096},{\"end\":85116,\"start\":85107}]", "bib_venue": "[{\"end\":53674,\"start\":53557},{\"end\":55860,\"start\":55789},{\"end\":60165,\"start\":60089},{\"end\":62189,\"start\":62102},{\"end\":63366,\"start\":63256},{\"end\":66999,\"start\":66918},{\"end\":68001,\"start\":67944},{\"end\":68314,\"start\":68298},{\"end\":70185,\"start\":70091},{\"end\":71981,\"start\":71909},{\"end\":74166,\"start\":74058},{\"end\":76197,\"start\":76151},{\"end\":77455,\"start\":77352},{\"end\":78227,\"start\":78121},{\"end\":79054,\"start\":78931},{\"end\":81969,\"start\":81897},{\"end\":83418,\"start\":83336},{\"end\":53555,\"start\":53423},{\"end\":54106,\"start\":54046},{\"end\":54578,\"start\":54509},{\"end\":55073,\"start\":54993},{\"end\":55406,\"start\":55334},{\"end\":55787,\"start\":55701},{\"end\":56261,\"start\":56179},{\"end\":56696,\"start\":56627},{\"end\":57230,\"start\":57185},{\"end\":57578,\"start\":57541},{\"end\":58061,\"start\":58011},{\"end\":58384,\"start\":58337},{\"end\":58626,\"start\":58540},{\"end\":59228,\"start\":59156},{\"end\":59589,\"start\":59509},{\"end\":60087,\"start\":60008},{\"end\":60646,\"start\":60519},{\"end\":61474,\"start\":61354},{\"end\":62100,\"start\":62013},{\"end\":62795,\"start\":62732},{\"end\":63254,\"start\":63129},{\"end\":63782,\"start\":63715},{\"end\":64244,\"start\":64198},{\"end\":64578,\"start\":64560},{\"end\":64755,\"start\":64695},{\"end\":65112,\"start\":65037},{\"end\":65552,\"start\":65503},{\"end\":66065,\"start\":66004},{\"end\":66387,\"start\":66313},{\"end\":66916,\"start\":66840},{\"end\":67535,\"start\":67461},{\"end\":67942,\"start\":67870},{\"end\":68296,\"start\":68265},{\"end\":68673,\"start\":68570},{\"end\":69238,\"start\":69183},{\"end\":69549,\"start\":69494},{\"end\":70089,\"start\":70015},{\"end\":70900,\"start\":70807},{\"end\":71434,\"start\":71377},{\"end\":71907,\"start\":71820},{\"end\":72287,\"start\":72228},{\"end\":72646,\"start\":72635},{\"end\":72907,\"start\":72826},{\"end\":73567,\"start\":73486},{\"end\":74056,\"start\":73976},{\"end\":74781,\"start\":74762},{\"end\":75278,\"start\":75229},{\"end\":75626,\"start\":75554},{\"end\":76149,\"start\":76088},{\"end\":76551,\"start\":76538},{\"end\":76892,\"start\":76881},{\"end\":77350,\"start\":77269},{\"end\":78119,\"start\":78033},{\"end\":78929,\"start\":78791},{\"end\":79470,\"start\":79459},{\"end\":79721,\"start\":79680},{\"end\":80046,\"start\":79945},{\"end\":80317,\"start\":80276},{\"end\":80626,\"start\":80557},{\"end\":80916,\"start\":80867},{\"end\":81219,\"start\":81142},{\"end\":81895,\"start\":81808},{\"end\":82479,\"start\":82387},{\"end\":82882,\"start\":82789},{\"end\":83334,\"start\":83263},{\"end\":83898,\"start\":83857},{\"end\":84350,\"start\":84301},{\"end\":84779,\"start\":84707},{\"end\":85203,\"start\":85142}]"}}}, "year": 2023, "month": 12, "day": 17}