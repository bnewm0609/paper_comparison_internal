{"id": 214713520, "updated": "2023-10-06 17:07:55.93", "metadata": {"title": "BVI-DVC: A Training Database for Deep Video Compression", "authors": "[{\"first\":\"Di\",\"last\":\"Ma\",\"middle\":[]},{\"first\":\"Fan\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"David\",\"last\":\"Bull\",\"middle\":[\"R.\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 3, "day": 30}, "abstract": "Deep learning methods are increasingly being applied in the optimisation of video compression algorithms and can achieve significantly enhanced coding gains, compared to conventional approaches. Such approaches often employ Convolutional Neural Networks (CNNs) which are trained on databases with relatively limited content coverage. In this paper, a new extensive and representative video database, BVI-DVC, is presented for training CNN-based video compression systems, with specific emphasis on machine learning tools that enhance conventional coding architectures, including spatial resolution and bit depth up-sampling, post-processing and in-loop filtering. BVI-DVC contains 800 sequences at various spatial resolutions from 270p to 2160p and has been evaluated on ten existing network architectures for four different coding tools. Experimental results show that this database produces significant improvements in terms of coding gains over three existing (commonly used) image/video training databases under the same training and evaluation configurations. The overall additional coding improvements by using the proposed database for all tested coding modules and CNN architectures are up to 10.3% based on the assessment of PSNR and 8.1% based on VMAF.", "fields_of_study": "[\"Engineering\",\"Computer Science\"]", "external_ids": {"arxiv": "2003.13552", "mag": "3013522332", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tmm/MaZB22", "doi": "10.1109/tmm.2021.3108943"}}, "content": {"source": {"pdf_hash": "f6f02a6075a775af3eb291cd6c25cfc7f466644a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2003.13552v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2003.13552", "status": "GREEN"}}, "grobid": {"id": "d84e3956825b48e3439489b85620f249ae842b31", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f6f02a6075a775af3eb291cd6c25cfc7f466644a.txt", "contents": "\nBVI-DVC: A Training Database for Deep Video Compression\n\n\nDi Ma \nMember, IEEEFan Zhang \nFellow, IEEEDavid R Bull \nBVI-DVC: A Training Database for Deep Video Compression\n1Index Terms-Video databaseCNN trainingvideo compres- sion\nDeep learning methods are increasingly being applied in the optimisation of video compression algorithms and can achieve significantly enhanced coding gains, compared to conventional approaches. Such approaches often employ Convolutional Neural Networks (CNNs) which are trained on databases with relatively limited content coverage. In this paper, a new extensive and representative video database, BVI-DVC 1 , is presented for training CNN-based video compression systems, with specific emphasis on machine learning tools that enhance conventional coding architectures, including spatial resolution and bit depth up-sampling, post-processing and in-loop filtering. BVI-DVC contains 800 sequences at various spatial resolutions from 270p to 2160p and has been evaluated on ten existing network architectures for four different coding tools. Experimental results show that this database produces significant improvements in terms of coding gains over three existing (commonly used) image/video training databases under the same training and evaluation configurations. The overall additional coding improvements by using the proposed database for all tested coding modules and CNN architectures are up to 10.3% based on the assessment of PSNR and 8.1% based on VMAF.\n\nI. INTRODUCTION\n\nF ROM the introduction of the first international standard in 1984, video compression has played an essential role in the application and uptake of video technologies across film, television, terrestrial and satellite transmission, surveillance and particularly Internet video [1]. Inspired by recent breakthroughs in AI technology, deep learning methods such as Convolutional Neural Networks (CNNs) have been increasingly exploited into video coding algorithms [2] to provide significant coding gains compared to conventional approaches based on classic signal/image processing theory.\n\nIt is noted that these learning-based compression approaches demand volumes of training material much greater than typically used for conventional compression or existing machine learning methods. These should include diverse content covering different formats and video texture types. As far as we are aware, no such public data sets for this purpose currently exist, and most learning-based coding methods [3] have been currently trained on image or video databases, which were mainly designed for computer vision applications, e.g. superresolution. Most of these databases do not provide sufficient D. Ma, F. Zhang and D. R. Bull are with the Department of Electrical and Electronic Engineering, University of Bristol, Bristol, BS8 1UB, UK (e-mail: di.ma@bristol.ac.uk; fan.zhang@bristol.ac.uk; dave.bull@bristol.ac.uk). 1 The BVI-DVC database can be downloaded from: https://vilab.blogs. bristol.ac.uk/?p=2375. content coverage and diversity. As a result, the generalisation of networks cannot be ensured in the context of video coding, and the optimum performance of employed CNN networks has not been achieved when trained on these databases.\n\nIn this paper, a new video database, referred as BVI-DVC, is proposed for training CNN-based video coding algorithms, in particular those tools that enhance the performance of conventional compression algorithms. These include spatial resolution re-sampling, bit depth re-sampling, post-processing and in-loop filtering, all of which have achieved significant coding gains compared to other deep learning enhancements. BVI-DVC contains 800 progressive-scanned video clips at a wide range of spatial resolutions from 270p to 2160p, with diverse and representative content. To demonstrate its training effectiveness, compared to three commonly used training databases [4][5][6], BVI-DVC has been utilised to train ten popular CNN architectures [7][8][9][10][11][12][13][14][15][16] using four video coding tools: post-processing (PP), in-loop filtering (ILF), spatial resolution adaptation (SRA) and effective bit depth adaptation (EBDA). The resulting CNN-based coding tools were then integrated into the Test Model (HM 16.20) of the current High Efficiency Video Coding (HEVC) standard [17], and evaluated based on the Joint Video Experts Team (JVET) Common Test Conditions (CTC) [18].\n\nThe primary contributions of this paper are: 1) A publicly available video database (BVI-DVC) specifically developed for training deep video coding compression algorithms. 2) An analysis of the performance of BVI-DVC in the context of four compression tools compared with three existing (commonly used) databases. 3) A performance comparison of ten popular CNN architectures based on identical training materials and evaluation configurations. The remainder of the paper is structured as follows. Section II summarises the related work in deep learning-based video compression and commonly used image/video training databases. Section III introduces the proposed (BVI-DVC) video training database, while Section IV presents the experimental configurations employed for evaluating the effectiveness of the proposed database. The results and discussions are provided in Section V, and Section VI concludes the paper and presents some suggestions for future work.\n\nII. BACKGROUND With increasing spatial resolutions, higher frame rates, greater dynamic range and the requirement for multiple viewpoints, accompanied by dramatic increases in user numbers, video content has become the primary driver for increased internet bandwidth. How we represent and communicate video (via compression) is key in ensuring that the content is delivered at an appropriate quality, while maintaining compatibility with the transmission bandwidth.\n\nTo address this issue, ISO (MPEG) and ITU initiated the development of a new coding standard, Versatile Video Coding (VVC) [19] in 2018, targeting increased coding gain (by 30-50%) compared to the current HEVC standard. Concurrently, the Alliance for Open Media (AOM -formed in 2015) finalised an open-source, royalty-free media delivery solution (AV1) [20] in 2018, offering performance competitive with HEVC [21].\n\n\nA. Machine learning based compression\n\nImage and video compression based on deep neural networks has become a popular research topic offering evident enhancements over conventional coding tools for: intra prediction [22,23], motion estimation [24,25], transforms [26,27], quantisation [28], entropy coding [29,30], post-processing [31,32] and loop filtering [33,34]. New coding tools such as format adaptation [35][36][37] and virtual reference frame optimisation [25] have also been reported. Other work has implemented a complete coding framework based on neural networks using end-to-end training and optimisation [38][39][40][41][42]. It is noted that, despite their performance benefits, few of these approaches are currently being adopted by the latest VVC video coding standard. This is due to the high computational complexity and the large GPU memory requirements associated with CNN computation.\n\n\nB. Training Databases\n\nTraining databases are a critical component for optimising the performance of machine learning based algorithms. A well designed training database can ensure good model generalisation and avoid potential over-fitting problems [43,44]. As far as we are aware, there is no publicly available database which is specifically designed for learning-based video coding. Researchers, to date, have typically employed training databases developed for other purposes (such as super-resolution, frame interpolation and classification) for training. Notable publicly available image and video training databases are summarised below.\n\n\u2022 ImageNet [45] is a large image database primarily designed for visual object recognition. It contains more than 14 million RGB images at various spatial resolutions (up to 2848p) covering a wide range of natural content. It has also been used as a training database for single image super-resolution [12]. \u2022 DIV2K [4] contains 1000 RGB source images with a variety of content types, which was firstly developed for super-resolution. It has currently been employed as training material by several JVET proposals [46,47] and many other CNN-based coding algorithms [48,49]. \u2022 BSDS [50] is an image database originally developed for image segmentation. It contains 500 RGB images, and has been used to train CNN-based loop filters [33] for video coding. Comparing to DIV2K, BSDS has fewer source images and lower spatial resolution (481\u00d7321). \u2022 Vimeo [51] is a video database originally developed for training CNN-based optical flow and temporal superresolution approaches. It contains 89,800 sequences at spatial resolutions up to 448\u00d7256. A constraint is imposed on motion vector magnitudes between any two adjacent frames and content with dynamic textures has not been included in this database. Vimeo has not been frequently employed for deep learning based coding approaches and in particular has not been used for those approaches that exhibit superior improvements over standard video codecs (e.g. HEVC and VVC) [3]. \u2022 CD (Combined Database) in [6] is a video database combining source content from the LIVE Video Quality Assessment Database [52], MCL-V Database [53] and TUM 1080p Database [54] and has been employed to train CNN-based super-resolution approaches [6]. It contains 29 sequences at two different spatial resolutions, 1920\u00d71080 and 768\u00d7432. \u2022 REDS [5] is a video database developed for training video super-resolution algorithms [55], which contains 300 video clips with spatial resolution 1280\u00d7720. \u2022 UCF101 [56] is a large video training database initially designed for human action recognition, and has been frequently used for training CNN-based temporal frame interpolation and motion prediction approaches [57][58][59]. It contains 13320 videos collected from YouTube, which consist of 101 types of human actions. All the sequences in UCF-101 have a relatively low spatial resolution of 320\u00d7240. Modern video coding algorithms are required to process content with diverse texture types at high spatial resolutions and bit depths. For example, the standard test sequences included in the JVET Common Test Conditions (CTC) dataset include video clips at UHD resolution (2160p) at a bit depth of 10 bits, with various static and dynamic textures 2 . However none of the training databases mentioned above contain image or video content with high spatial resolution and bit depth, and most do not include any dynamic texture content.  [72], 3 from MCL-V [53], 2 from MCL-JCV [73], 2 from Netflix Chimera [74], 1 from the TUM HD databases [75], and 1 from the Ultra  Video Group-Tampere University database [76]. These sequences contain natural scenes and objects [5], e.g. mountains, oceans, animals, grass, trees, countryside, city streets, towns, buildings, institutes, facilities, parks, marketplaces, historical places, vehicles and colorful textured fabrics. Different texture types such as static texture, dynamic texture 2 , structure content and luminance-plain content are also included.\n\n\nIII. THE BVI-DVC VIDEO TRAINING DATABASE\n(a) Animal (b) Wood (c) Leaves (d) Mountain (e) Myanmar (f) Venice (g) Tall Buildings (h) Traffics (i) Market (j) Ferris Wheel (k) Room (l) Store (m) Bookcase (n) Toy (o) Scarf (p) Cross Walk (q) Plasma (r) Firewood (s) Smoke (t) Water\nAll these sequences are progressive-scanned at a spatial resolution of 3840\u00d72160, with frame rates ranging from 24 fps to 120 fps, a bit depth of 10 bit, and in YCbCr 4:2:0 format. All are truncated to 64 frames without scene cuts, using the segmentation method described in [77]. To further increase data diversity and provide data augmentation, the 200 video clips were spatially down-sample to 1920\u00d71080, 960\u00d7540 and 480\u00d7270 using a Lanczos filter of order 3. This results in 800 sequences at four different resolutions. Fig. 1 shows the sample frames of twenty example sequences. The primary features of this database are summarised in Table I  in Fig. 2. The definitions of these feature can be found in [67,78]. It can be noted that the BVI-DVC database has a relatively wide coverage for these three video features, which indicates the diversity of the proposed database.\n\n\nIV. EXPERIMENTS\n\nIn order to evaluate the training effectiveness of the proposed BVI-DVC database in the context of video compression, ten network architectures [7][8][9][10][11][12][13][14][15][16]79] were employed in conjunction with four CNN-based coding modules: post processing (PP), in-loop filtering (ILF), spatial resolution adaptation (SRA) and effective bit depth adaptation (EBDA). These four coding modules were selected since they have been demonstrated to offer significant coding gains over standardised video codecs compared to other tools (e.g. inter prediction, entropy coding, etc.) and also outperform existing end-to-end solutions. Compared to end-to-end image coding architectures, they are also more amenable to integration into standard codecs for practical applications.\n\nIn terms of benchmarking databases, based on the limited time and resource available, we have chosen one image database (DIV2K) and two video databases (REDS and CD) to compare with BVI-DVC. The DIV2K is selected because it has been used for training CNN models in multiple JVET contributions and many other CNN-based coding algorithms. Comparing to other video databases such as BSDS, Vimeo and UCF101, REDS and CD contain relatively higher resolution content and have been employed for training successful CNNbased super-resolution approaches.\n\nA. Coding Modules 1) Coding Module 1 (Post Processing -PP): The coding workflow for post processing (PP) is illustrated in Fig. 3. PP is commonly applied at the decoder, on the reconstructed video frames, to reduce compression artefacts and enhance video quality. When a CNN-based approach is employed, the network takes each decoded frame as input and outputs the final reconstructed frame with the same format. Notable examples of employing CNN-based post processing for video coding can be found in [31,32]. 2) Coding Module 2 (In-loop Filtering -ILF): In-loop filtering applies processing at both the encoder and the decoder on the reconstructed frames, and the output can be used as reference for further encoding/decoding. An encoder architecture with a CNN-based ILF module is shown in Fig. 4. The input and the output of the CNN-based ILF are the same as those for PP [33,80].\n\n3) Coding Module 3 (Spatial Resolution Adaptation -SRA): CNN-based spatial resolution adaptation (SRA) down-samples the spatial resolution of the original video frames for encoding, and reconstructs the full resolution during decoding through CNN-based super-resolution. This approach can be applied at Coding Tree Unit level [35] or to the whole frame. Here we only implemented frame-level SRA [81], as shown in Fig.  5. In this case, the original video frames are spatially downsampled by a fixed factor of 2, using the Lanczos3 filter. The CNN-based super-resolution module processes the compressed and down-sampled video frames at the decoder to generate full resolution reconstructed frames. It is noted that a nearest neighbour filter is firstly applied to the reconstructed downsampled video frame before CNN operation [36].\n\n\nInput Video\n\nSpatial Downsampling (Lanczos3 Filter) \n\n\nHost Encoder\n\n\n4) Coding Module 4 (Effective Bit Depth Adaptation -EBDA):\n\nSimilar to the case for spatial resolution, bit depth can also be adapted during encoding in order to achieve improved coding efficiency. Here Effective Bit Depth (EBD) is defined as the actual bit depth used to represent the video content, which may be different from the Coding Bit Depth (CBD) that represents the pixel bit depth, e.g. InternalBitDepth in HEVC reference encoders. This process is demonstrated in Fig. 6. In this paper, we have fixed CBD at 10 bits, the same as in the Main10 profile of HEVC, and only down-sampled the original frames by 1 bit through bit-shifting. At the decoder, the bit depth of decoded frames is up-sampled to 10 bits using a CNN-based approach. More information about EBDA can be found in [82].\n\n\nB. Employed CNN Models\n\nFor these four coding modules, ten popular network architectures have been implemented for evaluation. These include five with residual blocks, two with residual dense blocks, This network structure has been employed in several CNN-based coding algorithms and has been reported to offer significant coding gains [36].\n\nIn this experiment, we have employed identical architectures for these ten networks, as reported in their original publications, and only modify the input and output interfaces in order to process content in the appropriate format. The input of all CNNs employed is a 96\u00d796 YCbCr 4:4:4 colour image, while the output targets the corresponding original image block with the same size. The input block can be either compressed (for PP and ILF), compressed and EBD downsampled (for EBDA) or compressed and spatial resolution re-sampled (for SRA -a nearest neighbour filter is applied before CNN processing). The same loss functions have been used as in the corresponding literature. All these ten networks have been re-implemented using the TensorFlow framework (version 1.8.0).\n\n\nC. Training Data\n\nThree existing image and video databases are selected to benchmark the training effectiveness of BVI-DVC, including DIV2K [4], REDS [5] and CD [6]. All the original images or videos in each database were first spatially down-sampled by a factor of 2 using a Lanczos3 filter or down-sampled by 1 bit through bit-shifting. The original content (for training PP and ILF CNNs), together with spatially down-sampled clips (for training SRA CNNs) and bit depth reduced sequences (for training EBDA CNNs) were then compressed by the HEVC Test Model (HM 16.20) based on the JVET Common Test Conditions (CTC) [18] using the Random Access configuration (Main10 profile) with four base QP (quantisation parameter) values: 22, 27, 32 and 37 3 (a fixed QP offset of -6 is applied for both spatially and bit depth down-sampled cases as in [85]). This results in three training input content groups for every database, each of which contains four QP sub-groups. For the input content group with reduced spatial resolution, a nearest neighbour filter was applied to obtain video frames with the same size as the original content.\n\nFor each input group and QP sub-group, the video frames of all reconstructed sequences and their original counterparts were randomly selected (with the same spatial and temporal sampling rates) and split into 96\u00d796 image blocks, which were then converted to YCbCr 4:4:4 format. Block rotation was also applied here for data augmentation.\n\n\nD. Network Training and Evaluation\n\nThe training process was conducted using the following parameters: Adam optimisation [86] with the following hyperparameters: \u03b2 1 =0.9 and \u03b2 2 =0.999; batch size of 16; 200 training epochs; learning rate (0.0001); weight decay of 0.1 for every 100 epochs. This generates 480 CNN models for 4 training databases, 3 input content groups (PP and ILF use the same CNN models), 4 QP sub-groups and 10 tested network architectures.\n\nDuring the evaluation stage, for a specific coding module, the decoded video frames (already up-sampled to the same spatial resolution if needed) are firstly segmented into 96\u00d796 overlapping blocks with an overlap size of 4 pixels as CNN input (YCbCr 4:4:4 conversion). The output blocks are then aggregated following the same pattern and then converted to YCbCr 4:2:0 format to form the final reconstructed frame.\n\n\nV. RESULTS AND DISCUSSIONS\n\nFour different coding modules have been integrated into the HEVC (HM 16.20) reference software, and have been fully tested under JVET CTC [18] using the Random Access configuration (Main10 profile). Nineteen JVET-CTC SDR (standard dynamic range) video sequences from resolution classes A1, A2, B, C and D were employed as test content, none of which were included in any of the three training databases. It is noted that only class A1 and A2 (2160p) were used to evaluate SRA coding module, as it has been previously reported [36] that for lower resolutions SRA may provide limited and inconsistent coding gains.\n\nThe rate quality performance (coding performance) is benchmarked against the original HEVC HM 16.20, using Bj\u00f8ntegaard Delta measurement (BD-rate) [87] based on two quality metrics, Peak Signal-to-Noise Ratio (PSNR, Yluminance channel only) and Video Multimethod Assessment Fusion (VMAF, version 0.6.1) [88]. PSNR is the most commonly used assessment method for video compression, while VMAF is a machine learning based quality metric commercially used in streaming. VMAF combines multiple quality metrics and video features using a Support Vector Machine (SVM) regressor. It has been reported to offer better correlation with subjective opinions [89]. BD-rate statistics indicate the overall bitrate savings across the tested QP range achieved by the test algorithm for the same video quality compared to the anchor approach. The average BD-rate values are reported in Table II-V for each evaluated training database, network architecture and coding module.\n\n\nA. Comparison of Databases\n\nIt can be observed from Table II-V and Fig. 7 that, for all tested network architectures and coding modules, the coding gains (in terms of average BD-rates for all tested sequences) achieved after training on the proposed BVI-DVC database are significantly greater than for the other three benchmark databases (DIV2K, REDS and CD) for both PSNR and VMAF quality metrics. This is reinforced by considering the mean (among ten networks and four coding modules) of all the average BD-rates for each database; Fig. 8 shows in excess of 4.2% and 5.4% additional bitrate savings obtained by using BVI-DVC compared to the other three databases based on the PSNR and VMAF quality metrics respectively. CD offers the worse overall performance, especially for results based on the assessment of PSNR.\n\n\nB. Comparison of Networks\n\nWe can also compare the ten evaluated network architectures under fair configurations (identical training and evaluation databases). The results in Table II-V are summarised, by taking the mean (among four training databases and four coding modules) of average BD-rate values for each network architecture, in Fig. 9. It can be observed that RCAN, RDN, ESRResNet and MSRResNet offer better coding performance (for both PSNR and VMAF) than the other six evaluated network architectures. This is likely to be because of the residual block structure employed. The coding gains for VDSR, FSRCNN and SRCNN are relatively low comparing to other networks, exhibiting coding loss when PSNR is used to assess video quality especially when they are trained on the CD database (refer to Fig. 7). This may be due to their simple network architecture (FSRCNN and SRCNN) and the large number convolutional layers without residual learning structure (VDSR), which lead to less stable training and evaluation [14,15].\n\n\nVI. CONCLUSION\n\nThis paper presents a new database (BVI-DVC) specifically designed for training CNN-based video compression algorithms. With carefully selected sequences including diverse content, this database offers significantly improved training effectiveness compared to other commonly used image and video training databases. It has been evaluated for four different coding modules with ten typical CNN architectures. The BVI-DVC database reported is available online 1 for public testing. Its content diversity makes it a reliable training database, not just for CNN-based compression approaches, but also for other computer vision and image processing related tasks, such as image/video de-noising, video frame interpolation and super-resolution. Future work should focus on developing large training databases with more immersive video formats, including higher dynamic range, higher frame rates and higher spatial resolutions.    \n\nFig. 1 :\n1Sample frames of 20 example sequences from the BVI-DVC database.\n\nFig. 2 :\n2alongside those for the other seven databases[4-6, 45, 50, 51, 56]   mentioned above.Three low-level video features of all 200 UHD source sequences, spatial information (SI), temporal information (TI) and colourfulness (CF) have been also calculated and plotted Scatter plots of three video features for 200 UHD source sequences in the BVI-DVC database.\n\nFig. 3 :\n3Coding workflow with a CNN-based post processing module.\n\nFig. 5 :\n5Coding workflow with a CNN-based spatial resolution adaptation module.\n\nFig. 8 :\n8Average BD-rate (based on PSNR and VMAF) of four tested training databases for all the evaluated coding modules and CNN architectures.\n\nFig. 9 :\n9Average BD-rate (based on PSNR and VMAF) of 10 test network architectures for all coding modules and training databases.\n\n\nTwo hundred source sequences were carefully selected from public video databases, including 69 sequences from the Videvo Free Stock Video Footage set [62], 37 from the IRIS32 Free 4K Footage set [63], 25 from the Harmonics database [64], 19 from BVI-Texture [65], 10 from the MCML 4K video quality database [66], 7 from BVI-HFR [67], 7 from the SJTU 4K video database [68], 6 from LIVE-Netflix [69, 70], 6 from the Mitch Martinez Free 4K Stock Footage set [71], 5 from the Dareful Free 4K Stock Video data set\n\nTABLE I :\nIKey features of eight training databases including BVI-DVC.Features \nImageNet [45] \nDIV2K [4] \nBSDS [50] \nVimeo [51] \nCD [6] \nREDS [5] \nUCF101 [56] \nBVI-DVC \n\nImage or Video? \nImage \nImage \nImage \nVideo \nVideo \nVideo \nVideo \nVideo \n\nSeq Number \n14M \n1000 \n500 \n89,800 \n29 \n300 \n13,320 \n800 \n\nMax Resolution \n2848p \n1152p \n321p \n256p \n1080p \n720p \n240p \n2160p \n\nBit depth \n8 \n8 \n8 \n8 \n8 \n8 \n8 \n10 \n\nVarious textures? \nNo \nNo \nNo \nNo \nNo \nNo \nNo \nYes \n\n\n\n\nFSRCNN[8] (trained by MSE loss) was also developed for SISR, containing 8 convolutional layers with various kernel sizes. \u2022 VDSR[9] (trained by MSE loss) contains 20 convolutional layers employing global residual learning to achieve enhanced performance. However it does not employ residual blocks[83], which may lead to unstable training and evaluation performance[10]. \u2022 SRResNet[12] (trained by MSE loss) was the first network structure with residual blocks designed for SISR, improving the overall performance and stability of the network. \u2022 DRRN[10] (trained by MSE loss) employs a recursive structure and also contains residual blocks. \u2022 EDSR[11] (trained by 1 loss) significantly increases MSRResNet[16] (trained by 1 loss) modified SRRes-Net by removing the BN layers for all the residual blocks.Input Video \n(EBD=CBD=10bit) \n\nBit Depth \nDown-sampling \n(Bit-shifting) \n\nBitstream \n\nHost Encoder \n(CBD=10bit, \nEBD=9bit) \n\nHost Decoder \n(CBD=10bit, \nEBD=9bit) \n\nBit Depth Down-\nsampled Video \n(EBD=9bit) \n\nDecoded Video \n(EBD=9bit) \n\nCNN-based \nBit Depth \nUp-sampling \n\nFinal Reconstructed Video \n(EBD=CBD=10bit) \n\nFig. 6: Coding workflow with a CNN-based effective bit depth adap-\ntation module. \n\nand three without any residual block structure. Most of \nthese network structures were initially designed for super-\nresolution processing or image enhancement, and some have \nbeen employed in CNN-based coding approaches as described \nin Section II. Their primary features are briefly described \nbelow: \n\n\u2022 SRCNN [7] (trained by mean-squared-error (MSE) loss) \nis the first CNN model designed for single image super \nresolution (SISR). It employs a simple network structure \nwith only 3 convolutional layers. \n\u2022 the number of feature maps (256) for the convolutional \nlayers in each residual block. It offers improved overall \nperformance but with much higher computational com-\nplexity. \n\u2022 RDN [15] (trained by 1 loss) was the first network archi-\ntecture to combine residual block and dense connections \n[84] for SISR. \n\u2022 ESRResNet [13] (trained by 1 loss) enhances SRResNet \nby combining residual blocks with dense connections, \nand employs residual learning at multiple levels. It also \nremoves the batch normalisation (BN) layer used in SR-\nResNet to further stabilise training and reduce artefacts. \n\u2022 RCAN [14] (trained by 1 loss) incorporates a channel \nattention (CA) scheme in the CNN, which better recovers \nhigh frequency texture details. \n\u2022 \n\nTABLE II :\nIIEvaluation results for PP coding module for ten tested network architectures and four different training databases.Values indicate \nthe average BD-rate (%) for all nineteen JVET CTC tested sequences assessed by PSNR or VMAF. \n\nCNN Model (PP) \nDIV2K [4] \nREDS [5] \nCD [6] \nBVI-DVC \n\nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n\nSRCNN [7] \n0.4 \n-2.8 \n2.5 \n-3.8 \n11.0 \n-6.2 \n-1.9 \n-7.4 \n\nFSRCNN [8] \n0.7 \n-2.6 \n3.2 \n-1.2 \n24.4 \n2.6 \n-1.6 \n-7.3 \n\nVDSR [9] \n0.3 \n-2.9 \n2.3 \n-4.0 \n3.1 \n-2.2 \n-1.9 \n-7.6 \n\nDRRN [10] \n-5.0 \n-6.1 \n-4.7 \n-8.2 \n0.4 \n-1.1 \n-10.8 \n-14.9 \n\nEDSR [11] \n-5.4 \n-4.9 \n-3.1 \n-6.1 \n-0.8 \n-6.5 \n-10.0 \n-14.6 \n\nSRResNet [12] \n-5.3 \n-5.4 \n-4.0 \n-9.0 \n4.0 \n-3.8 \n-9.8 \n-12.7 \n\nESRResNet [13] \n-6.9 \n-6.7 \n-6.1 \n-9.4 \n-3.5 \n-9.1 \n-11.8 \n-17.7 \n\nRCAN [14] \n-6.6 \n-7.3 \n-6.3 \n-9.7 \n-4.5 \n-11.0 \n-12.1 \n-18.5 \n\nRDN [15] \n-7.0 \n-7.2 \n-6.9 \n-10.6 \n-4.6 \n-10.9 \n-12.2 \n-17.0 \n\nMSRResNet [16] \n-6.4 \n-6.5 \n-5.3 \n-9.2 \n-2.6 \n-8.7 \n-10.4 \n-14.2 \n\n\n\nTABLE III :\nIIIEvaluation results for ILF coding module for ten tested network architectures and four different databases. Each value indicates the average BD-rate (%) for all nineteen JVET CTC tested sequences assessed by PSNR or VMAF.Fig. 7: Average coding gains for four coding modules obtained using 10 commonly employed network architectures trained on four different databases: BVI-DVC, DIV2K [4], REDS [5] and CD [6] All methods are integrated into HEVC Test Model (HM 16.20).CNN Model (ILF) \nDIV2K [4] \nREDS [5] \nCD [6] \nBVI-DVC \n\nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n\nSRCNN [7] \n-0.2 \n-2.6 \n-0.6 \n-2.5 \n-0.1 \n-1.4 \n-1.4 \n-8.5 \n\nFSRCNN [8] \n-0.1 \n-2.2 \n-0.2 \n-1.1 \n0.0 \n-0.5 \n-1.3 \n-8.1 \n\nVDSR [9] \n-1.0 \n-1.1 \n-0.7 \n-2.7 \n0.0 \n-0.5 \n-2.2 \n-6.5 \n\nDRRN [10] \n-4.0 \n-5.6 \n-3.1 \n-4.6 \n0.4 \n-1.1 \n-6.8 \n-11.0 \n\nEDSR [11] \n-4.5 \n-6.1 \n-2.7 \n-3.1 \n-1.3 \n-4.0 \n-5.9 \n-9.9 \n\nSRResNet [12] \n-5.1 \n-8.6 \n-2.9 \n-4.0 \n-1.1 \n-2.8 \n-6.4 \n-10.6 \n\nESRResNet [13] \n-5.8 \n-8.6 \n-3.3 \n-5.1 \n-2.5 \n-6.8 \n-7.3 \n-12.0 \n\nRCAN [14] \n-5.4 \n-8.5 \n-6.3 \n-9.7 \n-3.0 \n-8.5 \n-7.4 \n-11.4 \n\nRDN [15] \n-5.8 \n-8.8 \n-3.7 \n-5.6 \n-3.0 \n-8.9 \n-7.5 \n-11.8 \n\nMSRResNet [16] \n-5.6 \n-9.4 \n-4.6 \n-6.7 \n-2.0 \n-6.5 \n-6.4 \n-11.3 \n\nSRCNN \n\nFSRCNN \n\nVDSR \n\nEDSR \n\nSRResNet \n\nMSRResNet \n\nDRRN \n\nESRResNet \n\nRDN \n\nRCAN \n\n-15% \n-10% \n-5% \n0% \n5% \n10% \n15% \n20% \nAverage BD-rate (PSNR) \n\nDIV2K \nREDS \nCD \nBVI-DVC \n\nVDSR \n\nFSRCNN \n\nSRCNN \n\nSRResNet \n\nEDSR \n\nMSRResNet \n\nDRRN \n\nESRResNet \n\nRDN \n\nRCAN \n\n-25% \n-20% \n-15% \n-10% \n-5% \n0% \n5% \nAverage BD-rate (VMAF) \n\nDIV2K \nREDS \nCD \nBVI-DVC \n\n\n\nTABLE IV :\nIVEvaluation results for SRA coding module for ten tested network architectures and four different databases.. Each value indicates the average BD-rate (%) for all six UHD JVET CTC tested sequences assessed by PSNR or VMAF.CNN Model (SRA) \nDIV2K [4] \nREDS [5] \nCD [6] \nBVI-DVC \n\nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n\nSRCNN [7] \n3.9 \n-11.9 \n8.6 \n-19.6 \n6.6 \n-12.4 \n-3.1 \n-21.1 \n\nFSRCNN [8] \n1.1 \n-12.3 \n-0.3 \n-18.0 \n9.9 \n-9.8 \n-4.5 \n-20.9 \n\nVDSR [9] \n4.4 \n-11.5 \n4.3 \n-15.9 \n25.9 \n7.2 \n-6.6 \n-18.3 \n\nDRRN [10] \n-8.5 \n-17.6 \n-7.8 \n-26.1 \n-7.2 \n-22.1 \n-15.0 \n-33.2 \n\nEDSR [11] \n-6.4 \n-16.3 \n-6.9 \n-26.1 \n-3.2 \n-20.4 \n-13.4 \n-30.1 \n\nSRResNet [12] \n-6.7 \n-11.5 \n-7.0 \n-28.1 \n-5.5 \n-19.8 \n-13.2 \n-30.0 \n\nESRResNet [13] \n-9.9 \n-19.4 \n-9.9 \n-31.7 \n-7.8 \n-23.5 \n-16.1 \n-33.6 \n\nRCAN [14] \n-10.2 \n-19.3 \n-10.9 \n-32.2 \n-8.4 \n-23.2 \n-17.1 \n-35.1 \n\nRDN [15] \n-10.0 \n-19.1 \n-9.7 \n-31.4 \n-8.4 \n-22.7 \n-16.6 \n-34.5 \n\nMSRResNet [16] \n-9.2 \n-18.9 \n-8.5 \n-29.9 \n-7.1 \n-22.8 \n-14.6 \n-32.7 \nVDSR \n\nFSRCNN \n\nSRCNN \n\nSRResNet \n\nEDSR \n\nDRRN \n\nMSRResNet \n\nESRResNet \n\nRDN \n\nRCAN \n\n-8% \n-6% \n-4% \n-2% \n0% \n2% \n4% \n6% \nAverage BD-rate (PSNR) of 10 CNN models \n\nVDSR \n\nFSRCNN \n\nSRCNN \n\nSRResNet \n\nEDSR \n\nDRRN \n\nMSRResNet \n\nESRResNet \n\nRDN \n\nRCAN \n\n-16% \n-14% \n-12% \n-10% \n-8% \n-6% \n-4% \nAverage BD-rate (VMAF) of 10 CNN models \n\n\n\nTABLE V :\nVEvaluation results for EBDA coding module for ten tested network architectures and four different databases. Each value indicates the average BD-rate (%) for all nineteen JVET CTC tested sequences assessed by PSNR or VMAF.CNN Model (EBDA) \nDIV2K [4] \nREDS [5] \nCD [6] \nBVI-DVC \n\nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \nBD-rate \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n(PSNR) \n(VMAF) \n\nSRCNN [7] \n-0.1 \n-7.6 \n2.6 \n-7.0 \n11.9 \n-10.0 \n-2.1 \n-11.0 \n\nFSRCNN [8] \n0.1 \n-6.7 \n3.7 \n-5.2 \n28.0 \n-0.4 \n-2.9 \n-11.5 \n\nVDSR [9] \n0.93 \n-6.8 \n19.6 \n-4.5 \n23.0 \n-0.13 \n-5.6 \n-9.1 \n\nDRRN [10] \n-6.0 \n-10.8 \n-3.7 \n-9.8 \n-1.1 \n-11.3 \n-11.8 \n-18.4 \n\nEDSR [11] \n-6.1 \n-11.5 \n-3.6 \n-11.1 \n-0.2 \n-9.6 \n-10.3 \n-17.7 \n\nSRResNet [12] \n-5.9 \n-10.4 \n0.5 \n-9.2 \n2.1 \n-7.0 \n-10.5 \n-15.9 \n\nESRResNet [13] \n-7.1 \n-11.3 \n-4.1 \n-11.0 \n-2.0 \n-13.8 \n-12.0 \n-19.0 \n\nRCAN [14] \n-7.6 \n-11.0 \n-5.2 \n-11.7 \n-1.4 \n-12.3 \n-12.5 \n-19.8 \n\nHere we follow the definition of textures in[60,61]. Static textures are associated with rigid patterns undergoing simple movement or subject to camera movement, while dynamic textures have complex and irregular movements, e.g. water, fire or steam.\nHere results with four QP values are generated due to the limited time and resource given. During evaluation, if the base QP is different from these four, the CNN model for the closest QP value will be used.\nACKNOWLEDGMENTThe authors acknowledge funding from UK EPSRC (EP/L016656/1 and EP/M000885/1) and the NVIDIA GPU Seeding Grants.\nCommunicating pictures: A course in Image and Video Coding. D R Bull, Academic PressD. R. Bull, Communicating pictures: A course in Image and Video Coding. Academic Press, 2014.\n\nImage and video compression with neural networks: A review. S Ma, X Zhang, C Jia, Z Zhao, S Wang, S Wanga, IEEE Transactions on Circuits and Systems for Video Technology. S. Ma, X. Zhang, C. Jia, Z. Zhao, S. Wang, and S. Wanga, \"Image and video compression with neural networks: A re- view,\" IEEE Transactions on Circuits and Systems for Video Technology, 2019.\n\nDeep learning-based video coding: A review and a case study. D Liu, Y Li, J Lin, H Li, F Wu, ACM Computing Surveys (CSUR). 531D. Liu, Y. Li, J. Lin, H. Li, and F. Wu, \"Deep learning-based video coding: A review and a case study,\" ACM Computing Surveys (CSUR), vol. 53, no. 1, pp. 1-35, 2020.\n\nNTIRE 2017 challenge on single image super-resolution: Dataset and study. E Agustsson, R Timofte, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. the IEEE Conference on Computer Vision and Pattern Recognition WorkshopsCVPRWE. Agustsson and R. Timofte, \"NTIRE 2017 challenge on single image super-resolution: Dataset and study,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recog- nition Workshops (CVPRW), July 2017.\n\nNTIRE 2019 challenge on video deblurring and super-resolution: Dataset and study. S Nah, S Baik, S Hong, G Moon, S Son, R Timofte, K. Mu Lee, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. the IEEE Conference on Computer Vision and Pattern Recognition WorkshopsCVPRWS. Nah, S. Baik, S. Hong, G. Moon, S. Son, R. Timofte, and K. Mu Lee, \"NTIRE 2019 challenge on video deblurring and super-resolution: Dataset and study,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2019, pp. 0-0.\n\nRobust video super-resolution with learned temporal dynamics. D Liu, Z Wang, Y Fan, X Liu, Z Wang, S Chang, T Huang, Proceedings of the IEEE International Conference on Computer Vision (ICCV. the IEEE International Conference on Computer Vision (ICCVD. Liu, Z. Wang, Y. Fan, X. Liu, Z. Wang, S. Chang, and T. Huang, \"Robust video super-resolution with learned temporal dynamics,\" in Proceedings of the IEEE International Confer- ence on Computer Vision (ICCV), 2017, pp. 2507-2515.\n\nImage superresolution using deep convolutional networks. C Dong, C C Loy, K He, X Tang, IEEE transactions on pattern analysis and machine intelligence. 38C. Dong, C. C. Loy, K. He, and X. Tang, \"Image super- resolution using deep convolutional networks,\" IEEE transac- tions on pattern analysis and machine intelligence, vol. 38, no. 2, pp. 295-307, 2015.\n\nAccelerating the superresolution convolutional neural network. C Dong, C C Loy, X Tang, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)SpringerC. Dong, C. C. Loy, and X. Tang, \"Accelerating the super- resolution convolutional neural network,\" in Proceedings of the European Conference on Computer Vision (ECCV). Springer, 2016, pp. 391-407.\n\nAccurate image super-resolution using very deep convolutional networks. J Kim, J Lee, K. Mu Lee, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)J. Kim, J. Kwon Lee, and K. Mu Lee, \"Accurate image super-resolution using very deep convolutional networks,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 1646-1654.\n\nImage super-resolution via deep recursive residual network. Y Tai, J Yang, X Liu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR. the IEEE Conference on Computer Vision and Pattern Recognition (CVPRY. Tai, J. Yang, and X. Liu, \"Image super-resolution via deep recursive residual network,\" in Proceedings of the IEEE Con- ference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 3147-3155.\n\nEnhanced deep residual networks for single image super-resolution. B Lim, S Son, H Kim, S Nah, K. Mu Lee, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. the IEEE Conference on Computer Vision and Pattern Recognition WorkshopsCVPRWB. Lim, S. Son, H. Kim, S. Nah, and K. Mu Lee, \"Enhanced deep residual networks for single image super-resolution,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2017, pp. 136-144.\n\nPhoto-realistic single image super-resolution using a generative adversarial network. C Ledig, L Theis, F Husz\u00e1r, J Caballero, A Cunningham, A Acosta, A Aitken, A Tejani, J Totz, Z Wang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionC. Ledig, L. Theis, F. Husz\u00e1r, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang et al., \"Photo-realistic single image super-resolution using a generative adversarial network,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 4681-4690.\n\nESRGAN: Enhanced super-resolution generative adversarial networks. X Wang, K Yu, S Wu, J Gu, Y Liu, C Dong, Y Qiao, C. Change Loy, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)X. Wang, K. Yu, S. Wu, J. Gu, Y. Liu, C. Dong, Y. Qiao, and C. Change Loy, \"ESRGAN: Enhanced super-resolution gen- erative adversarial networks,\" in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 0-0.\n\nImage super-resolution using very deep residual channel attention networks. Y Zhang, K Li, K Li, L Wang, B Zhong, Y Fu, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Y. Zhang, K. Li, K. Li, L. Wang, B. Zhong, and Y. Fu, \"Image super-resolution using very deep residual channel attention networks,\" in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 286-301.\n\nResidual dense network for image super-resolution. Y Zhang, Y Tian, Y Kong, B Zhong, Y Fu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Y. Zhang, Y. Tian, Y. Kong, B. Zhong, and Y. Fu, \"Residual dense network for image super-resolution,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recog- nition (CVPR), 2018, pp. 2472-2481.\n\nPerceptuallyinspired super-resolution of compressed videos. D Ma, M F Afonso, F Zhang, D R Bull, Applications of Digital Image Processing XLII. 11137D. Ma, M. F. Afonso, F. Zhang, and D. R. Bull, \"Perceptually- inspired super-resolution of compressed videos,\" in Applications of Digital Image Processing XLII, vol. 11137. International Society for Optics and Photonics, 2019, pp. 310-318.\n\nHigh Efficiency Video Coding. . H Itu-T Rec, ITU-T Std. ITU-T Rec. H.265, \"High Efficiency Video Coding,\" ITU-T Std., (2015).\n\nJVET common test conditions and software reference configurations for SDR video. F Bossen, J Boyce, X Li, V Seregin, K Suhring, the JVET meeting, no. JVET-M1001. ITU-T, ISO/IEC. F. Bossen, J. Boyce, X. Li, V. Seregin, and K. Suhring, \"JVET common test conditions and software reference configurations for SDR video,\" in the JVET meeting, no. JVET-M1001. ITU- T, ISO/IEC, 2019.\n\nVersatile Video Coding (Draft 10). B Bross, J Chen, S Liu, Y.-K Wang, JVET-S2001. ITU-T and ISO/IEC. 2020B. Bross, J. Chen, S. Liu, and Y.-K. Wang, \"Versatile Video Coding (Draft 10),\" in JVET-S2001. ITU-T and ISO/IEC, 2020.\n\n. AOMedia Video. 1AV1AOMedia Video 1 (AV1), https://aomedia.googlesource.com/.\n\nA subjective comparison of AV1 and HEVC for adaptive video streaming. A V Katsenou, F Zhang, M Afonso, D R Bull, 2019 IEEE International Conference on Image Processing (ICIP). IEEEA. V. Katsenou, F. Zhang, M. Afonso, and D. R. Bull, \"A subjective comparison of AV1 and HEVC for adaptive video streaming,\" in 2019 IEEE International Conference on Image Processing (ICIP). IEEE, 2019, pp. 4145-4149.\n\nHEVC intra frame coding based on convolutional neural network. C.-H Yeh, Z.-T Zhang, M.-J Chen, C.-Y. Lin, IEEE Access. 695C.-H. Yeh, Z.-T. Zhang, M.-J. Chen, and C.-Y. Lin, \"HEVC intra frame coding based on convolutional neural network,\" IEEE Access, vol. 6, pp. 50 087-50 095, 2018.\n\nFully connected network-based intra prediction for image coding. J Li, B Li, J Xu, R Xiong, W Gao, IEEE Transactions on Image Processing. 277J. Li, B. Li, J. Xu, R. Xiong, and W. Gao, \"Fully connected network-based intra prediction for image coding,\" IEEE Trans- actions on Image Processing, vol. 27, no. 7, pp. 3236-3247, 2018.\n\nEnhanced bi-prediction with convolutional neural network for High Efficiency Video Coding. Z Zhao, S Wang, S Wang, X Zhang, S Ma, J Yang, IEEE Transactions on Circuits and Systems for Video Technology. Z. Zhao, S. Wang, S. Wang, X. Zhang, S. Ma, and J. Yang, \"Enhanced bi-prediction with convolutional neural network for High Efficiency Video Coding,\" IEEE Transactions on Circuits and Systems for Video Technology, 2018.\n\nEnhanced motion-compensated video coding with deep virtual reference frame generation. L Zhao, S Wang, X Zhang, S Wang, S Ma, W Gao, IEEE Transactions on Image Processing. L. Zhao, S. Wang, X. Zhang, S. Wang, S. Ma, and W. Gao, \"Enhanced motion-compensated video coding with deep virtual reference frame generation,\" IEEE Transactions on Image Pro- cessing, 2019.\n\nCNN-based transform index prediction in multiple transforms framework to assist. S Puri, S Lasserre, P Le Callet, S. Puri, S. Lasserre, and P. Le Callet, \"CNN-based transform index prediction in multiple transforms framework to assist\n\n2017 25th European Signal Processing Conference (EUSIPCO). IEEEentropy codingentropy coding,\" in 2017 25th European Signal Processing Conference (EUSIPCO). IEEE, 2017, pp. 798-802.\n\nDeep learning-based transformation matrix estimation for bidirectional interframe prediction. S Jimbo, J Wang, Y Yashima, 2018 IEEE 7th Global Conference on Consumer Electronics (GCCE). IEEES. Jimbo, J. Wang, and Y. Yashima, \"Deep learning-based transformation matrix estimation for bidirectional interframe prediction,\" in 2018 IEEE 7th Global Conference on Consumer Electronics (GCCE). IEEE, 2018, pp. 726-730.\n\nA perceptual quantization strategy for HEVC based on a convolutional neural network trained on natural images. M M Alam, T D Nguyen, M T Hagan, D M Chandler, Applications of Digital Image Processing XXXVIII. 9599959918M. M. Alam, T. D. Nguyen, M. T. Hagan, and D. M. Chandler, \"A perceptual quantization strategy for HEVC based on a convolutional neural network trained on natural images,\" in Applications of Digital Image Processing XXXVIII, vol. 9599. International Society for Optics and Photonics, 2015, p. 959918.\n\nNeural network-based arithmetic coding of intra prediction modes in HEVC. R Song, D Liu, H Li, F Wu, 2017 IEEE Visual Communications and Image Processing. VCIPR. Song, D. Liu, H. Li, and F. Wu, \"Neural network-based arithmetic coding of intra prediction modes in HEVC,\" in 2017 IEEE Visual Communications and Image Processing (VCIP).\n\n. IEEE. IEEE, 2017, pp. 1-4.\n\nConvolutional neural network-based arithmetic coding of DC coefficients for HEVC intra coding. C Ma, D Liu, X Peng, F Wu, 2018 25th IEEE International Conference on Image Processing (ICIP. IEEEC. Ma, D. Liu, X. Peng, and F. Wu, \"Convolutional neural network-based arithmetic coding of DC coefficients for HEVC intra coding,\" in 2018 25th IEEE International Conference on Image Processing (ICIP). IEEE, 2018, pp. 1772-1776.\n\nCNN based postprocessing to improve HEVC. C Li, L Song, R Xie, W Zhang, 2017 IEEE International Conference on Image Processing (ICIP). C. Li, L. Song, R. Xie, and W. Zhang, \"CNN based post- processing to improve HEVC,\" in 2017 IEEE International Conference on Image Processing (ICIP).\n\n. IEEE. IEEE, 2017, pp. 4577-4580.\n\nA CNN-based post-processing algorithm for video coding efficiency improvement. H Zhao, M He, G Teng, X Shang, G Wang, Y Feng, IEEE Access. H. Zhao, M. He, G. Teng, X. Shang, G. Wang, and Y. Feng, \"A CNN-based post-processing algorithm for video coding efficiency improvement,\" IEEE Access, 2019.\n\nContent-aware convolutional neural network for in-loop filtering in High Efficiency Video Coding. C Jia, S Wang, X Zhang, S Wang, J Liu, S Pu, S Ma, IEEE Transactions on Image Processing. 287C. Jia, S. Wang, X. Zhang, S. Wang, J. Liu, S. Pu, and S. Ma, \"Content-aware convolutional neural network for in-loop filtering in High Efficiency Video Coding,\" IEEE Transactions on Image Processing, vol. 28, no. 7, pp. 3343-3356, 2019.\n\nMFRNet: a new CNN architecture for post-processing and in-loop filtering. D Ma, F Zhang, D R Bull, arXiv:2007.07099arXiv preprintD. Ma, F. Zhang, and D. R. Bull, \"MFRNet: a new CNN architecture for post-processing and in-loop filtering,\" arXiv preprint arXiv:2007.07099, 2020.\n\nConvolutional neural network-based block up-sampling for HEVC. J Lin, D Liu, H Yang, H Li, F Wu, IEEE Transactions on Circuits and Systems for Video Technology. J. Lin, D. Liu, H. Yang, H. Li, and F. Wu, \"Convolutional neural network-based block up-sampling for HEVC,\" IEEE Transactions on Circuits and Systems for Video Technology, 2018.\n\nViSTRA2: Video coding using spatial resolution and effective bit depth adaptation. F Zhang, M Afonso, D R Bull, arXiv:1911.02833arXiv preprintF. Zhang, M. Afonso, and D. R. Bull, \"ViSTRA2: Video coding using spatial resolution and effective bit depth adaptation,\" arXiv preprint arXiv:1911.02833, 2019.\n\nGAN-based effective bit depth adaptation for perceptual video compression. D Ma, F Zhang, D R Bull, 2020 IEEE International Conference on Multimedia and Expo (ICME). IEEED. Ma, F. Zhang, and D. R. Bull, \"GAN-based effective bit depth adaptation for perceptual video compression,\" in 2020 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 2020, pp. 1-6.\n\nEnd-to-end optimized image compression. J Ball\u00e9, V Laparra, E P Simoncelli, arXiv:1611.01704arXiv preprintJ. Ball\u00e9, V. Laparra, and E. P. Simoncelli, \"End-to-end opti- mized image compression,\" arXiv preprint arXiv:1611.01704, 2016.\n\nLearned video compression. O Rippel, S Nair, C Lew, S Branson, A G Anderson, L Bourdev, Proceedings of the IEEE International Conference on Computer Vision (ICCV). the IEEE International Conference on Computer Vision (ICCV)O. Rippel, S. Nair, C. Lew, S. Branson, A. G. Anderson, and L. Bourdev, \"Learned video compression,\" in Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2019, pp. 3454-3463.\n\nDVC: An end-to-end deep video compression framework. G Lu, W Ouyang, D Xu, X Zhang, C Cai, Z Gao, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)1115G. Lu, W. Ouyang, D. Xu, X. Zhang, C. Cai, and Z. Gao, \"DVC: An end-to-end deep video compression framework,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 11 006-11 015.\n\nNeural inter-frame compression for video coding. A Djelouah, J Campos, S Schaub-Meyer, C Schroers, Proceedings of the IEEE International Conference on Computer Vision (ICCV). the IEEE International Conference on Computer Vision (ICCV)A. Djelouah, J. Campos, S. Schaub-Meyer, and C. Schroers, \"Neural inter-frame compression for video coding,\" in Proceed- ings of the IEEE International Conference on Computer Vision (ICCV), 2019, pp. 6421-6429.\n\nVideo compression with rate-distortion autoencoders. A Habibian, T V Rozendaal, J M Tomczak, T S Cohen, Proceedings of the IEEE International Conference on Computer Vision (ICCV). the IEEE International Conference on Computer Vision (ICCV)A. Habibian, T. v. Rozendaal, J. M. Tomczak, and T. S. Cohen, \"Video compression with rate-distortion autoencoders,\" in Pro- ceedings of the IEEE International Conference on Computer Vision (ICCV), 2019, pp. 7033-7042.\n\nDo we need more training data?. X Zhu, C Vondrick, C C Fowlkes, D Ramanan, International Journal of Computer Vision. 1191X. Zhu, C. Vondrick, C. C. Fowlkes, and D. Ramanan, \"Do we need more training data?\" International Journal of Computer Vision, vol. 119, no. 1, pp. 76-92, Aug 2016. [Online].\n\n. 10.1007/s11263-015-0812-2Available: https://doi.org/10.1007/s11263-015-0812-2\n\nTDAN: Temporally deformable alignment network for video super-resolution. Y Tian, Y Zhang, Y Fu, C Xu, arXiv:1812.02898arXiv preprintY. Tian, Y. Zhang, Y. Fu, and C. Xu, \"TDAN: Temporally de- formable alignment network for video super-resolution,\" arXiv preprint arXiv:1812.02898, 2018.\n\nImagenet large scale visual recognition challenge. O Russakovsky, J Deng, H Su, J Krause, S Satheesh, S Ma, Z Huang, A Karpathy, A Khosla, M Bernstein, International Journal of Computer Vision. 1153O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein et al., \"Im- agenet large scale visual recognition challenge,\" International Journal of Computer Vision, vol. 115, no. 3, pp. 211-252, 2015.\n\n. S Wan, M.-Z Wang, H Gong, C.-Y Zou, Y.-Z Ma, J.-Y , S. Wan, M.-Z. Wang, H. Gong, C.-Y. Zou, Y.-Z. Ma, J.-Y.\n\nCE10: Integrated in-loop filter based on CNN (Tests 2.1, 2.2 and 2.3),\" in the JVET meeting, no. JVET-O0079. Huo, ITU-T, ISO/IECGothenburg, SwedenHuo, and et al., \"CE10: Integrated in-loop filter based on CNN (Tests 2.1, 2.2 and 2.3),\" in the JVET meeting, no. JVET-O0079. Gothenburg, Sweden: ITU-T, ISO/IEC, 2019.\n\nAHG9: Separable convolutional neural network filter with squeeze-and-excitation block. T Hashimoto, E Sasaki, T Ikai, the JVET meeting, no. JVET-K0158. ITU-T, ISO/IECLjubljana, SloveniaT. Hashimoto, E. Sasaki, and T. Ikai, \"AHG9: Separable convolutional neural network filter with squeeze-and-excitation block,\" in the JVET meeting, no. JVET-K0158. Ljubljana, Slovenia: ITU-T, ISO/IEC, 2018.\n\nDense residual convolutional neural network based in-loop filter for HEVC. Y Wang, H Zhu, Y Li, Z Chen, S Liu, 2018 IEEE Visual Communications and Image Processing (VCIP). Y. Wang, H. Zhu, Y. Li, Z. Chen, and S. Liu, \"Dense residual convolutional neural network based in-loop filter for HEVC,\" in 2018 IEEE Visual Communications and Image Processing (VCIP), Dec 2018, pp. 1-4.\n\nPartition tree guided progressive rethinking network for in-loop filtering of HEVC. D Wang, S Xia, W Yang, Y Hu, J Liu, 2019 IEEE International Conference on Image Processing (ICIP). IEEED. Wang, S. Xia, W. Yang, Y. Hu, and J. Liu, \"Partition tree guided progressive rethinking network for in-loop filtering of HEVC,\" in 2019 IEEE International Conference on Image Processing (ICIP). IEEE, 2019, pp. 2671-2675.\n\nA database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. D Martin, C Fowlkes, D Tal, J Malik, Proceedings of the IEEE International Conference on Computer Vision (ICCV). the IEEE International Conference on Computer Vision (ICCV)2D. Martin, C. Fowlkes, D. Tal, and J. Malik, \"A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics,\" in Proceedings of the IEEE International Conference on Computer Vision (ICCV), vol. 2, July 2001, pp. 416-423 vol.2.\n\nVideo enhancement with task-oriented flow. T Xue, B Chen, J Wu, D Wei, W T Freeman, International Journal of Computer Vision. 1278T. Xue, B. Chen, J. Wu, D. Wei, and W. T. Freeman, \"Video enhancement with task-oriented flow,\" International Journal of Computer Vision, vol. 127, no. 8, pp. 1106-1125, 2019.\n\nStudy of subjective and objective quality assessment of video. K Seshadrinathan, R Soundararajan, A C Bovik, L K Cormack, IEEE transactions on Image Processing. 196K. Seshadrinathan, R. Soundararajan, A. C. Bovik, and L. K. Cormack, \"Study of subjective and objective quality assessment of video,\" IEEE transactions on Image Processing, vol. 19, no. 6, pp. 1427-1441, 2010.\n\nMCL-V: A streaming video quality assessment database. J Y Lin, R Song, C.-H Wu, T Liu, H Wang, C.-C J Kuo, Journal of Visual Communication and Image Representation. 30J. Y. Lin, R. Song, C.-H. Wu, T. Liu, H. Wang, and C.-C. J. Kuo, \"MCL-V: A streaming video quality assessment database,\" Journal of Visual Communication and Image Representation, vol. 30, pp. 1-9, 2015.\n\nVisual quality of current coding technologies at high definition iptv bitrates. C Keimel, J Habigt, T Habigt, M Rothbucher, K Diepold, 2010 IEEE International Workshop on Multimedia Signal Processing. IEEEC. Keimel, J. Habigt, T. Habigt, M. Rothbucher, and K. Diepold, \"Visual quality of current coding technologies at high definition iptv bitrates,\" in 2010 IEEE International Workshop on Multi- media Signal Processing. IEEE, 2010, pp. 390-393.\n\nS Nah, R Timofte, S Baik, S Hong, G Moon, S Son, K. Mu Lee, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. the IEEE Conference on Computer Vision and Pattern Recognition WorkshopsCVPRWNTIRE 2019 challenge on video deblurring: Methods and resultsS. Nah, R. Timofte, S. Baik, S. Hong, G. Moon, S. Son, and K. Mu Lee, \"NTIRE 2019 challenge on video deblurring: Methods and results,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2019, pp. 0-0.\n\nUCF101: A dataset of 101 human actions classes from videos in the wild. K Soomro, A R Zamir, M Shah, arXiv:1212.0402arXiv preprintK. Soomro, A. R. Zamir, and M. Shah, \"UCF101: A dataset of 101 human actions classes from videos in the wild,\" arXiv preprint arXiv:1212.0402, 2012.\n\nVideo frame synthesis using deep voxel flow. Z Liu, R A Yeh, X Tang, Y Liu, A Agarwala, Proceedings of the IEEE International Conference on Computer Vision (ICCV. the IEEE International Conference on Computer Vision (ICCVZ. Liu, R. A. Yeh, X. Tang, Y. Liu, and A. Agarwala, \"Video frame synthesis using deep voxel flow,\" in Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2017, pp. 4463-4471.\n\nA temporallyaware interpolation network for video frame inpainting. R Szeto, X Sun, K Lu, J J Corso, IEEE transactions. R. Szeto, X. Sun, K. Lu, and J. J. Corso, \"A temporally- aware interpolation network for video frame inpainting,\" IEEE transactions on pattern analysis and machine intelligence, 2019.\n\nFrame interpolation via refined deep voxel flow. Z Zhang, L Chen, R Xie, L Song, 2018 25th IEEE International Conference on Image Processing (ICIP). Z. Zhang, L. Chen, R. Xie, and L. Song, \"Frame interpolation via refined deep voxel flow,\" in 2018 25th IEEE International Conference on Image Processing (ICIP).\n\n. IEEE. IEEE, 2018, pp. 1473-1477.\n\nA parametric framework for video compression using region-based texture models. F Zhang, D R Bull, IEEE Journal of Selected Topics in Signal Processing. 57F. Zhang and D. R. Bull, \"A parametric framework for video compression using region-based texture models,\" IEEE Journal of Selected Topics in Signal Processing, vol. 5, no. 7, pp. 1378- 1392, 2011.\n\nA synthetic video dataset for video compression evaluation. D Ma, A V Katsenou, D R Bull, 2019 IEEE International Conference on Image Processing (ICIP). IEEED. Ma, A. V. Katsenou, and D. R. Bull, \"A synthetic video dataset for video compression evaluation,\" in 2019 IEEE Inter- national Conference on Image Processing (ICIP). IEEE, 2019, pp. 1094-1098.\n\nVidevo Free Stock Video Footage. Videvo Free Stock Video Footage, https://www.videvo.net/.\n\n. Free, Uhd Free, Footage, IRIS32 FREE 4K UHD FREE FOOTAGE, https://www. youtube.com/channel/UCjJee-JAzoRRH5T0wqe7 tw/.\n\nHarmonic Inc 4K demo footage. 1Harmonic Inc 4K demo footage, http://www.harmonicinc.com/ 4k-demo-footage-download/, (Accessed: 1st May 2017).\n\nA video texture database for perceptual compression and quality assessment. M A Papadopoulos, F Zhang, D Agrafiotis, D Bull, 2015 IEEE International Conference on Image Processing (ICIP). IEEEM. A. Papadopoulos, F. Zhang, D. Agrafiotis, and D. Bull, \"A video texture database for perceptual compression and quality assessment,\" in 2015 IEEE International Conference on Image Processing (ICIP). IEEE, 2015, pp. 2781-2785.\n\nSubjective and objective quality assessment of compressed 4k uhd videos for immersive experience. M Cheon, J.-S Lee, IEEE Transactions on Circuits and Systems for Video Technology. 28M. Cheon and J.-S. Lee, \"Subjective and objective quality assessment of compressed 4k uhd videos for immersive expe- rience,\" IEEE Transactions on Circuits and Systems for Video Technology, vol. 28, no. 7, pp. 1467-1480, 2017.\n\nA study of high frame rate video formats. A Mackin, F Zhang, D R Bull, IEEE Transactions on Multimedia. 216A. Mackin, F. Zhang, and D. R. Bull, \"A study of high frame rate video formats,\" IEEE Transactions on Multimedia, vol. 21, no. 6, pp. 1499-1512, 2018.\n\nThe SJTU 4k video sequence dataset. L Song, X Tang, W Zhang, X Yang, P Xia, 2013 Fifth International Workshop on Quality of Multimedia Experience (QoMEX). IEEEL. Song, X. Tang, W. Zhang, X. Yang, and P. Xia, \"The SJTU 4k video sequence dataset,\" in 2013 Fifth International Workshop on Quality of Multimedia Experience (QoMEX). IEEE, 2013, pp. 34-35.\n\nStudy of temporal effects on subjective video quality of experience. C G Bampis, Z Li, A K Moorthy, I Katsavounidis, A Aaron, A C Bovik, IEEE Transactions on Image Processing. 2611C. G. Bampis, Z. Li, A. K. Moorthy, I. Katsavounidis, A. Aaron, and A. C. Bovik, \"Study of temporal effects on subjective video quality of experience,\" IEEE Transactions on Image Processing, vol. 26, no. 11, pp. 5217-5231, 2017.\n\nTowards perceptually optimized end-to-end adaptive video streaming. C G Bampis, Z Li, I Katsavounidis, T.-Y Huang, C Ekanadham, A C Bovik, arXiv:1808.03898arXiv preprintC. G. Bampis, Z. Li, I. Katsavounidis, T.-Y. Huang, C. Ekanadham, and A. C. Bovik, \"Towards perceptually op- timized end-to-end adaptive video streaming,\" arXiv preprint arXiv:1808.03898, 2018.\n\n. Mitch Martinez, Free Stock Footage, Mitch Martinez FREE 4K STOCK FOOTAGE, http:// mitchmartinez.com/free-4k-red-epic-stock-footage/.\n\n. Dareful-Completely Free 4k Stock Video, Dareful-Completely Free 4K Stock Video, https://www.dareful. com/.\n\nMCL-JCV: a JND-based H.264/AVC video quality assessment dataset. H Wang, W Gan, S Hu, J Y Lin, L Jin, L Song, P Wang, I Katsavounidis, A Aaron, C.-C J Kuo, 2016 IEEE International Conference on Image Processing (ICIP). IEEEH. Wang, W. Gan, S. Hu, J. Y. Lin, L. Jin, L. Song, P. Wang, I. Katsavounidis, A. Aaron, and C.-C. J. Kuo, \"MCL-JCV: a JND-based H.264/AVC video quality assessment dataset,\" in 2016 IEEE International Conference on Image Processing (ICIP). IEEE, 2016, pp. 1509-1513.\n\nChimera video sequence details and scenes. I Katsavounidis, tech. rep., Netflix. I. Katsavounidis, \"Chimera video sequence details and scenes,\" tech. rep., Netflix, (November 2015).\n\nThe tum high definition video datasets. C Keimel, A Redl, K Diepold, 2012 Fourth International Workshop on Quality of Multimedia Experience. IEEEC. Keimel, A. Redl, and K. Diepold, \"The tum high definition video datasets,\" in 2012 Fourth International Workshop on Quality of Multimedia Experience. IEEE, 2012, pp. 97-102.\n\nOn the optimal presentation duration for subjective video quality assessment. F M Moss, K Wang, F Zhang, R Baddeley, D R Bull, IEEE Transactions on Circuits and Systems for Video Technology. 26F. M. Moss, K. Wang, F. Zhang, R. Baddeley, and D. R. Bull, \"On the optimal presentation duration for subjective video quality assessment,\" IEEE Transactions on Circuits and Systems for Video Technology, vol. 26, no. 11, pp. 1977-1987, 2015.\n\nAnalysis of public image and video databases for quality assessment. S Winkler, IEEE Journal of Selected Topics in Signal Processing. 66S. Winkler, \"Analysis of public image and video databases for quality assessment,\" IEEE Journal of Selected Topics in Signal Processing, vol. 6, no. 6, pp. 616-625, 2012.\n\nDescription of SDR video coding technology proposal by University of Bristol. D Bull, F Zhang, M Afonso, in the JVET meeting, no. JVET-J0031D. Bull, F. Zhang, and M. Afonso, \"Description of SDR video coding technology proposal by University of Bristol,\" in the JVET meeting, no. JVET-J0031.\n\n. San Diego, Us: Itu-T, Iso/Iec, San Diego, US: ITU-T, ISO/IEC, April 2018.\n\nA deep learning approach for multi-frame in-loop filter of HEVC. T Li, M Xu, C Zhu, R Yang, Z Wang, Z Guan, IEEE Transactions on Image Processing. 2811T. Li, M. Xu, C. Zhu, R. Yang, Z. Wang, and Z. Guan, \"A deep learning approach for multi-frame in-loop filter of HEVC,\" IEEE Transactions on Image Processing, vol. 28, no. 11, pp. 5663-5678, 2019.\n\nVideo compression based on spatio-temporal resolution adaptation. M Afonso, F Zhang, D R Bull, IEEE Transactions on Circuits and Systems for Video Technology. 29M. Afonso, F. Zhang, and D. R. Bull, \"Video compression based on spatio-temporal resolution adaptation,\" IEEE Transactions on Circuits and Systems for Video Technology, vol. 29, no. 1, pp. 275-280, 2019.\n\nEnhanced video compression based on effective bit depth adaptation. F Zhang, M Afonso, D R Bull, 2019 IEEE International Conference on Image Processing (ICIP). IEEEF. Zhang, M. Afonso, and D. R. Bull, \"Enhanced video com- pression based on effective bit depth adaptation,\" in 2019 IEEE International Conference on Image Processing (ICIP). IEEE, 2019, pp. 1720-1724.\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)K. He, X. Zhang, S. Ren, and J. Sun, \"Deep residual learning for image recognition,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 770-778.\n\nDensely connected convolutional networks. G Huang, Z Liu, L Van Der Maaten, K Q Weinberger, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR. the IEEE Conference on Computer Vision and Pattern Recognition (CVPRG. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, \"Densely connected convolutional networks,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recog- nition (CVPR), 2017, pp. 4700-4708.\n\nLow complexity video coding based on spatial resolution adaptation. M Afonso, F Zhang, A Katsenou, D Agrafiotis, D Bull, 2017 IEEE International Conference on Image Processing (ICIP). IEEEM. Afonso, F. Zhang, A. Katsenou, D. Agrafiotis, and D. Bull, \"Low complexity video coding based on spatial resolution adaptation,\" in 2017 IEEE International Conference on Image Processing (ICIP). IEEE, 2017, pp. 3011-3015.\n\nAdam: a method for stochastic optimization. D P Kingma, J Ba, arXiv:1412.6980arXiv preprintD. P. Kingma and J. Ba, \"Adam: a method for stochastic optimization,\" arXiv preprint arXiv:1412.6980, 2014.\n\nCalculation of average PSNR differences between RD-curves. G Bj\u00f8ntegaard, 13th VCEG Meeting, no. VCEG-M33. USA: ITU-TAustin, TexasG. Bj\u00f8ntegaard, \"Calculation of average PSNR differences between RD-curves,\" in 13th VCEG Meeting, no. VCEG- M33,Austin, Texas, 2001, pp. USA: ITU-T.\n\nToward a practical perceptual video quality metric. Z Li, A Aaron, I Katsavounidis, A Moorthy, M Manohara, The Netflix Tech Blog. 6Z. Li, A. Aaron, I. Katsavounidis, A. Moorthy, and M. Manohara, \"Toward a practical perceptual video quality metric,\" The Netflix Tech Blog, vol. 6, 2016.\n\nBVI-HD: A video quality database for HEVC compressed and texture synthesized content. F Zhang, F M Moss, R Baddeley, D R Bull, IEEE Transactions on Multimedia. 2010F. Zhang, F. M. Moss, R. Baddeley, and D. R. Bull, \"BVI- HD: A video quality database for HEVC compressed and texture synthesized content,\" IEEE Transactions on Multimedia, vol. 20, no. 10, pp. 2620-2630, 2018.\n", "annotations": {"author": "[{\"end\":65,\"start\":59},{\"end\":88,\"start\":66},{\"end\":114,\"start\":89}]", "publisher": null, "author_last_name": "[{\"end\":64,\"start\":62},{\"end\":87,\"start\":82},{\"end\":113,\"start\":109}]", "author_first_name": "[{\"end\":61,\"start\":59},{\"end\":81,\"start\":78},{\"end\":106,\"start\":101},{\"end\":108,\"start\":107}]", "author_affiliation": null, "title": "[{\"end\":56,\"start\":1},{\"end\":170,\"start\":115}]", "venue": null, "abstract": "[{\"end\":1495,\"start\":230}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1794,\"start\":1791},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1979,\"start\":1976},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2513,\"start\":2510},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2927,\"start\":2926},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3921,\"start\":3918},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3924,\"start\":3921},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3927,\"start\":3924},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3997,\"start\":3994},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4000,\"start\":3997},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4003,\"start\":4000},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4007,\"start\":4003},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4011,\"start\":4007},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4015,\"start\":4011},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4019,\"start\":4015},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4023,\"start\":4019},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4027,\"start\":4023},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4031,\"start\":4027},{\"end\":4277,\"start\":4267},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4342,\"start\":4338},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4436,\"start\":4432},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5995,\"start\":5991},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6225,\"start\":6221},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6282,\"start\":6278},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6506,\"start\":6502},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6509,\"start\":6506},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6533,\"start\":6529},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6536,\"start\":6533},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6553,\"start\":6549},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6556,\"start\":6553},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6575,\"start\":6571},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6596,\"start\":6592},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6599,\"start\":6596},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6621,\"start\":6617},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6624,\"start\":6621},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":6648,\"start\":6644},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":6651,\"start\":6648},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6700,\"start\":6696},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6704,\"start\":6700},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":6708,\"start\":6704},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6754,\"start\":6750},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6907,\"start\":6903},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6911,\"start\":6907},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":6915,\"start\":6911},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6919,\"start\":6915},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6923,\"start\":6919},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7447,\"start\":7443},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7450,\"start\":7447},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":7855,\"start\":7851},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8146,\"start\":8142},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8159,\"start\":8156},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":8357,\"start\":8353},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8360,\"start\":8357},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":8408,\"start\":8404},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":8411,\"start\":8408},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":8424,\"start\":8420},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":8573,\"start\":8569},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":8693,\"start\":8689},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9260,\"start\":9257},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9293,\"start\":9290},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":9391,\"start\":9387},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":9412,\"start\":9408},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":9440,\"start\":9436},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9513,\"start\":9510},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9611,\"start\":9608},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":9693,\"start\":9689},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":9773,\"start\":9769},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":9976,\"start\":9972},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":9980,\"start\":9976},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":9984,\"start\":9980},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":10701,\"start\":10697},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":10720,\"start\":10716},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":10741,\"start\":10737},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":10770,\"start\":10766},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":10804,\"start\":10800},{\"end\":10872,\"start\":10868},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10928,\"start\":10925},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":11817,\"start\":11813},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":12251,\"start\":12247},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":12254,\"start\":12251},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":12583,\"start\":12580},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12586,\"start\":12583},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12589,\"start\":12586},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12593,\"start\":12589},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12597,\"start\":12593},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12601,\"start\":12597},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12605,\"start\":12601},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12609,\"start\":12605},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12613,\"start\":12609},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12617,\"start\":12613},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":12620,\"start\":12617},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14269,\"start\":14265},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":14272,\"start\":14269},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":14643,\"start\":14639},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":14646,\"start\":14643},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":14979,\"start\":14975},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":15048,\"start\":15044},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":15479,\"start\":15475},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":16346,\"start\":16342},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":16690,\"start\":16686},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17614,\"start\":17611},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":17624,\"start\":17621},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17635,\"start\":17632},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":18093,\"start\":18089},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":18318,\"start\":18314},{\"attributes\":{\"ref_id\":\"b91\"},\"end\":19069,\"start\":19065},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":19994,\"start\":19990},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":20382,\"start\":20378},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":20617,\"start\":20613},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":20773,\"start\":20769},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":21117,\"start\":21113},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":23272,\"start\":23268},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23275,\"start\":23272},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":26076,\"start\":26073},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26198,\"start\":26195},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":26368,\"start\":26364},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26436,\"start\":26432},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":26452,\"start\":26448},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26621,\"start\":26617},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":26719,\"start\":26715},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26777,\"start\":26773},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":33624,\"start\":33620},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":33627,\"start\":33624}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24295,\"start\":24220},{\"attributes\":{\"id\":\"fig_1\"},\"end\":24660,\"start\":24296},{\"attributes\":{\"id\":\"fig_2\"},\"end\":24728,\"start\":24661},{\"attributes\":{\"id\":\"fig_3\"},\"end\":24810,\"start\":24729},{\"attributes\":{\"id\":\"fig_4\"},\"end\":24956,\"start\":24811},{\"attributes\":{\"id\":\"fig_5\"},\"end\":25088,\"start\":24957},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":25600,\"start\":25089},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":26064,\"start\":25601},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":28526,\"start\":26065},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":29579,\"start\":28527},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":31226,\"start\":29580},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":32638,\"start\":31227},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":33575,\"start\":32639}]", "paragraph": "[{\"end\":2100,\"start\":1514},{\"end\":3250,\"start\":2102},{\"end\":4437,\"start\":3252},{\"end\":5399,\"start\":4439},{\"end\":5866,\"start\":5401},{\"end\":6283,\"start\":5868},{\"end\":7191,\"start\":6325},{\"end\":7838,\"start\":7217},{\"end\":11258,\"start\":7840},{\"end\":12416,\"start\":11538},{\"end\":13214,\"start\":12436},{\"end\":13761,\"start\":13216},{\"end\":14647,\"start\":13763},{\"end\":15480,\"start\":14649},{\"end\":15535,\"start\":15496},{\"end\":16347,\"start\":15613},{\"end\":16691,\"start\":16374},{\"end\":17468,\"start\":16693},{\"end\":18602,\"start\":17489},{\"end\":18941,\"start\":18604},{\"end\":19405,\"start\":18980},{\"end\":19821,\"start\":19407},{\"end\":20464,\"start\":19852},{\"end\":21424,\"start\":20466},{\"end\":22245,\"start\":21455},{\"end\":23276,\"start\":22275},{\"end\":24219,\"start\":23295}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11537,\"start\":11302}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":12185,\"start\":12178},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21344,\"start\":21336},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22431,\"start\":22423}]", "section_header": "[{\"end\":1512,\"start\":1497},{\"end\":6323,\"start\":6286},{\"end\":7215,\"start\":7194},{\"end\":11301,\"start\":11261},{\"end\":12434,\"start\":12419},{\"end\":15494,\"start\":15483},{\"end\":15550,\"start\":15538},{\"end\":15611,\"start\":15553},{\"end\":16372,\"start\":16350},{\"end\":17487,\"start\":17471},{\"end\":18978,\"start\":18944},{\"end\":19850,\"start\":19824},{\"end\":21453,\"start\":21427},{\"end\":22273,\"start\":22248},{\"end\":23293,\"start\":23279},{\"end\":24229,\"start\":24221},{\"end\":24305,\"start\":24297},{\"end\":24670,\"start\":24662},{\"end\":24738,\"start\":24730},{\"end\":24820,\"start\":24812},{\"end\":24966,\"start\":24958},{\"end\":25611,\"start\":25602},{\"end\":28538,\"start\":28528},{\"end\":29592,\"start\":29581},{\"end\":31238,\"start\":31228},{\"end\":32649,\"start\":32640}]", "table": "[{\"end\":26064,\"start\":25672},{\"end\":28526,\"start\":26871},{\"end\":29579,\"start\":28656},{\"end\":31226,\"start\":30064},{\"end\":32638,\"start\":31462},{\"end\":33575,\"start\":32873}]", "figure_caption": "[{\"end\":24295,\"start\":24231},{\"end\":24660,\"start\":24307},{\"end\":24728,\"start\":24672},{\"end\":24810,\"start\":24740},{\"end\":24956,\"start\":24822},{\"end\":25088,\"start\":24968},{\"end\":25600,\"start\":25091},{\"end\":25672,\"start\":25613},{\"end\":26871,\"start\":26067},{\"end\":28656,\"start\":28541},{\"end\":30064,\"start\":29596},{\"end\":31462,\"start\":31241},{\"end\":32873,\"start\":32651}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12068,\"start\":12062},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12196,\"start\":12190},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13892,\"start\":13886},{\"end\":14562,\"start\":14556},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15069,\"start\":15062},{\"end\":16034,\"start\":16028},{\"end\":21500,\"start\":21494},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":21967,\"start\":21961},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":22591,\"start\":22585},{\"end\":23058,\"start\":23051}]", "bib_author_first_name": "[{\"end\":34222,\"start\":34221},{\"end\":34224,\"start\":34223},{\"end\":34401,\"start\":34400},{\"end\":34407,\"start\":34406},{\"end\":34416,\"start\":34415},{\"end\":34423,\"start\":34422},{\"end\":34431,\"start\":34430},{\"end\":34439,\"start\":34438},{\"end\":34765,\"start\":34764},{\"end\":34772,\"start\":34771},{\"end\":34778,\"start\":34777},{\"end\":34785,\"start\":34784},{\"end\":34791,\"start\":34790},{\"end\":35071,\"start\":35070},{\"end\":35084,\"start\":35083},{\"end\":35562,\"start\":35561},{\"end\":35569,\"start\":35568},{\"end\":35577,\"start\":35576},{\"end\":35585,\"start\":35584},{\"end\":35593,\"start\":35592},{\"end\":35600,\"start\":35599},{\"end\":35615,\"start\":35610},{\"end\":36120,\"start\":36119},{\"end\":36127,\"start\":36126},{\"end\":36135,\"start\":36134},{\"end\":36142,\"start\":36141},{\"end\":36149,\"start\":36148},{\"end\":36157,\"start\":36156},{\"end\":36166,\"start\":36165},{\"end\":36598,\"start\":36597},{\"end\":36606,\"start\":36605},{\"end\":36608,\"start\":36607},{\"end\":36615,\"start\":36614},{\"end\":36621,\"start\":36620},{\"end\":36961,\"start\":36960},{\"end\":36969,\"start\":36968},{\"end\":36971,\"start\":36970},{\"end\":36978,\"start\":36977},{\"end\":37380,\"start\":37379},{\"end\":37387,\"start\":37386},{\"end\":37398,\"start\":37393},{\"end\":37841,\"start\":37840},{\"end\":37848,\"start\":37847},{\"end\":37856,\"start\":37855},{\"end\":38287,\"start\":38286},{\"end\":38294,\"start\":38293},{\"end\":38301,\"start\":38300},{\"end\":38308,\"start\":38307},{\"end\":38319,\"start\":38314},{\"end\":38814,\"start\":38813},{\"end\":38823,\"start\":38822},{\"end\":38832,\"start\":38831},{\"end\":38842,\"start\":38841},{\"end\":38855,\"start\":38854},{\"end\":38869,\"start\":38868},{\"end\":38879,\"start\":38878},{\"end\":38889,\"start\":38888},{\"end\":38899,\"start\":38898},{\"end\":38907,\"start\":38906},{\"end\":39440,\"start\":39439},{\"end\":39448,\"start\":39447},{\"end\":39454,\"start\":39453},{\"end\":39460,\"start\":39459},{\"end\":39466,\"start\":39465},{\"end\":39473,\"start\":39472},{\"end\":39481,\"start\":39480},{\"end\":39497,\"start\":39488},{\"end\":39926,\"start\":39925},{\"end\":39935,\"start\":39934},{\"end\":39941,\"start\":39940},{\"end\":39947,\"start\":39946},{\"end\":39955,\"start\":39954},{\"end\":39964,\"start\":39963},{\"end\":40357,\"start\":40356},{\"end\":40366,\"start\":40365},{\"end\":40374,\"start\":40373},{\"end\":40382,\"start\":40381},{\"end\":40391,\"start\":40390},{\"end\":40827,\"start\":40826},{\"end\":40833,\"start\":40832},{\"end\":40835,\"start\":40834},{\"end\":40845,\"start\":40844},{\"end\":40854,\"start\":40853},{\"end\":40856,\"start\":40855},{\"end\":41187,\"start\":41186},{\"end\":41189,\"start\":41188},{\"end\":41365,\"start\":41364},{\"end\":41375,\"start\":41374},{\"end\":41384,\"start\":41383},{\"end\":41390,\"start\":41389},{\"end\":41401,\"start\":41400},{\"end\":41697,\"start\":41696},{\"end\":41706,\"start\":41705},{\"end\":41714,\"start\":41713},{\"end\":41724,\"start\":41720},{\"end\":42038,\"start\":42037},{\"end\":42040,\"start\":42039},{\"end\":42052,\"start\":42051},{\"end\":42061,\"start\":42060},{\"end\":42071,\"start\":42070},{\"end\":42073,\"start\":42072},{\"end\":42433,\"start\":42429},{\"end\":42443,\"start\":42439},{\"end\":42455,\"start\":42451},{\"end\":42467,\"start\":42462},{\"end\":42718,\"start\":42717},{\"end\":42724,\"start\":42723},{\"end\":42730,\"start\":42729},{\"end\":42736,\"start\":42735},{\"end\":42745,\"start\":42744},{\"end\":43074,\"start\":43073},{\"end\":43082,\"start\":43081},{\"end\":43090,\"start\":43089},{\"end\":43098,\"start\":43097},{\"end\":43107,\"start\":43106},{\"end\":43113,\"start\":43112},{\"end\":43493,\"start\":43492},{\"end\":43501,\"start\":43500},{\"end\":43509,\"start\":43508},{\"end\":43518,\"start\":43517},{\"end\":43526,\"start\":43525},{\"end\":43532,\"start\":43531},{\"end\":43852,\"start\":43851},{\"end\":43860,\"start\":43859},{\"end\":43872,\"start\":43871},{\"end\":43875,\"start\":43873},{\"end\":44283,\"start\":44282},{\"end\":44292,\"start\":44291},{\"end\":44300,\"start\":44299},{\"end\":44714,\"start\":44713},{\"end\":44716,\"start\":44715},{\"end\":44724,\"start\":44723},{\"end\":44726,\"start\":44725},{\"end\":44736,\"start\":44735},{\"end\":44738,\"start\":44737},{\"end\":44747,\"start\":44746},{\"end\":44749,\"start\":44748},{\"end\":45197,\"start\":45196},{\"end\":45205,\"start\":45204},{\"end\":45212,\"start\":45211},{\"end\":45218,\"start\":45217},{\"end\":45583,\"start\":45582},{\"end\":45589,\"start\":45588},{\"end\":45596,\"start\":45595},{\"end\":45604,\"start\":45603},{\"end\":45954,\"start\":45953},{\"end\":45960,\"start\":45959},{\"end\":45968,\"start\":45967},{\"end\":45975,\"start\":45974},{\"end\":46313,\"start\":46312},{\"end\":46321,\"start\":46320},{\"end\":46327,\"start\":46326},{\"end\":46335,\"start\":46334},{\"end\":46344,\"start\":46343},{\"end\":46352,\"start\":46351},{\"end\":46629,\"start\":46628},{\"end\":46636,\"start\":46635},{\"end\":46644,\"start\":46643},{\"end\":46653,\"start\":46652},{\"end\":46661,\"start\":46660},{\"end\":46668,\"start\":46667},{\"end\":46674,\"start\":46673},{\"end\":47035,\"start\":47034},{\"end\":47041,\"start\":47040},{\"end\":47050,\"start\":47049},{\"end\":47052,\"start\":47051},{\"end\":47302,\"start\":47301},{\"end\":47309,\"start\":47308},{\"end\":47316,\"start\":47315},{\"end\":47324,\"start\":47323},{\"end\":47330,\"start\":47329},{\"end\":47662,\"start\":47661},{\"end\":47671,\"start\":47670},{\"end\":47681,\"start\":47680},{\"end\":47683,\"start\":47682},{\"end\":47958,\"start\":47957},{\"end\":47964,\"start\":47963},{\"end\":47973,\"start\":47972},{\"end\":47975,\"start\":47974},{\"end\":48294,\"start\":48293},{\"end\":48303,\"start\":48302},{\"end\":48314,\"start\":48313},{\"end\":48316,\"start\":48315},{\"end\":48515,\"start\":48514},{\"end\":48525,\"start\":48524},{\"end\":48533,\"start\":48532},{\"end\":48540,\"start\":48539},{\"end\":48551,\"start\":48550},{\"end\":48553,\"start\":48552},{\"end\":48565,\"start\":48564},{\"end\":48966,\"start\":48965},{\"end\":48972,\"start\":48971},{\"end\":48982,\"start\":48981},{\"end\":48988,\"start\":48987},{\"end\":48997,\"start\":48996},{\"end\":49004,\"start\":49003},{\"end\":49444,\"start\":49443},{\"end\":49456,\"start\":49455},{\"end\":49466,\"start\":49465},{\"end\":49482,\"start\":49481},{\"end\":49894,\"start\":49893},{\"end\":49906,\"start\":49905},{\"end\":49908,\"start\":49907},{\"end\":49921,\"start\":49920},{\"end\":49923,\"start\":49922},{\"end\":49934,\"start\":49933},{\"end\":49936,\"start\":49935},{\"end\":50332,\"start\":50331},{\"end\":50339,\"start\":50338},{\"end\":50351,\"start\":50350},{\"end\":50353,\"start\":50352},{\"end\":50364,\"start\":50363},{\"end\":50752,\"start\":50751},{\"end\":50760,\"start\":50759},{\"end\":50769,\"start\":50768},{\"end\":50775,\"start\":50774},{\"end\":51017,\"start\":51016},{\"end\":51032,\"start\":51031},{\"end\":51040,\"start\":51039},{\"end\":51046,\"start\":51045},{\"end\":51056,\"start\":51055},{\"end\":51068,\"start\":51067},{\"end\":51074,\"start\":51073},{\"end\":51083,\"start\":51082},{\"end\":51095,\"start\":51094},{\"end\":51105,\"start\":51104},{\"end\":51418,\"start\":51417},{\"end\":51428,\"start\":51424},{\"end\":51436,\"start\":51435},{\"end\":51447,\"start\":51443},{\"end\":51457,\"start\":51453},{\"end\":51466,\"start\":51462},{\"end\":51930,\"start\":51929},{\"end\":51943,\"start\":51942},{\"end\":51953,\"start\":51952},{\"end\":52311,\"start\":52310},{\"end\":52319,\"start\":52318},{\"end\":52326,\"start\":52325},{\"end\":52332,\"start\":52331},{\"end\":52340,\"start\":52339},{\"end\":52698,\"start\":52697},{\"end\":52706,\"start\":52705},{\"end\":52713,\"start\":52712},{\"end\":52721,\"start\":52720},{\"end\":52727,\"start\":52726},{\"end\":53166,\"start\":53165},{\"end\":53176,\"start\":53175},{\"end\":53187,\"start\":53186},{\"end\":53194,\"start\":53193},{\"end\":53687,\"start\":53686},{\"end\":53694,\"start\":53693},{\"end\":53702,\"start\":53701},{\"end\":53708,\"start\":53707},{\"end\":53715,\"start\":53714},{\"end\":53717,\"start\":53716},{\"end\":54014,\"start\":54013},{\"end\":54032,\"start\":54031},{\"end\":54049,\"start\":54048},{\"end\":54051,\"start\":54050},{\"end\":54060,\"start\":54059},{\"end\":54062,\"start\":54061},{\"end\":54380,\"start\":54379},{\"end\":54382,\"start\":54381},{\"end\":54389,\"start\":54388},{\"end\":54400,\"start\":54396},{\"end\":54406,\"start\":54405},{\"end\":54413,\"start\":54412},{\"end\":54424,\"start\":54420},{\"end\":54426,\"start\":54425},{\"end\":54777,\"start\":54776},{\"end\":54787,\"start\":54786},{\"end\":54797,\"start\":54796},{\"end\":54807,\"start\":54806},{\"end\":54821,\"start\":54820},{\"end\":55145,\"start\":55144},{\"end\":55152,\"start\":55151},{\"end\":55163,\"start\":55162},{\"end\":55171,\"start\":55170},{\"end\":55179,\"start\":55178},{\"end\":55187,\"start\":55186},{\"end\":55198,\"start\":55193},{\"end\":55755,\"start\":55754},{\"end\":55765,\"start\":55764},{\"end\":55767,\"start\":55766},{\"end\":55776,\"start\":55775},{\"end\":56008,\"start\":56007},{\"end\":56015,\"start\":56014},{\"end\":56017,\"start\":56016},{\"end\":56024,\"start\":56023},{\"end\":56032,\"start\":56031},{\"end\":56039,\"start\":56038},{\"end\":56453,\"start\":56452},{\"end\":56462,\"start\":56461},{\"end\":56469,\"start\":56468},{\"end\":56475,\"start\":56474},{\"end\":56477,\"start\":56476},{\"end\":56739,\"start\":56738},{\"end\":56748,\"start\":56747},{\"end\":56756,\"start\":56755},{\"end\":56763,\"start\":56762},{\"end\":57118,\"start\":57117},{\"end\":57127,\"start\":57126},{\"end\":57129,\"start\":57128},{\"end\":57452,\"start\":57451},{\"end\":57458,\"start\":57457},{\"end\":57460,\"start\":57459},{\"end\":57472,\"start\":57471},{\"end\":57474,\"start\":57473},{\"end\":58178,\"start\":58177},{\"end\":58180,\"start\":58179},{\"end\":58196,\"start\":58195},{\"end\":58205,\"start\":58204},{\"end\":58219,\"start\":58218},{\"end\":58622,\"start\":58621},{\"end\":58634,\"start\":58630},{\"end\":58977,\"start\":58976},{\"end\":58987,\"start\":58986},{\"end\":58996,\"start\":58995},{\"end\":58998,\"start\":58997},{\"end\":59230,\"start\":59229},{\"end\":59238,\"start\":59237},{\"end\":59246,\"start\":59245},{\"end\":59255,\"start\":59254},{\"end\":59263,\"start\":59262},{\"end\":59615,\"start\":59614},{\"end\":59617,\"start\":59616},{\"end\":59627,\"start\":59626},{\"end\":59633,\"start\":59632},{\"end\":59635,\"start\":59634},{\"end\":59646,\"start\":59645},{\"end\":59663,\"start\":59662},{\"end\":59672,\"start\":59671},{\"end\":59674,\"start\":59673},{\"end\":60024,\"start\":60023},{\"end\":60026,\"start\":60025},{\"end\":60036,\"start\":60035},{\"end\":60042,\"start\":60041},{\"end\":60062,\"start\":60058},{\"end\":60071,\"start\":60070},{\"end\":60084,\"start\":60083},{\"end\":60086,\"start\":60085},{\"end\":60326,\"start\":60321},{\"end\":60341,\"start\":60337},{\"end\":60489,\"start\":60457},{\"end\":60631,\"start\":60630},{\"end\":60639,\"start\":60638},{\"end\":60646,\"start\":60645},{\"end\":60652,\"start\":60651},{\"end\":60654,\"start\":60653},{\"end\":60661,\"start\":60660},{\"end\":60668,\"start\":60667},{\"end\":60676,\"start\":60675},{\"end\":60684,\"start\":60683},{\"end\":60701,\"start\":60700},{\"end\":60713,\"start\":60709},{\"end\":60715,\"start\":60714},{\"end\":61100,\"start\":61099},{\"end\":61280,\"start\":61279},{\"end\":61290,\"start\":61289},{\"end\":61298,\"start\":61297},{\"end\":61641,\"start\":61640},{\"end\":61643,\"start\":61642},{\"end\":61651,\"start\":61650},{\"end\":61659,\"start\":61658},{\"end\":61668,\"start\":61667},{\"end\":61680,\"start\":61679},{\"end\":61682,\"start\":61681},{\"end\":62068,\"start\":62067},{\"end\":62385,\"start\":62384},{\"end\":62393,\"start\":62392},{\"end\":62402,\"start\":62401},{\"end\":62603,\"start\":62600},{\"end\":62741,\"start\":62740},{\"end\":62747,\"start\":62746},{\"end\":62753,\"start\":62752},{\"end\":62760,\"start\":62759},{\"end\":62768,\"start\":62767},{\"end\":62776,\"start\":62775},{\"end\":63091,\"start\":63090},{\"end\":63101,\"start\":63100},{\"end\":63110,\"start\":63109},{\"end\":63112,\"start\":63111},{\"end\":63459,\"start\":63458},{\"end\":63468,\"start\":63467},{\"end\":63478,\"start\":63477},{\"end\":63480,\"start\":63479},{\"end\":63804,\"start\":63803},{\"end\":63810,\"start\":63809},{\"end\":63819,\"start\":63818},{\"end\":63826,\"start\":63825},{\"end\":64224,\"start\":64223},{\"end\":64233,\"start\":64232},{\"end\":64240,\"start\":64239},{\"end\":64258,\"start\":64257},{\"end\":64260,\"start\":64259},{\"end\":64711,\"start\":64710},{\"end\":64721,\"start\":64720},{\"end\":64730,\"start\":64729},{\"end\":64742,\"start\":64741},{\"end\":64756,\"start\":64755},{\"end\":65101,\"start\":65100},{\"end\":65103,\"start\":65102},{\"end\":65113,\"start\":65112},{\"end\":65316,\"start\":65315},{\"end\":65590,\"start\":65589},{\"end\":65596,\"start\":65595},{\"end\":65605,\"start\":65604},{\"end\":65622,\"start\":65621},{\"end\":65633,\"start\":65632},{\"end\":65911,\"start\":65910},{\"end\":65920,\"start\":65919},{\"end\":65922,\"start\":65921},{\"end\":65930,\"start\":65929},{\"end\":65942,\"start\":65941},{\"end\":65944,\"start\":65943}]", "bib_author_last_name": "[{\"end\":34229,\"start\":34225},{\"end\":34404,\"start\":34402},{\"end\":34413,\"start\":34408},{\"end\":34420,\"start\":34417},{\"end\":34428,\"start\":34424},{\"end\":34436,\"start\":34432},{\"end\":34445,\"start\":34440},{\"end\":34769,\"start\":34766},{\"end\":34775,\"start\":34773},{\"end\":34782,\"start\":34779},{\"end\":34788,\"start\":34786},{\"end\":34794,\"start\":34792},{\"end\":35081,\"start\":35072},{\"end\":35092,\"start\":35085},{\"end\":35566,\"start\":35563},{\"end\":35574,\"start\":35570},{\"end\":35582,\"start\":35578},{\"end\":35590,\"start\":35586},{\"end\":35597,\"start\":35594},{\"end\":35608,\"start\":35601},{\"end\":35619,\"start\":35616},{\"end\":36124,\"start\":36121},{\"end\":36132,\"start\":36128},{\"end\":36139,\"start\":36136},{\"end\":36146,\"start\":36143},{\"end\":36154,\"start\":36150},{\"end\":36163,\"start\":36158},{\"end\":36172,\"start\":36167},{\"end\":36603,\"start\":36599},{\"end\":36612,\"start\":36609},{\"end\":36618,\"start\":36616},{\"end\":36626,\"start\":36622},{\"end\":36966,\"start\":36962},{\"end\":36975,\"start\":36972},{\"end\":36983,\"start\":36979},{\"end\":37384,\"start\":37381},{\"end\":37391,\"start\":37388},{\"end\":37402,\"start\":37399},{\"end\":37845,\"start\":37842},{\"end\":37853,\"start\":37849},{\"end\":37860,\"start\":37857},{\"end\":38291,\"start\":38288},{\"end\":38298,\"start\":38295},{\"end\":38305,\"start\":38302},{\"end\":38312,\"start\":38309},{\"end\":38323,\"start\":38320},{\"end\":38820,\"start\":38815},{\"end\":38829,\"start\":38824},{\"end\":38839,\"start\":38833},{\"end\":38852,\"start\":38843},{\"end\":38866,\"start\":38856},{\"end\":38876,\"start\":38870},{\"end\":38886,\"start\":38880},{\"end\":38896,\"start\":38890},{\"end\":38904,\"start\":38900},{\"end\":38912,\"start\":38908},{\"end\":39445,\"start\":39441},{\"end\":39451,\"start\":39449},{\"end\":39457,\"start\":39455},{\"end\":39463,\"start\":39461},{\"end\":39470,\"start\":39467},{\"end\":39478,\"start\":39474},{\"end\":39486,\"start\":39482},{\"end\":39501,\"start\":39498},{\"end\":39932,\"start\":39927},{\"end\":39938,\"start\":39936},{\"end\":39944,\"start\":39942},{\"end\":39952,\"start\":39948},{\"end\":39961,\"start\":39956},{\"end\":39967,\"start\":39965},{\"end\":40363,\"start\":40358},{\"end\":40371,\"start\":40367},{\"end\":40379,\"start\":40375},{\"end\":40388,\"start\":40383},{\"end\":40394,\"start\":40392},{\"end\":40830,\"start\":40828},{\"end\":40842,\"start\":40836},{\"end\":40851,\"start\":40846},{\"end\":40861,\"start\":40857},{\"end\":41199,\"start\":41190},{\"end\":41372,\"start\":41366},{\"end\":41381,\"start\":41376},{\"end\":41387,\"start\":41385},{\"end\":41398,\"start\":41391},{\"end\":41409,\"start\":41402},{\"end\":41703,\"start\":41698},{\"end\":41711,\"start\":41707},{\"end\":41718,\"start\":41715},{\"end\":41729,\"start\":41725},{\"end\":42049,\"start\":42041},{\"end\":42058,\"start\":42053},{\"end\":42068,\"start\":42062},{\"end\":42078,\"start\":42074},{\"end\":42437,\"start\":42434},{\"end\":42449,\"start\":42444},{\"end\":42460,\"start\":42456},{\"end\":42471,\"start\":42468},{\"end\":42721,\"start\":42719},{\"end\":42727,\"start\":42725},{\"end\":42733,\"start\":42731},{\"end\":42742,\"start\":42737},{\"end\":42749,\"start\":42746},{\"end\":43079,\"start\":43075},{\"end\":43087,\"start\":43083},{\"end\":43095,\"start\":43091},{\"end\":43104,\"start\":43099},{\"end\":43110,\"start\":43108},{\"end\":43118,\"start\":43114},{\"end\":43498,\"start\":43494},{\"end\":43506,\"start\":43502},{\"end\":43515,\"start\":43510},{\"end\":43523,\"start\":43519},{\"end\":43529,\"start\":43527},{\"end\":43536,\"start\":43533},{\"end\":43857,\"start\":43853},{\"end\":43869,\"start\":43861},{\"end\":43882,\"start\":43876},{\"end\":44289,\"start\":44284},{\"end\":44297,\"start\":44293},{\"end\":44308,\"start\":44301},{\"end\":44721,\"start\":44717},{\"end\":44733,\"start\":44727},{\"end\":44744,\"start\":44739},{\"end\":44758,\"start\":44750},{\"end\":45202,\"start\":45198},{\"end\":45209,\"start\":45206},{\"end\":45215,\"start\":45213},{\"end\":45221,\"start\":45219},{\"end\":45586,\"start\":45584},{\"end\":45593,\"start\":45590},{\"end\":45601,\"start\":45597},{\"end\":45607,\"start\":45605},{\"end\":45957,\"start\":45955},{\"end\":45965,\"start\":45961},{\"end\":45972,\"start\":45969},{\"end\":45981,\"start\":45976},{\"end\":46318,\"start\":46314},{\"end\":46324,\"start\":46322},{\"end\":46332,\"start\":46328},{\"end\":46341,\"start\":46336},{\"end\":46349,\"start\":46345},{\"end\":46357,\"start\":46353},{\"end\":46633,\"start\":46630},{\"end\":46641,\"start\":46637},{\"end\":46650,\"start\":46645},{\"end\":46658,\"start\":46654},{\"end\":46665,\"start\":46662},{\"end\":46671,\"start\":46669},{\"end\":46677,\"start\":46675},{\"end\":47038,\"start\":47036},{\"end\":47047,\"start\":47042},{\"end\":47057,\"start\":47053},{\"end\":47306,\"start\":47303},{\"end\":47313,\"start\":47310},{\"end\":47321,\"start\":47317},{\"end\":47327,\"start\":47325},{\"end\":47333,\"start\":47331},{\"end\":47668,\"start\":47663},{\"end\":47678,\"start\":47672},{\"end\":47688,\"start\":47684},{\"end\":47961,\"start\":47959},{\"end\":47970,\"start\":47965},{\"end\":47980,\"start\":47976},{\"end\":48300,\"start\":48295},{\"end\":48311,\"start\":48304},{\"end\":48327,\"start\":48317},{\"end\":48522,\"start\":48516},{\"end\":48530,\"start\":48526},{\"end\":48537,\"start\":48534},{\"end\":48548,\"start\":48541},{\"end\":48562,\"start\":48554},{\"end\":48573,\"start\":48566},{\"end\":48969,\"start\":48967},{\"end\":48979,\"start\":48973},{\"end\":48985,\"start\":48983},{\"end\":48994,\"start\":48989},{\"end\":49001,\"start\":48998},{\"end\":49008,\"start\":49005},{\"end\":49453,\"start\":49445},{\"end\":49463,\"start\":49457},{\"end\":49479,\"start\":49467},{\"end\":49491,\"start\":49483},{\"end\":49903,\"start\":49895},{\"end\":49918,\"start\":49909},{\"end\":49931,\"start\":49924},{\"end\":49942,\"start\":49937},{\"end\":50336,\"start\":50333},{\"end\":50348,\"start\":50340},{\"end\":50361,\"start\":50354},{\"end\":50372,\"start\":50365},{\"end\":50757,\"start\":50753},{\"end\":50766,\"start\":50761},{\"end\":50772,\"start\":50770},{\"end\":50778,\"start\":50776},{\"end\":51029,\"start\":51018},{\"end\":51037,\"start\":51033},{\"end\":51043,\"start\":51041},{\"end\":51053,\"start\":51047},{\"end\":51065,\"start\":51057},{\"end\":51071,\"start\":51069},{\"end\":51080,\"start\":51075},{\"end\":51092,\"start\":51084},{\"end\":51102,\"start\":51096},{\"end\":51115,\"start\":51106},{\"end\":51422,\"start\":51419},{\"end\":51433,\"start\":51429},{\"end\":51441,\"start\":51437},{\"end\":51451,\"start\":51448},{\"end\":51460,\"start\":51458},{\"end\":51638,\"start\":51635},{\"end\":51940,\"start\":51931},{\"end\":51950,\"start\":51944},{\"end\":51958,\"start\":51954},{\"end\":52316,\"start\":52312},{\"end\":52323,\"start\":52320},{\"end\":52329,\"start\":52327},{\"end\":52337,\"start\":52333},{\"end\":52344,\"start\":52341},{\"end\":52703,\"start\":52699},{\"end\":52710,\"start\":52707},{\"end\":52718,\"start\":52714},{\"end\":52724,\"start\":52722},{\"end\":52731,\"start\":52728},{\"end\":53173,\"start\":53167},{\"end\":53184,\"start\":53177},{\"end\":53191,\"start\":53188},{\"end\":53200,\"start\":53195},{\"end\":53691,\"start\":53688},{\"end\":53699,\"start\":53695},{\"end\":53705,\"start\":53703},{\"end\":53712,\"start\":53709},{\"end\":53725,\"start\":53718},{\"end\":54029,\"start\":54015},{\"end\":54046,\"start\":54033},{\"end\":54057,\"start\":54052},{\"end\":54070,\"start\":54063},{\"end\":54386,\"start\":54383},{\"end\":54394,\"start\":54390},{\"end\":54403,\"start\":54401},{\"end\":54410,\"start\":54407},{\"end\":54418,\"start\":54414},{\"end\":54430,\"start\":54427},{\"end\":54784,\"start\":54778},{\"end\":54794,\"start\":54788},{\"end\":54804,\"start\":54798},{\"end\":54818,\"start\":54808},{\"end\":54829,\"start\":54822},{\"end\":55149,\"start\":55146},{\"end\":55160,\"start\":55153},{\"end\":55168,\"start\":55164},{\"end\":55176,\"start\":55172},{\"end\":55184,\"start\":55180},{\"end\":55191,\"start\":55188},{\"end\":55202,\"start\":55199},{\"end\":55762,\"start\":55756},{\"end\":55773,\"start\":55768},{\"end\":55781,\"start\":55777},{\"end\":56012,\"start\":56009},{\"end\":56021,\"start\":56018},{\"end\":56029,\"start\":56025},{\"end\":56036,\"start\":56033},{\"end\":56048,\"start\":56040},{\"end\":56459,\"start\":56454},{\"end\":56466,\"start\":56463},{\"end\":56472,\"start\":56470},{\"end\":56483,\"start\":56478},{\"end\":56745,\"start\":56740},{\"end\":56753,\"start\":56749},{\"end\":56760,\"start\":56757},{\"end\":56768,\"start\":56764},{\"end\":57124,\"start\":57119},{\"end\":57134,\"start\":57130},{\"end\":57455,\"start\":57453},{\"end\":57469,\"start\":57461},{\"end\":57479,\"start\":57475},{\"end\":57843,\"start\":57839},{\"end\":57853,\"start\":57845},{\"end\":57862,\"start\":57855},{\"end\":58193,\"start\":58181},{\"end\":58202,\"start\":58197},{\"end\":58216,\"start\":58206},{\"end\":58224,\"start\":58220},{\"end\":58628,\"start\":58623},{\"end\":58638,\"start\":58635},{\"end\":58984,\"start\":58978},{\"end\":58993,\"start\":58988},{\"end\":59003,\"start\":58999},{\"end\":59235,\"start\":59231},{\"end\":59243,\"start\":59239},{\"end\":59252,\"start\":59247},{\"end\":59260,\"start\":59256},{\"end\":59267,\"start\":59264},{\"end\":59624,\"start\":59618},{\"end\":59630,\"start\":59628},{\"end\":59643,\"start\":59636},{\"end\":59660,\"start\":59647},{\"end\":59669,\"start\":59664},{\"end\":59680,\"start\":59675},{\"end\":60033,\"start\":60027},{\"end\":60039,\"start\":60037},{\"end\":60056,\"start\":60043},{\"end\":60068,\"start\":60063},{\"end\":60081,\"start\":60072},{\"end\":60092,\"start\":60087},{\"end\":60335,\"start\":60327},{\"end\":60355,\"start\":60342},{\"end\":60495,\"start\":60490},{\"end\":60636,\"start\":60632},{\"end\":60643,\"start\":60640},{\"end\":60649,\"start\":60647},{\"end\":60658,\"start\":60655},{\"end\":60665,\"start\":60662},{\"end\":60673,\"start\":60669},{\"end\":60681,\"start\":60677},{\"end\":60698,\"start\":60685},{\"end\":60707,\"start\":60702},{\"end\":60719,\"start\":60716},{\"end\":61114,\"start\":61101},{\"end\":61287,\"start\":61281},{\"end\":61295,\"start\":61291},{\"end\":61306,\"start\":61299},{\"end\":61648,\"start\":61644},{\"end\":61656,\"start\":61652},{\"end\":61665,\"start\":61660},{\"end\":61677,\"start\":61669},{\"end\":61687,\"start\":61683},{\"end\":62076,\"start\":62069},{\"end\":62390,\"start\":62386},{\"end\":62399,\"start\":62394},{\"end\":62409,\"start\":62403},{\"end\":62609,\"start\":62604},{\"end\":62620,\"start\":62611},{\"end\":62629,\"start\":62622},{\"end\":62744,\"start\":62742},{\"end\":62750,\"start\":62748},{\"end\":62757,\"start\":62754},{\"end\":62765,\"start\":62761},{\"end\":62773,\"start\":62769},{\"end\":62781,\"start\":62777},{\"end\":63098,\"start\":63092},{\"end\":63107,\"start\":63102},{\"end\":63117,\"start\":63113},{\"end\":63465,\"start\":63460},{\"end\":63475,\"start\":63469},{\"end\":63485,\"start\":63481},{\"end\":63807,\"start\":63805},{\"end\":63816,\"start\":63811},{\"end\":63823,\"start\":63820},{\"end\":63830,\"start\":63827},{\"end\":64230,\"start\":64225},{\"end\":64237,\"start\":64234},{\"end\":64255,\"start\":64241},{\"end\":64271,\"start\":64261},{\"end\":64718,\"start\":64712},{\"end\":64727,\"start\":64722},{\"end\":64739,\"start\":64731},{\"end\":64753,\"start\":64743},{\"end\":64761,\"start\":64757},{\"end\":65110,\"start\":65104},{\"end\":65116,\"start\":65114},{\"end\":65328,\"start\":65317},{\"end\":65593,\"start\":65591},{\"end\":65602,\"start\":65597},{\"end\":65619,\"start\":65606},{\"end\":65630,\"start\":65623},{\"end\":65642,\"start\":65634},{\"end\":65917,\"start\":65912},{\"end\":65927,\"start\":65923},{\"end\":65939,\"start\":65931},{\"end\":65949,\"start\":65945}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":34338,\"start\":34161},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":102350656},\"end\":34701,\"start\":34340},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":220369389},\"end\":34994,\"start\":34703},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4493958},\"end\":35477,\"start\":34996},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":195350771},\"end\":36055,\"start\":35479},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":23339528},\"end\":36538,\"start\":36057},{\"attributes\":{\"id\":\"b6\"},\"end\":36895,\"start\":36540},{\"attributes\":{\"id\":\"b7\"},\"end\":37305,\"start\":36897},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":9971732},\"end\":37778,\"start\":37307},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":21618854},\"end\":38217,\"start\":37780},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":6540453},\"end\":38725,\"start\":38219},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":211227},\"end\":39370,\"start\":38727},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":52154773},\"end\":39847,\"start\":39372},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":49657846},\"end\":40303,\"start\":39849},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3619954},\"end\":40764,\"start\":40305},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":201641096},\"end\":41154,\"start\":40766},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":27001523},\"end\":41281,\"start\":41156},{\"attributes\":{\"id\":\"b17\"},\"end\":41659,\"start\":41283},{\"attributes\":{\"id\":\"b18\"},\"end\":41885,\"start\":41661},{\"attributes\":{\"id\":\"b19\"},\"end\":41965,\"start\":41887},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":201890471},\"end\":42364,\"start\":41967},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":52903191},\"end\":42650,\"start\":42366},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":4789479},\"end\":42980,\"start\":42652},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":69636587},\"end\":43403,\"start\":42982},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":146811808},\"end\":43768,\"start\":43405},{\"attributes\":{\"id\":\"b25\"},\"end\":44004,\"start\":43770},{\"attributes\":{\"id\":\"b26\"},\"end\":44186,\"start\":44006},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":56169832},\"end\":44600,\"start\":44188},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":40382723},\"end\":45120,\"start\":44602},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":3684930},\"end\":45455,\"start\":45122},{\"attributes\":{\"id\":\"b30\"},\"end\":45485,\"start\":45457},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":52187854},\"end\":45909,\"start\":45487},{\"attributes\":{\"id\":\"b32\"},\"end\":46195,\"start\":45911},{\"attributes\":{\"id\":\"b33\"},\"end\":46231,\"start\":46197},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":209901099},\"end\":46528,\"start\":46233},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":73422882},\"end\":46958,\"start\":46530},{\"attributes\":{\"doi\":\"arXiv:2007.07099\",\"id\":\"b36\"},\"end\":47236,\"start\":46960},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":70006821},\"end\":47576,\"start\":47238},{\"attributes\":{\"doi\":\"arXiv:1911.02833\",\"id\":\"b38\"},\"end\":47880,\"start\":47578},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":214780768},\"end\":48251,\"start\":47882},{\"attributes\":{\"doi\":\"arXiv:1611.01704\",\"id\":\"b40\"},\"end\":48485,\"start\":48253},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":53731352},\"end\":48910,\"start\":48487},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":54441811},\"end\":49392,\"start\":48912},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":207934112},\"end\":49838,\"start\":49394},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":201058384},\"end\":50297,\"start\":49840},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":877989},\"end\":50594,\"start\":50299},{\"attributes\":{\"doi\":\"10.1007/s11263-015-0812-2\",\"id\":\"b46\"},\"end\":50675,\"start\":50596},{\"attributes\":{\"doi\":\"arXiv:1812.02898\",\"id\":\"b47\"},\"end\":50963,\"start\":50677},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":2930547},\"end\":51413,\"start\":50965},{\"attributes\":{\"id\":\"b49\"},\"end\":51524,\"start\":51415},{\"attributes\":{\"id\":\"b50\"},\"end\":51840,\"start\":51526},{\"attributes\":{\"id\":\"b51\"},\"end\":52233,\"start\":51842},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":133608545},\"end\":52611,\"start\":52235},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":202763148},\"end\":53023,\"start\":52613},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":64193},\"end\":53641,\"start\":53025},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":40412298},\"end\":53948,\"start\":53643},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":206724285},\"end\":54323,\"start\":53950},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":16474148},\"end\":54694,\"start\":54325},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":17219245},\"end\":55142,\"start\":54696},{\"attributes\":{\"id\":\"b59\"},\"end\":55680,\"start\":55144},{\"attributes\":{\"doi\":\"arXiv:1212.0402\",\"id\":\"b60\"},\"end\":55960,\"start\":55682},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":9207762},\"end\":56382,\"start\":55962},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":3983536},\"end\":56687,\"start\":56384},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":52191675},\"end\":56999,\"start\":56689},{\"attributes\":{\"id\":\"b64\"},\"end\":57035,\"start\":57001},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":15956455},\"end\":57389,\"start\":57037},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":191526704},\"end\":57743,\"start\":57391},{\"attributes\":{\"id\":\"b67\"},\"end\":57835,\"start\":57745},{\"attributes\":{\"id\":\"b68\"},\"end\":57956,\"start\":57837},{\"attributes\":{\"id\":\"b69\"},\"end\":58099,\"start\":57958},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":479948},\"end\":58521,\"start\":58101},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":49558972},\"end\":58932,\"start\":58523},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":69702720},\"end\":59191,\"start\":58934},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":21016627},\"end\":59543,\"start\":59193},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":23745377},\"end\":59953,\"start\":59545},{\"attributes\":{\"doi\":\"arXiv:1808.03898\",\"id\":\"b75\"},\"end\":60317,\"start\":59955},{\"attributes\":{\"id\":\"b76\"},\"end\":60453,\"start\":60319},{\"attributes\":{\"id\":\"b77\"},\"end\":60563,\"start\":60455},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":11387097},\"end\":61054,\"start\":60565},{\"attributes\":{\"id\":\"b79\"},\"end\":61237,\"start\":61056},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":7515044},\"end\":61560,\"start\":61239},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":24233477},\"end\":61996,\"start\":61562},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":11352985},\"end\":62304,\"start\":61998},{\"attributes\":{\"id\":\"b83\"},\"end\":62596,\"start\":62306},{\"attributes\":{\"id\":\"b84\"},\"end\":62673,\"start\":62598},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":195187461},\"end\":63022,\"start\":62675},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":57754684},\"end\":63388,\"start\":63024},{\"attributes\":{\"id\":\"b87\",\"matched_paper_id\":198359318},\"end\":63755,\"start\":63390},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":206594692},\"end\":64179,\"start\":63757},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":9433631},\"end\":64640,\"start\":64181},{\"attributes\":{\"id\":\"b90\",\"matched_paper_id\":3457283},\"end\":65054,\"start\":64642},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b91\"},\"end\":65254,\"start\":65056},{\"attributes\":{\"id\":\"b92\",\"matched_paper_id\":61598325},\"end\":65535,\"start\":65256},{\"attributes\":{\"id\":\"b93\"},\"end\":65822,\"start\":65537},{\"attributes\":{\"id\":\"b94\",\"matched_paper_id\":52289167},\"end\":66198,\"start\":65824}]", "bib_title": "[{\"end\":34398,\"start\":34340},{\"end\":34762,\"start\":34703},{\"end\":35068,\"start\":34996},{\"end\":35559,\"start\":35479},{\"end\":36117,\"start\":36057},{\"end\":36595,\"start\":36540},{\"end\":36958,\"start\":36897},{\"end\":37377,\"start\":37307},{\"end\":37838,\"start\":37780},{\"end\":38284,\"start\":38219},{\"end\":38811,\"start\":38727},{\"end\":39437,\"start\":39372},{\"end\":39923,\"start\":39849},{\"end\":40354,\"start\":40305},{\"end\":40824,\"start\":40766},{\"end\":41184,\"start\":41156},{\"end\":41362,\"start\":41283},{\"end\":41694,\"start\":41661},{\"end\":42035,\"start\":41967},{\"end\":42427,\"start\":42366},{\"end\":42715,\"start\":42652},{\"end\":43071,\"start\":42982},{\"end\":43490,\"start\":43405},{\"end\":44280,\"start\":44188},{\"end\":44711,\"start\":44602},{\"end\":45194,\"start\":45122},{\"end\":45580,\"start\":45487},{\"end\":45951,\"start\":45911},{\"end\":46310,\"start\":46233},{\"end\":46626,\"start\":46530},{\"end\":47299,\"start\":47238},{\"end\":47955,\"start\":47882},{\"end\":48512,\"start\":48487},{\"end\":48963,\"start\":48912},{\"end\":49441,\"start\":49394},{\"end\":49891,\"start\":49840},{\"end\":50329,\"start\":50299},{\"end\":51014,\"start\":50965},{\"end\":51927,\"start\":51842},{\"end\":52308,\"start\":52235},{\"end\":52695,\"start\":52613},{\"end\":53163,\"start\":53025},{\"end\":53684,\"start\":53643},{\"end\":54011,\"start\":53950},{\"end\":54377,\"start\":54325},{\"end\":54774,\"start\":54696},{\"end\":56005,\"start\":55962},{\"end\":56450,\"start\":56384},{\"end\":56736,\"start\":56689},{\"end\":57115,\"start\":57037},{\"end\":57449,\"start\":57391},{\"end\":58175,\"start\":58101},{\"end\":58619,\"start\":58523},{\"end\":58974,\"start\":58934},{\"end\":59227,\"start\":59193},{\"end\":59612,\"start\":59545},{\"end\":60628,\"start\":60565},{\"end\":61097,\"start\":61056},{\"end\":61277,\"start\":61239},{\"end\":61638,\"start\":61562},{\"end\":62065,\"start\":61998},{\"end\":62738,\"start\":62675},{\"end\":63088,\"start\":63024},{\"end\":63456,\"start\":63390},{\"end\":63801,\"start\":63757},{\"end\":64221,\"start\":64181},{\"end\":64708,\"start\":64642},{\"end\":65313,\"start\":65256},{\"end\":65587,\"start\":65537},{\"end\":65908,\"start\":65824}]", "bib_author": "[{\"end\":34231,\"start\":34221},{\"end\":34406,\"start\":34400},{\"end\":34415,\"start\":34406},{\"end\":34422,\"start\":34415},{\"end\":34430,\"start\":34422},{\"end\":34438,\"start\":34430},{\"end\":34447,\"start\":34438},{\"end\":34771,\"start\":34764},{\"end\":34777,\"start\":34771},{\"end\":34784,\"start\":34777},{\"end\":34790,\"start\":34784},{\"end\":34796,\"start\":34790},{\"end\":35083,\"start\":35070},{\"end\":35094,\"start\":35083},{\"end\":35568,\"start\":35561},{\"end\":35576,\"start\":35568},{\"end\":35584,\"start\":35576},{\"end\":35592,\"start\":35584},{\"end\":35599,\"start\":35592},{\"end\":35610,\"start\":35599},{\"end\":35621,\"start\":35610},{\"end\":36126,\"start\":36119},{\"end\":36134,\"start\":36126},{\"end\":36141,\"start\":36134},{\"end\":36148,\"start\":36141},{\"end\":36156,\"start\":36148},{\"end\":36165,\"start\":36156},{\"end\":36174,\"start\":36165},{\"end\":36605,\"start\":36597},{\"end\":36614,\"start\":36605},{\"end\":36620,\"start\":36614},{\"end\":36628,\"start\":36620},{\"end\":36968,\"start\":36960},{\"end\":36977,\"start\":36968},{\"end\":36985,\"start\":36977},{\"end\":37386,\"start\":37379},{\"end\":37393,\"start\":37386},{\"end\":37404,\"start\":37393},{\"end\":37847,\"start\":37840},{\"end\":37855,\"start\":37847},{\"end\":37862,\"start\":37855},{\"end\":38293,\"start\":38286},{\"end\":38300,\"start\":38293},{\"end\":38307,\"start\":38300},{\"end\":38314,\"start\":38307},{\"end\":38325,\"start\":38314},{\"end\":38822,\"start\":38813},{\"end\":38831,\"start\":38822},{\"end\":38841,\"start\":38831},{\"end\":38854,\"start\":38841},{\"end\":38868,\"start\":38854},{\"end\":38878,\"start\":38868},{\"end\":38888,\"start\":38878},{\"end\":38898,\"start\":38888},{\"end\":38906,\"start\":38898},{\"end\":38914,\"start\":38906},{\"end\":39447,\"start\":39439},{\"end\":39453,\"start\":39447},{\"end\":39459,\"start\":39453},{\"end\":39465,\"start\":39459},{\"end\":39472,\"start\":39465},{\"end\":39480,\"start\":39472},{\"end\":39488,\"start\":39480},{\"end\":39503,\"start\":39488},{\"end\":39934,\"start\":39925},{\"end\":39940,\"start\":39934},{\"end\":39946,\"start\":39940},{\"end\":39954,\"start\":39946},{\"end\":39963,\"start\":39954},{\"end\":39969,\"start\":39963},{\"end\":40365,\"start\":40356},{\"end\":40373,\"start\":40365},{\"end\":40381,\"start\":40373},{\"end\":40390,\"start\":40381},{\"end\":40396,\"start\":40390},{\"end\":40832,\"start\":40826},{\"end\":40844,\"start\":40832},{\"end\":40853,\"start\":40844},{\"end\":40863,\"start\":40853},{\"end\":41201,\"start\":41186},{\"end\":41374,\"start\":41364},{\"end\":41383,\"start\":41374},{\"end\":41389,\"start\":41383},{\"end\":41400,\"start\":41389},{\"end\":41411,\"start\":41400},{\"end\":41705,\"start\":41696},{\"end\":41713,\"start\":41705},{\"end\":41720,\"start\":41713},{\"end\":41731,\"start\":41720},{\"end\":42051,\"start\":42037},{\"end\":42060,\"start\":42051},{\"end\":42070,\"start\":42060},{\"end\":42080,\"start\":42070},{\"end\":42439,\"start\":42429},{\"end\":42451,\"start\":42439},{\"end\":42462,\"start\":42451},{\"end\":42473,\"start\":42462},{\"end\":42723,\"start\":42717},{\"end\":42729,\"start\":42723},{\"end\":42735,\"start\":42729},{\"end\":42744,\"start\":42735},{\"end\":42751,\"start\":42744},{\"end\":43081,\"start\":43073},{\"end\":43089,\"start\":43081},{\"end\":43097,\"start\":43089},{\"end\":43106,\"start\":43097},{\"end\":43112,\"start\":43106},{\"end\":43120,\"start\":43112},{\"end\":43500,\"start\":43492},{\"end\":43508,\"start\":43500},{\"end\":43517,\"start\":43508},{\"end\":43525,\"start\":43517},{\"end\":43531,\"start\":43525},{\"end\":43538,\"start\":43531},{\"end\":43859,\"start\":43851},{\"end\":43871,\"start\":43859},{\"end\":43884,\"start\":43871},{\"end\":44291,\"start\":44282},{\"end\":44299,\"start\":44291},{\"end\":44310,\"start\":44299},{\"end\":44723,\"start\":44713},{\"end\":44735,\"start\":44723},{\"end\":44746,\"start\":44735},{\"end\":44760,\"start\":44746},{\"end\":45204,\"start\":45196},{\"end\":45211,\"start\":45204},{\"end\":45217,\"start\":45211},{\"end\":45223,\"start\":45217},{\"end\":45588,\"start\":45582},{\"end\":45595,\"start\":45588},{\"end\":45603,\"start\":45595},{\"end\":45609,\"start\":45603},{\"end\":45959,\"start\":45953},{\"end\":45967,\"start\":45959},{\"end\":45974,\"start\":45967},{\"end\":45983,\"start\":45974},{\"end\":46320,\"start\":46312},{\"end\":46326,\"start\":46320},{\"end\":46334,\"start\":46326},{\"end\":46343,\"start\":46334},{\"end\":46351,\"start\":46343},{\"end\":46359,\"start\":46351},{\"end\":46635,\"start\":46628},{\"end\":46643,\"start\":46635},{\"end\":46652,\"start\":46643},{\"end\":46660,\"start\":46652},{\"end\":46667,\"start\":46660},{\"end\":46673,\"start\":46667},{\"end\":46679,\"start\":46673},{\"end\":47040,\"start\":47034},{\"end\":47049,\"start\":47040},{\"end\":47059,\"start\":47049},{\"end\":47308,\"start\":47301},{\"end\":47315,\"start\":47308},{\"end\":47323,\"start\":47315},{\"end\":47329,\"start\":47323},{\"end\":47335,\"start\":47329},{\"end\":47670,\"start\":47661},{\"end\":47680,\"start\":47670},{\"end\":47690,\"start\":47680},{\"end\":47963,\"start\":47957},{\"end\":47972,\"start\":47963},{\"end\":47982,\"start\":47972},{\"end\":48302,\"start\":48293},{\"end\":48313,\"start\":48302},{\"end\":48329,\"start\":48313},{\"end\":48524,\"start\":48514},{\"end\":48532,\"start\":48524},{\"end\":48539,\"start\":48532},{\"end\":48550,\"start\":48539},{\"end\":48564,\"start\":48550},{\"end\":48575,\"start\":48564},{\"end\":48971,\"start\":48965},{\"end\":48981,\"start\":48971},{\"end\":48987,\"start\":48981},{\"end\":48996,\"start\":48987},{\"end\":49003,\"start\":48996},{\"end\":49010,\"start\":49003},{\"end\":49455,\"start\":49443},{\"end\":49465,\"start\":49455},{\"end\":49481,\"start\":49465},{\"end\":49493,\"start\":49481},{\"end\":49905,\"start\":49893},{\"end\":49920,\"start\":49905},{\"end\":49933,\"start\":49920},{\"end\":49944,\"start\":49933},{\"end\":50338,\"start\":50331},{\"end\":50350,\"start\":50338},{\"end\":50363,\"start\":50350},{\"end\":50374,\"start\":50363},{\"end\":50759,\"start\":50751},{\"end\":50768,\"start\":50759},{\"end\":50774,\"start\":50768},{\"end\":50780,\"start\":50774},{\"end\":51031,\"start\":51016},{\"end\":51039,\"start\":51031},{\"end\":51045,\"start\":51039},{\"end\":51055,\"start\":51045},{\"end\":51067,\"start\":51055},{\"end\":51073,\"start\":51067},{\"end\":51082,\"start\":51073},{\"end\":51094,\"start\":51082},{\"end\":51104,\"start\":51094},{\"end\":51117,\"start\":51104},{\"end\":51424,\"start\":51417},{\"end\":51435,\"start\":51424},{\"end\":51443,\"start\":51435},{\"end\":51453,\"start\":51443},{\"end\":51462,\"start\":51453},{\"end\":51469,\"start\":51462},{\"end\":51640,\"start\":51635},{\"end\":51942,\"start\":51929},{\"end\":51952,\"start\":51942},{\"end\":51960,\"start\":51952},{\"end\":52318,\"start\":52310},{\"end\":52325,\"start\":52318},{\"end\":52331,\"start\":52325},{\"end\":52339,\"start\":52331},{\"end\":52346,\"start\":52339},{\"end\":52705,\"start\":52697},{\"end\":52712,\"start\":52705},{\"end\":52720,\"start\":52712},{\"end\":52726,\"start\":52720},{\"end\":52733,\"start\":52726},{\"end\":53175,\"start\":53165},{\"end\":53186,\"start\":53175},{\"end\":53193,\"start\":53186},{\"end\":53202,\"start\":53193},{\"end\":53693,\"start\":53686},{\"end\":53701,\"start\":53693},{\"end\":53707,\"start\":53701},{\"end\":53714,\"start\":53707},{\"end\":53727,\"start\":53714},{\"end\":54031,\"start\":54013},{\"end\":54048,\"start\":54031},{\"end\":54059,\"start\":54048},{\"end\":54072,\"start\":54059},{\"end\":54388,\"start\":54379},{\"end\":54396,\"start\":54388},{\"end\":54405,\"start\":54396},{\"end\":54412,\"start\":54405},{\"end\":54420,\"start\":54412},{\"end\":54432,\"start\":54420},{\"end\":54786,\"start\":54776},{\"end\":54796,\"start\":54786},{\"end\":54806,\"start\":54796},{\"end\":54820,\"start\":54806},{\"end\":54831,\"start\":54820},{\"end\":55151,\"start\":55144},{\"end\":55162,\"start\":55151},{\"end\":55170,\"start\":55162},{\"end\":55178,\"start\":55170},{\"end\":55186,\"start\":55178},{\"end\":55193,\"start\":55186},{\"end\":55204,\"start\":55193},{\"end\":55764,\"start\":55754},{\"end\":55775,\"start\":55764},{\"end\":55783,\"start\":55775},{\"end\":56014,\"start\":56007},{\"end\":56023,\"start\":56014},{\"end\":56031,\"start\":56023},{\"end\":56038,\"start\":56031},{\"end\":56050,\"start\":56038},{\"end\":56461,\"start\":56452},{\"end\":56468,\"start\":56461},{\"end\":56474,\"start\":56468},{\"end\":56485,\"start\":56474},{\"end\":56747,\"start\":56738},{\"end\":56755,\"start\":56747},{\"end\":56762,\"start\":56755},{\"end\":56770,\"start\":56762},{\"end\":57126,\"start\":57117},{\"end\":57136,\"start\":57126},{\"end\":57457,\"start\":57451},{\"end\":57471,\"start\":57457},{\"end\":57481,\"start\":57471},{\"end\":57845,\"start\":57839},{\"end\":57855,\"start\":57845},{\"end\":57864,\"start\":57855},{\"end\":58195,\"start\":58177},{\"end\":58204,\"start\":58195},{\"end\":58218,\"start\":58204},{\"end\":58226,\"start\":58218},{\"end\":58630,\"start\":58621},{\"end\":58640,\"start\":58630},{\"end\":58986,\"start\":58976},{\"end\":58995,\"start\":58986},{\"end\":59005,\"start\":58995},{\"end\":59237,\"start\":59229},{\"end\":59245,\"start\":59237},{\"end\":59254,\"start\":59245},{\"end\":59262,\"start\":59254},{\"end\":59269,\"start\":59262},{\"end\":59626,\"start\":59614},{\"end\":59632,\"start\":59626},{\"end\":59645,\"start\":59632},{\"end\":59662,\"start\":59645},{\"end\":59671,\"start\":59662},{\"end\":59682,\"start\":59671},{\"end\":60035,\"start\":60023},{\"end\":60041,\"start\":60035},{\"end\":60058,\"start\":60041},{\"end\":60070,\"start\":60058},{\"end\":60083,\"start\":60070},{\"end\":60094,\"start\":60083},{\"end\":60337,\"start\":60321},{\"end\":60357,\"start\":60337},{\"end\":60497,\"start\":60457},{\"end\":60638,\"start\":60630},{\"end\":60645,\"start\":60638},{\"end\":60651,\"start\":60645},{\"end\":60660,\"start\":60651},{\"end\":60667,\"start\":60660},{\"end\":60675,\"start\":60667},{\"end\":60683,\"start\":60675},{\"end\":60700,\"start\":60683},{\"end\":60709,\"start\":60700},{\"end\":60721,\"start\":60709},{\"end\":61116,\"start\":61099},{\"end\":61289,\"start\":61279},{\"end\":61297,\"start\":61289},{\"end\":61308,\"start\":61297},{\"end\":61650,\"start\":61640},{\"end\":61658,\"start\":61650},{\"end\":61667,\"start\":61658},{\"end\":61679,\"start\":61667},{\"end\":61689,\"start\":61679},{\"end\":62078,\"start\":62067},{\"end\":62392,\"start\":62384},{\"end\":62401,\"start\":62392},{\"end\":62411,\"start\":62401},{\"end\":62611,\"start\":62600},{\"end\":62622,\"start\":62611},{\"end\":62631,\"start\":62622},{\"end\":62746,\"start\":62740},{\"end\":62752,\"start\":62746},{\"end\":62759,\"start\":62752},{\"end\":62767,\"start\":62759},{\"end\":62775,\"start\":62767},{\"end\":62783,\"start\":62775},{\"end\":63100,\"start\":63090},{\"end\":63109,\"start\":63100},{\"end\":63119,\"start\":63109},{\"end\":63467,\"start\":63458},{\"end\":63477,\"start\":63467},{\"end\":63487,\"start\":63477},{\"end\":63809,\"start\":63803},{\"end\":63818,\"start\":63809},{\"end\":63825,\"start\":63818},{\"end\":63832,\"start\":63825},{\"end\":64232,\"start\":64223},{\"end\":64239,\"start\":64232},{\"end\":64257,\"start\":64239},{\"end\":64273,\"start\":64257},{\"end\":64720,\"start\":64710},{\"end\":64729,\"start\":64720},{\"end\":64741,\"start\":64729},{\"end\":64755,\"start\":64741},{\"end\":64763,\"start\":64755},{\"end\":65112,\"start\":65100},{\"end\":65118,\"start\":65112},{\"end\":65330,\"start\":65315},{\"end\":65595,\"start\":65589},{\"end\":65604,\"start\":65595},{\"end\":65621,\"start\":65604},{\"end\":65632,\"start\":65621},{\"end\":65644,\"start\":65632},{\"end\":65919,\"start\":65910},{\"end\":65929,\"start\":65919},{\"end\":65941,\"start\":65929},{\"end\":65951,\"start\":65941}]", "bib_venue": "[{\"end\":34219,\"start\":34161},{\"end\":34509,\"start\":34447},{\"end\":34824,\"start\":34796},{\"end\":35181,\"start\":35094},{\"end\":35708,\"start\":35621},{\"end\":36247,\"start\":36174},{\"end\":36690,\"start\":36628},{\"end\":37049,\"start\":36985},{\"end\":37488,\"start\":37404},{\"end\":37945,\"start\":37862},{\"end\":38412,\"start\":38325},{\"end\":38991,\"start\":38914},{\"end\":39567,\"start\":39503},{\"end\":40033,\"start\":39969},{\"end\":40480,\"start\":40396},{\"end\":40908,\"start\":40863},{\"end\":41210,\"start\":41201},{\"end\":41459,\"start\":41411},{\"end\":41760,\"start\":41731},{\"end\":41902,\"start\":41889},{\"end\":42141,\"start\":42080},{\"end\":42484,\"start\":42473},{\"end\":42788,\"start\":42751},{\"end\":43182,\"start\":43120},{\"end\":43575,\"start\":43538},{\"end\":43849,\"start\":43770},{\"end\":44063,\"start\":44006},{\"end\":44372,\"start\":44310},{\"end\":44808,\"start\":44760},{\"end\":45275,\"start\":45223},{\"end\":45463,\"start\":45459},{\"end\":45674,\"start\":45609},{\"end\":46044,\"start\":45983},{\"end\":46203,\"start\":46199},{\"end\":46370,\"start\":46359},{\"end\":46716,\"start\":46679},{\"end\":47032,\"start\":46960},{\"end\":47397,\"start\":47335},{\"end\":47659,\"start\":47578},{\"end\":48046,\"start\":47982},{\"end\":48291,\"start\":48253},{\"end\":48649,\"start\":48575},{\"end\":49094,\"start\":49010},{\"end\":49567,\"start\":49493},{\"end\":50018,\"start\":49944},{\"end\":50414,\"start\":50374},{\"end\":50749,\"start\":50677},{\"end\":51157,\"start\":51117},{\"end\":51633,\"start\":51526},{\"end\":51992,\"start\":51960},{\"end\":52405,\"start\":52346},{\"end\":52794,\"start\":52733},{\"end\":53276,\"start\":53202},{\"end\":53767,\"start\":53727},{\"end\":54109,\"start\":54072},{\"end\":54488,\"start\":54432},{\"end\":54895,\"start\":54831},{\"end\":55291,\"start\":55204},{\"end\":55752,\"start\":55682},{\"end\":56123,\"start\":56050},{\"end\":56502,\"start\":56485},{\"end\":56836,\"start\":56770},{\"end\":57007,\"start\":57003},{\"end\":57188,\"start\":57136},{\"end\":57542,\"start\":57481},{\"end\":57776,\"start\":57745},{\"end\":57986,\"start\":57958},{\"end\":58287,\"start\":58226},{\"end\":58702,\"start\":58640},{\"end\":59036,\"start\":59005},{\"end\":59346,\"start\":59269},{\"end\":59719,\"start\":59682},{\"end\":60021,\"start\":59955},{\"end\":60782,\"start\":60721},{\"end\":61135,\"start\":61116},{\"end\":61378,\"start\":61308},{\"end\":61751,\"start\":61689},{\"end\":62130,\"start\":62078},{\"end\":62382,\"start\":62306},{\"end\":62820,\"start\":62783},{\"end\":63181,\"start\":63119},{\"end\":63548,\"start\":63487},{\"end\":63916,\"start\":63832},{\"end\":64356,\"start\":64273},{\"end\":64824,\"start\":64763},{\"end\":65098,\"start\":65056},{\"end\":65361,\"start\":65330},{\"end\":65665,\"start\":65644},{\"end\":65982,\"start\":65951},{\"end\":35255,\"start\":35183},{\"end\":35782,\"start\":35710},{\"end\":36307,\"start\":36249},{\"end\":37100,\"start\":37051},{\"end\":37559,\"start\":37490},{\"end\":38015,\"start\":37947},{\"end\":38486,\"start\":38414},{\"end\":39055,\"start\":38993},{\"end\":39618,\"start\":39569},{\"end\":40084,\"start\":40035},{\"end\":40551,\"start\":40482},{\"end\":48710,\"start\":48651},{\"end\":49165,\"start\":49096},{\"end\":49628,\"start\":49569},{\"end\":50079,\"start\":50020},{\"end\":52027,\"start\":52008},{\"end\":53337,\"start\":53278},{\"end\":55365,\"start\":55293},{\"end\":56183,\"start\":56125},{\"end\":63987,\"start\":63918},{\"end\":64426,\"start\":64358},{\"end\":65386,\"start\":65373}]"}}}, "year": 2023, "month": 12, "day": 17}