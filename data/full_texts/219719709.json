{"id": 219719709, "updated": "2022-11-08 14:43:45.932", "metadata": {"title": "Significantly Improving Lossy Compression for HPC Datasets with Second-Order Prediction and Parameter Optimization", "authors": "[{\"first\":\"Kai\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Sheng\",\"last\":\"Di\",\"middle\":[]},{\"first\":\"Xin\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Sihuan\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Dingwen\",\"last\":\"Tao\",\"middle\":[]},{\"first\":\"Zizhong\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Franck\",\"last\":\"Cappello\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Today's extreme-scale high-performance computing (HPC) applications are producing volumes of data too large to save or transfer because of limited storage space and I/O bandwidth. Error-bounded lossy compression has been commonly known as one of the best solutions to the big science data issue, because it can significantly reduce the data volume with strictly controlled data distortion based on user requirements. In this work, we develop an adaptive parameter optimization algorithm integrated with a series of optimization strategies for SZ, a state-of-the-art prediction-based compression model. Our contribution is threefold. (1) We exploit effective strategies by using 2nd-order regression and 2nd-order Lorenzo predictors to improve the prediction accuracy significantly for SZ, thus substantially improving the overall compression quality. (2) We design an efficient approach selecting the best-fit parameter setting, by conducting a comprehensive priori compression quality analysis and exploiting an efficient online controlling mechanism. (3) We evaluate the compression quality and performance on a supercomputer with 4,096 cores, as compared with other state-of-the-art error-bounded lossy compressors. Experiments with multiple real-world HPC simulations datasets show that our solution can improve the compression ratio up to 46% compared with the second-best compressor. Moreover, the parallel I/O performance is improved by up to 40% thanks to the significant reduction of data size.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3037979316", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/hpdc/ZhaoDLLTCC20", "doi": "10.1145/3369583.3392688"}}, "content": {"source": {"pdf_hash": "71f9f406e128d9f7f9d0f97474aeaf32aa5618f4", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3369583.3392688", "status": "BRONZE"}}, "grobid": {"id": "0f9134046c3cfba323beafc3c9c3381f6c09bb6f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/71f9f406e128d9f7f9d0f97474aeaf32aa5618f4.txt", "contents": "\nSignificantly Improving Lossy Compression for HPC Datasets with Second-Order Prediction and Parameter Optimization\nACMCopyright ACMJune 23-26, 2020\n\nKai Zhao \nSheng Di \nXin Liang \nSihuan Li \nDingwen Tao dingwen.tao@wsu.edu \nZizhong Chen chen@cs.ucr.edu \nFranck Cappello cappello@mcs.anl.gov \nKai Zhao \nSheng Di \nXin Liang \nSihuan Li \nDingwen Tao \nZizhong Chen \n\nArgonne National Laboratory Lemont\nUniversity of California\nRiverside RiversideCA, IL\n\n\nUniversity of California\nRiverside RiversideCA\n\n\nUniversity of California\nRiverside RiversideCA\n\n\nWashington State University\nPullmanWA\n\n\nArgonne National Laboratory Lemont\nUniversity of California\nRiverside Riverside, StockholmCA, ILSweden\n\nSignificantly Improving Lossy Compression for HPC Datasets with Second-Order Prediction and Parameter Optimization\n\nProceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing (HPDC '20)\nthe 29th International Symposium on High-Performance Parallel and Distributed Computing (HPDC '20)Stockholm, Sweden; New York, NY, USAACM12June 23-26, 202010.1145/3369583.3392688* Corresponding author: Sheng Di, Mathematics and Computer Science Division, Argonne National Laboratory, Lemont, IL 60439 Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). HPDC '20, ACM Reference Format: and Franck Cappello. 2020. Significantly Improving Lossy Compression for HPC Datasets with Second-Order Prediction and Parameter Optimization. InLossy CompressionScience DataParameter OptimizationRate DistortionHigh-Performance Computing\nToday's extreme-scale high-performance computing (HPC) applications are producing volumes of data too large to save or transfer because of limited storage space and I/O bandwidth. Error-bounded lossy compression has been commonly known as one of the best solutions to the big science data issue, because it can significantly reduce the data volume with strictly controlled data distortion based on user requirements. In this work, we develop an adaptive parameter optimization algorithm integrated with a series of optimization strategies for SZ, a state-of-the-art prediction-based compression model. Our contribution is threefold. (1) We exploit effective strategies by using 2nd-order regression and 2nd-order Lorenzo predictors to improve the prediction accuracy significantly for SZ, thus substantially improving the overall compression quality.(2) We design an efficient approach selecting the best-fit parameter setting, by conducting a comprehensive priori compression quality analysis and exploiting an efficient online controlling mechanism.(3) We evaluate the compression quality and performance on a supercomputer with 4,096 cores, as compared with other state-ofthe-art error-bounded lossy compressors. Experiments with multiple real-world HPC simulations datasets show that our solution can improve the compression ratio up to 46% compared with the second-best compressor. Moreover, the parallel I/O performance is improved by up to 40% thanks to the significant reduction of data size.\n\nINTRODUCTION\n\nExtremely large amounts of data are being produced by today's high-performance computing (HPC) applications. Serious conflicts between the vast volume of data produced and the limited resources (such as limited storage space, I/O bandwidth, and memory capacity) significantly hinders today's HPC applications from scaling up in a parallel environment. According to cosmologists, HACC cosmology simulations [16] may produce 20+ petebytes of data during one run when simulating 1 trillion particles for hundreds of timesteps (or snapshots), while the most powerful supercomputer-the Summit supercomputer at Oak Ridge National Laboratory (ORNL) [36]-can provide only hundreds of terabytes of storage for ordinary users or at most several petabytes for specific users. Quantum computing simulation [20] may produce up to 32 exabytes of data, which need to be compressed and decompressed during the simulation because of inadequate memory space (e.g., Summit has only 2.8 PB of memory capacity in total).\n\nCompression techniques designed particularly for big science data have been studied for years. Lossless compressors are not suitable for science data in that the science data are composed mainly of floating-point values that involve disordered ending mantissa bits in their binary representations, such that few repeated patterns could be found in the data streams. Error-bounded lossy compression has been considered a promising solution because not only can it significantly reduce the data size (by 10\u00d7 or even 100\u00d7) but it can also strictly control the data distortion based on user-specified error bounds. In fact, error-bounded lossy compressors have been broadly verified as helpful in saving storage space and improving I/O performance for many production-level applications across different domains, such as cosmology [19,30], molecular dynamics [31], climate [18,44], and quantum computing [20].\n\nError-bounded lossy compression can be categorized into two models: prediction-based or transform-based. In general, the former performs data prediction for each value in the dataset and then converts the floating-point values to integer quantization codes, followed by an entropy encoding [17] and dictionary coding [48]. SZ [12,24,37], FPZIP [27], and ISABELA [21] are three typical examples adopting the prediction-based model. The transformbased compression model performs orthogonal data transforms to convert the original dataset to another data domain and then removes insignificant values [33] or adopts embedded coding [25] to shrink the size. Typical examples are ZFP [25] and wavelet-based compression [33]. Much prior work [4,12,26] has demonstrated that SZ and ZFP are the two top error-bounded lossy compressors in most cases; however, none of them can always exhibit the best compression quality on all datasets.\n\nOur research objective is to significantly improve the compression quality of the SZ compression model [12,37] for most of the datasets across from different domains. Such a research goal is challenging. On the one hand, SZ has been developed for many years, so its design and implementation have been tuned to a fairly optimized level, making further improvement to the compression quality difficult. On the other, many parameter settings (such as block size, dimension order, and regression order) are involved in the prediction-based compression model, making it nontrivial to select the best-fit combination to get the optimal compression quality, especially because of fairly diverse data characteristics in the datasets.\n\nIn this paper, we successfully leverage adaptive parameter optimization techniques with a series of optimization strategies on data prediction, which can significantly improve the compression quality for SZ with the same level of data distortion. Our contributions can be summarized as follows.\n\n\u2022 We develop optimization strategies utilizing 2nd-order Lorenzo and 2nd-order regression prediction to improve the prediction accuracy significantly for SZ, such that the overall compression quality can be improved prominently in many cases. \u2022 We design an efficient approach selecting the best-fit parameter settings during the compression. Specifically, we perform a comprehensive priori compression quality analysis to filter out the inferior settings based on error bounds and data characteristics, and we then exploit an efficient online controlling mechanism to determine the best-fit setting at runtime. \u2022 We evaluate the compression quality and performance by running our new compression solution on a supercomputer with 4,096 cores, as compared with other state-of-the-art error-bounded lossy compressors.\n\nThe rest of the paper is organized as follows. In Section 2, we discuss related work. In Section 3, we formulate the research problem.\n\nIn Section 4, we provide an overview of our design and implementation. Section 5 and Section 6 describe our major solution (2nd-order prediction and parameter optimization) in detail. In Section 7, we present the evaluation results from using multiple real-world simulation datasets on a supercomputer. In Section 8, we present our conclusions and discuss our future work.\n\n\nRELATED WORK\n\nTo mitigate the storage burden and I/O bottleneck presented by huge volumes of data, researchers have developed many data compressors. Lossless compressors [2,5,9,11,17,47,48] can guarantee that reconstructed data suffer from no data distortion; however, they cannot significantly reduce the scientific data size because of the random ending mantissa bits in the floating-point values. Their compression ratios are usually around 2 [26,32,34], far from the desired level for large-scale scientific simulations running on modern HPC systems [6,13].\n\nIn contrast, error-bounded lossy compressors have been effective in significantly reducing the science data volume for extreme-scale simulations while being able to strictly control the data distortion based on user requirements on pointwise compression errors. Two state-of-the-art models exist for error-bounded lossy compression: prediction-based [7,12,14,21,23,24,27,37] and transform-based [10,25,33,39,43]. SZ [12,24,37], ISABELA [21], FPZIP [27], and NUMARCK [7] are typical prediction-based compressors. Prior work [24] shows that SZ leads the compression quality among all the prediction-based compressors. SZ includes four key steps: data prediction, linear-scaling quantization, customized variable-length encoding, and dictionary encoding such as gzip [11] or zstd [48]. Vapor [10] and ZFP [25] are typical transform-based compressors. They use different data transformation methods (wavelet transform and a customized (non)orthogonal transform, respectively) and different encoding algorithms. Recent research [25,37] indicates that ZFP is one of the best error-controlled lossy compressors for scientific simulation datasets. ZFP compresses the dataset block by block (blocksize: 4\u00d74 for 2D data and 4\u00d74\u00d74 for 3D data). Each block involves four steps: exponent alignment, fixed-point alignment, (non)orthogonal block transform to decorrelate the values, and embedded encoding of the ordered coefficients one \"bit plane\" at a time.\n\nNo existing error-bounded lossy compressor can always exhibit the best compression quality (or rate distortion) over all other compressors in most cases. Prior experiments [38], for example, show that neither SZ nor ZFP consistently provides the best compression results on the 13 fields of the Hurricane ISABEL dataset or on the 100+ fields of the CESM-ATM climate simulation dataset.\n\nTo address this issue, some researchers studied how to improve the compression quality by combining the two compression models intuitively. Lu et al. [28] concluded that SZ and ZFP were the two best error-bounded lossy compressors. The authors also proposed a solution to estimate the compression ratios for SZ and ZFP, respectively. In [38], they explored an online approach that can select the better strategy between SZ and ZFP in terms of peak signal-to-noise ratio (PSNR). This solution, however, [24] is subject to the existing compression quality and performance of SZ and ZFP. Moreover, the two related works both used the outdated version of SZ (SZ1.4), which exhibits much worse compression quality than does the latest SZ version (SZ2.0) [24]. Liang et al. [22] proposed a compression method that treats ZFP's data transform as one predictor (called a transform-based predictor) in the SZ compression model and selects the better one between SZ's built-in predictor and the transform-based predictor, which can prominently improve the compression quality beyond SZ and ZFP. Compared with all these works, we develop an efficient approach that can further improve the compression quality of SZ. Specifically, experiments with multiple real-world HPC simulation datasets show that our approach can improve the compression quality by 10%\u223c46% over the second-best approach in most cases.\n\n\nPROBLEM FORMULATION\n\nOur objective in this work is to significantly improve the compression quality for error-bounded lossy compression. Similar to related work [22,24,37], we focus on structured datasets (i.e., 1D, 2D, or 3D structured mesh), because unstructured datasets (unable to be represented by a regular mesh grid) either need particular compression strategies [1] or are treated as 1D datasets for simplicity [8].\n\nThe error-bounded lossy compression problem can be formulated as follows: Given a structured mesh dataset (denoted by D = {d 1 , d 2 , \u00b7 \u00b7 \u00b7 , d N }) with N floating-point data values, how can the data be compressed to obtain a high compression quality, while the reconstructed data (denoted D \u2032 ) still strictly respect user-specified pointwise error bounds?\n\nIn the error-bounded lossy compression community, three ways have been formulated to assess compression quality in general.\n\n(1) Checking the compression ratio (defined as the ratio of the original raw data size to the compressed data size) based on the same error bound for different compressors. (2) Using rate distortion, a common indicator in the visualization community. Rate distortion involves two metrics: bit rate and data distortion. Bit-rate distortion is the average number of bits used to represent one data point after compression. The smaller the bit rate, the higher the compression ratio. Distortion is usually evaluated by using the peak signal-tonoise ratio, which is defined in Formula (1). In general, the higher the PSNR, the better the compression result.\nPSN R = 20\u00b7log 10 (max(d i ) \u2212 min(d i ))\u221210 log 10 (MSE(D, D \u2032 )) (1)\nwhere MSE stands for mean-squared error between D and D \u2032 . Rate distortion is arguably the most important indicator because some domain scientists care about the overall statistical errors, especially for visualization purposes. (3) Checking the visual quality of the reconstructed data compared with the original raw data, by aligning the compression ratios to the same level for different compressors. This method is also widely used by existing error-bounded lossy compression developers [10,12,21,25,27,33,37] and HPC application users [16,20,30,44].\n\nWe use all three assessment metrics for comparing our solution with other state-of-the-art lossy compressors such as SZ [12,37] and ZFP [25]. We will also evaluate the I/O performance of these compressors on a supercomputer.\n\n\nDESIGN OVERVIEW\n\nWe adopt the SZ compression model because it exhibits the best compression quality (rate distortion) from among the different compressors in literature and as confirmed by our experiments. SZ adopts four stages in the compression: data prediction, linear-scale quantization, Huffman encoding, and dictionary encoding (such as Zstd [48]). Here we focus mainly on how to improve the data prediction accuracy with as little overhead as possible and how to determine the best parameter settings for the overall compression. Our work involves only the prediction and quantization steps because the other steps involve lossless compression that already has optimized settings.\n\n\nBlock-wise Prediction Engine\n\nSampling engine\n\n\nOffline\n\nOpt.\n\n\nOnline\n\nOpt.\n\n\nD P\n\n2nd-order Lorenzo  We present the design overview of our method in Figure 1, in which we highlight the main contributions by purple rectangles. Specifically, we develop a compression quality optimizer that includes three key engines working systematically: sampling engine, parameter optimization engine, and blockwise prediction engine.\n\n\u2022 Sampling Engine. The sampling engine is designed for significantly reducing the overall overhead of our compression quality optimization solution. At the compression runtime, our approach selects a small portion of the whole dataset by a uniform sampling method, and the subsequent steps (i.e., parameter optimization and blockwise selection) are performed on top of the sampled dataset. \u2022 Parameter Optimization Engine. The parameter optimization engine addresses two critical issues: (1) how to estimate the overall compression ratio as accurately as possible based on the sampled dataset and (2) how to select the best-fit parameters as efficiently as possible. As for the first issue, simply assembling a new dataset with the uniformly sampled data blocks and performing lossy compression on top of it would cause a large deviation of the estimation (demonstrated later). Accordingly, we develop an effective method that can estimate the compression ratios accurately for various parameter settings. As for the second issue, we design a two-stage (offline and online) optimization strategy that can find the best-fit parameter setting with a fairly low time complexity at runtime. Details are given in Section 6. \u2022 Blockwise Prediction Engine. Blockwise prediction is the most important step in our design. In addition to the traditional prediction method [12,24,37] (either 1st-order Lorenzo or 1st-order regression), we introduce two new prediction methods, 2nd-order Lorenzo and 2nd-order regression, which can improve the overall compression quality significantly. Based on the optimized parameter settings selected by the parameter optimization engine, the blockwise prediction engine checks the compression quality for each data block and selects the best choice from among the four prediction methods for each block. The 2nd-order prediction methods is detailed in Section 5, and how to select the best-fit prediction method is described in Section 6.\n\n\nSECOND-ORDER DATA PREDICTION\n\nIn addition to the original 1st-order prediction methods, we propose to use 2nd-order Lorenzo and 2nd-order regression prediction, which can significantly improve the compression quality.\n\n\nSecond-Order Lorenzo Prediction\n\nSecond-order Lorenzo prediction was proposed by other researchers conceptually in the literature. For instance, it was called two-layer prediction in [37]. However, no compressors are using this idea in practice because of its limitations (detailed later). For instance, the authors in [37] reported that they did not achieve higher prediction accuracy in their experiments with 2nd-order Lorenzo prediction. In our work, we combine 2nd-order Lorenzo prediction with other prediction methods to make it work effectively. In what follows, we review the 1st-order and 2nd-order Lorenzo predictor and then discuss the pros and cons of the two predictors and in what situations 2nd-order Lorenzo is better than 1st-order Lorenzo prediction. We illustrate the 1st-order Lorenzo and 2nd-order Lorenzo prediction in Figure 2 (using a 2D dataset as an example). As shown in the figure, the 1st-order prediction involves 3 data points per data prediction while the 2nd-order prediction requires 7 nearby data points for predicting each value along the scanning order.\ni i-1 i+1 i+2 i-2 j-2 j j-1 j+2 j+1 i i-1 i+1 i+2 i-2 j-2 j j-1 j+2 j+1 (a) 1st-order Lorenzo (b) 2nd-order Lorenzo Current data point (i,j)\nThe points used in prediction In general, the more data points used, the higher the prediction accuracy will be. For example, the average prediction accuracy on the QMCPack dataset [20] is about 0.00197 and 0.00062 when using 1st-order and 2nd-order Lorenzo predictor, respectively. On the other hand, we note that SZ needs to use the decompressed data with biased values to do the prediction instead of the original data, in order to fully respect the preset error bound during the decompression. In this sense, the more data points involved, the more the compression errors impact the prediction accuracy, causing a lower prediction accuracy. Tao et al. [37] demonstrated that 2ndorder Lorenzo prediction does not work as well as the 1st-order Lorenzo, so they adopted only the 1st-order Lorenzo in the released SZ compressor.\n\nWe note, however, that 2nd-order Lorenzo prediction may significantly improve the compression ratio, especially when the error bound is required to be relatively low. Figure 3 demonstrates the frequency distribution of quantization bins generated by the 1storder and 2nd-order Lorenzo predictors with the same compression error bound for four example datasets. In principle, the sharper the distribution is, the higher the compression ratio will be. We observe that when the relative error bound 1 is set to the order of 1E-6\u223c1E-8, the 2nd-order Lorenzo predictor turns out to be better than the 1st-order Lorenzo. The key reason is discussed as follows. SZ has to perform the data prediction using decompressed data each with certain errors, which may impact the prediction accuracy in turn. If the error bound is small enough, the impact of decompressed data to the prediction accuracy will be very small. This result is also verified by our evaluation of the percentage breakdown of different predictors used in compression (discussed in Section 7). \n\n\nSecond-Order Regression-Based Prediction\n\nIn this subsection, we describe how we design the 2nd-order regression predictor in terms of the 2nd-order polynomial multivariate regression. The basic idea is constructing a 2nd-order regression hyperplane based on the coordinates and the values of all data in a specific data block and minimizing the mean squared error by derivation. In what follows, we first discuss the generic formula and then extend it to fit the blockwise design in compression. The generic formula can be derived based on a m-dimensional dataset (n 1 \u00d7n 2 \u00d7\u00b7 \u00b7 \u00b7 \u00d7n m ). The independent variable vector of the m-dimensional dataset is denoted as x = (x 1 , x 2 , .., x m ). Its corresponding dependent variable vector is f x . We use f 2r (x) to denote the prediction value of x by 2nd-order regression:\nf 2r (x) = t(x) T \u03b2, where t(x) = (1, x 1 , x 2 , \u00b7 \u00b7 \u00b7 , x m , x 2 1 , x 1 x 2 , x 1 x 3 , \u00b7 \u00b7 \u00b7 , x 1 x m , x 2 2 , x 2 x 3 , \u00b7 \u00b7 \u00b7 , x 2 x m , \u00b7 \u00b7 \u00b7 , x m x m ),(2)\nwhere \u03b2 = (\u03b2 0 , \u03b2 1 , \u03b2 2 , ..\u03b2 m 2 ) represents the coefficient vector in which \u03b2 0 is the intercept coefficient. We denote the total number of coefficients by m 2 = m \u00d7 (m + 1)/2 + m + 1. The 2nd-order regression uses f 2r (x) to estimate the dependent variable f x . The objective is to minimize the mean squared error between f 2r (x) and f x , as shown in Equation (3).\nf ob j = arg min \u03b2 \u2200x (t(x T )\u03b2 \u2212 f (x)) 2(3)\nThis objective function is hard to solve with a closed-form solution because of the unknown dimension m. Thus, we resolve it for each specific dimension separately. For simplicity, we describe our solution using a 3D dataset case, which can be extended to other dimensions easily without loss of generality.\n\nFor a 3D dataset, (\nx 1 , x 2 , x 3 ) in Formula (2) can be replaced by coordinates (i, j, k), where 0 \u2264 i < n 1 , 0 \u2264 j < n 2 , 0 \u2264 k < n 3 .\nThen, the objective function can be simplified to\nf ob j = arg min \u03b2 n 1 \u22121 i=0 n 2 \u22121 j=0 n 3 \u22121 k=0 (\u03b2 0 +\u03b2 1 i +\u03b2 2 j +\u03b2 3 k +\u03b2 4 i 2 +\u03b2 5 ij +\u03b2 6 ik +\u03b2 7 j 2 +\u03b2 8 jk +\u03b2 9 k 2 \u2212 f i jk ) 2 .(4)\nIt can be solved by setting all partial derivatives to 0.\nn 1 \u22121 i=0 n 2 \u22121 j=0 n 3 \u22121 k =0 A\u03b2 T = V T (5) A= \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 1 i j k i 2 i j ik j 2 jk k 2 i i 2 i j ik i 3 i 2 j i 2 k i j 2 i jk ik 2 j i j j 2 jk i 2 j i j 2 i jk j 3 j 2 k jk 2 k ik jk k 2 i 2 k i jk ik 2 j 2 k jk 2 k 3 i 2 i 3 i 2 j i 2 k i 4 i 3 j i 3 k i 2 j 2 i 2 jk i 2 k 2 i j i 2 j i j 2 i jk i 3 j i 2 j 2 i 2 jk i j 3 i j 2 k i jk 2 ik i 2 k i jk ik 2 i 3 k i 2 jk i 2 k 2 i j 2 k i jk 2 ik 3 j 2 i j 2 j 3 j 2 k i 2 j 2 i j 3 i j 2 k j 4 j 3 k j 2 k 2 jk i jk j 2 k jk 2 i 2 jk i j 2 k i jk 2 j 3 k j 2 k 2 jk 3 k 2 ik 2 jk 2 k 3 i 2 k 2 i jk 2 ik 3 j 2 k 2 jk 3 k 4 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb V = (V 1 , V 2 , .., V 9 ), V t = n 1 \u22121 i =0 n 2 \u22121 j=0 n 3 \u22121 k =0 \u0434 i jk (t ) * f i jk , 0 \u2264 t \u2264 9 \u0434 i , j ,k (t ) returns t th element from list [1, i, j, k , i 2 , i j, ik , j 2 , jk , k 2 ] Denote f A n 1 ,n 2 ,n 3 = n 1 \u22121 i=0 n 2 \u22121 j=0 n 3 \u22121 k =0 A. The solution \u03b2 equals (f A i,j,k ) \u22121 V T . Since f A n 1 ,n 2 ,n 3 is fixed under given (n 1 , n 2 , n 3 )\n, its inverse matrix can be calculated beforehand. During the process of 2nd-order regression, we just need to compute V followed by a matrix-vector multiplication to get the solution \u03b2 with the optimized coefficients. Based on the optimized coefficients, the prediction value for each data point (i, j, k) can be written as Figure 4 demonstrates the frequency distribution of quantization bins generated after the 1st-order regression predictor versus the 2nd-order regression predictor with the same compression error bound for four example datasets. The 2nd-order regression exhibits sharper distribution than does the 1st-order regression, which means that the 2nd-order regression will likely obtain higher compression ratios in these cases.\nf 2r (i, j, k) = \u03b2 0 + \u03b2 1 i + \u03b2 2 j + \u03b2 3 k + \u03b2 4 i 2 + \u03b2 5 ij + \u03b2 6 ik + \u03b2 7 j 2 + \u03b2 8 jk + \u03b2 9 k 2 .(a) Hurricane(TCf48), reb=1E-3 (b) Nyx(velocityz), reb=1E-3 (c) QMCPack dataset 1, reb=1E-4 (d) Scale-LETKF(W), reb=1E-3\n\nFigure 4: Frequency Distribution of Quantization Bins between 1st-and 2nd-Order regression Prediction\n\nNext we compress the 10 coefficients (\u03b2 0 \u223c\u03b2 1 0) used to construct the hyperplane. Specifically, we compress them using the SZ compressor, because this can lead to outstanding compression ratios that other compressors such as FPZIP [27], ZFP [25], or bit-truncation methods [15] cannot achieve.\n\n\nPARAMETER OPTIMIZATION\n\nIn this section, we describe another important contribution, which can further improve the compression ratios prominently.\n\nThe key idea is to optimize the parameter settings involved in the whole compression. This is motivated by our observation that different parameter settings (such as block size, number of quantization bins) may affect the compression quality.\n\nBased on our new compression design supporting 2nd-order prediction, we summarize a total of 12 critical parameters for the whole compression. Five of them are from SZ (version 2.0), as shown in Table 1, and the other 7 parameters are based on the 2nd-order prediction we designed, as shown in Table 2.\n\nFrom among the 7 parameters related to the 2nd-order prediction, four of them are of Boolean values used to control the four prediction methods (1st-order/2nd-order + Lorenzo/regression). For example, if use_lorenzo is set to false, the Lorenzo predictor will be excluded in the whole process of blockwise prediction. The other three parameters are used to control the compression of the coefficients for the 2nd-order regression.  The 12 parameters are determined by our in-depth analysis of their impact on the compression ratios based on experiments using 5 real-world simulation datasets each with multiple time steps, involving about 100 fields and thousands of data files in total. Different settings of these parameters may lead to largely different compression ratios. We demonstrate three examples in Figure 5, Figure 6, and Figure 7. For instance, based on Figure 5(a), SZ's compression ratio is 180:1 and 100:1 on Hurricane(TCf48) with the error bound 5E-3, when its block size is set to 5 and 11, respectively. In Figure 6, none of pred_dim = 2 or pred_dim = 3 can always exhibit the best compression ratio when the error bound is between 1E-3 and 1E-4. In Figure 7, 8192 is the best setting for quan_bin to compress the Hurricane dataset with a 1E-5 error bound. However, in order to compress the same dataset with 1E-7 error bound, the best setting for quan_bin is 1024. In the following text, we describe the detailed optimization strategies, including how to improve the estimation accuracy on compression quality in terms of the uniformly sampled datasets, offline parameter optimization, and online parameter optimization.\n\n\nOptimizing Compression Quality Estimation over Sampled Dataset\n\nAccurately estimating the compression quality based on the sampled dataset is critical to selecting the best-fit parameter settings and predictors at runtime. To estimate the compression quality as accurately as possible, we design an approach that takes into account how the data will be predicted and quantized for each block. This contrasts with some existing compression quality estimation methods [28,42] that overlook the compression principle. Lu et al. [28] proposed a sampling-based estimation method based on the distribution of quantization bins, which can estimate the compression ratios of SZ to a certain extent. Since this method can support only Huffman encoding but not dictionary encoding (zstd), it cannot be applied to our estimation. Moreover, since it is designed based on SZ 1.4, which has no regression predictor, it cannot estimate the compression ratios accurately for SZ 2.0. Underwood et al. [42] designed a black-box autotuning framework to generate the parameter settings for different compressors based on some target compression ratio. In order to control the runtime overhead, their solution needs to estimate the real compression ratio for the overall dataset based on sampled datasets. It estimates the compression ratios by simply assembling a new dataset using the sampled data blocks and compressing the assembled dataset by a particular compressor such as SZ 2.0. Such a black-box estimation method, however, may easily cause biased estimation of compression ratios because it totally ignores the compression principle. Unlike the simple black-box estimation method [42], we take into account how the data will be used in the compression steps. Specifically, we ensure that the sampled block size is consistent with the block size to be used in the compression steps. Our estimation method also leverages the data points from other adjacent blocks to estimate the prediction accuracy in each compression block. Figure 8 presents the significant improvement of our compressionprinciple-based estimation method over the black-box estimation method [42]. We can clearly see that even under a small sampling rate 8%, the compression ratios can be estimated accurately, with only about 5% estimation errors in most cases. Accordingly, we set the sampling rate to 8% in our experiments.    Finding the best parameter combination for a given dataset is a multivariable optimization problem. The objective is to find the maximum compression ratio using the same compression function and original data. Gradient-based algorithms such as gradient descent are difficult to apply for this problem since it is unclear whether the compression function itself is a differentiable function; also, the derivative is hard to obtain even if this function is differentiable. Derivative-free methods such as coordinate descent and (meta)heuristic methods such as simulated annealing, genetic algorithm, and ant colony optimization could be used to find the approximate global optimization in a large search space if the derivative is unknown or nonexistent. However, those (meta)heuristic algorithms are all time-consuming (generally requiring 20+ iterations to converge a near-global optimum solution). By contrast, we need to control the number of iterations to under 20 such that the analysis overhead can be limited within 100% when the sampling rate is set to 8%. To this end, we propose an offline + online parameter optimization method.\n\n\nOffline Parameter Optimization\n\nThe offline algorithm manually searches for the best parameters by testing as many parameter combinations as possible and analyzes the data generated by this process to get the best candidates. We manually tested more than 30K combinations of parameters for each field of each dataset and analyzed all the results to get the best candidate parameters. For parameters with discrete numbers (such as pred_dim), we evaluate all the possible values. For the parameters with continuous numbers (such as block_size or the error bounds of compressing regression coefficients), we evaluate 10+ values for each parameter; those values are actually outstanding settings based on our numerous experiments with many datasets. That is, the values outside this range are unlikely to achieve a good compression quality, based on our experience.\n\nThe pseudocode of the manual parameter search algorithm is demonstrated in Algorithm 1. In the first step (lines 2-6), the goal is to optimize the parameters with priority on the 1st-/2nd-order Lorenzo predictor. Two value sets are used for regression-related parameters, decided by our prior experience. In the second step (lines 7-9), the goal is to optimize the parameters of the 1st-order regression predictor: re\u0434_coe f _intercept, and re\u0434_coe f _linear . The third step (lines 10-12) is to optimize the parameters of the 2nd-order regression predictor: 2ndre\u0434_coe f _intercept, 2ndre\u0434_coe f _linear , 2ndre\u0434_coe f _poly. The final step (lines [13][14][15] is to optimize the quan_bin since it is independent of predictors.\n\nWe analyze the data generated by a manual parameter search to get the outstanding candidates. The manual search was conducted offline; that is, it does not involve runtime overhead for compression. The manual search results are maintained separately based on data fields. For each field, we first identify the best compression ratio (denoted as best_ratio) and then collect good parameter settings whose compression ratios are larger than 95% \u00d7 best_ratio. Having gleaned relatively good parameter combinations for each field, we can choose any one parameter combination selected and use it to do compression, which can achieve at least a 95% top compression ratio. Then we collect the outstanding candidates for each individual parameter statistically based on a prior probability. Specifically, if some parameter value appears frequently (larger than 85%), we put it in the outstanding-candidate set. For instance, if the parameter block_size=5 appears in the good candidate parameter combinations for 86 fields from among 100 fields, we choose it as one of the  Table 3. By this selection method, we considerably reduce the number of parameter values to be focused on during online parameter optimization.\n\n\nOnline Parameter Optimization\n\nOur solution searches the best parameters based on the outstanding candidates generated by the offline optimization. This auto parameter search process is an online process, which means it will be executed every time when we run the compressor. The subsets generated by sampling are used to find the best parameters. After that, the original datasets will be compressed by our compressor using the best parameters. The overhead of the online parameter optimization process is around 100% based on the runtime of SZ and the overhead of second-order predictors is 20%\u223c50% based on SZ. Thus, the total runtime overhead of our solution is around 120%\u223c150% based on SZ.\n\nParameters with multiple outstanding candidates in Table 3 will be evaluated to find the best setting. There are 5 parameters that need to be evaluated and we clarify them to 3 groups: pred_dim and enable_2ndlorenzo as group 1, block_size and enable_2ndre\u0434ression as group 2, quan_bins as group 3. The evaluation is performed group by group since parameters between groups have little correlation in terms of the compression process. To find the best settings, Group 1, 2, and 3 require 4, 10, and 2 iterations respectively, according to the number of outstanding candidates of each parameter in Table 3. Thus, there are 16 iterations in total in our auto parameter search to choose the best setting regarding the first 5 parameters. The remaining 7 parameters have only one outstanding candidate each; thus, they do not need to be optimized during this step. Using a heuristic algorithm such as simulated annealing or a derivative-free algorithm such as coordinate descent is unnecessary for the auto parameter search because there are only 16 iterations in total which is already efficient.\n\nAlthough the online auto parameter search performs on top of the outstanding candidates generated by an offline parameter optimization, this solution is also efficient on new datasets, as we verify in Section 7.4.\n\n\nPERFORMANCE EVALUATION\n\nIn this section, we present the evaluation results based on the datasets produced by five real-world scientific simulations from different domains. Table 4 describes the five applications, which all require compression techniques to store big science data [16,20,30,44]. In particular, QMCPack here involves three datasets that are stored in three scales-288\u00d7115\u00d769\u00d769 (1 field), 816\u00d7115\u00d769\u00d769 (2 fields), and 6192\u00d7115\u00d769\u00d769 (1 field)-corresponding to 0.6 GB, 3.4 GB, and 13 GB, respectively. We call them QMCPack dataset 1, QMCPack dataset 2, and QMCPack dataset 3, respectively. Since our experiments involve parallel processes each with several gigabytes, the de facto total data size is up to 10+ terabytes for one application in our experiments, when the execution scale is 4,096 cores. We conducted our experiments on the Bebop supercomputer [35] at Argonne National Laboratory using up to 4,096 cores. Specifically, the experiments involve 64\u223c128 nodes, and each node is equipped with 128 GB memory and two Intel Xeon E5-2695 v4 processors (each with 16 cores). Its storage system adopts a General Parallel File System (GPFS) equipped with 2 I/O nodes, and the I/O system is a typical high-end supercomputer facility. We perform data writing/reading by a file-per-process method with POSIX I/O [45] in parallel. 1 We compare our solution with three state-of-the-art lossy compression methods: SZ2.1.8 [24], ZFP0.5.5 [25], and a hybrid model [22], which have been confirmed as the best in class [8,22,28]. The hybrid model merges the SZ2.0 and ZFP0.3.1 to get the best compression quality, while suffering from 200% time overhead [22].\n\n\nExperimental Settings\n\nIn what follows, we first present the compression quality results based on second-order prediction and parameter optimization and then present the overall compression quality in terms of the indicators defined in our problem formulation (Section 3). We also evaluate the I/O performance gain by running a series of parallel experiments on a supercomputer with up to 4,096 cores, and compare the results with those of other existing state-of-the-art compressors.\n\n\nAssessment of Second-Order Prediction\n\nIn Figure 9, we present the rate distortion improvement obtained with the second-order prediction (shown as blue curves in the figure) over the original design in SZ 2.0 (called Base(SZ) and shown as black curves in the figure) that uses the 1st-order prediction. As mentioned in Section 3, the higher the PSNR, the better the compression quality; and the lower the bit rate, the higher the compression ratio. We can clearly see that using 2nd-order prediction (see Section 5) can significantly improve the compression quality over the original SZ with 1st-order prediction in many cases, especially with relatively high bit rates or relatively high precision. For instance, the compression ratios can be improved by about 50% when the PSNR is greater than 120 dB for the Miranda and QMCPack simulation. The main reason is the high-order nature of the datasets. However, we can also see that at some bit rates, the original SZ with 1st-order prediction outperforms the one with 2nd-order prediction. As shown in Figure 9, for instance, 1st-order prediction is much better than 2nd-order prediction when the bit rate is in the range of [1.5,5] for the Scale-LETKF(Pres) field. This result provides motivation for adopting both 1st-and 2nd-order predictions in the compression.  \n\n\nAssessment of Parameter Optimization\n\nIn Figure 9, we also demonstrate the further compression quality improvement (see the red curves versus the blue curves) when using parameter optimization strategies on top of 2nd-order prediction. In absolute terms, the rate distortion can be improved by 4%\u223c50% in most cases, depending on the bit rates. Such a significant improvement is attributed to our design of integrating both 1st-order prediction and 2nd-order prediction (four predictors in total) and an efficient online parameter optimization strategy selecting the bestfit parameter setting at runtime in fine granularity (as per block) (for details, see Section 6.1 and Section 6). The variation in the rate distortion improvement shows that the default parameter settings of the original SZ is nearly optimal for some datasets while it is far from the optimal level for some other datasets. This confirms the significance of our parameter optimization in order to achieve the optimal results for all datasets.\n\nTo demonstrate the effect of our parameter optimization engine, in Figure 10 we illustrate the percentage breakdown of the four different prediction methods used in the compression of different applications or fields. We clearly observe an interesting distribution pattern of the four prediction methods in terms of different error bounds. Specifically, when the error bound is relatively large (such as 1E-2), the regression-based predictor would take a major role, since the Lorenzo predictor may suffer from huge prediction errors in this situation because of the impact of decompressed data (keep in mind that Lorenzo prediction has to be performed by using decompressed data during the compression stage). When the error bound is relatively small, the Lorenzo prediction would outperform the regression-based prediction. In particular, when the error bound is extremely small, our optimization engine selects the 2nd-order Lorenzo predictor in most blocks. This action is consistent with our analysis in Section 5.1: many of the application datasets actually exhibit high-order smoothness, such that the 2nd-order Lorenzo predictor is more accurate for data prediction, especially with small compression error bounds.\n\n\nOverall Compression Quality\n\nIn Figure 11 we present the overall compression quality (rate distortion) based on five real-world scientific simulation datasets, and we demonstrate the result of one example field for Hufficane ISABEL, Miranda, and Scale-LETKF, respectively. The blue curve (called optimum) refers to the ideal level obtained by our offline parameter searching (MS) for optimal parameters. As highlighted in the figures, our compression solution can improve the compression ratios over SZ (see red curve versus black curve) by 20+% for Hurricane, by \u223c40+% for Miranda, and by \u223c30+% for QMCPack, respectively, with the same PSNR. Our solution also exhibits the best compression quality from among all existing compressors on the three applications. Specifically, with the same PSNR, its overall compression ratio is higher than that of the second best compressor generally by 20\u223c25% and by 5\u223c10% and 20\u223c30% for the three applications, respectively. For some specific fields, the improvement can be up to 46%, as shown in Figure 11(b). As for the simulation Scale-LETKF and NYX, our solution still leads to the best compression quality from among all the compressors, although it has no prominent improvement over the second-best compressor, probably because the default parameter setting of the original SZ is also (or nearly) the best choice in those cases. Figure 12 presents the compression quality of the QMCPack dataset 2 and dataset 3 compared with the QMCPack dataset 1 shown in Figure 11(g). Note that our offline parameter optimization was performed not based on these two QMCPack datasets, which are largely different from the QMCPack dataset 1 in scale. Based on the figure, we clearly see that for both datasets our solution can still get much better compression quality than the others can. This means that our optimization method can also be applied effectively on new simulation datasets that were not included in our offline optimization analysis.\n\nWe also evaluate the autocorrelation metric of the compression errors (as shown in Table 5), in order to check the randomness of the compression errors. The users generally expect to see close-to-zero autocorrelation results, because this introduces less bias to their post-analysis. Table 5 shows that our solution achieves comparable autocorrelation values of compression errors compared with SZ, indicating the same randomness of compression errors.  bounds are set to 1E-6 and 1E-5 respectively. We first show that the lossy compression with these two error bounds leads to fairly high precision of the reconstructed data compared with the original raw data. We then show the parallel I/O performance when using different compressors. The reconstructed data under lossy compression with these error bounds are of fairly high precision. On the one hand, some domain scientists [3] recommend keeping the structural similarity index measure (SSIM) [46] no less than 0.99995, based on their postanalysis using existing lossy compressors. The reconstructed data in our experiments here can get an overall SSIM up to 0.99999+, so the data are supposed to be acceptable to users w.r.t. SSIM. On the other hand, to confirm that the error bounds in our evaluation lead to high precision of the reconstructed data, we demonstrate the visual quality of the reconstructed data for the two applications in Figure 13 and Figure 14. We zoom in on a small region to 625\u00d7 for each image. We present the parallel I/O performance evaluation results in Figure 15 and Figure 16. Without any compression techniques, it took 6,141 s and 4,881 s to store the original data and 7,274 s and 5,891 s to read the original data (using 4,096 processes) because of limited I/O bandwidth. The figures clearly show that the parallel I/O performance with compression techniques is always less than 1,800 seconds. In particular, our solution has the least overall elapsed times, which are 20%\u223c40% less than the times when using the second-best lossy compressor (SZ). This is due to the significantly reduced data sizes achieved by our compressor. Such a performance gain can benefit the applications significantly. On the one hand, for the applications suffering a bottleneck in I/O cost, the overall runtime can be reduced significantly. On the other hand, the storage requirement would be decreased for each application, enabling more applications to run on supercomputers.   \n\n\nCONCLUSIONS AND FUTURE WORK\n\nIn this paper, we present an efficient solution to significantly improve the compression quality for the datasets produced by parallel scientific simulations. In our solution, we develop more efficient methods (2nd-order prediction) based on both Lorenzo prediction and regression prediction. We develop an efficient algorithm that can select the best-fit predictors and optimized parameter settings at runtime. We thoroughly evaluate the compression quality and performance on a supercomputer with 5 real-world scientific simulations. The key findings are summarized below.\n\n\u2022 The 2nd-order prediction can improve the compression ratio by 50+% when the PSNS is around 120 dB for the Miranda and QMCPack simulations. \u2022 Our parameter optimization can further improve the compression by 4%\u223c50% in most cases. \u2022 When using lossy compression techniques, the overall I/O times are reduced to several hundreds of seconds from the original several hours on the supercomputer. \u2022 Our solution has the least overall elapsed I/O times, which are 20%\u223c40% less than the times when using the second-best lossy compressor. As future work, we plan to explore more effective prediction models and coding algorithms.\n\n\nACKNOWLEDGMENTS\n\nThis research was supported by the Exascale Computing Project (ECP), Project Number: 17-SC-20-SC, a collaborative effort of two DOE organizations -the Office of Science and the National Nuclear Security Administration, responsible for the planning and preparation of a capable exascale ecosystem, including software, applications, hardware, advanced system engineering and early testbed platforms, to support the nation's exascale computing imperative. The material was supported by the U.S. Department of Energy, Office of Science, under contract DE-AC02-06CH11357, and supported by the National Science Foundation under Grant No. 1619253. This work was also supported by National Science Foundation CCF 1513201. We acknowledge the computing resources provided on Bebop, which is operated by the Laboratory Computing Resource Center at Argonne National Laboratory.\n\nFigure 1 :\n1Design Overview\n\nFigure 2 :\n21st-order Lorenzo vs. 2nd-order Lorenzo\n\nFigure 3 :\n3Frequency Distribution of Quantization Bins between 1st-and 2nd-order Lorenzo Prediction\n\nFigure 5 :\n5Change of Compression Ratios with Block Sizes\n\nFigure 7 :\n7Change of Compression Ratios with Numbers of Quantization Bins (Hurricane(QCLOUDf48) and Scale(QI))\n\nFigure 8 :\n8Comparison of Estimation Accuracy (sampling rate refers to the fraction of sampled data to the full data; sampling rate = 100% refers to the full dataset)\n\nFigure 9 :\n9Breakdown Compression Quality Analysis\n\nFigure 10 :\n10Percentage Breakdown of Four Predictors Used in the Blockwise Compression\n\nFigure 12 :\n12Evaluation on Multiple QMCPack Dataset\n\nFigure 13 :Figure 14 :\n1314Visualization Visualization ofMiranda (velocityz)    \n\nFigure 15 :\n15Parallel Performance on Hurricane (a) Data dumping performance (b) Data loading performance\n\nFigure 16 :\n16Parallel Performance on Miranda\n\nTable 1 :\n1SZ ParametersType \nName \nExplanation \nInput \ndata \nOriginal data \nInput \ndim \nThe dimension of original data \nInput \nreb \nValue range based relativity error bound \nParam \nblock_size \nBlock size used by predictors \n\nParam \npred_dim \n\nThe dimension used by Lorenzo and \nregression predictors, pred_dim \u2264 dim \nParam \nquan_bins \nNumber of bins used in quantization algorithm \n\nParam reg_coef_intercept \n\nError bound for compressing the intercept \ncoefficient of regression predictor \n\nParam \nreg_coef_linear \n\nError bound for compressing the linear \ncoefficients of regression predictor \n\n\nTable 2 :\n2Extended Parameters in Our SolutionName \nExplanation \nenable_lorenzo \nEnable Lorenzo predictor or not \nenable_2ndlorenzo \nEnable 2nd-order Lorenzo predictor or not \nenable_regression \nEnable regression predictor or not \nenable_2ndregression \nEnable 2nd-order regression predictor or not \n\n2ndreg_coef_intercept \n\nError bound for compressing the intercept \ncoefficient of 2nd-order regression predictor \n\n2ndreg_coef_linear \n\nError bound for compressing the linear \ncoefficients of 2nd-order regression predictor \n\n2ndreg_coef_poly \n\nError bound for compressing the polynomial \ncoefficients of 2nd-order regression predictor \n\n\n\nTable 3 :\n3Range of ParametersName \nValue Range \nValues to be Tested \nOutstanding \nCandidates \nenable_lorenzo \n[True,False] \nTrue, False \nTrue \nenable_2ndlorenzo \n[True,False] \nTrue, False \nTrue, False \nenable_regression \n[True,False] \nTrue, False \nTrue \nenable_2ndregression \n[True,False] \nTrue, False \nTrue, False \npred_dim \n[1,2,3] \n1,2,3 \n2,3 \nblock_size \nN \n3,4,5,6,7,8,9,10,11,12,15,20,25,30 \n4,5,6,7,8 \nquan_bins \nN \ns 1 , 4096, 8192, 16384, 32768, 65536, 131072 \ns 1 , 16384 \nreg_coef_intercept \nR + \n0.01, 0.1, 0.5, 1, 2, 5, 10, 20, 50, 100 \n1 \nreg_coef_linear \nR + \n0.01, 0.1, 0.5, 1, 2, 5, b 2 , 10, 20, 50, 100 \nb 2 \n2ndreg_coef_intercept \nR + \n0.01, 0.1, 0.5, 1, 2, 5, 10, 20, 50, 100 \n0.1 \n2ndreg_coef_linear \nR + \n0.01, 0.1, 0.5, 1, 2, 5, 10, 20, 50, 100 \n0.5 \n2ndreg_coef_poly \nR + \n0.01, 0.1, 0.5, 1, 2, 5, 10, 20, 50, 100 \n2 \n\n1 s means use the estimation value provided by SZ \n2 b means use block_size as reg_coef_linear \nBold values in column 3 are used in the first step of manual parameter search. \n\n\n\n\nSession: Big Data ManagementAlgorithm 1 Manual Parameter SearchInput: raw data D, relative error bound reb Output: list of parameter settings and its compression ratio outstanding candidates. The final results are shown in the last column of1: compressMode \u2190 no_sampling \n2: for (enable_lorenzo, enable_2ndlorenzo, enable_2ndregression, pred_dim, \nblock_size) in (values from Table 3) do \n3: \nfor \n(reg_coef_intercept, \nreg_coef_linear, \n2ndreg_coef_intercept, \n2ndreg_coef_linear, 2ndreg_coef_poly) in (bold values from Table 3) \ndo \n4: \nDo compression, Record parameter settings and compression ratio \n5: \nend for \n6: end for \n7: for (enable_regression, block_size, reg_coef_intercept, reg_coef_linear) in (values \nfrom Table 3) do \n8: \nDo compression, Record parameter settings and compression ratio \n9: end for \n10: for (enable_2ndlorenzo, block_size, 2ndreg_coef_intercept, 2ndreg_coef_linear, \n2ndreg_coef_poly) in (values from Table 3) do \n11: \nDo compression, Record parameter settings and compression ratio \n12: end for \n13: for quan_bin in (Values from Table 3) do \n14: \nDo compression, Record parameter settings and compression ratio \n15: end for \n\n\n\nTable 4 :\n4Applications Used in Our ExperimentsName \nDomain \n# Fields \nSize Per Snapshot \nHurricane [18] \nWeather \n13 \n1.3 GB (= 13\u00d7 96MB) \nMiranda [29] \nHydrodynamics \n7 \n1 GB (= 7 \u00d7 144MB)) \nQMCPack [20] \nAtom/Molecules \n4 \n\u223c17 GB (=0.6 + 3.4 +13) GB \n\nScale-LETKF [44] \nWeather \n12 \n6.4 GB (=12\u00d7539MB) \nNYX [30] \nCosmology \n6 \n3.1 GB (=6\u00d7512MB) \n\n\n\nTable 5 :\n5Lag One Autocorrelation of Compression ErrorIn this subsection, we present the parallel I/O evaluation results based on two scientific simulations (Hurricane and Miranda) on the Bebop supercomputer[35]. The value-range-based relative errorDataset \nError Bound (reb) \n\nAutocorrelation (lag=1) \nSZ \nZFP \nOur Solution \n\nHurricane (Uf48) \n\n1E-3 \n0.040711 0.151458 \n0.053633 \n1E-5 \n0.001358 0.115680 \n0.001687 \n\nMiranda (velocityz) \n\n1E-3 \n0.211425 0.343711 \n0.216588 \n1E-5 \n0.071940 0.266735 \n0.059465 \n\nQMCPack (dataset 1) \n\n1E-3 \n0.211425 0.374731 \n0.241557 \n1E-5 \n0.022431 0.217974 \n0.028725 \n\n7.5 I/O Performance Evaluation \n\n\nRelative error bound here refers to value-range-based error bound, which is defined as the ratio of absolute error bound to the data value range.\nAnother researcher[41] verified that POSIX I/O has comparable performance with parallel I/O, such as MPI-IO[40] when reading/writing thousands of files simultaneously on GPFS. We also further verified that the read/write performance difference of POSIX IO and MPI-IO is within \u00b110% on this supercomputer, when the execution scales between 2k cores and 8k cores.\n\nMultilevel techniques for compression and reduction of scientific data-the univariate case. Mark Ainsworth, Ozan Tugluk, Ben Whitney, Scott Klasky, Computing and Visualization in Science. 19Mark Ainsworth, Ozan Tugluk, Ben Whitney, and Scott Klasky. 2018. Multilevel techniques for compression and reduction of scientific data-the univariate case. Computing and Visualization in Science 19, 5-6 (2018), 65-76.\n\nBlosc, an extremely fast, multi-threaded, meta-compressor library. Francesc Alted. 2017. Blosc, an extremely fast, multi-threaded, meta-compressor library.\n\nEvaluating lossy data compression on climate simulation data within a large ensemble. H Allison, Dorit M Baker, Sheri A Hammerling, Haiying Mickelson, Xu, B Martin, Phillippe Stolpe, Ben Naveau, Imme Sanderson, Savini Ebert-Uphoff, Francesco De Samarasinghe, Simone, 10.5194/gmd-9-4381-2016Geoscientific Model Development. 9Allison H Baker, Dorit M Hammerling, Sheri A Mickelson, Haiying Xu, Martin B Stolpe, Phillippe Naveau, Ben Sanderson, Imme Ebert-Uphoff, Savini Samaras- inghe, Francesco De Simone, et al. 2016. Evaluating lossy data compression on climate simulation data within a large ensemble. Geoscientific Model Development 9, 12 (2016), 4381-4403. https://doi.org/10.5194/gmd-9-4381-2016\n\nToward a Multi-method Approach: Lossy Data Compression for Climate Simulation Data. Allison H Baker, Haiying Xu, Dorit M Hammerling, Shaomeng Li, John P Clyne, High Performance Computing. ChamSpringer International PublishingAllison H. Baker, Haiying Xu, Dorit M. Hammerling, Shaomeng Li, and John P. Clyne. 2017. Toward a Multi-method Approach: Lossy Data Compression for Climate Simulation Data. In High Performance Computing. Springer International Publishing, Cham, 30-42.\n\nFPC: A high-speed compressor for double-precision floating-point data. Martin Burtscher, Paruj Ratanaworabhan, IEEE Trans. Comput. 581Martin Burtscher and Paruj Ratanaworabhan. 2009. FPC: A high-speed compres- sor for double-precision floating-point data. IEEE Trans. Comput. 58, 1 (Jan 2009), 18-31.\n\nUse cases of lossy compression for floating-point data in scientific data sets. Franck Cappello, Sheng Di, Sihuan Li, Xin Liang, Ali Murat Gok, Dingwen Tao, Chun Hong Yoon, Xin-Chuan Wu, Yuri Alexeev, Frederic T Chong, The International Journal of High Performance Computing Applications. 33Franck Cappello, Sheng Di, Sihuan Li, Xin Liang, Ali Murat Gok, Dingwen Tao, Chun Hong Yoon, Xin-Chuan Wu, Yuri Alexeev, and Frederic T Chong. 2019. Use cases of lossy compression for floating-point data in scientific data sets. The International Journal of High Performance Computing Applications 33, 6 (2019), 1201-1220.\n\nNUMARCK: machine learning algorithm for resiliency and checkpointing. Zhengzhang Chen, Seung Woo Son, William Hendrix, Ankit Agrawal, Wei-Keng Liao, Alok Choudhary, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. the International Conference for High Performance Computing, Networking, Storage and AnalysisNew York, NY, USAIEEEZhengzhang Chen, Seung Woo Son, William Hendrix, Ankit Agrawal, Wei-keng Liao, and Alok Choudhary. 2014. NUMARCK: machine learning algorithm for resiliency and checkpointing. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE Press, IEEE, New York, NY, USA, 733-744.\n\nCoupling exascale multiphysics applications: Methods and lessons learned. Jong Youl Choi, Proceedings of IEEE International Conference on eScience. IEEE International Conference on eScienceNew York, NY, USAIEEEJong Youl Choi and et al. 2018. Coupling exascale multiphysics applications: Methods and lessons learned. In Proceedings of IEEE International Conference on eScience. IEEE, IEEE, New York, NY, USA, 442-452.\n\nSPDP: An Automatically Synthesized Lossless Compression Algorithm for Floating-Point Data. S Claggett, S Azimi, M Burtscher, 10.1109/DCC.2018.00042Data Compression Conference. New York, NY, USAIEEES. Claggett, S. Azimi, and M. Burtscher. 2018. SPDP: An Automatically Syn- thesized Lossless Compression Algorithm for Floating-Point Data. In 2018 Data Compression Conference. IEEE, New York, NY, USA, 335-344. https://doi.org/10. 1109/DCC.2018.00042\n\nInteractive desktop analysis of high resolution simulations: application to turbulent plume dynamics and current sheet formation. John Clyne, Pablo Mininni, Alan Norton, Mark Rast, New Journal of Physics. 9John Clyne, Pablo Mininni, Alan Norton, and Mark Rast. 2007. Interactive desktop analysis of high resolution simulations: application to turbulent plume dynamics and current sheet formation. New Journal of Physics 9, 301 (2007), 1-29.\n\n. Peter Deutsch, GZIP file format specification version 4.3L Peter Deutsch. 1996. GZIP file format specification version 4.3.\n\nFast error-bounded lossy HPC data compression with SZ. Sheng Di, Franck Cappello, 2016 IEEE International Parallel and Distributed Processing Symposium. New York, NY, USAIEEESheng Di and Franck Cappello. 2016. Fast error-bounded lossy HPC data com- pression with SZ. In 2016 IEEE International Parallel and Distributed Processing Symposium. IEEE, New York, NY, USA, 730-739.\n\nComputing just what you need: Online data analysis and reduction at extreme scales. Ian T Foster, European Conference on Parallel Processing. ChamSpringer International PublishingIan T. Foster et al. 2017. Computing just what you need: Online data analysis and reduction at extreme scales. In European Conference on Parallel Processing. Springer, Springer International Publishing, Cham, 3-19.\n\nPaSTRI: A novel data compression algorithm for two-electron integrals in quantum chemistry. Ali Murat Gok, Sheng Di, Alexeev Yuri, Dingwen Tao, Vladimir Mironov, IEEE International Conference on Cluster Computing (CLUSTER). New York, NY, USAIEEEXin Liang, and Franck CappelloAli Murat Gok, Sheng Di, Alexeev Yuri, Dingwen Tao, Vladimir Mironov, Xin Liang, and Franck Cappello. 2018. PaSTRI: A novel data compression algorithm for two-electron integrals in quantum chemistry. In IEEE International Conference on Cluster Computing (CLUSTER). IEEE, New York, NY, USA, 1-11.\n\nImproving floating point compression through binary masks. L A B Gomez, F Cappello, 2013 IEEE International Conference on Big Data. New York, NY, USAIEEEL. A. B. Gomez and F. Cappello. 2013. Improving floating point compression through binary masks. In 2013 IEEE International Conference on Big Data. IEEE, New York, NY, USA, 326-331.\n\nHACC: extreme scaling and performance across diverse architectures. Salman Habib, A Vitali, Nicholas Morozov, Hal Frontiere, Adrian Finkel, Katrin Pope, Kalyan Heitmann, Venkatram Kumaran, Tom Vishwanath, Joseph A Peterka, David Insley, Patricia K Daniel, Zarija Fasel, Lukic, Commun. ACM. 60Salman Habib, Vitali A. Morozov, Nicholas Frontiere, Hal Finkel, Adrian Pope, Ka- trin Heitmann, Kalyan Kumaran, Venkatram Vishwanath, Tom Peterka, Joseph A. Insley, David Daniel, Patricia K. Fasel, and Zarija Lukic. 2016. HACC: extreme scaling and performance across diverse architectures. Commun. ACM 60, 1 (2016), 97-104.\n\nA method for the construction of minimum-redundancy codes. A David, Huffman, Proceedings of the IRE. 40David A Huffman. 1952. A method for the construction of minimum-redundancy codes. Proceedings of the IRE 40, 9 (1952), 1098-1101.\n\nHurricane ISABEL simulation data. Hurricane ISABEL simulation data. 2019. http://vis.computer.org/vis2004contest/ data.html. Online.\n\nUnderstanding GPU-Based Lossy Compression for Extreme-Scale Cosmological Simulations. Sian Jin, Pascal Grosset, M Christopher, Jesus Biwer, Jiannan Pulido, Dingwen Tian, James Tao, Ahrens, Sian Jin, Pascal Grosset, Christopher M Biwer, Jesus Pulido, Jiannan Tian, Ding- wen Tao, and James Ahrens. 2020. Understanding GPU-Based Lossy Compression for Extreme-Scale Cosmological Simulations. https://arxiv.org/abs/2001.06139. Online.\n\nQMCPACK: an open source ab initio quantum Monte Carlo package for the electronic structure of atoms, molecules and solids. Jeongnim Kim, Journal of Physics: Condensed Matter. 30195901Jeongnim Kim and et al. 2018. QMCPACK: an open source ab initio quantum Monte Carlo package for the electronic structure of atoms, molecules and solids. Journal of Physics: Condensed Matter 30, 19 (2018), 195901.\n\nIsabela for effective in situ compression of scientific data. Sriram Lakshminarasimhan, Neil Shah, Stephane Ethier, Seung-Hoe Ku, Choong-Seock Chang, Scott Klasky, Rob Latham, Rob Ross, Nagiza F Samatova, Concurrency and Computation: Practice and Experience. 25Sriram Lakshminarasimhan, Neil Shah, Stephane Ethier, Seung-Hoe Ku, Choong- Seock Chang, Scott Klasky, Rob Latham, Rob Ross, and Nagiza F Samatova. 2013. Isabela for effective in situ compression of scientific data. Concurrency and Computation: Practice and Experience 25, 4 (2013), 524-540.\n\nSignificantly improving lossy compression quality based on an optimized hybrid prediction model. Xin Liang, Sheng Di, Sihuan Li, Dingwen Tao, Bogdan Nicolae, Zizhong Chen, Franck Cappello, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. the International Conference for High Performance Computing, Networking, Storage and AnalysisXin Liang, Sheng Di, Sihuan Li, Dingwen Tao, Bogdan Nicolae, Zizhong Chen, and Franck Cappello. 2019. Significantly improving lossy compression quality based on an optimized hybrid prediction model. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. 1-26.\n\nAn Efficient Transformation Scheme for Lossy Data Compression with Point-wise Relative Error Bound. Xin Liang, Sheng Di, Dingwen Tao, Zizhong Chen, Franck Cappello, IEEE International Conference on Cluster Computing (CLUSTER). New York, NY, USAIEEEXin Liang, Sheng Di, Dingwen Tao, Zizhong Chen, and Franck Cappello. 2018. An Efficient Transformation Scheme for Lossy Data Compression with Point-wise Relative Error Bound. In IEEE International Conference on Cluster Computing (CLUSTER). IEEE, New York, NY, USA, 179-189.\n\nError-controlled lossy compression optimized for high compression ratios of scientific datasets. Xin Liang, Sheng Di, Dingwen Tao, Sihuan Li, Shaomeng Li, Hanqi Guo, Zizhong Chen, Franck Cappello, 2018 IEEE International Conference on Big Data. New York, NY, USAIEEEXin Liang, Sheng Di, Dingwen Tao, Sihuan Li, Shaomeng Li, Hanqi Guo, Zizhong Chen, and Franck Cappello. 2018. Error-controlled lossy compression optimized for high compression ratios of scientific datasets. In 2018 IEEE International Conference on Big Data. IEEE, IEEE, New York, NY, USA.\n\nFixed-rate compressed floating-point arrays. Peter Lindstrom, IEEE Transactions on Visualization and Computer Graphics. 20Peter Lindstrom. 2014. Fixed-rate compressed floating-point arrays. IEEE Trans- actions on Visualization and Computer Graphics 20, 12 (2014), 2674-2683.\n\nError Distributions of Lossy Floating-Point Compressors. Peter Lindstrom, Joint Statistical Meetings. 1Peter Lindstrom. 2017. Error Distributions of Lossy Floating-Point Compressors. Joint Statistical Meetings 1, 1 (2017), 2574-2589.\n\nFast and efficient compression of floating-point data. Peter Lindstrom, Martin Isenburg, IEEE Transactions on Visualization and Computer Graphics. 125Peter Lindstrom and Martin Isenburg. 2006. Fast and efficient compression of floating-point data. IEEE Transactions on Visualization and Computer Graphics 12, 5 (2006), 1245-1250.\n\nUnderstanding and modeling lossy compression schemes on HPC scientific data. Tao Lu, Qing Liu, Xubin He, Huizhang Luo, Eric Suchyta, Jong Choi, Norbert Podhorszki, Scott Klasky, Mathew Wolf, Tong Liu, IEEE International Parallel and Distributed Processing Symposium. IEEETao Lu, Qing Liu, Xubin He, Huizhang Luo, Eric Suchyta, Jong Choi, Norbert Podhorszki, Scott Klasky, Mathew Wolf, Tong Liu, et al. 2018. Understanding and modeling lossy compression schemes on HPC scientific data. In 2018 IEEE International Parallel and Distributed Processing Symposium. IEEE, 348-357.\n\n. Miranda, Miranda. 2019. https://wci.llnl.gov/simulation/computer-codes/miranda/papers. Online.\n\nNYX simulation. NYX simulation. 2019. https://amrex-astro.github.io/Nyx. Online.\n\n. Exaalt, EXAALT project. 2019. https://www.exascaleproject.org/project/ exaalt-molecular-dynamics-at-the-exascale-materials-science/. Online.\n\nFast lossless compression of scientific floating-point data. Paruj Ratanaworabhan, Jian Ke, Martin Burtscher, Data Compression Conference (DCC'06). Paruj Ratanaworabhan, Jian Ke, and Martin Burtscher. 2006. Fast lossless compres- sion of scientific floating-point data. In Data Compression Conference (DCC'06).\n\n. Ieee Ieee, New York, NY, USAIEEE, IEEE, New York, NY, USA, 133-142.\n\nExploration of lossy compression for application-level checkpoint/restart. Naoto Sasaki, Kento Sato, Toshio Endo, Satoshi Matsuoka, 2015 IEEE International Parallel and Distributed Processing Symposium (IPDPS). New York, NY, USAIEEENaoto Sasaki, Kento Sato, Toshio Endo, and Satoshi Matsuoka. 2015. Exploration of lossy compression for application-level checkpoint/restart. In 2015 IEEE Inter- national Parallel and Distributed Processing Symposium (IPDPS). IEEE, New York, NY, USA, 914-922.\n\nData compression for the exascale computing era-survey. Zhengzhang Seung Woo Son, William Chen, Ankit Hendrix, Wei-Keng Agrawal, Alok Liao, Choudhary, Supercomputing Frontiers and Innovations. 1Seung Woo Son, Zhengzhang Chen, William Hendrix, Ankit Agrawal, Wei-keng Liao, and Alok Choudhary. 2014. Data compression for the exascale computing era-survey. Supercomputing Frontiers and Innovations 1, 2 (2014), 76-88.\n\n. Bebop Supercomputer, Bebop supercomputer. 2019. Available at https://www.lcrc.anl.gov/systems/ resources/bebop. Online.\n\n. Ornl Summit, Supercomputer, ORNL Summit supercomputer. 2019. https://www.olcf.ornl.gov/summit/. Online.\n\nSignificantly improving lossy compression for scientific data sets based on multidimensional prediction and error-controlled quantization. Dingwen Tao, Sheng Di, Zizhong Chen, Franck Cappello, 2017 IEEE International Parallel and Distributed Processing Symposium. New York, NY, USAIEEEDingwen Tao, Sheng Di, Zizhong Chen, and Franck Cappello. 2017. Significantly improving lossy compression for scientific data sets based on multidimensional prediction and error-controlled quantization. In 2017 IEEE International Parallel and Distributed Processing Symposium. IEEE, New York, NY, USA, 1129-1139.\n\nOptimizing Lossy Compression Rate-Distortion from Automatic Online Selection between SZ and ZFP. Dingwen Tao, Sheng Di, Xin Liang, Zizhong Chen, Franck Cappello, IEEE Trans. Parallel Distrib. Syst. 30Dingwen Tao, Sheng Di, Xin Liang, Zizhong Chen, and Franck Cappello. 2019. Optimizing Lossy Compression Rate-Distortion from Automatic Online Selection between SZ and ZFP. IEEE Trans. Parallel Distrib. Syst. 30, 8 (2019), 1857-1871.\n\nJPEG2000 Image Compression Fundamentals, Standards and Practice. David Taubman, Michael Marcellin, Springer Publishing CompanyNew York, NY, USAIncorporatedDavid Taubman and Michael Marcellin. 2013. JPEG2000 Image Compression Fun- damentals, Standards and Practice. Springer Publishing Company, Incorporated, New York, NY, USA.\n\nOn Implementing MPI-IO portably and with high performance. Rajeev Thakur, William Gropp, Ewing Lusk, Proceedings of the Sixth Workshop on I/O in Parallel and Distributed Systems (IOPADS '99). the Sixth Workshop on I/O in Parallel and Distributed Systems (IOPADS '99)New York, NY, USAACMRajeev Thakur, William Gropp, and Ewing Lusk. 1999. On Implementing MPI-IO portably and with high performance. In Proceedings of the Sixth Workshop on I/O in Parallel and Distributed Systems (IOPADS '99). ACM, New York, NY, USA, 23-32.\n\nParallel I/O Performance. Andy Turner, Andy Turner. 2019. Parallel I/O Performance. https://www.archer.ac.uk/training/ virtual/2017-02-08-Parallel-IO/2017_02_ParallelIO_ARCHERWebinar.pdf. On- line.\n\nFRaZ: A Generic High-Fidelity Fixed-Ratio Lossy Compression Framework for Scientific Floating-point Data. Robert Underwood, Sheng Di, Jon C Calhoun, Franck Cappello, Robert Underwood, Sheng Di, Jon C. Calhoun, and Franck Cappello. 2020. FRaZ: A Generic High-Fidelity Fixed-Ratio Lossy Compression Framework for Scientific Floating-point Data. https://arxiv.org/abs/2001.06139. Online.\n\nThe JPEG still picture compression standard. K Gregory, Wallace, IEEE Transactions on Consumer Electronics. 38Gregory K Wallace. 1992. The JPEG still picture compression standard. IEEE Transactions on Consumer Electronics 38, 1 (1992), xviii-xxxiv.\n\n. Scale-Letkf, SCALE-LETKF weather model. 2019. https://github.com/gylien/scale-letkf. On- line.\n\nPOSIX IO extensions for HPC. Brent Welch, 4th USENIX Conference on File and Storage Technologies (FAST05). USENIX Association. USA, 1Brent Welch. 2005. POSIX IO extensions for HPC. In 4th USENIX Conference on File and Storage Technologies (FAST05). USENIX Association, USA, 1.\n\nImage quality assessment: from error visibility to structural similarity. A C Zhou Wang, H R Bovik, E P Sheikh, Simoncelli, IEEE Transactions on Image Processing. 134Zhou Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli. 2004. Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image Processing 13, 4 (April 2004), 600-612.\n\nA universal algorithm for sequential data compression. Jacob Ziv, Abraham Lempel, IEEE Transactions on information theory. 23Jacob Ziv and Abraham Lempel. 1977. A universal algorithm for sequential data compression. IEEE Transactions on information theory 23, 3 (1977), 337-343.\n", "annotations": {"author": "[{\"end\":159,\"start\":150},{\"end\":169,\"start\":160},{\"end\":180,\"start\":170},{\"end\":191,\"start\":181},{\"end\":224,\"start\":192},{\"end\":254,\"start\":225},{\"end\":292,\"start\":255},{\"end\":302,\"start\":293},{\"end\":312,\"start\":303},{\"end\":323,\"start\":313},{\"end\":334,\"start\":324},{\"end\":347,\"start\":335},{\"end\":361,\"start\":348},{\"end\":449,\"start\":362},{\"end\":498,\"start\":450},{\"end\":547,\"start\":499},{\"end\":587,\"start\":548},{\"end\":692,\"start\":588}]", "publisher": "[{\"end\":119,\"start\":116},{\"end\":1060,\"start\":1057}]", "author_last_name": "[{\"end\":158,\"start\":154},{\"end\":168,\"start\":166},{\"end\":179,\"start\":174},{\"end\":190,\"start\":188},{\"end\":203,\"start\":200},{\"end\":237,\"start\":233},{\"end\":270,\"start\":262},{\"end\":301,\"start\":297},{\"end\":311,\"start\":309},{\"end\":322,\"start\":317},{\"end\":333,\"start\":331},{\"end\":346,\"start\":343},{\"end\":360,\"start\":356}]", "author_first_name": "[{\"end\":153,\"start\":150},{\"end\":165,\"start\":160},{\"end\":173,\"start\":170},{\"end\":187,\"start\":181},{\"end\":199,\"start\":192},{\"end\":232,\"start\":225},{\"end\":261,\"start\":255},{\"end\":296,\"start\":293},{\"end\":308,\"start\":303},{\"end\":316,\"start\":313},{\"end\":330,\"start\":324},{\"end\":342,\"start\":335},{\"end\":355,\"start\":348}]", "author_affiliation": "[{\"end\":448,\"start\":363},{\"end\":497,\"start\":451},{\"end\":546,\"start\":500},{\"end\":586,\"start\":549},{\"end\":691,\"start\":589}]", "title": "[{\"end\":115,\"start\":1},{\"end\":807,\"start\":693}]", "venue": "[{\"end\":922,\"start\":809}]", "abstract": "[{\"end\":3392,\"start\":1892}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3818,\"start\":3814},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":4054,\"start\":4050},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4206,\"start\":4202},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5240,\"start\":5236},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5243,\"start\":5240},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5268,\"start\":5264},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5282,\"start\":5278},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":5285,\"start\":5282},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5313,\"start\":5309},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5610,\"start\":5606},{\"end\":5637,\"start\":5633},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5646,\"start\":5642},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5649,\"start\":5646},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5652,\"start\":5649},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5664,\"start\":5660},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5682,\"start\":5678},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5917,\"start\":5913},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5948,\"start\":5944},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5998,\"start\":5994},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6033,\"start\":6029},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6054,\"start\":6051},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6057,\"start\":6054},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6060,\"start\":6057},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6352,\"start\":6348},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6355,\"start\":6352},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8770,\"start\":8767},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8772,\"start\":8770},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8774,\"start\":8772},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8777,\"start\":8774},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8780,\"start\":8777},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":8783,\"start\":8780},{\"end\":8786,\"start\":8783},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9047,\"start\":9043},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9050,\"start\":9047},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9053,\"start\":9050},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9154,\"start\":9151},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9157,\"start\":9154},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9513,\"start\":9510},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9516,\"start\":9513},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9519,\"start\":9516},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9522,\"start\":9519},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9525,\"start\":9522},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9528,\"start\":9525},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9531,\"start\":9528},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9534,\"start\":9531},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9559,\"start\":9555},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9562,\"start\":9559},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9565,\"start\":9562},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9568,\"start\":9565},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":9571,\"start\":9568},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9580,\"start\":9576},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9583,\"start\":9580},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9586,\"start\":9583},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9600,\"start\":9596},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9612,\"start\":9608},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9629,\"start\":9626},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9687,\"start\":9683},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9928,\"start\":9924},{\"end\":9941,\"start\":9937},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9953,\"start\":9949},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9966,\"start\":9962},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10187,\"start\":10183},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10190,\"start\":10187},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10782,\"start\":10778},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11147,\"start\":11143},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11334,\"start\":11330},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11499,\"start\":11495},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11746,\"start\":11742},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11765,\"start\":11761},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12555,\"start\":12551},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":12558,\"start\":12555},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":12561,\"start\":12558},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":12763,\"start\":12760},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12812,\"start\":12809},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":14522,\"start\":14518},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14525,\"start\":14522},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14528,\"start\":14525},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14531,\"start\":14528},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":14534,\"start\":14531},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14537,\"start\":14534},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":14540,\"start\":14537},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14571,\"start\":14567},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14574,\"start\":14571},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14577,\"start\":14574},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":14580,\"start\":14577},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14707,\"start\":14703},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":14710,\"start\":14707},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14723,\"start\":14719},{\"end\":15162,\"start\":15158},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17289,\"start\":17285},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":17292,\"start\":17289},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":17295,\"start\":17292},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18297,\"start\":18293},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18433,\"start\":18429},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":19528,\"start\":19524},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":20003,\"start\":19999},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":25681,\"start\":25677},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":25691,\"start\":25687},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":25723,\"start\":25719},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28551,\"start\":28547},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":28554,\"start\":28551},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28610,\"start\":28606},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":29069,\"start\":29065},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":29754,\"start\":29750},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":30234,\"start\":30230},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":33125,\"start\":33121},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":33129,\"start\":33125},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33133,\"start\":33129},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":36704,\"start\":36700},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":36707,\"start\":36704},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":36710,\"start\":36707},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":36713,\"start\":36710},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":37296,\"start\":37292},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":37749,\"start\":37745},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":37764,\"start\":37763},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":37856,\"start\":37852},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":37871,\"start\":37867},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":37896,\"start\":37892},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":37948,\"start\":37945},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":37951,\"start\":37948},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":37954,\"start\":37951},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":38084,\"start\":38080},{\"end\":39756,\"start\":39749},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":44994,\"start\":44991},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":45064,\"start\":45060},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":53617,\"start\":53613},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":54211,\"start\":54207},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":54300,\"start\":54296}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":48702,\"start\":48674},{\"attributes\":{\"id\":\"fig_1\"},\"end\":48755,\"start\":48703},{\"attributes\":{\"id\":\"fig_2\"},\"end\":48857,\"start\":48756},{\"attributes\":{\"id\":\"fig_3\"},\"end\":48916,\"start\":48858},{\"attributes\":{\"id\":\"fig_4\"},\"end\":49029,\"start\":48917},{\"attributes\":{\"id\":\"fig_6\"},\"end\":49197,\"start\":49030},{\"attributes\":{\"id\":\"fig_8\"},\"end\":49249,\"start\":49198},{\"attributes\":{\"id\":\"fig_9\"},\"end\":49338,\"start\":49250},{\"attributes\":{\"id\":\"fig_10\"},\"end\":49392,\"start\":49339},{\"attributes\":{\"id\":\"fig_11\"},\"end\":49474,\"start\":49393},{\"attributes\":{\"id\":\"fig_13\"},\"end\":49581,\"start\":49475},{\"attributes\":{\"id\":\"fig_14\"},\"end\":49628,\"start\":49582},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":50225,\"start\":49629},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":50864,\"start\":50226},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":51888,\"start\":50865},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":53051,\"start\":51889},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":53403,\"start\":53052},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":54042,\"start\":53404}]", "paragraph": "[{\"end\":4407,\"start\":3408},{\"end\":5314,\"start\":4409},{\"end\":6243,\"start\":5316},{\"end\":6971,\"start\":6245},{\"end\":7267,\"start\":6973},{\"end\":8084,\"start\":7269},{\"end\":8220,\"start\":8086},{\"end\":8594,\"start\":8222},{\"end\":9158,\"start\":8611},{\"end\":10604,\"start\":9160},{\"end\":10991,\"start\":10606},{\"end\":12387,\"start\":10993},{\"end\":12813,\"start\":12411},{\"end\":13174,\"start\":12815},{\"end\":13299,\"start\":13176},{\"end\":13954,\"start\":13301},{\"end\":14581,\"start\":14026},{\"end\":14807,\"start\":14583},{\"end\":15497,\"start\":14827},{\"end\":15545,\"start\":15530},{\"end\":15561,\"start\":15557},{\"end\":15576,\"start\":15572},{\"end\":15921,\"start\":15584},{\"end\":17887,\"start\":15923},{\"end\":18107,\"start\":17920},{\"end\":19201,\"start\":18143},{\"end\":20171,\"start\":19343},{\"end\":21226,\"start\":20173},{\"end\":22051,\"start\":21271},{\"end\":22595,\"start\":22220},{\"end\":22949,\"start\":22642},{\"end\":22970,\"start\":22951},{\"end\":23143,\"start\":23094},{\"end\":23348,\"start\":23291},{\"end\":25115,\"start\":24369},{\"end\":25739,\"start\":25444},{\"end\":25888,\"start\":25766},{\"end\":26132,\"start\":25890},{\"end\":26436,\"start\":26134},{\"end\":28078,\"start\":26438},{\"end\":31606,\"start\":28145},{\"end\":32470,\"start\":31641},{\"end\":33200,\"start\":32472},{\"end\":34410,\"start\":33202},{\"end\":35108,\"start\":34444},{\"end\":36202,\"start\":35110},{\"end\":36417,\"start\":36204},{\"end\":38085,\"start\":36444},{\"end\":38572,\"start\":38111},{\"end\":39891,\"start\":38614},{\"end\":40906,\"start\":39932},{\"end\":42130,\"start\":40908},{\"end\":44109,\"start\":42162},{\"end\":46558,\"start\":44111},{\"end\":47164,\"start\":46590},{\"end\":47788,\"start\":47166},{\"end\":48673,\"start\":47808}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14025,\"start\":13955},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19342,\"start\":19202},{\"attributes\":{\"id\":\"formula_2\"},\"end\":22219,\"start\":22052},{\"attributes\":{\"id\":\"formula_3\"},\"end\":22641,\"start\":22596},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23093,\"start\":22971},{\"attributes\":{\"id\":\"formula_5\"},\"end\":23290,\"start\":23144},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24368,\"start\":23349},{\"attributes\":{\"id\":\"formula_7\"},\"end\":25219,\"start\":25116},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25339,\"start\":25219}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26336,\"start\":26329},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26435,\"start\":26428},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":34274,\"start\":34267},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":35168,\"start\":35161},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":35713,\"start\":35706},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":36599,\"start\":36592},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":44201,\"start\":44194},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":44402,\"start\":44395}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3406,\"start\":3394},{\"attributes\":{\"n\":\"2\"},\"end\":8609,\"start\":8597},{\"attributes\":{\"n\":\"3\"},\"end\":12409,\"start\":12390},{\"attributes\":{\"n\":\"4\"},\"end\":14825,\"start\":14810},{\"end\":15528,\"start\":15500},{\"end\":15555,\"start\":15548},{\"end\":15570,\"start\":15564},{\"end\":15582,\"start\":15579},{\"attributes\":{\"n\":\"5\"},\"end\":17918,\"start\":17890},{\"attributes\":{\"n\":\"5.1\"},\"end\":18141,\"start\":18110},{\"attributes\":{\"n\":\"5.2\"},\"end\":21269,\"start\":21229},{\"end\":25442,\"start\":25341},{\"attributes\":{\"n\":\"6\"},\"end\":25764,\"start\":25742},{\"attributes\":{\"n\":\"6.1\"},\"end\":28143,\"start\":28081},{\"attributes\":{\"n\":\"6.2\"},\"end\":31639,\"start\":31609},{\"attributes\":{\"n\":\"6.3\"},\"end\":34442,\"start\":34413},{\"attributes\":{\"n\":\"7\"},\"end\":36442,\"start\":36420},{\"attributes\":{\"n\":\"7.1\"},\"end\":38109,\"start\":38088},{\"attributes\":{\"n\":\"7.2\"},\"end\":38612,\"start\":38575},{\"attributes\":{\"n\":\"7.3\"},\"end\":39930,\"start\":39894},{\"attributes\":{\"n\":\"7.4\"},\"end\":42160,\"start\":42133},{\"attributes\":{\"n\":\"8\"},\"end\":46588,\"start\":46561},{\"attributes\":{\"n\":\"9\"},\"end\":47806,\"start\":47791},{\"end\":48685,\"start\":48675},{\"end\":48714,\"start\":48704},{\"end\":48767,\"start\":48757},{\"end\":48869,\"start\":48859},{\"end\":48928,\"start\":48918},{\"end\":49041,\"start\":49031},{\"end\":49209,\"start\":49199},{\"end\":49262,\"start\":49251},{\"end\":49351,\"start\":49340},{\"end\":49416,\"start\":49394},{\"end\":49487,\"start\":49476},{\"end\":49594,\"start\":49583},{\"end\":49639,\"start\":49630},{\"end\":50236,\"start\":50227},{\"end\":50875,\"start\":50866},{\"end\":53062,\"start\":53053},{\"end\":53414,\"start\":53405}]", "table": "[{\"end\":50225,\"start\":49654},{\"end\":50864,\"start\":50273},{\"end\":51888,\"start\":50896},{\"end\":53051,\"start\":52132},{\"end\":53403,\"start\":53100},{\"end\":54042,\"start\":53655}]", "figure_caption": "[{\"end\":48702,\"start\":48687},{\"end\":48755,\"start\":48716},{\"end\":48857,\"start\":48769},{\"end\":48916,\"start\":48871},{\"end\":49029,\"start\":48930},{\"end\":49197,\"start\":49043},{\"end\":49249,\"start\":49211},{\"end\":49338,\"start\":49265},{\"end\":49392,\"start\":49354},{\"end\":49474,\"start\":49421},{\"end\":49581,\"start\":49490},{\"end\":49628,\"start\":49597},{\"end\":49654,\"start\":49641},{\"end\":50273,\"start\":50238},{\"end\":50896,\"start\":50877},{\"end\":52132,\"start\":51891},{\"end\":53100,\"start\":53064},{\"end\":53655,\"start\":53416}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15659,\"start\":15651},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18960,\"start\":18952},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20348,\"start\":20340},{\"end\":24702,\"start\":24694},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27256,\"start\":27248},{\"end\":27266,\"start\":27258},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27280,\"start\":27272},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27313,\"start\":27305},{\"end\":27472,\"start\":27464},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27615,\"start\":27607},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":30103,\"start\":30095},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":38625,\"start\":38617},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":39634,\"start\":39626},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":39943,\"start\":39935},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":40984,\"start\":40975},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":42174,\"start\":42165},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":43176,\"start\":43167},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":43514,\"start\":43505},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":43641,\"start\":43632},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45517,\"start\":45508},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45531,\"start\":45522},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45657,\"start\":45648},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45671,\"start\":45662}]", "bib_author_first_name": "[{\"end\":54648,\"start\":54644},{\"end\":54664,\"start\":54660},{\"end\":54676,\"start\":54673},{\"end\":54691,\"start\":54686},{\"end\":55207,\"start\":55206},{\"end\":55222,\"start\":55217},{\"end\":55224,\"start\":55223},{\"end\":55237,\"start\":55232},{\"end\":55239,\"start\":55238},{\"end\":55259,\"start\":55252},{\"end\":55276,\"start\":55275},{\"end\":55294,\"start\":55285},{\"end\":55306,\"start\":55303},{\"end\":55319,\"start\":55315},{\"end\":55337,\"start\":55331},{\"end\":55361,\"start\":55352},{\"end\":55364,\"start\":55362},{\"end\":55913,\"start\":55906},{\"end\":55915,\"start\":55914},{\"end\":55930,\"start\":55923},{\"end\":55940,\"start\":55935},{\"end\":55942,\"start\":55941},{\"end\":55963,\"start\":55955},{\"end\":55972,\"start\":55968},{\"end\":55974,\"start\":55973},{\"end\":56377,\"start\":56371},{\"end\":56394,\"start\":56389},{\"end\":56688,\"start\":56682},{\"end\":56704,\"start\":56699},{\"end\":56715,\"start\":56709},{\"end\":56723,\"start\":56720},{\"end\":56734,\"start\":56731},{\"end\":56753,\"start\":56746},{\"end\":56763,\"start\":56759},{\"end\":56768,\"start\":56764},{\"end\":56784,\"start\":56775},{\"end\":56793,\"start\":56789},{\"end\":56811,\"start\":56803},{\"end\":56813,\"start\":56812},{\"end\":57297,\"start\":57287},{\"end\":57309,\"start\":57304},{\"end\":57326,\"start\":57319},{\"end\":57341,\"start\":57336},{\"end\":57359,\"start\":57351},{\"end\":57370,\"start\":57366},{\"end\":58024,\"start\":58015},{\"end\":58451,\"start\":58450},{\"end\":58463,\"start\":58462},{\"end\":58472,\"start\":58471},{\"end\":58942,\"start\":58938},{\"end\":58955,\"start\":58950},{\"end\":58969,\"start\":58965},{\"end\":58982,\"start\":58978},{\"end\":59437,\"start\":59432},{\"end\":59448,\"start\":59442},{\"end\":59840,\"start\":59837},{\"end\":59842,\"start\":59841},{\"end\":60243,\"start\":60240},{\"end\":60260,\"start\":60255},{\"end\":60272,\"start\":60265},{\"end\":60286,\"start\":60279},{\"end\":60300,\"start\":60292},{\"end\":60780,\"start\":60779},{\"end\":60784,\"start\":60781},{\"end\":60793,\"start\":60792},{\"end\":61130,\"start\":61124},{\"end\":61139,\"start\":61138},{\"end\":61156,\"start\":61148},{\"end\":61169,\"start\":61166},{\"end\":61187,\"start\":61181},{\"end\":61202,\"start\":61196},{\"end\":61215,\"start\":61209},{\"end\":61235,\"start\":61226},{\"end\":61248,\"start\":61245},{\"end\":61267,\"start\":61261},{\"end\":61269,\"start\":61268},{\"end\":61284,\"start\":61279},{\"end\":61301,\"start\":61293},{\"end\":61303,\"start\":61302},{\"end\":61318,\"start\":61312},{\"end\":61734,\"start\":61733},{\"end\":62132,\"start\":62128},{\"end\":62144,\"start\":62138},{\"end\":62155,\"start\":62154},{\"end\":62174,\"start\":62169},{\"end\":62189,\"start\":62182},{\"end\":62205,\"start\":62198},{\"end\":62217,\"start\":62212},{\"end\":62605,\"start\":62597},{\"end\":62939,\"start\":62933},{\"end\":62963,\"start\":62959},{\"end\":62978,\"start\":62970},{\"end\":62996,\"start\":62987},{\"end\":63013,\"start\":63001},{\"end\":63026,\"start\":63021},{\"end\":63038,\"start\":63035},{\"end\":63050,\"start\":63047},{\"end\":63065,\"start\":63057},{\"end\":63525,\"start\":63522},{\"end\":63538,\"start\":63533},{\"end\":63549,\"start\":63543},{\"end\":63561,\"start\":63554},{\"end\":63573,\"start\":63567},{\"end\":63590,\"start\":63583},{\"end\":63603,\"start\":63597},{\"end\":64239,\"start\":64236},{\"end\":64252,\"start\":64247},{\"end\":64264,\"start\":64257},{\"end\":64277,\"start\":64270},{\"end\":64290,\"start\":64284},{\"end\":64759,\"start\":64756},{\"end\":64772,\"start\":64767},{\"end\":64784,\"start\":64777},{\"end\":64796,\"start\":64790},{\"end\":64809,\"start\":64801},{\"end\":64819,\"start\":64814},{\"end\":64832,\"start\":64825},{\"end\":64845,\"start\":64839},{\"end\":65265,\"start\":65260},{\"end\":65553,\"start\":65548},{\"end\":65786,\"start\":65781},{\"end\":65804,\"start\":65798},{\"end\":66137,\"start\":66134},{\"end\":66146,\"start\":66142},{\"end\":66157,\"start\":66152},{\"end\":66170,\"start\":66162},{\"end\":66180,\"start\":66176},{\"end\":66194,\"start\":66190},{\"end\":66208,\"start\":66201},{\"end\":66226,\"start\":66221},{\"end\":66241,\"start\":66235},{\"end\":66252,\"start\":66248},{\"end\":67022,\"start\":67017},{\"end\":67043,\"start\":67039},{\"end\":67054,\"start\":67048},{\"end\":67274,\"start\":67270},{\"end\":67419,\"start\":67414},{\"end\":67433,\"start\":67428},{\"end\":67446,\"start\":67440},{\"end\":67460,\"start\":67453},{\"end\":67898,\"start\":67888},{\"end\":67921,\"start\":67914},{\"end\":67933,\"start\":67928},{\"end\":67951,\"start\":67943},{\"end\":67965,\"start\":67961},{\"end\":68625,\"start\":68618},{\"end\":68636,\"start\":68631},{\"end\":68648,\"start\":68641},{\"end\":68661,\"start\":68655},{\"end\":69182,\"start\":69175},{\"end\":69193,\"start\":69188},{\"end\":69201,\"start\":69198},{\"end\":69216,\"start\":69209},{\"end\":69229,\"start\":69223},{\"end\":69582,\"start\":69577},{\"end\":69599,\"start\":69592},{\"end\":69905,\"start\":69899},{\"end\":69921,\"start\":69914},{\"end\":69934,\"start\":69929},{\"end\":70393,\"start\":70389},{\"end\":70674,\"start\":70668},{\"end\":70691,\"start\":70686},{\"end\":70699,\"start\":70696},{\"end\":70701,\"start\":70700},{\"end\":70717,\"start\":70711},{\"end\":70994,\"start\":70993},{\"end\":71330,\"start\":71325},{\"end\":71649,\"start\":71648},{\"end\":71651,\"start\":71650},{\"end\":71664,\"start\":71663},{\"end\":71666,\"start\":71665},{\"end\":71675,\"start\":71674},{\"end\":71677,\"start\":71676},{\"end\":72008,\"start\":72003},{\"end\":72021,\"start\":72014}]", "bib_author_last_name": "[{\"end\":54658,\"start\":54649},{\"end\":54671,\"start\":54665},{\"end\":54684,\"start\":54677},{\"end\":54698,\"start\":54692},{\"end\":55215,\"start\":55208},{\"end\":55230,\"start\":55225},{\"end\":55250,\"start\":55240},{\"end\":55269,\"start\":55260},{\"end\":55273,\"start\":55271},{\"end\":55283,\"start\":55277},{\"end\":55301,\"start\":55295},{\"end\":55313,\"start\":55307},{\"end\":55329,\"start\":55320},{\"end\":55350,\"start\":55338},{\"end\":55377,\"start\":55365},{\"end\":55385,\"start\":55379},{\"end\":55921,\"start\":55916},{\"end\":55933,\"start\":55931},{\"end\":55953,\"start\":55943},{\"end\":55966,\"start\":55964},{\"end\":55980,\"start\":55975},{\"end\":56387,\"start\":56378},{\"end\":56409,\"start\":56395},{\"end\":56697,\"start\":56689},{\"end\":56707,\"start\":56705},{\"end\":56718,\"start\":56716},{\"end\":56729,\"start\":56724},{\"end\":56744,\"start\":56735},{\"end\":56757,\"start\":56754},{\"end\":56773,\"start\":56769},{\"end\":56787,\"start\":56785},{\"end\":56801,\"start\":56794},{\"end\":56819,\"start\":56814},{\"end\":57302,\"start\":57298},{\"end\":57317,\"start\":57310},{\"end\":57334,\"start\":57327},{\"end\":57349,\"start\":57342},{\"end\":57364,\"start\":57360},{\"end\":57380,\"start\":57371},{\"end\":58029,\"start\":58025},{\"end\":58460,\"start\":58452},{\"end\":58469,\"start\":58464},{\"end\":58482,\"start\":58473},{\"end\":58948,\"start\":58943},{\"end\":58963,\"start\":58956},{\"end\":58976,\"start\":58970},{\"end\":58987,\"start\":58983},{\"end\":59265,\"start\":59252},{\"end\":59440,\"start\":59438},{\"end\":59457,\"start\":59449},{\"end\":59849,\"start\":59843},{\"end\":60253,\"start\":60244},{\"end\":60263,\"start\":60261},{\"end\":60277,\"start\":60273},{\"end\":60290,\"start\":60287},{\"end\":60308,\"start\":60301},{\"end\":60790,\"start\":60785},{\"end\":60802,\"start\":60794},{\"end\":61136,\"start\":61131},{\"end\":61146,\"start\":61140},{\"end\":61164,\"start\":61157},{\"end\":61179,\"start\":61170},{\"end\":61194,\"start\":61188},{\"end\":61207,\"start\":61203},{\"end\":61224,\"start\":61216},{\"end\":61243,\"start\":61236},{\"end\":61259,\"start\":61249},{\"end\":61277,\"start\":61270},{\"end\":61291,\"start\":61285},{\"end\":61310,\"start\":61304},{\"end\":61324,\"start\":61319},{\"end\":61331,\"start\":61326},{\"end\":61740,\"start\":61735},{\"end\":61749,\"start\":61742},{\"end\":62136,\"start\":62133},{\"end\":62152,\"start\":62145},{\"end\":62167,\"start\":62156},{\"end\":62180,\"start\":62175},{\"end\":62196,\"start\":62190},{\"end\":62210,\"start\":62206},{\"end\":62221,\"start\":62218},{\"end\":62229,\"start\":62223},{\"end\":62609,\"start\":62606},{\"end\":62957,\"start\":62940},{\"end\":62968,\"start\":62964},{\"end\":62985,\"start\":62979},{\"end\":62999,\"start\":62997},{\"end\":63019,\"start\":63014},{\"end\":63033,\"start\":63027},{\"end\":63045,\"start\":63039},{\"end\":63055,\"start\":63051},{\"end\":63074,\"start\":63066},{\"end\":63531,\"start\":63526},{\"end\":63541,\"start\":63539},{\"end\":63552,\"start\":63550},{\"end\":63565,\"start\":63562},{\"end\":63581,\"start\":63574},{\"end\":63595,\"start\":63591},{\"end\":63612,\"start\":63604},{\"end\":64245,\"start\":64240},{\"end\":64255,\"start\":64253},{\"end\":64268,\"start\":64265},{\"end\":64282,\"start\":64278},{\"end\":64299,\"start\":64291},{\"end\":64765,\"start\":64760},{\"end\":64775,\"start\":64773},{\"end\":64788,\"start\":64785},{\"end\":64799,\"start\":64797},{\"end\":64812,\"start\":64810},{\"end\":64823,\"start\":64820},{\"end\":64837,\"start\":64833},{\"end\":64854,\"start\":64846},{\"end\":65275,\"start\":65266},{\"end\":65563,\"start\":65554},{\"end\":65796,\"start\":65787},{\"end\":65813,\"start\":65805},{\"end\":66140,\"start\":66138},{\"end\":66150,\"start\":66147},{\"end\":66160,\"start\":66158},{\"end\":66174,\"start\":66171},{\"end\":66188,\"start\":66181},{\"end\":66199,\"start\":66195},{\"end\":66219,\"start\":66209},{\"end\":66233,\"start\":66227},{\"end\":66246,\"start\":66242},{\"end\":66256,\"start\":66253},{\"end\":66641,\"start\":66634},{\"end\":66820,\"start\":66814},{\"end\":67037,\"start\":67023},{\"end\":67046,\"start\":67044},{\"end\":67064,\"start\":67055},{\"end\":67279,\"start\":67275},{\"end\":67426,\"start\":67420},{\"end\":67438,\"start\":67434},{\"end\":67451,\"start\":67447},{\"end\":67469,\"start\":67461},{\"end\":67912,\"start\":67899},{\"end\":67926,\"start\":67922},{\"end\":67941,\"start\":67934},{\"end\":67959,\"start\":67952},{\"end\":67970,\"start\":67966},{\"end\":67981,\"start\":67972},{\"end\":68270,\"start\":68251},{\"end\":68385,\"start\":68374},{\"end\":68400,\"start\":68387},{\"end\":68629,\"start\":68626},{\"end\":68639,\"start\":68637},{\"end\":68653,\"start\":68649},{\"end\":68670,\"start\":68662},{\"end\":69186,\"start\":69183},{\"end\":69196,\"start\":69194},{\"end\":69207,\"start\":69202},{\"end\":69221,\"start\":69217},{\"end\":69238,\"start\":69230},{\"end\":69590,\"start\":69583},{\"end\":69609,\"start\":69600},{\"end\":69912,\"start\":69906},{\"end\":69927,\"start\":69922},{\"end\":69939,\"start\":69935},{\"end\":70400,\"start\":70394},{\"end\":70684,\"start\":70675},{\"end\":70694,\"start\":70692},{\"end\":70709,\"start\":70702},{\"end\":70726,\"start\":70718},{\"end\":71002,\"start\":70995},{\"end\":71011,\"start\":71004},{\"end\":71211,\"start\":71200},{\"end\":71336,\"start\":71331},{\"end\":71661,\"start\":71652},{\"end\":71672,\"start\":71667},{\"end\":71684,\"start\":71678},{\"end\":71696,\"start\":71686},{\"end\":72012,\"start\":72009},{\"end\":72028,\"start\":72022}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":57661300},\"end\":54961,\"start\":54552},{\"attributes\":{\"id\":\"b1\"},\"end\":55118,\"start\":54963},{\"attributes\":{\"doi\":\"10.5194/gmd-9-4381-2016\",\"id\":\"b2\",\"matched_paper_id\":55425594},\"end\":55820,\"start\":55120},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2510044},\"end\":56298,\"start\":55822},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":5132658},\"end\":56600,\"start\":56300},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":199012975},\"end\":57215,\"start\":56602},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":2909637},\"end\":57939,\"start\":57217},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":57190086},\"end\":58357,\"start\":57941},{\"attributes\":{\"doi\":\"10.1109/DCC.2018.00042\",\"id\":\"b8\",\"matched_paper_id\":20280062},\"end\":58806,\"start\":58359},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":16028174},\"end\":59248,\"start\":58808},{\"attributes\":{\"id\":\"b10\"},\"end\":59375,\"start\":59250},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":8296694},\"end\":59751,\"start\":59377},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":3434387},\"end\":60146,\"start\":59753},{\"attributes\":{\"id\":\"b13\"},\"end\":60718,\"start\":60148},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":8874631},\"end\":61054,\"start\":60720},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":691184},\"end\":61672,\"start\":61056},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":10606404},\"end\":61906,\"start\":61674},{\"attributes\":{\"id\":\"b17\"},\"end\":62040,\"start\":61908},{\"attributes\":{\"id\":\"b18\"},\"end\":62472,\"start\":62042},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":4913347},\"end\":62869,\"start\":62474},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":10297877},\"end\":63423,\"start\":62871},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":207925294},\"end\":64134,\"start\":63425},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":52200248},\"end\":64657,\"start\":64136},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":53358213},\"end\":65213,\"start\":64659},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":15277033},\"end\":65489,\"start\":65215},{\"attributes\":{\"id\":\"b25\"},\"end\":65724,\"start\":65491},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":12262331},\"end\":66055,\"start\":65726},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":51924604},\"end\":66630,\"start\":66057},{\"attributes\":{\"id\":\"b28\"},\"end\":66728,\"start\":66632},{\"attributes\":{\"id\":\"b29\"},\"end\":66810,\"start\":66730},{\"attributes\":{\"id\":\"b30\"},\"end\":66954,\"start\":66812},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7573897},\"end\":67266,\"start\":66956},{\"attributes\":{\"id\":\"b32\"},\"end\":67337,\"start\":67268},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":17594218},\"end\":67830,\"start\":67339},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3527510},\"end\":68247,\"start\":67832},{\"attributes\":{\"id\":\"b35\"},\"end\":68370,\"start\":68249},{\"attributes\":{\"id\":\"b36\"},\"end\":68477,\"start\":68372},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":2178023},\"end\":69076,\"start\":68479},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":49405466},\"end\":69510,\"start\":69078},{\"attributes\":{\"id\":\"b39\"},\"end\":69838,\"start\":69512},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":8653580},\"end\":70361,\"start\":69840},{\"attributes\":{\"id\":\"b41\"},\"end\":70560,\"start\":70363},{\"attributes\":{\"id\":\"b42\"},\"end\":70946,\"start\":70562},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":7051992},\"end\":71196,\"start\":70948},{\"attributes\":{\"id\":\"b44\"},\"end\":71294,\"start\":71198},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":58596691},\"end\":71572,\"start\":71296},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":207761262},\"end\":71946,\"start\":71574},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":9267632},\"end\":72226,\"start\":71948}]", "bib_title": "[{\"end\":54642,\"start\":54552},{\"end\":55204,\"start\":55120},{\"end\":55904,\"start\":55822},{\"end\":56369,\"start\":56300},{\"end\":56680,\"start\":56602},{\"end\":57285,\"start\":57217},{\"end\":58013,\"start\":57941},{\"end\":58448,\"start\":58359},{\"end\":58936,\"start\":58808},{\"end\":59430,\"start\":59377},{\"end\":59835,\"start\":59753},{\"end\":60238,\"start\":60148},{\"end\":60777,\"start\":60720},{\"end\":61122,\"start\":61056},{\"end\":61731,\"start\":61674},{\"end\":62595,\"start\":62474},{\"end\":62931,\"start\":62871},{\"end\":63520,\"start\":63425},{\"end\":64234,\"start\":64136},{\"end\":64754,\"start\":64659},{\"end\":65258,\"start\":65215},{\"end\":65546,\"start\":65491},{\"end\":65779,\"start\":65726},{\"end\":66132,\"start\":66057},{\"end\":67015,\"start\":66956},{\"end\":67412,\"start\":67339},{\"end\":67886,\"start\":67832},{\"end\":68616,\"start\":68479},{\"end\":69173,\"start\":69078},{\"end\":69897,\"start\":69840},{\"end\":70991,\"start\":70948},{\"end\":71323,\"start\":71296},{\"end\":71646,\"start\":71574},{\"end\":72001,\"start\":71948}]", "bib_author": "[{\"end\":54660,\"start\":54644},{\"end\":54673,\"start\":54660},{\"end\":54686,\"start\":54673},{\"end\":54700,\"start\":54686},{\"end\":55217,\"start\":55206},{\"end\":55232,\"start\":55217},{\"end\":55252,\"start\":55232},{\"end\":55271,\"start\":55252},{\"end\":55275,\"start\":55271},{\"end\":55285,\"start\":55275},{\"end\":55303,\"start\":55285},{\"end\":55315,\"start\":55303},{\"end\":55331,\"start\":55315},{\"end\":55352,\"start\":55331},{\"end\":55379,\"start\":55352},{\"end\":55387,\"start\":55379},{\"end\":55923,\"start\":55906},{\"end\":55935,\"start\":55923},{\"end\":55955,\"start\":55935},{\"end\":55968,\"start\":55955},{\"end\":55982,\"start\":55968},{\"end\":56389,\"start\":56371},{\"end\":56411,\"start\":56389},{\"end\":56699,\"start\":56682},{\"end\":56709,\"start\":56699},{\"end\":56720,\"start\":56709},{\"end\":56731,\"start\":56720},{\"end\":56746,\"start\":56731},{\"end\":56759,\"start\":56746},{\"end\":56775,\"start\":56759},{\"end\":56789,\"start\":56775},{\"end\":56803,\"start\":56789},{\"end\":56821,\"start\":56803},{\"end\":57304,\"start\":57287},{\"end\":57319,\"start\":57304},{\"end\":57336,\"start\":57319},{\"end\":57351,\"start\":57336},{\"end\":57366,\"start\":57351},{\"end\":57382,\"start\":57366},{\"end\":58031,\"start\":58015},{\"end\":58462,\"start\":58450},{\"end\":58471,\"start\":58462},{\"end\":58484,\"start\":58471},{\"end\":58950,\"start\":58938},{\"end\":58965,\"start\":58950},{\"end\":58978,\"start\":58965},{\"end\":58989,\"start\":58978},{\"end\":59267,\"start\":59252},{\"end\":59442,\"start\":59432},{\"end\":59459,\"start\":59442},{\"end\":59851,\"start\":59837},{\"end\":60255,\"start\":60240},{\"end\":60265,\"start\":60255},{\"end\":60279,\"start\":60265},{\"end\":60292,\"start\":60279},{\"end\":60310,\"start\":60292},{\"end\":60792,\"start\":60779},{\"end\":60804,\"start\":60792},{\"end\":61138,\"start\":61124},{\"end\":61148,\"start\":61138},{\"end\":61166,\"start\":61148},{\"end\":61181,\"start\":61166},{\"end\":61196,\"start\":61181},{\"end\":61209,\"start\":61196},{\"end\":61226,\"start\":61209},{\"end\":61245,\"start\":61226},{\"end\":61261,\"start\":61245},{\"end\":61279,\"start\":61261},{\"end\":61293,\"start\":61279},{\"end\":61312,\"start\":61293},{\"end\":61326,\"start\":61312},{\"end\":61333,\"start\":61326},{\"end\":61742,\"start\":61733},{\"end\":61751,\"start\":61742},{\"end\":62138,\"start\":62128},{\"end\":62154,\"start\":62138},{\"end\":62169,\"start\":62154},{\"end\":62182,\"start\":62169},{\"end\":62198,\"start\":62182},{\"end\":62212,\"start\":62198},{\"end\":62223,\"start\":62212},{\"end\":62231,\"start\":62223},{\"end\":62611,\"start\":62597},{\"end\":62959,\"start\":62933},{\"end\":62970,\"start\":62959},{\"end\":62987,\"start\":62970},{\"end\":63001,\"start\":62987},{\"end\":63021,\"start\":63001},{\"end\":63035,\"start\":63021},{\"end\":63047,\"start\":63035},{\"end\":63057,\"start\":63047},{\"end\":63076,\"start\":63057},{\"end\":63533,\"start\":63522},{\"end\":63543,\"start\":63533},{\"end\":63554,\"start\":63543},{\"end\":63567,\"start\":63554},{\"end\":63583,\"start\":63567},{\"end\":63597,\"start\":63583},{\"end\":63614,\"start\":63597},{\"end\":64247,\"start\":64236},{\"end\":64257,\"start\":64247},{\"end\":64270,\"start\":64257},{\"end\":64284,\"start\":64270},{\"end\":64301,\"start\":64284},{\"end\":64767,\"start\":64756},{\"end\":64777,\"start\":64767},{\"end\":64790,\"start\":64777},{\"end\":64801,\"start\":64790},{\"end\":64814,\"start\":64801},{\"end\":64825,\"start\":64814},{\"end\":64839,\"start\":64825},{\"end\":64856,\"start\":64839},{\"end\":65277,\"start\":65260},{\"end\":65565,\"start\":65548},{\"end\":65798,\"start\":65781},{\"end\":65815,\"start\":65798},{\"end\":66142,\"start\":66134},{\"end\":66152,\"start\":66142},{\"end\":66162,\"start\":66152},{\"end\":66176,\"start\":66162},{\"end\":66190,\"start\":66176},{\"end\":66201,\"start\":66190},{\"end\":66221,\"start\":66201},{\"end\":66235,\"start\":66221},{\"end\":66248,\"start\":66235},{\"end\":66258,\"start\":66248},{\"end\":66643,\"start\":66634},{\"end\":66822,\"start\":66814},{\"end\":67039,\"start\":67017},{\"end\":67048,\"start\":67039},{\"end\":67066,\"start\":67048},{\"end\":67281,\"start\":67270},{\"end\":67428,\"start\":67414},{\"end\":67440,\"start\":67428},{\"end\":67453,\"start\":67440},{\"end\":67471,\"start\":67453},{\"end\":67914,\"start\":67888},{\"end\":67928,\"start\":67914},{\"end\":67943,\"start\":67928},{\"end\":67961,\"start\":67943},{\"end\":67972,\"start\":67961},{\"end\":67983,\"start\":67972},{\"end\":68272,\"start\":68251},{\"end\":68387,\"start\":68374},{\"end\":68402,\"start\":68387},{\"end\":68631,\"start\":68618},{\"end\":68641,\"start\":68631},{\"end\":68655,\"start\":68641},{\"end\":68672,\"start\":68655},{\"end\":69188,\"start\":69175},{\"end\":69198,\"start\":69188},{\"end\":69209,\"start\":69198},{\"end\":69223,\"start\":69209},{\"end\":69240,\"start\":69223},{\"end\":69592,\"start\":69577},{\"end\":69611,\"start\":69592},{\"end\":69914,\"start\":69899},{\"end\":69929,\"start\":69914},{\"end\":69941,\"start\":69929},{\"end\":70402,\"start\":70389},{\"end\":70686,\"start\":70668},{\"end\":70696,\"start\":70686},{\"end\":70711,\"start\":70696},{\"end\":70728,\"start\":70711},{\"end\":71004,\"start\":70993},{\"end\":71013,\"start\":71004},{\"end\":71213,\"start\":71200},{\"end\":71338,\"start\":71325},{\"end\":71663,\"start\":71648},{\"end\":71674,\"start\":71663},{\"end\":71686,\"start\":71674},{\"end\":71698,\"start\":71686},{\"end\":72014,\"start\":72003},{\"end\":72030,\"start\":72014}]", "bib_venue": "[{\"end\":54738,\"start\":54700},{\"end\":55028,\"start\":54963},{\"end\":55441,\"start\":55410},{\"end\":56008,\"start\":55982},{\"end\":56429,\"start\":56411},{\"end\":56889,\"start\":56821},{\"end\":57490,\"start\":57382},{\"end\":58087,\"start\":58031},{\"end\":58533,\"start\":58506},{\"end\":59011,\"start\":58989},{\"end\":59528,\"start\":59459},{\"end\":59893,\"start\":59851},{\"end\":60370,\"start\":60310},{\"end\":60850,\"start\":60804},{\"end\":61344,\"start\":61333},{\"end\":61773,\"start\":61751},{\"end\":61940,\"start\":61908},{\"end\":62126,\"start\":62042},{\"end\":62647,\"start\":62611},{\"end\":63128,\"start\":63076},{\"end\":63722,\"start\":63614},{\"end\":64361,\"start\":64301},{\"end\":64902,\"start\":64856},{\"end\":65333,\"start\":65277},{\"end\":65591,\"start\":65565},{\"end\":65871,\"start\":65815},{\"end\":66322,\"start\":66258},{\"end\":66744,\"start\":66730},{\"end\":67102,\"start\":67066},{\"end\":67548,\"start\":67471},{\"end\":68023,\"start\":67983},{\"end\":68741,\"start\":68672},{\"end\":69274,\"start\":69240},{\"end\":69575,\"start\":69512},{\"end\":70030,\"start\":69941},{\"end\":70387,\"start\":70363},{\"end\":70666,\"start\":70562},{\"end\":71054,\"start\":71013},{\"end\":71421,\"start\":71338},{\"end\":71735,\"start\":71698},{\"end\":72069,\"start\":72030},{\"end\":56014,\"start\":56010},{\"end\":57602,\"start\":57492},{\"end\":58147,\"start\":58089},{\"end\":58552,\"start\":58535},{\"end\":59547,\"start\":59530},{\"end\":59899,\"start\":59895},{\"end\":60389,\"start\":60372},{\"end\":60869,\"start\":60852},{\"end\":63817,\"start\":63724},{\"end\":64380,\"start\":64363},{\"end\":64921,\"start\":64904},{\"end\":67567,\"start\":67550},{\"end\":68760,\"start\":68743},{\"end\":70123,\"start\":70032},{\"end\":71429,\"start\":71423}]"}}}, "year": 2023, "month": 12, "day": 17}