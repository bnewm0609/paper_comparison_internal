{"id": 7473831, "updated": "2023-10-01 15:04:21.583", "metadata": {"title": "Sentence Simplification with Deep Reinforcement Learning", "authors": "[{\"first\":\"Xingxing\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Mirella\",\"last\":\"Lapata\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "Sentence simplification aims to make sentences easier to read and understand. Most recent approaches draw on insights from machine translation to learn simplification rewrites from monolingual corpora of complex and simple sentences. We address the simplification problem with an encoder-decoder model coupled with a deep reinforcement learning framework. Our model, which we call DRESS (as shorthand for Deep REinforcement Sentence Simplification), explores the space of possible simplifications while learning to optimize a reward function that encourages outputs which are simple, fluent, and preserve the meaning of the input. Experiments on three datasets demonstrate that our model outperforms competitive simplification systems.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1703.10931", "mag": "2953033958", "acl": "D17-1062", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/ZhangL17", "doi": "10.18653/v1/d17-1062"}}, "content": {"source": {"pdf_hash": "1decfe4c92b9cdd90aa378faa52b85aa49b8a277", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/D17-1062.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/D17-1062.pdf", "status": "HYBRID"}}, "grobid": {"id": "005da54c3c7dd9da53ef7dbd7a23161c343594d2", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1decfe4c92b9cdd90aa378faa52b85aa49b8a277.txt", "contents": "\nSentence Simplification with Deep Reinforcement Learning\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsSeptember 7-11, 2017. 2017\n\nXingxing Zhang x.zhang@ed.ac.uk \nInstitute for Language, Cognition and Computation School of Informatics\nUniversity of Edinburgh\n10 Crichton StreetEH8 9ABEdinburgh\n\nMirella Lapata \nInstitute for Language, Cognition and Computation School of Informatics\nUniversity of Edinburgh\n10 Crichton StreetEH8 9ABEdinburgh\n\nSentence Simplification with Deep Reinforcement Learning\n\nNatural Language Processing\nCopenhagen, DenmarkAssociation for Computational LinguisticsSeptember 7-11, 2017. 2017\nSentence simplification aims to make sentences easier to read and understand. Most recent approaches draw on insights from machine translation to learn simplification rewrites from monolingual corpora of complex and simple sentences. We address the simplification problem with an encoder-decoder model coupled with a deep reinforcement learning framework. Our model, which we call DRESS (as shorthand for Deep REinforcement Sentence Simplification), explores the space of possible simplifications while learning to optimize a reward function that encourages outputs which are simple, fluent, and preserve the meaning of the input. Experiments on three datasets demonstrate that our model outperforms competitive simplification systems. 1\n\nIntroduction\n\nThe main goal of sentence simplification is to reduce the linguistic complexity of text, while still retaining its original information and meaning. The simplification task has been the subject of several modeling efforts in recent years due to its relevance for NLP applications and individuals alike (Siddharthan, 2014;Shardlow, 2014). For instance, a simplification component could be used as a preprocessing step to improve the performance of parsers (Chandrasekar et al., 1996), summarizers (Beigman Klebanov et al., 2004), and semantic role labelers (Vickrey and Koller, 2008;Woodsend and Lapata, 2014). Automatic simplification would also benefit people with low-literacy skills (Watanabe et al., 2009), such as children and non-native speakers as well as individuals with autism (Evans et al., 2014), aphasia (Carroll et al., 1999), or dyslexia (Rello et al., 2013).\n\nThe most prevalent rewrite operations which give rise to simplified text include substituting rare words with more common words or phrases, rendering syntactically complex structures simpler, and deleting elements of the original text (Siddharthan, 2014). Earlier work focused on individual aspects of the simplification problem. For example, several systems performed syntactic simplification only, using rules aimed at sentence splitting (Carroll et al., 1999;Chandrasekar et al., 1996;Vickrey and Koller, 2008;Siddharthan, 2004) while others turned to lexical simplification by substituting difficult words with more common WordNet synonyms or paraphrases (Devlin, 1999;Inui et al., 2003;Kaji et al., 2002).\n\nRecent approaches view the simplification process more holistically as a monolingual textto-text generation task borrowing ideas from statistical machine translation. Simplification rewrites are learned automatically from examples of complex-simple sentences extracted from online resources such as the ordinary and simple English Wikipedia.\n\nFor example, Zhu et al. (2010) draw inspiration from syntax-based translation and propose a model similar to Yamada and Knight (2001) which additionally performs simplification-specific rewrite operations (e.g., sentence splitting). Woodsend and Lapata (2011) formulate simplification in the framework of Quasi-synchronous grammar (Smith and Eisner, 2006) and use integer linear programming to score the candidate translations/simplifications. Wubben et al. (2012) propose a two-stage model: initially, a standard phrase-based machine translation (PBMT) model is trained on complex-simple sentence pairs. During inference, the K-best outputs of the PBMT model are reranked according to their dis-similarity to the (complex) input sentence. The hybrid model developed in Narayan and Gardent (2014) also operates in two phases. Initially, a probabilistic model performs sentence splitting and deletion operations over discourse representation structures assigned by Boxer (Curran et al., 2007). The resulting sentences are further simplified by a model similar to Wubben et al. (2012). Xu et al. (2016) train a syntax-based machine translation model on a large scale paraphrase dataset (Ganitkevitch et al., 2013) using simplification-specific objective functions and features to encourage simpler output.\n\nIn this paper we propose a simplification model which draws on insights from neural machine translation (Bahdanau et al., 2015;Sutskever et al., 2014). Central to this approach is an encoderdecoder architecture implemented by recurrent neural networks. The encoder reads the source sequence into a list of continuous-space representations from which the decoder generates the target sequence. Although our model uses the encoder-decoder architecture as its backbone, it must also meet constraints imposed by the simplification task itself, i.e., the predicted output must be simpler, preserve the meaning of the input, and grammatical. To incorporate this knowledge, the model is trained in a reinforcement learning framework (Williams, 1992): it explores the space of possible simplifications while learning to maximize an expected reward function that encourages outputs which meet simplificationspecific constraints. Reinforcement learning has been previously applied to extractive summarization (Ryang and Abekawa, 2012), information extraction (Narasimhan et al., 2016), dialogue generation (Li et al., 2016), machine translation, and image caption generation (Ranzato et al., 2016). We evaluate our system on three publicly available datasets collated automatically from Wikipedia (Zhu et al., 2010;Woodsend and Lapata, 2011) and human-authored news articles (Xu et al., 2015b). We experimentally show that the reinforcement learning framework is the key to successful generation of simplified text bringing significant improvements over strong simplification models across datasets.\n\n\nNeural Encoder-Decoder Model\n\nWe will first define a basic encoder-decoder model for sentence simplification and then explain how to embed it in a reinforcement learning framework. Given a (complex) source sentence X = (x 1 , x 2 , . . . , x |X| ), our model learns to predict its simplified target Y = (y 1 , y 2 , . . . , y |Y | ). Inferring the target Y given the source X is a typical sequence to sequence learning problem, which can be modeled with attention-based encoderdecoder models (Bahdanau et al., 2015;Luong et al., 2015). Sentence simplification is slightly different from related sequence transduction tasks (e.g., compression) in that it can involve splitting operations. For example, a long source sentence (In 1883, Faur married Marie Fremiet, with whom he had two sons.) can be simplified as two sentences (In 1883, Faur married Marie Fremiet. They had two sons.). Nevertheless, we still view the target as a sequence, i.e., two or more sequences concatenated with full stops.\n\nThe encoder-decoder model has two parts (see left hand side in Figure 1). The encoder transforms the source sentence X into a sequence of hidden states (h S 1 , h S 2 , . . . , h S |X| ) with a Long Short-Term Memory Network (LSTM; Hochreiter and Schmidhuber 1997), while the decoder uses another LSTM to generate one word y t+1 at a time in the simplified target Y . Generation is conditioned on all previously generated words y 1:t and a dynamically created context vector c t , which encodes the source sentence:\nP (Y |X) = |Y | t=1 P (y t |y 1:t\u22121 , X) (1) P (y t+1 |y 1:t , X) = softmax(g(h T t , c t ))(2)\nwhere g(\u00b7) is a one-hidden-layer neural network with the following parametrization:\ng(h T t , c t ) = W o tanh(U h h T t + W h c t ) (3)\nwhere W o \u2208 R |V |\u00d7d , U h \u2208 R d\u00d7d , and W h \u2208 R d\u00d7d ; |V | is the output vocabulary size and d the hidden unit size. h T t is the hidden state of the decoder LSTM which summarizes y 1:t , i.e., what has been generated so far:\nh T t = LSTM(y t , h T t\u22121 )(4)\nThe dynamic context vector c t is the weighted sum of the hidden states of the source sentence:\nc t = |X| i=1 \u03b1 ti h S i(5)\nwhose weights \u03b1 ti are determined by an attention mechanism:\n\u03b1 ti = exp(h T t \u00b7 h S i ) i exp(h T t \u00b7 h S i )(6)\nwhere \u00b7 is the dot product between two vectors. We use the dot product here mainly for efficiency reasons; alternative ways to compute attention scores have been proposed in the literature and we refer the interested reader to Luong et al. (2015). The model sketched above is usually trained by minimizing the negative log-likelihood of the training source-target pairs.\n\n\nReinforcement Learning for Sentence Simplification\n\nIn this section we present DRESS, our Deep REinforcement Sentence Simplification model. Despite successful application in numerous sequence transduction tasks (Jean et al., 2015;Xu et al., 2015a), a vanilla encoder-decoder model is not ideal for sentence simplification. Although a number of rewrite operations (e.g., copying, deletion, substitution, word reordering) can be used to simplify text, copying is by far the most common. We empirically found that 73% of the target words are copied from the source in the Newsela dataset. This number further increases to 83% when considering Wikipedia-based datasets (we provide details on these datasets in Section 5). As a result, a generic encoder-decoder model learns to copy all too well at the expense of other rewrite operations, often parroting back the source or making only a few trivial changes.\n\nTo encourage a wider variety of rewrite operations while remaining fluent and faithful to the meaning of the source, we employ a reinforcement learning framework (see Figure 1). We view the encoder-decoder model as an agent which first reads the source sentence X; then at each step, it takes an action\u0177 t \u2208 V (where V is the output vocabulary) according to a policy P RL (\u0177 t |\u0177 1:t\u22121 , X) (see Equation (2)). The agent continues to take actions until it produces an End Of Sentence (EOS) token yielding the action sequence\u0176 = (\u0177 1 ,\u0177 2 , . . . ,\u0177 |\u0176 | ), which is also the simplified output of our model. A reward r is then received and the REINFORCE algorithm (Williams, 1992) is used to update the agent. In the following, we first introduce our reward and then present the details of the REINFORCE algorithm.\n\n\nReward\n\nThe reward r(\u0176 ) for system output\u0176 is the weighted sum of the three components aimed at capturing key aspects of the target output, namely simplicity, relevance, and fluency:\nr(\u0176 ) = \u03bb S r S + \u03bb R r R + \u03bb F r F (7) where \u03bb S , \u03bb R , \u03bb F \u2208 [0, 1]; r(\u0176 ) is a shorthand for r(X, Y,\u0176 )\nwhere X is the source, Y the reference (or target), and\u0176 the system output. r S , r R , and r F are shorthands for simplicity r S (X, Y,\u0176 ), relevance r R (X,\u0176 ), and fluency r F (\u0176 ). We provide details for each reward summand below.\n\nSimplicity To encourage the model to apply a wide range of simplification operations, we use SARI (Xu et al., 2016), a recently proposed metric which compares System output Against References and against the Input sentence. SARI is the arithmetic average of n-gram precision and recall of three rewrite operations: addition, copying, and deletion. It rewards addition operations where system output was not in the input but occurred in the references. Analogously, it rewards words retained/deleted in both the system output and the references. In experimental evaluation Xu et al. (2016) demonstrate that SARI correlates well with human judgments of simplicity, whilst correctly rewarding systems that both make changes and simplify the input.\n\nOne caveat with using SARI as a reward is the fact that it relies on the availability of multiple references which are rare for sentence simplification. Xu et al. (2016) provide eight references for 2,350 sentences, but these are primarily for system tuning and evaluation rather than training. The majority of existing simplification datasets (see Section 5 for details) have a single reference for each source sentence. Moreover, they are unavoidably noisy as they are mostly constructed automatically, e.g., by aligning sentences from the ordinary and simple English Wikipedias. When relying solely on a single reference, SARI will try to reward accidental n-grams that should never have occurred in it. To countenance the effect of noise, we apply SARI(X,\u0176 , Y ) in the expected direction, with X as the source,\u0176 the system output, and Y the reference as well as in the reverse direction with Y as the system output and\u0176 as the reference. Assuming our system can produce reasonably good simplifications, by swapping the output\nX = x 1 x 2 x 3 x 4 x 5 Y =\u01771\u01772\u01773\nGet Action Seq.\u0176\n\n\nUpdate Agent\n\n\nSimplicity Model\n\n\nRelevance Model\n\nGrammar Model REINFORCE algorithm Y X\u0176 X\u0176 Y Figure 1: Deep reinforcement learning simplification model. X is the complex sentence, Y the reference (simple) sentence and\u0176 the action sequence (simplification) produced by the encoder-decoder model. and the reference, reverse SARI can be used to estimate how good a reference is with respect to the system output. Our first reward is therefore the weighted sum of SARI and reverse SARI:\nr S = \u03b2 SARI(X,\u0176 , Y )+(1\u2212\u03b2) SARI(X, Y,\u0176 ) (8)\nRelevance While the simplicity-based reward r S tries to encourage the model to make changes, the relevance reward r R ensures that the generated sentences preserve the meaning of the source. We use an LSTM sentence encoder to convert the source X and the predicted target\u0176 into two vectors q X and q\u0176 . The relevance reward r R is simply the cosine similarity between these two vectors:\nr R = cos(q X , q\u0176 ) = q X \u00b7 q\u0176 ||q X || ||q\u0176 ||(9)\nWe use a sequence auto-encoder (SAE; Dai and Le 2015) to train the LSTM sentence encoder on both the complex and simple sentences. Specifically, the SAE uses sentence X = (x 1 , . . . , x |X| ) to infer itself via an encoder-decoder model (without an attention mechanism). Firstly, an encoder LSTM converts X into a sequence of hidden states (h 1 , . . . , h |X| ). Then, we use h |X| to initialize the hidden state of the decoder LSTM and recover/generate X one word at a time.\n\nFluency Xu et al. (2016) observe that SARI correlates less with fluency compared to other metrics such as BLEU (Papineni et al., 2002). The fluency reward r F models the well-formedness of the generated sentences explicitly. It is the normalized sentence probability assigned by an LSTM language model trained on simple sentences:\nr F = exp \uf8eb \uf8ed 1 |\u0176 | |\u0176 | i=1 log P LM (\u0177 i |\u0177 0:i\u22121 ) \uf8f6 \uf8f8 (10)\nWe take the exponential of\u0176 's perplexity to ensure that r F \u2208 [0, 1] as is the case with r S and r R .\n\n\nThe REINFORCE Algorithm\n\nThe goal of the REINFORCE algorithm is to find an agent that maximizes the expected reward. The training loss for one sequence is its negative expected reward:\nL(\u03b8) = \u2212E (\u0177 1 ,...,\u0177 |\u0176 | )\u223cP RL (\u00b7|X) [r(\u0177 1 , . . .,\u0177 |\u0176 | )]\nwhere P RL is our policy, i.e., the distribution produced by the encoder-decoder model (see Equation(2)) and r(\u00b7) is the reward function of an action sequence\u0176 = (\u0177 1 , . . . ,\u0177 |\u0176 | ), i.e., a generated simplification. Unfortunately, computing the expectation term is prohibitive, since there is an infinite number of possible action sequences. In practice, we approximate this expectation with a single sample from the distribution of P LR (\u00b7|X). We refer to Williams (1992) for the full derivation of the gradients. The gradient of L(\u03b8) is:\n\u2207L(\u03b8) \u2248 |\u0176 | t=1 \u2207 log P RL (\u0177 t |\u0177 1:t\u22121 , X)[r(\u0177 1:|\u0176 | ) \u2212 b t ]\nTo reduce the variance of gradients, we also introduce a baseline linear regression model b t to estimate the expected future reward at time t (Ranzato et al., 2016). b t takes the concatenation of h T trained by minimizing mean squared error. We do not back-propagate this error to h T t or c t during training (Ranzato et al., 2016).\n\n\nLearning\n\nPresented in its original form, the REINFORCE algorithm starts learning with a random policy. This assumption can make model training challenging for generation tasks like ours with large vocabularies (i.e., action spaces). We address this issue by pre-training our agent (i.e., the encoderdecoder model) with a negative log-likelihood objective (see Section 2), making sure it can produce reasonable simplifications, thereby starting off with a policy which is better than random. We follow prior work (Ranzato et al., 2016) in adopting a curriculum learning strategy. In the beginning of training, we give little freedom to our agent allowing it to predict the last few words for each target sentence. For every target sequence, we use negative log-likelihood to train the first L (initially, L = 24) tokens and apply the reinforcement learning algorithm to the (L + 1)th tokens onwards. Every two epochs, we set L = L \u2212 3 and the training terminates when L is 0.\n\n\nLexical Simplification\n\nLexical substitution, the replacement of complex words with simpler alternatives, is an integral part of sentence simplification (Specia et al., 2012). The model presented so far learns lexical substitution and other rewrite operations jointly. In some cases, words are predicted because they seem natural in the their context, but are poor substitutes for the content of the complex sentence. To countenance this, we learn lexical simplifications explicitly and integrate them with our reinforcement learning-based model.\n\nWe use an pre-trained encoder-decoder model (which is trained on a parallel corpus of complex and simple sentences) to obtain probabilistic word alignments, aka attention scores (see \u03b1 t in Equation (6)). Let X = (x 1 , x 2 , . . . , x |X| ) denote a source sentence and Y = (y 1 , y 2 , . . . , y |Y | ) a target sentence. We convert X into |X| hidden states (v 1 , v 2 , . . . , v |X| ) with an LSTM. Note that v t \u2208 R d\u00d71 corresponds to the context dependent representation of x t . Let \u03b1 t denote the alignment scores \u03b1 t1 , \u03b1 t2 , . . . , \u03b1 t|X| . The lexical simplification probability of y t given the source sentence and the alignment scores is:\nP LS (y t |X, \u03b1 t ) = softmax(W l s t )(11)\nwhere W l \u2208 R |V |\u00d7d and s t represents the source:\ns t = |X| i=1 \u03b1 ti v i(12)\nThe lexical simplification model on its own encourages lexical substitutions, without taking into account what has been generated so far (i.e., y 1:t\u22121 ) and as a result fluency could be compromised. A straightforward solution is to integrate lexical simplification with our reinforcement learning trained model (Section 3) using linear interpolation, where \u03b7 \u2208 [0, 1]: P (y t |y 1:t\u22121 , X) = (1 \u2212 \u03b7) P RL (y t |y 1:t\u22121 , X)\n+ \u03b7 P LS (y t |X, \u03b1 t )(13)\n\nExperimental Setup\n\nIn this section we present our experimental setup for assessing the performance of the simplification model described above. We give details on our datasets, model training, evaluation protocol, and the systems used for comparison. We also constructed WikiLarge, a larger Wikipedia corpus by combining previously created simplification corpora. Specifically, we aggregated the aligned sentence pairs in Kauchak (2013), the aligned and revision sentence pairs in Woodsend and Lapata (2011), and Zhu's (2010) WikiSmall dataset described above. We used the development and test sets created in Xu et al. (2016). These are complex sentences taken from WikiSmall paired with simplifications provided by Amazon Mechanical Turk workers. The dataset contains 8 (reference) simplifications for 2,359 sentences partitioned into 2,000 for development and 359 for testing. After removing duplicates and sentences in development and test sets, the resulting training set contains 296,402 sentence pairs.\n\nOur third dataset is Newsela, a corpus collated by Xu et al. (2015b) who argue that Wikipediabased resources are suboptimal due to the automatic sentence alignment which unavoidably introduces errors, and their uniform writing style which leads to systems that generalize poorly. Newsela 2 consists of 1,130 news articles, each rewritten four times by professional editors for children at different grade levels (0 is the most complex level and 4 is simplest). Xu et al. (2015b) provide multiple aligned complex-simple pairs within each article. We removed sentence pairs corresponding to levels 0-1, 1-2, and 2-3, since they were too similar to each other. The first 1,070 documents were used for training (94,208 sentence pairs), the next 30 documents for development (1,129 sentence pairs) and the last 30 documents for testing (1,076 sentence pairs). 3 We are not aware of any published results on this dataset.\n\nTraining Details We trained our models on an Nvidia GPU card. We used the same hyperparameters across datasets. We first trained an encoder-decoder model, and then performed reinforcement learning training (Section 3), and trained the lexical simplification model (Section 4). Encoder-decoder parameters were uniformly initialized to [\u22120.1, 0.1]. We used Adam (Kingma and Ba, 2014) to optimize the model with learning rate 0.001; the first momentum coefficient was set to 0.9 and the second momentum coefficient to 0.999. The gradient was rescaled when the norm exceeded 5 (Pascanu et al., 2013). Both encoder and decoder LSTMs have two layers with 256 hidden neurons in each layer. We regularized all LSTMs with a dropout rate of 0.2 (Zaremba et al., 2014). We initialized the encoder and decoder word embedding matrices with 300 dimensional Glove vectors (Pennington et al., 2014).\n\nDuring reinforcement training, we used plain stochastic gradient descent with a learning rate of 0.01. We set \u03b2 = 0.1, \u03bb S = 1, \u03bb R = 0.25 and \u03bb F = 0.5. 4 Training details for the lexical 2 https://newsela.com 3 If a sentence has multiple references in the development or test set, we use the reference with highest simplicity level. 4 Weights were tuned on the development set of the Newsela dataset and kept fixed for the other two datasets. simplification model are identical to the encoderdecoder model except that word embedding matrices were randomly initialized. The weight of the lexical simplification model was set to \u03b7 = 0.1.\n\nTo reduce vocabulary size, named entities were tagged with the Stanford CoreNLP  and anonymized with a NE@N token, where NE \u2208 {PER, LOC, ORG, MISC} and N indicates NE@N is the N -th distinct NE typed entity. For example, \"John and Bob are . . . \" becomes \"PER@1 and PER@2 are . . . \". At test time, we de-anonymize NE@N tokens in the output by looking them up in their source sentences. Note that the de-anonymization may fail, but the chance is small (around 2% of the time on the Newsela development set). We replaced words occurring three times or less in the training set with UNK. At test time, when our models predict UNK, we adopt the UNK replacement method proposed in Jean et al. (2015).\n\nEvaluation Following previous work (Woodsend and Lapata, 2011;Xu et al., 2016) we evaluated system output automatically adopting metrics widely used in the simplification literature. Specifically, we used BLEU 5 (Papineni et al., 2002) to assess the degree to which generated simplifications differed from gold standard references and the Flesch-Kincaid Grade Level index (FKGL;Kincaid et al. 1975) to measure the readability of the output (lower FKGL 6 implies simpler output). In addition, we used SARI (Xu et al., 2016), which evaluates the quality of the output by comparing it against the source and reference simplifications. 7 BLEU, FKGL, and SARI are all measured at corpus-level. We also evaluated system output by eliciting human judgments via Amazon's Mechanical Turk. Specifically (selfreported) native English speakers were asked to rate simplifications on three dimensions: Fluency (is the output grammatical and well formed?), Adequacy (to what extent is the meaning expressed in the original sentence preserved in the output?) and Simplicity (is the output simpler than the original sentence?). All ratings were obtained using a five point Likert scale.\n\nComparison Systems We compared our model against several systems previously proposed in the literature. These include PBMT-R, a mono- lingual phrase-based machine translation system with a reranking post-processing step 8 (Wubben et al., 2012) and Hybrid, a model which first performs sentence splitting and deletion operations over discourse representation structures and then further simplifies sentences with PBMT-R (Narayan and Gardent, 2014). Hybrid 9 is state of the art on the WikiSmall dataset. Comparisons with SBMT-SARI, a syntax-based translation model trained on PPDB (Ganitkevitch et al., 2013) and tuned with SARI (Xu et al., 2016), are problematic due to the size of PPDB which is considerably larger than any of the datasets used in this work (it contains 106 million sentence pairs with 2 billion words). Nevertheless, we compare 10 against SBMT-SARI, but only models trained on Wikilarge, our largest dataset.\n\n\nResults\n\nSince Newsela contains high quality simplifications created by professional editors, we performed the bulk of our experiments on this dataset. Specifically, we set out to answer two questions: (a) which neural model performs best and (b) how do neural models which are resource lean and do not have access to linguistic annotations fare against more traditional systems. We therefore compared the basic attention-based encoder- 8 We made a good-faith effort to re-implement their system following closely the details in Wubben et al. (2012). 9 We are grateful to Shashi Narayan for running his system on our three datasets. 10 The output of SBMT-SARI is publicly available.   Section 3), and a linear combination of DRESS and the lexical simplification model (DRESS-LS; Section 4). Neural models were further compared against two strong baselines, PBMT-R and Hybrid. Table 3 shows example output of all models on the Newsela dataset. The top block in Table 1 summarizes the results of our automatic evaluation. As can be seen, all neural models obtain higher BLEU, lower FKGL and higher SARI compared to PBMT-R. Hybrid has the lowest FKGL and highest SARI. Compared to EncDecA, DRESS scores lower on FKGL and higher on SARI, which indicates that the model has indeed learned to optimize the reward function which includes SARI. Integrating lexical simplification (DRESS-LS) yields better BLEU, but slightly worse FKGL and SARI.\n\nThe results of our human evaluation are presented in the top block of Table 2. We elicited judgments for 100 randomly sampled test sentences.\n\nAside from comparing system output (PBMT-R, Hybrid, EncDecA, DRESS, and DRESS-LS), we also elicited ratings for the gold standard Reference as an upper bound. We report results for Fluency, Adequacy, and Simplicity individually and in combination (All is the average rating of the three dimensions). As can be seen, DRESS and DRESS-LS outperform PBMT-R and Complex There's just one major hitch: the primary purpose of education is to develop citizens with a wide variety of skills. Reference The purpose of education is to develop a wide range of skills. PBMT-R It's just one major hitch: the purpose of education is to make people with a wide variety of skills. Hybrid one hitch the purpose is to develop citizens. EncDecA\n\nThe key of education is to develop people with a wide variety of skills.\n\n\nDRESS\n\nThere's just one major hitch: the main goal of education is to develop people with lots of skills. DRESS-LS There's just one major hitch: the main goal of education is to develop citizens with lots of skills. Complex \"They were so burdened by the past they couldn't think about the future,\" said Barnet, 62, who was president of Columbia Records, the No.1 record label in the United States, before joining Capitol. Reference Capitol was stuck in the past. It could not think about the future, Barnett said. PBMT-R \"They were so affected by the past they couldn't think about the future,\" said Barnett, 62, was president of Columbia Records, before joining Capitol building. Hybrid 'They were so burdened by the past they couldn't think about the future,\" said Barnett, 62, who was Columbia Records, president of the No.1 record label in the united states, before joining Capitol. EncDecA \"They were so burdened by the past they couldn't think about the future,\" said Barnett, who was president of Columbia Records, the No.1 record labels in the United States. DRESS \"They were so sicker by the past they couldn't think about the future,\" said Barnett, who was president of Columbia Records. DRESS-LS \"They were so burdened by the past they couldn't think about the future,\" said Barnett, who was president of Columbia Records. Hybrid on Fluency, Simplicity, and overall. The fact that neural models (EncDecA, DRESS and DRESS-LS) fare well on Fluency, is perhaps not surprising given the recent success of LSTMs in language modeling and neural machine translation (Zaremba et al., 2014;Jean et al., 2015).\n\nNeural models obtain worse ratings on Adequacy but are closest to the human references on this dimension. DRESS-LS (and DRESS) are significantly better (p < 0.01) on Simplicity than EncDecA, PBMT-R, and Hybrid which indicates that our reinforcement learning based model is effective at creating simpler output. Combined ratings (All) for DRESS-LS are significantly different compared to the other models but not to DRESS and the Reference. Nevertheless, integration of the lexical simplification model boosts performance as ratings increase almost across the board (Simplicity is slightly worse). Returning to our original questions, we find that neural models are more fluent than comparison systems, while performing non-trivial rewrite operations (see the SARI scores in Table 1) which yield simpler output (see the Simplicity column in Table 2). Based on our judgment elicitation study, neural models trained with reinforcement learning perform best, with DRESS-LS having a slight advantage. We further analyzed model performance by computing various statistics on the simplified output. We measured average sentence length and the degree to which DRESS and comparison systems perform rewriting operations. We approximated the latter with Translation Error Rate (TER; Snover et al. 2006), a measure commonly used to automatically evaluate the quality of machine translation output. We used TER to compute the (average) number of edits required to change an original complex sentence to simpler output. We also report the number of edits by type, i.e., the number of insertions, substitutions, deletions, and shifts needed (on average) to convert complex to simple sentences.\n\nAs shown in Table 4, Hybrid obtains the highest TER, followed by our models (DRESS and  DRESS-LS), which indicates that they actively perform rewriting. Perhaps Hybrid is too aggressive when simplifying a sentence, it obtains low Fluency and Adequacy scores in human evaluation (Table 2). There is a strong correlation between sentence length and number of deletion operations (i.e., more deleteions lead to shorter sentences) and PBMT-R performs very few deletions. Overall, reinforcement learning encourages deletion (see DRESS and DRESS-LS), while performing a reasonable amount of additional operations (e.g., substitutions and shifts) compared to EncDecA and PBMT-R.\n\nThe middle blocks in Tables 1 and 2 report results on the WikiSmall dataset. FKGL and SARI follow a similar pattern as on Newsela. BLEU scores for PBMT-R, Hybrid, and EncDecA are much higher compared to DRESS and DRESS-LS. Hybrid obtains best BLEU and SARI scores, while DRESS and DRESS-LS do very well on FKGL. In human evaluation, we elicited judgments on the entire WikiSmall test set (100 sentences). We compared DRESS-LS, with PBMT-R, Hybrid, and gold standard Reference simplifications. As human experiments are time consuming and expensive, we did not include other neural models besides DRESS-LS based on our Newsela study which showed that EncDecA is inferior to variants trained with reinforcement learning and that DRESS-LS is the better performing model (however, we do compare all models in Table 1). DRESS-LS is significantly better on Simplicity than PBMT-R, Hybrid, and the Reference. It performs on par with PBMT-R on Fluency and worse on Adequacy (but still closer to the human Reference than PBMT-R or Hybrid). When combining all ratings (All in Table 2), DRESS-LS is significantly better than PBMT-R, Hybrid, and the Reference.\n\nThe bottom blocks in Tables 1 and 2 report results on Wikilarge. We compared our models with PBMT-R, Hybrid, and SBMT-SARI (Xu et al., 2016). The FKGL follows a similar pattern as in the previous datasets. PBMT-R and our models are best in terms of BLEU while SBMT-SARI outperforms all other systems on SARI. 11 Because there are 8 references for each complex sentence in the test set, BLEU scores are much higher compared to Newsela and WikiSmall. In human evaluation, we again elicited judgments for 100 randomly sampled test sentences. We randomly selected one of the 8 references as the Reference upper bound. On Simplicity, DRESS-LS is significantly better than all comparison systems, except Hybrid. On Adequacy, it is better than Hybrid but significantly worse than other comparison systems. On Fluency, it is on par with PBMT-R 12 but better than Hybrid and SBMT-SARI. On All dimension DRESS-LS significantly outperforms all comparison systems.\n\n\nConclusions\n\nWe developed a reinforcement learning-based text simplification model, which can jointly model simplicity, grammaticality, and semantic fidelity to the input. We also proposed a lexical simplification component that further boosts performance. Overall, we find that reinforcement learning offers a great means to inject prior knowledge to the simplification task achieving good results across three datasets. In the future, we would like to explicitly model sentence splitting and simplify entire documents (rather than individual sentences). Beyond sentence simplification, the reinforcement learning framework presented here is potentially applicable to generation tasks such as sentence compression , generation of programming code (Ling et al., 2016), or poems (Zhang and Lapata, 2014).\n\nTable 2 :\n2Mean ratings elicited by humans on \nNewsela, WikiSmall, and WkiLarge test sets. Rat-\nings significantly different from DRESS-LS are \nmarked with * (p < 0.05) and ** (p < 0.01). Sig-\nnificance tests were performed using a student \nt-test. \n\ndecoder model (EncDecA), with the deep rein-\nforcement learning model (DRESS; \n\nTable 3 :\n3System output for two sentences (Newsela development set). Substitutions are shown in bold.\n\nTable 4 :\n4Output length (average number of tokens), TER scores and number of edits by type (Insertions, Deletions, Substitutions, Shifts) on the Newsela test set. Higher TER means that more rewriting operations are performed.\nOur code and data are publicly available at https:// github.com/XingxingZhang/dress.\nt and c t as input and outputs a real value as the expected reward. The parameters of the regressor are\nWith the default mtevalv13a.pl settings. 6 FKGL implementation at http://goo.gl/OHP7k3.7  We used he implementation of SARI inXu et al. (2016).\nBLEU and SARI scores reported inXu et al. (2016) are 72.36 and 37.91, and measured at sentence-level.12  We used more data to train PBMT-R and maybe that is why PBMT-R performs better thanXu et al. (2016) reported.\nAcknowledgments We would like to thank Li Dong, Jianpeng Cheng, Shashi Narayan and the EMNLP reviewers for their valuable feedback. We are also grateful to Shashi Narayan for supplying us with the output of his system and Wei Xu for her help with this work. The authors acknowledge the support of the European Research Council (award number 681760).\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, Proceedings of ICLR. ICLRSan Diego, CADzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2015. Neural machine translation by jointly learning to align and translate. In Proceedings of ICLR, San Diego, CA.\n\nText simplification for informationseeking applications. Kevin Beata Beigman Klebanov, Daniel Knight, Marcu, Proceedings of ODBASE. ODBASEAgia Napa, CyprusSpringer3290Beata Beigman Klebanov, Kevin Knight, and Daniel Marcu. 2004. Text simplification for information- seeking applications. In Proceedings of ODBASE, volume 3290 of Lecture Notes in Computer Science, pages 735-747, Agia Napa, Cyprus. Springer.\n\nSimplifying text for languageimpaired readers. J Carroll, G Minnen, D Pearce, Y Canning, S Devlin, J Tait, Proceedings of the 9th EACL. the 9th EACLBergen, NorwayJ. Carroll, G. Minnen, D. Pearce, Y. Canning, S. De- vlin, and J Tait. 1999. Simplifying text for language- impaired readers. In Proceedings of the 9th EACL, pages 269-270, Bergen, Norway.\n\nMotivations and methods for text simplification. R Chandrasekar, C Doran, B Srinivas, Proceedings of the 16th COLING. the 16th COLINGCopenhagen, DenmarkR. Chandrasekar, C. Doran, and B. Srinivas. 1996. Mo- tivations and methods for text simplification. In Pro- ceedings of the 16th COLING, pages 1041-1044, Copenhagen, Denmark.\n\nAbstractive sentence summarization with attentive recurrent neural networks. Sumit Chopra, Michael Auli, Alexander M Rush, Proceedings of NAACL: HLT. NAACL: HLTSan Diego, CASumit Chopra, Michael Auli, and Alexander M. Rush. 2016. Abstractive sentence summarization with at- tentive recurrent neural networks. In Proceedings of NAACL: HLT, pages 93-98, San Diego, CA.\n\nLinguistically motivated large-scale nlp with c&c and boxer. James Curran, Stephen Clark, Johan Bos, Proceedings of the 45th ACL Companion Volume Proceedings of the Demo and Poster Sessions. the 45th ACL Companion Volume the Demo and Poster SessionsPrague, Czech RepublicJames Curran, Stephen Clark, and Johan Bos. 2007. Linguistically motivated large-scale nlp with c&c and boxer. In Proceedings of the 45th ACL Com- panion Volume Proceedings of the Demo and Poster Sessions, pages 33-36, Prague, Czech Republic.\n\nSemi-supervised sequence learning. M Andrew, Quoc V Dai, Le, Advances in Neural Information Processing Systems. Andrew M Dai and Quoc V Le. 2015. Semi-supervised sequence learning. In Advances in Neural Informa- tion Processing Systems, pages 3079-3087.\n\nSimplifying Natural Language for Aphasic Readers. Siobhan Devlin, University of SunderlandPh.D. thesisSiobhan Devlin. 1999. Simplifying Natural Language for Aphasic Readers. Ph.D. thesis, University of Sunderland.\n\nAn evaluation of syntactic simplification rules for people with autism. Richard Evans, Constantin Or Asan, Iustin Dornescu, Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR). the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR)Gothenburg, SwedenRichard Evans, Constantin Or asan, and Iustin Dor- nescu. 2014. An evaluation of syntactic simplifica- tion rules for people with autism. In Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR), pages 131-140, Gothenburg, Sweden.\n\nPPDB: The paraphrase database. Juri Ganitkevitch, Benjamin Van Durme, Chris Callison-Burch, Proceedings of NAACL-HLT. NAACL-HLTAtlanta, GAJuri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. 2013. PPDB: The paraphrase database. In Proceedings of NAACL-HLT, pages 758-764, Atlanta, GA.\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 98Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735-1780.\n\nText simplification for reading assistance: A project note. Kentaro Inui, Atsushi Fujita, Tetsuro Takahashi, Proceedings of the 2nd International Workshop on Paraphrasing. the 2nd International Workshop on ParaphrasingSapporo, JapanRyu Iida, and Tomoya IwakuraKentaro Inui, Atsushi Fujita, Tetsuro Takahashi, Ryu Iida, and Tomoya Iwakura. 2003. Text simplifica- tion for reading assistance: A project note. In Pro- ceedings of the 2nd International Workshop on Para- phrasing, pages 9-16, Sapporo, Japan.\n\nMontreal neural machine translation systems for WMT15. S\u00e9bastien Jean, Orhan Firat, Kyunghyun Cho, Roland Memisevic, Yoshua Bengio, Proceedings of the 10th Workshop on Statistical Machine Translation. the 10th Workshop on Statistical Machine TranslationLisbon, PortugalS\u00e9bastien Jean, Orhan Firat, Kyunghyun Cho, Roland Memisevic, and Yoshua Bengio. 2015. Montreal neural machine translation systems for WMT15. In Proceedings of the 10th Workshop on Statistical Ma- chine Translation, pages 134-140, Lisbon, Portugal.\n\nVerb paraphrase based on case frame alignment. Nobuhiro Kaji, Daisuke Kawahara, Sadao Kurohashi, Satoshi Sato, Proceedings of 40th ACL. 40th ACLPhiladelphia, PANobuhiro Kaji, Daisuke Kawahara, Sadao Kurohashi, and Satoshi Sato. 2002. Verb paraphrase based on case frame alignment. In Proceedings of 40th ACL, pages 215-222, Philadelphia, PA.\n\nImproving text simplification language modeling using unsimplified text data. David Kauchak, Proceedings of the 51st ACL. the 51st ACLSofia, BulgariaDavid Kauchak. 2013. Improving text simplification language modeling using unsimplified text data. In Proceedings of the 51st ACL, pages 1537-1546, Sofia, Bulgaria.\n\nDerivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel. Robert P Fishburne Peter Kincaid, Richard L Jr, Brad S Rogers, Chissom, DTIC DocumentTechnical reportJ Peter Kincaid, Robert P Fishburne Jr, Richard L Rogers, and Brad S Chissom. 1975. Derivation of new readability formulas (automated readability in- dex, fog count and flesch reading ease formula) for navy enlisted personnel. Technical report, DTIC Document.\n\nAdam: A method for stochastic optimization. Diederik Kingma, Jimmy Ba, arXiv:1412.6980arXiv preprintDiederik Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980.\n\nDeep reinforcement learning for dialogue generation. Jiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, Jianfeng Gao, Proceedings of the 2016 EMNLP. the 2016 EMNLPAustin, TXJiwei Li, Will Monroe, Alan Ritter, Dan Jurafsky, Michel Galley, and Jianfeng Gao. 2016. Deep re- inforcement learning for dialogue generation. In Proceedings of the 2016 EMNLP, pages 1192-1202, Austin, TX.\n\nLatent predictor networks for code generation. Wang Ling, Phil Blunsom, Edward Grefenstette, Karl Moritz Hermann, Tom\u00e1\u0161 Ko\u010disk\u00fd, Fumin Wang, Andrew Senior, Proceedings of the 54th ACL. the 54th ACLBerlin, GermanyWang Ling, Phil Blunsom, Edward Grefenstette, Karl Moritz Hermann, Tom\u00e1\u0161 Ko\u010disk\u00fd, Fumin Wang, and Andrew Senior. 2016. Latent predictor networks for code generation. In Proceedings of the 54th ACL, pages 599-609, Berlin, Germany.\n\nEffective approaches to attention-based neural machine translation. Thang Luong, Hieu Pham, Christopher D Manning, Proceedings of the 2015 EMNLP. the 2015 EMNLPLisbon, PortugalThang Luong, Hieu Pham, and Christopher D. Man- ning. 2015. Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 EMNLP, pages 1412-1421, Lisbon, Portugal.\n\nThe Stanford CoreNLP natural language processing toolkit. Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J Bethard, David Mc-Closky, ACL System Demonstrations. Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David Mc- Closky. 2014. The Stanford CoreNLP natural lan- guage processing toolkit. In ACL System Demon- strations, pages 55-60.\n\nImproving information extraction by acquiring external evidence with reinforcement learning. Karthik Narasimhan, Adam Yala, Regina Barzilay, Proceedings of the 2016 EMNLP. the 2016 EMNLPAustin, TXKarthik Narasimhan, Adam Yala, and Regina Barzilay. 2016. Improving information extraction by acquir- ing external evidence with reinforcement learning. In Proceedings of the 2016 EMNLP, pages 2355- 2365, Austin, TX.\n\nHybrid simplification using deep semantics and machine translation. Shashi Narayan, Claire Gardent, Proceedings of the 52nd ACL. the 52nd ACLBaltimore, MDShashi Narayan and Claire Gardent. 2014. Hybrid sim- plification using deep semantics and machine trans- lation. In Proceedings of the 52nd ACL, pages 435- 445, Baltimore, MD.\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th ACL. the 40th ACLPhiladelphia, PAKishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic eval- uation of machine translation. In Proceedings of the 40th ACL, pages 311-318, Philadelphia, PA.\n\nRazvan Pascanu, Tomas Mikolov, Yoshua Bengio, On the difficulty of training recurrent neural networks. ICML (3). 28Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. 2013. On the difficulty of training recurrent neural networks. ICML (3), 28:1310-1318.\n\nGlove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Proceedings of the EMNLP 2014. the EMNLP 2014Doha, Qatar14Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In In Proceedings of the EMNLP 2014, volume 14, pages 1532-43, Doha, Qatar.\n\nSequence level training with recurrent neural networks. Marcaurelio Ranzato, Sumit Chopra, Michael Auli, Wojciech Zaremba, Proceedings of ICLR. ICLRSan Juan, Puerto RicoMarcAurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2016. Sequence level train- ing with recurrent neural networks. In Proceedings of ICLR, San Juan, Puerto Rico.\n\nDyswebxia 2.0!: More accessible text for people with dyslexia. Luz Rello, Clara Bayarri, Azuki G\u00f3rriz, Ricardo Baeza-Yates, Saurabh Gupta, Gaurang Kanvinde, Horacio Saggion, Stefan Bott, Roberto Carlini, Vasile Topac, Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility. the 10th International Cross-Disciplinary Conference on Web AccessibilityBrazilLuz Rello, Clara Bayarri, Azuki G\u00f3rriz, Ricardo Baeza-Yates, Saurabh Gupta, Gaurang Kanvinde, Horacio Saggion, Stefan Bott, Roberto Carlini, and Vasile Topac. 2013. Dyswebxia 2.0!: More acces- sible text for people with dyslexia. In Proceedings of the 10th International Cross-Disciplinary Confer- ence on Web Accessibility, pages -, Brazil.\n\nFramework of automatic text summarization using reinforcement learning. Seonggi Ryang, Takeshi Abekawa, Proceedings of the 2012 EMNLP-CoNLL. the 2012 EMNLP-CoNLLJeju Island, KoreaSeonggi Ryang and Takeshi Abekawa. 2012. Frame- work of automatic text summarization using rein- forcement learning. In Proceedings of the 2012 EMNLP-CoNLL, pages 256-265, Jeju Island, Korea.\n\nA survey of automated text simplification. Matthew Shardlow, Special Issue on Natural Language Processing. Matthew Shardlow. 2014. A survey of automated text simplification. International Journal of Advanced Computer Science and Applications, pages 581- 701. Special Issue on Natural Language Processing.\n\nSyntactic simplification and text cohesion. Advaith Siddharthan, Research on Language and Computation. 4Advaith Siddharthan. 2004. Syntactic simplification and text cohesion. in research on language and com- putation. Research on Language and Computation, 4(1):77-109.\n\nA survey of research on text simplification. Advaith Siddharthan, International Journal of Applied Linguistics. 1652Advaith Siddharthan. 2014. A survey of research on text simplification. International Journal of Applied Linguistics, 165(2):259-298.\n\nQuasisynchronous grammars: Alignment by soft projection of syntactic dependencies. A David, Jason Smith, Eisner, Proceedings of the NAACL 206 Workshop on Statistical Machine Translation. the NAACL 206 Workshop on Statistical Machine TranslationNew York CityDavid A Smith and Jason Eisner. 2006. Quasi- synchronous grammars: Alignment by soft projec- tion of syntactic dependencies. In Proceedings of the NAACL 206 Workshop on Statistical Machine Translation, pages 23-30, New York City.\n\nA study of translation edit rate with targeted human annotation. Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, John Makhoul, Proceedings of association for machine translation in the Americas. association for machine translation in the Americas200Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin- nea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of association for machine transla- tion in the Americas, volume 200.\n\nSemeval-2012 task 1: English lexical simplification. Lucia Specia, Rada Sujay Kumar Jauhar, Mihalcea, Proceedings of *SEM 2012. *SEM 2012Montr\u00e9al, CanadaLucia Specia, Sujay Kumar Jauhar, and Rada Mihalcea. 2012. Semeval-2012 task 1: English lexical simpli- fication. In In Proceedings of *SEM 2012, pages 347-355, Montr\u00e9al, Canada.\n\nSequence to sequence learning with neural networks. Ilya Sutskever, Oriol Vinyals, Quoc V Le, Advances in Neural Information Processing Systems. Ilya Sutskever, Oriol Vinyals, and Quoc V Le. 2014. Sequence to sequence learning with neural net- works. In Advances in Neural Information Process- ing Systems, pages 3104-3112.\n\nSentence simplification for semantic role labeling. D Vickrey, D Koller, Proceedings of ACL-08: HLT. ACL-08: HLTColumbus, OHD. Vickrey and D. Koller. 2008. Sentence simplifica- tion for semantic role labeling. In Proceedings of ACL-08: HLT, pages 344-352, Columbus, OH.\n\nVin\u00edcius Rodriguez de Uz\u1ebdda, Renata Pontin de Mattos Fortes, Thiago Alexandre Salgueiro Pardo, and Sandra Maria Alu\u00b4sio. Arnaldo Candido Willian Massami Watanabe, Junior, Proceedings of the 27th ACM International Conference on Design of Communication. the 27th ACM International Conference on Design of CommunicationBloomington, INFacilita: reading assistance for low-literacy readersWillian Massami Watanabe, Arnaldo Candido Junior, Vin\u00edcius Rodriguez de Uz\u1ebdda, Renata Pontin de Mattos Fortes, Thiago Alexandre Salgueiro Pardo, and Sandra Maria Alu\u00b4sio. 2009. Facilita: reading assistance for low-literacy readers. In Proceedings of the 27th ACM International Conference on De- sign of Communication, Bloomington, IN.\n\nSimple statistical gradientfollowing algorithms for connectionist reinforcement learning. J Ronald, Williams, Machine learning. 83-4Ronald J Williams. 1992. Simple statistical gradient- following algorithms for connectionist reinforce- ment learning. Machine learning, 8(3-4):229-256.\n\nLearning to simplify sentences with quasi-synchronous grammar and integer programming. Kristian Woodsend, Mirella Lapata, Proceedings of the 2011 EMNLP. the 2011 EMNLPEdinburgh, ScotlandKristian Woodsend and Mirella Lapata. 2011. Learn- ing to simplify sentences with quasi-synchronous grammar and integer programming. In Proceedings of the 2011 EMNLP, pages 409-420, Edinburgh, Scotland.\n\nText rewriting improves semantic role labeling. Kristian Woodsend, Mirella Lapata, Journal of Artificial Intelligence Research. 51Kristian Woodsend and Mirella Lapata. 2014. Text rewriting improves semantic role labeling. Journal of Artificial Intelligence Research, 51:133-164.\n\nSentence simplification by monolingual machine translation. Sander Wubben, Van Den, Emiel Bosch, Krahmer, Proceedings of the 50th ACL. the 50th ACLJeju Island, KoreaSander Wubben, Antal Van Den Bosch, and Emiel Krahmer. 2012. Sentence simplification by mono- lingual machine translation. In Proceedings of the 50th ACL, pages 1015-1024, Jeju Island, Korea.\n\nShow, attend and tell: Neural image caption generation with visual attention. Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, S Richard, Yoshua Zemel, Bengio, arXiv:1502.0304425arXiv preprintKelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S Zemel, and Yoshua Bengio. 2015a. Show, attend and tell: Neural image caption generation with vi- sual attention. arXiv preprint arXiv:1502.03044, 2(3):5.\n\nProblems in current text simplification research: New data can help. Wei Xu, Chris Callison-Burch, Courtney Napoles, Transactions of the Association for Computational Linguistics. 3Wei Xu, Chris Callison-Burch, and Courtney Napoles. 2015b. Problems in current text simplification re- search: New data can help. Transactions of the As- sociation for Computational Linguistics, 3:283-297.\n\nOptimizing statistical machine translation for text simplification. Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, Chris Callison-Burch, Transactions of the Association for Computational Linguistics. 4Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, and Chris Callison-Burch. 2016. Optimizing statistical machine translation for text simplification. Transactions of the Association for Computational Linguistics, 4:401-415.\n\nA syntaxbased statistical translation model. Kenji Yamada, Kevin Knight, Proceedings of the 39th ACL. the 39th ACLToulouse, FranceKenji Yamada and Kevin Knight. 2001. A syntax- based statistical translation model. In Proceedings of the 39th ACL, pages 523-530, Toulouse, France.\n\nWojciech Zaremba, arXiv:1409.2329Ilya Sutskever, and Oriol Vinyals. 2014. Recurrent neural network regularization. arXiv preprintWojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. 2014. Recurrent neural network regularization. arXiv preprint arXiv:1409.2329.\n\nChinese poetry generation with recurrent neural networks. Xingxing Zhang, Mirella Lapata, Proceedings of the 2014 EMNLP. the 2014 EMNLPDoha, QatarXingxing Zhang and Mirella Lapata. 2014. Chinese poetry generation with recurrent neural networks. In Proceedings of the 2014 EMNLP, pages 670-680, Doha, Qatar.\n\nA monolingual tree-based translation model for sentence simplification. Zhemin Zhu, Delphine Bernhard, Iryna Gurevych, Proceedings of the 23rd COLING. the 23rd COLINGBeijing, ChinaZhemin Zhu, Delphine Bernhard, and Iryna Gurevych. 2010. A monolingual tree-based translation model for sentence simplification. In Proceedings of the 23rd COLING, pages 1353-1361, Beijing, China.\n", "annotations": {"author": "[{\"end\":342,\"start\":178},{\"end\":490,\"start\":343}]", "publisher": "[{\"end\":99,\"start\":58},{\"end\":637,\"start\":596}]", "author_last_name": "[{\"end\":192,\"start\":187},{\"end\":357,\"start\":351}]", "author_first_name": "[{\"end\":186,\"start\":178},{\"end\":350,\"start\":343}]", "author_affiliation": "[{\"end\":341,\"start\":211},{\"end\":489,\"start\":359}]", "title": "[{\"end\":57,\"start\":1},{\"end\":547,\"start\":491}]", "venue": "[{\"end\":576,\"start\":549}]", "abstract": "[{\"end\":1401,\"start\":664}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b31\"},\"end\":1738,\"start\":1719},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":1753,\"start\":1738},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1899,\"start\":1872},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1944,\"start\":1913},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":1999,\"start\":1973},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2025,\"start\":1999},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2126,\"start\":2103},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2224,\"start\":2204},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2256,\"start\":2234},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2290,\"start\":2270},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2547,\"start\":2528},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2755,\"start\":2733},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2781,\"start\":2755},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":2806,\"start\":2781},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2824,\"start\":2806},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2966,\"start\":2952},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2984,\"start\":2966},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3002,\"start\":2984},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3378,\"start\":3361},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3481,\"start\":3457},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3607,\"start\":3581},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3703,\"start\":3679},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3812,\"start\":3792},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4144,\"start\":4118},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4339,\"start\":4318},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4430,\"start\":4410},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4448,\"start\":4432},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4559,\"start\":4532},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4780,\"start\":4757},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":4803,\"start\":4780},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":5395,\"start\":5379},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5677,\"start\":5652},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5727,\"start\":5702},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5766,\"start\":5749},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5840,\"start\":5818},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":5958,\"start\":5940},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":5983,\"start\":5958},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6036,\"start\":6018},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6760,\"start\":6737},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6779,\"start\":6760},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8733,\"start\":8714},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9090,\"start\":9071},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9107,\"start\":9090},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10445,\"start\":10429},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11225,\"start\":11208},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11698,\"start\":11682},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":12025,\"start\":12009},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":14416,\"start\":14400},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14526,\"start\":14503},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":15619,\"start\":15604},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16089,\"start\":16067},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16628,\"start\":16606},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17245,\"start\":17224},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19287,\"start\":19273},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":19358,\"start\":19332},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":19477,\"start\":19461},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":19930,\"start\":19913},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":20340,\"start\":20323},{\"end\":20718,\"start\":20717},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21160,\"start\":21139},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":21374,\"start\":21352},{\"end\":21536,\"start\":21514},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21661,\"start\":21636},{\"end\":22000,\"start\":21999},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22998,\"start\":22980},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":23063,\"start\":23036},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":23079,\"start\":23063},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23236,\"start\":23213},{\"end\":23379,\"start\":23373},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23399,\"start\":23379},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":23523,\"start\":23506},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":24415,\"start\":24394},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24618,\"start\":24591},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24779,\"start\":24752},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":24817,\"start\":24800},{\"end\":25540,\"start\":25539},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":25651,\"start\":25631},{\"end\":25654,\"start\":25653},{\"end\":25737,\"start\":25735},{\"end\":29075,\"start\":29053},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":29093,\"start\":29075},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30386,\"start\":30368},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":32738,\"start\":32721},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":34320,\"start\":34301},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":34355,\"start\":34331},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":35351,\"start\":35335},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":35401,\"start\":35385},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":35557,\"start\":35541}]", "figure": "[{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":34687,\"start\":34357},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":34791,\"start\":34688},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":35019,\"start\":34792}]", "paragraph": "[{\"end\":2291,\"start\":1417},{\"end\":3003,\"start\":2293},{\"end\":3346,\"start\":3005},{\"end\":4651,\"start\":3348},{\"end\":6242,\"start\":4653},{\"end\":7240,\"start\":6275},{\"end\":7757,\"start\":7242},{\"end\":7937,\"start\":7854},{\"end\":8217,\"start\":7991},{\"end\":8345,\"start\":8250},{\"end\":8434,\"start\":8374},{\"end\":8857,\"start\":8487},{\"end\":9764,\"start\":8912},{\"end\":10579,\"start\":9766},{\"end\":10765,\"start\":10590},{\"end\":11108,\"start\":10874},{\"end\":11854,\"start\":11110},{\"end\":12886,\"start\":11856},{\"end\":12937,\"start\":12921},{\"end\":13424,\"start\":12991},{\"end\":13859,\"start\":13472},{\"end\":14390,\"start\":13912},{\"end\":14722,\"start\":14392},{\"end\":14890,\"start\":14787},{\"end\":15077,\"start\":14918},{\"end\":15686,\"start\":15143},{\"end\":16090,\"start\":15755},{\"end\":17068,\"start\":16103},{\"end\":17617,\"start\":17095},{\"end\":18272,\"start\":17619},{\"end\":18368,\"start\":18317},{\"end\":18820,\"start\":18396},{\"end\":19860,\"start\":18870},{\"end\":20777,\"start\":19862},{\"end\":21662,\"start\":20779},{\"end\":22301,\"start\":21664},{\"end\":22999,\"start\":22303},{\"end\":24170,\"start\":23001},{\"end\":25099,\"start\":24172},{\"end\":26538,\"start\":25111},{\"end\":26681,\"start\":26540},{\"end\":27406,\"start\":26683},{\"end\":27480,\"start\":27408},{\"end\":29094,\"start\":27490},{\"end\":30774,\"start\":29096},{\"end\":31447,\"start\":30776},{\"end\":32596,\"start\":31449},{\"end\":33550,\"start\":32598},{\"end\":34356,\"start\":33566}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7853,\"start\":7758},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7990,\"start\":7938},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8249,\"start\":8218},{\"attributes\":{\"id\":\"formula_3\"},\"end\":8373,\"start\":8346},{\"attributes\":{\"id\":\"formula_4\"},\"end\":8486,\"start\":8435},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10873,\"start\":10766},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12920,\"start\":12887},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13471,\"start\":13425},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13911,\"start\":13860},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14786,\"start\":14723},{\"attributes\":{\"id\":\"formula_10\"},\"end\":15142,\"start\":15078},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15754,\"start\":15687},{\"attributes\":{\"id\":\"formula_12\"},\"end\":18316,\"start\":18273},{\"attributes\":{\"id\":\"formula_13\"},\"end\":18395,\"start\":18369},{\"attributes\":{\"id\":\"formula_14\"},\"end\":18848,\"start\":18821}]", "table_ref": "[{\"end\":26069,\"start\":26062},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":26617,\"start\":26610},{\"end\":29877,\"start\":29870},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":29943,\"start\":29936},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":30795,\"start\":30788},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":31062,\"start\":31054},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":31484,\"start\":31470},{\"end\":32260,\"start\":32253},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32521,\"start\":32514}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1415,\"start\":1403},{\"attributes\":{\"n\":\"2\"},\"end\":6273,\"start\":6245},{\"attributes\":{\"n\":\"3\"},\"end\":8910,\"start\":8860},{\"attributes\":{\"n\":\"3.1\"},\"end\":10588,\"start\":10582},{\"end\":12952,\"start\":12940},{\"end\":12971,\"start\":12955},{\"end\":12989,\"start\":12974},{\"attributes\":{\"n\":\"3.2\"},\"end\":14916,\"start\":14893},{\"attributes\":{\"n\":\"3.3\"},\"end\":16101,\"start\":16093},{\"attributes\":{\"n\":\"4\"},\"end\":17093,\"start\":17071},{\"attributes\":{\"n\":\"5\"},\"end\":18868,\"start\":18850},{\"attributes\":{\"n\":\"6\"},\"end\":25109,\"start\":25102},{\"end\":27488,\"start\":27483},{\"attributes\":{\"n\":\"7\"},\"end\":33564,\"start\":33553},{\"end\":34367,\"start\":34358},{\"end\":34698,\"start\":34689},{\"end\":34802,\"start\":34793}]", "table": "[{\"end\":34687,\"start\":34369}]", "figure_caption": "[{\"end\":34791,\"start\":34700},{\"end\":35019,\"start\":34804}]", "figure_ref": "[{\"end\":7313,\"start\":7305},{\"end\":9941,\"start\":9933},{\"end\":13043,\"start\":13035},{\"end\":25797,\"start\":25787}]", "bib_author_first_name": "[{\"end\":35996,\"start\":35989},{\"end\":36016,\"start\":36007},{\"end\":36028,\"start\":36022},{\"end\":36308,\"start\":36303},{\"end\":36339,\"start\":36333},{\"end\":36703,\"start\":36702},{\"end\":36714,\"start\":36713},{\"end\":36724,\"start\":36723},{\"end\":36734,\"start\":36733},{\"end\":36745,\"start\":36744},{\"end\":36755,\"start\":36754},{\"end\":37057,\"start\":37056},{\"end\":37073,\"start\":37072},{\"end\":37082,\"start\":37081},{\"end\":37418,\"start\":37413},{\"end\":37434,\"start\":37427},{\"end\":37450,\"start\":37441},{\"end\":37452,\"start\":37451},{\"end\":37770,\"start\":37765},{\"end\":37786,\"start\":37779},{\"end\":37799,\"start\":37794},{\"end\":38255,\"start\":38254},{\"end\":38270,\"start\":38264},{\"end\":38531,\"start\":38524},{\"end\":38768,\"start\":38761},{\"end\":38786,\"start\":38776},{\"end\":38802,\"start\":38796},{\"end\":39371,\"start\":39367},{\"end\":39394,\"start\":39386},{\"end\":39411,\"start\":39406},{\"end\":39662,\"start\":39658},{\"end\":39681,\"start\":39675},{\"end\":39891,\"start\":39884},{\"end\":39905,\"start\":39898},{\"end\":39921,\"start\":39914},{\"end\":40394,\"start\":40385},{\"end\":40406,\"start\":40401},{\"end\":40423,\"start\":40414},{\"end\":40435,\"start\":40429},{\"end\":40453,\"start\":40447},{\"end\":40904,\"start\":40896},{\"end\":40918,\"start\":40911},{\"end\":40934,\"start\":40929},{\"end\":40953,\"start\":40946},{\"end\":41275,\"start\":41270},{\"end\":41666,\"start\":41648},{\"end\":41689,\"start\":41682},{\"end\":41691,\"start\":41690},{\"end\":41700,\"start\":41696},{\"end\":41702,\"start\":41701},{\"end\":42062,\"start\":42054},{\"end\":42076,\"start\":42071},{\"end\":42281,\"start\":42276},{\"end\":42290,\"start\":42286},{\"end\":42303,\"start\":42299},{\"end\":42315,\"start\":42312},{\"end\":42332,\"start\":42326},{\"end\":42349,\"start\":42341},{\"end\":42669,\"start\":42665},{\"end\":42680,\"start\":42676},{\"end\":42696,\"start\":42690},{\"end\":42715,\"start\":42711},{\"end\":42722,\"start\":42716},{\"end\":42737,\"start\":42732},{\"end\":42752,\"start\":42747},{\"end\":42765,\"start\":42759},{\"end\":43134,\"start\":43129},{\"end\":43146,\"start\":43142},{\"end\":43164,\"start\":43153},{\"end\":43166,\"start\":43165},{\"end\":43504,\"start\":43493},{\"end\":43506,\"start\":43505},{\"end\":43521,\"start\":43516},{\"end\":43536,\"start\":43532},{\"end\":43549,\"start\":43544},{\"end\":43564,\"start\":43558},{\"end\":43566,\"start\":43565},{\"end\":43581,\"start\":43576},{\"end\":43939,\"start\":43932},{\"end\":43956,\"start\":43952},{\"end\":43969,\"start\":43963},{\"end\":44327,\"start\":44321},{\"end\":44343,\"start\":44337},{\"end\":44655,\"start\":44648},{\"end\":44671,\"start\":44666},{\"end\":44684,\"start\":44680},{\"end\":44699,\"start\":44691},{\"end\":44968,\"start\":44962},{\"end\":44983,\"start\":44978},{\"end\":44999,\"start\":44993},{\"end\":45269,\"start\":45262},{\"end\":45289,\"start\":45282},{\"end\":45311,\"start\":45298},{\"end\":45639,\"start\":45628},{\"end\":45654,\"start\":45649},{\"end\":45670,\"start\":45663},{\"end\":45685,\"start\":45677},{\"end\":45990,\"start\":45987},{\"end\":46003,\"start\":45998},{\"end\":46018,\"start\":46013},{\"end\":46034,\"start\":46027},{\"end\":46055,\"start\":46048},{\"end\":46070,\"start\":46063},{\"end\":46088,\"start\":46081},{\"end\":46104,\"start\":46098},{\"end\":46118,\"start\":46111},{\"end\":46134,\"start\":46128},{\"end\":46733,\"start\":46726},{\"end\":46748,\"start\":46741},{\"end\":47076,\"start\":47069},{\"end\":47383,\"start\":47376},{\"end\":47654,\"start\":47647},{\"end\":47937,\"start\":47936},{\"end\":47950,\"start\":47945},{\"end\":48413,\"start\":48406},{\"end\":48428,\"start\":48422},{\"end\":48442,\"start\":48435},{\"end\":48459,\"start\":48453},{\"end\":48475,\"start\":48471},{\"end\":48907,\"start\":48902},{\"end\":48920,\"start\":48916},{\"end\":49238,\"start\":49234},{\"end\":49255,\"start\":49250},{\"end\":49271,\"start\":49265},{\"end\":49560,\"start\":49559},{\"end\":49571,\"start\":49570},{\"end\":49914,\"start\":49899},{\"end\":50589,\"start\":50588},{\"end\":50879,\"start\":50871},{\"end\":50897,\"start\":50890},{\"end\":51230,\"start\":51222},{\"end\":51248,\"start\":51241},{\"end\":51543,\"start\":51538},{\"end\":51896,\"start\":51890},{\"end\":51906,\"start\":51901},{\"end\":51915,\"start\":51911},{\"end\":51932,\"start\":51923},{\"end\":51943,\"start\":51938},{\"end\":51961,\"start\":51955},{\"end\":51978,\"start\":51977},{\"end\":51994,\"start\":51988},{\"end\":52366,\"start\":52363},{\"end\":52376,\"start\":52371},{\"end\":52401,\"start\":52393},{\"end\":52753,\"start\":52750},{\"end\":52766,\"start\":52758},{\"end\":52781,\"start\":52776},{\"end\":52797,\"start\":52791},{\"end\":52809,\"start\":52804},{\"end\":53169,\"start\":53164},{\"end\":53183,\"start\":53178},{\"end\":53407,\"start\":53399},{\"end\":53727,\"start\":53719},{\"end\":53742,\"start\":53735},{\"end\":54047,\"start\":54041},{\"end\":54061,\"start\":54053},{\"end\":54077,\"start\":54072}]", "bib_author_last_name": "[{\"end\":36005,\"start\":35997},{\"end\":36020,\"start\":36017},{\"end\":36035,\"start\":36029},{\"end\":36331,\"start\":36309},{\"end\":36346,\"start\":36340},{\"end\":36353,\"start\":36348},{\"end\":36711,\"start\":36704},{\"end\":36721,\"start\":36715},{\"end\":36731,\"start\":36725},{\"end\":36742,\"start\":36735},{\"end\":36752,\"start\":36746},{\"end\":36760,\"start\":36756},{\"end\":37070,\"start\":37058},{\"end\":37079,\"start\":37074},{\"end\":37091,\"start\":37083},{\"end\":37425,\"start\":37419},{\"end\":37439,\"start\":37435},{\"end\":37457,\"start\":37453},{\"end\":37777,\"start\":37771},{\"end\":37792,\"start\":37787},{\"end\":37803,\"start\":37800},{\"end\":38262,\"start\":38256},{\"end\":38274,\"start\":38271},{\"end\":38278,\"start\":38276},{\"end\":38538,\"start\":38532},{\"end\":38774,\"start\":38769},{\"end\":38794,\"start\":38787},{\"end\":38811,\"start\":38803},{\"end\":39384,\"start\":39372},{\"end\":39404,\"start\":39395},{\"end\":39426,\"start\":39412},{\"end\":39673,\"start\":39663},{\"end\":39693,\"start\":39682},{\"end\":39896,\"start\":39892},{\"end\":39912,\"start\":39906},{\"end\":39931,\"start\":39922},{\"end\":40399,\"start\":40395},{\"end\":40412,\"start\":40407},{\"end\":40427,\"start\":40424},{\"end\":40445,\"start\":40436},{\"end\":40460,\"start\":40454},{\"end\":40909,\"start\":40905},{\"end\":40927,\"start\":40919},{\"end\":40944,\"start\":40935},{\"end\":40958,\"start\":40954},{\"end\":41283,\"start\":41276},{\"end\":41680,\"start\":41667},{\"end\":41694,\"start\":41692},{\"end\":41709,\"start\":41703},{\"end\":41718,\"start\":41711},{\"end\":42069,\"start\":42063},{\"end\":42079,\"start\":42077},{\"end\":42284,\"start\":42282},{\"end\":42297,\"start\":42291},{\"end\":42310,\"start\":42304},{\"end\":42324,\"start\":42316},{\"end\":42339,\"start\":42333},{\"end\":42353,\"start\":42350},{\"end\":42674,\"start\":42670},{\"end\":42688,\"start\":42681},{\"end\":42709,\"start\":42697},{\"end\":42730,\"start\":42723},{\"end\":42745,\"start\":42738},{\"end\":42757,\"start\":42753},{\"end\":42772,\"start\":42766},{\"end\":43140,\"start\":43135},{\"end\":43151,\"start\":43147},{\"end\":43174,\"start\":43167},{\"end\":43514,\"start\":43507},{\"end\":43530,\"start\":43522},{\"end\":43542,\"start\":43537},{\"end\":43556,\"start\":43550},{\"end\":43574,\"start\":43567},{\"end\":43591,\"start\":43582},{\"end\":43950,\"start\":43940},{\"end\":43961,\"start\":43957},{\"end\":43978,\"start\":43970},{\"end\":44335,\"start\":44328},{\"end\":44351,\"start\":44344},{\"end\":44664,\"start\":44656},{\"end\":44678,\"start\":44672},{\"end\":44689,\"start\":44685},{\"end\":44703,\"start\":44700},{\"end\":44976,\"start\":44969},{\"end\":44991,\"start\":44984},{\"end\":45006,\"start\":45000},{\"end\":45280,\"start\":45270},{\"end\":45296,\"start\":45290},{\"end\":45319,\"start\":45312},{\"end\":45647,\"start\":45640},{\"end\":45661,\"start\":45655},{\"end\":45675,\"start\":45671},{\"end\":45693,\"start\":45686},{\"end\":45996,\"start\":45991},{\"end\":46011,\"start\":46004},{\"end\":46025,\"start\":46019},{\"end\":46046,\"start\":46035},{\"end\":46061,\"start\":46056},{\"end\":46079,\"start\":46071},{\"end\":46096,\"start\":46089},{\"end\":46109,\"start\":46105},{\"end\":46126,\"start\":46119},{\"end\":46140,\"start\":46135},{\"end\":46739,\"start\":46734},{\"end\":46756,\"start\":46749},{\"end\":47085,\"start\":47077},{\"end\":47395,\"start\":47384},{\"end\":47666,\"start\":47655},{\"end\":47943,\"start\":47938},{\"end\":47956,\"start\":47951},{\"end\":47964,\"start\":47958},{\"end\":48420,\"start\":48414},{\"end\":48433,\"start\":48429},{\"end\":48451,\"start\":48443},{\"end\":48469,\"start\":48460},{\"end\":48483,\"start\":48476},{\"end\":48914,\"start\":48908},{\"end\":48939,\"start\":48921},{\"end\":48949,\"start\":48941},{\"end\":49248,\"start\":49239},{\"end\":49263,\"start\":49256},{\"end\":49274,\"start\":49272},{\"end\":49568,\"start\":49561},{\"end\":49578,\"start\":49572},{\"end\":49939,\"start\":49915},{\"end\":49947,\"start\":49941},{\"end\":50596,\"start\":50590},{\"end\":50606,\"start\":50598},{\"end\":50888,\"start\":50880},{\"end\":50904,\"start\":50898},{\"end\":51239,\"start\":51231},{\"end\":51255,\"start\":51249},{\"end\":51527,\"start\":51514},{\"end\":51536,\"start\":51529},{\"end\":51549,\"start\":51544},{\"end\":51558,\"start\":51551},{\"end\":51899,\"start\":51897},{\"end\":51909,\"start\":51907},{\"end\":51921,\"start\":51916},{\"end\":51936,\"start\":51933},{\"end\":51953,\"start\":51944},{\"end\":51975,\"start\":51962},{\"end\":51986,\"start\":51979},{\"end\":52000,\"start\":51995},{\"end\":52008,\"start\":52002},{\"end\":52369,\"start\":52367},{\"end\":52391,\"start\":52377},{\"end\":52409,\"start\":52402},{\"end\":52756,\"start\":52754},{\"end\":52774,\"start\":52767},{\"end\":52789,\"start\":52782},{\"end\":52802,\"start\":52798},{\"end\":52824,\"start\":52810},{\"end\":53176,\"start\":53170},{\"end\":53190,\"start\":53184},{\"end\":53415,\"start\":53408},{\"end\":53733,\"start\":53728},{\"end\":53749,\"start\":53743},{\"end\":54051,\"start\":54048},{\"end\":54070,\"start\":54062},{\"end\":54086,\"start\":54078}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":11212020},\"end\":36244,\"start\":35918},{\"attributes\":{\"id\":\"b1\"},\"end\":36653,\"start\":36246},{\"attributes\":{\"id\":\"b2\"},\"end\":37005,\"start\":36655},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2935285},\"end\":37334,\"start\":37007},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":133195},\"end\":37702,\"start\":37336},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":313022},\"end\":38217,\"start\":37704},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":7138078},\"end\":38472,\"start\":38219},{\"attributes\":{\"id\":\"b7\"},\"end\":38687,\"start\":38474},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":6892734},\"end\":39334,\"start\":38689},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6067240},\"end\":39632,\"start\":39336},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1915014},\"end\":39822,\"start\":39634},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":15700645},\"end\":40328,\"start\":39824},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":359451},\"end\":40847,\"start\":40330},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":27521527},\"end\":41190,\"start\":40849},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":9516661},\"end\":41505,\"start\":41192},{\"attributes\":{\"id\":\"b15\"},\"end\":42008,\"start\":41507},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b16\"},\"end\":42221,\"start\":42010},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3147007},\"end\":42616,\"start\":42223},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14434979},\"end\":43059,\"start\":42618},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1998416},\"end\":43433,\"start\":43061},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":14068874},\"end\":43837,\"start\":43435},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":12203802},\"end\":44251,\"start\":43839},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":15489071},\"end\":44582,\"start\":44253},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":11080756},\"end\":44960,\"start\":44584},{\"attributes\":{\"id\":\"b24\"},\"end\":45213,\"start\":44962},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":1957433},\"end\":45570,\"start\":45215},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":7147309},\"end\":45922,\"start\":45572},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":28847064},\"end\":46652,\"start\":45924},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":14666654},\"end\":47024,\"start\":46654},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":6068649},\"end\":47330,\"start\":47026},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":14619244},\"end\":47600,\"start\":47332},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":3894107},\"end\":47851,\"start\":47602},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":741354},\"end\":48339,\"start\":47853},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":8938789},\"end\":48847,\"start\":48341},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":8884060},\"end\":49180,\"start\":48849},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":7961699},\"end\":49505,\"start\":49182},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":2382276},\"end\":49776,\"start\":49507},{\"attributes\":{\"id\":\"b37\"},\"end\":50496,\"start\":49778},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":2332513},\"end\":50782,\"start\":50498},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":9945908},\"end\":51172,\"start\":50784},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":11504485},\"end\":51452,\"start\":51174},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":141120},\"end\":51810,\"start\":51454},{\"attributes\":{\"doi\":\"arXiv:1502.03044\",\"id\":\"b42\"},\"end\":52292,\"start\":51812},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":17817489},\"end\":52680,\"start\":52294},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":2177849},\"end\":53117,\"start\":52682},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":455928},\"end\":53397,\"start\":53119},{\"attributes\":{\"doi\":\"arXiv:1409.2329\",\"id\":\"b46\"},\"end\":53659,\"start\":53399},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":12964363},\"end\":53967,\"start\":53661},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":15636533},\"end\":54345,\"start\":53969}]", "bib_title": "[{\"end\":35987,\"start\":35918},{\"end\":36301,\"start\":36246},{\"end\":36700,\"start\":36655},{\"end\":37054,\"start\":37007},{\"end\":37411,\"start\":37336},{\"end\":37763,\"start\":37704},{\"end\":38252,\"start\":38219},{\"end\":38759,\"start\":38689},{\"end\":39365,\"start\":39336},{\"end\":39656,\"start\":39634},{\"end\":39882,\"start\":39824},{\"end\":40383,\"start\":40330},{\"end\":40894,\"start\":40849},{\"end\":41268,\"start\":41192},{\"end\":42274,\"start\":42223},{\"end\":42663,\"start\":42618},{\"end\":43127,\"start\":43061},{\"end\":43491,\"start\":43435},{\"end\":43930,\"start\":43839},{\"end\":44319,\"start\":44253},{\"end\":44646,\"start\":44584},{\"end\":45260,\"start\":45215},{\"end\":45626,\"start\":45572},{\"end\":45985,\"start\":45924},{\"end\":46724,\"start\":46654},{\"end\":47067,\"start\":47026},{\"end\":47374,\"start\":47332},{\"end\":47645,\"start\":47602},{\"end\":47934,\"start\":47853},{\"end\":48404,\"start\":48341},{\"end\":48900,\"start\":48849},{\"end\":49232,\"start\":49182},{\"end\":49557,\"start\":49507},{\"end\":49897,\"start\":49778},{\"end\":50586,\"start\":50498},{\"end\":50869,\"start\":50784},{\"end\":51220,\"start\":51174},{\"end\":51512,\"start\":51454},{\"end\":52361,\"start\":52294},{\"end\":52748,\"start\":52682},{\"end\":53162,\"start\":53119},{\"end\":53717,\"start\":53661},{\"end\":54039,\"start\":53969}]", "bib_author": "[{\"end\":36007,\"start\":35989},{\"end\":36022,\"start\":36007},{\"end\":36037,\"start\":36022},{\"end\":36333,\"start\":36303},{\"end\":36348,\"start\":36333},{\"end\":36355,\"start\":36348},{\"end\":36713,\"start\":36702},{\"end\":36723,\"start\":36713},{\"end\":36733,\"start\":36723},{\"end\":36744,\"start\":36733},{\"end\":36754,\"start\":36744},{\"end\":36762,\"start\":36754},{\"end\":37072,\"start\":37056},{\"end\":37081,\"start\":37072},{\"end\":37093,\"start\":37081},{\"end\":37427,\"start\":37413},{\"end\":37441,\"start\":37427},{\"end\":37459,\"start\":37441},{\"end\":37779,\"start\":37765},{\"end\":37794,\"start\":37779},{\"end\":37805,\"start\":37794},{\"end\":38264,\"start\":38254},{\"end\":38276,\"start\":38264},{\"end\":38280,\"start\":38276},{\"end\":38540,\"start\":38524},{\"end\":38776,\"start\":38761},{\"end\":38796,\"start\":38776},{\"end\":38813,\"start\":38796},{\"end\":39386,\"start\":39367},{\"end\":39406,\"start\":39386},{\"end\":39428,\"start\":39406},{\"end\":39675,\"start\":39658},{\"end\":39695,\"start\":39675},{\"end\":39898,\"start\":39884},{\"end\":39914,\"start\":39898},{\"end\":39933,\"start\":39914},{\"end\":40401,\"start\":40385},{\"end\":40414,\"start\":40401},{\"end\":40429,\"start\":40414},{\"end\":40447,\"start\":40429},{\"end\":40462,\"start\":40447},{\"end\":40911,\"start\":40896},{\"end\":40929,\"start\":40911},{\"end\":40946,\"start\":40929},{\"end\":40960,\"start\":40946},{\"end\":41285,\"start\":41270},{\"end\":41682,\"start\":41648},{\"end\":41696,\"start\":41682},{\"end\":41711,\"start\":41696},{\"end\":41720,\"start\":41711},{\"end\":42071,\"start\":42054},{\"end\":42081,\"start\":42071},{\"end\":42286,\"start\":42276},{\"end\":42299,\"start\":42286},{\"end\":42312,\"start\":42299},{\"end\":42326,\"start\":42312},{\"end\":42341,\"start\":42326},{\"end\":42355,\"start\":42341},{\"end\":42676,\"start\":42665},{\"end\":42690,\"start\":42676},{\"end\":42711,\"start\":42690},{\"end\":42732,\"start\":42711},{\"end\":42747,\"start\":42732},{\"end\":42759,\"start\":42747},{\"end\":42774,\"start\":42759},{\"end\":43142,\"start\":43129},{\"end\":43153,\"start\":43142},{\"end\":43176,\"start\":43153},{\"end\":43516,\"start\":43493},{\"end\":43532,\"start\":43516},{\"end\":43544,\"start\":43532},{\"end\":43558,\"start\":43544},{\"end\":43576,\"start\":43558},{\"end\":43593,\"start\":43576},{\"end\":43952,\"start\":43932},{\"end\":43963,\"start\":43952},{\"end\":43980,\"start\":43963},{\"end\":44337,\"start\":44321},{\"end\":44353,\"start\":44337},{\"end\":44666,\"start\":44648},{\"end\":44680,\"start\":44666},{\"end\":44691,\"start\":44680},{\"end\":44705,\"start\":44691},{\"end\":44978,\"start\":44962},{\"end\":44993,\"start\":44978},{\"end\":45008,\"start\":44993},{\"end\":45282,\"start\":45262},{\"end\":45298,\"start\":45282},{\"end\":45321,\"start\":45298},{\"end\":45649,\"start\":45628},{\"end\":45663,\"start\":45649},{\"end\":45677,\"start\":45663},{\"end\":45695,\"start\":45677},{\"end\":45998,\"start\":45987},{\"end\":46013,\"start\":45998},{\"end\":46027,\"start\":46013},{\"end\":46048,\"start\":46027},{\"end\":46063,\"start\":46048},{\"end\":46081,\"start\":46063},{\"end\":46098,\"start\":46081},{\"end\":46111,\"start\":46098},{\"end\":46128,\"start\":46111},{\"end\":46142,\"start\":46128},{\"end\":46741,\"start\":46726},{\"end\":46758,\"start\":46741},{\"end\":47087,\"start\":47069},{\"end\":47397,\"start\":47376},{\"end\":47668,\"start\":47647},{\"end\":47945,\"start\":47936},{\"end\":47958,\"start\":47945},{\"end\":47966,\"start\":47958},{\"end\":48422,\"start\":48406},{\"end\":48435,\"start\":48422},{\"end\":48453,\"start\":48435},{\"end\":48471,\"start\":48453},{\"end\":48485,\"start\":48471},{\"end\":48916,\"start\":48902},{\"end\":48941,\"start\":48916},{\"end\":48951,\"start\":48941},{\"end\":49250,\"start\":49234},{\"end\":49265,\"start\":49250},{\"end\":49276,\"start\":49265},{\"end\":49570,\"start\":49559},{\"end\":49580,\"start\":49570},{\"end\":49941,\"start\":49899},{\"end\":49949,\"start\":49941},{\"end\":50598,\"start\":50588},{\"end\":50608,\"start\":50598},{\"end\":50890,\"start\":50871},{\"end\":50906,\"start\":50890},{\"end\":51241,\"start\":51222},{\"end\":51257,\"start\":51241},{\"end\":51529,\"start\":51514},{\"end\":51538,\"start\":51529},{\"end\":51551,\"start\":51538},{\"end\":51560,\"start\":51551},{\"end\":51901,\"start\":51890},{\"end\":51911,\"start\":51901},{\"end\":51923,\"start\":51911},{\"end\":51938,\"start\":51923},{\"end\":51955,\"start\":51938},{\"end\":51977,\"start\":51955},{\"end\":51988,\"start\":51977},{\"end\":52002,\"start\":51988},{\"end\":52010,\"start\":52002},{\"end\":52371,\"start\":52363},{\"end\":52393,\"start\":52371},{\"end\":52411,\"start\":52393},{\"end\":52758,\"start\":52750},{\"end\":52776,\"start\":52758},{\"end\":52791,\"start\":52776},{\"end\":52804,\"start\":52791},{\"end\":52826,\"start\":52804},{\"end\":53178,\"start\":53164},{\"end\":53192,\"start\":53178},{\"end\":53417,\"start\":53399},{\"end\":53735,\"start\":53719},{\"end\":53751,\"start\":53735},{\"end\":54053,\"start\":54041},{\"end\":54072,\"start\":54053},{\"end\":54088,\"start\":54072}]", "bib_venue": "[{\"end\":36056,\"start\":36037},{\"end\":36376,\"start\":36355},{\"end\":36789,\"start\":36762},{\"end\":37123,\"start\":37093},{\"end\":37484,\"start\":37459},{\"end\":37893,\"start\":37805},{\"end\":38329,\"start\":38280},{\"end\":38522,\"start\":38474},{\"end\":38926,\"start\":38813},{\"end\":39452,\"start\":39428},{\"end\":39713,\"start\":39695},{\"end\":39994,\"start\":39933},{\"end\":40529,\"start\":40462},{\"end\":40983,\"start\":40960},{\"end\":41312,\"start\":41285},{\"end\":41646,\"start\":41507},{\"end\":42052,\"start\":42010},{\"end\":42384,\"start\":42355},{\"end\":42801,\"start\":42774},{\"end\":43205,\"start\":43176},{\"end\":43618,\"start\":43593},{\"end\":44009,\"start\":43980},{\"end\":44380,\"start\":44353},{\"end\":44732,\"start\":44705},{\"end\":45073,\"start\":45008},{\"end\":45350,\"start\":45321},{\"end\":45714,\"start\":45695},{\"end\":46230,\"start\":46142},{\"end\":46793,\"start\":46758},{\"end\":47131,\"start\":47087},{\"end\":47433,\"start\":47397},{\"end\":47712,\"start\":47668},{\"end\":48038,\"start\":47966},{\"end\":48551,\"start\":48485},{\"end\":48975,\"start\":48951},{\"end\":49325,\"start\":49276},{\"end\":49606,\"start\":49580},{\"end\":50028,\"start\":49949},{\"end\":50624,\"start\":50608},{\"end\":50935,\"start\":50906},{\"end\":51300,\"start\":51257},{\"end\":51587,\"start\":51560},{\"end\":51888,\"start\":51812},{\"end\":52472,\"start\":52411},{\"end\":52887,\"start\":52826},{\"end\":53219,\"start\":53192},{\"end\":53512,\"start\":53432},{\"end\":53780,\"start\":53751},{\"end\":54118,\"start\":54088},{\"end\":36075,\"start\":36058},{\"end\":36401,\"start\":36378},{\"end\":36817,\"start\":36791},{\"end\":37159,\"start\":37125},{\"end\":37509,\"start\":37486},{\"end\":37975,\"start\":37895},{\"end\":39044,\"start\":38928},{\"end\":39474,\"start\":39454},{\"end\":40056,\"start\":39996},{\"end\":40599,\"start\":40531},{\"end\":41009,\"start\":40985},{\"end\":41341,\"start\":41314},{\"end\":42410,\"start\":42386},{\"end\":42830,\"start\":42803},{\"end\":43237,\"start\":43207},{\"end\":44035,\"start\":44011},{\"end\":44407,\"start\":44382},{\"end\":44762,\"start\":44734},{\"end\":45377,\"start\":45352},{\"end\":45741,\"start\":45716},{\"end\":46311,\"start\":46232},{\"end\":46833,\"start\":46795},{\"end\":48110,\"start\":48040},{\"end\":48604,\"start\":48553},{\"end\":49002,\"start\":48977},{\"end\":49631,\"start\":49608},{\"end\":50109,\"start\":50030},{\"end\":50970,\"start\":50937},{\"end\":51619,\"start\":51589},{\"end\":53249,\"start\":53221},{\"end\":53807,\"start\":53782},{\"end\":54149,\"start\":54120}]"}}}, "year": 2023, "month": 12, "day": 17}