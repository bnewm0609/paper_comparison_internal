{"id": 257279774, "updated": "2023-12-14 03:14:18.469", "metadata": {"title": "UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers", "authors": "[{\"first\":\"Jon\",\"last\":\"Saad-Falcon\",\"middle\":[]},{\"first\":\"Omar\",\"last\":\"Khattab\",\"middle\":[]},{\"first\":\"Keshav\",\"last\":\"Santhanam\",\"middle\":[]},{\"first\":\"Radu\",\"last\":\"Florian\",\"middle\":[]},{\"first\":\"Martin\",\"last\":\"Franz\",\"middle\":[]},{\"first\":\"Salim\",\"last\":\"Roukos\",\"middle\":[]},{\"first\":\"Avirup\",\"last\":\"Sil\",\"middle\":[]},{\"first\":\"Md\",\"last\":\"Sultan\",\"middle\":[\"Arafat\"]},{\"first\":\"Christopher\",\"last\":\"Potts\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Many information retrieval tasks require large labeled datasets for fine-tuning. However, such datasets are often unavailable, and their utility for real-world applications can diminish quickly due to domain shifts. To address this challenge, we develop and motivate a method for using large language models (LLMs) to generate large numbers of synthetic queries cheaply. The method begins by generating a small number of synthetic queries using an expensive LLM. After that, a much less expensive one is used to create large numbers of synthetic queries, which are used to fine-tune a family of reranker models. These rerankers are then distilled into a single efficient retriever for use in the target domain. We show that this technique boosts zero-shot accuracy in long-tail domains and achieves substantially lower latency than standard reranking methods.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/Saad-FalconKSFF23", "doi": "10.18653/v1/2023.emnlp-main.693"}}, "content": {"source": {"pdf_hash": "44b0d2e884efa5344e50424dbe2edf616981f201", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.00807v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "5d57aba7213967189ff1de7fc7f51dc70633ac89", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/44b0d2e884efa5344e50424dbe2edf616981f201.txt", "contents": "\nUDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers\n\n\nJon Saad-Falcon \nStanford University\n\n\nOmar Khattab \nStanford University\n\n\nKeshav Santhanam \nStanford University\n\n\nRadu Florian \nIBM Research AI\n\n\nMartin Franz \nIBM Research AI\n\n\nSalim Roukos \nIBM Research AI\n\n\nAvirup Sil \nIBM Research AI\n\n\nMd Arafat Sultan \nIBM Research AI\n\n\nChristopher Potts \nStanford University\n\n\nUDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers\nEF7330D1E6499DE86D9227F9C0C3B877\nMany information retrieval tasks require large labeled datasets for fine-tuning.However, such datasets are often unavailable, and their utility for real-world applications can diminish quickly due to domain shifts.To address this challenge, we develop and motivate a method for using large language models (LLMs) to generate large numbers of synthetic queries cheaply.The method begins by generating a small number of synthetic queries using an expensive LLM.After that, a much less expensive one is used to create large numbers of synthetic queries, which are used to fine-tune a family of reranker models.These rerankers are then distilled into a single efficient retriever for use in the target domain.We show that this technique boosts zero-shot accuracy in long-tail domains and achieves substantially lower latency than standard reranking methods.\n\nIntroduction\n\nThe advent of neural information retrieval (IR) has led to notable performance improvements on document and passage retrieval tasks (Nogueira and Cho, 2019;Khattab and Zaharia, 2020;Formal et al., 2021) as well as downstream knowledgeintensive NLP tasks such as open-domain questionanswering and fact verification (Guu et al., 2020;Lewis et al., 2020;Khattab et al., 2021;Izacard et al., 2022).Neural retrievers for these tasks often benefit from fine-tuning on large labeled datasets such as SQuAD (Rajpurkar et al., 2018), Natural Questions (NQ) (Kwiatkowski et al., 2019), and KILT (Petroni et al., 2021).However, IR models can experience significant drops in accuracy due to distribution shifts from the training to the target domain (Thakur et al., 2021;Santhanam et al., 2022b).For example, dense retrieval models trained on MS MARCO (Nguyen et al., 2016) might not generalize well to queries about COVID-19 scientific publications (Voorhees et al., 2021;Wang et al., Figure 1: Overview of UDAPDR.An expensive LLM like GPT-3 is used to create an initial set of synthetic queries.These are incorporated into a set of prompts for a less expensive LLM that can generate large numbers of synthetic queries cheaply.The queries stemming from each prompt are used to train separate rerankers, and these are distilled into a single ColBERTv2 retriever for use in the target domain.2020), considering for instance that MS MARCO predates COVID-19 and thus lacks related topics.\n\nRecent work has sought to adapt IR models to new domains by using large language models (LLMs) to create synthetic target-domain datasets for fine-tuning retrievers (Bonifacio et al., 2022;Meng et al., 2022;Dua et al., 2022).For example, using synthetic queries, Thakur et al. (2021) and Dai et al. (2022) fine-tune the retriever itself and train a cross-encoder to serve as a passage reranker for improving retrieval accuracy.This significantly improves retriever performance in novel domains, but it comes at a high computational cost stemming from extensive use of LLMs.This has limited the applicability of these methods for researchers and practitioners, particularly in high-demand, user-facing settings.\n\nIn this paper, we develop Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers (UDAPDR), 1 an efficient strategy for using LLMs to facilitate unsupervised domain adaptation of neural retriever models.We show that UDAPDR leads to large gains in zero-shot settings on a diverse range of domains.\n\nThe approach is outlined in Figure 1.We begin with a collection of passages from a target domain (no in-domain queries or labels are required) as well as a prompting strategy incorporating these passages with the goal of query generation.A powerful (and perhaps expensive) language model like GPT-3 is used to create a modest number of synthetic queries.These queries form the basis for corpus-adapted prompts that provide examples of passages with good and bad queries, with the goal of generating good queries for new target domain passages.These prompts are fed to a smaller (and presumably less expensive) LM that can generate a very large number of queries for fine-tuning neural rerankers.We train a separate reranker on the queries from each of these corpus-adapted prompts, and these rerankers are distilled into a single student ColBERTv2 retriever (Khattab and Zaharia, 2020;Santhanam et al., 2022b,a), which is evaluated on the target domain.\n\nBy distilling from multiple passage rerankers instead of a single one, we improve the utility of ColBERTv2, preserving more retrieval accuracy gains while reducing latency at inference.Our core contributions are as follows:\n\n\u2022 We propose UDAPDR, a novel unsupervised domain adaptation method for neural IR that strategically leverages expensive LLMs like GPT-3 (Brown et al., 2020) and less expensive ones like Flan-T5 XXL (Chung et al., 2022), as well as multiple passage rerankers.Our approach improves retrieval accuracy in zeroshot settings for LoTTE (Santhanam et al., 2022b), SQuAD, and NQ.\n\n\u2022 We preserve the accuracy gains of these rerankers while maintaining the competitive latency of ColBERTv2.This leads to substantial reductions in query latency.\n\n\u2022 Unlike a number of previous domain adaptation approaches that utilize millions of synthetic queries, our technique only requires 1 pronounced: Yoo-Dap-ter 1000s of synthetic queries to prove effective and is compatible with various LLMs designed for handling instruction-based tasks like creating synthetic queries (e.g., GPT-3, T5, Flan-T5).\n\n\u2022 We generate synthetic queries using multiple prompting strategies that leverage GPT-3 and Flan-T5 XXL.This bolsters the effectiveness of our unsupervised domain adaptation approach.The broader set of synthetic queries allows us to fine-tune multiple passage rerankers and distill them more effectively.\n\n2 Related Work\n\n\nData Augmentation for Neural IR\n\nLLMs have been used to generate synthetic datasets (He et al., 2022;Yang et al., 2020;Anaby-Tavor et al., 2020;Kumar et al., 2020), which have been shown to support effective domain adaptation in Transformer-based architectures (Vaswani et al., 2017) across various tasks.LLMs have also been used to improve IR accuracy in new domains via the creation of synthetic datasets for retriever finetuning (Bonifacio et al., 2022;Meng et al., 2022).Domain shift is the most pressing challenge for domain transfer.Dua et al. (2022) categorize different types of domain shifts, such as changes in query or document distributions, and provide intervention strategies for addressing each type of shift using synthetic data and indexing strategies.\n\nQuery generation can help retrieval models trained on general domain tasks adapt to more targeted domains through the use of generated querypassage pairs (Ma et al., 2020;Nogueira et al., 2019).Wang et al. (2022) also use generative models to pseudo-label synthetic queries, using the generated data to adapt dense retrieval models to domain-specific datasets like BEIR (Thakur et al., 2021).Thakur et al. (2021) and Dai et al. (2022) generate millions of synthetic examples for fine-tuning dense retrieval models, allowing for zero-shot and few-shot domain adaptation.\n\nSynthetic queries can also be used to train passage rerankers that assist neural retrievers.Crossencoders trained with synthetic queries boost retrieval accuracy substantially while proving more robust to domain shifts (Thakur et al., 2020(Thakur et al., , 2021;;Humeau et al., 2019).Dai et al. (2022) explore training the few-shot reranker Promptagator++, leveraging an unsupervised domain-adaptation approach that utilizes millions of synthetically gener-ated queries to train a passage reranker alongside a dense retrieval model.Additionally, Wang et al. (2022) found using zero-shot cross-encoders for reranking could further improve quality.\n\nHowever, due to the high computational cost of rerankers at inference, both Dai et al. (2022) and Wang et al. (2022) found it unlikely these approaches would be deployed in user-facing settings for information retrieval.Our work seeks to bolster the utility of passage rerankers in information retrieval systems.Overall, Dai et al. (2022) and Wang et al. (2022) demonstrated the efficacy of unsupervised domain adaptation approaches utilizing synthesized queries for fine-tuning dense retrievers or passage rerankers.By using distillation strategies, we can avoid their high computational cost while preserving the latent knowledge gained through unsupervised domain adaptation approaches.\n\n\nPretraining Objectives for IR\n\nPretraining objectives can help neural IR systems adapt to new domains without annotations.Masked Language Modeling (MLM) (Devlin et al., 2019) and Inverse Cloze Task (ICT) (Lee et al., 2019) offer unsupervised approaches for helping retrieval models adapt to new domains.Beyond MLM and ICT, Chang et al. (2020) proposed two unsupervised pretraining tasks, Body First Selection (BFS) and Wiki Link Prediction (WLP), which use sampled in-domain sentences and passages to warm-up a neural retriever to new domains.Additionally, Gysel et al. (2018) developed the Neural Vector Space Model (NVSM), an unsupervised pretraining task for news article retrieval that utilizes learned low-dimensional representations of documents and words.Izacard et al. (2021) also explore a contrastive learning objective for unsupervised training of dense retrievers, improving retrieval accuracy in new domains across different languages.\n\nThese pretraining objectives can be paired with additional domain adaptation strategies.Wang et al. (2022) coupled ICT with synthetic query data to achieve domain adaptation in dense retrieval models without the need for annotations.Dai et al. (2022) also paired the contrastive learning objective in Izacard et al. (2021) with their unsupervised Promptagator strategy.While our zero-shot domain adaptation approach can pair with other techniques, it does not require any further pretrainingfor bolstered retrieval performance; our approach only needs the language model pretraining of the re-triever's base model (Devlin et al., 2019), and we show that it combines effectively with multi-vector retrievers (Khattab and Zaharia, 2020;Santhanam et al., 2022b).\n\n\nMethodology\n\nFigure 1 outlines each stage of the UDAPDR strategy.For the target domain T , our approach requires access to in-domain passages (i.e., within the domain of T ).However, it does not require any in-domain queries or labels.The overall goal is to leverage our store of in-domain passages and LLM prompting to inexpensively generate large numbers of synthetic queries for passages.These synthetic queries are used to train domain-specific reranking models that serve as teachers for a single retriever.The specific stages of this process are as follows:\n\nStage 1: We begin with a set of prompts that embed examples of passages paired with good and bad queries and that seek to have the model generate a novel good query for a new passage.We sample X in-domain passages from the target domain T , and we use the prompts to generate 5X synthetic queries.In our experiments, we test values of X such as 5, 10, 50, and 100.(In Appendix A, we explore different strategies for selecting the X in-domain passages from the target domain.)\n\nIn this stage, we use GPT-3 (Brown et al., 2020), specifically the text-davinci-002 model.The guiding idea is to use a very effective LLM for the first stage, to seed the process with very high quality queries.We employ the five prompting strategies in Figure 2. Two of our prompts are from Bonifacio et al. 2022, where they proved successful for generating synthetic queries in a few-shot setting.The remaining three use a zero-shot strategy and were inspired by prompts in Asai et al. 2022.\n\nStage 2: The queries generated in Stage 1 form the basis for prompts in which passages from the target domain T are paired with good and bad synthetic queries.The prompt seeks to lead the model to generate a good query for a new passage.Our prompt template for this stage is given in Figure 3.We create Y corpus-adapted prompts in this fashion, which vary according to the demonstrations they include.In our experiments, we test out several values for Y , specifically, 1, 5, and 10.This programmatic creation of few-shot demonstrations for language models is inspired by the Demonstrate stage of the DSP framework (Khattab et al., 2022).The gold passage for each synthetic query is the passage it was generated from.We have the option of letting Z be large because using Flan-T5 XXL is considerably less expensive than using GPT-3 as we did in Stage 1.In our experiments, we test 1K, 10K, 100K, and 1M as values for Z.We primarily focus on Z = 10K and 100K in Section 4.3.\n\nWe use multiple corpus-adapted prompts to mitigate edge cases in which we create a low-quality prompt based on the chosen synthetic queries and in-domain passages from the target domain T .(See Stage 4 below for a description of how low-quality prompts can optionally be detected and removed.)\n\nAs a quality filter for selecting synthetic queries, we test whether a synthetic query can return its gold passage within the top 20 retrieved results using a zero-shot ColBERTv2 retriever.We only use synthetic queries that pass this filter, which has been shown to improve domain adaptation in neural IR (Dai et al., 2022;Jeronymo et al., 2023).\n\nStage 4: With each set of synthetic queries generated using the Y corpus-adapted prompts in Stage 3, we train an individual passage reranker from scratch for the target domain T .These will be used as teachers for a single ColBERTv2 model in Stage 5. Our multi-reranker strategy draws inspiration from Hofst\u00e4tter et al. (2021), who found a teacher ensemble effective for knowledge distillation into retrievers.At this stage, we can simply use all Y of these rerankers for the distillation process.As an alternative, we can select the N best rerankers based on their accuracy on the validation set of the target domain.For our main experiments, we use all of these rerankers.This is the most general case, in which we do not assume that a validation set exists for the target domain.(In Appendix A, we evaluate settings where a subset of them is used.)\n\nStage 5: The domain-specific passage rerankers from Stage 4 serve as multi-teachers creating a single ColBERTv2 retriever in a multi-teacher distillation process.For distillation, we use annotated triples that are created by using the trained domainspecific reranker to label additional synthetic questions.Overall, our distillation process allows us to improve the retrieval accuracy of ColBERTv2 without needing to use the rerankers at inference.\n\nStage 6: We test our domain-adapted Col-BERTv2 retriever on the evaluation set for the target domain T .This corresponds to deployment of the retriever within the target domain.\n\n\nExperiments\n\n\nModels\n\nWe leverage the Demonstrate-Search-Predict (DSP) (Khattab et al., 2022) codebase for running our experiments.The DSP architecture allows us to build a modular system with both retrieval models and LLMs.For our passage rerankers, we selected DeBERTaV3-Large (He et al., 2021) as the crossencoder after performing comparison experiments with RoBERTa-Large (Liu et al., 2019), BERT (Devlin et al., 2019), and MiniLMv2 (Wang et al., 2021).For our IR system, we use the ColBERTv2 retriever since it remains competitive for both accuracy and query latency across various domains and platforms (Santhanam et al., 2022c).\n\n\nDatasets\n\nFor our experiments, we use LoTTE (Santhanam et al., 2022b), BEIR (Thakur et al., 2021), NQ (Kwiatkowski et al., 2019), and SQuAD (Rajpurkar et al., 2016).This allows us to cover both long-tail IR (LoTTE, BEIR) and general-knowledge question answering (NQ, SQuAD).\n\nWe note that NQ and SQuAD were both part of Flan-T5's pretraining datasets (Chung et al., 2022).Wikipedia passages used in NQ and SQuAD were also part of DeBERTaV3 and GPT-3's pretraining datasets (He et al., 2021;Brown et al., 2020).Similarly, the raw StackExchange answers and questions (i.e., from which LoTTE-Forum is derived) may overlap in part with the training data of GPT-3.The overlap between pretraining and evaluation datasets may impact the efficacy of domain adaptation on NQ and SQuAD, leading to increased accuracy not caused by our approach.\n\n\nMulti-Reranker Domain Adaptation\n\nTable 1 provides our main results for UDAPDR accuracy.For these experiments, we set a total budget of 100K synthetic queries and distribute these equally across the chosen number of rerankers to be used as teachers in the distillation process.When exploring UDAPDR system designs, we report dev results, and we report core test results for LoTTE and BEIR in Section 4.7.\n\nWe compare UDAPDR to two baselines.In the leftmost column of Table 1, we have a Zero-shot ColBERTv2 retriever (no distillation).This model has been shown to be extremely effective in our benchmark domains, and it is very low latency, so it serves as an ambitious baseline.In the rightmost column, we have a Zero-shot ColBERTv2 retriever paired with a single non-distilled passage reranker, trained on 100K synthetic queries.We expect this model to be extremely competitive in terms of accuracy, but also very high latency.\n\nAll versions of UDAPDR are far superior to Zero-shot ColBERTv2 across all the domains we evaluated.In addition, two settings of our model are competitive with or superior to Zero-shot Col-BERTv2 plus a Reranker: distilling into Col-BERTv2 the scores from 5 rerankers, each trained on 20k synthetic queries, as well as 10 rerankers, each trained on 10k synthetic queries.\n\n\nQuery Latency\n\nThe accuracy results in Table 1 show that UDAPDR is highly effective.In addition to this, Table 2 reports a set of latency evaluations using the LoTTe Lifestyle section.Our latency costs refer to the complete retrieval process for a single query, from query encoding to the last stage of passage retrieval.\n\nZero-shot ColBERTv2 is known to have low retrieval latency (Santhanam et al., 2022a).However, its accuracy (repeated from Table 1), which is at a state-of-the-art level (Santhanam et al., 2022c) (Paszke et al., 2019).Query latencies rounded to three significant digits.\n\nZero-shot ColBERTv2 + Reranker models come close, but only with significantly higher latency.\n\n\nImpact of Pretrained Components\n\nUDAPDR involves three pretrained components: GPT-3 to generate our initial set of synthetic queries, Flan-T5 XXL to generate our second, larger set of synthetic queries, and DeBERTaV3-Large for the passage rerankers.What is the impact of these specific components on system behavior?To begin to address this question, we explored a range of variants.These results are summarized in Table 4.Our primary setting for UDAPDR performs the best, but it is noteworthy that very competitive performance can be obtained with no use of GPT-3 at all.Additionally, we tried using Flan-T5 XL instead of Flan-T5 XXL for the second stage of synthetic query generation, since it is more than 90% smaller than Flan-T5 XXL in terms of model parameters.This still leads to better performance than Zero-shot ColBERTv2.\n\nWe also explored using a smaller cross-encoder for UDAPDR.We tested using DeBERTaV3-Base instead of DeBERTaV3-Large for our passage reranker, decreasing the number of model parameters by over 70%.We found that DeBERTaV3-Base was still effective, though it results in a 4.1 point drop in Success@5 compared to DeBERTaV3-Large for LoTTE Pooled (Table 3).(In our initial explorations, we also tested using BERT-Base or RoBERTa-Large as the cross-encoder but found them less effective than DeBERTaV3, leading to 6-8 point drops in Success@5.)\n\n\nDifferent Prompting Strategies\n\nWe tested whether a simpler few-shot prompting strategy might be better than our corpus-adapted prompting approach for domain adaptation.In Table 4, we compare the InPars (Bonifacio et al., 2022) few-shot prompt to our corpus-adapted prompt approach for synthetic query generation and passage reranker distillation.We evaluate these using query generation with both Flan XXL and GPT-3.We find that our multi-reranker, corpus- Table 3: Model Configurations for Synthetic Query Generation and Passage Reranker.We describe the first and second query generators for UDAPDR in Section 3. The Success@5 scores are for the LoTTE Pooled dev task.\n\nA single non-distilled reranker is trained on 100K synthetic queries for each configuration.We do not explore a configuration with exclusively GPT-3 generated queries due to GPT-3 API costs.Table 4: Model Configurations for Prompting Strategies.We specify the prompting strategy, query generators, and reranker counts for each configuration.The Success@5 scores are for the LoTTE Pooled dev task.100,000 synthetic queries total are used for each approach except for the top row, which uses 5,000 synthetic queries due to the costs of the GPT-3 API.The synthetic queries are split evenly amongst the total rerankers used.The rerankers are distilled with a ColBERTv2 retriever for configuration.\n\nadapted prompting strategy is more successful, leading to a 3.5 point increase in Success@5 after ColBERTv2 distillation while using the same number of synthetic queries for training.\n\n\nLoTTE and BEIR Test Results\n\nIn Table 5 and Table 6, we include the test set results for LoTTE and BEIR, respectively.For LoTTE, UDAPDR increases ColBERTv2 zero-shot Success@5 for both Forum queries and Search queries, leading to a 7.1 point and a 3.9 point average improvement, respectively.For BEIR, we calculated ColBERTv2 accuracy using nDCG@10.We found that UDAPDR increases zero-shot accuracy by 5.2 points on average.Promptagator++ Few-shot offers similar improvements to zero-shot accuracy, achieving a 4.2 point increase compared to a zero-shot ColBERTv2 baseline.However, Promptagator++ Few-shot also uses a reranker during retrieval, leading to additional computational costs at inference time.By comparison, UDAPDR is a zero-shot method (i.e., that does not assume access to gold labels from the target domain) and only uses the ColBERTv2 retriever and thus has a lower query latency at inference time.\n\n\nAdditional Results\n\nTable 1 and Table 2 explore only a limited range of potential uses for UDAPDR.In Appendix A, we consider a wider range of uses.First, we ask whether it is productive to filter the set of rerankers based on in-domain dev set performance.We mostly find that this does not lead to gains over simply using all of them, and it introduces the requirement that we have a labeled dev set.Second, we evaluate whether substantially increasing the value of Z from 100K leads to improvements.We find that it does not, and indeed that substantally larger values of Z can hurt performance.\n\n\nDiscussion & Future Work\n\nOur experiments with UDAPDR suggest several directions for future work:\n\n\u2022 While we show that our domain adaptation strategy is effective for the multi-vector Col-BERTv2 model, whether it is also effective for other retrieval models is an open question for future research.\n\n\u2022 For our base model in ColBERTv2, we use BERT-Base.However, ColBERTv2 now allows for other base models, such as DeBER-TaV3, ELECTRA (Clark et al., 2020), and Table 6: nDCG@10 for BEIR Test Set Results.For each dataset, the highest-accuracy zero-shot result is marked in bold while the highest overall is underlined.For UDAPDR, we use 5 rerankers and 20K distinct synthetic queries for training each of them.The Promptagator and GPL results are taken directly from their respective papers.For Promptagator, we include both the best retriever-only configuration (Promptagator Few-shot) and the best retriever + reranker configuration (Promptagator++ Few-shot).We include the GPL+TSDAE pretraining strategy, which is found to improve retrieval accuracy (Wang et al., 2022).We copy the results for BM25, GenQ, ANCE, TAS-B, and RoBERTa (Liu et al., 2019).We would be interested to see the efficacy of our domain adaptation strategy with these larger encoders.\n\n\u2022 We explored distillation strategies for combining passage rerankers with ColBERTv2.However, testing distillation strategies for shrinking the reranker itself could be a viable direction for future work.\n\n\u2022 We draw upon several recent publications, including Bonifacio et al. (2022) and Asai et al. (2022), to create the prompts used for GPT-3 and Flan-T5 XXL in our domain adaptation strategy.Creating a more systematic approach for generating the initial prompts would be an important item for future work.\n\n\nConclusion\n\nWe present UDAPDR, a novel strategy for adapting retrieval models to new domains.UDAPDR uses synthetic queries created using generative models, such as GPT-3 and Flan-T5 XXL, to train multiple passage rerankers on queries for target domain passages.These passage rerankers are then distilled into ColBERTv2 to boost retrieval accuracy while keeping query latency competitive as compared to other retrieval systems.We validate our approach across the LoTTE, BEIR, NQ, and SQuAD datasets.Additionally, we explore various model configurations that alter the generative models, prompting strategies, retriever, and passage rerankers used in our approach.We find that UDAPDR can boost zero-shot retrieval accuracy on new domains without the use of labeled training examples.We also discuss several directions for future work.\n\nWhile our domain adaptation technique does not require questions or labels from the target domain, it does require a significant number of passages in the target domain.These passages are required for use in synthetic query generation with the help of LLMs like GPT-3 and Flan-T5, so future work should evaluate how effective these methods are on extremely small passage collections.\n\nThe synthetic queries created in our approach may also inherit biases from the LLMs and their training data.Moreover, the exact training data of the LLMs is not precisely known.Our understanding is that subsets of SQuAD and NQ, in particular, have been used in the pretraining of Flan-T5 models as we note in the main text.More generally, other subtle forms of data contamination are possible as with all research based on LLMs that have been trained on billions of tokens from the Web.We have mitigated this concern by evaluating on a very large range of datasets and relying most heavily on open models (i.e., Flan-T5, DeBERTa, and ColBERT).Notably, our approach achieves consistently large gains across the vast majority of the many evaluation datasets tested (e.g., the individual sets within BEIR), reinforcing our trust in the validity and transferability of our findings.\n\nAdditionally, the LLMs used in our technique benefit substantially from GPU-based hardware with abundant and rapid storage.These technologies are not available to all NLP practitioners and researchers due to their costs.Lastly, all of our selected information retrieval tasks are in English, a high-resource language.Future work can expand on the applicability of our domain adaptation techniques by using non-English passages in lowresource settings, helping us better understand the approach's strengths and limitations.\n\nFigure 2 :\n2\nFigure 2: The five prompts used in Stage 1 (Section 3).The few-shot prompts #1 and #2 were inspired by Bonifacio et al. (2022) while the zero-shot prompts #3, #4, and #5 were inspired byAsai et al. (2022).In our experiments, we prompt GPT-3 in this stage to generate an initial set of queries.\n\n\nFigure 3 :\n3\nFigure 3: The prompt template used in Stage 2. (Section 3).In our experiments, we create Y variants of this prompt, and each one is used with Flan-T5 XXL to generate Z queries for each Y .\n\n\nStage 3 :\n3\nEach of the corpus-adapted prompts from Stage 2 is used to generate a unique set of Z queries with Flan-T5 XXL (Chung et al., 2022).\n\n\n\n\nColBERT from Thakur et al. (2021), for MoDIR and DPR-M from Xin et al. (2022), for SPLADEv2 from Formal et al. (2021), and for BM25 Reranking of Cohere large and OpenAI ada2 from Kamalloo et al. (2023).\n\n\nTable 1 :\n1\n, trails by large margins the methods we propose in this work.UDAPDR (line 2) has similar latency but also achieves the best accuracy results.The Success@5 for Multi-Reranker Domain Adaptation Strategies with Different Synthetic Query Counts.LoTTE results are for the Forum configuration.All results are for dev sets.The reranker used is DeBERTa-v3-Large.The ColBERTv2 distillation strategies train Y rerankers each with Z synthetic queries before distilling each reranker with the same ColBERTv2 model.No selection process for rerankers is needed nor access to annotated in-domain dev sets (cf.Table7in our Appendices).The non-distilled reranker in the final column is trained on 100K synthetic queries created using Flan-T5 XXL model and the prompting strategy outlined in Section 3.\nColBERTv2 Distillation with UDAPDRZero-shot ColBERTv2Y = 1 reranker, Z = 100k queriesY = 5 rerankers, Z = 20k queriesY = 10 rerankers, Z = 10k queriesZero-shot ColBERTv2 + RerankerLoTTE Lifestyle64.573.074.874.473.5LoTTE Techology44.550.251.351.150.6LoTTE Writing80.084.385.786.285.5LoTTE Recreation70.876.980.479.879.1LoTTE Science61.565.667.968.067.2LoTTE Pooled63.770.072.172.271.1NaturalQuestions68.972.473.774.073.9SQuAD65.071.873.873.672.6Retriever and RerankerPassages RerankedQuery LatencySuccess@5Zero-shot ColBERTv2N/A35 ms64.5ColBERTv2 Distillation: Y = 5 rerankers, Z = 20k queriesN/A35 ms74.8Zero-shot ColBERTv2 + Reranker20412 ms73.3Zero-shot ColBERTv2 + Reranker1002060 ms73.5Zero-shot ColBERTv2 + Reranker100020600 ms73.5\n\nTable 2 :\n2\nAverage Single Query Latency for Retrieval + Reranker Systems.Latencies and Success@5 are for LoTTE Lifestyle.The ColBERTv2 distillation strategies train Y rerankers each with Z synthetic queries before distilling each reranker with the same ColBERTv2 model.These experiments were performed on a single NVIDIA V100 GPU with PyTorch, version 1.13\n\n\nTable 5 :\n5\nSanthanam et al. (2022b) Set Results.The ColBERTv2 distillation strategies train Y rerankers each with Z synthetic queries before distilling each reranker with the same ColBERTv2 model.For UDAPDR, we use 5 rerankers and 20K distinct synthetic queries for training each of them.For BM25, SPLADEv2, and RocketQAv2, we take results directly fromSanthanam et al. (2022b).\nLoTTE DatasetsForumSearchLife. Tech. Writing Rec. Science PooledLife. Tech. Writing Rec. Science PooledBM2560.6 39.464.0 55.437.1 47.263.8 41.860.3 56.532.7 48.3SPLADEv274.0 50.873.0 67.143.7 60.182.3 62.477.1 69.055.4 68.9RocketQAv273.7 47.371.5 65.738.0 57.782.1 63.478.0 72.155.3 69.8Zero-shot ColBERTv2 76.2 54.075.8 69.845.6 62.382.4 65.980.4 73.257.5 71.5UDAPDR84.9 59.983.2 78.648.8 70.886.8 67.784.3 77.961.0 76.6BEIR DatasetsArguAna Touch\u00e9 Covid NFcorpus HotpotQA DBPedia Climate-FEVER FEVER SciFact SCIDOCS FiQABM2531.536.7 65.632.560.331.321.375.366.515.8 23.6DPR (MS MARCO)41.4-56.120.837.128.117.658.947.810.8 27.5ANCE41.5-65.423.745.628.119.866.950.712.2 29.5ColBERT (v1)23.3-67.730.559.339.218.477.167.114.5 31.7TAS-B42.7-48.131.958.438.422.870.064.314.9 30.0RocketQAv245.124.7 67.529.353.335.618.067.656.813.1 30.2SPLADEv247.927.2 71.033.468.443.523.578.669.315.8 33.6BM25 Reranking w/ Coherelarge46.727.6 80.134.758.037.225.967.472.119.4 41.1BM25 Reranking w/ OpenAIada256.728.0 81.335.865.440.223.777.373.618.6 41.1Zero-shot ColBERTv246.126.3 84.733.870.344.627.178.066.015.4 45.8GenQ49.318.2 61.931.953.432.817.566.964.414.3 30.8GPL + TSDAE51.223.5 74.933.957.236.122.278.668.916.8 34.4UDAPDR57.532.4 88.034.175.347.433.783.272.217.8 53.5Promptagator Few-shot6338.1 76.23773.643.424.186.673.120.1 49.4\nAppendixA Reranker ConfigurationsWe aim to understand the impact of different model configurations on the efficacy of our domain adaptation technique.We expand on experiments from Section 4.3 and explore alternate configurations of key factors in the UDAPDR approach.Specifically, we want to answer the following questions through their corresponding experiments:1. (a) Question: Do corpus-adapted prompts improve domain adaptation and retriever distillation?(b) Experiment: Compare zero/few-shot prompts to corpus-adapted prompts for synthetic question generation (Table4).(a)Question: How does the number of rerankers affect downstream retrieval accuracy?(b) Experiment: Compare single-reranker to multi-reranker approach (with different reranker selection strategies) across various target domains (Table7).3. (a) Question: How does the synthetic query count affect downstream retrieval accuracy?(b) Experiment: Explore different query count configurations ranging from several thousand to hundreds of thousands of synthetic queries (Table1).(a)Question: How do triple counts during distillation affect domain adaptation for ColBERTv2?(b) Experiment: Explore different triple counts ranging from several thousand to millions of triples (Table8).In Table7and Table8(and Table1in the main text), we outline the results of different experimental configurations in which we alter synthetic query generation and passage reranker training.Based on our results for the LoTTE pooled dataset, we find that training multiple rerankers and selecting the best performing rerankers can improve our unsupervised domain adaptation approach.We generate multiple corpus-adapted prompts and rerankers to prevent edge cases in which sampled in-domain passages and queries have low quality.Furthermore, distilling the passage rerankers with ColBERTv2 allows us preserve their accuracy gains while avoiding their high computational costs.However, training many rerankers and selecting the best five rerankers can be computationally intensive and ultimately unnecessary to achieve domain adaptation.The simpler approach of training several rerankers and using them for distillation, without any quality filtering, yields comparable results with only a 0.6 point drop in Success@5 on average while computing 10x less synthetic queries (Table7).Additionally, by using our rerankers to generate more triples for distillation with ColBERTv2, we were able to boost performance even further as shown in Table8.B Fine-tuning Rerankers and RetrieverFor all passage reranker models that we fine-tune, we optimize for cross-entropy loss using Adam (Kingma and Ba, 2014) and apply a 0.1 dropout to the Transformer outputs.We feed the final hidden state of the [CLS] token into a single linear classification layer.We fine-tune for 1 epoch in all experimental configurations.Additionally, we using a 5e-6 learning rate combined with a linear warmup and linear decay for training(Howard and Ruder, 2018).We use a batch size of 32 across all experimental configurations.For our ColBERTv2 retriever, we use a 1e-5 learning rate and a batch size of 32 during distillation.The ColBERTv2 maximum document length is set to 300 tokens.We use a BERT-Base model(Devlin et al., 2019)as our encoder.Instead of fine-tuning the rerankers, we also tried fine-tuning ColBERTv2 directly with the synthetic datasets.We found that fine-tuning the retriever directly with the synthetic queries offered only limited benefits, only improving zero-shot retrieval by 1-3 points of accuracy at best and decreasing zero-shot accuracy at worst (for the LoTTE Forum dev set).Distilling the rerankers offered more substantive gains and better adaptation to the target domains more generally.LoTTE dataset results correspond to the Forum configuration.All results correspond to dev sets of each task.The reranker used in the experiments is DeBERTa-v3-Large.The ColBERTv2 distillation strategies train X number of rerankers before selecting the best Y based on their performance on the dev set of the target domain.Through the selection process, we aim to find an upper bound for retrieval accuracy, even though access to an annotated dev set is not realistic for all domains.In our distillation strategies, each reranker was trained on 2,000 synthetic queries.For our non-distilled reranker used in the final column, we trained it on 100,000 synthetic queries.The synthetic queries were created using Flan-T5 XXL model and the prompting strategy outlined in Section 3.For our non-distilled reranker used in the final column, we trained it on 100,000 synthetic queries.The synthetic queries were created using Flan-T5 XXL model and the prompting strategy outlined in Section 3.We ran additional experiments testing UDAPDR's efficacy on LoTTE Search dev, using one reranker trained with a unique set of 2000 synthetic queries.We found that the approach boosted accuracy by 1.6 points, increasing accuracy from 71.5 to 73.1.However, since the synthetic queries could be generated so cheaply, we decided to scale to tens of thousands of synthetic queries for further experiments.\nDo not have enough data? deep learning to the rescue!. Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor, George Kour, Segev Shlomov, Naama Tepper, Naama Zwerdling, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034\n\nAkari Asai, Timo Schick, Patrick Lewis, Xilun Chen, Gautier Izacard, Sebastian Riedel, Hannaneh Hajishirzi, Wen-Tau Yih, arXiv:2211.09260Task-aware retrieval with instructions. 2022arXiv preprint\n\nInpars: Data augmentation for information retrieval using large language models. Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Rodrigo Nogueira, arXiv:2202.051442022arXiv preprint\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033\n\nPre-training Tasks for Embedding-based Large-scale Retrieval. Wei-Cheng Chang, Felix X Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar, International Conference on Learning tions. 2020\n\nChung Hyung Won, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, arXiv:2210.11416Scaling instruction-finetuned language models. 2022arXiv preprint\n\nKevin Clark, Minh-Thang Luong, Quoc V Le, Christopher D Manning, arXiv:2003.10555ELECTRA: Pretraining text encoders as discriminators rather than generators. 2020arXiv preprint\n\nZhuyun Dai, Y Vincent, Ji Zhao, Yi Ma, Jianmo Luan, Jing Ni, Anton Lu, Kelvin Bakalov, Keith B Guu, Ming-Wei Hall, Chang, arXiv:2209.11755Promptagator: Few-shot dense retrieval from 8 examples. 2022arXiv preprint\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational Linguistics20191\n\nTo adapt or to annotate: Challenges and interventions for domain adaptation in open-domain question answering. Dheeru Dua, Emma Strubell, Sameer Singh, Pat Verga, arXiv:2212.103812022arXiv preprint\n\nThibault Formal, Carlos Lassance, Benjamin Piwowarski, St\u00e9phane Clinchant, arXiv:2109.10086Splade v2: Sparse lexical and expansion model for information retrieval. 2021arXiv preprint\n\nRetrieval augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, International Conference on Machine Learning. PMLR2020Panupong Pasupat, and Mingwei Chang\n\nNeural Vector Spaces for Unsupervised Information Retrieval. Christophe Van Gysel, 10.1145/3196826Maarten de Rijke, and Evangelos Kanoulas. 201836\n\nDeBERTaV3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing. Pengcheng He, Jianfeng Gao, Weizhu Chen, arXiv:2111.095432021arXiv preprint\n\nGholamreza Haffari, and Mohammad Norouzi. 2022. Generate, Annotate, and Learn: NLP with Synthetic Text. Xuanli He, Islam Nassar, Jamie Kiros, Transactions of the Association for Computational Linguistics. 10\n\nImproving efficient neural ranking models with crossarchitecture knowledge distillation. Sebastian Hofst\u00e4tter, Sophia Althammer, Michael Schr\u00f6der, Mete Sertkan, Allan Hanbury, 2021\n\nUniversal language model fine-tuning for text classification. Jeremy Howard, Sebastian Ruder, 10.18653/v1/P18-1031Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics20181\n\nPoly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring. Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, Jason Weston, arXiv:1905.019692019arXiv preprint\n\nUnsupervised dense information retrieval with contrastive learning. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, Edouard Grave, 10.48550/ARXIV.2112.091182021\n\nFew-shot learning with retrieval augmented language models. Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, Edouard Grave, arXiv:2208.032992022arXiv preprint\n\nInpars-v2: Large language models as efficient dataset generators for information retrieval. Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Roberto Lotufo, Jakub Zavrel, Rodrigo Nogueira, arXiv:2301.018202023arXiv preprint\n\nEvaluating embedding apis for information retrieval. Ehsan Kamalloo, Xinyu Zhang, Odunayo Ogundepo, Nandan Thakur, David Alfonso-Hermelo, Mehdi Rezagholizadeh, Jimmy Lin, 2023\n\nBaleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval. Omar Khattab, Christopher Potts, Matei Zaharia, Thirty-Fifth Conference on Neural Information Processing Systems. 2021\n\nDemonstrate-Search-Predict: Composing retrieval and language models for knowledge-intensive nlp. Omar Khattab, Keshav Santhanam, Lisa Xiang, David Li, Percy Hall, Christopher Liang, Matei Potts, Zaharia, 10.1145/3397271.3401075arXiv:2212.14024Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event. the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual EventChinaACM2022. 2020. July 25-30, 2020arXiv preprintColbert: Efficient and effective passage search via contextualized late interaction over BERT\n\nP Diederik, Jimmy Kingma, Ba, arXiv:1412.6980Adam: A method for stochastic optimization. 2014arXiv preprint\n\nData Augmentation using Pre-trained Transformer Models. Varun Kumar, Ashutosh Choudhary, Eunah Cho, Proceedings of the 2nd Workshop on Life-long Learning for Spoken Language Systems. the 2nd Workshop on Life-long Learning for Spoken Language SystemsSuzhou, ChinaAssociation for Computational Linguistics2020\n\nNatural Questions: A benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Transactions of the Association for Computational Linguistics. 72019\n\nLatent retrieval for weakly supervised open domain question answering. Kenton Lee, Ming-Wei Chang, Kristina Toutanova, 10.18653/v1/P19-1612Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational Linguistics2019\n\nRetrieval-augmented generation for knowledge-intensive NLP tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-Tau Yih, Tim Rockt\u00e4schel, Advances in Neural Information Processing Systems. 202033\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692RoBERTa: A robustly optimized BERT pretraining approach. 2019arXiv preprint\n\nZero-shot neural passage retrieval via domain-targeted synthetic question generation. Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, arXiv:2004.145032020arXiv preprint\n\nUnsupervised dense retrieval deserves better positive pairs: Scalable augmentation with query extraction and generation. Rui Meng, Ye Liu, Semih Yavuz, Divyansh Agarwal, Lifu Tu, Ning Yu, Jianguo Zhang, Meghana Bhat, Yingbo Zhou, arXiv:2212.088412022arXiv preprint\n\nMS MARCO: A human generated machine reading comprehension dataset. Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, Li Deng, CoCo@ NIPs. 2016\n\nRodrigo Nogueira, Kyunghyun Cho, arXiv:1901.04085Passage re-ranking with BERT. 2019arXiv preprint\n\nFrom doc2query to doctttttquery. Rodrigo Nogueira, Jimmy Lin, A I Epistemic, 20196Online preprint\n\nPytorch: An imperative style, high-performance deep learning library. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Advances in neural information processing systems. 201932\n\nKILT: a benchmark for knowledge intensive language tasks. Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani, Nicola De Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean Maillard, Vassilis Plachouras, Tim Rockt\u00e4schel, Sebastian Riedel, 10.18653/v1/2021.naacl-main.200Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterOnline. Association for Computational Linguistics2021\n\nKnow what you don't know: Unanswerable questions for SQuAD. Pranav Rajpurkar, Robin Jia, Percy Liang, 10.18653/v1/P18-2124Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics20182Short Papers)\n\nSQuAD: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, 10.18653/v1/D16-1264Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingAustin, TexasAssociation for Computational Linguistics2016\n\nPLAID: an efficient engine for late interaction retrieval. Keshav Santhanam, Omar Khattab, Christopher Potts, Matei Zaharia, Proceedings of the 31st ACM International Conference on Information & Knowledge Management. the 31st ACM International Conference on Information & Knowledge Management2022a\n\nCol-BERTv2: Effective and efficient retrieval via lightweight late interaction. Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, Matei Zaharia, 10.18653/v1/2022.naacl-main.272Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesUnited StatesAssociation for Computational Linguistics2022bSeattle\n\nKeshav Santhanam, Jon Saad-Falcon, Martin Franz, Omar Khattab, Avirup Sil, Radu Florian, Md Arafat Sultan, Salim Roukos, Matei Zaharia, Christopher Potts, arXiv:2212.01340Moving beyond downstream task accuracy for information retrieval benchmarking. 2022carXiv preprint\n\nAugmented SBERT: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks. Nandan Thakur, Nils Reimers, Johannes Daxenberger, Iryna Gurevych, arXiv:2010.082402020arXiv preprint\n\nBEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2021Abhishek Srivastava, and Iryna Gurevych\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141 Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, R Garnett, Curran Associates, Inc201730\n\nTREC-COVID: constructing a pandemic information retrieval test collection. Ellen Voorhees, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman, William R Hersh, Kyle Lo, Kirk Roberts, Ian Soboroff, Lucy Lu, Wang , ACM SIGIR Forum. New York, NY, USAACM202154\n\nGPL: Generative pseudo labeling for unsupervised domain adaptation of dense retrieval. Kexin Wang, Nandan Thakur, Nils Reimers, Iryna Gurevych, 10.18653/v1/2022.naacl-main.168Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational Linguistics2022\n\nCORD-19: The COVID-19 open research dataset. Lucy Lu, Wang , Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Doug Burdick, Darrin Eide, Kathryn Funk, Yannis Katsis, Rodney Michael Kinney, Yunyao Li, Ziyang Liu, William Merrill, Paul Mooney, Dewey A Murdick, Devvret Rishi, Jerry Sheehan, Zhihong Shen, Brandon Stilson, Alex D Wade, Kuansan Wang, Nancy Xin Ru, Christopher Wang, Boya Wilhelm, Douglas M Xie, Daniel S Raymond, Oren Weld, Sebastian Etzioni, Kohlmeier, Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020. the 1st Workshop on NLP for COVID-19 at ACL 2020Online. Association for Computational Linguistics2020\n\nMiniLMv2: Multi-head selfattention relation distillation for compressing pretrained transformers. Wenhui Wang, Hangbo Bao, Shaohan Huang, Li Dong, Furu Wei, 10.18653/v1/2021.findings-acl.188Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Online. Association for Computational Linguistics2021\n\nZeroshot dense retrieval with momentum adversarial domain invariant representations. Ji Xin, Chenyan Xiong, Ashwin Srinivasan, Ankita Sharma, Damien Jose, Paul Bennett, 10.18653/v1/2022.findings-acl.316Findings of the Association for Computational Linguistics: ACL 2022. Dublin, IrelandAssociation for Computational Linguistics2022\n\nGenerative data augmentation for commonsense reasoning. Yiben Yang, Chaitanya Malaviya, Jared Fernandez, Swabha Swayamdipta, Le Ronan, Ji-Ping Bras, Chandra Wang, Yejin Bhagavatula, Doug Choi, Downey, 10.18653/v1/2020.findings-emnlp.90Findings of the Association for Computational Linguistics: EMNLP 2020. Online. Association for Computational Linguistics2020\n", "annotations": {"author": "[{\"end\":128,\"start\":90},{\"end\":164,\"start\":129},{\"end\":204,\"start\":165},{\"end\":236,\"start\":205},{\"end\":268,\"start\":237},{\"end\":300,\"start\":269},{\"end\":330,\"start\":301},{\"end\":366,\"start\":331},{\"end\":407,\"start\":367}]", "publisher": null, "author_last_name": "[{\"end\":105,\"start\":94},{\"end\":141,\"start\":134},{\"end\":181,\"start\":172},{\"end\":217,\"start\":210},{\"end\":249,\"start\":244},{\"end\":281,\"start\":275},{\"end\":311,\"start\":308},{\"end\":347,\"start\":341},{\"end\":384,\"start\":379}]", "author_first_name": "[{\"end\":93,\"start\":90},{\"end\":133,\"start\":129},{\"end\":171,\"start\":165},{\"end\":209,\"start\":205},{\"end\":243,\"start\":237},{\"end\":274,\"start\":269},{\"end\":307,\"start\":301},{\"end\":333,\"start\":331},{\"end\":340,\"start\":334},{\"end\":378,\"start\":367}]", "author_affiliation": "[{\"end\":127,\"start\":107},{\"end\":163,\"start\":143},{\"end\":203,\"start\":183},{\"end\":235,\"start\":219},{\"end\":267,\"start\":251},{\"end\":299,\"start\":283},{\"end\":329,\"start\":313},{\"end\":365,\"start\":349},{\"end\":406,\"start\":386}]", "title": "[{\"end\":87,\"start\":1},{\"end\":494,\"start\":408}]", "venue": null, "abstract": "[{\"end\":1381,\"start\":528}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b33\"},\"end\":1553,\"start\":1529},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":1579,\"start\":1553},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":1599,\"start\":1579},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1729,\"start\":1711},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":1748,\"start\":1729},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1769,\"start\":1748},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":1790,\"start\":1769},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":1920,\"start\":1896},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":1971,\"start\":1945},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":2004,\"start\":1982},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":2156,\"start\":2135},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2180,\"start\":2156},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2258,\"start\":2237},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":2358,\"start\":2335},{\"end\":2370,\"start\":2358},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3061,\"start\":3037},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":3079,\"start\":3061},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3096,\"start\":3079},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3155,\"start\":3135},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3177,\"start\":3160},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4790,\"start\":4763},{\"end\":4816,\"start\":4790},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5241,\"start\":5221},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5303,\"start\":5283},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5440,\"start\":5415},{\"end\":6391,\"start\":6374},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":6409,\"start\":6391},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6434,\"start\":6409},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6453,\"start\":6434},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6573,\"start\":6551},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6746,\"start\":6722},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6764,\"start\":6746},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6846,\"start\":6829},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7232,\"start\":7215},{\"end\":7254,\"start\":7232},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":7273,\"start\":7255},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7452,\"start\":7431},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7473,\"start\":7453},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7495,\"start\":7478},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7871,\"start\":7851},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7895,\"start\":7871},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7915,\"start\":7895},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7933,\"start\":7916},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8196,\"start\":8178},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8373,\"start\":8356},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8396,\"start\":8378},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8618,\"start\":8601},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8641,\"start\":8623},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9146,\"start\":9125},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9194,\"start\":9176},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9314,\"start\":9295},{\"end\":9548,\"start\":9515},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9755,\"start\":9734},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":10028,\"start\":10010},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10172,\"start\":10155},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10244,\"start\":10223},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10557,\"start\":10536},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10656,\"start\":10629},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10680,\"start\":10656},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11774,\"start\":11754},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12038,\"start\":12017},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12217,\"start\":12201},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":12857,\"start\":12835},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13813,\"start\":13795},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13835,\"start\":13813},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14164,\"start\":14140},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15414,\"start\":15392},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15617,\"start\":15600},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":15715,\"start\":15697},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":15743,\"start\":15722},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":15777,\"start\":15758},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":15955,\"start\":15930},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":16028,\"start\":16003},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":16056,\"start\":16035},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16087,\"start\":16061},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":16123,\"start\":16099},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16330,\"start\":16310},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16449,\"start\":16432},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16468,\"start\":16449},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":18506,\"start\":18481},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":18616,\"start\":18591},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":18638,\"start\":18617},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20390,\"start\":20366},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":23685,\"start\":23665},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":24302,\"start\":24283},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24382,\"start\":24364},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":24772,\"start\":24749},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":24795,\"start\":24777},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":27841,\"start\":27823}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":27931,\"start\":27623},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28135,\"start\":27932},{\"attributes\":{\"id\":\"fig_2\"},\"end\":28282,\"start\":28136},{\"attributes\":{\"id\":\"fig_4\"},\"end\":28489,\"start\":28283},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30026,\"start\":28490},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":30386,\"start\":30027},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":32088,\"start\":30387}]", "paragraph": "[{\"end\":2870,\"start\":1397},{\"end\":3582,\"start\":2872},{\"end\":3903,\"start\":3584},{\"end\":4858,\"start\":3905},{\"end\":5083,\"start\":4860},{\"end\":5456,\"start\":5085},{\"end\":5619,\"start\":5458},{\"end\":5965,\"start\":5621},{\"end\":6271,\"start\":5967},{\"end\":6287,\"start\":6273},{\"end\":7059,\"start\":6323},{\"end\":7630,\"start\":7061},{\"end\":8278,\"start\":7632},{\"end\":8969,\"start\":8280},{\"end\":9920,\"start\":9003},{\"end\":10681,\"start\":9922},{\"end\":11247,\"start\":10697},{\"end\":11724,\"start\":11249},{\"end\":12218,\"start\":11726},{\"end\":13193,\"start\":12220},{\"end\":13488,\"start\":13195},{\"end\":13836,\"start\":13490},{\"end\":14689,\"start\":13838},{\"end\":15139,\"start\":14691},{\"end\":15318,\"start\":15141},{\"end\":15956,\"start\":15343},{\"end\":16233,\"start\":15969},{\"end\":16793,\"start\":16235},{\"end\":17200,\"start\":16830},{\"end\":17724,\"start\":17202},{\"end\":18096,\"start\":17726},{\"end\":18420,\"start\":18114},{\"end\":18691,\"start\":18422},{\"end\":18786,\"start\":18693},{\"end\":19620,\"start\":18822},{\"end\":20160,\"start\":19622},{\"end\":20833,\"start\":20195},{\"end\":21528,\"start\":20835},{\"end\":21713,\"start\":21530},{\"end\":22630,\"start\":21745},{\"end\":23228,\"start\":22653},{\"end\":23328,\"start\":23257},{\"end\":23530,\"start\":23330},{\"end\":24487,\"start\":23532},{\"end\":24693,\"start\":24489},{\"end\":24998,\"start\":24695},{\"end\":25833,\"start\":25013},{\"end\":26218,\"start\":25835},{\"end\":27098,\"start\":26220},{\"end\":27622,\"start\":27100},{\"end\":27930,\"start\":27637},{\"end\":28134,\"start\":27946},{\"end\":28281,\"start\":28149},{\"end\":28488,\"start\":28286},{\"end\":29288,\"start\":28503},{\"end\":30385,\"start\":30040},{\"end\":30767,\"start\":30400}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":16837,\"start\":16836},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":17270,\"start\":17269},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":18145,\"start\":18144},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":18211,\"start\":18210},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":18551,\"start\":18550},{\"end\":19211,\"start\":19210},{\"end\":19972,\"start\":19971},{\"end\":20628,\"start\":20627},{\"end\":21032,\"start\":21031},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":21755,\"start\":21754},{\"end\":21767,\"start\":21766},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22660,\"start\":22659},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22672,\"start\":22671},{\"end\":23698,\"start\":23697}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1395,\"start\":1383},{\"attributes\":{\"n\":\"2.1\"},\"end\":6321,\"start\":6290},{\"attributes\":{\"n\":\"2.2\"},\"end\":9001,\"start\":8972},{\"attributes\":{\"n\":\"3\"},\"end\":10695,\"start\":10684},{\"attributes\":{\"n\":\"4\"},\"end\":15332,\"start\":15321},{\"attributes\":{\"n\":\"4.1\"},\"end\":15341,\"start\":15335},{\"attributes\":{\"n\":\"4.2\"},\"end\":15967,\"start\":15959},{\"attributes\":{\"n\":\"4.3\"},\"end\":16828,\"start\":16796},{\"attributes\":{\"n\":\"4.4\"},\"end\":18112,\"start\":18099},{\"attributes\":{\"n\":\"4.5\"},\"end\":18820,\"start\":18789},{\"attributes\":{\"n\":\"4.6\"},\"end\":20193,\"start\":20163},{\"attributes\":{\"n\":\"4.7\"},\"end\":21743,\"start\":21716},{\"attributes\":{\"n\":\"4.8\"},\"end\":22651,\"start\":22633},{\"attributes\":{\"n\":\"5\"},\"end\":23255,\"start\":23231},{\"attributes\":{\"n\":\"6\"},\"end\":25011,\"start\":25001},{\"end\":27634,\"start\":27624},{\"end\":27943,\"start\":27933},{\"end\":28146,\"start\":28137},{\"end\":28500,\"start\":28491},{\"end\":30037,\"start\":30028},{\"end\":30397,\"start\":30388}]", "table": "[{\"end\":30026,\"start\":29289},{\"end\":32088,\"start\":30768}]", "figure_caption": "[{\"end\":27931,\"start\":27636},{\"end\":28135,\"start\":27945},{\"end\":28282,\"start\":28148},{\"end\":28489,\"start\":28285},{\"end\":29289,\"start\":28502},{\"end\":30386,\"start\":30039},{\"end\":30768,\"start\":30399}]", "figure_ref": "[{\"end\":2379,\"start\":2378},{\"end\":3941,\"start\":3940},{\"end\":10705,\"start\":10704},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11987,\"start\":11986},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12512,\"start\":12511}]", "bib_author_first_name": "[{\"end\":37265,\"start\":37259},{\"end\":37283,\"start\":37279},{\"end\":37299,\"start\":37293},{\"end\":37316,\"start\":37312},{\"end\":37331,\"start\":37325},{\"end\":37343,\"start\":37338},{\"end\":37358,\"start\":37353},{\"end\":37372,\"start\":37367},{\"end\":37506,\"start\":37501},{\"end\":37517,\"start\":37513},{\"end\":37533,\"start\":37526},{\"end\":37546,\"start\":37541},{\"end\":37560,\"start\":37553},{\"end\":37579,\"start\":37570},{\"end\":37596,\"start\":37588},{\"end\":37616,\"start\":37609},{\"end\":37783,\"start\":37779},{\"end\":37799,\"start\":37795},{\"end\":37817,\"start\":37810},{\"end\":37833,\"start\":37826},{\"end\":37922,\"start\":37919},{\"end\":37938,\"start\":37930},{\"end\":37949,\"start\":37945},{\"end\":37964,\"start\":37957},{\"end\":37979,\"start\":37974},{\"end\":37981,\"start\":37980},{\"end\":37998,\"start\":37990},{\"end\":38015,\"start\":38009},{\"end\":38035,\"start\":38029},{\"end\":38049,\"start\":38043},{\"end\":38064,\"start\":38058},{\"end\":38203,\"start\":38194},{\"end\":38216,\"start\":38211},{\"end\":38218,\"start\":38217},{\"end\":38230,\"start\":38223},{\"end\":38244,\"start\":38238},{\"end\":38257,\"start\":38251},{\"end\":38320,\"start\":38315},{\"end\":38334,\"start\":38332},{\"end\":38346,\"start\":38340},{\"end\":38362,\"start\":38356},{\"end\":38371,\"start\":38369},{\"end\":38384,\"start\":38377},{\"end\":38396,\"start\":38392},{\"end\":38407,\"start\":38401},{\"end\":38421,\"start\":38414},{\"end\":38442,\"start\":38432},{\"end\":38539,\"start\":38534},{\"end\":38557,\"start\":38547},{\"end\":38569,\"start\":38565},{\"end\":38571,\"start\":38570},{\"end\":38587,\"start\":38576},{\"end\":38589,\"start\":38588},{\"end\":38718,\"start\":38712},{\"end\":38725,\"start\":38724},{\"end\":38737,\"start\":38735},{\"end\":38746,\"start\":38744},{\"end\":38757,\"start\":38751},{\"end\":38768,\"start\":38764},{\"end\":38778,\"start\":38773},{\"end\":38789,\"start\":38783},{\"end\":38804,\"start\":38799},{\"end\":38806,\"start\":38805},{\"end\":38820,\"start\":38812},{\"end\":39013,\"start\":39008},{\"end\":39030,\"start\":39022},{\"end\":39044,\"start\":39038},{\"end\":39058,\"start\":39050},{\"end\":39571,\"start\":39565},{\"end\":39581,\"start\":39577},{\"end\":39598,\"start\":39592},{\"end\":39609,\"start\":39606},{\"end\":39661,\"start\":39653},{\"end\":39676,\"start\":39670},{\"end\":39695,\"start\":39687},{\"end\":39716,\"start\":39708},{\"end\":39892,\"start\":39886},{\"end\":39904,\"start\":39898},{\"end\":39914,\"start\":39910},{\"end\":40083,\"start\":40073},{\"end\":40277,\"start\":40268},{\"end\":40290,\"start\":40282},{\"end\":40302,\"start\":40296},{\"end\":40455,\"start\":40449},{\"end\":40465,\"start\":40460},{\"end\":40479,\"start\":40474},{\"end\":40652,\"start\":40643},{\"end\":40671,\"start\":40665},{\"end\":40690,\"start\":40683},{\"end\":40705,\"start\":40701},{\"end\":40720,\"start\":40715},{\"end\":40804,\"start\":40798},{\"end\":40822,\"start\":40813},{\"end\":41213,\"start\":41207},{\"end\":41226,\"start\":41222},{\"end\":41246,\"start\":41236},{\"end\":41261,\"start\":41256},{\"end\":41381,\"start\":41374},{\"end\":41399,\"start\":41391},{\"end\":41412,\"start\":41407},{\"end\":41432,\"start\":41423},{\"end\":41446,\"start\":41441},{\"end\":41465,\"start\":41459},{\"end\":41481,\"start\":41474},{\"end\":41587,\"start\":41580},{\"end\":41604,\"start\":41597},{\"end\":41617,\"start\":41612},{\"end\":41631,\"start\":41626},{\"end\":41647,\"start\":41642},{\"end\":41661,\"start\":41657},{\"end\":41674,\"start\":41670},{\"end\":41693,\"start\":41687},{\"end\":41711,\"start\":41702},{\"end\":41727,\"start\":41720},{\"end\":41868,\"start\":41863},{\"end\":41883,\"start\":41879},{\"end\":41899,\"start\":41895},{\"end\":41917,\"start\":41910},{\"end\":41933,\"start\":41926},{\"end\":41947,\"start\":41942},{\"end\":41963,\"start\":41956},{\"end\":42068,\"start\":42063},{\"end\":42084,\"start\":42079},{\"end\":42099,\"start\":42092},{\"end\":42116,\"start\":42110},{\"end\":42130,\"start\":42125},{\"end\":42153,\"start\":42148},{\"end\":42175,\"start\":42170},{\"end\":42260,\"start\":42256},{\"end\":42281,\"start\":42270},{\"end\":42294,\"start\":42289},{\"end\":42477,\"start\":42473},{\"end\":42493,\"start\":42487},{\"end\":42509,\"start\":42505},{\"end\":42522,\"start\":42517},{\"end\":42532,\"start\":42527},{\"end\":42550,\"start\":42539},{\"end\":42563,\"start\":42558},{\"end\":43028,\"start\":43027},{\"end\":43044,\"start\":43039},{\"end\":43197,\"start\":43192},{\"end\":43213,\"start\":43205},{\"end\":43230,\"start\":43225},{\"end\":43512,\"start\":43509},{\"end\":43536,\"start\":43526},{\"end\":43553,\"start\":43547},{\"end\":43571,\"start\":43564},{\"end\":43586,\"start\":43581},{\"end\":43600,\"start\":43595},{\"end\":43618,\"start\":43610},{\"end\":43633,\"start\":43628},{\"end\":43651,\"start\":43646},{\"end\":43666,\"start\":43660},{\"end\":43819,\"start\":43813},{\"end\":43833,\"start\":43825},{\"end\":43849,\"start\":43841},{\"end\":44177,\"start\":44170},{\"end\":44190,\"start\":44185},{\"end\":44208,\"start\":44198},{\"end\":44222,\"start\":44217},{\"end\":44240,\"start\":44232},{\"end\":44257,\"start\":44252},{\"end\":44273,\"start\":44265},{\"end\":44287,\"start\":44283},{\"end\":44302,\"start\":44295},{\"end\":44311,\"start\":44308},{\"end\":44390,\"start\":44384},{\"end\":44400,\"start\":44396},{\"end\":44411,\"start\":44406},{\"end\":44426,\"start\":44419},{\"end\":44437,\"start\":44431},{\"end\":44450,\"start\":44445},{\"end\":44461,\"start\":44457},{\"end\":44472,\"start\":44468},{\"end\":44484,\"start\":44480},{\"end\":44505,\"start\":44498},{\"end\":44697,\"start\":44695},{\"end\":44706,\"start\":44702},{\"end\":44723,\"start\":44717},{\"end\":44735,\"start\":44730},{\"end\":44746,\"start\":44742},{\"end\":44917,\"start\":44914},{\"end\":44926,\"start\":44924},{\"end\":44937,\"start\":44932},{\"end\":44953,\"start\":44945},{\"end\":44967,\"start\":44963},{\"end\":44976,\"start\":44972},{\"end\":44988,\"start\":44981},{\"end\":45003,\"start\":44996},{\"end\":45016,\"start\":45010},{\"end\":45129,\"start\":45126},{\"end\":45141,\"start\":45138},{\"end\":45156,\"start\":45153},{\"end\":45171,\"start\":45163},{\"end\":45184,\"start\":45177},{\"end\":45199,\"start\":45193},{\"end\":45212,\"start\":45210},{\"end\":45244,\"start\":45237},{\"end\":45264,\"start\":45255},{\"end\":45376,\"start\":45369},{\"end\":45392,\"start\":45387},{\"end\":45399,\"start\":45398},{\"end\":45401,\"start\":45400},{\"end\":45509,\"start\":45505},{\"end\":45521,\"start\":45518},{\"end\":45538,\"start\":45529},{\"end\":45550,\"start\":45546},{\"end\":45563,\"start\":45558},{\"end\":45581,\"start\":45574},{\"end\":45596,\"start\":45590},{\"end\":45612,\"start\":45606},{\"end\":45625,\"start\":45618},{\"end\":45642,\"start\":45638},{\"end\":45773,\"start\":45768},{\"end\":45793,\"start\":45783},{\"end\":45808,\"start\":45802},{\"end\":45821,\"start\":45814},{\"end\":45834,\"start\":45829},{\"end\":45850,\"start\":45844},{\"end\":45853,\"start\":45851},{\"end\":45864,\"start\":45859},{\"end\":45879,\"start\":45873},{\"end\":45897,\"start\":45889},{\"end\":45913,\"start\":45909},{\"end\":45932,\"start\":45924},{\"end\":45948,\"start\":45945},{\"end\":45971,\"start\":45962},{\"end\":46247,\"start\":46241},{\"end\":46264,\"start\":46259},{\"end\":46275,\"start\":46270},{\"end\":46612,\"start\":46606},{\"end\":46628,\"start\":46624},{\"end\":46646,\"start\":46636},{\"end\":46661,\"start\":46656},{\"end\":46973,\"start\":46967},{\"end\":46989,\"start\":46985},{\"end\":47010,\"start\":46999},{\"end\":47023,\"start\":47018},{\"end\":47293,\"start\":47287},{\"end\":47309,\"start\":47305},{\"end\":47322,\"start\":47319},{\"end\":47347,\"start\":47336},{\"end\":47360,\"start\":47355},{\"end\":47746,\"start\":47740},{\"end\":47761,\"start\":47758},{\"end\":47781,\"start\":47775},{\"end\":47793,\"start\":47789},{\"end\":47809,\"start\":47803},{\"end\":47819,\"start\":47815},{\"end\":47831,\"start\":47829},{\"end\":47852,\"start\":47847},{\"end\":47866,\"start\":47861},{\"end\":47887,\"start\":47876},{\"end\":48122,\"start\":48116},{\"end\":48135,\"start\":48131},{\"end\":48153,\"start\":48145},{\"end\":48172,\"start\":48167},{\"end\":48315,\"start\":48309},{\"end\":48328,\"start\":48324},{\"end\":48345,\"start\":48338},{\"end\":48528,\"start\":48522},{\"end\":48542,\"start\":48538},{\"end\":48556,\"start\":48552},{\"end\":48570,\"start\":48565},{\"end\":48587,\"start\":48582},{\"end\":48600,\"start\":48595},{\"end\":48602,\"start\":48601},{\"end\":48611,\"start\":48610},{\"end\":48625,\"start\":48620},{\"end\":48690,\"start\":48689},{\"end\":48699,\"start\":48698},{\"end\":48701,\"start\":48700},{\"end\":48712,\"start\":48711},{\"end\":48722,\"start\":48721},{\"end\":48733,\"start\":48732},{\"end\":48743,\"start\":48742},{\"end\":48759,\"start\":48758},{\"end\":48879,\"start\":48874},{\"end\":48897,\"start\":48890},{\"end\":48910,\"start\":48904},{\"end\":48924,\"start\":48920},{\"end\":48948,\"start\":48941},{\"end\":48950,\"start\":48949},{\"end\":48962,\"start\":48958},{\"end\":48971,\"start\":48967},{\"end\":48984,\"start\":48981},{\"end\":48999,\"start\":48995},{\"end\":49008,\"start\":49004},{\"end\":49148,\"start\":49143},{\"end\":49161,\"start\":49155},{\"end\":49174,\"start\":49170},{\"end\":49189,\"start\":49184},{\"end\":49620,\"start\":49616},{\"end\":49629,\"start\":49625},{\"end\":49636,\"start\":49632},{\"end\":49649,\"start\":49641},{\"end\":49672,\"start\":49665},{\"end\":49689,\"start\":49679},{\"end\":49700,\"start\":49696},{\"end\":49716,\"start\":49710},{\"end\":49730,\"start\":49723},{\"end\":49743,\"start\":49737},{\"end\":49758,\"start\":49752},{\"end\":49781,\"start\":49775},{\"end\":49792,\"start\":49786},{\"end\":49805,\"start\":49798},{\"end\":49819,\"start\":49815},{\"end\":49833,\"start\":49828},{\"end\":49835,\"start\":49834},{\"end\":49852,\"start\":49845},{\"end\":49865,\"start\":49860},{\"end\":49882,\"start\":49875},{\"end\":49896,\"start\":49889},{\"end\":49910,\"start\":49906},{\"end\":49912,\"start\":49911},{\"end\":49926,\"start\":49919},{\"end\":49938,\"start\":49933},{\"end\":49958,\"start\":49947},{\"end\":49969,\"start\":49965},{\"end\":49986,\"start\":49979},{\"end\":49988,\"start\":49987},{\"end\":50000,\"start\":49994},{\"end\":50002,\"start\":50001},{\"end\":50016,\"start\":50012},{\"end\":50032,\"start\":50023},{\"end\":50325,\"start\":50319},{\"end\":50338,\"start\":50332},{\"end\":50351,\"start\":50344},{\"end\":50361,\"start\":50359},{\"end\":50372,\"start\":50368},{\"end\":50629,\"start\":50627},{\"end\":50642,\"start\":50635},{\"end\":50656,\"start\":50650},{\"end\":50675,\"start\":50669},{\"end\":50690,\"start\":50684},{\"end\":50701,\"start\":50697},{\"end\":50936,\"start\":50931},{\"end\":50952,\"start\":50943},{\"end\":50968,\"start\":50963},{\"end\":50986,\"start\":50980},{\"end\":51002,\"start\":51000},{\"end\":51017,\"start\":51010},{\"end\":51031,\"start\":51024},{\"end\":51043,\"start\":51038},{\"end\":51061,\"start\":51057}]", "bib_author_last_name": "[{\"end\":37277,\"start\":37266},{\"end\":37291,\"start\":37284},{\"end\":37310,\"start\":37300},{\"end\":37323,\"start\":37317},{\"end\":37336,\"start\":37332},{\"end\":37351,\"start\":37344},{\"end\":37365,\"start\":37359},{\"end\":37382,\"start\":37373},{\"end\":37511,\"start\":37507},{\"end\":37524,\"start\":37518},{\"end\":37539,\"start\":37534},{\"end\":37551,\"start\":37547},{\"end\":37568,\"start\":37561},{\"end\":37586,\"start\":37580},{\"end\":37607,\"start\":37597},{\"end\":37620,\"start\":37617},{\"end\":37793,\"start\":37784},{\"end\":37808,\"start\":37800},{\"end\":37824,\"start\":37818},{\"end\":37842,\"start\":37834},{\"end\":37928,\"start\":37923},{\"end\":37943,\"start\":37939},{\"end\":37955,\"start\":37950},{\"end\":37972,\"start\":37965},{\"end\":37988,\"start\":37982},{\"end\":38007,\"start\":37999},{\"end\":38027,\"start\":38016},{\"end\":38041,\"start\":38036},{\"end\":38056,\"start\":38050},{\"end\":38071,\"start\":38065},{\"end\":38209,\"start\":38204},{\"end\":38221,\"start\":38219},{\"end\":38236,\"start\":38231},{\"end\":38249,\"start\":38245},{\"end\":38263,\"start\":38258},{\"end\":38330,\"start\":38321},{\"end\":38338,\"start\":38335},{\"end\":38354,\"start\":38347},{\"end\":38367,\"start\":38363},{\"end\":38375,\"start\":38372},{\"end\":38390,\"start\":38385},{\"end\":38399,\"start\":38397},{\"end\":38412,\"start\":38408},{\"end\":38430,\"start\":38422},{\"end\":38449,\"start\":38443},{\"end\":38545,\"start\":38540},{\"end\":38563,\"start\":38558},{\"end\":38574,\"start\":38572},{\"end\":38597,\"start\":38590},{\"end\":38722,\"start\":38719},{\"end\":38733,\"start\":38726},{\"end\":38742,\"start\":38738},{\"end\":38749,\"start\":38747},{\"end\":38762,\"start\":38758},{\"end\":38771,\"start\":38769},{\"end\":38781,\"start\":38779},{\"end\":38797,\"start\":38790},{\"end\":38810,\"start\":38807},{\"end\":38825,\"start\":38821},{\"end\":38832,\"start\":38827},{\"end\":39020,\"start\":39014},{\"end\":39036,\"start\":39031},{\"end\":39048,\"start\":39045},{\"end\":39068,\"start\":39059},{\"end\":39575,\"start\":39572},{\"end\":39590,\"start\":39582},{\"end\":39604,\"start\":39599},{\"end\":39615,\"start\":39610},{\"end\":39668,\"start\":39662},{\"end\":39685,\"start\":39677},{\"end\":39706,\"start\":39696},{\"end\":39726,\"start\":39717},{\"end\":39896,\"start\":39893},{\"end\":39908,\"start\":39905},{\"end\":39919,\"start\":39915},{\"end\":40093,\"start\":40084},{\"end\":40280,\"start\":40278},{\"end\":40294,\"start\":40291},{\"end\":40307,\"start\":40303},{\"end\":40458,\"start\":40456},{\"end\":40472,\"start\":40466},{\"end\":40485,\"start\":40480},{\"end\":40663,\"start\":40653},{\"end\":40681,\"start\":40672},{\"end\":40699,\"start\":40691},{\"end\":40713,\"start\":40706},{\"end\":40728,\"start\":40721},{\"end\":40811,\"start\":40805},{\"end\":40828,\"start\":40823},{\"end\":41220,\"start\":41214},{\"end\":41234,\"start\":41227},{\"end\":41254,\"start\":41247},{\"end\":41268,\"start\":41262},{\"end\":41389,\"start\":41382},{\"end\":41405,\"start\":41400},{\"end\":41421,\"start\":41413},{\"end\":41439,\"start\":41433},{\"end\":41457,\"start\":41447},{\"end\":41472,\"start\":41466},{\"end\":41487,\"start\":41482},{\"end\":41595,\"start\":41588},{\"end\":41610,\"start\":41605},{\"end\":41624,\"start\":41618},{\"end\":41640,\"start\":41632},{\"end\":41655,\"start\":41648},{\"end\":41668,\"start\":41662},{\"end\":41685,\"start\":41675},{\"end\":41700,\"start\":41694},{\"end\":41718,\"start\":41712},{\"end\":41733,\"start\":41728},{\"end\":41877,\"start\":41869},{\"end\":41893,\"start\":41884},{\"end\":41908,\"start\":41900},{\"end\":41924,\"start\":41918},{\"end\":41940,\"start\":41934},{\"end\":41954,\"start\":41948},{\"end\":41972,\"start\":41964},{\"end\":42077,\"start\":42069},{\"end\":42090,\"start\":42085},{\"end\":42108,\"start\":42100},{\"end\":42123,\"start\":42117},{\"end\":42146,\"start\":42131},{\"end\":42168,\"start\":42154},{\"end\":42179,\"start\":42176},{\"end\":42268,\"start\":42261},{\"end\":42287,\"start\":42282},{\"end\":42302,\"start\":42295},{\"end\":42485,\"start\":42478},{\"end\":42503,\"start\":42494},{\"end\":42515,\"start\":42510},{\"end\":42525,\"start\":42523},{\"end\":42537,\"start\":42533},{\"end\":42556,\"start\":42551},{\"end\":42569,\"start\":42564},{\"end\":42578,\"start\":42571},{\"end\":43037,\"start\":43029},{\"end\":43051,\"start\":43045},{\"end\":43055,\"start\":43053},{\"end\":43203,\"start\":43198},{\"end\":43223,\"start\":43214},{\"end\":43234,\"start\":43231},{\"end\":43524,\"start\":43513},{\"end\":43545,\"start\":43537},{\"end\":43562,\"start\":43554},{\"end\":43579,\"start\":43572},{\"end\":43593,\"start\":43587},{\"end\":43608,\"start\":43601},{\"end\":43626,\"start\":43619},{\"end\":43644,\"start\":43634},{\"end\":43658,\"start\":43652},{\"end\":43670,\"start\":43667},{\"end\":43823,\"start\":43820},{\"end\":43839,\"start\":43834},{\"end\":43859,\"start\":43850},{\"end\":44183,\"start\":44178},{\"end\":44196,\"start\":44191},{\"end\":44215,\"start\":44209},{\"end\":44230,\"start\":44223},{\"end\":44250,\"start\":44241},{\"end\":44263,\"start\":44258},{\"end\":44281,\"start\":44274},{\"end\":44293,\"start\":44288},{\"end\":44306,\"start\":44303},{\"end\":44323,\"start\":44312},{\"end\":44394,\"start\":44391},{\"end\":44404,\"start\":44401},{\"end\":44417,\"start\":44412},{\"end\":44429,\"start\":44427},{\"end\":44443,\"start\":44438},{\"end\":44455,\"start\":44451},{\"end\":44466,\"start\":44462},{\"end\":44478,\"start\":44473},{\"end\":44496,\"start\":44485},{\"end\":44514,\"start\":44506},{\"end\":44700,\"start\":44698},{\"end\":44715,\"start\":44707},{\"end\":44728,\"start\":44724},{\"end\":44740,\"start\":44736},{\"end\":44755,\"start\":44747},{\"end\":44922,\"start\":44918},{\"end\":44930,\"start\":44927},{\"end\":44943,\"start\":44938},{\"end\":44961,\"start\":44954},{\"end\":44970,\"start\":44968},{\"end\":44979,\"start\":44977},{\"end\":44994,\"start\":44989},{\"end\":45008,\"start\":45004},{\"end\":45021,\"start\":45017},{\"end\":45136,\"start\":45130},{\"end\":45151,\"start\":45142},{\"end\":45161,\"start\":45157},{\"end\":45175,\"start\":45172},{\"end\":45191,\"start\":45185},{\"end\":45208,\"start\":45200},{\"end\":45217,\"start\":45213},{\"end\":45253,\"start\":45245},{\"end\":45268,\"start\":45265},{\"end\":45385,\"start\":45377},{\"end\":45396,\"start\":45393},{\"end\":45411,\"start\":45402},{\"end\":45516,\"start\":45510},{\"end\":45527,\"start\":45522},{\"end\":45544,\"start\":45539},{\"end\":45556,\"start\":45551},{\"end\":45572,\"start\":45564},{\"end\":45588,\"start\":45582},{\"end\":45604,\"start\":45597},{\"end\":45616,\"start\":45613},{\"end\":45636,\"start\":45626},{\"end\":45649,\"start\":45643},{\"end\":45781,\"start\":45774},{\"end\":45800,\"start\":45794},{\"end\":45812,\"start\":45809},{\"end\":45827,\"start\":45822},{\"end\":45842,\"start\":45835},{\"end\":45857,\"start\":45854},{\"end\":45871,\"start\":45865},{\"end\":45887,\"start\":45880},{\"end\":45907,\"start\":45898},{\"end\":45922,\"start\":45914},{\"end\":45943,\"start\":45933},{\"end\":45960,\"start\":45949},{\"end\":45978,\"start\":45972},{\"end\":46257,\"start\":46248},{\"end\":46268,\"start\":46265},{\"end\":46281,\"start\":46276},{\"end\":46622,\"start\":46613},{\"end\":46634,\"start\":46629},{\"end\":46654,\"start\":46647},{\"end\":46667,\"start\":46662},{\"end\":46983,\"start\":46974},{\"end\":46997,\"start\":46990},{\"end\":47016,\"start\":47011},{\"end\":47031,\"start\":47024},{\"end\":47303,\"start\":47294},{\"end\":47317,\"start\":47310},{\"end\":47334,\"start\":47323},{\"end\":47353,\"start\":47348},{\"end\":47368,\"start\":47361},{\"end\":47756,\"start\":47747},{\"end\":47773,\"start\":47762},{\"end\":47787,\"start\":47782},{\"end\":47801,\"start\":47794},{\"end\":47813,\"start\":47810},{\"end\":47827,\"start\":47820},{\"end\":47845,\"start\":47832},{\"end\":47859,\"start\":47853},{\"end\":47874,\"start\":47867},{\"end\":47893,\"start\":47888},{\"end\":48129,\"start\":48123},{\"end\":48143,\"start\":48136},{\"end\":48165,\"start\":48154},{\"end\":48181,\"start\":48173},{\"end\":48322,\"start\":48316},{\"end\":48336,\"start\":48329},{\"end\":48352,\"start\":48346},{\"end\":48536,\"start\":48529},{\"end\":48550,\"start\":48543},{\"end\":48563,\"start\":48557},{\"end\":48580,\"start\":48571},{\"end\":48593,\"start\":48588},{\"end\":48608,\"start\":48603},{\"end\":48618,\"start\":48612},{\"end\":48636,\"start\":48626},{\"end\":48696,\"start\":48691},{\"end\":48709,\"start\":48702},{\"end\":48719,\"start\":48713},{\"end\":48730,\"start\":48723},{\"end\":48740,\"start\":48734},{\"end\":48756,\"start\":48744},{\"end\":48767,\"start\":48760},{\"end\":48888,\"start\":48880},{\"end\":48902,\"start\":48898},{\"end\":48918,\"start\":48911},{\"end\":48939,\"start\":48925},{\"end\":48956,\"start\":48951},{\"end\":48965,\"start\":48963},{\"end\":48979,\"start\":48972},{\"end\":48993,\"start\":48985},{\"end\":49002,\"start\":49000},{\"end\":49153,\"start\":49149},{\"end\":49168,\"start\":49162},{\"end\":49182,\"start\":49175},{\"end\":49198,\"start\":49190},{\"end\":49623,\"start\":49621},{\"end\":49639,\"start\":49637},{\"end\":49663,\"start\":49650},{\"end\":49677,\"start\":49673},{\"end\":49694,\"start\":49690},{\"end\":49708,\"start\":49701},{\"end\":49721,\"start\":49717},{\"end\":49735,\"start\":49731},{\"end\":49750,\"start\":49744},{\"end\":49773,\"start\":49759},{\"end\":49784,\"start\":49782},{\"end\":49796,\"start\":49793},{\"end\":49813,\"start\":49806},{\"end\":49826,\"start\":49820},{\"end\":49843,\"start\":49836},{\"end\":49858,\"start\":49853},{\"end\":49873,\"start\":49866},{\"end\":49887,\"start\":49883},{\"end\":49904,\"start\":49897},{\"end\":49917,\"start\":49913},{\"end\":49931,\"start\":49927},{\"end\":49945,\"start\":49939},{\"end\":49963,\"start\":49959},{\"end\":49977,\"start\":49970},{\"end\":49992,\"start\":49989},{\"end\":50010,\"start\":50003},{\"end\":50021,\"start\":50017},{\"end\":50040,\"start\":50033},{\"end\":50051,\"start\":50042},{\"end\":50330,\"start\":50326},{\"end\":50342,\"start\":50339},{\"end\":50357,\"start\":50352},{\"end\":50366,\"start\":50362},{\"end\":50376,\"start\":50373},{\"end\":50633,\"start\":50630},{\"end\":50648,\"start\":50643},{\"end\":50667,\"start\":50657},{\"end\":50682,\"start\":50676},{\"end\":50695,\"start\":50691},{\"end\":50709,\"start\":50702},{\"end\":50941,\"start\":50937},{\"end\":50961,\"start\":50953},{\"end\":50978,\"start\":50969},{\"end\":50998,\"start\":50987},{\"end\":51008,\"start\":51003},{\"end\":51022,\"start\":51018},{\"end\":51036,\"start\":51032},{\"end\":51055,\"start\":51044},{\"end\":51066,\"start\":51062},{\"end\":51074,\"start\":51068}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":212821571},\"end\":37499,\"start\":37204},{\"attributes\":{\"doi\":\"arXiv:2211.09260\",\"id\":\"b1\"},\"end\":37696,\"start\":37501},{\"attributes\":{\"doi\":\"arXiv:2202.05144\",\"id\":\"b2\"},\"end\":37878,\"start\":37698},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":218971783},\"end\":38130,\"start\":37880},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":211068995},\"end\":38313,\"start\":38132},{\"attributes\":{\"doi\":\"arXiv:2210.11416\",\"id\":\"b5\"},\"end\":38532,\"start\":38315},{\"attributes\":{\"doi\":\"arXiv:2003.10555\",\"id\":\"b6\"},\"end\":38710,\"start\":38534},{\"attributes\":{\"doi\":\"arXiv:2209.11755\",\"id\":\"b7\"},\"end\":38924,\"start\":38712},{\"attributes\":{\"doi\":\"10.18653/v1/N19-1423\",\"id\":\"b8\",\"matched_paper_id\":52967399},\"end\":39452,\"start\":38926},{\"attributes\":{\"doi\":\"arXiv:2212.10381\",\"id\":\"b9\"},\"end\":39651,\"start\":39454},{\"attributes\":{\"doi\":\"arXiv:2109.10086\",\"id\":\"b10\"},\"end\":39835,\"start\":39653},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":211204736},\"end\":40010,\"start\":39837},{\"attributes\":{\"doi\":\"10.1145/3196826\",\"id\":\"b12\",\"matched_paper_id\":4763454},\"end\":40158,\"start\":40012},{\"attributes\":{\"doi\":\"arXiv:2111.09543\",\"id\":\"b13\"},\"end\":40343,\"start\":40160},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":245007179},\"end\":40552,\"start\":40345},{\"attributes\":{\"id\":\"b15\"},\"end\":40734,\"start\":40554},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1031\",\"id\":\"b16\",\"matched_paper_id\":40100965},\"end\":41090,\"start\":40736},{\"attributes\":{\"doi\":\"arXiv:1905.01969\",\"id\":\"b17\"},\"end\":41304,\"start\":41092},{\"attributes\":{\"doi\":\"10.48550/ARXIV.2112.09118\",\"id\":\"b18\"},\"end\":41518,\"start\":41306},{\"attributes\":{\"doi\":\"arXiv:2208.03299\",\"id\":\"b19\"},\"end\":41769,\"start\":41520},{\"attributes\":{\"doi\":\"arXiv:2301.01820\",\"id\":\"b20\"},\"end\":42008,\"start\":41771},{\"attributes\":{\"id\":\"b21\"},\"end\":42185,\"start\":42010},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":230437663},\"end\":42374,\"start\":42187},{\"attributes\":{\"doi\":\"10.1145/3397271.3401075\",\"id\":\"b23\",\"matched_paper_id\":255186555},\"end\":43025,\"start\":42376},{\"attributes\":{\"id\":\"b24\"},\"end\":43134,\"start\":43027},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":211987786},\"end\":43443,\"start\":43136},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":86611921},\"end\":43740,\"start\":43445},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":173990818},\"end\":44102,\"start\":43742},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":218869575},\"end\":44382,\"start\":44104},{\"attributes\":{\"id\":\"b29\"},\"end\":44607,\"start\":44384},{\"attributes\":{\"id\":\"b30\"},\"end\":44791,\"start\":44609},{\"attributes\":{\"id\":\"b31\"},\"end\":45057,\"start\":44793},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":1289517},\"end\":45235,\"start\":45059},{\"attributes\":{\"id\":\"b33\"},\"end\":45334,\"start\":45237},{\"attributes\":{\"id\":\"b34\"},\"end\":45433,\"start\":45336},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":202786778},\"end\":45708,\"start\":45435},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":221507798},\"end\":46179,\"start\":45710},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":47018994},\"end\":46543,\"start\":46181},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":11816014},\"end\":46906,\"start\":46545},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":248887228},\"end\":47205,\"start\":46908},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":244799249},\"end\":47738,\"start\":47207},{\"attributes\":{\"id\":\"b41\"},\"end\":48009,\"start\":47740},{\"attributes\":{\"id\":\"b42\"},\"end\":48217,\"start\":48011},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":233296016},\"end\":48493,\"start\":48219},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":13756489},\"end\":48797,\"start\":48495},{\"attributes\":{\"id\":\"b45\"},\"end\":49054,\"start\":48799},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":245131402},\"end\":49569,\"start\":49056},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":216056360},\"end\":50219,\"start\":49571},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":229923069},\"end\":50540,\"start\":50221},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":238857091},\"end\":50873,\"start\":50542},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":250390686},\"end\":51234,\"start\":50875}]", "bib_title": "[{\"end\":37257,\"start\":37204},{\"end\":37917,\"start\":37880},{\"end\":38192,\"start\":38132},{\"end\":39006,\"start\":38926},{\"end\":39884,\"start\":39837},{\"end\":40071,\"start\":40012},{\"end\":40447,\"start\":40345},{\"end\":40796,\"start\":40736},{\"end\":42254,\"start\":42187},{\"end\":42471,\"start\":42376},{\"end\":43190,\"start\":43136},{\"end\":43507,\"start\":43445},{\"end\":43811,\"start\":43742},{\"end\":44168,\"start\":44104},{\"end\":45124,\"start\":45059},{\"end\":45503,\"start\":45435},{\"end\":45766,\"start\":45710},{\"end\":46239,\"start\":46181},{\"end\":46604,\"start\":46545},{\"end\":46965,\"start\":46908},{\"end\":47285,\"start\":47207},{\"end\":48307,\"start\":48219},{\"end\":48520,\"start\":48495},{\"end\":48872,\"start\":48799},{\"end\":49141,\"start\":49056},{\"end\":49614,\"start\":49571},{\"end\":50317,\"start\":50221},{\"end\":50625,\"start\":50542},{\"end\":50929,\"start\":50875}]", "bib_author": "[{\"end\":37279,\"start\":37259},{\"end\":37293,\"start\":37279},{\"end\":37312,\"start\":37293},{\"end\":37325,\"start\":37312},{\"end\":37338,\"start\":37325},{\"end\":37353,\"start\":37338},{\"end\":37367,\"start\":37353},{\"end\":37384,\"start\":37367},{\"end\":37513,\"start\":37501},{\"end\":37526,\"start\":37513},{\"end\":37541,\"start\":37526},{\"end\":37553,\"start\":37541},{\"end\":37570,\"start\":37553},{\"end\":37588,\"start\":37570},{\"end\":37609,\"start\":37588},{\"end\":37622,\"start\":37609},{\"end\":37795,\"start\":37779},{\"end\":37810,\"start\":37795},{\"end\":37826,\"start\":37810},{\"end\":37844,\"start\":37826},{\"end\":37930,\"start\":37919},{\"end\":37945,\"start\":37930},{\"end\":37957,\"start\":37945},{\"end\":37974,\"start\":37957},{\"end\":37990,\"start\":37974},{\"end\":38009,\"start\":37990},{\"end\":38029,\"start\":38009},{\"end\":38043,\"start\":38029},{\"end\":38058,\"start\":38043},{\"end\":38073,\"start\":38058},{\"end\":38211,\"start\":38194},{\"end\":38223,\"start\":38211},{\"end\":38238,\"start\":38223},{\"end\":38251,\"start\":38238},{\"end\":38265,\"start\":38251},{\"end\":38332,\"start\":38315},{\"end\":38340,\"start\":38332},{\"end\":38356,\"start\":38340},{\"end\":38369,\"start\":38356},{\"end\":38377,\"start\":38369},{\"end\":38392,\"start\":38377},{\"end\":38401,\"start\":38392},{\"end\":38414,\"start\":38401},{\"end\":38432,\"start\":38414},{\"end\":38451,\"start\":38432},{\"end\":38547,\"start\":38534},{\"end\":38565,\"start\":38547},{\"end\":38576,\"start\":38565},{\"end\":38599,\"start\":38576},{\"end\":38724,\"start\":38712},{\"end\":38735,\"start\":38724},{\"end\":38744,\"start\":38735},{\"end\":38751,\"start\":38744},{\"end\":38764,\"start\":38751},{\"end\":38773,\"start\":38764},{\"end\":38783,\"start\":38773},{\"end\":38799,\"start\":38783},{\"end\":38812,\"start\":38799},{\"end\":38827,\"start\":38812},{\"end\":38834,\"start\":38827},{\"end\":39022,\"start\":39008},{\"end\":39038,\"start\":39022},{\"end\":39050,\"start\":39038},{\"end\":39070,\"start\":39050},{\"end\":39577,\"start\":39565},{\"end\":39592,\"start\":39577},{\"end\":39606,\"start\":39592},{\"end\":39617,\"start\":39606},{\"end\":39670,\"start\":39653},{\"end\":39687,\"start\":39670},{\"end\":39708,\"start\":39687},{\"end\":39728,\"start\":39708},{\"end\":39898,\"start\":39886},{\"end\":39910,\"start\":39898},{\"end\":39921,\"start\":39910},{\"end\":40095,\"start\":40073},{\"end\":40282,\"start\":40268},{\"end\":40296,\"start\":40282},{\"end\":40309,\"start\":40296},{\"end\":40460,\"start\":40449},{\"end\":40474,\"start\":40460},{\"end\":40487,\"start\":40474},{\"end\":40665,\"start\":40643},{\"end\":40683,\"start\":40665},{\"end\":40701,\"start\":40683},{\"end\":40715,\"start\":40701},{\"end\":40730,\"start\":40715},{\"end\":40813,\"start\":40798},{\"end\":40830,\"start\":40813},{\"end\":41222,\"start\":41207},{\"end\":41236,\"start\":41222},{\"end\":41256,\"start\":41236},{\"end\":41270,\"start\":41256},{\"end\":41391,\"start\":41374},{\"end\":41407,\"start\":41391},{\"end\":41423,\"start\":41407},{\"end\":41441,\"start\":41423},{\"end\":41459,\"start\":41441},{\"end\":41474,\"start\":41459},{\"end\":41489,\"start\":41474},{\"end\":41597,\"start\":41580},{\"end\":41612,\"start\":41597},{\"end\":41626,\"start\":41612},{\"end\":41642,\"start\":41626},{\"end\":41657,\"start\":41642},{\"end\":41670,\"start\":41657},{\"end\":41687,\"start\":41670},{\"end\":41702,\"start\":41687},{\"end\":41720,\"start\":41702},{\"end\":41735,\"start\":41720},{\"end\":41879,\"start\":41863},{\"end\":41895,\"start\":41879},{\"end\":41910,\"start\":41895},{\"end\":41926,\"start\":41910},{\"end\":41942,\"start\":41926},{\"end\":41956,\"start\":41942},{\"end\":41974,\"start\":41956},{\"end\":42079,\"start\":42063},{\"end\":42092,\"start\":42079},{\"end\":42110,\"start\":42092},{\"end\":42125,\"start\":42110},{\"end\":42148,\"start\":42125},{\"end\":42170,\"start\":42148},{\"end\":42181,\"start\":42170},{\"end\":42270,\"start\":42256},{\"end\":42289,\"start\":42270},{\"end\":42304,\"start\":42289},{\"end\":42487,\"start\":42473},{\"end\":42505,\"start\":42487},{\"end\":42517,\"start\":42505},{\"end\":42527,\"start\":42517},{\"end\":42539,\"start\":42527},{\"end\":42558,\"start\":42539},{\"end\":42571,\"start\":42558},{\"end\":42580,\"start\":42571},{\"end\":43039,\"start\":43027},{\"end\":43053,\"start\":43039},{\"end\":43057,\"start\":43053},{\"end\":43205,\"start\":43192},{\"end\":43225,\"start\":43205},{\"end\":43236,\"start\":43225},{\"end\":43526,\"start\":43509},{\"end\":43547,\"start\":43526},{\"end\":43564,\"start\":43547},{\"end\":43581,\"start\":43564},{\"end\":43595,\"start\":43581},{\"end\":43610,\"start\":43595},{\"end\":43628,\"start\":43610},{\"end\":43646,\"start\":43628},{\"end\":43660,\"start\":43646},{\"end\":43672,\"start\":43660},{\"end\":43825,\"start\":43813},{\"end\":43841,\"start\":43825},{\"end\":43861,\"start\":43841},{\"end\":44185,\"start\":44170},{\"end\":44198,\"start\":44185},{\"end\":44217,\"start\":44198},{\"end\":44232,\"start\":44217},{\"end\":44252,\"start\":44232},{\"end\":44265,\"start\":44252},{\"end\":44283,\"start\":44265},{\"end\":44295,\"start\":44283},{\"end\":44308,\"start\":44295},{\"end\":44325,\"start\":44308},{\"end\":44396,\"start\":44384},{\"end\":44406,\"start\":44396},{\"end\":44419,\"start\":44406},{\"end\":44431,\"start\":44419},{\"end\":44445,\"start\":44431},{\"end\":44457,\"start\":44445},{\"end\":44468,\"start\":44457},{\"end\":44480,\"start\":44468},{\"end\":44498,\"start\":44480},{\"end\":44516,\"start\":44498},{\"end\":44702,\"start\":44695},{\"end\":44717,\"start\":44702},{\"end\":44730,\"start\":44717},{\"end\":44742,\"start\":44730},{\"end\":44757,\"start\":44742},{\"end\":44924,\"start\":44914},{\"end\":44932,\"start\":44924},{\"end\":44945,\"start\":44932},{\"end\":44963,\"start\":44945},{\"end\":44972,\"start\":44963},{\"end\":44981,\"start\":44972},{\"end\":44996,\"start\":44981},{\"end\":45010,\"start\":44996},{\"end\":45023,\"start\":45010},{\"end\":45138,\"start\":45126},{\"end\":45153,\"start\":45138},{\"end\":45163,\"start\":45153},{\"end\":45177,\"start\":45163},{\"end\":45193,\"start\":45177},{\"end\":45210,\"start\":45193},{\"end\":45219,\"start\":45210},{\"end\":45255,\"start\":45237},{\"end\":45270,\"start\":45255},{\"end\":45387,\"start\":45369},{\"end\":45398,\"start\":45387},{\"end\":45413,\"start\":45398},{\"end\":45518,\"start\":45505},{\"end\":45529,\"start\":45518},{\"end\":45546,\"start\":45529},{\"end\":45558,\"start\":45546},{\"end\":45574,\"start\":45558},{\"end\":45590,\"start\":45574},{\"end\":45606,\"start\":45590},{\"end\":45618,\"start\":45606},{\"end\":45638,\"start\":45618},{\"end\":45651,\"start\":45638},{\"end\":45783,\"start\":45768},{\"end\":45802,\"start\":45783},{\"end\":45814,\"start\":45802},{\"end\":45829,\"start\":45814},{\"end\":45844,\"start\":45829},{\"end\":45859,\"start\":45844},{\"end\":45873,\"start\":45859},{\"end\":45889,\"start\":45873},{\"end\":45909,\"start\":45889},{\"end\":45924,\"start\":45909},{\"end\":45945,\"start\":45924},{\"end\":45962,\"start\":45945},{\"end\":45980,\"start\":45962},{\"end\":46259,\"start\":46241},{\"end\":46270,\"start\":46259},{\"end\":46283,\"start\":46270},{\"end\":46624,\"start\":46606},{\"end\":46636,\"start\":46624},{\"end\":46656,\"start\":46636},{\"end\":46669,\"start\":46656},{\"end\":46985,\"start\":46967},{\"end\":46999,\"start\":46985},{\"end\":47018,\"start\":46999},{\"end\":47033,\"start\":47018},{\"end\":47305,\"start\":47287},{\"end\":47319,\"start\":47305},{\"end\":47336,\"start\":47319},{\"end\":47355,\"start\":47336},{\"end\":47370,\"start\":47355},{\"end\":47758,\"start\":47740},{\"end\":47775,\"start\":47758},{\"end\":47789,\"start\":47775},{\"end\":47803,\"start\":47789},{\"end\":47815,\"start\":47803},{\"end\":47829,\"start\":47815},{\"end\":47847,\"start\":47829},{\"end\":47861,\"start\":47847},{\"end\":47876,\"start\":47861},{\"end\":47895,\"start\":47876},{\"end\":48131,\"start\":48116},{\"end\":48145,\"start\":48131},{\"end\":48167,\"start\":48145},{\"end\":48183,\"start\":48167},{\"end\":48324,\"start\":48309},{\"end\":48338,\"start\":48324},{\"end\":48354,\"start\":48338},{\"end\":48538,\"start\":48522},{\"end\":48552,\"start\":48538},{\"end\":48565,\"start\":48552},{\"end\":48582,\"start\":48565},{\"end\":48595,\"start\":48582},{\"end\":48610,\"start\":48595},{\"end\":48620,\"start\":48610},{\"end\":48638,\"start\":48620},{\"end\":48890,\"start\":48874},{\"end\":48904,\"start\":48890},{\"end\":48920,\"start\":48904},{\"end\":48941,\"start\":48920},{\"end\":48958,\"start\":48941},{\"end\":48967,\"start\":48958},{\"end\":48981,\"start\":48967},{\"end\":48995,\"start\":48981},{\"end\":49004,\"start\":48995},{\"end\":49011,\"start\":49004},{\"end\":49155,\"start\":49143},{\"end\":49170,\"start\":49155},{\"end\":49184,\"start\":49170},{\"end\":49200,\"start\":49184},{\"end\":49625,\"start\":49616},{\"end\":49632,\"start\":49625},{\"end\":49641,\"start\":49632},{\"end\":49665,\"start\":49641},{\"end\":49679,\"start\":49665},{\"end\":49696,\"start\":49679},{\"end\":49710,\"start\":49696},{\"end\":49723,\"start\":49710},{\"end\":49737,\"start\":49723},{\"end\":49752,\"start\":49737},{\"end\":49775,\"start\":49752},{\"end\":49786,\"start\":49775},{\"end\":49798,\"start\":49786},{\"end\":49815,\"start\":49798},{\"end\":49828,\"start\":49815},{\"end\":49845,\"start\":49828},{\"end\":49860,\"start\":49845},{\"end\":49875,\"start\":49860},{\"end\":49889,\"start\":49875},{\"end\":49906,\"start\":49889},{\"end\":49919,\"start\":49906},{\"end\":49933,\"start\":49919},{\"end\":49947,\"start\":49933},{\"end\":49965,\"start\":49947},{\"end\":49979,\"start\":49965},{\"end\":49994,\"start\":49979},{\"end\":50012,\"start\":49994},{\"end\":50023,\"start\":50012},{\"end\":50042,\"start\":50023},{\"end\":50053,\"start\":50042},{\"end\":50332,\"start\":50319},{\"end\":50344,\"start\":50332},{\"end\":50359,\"start\":50344},{\"end\":50368,\"start\":50359},{\"end\":50378,\"start\":50368},{\"end\":50635,\"start\":50627},{\"end\":50650,\"start\":50635},{\"end\":50669,\"start\":50650},{\"end\":50684,\"start\":50669},{\"end\":50697,\"start\":50684},{\"end\":50711,\"start\":50697},{\"end\":50943,\"start\":50931},{\"end\":50963,\"start\":50943},{\"end\":50980,\"start\":50963},{\"end\":51000,\"start\":50980},{\"end\":51010,\"start\":51000},{\"end\":51024,\"start\":51010},{\"end\":51038,\"start\":51024},{\"end\":51057,\"start\":51038},{\"end\":51068,\"start\":51057},{\"end\":51076,\"start\":51068}]", "bib_venue": "[{\"end\":37445,\"start\":37384},{\"end\":37676,\"start\":37638},{\"end\":37777,\"start\":37698},{\"end\":38122,\"start\":38073},{\"end\":38307,\"start\":38265},{\"end\":38512,\"start\":38467},{\"end\":38690,\"start\":38615},{\"end\":38904,\"start\":38850},{\"end\":39232,\"start\":39090},{\"end\":39255,\"start\":39234},{\"end\":39563,\"start\":39454},{\"end\":39815,\"start\":39744},{\"end\":39965,\"start\":39921},{\"end\":40150,\"start\":40110},{\"end\":40266,\"start\":40160},{\"end\":40548,\"start\":40487},{\"end\":40641,\"start\":40554},{\"end\":40937,\"start\":40850},{\"end\":40950,\"start\":40939},{\"end\":41205,\"start\":41092},{\"end\":41372,\"start\":41306},{\"end\":41578,\"start\":41520},{\"end\":41861,\"start\":41771},{\"end\":42061,\"start\":42010},{\"end\":42368,\"start\":42304},{\"end\":42757,\"start\":42619},{\"end\":43114,\"start\":43072},{\"end\":43317,\"start\":43236},{\"end\":43733,\"start\":43672},{\"end\":43968,\"start\":43881},{\"end\":44374,\"start\":44325},{\"end\":44587,\"start\":44532},{\"end\":44693,\"start\":44609},{\"end\":44912,\"start\":44793},{\"end\":45229,\"start\":45219},{\"end\":45314,\"start\":45286},{\"end\":45367,\"start\":45336},{\"end\":45700,\"start\":45651},{\"end\":46075,\"start\":46011},{\"end\":46390,\"start\":46303},{\"end\":46775,\"start\":46689},{\"end\":47123,\"start\":47033},{\"end\":47543,\"start\":47401},{\"end\":47988,\"start\":47911},{\"end\":48114,\"start\":48011},{\"end\":48448,\"start\":48354},{\"end\":48687,\"start\":48638},{\"end\":49026,\"start\":49011},{\"end\":49373,\"start\":49231},{\"end\":50116,\"start\":50053},{\"end\":50485,\"start\":50411},{\"end\":50811,\"start\":50744},{\"end\":51179,\"start\":51110},{\"end\":37493,\"start\":37447},{\"end\":39406,\"start\":39257},{\"end\":41044,\"start\":40952},{\"end\":42887,\"start\":42759},{\"end\":43398,\"start\":43319},{\"end\":44057,\"start\":43970},{\"end\":46126,\"start\":46077},{\"end\":46484,\"start\":46392},{\"end\":46861,\"start\":46777},{\"end\":47200,\"start\":47125},{\"end\":47685,\"start\":47545},{\"end\":49045,\"start\":49028},{\"end\":49524,\"start\":49375},{\"end\":50166,\"start\":50118},{\"end\":50828,\"start\":50813}]"}}}, "year": 2023, "month": 12, "day": 17}