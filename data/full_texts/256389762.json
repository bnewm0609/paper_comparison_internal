{"id": 256389762, "updated": "2023-10-05 04:48:10.121", "metadata": {"title": "On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex", "authors": "[{\"first\":\"Terry Yue\",\"last\":\"Zhuo\",\"middle\":[]},{\"first\":\"Zhuang\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Yujin\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Fatemeh\",\"last\":\"Shiri\",\"middle\":[]},{\"first\":\"Weiqing\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Gholamreza\",\"last\":\"Haffari\",\"middle\":[]},{\"first\":\"Yuan-fang\",\"last\":\"Li\",\"middle\":[]}]", "venue": "EACL", "journal": "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Semantic parsing is a technique aimed at constructing a structured representation of the meaning of a natural-language question. Recent advances in language models trained on code have shown superior performance in generating these representations compared to language models trained solely on natural language text. The existing fine-tuned neural semantic parsers are vulnerable to adversarial attacks on natural-language inputs. While it has been established that the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios, as it requires both substantial computational resources and expensive human annotation on in-domain semantic parsing data. This paper presents the first empirical study on the adversarial robustness of a prompt-based semantic parser based on CODEX, a stateof-the-art (SOTA) language model trained on code. Our results demonstrate that the large language model of code is vulnerable to carefully crafted adversarial examples. To overcome this challenge, we propose methods for enhancing robustness without requiring substantial amounts of labelled data or intensive computational resources.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2301.12868", "mag": null, "acl": "2023.eacl-main.77", "pubmed": null, "pubmedcentral": null, "dblp": "conf/eacl/ZhuoLHSWHL23", "doi": "10.18653/v1/2023.eacl-main.77"}}, "content": {"source": {"pdf_hash": "38ae362396e8eea404810e72859121f441c39340", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2023.eacl-main.77.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "16b3a9e19f7651d0331372837f341e65f62d538b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/38ae362396e8eea404810e72859121f441c39340.txt", "contents": "\nOn Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex\nMay 2-6, 2023\n\nTerry Yue Zhuo terry.zhuo@monash.edu \nZhuang Li zhuang.li@monash.edu \nMonash University\nAustralia\n\nYujin Huang \nMonash University\nAustralia\n\nFatemeh Shiri \nMonash University\nAustralia\n\nWeiqing Wang \nMonash University\nAustralia\n\nGholamreza Haffari \nMonash University\nAustralia\n\nYuan-Fang Li \nMonash University\nAustralia\n\n\nCSIRO's Data61\nAustralia\n\nOn Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex\n\nProceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics\nthe 17th Conference of the European Chapter of the Association for Computational LinguisticsMay 2-6, 2023\nSemantic parsing is a technique aimed at constructing a structured representation of the meaning of a natural-language question. Recent advances in language models trained on code have shown superior performance in generating these representations compared to language models trained solely on natural language text. The existing fine-tuned neural semantic parsers are vulnerable to adversarial attacks on natural-language inputs. While it has been established that the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios, as it requires both substantial computational resources and expensive human annotation on in-domain semantic parsing data. This paper presents the first empirical study on the adversarial robustness of a prompt-based semantic parser based on CODEX, a state-ofthe-art (SOTA) language model trained on code. Our results demonstrate that the large language model of code is vulnerable to carefully crafted adversarial examples. To overcome this challenge, we propose methods for enhancing robustness without requiring substantial amounts of labelled data or intensive computational resources.\n\nIntroduction\n\nSemantic parsing is a technique that transforms natural-language utterances (NLs) into machinereadable logical forms (LFs) and has been widely applied in various research fields, such as code generation, question-answering systems, and dialogue systems (Kamath and Das, 2018). Most current state-of-the-art semantic parsers are deep-learning models trained in a supervised manner using indomain data. However, this approach requires a large amount of in-domain semantic parsing data, which can be costly to obtain (Bapna et al., 2017). * corresponding author To address this issue, prompt-based semantic parsers based on large pre-trained language models, such as Codex  and GPT-J (Wang and Komatsuzaki, 2021), have become a new choice for semantic parsing applications. Prompt-based semantic parsers learn to solve a new task by in-context learning, instructing the parsers to generate correct LFs by constructing the prompt with a few demonstration examples. Such a method can significantly lower the cost of annotations by including only a few exemplars in the prompt and achieve comparable results to fully-supervised semantic parsers (Shin and Van Durme, 2022).\n\nRecent studies (Huang et al., 2021;Pi et al., 2022) show that fully-supervised semantic parsers are vulnerable to adversarial attacks, which perturb input sentences into their semantic equivalent adversaries to mislead models to produce attackerdesired outputs. Hence, to mitigate such attacks, various adversarial training methods (Tramer and Boneh, 2019;Shafahi et al., 2019;Ganin et al., 2016;Shafahi et al., 2020) have been proposed to improve the adversarial robustness of the semantic parsers. In light of this, two main questions naturally arise: (1) Do prompt-based semantic parsers based on large pre-trained language models also suffer from adversarial attacks? (2) If so, how can we improve the robustness of the large promptbased semantic parsers?\n\nTo address the former question, we evaluate the prompt-based semantic parsers on several evaluation sets built by different perturbation approaches mentioned in the AdvGLUE  dataset. Adopting the adversarial evaluation metrics proposed by Huang et al. (2021), it is found that the prompt-based semantic parsers are vulnerable to various types of adversarial attacks.\n\nAccording to the experimental results from the first step, we perform a three-fold experiment to answer the latter questions. The first aspect of the study aims to determine if the inclusion of additional examples within the prompt during incontext learning improves the robustness of promptbased parsers. This hypothesis is based on prior research that has demonstrated that the increase in the size of the training data results in an enhancement of robustness in fully-supervised models (Pang et al., 2019). The second part of the study aims to determine if the integration of few-shot adversarial examples within prompts can improve the robustness of Codex. This was based on the observation that conventional adversarial training methods often include adversarial examples within the training set (Miyato et al., 2016;Tramer and Boneh, 2019). Finally, the third part of the study aims to evaluate if sampling methods other than random sampling can select more effective examples that improve the robustness of prompt-based parsers.\n\nIn this work, we perform a series of experiments to probe CODEX, a large pre-trained model trained on code, on two semantic parsing benchmarks, GeoQuery (Zelle and Mooney, 1996) and Scholar (Iyer et al., 2017). Our key findings from the above experiments are as follows:\n\n\u2022 Prompt-based semantic parsers are vulnerable\n\nto adversarial examples, particularly the ones crafted by sentence-level perturbations.\n\n\u2022 In-context learning with more demonstration examples in the prompt can improve the indomain robustness of prompt-based parsers.\n\n\u2022 Augmenting the prompt with adversarial examples has limited effect in improving the robustness of prompt-based parsers.\n\n\u2022 The few-shot example sampling strategy with higher language complexity can result in stronger robustness for the prompt-based parsers.\n\n\nRelated Work\n\nPrompt-based Learning. Prompt-based learning is an alternative approach to supervised learning that aims to reduce the reliance on large humanannotated datasets . Unlike traditional supervised models, which estimate the probability of an output given an input text, promptbased learning models estimate the probability of the text directly. This is achieved by applying prompt functions to modify the input text into various prompt templates with unfilled slots. By filling these slots, various Natural Language Processing (NLP) tasks can be completed, such as common-sense reasoning (Kojima et al., 2022), self-rationalization (Marasovi\u0107 et al., 2021), and text style transfer (Suzgun et al., 2022). The development of prompt-based methods has enabled zeroshot and few-shot learning in a variety of artificial intelligence domains (Ramesh et al., 2021;Yang et al., 2022;Sanghi et al., 2022). Recent research has also evaluated the capabilities of few-shot prompt-based learning for semantic parsing (Shin and Van Durme, 2022;Roy et al., 2022a;Drozdov et al., 2022 (Hosseini et al., 2017;Ebrahimi et al., 2018;Belinkov and Bisk, 2018;Gao et al., 2018;Eger et al., 2019;Boucher et al., 2022), sentencelevel rewriting (Iyyer et al., 2018;Ribeiro et al., 2018;Zhao et al., 2018), and adversarial word substitutions (Alzantot et al., 2018;Liang et al., 2018;Zhang et al., 2019).\n\nThere has been an increasing interest in defending against adversarial attacks in large language models via adversarial training (Yi et al., 2021;Bartolo et al., 2021;Guo et al., 2021). Adversarial training involves incorporating adversarial examples in the training set, thus making the model robust to such attacks. However, adversarial training can sometimes negatively impact the generalization ability of the neural models (Raghunathan et al., 2019;Min et al., 2021).\n\n\nRobustness Evaluation for Prompt-based Semantic Parsing\n\nThis section gives an overview of our evaluation framework, including the methods of constructing the evaluation corpora and the evaluation metrics to evaluate the robustness of the prompt-based semantic parser.  \n\n\nConstruction of the Evaluation Corpus\n\nA robust prompt-based semantic parser should be able to parse both the utterances and their adversarial counterparts into correct LFs. As proposed by Huang et al. (2021), an adversary of an utterance for a semantic parser is defined as i) an utterance with the same semantic meanings as the original one given the human judgment and ii) an utterance on which the semantic parser cannot produce correct LF. Therefore, to evaluate the robustness of prompt-based semantic parsers, we craft the robustness evaluation sets by perturbing the original utterances in existing benchmark datasets with multiple adversarial perturbation methods. Such perturbations should not alter the semantics of the original utterances. Each example in a robustness evaluation set is a perturbed utterance paired with its ground-truth LF. Next, we introduce the details of each perturbation method and how we guarantee the perturbations do not change the semantics. Table 1 illustrates some meaning-preserved utterances after perturbation in the robustness evaluation set of GeoQuery based on different perturbation methods. More examples can be found in Appendix B.\n\n\nAdversarial Perturbations\n\nFollowing the principles as in  to design adversarial attacks, we perform five wordlevel perturbations and two sentence-level perturbations to generate seven robustness evaluation sets for the standard evaluation set in each benchmark.\n\nWord-level Perturbations.\n\n\u2022 Typo-based (TB) uses TextBugger  to replace two words in each utterance with the typos.\n\n\u2022 Random Deletion (RD) randomly deletes two words in the utterance.\n\n\u2022 Random Swap (RS) swaps the positions of two random words in each utterance.\n\n\u2022 Context-aware Substitution (CS) leverages RoBERTa (Liu et al., 2019) to substitute two random words with their synonyms.\n\n\u2022 Context-aware Insertion (CI) inserts two most probable words selected by RoBERTa at two random positions in each utterance.\n\nSentence-level Perturbations.\n\n\u2022 Rewriting-based (RB) chooses Quillbot 1 (Fitria, 2021), a state-of-the-art (SOTA) commercial paraphrasing model, to rewrite the complete utterances. Quillbot has been demonstrated as an effective tool to paraphrase utterances in semantic parsing data (Shiri et al., 2022).\n\n\u2022 Distraction-based (DB) appends interrogation statements to the end of each NL, inspired by StressTest (Naik et al., 2018). Specifically, we design the following interrogation statements: \"who is who; what is what; when is when; which is which; where is where\", in which the selected interrogative words are more likely to appear in the utterance.\n\n\nData Filtering\n\nIn order to ensure that the perturbed examples preserve the meaning of the original NL, we design a two-stage evaluation process:\n\nStep1: We first generate 20 adversarial examples against the original NL for each perturbation method and choose the top 10 candidates ranked based on text similarity scores between the original and the perturbed ones, which are calculated by Sentence-BERT (Reimers and Gurevych, 2019).\n\nStep2: We engage human experts to select the best one among the 10 adversarial candidates produced in Step1.\n\n\nEvaluation Metrics\n\nSince the output LFs of the prompt-based language models may not follow the same naming convention (Shin et al., 2021;Shin and Van Durme, 2022) as the ground truth, previous string-based evaluation metrics, including BLEU (Papineni et al., 2002) and Exact Match (Poon and Domingos, 2009), are not suitable for prompt-based semantic parsers. Therefore, we follow Rajkumar et al. (2022) to report the execution accuracy, which is based solely on the execution correctness of the LFs on the test sets, for the purpose of robustness evaluation.\n\nFollowing Huang et al. (2021), we report the experiment results with three variants of execution accuracy, namely standard accuracy, perturbation accuracy and robust accuracy:\n\n\u2022 Standard Accuracy is measured on the standard (original) test sets.\n\n\u2022 Perturbation Accuracy tests the performance of the model on perturbed test sets.\n\n\u2022 Robust Accuracy is defined as n/|R eval |. R eval denotes a subset of the perturbed test sets, and n is the number of the utterances in R eval that are parsed correctly. More specifically, R eval consists of the examples whose counterparts before perturbation are parsed correctly. Intuitively, Robust Accuracy estimates the quantity of cases that a parser can successfully parse before perturbation but cannot do so after perturbation, and hence shows the robustness of the parsers against adversarial perturbation.\n\n\nImproving Robustness of Prompt-based Semantic Parsers\n\nInstead of predicting the LF conditioned on the input utterance, large language models such as CODEX could learn to solve a specific task by incontext learning. During in-context learning, the parser predicts the LF conditioned on a prompt which consists of a small list of utterance-LF pairs to demonstrate the semantic parsing task and, optionally, a Given the difference, it is unclear whether incontext learning could improve the robustness of the parser as the conventional supervised training. In this paper, we conduct the first investigation on in-context learning for model robustness. More specifically, we examine the impact of variants of in-context learning and sampling methods on parser robustness.\n\n\nStandard In-context Few-shot Learning\n\nIn our setting, given an input utterance x, the pretrained language model P (\u00b7; \u03b8) predicts the LF y \u2032 conditioned on the prompt, which consists of a set\nof demonstration examples M = {(x i , y i )} N i=1\n, and a table schema T :\ny \u2032 = arg max y\u2208Y P (y|x, M, T ; \u03b8)(1)\nFor the few-shot setting, the number of demonstration examples N is limited by a budget size.\n\n\nAdversarial In-context Few-shot Learning\n\nIn adversarial in-context learning, we include the perturbed adversarial examples, M adv , in the demonstration examples:\ny \u2032 = arg max y\u2208Y P (y|x, M \u222a M adv , T ; \u03b8) (2)\n\nIn-context Few-shot Selection\n\nCurrent in-context learning assumes there is an example pool from where they can select prompting examples. However, most of the works only randomly pick examples from the pools. We argue that the way to select the examples might deeply impact the robustness of the prompt-based semantic parser. Therefore, we examine various strategies to select in-context few-shot examples.\n\nRandom Sampling (Random). We randomly sample N utterances from the example pool.\n\nConfidence-based Sampling (Confidence) (Duong et al., 2018). We score each utterance with the confidence of the parser on the predicted LF given the utterance and the table schema. Then we select the ones with the lowest parser confidence scores 2 .\n\nDiversity-based Sampling. Following , we partition the utterances in the utterance pool into N clusters with the K-means (Wu, 2012) clustering algorithm and select the example closest to the cluster centers. We measure the edit distance (Cluster-ED) (Wagner and Fischer, 1974), and Euclidean distances using utterance features of TF-IDF (Cluster-TF-IDF) (Anand and Jeffrey David, 2011), or Contextual Word Embedding (Cluster-CWE) encoded by Sentence-BERT (Reimers and Gurevych, 2019), between each pair of utterances for K-means.\n\nPerplexity-based Sampling (Sen and Yilmaz, 2020). We score each utterance with the perplexity of GPT-2 on this utterance. Then we select the utterances with the highest (PPL. Asc) and lowest (PPL. Desc) perplexity scores, respectively. Prompt-based Semantic Parser. We choose CODEX  as the representative prompt-based semantic parser for our evaluation.\n\nIn recent studies, CODEX has performed comparably via in-context few-shot semantic parsing to the SOTA-supervised trained neural semantic parsers (Shin and Van Durme, 2022;Roy et al., 2022b;Drozdov et al., 2022) in terms of execution accuracy.\n\nTo examine the vulnerability of large promptbased semantic parsers against adversarial examples, we choose the code-davinci-002 version of CODEX as it is the most powerful variant among all CODEX models, with 175B parameters. In our experiments, we sample a maximum of 200 tokens from CODEX with the temperature set to 0, with the stop token to halt generation.\n\nPrompts. In this work, we adopt the prompt design of Create Table + Select X as presented in Rajkumar et al. (2022), which has been shown to be effective for semantic parsing using static prompting 3 .\n\nThe prompt for semantic parsing on CODEX consists of CREATE TABLE commands, including specifications for each table's columns, foreign key declarations, and the results of executing a SELECT * FROM T LIMIT X query on the tables via the column headers. As described in Section 4.3, we select NL-LF pairs as in-context few-shot examples from the train sets.\n\nTo guide the prompt-based semantic parser, we also include the textual instruction of \"Using valid SQLite, answer the following questions for the tables provided above.\" as proposed by Rajkumar et al. (2022).\n\n\nResearch Questions and Discussions\n\nOur experimental results answer the following four research questions (RQs) related to the robustness of CODEX.\n\n\nRQ1: How vulnerable is the prompt-based semantic parser to adversarial examples?\n\nSettings. To answer RQ1, we evaluate the standard accuracy and perturbation accuracy of CODEX on GeoQuery and Scholar test sets through zero-shot learning.\n\nResults. The zero-shot parsing performances of CODEX are shown in Table 2 Table 2: Results of perturbation accuracy (Pert. Acc.) and standard accuracy (Std. Acc.) of zero-shot performance on GeoQuery and Scholar. The zero-shot prompt only contain the table information and initial semantic parsing instruction. Perturbation accuracy is calculated based on each perturbation method.\n\ntion is that CODEX is more vulnerable to sentencelevel perturbations than to word-level perturbations, as indicated by the more significant performance gaps between standard and perturbed accuracies on the sentence-level perturbed test sets.  observed that neural language models are vulnerable to human-crafted adversarial examples where there are complex linguistic phenomenons (e.g., coreference resolution, numerical reasoning, negation). We observe that the rewriting model trained on human paraphrase pairs also introduces such complex linguistic phenomenons. With respect to the word-level perturbations, CODEX is most robust to typo-based perturbations, which is surprising as  shows typo-based perturbation is the most effective attack method for large language models like BERT (Devlin et al., 2019) in the evaluation of natural language understanding tasks. However, utterances with typos drop only 3% of the accuracy of CODEX. Random Deletion is also less effective than the other word-level methods, consistent with the observations by Huang et al. (2021) on the fullysupervised semantic parsers. This phenomenon can be attributed to the fact that Random Deletion primarily makes minor modifications to the standard NL utterances, as this method often involves removing non-functional words such as articles, for example, \"the\" and \"a.\"\n\nAlthough CODEX is pre-trained on a considerably large dataset, it does not show robustness on the in-domain tasks. We conjecture that the reason is that zero-shot CODEX has not yet learned any indomain knowledge on GeoQuery or Scholar. So in RQ2, we would address whether in-domain examples would improve the robustness of CODEX.   RQ2: Does standard in-context few-shot learning improve the robustness?\n\nSettings. We respectively select up to 50 and 10 examples from GeoQuery and Scholar train sets 4 , with the random sampling strategy, to construct prompts for parsers. Then, for each few-shot learning experiment, we measure standard accuracy, perturbation accuracy and robust accuracy on our various perturbed test sets.\n\n\nResults\n\n. Tables 3 and 4 show the performance of standard in-context few-shot learning on the robustness evaluation sets perturbed by different methods. We observe that more standard examples in the prompt can evidently improve the robust accuracy of CODEX, which demonstrates the effectiveness of standard in-context few-shot learning in improving the robustness of semantic parsing. Although it performs slightly worse on the test sets perturbed by typo-based methods than the one perturbed by the random deletion in GeoQuery, we argue that this is due to the performance variance, which does not necessarily hurt the model robustness.\n\nThe performance gap between perturbation accuracy with standard accuracy is enlarged when the number of in-context shots increases. However, the robust accuracy grows slowly. This indicates that improving the generalization ability of the parser does not necessarily mean the improvement of the robustness. The trade-off between standard and robust accuracies is a long-standing problem in adversarial training. Raghunathan et al. (2019) shows that increasing the training sample size could eliminate such a trade-off. Our experiments demonstrate that in-context learning follows similar patterns as supervised adversarial training. It can be observed that both objectives can be improved with a limited number of examples when compared to the zeroshot parser. However, the extent of improvement varies.\n\nTakeaways. With more standard in-context examples, few-shot CODEX can be guided to achieve better robustness and standard execution performance.\n\nRQ3: Does adversarial in-context learning improve robustness? Settings. In this work, we present the experimental results of CODEX on both GeoQuery and Scholar datasets, using 10 and 5 in-context examples, respectively. In order to assess the robustness of CODEX through adversarial in-context learning, we first augment the standard few-shot examples by incorporating examples whose utterances have been perturbed using various perturbation methods. Subsequently, for each set of augmented examples, we calculate the average robust accuracy of CODEX based on the average of the  parser robust accuracies on all robustness evaluation sets.\n\nResults. The experimental results of the various perturbation strategies applied to the in-context few-shot examples are presented in Table 5. While the approach of supervised adversarial training has been widely regarded as an effective means of enhancing the robustness of machine learning models, the results indicate that on both GeoQuery and Scholar, the robust accuracies are only marginally improved through the application of adversarial in-context learning. Previous studies (Raghunathan et al., 2019;Huang et al., 2021) have pointed out that supervised adversarial training can sometimes result in a decrease in standard accuracy, even as it improves robust accuracy. However, the results of adversarial in-context learning diverge from this trend, with significant improvement in standard accuracy, from 23% to more than 33%, observed on Scholar, while robust accuracy only experiences marginal improvement. These observations indicate that adversarial in-context learning represents a distinct approach from supervised adversarial training in terms of enhancing the robustness of the model. Furthermore, the results suggest that simply incorporating adversarial examples into the prompt has a limited impact on the robustness of parsers, in contrast to supervised adversarial training. Of all the perturbation strategies analyzed, the results indicate that CODEX achieves the best performance in terms of both standard and robust accuracy through the application of RB adversarial in-context learning, but experiences the worst performance through TB adversarial in-context learning. The hypothesis is that RB produces utterances   Takeaways. The robustness of few-shot CODEX can be marginally improved by adversarial incontext learning without significant negative impacts on standard performances.\n\n\nRQ4\n\n: What is the impact of sampling techniques on the robustness of parsers that utilize standard in-context few-shot learning?\n\nSettings. In order to compare the influence of different sampling methods on the robustness of the model, we vary standard in-context examples on GeoQuery and Scholar with all 7 strategies aforementioned in Section 4.3. We choose the 50shot setting for GeoQuery and 10-shot setting for Scholar.\n\nResults and Takeaways. We present standard accuracies in Table 6 when varying the sampling methods for the few-shot example selection. We first observe that different sampling strategies impact the robust and standard performance of the CODEX. Overall, the Cluster methods, which diversify the features of the selected utterances, perform better than the other sampling methods. On the other hand, PPL. Desc sampling method performs consistently poorly than the other sampling methods. In brief, we conclude that CODEX is sensitive to the few-shot example sampling strategies.\n\nRQ4-Ablation: Why does CODEX react differently to various sampling strategies?\n\nSettings. The findings of RQ 1 and RQ 3 indicate that linguistic complexity has an impact on the performance of CODEX. As a result, the results of RQ 4 may also be influenced by linguistic complexity. To further explore this correlation, three lexical diversity metrics, Type-Token Ratio (TTR) (Templin, 1957), Yule's I (Yule, 1944), and Measure of Textual Lexical Diversity (MTLD) (Mc-Carthy, 2005), are adopted to measure the lexical diversity of the selected NLs from GeoQuery and Scholar. The TTR is defined as the ratio of the number of unique tokens, also known as types, to the total number of tokens. The TTR is used as an indicator of lexical diversity, with a higher TTR indicating higher lexical diversity. Yule's Characteristic Constant (Yule's K) is a measure of text consistency that considers vocabulary repetition. Yule's K and its inverse, Yule's I, are considered more robust to variations in text length than the Type-Token Ratio (TTR). MTLD is computed as the average number of words in a text required to maintain a specified TTR value.\n\nResults and Takeaways. Table 7 presents the lexical diversity of each set of NLs sampled by different approaches. The diversity scores obtained from the three metrics align with the performance of CODEX as presented in Table 6. For instance, the three metrics indicate that the examples selected using the Cluster-TF-IDF method achieve higher lexical diversity compared to those selected through the other methods. Additionally, the Cluster-TF-IDF method also produces the highest results in terms of robust and standard accuracy for CODEX. Thus, it can be inferred that an increase in the lexical diversity of the few-shot examples leads to an improvement in the robust and standard accuracy of CODEX.\n\n\nConclusion\n\nThis study examines the robustness of semantic parsers in the context of prompt-based few-shot learning. To achieve this objective, robustness evaluation sets were curated to evaluate the robustness of the prompt-based semantic parser, CODEX. The research aims to identify methods to improve the robustness of CODEX. The results of our comprehensive experiments demonstrate that even the prompt-based semantic parser based on a large pretrained language model is susceptible to adversarial attacks. Our findings also indicate that various forms of in-context learning can improve the robustness of the prompt-based semantic parser. It is believed that this research will serve as a catalyst for future studies on the robustness of promptbased semantic parsing based on large language models.\n\n\nLimitations\n\nIn this study, we examine the robustness of the prompt-based semantic parser, CODEX, by focusing on the impact of prompt design on its execution performance. However, there is a need for future research to investigate more alternative adversarial training strategies for prompt-based semantic parsers in order to advance this field. In addition, our focus is limited to text-to-SQL tasks, and we encourage further investigation into the robustness of semantic parsers across different datasets and LFs. Despite these limitations, we emphasize the importance of exploring more effective prompt design in order to enhance the robustness of prompt-based semantic parsers, including CODEX, which shows non-negotiable vulnerability.\n\n\nA Experiments\n\nDatasets. The GeoQuery dataset contains 877 pairs of NL-LF pairs about U.S. geographical information. On the other hand, Scholar contains pairs of NL-SQL regarding information about academic publications. Finegan-Dollak et al. (2018) proposed a dataset split for evaluating the compositional generalization capability of semantic parsers on several datasets, including GeoQuery and Scholar.\n\nThe proposed split, referred to as the query-split, presents a more challenging scenario for semantic parsing models. This paper utilizes the query-split, where the two test sets in our experiments include 182 NL-LF pairs from GeoQuery and 315 NL-LF pairs from Scholar, respectively, during the evaluation of the prompt-based semantic parser.\n\nHyperparameters. We sample at most 200 tokens from CODEX with temperature 0, with the following strings used as stop tokens to halt generation: \"--\", \"\\n\\n\", \";\", \"#\".\n\nModel Versioning. The version of the code-davinci-002 model referred to in this paper is as of the midpoint of the year 2022.  \n\n\nB Adversarial Examples\n\n\n. We evaluate the robustness of the prompt-based semantic parsers via the adversarial robustness sets built on top of the test sets of GeoQuery (Finegan-Dollak et al., 2018) and Scholar (Finegan-Dollak et al., 2018) with the proposed perturbation methods in Section 3. As in Finegan-Dollak et al. (2018), we choose the query splits of both GeoQuery and Scholar, where there is no LF template overlap among train, test, and dev sets.\n\nTable 1 :\n1Examples from Robustness Evaluation Set. We show 3 examples from GeoQuery. These examples are generated with three different perturbations, and they all can successfully change the predictions of CODEX.\n\n\ntable schema. To defend against adversarial attacks, one seminal approach is adversarial training. One of the most typical adversarial training methods augments the training data with adversarial examples, from which the machine learning model could learn robust features(Allen-Zhu and Li, 2022) by gradient descent. However, directly adapting conventional adversarial training is not suitable for in-context learning. First, the number of demonstration examples is limited due to the restriction on the maximum number of tokens for the pre-trained language model. As a result, we cannot include an arbitrary number of adversarial examples in the prompt, which might not include enough robust features. Second, in-context learning does not update the parameters of the language model. The model would not be optimized towards learning the robust features in the adversarial examples through gradient descent.\n\n\n. Our first observa-Category \n\nPert. Strategy \nGeoQuery \nScholar \nPert. Acc. Std. Acc. \n\u2206 \nPert. Acc. Std. Acc. \n\u2206 \n\nWord-level \n\nTB \n53.85 \n\n57.14 \n\n-3.29 \n11.35 \n\n12.21 \n\n-0.86 \nRD \n50.55 \n-6.59 \n10.52 \n-1.69 \nRS \n37.36 \n-19.78 \n8.31 \n-3.90 \nCS \n42.31 \n-14.83 \n8.40 \n-3.81 \nCI \n38.46 \n-18.68 \n8.31 \n-3.90 \n\nSentence-level \nRB \n31.87 \n-25.27 \n5.22 \n-6.99 \nDB \n35.71 \n-21.43 \n7.88 \n-4.33 \n\n\n\n\nTakeaways. Zero-shot CODEX is vulnerable to adversarial examples, especially sentence-level perturbation of utterances, rather than to word-level perturbations.Pert. Strategy \n5-shot 10-shot 20-shot 30-shot 40-shot 50-shot \nTB \n63.19 \n71.98 \n78.02 \n81.32 \n81.30 \n82.42 \nRD \n59.34 \n64.29 \n71.43 \n71.98 \n70.33 \n75.27 \nRS \n52.20 \n52.75 \n54.87 \n59.34 \n60.99 \n63.14 \nCS \n54.40 \n56.04 \n60.44 \n63.19 \n65.93 \n67.03 \nCI \n51.65 \n54.95 \n55.49 \n57.69 \n58.79 \n61.02 \nRB \n44.51 \n47.80 \n49.45 \n50.55 \n54.23 \n57.27 \nDB \n48.35 \n49.77 \n53.30 \n54.20 \n59.34 \n59.89 \nAvg. Pert. Acc. \n53.38 \n56.80 \n57.50 \n59.49 \n64.42 \n66.58 \nStd. Acc. \n66.48 \n74.37 \n79.67 \n81.87 \n83.52 \n84.62 \nAvg. Robust Acc. \n75.67 \n77.28 \n78.74 \n80.44 \n82.07 \n83.22 \n\n\n\nTable 3 :\n3Few-shot performances on GeoQuery. We conduct {5, 10, 20, 30, 40, 50}-shot learning experiments. Average perturbation accuracy (Avg. Pert. Acc.) is the average score of execution accuracies on different perturbation sets. Average robust accuracy (Avg. Robust Acc.) is the average score of execution accuracies on the test sets perturbed by different perturbation methods.Pert. Strategy \n3-shot 5-shot 10-shot \nTB \n10.57 \n20.33 \n34.29 \nRD \n12.09 \n25.27 \n31.43 \nRS \n6.04 \n17.03 \n25.08 \nCS \n9.34 \n18.13 \n26.03 \nCI \n8.24 \n14.29 \n20.63 \nRB \n3.30 \n8.43 \n18.10 \nDB \n4.40 \n10.44 \n21.90 \nAvg. Pert. Acc. \n7.71 \n16.27 \n25.35 \nStd. Acc. \n14.29 \n23.08 \n40.32 \nAvg. Robust. Acc. \n51.12 \n53.10 \n55.97 \n\n\n\nTable 4 :\n4Few-shot performances on Scholar. We conduct {3, 5, 10}-shot learning experiments.\n\n\nAdv. L. StrategyGeoQuery Scholar Avg. Robust Acc. Std. Acc. Avg. Robust Acc. Std. Acc.No Adv. \n77.28 \n74.37 \n53.10 \n23.08 \nNo Adv. (\u00d7 2) \n78.74 \n79.67 \n55.97 \n40.32 \nTB \n77.32 \n73.62 \n52.75 \n34.99 \nRD \n77.40 \n73.64 \n53.11 \n33.65 \nRS \n78.30 \n74.73 \n54.88 \n33.46 \nCS \n78.05 \n74.47 \n53.12 \n34.86 \nCI \n78.14 \n74.81 \n54.66 \n33.65 \nRB \n78.47 \n75.51 \n56.58 \n35.85 \nDB \n78.31 \n75.08 \n55.08 \n35.71 \n\n\n\nTable 5 :\n5The results of the average robust accuracy \nobtained through Adversarial In-context Learning (Adv. \nL. Strategy) with different types of perturbed few-shot \nexamples. Additionally, we include results of applying \nthe method with only standard examples (No Adv.), as \nwell as with a doubled number of standard examples \n(No Adv. (\u00d7 2)). \n\n\n\nTable 6 :\n6The performance of standard few-shot in-context learning using various sampling methods on the GeoQuery and Scholar datasets. The average robust accuracy, average perturbation accuracy, and standard accuracy are computed for each sampling method to assess their efficiency in this learning scenario.Dataset \nLC. Metric Confidence Cluster-CWE Cluster-ED Cluster-TF-IDF PPL. Asc PPL. Desc Random \n\nGeoQuery \nTTR \u2191 \n7.68 \n7.24 \n8.47 \n10.26 \n5.94 \n3.22 \n6.44 \nYule's I \u2191 \n68.55 \n64.37 \n69.59 \n71.49 \n62.94 \n43.41 \n58.14 \nMTLD \u2191 \n12.44 \n12.19 \n13.37 \n15.58 \n11.32 \n8.16 \n10.41 \n\nScholar \nTTR \u2191 \n28.18 \n29.91 \n31.40 \n33.11 \n21.15 \n14.17 \n25.67 \nYule's I \u2191 \n198.15 \n207.11 \n223.76 \n262.36 \n177.37 \n102.17 \n193.31 \nMTLD \u2191 \n15.68 \n15.63 \n16.34 \n19.49 \n11.94 \n13.12 \n14.36 \n\n\n\nTable 7 :\n7Results of the language complexity of standard NLs sampled by different sampling strategies, measured by \nthree lexical diversity (LC.) metrics. For the ease of readability and comparison, we multiply both TTR scores and \nYule's I scores by 100. \n\nwith more complex linguistic features, resulting in \nenhanced standard and robust accuracy during in-\ncontext learning. To test this hypothesis, the num-\nber of standard examples is doubled (No Adv.\u00d72) \nto match the size of the examples augmented with \nthe adversarial examples. The results show that \nthe robust and standard accuracies of CODEX are \nhigher than those obtained through adversarial in-\ncontext learning, likely due to the greater diversity \nof linguistic variations in the doubled standard ex-\namples. \n\n\n\nTable 8\n8lists the examples generated by all perturbation strategies. Strikethrough = Original Text, red = Adversarial Perturbation) Typo (Word-level) NL: what can you tellte11 me about theth e population of missouri Random Deletion (Word-level) NL: what can you tell me about the population of missouri Random Swap (Word-level) NL: what can you tell me aboutmissouri the population of missouriabout NL: what canwill you tell me about thea population of missouri Context-aware Insertion (Word-level) NL: what what can you tell me about the exact population of missouri Rewriting (Sent.-level) NL: what can you tell me about the population of missouri What information can you provide on Missouri's population? Distraction (Sent.-level) NL: what can you tell me about the population of missouri who is who; what is what; when is when; which is which; where is whereLinguistic \nPhenomenon \nSamples (Context-aware \nSubstitution \n(Word-level) \n\n\nTable 8 :\n8Examples from Robustness Evaluation Set. The adversarial utterances in this Table are generated by applying various perturbation strategies to a single utterance \"what can you tell me about the population of missouri\" sampled from the GeoQuery dataset. All of the generated utterances can successfully alter Codex's output.\nhttps://www.quillbot.com/paraphrasing\nThe confidence scoring parser is a zero-shot model, meaning that there are no examples present in the prompt. It operates solely based on the input utterance, instructions, and schema provided within the prompt. Please see Section 5.1 for more information on the prompt structure.\nIn contrast to the approach of Shin et al. (2021) which involves dynamically selecting few-shot examples from an example pool, we refer to static prompting as being performed with a fixed set of examples.\nDue to the larger size of table schema in Scholar, we could only include up to 10 examples in the prompt.\n\nFeature purification: How adversarial training performs robust deep learning. Zeyuan Allen, -Zhu , Yuanzhi Li, 2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS). IEEEZeyuan Allen-Zhu and Yuanzhi Li. 2022. Feature pu- rification: How adversarial training performs robust deep learning. In 2021 IEEE 62nd Annual Sympo- sium on Foundations of Computer Science (FOCS), pages 977-988. IEEE.\n\nGenerating natural language adversarial examples. Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, Kai-Wei Chang, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingMoustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, and Kai-Wei Chang. 2018. Generating natural language adversarial ex- amples. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2890-2896.\n\nMining of massive datasets. Rajaraman Anand, Ullman Jeffrey David, Cambridge University PressRajaraman Anand and Ullman Jeffrey David. 2011. Mining of massive datasets. Cambridge University Press.\n\nTowards zero-shot frame semantic parsing for domain scaling. Ankur Bapna, Gokhan Tur, Dilek Hakkani-Tur, Larry Heck, arXiv:1707.02363arXiv preprintAnkur Bapna, Gokhan Tur, Dilek Hakkani-Tur, and Larry Heck. 2017. Towards zero-shot frame se- mantic parsing for domain scaling. arXiv preprint arXiv:1707.02363.\n\nPontus Stenetorp, and Douwe Kiela. 2021. Improving question answering model robustness with synthetic adversarial data generation. Max Bartolo, Tristan Thrush, Robin Jia, Sebastian Riedel, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingMax Bartolo, Tristan Thrush, Robin Jia, Sebastian Riedel, Pontus Stenetorp, and Douwe Kiela. 2021. Improving question answering model robustness with synthetic adversarial data generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 8830-8848.\n\nSynthetic and natural noise both break neural machine translation. Yonatan Belinkov, Yonatan Bisk, International Conference on Learning Representations. Yonatan Belinkov and Yonatan Bisk. 2018. Synthetic and natural noise both break neural machine transla- tion. In International Conference on Learning Rep- resentations.\n\nBad characters: Imperceptible nlp attacks. Nicholas Boucher, Ilia Shumailov, Ross Anderson, Nicolas Papernot, 2022 IEEE Symposium on Security and Privacy (SP). IEEENicholas Boucher, Ilia Shumailov, Ross Anderson, and Nicolas Papernot. 2022. Bad characters: Impercepti- ble nlp attacks. In 2022 IEEE Symposium on Security and Privacy (SP), pages 1987-2004. IEEE.\n\n. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, arXiv:2107.03374arXiv preprintet al. 2021. Evaluating large language models trained on codeMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Ka- plan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374.\n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understand- ing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Technolo- gies, Volume 1 (Long and Short Papers), pages 4171- 4186.\n\nCompositional semantic parsing with large language models. Andrew Drozdov, Nathanael Sch\u00e4rli, Ekin Akyu\u00fcrek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, Denny Zhou, arXiv:2209.15003arXiv preprintAndrew Drozdov, Nathanael Sch\u00e4rli, Ekin Akyu\u00fcrek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier Bousquet, and Denny Zhou. 2022. Compositional semantic parsing with large language models. arXiv preprint arXiv:2209.15003.\n\nActive learning for deep semantic parsing. Long Duong, Hadi Afshar, Dominique Estival, Glen Pink, Mark Philip R Cohen, Johnson, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsShort Papers2Long Duong, Hadi Afshar, Dominique Estival, Glen Pink, Philip R Cohen, and Mark Johnson. 2018. Ac- tive learning for deep semantic parsing. In Proceed- ings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 43-48.\n\nHotflip: White-box adversarial examples for text classification. Javid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou, Proceedings of the 56th. the 56thJavid Ebrahimi, Anyi Rao, Daniel Lowd, and Dejing Dou. 2018. Hotflip: White-box adversarial examples for text classification. In Proceedings of the 56th\n\nAnnual Meeting of the Association for Computational Linguistics. 2Short Papers)Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 31-36.\n\nText processing like humans do: Visually attacking and shielding nlp systems. Steffen Eger, G\u00f6zde G\u00fcl\u015fahin, Andreas R\u00fcckl\u00e9, Ji-Ung Lee, Claudia Schulz, Mohsen Mesgar, Krishnkant Swarnkar, Edwin Simpson, Iryna Gurevych, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Steffen Eger, G\u00f6zde G\u00fcl\u015eahin, Andreas R\u00fcckl\u00e9, Ji-Ung Lee, Claudia Schulz, Mohsen Mesgar, Krishnkant Swarnkar, Edwin Simpson, and Iryna Gurevych. 2019. Text processing like humans do: Visually attacking and shielding nlp systems. In Proceedings of the 2019 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 1634-1647.\n\nImproving textto-sql evaluation methodology. Catherine Finegan-Dollak, Jonathan K Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsLong Papers1Catherine Finegan-Dollak, Jonathan K Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, and Dragomir Radev. 2018. Improving text- to-sql evaluation methodology. In Proceedings of the 56th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 351-360.\n\nQuillbot as an online tool: Students' alternative in paraphrasing and rewriting of english writing. Fitria Tira Nur, Englisia: Journal of Language, Education, and Humanities. 91Tira Nur Fitria. 2021. Quillbot as an online tool: Stu- dents' alternative in paraphrasing and rewriting of english writing. Englisia: Journal of Language, Edu- cation, and Humanities, 9(1):183-196.\n\nDomain-adversarial training of neural networks. The journal of machine learning research. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Laviolette, Mario Marchand, Victor Lempitsky, 17Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Fran\u00e7ois Lavi- olette, Mario Marchand, and Victor Lempitsky. 2016. Domain-adversarial training of neural networks. The journal of machine learning research, 17(1):2096- 2030.\n\nBlack-box generation of adversarial text sequences to evade deep learning classifiers. Ji Gao, Jack Lanchantin, Mary Lou Soffa, Yanjun Qi, IEEE Security and Privacy Workshops. IEEEJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. 2018. Black-box generation of adversarial text sequences to evade deep learning classifiers. In 2018 IEEE Security and Privacy Workshops (SPW), pages 50-56. IEEE.\n\nGradient-based adversarial attacks against text transformers. Chuan Guo, Alexandre Sablayrolles, Herv\u00e9 J\u00e9gou, Douwe Kiela, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingChuan Guo, Alexandre Sablayrolles, Herv\u00e9 J\u00e9gou, and Douwe Kiela. 2021. Gradient-based adversarial at- tacks against text transformers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5747-5757.\n\nDeceiving google's perspective api built for detecting toxic comments. Hossein Hosseini, Sreeram Kannan, Baosen Zhang, Radha Poovendran, arXiv:1702.08138arXiv preprintHossein Hosseini, Sreeram Kannan, Baosen Zhang, and Radha Poovendran. 2017. Deceiving google's per- spective api built for detecting toxic comments. arXiv preprint arXiv:1702.08138.\n\nOn robustness of neural semantic parsers. Shuo Huang, Zhuang Li, Lizhen Qu, Lei Pan, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeShuo Huang, Zhuang Li, Lizhen Qu, and Lei Pan. 2021. On robustness of neural semantic parsers. In Pro- ceedings of the 16th Conference of the European Chapter of the Association for Computational Lin- guistics: Main Volume, pages 3333-3342.\n\nLearning a neural semantic parser from user feedback. Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy, Luke Zettlemoyer, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsLong Papers1Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, Jayant Krishnamurthy, and Luke Zettlemoyer. 2017. Learn- ing a neural semantic parser from user feedback. In Proceedings of the 55th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 963-973.\n\nAdversarial example generation with syntactically controlled paraphrase networks. Mohit Iyyer, John Wieting, Kevin Gimpel, Luke Zettlemoyer, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Long PapersMohit Iyyer, John Wieting, Kevin Gimpel, and Luke Zettlemoyer. 2018. Adversarial example generation with syntactically controlled paraphrase networks. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1875-1885.\n\nA survey on semantic parsing. Aishwarya Kamath, Rajarshi Das, Automated Knowledge Base Construction (AKBC). Aishwarya Kamath and Rajarshi Das. 2018. A survey on semantic parsing. In Automated Knowledge Base Construction (AKBC).\n\nLarge language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, ICML 2022 Workshop on Knowledge Retrieval and Language Models. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu- taka Matsuo, and Yusuke Iwasawa. 2022. Large lan- guage models are zero-shot reasoners. In ICML 2022 Workshop on Knowledge Retrieval and Language Models.\n\nJinfeng Li, Shouling Ji, Tianyu Du, Bo Li, Ting Wang, arXiv:1812.05271Textbugger: Generating adversarial text against real-world applications. arXiv preprintJinfeng Li, Shouling Ji, Tianyu Du, Bo Li, and Ting Wang. 2018. Textbugger: Generating adversarial text against real-world applications. arXiv preprint arXiv:1812.05271.\n\nTotal recall: a customized continual learning method for neural semantic parsers. Zhuang Li, Lizhen Qu, Gholamreza Haffari, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingZhuang Li, Lizhen Qu, and Gholamreza Haffari. 2021. Total recall: a customized continual learning method for neural semantic parsers. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3816-3831.\n\nDeep text classification can be fooled. Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li, Wenchang Shi, IJCAI. Bin Liang, Hongcheng Li, Miaoqiang Su, Pan Bian, Xirong Li, and Wenchang Shi. 2018. Deep text clas- sification can be fooled. In IJCAI.\n\nPretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig, arXiv:2107.13586arXiv preprintPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre- train, prompt, and predict: A systematic survey of prompting methods in natural language processing. arXiv preprint arXiv:2107.13586.\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. arXiv preprintYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining ap- proach. arXiv preprint arXiv:1907.11692.\n\nFew-shot selfrationalization with natural language prompts. Ana Marasovi\u0107, Iz Beltagy, Doug Downey, Matthew E Peters, arXiv:2111.08284arXiv preprintAna Marasovi\u0107, Iz Beltagy, Doug Downey, and Matthew E Peters. 2021. Few-shot self- rationalization with natural language prompts. arXiv preprint arXiv:2111.08284.\n\nAn assessment of the range and usefulness of lexical diversity measures and the potential of the measure of textual, lexical diversity (MTLD). M Philip, Mccarthy, The University of MemphisPh.D. thesisPhilip M McCarthy. 2005. An assessment of the range and usefulness of lexical diversity measures and the potential of the measure of textual, lexical diversity (MTLD). Ph.D. thesis, The University of Memphis.\n\nThe curious case of adversarially robust models: More data can help, double descend, or hurt generalization. Yifei Min, Lin Chen, Amin Karbasi, PMLRUncertainty in Artificial Intelligence. Yifei Min, Lin Chen, and Amin Karbasi. 2021. The curious case of adversarially robust models: More data can help, double descend, or hurt generalization. In Uncertainty in Artificial Intelligence, pages 129- 139. PMLR.\n\nAdversarial training methods for semi-supervised text classification. Takeru Miyato, M Andrew, Ian Dai, Goodfellow, arXiv:1605.07725arXiv preprintTakeru Miyato, Andrew M Dai, and Ian Goodfel- low. 2016. Adversarial training methods for semi-supervised text classification. arXiv preprint arXiv:1605.07725.\n\nAakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, Graham Neubig, arXiv:1806.00692Stress test evaluation for natural language inference. arXiv preprintAakanksha Naik, Abhilasha Ravichander, Norman Sadeh, Carolyn Rose, and Graham Neubig. 2018. Stress test evaluation for natural language inference. arXiv preprint arXiv:1806.00692.\n\nImproving adversarial robustness via promoting ensemble diversity. Tianyu Pang, Kun Xu, Chao Du, Ning Chen, PMLRInternational Conference on Machine Learning. Tianyu Pang, Kun Xu, Chao Du, Ning Chen, and Jun Zhu. 2019. Improving adversarial robustness via pro- moting ensemble diversity. In International Con- ference on Machine Learning, pages 4970-4979. PMLR.\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting of the Association for Computational Linguistics. the 40th annual meeting of the Association for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic evalu- ation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computa- tional Linguistics, pages 311-318.\n\nTowards robustness of text-to-sql models against natural and realistic adversarial table perturbation. Xinyu Pi, Bing Wang, Yan Gao, Jiaqi Guo, Zhoujun Li, Jian-Guang Lou, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsLong Papers1Xinyu Pi, Bing Wang, Yan Gao, Jiaqi Guo, Zhoujun Li, and Jian-Guang Lou. 2022. Towards robustness of text-to-sql models against natural and realistic ad- versarial table perturbation. In Proceedings of the 60th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 2007-2022.\n\nUnsupervised semantic parsing. Hoifung Poon, Pedro Domingos, Proceedings of the 2009 conference on empirical methods in natural language processing. the 2009 conference on empirical methods in natural language processingHoifung Poon and Pedro Domingos. 2009. Unsuper- vised semantic parsing. In Proceedings of the 2009 conference on empirical methods in natural language processing, pages 1-10.\n\nAdversarial training can hurt generalization. Aditi Raghunathan, Sang Michael Xie, Fanny Yang, C John, Percy Duchi, Liang, arXiv:1906.06032arXiv preprintAditi Raghunathan, Sang Michael Xie, Fanny Yang, John C Duchi, and Percy Liang. 2019. Adversar- ial training can hurt generalization. arXiv preprint arXiv:1906.06032.\n\nEvaluating the text-to-sql capabilities of large language models. Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau, arXiv:2204.00498arXiv preprintNitarshan Rajkumar, Raymond Li, and Dzmitry Bah- danau. 2022. Evaluating the text-to-sql capabil- ities of large language models. arXiv preprint arXiv:2204.00498.\n\nZero-shot text-to-image generation. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever, PMLRInternational Conference on Machine Learning. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. Zero-shot text-to-image gen- eration. In International Conference on Machine Learning, pages 8821-8831. PMLR.\n\nSentence-bert: Sentence embeddings using siamese bert-networks. Nils Reimers, Iryna Gurevych, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 3982-3992.\n\nSemantically equivalent adversarial rules for debugging nlp models. Sameer Marco Tulio Ribeiro, Carlos Singh, Guestrin, Annual Meeting of the Association for Computational Linguistics (ACL). Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2018. Semantically equivalent adversarial rules for debugging nlp models. In Annual Meet- ing of the Association for Computational Linguistics (ACL).\n\nTailor: Generating and perturbing text with semantic controls. Alexis Ross, Tongshuang Wu, Hao Peng, Matthew E Peters, Matt Gardner, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsLong Papers1Alexis Ross, Tongshuang Wu, Hao Peng, Matthew E Peters, and Matt Gardner. 2022. Tailor: Generat- ing and perturbing text with semantic controls. In Proceedings of the 60th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 3194-3213.\n\nBenchclamp: A benchmark for evaluating language models on semantic parsing. Subhro Roy, Sam Thomson, Tongfei Chen, Richard Shin, Adam Pauls, Jason Eisner, Benjamin Van Durme, 10.48550/ARXIV.2206.10668Subhro Roy, Sam Thomson, Tongfei Chen, Richard Shin, Adam Pauls, Jason Eisner, and Benjamin Van Durme. 2022a. Benchclamp: A benchmark for evaluating language models on semantic parsing.\n\nSubhro Roy, Sam Thomson, Tongfei Chen, Richard Shin, Adam Pauls, Jason Eisner, Benjamin Van Durme, arXiv:2206.106682022b. Benchclamp: A benchmark for evaluating language models on semantic parsing. arXiv preprintSubhro Roy, Sam Thomson, Tongfei Chen, Richard Shin, Adam Pauls, Jason Eisner, and Benjamin Van Durme. 2022b. Benchclamp: A benchmark for evaluating language models on semantic parsing. arXiv preprint arXiv:2206.10668.\n\nClip-forge: Towards zero-shot text-to-shape generation. Aditya Sanghi, Hang Chu, Ye Joseph G Lambourne, Chin-Yi Wang, Marco Cheng, Kamal Rahimi Fumero, Malekshan, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionAditya Sanghi, Hang Chu, Joseph G Lambourne, Ye Wang, Chin-Yi Cheng, Marco Fumero, and Ka- mal Rahimi Malekshan. 2022. Clip-forge: Towards zero-shot text-to-shape generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 18603-18613.\n\nUncertainty and traffic-aware active learning for semantic parsing. Priyanka Sen, Emine Yilmaz, 10.18653/v1/2020.intexsempar-1.2Proceedings of the First Workshop on Interactive and Executable Semantic Parsing. the First Workshop on Interactive and Executable Semantic ParsingOnline. Association for Computational LinguisticsPriyanka Sen and Emine Yilmaz. 2020. Uncertainty and traffic-aware active learning for semantic parsing. In Proceedings of the First Workshop on Interactive and Executable Semantic Parsing, pages 12-17, Online. Association for Computational Linguistics.\n\nAli Shafahi, Mahyar Najibi, Mohammad Amin Ghiasi, Zheng Xu, John Dickerson, Christoph Studer, S Larry, Gavin Davis, Tom Taylor, Goldstein, Adversarial training for free! Advances in Neural Information Processing Systems. 32Ali Shafahi, Mahyar Najibi, Mohammad Amin Ghi- asi, Zheng Xu, John Dickerson, Christoph Studer, Larry S Davis, Gavin Taylor, and Tom Goldstein. 2019. Adversarial training for free! Advances in Neural Information Processing Systems, 32.\n\nUniversal adversarial training. Ali Shafahi, Mahyar Najibi, Zheng Xu, John Dickerson, S Larry, Tom Davis, Goldstein, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Ali Shafahi, Mahyar Najibi, Zheng Xu, John Dickerson, Larry S Davis, and Tom Goldstein. 2020. Universal adversarial training. In Proceedings of the AAAI Con- ference on Artificial Intelligence, volume 34, pages 5636-5643.\n\nConstrained language models yield few-shot semantic parsers. Richard Shin, Christopher Lin, Sam Thomson, Charles ChenJr, Subhro Roy, Adam Emmanouil Antonios Platanios, Dan Pauls, Jason Klein, Benjamin Eisner, Van Durme, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingRichard Shin, Christopher Lin, Sam Thomson, Charles Chen Jr, Subhro Roy, Emmanouil Antonios Platanios, Adam Pauls, Dan Klein, Jason Eisner, and Benjamin Van Durme. 2021. Constrained language models yield few-shot semantic parsers. In Proceedings of the 2021 Conference on Empirical Methods in Natu- ral Language Processing, pages 7699-7715.\n\nFewshot semantic parsing with language models trained on code. Richard Shin, Benjamin Van Durme, 10.18653/v1/2022.naacl-main.396Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational LinguisticsRichard Shin and Benjamin Van Durme. 2022. Few- shot semantic parsing with language models trained on code. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies, pages 5417-5425, Seattle, United States. Association for Computational Linguistics.\n\nParaphrasing techniques for maritime qa system. Fatemeh Shiri, Terry Yue Zhuo, Zhuang Li, Shirui Pan, Weiqing Wang, Reza Haffari, Yuan-Fang Li, Van Nguyen, 2022 25th International Conference on Information Fusion (FUSION). IEEEFatemeh Shiri, Terry Yue Zhuo, Zhuang Li, Shirui Pan, Weiqing Wang, Reza Haffari, Yuan-Fang Li, and Van Nguyen. 2022. Paraphrasing techniques for maritime qa system. In 2022 25th International Conference on Information Fusion (FUSION), pages 1-8. IEEE.\n\nPrompt-and-rerank: A method for zero-shot and few-shot arbitrary textual style transfer with small language models. Mirac Suzgun, Luke Melas-Kyriazi, Dan Jurafsky, arXiv:2205.11503arXiv preprintMirac Suzgun, Luke Melas-Kyriazi, and Dan Juraf- sky. 2022. Prompt-and-rerank: A method for zero-shot and few-shot arbitrary textual style trans- fer with small language models. arXiv preprint arXiv:2205.11503.\n\nIntriguing properties of neural networks. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J Goodfellow, Rob Fergus, 2nd International Conference on Learning Representations. Banff, AB, CanadaConference Track ProceedingsChristian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. 2014. Intriguing properties of neural networks. In 2nd International Conference on Learn- ing Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings.\n\nCertain language skills in children: Their development and interrelationships. Mildred C Templin, JSTOR10Mildred C Templin. 1957. Certain language skills in children: Their development and interrelationships, volume 10. JSTOR.\n\nAdversarial training and robustness for multiple perturbations. Florian Tramer, Dan Boneh, Advances in Neural Information Processing Systems. 32Florian Tramer and Dan Boneh. 2019. Adversarial train- ing and robustness for multiple perturbations. Ad- vances in Neural Information Processing Systems, 32.\n\nThe string-to-string correction problem. A Robert, Michael J Wagner, Fischer, Journal of the ACM (JACM). 211Robert A Wagner and Michael J Fischer. 1974. The string-to-string correction problem. Journal of the ACM (JACM), 21(1):168-173.\n\nGPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. Ben Wang, Aran Komatsuzaki, Ben Wang and Aran Komatsuzaki. 2021. GPT- J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/ kingoflolz/mesh-transformer-jax.\n\nAdversarial glue: A multi-task benchmark for robustness evaluation of language models. Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng, Jianfeng Gao, Ahmed Hassan Awadallah, Bo Li, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. Round 2Boxin Wang, Chejian Xu, Shuohang Wang, Zhe Gan, Yu Cheng, Jianfeng Gao, Ahmed Hassan Awadallah, and Bo Li. 2021. Adversarial glue: A multi-task benchmark for robustness evaluation of language models. In Thirty-fifth Conference on Neural In- formation Processing Systems Datasets and Bench- marks Track (Round 2).\n\nAdvances in K-means clustering: a data mining thinking. Junjie Wu, Springer Science & Business MediaJunjie Wu. 2012. Advances in K-means clustering: a data mining thinking. Springer Science & Business Media.\n\nAn empirical study of gpt-3 for few-shot knowledgebased vqa. Zhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei Hu, Yumao Lu, Zicheng Liu, Lijuan Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence36Zhengyuan Yang, Zhe Gan, Jianfeng Wang, Xiaowei Hu, Yumao Lu, Zicheng Liu, and Lijuan Wang. 2022. An empirical study of gpt-3 for few-shot knowledge- based vqa. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 3081- 3089.\n\nImproved ood generalization via adversarial training and pretraing. Mingyang Yi, Lu Hou, Jiacheng Sun, Lifeng Shang, Xin Jiang, Qun Liu, Zhiming Ma, PMLRInternational Conference on Machine Learning. Mingyang Yi, Lu Hou, Jiacheng Sun, Lifeng Shang, Xin Jiang, Qun Liu, and Zhiming Ma. 2021. Im- proved ood generalization via adversarial training and pretraing. In International Conference on Ma- chine Learning, pages 11987-11997. PMLR.\n\nThe statistical study of literary vocabulary. cambridge, cambridge [eng. Gu Yule, GU Yule. 1944. The statistical study of literary vocabu- lary. cambridge, cambridge [eng.].\n\nLearning to parse database queries using inductive logic programming. M John, Raymond J Zelle, Mooney, Proceedings of the national conference on artificial intelligence. the national conference on artificial intelligenceJohn M Zelle and Raymond J Mooney. 1996. Learning to parse database queries using inductive logic pro- gramming. In Proceedings of the national conference on artificial intelligence, pages 1050-1055.\n\nTheoretically principled trade-off between robustness and accuracy. Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, Michael Jordan, PMLRInternational conference on machine learning. Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan. 2019. Theo- retically principled trade-off between robustness and accuracy. In International conference on machine learning, pages 7472-7482. PMLR.\n\nGenerating natural adversarial examples. Zhengli Zhao, Dheeru Dua, Sameer Singh, International Conference on Learning Representations. Zhengli Zhao, Dheeru Dua, and Sameer Singh. 2018. Generating natural adversarial examples. In Interna- tional Conference on Learning Representations.\n", "annotations": {"author": "[{\"end\":167,\"start\":130},{\"end\":228,\"start\":168},{\"end\":270,\"start\":229},{\"end\":314,\"start\":271},{\"end\":357,\"start\":315},{\"end\":406,\"start\":358},{\"end\":449,\"start\":407},{\"end\":476,\"start\":450}]", "publisher": null, "author_last_name": "[{\"end\":144,\"start\":140},{\"end\":177,\"start\":175},{\"end\":240,\"start\":235},{\"end\":284,\"start\":279},{\"end\":327,\"start\":323},{\"end\":376,\"start\":369},{\"end\":419,\"start\":417}]", "author_first_name": "[{\"end\":135,\"start\":130},{\"end\":139,\"start\":136},{\"end\":174,\"start\":168},{\"end\":234,\"start\":229},{\"end\":278,\"start\":271},{\"end\":322,\"start\":315},{\"end\":368,\"start\":358},{\"end\":416,\"start\":407}]", "author_affiliation": "[{\"end\":227,\"start\":200},{\"end\":269,\"start\":242},{\"end\":313,\"start\":286},{\"end\":356,\"start\":329},{\"end\":405,\"start\":378},{\"end\":448,\"start\":421},{\"end\":475,\"start\":451}]", "title": "[{\"end\":114,\"start\":1},{\"end\":590,\"start\":477}]", "venue": "[{\"end\":699,\"start\":592}]", "abstract": "[{\"end\":2031,\"start\":806}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2322,\"start\":2300},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2581,\"start\":2561},{\"end\":2756,\"start\":2722},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3212,\"start\":3186},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3250,\"start\":3230},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3266,\"start\":3250},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":3571,\"start\":3547},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3592,\"start\":3571},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3611,\"start\":3592},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3632,\"start\":3611},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4234,\"start\":4215},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":4852,\"start\":4833},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5166,\"start\":5145},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":5189,\"start\":5166},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":5558,\"start\":5545},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5590,\"start\":5571},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6802,\"start\":6781},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6849,\"start\":6825},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":6896,\"start\":6875},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":7050,\"start\":7029},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":7068,\"start\":7050},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7088,\"start\":7068},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":7223,\"start\":7197},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7241,\"start\":7223},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7261,\"start\":7241},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7285,\"start\":7262},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7307,\"start\":7285},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7331,\"start\":7307},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7348,\"start\":7331},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7366,\"start\":7348},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7387,\"start\":7366},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7433,\"start\":7413},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7454,\"start\":7433},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":7472,\"start\":7454},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7532,\"start\":7509},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7551,\"start\":7532},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":7570,\"start\":7551},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":7719,\"start\":7702},{\"end\":7740,\"start\":7719},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7757,\"start\":7740},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8027,\"start\":8001},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8044,\"start\":8027},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8529,\"start\":8510},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10105,\"start\":10087},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":10590,\"start\":10570},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10716,\"start\":10697},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11376,\"start\":11348},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":11628,\"start\":11609},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":11653,\"start\":11628},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11755,\"start\":11732},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11797,\"start\":11772},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11894,\"start\":11872},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12081,\"start\":12062},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14844,\"start\":14824},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":15167,\"start\":15157},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":15312,\"start\":15286},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15421,\"start\":15390},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":15519,\"start\":15491},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":15615,\"start\":15593},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":16094,\"start\":16068},{\"end\":16112,\"start\":16094},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16133,\"start\":16112},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":16645,\"start\":16623},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":17297,\"start\":17275},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18882,\"start\":18861},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19141,\"start\":19122},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":21229,\"start\":21204},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":22894,\"start\":22868},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":22913,\"start\":22894},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":25615,\"start\":25603},{\"end\":25682,\"start\":25665},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30616,\"start\":30592}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30103,\"start\":29669},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":30318,\"start\":30104},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":31229,\"start\":30319},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":31622,\"start\":31230},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":32344,\"start\":31623},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":33046,\"start\":32345},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":33141,\"start\":33047},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":33535,\"start\":33142},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":33886,\"start\":33536},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":34664,\"start\":33887},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":35445,\"start\":34665},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":36387,\"start\":35446},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":36723,\"start\":36388}]", "paragraph": "[{\"end\":3213,\"start\":2047},{\"end\":3974,\"start\":3215},{\"end\":4342,\"start\":3976},{\"end\":5379,\"start\":4344},{\"end\":5651,\"start\":5381},{\"end\":5699,\"start\":5653},{\"end\":5788,\"start\":5701},{\"end\":5919,\"start\":5790},{\"end\":6042,\"start\":5921},{\"end\":6180,\"start\":6044},{\"end\":7571,\"start\":6197},{\"end\":8045,\"start\":7573},{\"end\":8318,\"start\":8105},{\"end\":9502,\"start\":8360},{\"end\":9767,\"start\":9532},{\"end\":9794,\"start\":9769},{\"end\":9885,\"start\":9796},{\"end\":9954,\"start\":9887},{\"end\":10033,\"start\":9956},{\"end\":10157,\"start\":10035},{\"end\":10284,\"start\":10159},{\"end\":10315,\"start\":10286},{\"end\":10591,\"start\":10317},{\"end\":10941,\"start\":10593},{\"end\":11089,\"start\":10960},{\"end\":11377,\"start\":11091},{\"end\":11487,\"start\":11379},{\"end\":12050,\"start\":11510},{\"end\":12227,\"start\":12052},{\"end\":12298,\"start\":12229},{\"end\":12382,\"start\":12300},{\"end\":12902,\"start\":12384},{\"end\":13673,\"start\":12960},{\"end\":13868,\"start\":13715},{\"end\":13944,\"start\":13920},{\"end\":14077,\"start\":13984},{\"end\":14243,\"start\":14122},{\"end\":14701,\"start\":14325},{\"end\":14783,\"start\":14703},{\"end\":15034,\"start\":14785},{\"end\":15565,\"start\":15036},{\"end\":15920,\"start\":15567},{\"end\":16165,\"start\":15922},{\"end\":16528,\"start\":16167},{\"end\":16731,\"start\":16530},{\"end\":17088,\"start\":16733},{\"end\":17298,\"start\":17090},{\"end\":17448,\"start\":17337},{\"end\":17688,\"start\":17533},{\"end\":18071,\"start\":17690},{\"end\":19422,\"start\":18073},{\"end\":19827,\"start\":19424},{\"end\":20149,\"start\":19829},{\"end\":20790,\"start\":20161},{\"end\":21595,\"start\":20792},{\"end\":21741,\"start\":21597},{\"end\":22382,\"start\":21743},{\"end\":24195,\"start\":22384},{\"end\":24327,\"start\":24203},{\"end\":24623,\"start\":24329},{\"end\":25201,\"start\":24625},{\"end\":25281,\"start\":25203},{\"end\":26340,\"start\":25283},{\"end\":27044,\"start\":26342},{\"end\":27850,\"start\":27059},{\"end\":28593,\"start\":27866},{\"end\":29001,\"start\":28611},{\"end\":29345,\"start\":29003},{\"end\":29514,\"start\":29347},{\"end\":29643,\"start\":29516}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13919,\"start\":13869},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13983,\"start\":13945},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14292,\"start\":14244}]", "table_ref": "[{\"end\":17763,\"start\":17756},{\"end\":17771,\"start\":17764},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":20177,\"start\":20163},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":22525,\"start\":22518},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":24689,\"start\":24682},{\"attributes\":{\"ref_id\":\"tab_12\"},\"end\":26372,\"start\":26365},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":26568,\"start\":26561}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2045,\"start\":2033},{\"attributes\":{\"n\":\"2\"},\"end\":6195,\"start\":6183},{\"attributes\":{\"n\":\"3\"},\"end\":8103,\"start\":8048},{\"attributes\":{\"n\":\"3.1\"},\"end\":8358,\"start\":8321},{\"attributes\":{\"n\":\"3.1.1\"},\"end\":9530,\"start\":9505},{\"attributes\":{\"n\":\"3.1.2\"},\"end\":10958,\"start\":10944},{\"attributes\":{\"n\":\"3.2\"},\"end\":11508,\"start\":11490},{\"attributes\":{\"n\":\"4\"},\"end\":12958,\"start\":12905},{\"attributes\":{\"n\":\"4.1\"},\"end\":13713,\"start\":13676},{\"attributes\":{\"n\":\"4.2\"},\"end\":14120,\"start\":14080},{\"attributes\":{\"n\":\"4.3\"},\"end\":14323,\"start\":14294},{\"attributes\":{\"n\":\"5.2\"},\"end\":17335,\"start\":17301},{\"end\":17531,\"start\":17451},{\"end\":20159,\"start\":20152},{\"end\":24201,\"start\":24198},{\"attributes\":{\"n\":\"6\"},\"end\":27057,\"start\":27047},{\"end\":27864,\"start\":27853},{\"end\":28609,\"start\":28596},{\"end\":29668,\"start\":29646},{\"end\":30114,\"start\":30105},{\"end\":32355,\"start\":32346},{\"end\":33057,\"start\":33048},{\"end\":33546,\"start\":33537},{\"end\":33897,\"start\":33888},{\"end\":34675,\"start\":34666},{\"end\":35454,\"start\":35447},{\"end\":36398,\"start\":36389}]", "table": "[{\"end\":31622,\"start\":31252},{\"end\":32344,\"start\":31785},{\"end\":33046,\"start\":32728},{\"end\":33535,\"start\":33230},{\"end\":33886,\"start\":33548},{\"end\":34664,\"start\":34198},{\"end\":35445,\"start\":34677},{\"end\":36387,\"start\":36311}]", "figure_caption": "[{\"end\":30103,\"start\":29671},{\"end\":30318,\"start\":30116},{\"end\":31229,\"start\":30321},{\"end\":31252,\"start\":31232},{\"end\":31785,\"start\":31625},{\"end\":32728,\"start\":32357},{\"end\":33141,\"start\":33059},{\"end\":33230,\"start\":33144},{\"end\":34198,\"start\":33899},{\"end\":36311,\"start\":35456},{\"end\":36723,\"start\":36400}]", "figure_ref": null, "bib_author_first_name": "[{\"end\":37439,\"start\":37433},{\"end\":37451,\"start\":37447},{\"end\":37461,\"start\":37454},{\"end\":37824,\"start\":37816},{\"end\":37839,\"start\":37835},{\"end\":37853,\"start\":37848},{\"end\":37872,\"start\":37864},{\"end\":37881,\"start\":37877},{\"end\":37901,\"start\":37894},{\"end\":38369,\"start\":38360},{\"end\":38391,\"start\":38377},{\"end\":38596,\"start\":38591},{\"end\":38610,\"start\":38604},{\"end\":38621,\"start\":38616},{\"end\":38640,\"start\":38635},{\"end\":38974,\"start\":38971},{\"end\":38991,\"start\":38984},{\"end\":39005,\"start\":39000},{\"end\":39020,\"start\":39011},{\"end\":39560,\"start\":39553},{\"end\":39578,\"start\":39571},{\"end\":39860,\"start\":39852},{\"end\":39874,\"start\":39870},{\"end\":39890,\"start\":39886},{\"end\":39908,\"start\":39901},{\"end\":40178,\"start\":40174},{\"end\":40190,\"start\":40185},{\"end\":40205,\"start\":40199},{\"end\":40217,\"start\":40211},{\"end\":40232,\"start\":40224},{\"end\":40263,\"start\":40258},{\"end\":40277,\"start\":40272},{\"end\":40291,\"start\":40287},{\"end\":40307,\"start\":40299},{\"end\":40320,\"start\":40316},{\"end\":40765,\"start\":40760},{\"end\":40782,\"start\":40774},{\"end\":40796,\"start\":40790},{\"end\":40810,\"start\":40802},{\"end\":41519,\"start\":41513},{\"end\":41538,\"start\":41529},{\"end\":41552,\"start\":41548},{\"end\":41569,\"start\":41563},{\"end\":41585,\"start\":41578},{\"end\":41598,\"start\":41592},{\"end\":41612,\"start\":41605},{\"end\":41628,\"start\":41623},{\"end\":41937,\"start\":41933},{\"end\":41949,\"start\":41945},{\"end\":41967,\"start\":41958},{\"end\":41981,\"start\":41977},{\"end\":41992,\"start\":41988},{\"end\":42535,\"start\":42530},{\"end\":42550,\"start\":42546},{\"end\":42562,\"start\":42556},{\"end\":42575,\"start\":42569},{\"end\":43036,\"start\":43029},{\"end\":43048,\"start\":43043},{\"end\":43066,\"start\":43059},{\"end\":43081,\"start\":43075},{\"end\":43094,\"start\":43087},{\"end\":43109,\"start\":43103},{\"end\":43128,\"start\":43118},{\"end\":43144,\"start\":43139},{\"end\":43159,\"start\":43154},{\"end\":43926,\"start\":43917},{\"end\":43951,\"start\":43943},{\"end\":43953,\"start\":43952},{\"end\":43968,\"start\":43966},{\"end\":43983,\"start\":43976},{\"end\":44000,\"start\":43996},{\"end\":44015,\"start\":44012},{\"end\":44031,\"start\":44023},{\"end\":44631,\"start\":44625},{\"end\":45000,\"start\":44992},{\"end\":45016,\"start\":45008},{\"end\":45031,\"start\":45027},{\"end\":45046,\"start\":45040},{\"end\":45060,\"start\":45056},{\"end\":45081,\"start\":45073},{\"end\":45099,\"start\":45094},{\"end\":45116,\"start\":45110},{\"end\":45476,\"start\":45474},{\"end\":45486,\"start\":45482},{\"end\":45503,\"start\":45499},{\"end\":45507,\"start\":45504},{\"end\":45521,\"start\":45515},{\"end\":45854,\"start\":45849},{\"end\":45869,\"start\":45860},{\"end\":45889,\"start\":45884},{\"end\":45902,\"start\":45897},{\"end\":46391,\"start\":46384},{\"end\":46409,\"start\":46402},{\"end\":46424,\"start\":46418},{\"end\":46437,\"start\":46432},{\"end\":46709,\"start\":46705},{\"end\":46723,\"start\":46717},{\"end\":46734,\"start\":46728},{\"end\":46742,\"start\":46739},{\"end\":47281,\"start\":47271},{\"end\":47295,\"start\":47288},{\"end\":47310,\"start\":47305},{\"end\":47325,\"start\":47319},{\"end\":47345,\"start\":47341},{\"end\":47907,\"start\":47902},{\"end\":47919,\"start\":47915},{\"end\":47934,\"start\":47929},{\"end\":47947,\"start\":47943},{\"end\":48625,\"start\":48616},{\"end\":48642,\"start\":48634},{\"end\":48869,\"start\":48862},{\"end\":48883,\"start\":48878},{\"end\":48900,\"start\":48894},{\"end\":48911,\"start\":48905},{\"end\":48924,\"start\":48918},{\"end\":49219,\"start\":49212},{\"end\":49232,\"start\":49224},{\"end\":49243,\"start\":49237},{\"end\":49250,\"start\":49248},{\"end\":49259,\"start\":49255},{\"end\":49628,\"start\":49622},{\"end\":49639,\"start\":49633},{\"end\":49654,\"start\":49644},{\"end\":50109,\"start\":50106},{\"end\":50126,\"start\":50117},{\"end\":50140,\"start\":50131},{\"end\":50148,\"start\":50145},{\"end\":50161,\"start\":50155},{\"end\":50174,\"start\":50166},{\"end\":50435,\"start\":50428},{\"end\":50447,\"start\":50441},{\"end\":50460,\"start\":50454},{\"end\":50473,\"start\":50465},{\"end\":50488,\"start\":50481},{\"end\":50504,\"start\":50498},{\"end\":50784,\"start\":50778},{\"end\":50794,\"start\":50790},{\"end\":50805,\"start\":50800},{\"end\":50820,\"start\":50813},{\"end\":50831,\"start\":50825},{\"end\":50844,\"start\":50839},{\"end\":50855,\"start\":50851},{\"end\":50866,\"start\":50862},{\"end\":50878,\"start\":50874},{\"end\":50899,\"start\":50892},{\"end\":51297,\"start\":51294},{\"end\":51311,\"start\":51309},{\"end\":51325,\"start\":51321},{\"end\":51341,\"start\":51334},{\"end\":51343,\"start\":51342},{\"end\":51690,\"start\":51689},{\"end\":52070,\"start\":52065},{\"end\":52079,\"start\":52076},{\"end\":52090,\"start\":52086},{\"end\":52440,\"start\":52434},{\"end\":52450,\"start\":52449},{\"end\":52462,\"start\":52459},{\"end\":52680,\"start\":52671},{\"end\":52696,\"start\":52687},{\"end\":52716,\"start\":52710},{\"end\":52731,\"start\":52724},{\"end\":52744,\"start\":52738},{\"end\":53092,\"start\":53086},{\"end\":53102,\"start\":53099},{\"end\":53111,\"start\":53107},{\"end\":53120,\"start\":53116},{\"end\":53452,\"start\":53445},{\"end\":53468,\"start\":53463},{\"end\":53481,\"start\":53477},{\"end\":53496,\"start\":53488},{\"end\":54015,\"start\":54010},{\"end\":54024,\"start\":54020},{\"end\":54034,\"start\":54031},{\"end\":54045,\"start\":54040},{\"end\":54058,\"start\":54051},{\"end\":54073,\"start\":54063},{\"end\":54610,\"start\":54603},{\"end\":54622,\"start\":54617},{\"end\":55019,\"start\":55014},{\"end\":55037,\"start\":55033},{\"end\":55045,\"start\":55038},{\"end\":55056,\"start\":55051},{\"end\":55064,\"start\":55063},{\"end\":55076,\"start\":55071},{\"end\":55364,\"start\":55355},{\"end\":55382,\"start\":55375},{\"end\":55394,\"start\":55387},{\"end\":55641,\"start\":55635},{\"end\":55657,\"start\":55650},{\"end\":55673,\"start\":55666},{\"end\":55684,\"start\":55679},{\"end\":55698,\"start\":55691},{\"end\":55709,\"start\":55705},{\"end\":55723,\"start\":55719},{\"end\":55734,\"start\":55730},{\"end\":56096,\"start\":56092},{\"end\":56111,\"start\":56106},{\"end\":56834,\"start\":56828},{\"end\":56862,\"start\":56856},{\"end\":57227,\"start\":57221},{\"end\":57244,\"start\":57234},{\"end\":57252,\"start\":57249},{\"end\":57266,\"start\":57259},{\"end\":57268,\"start\":57267},{\"end\":57281,\"start\":57277},{\"end\":57827,\"start\":57821},{\"end\":57836,\"start\":57833},{\"end\":57853,\"start\":57846},{\"end\":57867,\"start\":57860},{\"end\":57878,\"start\":57874},{\"end\":57891,\"start\":57886},{\"end\":57908,\"start\":57900},{\"end\":58138,\"start\":58132},{\"end\":58147,\"start\":58144},{\"end\":58164,\"start\":58157},{\"end\":58178,\"start\":58171},{\"end\":58189,\"start\":58185},{\"end\":58202,\"start\":58197},{\"end\":58219,\"start\":58211},{\"end\":58626,\"start\":58620},{\"end\":58639,\"start\":58635},{\"end\":58647,\"start\":58645},{\"end\":58675,\"start\":58668},{\"end\":58687,\"start\":58682},{\"end\":58707,\"start\":58695},{\"end\":59233,\"start\":59225},{\"end\":59244,\"start\":59239},{\"end\":59739,\"start\":59736},{\"end\":59755,\"start\":59749},{\"end\":59772,\"start\":59764},{\"end\":59791,\"start\":59786},{\"end\":59800,\"start\":59796},{\"end\":59821,\"start\":59812},{\"end\":59831,\"start\":59830},{\"end\":59844,\"start\":59839},{\"end\":59855,\"start\":59852},{\"end\":60231,\"start\":60228},{\"end\":60247,\"start\":60241},{\"end\":60261,\"start\":60256},{\"end\":60270,\"start\":60266},{\"end\":60283,\"start\":60282},{\"end\":60294,\"start\":60291},{\"end\":60715,\"start\":60708},{\"end\":60733,\"start\":60722},{\"end\":60742,\"start\":60739},{\"end\":60759,\"start\":60752},{\"end\":60774,\"start\":60768},{\"end\":60784,\"start\":60780},{\"end\":60818,\"start\":60815},{\"end\":60831,\"start\":60826},{\"end\":60847,\"start\":60839},{\"end\":61438,\"start\":61431},{\"end\":61453,\"start\":61445},{\"end\":62227,\"start\":62220},{\"end\":62240,\"start\":62235},{\"end\":62244,\"start\":62241},{\"end\":62257,\"start\":62251},{\"end\":62268,\"start\":62262},{\"end\":62281,\"start\":62274},{\"end\":62292,\"start\":62288},{\"end\":62311,\"start\":62302},{\"end\":62319,\"start\":62316},{\"end\":62774,\"start\":62769},{\"end\":62787,\"start\":62783},{\"end\":62806,\"start\":62803},{\"end\":63110,\"start\":63101},{\"end\":63128,\"start\":63120},{\"end\":63142,\"start\":63138},{\"end\":63158,\"start\":63154},{\"end\":63173,\"start\":63166},{\"end\":63184,\"start\":63181},{\"end\":63186,\"start\":63185},{\"end\":63202,\"start\":63199},{\"end\":63919,\"start\":63912},{\"end\":63931,\"start\":63928},{\"end\":64194,\"start\":64193},{\"end\":64212,\"start\":64203},{\"end\":64455,\"start\":64452},{\"end\":64466,\"start\":64462},{\"end\":64727,\"start\":64722},{\"end\":64741,\"start\":64734},{\"end\":64754,\"start\":64746},{\"end\":64764,\"start\":64761},{\"end\":64772,\"start\":64770},{\"end\":64788,\"start\":64780},{\"end\":64799,\"start\":64794},{\"end\":64806,\"start\":64800},{\"end\":64820,\"start\":64818},{\"end\":65304,\"start\":65298},{\"end\":65521,\"start\":65512},{\"end\":65531,\"start\":65528},{\"end\":65545,\"start\":65537},{\"end\":65559,\"start\":65552},{\"end\":65569,\"start\":65564},{\"end\":65581,\"start\":65574},{\"end\":65593,\"start\":65587},{\"end\":66044,\"start\":66036},{\"end\":66051,\"start\":66049},{\"end\":66065,\"start\":66057},{\"end\":66077,\"start\":66071},{\"end\":66088,\"start\":66085},{\"end\":66099,\"start\":66096},{\"end\":66112,\"start\":66105},{\"end\":66651,\"start\":66650},{\"end\":66667,\"start\":66658},{\"end\":67077,\"start\":67069},{\"end\":67092,\"start\":67085},{\"end\":67104,\"start\":67097},{\"end\":67115,\"start\":67111},{\"end\":67129,\"start\":67122},{\"end\":67132,\"start\":67130},{\"end\":67148,\"start\":67141},{\"end\":67496,\"start\":67489},{\"end\":67509,\"start\":67503},{\"end\":67521,\"start\":67515}]", "bib_author_last_name": "[{\"end\":37445,\"start\":37440},{\"end\":37464,\"start\":37462},{\"end\":37833,\"start\":37825},{\"end\":37846,\"start\":37840},{\"end\":37862,\"start\":37854},{\"end\":37875,\"start\":37873},{\"end\":37892,\"start\":37882},{\"end\":37907,\"start\":37902},{\"end\":38375,\"start\":38370},{\"end\":38397,\"start\":38392},{\"end\":38602,\"start\":38597},{\"end\":38614,\"start\":38611},{\"end\":38633,\"start\":38622},{\"end\":38645,\"start\":38641},{\"end\":38982,\"start\":38975},{\"end\":38998,\"start\":38992},{\"end\":39009,\"start\":39006},{\"end\":39027,\"start\":39021},{\"end\":39569,\"start\":39561},{\"end\":39583,\"start\":39579},{\"end\":39868,\"start\":39861},{\"end\":39884,\"start\":39875},{\"end\":39899,\"start\":39891},{\"end\":39917,\"start\":39909},{\"end\":40183,\"start\":40179},{\"end\":40197,\"start\":40191},{\"end\":40209,\"start\":40206},{\"end\":40222,\"start\":40218},{\"end\":40256,\"start\":40233},{\"end\":40270,\"start\":40264},{\"end\":40285,\"start\":40278},{\"end\":40297,\"start\":40292},{\"end\":40314,\"start\":40308},{\"end\":40329,\"start\":40321},{\"end\":40772,\"start\":40766},{\"end\":40788,\"start\":40783},{\"end\":40800,\"start\":40797},{\"end\":40820,\"start\":40811},{\"end\":41527,\"start\":41520},{\"end\":41546,\"start\":41539},{\"end\":41561,\"start\":41553},{\"end\":41576,\"start\":41570},{\"end\":41590,\"start\":41586},{\"end\":41603,\"start\":41599},{\"end\":41621,\"start\":41613},{\"end\":41633,\"start\":41629},{\"end\":41943,\"start\":41938},{\"end\":41956,\"start\":41950},{\"end\":41975,\"start\":41968},{\"end\":41986,\"start\":41982},{\"end\":42007,\"start\":41993},{\"end\":42016,\"start\":42009},{\"end\":42544,\"start\":42536},{\"end\":42554,\"start\":42551},{\"end\":42567,\"start\":42563},{\"end\":42579,\"start\":42576},{\"end\":43041,\"start\":43037},{\"end\":43057,\"start\":43049},{\"end\":43073,\"start\":43067},{\"end\":43085,\"start\":43082},{\"end\":43101,\"start\":43095},{\"end\":43116,\"start\":43110},{\"end\":43137,\"start\":43129},{\"end\":43152,\"start\":43145},{\"end\":43168,\"start\":43160},{\"end\":43941,\"start\":43927},{\"end\":43964,\"start\":43954},{\"end\":43974,\"start\":43969},{\"end\":43994,\"start\":43984},{\"end\":44010,\"start\":44001},{\"end\":44021,\"start\":44016},{\"end\":44037,\"start\":44032},{\"end\":44640,\"start\":44632},{\"end\":45006,\"start\":45001},{\"end\":45025,\"start\":45017},{\"end\":45038,\"start\":45032},{\"end\":45054,\"start\":45047},{\"end\":45071,\"start\":45061},{\"end\":45092,\"start\":45082},{\"end\":45108,\"start\":45100},{\"end\":45126,\"start\":45117},{\"end\":45480,\"start\":45477},{\"end\":45497,\"start\":45487},{\"end\":45513,\"start\":45508},{\"end\":45524,\"start\":45522},{\"end\":45858,\"start\":45855},{\"end\":45882,\"start\":45870},{\"end\":45895,\"start\":45890},{\"end\":45908,\"start\":45903},{\"end\":46400,\"start\":46392},{\"end\":46416,\"start\":46410},{\"end\":46430,\"start\":46425},{\"end\":46448,\"start\":46438},{\"end\":46715,\"start\":46710},{\"end\":46726,\"start\":46724},{\"end\":46737,\"start\":46735},{\"end\":46746,\"start\":46743},{\"end\":47286,\"start\":47282},{\"end\":47303,\"start\":47296},{\"end\":47317,\"start\":47311},{\"end\":47339,\"start\":47326},{\"end\":47357,\"start\":47346},{\"end\":47913,\"start\":47908},{\"end\":47927,\"start\":47920},{\"end\":47941,\"start\":47935},{\"end\":47959,\"start\":47948},{\"end\":48632,\"start\":48626},{\"end\":48646,\"start\":48643},{\"end\":48876,\"start\":48870},{\"end\":48892,\"start\":48884},{\"end\":48903,\"start\":48901},{\"end\":48916,\"start\":48912},{\"end\":48931,\"start\":48925},{\"end\":48940,\"start\":48933},{\"end\":49222,\"start\":49220},{\"end\":49235,\"start\":49233},{\"end\":49246,\"start\":49244},{\"end\":49253,\"start\":49251},{\"end\":49264,\"start\":49260},{\"end\":49631,\"start\":49629},{\"end\":49642,\"start\":49640},{\"end\":49662,\"start\":49655},{\"end\":50115,\"start\":50110},{\"end\":50129,\"start\":50127},{\"end\":50143,\"start\":50141},{\"end\":50153,\"start\":50149},{\"end\":50164,\"start\":50162},{\"end\":50178,\"start\":50175},{\"end\":50439,\"start\":50436},{\"end\":50452,\"start\":50448},{\"end\":50463,\"start\":50461},{\"end\":50479,\"start\":50474},{\"end\":50496,\"start\":50489},{\"end\":50511,\"start\":50505},{\"end\":50788,\"start\":50785},{\"end\":50798,\"start\":50795},{\"end\":50811,\"start\":50806},{\"end\":50823,\"start\":50821},{\"end\":50837,\"start\":50832},{\"end\":50849,\"start\":50845},{\"end\":50860,\"start\":50856},{\"end\":50872,\"start\":50867},{\"end\":50890,\"start\":50879},{\"end\":50908,\"start\":50900},{\"end\":51307,\"start\":51298},{\"end\":51319,\"start\":51312},{\"end\":51332,\"start\":51326},{\"end\":51350,\"start\":51344},{\"end\":51697,\"start\":51691},{\"end\":51707,\"start\":51699},{\"end\":52074,\"start\":52071},{\"end\":52084,\"start\":52080},{\"end\":52098,\"start\":52091},{\"end\":52447,\"start\":52441},{\"end\":52457,\"start\":52451},{\"end\":52466,\"start\":52463},{\"end\":52478,\"start\":52468},{\"end\":52685,\"start\":52681},{\"end\":52708,\"start\":52697},{\"end\":52722,\"start\":52717},{\"end\":52736,\"start\":52732},{\"end\":52751,\"start\":52745},{\"end\":53097,\"start\":53093},{\"end\":53105,\"start\":53103},{\"end\":53114,\"start\":53112},{\"end\":53125,\"start\":53121},{\"end\":53461,\"start\":53453},{\"end\":53475,\"start\":53469},{\"end\":53486,\"start\":53482},{\"end\":53500,\"start\":53497},{\"end\":54018,\"start\":54016},{\"end\":54029,\"start\":54025},{\"end\":54038,\"start\":54035},{\"end\":54049,\"start\":54046},{\"end\":54061,\"start\":54059},{\"end\":54077,\"start\":54074},{\"end\":54615,\"start\":54611},{\"end\":54631,\"start\":54623},{\"end\":55031,\"start\":55020},{\"end\":55049,\"start\":55046},{\"end\":55061,\"start\":55057},{\"end\":55069,\"start\":55065},{\"end\":55082,\"start\":55077},{\"end\":55089,\"start\":55084},{\"end\":55373,\"start\":55365},{\"end\":55385,\"start\":55383},{\"end\":55403,\"start\":55395},{\"end\":55648,\"start\":55642},{\"end\":55664,\"start\":55658},{\"end\":55677,\"start\":55674},{\"end\":55689,\"start\":55685},{\"end\":55703,\"start\":55699},{\"end\":55717,\"start\":55710},{\"end\":55728,\"start\":55724},{\"end\":55744,\"start\":55735},{\"end\":56104,\"start\":56097},{\"end\":56120,\"start\":56112},{\"end\":56854,\"start\":56835},{\"end\":56868,\"start\":56863},{\"end\":56878,\"start\":56870},{\"end\":57232,\"start\":57228},{\"end\":57247,\"start\":57245},{\"end\":57257,\"start\":57253},{\"end\":57275,\"start\":57269},{\"end\":57289,\"start\":57282},{\"end\":57831,\"start\":57828},{\"end\":57844,\"start\":57837},{\"end\":57858,\"start\":57854},{\"end\":57872,\"start\":57868},{\"end\":57884,\"start\":57879},{\"end\":57898,\"start\":57892},{\"end\":57918,\"start\":57909},{\"end\":58142,\"start\":58139},{\"end\":58155,\"start\":58148},{\"end\":58169,\"start\":58165},{\"end\":58183,\"start\":58179},{\"end\":58195,\"start\":58190},{\"end\":58209,\"start\":58203},{\"end\":58229,\"start\":58220},{\"end\":58633,\"start\":58627},{\"end\":58643,\"start\":58640},{\"end\":58666,\"start\":58648},{\"end\":58680,\"start\":58676},{\"end\":58693,\"start\":58688},{\"end\":58714,\"start\":58708},{\"end\":58725,\"start\":58716},{\"end\":59237,\"start\":59234},{\"end\":59251,\"start\":59245},{\"end\":59747,\"start\":59740},{\"end\":59762,\"start\":59756},{\"end\":59784,\"start\":59773},{\"end\":59794,\"start\":59792},{\"end\":59810,\"start\":59801},{\"end\":59828,\"start\":59822},{\"end\":59837,\"start\":59832},{\"end\":59850,\"start\":59845},{\"end\":59862,\"start\":59856},{\"end\":59873,\"start\":59864},{\"end\":60239,\"start\":60232},{\"end\":60254,\"start\":60248},{\"end\":60264,\"start\":60262},{\"end\":60280,\"start\":60271},{\"end\":60289,\"start\":60284},{\"end\":60300,\"start\":60295},{\"end\":60311,\"start\":60302},{\"end\":60720,\"start\":60716},{\"end\":60737,\"start\":60734},{\"end\":60750,\"start\":60743},{\"end\":60764,\"start\":60760},{\"end\":60778,\"start\":60775},{\"end\":60813,\"start\":60785},{\"end\":60824,\"start\":60819},{\"end\":60837,\"start\":60832},{\"end\":60854,\"start\":60848},{\"end\":60865,\"start\":60856},{\"end\":61443,\"start\":61439},{\"end\":61463,\"start\":61454},{\"end\":62233,\"start\":62228},{\"end\":62249,\"start\":62245},{\"end\":62260,\"start\":62258},{\"end\":62272,\"start\":62269},{\"end\":62286,\"start\":62282},{\"end\":62300,\"start\":62293},{\"end\":62314,\"start\":62312},{\"end\":62326,\"start\":62320},{\"end\":62781,\"start\":62775},{\"end\":62801,\"start\":62788},{\"end\":62815,\"start\":62807},{\"end\":63118,\"start\":63111},{\"end\":63136,\"start\":63129},{\"end\":63152,\"start\":63143},{\"end\":63164,\"start\":63159},{\"end\":63179,\"start\":63174},{\"end\":63197,\"start\":63187},{\"end\":63209,\"start\":63203},{\"end\":63716,\"start\":63699},{\"end\":63926,\"start\":63920},{\"end\":63937,\"start\":63932},{\"end\":64201,\"start\":64195},{\"end\":64219,\"start\":64213},{\"end\":64228,\"start\":64221},{\"end\":64460,\"start\":64456},{\"end\":64478,\"start\":64467},{\"end\":64732,\"start\":64728},{\"end\":64744,\"start\":64742},{\"end\":64759,\"start\":64755},{\"end\":64768,\"start\":64765},{\"end\":64778,\"start\":64773},{\"end\":64792,\"start\":64789},{\"end\":64816,\"start\":64807},{\"end\":64823,\"start\":64821},{\"end\":65307,\"start\":65305},{\"end\":65526,\"start\":65522},{\"end\":65535,\"start\":65532},{\"end\":65550,\"start\":65546},{\"end\":65562,\"start\":65560},{\"end\":65572,\"start\":65570},{\"end\":65585,\"start\":65582},{\"end\":65598,\"start\":65594},{\"end\":66047,\"start\":66045},{\"end\":66055,\"start\":66052},{\"end\":66069,\"start\":66066},{\"end\":66083,\"start\":66078},{\"end\":66094,\"start\":66089},{\"end\":66103,\"start\":66100},{\"end\":66115,\"start\":66113},{\"end\":66485,\"start\":66478},{\"end\":66656,\"start\":66652},{\"end\":66673,\"start\":66668},{\"end\":66681,\"start\":66675},{\"end\":67083,\"start\":67078},{\"end\":67095,\"start\":67093},{\"end\":67109,\"start\":67105},{\"end\":67120,\"start\":67116},{\"end\":67139,\"start\":67133},{\"end\":67155,\"start\":67149},{\"end\":67501,\"start\":67497},{\"end\":67513,\"start\":67510},{\"end\":67527,\"start\":67522}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":218719281},\"end\":37764,\"start\":37355},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":5076191},\"end\":38330,\"start\":37766},{\"attributes\":{\"id\":\"b2\"},\"end\":38528,\"start\":38332},{\"attributes\":{\"doi\":\"arXiv:1707.02363\",\"id\":\"b3\"},\"end\":38838,\"start\":38530},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":233296924},\"end\":39484,\"start\":38840},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":3513372},\"end\":39807,\"start\":39486},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":235485405},\"end\":40170,\"start\":39809},{\"attributes\":{\"doi\":\"arXiv:2107.03374\",\"id\":\"b7\"},\"end\":40676,\"start\":40172},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":52967399},\"end\":41452,\"start\":40678},{\"attributes\":{\"doi\":\"arXiv:2209.15003\",\"id\":\"b9\"},\"end\":41888,\"start\":41454},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":51839897},\"end\":42463,\"start\":41890},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":21698802},\"end\":42766,\"start\":42465},{\"attributes\":{\"id\":\"b12\"},\"end\":42949,\"start\":42768},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":85531331},\"end\":43870,\"start\":42951},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":49417344},\"end\":44523,\"start\":43872},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":243878353},\"end\":44900,\"start\":44525},{\"attributes\":{\"id\":\"b16\"},\"end\":45385,\"start\":44902},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":4858173},\"end\":45785,\"start\":45387},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":233423658},\"end\":46311,\"start\":45787},{\"attributes\":{\"doi\":\"arXiv:1702.08138\",\"id\":\"b19\"},\"end\":46661,\"start\":46313},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":231749482},\"end\":47215,\"start\":46663},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":497108},\"end\":47818,\"start\":47217},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":4956100},\"end\":48584,\"start\":47820},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":54181011},\"end\":48813,\"start\":48586},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":249017743},\"end\":49210,\"start\":48815},{\"attributes\":{\"doi\":\"arXiv:1812.05271\",\"id\":\"b25\"},\"end\":49538,\"start\":49212},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":237491903},\"end\":50064,\"start\":49540},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":10642653},\"end\":50322,\"start\":50066},{\"attributes\":{\"doi\":\"arXiv:2107.13586\",\"id\":\"b28\"},\"end\":50776,\"start\":50324},{\"attributes\":{\"doi\":\"arXiv:1907.11692\",\"id\":\"b29\"},\"end\":51232,\"start\":50778},{\"attributes\":{\"doi\":\"arXiv:2111.08284\",\"id\":\"b30\"},\"end\":51544,\"start\":51234},{\"attributes\":{\"id\":\"b31\"},\"end\":51954,\"start\":51546},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b32\",\"matched_paper_id\":211296750},\"end\":52362,\"start\":51956},{\"attributes\":{\"doi\":\"arXiv:1605.07725\",\"id\":\"b33\"},\"end\":52669,\"start\":52364},{\"attributes\":{\"doi\":\"arXiv:1806.00692\",\"id\":\"b34\"},\"end\":53017,\"start\":52671},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b35\",\"matched_paper_id\":59291958},\"end\":53379,\"start\":53019},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":11080756},\"end\":53905,\"start\":53381},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":248780123},\"end\":54570,\"start\":53907},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":5337047},\"end\":54966,\"start\":54572},{\"attributes\":{\"doi\":\"arXiv:1906.06032\",\"id\":\"b39\"},\"end\":55287,\"start\":54968},{\"attributes\":{\"doi\":\"arXiv:2204.00498\",\"id\":\"b40\"},\"end\":55597,\"start\":55289},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b41\",\"matched_paper_id\":232035663},\"end\":56026,\"start\":55599},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":201646309},\"end\":56758,\"start\":56028},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":21740766},\"end\":57156,\"start\":56760},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":235898904},\"end\":57743,\"start\":57158},{\"attributes\":{\"doi\":\"10.48550/ARXIV.2206.10668\",\"id\":\"b45\"},\"end\":58130,\"start\":57745},{\"attributes\":{\"doi\":\"arXiv:2206.10668\",\"id\":\"b46\"},\"end\":58562,\"start\":58132},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":238408362},\"end\":59155,\"start\":58564},{\"attributes\":{\"doi\":\"10.18653/v1/2020.intexsempar-1.2\",\"id\":\"b48\",\"matched_paper_id\":226283862},\"end\":59734,\"start\":59157},{\"attributes\":{\"id\":\"b49\"},\"end\":60194,\"start\":59736},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":53806548},\"end\":60645,\"start\":60196},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":233297024},\"end\":61366,\"start\":60647},{\"attributes\":{\"doi\":\"10.18653/v1/2022.naacl-main.396\",\"id\":\"b52\",\"matched_paper_id\":245218525},\"end\":62170,\"start\":61368},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":247595229},\"end\":62651,\"start\":62172},{\"attributes\":{\"doi\":\"arXiv:2205.11503\",\"id\":\"b54\"},\"end\":63057,\"start\":62653},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":604334},\"end\":63618,\"start\":63059},{\"attributes\":{\"id\":\"b56\"},\"end\":63846,\"start\":63620},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":140311498},\"end\":64150,\"start\":63848},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":13381535},\"end\":64387,\"start\":64152},{\"attributes\":{\"id\":\"b59\"},\"end\":64633,\"start\":64389},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":242757097},\"end\":65240,\"start\":64635},{\"attributes\":{\"id\":\"b61\"},\"end\":65449,\"start\":65242},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":237485500},\"end\":65966,\"start\":65451},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b63\",\"matched_paper_id\":235166908},\"end\":66403,\"start\":65968},{\"attributes\":{\"id\":\"b64\"},\"end\":66578,\"start\":66405},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":263135},\"end\":66999,\"start\":66580},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b66\",\"matched_paper_id\":59222747},\"end\":67446,\"start\":67001},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":3513418},\"end\":67732,\"start\":67448}]", "bib_title": "[{\"end\":37431,\"start\":37355},{\"end\":37814,\"start\":37766},{\"end\":38969,\"start\":38840},{\"end\":39551,\"start\":39486},{\"end\":39850,\"start\":39809},{\"end\":40758,\"start\":40678},{\"end\":41931,\"start\":41890},{\"end\":42528,\"start\":42465},{\"end\":43027,\"start\":42951},{\"end\":43915,\"start\":43872},{\"end\":44623,\"start\":44525},{\"end\":45472,\"start\":45387},{\"end\":45847,\"start\":45787},{\"end\":46703,\"start\":46663},{\"end\":47269,\"start\":47217},{\"end\":47900,\"start\":47820},{\"end\":48614,\"start\":48586},{\"end\":48860,\"start\":48815},{\"end\":49620,\"start\":49540},{\"end\":50104,\"start\":50066},{\"end\":52063,\"start\":51956},{\"end\":53084,\"start\":53019},{\"end\":53443,\"start\":53381},{\"end\":54008,\"start\":53907},{\"end\":54601,\"start\":54572},{\"end\":55633,\"start\":55599},{\"end\":56090,\"start\":56028},{\"end\":56826,\"start\":56760},{\"end\":57219,\"start\":57158},{\"end\":58618,\"start\":58564},{\"end\":59223,\"start\":59157},{\"end\":60226,\"start\":60196},{\"end\":60706,\"start\":60647},{\"end\":61429,\"start\":61368},{\"end\":62218,\"start\":62172},{\"end\":63099,\"start\":63059},{\"end\":63910,\"start\":63848},{\"end\":64191,\"start\":64152},{\"end\":64720,\"start\":64635},{\"end\":65510,\"start\":65451},{\"end\":66034,\"start\":65968},{\"end\":66648,\"start\":66580},{\"end\":67067,\"start\":67001},{\"end\":67487,\"start\":67448}]", "bib_author": "[{\"end\":37447,\"start\":37433},{\"end\":37454,\"start\":37447},{\"end\":37466,\"start\":37454},{\"end\":37835,\"start\":37816},{\"end\":37848,\"start\":37835},{\"end\":37864,\"start\":37848},{\"end\":37877,\"start\":37864},{\"end\":37894,\"start\":37877},{\"end\":37909,\"start\":37894},{\"end\":38377,\"start\":38360},{\"end\":38399,\"start\":38377},{\"end\":38604,\"start\":38591},{\"end\":38616,\"start\":38604},{\"end\":38635,\"start\":38616},{\"end\":38647,\"start\":38635},{\"end\":38984,\"start\":38971},{\"end\":39000,\"start\":38984},{\"end\":39011,\"start\":39000},{\"end\":39029,\"start\":39011},{\"end\":39571,\"start\":39553},{\"end\":39585,\"start\":39571},{\"end\":39870,\"start\":39852},{\"end\":39886,\"start\":39870},{\"end\":39901,\"start\":39886},{\"end\":39919,\"start\":39901},{\"end\":40185,\"start\":40174},{\"end\":40199,\"start\":40185},{\"end\":40211,\"start\":40199},{\"end\":40224,\"start\":40211},{\"end\":40258,\"start\":40224},{\"end\":40272,\"start\":40258},{\"end\":40287,\"start\":40272},{\"end\":40299,\"start\":40287},{\"end\":40316,\"start\":40299},{\"end\":40331,\"start\":40316},{\"end\":40774,\"start\":40760},{\"end\":40790,\"start\":40774},{\"end\":40802,\"start\":40790},{\"end\":40822,\"start\":40802},{\"end\":41529,\"start\":41513},{\"end\":41548,\"start\":41529},{\"end\":41563,\"start\":41548},{\"end\":41578,\"start\":41563},{\"end\":41592,\"start\":41578},{\"end\":41605,\"start\":41592},{\"end\":41623,\"start\":41605},{\"end\":41635,\"start\":41623},{\"end\":41945,\"start\":41933},{\"end\":41958,\"start\":41945},{\"end\":41977,\"start\":41958},{\"end\":41988,\"start\":41977},{\"end\":42009,\"start\":41988},{\"end\":42018,\"start\":42009},{\"end\":42546,\"start\":42530},{\"end\":42556,\"start\":42546},{\"end\":42569,\"start\":42556},{\"end\":42581,\"start\":42569},{\"end\":43043,\"start\":43029},{\"end\":43059,\"start\":43043},{\"end\":43075,\"start\":43059},{\"end\":43087,\"start\":43075},{\"end\":43103,\"start\":43087},{\"end\":43118,\"start\":43103},{\"end\":43139,\"start\":43118},{\"end\":43154,\"start\":43139},{\"end\":43170,\"start\":43154},{\"end\":43943,\"start\":43917},{\"end\":43966,\"start\":43943},{\"end\":43976,\"start\":43966},{\"end\":43996,\"start\":43976},{\"end\":44012,\"start\":43996},{\"end\":44023,\"start\":44012},{\"end\":44039,\"start\":44023},{\"end\":44642,\"start\":44625},{\"end\":45008,\"start\":44992},{\"end\":45027,\"start\":45008},{\"end\":45040,\"start\":45027},{\"end\":45056,\"start\":45040},{\"end\":45073,\"start\":45056},{\"end\":45094,\"start\":45073},{\"end\":45110,\"start\":45094},{\"end\":45128,\"start\":45110},{\"end\":45482,\"start\":45474},{\"end\":45499,\"start\":45482},{\"end\":45515,\"start\":45499},{\"end\":45526,\"start\":45515},{\"end\":45860,\"start\":45849},{\"end\":45884,\"start\":45860},{\"end\":45897,\"start\":45884},{\"end\":45910,\"start\":45897},{\"end\":46402,\"start\":46384},{\"end\":46418,\"start\":46402},{\"end\":46432,\"start\":46418},{\"end\":46450,\"start\":46432},{\"end\":46717,\"start\":46705},{\"end\":46728,\"start\":46717},{\"end\":46739,\"start\":46728},{\"end\":46748,\"start\":46739},{\"end\":47288,\"start\":47271},{\"end\":47305,\"start\":47288},{\"end\":47319,\"start\":47305},{\"end\":47341,\"start\":47319},{\"end\":47359,\"start\":47341},{\"end\":47915,\"start\":47902},{\"end\":47929,\"start\":47915},{\"end\":47943,\"start\":47929},{\"end\":47961,\"start\":47943},{\"end\":48634,\"start\":48616},{\"end\":48648,\"start\":48634},{\"end\":48878,\"start\":48862},{\"end\":48894,\"start\":48878},{\"end\":48905,\"start\":48894},{\"end\":48918,\"start\":48905},{\"end\":48933,\"start\":48918},{\"end\":48942,\"start\":48933},{\"end\":49224,\"start\":49212},{\"end\":49237,\"start\":49224},{\"end\":49248,\"start\":49237},{\"end\":49255,\"start\":49248},{\"end\":49266,\"start\":49255},{\"end\":49633,\"start\":49622},{\"end\":49644,\"start\":49633},{\"end\":49664,\"start\":49644},{\"end\":50117,\"start\":50106},{\"end\":50131,\"start\":50117},{\"end\":50145,\"start\":50131},{\"end\":50155,\"start\":50145},{\"end\":50166,\"start\":50155},{\"end\":50180,\"start\":50166},{\"end\":50441,\"start\":50428},{\"end\":50454,\"start\":50441},{\"end\":50465,\"start\":50454},{\"end\":50481,\"start\":50465},{\"end\":50498,\"start\":50481},{\"end\":50513,\"start\":50498},{\"end\":50790,\"start\":50778},{\"end\":50800,\"start\":50790},{\"end\":50813,\"start\":50800},{\"end\":50825,\"start\":50813},{\"end\":50839,\"start\":50825},{\"end\":50851,\"start\":50839},{\"end\":50862,\"start\":50851},{\"end\":50874,\"start\":50862},{\"end\":50892,\"start\":50874},{\"end\":50910,\"start\":50892},{\"end\":51309,\"start\":51294},{\"end\":51321,\"start\":51309},{\"end\":51334,\"start\":51321},{\"end\":51352,\"start\":51334},{\"end\":51699,\"start\":51689},{\"end\":51709,\"start\":51699},{\"end\":52076,\"start\":52065},{\"end\":52086,\"start\":52076},{\"end\":52100,\"start\":52086},{\"end\":52449,\"start\":52434},{\"end\":52459,\"start\":52449},{\"end\":52468,\"start\":52459},{\"end\":52480,\"start\":52468},{\"end\":52687,\"start\":52671},{\"end\":52710,\"start\":52687},{\"end\":52724,\"start\":52710},{\"end\":52738,\"start\":52724},{\"end\":52753,\"start\":52738},{\"end\":53099,\"start\":53086},{\"end\":53107,\"start\":53099},{\"end\":53116,\"start\":53107},{\"end\":53127,\"start\":53116},{\"end\":53463,\"start\":53445},{\"end\":53477,\"start\":53463},{\"end\":53488,\"start\":53477},{\"end\":53502,\"start\":53488},{\"end\":54020,\"start\":54010},{\"end\":54031,\"start\":54020},{\"end\":54040,\"start\":54031},{\"end\":54051,\"start\":54040},{\"end\":54063,\"start\":54051},{\"end\":54079,\"start\":54063},{\"end\":54617,\"start\":54603},{\"end\":54633,\"start\":54617},{\"end\":55033,\"start\":55014},{\"end\":55051,\"start\":55033},{\"end\":55063,\"start\":55051},{\"end\":55071,\"start\":55063},{\"end\":55084,\"start\":55071},{\"end\":55091,\"start\":55084},{\"end\":55375,\"start\":55355},{\"end\":55387,\"start\":55375},{\"end\":55405,\"start\":55387},{\"end\":55650,\"start\":55635},{\"end\":55666,\"start\":55650},{\"end\":55679,\"start\":55666},{\"end\":55691,\"start\":55679},{\"end\":55705,\"start\":55691},{\"end\":55719,\"start\":55705},{\"end\":55730,\"start\":55719},{\"end\":55746,\"start\":55730},{\"end\":56106,\"start\":56092},{\"end\":56122,\"start\":56106},{\"end\":56856,\"start\":56828},{\"end\":56870,\"start\":56856},{\"end\":56880,\"start\":56870},{\"end\":57234,\"start\":57221},{\"end\":57249,\"start\":57234},{\"end\":57259,\"start\":57249},{\"end\":57277,\"start\":57259},{\"end\":57291,\"start\":57277},{\"end\":57833,\"start\":57821},{\"end\":57846,\"start\":57833},{\"end\":57860,\"start\":57846},{\"end\":57874,\"start\":57860},{\"end\":57886,\"start\":57874},{\"end\":57900,\"start\":57886},{\"end\":57920,\"start\":57900},{\"end\":58144,\"start\":58132},{\"end\":58157,\"start\":58144},{\"end\":58171,\"start\":58157},{\"end\":58185,\"start\":58171},{\"end\":58197,\"start\":58185},{\"end\":58211,\"start\":58197},{\"end\":58231,\"start\":58211},{\"end\":58635,\"start\":58620},{\"end\":58645,\"start\":58635},{\"end\":58668,\"start\":58645},{\"end\":58682,\"start\":58668},{\"end\":58695,\"start\":58682},{\"end\":58716,\"start\":58695},{\"end\":58727,\"start\":58716},{\"end\":59239,\"start\":59225},{\"end\":59253,\"start\":59239},{\"end\":59749,\"start\":59736},{\"end\":59764,\"start\":59749},{\"end\":59786,\"start\":59764},{\"end\":59796,\"start\":59786},{\"end\":59812,\"start\":59796},{\"end\":59830,\"start\":59812},{\"end\":59839,\"start\":59830},{\"end\":59852,\"start\":59839},{\"end\":59864,\"start\":59852},{\"end\":59875,\"start\":59864},{\"end\":60241,\"start\":60228},{\"end\":60256,\"start\":60241},{\"end\":60266,\"start\":60256},{\"end\":60282,\"start\":60266},{\"end\":60291,\"start\":60282},{\"end\":60302,\"start\":60291},{\"end\":60313,\"start\":60302},{\"end\":60722,\"start\":60708},{\"end\":60739,\"start\":60722},{\"end\":60752,\"start\":60739},{\"end\":60768,\"start\":60752},{\"end\":60780,\"start\":60768},{\"end\":60815,\"start\":60780},{\"end\":60826,\"start\":60815},{\"end\":60839,\"start\":60826},{\"end\":60856,\"start\":60839},{\"end\":60867,\"start\":60856},{\"end\":61445,\"start\":61431},{\"end\":61465,\"start\":61445},{\"end\":62235,\"start\":62220},{\"end\":62251,\"start\":62235},{\"end\":62262,\"start\":62251},{\"end\":62274,\"start\":62262},{\"end\":62288,\"start\":62274},{\"end\":62302,\"start\":62288},{\"end\":62316,\"start\":62302},{\"end\":62328,\"start\":62316},{\"end\":62783,\"start\":62769},{\"end\":62803,\"start\":62783},{\"end\":62817,\"start\":62803},{\"end\":63120,\"start\":63101},{\"end\":63138,\"start\":63120},{\"end\":63154,\"start\":63138},{\"end\":63166,\"start\":63154},{\"end\":63181,\"start\":63166},{\"end\":63199,\"start\":63181},{\"end\":63211,\"start\":63199},{\"end\":63718,\"start\":63699},{\"end\":63928,\"start\":63912},{\"end\":63939,\"start\":63928},{\"end\":64203,\"start\":64193},{\"end\":64221,\"start\":64203},{\"end\":64230,\"start\":64221},{\"end\":64462,\"start\":64452},{\"end\":64480,\"start\":64462},{\"end\":64734,\"start\":64722},{\"end\":64746,\"start\":64734},{\"end\":64761,\"start\":64746},{\"end\":64770,\"start\":64761},{\"end\":64780,\"start\":64770},{\"end\":64794,\"start\":64780},{\"end\":64818,\"start\":64794},{\"end\":64825,\"start\":64818},{\"end\":65309,\"start\":65298},{\"end\":65528,\"start\":65512},{\"end\":65537,\"start\":65528},{\"end\":65552,\"start\":65537},{\"end\":65564,\"start\":65552},{\"end\":65574,\"start\":65564},{\"end\":65587,\"start\":65574},{\"end\":65600,\"start\":65587},{\"end\":66049,\"start\":66036},{\"end\":66057,\"start\":66049},{\"end\":66071,\"start\":66057},{\"end\":66085,\"start\":66071},{\"end\":66096,\"start\":66085},{\"end\":66105,\"start\":66096},{\"end\":66117,\"start\":66105},{\"end\":66487,\"start\":66478},{\"end\":66658,\"start\":66650},{\"end\":66675,\"start\":66658},{\"end\":66683,\"start\":66675},{\"end\":67085,\"start\":67069},{\"end\":67097,\"start\":67085},{\"end\":67111,\"start\":67097},{\"end\":67122,\"start\":67111},{\"end\":67141,\"start\":67122},{\"end\":67157,\"start\":67141},{\"end\":67503,\"start\":67489},{\"end\":67515,\"start\":67503},{\"end\":67529,\"start\":67515}]", "bib_venue": "[{\"end\":37539,\"start\":37466},{\"end\":37995,\"start\":37909},{\"end\":38358,\"start\":38332},{\"end\":38589,\"start\":38530},{\"end\":39115,\"start\":39029},{\"end\":39637,\"start\":39585},{\"end\":39967,\"start\":39919},{\"end\":40964,\"start\":40822},{\"end\":41511,\"start\":41454},{\"end\":42105,\"start\":42018},{\"end\":42604,\"start\":42581},{\"end\":42831,\"start\":42768},{\"end\":43312,\"start\":43170},{\"end\":44126,\"start\":44039},{\"end\":44698,\"start\":44642},{\"end\":44990,\"start\":44902},{\"end\":45561,\"start\":45526},{\"end\":45996,\"start\":45910},{\"end\":46382,\"start\":46313},{\"end\":46868,\"start\":46748},{\"end\":47446,\"start\":47359},{\"end\":48103,\"start\":47961},{\"end\":48692,\"start\":48648},{\"end\":49003,\"start\":48942},{\"end\":49353,\"start\":49282},{\"end\":49750,\"start\":49664},{\"end\":50185,\"start\":50180},{\"end\":50426,\"start\":50324},{\"end\":50981,\"start\":50926},{\"end\":51292,\"start\":51234},{\"end\":51687,\"start\":51546},{\"end\":52142,\"start\":52104},{\"end\":52432,\"start\":52364},{\"end\":52822,\"start\":52769},{\"end\":53175,\"start\":53131},{\"end\":53589,\"start\":53502},{\"end\":54166,\"start\":54079},{\"end\":54719,\"start\":54633},{\"end\":55012,\"start\":54968},{\"end\":55353,\"start\":55289},{\"end\":55794,\"start\":55750},{\"end\":56297,\"start\":56122},{\"end\":56949,\"start\":56880},{\"end\":57378,\"start\":57291},{\"end\":57819,\"start\":57745},{\"end\":58328,\"start\":58247},{\"end\":58808,\"start\":58727},{\"end\":59365,\"start\":59285},{\"end\":59955,\"start\":59875},{\"end\":60374,\"start\":60313},{\"end\":60953,\"start\":60867},{\"end\":61638,\"start\":61496},{\"end\":62393,\"start\":62328},{\"end\":62767,\"start\":62653},{\"end\":63267,\"start\":63211},{\"end\":63697,\"start\":63620},{\"end\":63988,\"start\":63939},{\"end\":64255,\"start\":64230},{\"end\":64450,\"start\":64389},{\"end\":64919,\"start\":64825},{\"end\":65296,\"start\":65242},{\"end\":65661,\"start\":65600},{\"end\":66165,\"start\":66121},{\"end\":66476,\"start\":66405},{\"end\":66748,\"start\":66683},{\"end\":67205,\"start\":67161},{\"end\":67581,\"start\":67529},{\"end\":38068,\"start\":37997},{\"end\":39188,\"start\":39117},{\"end\":41093,\"start\":40966},{\"end\":42179,\"start\":42107},{\"end\":42614,\"start\":42606},{\"end\":43441,\"start\":43314},{\"end\":44200,\"start\":44128},{\"end\":46069,\"start\":45998},{\"end\":46975,\"start\":46870},{\"end\":47520,\"start\":47448},{\"end\":48232,\"start\":48105},{\"end\":49823,\"start\":49752},{\"end\":53663,\"start\":53591},{\"end\":54240,\"start\":54168},{\"end\":54792,\"start\":54721},{\"end\":56459,\"start\":56299},{\"end\":57452,\"start\":57380},{\"end\":58876,\"start\":58810},{\"end\":59432,\"start\":59367},{\"end\":60422,\"start\":60376},{\"end\":61026,\"start\":60955},{\"end\":61789,\"start\":61640},{\"end\":63286,\"start\":63269},{\"end\":65709,\"start\":65663},{\"end\":66800,\"start\":66750}]"}}}, "year": 2023, "month": 12, "day": 17}