{"id": 84187068, "updated": "2023-08-06 08:52:05.242", "metadata": {"title": "Numerically Stable Polynomially Coded Computing", "authors": "[{\"first\":\"Mohammad\",\"last\":\"Fahim\",\"middle\":[]},{\"first\":\"Viveck\",\"last\":\"Cadambe\",\"middle\":[\"R.\"]}]", "venue": "2019 IEEE International Symposium on Information Theory (ISIT)", "journal": "2019 IEEE International Symposium on Information Theory (ISIT)", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "We consider the issue of numerical stability in solving the problem of coded large scale matrix multiplication in distributed systems where worker nodes are prone to failures/delays. We construct new codes that achieve comparable fault tolerance as previous codes, but are more numerically stable. Unlike previous codes that use polynomials expanded in a monomial basis, our codes use polynomials expressed in a basis of orthonormal polynomials. We show via new theoretical results on the condition number, as well as numerical experiments, that the application of these codes can lead to significantly more numerically stable computation than the current monomial-basis codes.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2976645076", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/isit/FahimC19", "doi": "10.1109/isit.2019.8849468"}}, "content": {"source": {"pdf_hash": "01106c3fd8388f188ca7cef7518c1e3eab00a911", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1903.08326", "status": "GREEN"}}, "grobid": {"id": "2e4ad01b2f76f46802a82c537955a83e00391745", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/01106c3fd8388f188ca7cef7518c1e3eab00a911.txt", "contents": "\nNumerically Stable Polynomially Coded Computing\n\n\nMohammad Fahim fahim@psu.edu \nDepartment of Electrical Engineering\nPennsylvania State University\n\n\nViveck R Cadambe viveck@engr.psu.edu. \nDepartment of Electrical Engineering\nPennsylvania State University\n\n\nNumerically Stable Polynomially Coded Computing\n\nWe consider the issue of numerical stability in solving the problem of coded large scale matrix multiplication in distributed systems where worker nodes are prone to failures/delays. We construct new codes that achieve comparable fault tolerance as previous codes, but are more numerically stable. Unlike previous codes that use polynomials expanded in a monomial basis, our codes use polynomials expressed in a basis of orthonormal polynomials. We show via new theoretical results on the condition number, as well as numerical experiments, that the application of these codes can lead to significantly more numerically stable computation than the current monomial-basis codes.\n\nI. INTRODUCTION\n\nDistributed computing is central to modern machine learning and data analytics, where millions of data points with very high dimensions are being processed. The central challenges to implementing and scaling distributed data processing across a large number of nodes are stragglers, communication bottlenecks and security issues. A lot of recent research in the area of \"coded computing\" focuses on incorporating redundancy to distributed computation based on coding-inspired strategies to tackle these challenges. Such ideas have been applied to different large scale distributed computations such as matrix multiplication [1]- [3], gradient methods [4], [5], linear solvers [6], [7] (also see references in [8]). An important idea that has emerged from this body of the work is the use of novel, Reed-Solomon like polynomial based methods for encoding data. These polynomial based methods are the focus of our paper.\n\nIn polynomial based methods, the data is partitioned, and each worker stores a linearly encoded combination of these data partitions. The linear combination coefficients are chosen based on evaluations of an appropriate polynomial. The nodes then perform computation on these encoded versions of the data, and a central master/fusion nodes aggregates the outputs of these computations to recover the overall computation via a decoding process that inevitably involves polynomial interpolation. Perhaps the most striking application of polynomial based methods comes in the context of matrix multiplication. To multiply two N \u00d7 N matrices A, B, assuming that each node stores 1/m of each matrix, classical work in algorithm based fault tolerance [9] outlines a coding based method which has been analyzed in [10]. Reference [1] showed through polynomial based encoding methods that the result of just m 2 nodes can be used by the master node to recover the matrixproduct. That is, polynomial based codes ensures that the recovery threshold -the number of nodes whose computation suffices to recover the overall matrix-product -does not grow This work is supported by NSF grant No. CCF 1763657.\n\nwith P , the number of the distributed system's worker nodes, unlike the approaches of [9], [10]. The recovery threshold for matrix multiplication has been improved to 2m\u22121 via MatDot codes proposed in [2], albeit at a higher computation cost than [1] at the computation nodes. In addition to matrix multiplication, polynomial based coded computing methods have been applied to gradient coding [5], communication efficient and straggler-resilient linear inverse methods [7], [11], and secure, straggler resilient multi-variate polynomial computation [12]. Despite the enormous success, a central challenge that limits the scalability of polynomial based methods in practice are their numerical stability -this is the focus of our paper.\n\nThe decoding methods for polynomial based methods require interpolating a degree K \u22121 polynomial using K evaluation points. The main reason for the instability of interpolation is that interpolation effectively solves a linear system whose transform is characterized by a Vandermonde matrix. It is well known that the condition number of Vandermonde matrices with real-valued nodes grows exponentially in the size of the matrix [13], [14] (see also coded computing literature that reports this issue [5], [15]). The large condition number means that small perturbations of the Vandermonde matrix due to numerical precision issues can result in singular matrices [16]. The problem of numerically unstable decoding also arises in the context of signal reconstructions in communication systems and has been studied in [17] in presence of erasure channels with additive noise.\n\nOur Contributions: In this paper, we propose new codes for distributed real-valued matrix multiplications. In particular, when multiplying two matrices over P computation nodes where each node stores 1/m of each of the two matrices, our code achieves a recovery threshold of 2m \u2212 1 -the best known recovery threshold for matrix multiplication thus far [2], [18]. The basic template of our construction is provided in Section III (Constr. 1). In our construction, the generator matrix that is used to encode the original multiplicands has entries which are evaluations of orthonormal polynomials, instead of monomials like previous constructions. In Constr. 2 in Sec. IV, we specialize our constructions of Sec. III to the use of Chebyshev polynomials, which are a class of orthogonal polynomials that are ubiquitous in numerical methods and approximation theory. The use of Chebyshev polynomials leads to encoding matrices which are known as Chebyshev-Vandermonde matrices [14], instead of Vandermonde matrices. Constr. 2 coupled with carefully chosen evaluation points lead to numerically stable matrix-multiplication codes. In Theorem 4.1 in Sec. IV, we show that the condition number for our construction grows at most polynomially in the number of computation nodes. This result is in contrast with the well known exponential growth for Vandermonde systems. Numerical results reflect the significant improvement in stability as well. For instance in a system with P = 100 nodes, when a single redundant node is needed, the condition number for the monomial basis (e.g, MatDot codes [2]) is over 10 20 , whereas our codes with our choice of evaluation points leads to a condition number of less than 10 4 . From a technical viewpoint, our code constructions and results involves nontrivial use of ideas from numerical approximation theory. Our bound on the condition number of our construction may also be viewed as a new coding-inspired contribution to numerical methods literature.\n\n\nII. PRELIMINARIES ON ORTHOGONAL POLYNOMIALS\n\nIn the following, we present some definitions and theorems that will be used in this paper [19], [20]. Notice that, in the following, C[a, b] denotes the vector space of continuous integrable functions defined on the interval [a, b].\n\n\nDefinition 2.1 (Inner Products on C[a, b])\n\n: For any f, g \u2208 C[a, b], and given a non-negative integrable weight function w,\nf, g = b a f (x)g(x)w(x)dx defines an inner product on C[a, b] relative to w.\nDefinition 2.2 (Orthogonal Polynomials): Consider a non-negative integrable weight function w, the polynomials\n{q i } i\u22650 in C[a, b] where q i (x) has degree i and q i , q j = c i if i = j, 0 otherwise,(1)\nfor some non-zero values c i , where the inner product is relative to w, are called orthogonal polynomials relative to w, . Definition 2.3 (Orthonormal Polynomials): Consider a non-negative integrable weight function w, the polynomials\n{q i } i\u22650 , where q i (x) has degree i, in C[a, b] such that q i , q j = 1 if i = j, 0 otherwise,(2)\nwhere the inner product is relative to w, are called orthonormal polynomials relative to w.\n\nNote that based on the definition, q n (x) is orthogonal to all polynomials of degree \u2264 n \u2212 1. For w(x) = 1, the orthogonal polynomials are Legendre polynomials, which are derived via Gram-Schmidt procedure applied to {1, x, x 2 , . . . , } sequentially. The following is an important class of orthogonal polynomials in our paper. Example 2.1 (Chebyshev polynomials of the first kind): The following recurrence relation defines the Chebyshev polynomials of the first kind:\nT n (x) = 2xT n\u22121 (x) \u2212 T n\u22122 (x), where, T 0 (x) = 1, T 1 (x) = x.\nThese Chebyshev polynomials have a lot of interesting applications in numerical integration, and least-square approximations to functions [19]. In addition, 1 \u221a 2 T 0 , T 1 , T 2 , \u00b7 \u00b7 \u00b7 are orthonormal relative to the weight function 2 \u03c0 \u221a 1\u2212x 2 . In general, Chebyshev polynomials are defined over x \u2208 R. However, for x \u2208 [\u22121, 1], T n (x) = cos(n arccos(x)), for any n \u2208 N. For the rest of this paper, We next state the Gauss Quadrature result which is a fundamental result in numerical analysis [19].\n\nTheorem 2.1 (Gauss Quadrature [20]): Fix a weight function w, and let {q i } i\u22650 be a set of orthogonal polynomials in C[a, b] relative to w. Given n, let t 1 , \u00b7 \u00b7 \u00b7 , t n be the roots of q n such that a \u2264 t 1 < t 2 < \u00b7 \u00b7 \u00b7 < t n \u2264 b, there exist real values a 1 , \u00b7 \u00b7 \u00b7 , a n such that\nn i=1 a i f (t i ) = b a f (x)w(x)dx,\nfor any polynomial f with degree less than 2n.\n\nRemark 2.1: 1) Consider any orthonormal polynomials {q i } i>0 . For any n \u2208 N, the set {q 0 , q 1 , \u00b7 \u00b7 \u00b7 , q n\u22121 } forms a basis for the vector space of polynomials with degree less than n. 2) In Theorem 2.1, a 1 , \u00b7 \u00b7 \u00b7 , a n can be chosen as\na i = b a j\u2208[n]\u2212i x \u2212 t j t i \u2212 t j w(x)dx, i \u2208 [n].(3)\n3) In Theorem 2.1, the roots of q n , i.e., t 1 , \u00b7 \u00b7 \u00b7 , t n are, in fact, real and distinct. Moreover, the Chebyshev polynomial of the first kind T n has the following roots\n\u03c1 (n) i = cos 2i \u2212 1 2n \u03c0 , i \u2208 [n].(4)\nIn this paper, \u03c1\n(n) 1 , \u00b7 \u00b7 \u00b7 , \u03c1 (n)\nn are used to denote the n roots of T n . Furthermore, in this case, the weights a i in (3) are all equal to \u03c0 2 .\n\n\nIII. ORTHONORMAL POLYNOMIALS BASED CODES A. System Model and Problem Formulation\n\nWe consider the distributed framework depicted in Fig. 1 that consists of a master node, P worker nodes. The master node possesses two real-valued input matrices A, B with dimensions N 1 \u00d7 N 2 , N 2 \u00d7 N 3 , respectively. Every worker node receives from the master node an encoded matrix of A of dimension N 1 \u00d7 N 2 /m and an encoded matrix of B of dimension N 2 /m \u00d7 N 3 , for some positive integer partitioning factor m that divides N 2 , and performs matrix multiplication of these two received inputs. Upon performing the matrix multiplication, each worker node sends the result to the fusion node. The fusion node needs to recover the matrix 12 13 14 15\n\nPartitioning Factor (m) multiplication AB once it receives the results of any k worker nodes, where k \u2264 P . The quantity k is called the recovery threshold of the distributed computing scheme.\n\n\nB. Orthonormal Polynomials based Code Construction\n\nWe provide a construction for the problem in Sec. III-A based on orthonormal polynomials for any weight function w.\n\n\nConstruction 1 (Orthonormal Polynomials based Codes):\n\nSplitting of input matrices: Matrix A is split vertically into m equal sub-matrices (of dimension N 1 \u00d7 N 2 /m each) and B is split horizontally into m equal sub-matrices (of dimension N 2 /m \u00d7 N 3 each) as follows:\nA = (A 0 A 1 . . . A m\u22121 ) , B = \uf8eb \uf8ec \uf8ec \uf8ed B 0 B 1 . . . B m\u22121 \uf8f6 \uf8f7 \uf8f7 \uf8f8 .\nMaster node (encoding): Let x 1 , x 2 , . . . , x P be distinct real numbers in the range\n[a, b]. Let p A (x) = m\u22121 i=0 A i q i (x) and p B (x) = m\u22121 i=0 B i q i (x)\n. For all r \u2208 [P ], the master node sends to the r-th worker evaluations of p A (x), p B (x) at x = x r , that is, it sends p A (x r ), p B (x r ) to the r-th worker.\n\nWorker nodes: For r \u2208 {1, 2, . . . , P }, the r-th worker node computes the matrix product p C (x r ) = p A (x r )p B (x r ) and sends the result to the fusion node.\n\nFusion node (decoding): The fusion node performs the following steps: (i) waits till receiving the results of any 2m\u22121 worker nodes, (ii) interpolates the polynomial p C (x) = p A (x)p B (x), (iii) evaluates p C (x) at t 1 , \u00b7 \u00b7 \u00b7 , t m , where t 1 , \u00b7 \u00b7 \u00b7 , t m are the roots of q m , (iv) performs the summation m r=1 a r p C (t r ), where a 1 , \u00b7 \u00b7 \u00b7 , a m are as in (3). Note that Construction 1 differs from previous constructions [2], [18] in that the polynomials p A (x), p B (x) are expanded in the orthonormal polynomials basis in our constructions, whereas in the monomial basis in the latter construction. The following result shows that we achieve the same recovery threshold despite this difference.\n\nTheorem 3.1: For the matrix multiplication problem described in Section III-A, a recovery threshold of 2m \u2212 1 is achieved by Construction 1.\n\nWe begin with the following claim. Claim 3.2: AB = m r=1 a r p C (t r ).\n\nThe proof of this Claim is in the extended version [8]. Now, we can prove Theorem 3.1.\n\nProof of Theorem 3.1: In order to prove the theorem, it suffices to show that Construction 1 is a valid construction with a recovery threshold of 2m \u2212 1. Therefore, in the following, we prove that Construction 1 can recover AB after the fusion node receives the output of 2m \u2212 1 worker nodes. Assume that the fusion node has already received the results of any 2m \u2212 1 worker nodes. Now, because the polynomial p C (x) has degree 2m \u2212 2, the evaluations of p C (x) at any 2m \u2212 1 distinct points is sufficient to interpolate the polynomial, and since x 1 , \u00b7 \u00b7 \u00b7 , x P are distinct, the fusion node can interpolate p C (x) once it receives the output of any 2m\u22121 worker nodes. Afterwards, given that AB = m r=1 a r p C (t r ) (Claim 3.2), the fusion node can evaluate p C (t 1 ), \u00b7 \u00b7 \u00b7 , p C (t m ) and perform the scaled summation m r=1 a r p C (t r ) to recover AB. Remark 3.1: In Construction 1, setting x 1 , \u00b7 \u00b7 \u00b7 , x m to be the roots of q m leads to a faster decoding for the scenarios in which the first m worker nodes send their results but only less than 2m \u2212 1 workers succeed to send their outputs. For such scenarios, we already have m r=1 a r p C (x r ) = m r=1 a r p C (t r ) = AB, where the last equality follows from Claim 3.2.\n\n\nIV. CHEBYSHEV POLYNOMIALS BASED CODES\n\nIn this section, we apply Construction 1 for the specific case where the orthonormal polynomials are based on the Chebyshev polynomials {T i } i\u22650 , and show via numerical experiments that these codes provide a higher stability compared to MatDot codes in [2].\n\n\nA. Chebyshev Polynomials based Codes:\n\nRecalling from Example 2.1 that 1 \u221a 2 T 0 , T 1 , T 2 , \u00b7 \u00b7 \u00b7 form an orthonormal polynomial set relative to w = 2 \u03c0 \u221a 1\u2212x 2 , we explain the application of Chebyshev polynomials of the first kind to Construction 1 in the following construction.    For all r \u2208 [P ], the master node sends to the r-th worker\n(x) = 1 \u221a 2 A 0 T 0 + m\u22121 i=1 A i T i (x) and p B (x) = 1 \u221a 2 B 0 T 0 + m\u22121 i=1 B i T i (x).p A (x r ), p B (x r ).\nWorker nodes: Same as Construction 1.\n\nWhile the proof of Theorem 3.1 leads to a decoding procedure, the decoding procedure outlined in its proof (as presented) is numerically unstable since it involves evaluation of polynomial p C (x) via interpolation. A small but important tweak to this decoding procedure is described here.\n\nFusion node (decoding): The fusion node performs the following steps: (i) waits till receiving the output of any 2m\u22121 worker nodes,\n(ii) let p C (x) = 2m\u22122 i=0 C i T i (x)\n, the fusion node inverts the appropriate sub-matrix of G (2m\u22121,P ) (x) (defined in (5)) to obtain {C 0 , \u00b7 \u00b7 \u00b7 , C 2m\u22122 }, i.e., obtain p C (x), (iii) evaluates p C (x) at the Chebyshev points \u03c1 Note that the matrix G (s,t) for integers s, t, s \u2264 t in the above decoding procedure is the s\u00d7t Chebyshev-Vandermonde matrix [14] defined as:\nG (s,t) (x) = \uf8eb \uf8ec \uf8ed T 0 (x 1 ) \u00b7 \u00b7 \u00b7 T 0 (x t ) . . . . . . . . . T s\u22121 (x 1 ) \u00b7 \u00b7 \u00b7 T s\u22121 (x t ) \uf8f6 \uf8f7 \uf8f8 .(5)\n\nB. Evaluation points and Condition number Bound\n\nWhen there is no redundancy, i.e., n = 2m \u2212 1, it is well known that the n \u00d7 n decoding matrix G (n,n) has condition number n with the 2 as well as the Frobenius norms [21]. Note the remarkable contrast with the Vandermonde matrix, whose condition number real-valued evaluation points grows exponentially in n, no matter how the nodes are chosen [13], [21]. Our problem differs from the standard problem in numerical methods, since we have to choose a rectangular \"generator\" matrix where every square sub-matrix is well conditioned. In particular, that even for Chebyshev-Vandermonde matrix, if the evaluation points are not chosen carefully, they are poorly conditioned [14] (also see Fig. 3). Here, we show that choosing x i = \u03c1 (n) i leads to a well-conditioned system with s redundant nodes. For a k\u00d7n matrix H where k \u2264 n, we define the worst-case condition number -denoted by \u03ba max (H) -as the highest condition number among all the k \u00d7 k square sub-matrices of H. Our goal is to choose vector x such that \u03ba max (G (n\u2212s,n) (x)) is sufficiently small. where \u03ba max F denotes the worst-case condition number over all possible n \u2212 s \u00d7 n \u2212 s sub-matrices of G (n\u2212s,n) (x) with respect to the Frobenius norm, \u03c1 (n) = (\u03c1\n(n) 1 , \u03c1 (n) 2 , . . . , \u03c1 (n) n ), \u03c1 (n) i = cos 2i\u22121 2n \u03c0 , i \u2208 [n]. C. Numerical Results:\nThe numerical stability of our codes is determined by the condition number of the 2m \u2212 1 \u00d7 2m \u2212 1 sub-matrices of G (2m\u22121,P ) . The natural comparison is with MatDot codes where the decoding depends on effectively inverting 2m \u2212 1 \u00d7 2m \u2212 1 sub-matrices of\nG M = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ed 1 \u00b7 \u00b7 \u00b7 1 x 1 \u00b7 \u00b7 \u00b7 x P . . . . . . . . . x 2m\u22122 1 \u00b7 \u00b7 \u00b7 x 2m\u22122 P \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f8 .(6)\nBased on the result of Theorem 4.1, we choose the x i = \u03c1 (2m\u22121) i . In our experiments, we compare the average 2 condition number of all 2m \u2212 1 \u00d7 2m \u2212 1 sub-matrices of G (2m\u22121,P ) and all 2m\u22121\u00d72m\u22121 sub-matrices of G M . The results, in Fig. 2, show that, for every examined system, the maximum (average) condition numbers of the 2m\u22121\u00d72m\u22121 sub-matrices of G (2m\u22121,P ) are less than its MatDot codes counterparts, especially for larger systems with \u2265 60 worker nodes, where the improvement is around a factor of 10 15 . Fig.  3 shows how the maximum (average) condition number of the 2m\u22121\u00d72m\u22121 sub-matrices of G (2m\u22121,P ) grows with the size of the distributed system given a fixed number of redundant worker nodes, namely 1 and 3, and compares with MatDot codes. The figure shows that while MatDot codes provide a reasonable condition number (\u223c 10 10 ) to distributed systems with size up to only 25 worker nodes, Construction 2 can afford distributed systems with size up to 150 worker nodes for the same condition number bound \u223c 10 10 . As a reflection to the significant higher stability of Construction 2 compared to MatDot codes, Fig. 4 shows that Construction 2 provides much more accurate outputs compared to MatDot codes. For the experiments whose results are shown in Fig. 4, the entries of the input matrices A, B are chosen independently according to the standard Gaussian distribution N (0, 1). In addition, for any two input matrices A, B, let\u0108 be the output of the distributed system (which is not necessarily equal to the correct answer AB), we define the relative error between AB and\u0108 to be E r (AB,\u0108) = ||AB \u2212\u0108|| F /||AB|| F . Fig. 4 shows how the maximum relative error (the worst case relative error given a fixed number of parity workers s among all the P \u2212 s successful nodes scenarios) grows with the size of the distributed system. We plot the average result of five different realizations of the system at each system size P . The figure shows that MatDot codes crushes after the size of the system exceeds 50 workers, providing a relative error of \u223c 10 5 . On the other hand, Construction 2 can support systems with sizes up to 150 worker nodes only allowing for a relative error < 10 \u22125 .\n\nV. DISCUSSION Although MatDot codes [2] have a low recovery threshold of 2m \u2212 1, their worker to fusion nodes communication cost and computation cost per worker are high compared to polynomial codes [1]. However, polynomial codes have higher recovery threshold (m 2 ) than MatDot codes. Different codes have been proposed in [3], [18] offering a trade-off between the communication/computation cost and the recovery threshold. However, all of these codes are based on the \"ill-conditioned\" monomial basis. In the extended version [8], we offer a numerically stable code construction based on Chebyshev polynomials that offers a comm./computation costs vs recovery threshold trade-off. It is worth noting that our results are also useful for the coded matrix-vector multiplication problem and providing numerically stable lagrange coded computing techniques, we discuss this in details in [8]. The design of numerically stable codes for other applications in large scale machine learning such as distributed gradient methods and linear solvers is a potentially interesting future direction.\n\nFig. 1 .\n1The distributed system framework unless otherwise is stated, whenever Chebyshev polynomials are used, they are restricted only to the range [\u22121, 1].\n\nFig. 2 .\n2Comparison between the condition number of the interpolating matrix of the Chebyshev based codes and MatDot codes in two different distributed systems with 30, and 100 worker nodes, respectively.\n\nConstruction 2 (\n2Cheb. Polynomials based Code): Splitting of input matrices: Same as Construction 1. Master node (encoding): Let x 1 , x 2 , . . . , x P be distinct real numbers in the range [\u22121, 1]. Let p A\n\nFig. 3 .\n3The growth of the condition number, for both Construction 2 and MatDot codes, with the system size given a fixed number of redundant worker nodes.\n\n\nwhere a 1 , \u00b7 \u00b7 \u00b7 , a m are as in(3), where a i = \u03c0 2 , \u2200i \u2208 [m] based on 3) in Remark 2.1.\n\nTheorem 4 . 1 :\n41For any s \u2208 [n \u2212 1], \u03ba max F (G (n\u2212s,n) (\u03c1 (n) )) = O (n \u2212 s) ns(n \u2212 s) 2n 2 s\u22121 ,\n\nFig. 4 .\n4The growth of the relative error, for both Construction 2 and MatDot codes, both using Chebyshev points, with the system size given a fixed number of redundant worker nodes.\n\nPolynomial Codes: an Optimal Design for High-Dimensional Coded Matrix Multiplication. Q Yu, M A Maddah-Ali, A S Avestimehr, Advances In Neural Information Processing Systems (NIPS. Q. Yu, M. A. Maddah-Ali, and A. S. Avestimehr, \"Polynomial Codes: an Optimal Design for High-Dimensional Coded Matrix Multiplication,\" in Advances In Neural Information Processing Systems (NIPS), 2017, pp. 4403-4413.\n\nOn the optimal recovery threshold of coded matrix multiplication. M Fahim, H Jeong, F Haddadpour, S Dutta, V Cadambe, P Grover, Communication, Control, and Computing (Allerton). M. Fahim, H. Jeong, F. Haddadpour, S. Dutta, V. Cadambe, and P. Grover, \"On the optimal recovery threshold of coded matrix multiplication,\" in Communication, Control, and Comput- ing (Allerton), Oct 2017, pp. 1264-1270, extended version at http://arxiv.org/abs/1801.10292.\n\nA unified coded deep neural network training strategy based on generalized polydot codes. S Dutta, Z Bai, H Jeong, T M Low, P Grover, 2018 IEEE International Symposium on Information Theory (ISIT). 10751S. Dutta, Z. Bai, H. Jeong, T. M. Low, and P. Grover, \"A unified coded deep neural network training strategy based on generalized polydot codes,\" in 2018 IEEE International Symposium on Information Theory (ISIT), June 2018, pp. 1585-1589, http://arxiv.org/abs/1811.10 751.\n\nGradient Coding: Avoiding Stragglers in Distributed Learning. R Tandon, Q Lei, A G Dimakis, N Karampatziakis, International Conference on Machine Learning (ICML. R. Tandon, Q. Lei, A. G. Dimakis, and N. Karampatziakis, \"Gradient Coding: Avoiding Stragglers in Distributed Learning,\" in International Conference on Machine Learning (ICML), 2017, pp. 3368-3376.\n\nCommunication-computation efficient gradient coding. M Ye, E Abbe, Proceedings of the 35th International Conference on Machine Learning. the 35th International Conference on Machine LearningStockholmsm\u00e4ssan, Stockholm, SwedenM. Ye and E. Abbe, \"Communication-computation efficient gradient coding,\" in Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, Stockholm, Sweden, July 10-15, 2018, 2018, pp. 5606-5615. [Online]. Available: http://proceedings.mlr.press/v80/ye18a.html\n\nStraggler-resilient and communication-efficient distributed iterative linear solver. F Haddadpour, Y Yang, M Chaudhari, V R Cadambe, P Grover, abs/1806.06140CoRR. F. Haddadpour, Y. Yang, M. Chaudhari, V. R. Cadambe, and P. Grover, \"Straggler-resilient and communication-efficient distributed iterative linear solver,\" CoRR, vol. abs/1806.06140, 2018. [Online]. Available: http://arxiv.org/abs/1806.06140\n\nPolynomially coded regression: Optimal straggler mitigation via data encoding. S Li, S M M Kalan, Q Yu, M Soltanolkotabi, A S Avestimehr, arXiv:1805.09934preprintS. Li, S. M. M. Kalan, Q. Yu, M. Soltanolkotabi, and A. S. Avestimehr, \"Polynomially coded regression: Optimal straggler mitigation via data encoding,\" preprint arXiv:1805.09934, 2018.\n\nNumerically stable polynomially coded computing. M Fahim, V R Cadambe, abs/1903.08326CoRR. M. Fahim and V. R. Cadambe, \"Numerically stable polynomially coded computing,\" CoRR, vol. abs/1903.08326, 2019. [Online]. Available: http://arxiv.org/abs/1903.08326\n\nAlgorithm-Based Fault Tolerance for Matrix Operations. K H Huang, J Abraham, IEEE Transactions on Computers. 1006K. H. Huang and J. Abraham, \"Algorithm-Based Fault Tolerance for Matrix Operations,\" IEEE Transactions on Computers, vol. 100, no. 6, pp. 518-528, 1984.\n\nHigh-dimensional coded matrix multiplication. K Lee, C Suh, K Ramchandran, IEEE International Symposium on Information Theory. K. Lee, C. Suh, and K. Ramchandran, \"High-dimensional coded ma- trix multiplication,\" in IEEE International Symposium on Information Theory (ISIT), 2017, pp. 2418-2422.\n\nCrossiteration coded computing. F Haddadpour, Y Yang, V R Cadambe, P Grover, Communication, Control, and Computing (Allerton). F. Haddadpour, Y. Yang, V. R. Cadambe, and P. Grover., \"Cross- iteration coded computing,\" in Communication, Control, and Computing (Allerton), 2018.\n\nLagrange coded computing: Optimal design for resiliency, security and privacy. Q Yu, N Raviv, J So, A S Avestimehr, arXiv:1806.00939arXiv preprintQ. Yu, N. Raviv, J. So, and A. S. Avestimehr, \"Lagrange coded computing: Optimal design for resiliency, security and privacy,\" arXiv preprint arXiv:1806.00939, 2018.\n\nLower bounds for the condition number of vandermonde matrices. W Gautschi, G Inglese, Numerische Mathematik. 523W. Gautschi and G. Inglese, \"Lower bounds for the condition number of vandermonde matrices,\" Numerische Mathematik, vol. 52, no. 3, pp. 241-250, 1987.\n\nChebyshev-vandermonde systems. L Reichel, G Opfer, Math. of Computation. 57196L. Reichel and G. Opfer, \"Chebyshev-vandermonde systems,\" Math. of Computation, vol. 57, no. 196, pp. 703-721, 1991.\n\nAn Application of Storage-Optimal MatDot Codes for Coded Matrix Multiplication: Fast k-Nearest Neighbors Estimation. U Sheth, S Dutta, M Chaudhari, H Jeong, Y Yang, J Kohonen, T Roos, P Grover, IEEE Big Data. Short Paper)U. Sheth, S. Dutta, M. Chaudhari, H. Jeong, Y. Yang, J. Kohonen, T. Roos, and P. Grover, \"An Application of Storage-Optimal MatDot Codes for Coded Matrix Multiplication: Fast k-Nearest Neighbors Esti- mation,\" in IEEE Big Data (Short Paper), 2018.\n\nNumerical mathematics. A Quarteroni, R Sacco, F Saleri, Springer Science & Business Media37A. Quarteroni, R. Sacco, and F. Saleri, Numerical mathematics. Springer Science & Business Media, 2010, vol. 37.\n\nNumerically erasure-robust frames. M Fickus, D G Mixon, Linear Algebra and its Applications. 4376M. Fickus and D. G. Mixon, \"Numerically erasure-robust frames,\" Linear Algebra and its Applications, vol. 437, no. 6, pp. 1394-1407, 2012.\n\nStraggler mitigation in distributed matrix multiplication: Fundamental limits and optimal coding. Q Yu, M A Maddah-Ali, A S Avestimehr, 2018 IEEE International Symposium on Information Theory (ISIT). Q. Yu, M. A. Maddah-Ali, and A. S. Avestimehr, \"Straggler mitigation in distributed matrix multiplication: Fundamental limits and optimal coding,\" in 2018 IEEE International Symposium on Information Theory (ISIT), June 2018, pp. 2022-2026. http://arxiv.org/abs/1801.07 487.\n\n. L N Trefethen, D Bau, Numerical Linear Algebra. SIAM. L. N. Trefethen and D. Bau, Numerical Linear Algebra. SIAM, 1997.\n\nApproximation theory -a short course. N L Carothers, N. L. Carothers, \"Approximation theory -a short course,\" 1998.\n\nHow (un) stable are vandermonde systems. W Gautschi, Asymptotic and computational analysis. 124W. Gautschi, \"How (un) stable are vandermonde systems,\" Asymptotic and computational analysis, vol. 124, pp. 193-210, 1990.\n", "annotations": {"author": "[{\"end\":149,\"start\":51},{\"end\":257,\"start\":150}]", "publisher": null, "author_last_name": "[{\"end\":65,\"start\":60},{\"end\":166,\"start\":159}]", "author_first_name": "[{\"end\":59,\"start\":51},{\"end\":156,\"start\":150},{\"end\":158,\"start\":157}]", "author_affiliation": "[{\"end\":148,\"start\":81},{\"end\":256,\"start\":189}]", "title": "[{\"end\":48,\"start\":1},{\"end\":305,\"start\":258}]", "venue": null, "abstract": "[{\"end\":984,\"start\":307}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1630,\"start\":1627},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1635,\"start\":1632},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1657,\"start\":1654},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":1662,\"start\":1659},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1682,\"start\":1679},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1687,\"start\":1684},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1715,\"start\":1712},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2671,\"start\":2668},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2734,\"start\":2730},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2749,\"start\":2746},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3207,\"start\":3204},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3213,\"start\":3209},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3322,\"start\":3319},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3368,\"start\":3365},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3514,\"start\":3511},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3590,\"start\":3587},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3596,\"start\":3592},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3671,\"start\":3667},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4287,\"start\":4283},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4293,\"start\":4289},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4358,\"start\":4355},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4364,\"start\":4360},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4521,\"start\":4517},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4674,\"start\":4670},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5084,\"start\":5081},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5090,\"start\":5086},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5706,\"start\":5702},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6318,\"start\":6315},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6858,\"start\":6854},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6864,\"start\":6860},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8522,\"start\":8518},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8882,\"start\":8878},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8919,\"start\":8915},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10666,\"start\":10664},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12255,\"start\":12252},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12321,\"start\":12318},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":12327,\"start\":12323},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12866,\"start\":12863},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14443,\"start\":14440},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15738,\"start\":15734},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16082,\"start\":16078},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16260,\"start\":16256},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16266,\"start\":16262},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16586,\"start\":16582},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":19835,\"start\":19832},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":19998,\"start\":19995},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20124,\"start\":20121},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20130,\"start\":20126},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20329,\"start\":20326},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20687,\"start\":20684}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":21045,\"start\":20886},{\"attributes\":{\"id\":\"fig_1\"},\"end\":21252,\"start\":21046},{\"attributes\":{\"id\":\"fig_2\"},\"end\":21462,\"start\":21253},{\"attributes\":{\"id\":\"fig_4\"},\"end\":21620,\"start\":21463},{\"attributes\":{\"id\":\"fig_5\"},\"end\":21714,\"start\":21621},{\"attributes\":{\"id\":\"fig_6\"},\"end\":21816,\"start\":21715},{\"attributes\":{\"id\":\"fig_7\"},\"end\":22001,\"start\":21817}]", "paragraph": "[{\"end\":1921,\"start\":1003},{\"end\":3115,\"start\":1923},{\"end\":3853,\"start\":3117},{\"end\":4727,\"start\":3855},{\"end\":6715,\"start\":4729},{\"end\":6996,\"start\":6763},{\"end\":7123,\"start\":7043},{\"end\":7312,\"start\":7202},{\"end\":7643,\"start\":7408},{\"end\":7837,\"start\":7746},{\"end\":8311,\"start\":7839},{\"end\":8883,\"start\":8380},{\"end\":9172,\"start\":8885},{\"end\":9257,\"start\":9211},{\"end\":9504,\"start\":9259},{\"end\":9736,\"start\":9561},{\"end\":9793,\"start\":9777},{\"end\":9930,\"start\":9816},{\"end\":10672,\"start\":10015},{\"end\":10866,\"start\":10674},{\"end\":11036,\"start\":10921},{\"end\":11309,\"start\":11094},{\"end\":11470,\"start\":11381},{\"end\":11713,\"start\":11547},{\"end\":11880,\"start\":11715},{\"end\":12594,\"start\":11882},{\"end\":12736,\"start\":12596},{\"end\":12810,\"start\":12738},{\"end\":12898,\"start\":12812},{\"end\":14142,\"start\":12900},{\"end\":14444,\"start\":14184},{\"end\":14793,\"start\":14486},{\"end\":14947,\"start\":14910},{\"end\":15238,\"start\":14949},{\"end\":15371,\"start\":15240},{\"end\":15750,\"start\":15412},{\"end\":17130,\"start\":15910},{\"end\":17480,\"start\":17225},{\"end\":19794,\"start\":17578},{\"end\":20885,\"start\":19796}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7201,\"start\":7124},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7407,\"start\":7313},{\"attributes\":{\"id\":\"formula_2\"},\"end\":7745,\"start\":7644},{\"attributes\":{\"id\":\"formula_3\"},\"end\":8379,\"start\":8312},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9210,\"start\":9173},{\"attributes\":{\"id\":\"formula_5\"},\"end\":9560,\"start\":9505},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9776,\"start\":9737},{\"attributes\":{\"id\":\"formula_7\"},\"end\":9815,\"start\":9794},{\"attributes\":{\"id\":\"formula_8\"},\"end\":11380,\"start\":11310},{\"attributes\":{\"id\":\"formula_9\"},\"end\":11546,\"start\":11471},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14886,\"start\":14794},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14909,\"start\":14886},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15411,\"start\":15372},{\"attributes\":{\"id\":\"formula_13\"},\"end\":15859,\"start\":15751},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17224,\"start\":17131},{\"attributes\":{\"id\":\"formula_15\"},\"end\":17577,\"start\":17481}]", "table_ref": null, "section_header": "[{\"end\":1001,\"start\":986},{\"end\":6761,\"start\":6718},{\"end\":7041,\"start\":6999},{\"end\":10013,\"start\":9933},{\"end\":10919,\"start\":10869},{\"end\":11092,\"start\":11039},{\"end\":14182,\"start\":14145},{\"end\":14484,\"start\":14447},{\"end\":15908,\"start\":15861},{\"end\":20895,\"start\":20887},{\"end\":21055,\"start\":21047},{\"end\":21270,\"start\":21254},{\"end\":21472,\"start\":21464},{\"end\":21731,\"start\":21716},{\"end\":21826,\"start\":21818}]", "table": null, "figure_caption": "[{\"end\":21045,\"start\":20897},{\"end\":21252,\"start\":21057},{\"end\":21462,\"start\":21272},{\"end\":21620,\"start\":21474},{\"end\":21714,\"start\":21623},{\"end\":21816,\"start\":21734},{\"end\":22001,\"start\":21828}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10071,\"start\":10065},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":16603,\"start\":16597},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17822,\"start\":17816},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18105,\"start\":18098},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":18720,\"start\":18714},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":18862,\"start\":18856},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":19230,\"start\":19224}]", "bib_author_first_name": "[{\"end\":22090,\"start\":22089},{\"end\":22096,\"start\":22095},{\"end\":22098,\"start\":22097},{\"end\":22112,\"start\":22111},{\"end\":22114,\"start\":22113},{\"end\":22469,\"start\":22468},{\"end\":22478,\"start\":22477},{\"end\":22487,\"start\":22486},{\"end\":22501,\"start\":22500},{\"end\":22510,\"start\":22509},{\"end\":22521,\"start\":22520},{\"end\":22945,\"start\":22944},{\"end\":22954,\"start\":22953},{\"end\":22961,\"start\":22960},{\"end\":22970,\"start\":22969},{\"end\":22972,\"start\":22971},{\"end\":22979,\"start\":22978},{\"end\":23394,\"start\":23393},{\"end\":23404,\"start\":23403},{\"end\":23411,\"start\":23410},{\"end\":23413,\"start\":23412},{\"end\":23424,\"start\":23423},{\"end\":23746,\"start\":23745},{\"end\":23752,\"start\":23751},{\"end\":24303,\"start\":24302},{\"end\":24317,\"start\":24316},{\"end\":24325,\"start\":24324},{\"end\":24338,\"start\":24337},{\"end\":24340,\"start\":24339},{\"end\":24351,\"start\":24350},{\"end\":24702,\"start\":24701},{\"end\":24708,\"start\":24707},{\"end\":24712,\"start\":24709},{\"end\":24721,\"start\":24720},{\"end\":24727,\"start\":24726},{\"end\":24745,\"start\":24744},{\"end\":24747,\"start\":24746},{\"end\":25020,\"start\":25019},{\"end\":25029,\"start\":25028},{\"end\":25031,\"start\":25030},{\"end\":25283,\"start\":25282},{\"end\":25285,\"start\":25284},{\"end\":25294,\"start\":25293},{\"end\":25541,\"start\":25540},{\"end\":25548,\"start\":25547},{\"end\":25555,\"start\":25554},{\"end\":25824,\"start\":25823},{\"end\":25838,\"start\":25837},{\"end\":25846,\"start\":25845},{\"end\":25848,\"start\":25847},{\"end\":25859,\"start\":25858},{\"end\":26149,\"start\":26148},{\"end\":26155,\"start\":26154},{\"end\":26164,\"start\":26163},{\"end\":26170,\"start\":26169},{\"end\":26172,\"start\":26171},{\"end\":26446,\"start\":26445},{\"end\":26458,\"start\":26457},{\"end\":26678,\"start\":26677},{\"end\":26689,\"start\":26688},{\"end\":26960,\"start\":26959},{\"end\":26969,\"start\":26968},{\"end\":26978,\"start\":26977},{\"end\":26991,\"start\":26990},{\"end\":27000,\"start\":26999},{\"end\":27008,\"start\":27007},{\"end\":27019,\"start\":27018},{\"end\":27027,\"start\":27026},{\"end\":27336,\"start\":27335},{\"end\":27350,\"start\":27349},{\"end\":27359,\"start\":27358},{\"end\":27553,\"start\":27552},{\"end\":27563,\"start\":27562},{\"end\":27565,\"start\":27564},{\"end\":27853,\"start\":27852},{\"end\":27859,\"start\":27858},{\"end\":27861,\"start\":27860},{\"end\":27875,\"start\":27874},{\"end\":27877,\"start\":27876},{\"end\":28232,\"start\":28231},{\"end\":28234,\"start\":28233},{\"end\":28247,\"start\":28246},{\"end\":28391,\"start\":28390},{\"end\":28393,\"start\":28392},{\"end\":28511,\"start\":28510}]", "bib_author_last_name": "[{\"end\":22093,\"start\":22091},{\"end\":22109,\"start\":22099},{\"end\":22125,\"start\":22115},{\"end\":22475,\"start\":22470},{\"end\":22484,\"start\":22479},{\"end\":22498,\"start\":22488},{\"end\":22507,\"start\":22502},{\"end\":22518,\"start\":22511},{\"end\":22528,\"start\":22522},{\"end\":22951,\"start\":22946},{\"end\":22958,\"start\":22955},{\"end\":22967,\"start\":22962},{\"end\":22976,\"start\":22973},{\"end\":22986,\"start\":22980},{\"end\":23401,\"start\":23395},{\"end\":23408,\"start\":23405},{\"end\":23421,\"start\":23414},{\"end\":23439,\"start\":23425},{\"end\":23749,\"start\":23747},{\"end\":23757,\"start\":23753},{\"end\":24314,\"start\":24304},{\"end\":24322,\"start\":24318},{\"end\":24335,\"start\":24326},{\"end\":24348,\"start\":24341},{\"end\":24358,\"start\":24352},{\"end\":24705,\"start\":24703},{\"end\":24718,\"start\":24713},{\"end\":24724,\"start\":24722},{\"end\":24742,\"start\":24728},{\"end\":24758,\"start\":24748},{\"end\":25026,\"start\":25021},{\"end\":25039,\"start\":25032},{\"end\":25291,\"start\":25286},{\"end\":25302,\"start\":25295},{\"end\":25545,\"start\":25542},{\"end\":25552,\"start\":25549},{\"end\":25567,\"start\":25556},{\"end\":25835,\"start\":25825},{\"end\":25843,\"start\":25839},{\"end\":25856,\"start\":25849},{\"end\":25866,\"start\":25860},{\"end\":26152,\"start\":26150},{\"end\":26161,\"start\":26156},{\"end\":26167,\"start\":26165},{\"end\":26183,\"start\":26173},{\"end\":26455,\"start\":26447},{\"end\":26466,\"start\":26459},{\"end\":26686,\"start\":26679},{\"end\":26695,\"start\":26690},{\"end\":26966,\"start\":26961},{\"end\":26975,\"start\":26970},{\"end\":26988,\"start\":26979},{\"end\":26997,\"start\":26992},{\"end\":27005,\"start\":27001},{\"end\":27016,\"start\":27009},{\"end\":27024,\"start\":27020},{\"end\":27034,\"start\":27028},{\"end\":27347,\"start\":27337},{\"end\":27356,\"start\":27351},{\"end\":27366,\"start\":27360},{\"end\":27560,\"start\":27554},{\"end\":27571,\"start\":27566},{\"end\":27856,\"start\":27854},{\"end\":27872,\"start\":27862},{\"end\":27888,\"start\":27878},{\"end\":28244,\"start\":28235},{\"end\":28251,\"start\":28248},{\"end\":28403,\"start\":28394},{\"end\":28520,\"start\":28512}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":20729541},\"end\":22400,\"start\":22003},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":19323670},\"end\":22852,\"start\":22402},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":52020438},\"end\":23329,\"start\":22854},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":33632433},\"end\":23690,\"start\":23331},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":12945509},\"end\":24215,\"start\":23692},{\"attributes\":{\"doi\":\"abs/1806.06140\",\"id\":\"b5\",\"matched_paper_id\":49304370},\"end\":24620,\"start\":24217},{\"attributes\":{\"doi\":\"arXiv:1805.09934\",\"id\":\"b6\"},\"end\":24968,\"start\":24622},{\"attributes\":{\"doi\":\"abs/1903.08326\",\"id\":\"b7\",\"matched_paper_id\":84187068},\"end\":25225,\"start\":24970},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":705021},\"end\":25492,\"start\":25227},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6938356},\"end\":25789,\"start\":25494},{\"attributes\":{\"id\":\"b10\"},\"end\":26067,\"start\":25791},{\"attributes\":{\"doi\":\"arXiv:1806.00939\",\"id\":\"b11\"},\"end\":26380,\"start\":26069},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":122019463},\"end\":26644,\"start\":26382},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":43548175},\"end\":26840,\"start\":26646},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":54005277},\"end\":27310,\"start\":26842},{\"attributes\":{\"id\":\"b15\"},\"end\":27515,\"start\":27312},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":119611245},\"end\":27752,\"start\":27517},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":22184330},\"end\":28227,\"start\":27754},{\"attributes\":{\"id\":\"b18\"},\"end\":28350,\"start\":28229},{\"attributes\":{\"id\":\"b19\"},\"end\":28467,\"start\":28352},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":18896588},\"end\":28687,\"start\":28469}]", "bib_title": "[{\"end\":22087,\"start\":22003},{\"end\":22466,\"start\":22402},{\"end\":22942,\"start\":22854},{\"end\":23391,\"start\":23331},{\"end\":23743,\"start\":23692},{\"end\":24300,\"start\":24217},{\"end\":25017,\"start\":24970},{\"end\":25280,\"start\":25227},{\"end\":25538,\"start\":25494},{\"end\":25821,\"start\":25791},{\"end\":26443,\"start\":26382},{\"end\":26675,\"start\":26646},{\"end\":26957,\"start\":26842},{\"end\":27550,\"start\":27517},{\"end\":27850,\"start\":27754},{\"end\":28508,\"start\":28469}]", "bib_author": "[{\"end\":22095,\"start\":22089},{\"end\":22111,\"start\":22095},{\"end\":22127,\"start\":22111},{\"end\":22477,\"start\":22468},{\"end\":22486,\"start\":22477},{\"end\":22500,\"start\":22486},{\"end\":22509,\"start\":22500},{\"end\":22520,\"start\":22509},{\"end\":22530,\"start\":22520},{\"end\":22953,\"start\":22944},{\"end\":22960,\"start\":22953},{\"end\":22969,\"start\":22960},{\"end\":22978,\"start\":22969},{\"end\":22988,\"start\":22978},{\"end\":23403,\"start\":23393},{\"end\":23410,\"start\":23403},{\"end\":23423,\"start\":23410},{\"end\":23441,\"start\":23423},{\"end\":23751,\"start\":23745},{\"end\":23759,\"start\":23751},{\"end\":24316,\"start\":24302},{\"end\":24324,\"start\":24316},{\"end\":24337,\"start\":24324},{\"end\":24350,\"start\":24337},{\"end\":24360,\"start\":24350},{\"end\":24707,\"start\":24701},{\"end\":24720,\"start\":24707},{\"end\":24726,\"start\":24720},{\"end\":24744,\"start\":24726},{\"end\":24760,\"start\":24744},{\"end\":25028,\"start\":25019},{\"end\":25041,\"start\":25028},{\"end\":25293,\"start\":25282},{\"end\":25304,\"start\":25293},{\"end\":25547,\"start\":25540},{\"end\":25554,\"start\":25547},{\"end\":25569,\"start\":25554},{\"end\":25837,\"start\":25823},{\"end\":25845,\"start\":25837},{\"end\":25858,\"start\":25845},{\"end\":25868,\"start\":25858},{\"end\":26154,\"start\":26148},{\"end\":26163,\"start\":26154},{\"end\":26169,\"start\":26163},{\"end\":26185,\"start\":26169},{\"end\":26457,\"start\":26445},{\"end\":26468,\"start\":26457},{\"end\":26688,\"start\":26677},{\"end\":26697,\"start\":26688},{\"end\":26968,\"start\":26959},{\"end\":26977,\"start\":26968},{\"end\":26990,\"start\":26977},{\"end\":26999,\"start\":26990},{\"end\":27007,\"start\":26999},{\"end\":27018,\"start\":27007},{\"end\":27026,\"start\":27018},{\"end\":27036,\"start\":27026},{\"end\":27349,\"start\":27335},{\"end\":27358,\"start\":27349},{\"end\":27368,\"start\":27358},{\"end\":27562,\"start\":27552},{\"end\":27573,\"start\":27562},{\"end\":27858,\"start\":27852},{\"end\":27874,\"start\":27858},{\"end\":27890,\"start\":27874},{\"end\":28246,\"start\":28231},{\"end\":28253,\"start\":28246},{\"end\":28405,\"start\":28390},{\"end\":28522,\"start\":28510}]", "bib_venue": "[{\"end\":22182,\"start\":22127},{\"end\":22578,\"start\":22530},{\"end\":23050,\"start\":22988},{\"end\":23491,\"start\":23441},{\"end\":23827,\"start\":23759},{\"end\":24378,\"start\":24374},{\"end\":24699,\"start\":24622},{\"end\":25059,\"start\":25055},{\"end\":25334,\"start\":25304},{\"end\":25619,\"start\":25569},{\"end\":25916,\"start\":25868},{\"end\":26146,\"start\":26069},{\"end\":26489,\"start\":26468},{\"end\":26717,\"start\":26697},{\"end\":27049,\"start\":27036},{\"end\":27333,\"start\":27312},{\"end\":27608,\"start\":27573},{\"end\":27952,\"start\":27890},{\"end\":28283,\"start\":28253},{\"end\":28388,\"start\":28352},{\"end\":28559,\"start\":28522},{\"end\":23917,\"start\":23829}]"}}}, "year": 2023, "month": 12, "day": 17}