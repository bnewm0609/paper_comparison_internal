{"id": 260680386, "updated": "2023-10-04 21:40:44.78", "metadata": {"title": "APBench: A Unified Benchmark for Availability Poisoning Attacks and Defenses", "authors": "[{\"first\":\"Tianrui\",\"last\":\"Qin\",\"middle\":[]},{\"first\":\"Xitong\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Juanjuan\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Kejiang\",\"last\":\"Ye\",\"middle\":[]},{\"first\":\"Cheng-Zhong\",\"last\":\"Xu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "The efficacy of availability poisoning, a method of poisoning data by injecting imperceptible perturbations to prevent its use in model training, has been a hot subject of investigation. Previous research suggested that it was difficult to effectively counteract such poisoning attacks. However, the introduction of various defense methods has challenged this notion. Due to the rapid progress in this field, the performance of different novel methods cannot be accurately validated due to variations in experimental setups. To further evaluate the attack and defense capabilities of these poisoning methods, we have developed a benchmark -- APBench for assessing the efficacy of adversarial poisoning. APBench consists of 9 state-of-the-art availability poisoning attacks, 8 defense algorithms, and 4 conventional data augmentation techniques. We also have set up experiments with varying different poisoning ratios, and evaluated the attacks on multiple datasets and their transferability across model architectures. We further conducted a comprehensive evaluation of 2 additional attacks specifically targeting unsupervised models. Our results reveal the glaring inadequacy of existing attacks in safeguarding individual privacy. APBench is open source and available to the deep learning community: https://github.com/lafeat/apbench.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2308.03258", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2308-03258", "doi": "10.48550/arxiv.2308.03258"}}, "content": {"source": {"pdf_hash": "c0c06de39c1fd89db3bdb52b56851bfbabba0b09", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2308.03258v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "35324e8980582eedafe5762b9236454cf93cb1de", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c0c06de39c1fd89db3bdb52b56851bfbabba0b09.txt", "contents": "\nAPBENCH: A UNIFIED BENCHMARK FOR AVAILABILITY POISONING ATTACKS AND DEFENSES A PREPRINT\n\n\nTianrui Qin \nShenzhen Institutes of Advanced Technology\nChinese Academy of Sciences\nChina\n\nUniversity of Chinese Academy of Sciences\nChina\n\nXitong Gao \nShenzhen Institutes of Advanced Technology\nChinese Academy of Sciences\nChina\n\nJuanjuan Zhao \nShenzhen Institutes of Advanced Technology\nChinese Academy of Sciences\nChina\n\nKejiang Ye \nShenzhen Institutes of Advanced Technology\nChinese Academy of Sciences\nChina\n\nCheng-Zhong Xu \nUniversity of Macau\nMacauS.A.R., China\n\nAPBENCH: A UNIFIED BENCHMARK FOR AVAILABILITY POISONING ATTACKS AND DEFENSES A PREPRINT\n\nThe efficacy of availability poisoning, a method of poisoning data by injecting imperceptible perturbations to prevent its use in model training, has been a hot subject of investigation. Previous research suggested that it was difficult to effectively counteract such poisoning attacks. However, the introduction of various defense methods has challenged this notion. Due to the rapid progress in this field, the performance of different novel methods cannot be accurately validated due to variations in experimental setups. To further evaluate the attack and defense capabilities of these poisoning methods, we have developed a benchmark -APBench for assessing the efficacy of adversarial poisoning. APBench consists of 9 state-of-the-art availability poisoning attacks, 8 defense algorithms, and 4 conventional data augmentation techniques. We also have set up experiments with varying different poisoning ratios, and evaluated the attacks on multiple datasets and their transferability across model architectures. We further conducted a comprehensive evaluation of 2 additional attacks specifically targeting unsupervised models. Our results reveal the glaring inadequacy of existing attacks in safeguarding individual privacy. APBench is open source and available to the deep learning community: https://github.com/lafeat/apbench. * Equal contribution. Correspondence to Xitong Gao (xt.gao@siat.ac.cn).\n\nIntroduction\n\nRecent advancements of deep neural networks (DNNs) [14,20,34] heavily rely on the abundant availability of data resources [4,18,31]. However, the unauthorized collection of large-scale data through web scraping for model training has raised concerns regarding data security and privacy. In response to these concerns, a new paradigm of practical and effective data protection methods has emerged, known as availability poisoning attacks (APA) [7,8,9,13,13,16,30,30,33,36,39,40,41], or unlearnable example attacks. These poisoning methods inject small perturbations into images that are typically imperceptible to humans, creating \"shortcuts\" [10] in the training process that hinder the model's ability to learn the original features of the images. Recently, the field of deep learning has witnessed advancements in defense strategies [6,16,22,28] that hold the potential to challenge APAs, thereby undermining their claimed effectiveness and robustness. These defenses reveal the glaring inadequacy of existing APAs in safeguarding individual privacy in images. Consequently, we anticipate an impending arms race between attack and defense strategies in the near future.\n\nHowever, evaluating the performance of these new methods across diverse model architectures and datasets poses a significant challenge due to variations in experimental settings of recent literatures. In addition, researchers face the daunting task of staying abreast of the latest methods and assessing the effectiveness of various competing attack-defense combinations. This could greatly hamper the development and empirical exploration of novel attack and defense strategies.\n\nTo tackle this challenge, we propose the APBench, a benchmark specifically designed for availability poisoning attacks and defenses. It involves implementing poisoning attack and defense mechanisms under standardized perturbations and training hyperparameters, in order to ensure fair and reproducible comparative evaluations. APBench comprises a range of availability poisoning attacks and defense algorithms, and commonly-used data augmentation policies. This comprehensive suite allows us to evaluate the effectiveness of the poisoning attacks thoroughly.\n\nOur contributions can be summarized as follows:\n\n\u2022 An open source benchmark for state-of-the-art availability poisoning attacks and defenses, including 9 supervised and 2 unsupervised poisoning attack methods, 8 defense strategies and 4 common data augmentation methods. \u2022 We conduct a comprehensive evaluation of competitions between pairs of poisoning attacks and defenses. \u2022 We conducted experiments across 4 publicly available datasets, and also extensively examined scenarios of partial poisoning, increased perturbations, the transferability of attacks to 4 different DNN models under various defenses, and unsupervised learning. We provide visual evaluation tools such as t-SNE, Shapley value map and Grad-CAM to qualitatively analyze the impact of poisoning attacks.\n\nThe aim of APBench is to serve as a catalyst for facilitating and promoting future advancements in both availability poisoning attack and defense methods. By providing a platform for evaluation and comparison, we aspire to pave the way for the development of future availability poisoning attacks that can effectively preserve utility and protect privacy.\n\n2 Related Work\n\n\nAvailability Poisoning Attacks\n\nAvailability poisoning attacks belong to a category of data poisoning attacks [11] that adds a small perturbation to images, that is often imperceptible to humans. The purpose of these perturbations is to protect individual privacy from deep learning algorithms, preventing DNNs from effectively learning the features present in the images. To enforce a small perturbation budget, recent methods typically constrain their perturbations within a small \u2113 p -ball of \u03f5 radius, where typically p \u2208 {0, 2, \u221e}. DeepConfuse (DC) [7] proposes to use autoencoders to generate training-phase adversarial perturbations. Neural tangent generalization attacks (NTGA) [41] approximates the target model as a Gaussian process [17] using the generalized neural tangent kernel, and solves a bi-level optimization for perturbations. Error-minimizing attacks (EM) [16] minimizes the training error of the perturbed images relative to their original labels on the target model, creating shortcuts for the data to become \"unlearnable\" by the target model. Building upon EM, robust error-minimizing attacks (REM) [9] use adversarially trained models to generate perturbations in order to counter defense with adversarial training. Hypocritical [36] also generates error-minimizing perturbations similar to EM, but instead uses a pretrained surrogate model. Targeted adversarial poisoning (TAP) [8] uses adversarial examples as availability attacks. In contrast to the above approaches, indiscriminate poisoning (UCL) [13] and transferable unlearnable examples (TUE) [30] instead consider availability poisoning for unsupervised learning. On the other hand, \u2113 2 and \u2113 0 perturbation-based poisoning methods do not require a surrogate model. They achieve poisoning by searching for certain triggering patterns to create shortcuts in the network. Besides the above \u2113 \u221e -bounded methods, Linear-separable poisoning (LSP) [40] and Autoregressive Poisoning (AR) [33] both prescribe perturbations within an \u2113 2 perturbation budget. Specifically, LSP generates randomly initialized linearly separable color block perturbations, while AR fills the starting rows and columns of each channel with Gaussian noise and uses an autoregressive process to fill the remaining pixels, generating random noise perturbations. One Pixel Shortcut [39] (OPS), as an \u2113 0 -bounded poisoning method, perturbs only a single pixel in the training image to achieve strong poisoning in terms of usability. Figure 1 provides visual examples of these attacks.\n\n\nAvailability Poisoning Defenses\n\nCurrently, defense methods against perturbative availability poisoning can be mainly classified into two categories: preprocessing and training-phase defenses. Data preprocessing methods preprocess the training images to eliminate the poisoning perturbations prior to training. Image shortcuts squeezing (ISS) [22] consists of simple countermeasures based on image compression, including grayscale transformation, JPEG compression, or bit-depth reduction (BDR) to perform poison removal. Recently, AVATAR [6] leverages the method proposed in DiffPure [26] to employ diffusion models to disrupt deliberate perturbations while preserving semantics in the training images. On the other hand, training-phase defense algorithms apply specific modifications to the training phase to defense against availability attacks. Adversarial training has long been considered the most effective defense mechanism [9,16] against such attacks. Adversarial augmentations [28] sample multiple augmentations on one image, and train models on the maximum loss of all augmented images to prevent learning from poisoning shortcuts. For referential baselines, APBench also includes commonly used data augmentation techniques such as Gaussian blur, random crop and flip (standard training), CutOut [5], CutMix [42], and MixUp [43], and show their (limited) effect in mitigating availability poisons. \n\n\nRelated Benchmarks\n\nAvailability poisoning is closely connected to the domains of adversarial and backdoor attack and defense algorithms. Adversarial attacks primarily aim to deceive models with adversarial perturbations during inference to induce misclassifications. Currently, there are several libraries and benchmarks available for evaluating adversarial attack and defense techniques, such as Foolbox [29], AdvBox [12], and RobustBench [3].\n\nIn contrast, backdoor attacks focus on injecting backdoor triggers into the training data, causing trained models to misclassify images containing these triggers while maintaining or minimally impacting clean accuracy. Benchmark libraries specifically designed for backdoor attacks and defenses include TrojanZoo [27], Backdoorbench [38], and Backdoorbox [21].\n\nHowever, there is currently a lack and an urgent need of a dedicated and comprehensive benchmark that standardizes and evaluates availability poisoning attack and defense strategies. To the best of our knowledge, APBench is the first benchmark that fulfills this purpose. It offers an extensive library of recent attacks and defenses, explores various perspectives, including the impact of poisoning rates and model architectures, as well as attack transferability. We hope that APBench can make significant contributions to the community and foster the development of future availability attacks for effective privacy protection.\n\n\nProblem formulation\n\nAttacker In general, the objective of the attacker is to render the data unlearnable by deep learning models. They achieve this by introducing small perturbations to images, effectively hindering the trainer from utilizing the data to learn models that can generalize effectively to the original data distribution. Formally, consider a source dataset comprising original examples D clean = {(x 1 , y 1 ), . . . , (x n , y n )} where x i \u2208 X denotes an input image and y i \u2208 Y represents its label. The objective of the attacker is thus to construct a set of availability perturbations \u03b4, such that models trained on the set of availability poisoned examples D poi (\u03b4) = {(x + \u03b4 x , y) | (x, y) \u2208 D clean } are expected to perform poorly when evaluated on a test set D test sampled from the distribution S:\nmax \u03b4 E (xi,yi)\u223cDtest [L(f \u03b8 \u22c6 (\u03b4) (x i ), y i )], s.t. \u03b8 \u22c6 (\u03b4) = argmin \u03b8 E (xi,yi)\u223cDpoi(\u03b4) L(f \u03b8 (x i ), y i ),(1)\nwhere L denotes the loss function, usually the softmax cross-entropy loss. In order to limit the impact on the original utility of images, the perturbation \u03b4 i is generally constrained within a small \u03f5-ball of \u2113 p distance.\n\nDefender The objective of the defender is thus to find a novel training algorithm g(D poi ) that trains models to generalize well to the original data distribution:\nmin g E (xi,yi)\u223cDtest [L(f \u03b8 \u22c6 (x i ), y i )], s.t. \u03b8 \u22c6 = g(D poi ).(2)\nNotably, if the method employs the standard training loss but performs novel image transformations h, then g can be further specialized as follows:\ng(D poi ) = argmin \u03b8 E (xi,yi)\u223cDpoi(\u03b4) L(f \u03b8 (h(x i )), y i ).(3)\n\nA Unified Availability Poisoning Benchmark\n\nAs shown in Figure 2, APBench consists of three main components: (a) The availability poisoning attack module. This library includes a set of representative availability poisoning attacks that can generate unlearnable versions of a given clean dataset. (b) The poisoning defense module. This module integrates a suite of state-of-the-art defenses that can effectively mitigate the unlearning effect and restore clean accuracies to a certain extent. (c) The evaluation module. This module can efficiently analyze the performance of various availability poisoning attack methods using accuracy metrics and visual analysis strategies.\n\n\nInput Module\n\nClean data Clean data We built an extensible codebase as the foundation of APBench. In the attack module, we provide a total of 9 availability poisoning attacks of 3 different perturbation types (\u2113 p ) for supervised learning, and 2 attacks for unsupervised learning. For each availability poisoning attack method, we can generate their respective poisoned datasets. This module also allows us to further expand to different perturbations budgets, poisoning ratios, and easily extend to future poisoning methods. Using the poisoned datasets generated by the attack module, we can evaluate defenses through the defense module. The goal of this module is to ensure that models trained on unlearnable datasets can still generalize well on clean data. The defense module primarily achieves poisoning mitigation through data preprocessing or training-phase defenses. Finally, the evaluation module computes the accuracy metrics of different attacks and defense combinations, and can also perform qualitative visual analyses to help understand the characteristics of the datasets.\n\nOur benchmark currently includes 9 supervised and 2 unsupervised availability poisoning attacks and 8 defense algorithms, and 4 traditional image augmentation methods. In Table 1 and Table 2, we provide a brief summary of the properties of attack and defense algorithms. More detailed descriptions for each algorithm are provided in Appendix B.\n\n\nEvaluations\n\nDatasets We evaluated our benchmark on 4 commonly used datasets (CIFAR-10 [19], CIFAR-100 [19], SVHN [25], and an ImageNet [4] subset) and 5 mainstream models (ResNet-18 [14], ResNet-50 [14], MobileNetV2 [32], and DenseNet-121 [15]). To ensure a fair comparison between attack and defense methods, we used only the basic version of training for each model. Appendix A summarizes the specifications of the datasets and the test accuracies achievable through standard training on clean training data, and further describes the detail specifications of each dataset.\n\n\nAttacks and defenses\n\nWe evaluated combinations of availability poisoning attacks and defense methods introduced in Section 4. Moreover, we explored 5 different data poisoning rates and 5 different models. In addition, We also explore two availability poisonings for unsupervised learning (UCL [13] and TUE [30]) and evaluate them on the recently Table 1: Availability poisoning attack algorithms implemented in APBench. \"Type\" and \"Budget\" respectively denotes the type of perturbation and its budget. \"Mode\" denotes the training mode, where \"S\" and \"U\" and respectively mean supervised and unsupervised training. \"No surrogate\" denotes whether the attack requires access to a surrogate model for perturbation generation. \"Class-wise\" and \"Sample-wise\" indicate if the attack supports class-wise and sample-wise perturbation generation. \"Stealthy\" denotes whether the attack is stealthy to human.  Random image cropping and flipping CutOut [5] Low Random image erasing MixUp [43] Low Random image blending CutMix [42] Low Random image cutting and stitching\n\u2113\u221e 8/255 S \u2713 \u2713 NTGA [41] S \u2713 \u2713 HYPO [36] S \u2713 \u2713 EM [16] S \u2713 \u2713 \u2713 REM [9] S \u2713 \u2713 \u2713 TAP [8] S \u2713 \u2713 UCL [13] U \u2713 \u2713 \u2713 TUE [30] U \u2713 \u2713 LSP [40] \u21132 1.30 S \u2713 \u2299 \u2713 AR [33] 1.00 S \u2713 \u2299 \u2713 \u2713 OPS [39] \u21130 1 S \u2713 \u2713 \u2713\nGaussian (used in [22])\n\n\nData preprocessing\n\nLow Image blurring with a Gaussian kernel BDR (used in [22]) Low Bit-depth reduction Gray (used in [22]) Low Image grayscale transformation JPEG (used in [22]) Low Image compression AVATAR [6] High Image corruption and restoration U-Lite [28] Training-phase defense Low Stronger data augmentations U-Max [28] High Adversarial augmentations AT [24] High Adversarial training proposed defenses (Gray, JPEG, UEraser-Lite [28], and AVATAR [6]). The implementation details of all algorithms and additional results can be found in Appendix B.\n\nTraining settings We trained the CIAFR-10, CIFAR-100 and ImageNet-subset models for 200 epochs and the SVHN models for 100 epochs. We used the stochastic gradient descent (SGD) optimizer with a momentum of 0.9 and a learning rate of 0.1 by default. As for unsupervised learning, all experiments are trained for 500 epochs with the SGD optimizer. The learning rate is 0.5 for SimCLR [1] and 0.3 for MoCo-v2 [2]. Please note that we generate sample-wise perturbations for all availability poisoning attacks. Specific settings for each defense method may have slight differences, and detailed information can be found in the Appendix C.\n\n\nStandard Scenario\n\nTo start, we consider a common scenario where both the surrogate model and target model are ResNet-18, and the poisoning rate is set to 100%. We first evaluate the performance of the supervised poisoning methods against 4 state-of-the-art defense mechanisms and 4 commonly used data augmentation strategies. Table 3 presents the evaluation results on CIFAR-10 from our benchmark. It is evident that the conventional data augmentation methods appear to be ineffective against all poisoning methods. Yet, even simple image compression methods (BDR, grayscale, and JPEG corruption from ISS [22]) demonstrate a notable effect in mitigating the poisoning attacks, but fails to achieve high clean accuracy. Despite requiring more computational cost or additional resources (pretrained diffusion models for AVATAR), methods such as UEraser-Max [28] and AVATAR [6], generally surpass the image compression methods from ISS in terms of effectiveness. Adversarial training appears effective but in many cases is outperformed by even a simple JPEG compression. We further conduct experiments on the CIFAR-100, SVHN, and ImageNet-subset datasets, and the results are shown in Table 4. \n\n\nChallenging Scenarios\n\nTo further investigate the effectiveness and robustness of availability poisoning attacks and defenses, we conducted evaluations in more challenging scenarios. We considered partial poisoning scenarios, larger perturbation poisoning, and the attack transferability to different models.\n\nPartial poisoning Here, we investigate the impact of poisoning rate on the performance of availability poisoning. Figure 3 presents the results on CIFAR-10 and ResNet-18, w.r.t. each poisoning rate for attack-defense pairs, where each subplot corresponds to a specific poisoning attack method. We explore four different poisoning rates (20%, 40%, 60%, 80%). It is evident that due to the different objectives of availability poisoning compared to traditional data poisoning, partial poisoning can greatly affect the effectiveness of availability poisoning attacks. A small poisoning rate mostly nullified their effectiveness.       Larger perturbations We increased the magnitude of perturbations in availability poisoning attacks to further evaluate the performance of attacks and defenses. Table 5 presents the results of availability poisoning with larger perturbations on CIFAR-10. Due to such significant perturbations, their stealthiness is further reduced, making it challenging to carry out such attacks in realistic scenarios. However, larger perturbations indeed have a more pronounced impact on suppressing defense performance, leading to significant accuracy losses for all defense methods. There exists a trade-off between perturbation magnitude and accuracy recovery.\n\nAttack transferability across models In real-world scenarios, availability poisoning attackers can only manipulate the data and do not have access to specific details of the defender. Therefore, we conducted experiments on different model architectures. It is worth noting that all surrogate-based attack methods are considered using ResNet-18. The results are shown in Table 6. It is evident that all surrogate-based and -free poisoning methods exhibit strong transferability, while the three recently proposed defenses also achieve successful defense across different model architectures.\n\nUnsupervised learning We evaluated the availability poisoning attacks targeting unsupervised models on two benchmark datasets (CIFAR-10 and CIFAR-100). We assumed the victim model to be ResNet-18, while the attacker used ResNet-18 to generate adversarial perturbations. We considered two popular unsupervised learning frameworks: SimCLR [1] and MoCo-v2 [2]. All defense methods were applied before the data augmentation process, which means they were applied to preprocessed images before undergoing different data augmentations. Therefore, we only applied UEraser-lite as a data preprocessing method. The results of all experiments are shown in Table 7.\n\nVisual Analyses We provide visualization tools to facilitate the analysis and understanding of availability poisoning attacks. We use t-SNE [37] to visualize the availability poisons. Although t-SNE cannot accurately represent highdimensional spaces, it aids in the global visualization of feature representations, allowing us to observe specific characteristics of availability poisons. Gradient-weighted class activation mapping (Grad-CAM) [35] and Shapley value map [23] are commonly used image analysis tools that visualize the contributions of different pixels in an image to the model's predictions. Through Grad-CAM or Shapley value map, we can qualitatively compare the performance of test samples between the poisoned and clean models.  \n\n\nTAP OPS\n\nNo defense ISS UEraser-max AVATAR Figure 5: The t-SNE visualization of the models' feature representations on the clean test set. Note that without defenses, the feature representations of the poisoned models are mostly scrambled as the models struggle to learn useful features.\n\n\nDiscussion\n\nOur findings indicate that perturbations constrained by traditional \u2113 p norms are ineffective against adversarial augmentation (UEraser), and image restoration by pre-trained diffusion models (AVATAR), as they break free from the assumption of \u2113 p constraints. Even simple image compression techniques (JPEG, Grayscale, and BDR) can effectively remove the effect of perturbations. At this stage, availability poisoning attacks that rely on \u2113 p -bounded perturbations may not be as effective as initially suggested by the relevant attacks.\n\nFuture research directions should explore methods that enhance the resilience of perturbations. One approach to consider is the development of generalizable attacks, which can simultaneously target the DNNs being trained, diffusion models for image restoration, and remain robust against traditional or color distortions, among others. On the other hand, semantic-based perturbations offer an alternative strategy, as such modifications to images can be challenging to remove by defenses.\n\n\nConclusions\n\nWe have established the first comprehensive and up-to-date benchmark for the field of availability poisoning, covering a diverse range of availability poisoning attacks and state-of-the-art defense algorithms. We have conducted effective evaluations and analyses of different combinations of attacks and defenses, as well as additional challenging scenarios. Through this new benchmark, our primary objective is to provide researchers with a clearer understanding of the current progress in the field of availability poisoning attacks and defenses. We hope it can enable rapid comparisons between existing methods and new approaches, while also inspiring fresh ideas through our comprehensive evaluations and observations. We believe that our benchmark will contribute to the advancement of availability poisoning research and the development of more effective attacks to safeguard privacy. Table 8 summarizes the specifications of datasets and the respective test accuracies of typical training on ResNet-18 architectures. \n\n\nA Datasets\n\n\nB Implementation Details\n\nIn addition to the discussion of properties of the availability poisoning attacks and defenses presented in Tables 1 and 2, here, we provide a high-level description of the attack and defense algorithms implemented in APBench.\n\n\nAttacks:\n\n\u2022 Deep Confuse (DC) [7]: DC is proposed as a novel approach to manipulating classifiers by modifying the training data. Its key idea involves employing an autoencoder-like network to capture the training trajectory of the target model and adversarially perturbing the training data.\n\n\u2022 Error-minimizing attack (EM) [16]: EM trains a surrogate model by minimizing the error of images relative to their original labels, generating perturbations that minimize the errors and thus render the perturbed images unlearnable. The authors of EM introduce the threat model of availability poisoning attacks, highlighting their role as a mechanism for privacy protection.\n\n\u2022 Neural tangent generalization attack (NTGA) [41]: NTGA simulates the training dynamics of a generalized deep neural network using a Gaussian process and leverages this surrogate to find better local optima with improved transferability.\n\n\u2022 Hypocritical (HYPO) [36]: HYPO, similar to EM, generates images that minimize errors relative to their true labels using a pre-trained model.\n\n\u2022 Targeted adversarial poisoning (TAP) [8]: TAP achieves availability poisoning by generating targeted adversarial examples of non-ground-truth labels of pre-trained models.\n\n\u2022 Robust error-minimizing attacks (REM) [9]: REM improves the poisoning effect of availability poisoning by replacing the training process of the surrogate model with adversarial training.\n\n\u2022 Linear-separable poisoning (LSP) [40]: LSP generates randomly initialized linearly separable color block perturbations, enabling effective availability poisoning attacks without requiring surrogate models or excessive computational overhead.\n\n\u2022 Autoregressive Poisoning (AR) [33]: AR, similar to LSP, does not require additional surrogate models. It fills the initial rows and columns of each channel with Gaussian noise and uses an autoregressive process to fill the remaining pixels, generating random noise perturbations.\n\n\u2022 One-Pixel-Shortcut (OPS) [39]: OPS is a targeted availability poisoning attack that perturbs only one pixel of an image, generating an effective availability poisoning attack against traditional adversarial training methods.\n\n\u2022 Indiscriminate poisoning (UCL) [13]: UCL considers generating unlearnable examples for unsupervised learning by minimizing the CL loss (e.g., the InfoNCE loss) in the unsupervised learning setting.\n\n\u2022 Transferable unlearnable examples (TUE) [30]: TUE discovers that UCL is effective only in unsupervised learning, while its performance significantly deteriorates in supervised learning. Therefore, TUE is proposed that simultaneously targets both supervised and unsupervised learning. Different to UCL, it additionally embeds linear separable poisons into unsupervised unlearnable examples using the class-wise separability discriminant.\n\nDefenses:\n\n\u2022 Adversarial training (AT) [24]: AT is a widely-recognized effective approach against availability poisoning. Small adversarial perturbations are applied to the training images during training, in order to improve the robustness of the model against perturbations.\n\n\u2022 Image Shortcut Squeezing (ISS) [22]: ISS uses traditional image compression techniques such as grayscale transformation, bit-depth reduction (BDR), and JPEG compression, as defenses against availability poisoning.\n\n\u2022 Adversarial augmentations (UEraser) [28]: UEraser-Lite uses an effective augmentation pipeline to suppress availability poisoning shortcuts. UEraser-Max further improves the defense against availability poisoning through adversarial augmentations.\n\n\u2022 AVATAR [6]: Following DiffPure [26], AVATAR cleans the images of the unlearnable perturbations with diffusion models. Table 9 presents the default hyperparameters for all availability poisoning attacks implemented in APBench. D Additional Results Figure 6 shows the train and test accuracy curves during training with various defenses under different attacks for CIFAR-10. Figure 7 shows the t-SNE visualization of the models' feature representations on the clean test set for CIFAR-10.  \n\n\nC Experimental Settings\n\n\nE Limitations\n\nAPBench has mainly focused on providing algorithms and evaluations related to image data. However, such availability poisoning methods may also be applicable to text, speech, or video domains. In the future, we plan to expand APBench to include more domains, aiming to establish a more comprehensive and valuable benchmark for personal privacy protection against deep learning.  \n\n\nF Ethics Statement\n\nSimilar to many other technologies, the implementation of availability poisoning algorithms can be used by users for both beneficial and malicious purposes. We understand that these poisoning attack methods were originally proposed to protect privacy, but they can also be used to generate maliciously data to introduce model backdoors. The benchmark aims to promote an understanding of various availability poisoning attacks and defense methods, as well as encourage the development of new algorithms in this field. However, we emphasize that the use of these algorithms and evaluation results should comply with ethical guidelines and legal regulations. We encourage users to be aware of the potential risks of the technology and take appropriate measures to ensure its beneficial use for both society and individuals.\n\nFigure 1 :\n1Visualizations of unlearnable CIFAR-10 images with corresponding perturbations. Perturbations are normalized for visualization.\n\nFigure 2 :\n2The overall system design of APBench.\n\nFigure 3 :\n3The efficacy of defenses (No defense, Grayscale, JPEG, and UEraser-Max) against different partial poisoning attacks including EM (a), REM (b), LSP (c), and AR (d) with poisoning ratios ranging from 20% to 80%.\n\nFigure 4 :\n4Grad-CAM and Shapley value map visualizations of regions contributed to model decision under different attack methods and defense methods with ResNet-18. (Left) The Grad-CAM visualizations of EM and LSP poisoning attacks. (Right) The Shapley value map visualizations of REM and AR poisoning attacks.\n\nFigure 6 :\n6Train and test accuracy curves during trainig for different defenses (standard training, ISS, UEraser-Max, and AVATAR) under different attacks (EM, REM, LSP, and AR) for CIFAR-10.\n\n\nAttack Method Type Budget Mode No surrogate Class-wise Sample-wise StealthyDC [7] \n\n\n\nTable 2 :\n2Availability poisoning defense algorithms implemented in APBench.Defense Method \nType \nTime Cost Description \n\nStandard \n\nData augmentations \n\nLow \n\n\nTable 3 :\n3Test accuracies (%) of models trained on poisoned CIFAR-10 datasets.Method Standard CutOut CutMix MixUp Gaussian BDR Gray JPEG U-Max AVATAR \nAT \n\nDC \n15.19 \n19.94 \n17.91 \n25.07 \n16.10 \n67.73 85.55 83.57 \n92.17 \n82.10 \n76.85 \nEM \n20.78 \n18.79 \n22.28 \n31.14 \n14.71 \n37.94 92.03 80.72 \n93.61 \n75.62 \n82.51 \nREM \n17.47 \n21.96 \n26.22 \n43.07 \n21.80 \n58.60 92.27 85.44 \n92.43 \n82.42 \n77.46 \nHYPO \n70.38 \n69.04 \n67.12 \n74.25 \n62.17 \n74.82 63.35 85.21 \n88.44 \n85.94 \n81.49 \nNTGA \n22.76 \n13.78 \n12.91 \n20.59 \n19.95 \n59.32 70.41 68.72 \n86.78 \n86.22 \n69.70 \nTAP \n6.27 \n9.88 \n14.21 \n15.46 \n7.88 \n70.75 11.01 84.08 \n79.05 \n87.75 \n79.92 \n\nLSP \n13.06 \n14.96 \n17.69 \n18.77 \n18.61 \n53.86 64.70 80.14 \n92.83 \n76.90 \n81.38 \nAR \n11.74 \n10.95 \n12.60 \n14.15 \n13.83 \n36.14 35.17 84.75 \n90.12 \n88.60 \n81.15 \n\nOPS \n14.69 \n52.98 \n64.72 \n49.27 \n13.38 \n37.32 19.88 78.48 \n77.99 \n66.16 \n14.95 \n\nTable 4: Test accuracies (%) on poisoned CIFAR-100, SVHN and ImageNet-subset datasets. \nDataset \nMethod Standard CutOut CutMix MixUp Gaussian BDR Gray JPEG U-max \n\nCIFAR-100 \n\nEM \n3.03 \n4.15 \n3.98 \n6.46 \n2.99 \n34.10 59.14 58.71 68.81 \nREM \n3.73 \n4.00 \n3.71 \n10.90 \n3.59 \n29.16 57.47 55.60 67.72 \nLSP \n2.56 \n2.33 \n4.52 \n4.86 \n1.71 \n27.12 39.45 52.82 68.31 \nAR \n1.87 \n1.63 \n3.17 \n2.35 \n2.62 \n31.15 16.13 54.73 55.95 \n\nSVHN \n\nEM \n10.33 \n13.38 \n10.77 \n12.79 \n8.82 \n36.65 65.66 86.14 90.24 \nREM \n14.02 \n18.92 \n9.55 \n19.56 \n7.54 \n42.52 19.59 90.58 88.26 \nLSP \n12.16 \n12.98 \n8.17 \n18.86 \n7.15 \n26.67 16.90 84.06 90.64 \nAR \n19.23 \n14.92 \n6.71 \n13.52 \n7.75 \n39.24 10.00 92.46 90.07 \n\nImageNet-100 \n\nEM \n2.94 \n4.05 \n4.73 \n4.15 \n3.15 \n6.45 12.20 31.73 44.07 \nREM \n3.66 \n4.13 \n4.78 \n3.94 \n4.28 \n4.03 \n3.95 40.98 42.14 \nLSP \n38.52 \n40.56 \n29.78 \n7.85 \n42.68 \n26.58 25.18 36.83 63.28 \n\n\n\nTable 5 :\n5Test accuracies (%) on poisoned CIFAR-10 datasets with increased perturbations.Method Budget \nNo defense Gray JPEG U-max \nAT \n\nEM \n\u2113\u221e = 16/255 \n18.74 \n76.76 55.96 \n88.09 \n77.82 \nREM \n\u2113\u221e = 16/255 \n19.80 \n83.65 80.07 \n80.36 \n75.64 \n\nLSP \n\u21132 = 1.74 \n15.83 \n37.60 42.83 \n87.20 \n77.92 \nAR \n\u21132 = 1.50 \n11.20 \n26.10 78.24 \n68.42 \n70.14 \n\n\n\nTable 6 :\n6Clean test accuracy of CIFAR-10 target models in the transfer setting. Note that AR and LSP are surrogate-free and the surrogate model is ResNet-18 for EM and REM.Method Model \nNo defense Gray JPEG U-max AVATAR \n\nEM \n\nResNet-50 \n14.41 \n83.40 76.88 \n85.89 \n77.64 \nSENet-18 \n13.60 \n86.03 79.35 \n83.27 \n74.22 \nMobileNetV2 \n15.62 \n77.21 70.96 \n82.71 \n75.62 \nDenseNet-121 \n13.89 \n82.49 78.42 \n82.37 \n76.69 \n\nREM \n\nResNet-50 \n16.26 \n87.26 75.79 \n92.69 \n83.68 \nSENet-18 \n20.99 \n84.50 78.92 \n93.17 \n84.37 \nMobileNetV2 \n20.83 \n80.81 72.27 \n91.03 \n82.77 \nDenseNet-121 \n21.45 \n85.47 78.42 \n93.09 \n83.04 \n\nLSP \n\nResNet-50 \n19.23 \n68.94 73.24 \n93.08 \n76.47 \nSENet-18 \n18.54 \n65.06 76.51 \n92.53 \n75.19 \nMobileNetV2 \n16.82 \n61.07 72.03 \n92.10 \n76.81 \nDenseNet-121 \n18.94 \n67.95 74.90 \n93.47 \n78.22 \n\nAR \n\nResNet-50 \n11.83 \n27.51 80.24 \n81.40 \n86.39 \nSENet-18 \n13.68 \n34.26 79.29 \n75.06 \n84.37 \nMobileNetV2 \n13.36 \n28.54 68.14 \n73.40 \n81.63 \nDenseNet-121 \n13.43 \n25.51 81.12 \n82.36 \n89.92 \n\n\n\nTable 7 :\n7Performance of availability poisoning attacks and defense on different unsupervised learning algorithms and datasets. Note that \"U-lite\" denotes UEraser-lite.Algorithm Method No Defense \nGray \nJPEG U-lite AVATAR \n\nSimCLR \nUCL \n47.25 \n46.91 66.76 68.42 \n83.22 \nTUE \n57.10 \n56.37 67.54 66.59 \n84.24 \n\nMoCo-v2 \nUCL \n53.78 \n53.34 65.44 72.13 \n83.08 \nTUE \n66.73 \n64.95 67.28 74.82 \n82.48 \n\nEM \n\nLSP \n\nREM \n\nAR \n\nClean No-defense \nISS \nU-max AVATAR \nClean No-defense \nISS \nU-max AVATAR \n\nGrad-CAM \nShapley value map \n\n\n\nTable 8 :\n8Dataset specifications and the respective test accuracies on ResNet-18.Datasets \n#Classes Training / Test Size Image Dimensions Clean Accuracy (%) \n\nCIFAR-10 [19] \n10 \n50,000 / 10,000 \n32\u00d732\u00d73 \n94.32 \nCIFAR-100 [19] \n100 \n50,000 / 10,000 \n32\u00d732\u00d73 \n75.36 \nSVHN [25] \n10 \n73,257 / 26,032 \n32\u00d732\u00d73 \n96.03 \nImageNet-subset [4] \n100 \n20,000 / 4,000 \n224\u00d7224\u00d73 \n72.44 \n\n\n\nTable 9 :\n9Default hyperparameter settings of attack methods. Adversarial training perturbation \u2113 \u221e = 4/255 LSP Perturbation \u2113 2 = 1.30 (Project from \u2113 \u221e = 6/255) Patch size 8 for CIFAR-10/100 and SVHN; 32 for ImageNetMethods Hyperparameter \nSettings \n\nDC \nPerturbation \n\u2113 \u221e = 8/255 \nPre-trained model \nOfficial pretrained \n\nNTGA \nPerturbation \n\u2113 \u221e = 8/255 \nPoisoned dataset \nOfficial pretrained CIFAR-10 CNN (best) \n\nEM \n\nPerturbation \n\u2113 \u221e = 8/255 \nPerturbation type \nSample-wise \nStopping error rate \n0.01 \nLearning rate \n0.1 \nBatch size \n128 \nOptimizer \nSGD \n\nHYPO \nPerturbation \n\u2113 \u221e = 8/255 \nStep size \n\u2113 \u221e = 0.8/255 \n\nTAP \nPerturbation \n\u2113 \u221e = 8/255 \n\nREM \n\nPerturbation \n\u2113 \u221e = 8/255 \nPerturbation type \nSample-wise \nStopping error rate \n0.01 \nLearning rate \n0.1 \nBatch size \n128 \nOptimizer \nSGD \nAR \nPerturbation \n\u2113 2 = 1.00 \nDefault hyperparameters \nFollows official code \n\nOPS \n\nPerturbation \n\u2113 0 = 1 \nPerturbation type \nSample-wise \nDefault hyperparameters \nFollows official code \n\nUCL \nPerturbation \n\u2113 \u221e = 8/255 \nPoisoned dataset \nOfficial pretrained CP-S of UCL \n\nTUE \nPerturbation \n\u2113 \u221e = 8/255 \nPoisoned dataset \nOfficial pretrained \n\n\n\nTable 10 :\n10Default training hyperparameter settings.Datasets \nHyperparameter \nSettings \n\nCIFAR-10/-100 \n\nOptimizer \nSGD \nMomentum \n0.9 \nWeight-decay \n0.0005 \nBatch size \n128 \nStandard Augmentations Random crop, random horizontal flip \nTraining epochs \n50 \nInitial learning rate \n0.1 \nLearning rate schedule \nEpochs per decay: 100, decay factor: 0.5 \n\nSVHN \n\nOptimizer \nSGD \nMomentum \n0.9 \nWeight-decay \n0.0005 \nBatch size \n128 \nStandard augmentations None \nTraining epochs \n40 \nInitial learning rate \n0.1 \nLearning rate schedule \nEpochs per decay: 100, decay factor: 0.5 \n\nImageNet-100 \n\nOptimizer \nSGD \nMomentum \n0.9 \nWeight-decay \n0.0005 \nBatch size \n256 \nStandard augmentations Random crop, horizontal flip, and color jitter \nTraining epochs \n100 \nInitial learning rate \n0.1 \nLearning rate schedule \nEpochs per decay: 100, decay factor: 0.5 \n\n\n\nTable 11 :\n11Default hyperparameter settings of defenses.Methods \nHyperparameter \nSettings \n\nAdversarial training [24] \n\nPerturbation \n\u2113 \u221e = 8/255 \nSteps size \n\u2113 \u221e = 2/255 \nPGD steps \n10 \nTraining epochs \n200 \n\nCutOut [5] / CutMix [42] / MixUp [43] Training epochs \n60 \n\nGaussian [22] \n\nKernel size \n3 \nStandard deviation \n0.1 \nTraining epochs \n100 \n\nJPEG [22] \nQuality \n10 \nTraining epochs \n200 \n\nBDR [22] \nNumber of bits \n2 \nTraining epochs \n200 \n\nUEraser-Lite [28] \n\nPlasmaBrightness / PlasmaContrast p = 0.5 \nChannelShuffle \np = 0.5 \nTraining epochs \n200 \n\nUEraser-Max [28] \n\nPlasmaBrightness / PlasmaContrast p = 0.5 \nChannelShuffle \np = 0.5 \nNumber of Repeats K \n5 \nTraining epochs \n300 \n\nAVATAR [6] \n\nDiffusion sampler \nScore-SDE \nStarting step / Total diffusion steps 60 / 1000 \nPre-trained model \nOfficial pretrained \nTraining epochs \n200 \n\n\nAcknowledgementsThis work is supported in part by Guangdong Basic and Applied Basic Research Foundation (No. 2020B1515130004), and Shenzhen Science and Technology Innovation Commission (No. JCYJ20190812160003719).\nA simple framework for contrastive learning of visual representations. Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, International conference on machine learning. PMLRTing Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In International conference on machine learning, pages 1597-1607. PMLR, 2020.\n\nXinlei Chen, Haoqi Fan, arXiv:2003.04297Ross Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. arXiv preprintXinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved baselines with momentum contrastive learning. arXiv preprint arXiv:2003.04297, 2020.\n\nFrancesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti, arXiv:2010.09670Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. arXiv preprintFrancesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. arXiv preprint arXiv:2010.09670, 2020.\n\nImageNet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. IEEEJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248-255. IEEE, 2009.\n\nTerrance Devries, W Graham, Taylor, arXiv:1708.04552Improved regularization of convolutional neural networks with cutout. arXiv preprintTerrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017.\n\nThe devil's advocate: Shattering the illusion of unexploitable data using diffusion models. Sarah Hadi M Dolatabadi, Christopher Erfani, Leckie, arXiv:2303.08500arXiv preprintHadi M Dolatabadi, Sarah Erfani, and Christopher Leckie. The devil's advocate: Shattering the illusion of unexploitable data using diffusion models. arXiv preprint arXiv:2303.08500, 2023.\n\nLearning to confuse: generating training time adversarial data with auto-encoder. Ji Feng, Qi-Zhi Cai, Zhi-Hua Zhou, Advances in Neural Information Processing Systems. 32Ji Feng, Qi-Zhi Cai, and Zhi-Hua Zhou. Learning to confuse: generating training time adversarial data with auto-encoder. Advances in Neural Information Processing Systems, 32, 2019.\n\nAdversarial examples make strong poisons. Liam Fowl, Micah Goldblum, Ping-Yeh Chiang, Jonas Geiping, Wojciech Czaja, Tom Goldstein, Advances in Neural Information Processing Systems. 34Liam Fowl, Micah Goldblum, Ping-yeh Chiang, Jonas Geiping, Wojciech Czaja, and Tom Goldstein. Adversarial examples make strong poisons. Advances in Neural Information Processing Systems, 34:30339-30351, 2021.\n\nRobust unlearnable examples: Protecting data against adversarial learning. Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao, International Conference on Learning Representations. Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, and Dacheng Tao. Robust unlearnable examples: Protecting data against adversarial learning. In International Conference on Learning Representations, 2022.\n\nShortcut learning in deep neural networks. Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix A Wichmann, Nature Machine Intelligence. 211Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2(11):665-673, 2020.\n\nDataset security for machine learning: Data poisoning, backdoor attacks, and defenses. Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander M\u0105dry, Bo Li, Tom Goldstein, IEEE Transactions on Pattern Analysis and Machine Intelligence. 452Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander M\u0105dry, Bo Li, and Tom Goldstein. Dataset security for machine learning: Data poisoning, backdoor attacks, and defenses. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(2):1563-1580, 2022.\n\nAdvbox: a toolbox to generate adversarial examples that fool neural networks. Dou Goodman, Hao Xin, Wang Yang, Wu Yuesheng, Xiong Junfeng, Zhang Huan, arXiv:2001.05574arXiv preprintDou Goodman, Hao Xin, Wang Yang, Wu Yuesheng, Xiong Junfeng, and Zhang Huan. Advbox: a toolbox to generate adversarial examples that fool neural networks. arXiv preprint arXiv:2001.05574, 2020.\n\nIndiscriminate poisoning attacks on unsupervised contrastive learning. Kaiwen Hao He, Dina Zha, Katabi, International Conference on Learning Representations. Hao He, Kaiwen Zha, and Dina Katabi. Indiscriminate poisoning attacks on unsupervised contrastive learning. In International Conference on Learning Representations, 2023.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016.\n\nDensely connected convolutional networks. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, Kilian Q Weinberger, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionGao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4700-4708, 2017.\n\nUnlearnable examples: Making personal data unexploitable. Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang, International Conference on Learning Representations. Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, and Yisen Wang. Unlearnable examples: Making personal data unexploitable. In International Conference on Learning Representations, 2021.\n\nNeural tangent kernel: Convergence and generalization in neural networks. Arthur Jacot, Franck Gabriel, Cl\u00e9ment Hongler, Advances in neural information processing systems. 31Arthur Jacot, Franck Gabriel, and Cl\u00e9ment Hongler. Neural tangent kernel: Convergence and generalization in neural networks. Advances in neural information processing systems, 31, 2018.\n\nAnalyzing and improving the image quality of StyleGAN. Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. the IEEE/CVF conference on computer vision and pattern recognitionTero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of StyleGAN. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 8110-8119, 2020.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.\n\nDeep learning. nature. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, 521Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436-444, 2015.\n\nBackdoorBox: A Python toolbox for backdoor learning. Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, Shu-Tao Xia, Yiming Li, Mengxi Ya, Yang Bai, Yong Jiang, and Shu-Tao Xia. BackdoorBox: A Python toolbox for backdoor learning. 2023.\n\nImage shortcut squeezing: Countering perturbative availability poisons with compression. Zhuoran Liu, Zhengyu Zhao, Martha Larson, International conference on machine learning. Zhuoran Liu, Zhengyu Zhao, and Martha Larson. Image shortcut squeezing: Countering perturbative availability poisons with compression. In International conference on machine learning, 2023.\n\nA unified approach to interpreting model predictions. M Scott, Su-In Lundberg, Lee, 30Advances in neural information processing systemsScott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. Advances in neural information processing systems, 30, 2017.\n\nTowards deep learning models resistant to adversarial attacks. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu, arXiv:1706.06083arXiv preprintAleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083, 2017.\n\nReading digits in natural images with unsupervised feature learning. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y Ng, Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011.\n\nDiffusion models for adversarial purification. Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, Anima Anandkumar, International conference on machine learning. Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, and Anima Anandkumar. Diffusion models for adversarial purification. In International conference on machine learning, 2022.\n\nTrojanzoo: Everything you ever wanted to know about neural backdoors. Ren Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng, Ting Wang, but were afraid to ask). arXiv preprintRen Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng, and Ting Wang. Trojanzoo: Everything you ever wanted to know about neural backdoors (but were afraid to ask). arXiv preprint, 2020.\n\nTianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, Cheng-Zhong Xu, arXiv:2303.15127Learning the unlearnable: Adversarial augmentations suppress unlearnable example attacks. arXiv preprintTianrui Qin, Xitong Gao, Juanjuan Zhao, Kejiang Ye, and Cheng-Zhong Xu. Learning the unlearnable: Adversarial augmentations suppress unlearnable example attacks. arXiv preprint arXiv:2303.15127, 2023.\n\nFoolbox native: Fast adversarial attacks to benchmark the robustness of machine learning models in pytorch, tensorflow, and jax. Jonas Rauber, Roland Zimmermann, Matthias Bethge, Wieland Brendel, Journal of Open Source Software. 5532607Jonas Rauber, Roland Zimmermann, Matthias Bethge, and Wieland Brendel. Foolbox native: Fast adversarial attacks to benchmark the robustness of machine learning models in pytorch, tensorflow, and jax. Journal of Open Source Software, 5(53):2607, 2020.\n\nTransferable unlearnable examples. Jie Ren, Han Xu, Yuxuan Wan, Xingjun Ma, Lichao Sun, Jiliang Tang, International Conference on Learning Representations. Jie Ren, Han Xu, Yuxuan Wan, Xingjun Ma, Lichao Sun, and Jiliang Tang. Transferable unlearnable examples. In International Conference on Learning Representations, 2023.\n\nImageNet large scale visual recognition challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, International journal of computer vision. 115Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. ImageNet large scale visual recognition challenge. International journal of computer vision, 115:211-252, 2015.\n\nMobilenetv2: Inverted residuals and linear bottlenecks. Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionMark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4510-4520, 2018.\n\nAutoregressive perturbations for data poisoning. Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, David Jacobs, Advances in Neural Information Processing Systems. 35Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, and David Jacobs. Autoregressive perturbations for data poisoning. Advances in Neural Information Processing Systems, 35:27374- 27386, 2022.\n\nDeep learning in neural networks: An overview. J\u00fcrgen Schmidhuber, Neural networks. 61J\u00fcrgen Schmidhuber. Deep learning in neural networks: An overview. Neural networks, 61:85-117, 2015.\n\nGrad-CAM: Visual explanations from deep networks via gradient-based localization. R Ramprasaath, Michael Selvaraju, Abhishek Cogswell, Ramakrishna Das, Devi Vedantam, Dhruv Parikh, Batra, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer visionRamprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-CAM: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision, pages 618-626, 2017.\n\nBetter safe than sorry: Preventing delusive adversaries with adversarial training. Lue Tao, Lei Feng, Jinfeng Yi, Sheng-Jun Huang, Songcan Chen, Advances in Neural Information Processing Systems. 34Lue Tao, Lei Feng, Jinfeng Yi, Sheng-Jun Huang, and Songcan Chen. Better safe than sorry: Preventing delusive adversaries with adversarial training. Advances in Neural Information Processing Systems, 34:16209-16225, 2021.\n\nVisualizing data using t-sne. Laurens Van Der Maaten, Geoffrey Hinton, Journal of machine learning research. 911Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(11), 2008.\n\nBackdoorbench: A comprehensive benchmark of backdoor learning. Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Chao Shen, Advances in Neural Information Processing Systems. 35Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, and Chao Shen. Backdoor- bench: A comprehensive benchmark of backdoor learning. Advances in Neural Information Processing Systems, 35:10546-10559, 2022.\n\nOne-pixel shortcut: on the learning preference of deep neural networks. Shutong Wu, Sizhe Chen, Cihang Xie, Xiaolin Huang, International Conference on Learning Representations. Shutong Wu, Sizhe Chen, Cihang Xie, and Xiaolin Huang. One-pixel shortcut: on the learning preference of deep neural networks. In International Conference on Learning Representations, 2023.\n\nAvailability attacks create shortcuts. Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, Tie-Yan Liu, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data MiningDa Yu, Huishuai Zhang, Wei Chen, Jian Yin, and Tie-Yan Liu. Availability attacks create shortcuts. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 2367-2376, 2022.\n\nNeural tangent generalization attacks. Chia-Hung Yuan, Shan-Hung Wu, International Conference on Machine Learning. PMLRChia-Hung Yuan and Shan-Hung Wu. Neural tangent generalization attacks. In International Conference on Machine Learning, pages 12230-12240. PMLR, 2021.\n\nCutMix: Regularization strategy to train strong classifiers with localizable features. Sangdoo Yun, Dongyoon Han, Sanghyuk Seong Joon Oh, Junsuk Chun, Youngjoon Choe, Yoo, Proceedings of the IEEE/CVF international conference on computer vision. the IEEE/CVF international conference on computer visionSangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. CutMix: Regularization strategy to train strong classifiers with localizable features. In Proceedings of the IEEE/CVF international conference on computer vision, pages 6023-6032, 2019.\n\nMixUp: Beyond empirical risk minimization. Hongyi Zhang, Moustapha Cisse, David Yann N Dauphin, Lopez-Paz, International Conference on Learning Representations. Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. MixUp: Beyond empirical risk minimization. In International Conference on Learning Representations, 2018. Clean EM/No defense EM/ISS EM/UEraser EM/AVATAR\n\n. Lsp/Iss Lsp/No Defense, Lsp Lsp/Ueraser, Avatar, LSP/No defense LSP/ISS LSP/UEraser LSP/AVATAR\n\nThe t-SNE visualization of the models' feature representations on the clean test set under additional attacks for CIFAR-10. 7UEraser-MaxU-Max\" denotesFigure 7: The t-SNE visualization of the models' feature representations on the clean test set under additional attacks for CIFAR-10. \"U-Max\" denotes \"UEraser-Max\".\n\n. Resources, G Computational Resources\n\nGPU-hours per run for standard training / ISS methods / UEraser-max / AT on CIFAR-10, CIFAR-100 and SVHN. As for ImageNet-100. Nvidia V100 On, Gpus, we used up to 0.3 / 1.0 / 3.2 / 4.. we used up to 1.0 / 1.6 / 4.9 / 5.8On NVIDIA V100 GPUs, we used up to 0.3 / 1.0 / 3.2 / 4.7 GPU-hours per run for standard training / ISS methods / UEraser-max / AT on CIFAR-10, CIFAR-100 and SVHN. As for ImageNet-100, we used up to 1.0 / 1.6 / 4.9 / 5.8\n\nThe preprocessing stage of AVATAR took 4 GPU-hours on V100 on CIFAR-10. For unsupervised learning, the preprocessing cost of UEraser-lite and AVATAR was approximately 0. GPU-hours per run on NVIDIA A100 for standard training / ISS / UEraser-max / AT. 4 / 4.0 GPU-hours on V100, and we used up to 4.5 / 4.7 GPU-hours per run for standard training / ISS on CIFAR-10. All experiments in this paper used approximately 3,800 GPU-hours on V100 and 1,100 GPU-hours on A100 in totalGPU-hours per run on NVIDIA A100 for standard training / ISS / UEraser-max / AT. The preprocessing stage of AVATAR took 4 GPU-hours on V100 on CIFAR-10. For unsupervised learning, the preprocessing cost of UEraser-lite and AVATAR was approximately 0.4 / 4.0 GPU-hours on V100, and we used up to 4.5 / 4.7 GPU-hours per run for standard training / ISS on CIFAR-10. All experiments in this paper used approximately 3,800 GPU-hours on V100 and 1,100 GPU-hours on A100 in total.\n\nH Licenses APBench is open source, and the source code is. Table 12 provides the licenses of the derived implementations of the original algorithms and datasetsH Licenses APBench is open source, and the source code is available at https://github.com/lafeat/apbench. Table 12 provides the licenses of the derived implementations of the original algorithms and datasets.\n", "annotations": {"author": "[{\"end\":230,\"start\":91},{\"end\":320,\"start\":231},{\"end\":413,\"start\":321},{\"end\":503,\"start\":414},{\"end\":559,\"start\":504}]", "publisher": null, "author_last_name": "[{\"end\":102,\"start\":99},{\"end\":241,\"start\":238},{\"end\":334,\"start\":330},{\"end\":424,\"start\":422},{\"end\":518,\"start\":516}]", "author_first_name": "[{\"end\":98,\"start\":91},{\"end\":237,\"start\":231},{\"end\":329,\"start\":321},{\"end\":421,\"start\":414},{\"end\":515,\"start\":504}]", "author_affiliation": "[{\"end\":180,\"start\":104},{\"end\":229,\"start\":182},{\"end\":319,\"start\":243},{\"end\":412,\"start\":336},{\"end\":502,\"start\":426},{\"end\":558,\"start\":520}]", "title": "[{\"end\":88,\"start\":1},{\"end\":647,\"start\":560}]", "venue": null, "abstract": "[{\"end\":2055,\"start\":649}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2126,\"start\":2122},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2129,\"start\":2126},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2132,\"start\":2129},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2196,\"start\":2193},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2199,\"start\":2196},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2202,\"start\":2199},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2517,\"start\":2514},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2519,\"start\":2517},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2521,\"start\":2519},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2524,\"start\":2521},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2527,\"start\":2524},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2530,\"start\":2527},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2533,\"start\":2530},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2536,\"start\":2533},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2539,\"start\":2536},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2542,\"start\":2539},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2545,\"start\":2542},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2548,\"start\":2545},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2551,\"start\":2548},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2717,\"start\":2713},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2909,\"start\":2906},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2912,\"start\":2909},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2915,\"start\":2912},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2918,\"start\":2915},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4438,\"start\":4437},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5549,\"start\":5545},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5992,\"start\":5989},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6125,\"start\":6121},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6182,\"start\":6178},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6316,\"start\":6312},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6561,\"start\":6558},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":6693,\"start\":6689},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6842,\"start\":6839},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6966,\"start\":6962},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7015,\"start\":7011},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7366,\"start\":7362},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":7405,\"start\":7401},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":7773,\"start\":7769},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8321,\"start\":8317},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8515,\"start\":8512},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8562,\"start\":8558},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8908,\"start\":8905},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8911,\"start\":8908},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8964,\"start\":8960},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9283,\"start\":9280},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":9296,\"start\":9292},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9312,\"start\":9308},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9795,\"start\":9791},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9808,\"start\":9804},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9829,\"start\":9826},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10149,\"start\":10145},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10169,\"start\":10165},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10191,\"start\":10187},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14654,\"start\":14650},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14670,\"start\":14666},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14681,\"start\":14677},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14702,\"start\":14699},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14750,\"start\":14746},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14766,\"start\":14762},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14784,\"start\":14780},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":14807,\"start\":14803},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":15440,\"start\":15436},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":15453,\"start\":15449},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16086,\"start\":16083},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":16122,\"start\":16118},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":16160,\"start\":16156},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16417,\"start\":16413},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16500,\"start\":16496},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16544,\"start\":16540},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16599,\"start\":16595},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16633,\"start\":16630},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16683,\"start\":16679},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16749,\"start\":16745},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16788,\"start\":16784},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16863,\"start\":16859},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16879,\"start\":16876},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17364,\"start\":17361},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":17388,\"start\":17385},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":18225,\"start\":18221},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":18475,\"start\":18471},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18490,\"start\":18487},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21335,\"start\":21332},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21351,\"start\":21348},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":21795,\"start\":21791},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":22097,\"start\":22093},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22124,\"start\":22120},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25074,\"start\":25071},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":25370,\"start\":25366},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":25763,\"start\":25759},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":25979,\"start\":25975},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":26140,\"start\":26137},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26316,\"start\":26313},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":26502,\"start\":26498},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":26744,\"start\":26740},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27022,\"start\":27018},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":27256,\"start\":27252},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":27466,\"start\":27462},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":27903,\"start\":27899},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":28175,\"start\":28171},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28397,\"start\":28393},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":28618,\"start\":28615},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":28643,\"start\":28639}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30503,\"start\":30363},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30554,\"start\":30504},{\"attributes\":{\"id\":\"fig_6\"},\"end\":30777,\"start\":30555},{\"attributes\":{\"id\":\"fig_7\"},\"end\":31090,\"start\":30778},{\"attributes\":{\"id\":\"fig_9\"},\"end\":31283,\"start\":31091},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":31370,\"start\":31284},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":31531,\"start\":31371},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33281,\"start\":31532},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":33625,\"start\":33282},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":34613,\"start\":33626},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":35138,\"start\":34614},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":35515,\"start\":35139},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":36663,\"start\":35516},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":37513,\"start\":36664},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":38365,\"start\":37514}]", "paragraph": "[{\"end\":3242,\"start\":2071},{\"end\":3723,\"start\":3244},{\"end\":4283,\"start\":3725},{\"end\":4332,\"start\":4285},{\"end\":5059,\"start\":4334},{\"end\":5416,\"start\":5061},{\"end\":5432,\"start\":5418},{\"end\":7971,\"start\":5467},{\"end\":9382,\"start\":8007},{\"end\":9830,\"start\":9405},{\"end\":10192,\"start\":9832},{\"end\":10824,\"start\":10194},{\"end\":11653,\"start\":10848},{\"end\":11994,\"start\":11771},{\"end\":12160,\"start\":11996},{\"end\":12380,\"start\":12233},{\"end\":13123,\"start\":12492},{\"end\":14214,\"start\":13140},{\"end\":14560,\"start\":14216},{\"end\":15139,\"start\":14576},{\"end\":16199,\"start\":15164},{\"end\":16418,\"start\":16395},{\"end\":16977,\"start\":16441},{\"end\":17612,\"start\":16979},{\"end\":18807,\"start\":17634},{\"end\":19118,\"start\":18833},{\"end\":20401,\"start\":19120},{\"end\":20993,\"start\":20403},{\"end\":21649,\"start\":20995},{\"end\":22397,\"start\":21651},{\"end\":22687,\"start\":22409},{\"end\":23240,\"start\":22702},{\"end\":23730,\"start\":23242},{\"end\":24770,\"start\":23746},{\"end\":25038,\"start\":24812},{\"end\":25333,\"start\":25051},{\"end\":25711,\"start\":25335},{\"end\":25951,\"start\":25713},{\"end\":26096,\"start\":25953},{\"end\":26271,\"start\":26098},{\"end\":26461,\"start\":26273},{\"end\":26706,\"start\":26463},{\"end\":26989,\"start\":26708},{\"end\":27217,\"start\":26991},{\"end\":27418,\"start\":27219},{\"end\":27858,\"start\":27420},{\"end\":27869,\"start\":27860},{\"end\":28136,\"start\":27871},{\"end\":28353,\"start\":28138},{\"end\":28604,\"start\":28355},{\"end\":29096,\"start\":28606},{\"end\":29519,\"start\":29140},{\"end\":30362,\"start\":29542}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11770,\"start\":11654},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12232,\"start\":12161},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12446,\"start\":12381},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16394,\"start\":16200}]", "table_ref": "[{\"end\":14394,\"start\":14387},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":14406,\"start\":14399},{\"end\":15496,\"start\":15489},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":17949,\"start\":17942},{\"end\":18805,\"start\":18798},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":19919,\"start\":19912},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":20780,\"start\":20773},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":21648,\"start\":21641},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":24644,\"start\":24637},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24934,\"start\":24920},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":28733,\"start\":28726}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2069,\"start\":2057},{\"attributes\":{\"n\":\"2.1\"},\"end\":5465,\"start\":5435},{\"attributes\":{\"n\":\"2.2\"},\"end\":8005,\"start\":7974},{\"attributes\":{\"n\":\"2.3\"},\"end\":9403,\"start\":9385},{\"attributes\":{\"n\":\"3\"},\"end\":10846,\"start\":10827},{\"attributes\":{\"n\":\"4\"},\"end\":12490,\"start\":12448},{\"end\":13138,\"start\":13126},{\"attributes\":{\"n\":\"5\"},\"end\":14574,\"start\":14563},{\"end\":15162,\"start\":15142},{\"end\":16439,\"start\":16421},{\"attributes\":{\"n\":\"5.1\"},\"end\":17632,\"start\":17615},{\"attributes\":{\"n\":\"5.2\"},\"end\":18831,\"start\":18810},{\"end\":22407,\"start\":22400},{\"attributes\":{\"n\":\"6\"},\"end\":22700,\"start\":22690},{\"attributes\":{\"n\":\"7\"},\"end\":23744,\"start\":23733},{\"end\":24783,\"start\":24773},{\"end\":24810,\"start\":24786},{\"end\":25049,\"start\":25041},{\"end\":29122,\"start\":29099},{\"end\":29138,\"start\":29125},{\"end\":29540,\"start\":29522},{\"end\":30374,\"start\":30364},{\"end\":30515,\"start\":30505},{\"end\":30566,\"start\":30556},{\"end\":30789,\"start\":30779},{\"end\":31102,\"start\":31092},{\"end\":31381,\"start\":31372},{\"end\":31542,\"start\":31533},{\"end\":33292,\"start\":33283},{\"end\":33636,\"start\":33627},{\"end\":34624,\"start\":34615},{\"end\":35149,\"start\":35140},{\"end\":35526,\"start\":35517},{\"end\":36675,\"start\":36665},{\"end\":37525,\"start\":37515}]", "table": "[{\"end\":31370,\"start\":31361},{\"end\":31531,\"start\":31448},{\"end\":33281,\"start\":31612},{\"end\":33625,\"start\":33373},{\"end\":34613,\"start\":33801},{\"end\":35138,\"start\":34784},{\"end\":35515,\"start\":35222},{\"end\":36663,\"start\":35735},{\"end\":37513,\"start\":36719},{\"end\":38365,\"start\":37572}]", "figure_caption": "[{\"end\":30503,\"start\":30376},{\"end\":30554,\"start\":30517},{\"end\":30777,\"start\":30568},{\"end\":31090,\"start\":30791},{\"end\":31283,\"start\":31104},{\"end\":31361,\"start\":31286},{\"end\":31448,\"start\":31383},{\"end\":31612,\"start\":31544},{\"end\":33373,\"start\":33294},{\"end\":33801,\"start\":33638},{\"end\":34784,\"start\":34626},{\"end\":35222,\"start\":35151},{\"end\":35735,\"start\":35528},{\"end\":36719,\"start\":36678},{\"end\":37572,\"start\":37528}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7928,\"start\":7920},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12512,\"start\":12504},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":19242,\"start\":19234},{\"end\":22451,\"start\":22443},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":28863,\"start\":28855},{\"end\":28989,\"start\":28981}]", "bib_author_first_name": "[{\"end\":38655,\"start\":38651},{\"end\":38667,\"start\":38662},{\"end\":38687,\"start\":38679},{\"end\":38705,\"start\":38697},{\"end\":38987,\"start\":38981},{\"end\":38999,\"start\":38994},{\"end\":39280,\"start\":39271},{\"end\":39294,\"start\":39288},{\"end\":39317,\"start\":39311},{\"end\":39333,\"start\":39326},{\"end\":39809,\"start\":39806},{\"end\":39819,\"start\":39816},{\"end\":39833,\"start\":39826},{\"end\":39848,\"start\":39842},{\"end\":39856,\"start\":39853},{\"end\":39863,\"start\":39861},{\"end\":40170,\"start\":40162},{\"end\":40181,\"start\":40180},{\"end\":40543,\"start\":40538},{\"end\":40574,\"start\":40563},{\"end\":40894,\"start\":40892},{\"end\":40907,\"start\":40901},{\"end\":40920,\"start\":40913},{\"end\":41209,\"start\":41205},{\"end\":41221,\"start\":41216},{\"end\":41240,\"start\":41232},{\"end\":41254,\"start\":41249},{\"end\":41272,\"start\":41264},{\"end\":41283,\"start\":41280},{\"end\":41641,\"start\":41633},{\"end\":41655,\"start\":41646},{\"end\":41664,\"start\":41660},{\"end\":41672,\"start\":41670},{\"end\":41686,\"start\":41679},{\"end\":41997,\"start\":41991},{\"end\":42018,\"start\":42007},{\"end\":42036,\"start\":42029},{\"end\":42055,\"start\":42048},{\"end\":42070,\"start\":42063},{\"end\":42088,\"start\":42080},{\"end\":42102,\"start\":42097},{\"end\":42104,\"start\":42103},{\"end\":42461,\"start\":42456},{\"end\":42480,\"start\":42472},{\"end\":42496,\"start\":42490},{\"end\":42508,\"start\":42502},{\"end\":42518,\"start\":42515},{\"end\":42538,\"start\":42534},{\"end\":42555,\"start\":42545},{\"end\":42565,\"start\":42563},{\"end\":42573,\"start\":42570},{\"end\":43041,\"start\":43038},{\"end\":43054,\"start\":43051},{\"end\":43064,\"start\":43060},{\"end\":43073,\"start\":43071},{\"end\":43089,\"start\":43084},{\"end\":43104,\"start\":43099},{\"end\":43413,\"start\":43407},{\"end\":43426,\"start\":43422},{\"end\":43719,\"start\":43712},{\"end\":43731,\"start\":43724},{\"end\":43747,\"start\":43739},{\"end\":43757,\"start\":43753},{\"end\":44154,\"start\":44151},{\"end\":44168,\"start\":44162},{\"end\":44181,\"start\":44174},{\"end\":44206,\"start\":44198},{\"end\":44644,\"start\":44638},{\"end\":44659,\"start\":44652},{\"end\":44669,\"start\":44664},{\"end\":44677,\"start\":44670},{\"end\":44691,\"start\":44686},{\"end\":44705,\"start\":44700},{\"end\":45046,\"start\":45040},{\"end\":45060,\"start\":45054},{\"end\":45077,\"start\":45070},{\"end\":45386,\"start\":45382},{\"end\":45401,\"start\":45395},{\"end\":45414,\"start\":45409},{\"end\":45429,\"start\":45424},{\"end\":45446,\"start\":45440},{\"end\":45461,\"start\":45457},{\"end\":45931,\"start\":45927},{\"end\":45952,\"start\":45944},{\"end\":46091,\"start\":46087},{\"end\":46105,\"start\":46099},{\"end\":46122,\"start\":46114},{\"end\":46290,\"start\":46284},{\"end\":46301,\"start\":46295},{\"end\":46310,\"start\":46306},{\"end\":46320,\"start\":46316},{\"end\":46335,\"start\":46328},{\"end\":46558,\"start\":46551},{\"end\":46571,\"start\":46564},{\"end\":46584,\"start\":46578},{\"end\":46885,\"start\":46884},{\"end\":46898,\"start\":46893},{\"end\":47186,\"start\":47176},{\"end\":47204,\"start\":47194},{\"end\":47220,\"start\":47214},{\"end\":47238,\"start\":47230},{\"end\":47254,\"start\":47248},{\"end\":47559,\"start\":47554},{\"end\":47571,\"start\":47568},{\"end\":47582,\"start\":47578},{\"end\":47601,\"start\":47591},{\"end\":47614,\"start\":47612},{\"end\":47627,\"start\":47619},{\"end\":47842,\"start\":47837},{\"end\":47855,\"start\":47848},{\"end\":47866,\"start\":47861},{\"end\":47881,\"start\":47874},{\"end\":47893,\"start\":47888},{\"end\":47907,\"start\":47902},{\"end\":48229,\"start\":48226},{\"end\":48241,\"start\":48236},{\"end\":48258,\"start\":48249},{\"end\":48271,\"start\":48264},{\"end\":48284,\"start\":48276},{\"end\":48293,\"start\":48289},{\"end\":48305,\"start\":48301},{\"end\":48566,\"start\":48559},{\"end\":48578,\"start\":48572},{\"end\":48592,\"start\":48584},{\"end\":48606,\"start\":48599},{\"end\":48622,\"start\":48611},{\"end\":49083,\"start\":49078},{\"end\":49098,\"start\":49092},{\"end\":49119,\"start\":49111},{\"end\":49135,\"start\":49128},{\"end\":49475,\"start\":49472},{\"end\":49484,\"start\":49481},{\"end\":49495,\"start\":49489},{\"end\":49508,\"start\":49501},{\"end\":49519,\"start\":49513},{\"end\":49532,\"start\":49525},{\"end\":49818,\"start\":49814},{\"end\":49835,\"start\":49832},{\"end\":49845,\"start\":49842},{\"end\":49858,\"start\":49850},{\"end\":49874,\"start\":49867},{\"end\":49889,\"start\":49885},{\"end\":49901,\"start\":49894},{\"end\":49915,\"start\":49909},{\"end\":49932,\"start\":49926},{\"end\":49948,\"start\":49941},{\"end\":50331,\"start\":50327},{\"end\":50347,\"start\":50341},{\"end\":50364,\"start\":50356},{\"end\":50376,\"start\":50370},{\"end\":50399,\"start\":50388},{\"end\":50846,\"start\":50841},{\"end\":50868,\"start\":50864},{\"end\":50882,\"start\":50877},{\"end\":50897,\"start\":50892},{\"end\":50911,\"start\":50908},{\"end\":50928,\"start\":50923},{\"end\":51267,\"start\":51261},{\"end\":51485,\"start\":51484},{\"end\":51506,\"start\":51499},{\"end\":51526,\"start\":51518},{\"end\":51548,\"start\":51537},{\"end\":51558,\"start\":51554},{\"end\":51574,\"start\":51569},{\"end\":52082,\"start\":52079},{\"end\":52091,\"start\":52088},{\"end\":52105,\"start\":52098},{\"end\":52119,\"start\":52110},{\"end\":52134,\"start\":52127},{\"end\":52454,\"start\":52447},{\"end\":52479,\"start\":52471},{\"end\":52725,\"start\":52718},{\"end\":52737,\"start\":52730},{\"end\":52750,\"start\":52744},{\"end\":52763,\"start\":52758},{\"end\":52776,\"start\":52769},{\"end\":52787,\"start\":52782},{\"end\":52798,\"start\":52794},{\"end\":53167,\"start\":53160},{\"end\":53177,\"start\":53172},{\"end\":53190,\"start\":53184},{\"end\":53203,\"start\":53196},{\"end\":53497,\"start\":53495},{\"end\":53510,\"start\":53502},{\"end\":53521,\"start\":53518},{\"end\":53532,\"start\":53528},{\"end\":53545,\"start\":53538},{\"end\":53966,\"start\":53957},{\"end\":53982,\"start\":53973},{\"end\":54284,\"start\":54277},{\"end\":54298,\"start\":54290},{\"end\":54312,\"start\":54304},{\"end\":54334,\"start\":54328},{\"end\":54350,\"start\":54341},{\"end\":54816,\"start\":54810},{\"end\":54833,\"start\":54824},{\"end\":54846,\"start\":54841},{\"end\":55160,\"start\":55153},{\"end\":55180,\"start\":55177},{\"end\":55743,\"start\":55732}]", "bib_author_last_name": "[{\"end\":38660,\"start\":38656},{\"end\":38677,\"start\":38668},{\"end\":38695,\"start\":38688},{\"end\":38712,\"start\":38706},{\"end\":38992,\"start\":38988},{\"end\":39003,\"start\":39000},{\"end\":39286,\"start\":39281},{\"end\":39309,\"start\":39295},{\"end\":39324,\"start\":39318},{\"end\":39345,\"start\":39334},{\"end\":39814,\"start\":39810},{\"end\":39824,\"start\":39820},{\"end\":39840,\"start\":39834},{\"end\":39851,\"start\":39849},{\"end\":39859,\"start\":39857},{\"end\":39871,\"start\":39864},{\"end\":40178,\"start\":40171},{\"end\":40188,\"start\":40182},{\"end\":40196,\"start\":40190},{\"end\":40561,\"start\":40544},{\"end\":40581,\"start\":40575},{\"end\":40589,\"start\":40583},{\"end\":40899,\"start\":40895},{\"end\":40911,\"start\":40908},{\"end\":40925,\"start\":40921},{\"end\":41214,\"start\":41210},{\"end\":41230,\"start\":41222},{\"end\":41247,\"start\":41241},{\"end\":41262,\"start\":41255},{\"end\":41278,\"start\":41273},{\"end\":41293,\"start\":41284},{\"end\":41644,\"start\":41642},{\"end\":41658,\"start\":41656},{\"end\":41668,\"start\":41665},{\"end\":41677,\"start\":41673},{\"end\":41690,\"start\":41687},{\"end\":42005,\"start\":41998},{\"end\":42027,\"start\":42019},{\"end\":42046,\"start\":42037},{\"end\":42061,\"start\":42056},{\"end\":42078,\"start\":42071},{\"end\":42095,\"start\":42089},{\"end\":42113,\"start\":42105},{\"end\":42470,\"start\":42462},{\"end\":42488,\"start\":42481},{\"end\":42500,\"start\":42497},{\"end\":42513,\"start\":42509},{\"end\":42532,\"start\":42519},{\"end\":42543,\"start\":42539},{\"end\":42561,\"start\":42556},{\"end\":42568,\"start\":42566},{\"end\":42583,\"start\":42574},{\"end\":43049,\"start\":43042},{\"end\":43058,\"start\":43055},{\"end\":43069,\"start\":43065},{\"end\":43082,\"start\":43074},{\"end\":43097,\"start\":43090},{\"end\":43109,\"start\":43105},{\"end\":43420,\"start\":43414},{\"end\":43430,\"start\":43427},{\"end\":43438,\"start\":43432},{\"end\":43722,\"start\":43720},{\"end\":43737,\"start\":43732},{\"end\":43751,\"start\":43748},{\"end\":43761,\"start\":43758},{\"end\":44160,\"start\":44155},{\"end\":44172,\"start\":44169},{\"end\":44196,\"start\":44182},{\"end\":44217,\"start\":44207},{\"end\":44650,\"start\":44645},{\"end\":44662,\"start\":44660},{\"end\":44684,\"start\":44678},{\"end\":44698,\"start\":44692},{\"end\":44710,\"start\":44706},{\"end\":45052,\"start\":45047},{\"end\":45068,\"start\":45061},{\"end\":45085,\"start\":45078},{\"end\":45393,\"start\":45387},{\"end\":45407,\"start\":45402},{\"end\":45422,\"start\":45415},{\"end\":45438,\"start\":45430},{\"end\":45455,\"start\":45447},{\"end\":45466,\"start\":45462},{\"end\":45942,\"start\":45932},{\"end\":45959,\"start\":45953},{\"end\":46097,\"start\":46092},{\"end\":46112,\"start\":46106},{\"end\":46129,\"start\":46123},{\"end\":46293,\"start\":46291},{\"end\":46304,\"start\":46302},{\"end\":46314,\"start\":46311},{\"end\":46326,\"start\":46321},{\"end\":46339,\"start\":46336},{\"end\":46562,\"start\":46559},{\"end\":46576,\"start\":46572},{\"end\":46591,\"start\":46585},{\"end\":46891,\"start\":46886},{\"end\":46907,\"start\":46899},{\"end\":46912,\"start\":46909},{\"end\":47192,\"start\":47187},{\"end\":47212,\"start\":47205},{\"end\":47228,\"start\":47221},{\"end\":47246,\"start\":47239},{\"end\":47260,\"start\":47255},{\"end\":47566,\"start\":47560},{\"end\":47576,\"start\":47572},{\"end\":47589,\"start\":47583},{\"end\":47610,\"start\":47602},{\"end\":47617,\"start\":47615},{\"end\":47630,\"start\":47628},{\"end\":47846,\"start\":47843},{\"end\":47859,\"start\":47856},{\"end\":47872,\"start\":47867},{\"end\":47886,\"start\":47882},{\"end\":47900,\"start\":47894},{\"end\":47918,\"start\":47908},{\"end\":48234,\"start\":48230},{\"end\":48247,\"start\":48242},{\"end\":48262,\"start\":48259},{\"end\":48274,\"start\":48272},{\"end\":48287,\"start\":48285},{\"end\":48299,\"start\":48294},{\"end\":48310,\"start\":48306},{\"end\":48570,\"start\":48567},{\"end\":48582,\"start\":48579},{\"end\":48597,\"start\":48593},{\"end\":48609,\"start\":48607},{\"end\":48625,\"start\":48623},{\"end\":49090,\"start\":49084},{\"end\":49109,\"start\":49099},{\"end\":49126,\"start\":49120},{\"end\":49143,\"start\":49136},{\"end\":49479,\"start\":49476},{\"end\":49487,\"start\":49485},{\"end\":49499,\"start\":49496},{\"end\":49511,\"start\":49509},{\"end\":49523,\"start\":49520},{\"end\":49537,\"start\":49533},{\"end\":49830,\"start\":49819},{\"end\":49840,\"start\":49836},{\"end\":49848,\"start\":49846},{\"end\":49865,\"start\":49859},{\"end\":49883,\"start\":49875},{\"end\":49892,\"start\":49890},{\"end\":49907,\"start\":49902},{\"end\":49924,\"start\":49916},{\"end\":49939,\"start\":49933},{\"end\":49958,\"start\":49949},{\"end\":50339,\"start\":50332},{\"end\":50354,\"start\":50348},{\"end\":50368,\"start\":50365},{\"end\":50386,\"start\":50377},{\"end\":50404,\"start\":50400},{\"end\":50862,\"start\":50847},{\"end\":50875,\"start\":50869},{\"end\":50890,\"start\":50883},{\"end\":50906,\"start\":50898},{\"end\":50921,\"start\":50912},{\"end\":50935,\"start\":50929},{\"end\":51279,\"start\":51268},{\"end\":51497,\"start\":51486},{\"end\":51516,\"start\":51507},{\"end\":51535,\"start\":51527},{\"end\":51552,\"start\":51549},{\"end\":51567,\"start\":51559},{\"end\":51581,\"start\":51575},{\"end\":51588,\"start\":51583},{\"end\":52086,\"start\":52083},{\"end\":52096,\"start\":52092},{\"end\":52108,\"start\":52106},{\"end\":52125,\"start\":52120},{\"end\":52139,\"start\":52135},{\"end\":52469,\"start\":52455},{\"end\":52486,\"start\":52480},{\"end\":52728,\"start\":52726},{\"end\":52742,\"start\":52738},{\"end\":52756,\"start\":52751},{\"end\":52767,\"start\":52764},{\"end\":52780,\"start\":52777},{\"end\":52792,\"start\":52788},{\"end\":52803,\"start\":52799},{\"end\":53170,\"start\":53168},{\"end\":53182,\"start\":53178},{\"end\":53194,\"start\":53191},{\"end\":53209,\"start\":53204},{\"end\":53500,\"start\":53498},{\"end\":53516,\"start\":53511},{\"end\":53526,\"start\":53522},{\"end\":53536,\"start\":53533},{\"end\":53549,\"start\":53546},{\"end\":53971,\"start\":53967},{\"end\":53985,\"start\":53983},{\"end\":54288,\"start\":54285},{\"end\":54302,\"start\":54299},{\"end\":54326,\"start\":54313},{\"end\":54339,\"start\":54335},{\"end\":54355,\"start\":54351},{\"end\":54360,\"start\":54357},{\"end\":54822,\"start\":54817},{\"end\":54839,\"start\":54834},{\"end\":54861,\"start\":54847},{\"end\":54872,\"start\":54863},{\"end\":55175,\"start\":55161},{\"end\":55192,\"start\":55181},{\"end\":55200,\"start\":55194},{\"end\":55576,\"start\":55567},{\"end\":55746,\"start\":55744},{\"end\":55752,\"start\":55748}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":211096730},\"end\":38979,\"start\":38580},{\"attributes\":{\"doi\":\"arXiv:2003.04297\",\"id\":\"b1\"},\"end\":39269,\"start\":38981},{\"attributes\":{\"doi\":\"arXiv:2010.09670\",\"id\":\"b2\"},\"end\":39751,\"start\":39271},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":57246310},\"end\":40160,\"start\":39753},{\"attributes\":{\"doi\":\"arXiv:1708.04552\",\"id\":\"b4\"},\"end\":40444,\"start\":40162},{\"attributes\":{\"doi\":\"arXiv:2303.08500\",\"id\":\"b5\"},\"end\":40808,\"start\":40446},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":162168672},\"end\":41161,\"start\":40810},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":235489699},\"end\":41556,\"start\":41163},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":247763000},\"end\":41946,\"start\":41558},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":215786368},\"end\":42367,\"start\":41948},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":229934464},\"end\":42958,\"start\":42369},{\"attributes\":{\"doi\":\"arXiv:2001.05574\",\"id\":\"b11\"},\"end\":43334,\"start\":42960},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":247058667},\"end\":43664,\"start\":43336},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":206594692},\"end\":44107,\"start\":43666},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":9433631},\"end\":44578,\"start\":44109},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":231592390},\"end\":44964,\"start\":44580},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":49321232},\"end\":45325,\"start\":44966},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":209202273},\"end\":45870,\"start\":45327},{\"attributes\":{\"id\":\"b18\"},\"end\":46062,\"start\":45872},{\"attributes\":{\"id\":\"b19\"},\"end\":46229,\"start\":46064},{\"attributes\":{\"id\":\"b20\"},\"end\":46460,\"start\":46231},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":256416324},\"end\":46828,\"start\":46462},{\"attributes\":{\"id\":\"b22\"},\"end\":47111,\"start\":46830},{\"attributes\":{\"doi\":\"arXiv:1706.06083\",\"id\":\"b23\"},\"end\":47483,\"start\":47113},{\"attributes\":{\"id\":\"b24\"},\"end\":47788,\"start\":47485},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":248811081},\"end\":48154,\"start\":47790},{\"attributes\":{\"id\":\"b26\"},\"end\":48557,\"start\":48156},{\"attributes\":{\"doi\":\"arXiv:2303.15127\",\"id\":\"b27\"},\"end\":48947,\"start\":48559},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":224901284},\"end\":49435,\"start\":48949},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":252992876},\"end\":49761,\"start\":49437},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":2930547},\"end\":50269,\"start\":49763},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":4555207},\"end\":50790,\"start\":50271},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":249461756},\"end\":51212,\"start\":50792},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":11715509},\"end\":51400,\"start\":51214},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":15019293},\"end\":51994,\"start\":51402},{\"attributes\":{\"id\":\"b35\"},\"end\":52415,\"start\":51996},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":5855042},\"end\":52653,\"start\":52417},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":250072872},\"end\":53086,\"start\":52655},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":249017593},\"end\":53454,\"start\":53088},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":249282169},\"end\":53916,\"start\":53456},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":235804333},\"end\":54188,\"start\":53918},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":152282661},\"end\":54765,\"start\":54190},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":3162051},\"end\":55149,\"start\":54767},{\"attributes\":{\"id\":\"b43\"},\"end\":55247,\"start\":55151},{\"attributes\":{\"id\":\"b44\"},\"end\":55563,\"start\":55249},{\"attributes\":{\"id\":\"b45\"},\"end\":55603,\"start\":55565},{\"attributes\":{\"id\":\"b46\"},\"end\":56044,\"start\":55605},{\"attributes\":{\"id\":\"b47\"},\"end\":56994,\"start\":56046},{\"attributes\":{\"id\":\"b48\"},\"end\":57364,\"start\":56996}]", "bib_title": "[{\"end\":38649,\"start\":38580},{\"end\":39804,\"start\":39753},{\"end\":40890,\"start\":40810},{\"end\":41203,\"start\":41163},{\"end\":41631,\"start\":41558},{\"end\":41989,\"start\":41948},{\"end\":42454,\"start\":42369},{\"end\":43405,\"start\":43336},{\"end\":43710,\"start\":43666},{\"end\":44149,\"start\":44109},{\"end\":44636,\"start\":44580},{\"end\":45038,\"start\":44966},{\"end\":45380,\"start\":45327},{\"end\":46549,\"start\":46462},{\"end\":47835,\"start\":47790},{\"end\":49076,\"start\":48949},{\"end\":49470,\"start\":49437},{\"end\":49812,\"start\":49763},{\"end\":50325,\"start\":50271},{\"end\":50839,\"start\":50792},{\"end\":51259,\"start\":51214},{\"end\":51482,\"start\":51402},{\"end\":52077,\"start\":51996},{\"end\":52445,\"start\":52417},{\"end\":52716,\"start\":52655},{\"end\":53158,\"start\":53088},{\"end\":53493,\"start\":53456},{\"end\":53955,\"start\":53918},{\"end\":54275,\"start\":54190},{\"end\":54808,\"start\":54767},{\"end\":56214,\"start\":56046}]", "bib_author": "[{\"end\":38662,\"start\":38651},{\"end\":38679,\"start\":38662},{\"end\":38697,\"start\":38679},{\"end\":38714,\"start\":38697},{\"end\":38994,\"start\":38981},{\"end\":39005,\"start\":38994},{\"end\":39288,\"start\":39271},{\"end\":39311,\"start\":39288},{\"end\":39326,\"start\":39311},{\"end\":39347,\"start\":39326},{\"end\":39816,\"start\":39806},{\"end\":39826,\"start\":39816},{\"end\":39842,\"start\":39826},{\"end\":39853,\"start\":39842},{\"end\":39861,\"start\":39853},{\"end\":39873,\"start\":39861},{\"end\":40180,\"start\":40162},{\"end\":40190,\"start\":40180},{\"end\":40198,\"start\":40190},{\"end\":40563,\"start\":40538},{\"end\":40583,\"start\":40563},{\"end\":40591,\"start\":40583},{\"end\":40901,\"start\":40892},{\"end\":40913,\"start\":40901},{\"end\":40927,\"start\":40913},{\"end\":41216,\"start\":41205},{\"end\":41232,\"start\":41216},{\"end\":41249,\"start\":41232},{\"end\":41264,\"start\":41249},{\"end\":41280,\"start\":41264},{\"end\":41295,\"start\":41280},{\"end\":41646,\"start\":41633},{\"end\":41660,\"start\":41646},{\"end\":41670,\"start\":41660},{\"end\":41679,\"start\":41670},{\"end\":41692,\"start\":41679},{\"end\":42007,\"start\":41991},{\"end\":42029,\"start\":42007},{\"end\":42048,\"start\":42029},{\"end\":42063,\"start\":42048},{\"end\":42080,\"start\":42063},{\"end\":42097,\"start\":42080},{\"end\":42115,\"start\":42097},{\"end\":42472,\"start\":42456},{\"end\":42490,\"start\":42472},{\"end\":42502,\"start\":42490},{\"end\":42515,\"start\":42502},{\"end\":42534,\"start\":42515},{\"end\":42545,\"start\":42534},{\"end\":42563,\"start\":42545},{\"end\":42570,\"start\":42563},{\"end\":42585,\"start\":42570},{\"end\":43051,\"start\":43038},{\"end\":43060,\"start\":43051},{\"end\":43071,\"start\":43060},{\"end\":43084,\"start\":43071},{\"end\":43099,\"start\":43084},{\"end\":43111,\"start\":43099},{\"end\":43422,\"start\":43407},{\"end\":43432,\"start\":43422},{\"end\":43440,\"start\":43432},{\"end\":43724,\"start\":43712},{\"end\":43739,\"start\":43724},{\"end\":43753,\"start\":43739},{\"end\":43763,\"start\":43753},{\"end\":44162,\"start\":44151},{\"end\":44174,\"start\":44162},{\"end\":44198,\"start\":44174},{\"end\":44219,\"start\":44198},{\"end\":44652,\"start\":44638},{\"end\":44664,\"start\":44652},{\"end\":44686,\"start\":44664},{\"end\":44700,\"start\":44686},{\"end\":44712,\"start\":44700},{\"end\":45054,\"start\":45040},{\"end\":45070,\"start\":45054},{\"end\":45087,\"start\":45070},{\"end\":45395,\"start\":45382},{\"end\":45409,\"start\":45395},{\"end\":45424,\"start\":45409},{\"end\":45440,\"start\":45424},{\"end\":45457,\"start\":45440},{\"end\":45468,\"start\":45457},{\"end\":45944,\"start\":45927},{\"end\":45961,\"start\":45944},{\"end\":46099,\"start\":46087},{\"end\":46114,\"start\":46099},{\"end\":46131,\"start\":46114},{\"end\":46295,\"start\":46284},{\"end\":46306,\"start\":46295},{\"end\":46316,\"start\":46306},{\"end\":46328,\"start\":46316},{\"end\":46341,\"start\":46328},{\"end\":46564,\"start\":46551},{\"end\":46578,\"start\":46564},{\"end\":46593,\"start\":46578},{\"end\":46893,\"start\":46884},{\"end\":46909,\"start\":46893},{\"end\":46914,\"start\":46909},{\"end\":47194,\"start\":47176},{\"end\":47214,\"start\":47194},{\"end\":47230,\"start\":47214},{\"end\":47248,\"start\":47230},{\"end\":47262,\"start\":47248},{\"end\":47568,\"start\":47554},{\"end\":47578,\"start\":47568},{\"end\":47591,\"start\":47578},{\"end\":47612,\"start\":47591},{\"end\":47619,\"start\":47612},{\"end\":47632,\"start\":47619},{\"end\":47848,\"start\":47837},{\"end\":47861,\"start\":47848},{\"end\":47874,\"start\":47861},{\"end\":47888,\"start\":47874},{\"end\":47902,\"start\":47888},{\"end\":47920,\"start\":47902},{\"end\":48236,\"start\":48226},{\"end\":48249,\"start\":48236},{\"end\":48264,\"start\":48249},{\"end\":48276,\"start\":48264},{\"end\":48289,\"start\":48276},{\"end\":48301,\"start\":48289},{\"end\":48312,\"start\":48301},{\"end\":48572,\"start\":48559},{\"end\":48584,\"start\":48572},{\"end\":48599,\"start\":48584},{\"end\":48611,\"start\":48599},{\"end\":48627,\"start\":48611},{\"end\":49092,\"start\":49078},{\"end\":49111,\"start\":49092},{\"end\":49128,\"start\":49111},{\"end\":49145,\"start\":49128},{\"end\":49481,\"start\":49472},{\"end\":49489,\"start\":49481},{\"end\":49501,\"start\":49489},{\"end\":49513,\"start\":49501},{\"end\":49525,\"start\":49513},{\"end\":49539,\"start\":49525},{\"end\":49832,\"start\":49814},{\"end\":49842,\"start\":49832},{\"end\":49850,\"start\":49842},{\"end\":49867,\"start\":49850},{\"end\":49885,\"start\":49867},{\"end\":49894,\"start\":49885},{\"end\":49909,\"start\":49894},{\"end\":49926,\"start\":49909},{\"end\":49941,\"start\":49926},{\"end\":49960,\"start\":49941},{\"end\":50341,\"start\":50327},{\"end\":50356,\"start\":50341},{\"end\":50370,\"start\":50356},{\"end\":50388,\"start\":50370},{\"end\":50406,\"start\":50388},{\"end\":50864,\"start\":50841},{\"end\":50877,\"start\":50864},{\"end\":50892,\"start\":50877},{\"end\":50908,\"start\":50892},{\"end\":50923,\"start\":50908},{\"end\":50937,\"start\":50923},{\"end\":51281,\"start\":51261},{\"end\":51499,\"start\":51484},{\"end\":51518,\"start\":51499},{\"end\":51537,\"start\":51518},{\"end\":51554,\"start\":51537},{\"end\":51569,\"start\":51554},{\"end\":51583,\"start\":51569},{\"end\":51590,\"start\":51583},{\"end\":52088,\"start\":52079},{\"end\":52098,\"start\":52088},{\"end\":52110,\"start\":52098},{\"end\":52127,\"start\":52110},{\"end\":52141,\"start\":52127},{\"end\":52471,\"start\":52447},{\"end\":52488,\"start\":52471},{\"end\":52730,\"start\":52718},{\"end\":52744,\"start\":52730},{\"end\":52758,\"start\":52744},{\"end\":52769,\"start\":52758},{\"end\":52782,\"start\":52769},{\"end\":52794,\"start\":52782},{\"end\":52805,\"start\":52794},{\"end\":53172,\"start\":53160},{\"end\":53184,\"start\":53172},{\"end\":53196,\"start\":53184},{\"end\":53211,\"start\":53196},{\"end\":53502,\"start\":53495},{\"end\":53518,\"start\":53502},{\"end\":53528,\"start\":53518},{\"end\":53538,\"start\":53528},{\"end\":53551,\"start\":53538},{\"end\":53973,\"start\":53957},{\"end\":53987,\"start\":53973},{\"end\":54290,\"start\":54277},{\"end\":54304,\"start\":54290},{\"end\":54328,\"start\":54304},{\"end\":54341,\"start\":54328},{\"end\":54357,\"start\":54341},{\"end\":54362,\"start\":54357},{\"end\":54824,\"start\":54810},{\"end\":54841,\"start\":54824},{\"end\":54863,\"start\":54841},{\"end\":54874,\"start\":54863},{\"end\":55177,\"start\":55153},{\"end\":55194,\"start\":55177},{\"end\":55202,\"start\":55194},{\"end\":55578,\"start\":55567},{\"end\":55748,\"start\":55732},{\"end\":55754,\"start\":55748}]", "bib_venue": "[{\"end\":43904,\"start\":43842},{\"end\":44360,\"start\":44298},{\"end\":45617,\"start\":45551},{\"end\":50547,\"start\":50485},{\"end\":51711,\"start\":51659},{\"end\":53706,\"start\":53637},{\"end\":54491,\"start\":54435},{\"end\":38758,\"start\":38714},{\"end\":39105,\"start\":39021},{\"end\":39491,\"start\":39363},{\"end\":39936,\"start\":39873},{\"end\":40282,\"start\":40214},{\"end\":40536,\"start\":40446},{\"end\":40976,\"start\":40927},{\"end\":41344,\"start\":41295},{\"end\":41744,\"start\":41692},{\"end\":42142,\"start\":42115},{\"end\":42647,\"start\":42585},{\"end\":43036,\"start\":42960},{\"end\":43492,\"start\":43440},{\"end\":43840,\"start\":43763},{\"end\":44296,\"start\":44219},{\"end\":44764,\"start\":44712},{\"end\":45136,\"start\":45087},{\"end\":45549,\"start\":45468},{\"end\":45925,\"start\":45872},{\"end\":46085,\"start\":46064},{\"end\":46282,\"start\":46231},{\"end\":46637,\"start\":46593},{\"end\":46882,\"start\":46830},{\"end\":47174,\"start\":47113},{\"end\":47552,\"start\":47485},{\"end\":47964,\"start\":47920},{\"end\":48224,\"start\":48156},{\"end\":48731,\"start\":48643},{\"end\":49176,\"start\":49145},{\"end\":49591,\"start\":49539},{\"end\":50000,\"start\":49960},{\"end\":50483,\"start\":50406},{\"end\":50986,\"start\":50937},{\"end\":51296,\"start\":51281},{\"end\":51657,\"start\":51590},{\"end\":52190,\"start\":52141},{\"end\":52524,\"start\":52488},{\"end\":52854,\"start\":52805},{\"end\":53263,\"start\":53211},{\"end\":53635,\"start\":53551},{\"end\":54031,\"start\":53987},{\"end\":54433,\"start\":54362},{\"end\":54926,\"start\":54874},{\"end\":55371,\"start\":55249},{\"end\":55730,\"start\":55605},{\"end\":56295,\"start\":56216},{\"end\":57053,\"start\":56996}]"}}}, "year": 2023, "month": 12, "day": 17}