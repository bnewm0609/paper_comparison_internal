{"id": 227160462, "updated": "2023-03-08 14:31:22.179", "metadata": {"title": "Deep Entity Classification: Abusive Account Detection for Online Social Networks", "authors": "[{\"first\":\"Teng\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Gerard\",\"last\":\"Goossen\",\"middle\":[]},{\"first\":\"Huseyin\",\"last\":\"Cevahir\",\"middle\":[\"Kerem\"]},{\"first\":\"Sara\",\"last\":\"Khodeir\",\"middle\":[]},{\"first\":\"Yingyezhe\",\"last\":\"Jin\",\"middle\":[]},{\"first\":\"Frank\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Shawn\",\"last\":\"Shan\",\"middle\":[]},{\"first\":\"Sagar\",\"last\":\"Patel\",\"middle\":[]},{\"first\":\"David\",\"last\":\"Freeman\",\"middle\":[]},{\"first\":\"Paul\",\"last\":\"Pearce\",\"middle\":[]}]", "venue": "USENIX Security Symposium", "journal": "4097-4114", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Online social networks (OSNs) attract attackers that use abusive accounts to conduct malicious activities for economic, political, and personal gain. In response, OSNs often deploy abusive account classifiers using machine learning (ML) approaches. However, a practical, effective ML-based defense requires carefully engineering features that are robust to adversarial manipulation, obtaining enough ground truth labeled data for model training, and designing a system that can scale to all active accounts on an OSN (potentially in the billions). To address these challenges we present Deep Entity Classification (DEC), an ML framework that detects abusive accounts in OSNs that have evaded other, traditional abuse detection systems. We leverage the insight that while accounts in isolation may be difficult to classify, their embeddings in the social graph\u2014the network structure, properties, and behaviors of themselves and those around them\u2014are fundamentally difficult for attackers to replicate or manipulate at scale. Our system: \u2022 Extracts \u201cdeep features\u201d of accounts by aggregating properties and behavioral features from their direct and indirect neighbors in the social graph. \u2022 Employs a \u201cmulti-stage multi-task learning\u201d (MS-MTL) paradigm that leverages imprecise ground truth data by consuming, in separate stages, both a small number of highprecision human-labeled samples and a large amount of lower-precision automated labels. This architecture results in a single model that provides high-precision classification for multiple types of abusive accounts. \u2022 Scales to billions of users through various sampling and reclassification strategies that reduce system load. DEC has been deployed at Facebook, where it classifies all users continuously, resulting in an estimated reduction of abusive accounts on the network by 27% beyond those already detected by other, traditional methods.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/uss/XuGCKJ0SPFP21", "doi": null}}, "content": {"source": {"pdf_hash": "8d714852f4ef35a410f2de4fb5fddcdcd2992290", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0fed4a67fa9b2b3bd4462351bf8a84643f7605c8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/8d714852f4ef35a410f2de4fb5fddcdcd2992290.txt", "contents": "\nDeep Entity Classification: Abusive Account Detection for Online Social Networks\n\n\nTeng Xu \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nGerard Goossen \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nHuseyin Kerem \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nCevahir Sara \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nKhodeir Yingyezhe \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nJin Frank Li \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nShawn Shan Sagar \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nPatel David \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nFreeman Paul Pearce \nFacebook\nInc University of Chicago Georgia Institute of Technology\n\n\nDeep Entity Classification: Abusive Account Detection for Online Social Networks\n\nOnline social networks (OSNs) attract attackers that use abusive accounts to conduct malicious activities for economic, political, and personal gain. In response, OSNs often deploy abusive account classifiers using machine learning (ML) approaches. However, a practical, effective ML-based defense requires carefully engineering features that are robust to adversarial manipulation, obtaining enough ground truth labeled data for model training, and designing a system that can scale to all active accounts on an OSN (potentially in the billions).To address these challenges we present Deep Entity Classification (DEC), an ML framework that detects abusive accounts in OSNs that have evaded other, traditional abuse detection systems. We leverage the insight that while accounts in isolation may be difficult to classify, their embeddings in the social graph-the network structure, properties, and behaviors of themselves and those around them-are fundamentally difficult for attackers to replicate or manipulate at scale. Our system: \u2022 Extracts \"deep features\" of accounts by aggregating properties and behavioral features from their direct and indirect neighbors in the social graph. \u2022 Employs a \"multi-stage multi-task learning\" (MS-MTL) paradigm that leverages imprecise ground truth data by consuming, in separate stages, both a small number of highprecision human-labeled samples and a large amount of lower-precision automated labels. This architecture results in a single model that provides high-precision classification for multiple types of abusive accounts. \u2022 Scales to billions of users through various sampling and reclassification strategies that reduce system load. DEC has been deployed at Facebook, where it classifies all users continuously, resulting in an estimated reduction of abusive accounts on the network by 27% beyond those already detected by other, traditional methods. the vast majority of abuse[4], but identifying the remaining hard-to-classify accounts-those that closely resemble real users and/or evade OSN defenses-requires fundamentally different and more complex solutions.A critical insight is that while attackers can produce abusive accounts that appear legitimate in isolation, those accounts' embedding in and engagement with the social graph are fundamentally difficult to forge. For example, the number of friend requests sent by a given user is easy for an attacker to control, but the number of friend requests sent by all of that user's friends is outside of the attacker's control. 1 Although attackers can attempt to camouflage their accounts by connecting to legitimate nodes in the graph, this strategy not only is prohibitive to implement at scale, but also creates side effects (e.g., large numbers of rejected friend requests) that are detectable by traditional means.Leveraging this insight, we develop Deep Entity Classification (DEC), 2 a method and supporting system for OSN abusive account detection. Instead of classifying accounts based on \"direct\" features and behaviors, DEC leverages social network structure, extracting more than 20,000 features for each account, by operating across the graph. These features are used to train supervised machine learning models that classify accounts across many different kinds of abuse.The DEC system consists of label generation and feature extraction, as well as model training, deployment, and updating. Ultimately DEC produces per-account abusive classification results that are robust to adversarial iteration (Section 7).The large number of features generated by DEC's graph traversal imposes two challenges in terms of model training. First, if applied na\u00efvely, the large feature space could dramatically increase the underlying model complexity, resulting in poor generalization and degraded performance. Second, obtaining proper generalization across so many features would require a prohibitively large training set in a problem space where high-quality human-labeled data is difficult to obtain at billion-user scale.The second key DEC insight is that in addition to smallscale, high-quality human-labeled data, we can utilize the results of rule-based heuristics as additional \"approximate labels.\" The classifications from such rules are not human reviewed and thus have lower precision than human-reviewed data, but the absolute quantity is much higher.Building on this insight, we design a \"multi-stage multitask learning\" (MS-MTL) framework. Our framework extracts low-dimensional transferable representations via a deep neural network trained using the high-volume approximate labels, then fine-tunes dedicated models given the learned representations and the high-quality human-labeled data.Model training occurs in two separate stages. The firstOther Relevant ML WorkRecent advances in machine learning, especially in graph learning, transfer learning, and online learning, can also be applied to ML-based abusive account detection.\n\nIntroduction\n\nOnline Social Networks (OSNs) connect billions of users around the globe. The largest social network, Facebook, has more than two billion active users sharing content each month [45]. The vast scale of these networks in turn attracts adversaries that seek to exploit the platforms for economic, political, and personal gain. While most OSN activity comes from legitimate users, attackers invest significant resources in signing up fake accounts (i.e., accounts not representative of a real person), creating accounts that impersonate real people, or compromising the accounts of real users. These abusive accounts are used to drive a range of negative behaviors including spam, fake engagement, pornography, violence, and terrorism-all actions which violate community norms [12] and are widely studied forms of abuse [1].\n\nA core challenge faced by OSNs is how to identify and remediate abusive accounts in such a way that is both scalable and precise. Scalability requires approaches that can operate on billions of users and tens of billions of daily actions to detect dozens of different abuse types. Systems that prioritize precision are necessary because abusive accounts are relatively rare [44,45] and thus a drop in precision would lead to the OSN taking errant actions against a large number of benign users.\n\nOSNs use a broad set of techniques ranging from rulebased heuristics [49] to modern machine-learning algorithms [26,48] to classify and remediate abusive accounts at scale. Rule-based heuristics act as a first line of defense [4], identifying basic or common attacker tools, techniques, and resources. These heuristics however lack power: they focus on precision rather than recall, they often do not capture the complexity of account behaviors, and they are by definition reactive [25]. Machine learning systems overcome some of these problems: they generalize from past labeled data in order to improve recall, and they can be iterated on over time to adapt to adversarial evolution [8]. However, precise machine learning systems require a large amount of high-quality labeled ground truth data, can be costly to deploy (in both engineering effort and computational resources), and can be evaded by adversaries who learn how to mimic the appearance of real accounts [17]. Rule-based heuristics and traditional machine learning systems can identify and remediate stage trains a multi-task deep neural network [6] on the collected features using the large number of lower-precision approximate labels. Since accounts identified by these lowerprecision signals exhibit a multitude of different abuse types (e.g., spam, objectionable content, or malware), we formulate a learning \"task\" for each abuse type. We then extract the penultimate layer of the neural network as a low-dimensional feature vector [22]. This vector is input to the second stage of the model, which is trained using per-task high-precision human-labeled data with a standard binary classifier.\n\nMS-MTL allows DEC to learn the underlying common representations of different abuse types in the first model stage, and then to distinguish different abuse types using highprecision data with separate models in the second stage, resulting in a score for each abuse type for each account. In this way we can use a single model to label as \"abusive\" accounts exhibiting any of a multitude of abuse types (e.g., scams, spam, adult content, etc.).\n\nOur DEC design is deployed at Facebook, where it has run in production for more than two years. During that time DEC led to the identification and remediation of hundreds of millions of abusive accounts. By comparing the number of accounts actioned by DEC with an unbiased estimate of the number of abusive accounts remaining on the platform, we infer that DEC is responsible for reducing the volume of abusive accounts by approximately 27%.\n\nIn summary, our contributions include: \u2022 The algorithmic design, system architecture, and implementation of DEC. Extracting more than 20,000 features per entity, across multiple hops, for billions of active users, presents a unique set of systems challenges (Section 4). \u2022 A novel feature extraction process that produces \"deep features\" (Section 5) that, over our evaluation, showed no signs of adversarial adaptation (Section 7.4). \u2022 The MS-MTL classification paradigm, which allows us to use a single model architecture to produce high-precision classifiers for each abuse class (Section 6). \u2022 A quantitative evaluation of DEC and MS-MTL vs. other approaches, as well as a qualitative assessment of the impact DEC has had on the overall state of abusive accounts not caught by other systems (i.e., those hardest to classify) at Facebook (Section 7). \u2022 A discussion of the lessons learned from two years of production deployment at Facebook (Section 8).\n\n\nBackground\n\nHere we present an overview of abusive accounts on OSNs, existing defenses, and relevant machine learning terminology.\n\n\nAbusive Accounts\n\nWe define an abusive account to be any account that violates the written policies of a given OSN (e.g., [12]). Attackers use abusive accounts for various reasons, including for financially motivated schemes (e.g., spreading spam, scams, objection-able content, or phishing links [13][14][15]) and for causing user harm (e.g., online harassment or terrorism [16]). Abusive accounts can be broadly broken down along two dimensions: 1. Account Provenance. An abusive account can be fake, where the account does not represent an actual person or organization, or real, where it is a legitimate user account, though potentially hijacked by an attacker. 3 2. Abusive Behavior. An abusive account can be characterized by the type of abuse it conducts, such as spreading scams or spam.\n\n\nDefenses\n\nThere are multiple types of defenses against abusive accounts on OSNs. Rule-based heuristics, such as rate limits on particular user actions, are straightforward, easy to design and evaluate, and can be quite powerful in practice. However, they are often reactive, permitting some amount of abuse before a threshold is crossed and a rule is triggered. In addition, they conservatively focus on precision rather than recall to avoid false positives. Another large-scale detection technique is machine learning-based classification, which affords increased complexity of the detection algorithm through digesting more features. However, adversaries can adapt (sometimes quickly) in response to classifier actions [10], making it challenging to properly design features that are difficult for adversaries to discover and evade. Another challenge of this approach is to collect enough high-precision training data. Human labeling is typically the most reliable source but can be expensive in terms of time, money, and human effort.\n\nRule-based heuristics and typical machine-learning based classifiers are able to identify the vast majority of abusive activity in online services [4]. Identifying those accounts that are able to evade the primary detection systems presents a especially difficult challenge, as they represent the hardest to classify accounts. For example, such accounts may be those that adversaries have iterated on while adapting to OSN defenses, or they may very closely resemble real users. The system we present in this paper is designed to mitigate these issues by employing sparse aggregated features on the social graph that should be difficult for attackers to manipulate, and by using a multi-stage training framework.\n\n\nMachine Learning Terminology\n\nIn this section we describe the machine learning terminology relevant to DEC.\n\n\nDeep Neural Networks\n\nThe first stage of DEC uses a deep neural network (DNN) architecture [31]. It is a cascade of multiple layers of nonlinear processing units for feature extraction and transformation.\n\nEach successive layer uses the output from the previous layer as input. In deep learning, each layer learns to transform its input data into a slightly more abstract and composite representation, with the last layer outputting a single score.\n\n\nEmbeddings\n\nIn the context of neural networks, embeddings are lowdimensional, continuous, learned vector representations of a discrete feature vector. Neural network embeddings are useful because they can reduce the dimensionality of categorical variables and meaningfully represent categories in the transformed space [28]. A common usage of embeddings is to serve as input features for machine learning models. In each layer of a deep neural network, a low-dimensional vector can be extracted as the embedding of the layer.\n\n\nGradient Boosted Decision Trees\n\nThe embedding of the last layer of deep neural network in DEC's first stage is used as the input feature vector for the second stage of DEC training, which uses a model of gradient boosted decision trees (GBDTs). GBDTs are a machine learning approach that iteratively constructs an ensemble of weak decision tree learners through boosting. It is a widely used algorithm in classification and regression [20].\n\n\nRelated Work\n\nThe problem of detecting abusive accounts in OSNs has received a great deal of attention in the literature. We split the published efforts into three categories based on technique, and also describe the relevant machine learning literature.\n\n\nDetecting Abusive Accounts\n\nSeveral works have explored using graph structure and the features of neighboring nodes to detect abuse. Yang et al. examined the effectiveness of graph and neighbor-based features to identify spammers on Twitter [58]. Their work formalized 24 detection features-including four graph-based and three direct neighbor properties-showing how these features could identify spammers better than prior state-of-the-art solutions [32,49,53]. Our work creates a generalized machinelearning framework (utilizing these features among many others) based on graph, direct, and indirect neighbor features (the \"deep entity\") which scales to billions of social network users.\n\nOther work has focused exclusively on graph structure, with the goal of identifying groups or connected components. Stringhini et al. produced EVILCHORT, a system designed to identify accounts with common networking resources (e.g., IP addresses) and ultimately generate groups of malicious actors [50]. Earlier, Zhao et al. created BotGraph, which creates an activity graph from user actions and uses that graph to identify tightly connected components indicative of abuse [64]. Instead of focusing on the structure of the graph, Nilizadeh et al. observed how spam moved through the graph to identify common propagation patterns [38]. Compared to these works, we focus on a generalized framework which leverages such features, as well as a scalable machine learning approach which is utilized continuously at Facebook.\n\nAn alternative approach uses \"honeypot\" accounts to ultimately yield features which could be used for detection. Stringhini et al. used honeypot Twitter accounts to collect direct account, behavior, and content signals which could be used to identify spammers [49]. Similarly, Lee et al. also used honeypot Twitter and myspace accounts to collect direct account, content, and timing signals, also identifying abuse [32]. The features from both these works were later formalized and further analyzed (along with other features) by Yang et al. [58].\n\n\nSybil Accounts\n\nA Sybil attack refers to an attack where individual malicious users join the OSN multiple times under multiple fake identities. Many algorithms and systems have been proposed to defend against Sybil attacks.\n\nYu [61] conduct a comprehensive study comparing various Sybil defenses on social networks as of 2011. A typical graph theory-based Sybil defense systems is SybilGuard [63]. The protocol is based on the social graph among user identities, where an edge between two identities indicates a humanestablished trust relationship. The key observation is that malicious users can create many identities but few trust relationships. Thus there is a disproportionately small \"cut\" in the graph between the sybil nodes and the honest nodes. However, there are two downsides of SybilGuard: it can allow a large number of sybil nodes to be accepted, and it assumes that social networks are fast mixing, which has not been confirmed in the real world. Yu et al. [62] propose a SybilLimit protocol that leverages the same insight as SybilGuard but offers near-optimal guarantees. Yang et al. claim that sybils do not form tight knit communities, as other work has explored [59]; instead, linkages are formed between sybils and normal users \"accidentally\" and therefore tight linkage-based defenses in isolation are problematic.\n\nSybilInfer, proposed by Danezis and Mittal [9], is another sybil detection system. It uses a probabilistic model of honest social networks and a Bayesian inference engine that returns potential regions of dishonest nodes. SybilRank [5] is a detection framework that has been deployed in Tuenti's operation center. It relies on social graph properties to rank users according to their perceived likelihood of being fake, and has been shown to be computationally efficient and scalable. Wang et al. [54] take a different appproach, instead focusing on user actions as a stream and making the observation that the stream of actions for some types of attacks will be different than that of regular users.\n\nWhile most Sybil defense algorithms and systems focus on exploring connections inside the social graph, this approach may fail to detect some types of abuse such as compromised accounts since they are not distinguishable on the social graph. DEC instead operates by combining information from the social graph with direct user features to conduct general abuse classification, irrespective of Sybil properties.\n\n\nUser Footprint\n\nA \"user footprint\" is a signal that can be used to identify the behaviors of a same user across different OSNs. Malhotra et al. [37] propose the use of publicly available information to create a digital footprint of any user using social media services. This footprint can be used to detect malicious behaviors across different OSN platforms. Xiangnan et al. [29] study the problem of inferring anchor links across multiple heterogeneous social networks to detect users with multiple accounts. The key idea is that if a user is abusive on one platform, they are likely to be abusive on other platforms. However, the user footprint is not helpful when a user is only dedicated to spreading abuse in a single platform, which is the focus of DEC.\n\n\nMachine Learning\n\nIn this section we describe the relevant machine learning works that DEC draws inspiration from.\n\n\nML for Abuse Detection\n\nMachine learning-based classification is widely used in abuse detection. Stein et al. [48] proposed one of the first machine learning frameworks for abuse detection, applied to Facebook in 2011. The system extracts users' behavioral features and trains a machine learning model for classification. A similar spam detection system using content attributes and user behavior attributes has been deployed on Twitter as described by Benevenuto et al. [3]. These efforts laid the groundwork for our \"behavioral\" model described in Section 7.2.\n\nFire et al. [18] propose the use of topological anomalies on the social graph to identify spammers and fake profiles. Their approach uses only four features per user, all of which are related to the degree of graph connection of the user and their friends. The approach is proven to be useful in various OSNs. For DEC we employed a similar approach for feature extraction, however with a greatly expanded feature space.\n\nIn terms of classification algorithms, Tan et al. [51] designed an unsupervised spam detection scheme, called UNIK. Instead of detecting spammers directly, UNIK works by deliberately removing non-spammers from the network, leveraging both the social graph and the user-link graph. In the context of supervised learning, Lin et al. [35] conducted experiments on a Twitter dataset to compare the performance of a wide range of mainstream machine learning algorithms, aiming to identify the ones offering satisfactory detection performance and stability based on a large amount of ground truth data.\n\nGraph learning seeks to learn a node embedding or make predictions using relations in the graph. Variants of the techniques have been applied to modeling social networks [40], object interactions [24], citation networks [27], and abstract data structures in program verification [34]. Perozzi et al. [40] proposed an unsupervised graph learning technique to learn node embeddings using random walks in the local graph. Recent works on graph neural networks (GNNs) [27,33,55] extend convolutional neural networks to perform node classifications. However, none of the existing graph learning approaches has been shown to scale to billions of nodes as in a typical OSN social graph. We are actively experimenting with GNNs for DEC and have encountered numerous technical challenges in getting the system to work on a graph as large and diverse as that of an OSN. Our exploratory work does suggest potential improvements in model performance, but at a much higher computational cost for training.\n\nTransfer learning uses existing pre-trained models or embeddings as a basis for training models for new tasks. The technique is commonly used to improve the performance of ML models (e.g., facial recognition or image segmentation [39,60]), especially in cases where little labeled training data is available. In DEC, we leverage transfer learning to boost our model performance by training the first-stage embedding on a second set of labels.\n\nOnline learning, first proposed by Saad et al. [43], is a technique to tune existing ML classifiers in real time using newly available training data. Classified samples are sent for labeling, which updates the training set to better capture potential adaptive behaviors; retraining then strengthens the classifier against such behaviors [2]. In theory DEC could be adapted to incorporate online learning; however, our human labels are expensive and take a long time to collect, so the benefit of online learning over our current approach of regular offline retraining would be minimal.\n\nActive learning [7,46], similar to online learning, is a technique to retrain the model with new data. In active learning, only the data points in which the model has low confidence are assigned to human labellers for review. This approach is intended to achieve maximum model performance improvement with limited labeling resource. In our work we select accounts at random for expert labelling. While active learning is a potential avenue for improvement, we have been unable to test it because of labeling constraints: random-sample labeling is used not only for training DEC but also for other applications across Facebook, so any active learning experiments would require additional labellers.\n\n\nDEC System Overview\n\nDEC extracts features from active Facebook accounts, classifies them, and then takes actions on the classified abusive accounts. In order to deploy such a system in a scalable way, we need to address multiple challenges, including scalability, latency, variety of abuse types, and false positives. DEC uses multiple components in order to handle these challenges separately. Figure 1 shows the DEC architecture. At the highest level, we break down DEC into online and offline components, discussed subsequently.\n\n\nOnline Component\n\nDEC is triggered by Facebook user actions. When an action occurs, DEC may, based on heuristics (see Section 5.2), schedule a task concurrent with the user activity to start extracting the raw features for the target node and sampled neighboring nodes. For an average account on Facebook, DEC needs to extract hundreds of features for each of hundreds of neighboring nodes, resulting in tens of thousands of raw features to be extracted. Such queries are computationally expensive, and thus the whole process is done asynchronously offline without influencing the user's normal site activity. After feature extraction, DEC aggregates the raw features to form numerical sparse features (further discussed in Section 6). DEC then generates the classification result for the account based on the aggregated features and the in-production model. If the account is classified as abusive, DEC exercises enforcement on the account.\n\n\nOffline Component\n\nThe offline component of DEC includes model training, and feedback handling.\n\nTo classify multiple types of abuse, DEC maintains multiple models, where each model handles a different type of abuse. Each dedicated model is trained on the learned lowdimensional embeddings from the raw features collected as part of the concurrent feature extraction (online component). DEC uses the MS-MTL training framework to simultaneously train and maintain models for different abuse types (further discussed in Section 6).\n\nAs part of our implementation within Facebook, DEC has integrated both human labeling as well as user feedback into the training and enforcement process. Facebook uses a dedicated team of specialists who can label whether an account is abusive. These specialists label accounts both proactively (based on features) and reactively (based on user feedback). For proactive labeling, human labellers check accounts surfaced by various detection signals, take samples, label them, and then take actions accordingly. For the reactive labeling, the process begins when a user appeals an enforcement action (as surfaced through the Facebook product). A human reviewer then investigates the account and either accepts the appeal (false positive from DEC's perspective) or rejects the appeal (true positive). Both proactive and reactive human label results are fed into DEC model training as labeled data. Offline model training uses the human labeled data combined with the extracted features from the online component. After repeated offline and online testing, updated models are deployed into production. DEC is regularly retrained by Facebook to leverage the most recent abuse patterns and signals.\n\nTo summarize, DEC: 1. Extracts \"deep features\" across all active accounts on Facebook to allow classification. 2. Uses classification to predict the level of abusiveness for all active accounts, keeping up-to-date classification results for all users actively engaging with the network. 3. Incorporates user and labeler feedback to iterate classifier models.\n\n\nMethods: Deep Feature Extraction\n\nFeature extraction is a core part of DEC. Compared to traditional abuse detection systems, DEC uses the process of aggregate feature calculations which aims to extract deep features of a \"target\" account.\n\n\nDeep features\n\nIn the context of DEC, \"deep\" refers to the process of fanning out in the social graph. This graph consists of not only users but all entities that the platform supports, such as groups, posts, and more. A direct feature is a feature that is a function of a particular entity only, such as account age or group size. A deep feature is a feature that is a function of the direct features of entities linked to the entity in question. For example, \"average age of an account's friends\" is a deep feature for the account. Deep features can be defined recursively, as aggregations of deep features on linked accounts; for example, a deep feature on a photo could be \"average number of groups joined by friends of people tagged in the photo.\" Deep features are useful for classification because they reveal the position of target node in social graph by looking at neighboring nodes. For instance, in the detection of fake accounts, a common pattern that can be revealed by deep fea- tures is the batch creation of fake accounts. When classifying fake accounts, deep features include the features from the IP address that registers the account, as well as all the other accounts created from the IP address. When classifying using the above features, the scripted activity of batch account registration can be easily detected.\n\nA key insight is that deep features not only give additional information about an account, but also are difficult for adversaries to manipulate. Most direct features can easily be changed by the person controlling the entity. For example, account age is controlled by the account owner, and group membership is controlled by the group admin. In contrast, aggregated features that are generated from entities associated with the target account are much more difficult to change. For example, if we consider the age of all of a user's friends, the mean value would be much more difficult to alter by that user, especially when the number of friends is large. Eventually, we can even take a step further by scrutinizing all the friends of friends, and it becomes almost impossible for an adversary to completely change such information. Table 1 lists some of the entity types considered by DEC, including user, group, device, photo, status update, and group post. For each entity type, we list a few examples of direct features and deep (or fan-out) entities. For direct features, we use features effectively leveraged by other ML classifiers, as well as those found useful during manual investigations. Figure 2 illustrates an example deep feature. This feature is based on neighboring nodes within two hops from an example account (center, color orange). An edge between two nodes represents the relation of mutual friends. This 2-hop deep feature has exponentially more dependent values comprising the feature than a direct feature.\n\n\nImplementation\n\nTo extend the above examples to work in production, we have three issues to address: (a) What kind of neighboring nodes do we look at? (b) How can we generate the deep features meaningfully? and (c) How do we keep the computational cost from exploding as we fan out?\n\nThe complex and varied nature of OSN products requires us to build our system as generically as possible, allowing us to incorporate a wide variety of entities and edges between them. We also want to be able to add new types of entities or edges as Figure 2: Visualization of the level-2 social graph for a single \"target\" account in DEC. The centered orange node is the target node to classify. The blue nodes are the neighboring nodes from the first fan-out level. The red nodes are from the second fan-out level. An edge between two nodes represents the relation of mutual friends. For each node visualized in this graph, hundreds of features are extracted and aggregated for classification.\n\nnew features and products appear on Facebook. In the social graph, even a single pair of entities can be connected with multiple types of edges. For example, a user can be connected to a group by being the admin of the group. They can also be connected through membership, which is a weaker connection. Even further, a user can be connected by commenting on a post from the group.\n\nTo define deep features, we apply aggregation techniques on the set of direct features of nodes, following the lead of Xiao et al. [57], who effectively leveraged aggregated features across clusters of accounts to identify fake ones. As shown in Table 2, we use different aggregation methods for numerical features and categorical features. To aggregate numerical features such as age, we calculate statistics on their distribution such as mean and percentiles. On the other hand, for categorical features such as home country, our strategy is to aggregate them statistically into numerical features. Lastly, we also jointly aggregate numeric features with categorical features by observing the distribution of the numeric features for a given categorical feature. For example, a feature can be the number of accounts that logged in from the same device as the target account, given the device uses the Android operating system.\n\nThe use of aggregation has two advantages: first, it produces a dense feature vector, reducing the dimensionality of the model. Second, it helps the model resist adversarial adaptation as discussed in Section 5.1 above. Note that we do not need to define each deep feature explicitly: we can define var- ious graph traversal steps (e.g., user \u2192 user, or user \u2192 group \u2192 photo) and automatically apply all aggregation methods to all the direct features of the target entity. In practice, this method produces thousands of distinct deep features. Ideally, we would trigger a new feature extraction and classification every time a user action happens on Facebook. This is not possible at billion-user scale given the necessary computational resources. DEC relies on heuristics to decide when to begin the process of feature extraction and (re-)classification. The core idea is the use of a \"cool-down period\" between reclassifications, where the length of the cool-down period increases as the account spends more time active on the platform. Our motivating intuition is that accounts that have been active for longer have gone through many previous checks and are generally less likely to be abusive, while newly registered accounts are more likely to be created to abuse.\n\nWhile (re-)classification is triggered in production in real time, feature extraction and aggregation are computed asynchronously without interfering with an account's experience on Facebook. Given the expense of extracting all deep features, especially for an account with many connections in the social graph, we restrict the amount of computational resources used per account. Specifically, we place a limit on the number of neighboring nodes used to compute a deep feature, and sample randomly if the number is over the limit. The random sample is different on each reclassification; our goal is to capture the position of the entity in the graph from many different angles. This sampling procedure allows us to limit computational cost without reducing the diversity of features. 4 \n\n\nFeature selection\n\nWe only use deep features of a target account, and not direct features, for classification in DEC. The primary motivation for this choice is that we observed that direct target account features are extremely likely to become dominant features in the model. This undesired dominance is caused by the bias inherent in our training data. For example, one of our experimental spam detection models used whether a user posts a URL as a feature; it turns out that this feature easily becomes the dominant one in the model because spammers are much more likely to include URLs in their posts than benign users. However, it creates a huge number of false positives as it classifies almost all users posting URLs as abusive. In addition, direct features are easy for the attacker to manipulate; once the attacker learns that \"has posted URL\" is a feature, they can switch from directly posting URLs to putting URLs as overlay in a photo in order to avoid detection.\n\n\nFeature modification\n\nAs adversaries adapt and as we gain new insights about their behavior, we will wish to add new features to DEC and/or retire poorly performing features to save computation cost. There are two issues to consider when modifying features. The first is the influence on the current detection model. Once we add or remove any feature, the classification result from the original DEC model will be influenced as the model is still trained using the original list of features. Our solution is to split the feature logging into two pipelines: experimental features and production features. We can log (or not log) newly added (or removed) features into the experimental group, from which we can train a new model. Meanwhile, the production classifier still uses the production list of features. When the new model is pushed to production, we switch the experimental feature set into the production pipeline.\n\nA second problem with adding features is the computational cost of re-computing across the entire graph. When we add a new direct feature to an entity A, it not only influences A, but also all the connected entities because they use features from A to calculate their own deep features. Conversely, most direct features have multiple dependent deep features, and multiple levels of fan-out can easily require the recomputation of the whole feature space when a single feature is added. For example, DEC needs to extract new_feature from all of the friends of friends in order to compute 75th percentile, p75(friends.friends.new_feature). Traversing through other features along with friends ultimately results in re-extracting features of any active entity. To limit the impact of the re-computation overhead, we define isolated universes of features. The old and new versions of features will run in parallel universes, with existing models using the old universe of features, until feature generation for the new universe is complete. At that point the functionality of the old universe is subsumed, and it can be discarded as new models will be trained using the new universe of features.\n\nAgain referring to Figure 2, we see the potential computational impact of feature changes. In this example a change or addition of a new direct feature with dependent deep features has exponentially more dependent computations than the direct feature.  Figure 3: MS-MTL model training flow. Stage 1 uses the raw deep features with low precision labels to train a multitask deep neural network. By extracting the embedding from the last hidden layer of the deep neural network, we train dedicated GBDT models for each task in stage 2 with human labeled data.\n\n\nMethods: Multi-Stage Multi-Task Learning\n\nMulti-task learning [6] (MTL) is a type of transfer learning [41] used to improve model generalization. MTL trains multiple related \"tasks\" in parallel using a single neural network model. The core idea is that what the model learns for each task can boost the performance of other tasks. In our context of abusive account classification, we define \"task\" and \"label\" as follows:\n\n\u2022 A task refers to the classification of a specific category of abusive accounts on an OSN (e.g., fake accounts, spamming accounts). \u2022 A label of a training sample is a boolean value indicating whether or not the sample falls into an abusive account category. Each training example has multiple labels, one for each task. This multi-label is represented by a vector of boolean values.\n\nAs a concrete example, if we take four tasks in DEC model training to be classifying fake, compromised, spamming, and scamming accounts, the label vector of one account might be [1, 0, 0, 1]. This vector indicates the account was identified as fake and carrying out scams, but is not identified as compromised or spreading spam.\n\n\nMotivation\n\nWe employ a multi-stage framework to detect abusive accounts on Facebook. Our framework addresses three key challenges in abusive account classification: simultaneously supporting a variety of abuse types, leveraging a highdimensional feature space, and overcoming a shortage (relative to billions of accounts) of high quality human labels.\n\nFirst, since there are many different ways in which an account can be abusive, we use different tasks to represent different sub-types of abuse, and multi-task learning to increase the amount of information encoded in the model. The underlying assumption is that the features distinguishing abusive accounts from benign ones are correlated between abuse types. As a result, the knowledge learned for one abuse type can be beneficial for determining other abuse types because an account exhibiting one abuse type is more likely to show other abusive behaviors. As compared with splitting labeled data based on abuse types and training a separate model for each type, multi-task training gives us a full picture of the account by collectively looking at all associated abusive behavior. We expect that this knowledge sharing across tasks will allow us to achieve better prediction accuracy using multi-task learning, especially for smaller tasks.\n\nSecond, the multi-stage framework addresses the \"curse of dimensionality\" [23] by reducing the high-dimensional raw feature vector to a low-dimensional representation. Specifically, our two stages of training reduce the number of features from more than 10 4 (raw deep feature space) to around 10 2 (learned low-dimensional representation space). We achieve this reduction by using the embedding from the last hidden layer of the multi-task deep neural network as input features for the second stage of training.\n\nFinally, a practical engineering problem is that human labeled data is very expensive, and particularly so in the domain of account labeling. In order to label an account as abusive or benign, a human reviewer needs to look at many aspects of the account and consider multiple factors when making a decision. On the other hand, we have a large amount of lowerconfidence labeled data in the form of machine-generated labels. This scenario is ideal for multi-task leaning as it has proven to be successful to extract useful information from noisily labeled data [52].\n\n\nTraining Data Collection\n\nWe have two sources of data labels on abusive accounts in DEC. The first consists of human reviewers, who are shown hundreds of signals from each account and asked to provide a judgment on whether the account is abusive. Labels provided in this manner have high accuracy, but are also computationally expensive, and therefore can only be obtained in low volume (relative to the billions of accounts on Facebook).\n\nThe second label source consists of automated (non-DEC) algorithms designed to detect abusive accounts, as well as user reported abusive accounts. These algorithms may be focused on a specific attack or abuse type, or may be previous versions of global abuse detection models. We consider the accounts identified by these algorithms to be approximately labeled abusive accounts. We then split the labels into different tasks based on the type of abuse per each account. To obtain approximately labeled non-abusive accounts, we randomly sample accounts that have never been actioned on. Our approximate labels have lower precision than human reviewed data, but are much cheaper to obtain and can be obtained in high volume. For example, in our evaluation the training dataset has over 30 million approximate labels and only 240,000 human labels ( Table 3).\n\nWhile 30 million labels may seem significant, it represents less than 2% of the billions of accounts on Facebook. Thus, any adversary attempting a poisoning attack [21,36,47] on the training data would need to create thousands of accounts in order to ensure that some of them were sampled for our training set as negative examples (and tens of thousands if trying to poison the second stage). On the other hand, the fact that there are millions of negative samples implies that any one account cannot have outsize influence on the model, thus increasing the required attack size even further. Such large attacks are easy for both rule-based systems and human reviewers to detect and label, and thus the adversary's intention of poisioning the training set will be foiled. Furthermore, even if somehow the adversary obtains enough accounts to poison the training process, they will need to manipulate the features on these accounts to produce very specific values, which (as discussed in Section 5.1) is difficult to achieve with our \"deep feature\" architecture.\n\nTo provide insight into the reliability of this approach, we took a random sample of approximately labeled accounts and sent them through the manual review process described previously. In those experiments the approximate labeling precision varied between 90% and 95%, indicating that the approximate labels still provide significant discerning power. Figure 3 shows the two stage training flow of the MS-MTL framework. The first stage, trained on a large volume of low precision data, learns the embedding of the raw features. We then apply a transfer learning techique and use the embedding along with high precision labels to train the second stage model. The classification results are generated as the outputs from the second stage.\n\n\nModel Training Flow\n\n\nFirst Stage: Low Precision Training\n\nThe objective of the first training stage is to reduce the highdimensional vector of aggregated raw deep features to a lowdimensional embedding vector. This dimensionality reduction is done through the training of a multi-task deep neural network model [6] using our approximate label data. Each sample in the training data has a vector of labels where each label corresponds to a task, and each task corresponds to classifica-tion of a sub-type of abusive accounts on Facebook. After the training has converged, we take the outputs of the last hidden layer of the neural network as the learned low-dimensional embeddings.\n\nFor our implementation, we use a neural network model with 3 fully connected hidden layers having 512, 64, and 32 neurons respectively. For each task, the model outputs a probability using a sigmoid activation function. The inputs are normalized using a Box-Cox transformation. We trained the model using PyTorch [42] for an epoch using per-task binary cross entropy and an Adagrad optimizer [11], with a learning rate of 0.01.\n\n\nSecond Stage: High Precision Training\n\nWe leverage a technique from transfer learning [41] and extract the last hidden layer's output from the first stage model as the input for the second stage. We train the second stage (GBDT model) with high precision human-labeled data to classify abusive accounts regardless of the sub-types of violations. The scores output by the GBDT model are the final DEC classification scores.\n\nOur implementation of the GBDT model uses an ensemble of 7 trees with a maximum depth of 4. We trained the model with a company-internal gradient boosting framework similar to XGBoost [56], using penalized stochastic gradient boosting, with a learning rate of 0.03 and a feature sampling rate of 0.2.\n\n\nEvaluation\n\nIn this section we evaluate the performance of our MS-MTL approach and the DEC system as a whole. Specifically we analyze three abusive account models: 1. A behavioral-only model, which represents traditional detection techniques employed by OSNs; 2. DEC as a single multi-task neural network (\"Single Stage,\" SS), and 3. DEC with MS-MTL. We performed our evaluation on active accounts on Facebook. These accounts have already gone through multiple early-stage security systems such as registration or login-time actioning, but have not yet gone through full behavioral (i.e., activity-and content-based) detection. We also investigate adversarial adaptation, in particular looking at the stability of DEC's precision and recall over time. Table 3 summarizes the dataset used for our experiments and evaluation of DEC.\n\n\nDatasets\n\nTraining Data. We test DEC's performance on production Facebook data. We consider four types of abusive accounts (tasks) in our MS-MTL implementation: fake, compromised, spam, and scam. We split the abuse types into these four different categories for two reasons. First, they are violating different policies of Facebook, which causes the detected accounts We maintain separate datasets of approximate (lowerprecision) and human labels. The quantity of approximate labels is significantly larger than human labels. The first training stage uses four approximate datasets of abusive accounts and one of benign accounts, while the second stage requires only human-reviewed accounts labeled as abusive or benign. The approximately labeled data comes from three sources: 1. User reports: Users on Facebook can report other users as abusive. This source is noisy [19], but appropriate as low-precision labels for the first stage of training. 2. Rule-based systems: Outside of DEC, there are other existing enforcement rules on Facebook. We take users caught by these enforcements, categorized by the type of abuse, as an additional approximate label source. Some examples of users labeled by rule-based systems include:\n\n\u2022 Users sending friend requests too quickly;\n\n\u2022 Users with multiple items of content deleted by spamdetection systems; \u2022 Users distributing links to known phishing domains. In total, rule-based systems account for more than half of our abusive account labels. 3. Discovered attacks: It's common to have \"waves\" of scripted attacks on OSNs, such as malware or phishing attacks. When Facebook notices such a wave they can identify a \"signature\" for the accounts involved and use the signature as an approximate label for our first stage. These discovered attacks comprise approximately 10% of our abusive account labels. All of the above sources provide noisy, low-precision abuse data. While inappropriate for full system training, they are apt for the first stage of training. For the first stage, we construct a set of benign users by randomly sampling active users and excluding those contained in approximate abuse dataset.\n\nIn contrast, we generate training data for the second stage by having human labellers employed by Facebook manually review randomly sampled users on the platform. Accounts labeled as abusive are used as positive samples for training, and accounts labeled as benign are negative samples.\n\nEvaluation Data. To evaluate DEC's performance, we create an evaluation dataset of accounts by sampling active users from Facebook. These are users that have already passed through several early-stage abuse detection systems, and as such contain the hardest abusive accounts to classify. We perform manual human labeling of a large number of randomly selected accounts using the same methodology and process that Facebook uses for ground truth measurement. We then randomly select 3 \u00d7 10 4 accounts labeled abusive and 3 \u00d7 10 4 accounts labeled benign for offline evaluation.\n\n\nModel Evaluation\n\nWe use three different models to evaluate the performance of our DEC approach (single stage and with MS-MTL) both in isolation, and in comparison to traditional techniques. Note that the objective of DEC is to identify accounts committing a wide spectrum of abuse types. This approach goes beyond traditional Sybil defense techniques which primarily focus on detecting fake accounts.\n\nA summary of these models, their training data, and their evaluation data can be found in Table 4. The three models we compare are: 1. Behavioral: This GBDT model classifies accounts based only on the direct behavioral features of each account (e.g., number of friends), and outputs whether the account is abusive (regardless of the specific abuse type). Thus, this model does not use deep features and is not multi-task. Since the number of behavioral features is relatively small, we train the model with the human labeled dataset. This model is representative of traditional ML based detection techniques used in OSNs, similar to the system described by Stein et al. [48]. By operating on an evaluation dataset drawn from active accounts on Facebook that have already undergone early-stage remediation, adding this behavioral (later-stage) system is representative of an end-to-end solution. We employ a GBDT architecture with an ensemble of 200 trees of depth of 16, each with 32 leaf nodes. 2. DEC-SS: This model uses the DEC approach outlined in this paper to extract deep features, but does not leverage the MS-MTL learning approach. A single deep neural network model is trained by combining all the approximate data across multiple tasks. If a user is identified as violating by any one of the included tasks, we consider this as a positive sample. Because of the huge number of features extracted by DEC, the quantity of human labeled data is too small to be used for training. 3. DEC-MS-MTL: This is is the complete end-to-end framework and model described in Section 6. It combines the DEC-only approach with MS-MTL. Outside of this evaluation section, references to DEC without a MS-MTL or SS qualifier refer to DEC MS-MTL.\n\n\nPerformance Comparisons\n\nWe compare various metrics based on the results of above three models. Figure 4 examines the ROC performance of all three models. ROC curves capture the trade-off in a classifier between false positives and false negatives. For all operating points on the curve, the DEC models (both MS-MTL and SS) perform significantly better than a behavioral-only approach-by as much as 20%, depending on the operating point. From a ROC perspective, both DEC models perform similarly.\n\n\nROC Curves\n\nWhile ROC curves are important measures of the effectiveness of models, they are inherently scaleless, as the x-axis considers only ground-truth negatives and the y-axis considers only ground-truth positives. If the dataset is being classified is imbalanced, as is the case with abusive accounts (there are significantly more benign accounts than abusive accounts), ROC curves may not capture the actual operating performance of classification systems-particularly precision, a critical measure in accessing abuse detection systems. Figure 5 compares the precision and recall of the models. We find the behavioral model is unable to obtain precision above 0.95 and has very poor recall throughout the precision range. Both DEC models perform significantly better than the behavioral model, being able to achieve a higher precision and have significantly higher recall at all relevant operating  Figure 5: Comparison of precision vs recall curves for different models on our evaluation data. Both DEC models perform significantly better than the behavioral model, and the DEC-MS-MTL has higher recall across the entire operating space. This evaluation is over accounts that have already gone through several stages of security evaluation, and as such this population represents the hardest accounts to classify. Given the difficult classification nature of this sub-population, such recall performance is considered excellent by Facebook.\n\n\nPrecision and Recall\n\nregions. DEC with MS-MTL significantly improves the system recall over single stage DEC at high precision operating points, improving by as much as 30%. We note that this evaluation is over accounts that have already gone through other security classifications such as registration time or login-time remediation (i.e., the hardest to classify accounts). As such, the overall recall level is expected to be lower than that of a system which operates on all active accounts (Section 7.4).\n\nDEC with MS-MTL's improvement in recall over behavioral models makes it particularly attractive in a real world operating environment where recall over hard to classify accounts is an important operating characteristic.\n\n\nQuantiative Assessment: Area Under the (AUC)\n\nCurve and Precision / Recall Table 5 shows a comparison of precision, recall, and ROC performance between the three models. ROC performance is calculated as the total area under the curve (AUC). Precision is fixed at 0.95, a common operating point for assessing performance. The behavioral model is unable to achieve a precision of 0.95 at any recall, and is excluded. We find that while \n\n\nResults In Production Environment\n\nBuilding on our design and evaluation of DEC (with MS-MTL), we deployed the system into production at Facebook.\n\nThe system not only identified abusive accounts, but also triggered user-facing systems to take action on the accounts identified. To assess the model's real-world impact and longevity, we evaluate our system in production by looking at the stability of precision and recall over time.\n\nPrecision Over Time. Figure 6 examines the 3-day moving average of the precision of our DEC with MS-MTL system in production at Facebook. As with our prior evaluation, we obtain ground truth for our measurements by relying on manual human labeling of a random sample of accounts classified as abusive by DEC. We find that the precision of the system is stable, with the precision never dropping below 0.97, and frequently being higher than 0.98.\n\nRecall Over Time. We examine the stability of our production DEC-MS-MTL model's recall by considering its false negative rate (FNR), where FNR = 1\u2212recall. Using a longitudinal sample of 2 \u00d7 10 4 users randomly chosen and manually labeled each day, we compute an unbiased FNR statistical measure of the volume of abusive accounts on Facebook, regardless of direct detection. This measure is denoted as the \"prevalence\" of abusive accounts and can be thought of as the false negative rate of all abusive account detection systems (including DEC) combined. If we add to the prevalence measurement the number of abusive accounts caught by DEC  Figure 7 plots the observed prevalence of abusive accounts (with DEC deployed) and inferred prevalence without DEC, over the period of a month. A loss in DEC's recall (equivalently, an increase in DEC's FNR) would manifest as either an increase in overall abusive account prevalence, or a decrease in the power of DEC compared to non-DEC methods (a decrease in the difference between the two measures). We observed neither of these phenomena over our one-month experiment, indicating that DEC's recall did not meaningfully shift during this period and suggesting that there was not adversarial adaptation to DEC.\n\nBefore DEC's launch, Facebook reported instances of adversaries adapting within hours to new detection systems; since the advent of DEC there have been no such reports. Our hypothesis is that the \"deep feature\" architecture of DEC makes the system more resistant to adversarial adaptation than other abusive account detection systems. As discussed in Section 5.1, an adversary wishing to manipulate a user feature aggregated through the graph must control that feature on all of the relevant entities connected to the original user. When we apply this reasoning to the multitude of different entity associations -including but not limited to user friendship, group membership, device ownership, and IP address appearance -we are drawn to the conclusion that manipulating many such features would be far more expensive for an attacker than manipulating \"direct\" user features such as country, age, or friend count.\n\nSince deployment, DEC has become one of the key abusive account detection systems on Facebook, where it has been responsible for the identification and deactivation of hundreds of millions of accounts. Over our evaluation period the average estimated prevalence without DEC would have been 5.2%, while the average observed volume of abusive accounts  DEC Over All Accounts. Our evaluation of DEC thus far has focused on the hardest types of abuse to classify-accounts that were not identified by other production abuse detection systems. A separate question is how effective could DEC be at identifying all abusive accounts, including those caught by these other systems. To answer this question we evaluated DEC over 1.6 \u00d7 10 4 active accounts sampled at random from the entire population of accounts on Facebook, including those that had been detected as abusive by other systems. These accounts were definitively labeled by expert human labellers and used as ground truth for our evaluation. Table 6 shows the performance of DEC across this population of all accounts. DEC performs well over this population, with an AUC of 0.981, recall at precision 0.95 of 0.981 and recall at precision 0.99 of 0.955. As expected, both the AUC and recall at fixed precision are significantly higher on the full population than on the sub-population of accounts not detected by other systems (Table 5).\n\n\nReducing Computational & Human Load\n\nIt is computationally expensive to extract graph features for all active users at the scale of Facebook. Given our current implementation of feature extraction within two hops from the target node in graph, for each user we might need to reach out to hundreds or thousands of neighboring nodes in order to extract all of their information and aggregate it back to the target node. To mitigate this problem we have developed caching strategies that reuse previous feature extraction results as much as possible. However, because many features have time sensitivity, we still need to update and re-extract a considerable amount of them at each reclassification. The computational load of DEC is high-equivalent to 0.7% of global CPU resources of Facebook. However, the deployment of DEC actually reduced global CPU usage of Facebook. DEC achieved this counter-intuitive result by identifying and removing such a large volume of abusive accounts that the combined CPU usage of those abusive accounts more than accounted for the computation required for feature extraction, training, and deployment of DEC.\n\nDEC also greatly reduced human costs, in terms of human review resources that would have been needed to evaluate and take down abusive accounts manually. DEC's deployment reduced the total review resources needed for abusive account detection by between 15% and 20%.\n\n\nSegmentation and Fairness\n\nOne key finding is that a single-task classifier performs differently across different segments within the task. For example, if we segment accounts by the self-reported age of their owners, an abusive account classifier might show a higher false positive rate on one age segment than others. Similarly, the performance might vary over different geographies, as we are building a single model to fit a global product that may be used differently across different cultures. Such variation, which can be expected across such a large and heterogenous user base, may be interpreted as the model treating some groups of people unfairly relative to others. 5 In the data set used for this paper we were not able to find any segments on which classifier performance differed to a statistically significant extent, but it is possible that with retraining and/or different segmentation such unfairness may arise. As a result, we have proactively considered several measures to reduce variation across different segments.\n\nOur key insight is that segmentation effects are highly correlated with bias in the training data. Suppose for example that we use the account owner's age as a feature, and that the owners of abusive samples in the training data are younger on average the owners of non-abusive samples. In this case, if we do not adjust the proportions of different segments in our training data, the classifier may reach the conclusion that accounts owned by young people are more likely to be abusive.\n\nAs a first step towards preventing such bias, we have removed from the model all \"direct\" user demographic features, including age, gender, and country. While these features could be helpful in predicting abuse, they could easily introduce unfairness in the model as in the age example above -we don't want to penalize younger benign users just because attackers usually choose to set their fake accounts to have a young age.\n\nThe next approach we considered is to sample the labeled data in order to create a training set that reflects overall OSN distributions as closely as possible. In ongoing work, we are experimenting with training DEC using stratified sampling based on attack clustering, in particular downsampling large clusters so as to minimize the influence of a single attack on the ultimate model. This approach would make sure that a large attack from a given user demographic does not teach the model that most users from that demographic are abusive. However, stratified sampling becomes prohibitively costly as we try to match the distribution of more and more segments. In addition, as we add more dimensions the segments get smaller, and statistical noise soon introduces enough error to outweigh the precision gains from sampling.\n\nA final approach is to split particular segments out and create dedicated tasks in the MS-MTL framework for them; however, this approach requires us to collect sufficient training data for each segment, and the maintenance cost increases with the number of models trained. Instead of training and maintaining multiple models, Facebook has chosen to monitor specific high-profile segments for false positive spikes and address any issues by tuning the overall model to reduce segment-specific false positives.\n\n\nMeasuring in an Adversarial Setting\n\nSince abuse detection systems inherently operate in an adversarial environment, measuring the impact of system changes is a particularly difficult problem. A common adversarial iteration looks like: 1. The attacker finds a successful method to abuse Facebook. 2. Facebook adjusts its detection system and mitigates the attack. 3. The attacker iterates until they either achieve (1) again, or the resource cost becomes too high and they stop. Assuming constant effort on the part of the attacker and Facebook, the above cycle eventually settles on an equilibrium. Because of this cycle, it is difficult to properly measure the effect of our models using A/B tests during deployment. If our experiment group is too small, we never reach step 3 because the attacker has no incentive to change. Our metrics might look good in the experiment group, but we will hit step 3 when we launch more broadly and performance will decline.\n\nOne way to mitigate this problem is to add a \"holdout group\" to feature launches. The holdout group is a random sample of users that are predicted by the model to be abusive.\n\nInstead of acting to block these accounts immediately upon detection, we stand back and confirm the abuse happened as expected before enforcing on these users. Such holdouts help us to more accurately measure the precision of our classifier, but must be carefully weighed against the potential impact, as holdouts can lead to further abuse. For this reason, holdouts are not used for all types of abuse.\n\n\nAdversarial Attacks on DEC\n\nAn attacker may attempt to poison the first stage of lowquality labels by creating numerous colluding accounts that seek to be labelled benign by the rule-based detection systems. Given the scope of DEC's training data and the relatively low sample rate, it would be extremely difficult for attackers to generate such accounts at a scale that would significantly impact the trained model (Section 6.2), especially given that other (non-DEC) systems exist specifically to limit the creation of fake accounts at massive scale.\n\nAn attacker may attempt to evade the classifier by creating large groups of fake accounts connected to each other so that they can control all of the deep features. This subgraph would have to either be isolated from the rest of the friend graph (which is itself suspicious) or have a reasonable number of connections to the main graph. In the latter case, since DEC operates on second-order connections, almost all of the DEC features would include data from real accounts outside the adversary's control. In addition, while the adversary controls the fake accounts' behavior, they don't know how a similar set of connected legitimate users behaves, and the coordinated activity of the fake accounts would be detected as anomalous by DEC.\n\nAn attacker could also attempt to trick DEC into misclassifying a benign user as abusive, based on features of its neighbors that the victim has no control over. For example, an attacker could create a subgraph of abusive accounts as above and attempt to friend a victim using these accounts. If the victim accepts one or more friend requests, they embed themselves in the abusive sub-graph, which could cause DEC to incorrectly act on the victim. This \"forced-embedding\" attack is also challenging to execute. First, \"attempted\" links between entities (e.g., unresolved or denied friend requests) are not features in DEC. Second, a single bad edge between the victim and an abusive sub-graph is insufficient to cause a false classification. A victim would need to be deceived numerous times for there to be a risk of misclassification. Finally, DEC-identified accounts are given the opportunity to complete challenges or request human review as a fail-safe to guard against incorrect classification [30].\n\n\nLimitations and Future Directions\n\nWhile DEC has been highly effective at detecting abusive accounts in practice, its design offers several opportunities for improvement: \u2022 DEC is computationally expensive, particularly due to its use of deep features. However, in Section 8.1 we discussed how this high computational cost is actually balanced by resource savings from identifying more abusive accounts. Reducing the computational cost further is an active area of work that is receiving at least as much attention as improving model quality.\n\n\u2022 Intuitively, DEC's classifications are based on an account's position and connections within the Facebook graph. Accounts that exhibit low levels of activity or connections provide fewer signals for DEC to leverage for inference, limiting its effectiveness. However, even if such accounts are abusive, they inherently have less impact on Facebook and its users. We are currently exploring approaches to include features that better capture these low-signal accounts. \u2022 DEC's machine learning model lacks interpretability, as it relies on a DNN to reduce the high-dimensional space of deep features into the low-dimension embedding used for classification decisions. This characteristic makes it difficult to debug and understand the reasoning behind DEC's decisions. Making the model interpretable is an active area of research. \u2022 DEC's approach of aggregating data from many users to produce features for classification is less sensitive to outliers than an approach of using direct features. As a consequence, DEC may be less discriminative of extreme feature values than other model families. We have taken a \"defensein-depth\" approach to address this challenge, as extreme outliers can be captured quite effectively by manual rules. It still remains an open question to address such outliers within the DEC framework. \u2022 DEC, like other supervised or semi-supervised machine learning systems, is heavily dependent on the quality of its training data labels. Adversaries that manage to induce inaccurate human labeling at scale may be able to manipulate or interfere with DEC's classifications. We are constantly working to improve our labeling process to address any observed or potential limitations.\n\nEven with these limitations, our evaluation on production data at Facebook indicates that DEC offers better performance than traditional detection approaches.\n\n\nConclusion\n\nWe have presented Deep Entity Classification (DEC), a machine learning framework developed to detect abusive accounts in OSNs. Our framework addresses two problems in the existing abuse detection systems: First, its \"deep feature\" extraction method creates features that are powerful for classification and (thus far) show no signs of the adversarial adaptation typical for account or behavioral features. Second, it uses a novel machine learning training framework to leverage both high-quantity, low-precision and low-quantity, high-precision training data to improve model performance.\n\nOur evaluation on production data at Facebook indicates that DEC offers better performance than traditional detection approaches. Moreover, DEC's performance is stable over time, suggesting that it is robust to adversarial adaptation. During DEC's deployment for more than two years at Facebook, it has detected hundreds of millions of abusive accounts. We estimate that DEC is responsible for a 27% reduction in the volume of active abusive accounts on the platform.\n\nFigure 1 :\n1DEC system overview. When an user action occurs on Facebook, the online component will, concurrent with user activity, classify and potentially begin remediation on the user and/or action. Meanwhile, the extracted features from the online component, together with the training data, are used by the offline component to train new models.\n\nFigure 4 :\n4Comparison of ROC curves for different models on evaluation data. Both DEC models (single stage and with MS-MTL) perform significantly better than the behavioral model at all points in the curve.\n\nFigure 6 :\n6Precision over time: 3-day moving average of deployed (DEC-MS-MTL) model precision on live Facebook production data, spanning one month. Precision is stable, never decreasing below 0.97. The y-axis is truncated. specifically (and not other detection systems), we obtain an estimate of what the prevalence of abusive accounts would have been in the absence of DEC.\n\nFigure 7 :\n7Recall over time: DEC defense over a 30-day window, using 3-day moving averages. The green line is the observed volume (as a percent) of abusive accounts on Facebook, and the red marked line is the volume of accounts taken down by DEC. The blue line is the sum of the other two and estimates what the volume of abusive accounts would have been in the absence of DEC; the gray shaded area thus represents the inferred impact of DEC.\n\nTable 1 :\n1Types of entities with their example direct features and example deep entities in DEC.Entity Type \nDirect Features \nDeep Entities \n\nUser \nage, gender \nentities administered, posts \nGroup \nmember count, age \nadmins, group members \nDevice \noperating system \nusers sharing the device \nPhoto \nlike count, hash value \nusers in the photo \nStatus Update \nlike count, age \ngroups it shared to \nGroup Post \nhas a link? \nusers commenting \nShare \nnumber of times shared original creator \nIP Address \ncountry, reputation \nregistered accounts \n\n\n\nTable 2 :\n2Example aggregation methods for deep features. Here p25 and p75 refer to the 25th and 75th percentiles, respectively.Feature Type \nAggregation Method \n\nNumeric \nmin, max, mean, variance, p25, p75 \n\nCategorical \npercentage of the most common category, \npercentage of empty values, \nentropy of the category values, \nnumber of distinct categories \n\nBoth Numeric & \nmax of numeric A from category B, \nCategorical \np75 of numeric A from most common category \n\n\n\n\nLow Precision Multi-LabelVector [Fake? Compromised? ... Spam?] Results [Fake Score, Compromised Score ... Spam Score]Deep Features \n(>2*10 4 ) \n\nGBDT \nFake \nLabel \nGBDT \n\nCompromised \nLabel \n\nGBDT \nSpam \nLabel \n\nStage 1 \n\nStage 2 \n\nApproxi-\nmate \nData \n\nHuman \nLabelled \nData \n\nDeep Neural Network \n\nInput \nLayer \n\nHidden \nLayer \n\nHidden \nLayer \n\nOutput \nLayer \n\nEmbedding \n\n\n\nTable 3 :\n3Datasets: Number and composition of labels used for our training and evaluation. The longitudinal dataset is measured in # of samples per day.Training \nDataset \nLabel Type \nTraining \nStage \n# Samples \n\nFake \nApproximate \nFirst \n3.0 \u00d7 10 7 \nComp. \nApproximate \nFirst \n7.8 \u00d7 10 5 \nSpam \nApproximate \nFirst \n6.2 \u00d7 10 5 \nScam \nApproximate \nFirst \n6.2 \u00d7 10 5 \nBenign \nApproximate \nFirst \n2.6 \u00d7 10 8 \nAbusive \nHuman \nSecond \n1.2 \u00d7 10 5 \nBenign \nHuman \nSecond \n1.2 \u00d7 10 5 \nEvaluation \nDataset \nLabel Type \nEvaluation \nMechanism \n# Samples \n\nAbusive \nHuman \nOffline \n3.0 \u00d7 10 4 \nBenign \nHuman \nOffline \n3.0 \u00d7 10 4 \nLongitudinal \nHuman \nOnline \n2.0 \u00d7 10 4 /day \n\nto be actioned on by separate enforcement systems, each em-\nploying distinct appeals flows. Second, the positive samples \nof different abuse types are not homogeneous by nature. For \nexample, fake accounts are largely driven by scripted creation, \nwhile compromised accounts usually result from malware or \nphishing. The behavioral patterns and social connections of \nthese accounts are distinctive for each abuse type, lending \nthemselves well to different \"tasks\" in our formulation. \n\n\nTable 4 :\n4Comparisons of the three evaluation models' type, training features, training data, and evaluation data.Name \nModel \nTraining Features \nTraining Data \nEvaluation Data \nBehaviorial \nGBDT \nAccount behavior features (\u223c 10 2 ) \nHuman labels \nHuman labels \nDEC-SS \nMulti-Task DNN \nDEC deep features (\u223c 10 4 ) \nApproximate labels \nHuman labels \nDEC-MS-MTL Multi-Task DNN + GBDT \nDEC deep features (\u223c 10 4 ) \nApproximate labels+human labels \nHuman labels \n\n\n\nTable 5 :\n5Comparison of the area under the curve (AUC) and \nrecall at precision 0.95 for different models on evaluation data. \nThe DEC with MS-MTL model achieves the best result by a \nsignificant margin, a nearly 30% absolute improvement. The \nbehavioral model is unable to obtain precision 0.95. \n\nModel \nAUC Recall @ Precision 0.95 \nBehavioral \n0.81 \nNA \nDEC-SS \n0.89 \n0.22 \nDEC-MS-MTL 0.90 \n0.50 \n\nDEC both single stage and with MS-MTL have similar AUC \nperformance, adding MS-MTL more than doubles the model \nrecall, increasing it from 22% to 50%. This increased perfor-\nmance, both over behavioral and over DEC without MS-MTL, \nenables significantly better real-world impact when deployed \nin production. \n\n\n\nTable 6 :\n6Area under the curve (AUC) and recall at precisions 0.95 and 0.99 for DEC over a random sample of all accounts on Facebook.Population AUC Recall @ Prec. 0.95 Recall @ Prec. 0.99 \nAll accts. \n0.981 \n0.981 \n0.955 \n\non Facebook was 3.8%-an improvement of 27%. \n\n\nSee Section 8.4 for consideration of the case where attacker creates groups of abusive accounts that are connected to each other.2 In this context \"deep\" refers to the features generated via network fanout from each account, not neural network structure.\nReal user accounts that violate OSN policies without having been compromised are outside the scope of this work, as they are relatively small in volume and are actioned on by other systems.\nIn our implementation, we use up to 50 neighboring nodes to compute a deep feature, downsampling if the number of neighboring nodes exceeds that threshold. On average, two fan-out levels of neighboring entities are used for feature computations.\nDiscussion and Lessons LearnedAfter more than two years of deployment at Facebook, we have learned multiple lessons and identified several limitations from developing and using DEC.\nNote that the assessment of \"fairness\" will depend on the metric used, and one may get different results when using, for example, accuracy vs. precision vs. false positive rate.\nAcknowledgementsMany individuals at Facebook contributed to the development of DEC and to this publication. Among them we would like to thank Daniel Bernhardt, Scott Renfro, Vishwanath Sarang, and Gregg Stefancik.We would also like to thank the anonymous reviewers for their valuable feedback that substantially improved this work's quality.\nGraph based anomaly detection and description: A survey. Leman Akoglu, Hanghang Tong, Danai Koutra, Data mining and knowledge discovery. 29Leman Akoglu, Hanghang Tong, and Danai Koutra. Graph based anomaly detection and description: A sur- vey. In Data mining and knowledge discovery, vol- ume 29, pages 626-688, 2015.\n\nOnline bandit learning against an adaptive adversary. Raman Arora, Ofer Dekel, Ambuj Tewari, arXiv:1206.6400From regret to policy regret. arXiv preprintRaman Arora, Ofer Dekel, and Ambuj Tewari. Online bandit learning against an adaptive adversary: From regret to policy regret. arXiv preprint arXiv:1206.6400, 2012.\n\nDetecting spammers on Twitter. Fabricio Benevenuto, Gabriel Magno, Tiago Rodrigues, Virgilio Almeida, Collaboration, electronic messaging, anti-abuse and spam conference (CEAS). 612Fabricio Benevenuto, Gabriel Magno, Tiago Rodrigues, and Virgilio Almeida. Detecting spammers on Twitter. In Collaboration, electronic messaging, anti-abuse and spam conference (CEAS), volume 6, page 12, 2010.\n\nHow to successfully harness AI to combat fraud and abuse. Elie Bursztein, RSAElie Bursztein. How to successfully har- ness AI to combat fraud and abuse. https: //elie.net/talk/how-to-successfully- harness-ai-to-combat-fraud-and-abuse/, 2018. RSA.\n\nAiding the detection of fake accounts in large scale social online services. Qiang Cao, Michael Sirivianos, Xiaowei Yang, Tiago Pregueiro, USENIX NSDI. Qiang Cao, Michael Sirivianos, Xiaowei Yang, and Tiago Pregueiro. Aiding the detection of fake accounts in large scale social online services. In USENIX NSDI, pages 15-15, 2012.\n\nMultitask learning. Rich Caruana, Machine learning. Springer28Rich Caruana. Multitask learning. In Machine learning, volume 28, pages 41-75. Springer, 1997.\n\nActive learning with statistical models. Zoubin David A Cohn, Michael I Jordan Ghahramani, Journal of artificial intelligence research. 4David A Cohn, Zoubin Ghahramani, and Michael I Jor- dan. Active learning with statistical models. Journal of artificial intelligence research, 4:129-145, 1996.\n\nAdversarial classification. Nilesh Dalvi, Pedro Domingos, Sumit Sanghai, Deepak Verma, SIGKDD conference on knowledge discovery and data mining (KDD). ACMNilesh Dalvi, Pedro Domingos, Sumit Sanghai, Deepak Verma, et al. Adversarial classification. In SIGKDD conference on knowledge discovery and data mining (KDD), pages 99-108. ACM, 2004.\n\nSybilinfer: Detecting sybil nodes using social networks. George Danezis, Prateek Mittal, NDSS. George Danezis and Prateek Mittal. Sybilinfer: Detect- ing sybil nodes using social networks. In NDSS, pages 1-15, 2009.\n\nFollowing their footsteps: Characterizing account automation abuse and defenses. Louis Dekoven, Trevor Pottinger, Stefan Savage, Geoffrey Voelker, Nektarios Leontiadis, Internet Measurement Conference (IMC). ACMLouis DeKoven, Trevor Pottinger, Stefan Savage, Geof- frey Voelker, and Nektarios Leontiadis. Following their footsteps: Characterizing account automation abuse and defenses. In Internet Measurement Conference (IMC), pages 43-55. ACM, 2018.\n\nAdaptive subgradient methods for online learning and stochastic optimization. John Duchi, Elad Hazan, Yoram Singer, Journal of machine learning research. 12John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(Jul):2121-2159, 2011.\n\n. Facebook, Facebook.com. https://www.facebook.com/ communitystandards/, 2019.\n\n. Facebook, Facebook.com. https://www.facebook.com/help/ 287137088110949, 2019.\n\n. Facebook, Facebook.com. https://www.facebook.com/help/ 166863010078512?helpref=faq_content, 2019.\n\n. Facebook, Facebook.com. https://www.facebook.com/ communitystandards/objectionable_content, 2019.\n\n. Facebook, Facebook.com. https://www.facebook.com/ communitystandards/safety, 2019.\n\nAnalysis of classifiers' robustness to adversarial perturbations. Alhussein Fawzi, Omar Fawzi, Pascal Frossard, Machine learning. Springer107Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. Analysis of classifiers' robustness to adversarial per- turbations. In Machine learning, volume 107, pages 481-508. Springer, 2018.\n\nStrangers intrusion detection: Detecting spammers and fake profiles in social networks based on topology anomalies. Michael Fire, Gilad Katz, Yuval Elovici, Human journal. 1Michael Fire, Gilad Katz, and Yuval Elovici. Strangers intrusion detection: Detecting spammers and fake pro- files in social networks based on topology anomalies. In Human journal, volume 1, pages 26-39, 2012.\n\nCan you spot the fakes?: On the limitations of user feedback in online social networks. Freeman David Mandell, Proceedings of the 26th International Conference on World Wide Web. the 26th International Conference on World Wide WebDavid Mandell Freeman. Can you spot the fakes?: On the limitations of user feedback in online social net- works. In Proceedings of the 26th International Confer- ence on World Wide Web, pages 1093-1102, 2017.\n\nGreedy function approximation: A gradient boosting machine. H Jerome, Friedman, Annals of statistics. Jerome H Friedman. Greedy function approximation: A gradient boosting machine. Annals of statistics, pages 1189-1232, 2001.\n\nBadnets: Identifying vulnerabilities in the machine learning model supply chain. Tianyu Gu, Brendan Dolan-Gavitt, Siddharth Garg, arXiv:1708.06733arXiv preprintTianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. Badnets: Identifying vulnerabilities in the ma- chine learning model supply chain. arXiv preprint arXiv:1708.06733, 2017.\n\nReducing the dimensionality of data with neural networks. E Geoffrey, Hinton, R Ruslan, Salakhutdinov, In Science. 313Geoffrey E Hinton and Ruslan R Salakhutdinov. Reduc- ing the dimensionality of data with neural networks. In Science, volume 313, pages 504-507, 2006.\n\nApproximate nearest neighbors: Towards removing the curse of dimensionality. Piotr Indyk, Rajeev Motwani, ACM symposium on theory of computing. ACMPiotr Indyk and Rajeev Motwani. Approximate nearest neighbors: Towards removing the curse of dimensional- ity. In ACM symposium on theory of computing, pages 604-613. ACM, 1998.\n\nStructural-RNN: Deep learning on spatio-temporal graphs. Ashesh Jain, Silvio Amir R Zamir, Ashutosh Savarese, Saxena, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionAshesh Jain, Amir R Zamir, Silvio Savarese, and Ashutosh Saxena. Structural-RNN: Deep learning on spatio-temporal graphs. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5308-5317, 2016.\n\nSuspicious behavior detection: Current trends and future directions. Meng Jiang, Peng Cui, Christos Faloutsos, IEEE intelligent systems. IEEE31Meng Jiang, Peng Cui, and Christos Faloutsos. Suspi- cious behavior detection: Current trends and future di- rections. In IEEE intelligent systems, volume 31, pages 31-39. IEEE, 2016.\n\nA data mining-based spam detection system for social media networks. Xin Jin, Jiebo Lin, Jiawei Luo, Han, Proceedings of the VLDB endowment. the VLDB endowment4Xin Jin, C Lin, Jiebo Luo, and Jiawei Han. A data mining-based spam detection system for social media networks. In Proceedings of the VLDB endowment, volume 4, pages 1458-1461, 2011.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, arXiv:1609.02907arXiv preprintThomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016.\n\nEmbeddings in neural network. W Koehrsen, W. Koehrsen. Embeddings in neural network.\n\nInferring anchor links across multiple heterogeneous social networks. Xiangnan Kong, Jiawei Zhang, Philip S Yu, International conference on information & knowledge management. ACMXiangnan Kong, Jiawei Zhang, and Philip S Yu. Infer- ring anchor links across multiple heterogeneous social networks. In International conference on information & knowledge management, pages 179-188. ACM, 2013.\n\nA method for evaluating changes to fake account verification systems. Fedor Kozlov, Isabella Yuen, Jakub Kowalczy, Daniel Bernhardt, David Freeman, Paul Pearce, Ivan Ivanov, RAID. Fedor Kozlov, Isabella Yuen, Jakub Kowalczy, Daniel Bernhardt, David Freeman, Paul Pearce, and Ivan Ivanov. A method for evaluating changes to fake account verifi- cation systems. In RAID, 2020.\n\nDeep learning. In Nature. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, 521436Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. In Nature, volume 521, page 436, 2015.\n\nUncovering social spammers: Social honeypots + machine learning. Kyumin Lee, James Caverlee, Steve Webb, Conference on Research and Development in Information Retrieval (SIGIR). Kyumin Lee, James Caverlee, and Steve Webb. Un- covering social spammers: Social honeypots + machine learning. In Conference on Research and Development in Information Retrieval (SIGIR), 2010.\n\nDeeper insights into graph convolutional networks for semisupervised learning. Qimai Li, Zhichao Han, Xiao-Ming Wu, Thirty-Second AAAI Conference on Artificial Intelligence. Qimai Li, Zhichao Han, and Xiao-Ming Wu. Deeper insights into graph convolutional networks for semi- supervised learning. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.\n\nGated graph sequence neural networks. Yujia Li, Daniel Tarlow, Marc Brockschmidt, Richard Zemel, arXiv:1511.05493arXiv preprintYujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015.\n\nStatistical Twitter spam detection demystified: Performance, stability and scalability. Guanjun Lin, Nan Sun, Surya Nepal, Jun Zhang, Yang Xiang, Houcine Hassan, IEEE access. IEEE5Guanjun Lin, Nan Sun, Surya Nepal, Jun Zhang, Yang Xiang, and Houcine Hassan. Statistical Twitter spam detection demystified: Performance, stability and scala- bility. In IEEE access, volume 5, pages 11142-11154. IEEE, 2017.\n\nTrojaning attack on neural networks. Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, Xiangyu Zhang, NDSS. Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. Trojan- ing attack on neural networks. In NDSS, 2017.\n\nStudying user footprints in different online social networks. Anshu Malhotra, Luam Totti, Meira WagnerJr, Ponnurangam Kumaraguru, Virgilio Almeida, International conference on advances in social networks analysis and mining (ASONAM). IEEE Computer SocietyAnshu Malhotra, Luam Totti, Wagner Meira Jr, Pon- nurangam Kumaraguru, and Virgilio Almeida. Study- ing user footprints in different online social networks. In International conference on advances in social net- works analysis and mining (ASONAM), pages 1065- 1070. IEEE Computer Society, 2012.\n\nPoised: Spotting Twitter spam off the beaten paths. Shirin Nilizadeh, Francois Labr\u00e8che, Alireza Sedighian, Ali Zand, Jos\u00e9 Fernandez, Christopher Kruegel, Gianluca Stringhini, Giovanni Vigna, CCS. Shirin Nilizadeh, Francois Labr\u00e8che, Alireza Sedighian, Ali Zand, Jos\u00e9 Fernandez, Christopher Kruegel, Gian- luca Stringhini, and Giovanni Vigna. Poised: Spotting Twitter spam off the beaten paths. In CCS, 2017.\n\nA survey on transfer learning. Qiang Sinno Jialin Pan, Yang, IEEE Transactions on knowledge and data engineering. 2210Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10):1345-1359, 2009.\n\nDeepwalk: Online learning of social representations. Bryan Perozzi, Rami Al-Rfou, Steven Skiena, Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. the 20th ACM SIGKDD international conference on Knowledge discovery and data miningBryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deep- walk: Online learning of social representations. In Pro- ceedings of the 20th ACM SIGKDD international con- ference on Knowledge discovery and data mining, pages 701-710, 2014.\n\nDiscriminability-based transfer between neural networks. Y Lorien, Pratt, Advances in neural information processing systems. Lorien Y Pratt. Discriminability-based transfer between neural networks. In Advances in neural information processing systems, pages 204-211, 1993.\n\n. Pytorch, PyTorch. https://pytorch.org/.\n\nOnline algorithms and stochastic approximations. David Saad, Online Learning. 5David Saad. Online algorithms and stochastic approxi- mations. Online Learning, 5:6-3, 1998.\n\nUnited States Securities and Exchange Commission. Facebook archive form 10-q. United States Securities and Exchange Com- mission. Facebook archive form 10-q. https: //www.sec.gov/Archives/edgar/data/1326801/ 000132680117000007/fb-12312016x10k.htm, 2016.\n\nUnited States Securities and Exchange Commission. Facebook archive form 10-q. United States Securities and Exchange Com- mission. Facebook archive form 10-q. https: //www.sec.gov/Archives/edgar/data/1326801/ 000132680118000067/fb-09302018x10q.htm, 2018.\n\nActive learning literature survey. Burr Settles, University of Wisconsin-Madison Department of Computer SciencesTechnical reportBurr Settles. Active learning literature survey. Technical report, University of Wisconsin-Madison Department of Computer Sciences, 2009.\n\nPoison frogs! targeted clean-label poisoning attacks on neural networks. Ali Shafahi, Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer, Tudor Dumitras, Tom Goldstein, Advances in Neural Information Processing Systems. Ali Shafahi, W Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer, Tudor Dumitras, and Tom Gold- stein. Poison frogs! targeted clean-label poisoning at- tacks on neural networks. In Advances in Neural Infor- mation Processing Systems, pages 6103-6113, 2018.\n\nFacebook immune system. Tao Stein, Erdong Chen, Karan Mangla, Workshop on social network systems. ACMTao Stein, Erdong Chen, and Karan Mangla. Facebook immune system. In Workshop on social network systems, page 8. ACM, 2011.\n\nDetecting spammers on social networks. Gianluca Stringhini, Christopher Kruegel, Giovanni Vigna, Annual Computer Security Applications Conference (AC-SAC). Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna. Detecting spammers on social networks. In An- nual Computer Security Applications Conference (AC- SAC), 2010.\n\nEVILCOHORT: Detecting communities of malicious accounts on online services. Gianluca Stringhini, Pierre Mourlanne, Gregoire Jacob, Manuel Egele, Christopher Kruegel, Giovanni Vigna, USENIX Security. Gianluca Stringhini, Pierre Mourlanne, Gregoire Jacob, Manuel Egele, Christopher Kruegel, and Giovanni Vi- gna. EVILCOHORT: Detecting communities of mali- cious accounts on online services. In USENIX Security, 2015.\n\nUNIK: Unsupervised social network spam detection. Enhua Tan, Lei Guo, Songqing Chen, Xiaodong Zhang, Yihong Zhao, International conference on information & knowledge management. ACMEnhua Tan, Lei Guo, Songqing Chen, Xiaodong Zhang, and Yihong Zhao. UNIK: Unsupervised social network spam detection. In International conference on informa- tion & knowledge management, pages 479-488. ACM, 2013.\n\nLearning from noisy large-scale datasets with minimal supervision. Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, Serge J Belongie, CVPR. Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and Serge J Belongie. Learning from noisy large-scale datasets with minimal supervision. In CVPR, pages 6575-6583, 2017.\n\nDon't follow me: Spam detection in Twitter. A H Wang, Conference on Security and Cryptography (SE-CRYPT). A. H. Wang. Don't follow me: Spam detection in Twit- ter. In Conference on Security and Cryptography (SE- CRYPT), 2010.\n\nYou are how you click: Clickstream analysis for sybil detection. Gang Wang, Tristan Konolige, Christo Wilson, Xiao Wang, Haitao Zheng, Ben Y Zhao, USENIX Security. Gang Wang, Tristan Konolige, Christo Wilson, Xiao Wang, Haitao Zheng, and Ben Y. Zhao. You are how you click: Clickstream analysis for sybil detection. In USENIX Security, 2013.\n\nFelix Wu, Tianyi Zhang, Amauri Holanda De SouzaJr, Christopher Fifty, Tao Yu, Kilian Q Weinberger, arXiv:1902.07153Simplifying graph convolutional networks. arXiv preprintFelix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr, Christopher Fifty, Tao Yu, and Kilian Q Weinberger. Simplifying graph convolutional networks. arXiv preprint arXiv:1902.07153, 2019.\n\nDetecting clusters of fake accounts in online social networks. Cao Xiao, David Mandell Freeman, Theodore Hwa, Workshop on artificial intelligence and security. ACMCao Xiao, David Mandell Freeman, and Theodore Hwa. Detecting clusters of fake accounts in online social net- works. In Workshop on artificial intelligence and secu- rity, pages 91-101. ACM, 2015.\n\nDie free or live hard? empirical evaluation and new design for fighting evolving Twitter spammers. Chao Yang, Robert Chandler Harkreader, Guofei Gu, Conference on Recent Advances in Intrusion Detection (RAID). Chao Yang, Robert Chandler Harkreader, and Guofei Gu. Die free or live hard? empirical evaluation and new design for fighting evolving Twitter spammers. In Conference on Recent Advances in Intrusion Detection (RAID), 2011.\n\nUncovering social network sybils in the wild. Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y Zhao, Yafei Dai, Internet Measurement Conference (IMC). Zhi Yang, Christo Wilson, Xiao Wang, Tingting Gao, Ben Y. Zhao, and Yafei Dai. Uncovering social network sybils in the wild. In Internet Measurement Conference (IMC), 2011.\n\nHow transferable are features in deep neural networks?. Jason Yosinski, Jeff Clune, Yoshua Bengio, Hod Lipson, Proceedings of the Conference on Neural Information Processing Systems. the Conference on Neural Information Processing SystemsJason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable are features in deep neural networks? In Proceedings of the Conference on Neural Information Processing Systems, 2014.\n\nSybil defenses via social networks: A tutorial and survey. Haifeng Yu, ACM SIGACT news. ACM42Haifeng Yu. Sybil defenses via social networks: A tu- torial and survey. In ACM SIGACT news, volume 42, pages 80-101. ACM, 2011.\n\nSybillimit: A near-optimal social network defense against sybil attacks. Haifeng Yu, B Phillip, Michael Gibbons, Feng Kaminsky, Xiao, Symposium on security and privacy. IEEEHaifeng Yu, Phillip B Gibbons, Michael Kaminsky, and Feng Xiao. Sybillimit: A near-optimal social network defense against sybil attacks. In Symposium on security and privacy, pages 3-17. IEEE, 2008.\n\nSybilguard: Defending against sybil attacks via social networks. Haifeng Yu, Michael Kaminsky, B Phillip, Abraham Gibbons, Flaxman, ACM SIGCOMM computer communication review. ACM36Haifeng Yu, Michael Kaminsky, Phillip B Gibbons, and Abraham Flaxman. Sybilguard: Defending against sybil attacks via social networks. In ACM SIGCOMM com- puter communication review, volume 36, pages 267-278. ACM, 2006.\n\nBotgraph: Large scale spamming botnet detection. Yao Zhao, Yinglian Xie, Fang Yu, Qifa Ke, Yuan Yu, Yan Chen, Eliot Gillum, USENIX NSDI. Yao Zhao, Yinglian Xie, Fang Yu, Qifa Ke, Yuan Yu, Yan Chen, and Eliot Gillum. Botgraph: Large scale spamming botnet detection. In USENIX NSDI, 2009.\n", "annotations": {"author": "[{\"end\":161,\"start\":84},{\"end\":246,\"start\":162},{\"end\":330,\"start\":247},{\"end\":413,\"start\":331},{\"end\":501,\"start\":414},{\"end\":584,\"start\":502},{\"end\":671,\"start\":585},{\"end\":753,\"start\":672},{\"end\":843,\"start\":754}]", "publisher": null, "author_last_name": "[{\"end\":91,\"start\":89},{\"end\":176,\"start\":169},{\"end\":260,\"start\":255},{\"end\":343,\"start\":339},{\"end\":431,\"start\":422},{\"end\":514,\"start\":512},{\"end\":601,\"start\":596},{\"end\":683,\"start\":678},{\"end\":773,\"start\":767}]", "author_first_name": "[{\"end\":88,\"start\":84},{\"end\":168,\"start\":162},{\"end\":254,\"start\":247},{\"end\":338,\"start\":331},{\"end\":421,\"start\":414},{\"end\":505,\"start\":502},{\"end\":511,\"start\":506},{\"end\":590,\"start\":585},{\"end\":595,\"start\":591},{\"end\":677,\"start\":672},{\"end\":761,\"start\":754},{\"end\":766,\"start\":762}]", "author_affiliation": "[{\"end\":160,\"start\":93},{\"end\":245,\"start\":178},{\"end\":329,\"start\":262},{\"end\":412,\"start\":345},{\"end\":500,\"start\":433},{\"end\":583,\"start\":516},{\"end\":670,\"start\":603},{\"end\":752,\"start\":685},{\"end\":842,\"start\":775}]", "title": "[{\"end\":81,\"start\":1},{\"end\":924,\"start\":844}]", "venue": null, "abstract": "[{\"end\":5881,\"start\":926}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6079,\"start\":6075},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6675,\"start\":6671},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6717,\"start\":6714},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7098,\"start\":7094},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":7101,\"start\":7098},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":7289,\"start\":7285},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7332,\"start\":7328},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7335,\"start\":7332},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7445,\"start\":7442},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7702,\"start\":7698},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7904,\"start\":7901},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8188,\"start\":8184},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8329,\"start\":8326},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8722,\"start\":8718},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10986,\"start\":10982},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11161,\"start\":11157},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11165,\"start\":11161},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11169,\"start\":11165},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11239,\"start\":11235},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11527,\"start\":11526},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12383,\"start\":12379},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":12847,\"start\":12844},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13617,\"start\":13613},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":14296,\"start\":14292},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14941,\"start\":14937},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":15447,\"start\":15443},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15657,\"start\":15653},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":15660,\"start\":15657},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":15663,\"start\":15660},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":16195,\"start\":16191},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":16371,\"start\":16367},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":16527,\"start\":16523},{\"end\":16849,\"start\":16827},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":16978,\"start\":16974},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":17133,\"start\":17129},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":17260,\"start\":17256},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":17496,\"start\":17492},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":17660,\"start\":17656},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":18241,\"start\":18237},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":18451,\"start\":18447},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18649,\"start\":18646},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18838,\"start\":18835},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":19104,\"start\":19100},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":19866,\"start\":19862},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":20097,\"start\":20093},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":20711,\"start\":20707},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":21071,\"start\":21068},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":21177,\"start\":21173},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":21636,\"start\":21632},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":21917,\"start\":21913},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":22354,\"start\":22350},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22380,\"start\":22376},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":22404,\"start\":22400},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22463,\"start\":22459},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":22484,\"start\":22480},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":22648,\"start\":22644},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22651,\"start\":22648},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":22654,\"start\":22651},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":23408,\"start\":23404},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":23411,\"start\":23408},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":23669,\"start\":23665},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":23958,\"start\":23955},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":24224,\"start\":24221},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24227,\"start\":24224},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":33082,\"start\":33078},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":35934,\"start\":35933},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":39657,\"start\":39654},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":39699,\"start\":39695},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":42110,\"start\":42106},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":43110,\"start\":43106},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":44579,\"start\":44575},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":44582,\"start\":44579},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":44585,\"start\":44582},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":46530,\"start\":46527},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":47215,\"start\":47211},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":47294,\"start\":47290},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":47418,\"start\":47414},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":49761,\"start\":49757},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":52986,\"start\":52982},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":63705,\"start\":63704},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":70164,\"start\":70160},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":79158,\"start\":79157}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":74001,\"start\":73651},{\"attributes\":{\"id\":\"fig_1\"},\"end\":74210,\"start\":74002},{\"attributes\":{\"id\":\"fig_2\"},\"end\":74587,\"start\":74211},{\"attributes\":{\"id\":\"fig_3\"},\"end\":75032,\"start\":74588},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":75577,\"start\":75033},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":76045,\"start\":75578},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":76423,\"start\":76046},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":77577,\"start\":76424},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":78040,\"start\":77578},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":78755,\"start\":78041},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":79027,\"start\":78756}]", "paragraph": "[{\"end\":6718,\"start\":5897},{\"end\":7214,\"start\":6720},{\"end\":8879,\"start\":7216},{\"end\":9324,\"start\":8881},{\"end\":9767,\"start\":9326},{\"end\":10724,\"start\":9769},{\"end\":10857,\"start\":10739},{\"end\":11655,\"start\":10878},{\"end\":12695,\"start\":11668},{\"end\":13409,\"start\":12697},{\"end\":13519,\"start\":13442},{\"end\":13726,\"start\":13544},{\"end\":13970,\"start\":13728},{\"end\":14498,\"start\":13985},{\"end\":14942,\"start\":14534},{\"end\":15199,\"start\":14959},{\"end\":15891,\"start\":15230},{\"end\":16712,\"start\":15893},{\"end\":17261,\"start\":16714},{\"end\":17487,\"start\":17280},{\"end\":18601,\"start\":17489},{\"end\":19303,\"start\":18603},{\"end\":19715,\"start\":19305},{\"end\":20477,\"start\":19734},{\"end\":20594,\"start\":20498},{\"end\":21159,\"start\":20621},{\"end\":21580,\"start\":21161},{\"end\":22178,\"start\":21582},{\"end\":23172,\"start\":22180},{\"end\":23616,\"start\":23174},{\"end\":24203,\"start\":23618},{\"end\":24902,\"start\":24205},{\"end\":25437,\"start\":24926},{\"end\":26381,\"start\":25458},{\"end\":26479,\"start\":26403},{\"end\":26913,\"start\":26481},{\"end\":28108,\"start\":26915},{\"end\":28468,\"start\":28110},{\"end\":28709,\"start\":28505},{\"end\":30048,\"start\":28727},{\"end\":31582,\"start\":30050},{\"end\":31867,\"start\":31601},{\"end\":32563,\"start\":31869},{\"end\":32945,\"start\":32565},{\"end\":33875,\"start\":32947},{\"end\":35146,\"start\":33877},{\"end\":35935,\"start\":35148},{\"end\":36913,\"start\":35957},{\"end\":37837,\"start\":36938},{\"end\":39030,\"start\":37839},{\"end\":39589,\"start\":39032},{\"end\":40013,\"start\":39634},{\"end\":40399,\"start\":40015},{\"end\":40729,\"start\":40401},{\"end\":41084,\"start\":40744},{\"end\":42030,\"start\":41086},{\"end\":42544,\"start\":42032},{\"end\":43111,\"start\":42546},{\"end\":43552,\"start\":43140},{\"end\":44409,\"start\":43554},{\"end\":45472,\"start\":44411},{\"end\":46212,\"start\":45474},{\"end\":46896,\"start\":46274},{\"end\":47325,\"start\":46898},{\"end\":47750,\"start\":47367},{\"end\":48052,\"start\":47752},{\"end\":48885,\"start\":48067},{\"end\":50113,\"start\":48898},{\"end\":50159,\"start\":50115},{\"end\":51041,\"start\":50161},{\"end\":51329,\"start\":51043},{\"end\":51906,\"start\":51331},{\"end\":52310,\"start\":51927},{\"end\":54048,\"start\":52312},{\"end\":54547,\"start\":54076},{\"end\":55999,\"start\":54562},{\"end\":56511,\"start\":56024},{\"end\":56732,\"start\":56513},{\"end\":57169,\"start\":56781},{\"end\":57318,\"start\":57207},{\"end\":57605,\"start\":57320},{\"end\":58052,\"start\":57607},{\"end\":59306,\"start\":58054},{\"end\":60221,\"start\":59308},{\"end\":61613,\"start\":60223},{\"end\":62755,\"start\":61653},{\"end\":63023,\"start\":62757},{\"end\":64064,\"start\":63053},{\"end\":64553,\"start\":64066},{\"end\":64980,\"start\":64555},{\"end\":65807,\"start\":64982},{\"end\":66317,\"start\":65809},{\"end\":67281,\"start\":66357},{\"end\":67457,\"start\":67283},{\"end\":67862,\"start\":67459},{\"end\":68417,\"start\":67893},{\"end\":69158,\"start\":68419},{\"end\":70165,\"start\":69160},{\"end\":70710,\"start\":70203},{\"end\":72418,\"start\":70712},{\"end\":72578,\"start\":72420},{\"end\":73181,\"start\":72593},{\"end\":73650,\"start\":73183}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":30891,\"start\":30884},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":33200,\"start\":33193},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":44408,\"start\":44400},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":48814,\"start\":48807},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":52409,\"start\":52402},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":56817,\"start\":56810},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":61225,\"start\":61218},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":61611,\"start\":61603}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":5895,\"start\":5883},{\"attributes\":{\"n\":\"2\"},\"end\":10737,\"start\":10727},{\"attributes\":{\"n\":\"2.1\"},\"end\":10876,\"start\":10860},{\"attributes\":{\"n\":\"2.2\"},\"end\":11666,\"start\":11658},{\"attributes\":{\"n\":\"2.3\"},\"end\":13440,\"start\":13412},{\"attributes\":{\"n\":\"2.3.1\"},\"end\":13542,\"start\":13522},{\"attributes\":{\"n\":\"2.3.2\"},\"end\":13983,\"start\":13973},{\"attributes\":{\"n\":\"2.3.3\"},\"end\":14532,\"start\":14501},{\"attributes\":{\"n\":\"3\"},\"end\":14957,\"start\":14945},{\"attributes\":{\"n\":\"3.1\"},\"end\":15228,\"start\":15202},{\"attributes\":{\"n\":\"3.2\"},\"end\":17278,\"start\":17264},{\"attributes\":{\"n\":\"3.3\"},\"end\":19732,\"start\":19718},{\"attributes\":{\"n\":\"3.4\"},\"end\":20496,\"start\":20480},{\"attributes\":{\"n\":\"3.4.1\"},\"end\":20619,\"start\":20597},{\"attributes\":{\"n\":\"4\"},\"end\":24924,\"start\":24905},{\"attributes\":{\"n\":\"4.1\"},\"end\":25456,\"start\":25440},{\"attributes\":{\"n\":\"4.2\"},\"end\":26401,\"start\":26384},{\"attributes\":{\"n\":\"5\"},\"end\":28503,\"start\":28471},{\"attributes\":{\"n\":\"5.1\"},\"end\":28725,\"start\":28712},{\"attributes\":{\"n\":\"5.2\"},\"end\":31599,\"start\":31585},{\"attributes\":{\"n\":\"5.3\"},\"end\":35955,\"start\":35938},{\"attributes\":{\"n\":\"5.4\"},\"end\":36936,\"start\":36916},{\"attributes\":{\"n\":\"6\"},\"end\":39632,\"start\":39592},{\"attributes\":{\"n\":\"6.1\"},\"end\":40742,\"start\":40732},{\"attributes\":{\"n\":\"6.2\"},\"end\":43138,\"start\":43114},{\"attributes\":{\"n\":\"6.3\"},\"end\":46234,\"start\":46215},{\"attributes\":{\"n\":\"6.3.1\"},\"end\":46272,\"start\":46237},{\"attributes\":{\"n\":\"6.3.2\"},\"end\":47365,\"start\":47328},{\"attributes\":{\"n\":\"7\"},\"end\":48065,\"start\":48055},{\"attributes\":{\"n\":\"7.1\"},\"end\":48896,\"start\":48888},{\"attributes\":{\"n\":\"7.2\"},\"end\":51925,\"start\":51909},{\"attributes\":{\"n\":\"7.3\"},\"end\":54074,\"start\":54051},{\"attributes\":{\"n\":\"7.3.1\"},\"end\":54560,\"start\":54550},{\"attributes\":{\"n\":\"7.3.2\"},\"end\":56022,\"start\":56002},{\"attributes\":{\"n\":\"7.3.3\"},\"end\":56779,\"start\":56735},{\"attributes\":{\"n\":\"7.4\"},\"end\":57205,\"start\":57172},{\"attributes\":{\"n\":\"8.1\"},\"end\":61651,\"start\":61616},{\"attributes\":{\"n\":\"8.2\"},\"end\":63051,\"start\":63026},{\"attributes\":{\"n\":\"8.3\"},\"end\":66355,\"start\":66320},{\"attributes\":{\"n\":\"8.4\"},\"end\":67891,\"start\":67865},{\"attributes\":{\"n\":\"8.5\"},\"end\":70201,\"start\":70168},{\"attributes\":{\"n\":\"9\"},\"end\":72591,\"start\":72581},{\"end\":73662,\"start\":73652},{\"end\":74013,\"start\":74003},{\"end\":74222,\"start\":74212},{\"end\":74599,\"start\":74589},{\"end\":75043,\"start\":75034},{\"end\":75588,\"start\":75579},{\"end\":76434,\"start\":76425},{\"end\":77588,\"start\":77579},{\"end\":78051,\"start\":78042},{\"end\":78766,\"start\":78757}]", "table": "[{\"end\":75577,\"start\":75131},{\"end\":76045,\"start\":75707},{\"end\":76423,\"start\":76165},{\"end\":77577,\"start\":76578},{\"end\":78040,\"start\":77694},{\"end\":78755,\"start\":78053},{\"end\":79027,\"start\":78891}]", "figure_caption": "[{\"end\":74001,\"start\":73664},{\"end\":74210,\"start\":74015},{\"end\":74587,\"start\":74224},{\"end\":75032,\"start\":74601},{\"end\":75131,\"start\":75045},{\"end\":75707,\"start\":75590},{\"end\":76165,\"start\":76048},{\"end\":76578,\"start\":76436},{\"end\":77694,\"start\":77590},{\"end\":78891,\"start\":78768}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":25309,\"start\":25301},{\"end\":31259,\"start\":31251},{\"end\":32126,\"start\":32118},{\"end\":39059,\"start\":39051},{\"end\":39293,\"start\":39285},{\"end\":45835,\"start\":45827},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":54155,\"start\":54147},{\"end\":55103,\"start\":55095},{\"end\":55465,\"start\":55457},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":57636,\"start\":57628},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":58702,\"start\":58694}]", "bib_author_first_name": "[{\"end\":80483,\"start\":80478},{\"end\":80500,\"start\":80492},{\"end\":80512,\"start\":80507},{\"end\":80800,\"start\":80795},{\"end\":80812,\"start\":80808},{\"end\":80825,\"start\":80820},{\"end\":81098,\"start\":81090},{\"end\":81118,\"start\":81111},{\"end\":81131,\"start\":81126},{\"end\":81151,\"start\":81143},{\"end\":81513,\"start\":81509},{\"end\":81781,\"start\":81776},{\"end\":81794,\"start\":81787},{\"end\":81814,\"start\":81807},{\"end\":81826,\"start\":81821},{\"end\":82054,\"start\":82050},{\"end\":82235,\"start\":82229},{\"end\":82266,\"start\":82250},{\"end\":82520,\"start\":82514},{\"end\":82533,\"start\":82528},{\"end\":82549,\"start\":82544},{\"end\":82565,\"start\":82559},{\"end\":82890,\"start\":82884},{\"end\":82907,\"start\":82900},{\"end\":83130,\"start\":83125},{\"end\":83146,\"start\":83140},{\"end\":83164,\"start\":83158},{\"end\":83181,\"start\":83173},{\"end\":83200,\"start\":83191},{\"end\":83579,\"start\":83575},{\"end\":83591,\"start\":83587},{\"end\":83604,\"start\":83599},{\"end\":84361,\"start\":84352},{\"end\":84373,\"start\":84369},{\"end\":84387,\"start\":84381},{\"end\":84733,\"start\":84726},{\"end\":84745,\"start\":84740},{\"end\":84757,\"start\":84752},{\"end\":85089,\"start\":85082},{\"end\":85495,\"start\":85494},{\"end\":85748,\"start\":85742},{\"end\":85760,\"start\":85753},{\"end\":85784,\"start\":85775},{\"end\":86056,\"start\":86055},{\"end\":86076,\"start\":86075},{\"end\":86349,\"start\":86344},{\"end\":86363,\"start\":86357},{\"end\":86656,\"start\":86650},{\"end\":86669,\"start\":86663},{\"end\":86692,\"start\":86684},{\"end\":87153,\"start\":87149},{\"end\":87165,\"start\":87161},{\"end\":87179,\"start\":87171},{\"end\":87480,\"start\":87477},{\"end\":87491,\"start\":87486},{\"end\":87503,\"start\":87497},{\"end\":87819,\"start\":87818},{\"end\":87831,\"start\":87828},{\"end\":88045,\"start\":88044},{\"end\":88178,\"start\":88170},{\"end\":88191,\"start\":88185},{\"end\":88207,\"start\":88199},{\"end\":88566,\"start\":88561},{\"end\":88583,\"start\":88575},{\"end\":88595,\"start\":88590},{\"end\":88612,\"start\":88606},{\"end\":88629,\"start\":88624},{\"end\":88643,\"start\":88639},{\"end\":88656,\"start\":88652},{\"end\":88897,\"start\":88893},{\"end\":88911,\"start\":88905},{\"end\":88928,\"start\":88920},{\"end\":89117,\"start\":89111},{\"end\":89128,\"start\":89123},{\"end\":89144,\"start\":89139},{\"end\":89502,\"start\":89497},{\"end\":89514,\"start\":89507},{\"end\":89529,\"start\":89520},{\"end\":89825,\"start\":89820},{\"end\":89836,\"start\":89830},{\"end\":89849,\"start\":89845},{\"end\":89871,\"start\":89864},{\"end\":90145,\"start\":90138},{\"end\":90154,\"start\":90151},{\"end\":90165,\"start\":90160},{\"end\":90176,\"start\":90173},{\"end\":90188,\"start\":90184},{\"end\":90203,\"start\":90196},{\"end\":90499,\"start\":90493},{\"end\":90512,\"start\":90505},{\"end\":90523,\"start\":90517},{\"end\":90540,\"start\":90531},{\"end\":90550,\"start\":90546},{\"end\":90564,\"start\":90557},{\"end\":90578,\"start\":90571},{\"end\":90811,\"start\":90806},{\"end\":90826,\"start\":90822},{\"end\":90839,\"start\":90834},{\"end\":90861,\"start\":90850},{\"end\":90882,\"start\":90874},{\"end\":91353,\"start\":91347},{\"end\":91373,\"start\":91365},{\"end\":91391,\"start\":91384},{\"end\":91406,\"start\":91403},{\"end\":91417,\"start\":91413},{\"end\":91440,\"start\":91429},{\"end\":91458,\"start\":91450},{\"end\":91479,\"start\":91471},{\"end\":91741,\"start\":91736},{\"end\":92023,\"start\":92018},{\"end\":92037,\"start\":92033},{\"end\":92053,\"start\":92047},{\"end\":92535,\"start\":92534},{\"end\":92848,\"start\":92843},{\"end\":93516,\"start\":93512},{\"end\":93820,\"start\":93817},{\"end\":93835,\"start\":93830},{\"end\":93849,\"start\":93843},{\"end\":93866,\"start\":93858},{\"end\":93883,\"start\":93874},{\"end\":93897,\"start\":93892},{\"end\":93911,\"start\":93908},{\"end\":94270,\"start\":94267},{\"end\":94284,\"start\":94278},{\"end\":94296,\"start\":94291},{\"end\":94516,\"start\":94508},{\"end\":94540,\"start\":94529},{\"end\":94558,\"start\":94550},{\"end\":94882,\"start\":94874},{\"end\":94901,\"start\":94895},{\"end\":94921,\"start\":94913},{\"end\":94935,\"start\":94929},{\"end\":94954,\"start\":94943},{\"end\":94972,\"start\":94964},{\"end\":95269,\"start\":95264},{\"end\":95278,\"start\":95275},{\"end\":95292,\"start\":95284},{\"end\":95307,\"start\":95299},{\"end\":95321,\"start\":95315},{\"end\":95683,\"start\":95676},{\"end\":95694,\"start\":95690},{\"end\":95707,\"start\":95704},{\"end\":95721,\"start\":95717},{\"end\":95737,\"start\":95730},{\"end\":95750,\"start\":95745},{\"end\":95752,\"start\":95751},{\"end\":96005,\"start\":96004},{\"end\":96007,\"start\":96006},{\"end\":96256,\"start\":96252},{\"end\":96270,\"start\":96263},{\"end\":96288,\"start\":96281},{\"end\":96301,\"start\":96297},{\"end\":96314,\"start\":96308},{\"end\":96325,\"start\":96322},{\"end\":96327,\"start\":96326},{\"end\":96535,\"start\":96530},{\"end\":96546,\"start\":96540},{\"end\":96560,\"start\":96554},{\"end\":96592,\"start\":96581},{\"end\":96603,\"start\":96600},{\"end\":96616,\"start\":96608},{\"end\":96953,\"start\":96950},{\"end\":96965,\"start\":96960},{\"end\":96973,\"start\":96966},{\"end\":96991,\"start\":96983},{\"end\":97350,\"start\":97346},{\"end\":97363,\"start\":97357},{\"end\":97372,\"start\":97364},{\"end\":97391,\"start\":97385},{\"end\":97730,\"start\":97727},{\"end\":97744,\"start\":97737},{\"end\":97757,\"start\":97753},{\"end\":97772,\"start\":97764},{\"end\":97781,\"start\":97778},{\"end\":97783,\"start\":97782},{\"end\":97795,\"start\":97790},{\"end\":98075,\"start\":98070},{\"end\":98090,\"start\":98086},{\"end\":98104,\"start\":98098},{\"end\":98116,\"start\":98113},{\"end\":98514,\"start\":98507},{\"end\":98751,\"start\":98744},{\"end\":98757,\"start\":98756},{\"end\":98774,\"start\":98767},{\"end\":98788,\"start\":98784},{\"end\":99116,\"start\":99109},{\"end\":99128,\"start\":99121},{\"end\":99140,\"start\":99139},{\"end\":99157,\"start\":99150},{\"end\":99497,\"start\":99494},{\"end\":99512,\"start\":99504},{\"end\":99522,\"start\":99518},{\"end\":99531,\"start\":99527},{\"end\":99540,\"start\":99536},{\"end\":99548,\"start\":99545},{\"end\":99560,\"start\":99555}]", "bib_author_last_name": "[{\"end\":80490,\"start\":80484},{\"end\":80505,\"start\":80501},{\"end\":80519,\"start\":80513},{\"end\":80806,\"start\":80801},{\"end\":80818,\"start\":80813},{\"end\":80832,\"start\":80826},{\"end\":81109,\"start\":81099},{\"end\":81124,\"start\":81119},{\"end\":81141,\"start\":81132},{\"end\":81159,\"start\":81152},{\"end\":81523,\"start\":81514},{\"end\":81785,\"start\":81782},{\"end\":81805,\"start\":81795},{\"end\":81819,\"start\":81815},{\"end\":81836,\"start\":81827},{\"end\":82062,\"start\":82055},{\"end\":82248,\"start\":82236},{\"end\":82277,\"start\":82267},{\"end\":82526,\"start\":82521},{\"end\":82542,\"start\":82534},{\"end\":82557,\"start\":82550},{\"end\":82571,\"start\":82566},{\"end\":82898,\"start\":82891},{\"end\":82914,\"start\":82908},{\"end\":83138,\"start\":83131},{\"end\":83156,\"start\":83147},{\"end\":83171,\"start\":83165},{\"end\":83189,\"start\":83182},{\"end\":83211,\"start\":83201},{\"end\":83585,\"start\":83580},{\"end\":83597,\"start\":83592},{\"end\":83611,\"start\":83605},{\"end\":83847,\"start\":83839},{\"end\":83927,\"start\":83919},{\"end\":84008,\"start\":84000},{\"end\":84109,\"start\":84101},{\"end\":84210,\"start\":84202},{\"end\":84367,\"start\":84362},{\"end\":84379,\"start\":84374},{\"end\":84396,\"start\":84388},{\"end\":84738,\"start\":84734},{\"end\":84750,\"start\":84746},{\"end\":84765,\"start\":84758},{\"end\":85103,\"start\":85090},{\"end\":85502,\"start\":85496},{\"end\":85512,\"start\":85504},{\"end\":85751,\"start\":85749},{\"end\":85773,\"start\":85761},{\"end\":85789,\"start\":85785},{\"end\":86065,\"start\":86057},{\"end\":86073,\"start\":86067},{\"end\":86083,\"start\":86077},{\"end\":86098,\"start\":86085},{\"end\":86355,\"start\":86350},{\"end\":86371,\"start\":86364},{\"end\":86661,\"start\":86657},{\"end\":86682,\"start\":86670},{\"end\":86701,\"start\":86693},{\"end\":86709,\"start\":86703},{\"end\":87159,\"start\":87154},{\"end\":87169,\"start\":87166},{\"end\":87189,\"start\":87180},{\"end\":87484,\"start\":87481},{\"end\":87495,\"start\":87492},{\"end\":87507,\"start\":87504},{\"end\":87512,\"start\":87509},{\"end\":87826,\"start\":87820},{\"end\":87836,\"start\":87832},{\"end\":87845,\"start\":87838},{\"end\":88054,\"start\":88046},{\"end\":88183,\"start\":88179},{\"end\":88197,\"start\":88192},{\"end\":88210,\"start\":88208},{\"end\":88573,\"start\":88567},{\"end\":88588,\"start\":88584},{\"end\":88604,\"start\":88596},{\"end\":88622,\"start\":88613},{\"end\":88637,\"start\":88630},{\"end\":88650,\"start\":88644},{\"end\":88663,\"start\":88657},{\"end\":88903,\"start\":88898},{\"end\":88918,\"start\":88912},{\"end\":88935,\"start\":88929},{\"end\":89121,\"start\":89118},{\"end\":89137,\"start\":89129},{\"end\":89149,\"start\":89145},{\"end\":89505,\"start\":89503},{\"end\":89518,\"start\":89515},{\"end\":89532,\"start\":89530},{\"end\":89828,\"start\":89826},{\"end\":89843,\"start\":89837},{\"end\":89862,\"start\":89850},{\"end\":89877,\"start\":89872},{\"end\":90149,\"start\":90146},{\"end\":90158,\"start\":90155},{\"end\":90171,\"start\":90166},{\"end\":90182,\"start\":90177},{\"end\":90194,\"start\":90189},{\"end\":90210,\"start\":90204},{\"end\":90503,\"start\":90500},{\"end\":90515,\"start\":90513},{\"end\":90529,\"start\":90524},{\"end\":90544,\"start\":90541},{\"end\":90555,\"start\":90551},{\"end\":90569,\"start\":90565},{\"end\":90584,\"start\":90579},{\"end\":90820,\"start\":90812},{\"end\":90832,\"start\":90827},{\"end\":90846,\"start\":90840},{\"end\":90872,\"start\":90862},{\"end\":90890,\"start\":90883},{\"end\":91363,\"start\":91354},{\"end\":91382,\"start\":91374},{\"end\":91401,\"start\":91392},{\"end\":91411,\"start\":91407},{\"end\":91427,\"start\":91418},{\"end\":91448,\"start\":91441},{\"end\":91469,\"start\":91459},{\"end\":91485,\"start\":91480},{\"end\":91758,\"start\":91742},{\"end\":91764,\"start\":91760},{\"end\":92031,\"start\":92024},{\"end\":92045,\"start\":92038},{\"end\":92060,\"start\":92054},{\"end\":92542,\"start\":92536},{\"end\":92549,\"start\":92544},{\"end\":92760,\"start\":92753},{\"end\":92853,\"start\":92849},{\"end\":93524,\"start\":93517},{\"end\":93828,\"start\":93821},{\"end\":93841,\"start\":93836},{\"end\":93856,\"start\":93850},{\"end\":93872,\"start\":93867},{\"end\":93890,\"start\":93884},{\"end\":93906,\"start\":93898},{\"end\":93921,\"start\":93912},{\"end\":94276,\"start\":94271},{\"end\":94289,\"start\":94285},{\"end\":94303,\"start\":94297},{\"end\":94527,\"start\":94517},{\"end\":94548,\"start\":94541},{\"end\":94564,\"start\":94559},{\"end\":94893,\"start\":94883},{\"end\":94911,\"start\":94902},{\"end\":94927,\"start\":94922},{\"end\":94941,\"start\":94936},{\"end\":94962,\"start\":94955},{\"end\":94978,\"start\":94973},{\"end\":95273,\"start\":95270},{\"end\":95282,\"start\":95279},{\"end\":95297,\"start\":95293},{\"end\":95313,\"start\":95308},{\"end\":95326,\"start\":95322},{\"end\":95688,\"start\":95684},{\"end\":95702,\"start\":95695},{\"end\":95715,\"start\":95708},{\"end\":95728,\"start\":95722},{\"end\":95743,\"start\":95738},{\"end\":95761,\"start\":95753},{\"end\":96012,\"start\":96008},{\"end\":96261,\"start\":96257},{\"end\":96279,\"start\":96271},{\"end\":96295,\"start\":96289},{\"end\":96306,\"start\":96302},{\"end\":96320,\"start\":96315},{\"end\":96332,\"start\":96328},{\"end\":96538,\"start\":96536},{\"end\":96552,\"start\":96547},{\"end\":96577,\"start\":96561},{\"end\":96598,\"start\":96593},{\"end\":96606,\"start\":96604},{\"end\":96627,\"start\":96617},{\"end\":96958,\"start\":96954},{\"end\":96981,\"start\":96974},{\"end\":96995,\"start\":96992},{\"end\":97355,\"start\":97351},{\"end\":97383,\"start\":97373},{\"end\":97394,\"start\":97392},{\"end\":97735,\"start\":97731},{\"end\":97751,\"start\":97745},{\"end\":97762,\"start\":97758},{\"end\":97776,\"start\":97773},{\"end\":97788,\"start\":97784},{\"end\":97799,\"start\":97796},{\"end\":98084,\"start\":98076},{\"end\":98096,\"start\":98091},{\"end\":98111,\"start\":98105},{\"end\":98123,\"start\":98117},{\"end\":98517,\"start\":98515},{\"end\":98754,\"start\":98752},{\"end\":98765,\"start\":98758},{\"end\":98782,\"start\":98775},{\"end\":98797,\"start\":98789},{\"end\":98803,\"start\":98799},{\"end\":99119,\"start\":99117},{\"end\":99137,\"start\":99129},{\"end\":99148,\"start\":99141},{\"end\":99165,\"start\":99158},{\"end\":99174,\"start\":99167},{\"end\":99502,\"start\":99498},{\"end\":99516,\"start\":99513},{\"end\":99525,\"start\":99523},{\"end\":99534,\"start\":99532},{\"end\":99543,\"start\":99541},{\"end\":99553,\"start\":99549},{\"end\":99567,\"start\":99561}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":5865347},\"end\":80739,\"start\":80421},{\"attributes\":{\"doi\":\"arXiv:1206.6400\",\"id\":\"b1\",\"matched_paper_id\":10129757},\"end\":81057,\"start\":80741},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":14727973},\"end\":81449,\"start\":81059},{\"attributes\":{\"id\":\"b3\"},\"end\":81697,\"start\":81451},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":9627324},\"end\":82028,\"start\":81699},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":45998148},\"end\":82186,\"start\":82030},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":9242771},\"end\":82484,\"start\":82188},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":14134514},\"end\":82825,\"start\":82486},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":12056076},\"end\":83042,\"start\":82827},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":53222793},\"end\":83495,\"start\":83044},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":538820},\"end\":83835,\"start\":83497},{\"attributes\":{\"id\":\"b11\"},\"end\":83915,\"start\":83837},{\"attributes\":{\"id\":\"b12\"},\"end\":83996,\"start\":83917},{\"attributes\":{\"id\":\"b13\"},\"end\":84097,\"start\":83998},{\"attributes\":{\"id\":\"b14\"},\"end\":84198,\"start\":84099},{\"attributes\":{\"id\":\"b15\"},\"end\":84284,\"start\":84200},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":3222593},\"end\":84608,\"start\":84286},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":18183330},\"end\":84992,\"start\":84610},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":11591527},\"end\":85432,\"start\":84994},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":39450643},\"end\":85659,\"start\":85434},{\"attributes\":{\"doi\":\"arXiv:1708.06733\",\"id\":\"b20\"},\"end\":85995,\"start\":85661},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1658773},\"end\":86265,\"start\":85997},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":6110572},\"end\":86591,\"start\":86267},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":563473},\"end\":87078,\"start\":86593},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":13993114},\"end\":87406,\"start\":87080},{\"attributes\":{\"id\":\"b25\"},\"end\":87750,\"start\":87408},{\"attributes\":{\"doi\":\"arXiv:1609.02907\",\"id\":\"b26\"},\"end\":88012,\"start\":87752},{\"attributes\":{\"id\":\"b27\"},\"end\":88098,\"start\":88014},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":3914935},\"end\":88489,\"start\":88100},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":222895622},\"end\":88865,\"start\":88491},{\"attributes\":{\"id\":\"b30\"},\"end\":89044,\"start\":88867},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":14542723},\"end\":89416,\"start\":89046},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":11118105},\"end\":89780,\"start\":89418},{\"attributes\":{\"doi\":\"arXiv:1511.05493\",\"id\":\"b33\"},\"end\":90048,\"start\":89782},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3792717},\"end\":90454,\"start\":90050},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":31806516},\"end\":90742,\"start\":90456},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":582556},\"end\":91293,\"start\":90744},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":960086},\"end\":91703,\"start\":91295},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":740063},\"end\":91963,\"start\":91705},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":3051291},\"end\":92475,\"start\":91965},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":147613},\"end\":92749,\"start\":92477},{\"attributes\":{\"id\":\"b41\"},\"end\":92792,\"start\":92751},{\"attributes\":{\"id\":\"b42\"},\"end\":92965,\"start\":92794},{\"attributes\":{\"id\":\"b43\"},\"end\":93220,\"start\":92967},{\"attributes\":{\"id\":\"b44\"},\"end\":93475,\"start\":93222},{\"attributes\":{\"id\":\"b45\"},\"end\":93742,\"start\":93477},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":4626477},\"end\":94241,\"start\":93744},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":207188357},\"end\":94467,\"start\":94243},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":141518},\"end\":94796,\"start\":94469},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":15437068},\"end\":95212,\"start\":94798},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":5131153},\"end\":95607,\"start\":95214},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":164146},\"end\":95958,\"start\":95609},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":2759521},\"end\":96185,\"start\":95960},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":7264336},\"end\":96528,\"start\":96187},{\"attributes\":{\"doi\":\"arXiv:1902.07153\",\"id\":\"b54\"},\"end\":96885,\"start\":96530},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":13985021},\"end\":97245,\"start\":96887},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":573894},\"end\":97679,\"start\":97247},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":9103468},\"end\":98012,\"start\":97681},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":362467},\"end\":98446,\"start\":98014},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":2853483},\"end\":98669,\"start\":98448},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":915427},\"end\":99042,\"start\":98671},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":872796},\"end\":99443,\"start\":99044},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":7857406},\"end\":99731,\"start\":99445}]", "bib_title": "[{\"end\":80476,\"start\":80421},{\"end\":80793,\"start\":80741},{\"end\":81088,\"start\":81059},{\"end\":81774,\"start\":81699},{\"end\":82048,\"start\":82030},{\"end\":82227,\"start\":82188},{\"end\":82512,\"start\":82486},{\"end\":82882,\"start\":82827},{\"end\":83123,\"start\":83044},{\"end\":83573,\"start\":83497},{\"end\":84350,\"start\":84286},{\"end\":84724,\"start\":84610},{\"end\":85080,\"start\":84994},{\"end\":85492,\"start\":85434},{\"end\":86053,\"start\":85997},{\"end\":86342,\"start\":86267},{\"end\":86648,\"start\":86593},{\"end\":87147,\"start\":87080},{\"end\":87475,\"start\":87408},{\"end\":88168,\"start\":88100},{\"end\":88559,\"start\":88491},{\"end\":89109,\"start\":89046},{\"end\":89495,\"start\":89418},{\"end\":90136,\"start\":90050},{\"end\":90491,\"start\":90456},{\"end\":90804,\"start\":90744},{\"end\":91345,\"start\":91295},{\"end\":91734,\"start\":91705},{\"end\":92016,\"start\":91965},{\"end\":92532,\"start\":92477},{\"end\":92841,\"start\":92794},{\"end\":93815,\"start\":93744},{\"end\":94265,\"start\":94243},{\"end\":94506,\"start\":94469},{\"end\":94872,\"start\":94798},{\"end\":95262,\"start\":95214},{\"end\":95674,\"start\":95609},{\"end\":96002,\"start\":95960},{\"end\":96250,\"start\":96187},{\"end\":96948,\"start\":96887},{\"end\":97344,\"start\":97247},{\"end\":97725,\"start\":97681},{\"end\":98068,\"start\":98014},{\"end\":98505,\"start\":98448},{\"end\":98742,\"start\":98671},{\"end\":99107,\"start\":99044},{\"end\":99492,\"start\":99445}]", "bib_author": "[{\"end\":80492,\"start\":80478},{\"end\":80507,\"start\":80492},{\"end\":80521,\"start\":80507},{\"end\":80808,\"start\":80795},{\"end\":80820,\"start\":80808},{\"end\":80834,\"start\":80820},{\"end\":81111,\"start\":81090},{\"end\":81126,\"start\":81111},{\"end\":81143,\"start\":81126},{\"end\":81161,\"start\":81143},{\"end\":81525,\"start\":81509},{\"end\":81787,\"start\":81776},{\"end\":81807,\"start\":81787},{\"end\":81821,\"start\":81807},{\"end\":81838,\"start\":81821},{\"end\":82064,\"start\":82050},{\"end\":82250,\"start\":82229},{\"end\":82279,\"start\":82250},{\"end\":82528,\"start\":82514},{\"end\":82544,\"start\":82528},{\"end\":82559,\"start\":82544},{\"end\":82573,\"start\":82559},{\"end\":82900,\"start\":82884},{\"end\":82916,\"start\":82900},{\"end\":83140,\"start\":83125},{\"end\":83158,\"start\":83140},{\"end\":83173,\"start\":83158},{\"end\":83191,\"start\":83173},{\"end\":83213,\"start\":83191},{\"end\":83587,\"start\":83575},{\"end\":83599,\"start\":83587},{\"end\":83613,\"start\":83599},{\"end\":83849,\"start\":83839},{\"end\":83929,\"start\":83919},{\"end\":84010,\"start\":84000},{\"end\":84111,\"start\":84101},{\"end\":84212,\"start\":84202},{\"end\":84369,\"start\":84352},{\"end\":84381,\"start\":84369},{\"end\":84398,\"start\":84381},{\"end\":84740,\"start\":84726},{\"end\":84752,\"start\":84740},{\"end\":84767,\"start\":84752},{\"end\":85105,\"start\":85082},{\"end\":85504,\"start\":85494},{\"end\":85514,\"start\":85504},{\"end\":85753,\"start\":85742},{\"end\":85775,\"start\":85753},{\"end\":85791,\"start\":85775},{\"end\":86067,\"start\":86055},{\"end\":86075,\"start\":86067},{\"end\":86085,\"start\":86075},{\"end\":86100,\"start\":86085},{\"end\":86357,\"start\":86344},{\"end\":86373,\"start\":86357},{\"end\":86663,\"start\":86650},{\"end\":86684,\"start\":86663},{\"end\":86703,\"start\":86684},{\"end\":86711,\"start\":86703},{\"end\":87161,\"start\":87149},{\"end\":87171,\"start\":87161},{\"end\":87191,\"start\":87171},{\"end\":87486,\"start\":87477},{\"end\":87497,\"start\":87486},{\"end\":87509,\"start\":87497},{\"end\":87514,\"start\":87509},{\"end\":87828,\"start\":87818},{\"end\":87838,\"start\":87828},{\"end\":87847,\"start\":87838},{\"end\":88056,\"start\":88044},{\"end\":88185,\"start\":88170},{\"end\":88199,\"start\":88185},{\"end\":88212,\"start\":88199},{\"end\":88575,\"start\":88561},{\"end\":88590,\"start\":88575},{\"end\":88606,\"start\":88590},{\"end\":88624,\"start\":88606},{\"end\":88639,\"start\":88624},{\"end\":88652,\"start\":88639},{\"end\":88665,\"start\":88652},{\"end\":88905,\"start\":88893},{\"end\":88920,\"start\":88905},{\"end\":88937,\"start\":88920},{\"end\":89123,\"start\":89111},{\"end\":89139,\"start\":89123},{\"end\":89151,\"start\":89139},{\"end\":89507,\"start\":89497},{\"end\":89520,\"start\":89507},{\"end\":89534,\"start\":89520},{\"end\":89830,\"start\":89820},{\"end\":89845,\"start\":89830},{\"end\":89864,\"start\":89845},{\"end\":89879,\"start\":89864},{\"end\":90151,\"start\":90138},{\"end\":90160,\"start\":90151},{\"end\":90173,\"start\":90160},{\"end\":90184,\"start\":90173},{\"end\":90196,\"start\":90184},{\"end\":90212,\"start\":90196},{\"end\":90505,\"start\":90493},{\"end\":90517,\"start\":90505},{\"end\":90531,\"start\":90517},{\"end\":90546,\"start\":90531},{\"end\":90557,\"start\":90546},{\"end\":90571,\"start\":90557},{\"end\":90586,\"start\":90571},{\"end\":90822,\"start\":90806},{\"end\":90834,\"start\":90822},{\"end\":90850,\"start\":90834},{\"end\":90874,\"start\":90850},{\"end\":90892,\"start\":90874},{\"end\":91365,\"start\":91347},{\"end\":91384,\"start\":91365},{\"end\":91403,\"start\":91384},{\"end\":91413,\"start\":91403},{\"end\":91429,\"start\":91413},{\"end\":91450,\"start\":91429},{\"end\":91471,\"start\":91450},{\"end\":91487,\"start\":91471},{\"end\":91760,\"start\":91736},{\"end\":91766,\"start\":91760},{\"end\":92033,\"start\":92018},{\"end\":92047,\"start\":92033},{\"end\":92062,\"start\":92047},{\"end\":92544,\"start\":92534},{\"end\":92551,\"start\":92544},{\"end\":92762,\"start\":92753},{\"end\":92855,\"start\":92843},{\"end\":93526,\"start\":93512},{\"end\":93830,\"start\":93817},{\"end\":93843,\"start\":93830},{\"end\":93858,\"start\":93843},{\"end\":93874,\"start\":93858},{\"end\":93892,\"start\":93874},{\"end\":93908,\"start\":93892},{\"end\":93923,\"start\":93908},{\"end\":94278,\"start\":94267},{\"end\":94291,\"start\":94278},{\"end\":94305,\"start\":94291},{\"end\":94529,\"start\":94508},{\"end\":94550,\"start\":94529},{\"end\":94566,\"start\":94550},{\"end\":94895,\"start\":94874},{\"end\":94913,\"start\":94895},{\"end\":94929,\"start\":94913},{\"end\":94943,\"start\":94929},{\"end\":94964,\"start\":94943},{\"end\":94980,\"start\":94964},{\"end\":95275,\"start\":95264},{\"end\":95284,\"start\":95275},{\"end\":95299,\"start\":95284},{\"end\":95315,\"start\":95299},{\"end\":95328,\"start\":95315},{\"end\":95690,\"start\":95676},{\"end\":95704,\"start\":95690},{\"end\":95717,\"start\":95704},{\"end\":95730,\"start\":95717},{\"end\":95745,\"start\":95730},{\"end\":95763,\"start\":95745},{\"end\":96014,\"start\":96004},{\"end\":96263,\"start\":96252},{\"end\":96281,\"start\":96263},{\"end\":96297,\"start\":96281},{\"end\":96308,\"start\":96297},{\"end\":96322,\"start\":96308},{\"end\":96334,\"start\":96322},{\"end\":96540,\"start\":96530},{\"end\":96554,\"start\":96540},{\"end\":96581,\"start\":96554},{\"end\":96600,\"start\":96581},{\"end\":96608,\"start\":96600},{\"end\":96629,\"start\":96608},{\"end\":96960,\"start\":96950},{\"end\":96983,\"start\":96960},{\"end\":96997,\"start\":96983},{\"end\":97357,\"start\":97346},{\"end\":97385,\"start\":97357},{\"end\":97396,\"start\":97385},{\"end\":97737,\"start\":97727},{\"end\":97753,\"start\":97737},{\"end\":97764,\"start\":97753},{\"end\":97778,\"start\":97764},{\"end\":97790,\"start\":97778},{\"end\":97801,\"start\":97790},{\"end\":98086,\"start\":98070},{\"end\":98098,\"start\":98086},{\"end\":98113,\"start\":98098},{\"end\":98125,\"start\":98113},{\"end\":98519,\"start\":98507},{\"end\":98756,\"start\":98744},{\"end\":98767,\"start\":98756},{\"end\":98784,\"start\":98767},{\"end\":98799,\"start\":98784},{\"end\":98805,\"start\":98799},{\"end\":99121,\"start\":99109},{\"end\":99139,\"start\":99121},{\"end\":99150,\"start\":99139},{\"end\":99167,\"start\":99150},{\"end\":99176,\"start\":99167},{\"end\":99504,\"start\":99494},{\"end\":99518,\"start\":99504},{\"end\":99527,\"start\":99518},{\"end\":99536,\"start\":99527},{\"end\":99545,\"start\":99536},{\"end\":99555,\"start\":99545},{\"end\":99569,\"start\":99555}]", "bib_venue": "[{\"end\":85224,\"start\":85173},{\"end\":86852,\"start\":86790},{\"end\":87567,\"start\":87549},{\"end\":92245,\"start\":92162},{\"end\":98252,\"start\":98197},{\"end\":80556,\"start\":80521},{\"end\":80877,\"start\":80849},{\"end\":81235,\"start\":81161},{\"end\":81507,\"start\":81451},{\"end\":81849,\"start\":81838},{\"end\":82080,\"start\":82064},{\"end\":82322,\"start\":82279},{\"end\":82635,\"start\":82573},{\"end\":82920,\"start\":82916},{\"end\":83250,\"start\":83213},{\"end\":83649,\"start\":83613},{\"end\":84414,\"start\":84398},{\"end\":84780,\"start\":84767},{\"end\":85171,\"start\":85105},{\"end\":85534,\"start\":85514},{\"end\":85740,\"start\":85661},{\"end\":86110,\"start\":86100},{\"end\":86409,\"start\":86373},{\"end\":86788,\"start\":86711},{\"end\":87215,\"start\":87191},{\"end\":87547,\"start\":87514},{\"end\":87816,\"start\":87752},{\"end\":88042,\"start\":88014},{\"end\":88274,\"start\":88212},{\"end\":88669,\"start\":88665},{\"end\":88891,\"start\":88867},{\"end\":89222,\"start\":89151},{\"end\":89590,\"start\":89534},{\"end\":89818,\"start\":89782},{\"end\":90223,\"start\":90212},{\"end\":90590,\"start\":90586},{\"end\":90976,\"start\":90892},{\"end\":91490,\"start\":91487},{\"end\":91817,\"start\":91766},{\"end\":92160,\"start\":92062},{\"end\":92600,\"start\":92551},{\"end\":92870,\"start\":92855},{\"end\":93043,\"start\":92967},{\"end\":93298,\"start\":93222},{\"end\":93510,\"start\":93477},{\"end\":93972,\"start\":93923},{\"end\":94339,\"start\":94305},{\"end\":94623,\"start\":94566},{\"end\":94995,\"start\":94980},{\"end\":95390,\"start\":95328},{\"end\":95767,\"start\":95763},{\"end\":96064,\"start\":96014},{\"end\":96349,\"start\":96334},{\"end\":96685,\"start\":96645},{\"end\":97045,\"start\":96997},{\"end\":97455,\"start\":97396},{\"end\":97838,\"start\":97801},{\"end\":98195,\"start\":98125},{\"end\":98534,\"start\":98519},{\"end\":98838,\"start\":98805},{\"end\":99217,\"start\":99176},{\"end\":99580,\"start\":99569}]"}}}, "year": 2023, "month": 12, "day": 17}