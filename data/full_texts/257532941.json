{"id": 257532941, "updated": "2023-10-05 03:27:53.022", "metadata": {"title": "The Devil's Advocate: Shattering the Illusion of Unexploitable Data using Diffusion Models", "authors": "[{\"first\":\"Hadi\",\"last\":\"Dolatabadi\",\"middle\":[\"M.\"]},{\"first\":\"Sarah\",\"last\":\"Erfani\",\"middle\":[]},{\"first\":\"Christopher\",\"last\":\"Leckie\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Protecting personal data against the exploitation of machine learning models is of paramount importance. Recently, availability attacks have shown great promise to provide an extra layer of protection against the unauthorized use of data to train neural networks. These methods aim to add imperceptible noise to clean data so that the neural networks cannot extract meaningful patterns from the protected data, claiming that they can make personal data\"unexploitable.\"In this paper, we provide a strong countermeasure against such approaches, showing that unexploitable data might only be an illusion. In particular, we leverage the power of diffusion models and show that a carefully designed denoising process can defuse the ramifications of the data-protecting perturbations. We rigorously analyze our algorithm, and theoretically prove that the amount of required denoising is directly related to the magnitude of the data-protecting perturbations. Our approach, called AVATAR, delivers state-of-the-art performance against a suite of recent availability attacks in various scenarios, outperforming adversarial training. Our findings call for more research into making personal data unexploitable, showing that this goal is far from over.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2303.08500", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2303-08500", "doi": "10.48550/arxiv.2303.08500"}}, "content": {"source": {"pdf_hash": "253b8903c6dc437918edffd93e56f6b10d15a63e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.08500v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "04da576e6478dd1d4b253717bfe714c4e2849fda", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/253b8903c6dc437918edffd93e56f6b10d15a63e.txt", "contents": "\nThe Devil's Advocate: Shattering the Illusion of Unexploitable Data using Diffusion Models\n\n\nHadi M Dolatabadi h.dolatabadi@unimelb.edu.au \nSchool of Computing and Information Systems\nThe University of Melbourne\n\n\nSarah Erfani sarah.erfani@unimelb.edu.au \nSchool of Computing and Information Systems\nThe University of Melbourne\n\n\nChristopher Leckie caleckie@unimelb.edu.au \nSchool of Computing and Information Systems\nThe University of Melbourne\n\n\nThe Devil's Advocate: Shattering the Illusion of Unexploitable Data using Diffusion Models\n\nProtecting personal data against the exploitation of machine learning models is of paramount importance. Recently, availability attacks have shown great promise to provide an extra layer of protection against the unauthorized use of data to train neural networks. These methods aim to add imperceptible noise to clean data so that the neural networks cannot extract meaningful patterns from the protected data, claiming that they can make personal data \"unexploitable.\" In this paper, we provide a strong countermeasure against such approaches, showing that unexploitable data might only be an illusion. In particular, we leverage the power of diffusion models and show that a carefully designed denoising process can defuse the ramifications of the data-protecting perturbations. We rigorously analyze our algorithm, and theoretically prove that the amount of required denoising is directly related to the magnitude of the data-protecting perturbations. Our approach, called AVATAR, delivers state-of-the-art performance against a suite of recent availability attacks in various scenarios, outperforming adversarial training. Our findings call for more research into making personal data unexploitable, showing that this goal is far from over.\n\nIntroduction\n\nNeural networks have achieved great success in various areas of computer vision including object detection [22,12], semantic segmentation [72,34], and photo-realistic image/video generation [29,9,48]. While the efforts of the community in the development of such models cannot be undermined, this unparalleled success would have been impossible without the abundance of data resources available today [7,31,44,33]. In this regard, social media, and the internet in general, provides a platform that can be crawled easily to create massive datasets. This capability can act both as a blessing and a curse: while the collected data can facilitate learning larger, more accurate neural networks, the users might lose control over protecting their personal data from being exploited. This issue has raised increasing concerns about misuse of personal data [25,24,4].\n\nRecently, there has been an increasing number of studies on hindering the unauthorized use of personal data for neural network image classifiers [13,28,66,15,16,65,56,45]. These methods tend to add an imperceptible amount of noise to the clean images so that while the data has the same appearance as the ground-truth, it cannot provide any meaningful patterns for the neural networks to learn. As a result, such approaches, collectively known as availability attacks [3], claim that personal image data can be made unexploitable for the neural networks [28,65]. While there has been an abundance of research for designing better availability attacks, far too little attention has been paid to counter-attacks that might be employed by adversaries to break such precautionary measures.\n\nUnfortunately, the assumptions of existing availability attacks are far too weak to make the data unexploitable. Going back to our real-world example of users sharing their photos over their social media, one can clearly see that once the the data has been released, it can still be exploited for training a neural network. To clarify the real-world application of this regime, consider a corporate entity that aims to train face recognition models by crawling over social media without the consent of the users. While this unauthorized entity might not have unprotected versions of a particular person's image from his/her social media, they can have a large pre-trained model representing a facial image distribution. Given this threat model, shown in Figure 1, we aim to show that achieving this goal is indeed plausible.\n\nTo this end, we show that pre-trained density estimators are powerful tools that can be used to defuse the effects of the data-protecting perturbations, eventually enabling us to exploit protected data. We utilize the power of diffusion models in representing the image data distributions to show that reverse-engineering unexploitable data is easier than what is thought. In particular, given a training  Figure 1: The threat model considered in this paper. Availability attacks cannot guarantee to protect all the data that exists over the web. A data exploiter might use large density estimators to defuse the data-protecting perturbations and still be able to exploit the data. dataset, we first diffuse the images by adding a controlled amount of Gaussian noise following the forward process of a pre-trained diffusion model. Then, we denoise the noisy images using the reverse process of the aforementioned model, resulting in a dataset purified from data-protecting perturbations. Theoretically, using contraction properties of stochastic difference equations we prove that the number of diffusion steps required to cancel the data-protecting perturbations is directly influenced by its norm. We also empirically show that our approach is surprisingly powerful, being able to deliver the state-of-the-art (SOTA) performance against a wide variety of recent availability attacks. Our results demonstrate that in the era of diffusion models, protected personal data might only be an illusion. Thus, our findings indicate the fragility of unexploitable data, calling for more research to protect personal data.\n\nOur contributions can be summarized as follows:\n\n\u2022 We introduce AVATAR as a countermeasure against data availability attacks. To the best of our knowledge, this is the first work that explores the use of diffusion models to circumvent such attacks.\n\n\u2022 We show the power of AVATAR in breaking availability attacks over five datasets, four architectures, and seven of the most recent availability attacks. AVATAR achieves the SOTA performance against availability attacks, outperforming adversarial training.\n\n\u2022 Theoretically, we show that the amount of noise needed to diffuse the data-protecting perturbation is directly related to its norm. This result indicates that achieving both goals of availability attacks (data utility and protection) at the same time might be impossible.\n\n\nRelated Work\n\nIn this section, we review the related work to our approach. For an extended version, please see Appendix B.\n\nAvailability Attacks. Motivated to address the lack of personal data privacy, recently an emerging type of poisoning attacks known as availability attacks have drawn considerable attention. Unlike previous types of poisoning attacks, availability attacks seek to add imperceptible perturbations to the clean training data with two goals in mind. First, the added perturbation should be able to protect the underlying data from being exploited by a neural network during training. Second, the perturbed data should still preserve its normal utility. To understand these constraints, consider a user sharing their photo over their social media. While the user wants to protect their photo from unauthorized use of web-crawlers to train a face recognition model [25] (first constraint), they still wish their photo to appear normal to their audience (second constraint) [28].\n\nFeng et al. [13] propose to produce the poisoning perturbations by training an auto-encoder, which aim is to get the lowest performance from an auxiliary classifier. In a similar spirit, Tian et al.\n\n[56] train a conditional generative adversarial network (GAN) [19] to generate the availability attacks' perturbation. The training objective is designed to create a spurious correlation between the noisy image and the ground-truth labels. Concurrently, Yu et al. [65] empirically investigate various types of availability attacks and show that almost all of them leverage these spurious features to create a shortcut within neural networks [17]. Yu et al. [65] then propose a fast and scalable approach for perturbation generation by generating randomly-initialized linearly-separable perturbations which can generate availability attacks for an entire dataset in a few seconds. Concurrently, Sandoval-Segura et al. [45] proposed another approach that generates the random noise independent from the data. In this approach, first the beginning rows and columns of each channel are populated with Gaussian noise. Then, an autoregressive process is used to find the value of the remaining pixel values. tacks is via direct optimization. Huang et al. [28] defines a bi-level optimization objective to generate error-minimizing noise for data samples and an auxiliary classifier. It is argued that since the perturbed images minimize the auxiliary classifier's loss, they contain no useful information for any other target classifier to learn, and as such, the model would not exploit them during training. In contrast, Fowl et al. [15] show that using adversarial examples [54,20] as the poisoned data would make it hard for the classifier to learn any meaningful pattern, and thus, they can serve as a powerful family of availability attacks. While optimization-based availability attacks are potent, they are often computationally demanding and several attempts have been made to ease their computational burden [14,70].\n\nCompared to various types of availability attacks, preventative measures have received little attention. It has been shown that various data augmentation techniques (such as CutOut [8], Mixup [69], CutMix [67], and Fast Autoaugment [32]) are not able to prevent availability attacks [28,15,56,65]. Tao et al. [55] shows that adversarial training [36,71,11], originally proposed to enhance robustness against adversarial attacks [54,20], can be used to train successful classifiers against availability attacks. Later, Fu et al. [16] extended error-minimizing noise of Huang et al. [28] resulting in perturbations that can even prevent adversarial training from learning over the poisoned data. Despite this, adversarial training has remained the strongest defense baseline against availability attacks. In this work, we show that one can outperform adversarial training in an attempt to defuse availability attacks.\n\nDiffusion Models. Denoising diffusion probabilistic modeling (DDPM) [49,26] (also known as score-matching networks [50-52]) are a family of deep generative models that have achieved the SOTA performance in image [9,61], text-to-image [43], video [48], and 3D-object [42] generation. Diffusion models generally comprise of a forward and a backward process [6]. In the forward process, the model gradually adds noise to the data until it is transformed into Gaussian noise. The backward process is the reverse of the forward process, where the model tries to gradually transform/denoise a Gaussian vector into a data point.\n\nDiffusion models have been extensively used in various areas. Closely related to our work, Yoon et al. [64] and Nie et al. [39] have employed diffusion models to increase robustness against adversarial attacks. Yoon et al. [64] use Noise Conditioned Score Networks to denoise the input data via Langevin dynamics before feeding them into the neural network classifier. Similarly, Nie et al. [39] utilize the forward and reverse SDEs to add a controlled amount of noise to the data and then denoise them. Contrary to these methods, in this paper we investigate the capabilities of diffusion models as a threat against personal data protected by availability attacks. More precisely, unlike adversarial purification which aims to deliver a successful inference, in our scenario we need to denoise the data so that the model can learn meaningful patterns during training.\n\n\nProposed Method\n\nThis section formally introduces our proposed method, called AVATAR (dAta aVailAbiliTy Attacks defuseR). First, we define our notation and problem settings. Next, we introduce our proposed approach that materializes our threat model and provide a theoretical analysis of our framework. Lastly, we discuss the potential advantages of AVATAR compared to existing methods such as adversarial training.\n\n\nProblem Statement\nLet D = {(x (i) , y (i) )} n i=1\nbe a labeled dataset consisting of n i.i.d. samples x (i) each with a label y (i) . Without loss of generality, in this paper, we consider image data x (i) \u2208 R d where d shows the data dimension. Also, we assume that y (i) takes one of the K possible class values {1, 2, . . . , K}. Furthermore, let f \u03b8 : R d \u2192 R K denote a neural network classifier parameterized by \u03b8 that takes an image x and outputs a real-valued vector z = f \u03b8 (x) known as the logit. The final decision of the classifier is determined via\u0177 = arg max j z j . To train the classifier, one usually aims to minimize the empirical error between the groundtruth labels and the classifier predictions:\narg min \u03b8 E (x,y)\u2208D [ (f \u03b8 (x), y)],(1)\nwhere (\u00b7) denotes the cross-entropy loss. Following the convention in availability attacks, we assume that there exists a data curator that manipulates the dataset D into D pr = {(x (i) , y (i) )} n i=1 such that once a neural network is trained over D pr , it performs poorly over the clean data D:\narg max Dpr E (x,y)\u2208D [ (f \u03b8 * (x), y)] s.t. \u03b8 * = arg min \u03b8 E (x,y)\u2208Dpr [ (f \u03b8 (x), y)].(2)\nSince each imagex (i) needs to maintain its normal utility, it is assumed thatx (i) = x (i) + \u03b4 (i) . Here, \u03b4 (i) 's are the data-protecting perturbations such that \u03b4 (i) p \u2264 \u03b5, where \u00b7 p denotes the L p norm.\n\n\ndAta aVailAbiliTy Attacks defuseR (AVATAR)\n\nAs discussed, large pre-trained generative models can pose a threat to availability attacks and personal data protection. In this section, we show how diffusion models, which are the SOTA in image generation, can be leveraged to cancel out the effects of availability attacks. According to a pre-trained diffusion model, we first add a controlled amount of Gaussian noise to the training data. Then, we use the reverse diffusion process to denoise the data which is later going to be used for neural network training.\n\nRecall that availability attacks provide a manipulated version of the original data x that is seemingly unexploitable. At the same time, the protected imagex = x + \u03b4 should have its normal utility as it is going to be used by the users, e.g., to post over their social media. This condition reflects itself through the constraint that \u03b4 p \u2264 \u03b5.\n\nA trivial idea would be to add noise to the protected data such that the effects of the data-protecting perturbations are cancelled. However, simply making the data noisy would be detrimental to its training utility [28]. As such, we propose to use a diffusion model for denoising as outlined next. 1 Specifically, let us assume that we have a pre-trained DDPM [26] model that represents the data distribution x 0 \u223c p data (x). The forward process of this model is represented using a Markov chain of length T , such that:\nx t = 1 \u2212 \u03b2 t x t\u22121 + \u03b2 t t ,(3)\nwhere t \u223c N (0, I) is the normal distribution, and t = 1, 2, . . . , T . The constants \u03b2 t , known as variance schedules, are selected such that x T \u223c N (0, I). As can be seen, the forward process in Equation (3) gradually adds noise to the data until it is transformed into Gaussian noise. If we set \u03b1 t := t s=1 (1 \u2212 \u03b2 s ), then this Markov process can also be performed via a single step [26]:\nx t = \u221a \u03b1 t x 0 + \u221a 1 \u2212 \u03b1 t .(4)\nThe reverse of this process is also a variational Markov chain which is represented by:\nx t\u22121 = 1 \u221a 1 \u2212 \u03b2 t (x t + \u03b2 t s \u03c6 (x t , t)) + \u03b2 t t .(5)\nHere, s \u03c6 (\u00b7, t) is a network parameterized by \u03c6 representing the score of the noisy data distribution at scale t [52].\n\nTo cancel the effects of the data-protecting perturbations, we propose to first add Gaussian noise to the data. The amount of noise should be adjusted in a way that each image maintains its visual appearance. Otherwise, the semantic information of each image would be lost, and since the reverse process is probabilistic, the original image might not be recovered.\n\nIn particular, letx be a protected image. We perform the forward process up to a step t * < T such that the semantic information of the image is preserved:\nx t * = \u221a \u03b1 t * x + \u221a 1 \u2212 \u03b1 t * .(6)\nNow, we have managed to diminish the effects of the dataprotecting perturbation in x t * . However, this way we would also damage the semantic features of the data which makes it hard to train a neural network model (see the ablation study in Figure 4). To revert to the normal image space, we use the reverse process of our diffusion model to denoise the data:\nx t\u22121 = 1 \u221a 1 \u2212 \u03b2 t (x t + \u03b2 t s \u03c6 (x t , t)) + \u03b2 t t .(7)\nRecursively solving Equation (7) from t * to 1, we get a denoised version of the data which we denote byx =x 0 . Using this process, shown in Figure 2, we denoise the entire dataset D pr , and construct a new one D de = {(x (i) , y (i) )} for neural network training. Algorithm 1 shows our final algorithm for training a neural network using AVATAR.\n\n\nSetting t * in AVATAR\n\nSo far, we discussed how by adding controlled a amount of Gaussian noise through the forward diffusion process we can nullify the effects of the data-protecting perturbations. Here, we take a theoretical perspective on our proposed solution, AVATAR. Specifically, the following theorem indicates that canceling perturbations with a larger magnitude Algorithm 1 dAta aVailAbiliTy Attacks defuseR\nInput: protected dataset Dpr = {(x (i) , y (i) )} n i=1 , pre-trained dif- fusion model s \u03c6 (\u00b7, t).\nOutput: trained neural network classifier f \u03b8 (\u00b7). Parameters: noise time-step t * , learning rate \u03b1, total epochs E, and batch-size b.\n1: Initialize \u03b8 randomly. 2: Set D de = {}. 3: for (x, y) in Dpr do 4: Add noise:xt * = \u221a \u03b1t * x + \u221a 1 \u2212 \u03b1t * . 5:\nDenoise data:\nx t\u22121 = 1 \u221a 1\u2212\u03b2 t x t + \u03b2ts \u03c6 (xt, t) + \u221a \u03b2t t.\n\n6:\n\nAdd (x, y) to the dataset D de . 7: end for 8: for i = 1, 2, . . . , E do 9:\n\nAssign D de to batches of size b randomly. 10: for batch in batches do 11: \u03b8 \u2190 SGD (batch, f \u03b8 , \u03b1).\n\n\n12:\n\nend for 13: end for requires adding more noise. This, however, comes at the cost of greater distortion in the final, denoised image which makes it harder to learn a classifier. As a result, care must be taken when setting the forward diffusion step t * .\n\nTheorem 1. Let x \u2208 R d denote a clean image and x = x + \u03b4 its protected version. Also, letx 0 be the sanitized image using the AVATAR denoising process given in Equations (6) and (7). If we set t * such that\n2 log 2 \u03b4 2 + 4d \u00b5\u2206 \u2264 t * \u03b2 t * \u2264 \u00b5\u2206 4d ,\nthen the estimation error between the sanitizedx 0 and clean image x can be bounded as:\nE x 0 \u2212 x 2 \u2264 2(\u00b5 + 1)\u2206, where \u2206 = E[ x 0 \u2212 x 2 ].\nProof. See Appendix A for our proof based on the contraction property of stochastic difference equations [40].\n\nAs Theorem 1 states, for a protected image with a larger perturbation norm \u03b4 , a larger amount of noise (determined by t * \u03b2 t * ) is required. However, the amount of noise cannot be arbitrarily large as the semantic information of the image might be lost in the process (as indicated by the presence of \u2206 in the upper-bound).\n\nFrom the perspective of availability attacks, this result indicates that for a better data protection against AVATAR, we need larger perturbation norms. However, enlarging the perturbation is in contradiction with retaining data utility which is the ultimate aim of availability attacks as discussed in Section 3.2. This means that the conditions of availability attacks might be in contradiction with each other. We leave the further investigation of this line of research to future work.\n\n\nAVATAR vs. Adversarial Training\n\nAs Tao et al.\n\n[55] have demonstrated, adversarial training (AT) [36] could also be used to train successful models over unexploitable data. However, our approach has several key advantages compared to AT:\n\n(1) First, AT modifies the learning algorithm, and as such, it needs to be applied separately for training each neural network. In contrast, AVATAR sanitizes the data only once. Once the data is purified, it can be used for training as many neural networks as wanted. As a result, AVATAR is more efficient.\n\n(2) Second, as shown by Tsipras et al.\n\n[58], AT might sacrifice the clean accuracy in its learning process, and as such, might not be the ultimate method for defending against availability attacks.\n\n(3) Lastly, as Fu et al. [16] show, one can build unexploitable data against AT that would essentially render AT vulnerable to availability attacks.\n\n\nExperimental Results\n\nIn this section, we run various experiments to analyze the performance of AVATAR against availability attacks. As our results show, AVATAR can effectively eliminate availability attacks, and it achieves the SOTA performance.\n\nSettings. For our experiments, we consider four standard datasets: CIFAR-10 & 100 [31], SVHN [38], and a subset of ImageNet (IN) [44] with 100 classes. Using seven SOTA availability attacks, including DeepConfuse (CON) [13], Neural Tangent Generalization Attacks (NTGA) [66], Error-minimizing Noise (EMN) [28], Targeted Adversarial Poisoning (TAP) [15], Robust EMN (REMN) [16], Shortcut (SHR) [17], and Autoregressive attacks (AR) [45] we create a protected version of the above-mentioned datasets. 2 Then, we use AVATAR to sanitize the training set. To this end, we use pre-trained diffusion models (score-SDE [52] for CIFAR-10, CIFAR-100, and SVHN, guided DDPM [9] for ImageNet) to denoise the protected data. The Fr\u00e9chet Inception Distance (FID) [23] of the models used for denoising is given in Table 8 of the Appendix. After the denoising process is done, we train neural network classifiers over the denoised dataset and compare their performance against the protected training. We use several neural network architectures such as ResNet-18 (RN-18) [22], VGG-16 [47],  Exploiting Protected Data. Table 1 shows our results for breaking availability attacks against RN-18 models for four different datasets. As can be seen, AVATAR can significantly improve the performance of neural network training in almost all cases. Moreover, although the training data was produced using diffusion models, the trained neural networks can generalize to unseen test data easily. This trend is more evident in the CIFAR-10 and SVHN datasets where the pre-trained diffusion model can better represent the image data density, as indicated by their low FID scores. Our results also indicate that the SHR [65] method is a simple yet powerful method that can resist our approach more than any other type of availability attack. For more details, please see Appendix D.\n\nComparison with Data Augmentation Techniques. AVATAR can be regarded as a type of data pre-processing where the inner mechanics of the learning algorithms are not modified. As such, here we compare our approach with various SOTA data augmentation techniques that can be utilized during model training. To this end, we follow the settings of [28], and adopt four widely used data augmentation techniques. Table 2 shows the performance of these approaches compared to AVATAR. As shown, our approach outperforms various types of data augmentation.\n\nThe Effect of Early Stopping. It has been previously shown that early stopping can also be beneficial against availability attacks [28]. As such, here we run the same set of experiments over availability attacks for the CIFAR-10 dataset, but this time we record the highest accuracy attainable during training. Table 3 shows our results. As seen, using our approach one achieves stable training, where the variance between the final model accuracy and the highest attainable accuracy is very low. Notably, while these results  indicate that existing availability attacks are less powerful than what is thought, early stopping is not sufficient to recover the best model performance. In contrast, our approach can significantly cancel the effects of availability attacks.\n\nComparison with Adversarial Training. As mentioned in Section 2, adversarial training (AT) [36] is the most successful defense technique against availability attacks [55]. For the next set of experiments, we follow the settings of Fu et al. [16] and compare our approach with AT. To this end, we run two different scenarios. First, we perform AT over the protected data. Then, we run AT over the data that is defused by AVATAR. In both cases, we vary the perturbation bound \u03b5 from 0 to 4, where 0 is the vanilla training. Figure 3 shows our results. Apart from what we discussed in Section 3.4, two additional insights are worth mentioning here:\n\n(1) In most cases, AVATAR without AT (i.e., \u03b5 = 0) performs on-par or better than AT with \u03b5 > 0. Thus, AVATAR delivers the SOTA against availability attacks.\n\n(2) As seen in Figure 3, AT yields the worst performance against REMN [16]. However, our approach can combat REMN [16] successfully, and it is the first approach that does so.\n\n\nSetting Diffusion\n\nStep t * . As discussed in Section 3.3, setting the diffusion timestep should be performed care-fully. Otherwise, either the data-protecting noise is not eliminated, or the semantic information of the image is lost. In this section, we run an ablation study over the diffusion timestep. In particular, for our CIFAR-10 experiments, we run AVATAR with five different timesteps from {0, 0.1, 0.2, 0.3, 0.4}. Then, we measure the test accuracy of the trained neural networks over the clean test set. As shown in Figure 4, setting t * too small means that the dataprotecting perturbations are not removed. In contrast, setting t * to a large value might remove of the semantic information which in turn damages the generalizability of the trained model.\n\nDistribution Mismatch. Next, we show that AVATAR is somehow resilient to a distribution mismatch between the diffusion model and the training data. In particular, we train three diffusion models over the protected CIFAR-10 dataset with TAP [15], IN-10 which contains 10 classes of Ima-geNet that are most similar to CIFAR-10 dataset [28] (see Table 5 for more details), and CIFAR-100. Then, we use these surrogate distributions to sanitize protected CIFAR-10 data and train a neural network over the denoised data. We report our results in Table 4. Surprisingly, our approach can tolerate the distribution mismatch to some extent. As the diffusion model density gets closer to the true training data, the performance gap is gradually closed. Interestingly, even using a diffusion model that is trained over protected data can be beneficial in removing the effects of availability  attacks. Note that according to our threat model discussed in Figure 1, this case is too extreme, meaning that the data protector needs to add a perturbation to all the data on the web which is almost impossible.\n\nA Real-world Example. As for a real-world example of AVATAR, we use the facial recognition example given in Huang et al. [28]. As discussed in Figure 1, although an online exploiter might not have access to the unprotected photos of a social media user, they can use large pre-trained models to defuse the data-protecting perturbations. Here, we follow the settings of Huang et al. [28] and aim to train a facial recognition classifier over the WebFace dataset [63]. Like Huang et al. [28], we assume that 50 users are protecting photos using availability attacks, and the rest of the 10522 identities in the WebFace dataset are intact. To make this scenario close to a real-world case, we assume that the unauthorized entity in Figure 1 does not have access to the WebFace data and the underlying diffusion model was trained over CelebA [35] only. Then, the exploiter denoises the protected data before training a facial recognition model with InceptionResNet architecture [53]. Our results Figure 5: Test accuracy for protected vs. clean identities in WebFace [63] facial recognition. The protected users add EMN [28] perturbations to protect their images. Our approach uses a diffusion model trained over CelebA [35] dataset. For more details, please see Appendix D.\n\nare given in Figure 5. As seen, AVATAR can significantly enhance the performance of the protected classes. This endorses our claim that in the era of diffusion models, protecting personal data is challenging and requires further efforts to achieve it.\n\n\nConclusion\n\nIn this paper, we introduced a countermeasure against data protection algorithms that use availability attacks. In particular, we show that by adding a controlled amount of Gaussian noise to the images and subsequently denoising them one can eliminate data-protecting perturbations. To this end, we use the forward and reverse diffusion processes of pre-trained models. We theoretically analyze our approach and show that the amount of Gaussian noise required to defuse the data-protecting perturbations is directly related to their norm. We conduct extensive experiments over various availability attacks. Our experiments demonstrate the superiority of our approach compared to adversarial training, setting a new SOTA defense against availability attacks. AVATAR demonstrates brittleness of availability attacks and calls for more research to protect personal data. \n\n\nA. Proofs\n\nHere we provide our proof for Theorem 1. First, we provide the theoretical results that would be used in our proof. Then, we re-state Theorem 1 and provide its detailed proof. Our proofs heavily borrow from the contraction properties of stochastic difference equations [40,41,5].\n\nTheorem 2 (Discrete stochastic contraction [40,5]). Let\nx t\u22121 = h(x t , t) + \u03c3(x t , t) t ,(8)\ndenote a stochastic difference equation where:\n\n(a) h : R d \u00d7 N \u2192 R d is a contraction mapping, i.e., for every t \u2208 N there exists a \u03bb t \u2208 [0, 1) such that\nh(x, t) \u2212 h(y, t) \u2264 \u03bb t x \u2212 y \u2200 x, y \u2208 R d ,(9)(b) \u03c3 : R d \u00d7 N \u2192 R is a function such that for every t \u2208 N and x \u2208 R d Tr \u03c3(x, t)I\u03c3(x, t) \u2264 C t ,(10)\n(c) and t \u223c N (0, I).\n\nThen, for two sample trajectories x t\u22121 andx t\u22121 that satisfy Equation (8) we have:\nE x t\u22121 \u2212x t\u22121 2 \u2264 \u03bb 2 t E x t \u2212x t 2 + 2C t .(11)\nUsing Theorem 2 and Equation (5) we can get the following result [5].\n\nCorollary 2.1. The reverse diffusion process of DDPMs are contracting stochastic difference equations.\n\nProof. Our proof closely follows that of Chung et al. [5]. Specifically, we need to show that for the reverse diffusion process given in Equation (5), the conditions of Equations (9) and (10) hold. To show this, note that if we set:\nh(x t , t) = 1 \u221a 1 \u2212 \u03b2 t (x t + \u03b2 t s \u03c6 (x t , t))\nand \u03c3(x t , t) = \u03b2 t then Equations (5) and (8) coincide. Using Lemma A.1. from Chung et al. [5], one can show that for\n\u03bb t = 1 \u2212 \u03b2 t 1 \u2212 \u03b1 t\u22121 1 \u2212 \u03b1 t(12)\nand\nC t = d\u03b2 t(13)\nthe conditions of Equations (9) and (10) are satisfied. As such, for two reverse sample trajectories x t\u22121 andx t\u22121 that satisfy the reverse diffusion process of Equation (5), Equation (11) holds.\n\nNext, we present two lemmas that are going to be used in our proof of Theorem 1.\n\n\nLemma 1 ([5]\n\n). For \u03bb t 's given in Equation (12) the following holds:\nt * s=1 \u03bb 2 s \u2264 exp(\u2212 t * \u03b2 t * 2 ).(14)\nProof. See Lemma C.1. in [5].\n\nLemma 2. For two random vectors x and y we have:\nE x + y 2 \u2264 2 E x 2 + 2 E y 2 .(15)\nProof. We know that:\nE x + y 2 = E x 2 + E y 2 + 2 E x y \u2264 2 E x 2 + 2 E y 2 ,\nwhere the last inequality follows from the fact that E x \u2212 y 2 \u2265 0.\n\nWe are now ready to prove our theoretical result.\n\nTheorem 1 (restated). Let x \u2208 R d denote a clean image andx = x + \u03b4 its protected version. Also, letx 0 be the sanitized image using the AVATAR denoising process given in Equations (6) and (7). If we set t * such that\n2 log 2 \u03b4 2 + 4d \u00b5\u2206 \u2264 t * \u03b2 t * \u2264 \u00b5\u2206 4d ,\nthen the estimation error between the sanitizedx 0 and clean image x can be bounded as:\nE x 0 \u2212 x 2 \u2264 2(\u00b5 + 1)\u2206, where \u2206 = E[ x 0 \u2212 x 2 ].\nProof. We are looking to find an upper-bound for the estimation error between the sanitized image and its clean version. Using Lemma 2 we can write:\nE x 0 \u2212 x 2 = E (x 0 \u2212 x 0 ) + (x 0 \u2212 x) 2 \u2264 2 E x 0 \u2212 x 0 2 + 2 E x 0 \u2212 x 2 \u2264 2 E x 0 \u2212 x 0 2 + 2 \u2206.(16)\nNow, we need to find an upper-bound for the first term. To this end, we are going to use the contraction property of the DDPMs (Corollary 2.1). In particular, given the noisy versions of the clean x and the protected imagex = x + \u03b4, in other words:\nx t * = \u221a \u03b1 t * x + \u221a 1 \u2212 \u03b1 t * 0 x t * = \u221a \u03b1 t * x + \u221a 1 \u2212 \u03b1 t * 0 ,(17)\nwe know that both x 0 andx 0 satisfy the reverse diffusion process, or:\nx t\u22121 = 1 \u221a 1 \u2212 \u03b2 t (x t + \u03b2 t s \u03c6 (x t , t)) + \u03b2 t t x t\u22121 = 1 \u221a 1 \u2212 \u03b2 t (x t + \u03b2 t s \u03c6 (x t , t)) + \u03b2 t t , \u2200 t \u2208 {1, 2, . . . , t * },(18)\nwhere t , t \u223c N (0, I). As such, we can treat x 0 andx 0 as two sample trajectories of the same stochastic difference equation. Thus, by recursively applying Equation (11) we would get:\nE x 0 \u2212 x 0 2 \u2264 E x t * \u2212 x t * 2 t * s=1 \u03bb 2 s + 2 t * s=1 C s s\u22121 r=1 \u03bb 2 r .(19)\nNow, let us consider each term on the RHS of Equation (19) separately. For the red term, we can write:\nE x t * \u2212 x t * 2 (1) = E \u221a \u03b1 t * (x \u2212 x) + \u221a 1 \u2212 \u03b1 t * ( 0 \u2212 0 ) 2 (2) = E \u221a \u03b1 t * \u03b4 + \u221a 1 \u2212 \u03b1 t * ( 0 \u2212 0 ) 2 = \u221a \u03b1 t * \u03b4 2 + E \u221a 1 \u2212 \u03b1 t * ( 0 \u2212 0 ) 2 + 2 \u221a \u03b1 t * \u221a 1 \u2212 \u03b1 t * \u03b4 E [ 0 \u2212 0 ] (3) = \u03b1 t * \u03b4 2 + (1 \u2212 \u03b1 t * )E ( 0 \u2212 0 ) 2 .(20)\nwhere (1) is derived from Equation (17), (2) holds sincex = x + \u03b4, and (3) is valid as 0 , 0 \u223c N (0, I). Given that:\n0 \u2212 0 \u223c N (0, 2I)\n, we can simplify Equation (20) as:\nE x t * \u2212 x t * 2 = \u03b1 t * \u03b4 2 + 2(1 \u2212 \u03b1 t * )E [\u03c7] ,\nwhere \u03c7 follows the chi-squared distribution with d degrees of freedom. Using the fact that 0 < \u03b1 t * < 1, we can finally write:\nE x t * \u2212 x t * 2 = \u03b1 t * \u03b4 2 + 2(1 \u2212 \u03b1 t * )d \u2264 \u03b4 2 + 2d.(21)\nUsing Lemma 1, for the blue term in Equation (19) we can write:\nt * s=1 \u03bb 2 s \u2264 exp(\u2212 t * \u03b2 t * 2 ).(22)\nFinally, for the green term we have:\n2 t * s=1 C s s\u22121 r=1 \u03bb 2 r (1) = 2 t * s=1 d\u03b2 s s\u22121 r=1 \u03bb 2 r (2) \u2264 2 t * s=1 d\u03b2 s (3) \u2264 2dt * \u03b2 t * .(23)\nHere, (1) is the result of Equation (13), (2) holds since 0 < \u03bb r < 1 (see Equation (12)), and (3) is derived from 0 < \u03b2 1 < \u00b7 \u00b7 \u00b7 < \u03b2 t < 1.\n\nPutting Equations (21) to (23) together, we have:\nE x 0 \u2212 x 0 2 \u2264 \u03b4 2 + 2d exp(\u2212 t * \u03b2 t * 2 ) + 2dt * \u03b2 t * .(24)\nGiven that:\n2 log 2 \u03b4 2 + 4d \u00b5\u2206 \u2264 t * \u03b2 t * \u2264 \u00b5\u2206 4d ,\nwe can simplify Equation (24) as:\nE x 0 \u2212 x 0 2 \u2264 \u03b4 2 + 2d exp(\u2212 t * \u03b2 t * 2 ) + 2dt * \u03b2 t * \u2264 \u03b4 2 + 2d \u00b5\u2206 2 \u03b4 2 + 4d + 2d \u00b5\u2206 4d \u2264 \u00b5\u2206.(25)\nReplacing Equation (25) into Equation (16), the proof can be completed.\n\n\nB. Extended Related Work\n\nIn this section, we provide the rest of our related work that was omitted due to space limits.\n\nPoisoning and Attacks. A considerable number of studies have been published on various types of data poisoning attacks [3,46,18]. These attacks aim to pollute the training data so that they can hinder the performance of the machine learning model at test-time [2,30,37]. While these methods are quite successful in achieving this goal, they often tend to perform weakly against neural networks [37] and appear to be distinguishable from the clean samples, damaging the utility of the underlying data [62]. Backdoor attacks are a popular family of data poisonings against deep neural networks [21,1,57,10]. Unlike general poisoning attacks, these methods attach triggers to a small fraction of the clean training data so that the model creates an association between the existence of the trigger and a particular class. During inference, the neural network would behave normally on benign samples. However, if the trigger is activated, the model would output the attacker's desired value due to the existence of a backdoor in the model.\n\nDiffusion Models. As mentioned in Section 2, diffusion models are an emerging family of deep generative models with great capabilities in various domains. For the vision domain, the forward and backward processes can be defined in three different ways [6]. Song and Ermon [50] gradually add Gaussian noise to the image to create noisy versions of the data at different noise scales. They then utilize score-matching [59] to find a Noise Conditioned Score Network (NCSN) at various noise levels that can give an approximation of the ground-truth density score. In this framework, the reverse process uses Langevin dynamics [60] to give samples of the data distribution. Closely related to NCSNs, Ho et al. [26] propose to model the forward and backward processes using Markov chains [49]. Each step of the forward process comprises of adding a controlled amount of noise to the image. If the forward process is repeated for many steps, then the image is completely transferred to random Gaussian noise. The reverse process is also a Markov chain, where a neural network (known as a denoiser) is used for iterative sampling. Finally, Song et al.\n\n[52] model the forward and reverse processes through stochastic differential equations (SDE), and use existing differential solvers to find the solutions of the SDEs. It can be shown that these three methods are closely related [52].\n\n\nC. Details of Experimental Settings\n\nIn this section, we provide the details of our experimental settings.\n\nDatasets. In our experiments, we use four different datasets. CIFAR-10 & 100 [31] are 32 \u00d7 32 datasets of colored images, where the classes contain different objects, animals, plants, etc. SVHN [38] is a dataset of house numbers from 0 to 9 in a natural, street view setting. Finally, ImageNet [44] is a dataset of natural images of size 224 \u00d7 224 with 1000 classes. In our experiments, we use two simplified versions of this dataset. First, following the convention of prior research, we select the first 100 classes of this dataset, which we refer to as ImageNet (IN)-100. Second, for our distribution mismatch experiments, we follow Huang et al. [28] and select 10 classes of ImageNet that are closely aligned with CIFAR-10 and downscale them to 32 \u00d7 32 size. We call this dataset IN-10. The information on the selected classes can be found in Table 5.  [27], and WideResNet-34 (WRN-34) [68]. For training these classifiers over different datasets and also training objectives (vanilla vs. adversarial training (AT)), we follow two different training conventions. The hyper-parameters of each setting are given in Table 6. Furthermore, Table 7 indicates the setting used for each experiment in the paper.   Tables 1 and 9 (CIFAR-10)  -Tables 1 and 9 (CIFAR-100) - Tables 1 and 9 (SVHN)  -Tables 1 and 9 (IN-100) - Table 2 - Table 3 - Table 4 - Figures 4 and 8 - Figures 3 and 9 -Diffusion Models. For the diffusion models of AVATAR, we follow the implementation of DiffPure 3 and use score SDE [52] (for CIFAR-10, CIFAR-100, SVHN, IN-10) and the guided DDPM (for IN-100) [9]. For CIFAR-10 and IN-100, we download the pre-trained versions available online. 4 Additionally, for CIFAR-100, IN-10, and SVHN we use the PyTorch repository of score SDE [52], and train variance-preserving diffusion models with continuous DDPM++ architecture, similar to the one used for CIFAR-10. The FID score of the trained diffusion models is given in Table 8.   Denoised Image (c) REMN [28] Perturbation Protected Image Denoised Image (d) SHR [65] Figure 10: Samples from the WebFace [63] dataset. In each case, we generate the data-protecting perturbations with a maximum magnitude of 16/255. For denoising, we use AVATAR based on a diffusion model pre-trained on the CelebA [35] dataset. As seen, the SHR [65] perturbations leave a noticeable pattern over the protected data, which put their utility (e.g., posting over the social media) under question. Nevertheless, since they have a more global structure, they remain persistent even after denoising. Figure 11: Test accuracy for protected vs. clean identities in WebFace [63] facial recognition. The protected users protect their images using data-protecting perturbations. Our approach uses a diffusion model trained over the CelebA [35] dataset. As seen, for all the stealthy data-protecting perturbations our approach manages to recover the performance over protected data. The only exception is SHR, which according to Figure 10, leaves a noticeable trace over the image, rendering them not useful anymore.\n\nFigure 2 :\n2Overview of AVATAR.\n\nFigure 3 :\n3Test accuracy of different image classifiers against availability attacks using AT with varying perturbation radii. Best viewed electronically.\n\nFigure 4 :\n4Effect of changing the forward process diffusion timestep in AVATAR on the final test accuracy in CIFAR-10 RN-18 classifiers. For a comparison between different architectures, please see Figure 8 in Appendix D.\n\nFigure 8 :Figure 9 :\n89Effect of changing the forward process diffusion timestep in AVATAR on the final test accuracy in CIFARTest accuracy of CIFAR-10, SVHN, and CIFAR-100 classifiers against availability attacks using adversarial training with different perturbation radii.\n\nTable 1 :\n1Test accuracy (%) of RN-18 classifiers trained over data availability attacks on CIFAR-10, CIFAR-100, SVHN, and ImageNet-100 datasets without and with our denoising approach. The results are averaged over 5 runs. The best results are highlighted in bold.Data \nClean \nMethod \nData Availability Attacks \n\nNTGA [66] \nEMN [28] \nTAP [15] \nREMN [16] \nSHR [65] \nAR [45] \n\nCIFAR-10 94.50 \u00b1 0.09 \nVanilla \n11.49 \u00b1 0.69 24.85 \u00b1 0.71 7.86 \u00b1 0.90 20.50 \u00b1 1.16 10.82 \u00b1 0.22 12.09 \u00b1 1.12 \n\nAVATAR (Ours) 87.95 \u00b1 0.28 90.95 \u00b1 0.10 90.71 \u00b1 0.19 88.49 \u00b1 0.24 85.69 \u00b1 0.27 91.57 \u00b1 0.18 \n\nSVHN 96.29 \u00b1 0.12 \nVanilla \n9.65 \u00b1 0.70 9.13 \u00b1 2.00 65.97 \u00b1 1.99 11.55 \u00b1 0.19 10.59 \u00b1 3.98 6.76 \u00b1 0.07 \n\nAVATAR (Ours) 89.84 \u00b1 0.32 93.84 \u00b1 0.12 93.35 \u00b1 0.10 88.51 \u00b1 0.23 83.82 \u00b1 0.39 94.13 \u00b1 0.17 \n\nCIFAR-100 75.01 \u00b1 0.41 \nVanilla \n1.32 \u00b1 0.31 2.05 \u00b1 0.18 14.10 \u00b1 0.19 10.88 \u00b1 0.33 1.39 \u00b1 0.10 2.15 \u00b1 0.46 \n\nAVATAR (Ours) 63.98 \u00b1 0.55 65.73 \u00b1 0.36 64.99 \u00b1 0.10 64.88 \u00b1 0.08 58.52 \u00b1 0.46 64.54 \u00b1 0.23 \n\nIN-100 80.05 \u00b1 0.13 \nVanilla \n74.74 \u00b1 0.52 1.78 \u00b1 0.17 9.14 \u00b1 0.40 13.28 \u00b1 0.51 43.48 \u00b1 1.56 \n\u2212 \nAVATAR (Ours) 71.08 \u00b1 0.48 72.84 \u00b1 0.90 76.52 \u00b1 0.46 39.79 \u00b1 0.98 59.85 \u00b1 1.01 \n\n\n\nTable 2 :\n2Test accuracy (%) of RN-18 models trained over data availability attacks on CIFAR-10 dataset using different data augmentation/pre-processing techniques. The results are averaged over 5 runs. The best results are highlighted in bold.Method \nClean \nData Availability Attacks \n\nCON [13] \nNTGA [66] \nEMN [28] \nTAP [15] \nREMN [16] \nSHR [65] \nAR [45] \n\nVanilla \n\n94.50 \u00b1 0.09 \n\n15.75 \u00b1 0.82 11.49 \u00b1 0.69 24.85 \u00b1 0.71 7.86 \u00b1 0.90 20.50 \u00b1 1.16 10.82 \u00b1 0.22 12.09 \u00b1 1.12 \n\nCutout [8] \n13.53 \u00b1 0.34 13.43 \u00b1 1.15 23.79 \u00b1 1.28 9.73 \u00b1 1.06 20.48 \u00b1 1.09 11.78 \u00b1 0.81 11.21 \u00b1 1.01 \n\nMixUp [69] \n28.58 \u00b1 2.88 13.54 \u00b1 0.36 51.48 \u00b1 0.97 30.09 \u00b1 1.93 26.61 \u00b1 1.65 19.69 \u00b1 0.71 12.67 \u00b1 1.02 \n\nCutMix [67] \n19.04 \u00b1 2.74 14.16 \u00b1 1.64 25.30 \u00b1 1.18 7.45 \u00b1 1.21 26.83 \u00b1 1.99 10.89 \u00b1 0.34 11.36 \u00b1 0.50 \n\nFAutoAug. [32] \n51.62 \u00b1 1.28 27.56 \u00b1 2.45 56.31 \u00b1 1.13 20.39 \u00b1 0.81 26.65 \u00b1 0.89 25.88 \u00b1 0.62 13.53 \u00b1 0.79 \n\nAVATAR (Ours) \n89.43 \u00b1 0.09 87.95 \u00b1 0.28 90.95 \u00b1 0.10 90.71 \u00b1 0.19 88.49 \u00b1 0.24 85.69 \u00b1 0.27 91.57 \u00b1 0.18 \n\nDenseNet-121 (DN-121) [27], and WideResNet-34 (WRN-\n34) [68] as our classifier. For a detailed account of our set-\ntings, please see Appendix C. Here, we only present our \nresults for RN-18 models, and the extended version of our \nresults for other architectures can be found in Appendix D. \n\n\n\nTable 3 :\n3Test accuracy (%) of RN-18 models trained over data availability attacks on CIFAR-10 dataset. The early stopping rows contain the highest achievable accuracy over the course of training. The results are averaged over 5 runs.Method \nClean \nData Availability Attacks \n\nCON [13] \nNTGA [66] \nEMN [28] \nTAP [15] \nREMN [16] \nSHR [65] \nAR [45] \n\nVanilla \n\n94.50 \u00b1 0.09 \n\n15.75 \u00b1 0.82 11.49 \u00b1 0.69 24.85 \u00b1 0.71 7.86 \u00b1 0.90 20.50 \u00b1 1.16 10.82 \u00b1 0.22 12.09 \u00b1 1.12 \n\n+ Early Stopping \n23.99 \u00b1 6.22 31.71 \u00b1 3.97 27.23 \u00b1 1.83 67.13 \u00b1 2.03 21.90 \u00b1 0.57 22.72 \u00b1 0.83 38.78 \u00b1 8.65 \n\nAVATAR (Ours) \n89.43 \u00b1 0.09 87.95 \u00b1 0.28 90.95 \u00b1 0.10 90.71 \u00b1 0.19 88.49 \u00b1 0.24 85.69 \u00b1 0.27 91.57 \u00b1 0.18 \n\n+ Early Stopping \n89.55 \u00b1 0.15 88.07 \u00b1 0.22 91.07 \u00b1 0.11 91.00 \u00b1 0.11 88.59 \u00b1 0.26 85.76 \u00b1 0.25 91.63 \u00b1 0.17 \n\n\n\nTable 4 :\n4Test accuracy (%) of RN-18 models trained over data availability attacks on the CIFAR-10 dataset. For AVATAR, we use different pre-trained distributions over CIFAR-10, poisoned CIFAR-10 (TAP), ImageNet-10 (IN-10)[28], and CIFAR-100. The results are averaged over 5 runs.Distribution \nClean \nData Availability Attacks \n\nCON [13] \nNTGA [66] \nEMN [28] \nTAP [15] \nREMN [16] \nSHR [65] \nAR [45] \n\nVanilla \n\n94.50 \u00b1 0.09 \n\n15.75 \u00b1 0.82 11.49 \u00b1 0.69 24.85 \u00b1 0.71 7.86 \u00b1 0.90 20.50 \u00b1 1.16 10.82 \u00b1 0.22 12.09 \u00b1 1.12 \n\nCIFAR-10 (TAP) \n61.70 \u00b1 2.02 75.62 \u00b1 3.75 64.03 \u00b1 0.98 35.09 \u00b1 2.28 60.16 \u00b1 1.44 74.96 \u00b1 2.82 60.36 \u00b1 2.29 \n\nIN-10 \n80.98 \u00b1 0.06 79.42 \u00b1 0.25 83.78 \u00b1 0.39 82.71 \u00b1 0.24 82.83 \u00b1 0.28 75.91 \u00b1 0.06 84.88 \u00b1 0.19 \n\nCIFAR-100 \n84.85 \u00b1 0.49 83.07 \u00b1 0.33 87.81 \u00b1 0.14 86.55 \u00b1 0.26 85.84 \u00b1 0.19 79.52 \u00b1 0.22 88.59 \u00b1 0.15 \n\nCIFAR-10 \n89.43 \u00b1 0.09 87.95 \u00b1 0.28 90.95 \u00b1 0.10 90.71 \u00b1 0.19 88.49 \u00b1 0.24 85.69 \u00b1 0.27 91.57 \u00b1 0.18 \n\n\n\n\nlearning using nonequilibrium thermodynamics. In Proceedings of the 32nd International Conference on Machine Learning (ICML), pages 2256-2265, 2015. 3, 15 [50] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. In Advances in Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. Intriguing properties of neural networks. In Proceedings of the 2nd International Conference on Learning Representations (ICLR), 2014. 3 [55] Lue Tao, Lei Feng, Jinfeng Yi, Sheng-Jun Huang, and Songcan Chen. Better safe than sorry: Preventing delusive ad-Brandon Tran, Jerry Li, and Aleksander Madry. Spectral signatures in backdoor attacks. In Proceedings of the Ad-Neural Information Processing Systems 32: Annual Confer-\nence on Neural Information Processing Systems (NeurIPS), \npages 11895-11907, 2019. 3, 15 \n[51] Yang Song and Stefano Ermon. Improved techniques for \ntraining score-based generative models. In Advances in Neu-\nral Information Processing Systems 33: Annual Conference \non Neural Information Processing Systems (NeurIPS), pages \n12438-12448, 2020. \n[52] Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Ab-\nhishek Kumar, Stefano Ermon, and Ben Poole. Score-based \ngenerative modeling through stochastic differential equa-\ntions. In Procceding of the 9th International Conference on \nLearning Representations (ICLR), 2021. 3, 4, 5, 15, 16 \n[53] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and \nAlexander A. Alemi. Inception-v4, inception-resnet and the \nimpact of residual connections on learning. In Proceedings \nof the 31st AAAI Conference on Artificial Intelligence, pages \n4278-4284, 2017. 8, 20 \n[54] versaries with adversarial training. In Advances in Neu-\nral Information Processing Systems 34: Annual Conference \non Neural Information Processing Systems (NeurIPS), pages \n16209-16225, 2021. 3, 5, 7 \n[56] Qi Tian, Kun Kuang, Kelu Jiang, Furui Liu, Zhihua Wang, \nand Fei Wu. ConfounderGAN: Protecting image data privacy \nwith causal confounder. In Advances in Neural Information \nProcessing Systems 35: Annual Conference on Neural Infor-\nmation Processing Systems (NeurIPS), 2022. 1, 2, 3 \n[57] vances in Neural Information Processing Systems 31: An-\nnual Conference on Neural Information Processing Systems \n(NeurIPS), pages 8011-8021, 2018. 15 \n[58] Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, \nAlexander Turner, and Aleksander Madry. Robustness may \nbe at odds with accuracy. In Proceedings of the 7th Inter-\nnational Conference on Learning Representations (ICLR), \n2019. 5 \n[59] Pascal Vincent. A connection between score matching and \ndenoising autoencoders. Neural Computation, 23(7):1661-\n1674, 2011. 15 \n[60] Max Welling and Yee Whye Teh. Bayesian learning via \nstochastic gradient Langevin dynamics. In Proceedings \nof the 28th International Conference on Machine Learning \n(ICML), pages 681-688, 2011. 15 \n[61] Yilun Xu, Shangyuan Tong, and Tommi S. Jaakkola. Stable \ntarget field for reduced variance score estimation. In Pro-\nceedings of the 11th International Conference on Learning \nThe Devil's Advocate: \nShattering the Illusion of Unexploitable Data using Diffusion Models \n(Supplementary Materials) \n\n\n\nTable 5 :\n5The classes of CIFAR-10 and their matching ones in the ImageNet-10 dataset.Classifiers. In our experiments, we use four types of neural network image classifiers, namely: ResNet-18 (RN-18)[22], VGG-16[47], DenseNet-121 (DN-121)CIFAR-10 IN-10 \n\nAirplane \nAirliner \nAutomobile Wagon \nBird \nHumming Bird \nCat \nSiamese Cat \nDeer \nOx \nDog \nGolden Retriever \nFrog \nTailed Frog \nHorse \nZebra \nShip \nContainer Ship \nTruck \nTrailer Truck \n\n\n\nTable 6 :\n6Training hyper-parameters used in our experiments.Hyper-parameter \nSetting #1 \nSetting #2 \n\nOptimizer \nSGD \nSGD \nScheduler \nMulti-step \nMulti-step \nInitial lr. \n0.1 \n0.1 \nlr. decay \n0.1 (@epoch: 80 & 100) 0.1 (@iter: 16k & 32k) \nBatch Size \n128 \n128 \nTraining Steps \n120 (epochs) \n40k (iters) \nWeight Decay \n0.0005 \n0.0005 \nPGD Steps (for AT only) \n-\n10 \nPGD Step Size (for AT only) \n-\n0.8 \n\n\n\nTable 7 :\n7Setting number used for each experiment.Experiment \nSetting #1 Setting #2 \n\n\n\nTable 8 :\n8The FID of the diffusion models used for denoising. * denotes that the FID has been computed using 10k generated samples only. \u2020 indicates that the scores have been adapted from relative literature.Dataset \nFID \nDataset \nFID \n\nCIFAR-10  \u2020 \n2.41 \nSVHN * \n2.59 \n\nCIFAR-10 (TAP) * 4.11 CIFAR-100 * 4.85 \n\nIN-10 * \n17.32 \nIN  \u2020 \n4.59 \n\n\nTable 9 :\n9Test accuracy (%) of various neural network architectures trained over data availability attacks on CIFAR-10, CIFAR-100, SVHN, and ImageNet-100 datasets without and with our denoising approach. The mean and standard deviation are computed over 5 seeds.63 \u00b1 1.08 24.73 \u00b1 0.81 11.09 \u00b1 1.69 19.02 \u00b1 1.21 14.57 \u00b1 1.36 13.67 \u00b1 1.91 AVATAR 88.33 \u00b1 0.35 91.33 \u00b1 0.21 91.24 \u00b1 0.16 88.83 \u00b1 0.24 86.12 \u00b1 0.29 91.77 \u00b1 0.15 72 \u00b1 0.37 22.31 \u00b1 1.55 8.59 \u00b1 0.43 19.71 \u00b1 0.95 10.33 \u00b1 0.14 12.09 \u00b1 0.43 AVATAR 87.64 \u00b1 0.19 90.19 \u00b1 0.21 89.64 \u00b1 0.24 87.64 \u00b1 0.28 85.22 \u00b1 0.42 90.71 \u00b1 0.14 65 \u00b1 0.70 9.13 \u00b1 2.00 65.97 \u00b1 1.99 11.55 \u00b1 0.19 10.59 \u00b1 3.98 6.76 \u00b1 0.07 AVATAR 89.84 \u00b1 0.32 93.84 \u00b1 0.12 93.35 \u00b1 0.10 88.51 \u00b1 0.23 83.82 \u00b1 0.39 94.13 \u00b1 0.17 VGG-16 Vanilla 95.94 \u00b1 0.12 23.24 \u00b1 8.42 9.13 \u00b1 2.00 63.81 \u00b1 2.77 10.87 \u00b1 0.43 9.45 \u00b1 3.69 10.87 \u00b1 5.09 AVATAR 89.75 \u00b1 0.19 93.61 \u00b1 0.14 93.03 \u00b1 0.26 87.01 \u00b1 0.41 82.03 \u00b1 0.48 93.73 \u00b1 0.14 DN-121 Vanilla 96.47 \u00b1 0.12 19.06 \u00b1 5.84 30.49 \u00b1 5.53 69.04 \u00b1 1.80 11.48 \u00b1 2.09 10.54 \u00b1 3.45 10.23 \u00b1 3.64 AVATAR 90.52 \u00b1 0.13 94.39 \u00b1 0.24 94.05 \u00b1 0.18 88.76 \u00b1 0.53 84.35 \u00b1 0.71 94.61 \u00b1 0.10 24 \u00b1 8.42 18.57 \u00b1 7.00 70.72 \u00b1 1.23 18.10 \u00b1 10.17 6.84 \u00b1 0.15 9.04 \u00b1 2.47 AVATAR 90.26 \u00b1 0.16 94.29 \u00b1 0.12 94.01 \u00b1 0.28 89.34 \u00b1 0.35 83.50 \u00b1 0.47 94.60 \u00b1 0.12 32 \u00b1 0.31 2.05 \u00b1 0.18 14.10 \u00b1 0.19 10.88 \u00b1 0.33 1.39 \u00b1 0.10 2.15 \u00b1 0.46 AVATAR 63.98 \u00b1 0.55 65.73 \u00b1 0.36 64.99 \u00b1 0.10 64.88 \u00b1 0.08 58.52 \u00b1 0.46 64.54 \u00b1 0.23 VGG-16 Vanilla 72.03 \u00b1 0.06 1.16 \u00b1 0.03 1.94 \u00b1 0.19 15.25 \u00b1 0.57 9.11 \u00b1 0.54 1.57 \u00b1 0.33 2.42 \u00b1 0.38 AVATAR 62.00 \u00b1 0.34 63.60 \u00b1 0.26 62.69 \u00b1 0.21 62.38 \u00b1 0.30 56.38 \u00b1 0.41 62.27 \u00b1 0.34 DN-121 Vanilla 77.47 \u00b1 0.33 1.87 \u00b1 0.34 2.41 \u00b1 0.40 15.94 \u00b1 0.25 8.94 \u00b1 0.49 1.81 \u00b1 0.23 2.34 \u00b1 0.48 AVATAR 65.84 \u00b1 0.41 67.86 \u00b1 0.22 67.27 \u00b1 0.18 66.85 \u00b1 0.20 60.16 \u00b1 0.24 66.78 \u00b1 0.43 AVATAR 61.62 \u00b1 0.36 63.49 \u00b1 0.32 62.68 \u00b1 0.34 62.52 \u00b1 0.32 56.64 \u00b1 0.60 62.57 \u00b1 0.26 74 \u00b1 0.52 1.78 \u00b1 0.17 9.14 \u00b1 0.40 13.28 \u00b1 0.51 43.48 \u00b1 1.56 AVATAR 71.08 \u00b1 0.48 72.84 \u00b1 0.90 76.52 \u00b1 0.46 39.79 \u00b1 0.98 59.85 \u00b1 1.01 98 \u00b1 0.45 1.54 \u00b1 0.24 9.30 \u00b1 0.39 12.04 \u00b1 0.15 72.10 \u00b1 0.68 AVATAR 70.78 \u00b1 0.56 73.34 \u00b1 0.50 76.25 \u00b1 0.19 39.74 \u00b1 0.44 67.22 \u00b1 0.54 16 \u00b1 0.22 4.58 \u00b1 0.31 19.28 \u00b1 0.84 15.46 \u00b1 0.77 31.47 \u00b1 1.01 AVATAR 73.41 \u00b1 0.23 75.96 \u00b1 0.48 77.96 \u00b1 0.48 48.20 \u00b1 0.32 54.24 \u00b1 0.65 38 \u00b1 1.17 1.22 \u00b1 0.15 8.20 \u00b1 0.28 10.45 \u00b1 0.28 52.95 \u00b1 4.13 AVATAR 64.20 \u00b1 0.76 66.33 \u00b1 1.01 70.34 \u00b1 0.85 29.89 \u00b1 0.66 58.24 \u00b1 1.47Data \nModel \nMethod \nClean \nData Availability Attacks \n\nNTGA [66] \nEMN [28] \nTAP [15] \nREMN [16] \nSHR [65] \nAR [45] \n\nCIFAR-10 \n\nRN-18 \n\nVanilla \n94.50 \u00b1 0.09 \n11.49 \u00b1 0.69 24.85 \u00b1 0.71 7.86 \u00b1 0.90 20.50 \u00b1 1.16 10.82 \u00b1 0.22 12.09 \u00b1 1.12 \n\nAVATAR \n87.95 \u00b1 0.28 90.95 \u00b1 0.10 90.71 \u00b1 0.19 88.49 \u00b1 0.24 85.69 \u00b1 0.27 91.57 \u00b1 0.18 \n\nVGG-16 \n\nVanilla \n93.22 \u00b1 0.05 \n11.02 \u00b1 0.15 25.82 \u00b1 0.74 9.42 \u00b1 1.03 20.58 \u00b1 0.96 10.88 \u00b1 0.28 11.49 \u00b1 1.23 \n\nAVATAR \n87.13 \u00b1 0.27 89.71 \u00b1 0.16 89.38 \u00b1 0.17 87.17 \u00b1 0.22 84.74 \u00b1 0.30 90.21 \u00b1 0.15 \n\nDN-121 \n\nVanilla \n94.62 \u00b1 0.14 \n11.WRN-34 \n\nVanilla \n93.87 \u00b1 0.07 \n10.SVHN \n\nRN-18 \n\nVanilla \n96.29 \u00b1 0.12 \n9.WRN-34 \n\nVanilla \n96.35 \u00b1 0.07 \n23.CIFAR-100 \n\nRN-18 \n\nVanilla \n75.01 \u00b1 0.41 \n1.WRN-34 \n\nVanilla \n73.39 \u00b1 0.43 \n1.51 \u00b1 0.18 1.94 \u00b1 0.24 12.00 \u00b1 0.45 9.16 \u00b1 0.61 \n1.37 \u00b1 0.19 1.90 \u00b1 0.24 \n\nImageNet-100 \n\nRN-18 \n\nVanilla \n80.05 \u00b1 0.13 \n74.VGG-16 \n\nVanilla \n79.16 \u00b1 0.30 \n73.DN-121 \n\nVanilla \n79.66 \u00b1 0.25 \n75.WRN-34 \n\nVanilla \n74.46 \u00b1 0.52 \n68.\nNote that while here we use DDPMs[26] to demonstrate our method, it can be easily extended to other types of diffusion models as they are all different ways of representing the same process[52].\nFor CON[13] & AR[45], we only use their officially released data.\nhttps://github.com/NVlabs/DiffPure 4 For CIFAR-10, we used the checkpoint for the vp/cifar10 ddpmpp deep continuous setting on score SDE repository: https://github. com/yang-song/score_sde_pytorch. Moreover, we used the unconditional 256 \u00d7 256 model available on the guided DDPM code-base for IN: https://github.com/openai/guided-diffusion.\nAcknowledgements. This research was undertaken using the LIEF HPC-GPGPU Facility hosted at the University of Melbourne. This Facility was established with the assistance of LIEF Grant LE170100200. Sarah Erfani is in part supported by Australian Research Council (ARC) Discovery Early Career Researcher Award (DE-CRA) DE220100680.Availability Attacks. We use seven SOTA availability attacks in our experiments: DeepConfuse (CON)[13], Neural Tangent Generalization Attacks (NTGA)[66], Error-minimizing Noise (EMN)[28], Targeted Adversarial Poisoning (TAP)[15], Robust EMN (REMN)[16], Shortcut (SHR)[17], and Autoregressive attacks (AR)[45]. The details of each availability attack are given below:\u2022 For CON[13], we use the released protected CIFAR-10 dataset, available online at SHR[65]repository.5Note that since generating this attack for the CIFAR-10 dataset would take 5-7 days, we just used the available data for CIFAR-10 and skipped generating the attack for the other datasets.\u2022 For NTGA[66], we use their code 6 to generate availability attacks for our datasets. For CIFAR-10, we used the data published online. For CIFAR-100 and SVHN, we used the online repository, and generate NTGA protected data using the CNN surrogate model, time-step of 64, and block-size of 100 to generate perturbations of magnitude \u03b4 \u221e \u2264 8/255. Due to limited GPU memory, we used the FNN surrogate model to generate perturbations of magnitude \u03b4 \u221e \u2264 0.1 for IN-100. The rest of the hyper-parameters were set similarly to CIFAR-100 and SVHN.\u2022 For EMN[28], TAP[15], and REMN[16], we use the online repository of REMN 7 which contains an implementation of EMN and TAP as well. We use the default CIFAR-10 configurations of this repository for CIFAR-10, CIFAR-100, and SVHN. For IN-10, we used the default MiniIN configurations of the REMN code-base.\u2022 Moreover, we use the SHR GitHub repository 5 to generate shortcut attacks. For CIFAR-10, CIFAR-100, and SVHN, we use the default settings. For IN-100, we use patchsize of 32 as advised by the authors.\u2022 Finally, we use the official data released on the AR GitHub repository for this attack.8A few samples for each availability attack are shown inFigure 7.Pert. Pert.InputInputNoisy Denoised (b) TAP[15]Pert.InputNoisy Denoised (c) REMN[16]Pert.InputNoisy Denoised (d) SHR[65]Figure 7: Samples from IN-100 dataset. For each attack, we show the perturbation, the protected image, the noisy version of the image, and the denoised one using AVATAR.\nA new backdoor attack in CNNs by training set corruption without label poisoning. Mauro Barni, Kassem Kallas, Benedetta Tondi, Proceedings of the IEEE International Conference on Image Processing (ICIP). the IEEE International Conference on Image Processing (ICIP)15Mauro Barni, Kassem Kallas, and Benedetta Tondi. A new backdoor attack in CNNs by training set corruption with- out label poisoning. In Proceedings of the IEEE Interna- tional Conference on Image Processing (ICIP), pages 101- 105, 2019. 15\n\nPoisoning attacks against support vector machines. Battista Biggio, Blaine Nelson, Pavel Laskov, Proceedings of the 29th International Conference on Machine Learning (ICML). the 29th International Conference on Machine Learning (ICML)15Battista Biggio, Blaine Nelson, and Pavel Laskov. Poison- ing attacks against support vector machines. In Proceedings of the 29th International Conference on Machine Learning (ICML), pages 1467-1474, 2012. 15\n\nWild patterns: Ten years after the rise of adversarial machine learning. Pattern Recognition. Battista Biggio, Fabio Roli, 8415Battista Biggio and Fabio Roli. Wild patterns: Ten years af- ter the rise of adversarial machine learning. Pattern Recog- nition, 84:317-331, 2018. 1, 15\n\nLarge image datasets: A pyrrhic win for computer vision?. Abeba Birhane, Vinay Uday Prabhu, Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV). the IEEE Winter Conference on Applications of Computer Vision (WACV)Abeba Birhane and Vinay Uday Prabhu. Large image datasets: A pyrrhic win for computer vision? In Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV), pages 1536-1546, 2021. 1\n\nCome-closer-diffuse-faster: Accelerating conditional diffusion models for inverse problems through stochastic contraction. Hyungjin Chung, Byeongsu Sim, Jong Chul Ye, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)1213Hyungjin Chung, Byeongsu Sim, and Jong Chul Ye. Come-closer-diffuse-faster: Accelerating conditional diffu- sion models for inverse problems through stochastic contrac- tion. In Proceedings of the IEEE/CVF Conference on Com- puter Vision and Pattern Recognition (CVPR), pages 12403- 12412, 2022. 12, 13\n\nDiffusion models in vision: A survey. Florinel-Alin, Vlad Croitoru, Hondru, Tudor Radu, Mubarak Ionescu, Shah, Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion models in vision: A survey.\n\n. Corr, abs/2209.04747315CoRR, abs/2209.04747, 2022. 3, 15\n\nImageNet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Fei-Fei Li, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Fei-Fei Li. ImageNet: A large-scale hierarchical image database. In Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition (CVPR), pages 248- 255, 2009. 1\n\nImproved regularization of convolutional neural networks with cutout. Terrance Devries, Graham W Taylor, abs/1708.04552CoRR36Terrance Devries and Graham W. Taylor. Improved regular- ization of convolutional neural networks with cutout. CoRR, abs/1708.04552, 2017. 3, 6\n\nDiffusion models beat gans on image synthesis. Prafulla Dhariwal, Alexander Quinn, Nichol , Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems (NeurIPS). 516Prafulla Dhariwal and Alexander Quinn Nichol. Diffusion models beat gans on image synthesis. In Advances in Neu- ral Information Processing Systems 34: Annual Conference on Neural Information Processing Systems (NeurIPS), pages 8780-8794, 2021. 1, 3, 5, 16\n\nCOLLIDER: A robust training framework for backdoor data. M Hadi, Sarah M Dolatabadi, Christopher Erfani, Leckie, Proceedings of the 16th Asian Conference on Computer Vision (ACCV). the 16th Asian Conference on Computer Vision (ACCV)15Hadi M. Dolatabadi, Sarah M. Erfani, and Christopher Leckie. COLLIDER: A robust training framework for back- door data. In Proceedings of the 16th Asian Conference on Computer Vision (ACCV), pages 681-698, 2022. 15\n\n\u221e-robustness and beyond: Unleashing efficient adversarial training. M Hadi, Sarah M Dolatabadi, Christopher Erfani, Leckie, Proceedings of the 17th European Conference on Computer Vision (ECCV). the 17th European Conference on Computer Vision (ECCV)Hadi M. Dolatabadi, Sarah M. Erfani, and Christopher Leckie. \u221e-robustness and beyond: Unleashing efficient ad- versarial training. In Proceedings of the 17th European Con- ference on Computer Vision (ECCV), pages 467-483, 2022.\n\nSylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, 2021. 1Proceedings of the 9th International Conference on Learning Representations (ICLR. the 9th International Conference on Learning Representations (ICLRAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl- vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In Proceedings of the 9th International Conference on Learning Representations (ICLR), 2021. 1\n\nLearning to confuse: Generating training time adversarial data with auto-encoder. Ji Feng, Qi-Zhi Cai, Zhi-Hua Zhou, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems (NeurIPS). 817Ji Feng, Qi-Zhi Cai, and Zhi-Hua Zhou. Learning to confuse: Generating training time adversarial data with auto-encoder. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Sys- tems (NeurIPS), pages 11971-11981, 2019. 1, 2, 5, 6, 7, 8, 17\n\nPreventing unauthorized use of proprietary data: Poisoning for secure dataset release. Liam Fowl, Ping-Yeh Chiang, Micah Goldblum, Jonas Geiping, Arpit Bansal, Wojtek Czaja, Tom Goldstein, abs/2103.02683CoRRLiam Fowl, Ping-yeh Chiang, Micah Goldblum, Jonas Geip- ing, Arpit Bansal, Wojtek Czaja, and Tom Goldstein. Pre- venting unauthorized use of proprietary data: Poisoning for secure dataset release. CoRR, abs/2103.02683, 2021. 3\n\nAdversarial examples make strong poisons. Liam Fowl, Micah Goldblum, Ping-Yeh Chiang, Jonas Geiping, Wojciech Czaja, Tom Goldstein, Proceedings of the Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems (NeurIPS). the Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems (NeurIPS)2124Liam Fowl, Micah Goldblum, Ping-yeh Chiang, Jonas Geip- ing, Wojciech Czaja, and Tom Goldstein. Adversarial exam- ples make strong poisons. In Proceedings of the Advances in Neural Information Processing Systems 34: Annual Confer- ence on Neural Information Processing Systems (NeurIPS), pages 30339-30351, 2021. 1, 3, 5, 6, 7, 8, 17, 18, 20, 21, 24\n\nRobust unlearnable examples: Protecting data privacy against adversarial learning. Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao, Proceedings of the 10th International Conference on Learning Representations (ICLR). the 10th International Conference on Learning Representations (ICLR)2021Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, and Dacheng Tao. Robust unlearnable examples: Protecting data privacy against adversarial learning. In Proceedings of the 10th International Conference on Learning Representations (ICLR), 2022. 1, 3, 5, 6, 7, 8, 17, 19, 20, 21\n\nShortcut learning in deep neural networks. Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard S Zemel, Wieland Brendel, Matthias Bethge, Felix A Wichmann, Nature Machine Intelligence. 21117Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard S. Zemel, Wieland Brendel, Matthias Bethge, and Felix A. Wichmann. Shortcut learning in deep neural net- works. Nature Machine Intelligence, 2(11):665-673, 2020. 2, 5, 17\n\nDataset security for machine learning: Data poisoning, backdoor attacks, and defenses. Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein, IEEE Transactions of Pattern Analysis and Machine Intelligence. 4515Micah Goldblum, Dimitris Tsipras, Chulin Xie, Xinyun Chen, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, and Tom Goldstein. Dataset security for machine learning: Data poisoning, backdoor attacks, and defenses. IEEE Transactions of Pattern Analysis and Machine Intelli- gence, 45(2):1563-1580, 2023. 15\n\nGenerative adversarial nets. Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C Courville, Yoshua Bengio, Proceedings of the Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems (NeurIPS). the Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems (NeurIPS)Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, and Yoshua Bengio. Generative adversarial nets. In Pro- ceedings of the Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Pro- cessing Systems (NeurIPS), pages 2672-2680, 2014. 2\n\nExplaining and harnessing adversarial examples. Ian J Goodfellow, Jonathon Shlens, Christian Szegedy, Proceedings of the 3rd International Conference on Learning Representations (ICLR). the 3rd International Conference on Learning Representations (ICLR)Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In Proceed- ings of the 3rd International Conference on Learning Repre- sentations (ICLR), 2015. 3\n\nBad-Nets: Identifying vulnerabilities in the machine learning model supply chain. CoRR, abs/1708.06733. Tianyu Gu, Brendan Dolan-Gavitt, Siddharth Garg, 15Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. Bad- Nets: Identifying vulnerabilities in the machine learning model supply chain. CoRR, abs/1708.06733, 2017. 15\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)1620Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770-778, 2016. 1, 5, 16, 20\n\nGANs trained by a two time-scale update rule converge to a local nash equilibrium. Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems (NeurIPS). Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by a two time-scale update rule converge to a local nash equilib- rium. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems (NeurIPS), pages 6626-6637, 2017. 5\n\nThe secretive company that might end privacy as we know it. The New York Times. Kashmir Hill, Kashmir Hill. The secretive company that might end privacy as we know it. The New York Times, 2020. 1\n\nHow photos of your kids are powering surveillance technology. The New York Times. Kashmir Hill, Aaron Krolik, 1Kashmir Hill and Aaron Krolik. How photos of your kids are powering surveillance technology. The New York Times, 2019. 1, 2\n\nDenoising diffusion probabilistic models. Jonathan Ho, Ajay Jain, Pieter Abbeel, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems (NeurIPS). 15Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif- fusion probabilistic models. In Advances in Neural Informa- tion Processing Systems 33: Annual Conference on Neural Information Processing Systems (NeurIPS), 2020. 3, 4, 15\n\nDensely connected convolutional networks. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, Kilian Q Weinberger, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)1620Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kil- ian Q. Weinberger. Densely connected convolutional net- works. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2261-2269, 2017. 6, 16, 20\n\nUnlearnable examples: Making personal data unexploitable. Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang, Proceedings of the 9th International Conference on Learning Representations (ICLR). the 9th International Conference on Learning Representations (ICLR)2124Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, and Yisen Wang. Unlearnable examples: Making personal data unexploitable. In Proceedings of the 9th In- ternational Conference on Learning Representations (ICLR), 2021. 1, 2, 3, 4, 5, 6, 7, 8, 15, 17, 18, 20, 21, 24\n\nAnalyzing and improving the image quality of StyleGAN. Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improv- ing the image quality of StyleGAN. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8107-8116, 2020. 1\n\nUnderstanding blackbox predictions via influence functions. Wei Pang, Percy Koh, Liang, Proceedings of the 34th International Conference on Machine Learning (ICML). the 34th International Conference on Machine Learning (ICML)15Pang Wei Koh and Percy Liang. Understanding black- box predictions via influence functions. In Proceedings of the 34th International Conference on Machine Learning (ICML), pages 1885-1894, 2017. 15\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, 515Department of Computer Science, University of TorontoMaster's thesisAlex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Master's thesis, Depart- ment of Computer Science, University of Toronto, 2009. 1, 5, 15\n\nFast autoaugment. Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, Sungwoong Kim, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems (NeurIPS). 36Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, and Sungwoong Kim. Fast autoaugment. In Advances in Neu- ral Information Processing Systems 32: Annual Conference on Neural Information Processing Systems (NeurIPS), pages 6662-6672, 2019. 3, 6\n\nMicrosoft COCO: common objects in context. Tsung-Yi Lin, Michael Maire, Serge J Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, Proceedings of the 13th European Conference on Computer Vision (ECCV). the 13th European Conference on Computer Vision (ECCV)Tsung-Yi Lin, Michael Maire, Serge J. Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C. Lawrence Zitnick. Microsoft COCO: common objects in context. In Proceedings of the 13th European Conference on Computer Vision (ECCV), pages 740-755, 2014. 1\n\nCMX: cross-modal fusion for RGB-X semantic segmentation with transformers. Huayao Liu, Jiaming Zhang, Kailun Yang, Xinxin Hu, Rainer Stiefelhagen, abs/2203.04838, 2022. 1CoRRHuayao Liu, Jiaming Zhang, Kailun Yang, Xinxin Hu, and Rainer Stiefelhagen. CMX: cross-modal fusion for RGB-X semantic segmentation with transformers. CoRR, abs/2203.04838, 2022. 1\n\nDeep learning face attributes in the wild. Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang, Proceedings of the IEEE International Conference on Computer Vision (ICCV). the IEEE International Conference on Computer Vision (ICCV)25Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), pages 3730-3738, 2015. 8, 20, 25\n\nTowards deep learning models resistant to adversarial attacks. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu, Proceedings of the 6th International Conference on Learning Representations (ICLR). the 6th International Conference on Learning Representations (ICLR)57Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In Proceedings of the 6th International Conference on Learning Representations (ICLR), 2018. 3, 5, 7\n\nTowards poisoning of deep learning algorithms with back-gradient optimization. Luis Mu\u00f1oz-Gonz\u00e1lez, Battista Biggio, Ambra Demontis, Andrea Paudice, Vasin Wongrassamee, Emil C Lupu, Fabio Roli, Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (AISec@CCS). the 10th ACM Workshop on Artificial Intelligence and Security (AISec@CCS)15Luis Mu\u00f1oz-Gonz\u00e1lez, Battista Biggio, Ambra Demontis, Andrea Paudice, Vasin Wongrassamee, Emil C. Lupu, and Fabio Roli. Towards poisoning of deep learning algorithms with back-gradient optimization. In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security (AISec@CCS), pages 27-38, 2017. 15\n\nReading digits in natural images with unsupervised feature learning. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y Ng, NeurIPS Workshop on Deep Learning and Unsupervised Feature Learning. 515Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis- sacco, Bo Wu, and Andrew Y Ng. Reading digits in natu- ral images with unsupervised feature learning. In NeurIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011. 5, 15\n\nDiffusion models for adversarial purification. Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, Animashree Anandkumar, International Conference on Machine Learning (ICML). 2022Weili Nie, Brandon Guo, Yujia Huang, Chaowei Xiao, Arash Vahdat, and Animashree Anandkumar. Diffusion models for adversarial purification. In International Conference on Ma- chine Learning (ICML), pages 16805-16827, 2022. 3\n\nAnalysis of discrete and hybrid stochastic systems by nonlinear contraction theory. Quang-Cuong Pham, Proceedings of the 10th International Conference on Control, Automation, Robotics and Vision (ICARCV). the 10th International Conference on Control, Automation, Robotics and Vision (ICARCV)512Quang-Cuong Pham. Analysis of discrete and hybrid stochastic systems by nonlinear contraction theory. In Pro- ceedings of the 10th International Conference on Control, Automation, Robotics and Vision (ICARCV), pages 1054- 1059, 2008. 5, 12\n\nA contraction theory approach to stochastic incremental stability. Quang-Cuong Pham, Nicolas Tabareau, Jean-Jacques E Slotine, IEEE Transactions on Automatic Control. 54412Quang-Cuong Pham, Nicolas Tabareau, and Jean-Jacques E. Slotine. A contraction theory approach to stochastic incre- mental stability. IEEE Transactions on Automatic Control, 54(4):816-820, 2009. 12\n\nDreamFusion: Text-to-3D using 2D diffusion. Ben Poole, Ajay Jain, Jonathan T Barron, Ben Mildenhall, 2023. 3Proceedings of the 11th International Conference on Learning Representations (ICLR. the 11th International Conference on Learning Representations (ICLRBen Poole, Ajay Jain, Jonathan T. Barron, and Ben Milden- hall. DreamFusion: Text-to-3D using 2D diffusion. In Pro- ceedings of the 11th International Conference on Learning Representations (ICLR), 2023. 3\n\nHigh-resolution image synthesis with latent diffusion models. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)2022Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 10674-10685, 2022. 3\n\n. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael S Bernstein, Alexander C Berg, Fei-Fei Li, International Journal of Computer Vision (IJCV). 115315ImageNet large scale visual recognition challengeOlga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San- jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael S. Bernstein, Alexander C. Berg, and Fei-Fei Li. ImageNet large scale visual recognition chal- lenge. International Journal of Computer Vision (IJCV), 115(3):211-252, 2015. 1, 5, 15\n\nAutoregressive perturbations for data poisoning. Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, David W Jacobs, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems (NeurIPS). 1721Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, and David W. Jacobs. Autore- gressive perturbations for data poisoning. In Advances in Neural Information Processing Systems 35: Annual Confer- ence on Neural Information Processing Systems (NeurIPS), 2022. 1, 2, 5, 6, 7, 8, 17, 21\n\nJust how toxic is data poisoning? A unified benchmark for backdoor and data poisoning attacks. Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P Dickerson, Tom Goldstein, Proceedings of the 38th International Conference on Machine Learning (ICML). the 38th International Conference on Machine Learning (ICML)15Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P. Dickerson, and Tom Goldstein. Just how toxic is data poison- ing? A unified benchmark for backdoor and data poisoning attacks. In Proceedings of the 38th International Conference on Machine Learning (ICML), pages 9389-9398, 2021. 15\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, Proceedings of the 3rd International Conference on Learning Representations (ICLR). the 3rd International Conference on Learning Representations (ICLR)1620Karen Simonyan and Andrew Zisserman. Very deep convo- lutional networks for large-scale image recognition. In Pro- ceedings of the 3rd International Conference on Learning Representations (ICLR), 2015. 5, 16, 20\n\nMake-a-video: Text-to-video generation without text-video data. Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, Yaniv Taigman, Proceedings of the 11th International Conference on Learning Representations (ICLR). the 11th International Conference on Learning Representations (ICLR)13Uriel Singer, Adam Polyak, Thomas Hayes, Xi Yin, Jie An, Songyang Zhang, Qiyuan Hu, Harry Yang, Oron Ashual, Oran Gafni, Devi Parikh, Sonal Gupta, and Yaniv Taigman. Make-a-video: Text-to-video generation without text-video data. In Proceedings of the 11th International Conference on Learning Representations (ICLR), 2023. 1, 3\n\n. Jascha Sohl-Dickstein, Eric A Weiss, Niru Maheswaranathan, Surya Ganguli, 2023. 3Deep unsupervised Representations. Jascha Sohl-Dickstein, Eric A. Weiss, Niru Mah- eswaranathan, and Surya Ganguli. Deep unsupervised Representations (ICLR), 2023. 3\n\nGenerative poisoning attack method against neural networks. Chaofei Yang, Qing Wu, Hai Li, Yiran Chen, abs/1703.01340CoRR15Chaofei Yang, Qing Wu, Hai Li, and Yiran Chen. Genera- tive poisoning attack method against neural networks. CoRR, abs/1703.01340, 2017. 15\n\nLearning face representation from scratch. CoRR, abs/1411. Dong Yi, Zhen Lei, Shengcai Liao, Stan Z Li, 792325Dong Yi, Zhen Lei, Shengcai Liao, and Stan Z. Li. Learn- ing face representation from scratch. CoRR, abs/1411.7923, 2014. 8, 20, 25\n\nAdversarial purification with score-based generative models. Jongmin Yoon, Sung Ju Hwang, Juho Lee, Proceedings of the 38th International Conference on Machine Learning (ICML). the 38th International Conference on Machine Learning (ICML)Jongmin Yoon, Sung Ju Hwang, and Juho Lee. Adversar- ial purification with score-based generative models. In Pro- ceedings of the 38th International Conference on Machine Learning (ICML), pages 12062-12072, 2021. 3\n\nAvailability attacks create shortcuts. Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, Tie-Yan Liu, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2125Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, and Tie-Yan Liu. Availability attacks create shortcuts. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discov- ery and Data Mining, pages 2367-2376, 2022. 1, 2, 3, 6, 7, 8, 17, 19, 20, 21, 25\n\nNeural tangent generalization attacks. Chia-Hung Yuan, Shan-Hung Wu, Proceedings of the 38th International Conference on Machine Learning (ICML). the 38th International Conference on Machine Learning (ICML)Chia-Hung Yuan and Shan-Hung Wu. Neural tangent gener- alization attacks. In Proceedings of the 38th International Conference on Machine Learning (ICML), pages 12230- 12240, 2021. 1, 5, 6, 7, 8, 17, 21\n\nCutMix: Regularization strategy to train strong classifiers with localizable features. Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Youngjoon Seong Joon Oh, Junsuk Yoo, Choe, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). the IEEE/CVF International Conference on Computer Vision (ICCV)36Sangdoo Yun, Dongyoon Han, Sanghyuk Chun, Seong Joon Oh, Youngjoon Yoo, and Junsuk Choe. CutMix: Regulariza- tion strategy to train strong classifiers with localizable fea- tures. In Proceedings of the IEEE/CVF International Confer- ence on Computer Vision (ICCV), pages 6022-6031, 2019. 3, 6\n\nWide residual networks. Sergey Zagoruyko, Nikos Komodakis, Proceedings of the British Machine Vision Conference (BMVC). the British Machine Vision Conference (BMVC)1620Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In Proceedings of the British Machine Vision Confer- ence (BMVC), 2016. 6, 16, 20\n\nmixup: Beyond empirical risk minimization. Hongyi Zhang, Moustapha Ciss\u00e9, Yann N Dauphin, David Lopez-Paz, Proceedings of the 6th International Conference on Learning Representations (ICLR). the 6th International Conference on Learning Representations (ICLR)36Hongyi Zhang, Moustapha Ciss\u00e9, Yann N. Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimiza- tion. In Proceedings of the 6th International Conference on Learning Representations (ICLR), 2018. 3, 6\n\nData poisoning attacks against outcome interpretations of predictive models. Hengtong Zhang, Jing Gao, Lu Su, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 27th ACM SIGKDD Conference on Knowledge Discovery and Data MiningHengtong Zhang, Jing Gao, and Lu Su. Data poisoning at- tacks against outcome interpretations of predictive models. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 2165-2173, 2021. 3\n\nTheoretically principled trade-off between robustness and accuracy. Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P Xing, Laurent El Ghaoui, Michael I Jordan, Proceedings of the 36th International Conference on Machine Learning (ICML). the 36th International Conference on Machine Learning (ICML)Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, and Michael I. Jordan. Theoretically principled trade-off between robustness and accuracy. In Proceedings of the 36th International Conference on Ma- chine Learning (ICML), pages 7472-7482, 2019. 3\n\nGMNet: graded-feature multilabel-learning network for rgb-thermal urban scene semantic segmentation. Wujie Zhou, Jinfu Liu, Jingsheng Lei, Lu Yu, Jenq-Neng Hwang, IEEE Transactions on Image Processing. 301Wujie Zhou, Jinfu Liu, Jingsheng Lei, Lu Yu, and Jenq-Neng Hwang. GMNet: graded-feature multilabel-learning network for rgb-thermal urban scene semantic segmentation. IEEE Transactions on Image Processing, 30:7790-7802, 2021. 1\n\nExtended Experimental Results In this section, we go over our additional experimental results. D. Extended Experimental Results In this section, we go over our additional experimental results.\n\nAs discussed previously, our results in Section 4 are only evaluated against the RN-18 [22] architecture. To show that our performance is consistent across various neural network architectures. Availability Attacks against Different Neural Network Architectures. here we extend our results to three additional models: VGG-16 [47], DN-121 [27], and WRN-34 [68Availability Attacks against Different Neural Network Architectures. As discussed previously, our results in Section 4 are only evaluated against the RN-18 [22] architecture. To show that our performance is consistent across various neural network architectures, here we extend our results to three additional models: VGG-16 [47], DN-121 [27], and WRN-34 [68].\n\nAs can be seen, our results are consistent across different models, and AVATAR can significantly close the gap with clean data performance. Similarly, we repeat our adversarial training experiments for the above-mentioned models. Our results for the CIFAR-10, CIFAR-100, and SVHN are given in Figure 9. 9 Once again, we see that the RN-18 results are consistent with the other architectures. Finally, we repeat our ablation study on the selection of the diffusion timestep t * for these additional architectures. The training details for each case are given in Appendix C. Our results for these additional architectures are displayed in Table 9. As can be seen from Figure 8, the diffusion timestep is not sensitive to the neural network architecture, which makes it easier to setThe training details for each case are given in Appendix C. Our results for these additional architectures are displayed in Table 9. As can be seen, our results are consistent across different models, and AVATAR can significantly close the gap with clean data performance. Similarly, we repeat our adversarial training experiments for the above-mentioned models. Our results for the CIFAR-10, CIFAR-100, and SVHN are given in Figure 9. 9 Once again, we see that the RN-18 results are consistent with the other architectures. Finally, we repeat our ablation study on the selection of the diffusion timestep t * for these additional architectures. As can be seen from Figure 8, the diffusion timestep is not sensitive to the neural network architecture, which makes it easier to set.\n\nTo show this, we discussed a real-world example in Section 4 following a similar experiment from Huang et al. [28]. In particular, we create a set of clean and protected identities in the WebFace [63] dataset by randomly selecting 50 identities from this dataset. As a result, the remaining 10522 identities are going to constitute our clean data. For all of the identities, we randomly split the data so that 80% of that data is allocated to a training set and the rest is the test set. We assume that the protected identities would add data-protecting perturbations to their images before sharing them. Section 1, we discussed in detail that the threat model of existing availability attacks is fragile and a malicious adversary might still exploit the personal data. This means that possibly no imperceptible adversary can protect the image data from being maliciously used. To this end, we use class-wise EMN [28], TAP [15], REMN [16], and SHR [65] with a perturbation radius of \u03b4 \u221e \u2264 16/255. For perturbation generation using the first three attacks, we follow the settings of Huang et al. [28Facial Recognition and Data Protection. In Section 1, we discussed in detail that the threat model of existing availability attacks is fragile and a malicious adversary might still exploit the personal data. This means that possibly no imperceptible adversary can protect the image data from being maliciously used. To show this, we discussed a real-world example in Section 4 following a similar experiment from Huang et al. [28]. In particular, we create a set of clean and protected identities in the WebFace [63] dataset by randomly selecting 50 identities from this dataset. As a result, the remaining 10522 identities are going to constitute our clean data. For all of the identities, we randomly split the data so that 80% of that data is allocated to a training set and the rest is the test set. We assume that the protected identities would add data-protecting perturbations to their images before sharing them. To this end, we use class-wise EMN [28], TAP [15], REMN [16], and SHR [65] with a perturbation radius of \u03b4 \u221e \u2264 16/255. For perturbation generation using the first three attacks, we follow the settings of Huang et al. [28].\n\nSince the WebFace photos are of size 112 \u00d7 112 but the diffusion model generates 256 \u00d7 256 images, we use bi-linear up-and down-sampling to connect the two. Like the CIFAR-10 experiments, here we also denoise the data with timestep set to 100. Samples of the WebFace dataset along with the protected data is shown in Figure 10. To evaluate the performance of our method, we test the models over the clean test set and record the recognition accuracy for both the protected and clean identities. As shown in Figure 11, AVATAR can recover the recognition accuracy over protected identities in all cases except the SHR [65] perturbations. The reason behind this might be two-fold. First, we are using a sub-optimal diffusion model as both the domain and, more importantly, size of the images have a mismatch. Specifically, Once we have the protected data, we train an InceptionResNet [53] facial recognition over the training set with or without our approach and evaluate the models over the test set. In our case, we assume that the malicious entity has access to a pre-trained diffusion model over CelebA [35] faces 10 , and can run AVATAR over the protected data that it acquires from crawling the web. Second, looking at Figure 10, we see that while the SHR perturbations can protect the data, they trade the stealthiness of the original data due to their large patches. As such, the images would lose their utility. Now, the question is: Can we protect the data using stealthy patterns without losing the data utilitySpecifically, we select 100 random identities from the CelebA [35] dataset and create an auxiliary dataset consisting of these 100 identities and the 50 protected WebFace [63] identities. Then, using these 150 identities we generate data protecting perturbations against a neural network with 150 classes. For SHR, however, we generate the data for all the 10572 WebFace identities and select the relevant data for protecting our above-mentioned 50 identities. Once we have the protected data, we train an InceptionResNet [53] facial recognition over the training set with or without our approach and evaluate the models over the test set. In our case, we assume that the malicious entity has access to a pre-trained diffusion model over CelebA [35] faces 10 , and can run AVATAR over the protected data that it acquires from crawling the web. Since the WebFace photos are of size 112 \u00d7 112 but the diffusion model generates 256 \u00d7 256 images, we use bi-linear up-and down-sampling to connect the two. Like the CIFAR-10 experiments, here we also denoise the data with timestep set to 100. Samples of the WebFace dataset along with the protected data is shown in Figure 10. To evaluate the performance of our method, we test the models over the clean test set and record the recognition accuracy for both the protected and clean identities. As shown in Figure 11, AVATAR can recover the recognition accuracy over protected identities in all cases except the SHR [65] perturbations. The reason behind this might be two-fold. First, we are using a sub-optimal diffusion model as both the domain and, more importantly, size of the images have a mismatch. Second, looking at Figure 10, we see that while the SHR perturbations can protect the data, they trade the stealthiness of the original data due to their large patches. As such, the images would lose their utility. Now, the question is: Can we protect the data using stealthy patterns without losing the data utility?\n\nAccording to Theorem 1, if the data curator wants to makes the denoising process harder, they need to increase the data-protecting perturbation. This increase is naturally at odds with the data utility. theoretical result in Theorem 1 says that this might not be possible. since by adding more powerful perturbations we lose the data utilityInterestingly, our theoretical result in Theorem 1 says that this might not be possible. According to Theorem 1, if the data curator wants to makes the denoising process harder, they need to increase the data-protecting perturbation. This increase is naturally at odds with the data utility, since by adding more powerful perturbations we lose the data utility.\n\nNote that adversarial training of VGG-16 models over the SVHN dataset was unstable. As such, the respective figure show a few missing points. Note that adversarial training of VGG-16 models over the SVHN dataset was unstable. As such, the respective figure show a few missing points.\n\nFor this experiment, we use a pre-trained DDPM model over CelebA. For this experiment, we use a pre-trained DDPM model over CelebA-HQ: https://github.com/ermongroup/SDEdit.\n", "annotations": {"author": "[{\"end\":214,\"start\":94},{\"end\":330,\"start\":215},{\"end\":448,\"start\":331}]", "publisher": null, "author_last_name": "[{\"end\":111,\"start\":101},{\"end\":227,\"start\":221},{\"end\":349,\"start\":343}]", "author_first_name": "[{\"end\":98,\"start\":94},{\"end\":100,\"start\":99},{\"end\":220,\"start\":215},{\"end\":342,\"start\":331}]", "author_affiliation": "[{\"end\":213,\"start\":141},{\"end\":329,\"start\":257},{\"end\":447,\"start\":375}]", "title": "[{\"end\":91,\"start\":1},{\"end\":539,\"start\":449}]", "venue": null, "abstract": "[{\"end\":1785,\"start\":541}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1912,\"start\":1908},{\"end\":1915,\"start\":1912},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":1943,\"start\":1939},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":1946,\"start\":1943},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":1995,\"start\":1991},{\"end\":1997,\"start\":1995},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2000,\"start\":1997},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2205,\"start\":2202},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2208,\"start\":2205},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2211,\"start\":2208},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2214,\"start\":2211},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2657,\"start\":2653},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2660,\"start\":2657},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2662,\"start\":2660},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2814,\"start\":2810},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2817,\"start\":2814},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":2820,\"start\":2817},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2823,\"start\":2820},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2826,\"start\":2823},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2829,\"start\":2826},{\"end\":2832,\"start\":2829},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":2835,\"start\":2832},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3136,\"start\":3133},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3223,\"start\":3219},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":3226,\"start\":3223},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7565,\"start\":7561},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7673,\"start\":7669},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7692,\"start\":7688},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7942,\"start\":7938},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":8144,\"start\":8140},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8321,\"start\":8317},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":8337,\"start\":8333},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8597,\"start\":8593},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8929,\"start\":8925},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9309,\"start\":9305},{\"end\":9351,\"start\":9347},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9354,\"start\":9351},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9692,\"start\":9688},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":9695,\"start\":9692},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9882,\"start\":9879},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":9894,\"start\":9890},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":9907,\"start\":9903},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9934,\"start\":9930},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9985,\"start\":9981},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9988,\"start\":9985},{\"end\":9991,\"start\":9988},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":9994,\"start\":9991},{\"end\":10011,\"start\":10007},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10048,\"start\":10044},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":10051,\"start\":10048},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":10054,\"start\":10051},{\"end\":10130,\"start\":10126},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10133,\"start\":10130},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10230,\"start\":10226},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10283,\"start\":10279},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":10687,\"start\":10683},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10690,\"start\":10687},{\"end\":10830,\"start\":10827},{\"end\":10833,\"start\":10830},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":10853,\"start\":10849},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":10865,\"start\":10861},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":10885,\"start\":10881},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10973,\"start\":10970},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":11345,\"start\":11341},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":11365,\"start\":11361},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":11465,\"start\":11461},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":11633,\"start\":11629},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15019,\"start\":15015},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":15099,\"start\":15098},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":15164,\"start\":15160},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":15750,\"start\":15746},{\"end\":18345,\"start\":18342},{\"end\":18373,\"start\":18370},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":19161,\"start\":19157},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":20086,\"start\":20082},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20761,\"start\":20757},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":21217,\"start\":21213},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":21228,\"start\":21224},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":21264,\"start\":21260},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21354,\"start\":21350},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":21405,\"start\":21401},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":21440,\"start\":21436},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":21483,\"start\":21479},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21507,\"start\":21503},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":21528,\"start\":21524},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":21566,\"start\":21562},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21631,\"start\":21630},{\"end\":21797,\"start\":21794},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21884,\"start\":21880},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22190,\"start\":22186},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":22203,\"start\":22199},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":22826,\"start\":22822},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":23331,\"start\":23327},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":23667,\"start\":23663},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":24399,\"start\":24395},{\"end\":24474,\"start\":24470},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":24549,\"start\":24545},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25184,\"start\":25180},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25228,\"start\":25224},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26302,\"start\":26298},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":26395,\"start\":26391},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":27278,\"start\":27274},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":27539,\"start\":27535},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":27618,\"start\":27614},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":27642,\"start\":27638},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":27995,\"start\":27991},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":28219,\"start\":28215},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":28272,\"start\":28268},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":28372,\"start\":28368},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":29845,\"start\":29841},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":29848,\"start\":29845},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":29850,\"start\":29848},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":29900,\"start\":29896},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":29902,\"start\":29900},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30480,\"start\":30477},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30644,\"start\":30641},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":30967,\"start\":30964},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":31235,\"start\":31231},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31468,\"start\":31465},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33274,\"start\":33270},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":33727,\"start\":33723},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":34026,\"start\":34022},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":34392,\"start\":34388},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":34568,\"start\":34564},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":34701,\"start\":34697},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":34996,\"start\":34993},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":34999,\"start\":34996},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":35002,\"start\":34999},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":35137,\"start\":35134},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":35140,\"start\":35137},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":35143,\"start\":35140},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":35272,\"start\":35268},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":35378,\"start\":35374},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":35470,\"start\":35466},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":35472,\"start\":35470},{\"end\":35475,\"start\":35472},{\"end\":35478,\"start\":35475},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36166,\"start\":36163},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":36620,\"start\":36616},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":36697,\"start\":36693},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":37481,\"start\":37477},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":37598,\"start\":37594},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":37698,\"start\":37694},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":38053,\"start\":38049},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":38261,\"start\":38257},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":38294,\"start\":38290},{\"end\":38977,\"start\":38974},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":39060,\"start\":39059},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":39374,\"start\":39370},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":39431,\"start\":39427},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":39472,\"start\":39468},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":39664,\"start\":39660},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":39695,\"start\":39691},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":40015,\"start\":40011},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":40178,\"start\":40174},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":44634,\"start\":44630},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":48806,\"start\":48802},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":48818,\"start\":48814},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":50150,\"start\":50148},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":53322,\"start\":53318},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":53491,\"start\":53487},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":53500,\"start\":53496}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":40483,\"start\":40451},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40640,\"start\":40484},{\"attributes\":{\"id\":\"fig_2\"},\"end\":40864,\"start\":40641},{\"attributes\":{\"id\":\"fig_3\"},\"end\":41141,\"start\":40865},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":42304,\"start\":41142},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":43606,\"start\":42305},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":44405,\"start\":43607},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":45342,\"start\":44406},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":48601,\"start\":45343},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":49045,\"start\":48602},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":49450,\"start\":49046},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":49539,\"start\":49451},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":49883,\"start\":49540},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":53284,\"start\":49884}]", "paragraph": "[{\"end\":2663,\"start\":1801},{\"end\":3450,\"start\":2665},{\"end\":4276,\"start\":3452},{\"end\":5892,\"start\":4278},{\"end\":5941,\"start\":5894},{\"end\":6142,\"start\":5943},{\"end\":6400,\"start\":6144},{\"end\":6675,\"start\":6402},{\"end\":6800,\"start\":6692},{\"end\":7674,\"start\":6802},{\"end\":7874,\"start\":7676},{\"end\":9696,\"start\":7876},{\"end\":10613,\"start\":9698},{\"end\":11236,\"start\":10615},{\"end\":12106,\"start\":11238},{\"end\":12524,\"start\":12126},{\"end\":13245,\"start\":12578},{\"end\":13585,\"start\":13286},{\"end\":13888,\"start\":13679},{\"end\":14452,\"start\":13935},{\"end\":14797,\"start\":14454},{\"end\":15321,\"start\":14799},{\"end\":15751,\"start\":15355},{\"end\":15872,\"start\":15785},{\"end\":16051,\"start\":15932},{\"end\":16417,\"start\":16053},{\"end\":16574,\"start\":16419},{\"end\":16973,\"start\":16612},{\"end\":17382,\"start\":17033},{\"end\":17802,\"start\":17408},{\"end\":18038,\"start\":17903},{\"end\":18167,\"start\":18154},{\"end\":18297,\"start\":18221},{\"end\":18399,\"start\":18299},{\"end\":18661,\"start\":18407},{\"end\":18870,\"start\":18663},{\"end\":19000,\"start\":18913},{\"end\":19162,\"start\":19052},{\"end\":19490,\"start\":19164},{\"end\":19981,\"start\":19492},{\"end\":20030,\"start\":20017},{\"end\":20222,\"start\":20032},{\"end\":20530,\"start\":20224},{\"end\":20570,\"start\":20532},{\"end\":20730,\"start\":20572},{\"end\":20880,\"start\":20732},{\"end\":21129,\"start\":20905},{\"end\":22984,\"start\":21131},{\"end\":23530,\"start\":22986},{\"end\":24302,\"start\":23532},{\"end\":24949,\"start\":24304},{\"end\":25108,\"start\":24951},{\"end\":25285,\"start\":25110},{\"end\":26056,\"start\":25307},{\"end\":27151,\"start\":26058},{\"end\":28422,\"start\":27153},{\"end\":28675,\"start\":28424},{\"end\":29558,\"start\":28690},{\"end\":29851,\"start\":29572},{\"end\":29908,\"start\":29853},{\"end\":29994,\"start\":29948},{\"end\":30103,\"start\":29996},{\"end\":30275,\"start\":30254},{\"end\":30360,\"start\":30277},{\"end\":30481,\"start\":30412},{\"end\":30585,\"start\":30483},{\"end\":30819,\"start\":30587},{\"end\":30990,\"start\":30871},{\"end\":31030,\"start\":31027},{\"end\":31242,\"start\":31046},{\"end\":31324,\"start\":31244},{\"end\":31398,\"start\":31341},{\"end\":31469,\"start\":31440},{\"end\":31519,\"start\":31471},{\"end\":31576,\"start\":31556},{\"end\":31702,\"start\":31635},{\"end\":31753,\"start\":31704},{\"end\":31972,\"start\":31755},{\"end\":32102,\"start\":32015},{\"end\":32302,\"start\":32154},{\"end\":32657,\"start\":32409},{\"end\":32803,\"start\":32732},{\"end\":33131,\"start\":32946},{\"end\":33318,\"start\":33216},{\"end\":33677,\"start\":33561},{\"end\":33731,\"start\":33696},{\"end\":33913,\"start\":33785},{\"end\":34040,\"start\":33977},{\"end\":34118,\"start\":34082},{\"end\":34368,\"start\":34227},{\"end\":34419,\"start\":34370},{\"end\":34496,\"start\":34485},{\"end\":34572,\"start\":34539},{\"end\":34749,\"start\":34678},{\"end\":34872,\"start\":34778},{\"end\":35909,\"start\":34874},{\"end\":37054,\"start\":35911},{\"end\":37289,\"start\":37056},{\"end\":37398,\"start\":37329},{\"end\":40450,\"start\":37400}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12577,\"start\":12545},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13285,\"start\":13246},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13678,\"start\":13586},{\"attributes\":{\"id\":\"formula_3\"},\"end\":15354,\"start\":15322},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15784,\"start\":15752},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15931,\"start\":15873},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16611,\"start\":16575},{\"attributes\":{\"id\":\"formula_7\"},\"end\":17032,\"start\":16974},{\"attributes\":{\"id\":\"formula_8\"},\"end\":17902,\"start\":17803},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18153,\"start\":18039},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18215,\"start\":18168},{\"attributes\":{\"id\":\"formula_11\"},\"end\":18912,\"start\":18871},{\"attributes\":{\"id\":\"formula_12\"},\"end\":19051,\"start\":19001},{\"attributes\":{\"id\":\"formula_13\"},\"end\":29947,\"start\":29909},{\"attributes\":{\"id\":\"formula_14\"},\"end\":30151,\"start\":30104},{\"attributes\":{\"id\":\"formula_15\"},\"end\":30253,\"start\":30151},{\"attributes\":{\"id\":\"formula_16\"},\"end\":30411,\"start\":30361},{\"attributes\":{\"id\":\"formula_17\"},\"end\":30870,\"start\":30820},{\"attributes\":{\"id\":\"formula_18\"},\"end\":31026,\"start\":30991},{\"attributes\":{\"id\":\"formula_19\"},\"end\":31045,\"start\":31031},{\"attributes\":{\"id\":\"formula_20\"},\"end\":31439,\"start\":31399},{\"attributes\":{\"id\":\"formula_21\"},\"end\":31555,\"start\":31520},{\"attributes\":{\"id\":\"formula_22\"},\"end\":31634,\"start\":31577},{\"attributes\":{\"id\":\"formula_23\"},\"end\":32014,\"start\":31973},{\"attributes\":{\"id\":\"formula_24\"},\"end\":32153,\"start\":32103},{\"attributes\":{\"id\":\"formula_25\"},\"end\":32408,\"start\":32303},{\"attributes\":{\"id\":\"formula_26\"},\"end\":32731,\"start\":32658},{\"attributes\":{\"id\":\"formula_27\"},\"end\":32945,\"start\":32804},{\"attributes\":{\"id\":\"formula_28\"},\"end\":33215,\"start\":33132},{\"attributes\":{\"id\":\"formula_29\"},\"end\":33560,\"start\":33319},{\"attributes\":{\"id\":\"formula_30\"},\"end\":33695,\"start\":33678},{\"attributes\":{\"id\":\"formula_31\"},\"end\":33784,\"start\":33732},{\"attributes\":{\"id\":\"formula_32\"},\"end\":33976,\"start\":33914},{\"attributes\":{\"id\":\"formula_33\"},\"end\":34081,\"start\":34041},{\"attributes\":{\"id\":\"formula_34\"},\"end\":34226,\"start\":34119},{\"attributes\":{\"id\":\"formula_35\"},\"end\":34484,\"start\":34420},{\"attributes\":{\"id\":\"formula_36\"},\"end\":34538,\"start\":34497},{\"attributes\":{\"id\":\"formula_37\"},\"end\":34677,\"start\":34573}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":21937,\"start\":21930},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22240,\"start\":22233},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23397,\"start\":23390},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23850,\"start\":23843},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":26408,\"start\":26401},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26605,\"start\":26598},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":38254,\"start\":38247},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":38524,\"start\":38517},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":38546,\"start\":38539},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":38664,\"start\":38610},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":38714,\"start\":38667},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":38724,\"start\":38717},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":38734,\"start\":38727},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":38744,\"start\":38737},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":39342,\"start\":39335}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1799,\"start\":1787},{\"attributes\":{\"n\":\"2.\"},\"end\":6690,\"start\":6678},{\"attributes\":{\"n\":\"3.\"},\"end\":12124,\"start\":12109},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12544,\"start\":12527},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13933,\"start\":13891},{\"attributes\":{\"n\":\"3.3.\"},\"end\":17406,\"start\":17385},{\"end\":18219,\"start\":18217},{\"end\":18405,\"start\":18402},{\"attributes\":{\"n\":\"3.4.\"},\"end\":20015,\"start\":19984},{\"attributes\":{\"n\":\"4.\"},\"end\":20903,\"start\":20883},{\"end\":25305,\"start\":25288},{\"attributes\":{\"n\":\"5.\"},\"end\":28688,\"start\":28678},{\"end\":29570,\"start\":29561},{\"end\":31339,\"start\":31327},{\"end\":34776,\"start\":34752},{\"end\":37327,\"start\":37292},{\"end\":40462,\"start\":40452},{\"end\":40495,\"start\":40485},{\"end\":40652,\"start\":40642},{\"end\":40886,\"start\":40866},{\"end\":41152,\"start\":41143},{\"end\":42315,\"start\":42306},{\"end\":43617,\"start\":43608},{\"end\":44416,\"start\":44407},{\"end\":48612,\"start\":48603},{\"end\":49056,\"start\":49047},{\"end\":49461,\"start\":49452},{\"end\":49550,\"start\":49541},{\"end\":49894,\"start\":49885}]", "table": "[{\"end\":42304,\"start\":41408},{\"end\":43606,\"start\":42550},{\"end\":44405,\"start\":43843},{\"end\":45342,\"start\":44688},{\"end\":48601,\"start\":46101},{\"end\":49045,\"start\":48841},{\"end\":49450,\"start\":49108},{\"end\":49539,\"start\":49503},{\"end\":49883,\"start\":49750},{\"end\":53284,\"start\":52306}]", "figure_caption": "[{\"end\":40483,\"start\":40464},{\"end\":40640,\"start\":40497},{\"end\":40864,\"start\":40654},{\"end\":41141,\"start\":40889},{\"end\":41408,\"start\":41154},{\"end\":42550,\"start\":42317},{\"end\":43843,\"start\":43619},{\"end\":44688,\"start\":44418},{\"end\":46101,\"start\":45345},{\"end\":48841,\"start\":48614},{\"end\":49108,\"start\":49058},{\"end\":49503,\"start\":49463},{\"end\":49750,\"start\":49552},{\"end\":52306,\"start\":49896}]", "figure_ref": "[{\"end\":4214,\"start\":4206},{\"end\":4692,\"start\":4684},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16863,\"start\":16855},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":17183,\"start\":17175},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24834,\"start\":24826},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25133,\"start\":25125},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":25824,\"start\":25816},{\"end\":27009,\"start\":27001},{\"end\":27304,\"start\":27296},{\"end\":27890,\"start\":27882},{\"end\":28153,\"start\":28145},{\"end\":28445,\"start\":28437},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":38762,\"start\":38747},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":38780,\"start\":38765},{\"end\":39949,\"start\":39940},{\"end\":40372,\"start\":40363}]", "bib_author_first_name": "[{\"end\":56450,\"start\":56445},{\"end\":56464,\"start\":56458},{\"end\":56482,\"start\":56473},{\"end\":56929,\"start\":56921},{\"end\":56944,\"start\":56938},{\"end\":56958,\"start\":56953},{\"end\":57418,\"start\":57410},{\"end\":57432,\"start\":57427},{\"end\":57661,\"start\":57656},{\"end\":58182,\"start\":58174},{\"end\":58198,\"start\":58190},{\"end\":58213,\"start\":58204},{\"end\":58746,\"start\":58742},{\"end\":58770,\"start\":58765},{\"end\":58784,\"start\":58777},{\"end\":59030,\"start\":59027},{\"end\":59040,\"start\":59037},{\"end\":59054,\"start\":59047},{\"end\":59069,\"start\":59063},{\"end\":59077,\"start\":59074},{\"end\":59089,\"start\":59082},{\"end\":59567,\"start\":59559},{\"end\":59583,\"start\":59577},{\"end\":59585,\"start\":59584},{\"end\":59814,\"start\":59806},{\"end\":59834,\"start\":59825},{\"end\":59848,\"start\":59842},{\"end\":60294,\"start\":60293},{\"end\":60306,\"start\":60301},{\"end\":60308,\"start\":60307},{\"end\":60332,\"start\":60321},{\"end\":60755,\"start\":60754},{\"end\":60767,\"start\":60762},{\"end\":60769,\"start\":60768},{\"end\":60793,\"start\":60782},{\"end\":61296,\"start\":61290},{\"end\":61315,\"start\":61310},{\"end\":61332,\"start\":61323},{\"end\":61349,\"start\":61345},{\"end\":61370,\"start\":61363},{\"end\":61383,\"start\":61377},{\"end\":61404,\"start\":61397},{\"end\":61423,\"start\":61415},{\"end\":61439,\"start\":61434},{\"end\":62072,\"start\":62070},{\"end\":62085,\"start\":62079},{\"end\":62098,\"start\":62091},{\"end\":62620,\"start\":62616},{\"end\":62635,\"start\":62627},{\"end\":62649,\"start\":62644},{\"end\":62665,\"start\":62660},{\"end\":62680,\"start\":62675},{\"end\":62695,\"start\":62689},{\"end\":62706,\"start\":62703},{\"end\":63010,\"start\":63006},{\"end\":63022,\"start\":63017},{\"end\":63041,\"start\":63033},{\"end\":63055,\"start\":63050},{\"end\":63073,\"start\":63065},{\"end\":63084,\"start\":63081},{\"end\":63811,\"start\":63803},{\"end\":63825,\"start\":63816},{\"end\":63834,\"start\":63830},{\"end\":63842,\"start\":63840},{\"end\":63856,\"start\":63849},{\"end\":64342,\"start\":64336},{\"end\":64363,\"start\":64352},{\"end\":64381,\"start\":64374},{\"end\":64400,\"start\":64393},{\"end\":64402,\"start\":64401},{\"end\":64417,\"start\":64410},{\"end\":64435,\"start\":64427},{\"end\":64449,\"start\":64444},{\"end\":64451,\"start\":64450},{\"end\":64825,\"start\":64820},{\"end\":64844,\"start\":64836},{\"end\":64860,\"start\":64854},{\"end\":64872,\"start\":64866},{\"end\":64882,\"start\":64879},{\"end\":64902,\"start\":64898},{\"end\":64919,\"start\":64909},{\"end\":64929,\"start\":64927},{\"end\":64937,\"start\":64934},{\"end\":65362,\"start\":65359},{\"end\":65364,\"start\":65363},{\"end\":65381,\"start\":65377},{\"end\":65402,\"start\":65397},{\"end\":65414,\"start\":65410},{\"end\":65424,\"start\":65419},{\"end\":65446,\"start\":65439},{\"end\":65459,\"start\":65454},{\"end\":65461,\"start\":65460},{\"end\":65479,\"start\":65473},{\"end\":66148,\"start\":66145},{\"end\":66150,\"start\":66149},{\"end\":66171,\"start\":66163},{\"end\":66189,\"start\":66180},{\"end\":66667,\"start\":66661},{\"end\":66679,\"start\":66672},{\"end\":66703,\"start\":66694},{\"end\":66933,\"start\":66926},{\"end\":66945,\"start\":66938},{\"end\":66961,\"start\":66953},{\"end\":66971,\"start\":66967},{\"end\":67452,\"start\":67446},{\"end\":67467,\"start\":67461},{\"end\":67484,\"start\":67478},{\"end\":67506,\"start\":67498},{\"end\":67520,\"start\":67516},{\"end\":68073,\"start\":68066},{\"end\":68272,\"start\":68265},{\"end\":68284,\"start\":68279},{\"end\":68469,\"start\":68461},{\"end\":68478,\"start\":68474},{\"end\":68491,\"start\":68485},{\"end\":68903,\"start\":68900},{\"end\":68917,\"start\":68911},{\"end\":68930,\"start\":68923},{\"end\":68953,\"start\":68947},{\"end\":68955,\"start\":68954},{\"end\":69433,\"start\":69427},{\"end\":69448,\"start\":69441},{\"end\":69458,\"start\":69453},{\"end\":69466,\"start\":69459},{\"end\":69480,\"start\":69475},{\"end\":69494,\"start\":69489},{\"end\":69994,\"start\":69990},{\"end\":70009,\"start\":70003},{\"end\":70022,\"start\":70017},{\"end\":70037,\"start\":70032},{\"end\":70054,\"start\":70048},{\"end\":70069,\"start\":70065},{\"end\":70568,\"start\":70565},{\"end\":70580,\"start\":70575},{\"end\":70990,\"start\":70986},{\"end\":71011,\"start\":71003},{\"end\":71298,\"start\":71291},{\"end\":71309,\"start\":71304},{\"end\":71321,\"start\":71315},{\"end\":71334,\"start\":71327},{\"end\":71349,\"start\":71340},{\"end\":71776,\"start\":71768},{\"end\":71789,\"start\":71782},{\"end\":71802,\"start\":71797},{\"end\":71804,\"start\":71803},{\"end\":71820,\"start\":71815},{\"end\":71833,\"start\":71827},{\"end\":71846,\"start\":71842},{\"end\":71861,\"start\":71856},{\"end\":71871,\"start\":71870},{\"end\":71880,\"start\":71872},{\"end\":72365,\"start\":72359},{\"end\":72378,\"start\":72371},{\"end\":72392,\"start\":72386},{\"end\":72405,\"start\":72399},{\"end\":72416,\"start\":72410},{\"end\":72688,\"start\":72683},{\"end\":72698,\"start\":72694},{\"end\":72712,\"start\":72704},{\"end\":72725,\"start\":72719},{\"end\":73151,\"start\":73141},{\"end\":73169,\"start\":73159},{\"end\":73185,\"start\":73179},{\"end\":73203,\"start\":73195},{\"end\":73219,\"start\":73213},{\"end\":73718,\"start\":73714},{\"end\":73743,\"start\":73735},{\"end\":73757,\"start\":73752},{\"end\":73774,\"start\":73768},{\"end\":73789,\"start\":73784},{\"end\":73808,\"start\":73804},{\"end\":73810,\"start\":73809},{\"end\":73822,\"start\":73817},{\"end\":74383,\"start\":74378},{\"end\":74395,\"start\":74392},{\"end\":74406,\"start\":74402},{\"end\":74425,\"start\":74415},{\"end\":74438,\"start\":74436},{\"end\":74451,\"start\":74443},{\"end\":74820,\"start\":74815},{\"end\":74833,\"start\":74826},{\"end\":74844,\"start\":74839},{\"end\":74859,\"start\":74852},{\"end\":74871,\"start\":74866},{\"end\":74890,\"start\":74880},{\"end\":75280,\"start\":75269},{\"end\":75798,\"start\":75787},{\"end\":75812,\"start\":75805},{\"end\":75835,\"start\":75823},{\"end\":75837,\"start\":75836},{\"end\":76138,\"start\":76135},{\"end\":76150,\"start\":76146},{\"end\":76165,\"start\":76157},{\"end\":76167,\"start\":76166},{\"end\":76179,\"start\":76176},{\"end\":76624,\"start\":76619},{\"end\":76641,\"start\":76634},{\"end\":76660,\"start\":76653},{\"end\":76676,\"start\":76669},{\"end\":76689,\"start\":76684},{\"end\":77135,\"start\":77131},{\"end\":77152,\"start\":77149},{\"end\":77162,\"start\":77159},{\"end\":77175,\"start\":77167},{\"end\":77191,\"start\":77184},{\"end\":77206,\"start\":77202},{\"end\":77218,\"start\":77211},{\"end\":77232,\"start\":77226},{\"end\":77249,\"start\":77243},{\"end\":77265,\"start\":77258},{\"end\":77267,\"start\":77266},{\"end\":77288,\"start\":77279},{\"end\":77290,\"start\":77289},{\"end\":77304,\"start\":77297},{\"end\":77787,\"start\":77782},{\"end\":77809,\"start\":77805},{\"end\":77823,\"start\":77818},{\"end\":77838,\"start\":77833},{\"end\":77852,\"start\":77849},{\"end\":77869,\"start\":77864},{\"end\":77871,\"start\":77870},{\"end\":78421,\"start\":78418},{\"end\":78442,\"start\":78437},{\"end\":78458,\"start\":78453},{\"end\":78470,\"start\":78466},{\"end\":78472,\"start\":78471},{\"end\":78487,\"start\":78484},{\"end\":79001,\"start\":78996},{\"end\":79018,\"start\":79012},{\"end\":79467,\"start\":79462},{\"end\":79480,\"start\":79476},{\"end\":79495,\"start\":79489},{\"end\":79505,\"start\":79503},{\"end\":79514,\"start\":79511},{\"end\":79527,\"start\":79519},{\"end\":79541,\"start\":79535},{\"end\":79551,\"start\":79546},{\"end\":79562,\"start\":79558},{\"end\":79575,\"start\":79571},{\"end\":79587,\"start\":79583},{\"end\":79601,\"start\":79596},{\"end\":79614,\"start\":79609},{\"end\":80117,\"start\":80111},{\"end\":80138,\"start\":80134},{\"end\":80140,\"start\":80139},{\"end\":80152,\"start\":80148},{\"end\":80175,\"start\":80170},{\"end\":80426,\"start\":80419},{\"end\":80437,\"start\":80433},{\"end\":80445,\"start\":80442},{\"end\":80455,\"start\":80450},{\"end\":80686,\"start\":80682},{\"end\":80695,\"start\":80691},{\"end\":80709,\"start\":80701},{\"end\":80720,\"start\":80716},{\"end\":80722,\"start\":80721},{\"end\":80934,\"start\":80927},{\"end\":80945,\"start\":80941},{\"end\":80948,\"start\":80946},{\"end\":80960,\"start\":80956},{\"end\":81360,\"start\":81358},{\"end\":81373,\"start\":81365},{\"end\":81384,\"start\":81381},{\"end\":81395,\"start\":81391},{\"end\":81408,\"start\":81401},{\"end\":81872,\"start\":81863},{\"end\":81888,\"start\":81879},{\"end\":82327,\"start\":82320},{\"end\":82341,\"start\":82333},{\"end\":82355,\"start\":82347},{\"end\":82371,\"start\":82362},{\"end\":82393,\"start\":82387},{\"end\":82874,\"start\":82868},{\"end\":82891,\"start\":82886},{\"end\":83208,\"start\":83202},{\"end\":83225,\"start\":83216},{\"end\":83237,\"start\":83233},{\"end\":83239,\"start\":83238},{\"end\":83254,\"start\":83249},{\"end\":83717,\"start\":83709},{\"end\":83729,\"start\":83725},{\"end\":83737,\"start\":83735},{\"end\":84204,\"start\":84196},{\"end\":84219,\"start\":84212},{\"end\":84231,\"start\":84224},{\"end\":84242,\"start\":84238},{\"end\":84244,\"start\":84243},{\"end\":84258,\"start\":84251},{\"end\":84261,\"start\":84259},{\"end\":84277,\"start\":84270},{\"end\":84279,\"start\":84278},{\"end\":84805,\"start\":84800},{\"end\":84817,\"start\":84812},{\"end\":84832,\"start\":84823},{\"end\":84840,\"start\":84838},{\"end\":84854,\"start\":84845}]", "bib_author_last_name": "[{\"end\":56456,\"start\":56451},{\"end\":56471,\"start\":56465},{\"end\":56488,\"start\":56483},{\"end\":56936,\"start\":56930},{\"end\":56951,\"start\":56945},{\"end\":56965,\"start\":56959},{\"end\":57425,\"start\":57419},{\"end\":57437,\"start\":57433},{\"end\":57669,\"start\":57662},{\"end\":57688,\"start\":57671},{\"end\":58188,\"start\":58183},{\"end\":58202,\"start\":58199},{\"end\":58216,\"start\":58214},{\"end\":58740,\"start\":58727},{\"end\":58755,\"start\":58747},{\"end\":58763,\"start\":58757},{\"end\":58775,\"start\":58771},{\"end\":58792,\"start\":58785},{\"end\":58798,\"start\":58794},{\"end\":58920,\"start\":58916},{\"end\":59035,\"start\":59031},{\"end\":59045,\"start\":59041},{\"end\":59061,\"start\":59055},{\"end\":59072,\"start\":59070},{\"end\":59080,\"start\":59078},{\"end\":59092,\"start\":59090},{\"end\":59575,\"start\":59568},{\"end\":59592,\"start\":59586},{\"end\":59823,\"start\":59815},{\"end\":59840,\"start\":59835},{\"end\":60299,\"start\":60295},{\"end\":60319,\"start\":60309},{\"end\":60339,\"start\":60333},{\"end\":60347,\"start\":60341},{\"end\":60760,\"start\":60756},{\"end\":60780,\"start\":60770},{\"end\":60800,\"start\":60794},{\"end\":60808,\"start\":60802},{\"end\":61308,\"start\":61297},{\"end\":61321,\"start\":61316},{\"end\":61343,\"start\":61333},{\"end\":61361,\"start\":61350},{\"end\":61375,\"start\":61371},{\"end\":61395,\"start\":61384},{\"end\":61413,\"start\":61405},{\"end\":61432,\"start\":61424},{\"end\":61447,\"start\":61440},{\"end\":62077,\"start\":62073},{\"end\":62089,\"start\":62086},{\"end\":62103,\"start\":62099},{\"end\":62625,\"start\":62621},{\"end\":62642,\"start\":62636},{\"end\":62658,\"start\":62650},{\"end\":62673,\"start\":62666},{\"end\":62687,\"start\":62681},{\"end\":62701,\"start\":62696},{\"end\":62716,\"start\":62707},{\"end\":63015,\"start\":63011},{\"end\":63031,\"start\":63023},{\"end\":63048,\"start\":63042},{\"end\":63063,\"start\":63056},{\"end\":63079,\"start\":63074},{\"end\":63094,\"start\":63085},{\"end\":63814,\"start\":63812},{\"end\":63828,\"start\":63826},{\"end\":63838,\"start\":63835},{\"end\":63847,\"start\":63843},{\"end\":63860,\"start\":63857},{\"end\":64350,\"start\":64343},{\"end\":64372,\"start\":64364},{\"end\":64391,\"start\":64382},{\"end\":64408,\"start\":64403},{\"end\":64425,\"start\":64418},{\"end\":64442,\"start\":64436},{\"end\":64460,\"start\":64452},{\"end\":64834,\"start\":64826},{\"end\":64852,\"start\":64845},{\"end\":64864,\"start\":64861},{\"end\":64877,\"start\":64873},{\"end\":64896,\"start\":64883},{\"end\":64907,\"start\":64903},{\"end\":64925,\"start\":64920},{\"end\":64932,\"start\":64930},{\"end\":64947,\"start\":64938},{\"end\":65375,\"start\":65365},{\"end\":65395,\"start\":65382},{\"end\":65408,\"start\":65403},{\"end\":65417,\"start\":65415},{\"end\":65437,\"start\":65425},{\"end\":65452,\"start\":65447},{\"end\":65471,\"start\":65462},{\"end\":65486,\"start\":65480},{\"end\":66161,\"start\":66151},{\"end\":66178,\"start\":66172},{\"end\":66197,\"start\":66190},{\"end\":66670,\"start\":66668},{\"end\":66692,\"start\":66680},{\"end\":66708,\"start\":66704},{\"end\":66936,\"start\":66934},{\"end\":66951,\"start\":66946},{\"end\":66965,\"start\":66962},{\"end\":66975,\"start\":66972},{\"end\":67459,\"start\":67453},{\"end\":67476,\"start\":67468},{\"end\":67496,\"start\":67485},{\"end\":67514,\"start\":67507},{\"end\":67531,\"start\":67521},{\"end\":68078,\"start\":68074},{\"end\":68277,\"start\":68273},{\"end\":68291,\"start\":68285},{\"end\":68472,\"start\":68470},{\"end\":68483,\"start\":68479},{\"end\":68498,\"start\":68492},{\"end\":68909,\"start\":68904},{\"end\":68921,\"start\":68918},{\"end\":68945,\"start\":68931},{\"end\":68966,\"start\":68956},{\"end\":69439,\"start\":69434},{\"end\":69451,\"start\":69449},{\"end\":69473,\"start\":69467},{\"end\":69487,\"start\":69481},{\"end\":69499,\"start\":69495},{\"end\":70001,\"start\":69995},{\"end\":70015,\"start\":70010},{\"end\":70030,\"start\":70023},{\"end\":70046,\"start\":70038},{\"end\":70063,\"start\":70055},{\"end\":70074,\"start\":70070},{\"end\":70573,\"start\":70569},{\"end\":70584,\"start\":70581},{\"end\":70591,\"start\":70586},{\"end\":71001,\"start\":70991},{\"end\":71018,\"start\":71012},{\"end\":71302,\"start\":71299},{\"end\":71313,\"start\":71310},{\"end\":71325,\"start\":71322},{\"end\":71338,\"start\":71335},{\"end\":71353,\"start\":71350},{\"end\":71780,\"start\":71777},{\"end\":71795,\"start\":71790},{\"end\":71813,\"start\":71805},{\"end\":71825,\"start\":71821},{\"end\":71840,\"start\":71834},{\"end\":71854,\"start\":71847},{\"end\":71868,\"start\":71862},{\"end\":71888,\"start\":71881},{\"end\":72369,\"start\":72366},{\"end\":72384,\"start\":72379},{\"end\":72397,\"start\":72393},{\"end\":72408,\"start\":72406},{\"end\":72429,\"start\":72417},{\"end\":72692,\"start\":72689},{\"end\":72702,\"start\":72699},{\"end\":72717,\"start\":72713},{\"end\":72730,\"start\":72726},{\"end\":73157,\"start\":73152},{\"end\":73177,\"start\":73170},{\"end\":73193,\"start\":73186},{\"end\":73211,\"start\":73204},{\"end\":73225,\"start\":73220},{\"end\":73733,\"start\":73719},{\"end\":73750,\"start\":73744},{\"end\":73766,\"start\":73758},{\"end\":73782,\"start\":73775},{\"end\":73802,\"start\":73790},{\"end\":73815,\"start\":73811},{\"end\":73827,\"start\":73823},{\"end\":74390,\"start\":74384},{\"end\":74400,\"start\":74396},{\"end\":74413,\"start\":74407},{\"end\":74434,\"start\":74426},{\"end\":74441,\"start\":74439},{\"end\":74454,\"start\":74452},{\"end\":74824,\"start\":74821},{\"end\":74837,\"start\":74834},{\"end\":74850,\"start\":74845},{\"end\":74864,\"start\":74860},{\"end\":74878,\"start\":74872},{\"end\":74901,\"start\":74891},{\"end\":75285,\"start\":75281},{\"end\":75803,\"start\":75799},{\"end\":75821,\"start\":75813},{\"end\":75845,\"start\":75838},{\"end\":76144,\"start\":76139},{\"end\":76155,\"start\":76151},{\"end\":76174,\"start\":76168},{\"end\":76190,\"start\":76180},{\"end\":76632,\"start\":76625},{\"end\":76651,\"start\":76642},{\"end\":76667,\"start\":76661},{\"end\":76682,\"start\":76677},{\"end\":76695,\"start\":76690},{\"end\":77147,\"start\":77136},{\"end\":77157,\"start\":77153},{\"end\":77165,\"start\":77163},{\"end\":77182,\"start\":77176},{\"end\":77200,\"start\":77192},{\"end\":77209,\"start\":77207},{\"end\":77224,\"start\":77219},{\"end\":77241,\"start\":77233},{\"end\":77256,\"start\":77250},{\"end\":77277,\"start\":77268},{\"end\":77295,\"start\":77291},{\"end\":77307,\"start\":77305},{\"end\":77803,\"start\":77788},{\"end\":77816,\"start\":77810},{\"end\":77831,\"start\":77824},{\"end\":77847,\"start\":77839},{\"end\":77862,\"start\":77853},{\"end\":77878,\"start\":77872},{\"end\":78435,\"start\":78422},{\"end\":78451,\"start\":78443},{\"end\":78464,\"start\":78459},{\"end\":78482,\"start\":78473},{\"end\":78497,\"start\":78488},{\"end\":79010,\"start\":79002},{\"end\":79028,\"start\":79019},{\"end\":79474,\"start\":79468},{\"end\":79487,\"start\":79481},{\"end\":79501,\"start\":79496},{\"end\":79509,\"start\":79506},{\"end\":79517,\"start\":79515},{\"end\":79533,\"start\":79528},{\"end\":79544,\"start\":79542},{\"end\":79556,\"start\":79552},{\"end\":79569,\"start\":79563},{\"end\":79581,\"start\":79576},{\"end\":79594,\"start\":79588},{\"end\":79607,\"start\":79602},{\"end\":79622,\"start\":79615},{\"end\":80132,\"start\":80118},{\"end\":80146,\"start\":80141},{\"end\":80168,\"start\":80153},{\"end\":80183,\"start\":80176},{\"end\":80431,\"start\":80427},{\"end\":80440,\"start\":80438},{\"end\":80448,\"start\":80446},{\"end\":80460,\"start\":80456},{\"end\":80689,\"start\":80687},{\"end\":80699,\"start\":80696},{\"end\":80714,\"start\":80710},{\"end\":80725,\"start\":80723},{\"end\":80939,\"start\":80935},{\"end\":80954,\"start\":80949},{\"end\":80964,\"start\":80961},{\"end\":81363,\"start\":81361},{\"end\":81379,\"start\":81374},{\"end\":81389,\"start\":81385},{\"end\":81399,\"start\":81396},{\"end\":81412,\"start\":81409},{\"end\":81877,\"start\":81873},{\"end\":81891,\"start\":81889},{\"end\":82331,\"start\":82328},{\"end\":82345,\"start\":82342},{\"end\":82360,\"start\":82356},{\"end\":82385,\"start\":82372},{\"end\":82397,\"start\":82394},{\"end\":82403,\"start\":82399},{\"end\":82884,\"start\":82875},{\"end\":82901,\"start\":82892},{\"end\":83214,\"start\":83209},{\"end\":83231,\"start\":83226},{\"end\":83247,\"start\":83240},{\"end\":83264,\"start\":83255},{\"end\":83723,\"start\":83718},{\"end\":83733,\"start\":83730},{\"end\":83740,\"start\":83738},{\"end\":84210,\"start\":84205},{\"end\":84222,\"start\":84220},{\"end\":84236,\"start\":84232},{\"end\":84249,\"start\":84245},{\"end\":84268,\"start\":84262},{\"end\":84286,\"start\":84280},{\"end\":84810,\"start\":84806},{\"end\":84821,\"start\":84818},{\"end\":84836,\"start\":84833},{\"end\":84843,\"start\":84841},{\"end\":84860,\"start\":84855},{\"end\":90671,\"start\":90659}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":67855469},\"end\":56868,\"start\":56363},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":9089716},\"end\":57314,\"start\":56870},{\"attributes\":{\"id\":\"b2\"},\"end\":57596,\"start\":57316},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":220265500},\"end\":58049,\"start\":57598},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":245117332},\"end\":58687,\"start\":58051},{\"attributes\":{\"id\":\"b5\"},\"end\":58912,\"start\":58689},{\"attributes\":{\"doi\":\"abs/2209.04747\",\"id\":\"b6\"},\"end\":58972,\"start\":58914},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":57246310},\"end\":59487,\"start\":58974},{\"attributes\":{\"doi\":\"abs/1708.04552\",\"id\":\"b8\"},\"end\":59757,\"start\":59489},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":234357997},\"end\":60234,\"start\":59759},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":252873619},\"end\":60684,\"start\":60236},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":244923752},\"end\":61162,\"start\":60686},{\"attributes\":{\"doi\":\"2021. 1\",\"id\":\"b12\",\"matched_paper_id\":225039882},\"end\":61986,\"start\":61164},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":162168672},\"end\":62527,\"start\":61988},{\"attributes\":{\"doi\":\"abs/2103.02683\",\"id\":\"b14\"},\"end\":62962,\"start\":62529},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":235489699},\"end\":63718,\"start\":62964},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":251649167},\"end\":64291,\"start\":63720},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":215786368},\"end\":64731,\"start\":64293},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":229934464},\"end\":65328,\"start\":64733},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1033682},\"end\":66095,\"start\":65330},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":6706414},\"end\":66555,\"start\":66097},{\"attributes\":{\"id\":\"b21\"},\"end\":66878,\"start\":66557},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":206594692},\"end\":67361,\"start\":66880},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":326772},\"end\":67984,\"start\":67363},{\"attributes\":{\"id\":\"b24\"},\"end\":68181,\"start\":67986},{\"attributes\":{\"id\":\"b25\"},\"end\":68417,\"start\":68183},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":219955663},\"end\":68856,\"start\":68419},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":9433631},\"end\":69367,\"start\":68858},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":231592390},\"end\":69933,\"start\":69369},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":209202273},\"end\":70503,\"start\":69935},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":13193974},\"end\":70929,\"start\":70505},{\"attributes\":{\"id\":\"b31\"},\"end\":71271,\"start\":70931},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":141477988},\"end\":71723,\"start\":71273},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":14113767},\"end\":72282,\"start\":71725},{\"attributes\":{\"doi\":\"abs/2203.04838, 2022. 1\",\"id\":\"b34\"},\"end\":72638,\"start\":72284},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":459456},\"end\":73076,\"start\":72640},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":3488815},\"end\":73633,\"start\":73078},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":12424035},\"end\":74307,\"start\":73635},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":16852518},\"end\":74766,\"start\":74309},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":248811081},\"end\":75183,\"start\":74768},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":5787669},\"end\":75718,\"start\":75185},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":11771103},\"end\":76089,\"start\":75720},{\"attributes\":{\"doi\":\"2023. 3\",\"id\":\"b42\",\"matched_paper_id\":252596091},\"end\":76555,\"start\":76091},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":245335280},\"end\":77127,\"start\":76557},{\"attributes\":{\"id\":\"b44\"},\"end\":77731,\"start\":77129},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":249461756},\"end\":78321,\"start\":77733},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":219980448},\"end\":78926,\"start\":78323},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":14124313},\"end\":79396,\"start\":78928},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":252595919},\"end\":80107,\"start\":79398},{\"attributes\":{\"doi\":\"2023. 3\",\"id\":\"b49\"},\"end\":80357,\"start\":80109},{\"attributes\":{\"doi\":\"abs/1703.01340\",\"id\":\"b50\"},\"end\":80621,\"start\":80359},{\"attributes\":{\"id\":\"b51\"},\"end\":80864,\"start\":80623},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":235417493},\"end\":81317,\"start\":80866},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":249282169},\"end\":81822,\"start\":81319},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":235804333},\"end\":82231,\"start\":81824},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":152282661},\"end\":82842,\"start\":82233},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":15276198},\"end\":83157,\"start\":82844},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":3162051},\"end\":83630,\"start\":83159},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":236980304},\"end\":84126,\"start\":83632},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":59222747},\"end\":84697,\"start\":84128},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":237456156},\"end\":85131,\"start\":84699},{\"attributes\":{\"id\":\"b61\"},\"end\":85325,\"start\":85133},{\"attributes\":{\"id\":\"b62\"},\"end\":86045,\"start\":85327},{\"attributes\":{\"id\":\"b63\"},\"end\":87608,\"start\":86047},{\"attributes\":{\"id\":\"b64\"},\"end\":89851,\"start\":87610},{\"attributes\":{\"id\":\"b65\"},\"end\":93339,\"start\":89853},{\"attributes\":{\"id\":\"b66\"},\"end\":94043,\"start\":93341},{\"attributes\":{\"id\":\"b67\"},\"end\":94328,\"start\":94045},{\"attributes\":{\"id\":\"b68\"},\"end\":94502,\"start\":94330}]", "bib_title": "[{\"end\":56443,\"start\":56363},{\"end\":56919,\"start\":56870},{\"end\":57654,\"start\":57598},{\"end\":58172,\"start\":58051},{\"end\":59025,\"start\":58974},{\"end\":59804,\"start\":59759},{\"end\":60291,\"start\":60236},{\"end\":60752,\"start\":60686},{\"end\":61288,\"start\":61164},{\"end\":62068,\"start\":61988},{\"end\":63004,\"start\":62964},{\"end\":63801,\"start\":63720},{\"end\":64334,\"start\":64293},{\"end\":64818,\"start\":64733},{\"end\":65357,\"start\":65330},{\"end\":66143,\"start\":66097},{\"end\":66924,\"start\":66880},{\"end\":67444,\"start\":67363},{\"end\":68459,\"start\":68419},{\"end\":68898,\"start\":68858},{\"end\":69425,\"start\":69369},{\"end\":69988,\"start\":69935},{\"end\":70563,\"start\":70505},{\"end\":71289,\"start\":71273},{\"end\":71766,\"start\":71725},{\"end\":72681,\"start\":72640},{\"end\":73139,\"start\":73078},{\"end\":73712,\"start\":73635},{\"end\":74376,\"start\":74309},{\"end\":74813,\"start\":74768},{\"end\":75267,\"start\":75185},{\"end\":75785,\"start\":75720},{\"end\":76133,\"start\":76091},{\"end\":76617,\"start\":76557},{\"end\":77780,\"start\":77733},{\"end\":78416,\"start\":78323},{\"end\":78994,\"start\":78928},{\"end\":79460,\"start\":79398},{\"end\":80925,\"start\":80866},{\"end\":81356,\"start\":81319},{\"end\":81861,\"start\":81824},{\"end\":82318,\"start\":82233},{\"end\":82866,\"start\":82844},{\"end\":83200,\"start\":83159},{\"end\":83707,\"start\":83632},{\"end\":84194,\"start\":84128},{\"end\":84798,\"start\":84699},{\"end\":85519,\"start\":85327},{\"end\":86558,\"start\":86047},{\"end\":88213,\"start\":87610},{\"end\":93542,\"start\":93341}]", "bib_author": "[{\"end\":56458,\"start\":56445},{\"end\":56473,\"start\":56458},{\"end\":56490,\"start\":56473},{\"end\":56938,\"start\":56921},{\"end\":56953,\"start\":56938},{\"end\":56967,\"start\":56953},{\"end\":57427,\"start\":57410},{\"end\":57439,\"start\":57427},{\"end\":57671,\"start\":57656},{\"end\":57690,\"start\":57671},{\"end\":58190,\"start\":58174},{\"end\":58204,\"start\":58190},{\"end\":58218,\"start\":58204},{\"end\":58742,\"start\":58727},{\"end\":58757,\"start\":58742},{\"end\":58765,\"start\":58757},{\"end\":58777,\"start\":58765},{\"end\":58794,\"start\":58777},{\"end\":58800,\"start\":58794},{\"end\":58922,\"start\":58916},{\"end\":59037,\"start\":59027},{\"end\":59047,\"start\":59037},{\"end\":59063,\"start\":59047},{\"end\":59074,\"start\":59063},{\"end\":59082,\"start\":59074},{\"end\":59094,\"start\":59082},{\"end\":59577,\"start\":59559},{\"end\":59594,\"start\":59577},{\"end\":59825,\"start\":59806},{\"end\":59842,\"start\":59825},{\"end\":59851,\"start\":59842},{\"end\":60301,\"start\":60293},{\"end\":60321,\"start\":60301},{\"end\":60341,\"start\":60321},{\"end\":60349,\"start\":60341},{\"end\":60762,\"start\":60754},{\"end\":60782,\"start\":60762},{\"end\":60802,\"start\":60782},{\"end\":60810,\"start\":60802},{\"end\":61310,\"start\":61290},{\"end\":61323,\"start\":61310},{\"end\":61345,\"start\":61323},{\"end\":61363,\"start\":61345},{\"end\":61377,\"start\":61363},{\"end\":61397,\"start\":61377},{\"end\":61415,\"start\":61397},{\"end\":61434,\"start\":61415},{\"end\":61449,\"start\":61434},{\"end\":62079,\"start\":62070},{\"end\":62091,\"start\":62079},{\"end\":62105,\"start\":62091},{\"end\":62627,\"start\":62616},{\"end\":62644,\"start\":62627},{\"end\":62660,\"start\":62644},{\"end\":62675,\"start\":62660},{\"end\":62689,\"start\":62675},{\"end\":62703,\"start\":62689},{\"end\":62718,\"start\":62703},{\"end\":63017,\"start\":63006},{\"end\":63033,\"start\":63017},{\"end\":63050,\"start\":63033},{\"end\":63065,\"start\":63050},{\"end\":63081,\"start\":63065},{\"end\":63096,\"start\":63081},{\"end\":63816,\"start\":63803},{\"end\":63830,\"start\":63816},{\"end\":63840,\"start\":63830},{\"end\":63849,\"start\":63840},{\"end\":63862,\"start\":63849},{\"end\":64352,\"start\":64336},{\"end\":64374,\"start\":64352},{\"end\":64393,\"start\":64374},{\"end\":64410,\"start\":64393},{\"end\":64427,\"start\":64410},{\"end\":64444,\"start\":64427},{\"end\":64462,\"start\":64444},{\"end\":64836,\"start\":64820},{\"end\":64854,\"start\":64836},{\"end\":64866,\"start\":64854},{\"end\":64879,\"start\":64866},{\"end\":64898,\"start\":64879},{\"end\":64909,\"start\":64898},{\"end\":64927,\"start\":64909},{\"end\":64934,\"start\":64927},{\"end\":64949,\"start\":64934},{\"end\":65377,\"start\":65359},{\"end\":65397,\"start\":65377},{\"end\":65410,\"start\":65397},{\"end\":65419,\"start\":65410},{\"end\":65439,\"start\":65419},{\"end\":65454,\"start\":65439},{\"end\":65473,\"start\":65454},{\"end\":65488,\"start\":65473},{\"end\":66163,\"start\":66145},{\"end\":66180,\"start\":66163},{\"end\":66199,\"start\":66180},{\"end\":66672,\"start\":66661},{\"end\":66694,\"start\":66672},{\"end\":66710,\"start\":66694},{\"end\":66938,\"start\":66926},{\"end\":66953,\"start\":66938},{\"end\":66967,\"start\":66953},{\"end\":66977,\"start\":66967},{\"end\":67461,\"start\":67446},{\"end\":67478,\"start\":67461},{\"end\":67498,\"start\":67478},{\"end\":67516,\"start\":67498},{\"end\":67533,\"start\":67516},{\"end\":68080,\"start\":68066},{\"end\":68279,\"start\":68265},{\"end\":68293,\"start\":68279},{\"end\":68474,\"start\":68461},{\"end\":68485,\"start\":68474},{\"end\":68500,\"start\":68485},{\"end\":68911,\"start\":68900},{\"end\":68923,\"start\":68911},{\"end\":68947,\"start\":68923},{\"end\":68968,\"start\":68947},{\"end\":69441,\"start\":69427},{\"end\":69453,\"start\":69441},{\"end\":69475,\"start\":69453},{\"end\":69489,\"start\":69475},{\"end\":69501,\"start\":69489},{\"end\":70003,\"start\":69990},{\"end\":70017,\"start\":70003},{\"end\":70032,\"start\":70017},{\"end\":70048,\"start\":70032},{\"end\":70065,\"start\":70048},{\"end\":70076,\"start\":70065},{\"end\":70575,\"start\":70565},{\"end\":70586,\"start\":70575},{\"end\":70593,\"start\":70586},{\"end\":71003,\"start\":70986},{\"end\":71020,\"start\":71003},{\"end\":71304,\"start\":71291},{\"end\":71315,\"start\":71304},{\"end\":71327,\"start\":71315},{\"end\":71340,\"start\":71327},{\"end\":71355,\"start\":71340},{\"end\":71782,\"start\":71768},{\"end\":71797,\"start\":71782},{\"end\":71815,\"start\":71797},{\"end\":71827,\"start\":71815},{\"end\":71842,\"start\":71827},{\"end\":71856,\"start\":71842},{\"end\":71870,\"start\":71856},{\"end\":71890,\"start\":71870},{\"end\":72371,\"start\":72359},{\"end\":72386,\"start\":72371},{\"end\":72399,\"start\":72386},{\"end\":72410,\"start\":72399},{\"end\":72431,\"start\":72410},{\"end\":72694,\"start\":72683},{\"end\":72704,\"start\":72694},{\"end\":72719,\"start\":72704},{\"end\":72732,\"start\":72719},{\"end\":73159,\"start\":73141},{\"end\":73179,\"start\":73159},{\"end\":73195,\"start\":73179},{\"end\":73213,\"start\":73195},{\"end\":73227,\"start\":73213},{\"end\":73735,\"start\":73714},{\"end\":73752,\"start\":73735},{\"end\":73768,\"start\":73752},{\"end\":73784,\"start\":73768},{\"end\":73804,\"start\":73784},{\"end\":73817,\"start\":73804},{\"end\":73829,\"start\":73817},{\"end\":74392,\"start\":74378},{\"end\":74402,\"start\":74392},{\"end\":74415,\"start\":74402},{\"end\":74436,\"start\":74415},{\"end\":74443,\"start\":74436},{\"end\":74456,\"start\":74443},{\"end\":74826,\"start\":74815},{\"end\":74839,\"start\":74826},{\"end\":74852,\"start\":74839},{\"end\":74866,\"start\":74852},{\"end\":74880,\"start\":74866},{\"end\":74903,\"start\":74880},{\"end\":75287,\"start\":75269},{\"end\":75805,\"start\":75787},{\"end\":75823,\"start\":75805},{\"end\":75847,\"start\":75823},{\"end\":76146,\"start\":76135},{\"end\":76157,\"start\":76146},{\"end\":76176,\"start\":76157},{\"end\":76192,\"start\":76176},{\"end\":76634,\"start\":76619},{\"end\":76653,\"start\":76634},{\"end\":76669,\"start\":76653},{\"end\":76684,\"start\":76669},{\"end\":76697,\"start\":76684},{\"end\":77149,\"start\":77131},{\"end\":77159,\"start\":77149},{\"end\":77167,\"start\":77159},{\"end\":77184,\"start\":77167},{\"end\":77202,\"start\":77184},{\"end\":77211,\"start\":77202},{\"end\":77226,\"start\":77211},{\"end\":77243,\"start\":77226},{\"end\":77258,\"start\":77243},{\"end\":77279,\"start\":77258},{\"end\":77297,\"start\":77279},{\"end\":77309,\"start\":77297},{\"end\":77805,\"start\":77782},{\"end\":77818,\"start\":77805},{\"end\":77833,\"start\":77818},{\"end\":77849,\"start\":77833},{\"end\":77864,\"start\":77849},{\"end\":77880,\"start\":77864},{\"end\":78437,\"start\":78418},{\"end\":78453,\"start\":78437},{\"end\":78466,\"start\":78453},{\"end\":78484,\"start\":78466},{\"end\":78499,\"start\":78484},{\"end\":79012,\"start\":78996},{\"end\":79030,\"start\":79012},{\"end\":79476,\"start\":79462},{\"end\":79489,\"start\":79476},{\"end\":79503,\"start\":79489},{\"end\":79511,\"start\":79503},{\"end\":79519,\"start\":79511},{\"end\":79535,\"start\":79519},{\"end\":79546,\"start\":79535},{\"end\":79558,\"start\":79546},{\"end\":79571,\"start\":79558},{\"end\":79583,\"start\":79571},{\"end\":79596,\"start\":79583},{\"end\":79609,\"start\":79596},{\"end\":79624,\"start\":79609},{\"end\":80134,\"start\":80111},{\"end\":80148,\"start\":80134},{\"end\":80170,\"start\":80148},{\"end\":80185,\"start\":80170},{\"end\":80433,\"start\":80419},{\"end\":80442,\"start\":80433},{\"end\":80450,\"start\":80442},{\"end\":80462,\"start\":80450},{\"end\":80691,\"start\":80682},{\"end\":80701,\"start\":80691},{\"end\":80716,\"start\":80701},{\"end\":80727,\"start\":80716},{\"end\":80941,\"start\":80927},{\"end\":80956,\"start\":80941},{\"end\":80966,\"start\":80956},{\"end\":81365,\"start\":81358},{\"end\":81381,\"start\":81365},{\"end\":81391,\"start\":81381},{\"end\":81401,\"start\":81391},{\"end\":81414,\"start\":81401},{\"end\":81879,\"start\":81863},{\"end\":81893,\"start\":81879},{\"end\":82333,\"start\":82320},{\"end\":82347,\"start\":82333},{\"end\":82362,\"start\":82347},{\"end\":82387,\"start\":82362},{\"end\":82399,\"start\":82387},{\"end\":82405,\"start\":82399},{\"end\":82886,\"start\":82868},{\"end\":82903,\"start\":82886},{\"end\":83216,\"start\":83202},{\"end\":83233,\"start\":83216},{\"end\":83249,\"start\":83233},{\"end\":83266,\"start\":83249},{\"end\":83725,\"start\":83709},{\"end\":83735,\"start\":83725},{\"end\":83742,\"start\":83735},{\"end\":84212,\"start\":84196},{\"end\":84224,\"start\":84212},{\"end\":84238,\"start\":84224},{\"end\":84251,\"start\":84238},{\"end\":84270,\"start\":84251},{\"end\":84288,\"start\":84270},{\"end\":84812,\"start\":84800},{\"end\":84823,\"start\":84812},{\"end\":84838,\"start\":84823},{\"end\":84845,\"start\":84838},{\"end\":84862,\"start\":84845},{\"end\":90673,\"start\":90659}]", "bib_venue": "[{\"end\":56565,\"start\":56490},{\"end\":57042,\"start\":56967},{\"end\":57408,\"start\":57316},{\"end\":57773,\"start\":57690},{\"end\":58306,\"start\":58218},{\"end\":58725,\"start\":58689},{\"end\":59178,\"start\":59094},{\"end\":59557,\"start\":59489},{\"end\":59973,\"start\":59851},{\"end\":60415,\"start\":60349},{\"end\":60879,\"start\":60810},{\"end\":61537,\"start\":61456},{\"end\":62227,\"start\":62105},{\"end\":62614,\"start\":62529},{\"end\":63237,\"start\":63096},{\"end\":63945,\"start\":63862},{\"end\":64489,\"start\":64462},{\"end\":65011,\"start\":64949},{\"end\":65629,\"start\":65488},{\"end\":66281,\"start\":66199},{\"end\":66659,\"start\":66557},{\"end\":67061,\"start\":66977},{\"end\":67655,\"start\":67533},{\"end\":68064,\"start\":67986},{\"end\":68263,\"start\":68183},{\"end\":68622,\"start\":68500},{\"end\":69052,\"start\":68968},{\"end\":69583,\"start\":69501},{\"end\":70164,\"start\":70076},{\"end\":70668,\"start\":70593},{\"end\":70984,\"start\":70931},{\"end\":71477,\"start\":71355},{\"end\":71959,\"start\":71890},{\"end\":72357,\"start\":72284},{\"end\":72806,\"start\":72732},{\"end\":73309,\"start\":73227},{\"end\":73917,\"start\":73829},{\"end\":74523,\"start\":74456},{\"end\":74954,\"start\":74903},{\"end\":75388,\"start\":75287},{\"end\":75885,\"start\":75847},{\"end\":76281,\"start\":76199},{\"end\":76785,\"start\":76697},{\"end\":77356,\"start\":77309},{\"end\":78002,\"start\":77880},{\"end\":78574,\"start\":78499},{\"end\":79112,\"start\":79030},{\"end\":79707,\"start\":79624},{\"end\":80225,\"start\":80192},{\"end\":80417,\"start\":80359},{\"end\":80680,\"start\":80623},{\"end\":81041,\"start\":80966},{\"end\":81498,\"start\":81414},{\"end\":81968,\"start\":81893},{\"end\":82483,\"start\":82405},{\"end\":82962,\"start\":82903},{\"end\":83348,\"start\":83266},{\"end\":83826,\"start\":83742},{\"end\":84363,\"start\":84288},{\"end\":84899,\"start\":84862},{\"end\":85226,\"start\":85133},{\"end\":85588,\"start\":85521},{\"end\":86691,\"start\":86560},{\"end\":88378,\"start\":88215},{\"end\":90657,\"start\":89853},{\"end\":93612,\"start\":93544},{\"end\":94185,\"start\":94045},{\"end\":94394,\"start\":94330},{\"end\":56627,\"start\":56567},{\"end\":57104,\"start\":57044},{\"end\":57843,\"start\":57775},{\"end\":58381,\"start\":58308},{\"end\":59249,\"start\":59180},{\"end\":60468,\"start\":60417},{\"end\":60935,\"start\":60881},{\"end\":61605,\"start\":61539},{\"end\":63365,\"start\":63239},{\"end\":64015,\"start\":63947},{\"end\":65757,\"start\":65631},{\"end\":66350,\"start\":66283},{\"end\":67132,\"start\":67063},{\"end\":69123,\"start\":69054},{\"end\":69652,\"start\":69585},{\"end\":70239,\"start\":70166},{\"end\":70730,\"start\":70670},{\"end\":72015,\"start\":71961},{\"end\":72867,\"start\":72808},{\"end\":73378,\"start\":73311},{\"end\":73992,\"start\":73919},{\"end\":75476,\"start\":75390},{\"end\":76350,\"start\":76283},{\"end\":76860,\"start\":76787},{\"end\":78636,\"start\":78576},{\"end\":79181,\"start\":79114},{\"end\":79777,\"start\":79709},{\"end\":81103,\"start\":81043},{\"end\":81569,\"start\":81500},{\"end\":82030,\"start\":81970},{\"end\":82548,\"start\":82485},{\"end\":83008,\"start\":82964},{\"end\":83417,\"start\":83350},{\"end\":83897,\"start\":83828},{\"end\":84425,\"start\":84365}]"}}}, "year": 2023, "month": 12, "day": 17}