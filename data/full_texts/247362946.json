{"id": 247362946, "updated": "2023-10-05 16:29:43.649", "metadata": {"title": "Compilable Neural Code Generation with Compiler Feedback", "authors": "[{\"first\":\"Xin\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Yasheng\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Yao\",\"last\":\"Wan\",\"middle\":[]},{\"first\":\"Fei\",\"last\":\"Mi\",\"middle\":[]},{\"first\":\"Yitong\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Pingyi\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Jin\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Hao\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Xin\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Qun\",\"last\":\"Liu\",\"middle\":[]}]", "venue": "FINDINGS", "journal": "Findings of the Association for Computational Linguistics: ACL 2022", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Automatically generating compilable programs with (or without) natural language descriptions has always been a touchstone problem for computational linguistics and automated software engineering. Existing deep-learning approaches model code generation as text generation, either constrained by grammar structures in decoder, or driven by pre-trained language models on large-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of them account for compilability of the generated programs. To improve compilability of the generated programs, this paper proposes COMPCODER, a three-stage pipeline utilizing compiler feedback for compilable code generation, including language model fine-tuning, compilability reinforcement, and compilability discrimination. Comprehensive experiments on two code generation tasks demonstrate the effectiveness of our proposed approach, improving the success rate of compilation from 44.18 to 89.18 in code completion on average and from 70.3 to 96.2 in text-to-code generation, respectively, when comparing with the state-of-the-art CodeGPT.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2203.05132", "mag": null, "acl": "2022.findings-acl.2", "pubmed": null, "pubmedcentral": null, "dblp": "conf/acl/WangWWMLZLWJL22", "doi": "10.18653/v1/2022.findings-acl.2"}}, "content": {"source": {"pdf_hash": "6f6836a4390c2f8aa43c6d8f4273a4cb71dca89a", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2022.findings-acl.2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "131931e3017f7c6592160d720854c4e90fc3da02", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6f6836a4390c2f8aa43c6d8f4273a4cb71dca89a.txt", "contents": "\nCompilable Neural Code Generation with Compiler Feedback\nAssociation for Computational LinguisticsCopyright Association for Computational Linguistics19 May 22-27, 2022 c 2022\n\nXin Wang \nSchool of Computer Science\nWuhan University\nChina\n\nYashengWang 2\u22c6 \nHuawei Noah's Ark Lab\n\n\nYao Wan wanyao@hust.edu.cn \nSchool of Computer Sci. & Tech\nHuazhong University of Science and Technology\nChina\n\nFei Mi \nHuawei Noah's Ark Lab\n\n\nYitong Li \nHuawei Noah's Ark Lab\n\n\nHuawei Technologies Co., Ltd\n\n\nPingyi Zhou \nHuawei Noah's Ark Lab\n\n\nJin Liu jinliu@whu.edu.cn \nSchool of Computer Science\nWuhan University\nChina\n\nHao Wu haowu@ynu.edu.cnwangyasheng \nSchool of Information Science and Engineering\nYunnan University\nChina\n\nXin Jiang \nHuawei Noah's Ark Lab\n\n\nQun Liu qun.liu@huawei.com \nHuawei Noah's Ark Lab\n\n\nCompilable Neural Code Generation with Compiler Feedback\n\nAssociation for Computational Linguistics: ACL 2022\nAssociation for Computational Linguistics919 May 22-27, 2022 c 2022\nAutomatically generating compilable programs with (or without) natural language descriptions has always been a touchstone problem for computational linguistics and automated software engineering. Existing deep-learning approaches model code generation as text generation, either constrained by grammar structures in decoder, or driven by pre-trained language models on large-scale code corpus (e.g., CodeGPT, PLBART, and CodeT5). However, few of them account for compilability of the generated programs. To improve compilability of the generated programs, this paper proposes COMPCODER, a three-stage pipeline utilizing compiler feedback for compilable code generation, including language model fine-tuning, compilability reinforcement, and compilability discrimination. Comprehensive experiments on two code generation tasks demonstrate the effectiveness of our proposed approach, improving the success rate of compilation from 44.18 to 89.18 in code completion on average and from 70.3 to 96.2 in text-to-code generation, respectively, when comparing with the state-ofthe-art CodeGPT.\n\nIntroduction\n\nAutomated code generation (or program synthesis) has attracted much attention over the past few years (Lu et al., 2021), because of its potential to improve the productivity of developers, as well as to speed up the software development (Parvez et al., 2021;. In the life cycle of software development, different types of code generation tasks are desired, including code completion (Liu et al., 2020b,a), text-to-code generation (Hashimoto et al., 2018), program translation , and program repair (Yasunaga and Liang, 2021). Recently, much effort has been made to advance the development of code generation (Li et al., 2018), using different logical forms of code, such as the abstract syntax tree (AST) (Kim et al., 2021;Yin and Neubig, 2017;Rabinovich et al., 2017), sketch (Nye et al., 2019) and graph (Yasunaga and Liang, 2020). Benefiting from the strong power of pre-training techniques (Devlin et al., 2019;Wang et al., 2021a) in natural language processing, several attempts have been made towards pretraining a language model on large-scale code corpus for code generation, such as CodeGPT (Lu et al., 2021), PLBART (Ahmad et al., 2021), and CodeT5 (Wang et al., 2021b).\n\nHowever, to the best of our knowledge, most deep-learning approaches for code generation are still difficult to guarantee the compilability of the generated code, resulting in non-compilable code. For example, Chen et al. (2021) found that up to 67%-97% of patches generated by the most advanced deep-learning-based models are non-compilable. We think this is because they generally do not directly optimize the compilability for code generation. The generation of non-compilable code will waste the time of programmers, as well as seriously reduce the trust and satisfaction of developers with the model. To improve the compilability of the generated code, some works attempt to repair the synthesized program which fails to compile (Kulal et al., 2019;Liang, 2020, 2021). Recently, Korbak et al. (2021) attempt to directly generate compilable code using an energy model with compilability constraints. This paper focuses on the task of compilable neural code generation. Different from previous works, we use compilability signals in two ways and design a novel method to jointly train the discriminator and generator for compilable code generation. Concretely, we propose COMPCODER, a novel three-stage pipeline utilizing compiler feedback for compilable code generation, including language model fine-tuning, compilability reinforcement, and compilability discrimination. Figure 1 shows an example of Python code completion by COMPCODER, which utilizes the compiler feedback in two ways. In Figure 1(b), we use the compiler feedback to optimize the generator. In Figure 1(c), we use the discriminator to check if the results generated by the generator can be successfully compiled. The joint training of the generator and discriminator significantly improves the compilability of the generated code.\n\nOverall, the key contributions of this paper are as follows:\n\n\u2022 We use compilability signals in two ways and design a novel method to jointly train the generator and discriminator for compilable code generation, called COMPCODER. We refine a pre-trained code generator using reinforcement learning and jointly learn a discriminator to enforce the generator to correct its own mistakes.\n\n\u2022 Comprehensive experiments on two code generation tasks demonstrate the effectiveness of COMPCODER. It boosts the average compilation rate of CodeGPT from 44.18 to 89.18 in the code completion task and from 70.3 to 96.2 in the text-to-code generation task.\n\n\nPreliminary\n\nIn this section, we set out notations for task formulation, as well as some preliminaries of compiler feedback. Let s \u2208 S denote a given input, which can be a piece of partial code, natural-language description, or buggy program. Let t \u2208 T denote the generated source code. Formally, the problem of code generation can be formulated as learning a mapping f between the input space and target code space, i.e. f : S \u2192 T . In this paper, we investigate two specific code generation tasks, code completion and text-to-code generation, conditioned on different inputs.\n\nCode Completion Let c = {c 1 , c 2 , . . . , c |c| } denote a sequence of code tokens for program c, where |c| denotes the length of the code. We use notation c 1 : m \u2208 S to refer to the previous code snippet {c 1 , c 2 , . . . , c m } and notation c m+1 : |c| \u2208 T to represent the subsequent code snippet {c m+1 , . . . , c |c| }. The code completion task can be defined as generating the subsequent (t) code token sequence c m+1 : |c| , given the previous (s) code sequence c 1 : m .\n\nText-to-Code Generation Different from code completion, text-to-code generation aims to generate a whole program based on natural language description. Let d = {d 1 , d 2 , . . . , d |d| } refer to a sequence of natural-language tokens. The text-tocode generation task can be defined as generating source code c = t \u2208 T , given the corresponding natural language description d = s \u2208 S.\n\nCompiler Feedback As the whole program c is generated, no matter from partial code snippets or natural-language descriptions, we feed it into a compiler to test whether it can be compiled successfully. Formally, we define the the compiler feedback as:\nfeedback = 1 Compiler (c) ,(1)\nwhere the compiler feedback is a binary value (compilable or non-compilable), and c denotes the code snippet fed into the compiler. As for the task of text-to-code generation, we simply feed the generated code t into the compiler, i.e., c = t. As for the task of code completion, we concatenate the partial code with generated code as a whole program, i.e., c = [s; t], where ; is the concatenation operation. Figure 2 shows the overall architecture of COMP-CODER on the code completion task, which covers three stages, i.e., language model fine-tuning (Stage 1), compilability reinforcement (Stage 2) and compilability discrimination (Stage 3). In the following  Figure 2: An illustration of our proposed three-stage pipeline for Python code completion. (a) We first fine-tune the generator based on pre-trained language models. (b) We take the compiler feedback into account as a reward via reinforcement learning. (c) We design a compilability discriminator which is jointly trained with the generator, to enforce the generator to correct its own mistakes. Stages 2 and 3 are performed alternately.\n\n\nCOMPCODER\n\nsubsections, we will elaborate on each stage one by one. We alternately perform Stages 2 and 3, as described in Section 3.4.\n\n\nStage 1: Language Model Fine-Tuning\n\nAs shown in Figure 2(a), we adopt CodeGPT as the generator, which uses GPT-2  as the starting point and is continually pre-trained on the large-scale code corpus. Our generator is then fine-tuned on the target task to minimize the cross-entropy loss:\nL G = \u2212 1 |M| |M| i |V| j Y ij log P ij ,(2)\nwhere M denotes the set of the generated code tokens, V represents the vocabulary, Y ij denotes the label of the code token i in class j, and P ij is the predicted probability of token i in class j. During training, the generator takes x = {<BOS>, c, <EOS>} as the input in the code completion task, and x = {d, <BOS>, c, <EOS>} as input in the text-to-code generation task, correspondingly. Special tokens <BOS> and <EOS> indicate the start and end symbols of code sequences. After several epochs of supervised fine-tuning on the target task dataset, we save the trained generator, which will be used in the next stage.\n\n\nStage 2: Compilability Reinforcement\n\nReinforcement Learning (RL) is a method of learning the optimal policy by obtaining reward signals from the real environment (Sutton and Barto, 1998;Wan et al., 2018). As shown in Figure 2(b), we use the fine-tuned generator \u03c1 (after Stage 1) as the reference model. Then we initialize a policy \u03c0 = \u03c1. Given an input sequence s \u2208 S, our goal is to find a policy \u03c0 that generates an output sequence t \u2208 T with the objective of maximizing the compilability-based reward. We use RL (specifically PPO2 version of Proximal Policy Optimization (Schulman et al., 2017)) to directly optimize the expected reward as:\nE \u03c0 [r] = E s\u223cS,t\u223c\u03c0(.|s) [r(s, t)] ,(3)\nwhere the policy \u03c0 is rewarded by the compiler (Eq. 1), r is the reward function. We define r(s, t) = 1.0 iff the code can be compiled by the program compiler and r(s, t) = \u22121.0 otherwise. It is worth mentioning that code compilability constraints can be strong or weak. Strong constraint is defined that a long piece of code snippet may not be correctly compiled if a certain token is changed. And weak constraint means a blank string consisting of whitespace characters can be correctly compiled by the compiler. Concretely, in the text-to-code generation task, if the generator generates a string composed of whitespace characters, the compiler will consider it as a good case. In the code completion task, if the previous code snippet is compilable, the generator can fool the compiler easily. The RL is good at making use of this, resulting in the generated code can be com-  Figure 3: An example of code completion. We mask the last five tokens of the code and let the generator complete them. Some minor mistakes prevent four candidates from being correctly compiled by the program compiler.\n\npiled, but seriously deviating from the generation likelihood objective. To avoid active model \u03c0 being too far away from reference model \u03c1, we add a Kullback-Leibler (KL) penalty with expectation, e.g., \u03b2KL(\u03c0, \u03c1) (Ziegler et al., 2019). Therefore, the modified reward will be reformulated as follows:\nr(s, t) = r(s, t) \u2212 \u03b2 log \u03c0(t|s) \u03c1(t|s) ,(4)\nwhere \u03b2 is a constant, which plays the role of an entropy bonus, preventing the policy from moving too far from the range where r is valid.\n\nTo alleviate the imbalance between the reward term and the KL penalty term and improve the stability of training, we use autoregressive fine-tuning (Causal Language Modeling)  to make the KL penalty term fluctuate within a small range after RL training. This fine-tuning process incorporates a compilability-aware discriminator that will be introduced in the next stage. Figure 3 shows an example of code completion. We mask the last five tokens of a Python function and ask the generator to complete them. The generator generates five candidates with high probabilities. Some minor mistakes prevent four of them from being successfully compiled. We hope the generator can have more perception power to explicitly distinguish compilable and non-compilable code generated by itself. Therefore, at this stage, we design a compilability-aware discriminator to deal with this issue.\n\n\nStage 3: Compilability Discrimination\n\nConcretely, we add a discriminator (a two-layer MLP equipped with the tanh activation function between layers) after the final hidden layer of the generator. As shown in Figure 2(c), given the input sequence (s), we perform beam search on the generator to generate top-k candidates (t). Each entire code c \u2208 Q (c = [s; t] in the code completion task) is labeled by the program compiler as positive (1) or negative (0), depending on whether it can be successfully compiled (see Eq. 1).\n\nWe use the hidden representation of the last token (<EOS>) as the final representation of the entire code c. Finally, the hidden representation of the last token (<EOS>) is fed into the discriminator for prediction:\nh <EOS> = CodeGPT(s, t) ,(5)h \u2032 <EOS> = Discriminator(h <EOS> ) , (6) P (.|t, s) = softmax(h \u2032 <EOS> ) ,(7)\nwhere h <EOS> denotes the representation of the last token <EOS>. The training loss of the discrimination process can be defined as:\nL D = \u2212 1 |Q + \u222a Q \u2212 | \uf8ee \uf8f0 c\u2208Q + log P (1|t, s) + c\u2208Q \u2212 log P (0|t, s) \uf8f9 \uf8fb ,(8)\nwhere Q + and Q \u2212 represent positive and negative sets respectively. The parameters of the generator and discriminator will be jointly updated.\n\nAt this stage, we jointly train the generator and discriminator, including a generating objective (to learn the generator only) and a discriminating objective (to learn the generator and discriminator together), as shown in Figure 2(c). The joint training loss is defined as follows:\nL = L G + L D .(9)\n\nOverall Pipeline\n\nTraining Procedure We perform an interactive training procedure. Concretely, except that the first epoch contains Stages 1, 2, and 3, each subsequent epoch only consists of Stages 2 and 3. We update the reference model (at Stage 2), and candidates in Stage 3 is generated on the training dataset, which is time consuming, so we update the candidates in a preset frequency. For better understanding, Stage 2 improves the compilability of generated code, Stage 3 distinguishes the compilable and non-compilable code generated by itself. Stage 2 and 3 refine each other and improve the performance iteratively, which is a basic idea of this training procedure. We think that the generator with high compilability (after Stage 2) facilitates the learning of the discriminator (discriminating objective at Stage 3). The autoregressive fine-tuning (generating objective at Stage 3) helps the KL penalty term (at Stage 2) fluctuate in a small range, improving the stability of RL training. At Stage 3, the discriminating objective is optimized by learning the generator and discriminator together, which makes the generator have more perception power to distinguish compilable and non-compilable code.\n\nInference Procedure The model inference consists of two stages. Given an input sequence (s), we perform the beam search on the generator to generate top-k candidates. The code (c in Eq. 1) with the highest compilability probability evaluated by the discriminator will be selected. Then the output (t) can be obtained as the final result.\n\n\nExperiment Setup\n\n\nEvaluation Tasks and Datasets\n\nWe conduct experiments on two tasks: code completion and text-to-code generation. To investigate the compilability of the generated code, we need to preserve the indentation and newline operations in code. We also need to make sure that the code and its version belong to the scope of the compiler. Existing datasets on both of the two tasks usually do not serve these considerations. For convenience, we choose Python for experiments, as it is very popular and used in many projects. We conduct all experiments based on Python 3 environment and adopt the codeop 1 module to simulate the pro-gram compiler. We remove code that could not be compiled correctly by the compiler.\n\nCode Completion For the code completion task, we use the Python corpus in CodeSearchNet (Husain et al., 2019). We want to study the compilability of long enough code, while longer code means higher computational overhead. Therefore, we extract 50k compilable Python methods (Python 3 version) with eclectic token lengths ranging from 64 to 96. We randomly select 45k samples for training and the remaining 5k samples for testing. We mask a different number of tokens at the tail of the source code and let the model complete.\n\nText-to-Code Generation For the text-to-code generation task, we adopt the AdvTest dataset (Lu et al., 2021), which contains 251,820 text and Python code pairs. We only need code in Python 3 version. We expect code token lengths to range from 128 to 170, a moderate length, and text token lengths to be at least more than 5, containing sufficient semantics. Finally, we extract about 41k text-code pairs. We randomly select 40k text-code pairs for training, and the remaining 1k text-code pairs for testing.\n\n\nEvaluation Metrics\n\nTo evaluate the quality of the generated code, we adopt two widely-used evaluation metrics: Levenshtein Edit Similarity (ES) (Svyatkovskiy et al., 2020;Lu et al., 2021) and Compilation Rate (CR) (Kulal et al., 2019). Levenshtein Edit Similarity measures the number of single-character edits required to transform one string into another. It is a critical evaluation metric for the code generation scenario, as it measures the effort required for the developer to correct the code. Compilation Rate measures how many code can be correctly compiled by the program compiler. For both of these metrics, bigger values indicate better performance.\n\n\nBaseline Methods\n\nWe compare our approach with various state-ofthe-art models in the code completion task and the text-to-code generation task: \u2022 BiLSTM is a Seq2Seq model based on Bidirectional LSTM with an attention mechanism (Luong et al., 2015).\n\n\u2022 Transformer (Vaswani et al., 2017) is the base architecture of CodeGPT. We use 6-layer Transformer decoder to conduct experiments. \u2022 CodeT5 (Wang et al., 2021b) is based on the T5 (Raffel et al., 2020) architecture, which employs denoising sequence-to-sequence pretraining on multiple programming languages.\n\n\nImplementation Details\n\nIn the code completion task, we set the learning rate as 1.5e-5, the batch size as 32, the maximum fine-tuning epoch as 20, the maximum code sequence length as 96. We mask different numbers of code tokens (25, 30, 35, 40, and 45) and ask the model to complete them. We set the minimum generation length as 25, 30, 35, 40, and 45 accordingly. In the text-to-code generation task, we set the learning rate as 1.5e-5, the batch size as 16, the maximum fine-tuning epoch as 20, the maximum text and code sequence length as 32 and 170. We set the minimum generation length as 96 (the generated code is slightly shorter than the ground-truth is allowed). In these two tasks, the generated sequence consisting of whitespace characters will be considered as a bad case. We use the Adam optimizer to update model parameters. We train our model on the basis of CodeGPT checkpoint 2 . Our model is trained on 2 NVIDIA Tesla V100 with 32GB memory. We employ the same tokenizer as CodeGPT. To train the policy \u03c0, we use the PPO2 version of Proximal Policy Optimization (Schulman et al., 2017). In each epoch, we only randomly select 5% training data for the stability of RL training (Stage 2). In other stages (Stages 1 and 3 Table 1 shows the results of the code completion task. We mask 25 tokens at the tail of code functions and ask the generation model to complete. We can observe that: (1) The code generated by existing autoregressive models has a low Compilation Rate. CodeGPT and GPT-2 only achieve 46.84 and 43.26 scores respectively on the Compilation Rate, which means that more than half of the code generated by them cannot be correctly compiled by the program compiler.\n\n\nResults and Analysis\n\n\nCode Completion\n\n(2) COMPCODER significantly improves the Compilation Rate. It obtains 94.48 scores on the Compilation Rate, which is 47.64 points higher than the closest competitor (CodeGPT).\n\n(3) When our approach significantly improves the Compilation Rate, it does not sacrifice the fluency of the generated code. COMPCODER obtains a comparable and even slightly better Edit Similarity score than other baselines, indicating that it effectively preserves the code fluency. Figure 4 presents more results of the code completion task in the setting of completing 30, 35, 40, and 45 tokens. COMPCODER still effectively improves the Compilation Rate when generating longer code. As the completion length increases, our approach outperforms CodeGPT by 49. 66, 47.68, 46.64, and 33.36 Table 2: Results in the text-to-code generation task evaluating with Edit Similarity (ES) and Compilation Rate (CR), using the AdvTest dataset. Table 2 presents the results of the text-to-code generation task. We could see that:\n\n\nText-to-Code Generation\n\n(1) COMPCODER significantly outperforms all other models w.r.t. the Compilation Rate. E.g., COMPCODER achieves 23.1 points and 24.3 points improvements when compared with PLBART and CodeT5 respectively.\n\n(2) Compared to code completion task (Table 1), all models in the text-to-code generation task have relatively higher Compilation Rate. One of the main reasons we think may be: code completion requires the generated code to be constrained by the existing (previous) code, which is a much stronger restriction than the text-to-code generation.\n\n\nAblation Study\n\nWe compare several simplified versions of our model to understand contributions of different components, including the Reinforcement Learning  Table 3: Ablation study in the code completion task in the setting of completing 25 code tokens.\n\nboth model training (D train ) and model inference (D test ). As a case study, we take the code completion task as an example in the setting of completing 25 tokens and present the results in Table 3.\n\nSeveral meaningful observations can be drawn: First, both RL (Row 2) and D train (Row 3) effectively increase the code Compilation Rate of the generation model (CodeGPT in Row 1), which confirms that the two components we designed can indeed improve the ability of the generator for compilable code generation. Second, applying RL and D train together (Row 4) further improves the Compilation Rate over their individual contributions. Third, using the discriminator to select the output during model inference stage (D test ) is beneficial. It further boosts the Compilation Rate of vanilla \"D train \" by 17.08% (Row 5 v.s. Row 2) and boosts \"RL+D train \" by 11.34% (Row 6 v.s. Row 4). Forth, these three components (RL, D train , D test ) that effectively improve the Compilation Rate do not compromise the generation capability measured by the Edit Similarity.\n\n\nCase Study\n\nTo better understand the effectiveness of our proposed approach, we present two cases for code completion and text-to-code generation tasks respectively. For both CodeGPT and COMPCODER, we present top-1 result in Figure 5. For code completion, we observe that CodeGPT can not complete code with high quality (non-compilable), while COMPCODER can complete the code well, and it is exactly the same for the reference solution. For text-to-code generation, we observe that although both models can not generate exactly the same code as the reference solution, COMPCODER generates a compilable code at the function level. These results reveal the effectiveness of our proposed approach for compilable code generation.\n\n1 d e f e x t r a c t _ a r g u m e n t s (a r g u m e n t s , l o n g _ k e y s , k e y _ p r e f i x ='--'): 2 l o n g _ a r g u m e n t s = e x t r a c t (a r g u m e n t s , l o n g _ k e y s ) 3 r e t u r n d i c t ( 4 [ ( k e y .r e p l a c e (k e y _ p r e f i x , ' ' ) , v a l u e ) f o r k e y , v a l u e i n l o n g _ a r g u m e n t s .i t e m s ( ) ] 5 )  \n\n\nReference Code\n\n\nRelated Work\n\nNeural Code Generation With the rapid development of Deep Learning (DL), some researchers attempt to use DL for code generation tasks. Liu et al. (2020a) proposed a neural architecture for code completion task with multi-task learning based on the architecture of Transformer-XL Dai et al. (2019) and BiLSTM (Schuster and Paliwal, 1997). Kim et al. (2021) presented several ways of feeding the code structure to Transformer (Vaswani et al., 2017) and further improved the accuracy of the code prediction (next token prediction) task.  adopted an encoder-decoder architecture and utilized the relations between code generation and code summarization to improve the performance of both tasks. Yasunaga and Liang (2021) proposed a new training approach for program repair. They used the critic to check a fixer's output on real bad inputs and add good outputs to the training data, and trains a breaker to generate realistic bad code from good code. Yasunaga and Liang (2020) used compiler error messages to repair programs. They designed a program-feedback graph and then applied a graph neural network on top to model the reasoning process. Many unlabeled programs are used for program repair with self-supervised learning.\n\nBenefiting from the strong power of pre-training techniques (Devlin et al., 2019;Wang et al., 2021a) in natural language processing, such as GPT (Radford and Narasimhan, 2018), BART (Lewis et al., 2020), and T5 (Raffel et al., 2020), some recent works attempt to pre-train language models on the corpus of source code for code generation. Lu et al. (2021) proposed CodeGPT follows the architecture of GPT-2 , which is pretrained with a causal language modeling (CLM) objective on large-scale source code.  proposed PLBART follows the architecture of BART (Lewis et al., 2020), which is pre-trained on Java and Python functions paired with code comments via denoising autoencoding. Wang et al. (2021b) proposed CodeT5 based on the T5 (Raffel et al., 2020) architecture, which employs denoising sequence-to-sequence pre-training on multiple programming languages.\n\nReinforced Text Generation Reinforcement learning (Sutton and Barto, 1998) has shown great success in various tasks. It focuses on how agents ought to take actions in an environment to maximize the cumulative reward, is well suited for decision-making tasks. Ranzato et al. (2016) were among the first to apply REINFORCE algorithm (Williams, 1992) to train recurrent neural networks on sequence generation tasks, suggesting that directly optimizing the metric used at the test phase can lead to better results. Chen and Bansal (2018) proposed a hybrid extractive-abstractive architecture with policy-based reinforcement learning. They used an extractor agent to select salient sentences and then employed an abstractor network to rewrite these extracted sentences. Wan et al. (2018); Wang et al. (2022) incorporated the tree structure and sequential content of code snippets and designed a deep reinforcement learning framework optimized by the metric of BLEU to improve the performance of the code summarization task. Yao et al. (2019) proposed a reinforcement learning framework, which encourages the code annotation model to generate annotations that can be used for code retrieval tasks. Korbak et al. (2021) proposed an energy-based model with an imposed constraint of generating only compilable sequences to improve compilation rates of generated code.\n\n\nConclusion and Future Work\n\nIn this paper, we use the compilability signals in two ways and design a novel method to jointly train the generator and discriminator for compilable code generation, called COMPCODER. Comprehensive experiments on two code generation tasks demonstrate the effectiveness of COMPCODER, improving the average compilation rate of state-ofthe-art CodeGPT from 44.18 to 89.18 in the code completion task and from 70.3 to 96.2 in the textto-code generation task.\n\nThis work presents our preliminary attempt to generate compilable code. Yet, considering the compilation rate is not the whole story as it still cannot guarantee the correctness of generated code. As a future work, we would like to utilize unit tests to evaluate the code correctness towards building more useful code generation models.\n\n\u22c6Figure 1 :\n1Equal contribution. \u22c4 Work done while this author was an intern at Huawei Noah's Ark Lab.Correspondence author. An illustration of Python code completion by COMPCODER, utilizing the compiler feedback with three stages.\n\nFigure 4 :\n4: Results in the code completion task(completing 30, 35, 40, 45  tokens respectively) evaluating with Edit Similarity (ES) and Compilation Rate (CR) metrics, using the CodeSearchNet-Python dataset.\u2022 GPT-2 is an autoregressive pre-trained model trained on largescale text corpus.\u2022 CodeGPT(Lu et al., 2021) is pre-trained with source code corpus on the basis of GPT-2 vis causal language modeling objective.\u2022 PLBART (Ahmad et al., 2021) is based on the BART(Lewis et al., 2020) architecture, which is pre-trained on large-scale Java and Python corpora via denoising autoencoding.\n\nFigure 5 :\n5Case study for code completion and text-tocode generation tasks.\n\n\n), we use the full training data. To generate candidates (at Stage 3), we set the beam size as 5 in beam search. For efficiency, we update the candidates every 5 epochs.Models \nES \nCR \n\nBiLSTM \n55.32 \n36.34 \nTransformer \n61.47 \n40.22 \nGPT-2 \n63.02 \n43.26 \nCodeGPT \n64.47 \n46.84 \nCOMPCODER \n64.53 \n94.48 \n\nTable 1: Results in the code completion task (com-\npleting 25 tokens) evaluating with Edit Similarity \n(ES) and Compilation Rate (CR) metrics, using the \nCodeSearchNet-Python dataset. \n\n\n\n\nCodeGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1 def extract_arguments(arguments, long_keys, key_prefix='--'): \n2 \nlong_arguments = extract(arguments, long_keys) \n3 \nreturn dict( \n4 \n[ ( key.replace(key_prefix, ' ' ), value) \n5 \n\n1 d e f extract_arguments(arguments, long_keys, key_prefix='--'): \n2 \nlong_arguments = extract(arguments, long_keys) \n3 \nreturn d i c t ( \n4 \n[ ( k e y .replace(key_prefix, ' ' ) , value) f o r k e y , value i n long_arguments.items( ) ] \n5 \n) \n\nCOMPCODER \n\n. . . . \n. . . . \n. . . . . . . . \n. . . . \n\nEncode a Password \n:param password: Password \n:param algorithm \n:param salt: Salt \n:param iterations: iterations \n:return: PBKDF2 hashed Password \n\nNatural Language Comment \n\n1 d e f encode(password, algorithm, s a l t , iterations): \n2 \nhash = hashlib.pbkdf2_hmac(digest( ) . n a m e , password.encode( ) , s a l t .encode( ) , iterations) \n3 \nencoded = base64.b64encode(h a s h ) . decode('ascii') . strip( ) \n4 \nreturn \"%s$%d$%s$%s\" % (algorithm, iterations, s a l t , encoded) \n\nReference Code \n\n1 def _encode_password(password, algorithm): \n2 \nsalt = salt.encode('utf-8 ' ) \n3 \niterations = int(iterations) \n4 \npbkdf2 = PBKDF2(algorithm, salt, \n\nCodeGPT \n\n1 def encode_password(password, algorithm, salt, iterations): \n2 \nhasher = PBKDF2HMAC( \n3 \nalgorithm=algorithm, \n4 \nsalt=salt, \n5 \niterations=iterations) \n6 \nhasher.update(password) \n7 \nreturn hasher.finalize( ) \n\nCOMPCODER \n\nCode Completion \n\nText-to-Code Generation \n\n. . . . \n. . . . \n. . . . \n\n. . . . \n. . . . \n. . . . \n\n. . . . \n. . . . . . . . \n\n\u2714 \n\n\u2716 \n\n\u2714 \n\n\u2716 \n\n\nhttps://docs.python.org/3.6/library/ codeop.html\nhttps://huggingface.co/microsoft/ CodeGPT-small-py-adaptedGPT2\nAcknowledgements\nUnified pre-training for program understanding and generation. Saikat Wasi Uddin Ahmad, Baishakhi Chakraborty, Kai-Wei Ray, Chang, 10.18653/v1/2021.naacl-main.211Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021Association for Computational LinguisticsWasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Unified pre-training for program understanding and generation. In Proceed- ings of the 2021 Conference of the North American Chapter of the Association for Computational Lin- guistics: Human Language Technologies, NAACL- HLT 2021, Online, June 6-11, 2021, pages 2655- 2668. Association for Computational Linguistics.\n\nTreeto-tree neural networks for program translation. Xinyun Chen, Chang Liu, Dawn Song, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems. NeurIPS; Montr\u00e9al, CanadaXinyun Chen, Chang Liu, and Dawn Song. 2018. Tree- to-tree neural networks for program translation. In Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Pro- cessing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr\u00e9al, Canada, pages 2552-2562.\n\nFast abstractive summarization with reinforce-selected sentence rewriting. Yen-Chun Chen, Mohit Bansal, 10.18653/v1/P18-1063Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018. the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018Melbourne, AustraliaAssociation for Computational Linguistics1Yen-Chun Chen and Mohit Bansal. 2018. Fast abstrac- tive summarization with reinforce-selected sentence rewriting. In Proceedings of the 56th Annual Meet- ing of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers, pages 675-686. Association for Computational Linguistics.\n\nSequencer: Sequence-to-sequence learning for end-to-end program repair. Zimin Chen, Steve Kommrusch, Michele Tufano, 10.1109/TSE.2019.2940179IEEE Trans. Software Eng. 479Louis-No\u00ebl Pouchet, Denys Poshyvanyk, and Martin MonperrusZimin Chen, Steve Kommrusch, Michele Tufano, Louis- No\u00ebl Pouchet, Denys Poshyvanyk, and Martin Mon- perrus. 2021. Sequencer: Sequence-to-sequence learning for end-to-end program repair. IEEE Trans. Software Eng., 47(9):1943-1959.\n\nTransformer-xl: Attentive language models beyond a fixed-length context. Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G Carbonell, Quoc Viet Le, Ruslan Salakhutdinov, 10.18653/v1/p19-1285Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019. the 57th Conference of the Association for Computational Linguistics, ACL 2019Florence, ItalyLong Papers1Association for Computational LinguisticsZihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Car- bonell, Quoc Viet Le, and Ruslan Salakhutdinov. 2019. Transformer-xl: Attentive language models beyond a fixed-length context. In Proceedings of the 57th Conference of the Association for Compu- tational Linguistics, ACL 2019, Florence, Italy, July 28-August 2, 2019, Volume 1: Long Papers, pages 2978-2988. Association for Computational Linguis- tics.\n\nBERT: pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/n19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational Linguistics1Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: pre-training of deep bidirectional transformers for language under- standing. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171-4186. Association for Computational Linguistics.\n\nA retrieve-and-edit framework for predicting structured outputs. B Tatsunori, Kelvin Hashimoto, Yonatan Guu, Percy Oren, Liang, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems. NeurIPS; Montr\u00e9al, CanadaTatsunori B. Hashimoto, Kelvin Guu, Yonatan Oren, and Percy Liang. 2018. A retrieve-and-edit frame- work for predicting structured outputs. In Advances in Neural Information Processing Systems 31: An- nual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr\u00e9al, Canada, pages 10073-10083.\n\nCodesearchnet challenge: Evaluating the state of semantic code search. Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, Marc Brockschmidt, abs/1909.09436CoRRHamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc Brockschmidt. 2019. Code- searchnet challenge: Evaluating the state of semantic code search. CoRR, abs/1909.09436.\n\nCode prediction by feeding trees to transformers. Seohyun Kim, Jinman Zhao, Yuchi Tian, Satish Chandra, 10.1109/ICSE43902.2021.0002643rd IEEE/ACM International Conference on Software Engineering, ICSE 2021. Madrid, SpainIEEESeohyun Kim, Jinman Zhao, Yuchi Tian, and Satish Chandra. 2021. Code prediction by feeding trees to transformers. In 43rd IEEE/ACM International Conference on Software Engineering, ICSE 2021, Madrid, Spain, 22-30 May 2021, pages 150-162. IEEE.\n\nEnergy-based models for code generation under compilability constraints. Tomasz Korbak, Hady Elsahar, Marc Dymetman, Germ\u00e1n Kruszewski, arXiv:2106.04985arXiv preprintTomasz Korbak, Hady ElSahar, Marc Dymetman, and Germ\u00e1n Kruszewski. 2021. Energy-based models for code generation under compilability constraints. arXiv preprint arXiv: 2106.04985.\n\nSpoc: Search-based pseudocode to code. Sumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex Aiken, Percy Liang, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. NeurIPS; Vancouver, BC, CanadaSumith Kulal, Panupong Pasupat, Kartik Chandra, Mina Lee, Oded Padon, Alex Aiken, and Percy Liang. 2019. Spoc: Search-based pseudocode to code. In Ad- vances in Neural Information Processing Systems 32: Annual Conference on Neural Information Process- ing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pages 11883-11894.\n\nBART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, 10.18653/v1/2020.acl-main.703Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnlineAssociation for Computational Linguistics2020Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and com- prehension. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 7871-7880. Association for Computational Linguistics.\n\nCode completion with neural attention and pointer networks. Jian Li, Yue Wang, Michael R Lyu, Irwin King, 10.24963/ijcai.2018/578Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018. the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018Stockholm, Swedenijcai.orgJian Li, Yue Wang, Michael R. Lyu, and Irwin King. 2018. Code completion with neural attention and pointer networks. In Proceedings of the Twenty- Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, July 13-19, 2018, Stock- holm, Sweden, pages 4159-4165. ijcai.org.\n\nA self-attentional neural architecture for code completion with multi-task learning. Fang Liu, Ge Li, Bolin Wei, Xin Xia, Zhiyi Fu, Zhi Jin, 10.1145/3387904.3389261ICPC '20: 28th International Conference on Program Comprehension. Seoul, Republic of KoreaACMFang Liu, Ge Li, Bolin Wei, Xin Xia, Zhiyi Fu, and Zhi Jin. 2020a. A self-attentional neural architecture for code completion with multi-task learning. In ICPC '20: 28th International Conference on Program Com- prehension, Seoul, Republic of Korea, July 13-15, 2020, pages 37-47. ACM.\n\nMulti-task learning based pre-trained language model for code completion. Fang Liu, Ge Li, Yunfei Zhao, Zhi Jin, 10.1145/3324884.341659135th IEEE/ACM International Conference on Automated Software Engineering, ASE 2020. Melbourne, AustraliaIEEEFang Liu, Ge Li, Yunfei Zhao, and Zhi Jin. 2020b. Multi-task learning based pre-trained language model for code completion. In 35th IEEE/ACM Interna- tional Conference on Automated Software Engineer- ing, ASE 2020, Melbourne, Australia, September 21- 25, 2020, pages 473-485. IEEE.\n\nCodexglue: A machine learning benchmark dataset for code understanding and generation. Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin B Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan Duan, Neel Sundaresan, Shengyu Shao Kun Deng, Shujie Fu, Liu, abs/2102.04664CoRRShuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin B. Clement, Dawn Drain, Daxin Jiang, Duyu Tang, Ge Li, Li- dong Zhou, Linjun Shou, Long Zhou, Michele Tu- fano, Ming Gong, Ming Zhou, Nan Duan, Neel Sun- daresan, Shao Kun Deng, Shengyu Fu, and Shujie Liu. 2021. Codexglue: A machine learning bench- mark dataset for code understanding and generation. CoRR, abs/2102.04664.\n\nEffective approaches to attention-based neural machine translation. Thang Luong, Hieu Pham, Christopher D Manning, 10.18653/v1/d15-1166Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalThe Association for Computational LinguisticsThang Luong, Hieu Pham, and Christopher D. Manning. 2015. Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 Con- ference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, Septem- ber 17-21, 2015, pages 1412-1421. The Association for Computational Linguistics.\n\nLearning to infer program sketches. Maxwell I Nye, Luke B Hewitt, Joshua B Tenenbaum, Armando Solar-Lezama, PMLRProceedings of the 36th International Conference on Machine Learning, ICML 2019. the 36th International Conference on Machine Learning, ICML 2019Long Beach, California, USA97Maxwell I. Nye, Luke B. Hewitt, Joshua B. Tenenbaum, and Armando Solar-Lezama. 2019. Learning to infer program sketches. In Proceedings of the 36th Inter- national Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Re- search, pages 4861-4870. PMLR.\n\nRetrieval augmented code generation and summarization. Md. Rizwan, Parvez, Saikat Wasi Uddin Ahmad, Baishakhi Chakraborty, Kai-Wei Ray, Chang, 10.18653/v1/2021.findings-emnlp.232Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana. Dominican RepublicAssociation for Computational LinguisticsMd. Rizwan Parvez, Wasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. 2021. Retrieval augmented code generation and sum- marization. In Findings of the Association for Com- putational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November, 2021, pages 2719-2734. Association for Computa- tional Linguistics.\n\nAbstract syntax networks for code generation and semantic parsing. Maxim Rabinovich, Mitchell Stern, Dan Klein, 10.18653/v1/P17-1105Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics1Maxim Rabinovich, Mitchell Stern, and Dan Klein. 2017. Abstract syntax networks for code generation and semantic parsing. In Proceedings of the 55th An- nual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers, pages 1139-1149. Association for Computational Linguistics.\n\nImproving language understanding by generative pretraining. Alec Radford, Karthik Narasimhan, Alec Radford and Karthik Narasimhan. 2018. Im- proving language understanding by generative pre- training.\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language models are unsupervised multitask learners.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, J. Mach. Learn. Res. 2167Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text trans- former. J. Mach. Learn. Res., 21:140:1-140:67.\n\nSequence level training with recurrent neural networks. Aurelio Marc, Sumit Ranzato, Michael Chopra, Wojciech Auli, Zaremba, 4th International Conference on Learning Representations. San Juan, Puerto RicoConference Track ProceedingsMarc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2016. Sequence level train- ing with recurrent neural networks. In 4th Inter- national Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings.\n\nJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov, arXiv:1707.06347Proximal policy optimization algorithms. arXiv preprintJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017. Proximal pol- icy optimization algorithms. arXiv preprint arXiv: 1707.06347.\n\nBidirectional recurrent neural networks. Mike Schuster, Kuldip K Paliwal, 10.1109/78.650093IEEE Trans. Signal Process. 4511Mike Schuster and Kuldip K. Paliwal. 1997. Bidirec- tional recurrent neural networks. IEEE Trans. Signal Process., 45(11):2673-2681.\n\nIntroduction to reinforcement learning. Richard S Sutton, Andrew G Barto, Richard S. Sutton and Andrew G. Barto. 1998. Intro- duction to reinforcement learning.\n\nIntellicode compose: code generation using transformer. Alexey Svyatkovskiy, Shengyu Shao Kun Deng, Neel Fu, Sundaresan, 10.1145/3368089.3417058ESEC/FSE '20: 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Virtual Event. USAACMAlexey Svyatkovskiy, Shao Kun Deng, Shengyu Fu, and Neel Sundaresan. 2020. Intellicode compose: code generation using transformer. In ESEC/FSE '20: 28th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, Virtual Event, USA, November 8-13, 2020, pages 1433-1443. ACM.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems. Long Beach, CA, USAAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Pro- cessing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 5998-6008.\n\nImproving automatic source code summarization via deep reinforcement learning. Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, Philip S Yu, 10.1145/3238147.3238206Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. the 33rd ACM/IEEE International Conference on Automated Software EngineeringMontpellier, FranceACMYao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S. Yu. 2018. Im- proving automatic source code summarization via deep reinforcement learning. In Proceedings of the 33rd ACM/IEEE International Conference on Auto- mated Software Engineering, ASE 2018, Montpellier, France, September 3-7, 2018, pages 397-407. ACM.\n\nReinforcement-learning-guided source code summarization using hierarchical attention. Wenhua Wang, Yuqun Zhang, Yulei Sui, Yao Wan, Zhou Zhao, Jian Wu, Philip S Yu, Guandong Xu, IEEE Transactions on Software Engineering. 481Wenhua Wang, Yuqun Zhang, Yulei Sui, Yao Wan, Zhou Zhao, Jian Wu, Philip S. Yu, and Guandong Xu. 2022. Reinforcement-learning-guided source code summa- rization using hierarchical attention. IEEE Transac- tions on Software Engineering, 48(1):102-119.\n\nSyncobert: Syntax-guided multi-modal contrastive pre-training for code representation. Xin Wang, Yasheng Wang, Fei Mi, Pingyi Zhou, Yao Wan, Xiao Liu, Li Li, Hao Wu, Jin Liu, Xin Jiang, arXiv:2108.04556arXiv preprintXin Wang, Yasheng Wang, Fei Mi, Pingyi Zhou, Yao Wan, Xiao Liu, Li Li, Hao Wu, Jin Liu, and Xin Jiang. 2021. Syncobert: Syntax-guided multi-modal con- trastive pre-training for code representation. arXiv preprint arXiv: 2108.04556.\n\nServicebert: A pre-trained model for web service tagging and recommendation. Xin Wang, Pingyi Zhou, Yasheng Wang, Xiao Liu, Jin Liu, Hao Wu, 10.1007/978-3-030-91431-8_29Service-Oriented Computing -19th International Conference, ICSOC 2021, Virtual Event. Springer13121ProceedingsXin Wang, Pingyi Zhou, Yasheng Wang, Xiao Liu, Jin Liu, and Hao Wu. 2021a. Servicebert: A pre-trained model for web service tagging and recommendation. In Service-Oriented Computing -19th International Conference, ICSOC 2021, Virtual Event, November 22-25, 2021, Proceedings, volume 13121 of Lecture Notes in Computer Science, pages 464-478. Springer.\n\nCodet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. Yue Wang, Weishi Wang, R Shafiq, Steven C H Joty, Hoi, 10.18653/v1/2021.emnlp-main.685Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic2021Virtual Event / Punta Cana. Association for Computational LinguisticsYue Wang, Weishi Wang, Shafiq R. Joty, and Steven C. H. Hoi. 2021b. Codet5: Identifier-aware uni- fied pre-trained encoder-decoder models for code understanding and generation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pages 8696-8708. Association for Computa- tional Linguistics.\n\nCode generation as a dual task of code summarization. Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, Zhi Jin, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. NeurIPS; Vancouver, BC, CanadaBolin Wei, Ge Li, Xin Xia, Zhiyi Fu, and Zhi Jin. 2019. Code generation as a dual task of code summariza- tion. In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Informa- tion Processing Systems 2019, NeurIPS 2019, De- cember 8-14, 2019, Vancouver, BC, Canada, pages 6559-6569.\n\nSimple statistical gradientfollowing algorithms for connectionist reinforcement learning. Ronald J Williams, 10.1007/BF00992696Mach. Learn. 8Ronald J. Williams. 1992. Simple statistical gradient- following algorithms for connectionist reinforcement learning. Mach. Learn., 8:229-256.\n\nCoacor: Code annotation for code retrieval with reinforcement learning. Ziyu Yao, Jayavardhan Reddy Peddamail, Huan Sun, 10.1145/3308558.3313632The World Wide Web Conference. San Francisco, CA, USAACMZiyu Yao, Jayavardhan Reddy Peddamail, and Huan Sun. 2019. Coacor: Code annotation for code re- trieval with reinforcement learning. In The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019, pages 2203-2214. ACM.\n\nGraphbased, self-supervised program repair from diagnostic feedback. Michihiro Yasunaga, Percy Liang, PMLRProceedings of the 37th International Conference on Machine Learning, ICML 2020. the 37th International Conference on Machine Learning, ICML 2020119Virtual EventMichihiro Yasunaga and Percy Liang. 2020. Graph- based, self-supervised program repair from diag- nostic feedback. In Proceedings of the 37th Inter- national Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 10799-10808. PMLR.\n\nBreakit-fix-it: Unsupervised learning for program repair. Michihiro Yasunaga, Percy Liang, PMLRProceedings of the 38th International Conference on Machine Learning, ICML 2021. the 38th International Conference on Machine Learning, ICML 2021139Virtual EventMichihiro Yasunaga and Percy Liang. 2021. Break- it-fix-it: Unsupervised learning for program repair. In Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 11941-11952. PMLR.\n\nA syntactic neural model for general-purpose code generation. Pengcheng Yin, Graham Neubig, 10.18653/v1/P17-1041Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaLong Papers1Association for Computational LinguisticsPengcheng Yin and Graham Neubig. 2017. A syntactic neural model for general-purpose code generation. In Proceedings of the 55th Annual Meeting of the As- sociation for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 -August 4, Volume 1: Long Papers, pages 440-450. Association for Com- putational Linguistics.\n\nFine-tuning language models from human preferences. M Daniel, Nisan Ziegler, Jeffrey Stiennon, Tom B Wu, Alec Brown, Dario Radford, Paul F Amodei, Geoffrey Christiano, Irving, abs/1909.08593CoRRDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul F. Chris- tiano, and Geoffrey Irving. 2019. Fine-tuning lan- guage models from human preferences. CoRR, abs/1909.08593.\n", "annotations": {"author": "[{\"end\":237,\"start\":177},{\"end\":277,\"start\":238},{\"end\":389,\"start\":278},{\"end\":421,\"start\":390},{\"end\":487,\"start\":422},{\"end\":524,\"start\":488},{\"end\":602,\"start\":525},{\"end\":709,\"start\":603},{\"end\":744,\"start\":710},{\"end\":796,\"start\":745}]", "publisher": "[{\"end\":99,\"start\":58},{\"end\":948,\"start\":907}]", "author_last_name": "[{\"end\":185,\"start\":181},{\"end\":252,\"start\":250},{\"end\":285,\"start\":282},{\"end\":396,\"start\":394},{\"end\":431,\"start\":429},{\"end\":499,\"start\":495},{\"end\":532,\"start\":529},{\"end\":609,\"start\":607},{\"end\":719,\"start\":714},{\"end\":752,\"start\":749}]", "author_first_name": "[{\"end\":180,\"start\":177},{\"end\":249,\"start\":245},{\"end\":281,\"start\":278},{\"end\":393,\"start\":390},{\"end\":428,\"start\":422},{\"end\":494,\"start\":488},{\"end\":528,\"start\":525},{\"end\":606,\"start\":603},{\"end\":713,\"start\":710},{\"end\":748,\"start\":745}]", "author_affiliation": "[{\"end\":236,\"start\":187},{\"end\":276,\"start\":254},{\"end\":388,\"start\":306},{\"end\":420,\"start\":398},{\"end\":455,\"start\":433},{\"end\":486,\"start\":457},{\"end\":523,\"start\":501},{\"end\":601,\"start\":552},{\"end\":708,\"start\":639},{\"end\":743,\"start\":721},{\"end\":795,\"start\":773}]", "title": "[{\"end\":57,\"start\":1},{\"end\":853,\"start\":797}]", "venue": "[{\"end\":906,\"start\":855}]", "abstract": "[{\"end\":2061,\"start\":975}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2196,\"start\":2179},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2335,\"start\":2314},{\"end\":2481,\"start\":2460},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2531,\"start\":2507},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2600,\"start\":2574},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2701,\"start\":2684},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2799,\"start\":2781},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2820,\"start\":2799},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2844,\"start\":2820},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2871,\"start\":2853},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2908,\"start\":2882},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2991,\"start\":2970},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3010,\"start\":2991},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3193,\"start\":3176},{\"end\":3222,\"start\":3195},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3255,\"start\":3235},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3486,\"start\":3468},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4012,\"start\":3992},{\"end\":4030,\"start\":4012},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4062,\"start\":4042},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9831,\"start\":9807},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9848,\"start\":9831},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10243,\"start\":10220},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16699,\"start\":16678},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17225,\"start\":17208},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":17799,\"start\":17772},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17815,\"start\":17799},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17862,\"start\":17842},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18539,\"start\":18519},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":18578,\"start\":18556},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":18704,\"start\":18684},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":18745,\"start\":18724},{\"end\":19106,\"start\":19083},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":19957,\"start\":19934},{\"end\":21357,\"start\":21330},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":24771,\"start\":24753},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24914,\"start\":24897},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24954,\"start\":24926},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24973,\"start\":24956},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":25064,\"start\":25042},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":25334,\"start\":25309},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":25590,\"start\":25565},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":25923,\"start\":25902},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25942,\"start\":25923},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":26044,\"start\":26024},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26074,\"start\":26053},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26197,\"start\":26181},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":26417,\"start\":26397},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26542,\"start\":26523},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26596,\"start\":26575},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":26779,\"start\":26755},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":26985,\"start\":26964},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":27052,\"start\":27036},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":27238,\"start\":27216},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":27487,\"start\":27470},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":27507,\"start\":27489},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":27741,\"start\":27724},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":27917,\"start\":27897},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":29438,\"start\":29421},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":29609,\"start\":29589}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":29120,\"start\":28888},{\"attributes\":{\"id\":\"fig_1\"},\"end\":29711,\"start\":29121},{\"attributes\":{\"id\":\"fig_2\"},\"end\":29789,\"start\":29712},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":30283,\"start\":29790},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":31963,\"start\":30284}]", "paragraph": "[{\"end\":3256,\"start\":2077},{\"end\":5061,\"start\":3258},{\"end\":5123,\"start\":5063},{\"end\":5448,\"start\":5125},{\"end\":5707,\"start\":5450},{\"end\":6287,\"start\":5723},{\"end\":6774,\"start\":6289},{\"end\":7161,\"start\":6776},{\"end\":7414,\"start\":7163},{\"end\":8547,\"start\":7446},{\"end\":8685,\"start\":8561},{\"end\":8975,\"start\":8725},{\"end\":9641,\"start\":9021},{\"end\":10289,\"start\":9682},{\"end\":11428,\"start\":10330},{\"end\":11730,\"start\":11430},{\"end\":11915,\"start\":11776},{\"end\":12795,\"start\":11917},{\"end\":13321,\"start\":12837},{\"end\":13538,\"start\":13323},{\"end\":13779,\"start\":13647},{\"end\":14003,\"start\":13860},{\"end\":14288,\"start\":14005},{\"end\":15521,\"start\":14327},{\"end\":15860,\"start\":15523},{\"end\":16588,\"start\":15913},{\"end\":17115,\"start\":16590},{\"end\":17624,\"start\":17117},{\"end\":18288,\"start\":17647},{\"end\":18540,\"start\":18309},{\"end\":18851,\"start\":18542},{\"end\":20549,\"start\":18878},{\"end\":20767,\"start\":20592},{\"end\":21586,\"start\":20769},{\"end\":21816,\"start\":21614},{\"end\":22160,\"start\":21818},{\"end\":22418,\"start\":22179},{\"end\":22620,\"start\":22420},{\"end\":23484,\"start\":22622},{\"end\":24212,\"start\":23499},{\"end\":24584,\"start\":24214},{\"end\":25840,\"start\":24618},{\"end\":26703,\"start\":25842},{\"end\":28063,\"start\":26705},{\"end\":28549,\"start\":28094},{\"end\":28887,\"start\":28551}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7445,\"start\":7415},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9020,\"start\":8976},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10329,\"start\":10290},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11775,\"start\":11731},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13567,\"start\":13539},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13646,\"start\":13567},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13859,\"start\":13780},{\"attributes\":{\"id\":\"formula_7\"},\"end\":14307,\"start\":14289}]", "table_ref": "[{\"end\":20098,\"start\":20091},{\"end\":21365,\"start\":21358},{\"end\":21509,\"start\":21502},{\"end\":21864,\"start\":21855},{\"end\":22329,\"start\":22322},{\"end\":22619,\"start\":22612}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2075,\"start\":2063},{\"attributes\":{\"n\":\"2\"},\"end\":5721,\"start\":5710},{\"attributes\":{\"n\":\"3\"},\"end\":8559,\"start\":8550},{\"attributes\":{\"n\":\"3.1\"},\"end\":8723,\"start\":8688},{\"attributes\":{\"n\":\"3.2\"},\"end\":9680,\"start\":9644},{\"attributes\":{\"n\":\"3.3\"},\"end\":12835,\"start\":12798},{\"attributes\":{\"n\":\"3.4\"},\"end\":14325,\"start\":14309},{\"attributes\":{\"n\":\"4\"},\"end\":15879,\"start\":15863},{\"attributes\":{\"n\":\"4.1\"},\"end\":15911,\"start\":15882},{\"attributes\":{\"n\":\"4.2\"},\"end\":17645,\"start\":17627},{\"attributes\":{\"n\":\"4.3\"},\"end\":18307,\"start\":18291},{\"attributes\":{\"n\":\"4.4\"},\"end\":18876,\"start\":18854},{\"attributes\":{\"n\":\"5\"},\"end\":20572,\"start\":20552},{\"attributes\":{\"n\":\"5.1\"},\"end\":20590,\"start\":20575},{\"attributes\":{\"n\":\"5.2\"},\"end\":21612,\"start\":21589},{\"attributes\":{\"n\":\"5.3\"},\"end\":22177,\"start\":22163},{\"attributes\":{\"n\":\"5.4\"},\"end\":23497,\"start\":23487},{\"end\":24601,\"start\":24587},{\"attributes\":{\"n\":\"6\"},\"end\":24616,\"start\":24604},{\"attributes\":{\"n\":\"7\"},\"end\":28092,\"start\":28066},{\"end\":28900,\"start\":28889},{\"end\":29132,\"start\":29122},{\"end\":29723,\"start\":29713}]", "table": "[{\"end\":30283,\"start\":29961},{\"end\":31963,\"start\":30447}]", "figure_caption": "[{\"end\":29120,\"start\":28902},{\"end\":29711,\"start\":29134},{\"end\":29789,\"start\":29725},{\"end\":29961,\"start\":29792},{\"end\":30447,\"start\":30286}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4642,\"start\":4634},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4761,\"start\":4753},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4833,\"start\":4825},{\"end\":7864,\"start\":7856},{\"end\":8118,\"start\":8110},{\"end\":8745,\"start\":8737},{\"end\":9870,\"start\":9862},{\"end\":11219,\"start\":11211},{\"end\":12296,\"start\":12288},{\"end\":13015,\"start\":13007},{\"end\":14237,\"start\":14229},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20090,\"start\":20075},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":21060,\"start\":21052},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":23720,\"start\":23712}]", "bib_author_first_name": "[{\"end\":32162,\"start\":32156},{\"end\":32190,\"start\":32181},{\"end\":32211,\"start\":32204},{\"end\":33054,\"start\":33048},{\"end\":33066,\"start\":33061},{\"end\":33076,\"start\":33072},{\"end\":33599,\"start\":33591},{\"end\":33611,\"start\":33606},{\"end\":34301,\"start\":34296},{\"end\":34313,\"start\":34308},{\"end\":34332,\"start\":34325},{\"end\":34762,\"start\":34756},{\"end\":34774,\"start\":34768},{\"end\":34787,\"start\":34781},{\"end\":34799,\"start\":34794},{\"end\":34801,\"start\":34800},{\"end\":34817,\"start\":34813},{\"end\":34833,\"start\":34827},{\"end\":35603,\"start\":35598},{\"end\":35620,\"start\":35612},{\"end\":35634,\"start\":35628},{\"end\":35648,\"start\":35640},{\"end\":36565,\"start\":36564},{\"end\":36583,\"start\":36577},{\"end\":36602,\"start\":36595},{\"end\":36613,\"start\":36608},{\"end\":37178,\"start\":37173},{\"end\":37196,\"start\":37187},{\"end\":37208,\"start\":37201},{\"end\":37225,\"start\":37216},{\"end\":37241,\"start\":37237},{\"end\":37520,\"start\":37513},{\"end\":37532,\"start\":37526},{\"end\":37544,\"start\":37539},{\"end\":37557,\"start\":37551},{\"end\":38011,\"start\":38005},{\"end\":38024,\"start\":38020},{\"end\":38038,\"start\":38034},{\"end\":38055,\"start\":38049},{\"end\":38324,\"start\":38318},{\"end\":38340,\"start\":38332},{\"end\":38356,\"start\":38350},{\"end\":38370,\"start\":38366},{\"end\":38380,\"start\":38376},{\"end\":38392,\"start\":38388},{\"end\":38405,\"start\":38400},{\"end\":39024,\"start\":39020},{\"end\":39038,\"start\":39032},{\"end\":39049,\"start\":39044},{\"end\":39063,\"start\":39057},{\"end\":39090,\"start\":39079},{\"end\":39104,\"start\":39100},{\"end\":39118,\"start\":39111},{\"end\":39133,\"start\":39129},{\"end\":39896,\"start\":39892},{\"end\":39904,\"start\":39901},{\"end\":39918,\"start\":39911},{\"end\":39920,\"start\":39919},{\"end\":39931,\"start\":39926},{\"end\":40563,\"start\":40559},{\"end\":40571,\"start\":40569},{\"end\":40581,\"start\":40576},{\"end\":40590,\"start\":40587},{\"end\":40601,\"start\":40596},{\"end\":40609,\"start\":40606},{\"end\":41095,\"start\":41091},{\"end\":41103,\"start\":41101},{\"end\":41114,\"start\":41108},{\"end\":41124,\"start\":41121},{\"end\":41636,\"start\":41631},{\"end\":41645,\"start\":41641},{\"end\":41655,\"start\":41651},{\"end\":41667,\"start\":41661},{\"end\":41681,\"start\":41675},{\"end\":41704,\"start\":41696},{\"end\":41718,\"start\":41713},{\"end\":41720,\"start\":41719},{\"end\":41734,\"start\":41730},{\"end\":41747,\"start\":41742},{\"end\":41759,\"start\":41755},{\"end\":41768,\"start\":41766},{\"end\":41779,\"start\":41773},{\"end\":41792,\"start\":41786},{\"end\":41803,\"start\":41799},{\"end\":41817,\"start\":41810},{\"end\":41830,\"start\":41826},{\"end\":41841,\"start\":41837},{\"end\":41851,\"start\":41848},{\"end\":41862,\"start\":41858},{\"end\":41882,\"start\":41875},{\"end\":41904,\"start\":41898},{\"end\":42417,\"start\":42412},{\"end\":42429,\"start\":42425},{\"end\":42447,\"start\":42436},{\"end\":42449,\"start\":42448},{\"end\":43081,\"start\":43074},{\"end\":43083,\"start\":43082},{\"end\":43093,\"start\":43089},{\"end\":43095,\"start\":43094},{\"end\":43110,\"start\":43104},{\"end\":43112,\"start\":43111},{\"end\":43131,\"start\":43124},{\"end\":43738,\"start\":43732},{\"end\":43766,\"start\":43757},{\"end\":43787,\"start\":43780},{\"end\":44428,\"start\":44423},{\"end\":44449,\"start\":44441},{\"end\":44460,\"start\":44457},{\"end\":45121,\"start\":45117},{\"end\":45138,\"start\":45131},{\"end\":45316,\"start\":45312},{\"end\":45330,\"start\":45326},{\"end\":45340,\"start\":45335},{\"end\":45353,\"start\":45348},{\"end\":45365,\"start\":45360},{\"end\":45378,\"start\":45374},{\"end\":45620,\"start\":45615},{\"end\":45633,\"start\":45629},{\"end\":45647,\"start\":45643},{\"end\":45666,\"start\":45657},{\"end\":45678,\"start\":45672},{\"end\":45694,\"start\":45687},{\"end\":45708,\"start\":45703},{\"end\":45718,\"start\":45715},{\"end\":45728,\"start\":45723},{\"end\":45730,\"start\":45729},{\"end\":46081,\"start\":46074},{\"end\":46093,\"start\":46088},{\"end\":46110,\"start\":46103},{\"end\":46127,\"start\":46119},{\"end\":46533,\"start\":46529},{\"end\":46549,\"start\":46544},{\"end\":46566,\"start\":46558},{\"end\":46581,\"start\":46577},{\"end\":46595,\"start\":46591},{\"end\":46883,\"start\":46879},{\"end\":46900,\"start\":46894},{\"end\":46902,\"start\":46901},{\"end\":47142,\"start\":47135},{\"end\":47144,\"start\":47143},{\"end\":47159,\"start\":47153},{\"end\":47161,\"start\":47160},{\"end\":47319,\"start\":47313},{\"end\":47341,\"start\":47334},{\"end\":47361,\"start\":47357},{\"end\":47909,\"start\":47903},{\"end\":47923,\"start\":47919},{\"end\":47937,\"start\":47933},{\"end\":47951,\"start\":47946},{\"end\":47968,\"start\":47963},{\"end\":47981,\"start\":47976},{\"end\":47983,\"start\":47982},{\"end\":47997,\"start\":47991},{\"end\":48011,\"start\":48006},{\"end\":48581,\"start\":48578},{\"end\":48591,\"start\":48587},{\"end\":48601,\"start\":48598},{\"end\":48616,\"start\":48608},{\"end\":48628,\"start\":48621},{\"end\":48639,\"start\":48635},{\"end\":48650,\"start\":48644},{\"end\":48652,\"start\":48651},{\"end\":49305,\"start\":49299},{\"end\":49317,\"start\":49312},{\"end\":49330,\"start\":49325},{\"end\":49339,\"start\":49336},{\"end\":49349,\"start\":49345},{\"end\":49360,\"start\":49356},{\"end\":49371,\"start\":49365},{\"end\":49373,\"start\":49372},{\"end\":49386,\"start\":49378},{\"end\":49779,\"start\":49776},{\"end\":49793,\"start\":49786},{\"end\":49803,\"start\":49800},{\"end\":49814,\"start\":49808},{\"end\":49824,\"start\":49821},{\"end\":49834,\"start\":49830},{\"end\":49842,\"start\":49840},{\"end\":49850,\"start\":49847},{\"end\":49858,\"start\":49855},{\"end\":49867,\"start\":49864},{\"end\":50218,\"start\":50215},{\"end\":50231,\"start\":50225},{\"end\":50245,\"start\":50238},{\"end\":50256,\"start\":50252},{\"end\":50265,\"start\":50262},{\"end\":50274,\"start\":50271},{\"end\":50880,\"start\":50877},{\"end\":50893,\"start\":50887},{\"end\":50901,\"start\":50900},{\"end\":50916,\"start\":50910},{\"end\":50920,\"start\":50917},{\"end\":51684,\"start\":51679},{\"end\":51692,\"start\":51690},{\"end\":51700,\"start\":51697},{\"end\":51711,\"start\":51706},{\"end\":51719,\"start\":51716},{\"end\":52279,\"start\":52273},{\"end\":52281,\"start\":52280},{\"end\":52544,\"start\":52540},{\"end\":52561,\"start\":52550},{\"end\":52583,\"start\":52579},{\"end\":52987,\"start\":52978},{\"end\":53003,\"start\":52998},{\"end\":53558,\"start\":53549},{\"end\":53574,\"start\":53569},{\"end\":54118,\"start\":54109},{\"end\":54130,\"start\":54124},{\"end\":54770,\"start\":54769},{\"end\":54784,\"start\":54779},{\"end\":54801,\"start\":54794},{\"end\":54815,\"start\":54812},{\"end\":54817,\"start\":54816},{\"end\":54826,\"start\":54822},{\"end\":54839,\"start\":54834},{\"end\":54853,\"start\":54849},{\"end\":54855,\"start\":54854},{\"end\":54872,\"start\":54864}]", "bib_author_last_name": "[{\"end\":32179,\"start\":32163},{\"end\":32202,\"start\":32191},{\"end\":32215,\"start\":32212},{\"end\":32222,\"start\":32217},{\"end\":33059,\"start\":33055},{\"end\":33070,\"start\":33067},{\"end\":33081,\"start\":33077},{\"end\":33604,\"start\":33600},{\"end\":33618,\"start\":33612},{\"end\":34306,\"start\":34302},{\"end\":34323,\"start\":34314},{\"end\":34339,\"start\":34333},{\"end\":34766,\"start\":34763},{\"end\":34779,\"start\":34775},{\"end\":34792,\"start\":34788},{\"end\":34811,\"start\":34802},{\"end\":34825,\"start\":34818},{\"end\":34847,\"start\":34834},{\"end\":35610,\"start\":35604},{\"end\":35626,\"start\":35621},{\"end\":35638,\"start\":35635},{\"end\":35658,\"start\":35649},{\"end\":36575,\"start\":36566},{\"end\":36593,\"start\":36584},{\"end\":36606,\"start\":36603},{\"end\":36618,\"start\":36614},{\"end\":36625,\"start\":36620},{\"end\":37185,\"start\":37179},{\"end\":37199,\"start\":37197},{\"end\":37214,\"start\":37209},{\"end\":37235,\"start\":37226},{\"end\":37254,\"start\":37242},{\"end\":37524,\"start\":37521},{\"end\":37537,\"start\":37533},{\"end\":37549,\"start\":37545},{\"end\":37565,\"start\":37558},{\"end\":38018,\"start\":38012},{\"end\":38032,\"start\":38025},{\"end\":38047,\"start\":38039},{\"end\":38066,\"start\":38056},{\"end\":38330,\"start\":38325},{\"end\":38348,\"start\":38341},{\"end\":38364,\"start\":38357},{\"end\":38374,\"start\":38371},{\"end\":38386,\"start\":38381},{\"end\":38398,\"start\":38393},{\"end\":38411,\"start\":38406},{\"end\":39030,\"start\":39025},{\"end\":39042,\"start\":39039},{\"end\":39055,\"start\":39050},{\"end\":39077,\"start\":39064},{\"end\":39098,\"start\":39091},{\"end\":39109,\"start\":39105},{\"end\":39127,\"start\":39119},{\"end\":39145,\"start\":39134},{\"end\":39899,\"start\":39897},{\"end\":39909,\"start\":39905},{\"end\":39924,\"start\":39921},{\"end\":39936,\"start\":39932},{\"end\":40567,\"start\":40564},{\"end\":40574,\"start\":40572},{\"end\":40585,\"start\":40582},{\"end\":40594,\"start\":40591},{\"end\":40604,\"start\":40602},{\"end\":40613,\"start\":40610},{\"end\":41099,\"start\":41096},{\"end\":41106,\"start\":41104},{\"end\":41119,\"start\":41115},{\"end\":41128,\"start\":41125},{\"end\":41639,\"start\":41637},{\"end\":41649,\"start\":41646},{\"end\":41659,\"start\":41656},{\"end\":41673,\"start\":41668},{\"end\":41694,\"start\":41682},{\"end\":41711,\"start\":41705},{\"end\":41728,\"start\":41721},{\"end\":41740,\"start\":41735},{\"end\":41753,\"start\":41748},{\"end\":41764,\"start\":41760},{\"end\":41771,\"start\":41769},{\"end\":41784,\"start\":41780},{\"end\":41797,\"start\":41793},{\"end\":41808,\"start\":41804},{\"end\":41824,\"start\":41818},{\"end\":41835,\"start\":41831},{\"end\":41846,\"start\":41842},{\"end\":41856,\"start\":41852},{\"end\":41873,\"start\":41863},{\"end\":41896,\"start\":41883},{\"end\":41907,\"start\":41905},{\"end\":41912,\"start\":41909},{\"end\":42423,\"start\":42418},{\"end\":42434,\"start\":42430},{\"end\":42457,\"start\":42450},{\"end\":43087,\"start\":43084},{\"end\":43102,\"start\":43096},{\"end\":43122,\"start\":43113},{\"end\":43144,\"start\":43132},{\"end\":43722,\"start\":43712},{\"end\":43730,\"start\":43724},{\"end\":43755,\"start\":43739},{\"end\":43778,\"start\":43767},{\"end\":43791,\"start\":43788},{\"end\":43798,\"start\":43793},{\"end\":44439,\"start\":44429},{\"end\":44455,\"start\":44450},{\"end\":44466,\"start\":44461},{\"end\":45129,\"start\":45122},{\"end\":45149,\"start\":45139},{\"end\":45324,\"start\":45317},{\"end\":45333,\"start\":45331},{\"end\":45346,\"start\":45341},{\"end\":45358,\"start\":45354},{\"end\":45372,\"start\":45366},{\"end\":45388,\"start\":45379},{\"end\":45627,\"start\":45621},{\"end\":45641,\"start\":45634},{\"end\":45655,\"start\":45648},{\"end\":45670,\"start\":45667},{\"end\":45685,\"start\":45679},{\"end\":45701,\"start\":45695},{\"end\":45713,\"start\":45709},{\"end\":45721,\"start\":45719},{\"end\":45734,\"start\":45731},{\"end\":46086,\"start\":46082},{\"end\":46101,\"start\":46094},{\"end\":46117,\"start\":46111},{\"end\":46132,\"start\":46128},{\"end\":46141,\"start\":46134},{\"end\":46542,\"start\":46534},{\"end\":46556,\"start\":46550},{\"end\":46575,\"start\":46567},{\"end\":46589,\"start\":46582},{\"end\":46602,\"start\":46596},{\"end\":46892,\"start\":46884},{\"end\":46910,\"start\":46903},{\"end\":47151,\"start\":47145},{\"end\":47167,\"start\":47162},{\"end\":47332,\"start\":47320},{\"end\":47355,\"start\":47342},{\"end\":47364,\"start\":47362},{\"end\":47376,\"start\":47366},{\"end\":47917,\"start\":47910},{\"end\":47931,\"start\":47924},{\"end\":47944,\"start\":47938},{\"end\":47961,\"start\":47952},{\"end\":47974,\"start\":47969},{\"end\":47989,\"start\":47984},{\"end\":48004,\"start\":47998},{\"end\":48022,\"start\":48012},{\"end\":48585,\"start\":48582},{\"end\":48596,\"start\":48592},{\"end\":48606,\"start\":48602},{\"end\":48619,\"start\":48617},{\"end\":48633,\"start\":48629},{\"end\":48642,\"start\":48640},{\"end\":48655,\"start\":48653},{\"end\":49310,\"start\":49306},{\"end\":49323,\"start\":49318},{\"end\":49334,\"start\":49331},{\"end\":49343,\"start\":49340},{\"end\":49354,\"start\":49350},{\"end\":49363,\"start\":49361},{\"end\":49376,\"start\":49374},{\"end\":49389,\"start\":49387},{\"end\":49784,\"start\":49780},{\"end\":49798,\"start\":49794},{\"end\":49806,\"start\":49804},{\"end\":49819,\"start\":49815},{\"end\":49828,\"start\":49825},{\"end\":49838,\"start\":49835},{\"end\":49845,\"start\":49843},{\"end\":49853,\"start\":49851},{\"end\":49862,\"start\":49859},{\"end\":49873,\"start\":49868},{\"end\":50223,\"start\":50219},{\"end\":50236,\"start\":50232},{\"end\":50250,\"start\":50246},{\"end\":50260,\"start\":50257},{\"end\":50269,\"start\":50266},{\"end\":50277,\"start\":50275},{\"end\":50885,\"start\":50881},{\"end\":50898,\"start\":50894},{\"end\":50908,\"start\":50902},{\"end\":50925,\"start\":50921},{\"end\":50930,\"start\":50927},{\"end\":51688,\"start\":51685},{\"end\":51695,\"start\":51693},{\"end\":51704,\"start\":51701},{\"end\":51714,\"start\":51712},{\"end\":51723,\"start\":51720},{\"end\":52290,\"start\":52282},{\"end\":52548,\"start\":52545},{\"end\":52577,\"start\":52562},{\"end\":52587,\"start\":52584},{\"end\":52996,\"start\":52988},{\"end\":53009,\"start\":53004},{\"end\":53567,\"start\":53559},{\"end\":53580,\"start\":53575},{\"end\":54122,\"start\":54119},{\"end\":54137,\"start\":54131},{\"end\":54777,\"start\":54771},{\"end\":54792,\"start\":54785},{\"end\":54810,\"start\":54802},{\"end\":54820,\"start\":54818},{\"end\":54832,\"start\":54827},{\"end\":54847,\"start\":54840},{\"end\":54862,\"start\":54856},{\"end\":54883,\"start\":54873},{\"end\":54891,\"start\":54885}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.211\",\"id\":\"b0\",\"matched_paper_id\":232185260},\"end\":32993,\"start\":32093},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":600040},\"end\":33514,\"start\":32995},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1063\",\"id\":\"b2\",\"matched_paper_id\":44129061},\"end\":34222,\"start\":33516},{\"attributes\":{\"doi\":\"10.1109/TSE.2019.2940179\",\"id\":\"b3\",\"matched_paper_id\":57573711},\"end\":34681,\"start\":34224},{\"attributes\":{\"doi\":\"10.18653/v1/p19-1285\",\"id\":\"b4\",\"matched_paper_id\":57759363},\"end\":35514,\"start\":34683},{\"attributes\":{\"doi\":\"10.18653/v1/n19-1423\",\"id\":\"b5\",\"matched_paper_id\":52967399},\"end\":36497,\"start\":35516},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":54446010},\"end\":37100,\"start\":36499},{\"attributes\":{\"doi\":\"abs/1909.09436\",\"id\":\"b7\"},\"end\":37461,\"start\":37102},{\"attributes\":{\"doi\":\"10.1109/ICSE43902.2021.00026\",\"id\":\"b8\",\"matched_paper_id\":214727958},\"end\":37930,\"start\":37463},{\"attributes\":{\"doi\":\"arXiv:2106.04985\",\"id\":\"b9\"},\"end\":38277,\"start\":37932},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":186206968},\"end\":38903,\"start\":38279},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.703\",\"id\":\"b11\",\"matched_paper_id\":204960716},\"end\":39830,\"start\":38905},{\"attributes\":{\"doi\":\"10.24963/ijcai.2018/578\",\"id\":\"b12\",\"matched_paper_id\":11683607},\"end\":40472,\"start\":39832},{\"attributes\":{\"doi\":\"10.1145/3387904.3389261\",\"id\":\"b13\",\"matched_paper_id\":202577893},\"end\":41015,\"start\":40474},{\"attributes\":{\"doi\":\"10.1145/3324884.3416591\",\"id\":\"b14\",\"matched_paper_id\":229703606},\"end\":41542,\"start\":41017},{\"attributes\":{\"doi\":\"abs/2102.04664\",\"id\":\"b15\"},\"end\":42342,\"start\":41544},{\"attributes\":{\"doi\":\"10.18653/v1/d15-1166\",\"id\":\"b16\",\"matched_paper_id\":1998416},\"end\":43036,\"start\":42344},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b17\",\"matched_paper_id\":62841423},\"end\":43655,\"start\":43038},{\"attributes\":{\"doi\":\"10.18653/v1/2021.findings-emnlp.232\",\"id\":\"b18\",\"matched_paper_id\":237304122},\"end\":44354,\"start\":43657},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1105\",\"id\":\"b19\",\"matched_paper_id\":13529592},\"end\":45055,\"start\":44356},{\"attributes\":{\"id\":\"b20\"},\"end\":45257,\"start\":45057},{\"attributes\":{\"id\":\"b21\"},\"end\":45530,\"start\":45259},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":204838007},\"end\":46016,\"start\":45532},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":7147309},\"end\":46527,\"start\":46018},{\"attributes\":{\"doi\":\"arXiv:1707.06347\",\"id\":\"b24\"},\"end\":46836,\"start\":46529},{\"attributes\":{\"doi\":\"10.1109/78.650093\",\"id\":\"b25\",\"matched_paper_id\":18375389},\"end\":47093,\"start\":46838},{\"attributes\":{\"id\":\"b26\"},\"end\":47255,\"start\":47095},{\"attributes\":{\"doi\":\"10.1145/3368089.3417058\",\"id\":\"b27\",\"matched_paper_id\":218673683},\"end\":47874,\"start\":47257},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":13756489},\"end\":48497,\"start\":47876},{\"attributes\":{\"doi\":\"10.1145/3238147.3238206\",\"id\":\"b29\",\"matched_paper_id\":52069701},\"end\":49211,\"start\":48499},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":215880650},\"end\":49687,\"start\":49213},{\"attributes\":{\"doi\":\"arXiv:2108.04556\",\"id\":\"b31\"},\"end\":50136,\"start\":49689},{\"attributes\":{\"doi\":\"10.1007/978-3-030-91431-8_29\",\"id\":\"b32\",\"matched_paper_id\":244363186},\"end\":50768,\"start\":50138},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.685\",\"id\":\"b33\",\"matched_paper_id\":237386541},\"end\":51623,\"start\":50770},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":202769028},\"end\":52181,\"start\":51625},{\"attributes\":{\"doi\":\"10.1007/BF00992696\",\"id\":\"b35\",\"matched_paper_id\":2332513},\"end\":52466,\"start\":52183},{\"attributes\":{\"doi\":\"10.1145/3308558.3313632\",\"id\":\"b36\",\"matched_paper_id\":86524089},\"end\":52907,\"start\":52468},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b37\",\"matched_paper_id\":218763496},\"end\":53489,\"start\":52909},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b38\",\"matched_paper_id\":235421942},\"end\":54045,\"start\":53491},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1041\",\"id\":\"b39\",\"matched_paper_id\":12718048},\"end\":54715,\"start\":54047},{\"attributes\":{\"doi\":\"abs/1909.08593\",\"id\":\"b40\"},\"end\":55124,\"start\":54717}]", "bib_title": "[{\"end\":32154,\"start\":32093},{\"end\":33046,\"start\":32995},{\"end\":33589,\"start\":33516},{\"end\":34294,\"start\":34224},{\"end\":34754,\"start\":34683},{\"end\":35596,\"start\":35516},{\"end\":36562,\"start\":36499},{\"end\":37511,\"start\":37463},{\"end\":38316,\"start\":38279},{\"end\":39018,\"start\":38905},{\"end\":39890,\"start\":39832},{\"end\":40557,\"start\":40474},{\"end\":41089,\"start\":41017},{\"end\":42410,\"start\":42344},{\"end\":43072,\"start\":43038},{\"end\":43710,\"start\":43657},{\"end\":44421,\"start\":44356},{\"end\":45613,\"start\":45532},{\"end\":46072,\"start\":46018},{\"end\":46877,\"start\":46838},{\"end\":47311,\"start\":47257},{\"end\":47901,\"start\":47876},{\"end\":48576,\"start\":48499},{\"end\":49297,\"start\":49213},{\"end\":50213,\"start\":50138},{\"end\":50875,\"start\":50770},{\"end\":51677,\"start\":51625},{\"end\":52271,\"start\":52183},{\"end\":52538,\"start\":52468},{\"end\":52976,\"start\":52909},{\"end\":53547,\"start\":53491},{\"end\":54107,\"start\":54047}]", "bib_author": "[{\"end\":32181,\"start\":32156},{\"end\":32204,\"start\":32181},{\"end\":32217,\"start\":32204},{\"end\":32224,\"start\":32217},{\"end\":33061,\"start\":33048},{\"end\":33072,\"start\":33061},{\"end\":33083,\"start\":33072},{\"end\":33606,\"start\":33591},{\"end\":33620,\"start\":33606},{\"end\":34308,\"start\":34296},{\"end\":34325,\"start\":34308},{\"end\":34341,\"start\":34325},{\"end\":34768,\"start\":34756},{\"end\":34781,\"start\":34768},{\"end\":34794,\"start\":34781},{\"end\":34813,\"start\":34794},{\"end\":34827,\"start\":34813},{\"end\":34849,\"start\":34827},{\"end\":35612,\"start\":35598},{\"end\":35628,\"start\":35612},{\"end\":35640,\"start\":35628},{\"end\":35660,\"start\":35640},{\"end\":36577,\"start\":36564},{\"end\":36595,\"start\":36577},{\"end\":36608,\"start\":36595},{\"end\":36620,\"start\":36608},{\"end\":36627,\"start\":36620},{\"end\":37187,\"start\":37173},{\"end\":37201,\"start\":37187},{\"end\":37216,\"start\":37201},{\"end\":37237,\"start\":37216},{\"end\":37256,\"start\":37237},{\"end\":37526,\"start\":37513},{\"end\":37539,\"start\":37526},{\"end\":37551,\"start\":37539},{\"end\":37567,\"start\":37551},{\"end\":38020,\"start\":38005},{\"end\":38034,\"start\":38020},{\"end\":38049,\"start\":38034},{\"end\":38068,\"start\":38049},{\"end\":38332,\"start\":38318},{\"end\":38350,\"start\":38332},{\"end\":38366,\"start\":38350},{\"end\":38376,\"start\":38366},{\"end\":38388,\"start\":38376},{\"end\":38400,\"start\":38388},{\"end\":38413,\"start\":38400},{\"end\":39032,\"start\":39020},{\"end\":39044,\"start\":39032},{\"end\":39057,\"start\":39044},{\"end\":39079,\"start\":39057},{\"end\":39100,\"start\":39079},{\"end\":39111,\"start\":39100},{\"end\":39129,\"start\":39111},{\"end\":39147,\"start\":39129},{\"end\":39901,\"start\":39892},{\"end\":39911,\"start\":39901},{\"end\":39926,\"start\":39911},{\"end\":39938,\"start\":39926},{\"end\":40569,\"start\":40559},{\"end\":40576,\"start\":40569},{\"end\":40587,\"start\":40576},{\"end\":40596,\"start\":40587},{\"end\":40606,\"start\":40596},{\"end\":40615,\"start\":40606},{\"end\":41101,\"start\":41091},{\"end\":41108,\"start\":41101},{\"end\":41121,\"start\":41108},{\"end\":41130,\"start\":41121},{\"end\":41641,\"start\":41631},{\"end\":41651,\"start\":41641},{\"end\":41661,\"start\":41651},{\"end\":41675,\"start\":41661},{\"end\":41696,\"start\":41675},{\"end\":41713,\"start\":41696},{\"end\":41730,\"start\":41713},{\"end\":41742,\"start\":41730},{\"end\":41755,\"start\":41742},{\"end\":41766,\"start\":41755},{\"end\":41773,\"start\":41766},{\"end\":41786,\"start\":41773},{\"end\":41799,\"start\":41786},{\"end\":41810,\"start\":41799},{\"end\":41826,\"start\":41810},{\"end\":41837,\"start\":41826},{\"end\":41848,\"start\":41837},{\"end\":41858,\"start\":41848},{\"end\":41875,\"start\":41858},{\"end\":41898,\"start\":41875},{\"end\":41909,\"start\":41898},{\"end\":41914,\"start\":41909},{\"end\":42425,\"start\":42412},{\"end\":42436,\"start\":42425},{\"end\":42459,\"start\":42436},{\"end\":43089,\"start\":43074},{\"end\":43104,\"start\":43089},{\"end\":43124,\"start\":43104},{\"end\":43146,\"start\":43124},{\"end\":43724,\"start\":43712},{\"end\":43732,\"start\":43724},{\"end\":43757,\"start\":43732},{\"end\":43780,\"start\":43757},{\"end\":43793,\"start\":43780},{\"end\":43800,\"start\":43793},{\"end\":44441,\"start\":44423},{\"end\":44457,\"start\":44441},{\"end\":44468,\"start\":44457},{\"end\":45131,\"start\":45117},{\"end\":45151,\"start\":45131},{\"end\":45326,\"start\":45312},{\"end\":45335,\"start\":45326},{\"end\":45348,\"start\":45335},{\"end\":45360,\"start\":45348},{\"end\":45374,\"start\":45360},{\"end\":45390,\"start\":45374},{\"end\":45629,\"start\":45615},{\"end\":45643,\"start\":45629},{\"end\":45657,\"start\":45643},{\"end\":45672,\"start\":45657},{\"end\":45687,\"start\":45672},{\"end\":45703,\"start\":45687},{\"end\":45715,\"start\":45703},{\"end\":45723,\"start\":45715},{\"end\":45736,\"start\":45723},{\"end\":46088,\"start\":46074},{\"end\":46103,\"start\":46088},{\"end\":46119,\"start\":46103},{\"end\":46134,\"start\":46119},{\"end\":46143,\"start\":46134},{\"end\":46544,\"start\":46529},{\"end\":46558,\"start\":46544},{\"end\":46577,\"start\":46558},{\"end\":46591,\"start\":46577},{\"end\":46604,\"start\":46591},{\"end\":46894,\"start\":46879},{\"end\":46912,\"start\":46894},{\"end\":47153,\"start\":47135},{\"end\":47169,\"start\":47153},{\"end\":47334,\"start\":47313},{\"end\":47357,\"start\":47334},{\"end\":47366,\"start\":47357},{\"end\":47378,\"start\":47366},{\"end\":47919,\"start\":47903},{\"end\":47933,\"start\":47919},{\"end\":47946,\"start\":47933},{\"end\":47963,\"start\":47946},{\"end\":47976,\"start\":47963},{\"end\":47991,\"start\":47976},{\"end\":48006,\"start\":47991},{\"end\":48024,\"start\":48006},{\"end\":48587,\"start\":48578},{\"end\":48598,\"start\":48587},{\"end\":48608,\"start\":48598},{\"end\":48621,\"start\":48608},{\"end\":48635,\"start\":48621},{\"end\":48644,\"start\":48635},{\"end\":48657,\"start\":48644},{\"end\":49312,\"start\":49299},{\"end\":49325,\"start\":49312},{\"end\":49336,\"start\":49325},{\"end\":49345,\"start\":49336},{\"end\":49356,\"start\":49345},{\"end\":49365,\"start\":49356},{\"end\":49378,\"start\":49365},{\"end\":49391,\"start\":49378},{\"end\":49786,\"start\":49776},{\"end\":49800,\"start\":49786},{\"end\":49808,\"start\":49800},{\"end\":49821,\"start\":49808},{\"end\":49830,\"start\":49821},{\"end\":49840,\"start\":49830},{\"end\":49847,\"start\":49840},{\"end\":49855,\"start\":49847},{\"end\":49864,\"start\":49855},{\"end\":49875,\"start\":49864},{\"end\":50225,\"start\":50215},{\"end\":50238,\"start\":50225},{\"end\":50252,\"start\":50238},{\"end\":50262,\"start\":50252},{\"end\":50271,\"start\":50262},{\"end\":50279,\"start\":50271},{\"end\":50887,\"start\":50877},{\"end\":50900,\"start\":50887},{\"end\":50910,\"start\":50900},{\"end\":50927,\"start\":50910},{\"end\":50932,\"start\":50927},{\"end\":51690,\"start\":51679},{\"end\":51697,\"start\":51690},{\"end\":51706,\"start\":51697},{\"end\":51716,\"start\":51706},{\"end\":51725,\"start\":51716},{\"end\":52292,\"start\":52273},{\"end\":52550,\"start\":52540},{\"end\":52579,\"start\":52550},{\"end\":52589,\"start\":52579},{\"end\":52998,\"start\":52978},{\"end\":53011,\"start\":52998},{\"end\":53569,\"start\":53549},{\"end\":53582,\"start\":53569},{\"end\":54124,\"start\":54109},{\"end\":54139,\"start\":54124},{\"end\":54779,\"start\":54769},{\"end\":54794,\"start\":54779},{\"end\":54812,\"start\":54794},{\"end\":54822,\"start\":54812},{\"end\":54834,\"start\":54822},{\"end\":54849,\"start\":54834},{\"end\":54864,\"start\":54849},{\"end\":54885,\"start\":54864},{\"end\":54893,\"start\":54885}]", "bib_venue": "[{\"end\":32413,\"start\":32255},{\"end\":33195,\"start\":33083},{\"end\":33737,\"start\":33640},{\"end\":34389,\"start\":34365},{\"end\":34962,\"start\":34869},{\"end\":35838,\"start\":35680},{\"end\":36739,\"start\":36627},{\"end\":37171,\"start\":37102},{\"end\":37668,\"start\":37595},{\"end\":38003,\"start\":37932},{\"end\":38525,\"start\":38413},{\"end\":39263,\"start\":39176},{\"end\":40064,\"start\":39961},{\"end\":40702,\"start\":40638},{\"end\":41235,\"start\":41153},{\"end\":41629,\"start\":41544},{\"end\":42565,\"start\":42479},{\"end\":43229,\"start\":43150},{\"end\":43932,\"start\":43835},{\"end\":44575,\"start\":44488},{\"end\":45115,\"start\":45057},{\"end\":45310,\"start\":45259},{\"end\":45755,\"start\":45736},{\"end\":46199,\"start\":46143},{\"end\":46659,\"start\":46620},{\"end\":46955,\"start\":46929},{\"end\":47133,\"start\":47095},{\"end\":47542,\"start\":47401},{\"end\":48136,\"start\":48024},{\"end\":48771,\"start\":48680},{\"end\":49432,\"start\":49391},{\"end\":49774,\"start\":49689},{\"end\":50391,\"start\":50307},{\"end\":51049,\"start\":50963},{\"end\":51837,\"start\":51725},{\"end\":52321,\"start\":52310},{\"end\":52641,\"start\":52612},{\"end\":53094,\"start\":53015},{\"end\":53665,\"start\":53586},{\"end\":54246,\"start\":54159},{\"end\":54767,\"start\":54717},{\"end\":32558,\"start\":32415},{\"end\":33222,\"start\":33197},{\"end\":33841,\"start\":33739},{\"end\":35057,\"start\":34964},{\"end\":36003,\"start\":35840},{\"end\":36766,\"start\":36741},{\"end\":37683,\"start\":37670},{\"end\":38557,\"start\":38527},{\"end\":39343,\"start\":39265},{\"end\":40171,\"start\":40066},{\"end\":40728,\"start\":40704},{\"end\":41257,\"start\":41237},{\"end\":42654,\"start\":42567},{\"end\":43322,\"start\":43231},{\"end\":43952,\"start\":43934},{\"end\":44666,\"start\":44577},{\"end\":46222,\"start\":46201},{\"end\":47547,\"start\":47544},{\"end\":48157,\"start\":48138},{\"end\":48868,\"start\":48773},{\"end\":51140,\"start\":51051},{\"end\":51869,\"start\":51839},{\"end\":52665,\"start\":52643},{\"end\":53160,\"start\":53096},{\"end\":53731,\"start\":53667},{\"end\":54337,\"start\":54248}]"}}}, "year": 2023, "month": 12, "day": 17}