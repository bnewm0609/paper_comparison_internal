{"id": 219530626, "updated": "2023-10-06 14:36:05.22", "metadata": {"title": "Rethinking Importance Weighting for Deep Learning under Distribution Shift", "authors": "[{\"first\":\"Tongtong\",\"last\":\"Fang\",\"middle\":[]},{\"first\":\"Nan\",\"last\":\"Lu\",\"middle\":[]},{\"first\":\"Gang\",\"last\":\"Niu\",\"middle\":[]},{\"first\":\"Masashi\",\"last\":\"Sugiyama\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 6, "day": 8}, "abstract": "Under distribution shift (DS) where the training data distribution differs from the test one, a powerful technique is importance weighting (IW) which handles DS in two separate steps: weight estimation (WE) estimates the test-over-training density ratio and weighted classification (WC) trains the classifier from weighted training data. However, IW cannot work well on complex data, since WE is incompatible with deep learning. In this paper, we rethink IW and theoretically show it suffers from a circular dependency: we need not only WE for WC, but also WC for WE where a trained deep classifier is used as the feature extractor (FE). To cut off the dependency, we try to pretrain FE from unweighted training data, which leads to biased FE. To overcome the bias, we propose an end-to-end solution dynamic IW that iterates between WE and WC and combines them in a seamless manner, and hence our WE can also enjoy deep networks and stochastic optimizers indirectly. Experiments with two representative DSs on Fashion-MNIST and CIFAR-10/100 demonstrate that dynamic IW compares favorably with state-of-the-art methods.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2006.04662", "mag": "3102433174", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/FangL0S20", "doi": null}}, "content": {"source": {"pdf_hash": "47e098d1f9e0e03e2be76344da1cd2ea1c4defcc", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2006.04662v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c0ef9b6c5f0eb2ccb586436d76e7080bb0ff5995", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/47e098d1f9e0e03e2be76344da1cd2ea1c4defcc.txt", "contents": "\nRethinking Importance Weighting for Deep Learning under Distribution Shift\n\n\nTongtong Fang tongtongf@hotmail.com \nRIKEN & Univ. of Tokyo\nUniv. of Tokyo & RIKEN\n\n\nKth &amp; Riken \nRIKEN & Univ. of Tokyo\nUniv. of Tokyo & RIKEN\n\n\nGang Niu Riken \nRIKEN & Univ. of Tokyo\nUniv. of Tokyo & RIKEN\n\n\nNan Lu lu@ms.k.u-tokyo.ac.jp \nRIKEN & Univ. of Tokyo\nUniv. of Tokyo & RIKEN\n\n\nMasashi Sugiyama \nRIKEN & Univ. of Tokyo\nUniv. of Tokyo & RIKEN\n\n\nRethinking Importance Weighting for Deep Learning under Distribution Shift\n\nUnder distribution shift (DS) where the training data distribution differs from the test one, a powerful technique is importance weighting (IW) which handles DS in two separate steps: weight estimation (WE) estimates the test-over-training density ratio and weighted classification (WC) trains the classifier from weighted training data. However, IW cannot work well on complex data, since WE is incompatible with deep learning. In this paper, we rethink IW and theoretically show it suffers from a circular dependency: we need not only WE for WC, but also WC for WE where a trained deep classifier is used as the feature extractor (FE). To cut off the dependency, we try to pretrain FE from unweighted training data, which leads to biased FE. To overcome the bias, we propose an end-to-end solution dynamic IW that iterates between WE and WC and combines them in a seamless manner, and hence our WE can also enjoy deep networks and stochastic optimizers indirectly. Experiments with two representative DSs on Fashion-MNIST and CIFAR-10/100 demonstrate that dynamic IW compares favorably with state-of-the-art methods. * Equal contribution. 1 arXiv:2006.04662v1 [cs.LG] 8 Jun 2020 * We can update a weight by convexly combining its old value from the last epoch and its new value from DIW. This can stabilize the weight across epochs, in case that DIW is unstable when the batch size is small. . Co-teaching: Robust training of deep neural networks with extremely noisy labels. In NeurIPS, 2018b. R. V. Han Xiao, Kashif Rasul. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747v2, 2017. H. He and E. A. Garcia. Learning from imbalanced data.\n\nIntroduction\n\nSupervised deep learning is extremely successful (Goodfellow et al., 2016), while its success relies highly on the fact that training and test data come from the same distribution. A big challenge in this deep learning age is distribution shift or dataset shift where training and test data come from  two different distributions (Quionero-Candela et al., 2009;Sugiyama and Kawanabe, 2012;Pan and Yang, 2009): the training data are drawn from p tr (x, y), the test data are drawn from p te (x, y), and p tr (x, y) = p te (x, y). Under distribution shift, standard supervised deep learning will lead to deep classifiers which are biased to training data and whose performance will drop on test data.\n\nIt is usually assumed under distribution shift that p te (x, y) is absolutely continuous w.r.t. p tr (x, y), i.e., p tr (x, y) = 0 implies p te (x, y) = 0. Then, there is a function w * (x, y) = p te (x, y)/p tr (x, y), such that for any function f of x and y, E pte(x,y) [f (x, y)] = E ptr(x,y) [w * (x, y)f (x, y)].\n\n(1)\n\nEq.\n\n(1) means after taking proper weights into account, the weighted expectation of f over p tr (x, y) becomes unbiased, no matter if f is a loss to be minimized or a reward to be maximized. Thanks to this property, we can use importance weighting (IW) (Shimodaira, 2000;Sugiyama et al., 2007a;Huang et al., 2007;Sugiyama et al., 2007bSugiyama et al., , 2008Kanamori et al., 2009) to handle distribution shift in two separate steps: (i) weight estimation (WE) estimates w * from the training data and a tiny set of validation data drawn from p te (x, y) or p te (x); (ii) weighted classification (WC) approximates E ptr(x,y) [w * (x, y)f (x, y)] from the training data and then trains our favorite classifiers as if there is no distribution shift (Shimodaira, 2000). IW works very well if the form of data is simple, and has been the common practice of non-deep learning under distribution shift . Nonetheless, IW cannot work well if the form of data is complex. Consider a k-class classification problem with an input domain X \u2282 R d and an output domain Y = {1, . . . , k} where d is the input dimension, and let f : X \u2192 R k be the classifier to be trained for this problem. Here, w * processes (d + 1)-dimensional input and f processes d-dimensional input, and consequently the WE step is not necessarily easier than the WC step. Thus, more expressive power is definitely needed in WE.\n\nIn this paper, we focus on improving IW to make it work for deep learning under distribution shift. We argue that it is difficult to boost the expressive power of WE for three reasons. Firstly, some WE methods are model-free such that they assign weights to data without a model of w * . Secondly, other WE methods are model-based and model-independent, but the optimizations are constrained and incompatible with stochastic optimization solvers, because E ptr(x,y) [w * (x, y)] = E pte(x,y) [1] = 1. Finally, even if we ignore the constraint or satisfy it in each mini-batch, most powerful deep models nowadays are designed for classification and hard to train with WE objectives. Therefore, it is better to boost the expressive power by an external feature extractor (FE) inside f , a deep classifier (DC) chosen for the classification problem to be solved. Going along this way, we encounter the circular dependency in Figure 1: originally we need w * to train f ; now we need a trained f to estimate w * . This causality dilemma pushes us to ask which should come first: the chicken or the egg?\n\nWe think of two possible ways to solve the circular dependency, one pipelined and one endto-end. The pipelined solution has two steps: (i) pretrain a DC as FE from unweighted training data and perform WE on the data transformed by FE; (ii) perform WC. Since the weights cannot change, we call this method static importance weighting (SIW), as illustrated in the top diagram of Figure 2. The DC as FE is trained without considering distribution shift, and we empirically confirm it is biased to training data. As a result, this naive solution is only a bit better than no DC/FE unfortunately.\n\nOn the other hand, the end-to-end solution, called dynamic importance weighting (DIW) and illustrated in the bottom diagram of Figure 2, has a single step: train a DC as FE from weighted training data (i.e., perform WC) and at the same time perform WE on the data transformed by FE in a seamless manner. More specifically, let W be the set of importance weights initialized to be all ones and let f be initialized randomly. Subsequently, we update f for several epochs to pretrain it a little, and then we update both W and f for the remaining epochs: in each mini-batch, W is updated by an objective of WE where f is fixed and then f is updated by the objective of WC where W is fixed in backpropagation. * As a consequence, this more advanced solution gradually reduces the biases of W and f , which suggests that IW for deep learning nowadays can perform as well as IW for non-deep learning in the old days hopefully.\n\nThe rest of the paper is organized as follows. DIW is proposed in Sec. 2 with its applications given in Sec. 3. We discuss the related works in Sec. 4, and present the experiments in Sec. 5. Some more theoretical and experimental results can be found in the appendices.\n\n\nDynamic importance weighting\n\nAs mentioned earlier, under distribution shift, training and test data come from two different distributions p tr (x, y) and p te (x, y) (Quionero-Candela et al., 2009;Sugiyama and Kawanabe, 2012). Let {(x tr i , y tr i )} ntr i=1 be a set of i.i.d. training data sampled from p tr (x, y) where n tr is the training sample size, and\n{(x v i , y v i )} nv i=1\nbe a set of i.i.d. validation data sampled from p te (x, y) where n v is the validation sample size. We assume validation data are much less than training data, namely n v n tr , otherwise we can use validation data for training.\n\nWeighted classification From now on, we assume our classifier f to be trained is a deep network parameterized by \u03b8 that is denoted by f \u03b8 . Let : R k \u00d7 Y \u2192 R + be the surrogate loss function for k-class classification, e.g., softmax cross-entropy loss. The classification risk of f \u03b8 is defined as\nR(f \u03b8 ) = E pte(x,y) [ (f \u03b8 (x), y)],(2)\nwhich is the performance measure we would like to optimize. According to Eq. (1), if w * (x, y) is given or\nW * = {w * i | w * i = w * (x tr i , y tr i )} ntr i=1 is given, R(f \u03b8 ) can be approximated by R(f \u03b8 ) = 1 ntr ntr i=1 w * i (f \u03b8 (x tr i ), y tr i ),(3)\nwhich is the objective of weighted classification. The weighted empirical risk R(f \u03b8 ) in Eq. (3) is an unbiased estimator of the risk R(f \u03b8 ) in Eq.\n\n(2), and hence the trained classifier as the minimizer of R(f \u03b8 ) converges to the minimizer of R(f \u03b8 ) as n tr goes to infinity (Shimodaira, 2000;Sugiyama et al., 2007a;Huang et al., 2007;Sugiyama et al., 2007bSugiyama et al., , 2008Kanamori et al., 2009).\n\nNon-linear transformation of data Now, the issue is how to estimate the function w * or the set W * . As discussed earlier, we should boost the expressive power externally but not internally. This means we should apply a non-linear transformation of data rather than directly model w * (x, y) or p tr (x, y) and p te (x, y) by deep networks. Let \u03c0 : X \u00d7 Y \u2192 R dr or \u03c0 : X \u00d7 Y \u2192 R dr\u22121 \u00d7 Y be a transformation where d r is the reduced dimension and d r d; let z = \u03c0(x, y) be the transformed random variable whose source of randomness is (x, y) exclusively. We expect that weight estimation on z is much easier than on (x, y). The feasibility of applying \u03c0 to transform data is justified below.\n\nTheorem 1. For a fixed, deterministic and invertible transformation \u03c0 : (x, y) \u2192 z, let p tr (z) and p te (z) be the probability density functions (PDFs) induced by p tr (x, y), p te (x, y), and \u03c0. Then,\nw * (x, y) = p te (x, y) p tr (x, y) = p te (z) p tr (z) = w * (z).(4)\nProof. Let F tr (x, y), F te (x, y), F tr (z) as well as F te (z) be the corresponding cumulative distribution functions (CDFs). By the definition of CDFs, the fundamental theorem of calculus, \u2020 and three properties of \u03c0 namely \u03c0 is fixed, deterministic and invertible, it holds that\np tr (x, y)dx = dF tr (x, y) = dF tr (z) = p tr (z)dz,(5)p te (x, y)dx = dF te (x, y) = dF te (z) = p te (z)dz,(6)\n\u2020 Here, it is implicitly assumed that PDFs p * (x) are Riemann-integrable and CDFs F * (x) are differentiable, and the proof is invalid if p * (x) are only Lebesgue-integrable and F * (x) are only absolutely continuous. The more formal proof is given as follows. Since p * (x, y) are Lebesgue-Stieltjes-integrable, we can use probability measures: for example, let N x,y (x, y) be an arbitrary neighborhood around (x, y), then as N x,y \u2192 (x, y) where the convergence is w.r.t. the distance metric on X \u00d7 Y, it holds that p tr (x, y)d|N x,y | = d\u00b5 x,y,tr (N x,y ) = d\u00b5 z,tr (\u03c0(N x,y )) = p tr (z)d|\u03c0 (N x,y \n)|,\nwhere \u00b5 x,y,tr and \u00b5 z,tr are the corresponding probability measures, \u03c0(N x,y ) = {\u03c0(x , y ) | (x , y ) \u2208 N x,y }, and | \u00b7 | denotes the Lebesgue measure of a set. This more formal proof may be more than needed, since w * is estimable only if p * (x) are continuous and F * (x) are continuously differentiable.\n\nwhere d denotes the differential operator, and dF * (x, y) = \u2202 \u2202x y \u2264y x \u2264x p * (x , y )dx \u2212 y <y x \u2264x p * (x , y )dx \u00b7 dx.\n\nFor simplicity, the continuous random variable x and the discrete random variable y are considered separately. Dividing Eq. (6) by Eq. (5) proves Eq. (4).\n\nTheorem 1 requires that \u03c0 satisfies three properties: we cannot guarantee dF tr (z) = p tr (z)dz if \u03c0 is not fixed or dF tr (x, y) = dF tr (z) if \u03c0 is not deterministic or invertible. As a result, when W is updated in DIW, f \u03b8 is regarded as fixed, and it should be switched to the evaluation mode from the training mode to avoid the randomness due to dropout (Srivastava et al., 2014) or similar randomized algorithms. The invertibility of \u03c0 is non-trivial: it assumes that X \u00d7 Y is generated by a manifold M \u2282 R d with an intrinsic dimension d m \u2264 d r , and \u03c0 \u22121 recovers the generating function from M to X \u00d7 Y. If \u03c0 is from parts of f \u03b8 , f \u03b8 must be a reasonably good classifier so that \u03c0 compresses X \u00d7 Y back to M. This finding is the circular dependency in Figure 1 which is the major theoretical contribution.\n\nPractical choices of the transformation of data Let us take a closer look at practical choices of \u03c0. It seems obvious that \u03c0 can be f \u03b8 as a whole or f \u03b8 without the topmost layer. However, the latter drops y and corresponds to assuming\np tr (y | x) = p te (y | x) =\u21d2 p te (x, y) p tr (x, y) = p te (x) \u00b7 p te (y | x) p tr (x) \u00b7 p tr (y | x) = p te (x) p tr (x) = p te (z) p tr (z) ,(7)\nwhich is only possible under covariate shift (Pan and Yang, 2009;Shimodaira, 2000;Sugiyama et al., 2007bSugiyama et al., , 2008. It is conceptually a bad idea to attach y after the latent representation of x, since the distance metric on Y is completely different. A better idea to take the information of y into account would consist of three steps: first partition\n{(x tr i , y tr i )} ntr i=1 and {(x v i , y v i )} nv i=1\naccording to y, second estimate p te (y)/p tr (y), and third invoke weight estimation k times on k partitions separately based on the following identity: let w * y = p te (y)/p tr (y), then\np te (x, y) p tr (x, y) = p te (y) \u00b7 p te (x | y) p tr (y) \u00b7 p tr (x | y) = p te (y) p tr (y) \u00b7 p te (x | y) p tr (x | y) = w * y \u00b7 p te (z | y) p tr (z | y) .(8)\nThat being said, in a mini-batch, invoking weight estimation k times on k partitions may be remarkably unreliable than invoking it once on the whole mini-batch.\n\nTo this end, we propose an alternative choice \u03c0 : (x, y) \u2192 (f \u03b8 (x), y) that is motivated as follows. In practice, we are not sure about the existence of M, we cannot check whether d m \u2264 d r when M indeed exists, or it is computationally hard to confirm that \u03c0 is invertible. Consequently, Eqs. (7-8) may not hold or only hold approximately. As a matter of fact, Eq. (1) also only hold approximately after replacing the expectations with empirical averages, and it seems alright to go one step further. According to Eq. (1), there exists w(x, y) such that for all possible f (x, y),\n1 nv nv i=1 f (x v i , y v i ) \u2248 E pte(x,y) [f (x, y)] \u2248 E ptr(x,y) [w(x, y)f (x, y)] \u2248 1 ntr ntr i=1 w i f (x tr i , y tr i ),\n\nAlgorithm 1 Dynamic importance weighting (in a mini-batch).\n\nRequire: a training mini-batch S tr , a validation mini-batch S v , the current model f \u03b8t Hidden-layer-output transformation version: Loss-value transformation version:\n1: forward the input parts of S tr & S v 2: retrieve the hidden-layer outputs Z tr & Z v 3: partition Z tr & Z v into {Z tr y } k y=1 & {Z v y } k y=1 4: for y = 1, . . . , k do 5: match Z tr y & Z v\ny to obtain W y 6: end for 7: compute the loss values of S tr as L tr 8: weight the empirical risk R(f \u03b8 ) by {W y } k y=1 9: backward R(f \u03b8 ) and update \u03b8\n1: forward the input parts of S tr & S v 2: compute the loss values as L tr & L v 3: match L tr & L v to obtain W 4: weight the empirical risk R(f \u03b8 ) by W 5: backward R(f \u03b8 ) and update \u03b8 where w i = w(x tr i , y tr i ) for i = 1, .\n. . , n tr . This goal, IW for everything, is too general and then its only solution is w i = w * i ; however, it is more than needed-IW for classification should be enough. Specifically, the goal of DIW is to find a set of weights\nW = {w i } ntr i=1 such that for (f \u03b8 (x), y), 1 nv nv i=1 (f \u03b8 (x v i ), y v i ) \u03b8=\u03b8t \u2248 1 ntr ntr i=1 w i (f \u03b8 (x tr i ), y tr i ) \u03b8=\u03b8t ,(9)\nwhere the left-and right-hand sides are conditioned on \u03b8 = \u03b8 t , and \u03b8 t holds model parameters at a certain time point of training. After W is found, \u03b8 t will be updated to \u03b8 t+1 , and the current f \u03b8 will move to the next f \u03b8 ; then, we need to find a new set of weights satisfying Eq. (9) again. Compared with the general goal of IW, the goal of DIW is special and easy to achieve, and then there may be many different solutions, any of which can be used to replace\nW * = {w * i } ntr i=1 in R(f \u03b8 ) in Eq.\n(3). The above argument elaborates the motivation of \u03c0 : (x, y) \u2192 (f \u03b8 (x), y). This is possible thanks to the dynamic nature of weights in DIW which is the major methodological contribution.\n\nDistribution matching Finally, we perform distribution matching between the set of transformed training data {z tr i } ntr i=1 and the set of transformed validation data {z v i } nv i=1 . Let H be a Hilbert space of real-valued functions on R dr with an inner product \u00b7, \u00b7 H , or H be a reproducing kernel Hilbert space, where k : (z, z ) \u2192 \u03c6(z), \u03c6(z ) H is the reproducing kernel of H and \u03c6 : R dr \u2192 H is the kernel-induced feature map (Sch\u00f6lkopf and Smola, 2001). We perform distribution matching by kernel mean matching (Huang et al., 2007).\nLet \u00b5 tr = E ptr(x,y)\u00b7w(z) [\u03c6(z)] and \u00b5 te = E pte(x,y) [\u03c6(z)]\nbe the kernel embeddings of p tr \u00b7 w and p te in H, then the maximum mean discrepancy (MMD) (Borgwardt et al., 2006;Gretton et al., 2012) is defined as\nsup f H \u22641 E ptr(x,y)\u00b7w(z) [f (z)] \u2212 E pte(x,y) [f (z)] = \u00b5 tr \u2212 \u00b5 te H ,\nand the squared MMD can be approximated by\n1 ntr ntr i=1 w i \u03c6(z tr i ) \u2212 1 nv nv i=1 \u03c6(z v i ) 2 H = 1 n 2 tr w Kw \u2212 2 n 2 tr k w + Const.,(10)\nwhere w \u2208 R ntr is the weight vector, K \u2208 R ntr\u00d7ntr is a kernel matrix such that K ij = k(z tr i , z tr j ), and k \u2208 R ntr is a vector such that k i = ntr nv nv j=1 k(z tr i , z v j ). In practice, Eq. (10) is minimized subject to 0 \u2264 w i \u2264 B and | 1 ntr ntr i=1 w i \u2212 1| \u2264 where B > 0 and > 0 are hyperparameters as the upper bound of weights and the slack variable of 1 ntr ntr i=1 w i = 1. Eq. (10) is the objective of distribution matching, and the proposed DIW algorithm is presented in Algorithm 1 \u2021 , which is our major algorithmic contribution.\n\n\nApplications\n\nWe have proposed DIW for deep learning under distribution shift which is almost everywhere in the wild. Here, we introduce some examples: covariate shift, class imbalance, and label noise.\n\nCovariate shift may be the most popular shift whose definition was given in Eq. (7) (Pan and Yang, 2009;Shimodaira, 2000;Sugiyama et al., 2007bSugiyama et al., , 2008. It is harmful though p(y | x) does not change, since the expressive power of f \u03b8 is limited so that it will focus more on the regions where p tr (x) is higher but not where p te (x) is higher.\n\nClass imbalance may be the simplest shift which is defined by plugging p tr (x | y) = p te (x | y) in Eq. (8) (Japkowicz and Stephen, 2002;He and Garcia, 2009;Zhang et al., 2013;Huang et al., 2016;Buda et al., 2018;Lipton et al., 2018). The optimal solution is simply w * (x, y) = p te (y)/p tr (y), involving counting instead of density ratio estimation . It is however quite important-otherwise f \u03b8 will emphasize over-represented classes and neglect under-represented classes, which is unacceptable in terms of the transferability or fairness (Cao et al., 2019). It can also serve as a unit test to see if an IW method can successfully recover w * (x, y) without being told that the shift is indeed class imbalance.\n\nLabel noise may be the hardest or already adversarial shift where p tr (x) = p te (x) and p tr (y | x) = p te (y | x) which is opposite to covariate shift. There is a label corruption process p(\u1ef9 | y, x) where\u1ef9 denotes the corrupted label so that p tr (\u1ef9 | x) = y p(\u1ef9 | y, x) \u00b7 p te (y | x), i.e., a label y may flip to every corrupted label\u1ef9 = y with a probability p(\u1ef9 | y, x). It is extremely detrimental to training, since an over-parameterized f \u03b8 is able to fit any training data even if the training labels are random . As a result, label noise could significantly mislead f \u03b8 to fit p tr (\u1ef9 | x) that is an improper map from x to y, and this is much more serious than misleading the attention of f \u03b8 . Note that DIW can estimate p(\u1ef9 | y, x), since our validation data carry the information about p te (y | x); without those validation data, p(\u1ef9 | y, x) is unidentifiable, and then it is usually assumed to be independent of x and simplified as p(\u1ef9 | y), i.e., the class-conditional noise (CCN) (Natarajan et al., 2013;Patrini et al., 2017;Han et al., 2018b,a;Yu et al., 2019;Xia et al., 2019). DIW can also be applied to the shift where p tr (x |\u1ef9) = y p(\u1ef9 | y) \u00b7 p te (x | y) (Scott et al., 2013;du Plessis et al., 2013;Lu et al., 2019Lu et al., , 2020. \u2021 For space reasons, we defer convergence analysis of the proposed algorithm to Appendix A.\n\n\nDiscussions\n\nSince distribution shift is ubiquitous in the wild, there are many philosophies different from IW for mitigating its negative effects. In what follows, we discuss some very related philosophies: learning to reweight, distributionally robust supervised learning, and domain adaptation.\n\nLearning to reweight iterates between weighted classification on training data for updating f \u03b8 , and unweighted classification on validation data for updating W (Ren et al., 2018). Although this looks like DIW, its philosophy is fairly different from IW: IW has a specific target W * to estimate, while reweighting has a goal to optimize but no target to estimate; its goal is still empirical risk minimization on very limited validation data, and thus it may overfit the validation data. Technically, W is hidden in \u03b8 W in the objective of unweighted classification, so that (Ren et al., 2018) had to use a series of approximations just to differentiate the objective w.r.t. W through \u03b8 W , which is remarkably more difficult than Eq. (10). This reweighting philosophy can also be used to train another deep network for providing W (Jiang et al., 2018).\n\nDistributionally robust supervised learning (DRSL) assumes that there is no validation data drawn from p te (x, y) or p te (x), and consequently its philosophy is to consider the worst-case distribution shift within a prespecified uncertainty set (Ben-Tal et al., 2013;Wen et al., 2014;Duchi, 2016, 2017). We can clearly see its sufficient difference from IW: IW regards p te (x, y) as fixed and p tr (x, y) as shifted from p te (x, y) while DRSL regards p tr (x, y) as fixed and p te (x, y) as shifted from p tr (x, y). This worst-case philosophy makes DRSL more sensitive to bad training data (e.g., outliers or noisy labels) which leads to less robust f \u03b8 (Hu et al., 2018).\n\nDomain adaptation (DA) is also closely related where p te (x, y) and p tr (x, y) are called indomain and out-of-domain distributions (Daume III and Marcu, 2006) or called target and source domain distributions (Ben-David et al., 2007). Although supervised DA is more similar to DIW, this area focuses more on unsupervised DA (UDA), i.e., the validation data come from p te (x) rather than p te (x, y). UDA has at least three major philosophies: transfer knowledge from p tr (x) to p te (x) by bounding the domain discrepancy (Ghifary et al., 2017) or finding some domaininvariant representations (Ganin et al., 2016), transfer from p tr (x | y) to p te (x | y) by conditional domain-invariant representations (Gong et al., 2016), and transfer from p tr (y | x) to p te (y | x) by pseudo-labeling target domain data (Saito et al., 2017). They all have their own assumptions such as p(y | x) or p(x | y) cannot change too much, and hence none of them can deal with the label-noise application of IW. Technically, the key difference of UDA from IW is that UDA methods do not weight/reweight source domain data.\n\n\nExperiments\n\nIn this section, we verify the effectiveness of the proposed DIW for deep learning. First, we compare DIW (the loss-value transformation version in Algorithm 1) with baselines under two representative distribution shift settings: label noise and class imbalance. Second, we discuss which experimental choices (e.g., SIW/DIW, with/without FE, FE fixed/updated, with/without pretraining) contribute the most to the success of DIW in an extensive ablation study. Baselines (i) Clean, use only the tiny validation dataset for training; (ii) Uniform, assign the same weights to all the training data; (iii) Random, assign random weights according to a rectified Gaussian distribution w i = max(s i , 0), where s i \u223c N (0, 1); (iv) Reweight, proposed by (Ren et al., 2018); (v) IW, apply IW directly on the original data for assigning weights (Huang et al., 2007). \n\n\nExperimental results\n\nResults on label noise We start with the most challenging distribution shift setting, label noise. Two representative noise settings are considered here: symmetric flip  where each label is independently flipped to another class with a certain probability; pair flip (Han et al., 2018b) where the flipping occurs only within similar classes, and the noise rates are {0.3, 0.4, 0.5}. The experimental results are reported in Figure 3. We can see that the proposed method performs better than baselines, especially in the symmetric flip case. Moreover, as the noise level increases, the proposed method is still reasonably robust while others tend to overfit to the noisy labels.\n\nTo better understand how DIW contributes to learn more robust models, we take a closer look at the learned weights in the final training epoch. As shown in Figure 4, our method can successfully detect the wrongly labeled data and push them to nearly zero weights, and detect the correctly labeled data and upweight them, while others fail to do so. The results corroborate our analysis that DIW can gradually reduce the bias of DC and W together and learn robustly under the distribution shift. Results on class imbalance Then, we test another common distribution shift setting, class imbalance, where we create a multi-class imbalanced dataset from Fashion-MNIST by step imbalance (Buda et al., 2018): the sample sizes within the majority classes, and within the minority classes are the same. Let \u00b5 be the fraction of minority classes and \u03c1 be the ratio between sample sizes of the majority classes and minority classes. We test the following two settings: (i) \u00b5 = 0.2, \u03c1 = 100; (ii) \u00b5 = 0.2, \u03c1 = 200. From the results in Table 1, we can see that the proposed method performs favorably than the baselines. \n\n\nAblation study\n\nSince our proposed DIW comprises different options in algorithmic design as illustrated in Figure 2, here we perform an extensive ablation study to better understand the mechanism and provide a guidance for practical use. The options considered are whether to: (i) introduce FE; (ii) update W;\n\n(iii) update FE; (iv) pretrain FE. Starting from the original IW: adding (i) to IW yields SIW; adding (ii) to SIW yields DIW1; adding (iii) to DIW1 yields DIW3; adding (iv) to DIW3 yields DIW2. We conduct thorough experiments to compare the above methods in the label noise setting. The results are reported in Table 2, where method with \"-F\"/\"-L\" suffix means using hiddenlayer-output/loss-value transformation in Algorithm 1. Our observations in general are: (i) SIWs outperform IW due to the advantages of introducing FE; (ii) DIWs outperform SIWs since they benefit from updating W on-the-fly in an end-to-end fashion; (iii) for DIWs with pretrained FE (i.e. DIW1 and DIW2), updating FE during training is usually better than fixing it; (iv) for DIWs with updating FE (i.e. DIW2 and DIW3), \"-F\" methods perform better when FE is pretrained than randomly initialized, while \"-L\" methods do not necessarily need a pretrained FE to perform well and thus are more recommended.\n\nWe further visualize the last layer representations h(x) \u2208 R 64 of learned models on CIFAR-10 with 0.4 symmetric label noise by t-distributed stochastic neighbor embedding (t-SNE) (Maaten and Hinton, 2008) in Figure 5. The learned representations of DIWs are in general more concentrated within clusters and therefore easier to be separated for different classes, which shows their superiority over static methods. Table 2: Mean accuracy (standard deviation) in percentage on Fashion-MNIST (F-MNIST for short), CIFAR-10 and CIFAR-100 with label noise (5 repeated trials). Best and comparable methods (paired t-test at significance level 5%) are highlighted in bold. p/s is short for pair/symmetric flip. \nData Noise IW SIW-F SIW-L DIW1-F DIW2-F DIW3-F DIW1-L DIW2-L DIW3-L F-MNIST 0.\n\nConclusion\n\nWe rethought importance weighting for deep learning under distribution shift and explained that it suffers from a circular dependency conceptually and theoretically. To avoid the issue, we proposed dynamic importance weighting that iterates between deep classifier training and weight estimation, where features for weight estimation can be extracted as either hidden-layer outputs or loss values. Experiments on typical distribution shifts demonstrated the effectiveness of the proposed method. \u00a7 Note that \"-F\" methods for DIW is not applicable on CIFAR-100, since after partitioning the mini-batch data by 100 classes, the data in each partition is too few to conduct weight estimation.\n\n\nSupplementary Material\n\n\nA Convergence analysis\n\nLet R te (\u03b8) = E pte(x,y) [ (f \u03b8 (x), y)] be the classification risk which is the objective we would like to optimize, and R tr (\u03b8, w) = E ptr(x,y) [w(z) (f \u03b8 (x), y)] be the objective of our weighted classification, where w(z) = pte(z) ptr (z) . In what follows, we theoretically show that our method converges to a critical point of R te (\u03b8) under mild conditions, and we also give its convergence rate. Before presenting the analysis, we list required assumptions.\n\nAssumption 1 (Lipschitz continuous gradient). The learning objective R tr (\u03b8, w) is twice differentiable and has an L-Lipschitz continuous gradient for all w, i.e.,\n\u2212LI \u2207 2 \u03b8 R tr (\u03b8, w) LI,\nwhere I is the identity matrix.\n\nAssumption 2 (Bounded variance of noise). We consider the general stochastic gradient descent scenario. Denote the stochastic gradient by\u2207 \u03b8 , and we assume it satisfies:\nE[\u2207 \u03b8 R tr (\u03b8, w)] = E[\u2207 \u03b8 R tr (\u03b8, w)], E\u2207 \u03b8 \u2207 \u03b8 R tr (\u03b8, w) \u2212 \u2207 \u03b8 R tr (\u03b8, w) 2 \u2264 \u03c3 2\nfor some constant \u03c3 2 and all w.\n\nAssumption 3 (Sensitivity). For any \u03b8 and \u03b8 , we assume the sensitivity of weights with respect to the model parameters satisfy\nE ptr(x,y) |w \u2212 w| \u2264 B \u03b8 \u2212 \u03b8 2 ,\nwhere w = pte(\u03c0 \u03b8 (x,y)) ptr(\u03c0 \u03b8 (x,y)) and w = pte(\u03c0 \u03b8 (x,y)) ptr(\u03c0 \u03b8 (x,y)) in Theorem 1.\n\nNext, we show the main convergence result.\n\nTheorem 2. Suppose the learning objective R tr (\u03b8, w), learned weights w and model parameter \u03b8 satisfy the aforementioned assumptions. Let be a bounded loss such that < M and M > 0, T be the number of training epochs, and the learning rate \u03b1 t satisfies \u03b1 t = c \u221a t , where c is a constant and t \u2208 [T ]. Then, our proposed method given by Algorithm 1 achieves E[ \u2207R tr (\u03b8 t , w t ) 2 ] \u2264 in O (1/ 2 ) steps. More specifically, the uniformly randomized output satisfies\nE[ \u2207R tr (\u03b8 T , w T ) 2 ] \u2264 \u2206 \u221a T ,(11)\nwhere \u2206 = 2M c + 2cL\u03c3 2 + 4cM B\u03c3 2 is a constant independent of the convergence process.\n\nProof. The update rule for our proposed method given by Algorithm 1 in the population version is as follows:\n\u03b8 t+1 = \u03b8 t \u2212 \u03b1 t\u2207\u03b8 R tr (\u03b8 t , w t ).(12)\nGiven Eq. (1) and Theorem 1, we have\nR te (\u03b8) \u03b8=\u03b8t = E pte(x,y) [ (f \u03b8t (x), y)] = E ptr(x,y) w(z) (f \u03b8t (x), y) = R tr (\u03b8, w) \u03b8=\u03b8t,w=wt .(13)\nThen, the objective at next time step will be\nR te (\u03b8 t+1 ) = R tr (\u03b8 t+1 , w t+1 ) = R tr (\u03b8 t+1 , w t ) + R tr (\u03b8 t+1 , w t+1 ) \u2212 R tr (\u03b8 t+1 , w t ).(14)\nBy Taylor's theorem and Assumption 1, there exists \u03b8 such that\nR tr (\u03b8 t+1 , w t ) = R tr \u03b8 t \u2212 \u03b1 t\u2207t , w t = R tr (\u03b8 t , w t ) \u2212 \u03b1 t\u2207 T t \u2207 \u03b8 R tr (\u03b8 t , w t ) + \u03b1 2 t 2\u2207 T t \u2207 2 \u03b8 R tr (\u03b8 , w t )\u2207 t \u2264 R tr (\u03b8 t , w t ) \u2212 \u03b1 t\u2207 T t \u2207 \u03b8 R tr (\u03b8 t , w t ) + \u03b1 2 t L 2 \u2207 t 2 .(15)\nGiven the bounded loss function and Assumption 3, we have\nR tr (\u03b8 t+1 , w t+1 ) \u2212 R tr (\u03b8 t+1 , w t ) = E ptr(x,y) w t+1 (f \u03b8 t+1 (x), y)] \u2212 E ptr(x,y) [w t (f \u03b8 t+1 (x), y) = E ptr(x,y) (w t+1 \u2212 w t ) (f \u03b8 t+1 (x), y) \u2264 M E ptr(x,y) |w t+1 \u2212 w t | \u2264 M B \u03b8 t+1 \u2212 \u03b8 t 2 = M B\u03b1 2 t \u2207 t 2 .(16)\nThen, we obtain\nR te (\u03b8 t+1 ) \u2264 R tr (\u03b8 t , w t ) \u2212 \u03b1 t\u2207 T t \u2207 t + \u03b1 2 t L 2 + M B\u03b1 2 t \u2207 t 2 ,(17)\nwhere \u2207 t denotes \u2207 \u03b8 R tr (\u03b8 t , w t ). Taking the expected value gives us\nE[R te (\u03b8 t+1 )|\u03b8 t ] \u2264 R tr (\u03b8 t , w t ) \u2212 \u03b1 t E \u2207 T t \u2207 t \u03b8 t + \u03b1 2 t L 2 + M B\u03b1 2 t E \u2207 t 2 \u03b8 t \u2264 R tr (\u03b8 t , w t ) \u2212 \u03b1 t \u2207 t 2 + \u03b1 2 t L 2 + M B\u03b1 2 t E \u2207 t 2 \u03b8 t .(18)\nSince\nE \u2207 t 2 \u03b8 t = E \u2207 t \u2212 \u2207 t + \u2207 t 2 \u03b8 t = E \u2207 t \u2212 \u2207 t 2 + \u2207 t 2 + 2 \u2207 t \u2212 \u2207 t T \u2207 t \u03b8 t \u2264 \u03c3 2 + \u2207 t 2 ,(19)\nwhere the last inequality Eq. (19) comes from Assumption 2, then we have\nE[R te (\u03b8 t+1 )|\u03b8 t ] \u2264 R tr (\u03b8 t , w t ) \u2212 \u03b1 t \u2212 \u03b1 2 t L 2 \u2212 M B\u03b1 2 t \u2207 t 2 + \u03b1 2 t L 2 + M B\u03b1 2 t \u03c3 2 . (20)\nIf we set \u03b1 t small enough such that \u03b1 t < 1 L+2M B for all t, then\nE[R te (\u03b8 t+1 )|\u03b8 t ] \u2264 R tr (\u03b8 t , w t ) \u2212 \u03b1 t 2 \u2207 t 2 + \u03b1 2 t L 2 + M B\u03b1 2 t \u03c3 2 .(21)\nNow taking the full expectation,\nE[R te (\u03b8 t+1 )] \u2264 E[R tr (\u03b8 t , w t )] \u2212 \u03b1 t 2 E \u2207 t 2 + \u03b1 2 t L 2 + M B\u03b1 2 t \u03c3 2 ,(22)\nand then rearranging the terms,\n1 2 E \u2207 t 2 \u2264 E[R tr (\u03b8 t , w t )] \u2212 E[R te (\u03b8 t+1 )] \u03b1 t + \u03b1 t L 2 + M B\u03b1 t \u03c3 2 .(23)\nNext summing up Eq. (23) from t = 1 to T ,\n1 2 T t=1 E \u2207 t 2 \u2264 T t=1 E[R tr (\u03b8 t , w t )] \u03b1 t \u2212 T t=1 E[R te (\u03b8 t+1 )] \u03b1 t + L 2 + M B \u03c3 2 T t=1 \u03b1 t = T t=1 E[R te (\u03b8 t )] \u03b1 t \u2212 T +1 t=2 E[R te (\u03b8 t )] \u03b1 t\u22121 + L 2 + M B \u03c3 2 T t=1 \u03b1 t = T t=2 1 \u03b1 t \u2212 1 \u03b1 t\u22121 E[R te (\u03b8 t )] + E[R te (\u03b8 1 )] \u03b1 1 \u2212 E[R te (\u03b8 T +1 )] \u03b1 T + L 2 + M B \u03c3 2 T t=1 \u03b1 t \u2264 T t=2 1 \u03b1 t \u2212 1 \u03b1 t\u22121 M + M \u03b1 1 + L 2 + M B \u03c3 2 T t=1 \u03b1 t = M \u03b1 T + L 2 + M B \u03c3 2 T t=1 \u03b1 t ,(24)\n\nB.2 Label noise experiments\n\nIn this work, the noisy labels are generated according to a predefined label noise transition matrix T , where T ij = P (\u1ef9 = j|y = i). Two types of label noise transition matrices are defined in Figure 6, where \u03b7 is the label noise rate and n is the total number of classes. In pair flip case, the labels in every class only flip to one neighbor class with a probability \u03b7. In symmetric flip label noise, the labels can randomly flip to other n \u2212 1 classes with equal probability \u03b7 n\u22121 . Note that the label noise transition matrix and label noise rate are unknown to the model.    \n\uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 1 \u2212 \u03b7 \u03b7 0 . . . 0 0 1 \u2212 \u03b7 \u03b7 . . . 0 . . . . . . . . . . . . 0 0 . . . 1 \u2212 \u03b7 \u03b7 \u03b7 0 . . . 0 1 \u2212 \u03b7 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 1 \u2212 \u03b7 \u03b7 n\u22121 . . .\n\nB.3 Class imbalance experiments\n\nTo create a class imbalance version from Fashion-MNIST, we randomly select 10 data per class for validation set, 4,000 data (including the 10 validation data) per majority class for training set. The number of data per minority class (including the 10 validation data) in training set are computed according to \u03c1 as described in Sec. 5.1. We also randomly select 1,000 data from test set for the test set used in class imbalance experiments.  Table 3 presents the mean accuracy and standard deviation on Fashion-MNIST, CIFAR-10 and CIFAR-100 with label noise. This table corresponds to Figure 3 in Sec. 5.1. Figure 7 presents weight distribution for correctly and wrongly labeled data on CIFAR-10 under two label noise settings: 0.3 pair flip and 0.5 symmetric flip. We can see the results here are consistent with that in Figure 4.\n\n\nC Supplementary experimental results\n\n\nSummary of classification accuracy\n\n\nImportance weight distribution\n\nExperimental results on ablation study Here we provide supplementary results on ablation study. Figure 8 shows experimental results of methods discussed in in Sec. 5.2, which corresponds to Table 2. Figure 9 is given to present the t-SNE visualization of embeddings, where colors denote noisy labels actually used in training rather than ground-truth labels. By comparing Figure 9 with Figure 5, we can see how the label noise effect is mitigated in classification. \n\nFigure 2 :\n2Illustrations of SIW vs. DIW.\n\nFigure 3 :\n3Experimental results of training deep neural networks on Fashion-MNIST, CIFAR-10 and CIFAR-100 with label noise. Shaded regions present standard deviation over five repeated trials.SetupWe perform experiments on Fashion-MNIST (Han Xiao, 2017), CIFAR-10 (Krizhevsky and Hinton, 2009) and CIFAR-100 (Krizhevsky and Hinton, 2009). For the tiny validation set, we use 1,000 clean data for label noise experiments and 10 data per class for class imbalance experiments. Note that the validation set is included in the training set for all baseline methods. For Fashion-MNIST and CIFAR, the models areLeNet-5 (LeCun et al., 1998)  andResNet-32 (He et al.,  2016)  respectively; the optimizer is stochastic gradient descent(Robbins and Monro, 1951). For a fair comparison, we normalize the weights of all examples in a training batch so that they sum up to one, and we do not employ any form of data augmentation for all the methods. More details about the setups and supplementary experimental results can be found in Appendix B and C.\n\nFigure 4 :\n4Weight distribution for correctly and wrongly labeled data on CIFAR-10 0.4 symmetric flip.\n\nFigure 5\n5: t-SNE visualization of embeddings for CIFAR-10. Colors denote ground-truth labels.\n\nFigure 6 :\n6Label noise transition matrix. Left: Pair flip label noise; Right: Symmetric flip label noise.\n\nFigure 7 :Figure 8 :Figure 9\n789Weight distribution for correctly and wrongly labeled data on CIFAR-Experimental results of training deep neural networks on Fashion-MNIST, CIFAR-10 and CIFAR-100 with label noise. : t-SNE visualization of embeddings for CIFAR-10. Colors denote noisy labels.\n\n\nSIW/DIW stands for static/dynamic importance weighting; FE is short for feature extractor, and LC/DC is for linear/deep classifier; W is a set of weights. Circular update is employed to solve circular dependency.Linear \n\nClassifier \nFeature \nExtractor \n\nImportance Weights \n\nDeep Classifier \n\nWE \nWC \n\nBlue arrow depicts WC depending on \nWE; green arrow depicts WE depend-\ning on WC-this makes a circle. \n\nFigure 1: Circular dependency. \n\nTrain data \ntransformed \nW \nVal \ndata \n\nTrain \ndata \n\nSIW (estimating weights) \n\nFE \nLC \nDC \nPretrained \nVal data \ntransformed \n\nDC \n\nStatic weights \n\nTrain \ndata \n\nSIW (training classifier) \n\nW \n\nDIW (end-to-end solution) \n\nCircular update \n\nDynamic weights \n\nTrain \ndata \n\nFE \nLC \nDC \nPretrained \na little \nVal \ndata \n\nTrain \ndata \nTrain data \ntransformed \nW \nVal data \ntransformed \n\n\n\nTable 1 :\n1Mean accuracy (standard deviation) in percentage on imbalanced Fashion-MNIST (5 trials). Best and comparable methods (paired t-test at significance level 5%) are highlighted in bold.Method \n\u03c1 = 100 \n\u03c1 = 200 \n\nClean \n67.77 (0.94) 67.77 (0.94) \nUniform 82.39 (0.94) 76.87 (1.14) \nRandom 82.85 (0.76) 78.48 (0.79) \nIW \n81.58 (0.79) 77.01 (1.95) \nReweight 81.82 (0.95) 76.59 (1.11) \nProposed 83.69 (1.21) 81.38 (1.24) \n\n\n\nTable 3 :\n3Mean accuracy (standard deviation) in percentage on Fashion-MNIST (F-MNIST for short), CIFAR-10 and CIFAR-100 with label noise corresponding toFigure 3(5 repeated trials). Best and comparable methods (paired t-test at significance level 5%) are highlighted in bold. p/s is short for pair/symmetric flip.Dataset \nNoise \nClean \nUniform \nRandom \nIW \nReweight \nProposed \n\nF-MNIST \n\n0.3 p 79.11 (0.82) 71.91 (1.04) 77.98 (0.99) 81.90 (0.60) 86.92 (0.55) 88.14 (0.50) \n0.4 s 79.11 (0.82) 80.19 (1.21) 84.82 (0.90) 80.57 (0.58) 80.70 (0.97) 89.09 (0.07) \n0.5 s 79.11 (0.82) 77.90 (1.05) 83.30 (0.83) 79.53 (0.61) 77.81 (0.50) 88.31 (0.21) \n\nCIFAR-10 \n\n0.3 p 41.77 (0.78) 68.40 (0.77) 79.65 (0.66) 43.54 (0.84) 80.26 (0.28) 82.50 (0.26) \n0.4 s 41.77 (0.78) 60.70 (0.66) 68.68 (1.27) 43.53 (0.46) 68.06 (0.78) 79.76 (0.40) \n0.5 s 41.77 (0.78) 52.27 (1.12) 61.94 (1.14) 41.36 (0.84) 62.85 (0.39) 73.83 (0.53) \n\nCIFAR-100 \n\n0.3 p 10.32 (0.19) 52.02 (0.54) 53.00 (0.36) 9.24 (0.26) 48.20 (0.52) 54.03 (0.40) \n0.4 s 10.32 (0.19) 40.76 (0.51) 41.82 (0.59) 9.07 (0.19) 37.35 (0.98) 50.53 (0.34) \n0.5 s 10.32 (0.19) 34.11 (0.41) 33.42 (0.91) 8.97 (0.30) 29.67 (0.94) 46.62 (0.39) \n\n\nAcknowledgmentsWe thank Prof. Magnus Boman and Prof. Henrik Bostr\u00f6m for constructive suggestions in developing the work, and thank Xuyang Zhao, Tianyi Zhang, Yifan Zhang and Ikko Yamane for helpful discussions. NL was supported by MEXT scholarship No. 171536 and the MSRA D-CORE Program. GN and MS were supported by JST AIP Acceleration Research Grant Number JPMJCR20U3, Japan.\nAnalysis of representations for domain adaptation. J Ben-David, K Blitzer, F Crammer, Pereira, NeurIPS. Ben-David, J. Blitzer, K. Crammer, and F. Pereira. Analysis of representations for domain adaptation. In NeurIPS, 2007.\n\nRobust solutions of optimization problems affected by uncertain probabilities. A Ben-Tal, D Hertog, A De Waegenaere, B Melenberg, G Rennen, Management Science. 592A. Ben-Tal, D. Den Hertog, A. De Waegenaere, B. Melenberg, and G. Rennen. Robust solutions of optimization problems affected by uncertain probabilities. Management Science, 59(2):341-357, 2013.\n\nIntegrating structured biological data by kernel maximum mean discrepancy. K M Borgwardt, A Gretton, M J Rasch, H.-P Kriegel, B Sch\u00f6lkopf, A J Smola, Bioinformatics. 2214K. M. Borgwardt, A. Gretton, M. J. Rasch, H.-P. Kriegel, B. Sch\u00f6lkopf, and A. J. Smola. Integrating structured biological data by kernel maximum mean discrepancy. Bioinformatics, 22(14):e49-e57, 2006.\n\nA systematic study of the class imbalance problem in convolutional neural networks. M Buda, A Maki, M A Mazurowski, Neural Networks. 106M. Buda, A. Maki, and M. A. Mazurowski. A systematic study of the class imbalance problem in convolutional neural networks. Neural Networks, 106:249-259, 2018.\n\nLearning imbalanced datasets with labeldistribution-aware margin loss. K Cao, C Wei, A Gaidon, N Arechiga, T Ma, NeurIPS. K. Cao, C. Wei, A. Gaidon, N. Arechiga, and T. Ma. Learning imbalanced datasets with label- distribution-aware margin loss. In NeurIPS, 2019.\n\nDomain adaptation for statistical classifiers. Iii Daume, D Marcu, Journal of Artificial Intelligence Research. 26Daume III and D. Marcu. Domain adaptation for statistical classifiers. Journal of Artificial Intelligence Research, 26:101-126, 2006.\n\nClustering unclustered data: Unsupervised binary labeling of two datasets having different class balances. M C Du Plessis, G Niu, M Sugiyama, TAAI. M. C. du Plessis, G. Niu, and M. Sugiyama. Clustering unclustered data: Unsupervised binary labeling of two datasets having different class balances. In TAAI, 2013.\n\nDomain-adversarial training of neural networks. E Ganin, H Ustinova, P Ajakan, H Germain, F Larochelle, M Laviolette, V March, Lempitsky, Journal of Machine Learning Research. 1759Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. March, and V. Lempitsky. Domain-adversarial training of neural networks. Journal of Machine Learning Research, 17(59):1-35, 2016.\n\nScatter component analysis: A unified framework for domain adaptation and domain generalization. M Ghifary, D Balduzzi, W B Kleijn, M Zhang, IEEE Transactions on Pattern Analysis and Machine Intelligence. 397M. Ghifary, D. Balduzzi, W. B. Kleijn, and M. Zhang. Scatter component analysis: A unified framework for domain adaptation and domain generalization. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(7):1414-1430, 2017.\n\nDomain adaptation with conditional transferable components. M Gong, K Zhang, T Liu, D Tao, C Glymour, B Sch\u00f6lkopf, ICML. M. Gong, K. Zhang, T. Liu, D. Tao, C. Glymour, and B. Sch\u00f6lkopf. Domain adaptation with conditional transferable components. In ICML, 2016.\n\nDeep learning. I Goodfellow, Y Bengio, A Courville, The MIT pressI. Goodfellow, Y. Bengio, and A. Courville. Deep learning. The MIT press, 2016.\n\nA kernel two-sample test. A Gretton, K M Borgwardt, M J Rasch, B Sch\u00f6lkopf, A Smola, A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Sch\u00f6lkopf, and A. Smola. A kernel two-sample test.\n\nClassification with noisy labels by importance reweighting. T Liu, D Tao, IEEE Transactions on Pattern Analysis and Machine Intelligence. 383T. Liu and D. Tao. Classification with noisy labels by importance reweighting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 38(3):447-461, 2016.\n\nOn the minimal supervision for training any binary classifier from only unlabeled data. N Lu, G Niu, A K Menon, M Sugiyama, ICLR. N. Lu, G. Niu, A. K. Menon, and M. Sugiyama. On the minimal supervision for training any binary classifier from only unlabeled data. In ICLR, 2019.\n\nMitigating overfitting in supervised classification from two unlabeled datasets: A consistent risk correction approach. T Lu, G Zhang, M Niu, Sugiyama, AISTATS. Lu, T. Zhang, G. Niu, and M. Sugiyama. Mitigating overfitting in supervised classification from two unlabeled datasets: A consistent risk correction approach. In AISTATS, 2020.\n\nVisualizing data using t-sne. L V D Maaten, G Hinton, Journal of Machine Learning Research. 9L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of Machine Learning Research, 9(Nov):2579-2605, 2008.\n\nLearning from corrupted binary labels via class-probability estimation. A Menon, B Van Rooyen, C S Ong, B Williamson, ICML. A. Menon, B. Van Rooyen, C. S. Ong, and B. Williamson. Learning from corrupted binary labels via class-probability estimation. In ICML, 2015.\n\nStochastic gradient methods for distributionally robust optimization with f-divergences. H Namkoong, J C Duchi, NeurIPS. H. Namkoong and J. C. Duchi. Stochastic gradient methods for distributionally robust optimization with f-divergences. In NeurIPS, 2016.\n\nVariance-based regularization with convex objectives. H Namkoong, J C Duchi, NeurIPS. H. Namkoong and J. C. Duchi. Variance-based regularization with convex objectives. In NeurIPS, 2017.\n\nLearning with noisy labels. N Natarajan, I S Dhillon, P K Ravikumar, A Tewari, NeurIPS. N. Natarajan, I. S. Dhillon, P. K. Ravikumar, and A. Tewari. Learning with noisy labels. In NeurIPS, 2013.\n\nA survey on transfer learning. S Pan, Q Yang, IEEE Transactions on Knowledge and Data Engineering. 2210S. Pan and Q. Yang. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering, 22(10):1345-1359, 2009.\n\nMaking deep neural networks robust to label noise: A loss correction approach. G Patrini, A Rozza, A Menon, R Nock, L Qu, CVPR. G. Patrini, A. Rozza, A. Krishna Menon, R. Nock, and L. Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.\n\nDataset shift in machine learning. J Quionero-Candela, M Sugiyama, A Schwaighofer, N Lawrence, The MIT PressJ. Quionero-Candela, M. Sugiyama, A. Schwaighofer, and N. Lawrence. Dataset shift in machine learning. The MIT Press, 2009.\n\nLearning to reweight examples for robust deep learning. M Ren, W Zeng, B Yang, R Urtasun, ICML. M. Ren, W. Zeng, B. Yang, and R. Urtasun. Learning to reweight examples for robust deep learning. In ICML, 2018.\n\nA stochastic approximation method. Annals of mathematical statistics. H Robbins, S Monro, H. Robbins and S. Monro. A stochastic approximation method. Annals of mathematical statistics, pages 400-407, 1951.\n\nAsymmetric tri-training for unsupervised domain adaptation. K Saito, Y Ushiku, T Harada, ICML. K. Saito, Y. Ushiku, and T. Harada. Asymmetric tri-training for unsupervised domain adaptation. In ICML, 2017.\n\nLearning with Kernels. B Sch\u00f6lkopf, A Smola, The MIT PressB. Sch\u00f6lkopf and A. Smola. Learning with Kernels. The MIT Press, 2001.\n\nClassification with asymmetric label noise: Consistency and maximal denoising. C Scott, G Blanchard, G Handy, COLT. C. Scott, G. Blanchard, and G. Handy. Classification with asymmetric label noise: Consistency and maximal denoising. In COLT, 2013.\n\nImproving predictive inference under covariate shift by weighting the log-likelihood function. H Shimodaira, Journal of Statistical Planning and Inference. 902H. Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of Statistical Planning and Inference, 90(2):227-244, 2000.\n\nDropout: a simple way to prevent neural networks from overfitting. G Srivastava, A Hinton, I Krizhevsky, R Sutskever, Salakhutdinov, Journal of Machine Learning Research. 151Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1): 1929-1958, 2014.\n\nMachine learning in non-stationary environments: Introduction to covariate shift adaptation. M Sugiyama, M Kawanabe, The MIT pressM. Sugiyama and M. Kawanabe. Machine learning in non-stationary environments: Introduction to covariate shift adaptation. The MIT press, 2012.\n\nCovariate shift adaptation by importance weighted cross validation. M Sugiyama, M Krauledat, K M\u00fcller, Journal of Machine Learning Research. 85M. Sugiyama, M. Krauledat, and K. M\u00fcller. Covariate shift adaptation by importance weighted cross validation. Journal of Machine Learning Research, 8(5):985-1005, 2007a.\n\nDirect importance estimation with model selection and its application to covariate shift adaptation. M Sugiyama, S Nakajima, H Kashima, P Buenau, M Kawanabe, NeurIPS. M. Sugiyama, S. Nakajima, H. Kashima, P. Buenau, and M. Kawanabe. Direct importance estimation with model selection and its application to covariate shift adaptation. In NeurIPS, 2007b.\n\nDirect importance estimation for covariate shift adaptation. M Sugiyama, T Suzuki, S Nakajima, H Kashima, P B\u00fcnau, M Kawanabe, Annals of the Institute of Statistical Mathematics. 604M. Sugiyama, T. Suzuki, S. Nakajima, H. Kashima, P. von B\u00fcnau, and M. Kawanabe. Direct impor- tance estimation for covariate shift adaptation. Annals of the Institute of Statistical Mathematics, 60(4):699-746, 2008.\n\nDensity ratio estimation in machine learning. M Sugiyama, T Suzuki, T Kanamori, Cambridge University PressM. Sugiyama, T. Suzuki, and T. Kanamori. Density ratio estimation in machine learning. Cambridge University Press, 2012.\n\nLearning with symmetric label noise: The importance of being unhinged. B Van Rooyen, A Menon, R C Williamson, NeurIPS. B. Van Rooyen, A. Menon, and R. C. Williamson. Learning with symmetric label noise: The importance of being unhinged. In NeurIPS, 2015.\n\nRobust learning under uncertain test distributions: Relating covariate shift to model misspecification. C.-N Wen, R Yu, Greiner, ICML. Wen, C.-N. Yu, and R. Greiner. Robust learning under uncertain test distributions: Relating covariate shift to model misspecification. In ICML, 2014.\n\nAre anchor points really indispensable in label-noise learning? In NeurIPS. X Xia, T Liu, N Wang, B Han, C Gong, G Niu, M Sugiyama, X. Xia, T. Liu, N. Wang, B. Han, C. Gong, G. Niu, and M. Sugiyama. Are anchor points really indispensable in label-noise learning? In NeurIPS, 2019.\n\nHow does disagreement help generalization against label corruption? In ICML. B Yu, J Han, G Yao, I W Niu, M Tsang, Sugiyama, Yu, B. Han, J. Yao, G. Niu, I. W. Tsang, and M. Sugiyama. How does disagreement help generalization against label corruption? In ICML, 2019.\n\nUnderstanding deep learning requires rethinking generalization. S Zhang, M Bengio, B Hardt, O Recht, Vinyals, Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals. Understanding deep learning requires rethinking generalization. In ICLR, 2017.\n\ndataset is a collection of 60,000 real-world object images in 10 classes, 50,000 images for training and 10,000 for testing. Each class has 6,000 32x32 RGB images. K Zhang, B Sch\u00f6lkopf, K Muandet, Z Wang, CIFAR-100 Krizhevsky and HintonICML, 2013. contains 60,000 training images and 10,000 test images. 0th (input) layer: (32*32)-1st to 2nd layer: C(5*5,6)-S(2*2)-3rd to 4th layer: C(5*5,16)-S(2*2)-5th layer: FC(120)-6th layer: FC(84)-10. ResNet-32 He et al. (2016) is used as the base model for CIFAR-10 and CIFAR-100: 0th (input) layer: (32*32*3)-1st to 11th layers: C(3*3, 16)-[C(3*3, 16), C(3*3, 16)]*5-12th to 21st layers: [C(3*3, 32), C(3*3, 32)]*5-22nd to 31st layers: [C(3*3, 64), C(3*3, 64)]*5-32nd layer: Global Average Pooling-10/100 where the input is a 32*32 RGB image. \u00b7, \u00b7 ] means a building block (He et al., 2016) and [\u00b7]*2 means 2 such layers, etc. Batch normalization (Ioffe and Szegedy, 2015) is applied after the 1st layerK. Zhang, B. Sch\u00f6lkopf, K. Muandet, and Z. Wang. Domain adaptation under target and conditional shift. In ICML, 2013. contains 60,000 training images and 10,000 test images. See https: //github.com/zalandoresearch/fashion-mnist for details. The model for Fashion-MNIST is a LeNet-5 LeCun et al. (1998): 0th (input) layer: (32*32)- 1st to 2nd layer: C(5*5,6)-S(2*2)- 3rd to 4th layer: C(5*5,16)-S(2*2)- 5th layer: FC(120)- 6th layer: FC(84)-10 , etc. CIFAR-10 and CIFAR-100 CIFAR-10 Krizhevsky and Hinton (2009) dataset is a collection of 60,000 real-world object images in 10 classes, 50,000 images for training and 10,000 for testing. Each class has 6,000 32x32 RGB images. CIFAR-100 Krizhevsky and Hinton (2009class. See https://www.cs.toronto.edu/~kriz/cifar.html for details. ResNet-32 He et al. (2016) is used as the base model for CIFAR-10 and CIFAR-100: 0th (input) layer: (32*32*3)- 1st to 11th layers: C(3*3, 16)-[C(3*3, 16), C(3*3, 16)]*5- 12th to 21st layers: [C(3*3, 32), C(3*3, 32)]*5- 22nd to 31st layers: [C(3*3, 64), C(3*3, 64)]*5- 32nd layer: Global Average Pooling-10/100 where the input is a 32*32 RGB image, [ \u00b7, \u00b7 ] means a building block (He et al., 2016) and [\u00b7]*2 means 2 such layers, etc. Batch normalization (Ioffe and Szegedy, 2015) is applied after the 1st layer.\n", "annotations": {"author": "[{\"end\":162,\"start\":78},{\"end\":227,\"start\":163},{\"end\":291,\"start\":228},{\"end\":369,\"start\":292},{\"end\":435,\"start\":370}]", "publisher": null, "author_last_name": "[{\"end\":91,\"start\":87},{\"end\":178,\"start\":173},{\"end\":242,\"start\":237},{\"end\":298,\"start\":296},{\"end\":386,\"start\":378}]", "author_first_name": "[{\"end\":86,\"start\":78},{\"end\":166,\"start\":163},{\"end\":172,\"start\":167},{\"end\":232,\"start\":228},{\"end\":236,\"start\":233},{\"end\":295,\"start\":292},{\"end\":377,\"start\":370}]", "author_affiliation": "[{\"end\":161,\"start\":115},{\"end\":226,\"start\":180},{\"end\":290,\"start\":244},{\"end\":368,\"start\":322},{\"end\":434,\"start\":388}]", "title": "[{\"end\":75,\"start\":1},{\"end\":510,\"start\":436}]", "venue": null, "abstract": "[{\"end\":2217,\"start\":512}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2307,\"start\":2282},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2594,\"start\":2563},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2622,\"start\":2594},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2641,\"start\":2622},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3529,\"start\":3511},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":3552,\"start\":3529},{\"end\":3571,\"start\":3552},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3593,\"start\":3571},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3616,\"start\":3593},{\"end\":3637,\"start\":3616},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4023,\"start\":4005},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7732,\"start\":7701},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7760,\"start\":7732},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9054,\"start\":9036},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9077,\"start\":9054},{\"end\":9096,\"start\":9077},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9118,\"start\":9096},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9141,\"start\":9118},{\"end\":9162,\"start\":9141},{\"end\":11139,\"start\":11133},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12123,\"start\":12098},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13010,\"start\":12990},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":13027,\"start\":13010},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":13049,\"start\":13027},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":13072,\"start\":13049},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16960,\"start\":16933},{\"end\":17039,\"start\":17019},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17220,\"start\":17196},{\"end\":17241,\"start\":17220},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":18338,\"start\":18318},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":18355,\"start\":18338},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":18377,\"start\":18355},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":18400,\"start\":18377},{\"end\":18735,\"start\":18706},{\"end\":18755,\"start\":18735},{\"end\":18774,\"start\":18755},{\"end\":18793,\"start\":18774},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18811,\"start\":18793},{\"end\":18831,\"start\":18811},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":19160,\"start\":19142},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":20341,\"start\":20317},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20362,\"start\":20341},{\"end\":20382,\"start\":20362},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":20398,\"start\":20382},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":20415,\"start\":20398},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":20520,\"start\":20500},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20544,\"start\":20520},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20559,\"start\":20544},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":20576,\"start\":20559},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21151,\"start\":21133},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21566,\"start\":21548},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22097,\"start\":22075},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":22114,\"start\":22097},{\"end\":22132,\"start\":22114},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22667,\"start\":22640},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22741,\"start\":22717},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23054,\"start\":23032},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":23123,\"start\":23103},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":23235,\"start\":23216},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23342,\"start\":23322},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24396,\"start\":24378},{\"end\":24487,\"start\":24467},{\"end\":24800,\"start\":24781},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":25894,\"start\":25875},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":27798,\"start\":27773},{\"end\":29375,\"start\":29372},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":36531,\"start\":36506}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":35777,\"start\":35735},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36819,\"start\":35778},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36923,\"start\":36820},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37019,\"start\":36924},{\"attributes\":{\"id\":\"fig_7\"},\"end\":37127,\"start\":37020},{\"attributes\":{\"id\":\"fig_8\"},\"end\":37419,\"start\":37128},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38247,\"start\":37420},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":38676,\"start\":38248},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":39855,\"start\":38677}]", "paragraph": "[{\"end\":2931,\"start\":2233},{\"end\":3250,\"start\":2933},{\"end\":3255,\"start\":3252},{\"end\":3260,\"start\":3257},{\"end\":4645,\"start\":3262},{\"end\":5745,\"start\":4647},{\"end\":6338,\"start\":5747},{\"end\":7260,\"start\":6340},{\"end\":7531,\"start\":7262},{\"end\":7896,\"start\":7564},{\"end\":8152,\"start\":7923},{\"end\":8451,\"start\":8154},{\"end\":8600,\"start\":8493},{\"end\":8905,\"start\":8756},{\"end\":9164,\"start\":8907},{\"end\":9858,\"start\":9166},{\"end\":10063,\"start\":9860},{\"end\":10418,\"start\":10135},{\"end\":11140,\"start\":10534},{\"end\":11455,\"start\":11145},{\"end\":11580,\"start\":11457},{\"end\":11736,\"start\":11582},{\"end\":12556,\"start\":11738},{\"end\":12794,\"start\":12558},{\"end\":13311,\"start\":12945},{\"end\":13560,\"start\":13371},{\"end\":13884,\"start\":13724},{\"end\":14468,\"start\":13886},{\"end\":14828,\"start\":14659},{\"end\":15184,\"start\":15029},{\"end\":15650,\"start\":15419},{\"end\":16261,\"start\":15793},{\"end\":16494,\"start\":16303},{\"end\":17040,\"start\":16496},{\"end\":17255,\"start\":17104},{\"end\":17372,\"start\":17330},{\"end\":18027,\"start\":17475},{\"end\":18232,\"start\":18044},{\"end\":18594,\"start\":18234},{\"end\":19314,\"start\":18596},{\"end\":20669,\"start\":19316},{\"end\":20969,\"start\":20685},{\"end\":21826,\"start\":20971},{\"end\":22505,\"start\":21828},{\"end\":23614,\"start\":22507},{\"end\":24489,\"start\":23630},{\"end\":25191,\"start\":24514},{\"end\":26301,\"start\":25193},{\"end\":26613,\"start\":26320},{\"end\":27591,\"start\":26615},{\"end\":28297,\"start\":27593},{\"end\":29079,\"start\":28390},{\"end\":29598,\"start\":29131},{\"end\":29764,\"start\":29600},{\"end\":29822,\"start\":29791},{\"end\":29994,\"start\":29824},{\"end\":30115,\"start\":30083},{\"end\":30244,\"start\":30117},{\"end\":30369,\"start\":30278},{\"end\":30413,\"start\":30371},{\"end\":30883,\"start\":30415},{\"end\":31012,\"start\":30924},{\"end\":31122,\"start\":31014},{\"end\":31202,\"start\":31166},{\"end\":31354,\"start\":31309},{\"end\":31528,\"start\":31466},{\"end\":31801,\"start\":31744},{\"end\":32051,\"start\":32036},{\"end\":32211,\"start\":32136},{\"end\":32389,\"start\":32384},{\"end\":32568,\"start\":32496},{\"end\":32747,\"start\":32680},{\"end\":32869,\"start\":32837},{\"end\":32990,\"start\":32959},{\"end\":33120,\"start\":33078},{\"end\":34134,\"start\":33552},{\"end\":35157,\"start\":34325},{\"end\":35734,\"start\":35268}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7922,\"start\":7897},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8492,\"start\":8452},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8755,\"start\":8601},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10134,\"start\":10064},{\"attributes\":{\"id\":\"formula_4\"},\"end\":10476,\"start\":10419},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10533,\"start\":10476},{\"attributes\":{\"id\":\"formula_6\"},\"end\":11144,\"start\":11141},{\"attributes\":{\"id\":\"formula_7\"},\"end\":12944,\"start\":12795},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13370,\"start\":13312},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13723,\"start\":13561},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14596,\"start\":14469},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15028,\"start\":14829},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15418,\"start\":15185},{\"attributes\":{\"id\":\"formula_13\"},\"end\":15792,\"start\":15651},{\"attributes\":{\"id\":\"formula_14\"},\"end\":16302,\"start\":16262},{\"attributes\":{\"id\":\"formula_15\"},\"end\":17103,\"start\":17041},{\"attributes\":{\"id\":\"formula_16\"},\"end\":17329,\"start\":17256},{\"attributes\":{\"id\":\"formula_17\"},\"end\":17474,\"start\":17373},{\"attributes\":{\"id\":\"formula_18\"},\"end\":28376,\"start\":28298},{\"attributes\":{\"id\":\"formula_19\"},\"end\":29790,\"start\":29765},{\"attributes\":{\"id\":\"formula_20\"},\"end\":30082,\"start\":29995},{\"attributes\":{\"id\":\"formula_21\"},\"end\":30277,\"start\":30245},{\"attributes\":{\"id\":\"formula_22\"},\"end\":30923,\"start\":30884},{\"attributes\":{\"id\":\"formula_23\"},\"end\":31165,\"start\":31123},{\"attributes\":{\"id\":\"formula_24\"},\"end\":31308,\"start\":31203},{\"attributes\":{\"id\":\"formula_25\"},\"end\":31465,\"start\":31355},{\"attributes\":{\"id\":\"formula_26\"},\"end\":31743,\"start\":31529},{\"attributes\":{\"id\":\"formula_27\"},\"end\":32035,\"start\":31802},{\"attributes\":{\"id\":\"formula_28\"},\"end\":32135,\"start\":32052},{\"attributes\":{\"id\":\"formula_29\"},\"end\":32383,\"start\":32212},{\"attributes\":{\"id\":\"formula_30\"},\"end\":32495,\"start\":32390},{\"attributes\":{\"id\":\"formula_31\"},\"end\":32679,\"start\":32569},{\"attributes\":{\"id\":\"formula_32\"},\"end\":32836,\"start\":32748},{\"attributes\":{\"id\":\"formula_33\"},\"end\":32958,\"start\":32870},{\"attributes\":{\"id\":\"formula_34\"},\"end\":33077,\"start\":32991},{\"attributes\":{\"id\":\"formula_35\"},\"end\":33521,\"start\":33121},{\"attributes\":{\"id\":\"formula_36\"},\"end\":34290,\"start\":34135}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26224,\"start\":26217},{\"end\":26933,\"start\":26926},{\"end\":28015,\"start\":28008},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":34775,\"start\":34768}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2231,\"start\":2219},{\"attributes\":{\"n\":\"2\"},\"end\":7562,\"start\":7534},{\"end\":14657,\"start\":14598},{\"attributes\":{\"n\":\"3\"},\"end\":18042,\"start\":18030},{\"attributes\":{\"n\":\"4\"},\"end\":20683,\"start\":20672},{\"attributes\":{\"n\":\"5\"},\"end\":23628,\"start\":23617},{\"attributes\":{\"n\":\"5.1\"},\"end\":24512,\"start\":24492},{\"attributes\":{\"n\":\"5.2\"},\"end\":26318,\"start\":26304},{\"attributes\":{\"n\":\"6\"},\"end\":28388,\"start\":28378},{\"end\":29104,\"start\":29082},{\"end\":29129,\"start\":29107},{\"end\":33550,\"start\":33523},{\"end\":34323,\"start\":34292},{\"end\":35196,\"start\":35160},{\"end\":35233,\"start\":35199},{\"end\":35266,\"start\":35236},{\"end\":35746,\"start\":35736},{\"end\":35789,\"start\":35779},{\"end\":36831,\"start\":36821},{\"end\":36933,\"start\":36925},{\"end\":37031,\"start\":37021},{\"end\":37157,\"start\":37129},{\"end\":38258,\"start\":38249},{\"end\":38687,\"start\":38678}]", "table": "[{\"end\":38247,\"start\":37634},{\"end\":38676,\"start\":38442},{\"end\":39855,\"start\":38992}]", "figure_caption": "[{\"end\":35777,\"start\":35748},{\"end\":36819,\"start\":35791},{\"end\":36923,\"start\":36833},{\"end\":37019,\"start\":36935},{\"end\":37127,\"start\":37033},{\"end\":37419,\"start\":37161},{\"end\":37634,\"start\":37422},{\"end\":38442,\"start\":38260},{\"end\":38992,\"start\":38689}]", "figure_ref": "[{\"end\":5577,\"start\":5569},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6132,\"start\":6124},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6475,\"start\":6467},{\"end\":12511,\"start\":12503},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":21825,\"start\":21805},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22504,\"start\":22487},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24946,\"start\":24938},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":25357,\"start\":25349},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":26419,\"start\":26411},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27810,\"start\":27802},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":33755,\"start\":33747},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":34919,\"start\":34911},{\"end\":34941,\"start\":34933},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":35156,\"start\":35148},{\"end\":35372,\"start\":35364},{\"end\":35475,\"start\":35467},{\"end\":35648,\"start\":35640},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":35662,\"start\":35654}]", "bib_author_first_name": "[{\"end\":40286,\"start\":40285},{\"end\":40299,\"start\":40298},{\"end\":40310,\"start\":40309},{\"end\":40539,\"start\":40538},{\"end\":40550,\"start\":40549},{\"end\":40560,\"start\":40559},{\"end\":40577,\"start\":40576},{\"end\":40590,\"start\":40589},{\"end\":40893,\"start\":40892},{\"end\":40895,\"start\":40894},{\"end\":40908,\"start\":40907},{\"end\":40919,\"start\":40918},{\"end\":40921,\"start\":40920},{\"end\":40933,\"start\":40929},{\"end\":40944,\"start\":40943},{\"end\":40957,\"start\":40956},{\"end\":40959,\"start\":40958},{\"end\":41274,\"start\":41273},{\"end\":41282,\"start\":41281},{\"end\":41290,\"start\":41289},{\"end\":41292,\"start\":41291},{\"end\":41558,\"start\":41557},{\"end\":41565,\"start\":41564},{\"end\":41572,\"start\":41571},{\"end\":41582,\"start\":41581},{\"end\":41594,\"start\":41593},{\"end\":41801,\"start\":41798},{\"end\":41810,\"start\":41809},{\"end\":42108,\"start\":42107},{\"end\":42110,\"start\":42109},{\"end\":42124,\"start\":42123},{\"end\":42131,\"start\":42130},{\"end\":42363,\"start\":42362},{\"end\":42372,\"start\":42371},{\"end\":42384,\"start\":42383},{\"end\":42394,\"start\":42393},{\"end\":42405,\"start\":42404},{\"end\":42419,\"start\":42418},{\"end\":42433,\"start\":42432},{\"end\":42799,\"start\":42798},{\"end\":42810,\"start\":42809},{\"end\":42822,\"start\":42821},{\"end\":42824,\"start\":42823},{\"end\":42834,\"start\":42833},{\"end\":43208,\"start\":43207},{\"end\":43216,\"start\":43215},{\"end\":43225,\"start\":43224},{\"end\":43232,\"start\":43231},{\"end\":43239,\"start\":43238},{\"end\":43250,\"start\":43249},{\"end\":43425,\"start\":43424},{\"end\":43439,\"start\":43438},{\"end\":43449,\"start\":43448},{\"end\":43582,\"start\":43581},{\"end\":43593,\"start\":43592},{\"end\":43595,\"start\":43594},{\"end\":43608,\"start\":43607},{\"end\":43610,\"start\":43609},{\"end\":43619,\"start\":43618},{\"end\":43632,\"start\":43631},{\"end\":43798,\"start\":43797},{\"end\":43805,\"start\":43804},{\"end\":44132,\"start\":44131},{\"end\":44138,\"start\":44137},{\"end\":44145,\"start\":44144},{\"end\":44147,\"start\":44146},{\"end\":44156,\"start\":44155},{\"end\":44443,\"start\":44442},{\"end\":44449,\"start\":44448},{\"end\":44458,\"start\":44457},{\"end\":44692,\"start\":44691},{\"end\":44696,\"start\":44693},{\"end\":44706,\"start\":44705},{\"end\":44951,\"start\":44950},{\"end\":44960,\"start\":44959},{\"end\":44974,\"start\":44973},{\"end\":44976,\"start\":44975},{\"end\":44983,\"start\":44982},{\"end\":45235,\"start\":45234},{\"end\":45247,\"start\":45246},{\"end\":45249,\"start\":45248},{\"end\":45458,\"start\":45457},{\"end\":45470,\"start\":45469},{\"end\":45472,\"start\":45471},{\"end\":45620,\"start\":45619},{\"end\":45633,\"start\":45632},{\"end\":45635,\"start\":45634},{\"end\":45646,\"start\":45645},{\"end\":45648,\"start\":45647},{\"end\":45661,\"start\":45660},{\"end\":45819,\"start\":45818},{\"end\":45826,\"start\":45825},{\"end\":46099,\"start\":46098},{\"end\":46110,\"start\":46109},{\"end\":46119,\"start\":46118},{\"end\":46128,\"start\":46127},{\"end\":46136,\"start\":46135},{\"end\":46338,\"start\":46337},{\"end\":46358,\"start\":46357},{\"end\":46370,\"start\":46369},{\"end\":46386,\"start\":46385},{\"end\":46592,\"start\":46591},{\"end\":46599,\"start\":46598},{\"end\":46607,\"start\":46606},{\"end\":46615,\"start\":46614},{\"end\":46816,\"start\":46815},{\"end\":46827,\"start\":46826},{\"end\":47013,\"start\":47012},{\"end\":47022,\"start\":47021},{\"end\":47032,\"start\":47031},{\"end\":47183,\"start\":47182},{\"end\":47196,\"start\":47195},{\"end\":47369,\"start\":47368},{\"end\":47378,\"start\":47377},{\"end\":47391,\"start\":47390},{\"end\":47634,\"start\":47633},{\"end\":47944,\"start\":47943},{\"end\":47958,\"start\":47957},{\"end\":47968,\"start\":47967},{\"end\":47982,\"start\":47981},{\"end\":48348,\"start\":48347},{\"end\":48360,\"start\":48359},{\"end\":48597,\"start\":48596},{\"end\":48609,\"start\":48608},{\"end\":48622,\"start\":48621},{\"end\":48944,\"start\":48943},{\"end\":48956,\"start\":48955},{\"end\":48968,\"start\":48967},{\"end\":48979,\"start\":48978},{\"end\":48989,\"start\":48988},{\"end\":49258,\"start\":49257},{\"end\":49270,\"start\":49269},{\"end\":49280,\"start\":49279},{\"end\":49292,\"start\":49291},{\"end\":49303,\"start\":49302},{\"end\":49312,\"start\":49311},{\"end\":49642,\"start\":49641},{\"end\":49654,\"start\":49653},{\"end\":49664,\"start\":49663},{\"end\":49895,\"start\":49894},{\"end\":49909,\"start\":49908},{\"end\":49918,\"start\":49917},{\"end\":49920,\"start\":49919},{\"end\":50187,\"start\":50183},{\"end\":50194,\"start\":50193},{\"end\":50442,\"start\":50441},{\"end\":50449,\"start\":50448},{\"end\":50456,\"start\":50455},{\"end\":50464,\"start\":50463},{\"end\":50471,\"start\":50470},{\"end\":50479,\"start\":50478},{\"end\":50486,\"start\":50485},{\"end\":50725,\"start\":50724},{\"end\":50731,\"start\":50730},{\"end\":50738,\"start\":50737},{\"end\":50745,\"start\":50744},{\"end\":50747,\"start\":50746},{\"end\":50754,\"start\":50753},{\"end\":50979,\"start\":50978},{\"end\":50988,\"start\":50987},{\"end\":50998,\"start\":50997},{\"end\":51007,\"start\":51006},{\"end\":51323,\"start\":51322},{\"end\":51332,\"start\":51331},{\"end\":51345,\"start\":51344},{\"end\":51356,\"start\":51355}]", "bib_author_last_name": "[{\"end\":40296,\"start\":40287},{\"end\":40307,\"start\":40300},{\"end\":40318,\"start\":40311},{\"end\":40327,\"start\":40320},{\"end\":40547,\"start\":40540},{\"end\":40557,\"start\":40551},{\"end\":40574,\"start\":40561},{\"end\":40587,\"start\":40578},{\"end\":40597,\"start\":40591},{\"end\":40905,\"start\":40896},{\"end\":40916,\"start\":40909},{\"end\":40927,\"start\":40922},{\"end\":40941,\"start\":40934},{\"end\":40954,\"start\":40945},{\"end\":40965,\"start\":40960},{\"end\":41279,\"start\":41275},{\"end\":41287,\"start\":41283},{\"end\":41303,\"start\":41293},{\"end\":41562,\"start\":41559},{\"end\":41569,\"start\":41566},{\"end\":41579,\"start\":41573},{\"end\":41591,\"start\":41583},{\"end\":41597,\"start\":41595},{\"end\":41807,\"start\":41802},{\"end\":41816,\"start\":41811},{\"end\":42121,\"start\":42111},{\"end\":42128,\"start\":42125},{\"end\":42140,\"start\":42132},{\"end\":42369,\"start\":42364},{\"end\":42381,\"start\":42373},{\"end\":42391,\"start\":42385},{\"end\":42402,\"start\":42395},{\"end\":42416,\"start\":42406},{\"end\":42430,\"start\":42420},{\"end\":42439,\"start\":42434},{\"end\":42450,\"start\":42441},{\"end\":42807,\"start\":42800},{\"end\":42819,\"start\":42811},{\"end\":42831,\"start\":42825},{\"end\":42840,\"start\":42835},{\"end\":43213,\"start\":43209},{\"end\":43222,\"start\":43217},{\"end\":43229,\"start\":43226},{\"end\":43236,\"start\":43233},{\"end\":43247,\"start\":43240},{\"end\":43260,\"start\":43251},{\"end\":43436,\"start\":43426},{\"end\":43446,\"start\":43440},{\"end\":43459,\"start\":43450},{\"end\":43590,\"start\":43583},{\"end\":43605,\"start\":43596},{\"end\":43616,\"start\":43611},{\"end\":43629,\"start\":43620},{\"end\":43638,\"start\":43633},{\"end\":43802,\"start\":43799},{\"end\":43809,\"start\":43806},{\"end\":44135,\"start\":44133},{\"end\":44142,\"start\":44139},{\"end\":44153,\"start\":44148},{\"end\":44165,\"start\":44157},{\"end\":44446,\"start\":44444},{\"end\":44455,\"start\":44450},{\"end\":44462,\"start\":44459},{\"end\":44472,\"start\":44464},{\"end\":44703,\"start\":44697},{\"end\":44713,\"start\":44707},{\"end\":44957,\"start\":44952},{\"end\":44971,\"start\":44961},{\"end\":44980,\"start\":44977},{\"end\":44994,\"start\":44984},{\"end\":45244,\"start\":45236},{\"end\":45255,\"start\":45250},{\"end\":45467,\"start\":45459},{\"end\":45478,\"start\":45473},{\"end\":45630,\"start\":45621},{\"end\":45643,\"start\":45636},{\"end\":45658,\"start\":45649},{\"end\":45668,\"start\":45662},{\"end\":45823,\"start\":45820},{\"end\":45831,\"start\":45827},{\"end\":46107,\"start\":46100},{\"end\":46116,\"start\":46111},{\"end\":46125,\"start\":46120},{\"end\":46133,\"start\":46129},{\"end\":46139,\"start\":46137},{\"end\":46355,\"start\":46339},{\"end\":46367,\"start\":46359},{\"end\":46383,\"start\":46371},{\"end\":46395,\"start\":46387},{\"end\":46596,\"start\":46593},{\"end\":46604,\"start\":46600},{\"end\":46612,\"start\":46608},{\"end\":46623,\"start\":46616},{\"end\":46824,\"start\":46817},{\"end\":46833,\"start\":46828},{\"end\":47019,\"start\":47014},{\"end\":47029,\"start\":47023},{\"end\":47039,\"start\":47033},{\"end\":47193,\"start\":47184},{\"end\":47202,\"start\":47197},{\"end\":47375,\"start\":47370},{\"end\":47388,\"start\":47379},{\"end\":47397,\"start\":47392},{\"end\":47645,\"start\":47635},{\"end\":47955,\"start\":47945},{\"end\":47965,\"start\":47959},{\"end\":47979,\"start\":47969},{\"end\":47992,\"start\":47983},{\"end\":48007,\"start\":47994},{\"end\":48357,\"start\":48349},{\"end\":48369,\"start\":48361},{\"end\":48606,\"start\":48598},{\"end\":48619,\"start\":48610},{\"end\":48629,\"start\":48623},{\"end\":48953,\"start\":48945},{\"end\":48965,\"start\":48957},{\"end\":48976,\"start\":48969},{\"end\":48986,\"start\":48980},{\"end\":48998,\"start\":48990},{\"end\":49267,\"start\":49259},{\"end\":49277,\"start\":49271},{\"end\":49289,\"start\":49281},{\"end\":49300,\"start\":49293},{\"end\":49309,\"start\":49304},{\"end\":49321,\"start\":49313},{\"end\":49651,\"start\":49643},{\"end\":49661,\"start\":49655},{\"end\":49673,\"start\":49665},{\"end\":49906,\"start\":49896},{\"end\":49915,\"start\":49910},{\"end\":49931,\"start\":49921},{\"end\":50191,\"start\":50188},{\"end\":50197,\"start\":50195},{\"end\":50206,\"start\":50199},{\"end\":50446,\"start\":50443},{\"end\":50453,\"start\":50450},{\"end\":50461,\"start\":50457},{\"end\":50468,\"start\":50465},{\"end\":50476,\"start\":50472},{\"end\":50483,\"start\":50480},{\"end\":50495,\"start\":50487},{\"end\":50728,\"start\":50726},{\"end\":50735,\"start\":50732},{\"end\":50742,\"start\":50739},{\"end\":50751,\"start\":50748},{\"end\":50760,\"start\":50755},{\"end\":50770,\"start\":50762},{\"end\":50985,\"start\":50980},{\"end\":50995,\"start\":50989},{\"end\":51004,\"start\":50999},{\"end\":51013,\"start\":51008},{\"end\":51022,\"start\":51015},{\"end\":51329,\"start\":51324},{\"end\":51342,\"start\":51333},{\"end\":51353,\"start\":51346},{\"end\":51361,\"start\":51357}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":10908021},\"end\":40457,\"start\":40234},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":761793},\"end\":40815,\"start\":40459},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":13341746},\"end\":41187,\"start\":40817},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":25040300},\"end\":41484,\"start\":41189},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":189998981},\"end\":41749,\"start\":41486},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":14154185},\"end\":41998,\"start\":41751},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3050169},\"end\":42312,\"start\":42000},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":2871880},\"end\":42699,\"start\":42314},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":7923833},\"end\":43145,\"start\":42701},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":5807252},\"end\":43407,\"start\":43147},{\"attributes\":{\"id\":\"b10\"},\"end\":43553,\"start\":43409},{\"attributes\":{\"id\":\"b11\"},\"end\":43735,\"start\":43555},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":11777930},\"end\":44041,\"start\":43737},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":52144552},\"end\":44320,\"start\":44043},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":204800628},\"end\":44659,\"start\":44322},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":5855042},\"end\":44876,\"start\":44661},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":10708717},\"end\":45143,\"start\":44878},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":7481496},\"end\":45401,\"start\":45145},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":951180},\"end\":45589,\"start\":45403},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":423350},\"end\":45785,\"start\":45591},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":740063},\"end\":46017,\"start\":45787},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":16406313},\"end\":46300,\"start\":46019},{\"attributes\":{\"id\":\"b22\"},\"end\":46533,\"start\":46302},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":4321928},\"end\":46743,\"start\":46535},{\"attributes\":{\"id\":\"b24\"},\"end\":46950,\"start\":46745},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":12570770},\"end\":47157,\"start\":46952},{\"attributes\":{\"id\":\"b26\"},\"end\":47287,\"start\":47159},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":5370766},\"end\":47536,\"start\":47289},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":9238949},\"end\":47874,\"start\":47538},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":6844431},\"end\":48252,\"start\":47876},{\"attributes\":{\"id\":\"b30\"},\"end\":48526,\"start\":48254},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":17547265},\"end\":48840,\"start\":48528},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":9133542},\"end\":49194,\"start\":48842},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":44112860},\"end\":49593,\"start\":49196},{\"attributes\":{\"id\":\"b34\"},\"end\":49821,\"start\":49595},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":6788443},\"end\":50077,\"start\":49823},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":992849},\"end\":50363,\"start\":50079},{\"attributes\":{\"id\":\"b37\"},\"end\":50645,\"start\":50365},{\"attributes\":{\"id\":\"b38\"},\"end\":50912,\"start\":50647},{\"attributes\":{\"id\":\"b39\"},\"end\":51156,\"start\":50914},{\"attributes\":{\"doi\":\"CIFAR-100 Krizhevsky and Hinton\",\"id\":\"b40\"},\"end\":53394,\"start\":51158}]", "bib_title": "[{\"end\":40283,\"start\":40234},{\"end\":40536,\"start\":40459},{\"end\":40890,\"start\":40817},{\"end\":41271,\"start\":41189},{\"end\":41555,\"start\":41486},{\"end\":41796,\"start\":41751},{\"end\":42105,\"start\":42000},{\"end\":42360,\"start\":42314},{\"end\":42796,\"start\":42701},{\"end\":43205,\"start\":43147},{\"end\":43795,\"start\":43737},{\"end\":44129,\"start\":44043},{\"end\":44440,\"start\":44322},{\"end\":44689,\"start\":44661},{\"end\":44948,\"start\":44878},{\"end\":45232,\"start\":45145},{\"end\":45455,\"start\":45403},{\"end\":45617,\"start\":45591},{\"end\":45816,\"start\":45787},{\"end\":46096,\"start\":46019},{\"end\":46589,\"start\":46535},{\"end\":47010,\"start\":46952},{\"end\":47366,\"start\":47289},{\"end\":47631,\"start\":47538},{\"end\":47941,\"start\":47876},{\"end\":48594,\"start\":48528},{\"end\":48941,\"start\":48842},{\"end\":49255,\"start\":49196},{\"end\":49892,\"start\":49823},{\"end\":50181,\"start\":50079},{\"end\":51320,\"start\":51158}]", "bib_author": "[{\"end\":40298,\"start\":40285},{\"end\":40309,\"start\":40298},{\"end\":40320,\"start\":40309},{\"end\":40329,\"start\":40320},{\"end\":40549,\"start\":40538},{\"end\":40559,\"start\":40549},{\"end\":40576,\"start\":40559},{\"end\":40589,\"start\":40576},{\"end\":40599,\"start\":40589},{\"end\":40907,\"start\":40892},{\"end\":40918,\"start\":40907},{\"end\":40929,\"start\":40918},{\"end\":40943,\"start\":40929},{\"end\":40956,\"start\":40943},{\"end\":40967,\"start\":40956},{\"end\":41281,\"start\":41273},{\"end\":41289,\"start\":41281},{\"end\":41305,\"start\":41289},{\"end\":41564,\"start\":41557},{\"end\":41571,\"start\":41564},{\"end\":41581,\"start\":41571},{\"end\":41593,\"start\":41581},{\"end\":41599,\"start\":41593},{\"end\":41809,\"start\":41798},{\"end\":41818,\"start\":41809},{\"end\":42123,\"start\":42107},{\"end\":42130,\"start\":42123},{\"end\":42142,\"start\":42130},{\"end\":42371,\"start\":42362},{\"end\":42383,\"start\":42371},{\"end\":42393,\"start\":42383},{\"end\":42404,\"start\":42393},{\"end\":42418,\"start\":42404},{\"end\":42432,\"start\":42418},{\"end\":42441,\"start\":42432},{\"end\":42452,\"start\":42441},{\"end\":42809,\"start\":42798},{\"end\":42821,\"start\":42809},{\"end\":42833,\"start\":42821},{\"end\":42842,\"start\":42833},{\"end\":43215,\"start\":43207},{\"end\":43224,\"start\":43215},{\"end\":43231,\"start\":43224},{\"end\":43238,\"start\":43231},{\"end\":43249,\"start\":43238},{\"end\":43262,\"start\":43249},{\"end\":43438,\"start\":43424},{\"end\":43448,\"start\":43438},{\"end\":43461,\"start\":43448},{\"end\":43592,\"start\":43581},{\"end\":43607,\"start\":43592},{\"end\":43618,\"start\":43607},{\"end\":43631,\"start\":43618},{\"end\":43640,\"start\":43631},{\"end\":43804,\"start\":43797},{\"end\":43811,\"start\":43804},{\"end\":44137,\"start\":44131},{\"end\":44144,\"start\":44137},{\"end\":44155,\"start\":44144},{\"end\":44167,\"start\":44155},{\"end\":44448,\"start\":44442},{\"end\":44457,\"start\":44448},{\"end\":44464,\"start\":44457},{\"end\":44474,\"start\":44464},{\"end\":44705,\"start\":44691},{\"end\":44715,\"start\":44705},{\"end\":44959,\"start\":44950},{\"end\":44973,\"start\":44959},{\"end\":44982,\"start\":44973},{\"end\":44996,\"start\":44982},{\"end\":45246,\"start\":45234},{\"end\":45257,\"start\":45246},{\"end\":45469,\"start\":45457},{\"end\":45480,\"start\":45469},{\"end\":45632,\"start\":45619},{\"end\":45645,\"start\":45632},{\"end\":45660,\"start\":45645},{\"end\":45670,\"start\":45660},{\"end\":45825,\"start\":45818},{\"end\":45833,\"start\":45825},{\"end\":46109,\"start\":46098},{\"end\":46118,\"start\":46109},{\"end\":46127,\"start\":46118},{\"end\":46135,\"start\":46127},{\"end\":46141,\"start\":46135},{\"end\":46357,\"start\":46337},{\"end\":46369,\"start\":46357},{\"end\":46385,\"start\":46369},{\"end\":46397,\"start\":46385},{\"end\":46598,\"start\":46591},{\"end\":46606,\"start\":46598},{\"end\":46614,\"start\":46606},{\"end\":46625,\"start\":46614},{\"end\":46826,\"start\":46815},{\"end\":46835,\"start\":46826},{\"end\":47021,\"start\":47012},{\"end\":47031,\"start\":47021},{\"end\":47041,\"start\":47031},{\"end\":47195,\"start\":47182},{\"end\":47204,\"start\":47195},{\"end\":47377,\"start\":47368},{\"end\":47390,\"start\":47377},{\"end\":47399,\"start\":47390},{\"end\":47647,\"start\":47633},{\"end\":47957,\"start\":47943},{\"end\":47967,\"start\":47957},{\"end\":47981,\"start\":47967},{\"end\":47994,\"start\":47981},{\"end\":48009,\"start\":47994},{\"end\":48359,\"start\":48347},{\"end\":48371,\"start\":48359},{\"end\":48608,\"start\":48596},{\"end\":48621,\"start\":48608},{\"end\":48631,\"start\":48621},{\"end\":48955,\"start\":48943},{\"end\":48967,\"start\":48955},{\"end\":48978,\"start\":48967},{\"end\":48988,\"start\":48978},{\"end\":49000,\"start\":48988},{\"end\":49269,\"start\":49257},{\"end\":49279,\"start\":49269},{\"end\":49291,\"start\":49279},{\"end\":49302,\"start\":49291},{\"end\":49311,\"start\":49302},{\"end\":49323,\"start\":49311},{\"end\":49653,\"start\":49641},{\"end\":49663,\"start\":49653},{\"end\":49675,\"start\":49663},{\"end\":49908,\"start\":49894},{\"end\":49917,\"start\":49908},{\"end\":49933,\"start\":49917},{\"end\":50193,\"start\":50183},{\"end\":50199,\"start\":50193},{\"end\":50208,\"start\":50199},{\"end\":50448,\"start\":50441},{\"end\":50455,\"start\":50448},{\"end\":50463,\"start\":50455},{\"end\":50470,\"start\":50463},{\"end\":50478,\"start\":50470},{\"end\":50485,\"start\":50478},{\"end\":50497,\"start\":50485},{\"end\":50730,\"start\":50724},{\"end\":50737,\"start\":50730},{\"end\":50744,\"start\":50737},{\"end\":50753,\"start\":50744},{\"end\":50762,\"start\":50753},{\"end\":50772,\"start\":50762},{\"end\":50987,\"start\":50978},{\"end\":50997,\"start\":50987},{\"end\":51006,\"start\":50997},{\"end\":51015,\"start\":51006},{\"end\":51024,\"start\":51015},{\"end\":51331,\"start\":51322},{\"end\":51344,\"start\":51331},{\"end\":51355,\"start\":51344},{\"end\":51363,\"start\":51355}]", "bib_venue": "[{\"end\":40336,\"start\":40329},{\"end\":40617,\"start\":40599},{\"end\":40981,\"start\":40967},{\"end\":41320,\"start\":41305},{\"end\":41606,\"start\":41599},{\"end\":41861,\"start\":41818},{\"end\":42146,\"start\":42142},{\"end\":42488,\"start\":42452},{\"end\":42904,\"start\":42842},{\"end\":43266,\"start\":43262},{\"end\":43422,\"start\":43409},{\"end\":43579,\"start\":43555},{\"end\":43873,\"start\":43811},{\"end\":44171,\"start\":44167},{\"end\":44481,\"start\":44474},{\"end\":44751,\"start\":44715},{\"end\":45000,\"start\":44996},{\"end\":45264,\"start\":45257},{\"end\":45487,\"start\":45480},{\"end\":45677,\"start\":45670},{\"end\":45884,\"start\":45833},{\"end\":46145,\"start\":46141},{\"end\":46335,\"start\":46302},{\"end\":46629,\"start\":46625},{\"end\":46813,\"start\":46745},{\"end\":47045,\"start\":47041},{\"end\":47180,\"start\":47159},{\"end\":47403,\"start\":47399},{\"end\":47692,\"start\":47647},{\"end\":48045,\"start\":48009},{\"end\":48345,\"start\":48254},{\"end\":48667,\"start\":48631},{\"end\":49007,\"start\":49000},{\"end\":49373,\"start\":49323},{\"end\":49639,\"start\":49595},{\"end\":49940,\"start\":49933},{\"end\":50212,\"start\":50208},{\"end\":50439,\"start\":50365},{\"end\":50722,\"start\":50647},{\"end\":50976,\"start\":50914},{\"end\":51460,\"start\":51394}]"}}}, "year": 2023, "month": 12, "day": 17}