{"id": 226374030, "updated": "2023-07-19 16:39:58.842", "metadata": {"title": "An Experimental Study of State-of-the-Art Entity Alignment Approaches", "authors": "[{\"first\":\"Xiang\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Weixin\",\"last\":\"Zeng\",\"middle\":[]},{\"first\":\"Jiuyang\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Wei\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Fabian\",\"last\":\"Suchanek\",\"middle\":[\"M.\"]}]", "venue": "IEEE Transactions on Knowledge and Data Engineering", "journal": "IEEE Transactions on Knowledge and Data Engineering", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "\u2014Entity alignment (EA) finds equivalent entities that are located in different knowledge graphs (KGs), which is an essential step to enhance the quality of KGs, and hence of significance to downstream applications (e.g., question answering and recommendation). Recent years have witnessed a rapid increase of EA approaches, yet the relative performance of them remains unclear, partly due to the incomplete empirical evaluations, as well as the fact that comparisons were carried out under different settings (i.e., datasets, information used as input, etc.). In this paper, we fill in the gap by conducting a comprehensive evaluation and detailed analysis of state-of-the-art EA approaches. We first propose a general EA framework that encompasses all the current methods, and then group existing methods into three major categories. Next, we judiciously evaluate these solutions on a wide range of use cases, based on their effectiveness, efficiency and robustness. Finally, we construct a new EA dataset to mirror the real-life challenges of alignment, which were largely overlooked by existing literature. This study strives to provide a clear picture of the strengths and weaknesses of current EA approaches, so as to inspire quality follow-up research.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3080506591", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tkde/ZhaoZTWS22", "doi": "10.1109/tkde.2020.3018741"}}, "content": {"source": {"pdf_hash": "3266f06aefc20f052d6ee4536f45bfb3aa5afcb4", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://ieeexplore.ieee.org/ielx7/69/4358933/09174835.pdf", "status": "BRONZE"}}, "grobid": {"id": "d869a137b742ff197906b253e07eb52d91ab3bec", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3266f06aefc20f052d6ee4536f45bfb3aa5afcb4.txt", "contents": "\nAn Experimental Study of State-of-the-Art Entity Alignment Approaches An Experimental Study of State-of-the-Art Entity Alignment Approaches\n\n\nXiang Zhao \nWeixin Zeng \nJiuyang Tang \nWei Wang \nFabian Suchanek \nXiang Zhao \nWeixin Zeng \nJiuyang Tang \nWei Wang \nFabian Suchanek \nXiang Zhao \nWeixin Zeng \nJiuyang Tang \nWei Wang \nFabian M Suchanek \nAn Experimental Study of State-of-the-Art Entity Alignment Approaches An Experimental Study of State-of-the-Art Entity Alignment Approaches\n10.1109/TKDE.2020.3018741Submitted on 13 Jan 2021HAL Id: hal-03108522 https://hal-imt.archives-ouvertes.fr/hal-03108522 HAL is a multi-disciplinary open access archive for the deposit and dissemination of sci-entific research documents, whether they are pub-lished or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L'archive ouverte pluridisciplinaire HAL, est destin\u00e9e au d\u00e9p\u00f4t et \u00e0 la diffusion de documents scientifiques de niveau recherche, publi\u00e9s ou non, \u00e9manant des \u00e9tablissements d'enseignement et de recherche fran\u00e7ais ou \u00e9trangers, des laboratoires publics ou priv\u00e9s. To cite this version:\nEntity alignment (EA) finds equivalent entities that are located in different knowledge graphs (KGs), which is an essential step to enhance the quality of KGs, and hence of significance to downstream applications (e.g., question answering and recommendation). Recent years have witnessed a rapid increase of EA approaches, yet the relative performance of them remains unclear, partly due to the incomplete empirical evaluations, as well as the fact that comparisons were carried out under different settings (i.e., datasets, information used as input, etc.). In this paper, we fill in the gap by conducting a comprehensive evaluation and detailed analysis of state-of-the-art EA approaches. We first propose a general EA framework that encompasses all the current methods, and then group existing methods into three major categories. Next, we judiciously evaluate these solutions on a wide range of use cases, based on their effectiveness, efficiency and robustness. Finally, we construct a new EA dataset to mirror the real-life challenges of alignment, which were largely overlooked by existing literature. This study strives to provide a clear picture of the strengths and weaknesses of current EA approaches, so as to inspire quality follow-up research.\n\nINTRODUCTION\n\nRecent years have witnessed the proliferation of knowledge graphs (KGs) and their applications. Typical KGs store world knowledge in the form of triples (i.e., <entity, relation, entity>), where entities refer to unique objects in the real world while relations depict relationships connecting these objects. Using entities as anchors, the triples in a KG are intrinsically interlinked, thus constituting a large graph of knowledge. Currently, we have a large number of general KGs (e.g., DBpedia [1], YAGO [52], Google's Knowledge Vault [14]), and domain-specific KGs (e.g., Medical [48] and Scientific KGs [56]). These KGs have been leveraged to enhance various downstream applications, such as keyword search [64], fact checking [30], question answering [12], [28], etc.\n\nIn practice, a KG is usually constructed from one single data source, and hence, it is unlikely to reach full coverage of the domain [46]. To increase its completeness, a prevalent approach is to integrate knowledge from other KGs, which may contain extra or complementary information. For instance, a general KG may only involve basic information about a scientist, whereas more specifics (e.g., biography and publication lists) can be found in scientific domain KGs. In order to consolidate knowledge among KGs, one pivotal step is to align equivalent entities in different KGs, which is termed entity alignment (EA) [7], [25] 1 .\n\nIn general, current EA approaches mainly tackle the problem by assuming that equivalent entities in different KGs possess similar neighboring structure, and employing representation learning methods to embed entities as data points in a lowdimensional feature space. By performing effective (entity) embedding, pair-wise dissimilarity of entities can be easily evaluated as the distance between data points, in order to determine whether two entities match.\n\nWhile the direction is rapidly progressing (e.g., over twenty papers have been published in the last three years), there is no systematic and comprehensive comparison of these solutions. In 1. In fact, as where we are standing, entity alignment can be deemed as a special case of entity resolution (ER), which recalls a pile of literature (to be discussed in Section 2.2). As some ER methods (with minor adaptation) can be used to handle EA, they are also involved in this experimental study to ensure the comprehensiveness of the comparison. this article, we provide an empirical evaluation of state-of-the-art EA approaches with the following features:\n\n(1) Fair comparison within and across categories. Almost all recent studies [5], [24], [38], [55], [60], [61], [62], [63], [67] are confined to comparing with only a subset of methods. In addition, different approaches follow different settings: some merely use the KG structure for alignment, while others also utilize additional information; some align KGs in one pass, while others employ an iterative (re-)training strategy. Although a direct comparison of these methods, as reported in the literature, demonstrates the overall effectiveness of the solutions, a more preferable and fairer practice would be to group these methods into categories and then compare the results both within and across categories.\n\nIn this study, we include most state-of-the-art methods for lateral comparison, including those very recent efforts that have not yet been compared with others before. By dividing them into three groups and conducting detailed analysis on both intraand inter-group evaluations, we are able to better position these approaches and assess their effectiveness.\n\n(2) Comprehensive evaluation on representative datasets. To evaluate the performance of EA systems, several datasets have been constructed, which can be broadly categorized into cross-lingual benchmarks, represented by DBP15K [53], and mono-lingual benchmarks, represented by DWY100K [54]. A very recent study [24] points out that KGs in previous datasets are much denser than real-life ones, and consequently it creates the SRPRS dataset with entity degrees following normal distribution. Despite of a wide choice of datasets, existing studies merely report their results on one or two specific datasets, making it difficult to assess their effectiveness in a wide range of possible scenarios, e.g., cross-lingual/mono-lingual, dense/normal, and large-scale/medium-scale KGs.\n\nIn response, this study conducts a comprehensive experimental evaluation on all the representative datasets (i.e., DBP15K, DWY100K and SRPRS), which comprise nine KG pairs, and analyzes in depth in terms of effectiveness, efficiency and robustness.\n\n(3) New dataset for real-life challenges. Existing EA datasets contain, for each entity in source KG, exactly one corresponding entity in the target KG. This, however, is an unrealistic scenario.\n\nIn real life, KGs contain entities that other KGs do not contain. For instance, when aligning YAGO 4 and IMDB, only 1% of entities in YAGO 4 are related to movies, while the other 99% of entities in YAGO 4 necessarily have no match in IMDB. These unmatchable entities would increase the difficulty of EA.\n\nBesides, we observe that the KGs in existing datasets use identical naming systems, and the baseline approach that relies on the string similarity between entity names can achieve 100% accuracy on all mono-lingual datasets. Nevertheless, in real-life KGs, an entity is often identified by an incomprehensible id, and associated with one or several human-readable names. Therefore, different entities might share the same name. This obviously poses a problem for EA, as there is no guarantee that an entity with the name \"Paris\" in the source KG is the same as an entity with the name \"Paris\" in the target KG-simply because one might be the city in France and the other one a city in Texas.\n\nWe thus consider that the existing datasets for EA are an oversimplification of the real-life challenges, disregarding the fundamental issues of unmatchable entities and ambiguous entity names. As a remedy, we propose a new dataset that mirrors these difficulties.\n\n\nContributions.\n\nOverall, this article is oriented to both the scientific community and the practitioners. The main contributions of the article are:\n\n\u2022 To the best of our knowledge, this study is amongst the first efforts to systematically and comprehensively evaluate state-of-the-art EA approaches. This is accomplished by: (1) identifying the main components of existing EA approaches and offering a general EA framework; and (2) grouping stateof-the-art approaches into three categories and performing detailed intra-and inter-group evaluations, which better position different EA solutions; and (3) examining these approaches on a broad range of use cases, including cross-/mono-lingual alignment, and alignment on dense/normal, large-/medium-scale data. The empirical results reveal the effectiveness, efficiency and robustness of each solution. \u2022 The experience and insight we gained from the study enable us to discover the shortage of current EA datasets. As a remedy, we construct a new mono-lingual dataset to mirror the real-life challenges of unmatchable entities and ambiguous entity names, which were largely overlooked by current EA literature. We expect this new dataset to serve as a better benchmark for evaluating EA systems.\n\nOrganization. Section 2 formalizes the task of EA, and introduces the scope of this study. Section 3 presents a general EA framework to encompass state-of-the-art EA approaches. The categorization, experimental settings, results and discussions are elaborated in Section 4. Section 5 provides a new dataset and corresponding experiment results, and Section 6 concludes the article.\n\n\nPRELIMINARIES\n\nIn this section, we first formally define the task of EA, then we introduce the scope of this study.\n\n\nTask Definition\n\nA KG G=(E,R,T ) is a directed graph comprising a set of entities E, relations R, and triples T \u2286 E \u00d7R \u00d7E. A triple (h,r,t) \u2208 T represents a head entity h that is connected to a tail entity t via a relation r. Given a source KG G 1 =(E 1 ,R 1 ,T 1 ), a target KG G 2 = (E 2 ,R 2 ,T 2 ), and seed entity pairs (training set), i.e., S = {(u,v) | u \u2208 E 1 ,v \u2208 E 2 ,u \u2194 v}, where \u2194 represents equivalence (i.e., u and v refer to the same real-world object), the task of EA can be defined as discovering the equivalent entity pairs in the test set. Example 1. Figure 1 shows a partial English KG (KG EN ) and a partial Spanish KG (KG ES ) concerning the director Alfonso Cuar\u00f3n. Note that each entity in the KG has a unique identifier. For example, the movie \"Roma\" in the source KG is uniquely identified by Roma(film) 2 . Given the seed entity pair (Mexico, Mexico), EA aims to find the equivalent entity pairs in the test set, e.g., returning Roma(ciudad) in KG ES as the corresponding target entity to the source entity Roma(city) in KG EN .\n\n\nScope and Related Work\n\nWhile the problem of EA was introduced a few years ago, the more generic version of the problem-identifying entity records referring to the same real-world entity from different data sources-has been investigated from various angles by different communities, under the names of entity resolution (ER) [15], [18], [45], entity matching [13], [42], record linkage [8], [34], deduplication [16], instance/ontology matching [20], [35], [49], [50], [51], link discovery [43], [44], entity linking/entity disambiguation [11], [29]. Next, we describe the related work and the scope of this experimental study. Entity linking. The task of Entity Linking (EL) is also known as Entity Disambiguation. It is concerned with identifying entity mentions in natural language text, and mapping them to the entities of a given reference catalogue (a KG in most cases). For example, the goal is to identify the string \"Rome\" in a natural language text as an entity mention, and to find out whether it refers to the capital of Italy or to one of the many movies of that name. Existing approaches [21], [22], [29], [36], [68] exploit rich amount of information, including the words that surround the entity mention, the prior probability of certain target entities, the already disambiguated entity mentions, and background knowledge such as Wikipedia, to disambiguate linking targets.\n\nHowever, most of these information is not available in our KG alignment scenarios (e.g., embeddings of the description of entities, or the prior distribution of entity linking given a mention). Additionally, EL concerns the mapping between natural language text and a KG. Our work, in contrast, studies the mapping of entities between two KGs. Entity resolution. The task of entity resolution (ER), also known as entity matching, deduplication or record linkage, assumes that the input is relational data, and each data object usually has a large amount of textual information described in multiple attributes. Therefore, a number of known similarity or distance functions (e.g., Jaro-Winkler distance for names and numerical distance between dates) are used to quantify the similarity between two objects. Based on that, rule-based or machine learning-based methods are capable of solving the problem of classifying two objects as matching or non-matching [9]. More specifically, for mainstream ER solutions, to match entity records, the attributes are firstly aligned either manually or automatically, then the similarities between corresponding attribute values are computed, and finally the similarity scores between aligned attributes are aggregated to derive the similarities between records [32], [45].\n\nEntity resolution on KGs. Some ER approaches are designed to handle KGs and deal exclusively with binary relationships, i.e., graph-shaped data. These approaches are also frequently referred to as instance/ontology matching methods [49], [50]. The graph-shaped data comes with its own challenges: (1) the textual descriptive information about entities is often less present, or reduced to its bare minimum in the form of an entity name; and (2) KGs operate under the Open World Assumption, in which the attributes of an entity may be absent in the KG although they are present in reality. This distinguishes KGs from classical databases, where all fields of a record are usually assumed to be present; and (3) KGs have additional predefined semantics. In the simplest case, these take the form of a taxonomy of classes. In more complex cases, KGs can be equipped with an ontology of logical axioms.\n\nOver the last two decades, and particularly in the context of the rise of the Semantic Web and the Linked Open Data cloud [26], a number of approaches have been developed specifically for the setting of KGs. These can be classified along several dimensions:\n\n\u2022 Scope. Some approaches align the entities of two KGs, others align the relationship names (also known as the schema), and again other approaches align the class taxonomies of two KGs. Some methods achieve all three tasks at once. In this work, we focus on the first of these tasks, entity alignment. \u2022 Background knowledge. Some approaches use an ontology\n\n(T-box) as background information. This is true in particular for the approaches that participate in the Ontology Alignment Evaluation Initiative (OAEI) 3 . In this work, we concentrate on approaches that can work without such knowledge. \u2022 Training. Some approaches are unsupervised, which work directly on the input data, without any need for training data or indeed a training phase. Examples are PARIS [51] and SiGMa [35]. Other approaches, on the other hand, learn the mappings between the entities based on pre-defined mappings. In this work, we focus on the latter class of approaches. Among the supervised or semi-supervised approaches, most build on the recent advances in deep learning [23]. They mainly rely on graph representation learning technologies to model the KG structure and generate entity embeddings for alignment. We use \"entity alignment (EA) approaches\" as the general reference to them, and they are also the focus of this study. Nevertheless, we include PARIS [51] in our comparison, as a representative system 3. http://oaei.ontologymatching.org/ of the unsupervised approaches. We also include Agreement-MakerLight (AML) [17] as a representative unsupervised system that uses the background knowledge. For the other systems, we refer the reader to other surveys [9], [33], [41], [43].\n\nIn addition, since EA pursues the same goal as ER, it can be deemed a special but non-trivial case of ER. In this light, general ER approaches can be adapted to the problem of EA, and we include representative ER methods for comparison (to be detailed in Section 4).\n\n\nExisting benchmarks.\n\nTo evaluate the effectiveness of EA solutions, several synthetic datasets (e.g., DBP15K and DWY100K) have been constructed by using the existing interlanguage and reference links in DBpedia. More detailed statistics of these datasets can be found in Section 4.2.\n\nNotably, the Ontology Alignment Evaluation Initiative (OAEI) promoted the Knowledge Graph track 4 . In contrast to existing EA benchmarks, where merely instance-level information is provided, KGs in these datasets contain both schema and instance information, which can be unfair for evaluating current EA approaches that do not assume the availability of ontology information. Hence, they are not presented in this article.\n\n\nA GENERAL EA FRAMEWORK\n\nIn this section, we introduce a general EA framework that is conceived to encompass state-of-the-art EA approaches.\n\nBy carefully examining the frameworks of current EA solutions, we identify the following four main components (illustrated in Figure 2): \u2022 Embedding learning module. This component aims to learn embeddings for entities, which can be roughly categorized into two groups: KG representation based models, e.g., TransE [4] and graph neural network (GNN) based models, e.g., the graph convolutional network (GCN) [31].\n\n\u2022 Alignment module. This component aims to map the entity embeddings in different KGs (learned from the previous module) into a unified space. Most methods use the margin-based loss to enforce the seed entity embeddings from different KGs to be close. Another frequently used approach is corpus fusion, which aligns KGs on the corpus-level and directly embeds entities in different KGs into the same vector space.\n\n\u2022 Prediction module. Given the unified embedding space, for each source entity in the test set, the most likely target entity is predicted. Common strategies include using the cosine similarity, the Manhattan distance, or the Euclidean distance between entity embeddings to delegate the distance (similarity) between entities and then selecting the target entity with the lowest distance (highest similarity) as the counterpart.\n\n\u2022 Extra information module. On top of the basic modules, some solutions propose to take advantage of extra information to enhance EA performance. One common practice is the bootstrapping (or self-learning) strategy, which leverages confident alignment results generated by the prediction module as the training data for the subsequent alignment iterations (black dashed lines in Figure 2). Additionally, others propose to take advantage of multi-type literal information, e.g., attributes, entity descriptions and entity names, to complement the KG structure (blue dashed line).\n\n\nExample 2.\n\nFurther to Example 1, we explain these modules. The embedding learning module generates embeddings for entities in KG EN and KG ES , respectively. Then the alignment module projects the entity embeddings into the same vector space, where the entity embeddings in KG EN and KG ES are directly comparable. Finally, using the unified embeddings, the prediction module aims to predict the equivalent target entity in KG ES for each source entity in KG EN . The extra information module leverages several techniques to improve the EA performance. Concretely, the bootstrapping strategy aims to include the confident EA pairs detected from a previous round, e.g., (Spain, Espa\u00f1a), into the training set for learning in the next round. Another approach is to use the literal information, e.g., the comprehensible entity identifiers (shown in Figure 1), to complement the entity embeddings for alignment.\n\nTo provide a module-wise comparison, we organize the stateof-the-art approaches under the introduction to each module (Table 1). In this case, we refer interested readers to Appendix B for a concise but complete view. Next, we introduce how these modules are realized by different state-of-the-art approaches.\n\n\nEmbedding Learning Module\n\nIn this subsection, we introduce in detail the methods used for the embedding learning module, which leverages the KG structure to generate an embedding for each entity.\n\nAs can be observed from Table 1, TransE [4] and GCN [31] are the mainstream models. Here we provide a brief description of these basic models.\n\nTransE. TransE interprets relations as translations operating on the low-dimensional representations of entities. More specifically, given a relational triple (h, r, t), TransE suggests that the embedding of the tail entity t should be close to the embedding of the head entity h plus the embedding of the relationship r, i.e., h+ r \u2248 t. As thus, the structural information of entities can be preserved and the entities that share similar neighbors will have close representations in the embedding space.\n\n\nGCN.\n\nThe graph convolutional network (GCN) is a kind of convolutional networks that directly operates on graphstructured data. It generates node-level embeddings by encoding the information about node neighborhoods. The inputs of the GCN include feature vectors for every node in the KG, and a representative description of the graph structure in matrix form, i.e., an adjacency matrix. The output is a new feature matrix. A GCN model normally comprises multiple stacked GCN layers, hence it can capture a partial KG structure that is several hops away from the entity.\n\nOn top of these basic models, some methods make modifications. Regarding the TransE-based models, MTransE removes the negative triples during training, BootEA and NAEA replace the original margin-based loss function with a limit-based objective function, MuGNN uses the logistic loss to substitute for the margin-based loss, and JAPE designs a new loss function.\n\nAs for the GCN-based models, noticing that the GCN neglects the relations in KGs, RDGCN adopts the dual-primal graph convolutional neural network (DPGCNN) [40] as a remedy. MuGNN, on the other hand, utilizes an attention-based GNN model to assign different weights to different neighboring nodes. KECG combines the graph attention network (GAT) [58] and TransE to capture both the inner-graph structure and the inter-graph alignment information.\n\nThere are also a few approaches that design new embedding models. In RSNs, it is contended that the triple-level learning cannot capture the long-term relational dependencies of entities and is insufficient for the propagation of semantic information among entities. As thus, it uses recurrent neural networks (RNNs) with residual learning to learn the long-term relational paths between entities. In TransEdge, a new energy function to measure the error of edge translation between entity embeddings is devised for learning KG embeddings, in which edge embeddings are modeled by context compression and projection.\n\n\nAlignment Module\n\nIn this subsection, we introduce the methods used for the alignment module, which aims to unify separated KG embeddings.\n\nThe most common strategy is adding a margin-based loss function on top of the embedding learning module. The margin-based loss function requires that the distance between the entities in positive pairs should be small, the distance between the entities in negative pairs should be large, and there should exist a margin between the distances of positive and negative pairs. Here positive pairs denote the seed entity pairs, while the negative pairs are constructed by corrupting the positive pairs. In this way, the two separated KG embedding spaces can be pushed into one vector space. Table 1 shows that, most methods built on GNN adopt such a margin-based alignment model to unify two KG embedding spaces, whereas in GM-Align, the alignment process is achieved by a matching framework that maximizes the matching probabilities of seed entity pairs.\n\nAnother frequently used approach is corpus fusion, which utilizes the seed entity pairs to bridge the training corpora of two KGs. Given the triples of two KGs, some methods, e.g., BootEA and NAEA, swap the entities in the seed entity pairs and generate new triples to calibrate the embeddings into a unified space. Other approaches treat the entities in seed entity pairs as the same entity and build an overlay graph connecting two KGs, which is then used for learning entity embeddings.\n\nSome early studies design transition functions to map the embedding vectors in one KG to another, while some use additional information, e.g., the attributes of entities, to shift the entity embeddings into the same vector space.\n\n\nPrediction Module\n\nGiven the unified embedding space, this module aims to determine the most likely target entity for each source entity.\n\nThe most common approach is returning a ranked list of target entities for each source entity according to a specific distance measure between the entity embeddings, among which the top ranked entity is regarded as the match. Frequently used distance measures include the Euclidean distance, the Manhattan distance and the cosine similarity. Note that the similarity score between entities can be easily converted to the distance score  by subtracting the similarity score from 1, and vice versa 5 . In GM-Align, the target entity with the highest matching probability is aligned to the source entity. Besides, a very recent approach, CEA, points out that there is often an additional interdependence between different EA decisions, i.e., a target entity is less likely to be matched to a source entity if it is aligned to another source entity with higher confidence. To model such a collective signal, it formulates this process as a stable matching problem built upon the distance measure, which reduces mismatches and leads to higher accuracy.\n\n\nMethod Embedding Model Alignment Model Extra information Prediction C-L M-L Group\n\n\nExtra Information Module\n\nAlthough the embedding learning, alignment and prediction modules can already constitute a basic EA framework, there is still room for improvement. In this subsection, we introduce the methods used in the extra information module.\n\nA common method is the bootstrapping strategy (also frequently called the iterative training or self-learning strategy), which iteratively labels likely EA pairs as the training set for the next round and thus progressively improves the alignment results. Several methods have been devised, and the main difference lies in the selection of confident EA pairs. ITransE adopts a threshold-based strategy, while BootEA, NAEA and TransEdge formulate the selection as a maximum likelihood matching process under a 1-to-1 mapping constraint.\n\nSome methods use multi-type literal information to provide a more comprehensive view for alignment. The attributes associated with entities are frequently used. While some merely use the statistical characteristics of the attribute names (e.g., JAPE, GCN-Align and HMAN), the other methods generate attribute embeddings by encoding the characters of attribute values (e.g., AttrE and MultiKE).\n\nThere is a growing tendency towards the use of entity names. GM-Align, RDGCN and HGCN use entity names as the input features for learning entity embeddings, while CEA exploits the semantic and string-level aspects of entity names as individual features. 5. In this work, we use the distance between entity embeddings and the similarity between entity embeddings interchangeably.\n\nBesides, KDCoE and the description-enhanced version of HMAN encode entity descriptions into vector representations, which are considered as new features for alignment.\n\nIt is worth noting that multi-type information is not always available. Besides, since EA underlines the use of graph structure for alignment, the majority of existing EA datasets contain very limited textual information, which restrains the applicability of some approaches such as KDCoE, MultiKE and AttrE.\n\n\nEXPERIMENTS AND ANALYSIS\n\nThis section presents an in-depth empirical study 6 .\n\n\nCategorization\n\nAccording to the main components, we can broadly categorize current methods into three groups: Group I, which merely utilizes the KG structure for alignment, Group II, which harnesses the iterative training strategy to improve alignment results, and Group III, which utilizes information in addition to the KG structure. We introduce and compare these three categories using Example 1.\n\nGroup I. This category of methods merely harnesses the KG structure for aligning entities. Consider again Example 1. In KG EN , the entity Alfonso is connected to the entity Mexico and three other entities, while Spain is connected to Mexico and one more entity. The same structural information can be observed in KG ES . Since we already know that Mexico in KG EN is aligned to Mexico in KG ES , by using the KG structure, it is easy to conclude that the equivalent target entity for Spain is Espa\u00f1a, and the equivalent target entity for Alfonso is Alfonso.\n\nGroup II. Approaches in this category iteratively label likely EA pairs as the training set for the next round and progressively improve alignment results. They can also be categorized into Group I or III, depending on whether they merely use the KG structure or not. Nevertheless, they are all characterized by the use of the bootstrapping strategy. 6. A link will be provided, and all datasets and program sources will be made available on a Github page.\n\nWe still use Example 1 to illustrate the bootstrapping mechanism. As depicted in Figure 1, using the KG structure, it is easy to discover that the source entity Spain corresponds to the target entity Espa\u00f1a, and Alfonso to Alfonso. Nevertheless, for the source entity Madrid, its target entity remains unclear, since the target entities Roma(ciudad) and Madrid both have the same structural information with the source entity Madridtwo hops away from the seed entity and with degree 1. To resolve this issue, bootstrapping-based methods conduct several rounds of alignment, where the confident pairs detected from the previous round are regarded as seed entity pairs for the next round. More specifically, they consider the entity pairs detected from the first round, i.e., (Spain, Espa\u00f1a) and (Alfonso, Alfonso), as the seed pairs in the following rounds. Consequently, in the second round, for the source entity Madrid, only the target entity Madrid shares the same structural information with it-two hops away from the seed entity pair (Mexico, Mexico) and one hop away from the seed entity pair (Spain, Espa\u00f1a).\n\n\nGroup III.\n\nAlthough it is intuitive to leverage the KG structure for alignment given graph-formatted input data sources, KGs also contain rich semantics, which can be used to complement structural information. Methods in this category distinguish themselves by the use of information in addition to the KG structure.\n\nReferring to Example 1, after using the KG structure and even the bootstrapping strategy, it is still difficult to determine the target entity for the source entity Gravity(film), as its structural information (connected to the entity Alfonso and with degree 2) is shared by two target entities Gravity(pel\u00edcula) and Roma(pel\u00edcula). In this case, using entity name information to complement the KG structure can easily distinguish these two entities and return Gravity(pel\u00edcula) as the target entity for the source entity Gravity(film).\n\n\nExperiment Settings\n\n\nDatasets.\n\nWe adopt three frequently utilized and representative datasets, including nine KG pairs, for evaluation:\n\nDBP15K [53]. This dataset consists of three multilingual KG pairs extracted from DBpedia: English to Chinese (DBP15K ZH-EN ), English to Japanese (DBP15K JA-EN ) and English to French (DBP15K FR-EN ). Each KG pair contains 15 thousand inter-language links as gold standards.\n\nDWY100K [54]. This dataset comprises two mono-lingual KG pairs, DWY100K DBP-WD and DWY100K DBP-YG , which are extracted from DBpedia, Wikidata and YAGO 3. Each KG pair contains 100,000 entity pairs. The extraction process follows DBP15K, whereas the inter-language links are replaced with the reference links connecting these KGs.\n\nSRPRS. Guo et al. [24] point out that KGs in previous EA datasets, e.g., DBP15K and DWY100K, are too dense and the degree distributions deviate from real-life KGs. Therefore, they establish a new EA benchmark that follows real-life distribution by using the reference links in DBpedia. A summary of the datasets can be found in Table 2. In each KG pair, there are relational triples, cross-KG entity pairs (gold standards, in which 30% are seed entity pairs and used for training), and attribute triples. Degree distribution. To gain insight into the datasets, we show the degree distributions of entities in these datasets in Figure 3. The degree of an entity is defined as the number of triples an entity is involved in. Higher degree implies richer neighboring structure. In each dataset, since the degree distributions of different KG pairs are very similar, we merely present the distribution of one KG pair in Figure 3 in the interest of space. The (a) series of sub-figures corresponds to DBP15K. It is evident that the entities with degree of 1 account for the largest share, and with the increase of degree values, the number of entities fluctuates while it generally exhibits a downward trend. Noteworthily, the curve of the coverage approximates a straight line, as the number of entities changes subtly when the degree increases from 2 to 10.\n\nThe (b) series of sub-figures corresponds to DWY100K. The structure of the KGs in this dataset is very different from (a), as there are no entities with degree of 1 or 2. Besides, the number of entities peaks at degree of 4, and drops consistently when the entity degree increases.\n\nThe (c) series of sub-figures corresponds to SRPRS. Evidently, the degree distribution of entities in this dataset is more realistic, where the entities with lower degrees account for higher percentages. This can be attributed to its carefully designed sampling strategy. Note that the (d) series of sub-figures corresponds to our constructed dataset, which will be introduced in Section 5.\n\nEvaluation metrics. Following existing EA solutions, we utilize Hits@k (k=1, 10) and mean reciprocal rank (MRR) as the evaluation metrics. At the prediction stage, for each source entity, the target entities are ranked according to their distance scores with the source entity in an ascending order. Hits@k reflects the percentage of correctly aligned entities in the top-k closest target entities. In particular, Hits@1 represents the accuracy of alignment results, which is the most important indicator.\n\nMRR denotes the average of the reciprocal ranks of the ground truths. Note that higher Hits@k and MRR indicate better performance. Unless otherwise specified, the results of Hits@k are represented in percentages.\n\nMethods to compare. We include aforementioned methods for comparison, except for KDCoE and MultiKE, since the evaluation benchmarks do not contain entity descriptions. We also exclude AttrE as it only works under the mono-lingual setting. Additionally, we report the results of the structure-only variants of JAPE and GCN-Align, i.e., JAPE-Stru and GCN.\n\nAs mentioned in Section 2.2, in order to demonstrate the capability of ER approaches for coping with EA, we also compare with several name-based heuristics, as the typical approaches of these relevant tasks [13], [42], [47] heavily rely on the similarity between object names to discover the equivalence. Concretely, we use: (1) Lev, which aligns entities using Levenshtein distance [37], a string metric for measuring the difference between two sequences; and (2) Embed, which aligns entities according to the cosine similarity between the name embeddings (averaged word embedding) of two entities. Following [65], we use the pre-trained fastText embeddings [2] as word embeddings, and for multilingual KG pairs, we use the MUSE word embeddings [10]. Implementation details. The experiments are conducted on a personal computer with an Intel Core i7-4790 CPU, an NVIDIA GeForce GTX TITAN X GPU and 128 GB memory. The programs are all implemented in Python.\n\nWe directly use the source codes provided by the authors for reproduction, and the results are obtained by executing the models using the set of parameters reported in their original papers 7 . We use the same set of parameters on the datasets that are not included in the original papers.\n\nOn the DBP15K dataset, all of the evaluated methods provide results in their original papers, except for MTransE and ITransE. We compare our implemented results with their reported results. If the difference falls out of a reasonable range, i.e., \u00b15% of the original results, we mark the methods with * . Note that theoretically there should not be a huge difference, since we use the same source codes and the same parameters for implementation. On SRPRS, only RSNs reports the results in its original paper [24]. We run all methods on SRPRS and provide the results in Table 4. On DWY100K, we run all approaches, and compare the performance of BootEA, MuGNN, NAEA, KECG and TransEdge with the results provided in their original papers. Methods with notable differences are marked with * . 7. In the interest of space, we put the detailed parameter settings in the appendix.\n\nOn each dataset, the best results within each group are denoted in bold. We mark the best Hits@1 performance among all approaches with , as this metric can best reflect the effectiveness of EA methods.\n\n\nResults and Analyses on DBP15K\n\nThe experiment results on the cross-lingual dataset DBP15K are reported in Table 3. The Hits@10 and MRR results of CEA are missing as it directly generates aligned entity pairs instead of returning a list of ranked entities 8 . We then compare the performance within each category and across categories.\n\n\nGroup I.\n\nAmong the approaches merely using the KG structure, RSNs consistently achieves the best results in terms of both Hits@1 and MRR, which can be ascribed to the fact that the long-term relational paths it captures provide more structural signals for alignment. The results of MuGNN and KECG are equally matched, partially due to their shared objective of completing KGs and reconciling the structural differences. While MuGNN utilizes AMIE+ [19] to induce rules for completion, KECG harnesses TransE to implicitly achieve this aim.\n\nThe other three approaches attain relatively inferior results. Both MTransE and JAPE-Stru adopt TransE for capturing the KG structure, while JAPE-Stru outperforms MTransE, as MTransE models the structure of KGs in different vector spaces, and the information loss happens when translating between vector spaces [53]. GCN obtains relatively better results than MTransE and JAPE-Stru.\n\nGroup II. Within this category, ITransE attains much worse results than other methods, which can be attributed to the information loss during the translation between embedding spaces and its simpler bootstrapping strategy (detailed in Section 3.4). BootEA, NAEA and TransEdge utilize the same bootstrapping strategy. The performance of BootEA is slightly inferior to the reported results, while the results of NAEA are much worse. Theoretically, NAEA should achieve better performance than BootEA as it leverages an attentional mechanism to obtain neighbor-level information. TransEdge employs an edge-centric embedding model to capture structural information, which generates more precise entity embeddings and hence better alignment results.\n\nGroup III. Both JAPE and GCN-Align harness the attributes to complement entity embeddings, and their results exceed 8. The Hits@10 and MRR results of CEA are also missing in Table 4 and Table 5 because of the same reason. the results of their structure-only counterparts, validating the usefulness of the attribute information. Also utilizing the attributes, HMAN outperforms JAPE and GCN-Align, since it also considers relation types as the model input.\n\nThe other four methods exploit entity name information, instead of attributes, for alignment, and achieve better results. Among them, the results of RDGCN and HGCN are close, surpassing GM-Align. This is partially because they employ relations to optimize the learning of entity embeddings, which was largely neglected in previous GNN-based EA models. CEA attains the best performance in this group, as it effectively exploits and fuses available features.\n\nName-based heuristics. On KG pairs with closely-related languages, Lev attains promising results, whereas it fails to work on distantly-related language pairs, i.e., DBP15K ZH-EN and DBP15K JA-EN . As for Embed, it achieves consistent performance on all KG pairs. Intra-category comparison. CEA achieves the best Hits@1 performance on all datasets. As for other metrics, TransEdge, RDGCN and HGCN attain the leading results. This verifies the effectiveness of using extra information, i.e., the bootstrapping strategy and textual information.\n\nThe performance of the name-based heuristics (i.e., Embed) is very competitive, exceeding most of the methods that do not use entity name information in terms of Hits@1. This demonstrates that typical ER solutions can still work on the task of EA. Nevertheless, Embed is still inferior to most EA methods that incorporate the entity name information, i.e., RDGCN, HGCN and CEA.\n\nIt can also be observed that, methods from the first two groups, e.g., TransEdge, attain consistent results across all three KG pairs, while the solutions utilizing the entity name information, e.g., HGCN, achieve much better results on the KG pairs with closely-related languages (FR-EN) than those with distantly-related languages (ZH-EN). This reveals that the language barriers can hamper the use of textual information and in turn hurt the overall effectiveness.\n\n\nResults and Analyses on SRPRS\n\nThe results on SRPRS are reported in Table 4. There are some observations similar to DBP15K, which we will not elaborate. We focus on the differences from DBP15K, as well as the patterns specific to this dataset.\n\nGroup I. It is evident that the overall performance on SRPRS is lower than that on DBP15K, which indicates that these methods might not perform well on relatively sparse KGs. RSNs still outperforms the other approaches, which is closely followed by KECG. Notably, in contrast to the decent results on DBP15K, MuGNN attains much worse results on SRPRS, as there are no aligned relations on SRPRS, where the rule transferring fails to work. Also, the number of detected rules is much smaller, due to the sparser KG structure.\n\n\nGroup II.\n\nAmong these solutions, TransEdge still yields consistently superior results.\n\nGroup III. Compared with GCN and JAPE-Stru, incorporating the attributes leads to better results for GCN-Align, while it does not contribute to the performance of JAPE. This is because the number of attributes is relatively smaller in this dataset. In comparison, using entity names enhances the results to a much higher level. Note that CEA attains ground-truth performance on SRPRS DBP-WD and SRPRS DBP-YG .\n\nName-based heuristics. Lev and Embed achieve ground-truth performance on all mono-lingual EA datasets, since the names in the entity identifiers of DBpedia, Wikidata and YAGO are identical. Lev also achieves promising results on cross-lingual KG pairs with closely-related language pairs. Intra-category comparison. Different from DBP15K, methods that incorporate entity names (Group III) dominate on SRPRS. This is because: (1) the KG structure is less effective on this dataset (much sparser compared with DBP15K); and (2) the entity name information plays a very significant role on cross-lingual datasets with closely-related language pairs and mono-lingual datasets, where the names of equivalent entities are very similar.\n\n\nResults and Analyses on DWY100K\n\nThe results on the large-scale mono-lingual dataset, DWY100K, are reported in Table 5. We fail to obtain the results of RDGCN and NAEA under our experimental environment, as they require extremely large amount of memory space.\n\nMethods in the first group achieve more promising results on this dataset, which can be ascribed to the relatively richer KG structure (shown in Figure 3). Among them, MuGNN and KECG attain over 60% on DWY100K DBP-WD and 70% on DWY100K DBP-YG in terms of Hits@1, as the rich structure facilitates the process of KG completion, which in turn enhances the overall EA performance.\n\nWith the aid of the iterative training strategy, approaches in the second group further improve the results, whereas the results of BootEA and TransEdge are slightly lower than their reported values. As for methods in Group III, CEA achieves the ground-truth performance. Similarly, the name-based heuristics Lev and Embed also attain ground-truth results.\n\n\nEfficiency Analysis\n\nFor the comprehensiveness of the evaluation, we report the averaged running time on each dataset in Table 6 to compare the efficiency of state-of-the-art solutions, which can also reflect their scalability. We are aware that different parameter settings, e.g., the learning rate and the number of epochs, might influence the eventual time cost. However, here we merely aim to provide a general picture of the efficiency of these methods by adopting the parameters reported in their original papers. Again, we fail to obtain the results of RDGCN and NAEA on DWY100K under our experimental environment, as they require extremely large amount of memory space.\n\nOn DBP15K and SRPRS, GCN is the most efficient method with consistent alignment performance, which is closely followed by JAPE-Stru and ITransE. For the other methods, most of them have the same magnitude of time costs (1,000-10,000s), except for NAEA and GM-Align, which require extremely higher running time.\n\nOn the much larger dataset DWY100K, the time costs of all solutions climb dramatically, due to the larger number of parameters and higher computational costs. Among others, MuGNN, KECG, HMAN cannot work by using the GPU because of the memory limitation, and we report the time cost by using the CPU as suggested by the authors of these approaches. It is noted that merely three methods can finish the alignment process within 10,000s, and the time costs for most approaches fall between 10,000s and 100,000s. GM-Align even requires 5 days to generate the results. This unveils that state-of-the-art EA methods still have low efficiency when dealing with data at very large scale. Some of them, such as NAEA, RDGCN, and GM-Align, have rather poor scalability.\n\n\nComparison with Unsupervised Approaches\n\nAs mentioned in Section 2.2, there are many unsupervised approaches designed for the alignment between KGs, which do not utilize representation learning techniques. For the comprehensiveness of the study, we compare with a representative system, PARIS [51]. Built on the similarity comparison between literals, PARIS uses a probabilistic algorithm to jointly align entities in an unsupervised manner. Besides, we also compare with Agree-mentMakerLight (AML) [17], an unsupervised ontology alignment system that leverages the background knowledge of KGs 9 .\n\nWe use the F1 score as the evaluation metric, since PARIS and AML do not output a target entity for every source entity so as to deal with entities that do not have a match in the other KG. The F1 score is the harmonic mean between precision (i.e., the number of correctly aligned entity pairs divided by the number of source entities for which an approach returns a target entity) and recall (i.e., the number of source entities for which an approach returns a target entity divided by the total number of source entities).\n\nAs depicted in Figure 4, the overall performance of PARIS and AML are slightly inferior to CEA. However, although CEA has more robust performance, it relies on the training data (seed entity pairs), which might not exist in the real-world KGs. In contrast, unsupervised systems work without requiring any training data, and can still output very promising results. Besides, by comparing the results of PARIS and AML, it shows that the ontology information indeed can improve the alignment results. 9. AML requires ontology information, which does not exist in current EA datasets. Therefore, we mine the ontology information for these KGs. However, we can only successfully run AML on SRPRSEN-FR and SRPRSEN-DE.  \n\n\nModule-level Evaluation\n\nIn order to gain insight into the methods used in different modules, we conduct the module-level evaluation and report corresponding experiment results. Specifically, we choose the representative methods from each module, and generate possible combinations. By comparing the performance of different combinations, we can get a clearer view of the effectiveness of different methods in these modules.\n\nRegarding the embedding learning module, we use GCN and TransE. As for the alignment module, we adopt the marginbased loss function (Mgn) and the corpus fusion strategy (Cps). Following current approaches, we combine GCN with Mgn, and TransE with Cps, where the parameters are tuned in accordance to GCN-Align and JAPE, respectively. In the prediction module, we use the Euclidean distance (Euc), the Manhattan distance (Manh) and the cosine similarity (Cos). With regard to the extra information module, we denote the use of the bootstrapping strategy as B by implementing the iterative method in ITransE. The use of multi-type information is represented as Mul, and we adopt the semantic and string-level features of entity names as in CEA. The Hits@1 results of 24 combinations are shown in Table 7 10 . It can be observed that, adding the bootstrapping strategy and/or textual information indeed enhances the overall performance. Regarding the embedding model, the GCN+Mgn model appears to have more robust and superior performance than TransE+Cps. Besides, the distance measures also have influence on the results. Compared with Manh and Euc, Cos leads to better performance on TransE-based models, while it brings worse results on GCN-based models. Nevertheless, after incorporating entity name embeddings, using Cos leads to consistently better performance.\n\nNotably, GCN+Mgn+Cos+Mul+B (referred as CombEA) achieves the best performance, showcasing that a simple combination of the methods in existing modules can lead to promising alignment performance.\n\n\nSummary\n\nBased on the experimental results, we provide the following summaries. Nevertheless, solely relying on the KG structure has its limitations, since there exist long-tail entities that possess very limited structural information, or entities that have similar neighboring entities but do not refer to the same real-world object. As a remedy, some recent studies propose to incorporate textual information, and hence achieve better performance. This, however, raises a question about whether ER approaches can handle EA task, since the texts associated with entities are frequently used by typical ER solutions. We answer this question by involving the name-based heuristics that have been used in most typical ER methods for comparison, and the experimental results reveal that: (1) ER solutions can work on EA, whereas the performance heavily depends on the textual similarity between entities; and (2) although ER solutions can outperform most structure-based EA approaches, they are still outperformed by EA methods that use the name information to complement entity embeddings; and (3) incorporating the main ideas in ER, i.e., relying on the literal similarity to discover the equivalence between entities, into EA methods, is a promising direction worthy of exploration (as demonstrated by CEA). Figure 5, the performance of EA solutions varies greatly on different datasets. Generally, EA methods achieve relatively better results on dense datasets, i.e., on DBP15K and DWY100K. Besides, the results on mono-lingual KGs are better than those on cross-lingual ones (DWY100K vs. DBP15K). Particularly, on mono-lingual datasets, the most performant method CEA, as well as the name-based heuristics Lev and Embed, attain 100% accuracy. This is because these datasets are extracted from DBpedia, Wikidata and YAGO, and the equivalent entities in these KGs possess identical names in the entity identifiers. However, these datasets fail to mirror the real-life challenge of ambiguous entity names. To fill in this gap, we construct a new mono-lingual benchmark, which is to be detailed in Section 5. \n\n\nInfluence of datasets. As shown in\n\n\nGuidelines and Suggestions\n\nIn this section, we provide guidelines and suggestions for potential users of EA approaches.\n\n\nGuidelines for practitioners.\n\nThere are many factors that might influence the choice of EA models. We select four most common factors and give the following suggestions:\n\n\u2022 Input information. If the inputs only contain KG structure information, one might have to choose from the methods in Groups I and II. Conversely, if there exist abundant side information, one might want to use methods from Group III to take full advantage of these features and provide more reliable signals for alignment. \u2022 The scale of data. As mentioned in Section 4.6, some stateof-the-art methods have rather poor scalability. Therefore, the scale of data should be taken into consideration before making alignment decisions. For data of very large scale, one could use some simple but efficient models such as GCN-Align to reduce the computational overhead. \u2022 The objective of alignment. If one only focuses on the alignment of entities, one might want to adopt GNN based models since they are usually more robust and scalable. Nevertheless, if there are additional tasks such as alignment of relations, one might want to use the KG representation based methods since they intrinsically learn both entity and relation representations. Besides, several recent studies [55], [60] demonstrate that the relations can help the alignment of entities. \u2022 The trade-off in bootstrapping. The bootstrapping process is effective, as it can progressively augment the training set and lead to increasingly better alignment results. Nevertheless, it suffers from the error propagation problem, which might introduce wrongly-matched entity pairs and amplify their negative effect on the alignment in the following rounds. Also, it can be time-consuming. Consequently, when deciding whether to use the bootstrapping strategy, one could estimate the difficulty of the datasets. If the datasets are relatively easy, e.g., with rich literal information and dense KG structures, exploiting the bootstrapping strategy might be a better choice. Otherwise, one should be careful when using such a strategy.\n\nSuggestions for future research. We also discuss some open problems that are worthy of exploration in the future:\n\n\u2022 EA for long-tail entities. In real-life KGs, only a few entities are densely connected to others, and the rest majority possess rather sparse neighborhood structure. The alignment of these long-tail entities is vital to the overall alignment performance, which, however, was largely neglected by current EA literature. A very recent study [66] leverages the side information to complement structural information for aligning entities in tail. It also proposes to reduce long-tail entities through augmenting relational structure via KG completion embedded into an iterative self-training process. Nevertheless, there is still much room for further improvement. \u2022 Multi-modal EA. An entity could be associated with information in multiple modalities, such as texts, images, and even videos. To align such entities, the task of multimodal entity alignment is worth further investigation [39]. \u2022 EA in the open world. Current EA solutions work under the closed-domain setting [27]; that is, they assume every entity in the source KG has an equivalent entity in the target KG. Nevertheless, in practical settings, there always exist unmatchable entities. Besides, the labeled data, which are required by the majority of state-of-the-art approaches, might be unavailable. Therefore, it is of significance to explore EA in the open-world settings.\n\n\nNEW DATASET AND FURTHER EXPERIMENTS\n\nAs highlighted in Section 4, in existing mono-lingual datasets, the names in the identifiers of equivalent entities from different KGs are identical. This means that a simple comparison of these names can achieve reasonably accurate results (100% precision on SRPRS DBP-YG ). In real-life KGs, however, entity identifiers are often not human-readable. For example, Freebase identifies Paris (the capital of France) by /m/05qtj. Wikidata has a similar policy. These identifiers are then linked to one or several human-readable names. For example, /m/05qtj is linked to \"Paris\", \"The City of Light\", etc. As it so happens, just retrieving these names from the KGs, and matching entities that share a name, still achieves a precision of 100% on datasets such as DWY100K DBP-WD and SRPRS DBP-WD . In real-life KGs, however, this method will not work. The reason is that different entities (with different identifiers) can have the same name. For example, both the Freebase entity /m/05qtj (the capital of France) and /m/0h0_x (the king of Troy) share the name \"Paris\" -as do 20 cities in the U.S. that are called \"Paris\". This obviously poses a problem for EA, as there is no guarantee that an entity with the name \"Paris\" in the source KG is the same as an entity with the name \"Paris\" in the target KG -simply because one might be the city in France and the other one the king of Troy. This is an important complication in real-life KGs: For example, in YAGO 3, 34% of entities have a name that is shared by more than one entity. This problem is insufficiently mirrored in the mono-lingual datasets that are commonly used for EA. There is a second problem with the EA datasets: They contain, for each entity in the source KG, exactly one corresponding entity in the target KG. Thus, an EA approach can just map every entity in the source KG to the most similar entity in the target KG. This, however, is an unrealistic scenario. In real life, KGs contain entities that other KGs do not contain. For example, when one tries to align YAGO 3 and DBpedia, one will encounter entities that appear in YAGO 3, and not in DBpedia, and vice versa. The problem is even more pronounced for KGs that feed from different sources, such as, say, YAGO 4 and IMDB. Only 1% of entities in YAGO 4 are movies or entities related to movies (such as actors). The other 99% of entities in YAGO 4 (such as universities, smartphone brands, etc.) necessarily have no match in IMDB. This problem is not considered at all in current EA datasets.\n\nWe thus observe that the existing datasets for EA are an oversimplification of the real-life problem, disregarding the fundamental issues of ambiguity and unmatchable entities. As a remedy, we propose a new dataset that mirrors these difficulties. We expect this dataset to lead to better EA models that can deal with more challenging problem instances, and to offer a better direction for the research community. This section introduces the construction of the new dataset and our experimental results on it.\n\n\nDataset Construction\n\nTo reflect the difficulty of using entity names, we adopt Freebase [3] as the target KG, since it represents entities with incomprehensible identifiers (i.e., Freebase mids), and different entities might share the same name. DBpedia is used as the source KG, as it contains external links to Freebase, which can be directly utilized as gold standards. The specific construction process is elaborated as follows:\n\nDetermining the source entity set. We take advantage of the disambiguation records in DBpedia and collect the entities that share the same disambiguation term to constitute the entity set of the source KG. For instance, regarding the ambiguous term Apple, the disambiguation records involve entities such as Apple Inc. and Apple(fruit), and these entities are included in the source entity set.\n\nDetermining links and the target entity set. Then we use the external links between DBpedia and Freebase to retrieve the entities in Freebase that correspond to source entities, which constitute the entity set of the target KG. These external links are regarded as gold standards. Note that the entities in the target KG are identified by mids, and multiple entities might share the same name, e.g., Apple.\n\nRetrieving triples. After determining the entity sets in the source and target KGs, we mine from the respective KGs the relational and attributive triples that involve these entities.\n\nRefining links and entity sets. Following previous work [53], [54], we keep the links whose source and target entities are involved in at least one triple in respective KGs, which reduces the amount of links to 25,542. The entity sets are adjusted correspondingly, in which the entities that participate in triples but not in links are also included. Eventually, there are 29,861 entities in the source KG, among which 4,319 are unmatchable, and 25,542 matchable entities in the target KG. Following existing datasets, 30% of the links and unmatchable entities are used as training set. Other statistics of the dataset are shown in Table 2.\n\n\nExperiment Results on DBP-FB\n\nFollowing the current evaluation paradigm, we first discuss EA performance without the unmatchable entities. Table 5 reveals that, the overall performance of the methods in the first two groups is worse than that on SRPRS, which can be attributed to the higher structural heterogeneity of DBP-FB. This can also be observed from sub-figures (d) in Figure 3-unlike KG pairs in (a), (b) or (c), the entity distributions in these KGs are very different, which poses difficulty to the utilization of structural information.\n\nMethods harnessing entity names still yield the best results, whereas the performance all drops compared with the results on previous mono-lingual datasets. Additionally, on DBP-FB, Embed and Lev merely achieve the Hits@1 values at 58.3% and 57.8%, respectively, while these figures for SRPRS DBP-YG , SRPRS DBP-WD , DWY100K DBP-YG and DWY100K DBP-WD are all 100%. This validates that DBP-FB can better reflect the challenge of entity name ambiguity compared with existing ones. Therefore, DBP-FB can be considered as a more preferable mono-lingual dataset.\n\n\nUnmatchable Entities\n\nDBP-FB also includes the unmatchable entities, which is another a real-life challenge for EA. We take into consideration these unmatchable entities and report the performance of CombEA (from Section 4.8) on DBP-FB. Following Section 4.7, we adopt the precision, recall and F1 score as the evaluation metrics, except that, we define the recall as the number of matchable source entities for which an approach returns a target entity, divided by the total number of matchable source entities.  Table 8 reveals that, CombEA has very high recall, but relatively low precision, as it generates a target entity for each source entity (including the unmatchable ones). This also reflects how current EA solutions perform when there are source entities that cannot be aligned. However, this issue is neglected by existing EA datasets.\n\nTo mitigate this issue, on top of the current EA solutions, we propose an intuitive strategy to handle the unmatchable entities in DBP-FB. Specifically, we set a NIL threshold \u03b8 to predict the unmatchable entity. As introduced in Section 3.3, EA solutions normally use a specific distance measure to retrieve the target entity. If the distance value between a source entity and its closest target entity is above \u03b8, we consider the source entity to be unmatchable and do not generate the alignment result for it. The threshold value \u03b8 can be learned from the training data.\n\nAs shown in Table 8, the threshold-enhanced solution CombEA +TH achieves a better F1 score. We hope this preliminary study can inspire follow-up research on this issue.\n\n\nCONCLUSION\n\nEA is a pivotal step for integrating KGs to increase knowledge coverage and quality. Although many solutions have been proposed, there has not been a comprehensive assessment and detailed analysis of their performance. To fill in the gap, this article reports an empirical evaluation of state-of-the-art EA approaches in terms of both effectiveness and efficiency on representative datasets, analyzes their performance in depth, and provides evidence-based discussions. Moreover, we establish a new dataset that better reflects the real-life challenges for future research.\n\nFig. 2 .\n2A general EA framework.\n\n\nThe final evaluation benchmark consists of cross-lingual (SRPRS EN-FR , SRPRS EN-DE ) and mono-lingual KG pairs (SRPRS DBP-WD , SRPRS DBP-YG ), where EN, FR, DE, DBP, WD, and YG represent DBpedia (English), DBpedia (French), DBpedia (German), DBpedia, Wikidata and YAGO 3, respectively. Each KG pair contains 15,000 entity pairs.\n\nFig. 3 .\n3Degree distributions on different datasets. The X-axis denotes entity degree. The left Y-axis represents the number of entities (corresponding to bars), while the right Y-axis represents the percentage of entities with a degree lower than a given x value (corresponding to lines).\n\nFig. 4 .\n4F1 scores of PARIS, AML and CEA on EA datasets.\n\nFig. 5 .\n5The box plot of Hits@1 of all methods on different datasets.\n\n\nFig. 1. An example of EA. Relation identifiers and other entities are omitted for clarity; seed entity pairs are connected by dashed lines.KG EN \nKG ES \n\n[Roma(city)] \n\n[Alfonso] \n\n[Madrid] \n\n[Roma(film)] \n\n[Spain] \n\n[Mexico] \n\n[Roma(pel\u00ed cula)] \n\n[Espa\u00f1a] \n\n[Roma(ciudad)] \n\n[Madrid] \n\n[Alfonso] \n\n[Mexico] \n\n[Gravity(film)] \n[Gravity(pel\u00ed cula)] \n\n\n\nTABLE 1 A\n1summary of the EA approaches involved in this study.\n\n\nC-L stands for Cross-lingual Evaluation, M-L stands for Mono-lingual Evaluation.2 TransE represents variants of the TransE model.MTransE [7] \nTransE \nTransition \n\nEuclidean distance \n\n\nI \nRSNs [24] \nRSNs \nCorpus fusion \n\nCosine similarity \n\n\nI \nMuGNN [5] \nGNN \nMargin-based \n\nCosine similarity \n\n\nI \nKECG [38] \nGAT+TransE \nMargin-based \n\nEuclidean distance \n\n\nI \n\nITransE [69] \nTransE \nTransition \nBootstrapping \nEuclidean distance \n\n\nII \nBootEA [54] \nTransE \nCorpus fusion \nBootstrapping \nCosine similarity \n\n\nII \nNAEA [70] \nTransE \nCorpus fusion \nBootstrapping \nCosine similarity \n\n\nII \nTransEdge [55] TransEdge \nCorpus fusion \nBootstrapping \nCosine similarity \n\n\nII \n\nJAPE [53] \nTransE \nAttribute-refined \nAttribute \nCosine similarity \n\n\nIII \nGCN-Align [59] GCN \nMargin-based \nAttribute \nManhattan distance \n\n\nIII \nAttrE [57] \nTransE \nAttribute-refined \nAttribute \nCosine similarity \n\n\nIII \nKDCoE [6] \nTransE \nTransition \nEntity description \nEuclidean distance \n\n\nIII \nHMAN [63] \nGCN \nMargin-based \nDescription, Attribute \nEuclidean distance \n\n\nIII \nGM-Align [62] \nGCN \nGraph matching \nEntity name \nMatching probability \n\n\nIII \nRDGCN [60] \nDPGCNN \nMargin-based \nEntity name \nManhattan distance \n\n\nIII \nHGCN [61] \nGCN \nMargin-based \nEntity name \nManhattan distance \n\n\nIII \nMultiKE [67] \nTransE \nCorpus fusion \nEntity name, Attribute Cosine similarity \n\n\nIII \nCEA [65] \nGCN \nMargin-based \nEntity name \nCosine similarity \n\n\nIII \n\n1 \n\nTABLE 2\n2Statistics of EA benchmarks and our constructed dataset.KG pair \n#Rel Triples #Relations #Attr Triples \n\nDBP15KZH-EN \n\n70,414 \n1,701 \n248,035 \n95,142 \n1,323 \n343,218 \n\nDBP15KJA-EN \n\n77,214 \n1,299 \n248,991 \n93,484 \n1,153 \n320,616 \n\nDBP15KFR-EN \n\n105,998 \n903 \n273,825 \n115,722 \n1,208 \n351,094 \n\nDWY100KDBP-WD \n\n463,294 \n330 \n341,770 \n448,774 \n220 \n779,402 \n\nDWY100KDBP-YG \n\n428,952 \n302 \n383,757 \n502,563 \n31 \n98,028 \n\nSRPRSEN-FR \n\n36,508 \n221 \n60,800 \n33,532 \n177 \n53,045 \n\nSRPRSEN-DE \n38,363 \n222 \n55,580 \n37,377 \n120 \n73,753 \n\nSRPRSDBP-WD \n38,421 \n253 \n64,021 \n40,159 \n144 \n133,371 \n\nSRPRSDBP-YG \n33,748 \n223 \n58,853 \n36,569 \n30 \n18,241 \n\nDBP-FB \n96,414 \n407 \n127,614 \n111,974 \n882 \n78,740 \n\n\n\nTABLE 3\n3Experiment results on DBP15K.Method \n\nZH-EN \nJA-EN \nFR-EN \n\nHits@1 Hits@10 MRR Hits@1 Hits@10 MRR Hits@1 Hits@10 MRR \n\nMTransE \n20.9 \n51.2 \n0.31 \n25.0 \n57.2 \n0.36 \n24.7 \n57.7 \n0.36 \nJAPE-Stru \n37.2 \n68.9 \n0.48 \n32.9 \n63.8 \n0.43 \n29.3 \n61.7 \n0.40 \nGCN \n39.8 \n72.0 \n0.51 \n40.0 \n72.9 \n0.51 \n38.9 \n74.9 \n0.51 \nRSNs \n58.0 \n81.1 \n0.66 \n57.4 \n79.9 \n0.65 \n61.2 \n84.1 \n0.69 \nMuGNN \n47.0 \n83.5 \n0.59 \n48.3 \n85.6 \n0.61 \n49.1 \n86.7 \n0.62 \nKECG \n47.7 \n83.6 \n0.60 \n49.2 \n84.4 \n0.61 \n48.5 \n84.9 \n0.61 \n\nITransE \n33.2 \n64.5 \n0.43 \n29.0 \n59.5 \n0.39 \n24.5 \n56.8 \n0.35 \nBootEA  *  \n61.4 \n84.1 \n0.69 \n57.3 \n82.9 \n0.66 \n58.5 \n84.5 \n0.68 \nNAEA  *  \n38.5 \n63.5 \n0.47 \n35.3 \n61.3 \n0.44 \n30.8 \n59.6 \n0.40 \nTransEdge \n75.3 \n92.4 \n0.81 \n74.6 \n92.4 \n0.81 \n77.0 \n94.2 \n0.83 \n\nJAPE \n41.4 \n74.1 \n0.53 \n36.5 \n69.5 \n0.48 \n31.8 \n66.8 \n0.44 \nGCN-Align \n43.4 \n76.2 \n0.55 \n42.7 \n76.2 \n0.54 \n41.1 \n77.2 \n0.53 \nHMAN \n56.1 \n85.9 \n0.67 \n55.7 \n86.0 \n0.67 \n55.0 \n87.6 \n0.66 \nGM-Align  *  \n59.5 \n77.9 \n0.66 \n63.5 \n83.0 \n0.71 \n79.2 \n93.6 \n0.85 \nRDGCN \n69.7 \n84.2 \n0.75 \n76.3 \n89.7 \n0.81 \n87.3 \n95.0 \n0.90 \nHGCN \n70.8 \n84.0 \n0.76 \n75.8 \n88.9 \n0.81 \n88.8 \n95.9 \n0.91 \nCEA \n78.7 \n-\n-\n86.3 \n-\n-\n97.2 \n-\n-\n\nEmbed \n57.5 \n68.6 \n0.61 \n65.1 \n75.4 \n0.69 \n81.6 \n88.9 \n0.84 \nLev \n7.0 \n8.9 \n0.08 \n6.6 \n8.8 \n0.07 \n78.1 \n87.4 \n0.81 \n\nTABLE 4 \nExperiment results on SRPRS. \n\nMethod \n\nEN-FR \nEN-DE \nDBP-WD \nDBP-YG \n\nHits@1 Hits@10 MRR Hits@1 Hits@10 MRR Hits@1 Hits@10 MRR Hits@1 Hits@10 MRR \n\nMTransE \n21.3 \n44.7 \n0.29 \n10.7 \n24.8 \n0.16 \n18.8 \n38.2 \n0.26 \n19.6 \n40.1 \n0.27 \nJAPE-Stru \n24.1 \n53.3 \n0.34 \n30.2 \n57.8 \n0.40 \n21.0 \n48.5 \n0.30 \n21.5 \n51.6 \n0.32 \nGCN \n24.3 \n52.2 \n0.34 \n38.5 \n60.0 \n0.46 \n29.1 \n55.6 \n0.38 \n31.9 \n58.6 \n0.41 \nRSNs \n35.0 \n63.6 \n0.44 \n48.4 \n72.9 \n0.57 \n39.1 \n66.3 \n0.48 \n39.3 \n66.5 \n0.49 \nMuGNN \n13.1 \n34.2 \n0.20 \n24.5 \n43.1 \n0.31 \n15.1 \n36.6 \n0.22 \n17.5 \n38.1 \n0.24 \nKECG \n29.8 \n61.6 \n0.40 \n44.4 \n70.7 \n0.54 \n32.3 \n64.6 \n0.43 \n35.0 \n65.1 \n0.45 \n\nITransE \n12.4 \n30.1 \n0.18 \n13.5 \n31.6 \n0.20 \n10.1 \n26.2 \n0.16 \n10.3 \n26.0 \n0.16 \nBootEA \n36.5 \n64.9 \n0.46 \n50.3 \n73.2 \n0.58 \n38.4 \n66.7 \n0.48 \n38.1 \n65.1 \n0.47 \nNAEA \n17.7 \n41.6 \n0.26 \n30.7 \n53.5 \n0.39 \n18.2 \n42.9 \n0.26 \n19.5 \n45.1 \n0.28 \nTransEdge \n40.0 \n67.5 \n0.49 \n55.6 \n75.3 \n0.63 \n46.1 \n73.8 \n0.56 \n44.3 \n69.9 \n0.53 \n\nJAPE \n24.1 \n54.4 \n0.34 \n26.8 \n54.7 \n0.36 \n21.2 \n50.2 \n0.31 \n19.3 \n50.0 \n0.30 \nGCN-Align \n29.6 \n59.2 \n0.40 \n42.8 \n66.2 \n0.51 \n32.7 \n61.1 \n0.42 \n34.7 \n64.0 \n0.45 \nHMAN \n40.0 \n70.5 \n0.50 \n52.8 \n77.8 \n0.62 \n43.3 \n74.4 \n0.54 \n46.1 \n76.5 \n0.56 \nGM-Align \n57.4 \n64.6 \n0.60 \n68.1 \n74.8 \n0.71 \n76.2 \n83.0 \n0.79 \n80.4 \n83.7 \n0.82 \nRDGCN \n67.2 \n76.7 \n0.71 \n77.9 \n88.6 \n0.82 \n97.4 \n99.4 \n0.98 \n99.0 \n99.7 \n0.99 \nHGCN \n67.0 \n77.0 \n0.71 \n76.3 \n86.3 \n0.80 \n98.9 \n99.9 \n0.99 \n99.1 \n99.7 \n0.99 \nCEA \n96.2 \n-\n-\n97.1 \n-\n-\n100.0 \n-\n-\n100.0 \n-\n-\n\nEmbed \n58.1 \n66.8 \n0.61 \n62.6 \n77.6 \n0.68 \n100.0 \n100.0 \n1.00 \n100.0 \n100.0 \n1.00 \nLev \n85.1 \n90.1 \n0.87 \n86.2 \n92.1 \n0.88 \n100.0 \n100.0 \n1.00 \n100.0 \n100.0 \n1.00 \n\n\n\nTABLE 5\n5Experiment results on DWY100K and DBP-FB.Method \n\nDWY100KDBP-WD \nDWY100KDBP-YG \nDBP-FB \n\nHits@1 Hits@10 MRR Hits@1 Hits@10 MRR Hits@1 Hits@10 MRR \n\nMTransE \n23.8 \n50.7 \n0.33 \n22.7 \n41.4 \n0.29 \n8.5 \n23.0 \n0.14 \nJAPE-Stru \n27.3 \n52.2 \n0.36 \n21.6 \n45.8 \n0.30 \n4.7 \n16.1 \n0.09 \nGCN \n49.4 \n75.6 \n0.59 \n59.8 \n82.9 \n0.68 \n17.8 \n42.3 \n0.26 \nRSNs \n49.7 \n77.0 \n0.59 \n61.0 \n85.7 \n0.69 \n25.3 \n49.7 \n0.34 \nMuGNN \n60.4 \n89.4 \n0.70 \n73.9 \n93.7 \n0.81 \n21.3 \n51.8 \n0.31 \nKECG \n63.1 \n88.8 \n0.72 \n71.9 \n90.4 \n0.79 \n23.1 \n50.8 \n0.32 \n\nITransE \n17.1 \n36.4 \n0.24 \n15.9 \n36.1 \n0.23 \n3.0 \n10.0 \n0.06 \nBootEA  *  \n69.9 \n86.1 \n0.76 \n61.1 \n77.5 \n0.69 \n21.2 \n42.5 \n0.29 \nTransEdge  *  \n68.4 \n90.0 \n0.79 \n83.4 \n95.3 \n0.89 \n30.4 \n56.9 \n0.39 \n\nJAPE \n33.9 \n60.9 \n0.43 \n21.6 \n45.7 \n0.30 \n6.5 \n20.4 \n0.12 \nGCN-Align \n51.3 \n77.7 \n0.61 \n59.6 \n83.7 \n0.68 \n17.8 \n42.3 \n0.26 \nHMAN \n65.5 \n89.7 \n0.74 \n77.6 \n93.8 \n0.83 \n25.9 \n54.2 \n0.36 \nGM-Align \n86.3 \n92.2 \n0.89 \n78.3 \n82.3 \n0.80 \n72.1 \n85.5 \n0.77 \nRDGCN \n-\n-\n-\n-\n-\n-\n67.5 \n84.1 \n0.73 \nHGCN \n98.4 \n99.2 \n0.99 \n99.2 \n99.9 \n0.99 \n77.9 \n92.3 \n0.83 \nCEA \n100.0 \n-\n-\n100.0 \n-\n-\n96.3 \n-\n-\n\nEmbed \n100.0 \n100.0 \n1.00 \n100.0 \n100.0 \n1.00 \n58.3 \n79.4 \n0.65 \nLev \n100.0 \n100.0 \n1.00 \n100.0 \n100.0 \n1.00 \n57.8 \n78.9 \n0.64 \n\n\n\nTABLE 6\n6Averaged time cost on each dataset (in seconds).Method \nDBP15K SRPRS DWY100K DBP-FB \n\nMTransE \n6,467 \n3,355 \n70,085 \n9,147 \nJAPE-Stru \n298 \n405 \n6,636 \n767 \nGCN \n49 \n42 \n1,446 \n103 \nRSNs \n7,539 \n2,602 \n28,516 \n7,172 \nMuGNN \n3,156 \n2,215 \n47,735 \n9,049 \nKECG \n3,724 \n1,800 \n125,386 \n51,280 \n\nITransE \n494 \n175 \n9,021 \n517 \nBootEA \n4,661 \n2,659 \n64,471 \n4,345 \nNAEA \n19,115 \n11,746 \n-\n-\nTransEdge \n3,629 \n1,210 \n20,839 \n3,711 \n\nJAPE \n5,578 \n586 \n21,129 \n1,201 \nGCN-Align \n103 \n87 \n3,212 \n227 \nHMAN \n5,455 \n4,424 \n31,895 \n8,878 \nGM-Align \n26,328 \n13,032 \n459,715 \n53,332 \nRDGCN \n6,711 \n886 \n-\n3,627 \nHGCN \n11,275 \n2,504 \n60,005 \n4,983 \nCEA \n128 \n101 \n17,412 \n345 \n\n\n\nTABLE 7\n7Hits@1 results of module-level evaluation. EA vs. ER. EA differs from other relevant tasks as it works on graph-structured data. Consequently, all existing EA solutions use the KG structure to generate entity embeddings for aligning entities, which can achieve promising results on DBP15K and DWY100K.Method \n\nZH-EN \nJA-EN \nFR-EN \nSRPRSDBP-YG \n\nGCN+Mgn+Manh \n39.9 \n39.8 \n37.8 \n32.7 \nGCN+Mgn+Manh+Mul \n62.9 \n70.3 \n86.6 \n96.5 \nGCN+Mgn+Manh+B \n47.0 \n47.4 \n45.7 \n37.0 \nGCN+Mgn+Manh+Mul+B \n64.2 \n71.9 \n87.8 \n97.8 \n\nGCN+Mgn+Euc \n40.0 \n39.5 \n36.9 \n32.6 \nGCN+Mgn+Euc+Mul \n62.9 \n70.8 \n88.3 \n99.9 \nGCN+Mgn+Euc+B \n46.2 \n47.2 \n44.5 \n37.1 \nGCN+Mgn+Euc+Mul+B \n64.3 \n72.5 \n89.1 \n100.0 \n\nGCN+Mgn+Cos \n37.8 \n38.8 \n35.7 \n29.6 \nGCN+Mgn+Cos+Mul \n72.1 \n78.6 \n92.9 \n99.9 \nGCN+Mgn+Cos+B \n44.2 \n47.2 \n44.7 \n33.6 \nGCN+Mgn+Cos+Mul+B \n74.6 \n81.3 \n93.5 \n100.0 \n\nTransE+Cps+Manh \n41.0 \n36.0 \n30.3 \n18.1 \nTransE+Cps+Manh+Mul \n65.0 \n72.1 \n86.6 \n94.9 \nTransE+Cps+Manh+B \n46.4 \n40.9 \n35.7 \n18.8 \nTransE+Cps+Manh+Mul+B \n66.3 \n73.3 \n87.7 \n95.1 \n\nTransE+Cps+Euc \n41.5 \n36.4 \n30.6 \n18.0 \nTransE+Cps+Euc+Mul \n64.8 \n71.8 \n87.9 \n99.9 \nTransE+Cps+Euc+B \n46.3 \n41.2 \n35.7 \n18.2 \nTransE+Cps+Euc+Mul+B \n65.7 \n72.7 \n88.6 \n100.0 \n\nTransE+Cps+Cos \n41.5 \n36.4 \n30.6 \n18.2 \nTransE+Cps+Cos+Mul \n71.6 \n77.4 \n92.1 \n99.9 \nTransE+Cps+Cos+B \n46.5 \n41.4 \n36.0 \n19.1 \nTransE+Cps+Cos+Mul+B \n73.4 \n78.4 \n92.9 \n100.0 \n\n\n\nTABLE 8\n8EA performance on DBP-FB after considering unmatchable entities.Method \nPrecision Recall \nF1 \n\nCombEA \n0.662 \n1.000 \n0.797 \nCombEA +TH \n0.728 \n0.951 \n0.825 \n\n\n. The identifiers in some KGs are human-readable, such as the ones shown in the figure, while some can be incomprehensible, e.g., mids (/m/012rkqx) in Freebase.\n. http://oaei.ontologymatching.org/2019/knowledgegraph\n. The results on other datasets exhibit similar trends, and hence are omitted in the interest of space.\n\nDbpedia: A nucleus for a web of open data. S Auer, C Bizer, G Kobilarov, J Lehmann, R Cyganiak, Z G Ives, ISWC. S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and Z. G. Ives. Dbpedia: A nucleus for a web of open data. In ISWC, pages 722-735, 2007.\n\nEnriching word vectors with subword information. P Bojanowski, E Grave, A Joulin, T Mikolov, Transactions of the Association for Computational Linguistics. 5P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov. Enriching word vectors with subword information. Transactions of the Association for Computational Linguistics, 5:135-146, 2017.\n\nFreebase: a collaboratively created graph database for structuring human knowledge. K D Bollacker, C Evans, P Paritosh, T Sturge, J Taylor, SIGMOD. K. D. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, pages 1247-1250, 2008.\n\nTranslating embeddings for modeling multi-relational data. A Bordes, N Usunier, A Garc\u00eda-Dur\u00e1n, J Weston, O Yakhnenko, NIPS. A. Bordes, N. Usunier, A. Garc\u00eda-Dur\u00e1n, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In NIPS, pages 2787-2795, 2013.\n\nMulti-channel graph neural network for entity alignment. Y Cao, Z Liu, C Li, Z Liu, J Li, T Chua, ACL. Y. Cao, Z. Liu, C. Li, Z. Liu, J. Li, and T. Chua. Multi-channel graph neural network for entity alignment. In ACL, pages 1452-1461, 2019.\n\nCo-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment. M Chen, Y Tian, K Chang, S Skiena, C Zaniolo, IJCAI. M. Chen, Y. Tian, K. Chang, S. Skiena, and C. Zaniolo. Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment. In IJCAI, pages 3998-4004, 2018.\n\nMultilingual knowledge graph embeddings for cross-lingual knowledge alignment. M Chen, Y Tian, M Yang, C Zaniolo, IJCAI. M. Chen, Y. Tian, M. Yang, and C. Zaniolo. Multilingual knowledge graph embeddings for cross-lingual knowledge alignment. In IJCAI, pages 1511-1517, 2017.\n\nA survey of indexing techniques for scalable record linkage and deduplication. P Christen, IEEE Trans. Knowl. Data Eng. 249P. Christen. A survey of indexing techniques for scalable record linkage and deduplication. IEEE Trans. Knowl. Data Eng., 24(9):1537-1555, 2012.\n\nEnd-to-end entity resolution for big data: A survey. V Christophides, V Efthymiou, T Palpanas, G Papadakis, K Stefanidis, abs/1905.06397CoRRV. Christophides, V. Efthymiou, T. Palpanas, G. Papadakis, and K. Stefanidis. End-to-end entity resolution for big data: A survey. CoRR, abs/1905.06397, 2019.\n\nA Conneau, G Lample, M Ranzato, L Denoyer, H J\u00e9gou, arXiv:1710.04087Word translation without parallel data. arXiv preprintA. Conneau, G. Lample, M. Ranzato, L. Denoyer, and H. J\u00e9gou. Word translation without parallel data. arXiv preprint arXiv:1710.04087, 2017.\n\nLarge-scale named entity disambiguation based on wikipedia data. S Cucerzan, EMNLP-CoNLL. S. Cucerzan. Large-scale named entity disambiguation based on wikipedia data. In EMNLP-CoNLL, pages 708-716, 2007.\n\nKBQA: learning question answering over QA corpora and knowledge bases. W Cui, Y Xiao, H Wang, Y Song, S Hwang, W Wang, PVLDB. 105W. Cui, Y. Xiao, H. Wang, Y. Song, S. Hwang, and W. Wang. KBQA: learning question answering over QA corpora and knowledge bases. PVLDB, 10(5):565-576, 2017.\n\nFalcon: Scaling up hands-off crowdsourced entity matching to build cloud services. S Das, P S G C , A Doan, J F Naughton, G Krishnan, R Deep, E Arcaute, V Raghavendra, Y Park, SIGMOD. S. Das, P. S. G. C., A. Doan, J. F. Naughton, G. Krishnan, R. Deep, E. Arcaute, V. Raghavendra, and Y. Park. Falcon: Scaling up hands-off crowdsourced entity matching to build cloud services. In SIGMOD, pages 1431-1446, 2017.\n\nKnowledge vault: a web-scale approach to probabilistic knowledge fusion. X Dong, E Gabrilovich, G Heitz, W Horn, N Lao, K Murphy, T Strohmann, S Sun, W Zhang, KDD. X. Dong, E. Gabrilovich, G. Heitz, W. Horn, N. Lao, K. Murphy, T. Strohmann, S. Sun, and W. Zhang. Knowledge vault: a web-scale ap- proach to probabilistic knowledge fusion. In KDD, pages 601-610, 2014.\n\nDistributed representations of tuples for entity resolution. M Ebraheem, S Thirumuruganathan, S R Joty, M Ouzzani, N Tang, PVLDB. 1111M. Ebraheem, S. Thirumuruganathan, S. R. Joty, M. Ouzzani, and N. Tang. Distributed representations of tuples for entity resolution. PVLDB, 11(11):1454-1467, 2018.\n\nDuplicate record detection: A survey. A K Elmagarmid, P G Ipeirotis, V S Verykios, IEEE Trans. Knowl. Data Eng. 191A. K. Elmagarmid, P. G. Ipeirotis, and V. S. Verykios. Duplicate record detection: A survey. IEEE Trans. Knowl. Data Eng., 19(1):1-16, 2007.\n\nAgreementmakerlight 2.0: Towards efficient large-scale ontology matching. D Faria, C Pesquita, E Santos, I F Cruz, F M Couto, CEUR Workshop Proceedings. M. Horridge, M. Rospocher, and J. van Ossenbruggen1272CEUR-WS.orgD. Faria, C. Pesquita, E. Santos, I. F. Cruz, and F. M. Couto. Agreementmakerlight 2.0: Towards efficient large-scale ontology matching. In M. Horridge, M. Rospocher, and J. van Ossenbruggen, editors, ISWC, volume 1272 of CEUR Workshop Proceedings, pages 457-460. CEUR-WS.org, 2014.\n\nEnd-to-end multi-perspective matching for entity resolution. C Fu, X Han, L Sun, B Chen, W Zhang, S Wu, H Kong, IJCAI. C. Fu, X. Han, L. Sun, B. Chen, W. Zhang, S. Wu, and H. Kong. End-to-end multi-perspective matching for entity resolution. In IJCAI, pages 4961-4967, 2019.\n\nFast rule mining in ontological knowledge bases with AMIE+. L Gal\u00e1rraga, C Teflioudi, K Hose, F M Suchanek, VLDB J. 246L. Gal\u00e1rraga, C. Teflioudi, K. Hose, and F. M. Suchanek. Fast rule mining in ontological knowledge bases with AMIE+. VLDB J., 24(6):707-730, 2015.\n\nMining rules to align knowledge bases. L A Gal\u00e1rraga, N Preda, F M Suchanek, AKBC@CIKM. L. A. Gal\u00e1rraga, N. Preda, and F. M. Suchanek. Mining rules to align knowledge bases. In AKBC@CIKM, pages 43-48, 2013.\n\nDeep joint entity disambiguation with local neural attention. O.-E Ganea, T Hofmann, EMNLP. O.-E. Ganea and T. Hofmann. Deep joint entity disambiguation with local neural attention. In EMNLP, pages 2619-2629, Sept. 2017.\n\nCollective entity resolution with multi-focal attention. A Globerson, N Lazic, S Chakrabarti, A Subramanya, M Ringgaard, F Pereira, ACL. A. Globerson, N. Lazic, S. Chakrabarti, A. Subramanya, M. Ringgaard, and F. Pereira. Collective entity resolution with multi-focal attention. In ACL, pages 621-631, Aug. 2016.\n\nDeep Learning. Adaptive computation and machine learning. I J Goodfellow, Y Bengio, A C Courville, MIT PressI. J. Goodfellow, Y. Bengio, and A. C. Courville. Deep Learning. Adaptive computation and machine learning. MIT Press, 2016.\n\nLearning to exploit long-term relational dependencies in knowledge graphs. L Guo, Z Sun, W Hu, ICML. L. Guo, Z. Sun, and W. Hu. Learning to exploit long-term relational dependencies in knowledge graphs. In ICML, pages 2505-2514, 2019.\n\nA joint embedding method for entity alignment of knowledge bases. Y Hao, Y Zhang, S He, K Liu, J Zhao, CCKS. Y. Hao, Y. Zhang, S. He, K. Liu, and J. Zhao. A joint embedding method for entity alignment of knowledge bases. In CCKS, pages 3-14, 2016.\n\nLinked Data: Evolving the Web into a Global Data Space. Synthesis Lectures on the Semantic Web. T Heath, C Bizer, Morgan & Claypool PublishersT. Heath and C. Bizer. Linked Data: Evolving the Web into a Global Data Space. Synthesis Lectures on the Semantic Web. Morgan & Claypool Publishers, 2011.\n\nThe knowledge graph track at OAEIgold standards, baselines, and the golden hammer bias. S Hertling, H Paulheim, Lecture Notes in Computer Science. A. Harth, S. Kirrane, A. N. Ngomo, H. Paulheim, A. Rula, A. L. Gentile, P. Haase, and M. Cochez12123SpringerS. Hertling and H. Paulheim. The knowledge graph track at OAEI - gold standards, baselines, and the golden hammer bias. In A. Harth, S. Kirrane, A. N. Ngomo, H. Paulheim, A. Rula, A. L. Gentile, P. Haase, and M. Cochez, editors, ESWC, volume 12123 of Lecture Notes in Computer Science, pages 343-359. Springer, 2020.\n\nLearning knowledge graphs for question answering through conversational dialog. B Hixon, P Clark, H Hajishirzi, NAACL. B. Hixon, P. Clark, and H. Hajishirzi. Learning knowledge graphs for question answering through conversational dialog. In NAACL, pages 851-861, 2015.\n\nRobust disambiguation of named entities in text. J Hoffart, M A Yosef, I Bordino, H F\u00fcrstenau, M Pinkal, M Spaniol, B Taneva, S Thater, G Weikum, EMNLP. J. Hoffart, M. A. Yosef, I. Bordino, H. F\u00fcrstenau, M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and G. Weikum. Robust disambiguation of named entities in text. In EMNLP, pages 782-792, 2011.\n\nBuckle: Evaluating fact checking algorithms built on knowledge bases. V Huynh, P Papotti, PVLDB12V. Huynh and P. Papotti. Buckle: Evaluating fact checking algorithms built on knowledge bases. PVLDB, 12(12):1798-1801, 2019.\n\nSemi-supervised classification with graph convolutional networks. T N Kipf, M Welling, abs/1609.02907CoRRT. N. Kipf and M. Welling. Semi-supervised classification with graph convolutional networks. CoRR, abs/1609.02907, 2016.\n\nMagellan: Toward building entity matching management systems. P Konda, S Das, P S G C , A Doan, A Ardalan, J R Ballard, H Li, F Panahi, H Zhang, J F Naughton, S Prasad, G Krishnan, R Deep, V Raghavendra, PVLDB. 912P. Konda, S. Das, P. S. G. C., A. Doan, A. Ardalan, J. R. Ballard, H. Li, F. Panahi, H. Zhang, J. F. Naughton, S. Prasad, G. Krishnan, R. Deep, and V. Raghavendra. Magellan: Toward building entity matching management systems. PVLDB, 9(12):1197-1208, 2016.\n\nFrameworks for entity matching: A comparison. H K\u00f6pcke, E Rahm, Data Knowl. Eng. 692H. K\u00f6pcke and E. Rahm. Frameworks for entity matching: A comparison. Data Knowl. Eng., 69(2):197-210, 2010.\n\nRecord linkage: similarity measures and algorithms. N Koudas, S Sarawagi, D Srivastava, SIGMOD. N. Koudas, S. Sarawagi, and D. Srivastava. Record linkage: similarity measures and algorithms. In SIGMOD, pages 802-803, 2006.\n\nSigma: simple greedy matching for aligning large knowledge bases. S Lacoste-Julien, K Palla, A Davies, G Kasneci, T Graepel, Z Ghahramani, KDD. S. Lacoste-Julien, K. Palla, A. Davies, G. Kasneci, T. Graepel, and Z. Ghahramani. Sigma: simple greedy matching for aligning large knowledge bases. In KDD, pages 572-580, 2013.\n\nImproving entity linking by modeling latent relations between mentions. P Le, I Titov, ACL. P. Le and I. Titov. Improving entity linking by modeling latent relations between mentions. In ACL, pages 1595-1604, 2018.\n\nBinary codes capable of correcting deletions, insertions, and reversals. V I Levenshtein, Soviet physics doklady. 10V. I. Levenshtein. Binary codes capable of correcting deletions, insertions, and reversals. In Soviet physics doklady, volume 10, pages 707-710, 1966.\n\nSemi-supervised entity alignment via joint knowledge embedding model and cross-graph model. C Li, Y Cao, L Hou, J Shi, J Li, T.-S Chua, EMNLP. C. Li, Y. Cao, L. Hou, J. Shi, J. Li, and T.-S. Chua. Semi-supervised entity alignment via joint knowledge embedding model and cross-graph model. In EMNLP, pages 2723-2732, 2019.\n\nMMKG: multi-modal knowledge graphs. Y Liu, H Li, A Garc\u00eda-Dur\u00e1n, M Niepert, D O\u00f1oro-Rubio, D S Rosenblum, Lecture Notes in Computer Science. P. Hitzler, M. Fern\u00e1ndez, K. Janowicz, A. Zaveri, A. J. G. Gray, V. L\u00f3pez, A. Haller, and K. Hammar11503SpringerY. Liu, H. Li, A. Garc\u00eda-Dur\u00e1n, M. Niepert, D. O\u00f1oro-Rubio, and D. S. Rosenblum. MMKG: multi-modal knowledge graphs. In P. Hitzler, M. Fern\u00e1ndez, K. Janowicz, A. Zaveri, A. J. G. Gray, V. L\u00f3pez, A. Haller, and K. Hammar, editors, ESWC, volume 11503 of Lecture Notes in Computer Science, pages 459-474. Springer, 2019.\n\nDual-primal graph convolutional networks. F Monti, O Shchur, A Bojchevski, O Litany, S G\u00fcnnemann, M M Bronstein, abs/1806.00770CoRRF. Monti, O. Shchur, A. Bojchevski, O. Litany, S. G\u00fcnnemann, and M. M. Bronstein. Dual-primal graph convolutional networks. CoRR, abs/1806.00770, 2018.\n\nLarge-scale semantic integration of linked data: A survey. M Mountantonakis, Y Tzitzikas, 103:1-103:40ACM Comput. Surv. 525M. Mountantonakis and Y. Tzitzikas. Large-scale semantic integration of linked data: A survey. ACM Comput. Surv., 52(5):103:1-103:40, 2019.\n\nDeep learning for entity matching: A design space exploration. S Mudgal, H Li, T Rekatsinas, A Doan, Y Park, G Krishnan, R Deep, E Arcaute, V Raghavendra, SIGMOD. S. Mudgal, H. Li, T. Rekatsinas, A. Doan, Y. Park, G. Krishnan, R. Deep, E. Arcaute, and V. Raghavendra. Deep learning for entity matching: A design space exploration. In SIGMOD, pages 19-34, 2018.\n\nA survey of current link discovery frameworks. M Nentwig, M Hartung, A N Ngomo, E Rahm, Semantic Web. 83M. Nentwig, M. Hartung, A. N. Ngomo, and E. Rahm. A survey of current link discovery frameworks. Semantic Web, 8(3):419-436, 2017.\n\nLIMES -A time-efficient approach for largescale link discovery on the web of data. A N Ngomo, S Auer, IJCAI. A. N. Ngomo and S. Auer. LIMES -A time-efficient approach for large- scale link discovery on the web of data. In IJCAI, pages 2312-2317, 2011.\n\nDeep sequence-to-sequence entity matching for heterogeneous entity resolution. H Nie, X Han, B He, L Sun, B Chen, W Zhang, S Wu, H Kong, CIKM. H. Nie, X. Han, B. He, L. Sun, B. Chen, W. Zhang, S. Wu, and H. Kong. Deep sequence-to-sequence entity matching for heterogeneous entity resolution. In CIKM, pages 629-638, 2019.\n\nKnowledge graph refinement: A survey of approaches and evaluation methods. H Paulheim, Semantic Web. 83H. Paulheim. Knowledge graph refinement: A survey of approaches and evaluation methods. Semantic Web, 8(3):489-508, 2017.\n\nLarge-scale collective entity matching. V Rastogi, N N Dalvi, M N Garofalakis, PVLDB4V. Rastogi, N. N. Dalvi, and M. N. Garofalakis. Large-scale collective entity matching. PVLDB, 4(4):208-218, 2011.\n\nLearning a health knowledge graph from electronic medical records. M Rotmensch, Y Halpern, A Tlimat, S Horng, D Sontag, Scientific Reports. 72017M. Rotmensch, Y. Halpern, A. Tlimat, S. Horng, and D. Sontag. Learning a health knowledge graph from electronic medical records. Scientific Reports, 7, 12 2017.\n\nRimom-im: A novel iterative framework for instance matching. C Shao, L Hu, J Li, Z Wang, T L Chung, J Xia, J. Comput. Sci. Technol. 311C. Shao, L. Hu, J. Li, Z. Wang, T. L. Chung, and J. Xia. Rimom-im: A novel iterative framework for instance matching. J. Comput. Sci. Technol., 31(1):185-197, 2016.\n\nOntology matching: State of the art and future challenges. P Shvaiko, J Euzenat, IEEE Trans. Knowl. Data Eng. 251P. Shvaiko and J. Euzenat. Ontology matching: State of the art and future challenges. IEEE Trans. Knowl. Data Eng., 25(1):158-176, 2013.\n\nPARIS: probabilistic alignment of relations, instances, and schema. F M Suchanek, S Abiteboul, P Senellart, PVLDB5F. M. Suchanek, S. Abiteboul, and P. Senellart. PARIS: probabilistic align- ment of relations, instances, and schema. PVLDB, 5(3):157-168, 2011.\n\nYago: a core of semantic knowledge. F M Suchanek, G Kasneci, G Weikum, WWW. F. M. Suchanek, G. Kasneci, and G. Weikum. Yago: a core of semantic knowledge. In WWW, pages 697-706, 2007.\n\nCross-lingual entity alignment via joint attribute-preserving embedding. Z Sun, W Hu, C Li, ISWC. Z. Sun, W. Hu, and C. Li. Cross-lingual entity alignment via joint attribute-preserving embedding. In ISWC, pages 628-644, 2017.\n\nBootstrapping entity alignment with knowledge graph embedding. Z Sun, W Hu, Q Zhang, Y Qu, IJCAI. Z. Sun, W. Hu, Q. Zhang, and Y. Qu. Bootstrapping entity alignment with knowledge graph embedding. In IJCAI, pages 4396-4402, 2018.\n\nTransedge: Translating relation-contextualized embeddings for knowledge graphs. Z Sun, J Huang, W Hu, M Chen, L Guo, Y Qu, ISWC. Z. Sun, J. Huang, W. Hu, M. Chen, L. Guo, and Y. Qu. Transedge: Translating relation-contextualized embeddings for knowledge graphs. In ISWC, pages 612-629, 2019.\n\nArnetminer: extraction and mining of academic social networks. J Tang, J Zhang, L Yao, J Li, L Zhang, Z Su, SIGKDD. ACMJ. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su. Arnetminer: extraction and mining of academic social networks. In SIGKDD, pages 990-998. ACM, 2008.\n\nEntity alignment between knowledge graphs using attribute embeddings. B D Trisedya, J Qi, R Zhang, AAAI. B. D. Trisedya, J. Qi, and R. Zhang. Entity alignment between knowledge graphs using attribute embeddings. In AAAI, pages 297-304, 2019.\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, NIPS. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. In NIPS, pages 5998-6008, 2017.\n\nCross-lingual knowledge graph alignment via graph convolutional networks. Z Wang, Q Lv, X Lan, Y Zhang, EMNLP. Z. Wang, Q. Lv, X. Lan, and Y. Zhang. Cross-lingual knowledge graph alignment via graph convolutional networks. In EMNLP, pages 349-357, 2018.\n\nRelation-aware entity alignment for heterogeneous knowledge graphs. Y Wu, X Liu, Y Feng, Z Wang, R Yan, D Zhao, IJCAI. Y. Wu, X. Liu, Y. Feng, Z. Wang, R. Yan, and D. Zhao. Relation-aware entity alignment for heterogeneous knowledge graphs. In IJCAI, pages 5278-5284, 2019.\n\nJointly learning entity and relation representations for entity alignment. Y Wu, X Liu, Y Feng, Z Wang, D Zhao, EMNLP. Y. Wu, X. Liu, Y. Feng, Z. Wang, and D. Zhao. Jointly learning entity and relation representations for entity alignment. In EMNLP, pages 240-249, 2019.\n\nCross-lingual knowledge graph alignment via graph matching neural network. K Xu, L Wang, M Yu, Y Feng, Y Song, Z Wang, D Yu, ACL. K. Xu, L. Wang, M. Yu, Y. Feng, Y. Song, Z. Wang, and D. Yu. Cross-lingual knowledge graph alignment via graph matching neural network. In ACL, pages 3156-3161, 2019.\n\nAligning cross-lingual entities with multi-aspect information. H.-W Yang, Y Zou, P Shi, W Lu, J Lin, S Xu, EMNLP. H.-W. Yang, Y. Zou, P. Shi, W. Lu, J. Lin, and S. Xu. Aligning cross-lingual entities with multi-aspect information. In EMNLP, pages 4422-4432, 2019.\n\nAn efficient parallel keyword search engine on knowledge graphs. Y Yang, D Agrawal, H V Jagadish, A K H Tung, S Wu, ICDE. Y. Yang, D. Agrawal, H. V. Jagadish, A. K. H. Tung, and S. Wu. An efficient parallel keyword search engine on knowledge graphs. In ICDE, pages 338-349, 2019.\n\nCollective entity alignment via adaptive features. W Zeng, X Zhao, J Tang, X Lin, ICDE. IEEEW. Zeng, X. Zhao, J. Tang, and X. Lin. Collective entity alignment via adaptive features. In ICDE, pages 1870-1873. IEEE, 2020.\n\nDegree-aware alignment for entities in tail. W Zeng, X Zhao, W Wang, J Tang, Z Tan, SIGIR. W. Zeng, X. Zhao, W. Wang, J. Tang, and Z. Tan. Degree-aware alignment for entities in tail. In SIGIR, 2020.\n\nMulti-view knowledge graph embedding for entity alignment. Q Zhang, Z Sun, W Hu, M Chen, L Guo, Y Qu, IJCAI. Q. Zhang, Z. Sun, W. Hu, M. Chen, L. Guo, and Y. Qu. Multi-view knowledge graph embedding for entity alignment. In IJCAI, pages 5429-5435, 2019.\n\nA recurrent model for collective entity linking with adaptive features. X Zhou, Y Miao, W Wang, J Qin, AAAI. AAAI PressX. Zhou, Y. Miao, W. Wang, and J. Qin. A recurrent model for collective entity linking with adaptive features. In AAAI, pages 329-336. AAAI Press, 2020.\n\nIterative entity alignment via joint knowledge embeddings. H Zhu, R Xie, Z Liu, M Sun, IJCAI. H. Zhu, R. Xie, Z. Liu, and M. Sun. Iterative entity alignment via joint knowledge embeddings. In IJCAI, pages 4258-4264, 2017.\n\nNeighborhood-aware attentional representation for multilingual knowledge graphs. Q Zhu, X Zhou, J Wu, J Tan, L Guo, IJCAI. Q. Zhu, X. Zhou, J. Wu, J. Tan, and L. Guo. Neighborhood-aware attentional representation for multilingual knowledge graphs. In IJCAI, pages 1943-1949, 2019.\n", "annotations": {"author": "[{\"end\":154,\"start\":143},{\"end\":167,\"start\":155},{\"end\":181,\"start\":168},{\"end\":191,\"start\":182},{\"end\":208,\"start\":192},{\"end\":220,\"start\":209},{\"end\":233,\"start\":221},{\"end\":247,\"start\":234},{\"end\":257,\"start\":248},{\"end\":274,\"start\":258},{\"end\":286,\"start\":275},{\"end\":299,\"start\":287},{\"end\":313,\"start\":300},{\"end\":323,\"start\":314},{\"end\":342,\"start\":324}]", "publisher": null, "author_last_name": "[{\"end\":153,\"start\":149},{\"end\":166,\"start\":162},{\"end\":180,\"start\":176},{\"end\":190,\"start\":186},{\"end\":207,\"start\":199},{\"end\":219,\"start\":215},{\"end\":232,\"start\":228},{\"end\":246,\"start\":242},{\"end\":256,\"start\":252},{\"end\":285,\"start\":281},{\"end\":298,\"start\":294},{\"end\":312,\"start\":308},{\"end\":322,\"start\":318},{\"end\":341,\"start\":333}]", "author_first_name": "[{\"end\":148,\"start\":143},{\"end\":161,\"start\":155},{\"end\":175,\"start\":168},{\"end\":185,\"start\":182},{\"end\":198,\"start\":192},{\"end\":214,\"start\":209},{\"end\":227,\"start\":221},{\"end\":241,\"start\":234},{\"end\":251,\"start\":248},{\"end\":264,\"start\":258},{\"end\":273,\"start\":265},{\"end\":280,\"start\":275},{\"end\":293,\"start\":287},{\"end\":307,\"start\":300},{\"end\":317,\"start\":314},{\"end\":330,\"start\":324},{\"end\":332,\"start\":331}]", "author_affiliation": null, "title": "[{\"end\":140,\"start\":1},{\"end\":482,\"start\":343}]", "venue": null, "abstract": "[{\"end\":2426,\"start\":1169}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2942,\"start\":2939},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":2953,\"start\":2949},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2984,\"start\":2980},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3030,\"start\":3026},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":3054,\"start\":3050},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":3158,\"start\":3154},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3178,\"start\":3174},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3203,\"start\":3199},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3209,\"start\":3205},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3354,\"start\":3350},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3839,\"start\":3836},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3845,\"start\":3841},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3847,\"start\":3846},{\"end\":4502,\"start\":4500},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5045,\"start\":5042},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5051,\"start\":5047},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5057,\"start\":5053},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":5063,\"start\":5059},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":5069,\"start\":5065},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":5075,\"start\":5071},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":5081,\"start\":5077},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":5087,\"start\":5083},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":5093,\"start\":5089},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":6270,\"start\":6266},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":6328,\"start\":6324},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6354,\"start\":6350},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8859,\"start\":8856},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11667,\"start\":11663},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11673,\"start\":11669},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11679,\"start\":11675},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11701,\"start\":11697},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11707,\"start\":11703},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":11727,\"start\":11724},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11733,\"start\":11729},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11753,\"start\":11749},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11786,\"start\":11782},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":11792,\"start\":11788},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":11798,\"start\":11794},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":11804,\"start\":11800},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":11810,\"start\":11806},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11831,\"start\":11827},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":11837,\"start\":11833},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11880,\"start\":11876},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11886,\"start\":11882},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12443,\"start\":12439},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12449,\"start\":12445},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":12455,\"start\":12451},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12461,\"start\":12457},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":12467,\"start\":12463},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13689,\"start\":13686},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14031,\"start\":14027},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":14037,\"start\":14033},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":14276,\"start\":14272},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":14282,\"start\":14278},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15066,\"start\":15062},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15712,\"start\":15711},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":15967,\"start\":15963},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":15982,\"start\":15978},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":16257,\"start\":16253},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":16548,\"start\":16544},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":16711,\"start\":16707},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16851,\"start\":16848},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16857,\"start\":16853},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":16863,\"start\":16859},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":16869,\"start\":16865},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17524,\"start\":17523},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18313,\"start\":18310},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18407,\"start\":18403},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21299,\"start\":21296},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21312,\"start\":21308},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":23002,\"start\":22998},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":23192,\"start\":23188},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":26260,\"start\":26259},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28342,\"start\":28341},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30344,\"start\":30343},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":32576,\"start\":32572},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":32853,\"start\":32849},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33195,\"start\":33191},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":36491,\"start\":36487},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":36497,\"start\":36493},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":36503,\"start\":36499},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":36667,\"start\":36663},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":36894,\"start\":36890},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36942,\"start\":36939},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":37030,\"start\":37026},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":38043,\"start\":38039},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":38321,\"start\":38320},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":39400,\"start\":39396},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":39803,\"start\":39799},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":40734,\"start\":40733},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":47974,\"start\":47970},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":48180,\"start\":48176},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":49301,\"start\":49300},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":50748,\"start\":50746},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":55030,\"start\":55026},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":55036,\"start\":55032},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":56304,\"start\":56300},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":56850,\"start\":56846},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":56938,\"start\":56934},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":60463,\"start\":60460},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":61855,\"start\":61851},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":61861,\"start\":61857},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":67021,\"start\":67020}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":65764,\"start\":65730},{\"attributes\":{\"id\":\"fig_1\"},\"end\":66096,\"start\":65765},{\"attributes\":{\"id\":\"fig_2\"},\"end\":66388,\"start\":66097},{\"attributes\":{\"id\":\"fig_3\"},\"end\":66447,\"start\":66389},{\"attributes\":{\"id\":\"fig_4\"},\"end\":66519,\"start\":66448},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":66872,\"start\":66520},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":66937,\"start\":66873},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":68372,\"start\":66938},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":69077,\"start\":68373},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":72011,\"start\":69078},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":73247,\"start\":72012},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":73920,\"start\":73248},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":75290,\"start\":73921},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":75459,\"start\":75291}]", "paragraph": "[{\"end\":3215,\"start\":2442},{\"end\":3849,\"start\":3217},{\"end\":4308,\"start\":3851},{\"end\":4964,\"start\":4310},{\"end\":5679,\"start\":4966},{\"end\":6038,\"start\":5681},{\"end\":6816,\"start\":6040},{\"end\":7066,\"start\":6818},{\"end\":7263,\"start\":7068},{\"end\":7569,\"start\":7265},{\"end\":8261,\"start\":7571},{\"end\":8527,\"start\":8263},{\"end\":8678,\"start\":8546},{\"end\":9775,\"start\":8680},{\"end\":10158,\"start\":9777},{\"end\":10276,\"start\":10176},{\"end\":11335,\"start\":10296},{\"end\":12727,\"start\":11362},{\"end\":14038,\"start\":12729},{\"end\":14938,\"start\":14040},{\"end\":15197,\"start\":14940},{\"end\":15556,\"start\":15199},{\"end\":16870,\"start\":15558},{\"end\":17138,\"start\":16872},{\"end\":17425,\"start\":17163},{\"end\":17851,\"start\":17427},{\"end\":17993,\"start\":17878},{\"end\":18408,\"start\":17995},{\"end\":18823,\"start\":18410},{\"end\":19253,\"start\":18825},{\"end\":19833,\"start\":19255},{\"end\":20744,\"start\":19848},{\"end\":21055,\"start\":20746},{\"end\":21254,\"start\":21085},{\"end\":21398,\"start\":21256},{\"end\":21904,\"start\":21400},{\"end\":22477,\"start\":21913},{\"end\":22841,\"start\":22479},{\"end\":23288,\"start\":22843},{\"end\":23905,\"start\":23290},{\"end\":24046,\"start\":23926},{\"end\":24899,\"start\":24048},{\"end\":25390,\"start\":24901},{\"end\":25621,\"start\":25392},{\"end\":25761,\"start\":25643},{\"end\":26810,\"start\":25763},{\"end\":27153,\"start\":26923},{\"end\":27690,\"start\":27155},{\"end\":28085,\"start\":27692},{\"end\":28465,\"start\":28087},{\"end\":28634,\"start\":28467},{\"end\":28944,\"start\":28636},{\"end\":29026,\"start\":28973},{\"end\":29430,\"start\":29045},{\"end\":29990,\"start\":29432},{\"end\":30448,\"start\":29992},{\"end\":31565,\"start\":30450},{\"end\":31885,\"start\":31580},{\"end\":32423,\"start\":31887},{\"end\":32563,\"start\":32459},{\"end\":32839,\"start\":32565},{\"end\":33171,\"start\":32841},{\"end\":34527,\"start\":33173},{\"end\":34810,\"start\":34529},{\"end\":35202,\"start\":34812},{\"end\":35709,\"start\":35204},{\"end\":35923,\"start\":35711},{\"end\":36278,\"start\":35925},{\"end\":37237,\"start\":36280},{\"end\":37528,\"start\":37239},{\"end\":38404,\"start\":37530},{\"end\":38607,\"start\":38406},{\"end\":38945,\"start\":38642},{\"end\":39486,\"start\":38958},{\"end\":39870,\"start\":39488},{\"end\":40615,\"start\":39872},{\"end\":41071,\"start\":40617},{\"end\":41529,\"start\":41073},{\"end\":42073,\"start\":41531},{\"end\":42452,\"start\":42075},{\"end\":42921,\"start\":42454},{\"end\":43167,\"start\":42955},{\"end\":43692,\"start\":43169},{\"end\":43782,\"start\":43706},{\"end\":44193,\"start\":43784},{\"end\":44923,\"start\":44195},{\"end\":45185,\"start\":44959},{\"end\":45564,\"start\":45187},{\"end\":45922,\"start\":45566},{\"end\":46602,\"start\":45946},{\"end\":46914,\"start\":46604},{\"end\":47674,\"start\":46916},{\"end\":48274,\"start\":47718},{\"end\":48800,\"start\":48276},{\"end\":49515,\"start\":48802},{\"end\":49942,\"start\":49543},{\"end\":51308,\"start\":49944},{\"end\":51505,\"start\":51310},{\"end\":53616,\"start\":51517},{\"end\":53776,\"start\":53684},{\"end\":53949,\"start\":53810},{\"end\":55842,\"start\":53951},{\"end\":55957,\"start\":55844},{\"end\":57302,\"start\":55959},{\"end\":59857,\"start\":57342},{\"end\":60368,\"start\":59859},{\"end\":60804,\"start\":60393},{\"end\":61200,\"start\":60806},{\"end\":61608,\"start\":61202},{\"end\":61793,\"start\":61610},{\"end\":62435,\"start\":61795},{\"end\":62986,\"start\":62468},{\"end\":63545,\"start\":62988},{\"end\":64396,\"start\":63570},{\"end\":64971,\"start\":64398},{\"end\":65141,\"start\":64973},{\"end\":65729,\"start\":65156}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20872,\"start\":20864},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21287,\"start\":21280},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24642,\"start\":24635},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":33508,\"start\":33501},{\"end\":38107,\"start\":38100},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":38724,\"start\":38717},{\"end\":40798,\"start\":40791},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":40810,\"start\":40803},{\"end\":42999,\"start\":42992},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":45044,\"start\":45037},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":46053,\"start\":46046},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":50745,\"start\":50738},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":62434,\"start\":62427},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":62584,\"start\":62577},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":64069,\"start\":64062},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":64992,\"start\":64985}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2440,\"start\":2428},{\"end\":8544,\"start\":8530},{\"attributes\":{\"n\":\"2\"},\"end\":10174,\"start\":10161},{\"attributes\":{\"n\":\"2.1\"},\"end\":10294,\"start\":10279},{\"attributes\":{\"n\":\"2.2\"},\"end\":11360,\"start\":11338},{\"end\":17161,\"start\":17141},{\"attributes\":{\"n\":\"3\"},\"end\":17876,\"start\":17854},{\"end\":19846,\"start\":19836},{\"attributes\":{\"n\":\"3.1\"},\"end\":21083,\"start\":21058},{\"end\":21911,\"start\":21907},{\"attributes\":{\"n\":\"3.2\"},\"end\":23924,\"start\":23908},{\"attributes\":{\"n\":\"3.3\"},\"end\":25641,\"start\":25624},{\"end\":26894,\"start\":26813},{\"attributes\":{\"n\":\"3.4\"},\"end\":26921,\"start\":26897},{\"attributes\":{\"n\":\"4\"},\"end\":28971,\"start\":28947},{\"attributes\":{\"n\":\"4.1\"},\"end\":29043,\"start\":29029},{\"end\":31578,\"start\":31568},{\"attributes\":{\"n\":\"4.2\"},\"end\":32445,\"start\":32426},{\"end\":32457,\"start\":32448},{\"attributes\":{\"n\":\"4.3\"},\"end\":38640,\"start\":38610},{\"end\":38956,\"start\":38948},{\"attributes\":{\"n\":\"4.4\"},\"end\":42953,\"start\":42924},{\"end\":43704,\"start\":43695},{\"attributes\":{\"n\":\"4.5\"},\"end\":44957,\"start\":44926},{\"attributes\":{\"n\":\"4.6\"},\"end\":45944,\"start\":45925},{\"attributes\":{\"n\":\"4.7\"},\"end\":47716,\"start\":47677},{\"attributes\":{\"n\":\"4.8\"},\"end\":49541,\"start\":49518},{\"attributes\":{\"n\":\"4.9\"},\"end\":51515,\"start\":51508},{\"end\":53653,\"start\":53619},{\"attributes\":{\"n\":\"4.10\"},\"end\":53682,\"start\":53656},{\"end\":53808,\"start\":53779},{\"attributes\":{\"n\":\"5\"},\"end\":57340,\"start\":57305},{\"attributes\":{\"n\":\"5.1\"},\"end\":60391,\"start\":60371},{\"attributes\":{\"n\":\"5.2\"},\"end\":62466,\"start\":62438},{\"attributes\":{\"n\":\"5.3\"},\"end\":63568,\"start\":63548},{\"attributes\":{\"n\":\"6\"},\"end\":65154,\"start\":65144},{\"end\":65739,\"start\":65731},{\"end\":66106,\"start\":66098},{\"end\":66398,\"start\":66390},{\"end\":66457,\"start\":66449},{\"end\":66883,\"start\":66874},{\"end\":68381,\"start\":68374},{\"end\":69086,\"start\":69079},{\"end\":72020,\"start\":72013},{\"end\":73256,\"start\":73249},{\"end\":73929,\"start\":73922},{\"end\":75299,\"start\":75292}]", "table": "[{\"end\":66872,\"start\":66661},{\"end\":68372,\"start\":67069},{\"end\":69077,\"start\":68439},{\"end\":72011,\"start\":69117},{\"end\":73247,\"start\":72063},{\"end\":73920,\"start\":73306},{\"end\":75290,\"start\":74232},{\"end\":75459,\"start\":75365}]", "figure_caption": "[{\"end\":65764,\"start\":65741},{\"end\":66096,\"start\":65767},{\"end\":66388,\"start\":66108},{\"end\":66447,\"start\":66400},{\"end\":66519,\"start\":66459},{\"end\":66661,\"start\":66522},{\"end\":66937,\"start\":66885},{\"end\":67069,\"start\":66940},{\"end\":68439,\"start\":68383},{\"end\":69117,\"start\":69088},{\"end\":72063,\"start\":72022},{\"end\":73306,\"start\":73258},{\"end\":74232,\"start\":73931},{\"end\":75365,\"start\":75301}]", "figure_ref": "[{\"end\":10858,\"start\":10850},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18129,\"start\":18121},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19642,\"start\":19634},{\"end\":20691,\"start\":20683},{\"end\":30539,\"start\":30531},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":33808,\"start\":33800},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":34097,\"start\":34089},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":45340,\"start\":45332},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":48825,\"start\":48817},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":52825,\"start\":52817},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":62823,\"start\":62815}]", "bib_author_first_name": "[{\"end\":75825,\"start\":75824},{\"end\":75833,\"start\":75832},{\"end\":75842,\"start\":75841},{\"end\":75855,\"start\":75854},{\"end\":75866,\"start\":75865},{\"end\":75878,\"start\":75877},{\"end\":75880,\"start\":75879},{\"end\":76091,\"start\":76090},{\"end\":76105,\"start\":76104},{\"end\":76114,\"start\":76113},{\"end\":76124,\"start\":76123},{\"end\":76465,\"start\":76464},{\"end\":76467,\"start\":76466},{\"end\":76480,\"start\":76479},{\"end\":76489,\"start\":76488},{\"end\":76501,\"start\":76500},{\"end\":76511,\"start\":76510},{\"end\":76773,\"start\":76772},{\"end\":76783,\"start\":76782},{\"end\":76794,\"start\":76793},{\"end\":76810,\"start\":76809},{\"end\":76820,\"start\":76819},{\"end\":77057,\"start\":77056},{\"end\":77064,\"start\":77063},{\"end\":77071,\"start\":77070},{\"end\":77077,\"start\":77076},{\"end\":77084,\"start\":77083},{\"end\":77090,\"start\":77089},{\"end\":77346,\"start\":77345},{\"end\":77354,\"start\":77353},{\"end\":77362,\"start\":77361},{\"end\":77371,\"start\":77370},{\"end\":77381,\"start\":77380},{\"end\":77670,\"start\":77669},{\"end\":77678,\"start\":77677},{\"end\":77686,\"start\":77685},{\"end\":77694,\"start\":77693},{\"end\":77947,\"start\":77946},{\"end\":78190,\"start\":78189},{\"end\":78207,\"start\":78206},{\"end\":78220,\"start\":78219},{\"end\":78232,\"start\":78231},{\"end\":78245,\"start\":78244},{\"end\":78437,\"start\":78436},{\"end\":78448,\"start\":78447},{\"end\":78458,\"start\":78457},{\"end\":78469,\"start\":78468},{\"end\":78480,\"start\":78479},{\"end\":78765,\"start\":78764},{\"end\":78977,\"start\":78976},{\"end\":78984,\"start\":78983},{\"end\":78992,\"start\":78991},{\"end\":79000,\"start\":78999},{\"end\":79008,\"start\":79007},{\"end\":79017,\"start\":79016},{\"end\":79276,\"start\":79275},{\"end\":79283,\"start\":79282},{\"end\":79289,\"start\":79284},{\"end\":79293,\"start\":79292},{\"end\":79301,\"start\":79300},{\"end\":79303,\"start\":79302},{\"end\":79315,\"start\":79314},{\"end\":79327,\"start\":79326},{\"end\":79335,\"start\":79334},{\"end\":79346,\"start\":79345},{\"end\":79361,\"start\":79360},{\"end\":79677,\"start\":79676},{\"end\":79685,\"start\":79684},{\"end\":79700,\"start\":79699},{\"end\":79709,\"start\":79708},{\"end\":79717,\"start\":79716},{\"end\":79724,\"start\":79723},{\"end\":79734,\"start\":79733},{\"end\":79747,\"start\":79746},{\"end\":79754,\"start\":79753},{\"end\":80033,\"start\":80032},{\"end\":80045,\"start\":80044},{\"end\":80066,\"start\":80065},{\"end\":80068,\"start\":80067},{\"end\":80076,\"start\":80075},{\"end\":80087,\"start\":80086},{\"end\":80309,\"start\":80308},{\"end\":80311,\"start\":80310},{\"end\":80325,\"start\":80324},{\"end\":80327,\"start\":80326},{\"end\":80340,\"start\":80339},{\"end\":80342,\"start\":80341},{\"end\":80602,\"start\":80601},{\"end\":80611,\"start\":80610},{\"end\":80623,\"start\":80622},{\"end\":80633,\"start\":80632},{\"end\":80635,\"start\":80634},{\"end\":80643,\"start\":80642},{\"end\":80645,\"start\":80644},{\"end\":81091,\"start\":81090},{\"end\":81097,\"start\":81096},{\"end\":81104,\"start\":81103},{\"end\":81111,\"start\":81110},{\"end\":81119,\"start\":81118},{\"end\":81128,\"start\":81127},{\"end\":81134,\"start\":81133},{\"end\":81366,\"start\":81365},{\"end\":81379,\"start\":81378},{\"end\":81392,\"start\":81391},{\"end\":81400,\"start\":81399},{\"end\":81402,\"start\":81401},{\"end\":81612,\"start\":81611},{\"end\":81614,\"start\":81613},{\"end\":81627,\"start\":81626},{\"end\":81636,\"start\":81635},{\"end\":81638,\"start\":81637},{\"end\":81846,\"start\":81842},{\"end\":81855,\"start\":81854},{\"end\":82060,\"start\":82059},{\"end\":82073,\"start\":82072},{\"end\":82082,\"start\":82081},{\"end\":82097,\"start\":82096},{\"end\":82111,\"start\":82110},{\"end\":82124,\"start\":82123},{\"end\":82375,\"start\":82374},{\"end\":82377,\"start\":82376},{\"end\":82391,\"start\":82390},{\"end\":82401,\"start\":82400},{\"end\":82403,\"start\":82402},{\"end\":82626,\"start\":82625},{\"end\":82633,\"start\":82632},{\"end\":82640,\"start\":82639},{\"end\":82853,\"start\":82852},{\"end\":82860,\"start\":82859},{\"end\":82869,\"start\":82868},{\"end\":82875,\"start\":82874},{\"end\":82882,\"start\":82881},{\"end\":83132,\"start\":83131},{\"end\":83141,\"start\":83140},{\"end\":83422,\"start\":83421},{\"end\":83434,\"start\":83433},{\"end\":83987,\"start\":83986},{\"end\":83996,\"start\":83995},{\"end\":84005,\"start\":84004},{\"end\":84226,\"start\":84225},{\"end\":84237,\"start\":84236},{\"end\":84239,\"start\":84238},{\"end\":84248,\"start\":84247},{\"end\":84259,\"start\":84258},{\"end\":84272,\"start\":84271},{\"end\":84282,\"start\":84281},{\"end\":84293,\"start\":84292},{\"end\":84303,\"start\":84302},{\"end\":84313,\"start\":84312},{\"end\":84592,\"start\":84591},{\"end\":84601,\"start\":84600},{\"end\":84812,\"start\":84811},{\"end\":84814,\"start\":84813},{\"end\":84822,\"start\":84821},{\"end\":85035,\"start\":85034},{\"end\":85044,\"start\":85043},{\"end\":85051,\"start\":85050},{\"end\":85057,\"start\":85052},{\"end\":85061,\"start\":85060},{\"end\":85069,\"start\":85068},{\"end\":85080,\"start\":85079},{\"end\":85082,\"start\":85081},{\"end\":85093,\"start\":85092},{\"end\":85099,\"start\":85098},{\"end\":85109,\"start\":85108},{\"end\":85118,\"start\":85117},{\"end\":85120,\"start\":85119},{\"end\":85132,\"start\":85131},{\"end\":85142,\"start\":85141},{\"end\":85154,\"start\":85153},{\"end\":85162,\"start\":85161},{\"end\":85490,\"start\":85489},{\"end\":85500,\"start\":85499},{\"end\":85689,\"start\":85688},{\"end\":85699,\"start\":85698},{\"end\":85711,\"start\":85710},{\"end\":85927,\"start\":85926},{\"end\":85945,\"start\":85944},{\"end\":85954,\"start\":85953},{\"end\":85964,\"start\":85963},{\"end\":85975,\"start\":85974},{\"end\":85986,\"start\":85985},{\"end\":86256,\"start\":86255},{\"end\":86262,\"start\":86261},{\"end\":86473,\"start\":86472},{\"end\":86475,\"start\":86474},{\"end\":86760,\"start\":86759},{\"end\":86766,\"start\":86765},{\"end\":86773,\"start\":86772},{\"end\":86780,\"start\":86779},{\"end\":86787,\"start\":86786},{\"end\":86796,\"start\":86792},{\"end\":87027,\"start\":87026},{\"end\":87034,\"start\":87033},{\"end\":87040,\"start\":87039},{\"end\":87056,\"start\":87055},{\"end\":87067,\"start\":87066},{\"end\":87082,\"start\":87081},{\"end\":87084,\"start\":87083},{\"end\":87605,\"start\":87604},{\"end\":87614,\"start\":87613},{\"end\":87624,\"start\":87623},{\"end\":87638,\"start\":87637},{\"end\":87648,\"start\":87647},{\"end\":87661,\"start\":87660},{\"end\":87663,\"start\":87662},{\"end\":87906,\"start\":87905},{\"end\":87924,\"start\":87923},{\"end\":88174,\"start\":88173},{\"end\":88184,\"start\":88183},{\"end\":88190,\"start\":88189},{\"end\":88204,\"start\":88203},{\"end\":88212,\"start\":88211},{\"end\":88220,\"start\":88219},{\"end\":88232,\"start\":88231},{\"end\":88240,\"start\":88239},{\"end\":88251,\"start\":88250},{\"end\":88520,\"start\":88519},{\"end\":88531,\"start\":88530},{\"end\":88542,\"start\":88541},{\"end\":88544,\"start\":88543},{\"end\":88553,\"start\":88552},{\"end\":88792,\"start\":88791},{\"end\":88794,\"start\":88793},{\"end\":88803,\"start\":88802},{\"end\":89041,\"start\":89040},{\"end\":89048,\"start\":89047},{\"end\":89055,\"start\":89054},{\"end\":89061,\"start\":89060},{\"end\":89068,\"start\":89067},{\"end\":89076,\"start\":89075},{\"end\":89085,\"start\":89084},{\"end\":89091,\"start\":89090},{\"end\":89360,\"start\":89359},{\"end\":89551,\"start\":89550},{\"end\":89562,\"start\":89561},{\"end\":89564,\"start\":89563},{\"end\":89573,\"start\":89572},{\"end\":89575,\"start\":89574},{\"end\":89779,\"start\":89778},{\"end\":89792,\"start\":89791},{\"end\":89803,\"start\":89802},{\"end\":89813,\"start\":89812},{\"end\":89822,\"start\":89821},{\"end\":90080,\"start\":90079},{\"end\":90088,\"start\":90087},{\"end\":90094,\"start\":90093},{\"end\":90100,\"start\":90099},{\"end\":90108,\"start\":90107},{\"end\":90110,\"start\":90109},{\"end\":90119,\"start\":90118},{\"end\":90379,\"start\":90378},{\"end\":90390,\"start\":90389},{\"end\":90639,\"start\":90638},{\"end\":90641,\"start\":90640},{\"end\":90653,\"start\":90652},{\"end\":90666,\"start\":90665},{\"end\":90867,\"start\":90866},{\"end\":90869,\"start\":90868},{\"end\":90881,\"start\":90880},{\"end\":90892,\"start\":90891},{\"end\":91089,\"start\":91088},{\"end\":91096,\"start\":91095},{\"end\":91102,\"start\":91101},{\"end\":91307,\"start\":91306},{\"end\":91314,\"start\":91313},{\"end\":91320,\"start\":91319},{\"end\":91329,\"start\":91328},{\"end\":91555,\"start\":91554},{\"end\":91562,\"start\":91561},{\"end\":91571,\"start\":91570},{\"end\":91577,\"start\":91576},{\"end\":91585,\"start\":91584},{\"end\":91592,\"start\":91591},{\"end\":91831,\"start\":91830},{\"end\":91839,\"start\":91838},{\"end\":91848,\"start\":91847},{\"end\":91855,\"start\":91854},{\"end\":91861,\"start\":91860},{\"end\":91870,\"start\":91869},{\"end\":92113,\"start\":92112},{\"end\":92115,\"start\":92114},{\"end\":92127,\"start\":92126},{\"end\":92133,\"start\":92132},{\"end\":92313,\"start\":92312},{\"end\":92324,\"start\":92323},{\"end\":92335,\"start\":92334},{\"end\":92345,\"start\":92344},{\"end\":92358,\"start\":92357},{\"end\":92367,\"start\":92366},{\"end\":92369,\"start\":92368},{\"end\":92378,\"start\":92377},{\"end\":92388,\"start\":92387},{\"end\":92644,\"start\":92643},{\"end\":92652,\"start\":92651},{\"end\":92658,\"start\":92657},{\"end\":92665,\"start\":92664},{\"end\":92893,\"start\":92892},{\"end\":92899,\"start\":92898},{\"end\":92906,\"start\":92905},{\"end\":92914,\"start\":92913},{\"end\":92922,\"start\":92921},{\"end\":92929,\"start\":92928},{\"end\":93175,\"start\":93174},{\"end\":93181,\"start\":93180},{\"end\":93188,\"start\":93187},{\"end\":93196,\"start\":93195},{\"end\":93204,\"start\":93203},{\"end\":93447,\"start\":93446},{\"end\":93453,\"start\":93452},{\"end\":93461,\"start\":93460},{\"end\":93467,\"start\":93466},{\"end\":93475,\"start\":93474},{\"end\":93483,\"start\":93482},{\"end\":93491,\"start\":93490},{\"end\":93736,\"start\":93732},{\"end\":93744,\"start\":93743},{\"end\":93751,\"start\":93750},{\"end\":93758,\"start\":93757},{\"end\":93764,\"start\":93763},{\"end\":93771,\"start\":93770},{\"end\":94000,\"start\":93999},{\"end\":94008,\"start\":94007},{\"end\":94019,\"start\":94018},{\"end\":94021,\"start\":94020},{\"end\":94033,\"start\":94032},{\"end\":94037,\"start\":94034},{\"end\":94045,\"start\":94044},{\"end\":94267,\"start\":94266},{\"end\":94275,\"start\":94274},{\"end\":94283,\"start\":94282},{\"end\":94291,\"start\":94290},{\"end\":94482,\"start\":94481},{\"end\":94490,\"start\":94489},{\"end\":94498,\"start\":94497},{\"end\":94506,\"start\":94505},{\"end\":94514,\"start\":94513},{\"end\":94697,\"start\":94696},{\"end\":94706,\"start\":94705},{\"end\":94713,\"start\":94712},{\"end\":94719,\"start\":94718},{\"end\":94727,\"start\":94726},{\"end\":94734,\"start\":94733},{\"end\":94965,\"start\":94964},{\"end\":94973,\"start\":94972},{\"end\":94981,\"start\":94980},{\"end\":94989,\"start\":94988},{\"end\":95225,\"start\":95224},{\"end\":95232,\"start\":95231},{\"end\":95239,\"start\":95238},{\"end\":95246,\"start\":95245},{\"end\":95470,\"start\":95469},{\"end\":95477,\"start\":95476},{\"end\":95485,\"start\":95484},{\"end\":95491,\"start\":95490},{\"end\":95498,\"start\":95497}]", "bib_author_last_name": "[{\"end\":75830,\"start\":75826},{\"end\":75839,\"start\":75834},{\"end\":75852,\"start\":75843},{\"end\":75863,\"start\":75856},{\"end\":75875,\"start\":75867},{\"end\":75885,\"start\":75881},{\"end\":76102,\"start\":76092},{\"end\":76111,\"start\":76106},{\"end\":76121,\"start\":76115},{\"end\":76132,\"start\":76125},{\"end\":76477,\"start\":76468},{\"end\":76486,\"start\":76481},{\"end\":76498,\"start\":76490},{\"end\":76508,\"start\":76502},{\"end\":76518,\"start\":76512},{\"end\":76780,\"start\":76774},{\"end\":76791,\"start\":76784},{\"end\":76807,\"start\":76795},{\"end\":76817,\"start\":76811},{\"end\":76830,\"start\":76821},{\"end\":77061,\"start\":77058},{\"end\":77068,\"start\":77065},{\"end\":77074,\"start\":77072},{\"end\":77081,\"start\":77078},{\"end\":77087,\"start\":77085},{\"end\":77095,\"start\":77091},{\"end\":77351,\"start\":77347},{\"end\":77359,\"start\":77355},{\"end\":77368,\"start\":77363},{\"end\":77378,\"start\":77372},{\"end\":77389,\"start\":77382},{\"end\":77675,\"start\":77671},{\"end\":77683,\"start\":77679},{\"end\":77691,\"start\":77687},{\"end\":77702,\"start\":77695},{\"end\":77956,\"start\":77948},{\"end\":78204,\"start\":78191},{\"end\":78217,\"start\":78208},{\"end\":78229,\"start\":78221},{\"end\":78242,\"start\":78233},{\"end\":78256,\"start\":78246},{\"end\":78445,\"start\":78438},{\"end\":78455,\"start\":78449},{\"end\":78466,\"start\":78459},{\"end\":78477,\"start\":78470},{\"end\":78486,\"start\":78481},{\"end\":78774,\"start\":78766},{\"end\":78981,\"start\":78978},{\"end\":78989,\"start\":78985},{\"end\":78997,\"start\":78993},{\"end\":79005,\"start\":79001},{\"end\":79014,\"start\":79009},{\"end\":79022,\"start\":79018},{\"end\":79280,\"start\":79277},{\"end\":79298,\"start\":79294},{\"end\":79312,\"start\":79304},{\"end\":79324,\"start\":79316},{\"end\":79332,\"start\":79328},{\"end\":79343,\"start\":79336},{\"end\":79358,\"start\":79347},{\"end\":79366,\"start\":79362},{\"end\":79682,\"start\":79678},{\"end\":79697,\"start\":79686},{\"end\":79706,\"start\":79701},{\"end\":79714,\"start\":79710},{\"end\":79721,\"start\":79718},{\"end\":79731,\"start\":79725},{\"end\":79744,\"start\":79735},{\"end\":79751,\"start\":79748},{\"end\":79760,\"start\":79755},{\"end\":80042,\"start\":80034},{\"end\":80063,\"start\":80046},{\"end\":80073,\"start\":80069},{\"end\":80084,\"start\":80077},{\"end\":80092,\"start\":80088},{\"end\":80322,\"start\":80312},{\"end\":80337,\"start\":80328},{\"end\":80351,\"start\":80343},{\"end\":80608,\"start\":80603},{\"end\":80620,\"start\":80612},{\"end\":80630,\"start\":80624},{\"end\":80640,\"start\":80636},{\"end\":80651,\"start\":80646},{\"end\":81094,\"start\":81092},{\"end\":81101,\"start\":81098},{\"end\":81108,\"start\":81105},{\"end\":81116,\"start\":81112},{\"end\":81125,\"start\":81120},{\"end\":81131,\"start\":81129},{\"end\":81139,\"start\":81135},{\"end\":81376,\"start\":81367},{\"end\":81389,\"start\":81380},{\"end\":81397,\"start\":81393},{\"end\":81411,\"start\":81403},{\"end\":81624,\"start\":81615},{\"end\":81633,\"start\":81628},{\"end\":81647,\"start\":81639},{\"end\":81852,\"start\":81847},{\"end\":81863,\"start\":81856},{\"end\":82070,\"start\":82061},{\"end\":82079,\"start\":82074},{\"end\":82094,\"start\":82083},{\"end\":82108,\"start\":82098},{\"end\":82121,\"start\":82112},{\"end\":82132,\"start\":82125},{\"end\":82388,\"start\":82378},{\"end\":82398,\"start\":82392},{\"end\":82413,\"start\":82404},{\"end\":82630,\"start\":82627},{\"end\":82637,\"start\":82634},{\"end\":82643,\"start\":82641},{\"end\":82857,\"start\":82854},{\"end\":82866,\"start\":82861},{\"end\":82872,\"start\":82870},{\"end\":82879,\"start\":82876},{\"end\":82887,\"start\":82883},{\"end\":83138,\"start\":83133},{\"end\":83147,\"start\":83142},{\"end\":83431,\"start\":83423},{\"end\":83443,\"start\":83435},{\"end\":83993,\"start\":83988},{\"end\":84002,\"start\":83997},{\"end\":84016,\"start\":84006},{\"end\":84234,\"start\":84227},{\"end\":84245,\"start\":84240},{\"end\":84256,\"start\":84249},{\"end\":84269,\"start\":84260},{\"end\":84279,\"start\":84273},{\"end\":84290,\"start\":84283},{\"end\":84300,\"start\":84294},{\"end\":84310,\"start\":84304},{\"end\":84320,\"start\":84314},{\"end\":84598,\"start\":84593},{\"end\":84609,\"start\":84602},{\"end\":84819,\"start\":84815},{\"end\":84830,\"start\":84823},{\"end\":85041,\"start\":85036},{\"end\":85048,\"start\":85045},{\"end\":85066,\"start\":85062},{\"end\":85077,\"start\":85070},{\"end\":85090,\"start\":85083},{\"end\":85096,\"start\":85094},{\"end\":85106,\"start\":85100},{\"end\":85115,\"start\":85110},{\"end\":85129,\"start\":85121},{\"end\":85139,\"start\":85133},{\"end\":85151,\"start\":85143},{\"end\":85159,\"start\":85155},{\"end\":85174,\"start\":85163},{\"end\":85497,\"start\":85491},{\"end\":85505,\"start\":85501},{\"end\":85696,\"start\":85690},{\"end\":85708,\"start\":85700},{\"end\":85722,\"start\":85712},{\"end\":85942,\"start\":85928},{\"end\":85951,\"start\":85946},{\"end\":85961,\"start\":85955},{\"end\":85972,\"start\":85965},{\"end\":85983,\"start\":85976},{\"end\":85997,\"start\":85987},{\"end\":86259,\"start\":86257},{\"end\":86268,\"start\":86263},{\"end\":86487,\"start\":86476},{\"end\":86763,\"start\":86761},{\"end\":86770,\"start\":86767},{\"end\":86777,\"start\":86774},{\"end\":86784,\"start\":86781},{\"end\":86790,\"start\":86788},{\"end\":86801,\"start\":86797},{\"end\":87031,\"start\":87028},{\"end\":87037,\"start\":87035},{\"end\":87053,\"start\":87041},{\"end\":87064,\"start\":87057},{\"end\":87079,\"start\":87068},{\"end\":87094,\"start\":87085},{\"end\":87611,\"start\":87606},{\"end\":87621,\"start\":87615},{\"end\":87635,\"start\":87625},{\"end\":87645,\"start\":87639},{\"end\":87658,\"start\":87649},{\"end\":87673,\"start\":87664},{\"end\":87921,\"start\":87907},{\"end\":87934,\"start\":87925},{\"end\":88181,\"start\":88175},{\"end\":88187,\"start\":88185},{\"end\":88201,\"start\":88191},{\"end\":88209,\"start\":88205},{\"end\":88217,\"start\":88213},{\"end\":88229,\"start\":88221},{\"end\":88237,\"start\":88233},{\"end\":88248,\"start\":88241},{\"end\":88263,\"start\":88252},{\"end\":88528,\"start\":88521},{\"end\":88539,\"start\":88532},{\"end\":88550,\"start\":88545},{\"end\":88558,\"start\":88554},{\"end\":88800,\"start\":88795},{\"end\":88808,\"start\":88804},{\"end\":89045,\"start\":89042},{\"end\":89052,\"start\":89049},{\"end\":89058,\"start\":89056},{\"end\":89065,\"start\":89062},{\"end\":89073,\"start\":89069},{\"end\":89082,\"start\":89077},{\"end\":89088,\"start\":89086},{\"end\":89096,\"start\":89092},{\"end\":89369,\"start\":89361},{\"end\":89559,\"start\":89552},{\"end\":89570,\"start\":89565},{\"end\":89587,\"start\":89576},{\"end\":89789,\"start\":89780},{\"end\":89800,\"start\":89793},{\"end\":89810,\"start\":89804},{\"end\":89819,\"start\":89814},{\"end\":89829,\"start\":89823},{\"end\":90085,\"start\":90081},{\"end\":90091,\"start\":90089},{\"end\":90097,\"start\":90095},{\"end\":90105,\"start\":90101},{\"end\":90116,\"start\":90111},{\"end\":90123,\"start\":90120},{\"end\":90387,\"start\":90380},{\"end\":90398,\"start\":90391},{\"end\":90650,\"start\":90642},{\"end\":90663,\"start\":90654},{\"end\":90676,\"start\":90667},{\"end\":90878,\"start\":90870},{\"end\":90889,\"start\":90882},{\"end\":90899,\"start\":90893},{\"end\":91093,\"start\":91090},{\"end\":91099,\"start\":91097},{\"end\":91105,\"start\":91103},{\"end\":91311,\"start\":91308},{\"end\":91317,\"start\":91315},{\"end\":91326,\"start\":91321},{\"end\":91332,\"start\":91330},{\"end\":91559,\"start\":91556},{\"end\":91568,\"start\":91563},{\"end\":91574,\"start\":91572},{\"end\":91582,\"start\":91578},{\"end\":91589,\"start\":91586},{\"end\":91595,\"start\":91593},{\"end\":91836,\"start\":91832},{\"end\":91845,\"start\":91840},{\"end\":91852,\"start\":91849},{\"end\":91858,\"start\":91856},{\"end\":91867,\"start\":91862},{\"end\":91873,\"start\":91871},{\"end\":92124,\"start\":92116},{\"end\":92130,\"start\":92128},{\"end\":92139,\"start\":92134},{\"end\":92321,\"start\":92314},{\"end\":92332,\"start\":92325},{\"end\":92342,\"start\":92336},{\"end\":92355,\"start\":92346},{\"end\":92364,\"start\":92359},{\"end\":92375,\"start\":92370},{\"end\":92385,\"start\":92379},{\"end\":92399,\"start\":92389},{\"end\":92649,\"start\":92645},{\"end\":92655,\"start\":92653},{\"end\":92662,\"start\":92659},{\"end\":92671,\"start\":92666},{\"end\":92896,\"start\":92894},{\"end\":92903,\"start\":92900},{\"end\":92911,\"start\":92907},{\"end\":92919,\"start\":92915},{\"end\":92926,\"start\":92923},{\"end\":92934,\"start\":92930},{\"end\":93178,\"start\":93176},{\"end\":93185,\"start\":93182},{\"end\":93193,\"start\":93189},{\"end\":93201,\"start\":93197},{\"end\":93209,\"start\":93205},{\"end\":93450,\"start\":93448},{\"end\":93458,\"start\":93454},{\"end\":93464,\"start\":93462},{\"end\":93472,\"start\":93468},{\"end\":93480,\"start\":93476},{\"end\":93488,\"start\":93484},{\"end\":93494,\"start\":93492},{\"end\":93741,\"start\":93737},{\"end\":93748,\"start\":93745},{\"end\":93755,\"start\":93752},{\"end\":93761,\"start\":93759},{\"end\":93768,\"start\":93765},{\"end\":93774,\"start\":93772},{\"end\":94005,\"start\":94001},{\"end\":94016,\"start\":94009},{\"end\":94030,\"start\":94022},{\"end\":94042,\"start\":94038},{\"end\":94048,\"start\":94046},{\"end\":94272,\"start\":94268},{\"end\":94280,\"start\":94276},{\"end\":94288,\"start\":94284},{\"end\":94295,\"start\":94292},{\"end\":94487,\"start\":94483},{\"end\":94495,\"start\":94491},{\"end\":94503,\"start\":94499},{\"end\":94511,\"start\":94507},{\"end\":94518,\"start\":94515},{\"end\":94703,\"start\":94698},{\"end\":94710,\"start\":94707},{\"end\":94716,\"start\":94714},{\"end\":94724,\"start\":94720},{\"end\":94731,\"start\":94728},{\"end\":94737,\"start\":94735},{\"end\":94970,\"start\":94966},{\"end\":94978,\"start\":94974},{\"end\":94986,\"start\":94982},{\"end\":94993,\"start\":94990},{\"end\":95229,\"start\":95226},{\"end\":95236,\"start\":95233},{\"end\":95243,\"start\":95240},{\"end\":95250,\"start\":95247},{\"end\":95474,\"start\":95471},{\"end\":95482,\"start\":95478},{\"end\":95488,\"start\":95486},{\"end\":95495,\"start\":95492},{\"end\":95502,\"start\":95499}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":7278297},\"end\":76039,\"start\":75781},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":207556454},\"end\":76378,\"start\":76041},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":207167677},\"end\":76711,\"start\":76380},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":14941970},\"end\":76997,\"start\":76713},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":196205749},\"end\":77240,\"start\":76999},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":49299019},\"end\":77588,\"start\":77242},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":15912887},\"end\":77865,\"start\":77590},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":2082499},\"end\":78134,\"start\":77867},{\"attributes\":{\"doi\":\"abs/1905.06397\",\"id\":\"b8\"},\"end\":78434,\"start\":78136},{\"attributes\":{\"doi\":\"arXiv:1710.04087\",\"id\":\"b9\"},\"end\":78697,\"start\":78436},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7577640},\"end\":78903,\"start\":78699},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":18928027},\"end\":79190,\"start\":78905},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":16010903},\"end\":79601,\"start\":79192},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":4557963},\"end\":79969,\"start\":79603},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3684091},\"end\":80268,\"start\":79971},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":386036},\"end\":80525,\"start\":80270},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":12359035},\"end\":81027,\"start\":80527},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":199466280},\"end\":81303,\"start\":81029},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":207032678},\"end\":81570,\"start\":81305},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":8983396},\"end\":81778,\"start\":81572},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":1356505},\"end\":82000,\"start\":81780},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":17507793},\"end\":82314,\"start\":82002},{\"attributes\":{\"id\":\"b22\"},\"end\":82548,\"start\":82316},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":152282311},\"end\":82784,\"start\":82550},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":43100819},\"end\":83033,\"start\":82786},{\"attributes\":{\"id\":\"b25\"},\"end\":83331,\"start\":83035},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":211259202},\"end\":83904,\"start\":83333},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":6972449},\"end\":84174,\"start\":83906},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":6216506},\"end\":84519,\"start\":84176},{\"attributes\":{\"id\":\"b29\"},\"end\":84743,\"start\":84521},{\"attributes\":{\"doi\":\"abs/1609.02907\",\"id\":\"b30\"},\"end\":84970,\"start\":84745},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":1776335},\"end\":85441,\"start\":84972},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":16535573},\"end\":85634,\"start\":85443},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":13780050},\"end\":85858,\"start\":85636},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":6814936},\"end\":86181,\"start\":85860},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":13747961},\"end\":86397,\"start\":86183},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":60827152},\"end\":86665,\"start\":86399},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":202770936},\"end\":86988,\"start\":86667},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":76663467},\"end\":87560,\"start\":86990},{\"attributes\":{\"doi\":\"abs/1806.00770\",\"id\":\"b39\"},\"end\":87844,\"start\":87562},{\"attributes\":{\"doi\":\"103:1-103:40\",\"id\":\"b40\",\"matched_paper_id\":202676397},\"end\":88108,\"start\":87846},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":44063437},\"end\":88470,\"start\":88110},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":14074802},\"end\":88706,\"start\":88472},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":6111745},\"end\":88959,\"start\":88708},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":207758717},\"end\":89282,\"start\":88961},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":13151033},\"end\":89508,\"start\":89284},{\"attributes\":{\"id\":\"b46\"},\"end\":89709,\"start\":89510},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":3226443},\"end\":90016,\"start\":89711},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":11304431},\"end\":90317,\"start\":90018},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":7690873},\"end\":90568,\"start\":90319},{\"attributes\":{\"id\":\"b50\"},\"end\":90828,\"start\":90570},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":207163173},\"end\":91013,\"start\":90830},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":19197215},\"end\":91241,\"start\":91015},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":51605357},\"end\":91472,\"start\":91243},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":204754514},\"end\":91765,\"start\":91474},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":3348552},\"end\":92040,\"start\":91767},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":69930495},\"end\":92283,\"start\":92042},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":13756489},\"end\":92567,\"start\":92285},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":53082628},\"end\":92822,\"start\":92569},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":198354047},\"end\":93097,\"start\":92824},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":202712648},\"end\":93369,\"start\":93099},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":167217453},\"end\":93667,\"start\":93371},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":202121966},\"end\":93932,\"start\":93669},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":174820419},\"end\":94213,\"start\":93934},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":216171897},\"end\":94434,\"start\":94215},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":218870313},\"end\":94635,\"start\":94436},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":174802832},\"end\":94890,\"start\":94637},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":214514932},\"end\":95163,\"start\":94892},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":28913990},\"end\":95386,\"start\":95165},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":199465777},\"end\":95668,\"start\":95388}]", "bib_title": "[{\"end\":75822,\"start\":75781},{\"end\":76088,\"start\":76041},{\"end\":76462,\"start\":76380},{\"end\":76770,\"start\":76713},{\"end\":77054,\"start\":76999},{\"end\":77343,\"start\":77242},{\"end\":77667,\"start\":77590},{\"end\":77944,\"start\":77867},{\"end\":78762,\"start\":78699},{\"end\":78974,\"start\":78905},{\"end\":79273,\"start\":79192},{\"end\":79674,\"start\":79603},{\"end\":80030,\"start\":79971},{\"end\":80306,\"start\":80270},{\"end\":80599,\"start\":80527},{\"end\":81088,\"start\":81029},{\"end\":81363,\"start\":81305},{\"end\":81609,\"start\":81572},{\"end\":81840,\"start\":81780},{\"end\":82057,\"start\":82002},{\"end\":82623,\"start\":82550},{\"end\":82850,\"start\":82786},{\"end\":83419,\"start\":83333},{\"end\":83984,\"start\":83906},{\"end\":84223,\"start\":84176},{\"end\":85032,\"start\":84972},{\"end\":85487,\"start\":85443},{\"end\":85686,\"start\":85636},{\"end\":85924,\"start\":85860},{\"end\":86253,\"start\":86183},{\"end\":86470,\"start\":86399},{\"end\":86757,\"start\":86667},{\"end\":87024,\"start\":86990},{\"end\":87903,\"start\":87846},{\"end\":88171,\"start\":88110},{\"end\":88517,\"start\":88472},{\"end\":88789,\"start\":88708},{\"end\":89038,\"start\":88961},{\"end\":89357,\"start\":89284},{\"end\":89776,\"start\":89711},{\"end\":90077,\"start\":90018},{\"end\":90376,\"start\":90319},{\"end\":90864,\"start\":90830},{\"end\":91086,\"start\":91015},{\"end\":91304,\"start\":91243},{\"end\":91552,\"start\":91474},{\"end\":91828,\"start\":91767},{\"end\":92110,\"start\":92042},{\"end\":92310,\"start\":92285},{\"end\":92641,\"start\":92569},{\"end\":92890,\"start\":92824},{\"end\":93172,\"start\":93099},{\"end\":93444,\"start\":93371},{\"end\":93730,\"start\":93669},{\"end\":93997,\"start\":93934},{\"end\":94264,\"start\":94215},{\"end\":94479,\"start\":94436},{\"end\":94694,\"start\":94637},{\"end\":94962,\"start\":94892},{\"end\":95222,\"start\":95165},{\"end\":95467,\"start\":95388}]", "bib_author": "[{\"end\":75832,\"start\":75824},{\"end\":75841,\"start\":75832},{\"end\":75854,\"start\":75841},{\"end\":75865,\"start\":75854},{\"end\":75877,\"start\":75865},{\"end\":75887,\"start\":75877},{\"end\":76104,\"start\":76090},{\"end\":76113,\"start\":76104},{\"end\":76123,\"start\":76113},{\"end\":76134,\"start\":76123},{\"end\":76479,\"start\":76464},{\"end\":76488,\"start\":76479},{\"end\":76500,\"start\":76488},{\"end\":76510,\"start\":76500},{\"end\":76520,\"start\":76510},{\"end\":76782,\"start\":76772},{\"end\":76793,\"start\":76782},{\"end\":76809,\"start\":76793},{\"end\":76819,\"start\":76809},{\"end\":76832,\"start\":76819},{\"end\":77063,\"start\":77056},{\"end\":77070,\"start\":77063},{\"end\":77076,\"start\":77070},{\"end\":77083,\"start\":77076},{\"end\":77089,\"start\":77083},{\"end\":77097,\"start\":77089},{\"end\":77353,\"start\":77345},{\"end\":77361,\"start\":77353},{\"end\":77370,\"start\":77361},{\"end\":77380,\"start\":77370},{\"end\":77391,\"start\":77380},{\"end\":77677,\"start\":77669},{\"end\":77685,\"start\":77677},{\"end\":77693,\"start\":77685},{\"end\":77704,\"start\":77693},{\"end\":77958,\"start\":77946},{\"end\":78206,\"start\":78189},{\"end\":78219,\"start\":78206},{\"end\":78231,\"start\":78219},{\"end\":78244,\"start\":78231},{\"end\":78258,\"start\":78244},{\"end\":78447,\"start\":78436},{\"end\":78457,\"start\":78447},{\"end\":78468,\"start\":78457},{\"end\":78479,\"start\":78468},{\"end\":78488,\"start\":78479},{\"end\":78776,\"start\":78764},{\"end\":78983,\"start\":78976},{\"end\":78991,\"start\":78983},{\"end\":78999,\"start\":78991},{\"end\":79007,\"start\":78999},{\"end\":79016,\"start\":79007},{\"end\":79024,\"start\":79016},{\"end\":79282,\"start\":79275},{\"end\":79292,\"start\":79282},{\"end\":79300,\"start\":79292},{\"end\":79314,\"start\":79300},{\"end\":79326,\"start\":79314},{\"end\":79334,\"start\":79326},{\"end\":79345,\"start\":79334},{\"end\":79360,\"start\":79345},{\"end\":79368,\"start\":79360},{\"end\":79684,\"start\":79676},{\"end\":79699,\"start\":79684},{\"end\":79708,\"start\":79699},{\"end\":79716,\"start\":79708},{\"end\":79723,\"start\":79716},{\"end\":79733,\"start\":79723},{\"end\":79746,\"start\":79733},{\"end\":79753,\"start\":79746},{\"end\":79762,\"start\":79753},{\"end\":80044,\"start\":80032},{\"end\":80065,\"start\":80044},{\"end\":80075,\"start\":80065},{\"end\":80086,\"start\":80075},{\"end\":80094,\"start\":80086},{\"end\":80324,\"start\":80308},{\"end\":80339,\"start\":80324},{\"end\":80353,\"start\":80339},{\"end\":80610,\"start\":80601},{\"end\":80622,\"start\":80610},{\"end\":80632,\"start\":80622},{\"end\":80642,\"start\":80632},{\"end\":80653,\"start\":80642},{\"end\":81096,\"start\":81090},{\"end\":81103,\"start\":81096},{\"end\":81110,\"start\":81103},{\"end\":81118,\"start\":81110},{\"end\":81127,\"start\":81118},{\"end\":81133,\"start\":81127},{\"end\":81141,\"start\":81133},{\"end\":81378,\"start\":81365},{\"end\":81391,\"start\":81378},{\"end\":81399,\"start\":81391},{\"end\":81413,\"start\":81399},{\"end\":81626,\"start\":81611},{\"end\":81635,\"start\":81626},{\"end\":81649,\"start\":81635},{\"end\":81854,\"start\":81842},{\"end\":81865,\"start\":81854},{\"end\":82072,\"start\":82059},{\"end\":82081,\"start\":82072},{\"end\":82096,\"start\":82081},{\"end\":82110,\"start\":82096},{\"end\":82123,\"start\":82110},{\"end\":82134,\"start\":82123},{\"end\":82390,\"start\":82374},{\"end\":82400,\"start\":82390},{\"end\":82415,\"start\":82400},{\"end\":82632,\"start\":82625},{\"end\":82639,\"start\":82632},{\"end\":82645,\"start\":82639},{\"end\":82859,\"start\":82852},{\"end\":82868,\"start\":82859},{\"end\":82874,\"start\":82868},{\"end\":82881,\"start\":82874},{\"end\":82889,\"start\":82881},{\"end\":83140,\"start\":83131},{\"end\":83149,\"start\":83140},{\"end\":83433,\"start\":83421},{\"end\":83445,\"start\":83433},{\"end\":83995,\"start\":83986},{\"end\":84004,\"start\":83995},{\"end\":84018,\"start\":84004},{\"end\":84236,\"start\":84225},{\"end\":84247,\"start\":84236},{\"end\":84258,\"start\":84247},{\"end\":84271,\"start\":84258},{\"end\":84281,\"start\":84271},{\"end\":84292,\"start\":84281},{\"end\":84302,\"start\":84292},{\"end\":84312,\"start\":84302},{\"end\":84322,\"start\":84312},{\"end\":84600,\"start\":84591},{\"end\":84611,\"start\":84600},{\"end\":84821,\"start\":84811},{\"end\":84832,\"start\":84821},{\"end\":85043,\"start\":85034},{\"end\":85050,\"start\":85043},{\"end\":85060,\"start\":85050},{\"end\":85068,\"start\":85060},{\"end\":85079,\"start\":85068},{\"end\":85092,\"start\":85079},{\"end\":85098,\"start\":85092},{\"end\":85108,\"start\":85098},{\"end\":85117,\"start\":85108},{\"end\":85131,\"start\":85117},{\"end\":85141,\"start\":85131},{\"end\":85153,\"start\":85141},{\"end\":85161,\"start\":85153},{\"end\":85176,\"start\":85161},{\"end\":85499,\"start\":85489},{\"end\":85507,\"start\":85499},{\"end\":85698,\"start\":85688},{\"end\":85710,\"start\":85698},{\"end\":85724,\"start\":85710},{\"end\":85944,\"start\":85926},{\"end\":85953,\"start\":85944},{\"end\":85963,\"start\":85953},{\"end\":85974,\"start\":85963},{\"end\":85985,\"start\":85974},{\"end\":85999,\"start\":85985},{\"end\":86261,\"start\":86255},{\"end\":86270,\"start\":86261},{\"end\":86489,\"start\":86472},{\"end\":86765,\"start\":86759},{\"end\":86772,\"start\":86765},{\"end\":86779,\"start\":86772},{\"end\":86786,\"start\":86779},{\"end\":86792,\"start\":86786},{\"end\":86803,\"start\":86792},{\"end\":87033,\"start\":87026},{\"end\":87039,\"start\":87033},{\"end\":87055,\"start\":87039},{\"end\":87066,\"start\":87055},{\"end\":87081,\"start\":87066},{\"end\":87096,\"start\":87081},{\"end\":87613,\"start\":87604},{\"end\":87623,\"start\":87613},{\"end\":87637,\"start\":87623},{\"end\":87647,\"start\":87637},{\"end\":87660,\"start\":87647},{\"end\":87675,\"start\":87660},{\"end\":87923,\"start\":87905},{\"end\":87936,\"start\":87923},{\"end\":88183,\"start\":88173},{\"end\":88189,\"start\":88183},{\"end\":88203,\"start\":88189},{\"end\":88211,\"start\":88203},{\"end\":88219,\"start\":88211},{\"end\":88231,\"start\":88219},{\"end\":88239,\"start\":88231},{\"end\":88250,\"start\":88239},{\"end\":88265,\"start\":88250},{\"end\":88530,\"start\":88519},{\"end\":88541,\"start\":88530},{\"end\":88552,\"start\":88541},{\"end\":88560,\"start\":88552},{\"end\":88802,\"start\":88791},{\"end\":88810,\"start\":88802},{\"end\":89047,\"start\":89040},{\"end\":89054,\"start\":89047},{\"end\":89060,\"start\":89054},{\"end\":89067,\"start\":89060},{\"end\":89075,\"start\":89067},{\"end\":89084,\"start\":89075},{\"end\":89090,\"start\":89084},{\"end\":89098,\"start\":89090},{\"end\":89371,\"start\":89359},{\"end\":89561,\"start\":89550},{\"end\":89572,\"start\":89561},{\"end\":89589,\"start\":89572},{\"end\":89791,\"start\":89778},{\"end\":89802,\"start\":89791},{\"end\":89812,\"start\":89802},{\"end\":89821,\"start\":89812},{\"end\":89831,\"start\":89821},{\"end\":90087,\"start\":90079},{\"end\":90093,\"start\":90087},{\"end\":90099,\"start\":90093},{\"end\":90107,\"start\":90099},{\"end\":90118,\"start\":90107},{\"end\":90125,\"start\":90118},{\"end\":90389,\"start\":90378},{\"end\":90400,\"start\":90389},{\"end\":90652,\"start\":90638},{\"end\":90665,\"start\":90652},{\"end\":90678,\"start\":90665},{\"end\":90880,\"start\":90866},{\"end\":90891,\"start\":90880},{\"end\":90901,\"start\":90891},{\"end\":91095,\"start\":91088},{\"end\":91101,\"start\":91095},{\"end\":91107,\"start\":91101},{\"end\":91313,\"start\":91306},{\"end\":91319,\"start\":91313},{\"end\":91328,\"start\":91319},{\"end\":91334,\"start\":91328},{\"end\":91561,\"start\":91554},{\"end\":91570,\"start\":91561},{\"end\":91576,\"start\":91570},{\"end\":91584,\"start\":91576},{\"end\":91591,\"start\":91584},{\"end\":91597,\"start\":91591},{\"end\":91838,\"start\":91830},{\"end\":91847,\"start\":91838},{\"end\":91854,\"start\":91847},{\"end\":91860,\"start\":91854},{\"end\":91869,\"start\":91860},{\"end\":91875,\"start\":91869},{\"end\":92126,\"start\":92112},{\"end\":92132,\"start\":92126},{\"end\":92141,\"start\":92132},{\"end\":92323,\"start\":92312},{\"end\":92334,\"start\":92323},{\"end\":92344,\"start\":92334},{\"end\":92357,\"start\":92344},{\"end\":92366,\"start\":92357},{\"end\":92377,\"start\":92366},{\"end\":92387,\"start\":92377},{\"end\":92401,\"start\":92387},{\"end\":92651,\"start\":92643},{\"end\":92657,\"start\":92651},{\"end\":92664,\"start\":92657},{\"end\":92673,\"start\":92664},{\"end\":92898,\"start\":92892},{\"end\":92905,\"start\":92898},{\"end\":92913,\"start\":92905},{\"end\":92921,\"start\":92913},{\"end\":92928,\"start\":92921},{\"end\":92936,\"start\":92928},{\"end\":93180,\"start\":93174},{\"end\":93187,\"start\":93180},{\"end\":93195,\"start\":93187},{\"end\":93203,\"start\":93195},{\"end\":93211,\"start\":93203},{\"end\":93452,\"start\":93446},{\"end\":93460,\"start\":93452},{\"end\":93466,\"start\":93460},{\"end\":93474,\"start\":93466},{\"end\":93482,\"start\":93474},{\"end\":93490,\"start\":93482},{\"end\":93496,\"start\":93490},{\"end\":93743,\"start\":93732},{\"end\":93750,\"start\":93743},{\"end\":93757,\"start\":93750},{\"end\":93763,\"start\":93757},{\"end\":93770,\"start\":93763},{\"end\":93776,\"start\":93770},{\"end\":94007,\"start\":93999},{\"end\":94018,\"start\":94007},{\"end\":94032,\"start\":94018},{\"end\":94044,\"start\":94032},{\"end\":94050,\"start\":94044},{\"end\":94274,\"start\":94266},{\"end\":94282,\"start\":94274},{\"end\":94290,\"start\":94282},{\"end\":94297,\"start\":94290},{\"end\":94489,\"start\":94481},{\"end\":94497,\"start\":94489},{\"end\":94505,\"start\":94497},{\"end\":94513,\"start\":94505},{\"end\":94520,\"start\":94513},{\"end\":94705,\"start\":94696},{\"end\":94712,\"start\":94705},{\"end\":94718,\"start\":94712},{\"end\":94726,\"start\":94718},{\"end\":94733,\"start\":94726},{\"end\":94739,\"start\":94733},{\"end\":94972,\"start\":94964},{\"end\":94980,\"start\":94972},{\"end\":94988,\"start\":94980},{\"end\":94995,\"start\":94988},{\"end\":95231,\"start\":95224},{\"end\":95238,\"start\":95231},{\"end\":95245,\"start\":95238},{\"end\":95252,\"start\":95245},{\"end\":95476,\"start\":95469},{\"end\":95484,\"start\":95476},{\"end\":95490,\"start\":95484},{\"end\":95497,\"start\":95490},{\"end\":95504,\"start\":95497}]", "bib_venue": "[{\"end\":75891,\"start\":75887},{\"end\":76195,\"start\":76134},{\"end\":76526,\"start\":76520},{\"end\":76836,\"start\":76832},{\"end\":77100,\"start\":77097},{\"end\":77396,\"start\":77391},{\"end\":77709,\"start\":77704},{\"end\":77985,\"start\":77958},{\"end\":78187,\"start\":78136},{\"end\":78542,\"start\":78504},{\"end\":78787,\"start\":78776},{\"end\":79029,\"start\":79024},{\"end\":79374,\"start\":79368},{\"end\":79765,\"start\":79762},{\"end\":80099,\"start\":80094},{\"end\":80380,\"start\":80353},{\"end\":80678,\"start\":80653},{\"end\":81146,\"start\":81141},{\"end\":81419,\"start\":81413},{\"end\":81658,\"start\":81649},{\"end\":81870,\"start\":81865},{\"end\":82137,\"start\":82134},{\"end\":82372,\"start\":82316},{\"end\":82649,\"start\":82645},{\"end\":82893,\"start\":82889},{\"end\":83129,\"start\":83035},{\"end\":83478,\"start\":83445},{\"end\":84023,\"start\":84018},{\"end\":84327,\"start\":84322},{\"end\":84589,\"start\":84521},{\"end\":84809,\"start\":84745},{\"end\":85181,\"start\":85176},{\"end\":85522,\"start\":85507},{\"end\":85730,\"start\":85724},{\"end\":86002,\"start\":85999},{\"end\":86273,\"start\":86270},{\"end\":86511,\"start\":86489},{\"end\":86808,\"start\":86803},{\"end\":87129,\"start\":87096},{\"end\":87602,\"start\":87562},{\"end\":87964,\"start\":87948},{\"end\":88271,\"start\":88265},{\"end\":88572,\"start\":88560},{\"end\":88815,\"start\":88810},{\"end\":89102,\"start\":89098},{\"end\":89383,\"start\":89371},{\"end\":89548,\"start\":89510},{\"end\":89849,\"start\":89831},{\"end\":90148,\"start\":90125},{\"end\":90427,\"start\":90400},{\"end\":90636,\"start\":90570},{\"end\":90904,\"start\":90901},{\"end\":91111,\"start\":91107},{\"end\":91339,\"start\":91334},{\"end\":91601,\"start\":91597},{\"end\":91881,\"start\":91875},{\"end\":92145,\"start\":92141},{\"end\":92405,\"start\":92401},{\"end\":92678,\"start\":92673},{\"end\":92941,\"start\":92936},{\"end\":93216,\"start\":93211},{\"end\":93499,\"start\":93496},{\"end\":93781,\"start\":93776},{\"end\":94054,\"start\":94050},{\"end\":94301,\"start\":94297},{\"end\":94525,\"start\":94520},{\"end\":94744,\"start\":94739},{\"end\":94999,\"start\":94995},{\"end\":95257,\"start\":95252},{\"end\":95509,\"start\":95504}]"}}}, "year": 2023, "month": 12, "day": 17}