{"id": 254927623, "updated": "2023-12-14 07:56:53.969", "metadata": {"title": "Neurally-Inspired Hyperdimensional Classification for Efficient and Robust Biosignal Processing", "authors": "[{\"first\":\"Yang\",\"last\":\"Ni\",\"middle\":[]},{\"first\":\"Nicholas\",\"last\":\"Lesica\",\"middle\":[]},{\"first\":\"Fan-Gang\",\"last\":\"Zeng\",\"middle\":[]},{\"first\":\"Mohsen\",\"last\":\"Imani\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "The biosignals consist of several sensors that collect time series information. Since time series contain temporal dependencies, they are difficult to process by existing machine learning algorithms. Hyper-Dimensional Computing (HDC) is introduced as a brain-inspired paradigm for lightweight time series classification. However, there are the following drawbacks with existing HDC algorithms: (1) low classification accuracy that comes from linear hyperdimensional representation, (2) lack of real-time learning support due to costly and non-hardware friendly operations, and (3) unable to build up a strong model from partially labeled data. In this paper, we propose TempHD, a novel hyperdimensional computing method for efficient and accurate biosignal classification. We first develop a novel non-linear hyperdimensional encoding that maps data points into high-dimensional space. Unlike existing HDC solutions that use costly mathematics for encoding, TempHD preserves spatial-temporal information of data in original space before mapping data into high-dimensional space. To obtain the most informative representation, our encoding method considers the non-linear interactions between both spatial sensors and temporally sampled data. Our evaluation shows that TempHD provides higher classification accuracy, significantly higher computation efficiency, and, more importantly, the capability to learn from partially labeled data. We evaluate TempHD effectiveness on noisy EEG data used for a brain-machine interface. Our results show that TempHD achieves, on average, 2.3% higher classification accuracy as well as 7.7\u00d7 and 21.8\u00d7 speedup for training and testing time compared to state-of-the-art HDC algorithms, respectively.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iccad/NiLZI22", "doi": "10.1145/3508352.3549477"}}, "content": {"source": {"pdf_hash": "f303d0df3ae57aa86366757dd2b12daef62c573d", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "a187ea4a98d5899be3c797bba4712c3f08e3b690", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f303d0df3ae57aa86366757dd2b12daef62c573d.txt", "contents": "\nNeurally-Inspired Hyperdimensional Classification for Ef-ficient and Robust Biosignal Processing\nOctober 30-November 3, 2022. October 30-November 3, 2022\n\nYang Ni \nUniversity of California Irvine\n\n\nNicholas Lesica \nUniversity College London\n\n\nFan-Gang Zeng \nUniversity of California Irvine\n\n\nMohsen Imani \nUniversity of California Irvine\n\n\nYang Ni \nUniversity of California Irvine\n\n\nNicholas Lesica \nUniversity College London\n\n\nFan-Gang Zeng \nUniversity of California Irvine\n\n\nMohsen Imani \nUniversity of California Irvine\n\n\nNeurally-Inspired Hyperdimensional Classification for Ef-ficient and Robust Biosignal Processing\n\nIEEE/ACM Interna-tional Conference on Computer-Aided Design (ICCAD '22)\nSan Diego, CA, USA 2022; San Diego, CA, USAOctober 30-November 3, 2022. October 30-November 3, 202210.1145/3508352.3549477. ACM, New York, NY, USA, 9 pages. https://\nThe biosignals consist of several sensors that collect time series information. Since time series contain temporal dependencies, they are difficult to process by existing machine learning algorithms. Hyper-Dimensional Computing (HDC) is introduced as a brain-inspired paradigm for lightweight time series classification. However, there are the following drawbacks with existing HDC algorithms: (1) low classification accuracy that comes from linear hyperdimensional representation, (2) lack of real-time learning support due to costly and non-hardware friendly operations, and (3) unable to build up a strong model from partially labeled data.In this paper, we propose TempHD, a novel hyperdimensional computing method for efficient and accurate biosignal classification. We first develop a novel non-linear hyperdimensional encoding that maps data points into highdimensional space. Unlike existing HDC solutions that use costly mathematics for encoding, TempHD preserves spatialtemporal information of data in original space before mapping data into high-dimensional space. To obtain the most informative representation, our encoding method considers the non-linear interactions between both spatial sensors and temporally sampled data. Our evaluation shows that TempHD provides higher classification accuracy, significantly higher computation efficiency, and, more importantly, the capability to learn from partially labeled data. We evaluate TempHD effectiveness on noisy EEG data used for a brain-machine interface. Our results show that TempHD achieves, on average, 2.3% higher classification accuracy as well as 7.7\u00d7 and 21.8\u00d7 speedup for training and testing time compared to state-of-the-art HDC algorithms, respectively.\n\nINTRODUCTION\n\nIn many real-world applications, data are captured over the course of time, constituting a time series. Particularly, biosignals consist of several sensors that collect time series information [1]. Since time series contain temporal dependencies, it is often difficult to analyze them using machine learning algorithms. Deep learning algorithms have been commonly used to extract incident patterns or insights from data and build a supervised learning model. However, the current deep learning models have a weak notion of memorization, while biosignals often deal with temporal information. Recent research tried to use recurrent neural networks (RNN) and Long short-term memory (LSTM) to learn and memorize spatial-temporal information [2,3]. However, these models are significantly difficult and inefficient to train. In addition, running deep learning algorithms requires large off-chip memory to store train data and perform many learning iterations [4]. This resource requirement is often above the capability of today's embedded devices. Lastly, deep learning solutions require many train data to build up a reliable model, while in practice, it is costly and sometimes impossible to collect such labeled data.\n\nHyper-Dimensional Computing (HDC) is introduced as an alternative paradigm that mimics important brain functionalities towards high-efficiency and noise-tolerant computation [4][5][6][7][8]. HDC is motivated by the observation that the human brain operates on high-dimensional data representations. In HDC, objects are thereby encoded with highdimensional vectors, called hypervectors, which have thousands of elements [5]. HDC incorporates learning capability along with typical memory functions of storing/loading information. This makes HDC capable of dealing with noisy time-series data. In addition, HDC mimics important functionalities of the human memory model with vector operations, which are computationally tractable and mathematically rigorous in describing human cognition.\n\nSeveral recent works used HDC as a lightweight solution for biosignal classification. For example, works in [9][10][11][12][13] used HDC for real-time classification from Electroencephalography (EEG) and Electromyography (EMG) sensors.\n\nA key advantage is HDC training capability in one or a few shots, where data can be learned with few iterations. Research above already achieved comparable accuracy with fewer learning iterations as compared to support vector machines (SVMs), gradient boosting, and neural networks. Despite the success, there are three major drawbacks with the existing HDC solutions: (1) HDC algorithms use non-flexible mathematics, which has difficulty in encoding and representing complex time-series data. This results in a lower learning accuracy over complex time-series tasks. (2) The current HDC encoding methods use costly high-dimensional operations to preserve spatial-temporal relations. These operations are not friendly with existing embedded processors. For example, existing HDC methods use permutation (rotational shift) operation to preserve the orders in a sequence. Implementing this operation in the current CPU/GPU requires thousands of read/write operations in memory. (3) The existing HDC algorithms are sensitive to the amount of labeled data provided to learn a model. This is an essential factor for biosignal processing, as collecting labeled data is often very costly or sometimes impossible.\n\nIn this paper, we propose TempHD, a novel hyperdimensional computing method for efficient and accurate biosignal classification. Our solution provides a better representation of data in high-dimensional space with higher separability, thus providing a higher learning capability and classification accuracy with fewer labeled samples. The main contributions of the paper are as follows:\n\n\u2022 In contrast to the existing HDC algorithms that linearly map data points into the hyperspace, we develop a nonlinear encoding, inspired by the Kernel method, that maps spatial information into high-dimensional space. The proposed encoding explicitly considers the non-linear interactions between the input features. This enables TempHD to have a more informative representation, thus providing easier data separation in high-dimension. \u2022 We expand the proposed non-linear encoder to also preserve temporal information. Instead of using costly highdimensional mathematics, TempHD represents temporal information by sorting original data before feeding them into kernel encoding. This eliminates thousands of operations that are currently required to implement a simple ordering of signals in high-dimension. Our solution also considers the interactions between the correlated sampled signals, thus reducing sensitivity to the sampling noise. \u2022 We develop learning algorithms that adaptively update HDC model to eliminate possible model saturation. During training, we update HDC model adaptively depending on the already stored information in the model. This results in a higher learning accuracy. We evaluate TempHD effectiveness on noisy EEG data used for brain-machine interface [14]. Our evaluation shows that TempHD provides higher classification accuracy, significantly higher computation efficiency, and, more importantly, the capability to learn from partially labeled data. Our results indicate that TempHD achieves, on average, 2.3% higher classification accuracy as well as 7.7\u00d7 and 21.8\u00d7 speedup for training and testing time compared to state-of-the-art HDC algorithms, respectively.\n\n\nHYPERDIMENSIONAL COMPUTING\n\nHyper-Dimensional computing (HDC) is based on the understanding that brains compute with patterns of neural activity that are not readily associated with numbers. Due to the very size of the brain's circuits, neural patterns can be modeled with hypervectors [5]. HDC builds upon a well-defined set of operations with random hypervectors, is extremely robust in the presence of failures, and offers a complete computational paradigm that is easily applied to learning problems. There exist a huge number of different, nearly orthogonal hypervectors with dimensionality in the thousands. Figure 1 shows an overview of HDC learning. The first step in HDC is to encode data into high-dimensional space. Then, HDC performs a learning task over encoder data by performing a single-pass training. The result of training will be to generate a hypervector representing each class. The inference task can be performed by checking the similarity of an encoded query to the class hypervector.\n\n\nHDC Primitives\n\nThe encoder is the most important component of hyperdimensional learning. The goal of the encoder is to map data into high-dimensional space such that we can extract knowledge from data at a lower cost. The HDC encoding is performed based on a well-defined set of mathematics. Let \n\n\nTime-series Encoding\n\nAs Figure 2a shows, the time series often get sampled in an -gram window. In each sampling window, the signal values (in the y-axis) store the information, and the time (x-axis) represents the sequence. We assign a random vector to ( \u00ec representing minimum signal value) and ( \u00ec representing maximum signal value). Since these vectors are randomly generated, they are nearly orthogonal. For signal values between and , we perform vector quantization to generate vectors that have a spectrum of similarity to \u00ec and \u00ec . Finally, the encoding can be performed by binding the level hypervectors corresponding to sampled signal while using permutation to store the timing information. For example shown in Figure 2a, the trigram Windows can be encoded as \u00ec H = \u00ec 3 * \u00ec 2 * \u00ec 1 . Note that for time-series, the encoding repeats after moving a sliding window one time-step ahead. This will generate a large number of encoded data that can be used for training.\n\nFor applications with multi-sensors, the encoding follows the same procedure for each sensor using synchronized -gram windows. Let us assume a problem with sensors, where sensors generate the following encoded hyper-\nvectors { \u00ec H 1 , \u00ec H 2 , \u00b7 \u00b7 \u00b7 , \u00ec H }.\nWe accordingly generate random hypervector, where each is a signature of a sensor { \u00ec P 1 , \u00ec P 2 , \u00b7 \u00b7 \u00b7 , \u00ec P }. To aggregate information, the encoded hypervector from each sensor will be binded (associated) with the corresponding identification hypervector:\n\u00ec H = \u00ec P 1 * \u00ec H 1 + \u00ec P 2 * \u00ec H 2 + \u00b7 \u00b7 \u00b7 + \u00ec P * \u00ec H(1)\nwhere '+' memorizes the sensor information and each \u00ec P preserves the position of a sensor.\n\n\nChallenges\n\nDespite the effectiveness of the above encoding and learning methods, There is still three main drawbacks that are listed below: \u2022 The existing encoding methods linearly combine the hypervectors corresponding to each feature, resulting in suboptimal classification quality for general and complex classification problems. To obtain the most informative hypervectors, the HDC encoding should consider the non-linear interactions between the spatial sensors and temporally sampled data. \u2022 The encoding method is associated with high computational cost. For example, the permutation used to preserve the temporal correlation is not hardware friendly as it requires thousands of read/write operations in memory. Figure 2b shows the breakdown of HDC execution time.\n\nOur evaluation shows that the encoding module takes 99.9% and 99.8% of total execution time during training and inference. The results are reported when classifying EEG signals running state-of-the-art HDC algorithms on the CPU. The details of the experimental platform and dataset are listed in Section 5. \u2022 The current HDC models are weak in learning from partially labeled data. However, in practice, it is hard or impossible to collect labeled data from biosensors. Therefore, it is essential to develop algorithms that can effectively learn from few labeled data.\n\n\nKERNEL-BASED ENCODING\n\nIn this section, we introduce our encoding method that exploits the kernel trick [15,16] to map data points into the high-dimensional space. The underlying idea of the kernel trick is that data, which is not linearly separable in original dimensions, might be linearly separable in higher dimensions. Let us consider certain functions ( , ) which are equivalent to the dot product in a different space, such that\n( , ) = \u03a6( ) \u00b7 \u03a6( ), where \u03a6(\u00b7)\nis often a function for high dimensional projection. We can take advantage of this implicit mapping by replacing their decision function with a weighted sum of kernels:\n(\u00b7) = =0 (\u00b7, )(2)\nwhere ( , ) is the training data sample, and the s are constant weights. The study in [15] showed that the inner f1 f2 fn  product can efficiently approximate Radial Basis Function (RBF) kernel, such that:\n\u00d7 \u00d7 \u00d7 h b D h b 2 h b 1 B 1 B( , ) = \u03a6( ) \u00b7 \u03a6( ) \u2248 ( ) \u00b7 ( )(3)\nThe Gaussian kernel function can now be approximated by the dot product of two vectors, ( ) and ( ).\n\nThe proposed encoding method is inspired by the RBF kernel trick method. Figure 3 shows our encoding procedure. Assume an input vector in original space \u00ec = { 1 , 2 , \u00b7 \u00b7 \u00b7 , } and \u00ec \u2208 R . The encoding module maps this vector into highdimensional vector, \u00ec\nH = {\u210e 1 , \u210e 2 , \u00b7 \u00b7 \u00b7 , \u210e } \u2208 R ,\nwhere . The following equation shows an encoding method that maps input vector into high-dimensional space:\n\u210e = cos( \u00ec \u00b7 \u00ec B + ) sin( \u00ec \u00b7 \u00ec B )(4)\nwhere \u00ec B s are randomly chosen hence orthogonal base hypervectors of dimension 10 to retain the spatial or temporal location of features in an input and \u223c U(0, 2 ). That is, \u00ec B \u223c N (0, 1) and ( \u00ec B 1 , \u00ec B 2 ) 0, where denotes the cosine similarity. However, this activation is not a convex function, thus making it impossible to back-propagate from HDC encoder. To enable HDC model to support backpropagation, one can decide to exploit hyperbolic tangent function as an activation function: \u210e = tanh ( \u00ec \u00b7 \u00ec B + ).\n\n\nNon-Linear Time-Series Encoding\n\nThe above encoding is explained in the context of feature vectors to preserve spatial correlation. However, time series encoding also needs to preserve temporal information. Here, we show how the proposed kernel-based encoding can be extended to support temporal correlation. Let us consider the time series data shown in Figure 4a. We first sample data in an -gram window. The window size depends on the nature of the signal and sampling time; however, it is often smaller than the time-series length. Regardless of windows size, the goal of HDC encoding is to represent the pattern of a sampled signal as a high-dimensional pattern. In this representation, we need to store sampled values along with the corresponding time that they occur. In the example shown in Figure 4b, we sort the sampled signal value depending on their sampling time. In our example, { 1 , 2 , \u00b7 \u00b7 \u00b7 , } are happening in { 1 , 2 , \u00b7 \u00b7 \u00b7 , }. As Figure 4b shows, this temporally sorted data can be treated as a feature vector; thus, it can be mapped using our proposed kernel-based encoder (explained in Section 3).\n\nTo encode the entire time-series, the -gram windows will move over the signal in an overlapping manner. Our encoding repeats the same process by sorting the sampled signal values and feeding them into our non-linear encoder. This process continues until covering the entire time-series data. In the case of using a single sensor, the encoded data can be sent to the classification module for training. However, in practice, many biosignals often have multiple sensor data. For example, conventional EEG sensors consist of 64 electrodes collecting information of different brain regions [17,18]. Similarly, multi-electrode EMG signals are required for applications such as gesture detection [9]. Our encoding maps the multi-channel encoding by spatially sorting samples obtained from different sensors. Let us assume an example with sensors; all sampled synchronously over -gram windows. To consider the location of each sensor, our solution not only sorts the sampled signal from each sensor but also sorts the sample based on the index of the sensor. For example, the samples coming from sensor 1 will locate in indices [1 : ], while the \u210e sensor samples will locate in [ \u00d7 ( \u2212 1) + 1 : \u00d7 ] indices. This spatially sorted sensor signals will be a vector with \u00d7 length and can be sent to our proposed kernel encoder for projecting into high-dimensional space (Figure 4c).\n\nThis encoding provides multiple advantages as compared to existing hyperdimensional encoding for time-series encoding:\n\n(1) Quality of Encoding: Each row of the kernel encoder is a projection vector that adds up spatial-temporal information of all sensors with different weights (Figure 4d). Since the weights are non-binary, the encoder considers the non-linear interactions between the sensors and their temporal samples. In addition, the activation function used after the mapping mathematically gives non-linearity to our encoder to better represent data in high-dimension. This is an important factor since the sensors, e.g., electrodes in EEG sensors, are not independent. For example, physically close electrodes are likely to read correlated data. However, due to the complexity of the systems and sensors, it is hard to learn the relation. Instead, our encoder considers non-linear interactions that possibly occur between them. Note that the existing encoding modules linearly add up the sensor data by associating each sensor with a random bipolar vector. As a result, they have a more linear nature in both temporal and spatial mapping. In Section 5.2, we show how our encoding outperforms existing HDC algorithms in terms of accuracy.\n\nBesides the accuracy, our non-linear data encoding enables better data separation in high-dimensional space. Therefore, our learning models can provide high classification accuracy with very few labeled samples. In Section 5.6, we show HDC capability in learning from partially labeled data.\n\n(2) Computation Efficiency: Existing HDC methods map sampled data into high-dimensional space in a very initial step of an encoding process [9,10,13]. The sampled signals in each time series translate to a hypervector with thousands of dimensions. As a result, both temporal and spatial information needs to be preserved by computing over hypervectors. This means that they require thousands of operations for each encoding operation. Unfortunately, these operations are inefficient existing hardware platforms, such as CPU and GPU. Similar cost associates with spatial encoding, where the position of each sensor is preserved by associating it with a random hypervector. This also involves thousands of computations to ensure a simple and pre-defined sort operation. In contrast, our solution provides a new perspective to develop efficient HDC encoding modules. Our solution ensures both spatial and temporal information to preserve before mapping data into high-dimensional space. As a result, we have much higher parallelism and lower computational costs, which are essential for learning on embedded devices. In Section 5.3, we compare TempHD efficiency with state-of-the-art learning solutions for biosignal classification.\n\n\nHYPERDIMENSIONAL MODEL TRAINING\n\nWe exploit hyperdimensional learning to directly operate over encoded data. Figure 4e shows an overview of HDC classification. HDC identifies common patterns during learning and eliminates the saturation of the class hypervectors during single-pass training. Instead of naively combining all encoded data, our approach adds each encoded data to class hypervectors depending on how much new information the pattern adds to class hypervectors. If a data point already exists in a class hypervector, HDC will add no or a tiny portion of data to the model to prevent hypervector saturation. If the prediction matches the expected output, no update will be made to avoid overfitting. This adaptive update provides a higher chance and weight to non-common patterns to represent the final model. This method can eliminate the necessity of using costly iterative training. Let us assume \u00ec H as a new training data point. HDC computes the cosine similarity of \u00ec H with all class hypervectors \u00ec Cs. We compute similarity of this data point with class as:\n\n= ( \u00ec H, \u00ec C ). Instead of naively adding a data point to the model, HDC updates the model based on the similarity. If an input data has label and correctly matches with the class, the model updates as follows:\n\u00ec C \u2190 \u00ec C + 1 (1 \u2212 ) \u00d7 \u00ec H (5)\nwhere is a learning rate. A large indicates that the input is a common data point which is already exist in the model. Therefore, our update adds a very small portion of encoded query to model to eliminate model saturation (1 \u2212 0). If the input data get an incorrect label of , the model updates as:\n\u00ec C \u2190 \u00ec C \u2212 2 ( \u2212 ) \u00d7 \u00ec H (6)\nwhere \u2212 determines the weight that the model needs to be updated. Small \u2212 indicates that the query is marginally mismatched while larger mismatch is updated with a larger factor ( \u2212 0).\n\n\nHyperdimensional Inference\n\nIn inference, HDC checks the similarity of each encoded test data with the class hypervector in two steps. The first step encodes the input (the same encoding used for training) to produce a query hypervector \u00ec H . Then we compute the similarity ( ) of \u00ec H and all class hypervectors. Query data gets the label of the class with the highest similarity.\n\n\nEVALUATION 5.1 Experimental Setup\n\nOur method is general and applicable to classify a wide range of biosignals, including multi-channel EMG and EEG signals. In this work, we look at a particular application of TempHD in the noninvasive Brain-Computer Interfaces (BCI). One of the targets in BCI is to recognize user intention from collected biosignals, thereby enables controlling without body movement. For example, in [1,19,20], they request the human user to move a cursor to a specific location using mental commands. However, direct prediction for human intention using noninvasive biosignals often leads to low accuracy. Thus, researchers approach this problem by using error-related biosignals, e.g., EEG error-related potentials (ERP). Instead of being directly controlled by BCI and recognized human intention, the computer operates and learns by itself. In addition, it also tries to recognize the human response to its behavior via ERP, i.e., whether the human considers its behavior as correct or not. Our TempHD is particularly designed to classify biosignal with high efficiency and lower inference delay, so it is suitable for ERP recognition in BCI control tasks.\n\nAs the workload for our design, we use ERP signals collected using EEG sensors [14]. In this particular dataset, EEG signals are collected from six subjects using 64 electrodes. The task for subjects is moving a cursor to a target location, which is similar to the example we mentioned before. However, they have no control over the computer, and the cursor is moving by itself either towards the correct direction or the wrong one. For each trial, the probability of the cursor moving in the wrong direction is 0.2. Subjects are requested to judge the correctness of direction, and researchers collect the corresponding EEG signals of six subjects. The trial is labeled according to the correctness of the cursor direction. We use TempHD for direct ERP classification by learning on the EEG 64-channel raw waveform. We only apply simple data preprocessing, which is a band-pass filter of 1-10 Hz for noise reduction. The waveform length of each trial is around 2000 ms with the sampling rate of 512 Hz; and the effective time window of each trial is up to 600 ms. We use downsampling to reduce the number of data points in each time window for efficient HDC learning. The parameters of this dataset are shown in Table 1.\n\nDuring the experiment on this dataset, we test our TempHD by comparing the accuracy and efficiency with SVM and previous HDC method for time-series data, which is described in Section 2.2. We also compare the performance of two HDC methods under different dimensionality settings. By varying the size of the training dataset, we present the different learning accuracy of each method. The default dimensionality for both HDC methods is 10000, except for Section 5.4 where the  S1  250  128  8  16  S2  450  230  8  29  S3  250  128  8  16  S4  600  307  16  19  S5  450  230  8  29  S6 450 230 8 29 Figure 5: Single-subject accuracy and multi-subject average accuracy comparison between TempHD, NgramHD, and SVM dimensionality changes from 500 to 10000. The default number of iterations for TempHD training is 300. We collect all the results on the CPU platform with AMD Ryzen-5 3600X.\n\n\nTempHD Accuracy\n\nIn Figure 5, we show the classification accuracy for each subject and the average accuracy over all six subjects. We compare the results of our TempHD with two methods: i) state-of-the-art HDC classification (NgramHD) [9,21], and ii) support vector machine (SVM). TempHD with non-linear encoding achieves better accuracy in subjects 1 to 4 and also multi-subject average. Our TempHD gets around 80% accuracy for subject 1 and subject 3; it also achieves 73% accuracy, on average, which is about 3% higher than the NgramHD method's accuracy. In addition, TempHD significantly improves the accuracy compared to SVM. For example, TempHD accuracy is 15.5% higher in subject 6 and 10% higher on average.\n\n\nTempHD Efficiency\n\nAs shown in Figure 6, we collect the runtime results for training and testing on each subject for TempHD, NgramHD, and SVM. Although the accuracy results for SVM are the lowest, it achieves the fastest training and testing among the three methods because the dataset sizes are relatively small. However, SVM is known to require a long training time for large datasets, and biosignal datasets may include a large amount of data for practical applications. Our TempHD, on the other hand, not only achieves the highest accuracy but also significantly improves the runtime cost comparing to the previous HDC method. The speedup of TempHD over NgramHD is around 7.7\u00d7 for average training runtime; and for average testing runtime, the speedup is about 21.8\u00d7. The results show that our TempHD is more suitable and more efficient for biosignal and multi-channel time series classification.\n\nWe also explore the performance scalability of SVM and our TempHD by increasing the dataset size so that we can better infer the performance of both methods with larger biosignal datasets. We pick the training and testing dataset for subject 1 and expand it with different ratios from about 5\u00d7 to 200\u00d7. The original training and testing dataset size are 489 and 555, respectively. We present the results in Table 2, which records the training and testing runtime for different dataset sizes. We observe that the training time of SVM grows much faster than that of TempHD. SVM is faster in training when the dataset size is small; however, it is nearly 8\u00d7 slower than TempHD when the number of training samples is 100k. In fact, SVM also has a larger testing time when we increase the dataset size, i.e., about 2\u00d7 slower for testing when we expand the testing samples to 112k. Both results align with the fact that SVM is slow for large datasets. On the other hand, our TempHD scales better with increasing dataset size.\n\n\nTempHD & Dimensionality\n\nIn this section, we explore the effect of dimensionality on both classification accuracy and runtime. As shown in Figure 7, we compare the performance and efficiency of our TempHD and NgramHD under different dimensions. The accuracy and runtime results are averaged over six subjects. When increasing the dimensionality from 500 to 10,000, we observe that the accuracy and runtime for both methods increase as expected. However, TempHD constantly achieves better accuracy and has significantly lower runtime cost for all dimension settings. Notice that in Figure 7(a), our TempHD achieves over 70% accuracy with dimensions lower than 1000. This improvement over the previous HDC method is crucial because lower dimensionality leads to lower computation and runtime cost, especially for low-power devices. In  \n\n\nTempHD Breakdown\n\nIn Figure 8, we present the breakdown pie chart for the execution time of training and testing. The encoding time of TempHD still dominates in both the training and testing process, i.e., 65.1% for training set encoding and 99.6% for testing set encoding. Unlike the learning process in NgramHD, which takes up only 0.1% of the total training time, the adaptive multi-iteration learning in TempHD composes 34.9%. Although iterative learning requires more execution time, the fast encoding of TempHD significantly reduces the overall training time. Also, our iterative learning with an adaptive learning rate is the key to higher accuracy.\n\n\nTempHD with Partial Train Data\n\nIn Figure 9, we observe the change of average classification accuracy with varying percentages of training trials. We randomly sample a portion of training samples from the training dataset with the percentage changing from 10% to 90%. Notice that our TempHD provides nearly 60% accuracy with only 10% of the training samples. This is an appealing characteristic because the number of training samples is usually limited in practical applications. The figure also shows that TempHD constantly achieves better accuracy than NgramHD and significantly improves the classification quality comparing to the SVM method.  \n\n\nRELATED WORKS\n\nPrior research have applied the idea of hyperdimensional computing to diverse learning and cognitive tasks, such as graph reasoning [22], robotics [23], neuromorphic computing [24], language recognition [25], genome sequencing [26] and activity recognition [9,27]. Particularly, several recent works aimed to use HDC in area of biosignal sensors (i.e., EEG, EMG, or EXG sensors) for diverse tasks, including brain-computer interfaces, seizure identification, emotion detection, activity recognition, and gesture detection [9][10][11][12][13]. These methods often provide comparable accuracy to existing machine learning models while requiring a significantly lower computational cost. However, all existing HDC algorithms use a linear encoder with non-hardware-friendly operations. This makes HDC very inefficient as it requires to use of large dimensionality to solve realistic problems.\n\nTo the best of our knowledge, TempHD is the first effort to design a highly accurate and efficient HDC classification for biosignal. Our approach maps data points in a non-linear manner with higher separability in high-dimensional space. This results in higher classification accuracy as well as the capability to learn from fewer samples. Prior works also proposed different hardware acceleration for HDC, using ASIC [28][29][30] and processing in-memory [31][32][33][34]. However, these hardware designs are usually not commercially available and need a relatively long period to synthesize and fabricate after deriving the new applications. As such, to ease the deployment of the HDC in the real world, we need a framework solution to run HDC on a highly parallel but general-purpose platform, especially embedded CPU. However, the current HDC algorithms rely on costly highdimensional operations, which are significantly slower than traditional processors. In contrast, we designed a novel HDC classification with hardware-friendly operations. Our solution leverages hardware-friendly mathematics for encoding with significant potential of acceleration in hardware.\n\n\nCONCLUSION\n\nIn this paper, we propose TempHD, a novel hyperdimensional computing method for efficient and accurate biosignal classification. We first develop a novel non-linear hyperdimensional encoding that maps data points into highdimensional space. Unlike existing HDC solutions that use costly mathematics for encoding, TempHD preserves spatialtemporal information of data in original space before mapping data into high-dimensional space. To obtain the most informative representation, our encoding method considers the non-linear interactions between both spatial sensors and temporally sampled data. Our evaluation shows that TempHD provides higher classification accuracy, significantly higher computation efficiency as well as the capability to learn from partially labeled data.\n\nFigure 1 :\n1Hyperdimensional classification during both training and inference.\n\nFigure 2 :\n2(a) Existing time-series encoding and (b) Breakdown of HDC execution time during training and inference.\n\nFigure 3 :\n3Hyperdimensional kernel-based encoder.\n\nFigure 4 :\n4(a-c) Overview of our spatial-temporal encoder, (d) kernel encoder to map the sorted features into highdimension (e) hyperdimensional classification.\n\nFigure 6 :\n6Single-subject and multi-subject average runtime comparison between TempHD, NgramHD, and SVM.\n\nFigure 7 (\n7b) and (c), we observe that TempHD achieves nearly 40\u00d7 speedup in training runtime and about 741\u00d7 speedup in testing with 500 dimensions.\n\nFigure 7 : 000 Figure 8 :\n70008Average accuracy and runtime comparison with varying dimensionality from 500 to 10,TempHD\n\nFigure 9 :\n9accuracy comparison during partial training.\n\nTable 1 :\n1Time window & data points per channel for subjects.Subject \n\nTime \nwindow \n(ms) \n\nData points \nper window \n\nDownsampling \nrate (points/step) \n\nData points \nafter \ndownsampling \n\n\n\nTable 2 :\n2TempHD performance scalability with data size. TempHD 3.0s 5.7s 14.0s 27.6s 55.1s 82.0s 111.3s# Train Samples \n2.5k 5k 12.5k 25k 50k \n75k \n100k \n\nTraining \nSVM \n0.5s 1.2s \n3.1s \n6.1s 12.2s 451.6s 808.0s \n# Test Samples \n2.8k 5.6k 14k \n28k 56k \n84k \n112k \n\nTesting \nSVM \n0.6s 1.4s \n3.3s \n6.8s 13.7s 20.0s 26.5s \nTempHD 0.5s 0.8s \n2.0s \n3.4s 6.8s 10.1s 13.7s \n\n\nACKNOWLEDGEMENTS\nA brain-computer interface framework based on compressive sensing and deep learning. R R Shrivastwa, IEEE Consumer Electronics Magazine. 93R. R. Shrivastwa et al., \"A brain-computer interface framework based on compressive sensing and deep learning, \" IEEE Consumer Electronics Magazine, vol. 9, no. 3, pp. 90-96, 2020.\n\nRobust anomaly detection for multivariate time series through stochastic recurrent neural network. Y Su, ACM SIGKDD KDD. Y. Su et al., \"Robust anomaly detection for multivariate time series through stochastic recurrent neural network, \" in ACM SIGKDD KDD, 2019.\n\nA dual-stage attention-based recurrent neural network for time series prediction. Y Qin, arXiv:1704.02971arXiv preprintY. Qin et al., \"A dual-stage attention-based recurrent neural network for time series prediction, \" arXiv preprint arXiv:1704.02971, 2017.\n\nA framework for collaborative learning in secure high-dimensional space. M Imani, IEEECLOUDM. Imani et al., \"A framework for collaborative learning in secure high-dimensional space, \" in CLOUD. IEEE, 2019, pp. 435-446.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to com- puting in distributed representation with high-dimensional random vectors, \" Cognitive computation, vol. 1, no. 2, pp. 139-159, 2009.\n\nMimhd: Accurate and efficient hyperdimensional inference using multi-bit in-memory computing. A Kazemi, ISLPED. IEEEA. Kazemi et al., \"Mimhd: Accurate and efficient hyperdimensional inference using multi-bit in-memory computing,\" in ISLPED. IEEE, 2021, pp. 1-6.\n\nScalable edge-based hyperdimensional learning system with brain-like neural adaptation. Z Zou, Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. the International Conference for High Performance Computing, Networking, Storage and AnalysisZ. Zou et al., \"Scalable edge-based hyperdimensional learning system with brain-like neural adaptation, \" in Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, 2021, pp. 1-15.\n\nPrid: Model inversion privacy attacks in hyperdimensional learning systems. A Hern\u00e1ndez-Cano, 2021 58th ACM/IEEE Design Automation Conference (DAC). IEEEA. Hern\u00e1ndez-Cano et al., \"Prid: Model inversion privacy attacks in hyperdimensional learning systems,\" in 2021 58th ACM/IEEE Design Automation Conference (DAC). IEEE, 2021, pp. 553-558.\n\nA wearable biosensing system with in-sensor adaptive machine learning for hand gesture recognition. A Moin, Nature Electronics. A. Moin et al., \"A wearable biosensing system with in-sensor adaptive machine learning for hand gesture recognition,\" Nature Electronics, 2021.\n\nHyperdimensional biosignal processing: A case study for emg-based hand gesture recognition. A Rahimi, ICRC. IEEEA. Rahimi et al., \"Hyperdimensional biosignal processing: A case study for emg-based hand gesture recognition,\" in ICRC. IEEE, 2016, pp. 1-8.\n\nSystematic assessment of hyperdimensional computing for epileptic seizure detection. U Pale, arXiv:2105.00934arXiv preprintU. Pale et al., \"Systematic assessment of hyperdimensional computing for epileptic seizure detection, \" arXiv preprint arXiv:2105.00934, 2021.\n\nHyperdimensional computing-based multimodality emotion recognition with physiological signals. E.-J Chang, AICAS. IEEEE.-J. Chang et al., \"Hyperdimensional computing-based multimodality emotion recognition with physiological signals,\" in AICAS. IEEE, 2019, pp. 137-141.\n\nDetection of epileptic seizures from surface eeg using hyperdimensional computing. F Asgarinejad, EMBC. IEEEF. Asgarinejad et al., \"Detection of epileptic seizures from surface eeg using hyperdimensional computing,\" in EMBC. IEEE, 2020, pp. 536-540.\n\nMonitoring error-related potentials. \"Monitoring error-related potentials.\" 2020. [Online]. Available: http://bnci-horizon-2020.eu/database/data-sets\n\nRandom features for large-scale kernel machines. A Rahimi, B Recht, NIPS. 35A. Rahimi, B. Recht et al., \"Random features for large-scale kernel machines. \" in NIPS, vol. 3, no. 4. Citeseer, 2007, p. 5.\n\nWeighted sums of random kitchen sinks: replacing minimization with randomization in learning. A Rahimi, B Recht, Nips. Citeseer. A. Rahimi and B. Recht, \"Weighted sums of random kitchen sinks: replacing minimization with randomization in learning. \" in Nips. Cite- seer, 2008, pp. 1313-1320.\n\nSpatial filter selection for eeg-based communication. D J Mcfarland, Electroencephalography and clinical Neurophysiology. 1033D. J. McFarland et al., \"Spatial filter selection for eeg-based communi- cation, \" Electroencephalography and clinical Neurophysiology, vol. 103, no. 3, pp. 386-394, 1997.\n\nThe standardized eeg electrode array of the ifcn. M Seeck, Clinical Neurophysiology. 12810M. Seeck et al., \"The standardized eeg electrode array of the ifcn,\" Clinical Neurophysiology, vol. 128, no. 10, pp. 2070-2077, 2017.\n\nYou are wrong!-automatic detection of interaction errors from brain waves. P W Ferrez, IJCAI. CONFP. W. Ferrez et al., \"You are wrong!-automatic detection of interaction errors from brain waves, \" in IJCAI, no. CONF, 2005.\n\nError-related eeg potentials generated during simulated brain computer interaction. P Ferrez, IEEE T-BME. 553P. Ferrez et al., \"Error-related eeg potentials generated during simulated brain computer interaction, \" IEEE T-BME, vol. 55, no. 3, 2008.\n\nHyperdimensional computing for blind and one-shot classification of eeg error-related potentials. A Rahimi, Mobile Networks and Applications. A. Rahimi et al., \"Hyperdimensional computing for blind and one-shot classification of eeg error-related potentials,\" Mobile Networks and Applications, 2020.\n\nGraphd: Graph-based hyperdimensional memorization for brain-like cognitive learning. P , Frontiers in Neuroscience. 5P. Poduval et al., \"Graphd: Graph-based hyperdimensional memoriza- tion for brain-like cognitive learning,\" Frontiers in Neuroscience, p. 5, 2022.\n\nLearning sensorimotor control with neuromorphic sensors: Toward hyperdimensional active perception. A Mitrokhin, Science Robotics. 430A. Mitrokhin et al., \"Learning sensorimotor control with neuromorphic sensors: Toward hyperdimensional active perception, \" Science Robotics, vol. 4, no. 30, 2019.\n\nEventhd: Robust and efficient hyperdimensional learning with neuromorphic sensor. Z Zou, Frontiers in Neuroscience. 16Z. Zou, et al., \"Eventhd: Robust and efficient hyperdimensional learning with neuromorphic sensor, \" Frontiers in Neuroscience, vol. 16, 2022.\n\nA robust and energy-efficient classifier using braininspired hyperdimensional computing. A Rahimi, ISLPED. A. Rahimi et al., \"A robust and energy-efficient classifier using brain- inspired hyperdimensional computing, \" in ISLPED, 2016, pp. 64-69.\n\nBiohd: an efficient genome sequence search platform using hyperdimensional memorization. Z Zou, Proceedings of the 49th Annual International Symposium on Computer Architecture, 2022. the 49th Annual International Symposium on Computer Architecture, 2022Z. Zou et al., \"Biohd: an efficient genome sequence search platform using hyperdimensional memorization,\" in Proceedings of the 49th Annual International Symposium on Computer Architecture, 2022, pp. 656-669.\n\nEfficient human activity recognition using hyperdimensional computing. Y Kim, in IOT. Y. Kim et al., \"Efficient human activity recognition using hyperdimen- sional computing, \" in IOT, 2018, pp. 1-6.\n\nA programmable hyper-dimensional processor architecture for human-centric iot. S Datta, JETCAS. 93S. Datta et al., \"A programmable hyper-dimensional processor archi- tecture for human-centric iot, \" JETCAS, vol. 9, no. 3, pp. 439-452, 2019.\n\nShear er: highly-efficient hyperdimensional computing by software-hardware enabled multifold approximation. B Khaleghi, ISLPED. B. Khaleghi et al., \"Shear er: highly-efficient hyperdimensional com- puting by software-hardware enabled multifold approximation,\" in ISLPED, 2020, pp. 241-246.\n\nAlgorithm-hardware co-design for efficient brain-inspired hyperdimensional learning on edge. Y Ni, 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEEY. Ni et al., \"Algorithm-hardware co-design for efficient brain-inspired hyperdimensional learning on edge, \" in 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEE, 2022, pp. 292-297.\n\nIn-memory hyperdimensional computing. G Karunaratne, Nature Electronics. 36G. Karunaratne et al., \"In-memory hyperdimensional computing, \" Na- ture Electronics, vol. 3, no. 6, pp. 327-337, 2020.\n\nSearchd: A memory-centric hyperdimensional computing with stochastic training. M Imani, TCAD. 3910M. Imani et al., \"Searchd: A memory-centric hyperdimensional com- puting with stochastic training, \" TCAD, vol. 39, no. 10, pp. 2422-2433, 2019.\n\nBrain-inspired computing exploiting carbon nanotube fets and resistive ram: Hyperdimensional computing case study. T F Wu, ISSCC. IEEET. F. Wu et al., \"Brain-inspired computing exploiting carbon nanotube fets and resistive ram: Hyperdimensional computing case study,\" in ISSCC. IEEE, 2018.\n\nExploring hyperdimensional associative memory. M Imani, HPCA. IEEEM. Imani et al., \"Exploring hyperdimensional associative memory, \" in HPCA. IEEE, 2017, pp. 445-456.\n", "annotations": {"author": "[{\"end\":198,\"start\":156},{\"end\":243,\"start\":199},{\"end\":292,\"start\":244},{\"end\":340,\"start\":293},{\"end\":383,\"start\":341},{\"end\":428,\"start\":384},{\"end\":477,\"start\":429},{\"end\":525,\"start\":478}]", "publisher": null, "author_last_name": "[{\"end\":163,\"start\":161},{\"end\":214,\"start\":208},{\"end\":257,\"start\":253},{\"end\":305,\"start\":300},{\"end\":348,\"start\":346},{\"end\":399,\"start\":393},{\"end\":442,\"start\":438},{\"end\":490,\"start\":485}]", "author_first_name": "[{\"end\":160,\"start\":156},{\"end\":207,\"start\":199},{\"end\":252,\"start\":244},{\"end\":299,\"start\":293},{\"end\":345,\"start\":341},{\"end\":392,\"start\":384},{\"end\":437,\"start\":429},{\"end\":484,\"start\":478}]", "author_affiliation": "[{\"end\":197,\"start\":165},{\"end\":242,\"start\":216},{\"end\":291,\"start\":259},{\"end\":339,\"start\":307},{\"end\":382,\"start\":350},{\"end\":427,\"start\":401},{\"end\":476,\"start\":444},{\"end\":524,\"start\":492}]", "title": "[{\"end\":97,\"start\":1},{\"end\":622,\"start\":526}]", "venue": "[{\"end\":695,\"start\":624}]", "abstract": "[{\"end\":2592,\"start\":862}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2804,\"start\":2801},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3349,\"start\":3346},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3351,\"start\":3349},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3566,\"start\":3563},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4004,\"start\":4001},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4007,\"start\":4004},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4010,\"start\":4007},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4013,\"start\":4010},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4016,\"start\":4013},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4249,\"start\":4246},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4726,\"start\":4723},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4730,\"start\":4726},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4734,\"start\":4730},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4738,\"start\":4734},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4742,\"start\":4738},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5423,\"start\":5420},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7734,\"start\":7730},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8436,\"start\":8433},{\"end\":9454,\"start\":9451},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12560,\"start\":12556},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12563,\"start\":12560},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13197,\"start\":13193},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":16153,\"start\":16149},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":16156,\"start\":16153},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16256,\"start\":16253},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18621,\"start\":18618},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18624,\"start\":18621},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18627,\"start\":18624},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22355,\"start\":22352},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":22358,\"start\":22355},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22361,\"start\":22358},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":23196,\"start\":23192},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":25462,\"start\":25459},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25465,\"start\":25462},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":30163,\"start\":30159},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30178,\"start\":30174},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":30207,\"start\":30203},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":30234,\"start\":30230},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":30258,\"start\":30254},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30287,\"start\":30284},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":30290,\"start\":30287},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30552,\"start\":30549},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":30556,\"start\":30552},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":30560,\"start\":30556},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":30564,\"start\":30560},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":30568,\"start\":30564},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":31339,\"start\":31335},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":31343,\"start\":31339},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31347,\"start\":31343},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":31377,\"start\":31373},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31381,\"start\":31377},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":31385,\"start\":31381},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":31389,\"start\":31385}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":32959,\"start\":32879},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33077,\"start\":32960},{\"attributes\":{\"id\":\"fig_2\"},\"end\":33129,\"start\":33078},{\"attributes\":{\"id\":\"fig_3\"},\"end\":33292,\"start\":33130},{\"attributes\":{\"id\":\"fig_4\"},\"end\":33399,\"start\":33293},{\"attributes\":{\"id\":\"fig_5\"},\"end\":33550,\"start\":33400},{\"attributes\":{\"id\":\"fig_6\"},\"end\":33672,\"start\":33551},{\"attributes\":{\"id\":\"fig_7\"},\"end\":33730,\"start\":33673},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33921,\"start\":33731},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":34293,\"start\":33922}]", "paragraph": "[{\"end\":3825,\"start\":2608},{\"end\":4613,\"start\":3827},{\"end\":4850,\"start\":4615},{\"end\":6057,\"start\":4852},{\"end\":6445,\"start\":6059},{\"end\":8144,\"start\":6447},{\"end\":9155,\"start\":8175},{\"end\":9455,\"start\":9174},{\"end\":10433,\"start\":9480},{\"end\":10651,\"start\":10435},{\"end\":10953,\"start\":10693},{\"end\":11104,\"start\":11013},{\"end\":11879,\"start\":11119},{\"end\":12449,\"start\":11881},{\"end\":12887,\"start\":12475},{\"end\":13088,\"start\":12920},{\"end\":13312,\"start\":13107},{\"end\":13477,\"start\":13377},{\"end\":13735,\"start\":13479},{\"end\":13878,\"start\":13771},{\"end\":14435,\"start\":13918},{\"end\":15561,\"start\":14471},{\"end\":16934,\"start\":15563},{\"end\":17054,\"start\":16936},{\"end\":18183,\"start\":17056},{\"end\":18476,\"start\":18185},{\"end\":19707,\"start\":18478},{\"end\":20787,\"start\":19743},{\"end\":20999,\"start\":20789},{\"end\":21330,\"start\":21031},{\"end\":21546,\"start\":21361},{\"end\":21929,\"start\":21577},{\"end\":23111,\"start\":21967},{\"end\":24334,\"start\":23113},{\"end\":25221,\"start\":24336},{\"end\":25939,\"start\":25241},{\"end\":26842,\"start\":25961},{\"end\":27863,\"start\":26844},{\"end\":28700,\"start\":27891},{\"end\":29359,\"start\":28721},{\"end\":30009,\"start\":29394},{\"end\":30915,\"start\":30027},{\"end\":32086,\"start\":30917},{\"end\":32878,\"start\":32101}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10692,\"start\":10652},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11012,\"start\":10954},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12919,\"start\":12888},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13106,\"start\":13089},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13342,\"start\":13313},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13376,\"start\":13342},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13770,\"start\":13736},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13917,\"start\":13879},{\"attributes\":{\"id\":\"formula_8\"},\"end\":21030,\"start\":21000},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21360,\"start\":21331}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24333,\"start\":24326},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24921,\"start\":24813},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":27258,\"start\":27251}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2606,\"start\":2594},{\"attributes\":{\"n\":\"2\"},\"end\":8173,\"start\":8147},{\"attributes\":{\"n\":\"2.1\"},\"end\":9172,\"start\":9158},{\"attributes\":{\"n\":\"2.2\"},\"end\":9478,\"start\":9458},{\"attributes\":{\"n\":\"2.3\"},\"end\":11117,\"start\":11107},{\"attributes\":{\"n\":\"3\"},\"end\":12473,\"start\":12452},{\"attributes\":{\"n\":\"3.1\"},\"end\":14469,\"start\":14438},{\"attributes\":{\"n\":\"4\"},\"end\":19741,\"start\":19710},{\"attributes\":{\"n\":\"4.1\"},\"end\":21575,\"start\":21549},{\"attributes\":{\"n\":\"5\"},\"end\":21965,\"start\":21932},{\"attributes\":{\"n\":\"5.2\"},\"end\":25239,\"start\":25224},{\"attributes\":{\"n\":\"5.3\"},\"end\":25959,\"start\":25942},{\"attributes\":{\"n\":\"5.4\"},\"end\":27889,\"start\":27866},{\"attributes\":{\"n\":\"5.5\"},\"end\":28719,\"start\":28703},{\"attributes\":{\"n\":\"5.6\"},\"end\":29392,\"start\":29362},{\"attributes\":{\"n\":\"6\"},\"end\":30025,\"start\":30012},{\"attributes\":{\"n\":\"7\"},\"end\":32099,\"start\":32089},{\"end\":32890,\"start\":32880},{\"end\":32971,\"start\":32961},{\"end\":33089,\"start\":33079},{\"end\":33141,\"start\":33131},{\"end\":33304,\"start\":33294},{\"end\":33411,\"start\":33401},{\"end\":33577,\"start\":33552},{\"end\":33684,\"start\":33674},{\"end\":33741,\"start\":33732},{\"end\":33932,\"start\":33923}]", "table": "[{\"end\":33921,\"start\":33794},{\"end\":34293,\"start\":34028}]", "figure_caption": "[{\"end\":32959,\"start\":32892},{\"end\":33077,\"start\":32973},{\"end\":33129,\"start\":33091},{\"end\":33292,\"start\":33143},{\"end\":33399,\"start\":33306},{\"end\":33550,\"start\":33413},{\"end\":33672,\"start\":33583},{\"end\":33730,\"start\":33686},{\"end\":33794,\"start\":33743},{\"end\":34028,\"start\":33934}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8769,\"start\":8761},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9492,\"start\":9483},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10190,\"start\":10181},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11836,\"start\":11827},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13560,\"start\":13552},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14802,\"start\":14793},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15246,\"start\":15237},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15401,\"start\":15392},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16933,\"start\":16922},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17225,\"start\":17215},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19828,\"start\":19819},{\"end\":24943,\"start\":24935},{\"end\":25252,\"start\":25244},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":25981,\"start\":25973},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":28013,\"start\":28005},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":28455,\"start\":28447},{\"end\":28732,\"start\":28724},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":29405,\"start\":29397}]", "bib_author_first_name": "[{\"end\":34397,\"start\":34396},{\"end\":34399,\"start\":34398},{\"end\":34732,\"start\":34731},{\"end\":34978,\"start\":34977},{\"end\":35228,\"start\":35227},{\"end\":35500,\"start\":35499},{\"end\":35830,\"start\":35829},{\"end\":36087,\"start\":36086},{\"end\":36609,\"start\":36608},{\"end\":36974,\"start\":36973},{\"end\":37239,\"start\":37238},{\"end\":37487,\"start\":37486},{\"end\":37767,\"start\":37763},{\"end\":38023,\"start\":38022},{\"end\":38391,\"start\":38390},{\"end\":38401,\"start\":38400},{\"end\":38639,\"start\":38638},{\"end\":38649,\"start\":38648},{\"end\":38892,\"start\":38891},{\"end\":38894,\"start\":38893},{\"end\":39187,\"start\":39186},{\"end\":39437,\"start\":39436},{\"end\":39439,\"start\":39438},{\"end\":39670,\"start\":39669},{\"end\":39933,\"start\":39932},{\"end\":40221,\"start\":40220},{\"end\":40501,\"start\":40500},{\"end\":40782,\"start\":40781},{\"end\":41051,\"start\":41050},{\"end\":41299,\"start\":41298},{\"end\":41744,\"start\":41743},{\"end\":41953,\"start\":41952},{\"end\":42224,\"start\":42223},{\"end\":42500,\"start\":42499},{\"end\":42833,\"start\":42832},{\"end\":43070,\"start\":43069},{\"end\":43350,\"start\":43349},{\"end\":43352,\"start\":43351},{\"end\":43573,\"start\":43572}]", "bib_author_last_name": "[{\"end\":34410,\"start\":34400},{\"end\":34735,\"start\":34733},{\"end\":34982,\"start\":34979},{\"end\":35234,\"start\":35229},{\"end\":35508,\"start\":35501},{\"end\":35837,\"start\":35831},{\"end\":36091,\"start\":36088},{\"end\":36624,\"start\":36610},{\"end\":36979,\"start\":36975},{\"end\":37246,\"start\":37240},{\"end\":37492,\"start\":37488},{\"end\":37773,\"start\":37768},{\"end\":38035,\"start\":38024},{\"end\":38398,\"start\":38392},{\"end\":38407,\"start\":38402},{\"end\":38646,\"start\":38640},{\"end\":38655,\"start\":38650},{\"end\":38904,\"start\":38895},{\"end\":39193,\"start\":39188},{\"end\":39446,\"start\":39440},{\"end\":39677,\"start\":39671},{\"end\":39940,\"start\":39934},{\"end\":40511,\"start\":40502},{\"end\":40786,\"start\":40783},{\"end\":41058,\"start\":41052},{\"end\":41303,\"start\":41300},{\"end\":41748,\"start\":41745},{\"end\":41959,\"start\":41954},{\"end\":42233,\"start\":42225},{\"end\":42503,\"start\":42501},{\"end\":42845,\"start\":42834},{\"end\":43076,\"start\":43071},{\"end\":43355,\"start\":43353},{\"end\":43579,\"start\":43574}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":215722655},\"end\":34630,\"start\":34311},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":196175745},\"end\":34893,\"start\":34632},{\"attributes\":{\"doi\":\"arXiv:1704.02971\",\"id\":\"b2\"},\"end\":35152,\"start\":34895},{\"attributes\":{\"id\":\"b3\"},\"end\":35372,\"start\":35154},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":733980},\"end\":35733,\"start\":35374},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":235606247},\"end\":35996,\"start\":35735},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":239036966},\"end\":36530,\"start\":35998},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":243928303},\"end\":36871,\"start\":36532},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":231705788},\"end\":37144,\"start\":36873},{\"attributes\":{\"id\":\"b9\"},\"end\":37399,\"start\":37146},{\"attributes\":{\"doi\":\"arXiv:2105.00934\",\"id\":\"b10\"},\"end\":37666,\"start\":37401},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":155774532},\"end\":37937,\"start\":37668},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":221388379},\"end\":38188,\"start\":37939},{\"attributes\":{\"id\":\"b13\"},\"end\":38339,\"start\":38190},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":877929},\"end\":38542,\"start\":38341},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":14171621},\"end\":38835,\"start\":38544},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":11289215},\"end\":39134,\"start\":38837},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":3709707},\"end\":39359,\"start\":39136},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":1778469},\"end\":39583,\"start\":39361},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1189113},\"end\":39832,\"start\":39585},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":12928560},\"end\":40133,\"start\":39834},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":246531628},\"end\":40398,\"start\":40135},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":182118830},\"end\":40697,\"start\":40400},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":251072764},\"end\":40959,\"start\":40699},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":9812826},\"end\":41207,\"start\":40961},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":249205135},\"end\":41670,\"start\":41209},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":52978766},\"end\":41871,\"start\":41672},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":201900134},\"end\":42113,\"start\":41873},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":220665748},\"end\":42404,\"start\":42115},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":248923006},\"end\":42792,\"start\":42406},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":174797921},\"end\":42988,\"start\":42794},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":209093915},\"end\":43232,\"start\":42990},{\"attributes\":{\"id\":\"b32\"},\"end\":43523,\"start\":43234},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":1677864},\"end\":43691,\"start\":43525}]", "bib_title": "[{\"end\":34394,\"start\":34311},{\"end\":34729,\"start\":34632},{\"end\":35497,\"start\":35374},{\"end\":35827,\"start\":35735},{\"end\":36084,\"start\":35998},{\"end\":36606,\"start\":36532},{\"end\":36971,\"start\":36873},{\"end\":37761,\"start\":37668},{\"end\":38020,\"start\":37939},{\"end\":38388,\"start\":38341},{\"end\":38636,\"start\":38544},{\"end\":38889,\"start\":38837},{\"end\":39184,\"start\":39136},{\"end\":39434,\"start\":39361},{\"end\":39667,\"start\":39585},{\"end\":39930,\"start\":39834},{\"end\":40218,\"start\":40135},{\"end\":40498,\"start\":40400},{\"end\":40779,\"start\":40699},{\"end\":41048,\"start\":40961},{\"end\":41296,\"start\":41209},{\"end\":41741,\"start\":41672},{\"end\":41950,\"start\":41873},{\"end\":42221,\"start\":42115},{\"end\":42497,\"start\":42406},{\"end\":42830,\"start\":42794},{\"end\":43067,\"start\":42990},{\"end\":43570,\"start\":43525}]", "bib_author": "[{\"end\":34412,\"start\":34396},{\"end\":34737,\"start\":34731},{\"end\":34984,\"start\":34977},{\"end\":35236,\"start\":35227},{\"end\":35510,\"start\":35499},{\"end\":35839,\"start\":35829},{\"end\":36093,\"start\":36086},{\"end\":36626,\"start\":36608},{\"end\":36981,\"start\":36973},{\"end\":37248,\"start\":37238},{\"end\":37494,\"start\":37486},{\"end\":37775,\"start\":37763},{\"end\":38037,\"start\":38022},{\"end\":38400,\"start\":38390},{\"end\":38409,\"start\":38400},{\"end\":38648,\"start\":38638},{\"end\":38657,\"start\":38648},{\"end\":38906,\"start\":38891},{\"end\":39195,\"start\":39186},{\"end\":39448,\"start\":39436},{\"end\":39679,\"start\":39669},{\"end\":39942,\"start\":39932},{\"end\":40224,\"start\":40220},{\"end\":40513,\"start\":40500},{\"end\":40788,\"start\":40781},{\"end\":41060,\"start\":41050},{\"end\":41305,\"start\":41298},{\"end\":41750,\"start\":41743},{\"end\":41961,\"start\":41952},{\"end\":42235,\"start\":42223},{\"end\":42505,\"start\":42499},{\"end\":42847,\"start\":42832},{\"end\":43078,\"start\":43069},{\"end\":43357,\"start\":43349},{\"end\":43581,\"start\":43572}]", "bib_venue": "[{\"end\":34446,\"start\":34412},{\"end\":34751,\"start\":34737},{\"end\":34975,\"start\":34895},{\"end\":35225,\"start\":35154},{\"end\":35531,\"start\":35510},{\"end\":35845,\"start\":35839},{\"end\":36201,\"start\":36093},{\"end\":36679,\"start\":36626},{\"end\":36999,\"start\":36981},{\"end\":37236,\"start\":37146},{\"end\":37484,\"start\":37401},{\"end\":37780,\"start\":37775},{\"end\":38041,\"start\":38037},{\"end\":38225,\"start\":38190},{\"end\":38413,\"start\":38409},{\"end\":38671,\"start\":38657},{\"end\":38957,\"start\":38906},{\"end\":39219,\"start\":39195},{\"end\":39453,\"start\":39448},{\"end\":39689,\"start\":39679},{\"end\":39974,\"start\":39942},{\"end\":40249,\"start\":40224},{\"end\":40529,\"start\":40513},{\"end\":40813,\"start\":40788},{\"end\":41066,\"start\":41060},{\"end\":41390,\"start\":41305},{\"end\":41756,\"start\":41750},{\"end\":41967,\"start\":41961},{\"end\":42241,\"start\":42235},{\"end\":42576,\"start\":42505},{\"end\":42865,\"start\":42847},{\"end\":43082,\"start\":43078},{\"end\":43347,\"start\":43234},{\"end\":43585,\"start\":43581},{\"end\":36296,\"start\":36203},{\"end\":41462,\"start\":41392}]"}}}, "year": 2023, "month": 12, "day": 17}