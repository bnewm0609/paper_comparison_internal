{"id": 304614, "updated": "2023-09-29 14:55:00.889", "metadata": {"title": "Neural Rating Regression with Abstractive Tips Generation for Recommendation", "authors": "[{\"first\":\"Piji\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Zihao\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Zhaochun\",\"last\":\"Ren\",\"middle\":[]},{\"first\":\"Lidong\",\"last\":\"Bing\",\"middle\":[]},{\"first\":\"Wai\",\"last\":\"Lam\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval", "publication_date": {"year": 2017, "month": 8, "day": 1}, "abstract": "Recently, some E-commerce sites launch a new interaction box called Tips on their mobile apps. Users can express their experience and feelings or provide suggestions using short texts typically several words or one sentence. In essence, writing some tips and giving a numerical rating are two facets of a user's product assessment action, expressing the user experience and feelings. Jointly modeling these two facets is helpful for designing a better recommendation system. While some existing models integrate text information such as item specifications or user reviews into user and item latent factors for improving the rating prediction, no existing works consider tips for improving recommendation quality. We propose a deep learning based framework named NRT which can simultaneously predict precise ratings and generate abstractive tips with good linguistic quality simulating user experience and feelings. For abstractive tips generation, gated recurrent neural networks are employed to\"translate\"user and item latent representations into a concise sentence. Extensive experiments on benchmark datasets from different domains show that NRT achieves significant improvements over the state-of-the-art methods. Moreover, the generated tips can vividly predict the user experience and feelings.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1708.00154", "mag": "3103899101", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1708-00154", "doi": "10.1145/3077136.3080822"}}, "content": {"source": {"pdf_hash": "62a43f7b89404ac9a215fe2e0d4c122f430874e0", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1708.00154v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "https://arxiv.org/pdf/1708.00154", "status": "GREEN"}}, "grobid": {"id": "3d8b6fcb0256627a7e7052d584ec2ba53de119a6", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/62a43f7b89404ac9a215fe2e0d4c122f430874e0.txt", "contents": "\nNeural Rating Regression with Abstractive Tips Generation for Recommendation * Tips Review\nAugust 07-11, 2017\n\nPiji Li pjli@se.cuhk.edu.hk \nZihao Wang zhwang@se.cuhk.edu.hk \nZhaochun Ren renzhaochun@jd.com \nLidong Bing lyndonbing@tencent.com \nWai Lam wlam@se.cuhk.edu.hk \n\nDepartment of Systems Engineering and Engineering Management\nDepartment of Systems Engineering and Engineering Management\nData Science Lab, JD.com, North Star Century Center\nAI Lab\nThe Chinese University of Hong Kong\nThe Chinese University of Hong Kong\nTencent Inc. Hi-tech ParkBeijingChina\n\n\nDepartment of Systems Engineering and Engineering Management\nNanshan District\nShenzhenChina\n\n\nThe Chinese University of Hong Kong\n\n\nNeural Rating Regression with Abstractive Tips Generation for Recommendation * Tips Review\n\nSIGIR '17\nShinjuku, Tokyo, JapanAugust 07-11, 201710.1145/3077136.3080822CCS CONCEPTS \u2022 Information systems \u2192 Information retrievalRecommender systemsCollaborative filtering* KEYWORDS Rating PredictionTips GenerationDeep Learning\nRecently, some E-commerce sites launch a new interaction box called Tips on their mobile apps. Users can express their experience and feelings or provide suggestions using short texts typically several words or one sentence. In essence, writing some tips and giving a numerical rating are two facets of a user's product assessment action, expressing the user experience and feelings. Jointly modeling these two facets is helpful for designing a better recommendation system. While some existing models integrate text information such as item specifications or user reviews into user and item latent factors for improving the rating prediction, no existing works consider tips for improving recommendation quality. We propose a deep learning based framework named NRT which can simultaneously predict precise ratings and generate abstractive tips with good linguistic quality simulating user experience and feelings. For abstractive tips generation, gated recurrent neural networks are employed to \"translate\" user and item latent representations into a concise sentence. Extensive experiments on benchmark datasets from different domains show that NRT achieves significant improvements over the state-of-the-art methods. Moreover, the generated tips can vividly predict the user experience and feelings.Figure 1: Examples of reviews and tips selected from the restaurant \"Gary Danko\" on Yelp. Tips are more concise than reviews and can reveal user experience, feelings, and suggestions with only a few words. Users will get conclusions about this restaurant immediately after scanning the tips with their mobile phones.\n\nINTRODUCTION\n\nWith the explosive growth of Internet information, recommendation systems have been playing an increasingly important role in on-line E-commerce and applications in a variety of areas, including music streaming service such as Spotify 1 and Apple Music, movie rating such as IMDB 2 , video streaming service such as Netflix and Youtube, job recommendation such as LinkedIn 3 , and product recommendation such as Amazon. Many recommendation methods are based on Collaborative Filtering (CF) which mainly makes use of historical ratings [14,15,18,22,31,33,35]. Recently, some approaches also consider text information in addition to the rating data [1,21,23,26,40,49]. After some investigations, we observe that the text information in most recommendation tasks can be generally classified into two types: item specifications [40][41][42] and user reviews [1,21,23,26,46,47,49]. Item specifications are the text information for describing the attributes or properties of the items. For example, in article recommendation such as CiteULike 4 , it refers to titles and abstracts of papers. In product recommendation such as Amazon, it refers to product descriptions and technical specification information. The second type is user reviews which are written by users to explain why they like or dislike an item based on their usage experiences. Multi-faceted information can be extracted from reviews and used as user preferences or item features, which otherwise cannot be obtained from the overall ratings [5]. Although both types of text data are found to be useful for the recommendation task, they have some inherent limitations. Concretely, the former cannot reflect users' experience and preference, and the latter is usually too long and suffers from noise.\n\nRecently, some E-commerce sites such as Yelp 5 launch a new interaction box called Tips on their mobile platforms. As shown in Figure 1, the left column is a review from the user \"Monica H. \", and tips from several other users are shown on the right column. In the review text, Monica first generally introduced the restaurant, and then narrated her dining experience in detail. In the tips text, users expressed their experience and feelings plainly using short texts, such as \"The risotto was excellent. Amazing service.\". They also provide some suggestions to other people directly in several words, such as \"You have to make reservations much in advance. \" In contrast to item specifications and user reviews, tips have several characteristics: (1) tips are typically single-topic nuggets of information, and shorter than reviews with a length of about 10 words on average; (2) tips can express user experience, feelings, and suggestions directly; (3) tips can give other people quick insights, saving the time of reading long reviews. In essence, writing some tips and giving a numerical rating are two facets of a user's product assessment action, expressing the user experience and feelings. Jointly modeling these two facets is helpful for designing a better recommendation system.\n\nExisting models only integrate text information such as item specifications [40][41][42] and user reviews [1,21,23,26,46,47,49] to enhance the performance of latent factor modeling and rating prediction. To our best knowledge, we are the first to consider tips for improving the recommendation quality. We aim at developing a model that is capable of conducting the latent factor modeling and rating prediction, and more importantly, it can generate tips based on the learnt latent factors. We do not just extract some existing sentences and regard them as tips. Conversely, we investigate the task of automatically construing a concise sentence as tips, such capability can be treated as simulating how users write tips in order to express their experience and feelings, just as if they have bought and consumed the item. Therefore, we named this task abstractive tips generation, where \"abstractive\" is a terminology from the research of text summarization [3].\n\nGenerating abstractive tips only based on user latent factors and item latent factors is a challenging task. Recently, gated recurrent neural networks such as Long Short-Term Memory (LSTM) [12] and Gated Recurrent Unit (GRU) [6] demonstrate high capability in text generation related tasks [2,30]. Moreover, inspired by [11,41], neural network based models can help learn more effective latent factors when conducting rating prediction and improve the performance of collaborative filtering. We employ deep learning techniques for latent factor modeling, rating prediction, and abstractive tips generation. For abstractive tips generation, gated recurrent neural networks are employed to \"translate\" a user latent factor and an item latent factor into a concise sentence to express user experience and feelings. For neural rating regression, a multilayer perceptron network [28] is employed to project user latent factors and item latent factors into ratings. All the neural parameters in the gated recurrent neural networks and the multilayer perceptron network as well as the latent factors for users and items are learnt by a multi-task learning approach in an end-to-end training paradigm.\n\nThe main contributions of our framework are summarized below:\n\n\u2022 We propose a deep learning based framework named NRT which can simultaneously predict precise ratings and generate abstractive tips with good linguistic quality simulating user experience and feelings. All the neural parameters as well as the latent factors for users and items are learnt by a multi-task learning approach in an end-to-end training paradigm. \u2022 We are the first to explore using tips information to improve the recommendation quality. In essence, writing some tips and giving a numerical rating are two facets of a user's product assessment action, expressing the user experience and feelings. Jointly modeling these two facets is helpful for designing a better recommendation system. \u2022 Experimental results on benchmark datasets show that our framework achieves better performance than the stateof-the-art models on both tasks of rating prediction and abstractive tips generation.\n\n\nRELATED WORKS\n\nCollaborative filtering (CF) has been studied for a long time and has achieved some success in recommendation systems [27,37]. Latent Factor Models (LFM) based on Matrix Factorization (MF) [15] play an important role for rating prediction. Various MF algorithms have been proposed, such as Singular Value Decomposition (SVD) and SVD++ [14], Non-negative Matrix Factorization (NMF) [18], and Probabilistic Matrix Factorization (PMF) [31]. These methods map users and items into a shared latent factor space, and use a vector of latent features as the representation for users and items respectively. Then the inner product of their latent factor vectors can reflect the interactions between users and items. The recommendation performance will degrade significantly when the rating matrix is very sparse. Therefore, some works consider text information for improving the rating prediction. Both item specifications and user reviews have been investigated. In order to use the item specifications, CTR [40] integrates PMF [31] and Latent Dirichlet Allocation (LDA) [4] into a single framework and employs LDA to model the text. Collaborative Deep Learning (CDL) [41] employs a hierarchical Bayesian model which jointly performs deep representation learning for the specification text content and collaborative filtering for the rating matrix. For user review texts, some research works, such as HFT [23], RMR [21], TriRank [10], and sCVR [26], integrate topic models in their frameworks to generate the latent factors for users and items incorporating review texts. Moreover, TriRank and sCVR have been explicitly claimed that they can provide explanations for recommendations. However, one common limitation of them is that their explanations are simple extractions of words or phrases from the texts. In contrast, we aim at generating concise sentences representing tips, which express the feeling of users while they are reviewing an item.\n\nDeep Learning (DL) techniques have achieved significant success in the fields of computer vision, speech recognition, and natural language processing [8]. In the field of recommendation systems, researchers have made some attempts by combining different neural network structures with collaborative filtering to improve the recommendation performance. Salakhutdinov et al. [32] employ a class of two-layer Restricted Boltzmann Machines (RBM) with an efficient learning algorithm to model user interactions and perform collaborative filtering. Considering that the training procedure of Auto-Encoders [25] is more straightforward, some research works employ auto-encoders to tackle the latent factor modeling and rating prediction [34,39,44]. Recently, He et al. [11] combine generalized matrix factorization and multi-layer perceptions to find better latent structures from the user interactions for improving the performance of collaborative filtering. To model the temporal dynamic information in the user interactions, Wu et al. [43] propose a recurrent recommender network which is able to predict future behavioral trajectories.\n\n\nFRAMEWORK DESCRIPTION 3.1 Overview\n\nThe goal of recommendation, similar to collaborative filtering, is to predict a rating given a user and an item. Additionally, in our proposed task, our model also generates abstractive tips in the form of a concise sentence. At the operational stage, only a user and an item are given. There is no given review texts and obviously no tips texts.\n\nAt the training stage, the training data consists of users, items, tips texts, and review content. Table 1 depicts the notations and key concepts used in our paper. We denote the whole training corpus by X = {U, I, R, C, S}, where U and I are the sets of users and items respectively, R is the set of ratings, C is the set of review documents, and S is the set of tips sentences. As shown in Figure 2, our framework contains two major components: neural rating regression on the left and abstractive tips generation on the right. There are two crucial latent variables : user latent factors U \u2208 R k u \u00d7m and item latent factors V \u2208 R k v \u00d7n , where m is the number of users, and n is the number of items. k u and k v are the latent factor dimension for users and items respectively. For neural rating regression, given the user latent factor u and the item latent factor v, a multi-layer perceptron network based regression model is employed to project u and v to a real value via several layers of non-linear transformations. For abstractive tips generation, we design a sequence decoding model based on a gated recurrent neural network called Gated Recurrent Unit (GRU) [6] to \"translate\" the combination of a user latent factor u and an item latent factor v into a sequence of words, representing tips. Moreover, two kinds of context information generated based on u and v are also fed into the sequence decoder model. One is the hidden variable from the rating regression component, which is used as sentiment context information. The other is the hidden output of a generative model for review texts. At the operational or testing stage, we use a beam search algorithm [13] for decoding and generating the best tips given a trained model. All the neural parameters and the latent factors for users, items, and words are learnt by a multi-task learning approach. The model can be trained efficiently by an end-to-end paradigm using backpropagation algorithms [29].\n\n\nNeural Rating Regression\n\nThe aim of the neural rating regression component is to conduct representation learning for the user factor u and the item factor v mentioned above. In order to predict a rating, we need to design a model that can learn the function f r (\u00b7) which can project u and v to a real-valued ratingr :r\n= f r (u, v)(1)\nIn most of the existing latent factor models, f r (\u00b7) is represented by the inner product of u and v, or adds a bias item for the corresponding user and item respectively:\nr = u T v + b u + b v + b(2)\nIt is obvious that the rating is calculated by a linear combination of user latent factors, item latent factors, and bias. The learnt latent factors may not capture the complex structure implied in the user historical interactions. Recently, some research works on representation learning from different fields, such as computer vision [9,16], natural language processing [17,24], and knowledge base completion [36], demonstrate that non-linear transformations will enhance the representation ability. Moreover, most latent factor models assume that users and items or even text information are in the same vector space and share the same latent factors. Actually, user, item, and text information are different kinds of objects with different characteristics. Modeling them in the same vector space would lead to limitations. As shown in left part in Figure 2, we let user latent factors U \u2208 R k u \u00d7m and item latent factors V \u2208 R k v \u00d7n in different vector space, where k u and k v are the latent factor dimension for users and items respectively. m and n are the number of users and items respectively. In order to model the relationship between users and items, one may consider to use a neural tensor network [36] to describe the interactions between users and items, such as u T Wv, where W \u2208 R k u \u00d7d \u00d7k v . However, our investigation shows that such tensor network has too many parameters resulting in difficulty for handling large-scale datasets commonly found in recommendation applications. Therefore, we employ a multi-layer perceptron network to model the interactions between users and items, and map user latent factors and item latent factors into real-valued ratings.\n\nSpecifically, we first map latent factors to a shared hidden space:\nh r = \u03c3 (W r uh u + W r vh v + b r h )(3)\nwhere W r uh \u2208 R d \u00d7k u and W r vh \u2208 R d \u00d7k v are the mapping matrices for user latent factors and item latent factors respectively. b r h \u2208 R d is the bias term. d is the dimension of the hidden vector h r . The superscript r refers to variables related to the rating prediction component. \u03c3 (\u00b7) is the sigmoid activation function:\n\u03c3 (x) = 1 1 + e \u2212x(4)\nThis non-linear transformation can improve the performance of the rating prediction. For better performance, we can add more layers of non-linear transformations into our model:\nh r l = \u03c3 (W r hh l h r l \u22121 + b r h l )(5)\nwhere W r hh l \u2208 R d \u00d7d is the mapping matrix for the variables in the hidden layers. l is the index of a hidden layer. Assume that h r L is the output of the last hidden layer. The output layer transforms h r L into a real-valued ratingr :\nr = W r hr h r L + b r(6)\nwhere W r hr \u2208 R d and b r \u2208 R. In order to optimize the latent factors U and V, as well as all the neural parameters \u0398, we formulate it as a regression problem and the loss function is formulated as:\nL r = 1 2 |X| u \u2208U,i \u2208I (r u,i \u2212 r u,i ) 2(7)\nwhere X represents the training set. r u,i is the ground truth rating assigned by the user u to the item i.\n\n\nNeural Abstractive Tips Generation\n\nGenerating abstractive tips only based on user latent factors and item latent factors is a challenging task. As mentioned above, abstractive tips generation is different from review content summarization and explainable topic words extraction. At the operational stage, the input only consists of a user and an item, but without any text information. After obtaining the user latent factor u and the item latent factor v from the matrices U and V, we should design a strategy to \"translate\" these two latent vectors into a fluent sequence of words. Recently, gated recurrent neural networks such as Long Short-Term Memory (LSTM) [12] and Gated Recurrent Unit (GRU) [6] demonstrate high capability in text generation related tasks [2,30]. Inspired by these works and considering that GRU has comparable performance but with less parameters and more efficient computation, we employ GRU as the basic model in our sequence modeling framework. The right part of Figure 2 depicts our tips generation model. The major idea of sequence modeling for tips generation can be expressed as follows:\np(s t |s 1 , s 2 , . . . , s t \u22121 , C ct x ) = \u03c2(h s t )(8)\nwhere s t is the t-th word of the tips s. C ct x denotes the context information which will be described in the following sections. \u03c2(\u00b7) is the softmax function and defined as follows:\n\u03c2(x (i) ) = e x (i ) K k =1 e x (k )(9)\nh s t is the sequence hidden state at the time t and it depends on the input at the time t and the previous hidden state h s t \u22121 :\nh s t = f (h s t \u22121 , s t )(10)\nHere f (\u00b7) can be the vanilla RNN, LSTM, or GRU. In the case of GRU, the state updates are processed according to the following operations:\nr s t = \u03c3 (W s sr s t + W s hr h s t \u22121 + b s r ) z s t = \u03c3 (W s sz s t + W s hz h s t \u22121 + b s z ) g s t = tanh(W s sh s t + W s hh (r s t \u2299 h s t \u22121 ) + b s h ) h s t = z s t \u2299 h s t \u22121 + (1 \u2212 z s t ) \u2299 g s t(11)\nwhere s t \u2208 E is the embedding vector for the word s t of the tips and the vector is also learnt from our framework. r s t is the reset gate, z s t is the update gate. \u2299 denotes element-wise multiplication. tanh is the hyperbolic tangent activation function.\n\nAs shown in Figure 2, when t = 1, the sequence model has no input information. Therefore, we utilize the context information C ct x to initialize h s 0 . Context information is very crucial in a sequence decoding framework, which will directly affect the performance of sequence generation. In the field of neural machine translation [45], context information includes the encoding information of the source input and the decoding attention information from the source. In the field of neural summarization [19,30], the context is the encoded document information. In our framework, the corresponding user u and item i are the input from which we design two kinds of context information for tips generation: predicted ratin\u011d r u,i and the generated hidden variable for the review text h c L . For the input, we just find the user latent factor and the item latent factor from the matrices U and V:\nu = U(:, u), v = V(:, i)(12)\nFor the context of rating information, we can employ the output of the rating regression component in Section 3.2. Specifically, after getting the predicted ratingr u,i , for example,r u,i = 4.321, we cast it into an integer 4, and add a step of vectorization. Then we get the vector representation of ratingr u,i . If the rating range is [0, 5], we will get the rating vectorr u,i :\nr u,i = (0, 0, 0, 0, 1, 0) T(13)\nr u,i is used as the context information to control the sentiment of the generated tips. Another context information is from review texts. One should note that review texts cannot be used as the input directly. The reason is that at the testing state, there are no review information. We only make use of reviews to enhance the representation ability of the latent vectors U and V. We develop a standard generative model for review texts based on a multi-layer perceptron. For review content c u,i written by the user u to the item i, the generative process is defined as follows. We first map the user latent vector u and the item latent factor v into a hidden space:\nh c = \u03c3 (W c uh u + W c vh v + b c h )(14)\nIt is obvious that we can also add more layers of non-linear transformation into the generative hidden layers. Assume that h c L is the output of the last hidden layer. We add the final generative layer to map h c L into a |V |-size vector\u0109, where V is the vocabulary of words in the reviews and the tips:\nc = \u03c2(W c hc h c L + b c )(15)\nwhere W c hc \u2208 R |V |\u00d7d and b c \u2208 R |V | . \u03c2(\u00b7) is the softmax function defined in Equation 9. In fact we can regard\u0109 as a multinomial distribution defined on V. Therefore, we can draw some words from\u0109 and generate the content of the review c u,i . We let c be the ground truth of c u,i . c (k ) is the term frequency of the word k in c u,i . We employ the likelihood to evaluate the performance of this generative process. For convenience, we use the Negative Log-Likelihood (NLL) as the loss function:\nL c = \u2212 |V | k =1 c (k) log\u0109 (k)(16)\nOne characteristic of the design of our model is that both the rating and review texts are generated from the same user latent factors U and item latent factors V, i.e., U and V are shared by the subtasks of rating prediction and review text generation. Thus, in the training stage, both of U and V receive the feedback from all the subtasks, which improves the representation ability of the latent factors.\n\nAfter obtaining all the context information C ct x = {r, h c L }, we integrate them into the initial decoding hidden state h s 0 using a non-linear transformation:\nh s 0 = tanh(W s uh u + W s vh v + W s r hr + W s ch h c L + b s c )(17)\nwhere u is the user latent factor, v is the item latent factor,r is the vectorization for the predicted ratingr , and h c L is the generated hidden variable from the review text. Then GRU can conduct the sequence decoding progress. After getting all the sequence hidden states, we feed them to the final output layer to predict the word sequence in tips.\u015d\nt +1 = \u03c2(W s hs h s t + b s )(18)\nwhere W s hs \u2208 R d \u00d7|V | and b s \u2208 R |V | . \u03c2(\u00b7) is the softmax function defined in Equation 9. Then the word with the largest probability is the decoding result for the step t + 1:\nw * t +1 = arg max w i \u2208V\u015d (w i ) t +1(19)\nAt the training stage, we also use NLL as the loss function, where I w is the vocabulary index of the word w:\nL s = \u2212 w \u2208T ips log\u015d (I w )(20)\n\nAlgorithm 1 Beam search for abstractive tips generation\n\nInput: Beam size \u03b2, maximum length \u03b7, user id u, item id v, and tips generation model G. Output: \u03b2 best candidate tips. 1 \n\u03a0 \u2190 {s} \u03b2 \u22121 0 , \u03c0 \u2190 {l } \u03b2 \u22121 0 , \u03a0 p = \u2205, \u03c0 p = 0 15: t \u2190 t + 1 16: end while 17: return \u03a0, \u03c0 .\nAt the testing stage, given a trained model, we employ the beam search algorithm to find the best sequence s * having the maximum log-likelihood.\ns * = arg max s \u2208S w \u2208s log\u015d (I w )(21)\nThe details of the beam search algorithm is shown in Algorithm 1.\n\n\nMulti-task Learning\n\nWe integrate all the subtasks of rating prediction and abstractive tips generation into a unified multi-task learning framework whose objective function is:\nJ = min U,V,E,\u0398 (\u03bb r L r +\u03bb c L c +\u03bb s L s +\u03bb n (\u2225U\u2225 2 2 + \u2225V\u2225 2 2 + \u2225\u0398\u2225 2 2 )) (22)\nwhere L r is the rating regression loss from Equation 7, L c is the review text generation loss from Equation 16, and L r is the tips generation loss from Equation 20. \u0398 is the set of neural parameters. \u03bb r , \u03bb c , \u03bb s , and \u03bb n are the weight proportion of each term. The whole framework can be efficiently trained using back-propagation in an end-to-end paradigm.\n\n\nEXPERIMENTAL SETUP 4.1 Research Questions\n\nWe list the research questions we want to investigate in this paper:\n\n\u2022 RQ1: What is the performance of NRT in rating prediction tasks? Does it outperform the state-of-the-art models? (See Section 5.1.) \n\n\nDatasets\n\nIn our experiments, we use four standard benchmark datasets from different domains to evaluate our model. The ratings of these datasets are integers in the range of [0, 5]. There are three datasets from Amazon 5-core 6 : Books, Electronics, and Movies & TV. \"Books\" is the largest dataset among all the domains. It contains 603,668 users, 367,982 items, and 8,887,781 reviews. We regard the field \"summary\" as tips, and the number of tips texts is same with the number of reviews.\n\nAnother dataset is from Yelp Challenge 2016 7 . It is also a largescale dataset consisting of restaurant reviews and tips. The number of users is 684,295, which is the largest among all the datasets. Therefore this dataset is also the most sparse one. Tips are included in the dataset. For samples without tips, the first sentence of review texts is extracted and regarded as tips.\n\nWe filter out the words with low term frequency in the tips and review texts, and build a vocabulary V for each dataset. We show the statistics of our datasets in Table 2.\n\n\nEvaluation Metrics\n\nFor the evaluation of rating prediction, we employ two metrics: Mean Absolute Error (MAE) and Root Mean Square Error (RMSE). Both of them are widely used for rating prediction in recommender systems. Given a predicted ratingr u,i and a ground-truth rating r u,i from the user u for the item i, the RMSE is calculated as:\nRMSE = 1 N u,i (r u,i \u2212r u,i ) 2(23)\nwhere N indicates the number of ratings between users and items. Similarly, MAE is calculated as follows:\nMAE = 1 N u,i r u,i \u2212r u,i(24)\nFor the evaluation of abstractive tips generation, the ground truth s h is the tips written by the user for the item. We use ROUGE [20] as our evaluation metric with standard options 8 . It is a classical evaluation metric in the field of text summarization [3,20]. It counts the number of overlapping units between the generated tips and the ground truth written by users. Assuming that s is the generated tips, \u0434 n is n-gram, C(\u0434 n ) is the number of n-grams ins (s h or s), C m (\u0434 n ) is the number of n-grams co-occurring in s and s h , then the ROUGE-N score for s is defined as follows:\nROU GE-N (s) = \u0434 n \u2208s h C m (\u0434 n )/ \u0434 n \u2208s C(\u0434 n )(25)\nWhens = s h , we can get ROU GE r ecall , and whens = s, we get ROU GE pr esicion . We use Recall, Precision, and F-measure of ROUGE-1 (R-1), ROUGE-2 (R-2), ROUGE-L (R-L), and ROUGE-SU4 (R-SU4) to evaluate the quality of the generated tips.\n\n\nComparative Methods\n\nTo evaluate the performance of rating prediction, we compare our model with the following methods:\n\n\u2022 RMR: Ratings Meet Reviews [21]. It utilizes a topic modeling technique to model the review texts and achieves significant improvements compared with other strong topic modeling based methods. \u2022 CTR: Collaborative Topic Regression [40]. It is a popular method for scientific articles recommendation by solving a one-class collaborative filtering problem. Note that CTR uses both ratings and item specifications. \u2022 NMF: Non-negative Matrix Factorization [18]. It only uses the rating matrix as the input. \u2022 PMF: Probabilistic Matrix Factorization [31]. Gaussian distribution is introduced to model the latent factors for users and items. \u2022 LRMF: Learning to Rank with Matrix Factorization [35].\n\nIt combines a list-wise learning-to-rank algorithm with matrix factorization to improve recommendation. \u2022 SVD++: It extends Singular Value Decomposition by considering implicit feedback information for latent factor modeling [14]. \u2022 URP: User Rating Profile modeling [22]. Topic models are employed to model the user preference from a generative perspective. It still only uses the rating matrix as input. For abstractive tips generation, we find that no existing works can generate abstractive tips purely based on latent factors of users and items. In order to evaluate the performance and conduct comparison with some baselines, we refine some existing methods to make them capable of extracting sentences for tips generation as follows.\n\nLexRank [7] is a classical method in the field of text summarization. We add a preprocessing procedure to prepare the input texts for LexRank, which consists of the following steps: (1) Retrieval: For the user u, we first retrieve all her reviews C u from the training set. For the item i, we use the same method to get C i . (2) Filtering: Assuming that the ground truth rating for u and i is r u,i , then we remove all the reviews from C u and C i whose ratings are not equal to r u,i . The reviews whose words only appear in one set are also removed. (3) Tips extraction: We first merge C u and C i to get C u,i , then the problem can be regarded as a multi-document summarization problem. LexRank can extract a sentence from C u,i RMR for tips topic extraction [21] as the final tips. Note that we give an advantage of this method since the ground truth ratings are used. CTR contains a topic model component and it can generate topics for items. So the topic related variables are employed to extract tips: (1) We first get the latent factor \u03b8 i for item i, and draw the topic z with the largest probability from \u03b8 i . Then from \u03d5 z , which is a multinomial distribution of z on V, we select the top-50 words with the largest probability. (2) The most similar sentence from C u,i is extracted as the tips. This baseline is named CTR t . Another baseline method RMR t is designed in the same way.\n\nFinally, we list all the methods and baselines in Table 3.\n\n\nExperimental Settings\n\nEach dataset is divided into three subsets: 80%, 10%, and 10%, for training, validation, and testing, receptively. All the parameters of our model are tuned with the validation set. After the tuning process, we set the number of latent factors k = 10 for LRMF, NMF, PMF, and SVD++. We set the number of topics K = 50 for the methods using topic models. In our model NRT, we set K = 300 for user latent factors, item latent factors, and word latent factors. The dimension of the hidden size is 400. The number of layers for the rating regression model is 4, and for the tips generation model is 1. We set the beam size \u03b2 = 4, and the maximum length \u03b7 = 20. For the optimization objective, we let the weight parameters \u03bb r = \u03bb c = \u03bb s = 1, and \u03bb n = 0.0001. The batch size for mini-batch training is 200. All the neural matrix parameters in hidden layers and RNN layers are initialized from a uniform distribution between [\u22120.1, 0.1]. Adadelta [48] is used for gradient based optimization. Our framework is implemented with Theano [38] on a single Tesla K80 GPU.\n\n\nRESULTS AND DISCUSSIONS 5.1 Rating Prediction (RQ1)\n\nThe rating prediction results of our framework NRT and comparative models on all datasets are given in Table 4. It shows that our model consistently outperforms all comparative methods under both MAE and RMSE metrics on all datasets. From the comparison, we notice that the topic modeling based methods CTR and RMR are much better than LRMF, NMF, PMF, and SVD++. The reason is that CTR and RMR consider text information such as item specifications and user reviews to improve the representation quality of latent factors, while the traditional CF-based models (e.g. LRMF, NMF, PMF, and SVD++) only consider the rating matrix as the input. Statistical significance of differences between the performance of NRT and RMR, the best comparison method, is tested using a two-tailed paired t-test. The result shows that NRT is significantly better than RMR. Except jointly learning the tips decoder, we did not apply any sophisticated linguistic operations on the texts of reviews and tips. Jointly modeling the tips information is already very helpful for recommendation performance. In fact, tips and its corresponding rating are two facets of product assessment by a user on an item, namely, the qualitative facet and the quantitative facet. Our framework NRT elegantly captures this information with its multi-task learning model. Therefore the learnt latent factors are more effective.\n\n\nAbstractive Tips Generation (RQ2)\n\nOur NRT model can not only solve the rating prediction problem, but also generate abstractive tips simulating how users express their experience and feelings. The evaluation results of tips generation of our model and the comparative methods are given in Table 5\u223cTable 8. In order to capture more details, we report Recall, Precision, and F-measure (in percentage) of ROUGE-1, ROUGE-2, ROUGE-L, and ROUGE-SU4. Our model achieves the best performance in the metrics of Precision and F1-measure among all the four datasets. On the dataset of Movies&TV, NRT also achieves the best Recall for all ROUGE metrics.\n\nFor most of the datasets, our NRT model does not outperform the baselines on Recall. There are several reasons: (1) The ground truth tips used in the training set are very short, only about 10word length on average. Naturally, the model trained using this dataset cannot generate long sentence. (2) The mechanism of typical beam search algorithm makes the model favor short sentences. (3) The comparison models are extraction-based approaches and these models favor to extract long sentence, although we add a length (i.e., 20 words) restriction on them.   We investigate the performance of different beam size \u03b2 used in the beam search algorithm. The relationship between ROUGE and \u03b2 on two validation sets of Electronics and Movies&TV is shown in Figure 3. We test \u03b2 \u223c {1 \u223c 5, 10, 20} and find that when \u03b2 = 3 \u223c 5 our model can achieve the best performance of tips generation.\n\nInspired by [45], we make use of Length-Normalization (LN) to adjust the log-probability in the beam search algorithm to make the beam search algorithm also consider long sentences:\nLN (s) = (n + |s |) \u03b1 (n + 1) \u03b1(26)\nwhere s is the decoded sequence, n = 2, and \u03b1 = 0.6. We conduct several experiments to verify the effectiveness of LN. The comparison results are shown in Table 9, where F1-measures of ROUGE evaluation metrics are reported. It is obvious that our model NRT with LN is much better than the one without LN.\n\n\nCase Analysis (RQ3)\n\nFor the purpose of analyzing the linguistic quality and the sentiment correlation between the predicted ratings and the generated tips, we selected some real cases form different domains. The results are listed in Table 10. Although our model generates tips in an abstractive way, tips' linguistic quality is quite good.\n\nFor the sentiment correlation analysis, we also choose some generated tips with negative sentiment. Take the tips \"Not as good as i expected.\" as an example, our model predicts a rating of 2.25, which clearly shows the consistent sentiment. The ground truth     tips of this example is \"Jack of all trades master of none. \", which also conveys a negative sentiment. One interesting observation is that its ground truth rating is the full mark 5, which we guess, may be clicked by a fat finger. Nevertheless, our model can generate a consistent sentiment between this case's rating and tips. Another generated tips \"What a waste of time and money. \" with a negative predicted rating of 1.46 also demonstrates this property. There are also some bad cases. For example, the predicted rating of the generated tips \"Not bad for the price.\" is 4.34, which is a positive polarity. But the sentiment of the generated tips is neutral, consistent with the ground truth. Generally speaking, our model can achieve satisfactory performance on both rating prediction and abstractive tips generation.\n\n\nCONCLUSIONS\n\nWe propose a deep learning based framework named NRT which can simultaneously predict precise ratings and generate abstractive tips with good linguistic quality simulating user experience and feelings. For abstractive tips generation, GRU with context information is employed to \"translate\" user and item latent factors into a concise sentence. All the neural parameters as well as the latent factors for users and items are learnt by a multi-task learning approach in an end-to-end training paradigm. Experimental results on benchmark datasets show that NRT achieves better performance than the state-of-the-art models on both tasks of rating prediction and abstractive tips generation. The generated tips can vividly predict the user experience and feelings. Table 10: Examples of the predicted ratings and the generated tips. The first line of each group shows the generated rating and tips. The second line shows the ground truth.\n\n\nRating\n\nTips 4.64 This is a great product for a great price. 5\n\nGreat product at a great price. 4.87 I purchased this as a replacement and it is a perfect fit and the sound is excellent. 5\n\nAmazing sound. 4.69 I have been using these for a couple of months. 4\n\nPlenty of wire gets signals and power to my amp just fine quality wise.\n\n\n4.87\n\nOne of my favorite movies. 5\n\nThis is a movie that is not to be missed.\n\n\n4.07\n\nWhy do people hate this film. 4\n\nUniversal why didnt your company release this edition in 1999.\n\n\n2.25\n\nNot as good as i expected.\n\n\n5\n\nJack of all trades master of none.\n\n\n1.46\n\nWhat a waste of time and money. 1\n\nThe coen brothers are two sick bastards.\n\n\n4.34\n\nNot bad for the price. 3\n\nEnded up altering it to get rid of ripples.\n\nFigure 2 :\n2Our proposed framework NRT for rating regression and abstractive tips generation.\n\n\n: Initialize \u03a0 = \u2205, \u03c0 [0 : \u03b2 \u2212 1] = 0, \u03a0 p = \u2205, \u03c0 p = 0, t = 0; 2: Get user latent factor and item latent factor: u = U(:, u) and v = V(:, v) 3: while t < \u03b7 do4:    Generate \u03b2 new states based on \u03a0: {\u015d t } \u03b2 words {w 0 , w 1 , . . . , w \u03b2 \u22121 } \u2190 \u03b2arg max\n\nFigure 3 :\n3Effectiveness of beam size \u03b2 on the validation set.\n\nTable 1 :\n1Glossary.Symbol \nDescription \nX \ntraining set \nV \nvocabulary \nU \nset of users \nI \nset of items \nR \nset of ratings \nC \nset of reviews \nS \nset of tips \nC ct x \ncontext for tips decoder \nU \nuser latent factors \nV \nitem latent factors \nE \nword embeddings \nH \nneural hidden states \nu \nuser latent factor \nv \nitem latent factor \nW \nmapping matrix \nb \nbias item \n\u0398 \nset of neural parameters \nr u,i \nrating of user u to item j \n\u03c3 \nsigmoid function \n\u03c2 \nsoftmax function \ntanh \nhyperbolic tangent function \n\n\n\nTable 2 :\n2Overview of the datasets.Books Electronics Movies&TV Yelp-2016 \n\nusers \n603,668 \n192,403 \n123,960 \n684,295 \nitems \n367,982 \n63,001 \n50,052 \n85,533 \nreviews 8,887,781 \n1,684,779 \n1,697,533 \n2,346,227 \n|V | \n258,190 \n70,294 \n119,530 \n111,102 \n\n\u2022 RQ2: What is the performance of NRT in abstractive tips \ngeneration? Can the generated tips express user experience \nand feelings? (See Section 5.2) \n\u2022 RQ3: What is the relationship between predicted ratings \nand the sentiment of generated tips? (See Section 5.3) \nWe conduct extensive experiments to investigate the above re-\nsearch questions. \n\n\n\nTable 3 :\n3Baselines and methods used for comparison.Acronym Gloss \nReference \n\nNRT \nNeural rating and tips generation \nSection 3 \n\nRating prediction \nRMR \nRatings meet reviews model \n[21] \nCTR \nCollaborative topic regression model \n[40] \nNMF \nNon-negative matrix factorization \n[18] \nPMF \nProbabilistic matrix factorization \n[31] \nLRMF \nList-wise learning to rank for item ranking [35] \nSVD++ \nFactorization meets the neighborhood \n[14] \nURP \nUser rating profile modeling using LDA \n[22] \nTips generation \nLexRank Pagerank for summarization \n[7] \nCTR t \nCTR for tips topic extraction \n[40] \nRMR t \n\n\nTable 4 :\n4MAE and RMSE values for rating prediction.Books \nElectronics \nMovies \nYelp-2016 \n\nMAE \nRMSE \nMAE \nRMSE \nMAE \nRMSE \nMAE \nRMSE \n\nLRMF \n1.939 \n2.153 \n2.005 \n2.203 \n1.977 \n2.189 \n1.809 \n2.038 \nPMF \n0.882 \n1.219 \n1.220 \n1.612 \n0.927 \n1.290 \n1.320 \n1.752 \nNMF \n0.731 \n1.035 \n0.904 \n1.297 \n0.794 \n1.135 \n1.062 \n1.454 \nSVD++ 0.686 \n0.967 \n0.847 \n1.194 \n0.745 \n1.049 \n1.020 \n1.349 \nURP \n0.704 \n0.945 \n0.860 \n1.126 \n0.764 \n1.006 \n1.030 \n1.286 \nCTR \n0.736 \n0.961 \n0.903 \n1.154 \n0.854 \n1.069 \n1.174 \n1.392 \nRMR \n0.681 \n0.933 \n0.822 \n1.123 \n0.741 \n1.005 \n0.994 \n1.286 \nNRT \n0.667* 0.927* 0.806* 1.107* 0.702* 0.985* 0.985* 1.277* \n\n*Statistical significance tests show that our method is better than RMR [21]. \n\n\n\nTable 5 :\n5ROUGE evaluation on dataset Books. LexRank 12.94 12.02 12.18 2.26 2.29 2.23 11.72 10.89 11.02 4.13 4.15 4.02Methods \nROUGE-1 \nROUGE-2 \nROUGE-L \nROUGE-SU4 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \nRMR t \n13.80 11.69 12.43 1.79 1.57 1.64 12.54 10.55 11.25 4.49 3.54 3.80 \nCTR t \n14.06 11.85 12.62 2.03 1.80 1.87 12.68 10.64 11.35 4.71 3.71 3.99 \nNRT \n10.30 19.28 12.67 1.91 3.76 2.36 9.71 17.92 11.88 3.24 8.03 4.13 \n\n\n\nTable 6 :\n6ROUGE evaluation on dataset Electronics.Methods \nROUGE-1 \nROUGE-2 \nROUGE-L \nROUGE-SU4 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \nLexRank 13.42 13.48 12.08 1.90 2.04 1.83 11.72 11.48 10.44 4.57 4.51 3.88 \nRMR t \n15.68 11.32 12.30 2.52 2.04 2.15 13.37 9.61 \n10.45 5.41 3.72 3.97 \nCTR t \n15.81 11.37 12.38 2.49 1.92 2.05 13.45 9.62 \n10.50 5.39 3.63 3.89 \nNRT \n13.08 17.72 13.95 2.59 3.36 2.72 11.93 16.01 12.67 4.51 6.69 4.68 \n\n\n\nTable 7 :\n7ROUGE evaluation on dataset Movies&TV. LexRank 13.62 14.11 12.37 1.92 2.09 1.81 11.69 11.74 10.47 4.47 4.53 3.75 RMR t 14.64 10.26 11.33 1.78 1.36 1.46 12.62 NRT 15.17 20.22 16.20 4.25 5.72 4.56 13.82 18.36 14.73 6.04 8.76 6.33Methods \nROUGE-1 \nROUGE-2 \nROUGE-L \nROUGE-SU4 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \n8.72 \n9.67 \n4.63 3.00 3.28 \nCTR t \n15.13 10.37 11.57 1.90 1.42 1.54 13.02 \n8.77 \n9.85 \n4.88 3.03 3.36 \n\n\nTable 8 :\n8ROUGE evaluation on dataset Yelp-2016. LexRank 11.32 11.16 11.04 1.32 1.34 1.31 10.33 10.16 10.06 3.41 3.38 3.26 17.75 11.64 1.83 3.39 2.22 8.70 16.27 10.74 3.01 7.06 3.78Methods \nROUGE-1 \nROUGE-2 \nROUGE-L \nROUGE-SU4 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \nR \nP \nF1 \nRMR t \n11.17 10.25 10.54 2.25 2.16 2.19 10.22 9.39 \n9.65 3.88 3.66 3.72 \nCTR t \n10.74 9.95 \n10.19 2.21 2.14 2.15 9.91 \n9.19 \n9.41 3.96 3.64 3.70 \nNRT \n9.39 \n\nTable 9 :\n9Effectiveness of Length-Normalization (LN). R-* refers to ROUGE-*.Dataset \nMethod \nR-1 \nR-2 \nR-L R-SU4 \nElectronics \nNRT w/o LN 13.36 2.65 12.34 \n4.56 \nNRT \n13.72 2.68 12.57 \n4.66 \nMovies&TV NRT w/o LN 14.86 3.72 13.76 \n5.46 \nNRT \n15.21 4.00 13.90 \n5.71 \n\n\nhttp://www.spotify.com 2 http://www.imdb.com 3 http://www.linkedin.com\nhttp://www.citeulike.org 5 http://www.yelp.com\nhttp://jmcauley.ucsd.edu/data/amazon 7 https://www.yelp.com/dataset_challenge 8 ROUGE-1.5.5.pl -n 4 -w 1.2 -m -2 4 -u -c 95 -r 1000 -f A -p 0.5 -t 0\n\nLearning distributed representations from reviews for collaborative filtering. Amjad Almahairi, Kyle Kastner, Kyunghyun Cho, Aaron Courville, RecSys. ACM. Amjad Almahairi, Kyle Kastner, Kyunghyun Cho, and Aaron Courville. 2015. Learning distributed representations from reviews for collaborative filtering. In RecSys. ACM, 147-154.\n\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, ICLR. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate. In ICLR.\n\nAbstractive Multi-Document Summarization via Phrase Selection and Merging. Lidong Bing, Piji Li, Yi Liao, Wai Lam, Weiwei Guo, Rebecca Passonneau, ACL. Lidong Bing, Piji Li, Yi Liao, Wai Lam, Weiwei Guo, and Rebecca Passonneau. 2015. Abstractive Multi-Document Summarization via Phrase Selection and Merging. In ACL. 1587-1597.\n\nLatent dirichlet allocation. M David, Blei, Y Andrew, Michael I Jordan Ng, JMLR. 3David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. JMLR 3, Jan (2003), 993-1022.\n\nRecommender systems based on user reviews: the state of the art. Li Chen, Guanliang Chen, Feng Wang, User Modeling and User-Adapted Interaction. 25Li Chen, Guanliang Chen, and Feng Wang. 2015. Recommender systems based on user reviews: the state of the art. User Modeling and User-Adapted Interaction 25, 2 (2015), 99-154.\n\nLearning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. Kyunghyun Cho, Bart Van Merri\u00ebnboer Caglar Gulcehre, Dzmitry Bahdanau, EMNLP. Fethi Bougares Holger Schwenk, and Yoshua BengioKyunghyun Cho, Bart van Merri\u00ebnboer Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. EMNLP (2014), 1724-1734.\n\nLexrank: Graph-based lexical centrality as salience in text summarization. G\u00fcnes Erkan, Dragomir R Radev, JAIR. 22G\u00fcnes Erkan and Dragomir R Radev. 2004. Lexrank: Graph-based lexical central- ity as salience in text summarization. JAIR 22 (2004), 457-479.\n\nDeep Learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, MIT PressIan Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press. http://www.deeplearningbook.org.\n\nGenerative adversarial nets. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, NIPS. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarial nets. In NIPS. 2672-2680.\n\nTrirank: Reviewaware explainable recommendation by modeling aspects. Xiangnan He, Tao Chen, Min-Yen Kan, Xiao Chen, CIKM. ACM. Xiangnan He, Tao Chen, Min-Yen Kan, and Xiao Chen. 2015. Trirank: Review- aware explainable recommendation by modeling aspects. In CIKM. ACM, 1661- 1670.\n\n. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Neural Collaborative Filtering. In WWW. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In WWW. 173-182.\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780.\n\nPharaoh: a beam search decoder for phrase-based statistical machine translation models. Philipp Koehn, Conference of the Association for Machine Translation in the Americas. SpringerPhilipp Koehn. 2004. Pharaoh: a beam search decoder for phrase-based statis- tical machine translation models. In Conference of the Association for Machine Translation in the Americas. Springer, 115-124.\n\nFactorization meets the neighborhood: a multifaceted collaborative filtering model. Yehuda Koren, KDD. ACM. Yehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In KDD. ACM, 426-434.\n\nMatrix factorization techniques for recommender systems. Yehuda Koren, Robert Bell, Computer. 42Chris Volinsky, and othersYehuda Koren, Robert Bell, Chris Volinsky, and others. 2009. Matrix factorization techniques for recommender systems. Computer 42, 8 (2009), 30-37.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, NIPS. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classifi- cation with deep convolutional neural networks. In NIPS. 1097-1105.\n\nDistributed Representations of Sentences and Documents. V Quoc, Tomas Le, Mikolov, ICML. Quoc V Le and Tomas Mikolov. 2014. Distributed Representations of Sentences and Documents.. In ICML. 1188-1196.\n\nAlgorithms for non-negative matrix factorization. D Daniel, H Lee, Sebastian Seung, NIPS. Daniel D Lee and H Sebastian Seung. 2001. Algorithms for non-negative matrix factorization. In NIPS. 556-562.\n\nSalience Estimation via Variational Auto-Encoders for Multi-Document Summarization. Piji Li, Zihao Wang, Wai Lam, Zhaochun Ren, Lidong Bing, AAAI. Piji Li, Zihao Wang, Wai Lam, Zhaochun Ren, and Lidong Bing. 2017. Salience Estimation via Variational Auto-Encoders for Multi-Document Summarization. In AAAI. 3497-3503.\n\nRouge: A package for automatic evaluation of summaries. Chin-Yew Lin, ACL Workshop. 8Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In ACL Workshop, Vol. 8.\n\nRatings meet reviews, a combined approach to recommend. Guang Ling, Irwin Michael R Lyu, King, RecSys. Guang Ling, Michael R Lyu, and Irwin King. 2014. Ratings meet reviews, a combined approach to recommend. In RecSys. 105-112.\n\nModeling user rating profiles for collaborative filtering. Benjamin M Marlin, NIPS. Benjamin M Marlin. 2003. Modeling user rating profiles for collaborative filtering. In NIPS. 627-634.\n\nHidden factors and hidden topics: understanding rating dimensions with review text. Julian Mcauley, Jure Leskovec, RecSys. ACM. Julian McAuley and Jure Leskovec. 2013. Hidden factors and hidden topics: understanding rating dimensions with review text. In RecSys. ACM, 165-172.\n\nDistributed representations of words and phrases and their compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, NIPS. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In NIPS. 3111-3119.\n\nAndrew Ng, Sparse autoencoder. CS294A Lecture notes. 72Andrew Ng. 2011. Sparse autoencoder. CS294A Lecture notes 72 (2011), 1-19.\n\nSocial collaborative viewpoint regression with explainable recommendations. Shangsong Zhaochun Ren, Piji Liang, Shuaiqiang Li, Maarten Wang, De Rijke, WSDM. Zhaochun Ren, Shangsong Liang, Piji Li, Shuaiqiang Wang, and Maarten de Rijke. 2017. Social collaborative viewpoint regression with explainable recom- mendations. In WSDM.\n\nIntroduction to recommender systems handbook. Francesco Ricci, Lior Rokach, Bracha Shapira, SpringerFrancesco Ricci, Lior Rokach, and Bracha Shapira. 2011. Introduction to recom- mender systems handbook. Springer.\n\nPrinciples of neurodynamics. perceptrons and the theory of brain mechanisms. Frank Rosenblatt, DTIC DocumentTechnical ReportFrank Rosenblatt. 1961. Principles of neurodynamics. perceptrons and the theory of brain mechanisms. Technical Report. DTIC Document.\n\nLearning representations by back-propagating errors. Geoffrey E David E Rumelhart, Ronald J Hinton, Williams, Cognitive modeling. 51David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. 1988. Learning representations by back-propagating errors. Cognitive modeling 5, 3 (1988), 1.\n\nA neural attention model for abstractive sentence summarization. Sumit Alexander M Rush, Jason Chopra, Weston, EMNLP. Alexander M Rush, Sumit Chopra, and Jason Weston. 2015. A neural attention model for abstractive sentence summarization. In EMNLP.\n\nProbabilistic Matrix Factorization. Ruslan Salakhutdinov, Andriy Mnih, NIPS. Ruslan Salakhutdinov and Andriy Mnih. 2007. Probabilistic Matrix Factorization.. In NIPS. 1-8.\n\nRestricted Boltzmann machines for collaborative filtering. Ruslan Salakhutdinov, Andriy Mnih, Geoffrey Hinton, ICML. ACM. Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey Hinton. 2007. Restricted Boltzmann machines for collaborative filtering. In ICML. ACM, 791-798.\n\nItem-based collaborative filtering recommendation algorithms. Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl, WWW. ACM. Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based collaborative filtering recommendation algorithms. In WWW. ACM, 285-295.\n\nAutorec: Autoencoders meet collaborative filtering. Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, Lexing Xie, WWW. ACM. Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015. Autorec: Autoencoders meet collaborative filtering. In WWW. ACM, 111-112.\n\nList-wise learning to rank with matrix factorization for collaborative filtering. Yue Shi, Martha Larson, Alan Hanjalic, RecSys. Yue Shi, Martha Larson, and Alan Hanjalic. 2010. List-wise learning to rank with matrix factorization for collaborative filtering. In RecSys. 269-272.\n\nReasoning with neural tensor networks for knowledge base completion. Richard Socher, Danqi Chen, D Christopher, Andrew Manning, Ng, NIPS. Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In NIPS. 926-934.\n\nA survey of collaborative filtering techniques. Xiaoyuan Su, M Taghi, Khoshgoftaar, Advances in artificial intelligence. 4Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009 (2009), 4.\n\nTheano: A Python framework for fast computation of mathematical expressions. abs/1605.02688Theano Development TeamTheano Development Team. 2016. Theano: A Python framework for fast compu- tation of mathematical expressions. arXiv e-prints abs/1605.02688 (2016).\n\nStacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine Manzagol, JMLR. 11Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre- Antoine Manzagol. 2010. Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. JMLR 11 (2010), 3371-3408.\n\nCollaborative topic modeling for recommending scientific articles. Chong Wang, M David, Blei, KDD. ACM. Chong Wang and David M Blei. 2011. Collaborative topic modeling for recom- mending scientific articles. In KDD. ACM, 448-456.\n\nCollaborative deep learning for recommender systems. Hao Wang, Naiyan Wang, Dit-Yan Yeung, KDD. ACM. Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative deep learning for recommender systems. In KDD. ACM, 1235-1244.\n\nCollaborative recurrent autoencoder: Recommend while learning to fill in the blanks. Hao Wang, Dit-Yan Shi Xingjian, Yeung, NIPS. Hao Wang, SHI Xingjian, and Dit-Yan Yeung. 2016. Collaborative recurrent autoencoder: Recommend while learning to fill in the blanks. In NIPS. 415-423.\n\nRecurrent Recommender Networks. Chao-Yuan, Amr Wu, Alex Ahmed, Alexander J Beutel, How Smola, Jing, WSDM. Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. 2017. Recurrent Recommender Networks. In WSDM. 495-503.\n\nCollaborative denoising auto-encoders for top-n recommender systems. Yao Wu, Christopher Dubois, Alice X Zheng, Martin Ester, WSDM. ACM. Yao Wu, Christopher DuBois, Alice X Zheng, and Martin Ester. 2016. Collabora- tive denoising auto-encoders for top-n recommender systems. In WSDM. ACM, 153-162.\n\nYonghui Wu, Mike Schuster, Zhifeng Chen, V Quoc, Mohammad Le, Wolfgang Norouzi, Maxim Macherey, Yuan Krikun, Qin Cao, Gao, arXiv:1609.08144Klaus Macherey, and others. 2016. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arXiv preprintYonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, and others. 2016. Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation. arXiv preprint arXiv:1609.08144 (2016).\n\nCollaborative filtering incorporating review text and co-clusters of hidden user communities and item groups. Yinqing Xu, Wai Lam, Tianyi Lin, CIKM. ACM. Yinqing Xu, Wai Lam, and Tianyi Lin. 2014. Collaborative filtering incorporating review text and co-clusters of hidden user communities and item groups. In CIKM. ACM, 251-260.\n\nA Unified Model for Unsupervised Opinion Spamming Detection Incorporating Text Generality. Yinqing Xu, Bei Shi, Wentao Tian, Wai Lam, IJCAI. Yinqing Xu, Bei Shi, Wentao Tian, and Wai Lam. 2015. A Unified Model for Unsupervised Opinion Spamming Detection Incorporating Text Generality. In IJCAI. 725-731.\n\nADADELTA: an adaptive learning rate method. D Matthew, Zeiler, arXiv:1212.5701arXiv preprintMatthew D Zeiler. 2012. ADADELTA: an adaptive learning rate method. arXiv preprint arXiv:1212.5701 (2012).\n\nJoint deep modeling of users and items using reviews for recommendation. Lei Zheng, Vahid Noroozi, Philip S Yu, WSDM. ACM. Lei Zheng, Vahid Noroozi, and Philip S Yu. 2017. Joint deep modeling of users and items using reviews for recommendation. In WSDM. ACM, 425-434.\n", "annotations": {"author": "[{\"end\":140,\"start\":112},{\"end\":174,\"start\":141},{\"end\":207,\"start\":175},{\"end\":243,\"start\":208},{\"end\":272,\"start\":244},{\"end\":565,\"start\":273},{\"end\":659,\"start\":566},{\"end\":698,\"start\":660}]", "publisher": null, "author_last_name": "[{\"end\":119,\"start\":117},{\"end\":151,\"start\":147},{\"end\":187,\"start\":184},{\"end\":219,\"start\":215},{\"end\":251,\"start\":248}]", "author_first_name": "[{\"end\":116,\"start\":112},{\"end\":146,\"start\":141},{\"end\":183,\"start\":175},{\"end\":214,\"start\":208},{\"end\":247,\"start\":244}]", "author_affiliation": "[{\"end\":564,\"start\":274},{\"end\":658,\"start\":567},{\"end\":697,\"start\":661}]", "title": "[{\"end\":91,\"start\":1},{\"end\":789,\"start\":699}]", "venue": "[{\"end\":800,\"start\":791}]", "abstract": "[{\"end\":2640,\"start\":1021}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3195,\"start\":3191},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3198,\"start\":3195},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3201,\"start\":3198},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3204,\"start\":3201},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3207,\"start\":3204},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3210,\"start\":3207},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3213,\"start\":3210},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3306,\"start\":3303},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3309,\"start\":3306},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3312,\"start\":3309},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3315,\"start\":3312},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3318,\"start\":3315},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3321,\"start\":3318},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3484,\"start\":3480},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":3488,\"start\":3484},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3492,\"start\":3488},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3513,\"start\":3510},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3516,\"start\":3513},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3519,\"start\":3516},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3522,\"start\":3519},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3525,\"start\":3522},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3528,\"start\":3525},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3531,\"start\":3528},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3694,\"start\":3693},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4162,\"start\":4159},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5170,\"start\":5167},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":5789,\"start\":5785},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5793,\"start\":5789},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":5797,\"start\":5793},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5818,\"start\":5815},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5821,\"start\":5818},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5824,\"start\":5821},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5827,\"start\":5824},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":5830,\"start\":5827},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":5833,\"start\":5830},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":5836,\"start\":5833},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6671,\"start\":6668},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6867,\"start\":6863},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6902,\"start\":6899},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6967,\"start\":6964},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6970,\"start\":6967},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6998,\"start\":6994},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7001,\"start\":6998},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7552,\"start\":7548},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8971,\"start\":8967},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":8974,\"start\":8971},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9042,\"start\":9038},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9188,\"start\":9184},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9234,\"start\":9230},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9285,\"start\":9281},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9853,\"start\":9849},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9873,\"start\":9869},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9915,\"start\":9912},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10013,\"start\":10009},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10250,\"start\":10246},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10260,\"start\":10256},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10274,\"start\":10270},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10289,\"start\":10285},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10944,\"start\":10941},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":11168,\"start\":11164},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11395,\"start\":11391},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11525,\"start\":11521},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11528,\"start\":11525},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":11531,\"start\":11528},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11557,\"start\":11553},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11827,\"start\":11823},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":13486,\"start\":13483},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13989,\"start\":13985},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14278,\"start\":14274},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":15159,\"start\":15156},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15162,\"start\":15159},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15196,\"start\":15192},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15199,\"start\":15196},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":15235,\"start\":15231},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":16038,\"start\":16034},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18486,\"start\":18482},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18521,\"start\":18518},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18586,\"start\":18583},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":18589,\"start\":18586},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":20342,\"start\":20338},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20515,\"start\":20511},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":20518,\"start\":20515},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22490,\"start\":22489},{\"end\":24068,\"start\":24058},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":24521,\"start\":24520},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":25250,\"start\":25248},{\"end\":25304,\"start\":25293},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":25983,\"start\":25982},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":27454,\"start\":27450},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":27503,\"start\":27502},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":27580,\"start\":27577},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":27583,\"start\":27580},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":28363,\"start\":28359},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":28567,\"start\":28563},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":28789,\"start\":28785},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":28882,\"start\":28878},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":29024,\"start\":29020},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":29256,\"start\":29252},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":29298,\"start\":29294},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":29780,\"start\":29777},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":30098,\"start\":30095},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":30538,\"start\":30534},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":32201,\"start\":32197},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":35297,\"start\":35293}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":39035,\"start\":38941},{\"attributes\":{\"id\":\"fig_1\"},\"end\":39292,\"start\":39036},{\"attributes\":{\"id\":\"fig_4\"},\"end\":39357,\"start\":39293},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39868,\"start\":39358},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40472,\"start\":39869},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41073,\"start\":40473},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41785,\"start\":41074},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42213,\"start\":41786},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42649,\"start\":42214},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":43079,\"start\":42650},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":43506,\"start\":43080},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":43775,\"start\":43507}]", "paragraph": "[{\"end\":4416,\"start\":2656},{\"end\":5707,\"start\":4418},{\"end\":6672,\"start\":5709},{\"end\":7867,\"start\":6674},{\"end\":7930,\"start\":7869},{\"end\":8831,\"start\":7932},{\"end\":10789,\"start\":8849},{\"end\":11924,\"start\":10791},{\"end\":12309,\"start\":11963},{\"end\":14279,\"start\":12311},{\"end\":14602,\"start\":14308},{\"end\":14790,\"start\":14619},{\"end\":16504,\"start\":14820},{\"end\":16573,\"start\":16506},{\"end\":16948,\"start\":16616},{\"end\":17148,\"start\":16971},{\"end\":17433,\"start\":17193},{\"end\":17660,\"start\":17460},{\"end\":17814,\"start\":17707},{\"end\":18939,\"start\":17853},{\"end\":19184,\"start\":19000},{\"end\":19356,\"start\":19225},{\"end\":19528,\"start\":19389},{\"end\":20002,\"start\":19744},{\"end\":20901,\"start\":20004},{\"end\":21314,\"start\":20931},{\"end\":22016,\"start\":21348},{\"end\":22365,\"start\":22060},{\"end\":22900,\"start\":22397},{\"end\":23345,\"start\":22938},{\"end\":23510,\"start\":23347},{\"end\":23939,\"start\":23584},{\"end\":24155,\"start\":23974},{\"end\":24308,\"start\":24199},{\"end\":24522,\"start\":24400},{\"end\":24766,\"start\":24621},{\"end\":24872,\"start\":24807},{\"end\":25052,\"start\":24896},{\"end\":25503,\"start\":25138},{\"end\":25617,\"start\":25549},{\"end\":25752,\"start\":25619},{\"end\":26245,\"start\":25765},{\"end\":26628,\"start\":26247},{\"end\":26801,\"start\":26630},{\"end\":27144,\"start\":26824},{\"end\":27287,\"start\":27182},{\"end\":27911,\"start\":27319},{\"end\":28207,\"start\":27967},{\"end\":28329,\"start\":28231},{\"end\":29025,\"start\":28331},{\"end\":29767,\"start\":29027},{\"end\":31169,\"start\":29769},{\"end\":31229,\"start\":31171},{\"end\":32315,\"start\":31255},{\"end\":33754,\"start\":32371},{\"end\":34399,\"start\":33792},{\"end\":35279,\"start\":34401},{\"end\":35462,\"start\":35281},{\"end\":35803,\"start\":35499},{\"end\":36147,\"start\":35827},{\"end\":37234,\"start\":36149},{\"end\":38184,\"start\":37250},{\"end\":38249,\"start\":38195},{\"end\":38375,\"start\":38251},{\"end\":38446,\"start\":38377},{\"end\":38519,\"start\":38448},{\"end\":38556,\"start\":38528},{\"end\":38599,\"start\":38558},{\"end\":38639,\"start\":38608},{\"end\":38703,\"start\":38641},{\"end\":38738,\"start\":38712},{\"end\":38778,\"start\":38744},{\"end\":38820,\"start\":38787},{\"end\":38862,\"start\":38822},{\"end\":38895,\"start\":38871},{\"end\":38940,\"start\":38897}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14618,\"start\":14603},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14819,\"start\":14791},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16615,\"start\":16574},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16970,\"start\":16949},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17192,\"start\":17149},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17459,\"start\":17434},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17706,\"start\":17661},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18999,\"start\":18940},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19224,\"start\":19185},{\"attributes\":{\"id\":\"formula_9\"},\"end\":19388,\"start\":19357},{\"attributes\":{\"id\":\"formula_10\"},\"end\":19743,\"start\":19529},{\"attributes\":{\"id\":\"formula_11\"},\"end\":20930,\"start\":20902},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21347,\"start\":21315},{\"attributes\":{\"id\":\"formula_13\"},\"end\":22059,\"start\":22017},{\"attributes\":{\"id\":\"formula_14\"},\"end\":22396,\"start\":22366},{\"attributes\":{\"id\":\"formula_15\"},\"end\":22937,\"start\":22901},{\"attributes\":{\"id\":\"formula_16\"},\"end\":23583,\"start\":23511},{\"attributes\":{\"id\":\"formula_17\"},\"end\":23973,\"start\":23940},{\"attributes\":{\"id\":\"formula_18\"},\"end\":24198,\"start\":24156},{\"attributes\":{\"id\":\"formula_19\"},\"end\":24341,\"start\":24309},{\"attributes\":{\"id\":\"formula_20\"},\"end\":24620,\"start\":24523},{\"attributes\":{\"id\":\"formula_21\"},\"end\":24806,\"start\":24767},{\"attributes\":{\"id\":\"formula_22\"},\"end\":25137,\"start\":25053},{\"attributes\":{\"id\":\"formula_23\"},\"end\":27181,\"start\":27145},{\"attributes\":{\"id\":\"formula_24\"},\"end\":27318,\"start\":27288},{\"attributes\":{\"id\":\"formula_25\"},\"end\":27966,\"start\":27912},{\"attributes\":{\"id\":\"formula_26\"},\"end\":35498,\"start\":35463}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12417,\"start\":12410},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26800,\"start\":26793},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":31228,\"start\":31221},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32481,\"start\":32474},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":34060,\"start\":34047},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":35661,\"start\":35654},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":36049,\"start\":36041},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":38019,\"start\":38011}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2654,\"start\":2642},{\"attributes\":{\"n\":\"2\"},\"end\":8847,\"start\":8834},{\"attributes\":{\"n\":\"3\"},\"end\":11961,\"start\":11927},{\"attributes\":{\"n\":\"3.2\"},\"end\":14306,\"start\":14282},{\"attributes\":{\"n\":\"3.3\"},\"end\":17851,\"start\":17817},{\"end\":24398,\"start\":24343},{\"attributes\":{\"n\":\"3.4\"},\"end\":24894,\"start\":24875},{\"attributes\":{\"n\":\"4\"},\"end\":25547,\"start\":25506},{\"attributes\":{\"n\":\"4.2\"},\"end\":25763,\"start\":25755},{\"attributes\":{\"n\":\"4.3\"},\"end\":26822,\"start\":26804},{\"attributes\":{\"n\":\"4.4\"},\"end\":28229,\"start\":28210},{\"attributes\":{\"n\":\"4.5\"},\"end\":31253,\"start\":31232},{\"attributes\":{\"n\":\"5\"},\"end\":32369,\"start\":32318},{\"attributes\":{\"n\":\"5.2\"},\"end\":33790,\"start\":33757},{\"attributes\":{\"n\":\"5.3\"},\"end\":35825,\"start\":35806},{\"attributes\":{\"n\":\"6\"},\"end\":37248,\"start\":37237},{\"end\":38193,\"start\":38187},{\"end\":38526,\"start\":38522},{\"end\":38606,\"start\":38602},{\"end\":38710,\"start\":38706},{\"end\":38742,\"start\":38741},{\"end\":38785,\"start\":38781},{\"end\":38869,\"start\":38865},{\"end\":38952,\"start\":38942},{\"end\":39304,\"start\":39294},{\"end\":39368,\"start\":39359},{\"end\":39879,\"start\":39870},{\"end\":40483,\"start\":40474},{\"end\":41084,\"start\":41075},{\"end\":41796,\"start\":41787},{\"end\":42224,\"start\":42215},{\"end\":42660,\"start\":42651},{\"end\":43090,\"start\":43081},{\"end\":43517,\"start\":43508}]", "table": "[{\"end\":39868,\"start\":39379},{\"end\":40472,\"start\":39906},{\"end\":41073,\"start\":40527},{\"end\":41785,\"start\":41128},{\"end\":42213,\"start\":41906},{\"end\":42649,\"start\":42266},{\"end\":43079,\"start\":42889},{\"end\":43506,\"start\":43263},{\"end\":43775,\"start\":43585}]", "figure_caption": "[{\"end\":39035,\"start\":38954},{\"end\":39292,\"start\":39038},{\"end\":39357,\"start\":39306},{\"end\":39379,\"start\":39370},{\"end\":39906,\"start\":39881},{\"end\":40527,\"start\":40485},{\"end\":41128,\"start\":41086},{\"end\":41906,\"start\":41798},{\"end\":42266,\"start\":42226},{\"end\":42889,\"start\":42662},{\"end\":43263,\"start\":43092},{\"end\":43585,\"start\":43519}]", "figure_ref": "[{\"end\":4553,\"start\":4545},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12711,\"start\":12703},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15680,\"start\":15672},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18819,\"start\":18811},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20024,\"start\":20016},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":35158,\"start\":35150}]", "bib_author_first_name": "[{\"end\":44128,\"start\":44123},{\"end\":44144,\"start\":44140},{\"end\":44163,\"start\":44154},{\"end\":44174,\"start\":44169},{\"end\":44455,\"start\":44448},{\"end\":44475,\"start\":44466},{\"end\":44487,\"start\":44481},{\"end\":44722,\"start\":44716},{\"end\":44733,\"start\":44729},{\"end\":44740,\"start\":44738},{\"end\":44750,\"start\":44747},{\"end\":44762,\"start\":44756},{\"end\":44775,\"start\":44768},{\"end\":45000,\"start\":44999},{\"end\":45015,\"start\":45014},{\"end\":45040,\"start\":45024},{\"end\":45234,\"start\":45232},{\"end\":45250,\"start\":45241},{\"end\":45261,\"start\":45257},{\"end\":45595,\"start\":45586},{\"end\":45605,\"start\":45601},{\"end\":45646,\"start\":45639},{\"end\":46040,\"start\":46035},{\"end\":46235,\"start\":46232},{\"end\":46254,\"start\":46248},{\"end\":46268,\"start\":46263},{\"end\":46439,\"start\":46436},{\"end\":46456,\"start\":46452},{\"end\":46477,\"start\":46472},{\"end\":46489,\"start\":46485},{\"end\":46499,\"start\":46494},{\"end\":46521,\"start\":46514},{\"end\":46534,\"start\":46529},{\"end\":46552,\"start\":46546},{\"end\":46829,\"start\":46821},{\"end\":46837,\"start\":46834},{\"end\":46851,\"start\":46844},{\"end\":46861,\"start\":46857},{\"end\":47044,\"start\":47036},{\"end\":47053,\"start\":47049},{\"end\":47067,\"start\":47060},{\"end\":47082,\"start\":47075},{\"end\":47091,\"start\":47088},{\"end\":47104,\"start\":47096},{\"end\":47314,\"start\":47310},{\"end\":47333,\"start\":47327},{\"end\":47577,\"start\":47570},{\"end\":47959,\"start\":47953},{\"end\":48167,\"start\":48161},{\"end\":48181,\"start\":48175},{\"end\":48444,\"start\":48440},{\"end\":48461,\"start\":48457},{\"end\":48481,\"start\":48473},{\"end\":48483,\"start\":48482},{\"end\":48705,\"start\":48704},{\"end\":48717,\"start\":48712},{\"end\":48901,\"start\":48900},{\"end\":48911,\"start\":48910},{\"end\":49139,\"start\":49135},{\"end\":49149,\"start\":49144},{\"end\":49159,\"start\":49156},{\"end\":49173,\"start\":49165},{\"end\":49185,\"start\":49179},{\"end\":49434,\"start\":49426},{\"end\":49618,\"start\":49613},{\"end\":49630,\"start\":49625},{\"end\":50063,\"start\":50057},{\"end\":50077,\"start\":50073},{\"end\":50333,\"start\":50328},{\"end\":50347,\"start\":50343},{\"end\":50362,\"start\":50359},{\"end\":50373,\"start\":50369},{\"end\":50375,\"start\":50374},{\"end\":50389,\"start\":50385},{\"end\":50584,\"start\":50578},{\"end\":50794,\"start\":50785},{\"end\":50813,\"start\":50809},{\"end\":50831,\"start\":50821},{\"end\":50843,\"start\":50836},{\"end\":51094,\"start\":51085},{\"end\":51106,\"start\":51102},{\"end\":51121,\"start\":51115},{\"end\":51336,\"start\":51331},{\"end\":51574,\"start\":51566},{\"end\":51576,\"start\":51575},{\"end\":51604,\"start\":51596},{\"end\":51871,\"start\":51866},{\"end\":51895,\"start\":51890},{\"end\":52093,\"start\":52087},{\"end\":52115,\"start\":52109},{\"end\":52289,\"start\":52283},{\"end\":52311,\"start\":52305},{\"end\":52326,\"start\":52318},{\"end\":52559,\"start\":52553},{\"end\":52574,\"start\":52568},{\"end\":52590,\"start\":52584},{\"end\":52604,\"start\":52600},{\"end\":52834,\"start\":52828},{\"end\":52850,\"start\":52844},{\"end\":52858,\"start\":52851},{\"end\":52871,\"start\":52866},{\"end\":52886,\"start\":52880},{\"end\":53136,\"start\":53133},{\"end\":53148,\"start\":53142},{\"end\":53161,\"start\":53157},{\"end\":53408,\"start\":53401},{\"end\":53422,\"start\":53417},{\"end\":53430,\"start\":53429},{\"end\":53450,\"start\":53444},{\"end\":53686,\"start\":53678},{\"end\":53692,\"start\":53691},{\"end\":54282,\"start\":54276},{\"end\":54296,\"start\":54292},{\"end\":54317,\"start\":54309},{\"end\":54332,\"start\":54326},{\"end\":54355,\"start\":54341},{\"end\":54691,\"start\":54686},{\"end\":54699,\"start\":54698},{\"end\":54906,\"start\":54903},{\"end\":54919,\"start\":54913},{\"end\":54933,\"start\":54926},{\"end\":55165,\"start\":55162},{\"end\":55179,\"start\":55172},{\"end\":55406,\"start\":55403},{\"end\":55415,\"start\":55411},{\"end\":55432,\"start\":55423},{\"end\":55434,\"start\":55433},{\"end\":55446,\"start\":55443},{\"end\":55666,\"start\":55663},{\"end\":55682,\"start\":55671},{\"end\":55696,\"start\":55691},{\"end\":55698,\"start\":55697},{\"end\":55712,\"start\":55706},{\"end\":55900,\"start\":55893},{\"end\":55909,\"start\":55905},{\"end\":55927,\"start\":55920},{\"end\":55935,\"start\":55934},{\"end\":55950,\"start\":55942},{\"end\":55963,\"start\":55955},{\"end\":55978,\"start\":55973},{\"end\":55993,\"start\":55989},{\"end\":56005,\"start\":56002},{\"end\":56594,\"start\":56587},{\"end\":56602,\"start\":56599},{\"end\":56614,\"start\":56608},{\"end\":56906,\"start\":56899},{\"end\":56914,\"start\":56911},{\"end\":56926,\"start\":56920},{\"end\":56936,\"start\":56933},{\"end\":57158,\"start\":57157},{\"end\":57389,\"start\":57386},{\"end\":57402,\"start\":57397},{\"end\":57420,\"start\":57412}]", "bib_author_last_name": "[{\"end\":44138,\"start\":44129},{\"end\":44152,\"start\":44145},{\"end\":44167,\"start\":44164},{\"end\":44184,\"start\":44175},{\"end\":44464,\"start\":44456},{\"end\":44479,\"start\":44476},{\"end\":44494,\"start\":44488},{\"end\":44727,\"start\":44723},{\"end\":44736,\"start\":44734},{\"end\":44745,\"start\":44741},{\"end\":44754,\"start\":44751},{\"end\":44766,\"start\":44763},{\"end\":44786,\"start\":44776},{\"end\":45006,\"start\":45001},{\"end\":45012,\"start\":45008},{\"end\":45022,\"start\":45016},{\"end\":45043,\"start\":45041},{\"end\":45239,\"start\":45235},{\"end\":45255,\"start\":45251},{\"end\":45266,\"start\":45262},{\"end\":45599,\"start\":45596},{\"end\":45637,\"start\":45606},{\"end\":45655,\"start\":45647},{\"end\":46046,\"start\":46041},{\"end\":46064,\"start\":46048},{\"end\":46246,\"start\":46236},{\"end\":46261,\"start\":46255},{\"end\":46278,\"start\":46269},{\"end\":46450,\"start\":46440},{\"end\":46470,\"start\":46457},{\"end\":46483,\"start\":46478},{\"end\":46492,\"start\":46490},{\"end\":46512,\"start\":46500},{\"end\":46527,\"start\":46522},{\"end\":46544,\"start\":46535},{\"end\":46559,\"start\":46553},{\"end\":46832,\"start\":46830},{\"end\":46842,\"start\":46838},{\"end\":46855,\"start\":46852},{\"end\":46866,\"start\":46862},{\"end\":47047,\"start\":47045},{\"end\":47058,\"start\":47054},{\"end\":47073,\"start\":47068},{\"end\":47086,\"start\":47083},{\"end\":47094,\"start\":47092},{\"end\":47109,\"start\":47105},{\"end\":47325,\"start\":47315},{\"end\":47345,\"start\":47334},{\"end\":47583,\"start\":47578},{\"end\":47965,\"start\":47960},{\"end\":48173,\"start\":48168},{\"end\":48186,\"start\":48182},{\"end\":48455,\"start\":48445},{\"end\":48471,\"start\":48462},{\"end\":48490,\"start\":48484},{\"end\":48710,\"start\":48706},{\"end\":48720,\"start\":48718},{\"end\":48729,\"start\":48722},{\"end\":48908,\"start\":48902},{\"end\":48915,\"start\":48912},{\"end\":48932,\"start\":48917},{\"end\":49142,\"start\":49140},{\"end\":49154,\"start\":49150},{\"end\":49163,\"start\":49160},{\"end\":49177,\"start\":49174},{\"end\":49190,\"start\":49186},{\"end\":49438,\"start\":49435},{\"end\":49623,\"start\":49619},{\"end\":49644,\"start\":49631},{\"end\":49650,\"start\":49646},{\"end\":49862,\"start\":49845},{\"end\":50071,\"start\":50064},{\"end\":50086,\"start\":50078},{\"end\":50341,\"start\":50334},{\"end\":50357,\"start\":50348},{\"end\":50367,\"start\":50363},{\"end\":50383,\"start\":50376},{\"end\":50394,\"start\":50390},{\"end\":50587,\"start\":50585},{\"end\":50807,\"start\":50795},{\"end\":50819,\"start\":50814},{\"end\":50834,\"start\":50832},{\"end\":50848,\"start\":50844},{\"end\":50858,\"start\":50850},{\"end\":51100,\"start\":51095},{\"end\":51113,\"start\":51107},{\"end\":51129,\"start\":51122},{\"end\":51347,\"start\":51337},{\"end\":51594,\"start\":51577},{\"end\":51611,\"start\":51605},{\"end\":51621,\"start\":51613},{\"end\":51888,\"start\":51872},{\"end\":51902,\"start\":51896},{\"end\":51910,\"start\":51904},{\"end\":52107,\"start\":52094},{\"end\":52120,\"start\":52116},{\"end\":52303,\"start\":52290},{\"end\":52316,\"start\":52312},{\"end\":52333,\"start\":52327},{\"end\":52566,\"start\":52560},{\"end\":52582,\"start\":52575},{\"end\":52598,\"start\":52591},{\"end\":52610,\"start\":52605},{\"end\":52842,\"start\":52835},{\"end\":52864,\"start\":52859},{\"end\":52878,\"start\":52872},{\"end\":52890,\"start\":52887},{\"end\":53140,\"start\":53137},{\"end\":53155,\"start\":53149},{\"end\":53170,\"start\":53162},{\"end\":53415,\"start\":53409},{\"end\":53427,\"start\":53423},{\"end\":53442,\"start\":53431},{\"end\":53458,\"start\":53451},{\"end\":53462,\"start\":53460},{\"end\":53689,\"start\":53687},{\"end\":53698,\"start\":53693},{\"end\":53712,\"start\":53700},{\"end\":54290,\"start\":54283},{\"end\":54307,\"start\":54297},{\"end\":54324,\"start\":54318},{\"end\":54339,\"start\":54333},{\"end\":54364,\"start\":54356},{\"end\":54696,\"start\":54692},{\"end\":54705,\"start\":54700},{\"end\":54711,\"start\":54707},{\"end\":54911,\"start\":54907},{\"end\":54924,\"start\":54920},{\"end\":54939,\"start\":54934},{\"end\":55170,\"start\":55166},{\"end\":55192,\"start\":55180},{\"end\":55199,\"start\":55194},{\"end\":55401,\"start\":55392},{\"end\":55409,\"start\":55407},{\"end\":55421,\"start\":55416},{\"end\":55441,\"start\":55435},{\"end\":55452,\"start\":55447},{\"end\":55458,\"start\":55454},{\"end\":55669,\"start\":55667},{\"end\":55689,\"start\":55683},{\"end\":55704,\"start\":55699},{\"end\":55718,\"start\":55713},{\"end\":55903,\"start\":55901},{\"end\":55918,\"start\":55910},{\"end\":55932,\"start\":55928},{\"end\":55940,\"start\":55936},{\"end\":55953,\"start\":55951},{\"end\":55971,\"start\":55964},{\"end\":55987,\"start\":55979},{\"end\":56000,\"start\":55994},{\"end\":56009,\"start\":56006},{\"end\":56014,\"start\":56011},{\"end\":56597,\"start\":56595},{\"end\":56606,\"start\":56603},{\"end\":56618,\"start\":56615},{\"end\":56909,\"start\":56907},{\"end\":56918,\"start\":56915},{\"end\":56931,\"start\":56927},{\"end\":56940,\"start\":56937},{\"end\":57166,\"start\":57159},{\"end\":57174,\"start\":57168},{\"end\":57395,\"start\":57390},{\"end\":57410,\"start\":57403},{\"end\":57423,\"start\":57421}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":1378406},\"end\":44375,\"start\":44044},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11212020},\"end\":44639,\"start\":44377},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":8377315},\"end\":44968,\"start\":44641},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3177797},\"end\":45165,\"start\":44970},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":7847519},\"end\":45489,\"start\":45167},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":5590763},\"end\":45958,\"start\":45491},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":506350},\"end\":46215,\"start\":45960},{\"attributes\":{\"id\":\"b7\"},\"end\":46405,\"start\":46217},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1033682},\"end\":46750,\"start\":46407},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":2023519},\"end\":47032,\"start\":46752},{\"attributes\":{\"id\":\"b10\"},\"end\":47284,\"start\":47034},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":1915014},\"end\":47480,\"start\":47286},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":29758373},\"end\":47867,\"start\":47482},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":207168823},\"end\":48102,\"start\":47869},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":58370896},\"end\":48373,\"start\":48104},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":195908774},\"end\":48646,\"start\":48375},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":2407601},\"end\":48848,\"start\":48648},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":2095855},\"end\":49049,\"start\":48850},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":29562039},\"end\":49368,\"start\":49051},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":964287},\"end\":49555,\"start\":49370},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":207216684},\"end\":49784,\"start\":49557},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":381243},\"end\":49971,\"start\":49786},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":6440341},\"end\":50249,\"start\":49973},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":16447573},\"end\":50576,\"start\":50251},{\"attributes\":{\"id\":\"b24\"},\"end\":50707,\"start\":50578},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":7605591},\"end\":51037,\"start\":50709},{\"attributes\":{\"id\":\"b26\"},\"end\":51252,\"start\":51039},{\"attributes\":{\"id\":\"b27\"},\"end\":51511,\"start\":51254},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":205001834},\"end\":51799,\"start\":51513},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1918428},\"end\":52049,\"start\":51801},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":467086},\"end\":52222,\"start\":52051},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7285098},\"end\":52489,\"start\":52224},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":8047550},\"end\":52774,\"start\":52491},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":16274986},\"end\":53049,\"start\":52776},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":5472586},\"end\":53330,\"start\":53051},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":8429835},\"end\":53628,\"start\":53332},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":1805048},\"end\":53895,\"start\":53630},{\"attributes\":{\"doi\":\"abs/1605.02688\",\"id\":\"b37\"},\"end\":54158,\"start\":53897},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":17804904},\"end\":54617,\"start\":54160},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":96163},\"end\":54848,\"start\":54619},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":4833213},\"end\":55075,\"start\":54850},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":945659},\"end\":55358,\"start\":55077},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":5362246},\"end\":55592,\"start\":55360},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":6392154},\"end\":55891,\"start\":55594},{\"attributes\":{\"doi\":\"arXiv:1609.08144\",\"id\":\"b44\"},\"end\":56475,\"start\":55893},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":17792584},\"end\":56806,\"start\":56477},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":11832773},\"end\":57111,\"start\":56808},{\"attributes\":{\"doi\":\"arXiv:1212.5701\",\"id\":\"b47\"},\"end\":57311,\"start\":57113},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":5180076},\"end\":57580,\"start\":57313}]", "bib_title": "[{\"end\":44121,\"start\":44044},{\"end\":44446,\"start\":44377},{\"end\":44714,\"start\":44641},{\"end\":44997,\"start\":44970},{\"end\":45230,\"start\":45167},{\"end\":45584,\"start\":45491},{\"end\":46033,\"start\":45960},{\"end\":46434,\"start\":46407},{\"end\":46819,\"start\":46752},{\"end\":47308,\"start\":47286},{\"end\":47568,\"start\":47482},{\"end\":47951,\"start\":47869},{\"end\":48159,\"start\":48104},{\"end\":48438,\"start\":48375},{\"end\":48702,\"start\":48648},{\"end\":48898,\"start\":48850},{\"end\":49133,\"start\":49051},{\"end\":49424,\"start\":49370},{\"end\":49611,\"start\":49557},{\"end\":49843,\"start\":49786},{\"end\":50055,\"start\":49973},{\"end\":50326,\"start\":50251},{\"end\":50783,\"start\":50709},{\"end\":51564,\"start\":51513},{\"end\":51864,\"start\":51801},{\"end\":52085,\"start\":52051},{\"end\":52281,\"start\":52224},{\"end\":52551,\"start\":52491},{\"end\":52826,\"start\":52776},{\"end\":53131,\"start\":53051},{\"end\":53399,\"start\":53332},{\"end\":53676,\"start\":53630},{\"end\":54274,\"start\":54160},{\"end\":54684,\"start\":54619},{\"end\":54901,\"start\":54850},{\"end\":55160,\"start\":55077},{\"end\":55390,\"start\":55360},{\"end\":55661,\"start\":55594},{\"end\":56585,\"start\":56477},{\"end\":56897,\"start\":56808},{\"end\":57384,\"start\":57313}]", "bib_author": "[{\"end\":44140,\"start\":44123},{\"end\":44154,\"start\":44140},{\"end\":44169,\"start\":44154},{\"end\":44186,\"start\":44169},{\"end\":44466,\"start\":44448},{\"end\":44481,\"start\":44466},{\"end\":44496,\"start\":44481},{\"end\":44729,\"start\":44716},{\"end\":44738,\"start\":44729},{\"end\":44747,\"start\":44738},{\"end\":44756,\"start\":44747},{\"end\":44768,\"start\":44756},{\"end\":44788,\"start\":44768},{\"end\":45008,\"start\":44999},{\"end\":45014,\"start\":45008},{\"end\":45024,\"start\":45014},{\"end\":45045,\"start\":45024},{\"end\":45241,\"start\":45232},{\"end\":45257,\"start\":45241},{\"end\":45268,\"start\":45257},{\"end\":45601,\"start\":45586},{\"end\":45639,\"start\":45601},{\"end\":45657,\"start\":45639},{\"end\":46048,\"start\":46035},{\"end\":46066,\"start\":46048},{\"end\":46248,\"start\":46232},{\"end\":46263,\"start\":46248},{\"end\":46280,\"start\":46263},{\"end\":46452,\"start\":46436},{\"end\":46472,\"start\":46452},{\"end\":46485,\"start\":46472},{\"end\":46494,\"start\":46485},{\"end\":46514,\"start\":46494},{\"end\":46529,\"start\":46514},{\"end\":46546,\"start\":46529},{\"end\":46561,\"start\":46546},{\"end\":46834,\"start\":46821},{\"end\":46844,\"start\":46834},{\"end\":46857,\"start\":46844},{\"end\":46868,\"start\":46857},{\"end\":47049,\"start\":47036},{\"end\":47060,\"start\":47049},{\"end\":47075,\"start\":47060},{\"end\":47088,\"start\":47075},{\"end\":47096,\"start\":47088},{\"end\":47111,\"start\":47096},{\"end\":47327,\"start\":47310},{\"end\":47347,\"start\":47327},{\"end\":47585,\"start\":47570},{\"end\":47967,\"start\":47953},{\"end\":48175,\"start\":48161},{\"end\":48188,\"start\":48175},{\"end\":48457,\"start\":48440},{\"end\":48473,\"start\":48457},{\"end\":48492,\"start\":48473},{\"end\":48712,\"start\":48704},{\"end\":48722,\"start\":48712},{\"end\":48731,\"start\":48722},{\"end\":48910,\"start\":48900},{\"end\":48917,\"start\":48910},{\"end\":48934,\"start\":48917},{\"end\":49144,\"start\":49135},{\"end\":49156,\"start\":49144},{\"end\":49165,\"start\":49156},{\"end\":49179,\"start\":49165},{\"end\":49192,\"start\":49179},{\"end\":49440,\"start\":49426},{\"end\":49625,\"start\":49613},{\"end\":49646,\"start\":49625},{\"end\":49652,\"start\":49646},{\"end\":49864,\"start\":49845},{\"end\":50073,\"start\":50057},{\"end\":50088,\"start\":50073},{\"end\":50343,\"start\":50328},{\"end\":50359,\"start\":50343},{\"end\":50369,\"start\":50359},{\"end\":50385,\"start\":50369},{\"end\":50396,\"start\":50385},{\"end\":50589,\"start\":50578},{\"end\":50809,\"start\":50785},{\"end\":50821,\"start\":50809},{\"end\":50836,\"start\":50821},{\"end\":50850,\"start\":50836},{\"end\":50860,\"start\":50850},{\"end\":51102,\"start\":51085},{\"end\":51115,\"start\":51102},{\"end\":51131,\"start\":51115},{\"end\":51349,\"start\":51331},{\"end\":51596,\"start\":51566},{\"end\":51613,\"start\":51596},{\"end\":51623,\"start\":51613},{\"end\":51890,\"start\":51866},{\"end\":51904,\"start\":51890},{\"end\":51912,\"start\":51904},{\"end\":52109,\"start\":52087},{\"end\":52122,\"start\":52109},{\"end\":52305,\"start\":52283},{\"end\":52318,\"start\":52305},{\"end\":52335,\"start\":52318},{\"end\":52568,\"start\":52553},{\"end\":52584,\"start\":52568},{\"end\":52600,\"start\":52584},{\"end\":52612,\"start\":52600},{\"end\":52844,\"start\":52828},{\"end\":52866,\"start\":52844},{\"end\":52880,\"start\":52866},{\"end\":52892,\"start\":52880},{\"end\":53142,\"start\":53133},{\"end\":53157,\"start\":53142},{\"end\":53172,\"start\":53157},{\"end\":53417,\"start\":53401},{\"end\":53429,\"start\":53417},{\"end\":53444,\"start\":53429},{\"end\":53460,\"start\":53444},{\"end\":53464,\"start\":53460},{\"end\":53691,\"start\":53678},{\"end\":53700,\"start\":53691},{\"end\":53714,\"start\":53700},{\"end\":54292,\"start\":54276},{\"end\":54309,\"start\":54292},{\"end\":54326,\"start\":54309},{\"end\":54341,\"start\":54326},{\"end\":54366,\"start\":54341},{\"end\":54698,\"start\":54686},{\"end\":54707,\"start\":54698},{\"end\":54713,\"start\":54707},{\"end\":54913,\"start\":54903},{\"end\":54926,\"start\":54913},{\"end\":54941,\"start\":54926},{\"end\":55172,\"start\":55162},{\"end\":55194,\"start\":55172},{\"end\":55201,\"start\":55194},{\"end\":55403,\"start\":55392},{\"end\":55411,\"start\":55403},{\"end\":55423,\"start\":55411},{\"end\":55443,\"start\":55423},{\"end\":55454,\"start\":55443},{\"end\":55460,\"start\":55454},{\"end\":55671,\"start\":55663},{\"end\":55691,\"start\":55671},{\"end\":55706,\"start\":55691},{\"end\":55720,\"start\":55706},{\"end\":55905,\"start\":55893},{\"end\":55920,\"start\":55905},{\"end\":55934,\"start\":55920},{\"end\":55942,\"start\":55934},{\"end\":55955,\"start\":55942},{\"end\":55973,\"start\":55955},{\"end\":55989,\"start\":55973},{\"end\":56002,\"start\":55989},{\"end\":56011,\"start\":56002},{\"end\":56016,\"start\":56011},{\"end\":56599,\"start\":56587},{\"end\":56608,\"start\":56599},{\"end\":56620,\"start\":56608},{\"end\":56911,\"start\":56899},{\"end\":56920,\"start\":56911},{\"end\":56933,\"start\":56920},{\"end\":56942,\"start\":56933},{\"end\":57168,\"start\":57157},{\"end\":57176,\"start\":57168},{\"end\":57397,\"start\":57386},{\"end\":57412,\"start\":57397},{\"end\":57425,\"start\":57412}]", "bib_venue": "[{\"end\":44197,\"start\":44186},{\"end\":44500,\"start\":44496},{\"end\":44791,\"start\":44788},{\"end\":45049,\"start\":45045},{\"end\":45310,\"start\":45268},{\"end\":45662,\"start\":45657},{\"end\":46070,\"start\":46066},{\"end\":46230,\"start\":46217},{\"end\":46565,\"start\":46561},{\"end\":46877,\"start\":46868},{\"end\":47149,\"start\":47111},{\"end\":47365,\"start\":47347},{\"end\":47654,\"start\":47585},{\"end\":47975,\"start\":47967},{\"end\":48196,\"start\":48188},{\"end\":48496,\"start\":48492},{\"end\":48735,\"start\":48731},{\"end\":48938,\"start\":48934},{\"end\":49196,\"start\":49192},{\"end\":49452,\"start\":49440},{\"end\":49658,\"start\":49652},{\"end\":49868,\"start\":49864},{\"end\":50099,\"start\":50088},{\"end\":50400,\"start\":50396},{\"end\":50629,\"start\":50589},{\"end\":50864,\"start\":50860},{\"end\":51083,\"start\":51039},{\"end\":51329,\"start\":51254},{\"end\":51641,\"start\":51623},{\"end\":51917,\"start\":51912},{\"end\":52126,\"start\":52122},{\"end\":52344,\"start\":52335},{\"end\":52620,\"start\":52612},{\"end\":52900,\"start\":52892},{\"end\":53178,\"start\":53172},{\"end\":53468,\"start\":53464},{\"end\":53749,\"start\":53714},{\"end\":53972,\"start\":53897},{\"end\":54370,\"start\":54366},{\"end\":54721,\"start\":54713},{\"end\":54949,\"start\":54941},{\"end\":55205,\"start\":55201},{\"end\":55464,\"start\":55460},{\"end\":55729,\"start\":55720},{\"end\":56164,\"start\":56032},{\"end\":56629,\"start\":56620},{\"end\":56947,\"start\":56942},{\"end\":57155,\"start\":57113},{\"end\":57434,\"start\":57425}]"}}}, "year": 2023, "month": 12, "day": 17}