{"id": 221739066, "updated": "2023-10-06 11:03:56.829", "metadata": {"title": "TadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks", "authors": "[{\"first\":\"Alexander\",\"last\":\"Geiger\",\"middle\":[]},{\"first\":\"Dongyu\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Sarah\",\"last\":\"Alnegheimish\",\"middle\":[]},{\"first\":\"Alfredo\",\"last\":\"Cuesta-Infante\",\"middle\":[]},{\"first\":\"Kalyan\",\"last\":\"Veeramachaneni\",\"middle\":[]}]", "venue": "2020 IEEE International Conference on Big Data (Big Data)", "journal": "2020 IEEE International Conference on Big Data (Big Data)", "publication_date": {"year": 2020, "month": 9, "day": 16}, "abstract": "Time series anomalies can offer information relevant to critical situations facing various fields, from finance and aerospace to the IT, security, and medical domains. However, detecting anomalies in time series data is particularly challenging due to the vague definition of anomalies and said data's frequent lack of labels and highly complex temporal correlations. Current state-of-the-art unsupervised machine learning methods for anomaly detection suffer from scalability and portability issues, and may have high false positive rates. In this paper, we propose TadGAN, an unsupervised anomaly detection approach built on Generative Adversarial Networks (GANs). To capture the temporal correlations of time series distributions, we use LSTM Recurrent Neural Networks as base models for Generators and Critics. TadGAN is trained with cycle consistency loss to allow for effective time-series data reconstruction. We further propose several novel methods to compute reconstruction errors, as well as different approaches to combine reconstruction errors and Critic outputs to compute anomaly scores. To demonstrate the performance and generalizability of our approach, we test several anomaly scoring techniques and report the best-suited one. We compare our approach to 8 baseline anomaly detection methods on 11 datasets from multiple reputable sources such as NASA, Yahoo, Numenta, Amazon, and Twitter. The results show that our approach can effectively detect anomalies and outperform baseline methods in most cases (6 out of 11). Notably, our method has the highest averaged F1 score across all the datasets. Our code is open source and is available as a benchmarking tool.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2009.07769", "mag": "3087090211", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/bigdataconf/GeigerLACV20", "doi": "10.1109/bigdata50022.2020.9378139"}}, "content": {"source": {"pdf_hash": "0c9913dcf8287eadd2879b73c027b34d2f38458f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2009.07769v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2009.07769", "status": "GREEN"}}, "grobid": {"id": "dcc4b1f70e2ab0c41c39bbf2f4d8bcebddc36d4d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/0c9913dcf8287eadd2879b73c027b34d2f38458f.txt", "contents": "\nTadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks\n19 Sep 2020\n\nAlexander Geiger \nDongyu Liu \nSarah Alnegheimish \nAlfredo Cuesta-Infante \nKalyan Veeramachaneni \nTadGAN: Time Series Anomaly Detection Using Generative Adversarial Networks\n19 Sep 2020* Equal contribution 1 MIT, Cambridge, USA 2 Universidad Rey Juan Carlos, Madrid, Spain. Correspondence to: Kalyan Veera-machaneni <kalyanv@mit.edu>. This is a working draft/preprint. A previous version of this draft accidentally put ICML footnote here, which we promptly re-moved. But due to arxiv's versioning, readers may still gain ac-cess to it. available as a benchmarking tool.\nTime series anomalies can offer information relevant to critical situations facing various fields, from finance and aerospace to the IT, security, and medical domains. However, detecting anomalies in time series data is particularly challenging due to the vague definition of anomalies and said data's frequent lack of labels and highly complex temporal correlations. Current state-ofthe-art unsupervised machine learning methods for anomaly detection suffer from scalability and portability issues, and may have high false positive rates. In this paper, we propose TadGAN, an unsupervised anomaly detection approach built on Generative Adversarial Networks (GANs). To capture the temporal correlations of time series distributions, we use LSTM Recurrent Neural Networks as base models for Generators and Critics. TadGAN is trained with cycle consistency loss to allow for effective time-series data reconstruction. We further propose several novel methods to compute reconstruction errors, as well as different approaches to combine reconstruction errors and Critic outputs to compute anomaly scores. To demonstrate the performance and generalizability of our approach, we test several anomaly scoring techniques and report the best-suited one. We compare our approach to 8 baseline anomaly detection methods on 11 datasets from multiple reputable sources such as NASA, Yahoo, Numenta, Amazon, and Twitter. The results show that our approach can effectively detect anomalies and outperform baseline methods in most cases (6 out of 11). Notably, our method has the highest averaged F1 score across all the datasets. Our code is open source and is\n\nIntroduction\n\nThe recent proliferation of temporal observation data has led to an increasing demand for time series anomaly detection in many domains, from energy and finance to healthcare and cloud computing. A time series anomaly is defined as a time point or period where a system behaves unusually [8]. Broadly speaking, there are two types of anomalies: A point anomaly is a single data point that has reached an unusual value, while a collective anomaly is a continuous sequence of data points that are considered anomalous as a whole, even if the individual data points may not be unusual [8].\n\nTime series anomaly detection aims to isolate anomalous subsequences of varied lengths within time series. One of the simplest detection techniques is thresholding, which detects data points that exceed a normal range [8]. However, many anomalies do not exceed any boundaries -for example, they may have values that are purportedly \"normal,\" but are unusual at the specific time that they occur (i.e., contextual anomalies). These anomalies are harder to identify because the context of a signal is often unclear [1,8].\n\nVarious statistical methods have been proposed to improve upon thresholding, such as Statistical Process Control (SPC) [39], in which data points are identified as anomalies if they fail to pass statistical hypothesis testing. But these methods are unable to handle multivariate data streams, and statistical features are often unknown and various.\n\nResearchers have also studied a number of unsupervised machine learning-based approaches to anomaly detection. One popular method consists of segmenting a time series into subsequences (overlapping or otherwise) of a certain length and applying clustering algorithms to find outliers. Another learns a model that either predicts or reconstructs a time series signal, and makes comparison between the real and the predicted or reconstructed values. High prediction or reconstruction errors suggest the presence of anomalies.\n\n\nOutperforms\n\nDeep learning based method ARIMA, 1970 [6] LSTM AutoEncoder, 2016 [27] 5 LSTM, 2018 [21] 5 MAD-GAN, 2019 [24] 0 MS Azure, 2019 [30] 0 DeepAR, 2019 [32] 6 TadGAN 8 Table 1. The number of wins of a particular method compared with ARIMA, the traditional time series forecasting model, against an appropriate metric (f1 score) on 11 real datasets.\n\nDeep learning methods [22] are extremely capable of handling non-linearity in complex temporal correlations, and have excellent learning ability. For this reason, they have been used in a number of time series anomaly detection methods [26,21,14], including tools created by companies such as Microsoft [30]. Generative Adversarial Networks (GANs) [16] have also been shown to be very successful at generating time series sequences and outperforming state-of-the-art benchmarks [37]. Such a proliferation of methods invites the question: Do these new, complex approaches actually perform better than a simple baseline statistical method? To evaluate the new methods, we used 11 datasets (real and synthetic) that collectively have 492 signals and thousands of known anomalies to set-up a benchmarking system (see the details in Section 5 and Table 3). We implemented 5 of the most recent deep learning techniques introduced between 2016 and 2019, and compared their performances with that of a baseline method from the 1970s, ARIMA. While some methods were able to beat ARIMA on 50% of the datasets, two methods failed to outperform it at all (c.f. Table 1).\n\nOne of the foundational challenges with deep learningbased approaches is its remarkable ability to fit the data. As a result, it could fit the anomalous data as well. For example, autoencoders, using L2 objective function, could fit and reconstruct the data extremely accurately -thus fitting the anomalies as well. On the other hand, GANs, may be ineffective in learning the generator to fully capture the data hidden distribution, thus causing false alarms. Hence, we find the necessity to create a more nuanced approach by mixing the two methods. Additionally, frequently in these works, much of the emphasis is on the deep learning model itself. However, as we show in this paper, the post-processing steps could aid significantly in reducing the number of false positives.\n\nIn this work, we introduce a novel GAN architecture, TadGAN, for time series domain. We use TadGAN to reconstruct time series and assess errors in a contextual man-ner to identify anomalies. We explore different ways to compute anomaly scores based on the outputs from Generators and Critics. We benchmark our method against several well-known classical and deep learning based methods on eleven time-series datasets. The detailed results can be found in Table 3.\n\nThe key contributions of this paper are as follows:\n\n\u2022 We propose a novel unsupervised GANreconstruction-based anomaly detection method for time series data. In particular, we introduce a cycle-consistent GAN architecture for time-series to time-series mapping. \u2022 We identify two time series similarity measures suitable for evaluating the contextual similarity between original and GAN-reconstructed sequences. Our novel approach leverages both GAN's Generator and Critic to compute robust anomaly scores at every time step. \u2022 We conduct an extensive evaluation using 11 timeseries datasets from 3 reputable entities (NASA, Yahoo, and Numenta), demonstrating that our approach outperforms other 8 baselines. We further provide several insights into anomaly detection for time series data using GANs. \u2022 We develop a benchmarking system for time series anomaly detection.\n\nThe system is open-sourced and can be extended with additional approaches and datasets 1 .\n\nThe rest of this paper is structured as follows. Section 2 presents an overview of the related literature. Section 3 introduces the details of our GAN model. Afterwards, we describe how to use GANs for anomaly detection in Section 4, followed by the evaluation of our proposed framework in Section 5. Finally, Section 6 summarizes the paper and reports our key findings.\n\n\nRelated Work\n\n\nAnomaly Detection for Time Series Data.\n\nThe rich variety of anomaly types, data types and application scenarios has spurred a range of detection approaches over the past several years [20,8,15,18]. The simplest of which are out-of-limit methods, which flag regions where values exceed a certain threshold [28,10]. While these methods are intuitive, they are inflexible and incapable of detecting contextual anomalies. To overcome this more advanced techniques, namely: proximity-based, predictionbased, and reconstruction-based, have been proposed.\n\nProximity-based methods first use a distance measure to quantify similarity between objects -single data points for point anomalies, or fixed length sequences of data points for collective anomalies. Objects that are distant from others are considered as anomalies. This detection type can be further divided into distance-based methods, such as K-Nearest Neighbor (KNN) [3] -which use a given radius to define neighbors of an object and use the number of neighbors to determine an anomaly score -and densitybased methods, such as Local Outlier Factor (LOF) [7] and Clustering-Based Local Outlier Factor [19], which further consider the density of an object and that of its neighbors. There are two major drawbacks to applying proximitybased methods in time series data: (1) a priori knowledge about anomaly duration and the number of anomalies is required; (2) these methods are unable to capture temporal correlations.\n\nPrediction-based methods learn a predictive model to fit the given time series data, and then use that model to predict future values. A data point is identified as an anomaly if the difference between its predicted input and the original input exceeds a certain threshold. Statistical models, such as ARIMA [29], Holt-Winters [29], and FDA [35], can serve this purpose, but are sensitive to parameter selection and often require strong assumptions and extensive domain knowledge about the data. Machine learning based approaches attempt to overcome these limitations. [1] introduce Hierarchical Temporal Memory (HTM), an unsupervised online sequence memory algorithm, to detect anomalies in streaming data. HTM encodes the current input to a hidden state and predicts the next hidden state. A prediction error is measured by computing the difference between the current hidden state and the predicted hidden state. Hundman et al. [21] propose Long Short Term Recurrent Neural Networks (LSTM RNNs), to predict future time steps and flag large deviations from predictions.\n\nReconstruction-based methods learn a model to capture the latent structure (low-dimensional representations) of the given time series data and then create a synthetic reconstruction of the data. Reconstruction-based methods assume that anomalies lose information when they are mapped to a lower dimension space, thereby cannot be effectively reconstructed; thus, high reconstruction errors suggest high chances of being anomalies.\n\nPrincipal Component Analysis (PCA) [31], a dimensionality-reduction technique, can be used to reconstruct data, but it is limited to linear reconstruction and requires data to be highly correlated and to follow a Gaussian distribution [9]. More recently deep learning based techniques have been investigated. These include the use of Auto-Encoder (AE) [2], Variational Auto-Encoder (VAE) [2] and LSTM Encoder-Decoder [27].\n\nHowever, without proper regularization, these reconstruction-based methods may easily get overfitted, resulting in low performance. In this work, we propose to use adversarial learning to allow for time series reconstruction. We introduce an intuitive approach for regularizing reconstruction errors. The trained Generators can be directly used to reconstruct more concise time series data -thereby providing more accurate reconstruction errors -while the Critics can offer scores as a powerful complement to the reconstruction errors when computing an anomaly score.\n\n\nAnomaly Detection Using GANs.\n\nGenerative adversarial networks can successfully perform many image-related tasks, including image generation [16], image translation [41], and video prediction [36], and researchers have recently demonstrated the effectiveness of GANs for anomaly detection in images [34,11].\n\nAdversarial learning for images. Schlegl et al. [33] use the Critic network in a GAN to detect anomalies in medical images. They also attempt to use the reconstruction loss as an additional anomaly detection method, and find the inverse mapping from the data space to the latent space. This mapping is done in a separate step, after the GAN is trained. However, Zenati et al. [38] indicate that this method has proven impractical for large data sets or real-time applications. They propose a bi-directional GAN for anomaly detection in tabular and image data sets, which allows for simultaneous training of the inverse mapping through an encoding network.\n\nThe idea of training both encoder and decoder networks was developed by Donahue et al. [12] and Dumoulin et al. [13], who show how to achieve bidirectional GANs by trying to match joint distributions. In an optimal situation, the joint distributions are the same, and the Encoder and Decoder must be inverses of each other. A cycle-consistent GAN was introduced by Zhu et al. [41], who have two networks try to map into opposite dimensions, such that samples can be mapped from one space to the other and vice versa.\n\nAdversarial learning for time series. Prior GAN-related work has rarely involved time series data, because the complex temporal correlations within this type of data pose significant challenges to generative modeling. Three works published in 2019 are of note. First, to use GANs for anomaly detection in time series, Li et al. [24] propose using a vanilla GAN model to capture the distribution of a multivariate time series, and use the Critic to detect anomalies. Another approach in this line is BeatGAN [40], which is a Encoder and Decoder GAN architecture that allows for the use of the reconstruction error for anomaly detection in heartbeat signals. More recently, Yoon et al. [37] propose a time series GAN which adopts the same idea but introduces temporal embeddings to assist network training. However, their work is designed for time series representation learning instead of anomaly detection.\n\nTo the best of our knowledge, we are the first introducing cycle-consistent GAN architectures for time series data, such that Generators can be directly used for time series reconstructions. Besides, we systematically investigate how to utilize Critic and Generator outputs for anomaly score computation. A complete framework of time series anomaly detection is introduced to work with GANs.\n\n\nAdversarial Learning for time series reconstruction\n\nThe core idea of reconstruction-based anomaly detection method is to learn a model that can encode a data point (a segment of time series in our case) and then decode the encoded one (i.e., reconstructed one). An effective model should not be able to reconstruct anomalies as well as \"normal\" instances, because anomalies will lose information during encoding. In our model, we learn two mapping functions between two domains X and Z, namely E : X \u2192 Z and G : Z \u2192 X (Fig. 1). Where, X denotes the input data domain, describing the given training\nsamples {(x 1...t i )} N i=1 , x 1...t i \u2208 X.\nZ represents a standard multivariate normal distribution, i.e., z \u223c P Z = N (0, I).\n\nFor convenience of notation we use x i to denote a time sequence of length t starting at time step i. With the mapping functions, we can reconstruct the input time series:\nx i \u2192 E(x i ) \u2192 G(E(x i )) \u2248x i .\nWe propose to leverage adversarial learning approaches to obtain the two mapping functions E and G. As illustrated in Fig. 1, we view the two mapping functions as Generators. Note that E is serving as an Encoder which maps the time series sequences into the latent space, while G is serving as a Decoder that transforms the latent space into the reconstructed time series. We further introduce two adversarial Critics (aka discriminators) C x and C z . The goal of C x is to distinguish between real time series sequences from X and the generated time series sequences from G(z), whereas C z measures the goodness of the mapping into the latent space. In other words, G is trying to fool C x by generating real-looking sequences Thus, our high-level objective consists of two types of terms: (1) Wasserstein losses [4] to match the distribution of generated time series sequences to the data distribution in the target domain; and (2) cycle consistency losses [41] to prevent the contradiction between E and G.\n\n\nWasserstein Loss\n\nThe original formulation of GAN that applies the standard adversarial losses (Eq. 1) suffers from the mode collapse problem.\nL = E x\u223cPX [log C x (x)] + E z\u223cPZ [log(1 \u2212 C x (G(z)))] (1)\nwhere C x produces a probability score from 0 to 1 indicating the realness of the input time series sequence. To be specific, the Generator tends to learn a small fraction of the variability of the data, leading to that the Generator cannot perfectly converge to the target distribution. The key reason behind is that the Generator prefers to produce those samples that have already been found to be good for fooling the Critic and is reluctant to produce new ones. However, these new ones might be helpful to capture other \"modes\" in the data.\n\nTo overcome this limitation, we apply Wasserstein loss [4] as the adversarial loss to train the GAN. We make use of the Wasserstein-1 distance when training the Critic network. Formally, let P X be the distribution over X. For the mapping function G : Z \u2192 X and its Critic C x , we have the following objective:\nmin G max Cx\u2208Cx V X (C x , G) (2) with V X (C x , G) = E x\u223cPX [C x (x)] \u2212 E z\u223cPZ [C x (G(z)))] (3)\nwhere C x \u2208 C x which denotes the set of 1-Lipschitz continous functions. K-Lipschitz continous functions are defined as follows:\nf (x 1 ) \u2212 f (x 2 ) \u2264 K x 1 \u2212 x 2 , \u2200x 1 , x 2 \u2208 dom f .\nThe Lipschitz continous functions constrain the upper bound of the function, further smoothing the function. Therefore, the weights will not change dramatically when updated with gradient descent methods. This reduces the risk of gradient explosion and make the model training more stable and reliable. In addition, to enforce the 1-Lipschitz constraint during training, we apply a gradient penalty regularization term as introduced by Gulrajani et al. [17], which penalizes gradients not equal to 1 (cf. line 5).\n\nFollowing the similar approach, we introduce a Wasserstein loss for the mapping function E : X \u2192 Z and its Critic C z . The objective is expressed as:\nmin E max Cz\u2208Cz V Z (C z , E)(4)\nThe purpose of the second Critic C z is to distinguish between random latent samples z \u223c P Z and encoded samples E(x) with x \u223c P X . We present the model type and architecture for E, G, C x , C z in section 5.2.\n\n\nCycle Consistency Loss\n\nThe purpose of our GAN is to reconstruct the input time series:\nx i \u2192 E(x i ) \u2192 G(E(x i )) \u2248x i .\nHowever, training the GAN with the adversarial losses (i.e., Wasserstein Figure 1. Model architecture losses) alone cannot guarantee mapping individual input x i to a desired output z i which will be further mapped back t\u00f4 x i . To reduce the possible mapping function search space, we adapt cycle consistency loss to time series reconstruction. It was first introduced by Zhu et al. [41] for image translation tasks. We train the generative network E and G with the adapted cycle consistency loss by minimizing the L2 norm of the difference between the original and the reconstructed samples:\nC x x \u223c P X L2 G(E(x)) G(z) E G E(x) z \u223c P Z C zV L2 (E, G) = E x\u223cPX [ x \u2212 G(E(x)) 2 ](5)\nConsidering that our target is anomaly detection, we use L2 norm instead of L1 norm (the one used by Zhu et al. [41] for image translation) to emphasize the impacts of anomalous values. In our preliminary experiments, we observed that adding the backward consistency loss (i.e., E z\u223cPz [ z \u2212 E(G(z)) 2 ]) did not show an improved performance.\n\n\nFull Objective\n\nCombining all of the objectives given in (3), (4) and (5) leads to the final MinMax problem:\nmin {E,G} max {Cx\u2208Cx,Cz\u2208Cz} V X (C x , G) + V Z (C z , E) + V L2 (E, G)(6)\nThe full architecture of our model can be seen in Figure  1. The benefits of this architecture with respect to anomaly detection are twofold. First, we have a Critic C x that is trained to distinguish between real and fake time series sequences, hence the score of the Critic can directly serve as an anomaly measure. Second, the two Generators trained with cycle consistency loss allow us to encode and decode a time series sequence. The difference between the original sequence and the decoded sequence can be used as a second anomaly detection measure. For the detailed training steps, please refer to the pseudo code (cf. line [1][2][3][4][5][6][7][8][9][10][11][12][13][14]. The following section will introduce the details of how to use TadGAN for anomaly detection. \nSample {(x 1...t i )} m i=1 from real data. Sample {(z 1...k i )} m i=1 from random. g wC x = \u2207 wC x [ 1 m m i=1 C x (x i ) \u2212 1 m m i=1 C x (G(z i )) + gp(x i , G(z i ))] w Cx = w Cx + \u03b7 \u00b7 adam(w Cx , g wC x ) g wC z = \u2207 wC z [ 1 m m i=1 C z (z i ) \u2212 1 m m i=1 C z (E(x i )) + gp(z i , E(x i ))] w Cz = w Cz + \u03b7 \u00b7 adam(w Cz , g wC z ) end for Sample {(x 1...t i )} m i=1 from real data. Sample {(z 1...k i )} m i=1 from random. g wG,E = \u2207 wG ,wE [ 1 m m i=1 C x (x i ) \u2212 1 m m i=1 C x (G(z i )) + 1 m m i=1 C z (z i ) \u2212 1 m m i=1 C z (E(x i )) + 1 m m i=1 x i \u2212 G(E(x i )) 2 ] w G,E , = w G,E + \u03b7 \u00b7 adam(w G,E , g wG,E ) end for X = {(x 1...t i )} n i=1 for i = 1, . . . , n d\u00f4 x i = G(E(x i )) RE(x i ) = f (x i ,x i ) score = \u03b1Z RE (x i ) + (1 \u2212 \u03b1)Z Cx (x i ) end for\n\nTime-series GAN for anomaly detection (TadGAN)\n\nLet us assume that the given time series is (x 1 , x 2 , \u00b7 \u00b7 \u00b7 , x T ), where x i \u2286 R M\u00d71 indicates M types of measurements at time step i. For simplicity, we use M = 1 in the later description. Therefore, x i is viewed as a scalar afterwards. The same steps can be applied for multivariate time series (i.e., when M > 1).\n\nTo obtain the training samples, we introduce a sliding window with window size t and step size s to divide the original time series into N sub-sequences\nX = {(x 1...t i )} N i=1 , where N = T \u2212t s .\nIn practice, it is difficult to know the ground truth, and anomalous data points are rare. Hence, we assume all the training sample points are normal. In addition, we generate Z = {(z 1...k i )} N i=1 from a random space following normal distribution, where k denotes the dimension of the latent space. Then, we feed X and Z to our GAN model and train it with the objective defined in (6). With the trained model, we are able to compute anomaly scores (or likelihoods) at every time step by leveraging the reconstruction error and Critic output (cf. line [15][16][17][18][19][20].\n\n\nEstimating Anomaly Scores using Reconstruction Errors\n\nNote that the time series (x 1 , x 2 , \u00b7 \u00b7 \u00b7 , x T ), is divided into a set of sub-sequences with a sliding window of window size t and step size s. Thus, any individual data point at time point j, x j would appear in. Given a sequence x i of length t, TadGAN generates a reconstructed sequence of the same length:\nx i \u2192 E(x i ) \u2192 G(E(x i )) \u2248x i .\nTherefore, for each time point j, we have a collection of reconstructed values {x q i , i + q = j} We take the median from the collection as the final reconstructed valuex j . Note that in the preliminary experiments, we found that using the median achieved a better performance than using the mean. Now the reconstructed time series is (x 1 ,x 2 , \u00b7 \u00b7 \u00b7 ,x T ). Here we propose three different types of functions (cf. line 18) for computing the reconstruction errors at each time step (assume the interval between neighbor time steps is the same).\n\nPoint-wise difference. This is the most intuitive way to define the reconstruction error, which computes the difference between the true value and the reconstructed value at every time step:\ns t = x t \u2212x t(7)\nArea difference. This is applied over windows of a certain length to measure the similarity between local regions. It is defined as the average difference between the areas beneath two curves of length l:\ns t = 1 2 * l t+l t\u2212l x t \u2212x t dx(8)\nAlthough this seems intuitive, it is not often used in this context -however, we will show in our experiments that this approach works well in many cases. Compared with point-wise difference, area difference is good at identifying the regions where small differences exist over a long period of time. Since we are only given fixed samples of the functions, we use the trapezoidal rule to calculate the definite integral in the implementation.\n\nDynamic time warping (DTW). It aims to calculate the optimal match between two given time sequences [5] and is used to measure the similarity between local regions. We have two time series X = (x t\u22121 , x t\u2212l+1 , . . . , x t+l ) and X = (x t\u22121 ,x t\u2212l+1 , . . . ,x t+l ) and let W \u2208 R 2 * l\u00d72 * l be a matrix such that the (i, j)-th element is a distance measure between x i andx j , denoted as w k . We want to find the warp path W * = (w 1 , w 2 , . . . , w K ) that defines the minimum distance between the two curves, subject to boundary conditions at the start and end, as well as constraints on continuity and monotonicity. The DTW distance between time series X andX is defined as follows:\ns t = W * = DTW(X,X) = min W \uf8ee \uf8f0 1 K K k=1 w k \uf8f9 \uf8fb (9)\nSimilar to area difference, DTW is able to identify the regions of small difference over a long period of time, but DTW can handle time shift issues as well.\n\n\nEstimating Anomaly Scores with Critic Outputs\n\nDuring the training process, the Critic C x has to distinguish between real input sequences and synthetic ones. Because we use the Wasserstein-1 distance when training C x , the outputs can be seen as an indicator of how real (larger value) or fake (smaller value) a sequence is. Therefore, once the Critic is trained, it can directly serve as an anomaly measure for time series sequences.\n\nSimilar to the reconstruction errors, at time step j, we have a collection of Critic scores (c q i , i + q = j). We apply kernel density estimation (KDE) on the collection and then take the maximum value as the smoothed value c j Now the Critic score sequence is (c 1 , c 2 , . . . , c T ). We show in our experiments that it is indeed the case that the Critic assigns different scores to anomalous regions compared to normal regions. This allows for the use of thresholding techniques to identify the anomalous regions.\n\n\nCombining Both Scores\n\nThe reconstruction errors RE(x) and Critic outputs C x (x) cannot be directly used together as anomaly scores. Intuitively, the larger RE(x) and the smaller C x (x) indicate higher anomaly scores. Therefore, we first compute the mean and standard deviation of RE(x) and C x (x), and then calculate their respective z-scores Z RE (x) and Z Cx (x) to normalize both. Larger z-scores indicate high anomaly scores.\n\nWe have explored different ways to leverage Z RE (x) and Z Cx (x). As shown in Table 4 (row 1-4), we first tested three types of Z RE (x) and Z Cx (x) individually. We then explored two different ways to combine them (row 5 to the last row). First, we attempt to merge them into a single value a(x) with a convex combination (cf. line 19) [24,33]:\na(x) = \u03b1Z RE (x) + (1 \u2212 \u03b1)Z Cx (x)(10)\nwhere \u03b1 controls the relative importance of the two terms (by default alpha = 0.5). Second, we try to multiply both scores to emphasize the high values:\na(x) = \u03b1Z RE (x) \u2299 Z Cx (x)(11)\nwhere \u03b1 = 1 by default. Both methods result in robust anomaly scores. The results are reported in Section 5.3.\n\n\nIdentifying Anomalous Sequences\n\nFinding anomalous sequences with locally adaptive thresholding: Once we obtain anomaly scores at every time step, thresholding techniques can be applied to identify anomalous sequences. We use sliding windows to compute thresholds, and empirically set the window size as T 3 and the step size as T 3 * 10 . This is helpful to identify contextual anomalies whose contextual information is usually unknown. The sliding window size determines the number of historical anomaly scores to evaluate the current threshold. For each sliding window, we use a simple static threshold defined as 4 standard deviations from the mean of the window. We can then identify those points whose anomaly score is larger than the threshold as anomalous. Thus, continuous time points compose into anomalous sequences (or windows): {a i seq , i = 1, 2, . . . , K}, where a i seq = (a start(i) , . . . , a end(i) ) . Mitigating false positives: The use of sliding windows can increase recall of anomalies but may also produce many false positives. We employ an anomaly pruning approach inspired by Hundman et al. [21] to mitigate false positives. At first, for each anomalous sequence, we use the maximum anomaly score to represent it, obtaining a set of maximum values {a i max , i = 1, 2, . . . , K}. Once these values are sorted in descending order, we can compute the decrease percent p i = (a i\u22121 max \u2212 a i max )/a i\u22121 max . When the first p i does not exceed a certain threshold \u03b8 (by default \u03b8 = 0.1), we reclassify all subsequent sequences (i.e., {a j seq , i \u2264 j \u2264 K}) as normal.\n\n\nExperimental Results\n\n\nDatasets\n\nTo measure the performance of TadGAN, we evaluate it on multiple time series datasets. In total, we have collected 11 datasets (a total of 492 signals) across a variety of application domains. We use spacecraft telemetry signals provided by NASA 2 , consisting of two datasets: Mars Science Laboratory (MSL) and Soil Moisture Active Passive (SMAP). In addition, we use Yahoo S5 which contains four different sub-datasets 3 The A1 dataset is based on real production traffic to Yahoo computing systems, while A2, A3 and A4 are all synthetic datasets. Lastly, we use Numenta Anomaly Benchmark (NAB). NAB [23] includes multiple types of time series data from various application domains 4 We have picked five datasets: Art, AdEx, AWS, Traf, and Tweets.\n\nDatasets from different sources contain different numbers of signals and anomalies, and the locations of anomalies are known for each signal. Basic information for each dataset is summarized in Table 2. For each dataset, we present the total number of signals and the amount of anomalies pertaining to them. We also observe whether the anomalies in the dataset are a single \"point\" anomalies or a collections. In order to suss out the ease of anomaly identification, we measure how out of the ordinary each anomaly point is by categorizing it as \"out-of-dist\" if it falls 4 standard deviations away from the mean of all the data for a signal. As each dataset has some quality that make detecting its anomalies more challenging, this diverse selection will help us identify the effectiveness and limitations of each baseline.\n\n\nExperimental setup\n\n\nDATA PREPARATION\n\nFor each dataset, we first normalize the data betweeen [\u22121, 1]. Then we find a proper interval over which to aggregate the data, so that we have several thousands of equally spaced points in time for each signal. We then set a window size t = 100 and step size s = 1 to obtain training samples for TadGAN. Because many signals in the Yahoo datasets contain linear trends, we apply a simple detrending function (which subracts the result of a linear least-squares fit to the signal) before training and testing.\n\n\nARCHITECTURE\n\nIn our experiments, inputs to TadGAN are time series sequences of length 100 (domain X) and the latent space (domain Z) is 20-dimensional. We use a 1-layer bidirectional Long Short-Term Memory (LSTM) with 100 hidden units as Generator E, and a 2-layer bidirectional LSTM with 64 hidden units each as Generator G, where dropout is applied. We add a 1-D convolutional layer for both Critics, with the intention of capturing local temporal features that can determine how anomalous a sequence is. The model is trained on a specific signal from one dataset for 2000 iterations, with a batch size of 64.\n\n\nEVALUATION METRICS\n\nWe measure the performance of different methods using the commonly used metrics Precision, Recall and F1-Score. In many real-world application scenarios, anomalies are rare and usually window-based (i.e. a continuous sequence of points-see Sec. 4.4). From the perspective of end-users, Property  SMAP  MSL  A1  A2  A3  A4  Art AdEx  AWS  Traf Tweets   # SIGNALS  53  27  67  100  100  100  6  5  17  7  10  # ANOMALIES  67  36  178  200  939  835  6  11  30  14  33  point (len = 1)  0  0  68  33  935  833  0  0  0  0  0   the best outcome is to receive timely true alarms without too many false positives (FPs), as these may waste time and resources. To penalize high FPs and reward the timely true alarms, we present the following window-based rules:\n\n\nNASA Yahoo S5 NAB\n\n(1) If a known anomalous window overlaps any predicted windows, a TP is recorded. (2) If a known anomalous window does not overlap any predicted windows, a FN is recorded.\n\n(3) If a predicted window does not overlap any labeled anomalous region, a FP is recorded. This method is also used in Hundman et al's work [21].\n\n\nBASELINES\n\nThe baseline methods can be divided into three categories: prediction-based methods, reconstruction-based methods, and online commercial tools.\n\nARIMA (Prediction-based). An autoregressive integrated moving average (ARIMA) model is a popular statistical analysis model that learns the autocorrelations in the time series for future value prediction. We use point-wise prediction errors as the anomaly scores to detect anomalies.\n\nHTM (Prediction-based). Hierarchial Temporal Memory (HTM) [1] has shown better performance over many statistical analysis models in the Numenta Anomaly Benchmark. It encodes the current input to a hidden state and predicts the next hidden state. Prediction errors are computed as the differences between the predicted state and the true state, which are then used as the anomaly scores for anomaly detection.\n\nLSTM (Prediction-based). The neural network used in our experiments consists of two LSTM layers with 80 units each, and a subsequent dense layer with one unit which predicts the value at the next time step (similar to the one used by Hundman et al. [21]). Point-wise prediction errors are used for anomaly detection.\n\nAutoEncoder (Reconstruction-based). Our approach can be viewed as a special instance of \"adversarial autoencoders\" [25], E \u2022 G : X \u2192 X. Thus, we compare our method with standard autoencoders with dense layers or LSTM layers [27]. The dense autoencoder consists of three Dense layers with 60, 20 and 60 units respectively. The LSTM autoencoder contains two LSTM layers each having 60 units. Again, a point-wise reconstruction error is used to detect anomalies.\n\n\nMAD-GAN (Reconstruction-based). This method [24]\n\nuses a vanilla GAN along with an optimal instance searching strategy in latent space to support multivariate time series reconstruction. We use MAD-GAN to compute the anomaly scores at every time step and then apply the same anomaly detection method introduced in Sec. 4.4 to find anomalies.\n\nMicrosoft Azure Anomaly Detector (Commercial tool).\n\n\nMicrosoft uses Spectral Residual Convolutional Neural\n\nNetworks (SR-CNN) in which the models are applied serially [30]. The SR model is responsible for saliency detection and the CNN is responsible for learning a discriminating threshold. The output of the model is a sequence of binary labels that is attributed to each timestamp.\n\nAmazon DeepAR (Commercial tool). DeepAR is a probabilistic forecasting model with autoregressive recurrent networks [32]. We use this model in a similar manner as LSTM in a sense that it's a prediction-based approach. Anomaly scores are presented as the regression errors which are computed as the distance between the median of the predicted value and true value.  Table 3. F1-Scores of baseline models using window-based rules. Color encodes the performance of the F1 score. One is evenly divided into 10 bins, with each bin associated with one color. From dark red to dark blue, F1 score increases from 0 to 1.\n\n\nBenchmarking Results\n\nTadGAN outperformed all the baseline methods by having the highest averaged F1 score (0.7) across all the datasets. Table 3 ranks all the methods based on their averaged F1 scores (the last column) across the eleven datasets. The second (LSTM, 0.623) and the third (Arima, 0.599) best are both prediction-based methods and TadGAN outperformed them by 12.46% and 16.86%, respectively, in respect with the averaged F1 score.\n\nSynthetic data v.s. real-world datasets. Although TadGAN outperforms all baselines on average, we can notice that it ranks below Arima when detecting anomalies within synthetic dataset with point anomalies. Specifically, TadGAN achieved an average of 0.717 while Arima scored an average of 0.784. However, TadGAN still produces competitive results in both scenarios.\n\nHow well do AutoEncoders perform? To view the superiority of GAN, we compare it to other reconstruction-based method such as LSTM AE, and Dense AE. One striking result is that the auto encoder alone does not perform well on point anomalies. We observe that as LSTM AE and Dense AE obtained an average F1 Score on A3 and A4 of 0.205 and 0.082 respectively. On the other hand, TadGAN and MAD-GAN achieved a higher score of 0.643 and 0.527 respectively. One potential reason could be that AutoEncoders are optimizing L2 function and strictly attempt to fit the data, resulting in that anomalies get fitted as well. However, adversarial learning does not have this type of issue.\n\nTadGAN v.s. MadGAN. Overall, TadGAN (0.7) outperformed Mad-GAN (0.219) significantly. This fully demonstrates the usage of forward cycle-consistency loss (Eq. 5) which prevents the contradiction between two Generators E and G and paves the most direct way to the optimal z i that corresponds to the testing sample x i . Mad-GAN uses only vanilla GAN and does not include any regularization mechanisms to guarantee the mapping route x i \u2192 z i \u2192x i . Their approach to finding the optimal z i is that they first sample a random z from the latent space and then optimize it with gradient descent algorithm by optimizing the anomaly detection loss.\n\n\nAblation Study\n\nWe evaluated multiple variations of TadGAN, each variation using different anomaly score computation methods (Sec. 4.3). The results are summarized in Table 4. Here we reported some impressive insights.\n\nOnly using Critic is unstable, because it has the lowest averaged F1 score (0.29) and the highest standard deviation (0.237). Only using Critic can achieve good performance in some datasets such as SMAP and Art, but its performance may also be unexpectedly bad such as in A2, A3, A4, AdEx, and Traf. No clear shared characteristics are identified among these five datasets (see Table 2). For example, some datasets contain only collective anomalies (Traf, AdEx) while other datasets like A3 and A4 may have point anomalies as the majority types of anomalies. Perhaps one explanation could be that Critic's behavior is unpredictable when confronted with anomalies (x \u2241 P X ), because it is only taught to distinguish real time segments (x \u223c P X ) from generated ones.\n\nDTW outperforms the other two reconstruction error types slightly. Among all the variations, Critic\u00d7DTW has the best score (0.629). Further, its standard deviation is smaller than most of the other variations except for Point, indicating this combination is more stable than others. Therefore, this combination would be the safe choice when we are encountering new datasets without labels.\n\nCombining Critic outputs and reconstruction errors does improve the performance in most cases. In most cases, the combination ways achieve the best performance except fro A4. Let us take MSL dataset as an example. We observe that the F1 score of simply using DTW is 0.514. After multiplying the Critic score, we obtain 0.623 despite the fact that the F1 score of using Critic only is 0.393. In addition, we can find that after combining the Critic scores, the averaged F1 score is improved for each of the individual reconstruction error computation methods. However, one interesting pattern is that for dataset A4 that is almost consisted of point anomalies, using only point-wise errors achieve the best performance.\n\nMultiplication is a better option than convex combination.\n\nMultiplication constantly has higher averaged F1 score than convex combination's when using the same reconstruction error type (e.g., CritictimePoint v.s. Critic+Point). Moreover, multiplication also has smaller standard deviations constantly. Thus, multiplication is the recommended way to combine reconstruction scores and Critic scores. This can be explained by the intuition that multiplication can better amplify high anomaly scores.\n\n\nLimitations and Discussion\n\nWe compare our approach to one of the well-known GANbased anomaly detection methods [24]. However, there is a copious amount of GAN architectures tailored for time series reconstruction such as Time-Series GAN [37]. Given our modular design, we enable any reconstruction-based algorithm of time series to employ our anomaly scoring method for time series anomaly detection. In the future, we plan to investigate various strategies for time-series reconstruction and compare their performance to the current state-of-the-art.\n\n\nConclusion\n\nIn this paper, we presented a novel TadGAN framework that allows for time series reconstruction and effective anomaly detection, showing how GANs can be effectively used for anomaly detection in time series data. We explored point-wise and window-based methods to compute reconstruction errors. We further proposed two different ways to combine reconstruction errors and Critic outputs to obtain anomaly scores at every time step. We have also tested several anomaly-scoring techniques and reported the bestsuited one in this work. Our experimental results showed that (1) TadGAN outperformed all the baseline methods by having the highest averaged F1 score across all the datasets, and showed superior performance over baseline methods in 6 out of 11 datasets; (2) window-based reconstruction errors outperformed the point-wise method; and (3) the combination of both reconstruction errors and critic outputs offer more robust anomaly scores, which help to reduce the number of false positives as well as increase the number of true positives. Finally, our code is open source and is available as a tool for benchmarking time series datasets for anomaly detection.  Table 5. Precision, Recall and F1-Scores of baseline models\n\nTable 2 .\n2Dataset summary with information about the anomaly types. Overall the benchmark dataset contains a total of 492 signals and \n2349 anomalies. \n\n\n\n\nTable 4. F1-Scores of all the variations of our model.NASA \nYahoo S5 \nNAB \n\nVariation \nMSL SMAP A1 \nA2 \nA3 \nA4 \nArt \nAdEx AWS Traf \nTweets Mean+SD \n\nCritic \n0.393 0.672 \n0.285 0.118 0.008 0.024 0.625 0 \n0.35 \n0.167 0.548 \n0.290\u00b10.237 \nPoint \n0.585 0.588 \n0.674 0.758 0.628 0.6 \n0.588 0.611 0.551 0.383 0.571 \n0.594\u00b10.086 \nArea \n0.525 0.655 \n0.681 0.82 \n0.567 0.523 0.625 0.645 0.59 \n0.435 0.559 \n0.602\u00b10.096 \nDTW \n0.514 0.581 \n0.697 0.794 0.613 0.547 0.714 0.69 \n0.633 0.455 0.559 \n0.618\u00b10.095 \nCritic\u00d7Point 0.619 0.675 \n0.703 0.75 \n0.685 0.536 0.588 0.579 0.576 0.4 \n0.59 \n0.609\u00b10.091 \nCritic+Point \n0.529 0.653 \n0.8 \n0.78 \n0.571 0.44 \n0.625 0.595 0.644 0.439 0.592 \n0.606\u00b10.111 \nCritic\u00d7Area \n0.578 0.704 \n0.719 0.867 0.587 0.46 \n0.8 \n0.6 \n0.6 \n0.4 \n0.571 \n0.625\u00b10.131 \nCritic+Area \n0.493 0.692 \n0.789 0.847 0.483 0.367 0.75 \n0.75 \n0.607 0.474 0.6 \n0.623\u00b10.148 \nCritic\u00d7DTW 0.623 0.68 \n0.667 0.82 \n0.631 0.497 0.667 0.667 0.61 \n0.455 0.605 \n0.629\u00b10.091 \nCritic+DTW 0.462 0.658 \n0.735 0.857 0.523 0.388 0.667 0.8 \n0.632 0.486 0.609 \n0.620\u00b10.139 \nMean \n0.532 0.655 \n0.675 0.741 0.529 0.438 0.664 0.593 0.579 0.409 0.580 \nSD \n0.068 0.039 \n0.137 0.211 0.182 0.154 0.067 0.209 0.081 0.087 0.02 \n\n\nThe software is available at github https://github. com/signals-dev/Orion.\nSpacecraft telemetry data: https://s3-us-west-2. amazonaws.com/telemanom/data.zip 3 Yahoo S5 data can be requested here: https:// webscope.sandbox.yahoo.com/catalog.php? datatype=s&did=70 4 NAB data: https://github.com/numenta/NAB/ tree/master/data\nAppendix\nUnsupervised real-time anomaly detection for streaming data. S Ahmad, A Lavin, S Purdy, Agha , Z , Neurocomputing. 262Ahmad, S., Lavin, A., Purdy, S., and Agha, Z. Un- supervised real-time anomaly detection for streaming data. Neurocomputing, 262:134-147, 2017.\n\nVariational autoencoder based anomaly detection using reconstruction probability. J An, S Cho, Special Lecture on IE. 21An, J. and Cho, S. Variational autoencoder based anomaly detection using reconstruction probability. Special Lecture on IE, 2(1), 2015.\n\nFast outlier detection in high dimensional spaces. F Angiulli, C Pizzuti, European Conference on Principles of Data Mining and Knowledge Discovery. SpringerAngiulli, F. and Pizzuti, C. Fast outlier detection in high dimensional spaces. In European Conference on Principles of Data Mining and Knowledge Discovery, pp. 15-27. Springer, 2002.\n\nWasserstein generative adversarial networks. M Arjovsky, S Chintala, L Bottou, Proc. of the 34th Int. Conf. on Machine Learning, ICML. of the 34th Int. Conf. on Machine Learning, ICMLArjovsky, M., Chintala, S., and Bottou, L. Wasser- stein generative adversarial networks. In Proc. of the 34th Int. Conf. on Machine Learning, ICML, pp. 214- 223, 2017.\n\nUsing Dynamic Time Warping to Find Patterns in Time Series. D J Bemdt, J Clifford, AAAI-94 Workshop on Knowledge Discovery in Databases. Seattle, WashingtonBemdt, D. J. and Clifford, J. Using Dynamic Time Warping to Find Patterns in Time Series. In AAAI- 94 Workshop on Knowledge Discovery in Databases, Seattle, Washington, 1994.\n\nTime series analysis: forecasting and control. G E Box, G M Jenkins, G C Reinsel, G M Ljung, John Wiley & SonsBox, G. E., Jenkins, G. M., Reinsel, G. C., and Ljung, G. M. Time series analysis: forecasting and control. John Wiley & Sons, 2015.\n\nLof: identifying density-based local outliers. M M Breunig, H.-P Kriegel, R T Ng, J Sander, Proceedings of the 2000 ACM SIGMOD international conference on Management of data. the 2000 ACM SIGMOD international conference on Management of dataBreunig, M. M., Kriegel, H.-P., Ng, R. T., and Sander, J. Lof: identifying density-based local out- liers. In Proceedings of the 2000 ACM SIGMOD in- ternational conference on Management of data, pp. 93-104, 2000.\n\nAnomaly detection: A survey. V Chandola, A Banerjee, V Kumar, ACM computing surveys (CSUR). 41315Chandola, V., Banerjee, A., and Kumar, V. Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3):15, 2009.\n\nFrom model, signal to knowledge: A data-driven perspective of fault detection and diagnosis. X Dai, Z Gao, IEEE Transactions on Industrial Informatics. 94Dai, X. and Gao, Z. From model, signal to knowledge: A data-driven perspective of fault detection and diag- nosis. IEEE Transactions on Industrial Informatics, 9 (4):2226-2238, 2013.\n\nAutomated Learning and Monitoring of Limit Functions. D Decoste, International Symposium on Artificial Intelligence, Robotics, and Automation in Space. Decoste, D. Automated Learning and Monitoring of Limit Functions. In International Symposium on Arti- ficial Intelligence, Robotics, and Automation in Space, 1997.\n\nAnomaly detection with generative adversarial networks. L Deecke, R Vandermeulen, L Ruff, S Mandt, M Kloft, Deecke, L., Vandermeulen, R., Ruff, L., Mandt, S., and Kloft, M. Anomaly detection with genera- tive adversarial networks, 2018. URL https:// openreview.net/forum?id=S1EfylZ0Z.\n\nAdversarial Feature Learning. J Donahue, P Kr\u00e4henb\u00fchl, Darrell , T , IEEE Int. Conf. on Learning Representations (ICLR. Donahue, J., Kr\u00e4henb\u00fchl, P., and Darrell, T. Adversar- ial Feature Learning. In IEEE Int. Conf. on Learning Representations (ICLR), 2017.\n\nAdversarially Learned Inference. V Dumoulin, I Belghazi, B Poole, O Mastropietro, A Lamb, M Arjovsky, A Courville, IEEE Int. Conf. on Learning Representations (ICLR. Dumoulin, V., Belghazi, I., Poole, B., Mastropietro, O., Lamb, A., Arjovsky, M., and Courville, A. Ad- versarially Learned Inference. In IEEE Int. Conf. on Learning Representations (ICLR), 2017.\n\nAnomaly detection in cyber physical systems using recurrent neural networks. J Goh, S Adepu, M Tan, Z S Lee, IEEE 18th International Symposium on High Assurance Systems Engineering (HASE). Goh, J., Adepu, S., Tan, M., and Lee, Z. S. Anomaly detection in cyber physical systems using recurrent neural networks. 2017 IEEE 18th International Symposium on High Assurance Systems Engineering (HASE), pp. 140-145, 2017.\n\nA comparative evaluation of unsupervised anomaly detection algorithms for multivariate data. M Goldstein, S Uchida, PLOS ONE. 1142016Goldstein, M. and Uchida, S. A comparative evalu- ation of unsupervised anomaly detection algorithms for multivariate data. PLOS ONE, 11(4):1-31, 04 2016.\n\nGenerative Adversarial Nets. I J Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Advances in neural information processing systems. Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. Generative Adversarial Nets. In Advances in neural information processing systems, pp. 2672- 2680, 2014.\n\nImproved Training of Wasserstein GANs. I Gulrajani, F Ahmed, M Arjovsky, V Dumoulin, A Courville, Proc. of the 31st Int. Conf. on Neural Information Processing Systems. of the 31st Int. Conf. on Neural Information essing SystemsGulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., and Courville, A. Improved Training of Wasserstein GANs. In Proc. of the 31st Int. Conf. on Neural Infor- mation Processing Systems, pp. 5769-5779, 2017.\n\nReal-time big data processing for anomaly detection: A survey. R A A Habeeb, F Nasaruddin, A Gani, I A T Hashem, E Ahmed, M Imran, International Journal of Information Management. 45Habeeb, R. A. A., Nasaruddin, F., Gani, A., Hashem, I. A. T., Ahmed, E., and Imran, M. Real-time big data processing for anomaly detection: A survey. In- ternational Journal of Information Management, 45: 289-307, 2019.\n\nDiscovering clusterbased local outliers. Z He, X Xu, S Deng, Pattern Recognition Letters. 249He, Z., Xu, X., and Deng, S. Discovering cluster- based local outliers. Pattern Recognition Letters, 24 (9-10):1641-1650, 2003.\n\nA survey of outlier detection methodologies. V Hodge, J Austin, Artificial intelligence review. 222Hodge, V. and Austin, J. A survey of outlier detection methodologies. Artificial intelligence review, 22(2): 85-126, 2004.\n\nDetecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding. K Hundman, V Constantinou, C Laporte, I Colwell, T Soderstrom, 978-1-4503-5552-0Proc. of the 24th ACM SIGKDD Int. Conf. on Knowledge Discovery & Data Mining. of the 24th ACM SIGKDD Int. Conf. on Knowledge Discovery & Data MiningHundman, K., Constantinou, V., Laporte, C., Col- well, I., and Soderstrom, T. Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dy- namic Thresholding. In Proc. of the 24th ACM SIGKDD Int. Conf. on Knowledge Discovery & Data Mining, 2018. ISBN 978-1-4503-5552-0.\n\nA survey of deep learning-based network anomaly detection. D Kwon, H Kim, J Kim, S C Suh, I Kim, K J Kim, Cluster Computing. 22Kwon, D., Kim, H., Kim, J., Suh, S. C., Kim, I., and Kim, K. J. A survey of deep learning-based network anomaly detection. Cluster Computing, 22:949-961, 2017.\n\nEvaluating real-time anomaly detection algorithms-the numenta anomaly benchmark. A Lavin, S Ahmad, IEEE 14th International Conference on Machine Learning and Applications (ICMLA). Lavin, A. and Ahmad, S. Evaluating real-time anomaly detection algorithms-the numenta anomaly benchmark. In 2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA), pp. 38-44, 2015.\n\nMad-gan: Multivariate anomaly detection for time series data with generative adversarial networks. D Li, D Chen, B Jin, L Shi, J Goh, S.-K Ng, International Conference on Artificial Neural Networks. SpringerLi, D., Chen, D., Jin, B., Shi, L., Goh, J., and Ng, S.-K. Mad-gan: Multivariate anomaly detection for time series data with generative adversarial networks. In International Conference on Artificial Neural Net- works, pp. 703-716. Springer, 2019.\n\nAdversarial autoencoders. A Makhzani, J Shlens, N Jaitly, I Goodfellow, International Conference on Learning Representations, Workshop Track. Makhzani, A., Shlens, J., Jaitly, N., and Goodfellow, I. Adversarial autoencoders. In International Confer- ence on Learning Representations, Workshop Track, 2016.\n\nLong Short Term Memory Networks for Anomaly Detection in Time Series. P Malhotra, L Vig, G Shroff, P Agarwal, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning. ISBN 9782875870148Malhotra, P., Vig, L., Shroff, G., and Agarwal, P. Long Short Term Memory Networks for Anomaly De- tection in Time Series. In European Symposium on Ar- tificial Neural Networks, Computational Intelligence and Machine Learning, 2015. ISBN 9782875870148.\n\nLSTM-based encoderdecoder for multi-sensor anomaly detection. P Malhotra, A Ramakrishnan, G Anand, L Vig, P Agarwal, G Shroff, Anomaly Detection Workshop at 33rd Int. Conf. on Machine Learning (ICML). Malhotra, P., Ramakrishnan, A., Anand, G., Vig, L., Agarwal, P., and Shroff, G. LSTM-based encoder- decoder for multi-sensor anomaly detection. In Anomaly Detection Workshop at 33rd Int. Conf. on Machine Learning (ICML), 2016.\n\nEnhanced Telemetry Monitoring with Novelty Detection. J.-A Mart\u00ednez-Heras, A Donati, 0738-4602AI Magazine. 35437Mart\u00ednez-Heras, J.-A. and Donati, A. Enhanced Telemetry Monitoring with Novelty Detection. AI Magazine, 35(4):37, 2014. ISSN 0738-4602.\n\nAnomaly detection using forecasting methods arima and hwds. E H Pena, M V De Assis, M L Proen\u00e7a, 32nd International Conference of the Chilean Computer Science Society (SCCC). Pena, E. H., de Assis, M. V., and Proen\u00e7a, M. L. Anomaly detection using forecasting methods arima and hwds. In 2013 32nd International Conference of the Chilean Computer Science Society (SCCC), pp. 63-66, 2013.\n\nTimeseries anomaly detection service at microsoft. H Ren, B Xu, Y Wang, C Yi, C Huang, X Kou, T Xing, M Yang, J Tong, Q Zhang, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningRen, H., Xu, B., Wang, Y., Yi, C., Huang, C., Kou, X., Xing, T., Yang, M., Tong, J., and Zhang, Q. Time- series anomaly detection service at microsoft. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 3009-3017, 2019.\n\nSensitivity of pca for traffic anomaly detection. H Ringberg, A Soule, J Rexford, C Diot, Proceedings of the 2007 ACM SIGMETRICS international conference on Measurement and modeling of computer systems. the 2007 ACM SIGMETRICS international conference on Measurement and modeling of computer systemsRingberg, H., Soule, A., Rexford, J., and Diot, C. Sensitivity of pca for traffic anomaly detection. In Proceedings of the 2007 ACM SIGMETRICS interna- tional conference on Measurement and modeling of computer systems, pp. 109-120, 2007.\n\nProbabilistic forecasting with autoregressive recurrent networks. D Salinas, V Flunkert, J Gasthaus, T Januschowski, Deepar, International Journal of Forecasting. Salinas, D., Flunkert, V., Gasthaus, J., and Januschowski, T. Deepar: Probabilistic forecasting with autoregressive recurrent networks. International Journal of Forecasting, 2019.\n\nUnsupervised anomaly detection with generative adversarial networks to guide marker discovery. T Schlegl, P Seeb\u00f6ck, S M Waldstein, U Schmidt-Erfurth, G Langs, International Conference on Information Processing in Medical Imaging. SpringerSchlegl, T., Seeb\u00f6ck, P., Waldstein, S. M., Schmidt- Erfurth, U., and Langs, G. Unsupervised anomaly de- tection with generative adversarial networks to guide marker discovery. In International Conference on In- formation Processing in Medical Imaging, pp. 146- 157. Springer, 2017.\n\nFast unsupervised anomaly detection with generative adversarial networks. T Schlegl, P Seebck, S M Waldstein, G Langs, U Schmidt-Erfurth, 1361-8415Medical Image Analysis. 54Schlegl, T., Seebck, P., Waldstein, S. M., Langs, G., and Schmidt-Erfurth, U. f-AnoGAN: Fast unsuper- vised anomaly detection with generative adversarial networks. Medical Image Analysis, 54:30 -44, 2019. ISSN 1361-8415.\n\nDetection of outliers in gas emissions from urban areas using functional data analysis. J M Torres, P G Nieto, L Alejano, Reyes , A , Journal of hazardous materials. 1861Torres, J. M., Nieto, P. G., Alejano, L., and Reyes, A. Detection of outliers in gas emissions from urban areas using functional data analysis. Journal of haz- ardous materials, 186(1):144-149, 2011.\n\nGenerating videos with scene dynamics. C Vondrick, H Pirsiavash, A Torralba, Advances in neural information processing systems. Vondrick, C., Pirsiavash, H., and Torralba, A. Gen- erating videos with scene dynamics. In Advances in neural information processing systems, pp. 613-621, 2016.\n\nTimeseries generative adversarial networks. J Yoon, D Jarrett, M Van Der Schaar, Advances in Neural Information Processing Systems. Curran Associates, Inc32Yoon, J., Jarrett, D., and van der Schaar, M. Time- series generative adversarial networks. In Advances in Neural Information Processing Systems 32, pp. 5509- 5519. Curran Associates, Inc., 2019.\n\nAdversarially Learned Anomaly Detection. H Zenati, M Romain, C.-S Foo, B Lecouat, V Chandrasekhar, 978-1-5386- 9159-5IEEE Int. Conf. on Data Mining (ICDM). Zenati, H., Romain, M., Foo, C.-S., Lecouat, B., and Chandrasekhar, V. Adversarially Learned Anomaly Detection. In IEEE Int. Conf. on Data Mining (ICDM), pp. 727-736, nov 2018. ISBN 978-1-5386- 9159-5.\n\nSelf-adaptive statistical process control for anomaly detection in time series. D Zheng, F Li, T Zhao, Expert Systems with Applications. 57Zheng, D., Li, F., and Zhao, T. Self-adaptive statisti- cal process control for anomaly detection in time se- ries. Expert Systems with Applications, 57:324-336, 2016.\n\nAnomalous Rhythm Detection using Adversarially Generated Time Series. B Zhou, S Liu, B Hooi, X Cheng, Ye , J Beatgan, Proc. of the 28th Int. Joint Conf. on Artificial Intelligence, (IJCAI). of the 28th Int. Joint Conf. on Artificial Intelligence, (IJCAI)Zhou, B., Liu, S., Hooi, B., Cheng, X., and Ye, J. BeatGAN: Anomalous Rhythm Detection using Ad- versarially Generated Time Series. In Proc. of the 28th Int. Joint Conf. on Artificial Intelligence, (IJCAI), pp. 4433-4439, 2019.\n\nUnpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks. J.-Y Zhu, T Park, P Isola, A A Efros, IEEE Int. Conf. on Computer Vision (ICCV). Zhu, J.-Y., Park, T., Isola, P., and Efros, A. A. Unpaired Image-to-Image Translation Using Cycle- Consistent Adversarial Networks. In IEEE Int. Conf. on Computer Vision (ICCV), pp. 2242-2251, oct 2017. ISBN 978-1-5386-1032-9.\n", "annotations": {"author": "[{\"end\":107,\"start\":90},{\"end\":119,\"start\":108},{\"end\":139,\"start\":120},{\"end\":163,\"start\":140},{\"end\":186,\"start\":164}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":100},{\"end\":118,\"start\":115},{\"end\":138,\"start\":126},{\"end\":162,\"start\":148},{\"end\":185,\"start\":171}]", "author_first_name": "[{\"end\":99,\"start\":90},{\"end\":114,\"start\":108},{\"end\":125,\"start\":120},{\"end\":147,\"start\":140},{\"end\":170,\"start\":164}]", "author_affiliation": null, "title": "[{\"end\":76,\"start\":1},{\"end\":262,\"start\":187}]", "venue": null, "abstract": "[{\"end\":2305,\"start\":659}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2612,\"start\":2609},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2906,\"start\":2903},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3130,\"start\":3127},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3425,\"start\":3422},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3427,\"start\":3425},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3553,\"start\":3549},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4361,\"start\":4358},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4389,\"start\":4385},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4407,\"start\":4403},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4428,\"start\":4424},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4450,\"start\":4446},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4470,\"start\":4466},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4690,\"start\":4686},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4904,\"start\":4900},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4907,\"start\":4904},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4910,\"start\":4907},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4971,\"start\":4967},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5016,\"start\":5012},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5146,\"start\":5142},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8609,\"start\":8605},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":8611,\"start\":8609},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8614,\"start\":8611},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8617,\"start\":8614},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8730,\"start\":8726},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8733,\"start\":8730},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9345,\"start\":9342},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9532,\"start\":9529},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9579,\"start\":9575},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10205,\"start\":10201},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10224,\"start\":10220},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10238,\"start\":10234},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10465,\"start\":10462},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10828,\"start\":10824},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":11437,\"start\":11433},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11636,\"start\":11633},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11753,\"start\":11750},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11789,\"start\":11786},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11819,\"start\":11815},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12537,\"start\":12533},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12561,\"start\":12557},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12588,\"start\":12584},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12695,\"start\":12691},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12698,\"start\":12695},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":12753,\"start\":12749},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13081,\"start\":13077},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":13449,\"start\":13445},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13474,\"start\":13470},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":13738,\"start\":13734},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14208,\"start\":14204},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":14387,\"start\":14383},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":14564,\"start\":14560},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16932,\"start\":16929},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":17078,\"start\":17074},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17934,\"start\":17931},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18931,\"start\":18927},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":19897,\"start\":19893},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":20309,\"start\":20305},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21356,\"start\":21353},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21359,\"start\":21356},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":21362,\"start\":21359},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21365,\"start\":21362},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21368,\"start\":21365},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21371,\"start\":21368},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21374,\"start\":21371},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21377,\"start\":21374},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21380,\"start\":21377},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21384,\"start\":21380},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21388,\"start\":21384},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":21392,\"start\":21388},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21396,\"start\":21392},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21400,\"start\":21396},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":23226,\"start\":23223},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23397,\"start\":23393},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23401,\"start\":23397},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":23405,\"start\":23401},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23409,\"start\":23405},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23413,\"start\":23409},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":23417,\"start\":23413},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25373,\"start\":25370},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":27919,\"start\":27915},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":27922,\"start\":27919},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":29386,\"start\":29382},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":30315,\"start\":30314},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30499,\"start\":30495},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":30578,\"start\":30577},{\"end\":32907,\"start\":32903},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":33750,\"start\":33746},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":34256,\"start\":34253},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":34858,\"start\":34854},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":35042,\"start\":35038},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":35151,\"start\":35147},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":35900,\"start\":35896},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":36235,\"start\":36231},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":41585,\"start\":41581},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":41711,\"start\":41707}]", "figure": "[{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":43418,\"start\":43263},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":44612,\"start\":43419}]", "paragraph": "[{\"end\":2907,\"start\":2321},{\"end\":3428,\"start\":2909},{\"end\":3778,\"start\":3430},{\"end\":4303,\"start\":3780},{\"end\":4662,\"start\":4319},{\"end\":5822,\"start\":4664},{\"end\":6601,\"start\":5824},{\"end\":7066,\"start\":6603},{\"end\":7119,\"start\":7068},{\"end\":7938,\"start\":7121},{\"end\":8030,\"start\":7940},{\"end\":8402,\"start\":8032},{\"end\":8969,\"start\":8461},{\"end\":9891,\"start\":8971},{\"end\":10964,\"start\":9893},{\"end\":11396,\"start\":10966},{\"end\":11820,\"start\":11398},{\"end\":12389,\"start\":11822},{\"end\":12699,\"start\":12423},{\"end\":13356,\"start\":12701},{\"end\":13874,\"start\":13358},{\"end\":14782,\"start\":13876},{\"end\":15175,\"start\":14784},{\"end\":15776,\"start\":15231},{\"end\":15906,\"start\":15823},{\"end\":16079,\"start\":15908},{\"end\":17124,\"start\":16114},{\"end\":17269,\"start\":17145},{\"end\":17874,\"start\":17330},{\"end\":18187,\"start\":17876},{\"end\":18416,\"start\":18287},{\"end\":18987,\"start\":18474},{\"end\":19139,\"start\":18989},{\"end\":19384,\"start\":19173},{\"end\":19474,\"start\":19411},{\"end\":20102,\"start\":19509},{\"end\":20535,\"start\":20193},{\"end\":20646,\"start\":20554},{\"end\":21495,\"start\":20722},{\"end\":22637,\"start\":22315},{\"end\":22791,\"start\":22639},{\"end\":23418,\"start\":22838},{\"end\":23790,\"start\":23476},{\"end\":24373,\"start\":23825},{\"end\":24565,\"start\":24375},{\"end\":24788,\"start\":24584},{\"end\":25268,\"start\":24826},{\"end\":25964,\"start\":25270},{\"end\":26177,\"start\":26020},{\"end\":26616,\"start\":26227},{\"end\":27138,\"start\":26618},{\"end\":27574,\"start\":27164},{\"end\":27923,\"start\":27576},{\"end\":28115,\"start\":27963},{\"end\":28258,\"start\":28148},{\"end\":29857,\"start\":28294},{\"end\":30642,\"start\":29893},{\"end\":31468,\"start\":30644},{\"end\":32020,\"start\":31510},{\"end\":32635,\"start\":32037},{\"end\":33411,\"start\":32658},{\"end\":33604,\"start\":33433},{\"end\":33751,\"start\":33606},{\"end\":33908,\"start\":33765},{\"end\":34193,\"start\":33910},{\"end\":34603,\"start\":34195},{\"end\":34921,\"start\":34605},{\"end\":35382,\"start\":34923},{\"end\":35726,\"start\":35435},{\"end\":35779,\"start\":35728},{\"end\":36113,\"start\":35837},{\"end\":36728,\"start\":36115},{\"end\":37175,\"start\":36753},{\"end\":37543,\"start\":37177},{\"end\":38220,\"start\":37545},{\"end\":38866,\"start\":38222},{\"end\":39087,\"start\":38885},{\"end\":39855,\"start\":39089},{\"end\":40246,\"start\":39857},{\"end\":40966,\"start\":40248},{\"end\":41026,\"start\":40968},{\"end\":41466,\"start\":41028},{\"end\":42021,\"start\":41497},{\"end\":43262,\"start\":42036}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15822,\"start\":15777},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16113,\"start\":16080},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17329,\"start\":17270},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18286,\"start\":18188},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18473,\"start\":18417},{\"attributes\":{\"id\":\"formula_5\"},\"end\":19172,\"start\":19140},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19508,\"start\":19475},{\"attributes\":{\"id\":\"formula_7\"},\"end\":20151,\"start\":20103},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20192,\"start\":20151},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20721,\"start\":20647},{\"attributes\":{\"id\":\"formula_10\"},\"end\":22265,\"start\":21496},{\"attributes\":{\"id\":\"formula_11\"},\"end\":22837,\"start\":22792},{\"attributes\":{\"id\":\"formula_12\"},\"end\":23824,\"start\":23791},{\"attributes\":{\"id\":\"formula_13\"},\"end\":24583,\"start\":24566},{\"attributes\":{\"id\":\"formula_14\"},\"end\":24825,\"start\":24789},{\"attributes\":{\"id\":\"formula_15\"},\"end\":26019,\"start\":25965},{\"attributes\":{\"id\":\"formula_16\"},\"end\":27962,\"start\":27924},{\"attributes\":{\"id\":\"formula_17\"},\"end\":28147,\"start\":28116}]", "table_ref": "[{\"end\":4489,\"start\":4482},{\"end\":5513,\"start\":5506},{\"end\":5820,\"start\":5813},{\"end\":7065,\"start\":7058},{\"end\":27662,\"start\":27655},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30845,\"start\":30838},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":33179,\"start\":32944},{\"end\":36488,\"start\":36481},{\"end\":36876,\"start\":36869},{\"end\":39043,\"start\":39036},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":39474,\"start\":39467},{\"end\":43210,\"start\":43203}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2319,\"start\":2307},{\"end\":4317,\"start\":4306},{\"attributes\":{\"n\":\"2.\"},\"end\":8417,\"start\":8405},{\"attributes\":{\"n\":\"2.1.\"},\"end\":8459,\"start\":8420},{\"attributes\":{\"n\":\"2.2.\"},\"end\":12421,\"start\":12392},{\"attributes\":{\"n\":\"3.\"},\"end\":15229,\"start\":15178},{\"attributes\":{\"n\":\"3.1.\"},\"end\":17143,\"start\":17127},{\"attributes\":{\"n\":\"3.2.\"},\"end\":19409,\"start\":19387},{\"attributes\":{\"n\":\"3.3.\"},\"end\":20552,\"start\":20538},{\"attributes\":{\"n\":\"4.\"},\"end\":22313,\"start\":22267},{\"attributes\":{\"n\":\"4.1.\"},\"end\":23474,\"start\":23421},{\"attributes\":{\"n\":\"4.2.\"},\"end\":26225,\"start\":26180},{\"attributes\":{\"n\":\"4.3.\"},\"end\":27162,\"start\":27141},{\"attributes\":{\"n\":\"4.4.\"},\"end\":28292,\"start\":28261},{\"attributes\":{\"n\":\"5.\"},\"end\":29880,\"start\":29860},{\"attributes\":{\"n\":\"5.1.\"},\"end\":29891,\"start\":29883},{\"attributes\":{\"n\":\"5.2.\"},\"end\":31489,\"start\":31471},{\"attributes\":{\"n\":\"5.2.1.\"},\"end\":31508,\"start\":31492},{\"attributes\":{\"n\":\"5.2.2.\"},\"end\":32035,\"start\":32023},{\"attributes\":{\"n\":\"5.2.3.\"},\"end\":32656,\"start\":32638},{\"end\":33431,\"start\":33414},{\"attributes\":{\"n\":\"5.2.4.\"},\"end\":33763,\"start\":33754},{\"end\":35433,\"start\":35385},{\"end\":35835,\"start\":35782},{\"attributes\":{\"n\":\"5.3.\"},\"end\":36751,\"start\":36731},{\"attributes\":{\"n\":\"5.4.\"},\"end\":38883,\"start\":38869},{\"attributes\":{\"n\":\"5.5.\"},\"end\":41495,\"start\":41469},{\"attributes\":{\"n\":\"6.\"},\"end\":42034,\"start\":42024},{\"end\":43273,\"start\":43264}]", "table": "[{\"end\":43418,\"start\":43275},{\"end\":44612,\"start\":43475}]", "figure_caption": "[{\"end\":43475,\"start\":43421}]", "figure_ref": "[{\"end\":15705,\"start\":15697},{\"end\":16238,\"start\":16232},{\"end\":19590,\"start\":19582},{\"end\":20781,\"start\":20772}]", "bib_author_first_name": "[{\"end\":45008,\"start\":45007},{\"end\":45017,\"start\":45016},{\"end\":45026,\"start\":45025},{\"end\":45038,\"start\":45034},{\"end\":45042,\"start\":45041},{\"end\":45292,\"start\":45291},{\"end\":45298,\"start\":45297},{\"end\":45518,\"start\":45517},{\"end\":45530,\"start\":45529},{\"end\":45853,\"start\":45852},{\"end\":45865,\"start\":45864},{\"end\":45877,\"start\":45876},{\"end\":46221,\"start\":46220},{\"end\":46223,\"start\":46222},{\"end\":46232,\"start\":46231},{\"end\":46540,\"start\":46539},{\"end\":46542,\"start\":46541},{\"end\":46549,\"start\":46548},{\"end\":46551,\"start\":46550},{\"end\":46562,\"start\":46561},{\"end\":46564,\"start\":46563},{\"end\":46575,\"start\":46574},{\"end\":46577,\"start\":46576},{\"end\":46784,\"start\":46783},{\"end\":46786,\"start\":46785},{\"end\":46800,\"start\":46796},{\"end\":46811,\"start\":46810},{\"end\":46813,\"start\":46812},{\"end\":46819,\"start\":46818},{\"end\":47221,\"start\":47220},{\"end\":47233,\"start\":47232},{\"end\":47245,\"start\":47244},{\"end\":47500,\"start\":47499},{\"end\":47507,\"start\":47506},{\"end\":47799,\"start\":47798},{\"end\":48118,\"start\":48117},{\"end\":48128,\"start\":48127},{\"end\":48144,\"start\":48143},{\"end\":48152,\"start\":48151},{\"end\":48161,\"start\":48160},{\"end\":48378,\"start\":48377},{\"end\":48389,\"start\":48388},{\"end\":48409,\"start\":48402},{\"end\":48413,\"start\":48412},{\"end\":48640,\"start\":48639},{\"end\":48652,\"start\":48651},{\"end\":48664,\"start\":48663},{\"end\":48673,\"start\":48672},{\"end\":48689,\"start\":48688},{\"end\":48697,\"start\":48696},{\"end\":48709,\"start\":48708},{\"end\":49046,\"start\":49045},{\"end\":49053,\"start\":49052},{\"end\":49062,\"start\":49061},{\"end\":49069,\"start\":49068},{\"end\":49071,\"start\":49070},{\"end\":49477,\"start\":49476},{\"end\":49490,\"start\":49489},{\"end\":49702,\"start\":49701},{\"end\":49704,\"start\":49703},{\"end\":49718,\"start\":49717},{\"end\":49735,\"start\":49734},{\"end\":49744,\"start\":49743},{\"end\":49750,\"start\":49749},{\"end\":49766,\"start\":49765},{\"end\":49775,\"start\":49774},{\"end\":49788,\"start\":49787},{\"end\":50110,\"start\":50109},{\"end\":50123,\"start\":50122},{\"end\":50132,\"start\":50131},{\"end\":50144,\"start\":50143},{\"end\":50156,\"start\":50155},{\"end\":50571,\"start\":50570},{\"end\":50575,\"start\":50572},{\"end\":50585,\"start\":50584},{\"end\":50599,\"start\":50598},{\"end\":50607,\"start\":50606},{\"end\":50611,\"start\":50608},{\"end\":50621,\"start\":50620},{\"end\":50630,\"start\":50629},{\"end\":50952,\"start\":50951},{\"end\":50958,\"start\":50957},{\"end\":50964,\"start\":50963},{\"end\":51178,\"start\":51177},{\"end\":51187,\"start\":51186},{\"end\":51439,\"start\":51438},{\"end\":51450,\"start\":51449},{\"end\":51466,\"start\":51465},{\"end\":51477,\"start\":51476},{\"end\":51488,\"start\":51487},{\"end\":52001,\"start\":52000},{\"end\":52009,\"start\":52008},{\"end\":52016,\"start\":52015},{\"end\":52023,\"start\":52022},{\"end\":52025,\"start\":52024},{\"end\":52032,\"start\":52031},{\"end\":52039,\"start\":52038},{\"end\":52041,\"start\":52040},{\"end\":52311,\"start\":52310},{\"end\":52320,\"start\":52319},{\"end\":52721,\"start\":52720},{\"end\":52727,\"start\":52726},{\"end\":52735,\"start\":52734},{\"end\":52742,\"start\":52741},{\"end\":52749,\"start\":52748},{\"end\":52759,\"start\":52755},{\"end\":53104,\"start\":53103},{\"end\":53116,\"start\":53115},{\"end\":53126,\"start\":53125},{\"end\":53136,\"start\":53135},{\"end\":53455,\"start\":53454},{\"end\":53467,\"start\":53466},{\"end\":53474,\"start\":53473},{\"end\":53484,\"start\":53483},{\"end\":53928,\"start\":53927},{\"end\":53940,\"start\":53939},{\"end\":53956,\"start\":53955},{\"end\":53965,\"start\":53964},{\"end\":53972,\"start\":53971},{\"end\":53983,\"start\":53982},{\"end\":54352,\"start\":54348},{\"end\":54370,\"start\":54369},{\"end\":54604,\"start\":54603},{\"end\":54606,\"start\":54605},{\"end\":54614,\"start\":54613},{\"end\":54616,\"start\":54615},{\"end\":54628,\"start\":54627},{\"end\":54630,\"start\":54629},{\"end\":54983,\"start\":54982},{\"end\":54990,\"start\":54989},{\"end\":54996,\"start\":54995},{\"end\":55004,\"start\":55003},{\"end\":55010,\"start\":55009},{\"end\":55019,\"start\":55018},{\"end\":55026,\"start\":55025},{\"end\":55034,\"start\":55033},{\"end\":55042,\"start\":55041},{\"end\":55050,\"start\":55049},{\"end\":55563,\"start\":55562},{\"end\":55575,\"start\":55574},{\"end\":55584,\"start\":55583},{\"end\":55595,\"start\":55594},{\"end\":56117,\"start\":56116},{\"end\":56128,\"start\":56127},{\"end\":56140,\"start\":56139},{\"end\":56152,\"start\":56151},{\"end\":56490,\"start\":56489},{\"end\":56501,\"start\":56500},{\"end\":56512,\"start\":56511},{\"end\":56514,\"start\":56513},{\"end\":56527,\"start\":56526},{\"end\":56546,\"start\":56545},{\"end\":56992,\"start\":56991},{\"end\":57003,\"start\":57002},{\"end\":57013,\"start\":57012},{\"end\":57015,\"start\":57014},{\"end\":57028,\"start\":57027},{\"end\":57037,\"start\":57036},{\"end\":57401,\"start\":57400},{\"end\":57403,\"start\":57402},{\"end\":57413,\"start\":57412},{\"end\":57415,\"start\":57414},{\"end\":57424,\"start\":57423},{\"end\":57439,\"start\":57434},{\"end\":57443,\"start\":57442},{\"end\":57723,\"start\":57722},{\"end\":57735,\"start\":57734},{\"end\":57749,\"start\":57748},{\"end\":58018,\"start\":58017},{\"end\":58026,\"start\":58025},{\"end\":58037,\"start\":58036},{\"end\":58368,\"start\":58367},{\"end\":58378,\"start\":58377},{\"end\":58391,\"start\":58387},{\"end\":58398,\"start\":58397},{\"end\":58409,\"start\":58408},{\"end\":58766,\"start\":58765},{\"end\":58775,\"start\":58774},{\"end\":58781,\"start\":58780},{\"end\":59064,\"start\":59063},{\"end\":59072,\"start\":59071},{\"end\":59079,\"start\":59078},{\"end\":59087,\"start\":59086},{\"end\":59097,\"start\":59095},{\"end\":59101,\"start\":59100},{\"end\":59561,\"start\":59557},{\"end\":59568,\"start\":59567},{\"end\":59576,\"start\":59575},{\"end\":59585,\"start\":59584},{\"end\":59587,\"start\":59586}]", "bib_author_last_name": "[{\"end\":45014,\"start\":45009},{\"end\":45023,\"start\":45018},{\"end\":45032,\"start\":45027},{\"end\":45295,\"start\":45293},{\"end\":45302,\"start\":45299},{\"end\":45527,\"start\":45519},{\"end\":45538,\"start\":45531},{\"end\":45862,\"start\":45854},{\"end\":45874,\"start\":45866},{\"end\":45884,\"start\":45878},{\"end\":46229,\"start\":46224},{\"end\":46241,\"start\":46233},{\"end\":46546,\"start\":46543},{\"end\":46559,\"start\":46552},{\"end\":46572,\"start\":46565},{\"end\":46583,\"start\":46578},{\"end\":46794,\"start\":46787},{\"end\":46808,\"start\":46801},{\"end\":46816,\"start\":46814},{\"end\":46826,\"start\":46820},{\"end\":47230,\"start\":47222},{\"end\":47242,\"start\":47234},{\"end\":47251,\"start\":47246},{\"end\":47504,\"start\":47501},{\"end\":47511,\"start\":47508},{\"end\":47807,\"start\":47800},{\"end\":48125,\"start\":48119},{\"end\":48141,\"start\":48129},{\"end\":48149,\"start\":48145},{\"end\":48158,\"start\":48153},{\"end\":48167,\"start\":48162},{\"end\":48386,\"start\":48379},{\"end\":48400,\"start\":48390},{\"end\":48649,\"start\":48641},{\"end\":48661,\"start\":48653},{\"end\":48670,\"start\":48665},{\"end\":48686,\"start\":48674},{\"end\":48694,\"start\":48690},{\"end\":48706,\"start\":48698},{\"end\":48719,\"start\":48710},{\"end\":49050,\"start\":49047},{\"end\":49059,\"start\":49054},{\"end\":49066,\"start\":49063},{\"end\":49075,\"start\":49072},{\"end\":49487,\"start\":49478},{\"end\":49497,\"start\":49491},{\"end\":49715,\"start\":49705},{\"end\":49732,\"start\":49719},{\"end\":49741,\"start\":49736},{\"end\":49747,\"start\":49745},{\"end\":49763,\"start\":49751},{\"end\":49772,\"start\":49767},{\"end\":49785,\"start\":49776},{\"end\":49795,\"start\":49789},{\"end\":50120,\"start\":50111},{\"end\":50129,\"start\":50124},{\"end\":50141,\"start\":50133},{\"end\":50153,\"start\":50145},{\"end\":50166,\"start\":50157},{\"end\":50582,\"start\":50576},{\"end\":50596,\"start\":50586},{\"end\":50604,\"start\":50600},{\"end\":50618,\"start\":50612},{\"end\":50627,\"start\":50622},{\"end\":50636,\"start\":50631},{\"end\":50955,\"start\":50953},{\"end\":50961,\"start\":50959},{\"end\":50969,\"start\":50965},{\"end\":51184,\"start\":51179},{\"end\":51194,\"start\":51188},{\"end\":51447,\"start\":51440},{\"end\":51463,\"start\":51451},{\"end\":51474,\"start\":51467},{\"end\":51485,\"start\":51478},{\"end\":51499,\"start\":51489},{\"end\":52006,\"start\":52002},{\"end\":52013,\"start\":52010},{\"end\":52020,\"start\":52017},{\"end\":52029,\"start\":52026},{\"end\":52036,\"start\":52033},{\"end\":52045,\"start\":52042},{\"end\":52317,\"start\":52312},{\"end\":52326,\"start\":52321},{\"end\":52724,\"start\":52722},{\"end\":52732,\"start\":52728},{\"end\":52739,\"start\":52736},{\"end\":52746,\"start\":52743},{\"end\":52753,\"start\":52750},{\"end\":52762,\"start\":52760},{\"end\":53113,\"start\":53105},{\"end\":53123,\"start\":53117},{\"end\":53133,\"start\":53127},{\"end\":53147,\"start\":53137},{\"end\":53464,\"start\":53456},{\"end\":53471,\"start\":53468},{\"end\":53481,\"start\":53475},{\"end\":53492,\"start\":53485},{\"end\":53937,\"start\":53929},{\"end\":53953,\"start\":53941},{\"end\":53962,\"start\":53957},{\"end\":53969,\"start\":53966},{\"end\":53980,\"start\":53973},{\"end\":53990,\"start\":53984},{\"end\":54367,\"start\":54353},{\"end\":54377,\"start\":54371},{\"end\":54611,\"start\":54607},{\"end\":54625,\"start\":54617},{\"end\":54638,\"start\":54631},{\"end\":54987,\"start\":54984},{\"end\":54993,\"start\":54991},{\"end\":55001,\"start\":54997},{\"end\":55007,\"start\":55005},{\"end\":55016,\"start\":55011},{\"end\":55023,\"start\":55020},{\"end\":55031,\"start\":55027},{\"end\":55039,\"start\":55035},{\"end\":55047,\"start\":55043},{\"end\":55056,\"start\":55051},{\"end\":55572,\"start\":55564},{\"end\":55581,\"start\":55576},{\"end\":55592,\"start\":55585},{\"end\":55600,\"start\":55596},{\"end\":56125,\"start\":56118},{\"end\":56137,\"start\":56129},{\"end\":56149,\"start\":56141},{\"end\":56165,\"start\":56153},{\"end\":56173,\"start\":56167},{\"end\":56498,\"start\":56491},{\"end\":56509,\"start\":56502},{\"end\":56524,\"start\":56515},{\"end\":56543,\"start\":56528},{\"end\":56552,\"start\":56547},{\"end\":57000,\"start\":56993},{\"end\":57010,\"start\":57004},{\"end\":57025,\"start\":57016},{\"end\":57034,\"start\":57029},{\"end\":57053,\"start\":57038},{\"end\":57410,\"start\":57404},{\"end\":57421,\"start\":57416},{\"end\":57432,\"start\":57425},{\"end\":57732,\"start\":57724},{\"end\":57746,\"start\":57736},{\"end\":57758,\"start\":57750},{\"end\":58023,\"start\":58019},{\"end\":58034,\"start\":58027},{\"end\":58052,\"start\":58038},{\"end\":58375,\"start\":58369},{\"end\":58385,\"start\":58379},{\"end\":58395,\"start\":58392},{\"end\":58406,\"start\":58399},{\"end\":58423,\"start\":58410},{\"end\":58772,\"start\":58767},{\"end\":58778,\"start\":58776},{\"end\":58786,\"start\":58782},{\"end\":59069,\"start\":59065},{\"end\":59076,\"start\":59073},{\"end\":59084,\"start\":59080},{\"end\":59093,\"start\":59088},{\"end\":59109,\"start\":59102},{\"end\":59565,\"start\":59562},{\"end\":59573,\"start\":59569},{\"end\":59582,\"start\":59577},{\"end\":59593,\"start\":59588}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":207117713},\"end\":45207,\"start\":44946},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":36663713},\"end\":45464,\"start\":45209},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":41515630},\"end\":45805,\"start\":45466},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2057420},\"end\":46158,\"start\":45807},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":929893},\"end\":46490,\"start\":46160},{\"attributes\":{\"id\":\"b5\"},\"end\":46734,\"start\":46492},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6787631},\"end\":47189,\"start\":46736},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207172599},\"end\":47404,\"start\":47191},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":18268457},\"end\":47742,\"start\":47406},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":5399967},\"end\":48059,\"start\":47744},{\"attributes\":{\"id\":\"b10\"},\"end\":48345,\"start\":48061},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":84591},\"end\":48604,\"start\":48347},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":6104263},\"end\":48966,\"start\":48606},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":26489392},\"end\":49381,\"start\":48968},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3562477},\"end\":49670,\"start\":49383},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1033682},\"end\":50068,\"start\":49672},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":10894094},\"end\":50505,\"start\":50070},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":106407449},\"end\":50908,\"start\":50507},{\"attributes\":{\"id\":\"b18\"},\"end\":51130,\"start\":50910},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":3330313},\"end\":51353,\"start\":51132},{\"attributes\":{\"doi\":\"978-1-4503-5552-0\",\"id\":\"b20\",\"matched_paper_id\":3625298},\"end\":51939,\"start\":51355},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":4505261},\"end\":52227,\"start\":51941},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":6842305},\"end\":52619,\"start\":52229},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":58007096},\"end\":53075,\"start\":52621},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":5092785},\"end\":53382,\"start\":53077},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":43680425},\"end\":53863,\"start\":53384},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":9286983},\"end\":54292,\"start\":53865},{\"attributes\":{\"doi\":\"0738-4602\",\"id\":\"b27\",\"matched_paper_id\":18524238},\"end\":54541,\"start\":54294},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":8396303},\"end\":54929,\"start\":54543},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":182952311},\"end\":55510,\"start\":54931},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":1237823},\"end\":56048,\"start\":55512},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":12199225},\"end\":56392,\"start\":56050},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":17427022},\"end\":56915,\"start\":56394},{\"attributes\":{\"doi\":\"1361-8415\",\"id\":\"b33\"},\"end\":57310,\"start\":56917},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":23838478},\"end\":57681,\"start\":57312},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":9933254},\"end\":57971,\"start\":57683},{\"attributes\":{\"id\":\"b36\"},\"end\":58324,\"start\":57973},{\"attributes\":{\"doi\":\"978-1-5386- 9159-5\",\"id\":\"b37\",\"matched_paper_id\":54448471},\"end\":58683,\"start\":58326},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":28355246},\"end\":58991,\"start\":58685},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":198975275},\"end\":59474,\"start\":58993},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":195944196},\"end\":59864,\"start\":59476}]", "bib_title": "[{\"end\":45005,\"start\":44946},{\"end\":45289,\"start\":45209},{\"end\":45515,\"start\":45466},{\"end\":45850,\"start\":45807},{\"end\":46218,\"start\":46160},{\"end\":46781,\"start\":46736},{\"end\":47218,\"start\":47191},{\"end\":47497,\"start\":47406},{\"end\":47796,\"start\":47744},{\"end\":48375,\"start\":48347},{\"end\":48637,\"start\":48606},{\"end\":49043,\"start\":48968},{\"end\":49474,\"start\":49383},{\"end\":49699,\"start\":49672},{\"end\":50107,\"start\":50070},{\"end\":50568,\"start\":50507},{\"end\":50949,\"start\":50910},{\"end\":51175,\"start\":51132},{\"end\":51436,\"start\":51355},{\"end\":51998,\"start\":51941},{\"end\":52308,\"start\":52229},{\"end\":52718,\"start\":52621},{\"end\":53101,\"start\":53077},{\"end\":53452,\"start\":53384},{\"end\":53925,\"start\":53865},{\"end\":54346,\"start\":54294},{\"end\":54601,\"start\":54543},{\"end\":54980,\"start\":54931},{\"end\":55560,\"start\":55512},{\"end\":56114,\"start\":56050},{\"end\":56487,\"start\":56394},{\"end\":56989,\"start\":56917},{\"end\":57398,\"start\":57312},{\"end\":57720,\"start\":57683},{\"end\":58015,\"start\":57973},{\"end\":58365,\"start\":58326},{\"end\":58763,\"start\":58685},{\"end\":59061,\"start\":58993},{\"end\":59555,\"start\":59476}]", "bib_author": "[{\"end\":45016,\"start\":45007},{\"end\":45025,\"start\":45016},{\"end\":45034,\"start\":45025},{\"end\":45041,\"start\":45034},{\"end\":45045,\"start\":45041},{\"end\":45297,\"start\":45291},{\"end\":45304,\"start\":45297},{\"end\":45529,\"start\":45517},{\"end\":45540,\"start\":45529},{\"end\":45864,\"start\":45852},{\"end\":45876,\"start\":45864},{\"end\":45886,\"start\":45876},{\"end\":46231,\"start\":46220},{\"end\":46243,\"start\":46231},{\"end\":46548,\"start\":46539},{\"end\":46561,\"start\":46548},{\"end\":46574,\"start\":46561},{\"end\":46585,\"start\":46574},{\"end\":46796,\"start\":46783},{\"end\":46810,\"start\":46796},{\"end\":46818,\"start\":46810},{\"end\":46828,\"start\":46818},{\"end\":47232,\"start\":47220},{\"end\":47244,\"start\":47232},{\"end\":47253,\"start\":47244},{\"end\":47506,\"start\":47499},{\"end\":47513,\"start\":47506},{\"end\":47809,\"start\":47798},{\"end\":48127,\"start\":48117},{\"end\":48143,\"start\":48127},{\"end\":48151,\"start\":48143},{\"end\":48160,\"start\":48151},{\"end\":48169,\"start\":48160},{\"end\":48388,\"start\":48377},{\"end\":48402,\"start\":48388},{\"end\":48412,\"start\":48402},{\"end\":48416,\"start\":48412},{\"end\":48651,\"start\":48639},{\"end\":48663,\"start\":48651},{\"end\":48672,\"start\":48663},{\"end\":48688,\"start\":48672},{\"end\":48696,\"start\":48688},{\"end\":48708,\"start\":48696},{\"end\":48721,\"start\":48708},{\"end\":49052,\"start\":49045},{\"end\":49061,\"start\":49052},{\"end\":49068,\"start\":49061},{\"end\":49077,\"start\":49068},{\"end\":49489,\"start\":49476},{\"end\":49499,\"start\":49489},{\"end\":49717,\"start\":49701},{\"end\":49734,\"start\":49717},{\"end\":49743,\"start\":49734},{\"end\":49749,\"start\":49743},{\"end\":49765,\"start\":49749},{\"end\":49774,\"start\":49765},{\"end\":49787,\"start\":49774},{\"end\":49797,\"start\":49787},{\"end\":50122,\"start\":50109},{\"end\":50131,\"start\":50122},{\"end\":50143,\"start\":50131},{\"end\":50155,\"start\":50143},{\"end\":50168,\"start\":50155},{\"end\":50584,\"start\":50570},{\"end\":50598,\"start\":50584},{\"end\":50606,\"start\":50598},{\"end\":50620,\"start\":50606},{\"end\":50629,\"start\":50620},{\"end\":50638,\"start\":50629},{\"end\":50957,\"start\":50951},{\"end\":50963,\"start\":50957},{\"end\":50971,\"start\":50963},{\"end\":51186,\"start\":51177},{\"end\":51196,\"start\":51186},{\"end\":51449,\"start\":51438},{\"end\":51465,\"start\":51449},{\"end\":51476,\"start\":51465},{\"end\":51487,\"start\":51476},{\"end\":51501,\"start\":51487},{\"end\":52008,\"start\":52000},{\"end\":52015,\"start\":52008},{\"end\":52022,\"start\":52015},{\"end\":52031,\"start\":52022},{\"end\":52038,\"start\":52031},{\"end\":52047,\"start\":52038},{\"end\":52319,\"start\":52310},{\"end\":52328,\"start\":52319},{\"end\":52726,\"start\":52720},{\"end\":52734,\"start\":52726},{\"end\":52741,\"start\":52734},{\"end\":52748,\"start\":52741},{\"end\":52755,\"start\":52748},{\"end\":52764,\"start\":52755},{\"end\":53115,\"start\":53103},{\"end\":53125,\"start\":53115},{\"end\":53135,\"start\":53125},{\"end\":53149,\"start\":53135},{\"end\":53466,\"start\":53454},{\"end\":53473,\"start\":53466},{\"end\":53483,\"start\":53473},{\"end\":53494,\"start\":53483},{\"end\":53939,\"start\":53927},{\"end\":53955,\"start\":53939},{\"end\":53964,\"start\":53955},{\"end\":53971,\"start\":53964},{\"end\":53982,\"start\":53971},{\"end\":53992,\"start\":53982},{\"end\":54369,\"start\":54348},{\"end\":54379,\"start\":54369},{\"end\":54613,\"start\":54603},{\"end\":54627,\"start\":54613},{\"end\":54640,\"start\":54627},{\"end\":54989,\"start\":54982},{\"end\":54995,\"start\":54989},{\"end\":55003,\"start\":54995},{\"end\":55009,\"start\":55003},{\"end\":55018,\"start\":55009},{\"end\":55025,\"start\":55018},{\"end\":55033,\"start\":55025},{\"end\":55041,\"start\":55033},{\"end\":55049,\"start\":55041},{\"end\":55058,\"start\":55049},{\"end\":55574,\"start\":55562},{\"end\":55583,\"start\":55574},{\"end\":55594,\"start\":55583},{\"end\":55602,\"start\":55594},{\"end\":56127,\"start\":56116},{\"end\":56139,\"start\":56127},{\"end\":56151,\"start\":56139},{\"end\":56167,\"start\":56151},{\"end\":56175,\"start\":56167},{\"end\":56500,\"start\":56489},{\"end\":56511,\"start\":56500},{\"end\":56526,\"start\":56511},{\"end\":56545,\"start\":56526},{\"end\":56554,\"start\":56545},{\"end\":57002,\"start\":56991},{\"end\":57012,\"start\":57002},{\"end\":57027,\"start\":57012},{\"end\":57036,\"start\":57027},{\"end\":57055,\"start\":57036},{\"end\":57412,\"start\":57400},{\"end\":57423,\"start\":57412},{\"end\":57434,\"start\":57423},{\"end\":57442,\"start\":57434},{\"end\":57446,\"start\":57442},{\"end\":57734,\"start\":57722},{\"end\":57748,\"start\":57734},{\"end\":57760,\"start\":57748},{\"end\":58025,\"start\":58017},{\"end\":58036,\"start\":58025},{\"end\":58054,\"start\":58036},{\"end\":58377,\"start\":58367},{\"end\":58387,\"start\":58377},{\"end\":58397,\"start\":58387},{\"end\":58408,\"start\":58397},{\"end\":58425,\"start\":58408},{\"end\":58774,\"start\":58765},{\"end\":58780,\"start\":58774},{\"end\":58788,\"start\":58780},{\"end\":59071,\"start\":59063},{\"end\":59078,\"start\":59071},{\"end\":59086,\"start\":59078},{\"end\":59095,\"start\":59086},{\"end\":59100,\"start\":59095},{\"end\":59111,\"start\":59100},{\"end\":59567,\"start\":59557},{\"end\":59575,\"start\":59567},{\"end\":59584,\"start\":59575},{\"end\":59595,\"start\":59584}]", "bib_venue": "[{\"end\":45990,\"start\":45942},{\"end\":46316,\"start\":46297},{\"end\":46977,\"start\":46911},{\"end\":50298,\"start\":50239},{\"end\":51666,\"start\":51596},{\"end\":55237,\"start\":55156},{\"end\":55811,\"start\":55715},{\"end\":59247,\"start\":59183},{\"end\":45059,\"start\":45045},{\"end\":45325,\"start\":45304},{\"end\":45612,\"start\":45540},{\"end\":45940,\"start\":45886},{\"end\":46295,\"start\":46243},{\"end\":46537,\"start\":46492},{\"end\":46909,\"start\":46828},{\"end\":47281,\"start\":47253},{\"end\":47556,\"start\":47513},{\"end\":47894,\"start\":47809},{\"end\":48115,\"start\":48061},{\"end\":48465,\"start\":48416},{\"end\":48770,\"start\":48721},{\"end\":49155,\"start\":49077},{\"end\":49507,\"start\":49499},{\"end\":49846,\"start\":49797},{\"end\":50237,\"start\":50168},{\"end\":50685,\"start\":50638},{\"end\":50998,\"start\":50971},{\"end\":51226,\"start\":51196},{\"end\":51594,\"start\":51518},{\"end\":52064,\"start\":52047},{\"end\":52407,\"start\":52328},{\"end\":52818,\"start\":52764},{\"end\":53217,\"start\":53149},{\"end\":53591,\"start\":53494},{\"end\":54064,\"start\":53992},{\"end\":54399,\"start\":54388},{\"end\":54716,\"start\":54640},{\"end\":55154,\"start\":55058},{\"end\":55713,\"start\":55602},{\"end\":56211,\"start\":56175},{\"end\":56623,\"start\":56554},{\"end\":57086,\"start\":57064},{\"end\":57476,\"start\":57446},{\"end\":57809,\"start\":57760},{\"end\":58103,\"start\":58054},{\"end\":58480,\"start\":58443},{\"end\":58820,\"start\":58788},{\"end\":59181,\"start\":59111},{\"end\":59636,\"start\":59595}]"}}}, "year": 2023, "month": 12, "day": 17}